{
  "date": "2025-08-02",
  "category": "cs.AI",
  "summary": "æ¬¢è¿æ¥åˆ° UTC æ—¶é—´ 2025-08-02 çš„ arXiv ä¸­æ–‡ TLDR å¿«æŠ¥ï¼\n\nğŸ‘‹ **ä¸€å¥è¯æ€»ç»“ï¼š**\nä»Šå¤©çš„ arXiv å……æ»¡äº†å¯¹ LLM æœ¬è´¨èƒ½åŠ›çš„æ·±åˆ»åæ€ä¸æ¶æ„ä¼˜åŒ–ï¼Œä»è´¨ç–‘â€œæ€ç»´é“¾â€æ¨ç†çš„çœŸå®æ€§ï¼Œåˆ°é’ˆå¯¹ Agent å®‰å…¨å’Œ MoE æ•ˆç‡çš„ç¡¬æ ¸å·¥ç¨‹ï¼›ä¸æ­¤åŒæ—¶ï¼ŒAI åœ¨å¾®é‡åŠ›æ— äººæœºæ§åˆ¶ã€å°åº¦å¤å…¸éŸ³ä¹å’Œå…‰è°±å­¦ç­‰å‚ç±»é¢†åŸŸçš„åº”ç”¨ä¹Ÿä»¤äººçœ¼å‰ä¸€äº®ã€‚\n\n---\n\n### ğŸš€ æ·±åº¦å¯¹é½ä¸æ¨ç†æœ¬è´¨ (Reasoning & Alignment)\n\n**ä»Šå¤©çš„é‡ç£…è®¨è®ºé›†ä¸­åœ¨ LLM çš„â€œæ€è€ƒâ€ç©¶ç«Ÿæ˜¯ä¸æ˜¯ä¸€ç§å¹»è§‰ï¼Œä»¥åŠå¦‚ä½•æ›´å®‰å…¨åœ°æ§åˆ¶å®ƒä»¬ã€‚**\n\n**1. Is Chain-of-Thought Reasoning of LLMs a Mirage? A Data Distribution Lens**\n**LLM çš„æ€ç»´é“¾æ¨ç†æ˜¯æµ·å¸‚èœƒæ¥¼å—ï¼ŸåŸºäºæ•°æ®åˆ†å¸ƒè§†è§’çš„é€è§†**\n> è¿™ç¯‡æ–‡ç« å¯¹å½“å‰ç«çƒ­çš„ CoT æå‡ºäº†å°–é”è´¨ç–‘ã€‚ä½œè€…å‡è®¾ CoT æ¨ç†å¹¶éçœŸæ­£çš„é€»è¾‘æ¨ç†ï¼Œè€Œæ˜¯å¯¹è®­ç»ƒæ•°æ®ä¸­è§‚å¯Ÿåˆ°çš„æ¨ç†è½¨è¿¹çš„â€œç»“æ„åŒ–å½’çº³åç½®â€çš„æ¨¡ä»¿ã€‚é€šè¿‡æ„å»ºä¸€ä¸ªå®Œå…¨å¯æ§çš„è®­ç»ƒç¯å¢ƒ DataAlchemyï¼Œç ”ç©¶å‘ç°å½“æµ‹è¯•æ•°æ®è¶…å‡ºè®­ç»ƒåˆ†å¸ƒæ—¶ï¼ŒCoT çš„æ¨ç†èƒ½åŠ›ä¼šè¿…é€Ÿå´©æºƒã€‚è¿™è¡¨æ˜ç›®å‰çš„ CoT æ›´å¤šæ˜¯åœ¨æ‹Ÿåˆåˆ†å¸ƒï¼Œè€Œéå®ç°äº†é€šç”¨çš„æ¨ç†æ³›åŒ–ã€‚\n\n**2. PUZZLED: Jailbreaking LLMs through Word-Based Puzzles**\n**PUZZLEDï¼šé€šè¿‡æ–‡å­—è°œé¢˜å¯¹ LLM è¿›è¡Œè¶Šç‹±**\n> ä¸€ç§æ–°çš„è¶Šç‹±æ”»å‡»æ–¹å¼ã€‚æ”»å‡»è€…å°†æ¶æ„æŒ‡ä»¤ä¸­çš„å…³é”®è¯éšè—åœ¨â€œå­—è°œâ€ï¼ˆå¦‚å•è¯æœç´¢ã€å˜ä½è¯ã€å¡«å­—æ¸¸æˆï¼‰ä¸­ã€‚ç”±äº LLM å…·å¤‡è§£è°œèƒ½åŠ›ï¼Œå®ƒä»¬ä¼šå…ˆè§£å¼€è°œé¢˜æ¢å¤å…³é”®è¯ï¼Œç„¶åé¡ºåŠ¿æ‰§è¡Œäº†æ¶æ„æŒ‡ä»¤ã€‚åœ¨ GPT-4.1 å’Œ Claude 3.7 ä¸Šï¼Œè¿™ç§æ–¹æ³•çš„æ”»å‡»æˆåŠŸç‡é«˜è¾¾ 90% ä»¥ä¸Šï¼Œæ­ç¤ºäº†æ¨¡å‹æ¨ç†èƒ½åŠ›åè¢«åˆ©ç”¨çš„å®‰å…¨æ¼æ´ã€‚\n\n**3. AgentArmor: Enforcing Program Analysis on Agent Runtime Trace to Defend Against Prompt Injection**\n**AgentArmorï¼šåœ¨ Agent è¿è¡Œæ—¶è½¨è¿¹ä¸Šå®æ–½ç¨‹åºåˆ†æä»¥é˜²å¾¡æç¤ºæ³¨å…¥**\n> Agent çš„å®‰å…¨æ€§æ˜¯ä¸ªå¤§é—®é¢˜ã€‚è¿™ç¯‡æ–‡ç« æå‡ºå°† Agent çš„è¿è¡Œæ—¶è½¨è¿¹è§†ä¸ºâ€œç»“æ„åŒ–ç¨‹åºâ€ï¼Œé€šè¿‡æ§åˆ¶æµå›¾ï¼ˆCFGï¼‰å’Œæ•°æ®æµåˆ†ææ¥å®æ–½å®‰å…¨ç­–ç•¥ã€‚è¿™å°±åƒæ˜¯ç»™ Agent è£…äº†ä¸€ä¸ªæ€æ¯’è½¯ä»¶çš„å®æ—¶ç›‘æ§ï¼Œèƒ½æœ‰æ•ˆæ£€æµ‹å¹¶æ‹¦æˆªæç¤ºæ³¨å…¥æ”»å‡»ï¼Œåœ¨ AgentDojo åŸºå‡†æµ‹è¯•ä¸­å°†æ”»å‡»æˆåŠŸç‡é™è‡³ 3%ã€‚\n\n---\n\n### ğŸ—ï¸ æ¶æ„ä¼˜åŒ–ä¸ç³»ç»Ÿæ•ˆç‡ (Architecture & Systems)\n\n**å¤§æ¨¡å‹ä¸ä»…è¦å¤§ï¼Œè¿˜è¦å¿«ã€è¦çœæ˜¾å­˜ã€‚ä»Šå¤©çš„å‡ ç¯‡è®ºæ–‡åœ¨ MoE å’Œ KV Cache ä¸Šæœ‰æ‰å®çš„è´¡çŒ®ã€‚**\n\n**4. Unifying Mixture of Experts and Multi-Head Latent Attention for Efficient Language Models**\n**ç»Ÿä¸€æ··åˆä¸“å®¶ä¸å¤šå¤´æ½œåœ¨æ³¨æ„åŠ›ä»¥æ„å»ºé«˜æ•ˆè¯­è¨€æ¨¡å‹**\n> æå‡ºäº† **MoE-MLA-RoPE** æ¶æ„ã€‚é€šè¿‡ç»“åˆ MoEï¼ˆæ··åˆä¸“å®¶ï¼‰ã€MLAï¼ˆå¤šå¤´æ½œåœ¨æ³¨æ„åŠ›ï¼‰å’Œ RoPEï¼Œè§£å†³äº†æ¨¡å‹å®¹é‡ä¸è®¡ç®—æ•ˆç‡çš„æƒè¡¡ã€‚è¯¥æ¶æ„ä½¿ç”¨äº†ç»†ç²’åº¦çš„ä¸“å®¶è·¯ç”±ï¼ˆ64ä¸ªå¾®ä¸“å®¶ï¼‰å’Œå…±äº«ä¸“å®¶éš”ç¦»æœºåˆ¶ã€‚ç»“æœæ˜¾ç¤ºï¼Œåœ¨ä¿æŒå›°æƒ‘åº¦å‡ ä¹ä¸å˜çš„æƒ…å†µä¸‹ï¼ŒKV Cache æ˜¾å­˜å‡å°‘äº† 68%ï¼Œæ¨ç†é€Ÿåº¦æå‡äº† 3.2 å€ã€‚\n\n**5. PiKV: KV Cache Management System for Mixture of Experts**\n**PiKVï¼šé¢å‘æ··åˆä¸“å®¶æ¨¡å‹çš„ KV ç¼“å­˜ç®¡ç†ç³»ç»Ÿ**\n> é’ˆå¯¹ MoE æ¶æ„çš„ KV Cache ç“¶é¢ˆï¼Œæå‡ºäº† PiKV ç³»ç»Ÿã€‚å®ƒé‡‡ç”¨äº†ä¸“å®¶åˆ†ç‰‡å­˜å‚¨ï¼ˆExpert-sharded storageï¼‰å’Œè‡ªé€‚åº”ä¿ç•™ç­–ç•¥ï¼Œè§£å†³äº† MoE åœ¨å¤š GPU æ¨ç†æ—¶çš„é€šä¿¡å’Œæ˜¾å­˜å¼€é”€é—®é¢˜ã€‚å¯¹äºéƒ¨ç½²è¶…å¤§ä¸Šä¸‹æ–‡ MoE æ¨¡å‹æ¥è¯´ï¼Œè¿™æ˜¯ä¸€ä¸ªéå¸¸å®ç”¨çš„ç³»ç»Ÿçº§ä¼˜åŒ–ã€‚\n\n**6. FlashSVD: Memory-Efficient Inference with Streaming for Low-Rank Models**\n**FlashSVDï¼šä½ç§©æ¨¡å‹çš„é«˜æ•ˆæµå¼æ¨ç†**\n> é’ˆå¯¹ SVD å‹ç¼©åçš„ LLM æ¨ç†æ˜¾å­˜é—®é¢˜ï¼Œæå‡ºäº† FlashSVDã€‚å®ƒé€šè¿‡å°†ä½ç§©æŠ•å½±æ ¸ç›´æ¥èåˆåˆ° Attention å’Œ FFN ç®¡é“ä¸­ï¼Œé¿å…äº†å…¨å°ºå¯¸æ¿€æ´»ç¼“å†²åŒºçš„ç‰©åŒ–ã€‚åœ¨ BERT-Base ç­‰æ¨¡å‹ä¸Šï¼Œå³°å€¼æ¿€æ´»æ˜¾å­˜å‡å°‘äº† 70% ä»¥ä¸Šï¼Œä¸”ä¸æŸå¤±ç²¾åº¦ï¼Œéå¸¸é€‚åˆç«¯ä¾§éƒ¨ç½²ã€‚\n\n---\n\n### ğŸ¤– æœºå™¨äººä¸å…·èº«æ™ºèƒ½ (Robotics & Embodied AI)\n\n**7. Decentralized Aerial Manipulation of a Cable-Suspended Load using Multi-Agent Reinforcement Learning**\n**åŸºäºå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ çš„ç»³ç´¢æ‚¬æŒ‚è´Ÿè½½å»ä¸­å¿ƒåŒ–ç©ºä¸­æ“çºµ**\n> **å°è±¡æ·±åˆ»çš„æ§åˆ¶å·¥ä½œã€‚** å®ç°äº†ä¸€ç¾¤å¾®å‹æ— äººæœºï¼ˆMAVï¼‰ååŒæ¬è¿ç‰©ä½“ï¼Œè€Œä¸”æ˜¯å®Œå…¨å»ä¸­å¿ƒåŒ–çš„ã€‚æ¯ä¸ªæ— äººæœºä¸éœ€è¦çŸ¥é“é˜Ÿå‹çš„çŠ¶æ€ï¼Œç”šè‡³ä¸éœ€è¦é€šä¿¡ï¼Œä»…é€šè¿‡è§‚å¯Ÿè´Ÿè½½çš„å§¿æ€å°±èƒ½éšå¼åä½œã€‚è¿™ç§æ–¹æ³•å¤§å¤§é™ä½äº†è®¡ç®—æˆæœ¬ï¼Œä¸”å¯¹æŸæ¶æ— äººæœºçªç„¶æ‰çº¿å…·æœ‰æå¼ºçš„é²æ£’æ€§ã€‚\n\n**8. RoboMemory: A Brain-inspired Multi-memory Agentic Framework for Interactive Environmental Learning**\n**RoboMemoryï¼šé¢å‘å…·èº«ç³»ç»Ÿäº¤äº’å¼ç¯å¢ƒå­¦ä¹ çš„è„‘å¯å‘å¤šè®°å¿† Agent æ¡†æ¶**\n> ä¸ºäº†è§£å†³å…·èº«æ™ºèƒ½ï¼ˆå¦‚æœºå™¨äººï¼‰åœ¨é•¿ç¨‹ä»»åŠ¡ä¸­çš„é—å¿˜å’Œè§„åˆ’é—®é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªåŒ…å«ç©ºé—´ã€æ—¶é—´ã€æƒ…æ™¯å’Œè¯­ä¹‰è®°å¿†çš„ç»Ÿä¸€æ¡†æ¶ã€‚ç»“åˆåŠ¨æ€ç©ºé—´çŸ¥è¯†å›¾è°±ï¼Œè¯¥ç³»ç»Ÿåœ¨ EmbodiedBench ä¸Šçš„æˆåŠŸç‡æ¯” Gemini-1.5-Pro é«˜å‡º 3%ï¼Œå±•ç¤ºäº†ç±»è„‘è®°å¿†æœºåˆ¶åœ¨æœºå™¨äººé¢†åŸŸçš„æ½œåŠ›ã€‚\n\n---\n\n### ğŸµ è‰ºæœ¯ã€ç§‘å­¦ä¸å‚ç±»åº”ç”¨ (Arts & Science)\n\n**ä»Šå¤©çš„ arXiv åœ¨éä¸»æµé¢†åŸŸï¼ˆå°¤å…¶æ˜¯éŸ³ä¹ï¼‰æœ‰éå¸¸æœ‰æ„æ€çš„å·¥ä½œã€‚**\n\n**9. ShrutiSense: Microtonal Modeling and Correction in Indian Classical Music**\n**ShrutiSenseï¼šå°åº¦å¤å…¸éŸ³ä¹ä¸­çš„å¾®åˆ†éŸ³å»ºæ¨¡ä¸ä¿®æ­£**\n> è¿™æ˜¯ä¸€ä¸ªéå¸¸å‚ç›´ä½†æ–‡åŒ–æ„ä¹‰é‡å¤§çš„å·¥ä½œã€‚å°åº¦å¤å…¸éŸ³ä¹ä¾èµ–äº 22 ä¸ªâ€œShrutisâ€ï¼ˆå¾®åˆ†éŸ³ï¼‰ï¼Œç°æœ‰çš„è¥¿æ–¹ 12 å¹³å‡å¾‹ç³»ç»Ÿæ— æ³•æ•æ‰å…¶ç²¾é«“ã€‚ä½œè€…æå‡ºäº† ShrutiSenseï¼Œåˆ©ç”¨æœ‰é™çŠ¶æ€è½¬æ¢å™¨å’Œè¯­æ³•çº¦æŸçš„éšé©¬å°”å¯å¤«æ¨¡å‹ï¼Œèƒ½å¤Ÿç²¾ç¡®è¯†åˆ«å’Œä¿®æ­£å°åº¦æ‹‰æ ¼éŸ³ä¹ä¸­çš„å¾®åˆ†éŸ³åºåˆ—ï¼Œä¿æŠ¤äº†éŸ³ä¹çš„æ–‡åŒ–çœŸå®æ€§ã€‚\n\n**10. Via Score to Performance: Efficient Human-Controllable Long Song Generation with Bar-Level Symbolic Notation**\n**ä»ä¹è°±åˆ°æ¼”å¥ï¼šåŸºäºå°èŠ‚çº§ç¬¦å·ä¹è°±çš„é«˜æ•ˆå¯æ§é•¿æ­Œæ›²ç”Ÿæˆ**\n> æ—¢ç„¶ç«¯åˆ°ç«¯éŸ³é¢‘ç”Ÿæˆéš¾ä»¥æ§åˆ¶ï¼Œä¸å¦‚å›å½’ç¬¦å·ï¼Ÿæå‡ºäº† BACH æ¨¡å‹ï¼Œé€šè¿‡äººç±»å¯ç¼–è¾‘çš„ç¬¦å·ä¹è°±æ¥ç”Ÿæˆæ­Œæ›²ã€‚è¿™ç§æ–¹æ³•åœ¨å¯æ§æ€§ã€ç”Ÿæˆæ—¶é•¿å’ŒéŸ³ä¹ç»“æ„ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œå·ç§°åœ¨ä¸»è§‚è¯„æµ‹ä¸­è¶…è¶Šäº† Suno ç­‰å•†ä¸šæ¨¡å‹ã€‚\n\n**11. The Vanishing Gradient Problem for Stiff Neural Differential Equations**\n**åˆšæ€§ç¥ç»å¾®åˆ†æ–¹ç¨‹çš„æ¢¯åº¦æ¶ˆå¤±é—®é¢˜**\n> **ç¡¬æ ¸æ•°å­¦åˆ†æã€‚** ç¥ç»å¸¸å¾®åˆ†æ–¹ç¨‹ï¼ˆNeural ODEsï¼‰åœ¨å¤„ç†åˆšæ€§ç³»ç»Ÿï¼ˆstiff systemsï¼‰æ—¶è®­ç»ƒå›°éš¾ã€‚ä½œè€…è¯æ˜äº†è¿™ä¸æ˜¯æ–¹æ³•çš„é—®é¢˜ï¼Œè€Œæ˜¯æ‰€æœ‰ A-stable å’Œ L-stable æ•°å€¼ç§¯åˆ†æ–¹æ¡ˆçš„å›ºæœ‰ç¼ºé™·ã€‚è¿™ä¸€å‘ç°æ­ç¤ºäº†è®­ç»ƒåˆšæ€§ç¥ç» ODE çš„æ ¹æœ¬é™åˆ¶ï¼Œå¯¹ç§‘å­¦è®¡ç®— AI ç¤¾åŒºæœ‰é‡è¦å¯ç¤ºã€‚\n\n**12. CarbonScaling: Extending Neural Scaling Laws for Carbon Footprint in Large Language Models**\n**CarbonScalingï¼šæ‰©å±•å¤§è¯­è¨€æ¨¡å‹çš„ç¢³è¶³è¿¹ç¥ç»ç¼©æ”¾å®šå¾‹**\n> ç¼©æ”¾å®šå¾‹ï¼ˆScaling Lawsï¼‰é€šå¸¸åªå…³æ³¨æ€§èƒ½ï¼Œè¿™ç¯‡æ–‡ç« å°†å…¶æ‰©å±•åˆ°äº†ç¢³æ’æ”¾ã€‚ç ”ç©¶å‘ç°ï¼Œè™½ç„¶ç²¾åº¦ä¸ç¢³æ’æ”¾å‘ˆå¹‚å¾‹å…³ç³»ï¼Œä½†å®é™…ä¸­çš„ç¡¬ä»¶åˆ©ç”¨ç‡ä½ä¸‹å¯¼è‡´ç¢³æ’æ”¾æ¿€å¢ã€‚æ–‡ç« æå‡ºäº†ä¸€ä¸ªåˆ†ææ¡†æ¶ï¼Œé‡åŒ–äº†æ¨¡å‹å¤§å°ã€ç¡¬ä»¶æ¼”è¿›ä¸ç¢³è¶³è¿¹ä¹‹é—´çš„å…³ç³»ã€‚\n\n---\n\n### ğŸ’¡ å…¶ä»–å€¼å¾—å…³æ³¨çš„çŸ­è®¯\n\n*   **[Agents/GUI] NatureGAIA:** ä¸€ä¸ªåŸºäºå› æœè·¯å¾„è®¾è®¡çš„ GUI Agent æ–°åŸºå‡†ï¼Œå‘ç°å³ä¾¿æ˜¯ Claude-sonnet è¿™ç§å¼ºæ¨¡å‹ï¼ŒæˆåŠŸç‡ä¹Ÿä»…æœ‰ 34.6%ï¼ŒGUI è‡ªåŠ¨åŒ–ä¾ç„¶ä»»é‡é“è¿œã€‚\n*   **[Data Science] Large Language Model-based Data Science Agent: A Survey:** å…¨é¢æ€»ç»“äº† LLM åœ¨æ•°æ®ç§‘å­¦å…¨æµç¨‹ï¼ˆé¢„å¤„ç†ã€å»ºæ¨¡ã€è¯„ä¼°ï¼‰ä¸­çš„åº”ç”¨ï¼Œé€‚åˆä½œä¸ºè¯¥é¢†åŸŸçš„å…¥é—¨ç»¼è¿°ã€‚\n*   **[Security/Privacy] Reconstructing Trust Embeddings from Siamese Trust Scores:** è¯æ˜äº†ä»…é€šè¿‡å…¬å¼€çš„ä¿¡ä»»è¯„åˆ†ï¼ˆTrust Scoresï¼‰å°±èƒ½åæ¨å‡ºè®¾å¤‡çš„é«˜ç»´åµŒå…¥ï¼Œæ­ç¤ºäº†åˆ†å¸ƒå¼å®‰å…¨ç³»ç»Ÿä¸­çš„éšç§æ³„éœ²é£é™©ã€‚\n*   **[Benchmark] TripTailor:** ä¸€ä¸ªé’ˆå¯¹ä¸ªæ€§åŒ–æ—…è¡Œè§„åˆ’çš„çœŸå®ä¸–ç•ŒåŸºå‡†æµ‹è¯•ã€‚å‘ç°ç°æœ‰ LLM ç”Ÿæˆçš„è¡Œç¨‹åœ¨å¯è¡Œæ€§å’Œåˆç†æ€§ä¸Šä»ä¸åŠäººç±»æ°´å¹³ã€‚\n*   **[AI for Science] SpectrumWorld:** æå‡ºäº†ä¸€ä¸ªå…‰è°±å­¦çš„ AI åŸºç¡€å¹³å°ï¼ŒåŒ…å« 120 ä¸‡ç§åŒ–å­¦ç‰©è´¨çš„æ•°æ®å’ŒåŸºå‡†æµ‹è¯•ï¼Œæ—¨åœ¨åŠ é€Ÿå…‰è°±åˆ†æçš„æ·±åº¦å­¦ä¹ ç ”ç©¶ã€‚\n\n---\n\nå¸Œæœ›ä»Šå¤©çš„ç®€æŠ¥å¯¹ä½ çš„ç ”ç©¶æœ‰æ‰€å¯å‘ï¼å¦‚æœ‰å¯¹ç‰¹å®šè®ºæ–‡æ„Ÿå…´è¶£ï¼Œå»ºè®®æŸ¥é˜…åŸæ–‡ abstract è¿›è¡Œæ·±æŒ–ã€‚æˆ‘ä»¬æ˜å¤©è§ï¼",
  "papers": [
    {
      "arxiv_id": "2508.01522v3",
      "title": "Decentralized Aerial Manipulation of a Cable-Suspended Load using Multi-Agent Reinforcement Learning",
      "title_zh": "åŸºäºå¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ çš„ç¼†åŠè´Ÿè½½å»ä¸­å¿ƒåŒ–ç©ºä¸­æ“çºµ",
      "authors": [
        "Jack Zeng",
        "Andreu Matoses Gimenez",
        "Eugene Vinitsky",
        "Javier Alonso-Mora",
        "Sihao Sun"
      ],
      "abstract": "This paper presents the first decentralized method to enable real-world 6-DoF manipulation of a cable-suspended load using a team of Micro-Aerial Vehicles (MAVs). Our method leverages multi-agent reinforcement learning (MARL) to train an outer-loop control policy for each MAV. Unlike state-of-the-art controllers that utilize a centralized scheme, our policy does not require global states, inter-MAV communications, nor neighboring MAV information. Instead, agents communicate implicitly through load pose observations alone, which enables high scalability and flexibility. It also significantly reduces computing costs during inference time, enabling onboard deployment of the policy. In addition, we introduce a new action space design for the MAVs using linear acceleration and body rates. This choice, combined with a robust low-level controller, enables reliable sim-to-real transfer despite significant uncertainties caused by cable tension during dynamic 3D motion. We validate our method in various real-world experiments, including full-pose control under load model uncertainties, showing setpoint tracking performance comparable to the state-of-the-art centralized method. We also demonstrate cooperation amongst agents with heterogeneous control policies, and robustness to the complete in-flight loss of one MAV. Videos of experiments: https://autonomousrobots.nl/paper_websites/aerial-manipulation-marl",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†é¦–ä¸ªå»ä¸­å¿ƒåŒ– (decentralized) çš„æ–¹æ³•ï¼Œåˆ©ç”¨å¤šæ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹  (MARL) å®ç°äº†å¤šå¾®å‹é£è¡Œå™¨ (MAVs) å¯¹ç¼†ç»³æ‚¬æŒ‚è´Ÿè½½çš„çœŸå®ä¸–ç•Œ 6-DoF æ“ä½œã€‚è¯¥ç­–ç•¥æ— éœ€å…¨å±€çŠ¶æ€ã€æ™ºèƒ½ä½“é—´é€šä¿¡æˆ–é‚»è¿‘ MAV çš„ä¿¡æ¯ï¼Œä»…é€šè¿‡è§‚æµ‹è´Ÿè½½ä½å§¿å®ç°éšå¼é€šä¿¡ï¼Œä»è€Œæ˜¾è‘—æé«˜äº†ç³»ç»Ÿçš„å¯æ‰©å±•æ€§å¹¶é™ä½äº†æœºè½½éƒ¨ç½²çš„è®¡ç®—æˆæœ¬ã€‚ç ”ç©¶é€šè¿‡å¼•å…¥åŸºäºçº¿æ€§åŠ é€Ÿåº¦å’Œæœºä½“é€Ÿç‡ (body rates) çš„æ–°é¢–åŠ¨ä½œç©ºé—´ï¼Œé…åˆé²æ£’çš„åº•å±‚æ§åˆ¶å™¨ï¼ŒæˆåŠŸå…‹æœäº†ç¼†ç»³å¼ åŠ›å¼•èµ·çš„ä¸ç¡®å®šæ€§å¹¶å®ç°äº†é«˜æ•ˆçš„ sim-to-real è¿ç§»ã€‚å®éªŒéªŒè¯è¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç›®æ ‡ç‚¹è·Ÿè¸ªæ€§èƒ½ä¸Šå¯ä¸æœ€å…ˆè¿›çš„ä¸­å¿ƒåŒ–æ–¹æ³•åª²ç¾ï¼Œå¹¶èƒ½æ”¯æŒå¼‚æ„ç­–ç•¥åä½œã€‚æ­¤å¤–ï¼Œè¯¥ç³»ç»Ÿåœ¨é¢å¯¹é£è¡Œä¸­å•ä¸ª MAV å®Œå…¨å¤±æ•ˆçš„çªå‘æƒ…å†µæ—¶è¡¨ç°å‡ºäº†æå¼ºçš„é²æ£’æ€§ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.01522v3",
      "published_date": "2025-08-02 23:52:33 UTC",
      "updated_date": "2025-11-05 10:20:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:17:58.838970+00:00"
    },
    {
      "arxiv_id": "2508.01519v1",
      "title": "The Vanishing Gradient Problem for Stiff Neural Differential Equations",
      "title_zh": "åˆšæ€§ç¥ç»å¾®åˆ†æ–¹ç¨‹ä¸­çš„æ¢¯åº¦æ¶ˆå¤±é—®é¢˜",
      "authors": [
        "Colby Fronk",
        "Linda Petzold"
      ],
      "abstract": "Gradient-based optimization of neural differential equations and other parameterized dynamical systems fundamentally relies on the ability to differentiate numerical solutions with respect to model parameters. In stiff systems, it has been observed that sensitivities to parameters controlling fast-decaying modes become vanishingly small during training, leading to optimization difficulties. In this paper, we show that this vanishing gradient phenomenon is not an artifact of any particular method, but a universal feature of all A-stable and L-stable stiff numerical integration schemes. We analyze the rational stability function for general stiff integration schemes and demonstrate that the relevant parameter sensitivities, governed by the derivative of the stability function, decay to zero for large stiffness. Explicit formulas for common stiff integration schemes are provided, which illustrate the mechanism in detail. Finally, we rigorously prove that the slowest possible rate of decay for the derivative of the stability function is $O(|z|^{-1})$, revealing a fundamental limitation: all A-stable time-stepping methods inevitably suppress parameter gradients in stiff regimes, posing a significant barrier for training and parameter identification in stiff neural ODEs.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åˆšæ€§ç¥ç»å¾®åˆ†æ–¹ç¨‹ (Stiff Neural Differential Equations) ä¸­çš„æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼ŒæŒ‡å‡ºåœ¨åˆšæ€§ç³»ç»Ÿä¸­ï¼Œæ§åˆ¶å¿«é€Ÿè¡°å‡æ¨¡å¼çš„å‚æ•°æ•æ„Ÿæ€§åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¼šå˜å¾—å¾®ä¹å…¶å¾®ã€‚ä½œè€…è¯æ˜è¿™ä¸€ç°è±¡å¹¶éç‰¹å®šç®—æ³•çš„äº§ç‰©ï¼Œè€Œæ˜¯æ‰€æœ‰ A-stable å’Œ L-stable åˆšæ€§æ•°å€¼ç§¯åˆ†æ–¹æ¡ˆçš„æ™®éç‰¹å¾ã€‚é€šè¿‡åˆ†æé€šç”¨åˆšæ€§ç§¯åˆ†æ–¹æ¡ˆçš„æœ‰ç†ç¨³å®šæ€§å‡½æ•° (Rational Stability Function)ï¼Œç ”ç©¶å±•ç¤ºäº†å—ç¨³å®šæ€§å‡½æ•°å¯¼æ•°æ”¯é…çš„å‚æ•°æ•æ„Ÿæ€§åœ¨å¤§åˆšåº¦ä¸‹ä¼šè¡°å‡è‡³é›¶ã€‚è®ºæ–‡æä¾›äº†å¸¸ç”¨ç§¯åˆ†æ–¹æ¡ˆçš„æ˜¾å¼å…¬å¼å¹¶è¿›è¡Œäº†è¯¦ç»†æœºåˆ¶è¯´æ˜ï¼ŒåŒæ—¶ä¸¥è°¨åœ°è¯æ˜äº†ç¨³å®šæ€§å‡½æ•°å¯¼æ•°çš„æœ€æ…¢è¡°å‡é€Ÿç‡ä¸º $O(|z|^{-1})$ã€‚è¿™ä¸€å‘ç°æ­ç¤ºäº†ä¸€ä¸ªåŸºæœ¬å±€é™æ€§ï¼šæ‰€æœ‰ A-stable æ—¶é—´æ­¥è¿›æ–¹æ³•åœ¨åˆšæ€§çŠ¶æ€ä¸‹éƒ½ä¼šä¸å¯é¿å…åœ°æŠ‘åˆ¶å‚æ•°æ¢¯åº¦ï¼Œä»è€Œå¯¹ stiff Neural ODEs çš„è®­ç»ƒå’Œå‚æ•°è¯†åˆ«æ„æˆäº†æ˜¾è‘—éšœç¢ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SY",
        "math.NA"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.01519v1",
      "published_date": "2025-08-02 23:44:14 UTC",
      "updated_date": "2025-08-02 23:44:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:18:00.439397+00:00"
    },
    {
      "arxiv_id": "2508.03673v1",
      "title": "Classifying Epistemic Relationships in Human-AI Interaction: An Exploratory Approach",
      "title_zh": "äººæœºäº¤äº’ä¸­è®¤è¯†è®ºå…³ç³»çš„åˆ†ç±»ï¼šä¸€é¡¹æ¢ç´¢æ€§ç ”ç©¶",
      "authors": [
        "Shengnan Yang",
        "Rongqian Ma"
      ],
      "abstract": "As AI systems become integral to knowledge-intensive work, questions arise not only about their functionality but also their epistemic roles in human-AI interaction. While HCI research has proposed various AI role typologies, it often overlooks how AI reshapes users' roles as knowledge contributors. This study examines how users form epistemic relationships with AI-how they assess, trust, and collaborate with it in research and teaching contexts. Based on 31 interviews with academics across disciplines, we developed a five-part codebook and identified five relationship types: Instrumental Reliance, Contingent Delegation, Co-agency Collaboration, Authority Displacement, and Epistemic Abstention. These reflect variations in trust, assessment modes, tasks, and human epistemic status. Our findings show that epistemic roles are dynamic and context-dependent. We argue for shifting beyond static metaphors of AI toward a more nuanced framework that captures how humans and AI co-construct knowledge, enriching HCI's understanding of the relational and normative dimensions of AI use.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨çŸ¥è¯†å¯†é›†å‹å·¥ä½œä¸­ï¼Œäººå·¥æ™ºèƒ½(AI)å¦‚ä½•é‡å¡‘äººç±»ä½œä¸ºçŸ¥è¯†è´¡çŒ®è€…çš„è§’è‰²ï¼Œå¹¶é‡ç‚¹å…³æ³¨äººæœºäº¤äº’(Human-AI Interaction)ä¸­çš„è®¤è¯†è®ºå…³ç³»(Epistemic Relationships)ã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡å¯¹æ¥è‡ªä¸åŒå­¦ç§‘çš„31åå­¦æœ¯ç•Œäººå£«è¿›è¡Œæ·±åº¦è®¿è°ˆï¼Œå¼€å‘äº†ä¸€å¥—åŒ…å«äº”ä¸ªéƒ¨åˆ†çš„ç¼–ç ç°¿(Codebook)ï¼Œå¹¶è¯†åˆ«å‡ºäº”ç§ä¸»è¦çš„å…³ç³»ç±»å‹ï¼šå·¥å…·æ€§ä¾èµ–(Instrumental Reliance)ã€æƒå˜å§”æ´¾(Contingent Delegation)ã€ååŒä»£ç†åˆä½œ(Co-agency Collaboration)ã€æƒå¨ä½ç§»(Authority Displacement)ä»¥åŠè®¤è¯†è®ºå¼ƒæƒ(Epistemic Abstention)ã€‚è¿™äº›ç±»å‹åæ˜ äº†ç”¨æˆ·åœ¨ä¿¡ä»»ç¨‹åº¦ã€è¯„ä¼°æ¨¡å¼ã€ä»»åŠ¡æ€§è´¨åŠäººç±»è‡ªèº«è®¤è¯†è®ºåœ°ä½æ–¹é¢çš„æ˜¾è‘—å·®å¼‚ã€‚ç ”ç©¶ç»“æœè¡¨æ˜ï¼Œè®¤è¯†è®ºè§’è‰²æ˜¯åŠ¨æ€ä¸”ä¾èµ–äºå…·ä½“æƒ…å¢ƒçš„ã€‚è¯¥è®ºæ–‡ä¸»å¼ è¶…è¶Šé™æ€çš„AIéšå–»ï¼Œæ„å»ºä¸€ä¸ªèƒ½å¤Ÿæ•æ‰äººç±»ä¸AIå…±åŒæ„å»ºçŸ¥è¯†(Co-construct Knowledge)è¿‡ç¨‹çš„ç»†è‡´æ¡†æ¶ã€‚è¿™ä¸€æˆæœæ·±åŒ–äº†äººæœºäº¤äº’(HCI)é¢†åŸŸå¯¹AIä½¿ç”¨ä¸­å…³ç³»ä¸è§„èŒƒç»´åº¦çš„è®¤çŸ¥ï¼Œä¸ºç†è§£AIåä½œç¯å¢ƒä¸­çš„çŸ¥è¯†ç”Ÿäº§æä¾›äº†æ–°çš„è§†è§’ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.03673v1",
      "published_date": "2025-08-02 23:41:28 UTC",
      "updated_date": "2025-08-02 23:41:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:18:01.542485+00:00"
    },
    {
      "arxiv_id": "2508.01506v1",
      "title": "FlashSVD: Memory-Efficient Inference with Streaming for Low-Rank Models",
      "title_zh": "FlashSVDï¼šé¢å‘ä½ç§©æ¨¡å‹çš„æµå¼é«˜æ•ˆå†…å­˜æ¨ç†",
      "authors": [
        "Zishan Shao",
        "Yixiao Wang",
        "Qinsi Wang",
        "Ting Jiang",
        "Zhixu Du",
        "Hancheng Ye",
        "Danyang Zhuo",
        "Yiran Chen",
        "Hai Li"
      ],
      "abstract": "Singular Value Decomposition (SVD) has recently seen a surge of interest as a simple yet powerful tool for large language models (LLMs) compression, with a growing number of works demonstrating 20-80% parameter reductions at minimal accuracy loss. Previous SVD-based approaches have focused primarily on reducing the memory footprint of model weights, largely overlooking the additional activation memory overhead incurred during inference when applying truncated factors via standard dense CUDA kernels. Our experiments demonstrate that this activation overhead, scaling with sequence length and hidden dimension, prevents current SVD compression techniques from achieving any reduction in peak inference memory, thereby limiting their viability for real-world, on-device deployments.\n  We introduce FlashSVD, a novel, end-to-end rank-aware streaming inference framework specifically designed for SVD-compressed large language models. FlashSVD can be seamlessly integrated with any model that employs SVD-based methods for parameter reduction. By fusing low-rank projection kernels directly into both the self-attention and feed-forward network (FFN) pipelines, FlashSVD avoid materializing full-size activation buffers. Instead, small tiles of the truncated factors are loaded into on-chip SRAM, multiplied and reduced on the fly, and immediately evicted, preserving high GPU occupancy and adding no extra latency. On standard encoder benchmarks (e.g., BERT-Base), FlashSVD cuts peak activation memory by up to 70.2% and intermediate transient memory by 75%, all while incur no accuracy loss with upstreaming compression methods, offering a practical path toward memory-constrained deployment of low-rank LLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¥‡å¼‚å€¼åˆ†è§£(Singular Value Decomposition, SVD)åœ¨å¤§è¯­è¨€æ¨¡å‹(LLMs)å‹ç¼©ä¸­äº§ç”Ÿçš„æ¨ç†æ¿€æ´»å†…å­˜å¼€é”€é—®é¢˜ï¼Œæå‡ºäº†FlashSVDè¿™ä¸€ç«¯åˆ°ç«¯ç§©æ„ŸçŸ¥æµå¼æ¨ç†(Rank-aware Streaming Inference)æ¡†æ¶ã€‚FlashSVDé€šè¿‡å°†ä½ç§©æŠ•å½±ç®—å­ç›´æ¥èåˆè¿›è‡ªæ³¨æ„åŠ›(Self-attention)å’Œå‰é¦ˆç½‘ç»œ(FFN)æµæ°´çº¿ï¼Œé¿å…äº†å…¨å°ºå¯¸æ¿€æ´»ç¼“å†²åŒºçš„ç”Ÿæˆï¼Œä»è€Œæ˜¾è‘—é™ä½å†…å­˜å ç”¨ã€‚è¯¥æ¡†æ¶åˆ©ç”¨ç‰‡ä¸ŠSRAMå¯¹æˆªæ–­å› å­è¿›è¡Œåˆ†å—å¤„ç†å’Œå³æ—¶è®¡ç®—ï¼Œåœ¨ç¡®ä¿é«˜GPUåˆ©ç”¨ç‡çš„åŒæ—¶ä¸ä¼šå¼•å…¥é¢å¤–å»¶è¿Ÿã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨BERT-Baseç­‰åŸºå‡†æµ‹è¯•ä¸­ï¼ŒFlashSVDå¯å°†å³°å€¼æ¿€æ´»å†…å­˜é™ä½é«˜è¾¾70.2%ï¼Œä¸­é—´ç¬æ€å†…å­˜å‡å°‘75%ï¼Œä¸”ä¸æŸå¤±ä»»ä½•æ¨¡å‹å‡†ç¡®ç‡ã€‚è¿™ä¸€æˆæœä¸ºåœ¨æ˜¾å­˜å—é™çš„è®¾å¤‡ä¸Šéƒ¨ç½²ç»è¿‡SVDå‹ç¼©çš„ä½ç§©å¤§æ¨¡å‹æä¾›äº†ä¸€ç§é«˜æ•ˆä¸”å®ç”¨çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.PF"
      ],
      "primary_category": "cs.LG",
      "comment": "Technical Report",
      "pdf_url": "https://arxiv.org/pdf/2508.01506v1",
      "published_date": "2025-08-02 22:06:46 UTC",
      "updated_date": "2025-08-02 22:06:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:18:04.148297+00:00"
    },
    {
      "arxiv_id": "2508.01498v1",
      "title": "ShrutiSense: Microtonal Modeling and Correction in Indian Classical Music",
      "title_zh": "ShrutiSenseï¼šå°åº¦å¤å…¸éŸ³ä¹å¾®åˆ†éŸ³å»ºæ¨¡ä¸ä¿®æ­£",
      "authors": [
        "Rajarshi Ghosh",
        "Jayanth Athipatla"
      ],
      "abstract": "Indian classical music relies on a sophisticated microtonal system of 22 shrutis (pitch intervals), which provides expressive nuance beyond the 12-tone equal temperament system. Existing symbolic music processing tools fail to account for these microtonal distinctions and culturally specific raga grammars that govern melodic movement. We present ShrutiSense, a comprehensive symbolic pitch processing system designed for Indian classical music, addressing two critical tasks: (1) correcting westernized or corrupted pitch sequences, and (2) completing melodic sequences with missing values. Our approach employs complementary models for different tasks: a Shruti-aware finite-state transducer (FST) that performs contextual corrections within the 22-shruti framework and a grammar-constrained Shruti hidden Markov model (GC-SHMM) that incorporates raga-specific transition rules for contextual completions. Comprehensive evaluation on simulated data across five ragas demonstrates that ShrutiSense (FST model) achieves 91.3% shruti classification accuracy for correction tasks, with example sequences showing 86.7-90.0% accuracy at corruption levels of 0.2 to 0.4. The system exhibits robust performance under pitch noise up to +/-50 cents, maintaining consistent accuracy across ragas (90.7-91.8%), thus preserving the cultural authenticity of Indian classical music expression.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† ShrutiSenseï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“ä¸ºå°åº¦å¤å…¸éŸ³ä¹ (Indian classical music) è®¾è®¡çš„ç¬¦å·éŸ³é«˜å¤„ç†ç³»ç»Ÿï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿ 12-tone equal temperament ç³»ç»Ÿæ— æ³•å»ºæ¨¡ 22 shrutis å¾®éŸ³ç¨‹ä½“ç³»åŠç‰¹å®š raga è¯­æ³•çš„é—®é¢˜ã€‚è¯¥ç³»ç»Ÿä¸»è¦æ‰§è¡Œä¸¤é¡¹ä»»åŠ¡ï¼šä¿®æ­£è¢«è¥¿æ–¹åŒ–æˆ–æŸåçš„éŸ³é«˜åºåˆ—ï¼Œä»¥åŠè¡¥å…¨ç¼ºå¤±çš„æ—‹å¾‹åºåˆ—ã€‚ä¸ºäº†å®ç°è¿™äº›åŠŸèƒ½ï¼Œç ”ç©¶é‡‡ç”¨äº†ä¸¤ç§äº’è¡¥æ¨¡å‹ï¼Œåˆ†åˆ«æ˜¯ç”¨äºä¸Šä¸‹æ–‡ä¿®æ­£çš„ Shruti-aware finite-state transducer (FST) å’Œç»“åˆ raga è½¬æ¢è§„åˆ™è¿›è¡Œåºåˆ—è¡¥å…¨çš„ grammar-constrained Shruti hidden Markov model (GC-SHMM)ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒFST æ¨¡å‹åœ¨éŸ³é«˜ä¿®æ­£ä»»åŠ¡ä¸­è¾¾åˆ°äº† 91.3% çš„ shruti åˆ†ç±»å‡†ç¡®ç‡ï¼Œå¹¶åœ¨ä¸åŒæŸåç¨‹åº¦ä¸‹è¡¨ç°ç¨³å®šã€‚æ­¤å¤–ï¼ŒShrutiSense åœ¨é«˜è¾¾ +/-50 cents çš„éŸ³é«˜å™ªå£°ä¸‹å±•ç°å‡ºæå¼ºçš„é²æ£’æ€§ï¼Œåœ¨ä¸åŒ ragas é—´ä¿æŒäº† 90.7% è‡³ 91.8% çš„ä¸€è‡´å‡†ç¡®ç‡ã€‚è¯¥ç³»ç»Ÿæœ‰æ•ˆåœ°ä¿ç•™äº†å°åº¦å¤å…¸éŸ³ä¹è¡¨è¾¾çš„æ–‡åŒ–çœŸå®æ€§ï¼Œä¸ºå¤æ‚å¾®éŸ³ç¨‹ä½“ç³»çš„æ•°å­—åŒ–å¤„ç†æä¾›äº†æ–°æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.01498v1",
      "published_date": "2025-08-02 21:42:47 UTC",
      "updated_date": "2025-08-02 21:42:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:18:07.841088+00:00"
    },
    {
      "arxiv_id": "2508.01495v1",
      "title": "WinkTPG: An Execution Framework for Multi-Agent Path Finding Using Temporal Reasoning",
      "title_zh": "WinkTPGï¼šåŸºäºæ—¶é—´æ¨ç†çš„å¤šæ™ºèƒ½ä½“è·¯å¾„è§„åˆ’æ‰§è¡Œæ¡†æ¶",
      "authors": [
        "Jingtian Yan",
        "Stephen F. Smith",
        "Jiaoyang Li"
      ],
      "abstract": "Planning collision-free paths for a large group of agents is a challenging problem with numerous real-world applications. While recent advances in Multi-Agent Path Finding (MAPF) have shown promising progress, standard MAPF algorithms rely on simplified kinodynamic models, preventing agents from directly following the generated MAPF plan. To bridge this gap, we propose kinodynamic Temporal Plan Graph Planning (kTPG), a multi-agent speed optimization algorithm that efficiently refines a MAPF plan into a kinodynamically feasible plan while accounting for uncertainties and preserving collision-freeness. Building on kTPG, we propose Windowed kTPG (WinkTPG), a MAPF execution framework that incrementally refines MAPF plans using a window-based mechanism, dynamically incorporating agent information during execution to reduce uncertainty. Experiments show that WinkTPG can generate speed profiles for up to 1,000 agents in 1 second and improves solution quality by up to 51.7% over existing MAPF execution methods.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¼ ç»Ÿ Multi-Agent Path Finding (MAPF) ç®—æ³•å› ä¾èµ–ç®€åŒ–è¿åŠ¨å­¦æ¨¡å‹è€Œéš¾ä»¥ç›´æ¥æ‰§è¡Œçš„é—®é¢˜ï¼Œæå‡ºäº† kinodynamic Temporal Plan Graph Planning (kTPG) é€Ÿåº¦ä¼˜åŒ–ç®—æ³•ï¼Œæ—¨åœ¨å°† MAPF è®¡åˆ’ç»†åŒ–ä¸ºç¬¦åˆåŠ¨åŠ›å­¦çº¦æŸä¸”æ— ç¢°æ’çš„å¯è¡Œè®¡åˆ’ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œç ”ç©¶è€…è¿›ä¸€æ­¥å¼€å‘äº†åä¸º Windowed kTPG (WinkTPG) çš„æ‰§è¡Œæ¡†æ¶ï¼Œåˆ©ç”¨çª—å£åŒ–æœºåˆ¶å¢é‡å¼åœ°ä¼˜åŒ–è·¯å¾„ï¼Œå¹¶åœ¨æ‰§è¡Œè¿‡ç¨‹ä¸­åŠ¨æ€æ•´åˆæ™ºèƒ½ä½“ä¿¡æ¯ä»¥å‡å°‘ä¸ç¡®å®šæ€§ã€‚å®éªŒæ•°æ®è¯æ˜ï¼ŒWinkTPG å±•ç°å‡ºæé«˜çš„è®¡ç®—æ•ˆç‡ï¼Œèƒ½å¤Ÿåœ¨ 1 ç§’å†…ä¸ºå¤šè¾¾ 1,000 ä¸ªæ™ºèƒ½ä½“ç”Ÿæˆé€Ÿåº¦é…ç½®æ–‡ä»¶ã€‚ä¸ç°æœ‰çš„ MAPF æ‰§è¡Œæ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ¡†æ¶å°†è§£çš„è´¨é‡æå‡äº†é«˜è¾¾ 51.7%ï¼Œæœ‰æ•ˆè§£å†³äº†å¤§è§„æ¨¡æ™ºèƒ½ä½“ç¾¤ä½“åœ¨å¤æ‚åŠ¨åŠ›å­¦ç¯å¢ƒä¸‹çš„è·¯å¾„æ‰§è¡ŒæŒ‘æˆ˜ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.01495v1",
      "published_date": "2025-08-02 21:33:08 UTC",
      "updated_date": "2025-08-02 21:33:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:18:16.344995+00:00"
    },
    {
      "arxiv_id": "2508.01493v1",
      "title": "Translation-Equivariant Self-Supervised Learning for Pitch Estimation with Optimal Transport",
      "title_zh": "åŸºäºæœ€ä¼˜ä¼ è¾“çš„éŸ³é«˜ä¼°è®¡å¹³ç§»ç­‰å˜è‡ªç›‘ç£å­¦ä¹ ",
      "authors": [
        "Bernardo Torres",
        "Alain Riou",
        "GaÃ«l Richard",
        "Geoffroy Peeters"
      ],
      "abstract": "In this paper, we propose an Optimal Transport objective for learning one-dimensional translation-equivariant systems and demonstrate its applicability to single pitch estimation. Our method provides a theoretically grounded, more numerically stable, and simpler alternative for training state-of-the-art self-supervised pitch estimators.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºæœ€ä¼˜ä¼ è¾“(Optimal Transport)çš„ç›®æ ‡å‡½æ•°ï¼Œç”¨äºå­¦ä¹ ä¸€ç»´å¹³ç§»ç­‰å˜(translation-equivariant)ç³»ç»Ÿï¼Œå¹¶è¯¦ç»†å±•ç¤ºäº†å…¶åœ¨å•éŸ³é«˜ä¼°è®¡(single pitch estimation)ä»»åŠ¡ä¸­çš„åº”ç”¨ã€‚è¯¥æ–¹æ³•ä¸ºå½“å‰æœ€å…ˆè¿›çš„è‡ªç›‘ç£éŸ³é«˜ä¼°è®¡å™¨(self-supervised pitch estimators)çš„è®­ç»ƒæä¾›äº†ä¸€ä¸ªç†è®ºåŸºç¡€æ‰å®ã€æ•°å€¼æ›´ç¨³å®šä¸”æ›´åŠ ç®€æ´çš„æ›¿ä»£æ–¹æ¡ˆã€‚é€šè¿‡å¼•å…¥æœ€ä¼˜ä¼ è¾“æ¡†æ¶ï¼Œç ”ç©¶è€…æˆåŠŸè§£å†³äº†ä¼ ç»Ÿæ¨¡å‹åœ¨æ•æ‰ä¿¡å·å¹³ç§»ç‰¹æ€§æ—¶é¢ä¸´çš„å¤æ‚æ€§æŒ‘æˆ˜ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ¡ˆä¸ä»…åœ¨æ•°å­¦ä¸Šæ›´å…·å®Œå¤‡æ€§ï¼Œåœ¨å®é™…çš„è‡ªç›‘ç£å­¦ä¹ æµç¨‹ä¸­ä¹Ÿè¡¨ç°å‡ºæ›´ä¼˜çš„æ”¶æ•›ç‰¹å¾ã€‚è¿™ä¸€è´¡çŒ®ä¸ºæ„å»ºé«˜æ•ˆã€ç¨³å¥çš„éŸ³é¢‘ç‰¹å¾æå–ç³»ç»Ÿæä¾›äº†å…¨æ–°çš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Extended Abstracts for the Late-Breaking Demo Session of the 26th International Society for Music Information Retrieval Conference",
      "pdf_url": "https://arxiv.org/pdf/2508.01493v1",
      "published_date": "2025-08-02 21:31:14 UTC",
      "updated_date": "2025-08-02 21:31:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:18:19.440348+00:00"
    },
    {
      "arxiv_id": "2508.01490v2",
      "title": "A Large-Scale Benchmark of Cross-Modal Learning for Histology and Gene Expression in Spatial Transcriptomics",
      "title_zh": "ç©ºé—´è½¬å½•ç»„å­¦ä¸­ç»„ç»‡å­¦ä¸åŸºå› è¡¨è¾¾è·¨æ¨¡æ€å­¦ä¹ çš„å¤§è§„æ¨¡åŸºå‡†",
      "authors": [
        "Rushin H. Gindra",
        "Giovanni Palla",
        "Mathias Nguyen",
        "Sophia J. Wagner",
        "Manuel Tran",
        "Fabian J Theis",
        "Dieter Saur",
        "Lorin Crawford",
        "Tingying Peng"
      ],
      "abstract": "Spatial transcriptomics enables simultaneous measurement of gene expression and tissue morphology, offering unprecedented insights into cellular organization and disease mechanisms. However, the field lacks comprehensive benchmarks for evaluating multimodal learning methods that leverage both histology images and gene expression data. Here, we present HESCAPE, a large-scale benchmark for cross-modal contrastive pretraining in spatial transcriptomics, built on a curated pan-organ dataset spanning 6 different gene panels and 54 donors. We systematically evaluated state-of-the-art image and gene expression encoders across multiple pretraining strategies and assessed their effectiveness on two downstream tasks: gene mutation classification and gene expression prediction. Our benchmark demonstrates that gene expression encoders are the primary determinant of strong representational alignment, and that gene models pretrained on spatial transcriptomics data outperform both those trained without spatial data and simple baseline approaches. However, downstream task evaluation reveals a striking contradiction: while contrastive pretraining consistently improves gene mutation classification performance, it degrades direct gene expression prediction compared to baseline encoders trained without cross-modal objectives. We identify batch effects as a key factor that interferes with effective cross-modal alignment. Our findings highlight the critical need for batch-robust multimodal learning approaches in spatial transcriptomics. To accelerate progress in this direction, we release HESCAPE, providing standardized datasets, evaluation protocols, and benchmarking tools for the community",
      "tldr_zh": "æœ¬ç ”ç©¶æ¨å‡ºäº† HESCAPEï¼Œè¿™æ˜¯ä¸€ä¸ªé’ˆå¯¹ç©ºé—´è½¬å½•ç»„å­¦ (Spatial Transcriptomics) ä¸­ç»„ç»‡å­¦å›¾åƒä¸åŸºå› è¡¨è¾¾è·¨æ¨¡æ€å¯¹æ¯”é¢„è®­ç»ƒçš„å¤§è§„æ¨¡åŸºå‡†æµ‹è¯•ã€‚è¯¥åŸºå‡†åŸºäºè·¨è¶Š 6 ä¸ªåŸºå› ç»„å’Œ 54 åæèµ è€…çš„æ³›å™¨å®˜æ•°æ®é›†ï¼Œæ—¨åœ¨è§£å†³é¢†åŸŸå†…ç¼ºä¹è¯„ä¼°å¤šæ¨¡æ€å­¦ä¹ æ–¹æ³•ç»¼åˆæ ‡å‡†çš„é—®é¢˜ã€‚ä½œè€…ç³»ç»Ÿè¯„ä¼°äº†å¤šç§é¢„è®­ç»ƒç­–ç•¥ä¸‹çš„å›¾åƒä¸åŸºå› è¡¨è¾¾ç¼–ç å™¨ï¼Œå¹¶é’ˆå¯¹åŸºå› çªå˜åˆ†ç±» (Gene mutation classification) å’ŒåŸºå› è¡¨è¾¾é¢„æµ‹ (Gene expression prediction) ä»»åŠ¡è¿›è¡Œäº†æµ‹è¯•ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒåŸºå› è¡¨è¾¾ç¼–ç å™¨æ˜¯å®ç°å¼ºè¡¨å¾å¯¹é½çš„ä¸»è¦å†³å®šå› ç´ ï¼Œä¸”åœ¨ç©ºé—´è½¬å½•ç»„æ•°æ®ä¸Šé¢„è®­ç»ƒçš„æ¨¡å‹ä¼˜äºæ— ç©ºé—´æ•°æ®çš„æ¨¡å‹ã€‚ç ”ç©¶æ­ç¤ºäº†ä¸€ä¸ªæ˜¾è‘—çŸ›ç›¾ï¼šè™½ç„¶å¯¹æ¯”é¢„è®­ç»ƒèƒ½æå‡çªå˜åˆ†ç±»æ€§èƒ½ï¼Œä½†åœ¨ç›´æ¥é¢„æµ‹åŸºå› è¡¨è¾¾æ–¹é¢å´ä¸å¦‚æœªé‡‡ç”¨è·¨æ¨¡æ€ç›®æ ‡çš„åŸºçº¿æ¨¡å‹ã€‚è¿›ä¸€æ­¥åˆ†æå‘ç°æ‰¹æ¬¡æ•ˆåº” (Batch effects) æ˜¯å¹²æ‰°æœ‰æ•ˆè·¨æ¨¡æ€å¯¹é½çš„å…³é”®å› ç´ ã€‚HESCAPE é€šè¿‡æä¾›æ ‡å‡†åŒ–çš„æ•°æ®é›†å’Œè¯„ä¼°åè®®ï¼Œä¸ºå¼€å‘å¯¹æ‰¹æ¬¡æ•ˆåº”å…·æœ‰é²æ£’æ€§çš„ç©ºé—´è½¬å½•ç»„å¤šæ¨¡æ€å­¦ä¹ æ–¹æ³•å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "q-bio.GN",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "q-bio.TO",
        "stat.AP"
      ],
      "primary_category": "q-bio.GN",
      "comment": "The code is accessible at: https://github.com/peng-lab/hescape",
      "pdf_url": "https://arxiv.org/pdf/2508.01490v2",
      "published_date": "2025-08-02 21:11:36 UTC",
      "updated_date": "2025-08-27 08:13:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:18:16.580436+00:00"
    },
    {
      "arxiv_id": "2508.01488v2",
      "title": "PESTO: Real-Time Pitch Estimation with Self-supervised Transposition-equivariant Objective",
      "title_zh": "PESTOï¼šåŸºäºè‡ªç›‘ç£ç§»è°ƒç­‰å˜ç›®æ ‡çš„å®æ—¶éŸ³é«˜ä¼°è®¡",
      "authors": [
        "Alain Riou",
        "Bernardo Torres",
        "Ben Hayes",
        "Stefan Lattner",
        "GaÃ«tan Hadjeres",
        "GaÃ«l Richard",
        "Geoffroy Peeters"
      ],
      "abstract": "In this paper, we introduce PESTO, a self-supervised learning approach for single-pitch estimation using a Siamese architecture. Our model processes individual frames of a Variable-$Q$ Transform (VQT) and predicts pitch distributions. The neural network is designed to be equivariant to translations, notably thanks to a Toeplitz fully-connected layer. In addition, we construct pitch-shifted pairs by translating and cropping the VQT frames and train our model with a novel class-based transposition-equivariant objective, eliminating the need for annotated data. Thanks to this architecture and training objective, our model achieves remarkable performances while being very lightweight ($130$k parameters). Evaluations on music and speech datasets (MIR-1K, MDB-stem-synth, and PTDB) demonstrate that PESTO not only outperforms self-supervised baselines but also competes with supervised methods, exhibiting superior cross-dataset generalization. Finally, we enhance PESTO's practical utility by developing a streamable VQT implementation using cached convolutions. Combined with our model's low latency (less than 10 ms) and minimal parameter count, this makes PESTO particularly suitable for real-time applications.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† PESTOï¼Œä¸€ç§ç”¨äºå•éŸ³é«˜ä¼°è®¡ (single-pitch estimation) çš„è‡ªç›‘ç£å­¦ä¹  (self-supervised learning) æ–¹æ³•ï¼Œé€šè¿‡å­ªç”Ÿæ¶æ„ (Siamese architecture) å¤„ç† Variable-Q Transform (VQT) å¸§å¹¶é¢„æµ‹éŸ³é«˜åˆ†å¸ƒã€‚è¯¥æ¨¡å‹é‡‡ç”¨ Toeplitz å…¨è¿æ¥å±‚å®ç°äº†å¹³ç§»ç­‰å˜æ€§ (equivariant to translations)ï¼Œå¹¶åˆ©ç”¨ VQT å¸§çš„å¹³ç§»å’Œè£å‰ªæ„å»ºéŸ³é«˜åç§»å¯¹ï¼Œé€šè¿‡åˆ›æ–°çš„åŸºäºç±»åˆ«çš„è½¬ç½®ç­‰å˜ç›®æ ‡ (transposition-equivariant objective) è¿›è¡Œè®­ç»ƒï¼Œä»è€Œå®Œå…¨æ¶ˆé™¤äº†å¯¹æ ‡æ³¨æ•°æ®çš„éœ€æ±‚ã€‚PESTO å…·æœ‰æè½»é‡åŒ–çš„è®¾è®¡ï¼Œå‚æ•°é‡ä»…ä¸º 130kï¼Œåœ¨ MIR-1Kã€MDB-stem-synth å’Œ PTDB ç­‰æ•°æ®é›†ä¸Šçš„è¯„ä¼°è¡¨æ˜ï¼Œå…¶æ€§èƒ½ä¸ä»…æ˜¾è‘—ä¼˜äºè‡ªç›‘ç£åŸºå‡†ï¼Œç”šè‡³å¯ä¸ç›‘ç£å­¦ä¹ æ–¹æ³•ç›¸åª²ç¾ï¼Œå¹¶å±•ç°å‡ºå“è¶Šçš„è·¨æ•°æ®é›†æ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œç ”ç©¶å›¢é˜Ÿé€šè¿‡ç¼“å­˜å·ç§¯å®ç°äº†æµå¼ VQTï¼Œç»“åˆæ¨¡å‹ä½äº 10ms çš„æä½å»¶è¿Ÿï¼Œä½¿ PESTO ç‰¹åˆ«é€‚ç”¨äºå®æ—¶åº”ç”¨åœºæ™¯ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.01488v2",
      "published_date": "2025-08-02 21:00:55 UTC",
      "updated_date": "2025-10-27 11:55:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:18:26.745263+00:00"
    },
    {
      "arxiv_id": "2508.01483v1",
      "title": "Training Dynamics of the Cooldown Stage in Warmup-Stable-Decay Learning Rate Scheduler",
      "title_zh": "Warmup-Stable-Decay å­¦ä¹ ç‡è°ƒåº¦å™¨å†·å´é˜¶æ®µçš„è®­ç»ƒåŠ¨æ€",
      "authors": [
        "Aleksandr Dremov",
        "Alexander HÃ¤gele",
        "Atli Kosson",
        "Martin Jaggi"
      ],
      "abstract": "Learning rate scheduling is essential in transformer training, where the final annealing plays a crucial role in getting the best performance. However, the mechanisms behind this cooldown phase, with its characteristic drop in loss, remain poorly understood. To address this, we provide a comprehensive analysis focusing solely on the cooldown phase in the Warmup-Stable-Decay (WSD) learning rate scheduler. Our analysis reveals that different cooldown shapes reveal a fundamental bias-variance trade-off in the resulting models, with shapes that balance exploration and exploitation consistently outperforming alternatives. Similarly, we find substantial performance variations $\\unicode{x2013}$ comparable to those from cooldown shape selection $\\unicode{x2013}$ when tuning AdamW hyperparameters. Notably, we observe consistent improvements with higher values of $Î²_2$ during cooldown. From a loss landscape perspective, we provide visualizations of the landscape during cooldown, supporting the river valley loss perspective empirically. These findings offer practical recommendations for configuring the WSD scheduler in transformer training, emphasizing the importance of optimizing the cooldown phase alongside traditional hyperparameter tuning.",
      "tldr_zh": "è¯¥ç ”ç©¶æ·±å…¥æ¢è®¨äº†Transformerè®­ç»ƒä¸­ Warmup-Stable-Decay (WSD) å­¦ä¹ ç‡è°ƒåº¦å™¨çš„å†·å´é˜¶æ®µï¼ˆcooldown phaseï¼‰è®­ç»ƒåŠ¨æ€ï¼Œæ—¨åœ¨æ­ç¤ºè¯¥é˜¶æ®µæŸå¤±å¿«é€Ÿä¸‹é™èƒŒåçš„å†…åœ¨æœºåˆ¶ã€‚ç ”ç©¶åˆ†æè¡¨æ˜ï¼Œä¸åŒçš„å†·å´å½¢çŠ¶åæ˜ äº†æ¨¡å‹åœ¨åå·®-æ–¹å·® (bias-variance trade-off) ä¹‹é—´çš„åŸºæœ¬æƒè¡¡ï¼Œå…¶ä¸­èƒ½å¤Ÿå¹³è¡¡æ¢ç´¢ä¸åˆ©ç”¨çš„å½¢çŠ¶è¡¨ç°æœ€ä¸ºå‡ºè‰²ã€‚å®éªŒè¿˜å‘ç°ï¼Œåœ¨å†·å´é˜¶æ®µè°ƒèŠ‚ AdamW è¶…å‚æ•°ï¼ˆç‰¹åˆ«æ˜¯æé«˜ $\\beta_2$ çš„å€¼ï¼‰å¯¹æ€§èƒ½çš„æå‡æ˜¾è‘—ï¼Œå…¶å½±å“ç¨‹åº¦ä¸å†·å´å½¢çŠ¶çš„é€‰æ‹©ç›¸å½“ã€‚æ­¤å¤–ï¼Œé€šè¿‡æŸå¤±å¹³é¢å¯è§†åŒ–ï¼Œç ”ç©¶ä»ç»éªŒä¸Šæ”¯æŒäº†â€œæ²³è°·æŸå¤±â€ (river valley loss) çš„è§†è§’ã€‚è¿™äº›å‘ç°ä¸ºé…ç½® WSD è°ƒåº¦å™¨æä¾›äº†å®ç”¨çš„æŒ‡å¯¼å»ºè®®ï¼Œå¹¶å¼ºè°ƒäº†åœ¨ä¼ ç»Ÿè¶…å‚æ•°å¾®è°ƒä¹‹å¤–ï¼Œä¸“é—¨ä¼˜åŒ–å†·å´é˜¶æ®µå¯¹æå‡æ¨¡å‹æ€§èƒ½çš„é‡è¦æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published in TMLR. Review: https://openreview.net/forum?id=ZnSYEcZod3",
      "pdf_url": "https://arxiv.org/pdf/2508.01483v1",
      "published_date": "2025-08-02 20:36:52 UTC",
      "updated_date": "2025-08-02 20:36:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:18:23.220098+00:00"
    },
    {
      "arxiv_id": "2508.01479v1",
      "title": "Reconstructing Trust Embeddings from Siamese Trust Scores: A Direct-Sum Approach with Fixed-Point Semantics",
      "title_zh": "åŸºäºå­ªç”Ÿä¿¡ä»»åˆ†å€¼çš„ä¿¡ä»»åµŒå…¥é‡æ„ï¼šä¸€ç§å…·æœ‰ä¸åŠ¨ç‚¹è¯­ä¹‰çš„ç›´å’Œæ–¹æ³•",
      "authors": [
        "Faruk Alpay",
        "Taylan Alpay",
        "Bugra Kilictas"
      ],
      "abstract": "We study the inverse problem of reconstructing high-dimensional trust embeddings from the one-dimensional Siamese trust scores that many distributed-security frameworks expose. Starting from two independent agents that publish time-stamped similarity scores for the same set of devices, we formalise the estimation task, derive an explicit direct-sum estimator that concatenates paired score series with four moment features, and prove that the resulting reconstruction map admits a unique fixed point under a contraction argument rooted in Banach theory. A suite of synthetic benchmarks (20 devices x 10 time steps) confirms that, even in the presence of Gaussian noise, the recovered embeddings preserve inter-device geometry as measured by Euclidean and cosine metrics; we complement these experiments with non-asymptotic error bounds that link reconstruction accuracy to score-sequence length. Beyond methodology, the paper demonstrates a practical privacy risk: publishing granular trust scores can leak latent behavioural information about both devices and evaluation models. We therefore discuss counter-measures -- score quantisation, calibrated noise, obfuscated embedding spaces -- and situate them within wider debates on transparency versus confidentiality in networked AI systems. All datasets, reproduction scripts and extended proofs accompany the submission so that results can be verified without proprietary code.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ä»åˆ†å¸ƒå¼å®‰å…¨æ¡†æ¶æä¾›çš„ä¸€ç»´ Siamese trust scores ä¸­é‡å»ºé«˜ç»´ trust embeddings çš„é€†é—®é¢˜ã€‚ä½œè€…å½¢å¼åŒ–äº†è¿™ä¸€ä¼°è®¡ä»»åŠ¡ï¼Œæ¨å¯¼å‡ºä¸€ä¸ªç»“åˆå››ä¸ª moment features çš„ç›´æ¥æ±‚å’Œ (direct-sum) ä¼°è®¡å™¨ï¼Œå¹¶åŸºäº Banach theory è¯æ˜äº†è¯¥é‡å»ºæ˜ å°„åœ¨ä¸åŠ¨ç‚¹è¯­ä¹‰ä¸‹å…·æœ‰å”¯ä¸€è§£ã€‚é€šè¿‡åˆæˆåŸºå‡†æµ‹è¯•éªŒè¯ï¼Œå³ä¾¿åœ¨å­˜åœ¨é«˜æ–¯å™ªå£°çš„æƒ…å†µä¸‹ï¼Œæ¢å¤çš„åµŒå…¥ä»èƒ½ä¿æŒè®¾å¤‡é—´çš„ Euclidean å’Œ cosine å‡ ä½•ç‰¹å¾ï¼Œä¸”é‡å»ºç²¾åº¦ä¸è¯„åˆ†åºåˆ—é•¿åº¦éµå¾ªéæ¸è¿‘è¯¯å·®ç•Œã€‚æ­¤å¤–ï¼Œç ”ç©¶æ­ç¤ºäº†å‘å¸ƒç»†ç²’åº¦ä¿¡ä»»è¯„åˆ†å¯èƒ½æ³„éœ²è®¾å¤‡åŠæ¨¡å‹çš„æ½œåœ¨è¡Œä¸ºä¿¡æ¯è¿™ä¸€éšç§é£é™©ï¼Œå¹¶è®¨è®ºäº†åŒ…æ‹¬ score quantization å’Œ calibrated noise åœ¨å†…çš„é˜²å¾¡æªæ–½ï¼Œä¸ºç½‘ç»œåŒ– AI ç³»ç»Ÿä¸­é€æ˜åº¦ä¸æœºå¯†æ€§çš„å¹³è¡¡æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG",
        "cs.SI"
      ],
      "primary_category": "cs.CR",
      "comment": "22 pages, 3 figures, 1 table",
      "pdf_url": "https://arxiv.org/pdf/2508.01479v1",
      "published_date": "2025-08-02 20:19:22 UTC",
      "updated_date": "2025-08-02 20:19:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:18:39.549344+00:00"
    },
    {
      "arxiv_id": "2508.01476v1",
      "title": "CARGO: A Co-Optimization Framework for EV Charging and Routing in Goods Delivery Logistics",
      "title_zh": "CARGOï¼šè´§ç‰©é…é€ç‰©æµä¸­ç”µåŠ¨æ±½è½¦å……ç”µä¸è·¯å¾„è§„åˆ’çš„ååŒä¼˜åŒ–æ¡†æ¶",
      "authors": [
        "Arindam Khanda",
        "Anurag Satpathy",
        "Amit Jha",
        "Sajal K. Das"
      ],
      "abstract": "With growing interest in sustainable logistics, electric vehicle (EV)-based deliveries offer a promising alternative for urban distribution. However, EVs face challenges due to their limited battery capacity, requiring careful planning for recharging. This depends on factors such as the charging point (CP) availability, cost, proximity, and vehicles' state of charge (SoC). We propose CARGO, a framework addressing the EV-based delivery route planning problem (EDRP), which jointly optimizes route planning and charging for deliveries within time windows. After proving the problem's NP-hardness, we propose a mixed integer linear programming (MILP)-based exact solution and a computationally efficient heuristic method. Using real-world datasets, we evaluate our methods by comparing the heuristic to the MILP solution, and benchmarking it against baseline strategies, Earliest Deadline First (EDF) and Nearest Delivery First (NDF). The results show up to 39% and 22% reductions in the charging cost over EDF and NDF, respectively, while completing comparable deliveries.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†CARGOï¼Œä¸€ä¸ªç”¨äºè´§ç‰©é…é€ç‰©æµä¸­ç”µåŠ¨æ±½è½¦(EV)å……ç”µä¸è·¯å¾„è§„åˆ’çš„ååŒä¼˜åŒ–æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å—é™äºç”µæ± å®¹é‡çš„é…é€è·¯å¾„è§„åˆ’é—®é¢˜(EDRP)ã€‚è¯¥æ¡†æ¶åœ¨æ»¡è¶³æ—¶é—´çª—çº¦æŸçš„å‰æä¸‹ï¼Œè”åˆä¼˜åŒ–è·¯å¾„é€‰æ‹©ä¸å……ç”µå†³ç­–ï¼Œå¹¶ç»¼åˆè€ƒé‡äº†å……ç”µç‚¹(CP)å¯ç”¨æ€§ã€æˆæœ¬å’Œè½¦è¾†è·ç”µçŠ¶æ€(SoC)ç­‰åŠ¨æ€å› ç´ ã€‚ç ”ç©¶é¦–å…ˆè¯æ˜äº†è¯¥é—®é¢˜çš„NP-hardnesså±æ€§ï¼Œéšåæå‡ºäº†åŸºäºæ··åˆæ•´æ•°çº¿æ€§è§„åˆ’(MILP)çš„ç²¾ç¡®è§£æ³•ä»¥åŠä¸€ç§é«˜æ•ˆçš„å¯å‘å¼æ–¹æ³•(heuristic method)ã€‚é€šè¿‡çœŸå®ä¸–ç•Œæ•°æ®é›†çš„å®éªŒè¯„ä¼°ï¼ŒCARGOåœ¨å®ŒæˆåŒç­‰é…é€é‡çš„æƒ…å†µä¸‹ï¼Œç›¸æ¯”äºEarliest Deadline First (EDF)å’ŒNearest Delivery First (NDF)ç­–ç•¥ï¼Œåˆ†åˆ«å®ç°äº†é«˜è¾¾39%å’Œ22%çš„å……ç”µæˆæœ¬é™ä½ï¼Œä¸ºå¯æŒç»­åŸå¸‚é…é€ç‰©æµæä¾›äº†é«˜æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.01476v1",
      "published_date": "2025-08-02 20:08:46 UTC",
      "updated_date": "2025-08-02 20:08:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:18:43.148566+00:00"
    },
    {
      "arxiv_id": "2508.01475v1",
      "title": "$R^2$-CoD: Understanding Text-Graph Complementarity in Relational Reasoning via Knowledge Co-Distillation",
      "title_zh": "$R^2$-CoDï¼šé€šè¿‡çŸ¥è¯†ååŒè’¸é¦æ­ç¤ºå…³ç³»æ¨ç†ä¸­çš„æ–‡æœ¬-å›¾äº’è¡¥æ€§",
      "authors": [
        "Zhen Wu",
        "Ritam Dutt",
        "Luke M. Breitfeller",
        "Armineh Nourbakhsh",
        "Siddharth Parekh",
        "Carolyn RosÃ©"
      ],
      "abstract": "Relational reasoning lies at the core of many NLP tasks, drawing on complementary signals from text and graphs. While prior research has investigated how to leverage this dual complementarity, a detailed and systematic understanding of text-graph interplay and its effect on hybrid models remains underexplored. We take an analysis-driven approach to investigate text-graph representation complementarity via a unified architecture that supports knowledge co-distillation (CoD). We explore five tasks involving relational reasoning that differ in how text and graph structures encode the information needed to solve that task. By tracking how these dual representations evolve during training, we uncover interpretable patterns of alignment and divergence, and provide insights into when and why their integration is beneficial.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å…³ç³»æ¨ç†(Relational Reasoning)ä¸­æ–‡æœ¬ä¸å›¾ç»“æ„ä¹‹é—´çš„äº’è¡¥æ€§ï¼Œå¹¶æŒ‡å‡ºäº†ç›®å‰å¯¹è¿™ä¸¤è€…åœ¨æ··åˆæ¨¡å‹ä¸­ç›¸äº’ä½œç”¨æœºåˆ¶ç¼ºä¹ç³»ç»Ÿç†è§£çš„é—®é¢˜ã€‚ä¸ºäº†æ·±å…¥åˆ†æè¿™ç§äº’è¡¥æ€§ï¼Œä½œè€…æå‡ºäº†ä¸€ä¸ªæ”¯æŒçŸ¥è¯†å…±è’¸é¦(Knowledge Co-Distillation, CoD)çš„ç»Ÿä¸€æ¶æ„$R^2$-CoDã€‚é€šè¿‡åœ¨äº”é¡¹å…·æœ‰ä¸åŒä¿¡æ¯ç¼–ç ç‰¹å¾çš„å…³ç³»æ¨ç†ä»»åŠ¡ä¸Šè¿›è¡Œå®éªŒï¼Œè¯¥ç ”ç©¶è¿½è¸ªäº†è®­ç»ƒè¿‡ç¨‹ä¸­åŒé‡è¡¨ç¤ºçš„æ¼”åŒ–è¿‡ç¨‹ã€‚ç ”ç©¶æ­ç¤ºäº†æ–‡æœ¬ä¸å›¾è¡¨ç¤ºä¹‹é—´å¯¹é½ä¸åˆ†æ­§çš„å¯è§£é‡Šæ¨¡å¼ï¼Œä¸ºç†è§£ä¸¤è€…çš„é›†æˆåœ¨ä½•æ—¶ä»¥åŠä¸ºä½•æœ‰æ•ˆæä¾›äº†é‡è¦çš„ç†è®ºè§è§£ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.01475v1",
      "published_date": "2025-08-02 19:51:50 UTC",
      "updated_date": "2025-08-02 19:51:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:18:44.445552+00:00"
    },
    {
      "arxiv_id": "2508.01459v1",
      "title": "Fast and scalable retrosynthetic planning with a transformer neural network and speculative beam search",
      "title_zh": "åŸºäº Transformer ç¥ç»ç½‘ç»œä¸æŠ•æœºæ€§æŸæœç´¢çš„å¿«é€Ÿå¯æ‰©å±•é€†åˆæˆè§„åˆ’",
      "authors": [
        "Mikhail Andronov",
        "Natalia Andronova",
        "Michael Wand",
        "JÃ¼rgen Schmidhuber",
        "Djork-ArnÃ© Clevert"
      ],
      "abstract": "AI-based computer-aided synthesis planning (CASP) systems are in demand as components of AI-driven drug discovery workflows. However, the high latency of such CASP systems limits their utility for high-throughput synthesizability screening in de novo drug design. We propose a method for accelerating multi-step synthesis planning systems that rely on SMILES-to-SMILES transformers as single-step retrosynthesis models. Our approach reduces the latency of SMILES-to-SMILES transformers powering multi-step synthesis planning in AiZynthFinder through speculative beam search combined with a scalable drafting strategy called Medusa. Replacing standard beam search with our approach allows the CASP system to solve 26\\% to 86\\% more molecules under the same time constraints of several seconds. Our method brings AI-based CASP systems closer to meeting the strict latency requirements of high-throughput synthesizability screening and improving general user experience.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹äººå·¥æ™ºèƒ½è¾…åŠ©åˆæˆè§„åˆ’ (CASP) ç³»ç»Ÿåœ¨è¯ç‰©å‘ç°ä¸­å› é«˜å»¶è¿Ÿè€Œé™åˆ¶é«˜é€šé‡ç­›é€‰æ•ˆç‡çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŠ é€Ÿå¤šæ­¥åˆæˆè§„åˆ’çš„æ–°æ–¹æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡å°†æ¨æµ‹æ€§æŸæœç´¢ (Speculative Beam Search) ä¸åä¸º Medusa çš„å¯æ‰©å±•è‰æ‹Ÿç­–ç•¥ç›¸ç»“åˆï¼Œä¼˜åŒ–äº† AiZynthFinder ä¸­åŸºäº SMILES-to-SMILES transformers çš„å•æ­¥é€†åˆæˆæ¨¡å‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨ç›¸åŒçš„æ•°ç§’æ—¶é—´çº¦æŸä¸‹ï¼Œè¯¥æ–¹æ³•æ¯”æ ‡å‡†æŸæœç´¢èƒ½å¤Ÿå¤šè§£å†³ 26% è‡³ 86% çš„åˆ†å­ã€‚è¿™ä¸€çªç ´æ˜¾è‘—é™ä½äº† AI é©±åŠ¨çš„ CASP ç³»ç»Ÿå»¶è¿Ÿï¼Œä½¿å…¶æ›´æœ‰æ•ˆåœ°æ»¡è¶³é«˜é€šé‡å¯åˆæˆæ€§ç­›é€‰çš„ä¸¥æ ¼è¦æ±‚ï¼Œå¹¶æå‡äº†ç³»ç»Ÿçš„å®ç”¨æ€§ä¸ç”¨æˆ·ä½“éªŒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.01459v1",
      "published_date": "2025-08-02 18:30:06 UTC",
      "updated_date": "2025-08-02 18:30:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:18:53.331416+00:00"
    },
    {
      "arxiv_id": "2508.02744v2",
      "title": "Large Language Model-based Data Science Agent: A Survey",
      "title_zh": "åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„æ•°æ®ç§‘å­¦æ™ºèƒ½ä½“ç»¼è¿°",
      "authors": [
        "Ke Chen",
        "Peiran Wang",
        "Yaoning Yu",
        "Xianyang Zhan",
        "Haohan Wang"
      ],
      "abstract": "The rapid advancement of Large Language Models (LLMs) has driven novel applications across diverse domains, with LLM-based agents emerging as a crucial area of exploration. This survey presents a comprehensive analysis of LLM-based agents designed for data science tasks, summarizing insights from recent studies. From the agent perspective, we discuss the key design principles, covering agent roles, execution, knowledge, and reflection methods. From the data science perspective, we identify key processes for LLM-based agents, including data preprocessing, model development, evaluation, visualization, etc. Our work offers two key contributions: (1) a comprehensive review of recent developments in applying LLMbased agents to data science tasks; (2) a dual-perspective framework that connects general agent design principles with the practical workflows in data science.",
      "tldr_zh": "è¯¥ç»¼è¿°ç³»ç»Ÿåˆ†æäº†åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLM-based)çš„æ™ºèƒ½ä½“åœ¨æ•°æ®ç§‘å­¦(Data Science)ä»»åŠ¡ä¸­çš„åº”ç”¨ä¸ç ”ç©¶ç°çŠ¶ã€‚ä»æ™ºèƒ½ä½“è®¾è®¡çš„è§’åº¦ï¼Œè®ºæ–‡æ¢è®¨äº†æ ¸å¿ƒè®¾è®¡åŸåˆ™ï¼Œæ¶µç›–äº†è§’è‰²å®šä¹‰(Roles)ã€æ‰§è¡Œ(Execution)ã€çŸ¥è¯†(Knowledge)å’Œåæ€(Reflection)ç­‰å…³é”®æ–¹æ³•ã€‚ä»æ•°æ®ç§‘å­¦æµç¨‹å‡ºå‘ï¼Œç ”ç©¶æ·±å…¥åˆ†æäº†æ•°æ®é¢„å¤„ç†(Data Preprocessing)ã€æ¨¡å‹å¼€å‘(Model Development)ã€è¯„ä¼°(Evaluation)åŠå¯è§†åŒ–(Visualization)ç­‰å…³é”®ç¯èŠ‚ã€‚è®ºæ–‡çš„ä¸»è¦è´¡çŒ®åœ¨äºæå‡ºäº†ä¸€ä¸ªåŒè§†è§’æ¡†æ¶(Dual-perspective Framework)ï¼Œæœ‰æ•ˆåœ°å°†é€šç”¨çš„æ™ºèƒ½ä½“è®¾è®¡åŸåˆ™ä¸å®é™…çš„æ•°æ®ç§‘å­¦å·¥ä½œæµç›¸è¿æ¥ã€‚è¯¥å·¥ä½œä¸ä»…å…¨é¢å›é¡¾äº†è¿‘æœŸåˆ©ç”¨ LLM-based æ™ºèƒ½ä½“è§£å†³æ•°æ®ç§‘å­¦é—®é¢˜çš„æŠ€æœ¯è¿›å±•ï¼Œä¹Ÿä¸ºæœªæ¥è‡ªåŠ¨åŒ–æ•°æ®ç§‘å­¦ç³»ç»Ÿçš„ç ”ç©¶æä¾›äº†é‡è¦çš„å‚è€ƒè·¯å¾„ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.02744v2",
      "published_date": "2025-08-02 17:33:18 UTC",
      "updated_date": "2025-11-23 08:12:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:18:50.050200+00:00"
    },
    {
      "arxiv_id": "2508.01443v2",
      "title": "Tuning LLM-based Code Optimization via Meta-Prompting: An Industrial Perspective",
      "title_zh": "é€šè¿‡å…ƒæç¤ºè°ƒä¼˜åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„ä»£ç ä¼˜åŒ–ï¼šå·¥ä¸šç•Œè§†è§’",
      "authors": [
        "Jingzhi Gong",
        "Rafail Giavrimis",
        "Paul Brookes",
        "Vardan Voskanyan",
        "Fan Wu",
        "Mari Ashiga",
        "Matthew Truscott",
        "Mike Basios",
        "Leslie Kanthan",
        "Jie Xu",
        "Zheng Wang"
      ],
      "abstract": "There is a growing interest in leveraging multiple large language models (LLMs) for automated code optimization. However, industrial platforms deploying multiple LLMs face a critical challenge: prompts optimized for one LLM often fail with others, requiring expensive model-specific prompt engineering. This cross-model prompt engineering bottleneck severely limits the practical deployment of multi-LLM systems in production environments. We introduce Meta-Prompted Code Optimization (MPCO), a framework that automatically generates high-quality, task-specific prompts across diverse LLMs while maintaining industrial efficiency requirements. MPCO leverages metaprompting to dynamically synthesize context-aware optimization prompts by integrating project metadata, task requirements, and LLM-specific contexts. It is an essential part of the ARTEMIS code optimization platform for automated validation and scaling. Our comprehensive evaluation on five real-world codebases with 366 hours of runtime benchmarking demonstrates MPCO's effectiveness: it achieves overall performance improvements up to 19.06% with the best statistical rank across all systems compared to baseline methods. Analysis shows that 96% of the top-performing optimizations stem from meaningful edits. Through systematic ablation studies and meta-prompter sensitivity analysis, we identify that comprehensive context integration is essential for effective meta-prompting and that major LLMs can serve effectively as meta-prompters, providing actionable insights for industrial practitioners.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å·¥ä¸šç•Œåœ¨éƒ¨ç½²å¤šå¤§è¯­è¨€æ¨¡å‹(LLMs)è¿›è¡Œä»£ç è‡ªåŠ¨ä¼˜åŒ–æ—¶é¢ä¸´çš„è·¨æ¨¡å‹æç¤ºå·¥ç¨‹ç“¶é¢ˆï¼Œæå‡ºäº†Meta-Prompted Code Optimization (MPCO)æ¡†æ¶ã€‚MPCOåˆ©ç”¨å…ƒæç¤º(Meta-Prompting)æŠ€æœ¯ï¼Œé€šè¿‡é›†æˆé¡¹ç›®å…ƒæ•°æ®ã€ä»»åŠ¡éœ€æ±‚å’ŒLLMç‰¹å®šä¸Šä¸‹æ–‡ï¼ŒåŠ¨æ€åˆæˆå…·æœ‰ä¸Šä¸‹æ–‡æ„ŸçŸ¥èƒ½åŠ›çš„ä¼˜åŒ–æç¤ºã€‚è¯¥æ¡†æ¶ä½œä¸ºARTEMISä»£ç ä¼˜åŒ–å¹³å°çš„æ ¸å¿ƒç»„æˆéƒ¨åˆ†ï¼Œæœ‰æ•ˆæ”¯æŒäº†è‡ªåŠ¨åŒ–éªŒè¯ä¸æ‰©å±•ã€‚åœ¨äº”ä¸ªçœŸå®ä»£ç åº“ä¸Šè¿›è¡Œçš„366å°æ—¶è¿è¡Œæ—¶åŸºå‡†æµ‹è¯•æ˜¾ç¤ºï¼ŒMPCOç›¸æ¯”åŸºå‡†æ–¹æ³•å®ç°äº†æœ€é«˜19.06%çš„æ€§èƒ½æå‡ï¼Œå¹¶åœ¨ç»Ÿè®¡æ’åä¸­è¡¨ç°æœ€ä¼˜ã€‚åˆ†æè¡¨æ˜ï¼Œ96%çš„é«˜æ€§èƒ½ä¼˜åŒ–æºè‡ªå…·æœ‰å®é™…æ„ä¹‰çš„ç¼–è¾‘ï¼Œä¸”æ¶ˆèç ”ç©¶è¯å®å…¨é¢çš„ä¸Šä¸‹æ–‡æ•´åˆæ˜¯æœ‰æ•ˆå…ƒæç¤ºçš„å…³é”®ã€‚è¯¥ç ”ç©¶è¯æ˜äº†ä¸»æµLLMså¯ä»¥èƒœä»»Meta-Promptersï¼Œä¸ºå·¥ä¸šç•Œåˆ©ç”¨å…ƒæç¤ºæŠ€æœ¯æå‡ä»£ç ä¼˜åŒ–æ•ˆç‡æä¾›äº†é‡è¦å®è·µå‚è€ƒã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted by ASE'25 Industry Showcase",
      "pdf_url": "https://arxiv.org/pdf/2508.01443v2",
      "published_date": "2025-08-02 17:11:40 UTC",
      "updated_date": "2025-10-03 17:04:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:18:57.842156+00:00"
    },
    {
      "arxiv_id": "2508.02743v1",
      "title": "A Novel cVAE-Augmented Deep Learning Framework for Pan-Cancer RNA-Seq Classification",
      "title_zh": "ä¸€ç§ç”¨äºæ³›ç™Œ RNA-Seq åˆ†ç±»çš„æ–°å‹ cVAE å¢å¼ºæ·±åº¦å­¦ä¹ æ¡†æ¶",
      "authors": [
        "Vinil Polepalli"
      ],
      "abstract": "Pan-cancer classification using transcriptomic (RNA-Seq) data can inform tumor subtyping and therapy selection, but is challenging due to extremely high dimensionality and limited sample sizes. In this study, we propose a novel deep learning framework that uses a class-conditional variational autoencoder (cVAE) to augment training data for pan-cancer gene expression classification. Using 801 tumor RNA-Seq samples spanning 5 cancer types from The Cancer Genome Atlas (TCGA), we first perform feature selection to reduce 20,531 gene expression features to the 500 most variably expressed genes. A cVAE is then trained on this data to learn a latent representation of gene expression conditioned on cancer type, enabling the generation of synthetic gene expression samples for each tumor class. We augment the training set with these cVAE-generated samples (doubling the dataset size) to mitigate overfitting and class imbalance. A two-layer multilayer perceptron (MLP) classifier is subsequently trained on the augmented dataset to predict tumor type. The augmented framework achieves high classification accuracy (~98%) on a held-out test set, substantially outperforming a classifier trained on the original data alone. We present detailed experimental results, including VAE training curves, classifier performance metrics (ROC curves and confusion matrix), and architecture diagrams to illustrate the approach. The results demonstrate that cVAE-based synthetic augmentation can significantly improve pan-cancer prediction performance, especially for underrepresented cancer classes.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°å‹æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œåˆ©ç”¨ç±»æ¡ä»¶å˜åˆ†è‡ªç¼–ç å™¨(cVAE)æ¥å¢å¼ºæ³›ç™Œç—‡åŸºå› è¡¨è¾¾åˆ†ç±»çš„è®­ç»ƒæ•°æ®ã€‚é’ˆå¯¹è½¬å½•ç»„(RNA-Seq)æ•°æ®ç»´åº¦æé«˜ä¸”æ ·æœ¬é‡æœ‰é™çš„æŒ‘æˆ˜ï¼Œç ”ç©¶è€…é¦–å…ˆä»TCGAæ•°æ®é›†ä¸­é€‰å–äº†5ç§ç™Œç—‡ç±»å‹çš„801ä¸ªæ ·æœ¬ï¼Œå¹¶ç­›é€‰å‡ºè¡¨è¾¾å˜åŒ–æœ€æ˜¾è‘—çš„500ä¸ªåŸºå› ã€‚éšåï¼Œé€šè¿‡è®­ç»ƒcVAEå­¦ä¹ å—ç™Œç—‡ç±»å‹çº¦æŸçš„æ½œåœ¨è¡¨å¾ï¼Œç”ŸæˆåˆæˆåŸºå› è¡¨è¾¾æ ·æœ¬ï¼Œä»è€Œå°†è®­ç»ƒé›†è§„æ¨¡æ‰©å¤§ä¸€å€ä»¥ç¼“è§£è¿‡æ‹Ÿåˆä¸ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ã€‚åŸºäºå¢å¼ºæ•°æ®é›†è®­ç»ƒçš„åŒå±‚å¤šå±‚æ„ŸçŸ¥æœº(MLP)åˆ†ç±»å™¨åœ¨æµ‹è¯•é›†ä¸Šå®ç°äº†çº¦98%çš„åˆ†ç±»å‡†ç¡®ç‡ï¼Œæ˜¾è‘—ä¼˜äºä»…ä½¿ç”¨åŸå§‹æ•°æ®çš„æ¨¡å‹ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒåŸºäºcVAEçš„åˆæˆæ•°æ®å¢å¼ºèƒ½æ˜¾è‘—æå‡æ³›ç™Œç—‡é¢„æµ‹æ€§èƒ½ï¼Œå°¤å…¶æ˜¯å¯¹äºæ ·æœ¬ç¨€å°‘çš„ç™Œç—‡ç±»åˆ«å…·æœ‰é‡è¦çš„åº”ç”¨ä»·å€¼ã€‚",
      "categories": [
        "q-bio.GN",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.GN",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.02743v1",
      "published_date": "2025-08-02 16:57:31 UTC",
      "updated_date": "2025-08-02 16:57:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:18:57.142113+00:00"
    },
    {
      "arxiv_id": "2508.01432v1",
      "title": "TripTailor: A Real-World Benchmark for Personalized Travel Planning",
      "title_zh": "TripTailorï¼šé¢å‘ä¸ªæ€§åŒ–æ—…è¡Œè§„åˆ’çš„çœŸå®ä¸–ç•ŒåŸºå‡†",
      "authors": [
        "Yuanzhe Shen",
        "Kaimin Wang",
        "Changze Lv",
        "Xiaoqing Zheng",
        "Xuanjing Huang"
      ],
      "abstract": "The continuous evolution and enhanced reasoning capabilities of large language models (LLMs) have elevated their role in complex tasks, notably in travel planning, where demand for personalized, high-quality itineraries is rising. However, current benchmarks often rely on unrealistic simulated data, failing to reflect the differences between LLM-generated and real-world itineraries. Existing evaluation metrics, which primarily emphasize constraints, fall short of providing a comprehensive assessment of the overall quality of travel plans. To address these limitations, we introduce TripTailor, a benchmark designed specifically for personalized travel planning in real-world scenarios. This dataset features an extensive collection of over 500,000 real-world points of interest (POIs) and nearly 4,000 diverse travel itineraries, complete with detailed information, providing a more authentic evaluation framework. Experiments show that fewer than 10\\% of the itineraries generated by the latest state-of-the-art LLMs achieve human-level performance. Moreover, we identify several critical challenges in travel planning, including the feasibility, rationality, and personalized customization of the proposed solutions. We hope that TripTailor will drive the development of travel planning agents capable of understanding and meeting user needs while generating practical itineraries. Our code and dataset are available at https://github.com/swxkfm/TripTailor",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº†TripTailorï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“é—¨ä¸ºçœŸå®åœºæ™¯ä¸‹çš„ä¸ªæ€§åŒ–æ—…è¡Œè§„åˆ’è®¾è®¡çš„åŸºå‡†æµ‹è¯•é›†(Benchmark)ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰è¯„ä¼°æ¡†æ¶è¿‡åº¦ä¾èµ–æ¨¡æ‹Ÿæ•°æ®ä¸”è¯„ä¼°æŒ‡æ ‡ä¸å…¨é¢çš„é—®é¢˜ã€‚è¯¥æ•°æ®é›†æ•´åˆäº†è¶…è¿‡50ä¸‡ä¸ªçœŸå®å…´è¶£ç‚¹(POIs)å’Œè¿‘4,000æ¡çœŸå®çš„æ—…è¡Œè·¯çº¿ï¼Œä¸ºå¤§è¯­è¨€æ¨¡å‹(LLMs)æä¾›äº†æ›´å…·çœŸå®æ€§çš„è¯„ä¼°ç¯å¢ƒã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œå½“å‰æœ€å…ˆè¿›çš„å¤§è¯­è¨€æ¨¡å‹ç”Ÿæˆçš„è¡Œç¨‹ä¸­ä»…æœ‰ä¸åˆ°10%è¾¾åˆ°äº†äººç±»æ°´å¹³ï¼Œåæ˜ å‡ºæ¨¡å‹åœ¨å¤„ç†ç°å®å¤æ‚è§„åˆ’ä»»åŠ¡ä¸­çš„æ˜¾è‘—å·®è·ã€‚ç ”ç©¶æ˜ç¡®äº†æ—…è¡Œè§„åˆ’ä¸­çš„ä¸‰ä¸ªæ ¸å¿ƒæŒ‘æˆ˜ï¼Œå³æ–¹æ¡ˆçš„å¯è¡Œæ€§(Feasibility)ã€åˆç†æ€§(Rationality)ä»¥åŠä¸ªæ€§åŒ–å®šåˆ¶(Personalized Customization)ã€‚TripTailorçš„å‘å¸ƒä¸ä»…å¡«è¡¥äº†çœŸå®ä¸–ç•Œæ—…è¡Œè§„åˆ’æ•°æ®çš„ç©ºç™½ï¼Œä¹Ÿä¸ºå¼€å‘èƒ½å¤Ÿç”Ÿæˆå®ç”¨ä¸”ç²¾å‡†ç¬¦åˆç”¨æˆ·éœ€æ±‚çš„æ—…è¡Œæ™ºèƒ½ä½“æä¾›äº†å…³é”®çš„å®éªŒåŸºç¡€ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to ACL 2025 Findings",
      "pdf_url": "https://arxiv.org/pdf/2508.01432v1",
      "published_date": "2025-08-02 16:44:02 UTC",
      "updated_date": "2025-08-02 16:44:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:19:19.142322+00:00"
    },
    {
      "arxiv_id": "2508.01427v2",
      "title": "Capturing More: Learning Multi-Domain Representations for Robust Online Handwriting Verification",
      "title_zh": "Capturing Moreï¼šé¢å‘ç¨³å¥åœ¨çº¿æ‰‹å†™éªŒè¯çš„å¤šåŸŸè¡¨ç¤ºå­¦ä¹ ",
      "authors": [
        "Peirong Zhang",
        "Kai Ding",
        "Lianwen Jin"
      ],
      "abstract": "In this paper, we propose SPECTRUM, a temporal-frequency synergistic model that unlocks the untapped potential of multi-domain representation learning for online handwriting verification (OHV). SPECTRUM comprises three core components: (1) a multi-scale interactor that finely combines temporal and frequency features through dual-modal sequence interaction and multi-scale aggregation, (2) a self-gated fusion module that dynamically integrates global temporal and frequency features via self-driven balancing. These two components work synergistically to achieve micro-to-macro spectral-temporal integration. (3) A multi-domain distance-based verifier then utilizes both temporal and frequency representations to improve discrimination between genuine and forged handwriting, surpassing conventional temporal-only approaches. Extensive experiments demonstrate SPECTRUM's superior performance over existing OHV methods, underscoring the effectiveness of temporal-frequency multi-domain learning. Furthermore, we reveal that incorporating multiple handwritten biometrics fundamentally enhances the discriminative power of handwriting representations and facilitates verification. These findings not only validate the efficacy of multi-domain learning in OHV but also pave the way for future research in multi-domain approaches across both feature and biometric domains. Code is publicly available at https://github.com/NiceRingNode/SPECTRUM.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† SPECTRUMï¼Œä¸€ç§æ—¨åœ¨æŒ–æ˜å¤šåŸŸè¡¨ç¤ºå­¦ä¹ (multi-domain representation learning)æ½œåŠ›çš„æ—¶é¢‘ååŒæ¨¡å‹ï¼Œç”¨äºå¢å¼ºåœ¨çº¿æ‰‹å†™éªŒè¯(OHV)çš„é²æ£’æ€§ã€‚SPECTRUM æ ¸å¿ƒåŒ…å«å¤šå°ºåº¦äº¤äº’å™¨(multi-scale interactor)ã€è‡ªé—¨æ§èåˆæ¨¡å—(self-gated fusion module)å’ŒåŸºäºå¤šåŸŸè·ç¦»çš„éªŒè¯å™¨ï¼Œå®ç°äº†æ—¶åŸŸ(temporal)ä¸é¢‘åŸŸ(frequency)ç‰¹å¾ä»å¾®è§‚åˆ°å®è§‚çš„æ·±åº¦æ•´åˆã€‚è¯¥æ¡†æ¶é€šè¿‡åŒæ¨¡æ€åºåˆ—äº¤äº’å’Œè‡ªé©±åŠ¨å¹³è¡¡æŠ€æœ¯ï¼Œæ˜¾è‘—æå‡äº†åŒºåˆ†çœŸå®ä¸ä¼ªé€ æ‰‹å†™ç¨¿çš„è¾¨åˆ«åŠ›ï¼Œå…‹æœäº†ä¼ ç»Ÿä»…ä¾èµ–æ—¶åŸŸæ–¹æ³•çš„å±€é™æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSPECTRUM çš„æ€§èƒ½ä¼˜äºç°æœ‰çš„ OHV æ–¹æ³•ï¼Œæœ‰åŠ›éªŒè¯äº†æ—¶é¢‘å¤šåŸŸå­¦ä¹ çš„ä¼˜è¶Šæ€§ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å‘ç°å¼•å…¥å¤šç§æ‰‹å†™ç”Ÿç‰©ç‰¹å¾(handwritten biometrics)èƒ½ä»æ ¹æœ¬ä¸Šå¼ºåŒ–æ‰‹å†™è¡¨ç¤ºçš„åˆ¤åˆ«æ€§èƒ½ã€‚è¿™é¡¹å·¥ä½œä¸ä»…è¯æ˜äº†å¤šåŸŸå­¦ä¹ åœ¨æ‰‹å†™éªŒè¯ä¸­çš„æ•ˆç”¨ï¼Œä¹Ÿä¸ºæœªæ¥åœ¨ç‰¹å¾åŸŸå’Œç”Ÿç‰©ç‰¹å¾åŸŸæ¢ç´¢å¤šåŸŸç ”ç©¶æ–¹æ³•å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to ACM MM 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.01427v2",
      "published_date": "2025-08-02 16:20:35 UTC",
      "updated_date": "2025-10-14 13:36:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:19:08.342788+00:00"
    },
    {
      "arxiv_id": "2508.01426v2",
      "title": "UniExtreme: A Universal Foundation Model for Extreme Weather Forecasting",
      "title_zh": "UniExtremeï¼šæç«¯å¤©æ°”é¢„æŠ¥é€šç”¨åŸºç¡€æ¨¡å‹",
      "authors": [
        "Hang Ni",
        "Weijia Zhang",
        "Hao Liu"
      ],
      "abstract": "Recent advancements in deep learning have led to the development of Foundation Models (FMs) for weather forecasting, yet their ability to predict extreme weather events remains limited. Existing approaches either focus on general weather conditions or specialize in specific-type extremes, neglecting the real-world atmospheric patterns of diversified extreme events. In this work, we identify two key characteristics of extreme events: (1) the spectral disparity against normal weather regimes, and (2) the hierarchical drivers and geographic blending of diverse extremes. Along this line, we propose UniExtreme, a universal extreme weather forecasting foundation model that integrates (1) an Adaptive Frequency Modulation (AFM) module that captures region-wise spectral differences between normal and extreme weather, through learnable Beta-distribution filters and multi-granularity spectral aggregation, and (2) an Event Prior Augmentation (EPA) module which incorporates region-specific extreme event priors to resolve hierarchical extreme diversity and composite extreme schema, via a dual-level memory fusion network. Extensive experiments demonstrate that UniExtreme outperforms state-of-the-art baselines in both extreme and general weather forecasting, showcasing superior adaptability across diverse extreme scenarios.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰æ°”è±¡åŸºç¡€æ¨¡å‹ï¼ˆFoundation Modelsï¼‰åœ¨é¢„æµ‹æç«¯å¤©æ°”æ–¹é¢å­˜åœ¨çš„å±€é™æ€§ï¼Œæå‡ºäº† UniExtremeï¼Œè¿™æ˜¯ä¸€ç§é€šç”¨çš„æç«¯å¤©æ°”é¢„æŠ¥åŸºç¡€æ¨¡å‹ã€‚ä½œè€…è¯†åˆ«äº†æç«¯äº‹ä»¶ä¸å¸¸è§„å¤©æ°”æ¨¡å¼ä¹‹é—´çš„é¢‘è°±å·®å¼‚ï¼Œä»¥åŠå¤šæ ·åŒ–æç«¯äº‹ä»¶çš„å±‚çº§é©±åŠ¨å› ç´ ä¸åœ°ç†èåˆç‰¹å¾ã€‚UniExtreme é›†æˆäº†è‡ªé€‚åº”é¢‘ç‡è°ƒåˆ¶ï¼ˆAdaptive Frequency Modulation, AFMï¼‰æ¨¡å—ï¼Œé€šè¿‡å¯å­¦ä¹ çš„ Beta-distribution æ»¤æ³¢å™¨å’Œå¤šç²’åº¦é¢‘è°±èšåˆæ•æ‰åŒºåŸŸæ€§çš„é¢‘è°±ç‰¹å¾å·®å¼‚ã€‚åŒæ—¶ï¼Œè¯¥æ¨¡å‹å¼•å…¥äº†äº‹ä»¶å…ˆéªŒå¢å¼ºï¼ˆEvent Prior Augmentation, EPAï¼‰æ¨¡å—ï¼Œåˆ©ç”¨åŒå±‚å­˜å‚¨èåˆç½‘ç»œæ•´åˆç‰¹å®šåŒºåŸŸçš„æç«¯äº‹ä»¶å…ˆéªŒï¼Œä»¥åº”å¯¹å¤æ‚çš„å±‚çº§å¤šæ ·æ€§å’Œå¤åˆæç«¯æ¨¡å¼ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒUniExtreme åœ¨æç«¯å’Œå¸¸è§„å¤©æ°”é¢„æŠ¥ä»»åŠ¡ä¸­å‡ä¼˜äºå½“å‰æœ€å…ˆè¿›çš„åŸºçº¿æ¨¡å‹ã€‚è¯¥æ¨¡å‹å±•ç¤ºäº†åœ¨å¤šç§æç«¯åœºæ™¯ä¸‹å“è¶Šçš„è‡ªé€‚åº”èƒ½åŠ›ï¼Œä¸ºå…¨çƒæç«¯å¤©æ°”é¢„è­¦æä¾›äº†é«˜æ•ˆçš„é€šç”¨è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "35 pages, 80 figures, submitted to ACM KDD 2026 conference",
      "pdf_url": "https://arxiv.org/pdf/2508.01426v2",
      "published_date": "2025-08-02 16:20:19 UTC",
      "updated_date": "2025-09-04 11:24:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:19:16.358233+00:00"
    },
    {
      "arxiv_id": "2508.01424v2",
      "title": "From Query to Logic: Ontology-Driven Multi-Hop Reasoning in LLMs",
      "title_zh": "ä»æŸ¥è¯¢åˆ°é€»è¾‘ï¼šå¤§è¯­è¨€æ¨¡å‹ä¸­çš„æœ¬ä½“é©±åŠ¨å¤šè·³æ¨ç†",
      "authors": [
        "Haonan Bian",
        "Yutao Qi",
        "Rui Yang",
        "Yuanxi Che",
        "Jiaqian Wang",
        "Heming Xia",
        "Ranran Zhen"
      ],
      "abstract": "Large Language Models (LLMs), despite their success in question answering, exhibit limitations in complex multi-hop question answering (MQA) tasks that necessitate non-linear, structured reasoning. This limitation stems from their inability to adequately capture deep conceptual relationships between entities. To overcome this challenge, we present **ORACLE** (**O**ntology-driven **R**easoning **A**nd **C**hain for **L**ogical **E**ucidation), a training-free framework that combines LLMs' generative capabilities with the structural benefits of knowledge graphs. Our approach operates through three stages: (1) dynamic construction of question-specific knowledge ontologies using LLMs, (2) transformation of these ontologies into First-Order Logic reasoning chains, and (3) systematic decomposition of the original query into logically coherent sub-questions. Experimental results on several standard MQA benchmarks show that our framework achieves highly competitive performance, rivaling current state-of-the-art models like DeepSeek-R1. Detailed analyses further confirm the effectiveness of each component, while demonstrating that our method generates more logical and interpretable reasoning chains than existing approaches.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¤„ç†å¤æ‚å¤šè·³é—®ç­”(Multi-Hop Question Answering, MQA)ä»»åŠ¡æ—¶éš¾ä»¥æ•æ‰å®ä½“é—´æ·±å±‚æ¦‚å¿µå…³ç³»çš„å±€é™æ€§ï¼Œæå‡ºäº†åä¸ºORACLE(Ontology-driven Reasoning And Chain for Logical Elucidation)çš„å…è®­ç»ƒæ¡†æ¶ã€‚è¯¥æ¡†æ¶å°†LLMsçš„ç”Ÿæˆèƒ½åŠ›ä¸çŸ¥è¯†å›¾è°±(Knowledge Graphs)çš„ç»“æ„åŒ–ä¼˜åŠ¿ç›¸ç»“åˆï¼Œé€šè¿‡åŠ¨æ€æ„å»ºé’ˆå¯¹ç‰¹å®šé—®é¢˜çš„çŸ¥è¯†æœ¬ä½“(Ontologies)ã€å°†å…¶è½¬åŒ–ä¸ºä¸€é˜¶é€»è¾‘(First-Order Logic)æ¨ç†é“¾ï¼Œä»¥åŠå°†åŸå§‹æŸ¥è¯¢ç³»ç»Ÿåœ°åˆ†è§£ä¸ºé€»è¾‘è¿è´¯çš„å­é—®é¢˜æ¥æ‰§è¡Œæ¨ç†ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒORACLEåœ¨å¤šä¸ªæ ‡å‡†MQAåŸºå‡†æµ‹è¯•ä¸­å–å¾—äº†æå…·ç«äº‰åŠ›çš„è¡¨ç°ï¼Œè¶³ä»¥åª²ç¾DeepSeek-R1ç­‰å…ˆè¿›æ¨¡å‹ã€‚è¯¦ç»†åˆ†æè¿›ä¸€æ­¥è¯å®äº†å„æ ¸å¿ƒç»„ä»¶çš„æœ‰æ•ˆæ€§ï¼Œå¹¶è¡¨æ˜è¯¥æ–¹æ³•æ¯”ç°æœ‰æŠ€æœ¯èƒ½äº§ç”Ÿæ›´å…·é€»è¾‘æ€§å’Œå¯è§£é‡Šæ€§çš„æ¨ç†è·¯å¾„ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.01424v2",
      "published_date": "2025-08-02 16:12:42 UTC",
      "updated_date": "2025-09-24 05:11:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:19:35.917688+00:00"
    },
    {
      "arxiv_id": "2508.01415v5",
      "title": "RoboMemory: A Brain-inspired Multi-memory Agentic Framework for Interactive Environmental Learning in Physical Embodied Systems",
      "title_zh": "RoboMemoryï¼šé¢å‘ç‰©ç†å…·èº«ç³»ç»Ÿäº¤äº’å¼ç¯å¢ƒå­¦ä¹ çš„ç±»è„‘å¯å‘å¤šè®°å¿†æ™ºèƒ½ä½“æ¡†æ¶",
      "authors": [
        "Mingcong Lei",
        "Honghao Cai",
        "Zezhou Cui",
        "Liangchen Tan",
        "Junkun Hong",
        "Gehan Hu",
        "Shuangyu Zhu",
        "Yimou Wu",
        "Shaohan Jiang",
        "Ge Wang",
        "Yuyuan Yang",
        "Junyuan Tan",
        "Zhenglin Wan",
        "Zhen Li",
        "Shuguang Cui",
        "Yiming Zhao",
        "Yatong Han"
      ],
      "abstract": "Embodied agents face persistent challenges in real-world environments, including partial observability, limited spatial reasoning, and high-latency multi-memory integration. We present RoboMemory, a brain-inspired framework that unifies Spatial, Temporal, Episodic, and Semantic memory under a parallelized architecture for efficient long-horizon planning and interactive environmental learning. A dynamic spatial knowledge graph (KG) ensures scalable and consistent memory updates, while a closed-loop planner with a critic module supports adaptive decision-making in dynamic settings. Experiments on EmbodiedBench show that RoboMemory, built on Qwen2.5-VL-72B-Ins, improves average success rates by 25% over its baseline and exceeds the closed-source state-of-the-art (SOTA) Gemini-1.5-Pro by 3%. Real-world trials further confirm its capacity for cumulative learning, with performance improving across repeated tasks. These results highlight RoboMemory as a scalable foundation for memory-augmented embodied intelligence, bridging the gap between cognitive neuroscience and robotic autonomy.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† RoboMemoryï¼Œè¿™æ˜¯ä¸€ç§å—å¤§è„‘å¯å‘çš„ã€é›†æˆäº† Spatialã€Temporalã€Episodic å’Œ Semantic memory çš„å¤šå­˜å‚¨æ™ºèƒ½ä½“æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å…·èº«æ™ºèƒ½ä½“ï¼ˆEmbodied agentsï¼‰åœ¨ç°å®ç¯å¢ƒä¸­é¢ä¸´çš„éƒ¨åˆ†å¯è§‚æµ‹æ€§ã€ç©ºé—´æ¨ç†å—é™åŠå¤šå­˜å‚¨é›†æˆé«˜å»¶è¿Ÿç­‰æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶é‡‡ç”¨å¹¶è¡ŒåŒ–æ¶æ„å®ç°é«˜æ•ˆçš„é•¿ç¨‹è§„åˆ’ï¼ˆlong-horizon planningï¼‰å’Œäº¤äº’å¼ç¯å¢ƒå­¦ä¹ ï¼Œå¹¶é€šè¿‡åŠ¨æ€ç©ºé—´çŸ¥è¯†å›¾è°±ï¼ˆKGï¼‰ç¡®ä¿å­˜å‚¨æ›´æ–°çš„æ‰©å±•æ€§ä¸ä¸€è‡´æ€§ã€‚å…¶æ ¸å¿ƒè¿˜åŒ…æ‹¬ä¸€ä¸ªå¸¦æœ‰æ‰¹åˆ¤æ¨¡å—ï¼ˆcritic moduleï¼‰çš„é—­ç¯è§„åˆ’å™¨ï¼Œä»¥æ”¯æŒåœ¨åŠ¨æ€ç¯å¢ƒä¸­çš„è‡ªé€‚åº”å†³ç­–ã€‚åœ¨ EmbodiedBench çš„å®éªŒä¸­ï¼ŒåŸºäº Qwen2.5-VL-72B-Ins çš„ RoboMemory æ¯”åŸºçº¿æˆåŠŸç‡æå‡äº† 25%ï¼Œå¹¶ä»¥ 3% çš„ä¼˜åŠ¿è¶…è¶Šäº†é—­æº SOTA æ¨¡å‹ Gemini-1.5-Proã€‚çœŸå®ä¸–ç•Œæµ‹è¯•éªŒè¯äº†å…¶å…·å¤‡ç´¯ç§¯å­¦ä¹ ï¼ˆcumulative learningï¼‰èƒ½åŠ›ï¼Œæ€§èƒ½éšä»»åŠ¡é‡å¤æ˜¾è‘—æå‡ã€‚è¯¥ç ”ç©¶ä¸ºå­˜å‚¨å¢å¼ºå‹å…·èº«æ™ºèƒ½æä¾›äº†å¯æ‰©å±•çš„åŸºç¡€ï¼Œæœ‰æ•ˆå¼¥åˆäº†è®¤çŸ¥ç¥ç»ç§‘å­¦ä¸æœºå™¨äººè‡ªä¸»æ€§ä¹‹é—´çš„é¸¿æ²Ÿã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.01415v5",
      "published_date": "2025-08-02 15:39:42 UTC",
      "updated_date": "2025-10-22 11:48:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:19:39.040074+00:00"
    },
    {
      "arxiv_id": "2508.03747v2",
      "title": "Data-Driven Discovery of Mobility Periodicity for Understanding Urban Systems",
      "title_zh": "æ•°æ®é©±åŠ¨çš„å‡ºè¡Œå‘¨æœŸæ€§å‘ç°ï¼šåŠ©åŠ›åŸå¸‚ç³»ç»Ÿç†è§£",
      "authors": [
        "Xinyu Chen",
        "Qi Wang",
        "Yunhan Zheng",
        "Nina Cao",
        "HanQin Cai",
        "Jinhua Zhao"
      ],
      "abstract": "Human mobility regularity is crucial for understanding urban dynamics and informing decision-making processes. This study first quantifies the periodicity in complex human mobility data as a sparse identification of dominant positive auto-correlations in time series autoregression and then discovers periodic patterns. We apply the framework to large-scale metro passenger flow data in Hangzhou, China and multi-modal mobility data in New York City and Chicago, USA, revealing the interpretable weekly periodicity across different spatial locations over past several years. The analysis of ridesharing data from 2019 to 2024 demonstrates the disruptive impact of the pandemic on mobility regularity and the subsequent recovery trends. In 2024, the periodic mobility patterns of ridesharing, taxi, subway, and bikesharing in Manhattan uncover the regularity and variability of these travel modes. Our findings highlight the potential of interpretable machine learning to discover spatiotemporal mobility patterns and offer a valuable tool for understanding urban systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§æ•°æ®é©±åŠ¨çš„æ–¹æ³•ï¼Œæ—¨åœ¨å‘ç°äººç±»ç§»åŠ¨æ€§ä¸­çš„å‘¨æœŸæ€§è§„å¾‹ï¼Œä»è€Œæ·±åŒ–å¯¹åŸå¸‚åŠ¨æ€çš„ç†è§£ã€‚ç ”ç©¶é€šè¿‡æ—¶é—´åºåˆ—è‡ªå›å½’ (time series autoregression) ä¸­ä¸»å¯¼æ­£è‡ªç›¸å…³çš„ç¨€ç–è¯†åˆ« (sparse identification) æ¥é‡åŒ–ç§»åŠ¨æ•°æ®ä¸­çš„å‘¨æœŸæ€§ï¼Œå¹¶è¯†åˆ«ç‰¹å®šçš„å‘¨æœŸæ¨¡å¼ã€‚è¯¥æ¡†æ¶è¢«åº”ç”¨äºä¸­å›½æ­å·çš„åœ°é“å®¢æµæ•°æ®ä»¥åŠç¾å›½çº½çº¦å’ŒèŠåŠ å“¥çš„å¤šæ¨¡æ€ç§»åŠ¨æ•°æ®ï¼Œæ­ç¤ºäº†è·¨è¶Šä¸åŒåœ°ç†ä½ç½®ä¸”å…·å¤‡å¯è§£é‡Šæ€§çš„å‘¨å‘¨æœŸæ€§ (weekly periodicity)ã€‚é€šè¿‡å¯¹ 2019 å¹´è‡³ 2024 å¹´æ•°æ®çš„åˆ†æï¼Œç ”ç©¶å±•ç¤ºäº†æ–°å† ç–«æƒ…å¯¹ç§»åŠ¨è§„å¾‹çš„ç ´åæ€§å½±å“ä»¥åŠéšåçš„æ¢å¤è¶‹åŠ¿ã€‚2024 å¹´é’ˆå¯¹æ›¼å“ˆé¡¿å¤šç§äº¤é€šæ¨¡å¼ï¼ˆå¦‚ç½‘çº¦è½¦ã€å‡ºç§Ÿè½¦ã€åœ°é“å’Œå…±äº«å•è½¦ï¼‰çš„åˆ†æè¿›ä¸€æ­¥æ­ç¤ºäº†ä¸åŒå‡ºè¡Œæ–¹å¼çš„è§„å¾‹æ€§ä¸å˜å¼‚æ€§ã€‚è¿™äº›å‘ç°çªå‡ºäº†å¯è§£é‡Šæœºå™¨å­¦ä¹  (interpretable machine learning) åœ¨æŒ–æ˜æ—¶ç©ºç§»åŠ¨æ¨¡å¼æ–¹é¢çš„æ½œåŠ›ï¼Œä¸ºåŸå¸‚ç³»ç»Ÿçš„å†³ç­–è¿‡ç¨‹æä¾›äº†é‡è¦å‚è€ƒå·¥å…·ã€‚",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.03747v2",
      "published_date": "2025-08-02 15:25:20 UTC",
      "updated_date": "2025-09-12 14:48:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:19:38.141953+00:00"
    },
    {
      "arxiv_id": "2508.01401v1",
      "title": "MedSynth: Realistic, Synthetic Medical Dialogue-Note Pairs",
      "title_zh": "MedSynthï¼šé€¼çœŸçš„åˆæˆåŒ»å­¦å¯¹è¯-ç—…å†å¯¹",
      "authors": [
        "Ahmad Rezaie Mianroodi",
        "Amirali Rezaie",
        "Niko Grisel Todorov",
        "Cyril Rakovski",
        "Frank Rudzicz"
      ],
      "abstract": "Physicians spend significant time documenting clinical encounters, a burden that contributes to professional burnout. To address this, robust automation tools for medical documentation are crucial. We introduce MedSynth -- a novel dataset of synthetic medical dialogues and notes designed to advance the Dialogue-to-Note (Dial-2-Note) and Note-to-Dialogue (Note-2-Dial) tasks. Informed by an extensive analysis of disease distributions, this dataset includes over 10,000 dialogue-note pairs covering over 2000 ICD-10 codes. We demonstrate that our dataset markedly enhances the performance of models in generating medical notes from dialogues, and dialogues from medical notes. The dataset provides a valuable resource in a field where open-access, privacy-compliant, and diverse training data are scarce. Code is available at https://github.com/ahmadrezarm/MedSynth/tree/main and the dataset is available at https://huggingface.co/datasets/Ahmad0067/MedSynth.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† MedSynthï¼Œä¸€ä¸ªç”±åˆæˆçš„åŒ»ç–—å¯¹è¯å’Œä¸´åºŠç¬”è®°ç»„æˆçš„æ–°å‹æ•°æ®é›†ï¼Œæ—¨åœ¨é€šè¿‡è‡ªåŠ¨åŒ–æ–‡æ¡£å·¥å…·å‡è½»åŒ»ç”Ÿçš„å·¥ä½œè´Ÿæ‹…å¹¶ç¼“è§£èŒä¸šå€¦æ€ ã€‚è¯¥æ•°æ®é›†åŒ…å«äº†è¶…è¿‡ 10,000 å¯¹åŒ»ç–—å¯¹è¯ä¸ç¬”è®°ï¼Œæ¶µç›–äº† 2,000 å¤šä¸ª ICD-10 ä»£ç ï¼Œå…¶æ„å»ºè¿‡ç¨‹å……åˆ†å‚è€ƒäº†å¹¿æ³›çš„ç–¾ç—…åˆ†å¸ƒåˆ†æã€‚MedSynth ä¸“é—¨ç”¨äºæ¨åŠ¨ Dialogue-to-Note (Dial-2-Note) å’Œ Note-to-Dialogue (Note-2-Dial) ä»»åŠ¡çš„å‘å±•ï¼Œå®éªŒè¯æ˜è¯¥æ•°æ®é›†æ˜¾è‘—å¢å¼ºäº†æ¨¡å‹åœ¨ç”ŸæˆåŒ»ç–—ç¬”è®°å’Œå¯¹è¯æ–¹é¢çš„æ€§èƒ½ã€‚åœ¨å¼€æ”¾è·å–ã€ç¬¦åˆéšç§åˆè§„ä¸”å…·æœ‰å¤šæ ·æ€§çš„åŒ»ç–—è®­ç»ƒæ•°æ®ç¨€ç¼ºçš„èƒŒæ™¯ä¸‹ï¼Œè¯¥ç ”ç©¶ä¸ºåŒ»ç–—äººå·¥æ™ºèƒ½é¢†åŸŸæä¾›äº†æå…·ä»·å€¼çš„èµ„æºæ”¯æ’‘ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "7 pages excluding references and appendices",
      "pdf_url": "https://arxiv.org/pdf/2508.01401v1",
      "published_date": "2025-08-02 15:18:19 UTC",
      "updated_date": "2025-08-02 15:18:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:19:46.394158+00:00"
    },
    {
      "arxiv_id": "2508.01396v2",
      "title": "Spatial-Frequency Aware for Object Detection in RAW Image",
      "title_zh": "é¢å‘RAWå›¾åƒç›®æ ‡æ£€æµ‹çš„ç©ºé—´-é¢‘ç‡æ„ŸçŸ¥",
      "authors": [
        "Zhuohua Ye",
        "Liming Zhang",
        "Hongru Han"
      ],
      "abstract": "Direct RAW-based object detection offers great promise by utilizing RAW data (unprocessed sensor data), but faces inherent challenges due to its wide dynamic range and linear response, which tends to suppress crucial object details. In particular, existing enhancement methods are almost all performed in the spatial domain, making it difficult to effectively recover these suppressed details from the skewed pixel distribution of RAW images. To address this limitation, we turn to the frequency domain, where features, such as object contours and textures, can be naturally separated based on frequency. In this paper, we propose Space-Frequency Aware RAW Image Object Detection Enhancer (SFAE), a novel framework that synergizes spatial and frequency representations. Our contribution is threefold. The first lies in the ``spatialization\" of frequency bands. Different from the traditional paradigm of directly manipulating abstract spectra in deep networks, our method inversely transforms individual frequency bands back into tangible spatial maps, thus preserving direct physical intuition. Then the cross-domain fusion attention module is developed to enable deep multimodal interactions between these maps and the original spatial features. Finally, the framework performs adaptive nonlinear adjustments by predicting and applying different gamma parameters for the two domains.",
      "tldr_zh": "ç›´æ¥åŸºäº RAW å›¾åƒçš„ç›®æ ‡æ£€æµ‹ç”±äºå…¶å®½åŠ¨æ€èŒƒå›´å’Œçº¿æ€§å“åº”ç‰¹æ€§ï¼Œå¾€å¾€ä¼šæŠ‘åˆ¶å…³é”®çš„ç›®æ ‡ç»†èŠ‚ï¼Œä¸”ç°æœ‰çš„ç©ºé—´åŸŸå¢å¼ºæ–¹æ³•éš¾ä»¥æœ‰æ•ˆæ¢å¤è¿™äº›è¢«å‹æŠ‘çš„ä¿¡æ¯ã€‚è¯¥ç ”ç©¶æå‡ºäº†ç©ºé—´-é¢‘ç‡æ„ŸçŸ¥ RAW å›¾åƒç›®æ ‡æ£€æµ‹å¢å¼ºå™¨ (Space-Frequency Aware RAW Image Object Detection Enhancer, SFAE)ï¼Œæ—¨åœ¨é€šè¿‡ååŒç©ºé—´å’Œé¢‘ç‡è¡¨ç¤ºæ¥å…‹æœè¿™ä¸€éš¾é¢˜ã€‚è¯¥æ¡†æ¶çš„æ ¸å¿ƒè´¡çŒ®åœ¨äºå®ç°äº†é¢‘å¸¦çš„â€œç©ºé—´åŒ–â€ (spatialization)ï¼Œå°†ä¸åŒé¢‘å¸¦é€†å˜æ¢ä¸ºå…·ä½“çš„ç©ºé—´æ˜ å°„ä»¥ä¿ç•™ç‰©ç†ç›´è§‰ã€‚åŒæ—¶ï¼Œç ”ç©¶å¼•å…¥äº†è·¨åŸŸèåˆæ³¨æ„åŠ›æ¨¡å— (cross-domain fusion attention module)ï¼Œä¿ƒè¿›äº†é¢‘ç‡æ˜ å°„ä¸åŸå§‹ç©ºé—´ç‰¹å¾ä¹‹é—´çš„æ·±åº¦äº¤äº’ã€‚æ­¤å¤–ï¼ŒSFAE é€šè¿‡ä¸ºä¸¤ä¸ªé¢†åŸŸé¢„æµ‹å¹¶åº”ç”¨ä¸åŒçš„ Gamma å‚æ•°ï¼Œå®ç°äº†è‡ªé€‚åº”çš„éçº¿æ€§è°ƒæ•´ã€‚è¿™ç§æ–¹æ³•å……åˆ†åˆ©ç”¨äº†é¢‘ç‡åŸŸå¤©ç„¶åˆ†ç¦»ç›®æ ‡è½®å»“å’Œçº¹ç†çš„ç‰¹æ€§ï¼Œä¸ºæå‡ RAW å›¾åƒç›®æ ‡æ£€æµ‹çš„ç²¾ç¡®åº¦æä¾›äº†æ–°çš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.01396v2",
      "published_date": "2025-08-02 15:03:23 UTC",
      "updated_date": "2025-08-06 14:26:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:19:46.216491+00:00"
    },
    {
      "arxiv_id": "2508.01394v1",
      "title": "Via Score to Performance: Efficient Human-Controllable Long Song Generation with Bar-Level Symbolic Notation",
      "title_zh": "ä»ä¹è°±åˆ°æ¼”å¥ï¼šåŸºäºå°èŠ‚çº§ç¬¦å·è¡¨ç¤ºçš„é«˜æ•ˆå¯æ§é•¿æ­Œæ›²ç”Ÿæˆ",
      "authors": [
        "Tongxi Wang",
        "Yang Yu",
        "Qing Wang",
        "Junlang Qian"
      ],
      "abstract": "Song generation is regarded as the most challenging problem in music AIGC; nonetheless, existing approaches have yet to fully overcome four persistent limitations: controllability, generalizability, perceptual quality, and duration. We argue that these shortcomings stem primarily from the prevailing paradigm of attempting to learn music theory directly from raw audio, a task that remains prohibitively difficult for current models. To address this, we present Bar-level AI Composing Helper (BACH), the first model explicitly designed for song generation through human-editable symbolic scores. BACH introduces a tokenization strategy and a symbolic generative procedure tailored to hierarchical song structure. Consequently, it achieves substantial gains in the efficiency, duration, and perceptual quality of song generation. Experiments demonstrate that BACH, with a small model size, establishes a new SOTA among all publicly reported song generation systems, even surpassing commercial solutions such as Suno. Human evaluations further confirm its superiority across multiple subjective metrics.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰éŸ³é¢‘ç”Ÿæˆæ¨¡å‹åœ¨å¯æ§æ€§ã€æ³›åŒ–æ€§ã€æ„ŸçŸ¥è´¨é‡å’Œæ—¶é•¿æ–¹é¢çš„å±€é™æ€§ï¼Œæå‡ºäº†åä¸ºBACHï¼ˆBar-level AI Composing Helperï¼‰çš„æ­Œæ›²ç”Ÿæˆæ¨¡å‹ã€‚ä½œè€…æŒ‡å‡ºï¼Œç›´æ¥ä»åŸå§‹éŸ³é¢‘ï¼ˆraw audioï¼‰å­¦ä¹ éŸ³ä¹ç†è®ºéå¸¸å›°éš¾ï¼Œå› æ­¤BACHè½¬è€Œé‡‡ç”¨äººç±»å¯ç¼–è¾‘çš„ç¬¦å·è°±ï¼ˆsymbolic scoresï¼‰ä½œä¸ºç”ŸæˆåŸºç¡€ã€‚é€šè¿‡å¼•å…¥é’ˆå¯¹æ­Œæ›²å±‚æ¬¡ç»“æ„è®¾è®¡çš„æ ‡è®°åŒ–ç­–ç•¥ï¼ˆtokenization strategyï¼‰å’Œç¬¦å·ç”Ÿæˆæµç¨‹ï¼Œè¯¥æ¨¡å‹åœ¨ç”Ÿæˆæ•ˆç‡ã€æ­Œæ›²æ—¶é•¿å’Œæ„ŸçŸ¥è´¨é‡ä¸Šå–å¾—äº†æ˜¾è‘—çªç ´ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œå°½ç®¡æ¨¡å‹è§„æ¨¡è¾ƒå°ï¼ŒBACHåœ¨å„é¡¹æŒ‡æ ‡ä¸Šå‡è¾¾åˆ°äº†æ–°çš„SOTAï¼Œè¡¨ç°ç”šè‡³ä¼˜äºåŒ…æ‹¬Sunoåœ¨å†…çš„å•†ä¸šè§£å†³æ–¹æ¡ˆã€‚äººç±»è¯„ä¼°ç»“æœä¹Ÿè¿›ä¸€æ­¥éªŒè¯äº†BACHåœ¨å¤šé¡¹ä¸»è§‚æŒ‡æ ‡ä¸Šçš„é¢†å…ˆåœ°ä½ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.01394v1",
      "published_date": "2025-08-02 14:58:34 UTC",
      "updated_date": "2025-08-02 14:58:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:19:50.147340+00:00"
    },
    {
      "arxiv_id": "2508.01390v2",
      "title": "Recognising, Anticipating, and Mitigating LLM Pollution of Online Behavioural Research",
      "title_zh": "è¯†åˆ«ã€é¢„è§ä¸ç¼“è§£åœ¨çº¿è¡Œä¸ºç ”ç©¶ä¸­çš„ LLM æ±¡æŸ“",
      "authors": [
        "Raluca Rilla",
        "Tobias Werner",
        "Hiromu Yakura",
        "Iyad Rahwan",
        "Anne-Marie Nussberger"
      ],
      "abstract": "Online behavioural research faces an emerging threat as participants increasingly turn to large language models (LLMs) for advice, translation, or task delegation: LLM Pollution. We identify three interacting variants through which LLM Pollution threatens the validity and integrity of online behavioural research. First, Partial LLM Mediation occurs when participants make selective use of LLMs for specific aspects of a task, such as translation or wording support, leading researchers to (mis)interpret LLM-shaped outputs as human ones. Second, Full LLM Delegation arises when agentic LLMs complete studies with little to no human oversight, undermining the central premise of human-subject research at a more foundational level. Third, LLM Spillover signifies human participants altering their behaviour as they begin to anticipate LLM presence in online studies, even when none are involved. While Partial Mediation and Full Delegation form a continuum of increasing automation, LLM Spillover reflects second-order reactivity effects. Together, these variants interact and generate cascading distortions that compromise sample authenticity, introduce biases that are difficult to detect post hoc, and ultimately undermine the epistemic grounding of online research on human cognition and behaviour. Crucially, the threat of LLM Pollution is already co-evolving with advances in generative AI, creating an escalating methodological arms race. To address this, we propose a multi-layered response spanning researcher practices, platform accountability, and community efforts. As the challenge evolves, coordinated adaptation will be essential to safeguard methodological integrity and preserve the validity of online behavioural research.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨çº¿è¡Œä¸ºç ”ç©¶ï¼ˆOnline behavioural researchï¼‰é¢ä¸´çš„ä¸€ä¸ªæ–°å…´å¨èƒï¼Œå³å¤§è¯­è¨€æ¨¡å‹æ±¡æŸ“ï¼ˆLLM Pollutionï¼‰ï¼ŒæŒ‡å‚ä¸è€…åœ¨ç ”ç©¶è¿‡ç¨‹ä¸­åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¿›è¡Œä»»åŠ¡è¾…åŠ©ã€ç¿»è¯‘æˆ–ç›´æ¥å§”æ‰˜ä»»åŠ¡çš„ç°è±¡ã€‚æ–‡ç« è¯†åˆ«äº†ä¸‰ç§ç›¸äº’ä½œç”¨çš„æ±¡æŸ“æ¨¡å¼ï¼šéƒ¨åˆ†LLMä¸­ä»‹ï¼ˆPartial LLM Mediationï¼‰ã€å®Œå…¨LLMå§”æ‰˜ï¼ˆFull LLM Delegationï¼‰ä»¥åŠå› å‚ä¸è€…é¢„æœŸæ¨¡å‹å­˜åœ¨è€Œæ”¹å˜è¡Œä¸ºçš„LLMæº¢å‡ºï¼ˆLLM Spilloverï¼‰ã€‚è¿™äº›æ±¡æŸ“å˜ä½“å…±åŒäº§ç”Ÿäº†çº§è”å¤±çœŸï¼Œä¸ä»…æŸå®³äº†æ ·æœ¬çš„çœŸå®æ€§ï¼ˆauthenticityï¼‰ï¼Œè¿˜å¼•å…¥äº†éš¾ä»¥æ£€æµ‹çš„åå·®ï¼Œæœ€ç»ˆåŠ¨æ‘‡äº†åœ¨çº¿ç ”ç©¶åœ¨äººç±»è®¤çŸ¥å’Œè¡Œä¸ºæ–¹é¢çš„è®¤è¯†è®ºåŸºç¡€ï¼ˆepistemic groundingï¼‰ã€‚é’ˆå¯¹è¿™ä¸€ä¸æ–­æ¼”å˜çš„æ–¹æ³•è®ºæŒ‘æˆ˜ï¼Œç ”ç©¶æå‡ºäº†æ¶µç›–ç ”ç©¶è€…å®è·µã€å¹³å°è´£ä»»å’Œç¤¾åŒºå…±åŒåŠªåŠ›çš„å¤šå±‚æ¬¡å“åº”æ–¹æ¡ˆã€‚è¯¥ç ”ç©¶å¼ºè°ƒï¼Œåªæœ‰é€šè¿‡åè°ƒä¸€è‡´çš„é€‚åº”æ€§å¯¹ç­–ï¼Œæ‰èƒ½ç»´æŠ¤åœ¨çº¿è¡Œä¸ºç ”ç©¶çš„æ–¹æ³•è®ºå®Œæ•´æ€§ï¼ˆmethodological integrityï¼‰å¹¶ç¡®ä¿ç ”ç©¶ç»“è®ºçš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.01390v2",
      "published_date": "2025-08-02 14:40:54 UTC",
      "updated_date": "2025-11-01 18:45:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:19:50.339810+00:00"
    },
    {
      "arxiv_id": "2508.02742v2",
      "title": "SpectrumFM: Redefining Spectrum Cognition via Foundation Modeling",
      "title_zh": "SpectrumFMï¼šé€šè¿‡åŸºç¡€æ¨¡å‹é‡æ–°å®šä¹‰é¢‘è°±è®¤çŸ¥",
      "authors": [
        "Chunyu Liu",
        "Hao Zhang",
        "Wei Wu",
        "Fuhui Zhou",
        "Qihui Wu",
        "Derrick Wing Kwan Ng",
        "Chan-Byoung Chae"
      ],
      "abstract": "The enhancement of spectrum efficiency and the realization of secure spectrum utilization are critically dependent on spectrum cognition. However, existing spectrum cognition methods often exhibit limited generalization and suboptimal accuracy when deployed across diverse spectrum environments and tasks. To overcome these challenges, we propose a spectrum foundation model, termed SpectrumFM, which provides a new paradigm for spectrum cognition. An innovative spectrum encoder that exploits the convolutional neural networks and the multi-head self attention mechanisms is proposed to effectively capture both fine-grained local signal structures and high-level global dependencies in the spectrum data. To enhance its adaptability, two novel self-supervised learning tasks, namely masked reconstruction and next-slot signal prediction, are developed for pre-training SpectrumFM, enabling the model to learn rich and transferable representations. Furthermore, low-rank adaptation (LoRA) parameter-efficient fine-tuning is exploited to enable SpectrumFM to seamlessly adapt to various downstream spectrum cognition tasks, including spectrum sensing (SS), anomaly detection (AD), and wireless technology classification (WTC). Extensive experiments demonstrate the superiority of SpectrumFM over state-of-the-art methods. Specifically, it improves detection probability in the SS task by 30% at -4 dB signal-to-noise ratio (SNR), boosts the area under the curve (AUC) in the AD task by over 10%, and enhances WTC accuracy by 9.6%.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†SpectrumFMï¼Œè¿™æ˜¯ä¸€ç§æ—¨åœ¨é‡æ–°å®šä¹‰é¢‘è°±è®¤çŸ¥(Spectrum Cognition)çš„é¢‘è°±åŸºç¡€æ¨¡å‹ï¼Œæœ‰æ•ˆè§£å†³äº†ç°æœ‰æ–¹æ³•åœ¨å¤æ‚ç¯å¢ƒä¸‹æ³›åŒ–èƒ½åŠ›å·®å’Œå‡†ç¡®ç‡ä½çš„é—®é¢˜ã€‚è¯¥æ¨¡å‹è®¾è®¡äº†ä¸€ç§åˆ›æ–°çš„é¢‘è°±ç¼–ç å™¨ï¼Œç»“åˆäº†å·ç§¯ç¥ç»ç½‘ç»œ(CNNs)ä¸å¤šå¤´è‡ªæ³¨æ„åŠ›æœºåˆ¶(Multi-head Self Attention)ï¼Œèƒ½å¤ŸåŒæ—¶æ•æ‰ä¿¡å·çš„å±€éƒ¨å¾®è§‚ç»“æ„ä¸å…¨å±€ä¾èµ–å…³ç³»ã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡æ©ç é‡æ„(Masked Reconstruction)å’Œä¸‹ä¸€æ—¶éš™ä¿¡å·é¢„æµ‹(Next-slot Signal Prediction)ä¸¤é¡¹è‡ªç›‘ç£å­¦ä¹ ä»»åŠ¡å¯¹æ¨¡å‹è¿›è¡Œé¢„è®­ç»ƒï¼Œä½¿å…¶è·å¾—äº†æå¼ºçš„ç‰¹å¾è¿ç§»èƒ½åŠ›ã€‚åˆ©ç”¨ä½ç§©è‡ªé€‚åº”(LoRA)å¾®è°ƒæŠ€æœ¯ï¼ŒSpectrumFMå¯é«˜æ•ˆé€‚é…é¢‘è°±æ„ŸçŸ¥(SS)ã€å¼‚å¸¸æ£€æµ‹(AD)å’Œæ— çº¿æŠ€æœ¯åˆ†ç±»(WTC)ç­‰ä¸‹æ¸¸ä»»åŠ¡ã€‚å®éªŒç»“æœéªŒè¯äº†è¯¥æ¨¡å‹çš„å“è¶Šæ€§èƒ½ï¼Œå…¶åœ¨-4 dBä¿¡å™ªæ¯”(SNR)ä¸‹çš„æ£€æµ‹æ¦‚ç‡æå‡äº†30%ï¼Œå¼‚å¸¸æ£€æµ‹çš„AUCå€¼æå‡è¶…10%ï¼Œå¹¶å°†åˆ†ç±»å‡†ç¡®ç‡ä¼˜åŒ–äº†9.6%ï¼Œä¸ºé¢‘è°±è®¤çŸ¥é¢†åŸŸæä¾›äº†æ–°çš„èŒƒå¼ã€‚",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "This paper has been accepted for presentation at the 2025 IEEE Global Communications Conference (GLOBECOM 2025), Cognitive Radio and AI-Enabled Network Symposium",
      "pdf_url": "https://arxiv.org/pdf/2508.02742v2",
      "published_date": "2025-08-02 14:40:50 UTC",
      "updated_date": "2025-08-10 12:34:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:20:03.262042+00:00"
    },
    {
      "arxiv_id": "2508.01387v1",
      "title": "Video-based Vehicle Surveillance in the Wild: License Plate, Make, and Model Recognition with Self Reflective Vision-Language Models",
      "title_zh": "å¤æ‚åœºæ™¯ä¸‹çš„è§†é¢‘è½¦è¾†ç›‘æ§ï¼šåŸºäºè‡ªåæ€è§†è§‰è¯­è¨€æ¨¡å‹çš„è½¦ç‰Œã€å“ç‰ŒåŠå‹å·è¯†åˆ«",
      "authors": [
        "Pouya Parsa",
        "Keya Li",
        "Kara M. Kockelman",
        "Seongjin Choi"
      ],
      "abstract": "Automatic license plate recognition (ALPR) and vehicle make and model recognition underpin intelligent transportation systems, supporting law enforcement, toll collection, and post-incident investigation. Applying these methods to videos captured by handheld smartphones or non-static vehicle-mounted cameras presents unique challenges compared to fixed installations, including frequent camera motion, varying viewpoints, occlusions, and unknown road geometry. Traditional ALPR solutions, dependent on specialized hardware and handcrafted OCR pipelines, often degrade under these conditions. Recent advances in large vision-language models (VLMs) enable direct recognition of textual and semantic attributes from arbitrary imagery. This study evaluates the potential of VLMs for ALPR and makes and models recognition using monocular videos captured with handheld smartphones and non-static mounted cameras. The proposed license plate recognition pipeline filters to sharp frames, then sends a multimodal prompt to a VLM using several prompt strategies. Make and model recognition pipeline runs the same VLM with a revised prompt and an optional self-reflection module. In the self-reflection module, the model contrasts the query image with a reference from a 134-class dataset, correcting mismatches. Experiments on a smartphone dataset collected on the campus of the University of Texas at Austin, achieve top-1 accuracies of 91.67% for ALPR and 66.67% for make and model recognition. On the public UFPR-ALPR dataset, the approach attains 83.05% and 61.07%, respectively. The self-reflection module further improves results by 5.72% on average for make and model recognition. These findings demonstrate that VLMs provide a cost-effective solution for scalable, in-motion traffic video analysis.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æ¢è®¨äº†åˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡å‹ (VLMs) åœ¨æ‰‹æŒæ™ºèƒ½æ‰‹æœºæˆ–åŠ¨æ€æ‘„åƒå¤´æ‹æ‘„çš„é‡å¤–è§†é¢‘ä¸­å®ç°è‡ªåŠ¨è½¦ç‰Œè¯†åˆ« (ALPR) ä»¥åŠè½¦è¾†å“ç‰Œå’Œå‹å·è¯†åˆ«ã€‚ä¸ºäº†åº”å¯¹é¢‘ç¹çš„ç›¸æœºè¿åŠ¨ã€è§†è§’å˜åŒ–å’Œé®æŒ¡ç­‰æŒ‘æˆ˜ï¼Œç ”ç©¶æå‡ºäº†ä¸€å¥—é€šè¿‡é”åº¦è¿‡æ»¤å¹¶ç»“åˆå¤šæ¨¡æ€æç¤ºç­–ç•¥çš„å¤„ç†æµç¨‹ã€‚é’ˆå¯¹å“ç‰Œå’Œå‹å·è¯†åˆ«ï¼Œè¯¥æ–¹æ³•å¼•å…¥äº† Self-reflection æ¨¡å—ï¼Œé€šè¿‡å°†æŸ¥è¯¢å›¾åƒä¸åŒ…å« 134 ä¸ªç±»åˆ«çš„å‚è€ƒæ•°æ®é›†è¿›è¡Œå¯¹æ¯”æ¥çº æ­£è¯†åˆ«åå·®ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥ç³»ç»Ÿåœ¨å¾·å…‹è¨æ–¯å¤§å­¦å¥¥æ–¯æ±€åˆ†æ ¡çš„æ•°æ®é›†ä¸Šåˆ†åˆ«è¾¾åˆ°äº† 91.67% çš„ ALPR å‡†ç¡®ç‡å’Œ 66.67% çš„å‹å·è¯†åˆ«å‡†ç¡®ç‡ã€‚åœ¨å…¬å…±æ•°æ®é›† UFPR-ALPR ä¸Šï¼Œè¯¥æ–¹æ³•ä¹Ÿå±•ç¤ºäº†è¾ƒå¼ºçš„é²æ£’æ€§ï¼Œå…¶ä¸­ Self-reflection æ¨¡å—å°†å‹å·è¯†åˆ«å‡†ç¡®ç‡å¹³å‡æå‡äº† 5.72%ã€‚è¯¥ç ”ç©¶è¯æ˜äº† VLMs ä¸ºå¯æ‰©å±•çš„åŠ¨æ€äº¤é€šè§†é¢‘åˆ†ææä¾›äº†ä¸€ç§æå…·æ€§ä»·æ¯”çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "19 pages, 6 figures, 4 tables",
      "pdf_url": "https://arxiv.org/pdf/2508.01387v1",
      "published_date": "2025-08-02 14:34:19 UTC",
      "updated_date": "2025-08-02 14:34:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:20:01.746969+00:00"
    },
    {
      "arxiv_id": "2508.01382v1",
      "title": "A Full-Stage Refined Proposal Algorithm for Suppressing False Positives in Two-Stage CNN-Based Detection Methods",
      "title_zh": "æŠ‘åˆ¶ä¸¤é˜¶æ®µCNNæ£€æµ‹æ–¹æ³•ä¸­è¯¯æŠ¥çš„å…¨é˜¶æ®µç²¾ç»†åŒ–å»ºè®®æ¡†ç®—æ³•",
      "authors": [
        "Qiang Guo",
        "Rubo Zhang",
        "Bingbing Zhang",
        "Junjie Liu",
        "Jianqing Liu"
      ],
      "abstract": "False positives in pedestrian detection remain a challenge that has yet to be effectively resolved. To address this issue, this paper proposes a Full-stage Refined Proposal (FRP) algorithm aimed at eliminating these false positives within a two-stage CNN-based pedestrian detection framework. The main innovation of this work lies in employing various pedestrian feature re-evaluation strategies to filter out low-quality pedestrian proposals during both the training and testing stages. Specifically, in the training phase, the Training mode FRP algorithm (TFRP) introduces a novel approach for validating pedestrian proposals to effectively guide the model training process, thereby constructing a model with strong capabilities for false positive suppression. During the inference phase, two innovative strategies are implemented: the Classifier-guided FRP (CFRP) algorithm integrates a pedestrian classifier into the proposal generation pipeline to yield high-quality proposals through pedestrian feature evaluation, and the Split-proposal FRP (SFRP) algorithm vertically divides all proposals, sending both the original and the sub-region proposals to the subsequent subnetwork to evaluate their confidence scores, filtering out those with lower sub-region pedestrian confidence scores. As a result, the proposed algorithm enhances the model's ability to suppress pedestrian false positives across all stages. Various experiments conducted on multiple benchmarks and the SY-Metro datasets demonstrate that the model, supported by different combinations of the FRP algorithm, can effectively eliminate false positives to varying extents. Furthermore, experiments conducted on embedded platforms underscore the algorithm's effectiveness in enhancing the comprehensive pedestrian detection capabilities of the small pedestrian detector in resource-constrained edge devices.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Full-stage Refined Proposal (FRP)ç®—æ³•ï¼Œæ—¨åœ¨è§£å†³ä¸¤é˜¶æ®µCNN (Two-stage CNN)è¡Œäººæ£€æµ‹æ¡†æ¶ä¸­æ™®éå­˜åœ¨çš„è¯¯æŠ¥(False Positives)æŒ‘æˆ˜ã€‚å…¶ä¸»è¦åˆ›æ–°åœ¨äºé€šè¿‡å¤šç§è¡Œäººç‰¹å¾é‡æ–°è¯„ä¼°ç­–ç•¥ï¼Œåœ¨è®­ç»ƒå’Œæ¨ç†çš„å…¨é˜¶æ®µè¿‡æ»¤ä½è´¨é‡çš„å€™é€‰å»ºè®®(Proposals)ã€‚åœ¨è®­ç»ƒé˜¶æ®µï¼ŒTFRPç®—æ³•é€šè¿‡æ–°å‹éªŒè¯æ–¹å¼å¼•å¯¼æ¨¡å‹æ„å»ºæ›´å¼ºçš„è¯¯æŠ¥æŠ‘åˆ¶èƒ½åŠ›ï¼›åœ¨æ¨ç†é˜¶æ®µï¼ŒCFRPç®—æ³•åˆ©ç”¨åˆ†ç±»å™¨å¼•å¯¼ç”Ÿæˆé«˜è´¨é‡å»ºè®®ï¼Œè€ŒSFRPç®—æ³•åˆ™é€šè¿‡å‚ç›´åˆ†å‰²å»ºè®®æ¡†å¹¶è¯„ä¼°å­åŒºåŸŸç½®ä¿¡åº¦æ¥å‰”é™¤å¹²æ‰°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒFRPç®—æ³•åœ¨å¤šé¡¹åŸºå‡†æµ‹è¯•å’ŒSY-Metroæ•°æ®é›†ä¸Šå‡èƒ½æœ‰æ•ˆæ¶ˆé™¤è¯¯æŠ¥ã€‚æ­¤å¤–ï¼Œè¯¥ç®—æ³•åœ¨åµŒå…¥å¼å¹³å°ä¸Šçš„è¡¨ç°ä¹Ÿè¯æ˜äº†å…¶åœ¨èµ„æºå—é™çš„è¾¹ç¼˜è®¾å¤‡(Edge Devices)ä¸­æå‡å°å‹æ£€æµ‹å™¨æ€§èƒ½çš„å®ç”¨ä»·å€¼ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.01382v1",
      "published_date": "2025-08-02 14:25:37 UTC",
      "updated_date": "2025-08-02 14:25:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:20:02.144673+00:00"
    },
    {
      "arxiv_id": "2508.01380v1",
      "title": "Effective Damage Data Generation by Fusing Imagery with Human Knowledge Using Vision-Language Models",
      "title_zh": "åˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡å‹èåˆå½±åƒä¸äººç±»çŸ¥è¯†çš„é«˜æ•ˆæŸæ¯æ•°æ®ç”Ÿæˆ",
      "authors": [
        "Jie Wei",
        "Erika Ardiles-Cruz",
        "Aleksey Panasyuk",
        "Erik Blasch"
      ],
      "abstract": "It is of crucial importance to assess damages promptly and accurately in humanitarian assistance and disaster response (HADR). Current deep learning approaches struggle to generalize effectively due to the imbalance of data classes, scarcity of moderate damage examples, and human inaccuracy in pixel labeling during HADR situations. To accommodate for these limitations and exploit state-of-the-art techniques in vision-language models (VLMs) to fuse imagery with human knowledge understanding, there is an opportunity to generate a diversified set of image-based damage data effectively. Our initial experimental results suggest encouraging data generation quality, which demonstrates an improvement in classifying scenes with different levels of structural damage to buildings, roads, and infrastructures.",
      "tldr_zh": "åœ¨è¯¥ç ”ç©¶ä¸­ï¼Œé’ˆå¯¹äººé“ä¸»ä¹‰æ´åŠ©å’Œç¾éš¾å“åº” (HADR) é¢†åŸŸé¢ä¸´çš„æ•°æ®ç±»åˆ«ä¸å¹³è¡¡ã€ä¸­åº¦æŸå®³æ ·æœ¬ç¨€ç¼ºä»¥åŠåƒç´ æ ‡æ³¨ä¸å‡†ç¡®ç­‰æŒ‘æˆ˜ï¼Œä½œè€…æå‡ºäº†ä¸€ç§åˆ©ç”¨è§†è§‰è¯­è¨€æ¨¡å‹ (VLMs) å°†å›¾åƒä¿¡æ¯ä¸äººç±»çŸ¥è¯†ç†è§£ç›¸èåˆçš„æ•°æ®ç”Ÿæˆæ–¹æ³•ã€‚è¯¥æ–¹æ³•æ—¨åœ¨é€šè¿‡èåˆè·¨æ¨¡æ€çŸ¥è¯†ï¼Œé«˜æ•ˆç”Ÿæˆå¤šæ ·åŒ–çš„åŸºäºå›¾åƒçš„æŸå®³æ•°æ®é›†ï¼Œä»¥å¼¥è¡¥ç°æœ‰æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨æ³›åŒ–èƒ½åŠ›ä¸Šçš„ä¸è¶³ã€‚åˆæ­¥å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•äº§ç”Ÿçš„æ•°æ®å…·æœ‰é«˜è´¨é‡ï¼Œèƒ½å¤Ÿæ˜¾è‘—æå‡å¯¹å»ºç­‘ã€é“è·¯å’ŒåŸºç¡€è®¾æ–½ä¸åŒç¨‹åº¦ç»“æ„æŸå®³çš„åˆ†ç±»å‡†ç¡®æ€§ã€‚è¿™ä¸€ç ”ç©¶ä¸ºè§£å†³ HADR ç¯å¢ƒä¸‹çš„ç¨€ç¼ºæ•°æ®ç”Ÿæˆæä¾›äº†æœ‰æ•ˆé€”å¾„ï¼Œä¸ºæ›´ç²¾ç¡®ã€åŠæ—¶çš„ç¾å®³è¯„ä¼°å¥ å®šäº†æŠ€æœ¯åŸºç¡€ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages, IEEE NAECON'25",
      "pdf_url": "https://arxiv.org/pdf/2508.01380v1",
      "published_date": "2025-08-02 14:22:25 UTC",
      "updated_date": "2025-08-02 14:22:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:20:18.842064+00:00"
    },
    {
      "arxiv_id": "2508.02741v1",
      "title": "DeepGB-TB: A Risk-Balanced Cross-Attention Gradient-Boosted Convolutional Network for Rapid, Interpretable Tuberculosis Screening",
      "title_zh": "DeepGB-TBï¼šé¢å‘å¿«é€Ÿã€å¯è§£é‡Šç»“æ ¸ç—…ç­›æŸ¥çš„é£é™©å¹³è¡¡äº¤å‰æ³¨æ„åŠ›æ¢¯åº¦æå‡å·ç§¯ç½‘ç»œ",
      "authors": [
        "Zhixiang Lu",
        "Yulong Li",
        "Feilong Tang",
        "Zhengyong Jiang",
        "Chong Li",
        "Mian Zhou",
        "Tenglong Li",
        "Jionglong Su"
      ],
      "abstract": "Large-scale tuberculosis (TB) screening is limited by the high cost and operational complexity of traditional diagnostics, creating a need for artificial-intelligence solutions. We propose DeepGB-TB, a non-invasive system that instantly assigns TB risk scores using only cough audio and basic demographic data. The model couples a lightweight one-dimensional convolutional neural network for audio processing with a gradient-boosted decision tree for tabular features. Its principal innovation is a Cross-Modal Bidirectional Cross-Attention module (CM-BCA) that iteratively exchanges salient cues between modalities, emulating the way clinicians integrate symptoms and risk factors. To meet the clinical priority of minimizing missed cases, we design a Tuberculosis Risk-Balanced Loss (TRBL) that places stronger penalties on false-negative predictions, thereby reducing high-risk misclassifications. DeepGB-TB is evaluated on a diverse dataset of 1,105 patients collected across seven countries, achieving an AUROC of 0.903 and an F1-score of 0.851, representing a new state of the art. Its computational efficiency enables real-time, offline inference directly on common mobile devices, making it ideal for low-resource settings. Importantly, the system produces clinically validated explanations that promote trust and adoption by frontline health workers. By coupling AI innovation with public-health requirements for speed, affordability, and reliability, DeepGB-TB offers a tool for advancing global TB control.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†DeepGB-TBï¼Œä¸€ç§ä»…åˆ©ç”¨å’³å—½éŸ³é¢‘å’ŒåŸºç¡€äººå£ç»Ÿè®¡æ•°æ®å³å¯å³æ—¶åˆ†é…ç»“æ ¸ç—…(TB)é£é™©è¯„åˆ†çš„éä¾µå…¥æ€§ç³»ç»Ÿã€‚è¯¥æ¨¡å‹ç»“åˆäº†ç”¨äºéŸ³é¢‘å¤„ç†çš„è½»é‡çº§ä¸€ç»´å·ç§¯ç¥ç»ç½‘ç»œ(1D CNN)å’Œå¤„ç†è¡¨æ ¼ç‰¹å¾çš„æ¢¯åº¦æå‡å†³ç­–æ ‘(GBDT)ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºäº¤å‰æ¨¡æ€åŒå‘äº¤å‰æ³¨æ„åŠ›æ¨¡å—(CM-BCA)ï¼Œè¯¥æ¨¡å—é€šè¿‡åœ¨æ¨¡æ€é—´è¿­ä»£äº¤æ¢æ˜¾è‘—çº¿ç´¢æ¥æ¨¡æ‹Ÿä¸´åºŠåŒ»ç”Ÿæ•´åˆç—‡çŠ¶ä¸é£é™©å› ç´ çš„è¿‡ç¨‹ã€‚ä¸ºäº†æ»¡è¶³æœ€å°åŒ–æ¼è¯Šçš„ä¸´åºŠéœ€æ±‚ï¼Œç ”ç©¶è®¾è®¡äº†ç»“æ ¸ç—…é£é™©å¹³è¡¡æŸå¤±(TRBL)ï¼Œé€šè¿‡åŠ å¤§å¯¹å‡é˜´æ€§é¢„æµ‹çš„æƒ©ç½šæ¥å‡å°‘é«˜é£é™©è¯¯è¯Šã€‚åœ¨åŒ…å«ä¸ƒä¸ªå›½å®¶1,105åæ‚£è€…çš„å¤šæ ·åŒ–æ•°æ®é›†ä¸Šï¼ŒDeepGB-TBå®ç°äº†0.903çš„AUROCå’Œ0.851çš„F1-scoreï¼Œåˆ›ä¸‹äº†æ–°çš„æŠ€æœ¯æ°´å¹³ã€‚æ­¤å¤–ï¼Œè¯¥ç³»ç»Ÿçš„è®¡ç®—æ•ˆç‡æ”¯æŒåœ¨æ™®é€šç§»åŠ¨è®¾å¤‡ä¸Šè¿›è¡Œå®æ—¶ç¦»çº¿æ¨ç†ï¼Œå¹¶èƒ½äº§ç”Ÿç»è¿‡ä¸´åºŠéªŒè¯çš„è§£é‡Šï¼Œéå¸¸é€‚åˆä½èµ„æºåœ°åŒºçš„å…¨çƒç»“æ ¸ç—…é˜²æ§å·¥ä½œã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.02741v1",
      "published_date": "2025-08-02 14:11:07 UTC",
      "updated_date": "2025-08-02 14:11:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:20:21.246064+00:00"
    },
    {
      "arxiv_id": "2508.01371v1",
      "title": "Prompt to Pwn: Automated Exploit Generation for Smart Contracts",
      "title_zh": "Prompt to Pwnï¼šé¢å‘æ™ºèƒ½åˆçº¦çš„è‡ªåŠ¨åŒ–æ¼æ´åˆ©ç”¨ç”Ÿæˆ",
      "authors": [
        "Zeke Xiao",
        "Yuekang Li",
        "Qin Wang",
        "Shiping Chen"
      ],
      "abstract": "We explore the feasibility of using LLMs for Automated Exploit Generation (AEG) against vulnerable smart contracts. We present \\textsc{ReX}, a framework integrating LLM-based exploit synthesis with the Foundry testing suite, enabling the automated generation and validation of proof-of-concept (PoC) exploits. We evaluate five state-of-the-art LLMs (GPT-4.1, Gemini 2.5 Pro, Claude Opus 4, DeepSeek, and Qwen3 Plus) on both synthetic benchmarks and real-world smart contracts affected by known high-impact exploits. Our results show that modern LLMs can reliably generate functional PoC exploits for diverse vulnerability types, with success rates reaching up to 92\\%. Notably, Gemini 2.5 Pro and GPT-4.1 consistently outperform others in both synthetic and real-world scenarios. We further analyze factors influencing AEG effectiveness, including model capabilities, contract structure, and vulnerability types. We also collect the first curated dataset of real-world PoC exploits to support future research.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(LLMs)é’ˆå¯¹å­˜åœ¨æ¼æ´çš„æ™ºèƒ½åˆçº¦è¿›è¡Œè‡ªåŠ¨åŒ–æ¼æ´åˆ©ç”¨ç”Ÿæˆ(Automated Exploit Generation, AEG)çš„å¯è¡Œæ€§ï¼Œå¹¶æå‡ºäº†åä¸ºReXçš„æ¡†æ¶ã€‚è¯¥æ¡†æ¶å°†åŸºäºLLMçš„æ¼æ´åˆ©ç”¨åˆæˆä¸Foundryæµ‹è¯•å¥—ä»¶é›†æˆï¼Œå®ç°äº†æ¼æ´åˆ©ç”¨è¯æ˜(PoC)çš„è‡ªåŠ¨åŒ–ç”Ÿæˆä¸éªŒè¯ã€‚ç ”ç©¶äººå‘˜åœ¨åˆæˆåŸºå‡†å’Œå—çœŸå®é«˜å½±å“æ¼æ´å½±å“çš„æ™ºèƒ½åˆçº¦ä¸Šè¯„ä¼°äº†GPT-4.1ã€Gemini 2.5 Proç­‰äº”ç§å…ˆè¿›æ¨¡å‹ï¼Œå®éªŒç»“æœæ˜¾ç¤ºç°ä»£æ¨¡å‹èƒ½å¯é åœ°ç”Ÿæˆé’ˆå¯¹å¤šç§æ¼æ´ç±»å‹çš„åŠŸèƒ½æ€§PoCï¼ŒæˆåŠŸç‡æœ€é«˜å¯è¾¾92%ã€‚å…¶ä¸­Gemini 2.5 Proå’ŒGPT-4.1åœ¨åˆæˆåŠçœŸå®åœºæ™¯ä¸­çš„æ€§èƒ½è¡¨ç°å‡ä¼˜äºå…¶ä»–æ¨¡å‹ã€‚æ­¤å¤–ï¼Œç ”ç©¶æ·±å…¥åˆ†æäº†å½±å“AEGæœ‰æ•ˆæ€§çš„å› ç´ ï¼Œå¹¶æ”¶é›†äº†é¦–ä¸ªç»è¿‡æ•´ç†çš„çœŸå®ä¸–ç•ŒPoCåˆ©ç”¨æ•°æ®é›†ï¼Œä¸ºæœªæ¥ç ”ç©¶æä¾›äº†é‡è¦èµ„æºã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.01371v1",
      "published_date": "2025-08-02 13:52:15 UTC",
      "updated_date": "2025-08-02 13:52:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:21:08.546970+00:00"
    },
    {
      "arxiv_id": "2508.01368v1",
      "title": "Relation-Aware LNN-Transformer for Intersection-Centric Next-Step Prediction",
      "title_zh": "é¢å‘ä»¥äº¤å‰å£ä¸ºä¸­å¿ƒçš„ä¸‹ä¸€æ­¥é¢„æµ‹çš„å…³ç³»æ„ŸçŸ¥ LNN-Transformer",
      "authors": [
        "Zhehong Ren",
        "Tianluo Zhang",
        "Yiheng Lu",
        "Yushen Liang",
        "Promethee Spathis"
      ],
      "abstract": "Next-step location prediction plays a pivotal role in modeling human mobility, underpinning applications from personalized navigation to strategic urban planning. However, approaches that assume a closed world - restricting choices to a predefined set of points of interest (POIs) - often fail to capture exploratory or target-agnostic behavior and the topological constraints of urban road networks. Hence, we introduce a road-node-centric framework that represents road-user trajectories on the city's road-intersection graph, thereby relaxing the closed-world constraint and supporting next-step forecasting beyond fixed POI sets. To encode environmental context, we introduce a sector-wise directional POI aggregation that produces compact features capturing distance, bearing, density and presence cues. By combining these cues with structural graph embeddings, we obtain semantically grounded node representations. For sequence modeling, we integrate a Relation-Aware LNN-Transformer - a hybrid of a Continuous-time Forgetting Cell CfC-LNN and a bearing-biased self-attention module - to capture both fine-grained temporal dynamics and long-range spatial dependencies. Evaluated on city-scale road-user trajectories, our model outperforms six state-of-the-art baselines by up to 17 percentage points in accuracy at one hop and 10 percentage points in MRR, and maintains high resilience under noise, losing only 2.4 percentage points in accuracy at one under 50 meter GPS perturbation and 8.9 percentage points in accuracy at one hop under 25 percent POI noise.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹äººç±»ç§»åŠ¨å»ºæ¨¡ä¸­ä¼ ç»Ÿé—­ç¯ç‚¹ä½(POI)é¢„æµ‹éš¾ä»¥æ•æ‰æ¢ç´¢æ€§è¡Œä¸ºå’ŒåŸå¸‚è·¯ç½‘æ‹“æ‰‘çº¦æŸçš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ä»¥è·¯å£èŠ‚ç‚¹(intersection)ä¸ºä¸­å¿ƒçš„æ–°å‹é¢„æµ‹æ¡†æ¶ã€‚è¯¥æ¡†æ¶é€šè¿‡åœ¨åŸå¸‚è·¯å£å›¾ä¸Šè¡¨ç¤ºç”¨æˆ·è½¨è¿¹ï¼Œæ‰“ç ´äº†å›ºå®šPOIé›†çš„é™åˆ¶ï¼Œå¹¶å¼•å…¥äº†æ‰‡åŒºå®šå‘POIèšåˆæŠ€æœ¯(sector-wise directional POI aggregation)æ¥æå–åŒ…å«è·ç¦»ã€æ–¹ä½å’Œå¯†åº¦ä¿¡æ¯çš„ç¯å¢ƒè¯­ä¹‰ç‰¹å¾ã€‚å…¶æ ¸å¿ƒæ¶æ„é›†æˆäº†å…³ç³»æ„ŸçŸ¥å‹LNN-Transformer (Relation-Aware LNN-Transformer)ï¼Œé€šè¿‡ç»“åˆè¿ç»­æ—¶é—´é—å¿˜å•å…ƒ(CfC-LNN)ä¸æ–¹ä½åç½®è‡ªæ³¨æ„åŠ›æ¨¡å—(bearing-biased self-attention)ï¼Œæœ‰æ•ˆæ•è·äº†ç»†ç²’åº¦çš„æ—¶é—´åŠ¨æ€å’Œé•¿ç¨‹ç©ºé—´ä¾èµ–ã€‚åœ¨åŸå¸‚è§„æ¨¡è½¨è¿¹æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨å•è·³å‡†ç¡®ç‡(accuracy at one hop)ä¸Šæ¯”ç°æœ‰åŸºçº¿æ¨¡å‹æå‡è¾¾17ä¸ªç™¾åˆ†ç‚¹ï¼Œåœ¨å¹³å‡å€’æ•°æ’å(MRR)ä¸Šæå‡10ä¸ªç™¾åˆ†ç‚¹ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹åœ¨é¢å¯¹GPSæ‰°åŠ¨å’ŒPOIå™ªå£°æ—¶è¡¨ç°å‡ºæå¼ºçš„é²æ£’æ€§ï¼Œä¸ºè¶…è¶Šå›ºå®šç‚¹ä½é™åˆ¶çš„ç§»åŠ¨é¢„æµ‹ä»»åŠ¡æä¾›äº†é«˜æ€§èƒ½ä¸”é«˜å¯é æ€§çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.01368v1",
      "published_date": "2025-08-02 13:47:12 UTC",
      "updated_date": "2025-08-02 13:47:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:21:26.040279+00:00"
    },
    {
      "arxiv_id": "2508.02740v1",
      "title": "Who Gets Cited? Gender- and Majority-Bias in LLM-Driven Reference Selection",
      "title_zh": "è°è·å¾—äº†å¼•ç”¨ï¼Ÿå¤§è¯­è¨€æ¨¡å‹é©±åŠ¨çš„å‚è€ƒæ–‡çŒ®é€‰æ‹©ä¸­çš„æ€§åˆ«åè§ä¸å¤šæ•°ç¾¤ä½“åè§",
      "authors": [
        "Jiangen He"
      ],
      "abstract": "Large language models (LLMs) are rapidly being adopted as research assistants, particularly for literature review and reference recommendation, yet little is known about whether they introduce demographic bias into citation workflows. This study systematically investigates gender bias in LLM-driven reference selection using controlled experiments with pseudonymous author names. We evaluate several LLMs (GPT-4o, GPT-4o-mini, Claude Sonnet, and Claude Haiku) by varying gender composition within candidate reference pools and analyzing selection patterns across fields. Our results reveal two forms of bias: a persistent preference for male-authored references and a majority-group bias that favors whichever gender is more prevalent in the candidate pool. These biases are amplified in larger candidate pools and only modestly attenuated by prompt-based mitigation strategies. Field-level analysis indicates that bias magnitude varies across scientific domains, with social sciences showing the least bias. Our findings indicate that LLMs can reinforce or exacerbate existing gender imbalances in scholarly recognition. Effective mitigation strategies are needed to avoid perpetuating existing gender disparities in scientific citation practices before integrating LLMs into high-stakes academic workflows.",
      "tldr_zh": "è¯¥ç ”ç©¶ç³»ç»Ÿæ€§åœ°è°ƒæŸ¥äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨æ–‡çŒ®å¼•ç”¨å»ºè®®è¿‡ç¨‹ä¸­æ˜¯å¦å­˜åœ¨äººå£ç»Ÿè®¡å­¦åè§ï¼Œé€šè¿‡å¯¹ GPT-4o, GPT-4o-mini, Claude Sonnet å’Œ Claude Haiku ç­‰æ¨¡å‹è¿›è¡Œå—æ§å®éªŒï¼Œåˆ†æäº†å®ƒä»¬åœ¨ä¸åŒæ€§åˆ«ç»„æˆä¸‹çš„å‚è€ƒæ–‡çŒ®é€‰æ‹©æ¨¡å¼ã€‚å®éªŒç»“æœæ­ç¤ºäº†ä¸¤ç§æ˜¾è‘—çš„åè§ï¼Œå³å¯¹ç”·æ€§ä½œè€…æ–‡çŒ®çš„æŒç»­åå¥½ï¼Œä»¥åŠå€¾å‘äºé€‰æ‹©å€™é€‰æ± ä¸­å å¤šæ•°æ€§åˆ«çš„å¤šæ•°ç¾¤ä½“åè§(majority-group bias)ã€‚ç ”ç©¶å‘ç°è¿™äº›åè§åœ¨å€™é€‰æ± è§„æ¨¡å¢å¤§æ—¶ä¼šè¢«æ”¾å¤§ï¼Œä¸”å³ä¾¿é‡‡ç”¨æç¤ºè¯ç¼“è§£ç­–ç•¥(prompt-based mitigation strategies)ä¹Ÿåªèƒ½äº§ç”Ÿæœ‰é™çš„æ”¹å–„æ•ˆæœã€‚å­¦ç§‘åˆ†ææ˜¾ç¤ºï¼Œä¸åŒç§‘å­¦é¢†åŸŸçš„åè§ç¨‹åº¦å­˜åœ¨å·®å¼‚ï¼Œå…¶ä¸­ç¤¾ä¼šç§‘å­¦é¢†åŸŸçš„åè§è¡¨ç°æœ€ä¸ºè½»å¾®ã€‚è¯¥ç ”ç©¶è­¦å‘Š LLMs å¯èƒ½ä¼šå¼ºåŒ–æˆ–åŠ å‰§å­¦æœ¯ç•Œç°æœ‰çš„æ€§åˆ«å¤±è¡¡ï¼Œå› æ­¤åœ¨å°†æ¨¡å‹å¤§è§„æ¨¡åº”ç”¨äºå­¦æœ¯å¼•ç”¨å·¥ä½œæµä¹‹å‰ï¼Œå¿…é¡»åˆ¶å®šå¹¶å®æ–½æœ‰æ•ˆçš„å¹²é¢„æªæ–½ä»¥åº”å¯¹æ€§åˆ«æ­§è§†é£é™©ã€‚",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.DL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.02740v1",
      "published_date": "2025-08-02 13:27:32 UTC",
      "updated_date": "2025-08-02 13:27:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:21:10.040253+00:00"
    },
    {
      "arxiv_id": "2508.02739v1",
      "title": "Kronos: A Foundation Model for the Language of Financial Markets",
      "title_zh": "Kronosï¼šé‡‘èå¸‚åœºè¯­è¨€åŸºç¡€æ¨¡å‹",
      "authors": [
        "Yu Shi",
        "Zongliang Fu",
        "Shuo Chen",
        "Bohan Zhao",
        "Wei Xu",
        "Changshui Zhang",
        "Jian Li"
      ],
      "abstract": "The success of large-scale pre-training paradigm, exemplified by Large Language Models (LLMs), has inspired the development of Time Series Foundation Models (TSFMs). However, their application to financial candlestick (K-line) data remains limited, often underperforming non-pre-trained architectures. Moreover, existing TSFMs often overlook crucial downstream tasks such as volatility prediction and synthetic data generation. To address these limitations, we propose Kronos, a unified, scalable pre-training framework tailored to financial K-line modeling. Kronos introduces a specialized tokenizer that discretizes continuous market information into token sequences, preserving both price dynamics and trade activity patterns. We pre-train Kronos using an autoregressive objective on a massive, multi-market corpus of over 12 billion K-line records from 45 global exchanges, enabling it to learn nuanced temporal and cross-asset representations. Kronos excels in a zero-shot setting across a diverse set of financial tasks. On benchmark datasets, Kronos boosts price series forecasting RankIC by 93% over the leading TSFM and 87% over the best non-pre-trained baseline. It also achieves a 9% lower MAE in volatility forecasting and a 22% improvement in generative fidelity for synthetic K-line sequences. These results establish Kronos as a robust, versatile foundation model for end-to-end financial time series analysis. Our pre-trained model is publicly available at https://github.com/shiyu-coder/Kronos.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Kronosï¼Œä¸€ä¸ªä¸“é—¨é’ˆå¯¹é‡‘è K-line æ•°æ®å»ºæ¨¡çš„ç»Ÿä¸€ä¸”å¯æ‰©å±•çš„é¢„è®­ç»ƒæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰ Time Series Foundation Models (TSFMs) åœ¨é‡‘èå¸‚åœºåº”ç”¨ä¸­è¡¨ç°ä¸ä½³ä»¥åŠå¿½è§†æ³¢åŠ¨ç‡é¢„æµ‹ç­‰å…³é”®ä»»åŠ¡çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†ä¸€ç§ä¸“é—¨çš„åˆ†è¯å™¨ (tokenizer)ï¼Œå°†è¿ç»­çš„å¸‚åœºä¿¡æ¯ç¦»æ•£åŒ–ä¸º Token åºåˆ—ï¼Œä»è€Œå®Œæ•´ä¿ç•™ä»·æ ¼åŠ¨æ€å’Œäº¤æ˜“æ´»åŠ¨æ¨¡å¼ã€‚Kronos åœ¨åŒ…å«å…¨çƒ 45 ä¸ªäº¤æ˜“æ‰€ã€è¶…è¿‡ 120 äº¿æ¡ K-line è®°å½•çš„å¤§è§„æ¨¡è¯­æ–™åº“ä¸Šåˆ©ç”¨è‡ªå›å½’ (autoregressive) ç›®æ ‡è¿›è¡Œé¢„è®­ç»ƒï¼Œä½¿å…¶èƒ½å¤Ÿæ•æ‰æ·±å±‚çš„æ—¶é—´å’Œè·¨èµ„äº§è¡¨å¾ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒKronos åœ¨é›¶æ ·æœ¬ (zero-shot) åœºæ™¯ä¸‹çš„å¤šé¡¹é‡‘èä»»åŠ¡ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œå…¶ä»·æ ¼é¢„æµ‹ RankIC è¾ƒé¢†å…ˆ TSFM æå‡äº† 93%ï¼Œæ³¢åŠ¨ç‡é¢„æµ‹çš„ MAE é™ä½äº† 9%ï¼Œä¸”åˆæˆåºåˆ—çš„ç”Ÿæˆä¿çœŸåº¦æé«˜äº† 22%ã€‚è¿™äº›æˆæœç¡®ç«‹äº† Kronos ä½œä¸ºé‡‘èæ—¶é—´åºåˆ—åˆ†æé¢†åŸŸé²æ£’ä¸”é€šç”¨çš„åŸºç¡€æ¨¡å‹åœ°ä½ï¼Œä¸ºå®ç°ç«¯åˆ°ç«¯çš„é‡‘èæ™ºèƒ½æä¾›äº†æœ‰åŠ›æ”¯æ’‘ã€‚",
      "categories": [
        "q-fin.ST",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-fin.ST",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.02739v1",
      "published_date": "2025-08-02 13:15:59 UTC",
      "updated_date": "2025-08-02 13:15:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:21:03.322628+00:00"
    },
    {
      "arxiv_id": "2508.01350v1",
      "title": "Classification of Brain Tumors using Hybrid Deep Learning Models",
      "title_zh": "åŸºäºæ··åˆæ·±åº¦å­¦ä¹ æ¨¡å‹çš„è„‘è‚¿ç˜¤åˆ†ç±»",
      "authors": [
        "Neerav Nemchand Gala"
      ],
      "abstract": "The use of Convolutional Neural Networks (CNNs) has greatly improved the interpretation of medical images. However, conventional CNNs typically demand extensive computational resources and large training datasets. To address these limitations, this study applied transfer learning to achieve strong classification performance using fewer training samples. Specifically, the study compared EfficientNetV2 with its predecessor, EfficientNet, and with ResNet50 in classifying brain tumors into three types: glioma, meningioma, and pituitary tumors. Results showed that EfficientNetV2 delivered superior performance compared to the other models. However, this improvement came at the cost of increased training time, likely due to the model's greater complexity.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é’ˆå¯¹ä¼ ç»Ÿå·ç§¯ç¥ç»ç½‘ç»œ (Convolutional Neural Networks, CNNs) åœ¨åŒ»å­¦å›¾åƒè§£é‡Šä¸­å¯¹è®¡ç®—èµ„æºå’Œå¤§è§„æ¨¡è®­ç»ƒæ•°æ®é›†çš„é«˜éœ€æ±‚é—®é¢˜ï¼Œæ¢ç´¢äº†åˆ©ç”¨è¿ç§»å­¦ä¹  (transfer learning) å®ç°é«˜æ•ˆè„‘è‚¿ç˜¤åˆ†ç±»çš„æ–¹æ³•ã€‚ç ”ç©¶å¯¹æ¯”äº† EfficientNetV2ã€å…¶å‰ä»£æ¨¡å‹ EfficientNet ä»¥åŠ ResNet50 åœ¨èƒ¶è´¨ç˜¤ (glioma)ã€è„‘è†œç˜¤ (meningioma) å’Œå‚ä½“ç˜¤ (pituitary tumors) ä¸‰ç±»è„‘è‚¿ç˜¤åˆ†ç±»ä»»åŠ¡ä¸­çš„è¡¨ç°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒEfficientNetV2 åœ¨åˆ†ç±»æ€§èƒ½ä¸Šæ˜¾è‘—ä¼˜äºå…¶ä»–å¯¹æ¯”æ¨¡å‹ï¼Œå±•ç°å‡ºæ›´å¼ºçš„ç‰¹å¾æå–å’Œåˆ†ç±»èƒ½åŠ›ã€‚è™½ç„¶æ€§èƒ½è¡¨ç°ä¼˜å¼‚ï¼Œä½†ç”±äº EfficientNetV2 æ¨¡å‹çš„å¤æ‚åº¦æ›´é«˜ï¼Œå…¶è®­ç»ƒæ—¶é—´ä¹Ÿéšä¹‹å¢åŠ ã€‚è¯¥ç ”ç©¶è¯æ˜äº†é€šè¿‡è¿ç§»å­¦ä¹ å’Œå…ˆè¿›æ¨¡å‹æ¶æ„ï¼Œå¯ä»¥åœ¨è¾ƒå°‘è®­ç»ƒæ ·æœ¬çš„æƒ…å†µä¸‹å®ç°é«˜ç²¾åº¦çš„è„‘è‚¿ç˜¤åˆ†ç±»ï¼Œä¸ºä¸´åºŠåŒ»ç–—å½±åƒè¾…åŠ©è¯Šæ–­æä¾›äº†æœ‰æ•ˆçš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "6 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.01350v1",
      "published_date": "2025-08-02 12:56:18 UTC",
      "updated_date": "2025-08-02 12:56:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:21:03.146753+00:00"
    },
    {
      "arxiv_id": "2508.01348v2",
      "title": "Convergence Analysis of Aggregation-Broadcast in LoRA-enabled Distributed Fine-Tuning",
      "title_zh": "LoRA èµ‹èƒ½åˆ†å¸ƒå¼å¾®è°ƒä¸­èšåˆ-å¹¿æ’­æœºåˆ¶çš„æ”¶æ•›æ€§åˆ†æ",
      "authors": [
        "Xin Chen",
        "Shuaijun Chen",
        "Omid Tavallaie",
        "Nguyen Tran",
        "Shuhuang Xiang",
        "Albert Zomaya"
      ],
      "abstract": "Federated Learning (FL) enables collaborative model training across decentralized data sources while preserving data privacy. However, the growing size of Machine Learning (ML) models poses communication and computation challenges in FL. Low-Rank Adaptation (LoRA) has recently been introduced into FL as an efficient fine-tuning method, reducing communication overhead by updating only a small number of trainable parameters. Despite its effectiveness, how to aggregate LoRA-updated local models on the server remains a critical and understudied problem. In this paper, we provide a unified convergence analysis for LoRA-based FL. We first categories the current aggregation method into two major type: Sum-Product (SP) and Product-Sum (PS). Then we formally define the Aggregation-Broadcast Operator (ABO) and derive both weak and strong convergence condition under mild assumptions. Furthermore, we present both weak and strong convergence condition that guarantee convergence of the local model and the global model respectively. These theoretical analyze offer a principled understanding of various aggregation strategies. Notably, we prove that the SP and PS aggregation methods satisfy the weak and strong convergence condition respectively, but differ in their ability to achieve the optimal convergence rate. Extensive experiments on standard benchmarks validate our theoretical findings.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹LoRA-enabled Distributed Fine-Tuningä¸­æœ¬åœ°æ›´æ–°æ¨¡å‹åœ¨æœåŠ¡å™¨ç«¯å¦‚ä½•èšåˆè¿™ä¸€å…³é”®ä¸”ç ”ç©¶ä¸è¶³çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€å¥—ç»Ÿä¸€çš„æ”¶æ•›æ€§åˆ†ææ¡†æ¶ã€‚ä½œè€…å°†ç°æœ‰çš„èšåˆæ–¹æ³•å½’çº³ä¸ºSum-Product (SP)å’ŒProduct-Sum (PS)ä¸¤å¤§ç±»ï¼Œå¹¶æ­£å¼å®šä¹‰äº†Aggregation-Broadcast Operator (ABO)ä»¥æ¨å¯¼åœ¨ä¸åŒå‡è®¾ä¸‹çš„å¼±æ”¶æ•›ä¸å¼ºæ”¶æ•›æ¡ä»¶ã€‚ç†è®ºè¯æ˜æ˜¾ç¤ºï¼ŒSPå’ŒPSæ–¹æ³•åˆ†åˆ«æ»¡è¶³å¼±æ”¶æ•›å’Œå¼ºæ”¶æ•›è¦æ±‚ï¼Œä½†åœ¨å®ç°æœ€ä¼˜æ”¶æ•›é€Ÿç‡æ–¹é¢è¡¨ç°å„å¼‚ã€‚é€šè¿‡åœ¨æ ‡å‡†åŸºå‡†ä¸Šè¿›è¡Œçš„å¤§é‡å®éªŒï¼Œè¯¥ç ”ç©¶éªŒè¯äº†ç†è®ºåˆ†æçš„æœ‰æ•ˆæ€§ï¼Œä¸ºFederated Learningä¸­å„ç§èšåˆç­–ç•¥çš„ç†è§£ä¸åº”ç”¨æä¾›äº†é‡è¦çš„ç†è®ºæ”¯æ’‘ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.01348v2",
      "published_date": "2025-08-02 12:54:17 UTC",
      "updated_date": "2025-08-30 12:43:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:21:13.759957+00:00"
    },
    {
      "arxiv_id": "2508.01343v2",
      "title": "UEChecker: Detecting Unchecked External Call Vulnerabilities in DApps via Graph Analysis",
      "title_zh": "UECheckerï¼šåŸºäºå›¾åˆ†æçš„ DApp æœªæ£€æŸ¥å¤–éƒ¨è°ƒç”¨æ¼æ´æ£€æµ‹",
      "authors": [
        "Dechao Kong",
        "Xiaoqi Li",
        "Wenkai Li"
      ],
      "abstract": "The increasing number of attacks on the contract layer of DApps has resulted in economic losses amounting to $66 billion. Vulnerabilities arise when contracts interact with external protocols without verifying the results of the calls, leading to exploit entry points such as flash loan attacks and reentrancy attacks. In this paper, we propose UEChecker, a deep learning-based tool that utilizes a call graph and a Graph Convolutional Network to detect unchecked external call vulnerabilities. We design the following components: An edge prediction module that reconstructs the feature representation of nodes and edges in the call graph; A node aggregation module that captures structural information from both the node itself and its neighbors, thereby enhancing feature representation between nodes and improving the model's understanding of the global graph structure; A Conformer Block module that integrates multi-head attention, convolutional modules, and feedforward neural networks to more effectively capture dependencies of different scales within the call graph, extending beyond immediate neighbors and enhancing the performance of vulnerability detection. Finally, we combine these modules with Graph Convolutional Network to detect unchecked external call vulnerabilities. By auditing the smart contracts of 608 DApps, our results show that our tool achieves an accuracy of 87.59% in detecting unchecked external call vulnerabilities. Furthermore, we compare our tool with GAT, LSTM, and GCN baselines, and in the comparison experiments, UEChecker consistently outperforms these models in terms of accuracy.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å»ä¸­å¿ƒåŒ–åº”ç”¨ (DApps) ä¸­å› æœªéªŒè¯å¤–éƒ¨è°ƒç”¨ç»“æœè€Œå¯¼è‡´çš„ç»æµæŸå¤±é—®é¢˜ï¼Œæå‡ºäº†åŸºäºæ·±åº¦å­¦ä¹ çš„æ¼æ´æ£€æµ‹å·¥å…· UECheckerï¼Œæ—¨åœ¨è¯†åˆ«å¼•å‘é—ªç”µè´· (flash loan) å’Œé‡å…¥æ”»å‡» (reentrancy attacks) çš„å®‰å…¨éšæ‚£ã€‚è¯¥å·¥å…·åˆ©ç”¨è°ƒç”¨å›¾ (call graph) å’Œå›¾å·ç§¯ç½‘ç»œ (Graph Convolutional Network) è¿›è¡Œå»ºæ¨¡ï¼Œå¹¶è®¾è®¡äº†è¾¹é¢„æµ‹æ¨¡å—ä¸èŠ‚ç‚¹èšåˆæ¨¡å—ä»¥å¢å¼ºç‰¹å¾è¡¨ç¤ºå’Œå¯¹å…¨å±€å›¾ç»“æ„çš„ç†è§£ã€‚é€šè¿‡å¼•å…¥ç»“åˆå¤šå¤´æ³¨æ„åŠ›æœºåˆ¶ä¸å·ç§¯æ¨¡å—çš„ Conformer Blockï¼ŒUEChecker èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°æ•æ‰è°ƒç”¨å›¾ä¸­è·¨è¶Šä¸åŒå°ºåº¦çš„å¤æ‚ä¾èµ–å…³ç³»ã€‚å¯¹ 608 ä¸ª DApps æ™ºèƒ½åˆçº¦çš„å®¡è®¡ç»“æœæ˜¾ç¤ºï¼Œè¯¥å·¥å…·åœ¨æ£€æµ‹æœªéªŒè¯å¤–éƒ¨è°ƒç”¨æ¼æ´æ–¹é¢è¾¾åˆ°äº† 87.59% çš„å‡†ç¡®ç‡ã€‚å¯¹æ¯”å®éªŒè¿›ä¸€æ­¥è¯æ˜ï¼ŒUEChecker çš„æ€§èƒ½å§‹ç»ˆä¼˜äº GATã€LSTM å’Œä¼ ç»Ÿ GCN ç­‰åŸºå‡†æ¨¡å‹ï¼Œæ˜¾è‘—æå‡äº†æ™ºèƒ½åˆçº¦å±‚é¢çš„æ¼æ´æ£€æµ‹æ•ˆç‡ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.01343v2",
      "published_date": "2025-08-02 12:40:17 UTC",
      "updated_date": "2026-01-15 14:45:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:21:25.688726+00:00"
    },
    {
      "arxiv_id": "2508.01339v4",
      "title": "SBP-YOLO:A Lightweight Real-Time Model for Detecting Speed Bumps and Potholes toward Intelligent Vehicle Suspension Systems",
      "title_zh": "SBP-YOLOï¼šä¸€ç§é¢å‘æ™ºèƒ½è½¦è¾†æ‚¬æ¶ç³»ç»Ÿçš„è½»é‡çº§å®æ—¶å‡é€Ÿå¸¦ä¸å‘æ´¼æ£€æµ‹æ¨¡å‹",
      "authors": [
        "Chuanqi Liang",
        "Jie Fu",
        "Miao Yu",
        "Lei Luo"
      ],
      "abstract": "Speed bumps and potholes are the most common road anomalies, significantly affecting ride comfort and vehicle stability. Preview-based suspension control mitigates their impact by detecting such irregularities in advance and adjusting suspension parameters proactively. Accurate and real-time detection is essential, but embedded deployment is constrained by limited computational resources and the small size of targets in input images.To address these challenges, this paper proposes SBP-YOLO, an efficient detection framework for speed bumps and potholes in embedded systems. Built upon YOLOv11n, it integrates GhostConv and VoVGSCSPC modules in the backbone and neck to reduce computation while enhancing multi-scale semantic features. A P2-level branch improves small-object detection, and a lightweight and efficient detection head (LEDH) maintains accuracy with minimal overhead. A hybrid training strategy further enhances robustness under varying road and environmental conditions, combining NWD loss, BCKD knowledge distillation, and Albumentations-based augmentation. Experiments show that SBP-YOLO achieves 87.0% mAP, outperforming the YOLOv11n baseline by 5.8%. After TensorRT FP16 quantization, it runs at 139.5 FPS on Jetson AGX Xavier, yielding a 12.4% speedup over the P2-enhanced YOLOv11. These results demonstrate the framework's suitability for fast, low-latency road condition perception in embedded suspension control systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†SBP-YOLOï¼Œè¿™æ˜¯ä¸€ç§é’ˆå¯¹åµŒå…¥å¼ç³»ç»Ÿè®¾è®¡çš„é«˜æ•ˆå‡é€Ÿå¸¦å’Œå‘æ´¼æ£€æµ‹æ¡†æ¶ï¼Œæ—¨åœ¨æå‡æ™ºèƒ½è½¦è¾†æ‚¬æ¶ç³»ç»Ÿçš„è·¯é¢æ„ŸçŸ¥èƒ½åŠ›ã€‚è¯¥æ¨¡å‹ä»¥YOLOv11nä¸ºåŸºç¡€ï¼Œåœ¨éª¨å¹²ç½‘ç»œå’Œé¢ˆéƒ¨é›†æˆäº†GhostConvå’ŒVoVGSCSPCæ¨¡å—ä»¥å‡å°‘è®¡ç®—é‡å¹¶å¢å¼ºå¤šå°ºåº¦è¯­ä¹‰ç‰¹å¾ã€‚ä¸ºäº†åº”å¯¹è·¯é¢ç›®æ ‡è¾ƒå°ä¸”èµ„æºå—é™çš„æŒ‘æˆ˜ï¼Œç ”ç©¶å¼•å…¥äº†P2-levelåˆ†æ”¯å’Œè½»é‡çº§é«˜æ•ˆæ£€æµ‹å¤´ï¼ˆLEDHï¼‰ï¼Œå¹¶åœ¨è®­ç»ƒä¸­ç»“åˆäº†NWD lossã€BCKDçŸ¥è¯†è’¸é¦å’ŒAlbumentationså¢å¼ºã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSBP-YOLOè¾¾åˆ°äº†87.0%çš„mAPï¼Œæ¯”YOLOv11nåŸºå‡†æ¨¡å‹æé«˜äº†5.8%ã€‚åœ¨Jetson AGX Xavierå¹³å°ä¸Šç»TensorRT FP16é‡åŒ–åï¼Œè¯¥æ¨¡å‹è¿è¡Œé€Ÿåº¦è¾¾åˆ°139.5 FPSï¼Œæ¯”P2å¢å¼ºç‰ˆçš„YOLOv11æé€Ÿ12.4%ã€‚è¯¥ç ”ç©¶æˆæœä¸ºåµŒå…¥å¼æ‚¬æ¶æ§åˆ¶ç³»ç»Ÿæä¾›äº†ä¸€ç§å¿«é€Ÿã€å‡†ç¡®ä¸”ä½å»¶è¿Ÿçš„è·¯å†µæ„ŸçŸ¥æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "14pages,11figures",
      "pdf_url": "https://arxiv.org/pdf/2508.01339v4",
      "published_date": "2025-08-02 12:15:08 UTC",
      "updated_date": "2025-10-07 01:16:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:21:37.251476+00:00"
    },
    {
      "arxiv_id": "2508.01338v1",
      "title": "Weakly-Supervised Image Forgery Localization via Vision-Language Collaborative Reasoning Framework",
      "title_zh": "åŸºäºè§†è§‰-è¯­è¨€åä½œæ¨ç†æ¡†æ¶çš„å¼±ç›‘ç£å›¾åƒç¯¡æ”¹å®šä½",
      "authors": [
        "Ziqi Sheng",
        "Junyan Wu",
        "Wei Lu",
        "Jiantao Zhou"
      ],
      "abstract": "Image forgery localization aims to precisely identify tampered regions within images, but it commonly depends on costly pixel-level annotations. To alleviate this annotation burden, weakly supervised image forgery localization (WSIFL) has emerged, yet existing methods still achieve limited localization performance as they mainly exploit intra-image consistency clues and lack external semantic guidance to compensate for weak supervision. In this paper, we propose ViLaCo, a vision-language collaborative reasoning framework that introduces auxiliary semantic supervision distilled from pre-trained vision-language models (VLMs), enabling accurate pixel-level localization using only image-level labels. Specifically, ViLaCo first incorporates semantic knowledge through a vision-language feature modeling network, which jointly extracts textual and visual priors using pre-trained VLMs. Next, an adaptive vision-language reasoning network aligns textual semantics and visual features through mutual interactions, producing semantically aligned representations. Subsequently, these representations are passed into dual prediction heads, where the coarse head performs image-level classification and the fine head generates pixel-level localization masks, thereby bridging the gap between weak supervision and fine-grained localization. Moreover, a contrastive patch consistency module is introduced to cluster tampered features while separating authentic ones, facilitating more reliable forgery discrimination. Extensive experiments on multiple public datasets demonstrate that ViLaCo substantially outperforms existing WSIFL methods, achieving state-of-the-art performance in both detection and localization accuracy.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ViLaCoï¼Œä¸€ä¸ªæ—¨åœ¨é€šè¿‡ä»…ä½¿ç”¨å›¾åƒçº§æ ‡ç­¾å®ç°ç²¾ç¡®åƒç´ çº§å®šä½çš„è§†è§‰è¯­è¨€åä½œæ¨ç†æ¡†æ¶ï¼Œä»¥è§£å†³å¼±ç›‘ç£å›¾åƒä¼ªé€ å®šä½(WSIFL)ä¸­ç¼ºä¹å¤–éƒ¨è¯­ä¹‰å¼•å¯¼å’Œåƒç´ çº§æ ‡æ³¨æˆæœ¬é«˜æ˜‚çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶é€šè¿‡è§†è§‰è¯­è¨€ç‰¹å¾å»ºæ¨¡ç½‘ç»œä»é¢„è®­ç»ƒè§†è§‰è¯­è¨€æ¨¡å‹(VLMs)ä¸­æå–è¾…åŠ©è¯­ä¹‰ç›‘ç£ï¼Œå¹¶åˆ©ç”¨è‡ªé€‚åº”æ¨ç†ç½‘ç»œå®ç°æ–‡æœ¬è¯­ä¹‰ä¸è§†è§‰ç‰¹å¾çš„æ·±åº¦å¯¹é½ä¸äº¤äº’ã€‚ç³»ç»Ÿé‡‡ç”¨åŒé¢„æµ‹å¤´æœºåˆ¶ï¼Œé€šè¿‡å›¾åƒçº§åˆ†ç±»ä¸åƒç´ çº§å®šä½æ©ç çš„ç»“åˆï¼Œæœ‰æ•ˆå¼¥è¡¥äº†å¼±ç›‘ç£ä¿¡å·ä¸ç»†ç²’åº¦å®šä½ä»»åŠ¡ä¹‹é—´çš„å·®è·ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜å¼•å…¥äº†å¯¹æ¯”è¡¥ä¸ä¸€è‡´æ€§(Contrastive Patch Consistency)æ¨¡å—æ¥èšç±»ä¼ªé€ ç‰¹å¾å¹¶åˆ†ç¦»çœŸå®ç‰¹å¾ï¼Œä»è€Œæå‡é‰´åˆ«çš„å¯é æ€§ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒViLaCoåœ¨å¤šä¸ªå…¬å¼€æ•°æ®é›†ä¸Šå‡å–å¾—äº†SOTAæ€§èƒ½ï¼Œåœ¨æ£€æµ‹å’Œå®šä½å‡†ç¡®åº¦ä¸Šæ˜¾è‘—è¶…è¶Šäº†ç°æœ‰çš„WSIFLæ–¹æ³•ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.01338v1",
      "published_date": "2025-08-02 12:14:29 UTC",
      "updated_date": "2025-08-02 12:14:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:21:50.030159+00:00"
    },
    {
      "arxiv_id": "2508.01332v3",
      "title": "BlockA2A: Towards Secure and Verifiable Agent-to-Agent Interoperability",
      "title_zh": "BlockA2Aï¼šè¿ˆå‘å®‰å…¨ä¸”å¯éªŒè¯çš„æ™ºèƒ½ä½“é—´äº’æ“ä½œæ€§",
      "authors": [
        "Zhenhua Zou",
        "Zhuotao Liu",
        "Lepeng Zhao",
        "Qiuyang Zhan"
      ],
      "abstract": "The rapid adoption of agentic AI, powered by large language models (LLMs), is transforming enterprise ecosystems with autonomous agents that execute complex workflows. Yet we observe several key security vulnerabilities in LLM-driven multi-agent systems (MASes): fragmented identity frameworks, insecure communication channels, and inadequate defenses against Byzantine agents or adversarial prompts. In this paper, we present the first systematic analysis of these emerging multi-agent risks and explain why the legacy security strategies cannot effectively address these risks. Afterwards, we propose BlockA2A, the first unified multi-agent trust framework that enables secure and verifiable and agent-to-agent interoperability. At a high level, BlockA2A adopts decentralized identifiers (DIDs) to enable fine-grained cross-domain agent authentication, blockchain-anchored ledgers to enable immutable auditability, and smart contracts to dynamically enforce context-aware access control policies. BlockA2A eliminates centralized trust bottlenecks, ensures message authenticity and execution integrity, and guarantees accountability across agent interactions. Furthermore, we propose a Defense Orchestration Engine (DOE) that actively neutralizes attacks through real-time mechanisms, including Byzantine agent flagging, reactive execution halting, and instant permission revocation. Empirical evaluations demonstrate BlockA2A's effectiveness in neutralizing prompt-based, communication-based, behavioral and systemic MAS attacks. We formalize its integration into existing MAS and showcase a practical implementation for Google's A2A protocol. Experiments confirm that BlockA2A and DOE operate with sub-second overhead, enabling scalable deployment in production LLM-based MAS environments.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç”±å¤§è¯­è¨€æ¨¡å‹(LLMs)é©±åŠ¨çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ(MASes)ä¸­å­˜åœ¨çš„èº«ä»½æ¡†æ¶ç ´ç¢ã€é€šä¿¡é€šé“ä¸å®‰å…¨ä»¥åŠéš¾ä»¥é˜²å¾¡æ‹œå åº­æ™ºèƒ½ä½“(Byzantine agents)æˆ–å¯¹æŠ—æ€§æç¤ºç­‰å®‰å…¨æ¼æ´è¿›è¡Œäº†ç³»ç»Ÿåˆ†æã€‚ä¸ºåº”å¯¹è¿™äº›æŒ‘æˆ˜ï¼Œè®ºæ–‡æå‡ºäº†BlockA2Aï¼Œè¿™æ˜¯é¦–ä¸ªæ—¨åœ¨å®ç°å®‰å…¨ä¸”å¯éªŒè¯çš„æ™ºèƒ½ä½“é—´äº’æ“ä½œæ€§(agent-to-agent interoperability)çš„ç»Ÿä¸€ä¿¡ä»»æ¡†æ¶ã€‚BlockA2A é‡‡ç”¨å»ä¸­å¿ƒåŒ–æ ‡è¯†ç¬¦(DIDs)å®ç°ç»†ç²’åº¦çš„è·¨åŸŸèº«ä»½éªŒè¯ï¼Œåˆ©ç”¨åŒºå—é“¾è´¦æœ¬ç¡®ä¿ä¸å¯ç¯¡æ”¹çš„å¯å®¡è®¡æ€§ï¼Œå¹¶é€šè¿‡æ™ºèƒ½åˆçº¦åŠ¨æ€æ‰§è¡Œä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„è®¿é—®æ§åˆ¶ç­–ç•¥ã€‚æ­¤å¤–ï¼Œç ”ç©¶å¼•å…¥äº†é˜²å¾¡ç¼–æ’å¼•æ“(Defense Orchestration Engine, DOE)ï¼Œé€šè¿‡æ‹œå åº­æ ‡è®°å’Œå³æ—¶æƒé™æ’¤é”€ç­‰æœºåˆ¶å®æ—¶ä¸­å’Œæ”»å‡»ã€‚å®éªŒè¯„ä¼°è¯æ˜äº†è¯¥æ¡†æ¶åœ¨å¯¹æŠ—å¤šç§ MAS æ”»å‡»æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œå¹¶æˆåŠŸåœ¨ Google çš„ A2A åè®®ä¸­è¿›è¡Œäº†å®è·µéƒ¨ç½²ã€‚æµ‹è¯•ç»“æœç¡®è®¤ BlockA2A ä¸ DOE çš„è¿è¡Œå¼€é”€ä¿æŒåœ¨äºšç§’çº§ï¼Œä¸ºç”Ÿäº§ç¯å¢ƒä¸‹çš„å¤§è§„æ¨¡ LLM-based MAS éƒ¨ç½²æä¾›äº†å¯æ‰©å±•ä¸”é«˜å®Œæ•´æ€§çš„å®‰å…¨ä¿éšœã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "43 pages",
      "pdf_url": "https://arxiv.org/pdf/2508.01332v3",
      "published_date": "2025-08-02 11:59:21 UTC",
      "updated_date": "2025-09-21 03:31:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:21:53.257093+00:00"
    },
    {
      "arxiv_id": "2508.01331v1",
      "title": "Referring Remote Sensing Image Segmentation with Cross-view Semantics Interaction Network",
      "title_zh": "åŸºäºè·¨è§†è§’è¯­ä¹‰äº¤äº’ç½‘ç»œçš„æŒ‡ä»£æ€§é¥æ„Ÿå›¾åƒåˆ†å‰²",
      "authors": [
        "Jiaxing Yang",
        "Lihe Zhang",
        "Huchuan Lu"
      ],
      "abstract": "Recently, Referring Remote Sensing Image Segmentation (RRSIS) has aroused wide attention. To handle drastic scale variation of remote targets, existing methods only use the full image as input and nest the saliency-preferring techniques of cross-scale information interaction into traditional single-view structure. Although effective for visually salient targets, they still struggle in handling tiny, ambiguous ones in lots of real scenarios. In this work, we instead propose a paralleled yet unified segmentation framework Cross-view Semantics Interaction Network (CSINet) to solve the limitations. Motivated by human behavior in observing targets of interest, the network orchestrates visual cues from remote and close distances to conduct synergistic prediction. In its every encoding stage, a Cross-View Window-attention module (CVWin) is utilized to supplement global and local semantics into close-view and remote-view branch features, finally promoting the unified representation of feature in every encoding stage. In addition, we develop a Collaboratively Dilated Attention enhanced Decoder (CDAD) to mine the orientation property of target and meanwhile integrate cross-view multiscale features. The proposed network seamlessly enhances the exploitation of global and local semantics, achieving significant improvements over others while maintaining satisfactory speed.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æŒ‡ä»£é¥æ„Ÿå›¾åƒåˆ†å‰²(Referring Remote Sensing Image Segmentation, RRSIS)ä¸­ç”±äºç›®æ ‡å°ºåº¦å‰§çƒˆå˜åŒ–å¯¼è‡´çš„å°ç›®æ ‡åŠæ¨¡ç³Šç›®æ ‡è¯†åˆ«éš¾é¢˜ï¼Œæå‡ºäº†ä¸€ç§è·¨è§†å›¾è¯­ä¹‰äº¤äº’ç½‘ç»œ(Cross-view Semantics Interaction Network, CSINet)ã€‚è¯¥æ¡†æ¶æ¨¡æ‹Ÿäººç±»è§‚å¯Ÿç›®æ ‡çš„è¡Œä¸ºï¼Œé€šè¿‡å¹¶è¡Œç»“æ„ååŒå¤„ç†è¿œè¿‘ä¸åŒè·ç¦»çš„è§†è§‰çº¿ç´¢ã€‚åœ¨ç¼–ç é˜¶æ®µï¼Œç½‘ç»œé‡‡ç”¨è·¨è§†å›¾çª—å£æ³¨æ„åŠ›æ¨¡å—(Cross-View Window-attention module, CVWin)å°†å…¨å±€ä¸å±€éƒ¨è¯­ä¹‰èå…¥åŒåˆ†æ”¯ç‰¹å¾ï¼Œå®ç°äº†ç‰¹å¾çš„ç»Ÿä¸€è¡¨ç¤ºã€‚æ­¤å¤–ï¼Œç ”ç©¶å¼•å…¥äº†ååŒç©ºæ´æ³¨æ„åŠ›å¢å¼ºè§£ç å™¨(Collaboratively Dilated Attention enhanced Decoder, CDAD)ä»¥æŒ–æ˜ç›®æ ‡æ–¹ä½å±æ€§å¹¶æ•´åˆè·¨è§†å›¾å¤šå°ºåº¦ä¿¡æ¯ã€‚å®éªŒè¯æ˜ï¼ŒCSINetåœ¨ä¿æŒé«˜æ•ˆè¿è¡Œé€Ÿåº¦çš„åŒæ—¶ï¼Œæ˜¾è‘—æå‡äº†é¥æ„Ÿå›¾åƒåˆ†å‰²çš„å‡†ç¡®æ€§ï¼Œå…‹æœäº†ä¼ ç»Ÿå•è§†å›¾ç»“æ„åœ¨å¤„ç†å¤æ‚åœºæ™¯æ—¶çš„å±€é™æ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.01331v1",
      "published_date": "2025-08-02 11:57:56 UTC",
      "updated_date": "2025-08-02 11:57:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:21:53.929130+00:00"
    },
    {
      "arxiv_id": "2508.01330v2",
      "title": "NatureGAIA: Pushing the Frontiers of GUI Agents with a Challenging Benchmark and High-Quality Trajectory Dataset",
      "title_zh": "NatureGAIAï¼šé€šè¿‡æŒ‘æˆ˜æ€§åŸºå‡†æµ‹è¯•ä¸é«˜è´¨é‡è½¨è¿¹æ•°æ®é›†æ‹“å±• GUI æ™ºèƒ½ä½“å‰æ²¿",
      "authors": [
        "Zihan Zheng",
        "Tianle Cui",
        "Chuwen Xie",
        "Jiahui Zhang",
        "Jiahui Pan",
        "Lewei He",
        "Qianglong Chen"
      ],
      "abstract": "The rapid advancement of Large Language Model (LLM)-driven Graphical User Interface (GUI) agents is significantly hampered by the profound limitations of existing evaluation benchmarks in terms of accuracy, reproducibility, and scalability. To address this critical gap, we introduce NaturalGAIA, a novel benchmark engineered on the principle of Causal Pathways. This design paradigm structures complex tasks into a series of programmatically verifiable atomic steps, ensuring a rigorous, fully automated, and reproducible standard for assessment. Concurrently, to mitigate the inherent capability deficits of agents, we developed LightManus, a hierarchical agent architecture specifically optimized for long-horizon tasks. We leveraged this agent to generate a high-quality, human-verified trajectory dataset that uniquely captures diverse and even self-correcting interaction patterns of LLMs. We then utilized this dataset to perform Reinforcement Fine-Tuning (RFT) on the Qwen2.5-VL-7B model. Our experiments reveal that NaturalGAIA presents a formidable challenge to current state-of-the-art LLMs; even the top-performing Claude-sonnet-4 achieved a Weighted Pathway Success Rate (WPSR) of only 34.6%. Moreover, while RFT substantially improved the smaller model's GUI execution capabilities (WPSR increased from 3.3% to 10.8%), its performance degraded sharply when handling complex scenarios. This outcome highlights the inherent capability ceiling of smaller models when faced with comprehensive tasks that integrate perception, decision-making, and execution. This research contributes a rigorous evaluation standard and a high-quality dataset to the community, aiming to guide the future development of GUI agents.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰è¯„ä¼°åŸºå‡†åœ¨å‡†ç¡®æ€§ã€å¯é‡å¤æ€§å’Œå¯æ‰©å±•æ€§æ–¹é¢çš„å±€é™ï¼Œæå‡ºäº†NaturalGAIAï¼Œä¸€ä¸ªåŸºäºå› æœè·¯å¾„(Causal Pathways)åŸåˆ™è®¾è®¡çš„æ–°å‹GUIæ™ºèƒ½ä½“è¯„ä¼°åŸºå‡†ã€‚è¯¥åŸºå‡†é€šè¿‡å°†å¤æ‚ä»»åŠ¡åˆ†è§£ä¸ºå¯ç¨‹åºåŒ–éªŒè¯çš„åŸå­æ­¥éª¤ï¼Œç¡®ä¿äº†è¯„ä¼°è¿‡ç¨‹çš„ä¸¥æ ¼æ€§ä¸è‡ªåŠ¨åŒ–ã€‚ç ”ç©¶å›¢é˜Ÿè¿˜å¼€å‘äº†åä¸ºLightManusçš„åˆ†å±‚æ™ºèƒ½ä½“æ¶æ„ä»¥ä¼˜åŒ–é•¿ç¨‹ä»»åŠ¡ï¼Œå¹¶æ®æ­¤ç”Ÿæˆäº†ä¸€ä¸ªåŒ…å«å¤šæ ·åŒ–è‡ªæˆ‘ä¿®å¤æ¨¡å¼çš„é«˜è´¨é‡äººå·¥éªŒè¯è½¨è¿¹æ•°æ®é›†ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒNaturalGAIAå¯¹å½“å‰é¡¶å°–æ¨¡å‹æ„æˆäº†ä¸¥å³»æŒ‘æˆ˜ï¼Œè¡¨ç°æœ€å¥½çš„Claude-3.5-Sonnetå…¶åŠ æƒè·¯å¾„æˆåŠŸç‡(WPSR)ä»…ä¸º34.6%ã€‚å°½ç®¡é€šè¿‡å¼ºåŒ–å¾®è°ƒ(RFT)æå‡äº†Qwen2.5-VL-7Bç­‰è¾ƒå°æ¨¡å‹çš„æ‰§è¡Œèƒ½åŠ›ï¼Œä½†åœ¨é¢å¯¹éœ€è¦é›†æˆæ„ŸçŸ¥ã€å†³ç­–ä¸æ‰§è¡Œçš„å¤æ‚åœºæ™¯æ—¶ï¼Œæ¨¡å‹ä»è¡¨ç°å‡ºæ˜æ˜¾çš„æ€§èƒ½å¤©èŠ±æ¿ã€‚è¿™é¡¹å·¥ä½œä¸ºGUIæ™ºèƒ½ä½“é¢†åŸŸè´¡çŒ®äº†ä¸¥è°¨çš„è¯„ä¼°æ ‡å‡†å’Œé«˜è´¨é‡æ•°æ®é›†ï¼Œå¯¹å¼•å¯¼æœªæ¥æ™ºèƒ½ä½“çš„å‘å±•å…·æœ‰é‡è¦æ„ä¹‰ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.01330v2",
      "published_date": "2025-08-02 11:53:41 UTC",
      "updated_date": "2025-08-07 09:42:28 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:22:04.842140+00:00"
    },
    {
      "arxiv_id": "2508.01329v1",
      "title": "Is Exploration or Optimization the Problem for Deep Reinforcement Learning?",
      "title_zh": "æ·±åº¦å¼ºåŒ–å­¦ä¹ çš„é—®é¢˜åœ¨äºæ¢ç´¢è¿˜æ˜¯ä¼˜åŒ–ï¼Ÿ",
      "authors": [
        "Glen Berseth"
      ],
      "abstract": "In the era of deep reinforcement learning, making progress is more complex, as the collected experience must be compressed into a deep model for future exploitation and sampling. Many papers have shown that training a deep learning policy under the changing state and action distribution leads to sub-optimal performance, or even collapse. This naturally leads to the concern that even if the community creates improved exploration algorithms or reward objectives, will those improvements fall on the \\textit{deaf ears} of optimization difficulties. This work proposes a new \\textit{practical} sub-optimality estimator to determine optimization limitations of deep reinforcement learning algorithms. Through experiments across environments and RL algorithms, it is shown that the difference between the best experience generated is 2-3$\\times$ better than the policies' learned performance. This large difference indicates that deep RL methods only exploit half of the good experience they generate.",
      "tldr_zh": "è¯¥ç ”ç©¶æ·±å…¥æ¢è®¨äº†æ·±åº¦å¼ºåŒ–å­¦ä¹ ï¼ˆDeep Reinforcement Learningï¼‰ä¸­è¿›æ­¥å—é˜»çš„æ ¹æºï¼Œåˆ†æäº†æ€§èƒ½ç“¶é¢ˆç©¶ç«Ÿæºäºæ¢ç´¢ï¼ˆExplorationï¼‰è¿˜æ˜¯ä¼˜åŒ–ï¼ˆOptimizationï¼‰çš„å±€é™ã€‚ä½œè€…æŒ‡å‡ºï¼Œåœ¨ä¸æ–­å˜åŒ–çš„çŠ¶æ€å’ŒåŠ¨ä½œåˆ†å¸ƒä¸‹è®­ç»ƒæ·±åº¦ç­–ç•¥ï¼Œå¾€å¾€ä¼šå¯¼è‡´æ€§èƒ½æ¬¡ä¼˜ç”šè‡³æ¨¡å‹å´©æºƒã€‚ä¸ºæ­¤ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–°å‹çš„å®ç”¨æ¬¡ä¼˜æ€§è¯„ä¼°å™¨ï¼ˆpractical sub-optimality estimatorï¼‰ï¼Œæ—¨åœ¨é‡åŒ–è¯„ä¼° DRL ç®—æ³•åœ¨ä¼˜åŒ–å±‚é¢çš„é™åˆ¶ã€‚é€šè¿‡åœ¨ä¸åŒç¯å¢ƒå’Œç®—æ³•ä¸Šçš„å®éªŒå‘ç°ï¼Œæ™ºèƒ½ä½“äº§ç”Ÿçš„æœ€ä½³ç»éªŒï¼ˆbest experienceï¼‰è´¨é‡é€šå¸¸æ¯”å…¶å­¦åˆ°çš„ç­–ç•¥æ€§èƒ½é«˜å‡º 2 è‡³ 3 å€ã€‚è¿™ä¸€æ˜¾è‘—å·®å¼‚è¡¨æ˜ï¼Œå½“å‰çš„ DRL æ–¹æ³•ä»…èƒ½åˆ©ç”¨å…¶äº§ç”Ÿçš„é«˜è´¨é‡ç»éªŒçš„ä¸€åŠï¼Œæ­ç¤ºäº†ä¼˜åŒ–å›°éš¾æ˜¯åˆ¶çº¦æ€§èƒ½æå‡çš„å…³é”®å› ç´ ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.01329v1",
      "published_date": "2025-08-02 11:40:26 UTC",
      "updated_date": "2025-08-02 11:40:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:22:08.745429+00:00"
    },
    {
      "arxiv_id": "2508.01324v1",
      "title": "Towards Evaluation for Real-World LLM Unlearning",
      "title_zh": "è¿ˆå‘çœŸå®åœºæ™¯ä¸‹çš„å¤§è¯­è¨€æ¨¡å‹é—å¿˜è¯„ä¼°",
      "authors": [
        "Ke Miao",
        "Yuke Hu",
        "Xiaochen Li",
        "Wenjie Bao",
        "Zhihao Liu",
        "Zhan Qin",
        "Kui Ren"
      ],
      "abstract": "This paper analyzes the limitations of existing unlearning evaluation metrics in terms of practicality, exactness, and robustness in real-world LLM unlearning scenarios. To overcome these limitations, we propose a new metric called Distribution Correction-based Unlearning Evaluation (DCUE). It identifies core tokens and corrects distributional biases in their confidence scores using a validation set. The evaluation results are quantified using the Kolmogorov-Smirnov test. Experimental results demonstrate that DCUE overcomes the limitations of existing metrics, which also guides the design of more practical and reliable unlearning algorithms in the future.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶åˆ†æäº†ç°æœ‰ LLM Unlearning è¯„ä¼°æŒ‡æ ‡åœ¨å®é™…åº”ç”¨åœºæ™¯ä¸­é¢ä¸´çš„å®ç”¨æ€§ã€ç²¾ç¡®æ€§å’Œé²æ£’æ€§æ–¹é¢çš„å±€é™ã€‚ä¸ºäº†è§£å†³è¿™äº›é—®é¢˜ï¼Œä½œè€…æå‡ºäº†ä¸€ç§åä¸º Distribution Correction-based Unlearning Evaluation (DCUE) çš„æ–°æŒ‡æ ‡ã€‚è¯¥æ–¹æ³•é€šè¿‡è¯†åˆ«æ ¸å¿ƒ tokenï¼Œå¹¶åˆ©ç”¨éªŒè¯é›†æ ¡æ­£å…¶ç½®ä¿¡åº¦åˆ†æ•°ä¸­çš„åˆ†å¸ƒåå·®ï¼Œä»è€Œå®ç°æ›´å‡†ç¡®çš„è¯„ä¼°ã€‚è¯„ä¼°è¿‡ç¨‹é‡‡ç”¨äº† Kolmogorov-Smirnov æ£€éªŒå¯¹ç»“æœè¿›è¡Œé‡åŒ–ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDCUE æˆåŠŸå…‹æœäº†ç°æœ‰æŒ‡æ ‡çš„ç¼ºé™·ï¼Œä¸ºæœªæ¥è®¾è®¡æ›´å…·å®ç”¨æ€§å’Œå¯é æ€§çš„ unlearning ç®—æ³•æä¾›äº†æŒ‡å¯¼ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.01324v1",
      "published_date": "2025-08-02 11:32:41 UTC",
      "updated_date": "2025-08-02 11:32:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:22:05.042322+00:00"
    },
    {
      "arxiv_id": "2508.01323v1",
      "title": "Idempotent Equilibrium Analysis of Hybrid Workflow Allocation: A Mathematical Schema for Future Work",
      "title_zh": "æ··åˆå·¥ä½œæµåˆ†é…çš„å¹‚ç­‰å‡è¡¡åˆ†æï¼šé¢å‘æœªæ¥å·¥ä½œçš„æ•°å­¦æ¶æ„",
      "authors": [
        "Faruk Alpay",
        "Bugra Kilictas",
        "Taylan Alpay",
        "Hamdi Alakkad"
      ],
      "abstract": "The rapid advance of large-scale AI systems is reshaping how work is divided between people and machines. We formalise this reallocation as an iterated task-delegation map and show that--under broad, empirically grounded assumptions--the process converges to a stable idempotent equilibrium in which every task is performed by the agent (human or machine) with enduring comparative advantage. Leveraging lattice-theoretic fixed-point tools (Tarski and Banach), we (i) prove existence of at least one such equilibrium and (ii) derive mild monotonicity conditions that guarantee uniqueness. In a stylised continuous model the long-run automated share takes the closed form $x^* = Î±/ (Î±+ Î²)$, where $Î±$ captures the pace of automation and $Î²$ the rate at which new, human-centric tasks appear; hence full automation is precluded whenever $Î²> 0$. We embed this analytic result in three complementary dynamical benchmarks--a discrete linear update, an evolutionary replicator dynamic, and a continuous Beta-distributed task spectrum--each of which converges to the same mixed equilibrium and is reproducible from the provided code-free formulas. A 2025-to-2045 simulation calibrated to current adoption rates projects automation rising from approximately 10% of work to approximately 65%, leaving a persistent one-third of tasks to humans. We interpret that residual as a new profession of workflow conductor: humans specialise in assigning, supervising and integrating AI modules rather than competing with them. Finally, we discuss implications for skill development, benchmark design and AI governance, arguing that policies which promote \"centaur\" human-AI teaming can steer the economy toward the welfare-maximising fixed point.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªæ•°å­¦æ¡†æ¶ï¼Œé€šè¿‡è¿­ä»£ä»»åŠ¡å§”æ´¾å›¾(iterated task-delegation map)åˆ†æäººç±»ä¸AIä¹‹é—´çš„å·¥ä½œé‡æ–°åˆ†é…ï¼Œå¹¶è¯æ˜è¯¥è¿‡ç¨‹æœ€ç»ˆä¼šæ”¶æ•›äºä¸€ä¸ªç¨³å®šçš„å¹‚ç­‰å‡è¡¡(idempotent equilibrium)ã€‚åˆ©ç”¨Tarskiå’ŒBanachç­‰æ ¼è®ºä¸åŠ¨ç‚¹å·¥å…·ï¼Œç ”ç©¶è¯æ˜äº†æ­¤ç±»å‡è¡¡çš„å­˜åœ¨æ€§åŠå…¶å”¯ä¸€æ€§æ¡ä»¶ï¼Œå¹¶æ¨å¯¼å‡ºé•¿æœŸè‡ªåŠ¨åŒ–æ¯”ä¾‹çš„é—­å¼å…¬å¼$x^* = \\alpha/(\\alpha + \\beta)$ã€‚é€šè¿‡å¯¹2025è‡³2045å¹´çš„ä»¿çœŸæ¨¡æ‹Ÿï¼Œè®ºæ–‡é¢„æµ‹å·¥ä½œè‡ªåŠ¨åŒ–æ¯”ä¾‹å°†ä»ç›®å‰çš„10%ä¸Šå‡è‡³çº¦65%ï¼Œè€Œå‰©ä½™çš„ä»»åŠ¡å°†ä¿ƒä½¿äººç±»è½¬å‹ä¸ºä¸“é—¨è´Ÿè´£ç›‘ç£å’Œé›†æˆAIæ¨¡å—çš„â€œå·¥ä½œæµæŒ‡æŒ¥å®˜â€(workflow conductor)ã€‚è¯¥ç ”ç©¶å¼ºè°ƒäº†â€œåŠäººé©¬â€(centaur)å¼äººæœºåä½œåœ¨å®ç°ç¦åˆ©æœ€å¤§åŒ–å‡è¡¡ä¸­çš„é‡è¦æ€§ï¼Œä¸ºæœªæ¥çš„æŠ€èƒ½å‘å±•ã€åŸºå‡†è®¾è®¡å’ŒAIæ²»ç†æä¾›äº†å…³é”®çš„ç†è®ºæ”¯æ’‘ã€‚",
      "categories": [
        "cs.AI",
        "cs.CY",
        "econ.GN"
      ],
      "primary_category": "cs.AI",
      "comment": "25 pages, 9 figures, 4 tables. Proves existence/uniqueness of an \"idempotent equilibrium\" for human-AI task allocation and provides closed-form steady-state automation share",
      "pdf_url": "https://arxiv.org/pdf/2508.01323v1",
      "published_date": "2025-08-02 11:28:34 UTC",
      "updated_date": "2025-08-02 11:28:34 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:22:14.481787+00:00"
    },
    {
      "arxiv_id": "2508.01309v1",
      "title": "D-SCoRE: Document-Centric Segmentation and CoT Reasoning with Structured Export for QA-CoT Data Generation",
      "title_zh": "D-SCoREï¼šé¢å‘ QA-CoT æ•°æ®ç”Ÿæˆçš„ä»¥æ–‡æ¡£ä¸ºä¸­å¿ƒçš„åˆ†æ®µã€é“¾å¼æ€ç»´æ¨ç†ä¸ç»“æ„åŒ–å¯¼å‡º",
      "authors": [
        "Weibo Zhou",
        "Lingbo Li",
        "Shangsong Liang"
      ],
      "abstract": "The scarcity and high cost of high-quality question-answering (QA) datasets hinder supervised fine-tuning (SFT) for domain-specific large language models (LLMs). To address this, we introduce D-SCoRE, a training-free pipeline that utilizes LLMs and prompt engineering to produce diverse, high-quality QA datasets from arbitrary textual sources. D-SCoRE integrates $\\textbf{D}$ocument-centric processing, $\\textbf{S}$egmentation, $\\textbf{Co}$T $\\textbf{R}$easoning, and structured $\\textbf{E}$xport to generate QA-COT datasets tailored for domain-aware SFT. Multi-dimensional control mechanisms, such as semantic role transformation, question type balancing, and counterfactual materials, enhance diversity and relevance, overcoming limitations of existing QA generation. LLMs fine-tuned on D-SCoRE-generated QA datasets, and human-annotated QA datasets (SQuAD, Covid-QA) are evaluated on SQuADShifts and Covid-QA test sets, with D-SCoRE outperforming across most domains. D-SCoRE generates six QA-CoT pairs with four-option counterfactual materials per 100-200-word text in 90 seconds using an 8B LLM on consumer-grade hardware. Its simplicity and scalability enable efficient QA generation and high-performance fine-tuning across domains.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç‰¹å®šé¢†åŸŸå¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨ç›‘ç£å¾®è°ƒ(SFT)ä¸­é«˜è´¨é‡é—®ç­”(QA)æ•°æ®é›†ç¨€ç¼ºä¸”æˆæœ¬é«˜æ˜‚çš„é—®é¢˜ï¼Œæå‡ºäº†D-SCoREã€‚è¿™æ˜¯ä¸€ä¸ªæ— éœ€è®­ç»ƒçš„è‡ªåŠ¨åŒ–æµç¨‹ï¼Œé€šè¿‡é›†æˆä»¥æ–‡æ¡£ä¸ºä¸­å¿ƒçš„å¤„ç†(Document-centric processing)ã€åˆ†æ®µ(Segmentation)ã€é“¾å¼æ€ç»´æ¨ç†(CoT Reasoning)ä»¥åŠç»“æ„åŒ–å¯¼å‡º(Structured Export)æŠ€æœ¯ï¼Œä»ä»»æ„æ–‡æœ¬æºç”Ÿæˆé«˜è´¨é‡çš„QA-CoTæ•°æ®é›†ã€‚è¯¥æ¡†æ¶åˆ©ç”¨è¯­ä¹‰è§’è‰²è½¬æ¢ã€é—®é¢˜ç±»å‹å¹³è¡¡å’Œåäº‹å®ææ–™(Counterfactual materials)ç­‰å¤šç»´æ§åˆ¶æœºåˆ¶å¢å¼ºäº†æ•°æ®çš„å¤šæ ·æ€§ï¼Œå…‹æœäº†ç°æœ‰ç”Ÿæˆæ–¹æ³•çš„å±€é™æ€§ã€‚å®éªŒè¡¨æ˜ï¼Œåœ¨D-SCoREç”Ÿæˆçš„æ•°æ®é›†ä¸Šå¾®è°ƒçš„LLMsåœ¨SQuADShiftså’ŒCovid-QAç­‰æµ‹è¯•é›†ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œåœ¨å¤šæ•°é¢†åŸŸè¶…è¶Šäº†åŸºäºäººå·¥æ ‡æ³¨æ•°æ®çš„æ¨¡å‹ã€‚D-SCoREåœ¨æ¶ˆè´¹çº§ç¡¬ä»¶ä¸Šå±•ç°äº†æé«˜çš„æ•ˆç‡ï¼Œä»…éœ€90ç§’å³å¯ä»çŸ­æ–‡æœ¬ä¸­ç”Ÿæˆå¤šç»„å¤æ‚çš„QA-CoTå¯¹ã€‚å…¶ç®€æ´æ€§å’Œå¯æ‰©å±•æ€§ä¸ºè·¨é¢†åŸŸçš„é«˜æ€§èƒ½æ¨¡å‹å¾®è°ƒå’Œé«˜æ•ˆæ•°æ®ç”Ÿæˆæä¾›äº†å¯è¡Œçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.01309v1",
      "published_date": "2025-08-02 10:45:05 UTC",
      "updated_date": "2025-08-02 10:45:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:22:11.840003+00:00"
    },
    {
      "arxiv_id": "2508.01306v1",
      "title": "PUZZLED: Jailbreaking LLMs through Word-Based Puzzles",
      "title_zh": "PUZZLEDï¼šåŸºäºå•è¯è°œé¢˜çš„å¤§è¯­è¨€æ¨¡å‹è¶Šç‹±",
      "authors": [
        "Yelim Ahn",
        "Jaejin Lee"
      ],
      "abstract": "As large language models (LLMs) are increasingly deployed across diverse domains, ensuring their safety has become a critical concern. In response, studies on jailbreak attacks have been actively growing. Existing approaches typically rely on iterative prompt engineering or semantic transformations of harmful instructions to evade detection. In this work, we introduce PUZZLED, a novel jailbreak method that leverages the LLM's reasoning capabilities. It masks keywords in a harmful instruction and presents them as word puzzles for the LLM to solve. We design three puzzle types-word search, anagram, and crossword-that are familiar to humans but cognitively demanding for LLMs. The model must solve the puzzle to uncover the masked words and then proceed to generate responses to the reconstructed harmful instruction. We evaluate PUZZLED on five state-of-the-art LLMs and observe a high average attack success rate (ASR) of 88.8%, specifically 96.5% on GPT-4.1 and 92.3% on Claude 3.7 Sonnet. PUZZLED is a simple yet powerful attack that transforms familiar puzzles into an effective jailbreak strategy by harnessing LLMs' reasoning capabilities.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†PUZZLEDï¼Œä¸€ç§åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(LLMs)æ¨ç†èƒ½åŠ›çš„æ–°å‹è¶Šç‹±(jailbreak)æ”»å‡»æ–¹æ³•ï¼Œæ—¨åœ¨é€šè¿‡è®¤çŸ¥ä»»åŠ¡ç»•è¿‡æ¨¡å‹çš„å®‰å…¨é˜²å¾¡ã€‚è¯¥æ–¹æ³•å°†æœ‰å®³æŒ‡ä»¤ä¸­çš„æ ¸å¿ƒå…³é”®è¯æ©ç ï¼Œå¹¶å°†å…¶è½¬åŒ–ä¸ºå•è¯æœç´¢(word search)ã€æ˜“ä½æ„è¯(anagram)å’Œå¡«å­—æ¸¸æˆ(crossword)ç­‰å¯¹æ¨¡å‹å…·æœ‰è®¤çŸ¥æŒ‘æˆ˜æ€§çš„å•è¯è°œé¢˜ã€‚æ¨¡å‹å¿…é¡»é¦–å…ˆåˆ©ç”¨å…¶æ¨ç†èƒ½åŠ›è§£å†³è¿™äº›è°œé¢˜ä»¥è¿˜åŸæ©ç è¯æ±‡ï¼Œéšååœ¨é‡æ„æŒ‡ä»¤çš„è¿‡ç¨‹ä¸­ç”Ÿæˆå¯¹æœ‰å®³è¯·æ±‚çš„å“åº”ã€‚å®éªŒåœ¨äº”ç§æœ€å…ˆè¿›çš„LLMsä¸Šè¯æ˜äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ï¼Œå…¶å¹³å‡æ”»å‡»æˆåŠŸç‡(ASR)è¾¾åˆ°88.8%ï¼Œåœ¨GPT-4.1å’ŒClaude 3.7 Sonnetä¸Šæ›´æ˜¯åˆ†åˆ«é«˜è¾¾96.5%å’Œ92.3%ã€‚è¿™é¡¹ç ”ç©¶æ­ç¤ºäº†PUZZLEDä½œä¸ºä¸€ç§ç®€å•ä¸”å¼ºå¤§çš„æ”»å‡»æ‰‹æ®µï¼Œé€šè¿‡å°†æ—¥å¸¸è°œé¢˜ä¸æ¨¡å‹çš„æ¨ç†ç‰¹æ€§ç»“åˆï¼Œæ„æˆäº†å¯¹å½“å‰LLMå®‰å…¨æœºåˆ¶çš„ä¸¥å³»æŒ‘æˆ˜ã€‚",
      "categories": [
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.AI",
      "comment": "15 pages",
      "pdf_url": "https://arxiv.org/pdf/2508.01306v1",
      "published_date": "2025-08-02 10:36:01 UTC",
      "updated_date": "2025-08-02 10:36:01 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:22:21.260888+00:00"
    },
    {
      "arxiv_id": "2508.01300v1",
      "title": "How Far Are LLMs from Symbolic Planners? An NLP-Based Perspective",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹è·ç¦»ç¬¦å·è§„åˆ’å™¨è¿˜æœ‰å¤šè¿œï¼ŸåŸºäºè‡ªç„¶è¯­è¨€å¤„ç†è§†è§’çš„æ¢ç©¶",
      "authors": [
        "Ma'ayan Armony",
        "Albert MeroÃ±o-PeÃ±uela",
        "Gerard Canal"
      ],
      "abstract": "The reasoning and planning abilities of Large Language Models (LLMs) have been a frequent topic of discussion in recent years. Their ability to take unstructured planning problems as input has made LLMs' integration into AI planning an area of interest. Nevertheless, LLMs are still not reliable as planners, with the generated plans often containing mistaken or hallucinated actions. Existing benchmarking and evaluation methods investigate planning with LLMs, focusing primarily on success rate as a quality indicator in various planning tasks, such as validating plans or planning in relaxed conditions. In this paper, we approach planning with LLMs as a natural language processing (NLP) task, given that LLMs are NLP models themselves. We propose a recovery pipeline consisting of an NLP-based evaluation of the generated plans, along with three stages to recover the plans through NLP manipulation of the LLM-generated plans, and eventually complete the plan using a symbolic planner. This pipeline provides a holistic analysis of LLM capabilities in the context of AI task planning, enabling a broader understanding of the quality of invalid plans. Our findings reveal no clear evidence of underlying reasoning during plan generation, and that a pipeline comprising an NLP-based analysis of the plans, followed by a recovery mechanism, still falls short of the quality and reliability of classical planners. On average, only the first 2.65 actions of the plan are executable, with the average length of symbolically generated plans being 8.4 actions. The pipeline still improves action quality and increases the overall success rate from 21.9% to 27.5%.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰çš„è§†è§’å‡ºå‘ï¼Œæ·±å…¥æ¢è®¨äº†å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸ç¬¦å·è§„åˆ’å™¨ï¼ˆSymbolic Plannersï¼‰åœ¨ä»»åŠ¡è§„åˆ’èƒ½åŠ›ä¸Šçš„å·®è·ã€‚é’ˆå¯¹LLMsåœ¨ç”Ÿæˆè®¡åˆ’æ—¶é¢‘ç¹å‡ºç°çš„é”™è¯¯å’Œå¹»è§‰ï¼ˆhallucinated actionsï¼‰é—®é¢˜ï¼Œä½œè€…æå‡ºäº†ä¸€ç§åŒ…å«NLPè¯„ä¼°ã€ä¸‰é˜¶æ®µä¿®å¤æœºåˆ¶ä»¥åŠç»“åˆç¬¦å·è§„åˆ’å™¨å®Œæˆè®¡åˆ’çš„æ¢å¤æµæ°´çº¿ï¼ˆrecovery pipelineï¼‰ã€‚è¯¥ç ”ç©¶å¯¹LLMsç”Ÿæˆçš„æ— æ•ˆè®¡åˆ’è¿›è¡Œäº†å…¨é¢åˆ†æï¼Œç»“æœæ˜¾ç¤ºåœ¨è®¡åˆ’ç”Ÿæˆè¿‡ç¨‹ä¸­å¹¶æ²¡æœ‰æ˜ç¡®çš„è¯æ®æ”¯æŒå…¶å…·å¤‡åº•å±‚çš„æ¨ç†ï¼ˆreasoningï¼‰èƒ½åŠ›ã€‚å®éªŒè¡¨æ˜ï¼ŒLLMsç”Ÿæˆçš„è®¡åˆ’å¹³å‡ä»…æœ‰å‰2.65ä¸ªåŠ¨ä½œæ˜¯å¯æ‰§è¡Œçš„ï¼Œè¿œä½äºç¬¦å·è§„åˆ’å™¨ç”Ÿæˆçš„å¹³å‡8.4ä¸ªåŠ¨ä½œã€‚å°½ç®¡è¯¥æµæ°´çº¿å°†æ•´ä½“è§„åˆ’æˆåŠŸç‡ä»21.9%æå‡è‡³27.5%ï¼Œä½†åœ¨è´¨é‡å’Œå¯é æ€§æ–¹é¢ä»æ˜¾è‘—è½åäºç»å…¸çš„è§„åˆ’å™¨ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.01300v1",
      "published_date": "2025-08-02 10:20:52 UTC",
      "updated_date": "2025-08-02 10:20:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:22:21.924761+00:00"
    },
    {
      "arxiv_id": "2508.01293v2",
      "title": "GMAT: Grounded Multi-Agent Clinical Description Generation for Text Encoder in Vision-Language MIL for Whole Slide Image Classification",
      "title_zh": "GMATï¼šé¢å‘å…¨åˆ‡ç‰‡å›¾åƒåˆ†ç±»è§†è§‰-è¯­è¨€å¤šç¤ºä¾‹å­¦ä¹ æ–‡æœ¬ç¼–ç å™¨çš„çŸ¥è¯†å¢å¼ºå‹å¤šæ™ºèƒ½ä½“ä¸´åºŠæè¿°ç”Ÿæˆ",
      "authors": [
        "Ngoc Bui Lam Quang",
        "Nam Le Nguyen Binh",
        "Thanh-Huy Nguyen",
        "Le Thien Phuc Nguyen",
        "Quan Nguyen",
        "Ulas Bagci"
      ],
      "abstract": "Multiple Instance Learning (MIL) is the leading approach for whole slide image (WSI) classification, enabling efficient analysis of gigapixel pathology slides. Recent work has introduced vision-language models (VLMs) into MIL pipelines to incorporate medical knowledge through text-based class descriptions rather than simple class names. However, when these methods rely on large language models (LLMs) to generate clinical descriptions or use fixed-length prompts to represent complex pathology concepts, the limited token capacity of VLMs often constrains the expressiveness and richness of the encoded class information. Additionally, descriptions generated solely by LLMs may lack domain grounding and fine-grained medical specificity, leading to suboptimal alignment with visual features. To address these challenges, we propose a vision-language MIL framework with two key contributions: (1) A grounded multi-agent description generation system that leverages curated pathology textbooks and agent specialization (e.g., morphology, spatial context) to produce accurate and diverse clinical descriptions; (2) A text encoding strategy using a list of descriptions rather than a single prompt, capturing fine-grained and complementary clinical signals for better alignment with visual features. Integrated into a VLM-MIL pipeline, our approach shows improved performance over single-prompt class baselines and achieves results comparable to state-of-the-art models, as demonstrated on renal and lung cancer datasets.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† GMAT æ¡†æ¶ï¼Œæ—¨åœ¨ä¼˜åŒ–è§†è§‰è¯­è¨€å¤šå®ä¾‹å­¦ä¹  (Vision-Language MIL) åœ¨å…¨åˆ‡ç‰‡å›¾åƒ (Whole Slide Image, WSI) åˆ†ç±»ä¸­çš„åº”ç”¨ã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•ä¸­å¤§è¯­è¨€æ¨¡å‹ (LLM) ç”Ÿæˆçš„ä¸´åºŠæè¿°ç¼ºä¹é¢†åŸŸä¾æ®ä»¥åŠè§†è§‰è¯­è¨€æ¨¡å‹ (VLM) ä»¤ç‰Œå®¹é‡æœ‰é™å¯¼è‡´çš„è¡¨è¾¾åŠ›ä¸è¶³ï¼ŒGMAT å¼•å…¥äº†åŸºäºä¸“ä¸šç—…ç†å­¦æ•™ç§‘ä¹¦çš„ Grounded Multi-Agent æè¿°ç”Ÿæˆç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿåˆ©ç”¨å½¢æ€å­¦ã€ç©ºé—´ä¸Šä¸‹æ–‡ç­‰ä¸“é—¨æ™ºèƒ½ä½“ç”Ÿæˆå‡†ç¡®ä¸”å¤šæ ·åŒ–çš„ä¸´åºŠæè¿°ï¼Œå¹¶é…åˆä½¿ç”¨æè¿°åˆ—è¡¨è€Œéå•ä¸€æç¤ºçš„æ–‡æœ¬ç¼–ç ç­–ç•¥ï¼Œä»è€Œæ•æ‰æ›´ç»†ç²’åº¦ä¸”äº’è¡¥çš„ä¸´åºŠä¿¡å·ã€‚å®éªŒåœ¨è‚¾ç™Œå’Œè‚ºç™Œæ•°æ®é›†ä¸Šè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨è§†è§‰ç‰¹å¾å¯¹é½æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œæ€§èƒ½æ˜¾è‘—è¶…è¿‡å•ä¸€æç¤ºåŸºçº¿ï¼Œå¹¶è¾¾åˆ°äº†ä¸å½“å‰æœ€å…ˆè¿›æ¨¡å‹ (State-of-the-Art) ç›¸å½“çš„æ°´å¹³ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Acccepted in MICCAI Workshop 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.01293v2",
      "published_date": "2025-08-02 09:59:39 UTC",
      "updated_date": "2025-11-18 17:43:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:22:43.657918+00:00"
    },
    {
      "arxiv_id": "2508.01292v2",
      "title": "CoCoLIT: ControlNet-Conditioned Latent Image Translation for MRI to Amyloid PET Synthesis",
      "title_zh": "CoCoLITï¼šåŸºäº ControlNet çº¦æŸçš„æ½œåœ¨å›¾åƒè½¬æ¢ï¼Œç”¨äº MRI è‡³æ·€ç²‰æ ·è›‹ç™½ PET åˆæˆ",
      "authors": [
        "Alec Sargood",
        "Lemuel Puglisi",
        "James H. Cole",
        "Neil P. Oxtoby",
        "Daniele RavÃ¬",
        "Daniel C. Alexander"
      ],
      "abstract": "Synthesizing amyloid PET scans from the more widely available and accessible structural MRI modality offers a promising, cost-effective approach for large-scale Alzheimer's Disease (AD) screening. This is motivated by evidence that, while MRI does not directly detect amyloid pathology, it may nonetheless encode information correlated with amyloid deposition that can be uncovered through advanced modeling. However, the high dimensionality and structural complexity of 3D neuroimaging data pose significant challenges for existing MRI-to-PET translation methods. Modeling the cross-modality relationship in a lower-dimensional latent space can simplify the learning task and enable more effective translation. As such, we present CoCoLIT (ControlNet-Conditioned Latent Image Translation), a diffusion-based latent generative framework that incorporates three main innovations: (1) a novel Weighted Image Space Loss (WISL) that improves latent representation learning and synthesis quality; (2) a theoretical and empirical analysis of Latent Average Stabilization (LAS), an existing technique used in similar generative models to enhance inference consistency; and (3) the introduction of ControlNet-based conditioning for MRI-to-PET translation. We evaluate CoCoLIT's performance on publicly available datasets and find that our model significantly outperforms state-of-the-art methods on both image-based and amyloid-related metrics. Notably, in amyloid-positivity classification, CoCoLIT outperforms the second-best method with improvements of +10.5% on the internal dataset and +23.7% on the external dataset. The code and models of our approach are available at https://github.com/brAIn-science/CoCoLIT.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†CoCoLITï¼Œä¸€ç§åŸºäºæ‰©æ•£æ¨¡å‹(Diffusion-based)çš„æ½œç©ºé—´ç”Ÿæˆæ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡ç»“æ„åŒ–MRIåˆæˆæ·€ç²‰æ ·è›‹ç™½PETæ‰«æï¼Œä»è€Œä¸ºé˜¿å°”èŒ¨æµ·é»˜ç—…(AD)æä¾›ä¸€ç§é«˜æˆæœ¬æ•ˆç›Šçš„å¤§è§„æ¨¡ç­›æŸ¥æ‰‹æ®µã€‚è¯¥æ¡†æ¶åŒ…å«ä¸‰å¤§æ ¸å¿ƒåˆ›æ–°ï¼šå¼•å…¥æ–°å‹çš„åŠ æƒå›¾åƒç©ºé—´æŸå¤±(Weighted Image Space Loss, WISL)ä»¥ä¼˜åŒ–æ½œç©ºé—´è¡¨ç¤ºå­¦ä¹ å’Œåˆæˆè´¨é‡ï¼Œå¯¹æ½œç©ºé—´å¹³å‡ç¨³å®šæŠ€æœ¯(Latent Average Stabilization, LAS)è¿›è¡Œç†è®ºä¸å®è¯åˆ†æä»¥å¢å¼ºæ¨ç†ä¸€è‡´æ€§ï¼Œå¹¶é¦–æ¬¡å°†ControlNetè°ƒèŠ‚æœºåˆ¶åº”ç”¨äºMRIåˆ°PETçš„å½±åƒè½¬æ¢ä»»åŠ¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCoCoLITåœ¨å›¾åƒè´¨é‡åŠæ·€ç²‰æ ·è›‹ç™½ç›¸å…³æŒ‡æ ‡ä¸Šå‡æ˜¾è‘—ä¼˜äºç°æœ‰çš„å…ˆè¿›æ–¹æ³•ã€‚ç‰¹åˆ«æ˜¯åœ¨æ·€ç²‰æ ·è›‹ç™½é˜³æ€§åˆ†ç±»ä»»åŠ¡ä¸­ï¼Œè¯¥æ–¹æ³•åœ¨å†…éƒ¨å’Œå¤–éƒ¨æ•°æ®é›†ä¸Šè¾ƒæ¬¡ä¼˜æ¨¡å‹åˆ†åˆ«å®ç°äº†10.5%å’Œ23.7%çš„æ€§èƒ½æå‡ã€‚è¿™é¡¹ç ”ç©¶è¯æ˜äº†åœ¨ä½ç»´æ½œç©ºé—´ä¸­å»ºæ¨¡è·¨æ¨¡æ€å…³ç³»èƒ½æœ‰æ•ˆç®€åŒ–å­¦ä¹ ä»»åŠ¡å¹¶æå‡åˆæˆæ•ˆæœï¼Œä¸ºåˆ©ç”¨æ›´æ™®åŠçš„å½±åƒæ¨¡æ€æ£€æµ‹æ·€ç²‰æ ·è›‹ç™½ç—…ç†æä¾›äº†æœ‰åŠ›çš„æŠ€æœ¯æ”¯æŒã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "Article accepted at AAAI-2026",
      "pdf_url": "https://arxiv.org/pdf/2508.01292v2",
      "published_date": "2025-08-02 09:58:30 UTC",
      "updated_date": "2025-11-11 14:09:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:22:42.528111+00:00"
    },
    {
      "arxiv_id": "2508.01287v1",
      "title": "Exploitation Is All You Need... for Exploration",
      "title_zh": "ä»…éœ€â€œå¼€å‘â€â€¦â€¦å³å¯å®ç°â€œæ¢ç´¢â€",
      "authors": [
        "Micah Rentschler",
        "Jesse Roberts"
      ],
      "abstract": "Ensuring sufficient exploration is a central challenge when training meta-reinforcement learning (meta-RL) agents to solve novel environments. Conventional solutions to the exploration-exploitation dilemma inject explicit incentives such as randomization, uncertainty bonuses, or intrinsic rewards to encourage exploration. In this work, we hypothesize that an agent trained solely to maximize a greedy (exploitation-only) objective can nonetheless exhibit emergent exploratory behavior, provided three conditions are met: (1) Recurring Environmental Structure, where the environment features repeatable regularities that allow past experience to inform future choices; (2) Agent Memory, enabling the agent to retain and utilize historical interaction data; and (3) Long-Horizon Credit Assignment, where learning propagates returns over a time frame sufficient for the delayed benefits of exploration to inform current decisions. Through experiments in stochastic multi-armed bandits and temporally extended gridworlds, we observe that, when both structure and memory are present, a policy trained on a strictly greedy objective exhibits information-seeking exploratory behavior. We further demonstrate, through controlled ablations, that emergent exploration vanishes if either environmental structure or agent memory is absent (Conditions 1 & 2). Surprisingly, removing long-horizon credit assignment (Condition 3) does not always prevent emergent exploration-a result we attribute to the pseudo-Thompson Sampling effect. These findings suggest that, under the right prerequisites, exploration and exploitation need not be treated as orthogonal objectives but can emerge from a unified reward-maximization process.",
      "tldr_zh": "è¯¥ç ”ç©¶æŒ‘æˆ˜äº†å…ƒå¼ºåŒ–å­¦ä¹ (meta-RL)ä¸­æ¢ç´¢ä¸å‰¥å‰Šçš„ä¼ ç»Ÿå¯¹ç«‹è§‚ç‚¹ï¼Œæå‡ºä»…ä»¥æœ€å¤§åŒ–è´ªå©ªç›®æ ‡è®­ç»ƒçš„æ™ºèƒ½ä½“ä¹Ÿèƒ½äº§ç”Ÿæ¶Œç°çš„æ¢ç´¢è¡Œä¸ºã€‚ä½œè€…æŒ‡å‡ºè¿™ç§ç°è±¡çš„äº§ç”Ÿéœ€æ»¡è¶³é‡å¤çš„ç¯å¢ƒç»“æ„(Recurring Environmental Structure)ã€æ™ºèƒ½ä½“è®°å¿†(Agent Memory)åŠé•¿ç¨‹ä¿¡ç”¨åˆ†é…(Long-Horizon Credit Assignment)ä¸‰ä¸ªå…³é”®æ¡ä»¶ã€‚é€šè¿‡åœ¨éšæœºå¤šè‡‚è€è™æœº(stochastic multi-armed bandits)å’Œæ ¼ç‚¹ä¸–ç•Œ(gridworlds)ä¸­çš„å®éªŒï¼Œç ”ç©¶è§‚å¯Ÿåˆ°åœ¨å…·å¤‡ç»“æ„å’Œè®°å¿†çš„å‰æä¸‹ï¼Œçº¯è´ªå©ªç­–ç•¥å±•ç°å‡ºäº†æ˜æ˜¾çš„ä¿¡æ¯å¯»æ±‚è¡Œä¸ºã€‚æ¶ˆèå®éªŒè¿›ä¸€æ­¥è¡¨æ˜ï¼Œç¼ºå¤±ç¯å¢ƒç»“æ„æˆ–è®°å¿†ä¼šä½¿è¿™ç§æ¢ç´¢è¡Œä¸ºæ¶ˆå¤±ï¼Œè€Œé•¿ç¨‹ä¿¡ç”¨åˆ†é…çš„å½±å“ç”±äºä¼ªæ±¤æ™®æ£®é‡‡æ ·(pseudo-Thompson Sampling)æ•ˆåº”è¡¨ç°å‡ºä¸€å®šçš„ç‰¹æ®Šæ€§ã€‚è¯¥å‘ç°è¯æ˜ï¼Œåœ¨åˆé€‚çš„å…ˆå†³æ¡ä»¶ä¸‹ï¼Œæ¢ç´¢å¹¶ä¸ä¸€å®šéœ€è¦æ˜¾å¼çš„é¢å¤–å¥–åŠ±æ¿€åŠ±ï¼Œè€Œæ˜¯å¯ä»¥ä»ç»Ÿä¸€çš„å¥–åŠ±æœ€å¤§åŒ–è¿‡ç¨‹ä¸­è‡ªç„¶æ¶Œç°ã€‚ç ”ç©¶ç»“è®ºä¸ºç†è§£è‡ªä¸»æ™ºèƒ½ä½“çš„è¡Œä¸ºé€»è¾‘æä¾›äº†æ–°è§†è§’ï¼Œå³æ¢ç´¢ä¸å‰¥å‰Šä¸å¿…è¢«è§†ä¸ºæ­£äº¤çš„ç›®æ ‡ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.01287v1",
      "published_date": "2025-08-02 09:42:59 UTC",
      "updated_date": "2025-08-02 09:42:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:22:46.646592+00:00"
    },
    {
      "arxiv_id": "2508.01285v2",
      "title": "BioDisco: Multi-agent hypothesis generation with dual-mode evidence, iterative feedback and temporal evaluation",
      "title_zh": "BioDiscoï¼šèåˆåŒæ¨¡è¯æ®ã€è¿­ä»£åé¦ˆä¸æ—¶åºè¯„ä¼°çš„å¤šæ™ºèƒ½ä½“å‡è®¾ç”Ÿæˆ",
      "authors": [
        "Yujing Ke",
        "Kevin George",
        "Kathan Pandya",
        "David Blumenthal",
        "Maximilian Sprang",
        "Gerrit GroÃŸmann",
        "Sebastian Vollmer",
        "David Antony Selby"
      ],
      "abstract": "Identifying novel hypotheses is essential to scientific research, yet this process risks being overwhelmed by the sheer volume and complexity of available information. Existing automated methods often struggle to generate novel and evidence-grounded hypotheses, lack robust iterative refinement and rarely undergo rigorous temporal evaluation for future discovery potential. To address this, we propose BioDisco, a multi-agent framework that draws upon language model-based reasoning and a dual-mode evidence system (biomedical knowledge graphs and automated literature retrieval) for grounded novelty, integrates an internal scoring and feedback loop for iterative refinement, and validates performance through pioneering temporal and human evaluations and a Bradley-Terry paired comparison model to provide statistically-grounded assessment. Our evaluations demonstrate superior novelty and significance over ablated configurations and generalist biomedical agents. Designed for flexibility and modularity, BioDisco allows seamless integration of custom language models or knowledge graphs, and can be run with just a few lines of code.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†BioDiscoï¼Œè¿™æ˜¯ä¸€ä¸ªç”¨äºç”Ÿæˆç§‘å­¦å‡è®¾çš„å¤šæ™ºèƒ½ä½“(multi-agent)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰è‡ªåŠ¨åŒ–æ–¹æ³•åœ¨ç”Ÿæˆæ–°é¢–ä¸”æœ‰è¯æ®æ”¯æŒçš„å‡è®¾æ–¹é¢çš„å±€é™æ€§ã€‚è¯¥æ¡†æ¶ç»“åˆäº†åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„æ¨ç†èƒ½åŠ›ä¸åŒæ¨¡å¼è¯æ®ç³»ç»Ÿ(dual-mode evidence system)ï¼ŒåŒ…æ‹¬ç”Ÿç‰©åŒ»å­¦çŸ¥è¯†å›¾è°±(biomedical knowledge graphs)å’Œè‡ªåŠ¨åŒ–æ–‡çŒ®æ£€ç´¢(automated literature retrieval)ï¼Œä»¥ç¡®ä¿å‡è®¾å…·æœ‰åšå®çš„è¯æ®åŸºç¡€ã€‚ä¸ºäº†å®ç°è¿­ä»£ä¼˜åŒ–ï¼ŒBioDiscoå¼•å…¥äº†å†…éƒ¨è¯„åˆ†å’Œåé¦ˆå¾ªç¯æœºåˆ¶ï¼Œå¹¶é€šè¿‡å¼€åˆ›æ€§çš„æ—¶é—´è¯„ä¼°(temporal evaluation)å’ŒBradley-Terryé…å¯¹æ¯”è¾ƒæ¨¡å‹æ¥éªŒè¯å…¶å¯¹æœªæ¥ç§‘å­¦å‘ç°çš„æ½œåŠ›ã€‚å®éªŒè¯„ä¼°è¯æ˜ï¼Œè¯¥æ¡†æ¶åœ¨å‡è®¾çš„æ–°é¢–æ€§å’Œæ˜¾è‘—æ€§æ–¹é¢å‡ä¼˜äºæ¶ˆèå®éªŒé…ç½®åŠé€šç”¨çš„ç”Ÿç‰©åŒ»å­¦æ™ºèƒ½ä½“ã€‚è¯¥ç³»ç»Ÿè®¾è®¡å…·æœ‰é«˜åº¦çš„çµæ´»æ€§å’Œæ¨¡å—åŒ–ç‰¹æ€§ï¼Œå…è®¸ç”¨æˆ·æ— ç¼é›†æˆè‡ªå®šä¹‰è¯­è¨€æ¨¡å‹æˆ–çŸ¥è¯†å›¾è°±ï¼Œä»…éœ€å°‘é‡ä»£ç å³å¯éƒ¨ç½²ã€‚",
      "categories": [
        "cs.AI",
        "cs.IR",
        "stat.AP"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages main content, 31 including appendices. 8 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.01285v2",
      "published_date": "2025-08-02 09:32:52 UTC",
      "updated_date": "2025-11-24 16:36:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:22:46.248936+00:00"
    },
    {
      "arxiv_id": "2508.01276v1",
      "title": "Defending Against Beta Poisoning Attacks in Machine Learning Models",
      "title_zh": "é’ˆå¯¹æœºå™¨å­¦ä¹ æ¨¡å‹ä¸­ Beta ä¸­æ¯’æ”»å‡»çš„é˜²å¾¡",
      "authors": [
        "Nilufer Gulciftci",
        "M. Emre Gursoy"
      ],
      "abstract": "Poisoning attacks, in which an attacker adversarially manipulates the training dataset of a machine learning (ML) model, pose a significant threat to ML security. Beta Poisoning is a recently proposed poisoning attack that disrupts model accuracy by making the training dataset linearly nonseparable. In this paper, we propose four defense strategies against Beta Poisoning attacks: kNN Proximity-Based Defense (KPB), Neighborhood Class Comparison (NCC), Clustering-Based Defense (CBD), and Mean Distance Threshold (MDT). The defenses are based on our observations regarding the characteristics of poisoning samples generated by Beta Poisoning, e.g., poisoning samples have close proximity to one another, and they are centered near the mean of the target class. Experimental evaluations using MNIST and CIFAR-10 datasets demonstrate that KPB and MDT can achieve perfect accuracy and F1 scores, while CBD and NCC also provide strong defensive capabilities. Furthermore, by analyzing performance across varying parameters, we offer practical insights regarding defenses' behaviors under varying conditions.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹æœºå™¨å­¦ä¹ (Machine Learning)å®‰å…¨é¢†åŸŸçš„Beta Poisoningæ”»å‡»æå‡ºäº†å¤šç§é˜²å¾¡æ–¹æ¡ˆï¼Œè¯¥æ”»å‡»ä¸»è¦é€šè¿‡ä½¿è®­ç»ƒæ•°æ®é›†çº¿æ€§ä¸å¯åˆ†(linearly nonseparable)æ¥ç ´åæ¨¡å‹å‡†ç¡®æ€§ã€‚ä¸ºåº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œè®ºæ–‡æå‡ºäº†å››ç§é˜²å¾¡ç­–ç•¥ï¼šåŸºäºkNNé‚»è¿‘åº¦çš„é˜²å¾¡(KPB)ã€é‚»åŸŸç±»åˆ«æ¯”è¾ƒ(NCC)ã€åŸºäºèšç±»çš„é˜²å¾¡(CBD)ä»¥åŠå‡å€¼è·ç¦»é˜ˆå€¼(MDT)ã€‚è¿™äº›ç­–ç•¥çš„è®¾è®¡æºäºå¯¹Beta Poisoningç”Ÿæˆæ ·æœ¬ç‰¹å¾çš„è§‚å¯Ÿï¼Œå³æ¯’åŒ–æ ·æœ¬åœ¨ç©ºé—´ä¸Šå½¼æ­¤æ¥è¿‘ä¸”é›†ä¸­åœ¨ç›®æ ‡ç±»åˆ«çš„å‡å€¼é™„è¿‘ã€‚åœ¨MNISTå’ŒCIFAR-10æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒKPBå’ŒMDTèƒ½å¤Ÿå®ç°å®Œç¾çš„å‡†ç¡®ç‡å’ŒF1åˆ†æ•°ï¼Œè€ŒCBDå’ŒNCCä¹Ÿå±•ç°äº†å¼ºå¤§çš„é˜²å¾¡æ€§èƒ½ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶é€šè¿‡åˆ†æä¸åŒå‚æ•°ä¸‹çš„æ¨¡å‹è¡¨ç°ï¼Œä¸ºè¿™äº›é˜²å¾¡æœºåˆ¶åœ¨å¤šå˜æ¡ä»¶ä¸‹çš„å®é™…åº”ç”¨æä¾›äº†æ·±å…¥çš„è§è§£ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.01276v1",
      "published_date": "2025-08-02 09:13:10 UTC",
      "updated_date": "2025-08-02 09:13:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:22:47.041930+00:00"
    },
    {
      "arxiv_id": "2508.01274v1",
      "title": "Multi-TW: Benchmarking Multimodal Models on Traditional Chinese Question Answering in Taiwan",
      "title_zh": "Multi-TWï¼šé’ˆå¯¹ Taiwan ç¹ä½“ä¸­æ–‡é—®ç­”çš„å¤šæ¨¡æ€æ¨¡å‹åŸºå‡†æµ‹è¯•",
      "authors": [
        "Jui-Ming Yao",
        "Bing-Cheng Xie",
        "Sheng-Wei Peng",
        "Hao-Yuan Chen",
        "He-Rong Zheng",
        "Bing-Jia Tan",
        "Peter Shaojui Wang",
        "Shun-Feng Su"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) process visual, acoustic, and textual inputs, addressing the limitations of single-modality LLMs. However, existing benchmarks often overlook tri-modal evaluation in Traditional Chinese and do not consider inference latency. To address this, we introduce Multi-TW, the first Traditional Chinese benchmark for evaluating the performance and latency of any-to-any multimodal models. Multi-TW includes 900 multiple-choice questions (image and text, audio and text pairs) sourced from official proficiency tests developed with the Steering Committee for the Test of Proficiency-Huayu (SC-TOP). We evaluated various any-to-any models and vision-language models (VLMs) with audio transcription. Our results show that closed-source models generally outperform open-source ones across modalities, although open-source models can perform well in audio tasks. End-to-end any-to-any pipelines offer clear latency advantages compared to VLMs using separate audio transcription. Multi-TW presents a comprehensive view of model capabilities and highlights the need for Traditional Chinese fine-tuning and efficient multimodal architectures.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Multi-TWï¼Œè¿™æ˜¯é¦–ä¸ªä¸“é—¨ç”¨äºè¯„ä¼°å°æ¹¾ç¹ä½“ä¸­æ–‡ (Traditional Chinese) ç¯å¢ƒä¸‹å…¨æ¨¡æ€æ¨¡å‹ (any-to-any multimodal models) æ€§èƒ½ä¸æ¨ç†å»¶è¿Ÿçš„åŸºå‡†æµ‹è¯•é›†ã€‚è¯¥åŸºå‡†åŒ…å« 900 é“å¤šé¡¹é€‰æ‹©é¢˜ï¼Œæ¶µç›–å›¾åƒä¸æ–‡æœ¬ã€éŸ³é¢‘ä¸æ–‡æœ¬å¯¹ï¼Œç´ æå‡æºè‡ªå›½å®¶åè¯­æµ‹éªŒæ¨åŠ¨å§”å‘˜ä¼š (SC-TOP) çš„å®˜æ–¹èƒ½åŠ›æµ‹è¯•ã€‚ç ”ç©¶é€šè¿‡è¯„ä¼°å¤šç§å…¨æ¨¡æ€æ¨¡å‹ä¸è§†è§‰è¯­è¨€æ¨¡å‹ (VLMs) å‘ç°ï¼Œé—­æºæ¨¡å‹åœ¨å„æ¨¡æ€è¡¨ç°æ™®éä¼˜äºå¼€æºæ¨¡å‹ï¼Œä½†å¼€æºæ¨¡å‹åœ¨éŸ³é¢‘ä»»åŠ¡ä¸­ä¹Ÿå…·å¤‡ç«äº‰åŠ›ã€‚æ­¤å¤–ï¼Œå®éªŒè¯æ˜ç«¯åˆ°ç«¯ (End-to-end) æ¶æ„ç›¸æ¯”ç»“åˆéŸ³é¢‘è½¬å½•çš„æ¨¡å‹åœ¨æ¨ç†å»¶è¿Ÿä¸Šå…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚Multi-TW ä¸ºå…¨é¢ç†è§£æ¨¡å‹èƒ½åŠ›æä¾›äº†è§†è§’ï¼Œå¹¶å¼ºè°ƒäº†é’ˆå¯¹ç¹ä½“ä¸­æ–‡è¿›è¡Œå¾®è°ƒ (fine-tuning) åŠä¼˜åŒ–å¤šæ¨¡æ€æ¶æ„çš„ç´§è¿«æ€§ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.01274v1",
      "published_date": "2025-08-02 09:10:15 UTC",
      "updated_date": "2025-08-02 09:10:15 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:23:03.041847+00:00"
    },
    {
      "arxiv_id": "2508.01273v2",
      "title": "KCR: Resolving Long-Context Knowledge Conflicts via Reasoning in LLMs",
      "title_zh": "KCRï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹æ¨ç†åŒ–è§£é•¿ä¸Šä¸‹æ–‡çŸ¥è¯†å†²çª",
      "authors": [
        "Xianda Zheng",
        "Zijian Huang",
        "Meng-Fen Chiang",
        "Michael J. Witbrock",
        "Kaiqi Zhao"
      ],
      "abstract": "Knowledge conflicts commonly arise across diverse sources, and their prevalence has increased with the advent of LLMs. When dealing with conflicts between multiple contexts, also known as \\emph{inter-context knowledge conflicts}, LLMs are often confused by lengthy and conflicting contexts. To address this challenge, we propose the Knowledge Conflict Reasoning (KCR) framework, which enhances the ability of LLMs to resolve conflicting knowledge. The key idea of KCR is to train backbone LLMs to establish a correct reasoning process by rewarding them for selecting and adhering to the context with stronger logical consistency when presented with conflicting contexts. Specifically, we first extract reasoning paths, represented by either text or local knowledge graphs, from the conflicting long contexts. Subsequently, we employ Reinforcement Learning to encourage the model to learn the paradigm of reasoning process that follows correct reasoning paths rather than the incorrect counterparts. This enables the backbone models to genuinely acquire the capability to resolve inter-context knowledge conflicts within long contexts. Experimental results demonstrate that our framework significantly improves the ability of various backbone models to resolve knowledge conflicts in long-context scenarios, yielding substantial performance gains.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†KCRï¼ˆKnowledge Conflict Reasoningï¼‰æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤„ç†é•¿æ–‡æœ¬æ—¶é¢ä¸´çš„è¯­å¢ƒé—´çŸ¥è¯†å†²çªï¼ˆinter-context knowledge conflictsï¼‰é—®é¢˜ã€‚è¯¥æ¡†æ¶çš„æ ¸å¿ƒæ€æƒ³æ˜¯é€šè¿‡å¥–åŠ±æ¨¡å‹é€‰æ‹©é€»è¾‘ä¸€è‡´æ€§æ›´å¼ºçš„ä¸Šä¸‹æ–‡ï¼Œè®­ç»ƒéª¨å¹²æ¨¡å‹å»ºç«‹æ­£ç¡®çš„æ¨ç†è¿‡ç¨‹ã€‚å…·ä½“è€Œè¨€ï¼ŒKCRé¦–å…ˆä»å†²çªçš„é•¿æ–‡æœ¬ä¸­æå–ä»¥æ–‡æœ¬æˆ–å±€éƒ¨çŸ¥è¯†å›¾è°±ï¼ˆlocal knowledge graphsï¼‰è¡¨ç¤ºçš„æ¨ç†è·¯å¾„ã€‚éšåï¼Œåˆ©ç”¨å¼ºåŒ–å­¦ä¹ ï¼ˆReinforcement Learningï¼‰å¼•å¯¼æ¨¡å‹å­¦ä¹ å¹¶éµå¾ªæ­£ç¡®çš„æ¨ç†èŒƒå¼ï¼Œä»è€Œä½¿å…¶çœŸæ­£å…·å¤‡åœ¨å¤æ‚é•¿æ–‡æœ¬ä¸­è§£æå†²çªçš„èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶æ˜¾è‘—å¢å¼ºäº†å¤šç§éª¨å¹²æ¨¡å‹åœ¨é•¿æ–‡æœ¬åœºæ™¯ä¸‹è§£å†³çŸ¥è¯†å†²çªçš„è¡¨ç°ï¼Œå¹¶å–å¾—äº†å®è´¨æ€§çš„æ€§èƒ½æå‡ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.01273v2",
      "published_date": "2025-08-02 09:09:50 UTC",
      "updated_date": "2025-08-05 11:26:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:22:57.931683+00:00"
    },
    {
      "arxiv_id": "2508.01268v1",
      "title": "Win-k: Improved Membership Inference Attacks on Small Language Models",
      "title_zh": "Win-kï¼šé’ˆå¯¹å°è¯­è¨€æ¨¡å‹çš„æ”¹è¿›å‹æˆå‘˜æ¨ç†æ”»å‡»",
      "authors": [
        "Roya Arkhmammadova",
        "Hosein Madadi Tamar",
        "M. Emre Gursoy"
      ],
      "abstract": "Small language models (SLMs) are increasingly valued for their efficiency and deployability in resource-constrained environments, making them useful for on-device, privacy-sensitive, and edge computing applications. On the other hand, membership inference attacks (MIAs), which aim to determine whether a given sample was used in a model's training, are an important threat with serious privacy and intellectual property implications. In this paper, we study MIAs on SLMs. Although MIAs were shown to be effective on large language models (LLMs), they are relatively less studied on emerging SLMs, and furthermore, their effectiveness decreases as models get smaller. Motivated by this finding, we propose a new MIA called win-k, which builds on top of a state-of-the-art attack (min-k). We experimentally evaluate win-k by comparing it with five existing MIAs using three datasets and eight SLMs. Results show that win-k outperforms existing MIAs in terms of AUROC, TPR @ 1% FPR, and FPR @ 99% TPR metrics, especially on smaller models.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†é’ˆå¯¹å°å‹è¯­è¨€æ¨¡å‹ (Small Language Models, SLMs) çš„æˆå‘˜æ¨ç†æ”»å‡» (Membership Inference Attacks, MIAs)ï¼Œè¿™ç±»æ”»å‡»å¯¹éšç§ä¿æŠ¤å’ŒçŸ¥è¯†äº§æƒæ„æˆäº†ä¸¥é‡å¨èƒã€‚è™½ç„¶ MIAs åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) ä¸Šå·²è¢«è¯æ˜éå¸¸æœ‰æ•ˆï¼Œä½†åœ¨æ–°å…´çš„ SLMs é¢†åŸŸç ”ç©¶ç›¸å¯¹è¾ƒå°‘ï¼Œä¸”æ”»å‡»æœ‰æ•ˆæ€§å¾€å¾€éšæ¨¡å‹è§„æ¨¡å‡å°è€Œé™ä½ã€‚é’ˆå¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œä½œè€…æå‡ºäº†ä¸€ç§åä¸º win-k çš„æ–°å‹æ”»å‡»æ–¹æ³•ï¼Œè¯¥æ–¹æ³•åœ¨æœ€å…ˆè¿›çš„ min-k æ”»å‡»åŸºç¡€ä¸Šè¿›è¡Œäº†æ”¹è¿›ã€‚ç ”ç©¶äººå‘˜åœ¨ä¸‰ä¸ªæ•°æ®é›†å’Œå…«ä¸ª SLMs ä¸Šå°† win-k ä¸äº”ç§ç°æœ‰çš„ MIAs è¿›è¡Œäº†å®éªŒå¯¹æ¯”ã€‚ç»“æœè¡¨æ˜ï¼Œwin-k åœ¨ AUROCã€TPR @ 1% FPR å’Œ FPR @ 99% TPR ç­‰å…³é”®æŒ‡æ ‡ä¸Šå‡ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œå°¤å…¶æ˜¯åœ¨è§„æ¨¡æ›´å°çš„æ¨¡å‹ä¸Šè¡¨ç°å°¤ä¸ºçªå‡ºã€‚è¿™ä¸€å‘ç°ä¸ºè¯„ä¼° SLMs çš„å®‰å…¨è¾¹ç•Œæä¾›äº†æ–°è§è§£ï¼Œå¹¶å¼ºè°ƒäº†åœ¨è¾¹ç¼˜è®¡ç®—å’Œç§»åŠ¨ç«¯åº”ç”¨ä¸­åŠ å¼ºéšç§ä¿æŠ¤çš„å¿…è¦æ€§ã€‚",
      "categories": [
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.01268v1",
      "published_date": "2025-08-02 08:50:42 UTC",
      "updated_date": "2025-08-02 08:50:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:23:04.047606+00:00"
    },
    {
      "arxiv_id": "2508.01263v1",
      "title": "Bridging LLMs and Symbolic Reasoning in Educational QA Systems: Insights from the XAI Challenge at IJCNN 2025",
      "title_zh": "æ•™è‚²é—®ç­”ç³»ç»Ÿä¸­å¤§è¯­è¨€æ¨¡å‹ä¸ç¬¦å·æ¨ç†çš„èåˆï¼šIJCNN 2025 XAI æŒ‘æˆ˜èµ›çš„å¯ç¤º",
      "authors": [
        "Long S. T. Nguyen",
        "Khang H. N. Vo",
        "Thu H. A. Nguyen",
        "Tuan C. Bui",
        "Duc Q. Nguyen",
        "Thanh-Tung Tran",
        "Anh D. Nguyen",
        "Minh L. Nguyen",
        "Fabien Baldacci",
        "Thang H. Bui",
        "Emanuel Di Nardo",
        "Angelo Ciaramella",
        "Son H. Le",
        "Ihsan Ullah",
        "Lorenzo Di Rocco",
        "Tho T. Quan"
      ],
      "abstract": "The growing integration of Artificial Intelligence (AI) into education has intensified the need for transparency and interpretability. While hackathons have long served as agile environments for rapid AI prototyping, few have directly addressed eXplainable AI (XAI) in real-world educational contexts. This paper presents a comprehensive analysis of the XAI Challenge 2025, a hackathon-style competition jointly organized by Ho Chi Minh City University of Technology (HCMUT) and the International Workshop on Trustworthiness and Reliability in Neurosymbolic AI (TRNS-AI), held as part of the International Joint Conference on Neural Networks (IJCNN 2025). The challenge tasked participants with building Question-Answering (QA) systems capable of answering student queries about university policies while generating clear, logic-based natural language explanations. To promote transparency and trustworthiness, solutions were required to use lightweight Large Language Models (LLMs) or hybrid LLM-symbolic systems. A high-quality dataset was provided, constructed via logic-based templates with Z3 validation and refined through expert student review to ensure alignment with real-world academic scenarios. We describe the challenge's motivation, structure, dataset construction, and evaluation protocol. Situating the competition within the broader evolution of AI hackathons, we argue that it represents a novel effort to bridge LLMs and symbolic reasoning in service of explainability. Our findings offer actionable insights for future XAI-centered educational systems and competitive research initiatives.",
      "tldr_zh": "è¯¥è®ºæ–‡è¯¦ç»†åˆ†æäº†åœ¨ IJCNN 2025 ä¸¾åŠçš„ XAI Challengeï¼Œæ¢è®¨äº†æ•™è‚²é¢†åŸŸ AI åº”ç”¨ä¸­é€æ˜åº¦ä¸å¯è§£é‡Šæ€§çš„é‡è¦æ€§ã€‚æŒ‘æˆ˜èµ›è¦æ±‚å‚èµ›è€…åˆ©ç”¨è½»é‡çº§ Large Language Models (LLMs) æˆ– hybrid LLM-symbolic ç³»ç»Ÿå¼€å‘ Question-Answering (QA) å¹³å°ï¼Œä»¥å›ç­”å¤§å­¦æ”¿ç­–æŸ¥è¯¢å¹¶ç”Ÿæˆé€»è¾‘åŒ–çš„è§£é‡Šã€‚ç ”ç©¶é‡‡ç”¨åŸºäºé€»è¾‘æ¨¡æ¿å’Œ Z3 validation çš„æ–¹æ³•æ„å»ºé«˜è´¨é‡æ•°æ®é›†ï¼Œå¹¶ç»“åˆä¸“å®¶è¯„å®¡ç¡®ä¿å…¶è´´åˆçœŸå®æ ¡å›­åœºæ™¯ã€‚è®ºæ–‡ç³»ç»Ÿæè¿°äº†ç«èµ›çš„ç»„ç»‡æ¶æ„ä¸è¯„ä¼°åè®®ï¼Œå¼ºè°ƒäº†å°† LLMs ä¸ symbolic reasoning ç»“åˆåœ¨å¢å¼ºç³»ç»Ÿè§£é‡Šæ€§æ–¹é¢çš„æ ¸å¿ƒä½œç”¨ã€‚ç ”ç©¶å‘ç°ä¸ºæœªæ¥å¼€å‘ä»¥ eXplainable AI (XAI) ä¸ºä¸­å¿ƒçš„æ•™è‚²ç³»ç»Ÿå’Œæ¨è¿›ç«äº‰æ€§ç ”ç©¶å€¡è®®æä¾›äº†å…³é”®çš„å®è·µè§è§£ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.CL",
      "comment": "The XAI Challenge @ TRNS-AI Workshop, IJCNN 2025: Explainable AI for Educational Question Answering. Website: https://sites.google.com/view/trns-ai/challenge/",
      "pdf_url": "https://arxiv.org/pdf/2508.01263v1",
      "published_date": "2025-08-02 08:46:06 UTC",
      "updated_date": "2025-08-02 08:46:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:23:17.851566+00:00"
    },
    {
      "arxiv_id": "2508.09148v1",
      "title": "Motif 2.6B Technical Report",
      "title_zh": "Motif 2.6B æŠ€æœ¯æŠ¥å‘Š",
      "authors": [
        "Junghwan Lim",
        "Sungmin Lee",
        "Dongseok Kim",
        "Eunhwan Park",
        "Hyunbyung Park",
        "Junhyeok Lee",
        "Wai Ting Cheung",
        "Dahye Choi",
        "Jaeheui Her",
        "Jaeyeon Huh",
        "Hanbin Jung",
        "Changjin Kang",
        "Beomgyu Kim",
        "Jihwan Kim",
        "Minjae Kim",
        "Taehwan Kim",
        "Youngrok Kim",
        "Haesol Lee",
        "Jeesoo Lee",
        "Kungyu Lee",
        "Dongpin Oh",
        "Yeongjae Park",
        "Bokki Ryu",
        "Daewon Suh",
        "Dongjoo Weon"
      ],
      "abstract": "Recent advancements in Large Language Models (LLMs) have revolutionized artificial intelligence, yet developing an effective foundational LLM that balances high performance with computational efficiency remains challenging, especially for emerging research groups. To address this gap, we introduce Motif-2.6B, a 2.6-billion-parameter foundation model designed to democratize advanced LLM capabilities. Motif-2.6B incorporates several innovative architectural enhancements, including Differential Attention and PolyNorm activation functions, which improve long-context comprehension, reduce hallucination, and enhance in-context learning capabilities. We rigorously tested multiple novel architectural components through extensive experimentation to determine the optimal architecture for Motif-2.6B. Comprehensive evaluations demonstrate that Motif-2.6B consistently meets or exceeds the performance of similarly sized state-of-the-art models across diverse benchmarks, showcasing its effectiveness, scalability, and real-world applicability. Through detailed experiments and tailored techniques, Motif-2.6B significantly advances the landscape of efficient, scalable, and powerful foundational LLMs, offering valuable insights and a robust foundation for future research and deployment.",
      "tldr_zh": "è¯¥ç ”ç©¶å‘å¸ƒäº†Motif-2.6Bï¼Œä¸€ä¸ªæ‹¥æœ‰26äº¿å‚æ•°çš„åŸºåº§å¤§è¯­è¨€æ¨¡å‹(LLM)ï¼Œæ—¨åœ¨å¹³è¡¡é«˜æ€§èƒ½ä¸è®¡ç®—æ•ˆç‡ã€‚æ¨¡å‹å¼•å…¥äº†Differential Attentionå’ŒPolyNormæ¿€æ´»å‡½æ•°ç­‰æ¶æ„åˆ›æ–°ï¼Œæœ‰æ•ˆæå‡äº†é•¿æ–‡æœ¬ç†è§£åŠ›ã€é™ä½äº†å¹»è§‰å¹¶å¼ºåŒ–äº†In-context learningèƒ½åŠ›ã€‚é€šè¿‡å¯¹å¤šç§æ–°å‹æ¶æ„ç»„ä»¶çš„ä¸¥æ ¼å®éªŒï¼Œç ”ç©¶è€…ç¡®å®šäº†Motif-2.6Bçš„æœ€ä¼˜é…ç½®ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMotif-2.6Båœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å±•ç°å‡ºä¸åŒè§„æ¨¡SOTAæ¨¡å‹æŒå¹³ç”šè‡³æ›´ä¼˜çš„æ€§èƒ½ã€‚è¯¥ç ”ç©¶ä¸ä»…æ¨åŠ¨äº†é«˜æ•ˆã€å¯æ‰©å±•åŸºåº§æ¨¡å‹çš„å‘å±•ï¼Œè¿˜ä¸ºæœªæ¥çš„æ¨¡å‹ç ”ç©¶ä¸éƒ¨ç½²æä¾›äº†å®è´µçš„æŠ€æœ¯åŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09148v1",
      "published_date": "2025-08-02 08:41:47 UTC",
      "updated_date": "2025-08-02 08:41:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:23:13.348058+00:00"
    },
    {
      "arxiv_id": "2508.01261v1",
      "title": "Unifying Mixture of Experts and Multi-Head Latent Attention for Efficient Language Models",
      "title_zh": "èåˆæ··åˆä¸“å®¶æ¨¡å‹ä¸å¤šå¤´æ½œå˜é‡æ³¨æ„åŠ›çš„é«˜æ•ˆè¯­è¨€æ¨¡å‹",
      "authors": [
        "Sushant Mehta",
        "Raj Dandekar",
        "Rajat Dandekar",
        "Sreedath Panat"
      ],
      "abstract": "We present MoE-MLA-RoPE, a novel architecture combination that combines Mixture of Experts (MoE) with Multi-head Latent Attention (MLA) and Rotary Position Embeddings (RoPE) for efficient language modeling. Our approach addresses the fundamental trade-off between model capacity and computational efficiency through three key innovations: (1) fine-grained expert routing with 64 micro-experts and top-$k$ selection, enabling flexible specialization through 3.6 * 10^7 possible expert combinations; (2) shared expert isolation that dedicates 2 always active experts for common patterns while routing to 6 of 62 specialized experts; and (3) gradient-conflict-free load balancing that maintains expert utilization without interfering with primary loss optimization.\n  Extensive experiments on models ranging from 17M to 202M parameters demonstrate that MoE-MLA-RoPE with compression ratio r=d/2 achieves 68% KV cache memory reduction and 3.2x inference speedup while maintaining competitive perplexity (0.8% degradation). Compared to the parameters with 53.9M parameters, MoE-MLA-RoPE improves the validation loss by 6.9% over the vanilla transformers while using 42% fewer active parameters per forward pass. FLOP-matched experiments reveal even larger gains: 11.1% improvement with 3.2x inference acceleration. Automated evaluation using GPT-4 as a judge confirms quality improvements in generation, with higher scores on coherence (8.1/10), creativity (7.9/10) and grammatical correctness (8.2/10). Our results establish that architectural novelty, not parameter scaling, defines the efficiency frontier for resource-constrained language model deployment.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† MoE-MLA-RoPEï¼Œè¿™æ˜¯ä¸€ç§å°† Mixture of Experts (MoE) ä¸ Multi-head Latent Attention (MLA) åŠ Rotary Position Embeddings (RoPE) ç›¸ç»“åˆçš„æ–°å‹æ¶æ„ï¼Œæ—¨åœ¨è§£å†³è¯­è¨€æ¨¡å‹åœ¨å®¹é‡ä¸è®¡ç®—æ•ˆç‡ä¹‹é—´çš„æƒè¡¡é—®é¢˜ã€‚è¯¥æ–¹æ³•å¼•å…¥äº†ä¸‰å¤§æ ¸å¿ƒåˆ›æ–°ï¼šé‡‡ç”¨åŒ…å« 64 ä¸ªå¾®å‹ä¸“å®¶çš„ç»†ç²’åº¦è·¯ç”±æœºåˆ¶ä»¥å®ç°çµæ´»çš„ä¸“ä¸šåŒ–åˆ†å·¥ï¼›é€šè¿‡å…±äº«ä¸“å®¶éš”ç¦»æŠ€æœ¯ç¡®ä¿å¸¸é©»ä¸“å®¶ä¸ä¸“ä¸šä¸“å®¶çš„ååŒå·¥ä½œï¼›ä»¥åŠåº”ç”¨æ— æ¢¯åº¦å†²çªçš„è´Ÿè½½å‡è¡¡ç­–ç•¥æ¥ä¼˜åŒ–ä¸“å®¶åˆ©ç”¨ç‡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMoE-MLA-RoPE åœ¨å‹ç¼©æ¯”ä¸º r=d/2 çš„æƒ…å†µä¸‹ï¼Œå®ç°äº† 68% çš„ KV cache å†…å­˜ç¼©å‡å’Œ 3.2 å€çš„æ¨ç†åŠ é€Ÿï¼ŒåŒæ—¶ä¿æŒäº†æå…·ç«äº‰åŠ›çš„å›°æƒ‘åº¦ã€‚åœ¨ä¸å‚æ•°é‡ç›¸è¿‘çš„ vanilla Transformer å¯¹æ¯”ä¸­ï¼Œè¯¥æ¶æ„ä¸ä»…å°†éªŒè¯æŸå¤±é™ä½äº† 6.9%ï¼Œè¿˜å‡å°‘äº† 42% çš„å‰å‘ä¼ æ’­æ¿€æ´»å‚æ•°ã€‚åŸºäº GPT-4 çš„è‡ªåŠ¨åŒ–è¯„ä¼°è¿›ä¸€æ­¥è¯å®äº†å…¶åœ¨ç”Ÿæˆè¿è´¯æ€§ã€åˆ›æ„åŠè¯­æ³•æ­£ç¡®æ€§æ–¹é¢çš„è´¨é‡æå‡ã€‚è¿™é¡¹ç ”ç©¶æœ‰åŠ›åœ°è¯æ˜äº†æ¶æ„åˆ›æ–°è€Œéå•çº¯çš„å‚æ•°è§„æ¨¡æ‰©å¼ ï¼Œæ‰æ˜¯å®šä¹‰èµ„æºå—é™ç¯å¢ƒä¸‹è¯­è¨€æ¨¡å‹æ•ˆç‡è¾¹ç•Œçš„å…³é”®ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.01261v1",
      "published_date": "2025-08-02 08:33:30 UTC",
      "updated_date": "2025-08-02 08:33:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:23:32.166989+00:00"
    },
    {
      "arxiv_id": "2508.01249v3",
      "title": "AgentArmor: Enforcing Program Analysis on Agent Runtime Trace to Defend Against Prompt Injection",
      "title_zh": "AgentArmorï¼šé€šè¿‡å¯¹æ™ºèƒ½ä½“è¿è¡Œæ—¶è¿½è¸ªå®æ–½ç¨‹åºåˆ†æé˜²å¾¡æç¤ºè¯æ³¨å…¥",
      "authors": [
        "Peiran Wang",
        "Yang Liu",
        "Yunfei Lu",
        "Yifeng Cai",
        "Hongbo Chen",
        "Qingyou Yang",
        "Jie Zhang",
        "Jue Hong",
        "Ye Wu"
      ],
      "abstract": "Large Language Model (LLM) agents offer a powerful new paradigm for solving various problems by combining natural language reasoning with the execution of external tools. However, their dynamic and non-transparent behavior introduces critical security risks, particularly in the presence of prompt injection attacks. In this work, we propose a novel insight that treats the agent runtime traces as structured programs with analyzable semantics. Thus, we present AgentArmor, a program analysis framework that converts agent traces into graph intermediate representation-based structured program dependency representations (e.g., CFG, DFG, and PDG) and enforces security policies via a type system. AgentArmor consists of three key components: (1) a graph constructor that reconstructs the agent's runtime traces as graph-based intermediate representations with control and data flow described within; (2) a property registry that attaches security-relevant metadata of interacted tools \\& data, and (3) a type system that performs static inference and checking over the intermediate representation. By representing agent behavior as structured programs, AgentArmor enables program analysis for sensitive data flow, trust boundaries, and policy violations. We evaluate AgentArmor on the AgentDojo benchmark, the results show that AgentArmor can reduce the ASR to 3\\%, with the utility drop only 1\\%.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLM)æ™ºèƒ½ä½“åœ¨é¢å¯¹æç¤ºæ³¨å…¥æ”»å‡»(Prompt Injection)æ—¶çš„å®‰å…¨é£é™©ï¼Œæå‡ºäº†AgentArmoræ¡†æ¶ã€‚è¯¥æ¡†æ¶çš„æ ¸å¿ƒåˆ›æ–°åœ¨äºå°†æ™ºèƒ½ä½“çš„è¿è¡Œæ—¶è¿½è¸ª(Runtime Trace)è§†ä¸ºå…·æœ‰å¯åˆ†æè¯­ä¹‰çš„ç»“æ„åŒ–ç¨‹åºï¼Œä»è€Œå¼•å…¥ç¨‹åºåˆ†ææŠ€æœ¯è¿›è¡Œé˜²å¾¡ã€‚AgentArmoråŒ…å«ä¸€ä¸ªå›¾æ„é€ å™¨ï¼Œèƒ½å°†è¿è¡Œæ—¶è¿½è¸ªé‡æ„ä¸ºåŒ…å«æ§åˆ¶æµå’Œæ•°æ®æµçš„å›¾ä¸­é—´è¡¨ç¤º(Graph IR)ï¼Œå¦‚CFGã€DFGå’ŒPDGã€‚æ­¤å¤–ï¼Œæ¡†æ¶ç»“åˆäº†å±æ€§æ³¨å†Œè¡¨ä»¥é™„åŠ å®‰å…¨ç›¸å…³çš„å…ƒæ•°æ®ï¼Œå¹¶é€šè¿‡ç±»å‹ç³»ç»Ÿ(Type System)å¯¹ä¸­é—´è¡¨ç¤ºè¿›è¡Œé™æ€æ¨ç†å’Œæ£€æŸ¥ã€‚é€šè¿‡å°†æ™ºèƒ½ä½“è¡Œä¸ºç¨‹åºåŒ–ï¼ŒAgentArmorèƒ½å¤Ÿæœ‰æ•ˆè¯†åˆ«æ•æ„Ÿæ•°æ®æµã€ä¿¡ä»»è¾¹ç•ŒåŠç­–ç•¥è¿è§„æƒ…å†µã€‚åœ¨AgentDojoåŸºå‡†æµ‹è¯•ä¸Šçš„è¯„ä¼°ç»“æœæ˜¾ç¤ºï¼ŒAgentArmorèƒ½å°†æ”»å‡»æˆåŠŸç‡(ASR)é™ä½è‡³3%ï¼Œè€Œæ•ˆç”¨ä¸‹é™(Utility Drop)ä»…ä¸º1%ï¼Œè¯æ˜äº†å…¶åœ¨ä¿éšœæ™ºèƒ½ä½“å®‰å…¨æ–¹é¢çš„å“è¶Šæ€§èƒ½ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.01249v3",
      "published_date": "2025-08-02 07:59:34 UTC",
      "updated_date": "2025-11-18 03:57:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:23:40.057125+00:00"
    },
    {
      "arxiv_id": "2508.06528v1",
      "title": "A Framework Combining 3D CNN and Transformer for Video-Based Behavior Recognition",
      "title_zh": "èåˆ 3D CNN ä¸ Transformer çš„è§†é¢‘è¡Œä¸ºè¯†åˆ«æ¡†æ¶",
      "authors": [
        "Xiuliang Zhang",
        "Tadiwa Elisha Nyamasvisva",
        "Chuntao Liu"
      ],
      "abstract": "Video-based behavior recognition is essential in fields such as public safety, intelligent surveillance, and human-computer interaction. Traditional 3D Convolutional Neural Network (3D CNN) effectively capture local spatiotemporal features but struggle with modeling long-range dependencies. Conversely, Transformers excel at learning global contextual information but face challenges with high computational costs. To address these limitations, we propose a hybrid framework combining 3D CNN and Transformer architectures. The 3D CNN module extracts low-level spatiotemporal features, while the Transformer module captures long-range temporal dependencies, with a fusion mechanism integrating both representations. Evaluated on benchmark datasets, the proposed model outperforms traditional 3D CNN and standalone Transformers, achieving higher recognition accuracy with manageable complexity. Ablation studies further validate the complementary strengths of the two modules. This hybrid framework offers an effective and scalable solution for video-based behavior recognition.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§ç»“åˆ 3D CNN å’Œ Transformer æ¶æ„çš„æ··åˆæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³åŸºäºè§†é¢‘çš„è¡Œä¸ºè¯†åˆ«ä¸­å±€éƒ¨ç‰¹å¾æå–ä¸é•¿ç¨‹ä¾èµ–ï¼ˆlong-range dependenciesï¼‰å»ºæ¨¡ä¹‹é—´çš„çŸ›ç›¾ã€‚è¯¥æ¡†æ¶åˆ©ç”¨ 3D CNN æ¨¡å—æå–ä½å±‚çº§çš„æ—¶ç©ºç‰¹å¾ï¼ˆspatiotemporal featuresï¼‰ï¼Œå¹¶é€šè¿‡ Transformer æ¨¡å—æ•æ‰å…¨å±€çš„é•¿ç¨‹æ—¶é—´ä¾èµ–ï¼Œæœ€åç»ç”±èåˆæœºåˆ¶ï¼ˆfusion mechanismï¼‰é›†æˆä¸¤ç§è¡¨å¾ã€‚åœ¨åŸºå‡†æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ··åˆæ¨¡å‹åœ¨ä¿æŒå¯æ§å¤æ‚åº¦çš„å‰æä¸‹ï¼Œå…¶è¯†åˆ«å‡†ç¡®ç‡ä¼˜äºä¼ ç»Ÿçš„ 3D CNN å’Œç‹¬ç«‹ Transformerã€‚æ¶ˆèå®éªŒï¼ˆAblation studiesï¼‰è¿›ä¸€æ­¥è¯å®äº†ä¸¤ä¸ªæ¨¡å—ä¹‹é—´çš„ä¼˜åŠ¿äº’è¡¥ï¼Œä¸ºæ™ºèƒ½ç›‘æ§å’Œäººæœºäº¤äº’ç­‰é¢†åŸŸçš„è§†é¢‘è¡Œä¸ºè¯†åˆ«æä¾›äº†ä¸€ç§é«˜æ•ˆä¸”å¯æ‰©å±•çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages,6 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.06528v1",
      "published_date": "2025-08-02 07:33:29 UTC",
      "updated_date": "2025-08-02 07:33:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:23:37.855666+00:00"
    },
    {
      "arxiv_id": "2508.01237v1",
      "title": "SketchAgent: Generating Structured Diagrams from Hand-Drawn Sketches",
      "title_zh": "SketchAgentï¼šä»æ‰‹ç»˜è‰å›¾ç”Ÿæˆç»“æ„åŒ–å›¾è¡¨",
      "authors": [
        "Cheng Tan",
        "Qi Chen",
        "Jingxuan Wei",
        "Gaowei Wu",
        "Zhangyang Gao",
        "Siyuan Li",
        "Bihui Yu",
        "Ruifeng Guo",
        "Stan Z. Li"
      ],
      "abstract": "Hand-drawn sketches are a natural and efficient medium for capturing and conveying ideas. Despite significant advancements in controllable natural image generation, translating freehand sketches into structured, machine-readable diagrams remains a labor-intensive and predominantly manual task. The primary challenge stems from the inherent ambiguity of sketches, which lack the structural constraints and semantic precision required for automated diagram generation. To address this challenge, we introduce SketchAgent, a multi-agent system designed to automate the transformation of hand-drawn sketches into structured diagrams. SketchAgent integrates sketch recognition, symbolic reasoning, and iterative validation to produce semantically coherent and structurally accurate diagrams, significantly reducing the need for manual effort. To evaluate the effectiveness of our approach, we propose the Sketch2Diagram Benchmark, a comprehensive dataset and evaluation framework encompassing eight diverse diagram categories, such as flowcharts, directed graphs, and model architectures. The dataset comprises over 6,000 high-quality examples with token-level annotations, standardized preprocessing, and rigorous quality control. By streamlining the diagram generation process, SketchAgent holds great promise for applications in design, education, and engineering, while offering a significant step toward bridging the gap between intuitive sketching and machine-readable diagram generation. The benchmark is released at https://huggingface.co/datasets/DiagramAgent/Sketch2Diagram-Benchmark.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å°†æ‰‹ç»˜è‰å›¾è½¬æ¢ä¸ºç»“æ„åŒ–ã€æœºå™¨å¯è¯»å›¾è¡¨æ—¶å­˜åœ¨çš„æ­§ä¹‰æ€§å’Œè¯­ä¹‰ç²¾åº¦ä¸è¶³ç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº† SketchAgent å¤šæ™ºèƒ½ä½“ç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿé€šè¿‡æ•´åˆè‰å›¾è¯†åˆ« (sketch recognition)ã€ç¬¦å·æ¨ç† (symbolic reasoning) å’Œè¿­ä»£éªŒè¯ (iterative validation)ï¼Œå®ç°äº†ä»è‡ªç”±æ‰‹ç»˜åˆ°ç²¾ç¡®å›¾è¡¨çš„è‡ªåŠ¨åŒ–è½¬æ¢ï¼Œå¤§å¹…å‡å°‘äº†æ‰‹åŠ¨æ“ä½œçš„éœ€æ±‚ã€‚ä¸ºäº†è¯„ä¼°è¯¥ç³»ç»Ÿï¼Œç ”ç©¶å›¢é˜Ÿæ„å»ºäº† Sketch2Diagram Benchmarkï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å«æµç¨‹å›¾ã€ç³»ç»Ÿæ¶æ„å›¾ç­‰å…«å¤§ç±»åˆ«ã€è¶…è¿‡ 6,000 ä¸ªå¸¦æ³¨é‡Šç¤ºä¾‹çš„ç»¼åˆæ•°æ®é›†ã€‚å®éªŒè¯æ˜ SketchAgent èƒ½å¤Ÿç”Ÿæˆè¯­ä¹‰è¿è´¯ä¸”ç»“æ„å‡†ç¡®çš„å›¾è¡¨ï¼Œåœ¨è®¾è®¡ã€æ•™è‚²å’Œå·¥ç¨‹ç­‰é¢†åŸŸå…·æœ‰å¹¿é˜”çš„åº”ç”¨å‰æ™¯ï¼Œä¸ºå¼¥åˆç›´è§‚ç»˜å›¾ä¸æœºå™¨å¯è¯»ç”Ÿæˆä¹‹é—´çš„å·®è·è¿ˆå‡ºäº†é‡è¦ä¸€æ­¥ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by IJCAI 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.01237v1",
      "published_date": "2025-08-02 07:22:51 UTC",
      "updated_date": "2025-08-02 07:22:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:23:50.751480+00:00"
    },
    {
      "arxiv_id": "2508.01225v2",
      "title": "Multi-Cache Enhanced Prototype Learning for Test-Time Generalization of Vision-Language Models",
      "title_zh": "é¢å‘è§†è§‰-è¯­è¨€æ¨¡å‹æµ‹è¯•æ—¶æ³›åŒ–çš„å¤šç¼“å­˜å¢å¼ºåŸå‹å­¦ä¹ ",
      "authors": [
        "Xinyu Chen",
        "Haotian Zhai",
        "Can Zhang",
        "Xiupeng Shi",
        "Ruirui Li"
      ],
      "abstract": "In zero-shot setting, test-time adaptation adjusts pre-trained models using unlabeled data from the test phase to enhance performance on unknown test distributions. Existing cache-enhanced TTA methods rely on a low-entropy criterion to select samples for prototype construction, assuming intra-class compactness. However, low-entropy samples may be unreliable under distribution shifts, and the resulting prototypes may not ensure compact intra-class distributions. This study identifies a positive correlation between cache-enhanced performance and intra-class compactness. Based on this observation, we propose a Multi-Cache enhanced Prototype-based Test-Time Adaptation (MCP) featuring three caches: an entropy cache for initializing prototype representations with low-entropy samples, an align cache for integrating visual and textual information to achieve compact intra-class distributions, and a negative cache for prediction calibration using high-entropy samples. We further developed MCP++, a framework incorporating cross-modal prototype alignment and residual learning, introducing prototype residual fine-tuning. Comparative and ablation experiments across 15 downstream tasks demonstrate that the proposed method and framework achieve state-of-the-art generalization performance. Project Page available at: https://zhaihaotian.github.io/MCP-ICCV25/",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é›¶æ ·æœ¬(zero-shot)è®¾ç½®ä¸‹çš„æµ‹è¯•æ—¶è‡ªé€‚åº”(Test-Time Adaptation, TTA)é—®é¢˜ï¼ŒæŒ‡å‡ºä¼ ç»Ÿçš„ä½ç†µæ ‡å‡†åœ¨åˆ†å¸ƒåç§»æ—¶æ„å»ºåŸå‹(prototypes)å…·æœ‰ä¸å¯é æ€§ï¼Œä¸”éš¾ä»¥ä¿è¯ç±»å†…åˆ†å¸ƒçš„ç´§å‡‘æ€§ã€‚é€šè¿‡è¯†åˆ«ç¼“å­˜å¢å¼ºæ€§èƒ½ä¸ç±»å†…ç´§å‡‘æ€§ä¹‹é—´çš„æ­£ç›¸å…³å…³ç³»ï¼Œä½œè€…æå‡ºäº†å¤šç¼“å­˜å¢å¼ºåŸå‹æµ‹è¯•æ—¶è‡ªé€‚åº”æ¡†æ¶(MCP)ï¼Œåˆ©ç”¨ç†µç¼“å­˜(entropy cache)åˆå§‹åŒ–åŸå‹ã€å¯¹é½ç¼“å­˜(align cache)æ•´åˆè§†è§‰æ–‡æœ¬ä¿¡æ¯ä»¥åŠè´Ÿç¼“å­˜(negative cache)è¿›è¡Œé¢„æµ‹æ ¡å‡†ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œç ”ç©¶è¿›ä¸€æ­¥å¼€å‘äº†MCP++æ¡†æ¶ï¼Œé›†æˆäº†è·¨æ¨¡æ€åŸå‹å¯¹é½(cross-modal prototype alignment)ä¸æ®‹å·®å­¦ä¹ (residual learning)æŠ€æœ¯ï¼Œå¹¶å¼•å…¥äº†åŸå‹æ®‹å·®å¾®è°ƒ(prototype residual fine-tuning)æœºåˆ¶ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨15ä¸ªä¸‹æ¸¸ä»»åŠ¡ä¸­è¡¨ç°å“è¶Šï¼Œåœ¨è§†è§‰è¯­è¨€æ¨¡å‹çš„æµ‹è¯•æ—¶æ³›åŒ–æ€§èƒ½ä¸Šè¾¾åˆ°äº†å½“å‰æœ€å…ˆè¿›æ°´å¹³(state-of-the-art)ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ICCV 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.01225v2",
      "published_date": "2025-08-02 06:43:43 UTC",
      "updated_date": "2025-08-21 20:13:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:23:43.840497+00:00"
    },
    {
      "arxiv_id": "2508.01222v1",
      "title": "WebDS: An End-to-End Benchmark for Web-based Data Science",
      "title_zh": "WebDSï¼šåŸºäº Web çš„æ•°æ®ç§‘å­¦ç«¯åˆ°ç«¯åŸºå‡†",
      "authors": [
        "Ethan Hsu",
        "Hong Meng Yam",
        "Ines Bouissou",
        "Aaron Murali John",
        "Raj Thota",
        "Josh Koe",
        "Vivek Sarath Putta",
        "G K Dharesan",
        "Alexander Spangher",
        "Shikhar Murty",
        "Tenghao Huang",
        "Christopher D. Manning"
      ],
      "abstract": "A large portion of real-world data science tasks are complex and require multi-hop web-based interactions: finding appropriate data available on the internet, synthesizing real-time data of various modalities from different locations, and producing summarized analyses. Existing web benchmarks often focus on simplistic interactions, such as form submissions or e-commerce transactions, and often do not require diverse tool-using capabilities required for web based data science. Conversely, traditional data science benchmarks typically concentrate on static, often textually bound datasets and do not assess end-to-end workflows that encompass data acquisition, cleaning, analysis, and insight generation. In response, we introduce WebDS, the first end-to-end web-based data science benchmark. It comprises 870 web-based data science tasks across 29 diverse websites from structured government data portals to unstructured news media, challenging agents to perform complex, multi-step operations requiring the use of tools and heterogeneous data formats that better reflect the realities of modern data analytics. Evaluations of current SOTA LLM agents indicate significant performance gaps in accomplishing these tasks. For instance, Browser Use, which accomplishes 80% of tasks on Web Voyager, successfully completes only 15% of tasks in WebDS, which our analysis suggests is due to new failure modes like poor information grounding, repetitive behavior and shortcut-taking that agents performing WebDS' tasks display. By providing a more robust and realistic testing ground, WebDS sets the stage for significant advances in the development of practically useful LLM-based data science.",
      "tldr_zh": "è¯¥ç ”ç©¶æŒ‡å‡ºäº†ç°æœ‰WebåŸºå‡†æµ‹è¯•è¿‡äºç®€åŒ–ä¸”ä¼ ç»Ÿæ•°æ®ç§‘å­¦(Data Science)åŸºå‡†æµ‹è¯•å±€é™äºé™æ€æ•°æ®é›†ï¼Œéš¾ä»¥è¯„ä¼°çœŸå®ä¸–ç•Œä¸­å¤æ‚çš„å¤šè·³ç½‘ç»œäº¤äº’ä»»åŠ¡ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†WebDSï¼Œè¿™æ˜¯é¦–ä¸ªé’ˆå¯¹åŸºäºWebçš„æ•°æ®ç§‘å­¦çš„ç«¯åˆ°ç«¯(End-to-End)åŸºå‡†æµ‹è¯•ã€‚è¯¥åŸºå‡†åŒ…å«è·¨29ä¸ªä¸åŒç½‘ç«™çš„870ä¸ªä»»åŠ¡ï¼ŒæŒ‘æˆ˜æ™ºèƒ½ä½“åˆ©ç”¨å·¥å…·å¤„ç†å¼‚æ„æ•°æ®æ ¼å¼å¹¶æ‰§è¡Œå¤æ‚çš„å¤šæ­¥æ“ä½œã€‚å¯¹å½“å‰æœ€å…ˆè¿›çš„LLMæ™ºèƒ½ä½“è¿›è¡Œçš„è¯„ä¼°æ˜¾ç¤ºå‡ºæ˜¾è‘—çš„æ€§èƒ½å·®è·ï¼Œä¾‹å¦‚Browser Useåœ¨WebDSä¸Šçš„ä»»åŠ¡æˆåŠŸç‡ä»…ä¸º15%ã€‚åˆ†ææ­ç¤ºäº†æ™ºèƒ½ä½“åœ¨æ‰§è¡Œä»»åŠ¡æ—¶å­˜åœ¨ä¿¡æ¯å®šä½ä¸å‡†ç¡®(Poor information grounding)ã€é‡å¤è¡Œä¸ºå’ŒæŠ•æœºå–å·§ç­‰æ•…éšœæ¨¡å¼ã€‚WebDSä¸ºå¼€å‘å®é™…å¯ç”¨çš„åŸºäºå¤§è¯­è¨€æ¨¡å‹(LLM-based)çš„æ•°æ®ç§‘å­¦å·¥å…·æä¾›äº†æ›´å…·æŒ‘æˆ˜æ€§ä¸”çœŸå®çš„æµ‹è¯•ç¯å¢ƒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages",
      "pdf_url": "https://arxiv.org/pdf/2508.01222v1",
      "published_date": "2025-08-02 06:39:59 UTC",
      "updated_date": "2025-08-02 06:39:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:23:48.143148+00:00"
    },
    {
      "arxiv_id": "2508.09147v1",
      "title": "Agentic TinyML for Intent-aware Handover in 6G Wireless Networks",
      "title_zh": "é¢å‘ 6G æ— çº¿ç½‘ç»œæ„å›¾æ„ŸçŸ¥åˆ‡æ¢çš„æ™ºèƒ½ä½“åŒ– TinyML",
      "authors": [
        "Alaa Saleh",
        "Roberto Morabito",
        "Sasu Tarkoma",
        "Anders Lindgren",
        "Susanna Pirttikangas",
        "Lauri LovÃ©n"
      ],
      "abstract": "As 6G networks evolve into increasingly AI-driven, user-centric ecosystems, traditional reactive handover mechanisms demonstrate limitations, especially in mobile edge computing and autonomous agent-based service scenarios. This manuscript introduces WAAN, a cross-layer framework that enables intent-aware and proactive handovers by embedding lightweight TinyML agents as autonomous, negotiation-capable entities across heterogeneous edge nodes that contribute to intent propagation and network adaptation. To ensure continuity across mobility-induced disruptions, WAAN incorporates semi-stable rendezvous points that serve as coordination anchors for context transfer and state preservation. The framework's operational capabilities are demonstrated through a multimodal environmental control case study, highlighting its effectiveness in maintaining user experience under mobility. Finally, the article discusses key challenges and future opportunities associated with the deployment and evolution of WAAN.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹6Gç½‘ç»œä¸­ä¼ ç»Ÿååº”å¼åˆ‡æ¢æœºåˆ¶åœ¨ç§»åŠ¨è¾¹ç¼˜è®¡ç®—å’Œè‡ªä¸»æ™ºèƒ½ä½“åœºæ™¯ä¸‹çš„å±€é™æ€§ï¼Œæå‡ºäº†WAANè·¨å±‚æ¡†æ¶ï¼Œæ—¨åœ¨å®ç°æ„å›¾æ„ŸçŸ¥(intent-aware)å’Œä¸»åŠ¨åˆ‡æ¢(proactive handovers)ã€‚è¯¥æ¡†æ¶é€šè¿‡åœ¨å¼‚æ„è¾¹ç¼˜èŠ‚ç‚¹åµŒå…¥è½»é‡çº§çš„TinyMLæ™ºèƒ½ä½“ï¼Œä½¿å…¶ä½œä¸ºå…·æœ‰è‡ªä¸»åå•†èƒ½åŠ›çš„å®ä½“æ¥æ¨åŠ¨æ„å›¾ä¼ æ’­å’Œç½‘ç»œè‡ªé€‚åº”ã€‚ä¸ºäº†è§£å†³ç§»åŠ¨æ€§å¼•å‘çš„ä¸šåŠ¡ä¸­æ–­é—®é¢˜ï¼ŒWAANå¼•å…¥äº†åŠç¨³å®šæ±‡åˆç‚¹(semi-stable rendezvous points)ä½œä¸ºåè°ƒé”šç‚¹ï¼Œä»¥æ”¯æŒä¸Šä¸‹æ–‡ä¼ è¾“å’ŒçŠ¶æ€ä¿ç•™ã€‚å®éªŒé€šè¿‡ä¸€ä¸ªå¤šæ¨¡æ€ç¯å¢ƒæ§åˆ¶æ¡ˆä¾‹ç ”ç©¶ï¼ŒéªŒè¯äº†è¯¥æ¡†æ¶åœ¨ä¿éšœç§»åŠ¨çŠ¶æ€ä¸‹ç”¨æˆ·ä½“éªŒæ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚æ­¤å¤–ï¼Œæ–‡ç« è¿˜æ¢è®¨äº†WAANåœ¨æœªæ¥éƒ¨ç½²ä¸æ¼”è¿›è¿‡ç¨‹ä¸­é¢ä¸´çš„å…³é”®æŒ‘æˆ˜ä¸æœºé‡ã€‚",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.DC",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09147v1",
      "published_date": "2025-08-02 06:13:42 UTC",
      "updated_date": "2025-08-02 06:13:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:24:00.842182+00:00"
    },
    {
      "arxiv_id": "2508.01209v1",
      "title": "Oldie but Goodie: Re-illuminating Label Propagation on Graphs with Partially Observed Features",
      "title_zh": "å†ä¹…å¼¥æ–°ï¼šç‰¹å¾éƒ¨åˆ†è§‚æµ‹ä¸‹çš„å›¾æ ‡ç­¾ä¼ æ’­æœºåˆ¶å†æ¢",
      "authors": [
        "Sukwon Yun",
        "Xin Liu",
        "Yunhak Oh",
        "Junseok Lee",
        "Tianlong Chen",
        "Tsuyoshi Murata",
        "Chanyoung Park"
      ],
      "abstract": "In real-world graphs, we often encounter missing feature situations where a few or the majority of node features, e.g., sensitive information, are missed. In such scenarios, directly utilizing Graph Neural Networks (GNNs) would yield sub-optimal results in downstream tasks such as node classification. Despite the emergence of a few GNN-based methods attempting to mitigate its missing situation, when only a few features are available, they rather perform worse than traditional structure-based models. To this end, we propose a novel framework that further illuminates the potential of classical Label Propagation (Oldie), taking advantage of Feature Propagation, especially when only a partial feature is available. Now called by GOODIE, it takes a hybrid approach to obtain embeddings from the Label Propagation branch and Feature Propagation branch. To do so, we first design a GNN-based decoder that enables the Label Propagation branch to output hidden embeddings that align with those of the FP branch. Then, GOODIE automatically captures the significance of structure and feature information thanks to the newly designed Structure-Feature Attention. Followed by a novel Pseudo-Label contrastive learning that differentiates the contribution of each positive pair within pseudo-labels originating from the LP branch, GOODIE outputs the final prediction for the unlabeled nodes. Through extensive experiments, we demonstrate that our proposed model, GOODIE, outperforms the existing state-of-the-art methods not only when only a few features are available but also in abundantly available situations. Source code of GOODIE is available at: https://github.com/SukwonYun/GOODIE.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å›¾æ•°æ®ä¸­èŠ‚ç‚¹ç‰¹å¾éƒ¨åˆ†ç¼ºå¤±å¯¼è‡´å›¾ç¥ç»ç½‘ç»œ(GNNs)æ€§èƒ½å—æŸçš„é—®é¢˜ï¼Œæå‡ºäº†åä¸ºGOODIEçš„åˆ›æ–°æ¡†æ¶ï¼Œæ—¨åœ¨é‡æ–°å‘æ˜ç»å…¸æ ‡ç­¾ä¼ æ’­(Label Propagation)åœ¨ç‰¹å¾è§‚å¯Ÿä¸è¶³æ—¶çš„æ½œåŠ›ã€‚GOODIEé‡‡ç”¨äº†ç»“åˆæ ‡ç­¾ä¼ æ’­åˆ†æ”¯ä¸ç‰¹å¾ä¼ æ’­(Feature Propagation)åˆ†æ”¯çš„æ··åˆæ–¹æ³•ï¼Œå¹¶è®¾è®¡äº†ä¸“é—¨çš„GNNè§£ç å™¨æ¥ç¡®ä¿ä¸¤ä¸ªåˆ†æ”¯ç”Ÿæˆçš„éšè—åµŒå…¥å®ç°å¯¹é½ã€‚ä¸ºäº†å¹³è¡¡ä¸åŒä¿¡æ¯æºï¼Œè¯¥æ¡†æ¶é€šè¿‡ç»“æ„-ç‰¹å¾æ³¨æ„åŠ›(Structure-Feature Attention)æœºåˆ¶è‡ªåŠ¨æ•æ‰å›¾ç»“æ„ä¸èŠ‚ç‚¹ç‰¹å¾çš„ç›¸å¯¹é‡è¦æ€§ã€‚æ­¤å¤–ï¼Œç ”ç©¶å¼•å…¥äº†ä¸€ç§ä¼ªæ ‡ç­¾å¯¹æ¯”å­¦ä¹ (Pseudo-Label contrastive learning)ç­–ç•¥ï¼Œç”¨ä»¥ç»†åŒ–åŒºåˆ†æ ‡ç­¾ä¼ æ’­äº§ç”Ÿçš„ä¼ªæ ‡ç­¾åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­çš„å…·ä½“è´¡çŒ®ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒGOODIEåœ¨ç‰¹å¾ç¨€ç–å’Œç‰¹å¾å……è¶³çš„å¤šç§åœºæ™¯ä¸‹å‡ä¼˜äºç°æœ‰çš„æœ€å…ˆè¿›æ–¹æ³•ï¼Œæœ‰æ•ˆæå‡äº†èŠ‚ç‚¹åˆ†ç±»ç­‰ä¸‹æ¸¸ä»»åŠ¡çš„å‡†ç¡®æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "KDD 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.01209v1",
      "published_date": "2025-08-02 05:50:41 UTC",
      "updated_date": "2025-08-02 05:50:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:23:56.038520+00:00"
    },
    {
      "arxiv_id": "2508.01208v1",
      "title": "Calibrated Prediction Set in Fault Detection with Risk Guarantees via Significance Tests",
      "title_zh": "åŸºäºæ˜¾è‘—æ€§æ£€éªŒä¸”å…·å¤‡é£é™©ä¿è¯çš„æ•…éšœæ£€æµ‹æ ¡å‡†é¢„æµ‹é›†",
      "authors": [
        "Mingchen Mei",
        "Yi Li",
        "YiYao Qian",
        "Zijun Jia"
      ],
      "abstract": "Fault detection is crucial for ensuring the safety and reliability of modern industrial systems. However, a significant scientific challenge is the lack of rigorous risk control and reliable uncertainty quantification in existing diagnostic models, particularly when facing complex scenarios such as distributional shifts. To address this issue, this paper proposes a novel fault detection method that integrates significance testing with the conformal prediction framework to provide formal risk guarantees. The method transforms fault detection into a hypothesis testing task by defining a nonconformity measure based on model residuals. It then leverages a calibration dataset to compute p-values for new samples, which are used to construct prediction sets mathematically guaranteed to contain the true label with a user-specified probability, $1-Î±$. Fault classification is subsequently performed by analyzing the intersection of the constructed prediction set with predefined normal and fault label sets. Experimental results on cross-domain fault diagnosis tasks validate the theoretical properties of our approach. The proposed method consistently achieves an empirical coverage rate at or above the nominal level ($1-Î±$), demonstrating robustness even when the underlying point-prediction models perform poorly. Furthermore, the results reveal a controllable trade-off between the user-defined risk level ($Î±$) and efficiency, where higher risk tolerance leads to smaller average prediction set sizes. This research contributes a theoretically grounded framework for fault detection that enables explicit risk control, enhancing the trustworthiness of diagnostic systems in safety-critical applications and advancing the field from simple point predictions to informative, uncertainty-aware outputs.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å·¥ä¸šç³»ç»Ÿæ•…éšœæ£€æµ‹(Fault Detection)ä¸­ç°æœ‰è¯Šæ–­æ¨¡å‹ç¼ºä¹ä¸¥æ ¼é£é™©æ§åˆ¶å’Œå¯é ä¸ç¡®å®šæ€§é‡åŒ–(Uncertainty Quantification)çš„é—®é¢˜ï¼Œç‰¹åˆ«æ˜¯åœ¨é¢ä¸´åˆ†å¸ƒåç§»(Distributional Shifts)ç­‰å¤æ‚åœºæ™¯æ—¶ã€‚æå‡ºäº†ä¸€ç§ç»“åˆæ˜¾è‘—æ€§æ£€éªŒ(Significance Testing)ä¸ç¬¦åˆé¢„æµ‹æ¡†æ¶(Conformal Prediction Framework)çš„æ–°å‹æ•…éšœæ£€æµ‹æ–¹æ³•ï¼Œæ—¨åœ¨æä¾›æ­£å¼çš„é£é™©ä¿è¯ã€‚è¯¥æ–¹æ³•é€šè¿‡å®šä¹‰åŸºäºæ¨¡å‹æ®‹å·®çš„éç¬¦åˆæ€§åº¦é‡(Nonconformity Measure)ï¼Œå°†æ•…éšœæ£€æµ‹ä»»åŠ¡è½¬åŒ–ä¸ºå‡è®¾æ£€éªŒ(Hypothesis Testing)ï¼Œå¹¶åˆ©ç”¨æ ¡å‡†æ•°æ®é›†(Calibration Dataset)è®¡ç®—på€¼ä»¥æ„å»ºé¢„æµ‹é›†(Prediction Sets)ï¼Œåœ¨æ•°å­¦ä¸Šä¿è¯çœŸå®æ ‡ç­¾ä»¥$1-Î±$çš„æ¦‚ç‡åŒ…å«åœ¨å†…ã€‚è·¨é¢†åŸŸæ•…éšœè¯Šæ–­å®éªŒéªŒè¯äº†è¯¥æ–¹æ³•çš„ç†è®ºç‰¹æ€§ï¼Œå…¶ç»éªŒè¦†ç›–ç‡ä¸€è‡´è¾¾åˆ°æˆ–è¶…è¿‡åä¹‰æ°´å¹³ï¼Œå³ä½¿åœ¨åŸºç¡€ç‚¹é¢„æµ‹æ¨¡å‹è¡¨ç°ä¸ä½³æ—¶ä»å±•ç°å‡ºæå¼ºçš„é²æ£’æ€§(Robustness)ã€‚ç ”ç©¶è¿˜æ­ç¤ºäº†é£é™©æ°´å¹³($Î±$)ä¸æ•ˆç‡ä¹‹é—´å­˜åœ¨å¯æ§çš„æƒè¡¡å…³ç³»ï¼Œå³è¾ƒé«˜çš„é£é™©å®¹å¿åº¦èƒ½æ¢å–æ›´å°çš„é¢„æµ‹é›†è§„æ¨¡ã€‚è¯¥æ¡†æ¶ä¸ºæ•…éšœæ£€æµ‹æä¾›äº†ç†è®ºæ”¯æ’‘çš„é£é™©æ§åˆ¶æ‰‹æ®µï¼Œå¢å¼ºäº†å®‰å…¨å…³é”®åº”ç”¨ä¸­è¯Šæ–­ç³»ç»Ÿçš„å¯ä¿¡åº¦ï¼ŒæˆåŠŸå°†ä¼ ç»Ÿçš„ç‚¹é¢„æµ‹æå‡ä¸ºå…·æœ‰ä¸ç¡®å®šæ€§æ„ŸçŸ¥èƒ½åŠ›çš„è¾“å‡ºã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.01208v1",
      "published_date": "2025-08-02 05:49:02 UTC",
      "updated_date": "2025-08-02 05:49:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:24:01.836550+00:00"
    },
    {
      "arxiv_id": "2508.01206v1",
      "title": "Deep Learning for Pavement Condition Evaluation Using Satellite Imagery",
      "title_zh": "åŸºäºå«æ˜Ÿå½±åƒçš„æ·±åº¦å­¦ä¹ è·¯é¢çŠ¶å†µè¯„ä¼°",
      "authors": [
        "Prathyush Kumar Reddy Lebaku",
        "Lu Gao",
        "Pan Lu",
        "Jingran Sun"
      ],
      "abstract": "Civil infrastructure systems covers large land areas and needs frequent inspections to maintain their public service capabilities. The conventional approaches of manual surveys or vehicle-based automated surveys to assess infrastructure conditions are often labor-intensive and time-consuming. For this reason, it is worthwhile to explore more cost-effective methods for monitoring and maintaining these infrastructures. Fortunately, recent advancements in satellite systems and image processing algorithms have opened up new possibilities. Numerous satellite systems have been employed to monitor infrastructure conditions and identify damages. Due to the improvement in ground sample distance (GSD), the level of detail that can be captured has significantly increased. Taking advantage of these technology advancement, this research investigated to evaluate pavement conditions using deep learning models for analyzing satellite images. We gathered over 3,000 satellite images of pavement sections, together with pavement evaluation ratings from TxDOT's PMIS database. The results of our study show an accuracy rate is exceeding 90%. This research paves the way for a rapid and cost-effective approach to evaluating the pavement network in the future.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹ä¼ ç»Ÿäººå·¥æˆ–è½¦è½½è·¯é¢å·¡æ£€è€—æ—¶è€—åŠ›çš„é—®é¢˜ï¼Œæ¢ç´¢äº†åˆ©ç”¨å«æ˜Ÿé¥æ„Ÿå½±åƒè¿›è¡ŒåŸºç¡€è®¾æ–½ç›‘æµ‹çš„æ–°æ–¹æ³•ã€‚ç ”ç©¶å……åˆ†åˆ©ç”¨äº†å«æ˜Ÿç³»ç»Ÿåœ°é¢é‡‡æ ·è·ç¦»(Ground Sample Distance, GSD)æé«˜æ‰€å¸¦æ¥çš„ç»†èŠ‚ä¼˜åŠ¿ï¼Œé‡‡ç”¨æ·±åº¦å­¦ä¹ (Deep Learning)æ¨¡å‹å¯¹å«æ˜Ÿå›¾åƒè¿›è¡Œåˆ†æå¤„ç†ã€‚é€šè¿‡æ•´åˆè¶…è¿‡3000å¼ è·¯é¢å«æ˜Ÿå›¾åƒä»¥åŠæ¥è‡ªå¾·å…‹è¨æ–¯å·äº¤é€šéƒ¨(TxDOT)è·¯é¢ç®¡ç†ä¿¡æ¯ç³»ç»Ÿ(PMIS)çš„å®˜æ–¹è¯„çº§æ•°æ®ï¼Œè¯¥æ¨¡å‹åœ¨è¯„ä¼°è·¯é¢çŠ¶å†µæ—¶å®ç°äº†è¶…è¿‡90%çš„å‡†ç¡®ç‡ã€‚å®éªŒç»“æœè¯æ˜äº†åˆ©ç”¨é«˜åˆ†è¾¨ç‡å«æ˜Ÿå½±åƒè¿›è¡Œè‡ªåŠ¨åŒ–é“è·¯åˆ†æçš„å¯è¡Œæ€§ï¼Œä¸ºæœªæ¥æ„å»ºå¿«é€Ÿã€ä½æˆæœ¬çš„å¤§è§„æ¨¡è·¯é¢ç½‘ç»œè¯„ä¼°ä½“ç³»æä¾›äº†é‡è¦çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.01206v1",
      "published_date": "2025-08-02 05:43:33 UTC",
      "updated_date": "2025-08-02 05:43:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:24:03.847787+00:00"
    },
    {
      "arxiv_id": "2508.01205v1",
      "title": "Conquering High Packet-Loss Erasure: MoE Swin Transformer-Based Video Semantic Communication",
      "title_zh": "åº”å¯¹é«˜ä¸¢åŒ…æ“¦é™¤ï¼šåŸºäº MoE Swin Transformer çš„è§†é¢‘è¯­ä¹‰é€šä¿¡",
      "authors": [
        "Lei Teng",
        "Senran Fan",
        "Chen Dong",
        "Haotai Liang",
        "Zhicheng Bao",
        "Xiaodong Xu",
        "Rui Meng",
        "Ping Zhang"
      ],
      "abstract": "Semantic communication with joint semantic-channel coding robustly transmits diverse data modalities but faces challenges in mitigating semantic information loss due to packet drops in packet-based systems. Under current protocols, packets with errors are discarded, preventing the receiver from utilizing erroneous semantic data for robust decoding. To address this issue, a packet-loss-resistant MoE Swin Transformer-based Video Semantic Communication (MSTVSC) system is proposed in this paper. Semantic vectors are encoded by MSTVSC and transmitted through upper-layer protocol packetization. To investigate the impact of the packetization, a theoretical analysis of the packetization strategy is provided. To mitigate the semantic loss caused by packet loss, a 3D CNN at the receiver recovers missing information using un-lost semantic data and an packet-loss mask matrix. Semantic-level interleaving is employed to reduce concentrated semantic loss from packet drops. To improve compression, a common-individual decomposition approach is adopted, with downsampling applied to individual information to minimize redundancy. The model is lightweighted for practical deployment. Extensive simulations and comparisons demonstrate strong performance, achieving an MS-SSIM greater than 0.6 and a PSNR exceeding 20 dB at a 90% packet loss rate.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è¯­ä¹‰é€šä¿¡åœ¨åŸºäºæ•°æ®åŒ…çš„ä¼ è¾“ç³»ç»Ÿä¸­å› ä¸¢åŒ…å¯¼è‡´çš„è¯­ä¹‰ä¿¡æ¯ä¸¢å¤±é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§å…·æœ‰å¼ºæŠ—ä¸¢åŒ…æ€§èƒ½çš„ MoE Swin Transformer-based Video Semantic Communication (MSTVSC) ç³»ç»Ÿã€‚è¯¥æ–¹æ¡ˆå¯¹è¯­ä¹‰å‘é‡è¿›è¡Œç¼–ç å¹¶é€šè¿‡ä¸Šå±‚åè®®è¿›è¡Œåˆ†åŒ…ä¼ è¾“ï¼ŒåŒæ—¶å¯¹åˆ†åŒ…ç­–ç•¥è¿›è¡Œäº†æ·±å…¥çš„ç†è®ºåˆ†æã€‚ä¸ºäº†å‡è½»ä¸¢åŒ…å¸¦æ¥çš„è´Ÿé¢å½±å“ï¼Œæ¥æ”¶ç«¯é‡‡ç”¨ 3D CNN ç»“åˆä¸¢åŒ…æ©ç çŸ©é˜µ (packet-loss mask matrix) ä»æœªä¸¢å¤±çš„è¯­ä¹‰æ•°æ®ä¸­æ¢å¤ç¼ºå¤±ä¿¡æ¯ã€‚æ­¤å¤–ï¼Œç³»ç»Ÿå¼•å…¥äº†è¯­ä¹‰çº§äº¤ç»‡ (semantic-level interleaving) ä»¥å‡å°‘é›†ä¸­ä¸¢åŒ…æŸå¤±ï¼Œå¹¶é‡‡ç”¨å…±åŒ-ä¸ªä½“åˆ†è§£ (common-individual decomposition) åŠä¸‹é‡‡æ ·æ–¹æ³•æ¥ä¼˜åŒ–æ•°æ®å‹ç¼©å’Œå‡å°‘å†—ä½™ã€‚ä¸ºäº†ä¾¿äºå®é™…åº”ç”¨ï¼Œè¯¥æ¨¡å‹è¿˜è¿›è¡Œäº†è½»é‡åŒ–å¤„ç†ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒMSTVSC åœ¨é«˜è¾¾ 90% çš„ä¸¢åŒ…ç‡ä¸‹ä»èƒ½å®ç° MS-SSIM å¤§äº 0.6 å’Œ PSNR è¶…è¿‡ 20 dB çš„ä¼˜å¼‚è¡¨ç°ã€‚",
      "categories": [
        "cs.ET",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.ET",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.01205v1",
      "published_date": "2025-08-02 05:41:52 UTC",
      "updated_date": "2025-08-02 05:41:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:24:17.288526+00:00"
    },
    {
      "arxiv_id": "2508.01203v1",
      "title": "Importance Sampling is All You Need: Predict LLM's performance on new benchmark by reusing existing benchmark",
      "title_zh": "ä»…éœ€é‡è¦æ€§é‡‡æ ·ï¼šé€šè¿‡é‡ç”¨ç°æœ‰åŸºå‡†é¢„æµ‹å¤§è¯­è¨€æ¨¡å‹åœ¨æ–°åŸºå‡†ä¸Šçš„æ€§èƒ½",
      "authors": [
        "Junjie Shi",
        "Wei Ma",
        "Shi Ying",
        "Lingxiao Jiang",
        "Yang liu",
        "Bo Du"
      ],
      "abstract": "With the rapid advancement of large language models , code generation has become a key benchmark for evaluating LLM capabilities. However, existing benchmarks face two major challenges: (1) the escalating cost of constructing high-quality test suites and reference solutions, and (2) the increasing risk of data contamination, which undermines the reliability of benchmark-based evaluations. In this paper, we propose BIS, a prompt-centric evaluation framework that enables ground-truth-free prediction of LLM performance on code generation tasks. Rather than executing generated code, BIS estimates performance metrics by analyzing the prompt distribution alone. Built on importance sampling theory and implemented using Importance Weighted Autoencoders, our method reweights samples from existing annotated benchmarks to estimate performance on new, unseen benchmarks. To stabilize the estimation, we introduce weight truncation strategies and compute marginal expectations across the fitted distributions. BIS serves as a complementary tool that supports benchmark development and validation under constrained resources, offering actionable and quick feedback for prompt selection and contamination assessment. We conduct extensive experiments involving 8,000 evaluation points across 4 CodeLlama models and 9 diverse benchmarks. Our framework achieves an average absolute prediction error of 1.1% for code correctness scores, with best- and worst-case errors of 0.3% and 1.9%, respectively. It also generalizes well to other metrics, attaining average absolute errors of 2.15% for pass@1. These results demonstrate the reliability and broad applicability of BIS, which can significantly reduce the cost and effort of benchmarking LLMs in code-related tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†BISï¼Œä¸€ç§ä»¥æç¤ºè¯(Prompt)ä¸ºä¸­å¿ƒçš„è¯„ä¼°æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹(LLMs)ä»£ç ç”Ÿæˆä»»åŠ¡ä¸­é«˜æ˜‚çš„åŸºå‡†æµ‹è¯•æ„å»ºæˆæœ¬å’Œæ—¥ç›Šä¸¥é‡çš„æ•°æ®æ±¡æŸ“é—®é¢˜ã€‚è¯¥æ¡†æ¶æ ¸å¿ƒåŸºäºé‡è¦æ€§é‡‡æ ·(Importance Sampling)ç†è®ºå¹¶ç»“åˆé‡è¦æ€§åŠ æƒè‡ªåŠ¨ç¼–ç å™¨(Importance Weighted Autoencoders)å®ç°ï¼Œé€šè¿‡å¯¹ç°æœ‰å·²æ ‡æ³¨åŸºå‡†æµ‹è¯•æ ·æœ¬è¿›è¡Œé‡åŠ æƒï¼Œå®ç°åœ¨æ— éœ€çœŸå®æ ‡ç­¾(Ground-truth)çš„æƒ…å†µä¸‹é¢„æµ‹æ¨¡å‹åœ¨å…¨æ–°åŸºå‡†ä¸Šçš„æ€§èƒ½ã€‚ä¸ºäº†ç¡®ä¿é¢„æµ‹çš„ç¨³å®šæ€§ï¼Œç ”ç©¶å¼•å…¥äº†æƒé‡æˆªæ–­ç­–ç•¥å¹¶è®¡ç®—æ‹Ÿåˆåˆ†å¸ƒçš„è¾¹é™…æœŸæœ›ã€‚é’ˆå¯¹4ä¸ªCodeLlamaæ¨¡å‹åœ¨9ä¸ªåŸºå‡†æµ‹è¯•ä¸Šçš„å¤§è§„æ¨¡å®éªŒç»“æœè¡¨æ˜ï¼ŒBISåœ¨ä»£ç æ­£ç¡®æ€§å¾—åˆ†é¢„æµ‹ä¸Šçš„å¹³å‡ç»å¯¹è¯¯å·®ä»…ä¸º1.1%ï¼Œåœ¨pass@1æŒ‡æ ‡ä¸Šçš„å¹³å‡è¯¯å·®ä¸º2.15%ã€‚è¿™ä¸€æˆæœè¯æ˜äº†BISåœ¨é™ä½è¯„ä¼°æˆæœ¬æ–¹é¢çš„å¯é æ€§ï¼Œä¸ºæç¤ºè¯é€‰æ‹©å’Œæ±¡æŸ“è¯„ä¼°æä¾›äº†é«˜æ•ˆçš„åé¦ˆå·¥å…·ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.01203v1",
      "published_date": "2025-08-02 05:34:05 UTC",
      "updated_date": "2025-08-02 05:34:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:24:30.024152+00:00"
    },
    {
      "arxiv_id": "2508.01198v1",
      "title": "Adaptive Content Restriction for Large Language Models via Suffix Optimization",
      "title_zh": "åŸºäºåç¼€ä¼˜åŒ–çš„å¤§è¯­è¨€æ¨¡å‹è‡ªé€‚åº”å†…å®¹é™åˆ¶",
      "authors": [
        "Yige Li",
        "Peihai Jiang",
        "Jun Sun",
        "Peng Shu",
        "Tianming Liu",
        "Zhen Xiang"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated significant success across diverse applications. However, enforcing content restrictions remains a significant challenge due to their expansive output space. One aspect of content restriction is preventing LLMs from generating harmful content via model alignment approaches such as supervised fine-tuning (SFT). Yet, the need for content restriction may vary significantly across user groups, change rapidly over time, and not always align with general definitions of harmfulness. Applying SFT to each of these specific use cases is impractical due to the high computational, data, and storage demands. Motivated by this need, we propose a new task called \\textit{Adaptive Content Restriction} (AdaCoRe), which focuses on lightweight strategies -- methods without model fine-tuning -- to prevent deployed LLMs from generating restricted terms for specific use cases. We propose the first method for AdaCoRe, named \\textit{Suffix Optimization (SOP)}, which appends a short, optimized suffix to any prompt to a) prevent a target LLM from generating a set of restricted terms, while b) preserving the output quality. To evaluate AdaCoRe approaches, including our SOP, we create a new \\textit{Content Restriction Benchmark} (CoReBench), which contains 400 prompts for 80 restricted terms across 8 carefully selected categories. We demonstrate the effectiveness of SOP on CoReBench, which outperforms the system-level baselines such as system suffix by 15\\%, 17\\%, 10\\%, 9\\%, and 6\\% on average restriction rates for Gemma2-2B, Mistral-7B, Vicuna-7B, Llama3-8B, and Llama3.1-8B, respectively. We also demonstrate that SOP is effective on POE, an online platform hosting various commercial LLMs, highlighting its practicality in real-world scenarios.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)å†…å®¹é™åˆ¶éœ€æ±‚å¤šå˜ä¸”ç›‘ç£å¾®è°ƒ(SFT)æˆæœ¬é«˜æ˜‚çš„é—®é¢˜ï¼Œæå‡ºäº†è‡ªé€‚åº”å†…å®¹é™åˆ¶(Adaptive Content Restriction, AdaCoRe)ä»»åŠ¡ï¼Œæ¢ç´¢æ— éœ€å¾®è°ƒçš„è½»é‡åŒ–é˜²å¾¡ç­–ç•¥ã€‚ä½œè€…å¼€å‘äº†é¦–ä¸ªé’ˆå¯¹è¯¥ä»»åŠ¡çš„æ–¹æ³•â€”â€”åç¼€ä¼˜åŒ–(Suffix Optimization, SOP)ï¼Œé€šè¿‡åœ¨è¾“å…¥æç¤º(prompt)åé™„åŠ ç»è¿‡ä¼˜åŒ–çš„çŸ­åç¼€ï¼Œåœ¨æœ‰æ•ˆæ‹¦æˆªç‰¹å®šé™åˆ¶æœ¯è¯­çš„åŒæ—¶ä¿æŒæ¨¡å‹è¾“å‡ºè´¨é‡ã€‚ä¸ºäº†è¯„ä¼°è¯¥æ–¹æ³•ï¼Œç ”ç©¶è€…æ„å»ºäº†åŒ…å«400ä¸ªæµ‹è¯•ç”¨ä¾‹çš„CoReBenchåŸºå‡†æµ‹è¯•é›†ï¼Œè¦†ç›–8ä¸ªç²¾å¿ƒé€‰æ‹©çš„ç±»åˆ«ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒSOPåœ¨Gemma2ã€Mistralã€Vicunaä»¥åŠLlama3ç³»åˆ—æ¨¡å‹ä¸Šçš„å¹³å‡é™åˆ¶ç‡æ˜¾è‘—ä¼˜äºç³»ç»Ÿçº§åŸºå‡†ï¼Œæå‡å¹…åº¦è¾¾6%è‡³17%ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•åœ¨POEç­‰åœ¨çº¿å•†ä¸šå¹³å°ä¸Šçš„æˆåŠŸåº”ç”¨ï¼Œè¯æ˜äº†å…¶åœ¨å¤„ç†ç°å®ä¸–ç•Œå¤æ‚ç”¨ä¾‹æ—¶çš„å®ç”¨ä»·å€¼ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "19 pages",
      "pdf_url": "https://arxiv.org/pdf/2508.01198v1",
      "published_date": "2025-08-02 05:09:58 UTC",
      "updated_date": "2025-08-02 05:09:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:24:42.343554+00:00"
    },
    {
      "arxiv_id": "2508.01195v1",
      "title": "BSL: A Unified and Generalizable Multitask Learning Platform for Virtual Drug Discovery from Design to Synthesis",
      "title_zh": "BSLï¼šé¢å‘ä»è®¾è®¡åˆ°åˆæˆå…¨æµç¨‹è™šæ‹Ÿè¯ç‰©ç ”å‘çš„ç»Ÿä¸€ä¸”å¯æ³›åŒ–å¤šä»»åŠ¡å­¦ä¹ å¹³å°",
      "authors": [
        "Kun Li",
        "Zhennan Wu",
        "Yida Xiong",
        "Hongzhi Zhang",
        "Longtao Hu",
        "Zhonglie Liu",
        "Junqi Zeng",
        "Wenjie Wu",
        "Mukun Chen",
        "Jiameng Chen",
        "Wenbin Hu"
      ],
      "abstract": "Drug discovery is of great social significance in safeguarding human health, prolonging life, and addressing the challenges of major diseases. In recent years, artificial intelligence has demonstrated remarkable advantages in key tasks across bioinformatics and pharmacology, owing to its efficient data processing and data representation capabilities. However, most existing computational platforms cover only a subset of core tasks, leading to fragmented workflows and low efficiency. In addition, they often lack algorithmic innovation and show poor generalization to out-of-distribution (OOD) data, which greatly hinders the progress of drug discovery. To address these limitations, we propose Baishenglai (BSL), a deep learning-enhanced, open-access platform designed for virtual drug discovery. BSL integrates seven core tasks within a unified and modular framework, incorporating advanced technologies such as generative models and graph neural networks. In addition to achieving state-of-the-art (SOTA) performance on multiple benchmark datasets, the platform emphasizes evaluation mechanisms that focus on generalization to OOD molecular structures. Comparative experiments with existing platforms and baseline methods demonstrate that BSL provides a comprehensive, scalable, and effective solution for virtual drug discovery, offering both algorithmic innovation and high-precision prediction for real-world pharmaceutical research. In addition, BSL demonstrated its practical utility by discovering novel modulators of the GluN1/GluN3A NMDA receptor, successfully identifying three compounds with clear bioactivity in in-vitro electrophysiological assays. These results highlight BSL as a promising and comprehensive platform for accelerating biomedical research and drug discovery. The platform is accessible at https://www.baishenglai.net.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Baishenglai (BSL)ï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºæ·±åº¦å­¦ä¹ å¢å¼ºçš„å¼€æ”¾è·å–è™šæ‹Ÿè¯ç‰©ç ”å‘å¹³å°ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰å·¥å…·å·¥ä½œæµç¨‹ç¢ç‰‡åŒ–åŠåœ¨åˆ†å¸ƒå¤– (OOD) æ•°æ®ä¸Šæ³›åŒ–æ€§å·®çš„é—®é¢˜ã€‚BSL åœ¨ç»Ÿä¸€çš„æ¨¡å—åŒ–æ¡†æ¶ä¸­é›†æˆäº†ä¸ƒé¡¹æ ¸å¿ƒä»»åŠ¡ï¼Œå¹¶é‡‡ç”¨äº†ç”Ÿæˆæ¨¡å‹ (Generative Models) å’Œå›¾ç¥ç»ç½‘ç»œ (Graph Neural Networks) ç­‰å…ˆè¿›ç®—æ³•ã€‚è¯¥å¹³å°ä¸ä»…åœ¨å¤šä¸ªåŸºå‡†æ•°æ®é›†ä¸Šå–å¾—äº† SOTA æ€§èƒ½ï¼Œè¿˜é‡ç‚¹ä¼˜åŒ–äº†å¯¹ OOD åˆ†å­ç»“æ„çš„é¢„æµ‹å‡†ç¡®æ€§ã€‚å¯¹æ¯”å®éªŒè¯æ˜ï¼ŒBSL ä¸ºçœŸå®ä¸–ç•Œçš„è¯ç‰©ç ”ç©¶æä¾›äº†å…·å¤‡ç®—æ³•åˆ›æ–°æ€§ã€é«˜ç²¾åº¦ä¸”å¯æ‰©å±•çš„è§£å†³æ–¹æ¡ˆã€‚åœ¨å®é™…åº”ç”¨éªŒè¯ä¸­ï¼ŒBSL æˆåŠŸç­›é€‰å‡º GluN1/GluN3A NMDA å—ä½“çš„æ–°å‹è°ƒèŠ‚å‰‚ï¼Œå¹¶é€šè¿‡ä½“å¤–ç”µç”Ÿç†å®éªŒç¡®è®¤äº†ä¸‰ç§å…·æœ‰æ˜ç¡®ç”Ÿç‰©æ´»æ€§çš„åŒ–åˆç‰©ã€‚è¿™è¯æ˜äº† BSL æ˜¯ä¸€ä¸ªèƒ½å¤Ÿæ˜¾è‘—åŠ é€Ÿç”Ÿç‰©åŒ»å­¦ç ”ç©¶å’Œè¯ç‰©å‘ç°è¿›ç¨‹çš„ç»¼åˆæ€§å·¥å…·ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.01195v1",
      "published_date": "2025-08-02 04:58:56 UTC",
      "updated_date": "2025-08-02 04:58:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:24:25.145445+00:00"
    },
    {
      "arxiv_id": "2508.01191v4",
      "title": "Is Chain-of-Thought Reasoning of LLMs a Mirage? A Data Distribution Lens",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹çš„æ€ç»´é“¾æ¨ç†æ˜¯æµ·å¸‚èœƒæ¥¼å—ï¼ŸåŸºäºæ•°æ®åˆ†å¸ƒè§†è§’çš„è§£æ",
      "authors": [
        "Chengshuai Zhao",
        "Zhen Tan",
        "Pingchuan Ma",
        "Dawei Li",
        "Bohan Jiang",
        "Yancheng Wang",
        "Yingzhen Yang",
        "Huan Liu"
      ],
      "abstract": "Chain-of-Thought (CoT) prompting has been shown to be effective in eliciting structured reasoning (i.e., CoT reasoning) from large language models (LLMs). Regardless of its popularity, recent studies expose its failures in some reasoning tasks, raising fundamental questions about the nature of CoT reasoning. In this work, we propose a data distribution lens to understand when and why CoT reasoning succeeds or fails. We hypothesize that CoT reasoning reflects a structured inductive bias learned from in-distribution data, enabling models to conditionally generate reasoning trajectories that approximate those observed during training. As such, the effectiveness of CoT reasoning is fundamentally governed by the nature and degree of distribution discrepancy between training data and test queries. Guided by this lens, we dissect CoT reasoning via three dimensions: task, length, and format. To test the hypothesis, we introduce DataAlchemy, an abstract and fully controllable environment that trains LLMs from scratch and systematically probes them under various distribution conditions. Through rigorous controlled experiments, we reveal that CoT reasoning is a brittle mirage when it is pushed beyond training distributions, emphasizing the ongoing challenge of achieving genuine and generalizable reasoning.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ä¸­é“¾å¼æ€ç»´ï¼ˆChain-of-Thought, CoTï¼‰æ¨ç†çš„æœ¬è´¨ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªæ•°æ®åˆ†å¸ƒè§†è§’ï¼ˆData Distribution Lensï¼‰æ¥åˆ†æå…¶æˆåŠŸä¸å¤±è´¥çš„æ ¹æºã€‚ä½œè€…å‡è®¾ CoT æ¨ç†åæ˜ äº†æ¨¡å‹ä»åˆ†å¸ƒå†…ï¼ˆin-distributionï¼‰æ•°æ®ä¸­å­¦ä¹ åˆ°çš„ç»“æ„åŒ–å½’çº³åç½®ï¼Œå…¶æœ‰æ•ˆæ€§æœ¬è´¨ä¸Šå–å†³äºè®­ç»ƒæ•°æ®ä¸æµ‹è¯•æŸ¥è¯¢ä¹‹é—´çš„åˆ†å¸ƒå·®å¼‚ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶è€…å¼•å…¥äº† DataAlchemy è¿™ä¸€æŠ½è±¡ä¸”å®Œå…¨å¯æ§çš„ç¯å¢ƒï¼Œä»é›¶å¼€å§‹è®­ç»ƒ LLMs å¹¶ç³»ç»Ÿåœ°æµ‹è¯•å…¶åœ¨å„ç§åˆ†å¸ƒæ¡ä»¶ä¸‹çš„æ¨ç†èƒ½åŠ›ã€‚å®éªŒä»ä»»åŠ¡ã€é•¿åº¦å’Œæ ¼å¼ä¸‰ä¸ªç»´åº¦è¿›è¡Œäº†å‰–æï¼Œç»“æœè¡¨æ˜å½“æ¨ç†æ€§ä»»åŠ¡è¶…å‡ºè®­ç»ƒåˆ†å¸ƒæ—¶ï¼ŒCoT æ¨ç†è¡¨ç°å¾—åƒæ˜¯ä¸€ä¸ªè„†å¼±çš„â€œå¹»è±¡â€ï¼ˆMirageï¼‰ã€‚è¯¥ç ”ç©¶å¼ºè°ƒäº†å®ç°çœŸæ­£ä¸”å…·å¤‡æ³›åŒ–èƒ½åŠ›çš„æ¨ç†ä»ç„¶æ˜¯ä¸€ä¸ªæŒç»­çš„æŒ‘æˆ˜ï¼Œå¹¶æ­ç¤ºäº†å½“å‰ CoT æ¨ç†å¯¹æ•°æ®åˆ†å¸ƒçš„é«˜åº¦ä¾èµ–ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by the Foundations of Reasoning in Language Models (FoRLM) at NeurIPS 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.01191v4",
      "published_date": "2025-08-02 04:37:28 UTC",
      "updated_date": "2026-01-10 04:13:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:24:33.456517+00:00"
    },
    {
      "arxiv_id": "2508.11647v1",
      "title": "Categorical Construction of Logically Verifiable Neural Architectures",
      "title_zh": "é€»è¾‘å¯éªŒè¯ç¥ç»ç½‘ç»œæ¶æ„çš„èŒƒç•´è®ºæ„å»º",
      "authors": [
        "Logan Nye"
      ],
      "abstract": "Neural networks excel at pattern recognition but struggle with reliable logical reasoning, often violating basic logical principles during inference. We address this limitation by developing a categorical framework that systematically constructs neural architectures with provable logical guarantees. Our approach treats logical theories as algebraic structures called Lawvere theories, which we transform into neural networks using categorical algebra in the 2-category of parametric maps. Unlike existing methods that impose logical constraints during training, our categorical construction embeds logical principles directly into the network's architectural structure, making logical violations mathematically impossible. We demonstrate this framework by constructing differentiable neural architectures for propositional logic that preserve boolean reasoning while remaining trainable via gradient descent. Our main theoretical result establishes a bijective correspondence between finitary logical theories and neural architectures, proving that every logically constrained network arises uniquely from our construction. This extends Categorical Deep Learning beyond geometric symmetries to semantic constraints, enabling automatic derivation of verified architectures from logical specifications. The framework provides mathematical foundations for trustworthy AI systems, with applications to theorem proving, formal verification, and safety-critical reasoning tasks requiring verifiable logical behavior.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç¥ç»ç½‘ç»œåœ¨é€»è¾‘æ¨ç†ä¸­å­˜åœ¨å¯é æ€§ç¼ºå¤±åŠè¿ååŸºæœ¬é€»è¾‘åŸåˆ™çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§èƒ½å¤Ÿæ„å»ºå…·æœ‰å¯è¯æ˜é€»è¾‘ä¿è¯çš„ç¥ç»æ¶æ„çš„èŒƒç•´è®ºæ¡†æ¶ã€‚è¯¥æ–¹æ³•å°†é€»è¾‘ç†è®ºè§†ä¸ºåä¸º Lawvere theories çš„ä»£æ•°ç»“æ„ï¼Œå¹¶é€šè¿‡å‚æ•°æ˜ å°„ (parametric maps) çš„ 2-èŒƒç•´ (2-category) ä¸­çš„èŒƒç•´ä»£æ•°å°†å…¶è½¬åŒ–ä¸ºç¥ç»ç½‘ç»œã€‚ä¸åœ¨è®­ç»ƒæœŸé—´æ–½åŠ é€»è¾‘çº¦æŸçš„ç°æœ‰æ–¹æ³•ä¸åŒï¼Œè¯¥èŒƒç•´åŒ–æ„é€ å°†é€»è¾‘åŸåˆ™ç›´æ¥åµŒå…¥ç½‘ç»œæ¶æ„ä¸­ï¼Œä½¿é€»è¾‘è¿è§„åœ¨æ•°å­¦ä¸Šå˜å¾—ä¸å¯èƒ½ã€‚ç ”ç©¶å±•ç¤ºäº†ä¸ºå‘½é¢˜é€»è¾‘ (propositional logic) æ„å»ºçš„å¯å¾®ç¥ç»æ¶æ„ï¼Œåœ¨ä¿æŒå¸ƒå°”æ¨ç†çš„åŒæ—¶ä»å¯é€šè¿‡æ¢¯åº¦ä¸‹é™è¿›è¡Œè®­ç»ƒã€‚ä¸»è¦ç†è®ºæˆæœç¡®ç«‹äº†æœ‰é™é€»è¾‘ç†è®ºä¸ç¥ç»æ¶æ„ä¹‹é—´çš„åŒå°„å¯¹åº”å…³ç³»ï¼Œè¯æ˜äº†æ¯ä¸ªå—é€»è¾‘çº¦æŸçš„ç½‘ç»œéƒ½æºäºæ­¤æ„é€ ã€‚è¯¥æ¡†æ¶å°†èŒƒç•´æ·±åº¦å­¦ä¹  (Categorical Deep Learning) ä»å‡ ä½•å¯¹ç§°æ‰©å±•åˆ°è¯­ä¹‰çº¦æŸï¼Œä¸ºå®šç†è¯æ˜å’Œå®‰å…¨å…³é”®å‹æ¨ç†ä»»åŠ¡ç­‰éœ€è¦å¯éªŒè¯é€»è¾‘è¡Œä¸ºçš„å¯ä¿¡ AI ç³»ç»Ÿå¥ å®šäº†æ•°å­¦åŸºç¡€ã€‚",
      "categories": [
        "cs.LO",
        "cs.AI"
      ],
      "primary_category": "cs.LO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.11647v1",
      "published_date": "2025-08-02 04:30:05 UTC",
      "updated_date": "2025-08-02 04:30:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:24:36.929871+00:00"
    },
    {
      "arxiv_id": "2508.01188v4",
      "title": "SpectrumWorld: Artificial Intelligence Foundation for Spectroscopy",
      "title_zh": "SpectrumWorldï¼šé¢å‘å…‰è°±å­¦çš„äººå·¥æ™ºèƒ½åŸºç¡€",
      "authors": [
        "Zhuo Yang",
        "Jiaqing Xie",
        "Shuaike Shen",
        "Daolang Wang",
        "Yeyun Chen",
        "Ben Gao",
        "Shuzhou Sun",
        "Biqing Qi",
        "Dongzhan Zhou",
        "Lei Bai",
        "Linjiang Chen",
        "Shufei Zhang",
        "Qinying Gu",
        "Jun Jiang",
        "Tianfan Fu",
        "Yuqiang Li"
      ],
      "abstract": "Deep learning holds immense promise for spectroscopy, yet research and evaluation in this emerging field often lack standardized formulations. To address this issue, we introduce SpectrumLab, a pioneering unified platform designed to systematize and accelerate deep learning research in spectroscopy. SpectrumLab integrates three core components: a comprehensive Python library featuring essential data processing and evaluation tools, along with leaderboards; an innovative SpectrumAnnotator module that generates high-quality benchmarks from limited seed data; and SpectrumBench, a multi-layered benchmark suite covering 14 spectroscopic tasks and over 10 spectrum types, featuring spectra curated from over 1.2 million distinct chemical substances. Thorough empirical studies on SpectrumBench with 18 cutting-edge multimodal LLMs reveal critical limitations of current approaches. We hope SpectrumLab will serve as a crucial foundation for future advancements in deep learning-driven spectroscopy.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å…‰è°±å­¦é¢†åŸŸæ·±åº¦å­¦ä¹ ç ”ç©¶ç¼ºä¹æ ‡å‡†åŒ–å…¬å¼çš„é—®é¢˜ï¼Œæ¨å‡ºäº†é¦–ä¸ªç»Ÿä¸€å¹³å° SpectrumLabï¼Œæ—¨åœ¨ç³»ç»ŸåŒ–å’ŒåŠ é€Ÿè¯¥é¢†åŸŸçš„æ·±åº¦å­¦ä¹ ç ”ç©¶ã€‚è¯¥å¹³å°ç”±ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶æ„æˆï¼šä¸€ä¸ªåŒ…å«æ•°æ®å¤„ç†ã€è¯„ä¼°å·¥å…·å’Œæ’è¡Œæ¦œçš„ Python åº“ï¼Œä¸€ä¸ªèƒ½å¤Ÿä»æœ‰é™ç§å­æ•°æ®ç”Ÿæˆé«˜è´¨é‡åŸºå‡†æµ‹è¯•çš„åˆ›æ–° SpectrumAnnotator æ¨¡å—ï¼Œä»¥åŠä¸€ä¸ªåä¸º SpectrumBench çš„å¤šå±‚æ¬¡åŸºå‡†æµ‹è¯•å¥—ä»¶ã€‚SpectrumBench æ¶µç›–äº† 14 é¡¹å…‰è°±ä»»åŠ¡å’Œ 10 å¤šç§å…‰è°±ç±»å‹ï¼Œå…¶ä¸­çš„å…‰è°±æ•°æ®æºè‡ªè¶…è¿‡ 120 ä¸‡ç§ä¸åŒçš„åŒ–å­¦ç‰©è´¨ã€‚ç ”ç©¶äººå‘˜åˆ©ç”¨ SpectrumBench å¯¹ 18 ç§æœ€å…ˆè¿›çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ (Multimodal LLMs) è¿›è¡Œäº†æ·±å…¥çš„å®è¯ç ”ç©¶ï¼Œæ­ç¤ºäº†å½“å‰æ–¹æ³•åœ¨å¤„ç†å…‰è°±æ•°æ®æ—¶å­˜åœ¨çš„å…³é”®å±€é™æ€§ã€‚SpectrumLab ä¸ºå…‰è°±å­¦äººå·¥æ™ºèƒ½çš„å‘å±•æä¾›äº†é‡è¦çš„åŸºç¡€è®¾æ–½ï¼Œæœ‰æœ›æˆä¸ºæœªæ¥æ·±åº¦å­¦ä¹ é©±åŠ¨çš„å…‰è°±ç ”ç©¶çš„åŸºçŸ³ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.01188v4",
      "published_date": "2025-08-02 04:21:07 UTC",
      "updated_date": "2025-09-26 02:39:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:24:38.646178+00:00"
    },
    {
      "arxiv_id": "2508.01186v1",
      "title": "A Survey on Agent Workflow -- Status and Future",
      "title_zh": "æ™ºèƒ½ä½“å·¥ä½œæµç»¼è¿°ï¼šç°çŠ¶ä¸å±•æœ›",
      "authors": [
        "Chaojia Yu",
        "Zihan Cheng",
        "Hanwen Cui",
        "Yishuo Gao",
        "Zexu Luo",
        "Yijin Wang",
        "Hangbin Zheng",
        "Yong Zhao"
      ],
      "abstract": "In the age of large language models (LLMs), autonomous agents have emerged as a powerful paradigm for achieving general intelligence. These agents dynamically leverage tools, memory, and reasoning capabilities to accomplish user-defined goals. As agent systems grow in complexity, agent workflows-structured orchestration frameworks-have become central to enabling scalable, controllable, and secure AI behaviors. This survey provides a comprehensive review of agent workflow systems, spanning academic frameworks and industrial implementations. We classify existing systems along two key dimensions: functional capabilities (e.g., planning, multi-agent collaboration, external API integration) and architectural features (e.g., agent roles, orchestration flows, specification languages). By comparing over 20 representative systems, we highlight common patterns, potential technical challenges, and emerging trends. We further address concerns related to workflow optimization strategies and security. Finally, we outline open problems such as standardization and multimodal integration, offering insights for future research at the intersection of agent design, workflow infrastructure, and safe automation.",
      "tldr_zh": "è¯¥ç»¼è¿°å¯¹æ™ºèƒ½ä½“å·¥ä½œæµï¼ˆAgent Workflowï¼‰ç³»ç»Ÿçš„ç°çŠ¶ä¸æœªæ¥è¿›è¡Œäº†å…¨é¢å›é¡¾ã€‚éšç€å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é©±åŠ¨çš„è‡ªä¸»æ™ºèƒ½ä½“æ—¥ç›Šå¤æ‚ï¼ŒAgent Workflow ä½œä¸ºç»“æ„åŒ–ç¼–æ’æ¡†æ¶ï¼Œå·²æˆä¸ºå®ç° AI è¡Œä¸ºå¯æ‰©å±•æ€§ã€å¯æ§æ€§å’Œå®‰å…¨æ€§çš„æ ¸å¿ƒã€‚æ–‡ç« ä»åŠŸèƒ½èƒ½åŠ›ï¼ˆå¦‚ Planningã€Multi-agent collaborationã€External API integrationï¼‰å’Œæ¶æ„ç‰¹æ€§ï¼ˆå¦‚ Agent rolesã€Orchestration flowsã€Specification languagesï¼‰ä¸¤ä¸ªç»´åº¦å¯¹ç°æœ‰ç³»ç»Ÿè¿›è¡Œäº†ç³»ç»Ÿåˆ†ç±»ã€‚é€šè¿‡å¯¹æ¯” 20 å¤šä¸ªä»£è¡¨æ€§ç³»ç»Ÿï¼Œç ”ç©¶æ€»ç»“äº†è¡Œä¸šå¸¸è§æ¨¡å¼ã€æ½œåœ¨æŠ€æœ¯æŒ‘æˆ˜ä»¥åŠ Workflow optimization ç­–ç•¥ä¸å®‰å…¨é—®é¢˜ã€‚æœ€åï¼Œä½œè€…æ¢è®¨äº†æ ‡å‡†åŒ–å’Œ Multimodal integration ç­‰å¼€æ”¾æ€§é—®é¢˜ï¼Œä¸ºæœªæ¥æ™ºèƒ½ä½“è®¾è®¡ä¸å®‰å…¨è‡ªåŠ¨åŒ–åŸºç¡€è®¾æ–½çš„ç ”ç©¶æä¾›äº†é‡è¦è§è§£ã€‚",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages, 3 figures, accepted to IEEE Conference, ICAIBD(International Conference of Artificial Intelligence and Big Data) 2025. This is the author's version, not the publisher's. See https://ieeexplore.ieee.org/document/11082076",
      "pdf_url": "https://arxiv.org/pdf/2508.01186v1",
      "published_date": "2025-08-02 04:15:30 UTC",
      "updated_date": "2025-08-02 04:15:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:24:44.229188+00:00"
    },
    {
      "arxiv_id": "2508.01181v2",
      "title": "Benchmarking and Bridging Emotion Conflicts for Multimodal Emotion Reasoning",
      "title_zh": "å¤šæ¨¡æ€æƒ…æ„Ÿæ¨ç†ä¸­æƒ…æ„Ÿå†²çªçš„åŸºå‡†æµ‹è¯•ä¸å¼¥åˆ",
      "authors": [
        "Zhiyuan Han",
        "Beier Zhu",
        "Yanlong Xu",
        "Peipei Song",
        "Xun Yang"
      ],
      "abstract": "Despite their strong performance in multimodal emotion reasoning, existing Multimodal Large Language Models (MLLMs) often overlook the scenarios involving emotion conflicts, where emotional cues from different modalities are inconsistent. To fill this gap, we first introduce CA-MER, a new benchmark designed to examine MLLMs under realistic emotion conflicts. It consists of three subsets: video-aligned, audio-aligned, and consistent, where only one or all modalities reflect the true emotion. However, evaluations on our CA-MER reveal that current state-of-the-art emotion MLLMs systematically over-rely on audio signal during emotion conflicts, neglecting critical cues from visual modality. To mitigate this bias, we propose MoSEAR, a parameter-efficient framework that promotes balanced modality integration. MoSEAR consists of two modules: (1)MoSE, modality-specific experts with a regularized gating mechanism that reduces modality bias in the fine-tuning heads; and (2)AR, an attention reallocation mechanism that rebalances modality contributions in frozen backbones during inference. Our framework offers two key advantages: it mitigates emotion conflicts and improves performance on consistent samples-without incurring a trade-off between audio and visual modalities. Experiments on multiple benchmarks-including MER2023, EMER, DFEW, and our CA-MER-demonstrate that MoSEAR achieves state-of-the-art performance, particularly under modality conflict conditions.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ (Multimodal Large Language Models, MLLMs) åœ¨å¤šæ¨¡æ€æƒ…æ„Ÿæ¨ç†ä¸­å¿½è§†æƒ…æ„Ÿå†²çª (emotion conflicts) çš„ç°çŠ¶ï¼ŒæŒ‡å‡ºç°æœ‰æ¨¡å‹åœ¨ä¸åŒæ¨¡æ€çº¿ç´¢ä¸ä¸€è‡´æ—¶å¾€å¾€è¿‡åº¦ä¾èµ–éŸ³é¢‘ä¿¡å·ã€‚ä¸ºå¡«è¡¥è¿™ä¸€ç©ºç™½ï¼Œä½œè€…å¼•å…¥äº† CA-MER åŸºå‡†ï¼Œé€šè¿‡è§†é¢‘å¯¹é½ã€éŸ³é¢‘å¯¹é½å’Œä¸€è‡´æ€§ä¸‰ä¸ªå­é›†ï¼Œä¸“é—¨è¯„ä¼°æ¨¡å‹åœ¨çœŸå®å†²çªåœºæ™¯ä¸‹çš„è¡¨ç°ã€‚ç ”ç©¶è¿›ä¸€æ­¥æå‡ºäº†åä¸º MoSEAR çš„å‚æ•°é«˜æ•ˆæ¡†æ¶ï¼Œé€šè¿‡åŒ…å«æ­£åˆ™åŒ–é—¨æ§æœºåˆ¶çš„æ¨¡æ€ç‰¹å®šä¸“å®¶ (MoSE) æ¨¡å—æ¥å‡å°‘å¾®è°ƒè¿‡ç¨‹ä¸­çš„æ¨¡æ€åå·®ï¼Œå¹¶åˆ©ç”¨æ³¨æ„åŠ›é‡æ–°åˆ†é… (AR) æœºåˆ¶åœ¨æ¨ç†æ—¶é‡æ–°å¹³è¡¡å†»ç»“ä¸»å¹²ç½‘ç»œä¸­çš„æ¨¡æ€è´¡çŒ®ã€‚è¯¥æ¡†æ¶èƒ½å¤Ÿåœ¨ç¼“è§£æƒ…æ„Ÿå†²çªçš„åŒæ—¶æå‡ä¸€è‡´æ€§æ ·æœ¬çš„æ€§èƒ½ï¼Œä¸”æ— éœ€åœ¨éŸ³é¢‘å’Œè§†è§‰æ¨¡æ€ä¹‹é—´è¿›è¡Œæ€§èƒ½æƒè¡¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒMoSEAR åœ¨ MER2023ã€EMERã€DFEW åŠ CA-MER ç­‰å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å‡å–å¾—äº† state-of-the-art æ€§èƒ½ï¼Œå……åˆ†éªŒè¯äº†å…¶åœ¨å¤„ç†æ¨¡æ€å†²çªæ–¹é¢çš„ä¼˜è¶Šæ€§ã€‚",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.MM",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.AI",
      "comment": "ACM Multimedia 2025 Oral Code: https://github.com/ZhiyuanHan-Aaron/MoSEAR Project Page: https://zhiyuanhan-aaron.github.io/MoSEAR-page/",
      "pdf_url": "https://arxiv.org/pdf/2508.01181v2",
      "published_date": "2025-08-02 04:03:44 UTC",
      "updated_date": "2025-10-11 07:15:43 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:24:46.340987+00:00"
    },
    {
      "arxiv_id": "2508.06526v1",
      "title": "PiKV: KV Cache Management System for Mixture of Experts",
      "title_zh": "PiKVï¼šé’ˆå¯¹æ··åˆä¸“å®¶æ¨¡å‹çš„ KV ç¼“å­˜ç®¡ç†ç³»ç»Ÿ",
      "authors": [
        "Dong Liu",
        "Yanxuan Yu",
        "Ben Lengerich",
        "Ying Nian Wu",
        "Xuhong Wang"
      ],
      "abstract": "As large language models continue to scale up in both size and context length, the memory and communication cost of key-value (KV) cache storage has become a major bottleneck in multi-GPU and multi-node inference. While MoE-based architectures sparsify computation across experts, the corresponding KV caches remain dense and globally synchronized, resulting in significant overhead.\n  We introduce \\textbf{PiKV}, a parallel and distributed KV cache serving framework tailored for MoE architecture. PiKV leverages \\textit{expert-sharded KV storage} to partition caches across GPUs, \\textit{PiKV routing} to reduce token-to-KV access, and a \\textit{PiKV Scheduling} to adaptively retain query-relevant entries. To further reduce memory usage, PiKV integrates \\textit{PiKV Compression} modules the caching pipeline for acceleration.\n  PiKV is recently publicly available as an open-source software library: \\href{https://github.com/NoakLiu/PiKV}{https://github.com/NoakLiu/PiKV}. Experiments details is recorded at: \\href{https://github.com/NoakLiu/PiKV/blob/main/downstream_tasks/README.md}{https://github.com/NoakLiu/PiKV/Experimental\\_Results}. We also have PiKV integrated with Nvidia kvpress for acceleration, details see \\href{https://github.com/NoakLiu/PiKVpress}{https://github.com/NoakLiu/PiKVpress}. PiKV is still a living project, aiming to become a comprehesive KV Cache management system for MoE Architectures.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† PiKVï¼Œä¸€ä¸ªä¸“ä¸º Mixture of Experts (MoE) æ¶æ„è®¾è®¡çš„å¹¶è¡Œåˆ†å¸ƒå¼ KV Cache æœåŠ¡æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹åœ¨å¤š GPU å’Œå¤šèŠ‚ç‚¹æ¨ç†ä¸­é¢ä¸´çš„æ˜¾å­˜å’Œé€šä¿¡ç“¶é¢ˆã€‚é’ˆå¯¹ MoE æ¨¡å‹ä¸­ KV Cache å­˜å‚¨è¿‡äºå¯†é›†ä¸”å…¨å±€åŒæ­¥å¯¼è‡´çš„é«˜é¢å¼€é”€ï¼ŒPiKV å¼•å…¥äº†ä¸“å®¶åˆ†ç‰‡ KV å­˜å‚¨ (Expert-sharded KV storage) æŠ€æœ¯ï¼Œé€šè¿‡å°†ç¼“å­˜åˆ†ç‰‡è‡³ä¸åŒ GPU æ¥å®ç°åˆ†å¸ƒå¼ç®¡ç†ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶é‡‡ç”¨äº† PiKV routing ä»¥å‡å°‘ Token åˆ° KV çš„è®¿é—®é¢‘ç‡ï¼Œå¹¶ç»“åˆ PiKV Scheduling ç­–ç•¥åŠ¨æ€åœ°ä¿ç•™ä¸æŸ¥è¯¢ç›¸å…³çš„ç¼“å­˜æ¡ç›®ã€‚ä¸ºäº†è¿›ä¸€æ­¥ä¼˜åŒ–æ˜¾å­˜å ç”¨ï¼ŒPiKV è¿˜é›†æˆäº†å‹ç¼©æ¨¡å— (PiKV Compression) ä»¥åŠ é€Ÿæ¨ç†æµæ°´çº¿ã€‚ç›®å‰ PiKV å·²ä½œä¸ºå¼€æºè½¯ä»¶åº“å‘å¸ƒï¼Œå¹¶å®ç°äº†ä¸ Nvidia kvpress çš„é›†æˆï¼Œä¸ºæ„å»ºé«˜æ•ˆã€å¯æ‰©å±•çš„ MoE æ¶æ„ KV Cache ç®¡ç†ç³»ç»Ÿæä¾›äº†å®Œæ•´çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.DC",
      "comment": "Accepted to ICML ES-MoFo III WorkShop Paper Link: https://openreview.net/pdf?id=hHoK1kBPd9 Github Link: https://github.com/NoakLiu/PiKV",
      "pdf_url": "https://arxiv.org/pdf/2508.06526v1",
      "published_date": "2025-08-02 03:50:14 UTC",
      "updated_date": "2025-08-02 03:50:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:24:49.051196+00:00"
    },
    {
      "arxiv_id": "2508.01178v1",
      "title": "Advancing the Foundation Model for Music Understanding",
      "title_zh": "æ¨è¿›éŸ³ä¹ç†è§£åŸºç¡€æ¨¡å‹çš„å‘å±•",
      "authors": [
        "Yi Jiang",
        "Wei Wang",
        "Xianwen Guo",
        "Huiyun Liu",
        "Hanrui Wang",
        "Youri Xu",
        "Haoqi Gu",
        "Zhongqian Xie",
        "Chuanjiang Luo"
      ],
      "abstract": "The field of Music Information Retrieval (MIR) is fragmented, with specialized models excelling at isolated tasks. In this work, we challenge this paradigm by introducing a unified foundation model named MuFun for holistic music understanding. Our model features a novel architecture that jointly processes instrumental and lyrical content, and is trained on a large-scale dataset covering diverse tasks such as genre classification, music tagging, and question answering. To facilitate robust evaluation, we also propose a new benchmark for multi-faceted music understanding called MuCUE (Music Comprehensive Understanding Evaluation). Experiments show our model significantly outperforms existing audio large language models across the MuCUE tasks, demonstrating its state-of-the-art effectiveness and generalization ability.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Music Information Retrieval (MIR) é¢†åŸŸæ¨¡å‹ç¢ç‰‡åŒ–çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸º MuFun çš„ç»Ÿä¸€åŸºç¡€æ¨¡å‹ (foundation model)ï¼Œæ—¨åœ¨å®ç°å…¨é¢çš„éŸ³ä¹ç†è§£ã€‚è¯¥æ¨¡å‹é‡‡ç”¨äº†ä¸€ç§èƒ½å¤ŸåŒæ—¶å¤„ç†ä¹å™¨ (instrumental) å’Œæ­Œè¯ (lyrical) å†…å®¹çš„æ–°é¢–æ¶æ„ï¼Œå¹¶åœ¨æ¶µç›–æµæ´¾åˆ†ç±» (genre classification)ã€éŸ³ä¹æ ‡ç­¾ (music tagging) å’Œé—®ç­” (question answering) ç­‰å¤šæ ·åŒ–ä»»åŠ¡çš„å¤§è§„æ¨¡æ•°æ®é›†ä¸Šè¿›è¡Œäº†è®­ç»ƒã€‚æ­¤å¤–ï¼Œç ”ç©¶è€…è¿˜æå‡ºäº†ä¸€ä¸ªåä¸º MuCUE (Music Comprehensive Understanding Evaluation) çš„å¤šç»´åº¦éŸ³ä¹ç†è§£æ–°åŸºå‡†ï¼Œç”¨äºè¿›è¡Œæ›´ç¨³å¥çš„è¯„ä¼°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMuFun åœ¨ MuCUE å„é¡¹ä»»åŠ¡ä¸Šçš„è¡¨ç°æ˜¾è‘—ä¼˜äºç°æœ‰çš„éŸ³é¢‘å¤§è¯­è¨€æ¨¡å‹ (audio large language models)ï¼Œè¯æ˜äº†å…¶åœ¨éŸ³ä¹ç†è§£é¢†åŸŸçš„å…ˆè¿›æ€§ä¸æ³›åŒ–èƒ½åŠ›ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.IR",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.01178v1",
      "published_date": "2025-08-02 03:33:47 UTC",
      "updated_date": "2025-08-02 03:33:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:25:00.653453+00:00"
    },
    {
      "arxiv_id": "2508.01174v1",
      "title": "RSPO: Risk-Seeking Policy Optimization for Pass@k and Max@k Metrics in Large Language Models",
      "title_zh": "RSPOï¼šé¢å‘å¤§è¯­è¨€æ¨¡å‹ Pass@k ä¸ Max@k æŒ‡æ ‡çš„é£é™©å¯»æ±‚ç­–ç•¥ä¼˜åŒ–",
      "authors": [
        "Kaichen Zhang",
        "Shenghao Gao",
        "Yuzhong Hong",
        "Haipeng Sun",
        "Junwei Bao",
        "Hongfei Jiang",
        "Yang Song",
        "Hong Dingqian",
        "Hui Xiong"
      ],
      "abstract": "Current large language model post-training optimizes a risk-neutral objective that maximizes expected reward, yet evaluation relies heavily on risk-seeking metrics like Pass@k (at least one success in k trials) and Max@k (maximum reward across k responses). This mismatch in risk preferences can inevitably lead to suboptimal performance. To bridge this gap, we propose Risk-Seeking Policy Optimization (RSPO), a novel method that directly targets Pass@k and Max@k during training. A key challenge in optimizing these metrics is the \"hitchhiking\" problem: low-reward responses are inadvertently reinforced if they co-occur with a high-reward response within a sample of k generations, resulting in inefficient optimization. RSPO addresses this problem by leveraging the closed-form probability that a given response is the maximum among k samplings. Despite the complexity of nested gradients over multiple responses, RSPO produces efficient, unbiased gradient estimators for both metrics. We validate our approach with both rigorous theoretical analysis and comprehensive experimental results.",
      "tldr_zh": "è¯¥ç ”ç©¶æŒ‡å‡ºç›®å‰çš„å¤§å‹è¯­è¨€æ¨¡å‹(LLM)åè®­ç»ƒé€šå¸¸ä¼˜åŒ–æœ€å¤§åŒ–æœŸæœ›å¥–åŠ±çš„é£é™©ä¸­æ€§ç›®æ ‡ï¼Œä½†è¯„ä¼°å´é«˜åº¦ä¾èµ–äºPass@kå’ŒMax@kç­‰é£é™©è¿½æ±‚(risk-seeking)æŒ‡æ ‡ï¼Œè¿™ç§é£é™©åå¥½çš„ä¸åŒ¹é…å¯¼è‡´äº†æ€§èƒ½çš„æ¬ ä¼˜åŒ–ã€‚ä¸ºäº†å¼¥è¡¥è¿™ä¸€å·®è·ï¼Œä½œè€…æå‡ºäº†é£é™©è¿½æ±‚ç­–ç•¥ä¼˜åŒ–(RSPO)ï¼Œè¿™æ˜¯ä¸€ç§åœ¨è®­ç»ƒæœŸé—´ç›´æ¥é’ˆå¯¹Pass@kå’ŒMax@kæŒ‡æ ‡çš„æ–°å‹æ–¹æ³•ã€‚é’ˆå¯¹ä¼˜åŒ–è¿‡ç¨‹ä¸­ä½å¥–åŠ±å“åº”å› ä¸é«˜å¥–åŠ±å“åº”å…±å­˜è€Œè¢«è¯¯å¼ºåŒ–çš„â€œæ­ä¾¿è½¦â€(hitchhiking)é—®é¢˜ï¼ŒRSPOé€šè¿‡åˆ©ç”¨ç»™å®šå“åº”åœ¨kæ¬¡é‡‡æ ·ä¸­ä½œä¸ºæœ€å¤§å€¼çš„é—­å¼æ¦‚ç‡(closed-form probability)æ¥è§£å†³ã€‚å°½ç®¡æ¶‰åŠå¤šä¸ªå“åº”çš„åµŒå¥—æ¢¯åº¦å…·æœ‰å¤æ‚æ€§ï¼ŒRSPOä»ä¸ºè¿™ä¸¤ç§æŒ‡æ ‡ç”Ÿæˆäº†é«˜æ•ˆä¸”æ— åçš„æ¢¯åº¦ä¼°è®¡å™¨ã€‚è¯¥æ–¹æ³•é€šè¿‡ä¸¥è°¨çš„ç†è®ºåˆ†æå’Œå…¨é¢çš„å®éªŒç»“æœå¾—åˆ°äº†éªŒè¯ï¼Œè¯æ˜äº†å…¶åœ¨è§£å†³é£é™©åå¥½å¤±é…é—®é¢˜ä¸Šçš„å“è¶Šæ€§èƒ½ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.01174v1",
      "published_date": "2025-08-02 03:25:26 UTC",
      "updated_date": "2025-08-02 03:25:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:25:06.241939+00:00"
    },
    {
      "arxiv_id": "2508.01172v1",
      "title": "GeHirNet: A Gender-Aware Hierarchical Model for Voice Pathology Classification",
      "title_zh": "GeHirNetï¼šç”¨äºå—“éŸ³ç—…ç†åˆ†ç±»çš„æ€§åˆ«æ„ŸçŸ¥åˆ†å±‚æ¨¡å‹",
      "authors": [
        "Fan Wu",
        "Kaicheng Zhao",
        "Elgar Fleisch",
        "Filipe Barata"
      ],
      "abstract": "AI-based voice analysis shows promise for disease diagnostics, but existing classifiers often fail to accurately identify specific pathologies because of gender-related acoustic variations and the scarcity of data for rare diseases. We propose a novel two-stage framework that first identifies gender-specific pathological patterns using ResNet-50 on Mel spectrograms, then performs gender-conditioned disease classification. We address class imbalance through multi-scale resampling and time warping augmentation. Evaluated on a merged dataset from four public repositories, our two-stage architecture with time warping achieves state-of-the-art performance (97.63\\% accuracy, 95.25\\% MCC), with a 5\\% MCC improvement over single-stage baseline. This work advances voice pathology classification while reducing gender bias through hierarchical modeling of vocal characteristics.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†GeHirNetï¼Œä¸€ç§ç”¨äºè¯­éŸ³ç—…ç†åˆ†ç±»ï¼ˆVoice Pathology Classificationï¼‰çš„æ€§åˆ«æ„ŸçŸ¥åˆ†å±‚æ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰åˆ†ç±»å™¨å› æ€§åˆ«å£°å­¦å·®å¼‚åŠç½•è§ç—…æ•°æ®ç¨€ç¼ºå¯¼è‡´çš„è¯†åˆ«éš¾é¢˜ã€‚è¯¥æ¡†æ¶é‡‡ç”¨ä¸¤é˜¶æ®µç­–ç•¥ï¼Œé¦–å…ˆé€šè¿‡ResNet-50åœ¨Mel spectrogramsä¸Šè¯†åˆ«æ€§åˆ«ç‰¹å¼‚çš„ç—…ç†ç‰¹å¾ï¼Œéšåæ‰§è¡ŒåŸºäºæ€§åˆ«çš„ç–¾ç—…åˆ†ç±»ã€‚ä¸ºäº†ç¼“è§£ç±»åˆ«ä¸å¹³è¡¡ï¼Œç ”ç©¶å¼•å…¥äº†å¤šå°ºåº¦é‡é‡‡æ ·ï¼ˆmulti-scale resamplingï¼‰å’Œæ—¶é—´è§„æ•´å¢å¼ºï¼ˆtime warping augmentationï¼‰æŠ€æœ¯ã€‚åœ¨åˆå¹¶åçš„å››ä¸ªå…¬å…±æ•°æ®é›†ä¸Šï¼Œè¯¥æ¨¡å‹è¾¾åˆ°äº†97.63%çš„å‡†ç¡®ç‡å’Œ95.25%çš„MCCï¼Œè¾ƒå•é˜¶æ®µåŸºçº¿æ¨¡å‹çš„MCCæå‡äº†5%ã€‚è¿™é¡¹å·¥ä½œé€šè¿‡åˆ†å±‚å»ºæ¨¡æ˜¾è‘—é™ä½äº†æ€§åˆ«åå·®ï¼ˆgender biasï¼‰ï¼Œåœ¨æå‡åˆ†ç±»æ€§èƒ½çš„åŒæ—¶å¢å¼ºäº†è¯­éŸ³ç—…ç†è¯Šæ–­çš„é²æ£’æ€§ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.01172v1",
      "published_date": "2025-08-02 03:19:44 UTC",
      "updated_date": "2025-08-02 03:19:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:25:27.029473+00:00"
    },
    {
      "arxiv_id": "2508.01159v2",
      "title": "Asking the Right Questions: Benchmarking Large Language Models in the Development of Clinical Consultation Templates",
      "title_zh": "ç²¾å‡†æé—®ï¼šå¤§è¯­è¨€æ¨¡å‹åœ¨ä¸´åºŠå’¨è¯¢æ¨¡æ¿å¼€å‘ä¸­çš„åŸºå‡†è¯„ä¼°",
      "authors": [
        "Liam G. McCoy",
        "Fateme Nateghi Haredasht",
        "Kanav Chopra",
        "David Wu",
        "David JH Wu",
        "Abass Conteh",
        "Sarita Khemani",
        "Saloni Kumar Maharaj",
        "Vishnu Ravi",
        "Arth Pahwa",
        "Yingjie Weng",
        "Leah Rosengaus",
        "Lena Giang",
        "Kelvin Zhenghao Li",
        "Olivia Jee",
        "Daniel Shirvani",
        "Ethan Goh",
        "Jonathan H. Chen"
      ],
      "abstract": "This study evaluates the capacity of large language models (LLMs) to generate structured clinical consultation templates for electronic consultation. Using 145 expert-crafted templates developed and routinely used by Stanford's eConsult team, we assess frontier models -- including o3, GPT-4o, Kimi K2, Claude 4 Sonnet, Llama 3 70B, and Gemini 2.5 Pro -- for their ability to produce clinically coherent, concise, and prioritized clinical question schemas. Through a multi-agent pipeline combining prompt optimization, semantic autograding, and prioritization analysis, we show that while models like o3 achieve high comprehensiveness (up to 92.2\\%), they consistently generate excessively long templates and fail to correctly prioritize the most clinically important questions under length constraints. Performance varies across specialties, with significant degradation in narrative-driven fields such as psychiatry and pain medicine. Our findings demonstrate that LLMs can enhance structured clinical information exchange between physicians, while highlighting the need for more robust evaluation methods that capture a model's ability to prioritize clinically salient information within the time constraints of real-world physician communication.",
      "tldr_zh": "è¯¥ç ”ç©¶è¯„ä¼°äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨ä¸ºç”µå­ä¼šè¯Š(electronic consultation)ç”Ÿæˆç»“æ„åŒ–ä¸´åºŠå’¨è¯¢æ¨¡æ¿æ–¹é¢çš„èƒ½åŠ›ã€‚ç ”ç©¶äººå‘˜åˆ©ç”¨æ–¯å¦ç¦eConsultå›¢é˜Ÿå¼€å‘çš„145ä¸ªä¸“å®¶çº§æ¨¡æ¿ï¼Œå¯¹o3ã€GPT-4oã€Kimi K2ã€Claude 4 Sonnetã€Llama 3 70Bå’ŒGemini 2.5 Proç­‰å‰æ²¿æ¨¡å‹è¿›è¡Œäº†åŸºå‡†æµ‹è¯•ã€‚è¯¥è¯„ä¼°é€šè¿‡ç»“åˆæç¤ºä¼˜åŒ–(prompt optimization)ã€è¯­ä¹‰è‡ªåŠ¨è¯„åˆ†(semantic autograding)å’Œä¼˜å…ˆçº§åˆ†æ(prioritization analysis)çš„å¤šæ™ºèƒ½ä½“æµæ°´çº¿(multi-agent pipeline)å®Œæˆã€‚ç»“æœæ˜¾ç¤ºï¼Œè™½ç„¶åƒo3è¿™æ ·çš„æ¨¡å‹åœ¨å…¨é¢æ€§(comprehensiveness)ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œä½†å®ƒä»¬æ™®éä¼šç”Ÿæˆè¿‡é•¿çš„æ¨¡æ¿ï¼Œä¸”åœ¨é•¿åº¦å—é™æ—¶æ— æ³•æ­£ç¡®æ’åˆ—ä¸´åºŠé—®é¢˜çš„ä¼˜å…ˆçº§(prioritization)ã€‚ç ”ç©¶è¿˜å‘ç°æ¨¡å‹åœ¨ç²¾ç¥ç—…å­¦(psychiatry)å’Œç–¼ç—›åŒ»å­¦(pain medicine)ç­‰å™è¿°å¯¼å‘å‹é¢†åŸŸçš„æ€§èƒ½æ˜¾è‘—ä¸‹é™ã€‚æœ€ç»ˆç»“è®ºæŒ‡å‡ºï¼Œå°½ç®¡LLMsèƒ½å¢å¼ºåŒ»ç”Ÿé—´çš„ç»“æ„åŒ–ä¿¡æ¯äº¤æ¢ï¼Œä½†ä»éœ€æ›´ç¨³å¥çš„è¯„ä¼°æ–¹æ³•æ¥æ•æ‰æ¨¡å‹åœ¨çœŸå®ä¸´åºŠæ—¶é—´çº¦æŸä¸‹è¯†åˆ«å…³é”®ä¿¡æ¯çš„èƒ½åŠ›ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.01159v2",
      "published_date": "2025-08-02 02:51:27 UTC",
      "updated_date": "2025-11-12 12:17:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:25:28.625699+00:00"
    },
    {
      "arxiv_id": "2508.01158v2",
      "title": "H2C: Hippocampal Circuit-inspired Continual Learning for Lifelong Trajectory Prediction in Autonomous Driving",
      "title_zh": "H2Cï¼šå—æµ·é©¬å›è·¯å¯å‘çš„è‡ªåŠ¨é©¾é©¶ç»ˆèº«è½¨è¿¹é¢„æµ‹æŒç»­å­¦ä¹ ",
      "authors": [
        "Yunlong Lin",
        "Zirui Li",
        "Guodong Du",
        "Xiaocong Zhao",
        "Cheng Gong",
        "Xinwei Wang",
        "Chao Lu",
        "Jianwei Gong"
      ],
      "abstract": "Deep learning (DL) has shown state-of-the-art performance in trajectory prediction, which is critical to safe navigation in autonomous driving (AD). However, most DL-based methods suffer from catastrophic forgetting, where adapting to a new distribution may cause significant performance degradation in previously learned ones. Such inability to retain learned knowledge limits their applicability in the real world, where AD systems need to operate across varying scenarios with dynamic distributions. As revealed by neuroscience, the hippocampal circuit plays a crucial role in memory replay, effectively reconstructing learned knowledge based on limited resources. Inspired by this, we propose a hippocampal circuit-inspired continual learning method (H2C) for trajectory prediction across varying scenarios. H2C retains prior knowledge by selectively recalling a small subset of learned samples. First, two complementary strategies are developed to select the subset to represent learned knowledge. Specifically, one strategy maximizes inter-sample diversity to represent the distinctive knowledge, and the other estimates the overall knowledge by equiprobable sampling. Then, H2C updates via a memory replay loss function calculated by these selected samples to retain knowledge while learning new data. Experiments based on various scenarios from the INTERACTION dataset are designed to evaluate H2C. Experimental results show that H2C reduces catastrophic forgetting of DL baselines by 22.71% on average in a task-free manner, without relying on manually informed distributional shifts. The implementation is available at https://github.com/BIT-Jack/H2C-lifelong.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†H2Cï¼Œä¸€ç§å—æµ·é©¬ä½“ç¯è·¯(Hippocampal Circuit)å¯å‘çš„ä¸€ç³»åˆ—æŒç»­å­¦ä¹ (Continual Learning)æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³è‡ªåŠ¨é©¾é©¶è½¨è¿¹é¢„æµ‹ä¸­æ·±åº¦å­¦ä¹ æ¨¡å‹é¢ä¸´çš„ç¾éš¾æ€§é—å¿˜(Catastrophic Forgetting)é—®é¢˜ã€‚H2Cå€Ÿé‰´äº†ç¥ç»ç§‘å­¦ä¸­æµ·é©¬ä½“é€šè¿‡æœ‰é™èµ„æºé‡å»ºå·²å­¦çŸ¥è¯†çš„æœºåˆ¶ï¼Œé€šè¿‡é€‰æ‹©æ€§åœ°å¬å›ä¸€å°éƒ¨åˆ†å·²å­¦æ ·æœ¬è¿›è¡Œè®°å¿†å›æ”¾(Memory Replay)ä»¥ä¿ç•™å…ˆéªŒçŸ¥è¯†ã€‚è¯¥æ–¹æ³•è®¾è®¡äº†ä¸¤ç§äº’è¡¥çš„é€‰æ‹©ç­–ç•¥ï¼Œåˆ†åˆ«é€šè¿‡æœ€å¤§åŒ–æ ·æœ¬é—´å¤šæ ·æ€§æ¥æ•æ‰ç‰¹å¾çŸ¥è¯†ï¼Œä»¥åŠé€šè¿‡ç­‰æ¦‚ç‡é‡‡æ ·æ¥ä¼°ç®—æ•´ä½“åˆ†å¸ƒã€‚åœ¨å­¦ä¹ æ–°æ•°æ®æ—¶ï¼ŒH2Cé€šè¿‡è®¡ç®—è®°å¿†å›æ”¾æŸå¤±å‡½æ•°(Memory Replay Loss)å®ç°çŸ¥è¯†ä¿ç•™ï¼Œä¸”ä¸ä¾èµ–äººå·¥å®šä¹‰çš„ä»»åŠ¡è¾¹ç•Œã€‚åŸºäºINTERACTIONæ•°æ®é›†çš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒH2Cåœ¨æ— ä»»åŠ¡(Task-free)æ¨¡å¼ä¸‹å°†åŸºå‡†æ¨¡å‹çš„ç¾éš¾æ€§é—å¿˜å¹³å‡é™ä½äº†22.71%ï¼Œæœ‰æ•ˆæå‡äº†è‡ªåŠ¨é©¾é©¶ç³»ç»Ÿåœ¨åŠ¨æ€åœºæ™¯ä¸‹çš„ç»ˆèº«å­¦ä¹ èƒ½åŠ›ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Open source code: https://github.com/BIT-Jack/H2C-lifelong",
      "pdf_url": "https://arxiv.org/pdf/2508.01158v2",
      "published_date": "2025-08-02 02:49:41 UTC",
      "updated_date": "2025-08-09 02:28:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:25:12.730679+00:00"
    },
    {
      "arxiv_id": "2508.01151v2",
      "title": "Personalized Safety Alignment for Text-to-Image Diffusion Models",
      "title_zh": "æ–‡ç”Ÿå›¾æ‰©æ•£æ¨¡å‹çš„ä¸ªæ€§åŒ–å®‰å…¨å¯¹é½",
      "authors": [
        "Yu Lei",
        "Jinbin Bai",
        "Qingyu Shi",
        "Aosong Feng",
        "Kaidong Yu"
      ],
      "abstract": "Text-to-image diffusion models have revolutionized visual content generation, but current safety mechanisms apply uniform standards that often fail to account for individual user preferences. These models overlook the diverse safety boundaries shaped by factors like age, mental health, and personal beliefs. To address this, we propose Personalized Safety Alignment (PSA), a framework that allows user-specific control over safety behaviors in generative models. PSA integrates personalized user profiles into the diffusion process, adjusting the model's behavior to match individual safety preferences while preserving image quality. We introduce a new dataset, Sage, which captures user-specific safety preferences and incorporates these profiles through a cross-attention mechanism. Experiments show that PSA outperforms existing methods in harmful content suppression and aligns generated content better with user constraints, achieving higher Win Rate and Pass Rate scores. Our code, data, and models are publicly available at https://m-e-agi-lab.github.io/PSAlign/.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Personalized Safety Alignment (PSA)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³Text-to-Image Diffusion Modelsä¸­ç°æœ‰å®‰å…¨æœºåˆ¶å› é‡‡ç”¨ç»Ÿä¸€æ ‡å‡†è€Œå¿½è§†ä¸ªä½“ç”¨æˆ·åœ¨å¹´é¾„ã€å¿ƒç†å¥åº·å’Œä¸ªäººä¿¡ä»°ç­‰æ–¹é¢å®‰å…¨ç•Œé™å·®å¼‚çš„é—®é¢˜ã€‚PSAæ¡†æ¶é€šè¿‡å°†ä¸ªæ€§åŒ–çš„ç”¨æˆ·é…ç½®æ–‡ä»¶(User Profiles)æ•´åˆè¿›æ‰©æ•£è¿‡ç¨‹ï¼Œåˆ©ç”¨Cross-attentionæœºåˆ¶åŠ¨æ€è°ƒæ•´æ¨¡å‹è¡Œä¸ºï¼Œä»¥å®ç°ç”Ÿæˆå†…å®¹ä¸ä¸ªäººå®‰å…¨åå¥½çš„ç²¾å‡†åŒ¹é…å¹¶ä¿æŒå›¾åƒè´¨é‡ã€‚ç ”ç©¶è¿˜å¼•å…¥äº†å…¨æ–°çš„Sageæ•°æ®é›†ï¼Œç”¨äºæ•æ‰å’Œå»ºæ¨¡ç”¨æˆ·ç‰¹å®šçš„å®‰å…¨éœ€æ±‚ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒPSAåœ¨æœ‰å®³å†…å®¹æŠ‘åˆ¶å’Œç”¨æˆ·çº¦æŸå¯¹é½æ–¹é¢æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œåœ¨Win Rateå’ŒPass Rateç­‰æ ¸å¿ƒæŒ‡æ ‡ä¸Šå‡è¡¨ç°å“è¶Šã€‚è¯¥æ¡†æ¶ä¸ºå®ç°ç”Ÿæˆå¼æ¨¡å‹çš„å¯å®šåˆ¶åŒ–å®‰å…¨æ²»ç†æä¾›äº†æœ‰æ•ˆè·¯å¾„ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "metadata-only revision; corrected a typo in the abstract. No changes to the PDF content",
      "pdf_url": "https://arxiv.org/pdf/2508.01151v2",
      "published_date": "2025-08-02 02:23:20 UTC",
      "updated_date": "2025-08-07 16:06:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:25:34.130059+00:00"
    },
    {
      "arxiv_id": "2508.01139v3",
      "title": "Dataset Condensation with Color Compensation",
      "title_zh": "åŸºäºè‰²å½©è¡¥å¿çš„æ•°æ®é›†å‹ç¼©",
      "authors": [
        "Huyu Wu",
        "Duo Su",
        "Junjie Hou",
        "Guang Li"
      ],
      "abstract": "Dataset condensation always faces a constitutive trade-off: balancing performance and fidelity under extreme compression. Existing methods struggle with two bottlenecks: image-level selection methods (Coreset Selection, Dataset Quantization) suffer from inefficiency condensation, while pixel-level optimization (Dataset Distillation) introduces semantic distortion due to over-parameterization. With empirical observations, we find that a critical problem in dataset condensation is the oversight of color's dual role as an information carrier and a basic semantic representation unit. We argue that improving the colorfulness of condensed images is beneficial for representation learning. Motivated by this, we propose DC3: a Dataset Condensation framework with Color Compensation. After a calibrated selection strategy, DC3 utilizes the latent diffusion model to enhance the color diversity of an image rather than creating a brand-new one. Extensive experiments demonstrate the superior performance and generalization of DC3 that outperforms SOTA methods across multiple benchmarks. To the best of our knowledge, besides focusing on downstream tasks, DC3 is the first research to fine-tune pre-trained diffusion models with condensed datasets. The Frechet Inception Distance (FID) and Inception Score (IS) results prove that training networks with our high-quality datasets is feasible without model collapse or other degradation issues. Code and generated data are available at https://github.com/528why/Dataset-Condensation-with-Color-Compensation.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº† Dataset Condensation åœ¨æç«¯å‹ç¼©ä¸‹æ€§èƒ½ä¸å¿ å®åº¦ä¹‹é—´çš„æƒè¡¡é—®é¢˜ï¼ŒæŒ‡å‡ºå›¾åƒçº§é€‰æ‹©æ–¹æ³•å’Œåƒç´ çº§ä¼˜åŒ–æ–¹æ³•åˆ†åˆ«å­˜åœ¨æ•ˆç‡ä¸è¯­ä¹‰å¤±çœŸçš„ç“¶é¢ˆã€‚ä½œè€…é€šè¿‡å®è¯è§‚å¯Ÿå‘ç°ï¼Œé¢œè‰²ä½œä¸ºä¿¡æ¯è½½ä½“åœ¨å‹ç¼©è¿‡ç¨‹ä¸­å¸¸è¢«å¿½è§†ï¼Œè¿›è€Œæå‡ºäº†ä¸€ç§åä¸º DC3 çš„é¢œè‰²è¡¥å¿æ•°æ®é›†å‹ç¼©æ¡†æ¶ã€‚DC3 åœ¨æ ¡å‡†é€‰æ‹©ç­–ç•¥çš„åŸºç¡€ä¸Šï¼Œåˆ©ç”¨ Latent Diffusion Model å¢å¼ºå›¾åƒçš„é¢œè‰²å¤šæ ·æ€§ä»¥æå‡è¡¨ç¤ºå­¦ä¹ æ•ˆæœï¼Œè€Œéç”Ÿæˆå…¨æ–°å›¾åƒã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDC3 åœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å‡ä¼˜äº SOTA æ–¹æ³•ï¼Œå±•ç°å‡ºå“è¶Šçš„æ€§èƒ½å’Œæ³›åŒ–èƒ½åŠ›ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶æ˜¯é¦–æ¬¡å°è¯•åˆ©ç”¨å‹ç¼©æ•°æ®é›†å¾®è°ƒé¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹çš„å·¥ä½œï¼Œé€šè¿‡ FID å’Œ IS æŒ‡æ ‡éªŒè¯äº†ç”Ÿæˆæ•°æ®çš„é«˜è´¨é‡ï¼Œå¹¶è¯æ˜å…¶åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­èƒ½æœ‰æ•ˆé¿å… Model Collapse æˆ–å…¶ä»–é€€åŒ–é—®é¢˜ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted in TMLR",
      "pdf_url": "https://arxiv.org/pdf/2508.01139v3",
      "published_date": "2025-08-02 01:44:23 UTC",
      "updated_date": "2025-10-24 10:28:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:25:44.139362+00:00"
    },
    {
      "arxiv_id": "2508.01136v1",
      "title": "DBAIOps: A Reasoning LLM-Enhanced Database Operation and Maintenance System using Knowledge Graphs",
      "title_zh": "DBAIOpsï¼šåŸºäºçŸ¥è¯†å›¾è°±ä¸æ¨ç†å¤§è¯­è¨€æ¨¡å‹å¢å¼ºçš„æ•°æ®åº“è¿ç»´ç³»ç»Ÿ",
      "authors": [
        "Wei Zhou",
        "Peng Sun",
        "Xuanhe Zhou",
        "Qianglei Zang",
        "Ji Xu",
        "Tieying Zhang",
        "Guoliang Li",
        "Fan Wu"
      ],
      "abstract": "The operation and maintenance (O&M) of database systems is critical to ensuring system availability and performance, typically requiring expert experience (e.g., identifying metric-to-anomaly relations) for effective diagnosis and recovery. However, existing automatic database O&M methods, including commercial products, cannot effectively utilize expert experience. On the one hand, rule-based methods only support basic O&M tasks (e.g., metric-based anomaly detection), which are mostly numerical equations and cannot effectively incorporate literal O&M experience (e.g., troubleshooting guidance in manuals). On the other hand, LLM-based methods, which retrieve fragmented information (e.g., standard documents + RAG), often generate inaccurate or generic results. To address these limitations, we present DBAIOps, a novel hybrid database O&M system that combines reasoning LLMs with knowledge graphs to achieve DBA-style diagnosis. First, DBAIOps introduces a heterogeneous graph model for representing the diagnosis experience, and proposes a semi-automatic graph construction algorithm to build that graph from thousands of documents. Second, DBAIOps develops a collection of (800+) reusable anomaly models that identify both directly alerted metrics and implicitly correlated experience and metrics. Third, for each anomaly, DBAIOps proposes a two-stage graph evolution mechanism to explore relevant diagnosis paths and identify missing relations automatically. It then leverages a reasoning LLM (e.g., DeepSeek-R1) to infer root causes and generate clear diagnosis reports for both DBAs and common users. Our evaluation over four mainstream database systems (Oracle, MySQL, PostgreSQL, and DM8) demonstrates that DBAIOps outperforms state-of-the-art baselines, 34.85% and 47.22% higher in root cause and human evaluation accuracy, respectively.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† DBAIOpsï¼Œä¸€ç§ç»“åˆäº†æ¨ç†å¤§è¯­è¨€æ¨¡å‹ (reasoning LLMs) ä¸çŸ¥è¯†å›¾è°± (Knowledge Graphs) çš„æ–°å‹æ··åˆæ•°æ®åº“è¿ç»´ (O&M) ç³»ç»Ÿï¼Œæ—¨åœ¨é€šè¿‡æ¨¡ä»¿æ•°æ®åº“ç®¡ç†å‘˜ (DBA) çš„é€»è¾‘å®ç°ç²¾å‡†æ•…éšœè¯Šæ–­ã€‚è¯¥ç³»ç»Ÿé¦–å…ˆå¼•å…¥å¼‚æ„å›¾æ¨¡å‹ (heterogeneous graph model) æ¥è¡¨ç¤ºè¯Šæ–­ç»éªŒï¼Œå¹¶é€šè¿‡åŠè‡ªåŠ¨ç®—æ³•ä»æµ·é‡æ–‡æ¡£ä¸­æ„å»ºçŸ¥è¯†å›¾è°±ã€‚åŒæ—¶ï¼ŒDBAIOps å¼€å‘äº† 800 å¤šä¸ªå¯é‡ç”¨çš„å¼‚å¸¸æ¨¡å‹ (anomaly models) ä»¥è¯†åˆ«æŒ‡æ ‡ä¸ç»éªŒé—´çš„éšæ€§å…³è”ã€‚é’ˆå¯¹å…·ä½“å¼‚å¸¸ï¼Œç³»ç»Ÿé‡‡ç”¨ä¸¤é˜¶æ®µå›¾æ¼”åŒ–æœºåˆ¶ (two-stage graph evolution mechanism) è‡ªåŠ¨æ¢ç´¢è¯Šæ–­è·¯å¾„ï¼Œå¹¶åˆ©ç”¨ DeepSeek-R1 ç­‰æ¨ç†æ¨¡å‹æ¨æ–­æ ¹å› å¹¶ç”Ÿæˆè¯Šæ–­æŠ¥å‘Šã€‚åœ¨ Oracleã€MySQLã€PostgreSQL å’Œè¾¾æ¢¦ (DM8) æ•°æ®åº“ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒDBAIOps åœ¨æ ¹å› å‡†ç¡®ç‡å’Œäººå·¥è¯„ä¼°æ»¡æ„åº¦ä¸Šåˆ†åˆ«æ¯”ç°æœ‰æŠ€æœ¯é«˜å‡º 34.85% å’Œ 47.22%ï¼Œè¯æ˜äº†å…¶åœ¨å¤æ‚æ•°æ®åº“è¿ç»´åœºæ™¯ä¸­çš„å“è¶Šæ€§èƒ½ã€‚",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.DB",
      "comment": "DBAIOps supports 25 database systems and has been deployed in 20 real-world scenarios, covering domains like finance, energy, and healthcare. See website at: https://www.dbaiops.com; See code at: https://github.com/weAIDB/DBAIOps/",
      "pdf_url": "https://arxiv.org/pdf/2508.01136v1",
      "published_date": "2025-08-02 01:36:57 UTC",
      "updated_date": "2025-08-02 01:36:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:25:42.739162+00:00"
    },
    {
      "arxiv_id": "2508.01131v2",
      "title": "COLLAGE: Adaptive Fusion-based Retrieval for Augmented Policy Learning",
      "title_zh": "COLLAGEï¼šé¢å‘å¢å¼ºç­–ç•¥å­¦ä¹ çš„è‡ªé€‚åº”èåˆæ£€ç´¢",
      "authors": [
        "Sateesh Kumar",
        "Shivin Dass",
        "Georgios Pavlakos",
        "Roberto MartÃ­n-MartÃ­n"
      ],
      "abstract": "In this work, we study the problem of data retrieval for few-shot imitation learning: selecting data from a large dataset to train a performant policy for a specific task, given only a few target demonstrations. Prior methods retrieve data using a single-feature distance heuristic, assuming that the best demonstrations are those that most closely resemble the target examples in visual, semantic, or motion space. However, this approach captures only a subset of the relevant information and can introduce detrimental demonstrations, e.g., retrieving data from unrelated tasks due to similar scene layouts, or selecting similar motions from tasks with divergent goals. We present COLLAGE, a method for COLLective data AGgrEgation in few-shot imitation learning that uses an adaptive late fusion mechanism to guide the selection of relevant demonstrations based on a task-specific combination of multiple cues. COLLAGE follows a simple, flexible, and efficient recipe: it assigns weights to subsets of the dataset that are pre-selected using a single feature (e.g., appearance, shape, or language similarity), based on how well a policy trained on each subset predicts actions in the target demonstrations. These weights are then used to perform importance sampling during policy training, sampling data more densely or sparsely according to estimated relevance. COLLAGE is general and feature-agnostic, allowing it to combine any number of subsets selected by any retrieval heuristic, and to identify which subsets provide the greatest benefit for the target task. In extensive experiments, COLLAGE outperforms state-of-the-art retrieval and multi-task learning approaches by 5.1% in simulation across 10 tasks, and by 16.6% in the real world across 6 tasks, where we perform retrieval from the large-scale DROID dataset. More information at https://robin-lab.cs.utexas.edu/COLLAGE .",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† COLLAGEï¼Œä¸€ç§ç”¨äºå°‘æ ·æœ¬æ¨¡ä»¿å­¦ä¹  (few-shot imitation learning) çš„è‡ªé€‚åº”èåˆæ•°æ®æ£€ç´¢æ–¹æ³•ï¼Œæ—¨åœ¨ä»å¤§è§„æ¨¡æ•°æ®é›†ä¸­é«˜æ•ˆé€‰æ‹©ç›¸å…³æ¼”ç¤ºæ•°æ®ä»¥è®­ç»ƒç‰¹å®šä»»åŠ¡çš„ç­–ç•¥ã€‚é’ˆå¯¹ä¼ ç»Ÿæ–¹æ³•ä¾èµ–å•ä¸€ç‰¹å¾å¯å‘å¼ï¼ˆå¦‚è§†è§‰æˆ–è¯­ä¹‰ç›¸ä¼¼åº¦ï¼‰å®¹æ˜“å¼•å…¥æ— å…³å¹²æ‰°çš„é—®é¢˜ï¼ŒCOLLAGE å¼•å…¥äº†è‡ªé€‚åº”åæœŸèåˆ (late fusion) æœºåˆ¶ï¼Œé€šè¿‡ç»„åˆå¤šç§çº¿ç´¢æ¥å¼•å¯¼æ•°æ®é€‰æ‹©ã€‚è¯¥æ–¹æ³•æ ¹æ®åœ¨é¢„é€‰å­é›†ä¸Šè®­ç»ƒçš„ç­–ç•¥å¯¹ç›®æ ‡æ¼”ç¤ºåŠ¨ä½œçš„é¢„æµ‹å‡†ç¡®åº¦æ¥åˆ†é…æƒé‡ï¼Œå¹¶åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­é€šè¿‡é‡è¦æ€§é‡‡æ · (importance sampling) ä¼˜å…ˆé€‰å–é«˜ç›¸å…³æ€§æ•°æ®ã€‚COLLAGE å…·æœ‰é€šç”¨ä¸”ä¸ä¾èµ–ç‰¹å®šç‰¹å¾çš„ç‰¹æ€§ï¼Œèƒ½å¤Ÿçµæ´»æ•´åˆä»»ä½•æ•°é‡çš„æ£€ç´¢å¯å‘å¼å¹¶è¯†åˆ«æœ€æœ‰ç›Šçš„æ•°æ®ç»„åˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCOLLAGE åœ¨æ¨¡æ‹Ÿä»»åŠ¡å’ŒåŸºäº DROID æ•°æ®é›†çš„çœŸå®ä¸–ç•Œæœºå™¨äººå®éªŒä¸­ï¼Œåˆ†åˆ«æ¯”ç°æœ‰æœ€å…ˆè¿›çš„æ£€ç´¢æ–¹æ³•å‡†ç¡®ç‡æå‡äº† 5.1% å’Œ 16.6%ï¼ŒéªŒè¯äº†å…¶åœ¨å¤æ‚ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§å’Œé²æ£’æ€§ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted at the Conference on Robot Learning (CoRL), 2025. Project page: https://robin-lab.cs.utexas.edu/COLLAGE",
      "pdf_url": "https://arxiv.org/pdf/2508.01131v2",
      "published_date": "2025-08-02 01:23:09 UTC",
      "updated_date": "2025-09-07 01:44:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:26:00.754404+00:00"
    },
    {
      "arxiv_id": "2508.01129v1",
      "title": "Human-Robot Red Teaming for Safety-Aware Reasoning",
      "title_zh": "é¢å‘å®‰å…¨æ„ŸçŸ¥æ¨ç†çš„äººæœºçº¢é˜Ÿ",
      "authors": [
        "Emily Sheetz",
        "Emma Zemler",
        "Misha Savchenko",
        "Connor Rainen",
        "Erik Holum",
        "Jodi Graf",
        "Andrew Albright",
        "Shaun Azimi",
        "Benjamin Kuipers"
      ],
      "abstract": "While much research explores improving robot capabilities, there is a deficit in researching how robots are expected to perform tasks safely, especially in high-risk problem domains. Robots must earn the trust of human operators in order to be effective collaborators in safety-critical tasks, specifically those where robots operate in human environments. We propose the human-robot red teaming paradigm for safety-aware reasoning. We expect humans and robots to work together to challenge assumptions about an environment and explore the space of hazards that may arise. This exploration will enable robots to perform safety-aware reasoning, specifically hazard identification, risk assessment, risk mitigation, and safety reporting. We demonstrate that: (a) human-robot red teaming allows human-robot teams to plan to perform tasks safely in a variety of domains, and (b) robots with different embodiments can learn to operate safely in two different environments -- a lunar habitat and a household -- with varying definitions of safety. Taken together, our work on human-robot red teaming for safety-aware reasoning demonstrates the feasibility of this approach for safely operating and promoting trust on human-robot teams in safety-critical problem domains.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†äººæœºçº¢è“å¯¹æŠ—(Human-Robot Red Teaming)èŒƒå¼ï¼Œæ—¨åœ¨æå‡æœºå™¨äººåœ¨é«˜é£é™©å’Œå®‰å…¨å…³é”®é¢†åŸŸä¸­çš„å®‰å…¨æ„ŸçŸ¥æ¨ç†(Safety-Aware Reasoning)èƒ½åŠ›ã€‚è¯¥èŒƒå¼é€šè¿‡äººç±»ä¸æœºå™¨äººååŒæŒ‘æˆ˜ç¯å¢ƒå‡è®¾å¹¶æ¢ç´¢æ½œåœ¨å±é™©ç©ºé—´ï¼Œä½¿æœºå™¨äººèƒ½å¤Ÿæ‰§è¡Œå±é™©è¯†åˆ«(Hazard Identification)ã€é£é™©è¯„ä¼°(Risk Assessment)ã€é£é™©ç¼“è§£(Risk Mitigation)å’Œå®‰å…¨æŠ¥å‘Š(Safety Reporting)ç­‰å…³é”®ä»»åŠ¡ã€‚ç ”ç©¶åœ¨æœˆçƒæ –æ¯åœ°(Lunar Habitat)å’Œå®¶åº­ç¯å¢ƒ(Household)ç­‰å…·æœ‰ä¸åŒå®‰å…¨å®šä¹‰çš„åœºæ™¯ä¸­è¿›è¡Œäº†éªŒè¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä¸åŒå½¢æ€çš„æœºå™¨äººå‡èƒ½é€šè¿‡è¯¥æ–¹æ³•å­¦ä¼šåœ¨å¤šæ ·åŒ–é¢†åŸŸä¸­å®‰å…¨åœ°æ‰§è¡Œä»»åŠ¡è§„åˆ’ã€‚è¯¥å·¥ä½œè¯æ˜äº†åˆ©ç”¨çº¢è“å¯¹æŠ—æœºåˆ¶å®ç°å®‰å…¨æ„ŸçŸ¥æ¨ç†çš„å¯è¡Œæ€§ï¼Œå¯¹äºåœ¨å¤æ‚ç¯å¢ƒä¸­å»ºç«‹äººæœºåä½œçš„ä¿¡ä»»å…·æœ‰é‡è¦æ„ä¹‰ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 6 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.01129v1",
      "published_date": "2025-08-02 00:55:09 UTC",
      "updated_date": "2025-08-02 00:55:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:25:44.628185+00:00"
    },
    {
      "arxiv_id": "2508.01128v1",
      "title": "Towards Bridging Review Sparsity in Recommendation with Textual Edge Graph Representation",
      "title_zh": "é€šè¿‡æ–‡æœ¬è¾¹å›¾è¡¨ç¤ºå¼¥åˆæ¨èç³»ç»Ÿä¸­çš„è¯„è®ºç¨€ç–æ€§",
      "authors": [
        "Leyao Wang",
        "Xutao Mao",
        "Xuhui Zhan",
        "Yuying Zhao",
        "Bo Ni",
        "Ryan A. Rossi",
        "Nesreen K. Ahmed",
        "Tyler Derr"
      ],
      "abstract": "Textual reviews enrich recommender systems with fine-grained preference signals and enhanced explainability. However, in real-world scenarios, users rarely leave reviews, resulting in severe sparsity that undermines the effectiveness of existing models. A natural solution is to impute or generate missing reviews to enrich the data. However, conventional imputation techniques -- such as matrix completion and LLM-based augmentation -- either lose contextualized semantics by embedding texts into vectors, or overlook structural dependencies among user-item interactions. To address these shortcomings, we propose TWISTER (ToWards Imputation on Sparsity with Textual Edge Graph Representation), a unified framework that imputes missing reviews by jointly modeling semantic and structural signals. Specifically, we represent user-item interactions as a Textual-Edge Graph (TEG), treating reviews as edge attributes. To capture relational context, we construct line-graph views and employ a large language model as a graph-aware aggregator. For each interaction lacking a textual review, our model aggregates the neighborhood's natural-language representations to generate a coherent and personalized review. Experiments on the Amazon and Goodreads datasets show that TWISTER consistently outperforms traditional numeric, graph-based, and LLM baselines, delivering higher-quality imputed reviews and, more importantly, enhanced recommendation performance. In summary, TWISTER generates reviews that are more helpful, authentic, and specific, while smoothing structural signals for improved recommendations.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ¨èç³»ç»Ÿä¸­è¯„è®ºç¨€ç–æ€§(Review Sparsity)ä¸¥é‡å‰Šå¼±æ¨¡å‹æœ‰æ•ˆæ€§çš„é—®é¢˜ï¼ŒæŒ‡å‡ºä¼ ç»Ÿå¡«è¡¥æŠ€æœ¯å¾€å¾€ä¼šä¸¢å¤±ä¸Šä¸‹æ–‡è¯­ä¹‰æˆ–å¿½è§†ç”¨æˆ·-ç‰©å“äº¤äº’çš„ç»“æ„ä¾èµ–ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†TWISTERï¼ˆToWards Imputation on Sparsity with Textual Edge Graph Representationï¼‰ç»Ÿä¸€æ¡†æ¶ï¼Œé€šè¿‡è”åˆå»ºæ¨¡è¯­ä¹‰å’Œç»“æ„ä¿¡å·æ¥å¡«è¡¥ç¼ºå¤±çš„è¯„è®ºã€‚è¯¥æ¡†æ¶å°†ç”¨æˆ·-ç‰©å“äº¤äº’è¡¨ç¤ºä¸ºæ–‡æœ¬è¾¹å›¾(Textual-Edge Graph, TEG)ï¼Œå°†è¯„è®ºè§†ä¸ºè¾¹å±æ€§ï¼Œå¹¶åˆ©ç”¨çº¿å›¾(Line-graph)è§†å›¾å’Œå¤§å‹è¯­è¨€æ¨¡å‹(LLM)ä½œä¸ºæ„ŸçŸ¥å›¾çš„èšåˆå™¨ã€‚é€šè¿‡èšåˆé‚»åŸŸçš„è‡ªç„¶è¯­è¨€è¡¨ç¤ºï¼ŒTWISTERèƒ½å¤Ÿä¸ºæ¯ä¸ªç¼ºä¹è¯„è®ºçš„äº¤äº’ç”Ÿæˆè¿è´¯ä¸”ä¸ªæ€§åŒ–çš„æ–‡æœ¬å†…å®¹ã€‚åœ¨Amazonå’ŒGoodreadsæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒTWISTERåœ¨ç”Ÿæˆé«˜è´¨é‡è¯„è®ºåŠæå‡æ¨èæ€§èƒ½æ–¹é¢å‡æ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„æ•°å€¼å‹ã€å›¾æ¨¡å‹åŠLLMåŸºå‡†æ–¹æ³•ã€‚æ€»ç»“è€Œè¨€ï¼ŒTWISTERç”Ÿæˆçš„è¯„è®ºæ›´å…·å®ç”¨æ€§ã€çœŸå®æ€§å’Œå…·ä½“æ€§ï¼ŒæˆåŠŸé€šè¿‡å¹³æ»‘ç»“æ„ä¿¡å·å®ç°äº†æ›´ç²¾å‡†çš„æ¨èã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "13 pages",
      "pdf_url": "https://arxiv.org/pdf/2508.01128v1",
      "published_date": "2025-08-02 00:53:40 UTC",
      "updated_date": "2025-08-02 00:53:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:26:12.945351+00:00"
    },
    {
      "arxiv_id": "2508.06524v1",
      "title": "CarbonScaling: Extending Neural Scaling Laws for Carbon Footprint in Large Language Models",
      "title_zh": "CarbonScalingï¼šå¤§è¯­è¨€æ¨¡å‹ç¢³è¶³è¿¹çš„ç¥ç»ç¼©æ”¾æ³•åˆ™æ‰©å±•",
      "authors": [
        "Lei Jiang",
        "Fan Chen"
      ],
      "abstract": "Neural scaling laws have driven the development of increasingly large language models (LLMs) by linking accuracy improvements to growth in parameter count, dataset size, and compute. However, these laws overlook the carbon emissions that scale exponentially with LLM size. This paper presents \\textit{CarbonScaling}, an analytical framework that extends neural scaling laws to incorporate both operational and embodied carbon in LLM training. By integrating models for neural scaling, GPU hardware evolution, parallelism optimization, and carbon estimation, \\textit{CarbonScaling} quantitatively connects model accuracy to carbon footprint. Results show that while a power-law relationship between accuracy and carbon holds, real-world inefficiencies significantly increase the scaling factor. Hardware technology scaling reduces carbon emissions for small to mid-sized models, but offers diminishing returns for extremely large LLMs due to communication overhead and underutilized GPUs. Training optimizations-especially aggressive critical batch size scaling-help alleviate this inefficiency. \\textit{CarbonScaling} offers key insights for training more sustainable and carbon-efficient LLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†CarbonScalingï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨å°†ç¥ç»ç½‘ç»œç¼©æ”¾å®šå¾‹(Neural Scaling Laws)æ‰©å±•åˆ°å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)ç¢³è¶³è¿¹è¯„ä¼°çš„åˆ†ææ¡†æ¶ã€‚è¯¥æ¡†æ¶ç»¼åˆäº†ç¥ç»ç½‘ç»œç¼©æ”¾æ¨¡å‹ã€GPUç¡¬ä»¶æ¼”è¿›ã€å¹¶è¡ŒåŒ–ä¼˜åŒ–å’Œç¢³è¶³è¿¹ä¼°ç®—æŠ€æœ¯ï¼Œå®ç°äº†æ¨¡å‹å‡†ç¡®åº¦ä¸ç¢³æ’æ”¾ä¹‹é—´çš„å®šé‡å…³è”ï¼Œå¹¶åŒæ—¶è€ƒè™‘äº†è¿è¡Œç¢³æ’æ”¾(Operational Carbon)ä¸éšå«ç¢³(Embodied Carbon)ã€‚ç ”ç©¶å‘ç°ï¼Œè™½ç„¶å‡†ç¡®åº¦ä¸ç¢³æ’æ”¾ä¹‹é—´éµå¾ªå¹‚å¾‹å…³ç³»(Power-law Relationship)ï¼Œä½†ç°å®ä¸­çš„ä½æ•ˆç‡æ˜¾è‘—æé«˜äº†ç¼©æ”¾å› å­ã€‚å°½ç®¡ç¡¬ä»¶æŠ€æœ¯è¿›æ­¥èƒ½å‡å°‘ä¸­å°å‹æ¨¡å‹çš„ç¢³æ’æ”¾ï¼Œä½†å—é™äºé€šä¿¡å¼€é”€å’ŒGPUåˆ©ç”¨ç‡ä¸è¶³ï¼Œå…¶åœ¨å¤§è§„æ¨¡æ¨¡å‹ä¸Šçš„æ”¶ç›Šé€æ¸é€’å‡ã€‚é€šè¿‡ä¼˜åŒ–è®­ç»ƒç­–ç•¥ï¼Œç‰¹åˆ«æ˜¯ç§¯æçš„ä¸´ç•Œæ‰¹é‡å¤§å°(Critical Batch Size)ç¼©æ”¾ï¼Œå¯ä»¥æœ‰æ•ˆç¼“è§£æ­¤ç±»æ•ˆç‡é—®é¢˜ã€‚CarbonScalingä¸ºå¼€å‘æ›´å…·å¯æŒç»­æ€§ä¸”é«˜æ•ˆåˆ©ç”¨ç¢³èµ„æºçš„LLMsæä¾›äº†å…³é”®è§è§£ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.DC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages",
      "pdf_url": "https://arxiv.org/pdf/2508.06524v1",
      "published_date": "2025-08-02 00:41:45 UTC",
      "updated_date": "2025-08-02 00:41:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:26:19.034041+00:00"
    },
    {
      "arxiv_id": "2508.02734v1",
      "title": "Recovering Individual-Level Activity Sequences from Location-Based Service Data Using a Novel Transformer-Based Model",
      "title_zh": "åŸºäºæ–°å‹ Transformer æ¨¡å‹ä»ä½ç½®æœåŠ¡æ•°æ®ä¸­æ¢å¤ä¸ªä½“çº§æ´»åŠ¨åºåˆ—",
      "authors": [
        "Weiyu Luo",
        "Chenfeng Xiong"
      ],
      "abstract": "Location-Based Service (LBS) data provides critical insights into human mobility, yet its sparsity often yields incomplete trip and activity sequences, making accurate inferences about trips and activities difficult. We raise a research problem: Can we use activity sequences derived from high-quality LBS data to recover incomplete activity sequences at the individual level? This study proposes a new solution, the Variable Selection Network-fused Insertion Transformer (VSNIT), integrating the Insertion Transformer's flexible sequence construction with the Variable Selection Network's dynamic covariate handling capability, to recover missing segments in incomplete activity sequences while preserving existing data. The findings show that VSNIT inserts more diverse, realistic activity patterns, more closely matching real-world variability, and restores disrupted activity transitions more effectively aligning with the target. It also performs significantly better than the baseline model across all metrics. These results highlight VSNIT's superior accuracy and diversity in activity sequence recovery tasks, demonstrating its potential to enhance LBS data utility for mobility analysis. This approach offers a promising framework for future location-based research and applications.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸºäºåœ°ç†ä½ç½®çš„æœåŠ¡(LBS, Location-Based Service)æ•°æ®ç¨€ç–å¯¼è‡´ä¸ªä½“è¡Œç¨‹å’Œæ´»åŠ¨åºåˆ—ä¸å®Œæ•´çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºVSNIT(Variable Selection Network-fused Insertion Transformer)çš„æ–°å‹æ¨¡å‹ã€‚è¯¥æ¨¡å‹é€šè¿‡é›†æˆInsertion Transformerçµæ´»çš„åºåˆ—æ„å»ºèƒ½åŠ›ä¸Variable Selection NetworkåŠ¨æ€å¤„ç†åå˜é‡çš„èƒ½åŠ›ï¼Œèƒ½å¤Ÿåœ¨ä¿ç•™æ—¢æœ‰æ•°æ®çš„å‰æä¸‹ï¼Œæœ‰æ•ˆæ¢å¤æ´»åŠ¨åºåˆ—ä¸­çš„ç¼ºå¤±ç‰‡æ®µã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒVSNITèƒ½å¤Ÿç”Ÿæˆæ¯”åŸºçº¿æ¨¡å‹æ›´å…·å¤šæ ·æ€§ä¸”æ›´ç¬¦åˆç°å®è§„å¾‹çš„æ´»åŠ¨æ¨¡å¼ï¼Œæ›´å‡†ç¡®åœ°è¿˜åŸä¸­æ–­çš„æ´»åŠ¨è½¬æ¢ã€‚æ­¤å¤–ï¼ŒVSNITåœ¨æ‰€æœ‰è¯„ä¼°æŒ‡æ ‡ä¸Šå‡è¡¨ç°å‡ºæ˜¾è‘—ä¼˜åŠ¿ï¼Œè¯æ˜äº†å…¶åœ¨ä¸ªä½“å±‚çº§æ´»åŠ¨åºåˆ—æ¢å¤ä»»åŠ¡ä¸­çš„å“è¶Šæ€§èƒ½ã€‚è¿™é¡¹ç ”ç©¶ä¸ä»…æå‡äº†LBSæ•°æ®åœ¨ç§»åŠ¨æ€§åˆ†æä¸­çš„åº”ç”¨æ•ˆèƒ½ï¼Œä¹Ÿä¸ºæœªæ¥ç›¸å…³çš„åœ°ç†ä½ç½®ç ”ç©¶ä¸åº”ç”¨æä¾›äº†ä¸€ä¸ªæå…·æ½œåŠ›çš„æŠ€æœ¯æ¡†æ¶ã€‚",
      "categories": [
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.AI",
      "comment": "20 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.02734v1",
      "published_date": "2025-08-02 00:33:18 UTC",
      "updated_date": "2025-08-02 00:33:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T08:26:24.631503+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 93,
  "processed_papers_count": 93,
  "failed_papers_count": 0,
  "llm_backup_calls": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-01-24T08:27:48.168871+00:00"
}