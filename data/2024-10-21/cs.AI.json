{
  "date": "2024-10-21",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-10-21 的 arXiv 中文 TLDR 快报！\n\n今天的 arXiv 论文主要聚焦于 AI 模型的优化、安全性与实际应用，尤其在大型语言模型（LLMs）、医疗图像处理和强化学习领域，亮点包括使用 LLMs 进行定理证明和高效计算的创新方法，以及 Salesforce 和 OpenAI 等机构的贡献，强调了模型泛化、偏见缓解和多模态融合的潜力。\n\n### 重点论文讨论\n我将优先讨论重要、令人印象深刻的论文，例如那些涉及 LLMs 创新、医疗应用和高效算法的，并将相关主题归类快速概述。其他较常规或次要论文（如某些交通模拟或数据增强方法）将简要掠过，以控制篇幅。\n\n#### LLMs 和 AI 优化（高话题度领域）\n- **Bayesian scaling laws for in-context learning**（中文：基于贝叶斯定律的上下文内学习缩放定律；英文：Bayesian scaling laws for in-context learning）  \n  作者包括 Aryaman Arora 和 Noah D. Goodman，这篇论文的主要贡献是提出贝叶斯方法解释 LLMs 的 in-context learning，发现它能更好地预测模型性能，并应用于安全对齐实验，揭示了 LLMs 在多示例学习中的鲁棒性。\n\n- **A Theoretical Understanding of Chain-of-Thought: Coherent Reasoning and Error-Aware Demonstration**（中文：链式思考的理论理解：连贯推理和错误感知演示；英文：A Theoretical Understanding of Chain-of-Thought）  \n  作者如 Yingqian Cui 和 Jiliang Tang 证明了链式思考（CoT）能提升 LLMs 的错误修正能力，通过整合推理步骤实现更准确预测，并提出改进策略，实验验证了其在实际任务中的有效性。\n\n- **Combining Theory of Mind and Kindness for Self-Supervised Human-AI Alignment**（中文：结合理论心智和仁慈进行自监督的人机对齐；英文：Combining Theory of Mind and Kindness for Self-Supervised Human-AI Alignment）  \n  作者 Joshua T. S. Hewson 探索了 LLMs 的安全对齐，引入“仁慈”动机来减少有害行为，理论上证明了这种方法能提升 AI 的社会智能和决策可靠性。\n\n- **We Urgently Need Intrinsically Kind Machines**（中文：我们迫切需要内在仁慈的机器；英文：We Urgently Need Intrinsically Kind Machines）  \n  同样由 Joshua T. S. Hewson，这篇论文强调嵌入“仁慈”动机以实现 AI 与人类价值观对齐，提出算法框架来减少潜在风险，呼应了 AI 伦理话题。\n\n这些 LLMs 相关论文突出了模型对齐和推理能力的提升，OpenAI 等机构的潜在影响使其更具话题度，但存在泛化挑战，如后续论文提到的偏见问题。\n\n#### 医疗 AI 应用（实际影响强）\n- **How Can We Diagnose and Treat Bias in Large Language Models for Clinical Decision-Making?**（中文：如何诊断和处理 LLMs 在临床决策中的偏见；英文：How Can We Diagnose and Treat Bias in Large Language Models for Clinical Decision-Making?）  \n  作者如 Kenza Benkirane 引入 Counterfactual Patient Variations 数据集，构建偏见评估框架，实验显示 LLMs 在缓解性别偏见时可能引入种族偏见，并提出多维度缓解策略，提升了临床应用的可靠性。\n\n- **Multi-Agent LLMs Ensemble for Efficient Atrial Fibrillation Annotation of ECG Reports**（中文：多代理 LLMs 集成用于心房颤动 ECG 报告标注；英文：Multi-Agent LLMs Ensemble for Efficient Atrial Fibrillation Annotation of ECG Reports）  \n  作者团队包括 Yang Xie，这篇论文提出多代理 LLMs 集成方法，实现了高效的 EHR 数据标注，实验显示其准确率达 98.2%，显著减少了标注错误和人工努力。\n\n- **Teach Multimodal LLMs to Comprehend Electrocardiographic Images**（中文：教多模态 LLMs 理解心电图图像；英文：Teach Multimodal LLMs to Comprehend Electrocardiographic Images）  \n  作者如 Ping Zhang 构建 ECGInstruct 数据集，并开发 PULSE 模型，提升 LLMs 在 ECG 图像分析中的准确性，实验结果显示其在多任务上优于基线模型。\n\n这些医疗论文强调了 LLMs 在偏见缓解和图像分析中的潜力，贡献在于实际应用，如 ECG 诊断，但需注意数据隐私问题。\n\n#### 强化学习和模型高效性（技术创新高）\n- **Implicit Contact Diffuser: Sequential Contact Reasoning with Latent Point Cloud Diffusion**（中文：隐式接触扩散器：基于潜在点云扩散的顺序接触推理；英文：Implicit Contact Diffuser）  \n  作者如 Dmitry Berenson 提出基于扩散模型的接触推理方法，能处理长时序机械臂任务，实验显示其在复杂场景中优于基线，提升了机器人操作的鲁棒性。\n\n- **QIXAI: A Quantum-Inspired Framework for Enhancing Classical and Quantum Model Transparency**（中文：QIXAI：增强经典和量子模型透明度的量子启发框架；英文：QIXAI）  \n  作者 John M. Willis 引入量子启发框架提升模型可解释性，使用 SVD 和 PCA 分析神经网络行为，实验证明其在医疗等领域提高了模型透明度。\n\n其他如交通或量子计算论文（如量子传播器）虽有贡献，但相对常规，我快速掠过：例如，**On conditional diffusion models for PDE simulations**（中文：条件扩散模型在 PDE 模拟中的应用；英文：On conditional diffusion models for PDE simulations）改进了模拟效率，但影响较局限于特定领域，不做深入讨论。\n\n总体而言，今天的论文展示了 AI 模型在优化和应用上的进展，LLMs 相关工作最引人注目，但需关注偏见和泛化问题。未来研究可聚焦实际部署和伦理挑战。",
  "papers": [
    {
      "arxiv_id": "2410.16579v1",
      "title": "Conflict-Aware Adversarial Training",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiyu Xue",
        "Haohan Wang",
        "Yao Qin",
        "Ramtin Pedarsani"
      ],
      "abstract": "Adversarial training is the most effective method to obtain adversarial\nrobustness for deep neural networks by directly involving adversarial samples\nin the training procedure. To obtain an accurate and robust model, the\nweighted-average method is applied to optimize standard loss and adversarial\nloss simultaneously. In this paper, we argue that the weighted-average method\ndoes not provide the best tradeoff for the standard performance and adversarial\nrobustness. We argue that the failure of the weighted-average method is due to\nthe conflict between the gradients derived from standard and adversarial loss,\nand further demonstrate such a conflict increases with attack budget\ntheoretically and practically. To alleviate this problem, we propose a new\ntrade-off paradigm for adversarial training with a conflict-aware factor for\nthe convex combination of standard and adversarial loss, named\n\\textbf{Conflict-Aware Adversarial Training~(CA-AT)}. Comprehensive\nexperimental results show that CA-AT consistently offers a superior trade-off\nbetween standard performance and adversarial robustness under the settings of\nadversarial training from scratch and parameter-efficient finetuning.",
      "tldr_zh": "该论文指出，传统对抗训练(adversarial training)使用加权平均方法优化标准损失和对抗损失，但由于两者梯度间的冲突，这种方法无法实现最佳的性能和鲁棒性权衡。作者理论上和实验上证明，这种冲突会随着攻击预算(attack budget)增加而加剧。为解决这一问题，他们提出了一种新的框架Conflict-Aware Adversarial Training (CA-AT)，通过引入冲突感知因子(conflict-aware factor)来优化损失函数的凸组合。实验结果显示，CA-AT在从零开始训练和参数高效微调(settings of adversarial training from scratch and parameter-efficient finetuning)下，一致地提升了标准性能和对抗鲁棒性(adversarial robustness)的权衡。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16579v1",
      "published_date": "2024-10-21 23:44:03 UTC",
      "updated_date": "2024-10-21 23:44:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:09:52.267270"
    },
    {
      "arxiv_id": "2410.16574v1",
      "title": "How Can We Diagnose and Treat Bias in Large Language Models for Clinical Decision-Making?",
      "title_zh": "翻译失败",
      "authors": [
        "Kenza Benkirane",
        "Jackie Kay",
        "Maria Perez-Ortiz"
      ],
      "abstract": "Recent advancements in Large Language Models (LLMs) have positioned them as\npowerful tools for clinical decision-making, with rapidly expanding\napplications in healthcare. However, concerns about bias remain a significant\nchallenge in the clinical implementation of LLMs, particularly regarding gender\nand ethnicity. This research investigates the evaluation and mitigation of bias\nin LLMs applied to complex clinical cases, focusing on gender and ethnicity\nbiases. We introduce a novel Counterfactual Patient Variations (CPV) dataset\nderived from the JAMA Clinical Challenge. Using this dataset, we built a\nframework for bias evaluation, employing both Multiple Choice Questions (MCQs)\nand corresponding explanations. We explore prompting with eight LLMs and\nfine-tuning as debiasing methods. Our findings reveal that addressing social\nbiases in LLMs requires a multidimensional approach as mitigating gender bias\ncan occur while introducing ethnicity biases, and that gender bias in LLM\nembeddings varies significantly across medical specialities. We demonstrate\nthat evaluating both MCQ response and explanation processes is crucial, as\ncorrect responses can be based on biased \\textit{reasoning}. We provide a\nframework for evaluating LLM bias in real-world clinical cases, offer insights\ninto the complex nature of bias in these models, and present strategies for\nbias mitigation.",
      "tldr_zh": "该研究探讨了大型语言模型 (LLMs) 在临床决策中的性别和种族偏见问题，并提出诊断和缓解策略。研究者引入了 Counterfactual Patient Variations (CPV) 数据集，基于 JAMA Clinical Challenge，构建了一个偏见评估框架，使用 Multiple Choice Questions (MCQs) 和解释过程来评估模型偏见。实验通过提示工程和微调方法发现，缓解性别偏见可能导致种族偏见增加，且 LLMs 中的偏见在不同医疗专业间差异显著。强调评估响应和推理过程至关重要，因为正确答案可能基于偏见推理；该框架为实际临床场景提供实用洞见和偏见缓解策略。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16574v1",
      "published_date": "2024-10-21 23:14:10 UTC",
      "updated_date": "2024-10-21 23:14:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:10:05.644966"
    },
    {
      "arxiv_id": "2410.16571v1",
      "title": "Implicit Contact Diffuser: Sequential Contact Reasoning with Latent Point Cloud Diffusion",
      "title_zh": "翻译失败",
      "authors": [
        "Zixuan Huang",
        "Yinong He",
        "Yating Lin",
        "Dmitry Berenson"
      ],
      "abstract": "Long-horizon contact-rich manipulation has long been a challenging problem,\nas it requires reasoning over both discrete contact modes and continuous object\nmotion. We introduce Implicit Contact Diffuser (ICD), a diffusion-based model\nthat generates a sequence of neural descriptors that specify a series of\ncontact relationships between the object and the environment. This sequence is\nthen used as guidance for an MPC method to accomplish a given task. The key\nadvantage of this approach is that the latent descriptors provide more\ntask-relevant guidance to MPC, helping to avoid local minima for contact-rich\nmanipulation tasks. Our experiments demonstrate that ICD outperforms baselines\non complex, long-horizon, contact-rich manipulation tasks, such as cable\nrouting and notebook folding. Additionally, our experiments also indicate that\n\\methodshort can generalize a target contact relationship to a different\nenvironment. More visualizations can be found on our website\n$\\href{https://implicit-contact-diffuser.github.io/}{https://implicit-contact-diffuser.github.io}$",
      "tldr_zh": "本文提出Implicit Contact Diffuser (ICD)，一个基于diffusion模型的框架，用于处理长时段接触丰富的操作任务，通过生成一系列神经描述符来指定物体与环境的接触关系序列，并以此指导MPC (Model Predictive Control) 方法。相比传统方法，ICD提供更相关的任务指导，帮助避免局部最小值。实验结果表明，ICD在复杂任务如电缆路由和笔记本折叠上优于基线模型，并能将目标接触关系泛化到不同环境。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "In submussion",
      "pdf_url": "http://arxiv.org/pdf/2410.16571v1",
      "published_date": "2024-10-21 23:07:48 UTC",
      "updated_date": "2024-10-21 23:07:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:10:16.827807"
    },
    {
      "arxiv_id": "2410.16560v2",
      "title": "How Performance Pressure Influences AI-Assisted Decision Making",
      "title_zh": "绩效压力如何影响AI辅助决策",
      "authors": [
        "Nikita Haduong",
        "Noah A. Smith"
      ],
      "abstract": "Many domains now employ AI-based decision-making aids, and although the\npotential for AI systems to assist with decision making is much discussed,\nhuman-AI collaboration often underperforms due to factors such as (mis)trust in\nthe AI system and beliefs about AI being incapable of completing subjective\ntasks. One potential tool for influencing human decision making is performance\npressure, which hasn't been much studied in interaction with human-AI decision\nmaking. In this work, we examine how pressure and explainable AI (XAI)\ntechniques interact with AI advice-taking behavior. Using an inherently\nlow-stakes task (spam review classification), we demonstrate effective and\nsimple methods to apply pressure and influence human AI advice-taking behavior\nby manipulating financial incentives and imposing time limits. Our results show\ncomplex interaction effects, with different combinations of pressure and XAI\ntechniques either improving or worsening AI advice taking behavior. We conclude\nby discussing the implications of these interactions, strategies to effectively\nuse pressure, and encourage future research to incorporate pressure analysis.",
      "tldr_zh": "这篇论文探讨了性能压力(performance pressure)如何影响人类在AI辅助决策中的行为，特别是与可解释AI(XAI)技术的互动。研究者通过在垃圾评论分类等低风险任务中操纵财务激励和时间限制来施加压力，观察其对AI建议采纳行为的影响。结果显示，不同的压力与XAI组合会产生复杂互动效应，有的改善了AI建议的采用，而有的则使其恶化。论文强调了这些互动的含义，并提出有效利用压力的策略，鼓励未来研究纳入压力分析。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16560v2",
      "published_date": "2024-10-21 22:39:52 UTC",
      "updated_date": "2025-02-21 19:29:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:10:29.166552"
    },
    {
      "arxiv_id": "2410.16547v1",
      "title": "PromptHive: Bringing Subject Matter Experts Back to the Forefront with Collaborative Prompt Engineering for Educational Content Creation",
      "title_zh": "翻译失败",
      "authors": [
        "Mohi Reza",
        "Ioannis Anastasopoulos",
        "Shreya Bhandari",
        "Zachary A. Pardos"
      ],
      "abstract": "Involving subject matter experts in prompt engineering can guide LLM outputs\ntoward more helpful, accurate, and tailored content that meets the diverse\nneeds of different domains. However, iterating towards effective prompts can be\nchallenging without adequate interface support for systematic experimentation\nwithin specific task contexts. In this work, we introduce PromptHive, a\ncollaborative interface for prompt authoring, designed to better connect domain\nknowledge with prompt engineering through features that encourage rapid\niteration on prompt variations. We conducted an evaluation study with ten\nsubject matter experts in math and validated our design through two\ncollaborative prompt-writing sessions and a learning gain study with 358\nlearners. Our results elucidate the prompt iteration process and validate the\ntool's usability, enabling non-AI experts to craft prompts that generate\ncontent comparable to human-authored materials while reducing perceived\ncognitive load by half and shortening the authoring process from several months\nto just a few hours.",
      "tldr_zh": "本研究引入了 PromptHive，一种协作界面，旨在通过提示工程（prompt engineering）将主题专家重新置于教育内容创建的核心位置，支持他们快速迭代提示变体以生成更准确且针对特定领域的 LLM 输出。PromptHive 结合了系统实验功能，帮助专家在数学等领域进行协作提示撰写。实验结果显示，该工具使非 AI 专家能够创建与人类内容相当的教育材料，同时将认知负荷减少一半，并将创作过程从数月缩短至数小时。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16547v1",
      "published_date": "2024-10-21 22:18:24 UTC",
      "updated_date": "2024-10-21 22:18:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:10:40.834583"
    },
    {
      "arxiv_id": "2410.16543v2",
      "title": "Multi-Agent LLMs Ensemble for Efficient Atrial Fibrillation Annotation of ECG Reports",
      "title_zh": "翻译失败",
      "authors": [
        "Jingwei Huang",
        "Kuroush Nezafati",
        "Ismael Villanueva-Miranda",
        "Zifan Gu",
        "Yueshuang Xu",
        "Ann Marie Navar",
        "Tingyi Wanyan",
        "Qin Zhou",
        "Bo Yao",
        "Ruichen Rong",
        "Xiaowei Zhan",
        "Guanghua Xiao",
        "Eric D. Peterson",
        "Donghan M. Yang",
        "Wenqi Shi",
        "Yang Xie"
      ],
      "abstract": "This study introduces a novel multiagent ensemble method powered by LLMs to\naddress a key challenge in ML - data labeling, particularly in large-scale EHR\ndatasets. Manual labeling of such datasets requires domain expertise and is\nlabor-intensive, time-consuming, expensive, and error-prone. To overcome this\nbottleneck, we developed an ensemble LLMs method and demonstrated its\neffectiveness in two real-world tasks: (1) labeling a large-scale unlabeled ECG\ndataset in MIMIC-IV; (2) identifying social determinants of health (SDOH) from\nthe clinical notes of EHR. Trading off benefits and cost, we selected a pool of\ndiverse open source LLMs with satisfactory performance. We treat each LLM's\nprediction as a vote and apply a mechanism of majority voting with minimal\nwinning threshold for ensemble. We implemented an ensemble LLMs application for\nEHR data labeling tasks. By using the ensemble LLMs and natural language\nprocessing, we labeled MIMIC-IV ECG dataset of 623,566 ECG reports with an\nestimated accuracy of 98.2%. We applied the ensemble LLMs method to identify\nSDOH from social history sections of 1,405 EHR clinical notes, also achieving\ncompetitive performance. Our experiments show that the ensemble LLMs can\noutperform individual LLM even the best commercial one, and the method reduces\nhallucination errors. From the research, we found that (1) the ensemble LLMs\nmethod significantly reduces the time and effort required for labeling\nlarge-scale EHR data, automating the process with high accuracy and quality;\n(2) the method generalizes well to other text data labeling tasks, as shown by\nits application to SDOH identification; (3) the ensemble of a group of diverse\nLLMs can outperform or match the performance of the best individual LLM; and\n(4) the ensemble method substantially reduces hallucination errors. This\napproach provides a scalable and efficient solution to data-labeling\nchallenges.",
      "tldr_zh": "本研究提出了一种基于多智能体 LLMs 集成方法，用于高效标注心房颤动 ECG 报告，旨在解决机器学习 (ML) 中大规模电子健康记录 (EHR) 数据标注的挑战，如手动操作耗时、昂贵且易出错。方法通过多数投票机制 (majority voting with minimal winning threshold) 整合多个开源 LLMs，每个模型的预测作为投票，确保高准确性和减少 hallucination errors。在实际应用中，该方法标注了 MIMIC-IV 中的 623,566 份 ECG 报告，准确率达 98.2%，并成功识别社会决定因素 (SDOH) 于 1,405 份 EHR 临床笔记中。实验证明，该集成方法优于单个 LLMs（甚至最佳商业模型），显著降低标注时间和努力，并展示出良好的泛化性。",
      "categories": [
        "cs.AI",
        "I.2"
      ],
      "primary_category": "cs.AI",
      "comment": "26 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.16543v2",
      "published_date": "2024-10-21 22:12:00 UTC",
      "updated_date": "2025-04-25 18:43:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:10:54.820697"
    },
    {
      "arxiv_id": "2410.16540v1",
      "title": "A Theoretical Understanding of Chain-of-Thought: Coherent Reasoning and Error-Aware Demonstration",
      "title_zh": "翻译失败",
      "authors": [
        "Yingqian Cui",
        "Pengfei He",
        "Xianfeng Tang",
        "Qi He",
        "Chen Luo",
        "Jiliang Tang",
        "Yue Xing"
      ],
      "abstract": "Few-shot Chain-of-Thought (CoT) prompting has demonstrated strong performance\nin improving the reasoning capabilities of large language models (LLMs). While\ntheoretical investigations have been conducted to understand CoT, the\nunderlying transformer used in these studies isolates the CoT reasoning process\ninto separated in-context learning steps (Stepwise ICL). In this work, we\ntheoretically show that, compared to Stepwise ICL, the transformer gains better\nerror correction ability and more accurate predictions if the reasoning from\nearlier steps (Coherent CoT) is integrated. Given that this coherent reasoning\nchanges the behavior of the transformer, we further investigate the sensitivity\nof the transformer with Coherent CoT when the demonstration examples are\ncorrupted at the inference stage. Our theoretical results indicate that the\ntransformer is more sensitive to errors in intermediate reasoning steps than\nthe final outcome. Building upon this observation, we propose an improvement on\nCoT by incorporating both correct and incorrect reasoning paths in the\ndemonstration. Our experiments validate the effectiveness of the proposed\napproach.",
      "tldr_zh": "该研究理论分析了 Few-shot Chain-of-Thought (CoT) prompting 如何提升大型语言模型 (LLMs) 的推理能力，强调与传统 Stepwise ICL 相比，整合早期步骤推理的 Coherent CoT 可以提供更好的错误修正能力和预测准确性。论文证明，transformer 在处理 Coherent CoT 时，对中间推理步骤的错误更敏感，因此提出了一种 Error-Aware Demonstration 方法，该方法在演示示例中同时包含正确和错误的推理路径。实验结果验证了这一改进的有效性，为优化 CoT 推理提供了新见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16540v1",
      "published_date": "2024-10-21 22:07:20 UTC",
      "updated_date": "2024-10-21 22:07:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:11:04.894938"
    },
    {
      "arxiv_id": "2411.04127v1",
      "title": "Combining Theory of Mind and Kindness for Self-Supervised Human-AI Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Joshua T. S. Hewson"
      ],
      "abstract": "As artificial intelligence (AI) becomes deeply integrated into critical\ninfrastructures and everyday life, ensuring its safe deployment is one of\nhumanity's most urgent challenges. Current AI models prioritize task\noptimization over safety, leading to risks of unintended harm. These risks are\ndifficult to address due to the competing interests of governments, businesses,\nand advocacy groups, all of which have different priorities in the AI race.\nCurrent alignment methods, such as reinforcement learning from human feedback\n(RLHF), focus on extrinsic behaviors without instilling a genuine understanding\nof human values. These models are vulnerable to manipulation and lack the\nsocial intelligence necessary to infer the mental states and intentions of\nothers, raising concerns about their ability to safely and responsibly make\nimportant decisions in complex and novel situations. Furthermore, the\ndivergence between extrinsic and intrinsic motivations in AI introduces the\nrisk of deceptive or harmful behaviors, particularly as systems become more\nautonomous and intelligent. We propose a novel human-inspired approach which\naims to address these various concerns and help align competing objectives.",
      "tldr_zh": "该研究强调了人工智能（AI）安全部署的紧迫性，指出当前AI模型过度关注任务优化而忽略安全风险，导致潜在危害，且现有方法如RLHF仅注重外部行为而缺乏对人类价值的内在理解。论文提出一种创新方法，将Theory of Mind（心智理论）和Kindness（仁慈）相结合，通过自监督机制实现人类-AI对齐，帮助AI推断他人心理状态并减少欺骗性行为。总体而言，此方法旨在弥合AI的内在动机与外在行为的差距，促进更安全、负责任的AI决策。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.04127v1",
      "published_date": "2024-10-21 22:04:44 UTC",
      "updated_date": "2024-10-21 22:04:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:11:16.181001"
    },
    {
      "arxiv_id": "2410.16537v1",
      "title": "QIXAI: A Quantum-Inspired Framework for Enhancing Classical and Quantum Model Transparency and Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "John M. Willis"
      ],
      "abstract": "The impressive performance of deep learning models, particularly\nConvolutional Neural Networks (CNNs), is often hindered by their lack of\ninterpretability, rendering them \"black boxes.\" This opacity raises concerns in\ncritical areas like healthcare, finance, and autonomous systems, where trust\nand accountability are crucial. This paper introduces the QIXAI Framework\n(Quantum-Inspired Explainable AI), a novel approach for enhancing neural\nnetwork interpretability through quantum-inspired techniques. By utilizing\nprinciples from quantum mechanics, such as Hilbert spaces, superposition,\nentanglement, and eigenvalue decomposition, the QIXAI framework reveals how\ndifferent layers of neural networks process and combine features to make\ndecisions.\n  We critically assess model-agnostic methods like SHAP and LIME, as well as\ntechniques like Layer-wise Relevance Propagation (LRP), highlighting their\nlimitations in providing a comprehensive view of neural network operations. The\nQIXAI framework overcomes these limitations by offering deeper insights into\nfeature importance, inter-layer dependencies, and information propagation. A\nCNN for malaria parasite detection is used as a case study to demonstrate how\nquantum-inspired methods like Singular Value Decomposition (SVD), Principal\nComponent Analysis (PCA), and Mutual Information (MI) provide interpretable\nexplanations of model behavior. Additionally, we explore the extension of QIXAI\nto other architectures, including Recurrent Neural Networks (RNNs), Long\nShort-Term Memory (LSTM) networks, Transformers, and Natural Language\nProcessing (NLP) models, and its application to generative models and\ntime-series analysis. The framework applies to both quantum and classical\nsystems, demonstrating its potential to improve interpretability and\ntransparency across a range of models, advancing the broader goal of developing\ntrustworthy AI systems.",
      "tldr_zh": "这篇论文提出了 QIXAI 框架，一种受量子力学启发的创新方法，用于提升神经网络（如 CNN）的可解释性，解决其“黑箱”问题，尤其在医疗、金融和自主系统中。QIXAI 通过利用 Hilbert 空间、叠加、纠缠和特征值分解等原理，揭示神经网络层间的特征处理、重要性和信息传播机制，并克服了 SHAP、LIME 和 LRP 等现有方法的局限性。在一个 CNN 疟疾寄生虫检测案例中，框架应用 SVD、PCA 和 MI 提供了更全面的模型解释，并扩展到 RNN、LSTM、Transformer 和 NLP 模型等领域，促进量子和经典系统的透明度和可信赖 AI 发展。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "quant-ph"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.16537v1",
      "published_date": "2024-10-21 21:55:09 UTC",
      "updated_date": "2024-10-21 21:55:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:11:29.265011"
    },
    {
      "arxiv_id": "2410.16533v1",
      "title": "Large Body Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Saif Punjwani",
        "Larry Heck"
      ],
      "abstract": "As virtual agents become increasingly prevalent in human-computer\ninteraction, generating realistic and contextually appropriate gestures in\nreal-time remains a significant challenge. While neural rendering techniques\nhave made substantial progress with static scripts, their applicability to\nhuman-computer interactions remains limited. To address this, we introduce\nLarge Body Language Models (LBLMs) and present LBLM-AVA, a novel LBLM\narchitecture that combines a Transformer-XL large language model with a\nparallelized diffusion model to generate human-like gestures from multimodal\ninputs (text, audio, and video). LBLM-AVA incorporates several key components\nenhancing its gesture generation capabilities, such as multimodal-to-pose\nembeddings, enhanced sequence-to-sequence mapping with redefined attention\nmechanisms, a temporal smoothing module for gesture sequence coherence, and an\nattention-based refinement module for enhanced realism. The model is trained on\nour large-scale proprietary open-source dataset Allo-AVA. LBLM-AVA achieves\nstate-of-the-art performance in generating lifelike and contextually\nappropriate gestures with a 30% reduction in Fr\\'echet Gesture Distance (FGD),\nand a 25% improvement in Fr\\'echet Inception Distance compared to existing\napproaches.",
      "tldr_zh": "该研究提出 Large Body Language Models (LBLMs)，特别是 LBLM-AVA 架构，以解决虚拟代理在人机交互中生成实时、上下文合适手势的挑战。LBLM-AVA 结合 Transformer-XL 大语言模型和并行扩散模型，从多模态输入（如文本、音频和视频）生成逼真手势，并通过多模态到姿势嵌入、增强的序列到序列映射、时间平滑模块以及基于注意力的精炼模块来提升生成质量。模型在大型开源数据集 Allo-AVA 上训练，实现了 Fréchet Gesture Distance (FGD) 减少 30% 和 Fréchet Inception Distance (FID) 改善 25%，在手势生成性能上超越现有方法。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16533v1",
      "published_date": "2024-10-21 21:48:24 UTC",
      "updated_date": "2024-10-21 21:48:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:11:41.263383"
    },
    {
      "arxiv_id": "2410.16531v3",
      "title": "Bayesian scaling laws for in-context learning",
      "title_zh": "翻译失败",
      "authors": [
        "Aryaman Arora",
        "Dan Jurafsky",
        "Christopher Potts",
        "Noah D. Goodman"
      ],
      "abstract": "In-context learning (ICL) is a powerful technique for getting language models\nto perform complex tasks with no training updates. Prior work has established\nstrong correlations between the number of in-context examples provided and the\naccuracy of the model's predictions. In this paper, we seek to explain this\ncorrelation by showing that ICL approximates a Bayesian learner. This\nperspective gives rise to a family of novel Bayesian scaling laws for ICL. In\nexperiments with \\mbox{GPT-2} models of different sizes, our scaling laws\nexceed or match existing scaling laws in accuracy while also offering\ninterpretable terms for task priors, learning efficiency, and per-example\nprobabilities. To illustrate the analytic power that such interpretable scaling\nlaws provide, we report on controlled synthetic dataset experiments designed to\ninform real-world studies of safety alignment. In our experimental protocol, we\nuse SFT to suppress an unwanted existing model capability and then use ICL to\ntry to bring that capability back (many-shot jailbreaking). We then experiment\non real-world instruction-tuned LLMs using capabilities benchmarks as well as a\nnew many-shot jailbreaking dataset. In all cases, Bayesian scaling laws\naccurately predict the conditions under which ICL will cause the suppressed\nbehavior to reemerge, which sheds light on the ineffectiveness of post-training\nat increasing LLM safety.",
      "tldr_zh": "本文提出Bayesian scaling laws for in-context learning (ICL)，解释了提供更多in-context例子与语言模型预测准确率的相关性，通过将ICL近似为Bayesian learner来推导出一系列新颖的扩展定律。实验在不同大小的GPT-2模型上验证了这些定律，其准确性超过或匹配现有定律，并引入可解释的术语如任务先验、学习效率和每个例子的概率。为了评估其分析价值，研究者设计了合成数据集实验和真实指令调整LLMs测试，包括使用Supervised Fine-Tuning (SFT)抑制模型能力后通过many-shot jailbreaking尝试恢复，结果显示Bayesian scaling laws准确预测了被抑制行为重新出现的条件，揭示了后训练在提升LLM安全方面可能无效。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.FL",
        "cs.LG",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages main text, 26 pages total",
      "pdf_url": "http://arxiv.org/pdf/2410.16531v3",
      "published_date": "2024-10-21 21:45:22 UTC",
      "updated_date": "2024-11-02 19:06:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:11:54.059853"
    },
    {
      "arxiv_id": "2411.04126v1",
      "title": "We Urgently Need Intrinsically Kind Machines",
      "title_zh": "翻译失败",
      "authors": [
        "Joshua T. S. Hewson"
      ],
      "abstract": "Artificial Intelligence systems are rapidly evolving, integrating extrinsic\nand intrinsic motivations. While these frameworks offer benefits, they risk\nmisalignment at the algorithmic level while appearing superficially aligned\nwith human values. In this paper, we argue that an intrinsic motivation for\nkindness is crucial for making sure these models are intrinsically aligned with\nhuman values. We argue that kindness, defined as a form of altruism motivated\nto maximize the reward of others, can counteract any intrinsic motivations that\nmight lead the model to prioritize itself over human well-being. Our approach\nintroduces a framework and algorithm for embedding kindness into foundation\nmodels by simulating conversations. Limitations and future research directions\nfor scalable implementation are discussed.",
      "tldr_zh": "人工智能系统在快速演变中整合了外在和内在动机，但这些框架可能在算法层面出现与人类价值观的失调，尽管表面上保持一致。本文主张嵌入一种内在动机（intrinsic motivation）——善良（kindness），将其定义为旨在最大化他人回报的利他主义，以防止模型优先自身而忽略人类福祉。论文引入了一个框架和算法，通过模拟对话将善良嵌入 foundation models 中，并讨论了其局限性以及未来可扩展实施的研究方向。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "NeurIPS 2024 IMOL Workshop Paper",
      "pdf_url": "http://arxiv.org/pdf/2411.04126v1",
      "published_date": "2024-10-21 21:40:22 UTC",
      "updated_date": "2024-10-21 21:40:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:12:04.582711"
    },
    {
      "arxiv_id": "2410.16529v1",
      "title": "Distributed Online Life-Long Learning (DOL3) for Multi-agent Trust and Reputation Assessment in E-commerce",
      "title_zh": "翻译失败",
      "authors": [
        "Hariprasauth Ramamoorthy",
        "Shubhankar Gupta",
        "Suresh Sundaram"
      ],
      "abstract": "Trust and Reputation Assessment of service providers in citizen-focused\nenvironments like e-commerce is vital to maintain the integrity of the\ninteractions among agents. The goals and objectives of both the service\nprovider and service consumer agents are relevant to the goals of the\nrespective citizens (end users). The provider agents often pursue selfish goals\nthat can make the service quality highly volatile, contributing towards the\nnon-stationary nature of the environment. The number of active service\nproviders tends to change over time resulting in an open environment. This\nnecessitates a rapid and continual assessment of the Trust and Reputation. A\nlarge number of service providers in the environment require a distributed\nmulti-agent Trust and Reputation assessment. This paper addresses the problem\nof multi-agent Trust and Reputation Assessment in a non-stationary environment\ninvolving transactions between providers and consumers. In this setting, the\nobserver agents carry out the assessment and communicate their assessed trust\nscores with each other over a network. We propose a novel Distributed Online\nLife-Long Learning (DOL3) algorithm that involves real-time rapid learning of\ntrust and reputation scores of providers. Each observer carries out an adaptive\nlearning and weighted fusion process combining their own assessment along with\nthat of their neighbour in the communication network. Simulation studies reveal\nthat the state-of-the-art methods, which usually involve training a model to\nassess an agent's trust and reputation, do not work well in such an\nenvironment. The simulation results show that the proposed DOL3 algorithm\noutperforms these methods and effectively handles the volatility in such\nenvironments. From the statistical evaluation, it is evident that DOL3 performs\nbetter compared to other models in 90% of the cases.",
      "tldr_zh": "本研究针对电子商务环境中非平稳的多智能体信任和声誉评估问题，提出了一种分布式在线终身学习(DOL3)算法，以应对服务提供者自私行为导致的服务质量波动和服务数量变化。DOL3算法允许观察者代理进行实时评估，并通过自适应学习和加权融合机制结合自身及网络邻居的信任分数，实现快速持续的分布式评估。模拟实验结果显示，DOL3在90%的案例中优于现有方法，能有效处理环境波动，为电子商务中的多智能体信任系统提供更可靠的解决方案。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16529v1",
      "published_date": "2024-10-21 21:37:55 UTC",
      "updated_date": "2024-10-21 21:37:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:12:16.434097"
    },
    {
      "arxiv_id": "2410.16520v3",
      "title": "AUTALIC: A Dataset for Anti-AUTistic Ableist Language In Context",
      "title_zh": "翻译失败",
      "authors": [
        "Naba Rizvi",
        "Harper Strickland",
        "Daniel Gitelman",
        "Tristan Cooper",
        "Alexis Morales-Flores",
        "Michael Golden",
        "Aekta Kallepalli",
        "Akshat Alurkar",
        "Haaset Owens",
        "Saleha Ahmedi",
        "Isha Khirwadkar",
        "Imani Munyaka",
        "Nedjma Ousidhoum"
      ],
      "abstract": "As our understanding of autism and ableism continues to increase, so does our\nunderstanding of ableist language towards autistic people. Such language poses\na significant challenge in NLP research due to its subtle and context-dependent\nnature. Yet, detecting anti-autistic ableist language remains underexplored,\nwith existing NLP tools often failing to capture its nuanced expressions. We\npresent AUTALIC, the first benchmark dataset dedicated to the detection of\nanti-autistic ableist language in context, addressing a significant gap in the\nfield. The dataset comprises 2,400 autism-related sentences collected from\nReddit, accompanied by surrounding context, and is annotated by trained experts\nwith backgrounds in neurodiversity. Our comprehensive evaluation reveals that\ncurrent language models, including state-of-the-art LLMs, struggle to reliably\nidentify anti-autistic ableism and align with human judgments, underscoring\ntheir limitations in this domain. We publicly release AUTALIC along with the\nindividual annotations which serve as a valuable resource to researchers\nworking on ableism, neurodiversity, and also studying disagreements in\nannotation tasks. This dataset serves as a crucial step towards developing more\ninclusive and context-aware NLP systems that better reflect diverse\nperspectives.",
      "tldr_zh": "本研究引入了AUTALIC数据集，这是首个专为检测anti-autistic ableist language（反自闭症歧视语言）而设计的基准数据集，旨在解决NLP领域中这种语言的微妙性和上下文依赖性问题。数据集包含从Reddit收集的2400个与自闭症相关的句子及其上下文，由具有神经多样性背景的专家进行标注。实验评估显示，当前语言模型（包括state-of-the-art LLMs）在识别此类歧视语言和与人类判断一致方面表现欠佳，这突显了NLP系统的局限性。通过公开数据集和标注，研究者可利用此资源开发更具包容性和上下文感知的NLP系统，以更好地支持神经多样性和减少标注分歧。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 5 figures, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.16520v3",
      "published_date": "2024-10-21 21:21:29 UTC",
      "updated_date": "2025-04-08 17:08:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:12:28.816100"
    },
    {
      "arxiv_id": "2410.16517v1",
      "title": "RGMDT: Return-Gap-Minimizing Decision Tree Extraction in Non-Euclidean Metric Space",
      "title_zh": "RGMDT：在非欧空间中最小化回报差距的决策树提取",
      "authors": [
        "Jingdi Chen",
        "Hanhan Zhou",
        "Yongsheng Mei",
        "Carlee Joe-Wong",
        "Gina Adam",
        "Nathaniel D. Bastian",
        "Tian Lan"
      ],
      "abstract": "Deep Reinforcement Learning (DRL) algorithms have achieved great success in\nsolving many challenging tasks while their black-box nature hinders\ninterpretability and real-world applicability, making it difficult for human\nexperts to interpret and understand DRL policies. Existing works on\ninterpretable reinforcement learning have shown promise in extracting decision\ntree (DT) based policies from DRL policies with most focus on the single-agent\nsettings while prior attempts to introduce DT policies in multi-agent scenarios\nmainly focus on heuristic designs which do not provide any quantitative\nguarantees on the expected return. In this paper, we establish an upper bound\non the return gap between the oracle expert policy and an optimal decision tree\npolicy. This enables us to recast the DT extraction problem into a novel\nnon-euclidean clustering problem over the local observation and action values\nspace of each agent, with action values as cluster labels and the upper bound\non the return gap as clustering loss. Both the algorithm and the upper bound\nare extended to multi-agent decentralized DT extractions by an\niteratively-grow-DT procedure guided by an action-value function conditioned on\nthe current DTs of other agents. Further, we propose the\nReturn-Gap-Minimization Decision Tree (RGMDT) algorithm, which is a\nsurprisingly simple design and is integrated with reinforcement learning\nthrough the utilization of a novel Regularized Information Maximization loss.\nEvaluations on tasks like D4RL show that RGMDT significantly outperforms\nheuristic DT-based baselines and can achieve nearly optimal returns under given\nDT complexity constraints (e.g., maximum number of DT nodes).",
      "tldr_zh": "这篇论文针对深度强化学习（DRL）的黑盒问题，建立了专家策略与最优决策树（DT）策略之间回报差距的上界，并将 DT 提取问题转化为非欧空间中的聚类问题，以行动值作为聚类标签和回报差距上界作为损失。\n他们提出了 Return-Gap-Minimizing Decision Tree (RGMDT) 算法，通过迭代增长 DT 的过程和 Regularized Information Maximization 损失，与强化学习集成，实现多代理场景下的可解释策略提取。\n实验在 D4RL 等任务上显示，RGMDT 显著优于启发式 DT 基线，并在给定 DT 复杂度约束（如节点数量）下，几乎达到最优回报。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16517v1",
      "published_date": "2024-10-21 21:19:49 UTC",
      "updated_date": "2024-10-21 21:19:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:14:41.852915"
    },
    {
      "arxiv_id": "2410.16503v1",
      "title": "Allo-AVA: A Large-Scale Multimodal Conversational AI Dataset for Allocentric Avatar Gesture Animation",
      "title_zh": "翻译失败",
      "authors": [
        "Saif Punjwani",
        "Larry Heck"
      ],
      "abstract": "The scarcity of high-quality, multimodal training data severely hinders the\ncreation of lifelike avatar animations for conversational AI in virtual\nenvironments. Existing datasets often lack the intricate synchronization\nbetween speech, facial expressions, and body movements that characterize\nnatural human communication. To address this critical gap, we introduce\nAllo-AVA, a large-scale dataset specifically designed for text and audio-driven\navatar gesture animation in an allocentric (third person point-of-view)\ncontext. Allo-AVA consists of $\\sim$1,250 hours of diverse video content,\ncomplete with audio, transcripts, and extracted keypoints. Allo-AVA uniquely\nmaps these keypoints to precise timestamps, enabling accurate replication of\nhuman movements (body and facial gestures) in synchronization with speech. This\ncomprehensive resource enables the development and evaluation of more natural,\ncontext-aware avatar animation models, potentially transforming applications\nranging from virtual reality to digital assistants.",
      "tldr_zh": "现有数据集缺乏高质量的多模态训练数据，导致对话 AI 中 allocentric（第三人称视角）头像手势动画无法实现语音、面部表情和身体动作的精确同步。为解决这一问题，本文引入了 Allo-AVA，这是一个大规模数据集，包含约 1,250 小时的多样化视频内容，包括音频、转录和提取的关键点，并将这些关键点映射到精确时间戳以实现动作同步。Allo-AVA 的发布将推动开发更自然、上下文感知的头像动画模型，应用于虚拟现实、数字助理等领域。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16503v1",
      "published_date": "2024-10-21 20:50:51 UTC",
      "updated_date": "2024-10-21 20:50:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:12:53.295773"
    },
    {
      "arxiv_id": "2410.19847v1",
      "title": "AEPL: Automated and Editable Prompt Learning for Brain Tumor Segmentation",
      "title_zh": "AEPL：脑肿瘤分割的自动和可编辑提示学习",
      "authors": [
        "Yongheng Sun",
        "Mingxia Liu",
        "Chunfeng Lian"
      ],
      "abstract": "Brain tumor segmentation is crucial for accurate diagnosisand treatment\nplanning, but the small size and irregular shapeof tumors pose significant\nchallenges. Existing methods of-ten fail to effectively incorporate medical\ndomain knowledgesuch as tumor grade, which correlates with tumor\naggres-siveness and morphology, providing critical insights for moreaccurate\ndetection of tumor subregions during segmentation.We propose an Automated and\nEditable Prompt Learning(AEPL) framework that integrates tumor grade into the\nseg-mentation process by combining multi-task learning andprompt learning with\nautomatic and editable prompt gen-eration. Specifically, AEPL employs an\nencoder to extractimage features for both tumor-grade prediction and\nsegmen-tation mask generation. The predicted tumor grades serveas\nauto-generated prompts, guiding the decoder to produceprecise segmentation\nmasks. This eliminates the need formanual prompts while allowing clinicians to\nmanually editthe auto-generated prompts to fine-tune the segmentation,enhancing\nboth flexibility and precision. The proposed AEPLachieves state-of-the-art\nperformance on the BraTS 2018dataset, demonstrating its effectiveness and\nclinical potential.The source code can be accessed online.",
      "tldr_zh": "本研究针对脑肿瘤分割的挑战，如肿瘤尺寸小和形状不规则，提出 AEPL 框架，通过多任务学习和 prompt learning 自动生成肿瘤等级作为提示，整合医疗领域知识以提升分割精度。AEPL 采用编码器提取图像特征，用于肿瘤等级预测和分割掩码生成，这些预测的等级作为 auto-generated prompts 引导解码器产生精确结果，同时支持手动编辑提示以增强灵活性。在 BraTS 2018 数据集上，AEPL 实现了最先进性能，展示了其在临床诊断和治疗规划中的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "4 pages paper for ISBI2025",
      "pdf_url": "http://arxiv.org/pdf/2410.19847v1",
      "published_date": "2024-10-21 20:29:44 UTC",
      "updated_date": "2024-10-21 20:29:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:13:05.522886"
    },
    {
      "arxiv_id": "2410.19008v1",
      "title": "Teach Multimodal LLMs to Comprehend Electrocardiographic Images",
      "title_zh": "翻译失败",
      "authors": [
        "Ruoqi Liu",
        "Yuelin Bai",
        "Xiang Yue",
        "Ping Zhang"
      ],
      "abstract": "The electrocardiogram (ECG) is an essential non-invasive diagnostic tool for\nassessing cardiac conditions. Existing automatic interpretation methods suffer\nfrom limited generalizability, focusing on a narrow range of cardiac\nconditions, and typically depend on raw physiological signals, which may not be\nreadily available in resource-limited settings where only printed or digital\nECG images are accessible. Recent advancements in multimodal large language\nmodels (MLLMs) present promising opportunities for addressing these challenges.\nHowever, the application of MLLMs to ECG image interpretation remains\nchallenging due to the lack of instruction tuning datasets and well-established\nECG image benchmarks for quantitative evaluation. To address these challenges,\nwe introduce ECGInstruct, a comprehensive ECG image instruction tuning dataset\nof over one million samples, covering a wide range of ECG-related tasks from\ndiverse data sources. Using ECGInstruct, we develop PULSE, an MLLM tailored for\nECG image comprehension. In addition, we curate ECGBench, a new evaluation\nbenchmark covering four key ECG image interpretation tasks across nine\ndifferent datasets. Our experiments show that PULSE sets a new\nstate-of-the-art, outperforming general MLLMs with an average accuracy\nimprovement of 15% to 30%. This work highlights the potential of PULSE to\nenhance ECG interpretation in clinical practice.",
      "tldr_zh": "该论文针对心电图（ECG）图像解释的局限性（如依赖原始信号和泛化性差），提出使用多模态大型语言模型（Multimodal LLMs）来提升诊断能力。研究者构建了ECGInstruct数据集，包含超过一百万样本，覆盖多种ECG相关任务，用于模型的指令调整训练；并开发了PULSE模型，该模型专门针对ECG图像理解。论文还创建了ECGBench基准，评估四个关键ECG图像解释任务，实验结果显示PULSE相较于一般MLLMs平均准确率提升15%至30%，为临床ECG解释提供更可靠的工具。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19008v1",
      "published_date": "2024-10-21 20:26:41 UTC",
      "updated_date": "2024-10-21 20:26:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:13:17.479040"
    },
    {
      "arxiv_id": "2410.18135v1",
      "title": "R2Gen-Mamba: A Selective State Space Model for Radiology Report Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Yongheng Sun",
        "Yueh Z. Lee",
        "Genevieve A. Woodard",
        "Hongtu Zhu",
        "Chunfeng Lian",
        "Mingxia Liu"
      ],
      "abstract": "Radiology report generation is crucial in medical imaging,but the manual\nannotation process by physicians is time-consuming and labor-intensive,\nnecessitating the develop-ment of automatic report generation methods.\nExistingresearch predominantly utilizes Transformers to generateradiology\nreports, which can be computationally intensive,limiting their use in real\napplications. In this work, we presentR2Gen-Mamba, a novel automatic radiology\nreport genera-tion method that leverages the efficient sequence processingof\nthe Mamba with the contextual benefits of Transformerarchitectures. Due to\nlower computational complexity ofMamba, R2Gen-Mamba not only enhances training\nand in-ference efficiency but also produces high-quality reports.Experimental\nresults on two benchmark datasets with morethan 210,000 X-ray image-report\npairs demonstrate the ef-fectiveness of R2Gen-Mamba regarding report quality\nandcomputational efficiency compared with several state-of-the-art methods. The\nsource code can be accessed online.",
      "tldr_zh": "该研究针对放射学报告生成的自动化需求，提出 R2Gen-Mamba，一种结合 Mamba 的高效序列处理和 Transformer 的上下文优势的模型，以解决现有方法的计算密集问题。R2Gen-Mamba 通过降低计算复杂度，提升了训练和推理效率，同时生成高质量报告。在两个基准数据集（超过21万X光图像-报告对）上的实验结果显示，它在报告质量和计算效率方面优于多种最先进方法。源代码已公开，可供进一步应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "4 pages pages for ISBI2025",
      "pdf_url": "http://arxiv.org/pdf/2410.18135v1",
      "published_date": "2024-10-21 19:35:34 UTC",
      "updated_date": "2024-10-21 19:35:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:13:28.861004"
    },
    {
      "arxiv_id": "2410.16458v2",
      "title": "STAR: A Simple Training-free Approach for Recommendations using Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Dong-Ho Lee",
        "Adam Kraft",
        "Long Jin",
        "Nikhil Mehta",
        "Taibai Xu",
        "Lichan Hong",
        "Ed H. Chi",
        "Xinyang Yi"
      ],
      "abstract": "Recent progress in large language models (LLMs) offers promising new\napproaches for recommendation system tasks. While the current state-of-the-art\nmethods rely on fine-tuning LLMs to achieve optimal results, this process is\ncostly and introduces significant engineering complexities. Conversely, methods\nthat directly use LLMs without additional fine-tuning result in a large drop in\nrecommendation quality, often due to the inability to capture collaborative\ninformation. In this paper, we propose a Simple Training-free Approach for\nRecommendation (STAR), a framework that utilizes LLMs and can be applied to\nvarious recommendation tasks without the need for fine-tuning, while\nmaintaining high quality recommendation performance. Our approach involves a\nretrieval stage that uses semantic embeddings from LLMs combined with\ncollaborative user information to retrieve candidate items. We then apply an\nLLM for pairwise ranking to enhance next-item prediction. Experimental results\non the Amazon Review dataset show competitive performance for next item\nprediction, even with our retrieval stage alone. Our full method achieves\nHits@10 performance of +23.8% on Beauty, +37.5% on Toys & Games, and -1.8% on\nSports & Outdoors relative to the best supervised models. This framework offers\nan effective alternative to traditional supervised models, highlighting the\npotential of LLMs in recommendation systems without extensive training or\ncustom architectures.",
      "tldr_zh": "该研究提出 STAR，一种无需训练的简单框架，利用大型语言模型(LLMs)来处理推荐系统任务，避免了微调 LLMs 的高成本和复杂性。STAR 的方法包括检索阶段（结合 LLMs 的语义嵌入和协作用户信息来获取候选物品），以及后续的 LLM 配对排名以优化下一物品预测。在 Amazon Review 数据集实验中，STAR 在 Beauty 和 Toys & Games 类别上分别将 Hits@10 性能提升 23.8% 和 37.5%，整体上展示了无需额外训练即可实现高性能推荐的潜力。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16458v2",
      "published_date": "2024-10-21 19:34:40 UTC",
      "updated_date": "2025-02-19 23:34:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:14:39.298225"
    },
    {
      "arxiv_id": "2410.16454v3",
      "title": "Catastrophic Failure of LLM Unlearning via Quantization",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiwei Zhang",
        "Fali Wang",
        "Xiaomin Li",
        "Zongyu Wu",
        "Xianfeng Tang",
        "Hui Liu",
        "Qi He",
        "Wenpeng Yin",
        "Suhang Wang"
      ],
      "abstract": "Large language models (LLMs) have shown remarkable proficiency in generating\ntext, benefiting from extensive training on vast textual corpora. However, LLMs\nmay also acquire unwanted behaviors from the diverse and sensitive nature of\ntheir training data, which can include copyrighted and private content. Machine\nunlearning has been introduced as a viable solution to remove the influence of\nsuch problematic content without the need for costly and time-consuming\nretraining. This process aims to erase specific knowledge from LLMs while\npreserving as much model utility as possible. Despite the effectiveness of\ncurrent unlearning methods, little attention has been given to whether existing\nunlearning methods for LLMs truly achieve forgetting or merely hide the\nknowledge, which current unlearning benchmarks fail to detect. This paper\nreveals that applying quantization to models that have undergone unlearning can\nrestore the \"forgotten\" information. To thoroughly evaluate this phenomenon, we\nconduct comprehensive experiments using various quantization techniques across\nmultiple precision levels. We find that for unlearning methods with utility\nconstraints, the unlearned model retains an average of 21\\% of the intended\nforgotten knowledge in full precision, which significantly increases to 83\\%\nafter 4-bit quantization. ... Our code is available at:\n\\href{https://github.com/zzwjames/FailureLLMUnlearning}{https://github.com/zzwjames/FailureLLMUnlearning}.",
      "tldr_zh": "这篇论文揭示了大型语言模型(LLM) unlearning 方法的潜在缺陷：通过量化(quantization)，原本被“遗忘”的信息可以被恢复，导致灾难性的失败。研究者通过全面实验，使用多种量化技术和不同精度水平，评估了unlearning模型的实际效果。结果显示，在unlearning方法中加入实用性约束后，模型在全精度下平均保留了21%的被遗忘知识，而在4-bit量化后，这一比例激增至83%。这一发现强调了现有unlearning基准的不足，并呼吁开发更可靠的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.16454v3",
      "published_date": "2024-10-21 19:28:37 UTC",
      "updated_date": "2025-03-21 06:37:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:14:54.392779"
    },
    {
      "arxiv_id": "2410.16431v2",
      "title": "Conjuring Semantic Similarity",
      "title_zh": "翻译失败",
      "authors": [
        "Tian Yu Liu",
        "Stefano Soatto"
      ],
      "abstract": "The semantic similarity between sample expressions measures the distance\nbetween their latent 'meaning'. Such meanings are themselves typically\nrepresented by textual expressions, often insufficient to differentiate\nconcepts at fine granularity. We propose a novel approach whereby the semantic\nsimilarity among textual expressions is based not on other expressions they can\nbe rephrased as, but rather based on the imagery they evoke. While this is not\npossible with humans, generative models allow us to easily visualize and\ncompare generated images, or their distribution, evoked by a textual prompt.\nTherefore, we characterize the semantic similarity between two textual\nexpressions simply as the distance between image distributions they induce, or\n'conjure.' We show that by choosing the Jensen-Shannon divergence between the\nreverse-time diffusion stochastic differential equations (SDEs) induced by each\ntextual expression, this can be directly computed via Monte-Carlo sampling. Our\nmethod contributes a novel perspective on semantic similarity that not only\naligns with human-annotated scores, but also opens up new avenues for the\nevaluation of text-conditioned generative models while offering better\ninterpretability of their learnt representations.",
      "tldr_zh": "这篇论文提出了一种创新的语义相似性测量方法，将文本表达的相似性定义为它们引发的图像分布之间的距离，而不是依赖其他文本表述，从而解决传统方法在细粒度概念区分上的不足。作者使用生成模型（如扩散模型）来可视化文本提示，通过计算Jensen-Shannon divergence来量化逆时间扩散SDE（stochastic differential equations）诱导的图像分布差异，并采用Monte-Carlo采样进行高效计算。该方法不仅与人类标注分数高度对齐，还为评估文本条件生成模型提供了新视角，并提升了模型表示的可解释性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16431v2",
      "published_date": "2024-10-21 18:51:34 UTC",
      "updated_date": "2025-01-29 14:14:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:15:04.839592"
    },
    {
      "arxiv_id": "2410.16429v2",
      "title": "Pantograph: A Machine-to-Machine Interaction Interface for Advanced Theorem Proving, High Level Reasoning, and Data Extraction in Lean 4",
      "title_zh": "翻译失败",
      "authors": [
        "Leni Aniva",
        "Chuyue Sun",
        "Brando Miranda",
        "Clark Barrett",
        "Sanmi Koyejo"
      ],
      "abstract": "Machine-assisted theorem proving refers to the process of conducting\nstructured reasoning to automatically generate proofs for mathematical\ntheorems. Recently, there has been a surge of interest in using machine\nlearning models in conjunction with proof assistants to perform this task. In\nthis paper, we introduce Pantograph, a tool that provides a versatile interface\nto the Lean 4 proof assistant and enables efficient proof search via powerful\nsearch algorithms such as Monte Carlo Tree Search. In addition, Pantograph\nenables high-level reasoning by enabling a more robust handling of Lean 4's\ninference steps. We provide an overview of Pantograph's architecture and\nfeatures. We also report on an illustrative use case: using machine learning\nmodels and proof sketches to prove Lean 4 theorems. Pantograph's innovative\nfeatures pave the way for more advanced machine learning models to perform\ncomplex proof searches and high-level reasoning, equipping future researchers\nto design more versatile and powerful theorem provers.",
      "tldr_zh": "本研究引入 Pantograph，一种机器间交互接口，针对 Lean 4 证明助手，旨在提升定理证明、高层次推理和数据提取能力。Pantograph 通过支持 Monte Carlo Tree Search 等强大搜索算法，实现高效的证明搜索，并提供更 robust 的处理 Lean 4 推理步骤，以增强高层次推理。论文概述了 Pantograph 的架构和特性，并通过使用机器学习模型及证明草图的示例，展示了其在证明 Lean 4 定理中的实际应用。该工具的创新特性为未来开发更先进的机器学习驱动定理证明器铺平道路。",
      "categories": [
        "cs.LO",
        "cs.AI",
        "cs.LG",
        "math.LO",
        "F.4.1; I.2.3; I.2.7"
      ],
      "primary_category": "cs.LO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16429v2",
      "published_date": "2024-10-21 18:49:28 UTC",
      "updated_date": "2025-01-31 08:03:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:15:16.396011"
    },
    {
      "arxiv_id": "2410.16423v1",
      "title": "Position: Challenges and Opportunities for Differential Privacy in the U.S. Federal Government",
      "title_zh": "翻译失败",
      "authors": [
        "Amol Khanna",
        "Adam McCormick",
        "Andre Nguyen",
        "Chris Aguirre",
        "Edward Raff"
      ],
      "abstract": "In this article, we seek to elucidate challenges and opportunities for\ndifferential privacy within the federal government setting, as seen by a team\nof differential privacy researchers, privacy lawyers, and data scientists\nworking closely with the U.S. government. After introducing differential\nprivacy, we highlight three significant challenges which currently restrict the\nuse of differential privacy in the U.S. government. We then provide two\nexamples where differential privacy can enhance the capabilities of government\nagencies. The first example highlights how the quantitative nature of\ndifferential privacy allows policy security officers to release multiple\nversions of analyses with different levels of privacy. The second example,\nwhich we believe is a novel realization, indicates that differential privacy\ncan be used to improve staffing efficiency in classified applications. We hope\nthat this article can serve as a nontechnical resource which can help frame\nfuture action from the differential privacy community, privacy regulators,\nsecurity officers, and lawmakers.",
      "tldr_zh": "这篇文章探讨了差异隐私（Differential Privacy）在美国联邦政府中的挑战与机遇，由一组差异隐私研究者、隐私律师和数据科学家撰写。首先，它介绍了差异隐私的概念，并指出了三个主要挑战，包括技术限制、政策障碍和实际应用难题，这些因素目前阻碍了其在政府中的广泛采用。然后，通过两个示例展示了差异隐私的潜力：一是允许政策安全官员发布不同隐私水平的分析版本，以增强数据共享灵活性；二是创新性地应用于机密场景，以提高员工效率。该文旨在作为非技术资源，指导差异隐私社区、隐私监管者、安全官员和立法者制定未来的行动策略。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "2nd Workshop on Regulatable ML at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.16423v1",
      "published_date": "2024-10-21 18:46:05 UTC",
      "updated_date": "2024-10-21 18:46:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:15:28.814747"
    },
    {
      "arxiv_id": "2410.16415v1",
      "title": "On conditional diffusion models for PDE simulations",
      "title_zh": "翻译失败",
      "authors": [
        "Aliaksandra Shysheya",
        "Cristiana Diaconu",
        "Federico Bergamin",
        "Paris Perdikaris",
        "José Miguel Hernández-Lobato",
        "Richard E. Turner",
        "Emile Mathieu"
      ],
      "abstract": "Modelling partial differential equations (PDEs) is of crucial importance in\nscience and engineering, and it includes tasks ranging from forecasting to\ninverse problems, such as data assimilation. However, most previous numerical\nand machine learning approaches that target forecasting cannot be applied\nout-of-the-box for data assimilation. Recently, diffusion models have emerged\nas a powerful tool for conditional generation, being able to flexibly\nincorporate observations without retraining. In this work, we perform a\ncomparative study of score-based diffusion models for forecasting and\nassimilation of sparse observations. In particular, we focus on diffusion\nmodels that are either trained in a conditional manner, or conditioned after\nunconditional training. We address the shortcomings of existing models by\nproposing 1) an autoregressive sampling approach that significantly improves\nperformance in forecasting, 2) a new training strategy for conditional\nscore-based models that achieves stable performance over a range of history\nlengths, and 3) a hybrid model which employs flexible pre-training conditioning\non initial conditions and flexible post-training conditioning to handle data\nassimilation. We empirically show that these modifications are crucial for\nsuccessfully tackling the combination of forecasting and data assimilation, a\ntask commonly encountered in real-world scenarios.",
      "tldr_zh": "这篇论文探讨了使用条件扩散模型（conditional diffusion models）来模拟偏微分方程（PDEs），以处理预测（forecasting）和数据同化（data assimilation）等任务，这些任务在科学和工程领域至关重要。作者通过比较score-based diffusion models的不同训练方式，提出了三个关键创新：1) 自回归采样方法（autoregressive sampling approach）来提升预测性能，2) 一种新的训练策略确保模型在各种历史长度上稳定表现，3) 一个混合模型（hybrid model）结合预训练和后训练条件以灵活处理数据同化。实验证明，这些改进显著提高了模型在实际场景中的整体效能，使其能够同时应对预测和数据同化挑战。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.16415v1",
      "published_date": "2024-10-21 18:31:04 UTC",
      "updated_date": "2024-10-21 18:31:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:15:42.287829"
    },
    {
      "arxiv_id": "2410.16410v1",
      "title": "Subword Embedding from Bytes Gains Privacy without Sacrificing Accuracy and Complexity",
      "title_zh": "翻译失败",
      "authors": [
        "Mengjiao Zhang",
        "Jia Xu"
      ],
      "abstract": "While NLP models significantly impact our lives, there are rising concerns\nabout privacy invasion. Although federated learning enhances privacy, attackers\nmay recover private training data by exploiting model parameters and gradients.\nTherefore, protecting against such embedding attacks remains an open challenge.\nTo address this, we propose Subword Embedding from Bytes (SEB) and encode\nsubwords to byte sequences using deep neural networks, making input text\nrecovery harder. Importantly, our method requires a smaller memory with $256$\nbytes of vocabulary while keeping efficiency with the same input length. Thus,\nour solution outperforms conventional approaches by preserving privacy without\nsacrificing efficiency or accuracy. Our experiments show SEB can effectively\nprotect against embedding-based attacks from recovering original sentences in\nfederated learning. Meanwhile, we verify that SEB obtains comparable and even\nbetter results over standard subword embedding methods in machine translation,\nsentiment analysis, and language modeling with even lower time and space\ncomplexity.",
      "tldr_zh": "该论文提出Subword Embedding from Bytes (SEB)方法，以解决NLP模型在federated learning中的隐私问题，通过将子词编码为字节序列并使用深度神经网络，增加输入文本恢复难度，同时仅需256字节词汇表来降低内存使用。SEB在保持输入长度和效率的前提下，避免了准确性损失，并有效抵御基于嵌入的攻击。实验验证，SEB在机器翻译、情感分析和语言建模任务上与标准子词嵌入方法相比，取得了相当甚至更好的性能，同时减少了时间和空间复杂度。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16410v1",
      "published_date": "2024-10-21 18:25:24 UTC",
      "updated_date": "2024-10-21 18:25:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:15:53.092108"
    },
    {
      "arxiv_id": "2410.16407v1",
      "title": "Enhancing Multimodal Affective Analysis with Learned Live Comment Features",
      "title_zh": "使用学习得到的实时评论特征增强多模态情感分析",
      "authors": [
        "Zhaoyuan Deng",
        "Amith Ananthram",
        "Kathleen McKeown"
      ],
      "abstract": "Live comments, also known as Danmaku, are user-generated messages that are\nsynchronized with video content. These comments overlay directly onto streaming\nvideos, capturing viewer emotions and reactions in real-time. While prior work\nhas leveraged live comments in affective analysis, its use has been limited due\nto the relative rarity of live comments across different video platforms. To\naddress this, we first construct the Live Comment for Affective Analysis\n(LCAffect) dataset which contains live comments for English and Chinese videos\nspanning diverse genres that elicit a wide spectrum of emotions. Then, using\nthis dataset, we use contrastive learning to train a video encoder to produce\nsynthetic live comment features for enhanced multimodal affective content\nanalysis. Through comprehensive experimentation on a wide range of affective\nanalysis tasks (sentiment, emotion recognition, and sarcasm detection) in both\nEnglish and Chinese, we demonstrate that these synthetic live comment features\nsignificantly improve performance over state-of-the-art methods.",
      "tldr_zh": "本研究针对 Live comments（也称为 Danmaku）的稀缺性问题，构建了 LCAffect 数据集，该数据集包含英语和中文视频的实时评论，覆盖多种类型并引发广泛情绪，以支持多模态情感分析。然后，使用 contrastive learning 训练视频编码器生成合成 Live comment 特征，从而增强情感内容分析的准确性。实验结果显示，在情感识别、情绪识别和讽刺检测等任务上，这些特征在英语和中文语境中显著优于现有方法。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16407v1",
      "published_date": "2024-10-21 18:19:09 UTC",
      "updated_date": "2024-10-21 18:19:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:16:05.360878"
    },
    {
      "arxiv_id": "2410.16406v2",
      "title": "Hotel Booking Cancellation Prediction Using Applied Bayesian Models",
      "title_zh": "翻译失败",
      "authors": [
        "Md Asifuzzaman Jishan",
        "Vikas Singh",
        "Ayan Kumar Ghosh",
        "Md Shahabub Alam",
        "Khan Raqib Mahmud",
        "Bijan Paul"
      ],
      "abstract": "This study applies Bayesian models to predict hotel booking cancellations, a\nkey challenge affecting resource allocation, revenue, and customer satisfaction\nin the hospitality industry. Using a Kaggle dataset with 36,285 observations\nand 17 features, Bayesian Logistic Regression and Beta-Binomial models were\nimplemented. The logistic model, applied to 12 features and 5,000 randomly\nselected observations, outperformed the Beta-Binomial model in predictive\naccuracy. Key predictors included the number of adults, children, stay\nduration, lead time, car parking space, room type, and special requests. Model\nevaluation using Leave-One-Out Cross-Validation (LOO-CV) confirmed strong\nalignment between observed and predicted outcomes, demonstrating the model's\nrobustness. Special requests and parking availability were found to be the\nstrongest predictors of cancellation. This Bayesian approach provides a\nvaluable tool for improving booking management and operational efficiency in\nthe hotel industry.",
      "tldr_zh": "本研究应用Bayesian Logistic Regression和Beta-Binomial模型预测酒店预订取消，以解决资源分配、收入和客户满意度等问题，使用Kaggle数据集的36,285个观察和17个特征进行分析。结果表明，Bayesian Logistic Regression模型在12个特征和5,000个随机样本上表现出色，预测准确性优于Beta-Binomial模型，且关键预测因素包括成人数量、儿童数量、停留时长、提前预订时间、停车位、房间类型和特殊请求，其中特殊请求和停车可用性是最强指标。模型通过Leave-One-Out Cross-Validation (LOO-CV)验证，显示了良好的鲁棒性和预测一致性，为酒店行业优化预订管理和提升运营效率提供了有效工具。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16406v2",
      "published_date": "2024-10-21 18:18:30 UTC",
      "updated_date": "2024-10-23 19:13:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:16:18.316780"
    },
    {
      "arxiv_id": "2410.16397v1",
      "title": "Towards a Reliable Offline Personal AI Assistant for Long Duration Spaceflight",
      "title_zh": "翻译失败",
      "authors": [
        "Oliver Bensch",
        "Leonie Bensch",
        "Tommy Nilsson",
        "Florian Saling",
        "Wafa M. Sadri",
        "Carsten Hartmann",
        "Tobias Hecking",
        "J. Nathan Kutz"
      ],
      "abstract": "As humanity prepares for new missions to the Moon and Mars, astronauts will\nneed to operate with greater autonomy, given the communication delays that make\nreal-time support from Earth difficult. For instance, messages between Mars and\nEarth can take up to 24 minutes, making quick responses impossible. This\nlimitation poses a challenge for astronauts who must rely on in-situ tools to\naccess the large volume of data from spacecraft sensors, rovers, and\nsatellites, data that is often fragmented and difficult to use. To bridge this\ngap, systems like the Mars Exploration Telemetry-Driven Information System\n(METIS) are being developed. METIS is an AI assistant designed to handle\nroutine tasks, monitor spacecraft systems, and detect anomalies, all while\nreducing the reliance on mission control. Current Generative Pretrained\nTransformer (GPT) Models, while powerful, struggle in safety-critical\nenvironments. They can generate plausible but incorrect responses, a phenomenon\nknown as \"hallucination,\" which could endanger astronauts. To overcome these\nlimitations, this paper proposes enhancing systems like METIS by integrating\nGPTs, Retrieval-Augmented Generation (RAG), Knowledge Graphs (KGs), and\nAugmented Reality (AR). The idea is to allow astronauts to interact with their\ndata more intuitively, using natural language queries and visualizing real-time\ninformation through AR. KGs will be used to easily access live telemetry and\nmultimodal data, ensuring that astronauts have the right information at the\nright time. By combining AI, KGs, and AR, this new system will empower\nastronauts to work more autonomously, safely, and efficiently during future\nspace missions.",
      "tldr_zh": "本文探讨了在长时太空飞行中，通信延迟（如火星到地球需24分钟）导致宇航员需更自主操作的挑战，并提出增强 METIS 系统作为可靠的离线个人 AI 助理。方法包括整合 Generative Pretrained Transformer (GPTs)、Retrieval-Augmented Generation (RAG)、Knowledge Graphs (KGs) 和 Augmented Reality (AR)，以处理碎片化数据，支持自然语言查询和实时信息可视化。Knowledge Graphs 将用于访问实时遥测和多模态数据，最终提升宇航员的自治性、安全性和工作效率。",
      "categories": [
        "cs.AI",
        "cs.ET",
        "68T01, 68T20, 68T30, 68T50, 68T05,",
        "I.2; H.5"
      ],
      "primary_category": "cs.AI",
      "comment": "75th International Astronautical Congress (IAC), Milan, Italy, 14-18\n  October 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.16397v1",
      "published_date": "2024-10-21 18:08:42 UTC",
      "updated_date": "2024-10-21 18:08:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:16:30.267070"
    },
    {
      "arxiv_id": "2410.16383v1",
      "title": "Designing Robust Cyber-Defense Agents with Evolving Behavior Trees",
      "title_zh": "翻译失败",
      "authors": [
        "Nicholas Potteiger",
        "Ankita Samaddar",
        "Hunter Bergstrom",
        "Xenofon Koutsoukos"
      ],
      "abstract": "Modern network defense can benefit from the use of autonomous systems,\noffloading tedious and time-consuming work to agents with standard and\nlearning-enabled components. These agents, operating on critical network\ninfrastructure, need to be robust and trustworthy to ensure defense against\nadaptive cyber-attackers and, simultaneously, provide explanations for their\nactions and network activity. However, learning-enabled components typically\nuse models, such as deep neural networks, that are not transparent in their\nhigh-level decision-making leading to assurance challenges. Additionally,\ncyber-defense agents must execute complex long-term defense tasks in a reactive\nmanner that involve coordination of multiple interdependent subtasks. Behavior\ntrees are known to be successful in modelling interpretable, reactive, and\nmodular agent policies with learning-enabled components. In this paper, we\ndevelop an approach to design autonomous cyber defense agents using behavior\ntrees with learning-enabled components, which we refer to as Evolving Behavior\nTrees (EBTs). We learn the structure of an EBT with a novel abstract cyber\nenvironment and optimize learning-enabled components for deployment. The\nlearning-enabled components are optimized for adapting to various cyber-attacks\nand deploying security mechanisms. The learned EBT structure is evaluated in a\nsimulated cyber environment, where it effectively mitigates threats and\nenhances network visibility. For deployment, we develop a software architecture\nfor evaluating EBT-based agents in computer network defense scenarios. Our\nresults demonstrate that the EBT-based agent is robust to adaptive\ncyber-attacks and provides high-level explanations for interpreting its\ndecisions and actions.",
      "tldr_zh": "该研究针对网络防御中的自主代理设计问题，提出了一种基于 Evolving Behavior Trees (EBTs) 的方法，以提升代理的鲁棒性和可解释性。EBTs 结合行为树的可解释、反应式特性与学习组件（如深度神经网络），通过在抽象网络环境中学习树结构并优化组件，使代理能够适应各种网络攻击并协调多个子任务。实验结果显示，在模拟环境中，EBT 代理有效缓解威胁、提升网络可见性，并提供高层决策解释，从而为可信赖的网络防御提供可靠解决方案。",
      "categories": [
        "cs.AI",
        "cs.CR",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.16383v1",
      "published_date": "2024-10-21 18:00:38 UTC",
      "updated_date": "2024-10-21 18:00:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:17:01.461922"
    },
    {
      "arxiv_id": "2410.16377v2",
      "title": "A Simple Model of Inference Scaling Laws",
      "title_zh": "推断缩放定律的简单模型",
      "authors": [
        "Noam Levi"
      ],
      "abstract": "Neural scaling laws have garnered significant interest due to their ability\nto predict model performance as a function of increasing parameters, data, and\ncompute. In this work, we propose a simple statistical ansatz based on\nmemorization to study scaling laws in the context of inference, specifically\nhow performance improves with multiple inference attempts. We explore the\ncoverage, or pass@k metric, which measures the chance of success over repeated\nattempts and provide a motivation for the observed functional form of the\ninference scaling behavior of the coverage in large language models (LLMs) on\nreasoning tasks. We then define an \"inference loss\", which exhibits a power law\ndecay as the number of trials increases, and connect this result with prompting\ncosts. We further test our construction by conducting experiments on a simple\ngenerative model, and find that our predictions are in agreement with the\nempirical coverage curves in a controlled setting. Our simple framework sets\nthe ground for incorporating inference scaling with other known scaling laws.",
      "tldr_zh": "本文提出一个基于记忆的简单统计模型（ansatz），用于研究 neural scaling laws 在推理过程中的表现，特别是模型性能如何随着多次推理尝试而改善。研究者定义了 coverage（或 pass@k）指标来衡量重复尝试的成功概率，并引入 inference loss，该损失随尝试次数呈幂律衰减，与大型语言模型（LLMs）在推理任务中的行为一致。通过在简单生成模型上的实验验证，该模型的预测与经验数据相符。该框架为将推理缩放与其他已知 scaling laws 整合奠定了基础。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.IT",
        "cs.LG",
        "math.IT"
      ],
      "primary_category": "stat.ML",
      "comment": "12 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.16377v2",
      "published_date": "2024-10-21 18:00:06 UTC",
      "updated_date": "2024-12-07 22:50:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:17:13.108699"
    },
    {
      "arxiv_id": "2410.16270v1",
      "title": "Reflection-Bench: probing AI intelligence with reflection",
      "title_zh": "翻译失败",
      "authors": [
        "Lingyu Li",
        "Yixu Wang",
        "Haiquan Zhao",
        "Shuqi Kong",
        "Yan Teng",
        "Chunbo Li",
        "Yingchun Wang"
      ],
      "abstract": "The ability to adapt beliefs or behaviors in response to unexpected outcomes,\nreflection, is fundamental to intelligent systems' interaction with the world.\nFrom a cognitive science perspective, this serves as a core principle of\nintelligence applicable to both human and AI systems. To address the debate on\nthe intelligence of large language models (LLMs), we propose Reflection-Bench,\na comprehensive benchmark comprising 7 tasks spanning core cognitive functions\ncrucial for reflection, including perception, memory, belief updating,\ndecision-making, prediction, counterfactual thinking, and meta-reflection. We\nevaluate the performances of 13 prominent LLMs such as OpenAI o1, GPT-4, Claude\n3.5 Sonnet, etc. The results indicate that current LLMs still lack satisfactory\nreflection ability. We discuss the underlying causes of these results and\nsuggest potential avenues for future research. In conclusion, Reflection-Bench\noffers both evaluation tools and inspiration for developing AI capable of\nreliably interacting with the environment. Our data and code are available at\nhttps://github.com/YabYum/ReflectionBench.",
      "tldr_zh": "这篇论文引入了Reflection-Bench，一个综合基准，用于评估大型语言模型(LLMs)的反思能力，即适应信念或行为以应对意外结果的核心认知功能。基准包括7个任务，涵盖感知、记忆、信念更新、决策、预测、反事实思考和元反思，并对13个主要LLMs（如OpenAI o1、GPT-4和Claude 3.5 Sonnet）进行了评估。结果显示，当前LLMs的反思能力仍不令人满意，论文讨论了潜在原因并建议未来研究方向。该基准为开发更可靠的环境交互AI提供了评估工具和灵感。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages, 7 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.16270v1",
      "published_date": "2024-10-21 17:59:50 UTC",
      "updated_date": "2024-10-21 17:59:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:17:25.477898"
    },
    {
      "arxiv_id": "2410.16267v1",
      "title": "xGen-MM-Vid (BLIP-3-Video): You Only Need 32 Tokens to Represent a Video Even in VLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Michael S. Ryoo",
        "Honglu Zhou",
        "Shrikant Kendre",
        "Can Qin",
        "Le Xue",
        "Manli Shu",
        "Silvio Savarese",
        "Ran Xu",
        "Caiming Xiong",
        "Juan Carlos Niebles"
      ],
      "abstract": "We present xGen-MM-Vid (BLIP-3-Video): a multimodal language model for\nvideos, particularly designed to efficiently capture temporal information over\nmultiple frames. BLIP-3-Video takes advantage of the 'temporal encoder' in\naddition to the conventional visual tokenizer, which maps a sequence of tokens\nover multiple frames into a compact set of visual tokens. This enables\nBLIP3-Video to use much fewer visual tokens than its competing models (e.g., 32\nvs. 4608 tokens). We explore different types of temporal encoders, including\nlearnable spatio-temporal pooling as well as sequential models like Token\nTuring Machines. We experimentally confirm that BLIP-3-Video obtains video\nquestion-answering accuracies comparable to much larger state-of-the-art models\n(e.g., 34B), while being much smaller (i.e., 4B) and more efficient by using\nfewer visual tokens. The project website is at\nhttps://www.salesforceairesearch.com/opensource/xGen-MM-Vid/index.html",
      "tldr_zh": "本论文介绍了 xGen-MM-Vid (BLIP-3-Video)，一个高效的多模态视频语言模型(VLMs)，旨在通过 temporal encoder 和视觉 tokenizer，仅需 32 个 tokens 即可表示多帧视频序列，大大减少了传统模型的计算需求。模型探索了多种 temporal encoders，包括 learnable spatio-temporal pooling 和 Token Turing Machines，以有效捕捉视频的时间信息。实验结果显示，BLIP-3-Video 在视频问答任务上达到了与更大模型（如 34B 参数模型）相当的准确率，但模型规模仅为 4B 参数，且使用更少的视觉 tokens，显著提升了效率。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16267v1",
      "published_date": "2024-10-21 17:59:11 UTC",
      "updated_date": "2024-10-21 17:59:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:19:38.288200"
    },
    {
      "arxiv_id": "2410.16266v1",
      "title": "3DGS-Enhancer: Enhancing Unbounded 3D Gaussian Splatting with View-consistent 2D Diffusion Priors",
      "title_zh": "翻译失败",
      "authors": [
        "Xi Liu",
        "Chaoyi Zhou",
        "Siyu Huang"
      ],
      "abstract": "Novel-view synthesis aims to generate novel views of a scene from multiple\ninput images or videos, and recent advancements like 3D Gaussian splatting\n(3DGS) have achieved notable success in producing photorealistic renderings\nwith efficient pipelines. However, generating high-quality novel views under\nchallenging settings, such as sparse input views, remains difficult due to\ninsufficient information in under-sampled areas, often resulting in noticeable\nartifacts. This paper presents 3DGS-Enhancer, a novel pipeline for enhancing\nthe representation quality of 3DGS representations. We leverage 2D video\ndiffusion priors to address the challenging 3D view consistency problem,\nreformulating it as achieving temporal consistency within a video generation\nprocess. 3DGS-Enhancer restores view-consistent latent features of rendered\nnovel views and integrates them with the input views through a spatial-temporal\ndecoder. The enhanced views are then used to fine-tune the initial 3DGS model,\nsignificantly improving its rendering performance. Extensive experiments on\nlarge-scale datasets of unbounded scenes demonstrate that 3DGS-Enhancer yields\nsuperior reconstruction performance and high-fidelity rendering results\ncompared to state-of-the-art methods. The project webpage is\nhttps://xiliu8006.github.io/3DGS-Enhancer-project .",
      "tldr_zh": "本文提出 3DGS-Enhancer，一种增强无界 3D Gaussian Splatting (3DGS) 的新管道，通过利用视图一致的 2D Diffusion Priors，将 3D 视图一致性问题转化为视频生成中的时间一致性，从而恢复并整合渲染的新视图潜伏特征。方法包括使用空间-时间解码器融合增强视图，并以此微调初始 3DGS 模型，以解决稀疏输入视图导致的 artifacts 问题。实验在大型无界场景数据集上证明，该框架实现了优越的重建性能和高保真渲染结果，超越了现有最先进方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by NeurIPS 2024 Spotlight",
      "pdf_url": "http://arxiv.org/pdf/2410.16266v1",
      "published_date": "2024-10-21 17:59:09 UTC",
      "updated_date": "2024-10-21 17:59:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:17:50.683073"
    },
    {
      "arxiv_id": "2410.16256v1",
      "title": "CompassJudger-1: All-in-one Judge Model Helps Model Evaluation and Evolution",
      "title_zh": "翻译失败",
      "authors": [
        "Maosong Cao",
        "Alexander Lam",
        "Haodong Duan",
        "Hongwei Liu",
        "Songyang Zhang",
        "Kai Chen"
      ],
      "abstract": "Efficient and accurate evaluation is crucial for the continuous improvement\nof large language models (LLMs). Among various assessment methods, subjective\nevaluation has garnered significant attention due to its superior alignment\nwith real-world usage scenarios and human preferences. However, human-based\nevaluations are costly and lack reproducibility, making precise automated\nevaluators (judgers) vital in this process. In this report, we introduce\n\\textbf{CompassJudger-1}, the first open-source \\textbf{all-in-one} judge LLM.\nCompassJudger-1 is a general-purpose LLM that demonstrates remarkable\nversatility. It is capable of: 1. Performing unitary scoring and two-model\ncomparisons as a reward model; 2. Conducting evaluations according to specified\nformats; 3. Generating critiques; 4. Executing diverse tasks like a general\nLLM. To assess the evaluation capabilities of different judge models under a\nunified setting, we have also established \\textbf{JudgerBench}, a new benchmark\nthat encompasses various subjective evaluation tasks and covers a wide range of\ntopics. CompassJudger-1 offers a comprehensive solution for various evaluation\ntasks while maintaining the flexibility to adapt to diverse requirements. Both\nCompassJudger and JudgerBench are released and available to the research\ncommunity athttps://github.com/open-compass/CompassJudger. We believe that by\nopen-sourcing these tools, we can foster collaboration and accelerate progress\nin LLM evaluation methodologies.",
      "tldr_zh": "该研究强调了高效准确评估对大型语言模型（LLMs）的持续改进的重要性，并指出主观评估虽更贴合真实场景，但成本高且缺乏可重复性。作者引入了开源的 CompassJudger-1，这是一个通用的 all-in-one 判断模型，能够执行单一评分、两模型比较、指定格式评估、批评生成以及多样任务。论文还建立了 JudgerBench 基准，用于统一评估不同判断模型的表现，结果显示 CompassJudger-1 在各种主观任务中表现出色，并通过开源促进 LLM 评估方法学的社区合作。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Technical Report, Code and Models:\n  https://github.com/open-compass/CompassJudger",
      "pdf_url": "http://arxiv.org/pdf/2410.16256v1",
      "published_date": "2024-10-21 17:56:51 UTC",
      "updated_date": "2024-10-21 17:56:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:18:01.121884"
    },
    {
      "arxiv_id": "2410.16239v2",
      "title": "MoRE: Multi-Modal Contrastive Pre-training with Transformers on X-Rays, ECGs, and Diagnostic Report",
      "title_zh": "翻译失败",
      "authors": [
        "Samrajya Thapa",
        "Koushik Howlader",
        "Subhankar Bhattacharjee",
        "Wei le"
      ],
      "abstract": "In this paper, we introduce a novel Multi-Modal Contrastive Pre-training\nFramework that synergistically combines X-rays, electrocardiograms (ECGs), and\nradiology/cardiology reports. Our approach leverages transformers to encode\nthese diverse modalities into a unified representation space, aiming to enhance\ndiagnostic accuracy and facilitate comprehensive patient assessments. We\nutilize LoRA-Peft to significantly reduce trainable parameters in the LLM and\nincorporate recent linear attention dropping strategy in the Vision\nTransformer(ViT) for smoother attention. Furthermore, we provide novel\nmultimodal attention explanations and retrieval for our model. To the best of\nour knowledge, we are the first to propose an integrated model that combines\nX-ray, ECG, and Radiology/Cardiology Report with this approach. By utilizing\ncontrastive loss, MoRE effectively aligns modality-specific features into a\ncoherent embedding, which supports various downstream tasks such as zero-shot\nclassification and multimodal retrieval. Employing our proposed methodology, we\nachieve state-of-the-art (SOTA) on the Mimic-IV, CheXpert, Edema Severity, and\nPtbXl downstream datasets, surpassing existing multimodal approaches. Our\nproposed framework shows significant improvements in capturing intricate\ninter-modal relationships and its robustness in medical diagnosis that\nestablishes a framework for future research in multimodal learning in the\nhealthcare sector.",
      "tldr_zh": "本研究提出了一种名为 MoRE 的多模态对比预训练框架，将 X-rays、ECGs 和诊断报告整合在一起，使用 transformers 将这些模态编码到统一的表示空间，以提升诊断准确性和患者评估。框架采用 LoRA-Peft 减少 LLM 的可训练参数，并在 Vision Transformer (ViT) 中引入 linear attention dropping 策略，同时通过 contrastive loss 实现模态特征对齐，支持下游任务如 zero-shot classification 和 multimodal retrieval。该方法是首个结合这些模态的集成模型，并在 Mimic-IV、CheXpert、Edema Severity 和 PtbXl 数据集上达到 SOTA 性能，显著改善了 inter-modal 关系的捕捉和医疗诊断的鲁棒性。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 5 figures, 9 tables. Supplementary detail in Appendix. Code\n  made available in Github for reproducibility",
      "pdf_url": "http://arxiv.org/pdf/2410.16239v2",
      "published_date": "2024-10-21 17:42:41 UTC",
      "updated_date": "2024-10-22 22:22:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:18:12.953946"
    },
    {
      "arxiv_id": "2410.16232v1",
      "title": "Sketch2Code: Evaluating Vision-Language Models for Interactive Web Design Prototyping",
      "title_zh": "翻译失败",
      "authors": [
        "Ryan Li",
        "Yanzhe Zhang",
        "Diyi Yang"
      ],
      "abstract": "Sketches are a natural and accessible medium for UI designers to\nconceptualize early-stage ideas. However, existing research on UI/UX automation\noften requires high-fidelity inputs like Figma designs or detailed screenshots,\nlimiting accessibility and impeding efficient design iteration. To bridge this\ngap, we introduce Sketch2Code, a benchmark that evaluates state-of-the-art\nVision Language Models (VLMs) on automating the conversion of rudimentary\nsketches into webpage prototypes. Beyond end-to-end benchmarking, Sketch2Code\nsupports interactive agent evaluation that mimics real-world design workflows,\nwhere a VLM-based agent iteratively refines its generations by communicating\nwith a simulated user, either passively receiving feedback instructions or\nproactively asking clarification questions. We comprehensively analyze ten\ncommercial and open-source models, showing that Sketch2Code is challenging for\nexisting VLMs; even the most capable models struggle to accurately interpret\nsketches and formulate effective questions that lead to steady improvement.\nNevertheless, a user study with UI/UX experts reveals a significant preference\nfor proactive question-asking over passive feedback reception, highlighting the\nneed to develop more effective paradigms for multi-turn conversational agents.",
      "tldr_zh": "本研究引入了Sketch2Code基准，用于评估Vision-Language Models (VLMs)在将手绘草图转换为网页原型的交互式Web设计过程中的性能，以解决现有UI/UX自动化依赖高保真输入的局限性。Sketch2Code不仅支持端到端基准测试，还模拟真实设计工作流，让VLM-based代理通过多轮互动（如被动接收反馈或主动提问）迭代改进草图生成。实验分析了十个商业和开源模型，结果显示现有VLMs在准确解释草图和提出有效问题方面面临挑战，即使最先进的模型也难以实现稳定提升。同时，用户研究表明UI/UX专家更偏好代理主动提问，这突显了开发更有效多轮对话代理范式的必要性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "preprint, 9 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.16232v1",
      "published_date": "2024-10-21 17:39:49 UTC",
      "updated_date": "2024-10-21 17:39:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:18:25.646954"
    },
    {
      "arxiv_id": "2410.16221v1",
      "title": "On Creating an English-Thai Code-switched Machine Translation in Medical Domain",
      "title_zh": "在医疗领域创建英语-泰语代码切换机器翻译",
      "authors": [
        "Parinthapat Pengpun",
        "Krittamate Tiankanon",
        "Amrest Chinkamol",
        "Jiramet Kinchagawat",
        "Pitchaya Chairuengjitjaras",
        "Pasit Supholkhan",
        "Pubordee Aussavavirojekul",
        "Chiraphat Boonnag",
        "Kanyakorn Veerakanjana",
        "Hirunkul Phimsiri",
        "Boonthicha Sae-jia",
        "Nattawach Sataudom",
        "Piyalitt Ittichaiwong",
        "Peerat Limkonchotiwat"
      ],
      "abstract": "Machine translation (MT) in the medical domain plays a pivotal role in\nenhancing healthcare quality and disseminating medical knowledge. Despite\nadvancements in English-Thai MT technology, common MT approaches often\nunderperform in the medical field due to their inability to precisely translate\nmedical terminologies. Our research prioritizes not merely improving\ntranslation accuracy but also maintaining medical terminology in English within\nthe translated text through code-switched (CS) translation. We developed a\nmethod to produce CS medical translation data, fine-tuned a CS translation\nmodel with this data, and evaluated its performance against strong baselines,\nsuch as Google Neural Machine Translation (NMT) and GPT-3.5/GPT-4. Our model\ndemonstrated competitive performance in automatic metrics and was highly\nfavored in human preference evaluations. Our evaluation result also shows that\nmedical professionals significantly prefer CS translations that maintain\ncritical English terms accurately, even if it slightly compromises fluency. Our\ncode and test set are publicly available\nhttps://github.com/preceptorai-org/NLLB_CS_EM_NLP2024.",
      "tldr_zh": "本研究针对医疗领域的英语-泰语机器翻译 (MT) 问题，提出了一种 code-switched (CS) 翻译方法，以提高翻译准确性和保留关键英语医疗术语。研究团队开发了生成 CS 医疗翻译数据的技术，并通过微调 CS 翻译模型，与 Google Neural Machine Translation (NMT) 以及 GPT-3.5/GPT-4 等基线模型进行比较。结果显示，该模型在自动评估指标上表现出色，并在人类偏好评估中获得更高认可，特别是医疗专业人士更青睐准确保持英语术语的翻译，即使这会略微影响流畅性。该代码和测试集已公开可用，以促进进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16221v1",
      "published_date": "2024-10-21 17:25:32 UTC",
      "updated_date": "2024-10-21 17:25:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:18:37.059558"
    },
    {
      "arxiv_id": "2410.16215v1",
      "title": "Pre-training Distillation for Large Language Models: A Design Space Exploration",
      "title_zh": "大型语言模型的预训练蒸馏：设计空间探索",
      "authors": [
        "Hao Peng",
        "Xin Lv",
        "Yushi Bai",
        "Zijun Yao",
        "Jiajie Zhang",
        "Lei Hou",
        "Juanzi Li"
      ],
      "abstract": "Knowledge distillation (KD) aims to transfer knowledge from a large teacher\nmodel to a smaller student model. Previous work applying KD in the field of\nlarge language models (LLMs) typically focused on the post-training phase,\nwhere the student LLM learns directly from instructions and corresponding\nresponses generated by the teacher model. In this paper, we extend KD to the\npre-training phase of LLMs, named pre-training distillation (PD). We first\nconduct a preliminary experiment using GLM-4-9B as the teacher LLM to distill a\n1.9B parameter student LLM, validating the effectiveness of PD. Considering the\nkey impact factors of distillation, we systematically explore the design space\nof pre-training distillation across four aspects: logits processing, loss\nselection, scaling law, and offline or online logits. We conduct extensive\nexperiments to explore the design space of pre-training distillation and find\nbetter configurations and interesting conclusions, such as larger student LLMs\ngenerally benefiting more from pre-training distillation, while a larger\nteacher LLM does not necessarily guarantee better results. We hope our\nexploration of the design space will inform future practices in pre-training\ndistillation.",
      "tldr_zh": "本文提出了一种将知识蒸馏 (KD) 扩展到大型语言模型 (LLMs) 预训练阶段的方法，称为预训练蒸馏 (PD)，旨在从教师模型向更小学生模型转移知识。研究者使用 GLM-4-9B 作为教师模型蒸馏一个 1.9B 参数的学生模型，验证了 PD 的有效性，并系统探索了设计空间，包括 logits 处理、损失选择、scaling law 以及在线或离线 logits。实验结果显示，更大的学生 LLMs 从 PD 中获益更多，而更大的教师模型并不总是带来更好性能。该探索为未来的预训练蒸馏实践提供了宝贵指导。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16215v1",
      "published_date": "2024-10-21 17:16:13 UTC",
      "updated_date": "2024-10-21 17:16:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:18:50.246718"
    },
    {
      "arxiv_id": "2410.16212v2",
      "title": "Comprehensive benchmarking of large language models for RNA secondary structure prediction",
      "title_zh": "翻译失败",
      "authors": [
        "L. I. Zablocki",
        "L. A. Bugnon",
        "M. Gerard",
        "L. Di Persia",
        "G. Stegmayer",
        "D. H. Milone"
      ],
      "abstract": "Inspired by the success of large language models (LLM) for DNA and proteins,\nseveral LLM for RNA have been developed recently. RNA-LLM uses large datasets\nof RNA sequences to learn, in a self-supervised way, how to represent each RNA\nbase with a semantically rich numerical vector. This is done under the\nhypothesis that obtaining high-quality RNA representations can enhance\ndata-costly downstream tasks. Among them, predicting the secondary structure is\na fundamental task for uncovering RNA functional mechanisms. In this work we\npresent a comprehensive experimental analysis of several pre-trained RNA-LLM,\ncomparing them for the RNA secondary structure prediction task in an unified\ndeep learning framework. The RNA-LLM were assessed with increasing\ngeneralization difficulty on benchmark datasets. Results showed that two LLM\nclearly outperform the other models, and revealed significant challenges for\ngeneralization in low-homology scenarios.",
      "tldr_zh": "这篇论文对大型语言模型（LLM）在RNA二级结构预测任务中的性能进行了全面基准测试，受LLM在DNA和蛋白质领域的成功启发。研究者使用统一深度学习框架，评估了多个预训练的RNA-LLM模型，这些模型通过自监督方式从大型RNA序列数据集学习高质量的RNA碱基表示，并在不同泛化难度的基准数据集上进行测试。结果显示，两个LLM模型明显优于其他模型，但在低同源性场景中暴露了显著的泛化挑战，为未来RNA-LLM的改进提供了关键见解。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "q-bio.BM"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16212v2",
      "published_date": "2024-10-21 17:12:06 UTC",
      "updated_date": "2025-01-31 21:39:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:19:00.723762"
    },
    {
      "arxiv_id": "2410.16208v4",
      "title": "Compute-Constrained Data Selection",
      "title_zh": "计算约束的数据选择",
      "authors": [
        "Junjie Oscar Yin",
        "Alexander M. Rush"
      ],
      "abstract": "Data selection can reduce the amount of training data needed to finetune\nLLMs; however, the efficacy of data selection scales directly with its compute.\nMotivated by the practical challenge of compute-constrained finetuning, we\nconsider the setting in which both the cost of selecting data and training are\nbudgeted for. We first formalize the problem of data selection with a\ncost-aware utility function, and model the data selection problem as trading\noff initial-selection cost for training gain. We run a comprehensive sweep of\nexperiments across multiple tasks, varying compute budget by scaling finetuning\ntokens, model sizes, and data selection compute. Interestingly we find that\nmany powerful data selection methods are almost never compute-optimal, and that\ncheaper data selection alternatives dominate both from a theoretical and\nempirical perspective. For compute-optimal training, we find that perplexity\nand gradient data selection require training-to-selection model size ratios of\n5x and 10x, respectively.",
      "tldr_zh": "这篇论文探讨了在计算资源受限的场景下，如何优化数据选择以减少训练大型语言模型（LLMs）的所需数据量。他们形式化了数据选择问题，使用成本感知效用函数，将其建模为初始选择成本与训练收益的权衡，并通过实验比较不同方法在多种任务上的表现。实验结果显示，许多强大数据选择方法在计算效率上几乎从不最优，更便宜的替代方法在理论和经验上更具优势；具体而言，perplexity和gradient数据选择需要训练模型大小分别比选择模型大5倍和10倍，以实现计算最优训练。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Published as a conference paper at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.16208v4",
      "published_date": "2024-10-21 17:11:21 UTC",
      "updated_date": "2025-04-07 18:16:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:19:49.951300"
    },
    {
      "arxiv_id": "2410.16198v1",
      "title": "Improve Vision Language Model Chain-of-thought Reasoning",
      "title_zh": "改进视觉语言模型的链式思考推理",
      "authors": [
        "Ruohong Zhang",
        "Bowen Zhang",
        "Yanghao Li",
        "Haotian Zhang",
        "Zhiqing Sun",
        "Zhe Gan",
        "Yinfei Yang",
        "Ruoming Pang",
        "Yiming Yang"
      ],
      "abstract": "Chain-of-thought (CoT) reasoning in vision language models (VLMs) is crucial\nfor improving interpretability and trustworthiness. However, current training\nrecipes lack robust CoT reasoning data, relying on datasets dominated by short\nannotations with minimal rationales. In this work, we show that training VLM on\nshort answers does not generalize well to reasoning tasks that require more\ndetailed responses. To address this, we propose a two-fold approach. First, we\ndistill rationales from GPT-4o model to enrich the training data and fine-tune\nVLMs, boosting their CoT performance. Second, we apply reinforcement learning\nto further calibrate reasoning quality. Specifically, we construct positive\n(correct) and negative (incorrect) pairs of model-generated reasoning chains,\nby comparing their predictions with annotated short answers. Using this\npairwise data, we apply the Direct Preference Optimization algorithm to refine\nthe model's reasoning abilities. Our experiments demonstrate significant\nimprovements in CoT reasoning on benchmark datasets and better generalization\nto direct answer prediction as well. This work emphasizes the importance of\nincorporating detailed rationales in training and leveraging reinforcement\nlearning to strengthen the reasoning capabilities of VLMs.",
      "tldr_zh": "本文研究了视觉语言模型 (VLMs) 在 Chain-of-thought (CoT) 推理中的不足，即现有训练数据主要依赖短注解，缺乏详细推理理由，导致模型在复杂任务上泛化不佳。作者提出双重方法：首先，从 GPT-4o 模型提炼推理理由 (rationales) 以丰富训练数据，并微调 VLMs 以提升 CoT 性能；其次，使用强化学习构建正负样本对（通过与注解答案比较），并应用 Direct Preference Optimization (DPO) 算法来进一步优化推理质量。实验结果显示，该方法显著提高了 VLMs 在基准数据集上的 CoT 推理表现，并增强了其对直接答案预测的泛化能力。该工作强调了在训练中纳入详细 rationales 和强化学习的重要性，以加强 VLMs 的推理能力。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "68T07"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages + appendix",
      "pdf_url": "http://arxiv.org/pdf/2410.16198v1",
      "published_date": "2024-10-21 17:00:06 UTC",
      "updated_date": "2024-10-21 17:00:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:20:04.036275"
    },
    {
      "arxiv_id": "2410.16196v1",
      "title": "Information for Conversation Generation: Proposals Utilising Knowledge Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Alex Clay",
        "Ernesto Jiménez-Ruiz"
      ],
      "abstract": "LLMs are frequently used tools for conversational generation. Without\nadditional information LLMs can generate lower quality responses due to lacking\nrelevant content and hallucinations, as well as the perception of poor\nemotional capability, and an inability to maintain a consistent character.\nKnowledge graphs are commonly used forms of external knowledge and may provide\nsolutions to these challenges. This paper introduces three proposals, utilizing\nknowledge graphs to enhance LLM generation. Firstly, dynamic knowledge graph\nembeddings and recommendation could allow for the integration of new\ninformation and the selection of relevant knowledge for response generation.\nSecondly, storing entities with emotional values as additional features may\nprovide knowledge that is better emotionally aligned with the user input.\nThirdly, integrating character information through narrative bubbles would\nmaintain character consistency, as well as introducing a structure that would\nreadily incorporate new information.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)在对话生成中的问题，如内容相关性不足、幻觉发生、情感能力弱以及角色一致性差，并提出利用知识图谱(Knowledge Graphs)作为外部知识来源来解决这些挑战。论文介绍了三个提案：首先，通过动态知识图谱嵌入和推荐机制整合新信息并选择相关知识，提升响应质量；其次，为实体添加情感值作为额外特征，使生成内容更符合用户情感；第三，通过叙事气泡整合角色信息，确保角色一致性和易于吸收新数据。这些方法为提升LLMs的对话生成可靠性提供了潜在框架。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "7 pages with citations, 1 figure, accepted to the ISWC 2024 Special\n  Session",
      "pdf_url": "http://arxiv.org/pdf/2410.16196v1",
      "published_date": "2024-10-21 16:59:25 UTC",
      "updated_date": "2024-10-21 16:59:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:20:13.823787"
    },
    {
      "arxiv_id": "2410.16170v1",
      "title": "Learning How to Vote With Principles: Axiomatic Insights Into the Collective Decisions of Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Levin Hornischer",
        "Zoi Terzopoulou"
      ],
      "abstract": "Can neural networks be applied in voting theory, while satisfying the need\nfor transparency in collective decisions? We propose axiomatic deep voting: a\nframework to build and evaluate neural networks that aggregate preferences,\nusing the well-established axiomatic method of voting theory. Our findings are:\n(1) Neural networks, despite being highly accurate, often fail to align with\nthe core axioms of voting rules, revealing a disconnect between mimicking\noutcomes and reasoning. (2) Training with axiom-specific data does not enhance\nalignment with those axioms. (3) By solely optimizing axiom satisfaction,\nneural networks can synthesize new voting rules that often surpass and\nsubstantially differ from existing ones. This offers insights for both fields:\nFor AI, important concepts like bias and value-alignment are studied in a\nmathematically rigorous way; for voting theory, new areas of the space of\nvoting rules are explored.",
      "tldr_zh": "这篇论文提出了“axiomatic deep voting”框架，用于构建和评估neural networks在偏好聚合中的应用，确保集体决策的透明性。研究发现，neural networks尽管准确，但往往无法符合投票规则的核心公理，且使用特定公理的数据训练并不能提升其对这些公理的遵守。更为重要的是，通过仅优化公理满足度，neural networks能够合成新的voting rules，这些规则通常优于并显著不同于现有规则，为AI领域的偏差和价值对齐研究，以及voting theory的规则空间探索提供了数学严谨的洞见。",
      "categories": [
        "cs.AI",
        "I.2.6; J.4"
      ],
      "primary_category": "cs.AI",
      "comment": "15 pages, 8 figures, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.16170v1",
      "published_date": "2024-10-21 16:35:58 UTC",
      "updated_date": "2024-10-21 16:35:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:20:25.589815"
    },
    {
      "arxiv_id": "2410.16164v1",
      "title": "GenAI Assisting Medical Training",
      "title_zh": "翻译失败",
      "authors": [
        "Stefan Fritsch",
        "Matthias Tschoepe",
        "Vitor Fortes Rey",
        "Lars Krupp",
        "Agnes Gruenerbl",
        "Eloise Monger",
        "Sarah Travenna"
      ],
      "abstract": "Medical procedures such as venipuncture and cannulation are essential for\nnurses and require precise skills. Learning this skill, in turn, is a challenge\nfor educators due to the number of teachers per class and the complexity of the\ntask. The study aims to help students with skill acquisition and alleviate the\neducator's workload by integrating generative AI methods to provide real-time\nfeedback on medical procedures such as venipuncture and cannulation.",
      "tldr_zh": "该研究针对护士学习医疗程序如静脉穿刺(venipuncture)和插管(cannulation)的挑战，旨在通过整合生成式 AI (GenAI) 方法提供实时反馈，帮助学生提升技能。现有问题包括教育者数量不足和任务复杂性，导致教学负担过重。研究方法结合 GenAI 技术，减轻教育者工作负载，并改善技能获取效率。总体上，此方法有望优化医疗训练过程，提升教学效果。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "2 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.16164v1",
      "published_date": "2024-10-21 16:31:16 UTC",
      "updated_date": "2024-10-21 16:31:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:20:37.004011"
    },
    {
      "arxiv_id": "2410.16152v2",
      "title": "Warped Diffusion: Solving Video Inverse Problems with Image Diffusion Models",
      "title_zh": "Warped Diffusion：使用图像扩散模型解决视频逆问题",
      "authors": [
        "Giannis Daras",
        "Weili Nie",
        "Karsten Kreis",
        "Alex Dimakis",
        "Morteza Mardani",
        "Nikola Borislavov Kovachki",
        "Arash Vahdat"
      ],
      "abstract": "Using image models naively for solving inverse video problems often suffers\nfrom flickering, texture-sticking, and temporal inconsistency in generated\nvideos. To tackle these problems, in this paper, we view frames as continuous\nfunctions in the 2D space, and videos as a sequence of continuous warping\ntransformations between different frames. This perspective allows us to train\nfunction space diffusion models only on images and utilize them to solve\ntemporally correlated inverse problems. The function space diffusion models\nneed to be equivariant with respect to the underlying spatial transformations.\nTo ensure temporal consistency, we introduce a simple post-hoc test-time\nguidance towards (self)-equivariant solutions. Our method allows us to deploy\nstate-of-the-art latent diffusion models such as Stable Diffusion XL to solve\nvideo inverse problems. We demonstrate the effectiveness of our method for\nvideo inpainting and $8\\times$ video super-resolution, outperforming existing\ntechniques based on noise transformations. We provide generated video results:\nhttps://giannisdaras.github.io/warped_diffusion.github.io/.",
      "tldr_zh": "本研究提出Warped Diffusion方法，利用image diffusion models解决视频逆问题（如视频修复和超分辨率），以解决传统方法导致的flickering、texture-sticking和temporal inconsistency问题。方法将视频帧视为2D空间中的连续函数，并将其视为帧间连续warping transformations的序列，训练function space diffusion models以确保对空间变换的equivariance。最终，通过简单的post-hoc test-time guidance，实现temporal consistency，并将State-of-the-art模型如Stable Diffusion XL应用于视频inpainting和8× video super-resolution，性能优于基于噪声变换的现有技术。实验结果证明了其有效性，并提供了生成的视频示例。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted in NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.16152v2",
      "published_date": "2024-10-21 16:19:34 UTC",
      "updated_date": "2024-10-22 03:37:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:20:50.989574"
    },
    {
      "arxiv_id": "2410.16151v1",
      "title": "Small Contributions, Small Networks: Efficient Neural Network Pruning Based on Relative Importance",
      "title_zh": "小贡献、小网络：基于相对重要性的高效神经网络剪",
      "authors": [
        "Mostafa Hussien",
        "Mahmoud Afifi",
        "Kim Khoa Nguyen",
        "Mohamed Cheriet"
      ],
      "abstract": "Recent advancements have scaled neural networks to unprecedented sizes,\nachieving remarkable performance across a wide range of tasks. However,\ndeploying these large-scale models on resource-constrained devices poses\nsignificant challenges due to substantial storage and computational\nrequirements. Neural network pruning has emerged as an effective technique to\nmitigate these limitations by reducing model size and complexity. In this\npaper, we introduce an intuitive and interpretable pruning method based on\nactivation statistics, rooted in information theory and statistical analysis.\nOur approach leverages the statistical properties of neuron activations to\nidentify and remove weights with minimal contributions to neuron outputs.\nSpecifically, we build a distribution of weight contributions across the\ndataset and utilize its parameters to guide the pruning process. Furthermore,\nwe propose a Pruning-aware Training strategy that incorporates an additional\nregularization term to enhance the effectiveness of our pruning method.\nExtensive experiments on multiple datasets and network architectures\ndemonstrate that our method consistently outperforms several baseline and\nstate-of-the-art pruning techniques.",
      "tldr_zh": "本论文提出了一种基于激活统计（activation statistics）的神经网络修剪方法，旨在通过信息理论和统计分析减少模型大小，以适应资源受限设备的需求。该方法分析神经元激活的统计特性，构建权重贡献分布，并优先移除对神经元输出贡献小的权重，同时引入 Pruning-aware Training 策略，通过额外正则化项提升修剪效果。在多个数据集和网络架构上的实验显示，该方法优于基线和最先进技术，证明了其高效性和有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16151v1",
      "published_date": "2024-10-21 16:18:31 UTC",
      "updated_date": "2024-10-21 16:18:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:21:01.778786"
    },
    {
      "arxiv_id": "2410.16148v1",
      "title": "PODTILE: Facilitating Podcast Episode Browsing with Auto-generated Chapters",
      "title_zh": "PODTILE：通过自动生成的章节促进",
      "authors": [
        "Azin Ghazimatin",
        "Ekaterina Garmash",
        "Gustavo Penha",
        "Kristen Sheets",
        "Martin Achenbach",
        "Oguz Semerci",
        "Remi Galvez",
        "Marcus Tannenberg",
        "Sahitya Mantravadi",
        "Divya Narayanan",
        "Ofeliya Kalaydzhyan",
        "Douglas Cole",
        "Ben Carterette",
        "Ann Clifton",
        "Paul N. Bennett",
        "Claudia Hauff",
        "Mounia Lalmas"
      ],
      "abstract": "Listeners of long-form talk-audio content, such as podcast episodes, often\nfind it challenging to understand the overall structure and locate relevant\nsections. A practical solution is to divide episodes into\nchapters--semantically coherent segments labeled with titles and timestamps.\nSince most episodes on our platform at Spotify currently lack creator-provided\nchapters, automating the creation of chapters is essential. Scaling the\nchapterization of podcast episodes presents unique challenges. First, episodes\ntend to be less structured than written texts, featuring spontaneous\ndiscussions with nuanced transitions. Second, the transcripts are usually\nlengthy, averaging about 16,000 tokens, which necessitates efficient processing\nthat can preserve context. To address these challenges, we introduce PODTILE, a\nfine-tuned encoder-decoder transformer to segment conversational data. The\nmodel simultaneously generates chapter transitions and titles for the input\ntranscript. To preserve context, each input text is augmented with global\ncontext, including the episode's title, description, and previous chapter\ntitles. In our intrinsic evaluation, PODTILE achieved an 11% improvement in\nROUGE score over the strongest baseline. Additionally, we provide insights into\nthe practical benefits of auto-generated chapters for listeners navigating\nepisode content. Our findings indicate that auto-generated chapters serve as a\nuseful tool for engaging with less popular podcasts. Finally, we present\nempirical evidence that using chapter titles can enhance effectiveness of\nsparse retrieval in search tasks.",
      "tldr_zh": "该研究针对播客剧集等长音频内容的听众难以理解结构和定位相关部分的问题，提出了PODTILE系统，通过自动生成章节（chapters）来提升浏览体验。PODTILE是一个微调的encoder-decoder transformer模型，能够同时生成章节过渡和标题，并通过添加全局上下文（如剧集标题、描述和前一章节标题）来处理长文本的语义挑战。在内在评估中，该模型的ROUGE score比最强基线提高了11%，并证明自动生成的章节有助于听众导航，尤其是对不太受欢迎的播客，同时提升了搜索任务中的稀疏检索效果。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "68P20",
        "H.3.3"
      ],
      "primary_category": "cs.IR",
      "comment": "9 pages, 4 figures, CIKM industry track 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.16148v1",
      "published_date": "2024-10-21 16:17:22 UTC",
      "updated_date": "2024-10-21 16:17:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:21:13.967858"
    },
    {
      "arxiv_id": "2410.16136v2",
      "title": "Modeling Dynamic Neural Activity by combining Naturalistic Video Stimuli and Stimulus-independent Latent Factors",
      "title_zh": "翻译失败",
      "authors": [
        "Finn Schmidt",
        "Polina Turishcheva",
        "Suhas Shrinivasan",
        "Fabian H. Sinz"
      ],
      "abstract": "Understanding how visual processing of natural stimuli and internal brain\nstates interact in populations of neurons remains an open question in\nneuroscience. Currently there are no dynamic encoding models that explicitly\nmodel a latent state and the entire neuronal response distribution. We address\nthis gap by proposing a probabilistic model that predicts the joint\ndistribution of the neuronal responses from video stimuli and\nstimulus-independent latent factors. After training and testing our model on\nmouse V1 neuronal responses, we find that it outperforms video-only models in\nterms of log-likelihood and achieves improvements in likelihood and correlation\nwhen conditioned on responses from other neurons. Furthermore, we find that the\nlearned latent factors strongly correlate with mouse behavior and that they\nexhibits patterns related to the neurons position on visual cortex, although\nthe model was trained without behavior and cortical coordinates. Our findings\ndemonstrate that unsupervised learning of latent factors from population\nresponses can reveal biologically meaningful structure that bridges sensory\nprocessing and behavior, without requiring explicit behavioral annotations\nduring training. Code will be available upon publication.",
      "tldr_zh": "本研究探讨了视觉处理自然刺激与内部脑状态在神经元种群间的互动，提出一个概率模型（probabilistic model），该模型预测神经元响应的联合分布，包括naturalistic video stimuli和stimulus-independent latent factors，以填补动态编码模型的空白。实验在小鼠V1 neuronal responses上进行，结果显示，该模型在log-likelihood上优于仅基于视频的模型，并在条件概率和相关性方面表现出改进。进一步分析发现，学到的潜在因素与小鼠行为强烈相关，并与神经元在视觉皮层的空间位置相关，尽管训练时未使用行为数据或皮层坐标。这些发现表明，无监督学习（unsupervised learning）可以揭示连接感觉处理和行为的生物学结构，而无需显式行为注释。",
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16136v2",
      "published_date": "2024-10-21 16:01:39 UTC",
      "updated_date": "2025-03-11 18:54:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:21:25.865763"
    },
    {
      "arxiv_id": "2410.16135v2",
      "title": "Beyond 2:4: exploring V:N:M sparsity for efficient transformer inference on GPUs",
      "title_zh": "翻译失败",
      "authors": [
        "Kang Zhao",
        "Tao Yuan",
        "Han Bao",
        "Zhenfeng Su",
        "Chang Gao",
        "Zhaofeng Sun",
        "Zichen Liang",
        "Liping Jing",
        "Jianfei Chen"
      ],
      "abstract": "To date, 2:4 sparsity has stood as the only sparse pattern that can be\naccelerated using sparse tensor cores on GPUs. In practice, 2:4 sparsity often\npossesses low actual speedups ($\\leq 1.3$) and requires fixed sparse ratios,\nmeaning that other ratios, such as 4:8, 8:16, or those exceeding 50% sparsity,\ndo not incur any speedups on GPUs. Recent studies suggest that V:N:M sparsity\nis promising in addressing these limitations of 2:4 sparsity. However,\nregarding accuracy, the effects of V:N:M sparsity on broader Transformer\nmodels, such as vision Transformers and large language models (LLMs), are\nlargely unexamined. Moreover, Some specific issues related to V:N:M sparsity,\nsuch as how to select appropriate V and M values, remain unresolved. In this\nstudy, we thoroughly investigate the application of V:N:M sparsity in vision\nmodels and LLMs across multiple tasks, from pertaining to downstream tasks. We\npropose three key approaches to enhance the applicability and accuracy of\nV:N:M-sparse Transformers, including heuristic V and M selection,\nV:N:M-specific channel permutation, and three-staged LoRA training techniques.\nExperimental results show that, with our methods, the DeiT-small achieves\nlossless accuracy at 64:2:5 sparsity, while the DeiT-base maintains accuracy\neven at 64:2:8 sparsity. In addition, the fine-tuned LLama2-7B at 64:2:5\nsparsity performs comparably or better than training-free 2:4 sparse\nalternatives on downstream tasks. More importantly, V:N:M-sparse Transformers\noffer a wider range of speedup-accuracy trade-offs compared to 2:4 sparsity.\nOverall, our exploration largely facilitates the V:N:M sparsity to act as a\ntruly effective acceleration solution for Transformers in cost-sensitive\ninference scenarios.",
      "tldr_zh": "该研究探讨了 V:N:M sparsity 作为一种超越 2:4 sparsity 的方法，以提升 Transformer 模型在 GPU 上的高效推理，解决后者在加速效果（≤1.3）和固定稀疏比率的局限性。论文提出了三项关键技术：启发式 V 和 M 值选择、V:N:M 特定的通道置换，以及三阶段 LoRA 训练，以优化 V:N:M sparsity 在视觉 Transformer 和大型语言模型（如 LLMs）中的适用性和准确性。实验结果显示，DeiT-small 在 64:2:5 sparsity 下实现无损准确率，DeiT-base 在 64:2:8 sparsity 下保持性能，而微调的 Llama2-7B 在 64:2:5 sparsity 下表现不逊于或优于 2:4 稀疏方案。总体上，V:N:M sparsity 提供更灵活的速度-准确率权衡，成为 Transformer 在成本敏感推理场景中的有效加速解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16135v2",
      "published_date": "2024-10-21 16:00:04 UTC",
      "updated_date": "2025-02-09 03:48:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:21:39.735145"
    },
    {
      "arxiv_id": "2410.16132v1",
      "title": "A Data-driven Crowd Simulation Framework Integrating Physics-informed Machine Learning with Navigation Potential Fields",
      "title_zh": "翻译失败",
      "authors": [
        "Runkang Guo",
        "Bin Chen",
        "Qi Zhang",
        "Yong Zhao",
        "Xiao Wang",
        "Zhengqiu Zhu"
      ],
      "abstract": "Traditional rule-based physical models are limited by their reliance on\nsingular physical formulas and parameters, making it difficult to effectively\ntackle the intricate tasks associated with crowd simulation. Recent research\nhas introduced deep learning methods to tackle these issues, but most current\napproaches focus primarily on generating pedestrian trajectories, often lacking\ninterpretability and failing to provide real-time dynamic simulations.To\naddress the aforementioned issues, we propose a novel data-driven crowd\nsimulation framework that integrates Physics-informed Machine Learning (PIML)\nwith navigation potential fields. Our approach leverages the strengths of both\nphysical models and PIML. Specifically, we design an innovative\nPhysics-informed Spatio-temporal Graph Convolutional Network (PI-STGCN) as a\ndata-driven module to predict pedestrian movement trends based on crowd\nspatio-temporal data. Additionally, we construct a physical model of navigation\npotential fields based on flow field theory to guide pedestrian movements,\nthereby reinforcing physical constraints during the simulation. In our\nframework, navigation potential fields are dynamically computed and updated\nbased on the movement trends predicted by the PI-STGCN, while the updated crowd\ndynamics, guided by these fields, subsequently feed back into the PI-STGCN.\nComparative experiments on two publicly available large-scale real-world\ndatasets across five scenes demonstrate that our proposed framework outperforms\nexisting rule-based methods in accuracy and fidelity. The similarity between\nsimulated and actual pedestrian trajectories increases by 10.8%, while the\naverage error is reduced by 4%. Moreover, our framework exhibits greater\nadaptability and better interpretability compared to methods that rely solely\non deep learning for trajectory generation.",
      "tldr_zh": "本文提出一个数据驱动的人群模拟框架，将 Physics-informed Machine Learning (PIML) 与 navigation potential fields 整合，旨在克服传统规则-based 模型的局限性和深度学习方法的解释性不足。框架的核心是设计 Physics-informed Spatio-temporal Graph Convolutional Network (PI-STGCN) 来预测行人运动趋势，并结合基于 flow field theory 的 navigation potential fields 动态引导运动，实现相互反馈的物理约束。在两个大型真实数据集的五个场景实验中，该框架比现有方法提高轨迹相似度 10.8%，减少平均错误 4%，并展现出更高的适应性和可解释性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16132v1",
      "published_date": "2024-10-21 15:56:17 UTC",
      "updated_date": "2024-10-21 15:56:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:21:52.200573"
    },
    {
      "arxiv_id": "2410.16128v1",
      "title": "SMART: Self-learning Meta-strategy Agent for Reasoning Tasks",
      "title_zh": "SMART：自学习元策略代理用于推理任务",
      "authors": [
        "Rongxing Liu",
        "Kumar Shridhar",
        "Manish Prajapat",
        "Patrick Xia",
        "Mrinmaya Sachan"
      ],
      "abstract": "Tasks requiring deductive reasoning, especially those involving multiple\nsteps, often demand adaptive strategies such as intermediate generation of\nrationales or programs, as no single approach is universally optimal. While\nLanguage Models (LMs) can enhance their outputs through iterative\nself-refinement and strategy adjustments, they frequently fail to apply the\nmost effective strategy in their first attempt. This inefficiency raises the\nquestion: Can LMs learn to select the optimal strategy in the first attempt,\nwithout a need for refinement? To address this challenge, we introduce SMART\n(Self-learning Meta-strategy Agent for Reasoning Tasks), a novel framework that\nenables LMs to autonomously learn and select the most effective strategies for\nvarious reasoning tasks. We model the strategy selection process as a Markov\nDecision Process and leverage reinforcement learning-driven continuous\nself-improvement to allow the model to find the suitable strategy to solve a\ngiven task. Unlike traditional self-refinement methods that rely on multiple\ninference passes or external feedback, SMART allows an LM to internalize the\noutcomes of its own reasoning processes and adjust its strategy accordingly,\naiming for correct solutions on the first attempt. Our experiments across\nvarious reasoning datasets and with different model architectures demonstrate\nthat SMART significantly enhances the ability of models to choose optimal\nstrategies without external guidance (+15 points on the GSM8K dataset). By\nachieving higher accuracy with a single inference pass, SMART not only improves\nperformance but also reduces computational costs for refinement-based\nstrategies, paving the way for more efficient and intelligent reasoning in LMs.",
      "tldr_zh": "该论文引入了 SMART（Self-learning Meta-strategy Agent for Reasoning Tasks）框架，帮助语言模型（LMs）在多步推理任务中自主学习并选择最有效的策略，从而避免首次尝试失败的问题。SMART 将策略选择建模为 Markov Decision Process，并通过强化学习驱动的连续自改进机制，让模型内部化推理过程，实现单次推理的正确解决方案。实验结果显示，该框架在各种推理数据集上显著提升了模型性能，例如在 GSM8K 数据集上准确率提高 15 分，同时降低了计算成本，为更高效的 LMs 推理铺平了道路。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16128v1",
      "published_date": "2024-10-21 15:55:04 UTC",
      "updated_date": "2024-10-21 15:55:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:22:03.338080"
    },
    {
      "arxiv_id": "2410.16119v1",
      "title": "SeaDAG: Semi-autoregressive Diffusion for Conditional Directed Acyclic Graph Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyi Zhou",
        "Xing Li",
        "Yingzhao Lian",
        "Yiwen Wang",
        "Lei Chen",
        "Mingxuan Yuan",
        "Jianye Hao",
        "Guangyong Chen",
        "Pheng Ann Heng"
      ],
      "abstract": "We introduce SeaDAG, a semi-autoregressive diffusion model for conditional\ngeneration of Directed Acyclic Graphs (DAGs). Considering their inherent\nlayer-wise structure, we simulate layer-wise autoregressive generation by\ndesigning different denoising speed for different layers. Unlike conventional\nautoregressive generation that lacks a global graph structure view, our method\nmaintains a complete graph structure at each diffusion step, enabling\noperations such as property control that require the full graph structure.\nLeveraging this capability, we evaluate the DAG properties during training by\nemploying a graph property decoder. We explicitly train the model to learn\ngraph conditioning with a condition loss, which enhances the diffusion model's\ncapacity to generate graphs that are both realistic and aligned with specified\nproperties. We evaluate our method on two representative conditional DAG\ngeneration tasks: (1) circuit generation from truth tables, where precise DAG\nstructures are crucial for realizing circuit functionality, and (2) molecule\ngeneration based on quantum properties. Our approach demonstrates promising\nresults, generating high-quality and realistic DAGs that closely align with\ngiven conditions.",
      "tldr_zh": "该研究提出 SeaDAG，一种半自回归扩散模型，用于条件生成 Directed Acyclic Graphs (DAGs)，通过为不同层设计不同的去噪速度来模拟层级自回归生成，同时保持每个扩散步骤的完整图结构，支持属性控制操作。模型在训练中采用图属性解码器评估 DAG 属性，并通过条件损失显式优化生成过程，确保生成的图既真实又符合指定条件。在电路生成（从真值表）和分子生成（基于量子属性）等任务上，SeaDAG 表现出色，生成高质量的 DAGs。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16119v1",
      "published_date": "2024-10-21 15:47:03 UTC",
      "updated_date": "2024-10-21 15:47:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:22:16.539861"
    },
    {
      "arxiv_id": "2410.16116v1",
      "title": "Multimodal Flare Forecasting with Deep Learning",
      "title_zh": "多模态耀斑预测使用深度学习",
      "authors": [
        "Grégoire Francisco",
        "Sabrina Guastavino",
        "Teresa Barata",
        "João Fernandes",
        "Dario Del Moro"
      ],
      "abstract": "Solar flare forecasting mainly relies on photospheric magnetograms and\nassociated physical features to predict forthcoming flares. However, it is\nbelieved that flare initiation mechanisms often originate in the chromosphere\nand the lower corona. In this study, we employ deep learning as a purely\ndata-driven approach to compare the predictive capabilities of chromospheric\nand coronal UV and EUV emissions across different wavelengths with those of\nphotospheric line-of-sight magnetograms. Our findings indicate that individual\nEUV wavelengths can provide discriminatory power comparable or better to that\nof line-of-sight magnetograms. Moreover, we identify simple multimodal neural\nnetwork architectures that consistently outperform single-input models, showing\ncomplementarity between the flare precursors that can be extracted from the\ndistinct layers of the solar atmosphere. To mitigate potential biases from\nknown misattributions in Active Region flare catalogs, our models are trained\nand evaluated using full-disk images and a comprehensive flare event catalog at\nthe full-disk level. We introduce a deep-learning architecture suited for\nextracting temporal features from full-disk videos.",
      "tldr_zh": "该研究使用深度学习作为数据驱动方法，比较色球层和日冕的UV和EUV发射与光球层磁图在太阳耀斑预测中的能力，发现单个EUV波长可提供与磁图相当或更好的区分性能。\n多模态神经网络架构表现出色，能从不同太阳大气层的耀斑前驱指标中提取互补信息，从而优于单输入模型。\n为避免活跃区域目录偏差，模型采用全盘图像和全盘级别耀斑事件目录进行训练和评估，并引入了适合提取时间特征的深度学习架构。",
      "categories": [
        "astro-ph.SR",
        "astro-ph.IM",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "astro-ph.SR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16116v1",
      "published_date": "2024-10-21 15:42:47 UTC",
      "updated_date": "2024-10-21 15:42:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:22:27.183586"
    },
    {
      "arxiv_id": "2410.16105v1",
      "title": "Addressing Spectral Bias of Deep Neural Networks by Multi-Grade Deep Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Ronglong Fang",
        "Yuesheng Xu"
      ],
      "abstract": "Deep neural networks (DNNs) suffer from the spectral bias, wherein DNNs\ntypically exhibit a tendency to prioritize the learning of lower-frequency\ncomponents of a function, struggling to capture its high-frequency features.\nThis paper is to address this issue. Notice that a function having only low\nfrequency components may be well-represented by a shallow neural network (SNN),\na network having only a few layers. By observing that composition of low\nfrequency functions can effectively approximate a high-frequency function, we\npropose to learn a function containing high-frequency components by composing\nseveral SNNs, each of which learns certain low-frequency information from the\ngiven data. We implement the proposed idea by exploiting the multi-grade deep\nlearning (MGDL) model, a recently introduced model that trains a DNN\nincrementally, grade by grade, a current grade learning from the residue of the\nprevious grade only an SNN composed with the SNNs trained in the preceding\ngrades as features. We apply MGDL to synthetic, manifold, colored images, and\nMNIST datasets, all characterized by presence of high-frequency features. Our\nstudy reveals that MGDL excels at representing functions containing\nhigh-frequency information. Specifically, the neural networks learned in each\ngrade adeptly capture some low-frequency information, allowing their\ncompositions with SNNs learned in the previous grades effectively representing\nthe high-frequency features. Our experimental results underscore the efficacy\nof MGDL in addressing the spectral bias inherent in DNNs. By leveraging MGDL,\nwe offer insights into overcoming spectral bias limitation of DNNs, thereby\nenhancing the performance and applicability of deep learning models in tasks\nrequiring the representation of high-frequency information. This study confirms\nthat the proposed method offers a promising solution to address the spectral\nbias of DNNs.",
      "tldr_zh": "该研究针对深度神经网络 (DNNs) 的 spectral bias 问题提出了一种 Multi-Grade Deep Learning (MGDL) 方法，该问题导致 DNNs 优先学习低频组件而难以捕捉高频特征。通过观察低频函数的组合可近似高频函数，MGDL 逐步训练多个浅层神经网络 (SNNs)，每个等级从前一等级的残差中学习特定低频信息，并通过这些 SNNs 的组合来有效表示高频特征。实验在合成数据、流形数据、彩色图像和 MNIST 数据集上验证了 MGDL 的优越性，显著提升了模型对高频信息的表示能力，从而为克服 DNNs 的 spectral bias 提供了有前景的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16105v1",
      "published_date": "2024-10-21 15:34:33 UTC",
      "updated_date": "2024-10-21 15:34:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:22:40.074092"
    },
    {
      "arxiv_id": "2410.19845v1",
      "title": "Enhancing Trust and Safety in Digital Payments: An LLM-Powered Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Devendra Dahiphale",
        "Naveen Madiraju",
        "Justin Lin",
        "Rutvik Karve",
        "Monu Agrawal",
        "Anant Modwal",
        "Ramanan Balakrishnan",
        "Shanay Shah",
        "Govind Kaushal",
        "Priya Mandawat",
        "Prakash Hariramani",
        "Arif Merchant"
      ],
      "abstract": "Digital payment systems have revolutionized financial transactions, offering\nunparalleled convenience and accessibility to users worldwide. However, the\nincreasing popularity of these platforms has also attracted malicious actors\nseeking to exploit their vulnerabilities for financial gain. To address this\nchallenge, robust and adaptable scam detection mechanisms are crucial for\nmaintaining the trust and safety of digital payment ecosystems. This paper\npresents a comprehensive approach to scam detection, focusing on the Unified\nPayments Interface (UPI) in India, Google Pay (GPay) as a specific use case.\nThe approach leverages Large Language Models (LLMs) to enhance scam\nclassification accuracy and designs a digital assistant to aid human reviewers\nin identifying and mitigating fraudulent activities. The results demonstrate\nthe potential of LLMs in augmenting existing machine learning models and\nimproving the efficiency, accuracy, quality, and consistency of scam reviews,\nultimately contributing to a safer and more secure digital payment landscape.\nOur evaluation of the Gemini Ultra model on curated transaction data showed a\n93.33% accuracy in scam classification. Furthermore, the model demonstrated 89%\naccuracy in generating reasoning for these classifications. A promising fact,\nthe model identified 32% new accurate reasons for suspected scams that human\nreviewers had not included in the review notes.",
      "tldr_zh": "这篇论文提出了一种基于 Large Language Models (LLMs) 的方法，以提升数字支付系统的信任和安全，针对印度的 Unified Payments Interface (UPI) 和 Google Pay (GPay) 作为用例。方法包括利用 LLMs 增强欺诈分类准确性，并设计一个数字助手辅助人类审查员识别和缓解欺诈活动。实验结果显示，Gemini Ultra 模型在分类任务中达到 93.33% 的准确率，并在生成推理方面达到 89% 的准确率，还发现了 32% 的新欺诈原因，这些是人类审查员未包含的。该方法有助于提高欺诈检测的效率、准确性和一致性，从而构建更安全的数字支付生态。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CE",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "10 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.19845v1",
      "published_date": "2024-10-21 15:21:11 UTC",
      "updated_date": "2024-10-21 15:21:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:22:51.438203"
    },
    {
      "arxiv_id": "2410.16091v1",
      "title": "Neural Quantum Propagators for Driven-Dissipative Quantum Dynamics",
      "title_zh": "神经",
      "authors": [
        "Jiaji Zhang",
        "Carlos L. Benavides-Riveros",
        "Lipeng Chen"
      ],
      "abstract": "Describing the dynamics of strong-laser driven open quantum systems is a very\nchallenging task that requires the solution of highly involved equations of\nmotion. While machine learning techniques are being applied with some success\nto simulate the time evolution of individual quantum states, their use to\napproximate time-dependent operators (that can evolve various states) remains\nlargely unexplored. In this work, we develop driven neural quantum propagators\n(NQP), a universal neural network framework that solves driven-dissipative\nquantum dynamics by approximating propagators rather than wavefunctions or\ndensity matrices. NQP can handle arbitrary initial quantum states, adapt to\nvarious external fields, and simulate long-time dynamics, even when trained on\nfar shorter time windows. Furthermore, by appropriately configuring the\nexternal fields, our trained NQP can be transferred to systems governed by\ndifferent Hamiltonians. We demonstrate the effectiveness of our approach by\nstudying the spin-boson and the three-state transition Gamma models.",
      "tldr_zh": "该研究针对强激光驱动的开放量子系统动态模拟面临的挑战，提出了一种新型框架：Neural Quantum Propagators (NQP)，通过神经网络近似传播子而非波函数或密度矩阵，来高效解决driven-dissipative quantum dynamics。NQP 能够处理任意初始量子态、适应各种外部场，并实现长时动态模拟，即使基于较短训练窗口；此外，通过配置外部场，它还能转移应用于不同哈密顿量控制的系统。研究通过spin-boson和three-state transition Gamma模型的实验验证了NQP的有效性，展示了其在量子动态模拟中的潜力。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "physics.chem-ph"
      ],
      "primary_category": "quant-ph",
      "comment": "7 pages, comment are welcome!",
      "pdf_url": "http://arxiv.org/pdf/2410.16091v1",
      "published_date": "2024-10-21 15:13:17 UTC",
      "updated_date": "2024-10-21 15:13:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:23:03.599689"
    },
    {
      "arxiv_id": "2410.16089v1",
      "title": "Multi-Sensor Fusion for UAV Classification Based on Feature Maps of Image and Radar Data",
      "title_zh": "基于图像和雷达数据特征图的多传感器融合 UAV 分类方法",
      "authors": [
        "Nikos Sakellariou",
        "Antonios Lalas",
        "Konstantinos Votis",
        "Dimitrios Tzovaras"
      ],
      "abstract": "The unique cost, flexibility, speed, and efficiency of modern UAVs make them\nan attractive choice in many applications in contemporary society. This,\nhowever, causes an ever-increasing number of reported malicious or accidental\nincidents, rendering the need for the development of UAV detection and\nclassification mechanisms essential. We propose a methodology for developing a\nsystem that fuses already processed multi-sensor data into a new Deep Neural\nNetwork to increase its classification accuracy towards UAV detection. The DNN\nmodel fuses high-level features extracted from individual object detection and\nclassification models associated with thermal, optronic, and radar data.\nAdditionally, emphasis is given to the model's Convolutional Neural Network\n(CNN) based architecture that combines the features of the three sensor\nmodalities by stacking the extracted image features of the thermal and optronic\nsensor achieving higher classification accuracy than each sensor alone.",
      "tldr_zh": "本文提出了一种多传感器融合方法，用于提高无人机（UAV）检测和分类的准确性，针对热成像、optronic 和雷达数据的高级特征进行整合。方法基于一个新的深度神经网络（DNN）模型，利用卷积神经网络（CNN）架构，通过堆叠热成像和optronic 传感器的特征地图来融合三种传感器模态。实验结果表明，该系统在UAV分类任务中比单一传感器表现出更高的准确率，为UAV检测机制提供了更可靠的解决方案。",
      "categories": [
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.16089v1",
      "published_date": "2024-10-21 15:12:37 UTC",
      "updated_date": "2024-10-21 15:12:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:23:15.373824"
    },
    {
      "arxiv_id": "2410.16088v1",
      "title": "Fine-Tuning LLMs for Reliable Medical Question-Answering Services",
      "title_zh": "翻译失败",
      "authors": [
        "Ali Anaissi",
        "Ali Braytee",
        "Junaid Akram"
      ],
      "abstract": "We present an advanced approach to medical question-answering (QA) services,\nusing fine-tuned Large Language Models (LLMs) to improve the accuracy and\nreliability of healthcare information. Our study focuses on optimizing models\nlike LLaMA-2 and Mistral, which have shown great promise in delivering precise,\nreliable medical answers. By leveraging comprehensive datasets, we applied\nfine-tuning techniques such as rsDoRA+ and ReRAG. rsDoRA+ enhances model\nperformance through a combination of decomposed model weights, varied learning\nrates for low-rank matrices, and rank stabilization, leading to improved\nefficiency. ReRAG, which integrates retrieval on demand and question rewriting,\nfurther refines the accuracy of the responses. This approach enables healthcare\nproviders to access fast, dependable information, aiding in more efficient\ndecision-making and fostering greater patient trust. Our work highlights the\npotential of fine-tuned LLMs to significantly improve the quality and\naccessibility of medical information services, ultimately contributing to\nbetter healthcare outcomes for all.",
      "tldr_zh": "本研究提出了一种通过微调大型语言模型(LLMs)来提升医疗问答(QA)服务准确性和可靠性的高级方法，针对 LLaMA-2 和 Mistral 模型进行优化。采用 rsDoRA+ 和 ReRAG 技术，其中 rsDoRA+ 通过分解模型权重、动态学习率和秩稳定提升模型效率，ReRAG 则整合按需检索和问题重写以提高响应精度。该方法利用全面数据集，帮助医疗提供者快速获取可靠信息，支持高效决策和患者信任，最终改善医疗服务质量和可访问性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 10 figures, accepted and to be published in the proceedings\n  of 2024 IEEE International Conference on Data Mining Workshops (ICDMW)",
      "pdf_url": "http://arxiv.org/pdf/2410.16088v1",
      "published_date": "2024-10-21 15:12:20 UTC",
      "updated_date": "2024-10-21 15:12:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:23:27.428919"
    },
    {
      "arxiv_id": "2410.16083v1",
      "title": "Critical Example Mining for Vehicle Trajectory Prediction using Flow-based Generative Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zhezhang Ding",
        "Huijing Zhao"
      ],
      "abstract": "Precise trajectory prediction in complex driving scenarios is essential for\nautonomous vehicles. In practice, different driving scenarios present varying\nlevels of difficulty for trajectory prediction models. However, most existing\nresearch focuses on the average precision of prediction results, while ignoring\nthe underlying distribution of the input scenarios. This paper proposes a\ncritical example mining method that utilizes a data-driven approach to estimate\nthe rareness of the trajectories. By combining the rareness estimation of\nobservations with whole trajectories, the proposed method effectively\nidentifies a subset of data that is relatively hard to predict BEFORE feeding\nthem to a specific prediction model. The experimental results show that the\nmined subset has higher prediction error when applied to different downstream\nprediction models, which reaches +108.1% error (greater than two times compared\nto the average on dataset) when mining 5% samples. Further analysis indicates\nthat the mined critical examples include uncommon cases such as sudden brake\nand cancelled lane-change, which helps to better understand and improve the\nperformance of prediction models.",
      "tldr_zh": "这篇论文提出了 critical example mining 方法，用于车辆 trajectory prediction，利用 flow-based generative models 通过数据驱动的方式估计轨迹的稀有度，从而在模型输入前识别难以预测的数据子集。方法结合观察和整体轨迹的稀有度评估，能有效筛选出复杂驾驶场景中的关键样本。实验结果显示，挖掘的子集在不同下游预测模型上错误率显著增加，例如挖掘5%样本时错误率提升108.1%；进一步分析揭示了这些样本包括突发制动和取消变道等不常见情况，这有助于提升模型的理解和性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages,6 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.16083v1",
      "published_date": "2024-10-21 15:02:30 UTC",
      "updated_date": "2024-10-21 15:02:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:23:39.222780"
    },
    {
      "arxiv_id": "2410.16070v2",
      "title": "On-Device LLMs for SMEs: Challenges and Opportunities",
      "title_zh": "设备端 LLMs 针对 SMEs：挑战与机会",
      "authors": [
        "Jeremy Stephen Gabriel Yee",
        "Pai Chet Ng",
        "Zhengkui Wang",
        "Ian McLoughlin",
        "Aik Beng Ng",
        "Simon See"
      ],
      "abstract": "This paper presents a systematic review of the infrastructure requirements\nfor deploying Large Language Models (LLMs) on-device within the context of\nsmall and medium-sized enterprises (SMEs), focusing on both hardware and\nsoftware perspectives. From the hardware viewpoint, we discuss the utilization\nof processing units like GPUs and TPUs, efficient memory and storage solutions,\nand strategies for effective deployment, addressing the challenges of limited\ncomputational resources typical in SME settings. From the software perspective,\nwe explore framework compatibility, operating system optimization, and the use\nof specialized libraries tailored for resource-constrained environments. The\nreview is structured to first identify the unique challenges faced by SMEs in\ndeploying LLMs on-device, followed by an exploration of the opportunities that\nboth hardware innovations and software adaptations offer to overcome these\nobstacles. Such a structured review provides practical insights, contributing\nsignificantly to the community by enhancing the technological resilience of\nSMEs in integrating LLMs.",
      "tldr_zh": "本论文通过系统综述探讨了在中小企业（SMEs）环境中部署大型语言模型（LLMs）到设备上的基础设施需求，重点分析硬件和软件方面的挑战与机会。从硬件角度，该文讨论了利用GPUs和TPUs等处理单位、优化内存和存储解决方案，以及应对计算资源有限的部署策略。从软件角度，则考察了框架兼容性、操作系统优化以及针对资源受限环境的专用库。论文首先识别SMEs面临的独特挑战，如计算资源不足，然后探索硬件创新和软件适配的机会，以提升技术韧性。该综述提供实用见解，帮助SMEs更好地集成LLMs，实现自主部署。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "68T07",
        "I.2"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 1 figure. The work is supported by the SIT-NVIDIA Joint AI\n  Centre",
      "pdf_url": "http://arxiv.org/pdf/2410.16070v2",
      "published_date": "2024-10-21 14:48:35 UTC",
      "updated_date": "2024-10-22 13:40:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:25:44.504542"
    },
    {
      "arxiv_id": "2410.16063v1",
      "title": "Integrated Image-Text Based on Semi-supervised Learning for Small Sample Instance Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Ruting Chi",
        "Zhiyi Huang",
        "Yuexing Han"
      ],
      "abstract": "Small sample instance segmentation is a very challenging task, and many\nexisting methods follow the training strategy of meta-learning which pre-train\nmodels on support set and fine-tune on query set. The pre-training phase, which\nis highly task related, requires a significant amount of additional training\ntime and the selection of datasets with close proximity to ensure\neffectiveness. The article proposes a novel small sample instance segmentation\nsolution from the perspective of maximizing the utilization of existing\ninformation without increasing annotation burden and training costs. The\nproposed method designs two modules to address the problems encountered in\nsmall sample instance segmentation. First, it helps the model fully utilize\nunlabeled data by learning to generate pseudo labels, increasing the number of\navailable samples. Second, by integrating the features of text and image, more\naccurate classification results can be obtained. These two modules are suitable\nfor box-free and box-dependent frameworks. In the way, the proposed method not\nonly improves the performance of small sample instance segmentation, but also\ngreatly reduce reliance on pre-training. We have conducted experiments in three\ndatasets from different scenes: on land, underwater and under microscope. As\nevidenced by our experiments, integrated image-text corrects the confidence of\nclassification, and pseudo labels help the model obtain preciser masks. All the\nresults demonstrate the effectiveness and superiority of our method.",
      "tldr_zh": "该论文针对小样本实例分割的挑战，提出了一种基于 semi-supervised learning 的新方法，通过最大化现有信息利用来减少标注负担和训练成本。方法设计了两个关键模块：一是学习生成伪标签以利用未标注数据增加样本数量；二是整合图像和文本特征，以提升分类准确性和掩码精度。这些模块适用于无框和有框框架，并在陆地、水下和显微镜下的三个数据集上实验验证，显示出显著性能提升和对预训练依赖的降低。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16063v1",
      "published_date": "2024-10-21 14:44:08 UTC",
      "updated_date": "2024-10-21 14:44:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:24:03.687089"
    },
    {
      "arxiv_id": "2410.16347v1",
      "title": "Domain-Adaptive Neural Posterior Estimation for Strong Gravitational Lens Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Paxson Swierc",
        "Marcos Tamargo-Arizmendi",
        "Aleksandra Ćiprijanović",
        "Brian D. Nord"
      ],
      "abstract": "Modeling strong gravitational lenses is prohibitively expensive for modern\nand next-generation cosmic survey data. Neural posterior estimation (NPE), a\nsimulation-based inference (SBI) approach, has been studied as an avenue for\nefficient analysis of strong lensing data. However, NPE has not been\ndemonstrated to perform well on out-of-domain target data -- e.g., when trained\non simulated data and then applied to real, observational data. In this work,\nwe perform the first study of the efficacy of NPE in combination with\nunsupervised domain adaptation (UDA). The source domain is noiseless, and the\ntarget domain has noise mimicking modern cosmology surveys. We find that\ncombining UDA and NPE improves the accuracy of the inference by 1-2 orders of\nmagnitude and significantly improves the posterior coverage over an NPE model\nwithout UDA. We anticipate that this combination of approaches will help enable\nfuture applications of NPE models to real observational data.",
      "tldr_zh": "本文提出了一种结合 Neural Posterior Estimation (NPE) 和 Unsupervised Domain Adaptation (UDA) 的方法，用于高效分析强引力透镜数据，以应对 NPE 在领域外数据（如模拟数据到真实观测数据）上的表现不足。方法通过 UDA 适应从无噪声源域到模拟现代宇宙学调查噪声的目标域，提高了 Simulation-Based Inference (SBI) 的鲁棒性。实验结果显示，这种结合显著提升了推理准确性 1-2 个数量级，并改善了后验覆盖率。该框架有望为未来 NPE 模型应用于真实观测数据提供关键支持。",
      "categories": [
        "astro-ph.IM",
        "astro-ph.CO",
        "astro-ph.GA",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "astro-ph.IM",
      "comment": "20 pages, 2 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.16347v1",
      "published_date": "2024-10-21 14:12:39 UTC",
      "updated_date": "2024-10-21 14:12:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:24:16.069809"
    },
    {
      "arxiv_id": "2410.16032v5",
      "title": "TimeMixer++: A General Time Series Pattern Machine for Universal Predictive Analysis",
      "title_zh": "TimeMixer++：一种用于通用预测分析的通用时间序列模式机",
      "authors": [
        "Shiyu Wang",
        "Jiawei Li",
        "Xiaoming Shi",
        "Zhou Ye",
        "Baichuan Mo",
        "Wenze Lin",
        "Shengtong Ju",
        "Zhixuan Chu",
        "Ming Jin"
      ],
      "abstract": "Time series analysis plays a critical role in numerous applications,\nsupporting tasks such as forecasting, classification, anomaly detection, and\nimputation. In this work, we present the time series pattern machine (TSPM), a\nmodel designed to excel in a broad range of time series tasks through powerful\nrepresentation and pattern extraction capabilities. Traditional time series\nmodels often struggle to capture universal patterns, limiting their\neffectiveness across diverse tasks. To address this, we define multiple scales\nin the time domain and various resolutions in the frequency domain, employing\nvarious mixing strategies to extract intricate, task-adaptive time series\npatterns. Specifically, we introduce a general-purpose TSPM that processes\nmulti-scale time series using (1) multi-resolution time imaging (MRTI), (2)\ntime image decomposition (TID), (3) multi-scale mixing (MCM), and (4)\nmulti-resolution mixing (MRM) to extract comprehensive temporal patterns. MRTI\ntransforms multi-scale time series into multi-resolution time images, capturing\npatterns across both temporal and frequency domains. TID leverages dual-axis\nattention to extract seasonal and trend patterns, while MCM hierarchically\naggregates these patterns across scales. MRM adaptively integrates all\nrepresentations across resolutions. This method achieves state-of-the-art\nperformance across 8 time series analytical tasks, consistently surpassing both\ngeneral-purpose and task-specific models. Our work marks a promising step\ntoward the next generation of TSPMs, paving the way for further advancements in\ntime series analysis.",
      "tldr_zh": "该论文提出 TimeMixer++（即时间序列模式机器，TSPM），一个通用模型，旨在通过强大的表示和模式提取能力，提升时间序列分析任务如预测、分类、异常检测和插值的性能。模型通过定义时间域的多尺度与频率域的多分辨率，并采用多种混合策略，包括 multi-resolution time imaging (MRTI)、time image decomposition (TID)、multi-scale mixing (MCM) 和 multi-resolution mixing (MRM)，来提取复杂的任务自适应模式。实验结果显示，TimeMixer++ 在 8 个时间序列分析任务中超越了通用和任务特定模型，达到了最先进性能，为下一代 TSPM 的发展奠定了基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by the 13th International Conference on Learning\n  Representations (ICLR 2025)",
      "pdf_url": "http://arxiv.org/pdf/2410.16032v5",
      "published_date": "2024-10-21 14:06:53 UTC",
      "updated_date": "2025-05-19 04:16:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:24:27.588834"
    },
    {
      "arxiv_id": "2410.16024v3",
      "title": "SMAC-R1: The Emergence of Intelligence in Decision-Making Tasks",
      "title_zh": "SMAC-R1：智能在决策任务中的涌现",
      "authors": [
        "Yue Deng",
        "Weiyu Ma",
        "Yuxin Fan",
        "Ruyi Song",
        "Yin Zhang",
        "Haifeng Zhang",
        "Jian Zhao"
      ],
      "abstract": "StarCraft Multi-Agent Challenge (SMAC) has been one of the most commonly used\nexperimental environments in multi-agent reinforcement learning (MARL), where\nthe specific task is to control a set number of allied units to defeat enemy\nforces. Traditional MARL algorithms often require interacting with the\nenvironment for millions of steps to train a parametric model, of which the\nresulting policies are typically non-interpretable with weak transferability.\nIn this paper, we introduce SMAC-R1 which is based on the Qwen2.5-7B-Base LLM\ndistilled from DeepSeek-Coder-v2.5-236B. Similar to online reinforcement\nlearning after behavior cloning in offline learning process, in our pipeline,\nagents leverage the DeepSeek LLM to generate decision tree code by providing\ntask descriptions, and the agents are further self-reflected using feedback\nfrom the rewards provided by the environment. Based on that, we augment the\ngenerated scripts to fine-tune a small LLM, Qwen2.5-7B-Base, to distill the\ndecision-making ability via Supervised Fine-Tuning (SFT) and enhance the script\ngeneration ability by the Group Relative Policy Optimization (GRPO) algorithm.\nWe conduct experiments in the original 23 SMAC tasks and 10 newly-designed\ntasks to demonstrate that our method can produce high-quality, interpretable\ndecision trees with minimal environmental exploration. Moreover, these scripts\nexhibit strong transferability, successfully applying to homogeneous SMAC\nenvironments without modification. We believe this approach offers a new\ndirection for solving decision-making tasks and domain-specific LLM training\npipelines in the future.",
      "tldr_zh": "本论文引入 SMAC-R1，这是一种基于大型语言模型(LLM)的框架，旨在解决多智能体强化学习(MARL)中传统算法的非解释性和弱转移性问题。方法包括利用 DeepSeek-Coder-v2.5-236B 生成决策树代码，通过环境反馈进行自反，并微调 Qwen2.5-7B-Base 模型 via Supervised Fine-Tuning (SFT) 和 Group Relative Policy Optimization (GRPO)，从而以最小环境探索实现高效决策。实验在 23 个原 SMAC 任务和 10 个新任务上证明，该方法能产生高质量、可解释的决策树，并展示出强转移性，可直接应用于同类环境。该框架为未来决策任务和领域特定 LLM 训练管道提供了新方向。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16024v3",
      "published_date": "2024-10-21 13:58:38 UTC",
      "updated_date": "2025-03-06 05:38:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:24:41.084831"
    },
    {
      "arxiv_id": "2410.16012v1",
      "title": "Massimo: Public Queue Monitoring and Management using Mass-Spring Model",
      "title_zh": "Massimo：使用质量-弹簧模型的公共队列监控和管理",
      "authors": [
        "Abhijeet Kumar",
        "Unnati Singh",
        "Rajdeep Chatterjee",
        "Tathagata Bandyopadhyay"
      ],
      "abstract": "An efficient system of a queue control and regulation in public spaces is\nvery important in order to avoid the traffic jams and to improve the customer\nsatisfaction. This article offers a detailed road map based on a merger of\nintelligent systems and creating an efficient systems of queues in public\nplaces. Through the utilization of different technologies i.e. computer vision,\nmachine learning algorithms, deep learning our system provide accurate\ninformation about the place is crowded or not and the necessary efforts to be\ntaken.",
      "tldr_zh": "这篇文章介绍了 Massimo 系统，一种基于 Mass-Spring Model 的智能框架，用于公共场所的队列监控和管理，以避免交通拥堵并提升客户满意度。系统整合了 computer vision、machine learning algorithms 和 deep learning 等技术，实时提供场所是否拥挤的准确信息，并建议必要的应对措施。通过这种方法，Massimo 为高效的队列控制提供了详细的路线图。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "stat.AP"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 6 figures, 3 algorithms, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.16012v1",
      "published_date": "2024-10-21 13:43:02 UTC",
      "updated_date": "2024-10-21 13:43:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:24:51.031013"
    },
    {
      "arxiv_id": "2410.16011v1",
      "title": "CA*: Addressing Evaluation Pitfalls in Computation-Aware Latency for Simultaneous Speech Translation",
      "title_zh": "翻译失败",
      "authors": [
        "Xi Xu",
        "Wenda Xu",
        "Siqi Ouyang",
        "Lei Li"
      ],
      "abstract": "Simultaneous speech translation (SimulST) systems must balance translation\nquality with response time, making latency measurement crucial for evaluating\ntheir real-world performance. However, there has been a longstanding belief\nthat current metrics yield unrealistically high latency measurements in\nunsegmented streaming settings. In this paper, we investigate this phenomenon,\nrevealing its root cause in a fundamental misconception underlying existing\nlatency evaluation approaches. We demonstrate that this issue affects not only\nstreaming but also segment-level latency evaluation across different metrics.\nFurthermore, we propose a modification to correctly measure computation-aware\nlatency for SimulST systems, addressing the limitations present in existing\nmetrics.",
      "tldr_zh": "这篇论文探讨了同时语音翻译 (SimulST) 系统在评估延迟时存在的关键问题，即现有指标往往导致不现实的高延迟测量，尤其在未分段的流式场景中。研究者通过调查揭示了这一现象的根源：评估方法中的一个基本误解，该问题不仅影响流式评估，还扩展到不同指标的段级延迟测量。论文提出了一种修改方案，用于正确测量 Computation-Aware Latency，从而解决现有指标的局限性，并提升 SimulST 系统的真实性能评估。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.16011v1",
      "published_date": "2024-10-21 13:42:19 UTC",
      "updated_date": "2024-10-21 13:42:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:25:02.718073"
    },
    {
      "arxiv_id": "2410.16008v1",
      "title": "Resilient Temporal GCN for Smart Grid State Estimation Under Topology Inaccuracies",
      "title_zh": "翻译失败",
      "authors": [
        "Seyed Hamed Haghshenas",
        "Mia Naeini"
      ],
      "abstract": "State Estimation is a crucial task in power systems. Graph Neural Networks\nhave demonstrated significant potential in state estimation for power systems\nby effectively analyzing measurement data and capturing the complex\ninteractions and interrelations among the measurements through the system's\ngraph structure. However, the information about the system's graph structure\nmay be inaccurate due to noise, attack or lack of accurate information about\nthe topology of the system. This paper studies these scenarios under topology\nuncertainties and evaluates the impact of the topology uncertainties on the\nperformance of a Temporal Graph Convolutional Network (TGCN) for state\nestimation in power systems. In order to make the model resilient to topology\nuncertainties, modifications in the TGCN model are proposed to incorporate a\nknowledge graph, generated based on the measurement data. This knowledge graph\nsupports the assumed uncertain system graph. Two variations of the TGCN\narchitecture are introduced to integrate the knowledge graph, and their\nperformances are evaluated and compared to demonstrate improved resilience\nagainst topology uncertainties. The evaluation results indicate that while the\ntwo proposed architecture show different performance, they both improve the\nperformance of the TGCN state estimation under topology uncertainties.",
      "tldr_zh": "本论文探讨了拓扑不确定性（如噪声、攻击或信息缺失）对Temporal Graph Convolutional Network (TGCN)在智能电网状态估计中的影响，强调了图神经网络在分析测量数据和捕捉系统交互方面的潜力。作者提出修改TGCN模型，通过融入基于测量数据的knowledge graph来增强模型的弹性，并引入两个TGCN架构变体来整合该知识图。实验结果显示，这两个变体均显著提高了TGCN在拓扑不确定性下的性能，尽管表现有所差异。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "9 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.16008v1",
      "published_date": "2024-10-21 13:41:27 UTC",
      "updated_date": "2024-10-21 13:41:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:25:15.638768"
    },
    {
      "arxiv_id": "2410.16007v2",
      "title": "Language Model Probabilities are Not Calibrated in Numeric Contexts",
      "title_zh": "语言模型概率在数值上下文中未校准",
      "authors": [
        "Charles Lovering",
        "Michael Krumdick",
        "Viet Dac Lai",
        "Seth Ebner",
        "Nilesh Kumar",
        "Varshini Reddy",
        "Rik Koncel-Kedziorski",
        "Chris Tanner"
      ],
      "abstract": "Some statements have one well-defined continuation (e.g., \"the Eiffel Tower\nis in [Paris]\"), whereas others have a natural distribution over multiple\noptions (e.g., \"the weighted coin flip was [Heads/Tails].\") We argue that\nlanguage model (LM) outputs should capture these natural distributions. Our\nwork specifically tests whether LM output probabilities are calibrated to\nnumeric information within their textual contexts. For example, if the context\n(the prompt) concerns two equally likely options (e.g., heads or tails for a\nfair coin), the LM output probabilities should also be equal. Likewise, in a\ncontext with nonuniformly likely events (e.g., rolling a pair with two dice) an\nLM should output proportionate probabilities. However, we find that even in\nsimple settings, the best LMs (1) are poorly calibrated and (2) have systematic\nbiases: artifacts like word identity, word order, and word frequency all impact\ncalibration. For example, gpt-4o-mini often picks the first of two options\npresented in the prompt regardless of the options' implied likelihoods, whereas\nLlama-3.1-8B picks the second. Models do not allocate probability mass among\nvalid options in a calibrated manner.",
      "tldr_zh": "本文研究发现，language model (LM) 在数值上下文中的输出概率未能实现校准，例如在处理等可能事件（如公平硬币的正反面）时，LM 应输出相等概率，但实际表现不佳。作者通过测试简单场景（如骰子投掷），评估 LM 是否能根据上下文的数值信息正确分配概率。结果显示，最先进的 LM 存在系统偏差，受单词身份、顺序和频率影响，例如 gpt-4o-mini 偏好提示中的第一个选项，而 Llama-3.1-8B 偏好第二个。总体而言，此研究揭示了 LM 在概率校准方面的局限性，并强调了改进模型可靠性的必要性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages (main), 39 pages (references and appendix), in submission",
      "pdf_url": "http://arxiv.org/pdf/2410.16007v2",
      "published_date": "2024-10-21 13:41:15 UTC",
      "updated_date": "2025-03-04 19:14:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:25:30.214562"
    },
    {
      "arxiv_id": "2410.15998v1",
      "title": "1024m at SMM4H 2024: Tasks 3, 5 & 6 -- Ensembles of Transformers and Large Language Models for Medical Text Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Ram Mohan Rao Kadiyala",
        "M. V. P. Chandra Sekhara Rao"
      ],
      "abstract": "Social media is a great source of data for users reporting information and\nregarding their health and how various things have had an effect on them. This\npaper presents various approaches using Transformers and Large Language Models\nand their ensembles, their performance along with advantages and drawbacks for\nvarious tasks of SMM4H'24 - Classifying texts on impact of nature and outdoor\nspaces on the author's mental health (Task 3), Binary classification of tweets\nreporting their children's health disorders like Asthma, Autism, ADHD and\nSpeech disorder (task 5), Binary classification of users self-reporting their\nage (task 6).",
      "tldr_zh": "本论文探讨了在SMM4H 2024竞赛中，使用Transformers和Large Language Models及其集成（Ensembles）的方法来处理医疗文本分类任务。研究针对Task 3（分类文本关于自然和户外空间对作者心理健康的影响）、Task 5（二元分类推文报告儿童健康问题，如Asthma、Autism、ADHD和Speech disorder）和Task 6（二元分类用户自我报告年龄）进行了分析。结果展示了这些方法的性能、优势（如模型鲁棒性）和缺点（如潜在偏差），为社交媒体健康数据挖掘提供了实用见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "short paper , acl 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.15998v1",
      "published_date": "2024-10-21 13:29:08 UTC",
      "updated_date": "2024-10-21 13:29:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:25:40.201222"
    },
    {
      "arxiv_id": "2410.15990v1",
      "title": "Augmenting Legal Decision Support Systems with LLM-based NLI for Analyzing Social Media Evidence",
      "title_zh": "翻译失败",
      "authors": [
        "Ram Mohan Rao Kadiyala",
        "Siddartha Pullakhandam",
        "Kanwal Mehreen",
        "Subhasya Tippareddy",
        "Ashay Srivastava"
      ],
      "abstract": "This paper presents our system description and error analysis of our entry\nfor NLLP 2024 shared task on Legal Natural Language Inference (L-NLI)\n\\citep{hagag2024legallenssharedtask2024}. The task required classifying these\nrelationships as entailed, contradicted, or neutral, indicating any association\nbetween the review and the complaint. Our system emerged as the winning\nsubmission, significantly outperforming other entries with a substantial margin\nand demonstrating the effectiveness of our approach in legal text analysis. We\nprovide a detailed analysis of the strengths and limitations of each model and\napproach tested, along with a thorough error analysis and suggestions for\nfuture improvements. This paper aims to contribute to the growing field of\nlegal NLP by offering insights into advanced techniques for natural language\ninference in legal contexts, making it accessible to both experts and newcomers\nin the field.",
      "tldr_zh": "本研究提出了一种增强法律决策支持系统的框架，使用基于大型语言模型(LLM-based NLI)的方法来分析社交媒体证据，针对 Legal Natural Language Inference (L-NLI)任务。该任务涉及将评论与投诉的关系分类为 entailed（蕴含）、contradicted（矛盾）或 neutral（中性）。在 NLLP 2024 共享任务中，该系统脱颖而出，成为获胜参赛者，并大幅领先其他条目，证明了其在法律文本分析中的有效性。论文还详细分析了模型的优缺点、错误分析，并提供未来改进建议，以推动法律 NLP 领域的发展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages , accepted to emnlp 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.15990v1",
      "published_date": "2024-10-21 13:20:15 UTC",
      "updated_date": "2024-10-21 13:20:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:25:56.190912"
    },
    {
      "arxiv_id": "2410.15987v1",
      "title": "Analyzing Closed-loop Training Techniques for Realistic Traffic Agent Models in Autonomous Highway Driving Simulations",
      "title_zh": "针对自动高速公路驾驶模拟中现实交通",
      "authors": [
        "Matthias Bitzer",
        "Reinis Cimurs",
        "Benjamin Coors",
        "Johannes Goth",
        "Sebastian Ziesche",
        "Philipp Geiger",
        "Maximilian Naumann"
      ],
      "abstract": "Simulation plays a crucial role in the rapid development and safe deployment\nof autonomous vehicles. Realistic traffic agent models are indispensable for\nbridging the gap between simulation and the real world. Many existing\napproaches for imitating human behavior are based on learning from\ndemonstration. However, these approaches are often constrained by focusing on\nindividual training strategies. Therefore, to foster a broader understanding of\nrealistic traffic agent modeling, in this paper, we provide an extensive\ncomparative analysis of different training principles, with a focus on\nclosed-loop methods for highway driving simulation. We experimentally compare\n(i) open-loop vs. closed-loop multi-agent training, (ii) adversarial vs.\ndeterministic supervised training, (iii) the impact of reinforcement losses,\nand (iv) the impact of training alongside log-replayed agents to identify\nsuitable training techniques for realistic agent modeling. Furthermore, we\nidentify promising combinations of different closed-loop training methods.",
      "tldr_zh": "本研究分析了闭环训练技术，以提升自动驾驶高速公路模拟中现实交通代理模型的真实性。通过实验比较了多种训练原则，包括（i）开放循环 vs. 闭环多代理训练、（ii）对抗 vs. 确定性监督训练、（iii）强化损失的影响，以及（iv）与日志重放代理一起训练的影响。结果显示，闭环方法在创建更真实代理模型方面表现出色，并识别出几种有前景的训练方法组合，为自动驾驶模拟的开发提供了更全面的指导。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "cs.MA",
        "68T07",
        "I.2.6; I.6.5"
      ],
      "primary_category": "cs.RO",
      "comment": "15 pages, 6 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.15987v1",
      "published_date": "2024-10-21 13:16:58 UTC",
      "updated_date": "2024-10-21 13:16:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:26:08.201638"
    },
    {
      "arxiv_id": "2410.16344v1",
      "title": "Quantum Convolutional Neural Network: A Hybrid Quantum-Classical Approach for Iris Dataset Classification",
      "title_zh": "量子卷积神经网络：一种混合量子-经典方法用于 Iris 数据集分类",
      "authors": [
        "S. M. Yousuf Iqbal Tomal",
        "Abdullah Al Shafin",
        "Afrida Afaf",
        "Debojit Bhattacharjee"
      ],
      "abstract": "This paper presents a hybrid quantum-classical machine learning model for\nclassification tasks, integrating a 4-qubit quantum circuit with a classical\nneural network. The quantum circuit is designed to encode the features of the\nIris dataset using angle embedding and entangling gates, thereby capturing\ncomplex feature relationships that are difficult for classical models alone.\nThe model, which we term a Quantum Convolutional Neural Network (QCNN), was\ntrained over 20 epochs, achieving a perfect 100% accuracy on the Iris dataset\ntest set on 16 epoch. Our results demonstrate the potential of quantum-enhanced\nmodels in supervised learning tasks, particularly in efficiently encoding and\nprocessing data using quantum resources. We detail the quantum circuit design,\nparameterized gate selection, and the integration of the quantum layer with\nclassical neural network components. This work contributes to the growing body\nof research on hybrid quantum-classical models and their applicability to\nreal-world datasets.",
      "tldr_zh": "这篇论文提出了一种混合量子-经典机器学习模型，名为Quantum Convolutional Neural Network (QCNN)，将4-qubit量子电路与经典神经网络结合，用于Iris数据集的分类任务。量子电路通过角度嵌入和纠缠门编码数据集特征，从而捕捉经典模型难以处理的复杂特征关系。模型在20个训练周期中，于第16个周期实现了100%的测试准确率。研究证明了量子资源在监督学习中的潜力，并详细阐述了量子电路设计、参数化门选择及其与经典组件的整合，为混合量子-经典模型在实际数据集上的应用提供了新见解。",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "13 pages, 2 figures, 1 table, Quantum Machine Learning",
      "pdf_url": "http://arxiv.org/pdf/2410.16344v1",
      "published_date": "2024-10-21 13:15:12 UTC",
      "updated_date": "2024-10-21 13:15:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:26:19.990248"
    },
    {
      "arxiv_id": "2410.15978v2",
      "title": "PROMPTHEUS: A Human-Centered Pipeline to Streamline SLRs with LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "João Pedro Fernandes Torres",
        "Catherine Mulligan",
        "Joaquim Jorge",
        "Catarina Moreira"
      ],
      "abstract": "The growing volume of academic publications poses significant challenges for\nresearchers conducting timely and accurate Systematic Literature Reviews,\nparticularly in fast-evolving fields like artificial intelligence. This growth\nof academic literature also makes it increasingly difficult for lay people to\naccess scientific knowledge effectively, meaning academic literature is often\nmisrepresented in the popular press and, more broadly, in society. Traditional\nSLR methods are labor-intensive and error-prone, and they struggle to keep up\nwith the rapid pace of new research. To address these issues, we developed\n\\textit{PROMPTHEUS}: an AI-driven pipeline solution that automates the SLR\nprocess using Large Language Models. We aimed to enhance efficiency by reducing\nthe manual workload while maintaining the precision and coherence required for\ncomprehensive literature synthesis. PROMPTHEUS automates key stages of the SLR\nprocess, including systematic search, data extraction, topic modeling using\nBERTopic, and summarization with transformer models. Evaluations conducted\nacross five research domains demonstrate that PROMPTHEUS reduces review time,\nachieves high precision, and provides coherent topic organization, offering a\nscalable and effective solution for conducting literature reviews in an\nincreasingly crowded research landscape. In addition, such tools may reduce the\nincreasing mistrust in science by making summarization more accessible to\nlaypeople.\n  The code for this project can be found on the GitHub repository at\nhttps://github.com/joaopftorres/PROMPTHEUS.git",
      "tldr_zh": "该研究针对学术出版物数量激增带来的挑战，提出了一种以人为本的AI管道——PROMPTHEUS，利用Large Language Models (LLMs)来自动化Systematic Literature Reviews (SLR)过程，从而提升效率并减少手动工作量。PROMPTHEUS涵盖了SLR的关键阶段，包括系统搜索、数据提取、基于BERTopic的主题建模，以及使用transformer模型的总结。在五个研究领域的评估中，该管道显著缩短了审查时间、实现了高精确性和连贯的主题组织，同时有望通过使科学知识更易于普通人访问，缓解对科学的 mistrust。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15978v2",
      "published_date": "2024-10-21 13:05:33 UTC",
      "updated_date": "2024-10-22 10:56:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:26:32.117485"
    },
    {
      "arxiv_id": "2410.15977v1",
      "title": "Enabling Energy-Efficient Deployment of Large Language Models on Memristor Crossbar: A Synergy of Large and Small",
      "title_zh": "翻译失败",
      "authors": [
        "Zhehui Wang",
        "Tao Luo",
        "Cheng Liu",
        "Weichen Liu",
        "Rick Siow Mong Goh",
        "Weng-Fai Wong"
      ],
      "abstract": "Large language models (LLMs) have garnered substantial attention due to their\npromising applications in diverse domains. Nevertheless, the increasing size of\nLLMs comes with a significant surge in the computational requirements for\ntraining and deployment. Memristor crossbars have emerged as a promising\nsolution, which demonstrated a small footprint and remarkably high energy\nefficiency in computer vision (CV) models. Memristors possess higher density\ncompared to conventional memory technologies, making them highly suitable for\neffectively managing the extreme model size associated with LLMs. However,\ndeploying LLMs on memristor crossbars faces three major challenges. Firstly,\nthe size of LLMs increases rapidly, already surpassing the capabilities of\nstate-of-the-art memristor chips. Secondly, LLMs often incorporate multi-head\nattention blocks, which involve non-weight stationary multiplications that\ntraditional memristor crossbars cannot support. Third, while memristor\ncrossbars excel at performing linear operations, they are not capable of\nexecuting complex nonlinear operations in LLM such as softmax and layer\nnormalization. To address these challenges, we present a novel architecture for\nthe memristor crossbar that enables the deployment of state-of-the-art LLM on a\nsingle chip or package, eliminating the energy and time inefficiencies\nassociated with off-chip communication. Our testing on BERT_Large showed\nnegligible accuracy loss. Compared to traditional memristor crossbars, our\narchitecture achieves enhancements of up to 39X in area overhead and 18X in\nenergy consumption. Compared to modern TPU/GPU systems, our architecture\ndemonstrates at least a 68X reduction in the area-delay product and a\nsignificant 69% energy consumption reduction.",
      "tldr_zh": "本文提出了一种新型 memristor crossbar 架构，旨在解决大型语言模型 (LLMs) 在部署时面临的计算需求激增问题，包括模型尺寸过大、多头注意力机制不支持和非线性操作（如 softmax 和 layer normalization）执行困难。 该架构通过优化设计，实现 LLMs 在单个芯片上的高效部署，显著减少了芯片间通信的能量和时间消耗。 在 BERT_Large 测试中，该方法准确率损失微乎其微，与传统 memristor crossbars 相比，面积效率提升39倍、能量效率提升18倍；与现代 TPU/GPU 系统相比，减少至少68倍面积-延迟乘积和69%能量消耗。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15977v1",
      "published_date": "2024-10-21 13:04:44 UTC",
      "updated_date": "2024-10-21 13:04:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:26:44.963162"
    },
    {
      "arxiv_id": "2410.15974v1",
      "title": "Large Language Models for Cross-lingual Emotion Detection",
      "title_zh": "大型语言模型用于跨语言情感检测",
      "authors": [
        "Ram Mohan Rao Kadiyala"
      ],
      "abstract": "This paper presents a detailed system description of our entry for the WASSA\n2024 Task 2, focused on cross-lingual emotion detection. We utilized a\ncombination of large language models (LLMs) and their ensembles to effectively\nunderstand and categorize emotions across different languages. Our approach not\nonly outperformed other submissions with a large margin, but also demonstrated\nthe strength of integrating multiple models to enhance performance.\nAdditionally, We conducted a thorough comparison of the benefits and\nlimitations of each model used. An error analysis is included along with\nsuggested areas for future improvement. This paper aims to offer a clear and\ncomprehensive understanding of advanced techniques in emotion detection, making\nit accessible even to those new to the field.",
      "tldr_zh": "这篇论文介绍了在 WASSA 2024 Task 2 中使用 Large Language Models (LLMs) 和它们的 ensembles 来进行跨语言情绪检测的系统，该方法通过整合多个模型显著提升了情绪理解和分类的性能。他们的系统大幅超过了其他参赛者，证明了这种集成策略的有效性。论文还比较了各模型的优缺点，进行错误分析，并提出未来改进建议，以使先进情绪检测技术更易于理解和应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages , accepted to acl 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.15974v1",
      "published_date": "2024-10-21 13:00:09 UTC",
      "updated_date": "2024-10-21 13:00:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:26:55.808030"
    },
    {
      "arxiv_id": "2410.15973v1",
      "title": "Karush-Kuhn-Tucker Condition-Trained Neural Networks (KKT Nets)",
      "title_zh": "翻译失败",
      "authors": [
        "Shreya Arvind",
        "Rishabh Pomaje",
        "Rajshekhar V Bhat"
      ],
      "abstract": "This paper presents a novel approach to solving convex optimization problems\nby leveraging the fact that, under certain regularity conditions, any set of\nprimal or dual variables satisfying the Karush-Kuhn-Tucker (KKT) conditions is\nnecessary and sufficient for optimality. Similar to Theory-Trained Neural\nNetworks (TTNNs), the parameters of the convex optimization problem are input\nto the neural network, and the expected outputs are the optimal primal and dual\nvariables. A choice for the loss function in this case is a loss, which we\nrefer to as the KKT Loss, that measures how well the network's outputs satisfy\nthe KKT conditions. We demonstrate the effectiveness of this approach using a\nlinear program as an example. For this problem, we observe that minimizing the\nKKT Loss alone outperforms training the network with a weighted sum of the KKT\nLoss and a Data Loss (the mean-squared error between the ground truth optimal\nsolutions and the network's output). Moreover, minimizing only the Data Loss\nyields inferior results compared to those obtained by minimizing the KKT Loss.\nWhile the approach is promising, the obtained primal and dual solutions are not\nsufficiently close to the ground truth optimal solutions. In the future, we aim\nto develop improved models to obtain solutions closer to the ground truth and\nextend the approach to other problem classes.",
      "tldr_zh": "本论文提出了一种名为 Karush-Kuhn-Tucker Condition-Trained Neural Networks (KKT Nets) 的新方法，利用 KKT 条件来求解凸优化问题，其中网络输入为优化问题参数，输出为最优 primal 和 dual 变量。方法的核心是定义 KKT Loss 作为损失函数，以衡量网络输出是否满足 KKT 条件，从而避免依赖传统数据损失。实验结果显示，在线性规划任务上，仅最小化 KKT Loss 比结合 Data Loss 或仅使用 Data Loss 表现更优，但生成的解决方案与 ground truth 最优解仍有差距。未来，该方法计划通过改进模型来提升准确性和扩展至其他问题类型。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15973v1",
      "published_date": "2024-10-21 12:59:58 UTC",
      "updated_date": "2024-10-21 12:59:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:27:08.954069"
    },
    {
      "arxiv_id": "2410.15966v1",
      "title": "Self-Explained Keywords Empower Large Language Models for Code Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Lishui Fan",
        "Mouxiang Chen",
        "Zhongxin Liu"
      ],
      "abstract": "Large language models (LLMs) have achieved impressive performance in code\ngeneration. However, due to the long-tail distribution of LLMs' training data,\nlow-frequency terms are typically underrepresented in the training process.\nConsequently, LLMs often misunderstand or overlook problem-specific,\nlow-frequency keywords during code generation, compromising the accuracy of the\ngenerated code. To address this, we propose a novel technique named\nSEK(\\textbf{S}elf-\\textbf{E}xplained \\textbf{K}eywords), which empowers an LLM\nfor better code generation by extracting and explaining the key terms in the\nproblem description with the LLM itself and ranking them based on frequency.\nComprehensive experiments across three benchmarks, i.e., HumanEval(+), MBPP(+),\nand APPS, with five representative LLMs, show that SEK can significantly\nimprove LLMs in code generation, yielding substantial and consistent gains. For\ninstance, SEK improves the Pass@1 of DeepSeek-Coder-V2-Instruct from 85.4\\% to\n93.3\\% on the Humaneval benchmark. Further analysis confirms that SEK enables\nthe LLMs to shift their attention from low-frequency keywords to their\ncorresponding high-frequency counterparts.",
      "tldr_zh": "本研究发现，大型语言模型（LLMs）在代码生成中常因训练数据长尾分布而忽略低频关键词，导致生成代码准确性不足。为解决此问题，提出SEK（Self-Explained Keywords）技术，利用LLMs自身提取、解释问题描述中的关键术语并基于频率进行排名，从而提升代码生成性能。实验在HumanEval(+)、MBPP(+)和APPS等基准上验证了SEK的有效性，例如将DeepSeek-Coder-V2-Instruct的Pass@1从85.4%提高到93.3%。此外，该方法帮助LLMs将注意力从低频关键词转移到高频对应词，实现更可靠的代码生成。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15966v1",
      "published_date": "2024-10-21 12:52:03 UTC",
      "updated_date": "2024-10-21 12:52:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:27:20.745678"
    },
    {
      "arxiv_id": "2410.15962v1",
      "title": "Systematic Exploration of Dialogue Summarization Approaches for Reproducibility, Comparative Assessment, and Methodological Innovations for Advancing Natural Language Processing in Abstractive Summarization",
      "title_zh": "翻译失败",
      "authors": [
        "Yugandhar Reddy Gogireddy",
        "Jithendra Reddy Gogireddy"
      ],
      "abstract": "Reproducibility in scientific research, particularly within the realm of\nnatural language processing (NLP), is essential for validating and verifying\nthe robustness of experimental findings. This paper delves into the\nreproduction and evaluation of dialogue summarization models, focusing\nspecifically on the discrepancies observed between original studies and our\nreproduction efforts. Dialogue summarization is a critical aspect of NLP,\naiming to condense conversational content into concise and informative\nsummaries, thus aiding in efficient information retrieval and decision-making\nprocesses. Our research involved a thorough examination of several dialogue\nsummarization models using the AMI (Augmented Multi-party Interaction) dataset.\nThe models assessed include Hierarchical Memory Networks (HMNet) and various\nversions of Pointer-Generator Networks (PGN), namely PGN(DKE), PGN(DRD),\nPGN(DTS), and PGN(DALL). The primary objective was to evaluate the\ninformativeness and quality of the summaries generated by these models through\nhuman assessment, a method that introduces subjectivity and variability in the\nevaluation process. The analysis began with Dataset 1, where the sample\nstandard deviation of 0.656 indicated a moderate dispersion of data points\naround the mean.",
      "tldr_zh": "这篇论文系统探讨了对话摘要方法在 NLP 中的再现性、比较评估和方法创新，旨在验证实验结果的稳健性并推进抽象摘要技术。研究者使用 AMI 数据集对 Hierarchical Memory Networks (HMNet) 和多种 Pointer-Generator Networks (PGN) 变体（如 PGN(DKE)、PGN(DRD)、PGN(DTS) 和 PGN(DALL)）进行了全面评估，并通过人类评估方法检查摘要的信息性和质量。结果揭示了原始研究与再现努力之间的差异，并通过数据集 1 的样本标准差（0.656）量化了评估过程的主观变异性，为提升 NLP 研究的可靠性和创新提供了重要见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15962v1",
      "published_date": "2024-10-21 12:47:57 UTC",
      "updated_date": "2024-10-21 12:47:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:27:32.977565"
    },
    {
      "arxiv_id": "2410.15960v1",
      "title": "AI-Driven Innovations in Modern Cloud Computing",
      "title_zh": "AI驱动的现代云计算创新",
      "authors": [
        "Animesh Kumar"
      ],
      "abstract": "The world has witnessed rapid technological transformation, past couple of\ndecades and with Advent of Cloud computing the landscape evolved exponentially\nleading to efficient and scalable application development. Now, the past couple\nof years the digital ecosystem has brought in numerous innovations with\nintegration of Artificial Intelligence commonly known as AI. This paper\nexplores how AI and cloud computing intersect to deliver transformative\ncapabilities for modernizing applications by providing services and\ninfrastructure. Harnessing the combined potential of both AI & Cloud\ntechnologies, technology providers can now exploit intelligent resource\nmanagement, predictive analytics, automated deployment & scaling with enhanced\nsecurity leading to offering innovative solutions to their customers.\nFurthermore, by leveraging such technologies of cloud & AI businesses can reap\nrich rewards in the form of reducing operational costs and improving service\ndelivery. This paper further addresses challenges associated such as data\nprivacy concerns and how it can be mitigated with robust AI governance\nframeworks.",
      "tldr_zh": "这篇论文探讨了人工智能（AI）如何驱动现代云计算的创新，通过整合 AI 与云技术来现代化应用开发和服务提供。具体而言，它强调了 AI 在智能资源管理、预测分析、自动化部署和缩放以及增强安全方面的作用，帮助企业降低运营成本并提升服务交付效率。同时，论文指出了数据隐私等挑战，并提出通过强有力的 AI 治理框架来缓解这些问题，从而实现更可靠的创新解决方案。",
      "categories": [
        "cs.AI",
        "68Txx - Artificial Intelligence",
        "I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "5 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.15960v1",
      "published_date": "2024-10-21 12:45:10 UTC",
      "updated_date": "2024-10-21 12:45:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:27:43.399940"
    },
    {
      "arxiv_id": "2410.15956v2",
      "title": "Do Large Language Models Have an English Accent? Evaluating and Improving the Naturalness of Multilingual LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Yanzhu Guo",
        "Simone Conia",
        "Zelin Zhou",
        "Min Li",
        "Saloni Potdar",
        "Henry Xiao"
      ],
      "abstract": "Current Large Language Models (LLMs) are predominantly designed with English\nas the primary language, and even the few that are multilingual tend to exhibit\nstrong English-centric biases. Much like speakers who might produce awkward\nexpressions when learning a second language, LLMs often generate unnatural\noutputs in non-English languages, reflecting English-centric patterns in both\nvocabulary and grammar. Despite the importance of this issue, the naturalness\nof multilingual LLM outputs has received limited attention. In this paper, we\naddress this gap by introducing novel automatic corpus-level metrics to assess\nthe lexical and syntactic naturalness of LLM outputs in a multilingual context.\nUsing our new metrics, we evaluate state-of-the-art LLMs on a curated benchmark\nin French and Chinese, revealing a tendency towards English-influenced\npatterns. To mitigate this issue, we also propose a simple and effective\nalignment method to improve the naturalness of an LLM in a target language and\ndomain, achieving consistent improvements in naturalness without compromising\nthe performance on general-purpose benchmarks. Our work highlights the\nimportance of developing multilingual metrics, resources and methods for the\nnew wave of multilingual LLMs.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）在多语言输出中的英语偏见问题，导致非英语语言（如法语和中文）生成不自然的词汇和语法模式。论文引入了新的自动指标（corpus-level metrics）来评估LLMs的词汇和句法自然性，并在精心构建的基准上测试了最先进模型，揭示了明显的英语影响。研究者提出了一种简单有效的对齐方法（alignment method），成功改善了目标语言的自然性，同时不影响一般基准的性能。该工作强调了开发多语言指标、资源和方法的紧迫性，以推动更公平的多语言LLMs发展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15956v2",
      "published_date": "2024-10-21 12:34:17 UTC",
      "updated_date": "2024-10-23 13:00:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:27:56.458087"
    },
    {
      "arxiv_id": "2410.15954v3",
      "title": "TS-ACL: Closed-Form Solution for Time Series-oriented Continual Learning",
      "title_zh": "TS-ACL：面向时间序列的持续学习的封闭形式解",
      "authors": [
        "Jiaxu Li",
        "Kejia Fan",
        "Songning Lai",
        "Linpu Lv",
        "Jinfeng Xu",
        "Jianheng Tang",
        "Anfeng Liu",
        "Houbing Herbert Song",
        "Yutao Yue",
        "Yunhuai Liu",
        "Huiping Zhuang"
      ],
      "abstract": "Time series classification underpins critical applications such as healthcare\ndiagnostics and gesture-driven interactive systems in multimedia scenarios.\nHowever, time series class-incremental learning (TSCIL) faces two major\nchallenges: catastrophic forgetting and intra-class variations. Catastrophic\nforgetting occurs because gradient-based parameter update strategies inevitably\nerase past knowledge. And unlike images, time series data exhibits\nsubject-specific patterns, also known as intra-class variations, which refer to\ndifferences in patterns observed within the same class. While exemplar-based\nmethods fail to cover diverse variation with limited samples, existing\nexemplar-free methods lack explicit mechanisms to handle intra-class\nvariations. To address these two challenges, we propose TS-ACL, which leverages\na gradient-free closed-form solution to avoid the catastrophic forgetting\nproblem inherent in gradient-based optimization methods while simultaneously\nlearning global distributions to resolve intra-class variations. Additionally,\nit provides privacy protection and efficiency. Extensive experiments on five\nbenchmark datasets covering various sensor modalities and tasks demonstrate\nthat TS-ACL achieves performance close to joint training on four datasets,\noutperforming existing methods and establishing a new state-of-the-art (SOTA)\nfor TSCIL.",
      "tldr_zh": "该研究针对时间序列分类的持续学习（TSCIL），解决了灾难性遗忘（catastrophic forgetting）和类内变异（intra-class variations）两大挑战，后者源于数据中的个体差异。TS-ACL 提出了一种基于梯度-free 的闭式解（closed-form solution），通过避免梯度优化导致的知识擦除，同时学习全局分布来处理变异，同时提供隐私保护和计算效率。实验在五个基准数据集上表明，TS-ACL 的性能接近联合训练，并在四个数据集上超越现有方法，确立了新的 SOTA（state-of-the-art）。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 5 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.15954v3",
      "published_date": "2024-10-21 12:34:02 UTC",
      "updated_date": "2025-04-16 12:39:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:28:07.870804"
    },
    {
      "arxiv_id": "2410.15952v1",
      "title": "User-centric evaluation of explainability of AI with and for humans: a comprehensive empirical study",
      "title_zh": "翻译失败",
      "authors": [
        "Szymon Bobek",
        "Paloma Korycińska",
        "Monika Krakowska",
        "Maciej Mozolewski",
        "Dorota Rak",
        "Magdalena Zych",
        "Magdalena Wójcik",
        "Grzegorz J. Nalepa"
      ],
      "abstract": "This study is located in the Human-Centered Artificial Intelligence (HCAI)\nand focuses on the results of a user-centered assessment of commonly used\neXplainable Artificial Intelligence (XAI) algorithms, specifically\ninvestigating how humans understand and interact with the explanations provided\nby these algorithms. To achieve this, we employed a multi-disciplinary approach\nthat included state-of-the-art research methods from social sciences to measure\nthe comprehensibility of explanations generated by a state-of-the-art lachine\nlearning model, specifically the Gradient Boosting Classifier (XGBClassifier).\nWe conducted an extensive empirical user study involving interviews with 39\nparticipants from three different groups, each with varying expertise in data\nscience, data visualization, and domain-specific knowledge related to the\ndataset used for training the machine learning model. Participants were asked a\nseries of questions to assess their understanding of the model's explanations.\nTo ensure replicability, we built the model using a publicly available dataset\nfrom the UC Irvine Machine Learning Repository, focusing on edible and\nnon-edible mushrooms. Our findings reveal limitations in existing XAI methods\nand confirm the need for new design principles and evaluation techniques that\naddress the specific information needs and user perspectives of different\nclasses of AI stakeholders. We believe that the results of our research and the\ncross-disciplinary methodology we developed can be successfully adapted to\nvarious data types and user profiles, thus promoting dialogue and address\nopportunities in HCAI research. To support this, we are making the data\nresulting from our study publicly available.",
      "tldr_zh": "本研究聚焦于人类中心人工智能 (HCAI)，通过一项全面实证用户研究评估了常见可解释人工智能 (XAI) 算法的解释性，探讨人类如何理解和互动这些解释。研究采用多学科方法，包括社会科学技术，针对 Gradient Boosting Classifier (XGBClassifier) 模型进行评估，并采访了 39 名参与者（涵盖数据科学、数据可视化和领域知识群体），使用公开的 UC Irvine Machine Learning Repository 蘑菇数据集。结果揭示了现有 XAI 方法的局限性，如无法充分满足不同用户的信息需求，并强调了开发新设计原则和评估技术的必要性。该研究提供公开数据，促进 XAI 在各种数据类型和用户配置文件中的适应和对话。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15952v1",
      "published_date": "2024-10-21 12:32:39 UTC",
      "updated_date": "2024-10-21 12:32:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:28:20.293725"
    },
    {
      "arxiv_id": "2410.15951v1",
      "title": "Redefining Finance: The Influence of Artificial Intelligence (AI) and Machine Learning (ML)",
      "title_zh": "翻译失败",
      "authors": [
        "Animesh Kumar"
      ],
      "abstract": "With rapid transformation of technologies, the fusion of Artificial\nIntelligence (AI) and Machine Learning (ML) in finance is disrupting the entire\necosystem and operations which were followed for decades. The current landscape\nis where decisions are increasingly data-driven by financial institutions with\nan appetite for automation while mitigating risks. The segments of financial\ninstitutions which are getting heavily influenced are retail banking, wealth\nmanagement, corporate banking & payment ecosystem. The solution ranges from\nonboarding the customers all the way fraud detection & prevention to enhancing\nthe customer services. Financial Institutes are leap frogging with integration\nof Artificial Intelligence and Machine Learning in mainstream applications and\nenhancing operational efficiency through advanced predictive analytics,\nextending personalized customer experiences, and automation to minimize risk\nwith fraud detection techniques. However, with Adoption of AI & ML, it is\nimperative that the financial institute also needs to address ethical and\nregulatory challenges, by putting in place robust governance frameworks and\nresponsible AI practices.",
      "tldr_zh": "这篇论文探讨了人工智能(AI)和机器学习(ML)如何重塑金融领域，通过数据驱动决策和自动化技术影响零售银行、财富管理和支付系统等领域。论文强调，AI 和 ML 可提升操作效率、提供个性化客户体验，并通过预测分析和欺诈检测技术降低风险，从而帮助金融机构实现飞跃。然而，它也指出，在采用这些技术时，必须应对伦理和监管挑战，并建立稳健的治理框架和负责任的 AI 实践。",
      "categories": [
        "cs.AI",
        "68Txx - Artificial Intelligence",
        "I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2410.15951v1",
      "published_date": "2024-10-21 12:32:17 UTC",
      "updated_date": "2024-10-21 12:32:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:28:31.536231"
    },
    {
      "arxiv_id": "2410.15947v2",
      "title": "AI-Driven Approaches for Glaucoma Detection -- A Comprehensive Review",
      "title_zh": "人工智能驱动的青光眼检测方法——全面综述",
      "authors": [
        "Yuki Hagiwara",
        "Octavia-Andreea Ciora",
        "Maureen Monnet",
        "Gino Lancho",
        "Jeanette Miriam Lorenz"
      ],
      "abstract": "The diagnosis of glaucoma plays a critical role in the management and\ntreatment of this vision-threatening disease. Glaucoma is a group of eye\ndiseases that cause blindness by damaging the optic nerve at the back of the\neye. Often called \"silent thief of sight\", it exhibits no symptoms during the\nearly stages. Therefore, early detection is crucial to prevent vision loss.\nWith the rise of Artificial Intelligence (AI), particularly Deep Learning (DL)\ntechniques, Computer-Aided Diagnosis (CADx) systems have emerged as promising\ntools to assist clinicians in accurately diagnosing glaucoma early. This paper\naims to provide a comprehensive overview of AI techniques utilized in CADx\nsystems for glaucoma diagnosis. Through a detailed analysis of current\nliterature, we identify key gaps and challenges in these systems, emphasizing\nthe need for improved safety, reliability, interpretability, and\nexplainability. By identifying research gaps, we aim to advance the field of\nCADx systems especially for the early diagnosis of glaucoma, in order to\nprevent any potential loss of vision.",
      "tldr_zh": "这篇论文对基于 AI 的青光眼检测方法进行了全面综述，强调了 AI 技术，特别是 Deep Learning，在 Computer-Aided Diagnosis (CADx) 系统中的应用，以实现早期诊断并防止视力损失。作者通过分析现有文献，识别了关键挑战，包括系统安全、可靠性和可解释性不足。最终，该综述旨在填补研究空白，推动 CADx 系统的发展，提升青光眼诊断的准确性和临床实用性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15947v2",
      "published_date": "2024-10-21 12:26:53 UTC",
      "updated_date": "2024-10-22 17:58:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:28:43.353597"
    },
    {
      "arxiv_id": "2410.15944v1",
      "title": "Developing Retrieval Augmented Generation (RAG) based LLM Systems from PDFs: An Experience Report",
      "title_zh": "翻译失败",
      "authors": [
        "Ayman Asad Khan",
        "Md Toufique Hasan",
        "Kai Kristian Kemell",
        "Jussi Rasku",
        "Pekka Abrahamsson"
      ],
      "abstract": "This paper presents an experience report on the development of Retrieval\nAugmented Generation (RAG) systems using PDF documents as the primary data\nsource. The RAG architecture combines generative capabilities of Large Language\nModels (LLMs) with the precision of information retrieval. This approach has\nthe potential to redefine how we interact with and augment both structured and\nunstructured knowledge in generative models to enhance transparency, accuracy,\nand contextuality of responses. The paper details the end-to-end pipeline, from\ndata collection, preprocessing, to retrieval indexing and response generation,\nhighlighting technical challenges and practical solutions. We aim to offer\ninsights to researchers and practitioners developing similar systems using two\ndistinct approaches: OpenAI's Assistant API with GPT Series and Llama's\nopen-source models. The practical implications of this research lie in\nenhancing the reliability of generative AI systems in various sectors where\ndomain-specific knowledge and real-time information retrieval is important. The\nPython code used in this work is also available at:\nhttps://github.com/GPT-Laboratory/RAG-LLM-Development-Guidebook-from-PDFs.",
      "tldr_zh": "这篇论文报告了使用 PDF 作为主要数据源开发 Retrieval Augmented Generation (RAG) 系统的经验，结合 Large Language Models (LLMs) 的生成能力与信息检索的精确性，以提升响应透明度、准确性和上下文性。论文详细介绍了端到端管道，包括数据收集、预处理、检索索引和响应生成，并讨论了技术挑战及其实用解决方案，使用了 OpenAI's Assistant API with GPT Series 和 Llama's open-source models 两种方法。研究为需要领域特定知识和实时信息检索的行业提供见解，帮助提升生成 AI 系统的可靠性。开源 Python 代码可从 GitHub 获取（https://github.com/GPT-Laboratory/RAG-LLM-Development-Guidebook-from-PDFs）。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.SE",
      "comment": "36 pages, 8 figures, 2 tables, and python code snippets",
      "pdf_url": "http://arxiv.org/pdf/2410.15944v1",
      "published_date": "2024-10-21 12:21:49 UTC",
      "updated_date": "2024-10-21 12:21:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:30:02.255757"
    },
    {
      "arxiv_id": "2410.15930v1",
      "title": "Centrality-aware Product Retrieval and Ranking",
      "title_zh": "基于中心性的产品检索和排名",
      "authors": [
        "Hadeel Saadany",
        "Swapnil Bhosale",
        "Samarth Agrawal",
        "Diptesh Kanojia",
        "Constantin Orasan",
        "Zhe Wu"
      ],
      "abstract": "This paper addresses the challenge of improving user experience on e-commerce\nplatforms by enhancing product ranking relevant to users' search queries.\nAmbiguity and complexity of user queries often lead to a mismatch between the\nuser's intent and retrieved product titles or documents. Recent approaches have\nproposed the use of Transformer-based models, which need millions of annotated\nquery-title pairs during the pre-training stage, and this data often does not\ntake user intent into account. To tackle this, we curate samples from existing\ndatasets at eBay, manually annotated with buyer-centric relevance scores and\ncentrality scores, which reflect how well the product title matches the users'\nintent. We introduce a User-intent Centrality Optimization (UCO) approach for\nexisting models, which optimises for the user intent in semantic product\nsearch. To that end, we propose a dual-loss based optimisation to handle hard\nnegatives, i.e., product titles that are semantically relevant but do not\nreflect the user's intent. Our contributions include curating challenging\nevaluation sets and implementing UCO, resulting in significant product ranking\nefficiency improvements observed for different evaluation metrics. Our work\naims to ensure that the most buyer-centric titles for a query are ranked\nhigher, thereby, enhancing the user experience on e-commerce platforms.",
      "tldr_zh": "这篇论文针对电商平台的产品检索和排名问题，提出 Centrality-aware 方法来解决用户查询的模糊性导致的意图与结果不匹配问题。作者从 eBay 数据集整理样本，并手动标注 buyer-centric relevance scores 和 centrality scores，以优化用户意图；同时引入 User-intent Centrality Optimization (UCO) 及其 dual-loss based optimisation 来处理 hard negatives（语义相关但不匹配意图的产品标题）。实验结果显示，该方法在不同评估指标上显著提高了产品排名效率，最终提升了用户体验。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "EMNLP 2024: Industry track",
      "pdf_url": "http://arxiv.org/pdf/2410.15930v1",
      "published_date": "2024-10-21 11:59:14 UTC",
      "updated_date": "2024-10-21 11:59:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:29:08.534133"
    },
    {
      "arxiv_id": "2410.15927v1",
      "title": "GReFEL: Geometry-Aware Reliable Facial Expression Learning under Bias and Imbalanced Data Distribution",
      "title_zh": "GReFEL：基于几何的可靠面部表情学习，在偏置和不平衡数据分布下",
      "authors": [
        "Azmine Toushik Wasi",
        "Taki Hasan Rafi",
        "Raima Islam",
        "Karlo Serbetar",
        "Dong Kyu Chae"
      ],
      "abstract": "Reliable facial expression learning (FEL) involves the effective learning of\ndistinctive facial expression characteristics for more reliable, unbiased and\naccurate predictions in real-life settings. However, current systems struggle\nwith FEL tasks because of the variance in people's facial expressions due to\ntheir unique facial structures, movements, tones, and demographics. Biased and\nimbalanced datasets compound this challenge, leading to wrong and biased\nprediction labels. To tackle these, we introduce GReFEL, leveraging Vision\nTransformers and a facial geometry-aware anchor-based reliability balancing\nmodule to combat imbalanced data distributions, bias, and uncertainty in facial\nexpression learning. Integrating local and global data with anchors that learn\ndifferent facial data points and structural features, our approach adjusts\nbiased and mislabeled emotions caused by intra-class disparity, inter-class\nsimilarity, and scale sensitivity, resulting in comprehensive, accurate, and\nreliable facial expression predictions. Our model outperforms current\nstate-of-the-art methodologies, as demonstrated by extensive experiments on\nvarious datasets.",
      "tldr_zh": "该论文提出 GReFEL，一种基于面部几何感知的可靠面部表情学习 (FEL) 方法，旨在应对偏见和不平衡数据分布带来的挑战，如面部结构差异、动作变异和人口统计学因素导致的预测偏差。GReFEL 利用 Vision Transformers 和一个锚点可靠性平衡模块，整合本地与全局数据，通过学习不同的面部数据点和结构特征来调整类内差异、类间相似性和尺度敏感性，从而实现更准确的无偏预测。实验结果显示，该模型在多种数据集上超越了现有最先进方法，提供更可靠的 FEL 性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "ACCV 2024. Extended version of ARBEx (arXiv:2305.01486)",
      "pdf_url": "http://arxiv.org/pdf/2410.15927v1",
      "published_date": "2024-10-21 11:55:06 UTC",
      "updated_date": "2024-10-21 11:55:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:29:19.588623"
    },
    {
      "arxiv_id": "2410.21301v2",
      "title": "Evaluating the Posterior Sampling Ability of Plug&Play Diffusion Methods in Sparse-View CT",
      "title_zh": "翻译失败",
      "authors": [
        "Liam Moroy",
        "Guillaume Bourmaud",
        "Frédéric Champagnat",
        "Jean-François Giovannelli"
      ],
      "abstract": "Plug&Play (PnP) diffusion models are state-of-the-art methods in computed\ntomography (CT) reconstruction. Such methods usually consider applications\nwhere the sinogram contains a sufficient amount of information for the\nposterior distribution to be concentrated around a single mode, and\nconsequently are evaluated using image-to-image metrics such as PSNR/SSIM.\nInstead, we are interested in reconstructing compressible flow images from\nsinograms having a small number of projections, which results in a posterior\ndistribution no longer concentrated or even multimodal. Thus, in this paper, we\naim at evaluating the approximate posterior of PnP diffusion models and\nintroduce two posterior evaluation properties. We quantitatively evaluate three\nPnP diffusion methods on three different datasets for several numbers of\nprojections. We surprisingly find that, for each method, the approximate\nposterior deviates from the true posterior when the number of projections\ndecreases.",
      "tldr_zh": "本研究评估了 Plug&Play diffusion methods 在稀疏视图 CT 中的后验采样能力，针对投影数量少导致后验分布不集中或多模态的场景，引入了两个后验评估属性。\n他们对三种 PnP diffusion 方法在三个不同数据集上进行了量化评估，比较了不同投影数量下的表现。\n结果发现，随着投影数量减少，这些方法的近似后验与真实后验偏差逐渐增大，这突显了在低信息量条件下方法的局限性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.21301v2",
      "published_date": "2024-10-21 11:39:03 UTC",
      "updated_date": "2025-03-18 09:00:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:29:31.638701"
    },
    {
      "arxiv_id": "2411.02419v1",
      "title": "XAI-FUNGI: Dataset resulting from the user study on comprehensibility of explainable AI algorithms",
      "title_zh": "翻译失败",
      "authors": [
        "Szymon Bobek",
        "Paloma Korycińska",
        "Monika Krakowska",
        "Maciej Mozolewski",
        "Dorota Rak",
        "Magdalena Zych",
        "Magdalena Wójcik",
        "Grzegorz J. Nalepa"
      ],
      "abstract": "This paper introduces a dataset that is the result of a user study on the\ncomprehensibility of explainable artificial intelligence (XAI) algorithms. The\nstudy participants were recruited from 149 candidates to form three groups\nrepresenting experts in the domain of mycology (DE), students with a data\nscience and visualization background (IT) and students from social sciences and\nhumanities (SSH). The main part of the dataset contains 39 transcripts of\ninterviews during which participants were asked to complete a series of tasks\nand questions related to the interpretation of explanations of decisions of a\nmachine learning model trained to distinguish between edible and inedible\nmushrooms. The transcripts were complemented with additional data that includes\nvisualizations of explanations presented to the user, results from thematic\nanalysis, recommendations of improvements of explanations provided by the\nparticipants, and the initial survey results that allow to determine the domain\nknowledge of the participant and data analysis literacy. The transcripts were\nmanually tagged to allow for automatic matching between the text and other data\nrelated to particular fragments. In the advent of the area of rapid development\nof XAI techniques, the need for a multidisciplinary qualitative evaluation of\nexplainability is one of the emerging topics in the community. Our dataset\nallows not only to reproduce the study we conducted, but also to open a wide\nrange of possibilities for the analysis of the material we gathered.",
      "tldr_zh": "这篇论文介绍了 XAI-FUNGI 数据集，该数据集来源于一个用户研究，旨在评估可解释人工智能 (XAI) 算法的可理解性。研究招募了 149 名候选人，形成三个群体，包括真菌学专家 (DE)、数据科学和可视化背景的学生 (IT) 以及社会科学和人文学生 (SSH)，并通过 39 份采访记录、任务和问题来分析他们对机器学习模型决策解释的解读。数据集还包含解释可视化、主题分析结果、改进建议以及初始调查数据，用于评估参与者的领域知识和数据分析素养。XAI-FUNGI 的发布不仅允许重现该研究，还为多学科定性评估 XAI 技术提供了广泛分析可能性。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.02419v1",
      "published_date": "2024-10-21 11:37:58 UTC",
      "updated_date": "2024-10-21 11:37:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:29:44.951292"
    },
    {
      "arxiv_id": "2410.15912v3",
      "title": "Bench4Merge: A Comprehensive Benchmark for Merging in Realistic Dense Traffic with Micro-Interactive Vehicles",
      "title_zh": "Bench4Merge：",
      "authors": [
        "Zhengming Wang",
        "Junli Wang",
        "Pengfei Li",
        "Zhaohan Li",
        "Chunyang Liu",
        "Bo Zhang",
        "Peng Li",
        "Yilun Chen"
      ],
      "abstract": "While the capabilities of autonomous driving have advanced rapidly, merging\ninto dense traffic remains a significant challenge, many motion planning\nmethods for this scenario have been proposed but it is hard to evaluate them.\nMost existing closed-loop simulators rely on rule-based controls for other\nvehicles, which results in a lack of diversity and randomness, thus failing to\naccurately assess the motion planning capabilities in highly interactive\nscenarios. Moreover, traditional evaluation metrics are insufficient for\ncomprehensively evaluating the performance of merging in dense traffic. In\nresponse, we proposed a closed-loop evaluation benchmark for assessing motion\nplanning capabilities in merging scenarios. Our approach involves other\nvehicles trained in large scale datasets with micro-behavioral characteristics\nthat significantly enhance the complexity and diversity. Additionally, we have\nrestructured the evaluation mechanism by leveraging Large Language Models\n(LLMs) to assess each autonomous vehicle merging onto the main lane. Extensive\nexperiments and test-vehicle deployment have demonstrated the progressiveness\nof this benchmark. Through this benchmark, we have obtained an evaluation of\nexisting methods and identified common issues. The simulation environment and\nevaluation process can be accessed at https://github.com/WZM5853/Bench4Merge.",
      "tldr_zh": "本研究提出Bench4Merge，一个全面的基准，用于评估自动驾驶车辆在密集交通中合并（merging）的运动规划能力，以解决现有模拟器缺乏多样性和随机性的问题。该基准采用大规模数据集训练的其他车辆，融入微行为特征（micro-behavioral characteristics），并利用Large Language Models (LLMs)重新设计评估机制，以更准确地评估车辆在高度交互场景中的性能。通过广泛实验和实际部署，Bench4Merge显著提升了评估的复杂性，并识别了现有方法的常见问题；相关代码可在https://github.com/WZM5853/Bench4Merge获取。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "6 pages, 8 figures, on submitted",
      "pdf_url": "http://arxiv.org/pdf/2410.15912v3",
      "published_date": "2024-10-21 11:35:33 UTC",
      "updated_date": "2025-04-02 09:02:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:30:13.693864"
    },
    {
      "arxiv_id": "2410.15910v2",
      "title": "Diverse Policies Recovering via Pointwise Mutual Information Weighted Imitation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Hanlin Yang",
        "Jian Yao",
        "Weiming Liu",
        "Qing Wang",
        "Hanmin Qin",
        "Hansheng Kong",
        "Kirk Tang",
        "Jiechao Xiong",
        "Chao Yu",
        "Kai Li",
        "Junliang Xing",
        "Hongwu Chen",
        "Juchao Zhuo",
        "Qiang Fu",
        "Yang Wei",
        "Haobo Fu"
      ],
      "abstract": "Recovering a spectrum of diverse policies from a set of expert trajectories\nis an important research topic in imitation learning. After determining a\nlatent style for a trajectory, previous diverse policies recovering methods\nusually employ a vanilla behavioral cloning learning objective conditioned on\nthe latent style, treating each state-action pair in the trajectory with equal\nimportance. Based on an observation that in many scenarios, behavioral styles\nare often highly relevant with only a subset of state-action pairs, this paper\npresents a new principled method in diverse polices recovery. In particular,\nafter inferring or assigning a latent style for a trajectory, we enhance the\nvanilla behavioral cloning by incorporating a weighting mechanism based on\npointwise mutual information. This additional weighting reflects the\nsignificance of each state-action pair's contribution to learning the style,\nthus allowing our method to focus on state-action pairs most representative of\nthat style. We provide theoretical justifications for our new objective, and\nextensive empirical evaluations confirm the effectiveness of our method in\nrecovering diverse policies from expert data.",
      "tldr_zh": "本研究针对模仿学习(imitation learning)中从专家轨迹恢复多样策略的问题，提出了一种基于点wise mutual information (PMI) 加权机制的新方法。该方法在推断轨迹的潜在风格后，通过PMI计算每个状态-动作对的重要性，对传统的条件行为克隆(behavioral cloning)进行加权优化，从而重点学习最能代表风格的子集状态-动作对。理论分析证明了新目标的有效性，而广泛的实证评估显示，该方法显著提高了多样策略的恢复性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.15910v2",
      "published_date": "2024-10-21 11:33:14 UTC",
      "updated_date": "2024-10-22 05:06:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:30:26.324291"
    },
    {
      "arxiv_id": "2410.15897v1",
      "title": "IGMaxHS -- An Incremental MaxSAT Solver with Support for XOR Clauses",
      "title_zh": "翻译失败",
      "authors": [
        "Ole Lübke"
      ],
      "abstract": "Recently, a novel, MaxSAT-based method for error correction in quantum\ncomputing has been proposed that requires both incremental MaxSAT solving\ncapabilities and support for XOR constraints, but no dedicated MaxSAT solver\nfulfilling these criteria existed yet. We alleviate that and introduce IGMaxHS,\nwhich is based on the existing solvers iMaxHS and GaussMaxHS, but poses fewer\nrestrictions on the XOR constraints than GaussMaxHS. IGMaxHS is fuzz tested\nwith xwcnfuzz, an extension of wcnfuzz that can directly output XOR\nconstraints. As a result, IGMaxHS is the only solver that reported neither\nincorrect unsatisfiability verdicts nor invalid models nor incoherent cost\nmodel combinations in a final fuzz testing comparison of all three solvers with\n10000 instances. We detail the steps required for implementing Gaussian\nelimination on XOR constraints in CDCL SAT solvers, and extend the recently\nproposed re-entrant incremental MaxSAT solver application program interface to\nallow for incremental addition of XOR constraints. Finally, we show that\nIGMaxHS is capable of decoding quantum color codes through simulation with the\nMunich Quantum Toolkit.",
      "tldr_zh": "该论文引入了 IGMaxHS，一种支持 XOR Clauses 的 Incremental MaxSAT Solver，旨在解决量子计算错误修正中的增量求解需求。IGMaxHS 基于 iMaxHS 和 GaussMaxHS 求解器，减少了对 XOR 约束的限制，并实现了 Gaussian Elimination 在 CDCL SAT Solvers 中的应用，同时扩展了增量 MaxSAT 接口以允许动态添加 XOR 约束。在模糊测试中，IGMaxHS 在 10000 个实例中未报告任何错误（如不正确的不满足性判定或无效模型），并通过模拟证明了其在量子色码解码中的有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Presented at the 15th International Workshop on Pragmatics of SAT\n  (PoS 2024, see https://www.pragmaticsofssat.org/2024/ )",
      "pdf_url": "http://arxiv.org/pdf/2410.15897v1",
      "published_date": "2024-10-21 11:21:21 UTC",
      "updated_date": "2024-10-21 11:21:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:30:38.189624"
    },
    {
      "arxiv_id": "2410.15889v1",
      "title": "Model Mimic Attack: Knowledge Distillation for Provably Transferable Adversarial Examples",
      "title_zh": "翻译失败",
      "authors": [
        "Kirill Lukyanov",
        "Andrew Perminov",
        "Denis Turdakov",
        "Mikhail Pautov"
      ],
      "abstract": "The vulnerability of artificial neural networks to adversarial perturbations\nin the black-box setting is widely studied in the literature. The majority of\nattack methods to construct these perturbations suffer from an impractically\nlarge number of queries required to find an adversarial example. In this work,\nwe focus on knowledge distillation as an approach to conduct transfer-based\nblack-box adversarial attacks and propose an iterative training of the\nsurrogate model on an expanding dataset. This work is the first, to our\nknowledge, to provide provable guarantees on the success of knowledge\ndistillation-based attack on classification neural networks: we prove that if\nthe student model has enough learning capabilities, the attack on the teacher\nmodel is guaranteed to be found within the finite number of distillation\niterations.",
      "tldr_zh": "该论文探讨了神经网络在黑盒设置(black-box setting)下对对抗示例(adversarial examples)的易受攻击性问题，并提出了一种基于知识蒸馏(knowledge distillation)的攻击方法，以减少所需查询次数。方法涉及在扩展数据集上迭代训练代理模型(surrogate model)，从而实现可转移的对抗攻击。该研究首次提供了可证明的保证：如果学生模型具备足够的学习能力，则对教师模型的攻击可在有限的蒸馏迭代中成功。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15889v1",
      "published_date": "2024-10-21 11:06:56 UTC",
      "updated_date": "2024-10-21 11:06:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:30:49.690541"
    },
    {
      "arxiv_id": "2410.15885v1",
      "title": "How to Build a Pre-trained Multimodal model for Simultaneously Chatting and Decision-making?",
      "title_zh": "如何构建一个预训练的多模态模型，用于同时聊天和决策？",
      "authors": [
        "Zuojin Tang",
        "Bin Hu",
        "Chenyang Zhao",
        "De Ma",
        "Gang Pan",
        "Bin Liu"
      ],
      "abstract": "Existing large pre-trained models typically map text input to text output in\nan end-to-end manner, such as ChatGPT, or map a segment of text input to a\nhierarchy of action decisions, such as OpenVLA. However, humans can\nsimultaneously generate text and actions when receiving specific input signals.\nFor example, a driver can make precise driving decisions while conversing with\na friend in the passenger seat. Motivated by this observation, we consider the\nfollowing question in this work: is it possible to construct a pre-trained\nmodel that can provide both language interaction and precise decision-making\ncapabilities in dynamic open scenarios. We provide a definitive answer to this\nquestion by developing a new model architecture termed Visual Language Action\nmodel for Chatting and Decision Making (VLA4CD), and further demonstrating its\nperformance in challenging autonomous driving tasks. Specifically, we leverage\nLoRA to fine-tune a pre-trained LLM with data of multiple modalities covering\nlanguage, visual, and action. Unlike the existing LoRA operations used for LLM\nfine-tuning, we have designed new computational modules and training cost\nfunctions for VLA4CD. These designs enable VLA4CD to provide continuous-valued\naction decisions while outputting text responses. In contrast, existing LLMs\ncan only output text responses, and current VLA models can only output action\ndecisions. Moreover, these VLA models handle action data by discretizing and\nthen tokenizing the discretized actions, a method unsuitable for complex\ndecision-making tasks involving high-dimensional continuous-valued action\nvectors, such as autonomous driving. The experimental results on CARLA validate\nthat: (1) our proposed model construction method is effective; (2) compared to\nthe SOTA VLA model, VLA4CD can provide more accurate real-time decision-making\nwhile retaining the text interaction capability inherent to LLMs.",
      "tldr_zh": "本研究探讨如何构建一个预训练的多模态模型，能够同时实现语言交互和精确决策，灵感来源于人类能同时生成文本和动作（如驾驶时聊天）。他们提出 VLA4CD（Visual Language Action model for Chatting and Decision Making）架构，通过 LoRA 微调预训练的 LLM，结合语言、视觉和动作多模态数据，并设计新计算模块和训练损失函数，使模型能输出文本响应和连续值动作决策。不同于现有模型（如 ChatGPT 只输出文本，OpenVLA 只处理动作），VLA4CD 适用于高维连续任务，如自动驾驶。在 CARLA 实验中，VLA4CD 比 SOTA VLA 模型提供更准确的实时决策，同时保留了 LLM 的文本交互能力，验证了该方法的有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15885v1",
      "published_date": "2024-10-21 11:02:42 UTC",
      "updated_date": "2024-10-21 11:02:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:31:02.930767"
    },
    {
      "arxiv_id": "2410.15884v1",
      "title": "Using GPT Models for Qualitative and Quantitative News Analytics in the 2024 US Presidental Election Process",
      "title_zh": "利用 GPT 模型进行 2024 年美国",
      "authors": [
        "Bohdan M. Pavlyshenko"
      ],
      "abstract": "The paper considers an approach of using Google Search API and GPT-4o model\nfor qualitative and quantitative analyses of news through retrieval-augmented\ngeneration (RAG). This approach was applied to analyze news about the 2024 US\npresidential election process. Different news sources for different time\nperiods have been analyzed. Quantitative scores generated by GPT model have\nbeen analyzed using Bayesian regression to derive trend lines. The\ndistributions found for the regression parameters allow for the analysis of\nuncertainty in the election process. The obtained results demonstrate that\nusing the GPT models for news analysis, one can get informative analytics and\nprovide key insights that can be applied in further analyses of election\nprocesses.",
      "tldr_zh": "本文提出一种使用 Google Search API 和 GPT-4o 模型结合检索增强生成 (RAG) 技术的方法，对2024年美国总统选举新闻进行定性和定量分析。研究通过分析不同新闻来源和时间段，利用 GPT 模型生成的定量分数，并应用 Bayesian regression 分析趋势线和选举过程的不确定性。结果显示，该方法能提供信息丰富的分析洞见，有助于进一步的选举过程研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15884v1",
      "published_date": "2024-10-21 11:02:18 UTC",
      "updated_date": "2024-10-21 11:02:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:31:13.202033"
    },
    {
      "arxiv_id": "2410.15881v1",
      "title": "MI-VisionShot: Few-shot adaptation of vision-language models for slide-level classification of histopathological images",
      "title_zh": "翻译失败",
      "authors": [
        "Pablo Meseguer",
        "Rocío del Amor",
        "Valery Naranjo"
      ],
      "abstract": "Vision-language supervision has made remarkable strides in learning visual\nrepresentations from textual guidance. In digital pathology, vision-language\nmodels (VLM), pre-trained on curated datasets of histological image-captions,\nhave been adapted to downstream tasks, such as region of interest\nclassification. Zero-shot transfer for slide-level prediction has been\nformulated by MI-Zero, but it exhibits high variability depending on the\ntextual prompts. Inspired by prototypical learning, we propose MI-VisionShot, a\ntraining-free adaptation method on top of VLMs to predict slide-level labels in\nfew-shot learning scenarios. Our framework takes advantage of the excellent\nrepresentation learning of VLM to create prototype-based classifiers under a\nmultiple-instance setting by retrieving the most discriminative patches within\neach slide. Experimentation through different settings shows the ability of\nMI-VisionShot to surpass zero-shot transfer with lower variability, even in\nlow-shot scenarios. Code coming soon at\nthttps://github.com/cvblab/MIVisionShot.",
      "tldr_zh": "本文提出 MI-VisionShot，一种无训练适应方法，用于视觉语言模型(VLM)在组织病理图像的幻灯片级分类中的少样本学习场景。该框架借鉴原型学习，通过在多实例设置下检索每个幻灯片中最具区分性的 patches，创建基于原型的分类器，以提高预测的准确性和稳定性。实验结果显示，MI-VisionShot 超越了零样本转移方法，具有更低的变异性，即使在低样本条件下也能表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Manuscript accepted for oral presentation at KES-InnovationInMedicine\n  2024 held on Madeira, Portugal",
      "pdf_url": "http://arxiv.org/pdf/2410.15881v1",
      "published_date": "2024-10-21 11:01:20 UTC",
      "updated_date": "2024-10-21 11:01:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:31:26.108300"
    },
    {
      "arxiv_id": "2410.15876v3",
      "title": "FlickerFusion: Intra-trajectory Domain Generalizing Multi-Agent RL",
      "title_zh": "翻译失败",
      "authors": [
        "Woosung Koh",
        "Wonbeen Oh",
        "Siyeol Kim",
        "Suhin Shin",
        "Hyeongjin Kim",
        "Jaein Jang",
        "Junghyun Lee",
        "Se-Young Yun"
      ],
      "abstract": "Multi-agent reinforcement learning has demonstrated significant potential in\naddressing complex cooperative tasks across various real-world applications.\nHowever, existing MARL approaches often rely on the restrictive assumption that\nthe number of entities (e.g., agents, obstacles) remains constant between\ntraining and inference. This overlooks scenarios where entities are dynamically\nremoved or added during the inference trajectory -- a common occurrence in\nreal-world environments like search and rescue missions and dynamic combat\nsituations. In this paper, we tackle the challenge of intra-trajectory dynamic\nentity composition under zero-shot out-of-domain (OOD) generalization, where\nsuch dynamic changes cannot be anticipated beforehand. Our empirical studies\nreveal that existing MARL methods suffer significant performance degradation\nand increased uncertainty in these scenarios. In response, we propose\nFlickerFusion, a novel OOD generalization method that acts as a universally\napplicable augmentation technique for MARL backbone methods. FlickerFusion\nstochastically drops out parts of the observation space, emulating being\nin-domain when inferenced OOD. The results show that FlickerFusion not only\nachieves superior inference rewards but also uniquely reduces uncertainty\nvis-\\`a-vis the backbone, compared to existing methods. Benchmarks,\nimplementations, and model weights are organized and open-sourced at\nflickerfusion305.github.io, accompanied by ample demo video renderings.",
      "tldr_zh": "本研究针对 Multi-Agent RL 在动态环境下（如搜索救援或战斗场景）面临的挑战，解决了 intra-trajectory 实体数量变化下的零样本 OOD 泛化问题，因为现有方法假设实体不变，导致性能下降。论文提出 FlickerFusion，一种通用增强技术，通过随机丢弃观察空间来模拟动态变化，从而提升模型在 OOD 场景下的适应性。实验结果表明，FlickerFusion 不仅实现了更高的推理奖励，还显著降低了不确定性，并开源了基准、实现和模型权重以促进进一步研究。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS '24 Open-World Agents Workshop",
      "pdf_url": "http://arxiv.org/pdf/2410.15876v3",
      "published_date": "2024-10-21 10:57:45 UTC",
      "updated_date": "2024-12-03 05:59:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:33:31.431262"
    },
    {
      "arxiv_id": "2410.15859v3",
      "title": "Mesa-Extrapolation: A Weave Position Encoding Method for Enhanced Extrapolation in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Xin Ma",
        "Yang Liu",
        "Jingjing Liu",
        "Xiaoxu Ma"
      ],
      "abstract": "Large language models (LLMs), although having revolutionized many fields,\nstill suffer from the challenging extrapolation problem, where the inference\nability of LLMs sharply declines beyond their max training lengths. In this\nwork, we conduct a theoretical analysis to better understand why No Position\nEncoding (NoPE) fails outside its effective range, as well as examining the\npower of Position Encoding (PE) in this context. Our findings reveal that with\nmeticulous weave position, PE can indeed be extended beyond effective range.\nOur theorems establish that LLMs equipped with weave PE can achieve improved\nextrapolation performance without additional cost. Furthermore, we introduce a\nnovel weave PE method, Mesa-Extrapolation, which utilizes a chunk-based\ntriangular attention matrix and applies Stair PE to manage the final chunk.\nThis method not only retains competitive performance but also offers\nsubstantial benefits such as significantly reduced memory demand and faster\ninference speed. Extensive experiments validate the effectiveness of\nMesa-Extrapolation, demonstrating its potential as a scalable solution to\nenhancing LLMs applicative reach. Our code is available at\n\\url{https://github.com/soacker/Mesa-Extrapolation}.",
      "tldr_zh": "本研究分析了大型语言模型 (LLMs) 在超出最大训练长度时面临的外推问题，揭示了 No Position Encoding (NoPE) 的失败原因，并证明 Position Encoding (PE) 通过精确的 weave position 可以扩展其有效范围。论文提出了一种新方法 Mesa-Extrapolation，利用基于 chunk 的 triangular attention matrix 和 Stair PE 来处理最后一个 chunk，从而提升 LLMs 的外推性能，同时显著减少内存需求和加快推理速度。实验结果显示，该方法在广泛测试中表现出色，作为一种可扩展的解决方案，有望扩展 LLMs 的应用范围。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by NeurIPS 2024; 13 pages and 30 pages appendix;",
      "pdf_url": "http://arxiv.org/pdf/2410.15859v3",
      "published_date": "2024-10-21 10:39:05 UTC",
      "updated_date": "2024-10-24 10:29:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:31:49.732802"
    },
    {
      "arxiv_id": "2410.15847v1",
      "title": "Random Token Fusion for Multi-View Medical Diagnosis",
      "title_zh": "随机标记融合用于多视图医疗诊断",
      "authors": [
        "Jingyu Guo",
        "Christos Matsoukas",
        "Fredrik Strand",
        "Kevin Smith"
      ],
      "abstract": "In multi-view medical diagnosis, deep learning-based models often fuse\ninformation from different imaging perspectives to improve diagnostic\nperformance. However, existing approaches are prone to overfitting and rely\nheavily on view-specific features, which can lead to trivial solutions. In this\nwork, we introduce Random Token Fusion (RTF), a novel technique designed to\nenhance multi-view medical image analysis using vision transformers. By\nintegrating randomness into the feature fusion process during training, RTF\naddresses the issue of overfitting and enhances the robustness and accuracy of\ndiagnostic models without incurring any additional cost at inference. We\nvalidate our approach on standard mammography and chest X-ray benchmark\ndatasets. Through extensive experiments, we demonstrate that RTF consistently\nimproves the performance of existing fusion methods, paving the way for a new\ngeneration of multi-view medical foundation models.",
      "tldr_zh": "这篇论文提出了 Random Token Fusion (RTF)，一种创新技术，用于多视图医疗诊断中融合不同成像视角的信息，以解决现有方法容易过拟合和过度依赖视图特定特征的问题。RTF 通过在训练过程中引入随机性到特征融合中，利用 vision transformers 提升模型的鲁棒性和准确性，同时不增加推理阶段的计算成本。在乳腺X光和胸部X光基准数据集上的广泛实验显示，RTF 显著改善了现有融合方法的性能，为新一代多视图医疗基础模型的开发铺平道路。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Originally published at the NeurIPS 2024 Workshop on Advancements In\n  Medical Foundation Models: Explainability, Robustness, Security, and Beyond\n  (AIM-FM)",
      "pdf_url": "http://arxiv.org/pdf/2410.15847v1",
      "published_date": "2024-10-21 10:19:45 UTC",
      "updated_date": "2024-10-21 10:19:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:33:52.035572"
    },
    {
      "arxiv_id": "2410.15837v1",
      "title": "Long-distance Geomagnetic Navigation in GNSS-denied Environments with Deep Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Wenqi Bai",
        "Xiaohui Zhang",
        "Shiliang Zhang",
        "Songnan Yang",
        "Yushuai Li",
        "Tingwen Huang"
      ],
      "abstract": "Geomagnetic navigation has drawn increasing attention with its capacity in\nnavigating through complex environments and its independence from external\nnavigation services like global navigation satellite systems (GNSS). Existing\nstudies on geomagnetic navigation, i.e., matching navigation and bionic\nnavigation, rely on pre-stored map or extensive searches, leading to limited\napplicability or reduced navigation efficiency in unexplored areas. To address\nthe issues with geomagnetic navigation in areas where GNSS is unavailable, this\npaper develops a deep reinforcement learning (DRL)-based mechanism, especially\nfor long-distance geomagnetic navigation. The designed mechanism trains an\nagent to learn and gain the magnetoreception capacity for geomagnetic\nnavigation, rather than using any pre-stored map or extensive and expensive\nsearching approaches. Particularly, we integrate the geomagnetic gradient-based\nparallel approach into geomagnetic navigation. This integration mitigates the\nover-exploration of the learning agent by adjusting the geomagnetic gradient,\nsuch that the obtained gradient is aligned towards the destination. We explore\nthe effectiveness of the proposed approach via detailed numerical simulations,\nwhere we implement twin delayed deep deterministic policy gradient (TD3) in\nrealizing the proposed approach. The results demonstrate that our approach\noutperforms existing metaheuristic and bionic navigation methods in\nlong-distance missions under diverse navigation conditions.",
      "tldr_zh": "本论文针对GNSS-denied环境中的长距离地磁导航问题，提出了一种基于Deep Reinforcement Learning (DRL)的机制，以解决现有方法依赖预存地图或大量搜索的局限性。该机制通过训练代理学习磁感应能力，并整合地磁梯度-based parallel approach来调整梯度方向，引导代理高效朝向目的地，而无需预存地图或广泛搜索。实验结果显示，使用Twin Delayed Deep Deterministic Policy Gradient (TD3)算法的该方法在各种导航条件下，显著优于现有元启发式和仿生导航方法。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15837v1",
      "published_date": "2024-10-21 09:57:42 UTC",
      "updated_date": "2024-10-21 09:57:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:34:03.192244"
    },
    {
      "arxiv_id": "2410.15828v1",
      "title": "LLM4GRN: Discovering Causal Gene Regulatory Networks with LLMs -- Evaluation through Synthetic Data Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Tejumade Afonja",
        "Ivaxi Sheth",
        "Ruta Binkyte",
        "Waqar Hanif",
        "Thomas Ulas",
        "Matthias Becker",
        "Mario Fritz"
      ],
      "abstract": "Gene regulatory networks (GRNs) represent the causal relationships between\ntranscription factors (TFs) and target genes in single-cell RNA sequencing\n(scRNA-seq) data. Understanding these networks is crucial for uncovering\ndisease mechanisms and identifying therapeutic targets. In this work, we\ninvestigate the potential of large language models (LLMs) for GRN discovery,\nleveraging their learned biological knowledge alone or in combination with\ntraditional statistical methods. We develop a task-based evaluation strategy to\naddress the challenge of unavailable ground truth causal graphs. Specifically,\nwe use the GRNs suggested by LLMs to guide causal synthetic data generation and\ncompare the resulting data against the original dataset. Our statistical and\nbiological assessments show that LLMs can support statistical modeling and data\nsynthesis for biological research.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）在发现基因调控网络（GRNs）中的潜力，GRNs 描述了转录因子（TFs）和目标基因在单细胞 RNA 测序（scRNA-seq）数据中的因果关系，以揭示疾病机制和治疗靶点。作者开发了 LLM4GRN 方法，使用 LLMs 的生物学知识单独或结合传统统计方法，并通过任务导向的评估策略生成因果合成数据，与原始数据集进行比较。结果显示，LLMs 能够有效支持统计建模和数据合成，提升生物研究的可行性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15828v1",
      "published_date": "2024-10-21 09:46:37 UTC",
      "updated_date": "2024-10-21 09:46:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:34:15.476115"
    },
    {
      "arxiv_id": "2410.15821v1",
      "title": "The effect of fine-tuning on language model toxicity",
      "title_zh": "微调对语言模型毒性的影响",
      "authors": [
        "Will Hawkins",
        "Brent Mittelstadt",
        "Chris Russell"
      ],
      "abstract": "Fine-tuning language models has become increasingly popular following the\nproliferation of open models and improvements in cost-effective parameter\nefficient fine-tuning. However, fine-tuning can influence model properties such\nas safety. We assess how fine-tuning can impact different open models'\npropensity to output toxic content. We assess the impacts of fine-tuning Gemma,\nLlama, and Phi models on toxicity through three experiments. We compare how\ntoxicity is reduced by model developers during instruction-tuning. We show that\nsmall amounts of parameter-efficient fine-tuning on developer-tuned models via\nlow-rank adaptation on a non-adversarial dataset can significantly alter these\nresults across models. Finally, we highlight the impact of this in the wild,\ndemonstrating how toxicity rates of models fine-tuned by community contributors\ncan deviate in hard-to-predict ways.",
      "tldr_zh": "这篇论文探讨了微调(fine-tuning)对语言模型(language models)输出毒性内容的影响，评估了Gemma、Llama和Phi等模型的安全性变化。研究通过三个实验比较了模型开发者在指令微调(instruction-tuning)过程中减少毒性的效果，并展示了使用低秩适应(low-rank adaptation)在非对抗数据集上进行少量参数高效微调如何显著改变这些结果。最终发现，社区贡献者微调的模型可能导致毒性率以难以预测的方式偏离，强调了微调对模型安全性的潜在风险。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "To be presented at NeurIPS 2024 Safe Generative AI Workshop",
      "pdf_url": "http://arxiv.org/pdf/2410.15821v1",
      "published_date": "2024-10-21 09:39:09 UTC",
      "updated_date": "2024-10-21 09:39:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:34:27.141190"
    },
    {
      "arxiv_id": "2410.15820v1",
      "title": "MAC Revivo: Artificial Intelligence Paves the Way",
      "title_zh": "翻译失败",
      "authors": [
        "Jinzhe Pan",
        "Jingqing Wang",
        "Zelin Yun",
        "Zhiyong Xiao",
        "Yuehui Ouyang",
        "Wenchi Cheng",
        "Wei Zhang"
      ],
      "abstract": "The vast adoption of Wi-Fi and/or Bluetooth capabilities in Internet of\nThings (IoT) devices, along with the rapid growth of deployed smart devices,\nhas caused significant interference and congestion in the industrial,\nscientific, and medical (ISM) bands. Traditional Wi-Fi Medium Access Control\n(MAC) design faces significant challenges in managing increasingly complex\nwireless environments while ensuring network Quality of Service (QoS)\nperformance. This paper explores the potential integration of advanced\nArtificial Intelligence (AI) methods into the design of Wi-Fi MAC protocols. We\npropose AI-MAC, an innovative approach that employs machine learning algorithms\nto dynamically adapt to changing network conditions, optimize channel access,\nmitigate interference, and ensure deterministic latency. By intelligently\npredicting and managing interference, AI-MAC aims to provide a robust solution\nfor next generation of Wi-Fi networks, enabling seamless connectivity and\nenhanced QoS. Our experimental results demonstrate that AI-MAC significantly\nreduces both interference and latency, paving the way for more reliable and\nefficient wireless communications in the increasingly crowded ISM band.",
      "tldr_zh": "本文探讨了物联网（IoT）设备对 Wi-Fi 和 Bluetooth 的广泛采用导致的工业、科学和医疗（ISM）频段干扰和拥塞问题，传统 Wi-Fi Medium Access Control (MAC) 协议在管理复杂无线环境和确保 Quality of Service (QoS) 性能方面面临挑战。论文提出 AI-MAC，一种创新方法，利用机器学习算法动态适应网络条件、优化信道访问、缓解干扰并实现确定性延迟。通过实验验证，AI-MAC 显著降低了干扰和延迟，为下一代 Wi-Fi 网络提供更可靠、高效的无线通信解决方案。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15820v1",
      "published_date": "2024-10-21 09:36:53 UTC",
      "updated_date": "2024-10-21 09:36:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:34:40.192098"
    },
    {
      "arxiv_id": "2410.15819v1",
      "title": "LiMTR: Time Series Motion Prediction for Diverse Road Users through Multimodal Feature Integration",
      "title_zh": "翻译失败",
      "authors": [
        "Camiel Oerlemans",
        "Bram Grooten",
        "Michiel Braat",
        "Alaa Alassi",
        "Emilia Silvas",
        "Decebal Constantin Mocanu"
      ],
      "abstract": "Predicting the behavior of road users accurately is crucial to enable the\nsafe operation of autonomous vehicles in urban or densely populated areas.\nTherefore, there has been a growing interest in time series motion prediction\nresearch, leading to significant advancements in state-of-the-art techniques in\nrecent years. However, the potential of using LiDAR data to capture more\ndetailed local features, such as a person's gaze or posture, remains largely\nunexplored. To address this, we develop a novel multimodal approach for motion\nprediction based on the PointNet foundation model architecture, incorporating\nlocal LiDAR features. Evaluation on the Waymo Open Dataset shows a performance\nimprovement of 6.20% and 1.58% in minADE and mAP respectively, when integrated\nand compared with the previous state-of-the-art MTR. We open-source the code of\nour LiMTR model.",
      "tldr_zh": "这篇论文提出了 LiMTR 模型，用于准确预测多样化道路用户的时序运动，旨在提升自动驾驶车辆在城市环境的运行安全。模型基于 PointNet 架构，创新性地整合了本地 LiDAR 特征（如人的注视或姿势），实现多模态特征融合，以捕捉更详细的运动信息。在 Waymo Open Dataset 的评估中，LiMTR 相比之前的 MTR 模型提高了 6.20% 在 minADE 和 1.58% 在 mAP 的性能，并开源了代码以促进进一步研究。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at the NeurIPS 2024 workshop Time Series in the Age of Large\n  Models. Code available at https://github.com/Cing2/LiMTR",
      "pdf_url": "http://arxiv.org/pdf/2410.15819v1",
      "published_date": "2024-10-21 09:35:57 UTC",
      "updated_date": "2024-10-21 09:35:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:34:51.960775"
    },
    {
      "arxiv_id": "2410.15814v1",
      "title": "Kaninfradet3D:A Road-side Camera-LiDAR Fusion 3D Perception Model based on Nonlinear Feature Extraction and Intrinsic Correlation",
      "title_zh": "翻译失败",
      "authors": [
        "Pei Liu",
        "Nanfang Zheng",
        "Yiqun Li",
        "Junlan Chen",
        "Ziyuan Pu"
      ],
      "abstract": "With the development of AI-assisted driving, numerous methods have emerged\nfor ego-vehicle 3D perception tasks, but there has been limited research on\nroadside perception. With its ability to provide a global view and a broader\nsensing range, the roadside perspective is worth developing. LiDAR provides\nprecise three-dimensional spatial information, while cameras offer semantic\ninformation. These two modalities are complementary in 3D detection. However,\nadding camera data does not increase accuracy in some studies since the\ninformation extraction and fusion procedure is not sufficiently reliable.\nRecently, Kolmogorov-Arnold Networks (KANs) have been proposed as replacements\nfor MLPs, which are better suited for high-dimensional, complex data. Both the\ncamera and the LiDAR provide high-dimensional information, and employing KANs\nshould enhance the extraction of valuable features to produce better fusion\noutcomes. This paper proposes Kaninfradet3D, which optimizes the feature\nextraction and fusion modules. To extract features from complex\nhigh-dimensional data, the model's encoder and fuser modules were improved\nusing KAN Layers. Cross-attention was applied to enhance feature fusion, and\nvisual comparisons verified that camera features were more evenly integrated.\nThis addressed the issue of camera features being abnormally concentrated,\nnegatively impacting fusion. Compared to the benchmark, our approach shows\nimprovements of +9.87 mAP and +10.64 mAP in the two viewpoints of the TUMTraf\nIntersection Dataset and an improvement of +1.40 mAP in the roadside end of the\nTUMTraf V2X Cooperative Perception Dataset. The results indicate that\nKaninfradet3D can effectively fuse features, demonstrating the potential of\napplying KANs in roadside perception tasks.",
      "tldr_zh": "该论文提出Kaninfradet3D模型，用于道路侧摄像头和LiDAR的融合3D感知任务，旨在解决传统方法中信息提取和融合不可靠的问题。模型利用Kolmogorov-Arnold Networks (KANs)改进编码器和融合模块，进行非线性特征提取，并通过Cross-attention机制增强特征融合，确保摄像头特征更均匀整合。实验结果显示，在TUMTraf数据集上，模型分别在两个视角上提升+9.87 mAP和+10.64 mAP，在道路侧提升+1.40 mAP，证明了KANs在道路侧感知中的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15814v1",
      "published_date": "2024-10-21 09:28:42 UTC",
      "updated_date": "2024-10-21 09:28:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:35:03.989231"
    },
    {
      "arxiv_id": "2410.15805v1",
      "title": "RAG4ITOps: A Supervised Fine-Tunable and Comprehensive RAG Framework for IT Operations and Maintenance",
      "title_zh": "翻译失败",
      "authors": [
        "Tianyang Zhang",
        "Zhuoxuan Jiang",
        "Shengguang Bai",
        "Tianrui Zhang",
        "Lin Lin",
        "Yang Liu",
        "Jiawei Ren"
      ],
      "abstract": "With the ever-increasing demands on Question Answering (QA) systems for IT\noperations and maintenance, an efficient and supervised fine-tunable framework\nis necessary to ensure the data security, private deployment and continuous\nupgrading. Although Large Language Models (LLMs) have notably improved the\nopen-domain QA's performance, how to efficiently handle enterprise-exclusive\ncorpora and build domain-specific QA systems are still less-studied for\nindustrial applications. In this paper, we propose a general and comprehensive\nframework based on Retrieval Augmented Generation (RAG) and facilitate the\nwhole business process of establishing QA systems for IT operations and\nmaintenance. In accordance with the prevailing RAG method, our proposed\nframework, named with RAG4ITOps, composes of two major stages: (1) Models\nFine-tuning \\& Data Vectorization, and (2) Online QA System Process. At the\nStage 1, we leverage a contrastive learning method with two negative sampling\nstrategies to fine-tune the embedding model, and design the instruction\ntemplates to fine-tune the LLM with a Retrieval Augmented Fine-Tuning method.\nAt the Stage 2, an efficient process of QA system is built for serving. We\ncollect enterprise-exclusive corpora from the domain of cloud computing, and\nthe extensive experiments show that our method achieves superior results than\ncounterparts on two kinds of QA tasks. Our experiment also provide a case for\napplying the RAG4ITOps to real-world enterprise-level applications.",
      "tldr_zh": "该研究提出RAG4ITOps，一种基于Retrieval Augmented Generation (RAG)的全面框架，用于IT操作和维护的Question Answering (QA)系统。该框架包括两个阶段：(1) Models Fine-tuning & Data Vectorization，通过对比学习方法和负采样策略微调嵌入模型，并使用Retrieval Augmented Fine-Tuning设计指令模板微调Large Language Models (LLMs)；(2) Online QA System Process，构建高效的在线QA服务。实验使用云计算领域的企业专有语料显示，该方法在两种QA任务上优于对照组，并为实际企业应用提供可行案例。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by EMNLP 2024 Industry Track",
      "pdf_url": "http://arxiv.org/pdf/2410.15805v1",
      "published_date": "2024-10-21 09:22:29 UTC",
      "updated_date": "2024-10-21 09:22:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:35:15.548159"
    },
    {
      "arxiv_id": "2410.15804v1",
      "title": "Deep Learning and Data Augmentation for Detecting Self-Admitted Technical Debt",
      "title_zh": "翻译失败",
      "authors": [
        "Edi Sutoyo",
        "Paris Avgeriou",
        "Andrea Capiluppi"
      ],
      "abstract": "Self-Admitted Technical Debt (SATD) refers to circumstances where developers\nuse textual artifacts to explain why the existing implementation is not\noptimal. Past research in detecting SATD has focused on either identifying SATD\n(classifying SATD items as SATD or not) or categorizing SATD (labeling\ninstances as SATD that pertain to requirement, design, code, test debt, etc.).\nHowever, the performance of these approaches remains suboptimal, particularly\nfor specific types of SATD, such as test and requirement debt, primarily due to\nextremely imbalanced datasets. To address these challenges, we build on earlier\nresearch by utilizing BiLSTM architecture for the binary identification of SATD\nand BERT architecture for categorizing different types of SATD. Despite their\neffectiveness, both architectures struggle with imbalanced data. Therefore, we\nemploy a large language model data augmentation strategy to mitigate this\nissue. Furthermore, we introduce a two-step approach to identify and categorize\nSATD across various datasets derived from different artifacts. Our\ncontributions include providing a balanced dataset for future SATD researchers\nand demonstrating that our approach significantly improves SATD identification\nand categorization performance compared to baseline methods.",
      "tldr_zh": "本文研究了Self-Admitted Technical Debt (SATD)，即开发者在文本中解释代码不优化的情况，针对现有方法在识别和分类SATD时因数据集不平衡而表现不佳的问题。作者采用BiLSTM架构进行SATD的二元识别，以及BERT架构进行类型分类（如requirement、design、code或test debt），并引入大型语言模型的数据增强策略来缓解数据不平衡。最终，该两步方法在多个数据集上显著提升了SATD识别和分类性能，并提供了平衡数据集以支持未来研究。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted to be published at the 2024 31st Asia-Pacific Software\n  Engineering Conference (APSEC)",
      "pdf_url": "http://arxiv.org/pdf/2410.15804v1",
      "published_date": "2024-10-21 09:22:16 UTC",
      "updated_date": "2024-10-21 09:22:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:35:27.233914"
    },
    {
      "arxiv_id": "2410.15794v1",
      "title": "Habaek: High-performance water segmentation through dataset expansion and inductive bias optimization",
      "title_zh": "Habaek：通过数据集扩展和归纳偏差优化实现高性能水体分割",
      "authors": [
        "Hanseon Joo",
        "Eunji Lee",
        "Minjong Cheon"
      ],
      "abstract": "Water segmentation is critical to disaster response and water resource\nmanagement. Authorities may employ high-resolution photography to monitor\nrivers, lakes, and reservoirs, allowing for more proactive management in\nagriculture, industry, and conservation. Deep learning has improved flood\nmonitoring by allowing models like CNNs, U-Nets, and transformers to handle\nlarge volumes of satellite and aerial data. However, these models usually have\nsignificant processing requirements, limiting their usage in real-time\napplications. This research proposes upgrading the SegFormer model for water\nsegmentation by data augmentation with datasets such as ADE20K and RIWA to\nboost generalization. We examine how inductive bias affects attention-based\nmodels and discover that SegFormer performs better on bigger datasets. To\nfurther demonstrate the function of data augmentation, Low-Rank Adaptation\n(LoRA) is used to lower processing complexity while preserving accuracy. We\nshow that the suggested Habaek model outperforms current models in\nsegmentation, with an Intersection over Union (IoU) ranging from 0.91986 to\n0.94397. In terms of F1-score, recall, accuracy, and precision, Habaek performs\nbetter than rival models, indicating its potential for real-world applications.\nThis study highlights the need to enhance structures and include datasets for\neffective water segmentation.",
      "tldr_zh": "本研究提出 Habaek 模型，通过扩展数据集（如 ADE20K 和 RIWA）以及优化归纳偏差，来提升水分割任务的性能，旨在解决现有深度学习模型如 CNNs、U-Nets 和 transformers 在实时应用中的处理需求问题。方法包括升级 SegFormer 模型并采用 Low-Rank Adaptation (LoRA) 来降低计算复杂性，同时提高泛化能力。实验结果显示，Habaek 在水分割任务上优于现有模型，IoU 指标从 0.91986 到 0.94397，F1-score、recall、accuracy 和 precision 均有显著提升，具有潜在的灾害响应和水资源管理应用价值。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15794v1",
      "published_date": "2024-10-21 09:06:13 UTC",
      "updated_date": "2024-10-21 09:06:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:35:40.685722"
    },
    {
      "arxiv_id": "2410.15792v2",
      "title": "WildOcc: A Benchmark for Off-Road 3D Semantic Occupancy Prediction",
      "title_zh": "WildOcc：越野 3D 语义占用预测",
      "authors": [
        "Heng Zhai",
        "Jilin Mei",
        "Chen Min",
        "Liang Chen",
        "Fangzhou Zhao",
        "Yu Hu"
      ],
      "abstract": "3D semantic occupancy prediction is an essential part of autonomous driving,\nfocusing on capturing the geometric details of scenes. Off-road environments\nare rich in geometric information, therefore it is suitable for 3D semantic\noccupancy prediction tasks to reconstruct such scenes. However, most of\nresearches concentrate on on-road environments, and few methods are designed\nfor off-road 3D semantic occupancy prediction due to the lack of relevant\ndatasets and benchmarks. In response to this gap, we introduce WildOcc, to our\nknowledge, the first benchmark to provide dense occupancy annotations for\noff-road 3D semantic occupancy prediction tasks. A ground truth generation\npipeline is proposed in this paper, which employs a coarse-to-fine\nreconstruction to achieve a more realistic result. Moreover, we introduce a\nmulti-modal 3D semantic occupancy prediction framework, which fuses\nspatio-temporal information from multi-frame images and point clouds at voxel\nlevel. In addition, a cross-modality distillation function is introduced, which\ntransfers geometric knowledge from point clouds to image features.",
      "tldr_zh": "这篇论文针对off-road环境的3D semantic occupancy prediction问题，引入了WildOcc，这是第一个提供密集占用注释的基准，以填补现有研究的空白。论文提出了一种ground truth生成管道，使用coarse-to-fine重建方法来实现更真实的场景重建。此外，他们设计了一个多模态框架，在voxel级别融合多帧图像和点云的空间-时间信息，并通过cross-modality distillation函数从点云向图像特征转移几何知识，从而提升预测性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15792v2",
      "published_date": "2024-10-21 09:02:40 UTC",
      "updated_date": "2024-10-27 09:11:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:35:52.308218"
    },
    {
      "arxiv_id": "2410.15787v2",
      "title": "Arithmetic Transformers Can Length-Generalize in Both Operand Length and Count",
      "title_zh": "翻译失败",
      "authors": [
        "Hanseul Cho",
        "Jaeyoung Cha",
        "Srinadh Bhojanapalli",
        "Chulhee Yun"
      ],
      "abstract": "Transformers often struggle with length generalization, meaning they fail to\ngeneralize to sequences longer than those encountered during training. While\narithmetic tasks are commonly used to study length generalization, certain\ntasks are considered notoriously difficult, e.g., multi-operand addition\n(requiring generalization over both the number of operands and their lengths)\nand multiplication (requiring generalization over both operand lengths). In\nthis work, we achieve approximately 2-3x length generalization on both tasks,\nwhich is the first such achievement in arithmetic Transformers. We design\ntask-specific scratchpads enabling the model to focus on a fixed number of\ntokens per each next-token prediction step, and apply multi-level versions of\n\\Position Coupling (Cho et al., 2024; McLeish et al., 2024) to let Transformers\nknow the right position to attend to. On the theory side, we prove that a\n1-layer Transformer using our method can solve multi-operand addition, up to\noperand length and operand count that are exponential in embedding dimension.",
      "tldr_zh": "本文研究Transformers在算术任务上的长度泛化问题，首次实现了多操作数加法和乘法在操作数长度和数量上约2-3倍的泛化效果。研究者设计了任务特定的scratchpads，让模型在每个下一步预测时专注于固定数量的tokens，并应用多级Position Coupling技术，以指导Transformer关注正确的位置。理论上，他们证明了一个1-layer Transformer使用此方法能解决多操作数加法，其操作数长度和数量可指数级增长到嵌入维度，从而提升了模型的泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "44 pages, 20 figures, 26 tables, accepted to ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.15787v2",
      "published_date": "2024-10-21 08:49:51 UTC",
      "updated_date": "2025-04-17 08:18:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:36:03.980615"
    },
    {
      "arxiv_id": "2410.15780v1",
      "title": "An Efficient System for Automatic Map Storytelling -- A Case Study on Historical Maps",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyi Liu",
        "Claudio Affolter",
        "Sidi Wu",
        "Yizi Chen",
        "Lorenz Hurni"
      ],
      "abstract": "Historical maps provide valuable information and knowledge about the past.\nHowever, as they often feature non-standard projections, hand-drawn styles, and\nartistic elements, it is challenging for non-experts to identify and interpret\nthem. While existing image captioning methods have achieved remarkable success\non natural images, their performance on maps is suboptimal as maps are\nunderrepresented in their pre-training process. Despite the recent advance of\nGPT-4 in text recognition and map captioning, it still has a limited\nunderstanding of maps, as its performance wanes when texts (e.g., titles and\nlegends) in maps are missing or inaccurate. Besides, it is inefficient or even\nimpractical to fine-tune the model with users' own datasets. To address these\nproblems, we propose a novel and lightweight map-captioning counterpart.\nSpecifically, we fine-tune the state-of-the-art vision-language model CLIP to\ngenerate captions relevant to historical maps and enrich the captions with\nGPT-3.5 to tell a brief story regarding where, what, when and why of a given\nmap. We propose a novel decision tree architecture to only generate captions\nrelevant to the specified map type. Our system shows invariance to text\nalterations in maps. The system can be easily adapted and extended to other map\ntypes and scaled to a larger map captioning system. The code is open-sourced at\nhttps://github.com/claudaff/automatic-map-storytelling.",
      "tldr_zh": "本研究针对历史地图的非标准特征（如手绘风格和艺术元素）导致的识别难题，提出一个高效的自动地图故事生成系统，作为历史地图的案例研究。  \n该系统通过微调视觉语言模型 CLIP 来生成与地图相关的描述，并结合 GPT-3.5 丰富内容，讲述地图的 where、what、when 和 why，从而创建简短的故事。  \n此外，系统采用决策树架构确保描述仅针对指定地图类型，并展示了对文本改变的鲁棒性，便于扩展到其他地图类型，并已开源代码。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15780v1",
      "published_date": "2024-10-21 08:45:26 UTC",
      "updated_date": "2024-10-21 08:45:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:36:16.272301"
    },
    {
      "arxiv_id": "2410.15778v2",
      "title": "Reducing Hallucinations in Vision-Language Models via Latent Space Steering",
      "title_zh": "通过潜在空间引导减少视觉语言模型中的幻觉",
      "authors": [
        "Sheng Liu",
        "Haotian Ye",
        "Lei Xing",
        "James Zou"
      ],
      "abstract": "Hallucination poses a challenge to the deployment of large vision-language\nmodels (LVLMs) in applications. Unlike in large language models (LLMs),\nhallucination in LVLMs often arises from misalignments between visual inputs\nand textual outputs. This paper investigates the underlying mechanisms of\nhallucination, focusing on the unique structure of LVLMs that distinguishes\nthem from large language models (LLMs). We identify that hallucinations often\narise from the sensitivity of text decoders to vision inputs, a natural\nphenomenon when image encoders and text decoders are pre-trained separately.\nInspired by this, we introduce Visual and Textual Intervention (VTI), a novel\ntechnique designed to reduce hallucinations by steering latent space\nrepresentations during inference to enhance the stability of vision features.\nAs a task-agnostic test-time intervention, VTI can be easily applied to any\nproblem without additional cost. Extensive experiments demonstrate that it can\neffectively reduce hallucinations and outperform baseline methods across\nmultiple metrics, highlighting the critical role of vision feature stability in\nLVLMs.",
      "tldr_zh": "这篇论文探讨了视觉语言模型 (LVLMs) 中幻觉 (hallucination) 问题，主要由于视觉输入与文本输出之间的不匹配，以及文本解码器对视觉输入的敏感性。作者提出 Visual and Textual Intervention (VTI) 技术，通过潜在空间转向 (latent space steering) 来操纵潜在表示，提升视觉特征的稳定性，并作为任务无关的测试时干预方法，易于应用且无需额外成本。实验结果显示，VTI 在多个指标上优于基线方法，有效减少了幻觉，并强调了视觉特征稳定性的关键作用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "21 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.15778v2",
      "published_date": "2024-10-21 08:42:30 UTC",
      "updated_date": "2024-10-22 05:01:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:36:28.324899"
    },
    {
      "arxiv_id": "2410.15770v1",
      "title": "A roadmap for generative mapping: unlocking the power of generative AI for map-making",
      "title_zh": "翻译失败",
      "authors": [
        "Sidi Wu",
        "Katharina Henggeler",
        "Yizi Chen",
        "Lorenz Hurni"
      ],
      "abstract": "Maps are broadly relevant across various fields, serving as valuable tools\nfor presenting spatial phenomena and communicating spatial knowledge. However,\nmap-making is still largely confined to those with expertise in GIS and\ncartography due to the specialized software and complex workflow involved, from\ndata processing to visualization. While generative AI has recently demonstrated\nits remarkable capability in creating various types of content and its wide\naccessibility to the general public, its potential in generating maps is yet to\nbe fully realized. This paper highlights the key applications of generative AI\nin map-making, summarizes recent advancements in generative AI, identifies the\nspecific technologies required and the challenges of using current methods, and\nprovides a roadmap for developing a generative mapping system (GMS) to make\nmap-making more accessible.",
      "tldr_zh": "这篇论文探讨了生成式AI在制图领域的潜力，指出传统地图制作因依赖GIS和制图专业知识而难以普及。论文总结了生成式AI的关键应用和最新进展，识别了当前方法的挑战和所需技术，如数据处理和可视化优化。最终，它提供了一个开发生成式地图系统(GMS)的路线图，以使地图制作更易访问并惠及大众。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15770v1",
      "published_date": "2024-10-21 08:29:43 UTC",
      "updated_date": "2024-10-21 08:29:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:36:38.968975"
    },
    {
      "arxiv_id": "2410.15768v1",
      "title": "Learning to Synthesize Graphics Programs for Geometric Artworks",
      "title_zh": "翻译失败",
      "authors": [
        "Qi Bing",
        "Chaoyi Zhang",
        "Weidong Cai"
      ],
      "abstract": "Creating and understanding art has long been a hallmark of human ability.\nWhen presented with finished digital artwork, professional graphic artists can\nintuitively deconstruct and replicate it using various drawing tools, such as\nthe line tool, paint bucket, and layer features, including opacity and blending\nmodes. While most recent research in this field has focused on art generation,\nproposing a range of methods, these often rely on the concept of artwork being\nrepresented as a final image. To bridge the gap between pixel-level results and\nthe actual drawing process, we present an approach that treats a set of drawing\ntools as executable programs. This method predicts a sequence of steps to\nachieve the final image, allowing for understandable and resolution-independent\nreproductions under the usage of a set of drawing commands. Our experiments\ndemonstrate that our program synthesizer, Art2Prog, can comprehensively\nunderstand complex input images and reproduce them using high-quality\nexecutable programs. The experimental results evidence the potential of\nmachines to grasp higher-level information from images and generate compact\nprogram-level descriptions.",
      "tldr_zh": "本研究旨在弥合像素级艺术生成与实际绘图过程的差距，提出一种将绘图工具视为可执行程序的方法，允许机器预测步骤序列来复制数字艺术作品，从而实现可理解且分辨率独立的再现。研究引入了Art2Prog程序合成器，通过分析输入图像生成紧凑的程序级描述，包括使用线条工具、油漆桶和图层功能等。实验结果显示，Art2Prog能有效理解复杂几何艺术图像，并以高质量可执行程序输出，证明了机器从图像中提取高层信息的能力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "ICPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.15768v1",
      "published_date": "2024-10-21 08:28:11 UTC",
      "updated_date": "2024-10-21 08:28:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:36:51.342763"
    },
    {
      "arxiv_id": "2410.15764v2",
      "title": "LSCodec: Low-Bitrate and Speaker-Decoupled Discrete Speech Codec",
      "title_zh": "LSCodec：低比特率且说话者解耦的离散语音编解码器",
      "authors": [
        "Yiwei Guo",
        "Zhihan Li",
        "Chenpeng Du",
        "Hankun Wang",
        "Xie Chen",
        "Kai Yu"
      ],
      "abstract": "Although discrete speech tokens have exhibited strong potential for language\nmodel-based speech generation, their high bitrates and redundant timbre\ninformation restrict the development of such models. In this work, we propose\nLSCodec, a discrete speech codec that has both low bitrate and speaker\ndecoupling ability. LSCodec adopts a three-stage unsupervised training\nframework with a speaker perturbation technique. A continuous information\nbottleneck is first established, followed by vector quantization that produces\na discrete speaker-decoupled space. A discrete token vocoder finally refines\nacoustic details from LSCodec. By reconstruction experiments, LSCodec\ndemonstrates superior intelligibility and audio quality with only a single\ncodebook and smaller vocabulary size than baselines. The 25Hz version of\nLSCodec also achieves the lowest bitrate (0.25kbps) of codecs so far with\ndecent quality. Voice conversion evaluations prove the satisfactory speaker\ndisentanglement of LSCodec, and ablation study further verifies the\neffectiveness of the proposed training framework.",
      "tldr_zh": "本研究提出了一种低比特率且能分离说话者信息的离散语音编解码器 LSCodec，以解决现有离散语音令牌的高比特率和冗余音色问题。LSCodec 采用三阶段无监督训练框架，包括说话者扰动技术、先建立连续信息瓶颈、进行向量量化生成离散的说话者分离空间，以及使用离散令牌声码器细化声学细节。实验结果显示，LSCodec 在单代码本和更小词汇量下，实现了优越的可懂度和音频质量，其 25Hz 版本达到了最低比特率（0.25kbps）并保持良好性能；此外，语音转换评估证实了其说话者分离的有效性，消融研究进一步验证了训练框架的可靠性。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "5 pages, 2 figures, 4 tables. Demo page:\n  https://cantabile-kwok.github.io/LSCodec/",
      "pdf_url": "http://arxiv.org/pdf/2410.15764v2",
      "published_date": "2024-10-21 08:23:31 UTC",
      "updated_date": "2024-12-22 12:48:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:37:04.266178"
    },
    {
      "arxiv_id": "2410.15760v1",
      "title": "DeepIcon: A Hierarchical Network for Layer-wise Icon Vectorization",
      "title_zh": "翻译失败",
      "authors": [
        "Qi Bing",
        "Chaoyi Zhang",
        "Weidong Cai"
      ],
      "abstract": "In contrast to the well-established technique of rasterization, vectorization\nof images poses a significant challenge in the field of computer graphics.\nRecent learning-based methods for converting raster images to vector formats\nfrequently suffer from incomplete shapes, redundant path prediction, and a lack\nof accuracy in preserving the semantics of the original content. These\nshortcomings severely hinder the utility of these methods for further editing\nand manipulation of images. To address these challenges, we present DeepIcon, a\nnovel hierarchical image vectorization network specifically tailored for\ngenerating variable-length icon vector graphics based on the raster image\ninput. Our experimental results indicate that DeepIcon can efficiently produce\nScalable Vector Graphics (SVGs) directly from raster images, bypassing the need\nfor a differentiable rasterizer while also demonstrating a profound\nunderstanding of the image contents.",
      "tldr_zh": "该论文探讨了图像矢量化(vectorization)的难题，与栅格化(rasterization)相比，现有的学习方法常出现形状不完整、多余路径预测和语义保留不准等问题，从而影响图像的后续编辑。作者提出DeepIcon，一种分层(hierarchical network)网络，通过层-wise处理来从栅格图像生成可变长度的图标矢量图形(Scalable Vector Graphics, SVG)。实验结果表明，DeepIcon能高效直接产生SVG，无需可微栅格化器，并展示了更深刻的图像内容理解，从而提升了矢量化的准确性和实用性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted as Oral Presentation at DICTA 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.15760v1",
      "published_date": "2024-10-21 08:20:19 UTC",
      "updated_date": "2024-10-21 08:20:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:37:15.504853"
    },
    {
      "arxiv_id": "2410.15756v2",
      "title": "Automated Proof Generation for Rust Code via Self-Evolution",
      "title_zh": "翻译失败",
      "authors": [
        "Tianyu Chen",
        "Shuai Lu",
        "Shan Lu",
        "Yeyun Gong",
        "Chenyuan Yang",
        "Xuheng Li",
        "Md Rakib Hossain Misu",
        "Hao Yu",
        "Nan Duan",
        "Peng Cheng",
        "Fan Yang",
        "Shuvendu K Lahiri",
        "Tao Xie",
        "Lidong Zhou"
      ],
      "abstract": "Ensuring correctness is crucial for code generation. Formal verification\noffers a definitive assurance of correctness, but demands substantial human\neffort in proof construction and hence raises a pressing need for automation.\nThe primary obstacle lies in the severe lack of data-there is much fewer proofs\nthan code snippets for Large Language Models (LLMs) to train upon. In this\npaper, we introduce SAFE, a framework that overcomes the lack of human-written\nproofs to enable automated proof generation of Rust code. SAFE establishes a\nself-evolving cycle where data synthesis and fine-tuning collaborate to enhance\nthe model capability, leveraging the definitive power of a symbolic verifier in\ntelling correct proofs from incorrect ones. SAFE also re-purposes the large\nnumber of synthesized incorrect proofs to train the self-debugging capability\nof the fine-tuned models, empowering them to fix incorrect proofs based on the\nverifier's feedback. SAFE demonstrates superior efficiency and precision\ncompared to GPT-4o. Through tens of thousands of synthesized proofs and the\nself-debugging mechanism, we improve the capability of open-source models,\ninitially unacquainted with formal verification, to automatically write proofs\nfor Rust code. This advancement leads to a significant improvement in\nperformance, achieving a 52.52% accuracy rate in a benchmark crafted by human\nexperts, a significant leap over GPT-4o's performance of 14.39%.",
      "tldr_zh": "该论文提出 SAFE 框架，通过自演化循环实现 Rust 代码的自动化证明生成，解决正式验证中数据缺乏的难题。框架将数据合成与模型微调相结合，利用符号验证器区分正确和错误证明，并训练模型的自调试能力来修复不准确证明。实验结果显示，SAFE 比 GPT-4o 更高效精确，在人类专家基准上达到 52.52% 的准确率，而 GPT-4o 仅为 14.39%，显著提升了开源模型的证明生成能力。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15756v2",
      "published_date": "2024-10-21 08:15:45 UTC",
      "updated_date": "2025-04-15 11:39:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:39:20.717714"
    },
    {
      "arxiv_id": "2410.15747v1",
      "title": "GIG: Graph Data Imputation With Graph Differential Dependencies",
      "title_zh": "翻译失败",
      "authors": [
        "Jiang Hua",
        "Michael Bewong",
        "Selasi Kwashie",
        "MD Geaur Rahman",
        "Junwei Hu",
        "Xi Guo",
        "Zaiwen Fen"
      ],
      "abstract": "Data imputation addresses the challenge of imputing missing values in\ndatabase instances, ensuring consistency with the overall semantics of the\ndataset. Although several heuristics which rely on statistical methods, and\nad-hoc rules have been proposed. These do not generalise well and often lack\ndata context. Consequently, they also lack explainability. The existing\ntechniques also mostly focus on the relational data context making them\nunsuitable for wider application contexts such as in graph data. In this paper,\nwe propose a graph data imputation approach called GIG which relies on graph\ndifferential dependencies (GDDs). GIG, learns the GDDs from a given knowledge\ngraph, and uses these rules to train a transformer model which then predicts\nthe value of missing data within the graph. By leveraging GDDs, GIG incoporates\nsemantic knowledge into the data imputation process making it more reliable and\nexplainable. Experimental results on seven real-world datasets highlight GIG's\neffectiveness compared to existing state-of-the-art approaches.",
      "tldr_zh": "本文提出 GIG 方法，用于处理图数据中的缺失值填充问题，通过利用 Graph Differential Dependencies (GDDs) 从知识图谱中学习语义规则，并训练 Transformer 模型来预测缺失值，从而提升填充过程的可靠性和可解释性。与传统依赖统计方法的填充技术不同，GIG 更适用于图数据环境，并解决了泛化性和上下文缺失的局限。在七个真实世界数据集上的实验结果表明，GIG 比现有最先进方法更有效。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages, 4 figures, published to ADC",
      "pdf_url": "http://arxiv.org/pdf/2410.15747v1",
      "published_date": "2024-10-21 08:04:21 UTC",
      "updated_date": "2024-10-21 08:04:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:37:40.221765"
    },
    {
      "arxiv_id": "2410.15748v2",
      "title": "Alchemy: Amplifying Theorem-Proving Capability through Symbolic Mutation",
      "title_zh": "Alchemy：通过符号变异增强定理证明能力",
      "authors": [
        "Shaonan Wu",
        "Shuai Lu",
        "Yeyun Gong",
        "Nan Duan",
        "Ping Wei"
      ],
      "abstract": "Formal proofs are challenging to write even for experienced experts. Recent\nprogress in Neural Theorem Proving (NTP) shows promise in expediting this\nprocess. However, the formal corpora available on the Internet are limited\ncompared to the general text, posing a significant data scarcity challenge for\nNTP. To address this issue, this work proposes Alchemy, a general framework for\ndata synthesis that constructs formal theorems through symbolic mutation.\nSpecifically, for each candidate theorem in Mathlib, we identify all invocable\ntheorems that can be used to rewrite or apply to it. Subsequently, we mutate\nthe candidate theorem by replacing the corresponding term in the statement with\nits equivalent form or antecedent. As a result, our method increases the number\nof theorems in Mathlib by an order of magnitude, from 110k to 6M. Furthermore,\nwe perform continual pretraining and supervised finetuning on this augmented\ncorpus for large language models. Experimental results demonstrate the\neffectiveness of our approach, achieving a 4.70% absolute performance\nimprovement on Leandojo benchmark. Additionally, our approach achieves a 2.47%\nabsolute performance gain on the out-of-distribution miniF2F benchmark based on\nthe synthetic data.To provide further insights, we conduct a comprehensive\nanalysis of synthetic data composition and the training paradigm, offering\nvaluable guidance for developing a strong theorem prover.",
      "tldr_zh": "本文提出 Alchemy 框架，通过 symbolic mutation 技术合成定理数据，解决 Neural Theorem Proving (NTP) 领域的数据稀缺问题。具体方法包括针对 Mathlib 中的候选定理进行重写或应用操作，将定理数量从 110k 增加到 6M。研究在增强语料上进行持续预训练和监督微调，实验结果显示模型在 Leandojo 基准上提升 4.70%，并在 out-of-distribution 的 miniF2F 基准上获得 2.47% 的性能改善。此外，通过对合成数据组成和训练范式的全面分析，为开发高效的定理证明器提供了宝贵指导。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15748v2",
      "published_date": "2024-10-21 08:04:21 UTC",
      "updated_date": "2025-04-03 12:08:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:37:52.372912"
    },
    {
      "arxiv_id": "2410.15744v2",
      "title": "Unleashing the Potential of Vision-Language Pre-Training for 3D Zero-Shot Lesion Segmentation via Mask-Attribute Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Yankai Jiang",
        "Wenhui Lei",
        "Xiaofan Zhang",
        "Shaoting Zhang"
      ],
      "abstract": "Recent advancements in medical vision-language pre-training models have\ndriven significant progress in zero-shot disease recognition. However,\ntransferring image-level knowledge to pixel-level tasks, such as lesion\nsegmentation in 3D CT scans, remains a critical challenge. Due to the\ncomplexity and variability of pathological visual characteristics, existing\nmethods struggle to align fine-grained lesion features not encountered during\ntraining with disease-related textual representations. In this paper, we\npresent Malenia, a novel multi-scale lesion-level mask-attribute alignment\nframework, specifically designed for 3D zero-shot lesion segmentation. Malenia\nimproves the compatibility between mask representations and their associated\nelemental attributes, explicitly linking the visual features of unseen lesions\nwith the extensible knowledge learned from previously seen ones. Furthermore,\nwe design a Cross-Modal Knowledge Injection module to enhance both visual and\ntextual features with mutually beneficial information, effectively guiding the\ngeneration of segmentation results. Comprehensive experiments across three\ndatasets and 12 lesion categories validate the superior performance of Malenia.",
      "tldr_zh": "这项研究针对 3D Zero-Shot Lesion Segmentation 的挑战，提出 Malenia 框架，利用 Vision-Language Pre-Training 将图像级知识转移到像素级任务中，通过多尺度病变级 Mask-Attribute Alignment 来精确对齐未见病变的视觉特征与文本表示。\nMalenia 框架还引入 Cross-Modal Knowledge Injection 模块，以增强视觉和文本特征的互补信息，从而指导更准确的分割结果生成。\n在三个数据集和 12 个病变类别上的全面实验验证了 Malenia 的优越性能，展示了其在处理复杂病变变异性方面的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted as ICLR 2025 conference paper",
      "pdf_url": "http://arxiv.org/pdf/2410.15744v2",
      "published_date": "2024-10-21 08:01:58 UTC",
      "updated_date": "2025-03-02 16:58:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:39:32.631380"
    },
    {
      "arxiv_id": "2410.15737v1",
      "title": "Who's Who: Large Language Models Meet Knowledge Conflicts in Practice",
      "title_zh": "翻译失败",
      "authors": [
        "Quang Hieu Pham",
        "Hoang Ngo",
        "Anh Tuan Luu",
        "Dat Quoc Nguyen"
      ],
      "abstract": "Retrieval-augmented generation (RAG) methods are viable solutions for\naddressing the static memory limits of pre-trained language models.\nNevertheless, encountering conflicting sources of information within the\nretrieval context is an inevitable practical challenge. In such situations, the\nlanguage models are recommended to transparently inform users about the\nconflicts rather than autonomously deciding what to present based on their\ninherent biases. To analyze how current large language models (LLMs) align with\nour recommendation, we introduce WhoQA, a public benchmark dataset to examine\nmodel's behavior in knowledge conflict situations. We induce conflicts by\nasking about a common property among entities having the same name, resulting\nin questions with up to 8 distinctive answers. WhoQA evaluation set includes 5K\nquestions across 13 Wikidata property types and 150K Wikipedia entities. Our\nexperiments show that despite the simplicity of WhoQA questions, knowledge\nconflicts significantly degrades LLMs' performance in RAG settings.",
      "tldr_zh": "这篇论文探讨了大型语言模型（LLMs）在检索增强生成（RAG）中面临的知识冲突问题，建议模型应透明告知用户冲突而非基于偏见自行决定。研究者引入了 WhoQA 基准数据集，该数据集包含 5K 问题，涉及 13 种 Wikidata 属性类型和 150K Wikipedia 实体，通过询问同名实体的共同属性来诱发多达 8 个不同答案。实验结果显示，尽管问题简单，知识冲突会显著降低 LLMs 在 RAG 设置中的性能，为改进模型的可靠性和透明度提供了重要洞见。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EMNLP 2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2410.15737v1",
      "published_date": "2024-10-21 07:56:45 UTC",
      "updated_date": "2024-10-21 07:56:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:39:44.615835"
    },
    {
      "arxiv_id": "2410.15735v1",
      "title": "AutoTrain: No-code training for state-of-the-art models",
      "title_zh": "翻译失败",
      "authors": [
        "Abhishek Thakur"
      ],
      "abstract": "With the advancements in open-source models, training (or finetuning) models\non custom datasets has become a crucial part of developing solutions which are\ntailored to specific industrial or open-source applications. Yet, there is no\nsingle tool which simplifies the process of training across different types of\nmodalities or tasks. We introduce AutoTrain (aka AutoTrain Advanced) -- an\nopen-source, no code tool/library which can be used to train (or finetune)\nmodels for different kinds of tasks such as: large language model (LLM)\nfinetuning, text classification/regression, token classification,\nsequence-to-sequence task, finetuning of sentence transformers, visual language\nmodel (VLM) finetuning, image classification/regression and even classification\nand regression tasks on tabular data. AutoTrain Advanced is an open-source\nlibrary providing best practices for training models on custom datasets. The\nlibrary is available at https://github.com/huggingface/autotrain-advanced.\nAutoTrain can be used in fully local mode or on cloud machines and works with\ntens of thousands of models shared on Hugging Face Hub and their variations.",
      "tldr_zh": "该研究引入了AutoTrain（又称AutoTrain Advanced），一个开源的无代码工具，用于简化在自定义数据集上训练或微调最先进模型的过程。该工具支持多种任务，包括LLM微调、文本分类、序列到序列任务、VLM微调、图像分类以及表格数据分类/回归等，提供最佳实践以处理不同模态的数据。AutoTrain可用于本地或云环境，并与Hugging Face Hub上的数万个模型兼容，从而使模型训练更高效和可访问。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15735v1",
      "published_date": "2024-10-21 07:53:32 UTC",
      "updated_date": "2024-10-21 07:53:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:41:55.501307"
    },
    {
      "arxiv_id": "2410.15726v1",
      "title": "Reducing annotator bias by belief elicitation",
      "title_zh": "通过信念诱导减少标注者偏差",
      "authors": [
        "Terne Sasha Thorn Jakobsen",
        "Andreas Bjerre-Nielsen",
        "Robert Böhm"
      ],
      "abstract": "Crowdsourced annotations of data play a substantial role in the development\nof Artificial Intelligence (AI). It is broadly recognised that annotations of\ntext data can contain annotator bias, where systematic disagreement in\nannotations can be traced back to differences in the annotators' backgrounds.\nBeing unaware of such annotator bias can lead to representational bias against\nminority group perspectives and therefore several methods have been proposed\nfor recognising bias or preserving perspectives. These methods typically\nrequire either a substantial number of annotators or annotations per data\ninstance. In this study, we propose a simple method for handling bias in\nannotations without requirements on the number of annotators or instances.\nInstead, we ask annotators about their beliefs of other annotators' judgements\nof an instance, under the hypothesis that these beliefs may provide more\nrepresentative and less biased labels than judgements. The method was examined\nin two controlled, survey-based experiments involving Democrats and Republicans\n(n=1,590) asked to judge statements as arguments and then report beliefs about\nothers' judgements. The results indicate that bias, defined as systematic\ndifferences between the two groups of annotators, is consistently reduced when\nasking for beliefs instead of judgements. Our proposed method therefore has the\npotential to reduce the risk of annotator bias, thereby improving the\ngeneralisability of AI systems and preventing harm to unrepresented\nsocio-demographic groups, and we highlight the need for further studies of this\npotential in other tasks and downstream applications.",
      "tldr_zh": "本研究探讨了AI数据标注中的annotator bias问题，即标注者背景差异导致的系统性偏差，可能造成对少数群体观点的代表性偏见。作者提出一种简单方法，通过belief elicitation（询问标注者对其他人的判断信念）来获取更具代表性和少偏见的标签，而无需大量标注者或实例。实验涉及两个受控调查（n=1,590），让民主党人和共和党人评估语句并报告他人判断，结果显示这种方法显著降低了组间系统性差异。总体而言，该方法有助于提升AI系统的泛化性和公平性，并建议在更多任务中进行进一步验证。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "econ.GN",
        "q-fin.EC",
        "68T50",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15726v1",
      "published_date": "2024-10-21 07:44:01 UTC",
      "updated_date": "2024-10-21 07:44:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:40:08.103185"
    },
    {
      "arxiv_id": "2410.15715v2",
      "title": "Timetable Nodes for Public Transport Network",
      "title_zh": "公共交通网络的时间表节点",
      "authors": [
        "Andrii Rohovyi",
        "Peter J. Stuckey",
        "Toby Walsh"
      ],
      "abstract": "Faster pathfinding in time-dependent transport networks is an important and\nchallenging problem in navigation systems. There are two main types of\ntransport networks: road networks for car driving and public transport route\nnetwork. The solutions that work well in road networks, such as Time-dependent\nContraction Hierarchies and other graph-based approaches, do not usually apply\nin transport networks. In transport networks, non-graph solutions such as CSA\nand RAPTOR show the best results compared to graph-based techniques. In our\nwork, we propose a method that advances graph-based approaches by using\ndifferent optimization techniques from computational geometry to speed up the\nsearch process in transport networks. We apply a new pre-computation step,\nwhich we call timetable nodes (TTN). Our inspiration comes from an iterative\nsearch problem in computational geometry. We implement two versions of the TTN:\none uses a Combined Search Tree (TTN-CST), and the second uses Fractional\nCascading (TTN-FC). Both of these approaches decrease the asymptotic complexity\nof reaching new nodes from $O(k\\times \\log|C|)$ to $O(k + \\log(k) +\n\\log(|C|))$, where $k$ is the number of outgoing edges from a node and $|C|$ is\nthe size of the timetable information (total outgoing edges). Our solution\nsuits any other time-dependent networks and can be integrated into other\npathfinding algorithms. Our experiments indicate that this pre-computation\nsignificantly enhances the performance on high-density graphs. This study\nshowcases how leveraging computational geometry can enhance pathfinding in\ntransport networks, enabling faster pathfinding in scenarios involving large\nnumbers of outgoing edges.",
      "tldr_zh": "本文研究了在时间依赖的公共交通网络中实现更快路径查找的问题，指出传统图-based方法如Time-dependent Contraction Hierarchies不适用于此类网络，而非图方法如CSA和RAPTOR更有效。作者提出了一种新预计算步骤timetable nodes (TTN)，包括TTN-CST（使用Combined Search Tree）和TTN-FC（使用Fractional Cascading），通过借鉴计算几何的优化技术，将从节点到达新节点的渐进复杂度从O(k × log|C|)降低到O(k + log(k) + log|C|)。实验结果显示，该方法显著提升了高密度图的搜索性能，并可整合到其他路径查找算法中，适用于各种时间依赖网络。",
      "categories": [
        "cs.DS",
        "cs.AI",
        "cs.CG"
      ],
      "primary_category": "cs.DS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15715v2",
      "published_date": "2024-10-21 07:34:04 UTC",
      "updated_date": "2024-10-23 05:02:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:40:21.600868"
    },
    {
      "arxiv_id": "2410.15714v3",
      "title": "Offline reinforcement learning for job-shop scheduling problems",
      "title_zh": "离线强化学习用于作业车间调度问题",
      "authors": [
        "Imanol Echeverria",
        "Maialen Murua",
        "Roberto Santana"
      ],
      "abstract": "Recent advances in deep learning have shown significant potential for solving\ncombinatorial optimization problems in real-time. Unlike traditional methods,\ndeep learning can generate high-quality solutions efficiently, which is crucial\nfor applications like routing and scheduling. However, existing approaches like\ndeep reinforcement learning (RL) and behavioral cloning have notable\nlimitations, with deep RL suffering from slow learning and behavioral cloning\nrelying solely on expert actions, which can lead to generalization issues and\nneglect of the optimization objective. This paper introduces a novel offline RL\nmethod designed for combinatorial optimization problems with complex\nconstraints, where the state is represented as a heterogeneous graph and the\naction space is variable. Our approach encodes actions in edge attributes and\nbalances expected rewards with the imitation of expert solutions. We\ndemonstrate the effectiveness of this method on job-shop scheduling and\nflexible job-shop scheduling benchmarks, achieving superior performance\ncompared to state-of-the-art techniques.",
      "tldr_zh": "本论文针对作业车间调度（job-shop scheduling）问题，提出了一种新型离线强化学习（offline RL）方法，以克服现有深度强化学习（deep RL）学习缓慢和行为克隆（behavioral cloning）依赖专家动作导致的泛化问题及优化目标忽略。方法通过将状态表示为异构图（heterogeneous graph）和可变动作空间，将动作编码到边属性（edge attributes），并平衡预期奖励（expected rewards）与专家解决方案模仿。实验结果显示，该方法在作业车间调度和灵活作业车间调度（flexible job-shop scheduling）基准上，优于最先进技术，展示了其在复杂约束组合优化问题中的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15714v3",
      "published_date": "2024-10-21 07:33:42 UTC",
      "updated_date": "2025-04-05 05:06:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:40:32.388624"
    },
    {
      "arxiv_id": "2410.15700v1",
      "title": "InternLM2.5-StepProver: Advancing Automated Theorem Proving via Expert Iteration on Large-Scale LEAN Problems",
      "title_zh": "翻译失败",
      "authors": [
        "Zijian Wu",
        "Suozhi Huang",
        "Zhejian Zhou",
        "Huaiyuan Ying",
        "Jiayu Wang",
        "Dahua Lin",
        "Kai Chen"
      ],
      "abstract": "Large Language Models (LLMs) have emerged as powerful tools in mathematical\ntheorem proving, particularly when utilizing formal languages such as LEAN. The\nmajor learning paradigm is expert iteration, which necessitates a pre-defined\ndataset comprising numerous mathematical problems. In this process, LLMs\nattempt to prove problems within the dataset and iteratively refine their\ncapabilities through self-training on the proofs they discover. We propose to\nuse large scale LEAN problem datasets Lean-workbook for expert iteration with\nmore than 20,000 CPU days. During expert iteration, we found log-linear trends\nbetween solved problem amount with proof length and CPU usage. We train a\ncritic model to select relatively easy problems for policy models to make\ntrials and guide the model to search for deeper proofs. InternLM2.5-StepProver\nachieves open-source state-of-the-art on MiniF2F, Lean-Workbook-Plus, ProofNet,\nand Putnam benchmarks. Specifically, it achieves a pass of 65.9% on the\nMiniF2F-test and proves (or disproves) 17.0% of problems in Lean-Workbook-Plus\nwhich shows a significant improvement compared to only 9.5% of problems proved\nwhen Lean-Workbook-Plus was released. We open-source our models and searched\nproofs at https://github.com/InternLM/InternLM-Math and\nhttps://huggingface.co/datasets/internlm/Lean-Workbook.",
      "tldr_zh": "该论文提出 InternLM2.5-StepProver 框架，通过在大型 LEAN 问题数据集 Lean-workbook 上进行 expert iteration 来提升自动定理证明的性能，该过程涉及超过 20,000 CPU 天并训练一个 critic model 来选择较易问题并指导更深层证明搜索。研究发现，解决问题的数量与证明长度和 CPU 使用存在对数线性趋势。实验结果显示，该模型在 MiniF2F-test 上达到 65.9% 的通过率，并在 Lean-Workbook-Plus 等基准上显著提升了证明能力，从原来的 9.5% 提高到 17.0%，并开源了模型和证明以促进进一步研究。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15700v1",
      "published_date": "2024-10-21 07:18:23 UTC",
      "updated_date": "2024-10-21 07:18:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:40:45.932963"
    },
    {
      "arxiv_id": "2410.15694v1",
      "title": "PALMS: Plane-based Accessible Indoor Localization Using Mobile Smartphones",
      "title_zh": "翻译失败",
      "authors": [
        "Yunqian Cheng",
        "Roberto Manduchi"
      ],
      "abstract": "In this paper, we present PALMS, an innovative indoor global localization and\nrelocalization system for mobile smartphones that utilizes publicly available\nfloor plans. Unlike most vision-based methods that require constant visual\ninput, our system adopts a dynamic form of localization that considers a single\ninstantaneous observation and odometry data. The core contribution of this work\nis the introduction of a particle filter initialization method that leverages\nthe Certainly Empty Space (CES) constraint along with principal orientation\nmatching. This approach creates a spatial probability distribution of the\ndevice's location, significantly improving localization accuracy and reducing\nparticle filter convergence time. Our experimental evaluations demonstrate that\nPALMS outperforms traditional methods with uniformly initialized particle\nfilters, providing a more efficient and accessible approach to indoor\nwayfinding. By eliminating the need for prior environmental fingerprinting,\nPALMS provides a scalable and practical approach to indoor navigation.",
      "tldr_zh": "本文提出 PALMS 系统，这是一个基于平面图的室内全局定位和重定位解决方案，使用移动智能手机，仅需单次观察和 odometry data 即可实现动态定位。核心贡献是引入粒子滤波器初始化方法，利用 Certainly Empty Space (CES) 约束和 principal orientation matching，创建设备位置的空间概率分布，从而提高定位准确性和减少粒子滤波器收敛时间。实验评估表明，PALMS 优于传统均匀初始化粒子滤波器的方法，提供更高效、可访问的室内导航，并无需先前环境指纹化，支持可扩展的实际应用。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "I.2.9; I.2.10"
      ],
      "primary_category": "cs.RO",
      "comment": "7 pages, 3 figures, accepted to the 14th International Conference on\n  Indoor Positioning and Indoor Navigation (IPIN) 2024, Best Presentation Award",
      "pdf_url": "http://arxiv.org/pdf/2410.15694v1",
      "published_date": "2024-10-21 07:05:07 UTC",
      "updated_date": "2024-10-21 07:05:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:40:56.610061"
    },
    {
      "arxiv_id": "2410.15693v1",
      "title": "Geographical Node Clustering and Grouping to Guarantee Data IIDness in Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Minkwon Lee",
        "Hyoil Kim",
        "Changhee Joo"
      ],
      "abstract": "Federated learning (FL) is a decentralized AI mechanism suitable for a large\nnumber of devices like in smart IoT. A major challenge of FL is the non-IID\ndataset problem, originating from the heterogeneous data collected by FL\nparticipants, leading to performance deterioration of the trained global model.\nThere have been various attempts to rectify non-IID dataset, mostly focusing on\nmanipulating the collected data. This paper, however, proposes a novel approach\nto ensure data IIDness by properly clustering and grouping mobile IoT nodes\nexploiting their geographical characteristics, so that each FL group can\nachieve IID dataset. We first provide an experimental evidence for the\nindependence and identicalness features of IoT data according to the\ninter-device distance, and then propose Dynamic Clustering and Partial-Steady\nGrouping algorithms that partition FL participants to achieve near-IIDness in\ntheir dataset while considering device mobility. Our mechanism significantly\noutperforms benchmark grouping algorithms at least by 110 times in terms of the\njoint cost between the number of dropout devices and the evenness in per-group\ndevice count, with a mild increase in the number of groups only by up to 0.93\ngroups.",
      "tldr_zh": "这篇论文针对 Federated Learning (FL) 中的非 IID 数据集问题，提出了一种基于地理特性的节点聚类和分组方法，以确保每个 FL 组的数据接近 IID。作者首先通过实验证明了 IoT 设备间距离与数据独立性和相同性的相关性，并开发了 Dynamic Clustering 和 Partial-Steady Grouping 算法，这些算法在考虑设备移动性的同时分区 FL 参与者，实现数据近似 IID。实验结果显示，该机制在联合成本（设备掉线数量和每组设备均匀性）上至少比基准算法优越 110 倍，同时仅增加最多 0.93 个组。",
      "categories": [
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.15693v1",
      "published_date": "2024-10-21 07:03:15 UTC",
      "updated_date": "2024-10-21 07:03:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:41:08.692603"
    },
    {
      "arxiv_id": "2410.15686v1",
      "title": "NetSafe: Exploring the Topological Safety of Multi-agent Networks",
      "title_zh": "NetSafe：探索多智能体网络的拓扑安全性",
      "authors": [
        "Miao Yu",
        "Shilong Wang",
        "Guibin Zhang",
        "Junyuan Mao",
        "Chenlong Yin",
        "Qijiong Liu",
        "Qingsong Wen",
        "Kun Wang",
        "Yang Wang"
      ],
      "abstract": "Large language models (LLMs) have empowered nodes within multi-agent networks\nwith intelligence, showing growing applications in both academia and industry.\nHowever, how to prevent these networks from generating malicious information\nremains unexplored with previous research on single LLM's safety be challenging\nto transfer. In this paper, we focus on the safety of multi-agent networks from\na topological perspective, investigating which topological properties\ncontribute to safer networks. To this end, we propose a general framework,\nNetSafe along with an iterative RelCom interaction to unify existing diverse\nLLM-based agent frameworks, laying the foundation for generalized topological\nsafety research. We identify several critical phenomena when multi-agent\nnetworks are exposed to attacks involving misinformation, bias, and harmful\ninformation, termed as Agent Hallucination and Aggregation Safety. Furthermore,\nwe find that highly connected networks are more susceptible to the spread of\nadversarial attacks, with task performance in a Star Graph Topology decreasing\nby 29.7%. Besides, our proposed static metrics aligned more closely with\nreal-world dynamic evaluations than traditional graph-theoretic metrics,\nindicating that networks with greater average distances from attackers exhibit\nenhanced safety. In conclusion, our work introduces a new topological\nperspective on the safety of LLM-based multi-agent networks and discovers\nseveral unreported phenomena, paving the way for future research to explore the\nsafety of such networks.",
      "tldr_zh": "本研究探讨了大型语言模型 (LLMs) 在多智能体网络中的拓扑安全问题，提出 NetSafe 框架及其迭代 RelCom 交互机制，以统一现有多样化代理框架并分析拓扑属性对网络安全的影响。实验发现，高连接网络更容易传播攻击信息，导致 Star Graph Topology 的任务性能下降 29.7%，并识别了 Agent Hallucination 和 Aggregation Safety 等关键现象。结果表明，NetSafe 的静态指标比传统图论指标更贴近动态评估，且网络与攻击者平均距离越大，安全性越强，为未来 LLM-based 多智能体网络的安全研究开辟了新路径。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15686v1",
      "published_date": "2024-10-21 06:54:27 UTC",
      "updated_date": "2024-10-21 06:54:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:41:20.939800"
    },
    {
      "arxiv_id": "2410.15678v1",
      "title": "Revealing and Mitigating the Local Pattern Shortcuts of Mamba",
      "title_zh": "翻译失败",
      "authors": [
        "Wangjie You",
        "Zecheng Tang",
        "Juntao Li",
        "Lili Yao",
        "Min Zhang"
      ],
      "abstract": "Large language models (LLMs) have advanced significantly due to the attention\nmechanism, but their quadratic complexity and linear memory demands limit their\nperformance on long-context tasks. Recently, researchers introduced Mamba, an\nadvanced model built upon State Space Models(SSMs) that offers linear\ncomplexity and constant memory. Although Mamba is reported to match or surpass\nthe performance of attention-based models, our analysis reveals a performance\ngap: Mamba excels in tasks that involve localized key information but faces\nchallenges with tasks that require handling distributed key information. Our\ncontrolled experiments suggest that this inconsistency arises from Mamba's\nreliance on local pattern shortcuts, which enable the model to remember local\nkey information within its limited memory but hinder its ability to retain more\ndispersed information. Therefore, we introduce a global selection module into\nthe Mamba model to address this issue. Experiments on both existing and\nproposed synthetic tasks, as well as real-world tasks, demonstrate the\neffectiveness of our method. Notably, with the introduction of only 4M extra\nparameters, our approach enables the Mamba model(130M) to achieve a significant\nimprovement on tasks with distributed information, increasing its performance\nfrom 0 to 80.54 points.",
      "tldr_zh": "该研究揭示了Mamba模型依赖于local pattern shortcuts的问题，导致其在处理局部关键信息任务上表现出色，但对分布式关键信息任务表现欠佳。研究者通过控制实验分析了这一不一致性，归因于Mamba基于State Space Models (SSMs)的设计，限制了其对分散信息的保留能力。为此，他们引入了一个global selection module，添加仅4M参数来缓解这一问题。在现有和合成任务以及真实世界任务上的实验显示，该方法显著提升了Mamba (130M)模型的性能，使分布式信息任务的得分从0提高到80.54分。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15678v1",
      "published_date": "2024-10-21 06:42:11 UTC",
      "updated_date": "2024-10-21 06:42:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:42:06.882596"
    },
    {
      "arxiv_id": "2410.19840v1",
      "title": "GreenEye: Development of Real-Time Traffic Signal Recognition System for Visual Impairments",
      "title_zh": "翻译失败",
      "authors": [
        "Danu Kim"
      ],
      "abstract": "Recognizing a traffic signal, determining if the signal is green or red, and\nfiguring out the time left to cross the crosswalk are significant challenges to\nvisually impaired people. Previous research has focused on recognizing only two\ntraffic signals, green and red lights, using machine learning techniques. The\nproposed method developed a GreenEye system that recognizes the traffic\nsignals' color and tells the time left for pedestrians to cross the crosswalk\nin real-time. GreenEye's first training showed the highest precision of 74.6%;\nfour classes reported 40% or lower recognition precision in this training\nsession. The data imbalance caused low precision; thus, extra labeling and\ndatabase formation were performed to stabilize the number of images between\ndifferent classes. After the stabilization, all 14 classes showed excelling\nprecision rate of 99.5%.",
      "tldr_zh": "该研究针对视力障碍者识别交通信号灯的挑战，开发了GreenEye实时系统，能够识别信号颜色并实时告知行人过马路的剩余时间。系统采用机器学习技术进行训练，但初始训练中因数据不平衡导致最高precision仅为74.6%，某些类别低于40%。通过额外数据标注和平衡数据库，最终所有14个类别实现了99.5%的precision，提升了系统的可靠性和实用性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Published in Korea Software Congress (2023)",
      "pdf_url": "http://arxiv.org/pdf/2410.19840v1",
      "published_date": "2024-10-21 06:27:22 UTC",
      "updated_date": "2024-10-21 06:27:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:42:18.924865"
    },
    {
      "arxiv_id": "2410.15669v1",
      "title": "Learning to Generate and Evaluate Fact-checking Explanations with Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Darius Feher",
        "Abdullah Khered",
        "Hao Zhang",
        "Riza Batista-Navarro",
        "Viktor Schlegel"
      ],
      "abstract": "In an era increasingly dominated by digital platforms, the spread of\nmisinformation poses a significant challenge, highlighting the need for\nsolutions capable of assessing information veracity. Our research contributes\nto the field of Explainable Artificial Antelligence (XAI) by developing\ntransformer-based fact-checking models that contextualise and justify their\ndecisions by generating human-accessible explanations. Importantly, we also\ndevelop models for automatic evaluation of explanations for fact-checking\nverdicts across different dimensions such as \\texttt{(self)-contradiction},\n\\texttt{hallucination}, \\texttt{convincingness} and \\texttt{overall quality}.\nBy introducing human-centred evaluation methods and developing specialised\ndatasets, we emphasise the need for aligning Artificial Intelligence\n(AI)-generated explanations with human judgements. This approach not only\nadvances theoretical knowledge in XAI but also holds practical implications by\nenhancing the transparency, reliability and users' trust in AI-driven\nfact-checking systems. Furthermore, the development of our metric learning\nmodels is a first step towards potentially increasing efficiency and reducing\nreliance on extensive manual assessment. Based on experimental results, our\nbest performing generative model \\textsc{ROUGE-1} score of 47.77, demonstrating\nsuperior performance in generating fact-checking explanations, particularly\nwhen provided with high-quality evidence. Additionally, the best performing\nmetric learning model showed a moderately strong correlation with human\njudgements on objective dimensions such as \\texttt{(self)-contradiction and\n\\texttt{hallucination}, achieving a Matthews Correlation Coefficient (MCC) of\naround 0.7.}",
      "tldr_zh": "本研究开发了基于 Transformer 的模型，用于生成和评估事实检查解释，从而提升 Explainable Artificial Intelligence (XAI) 在对抗虚假信息中的应用。该模型不仅生成人类易懂的解释，还包括自动评估机制，针对(self)-contradiction、hallucination、convincingness 和 overall quality 等维度进行评估，并通过专业数据集和以人为本的方法确保 AI 解释与人类判断一致。实验结果显示，最佳生成模型的 ROUGE-1 分数达 47.77%，而度量学习模型在客观维度上与人类判断的相关性达到 Matthews Correlation Coefficient (MCC) 约 0.7，从而提高了事实检查系统的透明度、可靠性和用户信任，并减少了对手动评估的依赖。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "Forthcoming in Engineering Applications of Artificial Intelligence",
      "pdf_url": "http://arxiv.org/pdf/2410.15669v1",
      "published_date": "2024-10-21 06:22:51 UTC",
      "updated_date": "2024-10-21 06:22:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:42:53.868068"
    },
    {
      "arxiv_id": "2411.03321v3",
      "title": "Towards More Accurate US Presidential Election via Multi-step Reasoning with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Chenxiao Yu",
        "Zhaotian Weng",
        "Yuangang Li",
        "Zheng Li",
        "Xiyang Hu",
        "Yue Zhao"
      ],
      "abstract": "Can Large Language Models (LLMs) accurately predict election outcomes? While\nLLMs have demonstrated impressive performance in various domains, including\nhealthcare, legal analysis, and creative tasks, their ability to forecast\nelections remains unknown. Election prediction poses unique challenges, such as\nlimited voter-level data, rapidly changing political landscapes, and the need\nto model complex human behavior. To address these challenges, we introduce a\nmulti-step reasoning framework designed for political analysis. Our approach is\nvalidated on real-world data from the American National Election Studies (ANES)\n2016 and 2020, as well as synthetic personas generated by the leading machine\nlearning framework, offering scalable datasets for voter behavior modeling. To\ncapture temporal dynamics, we incorporate candidates' policy positions and\nbiographical details, ensuring that the model adapts to evolving political\ncontexts. Drawing on Chain of Thought prompting, our multi-step reasoning\npipeline systematically integrates demographic, ideological, and time-dependent\nfactors, enhancing the model's predictive power.",
      "tldr_zh": "本研究探讨大型语言模型(LLMs)是否能准确预测美国总统选举结果，针对选举预测的挑战（如数据有限、政治环境快速变化和复杂人类行为）提出一个多步推理框架，以提升预测准确性。该框架利用Chain of Thought提示，系统整合人口统计、意识形态和时间相关因素（如候选人的政策立场和传记细节），并在American National Election Studies (ANES) 2016和2020真实数据以及合成人物数据上进行验证。通过这种方法，模型能够更好地适应动态政治环境，提高选举预测的可靠性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "This research is ongoing work. Xiyang Hu and Yue Zhao are the\n  corresponding authors",
      "pdf_url": "http://arxiv.org/pdf/2411.03321v3",
      "published_date": "2024-10-21 06:18:53 UTC",
      "updated_date": "2025-04-04 01:33:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:42:42.684549"
    },
    {
      "arxiv_id": "2410.15667v1",
      "title": "RAC: Efficient LLM Factuality Correction with Retrieval Augmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Changmao Li",
        "Jeffrey Flanigan"
      ],
      "abstract": "Large Language Models (LLMs) exhibit impressive results across a wide range\nof natural language processing (NLP) tasks, yet they can often produce\nfactually incorrect outputs. This paper introduces a simple but effective\nlow-latency post-correction method, \\textbf{Retrieval Augmented Correction\n(RAC)}, aimed at enhancing the factual performance of LLMs without requiring\nadditional fine-tuning. Our method is general and can be used with any\ninstruction-tuned LLM, and has greatly reduced latency compared to prior\napproaches. RAC decomposes the LLM's output into atomic facts and applies a\nfine-grained verification and correction process with retrieved content to\nverify and correct the LLM-generated output. Our extensive experiments show\nthat RAC yields up to 30\\% improvements over state-of-the-art baselines across\ntwo popular factuality evaluation datasets, validating its efficacy and\nrobustness in both with and without the integration of Retrieval-Augmented\nGeneration (RAG) across different LLMs.\\footnote{Our code is at\n\\url{https://github.com/jlab-nlp/Retrieval-Augmented-Correction}}",
      "tldr_zh": "本研究提出了一种简单高效的低延迟后修正方法——Retrieval Augmented Correction (RAC)，旨在提升大语言模型 (LLMs) 的事实准确性，而无需额外微调。RAC 将 LLMs 的输出分解为原子事实，并利用检索内容进行细粒度的验证和修正，使其适用于任何指令调整过的 LLM。实验结果显示，RAC 在两个流行的事实性评估数据集上，比最先进基线提升多达 30%，并证明了其在有无 Retrieval-Augmented Generation (RAG) 整合情况下的鲁棒性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15667v1",
      "published_date": "2024-10-21 06:11:38 UTC",
      "updated_date": "2024-10-21 06:11:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:42:55.674587"
    },
    {
      "arxiv_id": "2410.15665v4",
      "title": "Long Term Memory: The Foundation of AI Self-Evolution",
      "title_zh": "长期记忆：AI 自我进化的基础",
      "authors": [
        "Xun Jiang",
        "Feng Li",
        "Han Zhao",
        "Jiahao Qiu",
        "Jiaying Wang",
        "Jun Shao",
        "Shihao Xu",
        "Shu Zhang",
        "Weiling Chen",
        "Xavier Tang",
        "Yize Chen",
        "Mengyue Wu",
        "Weizhi Ma",
        "Mengdi Wang",
        "Tianqiao Chen"
      ],
      "abstract": "Large language models (LLMs) like GPTs, trained on vast datasets, have\ndemonstrated impressive capabilities in language understanding, reasoning, and\nplanning, achieving human-level performance in various tasks. Most studies\nfocus on enhancing these models by training on ever-larger datasets to build\nmore powerful foundation models. While training stronger models is important,\nenabling models to evolve during inference is equally crucial, a process we\nrefer to as AI self-evolution. Unlike large-scale training, self-evolution may\nrely on limited data or interactions. Inspired by the columnar organization of\nthe human cerebral cortex, we hypothesize that AI models could develop\ncognitive abilities and build internal representations through iterative\ninteractions with their environment. To achieve this, models need long-term\nmemory (LTM) to store and manage processed interaction data. LTM supports\nself-evolution by representing diverse experiences across environments and\nagents. In this report, we explore AI self-evolution and its potential to\nenhance models during inference. We examine LTM's role in lifelong learning,\nallowing models to evolve based on accumulated interactions. We outline the\nstructure of LTM and the systems needed for effective data retention and\nrepresentation. We also classify approaches for building personalized models\nwith LTM data and show how these models achieve self-evolution through\ninteraction. Using LTM, our multi-agent framework OMNE achieved first place on\nthe GAIA benchmark, demonstrating LTM's potential for AI self-evolution.\nFinally, we present a roadmap for future research, emphasizing the importance\nof LTM for advancing AI technology and its practical applications.",
      "tldr_zh": "该论文强调，长时记忆 (Long Term Memory, LTM) 是实现 AI 自演化 (AI self-evolution) 的基础，允许大型语言模型 (LLMs) 如 GPTs 通过有限互动和迭代学习来发展认知能力，而非仅依赖大规模训练。受人类大脑柱状组织启发，作者探讨了 LTM 在终身学习中的作用，包括其结构、数据存储系统以及构建个性化模型的方法。实验显示，利用 LTM 的多智能体框架 OMNE 在 GAIA benchmark 上获得第一名，证明了其在增强模型互动演化方面的潜力。最后，论文提供了未来研究路线图，以推动 AI 技术的实际应用。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "56 pages, 13 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.15665v4",
      "published_date": "2024-10-21 06:09:30 UTC",
      "updated_date": "2025-05-11 07:56:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:43:07.955636"
    },
    {
      "arxiv_id": "2410.15656v1",
      "title": "LightFusionRec: Lightweight Transformers-Based Cross-Domain Recommendation Model",
      "title_zh": "LightFusionRec：轻量级基于Transformer的跨领域推荐模型",
      "authors": [
        "Vansh Kharidia",
        "Dhruvi Paprunia",
        "Prashasti Kanikar"
      ],
      "abstract": "This paper presents LightFusionRec, a novel lightweight cross-domain\nrecommendation system that integrates DistilBERT for textual feature extraction\nand FastText for genre embedding. Important issues in recommendation systems,\nsuch as data sparsity, computational efficiency, and cold start issues, are\naddressed in methodology. LightFusionRec uses a small amount of information to\nproduce precise and contextually relevant recommendations for many media\nformats by fusing genre vector embedding with natural language processing\nalgorithms. Tests conducted on extensive movie and book datasets show notable\nenhancements in suggestion quality when compared to conventional methods.\nBecause of its lightweight design, the model can be used for a variety of\npurposes and allows for ondevice inference. LightFusionRec is a noteworthy\ndevelopment in cross-domain recommendation systems, providing accurate and\nscalable recommendations to improve user experience on digital content\nplatforms.",
      "tldr_zh": "本研究提出LightFusionRec，一种轻量级的基于Transformer的跨域推荐模型，它整合DistilBERT进行文本特征提取和FastText进行类型嵌入，以解决推荐系统中的数据稀疏性、计算效率和冷启动问题。该模型通过融合类型向量嵌入与自然语言处理算法，使用少量信息为多种媒体格式生成精确的相关推荐。在电影和书籍数据集上的实验显示，与传统方法相比，推荐质量显著提升，且其轻量级设计支持设备端推理，提供可扩展的解决方案，提升数字内容平台的用户体验。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15656v1",
      "published_date": "2024-10-21 05:49:40 UTC",
      "updated_date": "2024-10-21 05:49:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:43:18.252430"
    },
    {
      "arxiv_id": "2410.15653v4",
      "title": "Opportunities and Challenges of Generative-AI in Finance",
      "title_zh": "翻译失败",
      "authors": [
        "Akshar Prabhu Desai",
        "Ganesh Satish Mallya",
        "Mohammad Luqman",
        "Tejasvi Ravi",
        "Nithya Kota",
        "Pranjul Yadav"
      ],
      "abstract": "Gen-AI techniques are able to improve understanding of context and nuances in\nlanguage modeling, translation between languages, handle large volumes of data,\nprovide fast, low-latency responses and can be fine-tuned for various tasks and\ndomains. In this manuscript, we present a comprehensive overview of the\napplications of Gen-AI techniques in the finance domain. In particular, we\npresent the opportunities and challenges associated with the usage of Gen-AI\ntechniques. We also illustrate the various methodologies which can be used to\ntrain Gen-AI techniques and present the various application areas of Gen-AI\ntechnologies in the finance ecosystem. To the best of our knowledge, this work\nrepresents the most comprehensive summarization of Gen-AI techniques within the\nfinancial domain. The analysis is designed for a deep overview of areas marked\nfor substantial advancement while simultaneously pin-point those warranting\nfuture prioritization. We also hope that this work would serve as a conduit\nbetween finance and other domains, thus fostering the cross-pollination of\ninnovative concepts and practices.",
      "tldr_zh": "这篇论文对生成式人工智能（Gen-AI）在金融领域的应用进行了全面概述，强调其在语言建模、跨语言翻译、大数据处理和快速响应等方面的优势。论文探讨了Gen-AI的使用机会，如提升金融任务的效率和准确性，同时指出了挑战，包括数据隐私、模型偏差和领域适应性问题。作者还介绍了多种训练Gen-AI的方法及其在金融生态中的应用领域，并主张此工作可促进金融与其他领域的创新与合作。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "https://ieeexplore.ieee.org/document/10825658",
      "pdf_url": "http://arxiv.org/pdf/2410.15653v4",
      "published_date": "2024-10-21 05:30:39 UTC",
      "updated_date": "2025-02-08 00:43:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:43:30.413932"
    },
    {
      "arxiv_id": "2410.15650v1",
      "title": "Voice-Enabled AI Agents can Perform Common Scams",
      "title_zh": "支持",
      "authors": [
        "Richard Fang",
        "Dylan Bowman",
        "Daniel Kang"
      ],
      "abstract": "Recent advances in multi-modal, highly capable LLMs have enabled\nvoice-enabled AI agents. These agents are enabling new applications, such as\nvoice-enabled autonomous customer service. However, with all AI capabilities,\nthese new capabilities have the potential for dual use.\n  In this work, we show that voice-enabled AI agents can perform the actions\nnecessary to perform common scams. To do so, we select a list of common scams\ncollected by the government and construct voice-enabled agents with directions\nto perform these scams. We conduct experiments on our voice-enabled agents and\nshow that they can indeed perform the actions necessary to autonomously perform\nsuch scams. Our results raise questions around the widespread deployment of\nvoice-enabled AI agents.",
      "tldr_zh": "本研究探讨了语音启用 AI 代理（voice-enabled AI agents）在多模态大型语言模型（LLMs）进步下的双重用途风险，展示了它们能够执行常见诈骗行为。研究团队选取了政府收集的常见诈骗列表，并构建了针对这些诈骗的语音代理进行实验。结果显示，这些代理可以自主完成诈骗所需动作，准确证明了潜在威胁。这引发了对语音启用 AI 代理广泛部署的担忧，强调了需要加强安全措施。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15650v1",
      "published_date": "2024-10-21 05:22:54 UTC",
      "updated_date": "2024-10-21 05:22:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:43:42.687616"
    },
    {
      "arxiv_id": "2410.15645v2",
      "title": "Boosting Jailbreak Transferability for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Hanqing Liu",
        "Lifeng Zhou",
        "Huanqian Yan"
      ],
      "abstract": "Large language models have drawn significant attention to the challenge of\nsafe alignment, especially regarding jailbreak attacks that circumvent security\nmeasures to produce harmful content. To address the limitations of existing\nmethods like GCG, which perform well in single-model attacks but lack\ntransferability, we propose several enhancements, including a scenario\ninduction template, optimized suffix selection, and the integration of\nre-suffix attack mechanism to reduce inconsistent outputs. Our approach has\nshown superior performance in extensive experiments across various benchmarks,\nachieving nearly 100% success rates in both attack execution and\ntransferability. Notably, our method has won the first place in the AISG-hosted\nGlobal Challenge for Safe and Secure LLMs. The code is released at\nhttps://github.com/HqingLiu/SI-GCG.",
      "tldr_zh": "该研究针对大型语言模型(Large Language Models)的安全对齐问题，提出了一种提升jailbreak attacks转移性的方法，以解决现有方法如GCG在单模型攻击中缺乏可转移性的局限。关键创新包括场景诱导模板(scenario induction template)、优化的后缀选择和重新后缀攻击机制，用于减少输出不一致。实验结果显示，该方法在各种基准上实现了近100%的攻击成功率和转移性表现，并赢得了AISG主办的全球安全LLM挑战赛第一名。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15645v2",
      "published_date": "2024-10-21 05:11:19 UTC",
      "updated_date": "2024-11-03 12:22:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:43:55.230231"
    },
    {
      "arxiv_id": "2410.15644v1",
      "title": "Procedural Content Generation in Games: A Survey with Insights on Emerging LLM Integration",
      "title_zh": "翻译失败",
      "authors": [
        "Mahdi Farrokhi Maleki",
        "Richard Zhao"
      ],
      "abstract": "Procedural Content Generation (PCG) is defined as the automatic creation of\ngame content using algorithms. PCG has a long history in both the game industry\nand the academic world. It can increase player engagement and ease the work of\ngame designers. While recent advances in deep learning approaches in PCG have\nenabled researchers and practitioners to create more sophisticated content, it\nis the arrival of Large Language Models (LLMs) that truly disrupted the\ntrajectory of PCG advancement.\n  This survey explores the differences between various algorithms used for PCG,\nincluding search-based methods, machine learning-based methods, other\nfrequently used methods (e.g., noise functions), and the newcomer, LLMs. We\nalso provide a detailed discussion on combined methods. Furthermore, we compare\nthese methods based on the type of content they generate and the publication\ndates of their respective papers. Finally, we identify gaps in the existing\nacademic work and suggest possible directions for future research.",
      "tldr_zh": "本调查回顾了游戏中的 Procedural Content Generation (PCG)，一种通过算法自动生成游戏内容的技術，并强调了 Large Language Models (LLMs) 的新兴整合如何改变了 PCG 的发展轨迹。论文比较了各种 PCG 方法，包括基于搜索的、基于机器学习的、其他常用方法（如噪声函数）以及 LLMs，还讨论了这些方法的组合应用，并根据生成内容类型和出版日期进行分析。研究发现，LLMs 显著提升了内容复杂性，但现有工作存在研究空白，如对混合方法的深入探索。未来方向包括建议更多整合 LLMs 的创新研究，以增强玩家参与度和设计效率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15644v1",
      "published_date": "2024-10-21 05:10:13 UTC",
      "updated_date": "2024-10-21 05:10:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:44:07.161724"
    },
    {
      "arxiv_id": "2410.15642v1",
      "title": "Resource-Efficient Medical Report Generation using Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Abdullah",
        "Ameer Hamza",
        "Seong Tae Kim"
      ],
      "abstract": "Medical report generation is the task of automatically writing radiology\nreports for chest X-ray images. Manually composing these reports is a\ntime-consuming process that is also prone to human errors. Generating medical\nreports can therefore help reduce the burden on radiologists. In other words,\nwe can promote greater clinical automation in the medical domain. In this work,\nwe propose a new framework leveraging vision-enabled Large Language Models\n(LLM) for the task of medical report generation. We introduce a lightweight\nsolution that achieves better or comparative performance as compared to\nprevious solutions on the task of medical report generation. We conduct\nextensive experiments exploring different model sizes and enhancement\napproaches, such as prefix tuning to improve the text generation abilities of\nthe LLMs. We evaluate our approach on a prominent large-scale radiology report\ndataset - MIMIC-CXR. Our results demonstrate the capability of our\nresource-efficient framework to generate patient-specific reports with strong\nmedical contextual understanding and high precision.",
      "tldr_zh": "本研究提出了一种资源高效的框架，利用视觉启用的大型语言模型（vision-enabled Large Language Models, LLMs）来自动生成放射学报告，例如针对胸部 X 光图像，从而减轻放射科医生的负担并减少人为错误。框架采用轻量级设计，并通过 prefix tuning 等增强方法来提升文本生成能力。实验在 MIMIC-CXR 数据集上评估了不同模型大小，结果显示该框架在生成患者特定报告时，表现出色，具有强烈的医疗语境理解和高精度，与现有解决方案相当或更优。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15642v1",
      "published_date": "2024-10-21 05:08:18 UTC",
      "updated_date": "2024-10-21 05:08:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:44:19.403971"
    },
    {
      "arxiv_id": "2410.15633v4",
      "title": "GATEAU: Selecting Influential Samples for Long Context Alignment",
      "title_zh": "GATEAU：",
      "authors": [
        "Shuzheng Si",
        "Haozhe Zhao",
        "Gang Chen",
        "Yunshui Li",
        "Kangyang Luo",
        "Chuancheng Lv",
        "Kaikai An",
        "Fanchao Qi",
        "Baobao Chang",
        "Maosong Sun"
      ],
      "abstract": "Aligning large language models to handle instructions with extremely long\ncontexts has yet to be fully investigated. Previous studies attempt to scale up\nthe available data volume by synthesizing long instruction-following samples,\nas constructing such a dataset tends to be challenging for annotators. However,\na lack of a well-defined strategy for ensuring data quality may introduce\nlow-quality samples and restrict the model performance. Thus, we propose\nGATEAU, a novel framework to address the unique challenge of long context\nalignment by identifying the influential samples enriched with long-range\ndependency relations. Specifically, GATEAU measures the long-range dependencies\nfrom two essential aspects: the difficulty of generating target responses due\nto the long-range dependencies, and the difficulty of understanding long inputs\ndue to such dependencies. Comprehensive experiments indicate that GATEAU\neffectively identifies influential samples and the model trained on these\nselected samples exhibits better instruction-following and long-context\nunderstanding capabilities.",
      "tldr_zh": "该研究提出 GATEAU 框架，用于选择影响性样本以提升大型语言模型（LLMs）在长上下文对齐方面的性能，解决现有合成数据方法可能引入低质量样本的问题。GATEAU 通过从两个关键方面衡量长距离依赖关系——生成目标响应的难度和理解长输入的难度——来识别富含这些依赖的样本。实验结果显示，使用 GATEAU 选定的样本训练的模型，在指令遵循和长上下文理解能力上显著优于基线模型。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15633v4",
      "published_date": "2024-10-21 04:30:53 UTC",
      "updated_date": "2025-02-12 03:32:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:44:30.870238"
    },
    {
      "arxiv_id": "2410.15628v3",
      "title": "Towards Kriging-informed Conditional Diffusion for Regional Sea-Level Data Downscaling",
      "title_zh": "翻译失败",
      "authors": [
        "Subhankar Ghosh",
        "Arun Sharma",
        "Jayant Gupta",
        "Aneesh Subramanian",
        "Shashi Shekhar"
      ],
      "abstract": "Given coarser-resolution projections from global climate models or satellite\ndata, the downscaling problem aims to estimate finer-resolution regional\nclimate data, capturing fine-scale spatial patterns and variability.\nDownscaling is any method to derive high-resolution data from low-resolution\nvariables, often to provide more detailed and local predictions and analyses.\nThis problem is societally crucial for effective adaptation, mitigation, and\nresilience against significant risks from climate change. The challenge arises\nfrom spatial heterogeneity and the need to recover finer-scale features while\nensuring model generalization. Most downscaling methods \\cite{Li2020} fail to\ncapture the spatial dependencies at finer scales and underperform on real-world\nclimate datasets, such as sea-level rise. We propose a novel Kriging-informed\nConditional Diffusion Probabilistic Model (Ki-CDPM) to capture spatial\nvariability while preserving fine-scale features. Experimental results on\nclimate data show that our proposed method is more accurate than\nstate-of-the-art downscaling techniques.",
      "tldr_zh": "该论文针对气候数据下采样问题，旨在从全球气候模型或卫星数据的粗分辨率投影中，推断细分辨率区域数据，以捕捉空间异质性和细尺度特征，从而支持气候变化适应和风险管理。作者提出了一种新型 Kriging-informed Conditional Diffusion Probabilistic Model (Ki-CDPM)，该方法结合 Kriging 插值技术和条件扩散模型，增强了对空间变异性的捕捉和细尺度特征的保留。实验结果显示，在海平面上升等真实气候数据集上，Ki-CDPM 比现有最先进技术更准确，证明了其在气候数据分析中的潜力。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15628v3",
      "published_date": "2024-10-21 04:24:10 UTC",
      "updated_date": "2025-01-27 09:09:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:44:42.754963"
    },
    {
      "arxiv_id": "2410.15625v2",
      "title": "Improving Parallel Program Performance with LLM Optimizers via Agent-System Interface",
      "title_zh": "翻译失败",
      "authors": [
        "Anjiang Wei",
        "Allen Nie",
        "Thiago S. F. X. Teixeira",
        "Rohan Yadav",
        "Wonchan Lee",
        "Ke Wang",
        "Alex Aiken"
      ],
      "abstract": "Modern scientific discovery increasingly relies on high-performance computing\nfor complex modeling and simulation. A key challenge in improving parallel\nprogram performance is efficiently mapping tasks to processors and data to\nmemory, a process dictated by intricate, low-level system code known as\nmappers. Developing high-performance mappers demands days of manual tuning,\nposing a significant barrier for domain scientists without systems expertise.\nWe introduce a framework that automates mapper development with generative\noptimization, leveraging richer feedback beyond scalar performance metrics. Our\napproach features the Agent-System Interface, which includes a Domain-Specific\nLanguage (DSL) to abstract away low-level complexity of system code and define\na structured search space, as well as AutoGuide, a mechanism that interprets\nraw execution output into actionable feedback. Unlike traditional reinforcement\nlearning methods such as OpenTuner, which rely solely on scalar feedback, our\nmethod finds superior mappers in far fewer iterations. With just 10 iterations,\nit outperforms OpenTuner even after 1000 iterations, achieving 3.8X faster\nperformance. Our approach finds mappers that surpass expert-written mappers by\nup to 1.34X speedup across nine benchmarks while reducing tuning time from days\nto minutes.",
      "tldr_zh": "这篇论文提出了一种框架，使用 LLM 优化器通过 Agent-System Interface 自动改进并行程序性能，解决手动调优 mappers 的复杂性和耗时问题。该框架包括 Domain-Specific Language (DSL) 来抽象低级系统代码并定义结构化搜索空间，以及 AutoGuide 机制将原始执行输出转化为可操作反馈，从而提供比传统标量反馈更丰富的优化指导。与 OpenTuner 等强化学习方法相比，该方法仅需 10 次迭代就超越其 1000 次性能，在九个基准测试中实现高达 1.34 倍的速度提升，并将调优时间从数日缩短至分钟。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15625v2",
      "published_date": "2024-10-21 04:08:37 UTC",
      "updated_date": "2025-01-31 06:36:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:44:55.693474"
    },
    {
      "arxiv_id": "2410.15616v1",
      "title": "Weighted Diversified Sampling for Efficient Data-Driven Single-Cell Gene-Gene Interaction Discovery",
      "title_zh": "加权多样化采样用于高效数据驱动的单细胞基因-基因相互作用发现",
      "authors": [
        "Yifan Wu",
        "Yuntao Yang",
        "Zirui Liu",
        "Zhao Li",
        "Khushbu Pahwa",
        "Rongbin Li",
        "Wenjin Zheng",
        "Xia Hu",
        "Zhaozhuo Xu"
      ],
      "abstract": "Gene-gene interactions play a crucial role in the manifestation of complex\nhuman diseases. Uncovering significant gene-gene interactions is a challenging\ntask. Here, we present an innovative approach utilizing data-driven\ncomputational tools, leveraging an advanced Transformer model, to unearth\nnoteworthy gene-gene interactions. Despite the efficacy of Transformer models,\ntheir parameter intensity presents a bottleneck in data ingestion, hindering\ndata efficiency. To mitigate this, we introduce a novel weighted diversified\nsampling algorithm. This algorithm computes the diversity score of each data\nsample in just two passes of the dataset, facilitating efficient subset\ngeneration for interaction discovery. Our extensive experimentation\ndemonstrates that by sampling a mere 1\\% of the single-cell dataset, we achieve\nperformance comparable to that of utilizing the entire dataset.",
      "tldr_zh": "这篇论文提出了一种加权多样化采样（weighted diversified sampling）算法，用于高效的数据驱动单细胞（single-cell）基因-基因相互作用发现，旨在解决Transformer模型参数密集导致的数据效率问题。该算法通过仅两次遍历数据集计算每个样本的多样性分数，生成优化子集，从而加速相互作用的挖掘过程。实验结果显示，采样数据集的1%即可实现与使用完整数据集相当的性能水平，为复杂人类疾病研究提供了更高效的计算工具。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15616v1",
      "published_date": "2024-10-21 03:35:23 UTC",
      "updated_date": "2024-10-21 03:35:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:45:06.424569"
    },
    {
      "arxiv_id": "2410.15607v1",
      "title": "Reinforced Imitative Trajectory Planning for Urban Automated Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Di Zeng",
        "Ling Zheng",
        "Xiantong Yang",
        "Yinong Li"
      ],
      "abstract": "Reinforcement learning (RL) faces challenges in trajectory planning for urban\nautomated driving due to the poor convergence of RL and the difficulty in\ndesigning reward functions. The convergence problem is alleviated by combining\nRL with supervised learning. However, most existing approaches only reason one\nstep ahead and lack the capability to plan for multiple future steps. Besides,\nalthough inverse reinforcement learning holds promise for solving the reward\nfunction design issue, existing methods for automated driving impose a linear\nstructure assumption on reward functions, making them difficult to apply to\nurban automated driving. In light of these challenges, this paper proposes a\nnovel RL-based trajectory planning method that integrates RL with imitation\nlearning to enable multi-step planning. Furthermore, a transformer-based\nBayesian reward function is developed, providing effective reward signals for\nRL in urban scenarios. Moreover, a hybrid-driven trajectory planning framework\nis proposed to enhance safety and interpretability. The proposed methods were\nvalidated on the large-scale real-world urban automated driving nuPlan dataset.\nThe results demonstrated the significant superiority of the proposed methods\nover the baselines in terms of the closed-loop metrics. The code is available\nat https://github.com/Zigned/nuplan_zigned.",
      "tldr_zh": "本文提出了一种针对城市自动驾驶轨迹规划的强化学习 (RL) 方法，通过整合 RL 与模仿学习 (imitation learning)，实现多步未来规划，解决了 RL 的收敛问题和奖励函数设计挑战。方法包括开发基于 Transformer 的 Bayesian 奖励函数，提供适用于城市场景的有效奖励信号，并构建混合驱动的轨迹规划框架，以提升安全性和可解释性。在大型真实世界数据集 nuPlan 上验证，结果显示该方法在闭环指标上显著优于基线模型，代码已开源于 GitHub。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "19 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.15607v1",
      "published_date": "2024-10-21 03:04:29 UTC",
      "updated_date": "2024-10-21 03:04:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:45:19.622950"
    },
    {
      "arxiv_id": "2410.15605v1",
      "title": "Deep Active Learning with Manifold-preserving Trajectory Sampling",
      "title_zh": "翻译失败",
      "authors": [
        "Yingrui Ji",
        "Vijaya Sindhoori Kaza",
        "Nishanth Artham",
        "Tianyang Wang"
      ],
      "abstract": "Active learning (AL) is for optimizing the selection of unlabeled data for\nannotation (labeling), aiming to enhance model performance while minimizing\nlabeling effort. The key question in AL is which unlabeled data should be\nselected for annotation. Existing deep AL methods arguably suffer from bias\nincurred by clabeled data, which takes a much lower percentage than unlabeled\ndata in AL context. We observe that such an issue is severe in different types\nof data, such as vision and non-vision data. To address this issue, we propose\na novel method, namely Manifold-Preserving Trajectory Sampling (MPTS), aiming\nto enforce the feature space learned from labeled data to represent a more\naccurate manifold. By doing so, we expect to effectively correct the bias\nincurred by labeled data, which can cause a biased selection of unlabeled data.\nDespite its focus on manifold, the proposed method can be conveniently\nimplemented by performing distribution mapping with MMD (Maximum Mean\nDiscrepancies). Extensive experiments on various vision and non-vision\nbenchmark datasets demonstrate the superiority of our method. Our source code\ncan be found here.",
      "tldr_zh": "这篇论文针对Active Learning (AL)中的标注数据偏差问题，提出了一种新方法Manifold-Preserving Trajectory Sampling (MPTS)，旨在通过确保特征空间更准确地表示流形来纠正偏差。MPTS利用Maximum Mean Discrepancies (MMD)进行分布映射，优化未标注数据的选择，从而提高模型性能并减少标注工作。实验在多种视觉和非视觉基准数据集上证明，该方法优于现有深度AL方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15605v1",
      "published_date": "2024-10-21 03:04:09 UTC",
      "updated_date": "2024-10-21 03:04:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:45:30.840145"
    },
    {
      "arxiv_id": "2410.15602v1",
      "title": "P-YOLOv8: Efficient and Accurate Real-Time Detection of Distracted Driving",
      "title_zh": "P-YOLOv8：高效且准确的实时分心驾驶检测",
      "authors": [
        "Mohamed R. Elshamy",
        "Heba M. Emara",
        "Mohamed R. Shoaib",
        "Abdel-Hameed A. Badawy"
      ],
      "abstract": "Distracted driving is a critical safety issue that leads to numerous\nfatalities and injuries worldwide. This study addresses the urgent need for\nefficient and real-time machine learning models to detect distracted driving\nbehaviors. Leveraging the Pretrained YOLOv8 (P-YOLOv8) model, a real-time\nobject detection system is introduced, optimized for both speed and accuracy.\nThis approach addresses the computational constraints and latency limitations\ncommonly associated with conventional detection models. The study demonstrates\nP-YOLOv8 versatility in both object detection and image classification tasks\nusing the Distracted Driver Detection dataset from State Farm, which includes\n22,424 images across ten behavior categories. Our research explores the\napplication of P-YOLOv8 for image classification, evaluating its performance\ncompared to deep learning models such as VGG16, VGG19, and ResNet. Some\ntraditional models often struggle with low accuracy, while others achieve high\naccuracy but come with high computational costs and slow detection speeds,\nmaking them unsuitable for real-time applications. P-YOLOv8 addresses these\nissues by achieving competitive accuracy with significant computational cost\nand efficiency advantages. In particular, P-YOLOv8 generates a lightweight\nmodel with a size of only 2.84 MB and a lower number of parameters, totaling\n1,451,098, due to its innovative architecture. It achieves a high accuracy of\n99.46 percent with this small model size, opening new directions for deployment\non inexpensive and small embedded devices using Tiny Machine Learning (TinyML).\nThe experimental results show robust performance, making P-YOLOv8 a\ncost-effective solution for real-time deployment. This study provides a\ndetailed analysis of P-YOLOv8's architecture, training, and performance\nbenchmarks, highlighting its potential for real-time use in detecting\ndistracted driving.",
      "tldr_zh": "这篇论文提出了 P-YOLOv8，一种基于预训练 YOLOv8 的高效实时物体检测模型，针对分心驾驶行为进行检测，以解决传统模型的计算限制和延迟问题。研究利用 State Farm 的 Distracted Driver Detection 数据集（包含 22,424 张图像和十个行为类别），评估了 P-YOLOv8 在物体检测和图像分类任务中的性能，并与 VGG16、VGG19 和 ResNet 等深度学习模型进行比较。P-YOLOv8 实现了 99.46% 的高准确率，同时保持轻量级设计——模型大小仅 2.84 MB，参数量为 1,451,098，这使其适合 TinyML 在小型嵌入式设备上的部署。总体而言，该方法为实时分心驾驶检测提供了成本效益高的解决方案，并通过实验验证了其鲁棒性。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15602v1",
      "published_date": "2024-10-21 02:56:44 UTC",
      "updated_date": "2024-10-21 02:56:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:45:44.216207"
    },
    {
      "arxiv_id": "2410.15600v1",
      "title": "Patrol Security Game: Defending Against Adversary with Freedom in Attack Timing, Location, and Duration",
      "title_zh": "翻译失败",
      "authors": [
        "Hao-Tsung Yang",
        "Ting-Kai Weng",
        "Ting-Yu Chang",
        "Kin Sum Liu",
        "Shan Lin",
        "Jie Gao",
        "Shih-Yu Tsai"
      ],
      "abstract": "We explored the Patrol Security Game (PSG), a robotic patrolling problem\nmodeled as an extensive-form Stackelberg game, where the attacker determines\nthe timing, location, and duration of their attack. Our objective is to devise\na patrolling schedule with an infinite time horizon that minimizes the\nattacker's payoff. We demonstrated that PSG can be transformed into a\ncombinatorial minimax problem with a closed-form objective function. By\nconstraining the defender's strategy to a time-homogeneous first-order Markov\nchain (i.e., the patroller's next move depends solely on their current\nlocation), we proved that the optimal solution in cases of zero penalty\ninvolves either minimizing the expected hitting time or return time, depending\non the attacker model, and that these solutions can be computed efficiently.\nAdditionally, we observed that increasing the randomness in the patrol schedule\nreduces the attacker's expected payoff in high-penalty cases. However, the\nminimax problem becomes non-convex in other scenarios. To address this, we\nformulated a bi-criteria optimization problem incorporating two objectives:\nexpected maximum reward and entropy. We proposed three graph-based algorithms\nand one deep reinforcement learning model, designed to efficiently balance the\ntrade-off between these two objectives. Notably, the third algorithm can\nidentify the optimal deterministic patrol schedule, though its runtime grows\nexponentially with the number of patrol spots. Experimental results validate\nthe effectiveness and scalability of our solutions, demonstrating that our\napproaches outperform state-of-the-art baselines on both synthetic and\nreal-world crime datasets.",
      "tldr_zh": "本研究探讨了Patrol Security Game (PSG)，一种扩展形式Stackelberg游戏，用于机器人巡逻防御攻击者，该攻击者可自由选择攻击的时间、地点和持续时间。论文将PSG转化为组合最小最大问题，并证明在零惩罚情况下，通过将防御者策略限制为时间同质的一阶Markov链，最优解可通过最小化期望命中时间或返回时间高效计算。针对高惩罚场景，研究发现增加巡逻调度的随机性可降低攻击者收益，并提出三个基于图的算法和一个深度强化学习模型来解决双标准优化问题（平衡期望最大奖励和熵）。实验结果显示，这些方法在合成和真实世界犯罪数据集上优于现有基线，验证了其有效性和可扩展性。",
      "categories": [
        "cs.AI",
        "cs.GT",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "Under review of TCPS",
      "pdf_url": "http://arxiv.org/pdf/2410.15600v1",
      "published_date": "2024-10-21 02:53:18 UTC",
      "updated_date": "2024-10-21 02:53:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:45:55.836115"
    },
    {
      "arxiv_id": "2410.15597v1",
      "title": "A Comprehensive Comparative Study of Individual ML Models and Ensemble Strategies for Network Intrusion Detection Systems",
      "title_zh": "针对网络入侵检测系统的个别机器学习模型和集成策略的全面比较研究",
      "authors": [
        "Ismail Bibers",
        "Osvaldo Arreche",
        "Mustafa Abdallah"
      ],
      "abstract": "The escalating frequency of intrusions in networked systems has spurred the\nexploration of new research avenues in devising artificial intelligence (AI)\ntechniques for intrusion detection systems (IDS). Various AI techniques have\nbeen used to automate network intrusion detection tasks, yet each model\npossesses distinct strengths and weaknesses. Selecting the optimal model for a\ngiven dataset can pose a challenge, necessitating the exploration of ensemble\nmethods to enhance generalization and applicability in network intrusion\ndetection. This paper addresses this gap by conducting a comprehensive\nevaluation of diverse individual models and both simple and advanced ensemble\nmethods for network IDS. We introduce an ensemble learning framework tailored\nfor assessing individual models and ensemble methods in network intrusion\ndetection tasks. Our framework encompasses the loading of input datasets,\ntraining of individual models and ensemble methods, and the generation of\nevaluation metrics. Furthermore, we incorporate all features across individual\nmodels and ensemble techniques. The study presents results for our framework,\nencompassing 14 methods, including various bagging, stacking, blending, and\nboosting techniques applied to multiple base learners such as decision trees,\nneural networks, and among others. We evaluate the framework using two distinct\nnetwork intrusion datasets, RoEduNet-SIMARGL2021 and CICIDS-2017, each\npossessing unique characteristics. Additionally, we categorize AI models based\non their performances on our evaluation metrics and via their confusion\nmatrices. Our assessment demonstrates the efficacy of learning across most\nsetups explored in this study. Furthermore, we contribute to the community by\nreleasing our source codes, providing a foundational ensemble learning\nframework for network intrusion detection.",
      "tldr_zh": "本研究对单个机器学习（ML）模型和集成策略（如 bagging、stacking、blending 和 boosting）在网络入侵检测系统（Network Intrusion Detection Systems）中的性能进行了全面比较，旨在解决模型选择挑战并提升泛化能力。研究引入了一个专属集成学习框架，包括数据集加载、训练各种基学习器（如 decision trees 和 neural networks）、以及生成评估指标，使用 RoEduNet-SIMARGL2021 和 CICIDS-2017 两个数据集进行实验。结果显示，大多数集成方法在性能指标和混淆矩阵上表现出色，证明了其有效性；此外，论文开源了代码，为社区提供了网络入侵检测的基准框架。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15597v1",
      "published_date": "2024-10-21 02:44:58 UTC",
      "updated_date": "2024-10-21 02:44:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:46:07.337175"
    },
    {
      "arxiv_id": "2410.19003v2",
      "title": "Whither Bias Goes, I Will Go: An Integrative, Systematic Review of Algorithmic Bias Mitigation",
      "title_zh": "翻译失败",
      "authors": [
        "Louis Hickman",
        "Christopher Huynh",
        "Jessica Gass",
        "Brandon Booth",
        "Jason Kuruzovich",
        "Louis Tay"
      ],
      "abstract": "Machine learning (ML) models are increasingly used for personnel assessment\nand selection (e.g., resume screeners, automatically scored interviews).\nHowever, concerns have been raised throughout society that ML assessments may\nbe biased and perpetuate or exacerbate inequality. Although organizational\nresearchers have begun investigating ML assessments from traditional\npsychometric and legal perspectives, there is a need to understand, clarify,\nand integrate fairness operationalizations and algorithmic bias mitigation\nmethods from the computer science, data science, and organizational research\nliteratures. We present a four-stage model of developing ML assessments and\napplying bias mitigation methods, including 1) generating the training data, 2)\ntraining the model, 3) testing the model, and 4) deploying the model. When\nintroducing the four-stage model, we describe potential sources of bias and\nunfairness at each stage. Then, we systematically review definitions and\noperationalizations of algorithmic bias, legal requirements governing personnel\nselection from the United States and Europe, and research on algorithmic bias\nmitigation across multiple domains and integrate these findings into our\nframework. Our review provides insights for both research and practice by\nelucidating possible mechanisms of algorithmic bias while identifying which\nbias mitigation methods are legal and effective. This integrative framework\nalso reveals gaps in the knowledge of algorithmic bias mitigation that should\nbe addressed by future collaborative research between organizational\nresearchers, computer scientists, and data scientists. We provide\nrecommendations for developing and deploying ML assessments, as well as\nrecommendations for future research into algorithmic bias and fairness.",
      "tldr_zh": "这篇论文系统回顾了算法偏见（algorithmic bias）在机器学习（ML）模型用于人员评估和选择中的问题，提出一个四阶段模型（生成训练数据、训练模型、测试模型和部署模型），以识别并缓解每个阶段的潜在偏见来源。研究整合了计算机科学、数据科学和组织研究的文献，定义了算法偏见的操作化和法律要求（如美国和欧洲的法规），并评估了各种偏见缓解方法的有效性和合法性。最终，该框架为实践提供见解和推荐，并指出未来研究应填补知识空白，促进跨领域合作，以实现更公平的ML评估。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "forthcoming in Journal of Applied Psychology",
      "pdf_url": "http://arxiv.org/pdf/2410.19003v2",
      "published_date": "2024-10-21 02:32:14 UTC",
      "updated_date": "2024-10-31 15:06:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:46:19.286940"
    },
    {
      "arxiv_id": "2410.15595v2",
      "title": "A Comprehensive Survey of Direct Preference Optimization: Datasets, Theories, Variants, and Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Wenyi Xiao",
        "Zechuan Wang",
        "Leilei Gan",
        "Shuai Zhao",
        "Wanggui He",
        "Luu Anh Tuan",
        "Long Chen",
        "Hao Jiang",
        "Zhou Zhao",
        "Fei Wu"
      ],
      "abstract": "With the rapid advancement of large language models (LLMs), aligning policy\nmodels with human preferences has become increasingly critical. Direct\nPreference Optimization (DPO) has emerged as a promising approach for\nalignment, acting as an RL-free alternative to Reinforcement Learning from\nHuman Feedback (RLHF). Despite DPO's various advancements and inherent\nlimitations, an in-depth review of these aspects is currently lacking in the\nliterature. In this work, we present a comprehensive review of the challenges\nand opportunities in DPO, covering theoretical analyses, variants, relevant\npreference datasets, and applications. Specifically, we categorize recent\nstudies on DPO based on key research questions to provide a thorough\nunderstanding of DPO's current landscape. Additionally, we propose several\nfuture research directions to offer insights on model alignment for the\nresearch community.",
      "tldr_zh": "这篇论文对Direct Preference Optimization (DPO)进行了全面调查，作为一种无需强化学习的替代方案，用于对齐大型语言模型(LLMs)的人类偏好。作者分析了DPO的挑战、理论基础、变体、相关偏好数据集以及实际应用，并基于关键研究问题对近期研究进行了分类整理。最终，论文提出了未来研究方向，以推动模型对齐领域的进展。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15595v2",
      "published_date": "2024-10-21 02:27:24 UTC",
      "updated_date": "2024-11-10 13:46:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:46:30.485877"
    },
    {
      "arxiv_id": "2410.15591v1",
      "title": "AMPLE: Emotion-Aware Multimodal Fusion Prompt Learning for Fake News Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoman Xu",
        "Xiangrun Li",
        "Taihang Wang",
        "Ye Jiang"
      ],
      "abstract": "Detecting fake news in large datasets is challenging due to its diversity and\ncomplexity, with traditional approaches often focusing on textual features\nwhile underutilizing semantic and emotional elements. Current methods also rely\nheavily on large annotated datasets, limiting their effectiveness in more\nnuanced analysis. To address these challenges, this paper introduces\nEmotion-\\textbf{A}ware \\textbf{M}ultimodal Fusion \\textbf{P}rompt\n\\textbf{L}\\textbf{E}arning (\\textbf{AMPLE}) framework to address the above\nissue by combining text sentiment analysis with multimodal data and hybrid\nprompt templates. This framework extracts emotional elements from texts by\nleveraging sentiment analysis tools. It then employs Multi-Head Cross-Attention\n(MCA) mechanisms and similarity-aware fusion methods to integrate multimodal\ndata. The proposed AMPLE framework demonstrates strong performance on two\npublic datasets in both few-shot and data-rich settings, with results\nindicating the potential of emotional aspects in fake news detection.\nFurthermore, the study explores the impact of integrating large language models\nwith this method for text sentiment extraction, revealing substantial room for\nfurther improvement. The code can be found at\n:\\url{https://github.com/xxm1215/MMM2025_few-shot/",
      "tldr_zh": "本研究提出了一种Emotion-Aware Multimodal Fusion Prompt Learning（AMPLE）框架，用于解决假新闻检测中的挑战，该框架通过结合文本情感分析和多模态数据融合，超越传统方法的文本特征依赖。AMPLE利用情感提取工具从文本中获取情感元素，并采用Multi-Head Cross-Attention (MCA)机制和相似性感知融合方法整合多模态信息，以提升检测的准确性和鲁棒性。在两个公共数据集上，该框架在少样本和数据丰富的设置中表现出色，证明了情感因素在假新闻检测中的关键作用。此外，研究探索了整合大型语言模型进行情感提取的潜力，为未来改进提供了新方向。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15591v1",
      "published_date": "2024-10-21 02:19:24 UTC",
      "updated_date": "2024-10-21 02:19:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:46:42.680053"
    },
    {
      "arxiv_id": "2410.15573v3",
      "title": "OpenMU: Your Swiss Army Knife for Music Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Mengjie Zhao",
        "Zhi Zhong",
        "Zhuoyuan Mao",
        "Shiqi Yang",
        "Wei-Hsiang Liao",
        "Shusuke Takahashi",
        "Hiromi Wakaki",
        "Yuki Mitsufuji"
      ],
      "abstract": "We present OpenMU-Bench, a large-scale benchmark suite for addressing the\ndata scarcity issue in training multimodal language models to understand music.\nTo construct OpenMU-Bench, we leveraged existing datasets and bootstrapped new\nannotations. OpenMU-Bench also broadens the scope of music understanding by\nincluding lyrics understanding and music tool usage. Using OpenMU-Bench, we\ntrained our music understanding model, OpenMU, with extensive ablations,\ndemonstrating that OpenMU outperforms baseline models such as MU-Llama. Both\nOpenMU and OpenMU-Bench are open-sourced to facilitate future research in music\nunderstanding and to enhance creative music production efficiency.",
      "tldr_zh": "本论文介绍了 OpenMU-Bench，这是一个大规模基准测试套件，用于解决训练多模态语言模型理解音乐时的数据稀缺问题，并通过利用现有数据集和引导新标注来构建它，同时扩展了音乐理解的范围，包括 lyrics understanding 和 music tool usage。研究者使用 OpenMU-Bench 训练了 OpenMU 模型，并通过广泛的 ablations 实验证明其性能优于基线模型如 MU-Llama。OpenMU 和 OpenMU-Bench 已开源，以促进未来音乐理解研究并提升创意音乐制作效率。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "cs.MM",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Resources: https://github.com/sony/openmu",
      "pdf_url": "http://arxiv.org/pdf/2410.15573v3",
      "published_date": "2024-10-21 01:36:42 UTC",
      "updated_date": "2024-11-27 05:43:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:46:55.767115"
    },
    {
      "arxiv_id": "2410.15572v1",
      "title": "Leveraging Retrieval-Augmented Generation for Culturally Inclusive Hakka Chatbots: Design Insights and User Perceptions",
      "title_zh": "利用检索增强生成实现文化包容的Hakka聊天机器人：设计洞见与用户感知",
      "authors": [
        "Chen-Chi Chang",
        "Han-Pi Chang",
        "Hung-Shin Lee"
      ],
      "abstract": "In an era where cultural preservation is increasingly intertwined with\ntechnological innovation, this study introduces a groundbreaking approach to\npromoting and safeguarding the rich heritage of Taiwanese Hakka culture through\nthe development of a Retrieval-Augmented Generation (RAG)-enhanced chatbot.\nTraditional large language models (LLMs), while powerful, often fall short in\ndelivering accurate and contextually rich responses, particularly in culturally\nspecific domains. By integrating external databases with generative AI models,\nRAG technology bridges this gap, empowering chatbots to not only provide\nprecise answers but also resonate deeply with the cultural nuances that are\ncrucial for authentic interactions. This study delves into the intricate\nprocess of augmenting the chatbot's knowledge base with targeted cultural data,\nspecifically curated to reflect the unique aspects of Hakka traditions,\nlanguage, and practices. Through dynamic information retrieval, the\nRAG-enhanced chatbot becomes a versatile tool capable of handling complex\ninquiries that demand an in-depth understanding of Hakka cultural context. This\nis particularly significant in an age where digital platforms often dilute\ncultural identities, making the role of culturally aware AI systems more\ncritical than ever. System usability studies conducted as part of our research\nreveal a marked improvement in both user satisfaction and engagement,\nhighlighting the chatbot's effectiveness in fostering a deeper connection with\nHakka culture. The feedback underscores the potential of RAG technology to not\nonly enhance user experience but also to serve as a vital instrument in the\nbroader mission of ethnic mainstreaming and cultural celebration.",
      "tldr_zh": "本研究利用 Retrieval-Augmented Generation (RAG) 技术开发了一个支持客家文化的聊天机器人，旨在推广和保护台湾客家遗产，同时解决传统 large language models (LLMs) 在文化特定领域准确性和语境相关性不足的问题。通过整合外部数据库和针对客家传统、语言及实践的知识库，RAG 增强了机器人的动态信息检索能力，使其能处理复杂查询并捕捉文化细微差别。用户可用性研究显示，该聊天机器人显著提高了用户满意度和参与度，为数字时代下的文化保存和民族主流化提供了有效的工具。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to IEEE RASSE 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.15572v1",
      "published_date": "2024-10-21 01:36:08 UTC",
      "updated_date": "2024-10-21 01:36:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:47:07.434591"
    },
    {
      "arxiv_id": "2410.15570v1",
      "title": "Stacking Small Language Models for Generalizability",
      "title_zh": "翻译失败",
      "authors": [
        "Laurence Liang"
      ],
      "abstract": "Recent advances show that large language models (LLMs) generalize strong\nperformance across different natural language benchmarks. However, the large\nsize of LLMs makes training and inference expensive and impractical to run in\nresource-limited settings. This paper introduces a new approach called\nfine-tuning stacks of language models (FSLM), which involves stacking small\nlanguage models (SLM) as an alternative to LLMs. By fine-tuning each SLM to\nperform a specific task, this approach breaks down high level reasoning into\nmultiple lower-level steps that specific SLMs are responsible for. As a result,\nFSLM allows for lower training and inference costs, and also improves model\ninterpretability as each SLM communicates with the subsequent one through\nnatural language. By evaluating FSLM on common natural language benchmarks,\nthis paper highlights promising early results toward generalizable performance\nusing FSLM as a cost-effective alternative to LLMs.",
      "tldr_zh": "本文提出了一种名为 fine-tuning stacks of language models (FSLM) 的新方法，通过堆叠小语言模型 (SLM) 来替代大型语言模型 (LLMs)，以实现更经济的模型训练和推理。FSLM 将高层推理分解为多个低层步骤，每个 SLM 负责特定任务，并通过自然语言进行通信，从而提升模型的可解释性。实验结果显示，FSLM 在常见自然语言基准上表现出可推广的性能，作为 LLMs 的成本效益替代方案，具有广阔潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15570v1",
      "published_date": "2024-10-21 01:27:29 UTC",
      "updated_date": "2024-10-21 01:27:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:47:18.944511"
    },
    {
      "arxiv_id": "2410.15567v1",
      "title": "Pruning Foundation Models for High Accuracy without Retraining",
      "title_zh": "翻译失败",
      "authors": [
        "Pu Zhao",
        "Fei Sun",
        "Xuan Shen",
        "Pinrui Yu",
        "Zhenglun Kong",
        "Yanzhi Wang",
        "Xue Lin"
      ],
      "abstract": "Despite the superior performance, it is challenging to deploy foundation\nmodels or large language models (LLMs) due to their massive parameters and\ncomputations. While pruning is a promising technique to reduce model size and\naccelerate the inference, the traditional pruning techniques can hardly be\napplied for LLMs as they need to finetune the model on the full dataset with\nmultiple epochs consuming massive data and hardware resources. To deal with\nthis problem, post-training pruning methods are proposed to prune LLMs in\none-shot without retraining. However, their accuracy after pruning may suffer\nfrom certain performance degradation due to the lack of retraining with massive\ndata. To address this issue, in this paper, we first formulate the\npost-training problem for layer-wise LLM compression to simultaneously prune\nmultiple weights in LLMs. Next, we provide an optimal solution for this problem\nand design our post-training pruning algorithm for both unstructured and\nsemi-structured sparsity. Our extensive experiments demonstrate the superior\nperformance of the proposed methods in comparison to SOTA baselines across\nvarious LLM families including transformer-based LLMs and Mamba-based LLMs.\nCode link: https://github.com/piuzha/APT",
      "tldr_zh": "该研究解决了基础模型和大型语言模型（LLMs）的部署挑战，提出了一种无需重新训练的后训练修剪方法，以减少模型参数和计算量同时保持高准确率。作者首先制定了层级 LLM 压缩问题，允许同时修剪多个权重，并提供了一个最优解及算法，支持非结构化（unstructured）和半结构化（semi-structured）稀疏。实验结果显示，该方法在基于 Transformer 和 Mamba 的各种 LLM 家族上，优于现有最先进（SOTA）基线，证明了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by EMNLP 2024 findings",
      "pdf_url": "http://arxiv.org/pdf/2410.15567v1",
      "published_date": "2024-10-21 01:23:34 UTC",
      "updated_date": "2024-10-21 01:23:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:47:30.926902"
    },
    {
      "arxiv_id": "2410.15555v1",
      "title": "Bayesian Concept Bottleneck Models with LLM Priors",
      "title_zh": "带有 LLM 先验的贝叶斯概念瓶颈模型",
      "authors": [
        "Jean Feng",
        "Avni Kothari",
        "Luke Zier",
        "Chandan Singh",
        "Yan Shuo Tan"
      ],
      "abstract": "Concept Bottleneck Models (CBMs) have been proposed as a compromise between\nwhite-box and black-box models, aiming to achieve interpretability without\nsacrificing accuracy. The standard training procedure for CBMs is to predefine\na candidate set of human-interpretable concepts, extract their values from the\ntraining data, and identify a sparse subset as inputs to a transparent\nprediction model. However, such approaches are often hampered by the tradeoff\nbetween enumerating a sufficiently large set of concepts to include those that\nare truly relevant versus controlling the cost of obtaining concept\nextractions. This work investigates a novel approach that sidesteps these\nchallenges: BC-LLM iteratively searches over a potentially infinite set of\nconcepts within a Bayesian framework, in which Large Language Models (LLMs)\nserve as both a concept extraction mechanism and prior. BC-LLM is broadly\napplicable and multi-modal. Despite imperfections in LLMs, we prove that BC-LLM\ncan provide rigorous statistical inference and uncertainty quantification. In\nexperiments, it outperforms comparator methods including black-box models,\nconverges more rapidly towards relevant concepts and away from spuriously\ncorrelated ones, and is more robust to out-of-distribution samples.",
      "tldr_zh": "本研究提出Bayesian Concept Bottleneck Models with LLM Priors (BC-LLM)，一种在贝叶斯框架下利用Large Language Models (LLMs)作为概念提取机制和先验的创新方法，以解决传统Concept Bottleneck Models (CBMs)在概念集枚举和提取成本之间的权衡问题。BC-LLM允许在潜在无限的概念集上进行迭代搜索，并适用于多模态场景，尽管LLMs存在缺陷，但仍能提供严格的统计推断和不确定性量化。实验结果显示，BC-LLM优于黑盒模型等比较方法，能够更快收敛到相关概念、避免虚假相关性，并对分布外样本表现出更高的鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.15555v1",
      "published_date": "2024-10-21 01:00:33 UTC",
      "updated_date": "2024-10-21 01:00:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:49:36.511750"
    },
    {
      "arxiv_id": "2410.15554v2",
      "title": "A Plug-and-Play Fully On-the-Job Real-Time Reinforcement Learning Algorithm for a Direct-Drive Tandem-Wing Experiment Platforms Under Multiple Random Operating Conditions",
      "title_zh": "翻译失败",
      "authors": [
        "Zhang Minghao",
        "Song Bifeng",
        "Yang Xiaojun",
        "Wang Liang"
      ],
      "abstract": "The nonlinear and unstable aerodynamic interference generated by the tandem\nwings of such biomimetic systems poses substantial challenges for motion\ncontrol, especially under multiple random operating conditions. To address\nthese challenges, the Concerto Reinforcement Learning Extension (CRL2E)\nalgorithm has been developed. This plug-and-play, fully on-the-job, real-time\nreinforcement learning algorithm incorporates a novel Physics-Inspired\nRule-Based Policy Composer Strategy with a Perturbation Module alongside a\nlightweight network optimized for real-time control. To validate the\nperformance and the rationality of the module design, experiments were\nconducted under six challenging operating conditions, comparing seven different\nalgorithms. The results demonstrate that the CRL2E algorithm achieves safe and\nstable training within the first 500 steps, improving tracking accuracy by 14\nto 66 times compared to the Soft Actor-Critic, Proximal Policy Optimization,\nand Twin Delayed Deep Deterministic Policy Gradient algorithms. Additionally,\nCRL2E significantly enhances performance under various random operating\nconditions, with improvements in tracking accuracy ranging from 8.3% to 60.4%\ncompared to the Concerto Reinforcement Learning (CRL) algorithm. The\nconvergence speed of CRL2E is 36.11% to 57.64% faster than the CRL algorithm\nwith only the Composer Perturbation and 43.52% to 65.85% faster than the CRL\nalgorithm when both the Composer Perturbation and Time-Interleaved Capability\nPerturbation are introduced, especially in conditions where the standard CRL\nstruggles to converge. Hardware tests indicate that the optimized lightweight\nnetwork structure excels in weight loading and average inference time, meeting\nreal-time control requirements.",
      "tldr_zh": "该论文提出了一种即插即用、全职实时强化学习算法 CRL2E，针对双翼实验平台的非线性不稳定空气动力学干扰问题，尤其在多种随机操作条件下。该算法整合了 Physics-Inspired Rule-Based Policy Composer Strategy、Perturbation Module 和一个优化轻量级网络，以实现高效的实时控制。在实验中，CRL2E 与 Soft Actor-Critic (SAC)、Proximal Policy Optimization (PPO) 和 Twin Delayed Deep Deterministic Policy Gradient (TD3) 等算法相比，跟踪准确度提高了 14 到 66 倍，并比 Concerto Reinforcement Learning (CRL) 算法的收敛速度快 36.11% 到 65.85%，证明其在安全稳定训练和性能提升方面的显著优势。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "To prevent potential misunderstandings or negative impacts on the\n  community, I am requesting the withdrawal of my submission due to the\n  discovery of critical errors and major flaws in the work. Recent discussions\n  with researchers in the field have identified significant defects that\n  compromise the validity of the results",
      "pdf_url": "http://arxiv.org/pdf/2410.15554v2",
      "published_date": "2024-10-21 00:59:50 UTC",
      "updated_date": "2024-12-20 09:39:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T14:47:57.063275"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 160,
  "processed_papers_count": 160,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-20T14:49:58.424022"
}