[
  {
    "arxiv_id": "2410.16579v1",
    "title": "Conflict-Aware Adversarial Training",
    "authors": [
      "Zhiyu Xue",
      "Haohan Wang",
      "Yao Qin",
      "Ramtin Pedarsani"
    ],
    "abstract": "Adversarial training is the most effective method to obtain adversarial\nrobustness for deep neural networks by directly involving adversarial samples\nin the training procedure. To obtain an accurate and robust model, the\nweighted-average method is applied to optimize standard loss and adversarial\nloss simultaneously. In this paper, we argue that the weighted-average method\ndoes not provide the best tradeoff for the standard performance and adversarial\nrobustness. We argue that the failure of the weighted-average method is due to\nthe conflict between the gradients derived from standard and adversarial loss,\nand further demonstrate such a conflict increases with attack budget\ntheoretically and practically. To alleviate this problem, we propose a new\ntrade-off paradigm for adversarial training with a conflict-aware factor for\nthe convex combination of standard and adversarial loss, named\n\\textbf{Conflict-Aware Adversarial Training~(CA-AT)}. Comprehensive\nexperimental results show that CA-AT consistently offers a superior trade-off\nbetween standard performance and adversarial robustness under the settings of\nadversarial training from scratch and parameter-efficient finetuning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.16579v1",
    "published_date": "2024-10-21 23:44:03 UTC",
    "updated_date": "2024-10-21 23:44:03 UTC"
  },
  {
    "arxiv_id": "2410.16574v1",
    "title": "How Can We Diagnose and Treat Bias in Large Language Models for Clinical Decision-Making?",
    "authors": [
      "Kenza Benkirane",
      "Jackie Kay",
      "Maria Perez-Ortiz"
    ],
    "abstract": "Recent advancements in Large Language Models (LLMs) have positioned them as\npowerful tools for clinical decision-making, with rapidly expanding\napplications in healthcare. However, concerns about bias remain a significant\nchallenge in the clinical implementation of LLMs, particularly regarding gender\nand ethnicity. This research investigates the evaluation and mitigation of bias\nin LLMs applied to complex clinical cases, focusing on gender and ethnicity\nbiases. We introduce a novel Counterfactual Patient Variations (CPV) dataset\nderived from the JAMA Clinical Challenge. Using this dataset, we built a\nframework for bias evaluation, employing both Multiple Choice Questions (MCQs)\nand corresponding explanations. We explore prompting with eight LLMs and\nfine-tuning as debiasing methods. Our findings reveal that addressing social\nbiases in LLMs requires a multidimensional approach as mitigating gender bias\ncan occur while introducing ethnicity biases, and that gender bias in LLM\nembeddings varies significantly across medical specialities. We demonstrate\nthat evaluating both MCQ response and explanation processes is crucial, as\ncorrect responses can be based on biased \\textit{reasoning}. We provide a\nframework for evaluating LLM bias in real-world clinical cases, offer insights\ninto the complex nature of bias in these models, and present strategies for\nbias mitigation.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.16574v1",
    "published_date": "2024-10-21 23:14:10 UTC",
    "updated_date": "2024-10-21 23:14:10 UTC"
  },
  {
    "arxiv_id": "2410.16571v1",
    "title": "Implicit Contact Diffuser: Sequential Contact Reasoning with Latent Point Cloud Diffusion",
    "authors": [
      "Zixuan Huang",
      "Yinong He",
      "Yating Lin",
      "Dmitry Berenson"
    ],
    "abstract": "Long-horizon contact-rich manipulation has long been a challenging problem,\nas it requires reasoning over both discrete contact modes and continuous object\nmotion. We introduce Implicit Contact Diffuser (ICD), a diffusion-based model\nthat generates a sequence of neural descriptors that specify a series of\ncontact relationships between the object and the environment. This sequence is\nthen used as guidance for an MPC method to accomplish a given task. The key\nadvantage of this approach is that the latent descriptors provide more\ntask-relevant guidance to MPC, helping to avoid local minima for contact-rich\nmanipulation tasks. Our experiments demonstrate that ICD outperforms baselines\non complex, long-horizon, contact-rich manipulation tasks, such as cable\nrouting and notebook folding. Additionally, our experiments also indicate that\n\\methodshort can generalize a target contact relationship to a different\nenvironment. More visualizations can be found on our website\n$\\href{https://implicit-contact-diffuser.github.io/}{https://implicit-contact-diffuser.github.io}$",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "In submussion",
    "pdf_url": "http://arxiv.org/pdf/2410.16571v1",
    "published_date": "2024-10-21 23:07:48 UTC",
    "updated_date": "2024-10-21 23:07:48 UTC"
  },
  {
    "arxiv_id": "2410.16560v2",
    "title": "How Performance Pressure Influences AI-Assisted Decision Making",
    "authors": [
      "Nikita Haduong",
      "Noah A. Smith"
    ],
    "abstract": "Many domains now employ AI-based decision-making aids, and although the\npotential for AI systems to assist with decision making is much discussed,\nhuman-AI collaboration often underperforms due to factors such as (mis)trust in\nthe AI system and beliefs about AI being incapable of completing subjective\ntasks. One potential tool for influencing human decision making is performance\npressure, which hasn't been much studied in interaction with human-AI decision\nmaking. In this work, we examine how pressure and explainable AI (XAI)\ntechniques interact with AI advice-taking behavior. Using an inherently\nlow-stakes task (spam review classification), we demonstrate effective and\nsimple methods to apply pressure and influence human AI advice-taking behavior\nby manipulating financial incentives and imposing time limits. Our results show\ncomplex interaction effects, with different combinations of pressure and XAI\ntechniques either improving or worsening AI advice taking behavior. We conclude\nby discussing the implications of these interactions, strategies to effectively\nuse pressure, and encourage future research to incorporate pressure analysis.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.16560v2",
    "published_date": "2024-10-21 22:39:52 UTC",
    "updated_date": "2025-02-21 19:29:55 UTC"
  },
  {
    "arxiv_id": "2410.16547v1",
    "title": "PromptHive: Bringing Subject Matter Experts Back to the Forefront with Collaborative Prompt Engineering for Educational Content Creation",
    "authors": [
      "Mohi Reza",
      "Ioannis Anastasopoulos",
      "Shreya Bhandari",
      "Zachary A. Pardos"
    ],
    "abstract": "Involving subject matter experts in prompt engineering can guide LLM outputs\ntoward more helpful, accurate, and tailored content that meets the diverse\nneeds of different domains. However, iterating towards effective prompts can be\nchallenging without adequate interface support for systematic experimentation\nwithin specific task contexts. In this work, we introduce PromptHive, a\ncollaborative interface for prompt authoring, designed to better connect domain\nknowledge with prompt engineering through features that encourage rapid\niteration on prompt variations. We conducted an evaluation study with ten\nsubject matter experts in math and validated our design through two\ncollaborative prompt-writing sessions and a learning gain study with 358\nlearners. Our results elucidate the prompt iteration process and validate the\ntool's usability, enabling non-AI experts to craft prompts that generate\ncontent comparable to human-authored materials while reducing perceived\ncognitive load by half and shortening the authoring process from several months\nto just a few hours.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.16547v1",
    "published_date": "2024-10-21 22:18:24 UTC",
    "updated_date": "2024-10-21 22:18:24 UTC"
  },
  {
    "arxiv_id": "2410.16543v2",
    "title": "Multi-Agent LLMs Ensemble for Efficient Atrial Fibrillation Annotation of ECG Reports",
    "authors": [
      "Jingwei Huang",
      "Kuroush Nezafati",
      "Ismael Villanueva-Miranda",
      "Zifan Gu",
      "Yueshuang Xu",
      "Ann Marie Navar",
      "Tingyi Wanyan",
      "Qin Zhou",
      "Bo Yao",
      "Ruichen Rong",
      "Xiaowei Zhan",
      "Guanghua Xiao",
      "Eric D. Peterson",
      "Donghan M. Yang",
      "Wenqi Shi",
      "Yang Xie"
    ],
    "abstract": "This study introduces a novel multiagent ensemble method powered by LLMs to\naddress a key challenge in ML - data labeling, particularly in large-scale EHR\ndatasets. Manual labeling of such datasets requires domain expertise and is\nlabor-intensive, time-consuming, expensive, and error-prone. To overcome this\nbottleneck, we developed an ensemble LLMs method and demonstrated its\neffectiveness in two real-world tasks: (1) labeling a large-scale unlabeled ECG\ndataset in MIMIC-IV; (2) identifying social determinants of health (SDOH) from\nthe clinical notes of EHR. Trading off benefits and cost, we selected a pool of\ndiverse open source LLMs with satisfactory performance. We treat each LLM's\nprediction as a vote and apply a mechanism of majority voting with minimal\nwinning threshold for ensemble. We implemented an ensemble LLMs application for\nEHR data labeling tasks. By using the ensemble LLMs and natural language\nprocessing, we labeled MIMIC-IV ECG dataset of 623,566 ECG reports with an\nestimated accuracy of 98.2%. We applied the ensemble LLMs method to identify\nSDOH from social history sections of 1,405 EHR clinical notes, also achieving\ncompetitive performance. Our experiments show that the ensemble LLMs can\noutperform individual LLM even the best commercial one, and the method reduces\nhallucination errors. From the research, we found that (1) the ensemble LLMs\nmethod significantly reduces the time and effort required for labeling\nlarge-scale EHR data, automating the process with high accuracy and quality;\n(2) the method generalizes well to other text data labeling tasks, as shown by\nits application to SDOH identification; (3) the ensemble of a group of diverse\nLLMs can outperform or match the performance of the best individual LLM; and\n(4) the ensemble method substantially reduces hallucination errors. This\napproach provides a scalable and efficient solution to data-labeling\nchallenges.",
    "categories": [
      "cs.AI",
      "I.2"
    ],
    "primary_category": "cs.AI",
    "comment": "26 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.16543v2",
    "published_date": "2024-10-21 22:12:00 UTC",
    "updated_date": "2025-04-25 18:43:19 UTC"
  },
  {
    "arxiv_id": "2410.16540v1",
    "title": "A Theoretical Understanding of Chain-of-Thought: Coherent Reasoning and Error-Aware Demonstration",
    "authors": [
      "Yingqian Cui",
      "Pengfei He",
      "Xianfeng Tang",
      "Qi He",
      "Chen Luo",
      "Jiliang Tang",
      "Yue Xing"
    ],
    "abstract": "Few-shot Chain-of-Thought (CoT) prompting has demonstrated strong performance\nin improving the reasoning capabilities of large language models (LLMs). While\ntheoretical investigations have been conducted to understand CoT, the\nunderlying transformer used in these studies isolates the CoT reasoning process\ninto separated in-context learning steps (Stepwise ICL). In this work, we\ntheoretically show that, compared to Stepwise ICL, the transformer gains better\nerror correction ability and more accurate predictions if the reasoning from\nearlier steps (Coherent CoT) is integrated. Given that this coherent reasoning\nchanges the behavior of the transformer, we further investigate the sensitivity\nof the transformer with Coherent CoT when the demonstration examples are\ncorrupted at the inference stage. Our theoretical results indicate that the\ntransformer is more sensitive to errors in intermediate reasoning steps than\nthe final outcome. Building upon this observation, we propose an improvement on\nCoT by incorporating both correct and incorrect reasoning paths in the\ndemonstration. Our experiments validate the effectiveness of the proposed\napproach.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.16540v1",
    "published_date": "2024-10-21 22:07:20 UTC",
    "updated_date": "2024-10-21 22:07:20 UTC"
  },
  {
    "arxiv_id": "2411.04127v1",
    "title": "Combining Theory of Mind and Kindness for Self-Supervised Human-AI Alignment",
    "authors": [
      "Joshua T. S. Hewson"
    ],
    "abstract": "As artificial intelligence (AI) becomes deeply integrated into critical\ninfrastructures and everyday life, ensuring its safe deployment is one of\nhumanity's most urgent challenges. Current AI models prioritize task\noptimization over safety, leading to risks of unintended harm. These risks are\ndifficult to address due to the competing interests of governments, businesses,\nand advocacy groups, all of which have different priorities in the AI race.\nCurrent alignment methods, such as reinforcement learning from human feedback\n(RLHF), focus on extrinsic behaviors without instilling a genuine understanding\nof human values. These models are vulnerable to manipulation and lack the\nsocial intelligence necessary to infer the mental states and intentions of\nothers, raising concerns about their ability to safely and responsibly make\nimportant decisions in complex and novel situations. Furthermore, the\ndivergence between extrinsic and intrinsic motivations in AI introduces the\nrisk of deceptive or harmful behaviors, particularly as systems become more\nautonomous and intelligent. We propose a novel human-inspired approach which\naims to address these various concerns and help align competing objectives.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.04127v1",
    "published_date": "2024-10-21 22:04:44 UTC",
    "updated_date": "2024-10-21 22:04:44 UTC"
  },
  {
    "arxiv_id": "2410.16537v1",
    "title": "QIXAI: A Quantum-Inspired Framework for Enhancing Classical and Quantum Model Transparency and Understanding",
    "authors": [
      "John M. Willis"
    ],
    "abstract": "The impressive performance of deep learning models, particularly\nConvolutional Neural Networks (CNNs), is often hindered by their lack of\ninterpretability, rendering them \"black boxes.\" This opacity raises concerns in\ncritical areas like healthcare, finance, and autonomous systems, where trust\nand accountability are crucial. This paper introduces the QIXAI Framework\n(Quantum-Inspired Explainable AI), a novel approach for enhancing neural\nnetwork interpretability through quantum-inspired techniques. By utilizing\nprinciples from quantum mechanics, such as Hilbert spaces, superposition,\nentanglement, and eigenvalue decomposition, the QIXAI framework reveals how\ndifferent layers of neural networks process and combine features to make\ndecisions.\n  We critically assess model-agnostic methods like SHAP and LIME, as well as\ntechniques like Layer-wise Relevance Propagation (LRP), highlighting their\nlimitations in providing a comprehensive view of neural network operations. The\nQIXAI framework overcomes these limitations by offering deeper insights into\nfeature importance, inter-layer dependencies, and information propagation. A\nCNN for malaria parasite detection is used as a case study to demonstrate how\nquantum-inspired methods like Singular Value Decomposition (SVD), Principal\nComponent Analysis (PCA), and Mutual Information (MI) provide interpretable\nexplanations of model behavior. Additionally, we explore the extension of QIXAI\nto other architectures, including Recurrent Neural Networks (RNNs), Long\nShort-Term Memory (LSTM) networks, Transformers, and Natural Language\nProcessing (NLP) models, and its application to generative models and\ntime-series analysis. The framework applies to both quantum and classical\nsystems, demonstrating its potential to improve interpretability and\ntransparency across a range of models, advancing the broader goal of developing\ntrustworthy AI systems.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "quant-ph"
    ],
    "primary_category": "cs.AI",
    "comment": "18 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.16537v1",
    "published_date": "2024-10-21 21:55:09 UTC",
    "updated_date": "2024-10-21 21:55:09 UTC"
  },
  {
    "arxiv_id": "2410.16533v1",
    "title": "Large Body Language Models",
    "authors": [
      "Saif Punjwani",
      "Larry Heck"
    ],
    "abstract": "As virtual agents become increasingly prevalent in human-computer\ninteraction, generating realistic and contextually appropriate gestures in\nreal-time remains a significant challenge. While neural rendering techniques\nhave made substantial progress with static scripts, their applicability to\nhuman-computer interactions remains limited. To address this, we introduce\nLarge Body Language Models (LBLMs) and present LBLM-AVA, a novel LBLM\narchitecture that combines a Transformer-XL large language model with a\nparallelized diffusion model to generate human-like gestures from multimodal\ninputs (text, audio, and video). LBLM-AVA incorporates several key components\nenhancing its gesture generation capabilities, such as multimodal-to-pose\nembeddings, enhanced sequence-to-sequence mapping with redefined attention\nmechanisms, a temporal smoothing module for gesture sequence coherence, and an\nattention-based refinement module for enhanced realism. The model is trained on\nour large-scale proprietary open-source dataset Allo-AVA. LBLM-AVA achieves\nstate-of-the-art performance in generating lifelike and contextually\nappropriate gestures with a 30% reduction in Fr\\'echet Gesture Distance (FGD),\nand a 25% improvement in Fr\\'echet Inception Distance compared to existing\napproaches.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.16533v1",
    "published_date": "2024-10-21 21:48:24 UTC",
    "updated_date": "2024-10-21 21:48:24 UTC"
  },
  {
    "arxiv_id": "2410.16531v3",
    "title": "Bayesian scaling laws for in-context learning",
    "authors": [
      "Aryaman Arora",
      "Dan Jurafsky",
      "Christopher Potts",
      "Noah D. Goodman"
    ],
    "abstract": "In-context learning (ICL) is a powerful technique for getting language models\nto perform complex tasks with no training updates. Prior work has established\nstrong correlations between the number of in-context examples provided and the\naccuracy of the model's predictions. In this paper, we seek to explain this\ncorrelation by showing that ICL approximates a Bayesian learner. This\nperspective gives rise to a family of novel Bayesian scaling laws for ICL. In\nexperiments with \\mbox{GPT-2} models of different sizes, our scaling laws\nexceed or match existing scaling laws in accuracy while also offering\ninterpretable terms for task priors, learning efficiency, and per-example\nprobabilities. To illustrate the analytic power that such interpretable scaling\nlaws provide, we report on controlled synthetic dataset experiments designed to\ninform real-world studies of safety alignment. In our experimental protocol, we\nuse SFT to suppress an unwanted existing model capability and then use ICL to\ntry to bring that capability back (many-shot jailbreaking). We then experiment\non real-world instruction-tuned LLMs using capabilities benchmarks as well as a\nnew many-shot jailbreaking dataset. In all cases, Bayesian scaling laws\naccurately predict the conditions under which ICL will cause the suppressed\nbehavior to reemerge, which sheds light on the ineffectiveness of post-training\nat increasing LLM safety.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.FL",
      "cs.LG",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages main text, 26 pages total",
    "pdf_url": "http://arxiv.org/pdf/2410.16531v3",
    "published_date": "2024-10-21 21:45:22 UTC",
    "updated_date": "2024-11-02 19:06:53 UTC"
  },
  {
    "arxiv_id": "2411.04126v1",
    "title": "We Urgently Need Intrinsically Kind Machines",
    "authors": [
      "Joshua T. S. Hewson"
    ],
    "abstract": "Artificial Intelligence systems are rapidly evolving, integrating extrinsic\nand intrinsic motivations. While these frameworks offer benefits, they risk\nmisalignment at the algorithmic level while appearing superficially aligned\nwith human values. In this paper, we argue that an intrinsic motivation for\nkindness is crucial for making sure these models are intrinsically aligned with\nhuman values. We argue that kindness, defined as a form of altruism motivated\nto maximize the reward of others, can counteract any intrinsic motivations that\nmight lead the model to prioritize itself over human well-being. Our approach\nintroduces a framework and algorithm for embedding kindness into foundation\nmodels by simulating conversations. Limitations and future research directions\nfor scalable implementation are discussed.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "NeurIPS 2024 IMOL Workshop Paper",
    "pdf_url": "http://arxiv.org/pdf/2411.04126v1",
    "published_date": "2024-10-21 21:40:22 UTC",
    "updated_date": "2024-10-21 21:40:22 UTC"
  },
  {
    "arxiv_id": "2410.16529v1",
    "title": "Distributed Online Life-Long Learning (DOL3) for Multi-agent Trust and Reputation Assessment in E-commerce",
    "authors": [
      "Hariprasauth Ramamoorthy",
      "Shubhankar Gupta",
      "Suresh Sundaram"
    ],
    "abstract": "Trust and Reputation Assessment of service providers in citizen-focused\nenvironments like e-commerce is vital to maintain the integrity of the\ninteractions among agents. The goals and objectives of both the service\nprovider and service consumer agents are relevant to the goals of the\nrespective citizens (end users). The provider agents often pursue selfish goals\nthat can make the service quality highly volatile, contributing towards the\nnon-stationary nature of the environment. The number of active service\nproviders tends to change over time resulting in an open environment. This\nnecessitates a rapid and continual assessment of the Trust and Reputation. A\nlarge number of service providers in the environment require a distributed\nmulti-agent Trust and Reputation assessment. This paper addresses the problem\nof multi-agent Trust and Reputation Assessment in a non-stationary environment\ninvolving transactions between providers and consumers. In this setting, the\nobserver agents carry out the assessment and communicate their assessed trust\nscores with each other over a network. We propose a novel Distributed Online\nLife-Long Learning (DOL3) algorithm that involves real-time rapid learning of\ntrust and reputation scores of providers. Each observer carries out an adaptive\nlearning and weighted fusion process combining their own assessment along with\nthat of their neighbour in the communication network. Simulation studies reveal\nthat the state-of-the-art methods, which usually involve training a model to\nassess an agent's trust and reputation, do not work well in such an\nenvironment. The simulation results show that the proposed DOL3 algorithm\noutperforms these methods and effectively handles the volatility in such\nenvironments. From the statistical evaluation, it is evident that DOL3 performs\nbetter compared to other models in 90% of the cases.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.16529v1",
    "published_date": "2024-10-21 21:37:55 UTC",
    "updated_date": "2024-10-21 21:37:55 UTC"
  },
  {
    "arxiv_id": "2410.16520v3",
    "title": "AUTALIC: A Dataset for Anti-AUTistic Ableist Language In Context",
    "authors": [
      "Naba Rizvi",
      "Harper Strickland",
      "Daniel Gitelman",
      "Tristan Cooper",
      "Alexis Morales-Flores",
      "Michael Golden",
      "Aekta Kallepalli",
      "Akshat Alurkar",
      "Haaset Owens",
      "Saleha Ahmedi",
      "Isha Khirwadkar",
      "Imani Munyaka",
      "Nedjma Ousidhoum"
    ],
    "abstract": "As our understanding of autism and ableism continues to increase, so does our\nunderstanding of ableist language towards autistic people. Such language poses\na significant challenge in NLP research due to its subtle and context-dependent\nnature. Yet, detecting anti-autistic ableist language remains underexplored,\nwith existing NLP tools often failing to capture its nuanced expressions. We\npresent AUTALIC, the first benchmark dataset dedicated to the detection of\nanti-autistic ableist language in context, addressing a significant gap in the\nfield. The dataset comprises 2,400 autism-related sentences collected from\nReddit, accompanied by surrounding context, and is annotated by trained experts\nwith backgrounds in neurodiversity. Our comprehensive evaluation reveals that\ncurrent language models, including state-of-the-art LLMs, struggle to reliably\nidentify anti-autistic ableism and align with human judgments, underscoring\ntheir limitations in this domain. We publicly release AUTALIC along with the\nindividual annotations which serve as a valuable resource to researchers\nworking on ableism, neurodiversity, and also studying disagreements in\nannotation tasks. This dataset serves as a crucial step towards developing more\ninclusive and context-aware NLP systems that better reflect diverse\nperspectives.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages, 5 figures, 7 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.16520v3",
    "published_date": "2024-10-21 21:21:29 UTC",
    "updated_date": "2025-04-08 17:08:26 UTC"
  },
  {
    "arxiv_id": "2410.16517v1",
    "title": "RGMDT: Return-Gap-Minimizing Decision Tree Extraction in Non-Euclidean Metric Space",
    "authors": [
      "Jingdi Chen",
      "Hanhan Zhou",
      "Yongsheng Mei",
      "Carlee Joe-Wong",
      "Gina Adam",
      "Nathaniel D. Bastian",
      "Tian Lan"
    ],
    "abstract": "Deep Reinforcement Learning (DRL) algorithms have achieved great success in\nsolving many challenging tasks while their black-box nature hinders\ninterpretability and real-world applicability, making it difficult for human\nexperts to interpret and understand DRL policies. Existing works on\ninterpretable reinforcement learning have shown promise in extracting decision\ntree (DT) based policies from DRL policies with most focus on the single-agent\nsettings while prior attempts to introduce DT policies in multi-agent scenarios\nmainly focus on heuristic designs which do not provide any quantitative\nguarantees on the expected return. In this paper, we establish an upper bound\non the return gap between the oracle expert policy and an optimal decision tree\npolicy. This enables us to recast the DT extraction problem into a novel\nnon-euclidean clustering problem over the local observation and action values\nspace of each agent, with action values as cluster labels and the upper bound\non the return gap as clustering loss. Both the algorithm and the upper bound\nare extended to multi-agent decentralized DT extractions by an\niteratively-grow-DT procedure guided by an action-value function conditioned on\nthe current DTs of other agents. Further, we propose the\nReturn-Gap-Minimization Decision Tree (RGMDT) algorithm, which is a\nsurprisingly simple design and is integrated with reinforcement learning\nthrough the utilization of a novel Regularized Information Maximization loss.\nEvaluations on tasks like D4RL show that RGMDT significantly outperforms\nheuristic DT-based baselines and can achieve nearly optimal returns under given\nDT complexity constraints (e.g., maximum number of DT nodes).",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.16517v1",
    "published_date": "2024-10-21 21:19:49 UTC",
    "updated_date": "2024-10-21 21:19:49 UTC"
  },
  {
    "arxiv_id": "2410.16503v1",
    "title": "Allo-AVA: A Large-Scale Multimodal Conversational AI Dataset for Allocentric Avatar Gesture Animation",
    "authors": [
      "Saif Punjwani",
      "Larry Heck"
    ],
    "abstract": "The scarcity of high-quality, multimodal training data severely hinders the\ncreation of lifelike avatar animations for conversational AI in virtual\nenvironments. Existing datasets often lack the intricate synchronization\nbetween speech, facial expressions, and body movements that characterize\nnatural human communication. To address this critical gap, we introduce\nAllo-AVA, a large-scale dataset specifically designed for text and audio-driven\navatar gesture animation in an allocentric (third person point-of-view)\ncontext. Allo-AVA consists of $\\sim$1,250 hours of diverse video content,\ncomplete with audio, transcripts, and extracted keypoints. Allo-AVA uniquely\nmaps these keypoints to precise timestamps, enabling accurate replication of\nhuman movements (body and facial gestures) in synchronization with speech. This\ncomprehensive resource enables the development and evaluation of more natural,\ncontext-aware avatar animation models, potentially transforming applications\nranging from virtual reality to digital assistants.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.16503v1",
    "published_date": "2024-10-21 20:50:51 UTC",
    "updated_date": "2024-10-21 20:50:51 UTC"
  },
  {
    "arxiv_id": "2410.19847v1",
    "title": "AEPL: Automated and Editable Prompt Learning for Brain Tumor Segmentation",
    "authors": [
      "Yongheng Sun",
      "Mingxia Liu",
      "Chunfeng Lian"
    ],
    "abstract": "Brain tumor segmentation is crucial for accurate diagnosisand treatment\nplanning, but the small size and irregular shapeof tumors pose significant\nchallenges. Existing methods of-ten fail to effectively incorporate medical\ndomain knowledgesuch as tumor grade, which correlates with tumor\naggres-siveness and morphology, providing critical insights for moreaccurate\ndetection of tumor subregions during segmentation.We propose an Automated and\nEditable Prompt Learning(AEPL) framework that integrates tumor grade into the\nseg-mentation process by combining multi-task learning andprompt learning with\nautomatic and editable prompt gen-eration. Specifically, AEPL employs an\nencoder to extractimage features for both tumor-grade prediction and\nsegmen-tation mask generation. The predicted tumor grades serveas\nauto-generated prompts, guiding the decoder to produceprecise segmentation\nmasks. This eliminates the need formanual prompts while allowing clinicians to\nmanually editthe auto-generated prompts to fine-tune the segmentation,enhancing\nboth flexibility and precision. The proposed AEPLachieves state-of-the-art\nperformance on the BraTS 2018dataset, demonstrating its effectiveness and\nclinical potential.The source code can be accessed online.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "4 pages paper for ISBI2025",
    "pdf_url": "http://arxiv.org/pdf/2410.19847v1",
    "published_date": "2024-10-21 20:29:44 UTC",
    "updated_date": "2024-10-21 20:29:44 UTC"
  },
  {
    "arxiv_id": "2410.19008v1",
    "title": "Teach Multimodal LLMs to Comprehend Electrocardiographic Images",
    "authors": [
      "Ruoqi Liu",
      "Yuelin Bai",
      "Xiang Yue",
      "Ping Zhang"
    ],
    "abstract": "The electrocardiogram (ECG) is an essential non-invasive diagnostic tool for\nassessing cardiac conditions. Existing automatic interpretation methods suffer\nfrom limited generalizability, focusing on a narrow range of cardiac\nconditions, and typically depend on raw physiological signals, which may not be\nreadily available in resource-limited settings where only printed or digital\nECG images are accessible. Recent advancements in multimodal large language\nmodels (MLLMs) present promising opportunities for addressing these challenges.\nHowever, the application of MLLMs to ECG image interpretation remains\nchallenging due to the lack of instruction tuning datasets and well-established\nECG image benchmarks for quantitative evaluation. To address these challenges,\nwe introduce ECGInstruct, a comprehensive ECG image instruction tuning dataset\nof over one million samples, covering a wide range of ECG-related tasks from\ndiverse data sources. Using ECGInstruct, we develop PULSE, an MLLM tailored for\nECG image comprehension. In addition, we curate ECGBench, a new evaluation\nbenchmark covering four key ECG image interpretation tasks across nine\ndifferent datasets. Our experiments show that PULSE sets a new\nstate-of-the-art, outperforming general MLLMs with an average accuracy\nimprovement of 15% to 30%. This work highlights the potential of PULSE to\nenhance ECG interpretation in clinical practice.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19008v1",
    "published_date": "2024-10-21 20:26:41 UTC",
    "updated_date": "2024-10-21 20:26:41 UTC"
  },
  {
    "arxiv_id": "2410.18135v1",
    "title": "R2Gen-Mamba: A Selective State Space Model for Radiology Report Generation",
    "authors": [
      "Yongheng Sun",
      "Yueh Z. Lee",
      "Genevieve A. Woodard",
      "Hongtu Zhu",
      "Chunfeng Lian",
      "Mingxia Liu"
    ],
    "abstract": "Radiology report generation is crucial in medical imaging,but the manual\nannotation process by physicians is time-consuming and labor-intensive,\nnecessitating the develop-ment of automatic report generation methods.\nExistingresearch predominantly utilizes Transformers to generateradiology\nreports, which can be computationally intensive,limiting their use in real\napplications. In this work, we presentR2Gen-Mamba, a novel automatic radiology\nreport genera-tion method that leverages the efficient sequence processingof\nthe Mamba with the contextual benefits of Transformerarchitectures. Due to\nlower computational complexity ofMamba, R2Gen-Mamba not only enhances training\nand in-ference efficiency but also produces high-quality reports.Experimental\nresults on two benchmark datasets with morethan 210,000 X-ray image-report\npairs demonstrate the ef-fectiveness of R2Gen-Mamba regarding report quality\nandcomputational efficiency compared with several state-of-the-art methods. The\nsource code can be accessed online.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "4 pages pages for ISBI2025",
    "pdf_url": "http://arxiv.org/pdf/2410.18135v1",
    "published_date": "2024-10-21 19:35:34 UTC",
    "updated_date": "2024-10-21 19:35:34 UTC"
  },
  {
    "arxiv_id": "2410.16458v2",
    "title": "STAR: A Simple Training-free Approach for Recommendations using Large Language Models",
    "authors": [
      "Dong-Ho Lee",
      "Adam Kraft",
      "Long Jin",
      "Nikhil Mehta",
      "Taibai Xu",
      "Lichan Hong",
      "Ed H. Chi",
      "Xinyang Yi"
    ],
    "abstract": "Recent progress in large language models (LLMs) offers promising new\napproaches for recommendation system tasks. While the current state-of-the-art\nmethods rely on fine-tuning LLMs to achieve optimal results, this process is\ncostly and introduces significant engineering complexities. Conversely, methods\nthat directly use LLMs without additional fine-tuning result in a large drop in\nrecommendation quality, often due to the inability to capture collaborative\ninformation. In this paper, we propose a Simple Training-free Approach for\nRecommendation (STAR), a framework that utilizes LLMs and can be applied to\nvarious recommendation tasks without the need for fine-tuning, while\nmaintaining high quality recommendation performance. Our approach involves a\nretrieval stage that uses semantic embeddings from LLMs combined with\ncollaborative user information to retrieve candidate items. We then apply an\nLLM for pairwise ranking to enhance next-item prediction. Experimental results\non the Amazon Review dataset show competitive performance for next item\nprediction, even with our retrieval stage alone. Our full method achieves\nHits@10 performance of +23.8% on Beauty, +37.5% on Toys & Games, and -1.8% on\nSports & Outdoors relative to the best supervised models. This framework offers\nan effective alternative to traditional supervised models, highlighting the\npotential of LLMs in recommendation systems without extensive training or\ncustom architectures.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.16458v2",
    "published_date": "2024-10-21 19:34:40 UTC",
    "updated_date": "2025-02-19 23:34:29 UTC"
  },
  {
    "arxiv_id": "2410.16454v3",
    "title": "Catastrophic Failure of LLM Unlearning via Quantization",
    "authors": [
      "Zhiwei Zhang",
      "Fali Wang",
      "Xiaomin Li",
      "Zongyu Wu",
      "Xianfeng Tang",
      "Hui Liu",
      "Qi He",
      "Wenpeng Yin",
      "Suhang Wang"
    ],
    "abstract": "Large language models (LLMs) have shown remarkable proficiency in generating\ntext, benefiting from extensive training on vast textual corpora. However, LLMs\nmay also acquire unwanted behaviors from the diverse and sensitive nature of\ntheir training data, which can include copyrighted and private content. Machine\nunlearning has been introduced as a viable solution to remove the influence of\nsuch problematic content without the need for costly and time-consuming\nretraining. This process aims to erase specific knowledge from LLMs while\npreserving as much model utility as possible. Despite the effectiveness of\ncurrent unlearning methods, little attention has been given to whether existing\nunlearning methods for LLMs truly achieve forgetting or merely hide the\nknowledge, which current unlearning benchmarks fail to detect. This paper\nreveals that applying quantization to models that have undergone unlearning can\nrestore the \"forgotten\" information. To thoroughly evaluate this phenomenon, we\nconduct comprehensive experiments using various quantization techniques across\nmultiple precision levels. We find that for unlearning methods with utility\nconstraints, the unlearned model retains an average of 21\\% of the intended\nforgotten knowledge in full precision, which significantly increases to 83\\%\nafter 4-bit quantization. ... Our code is available at:\n\\href{https://github.com/zzwjames/FailureLLMUnlearning}{https://github.com/zzwjames/FailureLLMUnlearning}.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.16454v3",
    "published_date": "2024-10-21 19:28:37 UTC",
    "updated_date": "2025-03-21 06:37:37 UTC"
  },
  {
    "arxiv_id": "2410.16431v2",
    "title": "Conjuring Semantic Similarity",
    "authors": [
      "Tian Yu Liu",
      "Stefano Soatto"
    ],
    "abstract": "The semantic similarity between sample expressions measures the distance\nbetween their latent 'meaning'. Such meanings are themselves typically\nrepresented by textual expressions, often insufficient to differentiate\nconcepts at fine granularity. We propose a novel approach whereby the semantic\nsimilarity among textual expressions is based not on other expressions they can\nbe rephrased as, but rather based on the imagery they evoke. While this is not\npossible with humans, generative models allow us to easily visualize and\ncompare generated images, or their distribution, evoked by a textual prompt.\nTherefore, we characterize the semantic similarity between two textual\nexpressions simply as the distance between image distributions they induce, or\n'conjure.' We show that by choosing the Jensen-Shannon divergence between the\nreverse-time diffusion stochastic differential equations (SDEs) induced by each\ntextual expression, this can be directly computed via Monte-Carlo sampling. Our\nmethod contributes a novel perspective on semantic similarity that not only\naligns with human-annotated scores, but also opens up new avenues for the\nevaluation of text-conditioned generative models while offering better\ninterpretability of their learnt representations.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.16431v2",
    "published_date": "2024-10-21 18:51:34 UTC",
    "updated_date": "2025-01-29 14:14:27 UTC"
  },
  {
    "arxiv_id": "2410.16429v2",
    "title": "Pantograph: A Machine-to-Machine Interaction Interface for Advanced Theorem Proving, High Level Reasoning, and Data Extraction in Lean 4",
    "authors": [
      "Leni Aniva",
      "Chuyue Sun",
      "Brando Miranda",
      "Clark Barrett",
      "Sanmi Koyejo"
    ],
    "abstract": "Machine-assisted theorem proving refers to the process of conducting\nstructured reasoning to automatically generate proofs for mathematical\ntheorems. Recently, there has been a surge of interest in using machine\nlearning models in conjunction with proof assistants to perform this task. In\nthis paper, we introduce Pantograph, a tool that provides a versatile interface\nto the Lean 4 proof assistant and enables efficient proof search via powerful\nsearch algorithms such as Monte Carlo Tree Search. In addition, Pantograph\nenables high-level reasoning by enabling a more robust handling of Lean 4's\ninference steps. We provide an overview of Pantograph's architecture and\nfeatures. We also report on an illustrative use case: using machine learning\nmodels and proof sketches to prove Lean 4 theorems. Pantograph's innovative\nfeatures pave the way for more advanced machine learning models to perform\ncomplex proof searches and high-level reasoning, equipping future researchers\nto design more versatile and powerful theorem provers.",
    "categories": [
      "cs.LO",
      "cs.AI",
      "cs.LG",
      "math.LO",
      "F.4.1; I.2.3; I.2.7"
    ],
    "primary_category": "cs.LO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.16429v2",
    "published_date": "2024-10-21 18:49:28 UTC",
    "updated_date": "2025-01-31 08:03:07 UTC"
  },
  {
    "arxiv_id": "2410.16423v1",
    "title": "Position: Challenges and Opportunities for Differential Privacy in the U.S. Federal Government",
    "authors": [
      "Amol Khanna",
      "Adam McCormick",
      "Andre Nguyen",
      "Chris Aguirre",
      "Edward Raff"
    ],
    "abstract": "In this article, we seek to elucidate challenges and opportunities for\ndifferential privacy within the federal government setting, as seen by a team\nof differential privacy researchers, privacy lawyers, and data scientists\nworking closely with the U.S. government. After introducing differential\nprivacy, we highlight three significant challenges which currently restrict the\nuse of differential privacy in the U.S. government. We then provide two\nexamples where differential privacy can enhance the capabilities of government\nagencies. The first example highlights how the quantitative nature of\ndifferential privacy allows policy security officers to release multiple\nversions of analyses with different levels of privacy. The second example,\nwhich we believe is a novel realization, indicates that differential privacy\ncan be used to improve staffing efficiency in classified applications. We hope\nthat this article can serve as a nontechnical resource which can help frame\nfuture action from the differential privacy community, privacy regulators,\nsecurity officers, and lawmakers.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "2nd Workshop on Regulatable ML at NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.16423v1",
    "published_date": "2024-10-21 18:46:05 UTC",
    "updated_date": "2024-10-21 18:46:05 UTC"
  },
  {
    "arxiv_id": "2410.16415v1",
    "title": "On conditional diffusion models for PDE simulations",
    "authors": [
      "Aliaksandra Shysheya",
      "Cristiana Diaconu",
      "Federico Bergamin",
      "Paris Perdikaris",
      "José Miguel Hernández-Lobato",
      "Richard E. Turner",
      "Emile Mathieu"
    ],
    "abstract": "Modelling partial differential equations (PDEs) is of crucial importance in\nscience and engineering, and it includes tasks ranging from forecasting to\ninverse problems, such as data assimilation. However, most previous numerical\nand machine learning approaches that target forecasting cannot be applied\nout-of-the-box for data assimilation. Recently, diffusion models have emerged\nas a powerful tool for conditional generation, being able to flexibly\nincorporate observations without retraining. In this work, we perform a\ncomparative study of score-based diffusion models for forecasting and\nassimilation of sparse observations. In particular, we focus on diffusion\nmodels that are either trained in a conditional manner, or conditioned after\nunconditional training. We address the shortcomings of existing models by\nproposing 1) an autoregressive sampling approach that significantly improves\nperformance in forecasting, 2) a new training strategy for conditional\nscore-based models that achieves stable performance over a range of history\nlengths, and 3) a hybrid model which employs flexible pre-training conditioning\non initial conditions and flexible post-training conditioning to handle data\nassimilation. We empirically show that these modifications are crucial for\nsuccessfully tackling the combination of forecasting and data assimilation, a\ntask commonly encountered in real-world scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.16415v1",
    "published_date": "2024-10-21 18:31:04 UTC",
    "updated_date": "2024-10-21 18:31:04 UTC"
  },
  {
    "arxiv_id": "2410.16410v1",
    "title": "Subword Embedding from Bytes Gains Privacy without Sacrificing Accuracy and Complexity",
    "authors": [
      "Mengjiao Zhang",
      "Jia Xu"
    ],
    "abstract": "While NLP models significantly impact our lives, there are rising concerns\nabout privacy invasion. Although federated learning enhances privacy, attackers\nmay recover private training data by exploiting model parameters and gradients.\nTherefore, protecting against such embedding attacks remains an open challenge.\nTo address this, we propose Subword Embedding from Bytes (SEB) and encode\nsubwords to byte sequences using deep neural networks, making input text\nrecovery harder. Importantly, our method requires a smaller memory with $256$\nbytes of vocabulary while keeping efficiency with the same input length. Thus,\nour solution outperforms conventional approaches by preserving privacy without\nsacrificing efficiency or accuracy. Our experiments show SEB can effectively\nprotect against embedding-based attacks from recovering original sentences in\nfederated learning. Meanwhile, we verify that SEB obtains comparable and even\nbetter results over standard subword embedding methods in machine translation,\nsentiment analysis, and language modeling with even lower time and space\ncomplexity.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.16410v1",
    "published_date": "2024-10-21 18:25:24 UTC",
    "updated_date": "2024-10-21 18:25:24 UTC"
  },
  {
    "arxiv_id": "2410.16407v1",
    "title": "Enhancing Multimodal Affective Analysis with Learned Live Comment Features",
    "authors": [
      "Zhaoyuan Deng",
      "Amith Ananthram",
      "Kathleen McKeown"
    ],
    "abstract": "Live comments, also known as Danmaku, are user-generated messages that are\nsynchronized with video content. These comments overlay directly onto streaming\nvideos, capturing viewer emotions and reactions in real-time. While prior work\nhas leveraged live comments in affective analysis, its use has been limited due\nto the relative rarity of live comments across different video platforms. To\naddress this, we first construct the Live Comment for Affective Analysis\n(LCAffect) dataset which contains live comments for English and Chinese videos\nspanning diverse genres that elicit a wide spectrum of emotions. Then, using\nthis dataset, we use contrastive learning to train a video encoder to produce\nsynthetic live comment features for enhanced multimodal affective content\nanalysis. Through comprehensive experimentation on a wide range of affective\nanalysis tasks (sentiment, emotion recognition, and sarcasm detection) in both\nEnglish and Chinese, we demonstrate that these synthetic live comment features\nsignificantly improve performance over state-of-the-art methods.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.16407v1",
    "published_date": "2024-10-21 18:19:09 UTC",
    "updated_date": "2024-10-21 18:19:09 UTC"
  },
  {
    "arxiv_id": "2410.16406v2",
    "title": "Hotel Booking Cancellation Prediction Using Applied Bayesian Models",
    "authors": [
      "Md Asifuzzaman Jishan",
      "Vikas Singh",
      "Ayan Kumar Ghosh",
      "Md Shahabub Alam",
      "Khan Raqib Mahmud",
      "Bijan Paul"
    ],
    "abstract": "This study applies Bayesian models to predict hotel booking cancellations, a\nkey challenge affecting resource allocation, revenue, and customer satisfaction\nin the hospitality industry. Using a Kaggle dataset with 36,285 observations\nand 17 features, Bayesian Logistic Regression and Beta-Binomial models were\nimplemented. The logistic model, applied to 12 features and 5,000 randomly\nselected observations, outperformed the Beta-Binomial model in predictive\naccuracy. Key predictors included the number of adults, children, stay\nduration, lead time, car parking space, room type, and special requests. Model\nevaluation using Leave-One-Out Cross-Validation (LOO-CV) confirmed strong\nalignment between observed and predicted outcomes, demonstrating the model's\nrobustness. Special requests and parking availability were found to be the\nstrongest predictors of cancellation. This Bayesian approach provides a\nvaluable tool for improving booking management and operational efficiency in\nthe hotel industry.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.16406v2",
    "published_date": "2024-10-21 18:18:30 UTC",
    "updated_date": "2024-10-23 19:13:31 UTC"
  },
  {
    "arxiv_id": "2410.16397v1",
    "title": "Towards a Reliable Offline Personal AI Assistant for Long Duration Spaceflight",
    "authors": [
      "Oliver Bensch",
      "Leonie Bensch",
      "Tommy Nilsson",
      "Florian Saling",
      "Wafa M. Sadri",
      "Carsten Hartmann",
      "Tobias Hecking",
      "J. Nathan Kutz"
    ],
    "abstract": "As humanity prepares for new missions to the Moon and Mars, astronauts will\nneed to operate with greater autonomy, given the communication delays that make\nreal-time support from Earth difficult. For instance, messages between Mars and\nEarth can take up to 24 minutes, making quick responses impossible. This\nlimitation poses a challenge for astronauts who must rely on in-situ tools to\naccess the large volume of data from spacecraft sensors, rovers, and\nsatellites, data that is often fragmented and difficult to use. To bridge this\ngap, systems like the Mars Exploration Telemetry-Driven Information System\n(METIS) are being developed. METIS is an AI assistant designed to handle\nroutine tasks, monitor spacecraft systems, and detect anomalies, all while\nreducing the reliance on mission control. Current Generative Pretrained\nTransformer (GPT) Models, while powerful, struggle in safety-critical\nenvironments. They can generate plausible but incorrect responses, a phenomenon\nknown as \"hallucination,\" which could endanger astronauts. To overcome these\nlimitations, this paper proposes enhancing systems like METIS by integrating\nGPTs, Retrieval-Augmented Generation (RAG), Knowledge Graphs (KGs), and\nAugmented Reality (AR). The idea is to allow astronauts to interact with their\ndata more intuitively, using natural language queries and visualizing real-time\ninformation through AR. KGs will be used to easily access live telemetry and\nmultimodal data, ensuring that astronauts have the right information at the\nright time. By combining AI, KGs, and AR, this new system will empower\nastronauts to work more autonomously, safely, and efficiently during future\nspace missions.",
    "categories": [
      "cs.AI",
      "cs.ET",
      "68T01, 68T20, 68T30, 68T50, 68T05,",
      "I.2; H.5"
    ],
    "primary_category": "cs.AI",
    "comment": "75th International Astronautical Congress (IAC), Milan, Italy, 14-18\n  October 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.16397v1",
    "published_date": "2024-10-21 18:08:42 UTC",
    "updated_date": "2024-10-21 18:08:42 UTC"
  },
  {
    "arxiv_id": "2410.16383v1",
    "title": "Designing Robust Cyber-Defense Agents with Evolving Behavior Trees",
    "authors": [
      "Nicholas Potteiger",
      "Ankita Samaddar",
      "Hunter Bergstrom",
      "Xenofon Koutsoukos"
    ],
    "abstract": "Modern network defense can benefit from the use of autonomous systems,\noffloading tedious and time-consuming work to agents with standard and\nlearning-enabled components. These agents, operating on critical network\ninfrastructure, need to be robust and trustworthy to ensure defense against\nadaptive cyber-attackers and, simultaneously, provide explanations for their\nactions and network activity. However, learning-enabled components typically\nuse models, such as deep neural networks, that are not transparent in their\nhigh-level decision-making leading to assurance challenges. Additionally,\ncyber-defense agents must execute complex long-term defense tasks in a reactive\nmanner that involve coordination of multiple interdependent subtasks. Behavior\ntrees are known to be successful in modelling interpretable, reactive, and\nmodular agent policies with learning-enabled components. In this paper, we\ndevelop an approach to design autonomous cyber defense agents using behavior\ntrees with learning-enabled components, which we refer to as Evolving Behavior\nTrees (EBTs). We learn the structure of an EBT with a novel abstract cyber\nenvironment and optimize learning-enabled components for deployment. The\nlearning-enabled components are optimized for adapting to various cyber-attacks\nand deploying security mechanisms. The learned EBT structure is evaluated in a\nsimulated cyber environment, where it effectively mitigates threats and\nenhances network visibility. For deployment, we develop a software architecture\nfor evaluating EBT-based agents in computer network defense scenarios. Our\nresults demonstrate that the EBT-based agent is robust to adaptive\ncyber-attacks and provides high-level explanations for interpreting its\ndecisions and actions.",
    "categories": [
      "cs.AI",
      "cs.CR",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.16383v1",
    "published_date": "2024-10-21 18:00:38 UTC",
    "updated_date": "2024-10-21 18:00:38 UTC"
  },
  {
    "arxiv_id": "2410.16377v2",
    "title": "A Simple Model of Inference Scaling Laws",
    "authors": [
      "Noam Levi"
    ],
    "abstract": "Neural scaling laws have garnered significant interest due to their ability\nto predict model performance as a function of increasing parameters, data, and\ncompute. In this work, we propose a simple statistical ansatz based on\nmemorization to study scaling laws in the context of inference, specifically\nhow performance improves with multiple inference attempts. We explore the\ncoverage, or pass@k metric, which measures the chance of success over repeated\nattempts and provide a motivation for the observed functional form of the\ninference scaling behavior of the coverage in large language models (LLMs) on\nreasoning tasks. We then define an \"inference loss\", which exhibits a power law\ndecay as the number of trials increases, and connect this result with prompting\ncosts. We further test our construction by conducting experiments on a simple\ngenerative model, and find that our predictions are in agreement with the\nempirical coverage curves in a controlled setting. Our simple framework sets\nthe ground for incorporating inference scaling with other known scaling laws.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.IT",
      "cs.LG",
      "math.IT"
    ],
    "primary_category": "stat.ML",
    "comment": "12 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.16377v2",
    "published_date": "2024-10-21 18:00:06 UTC",
    "updated_date": "2024-12-07 22:50:41 UTC"
  },
  {
    "arxiv_id": "2410.16270v1",
    "title": "Reflection-Bench: probing AI intelligence with reflection",
    "authors": [
      "Lingyu Li",
      "Yixu Wang",
      "Haiquan Zhao",
      "Shuqi Kong",
      "Yan Teng",
      "Chunbo Li",
      "Yingchun Wang"
    ],
    "abstract": "The ability to adapt beliefs or behaviors in response to unexpected outcomes,\nreflection, is fundamental to intelligent systems' interaction with the world.\nFrom a cognitive science perspective, this serves as a core principle of\nintelligence applicable to both human and AI systems. To address the debate on\nthe intelligence of large language models (LLMs), we propose Reflection-Bench,\na comprehensive benchmark comprising 7 tasks spanning core cognitive functions\ncrucial for reflection, including perception, memory, belief updating,\ndecision-making, prediction, counterfactual thinking, and meta-reflection. We\nevaluate the performances of 13 prominent LLMs such as OpenAI o1, GPT-4, Claude\n3.5 Sonnet, etc. The results indicate that current LLMs still lack satisfactory\nreflection ability. We discuss the underlying causes of these results and\nsuggest potential avenues for future research. In conclusion, Reflection-Bench\noffers both evaluation tools and inspiration for developing AI capable of\nreliably interacting with the environment. Our data and code are available at\nhttps://github.com/YabYum/ReflectionBench.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "11 pages, 7 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.16270v1",
    "published_date": "2024-10-21 17:59:50 UTC",
    "updated_date": "2024-10-21 17:59:50 UTC"
  },
  {
    "arxiv_id": "2410.16267v1",
    "title": "xGen-MM-Vid (BLIP-3-Video): You Only Need 32 Tokens to Represent a Video Even in VLMs",
    "authors": [
      "Michael S. Ryoo",
      "Honglu Zhou",
      "Shrikant Kendre",
      "Can Qin",
      "Le Xue",
      "Manli Shu",
      "Silvio Savarese",
      "Ran Xu",
      "Caiming Xiong",
      "Juan Carlos Niebles"
    ],
    "abstract": "We present xGen-MM-Vid (BLIP-3-Video): a multimodal language model for\nvideos, particularly designed to efficiently capture temporal information over\nmultiple frames. BLIP-3-Video takes advantage of the 'temporal encoder' in\naddition to the conventional visual tokenizer, which maps a sequence of tokens\nover multiple frames into a compact set of visual tokens. This enables\nBLIP3-Video to use much fewer visual tokens than its competing models (e.g., 32\nvs. 4608 tokens). We explore different types of temporal encoders, including\nlearnable spatio-temporal pooling as well as sequential models like Token\nTuring Machines. We experimentally confirm that BLIP-3-Video obtains video\nquestion-answering accuracies comparable to much larger state-of-the-art models\n(e.g., 34B), while being much smaller (i.e., 4B) and more efficient by using\nfewer visual tokens. The project website is at\nhttps://www.salesforceairesearch.com/opensource/xGen-MM-Vid/index.html",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.16267v1",
    "published_date": "2024-10-21 17:59:11 UTC",
    "updated_date": "2024-10-21 17:59:11 UTC"
  },
  {
    "arxiv_id": "2410.16266v1",
    "title": "3DGS-Enhancer: Enhancing Unbounded 3D Gaussian Splatting with View-consistent 2D Diffusion Priors",
    "authors": [
      "Xi Liu",
      "Chaoyi Zhou",
      "Siyu Huang"
    ],
    "abstract": "Novel-view synthesis aims to generate novel views of a scene from multiple\ninput images or videos, and recent advancements like 3D Gaussian splatting\n(3DGS) have achieved notable success in producing photorealistic renderings\nwith efficient pipelines. However, generating high-quality novel views under\nchallenging settings, such as sparse input views, remains difficult due to\ninsufficient information in under-sampled areas, often resulting in noticeable\nartifacts. This paper presents 3DGS-Enhancer, a novel pipeline for enhancing\nthe representation quality of 3DGS representations. We leverage 2D video\ndiffusion priors to address the challenging 3D view consistency problem,\nreformulating it as achieving temporal consistency within a video generation\nprocess. 3DGS-Enhancer restores view-consistent latent features of rendered\nnovel views and integrates them with the input views through a spatial-temporal\ndecoder. The enhanced views are then used to fine-tune the initial 3DGS model,\nsignificantly improving its rendering performance. Extensive experiments on\nlarge-scale datasets of unbounded scenes demonstrate that 3DGS-Enhancer yields\nsuperior reconstruction performance and high-fidelity rendering results\ncompared to state-of-the-art methods. The project webpage is\nhttps://xiliu8006.github.io/3DGS-Enhancer-project .",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by NeurIPS 2024 Spotlight",
    "pdf_url": "http://arxiv.org/pdf/2410.16266v1",
    "published_date": "2024-10-21 17:59:09 UTC",
    "updated_date": "2024-10-21 17:59:09 UTC"
  },
  {
    "arxiv_id": "2410.16256v1",
    "title": "CompassJudger-1: All-in-one Judge Model Helps Model Evaluation and Evolution",
    "authors": [
      "Maosong Cao",
      "Alexander Lam",
      "Haodong Duan",
      "Hongwei Liu",
      "Songyang Zhang",
      "Kai Chen"
    ],
    "abstract": "Efficient and accurate evaluation is crucial for the continuous improvement\nof large language models (LLMs). Among various assessment methods, subjective\nevaluation has garnered significant attention due to its superior alignment\nwith real-world usage scenarios and human preferences. However, human-based\nevaluations are costly and lack reproducibility, making precise automated\nevaluators (judgers) vital in this process. In this report, we introduce\n\\textbf{CompassJudger-1}, the first open-source \\textbf{all-in-one} judge LLM.\nCompassJudger-1 is a general-purpose LLM that demonstrates remarkable\nversatility. It is capable of: 1. Performing unitary scoring and two-model\ncomparisons as a reward model; 2. Conducting evaluations according to specified\nformats; 3. Generating critiques; 4. Executing diverse tasks like a general\nLLM. To assess the evaluation capabilities of different judge models under a\nunified setting, we have also established \\textbf{JudgerBench}, a new benchmark\nthat encompasses various subjective evaluation tasks and covers a wide range of\ntopics. CompassJudger-1 offers a comprehensive solution for various evaluation\ntasks while maintaining the flexibility to adapt to diverse requirements. Both\nCompassJudger and JudgerBench are released and available to the research\ncommunity athttps://github.com/open-compass/CompassJudger. We believe that by\nopen-sourcing these tools, we can foster collaboration and accelerate progress\nin LLM evaluation methodologies.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Technical Report, Code and Models:\n  https://github.com/open-compass/CompassJudger",
    "pdf_url": "http://arxiv.org/pdf/2410.16256v1",
    "published_date": "2024-10-21 17:56:51 UTC",
    "updated_date": "2024-10-21 17:56:51 UTC"
  },
  {
    "arxiv_id": "2410.16239v2",
    "title": "MoRE: Multi-Modal Contrastive Pre-training with Transformers on X-Rays, ECGs, and Diagnostic Report",
    "authors": [
      "Samrajya Thapa",
      "Koushik Howlader",
      "Subhankar Bhattacharjee",
      "Wei le"
    ],
    "abstract": "In this paper, we introduce a novel Multi-Modal Contrastive Pre-training\nFramework that synergistically combines X-rays, electrocardiograms (ECGs), and\nradiology/cardiology reports. Our approach leverages transformers to encode\nthese diverse modalities into a unified representation space, aiming to enhance\ndiagnostic accuracy and facilitate comprehensive patient assessments. We\nutilize LoRA-Peft to significantly reduce trainable parameters in the LLM and\nincorporate recent linear attention dropping strategy in the Vision\nTransformer(ViT) for smoother attention. Furthermore, we provide novel\nmultimodal attention explanations and retrieval for our model. To the best of\nour knowledge, we are the first to propose an integrated model that combines\nX-ray, ECG, and Radiology/Cardiology Report with this approach. By utilizing\ncontrastive loss, MoRE effectively aligns modality-specific features into a\ncoherent embedding, which supports various downstream tasks such as zero-shot\nclassification and multimodal retrieval. Employing our proposed methodology, we\nachieve state-of-the-art (SOTA) on the Mimic-IV, CheXpert, Edema Severity, and\nPtbXl downstream datasets, surpassing existing multimodal approaches. Our\nproposed framework shows significant improvements in capturing intricate\ninter-modal relationships and its robustness in medical diagnosis that\nestablishes a framework for future research in multimodal learning in the\nhealthcare sector.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 5 figures, 9 tables. Supplementary detail in Appendix. Code\n  made available in Github for reproducibility",
    "pdf_url": "http://arxiv.org/pdf/2410.16239v2",
    "published_date": "2024-10-21 17:42:41 UTC",
    "updated_date": "2024-10-22 22:22:14 UTC"
  },
  {
    "arxiv_id": "2410.16232v1",
    "title": "Sketch2Code: Evaluating Vision-Language Models for Interactive Web Design Prototyping",
    "authors": [
      "Ryan Li",
      "Yanzhe Zhang",
      "Diyi Yang"
    ],
    "abstract": "Sketches are a natural and accessible medium for UI designers to\nconceptualize early-stage ideas. However, existing research on UI/UX automation\noften requires high-fidelity inputs like Figma designs or detailed screenshots,\nlimiting accessibility and impeding efficient design iteration. To bridge this\ngap, we introduce Sketch2Code, a benchmark that evaluates state-of-the-art\nVision Language Models (VLMs) on automating the conversion of rudimentary\nsketches into webpage prototypes. Beyond end-to-end benchmarking, Sketch2Code\nsupports interactive agent evaluation that mimics real-world design workflows,\nwhere a VLM-based agent iteratively refines its generations by communicating\nwith a simulated user, either passively receiving feedback instructions or\nproactively asking clarification questions. We comprehensively analyze ten\ncommercial and open-source models, showing that Sketch2Code is challenging for\nexisting VLMs; even the most capable models struggle to accurately interpret\nsketches and formulate effective questions that lead to steady improvement.\nNevertheless, a user study with UI/UX experts reveals a significant preference\nfor proactive question-asking over passive feedback reception, highlighting the\nneed to develop more effective paradigms for multi-turn conversational agents.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "preprint, 9 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.16232v1",
    "published_date": "2024-10-21 17:39:49 UTC",
    "updated_date": "2024-10-21 17:39:49 UTC"
  },
  {
    "arxiv_id": "2410.16221v1",
    "title": "On Creating an English-Thai Code-switched Machine Translation in Medical Domain",
    "authors": [
      "Parinthapat Pengpun",
      "Krittamate Tiankanon",
      "Amrest Chinkamol",
      "Jiramet Kinchagawat",
      "Pitchaya Chairuengjitjaras",
      "Pasit Supholkhan",
      "Pubordee Aussavavirojekul",
      "Chiraphat Boonnag",
      "Kanyakorn Veerakanjana",
      "Hirunkul Phimsiri",
      "Boonthicha Sae-jia",
      "Nattawach Sataudom",
      "Piyalitt Ittichaiwong",
      "Peerat Limkonchotiwat"
    ],
    "abstract": "Machine translation (MT) in the medical domain plays a pivotal role in\nenhancing healthcare quality and disseminating medical knowledge. Despite\nadvancements in English-Thai MT technology, common MT approaches often\nunderperform in the medical field due to their inability to precisely translate\nmedical terminologies. Our research prioritizes not merely improving\ntranslation accuracy but also maintaining medical terminology in English within\nthe translated text through code-switched (CS) translation. We developed a\nmethod to produce CS medical translation data, fine-tuned a CS translation\nmodel with this data, and evaluated its performance against strong baselines,\nsuch as Google Neural Machine Translation (NMT) and GPT-3.5/GPT-4. Our model\ndemonstrated competitive performance in automatic metrics and was highly\nfavored in human preference evaluations. Our evaluation result also shows that\nmedical professionals significantly prefer CS translations that maintain\ncritical English terms accurately, even if it slightly compromises fluency. Our\ncode and test set are publicly available\nhttps://github.com/preceptorai-org/NLLB_CS_EM_NLP2024.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.16221v1",
    "published_date": "2024-10-21 17:25:32 UTC",
    "updated_date": "2024-10-21 17:25:32 UTC"
  },
  {
    "arxiv_id": "2410.16215v1",
    "title": "Pre-training Distillation for Large Language Models: A Design Space Exploration",
    "authors": [
      "Hao Peng",
      "Xin Lv",
      "Yushi Bai",
      "Zijun Yao",
      "Jiajie Zhang",
      "Lei Hou",
      "Juanzi Li"
    ],
    "abstract": "Knowledge distillation (KD) aims to transfer knowledge from a large teacher\nmodel to a smaller student model. Previous work applying KD in the field of\nlarge language models (LLMs) typically focused on the post-training phase,\nwhere the student LLM learns directly from instructions and corresponding\nresponses generated by the teacher model. In this paper, we extend KD to the\npre-training phase of LLMs, named pre-training distillation (PD). We first\nconduct a preliminary experiment using GLM-4-9B as the teacher LLM to distill a\n1.9B parameter student LLM, validating the effectiveness of PD. Considering the\nkey impact factors of distillation, we systematically explore the design space\nof pre-training distillation across four aspects: logits processing, loss\nselection, scaling law, and offline or online logits. We conduct extensive\nexperiments to explore the design space of pre-training distillation and find\nbetter configurations and interesting conclusions, such as larger student LLMs\ngenerally benefiting more from pre-training distillation, while a larger\nteacher LLM does not necessarily guarantee better results. We hope our\nexploration of the design space will inform future practices in pre-training\ndistillation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.16215v1",
    "published_date": "2024-10-21 17:16:13 UTC",
    "updated_date": "2024-10-21 17:16:13 UTC"
  },
  {
    "arxiv_id": "2410.16212v2",
    "title": "Comprehensive benchmarking of large language models for RNA secondary structure prediction",
    "authors": [
      "L. I. Zablocki",
      "L. A. Bugnon",
      "M. Gerard",
      "L. Di Persia",
      "G. Stegmayer",
      "D. H. Milone"
    ],
    "abstract": "Inspired by the success of large language models (LLM) for DNA and proteins,\nseveral LLM for RNA have been developed recently. RNA-LLM uses large datasets\nof RNA sequences to learn, in a self-supervised way, how to represent each RNA\nbase with a semantically rich numerical vector. This is done under the\nhypothesis that obtaining high-quality RNA representations can enhance\ndata-costly downstream tasks. Among them, predicting the secondary structure is\na fundamental task for uncovering RNA functional mechanisms. In this work we\npresent a comprehensive experimental analysis of several pre-trained RNA-LLM,\ncomparing them for the RNA secondary structure prediction task in an unified\ndeep learning framework. The RNA-LLM were assessed with increasing\ngeneralization difficulty on benchmark datasets. Results showed that two LLM\nclearly outperform the other models, and revealed significant challenges for\ngeneralization in low-homology scenarios.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "q-bio.BM"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.16212v2",
    "published_date": "2024-10-21 17:12:06 UTC",
    "updated_date": "2025-01-31 21:39:40 UTC"
  },
  {
    "arxiv_id": "2410.16208v4",
    "title": "Compute-Constrained Data Selection",
    "authors": [
      "Junjie Oscar Yin",
      "Alexander M. Rush"
    ],
    "abstract": "Data selection can reduce the amount of training data needed to finetune\nLLMs; however, the efficacy of data selection scales directly with its compute.\nMotivated by the practical challenge of compute-constrained finetuning, we\nconsider the setting in which both the cost of selecting data and training are\nbudgeted for. We first formalize the problem of data selection with a\ncost-aware utility function, and model the data selection problem as trading\noff initial-selection cost for training gain. We run a comprehensive sweep of\nexperiments across multiple tasks, varying compute budget by scaling finetuning\ntokens, model sizes, and data selection compute. Interestingly we find that\nmany powerful data selection methods are almost never compute-optimal, and that\ncheaper data selection alternatives dominate both from a theoretical and\nempirical perspective. For compute-optimal training, we find that perplexity\nand gradient data selection require training-to-selection model size ratios of\n5x and 10x, respectively.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Published as a conference paper at ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.16208v4",
    "published_date": "2024-10-21 17:11:21 UTC",
    "updated_date": "2025-04-07 18:16:42 UTC"
  },
  {
    "arxiv_id": "2410.16198v1",
    "title": "Improve Vision Language Model Chain-of-thought Reasoning",
    "authors": [
      "Ruohong Zhang",
      "Bowen Zhang",
      "Yanghao Li",
      "Haotian Zhang",
      "Zhiqing Sun",
      "Zhe Gan",
      "Yinfei Yang",
      "Ruoming Pang",
      "Yiming Yang"
    ],
    "abstract": "Chain-of-thought (CoT) reasoning in vision language models (VLMs) is crucial\nfor improving interpretability and trustworthiness. However, current training\nrecipes lack robust CoT reasoning data, relying on datasets dominated by short\nannotations with minimal rationales. In this work, we show that training VLM on\nshort answers does not generalize well to reasoning tasks that require more\ndetailed responses. To address this, we propose a two-fold approach. First, we\ndistill rationales from GPT-4o model to enrich the training data and fine-tune\nVLMs, boosting their CoT performance. Second, we apply reinforcement learning\nto further calibrate reasoning quality. Specifically, we construct positive\n(correct) and negative (incorrect) pairs of model-generated reasoning chains,\nby comparing their predictions with annotated short answers. Using this\npairwise data, we apply the Direct Preference Optimization algorithm to refine\nthe model's reasoning abilities. Our experiments demonstrate significant\nimprovements in CoT reasoning on benchmark datasets and better generalization\nto direct answer prediction as well. This work emphasizes the importance of\nincorporating detailed rationales in training and leveraging reinforcement\nlearning to strengthen the reasoning capabilities of VLMs.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "68T07"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages + appendix",
    "pdf_url": "http://arxiv.org/pdf/2410.16198v1",
    "published_date": "2024-10-21 17:00:06 UTC",
    "updated_date": "2024-10-21 17:00:06 UTC"
  },
  {
    "arxiv_id": "2410.16196v1",
    "title": "Information for Conversation Generation: Proposals Utilising Knowledge Graphs",
    "authors": [
      "Alex Clay",
      "Ernesto Jiménez-Ruiz"
    ],
    "abstract": "LLMs are frequently used tools for conversational generation. Without\nadditional information LLMs can generate lower quality responses due to lacking\nrelevant content and hallucinations, as well as the perception of poor\nemotional capability, and an inability to maintain a consistent character.\nKnowledge graphs are commonly used forms of external knowledge and may provide\nsolutions to these challenges. This paper introduces three proposals, utilizing\nknowledge graphs to enhance LLM generation. Firstly, dynamic knowledge graph\nembeddings and recommendation could allow for the integration of new\ninformation and the selection of relevant knowledge for response generation.\nSecondly, storing entities with emotional values as additional features may\nprovide knowledge that is better emotionally aligned with the user input.\nThirdly, integrating character information through narrative bubbles would\nmaintain character consistency, as well as introducing a structure that would\nreadily incorporate new information.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "7 pages with citations, 1 figure, accepted to the ISWC 2024 Special\n  Session",
    "pdf_url": "http://arxiv.org/pdf/2410.16196v1",
    "published_date": "2024-10-21 16:59:25 UTC",
    "updated_date": "2024-10-21 16:59:25 UTC"
  },
  {
    "arxiv_id": "2410.16170v1",
    "title": "Learning How to Vote With Principles: Axiomatic Insights Into the Collective Decisions of Neural Networks",
    "authors": [
      "Levin Hornischer",
      "Zoi Terzopoulou"
    ],
    "abstract": "Can neural networks be applied in voting theory, while satisfying the need\nfor transparency in collective decisions? We propose axiomatic deep voting: a\nframework to build and evaluate neural networks that aggregate preferences,\nusing the well-established axiomatic method of voting theory. Our findings are:\n(1) Neural networks, despite being highly accurate, often fail to align with\nthe core axioms of voting rules, revealing a disconnect between mimicking\noutcomes and reasoning. (2) Training with axiom-specific data does not enhance\nalignment with those axioms. (3) By solely optimizing axiom satisfaction,\nneural networks can synthesize new voting rules that often surpass and\nsubstantially differ from existing ones. This offers insights for both fields:\nFor AI, important concepts like bias and value-alignment are studied in a\nmathematically rigorous way; for voting theory, new areas of the space of\nvoting rules are explored.",
    "categories": [
      "cs.AI",
      "I.2.6; J.4"
    ],
    "primary_category": "cs.AI",
    "comment": "15 pages, 8 figures, 7 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.16170v1",
    "published_date": "2024-10-21 16:35:58 UTC",
    "updated_date": "2024-10-21 16:35:58 UTC"
  },
  {
    "arxiv_id": "2410.16164v1",
    "title": "GenAI Assisting Medical Training",
    "authors": [
      "Stefan Fritsch",
      "Matthias Tschoepe",
      "Vitor Fortes Rey",
      "Lars Krupp",
      "Agnes Gruenerbl",
      "Eloise Monger",
      "Sarah Travenna"
    ],
    "abstract": "Medical procedures such as venipuncture and cannulation are essential for\nnurses and require precise skills. Learning this skill, in turn, is a challenge\nfor educators due to the number of teachers per class and the complexity of the\ntask. The study aims to help students with skill acquisition and alleviate the\neducator's workload by integrating generative AI methods to provide real-time\nfeedback on medical procedures such as venipuncture and cannulation.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "2 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.16164v1",
    "published_date": "2024-10-21 16:31:16 UTC",
    "updated_date": "2024-10-21 16:31:16 UTC"
  },
  {
    "arxiv_id": "2410.16152v2",
    "title": "Warped Diffusion: Solving Video Inverse Problems with Image Diffusion Models",
    "authors": [
      "Giannis Daras",
      "Weili Nie",
      "Karsten Kreis",
      "Alex Dimakis",
      "Morteza Mardani",
      "Nikola Borislavov Kovachki",
      "Arash Vahdat"
    ],
    "abstract": "Using image models naively for solving inverse video problems often suffers\nfrom flickering, texture-sticking, and temporal inconsistency in generated\nvideos. To tackle these problems, in this paper, we view frames as continuous\nfunctions in the 2D space, and videos as a sequence of continuous warping\ntransformations between different frames. This perspective allows us to train\nfunction space diffusion models only on images and utilize them to solve\ntemporally correlated inverse problems. The function space diffusion models\nneed to be equivariant with respect to the underlying spatial transformations.\nTo ensure temporal consistency, we introduce a simple post-hoc test-time\nguidance towards (self)-equivariant solutions. Our method allows us to deploy\nstate-of-the-art latent diffusion models such as Stable Diffusion XL to solve\nvideo inverse problems. We demonstrate the effectiveness of our method for\nvideo inpainting and $8\\times$ video super-resolution, outperforming existing\ntechniques based on noise transformations. We provide generated video results:\nhttps://giannisdaras.github.io/warped_diffusion.github.io/.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted in NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.16152v2",
    "published_date": "2024-10-21 16:19:34 UTC",
    "updated_date": "2024-10-22 03:37:37 UTC"
  },
  {
    "arxiv_id": "2410.16151v1",
    "title": "Small Contributions, Small Networks: Efficient Neural Network Pruning Based on Relative Importance",
    "authors": [
      "Mostafa Hussien",
      "Mahmoud Afifi",
      "Kim Khoa Nguyen",
      "Mohamed Cheriet"
    ],
    "abstract": "Recent advancements have scaled neural networks to unprecedented sizes,\nachieving remarkable performance across a wide range of tasks. However,\ndeploying these large-scale models on resource-constrained devices poses\nsignificant challenges due to substantial storage and computational\nrequirements. Neural network pruning has emerged as an effective technique to\nmitigate these limitations by reducing model size and complexity. In this\npaper, we introduce an intuitive and interpretable pruning method based on\nactivation statistics, rooted in information theory and statistical analysis.\nOur approach leverages the statistical properties of neuron activations to\nidentify and remove weights with minimal contributions to neuron outputs.\nSpecifically, we build a distribution of weight contributions across the\ndataset and utilize its parameters to guide the pruning process. Furthermore,\nwe propose a Pruning-aware Training strategy that incorporates an additional\nregularization term to enhance the effectiveness of our pruning method.\nExtensive experiments on multiple datasets and network architectures\ndemonstrate that our method consistently outperforms several baseline and\nstate-of-the-art pruning techniques.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.16151v1",
    "published_date": "2024-10-21 16:18:31 UTC",
    "updated_date": "2024-10-21 16:18:31 UTC"
  },
  {
    "arxiv_id": "2410.16148v1",
    "title": "PODTILE: Facilitating Podcast Episode Browsing with Auto-generated Chapters",
    "authors": [
      "Azin Ghazimatin",
      "Ekaterina Garmash",
      "Gustavo Penha",
      "Kristen Sheets",
      "Martin Achenbach",
      "Oguz Semerci",
      "Remi Galvez",
      "Marcus Tannenberg",
      "Sahitya Mantravadi",
      "Divya Narayanan",
      "Ofeliya Kalaydzhyan",
      "Douglas Cole",
      "Ben Carterette",
      "Ann Clifton",
      "Paul N. Bennett",
      "Claudia Hauff",
      "Mounia Lalmas"
    ],
    "abstract": "Listeners of long-form talk-audio content, such as podcast episodes, often\nfind it challenging to understand the overall structure and locate relevant\nsections. A practical solution is to divide episodes into\nchapters--semantically coherent segments labeled with titles and timestamps.\nSince most episodes on our platform at Spotify currently lack creator-provided\nchapters, automating the creation of chapters is essential. Scaling the\nchapterization of podcast episodes presents unique challenges. First, episodes\ntend to be less structured than written texts, featuring spontaneous\ndiscussions with nuanced transitions. Second, the transcripts are usually\nlengthy, averaging about 16,000 tokens, which necessitates efficient processing\nthat can preserve context. To address these challenges, we introduce PODTILE, a\nfine-tuned encoder-decoder transformer to segment conversational data. The\nmodel simultaneously generates chapter transitions and titles for the input\ntranscript. To preserve context, each input text is augmented with global\ncontext, including the episode's title, description, and previous chapter\ntitles. In our intrinsic evaluation, PODTILE achieved an 11% improvement in\nROUGE score over the strongest baseline. Additionally, we provide insights into\nthe practical benefits of auto-generated chapters for listeners navigating\nepisode content. Our findings indicate that auto-generated chapters serve as a\nuseful tool for engaging with less popular podcasts. Finally, we present\nempirical evidence that using chapter titles can enhance effectiveness of\nsparse retrieval in search tasks.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "68P20",
      "H.3.3"
    ],
    "primary_category": "cs.IR",
    "comment": "9 pages, 4 figures, CIKM industry track 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.16148v1",
    "published_date": "2024-10-21 16:17:22 UTC",
    "updated_date": "2024-10-21 16:17:22 UTC"
  },
  {
    "arxiv_id": "2410.16136v2",
    "title": "Modeling Dynamic Neural Activity by combining Naturalistic Video Stimuli and Stimulus-independent Latent Factors",
    "authors": [
      "Finn Schmidt",
      "Polina Turishcheva",
      "Suhas Shrinivasan",
      "Fabian H. Sinz"
    ],
    "abstract": "Understanding how visual processing of natural stimuli and internal brain\nstates interact in populations of neurons remains an open question in\nneuroscience. Currently there are no dynamic encoding models that explicitly\nmodel a latent state and the entire neuronal response distribution. We address\nthis gap by proposing a probabilistic model that predicts the joint\ndistribution of the neuronal responses from video stimuli and\nstimulus-independent latent factors. After training and testing our model on\nmouse V1 neuronal responses, we find that it outperforms video-only models in\nterms of log-likelihood and achieves improvements in likelihood and correlation\nwhen conditioned on responses from other neurons. Furthermore, we find that the\nlearned latent factors strongly correlate with mouse behavior and that they\nexhibits patterns related to the neurons position on visual cortex, although\nthe model was trained without behavior and cortical coordinates. Our findings\ndemonstrate that unsupervised learning of latent factors from population\nresponses can reveal biologically meaningful structure that bridges sensory\nprocessing and behavior, without requiring explicit behavioral annotations\nduring training. Code will be available upon publication.",
    "categories": [
      "q-bio.NC",
      "cs.AI"
    ],
    "primary_category": "q-bio.NC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.16136v2",
    "published_date": "2024-10-21 16:01:39 UTC",
    "updated_date": "2025-03-11 18:54:53 UTC"
  },
  {
    "arxiv_id": "2410.16135v2",
    "title": "Beyond 2:4: exploring V:N:M sparsity for efficient transformer inference on GPUs",
    "authors": [
      "Kang Zhao",
      "Tao Yuan",
      "Han Bao",
      "Zhenfeng Su",
      "Chang Gao",
      "Zhaofeng Sun",
      "Zichen Liang",
      "Liping Jing",
      "Jianfei Chen"
    ],
    "abstract": "To date, 2:4 sparsity has stood as the only sparse pattern that can be\naccelerated using sparse tensor cores on GPUs. In practice, 2:4 sparsity often\npossesses low actual speedups ($\\leq 1.3$) and requires fixed sparse ratios,\nmeaning that other ratios, such as 4:8, 8:16, or those exceeding 50% sparsity,\ndo not incur any speedups on GPUs. Recent studies suggest that V:N:M sparsity\nis promising in addressing these limitations of 2:4 sparsity. However,\nregarding accuracy, the effects of V:N:M sparsity on broader Transformer\nmodels, such as vision Transformers and large language models (LLMs), are\nlargely unexamined. Moreover, Some specific issues related to V:N:M sparsity,\nsuch as how to select appropriate V and M values, remain unresolved. In this\nstudy, we thoroughly investigate the application of V:N:M sparsity in vision\nmodels and LLMs across multiple tasks, from pertaining to downstream tasks. We\npropose three key approaches to enhance the applicability and accuracy of\nV:N:M-sparse Transformers, including heuristic V and M selection,\nV:N:M-specific channel permutation, and three-staged LoRA training techniques.\nExperimental results show that, with our methods, the DeiT-small achieves\nlossless accuracy at 64:2:5 sparsity, while the DeiT-base maintains accuracy\neven at 64:2:8 sparsity. In addition, the fine-tuned LLama2-7B at 64:2:5\nsparsity performs comparably or better than training-free 2:4 sparse\nalternatives on downstream tasks. More importantly, V:N:M-sparse Transformers\noffer a wider range of speedup-accuracy trade-offs compared to 2:4 sparsity.\nOverall, our exploration largely facilitates the V:N:M sparsity to act as a\ntruly effective acceleration solution for Transformers in cost-sensitive\ninference scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.16135v2",
    "published_date": "2024-10-21 16:00:04 UTC",
    "updated_date": "2025-02-09 03:48:41 UTC"
  },
  {
    "arxiv_id": "2410.16132v1",
    "title": "A Data-driven Crowd Simulation Framework Integrating Physics-informed Machine Learning with Navigation Potential Fields",
    "authors": [
      "Runkang Guo",
      "Bin Chen",
      "Qi Zhang",
      "Yong Zhao",
      "Xiao Wang",
      "Zhengqiu Zhu"
    ],
    "abstract": "Traditional rule-based physical models are limited by their reliance on\nsingular physical formulas and parameters, making it difficult to effectively\ntackle the intricate tasks associated with crowd simulation. Recent research\nhas introduced deep learning methods to tackle these issues, but most current\napproaches focus primarily on generating pedestrian trajectories, often lacking\ninterpretability and failing to provide real-time dynamic simulations.To\naddress the aforementioned issues, we propose a novel data-driven crowd\nsimulation framework that integrates Physics-informed Machine Learning (PIML)\nwith navigation potential fields. Our approach leverages the strengths of both\nphysical models and PIML. Specifically, we design an innovative\nPhysics-informed Spatio-temporal Graph Convolutional Network (PI-STGCN) as a\ndata-driven module to predict pedestrian movement trends based on crowd\nspatio-temporal data. Additionally, we construct a physical model of navigation\npotential fields based on flow field theory to guide pedestrian movements,\nthereby reinforcing physical constraints during the simulation. In our\nframework, navigation potential fields are dynamically computed and updated\nbased on the movement trends predicted by the PI-STGCN, while the updated crowd\ndynamics, guided by these fields, subsequently feed back into the PI-STGCN.\nComparative experiments on two publicly available large-scale real-world\ndatasets across five scenes demonstrate that our proposed framework outperforms\nexisting rule-based methods in accuracy and fidelity. The similarity between\nsimulated and actual pedestrian trajectories increases by 10.8%, while the\naverage error is reduced by 4%. Moreover, our framework exhibits greater\nadaptability and better interpretability compared to methods that rely solely\non deep learning for trajectory generation.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.16132v1",
    "published_date": "2024-10-21 15:56:17 UTC",
    "updated_date": "2024-10-21 15:56:17 UTC"
  },
  {
    "arxiv_id": "2410.16128v1",
    "title": "SMART: Self-learning Meta-strategy Agent for Reasoning Tasks",
    "authors": [
      "Rongxing Liu",
      "Kumar Shridhar",
      "Manish Prajapat",
      "Patrick Xia",
      "Mrinmaya Sachan"
    ],
    "abstract": "Tasks requiring deductive reasoning, especially those involving multiple\nsteps, often demand adaptive strategies such as intermediate generation of\nrationales or programs, as no single approach is universally optimal. While\nLanguage Models (LMs) can enhance their outputs through iterative\nself-refinement and strategy adjustments, they frequently fail to apply the\nmost effective strategy in their first attempt. This inefficiency raises the\nquestion: Can LMs learn to select the optimal strategy in the first attempt,\nwithout a need for refinement? To address this challenge, we introduce SMART\n(Self-learning Meta-strategy Agent for Reasoning Tasks), a novel framework that\nenables LMs to autonomously learn and select the most effective strategies for\nvarious reasoning tasks. We model the strategy selection process as a Markov\nDecision Process and leverage reinforcement learning-driven continuous\nself-improvement to allow the model to find the suitable strategy to solve a\ngiven task. Unlike traditional self-refinement methods that rely on multiple\ninference passes or external feedback, SMART allows an LM to internalize the\noutcomes of its own reasoning processes and adjust its strategy accordingly,\naiming for correct solutions on the first attempt. Our experiments across\nvarious reasoning datasets and with different model architectures demonstrate\nthat SMART significantly enhances the ability of models to choose optimal\nstrategies without external guidance (+15 points on the GSM8K dataset). By\nachieving higher accuracy with a single inference pass, SMART not only improves\nperformance but also reduces computational costs for refinement-based\nstrategies, paving the way for more efficient and intelligent reasoning in LMs.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.16128v1",
    "published_date": "2024-10-21 15:55:04 UTC",
    "updated_date": "2024-10-21 15:55:04 UTC"
  },
  {
    "arxiv_id": "2410.16119v1",
    "title": "SeaDAG: Semi-autoregressive Diffusion for Conditional Directed Acyclic Graph Generation",
    "authors": [
      "Xinyi Zhou",
      "Xing Li",
      "Yingzhao Lian",
      "Yiwen Wang",
      "Lei Chen",
      "Mingxuan Yuan",
      "Jianye Hao",
      "Guangyong Chen",
      "Pheng Ann Heng"
    ],
    "abstract": "We introduce SeaDAG, a semi-autoregressive diffusion model for conditional\ngeneration of Directed Acyclic Graphs (DAGs). Considering their inherent\nlayer-wise structure, we simulate layer-wise autoregressive generation by\ndesigning different denoising speed for different layers. Unlike conventional\nautoregressive generation that lacks a global graph structure view, our method\nmaintains a complete graph structure at each diffusion step, enabling\noperations such as property control that require the full graph structure.\nLeveraging this capability, we evaluate the DAG properties during training by\nemploying a graph property decoder. We explicitly train the model to learn\ngraph conditioning with a condition loss, which enhances the diffusion model's\ncapacity to generate graphs that are both realistic and aligned with specified\nproperties. We evaluate our method on two representative conditional DAG\ngeneration tasks: (1) circuit generation from truth tables, where precise DAG\nstructures are crucial for realizing circuit functionality, and (2) molecule\ngeneration based on quantum properties. Our approach demonstrates promising\nresults, generating high-quality and realistic DAGs that closely align with\ngiven conditions.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.16119v1",
    "published_date": "2024-10-21 15:47:03 UTC",
    "updated_date": "2024-10-21 15:47:03 UTC"
  },
  {
    "arxiv_id": "2410.16116v1",
    "title": "Multimodal Flare Forecasting with Deep Learning",
    "authors": [
      "Grégoire Francisco",
      "Sabrina Guastavino",
      "Teresa Barata",
      "João Fernandes",
      "Dario Del Moro"
    ],
    "abstract": "Solar flare forecasting mainly relies on photospheric magnetograms and\nassociated physical features to predict forthcoming flares. However, it is\nbelieved that flare initiation mechanisms often originate in the chromosphere\nand the lower corona. In this study, we employ deep learning as a purely\ndata-driven approach to compare the predictive capabilities of chromospheric\nand coronal UV and EUV emissions across different wavelengths with those of\nphotospheric line-of-sight magnetograms. Our findings indicate that individual\nEUV wavelengths can provide discriminatory power comparable or better to that\nof line-of-sight magnetograms. Moreover, we identify simple multimodal neural\nnetwork architectures that consistently outperform single-input models, showing\ncomplementarity between the flare precursors that can be extracted from the\ndistinct layers of the solar atmosphere. To mitigate potential biases from\nknown misattributions in Active Region flare catalogs, our models are trained\nand evaluated using full-disk images and a comprehensive flare event catalog at\nthe full-disk level. We introduce a deep-learning architecture suited for\nextracting temporal features from full-disk videos.",
    "categories": [
      "astro-ph.SR",
      "astro-ph.IM",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "astro-ph.SR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.16116v1",
    "published_date": "2024-10-21 15:42:47 UTC",
    "updated_date": "2024-10-21 15:42:47 UTC"
  },
  {
    "arxiv_id": "2410.16105v1",
    "title": "Addressing Spectral Bias of Deep Neural Networks by Multi-Grade Deep Learning",
    "authors": [
      "Ronglong Fang",
      "Yuesheng Xu"
    ],
    "abstract": "Deep neural networks (DNNs) suffer from the spectral bias, wherein DNNs\ntypically exhibit a tendency to prioritize the learning of lower-frequency\ncomponents of a function, struggling to capture its high-frequency features.\nThis paper is to address this issue. Notice that a function having only low\nfrequency components may be well-represented by a shallow neural network (SNN),\na network having only a few layers. By observing that composition of low\nfrequency functions can effectively approximate a high-frequency function, we\npropose to learn a function containing high-frequency components by composing\nseveral SNNs, each of which learns certain low-frequency information from the\ngiven data. We implement the proposed idea by exploiting the multi-grade deep\nlearning (MGDL) model, a recently introduced model that trains a DNN\nincrementally, grade by grade, a current grade learning from the residue of the\nprevious grade only an SNN composed with the SNNs trained in the preceding\ngrades as features. We apply MGDL to synthetic, manifold, colored images, and\nMNIST datasets, all characterized by presence of high-frequency features. Our\nstudy reveals that MGDL excels at representing functions containing\nhigh-frequency information. Specifically, the neural networks learned in each\ngrade adeptly capture some low-frequency information, allowing their\ncompositions with SNNs learned in the previous grades effectively representing\nthe high-frequency features. Our experimental results underscore the efficacy\nof MGDL in addressing the spectral bias inherent in DNNs. By leveraging MGDL,\nwe offer insights into overcoming spectral bias limitation of DNNs, thereby\nenhancing the performance and applicability of deep learning models in tasks\nrequiring the representation of high-frequency information. This study confirms\nthat the proposed method offers a promising solution to address the spectral\nbias of DNNs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.16105v1",
    "published_date": "2024-10-21 15:34:33 UTC",
    "updated_date": "2024-10-21 15:34:33 UTC"
  },
  {
    "arxiv_id": "2410.19845v1",
    "title": "Enhancing Trust and Safety in Digital Payments: An LLM-Powered Approach",
    "authors": [
      "Devendra Dahiphale",
      "Naveen Madiraju",
      "Justin Lin",
      "Rutvik Karve",
      "Monu Agrawal",
      "Anant Modwal",
      "Ramanan Balakrishnan",
      "Shanay Shah",
      "Govind Kaushal",
      "Priya Mandawat",
      "Prakash Hariramani",
      "Arif Merchant"
    ],
    "abstract": "Digital payment systems have revolutionized financial transactions, offering\nunparalleled convenience and accessibility to users worldwide. However, the\nincreasing popularity of these platforms has also attracted malicious actors\nseeking to exploit their vulnerabilities for financial gain. To address this\nchallenge, robust and adaptable scam detection mechanisms are crucial for\nmaintaining the trust and safety of digital payment ecosystems. This paper\npresents a comprehensive approach to scam detection, focusing on the Unified\nPayments Interface (UPI) in India, Google Pay (GPay) as a specific use case.\nThe approach leverages Large Language Models (LLMs) to enhance scam\nclassification accuracy and designs a digital assistant to aid human reviewers\nin identifying and mitigating fraudulent activities. The results demonstrate\nthe potential of LLMs in augmenting existing machine learning models and\nimproving the efficiency, accuracy, quality, and consistency of scam reviews,\nultimately contributing to a safer and more secure digital payment landscape.\nOur evaluation of the Gemini Ultra model on curated transaction data showed a\n93.33% accuracy in scam classification. Furthermore, the model demonstrated 89%\naccuracy in generating reasoning for these classifications. A promising fact,\nthe model identified 32% new accurate reasons for suspected scams that human\nreviewers had not included in the review notes.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CE",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "10 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.19845v1",
    "published_date": "2024-10-21 15:21:11 UTC",
    "updated_date": "2024-10-21 15:21:11 UTC"
  },
  {
    "arxiv_id": "2410.16091v1",
    "title": "Neural Quantum Propagators for Driven-Dissipative Quantum Dynamics",
    "authors": [
      "Jiaji Zhang",
      "Carlos L. Benavides-Riveros",
      "Lipeng Chen"
    ],
    "abstract": "Describing the dynamics of strong-laser driven open quantum systems is a very\nchallenging task that requires the solution of highly involved equations of\nmotion. While machine learning techniques are being applied with some success\nto simulate the time evolution of individual quantum states, their use to\napproximate time-dependent operators (that can evolve various states) remains\nlargely unexplored. In this work, we develop driven neural quantum propagators\n(NQP), a universal neural network framework that solves driven-dissipative\nquantum dynamics by approximating propagators rather than wavefunctions or\ndensity matrices. NQP can handle arbitrary initial quantum states, adapt to\nvarious external fields, and simulate long-time dynamics, even when trained on\nfar shorter time windows. Furthermore, by appropriately configuring the\nexternal fields, our trained NQP can be transferred to systems governed by\ndifferent Hamiltonians. We demonstrate the effectiveness of our approach by\nstudying the spin-boson and the three-state transition Gamma models.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "physics.chem-ph"
    ],
    "primary_category": "quant-ph",
    "comment": "7 pages, comment are welcome!",
    "pdf_url": "http://arxiv.org/pdf/2410.16091v1",
    "published_date": "2024-10-21 15:13:17 UTC",
    "updated_date": "2024-10-21 15:13:17 UTC"
  },
  {
    "arxiv_id": "2410.16089v1",
    "title": "Multi-Sensor Fusion for UAV Classification Based on Feature Maps of Image and Radar Data",
    "authors": [
      "Nikos Sakellariou",
      "Antonios Lalas",
      "Konstantinos Votis",
      "Dimitrios Tzovaras"
    ],
    "abstract": "The unique cost, flexibility, speed, and efficiency of modern UAVs make them\nan attractive choice in many applications in contemporary society. This,\nhowever, causes an ever-increasing number of reported malicious or accidental\nincidents, rendering the need for the development of UAV detection and\nclassification mechanisms essential. We propose a methodology for developing a\nsystem that fuses already processed multi-sensor data into a new Deep Neural\nNetwork to increase its classification accuracy towards UAV detection. The DNN\nmodel fuses high-level features extracted from individual object detection and\nclassification models associated with thermal, optronic, and radar data.\nAdditionally, emphasis is given to the model's Convolutional Neural Network\n(CNN) based architecture that combines the features of the three sensor\nmodalities by stacking the extracted image features of the thermal and optronic\nsensor achieving higher classification accuracy than each sensor alone.",
    "categories": [
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.16089v1",
    "published_date": "2024-10-21 15:12:37 UTC",
    "updated_date": "2024-10-21 15:12:37 UTC"
  },
  {
    "arxiv_id": "2410.16088v1",
    "title": "Fine-Tuning LLMs for Reliable Medical Question-Answering Services",
    "authors": [
      "Ali Anaissi",
      "Ali Braytee",
      "Junaid Akram"
    ],
    "abstract": "We present an advanced approach to medical question-answering (QA) services,\nusing fine-tuned Large Language Models (LLMs) to improve the accuracy and\nreliability of healthcare information. Our study focuses on optimizing models\nlike LLaMA-2 and Mistral, which have shown great promise in delivering precise,\nreliable medical answers. By leveraging comprehensive datasets, we applied\nfine-tuning techniques such as rsDoRA+ and ReRAG. rsDoRA+ enhances model\nperformance through a combination of decomposed model weights, varied learning\nrates for low-rank matrices, and rank stabilization, leading to improved\nefficiency. ReRAG, which integrates retrieval on demand and question rewriting,\nfurther refines the accuracy of the responses. This approach enables healthcare\nproviders to access fast, dependable information, aiding in more efficient\ndecision-making and fostering greater patient trust. Our work highlights the\npotential of fine-tuned LLMs to significantly improve the quality and\naccessibility of medical information services, ultimately contributing to\nbetter healthcare outcomes for all.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages, 10 figures, accepted and to be published in the proceedings\n  of 2024 IEEE International Conference on Data Mining Workshops (ICDMW)",
    "pdf_url": "http://arxiv.org/pdf/2410.16088v1",
    "published_date": "2024-10-21 15:12:20 UTC",
    "updated_date": "2024-10-21 15:12:20 UTC"
  },
  {
    "arxiv_id": "2410.16083v1",
    "title": "Critical Example Mining for Vehicle Trajectory Prediction using Flow-based Generative Models",
    "authors": [
      "Zhezhang Ding",
      "Huijing Zhao"
    ],
    "abstract": "Precise trajectory prediction in complex driving scenarios is essential for\nautonomous vehicles. In practice, different driving scenarios present varying\nlevels of difficulty for trajectory prediction models. However, most existing\nresearch focuses on the average precision of prediction results, while ignoring\nthe underlying distribution of the input scenarios. This paper proposes a\ncritical example mining method that utilizes a data-driven approach to estimate\nthe rareness of the trajectories. By combining the rareness estimation of\nobservations with whole trajectories, the proposed method effectively\nidentifies a subset of data that is relatively hard to predict BEFORE feeding\nthem to a specific prediction model. The experimental results show that the\nmined subset has higher prediction error when applied to different downstream\nprediction models, which reaches +108.1% error (greater than two times compared\nto the average on dataset) when mining 5% samples. Further analysis indicates\nthat the mined critical examples include uncommon cases such as sudden brake\nand cancelled lane-change, which helps to better understand and improve the\nperformance of prediction models.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages,6 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.16083v1",
    "published_date": "2024-10-21 15:02:30 UTC",
    "updated_date": "2024-10-21 15:02:30 UTC"
  },
  {
    "arxiv_id": "2410.16070v2",
    "title": "On-Device LLMs for SMEs: Challenges and Opportunities",
    "authors": [
      "Jeremy Stephen Gabriel Yee",
      "Pai Chet Ng",
      "Zhengkui Wang",
      "Ian McLoughlin",
      "Aik Beng Ng",
      "Simon See"
    ],
    "abstract": "This paper presents a systematic review of the infrastructure requirements\nfor deploying Large Language Models (LLMs) on-device within the context of\nsmall and medium-sized enterprises (SMEs), focusing on both hardware and\nsoftware perspectives. From the hardware viewpoint, we discuss the utilization\nof processing units like GPUs and TPUs, efficient memory and storage solutions,\nand strategies for effective deployment, addressing the challenges of limited\ncomputational resources typical in SME settings. From the software perspective,\nwe explore framework compatibility, operating system optimization, and the use\nof specialized libraries tailored for resource-constrained environments. The\nreview is structured to first identify the unique challenges faced by SMEs in\ndeploying LLMs on-device, followed by an exploration of the opportunities that\nboth hardware innovations and software adaptations offer to overcome these\nobstacles. Such a structured review provides practical insights, contributing\nsignificantly to the community by enhancing the technological resilience of\nSMEs in integrating LLMs.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "68T07",
      "I.2"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages, 1 figure. The work is supported by the SIT-NVIDIA Joint AI\n  Centre",
    "pdf_url": "http://arxiv.org/pdf/2410.16070v2",
    "published_date": "2024-10-21 14:48:35 UTC",
    "updated_date": "2024-10-22 13:40:18 UTC"
  },
  {
    "arxiv_id": "2410.16063v1",
    "title": "Integrated Image-Text Based on Semi-supervised Learning for Small Sample Instance Segmentation",
    "authors": [
      "Ruting Chi",
      "Zhiyi Huang",
      "Yuexing Han"
    ],
    "abstract": "Small sample instance segmentation is a very challenging task, and many\nexisting methods follow the training strategy of meta-learning which pre-train\nmodels on support set and fine-tune on query set. The pre-training phase, which\nis highly task related, requires a significant amount of additional training\ntime and the selection of datasets with close proximity to ensure\neffectiveness. The article proposes a novel small sample instance segmentation\nsolution from the perspective of maximizing the utilization of existing\ninformation without increasing annotation burden and training costs. The\nproposed method designs two modules to address the problems encountered in\nsmall sample instance segmentation. First, it helps the model fully utilize\nunlabeled data by learning to generate pseudo labels, increasing the number of\navailable samples. Second, by integrating the features of text and image, more\naccurate classification results can be obtained. These two modules are suitable\nfor box-free and box-dependent frameworks. In the way, the proposed method not\nonly improves the performance of small sample instance segmentation, but also\ngreatly reduce reliance on pre-training. We have conducted experiments in three\ndatasets from different scenes: on land, underwater and under microscope. As\nevidenced by our experiments, integrated image-text corrects the confidence of\nclassification, and pseudo labels help the model obtain preciser masks. All the\nresults demonstrate the effectiveness and superiority of our method.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.16063v1",
    "published_date": "2024-10-21 14:44:08 UTC",
    "updated_date": "2024-10-21 14:44:08 UTC"
  },
  {
    "arxiv_id": "2410.16347v1",
    "title": "Domain-Adaptive Neural Posterior Estimation for Strong Gravitational Lens Analysis",
    "authors": [
      "Paxson Swierc",
      "Marcos Tamargo-Arizmendi",
      "Aleksandra Ćiprijanović",
      "Brian D. Nord"
    ],
    "abstract": "Modeling strong gravitational lenses is prohibitively expensive for modern\nand next-generation cosmic survey data. Neural posterior estimation (NPE), a\nsimulation-based inference (SBI) approach, has been studied as an avenue for\nefficient analysis of strong lensing data. However, NPE has not been\ndemonstrated to perform well on out-of-domain target data -- e.g., when trained\non simulated data and then applied to real, observational data. In this work,\nwe perform the first study of the efficacy of NPE in combination with\nunsupervised domain adaptation (UDA). The source domain is noiseless, and the\ntarget domain has noise mimicking modern cosmology surveys. We find that\ncombining UDA and NPE improves the accuracy of the inference by 1-2 orders of\nmagnitude and significantly improves the posterior coverage over an NPE model\nwithout UDA. We anticipate that this combination of approaches will help enable\nfuture applications of NPE models to real observational data.",
    "categories": [
      "astro-ph.IM",
      "astro-ph.CO",
      "astro-ph.GA",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "astro-ph.IM",
    "comment": "20 pages, 2 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.16347v1",
    "published_date": "2024-10-21 14:12:39 UTC",
    "updated_date": "2024-10-21 14:12:39 UTC"
  },
  {
    "arxiv_id": "2410.16032v5",
    "title": "TimeMixer++: A General Time Series Pattern Machine for Universal Predictive Analysis",
    "authors": [
      "Shiyu Wang",
      "Jiawei Li",
      "Xiaoming Shi",
      "Zhou Ye",
      "Baichuan Mo",
      "Wenze Lin",
      "Shengtong Ju",
      "Zhixuan Chu",
      "Ming Jin"
    ],
    "abstract": "Time series analysis plays a critical role in numerous applications,\nsupporting tasks such as forecasting, classification, anomaly detection, and\nimputation. In this work, we present the time series pattern machine (TSPM), a\nmodel designed to excel in a broad range of time series tasks through powerful\nrepresentation and pattern extraction capabilities. Traditional time series\nmodels often struggle to capture universal patterns, limiting their\neffectiveness across diverse tasks. To address this, we define multiple scales\nin the time domain and various resolutions in the frequency domain, employing\nvarious mixing strategies to extract intricate, task-adaptive time series\npatterns. Specifically, we introduce a general-purpose TSPM that processes\nmulti-scale time series using (1) multi-resolution time imaging (MRTI), (2)\ntime image decomposition (TID), (3) multi-scale mixing (MCM), and (4)\nmulti-resolution mixing (MRM) to extract comprehensive temporal patterns. MRTI\ntransforms multi-scale time series into multi-resolution time images, capturing\npatterns across both temporal and frequency domains. TID leverages dual-axis\nattention to extract seasonal and trend patterns, while MCM hierarchically\naggregates these patterns across scales. MRM adaptively integrates all\nrepresentations across resolutions. This method achieves state-of-the-art\nperformance across 8 time series analytical tasks, consistently surpassing both\ngeneral-purpose and task-specific models. Our work marks a promising step\ntoward the next generation of TSPMs, paving the way for further advancements in\ntime series analysis.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by the 13th International Conference on Learning\n  Representations (ICLR 2025)",
    "pdf_url": "http://arxiv.org/pdf/2410.16032v5",
    "published_date": "2024-10-21 14:06:53 UTC",
    "updated_date": "2025-05-19 04:16:13 UTC"
  },
  {
    "arxiv_id": "2410.16024v3",
    "title": "SMAC-R1: The Emergence of Intelligence in Decision-Making Tasks",
    "authors": [
      "Yue Deng",
      "Weiyu Ma",
      "Yuxin Fan",
      "Ruyi Song",
      "Yin Zhang",
      "Haifeng Zhang",
      "Jian Zhao"
    ],
    "abstract": "StarCraft Multi-Agent Challenge (SMAC) has been one of the most commonly used\nexperimental environments in multi-agent reinforcement learning (MARL), where\nthe specific task is to control a set number of allied units to defeat enemy\nforces. Traditional MARL algorithms often require interacting with the\nenvironment for millions of steps to train a parametric model, of which the\nresulting policies are typically non-interpretable with weak transferability.\nIn this paper, we introduce SMAC-R1 which is based on the Qwen2.5-7B-Base LLM\ndistilled from DeepSeek-Coder-v2.5-236B. Similar to online reinforcement\nlearning after behavior cloning in offline learning process, in our pipeline,\nagents leverage the DeepSeek LLM to generate decision tree code by providing\ntask descriptions, and the agents are further self-reflected using feedback\nfrom the rewards provided by the environment. Based on that, we augment the\ngenerated scripts to fine-tune a small LLM, Qwen2.5-7B-Base, to distill the\ndecision-making ability via Supervised Fine-Tuning (SFT) and enhance the script\ngeneration ability by the Group Relative Policy Optimization (GRPO) algorithm.\nWe conduct experiments in the original 23 SMAC tasks and 10 newly-designed\ntasks to demonstrate that our method can produce high-quality, interpretable\ndecision trees with minimal environmental exploration. Moreover, these scripts\nexhibit strong transferability, successfully applying to homogeneous SMAC\nenvironments without modification. We believe this approach offers a new\ndirection for solving decision-making tasks and domain-specific LLM training\npipelines in the future.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.16024v3",
    "published_date": "2024-10-21 13:58:38 UTC",
    "updated_date": "2025-03-06 05:38:52 UTC"
  },
  {
    "arxiv_id": "2410.16012v1",
    "title": "Massimo: Public Queue Monitoring and Management using Mass-Spring Model",
    "authors": [
      "Abhijeet Kumar",
      "Unnati Singh",
      "Rajdeep Chatterjee",
      "Tathagata Bandyopadhyay"
    ],
    "abstract": "An efficient system of a queue control and regulation in public spaces is\nvery important in order to avoid the traffic jams and to improve the customer\nsatisfaction. This article offers a detailed road map based on a merger of\nintelligent systems and creating an efficient systems of queues in public\nplaces. Through the utilization of different technologies i.e. computer vision,\nmachine learning algorithms, deep learning our system provide accurate\ninformation about the place is crowded or not and the necessary efforts to be\ntaken.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "stat.AP"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, 6 figures, 3 algorithms, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.16012v1",
    "published_date": "2024-10-21 13:43:02 UTC",
    "updated_date": "2024-10-21 13:43:02 UTC"
  },
  {
    "arxiv_id": "2410.16011v1",
    "title": "CA*: Addressing Evaluation Pitfalls in Computation-Aware Latency for Simultaneous Speech Translation",
    "authors": [
      "Xi Xu",
      "Wenda Xu",
      "Siqi Ouyang",
      "Lei Li"
    ],
    "abstract": "Simultaneous speech translation (SimulST) systems must balance translation\nquality with response time, making latency measurement crucial for evaluating\ntheir real-world performance. However, there has been a longstanding belief\nthat current metrics yield unrealistically high latency measurements in\nunsegmented streaming settings. In this paper, we investigate this phenomenon,\nrevealing its root cause in a fundamental misconception underlying existing\nlatency evaluation approaches. We demonstrate that this issue affects not only\nstreaming but also segment-level latency evaluation across different metrics.\nFurthermore, we propose a modification to correctly measure computation-aware\nlatency for SimulST systems, addressing the limitations present in existing\nmetrics.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.16011v1",
    "published_date": "2024-10-21 13:42:19 UTC",
    "updated_date": "2024-10-21 13:42:19 UTC"
  },
  {
    "arxiv_id": "2410.16008v1",
    "title": "Resilient Temporal GCN for Smart Grid State Estimation Under Topology Inaccuracies",
    "authors": [
      "Seyed Hamed Haghshenas",
      "Mia Naeini"
    ],
    "abstract": "State Estimation is a crucial task in power systems. Graph Neural Networks\nhave demonstrated significant potential in state estimation for power systems\nby effectively analyzing measurement data and capturing the complex\ninteractions and interrelations among the measurements through the system's\ngraph structure. However, the information about the system's graph structure\nmay be inaccurate due to noise, attack or lack of accurate information about\nthe topology of the system. This paper studies these scenarios under topology\nuncertainties and evaluates the impact of the topology uncertainties on the\nperformance of a Temporal Graph Convolutional Network (TGCN) for state\nestimation in power systems. In order to make the model resilient to topology\nuncertainties, modifications in the TGCN model are proposed to incorporate a\nknowledge graph, generated based on the measurement data. This knowledge graph\nsupports the assumed uncertain system graph. Two variations of the TGCN\narchitecture are introduced to integrate the knowledge graph, and their\nperformances are evaluated and compared to demonstrate improved resilience\nagainst topology uncertainties. The evaluation results indicate that while the\ntwo proposed architecture show different performance, they both improve the\nperformance of the TGCN state estimation under topology uncertainties.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "9 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.16008v1",
    "published_date": "2024-10-21 13:41:27 UTC",
    "updated_date": "2024-10-21 13:41:27 UTC"
  },
  {
    "arxiv_id": "2410.16007v2",
    "title": "Language Model Probabilities are Not Calibrated in Numeric Contexts",
    "authors": [
      "Charles Lovering",
      "Michael Krumdick",
      "Viet Dac Lai",
      "Seth Ebner",
      "Nilesh Kumar",
      "Varshini Reddy",
      "Rik Koncel-Kedziorski",
      "Chris Tanner"
    ],
    "abstract": "Some statements have one well-defined continuation (e.g., \"the Eiffel Tower\nis in [Paris]\"), whereas others have a natural distribution over multiple\noptions (e.g., \"the weighted coin flip was [Heads/Tails].\") We argue that\nlanguage model (LM) outputs should capture these natural distributions. Our\nwork specifically tests whether LM output probabilities are calibrated to\nnumeric information within their textual contexts. For example, if the context\n(the prompt) concerns two equally likely options (e.g., heads or tails for a\nfair coin), the LM output probabilities should also be equal. Likewise, in a\ncontext with nonuniformly likely events (e.g., rolling a pair with two dice) an\nLM should output proportionate probabilities. However, we find that even in\nsimple settings, the best LMs (1) are poorly calibrated and (2) have systematic\nbiases: artifacts like word identity, word order, and word frequency all impact\ncalibration. For example, gpt-4o-mini often picks the first of two options\npresented in the prompt regardless of the options' implied likelihoods, whereas\nLlama-3.1-8B picks the second. Models do not allocate probability mass among\nvalid options in a calibrated manner.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages (main), 39 pages (references and appendix), in submission",
    "pdf_url": "http://arxiv.org/pdf/2410.16007v2",
    "published_date": "2024-10-21 13:41:15 UTC",
    "updated_date": "2025-03-04 19:14:05 UTC"
  },
  {
    "arxiv_id": "2410.15998v1",
    "title": "1024m at SMM4H 2024: Tasks 3, 5 & 6 -- Ensembles of Transformers and Large Language Models for Medical Text Classification",
    "authors": [
      "Ram Mohan Rao Kadiyala",
      "M. V. P. Chandra Sekhara Rao"
    ],
    "abstract": "Social media is a great source of data for users reporting information and\nregarding their health and how various things have had an effect on them. This\npaper presents various approaches using Transformers and Large Language Models\nand their ensembles, their performance along with advantages and drawbacks for\nvarious tasks of SMM4H'24 - Classifying texts on impact of nature and outdoor\nspaces on the author's mental health (Task 3), Binary classification of tweets\nreporting their children's health disorders like Asthma, Autism, ADHD and\nSpeech disorder (task 5), Binary classification of users self-reporting their\nage (task 6).",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "short paper , acl 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.15998v1",
    "published_date": "2024-10-21 13:29:08 UTC",
    "updated_date": "2024-10-21 13:29:08 UTC"
  },
  {
    "arxiv_id": "2410.15990v1",
    "title": "Augmenting Legal Decision Support Systems with LLM-based NLI for Analyzing Social Media Evidence",
    "authors": [
      "Ram Mohan Rao Kadiyala",
      "Siddartha Pullakhandam",
      "Kanwal Mehreen",
      "Subhasya Tippareddy",
      "Ashay Srivastava"
    ],
    "abstract": "This paper presents our system description and error analysis of our entry\nfor NLLP 2024 shared task on Legal Natural Language Inference (L-NLI)\n\\citep{hagag2024legallenssharedtask2024}. The task required classifying these\nrelationships as entailed, contradicted, or neutral, indicating any association\nbetween the review and the complaint. Our system emerged as the winning\nsubmission, significantly outperforming other entries with a substantial margin\nand demonstrating the effectiveness of our approach in legal text analysis. We\nprovide a detailed analysis of the strengths and limitations of each model and\napproach tested, along with a thorough error analysis and suggestions for\nfuture improvements. This paper aims to contribute to the growing field of\nlegal NLP by offering insights into advanced techniques for natural language\ninference in legal contexts, making it accessible to both experts and newcomers\nin the field.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages , accepted to emnlp 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.15990v1",
    "published_date": "2024-10-21 13:20:15 UTC",
    "updated_date": "2024-10-21 13:20:15 UTC"
  },
  {
    "arxiv_id": "2410.15987v1",
    "title": "Analyzing Closed-loop Training Techniques for Realistic Traffic Agent Models in Autonomous Highway Driving Simulations",
    "authors": [
      "Matthias Bitzer",
      "Reinis Cimurs",
      "Benjamin Coors",
      "Johannes Goth",
      "Sebastian Ziesche",
      "Philipp Geiger",
      "Maximilian Naumann"
    ],
    "abstract": "Simulation plays a crucial role in the rapid development and safe deployment\nof autonomous vehicles. Realistic traffic agent models are indispensable for\nbridging the gap between simulation and the real world. Many existing\napproaches for imitating human behavior are based on learning from\ndemonstration. However, these approaches are often constrained by focusing on\nindividual training strategies. Therefore, to foster a broader understanding of\nrealistic traffic agent modeling, in this paper, we provide an extensive\ncomparative analysis of different training principles, with a focus on\nclosed-loop methods for highway driving simulation. We experimentally compare\n(i) open-loop vs. closed-loop multi-agent training, (ii) adversarial vs.\ndeterministic supervised training, (iii) the impact of reinforcement losses,\nand (iv) the impact of training alongside log-replayed agents to identify\nsuitable training techniques for realistic agent modeling. Furthermore, we\nidentify promising combinations of different closed-loop training methods.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "cs.MA",
      "68T07",
      "I.2.6; I.6.5"
    ],
    "primary_category": "cs.RO",
    "comment": "15 pages, 6 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.15987v1",
    "published_date": "2024-10-21 13:16:58 UTC",
    "updated_date": "2024-10-21 13:16:58 UTC"
  },
  {
    "arxiv_id": "2410.16344v1",
    "title": "Quantum Convolutional Neural Network: A Hybrid Quantum-Classical Approach for Iris Dataset Classification",
    "authors": [
      "S. M. Yousuf Iqbal Tomal",
      "Abdullah Al Shafin",
      "Afrida Afaf",
      "Debojit Bhattacharjee"
    ],
    "abstract": "This paper presents a hybrid quantum-classical machine learning model for\nclassification tasks, integrating a 4-qubit quantum circuit with a classical\nneural network. The quantum circuit is designed to encode the features of the\nIris dataset using angle embedding and entangling gates, thereby capturing\ncomplex feature relationships that are difficult for classical models alone.\nThe model, which we term a Quantum Convolutional Neural Network (QCNN), was\ntrained over 20 epochs, achieving a perfect 100% accuracy on the Iris dataset\ntest set on 16 epoch. Our results demonstrate the potential of quantum-enhanced\nmodels in supervised learning tasks, particularly in efficiently encoding and\nprocessing data using quantum resources. We detail the quantum circuit design,\nparameterized gate selection, and the integration of the quantum layer with\nclassical neural network components. This work contributes to the growing body\nof research on hybrid quantum-classical models and their applicability to\nreal-world datasets.",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "primary_category": "quant-ph",
    "comment": "13 pages, 2 figures, 1 table, Quantum Machine Learning",
    "pdf_url": "http://arxiv.org/pdf/2410.16344v1",
    "published_date": "2024-10-21 13:15:12 UTC",
    "updated_date": "2024-10-21 13:15:12 UTC"
  },
  {
    "arxiv_id": "2410.15978v2",
    "title": "PROMPTHEUS: A Human-Centered Pipeline to Streamline SLRs with LLMs",
    "authors": [
      "João Pedro Fernandes Torres",
      "Catherine Mulligan",
      "Joaquim Jorge",
      "Catarina Moreira"
    ],
    "abstract": "The growing volume of academic publications poses significant challenges for\nresearchers conducting timely and accurate Systematic Literature Reviews,\nparticularly in fast-evolving fields like artificial intelligence. This growth\nof academic literature also makes it increasingly difficult for lay people to\naccess scientific knowledge effectively, meaning academic literature is often\nmisrepresented in the popular press and, more broadly, in society. Traditional\nSLR methods are labor-intensive and error-prone, and they struggle to keep up\nwith the rapid pace of new research. To address these issues, we developed\n\\textit{PROMPTHEUS}: an AI-driven pipeline solution that automates the SLR\nprocess using Large Language Models. We aimed to enhance efficiency by reducing\nthe manual workload while maintaining the precision and coherence required for\ncomprehensive literature synthesis. PROMPTHEUS automates key stages of the SLR\nprocess, including systematic search, data extraction, topic modeling using\nBERTopic, and summarization with transformer models. Evaluations conducted\nacross five research domains demonstrate that PROMPTHEUS reduces review time,\nachieves high precision, and provides coherent topic organization, offering a\nscalable and effective solution for conducting literature reviews in an\nincreasingly crowded research landscape. In addition, such tools may reduce the\nincreasing mistrust in science by making summarization more accessible to\nlaypeople.\n  The code for this project can be found on the GitHub repository at\nhttps://github.com/joaopftorres/PROMPTHEUS.git",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15978v2",
    "published_date": "2024-10-21 13:05:33 UTC",
    "updated_date": "2024-10-22 10:56:35 UTC"
  },
  {
    "arxiv_id": "2410.15977v1",
    "title": "Enabling Energy-Efficient Deployment of Large Language Models on Memristor Crossbar: A Synergy of Large and Small",
    "authors": [
      "Zhehui Wang",
      "Tao Luo",
      "Cheng Liu",
      "Weichen Liu",
      "Rick Siow Mong Goh",
      "Weng-Fai Wong"
    ],
    "abstract": "Large language models (LLMs) have garnered substantial attention due to their\npromising applications in diverse domains. Nevertheless, the increasing size of\nLLMs comes with a significant surge in the computational requirements for\ntraining and deployment. Memristor crossbars have emerged as a promising\nsolution, which demonstrated a small footprint and remarkably high energy\nefficiency in computer vision (CV) models. Memristors possess higher density\ncompared to conventional memory technologies, making them highly suitable for\neffectively managing the extreme model size associated with LLMs. However,\ndeploying LLMs on memristor crossbars faces three major challenges. Firstly,\nthe size of LLMs increases rapidly, already surpassing the capabilities of\nstate-of-the-art memristor chips. Secondly, LLMs often incorporate multi-head\nattention blocks, which involve non-weight stationary multiplications that\ntraditional memristor crossbars cannot support. Third, while memristor\ncrossbars excel at performing linear operations, they are not capable of\nexecuting complex nonlinear operations in LLM such as softmax and layer\nnormalization. To address these challenges, we present a novel architecture for\nthe memristor crossbar that enables the deployment of state-of-the-art LLM on a\nsingle chip or package, eliminating the energy and time inefficiencies\nassociated with off-chip communication. Our testing on BERT_Large showed\nnegligible accuracy loss. Compared to traditional memristor crossbars, our\narchitecture achieves enhancements of up to 39X in area overhead and 18X in\nenergy consumption. Compared to modern TPU/GPU systems, our architecture\ndemonstrates at least a 68X reduction in the area-delay product and a\nsignificant 69% energy consumption reduction.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15977v1",
    "published_date": "2024-10-21 13:04:44 UTC",
    "updated_date": "2024-10-21 13:04:44 UTC"
  },
  {
    "arxiv_id": "2410.15974v1",
    "title": "Large Language Models for Cross-lingual Emotion Detection",
    "authors": [
      "Ram Mohan Rao Kadiyala"
    ],
    "abstract": "This paper presents a detailed system description of our entry for the WASSA\n2024 Task 2, focused on cross-lingual emotion detection. We utilized a\ncombination of large language models (LLMs) and their ensembles to effectively\nunderstand and categorize emotions across different languages. Our approach not\nonly outperformed other submissions with a large margin, but also demonstrated\nthe strength of integrating multiple models to enhance performance.\nAdditionally, We conducted a thorough comparison of the benefits and\nlimitations of each model used. An error analysis is included along with\nsuggested areas for future improvement. This paper aims to offer a clear and\ncomprehensive understanding of advanced techniques in emotion detection, making\nit accessible even to those new to the field.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "6 pages , accepted to acl 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.15974v1",
    "published_date": "2024-10-21 13:00:09 UTC",
    "updated_date": "2024-10-21 13:00:09 UTC"
  },
  {
    "arxiv_id": "2410.15973v1",
    "title": "Karush-Kuhn-Tucker Condition-Trained Neural Networks (KKT Nets)",
    "authors": [
      "Shreya Arvind",
      "Rishabh Pomaje",
      "Rajshekhar V Bhat"
    ],
    "abstract": "This paper presents a novel approach to solving convex optimization problems\nby leveraging the fact that, under certain regularity conditions, any set of\nprimal or dual variables satisfying the Karush-Kuhn-Tucker (KKT) conditions is\nnecessary and sufficient for optimality. Similar to Theory-Trained Neural\nNetworks (TTNNs), the parameters of the convex optimization problem are input\nto the neural network, and the expected outputs are the optimal primal and dual\nvariables. A choice for the loss function in this case is a loss, which we\nrefer to as the KKT Loss, that measures how well the network's outputs satisfy\nthe KKT conditions. We demonstrate the effectiveness of this approach using a\nlinear program as an example. For this problem, we observe that minimizing the\nKKT Loss alone outperforms training the network with a weighted sum of the KKT\nLoss and a Data Loss (the mean-squared error between the ground truth optimal\nsolutions and the network's output). Moreover, minimizing only the Data Loss\nyields inferior results compared to those obtained by minimizing the KKT Loss.\nWhile the approach is promising, the obtained primal and dual solutions are not\nsufficiently close to the ground truth optimal solutions. In the future, we aim\nto develop improved models to obtain solutions closer to the ground truth and\nextend the approach to other problem classes.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15973v1",
    "published_date": "2024-10-21 12:59:58 UTC",
    "updated_date": "2024-10-21 12:59:58 UTC"
  },
  {
    "arxiv_id": "2410.15966v1",
    "title": "Self-Explained Keywords Empower Large Language Models for Code Generation",
    "authors": [
      "Lishui Fan",
      "Mouxiang Chen",
      "Zhongxin Liu"
    ],
    "abstract": "Large language models (LLMs) have achieved impressive performance in code\ngeneration. However, due to the long-tail distribution of LLMs' training data,\nlow-frequency terms are typically underrepresented in the training process.\nConsequently, LLMs often misunderstand or overlook problem-specific,\nlow-frequency keywords during code generation, compromising the accuracy of the\ngenerated code. To address this, we propose a novel technique named\nSEK(\\textbf{S}elf-\\textbf{E}xplained \\textbf{K}eywords), which empowers an LLM\nfor better code generation by extracting and explaining the key terms in the\nproblem description with the LLM itself and ranking them based on frequency.\nComprehensive experiments across three benchmarks, i.e., HumanEval(+), MBPP(+),\nand APPS, with five representative LLMs, show that SEK can significantly\nimprove LLMs in code generation, yielding substantial and consistent gains. For\ninstance, SEK improves the Pass@1 of DeepSeek-Coder-V2-Instruct from 85.4\\% to\n93.3\\% on the Humaneval benchmark. Further analysis confirms that SEK enables\nthe LLMs to shift their attention from low-frequency keywords to their\ncorresponding high-frequency counterparts.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15966v1",
    "published_date": "2024-10-21 12:52:03 UTC",
    "updated_date": "2024-10-21 12:52:03 UTC"
  },
  {
    "arxiv_id": "2410.15962v1",
    "title": "Systematic Exploration of Dialogue Summarization Approaches for Reproducibility, Comparative Assessment, and Methodological Innovations for Advancing Natural Language Processing in Abstractive Summarization",
    "authors": [
      "Yugandhar Reddy Gogireddy",
      "Jithendra Reddy Gogireddy"
    ],
    "abstract": "Reproducibility in scientific research, particularly within the realm of\nnatural language processing (NLP), is essential for validating and verifying\nthe robustness of experimental findings. This paper delves into the\nreproduction and evaluation of dialogue summarization models, focusing\nspecifically on the discrepancies observed between original studies and our\nreproduction efforts. Dialogue summarization is a critical aspect of NLP,\naiming to condense conversational content into concise and informative\nsummaries, thus aiding in efficient information retrieval and decision-making\nprocesses. Our research involved a thorough examination of several dialogue\nsummarization models using the AMI (Augmented Multi-party Interaction) dataset.\nThe models assessed include Hierarchical Memory Networks (HMNet) and various\nversions of Pointer-Generator Networks (PGN), namely PGN(DKE), PGN(DRD),\nPGN(DTS), and PGN(DALL). The primary objective was to evaluate the\ninformativeness and quality of the summaries generated by these models through\nhuman assessment, a method that introduces subjectivity and variability in the\nevaluation process. The analysis began with Dataset 1, where the sample\nstandard deviation of 0.656 indicated a moderate dispersion of data points\naround the mean.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15962v1",
    "published_date": "2024-10-21 12:47:57 UTC",
    "updated_date": "2024-10-21 12:47:57 UTC"
  },
  {
    "arxiv_id": "2410.15960v1",
    "title": "AI-Driven Innovations in Modern Cloud Computing",
    "authors": [
      "Animesh Kumar"
    ],
    "abstract": "The world has witnessed rapid technological transformation, past couple of\ndecades and with Advent of Cloud computing the landscape evolved exponentially\nleading to efficient and scalable application development. Now, the past couple\nof years the digital ecosystem has brought in numerous innovations with\nintegration of Artificial Intelligence commonly known as AI. This paper\nexplores how AI and cloud computing intersect to deliver transformative\ncapabilities for modernizing applications by providing services and\ninfrastructure. Harnessing the combined potential of both AI & Cloud\ntechnologies, technology providers can now exploit intelligent resource\nmanagement, predictive analytics, automated deployment & scaling with enhanced\nsecurity leading to offering innovative solutions to their customers.\nFurthermore, by leveraging such technologies of cloud & AI businesses can reap\nrich rewards in the form of reducing operational costs and improving service\ndelivery. This paper further addresses challenges associated such as data\nprivacy concerns and how it can be mitigated with robust AI governance\nframeworks.",
    "categories": [
      "cs.AI",
      "68Txx - Artificial Intelligence",
      "I.2.7"
    ],
    "primary_category": "cs.AI",
    "comment": "5 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.15960v1",
    "published_date": "2024-10-21 12:45:10 UTC",
    "updated_date": "2024-10-21 12:45:10 UTC"
  },
  {
    "arxiv_id": "2410.15956v2",
    "title": "Do Large Language Models Have an English Accent? Evaluating and Improving the Naturalness of Multilingual LLMs",
    "authors": [
      "Yanzhu Guo",
      "Simone Conia",
      "Zelin Zhou",
      "Min Li",
      "Saloni Potdar",
      "Henry Xiao"
    ],
    "abstract": "Current Large Language Models (LLMs) are predominantly designed with English\nas the primary language, and even the few that are multilingual tend to exhibit\nstrong English-centric biases. Much like speakers who might produce awkward\nexpressions when learning a second language, LLMs often generate unnatural\noutputs in non-English languages, reflecting English-centric patterns in both\nvocabulary and grammar. Despite the importance of this issue, the naturalness\nof multilingual LLM outputs has received limited attention. In this paper, we\naddress this gap by introducing novel automatic corpus-level metrics to assess\nthe lexical and syntactic naturalness of LLM outputs in a multilingual context.\nUsing our new metrics, we evaluate state-of-the-art LLMs on a curated benchmark\nin French and Chinese, revealing a tendency towards English-influenced\npatterns. To mitigate this issue, we also propose a simple and effective\nalignment method to improve the naturalness of an LLM in a target language and\ndomain, achieving consistent improvements in naturalness without compromising\nthe performance on general-purpose benchmarks. Our work highlights the\nimportance of developing multilingual metrics, resources and methods for the\nnew wave of multilingual LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15956v2",
    "published_date": "2024-10-21 12:34:17 UTC",
    "updated_date": "2024-10-23 13:00:27 UTC"
  },
  {
    "arxiv_id": "2410.15954v3",
    "title": "TS-ACL: Closed-Form Solution for Time Series-oriented Continual Learning",
    "authors": [
      "Jiaxu Li",
      "Kejia Fan",
      "Songning Lai",
      "Linpu Lv",
      "Jinfeng Xu",
      "Jianheng Tang",
      "Anfeng Liu",
      "Houbing Herbert Song",
      "Yutao Yue",
      "Yunhuai Liu",
      "Huiping Zhuang"
    ],
    "abstract": "Time series classification underpins critical applications such as healthcare\ndiagnostics and gesture-driven interactive systems in multimedia scenarios.\nHowever, time series class-incremental learning (TSCIL) faces two major\nchallenges: catastrophic forgetting and intra-class variations. Catastrophic\nforgetting occurs because gradient-based parameter update strategies inevitably\nerase past knowledge. And unlike images, time series data exhibits\nsubject-specific patterns, also known as intra-class variations, which refer to\ndifferences in patterns observed within the same class. While exemplar-based\nmethods fail to cover diverse variation with limited samples, existing\nexemplar-free methods lack explicit mechanisms to handle intra-class\nvariations. To address these two challenges, we propose TS-ACL, which leverages\na gradient-free closed-form solution to avoid the catastrophic forgetting\nproblem inherent in gradient-based optimization methods while simultaneously\nlearning global distributions to resolve intra-class variations. Additionally,\nit provides privacy protection and efficiency. Extensive experiments on five\nbenchmark datasets covering various sensor modalities and tasks demonstrate\nthat TS-ACL achieves performance close to joint training on four datasets,\noutperforming existing methods and establishing a new state-of-the-art (SOTA)\nfor TSCIL.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.6"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, 5 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.15954v3",
    "published_date": "2024-10-21 12:34:02 UTC",
    "updated_date": "2025-04-16 12:39:13 UTC"
  },
  {
    "arxiv_id": "2410.15952v1",
    "title": "User-centric evaluation of explainability of AI with and for humans: a comprehensive empirical study",
    "authors": [
      "Szymon Bobek",
      "Paloma Korycińska",
      "Monika Krakowska",
      "Maciej Mozolewski",
      "Dorota Rak",
      "Magdalena Zych",
      "Magdalena Wójcik",
      "Grzegorz J. Nalepa"
    ],
    "abstract": "This study is located in the Human-Centered Artificial Intelligence (HCAI)\nand focuses on the results of a user-centered assessment of commonly used\neXplainable Artificial Intelligence (XAI) algorithms, specifically\ninvestigating how humans understand and interact with the explanations provided\nby these algorithms. To achieve this, we employed a multi-disciplinary approach\nthat included state-of-the-art research methods from social sciences to measure\nthe comprehensibility of explanations generated by a state-of-the-art lachine\nlearning model, specifically the Gradient Boosting Classifier (XGBClassifier).\nWe conducted an extensive empirical user study involving interviews with 39\nparticipants from three different groups, each with varying expertise in data\nscience, data visualization, and domain-specific knowledge related to the\ndataset used for training the machine learning model. Participants were asked a\nseries of questions to assess their understanding of the model's explanations.\nTo ensure replicability, we built the model using a publicly available dataset\nfrom the UC Irvine Machine Learning Repository, focusing on edible and\nnon-edible mushrooms. Our findings reveal limitations in existing XAI methods\nand confirm the need for new design principles and evaluation techniques that\naddress the specific information needs and user perspectives of different\nclasses of AI stakeholders. We believe that the results of our research and the\ncross-disciplinary methodology we developed can be successfully adapted to\nvarious data types and user profiles, thus promoting dialogue and address\nopportunities in HCAI research. To support this, we are making the data\nresulting from our study publicly available.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15952v1",
    "published_date": "2024-10-21 12:32:39 UTC",
    "updated_date": "2024-10-21 12:32:39 UTC"
  },
  {
    "arxiv_id": "2410.15951v1",
    "title": "Redefining Finance: The Influence of Artificial Intelligence (AI) and Machine Learning (ML)",
    "authors": [
      "Animesh Kumar"
    ],
    "abstract": "With rapid transformation of technologies, the fusion of Artificial\nIntelligence (AI) and Machine Learning (ML) in finance is disrupting the entire\necosystem and operations which were followed for decades. The current landscape\nis where decisions are increasingly data-driven by financial institutions with\nan appetite for automation while mitigating risks. The segments of financial\ninstitutions which are getting heavily influenced are retail banking, wealth\nmanagement, corporate banking & payment ecosystem. The solution ranges from\nonboarding the customers all the way fraud detection & prevention to enhancing\nthe customer services. Financial Institutes are leap frogging with integration\nof Artificial Intelligence and Machine Learning in mainstream applications and\nenhancing operational efficiency through advanced predictive analytics,\nextending personalized customer experiences, and automation to minimize risk\nwith fraud detection techniques. However, with Adoption of AI & ML, it is\nimperative that the financial institute also needs to address ethical and\nregulatory challenges, by putting in place robust governance frameworks and\nresponsible AI practices.",
    "categories": [
      "cs.AI",
      "68Txx - Artificial Intelligence",
      "I.2.7"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2410.15951v1",
    "published_date": "2024-10-21 12:32:17 UTC",
    "updated_date": "2024-10-21 12:32:17 UTC"
  },
  {
    "arxiv_id": "2410.15947v2",
    "title": "AI-Driven Approaches for Glaucoma Detection -- A Comprehensive Review",
    "authors": [
      "Yuki Hagiwara",
      "Octavia-Andreea Ciora",
      "Maureen Monnet",
      "Gino Lancho",
      "Jeanette Miriam Lorenz"
    ],
    "abstract": "The diagnosis of glaucoma plays a critical role in the management and\ntreatment of this vision-threatening disease. Glaucoma is a group of eye\ndiseases that cause blindness by damaging the optic nerve at the back of the\neye. Often called \"silent thief of sight\", it exhibits no symptoms during the\nearly stages. Therefore, early detection is crucial to prevent vision loss.\nWith the rise of Artificial Intelligence (AI), particularly Deep Learning (DL)\ntechniques, Computer-Aided Diagnosis (CADx) systems have emerged as promising\ntools to assist clinicians in accurately diagnosing glaucoma early. This paper\naims to provide a comprehensive overview of AI techniques utilized in CADx\nsystems for glaucoma diagnosis. Through a detailed analysis of current\nliterature, we identify key gaps and challenges in these systems, emphasizing\nthe need for improved safety, reliability, interpretability, and\nexplainability. By identifying research gaps, we aim to advance the field of\nCADx systems especially for the early diagnosis of glaucoma, in order to\nprevent any potential loss of vision.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15947v2",
    "published_date": "2024-10-21 12:26:53 UTC",
    "updated_date": "2024-10-22 17:58:06 UTC"
  },
  {
    "arxiv_id": "2410.15944v1",
    "title": "Developing Retrieval Augmented Generation (RAG) based LLM Systems from PDFs: An Experience Report",
    "authors": [
      "Ayman Asad Khan",
      "Md Toufique Hasan",
      "Kai Kristian Kemell",
      "Jussi Rasku",
      "Pekka Abrahamsson"
    ],
    "abstract": "This paper presents an experience report on the development of Retrieval\nAugmented Generation (RAG) systems using PDF documents as the primary data\nsource. The RAG architecture combines generative capabilities of Large Language\nModels (LLMs) with the precision of information retrieval. This approach has\nthe potential to redefine how we interact with and augment both structured and\nunstructured knowledge in generative models to enhance transparency, accuracy,\nand contextuality of responses. The paper details the end-to-end pipeline, from\ndata collection, preprocessing, to retrieval indexing and response generation,\nhighlighting technical challenges and practical solutions. We aim to offer\ninsights to researchers and practitioners developing similar systems using two\ndistinct approaches: OpenAI's Assistant API with GPT Series and Llama's\nopen-source models. The practical implications of this research lie in\nenhancing the reliability of generative AI systems in various sectors where\ndomain-specific knowledge and real-time information retrieval is important. The\nPython code used in this work is also available at:\nhttps://github.com/GPT-Laboratory/RAG-LLM-Development-Guidebook-from-PDFs.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.SE",
    "comment": "36 pages, 8 figures, 2 tables, and python code snippets",
    "pdf_url": "http://arxiv.org/pdf/2410.15944v1",
    "published_date": "2024-10-21 12:21:49 UTC",
    "updated_date": "2024-10-21 12:21:49 UTC"
  },
  {
    "arxiv_id": "2410.15930v1",
    "title": "Centrality-aware Product Retrieval and Ranking",
    "authors": [
      "Hadeel Saadany",
      "Swapnil Bhosale",
      "Samarth Agrawal",
      "Diptesh Kanojia",
      "Constantin Orasan",
      "Zhe Wu"
    ],
    "abstract": "This paper addresses the challenge of improving user experience on e-commerce\nplatforms by enhancing product ranking relevant to users' search queries.\nAmbiguity and complexity of user queries often lead to a mismatch between the\nuser's intent and retrieved product titles or documents. Recent approaches have\nproposed the use of Transformer-based models, which need millions of annotated\nquery-title pairs during the pre-training stage, and this data often does not\ntake user intent into account. To tackle this, we curate samples from existing\ndatasets at eBay, manually annotated with buyer-centric relevance scores and\ncentrality scores, which reflect how well the product title matches the users'\nintent. We introduce a User-intent Centrality Optimization (UCO) approach for\nexisting models, which optimises for the user intent in semantic product\nsearch. To that end, we propose a dual-loss based optimisation to handle hard\nnegatives, i.e., product titles that are semantically relevant but do not\nreflect the user's intent. Our contributions include curating challenging\nevaluation sets and implementing UCO, resulting in significant product ranking\nefficiency improvements observed for different evaluation metrics. Our work\naims to ensure that the most buyer-centric titles for a query are ranked\nhigher, thereby, enhancing the user experience on e-commerce platforms.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "EMNLP 2024: Industry track",
    "pdf_url": "http://arxiv.org/pdf/2410.15930v1",
    "published_date": "2024-10-21 11:59:14 UTC",
    "updated_date": "2024-10-21 11:59:14 UTC"
  },
  {
    "arxiv_id": "2410.15927v1",
    "title": "GReFEL: Geometry-Aware Reliable Facial Expression Learning under Bias and Imbalanced Data Distribution",
    "authors": [
      "Azmine Toushik Wasi",
      "Taki Hasan Rafi",
      "Raima Islam",
      "Karlo Serbetar",
      "Dong Kyu Chae"
    ],
    "abstract": "Reliable facial expression learning (FEL) involves the effective learning of\ndistinctive facial expression characteristics for more reliable, unbiased and\naccurate predictions in real-life settings. However, current systems struggle\nwith FEL tasks because of the variance in people's facial expressions due to\ntheir unique facial structures, movements, tones, and demographics. Biased and\nimbalanced datasets compound this challenge, leading to wrong and biased\nprediction labels. To tackle these, we introduce GReFEL, leveraging Vision\nTransformers and a facial geometry-aware anchor-based reliability balancing\nmodule to combat imbalanced data distributions, bias, and uncertainty in facial\nexpression learning. Integrating local and global data with anchors that learn\ndifferent facial data points and structural features, our approach adjusts\nbiased and mislabeled emotions caused by intra-class disparity, inter-class\nsimilarity, and scale sensitivity, resulting in comprehensive, accurate, and\nreliable facial expression predictions. Our model outperforms current\nstate-of-the-art methodologies, as demonstrated by extensive experiments on\nvarious datasets.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "ACCV 2024. Extended version of ARBEx (arXiv:2305.01486)",
    "pdf_url": "http://arxiv.org/pdf/2410.15927v1",
    "published_date": "2024-10-21 11:55:06 UTC",
    "updated_date": "2024-10-21 11:55:06 UTC"
  },
  {
    "arxiv_id": "2410.21301v2",
    "title": "Evaluating the Posterior Sampling Ability of Plug&Play Diffusion Methods in Sparse-View CT",
    "authors": [
      "Liam Moroy",
      "Guillaume Bourmaud",
      "Frédéric Champagnat",
      "Jean-François Giovannelli"
    ],
    "abstract": "Plug&Play (PnP) diffusion models are state-of-the-art methods in computed\ntomography (CT) reconstruction. Such methods usually consider applications\nwhere the sinogram contains a sufficient amount of information for the\nposterior distribution to be concentrated around a single mode, and\nconsequently are evaluated using image-to-image metrics such as PSNR/SSIM.\nInstead, we are interested in reconstructing compressible flow images from\nsinograms having a small number of projections, which results in a posterior\ndistribution no longer concentrated or even multimodal. Thus, in this paper, we\naim at evaluating the approximate posterior of PnP diffusion models and\nintroduce two posterior evaluation properties. We quantitatively evaluate three\nPnP diffusion methods on three different datasets for several numbers of\nprojections. We surprisingly find that, for each method, the approximate\nposterior deviates from the true posterior when the number of projections\ndecreases.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21301v2",
    "published_date": "2024-10-21 11:39:03 UTC",
    "updated_date": "2025-03-18 09:00:53 UTC"
  },
  {
    "arxiv_id": "2411.02419v1",
    "title": "XAI-FUNGI: Dataset resulting from the user study on comprehensibility of explainable AI algorithms",
    "authors": [
      "Szymon Bobek",
      "Paloma Korycińska",
      "Monika Krakowska",
      "Maciej Mozolewski",
      "Dorota Rak",
      "Magdalena Zych",
      "Magdalena Wójcik",
      "Grzegorz J. Nalepa"
    ],
    "abstract": "This paper introduces a dataset that is the result of a user study on the\ncomprehensibility of explainable artificial intelligence (XAI) algorithms. The\nstudy participants were recruited from 149 candidates to form three groups\nrepresenting experts in the domain of mycology (DE), students with a data\nscience and visualization background (IT) and students from social sciences and\nhumanities (SSH). The main part of the dataset contains 39 transcripts of\ninterviews during which participants were asked to complete a series of tasks\nand questions related to the interpretation of explanations of decisions of a\nmachine learning model trained to distinguish between edible and inedible\nmushrooms. The transcripts were complemented with additional data that includes\nvisualizations of explanations presented to the user, results from thematic\nanalysis, recommendations of improvements of explanations provided by the\nparticipants, and the initial survey results that allow to determine the domain\nknowledge of the participant and data analysis literacy. The transcripts were\nmanually tagged to allow for automatic matching between the text and other data\nrelated to particular fragments. In the advent of the area of rapid development\nof XAI techniques, the need for a multidisciplinary qualitative evaluation of\nexplainability is one of the emerging topics in the community. Our dataset\nallows not only to reproduce the study we conducted, but also to open a wide\nrange of possibilities for the analysis of the material we gathered.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.02419v1",
    "published_date": "2024-10-21 11:37:58 UTC",
    "updated_date": "2024-10-21 11:37:58 UTC"
  },
  {
    "arxiv_id": "2410.15912v3",
    "title": "Bench4Merge: A Comprehensive Benchmark for Merging in Realistic Dense Traffic with Micro-Interactive Vehicles",
    "authors": [
      "Zhengming Wang",
      "Junli Wang",
      "Pengfei Li",
      "Zhaohan Li",
      "Chunyang Liu",
      "Bo Zhang",
      "Peng Li",
      "Yilun Chen"
    ],
    "abstract": "While the capabilities of autonomous driving have advanced rapidly, merging\ninto dense traffic remains a significant challenge, many motion planning\nmethods for this scenario have been proposed but it is hard to evaluate them.\nMost existing closed-loop simulators rely on rule-based controls for other\nvehicles, which results in a lack of diversity and randomness, thus failing to\naccurately assess the motion planning capabilities in highly interactive\nscenarios. Moreover, traditional evaluation metrics are insufficient for\ncomprehensively evaluating the performance of merging in dense traffic. In\nresponse, we proposed a closed-loop evaluation benchmark for assessing motion\nplanning capabilities in merging scenarios. Our approach involves other\nvehicles trained in large scale datasets with micro-behavioral characteristics\nthat significantly enhance the complexity and diversity. Additionally, we have\nrestructured the evaluation mechanism by leveraging Large Language Models\n(LLMs) to assess each autonomous vehicle merging onto the main lane. Extensive\nexperiments and test-vehicle deployment have demonstrated the progressiveness\nof this benchmark. Through this benchmark, we have obtained an evaluation of\nexisting methods and identified common issues. The simulation environment and\nevaluation process can be accessed at https://github.com/WZM5853/Bench4Merge.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "6 pages, 8 figures, on submitted",
    "pdf_url": "http://arxiv.org/pdf/2410.15912v3",
    "published_date": "2024-10-21 11:35:33 UTC",
    "updated_date": "2025-04-02 09:02:05 UTC"
  },
  {
    "arxiv_id": "2410.15910v2",
    "title": "Diverse Policies Recovering via Pointwise Mutual Information Weighted Imitation Learning",
    "authors": [
      "Hanlin Yang",
      "Jian Yao",
      "Weiming Liu",
      "Qing Wang",
      "Hanmin Qin",
      "Hansheng Kong",
      "Kirk Tang",
      "Jiechao Xiong",
      "Chao Yu",
      "Kai Li",
      "Junliang Xing",
      "Hongwu Chen",
      "Juchao Zhuo",
      "Qiang Fu",
      "Yang Wei",
      "Haobo Fu"
    ],
    "abstract": "Recovering a spectrum of diverse policies from a set of expert trajectories\nis an important research topic in imitation learning. After determining a\nlatent style for a trajectory, previous diverse policies recovering methods\nusually employ a vanilla behavioral cloning learning objective conditioned on\nthe latent style, treating each state-action pair in the trajectory with equal\nimportance. Based on an observation that in many scenarios, behavioral styles\nare often highly relevant with only a subset of state-action pairs, this paper\npresents a new principled method in diverse polices recovery. In particular,\nafter inferring or assigning a latent style for a trajectory, we enhance the\nvanilla behavioral cloning by incorporating a weighting mechanism based on\npointwise mutual information. This additional weighting reflects the\nsignificance of each state-action pair's contribution to learning the style,\nthus allowing our method to focus on state-action pairs most representative of\nthat style. We provide theoretical justifications for our new objective, and\nextensive empirical evaluations confirm the effectiveness of our method in\nrecovering diverse policies from expert data.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "18 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.15910v2",
    "published_date": "2024-10-21 11:33:14 UTC",
    "updated_date": "2024-10-22 05:06:36 UTC"
  },
  {
    "arxiv_id": "2410.15897v1",
    "title": "IGMaxHS -- An Incremental MaxSAT Solver with Support for XOR Clauses",
    "authors": [
      "Ole Lübke"
    ],
    "abstract": "Recently, a novel, MaxSAT-based method for error correction in quantum\ncomputing has been proposed that requires both incremental MaxSAT solving\ncapabilities and support for XOR constraints, but no dedicated MaxSAT solver\nfulfilling these criteria existed yet. We alleviate that and introduce IGMaxHS,\nwhich is based on the existing solvers iMaxHS and GaussMaxHS, but poses fewer\nrestrictions on the XOR constraints than GaussMaxHS. IGMaxHS is fuzz tested\nwith xwcnfuzz, an extension of wcnfuzz that can directly output XOR\nconstraints. As a result, IGMaxHS is the only solver that reported neither\nincorrect unsatisfiability verdicts nor invalid models nor incoherent cost\nmodel combinations in a final fuzz testing comparison of all three solvers with\n10000 instances. We detail the steps required for implementing Gaussian\nelimination on XOR constraints in CDCL SAT solvers, and extend the recently\nproposed re-entrant incremental MaxSAT solver application program interface to\nallow for incremental addition of XOR constraints. Finally, we show that\nIGMaxHS is capable of decoding quantum color codes through simulation with the\nMunich Quantum Toolkit.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Presented at the 15th International Workshop on Pragmatics of SAT\n  (PoS 2024, see https://www.pragmaticsofssat.org/2024/ )",
    "pdf_url": "http://arxiv.org/pdf/2410.15897v1",
    "published_date": "2024-10-21 11:21:21 UTC",
    "updated_date": "2024-10-21 11:21:21 UTC"
  },
  {
    "arxiv_id": "2410.15889v1",
    "title": "Model Mimic Attack: Knowledge Distillation for Provably Transferable Adversarial Examples",
    "authors": [
      "Kirill Lukyanov",
      "Andrew Perminov",
      "Denis Turdakov",
      "Mikhail Pautov"
    ],
    "abstract": "The vulnerability of artificial neural networks to adversarial perturbations\nin the black-box setting is widely studied in the literature. The majority of\nattack methods to construct these perturbations suffer from an impractically\nlarge number of queries required to find an adversarial example. In this work,\nwe focus on knowledge distillation as an approach to conduct transfer-based\nblack-box adversarial attacks and propose an iterative training of the\nsurrogate model on an expanding dataset. This work is the first, to our\nknowledge, to provide provable guarantees on the success of knowledge\ndistillation-based attack on classification neural networks: we prove that if\nthe student model has enough learning capabilities, the attack on the teacher\nmodel is guaranteed to be found within the finite number of distillation\niterations.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15889v1",
    "published_date": "2024-10-21 11:06:56 UTC",
    "updated_date": "2024-10-21 11:06:56 UTC"
  },
  {
    "arxiv_id": "2410.15885v1",
    "title": "How to Build a Pre-trained Multimodal model for Simultaneously Chatting and Decision-making?",
    "authors": [
      "Zuojin Tang",
      "Bin Hu",
      "Chenyang Zhao",
      "De Ma",
      "Gang Pan",
      "Bin Liu"
    ],
    "abstract": "Existing large pre-trained models typically map text input to text output in\nan end-to-end manner, such as ChatGPT, or map a segment of text input to a\nhierarchy of action decisions, such as OpenVLA. However, humans can\nsimultaneously generate text and actions when receiving specific input signals.\nFor example, a driver can make precise driving decisions while conversing with\na friend in the passenger seat. Motivated by this observation, we consider the\nfollowing question in this work: is it possible to construct a pre-trained\nmodel that can provide both language interaction and precise decision-making\ncapabilities in dynamic open scenarios. We provide a definitive answer to this\nquestion by developing a new model architecture termed Visual Language Action\nmodel for Chatting and Decision Making (VLA4CD), and further demonstrating its\nperformance in challenging autonomous driving tasks. Specifically, we leverage\nLoRA to fine-tune a pre-trained LLM with data of multiple modalities covering\nlanguage, visual, and action. Unlike the existing LoRA operations used for LLM\nfine-tuning, we have designed new computational modules and training cost\nfunctions for VLA4CD. These designs enable VLA4CD to provide continuous-valued\naction decisions while outputting text responses. In contrast, existing LLMs\ncan only output text responses, and current VLA models can only output action\ndecisions. Moreover, these VLA models handle action data by discretizing and\nthen tokenizing the discretized actions, a method unsuitable for complex\ndecision-making tasks involving high-dimensional continuous-valued action\nvectors, such as autonomous driving. The experimental results on CARLA validate\nthat: (1) our proposed model construction method is effective; (2) compared to\nthe SOTA VLA model, VLA4CD can provide more accurate real-time decision-making\nwhile retaining the text interaction capability inherent to LLMs.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15885v1",
    "published_date": "2024-10-21 11:02:42 UTC",
    "updated_date": "2024-10-21 11:02:42 UTC"
  },
  {
    "arxiv_id": "2410.15884v1",
    "title": "Using GPT Models for Qualitative and Quantitative News Analytics in the 2024 US Presidental Election Process",
    "authors": [
      "Bohdan M. Pavlyshenko"
    ],
    "abstract": "The paper considers an approach of using Google Search API and GPT-4o model\nfor qualitative and quantitative analyses of news through retrieval-augmented\ngeneration (RAG). This approach was applied to analyze news about the 2024 US\npresidential election process. Different news sources for different time\nperiods have been analyzed. Quantitative scores generated by GPT model have\nbeen analyzed using Bayesian regression to derive trend lines. The\ndistributions found for the regression parameters allow for the analysis of\nuncertainty in the election process. The obtained results demonstrate that\nusing the GPT models for news analysis, one can get informative analytics and\nprovide key insights that can be applied in further analyses of election\nprocesses.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15884v1",
    "published_date": "2024-10-21 11:02:18 UTC",
    "updated_date": "2024-10-21 11:02:18 UTC"
  },
  {
    "arxiv_id": "2410.15881v1",
    "title": "MI-VisionShot: Few-shot adaptation of vision-language models for slide-level classification of histopathological images",
    "authors": [
      "Pablo Meseguer",
      "Rocío del Amor",
      "Valery Naranjo"
    ],
    "abstract": "Vision-language supervision has made remarkable strides in learning visual\nrepresentations from textual guidance. In digital pathology, vision-language\nmodels (VLM), pre-trained on curated datasets of histological image-captions,\nhave been adapted to downstream tasks, such as region of interest\nclassification. Zero-shot transfer for slide-level prediction has been\nformulated by MI-Zero, but it exhibits high variability depending on the\ntextual prompts. Inspired by prototypical learning, we propose MI-VisionShot, a\ntraining-free adaptation method on top of VLMs to predict slide-level labels in\nfew-shot learning scenarios. Our framework takes advantage of the excellent\nrepresentation learning of VLM to create prototype-based classifiers under a\nmultiple-instance setting by retrieving the most discriminative patches within\neach slide. Experimentation through different settings shows the ability of\nMI-VisionShot to surpass zero-shot transfer with lower variability, even in\nlow-shot scenarios. Code coming soon at\nthttps://github.com/cvblab/MIVisionShot.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Manuscript accepted for oral presentation at KES-InnovationInMedicine\n  2024 held on Madeira, Portugal",
    "pdf_url": "http://arxiv.org/pdf/2410.15881v1",
    "published_date": "2024-10-21 11:01:20 UTC",
    "updated_date": "2024-10-21 11:01:20 UTC"
  },
  {
    "arxiv_id": "2410.15876v3",
    "title": "FlickerFusion: Intra-trajectory Domain Generalizing Multi-Agent RL",
    "authors": [
      "Woosung Koh",
      "Wonbeen Oh",
      "Siyeol Kim",
      "Suhin Shin",
      "Hyeongjin Kim",
      "Jaein Jang",
      "Junghyun Lee",
      "Se-Young Yun"
    ],
    "abstract": "Multi-agent reinforcement learning has demonstrated significant potential in\naddressing complex cooperative tasks across various real-world applications.\nHowever, existing MARL approaches often rely on the restrictive assumption that\nthe number of entities (e.g., agents, obstacles) remains constant between\ntraining and inference. This overlooks scenarios where entities are dynamically\nremoved or added during the inference trajectory -- a common occurrence in\nreal-world environments like search and rescue missions and dynamic combat\nsituations. In this paper, we tackle the challenge of intra-trajectory dynamic\nentity composition under zero-shot out-of-domain (OOD) generalization, where\nsuch dynamic changes cannot be anticipated beforehand. Our empirical studies\nreveal that existing MARL methods suffer significant performance degradation\nand increased uncertainty in these scenarios. In response, we propose\nFlickerFusion, a novel OOD generalization method that acts as a universally\napplicable augmentation technique for MARL backbone methods. FlickerFusion\nstochastically drops out parts of the observation space, emulating being\nin-domain when inferenced OOD. The results show that FlickerFusion not only\nachieves superior inference rewards but also uniquely reduces uncertainty\nvis-\\`a-vis the backbone, compared to existing methods. Benchmarks,\nimplementations, and model weights are organized and open-sourced at\nflickerfusion305.github.io, accompanied by ample demo video renderings.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS '24 Open-World Agents Workshop",
    "pdf_url": "http://arxiv.org/pdf/2410.15876v3",
    "published_date": "2024-10-21 10:57:45 UTC",
    "updated_date": "2024-12-03 05:59:09 UTC"
  },
  {
    "arxiv_id": "2410.15859v3",
    "title": "Mesa-Extrapolation: A Weave Position Encoding Method for Enhanced Extrapolation in LLMs",
    "authors": [
      "Xin Ma",
      "Yang Liu",
      "Jingjing Liu",
      "Xiaoxu Ma"
    ],
    "abstract": "Large language models (LLMs), although having revolutionized many fields,\nstill suffer from the challenging extrapolation problem, where the inference\nability of LLMs sharply declines beyond their max training lengths. In this\nwork, we conduct a theoretical analysis to better understand why No Position\nEncoding (NoPE) fails outside its effective range, as well as examining the\npower of Position Encoding (PE) in this context. Our findings reveal that with\nmeticulous weave position, PE can indeed be extended beyond effective range.\nOur theorems establish that LLMs equipped with weave PE can achieve improved\nextrapolation performance without additional cost. Furthermore, we introduce a\nnovel weave PE method, Mesa-Extrapolation, which utilizes a chunk-based\ntriangular attention matrix and applies Stair PE to manage the final chunk.\nThis method not only retains competitive performance but also offers\nsubstantial benefits such as significantly reduced memory demand and faster\ninference speed. Extensive experiments validate the effectiveness of\nMesa-Extrapolation, demonstrating its potential as a scalable solution to\nenhancing LLMs applicative reach. Our code is available at\n\\url{https://github.com/soacker/Mesa-Extrapolation}.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by NeurIPS 2024; 13 pages and 30 pages appendix;",
    "pdf_url": "http://arxiv.org/pdf/2410.15859v3",
    "published_date": "2024-10-21 10:39:05 UTC",
    "updated_date": "2024-10-24 10:29:15 UTC"
  },
  {
    "arxiv_id": "2410.15847v1",
    "title": "Random Token Fusion for Multi-View Medical Diagnosis",
    "authors": [
      "Jingyu Guo",
      "Christos Matsoukas",
      "Fredrik Strand",
      "Kevin Smith"
    ],
    "abstract": "In multi-view medical diagnosis, deep learning-based models often fuse\ninformation from different imaging perspectives to improve diagnostic\nperformance. However, existing approaches are prone to overfitting and rely\nheavily on view-specific features, which can lead to trivial solutions. In this\nwork, we introduce Random Token Fusion (RTF), a novel technique designed to\nenhance multi-view medical image analysis using vision transformers. By\nintegrating randomness into the feature fusion process during training, RTF\naddresses the issue of overfitting and enhances the robustness and accuracy of\ndiagnostic models without incurring any additional cost at inference. We\nvalidate our approach on standard mammography and chest X-ray benchmark\ndatasets. Through extensive experiments, we demonstrate that RTF consistently\nimproves the performance of existing fusion methods, paving the way for a new\ngeneration of multi-view medical foundation models.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Originally published at the NeurIPS 2024 Workshop on Advancements In\n  Medical Foundation Models: Explainability, Robustness, Security, and Beyond\n  (AIM-FM)",
    "pdf_url": "http://arxiv.org/pdf/2410.15847v1",
    "published_date": "2024-10-21 10:19:45 UTC",
    "updated_date": "2024-10-21 10:19:45 UTC"
  },
  {
    "arxiv_id": "2410.15837v1",
    "title": "Long-distance Geomagnetic Navigation in GNSS-denied Environments with Deep Reinforcement Learning",
    "authors": [
      "Wenqi Bai",
      "Xiaohui Zhang",
      "Shiliang Zhang",
      "Songnan Yang",
      "Yushuai Li",
      "Tingwen Huang"
    ],
    "abstract": "Geomagnetic navigation has drawn increasing attention with its capacity in\nnavigating through complex environments and its independence from external\nnavigation services like global navigation satellite systems (GNSS). Existing\nstudies on geomagnetic navigation, i.e., matching navigation and bionic\nnavigation, rely on pre-stored map or extensive searches, leading to limited\napplicability or reduced navigation efficiency in unexplored areas. To address\nthe issues with geomagnetic navigation in areas where GNSS is unavailable, this\npaper develops a deep reinforcement learning (DRL)-based mechanism, especially\nfor long-distance geomagnetic navigation. The designed mechanism trains an\nagent to learn and gain the magnetoreception capacity for geomagnetic\nnavigation, rather than using any pre-stored map or extensive and expensive\nsearching approaches. Particularly, we integrate the geomagnetic gradient-based\nparallel approach into geomagnetic navigation. This integration mitigates the\nover-exploration of the learning agent by adjusting the geomagnetic gradient,\nsuch that the obtained gradient is aligned towards the destination. We explore\nthe effectiveness of the proposed approach via detailed numerical simulations,\nwhere we implement twin delayed deep deterministic policy gradient (TD3) in\nrealizing the proposed approach. The results demonstrate that our approach\noutperforms existing metaheuristic and bionic navigation methods in\nlong-distance missions under diverse navigation conditions.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15837v1",
    "published_date": "2024-10-21 09:57:42 UTC",
    "updated_date": "2024-10-21 09:57:42 UTC"
  },
  {
    "arxiv_id": "2410.15828v1",
    "title": "LLM4GRN: Discovering Causal Gene Regulatory Networks with LLMs -- Evaluation through Synthetic Data Generation",
    "authors": [
      "Tejumade Afonja",
      "Ivaxi Sheth",
      "Ruta Binkyte",
      "Waqar Hanif",
      "Thomas Ulas",
      "Matthias Becker",
      "Mario Fritz"
    ],
    "abstract": "Gene regulatory networks (GRNs) represent the causal relationships between\ntranscription factors (TFs) and target genes in single-cell RNA sequencing\n(scRNA-seq) data. Understanding these networks is crucial for uncovering\ndisease mechanisms and identifying therapeutic targets. In this work, we\ninvestigate the potential of large language models (LLMs) for GRN discovery,\nleveraging their learned biological knowledge alone or in combination with\ntraditional statistical methods. We develop a task-based evaluation strategy to\naddress the challenge of unavailable ground truth causal graphs. Specifically,\nwe use the GRNs suggested by LLMs to guide causal synthetic data generation and\ncompare the resulting data against the original dataset. Our statistical and\nbiological assessments show that LLMs can support statistical modeling and data\nsynthesis for biological research.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15828v1",
    "published_date": "2024-10-21 09:46:37 UTC",
    "updated_date": "2024-10-21 09:46:37 UTC"
  },
  {
    "arxiv_id": "2410.15821v1",
    "title": "The effect of fine-tuning on language model toxicity",
    "authors": [
      "Will Hawkins",
      "Brent Mittelstadt",
      "Chris Russell"
    ],
    "abstract": "Fine-tuning language models has become increasingly popular following the\nproliferation of open models and improvements in cost-effective parameter\nefficient fine-tuning. However, fine-tuning can influence model properties such\nas safety. We assess how fine-tuning can impact different open models'\npropensity to output toxic content. We assess the impacts of fine-tuning Gemma,\nLlama, and Phi models on toxicity through three experiments. We compare how\ntoxicity is reduced by model developers during instruction-tuning. We show that\nsmall amounts of parameter-efficient fine-tuning on developer-tuned models via\nlow-rank adaptation on a non-adversarial dataset can significantly alter these\nresults across models. Finally, we highlight the impact of this in the wild,\ndemonstrating how toxicity rates of models fine-tuned by community contributors\ncan deviate in hard-to-predict ways.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "To be presented at NeurIPS 2024 Safe Generative AI Workshop",
    "pdf_url": "http://arxiv.org/pdf/2410.15821v1",
    "published_date": "2024-10-21 09:39:09 UTC",
    "updated_date": "2024-10-21 09:39:09 UTC"
  },
  {
    "arxiv_id": "2410.15820v1",
    "title": "MAC Revivo: Artificial Intelligence Paves the Way",
    "authors": [
      "Jinzhe Pan",
      "Jingqing Wang",
      "Zelin Yun",
      "Zhiyong Xiao",
      "Yuehui Ouyang",
      "Wenchi Cheng",
      "Wei Zhang"
    ],
    "abstract": "The vast adoption of Wi-Fi and/or Bluetooth capabilities in Internet of\nThings (IoT) devices, along with the rapid growth of deployed smart devices,\nhas caused significant interference and congestion in the industrial,\nscientific, and medical (ISM) bands. Traditional Wi-Fi Medium Access Control\n(MAC) design faces significant challenges in managing increasingly complex\nwireless environments while ensuring network Quality of Service (QoS)\nperformance. This paper explores the potential integration of advanced\nArtificial Intelligence (AI) methods into the design of Wi-Fi MAC protocols. We\npropose AI-MAC, an innovative approach that employs machine learning algorithms\nto dynamically adapt to changing network conditions, optimize channel access,\nmitigate interference, and ensure deterministic latency. By intelligently\npredicting and managing interference, AI-MAC aims to provide a robust solution\nfor next generation of Wi-Fi networks, enabling seamless connectivity and\nenhanced QoS. Our experimental results demonstrate that AI-MAC significantly\nreduces both interference and latency, paving the way for more reliable and\nefficient wireless communications in the increasingly crowded ISM band.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15820v1",
    "published_date": "2024-10-21 09:36:53 UTC",
    "updated_date": "2024-10-21 09:36:53 UTC"
  },
  {
    "arxiv_id": "2410.15819v1",
    "title": "LiMTR: Time Series Motion Prediction for Diverse Road Users through Multimodal Feature Integration",
    "authors": [
      "Camiel Oerlemans",
      "Bram Grooten",
      "Michiel Braat",
      "Alaa Alassi",
      "Emilia Silvas",
      "Decebal Constantin Mocanu"
    ],
    "abstract": "Predicting the behavior of road users accurately is crucial to enable the\nsafe operation of autonomous vehicles in urban or densely populated areas.\nTherefore, there has been a growing interest in time series motion prediction\nresearch, leading to significant advancements in state-of-the-art techniques in\nrecent years. However, the potential of using LiDAR data to capture more\ndetailed local features, such as a person's gaze or posture, remains largely\nunexplored. To address this, we develop a novel multimodal approach for motion\nprediction based on the PointNet foundation model architecture, incorporating\nlocal LiDAR features. Evaluation on the Waymo Open Dataset shows a performance\nimprovement of 6.20% and 1.58% in minADE and mAP respectively, when integrated\nand compared with the previous state-of-the-art MTR. We open-source the code of\nour LiMTR model.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at the NeurIPS 2024 workshop Time Series in the Age of Large\n  Models. Code available at https://github.com/Cing2/LiMTR",
    "pdf_url": "http://arxiv.org/pdf/2410.15819v1",
    "published_date": "2024-10-21 09:35:57 UTC",
    "updated_date": "2024-10-21 09:35:57 UTC"
  },
  {
    "arxiv_id": "2410.15814v1",
    "title": "Kaninfradet3D:A Road-side Camera-LiDAR Fusion 3D Perception Model based on Nonlinear Feature Extraction and Intrinsic Correlation",
    "authors": [
      "Pei Liu",
      "Nanfang Zheng",
      "Yiqun Li",
      "Junlan Chen",
      "Ziyuan Pu"
    ],
    "abstract": "With the development of AI-assisted driving, numerous methods have emerged\nfor ego-vehicle 3D perception tasks, but there has been limited research on\nroadside perception. With its ability to provide a global view and a broader\nsensing range, the roadside perspective is worth developing. LiDAR provides\nprecise three-dimensional spatial information, while cameras offer semantic\ninformation. These two modalities are complementary in 3D detection. However,\nadding camera data does not increase accuracy in some studies since the\ninformation extraction and fusion procedure is not sufficiently reliable.\nRecently, Kolmogorov-Arnold Networks (KANs) have been proposed as replacements\nfor MLPs, which are better suited for high-dimensional, complex data. Both the\ncamera and the LiDAR provide high-dimensional information, and employing KANs\nshould enhance the extraction of valuable features to produce better fusion\noutcomes. This paper proposes Kaninfradet3D, which optimizes the feature\nextraction and fusion modules. To extract features from complex\nhigh-dimensional data, the model's encoder and fuser modules were improved\nusing KAN Layers. Cross-attention was applied to enhance feature fusion, and\nvisual comparisons verified that camera features were more evenly integrated.\nThis addressed the issue of camera features being abnormally concentrated,\nnegatively impacting fusion. Compared to the benchmark, our approach shows\nimprovements of +9.87 mAP and +10.64 mAP in the two viewpoints of the TUMTraf\nIntersection Dataset and an improvement of +1.40 mAP in the roadside end of the\nTUMTraf V2X Cooperative Perception Dataset. The results indicate that\nKaninfradet3D can effectively fuse features, demonstrating the potential of\napplying KANs in roadside perception tasks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15814v1",
    "published_date": "2024-10-21 09:28:42 UTC",
    "updated_date": "2024-10-21 09:28:42 UTC"
  },
  {
    "arxiv_id": "2410.15805v1",
    "title": "RAG4ITOps: A Supervised Fine-Tunable and Comprehensive RAG Framework for IT Operations and Maintenance",
    "authors": [
      "Tianyang Zhang",
      "Zhuoxuan Jiang",
      "Shengguang Bai",
      "Tianrui Zhang",
      "Lin Lin",
      "Yang Liu",
      "Jiawei Ren"
    ],
    "abstract": "With the ever-increasing demands on Question Answering (QA) systems for IT\noperations and maintenance, an efficient and supervised fine-tunable framework\nis necessary to ensure the data security, private deployment and continuous\nupgrading. Although Large Language Models (LLMs) have notably improved the\nopen-domain QA's performance, how to efficiently handle enterprise-exclusive\ncorpora and build domain-specific QA systems are still less-studied for\nindustrial applications. In this paper, we propose a general and comprehensive\nframework based on Retrieval Augmented Generation (RAG) and facilitate the\nwhole business process of establishing QA systems for IT operations and\nmaintenance. In accordance with the prevailing RAG method, our proposed\nframework, named with RAG4ITOps, composes of two major stages: (1) Models\nFine-tuning \\& Data Vectorization, and (2) Online QA System Process. At the\nStage 1, we leverage a contrastive learning method with two negative sampling\nstrategies to fine-tune the embedding model, and design the instruction\ntemplates to fine-tune the LLM with a Retrieval Augmented Fine-Tuning method.\nAt the Stage 2, an efficient process of QA system is built for serving. We\ncollect enterprise-exclusive corpora from the domain of cloud computing, and\nthe extensive experiments show that our method achieves superior results than\ncounterparts on two kinds of QA tasks. Our experiment also provide a case for\napplying the RAG4ITOps to real-world enterprise-level applications.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by EMNLP 2024 Industry Track",
    "pdf_url": "http://arxiv.org/pdf/2410.15805v1",
    "published_date": "2024-10-21 09:22:29 UTC",
    "updated_date": "2024-10-21 09:22:29 UTC"
  },
  {
    "arxiv_id": "2410.15804v1",
    "title": "Deep Learning and Data Augmentation for Detecting Self-Admitted Technical Debt",
    "authors": [
      "Edi Sutoyo",
      "Paris Avgeriou",
      "Andrea Capiluppi"
    ],
    "abstract": "Self-Admitted Technical Debt (SATD) refers to circumstances where developers\nuse textual artifacts to explain why the existing implementation is not\noptimal. Past research in detecting SATD has focused on either identifying SATD\n(classifying SATD items as SATD or not) or categorizing SATD (labeling\ninstances as SATD that pertain to requirement, design, code, test debt, etc.).\nHowever, the performance of these approaches remains suboptimal, particularly\nfor specific types of SATD, such as test and requirement debt, primarily due to\nextremely imbalanced datasets. To address these challenges, we build on earlier\nresearch by utilizing BiLSTM architecture for the binary identification of SATD\nand BERT architecture for categorizing different types of SATD. Despite their\neffectiveness, both architectures struggle with imbalanced data. Therefore, we\nemploy a large language model data augmentation strategy to mitigate this\nissue. Furthermore, we introduce a two-step approach to identify and categorize\nSATD across various datasets derived from different artifacts. Our\ncontributions include providing a balanced dataset for future SATD researchers\nand demonstrating that our approach significantly improves SATD identification\nand categorization performance compared to baseline methods.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted to be published at the 2024 31st Asia-Pacific Software\n  Engineering Conference (APSEC)",
    "pdf_url": "http://arxiv.org/pdf/2410.15804v1",
    "published_date": "2024-10-21 09:22:16 UTC",
    "updated_date": "2024-10-21 09:22:16 UTC"
  },
  {
    "arxiv_id": "2410.15794v1",
    "title": "Habaek: High-performance water segmentation through dataset expansion and inductive bias optimization",
    "authors": [
      "Hanseon Joo",
      "Eunji Lee",
      "Minjong Cheon"
    ],
    "abstract": "Water segmentation is critical to disaster response and water resource\nmanagement. Authorities may employ high-resolution photography to monitor\nrivers, lakes, and reservoirs, allowing for more proactive management in\nagriculture, industry, and conservation. Deep learning has improved flood\nmonitoring by allowing models like CNNs, U-Nets, and transformers to handle\nlarge volumes of satellite and aerial data. However, these models usually have\nsignificant processing requirements, limiting their usage in real-time\napplications. This research proposes upgrading the SegFormer model for water\nsegmentation by data augmentation with datasets such as ADE20K and RIWA to\nboost generalization. We examine how inductive bias affects attention-based\nmodels and discover that SegFormer performs better on bigger datasets. To\nfurther demonstrate the function of data augmentation, Low-Rank Adaptation\n(LoRA) is used to lower processing complexity while preserving accuracy. We\nshow that the suggested Habaek model outperforms current models in\nsegmentation, with an Intersection over Union (IoU) ranging from 0.91986 to\n0.94397. In terms of F1-score, recall, accuracy, and precision, Habaek performs\nbetter than rival models, indicating its potential for real-world applications.\nThis study highlights the need to enhance structures and include datasets for\neffective water segmentation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15794v1",
    "published_date": "2024-10-21 09:06:13 UTC",
    "updated_date": "2024-10-21 09:06:13 UTC"
  },
  {
    "arxiv_id": "2410.15792v2",
    "title": "WildOcc: A Benchmark for Off-Road 3D Semantic Occupancy Prediction",
    "authors": [
      "Heng Zhai",
      "Jilin Mei",
      "Chen Min",
      "Liang Chen",
      "Fangzhou Zhao",
      "Yu Hu"
    ],
    "abstract": "3D semantic occupancy prediction is an essential part of autonomous driving,\nfocusing on capturing the geometric details of scenes. Off-road environments\nare rich in geometric information, therefore it is suitable for 3D semantic\noccupancy prediction tasks to reconstruct such scenes. However, most of\nresearches concentrate on on-road environments, and few methods are designed\nfor off-road 3D semantic occupancy prediction due to the lack of relevant\ndatasets and benchmarks. In response to this gap, we introduce WildOcc, to our\nknowledge, the first benchmark to provide dense occupancy annotations for\noff-road 3D semantic occupancy prediction tasks. A ground truth generation\npipeline is proposed in this paper, which employs a coarse-to-fine\nreconstruction to achieve a more realistic result. Moreover, we introduce a\nmulti-modal 3D semantic occupancy prediction framework, which fuses\nspatio-temporal information from multi-frame images and point clouds at voxel\nlevel. In addition, a cross-modality distillation function is introduced, which\ntransfers geometric knowledge from point clouds to image features.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15792v2",
    "published_date": "2024-10-21 09:02:40 UTC",
    "updated_date": "2024-10-27 09:11:07 UTC"
  },
  {
    "arxiv_id": "2410.15787v2",
    "title": "Arithmetic Transformers Can Length-Generalize in Both Operand Length and Count",
    "authors": [
      "Hanseul Cho",
      "Jaeyoung Cha",
      "Srinadh Bhojanapalli",
      "Chulhee Yun"
    ],
    "abstract": "Transformers often struggle with length generalization, meaning they fail to\ngeneralize to sequences longer than those encountered during training. While\narithmetic tasks are commonly used to study length generalization, certain\ntasks are considered notoriously difficult, e.g., multi-operand addition\n(requiring generalization over both the number of operands and their lengths)\nand multiplication (requiring generalization over both operand lengths). In\nthis work, we achieve approximately 2-3x length generalization on both tasks,\nwhich is the first such achievement in arithmetic Transformers. We design\ntask-specific scratchpads enabling the model to focus on a fixed number of\ntokens per each next-token prediction step, and apply multi-level versions of\n\\Position Coupling (Cho et al., 2024; McLeish et al., 2024) to let Transformers\nknow the right position to attend to. On the theory side, we prove that a\n1-layer Transformer using our method can solve multi-operand addition, up to\noperand length and operand count that are exponential in embedding dimension.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "44 pages, 20 figures, 26 tables, accepted to ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.15787v2",
    "published_date": "2024-10-21 08:49:51 UTC",
    "updated_date": "2025-04-17 08:18:02 UTC"
  },
  {
    "arxiv_id": "2410.15780v1",
    "title": "An Efficient System for Automatic Map Storytelling -- A Case Study on Historical Maps",
    "authors": [
      "Ziyi Liu",
      "Claudio Affolter",
      "Sidi Wu",
      "Yizi Chen",
      "Lorenz Hurni"
    ],
    "abstract": "Historical maps provide valuable information and knowledge about the past.\nHowever, as they often feature non-standard projections, hand-drawn styles, and\nartistic elements, it is challenging for non-experts to identify and interpret\nthem. While existing image captioning methods have achieved remarkable success\non natural images, their performance on maps is suboptimal as maps are\nunderrepresented in their pre-training process. Despite the recent advance of\nGPT-4 in text recognition and map captioning, it still has a limited\nunderstanding of maps, as its performance wanes when texts (e.g., titles and\nlegends) in maps are missing or inaccurate. Besides, it is inefficient or even\nimpractical to fine-tune the model with users' own datasets. To address these\nproblems, we propose a novel and lightweight map-captioning counterpart.\nSpecifically, we fine-tune the state-of-the-art vision-language model CLIP to\ngenerate captions relevant to historical maps and enrich the captions with\nGPT-3.5 to tell a brief story regarding where, what, when and why of a given\nmap. We propose a novel decision tree architecture to only generate captions\nrelevant to the specified map type. Our system shows invariance to text\nalterations in maps. The system can be easily adapted and extended to other map\ntypes and scaled to a larger map captioning system. The code is open-sourced at\nhttps://github.com/claudaff/automatic-map-storytelling.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15780v1",
    "published_date": "2024-10-21 08:45:26 UTC",
    "updated_date": "2024-10-21 08:45:26 UTC"
  },
  {
    "arxiv_id": "2410.15778v2",
    "title": "Reducing Hallucinations in Vision-Language Models via Latent Space Steering",
    "authors": [
      "Sheng Liu",
      "Haotian Ye",
      "Lei Xing",
      "James Zou"
    ],
    "abstract": "Hallucination poses a challenge to the deployment of large vision-language\nmodels (LVLMs) in applications. Unlike in large language models (LLMs),\nhallucination in LVLMs often arises from misalignments between visual inputs\nand textual outputs. This paper investigates the underlying mechanisms of\nhallucination, focusing on the unique structure of LVLMs that distinguishes\nthem from large language models (LLMs). We identify that hallucinations often\narise from the sensitivity of text decoders to vision inputs, a natural\nphenomenon when image encoders and text decoders are pre-trained separately.\nInspired by this, we introduce Visual and Textual Intervention (VTI), a novel\ntechnique designed to reduce hallucinations by steering latent space\nrepresentations during inference to enhance the stability of vision features.\nAs a task-agnostic test-time intervention, VTI can be easily applied to any\nproblem without additional cost. Extensive experiments demonstrate that it can\neffectively reduce hallucinations and outperform baseline methods across\nmultiple metrics, highlighting the critical role of vision feature stability in\nLVLMs.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "21 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.15778v2",
    "published_date": "2024-10-21 08:42:30 UTC",
    "updated_date": "2024-10-22 05:01:28 UTC"
  },
  {
    "arxiv_id": "2410.15770v1",
    "title": "A roadmap for generative mapping: unlocking the power of generative AI for map-making",
    "authors": [
      "Sidi Wu",
      "Katharina Henggeler",
      "Yizi Chen",
      "Lorenz Hurni"
    ],
    "abstract": "Maps are broadly relevant across various fields, serving as valuable tools\nfor presenting spatial phenomena and communicating spatial knowledge. However,\nmap-making is still largely confined to those with expertise in GIS and\ncartography due to the specialized software and complex workflow involved, from\ndata processing to visualization. While generative AI has recently demonstrated\nits remarkable capability in creating various types of content and its wide\naccessibility to the general public, its potential in generating maps is yet to\nbe fully realized. This paper highlights the key applications of generative AI\nin map-making, summarizes recent advancements in generative AI, identifies the\nspecific technologies required and the challenges of using current methods, and\nprovides a roadmap for developing a generative mapping system (GMS) to make\nmap-making more accessible.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15770v1",
    "published_date": "2024-10-21 08:29:43 UTC",
    "updated_date": "2024-10-21 08:29:43 UTC"
  },
  {
    "arxiv_id": "2410.15768v1",
    "title": "Learning to Synthesize Graphics Programs for Geometric Artworks",
    "authors": [
      "Qi Bing",
      "Chaoyi Zhang",
      "Weidong Cai"
    ],
    "abstract": "Creating and understanding art has long been a hallmark of human ability.\nWhen presented with finished digital artwork, professional graphic artists can\nintuitively deconstruct and replicate it using various drawing tools, such as\nthe line tool, paint bucket, and layer features, including opacity and blending\nmodes. While most recent research in this field has focused on art generation,\nproposing a range of methods, these often rely on the concept of artwork being\nrepresented as a final image. To bridge the gap between pixel-level results and\nthe actual drawing process, we present an approach that treats a set of drawing\ntools as executable programs. This method predicts a sequence of steps to\nachieve the final image, allowing for understandable and resolution-independent\nreproductions under the usage of a set of drawing commands. Our experiments\ndemonstrate that our program synthesizer, Art2Prog, can comprehensively\nunderstand complex input images and reproduce them using high-quality\nexecutable programs. The experimental results evidence the potential of\nmachines to grasp higher-level information from images and generate compact\nprogram-level descriptions.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "ICPR 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.15768v1",
    "published_date": "2024-10-21 08:28:11 UTC",
    "updated_date": "2024-10-21 08:28:11 UTC"
  },
  {
    "arxiv_id": "2410.15764v2",
    "title": "LSCodec: Low-Bitrate and Speaker-Decoupled Discrete Speech Codec",
    "authors": [
      "Yiwei Guo",
      "Zhihan Li",
      "Chenpeng Du",
      "Hankun Wang",
      "Xie Chen",
      "Kai Yu"
    ],
    "abstract": "Although discrete speech tokens have exhibited strong potential for language\nmodel-based speech generation, their high bitrates and redundant timbre\ninformation restrict the development of such models. In this work, we propose\nLSCodec, a discrete speech codec that has both low bitrate and speaker\ndecoupling ability. LSCodec adopts a three-stage unsupervised training\nframework with a speaker perturbation technique. A continuous information\nbottleneck is first established, followed by vector quantization that produces\na discrete speaker-decoupled space. A discrete token vocoder finally refines\nacoustic details from LSCodec. By reconstruction experiments, LSCodec\ndemonstrates superior intelligibility and audio quality with only a single\ncodebook and smaller vocabulary size than baselines. The 25Hz version of\nLSCodec also achieves the lowest bitrate (0.25kbps) of codecs so far with\ndecent quality. Voice conversion evaluations prove the satisfactory speaker\ndisentanglement of LSCodec, and ablation study further verifies the\neffectiveness of the proposed training framework.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "5 pages, 2 figures, 4 tables. Demo page:\n  https://cantabile-kwok.github.io/LSCodec/",
    "pdf_url": "http://arxiv.org/pdf/2410.15764v2",
    "published_date": "2024-10-21 08:23:31 UTC",
    "updated_date": "2024-12-22 12:48:43 UTC"
  },
  {
    "arxiv_id": "2410.15760v1",
    "title": "DeepIcon: A Hierarchical Network for Layer-wise Icon Vectorization",
    "authors": [
      "Qi Bing",
      "Chaoyi Zhang",
      "Weidong Cai"
    ],
    "abstract": "In contrast to the well-established technique of rasterization, vectorization\nof images poses a significant challenge in the field of computer graphics.\nRecent learning-based methods for converting raster images to vector formats\nfrequently suffer from incomplete shapes, redundant path prediction, and a lack\nof accuracy in preserving the semantics of the original content. These\nshortcomings severely hinder the utility of these methods for further editing\nand manipulation of images. To address these challenges, we present DeepIcon, a\nnovel hierarchical image vectorization network specifically tailored for\ngenerating variable-length icon vector graphics based on the raster image\ninput. Our experimental results indicate that DeepIcon can efficiently produce\nScalable Vector Graphics (SVGs) directly from raster images, bypassing the need\nfor a differentiable rasterizer while also demonstrating a profound\nunderstanding of the image contents.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted as Oral Presentation at DICTA 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.15760v1",
    "published_date": "2024-10-21 08:20:19 UTC",
    "updated_date": "2024-10-21 08:20:19 UTC"
  },
  {
    "arxiv_id": "2410.15756v2",
    "title": "Automated Proof Generation for Rust Code via Self-Evolution",
    "authors": [
      "Tianyu Chen",
      "Shuai Lu",
      "Shan Lu",
      "Yeyun Gong",
      "Chenyuan Yang",
      "Xuheng Li",
      "Md Rakib Hossain Misu",
      "Hao Yu",
      "Nan Duan",
      "Peng Cheng",
      "Fan Yang",
      "Shuvendu K Lahiri",
      "Tao Xie",
      "Lidong Zhou"
    ],
    "abstract": "Ensuring correctness is crucial for code generation. Formal verification\noffers a definitive assurance of correctness, but demands substantial human\neffort in proof construction and hence raises a pressing need for automation.\nThe primary obstacle lies in the severe lack of data-there is much fewer proofs\nthan code snippets for Large Language Models (LLMs) to train upon. In this\npaper, we introduce SAFE, a framework that overcomes the lack of human-written\nproofs to enable automated proof generation of Rust code. SAFE establishes a\nself-evolving cycle where data synthesis and fine-tuning collaborate to enhance\nthe model capability, leveraging the definitive power of a symbolic verifier in\ntelling correct proofs from incorrect ones. SAFE also re-purposes the large\nnumber of synthesized incorrect proofs to train the self-debugging capability\nof the fine-tuned models, empowering them to fix incorrect proofs based on the\nverifier's feedback. SAFE demonstrates superior efficiency and precision\ncompared to GPT-4o. Through tens of thousands of synthesized proofs and the\nself-debugging mechanism, we improve the capability of open-source models,\ninitially unacquainted with formal verification, to automatically write proofs\nfor Rust code. This advancement leads to a significant improvement in\nperformance, achieving a 52.52% accuracy rate in a benchmark crafted by human\nexperts, a significant leap over GPT-4o's performance of 14.39%.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15756v2",
    "published_date": "2024-10-21 08:15:45 UTC",
    "updated_date": "2025-04-15 11:39:09 UTC"
  },
  {
    "arxiv_id": "2410.15747v1",
    "title": "GIG: Graph Data Imputation With Graph Differential Dependencies",
    "authors": [
      "Jiang Hua",
      "Michael Bewong",
      "Selasi Kwashie",
      "MD Geaur Rahman",
      "Junwei Hu",
      "Xi Guo",
      "Zaiwen Fen"
    ],
    "abstract": "Data imputation addresses the challenge of imputing missing values in\ndatabase instances, ensuring consistency with the overall semantics of the\ndataset. Although several heuristics which rely on statistical methods, and\nad-hoc rules have been proposed. These do not generalise well and often lack\ndata context. Consequently, they also lack explainability. The existing\ntechniques also mostly focus on the relational data context making them\nunsuitable for wider application contexts such as in graph data. In this paper,\nwe propose a graph data imputation approach called GIG which relies on graph\ndifferential dependencies (GDDs). GIG, learns the GDDs from a given knowledge\ngraph, and uses these rules to train a transformer model which then predicts\nthe value of missing data within the graph. By leveraging GDDs, GIG incoporates\nsemantic knowledge into the data imputation process making it more reliable and\nexplainable. Experimental results on seven real-world datasets highlight GIG's\neffectiveness compared to existing state-of-the-art approaches.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "12 pages, 4 figures, published to ADC",
    "pdf_url": "http://arxiv.org/pdf/2410.15747v1",
    "published_date": "2024-10-21 08:04:21 UTC",
    "updated_date": "2024-10-21 08:04:21 UTC"
  },
  {
    "arxiv_id": "2410.15748v2",
    "title": "Alchemy: Amplifying Theorem-Proving Capability through Symbolic Mutation",
    "authors": [
      "Shaonan Wu",
      "Shuai Lu",
      "Yeyun Gong",
      "Nan Duan",
      "Ping Wei"
    ],
    "abstract": "Formal proofs are challenging to write even for experienced experts. Recent\nprogress in Neural Theorem Proving (NTP) shows promise in expediting this\nprocess. However, the formal corpora available on the Internet are limited\ncompared to the general text, posing a significant data scarcity challenge for\nNTP. To address this issue, this work proposes Alchemy, a general framework for\ndata synthesis that constructs formal theorems through symbolic mutation.\nSpecifically, for each candidate theorem in Mathlib, we identify all invocable\ntheorems that can be used to rewrite or apply to it. Subsequently, we mutate\nthe candidate theorem by replacing the corresponding term in the statement with\nits equivalent form or antecedent. As a result, our method increases the number\nof theorems in Mathlib by an order of magnitude, from 110k to 6M. Furthermore,\nwe perform continual pretraining and supervised finetuning on this augmented\ncorpus for large language models. Experimental results demonstrate the\neffectiveness of our approach, achieving a 4.70% absolute performance\nimprovement on Leandojo benchmark. Additionally, our approach achieves a 2.47%\nabsolute performance gain on the out-of-distribution miniF2F benchmark based on\nthe synthetic data.To provide further insights, we conduct a comprehensive\nanalysis of synthetic data composition and the training paradigm, offering\nvaluable guidance for developing a strong theorem prover.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15748v2",
    "published_date": "2024-10-21 08:04:21 UTC",
    "updated_date": "2025-04-03 12:08:09 UTC"
  },
  {
    "arxiv_id": "2410.15744v2",
    "title": "Unleashing the Potential of Vision-Language Pre-Training for 3D Zero-Shot Lesion Segmentation via Mask-Attribute Alignment",
    "authors": [
      "Yankai Jiang",
      "Wenhui Lei",
      "Xiaofan Zhang",
      "Shaoting Zhang"
    ],
    "abstract": "Recent advancements in medical vision-language pre-training models have\ndriven significant progress in zero-shot disease recognition. However,\ntransferring image-level knowledge to pixel-level tasks, such as lesion\nsegmentation in 3D CT scans, remains a critical challenge. Due to the\ncomplexity and variability of pathological visual characteristics, existing\nmethods struggle to align fine-grained lesion features not encountered during\ntraining with disease-related textual representations. In this paper, we\npresent Malenia, a novel multi-scale lesion-level mask-attribute alignment\nframework, specifically designed for 3D zero-shot lesion segmentation. Malenia\nimproves the compatibility between mask representations and their associated\nelemental attributes, explicitly linking the visual features of unseen lesions\nwith the extensible knowledge learned from previously seen ones. Furthermore,\nwe design a Cross-Modal Knowledge Injection module to enhance both visual and\ntextual features with mutually beneficial information, effectively guiding the\ngeneration of segmentation results. Comprehensive experiments across three\ndatasets and 12 lesion categories validate the superior performance of Malenia.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted as ICLR 2025 conference paper",
    "pdf_url": "http://arxiv.org/pdf/2410.15744v2",
    "published_date": "2024-10-21 08:01:58 UTC",
    "updated_date": "2025-03-02 16:58:17 UTC"
  },
  {
    "arxiv_id": "2410.15737v1",
    "title": "Who's Who: Large Language Models Meet Knowledge Conflicts in Practice",
    "authors": [
      "Quang Hieu Pham",
      "Hoang Ngo",
      "Anh Tuan Luu",
      "Dat Quoc Nguyen"
    ],
    "abstract": "Retrieval-augmented generation (RAG) methods are viable solutions for\naddressing the static memory limits of pre-trained language models.\nNevertheless, encountering conflicting sources of information within the\nretrieval context is an inevitable practical challenge. In such situations, the\nlanguage models are recommended to transparently inform users about the\nconflicts rather than autonomously deciding what to present based on their\ninherent biases. To analyze how current large language models (LLMs) align with\nour recommendation, we introduce WhoQA, a public benchmark dataset to examine\nmodel's behavior in knowledge conflict situations. We induce conflicts by\nasking about a common property among entities having the same name, resulting\nin questions with up to 8 distinctive answers. WhoQA evaluation set includes 5K\nquestions across 13 Wikidata property types and 150K Wikipedia entities. Our\nexperiments show that despite the simplicity of WhoQA questions, knowledge\nconflicts significantly degrades LLMs' performance in RAG settings.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to EMNLP 2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2410.15737v1",
    "published_date": "2024-10-21 07:56:45 UTC",
    "updated_date": "2024-10-21 07:56:45 UTC"
  },
  {
    "arxiv_id": "2410.15735v1",
    "title": "AutoTrain: No-code training for state-of-the-art models",
    "authors": [
      "Abhishek Thakur"
    ],
    "abstract": "With the advancements in open-source models, training (or finetuning) models\non custom datasets has become a crucial part of developing solutions which are\ntailored to specific industrial or open-source applications. Yet, there is no\nsingle tool which simplifies the process of training across different types of\nmodalities or tasks. We introduce AutoTrain (aka AutoTrain Advanced) -- an\nopen-source, no code tool/library which can be used to train (or finetune)\nmodels for different kinds of tasks such as: large language model (LLM)\nfinetuning, text classification/regression, token classification,\nsequence-to-sequence task, finetuning of sentence transformers, visual language\nmodel (VLM) finetuning, image classification/regression and even classification\nand regression tasks on tabular data. AutoTrain Advanced is an open-source\nlibrary providing best practices for training models on custom datasets. The\nlibrary is available at https://github.com/huggingface/autotrain-advanced.\nAutoTrain can be used in fully local mode or on cloud machines and works with\ntens of thousands of models shared on Hugging Face Hub and their variations.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15735v1",
    "published_date": "2024-10-21 07:53:32 UTC",
    "updated_date": "2024-10-21 07:53:32 UTC"
  },
  {
    "arxiv_id": "2410.15726v1",
    "title": "Reducing annotator bias by belief elicitation",
    "authors": [
      "Terne Sasha Thorn Jakobsen",
      "Andreas Bjerre-Nielsen",
      "Robert Böhm"
    ],
    "abstract": "Crowdsourced annotations of data play a substantial role in the development\nof Artificial Intelligence (AI). It is broadly recognised that annotations of\ntext data can contain annotator bias, where systematic disagreement in\nannotations can be traced back to differences in the annotators' backgrounds.\nBeing unaware of such annotator bias can lead to representational bias against\nminority group perspectives and therefore several methods have been proposed\nfor recognising bias or preserving perspectives. These methods typically\nrequire either a substantial number of annotators or annotations per data\ninstance. In this study, we propose a simple method for handling bias in\nannotations without requirements on the number of annotators or instances.\nInstead, we ask annotators about their beliefs of other annotators' judgements\nof an instance, under the hypothesis that these beliefs may provide more\nrepresentative and less biased labels than judgements. The method was examined\nin two controlled, survey-based experiments involving Democrats and Republicans\n(n=1,590) asked to judge statements as arguments and then report beliefs about\nothers' judgements. The results indicate that bias, defined as systematic\ndifferences between the two groups of annotators, is consistently reduced when\nasking for beliefs instead of judgements. Our proposed method therefore has the\npotential to reduce the risk of annotator bias, thereby improving the\ngeneralisability of AI systems and preventing harm to unrepresented\nsocio-demographic groups, and we highlight the need for further studies of this\npotential in other tasks and downstream applications.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "econ.GN",
      "q-fin.EC",
      "68T50",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15726v1",
    "published_date": "2024-10-21 07:44:01 UTC",
    "updated_date": "2024-10-21 07:44:01 UTC"
  },
  {
    "arxiv_id": "2410.15715v2",
    "title": "Timetable Nodes for Public Transport Network",
    "authors": [
      "Andrii Rohovyi",
      "Peter J. Stuckey",
      "Toby Walsh"
    ],
    "abstract": "Faster pathfinding in time-dependent transport networks is an important and\nchallenging problem in navigation systems. There are two main types of\ntransport networks: road networks for car driving and public transport route\nnetwork. The solutions that work well in road networks, such as Time-dependent\nContraction Hierarchies and other graph-based approaches, do not usually apply\nin transport networks. In transport networks, non-graph solutions such as CSA\nand RAPTOR show the best results compared to graph-based techniques. In our\nwork, we propose a method that advances graph-based approaches by using\ndifferent optimization techniques from computational geometry to speed up the\nsearch process in transport networks. We apply a new pre-computation step,\nwhich we call timetable nodes (TTN). Our inspiration comes from an iterative\nsearch problem in computational geometry. We implement two versions of the TTN:\none uses a Combined Search Tree (TTN-CST), and the second uses Fractional\nCascading (TTN-FC). Both of these approaches decrease the asymptotic complexity\nof reaching new nodes from $O(k\\times \\log|C|)$ to $O(k + \\log(k) +\n\\log(|C|))$, where $k$ is the number of outgoing edges from a node and $|C|$ is\nthe size of the timetable information (total outgoing edges). Our solution\nsuits any other time-dependent networks and can be integrated into other\npathfinding algorithms. Our experiments indicate that this pre-computation\nsignificantly enhances the performance on high-density graphs. This study\nshowcases how leveraging computational geometry can enhance pathfinding in\ntransport networks, enabling faster pathfinding in scenarios involving large\nnumbers of outgoing edges.",
    "categories": [
      "cs.DS",
      "cs.AI",
      "cs.CG"
    ],
    "primary_category": "cs.DS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15715v2",
    "published_date": "2024-10-21 07:34:04 UTC",
    "updated_date": "2024-10-23 05:02:39 UTC"
  },
  {
    "arxiv_id": "2410.15714v3",
    "title": "Offline reinforcement learning for job-shop scheduling problems",
    "authors": [
      "Imanol Echeverria",
      "Maialen Murua",
      "Roberto Santana"
    ],
    "abstract": "Recent advances in deep learning have shown significant potential for solving\ncombinatorial optimization problems in real-time. Unlike traditional methods,\ndeep learning can generate high-quality solutions efficiently, which is crucial\nfor applications like routing and scheduling. However, existing approaches like\ndeep reinforcement learning (RL) and behavioral cloning have notable\nlimitations, with deep RL suffering from slow learning and behavioral cloning\nrelying solely on expert actions, which can lead to generalization issues and\nneglect of the optimization objective. This paper introduces a novel offline RL\nmethod designed for combinatorial optimization problems with complex\nconstraints, where the state is represented as a heterogeneous graph and the\naction space is variable. Our approach encodes actions in edge attributes and\nbalances expected rewards with the imitation of expert solutions. We\ndemonstrate the effectiveness of this method on job-shop scheduling and\nflexible job-shop scheduling benchmarks, achieving superior performance\ncompared to state-of-the-art techniques.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15714v3",
    "published_date": "2024-10-21 07:33:42 UTC",
    "updated_date": "2025-04-05 05:06:24 UTC"
  },
  {
    "arxiv_id": "2410.15700v1",
    "title": "InternLM2.5-StepProver: Advancing Automated Theorem Proving via Expert Iteration on Large-Scale LEAN Problems",
    "authors": [
      "Zijian Wu",
      "Suozhi Huang",
      "Zhejian Zhou",
      "Huaiyuan Ying",
      "Jiayu Wang",
      "Dahua Lin",
      "Kai Chen"
    ],
    "abstract": "Large Language Models (LLMs) have emerged as powerful tools in mathematical\ntheorem proving, particularly when utilizing formal languages such as LEAN. The\nmajor learning paradigm is expert iteration, which necessitates a pre-defined\ndataset comprising numerous mathematical problems. In this process, LLMs\nattempt to prove problems within the dataset and iteratively refine their\ncapabilities through self-training on the proofs they discover. We propose to\nuse large scale LEAN problem datasets Lean-workbook for expert iteration with\nmore than 20,000 CPU days. During expert iteration, we found log-linear trends\nbetween solved problem amount with proof length and CPU usage. We train a\ncritic model to select relatively easy problems for policy models to make\ntrials and guide the model to search for deeper proofs. InternLM2.5-StepProver\nachieves open-source state-of-the-art on MiniF2F, Lean-Workbook-Plus, ProofNet,\nand Putnam benchmarks. Specifically, it achieves a pass of 65.9% on the\nMiniF2F-test and proves (or disproves) 17.0% of problems in Lean-Workbook-Plus\nwhich shows a significant improvement compared to only 9.5% of problems proved\nwhen Lean-Workbook-Plus was released. We open-source our models and searched\nproofs at https://github.com/InternLM/InternLM-Math and\nhttps://huggingface.co/datasets/internlm/Lean-Workbook.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15700v1",
    "published_date": "2024-10-21 07:18:23 UTC",
    "updated_date": "2024-10-21 07:18:23 UTC"
  },
  {
    "arxiv_id": "2410.15694v1",
    "title": "PALMS: Plane-based Accessible Indoor Localization Using Mobile Smartphones",
    "authors": [
      "Yunqian Cheng",
      "Roberto Manduchi"
    ],
    "abstract": "In this paper, we present PALMS, an innovative indoor global localization and\nrelocalization system for mobile smartphones that utilizes publicly available\nfloor plans. Unlike most vision-based methods that require constant visual\ninput, our system adopts a dynamic form of localization that considers a single\ninstantaneous observation and odometry data. The core contribution of this work\nis the introduction of a particle filter initialization method that leverages\nthe Certainly Empty Space (CES) constraint along with principal orientation\nmatching. This approach creates a spatial probability distribution of the\ndevice's location, significantly improving localization accuracy and reducing\nparticle filter convergence time. Our experimental evaluations demonstrate that\nPALMS outperforms traditional methods with uniformly initialized particle\nfilters, providing a more efficient and accessible approach to indoor\nwayfinding. By eliminating the need for prior environmental fingerprinting,\nPALMS provides a scalable and practical approach to indoor navigation.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "I.2.9; I.2.10"
    ],
    "primary_category": "cs.RO",
    "comment": "7 pages, 3 figures, accepted to the 14th International Conference on\n  Indoor Positioning and Indoor Navigation (IPIN) 2024, Best Presentation Award",
    "pdf_url": "http://arxiv.org/pdf/2410.15694v1",
    "published_date": "2024-10-21 07:05:07 UTC",
    "updated_date": "2024-10-21 07:05:07 UTC"
  },
  {
    "arxiv_id": "2410.15693v1",
    "title": "Geographical Node Clustering and Grouping to Guarantee Data IIDness in Federated Learning",
    "authors": [
      "Minkwon Lee",
      "Hyoil Kim",
      "Changhee Joo"
    ],
    "abstract": "Federated learning (FL) is a decentralized AI mechanism suitable for a large\nnumber of devices like in smart IoT. A major challenge of FL is the non-IID\ndataset problem, originating from the heterogeneous data collected by FL\nparticipants, leading to performance deterioration of the trained global model.\nThere have been various attempts to rectify non-IID dataset, mostly focusing on\nmanipulating the collected data. This paper, however, proposes a novel approach\nto ensure data IIDness by properly clustering and grouping mobile IoT nodes\nexploiting their geographical characteristics, so that each FL group can\nachieve IID dataset. We first provide an experimental evidence for the\nindependence and identicalness features of IoT data according to the\ninter-device distance, and then propose Dynamic Clustering and Partial-Steady\nGrouping algorithms that partition FL participants to achieve near-IIDness in\ntheir dataset while considering device mobility. Our mechanism significantly\noutperforms benchmark grouping algorithms at least by 110 times in terms of the\njoint cost between the number of dropout devices and the evenness in per-group\ndevice count, with a mild increase in the number of groups only by up to 0.93\ngroups.",
    "categories": [
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.15693v1",
    "published_date": "2024-10-21 07:03:15 UTC",
    "updated_date": "2024-10-21 07:03:15 UTC"
  },
  {
    "arxiv_id": "2410.15686v1",
    "title": "NetSafe: Exploring the Topological Safety of Multi-agent Networks",
    "authors": [
      "Miao Yu",
      "Shilong Wang",
      "Guibin Zhang",
      "Junyuan Mao",
      "Chenlong Yin",
      "Qijiong Liu",
      "Qingsong Wen",
      "Kun Wang",
      "Yang Wang"
    ],
    "abstract": "Large language models (LLMs) have empowered nodes within multi-agent networks\nwith intelligence, showing growing applications in both academia and industry.\nHowever, how to prevent these networks from generating malicious information\nremains unexplored with previous research on single LLM's safety be challenging\nto transfer. In this paper, we focus on the safety of multi-agent networks from\na topological perspective, investigating which topological properties\ncontribute to safer networks. To this end, we propose a general framework,\nNetSafe along with an iterative RelCom interaction to unify existing diverse\nLLM-based agent frameworks, laying the foundation for generalized topological\nsafety research. We identify several critical phenomena when multi-agent\nnetworks are exposed to attacks involving misinformation, bias, and harmful\ninformation, termed as Agent Hallucination and Aggregation Safety. Furthermore,\nwe find that highly connected networks are more susceptible to the spread of\nadversarial attacks, with task performance in a Star Graph Topology decreasing\nby 29.7%. Besides, our proposed static metrics aligned more closely with\nreal-world dynamic evaluations than traditional graph-theoretic metrics,\nindicating that networks with greater average distances from attackers exhibit\nenhanced safety. In conclusion, our work introduces a new topological\nperspective on the safety of LLM-based multi-agent networks and discovers\nseveral unreported phenomena, paving the way for future research to explore the\nsafety of such networks.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15686v1",
    "published_date": "2024-10-21 06:54:27 UTC",
    "updated_date": "2024-10-21 06:54:27 UTC"
  },
  {
    "arxiv_id": "2410.15678v1",
    "title": "Revealing and Mitigating the Local Pattern Shortcuts of Mamba",
    "authors": [
      "Wangjie You",
      "Zecheng Tang",
      "Juntao Li",
      "Lili Yao",
      "Min Zhang"
    ],
    "abstract": "Large language models (LLMs) have advanced significantly due to the attention\nmechanism, but their quadratic complexity and linear memory demands limit their\nperformance on long-context tasks. Recently, researchers introduced Mamba, an\nadvanced model built upon State Space Models(SSMs) that offers linear\ncomplexity and constant memory. Although Mamba is reported to match or surpass\nthe performance of attention-based models, our analysis reveals a performance\ngap: Mamba excels in tasks that involve localized key information but faces\nchallenges with tasks that require handling distributed key information. Our\ncontrolled experiments suggest that this inconsistency arises from Mamba's\nreliance on local pattern shortcuts, which enable the model to remember local\nkey information within its limited memory but hinder its ability to retain more\ndispersed information. Therefore, we introduce a global selection module into\nthe Mamba model to address this issue. Experiments on both existing and\nproposed synthetic tasks, as well as real-world tasks, demonstrate the\neffectiveness of our method. Notably, with the introduction of only 4M extra\nparameters, our approach enables the Mamba model(130M) to achieve a significant\nimprovement on tasks with distributed information, increasing its performance\nfrom 0 to 80.54 points.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15678v1",
    "published_date": "2024-10-21 06:42:11 UTC",
    "updated_date": "2024-10-21 06:42:11 UTC"
  },
  {
    "arxiv_id": "2410.19840v1",
    "title": "GreenEye: Development of Real-Time Traffic Signal Recognition System for Visual Impairments",
    "authors": [
      "Danu Kim"
    ],
    "abstract": "Recognizing a traffic signal, determining if the signal is green or red, and\nfiguring out the time left to cross the crosswalk are significant challenges to\nvisually impaired people. Previous research has focused on recognizing only two\ntraffic signals, green and red lights, using machine learning techniques. The\nproposed method developed a GreenEye system that recognizes the traffic\nsignals' color and tells the time left for pedestrians to cross the crosswalk\nin real-time. GreenEye's first training showed the highest precision of 74.6%;\nfour classes reported 40% or lower recognition precision in this training\nsession. The data imbalance caused low precision; thus, extra labeling and\ndatabase formation were performed to stabilize the number of images between\ndifferent classes. After the stabilization, all 14 classes showed excelling\nprecision rate of 99.5%.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Published in Korea Software Congress (2023)",
    "pdf_url": "http://arxiv.org/pdf/2410.19840v1",
    "published_date": "2024-10-21 06:27:22 UTC",
    "updated_date": "2024-10-21 06:27:22 UTC"
  },
  {
    "arxiv_id": "2410.15669v1",
    "title": "Learning to Generate and Evaluate Fact-checking Explanations with Transformers",
    "authors": [
      "Darius Feher",
      "Abdullah Khered",
      "Hao Zhang",
      "Riza Batista-Navarro",
      "Viktor Schlegel"
    ],
    "abstract": "In an era increasingly dominated by digital platforms, the spread of\nmisinformation poses a significant challenge, highlighting the need for\nsolutions capable of assessing information veracity. Our research contributes\nto the field of Explainable Artificial Antelligence (XAI) by developing\ntransformer-based fact-checking models that contextualise and justify their\ndecisions by generating human-accessible explanations. Importantly, we also\ndevelop models for automatic evaluation of explanations for fact-checking\nverdicts across different dimensions such as \\texttt{(self)-contradiction},\n\\texttt{hallucination}, \\texttt{convincingness} and \\texttt{overall quality}.\nBy introducing human-centred evaluation methods and developing specialised\ndatasets, we emphasise the need for aligning Artificial Intelligence\n(AI)-generated explanations with human judgements. This approach not only\nadvances theoretical knowledge in XAI but also holds practical implications by\nenhancing the transparency, reliability and users' trust in AI-driven\nfact-checking systems. Furthermore, the development of our metric learning\nmodels is a first step towards potentially increasing efficiency and reducing\nreliance on extensive manual assessment. Based on experimental results, our\nbest performing generative model \\textsc{ROUGE-1} score of 47.77, demonstrating\nsuperior performance in generating fact-checking explanations, particularly\nwhen provided with high-quality evidence. Additionally, the best performing\nmetric learning model showed a moderately strong correlation with human\njudgements on objective dimensions such as \\texttt{(self)-contradiction and\n\\texttt{hallucination}, achieving a Matthews Correlation Coefficient (MCC) of\naround 0.7.}",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "Forthcoming in Engineering Applications of Artificial Intelligence",
    "pdf_url": "http://arxiv.org/pdf/2410.15669v1",
    "published_date": "2024-10-21 06:22:51 UTC",
    "updated_date": "2024-10-21 06:22:51 UTC"
  },
  {
    "arxiv_id": "2411.03321v3",
    "title": "Towards More Accurate US Presidential Election via Multi-step Reasoning with Large Language Models",
    "authors": [
      "Chenxiao Yu",
      "Zhaotian Weng",
      "Yuangang Li",
      "Zheng Li",
      "Xiyang Hu",
      "Yue Zhao"
    ],
    "abstract": "Can Large Language Models (LLMs) accurately predict election outcomes? While\nLLMs have demonstrated impressive performance in various domains, including\nhealthcare, legal analysis, and creative tasks, their ability to forecast\nelections remains unknown. Election prediction poses unique challenges, such as\nlimited voter-level data, rapidly changing political landscapes, and the need\nto model complex human behavior. To address these challenges, we introduce a\nmulti-step reasoning framework designed for political analysis. Our approach is\nvalidated on real-world data from the American National Election Studies (ANES)\n2016 and 2020, as well as synthetic personas generated by the leading machine\nlearning framework, offering scalable datasets for voter behavior modeling. To\ncapture temporal dynamics, we incorporate candidates' policy positions and\nbiographical details, ensuring that the model adapts to evolving political\ncontexts. Drawing on Chain of Thought prompting, our multi-step reasoning\npipeline systematically integrates demographic, ideological, and time-dependent\nfactors, enhancing the model's predictive power.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "This research is ongoing work. Xiyang Hu and Yue Zhao are the\n  corresponding authors",
    "pdf_url": "http://arxiv.org/pdf/2411.03321v3",
    "published_date": "2024-10-21 06:18:53 UTC",
    "updated_date": "2025-04-04 01:33:20 UTC"
  },
  {
    "arxiv_id": "2410.15667v1",
    "title": "RAC: Efficient LLM Factuality Correction with Retrieval Augmentation",
    "authors": [
      "Changmao Li",
      "Jeffrey Flanigan"
    ],
    "abstract": "Large Language Models (LLMs) exhibit impressive results across a wide range\nof natural language processing (NLP) tasks, yet they can often produce\nfactually incorrect outputs. This paper introduces a simple but effective\nlow-latency post-correction method, \\textbf{Retrieval Augmented Correction\n(RAC)}, aimed at enhancing the factual performance of LLMs without requiring\nadditional fine-tuning. Our method is general and can be used with any\ninstruction-tuned LLM, and has greatly reduced latency compared to prior\napproaches. RAC decomposes the LLM's output into atomic facts and applies a\nfine-grained verification and correction process with retrieved content to\nverify and correct the LLM-generated output. Our extensive experiments show\nthat RAC yields up to 30\\% improvements over state-of-the-art baselines across\ntwo popular factuality evaluation datasets, validating its efficacy and\nrobustness in both with and without the integration of Retrieval-Augmented\nGeneration (RAG) across different LLMs.\\footnote{Our code is at\n\\url{https://github.com/jlab-nlp/Retrieval-Augmented-Correction}}",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15667v1",
    "published_date": "2024-10-21 06:11:38 UTC",
    "updated_date": "2024-10-21 06:11:38 UTC"
  },
  {
    "arxiv_id": "2410.15665v4",
    "title": "Long Term Memory: The Foundation of AI Self-Evolution",
    "authors": [
      "Xun Jiang",
      "Feng Li",
      "Han Zhao",
      "Jiahao Qiu",
      "Jiaying Wang",
      "Jun Shao",
      "Shihao Xu",
      "Shu Zhang",
      "Weiling Chen",
      "Xavier Tang",
      "Yize Chen",
      "Mengyue Wu",
      "Weizhi Ma",
      "Mengdi Wang",
      "Tianqiao Chen"
    ],
    "abstract": "Large language models (LLMs) like GPTs, trained on vast datasets, have\ndemonstrated impressive capabilities in language understanding, reasoning, and\nplanning, achieving human-level performance in various tasks. Most studies\nfocus on enhancing these models by training on ever-larger datasets to build\nmore powerful foundation models. While training stronger models is important,\nenabling models to evolve during inference is equally crucial, a process we\nrefer to as AI self-evolution. Unlike large-scale training, self-evolution may\nrely on limited data or interactions. Inspired by the columnar organization of\nthe human cerebral cortex, we hypothesize that AI models could develop\ncognitive abilities and build internal representations through iterative\ninteractions with their environment. To achieve this, models need long-term\nmemory (LTM) to store and manage processed interaction data. LTM supports\nself-evolution by representing diverse experiences across environments and\nagents. In this report, we explore AI self-evolution and its potential to\nenhance models during inference. We examine LTM's role in lifelong learning,\nallowing models to evolve based on accumulated interactions. We outline the\nstructure of LTM and the systems needed for effective data retention and\nrepresentation. We also classify approaches for building personalized models\nwith LTM data and show how these models achieve self-evolution through\ninteraction. Using LTM, our multi-agent framework OMNE achieved first place on\nthe GAIA benchmark, demonstrating LTM's potential for AI self-evolution.\nFinally, we present a roadmap for future research, emphasizing the importance\nof LTM for advancing AI technology and its practical applications.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "56 pages, 13 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.15665v4",
    "published_date": "2024-10-21 06:09:30 UTC",
    "updated_date": "2025-05-11 07:56:18 UTC"
  },
  {
    "arxiv_id": "2410.15656v1",
    "title": "LightFusionRec: Lightweight Transformers-Based Cross-Domain Recommendation Model",
    "authors": [
      "Vansh Kharidia",
      "Dhruvi Paprunia",
      "Prashasti Kanikar"
    ],
    "abstract": "This paper presents LightFusionRec, a novel lightweight cross-domain\nrecommendation system that integrates DistilBERT for textual feature extraction\nand FastText for genre embedding. Important issues in recommendation systems,\nsuch as data sparsity, computational efficiency, and cold start issues, are\naddressed in methodology. LightFusionRec uses a small amount of information to\nproduce precise and contextually relevant recommendations for many media\nformats by fusing genre vector embedding with natural language processing\nalgorithms. Tests conducted on extensive movie and book datasets show notable\nenhancements in suggestion quality when compared to conventional methods.\nBecause of its lightweight design, the model can be used for a variety of\npurposes and allows for ondevice inference. LightFusionRec is a noteworthy\ndevelopment in cross-domain recommendation systems, providing accurate and\nscalable recommendations to improve user experience on digital content\nplatforms.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15656v1",
    "published_date": "2024-10-21 05:49:40 UTC",
    "updated_date": "2024-10-21 05:49:40 UTC"
  },
  {
    "arxiv_id": "2410.15653v4",
    "title": "Opportunities and Challenges of Generative-AI in Finance",
    "authors": [
      "Akshar Prabhu Desai",
      "Ganesh Satish Mallya",
      "Mohammad Luqman",
      "Tejasvi Ravi",
      "Nithya Kota",
      "Pranjul Yadav"
    ],
    "abstract": "Gen-AI techniques are able to improve understanding of context and nuances in\nlanguage modeling, translation between languages, handle large volumes of data,\nprovide fast, low-latency responses and can be fine-tuned for various tasks and\ndomains. In this manuscript, we present a comprehensive overview of the\napplications of Gen-AI techniques in the finance domain. In particular, we\npresent the opportunities and challenges associated with the usage of Gen-AI\ntechniques. We also illustrate the various methodologies which can be used to\ntrain Gen-AI techniques and present the various application areas of Gen-AI\ntechnologies in the finance ecosystem. To the best of our knowledge, this work\nrepresents the most comprehensive summarization of Gen-AI techniques within the\nfinancial domain. The analysis is designed for a deep overview of areas marked\nfor substantial advancement while simultaneously pin-point those warranting\nfuture prioritization. We also hope that this work would serve as a conduit\nbetween finance and other domains, thus fostering the cross-pollination of\ninnovative concepts and practices.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "https://ieeexplore.ieee.org/document/10825658",
    "pdf_url": "http://arxiv.org/pdf/2410.15653v4",
    "published_date": "2024-10-21 05:30:39 UTC",
    "updated_date": "2025-02-08 00:43:32 UTC"
  },
  {
    "arxiv_id": "2410.15650v1",
    "title": "Voice-Enabled AI Agents can Perform Common Scams",
    "authors": [
      "Richard Fang",
      "Dylan Bowman",
      "Daniel Kang"
    ],
    "abstract": "Recent advances in multi-modal, highly capable LLMs have enabled\nvoice-enabled AI agents. These agents are enabling new applications, such as\nvoice-enabled autonomous customer service. However, with all AI capabilities,\nthese new capabilities have the potential for dual use.\n  In this work, we show that voice-enabled AI agents can perform the actions\nnecessary to perform common scams. To do so, we select a list of common scams\ncollected by the government and construct voice-enabled agents with directions\nto perform these scams. We conduct experiments on our voice-enabled agents and\nshow that they can indeed perform the actions necessary to autonomously perform\nsuch scams. Our results raise questions around the widespread deployment of\nvoice-enabled AI agents.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15650v1",
    "published_date": "2024-10-21 05:22:54 UTC",
    "updated_date": "2024-10-21 05:22:54 UTC"
  },
  {
    "arxiv_id": "2410.15645v2",
    "title": "Boosting Jailbreak Transferability for Large Language Models",
    "authors": [
      "Hanqing Liu",
      "Lifeng Zhou",
      "Huanqian Yan"
    ],
    "abstract": "Large language models have drawn significant attention to the challenge of\nsafe alignment, especially regarding jailbreak attacks that circumvent security\nmeasures to produce harmful content. To address the limitations of existing\nmethods like GCG, which perform well in single-model attacks but lack\ntransferability, we propose several enhancements, including a scenario\ninduction template, optimized suffix selection, and the integration of\nre-suffix attack mechanism to reduce inconsistent outputs. Our approach has\nshown superior performance in extensive experiments across various benchmarks,\nachieving nearly 100% success rates in both attack execution and\ntransferability. Notably, our method has won the first place in the AISG-hosted\nGlobal Challenge for Safe and Secure LLMs. The code is released at\nhttps://github.com/HqingLiu/SI-GCG.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15645v2",
    "published_date": "2024-10-21 05:11:19 UTC",
    "updated_date": "2024-11-03 12:22:30 UTC"
  },
  {
    "arxiv_id": "2410.15644v1",
    "title": "Procedural Content Generation in Games: A Survey with Insights on Emerging LLM Integration",
    "authors": [
      "Mahdi Farrokhi Maleki",
      "Richard Zhao"
    ],
    "abstract": "Procedural Content Generation (PCG) is defined as the automatic creation of\ngame content using algorithms. PCG has a long history in both the game industry\nand the academic world. It can increase player engagement and ease the work of\ngame designers. While recent advances in deep learning approaches in PCG have\nenabled researchers and practitioners to create more sophisticated content, it\nis the arrival of Large Language Models (LLMs) that truly disrupted the\ntrajectory of PCG advancement.\n  This survey explores the differences between various algorithms used for PCG,\nincluding search-based methods, machine learning-based methods, other\nfrequently used methods (e.g., noise functions), and the newcomer, LLMs. We\nalso provide a detailed discussion on combined methods. Furthermore, we compare\nthese methods based on the type of content they generate and the publication\ndates of their respective papers. Finally, we identify gaps in the existing\nacademic work and suggest possible directions for future research.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15644v1",
    "published_date": "2024-10-21 05:10:13 UTC",
    "updated_date": "2024-10-21 05:10:13 UTC"
  },
  {
    "arxiv_id": "2410.15642v1",
    "title": "Resource-Efficient Medical Report Generation using Large Language Models",
    "authors": [
      "Abdullah",
      "Ameer Hamza",
      "Seong Tae Kim"
    ],
    "abstract": "Medical report generation is the task of automatically writing radiology\nreports for chest X-ray images. Manually composing these reports is a\ntime-consuming process that is also prone to human errors. Generating medical\nreports can therefore help reduce the burden on radiologists. In other words,\nwe can promote greater clinical automation in the medical domain. In this work,\nwe propose a new framework leveraging vision-enabled Large Language Models\n(LLM) for the task of medical report generation. We introduce a lightweight\nsolution that achieves better or comparative performance as compared to\nprevious solutions on the task of medical report generation. We conduct\nextensive experiments exploring different model sizes and enhancement\napproaches, such as prefix tuning to improve the text generation abilities of\nthe LLMs. We evaluate our approach on a prominent large-scale radiology report\ndataset - MIMIC-CXR. Our results demonstrate the capability of our\nresource-efficient framework to generate patient-specific reports with strong\nmedical contextual understanding and high precision.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15642v1",
    "published_date": "2024-10-21 05:08:18 UTC",
    "updated_date": "2024-10-21 05:08:18 UTC"
  },
  {
    "arxiv_id": "2410.15633v4",
    "title": "GATEAU: Selecting Influential Samples for Long Context Alignment",
    "authors": [
      "Shuzheng Si",
      "Haozhe Zhao",
      "Gang Chen",
      "Yunshui Li",
      "Kangyang Luo",
      "Chuancheng Lv",
      "Kaikai An",
      "Fanchao Qi",
      "Baobao Chang",
      "Maosong Sun"
    ],
    "abstract": "Aligning large language models to handle instructions with extremely long\ncontexts has yet to be fully investigated. Previous studies attempt to scale up\nthe available data volume by synthesizing long instruction-following samples,\nas constructing such a dataset tends to be challenging for annotators. However,\na lack of a well-defined strategy for ensuring data quality may introduce\nlow-quality samples and restrict the model performance. Thus, we propose\nGATEAU, a novel framework to address the unique challenge of long context\nalignment by identifying the influential samples enriched with long-range\ndependency relations. Specifically, GATEAU measures the long-range dependencies\nfrom two essential aspects: the difficulty of generating target responses due\nto the long-range dependencies, and the difficulty of understanding long inputs\ndue to such dependencies. Comprehensive experiments indicate that GATEAU\neffectively identifies influential samples and the model trained on these\nselected samples exhibits better instruction-following and long-context\nunderstanding capabilities.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15633v4",
    "published_date": "2024-10-21 04:30:53 UTC",
    "updated_date": "2025-02-12 03:32:34 UTC"
  },
  {
    "arxiv_id": "2410.15628v3",
    "title": "Towards Kriging-informed Conditional Diffusion for Regional Sea-Level Data Downscaling",
    "authors": [
      "Subhankar Ghosh",
      "Arun Sharma",
      "Jayant Gupta",
      "Aneesh Subramanian",
      "Shashi Shekhar"
    ],
    "abstract": "Given coarser-resolution projections from global climate models or satellite\ndata, the downscaling problem aims to estimate finer-resolution regional\nclimate data, capturing fine-scale spatial patterns and variability.\nDownscaling is any method to derive high-resolution data from low-resolution\nvariables, often to provide more detailed and local predictions and analyses.\nThis problem is societally crucial for effective adaptation, mitigation, and\nresilience against significant risks from climate change. The challenge arises\nfrom spatial heterogeneity and the need to recover finer-scale features while\nensuring model generalization. Most downscaling methods \\cite{Li2020} fail to\ncapture the spatial dependencies at finer scales and underperform on real-world\nclimate datasets, such as sea-level rise. We propose a novel Kriging-informed\nConditional Diffusion Probabilistic Model (Ki-CDPM) to capture spatial\nvariability while preserving fine-scale features. Experimental results on\nclimate data show that our proposed method is more accurate than\nstate-of-the-art downscaling techniques.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15628v3",
    "published_date": "2024-10-21 04:24:10 UTC",
    "updated_date": "2025-01-27 09:09:28 UTC"
  },
  {
    "arxiv_id": "2410.15625v2",
    "title": "Improving Parallel Program Performance with LLM Optimizers via Agent-System Interface",
    "authors": [
      "Anjiang Wei",
      "Allen Nie",
      "Thiago S. F. X. Teixeira",
      "Rohan Yadav",
      "Wonchan Lee",
      "Ke Wang",
      "Alex Aiken"
    ],
    "abstract": "Modern scientific discovery increasingly relies on high-performance computing\nfor complex modeling and simulation. A key challenge in improving parallel\nprogram performance is efficiently mapping tasks to processors and data to\nmemory, a process dictated by intricate, low-level system code known as\nmappers. Developing high-performance mappers demands days of manual tuning,\nposing a significant barrier for domain scientists without systems expertise.\nWe introduce a framework that automates mapper development with generative\noptimization, leveraging richer feedback beyond scalar performance metrics. Our\napproach features the Agent-System Interface, which includes a Domain-Specific\nLanguage (DSL) to abstract away low-level complexity of system code and define\na structured search space, as well as AutoGuide, a mechanism that interprets\nraw execution output into actionable feedback. Unlike traditional reinforcement\nlearning methods such as OpenTuner, which rely solely on scalar feedback, our\nmethod finds superior mappers in far fewer iterations. With just 10 iterations,\nit outperforms OpenTuner even after 1000 iterations, achieving 3.8X faster\nperformance. Our approach finds mappers that surpass expert-written mappers by\nup to 1.34X speedup across nine benchmarks while reducing tuning time from days\nto minutes.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15625v2",
    "published_date": "2024-10-21 04:08:37 UTC",
    "updated_date": "2025-01-31 06:36:22 UTC"
  },
  {
    "arxiv_id": "2410.15616v1",
    "title": "Weighted Diversified Sampling for Efficient Data-Driven Single-Cell Gene-Gene Interaction Discovery",
    "authors": [
      "Yifan Wu",
      "Yuntao Yang",
      "Zirui Liu",
      "Zhao Li",
      "Khushbu Pahwa",
      "Rongbin Li",
      "Wenjin Zheng",
      "Xia Hu",
      "Zhaozhuo Xu"
    ],
    "abstract": "Gene-gene interactions play a crucial role in the manifestation of complex\nhuman diseases. Uncovering significant gene-gene interactions is a challenging\ntask. Here, we present an innovative approach utilizing data-driven\ncomputational tools, leveraging an advanced Transformer model, to unearth\nnoteworthy gene-gene interactions. Despite the efficacy of Transformer models,\ntheir parameter intensity presents a bottleneck in data ingestion, hindering\ndata efficiency. To mitigate this, we introduce a novel weighted diversified\nsampling algorithm. This algorithm computes the diversity score of each data\nsample in just two passes of the dataset, facilitating efficient subset\ngeneration for interaction discovery. Our extensive experimentation\ndemonstrates that by sampling a mere 1\\% of the single-cell dataset, we achieve\nperformance comparable to that of utilizing the entire dataset.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15616v1",
    "published_date": "2024-10-21 03:35:23 UTC",
    "updated_date": "2024-10-21 03:35:23 UTC"
  },
  {
    "arxiv_id": "2410.15607v1",
    "title": "Reinforced Imitative Trajectory Planning for Urban Automated Driving",
    "authors": [
      "Di Zeng",
      "Ling Zheng",
      "Xiantong Yang",
      "Yinong Li"
    ],
    "abstract": "Reinforcement learning (RL) faces challenges in trajectory planning for urban\nautomated driving due to the poor convergence of RL and the difficulty in\ndesigning reward functions. The convergence problem is alleviated by combining\nRL with supervised learning. However, most existing approaches only reason one\nstep ahead and lack the capability to plan for multiple future steps. Besides,\nalthough inverse reinforcement learning holds promise for solving the reward\nfunction design issue, existing methods for automated driving impose a linear\nstructure assumption on reward functions, making them difficult to apply to\nurban automated driving. In light of these challenges, this paper proposes a\nnovel RL-based trajectory planning method that integrates RL with imitation\nlearning to enable multi-step planning. Furthermore, a transformer-based\nBayesian reward function is developed, providing effective reward signals for\nRL in urban scenarios. Moreover, a hybrid-driven trajectory planning framework\nis proposed to enhance safety and interpretability. The proposed methods were\nvalidated on the large-scale real-world urban automated driving nuPlan dataset.\nThe results demonstrated the significant superiority of the proposed methods\nover the baselines in terms of the closed-loop metrics. The code is available\nat https://github.com/Zigned/nuplan_zigned.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "19 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.15607v1",
    "published_date": "2024-10-21 03:04:29 UTC",
    "updated_date": "2024-10-21 03:04:29 UTC"
  },
  {
    "arxiv_id": "2410.15605v1",
    "title": "Deep Active Learning with Manifold-preserving Trajectory Sampling",
    "authors": [
      "Yingrui Ji",
      "Vijaya Sindhoori Kaza",
      "Nishanth Artham",
      "Tianyang Wang"
    ],
    "abstract": "Active learning (AL) is for optimizing the selection of unlabeled data for\nannotation (labeling), aiming to enhance model performance while minimizing\nlabeling effort. The key question in AL is which unlabeled data should be\nselected for annotation. Existing deep AL methods arguably suffer from bias\nincurred by clabeled data, which takes a much lower percentage than unlabeled\ndata in AL context. We observe that such an issue is severe in different types\nof data, such as vision and non-vision data. To address this issue, we propose\na novel method, namely Manifold-Preserving Trajectory Sampling (MPTS), aiming\nto enforce the feature space learned from labeled data to represent a more\naccurate manifold. By doing so, we expect to effectively correct the bias\nincurred by labeled data, which can cause a biased selection of unlabeled data.\nDespite its focus on manifold, the proposed method can be conveniently\nimplemented by performing distribution mapping with MMD (Maximum Mean\nDiscrepancies). Extensive experiments on various vision and non-vision\nbenchmark datasets demonstrate the superiority of our method. Our source code\ncan be found here.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15605v1",
    "published_date": "2024-10-21 03:04:09 UTC",
    "updated_date": "2024-10-21 03:04:09 UTC"
  },
  {
    "arxiv_id": "2410.15602v1",
    "title": "P-YOLOv8: Efficient and Accurate Real-Time Detection of Distracted Driving",
    "authors": [
      "Mohamed R. Elshamy",
      "Heba M. Emara",
      "Mohamed R. Shoaib",
      "Abdel-Hameed A. Badawy"
    ],
    "abstract": "Distracted driving is a critical safety issue that leads to numerous\nfatalities and injuries worldwide. This study addresses the urgent need for\nefficient and real-time machine learning models to detect distracted driving\nbehaviors. Leveraging the Pretrained YOLOv8 (P-YOLOv8) model, a real-time\nobject detection system is introduced, optimized for both speed and accuracy.\nThis approach addresses the computational constraints and latency limitations\ncommonly associated with conventional detection models. The study demonstrates\nP-YOLOv8 versatility in both object detection and image classification tasks\nusing the Distracted Driver Detection dataset from State Farm, which includes\n22,424 images across ten behavior categories. Our research explores the\napplication of P-YOLOv8 for image classification, evaluating its performance\ncompared to deep learning models such as VGG16, VGG19, and ResNet. Some\ntraditional models often struggle with low accuracy, while others achieve high\naccuracy but come with high computational costs and slow detection speeds,\nmaking them unsuitable for real-time applications. P-YOLOv8 addresses these\nissues by achieving competitive accuracy with significant computational cost\nand efficiency advantages. In particular, P-YOLOv8 generates a lightweight\nmodel with a size of only 2.84 MB and a lower number of parameters, totaling\n1,451,098, due to its innovative architecture. It achieves a high accuracy of\n99.46 percent with this small model size, opening new directions for deployment\non inexpensive and small embedded devices using Tiny Machine Learning (TinyML).\nThe experimental results show robust performance, making P-YOLOv8 a\ncost-effective solution for real-time deployment. This study provides a\ndetailed analysis of P-YOLOv8's architecture, training, and performance\nbenchmarks, highlighting its potential for real-time use in detecting\ndistracted driving.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15602v1",
    "published_date": "2024-10-21 02:56:44 UTC",
    "updated_date": "2024-10-21 02:56:44 UTC"
  },
  {
    "arxiv_id": "2410.15600v1",
    "title": "Patrol Security Game: Defending Against Adversary with Freedom in Attack Timing, Location, and Duration",
    "authors": [
      "Hao-Tsung Yang",
      "Ting-Kai Weng",
      "Ting-Yu Chang",
      "Kin Sum Liu",
      "Shan Lin",
      "Jie Gao",
      "Shih-Yu Tsai"
    ],
    "abstract": "We explored the Patrol Security Game (PSG), a robotic patrolling problem\nmodeled as an extensive-form Stackelberg game, where the attacker determines\nthe timing, location, and duration of their attack. Our objective is to devise\na patrolling schedule with an infinite time horizon that minimizes the\nattacker's payoff. We demonstrated that PSG can be transformed into a\ncombinatorial minimax problem with a closed-form objective function. By\nconstraining the defender's strategy to a time-homogeneous first-order Markov\nchain (i.e., the patroller's next move depends solely on their current\nlocation), we proved that the optimal solution in cases of zero penalty\ninvolves either minimizing the expected hitting time or return time, depending\non the attacker model, and that these solutions can be computed efficiently.\nAdditionally, we observed that increasing the randomness in the patrol schedule\nreduces the attacker's expected payoff in high-penalty cases. However, the\nminimax problem becomes non-convex in other scenarios. To address this, we\nformulated a bi-criteria optimization problem incorporating two objectives:\nexpected maximum reward and entropy. We proposed three graph-based algorithms\nand one deep reinforcement learning model, designed to efficiently balance the\ntrade-off between these two objectives. Notably, the third algorithm can\nidentify the optimal deterministic patrol schedule, though its runtime grows\nexponentially with the number of patrol spots. Experimental results validate\nthe effectiveness and scalability of our solutions, demonstrating that our\napproaches outperform state-of-the-art baselines on both synthetic and\nreal-world crime datasets.",
    "categories": [
      "cs.AI",
      "cs.GT",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "Under review of TCPS",
    "pdf_url": "http://arxiv.org/pdf/2410.15600v1",
    "published_date": "2024-10-21 02:53:18 UTC",
    "updated_date": "2024-10-21 02:53:18 UTC"
  },
  {
    "arxiv_id": "2410.15597v1",
    "title": "A Comprehensive Comparative Study of Individual ML Models and Ensemble Strategies for Network Intrusion Detection Systems",
    "authors": [
      "Ismail Bibers",
      "Osvaldo Arreche",
      "Mustafa Abdallah"
    ],
    "abstract": "The escalating frequency of intrusions in networked systems has spurred the\nexploration of new research avenues in devising artificial intelligence (AI)\ntechniques for intrusion detection systems (IDS). Various AI techniques have\nbeen used to automate network intrusion detection tasks, yet each model\npossesses distinct strengths and weaknesses. Selecting the optimal model for a\ngiven dataset can pose a challenge, necessitating the exploration of ensemble\nmethods to enhance generalization and applicability in network intrusion\ndetection. This paper addresses this gap by conducting a comprehensive\nevaluation of diverse individual models and both simple and advanced ensemble\nmethods for network IDS. We introduce an ensemble learning framework tailored\nfor assessing individual models and ensemble methods in network intrusion\ndetection tasks. Our framework encompasses the loading of input datasets,\ntraining of individual models and ensemble methods, and the generation of\nevaluation metrics. Furthermore, we incorporate all features across individual\nmodels and ensemble techniques. The study presents results for our framework,\nencompassing 14 methods, including various bagging, stacking, blending, and\nboosting techniques applied to multiple base learners such as decision trees,\nneural networks, and among others. We evaluate the framework using two distinct\nnetwork intrusion datasets, RoEduNet-SIMARGL2021 and CICIDS-2017, each\npossessing unique characteristics. Additionally, we categorize AI models based\non their performances on our evaluation metrics and via their confusion\nmatrices. Our assessment demonstrates the efficacy of learning across most\nsetups explored in this study. Furthermore, we contribute to the community by\nreleasing our source codes, providing a foundational ensemble learning\nframework for network intrusion detection.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15597v1",
    "published_date": "2024-10-21 02:44:58 UTC",
    "updated_date": "2024-10-21 02:44:58 UTC"
  },
  {
    "arxiv_id": "2410.19003v2",
    "title": "Whither Bias Goes, I Will Go: An Integrative, Systematic Review of Algorithmic Bias Mitigation",
    "authors": [
      "Louis Hickman",
      "Christopher Huynh",
      "Jessica Gass",
      "Brandon Booth",
      "Jason Kuruzovich",
      "Louis Tay"
    ],
    "abstract": "Machine learning (ML) models are increasingly used for personnel assessment\nand selection (e.g., resume screeners, automatically scored interviews).\nHowever, concerns have been raised throughout society that ML assessments may\nbe biased and perpetuate or exacerbate inequality. Although organizational\nresearchers have begun investigating ML assessments from traditional\npsychometric and legal perspectives, there is a need to understand, clarify,\nand integrate fairness operationalizations and algorithmic bias mitigation\nmethods from the computer science, data science, and organizational research\nliteratures. We present a four-stage model of developing ML assessments and\napplying bias mitigation methods, including 1) generating the training data, 2)\ntraining the model, 3) testing the model, and 4) deploying the model. When\nintroducing the four-stage model, we describe potential sources of bias and\nunfairness at each stage. Then, we systematically review definitions and\noperationalizations of algorithmic bias, legal requirements governing personnel\nselection from the United States and Europe, and research on algorithmic bias\nmitigation across multiple domains and integrate these findings into our\nframework. Our review provides insights for both research and practice by\nelucidating possible mechanisms of algorithmic bias while identifying which\nbias mitigation methods are legal and effective. This integrative framework\nalso reveals gaps in the knowledge of algorithmic bias mitigation that should\nbe addressed by future collaborative research between organizational\nresearchers, computer scientists, and data scientists. We provide\nrecommendations for developing and deploying ML assessments, as well as\nrecommendations for future research into algorithmic bias and fairness.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "forthcoming in Journal of Applied Psychology",
    "pdf_url": "http://arxiv.org/pdf/2410.19003v2",
    "published_date": "2024-10-21 02:32:14 UTC",
    "updated_date": "2024-10-31 15:06:44 UTC"
  },
  {
    "arxiv_id": "2410.15595v2",
    "title": "A Comprehensive Survey of Direct Preference Optimization: Datasets, Theories, Variants, and Applications",
    "authors": [
      "Wenyi Xiao",
      "Zechuan Wang",
      "Leilei Gan",
      "Shuai Zhao",
      "Wanggui He",
      "Luu Anh Tuan",
      "Long Chen",
      "Hao Jiang",
      "Zhou Zhao",
      "Fei Wu"
    ],
    "abstract": "With the rapid advancement of large language models (LLMs), aligning policy\nmodels with human preferences has become increasingly critical. Direct\nPreference Optimization (DPO) has emerged as a promising approach for\nalignment, acting as an RL-free alternative to Reinforcement Learning from\nHuman Feedback (RLHF). Despite DPO's various advancements and inherent\nlimitations, an in-depth review of these aspects is currently lacking in the\nliterature. In this work, we present a comprehensive review of the challenges\nand opportunities in DPO, covering theoretical analyses, variants, relevant\npreference datasets, and applications. Specifically, we categorize recent\nstudies on DPO based on key research questions to provide a thorough\nunderstanding of DPO's current landscape. Additionally, we propose several\nfuture research directions to offer insights on model alignment for the\nresearch community.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15595v2",
    "published_date": "2024-10-21 02:27:24 UTC",
    "updated_date": "2024-11-10 13:46:15 UTC"
  },
  {
    "arxiv_id": "2410.15591v1",
    "title": "AMPLE: Emotion-Aware Multimodal Fusion Prompt Learning for Fake News Detection",
    "authors": [
      "Xiaoman Xu",
      "Xiangrun Li",
      "Taihang Wang",
      "Ye Jiang"
    ],
    "abstract": "Detecting fake news in large datasets is challenging due to its diversity and\ncomplexity, with traditional approaches often focusing on textual features\nwhile underutilizing semantic and emotional elements. Current methods also rely\nheavily on large annotated datasets, limiting their effectiveness in more\nnuanced analysis. To address these challenges, this paper introduces\nEmotion-\\textbf{A}ware \\textbf{M}ultimodal Fusion \\textbf{P}rompt\n\\textbf{L}\\textbf{E}arning (\\textbf{AMPLE}) framework to address the above\nissue by combining text sentiment analysis with multimodal data and hybrid\nprompt templates. This framework extracts emotional elements from texts by\nleveraging sentiment analysis tools. It then employs Multi-Head Cross-Attention\n(MCA) mechanisms and similarity-aware fusion methods to integrate multimodal\ndata. The proposed AMPLE framework demonstrates strong performance on two\npublic datasets in both few-shot and data-rich settings, with results\nindicating the potential of emotional aspects in fake news detection.\nFurthermore, the study explores the impact of integrating large language models\nwith this method for text sentiment extraction, revealing substantial room for\nfurther improvement. The code can be found at\n:\\url{https://github.com/xxm1215/MMM2025_few-shot/",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15591v1",
    "published_date": "2024-10-21 02:19:24 UTC",
    "updated_date": "2024-10-21 02:19:24 UTC"
  },
  {
    "arxiv_id": "2410.15573v3",
    "title": "OpenMU: Your Swiss Army Knife for Music Understanding",
    "authors": [
      "Mengjie Zhao",
      "Zhi Zhong",
      "Zhuoyuan Mao",
      "Shiqi Yang",
      "Wei-Hsiang Liao",
      "Shusuke Takahashi",
      "Hiromi Wakaki",
      "Yuki Mitsufuji"
    ],
    "abstract": "We present OpenMU-Bench, a large-scale benchmark suite for addressing the\ndata scarcity issue in training multimodal language models to understand music.\nTo construct OpenMU-Bench, we leveraged existing datasets and bootstrapped new\nannotations. OpenMU-Bench also broadens the scope of music understanding by\nincluding lyrics understanding and music tool usage. Using OpenMU-Bench, we\ntrained our music understanding model, OpenMU, with extensive ablations,\ndemonstrating that OpenMU outperforms baseline models such as MU-Llama. Both\nOpenMU and OpenMU-Bench are open-sourced to facilitate future research in music\nunderstanding and to enhance creative music production efficiency.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Resources: https://github.com/sony/openmu",
    "pdf_url": "http://arxiv.org/pdf/2410.15573v3",
    "published_date": "2024-10-21 01:36:42 UTC",
    "updated_date": "2024-11-27 05:43:19 UTC"
  },
  {
    "arxiv_id": "2410.15572v1",
    "title": "Leveraging Retrieval-Augmented Generation for Culturally Inclusive Hakka Chatbots: Design Insights and User Perceptions",
    "authors": [
      "Chen-Chi Chang",
      "Han-Pi Chang",
      "Hung-Shin Lee"
    ],
    "abstract": "In an era where cultural preservation is increasingly intertwined with\ntechnological innovation, this study introduces a groundbreaking approach to\npromoting and safeguarding the rich heritage of Taiwanese Hakka culture through\nthe development of a Retrieval-Augmented Generation (RAG)-enhanced chatbot.\nTraditional large language models (LLMs), while powerful, often fall short in\ndelivering accurate and contextually rich responses, particularly in culturally\nspecific domains. By integrating external databases with generative AI models,\nRAG technology bridges this gap, empowering chatbots to not only provide\nprecise answers but also resonate deeply with the cultural nuances that are\ncrucial for authentic interactions. This study delves into the intricate\nprocess of augmenting the chatbot's knowledge base with targeted cultural data,\nspecifically curated to reflect the unique aspects of Hakka traditions,\nlanguage, and practices. Through dynamic information retrieval, the\nRAG-enhanced chatbot becomes a versatile tool capable of handling complex\ninquiries that demand an in-depth understanding of Hakka cultural context. This\nis particularly significant in an age where digital platforms often dilute\ncultural identities, making the role of culturally aware AI systems more\ncritical than ever. System usability studies conducted as part of our research\nreveal a marked improvement in both user satisfaction and engagement,\nhighlighting the chatbot's effectiveness in fostering a deeper connection with\nHakka culture. The feedback underscores the potential of RAG technology to not\nonly enhance user experience but also to serve as a vital instrument in the\nbroader mission of ethnic mainstreaming and cultural celebration.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to IEEE RASSE 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.15572v1",
    "published_date": "2024-10-21 01:36:08 UTC",
    "updated_date": "2024-10-21 01:36:08 UTC"
  },
  {
    "arxiv_id": "2410.15570v1",
    "title": "Stacking Small Language Models for Generalizability",
    "authors": [
      "Laurence Liang"
    ],
    "abstract": "Recent advances show that large language models (LLMs) generalize strong\nperformance across different natural language benchmarks. However, the large\nsize of LLMs makes training and inference expensive and impractical to run in\nresource-limited settings. This paper introduces a new approach called\nfine-tuning stacks of language models (FSLM), which involves stacking small\nlanguage models (SLM) as an alternative to LLMs. By fine-tuning each SLM to\nperform a specific task, this approach breaks down high level reasoning into\nmultiple lower-level steps that specific SLMs are responsible for. As a result,\nFSLM allows for lower training and inference costs, and also improves model\ninterpretability as each SLM communicates with the subsequent one through\nnatural language. By evaluating FSLM on common natural language benchmarks,\nthis paper highlights promising early results toward generalizable performance\nusing FSLM as a cost-effective alternative to LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15570v1",
    "published_date": "2024-10-21 01:27:29 UTC",
    "updated_date": "2024-10-21 01:27:29 UTC"
  },
  {
    "arxiv_id": "2410.15567v1",
    "title": "Pruning Foundation Models for High Accuracy without Retraining",
    "authors": [
      "Pu Zhao",
      "Fei Sun",
      "Xuan Shen",
      "Pinrui Yu",
      "Zhenglun Kong",
      "Yanzhi Wang",
      "Xue Lin"
    ],
    "abstract": "Despite the superior performance, it is challenging to deploy foundation\nmodels or large language models (LLMs) due to their massive parameters and\ncomputations. While pruning is a promising technique to reduce model size and\naccelerate the inference, the traditional pruning techniques can hardly be\napplied for LLMs as they need to finetune the model on the full dataset with\nmultiple epochs consuming massive data and hardware resources. To deal with\nthis problem, post-training pruning methods are proposed to prune LLMs in\none-shot without retraining. However, their accuracy after pruning may suffer\nfrom certain performance degradation due to the lack of retraining with massive\ndata. To address this issue, in this paper, we first formulate the\npost-training problem for layer-wise LLM compression to simultaneously prune\nmultiple weights in LLMs. Next, we provide an optimal solution for this problem\nand design our post-training pruning algorithm for both unstructured and\nsemi-structured sparsity. Our extensive experiments demonstrate the superior\nperformance of the proposed methods in comparison to SOTA baselines across\nvarious LLM families including transformer-based LLMs and Mamba-based LLMs.\nCode link: https://github.com/piuzha/APT",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by EMNLP 2024 findings",
    "pdf_url": "http://arxiv.org/pdf/2410.15567v1",
    "published_date": "2024-10-21 01:23:34 UTC",
    "updated_date": "2024-10-21 01:23:34 UTC"
  },
  {
    "arxiv_id": "2410.15555v1",
    "title": "Bayesian Concept Bottleneck Models with LLM Priors",
    "authors": [
      "Jean Feng",
      "Avni Kothari",
      "Luke Zier",
      "Chandan Singh",
      "Yan Shuo Tan"
    ],
    "abstract": "Concept Bottleneck Models (CBMs) have been proposed as a compromise between\nwhite-box and black-box models, aiming to achieve interpretability without\nsacrificing accuracy. The standard training procedure for CBMs is to predefine\na candidate set of human-interpretable concepts, extract their values from the\ntraining data, and identify a sparse subset as inputs to a transparent\nprediction model. However, such approaches are often hampered by the tradeoff\nbetween enumerating a sufficiently large set of concepts to include those that\nare truly relevant versus controlling the cost of obtaining concept\nextractions. This work investigates a novel approach that sidesteps these\nchallenges: BC-LLM iteratively searches over a potentially infinite set of\nconcepts within a Bayesian framework, in which Large Language Models (LLMs)\nserve as both a concept extraction mechanism and prior. BC-LLM is broadly\napplicable and multi-modal. Despite imperfections in LLMs, we prove that BC-LLM\ncan provide rigorous statistical inference and uncertainty quantification. In\nexperiments, it outperforms comparator methods including black-box models,\nconverges more rapidly towards relevant concepts and away from spuriously\ncorrelated ones, and is more robust to out-of-distribution samples.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.15555v1",
    "published_date": "2024-10-21 01:00:33 UTC",
    "updated_date": "2024-10-21 01:00:33 UTC"
  },
  {
    "arxiv_id": "2410.15554v2",
    "title": "A Plug-and-Play Fully On-the-Job Real-Time Reinforcement Learning Algorithm for a Direct-Drive Tandem-Wing Experiment Platforms Under Multiple Random Operating Conditions",
    "authors": [
      "Zhang Minghao",
      "Song Bifeng",
      "Yang Xiaojun",
      "Wang Liang"
    ],
    "abstract": "The nonlinear and unstable aerodynamic interference generated by the tandem\nwings of such biomimetic systems poses substantial challenges for motion\ncontrol, especially under multiple random operating conditions. To address\nthese challenges, the Concerto Reinforcement Learning Extension (CRL2E)\nalgorithm has been developed. This plug-and-play, fully on-the-job, real-time\nreinforcement learning algorithm incorporates a novel Physics-Inspired\nRule-Based Policy Composer Strategy with a Perturbation Module alongside a\nlightweight network optimized for real-time control. To validate the\nperformance and the rationality of the module design, experiments were\nconducted under six challenging operating conditions, comparing seven different\nalgorithms. The results demonstrate that the CRL2E algorithm achieves safe and\nstable training within the first 500 steps, improving tracking accuracy by 14\nto 66 times compared to the Soft Actor-Critic, Proximal Policy Optimization,\nand Twin Delayed Deep Deterministic Policy Gradient algorithms. Additionally,\nCRL2E significantly enhances performance under various random operating\nconditions, with improvements in tracking accuracy ranging from 8.3% to 60.4%\ncompared to the Concerto Reinforcement Learning (CRL) algorithm. The\nconvergence speed of CRL2E is 36.11% to 57.64% faster than the CRL algorithm\nwith only the Composer Perturbation and 43.52% to 65.85% faster than the CRL\nalgorithm when both the Composer Perturbation and Time-Interleaved Capability\nPerturbation are introduced, especially in conditions where the standard CRL\nstruggles to converge. Hardware tests indicate that the optimized lightweight\nnetwork structure excels in weight loading and average inference time, meeting\nreal-time control requirements.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "To prevent potential misunderstandings or negative impacts on the\n  community, I am requesting the withdrawal of my submission due to the\n  discovery of critical errors and major flaws in the work. Recent discussions\n  with researchers in the field have identified significant defects that\n  compromise the validity of the results",
    "pdf_url": "http://arxiv.org/pdf/2410.15554v2",
    "published_date": "2024-10-21 00:59:50 UTC",
    "updated_date": "2024-12-20 09:39:06 UTC"
  }
]