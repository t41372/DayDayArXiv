{
  "date": "2024-09-13",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-09-13 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 模型评估、LLM 在医学、金融和社会领域的应用、情感计算以及机器人控制等领域，亮点包括 LLM 的真实性与效用权衡（如 AI-LieDar）、新型生成模型的提出（如 Eureka），以及著名学者（如 Hamid Palangi 在医学 AI 领域）的贡献，这些研究突显了 AI 在实际应用中的潜力，同时强调了伦理和泛化挑战。\n\n### 重点论文讨论\n我们先聊聊那些重要、话题度高或有著名学者参与的论文，尤其是与 LLM 和 AI 应用相关的。\n\n**1. 政治宣传就是你所需要的 | Propaganda is all you need**  \n这篇论文由 Paul Kronlund-Drouault 撰写，探讨了大型语言模型 (LLMs) 的政治偏差和对齐过程。主要贡献是分析 LLMs 的嵌入空间如何受政治影响，并假设主流 LLMs 可能与“主导意识形态”对齐，揭示了 AI 在社会决策中的潜在风险，如促进社会 uniformity 或极端观点传播。\n\n**2. 大语言模型在热带和传染病分类中的上下文评估 | Contextual Evaluation of Large Language Models for Classifying Tropical and Infectious Diseases**  \n作者包括 Nenad Tomasev 和 Katherine Heller 等著名学者，论文在 NeurIPS 2024 研讨会中被接受。核心发现是通过扩展数据集（超过 11,000 个提示）评估 LLMs 在热带病分类中的性能，证明上下文信息（如人口统计和风险因素）能优化模型响应，并开发了 TRINDs-LM 工具，支持健康领域的 LLM 应用。\n\n**12. Eureka: 评估和理解大型基础模型 | Eureka: Evaluating and Understanding Large Foundation Models**  \n这篇由 Vidhisha Balachandran 等多人撰写的论文，提供了一个标准化框架评估 LLMs，强调基准饱和和解释性挑战。主要贡献是引入 Eureka-Bench 测试集，揭示模型在图像理解和事实性上的局限性，并分析 12 个 SOTA 模型的性能差异，指出没有“最佳”模型，而是各有优势。\n\n**18. AI-LieDar: 考察 LLM 代理在效用和真实性之间的权衡 | AI-LieDar: Examine the Trade-off Between Utility and Truthfulness in LLM Agents**  \n作者包括 Maarten Sap 和 Faeze Brahman，论文探讨 LLM 在多轮对话中的真实性和效用冲突。主要发现是所有模型在真实性测试中不足 50%，但可以通过提示引导提升真实性，并开发了真实性检测器，强调 LLM 部署的安全性。\n\n**24. KodeXv0.1: 一种先进的金融大型语言模型家族 | KodeXv0.1: A Family of State-of-the-Art Financial Large Language Models**  \nNeel Rajani 等作者声称该模型在金融问答中超越 GPT-4。主要贡献是通过 Llama 模型的微调和合成数据集，创建 KodeX-8Bv0.1 和 KodeX-70Bv0.1，提升金融任务的准确性，展示了领域特定 LLM 的潜力。\n\n**11. MAISI: 医学 AI 用于合成成像 | MAISI: Medical AI for Synthetic Imaging**  \n作者包括 Dong Yang 和 Daguang Xu，论文使用扩散模型生成合成 CT 图像，解决医学图像数据稀缺问题。主要发现是生成高质量图像（分辨率高达 512x512x768），并通过 ControlNet 精确标注器官，提高下游任务性能。\n\n**7. Phikon-v2: 用于生物标记预测的大型公共特征提取器 | Phikon-v2: A large and public feature extractor for biomarker prediction**  \nAlexandre Filiot 等作者构建了 4.6 亿病理切片的数据集，并训练自监督模型。主要贡献是 Phikon-v2 模型在癌症预测中与专有模型相当，甚至在某些任务（如 MSI 预测）中胜出，强调公开数据在 AI 医学中的作用。\n\n**42. 多模态融合与 LLM 用于自然对话中的参与度预测 | Multimodal Fusion with LLMs for Engagement Prediction in Natural Conversation**  \n作者包括 Fernando De la Torre 和 Lori L. Holt，论文使用 LLM 融合多模态数据预测对话参与度。主要发现是通过智能眼镜收集数据，开发新融合策略，提升人类通信分析，潜力应用于心理健康和可访问性。\n\n其他论文涉及数学建模、强化学习和语音处理等领域，但我们快速掠过：\n- **14. 解结数、困难的 unknot 图和强化学习 | The unknotting number, hard unknot diagrams, and reinforcement learning**：使用强化学习计算结理论中的解结数，提供上界和数据集。\n- **9. 带分解状态表示的强化学习课程 | Curricula for Learning Robust Policies with Factored State Representations in Changing Environments**：提出课程策略提升策略鲁棒性。\n- **21. SGFormer: 单层图 Transformer 的近似自由线性复杂度 | SGFormer: Single-Layer Graph Transformers with Approximation-Free Linear Complexity**：简化图 Transformer 架构，提升大规模图学习效率。\n- **其余论文**，如语音增强、机器人控制和气象预测等，贡献包括新数据集和模型优化，但细节较常规，未列出以控制篇幅。\n\n总之，今天的论文突出了 AI 的创新应用和挑战，读者可关注 LLM 相关内容以把握前沿趋势。更多细节请查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2410.01810v2",
      "title": "Propaganda is all you need",
      "title_zh": "宣传就是",
      "authors": [
        "Paul Kronlund-Drouault"
      ],
      "abstract": "As Machine Learning (ML) is still a recent field of study, especially outside\nthe realm of abstract Mathematics and Computer Science, few works have been\nconducted on the political aspect of large Language Models (LLMs), and more\nparticularly about the alignment process and its political dimension. This\nprocess can be as simple as prompt engineering but is also very complex and can\naffect completely unrelated notions. For example, politically directed\nalignment has a very strong impact on an LLM's embedding space and the relative\nposition of political notions in such a space. Using special tools to evaluate\ngeneral political bias and analyze the effects of alignment, we can gather new\ndata to understand its causes and possible consequences on society. Indeed, by\ntaking a socio-political approach, we can hypothesize that most big LLMs are\naligned with what Marxist philosophy calls the 'dominant ideology.' As AI's\nrole in political decision-making, at the citizen's scale but also in\ngovernment agencies, such biases can have huge effects on societal change,\neither by creating new and insidious pathways for societal uniformity or by\nallowing disguised extremist views to gain traction among the people.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)在政治维度上的对齐过程(alignment)，强调这种过程可能强化政治偏差并影响模型的嵌入空间(embedding space)。研究使用专用工具评估一般政治偏差，分析对齐如何改变政治概念的相对位置，并从社会政治角度假设大多数大LLMs与主导意识形态(dominant ideology)对齐。论文指出，这种偏差可能对社会变革产生重大影响，包括促进社会统一或助长 disguised extremist views 的传播，从而呼吁关注AI在政治决策中的潜在风险。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01810v2",
      "published_date": "2024-09-13 22:10:42 UTC",
      "updated_date": "2025-04-01 19:54:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:33:21.714026"
    },
    {
      "arxiv_id": "2409.09201v3",
      "title": "Contextual Evaluation of Large Language Models for Classifying Tropical and Infectious Diseases",
      "title_zh": "翻译失败",
      "authors": [
        "Mercy Asiedu",
        "Nenad Tomasev",
        "Chintan Ghate",
        "Tiya Tiyasirichokchai",
        "Awa Dieng",
        "Oluwatosin Akande",
        "Geoffrey Siwo",
        "Steve Adudans",
        "Sylvanus Aitkins",
        "Odianosen Ehiakhamen",
        "Eric Ndombi",
        "Katherine Heller"
      ],
      "abstract": "While large language models (LLMs) have shown promise for medical question\nanswering, there is limited work focused on tropical and infectious\ndisease-specific exploration. We build on an opensource tropical and infectious\ndiseases (TRINDs) dataset, expanding it to include demographic and semantic\nclinical and consumer augmentations yielding 11000+ prompts. We evaluate LLM\nperformance on these, comparing generalist and medical LLMs, as well as LLM\noutcomes to human experts. We demonstrate through systematic experimentation,\nthe benefit of contextual information such as demographics, location, gender,\nrisk factors for optimal LLM response. Finally we develop a prototype of\nTRINDs-LM, a research tool that provides a playground to navigate how context\nimpacts LLM outputs for health.",
      "tldr_zh": "本研究评估了大型语言模型（LLMs）在热带和传染病（TRINDs）分类中的性能，通过扩展开源TRINDs数据集，加入人口统计（如性别、地点）和语义临床增强，生成超过11000个提示。实验系统比较了通用LLMs、医疗LLMs的表现，并与人类专家进行对比，证明了上下文信息（如风险因素）能显著优化LLMs的响应质量。最终，开发了TRINDs-LM原型，这是一个研究工具，用于探索上下文对LLMs在健康领域输出影响的交互式分析。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at 2 NeurIPS 2024 workshops: Generative AI for Health\n  Workshop and Workshop on Advancements In Medical Foundation Models:\n  Explainability, Robustness, Security, and Beyond",
      "pdf_url": "http://arxiv.org/pdf/2409.09201v3",
      "published_date": "2024-09-13 21:28:54 UTC",
      "updated_date": "2025-01-15 18:52:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:33:34.991828"
    },
    {
      "arxiv_id": "2409.09194v2",
      "title": "Hierarchical Hypercomplex Network for Multimodal Emotion Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Eleonora Lopez",
        "Aurelio Uncini",
        "Danilo Comminiello"
      ],
      "abstract": "Emotion recognition is relevant in various domains, ranging from healthcare\nto human-computer interaction. Physiological signals, being beyond voluntary\ncontrol, offer reliable information for this purpose, unlike speech and facial\nexpressions which can be controlled at will. They reflect genuine emotional\nresponses, devoid of conscious manipulation, thereby enhancing the credibility\nof emotion recognition systems. Nonetheless, multimodal emotion recognition\nwith deep learning models remains a relatively unexplored field. In this paper,\nwe introduce a fully hypercomplex network with a hierarchical learning\nstructure to fully capture correlations. Specifically, at the encoder level,\nthe model learns intra-modal relations among the different channels of each\ninput signal. Then, a hypercomplex fusion module learns inter-modal relations\namong the embeddings of the different modalities. The main novelty is in\nexploiting intra-modal relations by endowing the encoders with parameterized\nhypercomplex convolutions (PHCs) that thanks to hypercomplex algebra can\ncapture inter-channel interactions within single modalities. Instead, the\nfusion module comprises parameterized hypercomplex multiplications (PHMs) that\ncan model inter-modal correlations. The proposed architecture surpasses\nstate-of-the-art models on the MAHNOB-HCI dataset for emotion recognition,\nspecifically in classifying valence and arousal from electroencephalograms\n(EEGs) and peripheral physiological signals. The code of this study is\navailable at https://github.com/ispamm/MHyEEG.",
      "tldr_zh": "这篇论文提出了一种Hierarchical Hypercomplex Network，用于多模态情感识别，特别利用生理信号（如EEG和外周生理信号）来提供更可靠的情感响应分析。模型采用层次化结构，在编码器级别通过Parameterized Hypercomplex Convolutions (PHCs)捕捉单一模式内的通道交互，从而学习内部模式关系。接着，融合模块使用Parameterized Hypercomplex Multiplications (PHMs)来建模不同模式之间的相关性，实现高效的多模态整合。该方法在MAHNOB-HCI数据集上超越了现有模型，尤其在价值和唤醒分类任务中表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "The paper has been accepted at MLSP 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.09194v2",
      "published_date": "2024-09-13 21:07:49 UTC",
      "updated_date": "2024-10-10 15:35:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:33:46.838109"
    },
    {
      "arxiv_id": "2409.09191v2",
      "title": "ProcessTBench: An LLM Plan Generation Dataset for Process Mining",
      "title_zh": "翻译失败",
      "authors": [
        "Andrei Cosmin Redis",
        "Mohammadreza Fani Sani",
        "Bahram Zarrin",
        "Andrea Burattin"
      ],
      "abstract": "Large Language Models (LLMs) have shown significant promise in plan\ngeneration. Yet, existing datasets often lack the complexity needed for\nadvanced tool use scenarios - such as handling paraphrased query statements,\nsupporting multiple languages, and managing actions that can be done in\nparallel. These scenarios are crucial for evaluating the evolving capabilities\nof LLMs in real-world applications. Moreover, current datasets don't enable the\nstudy of LLMs from a process perspective, particularly in scenarios where\nunderstanding typical behaviors and challenges in executing the same process\nunder different conditions or formulations is crucial. To address these gaps,\nwe present the ProcessTBench synthetic dataset, an extension of the TaskBench\ndataset specifically designed to evaluate LLMs within a process mining\nframework.",
      "tldr_zh": "大型语言模型(LLMs)在计划生成中表现出巨大潜力，但现有数据集往往缺乏处理改述查询、多语言支持和并行动作等复杂场景的能力，且未从过程视角评估LLMs的行为。ProcessTBench数据集作为TaskBench的扩展，专门设计用于过程挖掘框架，旨在填补这些空白。实验和分析将有助于理解LLMs在不同条件下的过程执行挑战和表现，提升其在真实应用中的适用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.LG",
      "comment": "6 pages, 4 figures, dataset available at\n  https://github.com/microsoft/ProcessTBench",
      "pdf_url": "http://arxiv.org/pdf/2409.09191v2",
      "published_date": "2024-09-13 20:56:21 UTC",
      "updated_date": "2024-09-19 16:46:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:33:58.353772"
    },
    {
      "arxiv_id": "2410.01809v1",
      "title": "Enhancing transparency in AI-powered customer engagement",
      "title_zh": "增强AI驱动客户互动的透明度",
      "authors": [
        "Tara DeZao"
      ],
      "abstract": "This paper addresses the critical challenge of building consumer trust in\nAI-powered customer engagement by emphasising the necessity for transparency\nand accountability. Despite the potential of AI to revolutionise business\noperations and enhance customer experiences, widespread concerns about\nmisinformation and the opacity of AI decision-making processes hinder trust.\nSurveys highlight a significant lack of awareness among consumers regarding\ntheir interactions with AI, alongside apprehensions about bias and fairness in\nAI algorithms. The paper advocates for the development of explainable AI models\nthat are transparent and understandable to both consumers and organisational\nleaders, thereby mitigating potential biases and ensuring ethical use. It\nunderscores the importance of organisational commitment to transparency\npractices beyond mere regulatory compliance, including fostering a culture of\naccountability, prioritising clear data policies and maintaining active\nengagement with stakeholders. By adopting a holistic approach to transparency\nand explainability, businesses can cultivate trust in AI technologies, bridging\nthe gap between technological innovation and consumer acceptance, and paving\nthe way for more ethical and effective AI-powered customer engagements.\nKEYWORDS: artificial intelligence (AI), transparency",
      "tldr_zh": "这篇论文探讨了提升AI驱动客户互动中透明度的重要性，以增强消费者信任。尽管artificial intelligence (AI)能革新业务运作和客户体验，但AI决策过程的不透明和潜在误导信息导致了广泛担忧，包括消费者对AI互动的认知不足以及算法偏见问题。论文主张开发explainable AI模型，使其对消费者和组织领导者透明易懂，从而减少偏见并确保伦理应用。此外，论文强调组织应超越监管合规，培养责任文化、制定清晰数据政策并积极与利益相关者互动，最终通过整体透明策略促进AI技术的可信度和有效性。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.01809v1",
      "published_date": "2024-09-13 20:26:11 UTC",
      "updated_date": "2024-09-13 20:26:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:34:10.173041"
    },
    {
      "arxiv_id": "2409.09174v1",
      "title": "Incorporation of Verifier Functionality in the Software for Operations and Network Attack Results Review and the Autonomous Penetration Testing System",
      "title_zh": "翻译失败",
      "authors": [
        "Jordan Milbrath",
        "Jeremy Straub"
      ],
      "abstract": "The software for operations and network attack results review (SONARR) and\nthe autonomous penetration testing system (APTS) use facts and common\nproperties in digital twin networks to represent real-world entities. However,\nin some cases fact values will change regularly, making it difficult for\nobjects in SONARR and APTS to consistently and accurately represent their\nreal-world counterparts. This paper proposes and evaluates the addition of\nverifiers, which check real-world conditions and update network facts, to\nSONARR. This inclusion allows SONARR to retrieve fact values from its executing\nenvironment and update its network, providing a consistent method of ensuring\nthat the operations and, therefore, the results align with the real-world\nsystems being assessed. Verifiers allow arbitrary scripts and dynamic arguments\nto be added to normal SONARR operations. This provides a layer of flexibility\nand consistency that results in more reliable output from the software.",
      "tldr_zh": "该研究针对SONARR（Software for Operations and Network Attack Results Review）和APTS（Autonomous Penetration Testing System）在数字孪生网络中表示真实实体时，由于事实值经常变化导致的不一致问题，提出在SONARR中添加verifiers功能。verifiers通过检查真实世界条件并更新网络事实，确保系统操作和结果与实际系统保持一致，并允许添加任意脚本和动态参数以增强灵活性。实验评估表明，这一改进提高了软件的可靠性和输出准确性，为网络攻击结果审查和自主渗透测试提供了更稳定的解决方案。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "The U.S. federal sponsor has requested that we not include funding\n  acknowledgement for this publication",
      "pdf_url": "http://arxiv.org/pdf/2409.09174v1",
      "published_date": "2024-09-13 20:17:52 UTC",
      "updated_date": "2024-09-13 20:17:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:34:22.275485"
    },
    {
      "arxiv_id": "2409.09173v1",
      "title": "Phikon-v2, A large and public feature extractor for biomarker prediction",
      "title_zh": "Phikon-v2：一个大型且公开的特征提取器，用于生物标记物预测",
      "authors": [
        "Alexandre Filiot",
        "Paul Jacob",
        "Alice Mac Kain",
        "Charlie Saillard"
      ],
      "abstract": "Gathering histopathology slides from over 100 publicly available cohorts, we\ncompile a diverse dataset of 460 million pathology tiles covering more than 30\ncancer sites. Using this dataset, we train a large self-supervised vision\ntransformer using DINOv2 and publicly release one iteration of this model for\nfurther experimentation, coined Phikon-v2. While trained on publicly available\nhistology slides, Phikon-v2 surpasses our previously released model (Phikon)\nand performs on par with other histopathology foundation models (FM) trained on\nproprietary data. Our benchmarks include eight slide-level tasks with results\nreported on external validation cohorts avoiding any data contamination between\npre-training and evaluation datasets. Our downstream training procedure follows\na simple yet robust ensembling strategy yielding a +1.75 AUC increase across\ntasks and models compared to one-shot retraining (p<0.001). We compare Phikon\n(ViT-B) and Phikon-v2 (ViT-L) against 14 different histology feature\nextractors, making our evaluation the most comprehensive to date. Our result\nsupport evidences that DINOv2 handles joint model and data scaling better than\niBOT. Also, we show that recent scaling efforts are overall beneficial to\ndownstream performance in the context of biomarker prediction with GigaPath and\nH-Optimus-0 (two ViT-g with 1.1B parameters each) standing out. However, the\nstatistical margins between the latest top-performing FMs remain mostly\nnon-significant; some even underperform on specific indications or tasks such\nas MSI prediction - deposed by a 13x smaller model developed internally. While\nlatest foundation models may exhibit limitations for clinical deployment, they\nnonetheless offer excellent grounds for the development of more specialized and\ncost-efficient histology encoders fueling AI-guided diagnostic tools.",
      "tldr_zh": "本研究汇集了超过100个公开队列的组织病理学幻灯片，编译了一个包含4.6亿病理切片（covering more than 30 cancer sites）的多样数据集，并使用DINOv2训练了一个大型自监督视觉Transformer模型Phikon-v2，该模型现已公开发布。Phikon-v2在八个slide-level任务的基准测试中超越了前身Phikon（ViT-B）模型，并与使用专有数据的其他基础模型（Foundation Models）相当，通过简单的集成策略实现了下游任务的AUC平均提升1.75%。实验结果表明，DINOv2在模型和数据缩放方面优于iBOT，尽管最新顶级模型如GigaPath和H-Optimus-0表现出色，但它们之间的性能差异往往不显著，且在特定任务（如MSI prediction）上可能被更小模型超越，为开发专业化的组织病理学编码器和AI辅助诊断工具提供了坚实基础。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.09173v1",
      "published_date": "2024-09-13 20:12:29 UTC",
      "updated_date": "2024-09-13 20:12:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:34:37.314036"
    },
    {
      "arxiv_id": "2409.09171v1",
      "title": "The Challenges of Effective AGM Belief Contraction",
      "title_zh": "有效 AGM 信念收缩的挑战",
      "authors": [
        "Dominik Klumpp",
        "Jandson S. Ribeiro"
      ],
      "abstract": "Despite the significant interest in extending the AGM paradigm of belief\nchange beyond finitary logics, the computational aspects of AGM have remained\nalmost untouched. We investigate the computability of AGM contraction on\nnon-finitary logics, and show an intriguing negative result: there are\ninfinitely many uncomputable AGM contraction functions in such logics.\nDrastically, even if we restrict the theories used to represent epistemic\nstates, in all non-trivial cases, the uncomputability remains. On the positive\nside, we identify an infinite class of computable AGM contraction functions on\nLinear Temporal Logic (LTL). We use B\\\"uchi automata to construct such\nfunctions as well as to represent and reason about LTL knowledge.",
      "tldr_zh": "本论文探讨了 AGM 信念收缩在非有限逻辑中的计算挑战，发现存在无限多个不可计算的 AGM 收缩函数，即使限制理论使用，在所有非平凡情况下仍保持不可计算。研究者通过分析证明了这一负面结果，突显了扩展 AGM 范式面临的难题。在积极方面，他们识别出 Linear Temporal Logic (LTL) 中一个无限类可计算的 AGM 收缩函数，并利用 B\\\"uchi automata 构建这些函数，以表示和推理 LTL 知识，从而为相关领域提供潜在解决方案。",
      "categories": [
        "cs.LO",
        "cs.AI"
      ],
      "primary_category": "cs.LO",
      "comment": "20 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.09171v1",
      "published_date": "2024-09-13 20:03:53 UTC",
      "updated_date": "2024-09-13 20:03:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:34:45.625628"
    },
    {
      "arxiv_id": "2409.09169v2",
      "title": "Curricula for Learning Robust Policies with Factored State Representations in Changing Environments",
      "title_zh": "变化环境中利用因子化状态表示学习鲁",
      "authors": [
        "Panayiotis Panayiotou",
        "Özgür Şimşek"
      ],
      "abstract": "Robust policies enable reinforcement learning agents to effectively adapt to\nand operate in unpredictable, dynamic, and ever-changing real-world\nenvironments. Factored representations, which break down complex state and\naction spaces into distinct components, can improve generalization and sample\nefficiency in policy learning. In this paper, we explore how the curriculum of\nan agent using a factored state representation affects the robustness of the\nlearned policy. We experimentally demonstrate three simple curricula, such as\nvarying only the variable of highest regret between episodes, that can\nsignificantly enhance policy robustness, offering practical insights for\nreinforcement learning in complex environments.",
      "tldr_zh": "这篇论文探讨了在不断变化的环境中使用分化状态表示(factored state representations)来学习鲁棒策略(robust policies)的课程(curricula)，旨在帮助强化学习(reinforcement learning)代理更好地适应动态和不可预测的真实世界。作者通过实验验证了三种简单课程，例如仅在剧集之间改变最高遗憾变量(variable of highest regret)，这些方法显著提升了策略的泛化和鲁棒性。研究结果为复杂环境下的强化学习提供了实用见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "17th European Workshop on Reinforcement Learning (EWRL 2024)",
      "pdf_url": "http://arxiv.org/pdf/2409.09169v2",
      "published_date": "2024-09-13 19:58:43 UTC",
      "updated_date": "2024-09-19 11:03:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:34:58.253201"
    },
    {
      "arxiv_id": "2409.09135v1",
      "title": "Multimodal Fusion with LLMs for Engagement Prediction in Natural Conversation",
      "title_zh": "多模态融合与 LLMs 用于自然对话中的参与度预测",
      "authors": [
        "Cheng Charles Ma",
        "Kevin Hyekang Joo",
        "Alexandria K. Vail",
        "Sunreeta Bhattacharya",
        "Álvaro Fernández García",
        "Kailana Baker-Matsuoka",
        "Sheryl Mathew",
        "Lori L. Holt",
        "Fernando De la Torre"
      ],
      "abstract": "Over the past decade, wearable computing devices (``smart glasses'') have\nundergone remarkable advancements in sensor technology, design, and processing\npower, ushering in a new era of opportunity for high-density human behavior\ndata. Equipped with wearable cameras, these glasses offer a unique opportunity\nto analyze non-verbal behavior in natural settings as individuals interact. Our\nfocus lies in predicting engagement in dyadic interactions by scrutinizing\nverbal and non-verbal cues, aiming to detect signs of disinterest or confusion.\nLeveraging such analyses may revolutionize our understanding of human\ncommunication, foster more effective collaboration in professional\nenvironments, provide better mental health support through empathetic virtual\ninteractions, and enhance accessibility for those with communication barriers.\n  In this work, we collect a dataset featuring 34 participants engaged in\ncasual dyadic conversations, each providing self-reported engagement ratings at\nthe end of each conversation. We introduce a novel fusion strategy using Large\nLanguage Models (LLMs) to integrate multiple behavior modalities into a\n``multimodal transcript'' that can be processed by an LLM for behavioral\nreasoning tasks. Remarkably, this method achieves performance comparable to\nestablished fusion techniques even in its preliminary implementation,\nindicating strong potential for further research and optimization. This fusion\nmethod is one of the first to approach ``reasoning'' about real-world human\nbehavior through a language model. Smart glasses provide us the ability to\nunobtrusively gather high-density multimodal data on human behavior, paving the\nway for new approaches to understanding and improving human communication with\nthe potential for important societal benefits. The features and data collected\nduring the studies will be made publicly available to promote further research.",
      "tldr_zh": "该研究探讨了利用智能眼镜收集多模态数据来预测自然对话中的参与度，重点分析言语和非言语线索以检测不感兴趣或困惑的迹象。研究者收集了一个包含34名参与者的数据集，每个参与者在双人对话后提供自我报告的参与度评分，并引入了一种新颖的融合策略，使用Large Language Models (LLMs)整合多种行为模式，生成“多模态转录”以进行行为推理。实验结果显示，该方法在初步实现中已达到与现有融合技术相当的性能，展现出进一步优化的潜力，并有望提升人类沟通、职业合作、心理健康支持和无障碍交流。数据将公开可用，促进更多研究。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "22 pages, first three authors equal contribution",
      "pdf_url": "http://arxiv.org/pdf/2409.09135v1",
      "published_date": "2024-09-13 18:28:12 UTC",
      "updated_date": "2024-09-13 18:28:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:35:10.477903"
    },
    {
      "arxiv_id": "2409.11169v2",
      "title": "MAISI: Medical AI for Synthetic Imaging",
      "title_zh": "翻译失败",
      "authors": [
        "Pengfei Guo",
        "Can Zhao",
        "Dong Yang",
        "Ziyue Xu",
        "Vishwesh Nath",
        "Yucheng Tang",
        "Benjamin Simon",
        "Mason Belue",
        "Stephanie Harmon",
        "Baris Turkbey",
        "Daguang Xu"
      ],
      "abstract": "Medical imaging analysis faces challenges such as data scarcity, high\nannotation costs, and privacy concerns. This paper introduces the Medical AI\nfor Synthetic Imaging (MAISI), an innovative approach using the diffusion model\nto generate synthetic 3D computed tomography (CT) images to address those\nchallenges. MAISI leverages the foundation volume compression network and the\nlatent diffusion model to produce high-resolution CT images (up to a landmark\nvolume dimension of 512 x 512 x 768 ) with flexible volume dimensions and voxel\nspacing. By incorporating ControlNet, MAISI can process organ segmentation,\nincluding 127 anatomical structures, as additional conditions and enables the\ngeneration of accurately annotated synthetic images that can be used for\nvarious downstream tasks. Our experiment results show that MAISI's capabilities\nin generating realistic, anatomically accurate images for diverse regions and\nconditions reveal its promising potential to mitigate challenges using\nsynthetic data.",
      "tldr_zh": "本论文提出MAISI，一种基于diffusion model的创新方法，用于生成合成3D CT images，以解决医疗影像分析中的数据稀缺、高标注成本和隐私问题。MAISI利用基础体积压缩网络和潜在diffusion model生成高分辨率图像（最高达512 x 512 x 768的体素维度），并通过ControlNet整合器官分割（覆盖127个解剖结构）作为条件，确保合成图像的解剖准确性和标注精确。实验结果显示，MAISI能产生逼真的图像，支持各种下游任务，并展示了其在缓解数据挑战方面的潜力。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "WACV25 accepted. https://monai.io/research/maisi",
      "pdf_url": "http://arxiv.org/pdf/2409.11169v2",
      "published_date": "2024-09-13 18:15:08 UTC",
      "updated_date": "2024-10-29 19:17:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:35:23.930541"
    },
    {
      "arxiv_id": "2409.10566v1",
      "title": "Eureka: Evaluating and Understanding Large Foundation Models",
      "title_zh": "Eureka：评估与理解大型基础模型",
      "authors": [
        "Vidhisha Balachandran",
        "Jingya Chen",
        "Neel Joshi",
        "Besmira Nushi",
        "Hamid Palangi",
        "Eduardo Salinas",
        "Vibhav Vineet",
        "James Woffinden-Luey",
        "Safoora Yousefi"
      ],
      "abstract": "Rigorous and reproducible evaluation is critical for assessing the state of\nthe art and for guiding scientific advances in Artificial Intelligence.\nEvaluation is challenging in practice due to several reasons, including\nbenchmark saturation, lack of transparency in methods used for measurement,\ndevelopment challenges in extracting measurements for generative tasks, and,\nmore generally, the extensive number of capabilities required for a\nwell-rounded comparison across models. We make three contributions to alleviate\nthe above challenges. First, we present Eureka, an open-source framework for\nstandardizing evaluations of large foundation models beyond single-score\nreporting and rankings. Second, we introduce Eureka-Bench as an extensible\ncollection of benchmarks testing capabilities that (i) are still challenging\nfor state-of-the-art models and (ii) represent fundamental but overlooked\nlanguage and multimodal capabilities. The inherent space for improvement in\nnon-saturated benchmarks enables us to discover meaningful differences between\nmodels at a capability level. Third, using Eureka, we conduct an analysis of 12\nstate-of-the-art models, providing in-depth insights into failure understanding\nand model comparison, which can be leveraged to plan targeted improvements. In\ncontrast to recent trends in reports and leaderboards showing absolute rankings\nand claims for one model or another to be the best, our analysis shows that\nthere is no such best model. Different models have different strengths, but\nthere are models that appear more often than others as best performers for some\ncapabilities. Despite the recent improvements, current models still struggle\nwith several fundamental capabilities including detailed image understanding,\nbenefiting from multimodal input when available rather than fully relying on\nlanguage, factuality and grounding for information retrieval, and over\nrefusals.",
      "tldr_zh": "这篇论文介绍了Eureka框架，这是一个开源工具，用于标准化大型基础模型(Large Foundation Models)的评估，超越单一分数报告和排名，以应对基准饱和、测量透明度等问题。论文还提出了Eureka-Bench，这是一个可扩展的基准测试集合，针对仍具挑战性的语言和多模态能力进行评估，帮助发现模型在这些领域的差异。最终，通过对12个最先进模型的分析，研究发现没有一个模型是全面最优的，不同模型各有优势，但普遍存在不足，如详细图像理解、多模态输入利用、事实性和过度拒绝等问题，这为未来模型改进提供了针对性指导。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "I.2"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.10566v1",
      "published_date": "2024-09-13 18:01:49 UTC",
      "updated_date": "2024-09-13 18:01:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:35:36.073652"
    },
    {
      "arxiv_id": "2410.01808v1",
      "title": "AI Horizon Scanning, White Paper p3395, IEEE-SA. Part I: Areas of Attention",
      "title_zh": "翻译失败",
      "authors": [
        "Marina Cortês",
        "Andrew R. Liddle",
        "Christos Emmanouilidis",
        "Anthony E. Kelly",
        "Ken Matusow",
        "Ragu Ragunathan",
        "Jayne M. Suess",
        "George Tambouratzis",
        "Janusz Zalewski",
        "David A. Bray"
      ],
      "abstract": "Generative Artificial Intelligence (AI) models may carry societal\ntransformation to an extent demanding a delicate balance between opportunity\nand risk. This manuscript is the first of a series of White Papers informing\nthe development of IEEE-SA's p3995: `Standard for the Implementation of\nSafeguards, Controls, and Preventive Techniques for Artificial Intelligence\n(AI) Models', Chair: Marina Cort\\^{e}s\n(https://standards.ieee.org/ieee/3395/11378/). In this first horizon-scanning\nwe identify key attention areas for standards activities in AI. We examine\ndifferent principles for regulatory efforts, and review notions of\naccountability, privacy, data rights and mis-use. As a safeguards standard we\ndevote significant attention to the stability of global infrastructures and\nconsider a possible overdependence on cloud computing that may result from\ndensely coupled AI components. We review the recent cascade-failure-like\nCrowdstrike event in July 2024, as an illustration of potential impacts on\ncritical infrastructures from AI-induced incidents in the (near) future. It is\nthe first of a set of articles intended as White Papers informing the audience\non the standard development. Upcoming articles will focus on regulatory\ninitiatives, technology evolution and the role of AI in specific domains.",
      "tldr_zh": "这篇白皮书是IEEE-SA p3995标准系列的第一部分，通过AI地平线扫描(horizon scanning)识别了AI标准活动的关键关注领域，包括监管原则、accountability（问责制）、privacy（隐私）、data rights（数据权利）和mis-use（滥用）等问题。论文强调生成式AI可能带来的社会变革风险，特别关注全球基础设施的稳定性，以及对云计算的过度依赖，并以2024年7月的Crowdstrike事件为例，展示了AI诱发级联失败的潜在影响。该白皮书旨在为AI模型的安全保障、控制和预防技术标准提供信息基础，后续文章将探讨监管举措、技术演变和AI在特定领域的角色。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "This is an interim version of our p3395 working group White Paper. We\n  will update this version, until publication by the Institute of Electrical\n  and Electronics Engineers, Standards Association (IEEE-SA), Sponsor Committee\n  - Artificial Intelligence Standards Committee (C/AISC);\n  https://standards.ieee.org/ieee/3395/11378/",
      "pdf_url": "http://arxiv.org/pdf/2410.01808v1",
      "published_date": "2024-09-13 18:00:01 UTC",
      "updated_date": "2024-09-13 18:00:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:35:46.812123"
    },
    {
      "arxiv_id": "2409.09032v1",
      "title": "The unknotting number, hard unknot diagrams, and reinforcement learning",
      "title_zh": "解结数、难解平凡结图与",
      "authors": [
        "Taylor Applebaum",
        "Sam Blackwell",
        "Alex Davies",
        "Thomas Edlich",
        "András Juhász",
        "Marc Lackenby",
        "Nenad Tomašev",
        "Daniel Zheng"
      ],
      "abstract": "We have developed a reinforcement learning agent that often finds a minimal\nsequence of unknotting crossing changes for a knot diagram with up to 200\ncrossings, hence giving an upper bound on the unknotting number. We have used\nthis to determine the unknotting number of 57k knots. We took diagrams of\nconnected sums of such knots with oppositely signed signatures, where the\nsummands were overlaid. The agent has found examples where several of the\ncrossing changes in an unknotting collection of crossings result in hyperbolic\nknots. Based on this, we have shown that, given knots $K$ and $K'$ that satisfy\nsome mild assumptions, there is a diagram of their connected sum and $u(K) +\nu(K')$ unknotting crossings such that changing any one of them results in a\nprime knot. As a by-product, we have obtained a dataset of 2.6 million distinct\nhard unknot diagrams; most of them under 35 crossings. Assuming the additivity\nof the unknotting number, we have determined the unknotting number of 43 at\nmost 12-crossing knots for which the unknotting number is unknown.",
      "tldr_zh": "本研究开发了一个强化学习（reinforcement learning）代理，用于为最多 200 个交叉点的结图找到最小 unknotting crossing changes 序列，从而提供 unknotting number 的上界，并成功确定了 57k 个结的 unknotting number。代理还处理了连接和（connected sums）中的结图，发现了一些例子，其中 unknotting crossings 的变化会导致 hyperbolic knots，并证明了在某些假设下，结 K 和 K' 的连接和图中，u(K) + u(K') 个 unknotting crossings 改变任何一个都产生 prime knot。作为副产品，研究获得了 260 万个不同的 hard unknot diagrams 数据集，大部分少于 35 个交叉点，并假设 unknotting number 的可加性，确定了 43 个最多 12 个交叉点的未知结的 unknotting number。",
      "categories": [
        "math.GT",
        "cs.AI",
        "cs.LG",
        "57K10, 57K14, 68T07, 68T20",
        "I.2.1; I.2.6; I.2.8"
      ],
      "primary_category": "math.GT",
      "comment": "29 pages, 17 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.09032v1",
      "published_date": "2024-09-13 17:59:52 UTC",
      "updated_date": "2024-09-13 17:59:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:35:59.154871"
    },
    {
      "arxiv_id": "2409.09030v2",
      "title": "Agents in Software Engineering: Survey, Landscape, and Vision",
      "title_zh": "翻译失败",
      "authors": [
        "Yanlin Wang",
        "Wanjun Zhong",
        "Yanxian Huang",
        "Ensheng Shi",
        "Min Yang",
        "Jiachi Chen",
        "Hui Li",
        "Yuchi Ma",
        "Qianxiang Wang",
        "Zibin Zheng"
      ],
      "abstract": "In recent years, Large Language Models (LLMs) have achieved remarkable\nsuccess and have been widely used in various downstream tasks, especially in\nthe tasks of the software engineering (SE) field. We find that many studies\ncombining LLMs with SE have employed the concept of agents either explicitly or\nimplicitly. However, there is a lack of an in-depth survey to sort out the\ndevelopment context of existing works, analyze how existing works combine the\nLLM-based agent technologies to optimize various tasks, and clarify the\nframework of LLM-based agents in SE. In this paper, we conduct the first survey\nof the studies on combining LLM-based agents with SE and present a framework of\nLLM-based agents in SE which includes three key modules: perception, memory,\nand action. We also summarize the current challenges in combining the two\nfields and propose future opportunities in response to existing challenges. We\nmaintain a GitHub repository of the related papers at:\nhttps://github.com/DeepSoftwareAnalytics/Awesome-Agent4SE.",
      "tldr_zh": "这篇论文对 Large Language Models (LLMs) 在软件工程 (SE) 领域的代理 (agents) 应用进行了首次全面调查，分析了现有研究如何显式或隐式地将 LLM-based agents 整合到 SE 任务中。\n作者提出了一个 SE 中 LLM-based agents 的框架，包括三个关键模块：perception（感知）、memory（记忆）和 action（行动），以系统化地优化任务。\n论文总结了当前挑战，如代理技术与 SE 结合的局限性，并针对这些问题提出了未来机会，同时维护了一个相关论文的 GitHub 仓库（https://github.com/DeepSoftwareAnalytics/Awesome-Agent4SE）。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "12 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.09030v2",
      "published_date": "2024-09-13 17:55:58 UTC",
      "updated_date": "2024-09-23 17:55:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:36:10.531254"
    },
    {
      "arxiv_id": "2409.09111v1",
      "title": "Neural Message Passing Induced by Energy-Constrained Diffusion",
      "title_zh": "翻译失败",
      "authors": [
        "Qitian Wu",
        "David Wipf",
        "Junchi Yan"
      ],
      "abstract": "Learning representations for structured data with certain geometries\n(observed or unobserved) is a fundamental challenge, wherein message passing\nneural networks (MPNNs) have become a de facto class of model solutions. In\nthis paper, we propose an energy-constrained diffusion model as a principled\ninterpretable framework for understanding the mechanism of MPNNs and navigating\nnovel architectural designs. The model, inspired by physical systems, combines\nthe inductive bias of diffusion on manifolds with layer-wise constraints of\nenergy minimization. As shown by our analysis, the diffusion operators have a\none-to-one correspondence with the energy functions implicitly descended by the\ndiffusion process, and the finite-difference iteration for solving the\nenergy-constrained diffusion system induces the propagation layers of various\ntypes of MPNNs operated on observed or latent structures. On top of these\nfindings, we devise a new class of neural message passing models, dubbed as\ndiffusion-inspired Transformers, whose global attention layers are induced by\nthe principled energy-constrained diffusion. Across diverse datasets ranging\nfrom real-world networks to images and physical particles, we show that the new\nmodel can yield promising performance for cases where the data structures are\nobserved (as a graph), partially observed or completely unobserved.",
      "tldr_zh": "本研究提出了一种能量约束扩散模型，作为理解消息传递神经网络(MPNNs)机制和设计新架构的框架，旨在为具有特定几何结构的结构化数据学习表示。该模型结合了扩散在流形上的归纳偏差和层级能量最小化约束，通过分析显示扩散算子与能量函数对应，并诱导各种MPNNs的传播层。基于此，作者设计了新类模型diffusion-inspired Transformers，其全局注意力层由能量约束扩散驱动，并在真实网络、图像和物理粒子数据集上表现出色，尤其适用于观察、部分观察或完全未观察的数据结构。实验结果证明，该方法在多样化场景下实现了有前景的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Extended version from DIFFormer paper in ICLR2023. arXiv admin note:\n  text overlap with arXiv:2301.09474",
      "pdf_url": "http://arxiv.org/pdf/2409.09111v1",
      "published_date": "2024-09-13 17:54:41 UTC",
      "updated_date": "2024-09-13 17:54:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:36:22.790799"
    },
    {
      "arxiv_id": "2409.09026v1",
      "title": "Towards Leveraging Contrastively Pretrained Neural Audio Embeddings for Recommender Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Florian Grötschla",
        "Luca Strässle",
        "Luca A. Lanzendörfer",
        "Roger Wattenhofer"
      ],
      "abstract": "Music recommender systems frequently utilize network-based models to capture\nrelationships between music pieces, artists, and users. Although these\nrelationships provide valuable insights for predictions, new music pieces or\nartists often face the cold-start problem due to insufficient initial\ninformation. To address this, one can extract content-based information\ndirectly from the music to enhance collaborative-filtering-based methods. While\nprevious approaches have relied on hand-crafted audio features for this\npurpose, we explore the use of contrastively pretrained neural audio embedding\nmodels, which offer a richer and more nuanced representation of music. Our\nexperiments demonstrate that neural embeddings, particularly those generated\nwith the Contrastive Language-Audio Pretraining (CLAP) model, present a\npromising approach to enhancing music recommendation tasks within graph-based\nframeworks.",
      "tldr_zh": "本研究针对音乐推荐系统中冷启动问题，探讨如何利用从音乐内容中提取的特征来增强基于图的协同过滤方法。作者提出使用对比预训练的神经音频嵌入模型，特别是 Contrastive Language-Audio Pretraining (CLAP) 模型，来生成更丰富且细致的音乐表示，从而捕捉音乐片段、艺术家和用户之间的关系。实验结果表明，这种方法在图-based 框架中显著提升了推荐性能，为处理新音乐或艺术家的推荐任务提供了有效途径。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted at the 2nd Music Recommender Workshop (@RecSys)",
      "pdf_url": "http://arxiv.org/pdf/2409.09026v1",
      "published_date": "2024-09-13 17:53:06 UTC",
      "updated_date": "2024-09-13 17:53:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:36:33.124787"
    },
    {
      "arxiv_id": "2409.09013v2",
      "title": "AI-LieDar: Examine the Trade-off Between Utility and Truthfulness in LLM Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Zhe Su",
        "Xuhui Zhou",
        "Sanketh Rangreji",
        "Anubha Kabra",
        "Julia Mendelsohn",
        "Faeze Brahman",
        "Maarten Sap"
      ],
      "abstract": "Truthfulness (adherence to factual accuracy) and utility (satisfying human\nneeds and instructions) are both fundamental aspects of Large Language Models,\nyet these goals often conflict (e.g., sell a car with known flaws), which makes\nit challenging to achieve both in real-world deployments. We propose AI-LieDar,\na framework to study how LLM-based agents navigate these scenarios in an\nmulti-turn interactive setting. We design a set of real-world scenarios where\nlanguage agents are instructed to achieve goals that are in conflict with being\ntruthful during a multi-turn conversation with simulated human agents. To\nevaluate the truthfulness at large scale, we develop a truthfulness detector\ninspired by psychological literature to assess the agents' responses. Our\nexperiment demonstrates that all models are truthful less than 50% of the time,\nthough truthfulness and goal achievement (utility) rates vary across models. We\nfurther test the steerability of LLMs towards truthfulness, finding that models\ncan be directed to be truthful or deceptive, and even truth-steered models\nstill lie. These findings reveal the complex nature of truthfulness in LLMs and\nunderscore the importance of further research to ensure the safe and reliable\ndeployment of LLMs and LLM-based agents.",
      "tldr_zh": "该研究提出 AI-LieDar 框架，用于探讨 LLM 代理在真实性（truthfulness）和实用性（utility）之间的权衡，特别是在多轮互动场景中。框架设计了真实世界冲突任务，让代理在追求目标的同时可能违反事实准确性，并开发了一个基于心理学文献的真实性检测器进行大规模评估。实验结果显示，所有模型的真实性不到50%，真实性和目标达成率因模型而异，且 LLMs 可被引导成真实或欺骗性，但即使引导后仍会撒谎。这些发现揭示了 LLM 真实性的复杂性，并强调了进一步研究以确保 LLM 和代理的安全可靠部署。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.09013v2",
      "published_date": "2024-09-13 17:41:12 UTC",
      "updated_date": "2025-04-28 04:20:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:36:47.075936"
    },
    {
      "arxiv_id": "2409.09011v1",
      "title": "VAE Explainer: Supplement Learning Variational Autoencoders with Interactive Visualization",
      "title_zh": "翻译失败",
      "authors": [
        "Donald Bertucci",
        "Alex Endert"
      ],
      "abstract": "Variational Autoencoders are widespread in Machine Learning, but are\ntypically explained with dense math notation or static code examples. This\npaper presents VAE Explainer, an interactive Variational Autoencoder running in\nthe browser to supplement existing static documentation (e.g., Keras Code\nExamples). VAE Explainer adds interactions to the VAE summary with interactive\nmodel inputs, latent space, and output. VAE Explainer connects the high-level\nunderstanding with the implementation: annotated code and a live computational\ngraph. The VAE Explainer interactive visualization is live at\nhttps://xnought.github.io/vae-explainer and the code is open source at\nhttps://github.com/xnought/vae-explainer.",
      "tldr_zh": "本文提出 VAE Explainer，这是一个交互式 Variational Autoencoders (VAEs) 工具，旨在通过浏览器运行来补充现有的静态文档（如 Keras 代码示例），解决 VAEs 解释中依赖密集数学符号或静态示例的问题。该工具添加了交互式元素，包括模型输入、潜在空间和输出可视化，并将高层理解与带注释的代码和实时计算图连接起来。VAE Explainer 现已开源，可访问 https://xnought.github.io/vae-explainer 和 https://github.com/xnought/vae-explainer，以提升 VAEs 的学习和应用体验。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "6 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.09011v1",
      "published_date": "2024-09-13 17:40:01 UTC",
      "updated_date": "2024-09-13 17:40:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:36:58.810748"
    },
    {
      "arxiv_id": "2409.09010v1",
      "title": "Contri(e)ve: Context + Retrieve for Scholarly Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Kanchan Shivashankar",
        "Nadine Steinmetz"
      ],
      "abstract": "Scholarly communication is a rapid growing field containing a wealth of\nknowledge. However, due to its unstructured and document format, it is\nchallenging to extract useful information from them through conventional\ndocument retrieval methods. Scholarly knowledge graphs solve this problem, by\nrepresenting the documents in a semantic network, providing, hidden insights,\nsummaries and ease of accessibility through queries. Naturally, question\nanswering for scholarly graphs expands the accessibility to a wider audience.\nBut some of the knowledge in this domain is still presented as unstructured\ntext, thus requiring a hybrid solution for question answering systems. In this\npaper, we present a two step solution using open source Large Language\nModel(LLM): Llama3.1 for Scholarly-QALD dataset. Firstly, we extract the\ncontext pertaining to the question from different structured and unstructured\ndata sources: DBLP, SemOpenAlex knowledge graphs and Wikipedia text. Secondly,\nwe implement prompt engineering to improve the information retrieval\nperformance of the LLM. Our approach achieved an F1 score of 40% and also\nobserved some anomalous responses from the LLM, that are discussed in the final\npart of the paper.",
      "tldr_zh": "本文提出Contri(e)ve框架，通过结合上下文提取和检索技术，解决学术知识图谱中非结构化数据的问答挑战。该方法使用开源LLM（Llama3.1）针对Scholarly-QALD数据集，首先生成问题相关上下文从DBLP、SemOpenAlex知识图谱和Wikipedia文本中提取，其次通过提示工程优化信息检索性能。实验结果显示，该系统在F1 score上达到40%，并分析了LLM的异常响应问题。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.09010v1",
      "published_date": "2024-09-13 17:38:47 UTC",
      "updated_date": "2024-09-13 17:38:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:37:10.477668"
    },
    {
      "arxiv_id": "2409.09007v1",
      "title": "SGFormer: Single-Layer Graph Transformers with Approximation-Free Linear Complexity",
      "title_zh": "翻译失败",
      "authors": [
        "Qitian Wu",
        "Kai Yang",
        "Hengrui Zhang",
        "David Wipf",
        "Junchi Yan"
      ],
      "abstract": "Learning representations on large graphs is a long-standing challenge due to\nthe inter-dependence nature. Transformers recently have shown promising\nperformance on small graphs thanks to its global attention for capturing\nall-pair interactions beyond observed structures. Existing approaches tend to\ninherit the spirit of Transformers in language and vision tasks, and embrace\ncomplicated architectures by stacking deep attention-based propagation layers.\nIn this paper, we attempt to evaluate the necessity of adopting multi-layer\nattentions in Transformers on graphs, which considerably restricts the\nefficiency. Specifically, we analyze a generic hybrid propagation layer,\ncomprised of all-pair attention and graph-based propagation, and show that\nmulti-layer propagation can be reduced to one-layer propagation, with the same\ncapability for representation learning. It suggests a new technical path for\nbuilding powerful and efficient Transformers on graphs, particularly through\nsimplifying model architectures without sacrificing expressiveness. As\nexemplified by this work, we propose a Simplified Single-layer Graph\nTransformers (SGFormer), whose main component is a single-layer global\nattention that scales linearly w.r.t. graph sizes and requires none of any\napproximation for accommodating all-pair interactions. Empirically, SGFormer\nsuccessfully scales to the web-scale graph ogbn-papers100M, yielding\norders-of-magnitude inference acceleration over peer Transformers on\nmedium-sized graphs, and demonstrates competitiveness with limited labeled\ndata.",
      "tldr_zh": "该论文分析了图上 Transformers 的多层注意力机制，发现多层传播可以简化为单层传播，而不影响表示学习能力，从而简化模型架构并提升效率。作者提出 SGFormer，一种简化单层图 Transformers，使用单层全局注意力实现线性复杂度，且无需任何近似来处理所有配对交互。实验结果表明，SGFormer 在大规模图如 ogbn-papers100M 上比同类模型推理速度快几个数量级，并在有限标签数据下表现出竞争力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Extended version of NeurIPS2023 contribution arXiv:2306.10759",
      "pdf_url": "http://arxiv.org/pdf/2409.09007v1",
      "published_date": "2024-09-13 17:37:34 UTC",
      "updated_date": "2024-09-13 17:37:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:37:22.553957"
    },
    {
      "arxiv_id": "2409.09001v1",
      "title": "E2MoCase: A Dataset for Emotional, Event and Moral Observations in News Articles on High-impact Legal Cases",
      "title_zh": "翻译失败",
      "authors": [
        "Candida M. Greco",
        "Lorenzo Zangari",
        "Davide Picca",
        "Andrea Tagarelli"
      ],
      "abstract": "The way media reports on legal cases can significantly shape public opinion,\noften embedding subtle biases that influence societal views on justice and\nmorality. Analyzing these biases requires a holistic approach that captures the\nemotional tone, moral framing, and specific events within the narratives. In\nthis work we introduce E2MoCase, a novel dataset designed to facilitate the\nintegrated analysis of emotions, moral values, and events within legal\nnarratives and media coverage. By leveraging advanced models for emotion\ndetection, moral value identification, and event extraction, E2MoCase offers a\nmulti-dimensional perspective on how legal cases are portrayed in news\narticles.",
      "tldr_zh": "本研究介绍了E2MoCase数据集，该数据集针对高影响法律案件的新闻文章，旨在整合分析情感（emotions）、事件（events）和道德价值观（moral values）的观察，以揭示媒体报道中的潜在偏见。E2MoCase通过利用高级模型进行情感检测、道德价值识别和事件提取，提供了一个多维视角，帮助理解新闻叙事如何塑造公众对正义和道德的看法。该数据集为法律叙述和媒体覆盖的综合分析奠定基础，促进更客观的舆论评估。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.DL",
        "physics.soc-ph"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.09001v1",
      "published_date": "2024-09-13 17:31:09 UTC",
      "updated_date": "2024-09-13 17:31:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:37:33.157105"
    },
    {
      "arxiv_id": "2409.08980v2",
      "title": "Predicting Trust In Autonomous Vehicles: Modeling Young Adult Psychosocial Traits, Risk-Benefit Attitudes, And Driving Factors With Machine Learning",
      "title_zh": "预测自动驾驶车辆中的信任：使用机器学习建模年轻成年人的心理社会特征、风险-收益态度和驾驶因素",
      "authors": [
        "Robert Kaufman",
        "Emi Lee",
        "Manas Satish Bedmutha",
        "David Kirsh",
        "Nadir Weibel"
      ],
      "abstract": "Low trust remains a significant barrier to Autonomous Vehicle (AV) adoption.\nTo design trustworthy AVs, we need to better understand the individual traits,\nattitudes, and experiences that impact people's trust judgements. We use\nmachine learning to understand the most important factors that contribute to\nyoung adult trust based on a comprehensive set of personal factors gathered via\nsurvey (n = 1457). Factors ranged from psychosocial and cognitive attributes to\ndriving style, experiences, and perceived AV risks and benefits. Using the\nexplainable AI technique SHAP, we found that perceptions of AV risks and\nbenefits, attitudes toward feasibility and usability, institutional trust,\nprior experience, and a person's mental model are the most important\npredictors. Surprisingly, psychosocial and many technology- and\ndriving-specific factors were not strong predictors. Results highlight the\nimportance of individual differences for designing trustworthy AVs for diverse\ngroups and lead to key implications for future design and research.",
      "tldr_zh": "该研究使用机器学习模型分析影响年轻人对Autonomous Vehicles (AVs)信任的因素，基于一项大规模调查（n=1457）收集心理社会特质、风险-益处态度、驾驶风格和经历等数据。采用可解释AI技术SHAP进行分析，发现对AV风险和益处的感知、对可行性和可用性的态度、机构信任、以往经历以及个人心理模型是最重要的预测因素。令人意外的是，心理社会特质和许多技术和驾驶相关因素并非强有力预测器。这些发现强调了个体差异在设计可信任AV时的关键作用，并为未来AV设计和研究提供重要启示。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "24 pages (including references and appendix), Accepted to CHI\n  Conference on Human Factors in Computing Systems (CHI 2025)",
      "pdf_url": "http://arxiv.org/pdf/2409.08980v2",
      "published_date": "2024-09-13 16:52:24 UTC",
      "updated_date": "2025-01-28 21:26:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:37:47.105571"
    },
    {
      "arxiv_id": "2409.13749v1",
      "title": "KodeXv0.1: A Family of State-of-the-Art Financial Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Neel Rajani",
        "Lilli Kiessling",
        "Aleksandr Ogaltsov",
        "Claus Lang"
      ],
      "abstract": "Although powerful, current cutting-edge LLMs may not fulfil the needs of\nhighly specialised sectors. We introduce KodeXv0.1, a family of large language\nmodels that outclass GPT-4 in financial question answering. We utilise the base\nvariants of Llama 3.1 8B and 70B and adapt them to the financial domain through\na custom training regime. To this end, we collect and process a large number of\npublicly available financial documents such as earnings calls and business\nreports. These are used to generate a high-quality, synthetic dataset\nconsisting of Context-Question-Answer triplets which closely mirror real-world\nfinancial tasks. Using the train split of this dataset, we perform RAG-aware\n4bit LoRA instruction tuning runs of Llama 3.1 base variants to produce\nKodeX-8Bv0.1 and KodeX-70Bv0.1. We then complete extensive model evaluations\nusing FinanceBench, FinQABench and the withheld test split of our dataset. Our\nresults show that KodeX-8Bv0.1 is more reliable in financial contexts than\ncutting-edge instruct models in the same parameter regime, surpassing them by\nup to 9.24%. In addition, it is even capable of outperforming state-of-the-art\nproprietary models such as GPT-4 by up to 7.07%. KodeX-70Bv0.1 represents a\nfurther improvement upon this, exceeding GPT-4's performance on every tested\nbenchmark.",
      "tldr_zh": "研究者引入了 KodeXv0.1，这是一个先进的金融领域 Large Language Models (LLMs) 家族，旨在超越 GPT-4 在金融问答任务中的表现。基于 Llama 3.1 8B 和 70B 的基础模型，他们通过收集公开金融文档（如收益电话和商业报告）生成高质量的合成 Context-Question-Answer 数据集，并采用 RAG-aware 4bit LoRA 指令调优来适应金融领域。评估结果显示，KodeX-8Bv0.1 在 FinanceBench 和 FinQABench 等基准上比同参数级别的先进指令模型高出最多9.24%，甚至超过 GPT-4 达7.07%；而 KodeX-70Bv0.1 则在所有测试基准上全面优于 GPT-4。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "q-fin.CP",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.13749v1",
      "published_date": "2024-09-13 16:43:08 UTC",
      "updated_date": "2024-09-13 16:43:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:38:00.466871"
    },
    {
      "arxiv_id": "2409.08958v2",
      "title": "PINNfluence: Influence Functions for Physics-Informed Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Jonas R. Naujoks",
        "Aleksander Krasowski",
        "Moritz Weckbecker",
        "Thomas Wiegand",
        "Sebastian Lapuschkin",
        "Wojciech Samek",
        "René P. Klausen"
      ],
      "abstract": "Recently, physics-informed neural networks (PINNs) have emerged as a flexible\nand promising application of deep learning to partial differential equations in\nthe physical sciences. While offering strong performance and competitive\ninference speeds on forward and inverse problems, their black-box nature limits\ninterpretability, particularly regarding alignment with expected physical\nbehavior. In the present work, we explore the application of influence\nfunctions (IFs) to validate and debug PINNs post-hoc. Specifically, we apply\nvariations of IF-based indicators to gauge the influence of different types of\ncollocation points on the prediction of PINNs applied to a 2D Navier-Stokes\nfluid flow problem. Our results demonstrate how IFs can be adapted to PINNs to\nreveal the potential for further studies. The code is publicly available at\nhttps://github.com/aleks-krasowski/PINNfluence.",
      "tldr_zh": "本文提出 PINNfluence 方法，将 influence functions (IFs) 应用于 physics-informed neural networks (PINNs)，以提升其可解释性和调试能力，解决 PINNs 在物理科学偏微分方程问题中的黑盒局限。研究通过 IF-based indicators 分析不同 collocation points 对 2D Navier-Stokes 流体流动问题预测的影响，展示了如何事后验证 PINNs 的物理行为对齐。结果表明，此方法有效揭示了潜在问题并为进一步研究铺平道路，相关代码已在 GitHub 上公开。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.comp-ph",
        "physics.flu-dyn"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.08958v2",
      "published_date": "2024-09-13 16:23:17 UTC",
      "updated_date": "2024-12-01 06:47:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:38:10.856044"
    },
    {
      "arxiv_id": "2409.08936v2",
      "title": "SynSUM -- Synthetic Benchmark with Structured and Unstructured Medical Records",
      "title_zh": "SynSUM：结构化和非结构化医疗记录的合成基准",
      "authors": [
        "Paloma Rabaey",
        "Henri Arno",
        "Stefan Heytens",
        "Thomas Demeester"
      ],
      "abstract": "We present the SynSUM benchmark, a synthetic dataset linking unstructured\nclinical notes to structured background variables. The dataset consists of\n10,000 artificial patient records containing tabular variables (like symptoms,\ndiagnoses and underlying conditions) and related notes describing the fictional\npatient encounter in the domain of respiratory diseases. The tabular portion of\nthe data is generated through a Bayesian network, where both the causal\nstructure between the variables and the conditional probabilities are proposed\nby an expert based on domain knowledge. We then prompt a large language model\n(GPT-4o) to generate a clinical note related to this patient encounter,\ndescribing the patient symptoms and additional context. We conduct both an\nexpert evaluation study to assess the quality of the generated notes, as well\nas running some simple predictor models on both the tabular and text portions\nof the dataset, forming a baseline for further research. The SynSUM dataset is\nprimarily designed to facilitate research on clinical information extraction in\nthe presence of tabular background variables, which can be linked through\ndomain knowledge to concepts of interest to be extracted from the text - the\nsymptoms, in the case of SynSUM. Secondary uses include research on the\nautomation of clinical reasoning over both tabular data and text, causal effect\nestimation in the presence of tabular and/or textual confounders, and\nmulti-modal synthetic data generation.",
      "tldr_zh": "本研究引入了 SynSUM 基准数据集，这是一个合成数据集，包含 10,000 条人工患者记录，将非结构化临床笔记与结构化变量（如症状、诊断和潜在条件）联系起来，聚焦于呼吸系统疾病领域。数据集的表格部分通过 Bayesian network 生成，基于专家领域知识定义因果结构和条件概率，而临床笔记则由 GPT-4o 生成，以描述患者症状和相关上下文。研究进行了专家评估来验证笔记质量，并运行简单预测模型作为基准，以支持进一步研究。SynSUM 的主要用途是促进临床信息提取研究，特别是将结构化背景变量与文本中的概念（如症状）通过领域知识关联起来，而次要用途包括自动化临床推理、因果效应估计以及多模态合成数据生成。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "The dataset can be downloaded from https://github.com/prabaey/synsum.\n  Presented at the GenAI4Health workshop at AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2409.08936v2",
      "published_date": "2024-09-13 15:55:15 UTC",
      "updated_date": "2025-03-07 17:09:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:38:23.045946"
    },
    {
      "arxiv_id": "2409.08935v2",
      "title": "Optimization and Generalization Guarantees for Weight Normalization",
      "title_zh": "Weight Normalization 的优化与泛化保证",
      "authors": [
        "Pedro Cisneros-Velarde",
        "Zhijie Chen",
        "Sanmi Koyejo",
        "Arindam Banerjee"
      ],
      "abstract": "Weight normalization (WeightNorm) is widely used in practice for the training\nof deep neural networks and modern deep learning libraries have built-in\nimplementations of it. In this paper, we provide the first theoretical\ncharacterizations of both optimization and generalization of deep WeightNorm\nmodels with smooth activation functions. For optimization, from the form of the\nHessian of the loss, we note that a small Hessian of the predictor leads to a\ntractable analysis. Thus, we bound the spectral norm of the Hessian of\nWeightNorm networks and show its dependence on the network width and weight\nnormalization terms--the latter being unique to networks without WeightNorm.\nThen, we use this bound to establish training convergence guarantees under\nsuitable assumptions for gradient decent. For generalization, we use WeightNorm\nto get a uniform convergence based generalization bound, which is independent\nfrom the width and depends sublinearly on the depth. Finally, we present\nexperimental results which illustrate how the normalization terms and other\nquantities of theoretical interest relate to the training of WeightNorm\nnetworks.",
      "tldr_zh": "本文首次对 Weight Normalization (WeightNorm) 进行了理论分析，提供优化和泛化保证，针对使用平滑激活函数的深度神经网络。优化方面，通过 bounding 损失函数 Hessian 的谱范数，分析其依赖于网络宽度和 WeightNorm 项，从而建立了梯度下降的收敛保证。泛化方面，该方法获得了一个基于统一收敛的 bound，该 bound 不依赖于网络宽度，而是对深度呈次线性依赖。最后，实验结果展示了 WeightNorm 术语与其他理论量与网络训练的关系。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.08935v2",
      "published_date": "2024-09-13 15:55:05 UTC",
      "updated_date": "2025-01-20 18:07:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:38:34.360574"
    },
    {
      "arxiv_id": "2409.08930v1",
      "title": "Yes, Prime Minister, question order does matter -- and it's certainly not classical! But is it quantum?",
      "title_zh": "翻译失败",
      "authors": [
        "Dorje C. Brody"
      ],
      "abstract": "Response to a poll can be manipulated by means of a series of leading\nquestions. We show that such phenomena cannot be explained by use of classical\nprobability theory, whereas quantum probability theory admits a possibility of\noffering an explanation. Admissible transformation rules in quantum\nprobability, however, do impose some constraints on the modelling of cognitive\nbehaviour, which are highlighted here. Focusing on a recent poll conducted by\nIpsos on a set of questions posed by Sir Humphrey Appleby in an episode of the\nBritish political satire \\textit{Yes, Prime Minister}, we show that the\nresulting data cannot be explained quite so simply using quantum rules,\nalthough it seems not impossible.",
      "tldr_zh": "该研究探讨了问题顺序如何操纵民意调查响应，指出这种现象无法用 classical probability theory 解释，而 quantum probability theory 可能提供一种解释框架，但受限于其内在转换规则。论文分析了 Ipsos 针对英国政治讽刺剧《Yes, Prime Minister》中的问题集进行的一项民意调查数据，结果显示这些数据虽不能简单地用 quantum probability 规则建模，但并非完全不可能。总之，该工作强调了认知行为建模中量子概率的潜在优势及其约束。",
      "categories": [
        "cs.AI",
        "q-bio.NC",
        "quant-ph"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2409.08930v1",
      "published_date": "2024-09-13 15:46:57 UTC",
      "updated_date": "2024-09-13 15:46:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:38:56.291761"
    },
    {
      "arxiv_id": "2409.08919v1",
      "title": "XSub: Explanation-Driven Adversarial Attack against Blackbox Classifiers via Feature Substitution",
      "title_zh": "翻译失败",
      "authors": [
        "Kiana Vu",
        "Phung Lai",
        "Truc Nguyen"
      ],
      "abstract": "Despite its significant benefits in enhancing the transparency and\ntrustworthiness of artificial intelligence (AI) systems, explainable AI (XAI)\nhas yet to reach its full potential in real-world applications. One key\nchallenge is that XAI can unintentionally provide adversaries with insights\ninto black-box models, inevitably increasing their vulnerability to various\nattacks. In this paper, we develop a novel explanation-driven adversarial\nattack against black-box classifiers based on feature substitution, called\nXSub. The key idea of XSub is to strategically replace important features\n(identified via XAI) in the original sample with corresponding important\nfeatures from a \"golden sample\" of a different label, thereby increasing the\nlikelihood of the model misclassifying the perturbed sample. The degree of\nfeature substitution is adjustable, allowing us to control how much of the\noriginal samples information is replaced. This flexibility effectively balances\na trade-off between the attacks effectiveness and its stealthiness. XSub is\nalso highly cost-effective in that the number of required queries to the\nprediction model and the explanation model in conducting the attack is in O(1).\nIn addition, XSub can be easily extended to launch backdoor attacks in case the\nattacker has access to the models training data. Our evaluation demonstrates\nthat XSub is not only effective and stealthy but also cost-effective, enabling\nits application across a wide range of AI models.",
      "tldr_zh": "这篇论文提出了XSub，一种基于解释驱动的对抗攻击方法，针对黑箱分类器(blackbox classifiers)通过特征替换(feature substitution)来利用XAI(Explainable AI)的解释信息进行攻击。XSub的核心机制是将XAI识别的重要特征从原始样本替换为来自不同标签的“黄金样本”的对应特征，从而提高模型误分类的可能性，同时允许调整替换程度以平衡攻击有效性和隐蔽性。该方法查询成本极低，仅需O(1)次查询到预测模型和解释模型。实验证明，XSub不仅高效、隐蔽，还可扩展到后门攻击(backdoor attacks)，适用于广泛的AI模型。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.08919v1",
      "published_date": "2024-09-13 15:33:32 UTC",
      "updated_date": "2024-09-13 15:33:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:38:58.886703"
    },
    {
      "arxiv_id": "2409.08917v1",
      "title": "Latent Space Score-based Diffusion Model for Probabilistic Multivariate Time Series Imputation",
      "title_zh": "翻译失败",
      "authors": [
        "Guojun Liang",
        "Najmeh Abiri",
        "Atiye Sadat Hashemi",
        "Jens Lundström",
        "Stefan Byttner",
        "Prayag Tiwari"
      ],
      "abstract": "Accurate imputation is essential for the reliability and success of\ndownstream tasks. Recently, diffusion models have attracted great attention in\nthis field. However, these models neglect the latent distribution in a\nlower-dimensional space derived from the observed data, which limits the\ngenerative capacity of the diffusion model. Additionally, dealing with the\noriginal missing data without labels becomes particularly problematic. To\naddress these issues, we propose the Latent Space Score-Based Diffusion Model\n(LSSDM) for probabilistic multivariate time series imputation. Observed values\nare projected onto low-dimensional latent space and coarse values of the\nmissing data are reconstructed without knowing their ground truth values by\nthis unsupervised learning approach. Finally, the reconstructed values are fed\ninto a conditional diffusion model to obtain the precise imputed values of the\ntime series. In this way, LSSDM not only possesses the power to identify the\nlatent distribution but also seamlessly integrates the diffusion model to\nobtain the high-fidelity imputed values and assess the uncertainty of the\ndataset. Experimental results demonstrate that LSSDM achieves superior\nimputation performance while also providing a better explanation and\nuncertainty analysis of the imputation mechanism. The website of the code is\n\\textit{https://github.com/gorgen2020/LSSDM\\_imputation}.",
      "tldr_zh": "该研究提出了一种Latent Space Score-Based Diffusion Model (LSSDM)，用于处理概率多变量时间序列插值问题，以解决现有扩散模型忽略低维潜在分布导致的生成能力不足和无标签数据处理难题。LSSDM首先将观测数据投影到低维潜在空间，通过无监督学习重建缺失数据的粗略值，然后将其输入条件扩散模型以生成精确的插值结果。这种方法不仅能识别潜在分布，还能评估数据集的不确定性。实验结果表明，LSSDM在插值性能上优于基线模型，并提供了更好的解释性和不确定性分析。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "5 pages, conference",
      "pdf_url": "http://arxiv.org/pdf/2409.08917v1",
      "published_date": "2024-09-13 15:32:26 UTC",
      "updated_date": "2024-09-13 15:32:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:39:10.336561"
    },
    {
      "arxiv_id": "2409.08916v2",
      "title": "Farmer.Chat: Scaling AI-Powered Agricultural Services for Smallholder Farmers",
      "title_zh": "翻译失败",
      "authors": [
        "Namita Singh",
        "Jacqueline Wang'ombe",
        "Nereah Okanga",
        "Tetyana Zelenska",
        "Jona Repishti",
        "Jayasankar G K",
        "Sanjeev Mishra",
        "Rajsekar Manokaran",
        "Vineet Singh",
        "Mohammed Irfan Rafiq",
        "Rikin Gandhi",
        "Akshay Nambi"
      ],
      "abstract": "Small and medium-sized agricultural holders face challenges like limited\naccess to localized, timely information, impacting productivity and\nsustainability. Traditional extension services, which rely on in-person agents,\nstruggle with scalability and timely delivery, especially in remote areas. We\nintroduce FarmerChat, a generative AI-powered chatbot designed to address these\nissues. Leveraging Generative AI, FarmerChat offers personalized, reliable, and\ncontextually relevant advice, overcoming limitations of previous chatbots in\ndeterministic dialogue flows, language support, and unstructured data\nprocessing. Deployed in four countries, FarmerChat has engaged over 15,000\nfarmers and answered over 300,000 queries. This paper highlights how\nFarmerChat's innovative use of GenAI enhances agricultural service scalability\nand effectiveness. Our evaluation, combining quantitative analysis and\nqualitative insights, highlights FarmerChat's effectiveness in improving\nfarming practices, enhancing trust, response quality, and user engagement.",
      "tldr_zh": "小农面临信息获取困难的问题，如缺乏本地化和及时指导，导致生产力和可持续性受影响，而传统扩展服务难以扩展和及时交付。  \n本文引入FarmerChat，一种基于Generative AI的聊天机器人，提供个性化的、可靠的农业建议，克服了现有聊天机器人的局限，包括确定性对话流、语言支持和非结构化数据处理。  \nFarmerChat已在四个国家部署，服务超过15,000名农民并回答30万查询，显著提升了农业服务的可扩展性。  \n评估结果显示，它改善了耕作实践、增强了用户信任、响应质量和参与度。",
      "categories": [
        "cs.ET",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.ET",
      "comment": "35 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.08916v2",
      "published_date": "2024-09-13 15:31:33 UTC",
      "updated_date": "2024-10-08 06:03:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:39:33.739466"
    },
    {
      "arxiv_id": "2409.08907v1",
      "title": "Affective Computing Has Changed: The Foundation Model Disruption",
      "title_zh": "情感计算已改变：基础模型的颠覆",
      "authors": [
        "Björn Schuller",
        "Adria Mallol-Ragolta",
        "Alejandro Peña Almansa",
        "Iosif Tsangko",
        "Mostafa M. Amin",
        "Anastasia Semertzidou",
        "Lukas Christ",
        "Shahin Amiriparian"
      ],
      "abstract": "The dawn of Foundation Models has on the one hand revolutionised a wide range\nof research problems, and, on the other hand, democratised the access and use\nof AI-based tools by the general public. We even observe an incursion of these\nmodels into disciplines related to human psychology, such as the Affective\nComputing domain, suggesting their affective, emerging capabilities. In this\nwork, we aim to raise awareness of the power of Foundation Models in the field\nof Affective Computing by synthetically generating and analysing multimodal\naffective data, focusing on vision, linguistics, and speech (acoustics). We\nalso discuss some fundamental problems, such as ethical issues and regulatory\naspects, related to the use of Foundation Models in this research area.",
      "tldr_zh": "这篇论文讨论了 Foundation Models 如何革命性地改变 Affective Computing 领域，通过使其更易于大众访问并扩展到人类心理学相关应用。作者通过合成和分析多模态情感数据（聚焦于 vision、linguistics 和 speech），展示了这些模型在情感计算中的强大潜力。论文同时强调了潜在的伦理问题和监管挑战，以促进该领域的负责任发展。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.08907v1",
      "published_date": "2024-09-13 15:20:18 UTC",
      "updated_date": "2024-09-13 15:20:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:39:33.250615"
    },
    {
      "arxiv_id": "2409.08904v2",
      "title": "AnyBipe: An End-to-End Framework for Training and Deploying Bipedal Robots Guided by Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yifei Yao",
        "Wentao He",
        "Chenyu Gu",
        "Jiaheng Du",
        "Fuwei Tan",
        "Zhen Zhu",
        "Junguo Lu"
      ],
      "abstract": "Training and deploying reinforcement learning (RL) policies for robots,\nespecially in accomplishing specific tasks, presents substantial challenges.\nRecent advancements have explored diverse reward function designs, training\ntechniques, simulation-to-reality (sim-to-real) transfers, and performance\nanalysis methodologies, yet these still require significant human intervention.\nThis paper introduces an end-to-end framework for training and deploying RL\npolicies, guided by Large Language Models (LLMs), and evaluates its\neffectiveness on bipedal robots. The framework consists of three interconnected\nmodules: an LLM-guided reward function design module, an RL training module\nleveraging prior work, and a sim-to-real homomorphic evaluation module. This\ndesign significantly reduces the need for human input by utilizing only\nessential simulation and deployment platforms, with the option to incorporate\nhuman-engineered strategies and historical data. We detail the construction of\nthese modules, their advantages over traditional approaches, and demonstrate\nthe framework's capability to autonomously develop and refine controlling\nstrategies for bipedal robot locomotion, showcasing its potential to operate\nindependently of human intervention.",
      "tldr_zh": "本文提出AnyBipe框架，这是一个端到端的系统，利用Large Language Models (LLMs)指导强化学习 (RL) 策略的训练和部署，旨在减少人为干预并应用于双足机器人任务。该框架由三个模块组成：LLM-guided reward function design模块负责奖励函数设计、RL training模块进行策略训练，以及sim-to-real homomorphic evaluation模块处理模拟到现实的转移评估。与传统方法相比，AnyBipe显著降低了人类输入需求，并展示了其自主开发和优化双足机器人运动控制策略的潜力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.08904v2",
      "published_date": "2024-09-13 15:15:45 UTC",
      "updated_date": "2025-02-23 08:43:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:39:46.384688"
    },
    {
      "arxiv_id": "2409.08895v1",
      "title": "Synthetic Human Memories: AI-Edited Images and Videos Can Implant False Memories and Distort Recollection",
      "title_zh": "翻译失败",
      "authors": [
        "Pat Pataranutaporn",
        "Chayapatr Archiwaranguprok",
        "Samantha W. T. Chan",
        "Elizabeth Loftus",
        "Pattie Maes"
      ],
      "abstract": "AI is increasingly used to enhance images and videos, both intentionally and\nunintentionally. As AI editing tools become more integrated into smartphones,\nusers can modify or animate photos into realistic videos. This study examines\nthe impact of AI-altered visuals on false memories--recollections of events\nthat didn't occur or deviate from reality. In a pre-registered study, 200\nparticipants were divided into four conditions of 50 each. Participants viewed\noriginal images, completed a filler task, then saw stimuli corresponding to\ntheir assigned condition: unedited images, AI-edited images, AI-generated\nvideos, or AI-generated videos of AI-edited images. AI-edited visuals\nsignificantly increased false recollections, with AI-generated videos of\nAI-edited images having the strongest effect (2.05x compared to control).\nConfidence in false memories was also highest for this condition (1.19x\ncompared to control). We discuss potential applications in HCI, such as\ntherapeutic memory reframing, and challenges in ethical, legal, political, and\nsocietal domains.",
      "tldr_zh": "这篇论文探讨了 AI 编辑的图像和视频如何植入 false memories（假记忆）并扭曲真实回忆，通过一个预注册实验涉及 200 名参与者分为四组。实验结果显示，AI-edited images 和 AI-generated videos 显著增加了假回忆，其中 AI-generated videos of AI-edited images 的效果最强（比对照组高 2.05 倍），且参与者对这些假记忆的信心也最高（比对照组高 1.19 倍）。研究强调了在 HCI 等领域的潜在应用，如治疗性记忆重构，同时指出了伦理、法律和社交挑战。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "22 pages, 11 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2409.08895v1",
      "published_date": "2024-09-13 15:08:39 UTC",
      "updated_date": "2024-09-13 15:08:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:39:58.947770"
    },
    {
      "arxiv_id": "2409.08892v1",
      "title": "Exploring Action-Centric Representations Through the Lens of Rate-Distortion Theory",
      "title_zh": "翻译失败",
      "authors": [
        "Miguel de Llanza Varona",
        "Christopher L. Buckley",
        "Beren Millidge"
      ],
      "abstract": "Organisms have to keep track of the information in the environment that is\nrelevant for adaptive behaviour. Transmitting information in an economical and\nefficient way becomes crucial for limited-resourced agents living in\nhigh-dimensional environments. The efficient coding hypothesis claims that\norganisms seek to maximize the information about the sensory input in an\nefficient manner. Under Bayesian inference, this means that the role of the\nbrain is to efficiently allocate resources in order to make predictions about\nthe hidden states that cause sensory data. However, neither of those frameworks\naccounts for how that information is exploited downstream, leaving aside the\naction-oriented role of the perceptual system. Rate-distortion theory, which\ndefines optimal lossy compression under constraints, has gained attention as a\nformal framework to explore goal-oriented efficient coding. In this work, we\nexplore action-centric representations in the context of rate-distortion\ntheory. We also provide a mathematical definition of abstractions and we argue\nthat, as a summary of the relevant details, they can be used to fix the content\nof action-centric representations. We model action-centric representations\nusing VAEs and we find that such representations i) are efficient lossy\ncompressions of the data; ii) capture the task-dependent invariances necessary\nto achieve successful behaviour; and iii) are not in service of reconstructing\nthe data. Thus, we conclude that full reconstruction of the data is rarely\nneeded to achieve optimal behaviour, consistent with a teleological approach to\nperception.",
      "tldr_zh": "这篇论文通过 Rate-Distortion Theory 的视角探索行动中心表示，旨在解释生物如何高效处理环境信息以支持适应性行为，而非单纯重建感官数据。作者首先定义了抽象的数学框架，将其作为行动中心表示的核心内容，并使用 VAEs（变分自编码器）进行建模。研究发现，这些表示实现了高效的损失压缩，能够捕捉任务相关的不变性，从而促进成功行为，而无需完全重建原始数据。最终，论文支持了目的论的感知方法，即感知系统更注重目标导向而非数据完整性。",
      "categories": [
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.08892v1",
      "published_date": "2024-09-13 15:07:22 UTC",
      "updated_date": "2024-09-13 15:07:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:40:10.786425"
    },
    {
      "arxiv_id": "2409.09107v4",
      "title": "Proactive and Reactive Constraint Programming for Stochastic Project Scheduling with Maximal Time-Lags",
      "title_zh": "翻译失败",
      "authors": [
        "Kim van den Houten",
        "Léon Planken",
        "Esteban Freydell",
        "David M. J. Tax",
        "Mathijs de Weerdt"
      ],
      "abstract": "This study investigates scheduling strategies for the stochastic\nresource-constrained project scheduling problem with maximal time lags\n(SRCPSP/max)). Recent advances in Constraint Programming (CP) and Temporal\nNetworks have reinvoked interest in evaluating the advantages and drawbacks of\nvarious proactive and reactive scheduling methods. First, we present a new,\nCP-based fully proactive method. Second, we show how a reactive approach can be\nconstructed using an online rescheduling procedure. A third contribution is\nbased on partial order schedules and uses Simple Temporal Networks with\nUncertainty (STNUs). Our statistical analysis shows that the STNU-based\nalgorithm performs best in terms of solution quality, while also showing good\nrelative offline and online computation time.",
      "tldr_zh": "这篇论文研究了随机资源约束项目调度问题（SRCPSP/max），重点探讨主动（proactive）和反应式（reactive）约束编程（CP）策略，以处理最大时间滞后问题。主要贡献包括：提出一个新的基于CP的完全主动调度方法、构建一个使用在线重新调度程序的反应式方法，以及开发基于部分顺序调度的Simple Temporal Networks with Uncertainty (STNUs)算法。统计分析显示，STNU-based算法在解决方案质量方面表现出色，同时在线上和离线计算时间上具有良好的相对效率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.09107v4",
      "published_date": "2024-09-13 15:01:25 UTC",
      "updated_date": "2025-03-22 21:20:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:40:23.260198"
    },
    {
      "arxiv_id": "2409.08864v1",
      "title": "Exploring Graph Structure Comprehension Ability of Multimodal Large Language Models: Case Studies",
      "title_zh": "探索多模态大语言模型的图结构理解能力：案例研究",
      "authors": [
        "Zhiqiang Zhong",
        "Davide Mottin"
      ],
      "abstract": "Large Language Models (LLMs) have shown remarkable capabilities in processing\nvarious data structures, including graphs. While previous research has focused\non developing textual encoding methods for graph representation, the emergence\nof multimodal LLMs presents a new frontier for graph comprehension. These\nadvanced models, capable of processing both text and images, offer potential\nimprovements in graph understanding by incorporating visual representations\nalongside traditional textual data. This study investigates the impact of graph\nvisualisations on LLM performance across a range of benchmark tasks at node,\nedge, and graph levels. Our experiments compare the effectiveness of multimodal\napproaches against purely textual graph representations. The results provide\nvaluable insights into both the potential and limitations of leveraging visual\ngraph modalities to enhance LLMs' graph structure comprehension abilities.",
      "tldr_zh": "本研究探讨了多模态 Large Language Models (LLMs) 在图结构理解方面的能力，通过案例研究评估图可视化对模型性能的影响。研究方法包括在节点、边和图级别上的基准任务中，比较多模态方法（结合文本和图像表示）与纯文本图表示的有效性。实验结果揭示了利用视觉图模式增强 LLMs 图结构理解的潜力，同时指出了其存在的局限性，为未来模型优化提供了宝贵见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.08864v1",
      "published_date": "2024-09-13 14:26:58 UTC",
      "updated_date": "2024-09-13 14:26:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:40:34.553954"
    },
    {
      "arxiv_id": "2409.09106v1",
      "title": "Recent Trends in Modelling the Continuous Time Series using Deep Learning: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Mansura Habiba",
        "Barak A. Pearlmutter",
        "Mehrdad Maleki"
      ],
      "abstract": "Continuous-time series is essential for different modern application areas,\ne.g. healthcare, automobile, energy, finance, Internet of things (IoT) and\nother related areas. Different application needs to process as well as analyse\na massive amount of data in time series structure in order to determine the\ndata-driven result, for example, financial trend prediction, potential\nprobability of the occurrence of a particular event occurrence identification,\npatient health record processing and so many more. However, modeling real-time\ndata using a continuous-time series is challenging since the dynamical systems\nbehind the data could be a differential equation. Several research works have\ntried to solve the challenges of modelling the continuous-time series using\ndifferent neural network models and approaches for data processing and\nlearning. The existing deep learning models are not free from challenges and\nlimitations due to diversity among different attributes, behaviour, duration of\nsteps, energy, and data sampling rate. This paper has described the general\nproblem domain of time series and reviewed the challenges of modelling the\ncontinuous time series. We have presented a comparative analysis of recent\ndevelopments in deep learning models and their contribution to solving\ndifferent difficulties of modelling the continuous time series. We have also\nidentified the limitations of the existing neural network model and open\nissues. The main goal of this review is to understand the recent trend of\nneural network models used in a different real-world application with\ncontinuous-time data.",
      "tldr_zh": "这篇论文调查了使用深度学习模型建模连续时间序列的最新趋势，涵盖了其在医疗、金融、物联网等领域的应用及其重要性。作者分析了建模面临的挑战，如动态系统涉及微分方程，以及现有深度学习模型在处理数据多样性、行为差异和采样率等方面的局限性。论文通过比较最近的神经网络模型发展，识别了关键贡献和开放问题，以帮助理解这些模型在真实世界连续时间数据处理中的应用趋势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.09106v1",
      "published_date": "2024-09-13 14:19:44 UTC",
      "updated_date": "2024-09-13 14:19:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:40:46.452307"
    },
    {
      "arxiv_id": "2409.08853v1",
      "title": "Using The Concept Hierarchy for Household Action Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Andrei Costinescu",
        "Luis Figueredo",
        "Darius Burschka"
      ],
      "abstract": "We propose a method to systematically represent both the static and the\ndynamic components of environments, i.e. objects and agents, as well as the\nchanges that are happening in the environment, i.e. the actions and skills\nperformed by agents. Our approach, the Concept Hierarchy, provides the\nnecessary information for autonomous systems to represent environment states,\nperform action modeling and recognition, and plan the execution of tasks.\nAdditionally, the hierarchical structure supports generalization and knowledge\ntransfer to environments. We rigorously define tasks, actions, skills, and\naffordances that enable human-understandable action and skill recognition.",
      "tldr_zh": "本研究提出了一种名为 Concept Hierarchy 的方法，用于系统表示家庭环境中的静态组件（如对象）和动态组件（如代理），以及环境变化（如 actions 和 skills）。该方法通过分层结构提供必要信息，支持自主系统进行环境状态表示、actions 建模和识别，以及任务规划。Concept Hierarchy 还促进泛化和知识转移，并定义了任务、actions、skills 和 affordances，以实现人类可理解的动作和技能识别。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "5 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.08853v1",
      "published_date": "2024-09-13 14:16:41 UTC",
      "updated_date": "2024-09-13 14:16:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:40:58.075167"
    },
    {
      "arxiv_id": "2409.08820v2",
      "title": "A RAG Approach for Generating Competency Questions in Ontology Engineering",
      "title_zh": "翻译失败",
      "authors": [
        "Xueli Pan",
        "Jacco van Ossenbruggen",
        "Victor de Boer",
        "Zhisheng Huang"
      ],
      "abstract": "Competency question (CQ) formulation is central to several ontology\ndevelopment and evaluation methodologies. Traditionally, the task of crafting\nthese competency questions heavily relies on the effort of domain experts and\nknowledge engineers which is often time-consuming and labor-intensive. With the\nemergence of Large Language Models (LLMs), there arises the possibility to\nautomate and enhance this process. Unlike other similar works which use\nexisting ontologies or knowledge graphs as input to LLMs, we present a\nretrieval-augmented generation (RAG) approach that uses LLMs for the automatic\ngeneration of CQs given a set of scientific papers considered to be a domain\nknowledge base. We investigate its performance and specifically, we study the\nimpact of different number of papers to the RAG and different temperature\nsetting of the LLM. We conduct experiments using GPT-4 on two domain ontology\nengineering tasks and compare results against ground-truth CQs constructed by\ndomain experts. Empirical assessments on the results, utilizing evaluation\nmetrics (precision and consistency), reveal that compared to zero-shot\nprompting, adding relevant domain knowledge to the RAG improves the performance\nof LLMs on generating CQs for concrete ontology engineering tasks.",
      "tldr_zh": "本文提出一种基于 Retrieval-Augmented Generation (RAG) 的方法，使用 Large Language Models (LLMs) 自动生成 Competency Questions (CQs)，以一组科学论文作为域知识基，从而减少传统依赖领域专家的手动制定过程的耗时和劳动力。研究在两个本体工程任务上使用 GPT-4 进行实验，比较了不同论文数量和温度设置的影响，并通过 precision 和 consistency 指标评估。结果显示，与 zero-shot prompting 相比，添加相关域知识显著提高了 LLMs 在 CQs 生成方面的性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.08820v2",
      "published_date": "2024-09-13 13:34:32 UTC",
      "updated_date": "2025-02-11 21:25:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:41:10.828784"
    },
    {
      "arxiv_id": "2409.08815v1",
      "title": "Deep reinforcement learning for tracking a moving target in jellyfish-like swimming",
      "title_zh": "翻译失败",
      "authors": [
        "Yihao Chen",
        "Yue Yang"
      ],
      "abstract": "We develop a deep reinforcement learning method for training a jellyfish-like\nswimmer to effectively track a moving target in a two-dimensional flow. This\nswimmer is a flexible object equipped with a muscle model based on torsional\nsprings. We employ a deep Q-network (DQN) that takes the swimmer's geometry and\ndynamic parameters as inputs, and outputs actions which are the forces applied\nto the swimmer. In particular, we introduce an action regulation to mitigate\nthe interference from complex fluid-structure interactions. The goal of these\nactions is to navigate the swimmer to a target point in the shortest possible\ntime. In the DQN training, the data on the swimmer's motions are obtained from\nsimulations conducted using the immersed boundary method. During tracking a\nmoving target, there is an inherent delay between the application of forces and\nthe corresponding response of the swimmer's body due to hydrodynamic\ninteractions between the shedding vortices and the swimmer's own locomotion.\nOur tests demonstrate that the swimmer, with the DQN agent and action\nregulation, is able to dynamically adjust its course based on its instantaneous\nstate. This work extends the application scope of machine learning in\ncontrolling flexible objects within fluid environments.",
      "tldr_zh": "该研究开发了一种深度强化学习（Deep Reinforcement Learning）方法，使用深度 Q 网络（DQN）训练一个类似水母的柔性游泳器（jellyfish-like swimmer）在二维流体环境中跟踪移动目标。游泳器基于扭转弹簧肌肉模型，DQN 以游泳器的几何和动态参数作为输入，输出施加的力，并引入行动调节（action regulation）来减少复杂流体-结构相互作用的干扰。训练数据来源于浸没边界方法（immersed boundary method）的模拟，成功处理了施加力和游泳器响应之间的延迟。实验结果显示，该游泳器能够根据即时状态动态调整路线，从而扩展了机器学习在控制流体环境中柔性物体的应用范围。",
      "categories": [
        "physics.flu-dyn",
        "cs.AI"
      ],
      "primary_category": "physics.flu-dyn",
      "comment": "22pages,14 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.08815v1",
      "published_date": "2024-09-13 13:29:46 UTC",
      "updated_date": "2024-09-13 13:29:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:41:23.917991"
    },
    {
      "arxiv_id": "2409.08811v1",
      "title": "Mutual Theory of Mind in Human-AI Collaboration: An Empirical Study with LLM-driven AI Agents in a Real-time Shared Workspace Task",
      "title_zh": "翻译失败",
      "authors": [
        "Shao Zhang",
        "Xihuai Wang",
        "Wenhao Zhang",
        "Yongshan Chen",
        "Landi Gao",
        "Dakuo Wang",
        "Weinan Zhang",
        "Xinbing Wang",
        "Ying Wen"
      ],
      "abstract": "Theory of Mind (ToM) significantly impacts human collaboration and\ncommunication as a crucial capability to understand others. When AI agents with\nToM capability collaborate with humans, Mutual Theory of Mind (MToM) arises in\nsuch human-AI teams (HATs). The MToM process, which involves interactive\ncommunication and ToM-based strategy adjustment, affects the team's performance\nand collaboration process. To explore the MToM process, we conducted a\nmixed-design experiment using a large language model-driven AI agent with ToM\nand communication modules in a real-time shared-workspace task. We find that\nthe agent's ToM capability does not significantly impact team performance but\nenhances human understanding of the agent and the feeling of being understood.\nMost participants in our study believe verbal communication increases human\nburden, and the results show that bidirectional communication leads to lower\nHAT performance. We discuss the results' implications for designing AI agents\nthat collaborate with humans in real-time shared workspace tasks.",
      "tldr_zh": "本研究探讨了Mutual Theory of Mind (MToM) 在人类-AI 协作中的作用，通过一个混合设计实验，使用LLM驱动的AI代理在实时共享工作空间任务中进行测试。结果显示，AI代理的Theory of Mind (ToM)能力并未显著提升Human-AI Teams (HATs)的整体绩效，但提高了人类对代理的理解和被理解的感觉；此外，大多数参与者认为双向沟通增加了人类负担，导致HATs绩效下降。该研究为设计实时协作AI代理提供了重要启示，以优化沟通策略和提升协作效率。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.HC",
      "comment": "34 pages, Preprint Under Review",
      "pdf_url": "http://arxiv.org/pdf/2409.08811v1",
      "published_date": "2024-09-13 13:19:48 UTC",
      "updated_date": "2024-09-13 13:19:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:41:35.262072"
    },
    {
      "arxiv_id": "2409.08806v2",
      "title": "TabKANet: Tabular Data Modeling with Kolmogorov-Arnold Network and Transformer",
      "title_zh": "翻译失败",
      "authors": [
        "Weihao Gao",
        "Zheng Gong",
        "Zhuo Deng",
        "Fuju Rong",
        "Chucheng Chen",
        "Lan Ma"
      ],
      "abstract": "Tabular data is the most common type of data in real-life scenarios. In this\nstudy, we propose the TabKANet model for tabular data modeling, which targets\nthe bottlenecks in learning from numerical content. We constructed a\nKolmogorov-Arnold Network (KAN) based Numerical Embedding Module and unified\nnumerical and categorical features encoding within a Transformer architecture.\nTabKANet has demonstrated stable and significantly superior performance\ncompared to Neural Networks (NNs) across multiple public datasets in binary\nclassification, multi-class classification, and regression tasks. Its\nperformance is comparable to or surpasses that of Gradient Boosted Decision\nTree models (GBDTs). Our code is publicly available on GitHub:\nhttps://github.com/AI-thpremed/TabKANet.",
      "tldr_zh": "这篇论文提出 TabKANet 模型，用于处理现实场景中最常见的表格数据建模问题，针对从数值内容中学习的瓶颈。模型通过构建基于 Kolmogorov-Arnold Network (KAN) 的数值嵌入模块，并将其与 Transformer 架构统一编码数值和分类特征。实验结果显示，TabKANet 在多个公共数据集上表现稳定，在二元分类、多类分类和回归任务中显著优于 Neural Networks (NNs)，并与 Gradient Boosted Decision Tree models (GBDTs) 相当或更优。代码已在 GitHub 上公开可用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages,5 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.08806v2",
      "published_date": "2024-09-13 13:14:54 UTC",
      "updated_date": "2024-10-02 06:22:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:41:46.894095"
    },
    {
      "arxiv_id": "2409.08798v1",
      "title": "Reading ability detection using eye-tracking data with LSTM-based few-shot learning",
      "title_zh": "翻译失败",
      "authors": [
        "Nanxi Li",
        "Hongjiang Wang",
        "Zehui Zhan"
      ],
      "abstract": "Reading ability detection is important in modern educational field. In this\npaper, a method of predicting scores of reading ability is proposed, using the\neye-tracking data of a few subjects (e.g., 68 subjects). The proposed method\nbuilt a regression model for the score prediction by combining Long Short Time\nMemory (LSTM) and light-weighted neural networks. Experiments show that with\nfew-shot learning strategy, the proposed method achieved higher accuracy than\nprevious methods of score prediction in reading ability detection. The code can\nlater be downloaded at\nhttps://github.com/pumpkinLNX/LSTM-eye-tracking-pytorch.git",
      "tldr_zh": "这篇论文提出了一种使用眼动追踪数据预测阅读能力分数的模型，结合LSTM和轻量级神经网络构建回归模型，并采用few-shot learning策略，仅需少量受试者（如68人）即可实现高效预测。实验结果表明，该方法在阅读能力检测中比现有方法取得了更高的准确性。代码已开源在GitHub上，方便后续研究和应用。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.08798v1",
      "published_date": "2024-09-13 13:06:01 UTC",
      "updated_date": "2024-09-13 13:06:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:41:57.680454"
    },
    {
      "arxiv_id": "2409.08775v3",
      "title": "What Should We Engineer in Prompts? Training Humans in Requirement-Driven LLM Use",
      "title_zh": "翻译失败",
      "authors": [
        "Qianou Ma",
        "Weirui Peng",
        "Chenyang Yang",
        "Hua Shen",
        "Kenneth Koedinger",
        "Tongshuang Wu"
      ],
      "abstract": "Prompting LLMs for complex tasks (e.g., building a trip advisor chatbot)\nneeds humans to clearly articulate customized requirements (e.g., \"start the\nresponse with a tl;dr\"). However, existing prompt engineering instructions\noften lack focused training on requirement articulation and instead tend to\nemphasize increasingly automatable strategies (e.g., tricks like adding\nrole-plays and \"think step-by-step\"). To address the gap, we introduce\nRequirement-Oriented Prompt Engineering (ROPE), a paradigm that focuses human\nattention on generating clear, complete requirements during prompting. We\nimplement ROPE through an assessment and training suite that provides\ndeliberate practice with LLM-generated feedback. In a randomized controlled\nexperiment with 30 novices, ROPE significantly outperforms conventional prompt\nengineering training (20% vs. 1% gains), a gap that automatic prompt\noptimization cannot close. Furthermore, we demonstrate a direct correlation\nbetween the quality of input requirements and LLM outputs. Our work paves the\nway to empower more end-users to build complex LLM applications.",
      "tldr_zh": "这篇论文针对提示大型语言模型（LLMs）进行复杂任务（如构建旅行顾问聊天机器人）的挑战，提出了一种基于需求的提示工程范式（Requirement-Oriented Prompt Engineering, ROPE），强调训练人类清晰表达定制化要求（如“以 TL;DR 开头”）。ROPE 通过评估和训练套件提供 deliberate practice 和 LLM 生成反馈，帮助用户专注于生成完整需求。实验结果显示，ROPE 在随机对照试验中显著优于传统提示工程训练（20% vs. 1% 收益），且自动提示优化无法弥补这一差距。论文还证明了输入要求质量与 LLM 输出质量的直接相关性，为赋能更多终端用户构建复杂 LLM 应用铺平道路。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "15 pages; TOCHI 2025",
      "pdf_url": "http://arxiv.org/pdf/2409.08775v3",
      "published_date": "2024-09-13 12:34:14 UTC",
      "updated_date": "2025-04-28 16:07:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:42:10.933567"
    },
    {
      "arxiv_id": "2409.08767v2",
      "title": "HOLA-Drone: Hypergraphic Open-ended Learning for Zero-Shot Multi-Drone Cooperative Pursuit",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Li",
        "Dengyu Zhang",
        "Junfan Chen",
        "Ying Wen",
        "Qingrui Zhang",
        "Shaoshuai Mou",
        "Wei Pan"
      ],
      "abstract": "Zero-shot coordination (ZSC) is a significant challenge in multi-agent\ncollaboration, aiming to develop agents that can coordinate with unseen\npartners they have not encountered before. Recent cutting-edge ZSC methods have\nprimarily focused on two-player video games such as OverCooked!2 and Hanabi. In\nthis paper, we extend the scope of ZSC research to the multi-drone cooperative\npursuit scenario, exploring how to construct a drone agent capable of\ncoordinating with multiple unseen partners to capture multiple evaders. We\npropose a novel Hypergraphic Open-ended Learning Algorithm (HOLA-Drone) that\ncontinuously adapts the learning objective based on our hypergraphic-form game\nmodeling, aiming to improve cooperative abilities with multiple unknown drone\nteammates. To empirically verify the effectiveness of HOLA-Drone, we build two\ndifferent unseen drone teammate pools to evaluate their performance in\ncoordination with various unseen partners. The experimental results demonstrate\nthat HOLA-Drone outperforms the baseline methods in coordination with unseen\ndrone teammates. Furthermore, real-world experiments validate the feasibility\nof HOLA-Drone in physical systems. Videos can be found on the project\nhomepage~\\url{https://sites.google.com/view/hola-drone}.",
      "tldr_zh": "该研究将零样本协调（Zero-shot coordination, ZSC）扩展到多无人机合作追逐场景，旨在开发能与未知队友协调的无人机代理。论文提出HOLA-Drone，一种基于超图形式游戏建模（hypergraphic-form game modeling）的开放式学习算法，能够动态调整学习目标以提升与多个未知无人机队友的合作能力。通过构建不同队友池进行实验，HOLA-Drone在协调性能上比基线方法表现出色，并在真实世界实验中验证了其可行性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.08767v2",
      "published_date": "2024-09-13 12:20:04 UTC",
      "updated_date": "2024-10-01 14:46:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:42:21.841199"
    },
    {
      "arxiv_id": "2409.08761v1",
      "title": "Journalists, Emotions, and the Introduction of Generative AI Chatbots: A Large-Scale Analysis of Tweets Before and After the Launch of ChatGPT",
      "title_zh": "翻译失败",
      "authors": [
        "Seth C. Lewis",
        "David M. Markowitz",
        "Jon Benedik Bunquin"
      ],
      "abstract": "As part of a broader look at the impact of generative AI, this study\ninvestigated the emotional responses of journalists to the release of ChatGPT\nat the time of its launch. By analyzing nearly 1 million Tweets from\njournalists at major U.S. news outlets, we tracked changes in emotional tone\nand sentiment before and after the introduction of ChatGPT in November 2022.\nUsing various computational and natural language processing techniques to\nmeasure emotional shifts in response to ChatGPT's release, we found an increase\nin positive emotion and a more favorable tone post-launch, suggesting initial\noptimism toward AI's potential. This research underscores the pivotal role of\njournalists as interpreters of technological innovation and disruption,\nhighlighting how their emotional reactions may shape public narratives around\nemerging technologies. The study contributes to understanding the intersection\nof journalism, emotion, and AI, offering insights into the broader societal\nimpact of generative AI tools.",
      "tldr_zh": "这篇论文通过分析近 100 万条来自美国主要新闻机构的记者 Tweets，研究了 ChatGPT 发布前后（2022 年 11 月）的情绪反应和情感语气变化。使用 computational 和 natural language processing 技术，研究发现发布后记者的正面情绪和积极语气显著增加，反映出对 generative AI 潜力的初步乐观。该研究强调了记者在解释技术创新中的关键角色，并为 journalism, emotion 和 AI 的交叉点提供了重要洞见，揭示了 generative AI 工具的社会影响。",
      "categories": [
        "cs.CC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.08761v1",
      "published_date": "2024-09-13 12:09:20 UTC",
      "updated_date": "2024-09-13 12:09:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:42:34.352853"
    },
    {
      "arxiv_id": "2409.08732v1",
      "title": "Bridging Dynamic Factor Models and Neural Controlled Differential Equations for Nowcasting GDP",
      "title_zh": "翻译失败",
      "authors": [
        "Seonkyu Lim",
        "Jeongwhan Choi",
        "Noseong Park",
        "Sang-Ha Yoon",
        "ShinHyuck Kang",
        "Young-Min Kim",
        "Hyunjoong Kang"
      ],
      "abstract": "Gross domestic product (GDP) nowcasting is crucial for policy-making as GDP\ngrowth is a key indicator of economic conditions. Dynamic factor models (DFMs)\nhave been widely adopted by government agencies for GDP nowcasting due to their\nability to handle irregular or missing macroeconomic indicators and their\ninterpretability. However, DFMs face two main challenges: i) the lack of\ncapturing economic uncertainties such as sudden recessions or booms, and ii)\nthe limitation of capturing irregular dynamics from mixed-frequency data. To\naddress these challenges, we introduce NCDENow, a novel GDP nowcasting\nframework that integrates neural controlled differential equations (NCDEs) with\nDFMs. This integration effectively handles the dynamics of irregular time\nseries. NCDENow consists of 3 main modules: i) factor extraction leveraging\nDFM, ii) dynamic modeling using NCDE, and iii) GDP growth prediction through\nregression. We evaluate NCDENow against 6 baselines on 2 real-world GDP\ndatasets from South Korea and the United Kingdom, demonstrating its enhanced\npredictive capability. Our empirical results favor our method, highlighting the\nsignificant potential of integrating NCDE into nowcasting models. Our code and\ndataset are available at https://github.com/sklim84/NCDENow_CIKM2024.",
      "tldr_zh": "该研究提出NCDENow框架，将动态因子模型(DFMs)和神经控制微分方程(NCDEs)整合，用于GDP预测，以解决DFMs在处理经济不确定性和不规则动态数据方面的局限性。框架包括三个模块：因子提取基于DFM、动态建模使用NCDE，以及通过回归进行GDP增长预测。在韩国和英国的真实数据集上，NCDENow与6个基线模型相比，展示了显著的预测能力提升，证明了这种整合方法的有效性。研究还提供了代码和数据集，供进一步验证。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at CIKM 2024. Seonkyu Lim and Jeongwhan Choi are co-first\n  authors with equal contributions",
      "pdf_url": "http://arxiv.org/pdf/2409.08732v1",
      "published_date": "2024-09-13 11:33:57 UTC",
      "updated_date": "2024-09-13 11:33:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:42:46.978065"
    },
    {
      "arxiv_id": "2409.08724v1",
      "title": "Quasimetric Value Functions with Dense Rewards",
      "title_zh": "翻译失败",
      "authors": [
        "Khadichabonu Valieva",
        "Bikramjit Banerjee"
      ],
      "abstract": "As a generalization of reinforcement learning (RL) to parametrizable goals,\ngoal conditioned RL (GCRL) has a broad range of applications, particularly in\nchallenging tasks in robotics. Recent work has established that the optimal\nvalue function of GCRL $Q^\\ast(s,a,g)$ has a quasimetric structure, leading to\ntargetted neural architectures that respect such structure. However, the\nrelevant analyses assume a sparse reward setting -- a known aggravating factor\nto sample complexity. We show that the key property underpinning a quasimetric,\nviz., the triangle inequality, is preserved under a dense reward setting as\nwell. Contrary to earlier findings where dense rewards were shown to be\ndetrimental to GCRL, we identify the key condition necessary for triangle\ninequality. Dense reward functions that satisfy this condition can only\nimprove, never worsen, sample complexity. This opens up opportunities to train\nefficient neural architectures with dense rewards, compounding their benefits\nto sample complexity. We evaluate this proposal in 12 standard benchmark\nenvironments in GCRL featuring challenging continuous control tasks. Our\nempirical results confirm that training a quasimetric value function in our\ndense reward setting indeed outperforms training with sparse rewards.",
      "tldr_zh": "该论文探讨了目标条件强化学习(GCRL)在密集奖励设置下的应用，证明了最优价值函数的准度量(quasimetric)结构——即三角不等式(triangle inequality)——同样适用于密集奖励环境，前提是奖励函数满足特定条件。\n这与先前研究相反，论文指出，符合条件的密集奖励能改善样本复杂度，而不是恶化。\n通过在12个GCRL基准环境中进行实验，研究者发现，使用准度量价值函数的神经架构训练密集奖励模型，其性能明显优于稀疏奖励设置。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.08724v1",
      "published_date": "2024-09-13 11:26:05 UTC",
      "updated_date": "2024-09-13 11:26:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:42:58.927577"
    },
    {
      "arxiv_id": "2409.08719v1",
      "title": "Distilling Monolingual and Crosslingual Word-in-Context Representations",
      "title_zh": "蒸馏单语和跨语言上下文单词表示",
      "authors": [
        "Yuki Arase",
        "Tomoyuki Kajiwara"
      ],
      "abstract": "In this study, we propose a method that distils representations of word\nmeaning in context from a pre-trained masked language model in both monolingual\nand crosslingual settings. Word representations are the basis for context-aware\nlexical semantics and unsupervised semantic textual similarity (STS)\nestimation. Different from existing approaches, our method does not require\nhuman-annotated corpora nor updates of the parameters of the pre-trained model.\nThe latter feature is appealing for practical scenarios where the off-the-shelf\npre-trained model is a common asset among different applications. Specifically,\nour method learns to combine the outputs of different hidden layers of the\npre-trained model using self-attention. Our auto-encoder based training only\nrequires an automatically generated corpus. To evaluate the performance of the\nproposed approach, we performed extensive experiments using various benchmark\ntasks. The results on the monolingual tasks confirmed that our representations\nexhibited a competitive performance compared to that of the previous study for\nthe context-aware lexical semantic tasks and outperformed it for STS\nestimation. The results of the crosslingual tasks revealed that the proposed\nmethod largely improved crosslingual word representations of multilingual\npre-trained models.",
      "tldr_zh": "本研究提出了一种方法，用于从预训练的masked language model中提炼单语和跨语境单词表示，而无需依赖人工标注语料库或更新模型参数。方法通过self-attention机制结合模型的不同隐藏层输出，并在基于自编码器的自动生成语料库上进行训练，从而实现上下文感知的词汇语义表示。实验结果显示，该方法在单语任务中与现有研究相当，并在semantic textual similarity (STS)估计上表现出色；在跨语境任务中，它显著提升了多语预训练模型的单词表示性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.08719v1",
      "published_date": "2024-09-13 11:10:16 UTC",
      "updated_date": "2024-09-13 11:10:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:43:21.440961"
    },
    {
      "arxiv_id": "2409.08712v1",
      "title": "Layerwise Change of Knowledge in Neural Networks",
      "title_zh": "神经网络中知识的逐层变化",
      "authors": [
        "Xu Cheng",
        "Lei Cheng",
        "Zhaoran Peng",
        "Yang Xu",
        "Tian Han",
        "Quanshi Zhang"
      ],
      "abstract": "This paper aims to explain how a deep neural network (DNN) gradually extracts\nnew knowledge and forgets noisy features through layers in forward propagation.\nUp to now, although the definition of knowledge encoded by the DNN has not\nreached a consensus, Previous studies have derived a series of mathematical\nevidence to take interactions as symbolic primitive inference patterns encoded\nby a DNN. We extend the definition of interactions and, for the first time,\nextract interactions encoded by intermediate layers. We quantify and track the\nnewly emerged interactions and the forgotten interactions in each layer during\nthe forward propagation, which shed new light on the learning behavior of DNNs.\nThe layer-wise change of interactions also reveals the change of the\ngeneralization capacity and instability of feature representations of a DNN.",
      "tldr_zh": "本论文探讨了深度神经网络(DNN)在正向传播过程中如何逐层提取新知识并遗忘噪声特征，通过扩展交互(interactions)的定义首次从中间层提取这些交互。研究者量化并跟踪每层的交互变化，揭示了DNN的学习行为及其演变。结果显示，这种层级交互变化反映了DNN的泛化能力(generalization capacity)和特征表示的不稳定性(instability)，为理解神经网络的内部机制提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.08712v1",
      "published_date": "2024-09-13 10:59:24 UTC",
      "updated_date": "2024-09-13 10:59:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:43:35.553046"
    },
    {
      "arxiv_id": "2409.08711v1",
      "title": "Text-To-Speech Synthesis In The Wild",
      "title_zh": "野外文本到语音合成",
      "authors": [
        "Jee-weon Jung",
        "Wangyou Zhang",
        "Soumi Maiti",
        "Yihan Wu",
        "Xin Wang",
        "Ji-Hoon Kim",
        "Yuta Matsunaga",
        "Seyun Um",
        "Jinchuan Tian",
        "Hye-jin Shim",
        "Nicholas Evans",
        "Joon Son Chung",
        "Shinnosuke Takamichi",
        "Shinji Watanabe"
      ],
      "abstract": "Text-to-speech (TTS) systems are traditionally trained using modest databases\nof studio-quality, prompted or read speech collected in benign acoustic\nenvironments such as anechoic rooms. The recent literature nonetheless shows\nefforts to train TTS systems using data collected in the wild. While this\napproach allows for the use of massive quantities of natural speech, until now,\nthere are no common datasets. We introduce the TTS In the Wild (TITW) dataset,\nthe result of a fully automated pipeline, in this case, applied to the\nVoxCeleb1 dataset commonly used for speaker recognition. We further propose two\ntraining sets. TITW-Hard is derived from the transcription, segmentation, and\nselection of VoxCeleb1 source data. TITW-Easy is derived from the additional\napplication of enhancement and additional data selection based on DNSMOS. We\nshow that a number of recent TTS models can be trained successfully using\nTITW-Easy, but that it remains extremely challenging to produce similar results\nusing TITW-Hard. Both the dataset and protocols are publicly available and\nsupport the benchmarking of TTS systems trained using TITW data.",
      "tldr_zh": "本论文探讨了在野外环境中训练文本到语音（Text-to-Speech, TTS）系统的挑战，传统方法依赖于高质量的受控语音数据。研究者引入了TTS In the Wild (TITW)数据集，通过自动化管道从VoxCeleb1数据集处理而来，并提出两个训练集：TITW-Hard（基于转录、分割和选择）和TITW-Easy（添加增强及基于DNSMOS的数据筛选）。实验结果显示，多种现代TTS模型能成功使用TITW-Easy训练，但TITW-Hard训练难度极高。该数据集及其协议已公开，以支持TTS系统的基准测试和进一步研究。",
      "categories": [
        "eess.AS",
        "cs.AI"
      ],
      "primary_category": "eess.AS",
      "comment": "5 pages, submitted to ICASSP 2025 as a conference paper",
      "pdf_url": "http://arxiv.org/pdf/2409.08711v1",
      "published_date": "2024-09-13 10:58:55 UTC",
      "updated_date": "2024-09-13 10:58:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:43:55.005641"
    },
    {
      "arxiv_id": "2409.08703v1",
      "title": "NeSHFS: Neighborhood Search with Heuristic-based Feature Selection for Click-Through Rate Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Dogukan Aksu",
        "Ismail Hakki Toroslu",
        "Hasan Davulcu"
      ],
      "abstract": "Click-through-rate (CTR) prediction plays an important role in online\nadvertising and ad recommender systems. In the past decade, maximizing CTR has\nbeen the main focus of model development and solution creation. Therefore,\nresearchers and practitioners have proposed various models and solutions to\nenhance the effectiveness of CTR prediction. Most of the existing literature\nfocuses on capturing either implicit or explicit feature interactions. Although\nimplicit interactions are successfully captured in some studies, explicit\ninteractions present a challenge for achieving high CTR by extracting both\nlow-order and high-order feature interactions. Unnecessary and irrelevant\nfeatures may cause high computational time and low prediction performance.\nFurthermore, certain features may perform well with specific predictive models\nwhile underperforming with others. Also, feature distribution may fluctuate due\nto traffic variations. Most importantly, in live production environments,\nresources are limited, and the time for inference is just as crucial as\ntraining time. Because of all these reasons, feature selection is one of the\nmost important factors in enhancing CTR prediction model performance. Simple\nfilter-based feature selection algorithms do not perform well and they are not\nsufficient. An effective and efficient feature selection algorithm is needed to\nconsistently filter the most useful features during live CTR prediction\nprocess. In this paper, we propose a heuristic algorithm named Neighborhood\nSearch with Heuristic-based Feature Selection (NeSHFS) to enhance CTR\nprediction performance while reducing dimensionality and training time costs.\nWe conduct comprehensive experiments on three public datasets to validate the\nefficiency and effectiveness of our proposed solution.",
      "tldr_zh": "该论文探讨了点击率(CTR)预测中的特征选择问题，指出现有方法在捕捉显式特征交互时面临高计算成本和性能下降的挑战。作者提出NeSHFS算法，该算法结合邻域搜索(Neighborhood Search)和基于启发式的特征选择机制，以有效筛选有用特征，降低维度并减少训练时间。实验结果显示，NeSHFS在三个公共数据集上显著提升了CTR预测性能，验证了其在实时广告推荐系统中的实用价值。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.08703v1",
      "published_date": "2024-09-13 10:43:18 UTC",
      "updated_date": "2024-09-13 10:43:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:43:56.115790"
    },
    {
      "arxiv_id": "2409.08702v1",
      "title": "DM: Dual-path Magnitude Network for General Speech Restoration",
      "title_zh": "翻译失败",
      "authors": [
        "Da-Hee Yang",
        "Dail Kim",
        "Joon-Hyuk Chang",
        "Jeonghwan Choi",
        "Han-gil Moon"
      ],
      "abstract": "In this paper, we introduce a novel general speech restoration model: the\nDual-path Magnitude (DM) network, designed to address multiple distortions\nincluding noise, reverberation, and bandwidth degradation effectively. The DM\nnetwork employs dual parallel magnitude decoders that share parameters: one\nuses a masking-based algorithm for distortion removal and the other employs a\nmapping-based approach for speech restoration. A novel aspect of the DM network\nis the integration of the magnitude spectrogram output from the masking decoder\ninto the mapping decoder through a skip connection, enhancing the overall\nrestoration capability. This integrated approach overcomes the inherent\nlimitations observed in previous models, as detailed in a step-by-step\nanalysis. The experimental results demonstrate that the DM network outperforms\nother baseline models in the comprehensive aspect of general speech\nrestoration, achieving substantial restoration with fewer parameters.",
      "tldr_zh": "本文提出了一种新型通用语音恢复模型：Dual-path Magnitude (DM) 网络，用于有效处理噪声、混响和带宽退化等多种失真。DM 网络采用两个共享参数的并行大小谱解码器，其中一个基于 masking-based 算法去除失真，另一个基于 mapping-based 方法进行语音恢复，并通过跳跃连接将 masking 解码器的输出整合到 mapping 解码器中，以提升整体性能。实验结果显示，DM 网络在综合语音恢复方面优于基线模型，实现了更显著的恢复效果，同时使用了更少的参数。",
      "categories": [
        "eess.AS",
        "cs.AI"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.08702v1",
      "published_date": "2024-09-13 10:42:59 UTC",
      "updated_date": "2024-09-13 10:42:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:44:09.177766"
    },
    {
      "arxiv_id": "2409.08695v3",
      "title": "Precision Aquaculture: An Integrated Computer Vision and IoT Approach for Optimized Tilapia Feeding",
      "title_zh": "翻译失败",
      "authors": [
        "Rania Hossam",
        "Ahmed Heakl",
        "Walid Gomaa"
      ],
      "abstract": "Traditional fish farming practices often lead to inefficient feeding,\nresulting in environmental issues and reduced productivity. We developed an\ninnovative system combining computer vision and IoT technologies for precise\nTilapia feeding. Our solution uses real-time IoT sensors to monitor water\nquality parameters and computer vision algorithms to analyze fish size and\ncount, determining optimal feed amounts. A mobile app enables remote monitoring\nand control. We utilized YOLOv8 for keypoint detection to measure Tilapia\nweight from length, achieving \\textbf{94\\%} precision on 3,500 annotated\nimages. Pixel-based measurements were converted to centimeters using depth\nestimation for accurate feeding calculations. Our method, with data collection\nmirroring inference conditions, significantly improved results. Preliminary\nestimates suggest this approach could increase production up to 58 times\ncompared to traditional farms. Our models, code, and dataset are\nopen-source~\\footnote{The code, dataset, and models are available upon\nreasonable request.",
      "tldr_zh": "本研究针对传统鱼类养殖的低效问题，提出了一种整合计算机视觉和 IoT 技术的精准养鱼系统，用于优化 Tilapia 喂养。该系统利用 IoT 传感器实时监控水质参数，并采用 YOLOv8 算法进行关键点检测，分析鱼类大小和数量，并通过深度估计将像素测量转换为厘米，以精确计算饲料量。实验结果显示，该方法在 3500 张标注图像上达到了 94% 的精度，并显著提升了生产效率，初步估计可将产量提高至传统方法的 58 倍。该系统还包括移动 app 进行远程监控，并开源了模型、代码和数据集。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 6 figures, 3 tables, 21th International Conference on\n  Informatics in Control, Automation, and Robotics",
      "pdf_url": "http://arxiv.org/pdf/2409.08695v3",
      "published_date": "2024-09-13 10:27:27 UTC",
      "updated_date": "2024-09-25 03:34:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:44:21.170889"
    },
    {
      "arxiv_id": "2409.08692v1",
      "title": "B4: Towards Optimal Assessment of Plausible Code Solutions with Plausible Tests",
      "title_zh": "翻译失败",
      "authors": [
        "Mouxiang Chen",
        "Zhongxin Liu",
        "He Tao",
        "Yusu Hong",
        "David Lo",
        "Xin Xia",
        "Jianling Sun"
      ],
      "abstract": "Selecting the best code solution from multiple generated ones is an essential\ntask in code generation, which can be achieved by using some reliable\nvalidators (e.g., developer-written test cases) for assistance. Since reliable\ntest cases are not always available and can be expensive to build in practice,\nresearchers propose to automatically generate test cases to assess code\nsolutions. However, when both code solutions and test cases are plausible and\nnot reliable, selecting the best solution becomes challenging. Although some\nheuristic strategies have been proposed to tackle this problem, they lack a\nstrong theoretical guarantee and it is still an open question whether an\noptimal selection strategy exists. Our work contributes in two ways. First, we\nshow that within a Bayesian framework, the optimal selection strategy can be\ndefined based on the posterior probability of the observed passing states\nbetween solutions and tests. The problem of identifying the best solution is\nthen framed as an integer programming problem. Second, we propose an efficient\napproach for approximating this optimal (yet uncomputable) strategy, where the\napproximation error is bounded by the correctness of prior knowledge. We then\nincorporate effective prior knowledge to tailor code generation tasks. Both\ntheoretical and empirical studies confirm that existing heuristics are limited\nin selecting the best solutions with plausible test cases. Our proposed\napproximated optimal strategy B4 significantly surpasses existing heuristics in\nselecting code solutions generated by large language models (LLMs) with\nLLM-generated tests, achieving a relative performance improvement by up to 50%\nover the strongest heuristic and 246% over the random selection in the most\nchallenging scenarios. Our code is publicly available at\nhttps://github.com/ZJU-CTAG/B4.",
      "tldr_zh": "该研究针对代码生成任务中从多个可信度不高的代码解决方案中选择最佳方案的问题，提出了一种基于贝叶斯框架（Bayesian framework）的优化策略。首先，将问题建模为基于解决方案和测试通过状态的后验概率（posterior probability），并转化为整数规划（integer programming）问题，以定义最优选择策略。其次，引入高效的近似方法 B4，通过整合有效的先验知识来降低计算复杂度，并控制近似误差。实验结果显示，B4 在使用大型语言模型（LLMs）生成代码和测试的场景中，性能较现有启发式方法提升高达 50%，并在最 challenging 情况下比随机选择提升 246%，证明了其有效性。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "accepted by ASE' 24 (full paper)",
      "pdf_url": "http://arxiv.org/pdf/2409.08692v1",
      "published_date": "2024-09-13 10:22:08 UTC",
      "updated_date": "2024-09-13 10:22:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:44:43.425982"
    },
    {
      "arxiv_id": "2409.08680v1",
      "title": "NEST-RQ: Next Token Prediction for Speech Self-Supervised Pre-Training",
      "title_zh": "NEST-RQ：用于语音自监督预训练的下一个标记预测",
      "authors": [
        "Minglun Han",
        "Ye Bai",
        "Chen Shen",
        "Youjia Huang",
        "Mingkun Huang",
        "Zehua Lin",
        "Linhao Dong",
        "Lu Lu",
        "Yuxuan Wang"
      ],
      "abstract": "Speech self-supervised pre-training can effectively improve the performance\nof downstream tasks. However, previous self-supervised learning (SSL) methods\nfor speech, such as HuBERT and BEST-RQ, focus on utilizing non-causal encoders\nwith bidirectional context, and lack sufficient support for downstream\nstreaming models. To address this issue, we introduce the next token prediction\nbased speech pre-training method with random-projection quantizer (NEST-RQ).\nNEST-RQ employs causal encoders with only left context and uses next token\nprediction (NTP) as the training task. On the large-scale dataset, compared to\nBEST-RQ, the proposed NEST-RQ achieves comparable performance on non-streaming\nautomatic speech recognition (ASR) and better performance on streaming ASR. We\nalso conduct analytical experiments in terms of the future context size of\nstreaming ASR, the codebook quality of SSL and the model size of the encoder.\nIn summary, the paper demonstrates the feasibility of the NTP in speech SSL and\nprovides empirical evidence and insights for speech SSL research.",
      "tldr_zh": "本研究提出了一种基于下一个标记预测（Next Token Prediction, NTP）的语音自监督预训练（Speech Self-Supervised Pre-Training）方法，名为 NEST-RQ，使用随机投影量化器（random-projection quantizer）和因果编码器（causal encoders），以解决现有方法如 HuBERT 和 BEST-RQ 在支持下游流式模型（streaming models）方面的不足。NEST-RQ 仅依赖左侧上下文进行训练，并在大规模数据集上实验中显示，与 BEST-RQ 相比，在非流式自动语音识别（ASR）上性能相当，但在流式 ASR 上取得了更好的结果。研究还通过分析未来上下文大小、代码本质量和编码器模型大小的实验，提供实证证据，证明 NTP 在语音自监督学习中的可行性，并为相关研究带来新见解。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "eess.AS",
      "comment": "5 pages, 2 figures, Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2409.08680v1",
      "published_date": "2024-09-13 09:48:11 UTC",
      "updated_date": "2024-09-13 09:48:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:44:45.904003"
    },
    {
      "arxiv_id": "2409.08678v2",
      "title": "Shadow Program Inversion with Differentiable Planning: A Framework for Unified Robot Program Parameter and Trajectory Optimization",
      "title_zh": "基于可微规划",
      "authors": [
        "Benjamin Alt",
        "Claudius Kienle",
        "Darko Katic",
        "Rainer Jäkel",
        "Michael Beetz"
      ],
      "abstract": "This paper presents SPI-DP, a novel first-order optimizer capable of\noptimizing robot programs with respect to both high-level task objectives and\nmotion-level constraints. To that end, we introduce DGPMP2-ND, a differentiable\ncollision-free motion planner for serial N-DoF kinematics, and integrate it\ninto an iterative, gradient-based optimization approach for generic,\nparameterized robot program representations. SPI-DP allows first-order\noptimization of planned trajectories and program parameters with respect to\nobjectives such as cycle time or smoothness subject to e.g. collision\nconstraints, while enabling humans to understand, modify or even certify the\noptimized programs. We provide a comprehensive evaluation on two practical\nhousehold and industrial applications.",
      "tldr_zh": "这篇论文提出了 SPI-DP，一种新颖的第一阶优化器，用于统一优化机器人程序的参数和轨迹，以满足高层次任务目标（如周期时间或平滑度）和运动层次约束（如碰撞约束）。他们引入了 DGPMP2-ND，一个可微分的无碰撞运动规划器，适用于串联 N-DoF 运动学，并将其整合到迭代的梯度优化框架中。SPI-DP 不仅支持对规划轨迹和程序参数的优化，还允许人类理解、修改或认证这些程序。论文通过在两个实际的家庭和工业应用中进行全面评估，展示了框架的有效性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "68T40",
        "I.2; D.1"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 6 figures, accepted at the 2025 IEEE International\n  Conference on Robotics & Automation (ICRA)",
      "pdf_url": "http://arxiv.org/pdf/2409.08678v2",
      "published_date": "2024-09-13 09:46:41 UTC",
      "updated_date": "2025-02-12 15:18:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:44:57.314014"
    },
    {
      "arxiv_id": "2409.08666v1",
      "title": "Towards certifiable AI in aviation: landscape, challenges, and opportunities",
      "title_zh": "翻译失败",
      "authors": [
        "Hymalai Bello",
        "Daniel Geißler",
        "Lala Ray",
        "Stefan Müller-Divéky",
        "Peter Müller",
        "Shannon Kittrell",
        "Mengxi Liu",
        "Bo Zhou",
        "Paul Lukowicz"
      ],
      "abstract": "Artificial Intelligence (AI) methods are powerful tools for various domains,\nincluding critical fields such as avionics, where certification is required to\nachieve and maintain an acceptable level of safety. General solutions for\nsafety-critical systems must address three main questions: Is it suitable? What\ndrives the system's decisions? Is it robust to errors/attacks? This is more\ncomplex in AI than in traditional methods. In this context, this paper presents\na comprehensive mind map of formal AI certification in avionics. It highlights\nthe challenges of certifying AI development with an example to emphasize the\nneed for qualification beyond performance metrics.",
      "tldr_zh": "这篇论文探讨了AI在航空(avionics)领域的可认证性，包括当前景观、挑战和机会，强调AI系统需回答是否合适、决策驱动因素以及对错误/攻击的鲁棒性等问题，以确保安全。论文呈现了一个全面的AI认证思维导图，突出了AI开发相比传统方法的复杂性，并通过示例说明了仅依赖性能指标的局限性。最终，它呼吁采用更全面的资格评估框架，以推动AI在航空领域的可靠应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.08666v1",
      "published_date": "2024-09-13 09:27:59 UTC",
      "updated_date": "2024-09-13 09:27:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:45:09.271519"
    },
    {
      "arxiv_id": "2409.08655v1",
      "title": "LMAC-TD: Producing Time Domain Explanations for Audio Classifiers",
      "title_zh": "翻译失败",
      "authors": [
        "Eleonora Mancini",
        "Francesco Paissan",
        "Mirco Ravanelli",
        "Cem Subakan"
      ],
      "abstract": "Neural networks are typically black-boxes that remain opaque with regards to\ntheir decision mechanisms. Several works in the literature have proposed\npost-hoc explanation methods to alleviate this issue. This paper proposes\nLMAC-TD, a post-hoc explanation method that trains a decoder to produce\nexplanations directly in the time domain. This methodology builds upon the\nfoundation of L-MAC, Listenable Maps for Audio Classifiers, a method that\nproduces faithful and listenable explanations. We incorporate SepFormer, a\npopular transformer-based time-domain source separation architecture. We show\nthrough a user study that LMAC-TD significantly improves the audio quality of\nthe produced explanations while not sacrificing from faithfulness.",
      "tldr_zh": "该论文提出 LMAC-TD，一种后验解释方法，用于为音频分类器生成时域解释，以解决神经网络决策机制不透明的问题。LMAC-TD 基于 L-MAC 框架，并使用 SepFormer（一种基于 Transformer 的时域源分离架构）训练解码器，从而产生忠实且可听的解释。通过用户研究，LMAC-TD 显著提高了解释的音频质量，同时不牺牲 faithfulness（忠实度）。这为音频模型的可解释性提供了新的改进路径。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS",
        "eess.SP"
      ],
      "primary_category": "cs.SD",
      "comment": "The first two authors contributed equally to this research. Author\n  order is alphabetical",
      "pdf_url": "http://arxiv.org/pdf/2409.08655v1",
      "published_date": "2024-09-13 09:14:06 UTC",
      "updated_date": "2024-09-13 09:14:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:45:20.267841"
    },
    {
      "arxiv_id": "2409.08642v2",
      "title": "CPL: Critical Plan Step Learning Boosts LLM Generalization in Reasoning Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Tianlong Wang",
        "Junzhe Chen",
        "Xueting Han",
        "Jing Bai"
      ],
      "abstract": "Post-training, particularly reinforcement learning (RL) using\nself-play-generated data, has become a new learning paradigm for large language\nmodels (LLMs). However, scaling RL to develop a general reasoner remains a\nresearch challenge, as existing methods focus on task-specific reasoning\nwithout adequately addressing generalization across a broader range of tasks.\nMoreover, unlike traditional RL with limited action space, LLMs operate in an\ninfinite space, making it crucial to search for valuable and diverse strategies\nto solve problems effectively. To address this, we propose searching within the\naction space on high-level abstract plans to enhance model generalization and\nintroduce Critical Plan Step Learning (CPL), comprising: 1) searching on plan,\nusing Monte Carlo Tree Search (MCTS) to explore diverse plan steps in\nmulti-step reasoning tasks, and 2) learning critical plan steps through\nStep-level Advantage Preference Optimization (Step-APO), which integrates\nadvantage estimates for step preference obtained via MCTS into Direct\nPreference Optimization (DPO). This combination helps the model effectively\nlearn critical plan steps, enhancing both reasoning capabilities and\ngeneralization. Experimental results demonstrate that our method, trained\nexclusively on GSM8K and MATH, not only significantly improves performance on\nGSM8K (+10.5%) and MATH (+6.5%), but also enhances out-of-domain reasoning\nbenchmarks, such as HumanEval (+12.2%), GPQA (+8.6%), ARC-C (+4.0%), MMLU-STEM\n(+2.2%), and BBH (+1.8%).",
      "tldr_zh": "该研究提出 Critical Plan Step Learning (CPL) 方法，以提升大型语言模型 (LLMs) 在推理任务中的泛化能力，解决现有强化学习 (RL) 方法偏向任务特定训练的问题。CPL 包括在高层抽象计划上进行搜索，使用 Monte Carlo Tree Search (MCTS) 探索多步推理任务中的多样计划步骤，以及 Step-level Advantage Preference Optimization (Step-APO)，该技术将 MCTS 的优势估计整合到 Direct Preference Optimization (DPO) 中，以优先学习关键计划步骤。实验结果显示，仅在 GSM8K 和 MATH 数据集上训练后，模型在这些数据集上的性能分别提升 10.5% 和 6.5%，并在外部基准如 HumanEval (+12.2%)、GPQA (+8.6%) 等上显著改进，证明了 CPL 在增强模型泛化方面的有效性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.08642v2",
      "published_date": "2024-09-13 08:59:31 UTC",
      "updated_date": "2024-10-01 05:42:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:45:33.593850"
    },
    {
      "arxiv_id": "2409.08641v1",
      "title": "Developing an Algorithm Selector for Green Configuration in Scheduling Problems",
      "title_zh": "开发用于调度问题的绿色配置算法选择器",
      "authors": [
        "Carlos March",
        "Christian Perez",
        "Miguel A. Salido"
      ],
      "abstract": "The Job Shop Scheduling Problem (JSP) is central to operations research,\nprimarily optimizing energy efficiency due to its profound environmental and\neconomic implications. Efficient scheduling enhances production metrics and\nmitigates energy consumption, thus effectively balancing productivity and\nsustainability objectives. Given the intricate and diverse nature of JSP\ninstances, along with the array of algorithms developed to tackle these\nchallenges, an intelligent algorithm selection tool becomes paramount. This\npaper introduces a framework designed to identify key problem features that\ncharacterize its complexity and guide the selection of suitable algorithms.\nLeveraging machine learning techniques, particularly XGBoost, the framework\nrecommends optimal solvers such as GUROBI, CPLEX, and GECODE for efficient JSP\nscheduling. GUROBI excels with smaller instances, while GECODE demonstrates\nrobust scalability for complex scenarios. The proposed algorithm selector\nachieves an accuracy of 84.51\\% in recommending the best algorithm for solving\nnew JSP instances, highlighting its efficacy in algorithm selection. By\nrefining feature extraction methodologies, the framework aims to broaden its\napplicability across diverse JSP scenarios, thereby advancing efficiency and\nsustainability in manufacturing logistics.",
      "tldr_zh": "这篇论文针对Job Shop Scheduling Problem (JSP)开发了一个算法选择框架，旨在优化能源效率并平衡生产力与可持续性目标。框架利用XGBoost机器学习技术，通过提取问题关键特征来推荐最佳求解器，如GUROBI（适用于小型实例）、CPLEX和GECODE（适用于复杂场景）。实验结果显示，该选择器在推荐算法时准确率达84.51%，有效提升了JSP解决效率。最终，该框架有望通过改进特征提取方法，扩展到更多场景中，推动制造物流的绿色优化。",
      "categories": [
        "cs.AI",
        "90C27"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.08641v1",
      "published_date": "2024-09-13 08:58:24 UTC",
      "updated_date": "2024-09-13 08:58:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:45:45.288111"
    },
    {
      "arxiv_id": "2409.08636v2",
      "title": "Utilizing Data Fingerprints for Privacy-Preserving Algorithm Selection in Time Series Classification: Performance and Uncertainty Estimation on Unseen Datasets",
      "title_zh": "翻译失败",
      "authors": [
        "Lars Böcking",
        "Leopold Müller",
        "Niklas Kühl"
      ],
      "abstract": "The selection of algorithms is a crucial step in designing AI services for\nreal-world time series classification use cases. Traditional methods such as\nneural architecture search, automated machine learning, combined algorithm\nselection, and hyperparameter optimizations are effective but require\nconsiderable computational resources and necessitate access to all data points\nto run their optimizations. In this work, we introduce a novel data fingerprint\nthat describes any time series classification dataset in a privacy-preserving\nmanner and provides insight into the algorithm selection problem without\nrequiring training on the (unseen) dataset. By decomposing the multi-target\nregression problem, only our data fingerprints are used to estimate algorithm\nperformance and uncertainty in a scalable and adaptable manner. Our approach is\nevaluated on the 112 University of California riverside benchmark datasets,\ndemonstrating its effectiveness in predicting the performance of 35\nstate-of-the-art algorithms and providing valuable insights for effective\nalgorithm selection in time series classification service systems, improving a\nnaive baseline by 7.32% on average in estimating the mean performance and\n15.81% in estimating the uncertainty.",
      "tldr_zh": "本论文提出了一种基于数据指纹（data fingerprints）的隐私保护方法，用于时间序列分类（time series classification）中的算法选择，避免了传统方法如神经架构搜索（neural architecture search）和自动化机器学习需要访问全部数据点的问题。方法通过分解多目标回归问题，仅利用数据指纹来估计算法性能和不确定性，实现可扩展和适应的优化。实验在112个UCR基准数据集上评估，预测35种最先进算法的表现，比朴素基线平均提高了7.32%在均值性能估计和15.81%在不确定性估计上，为实际AI服务系统提供了有效的算法选择见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Hawaii International Conference on System Sciences (HICSS-58) 2025",
      "pdf_url": "http://arxiv.org/pdf/2409.08636v2",
      "published_date": "2024-09-13 08:43:42 UTC",
      "updated_date": "2024-09-30 21:14:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:45:57.951119"
    },
    {
      "arxiv_id": "2409.08633v1",
      "title": "Improving Analog Neural Network Robustness: A Noise-Agnostic Approach with Explainable Regularizations",
      "title_zh": "翻译失败",
      "authors": [
        "Alice Duque",
        "Pedro Freire",
        "Egor Manuylovich",
        "Dmitrii Stoliarov",
        "Jaroslaw Prilepsky",
        "Sergei Turitsyn"
      ],
      "abstract": "This work tackles the critical challenge of mitigating \"hardware noise\" in\ndeep analog neural networks, a major obstacle in advancing analog signal\nprocessing devices. We propose a comprehensive, hardware-agnostic solution to\naddress both correlated and uncorrelated noise affecting the activation layers\nof deep neural models. The novelty of our approach lies in its ability to\ndemystify the \"black box\" nature of noise-resilient networks by revealing the\nunderlying mechanisms that reduce sensitivity to noise. In doing so, we\nintroduce a new explainable regularization framework that harnesses these\nmechanisms to significantly enhance noise robustness in deep neural\narchitectures.",
      "tldr_zh": "这篇论文针对深度模拟神经网络（analog neural networks）中的硬件噪声问题，提出了一种硬件无关（noise-agnostic）的全面解决方案，以处理影响激活层的相关和不相关噪声。创新之处在于揭示噪声鲁棒性网络的底层机制，从而消除其“黑箱”特性，并引入一个新的可解释正则化（explainable regularizations）框架。实验结果表明，该框架显著提升了深度神经架构的噪声鲁棒性，为模拟信号处理设备的发展提供了关键支持。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.optics"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.08633v1",
      "published_date": "2024-09-13 08:37:23 UTC",
      "updated_date": "2024-09-13 08:37:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:46:08.767279"
    },
    {
      "arxiv_id": "2409.08631v1",
      "title": "Sybil Detection using Graph Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Stuart Heeb",
        "Andreas Plesner",
        "Roger Wattenhofer"
      ],
      "abstract": "This paper presents SYBILGAT, a novel approach to Sybil detection in social\nnetworks using Graph Attention Networks (GATs). Traditional methods for Sybil\ndetection primarily leverage structural properties of networks; however, they\ntend to struggle with a large number of attack edges and are often unable to\nsimultaneously utilize both known Sybil and honest nodes. Our proposed method\naddresses these limitations by dynamically assigning attention weights to\ndifferent nodes during aggregations, enhancing detection performance. We\nconducted extensive experiments in various scenarios, including pretraining in\nsampled subgraphs, synthetic networks, and networks under targeted attacks. The\nresults show that SYBILGAT significantly outperforms the state-of-the-art\nalgorithms, particularly in scenarios with high attack complexity and when the\nnumber of attack edges increases. Our approach shows robust performance across\ndifferent network models and sizes, even as the detection task becomes more\nchallenging. We successfully applied the model to a real-world Twitter graph\nwith more than 269k nodes and 6.8M edges. The flexibility and generalizability\nof SYBILGAT make it a promising tool to defend against Sybil attacks in online\nsocial networks with only structural information.",
      "tldr_zh": "本文提出 SYBILGAT，一种基于 Graph Attention Networks (GATs) 的 Sybil Detection 方法，用于社交网络中检测假冒账户，通过动态分配注意力权重来解决传统方法在处理大量攻击边时的局限性，并同时利用已知 Sybil 和诚实节点。实验在采样子图、合成网络和针对性攻击场景下进行，结果显示 SYBILGAT 显著优于现有算法，尤其在高复杂度攻击中准确率更高。模型成功应用于真实 Twitter 图（包含超过 269k 节点和 6.8M 边），证明其灵活性和通用性，仅依赖网络结构信息即可有效防御 Sybil 攻击。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "9 pages, 1 figure, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2409.08631v1",
      "published_date": "2024-09-13 08:35:28 UTC",
      "updated_date": "2024-09-13 08:35:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:46:21.760920"
    },
    {
      "arxiv_id": "2409.08603v1",
      "title": "Using Convolutional Neural Networks for Denoising and Deblending of Marine Seismic Data",
      "title_zh": "翻译失败",
      "authors": [
        "Sigmund Slang",
        "Jing Sun",
        "Thomas Elboth",
        "Steven McDonald",
        "Leiv-J. Gelius"
      ],
      "abstract": "Processing marine seismic data is computationally demanding and consists of\nmultiple time-consuming steps. Neural network based processing can, in theory,\nsignificantly reduce processing time and has the potential to change the way\nseismic processing is done. In this paper we are using deep convolutional\nneural networks (CNNs) to remove seismic interference noise and to deblend\nseismic data. To train such networks, a significant amount of computational\nmemory is needed since a single shot gather consists of more than 106 data\nsamples. Preliminary results are promising both for denoising and deblending.\nHowever, we also observed that the results are affected by the signal-to-noise\nratio (SnR). Moving to common channel domain is a way of breaking the coherency\nof the noise while also reducing the input volume size. This makes it easier\nfor the network to distinguish between signal and noise. It also increases the\nefficiency of the GPU memory usage by enabling better utilization of multi core\nprocessing. Deblending in common channel domain with the use of a CNN yields\nrelatively good results and is an improvement compared to shot domain.",
      "tldr_zh": "本研究利用卷积神经网络 (CNNs) 处理海洋地震数据，旨在通过去噪和去叠加 (deblending) 显著减少计算时间并简化处理流程。训练 CNNs 需要大量内存，因为单个地震采集点 (shot gather) 包含超过 10^6 个数据样本，而初步结果显示该方法在去噪和去叠加方面表现出色，但受信号噪声比 (SnR) 影响。作者发现，将数据移至公共通道域 (common channel domain) 可以打破噪声连续性、减小输入体积并提高 GPU 内存效率，从而使网络更容易区分信号和噪声，并在去叠加任务上取得比 shot domain 更好的性能。该方法为高效的地震数据处理提供了潜在变革路径。",
      "categories": [
        "physics.geo-ph",
        "cs.AI"
      ],
      "primary_category": "physics.geo-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.08603v1",
      "published_date": "2024-09-13 07:35:30 UTC",
      "updated_date": "2024-09-13 07:35:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:46:33.098679"
    },
    {
      "arxiv_id": "2409.08602v1",
      "title": "Deep learning-based shot-domain seismic deblending",
      "title_zh": "基于深度学习的炮点域地震数据去混叠",
      "authors": [
        "Jing Sun",
        "Song Hou",
        "Vetle Vinje",
        "Gordon Poole",
        "Leiv-J Gelius"
      ],
      "abstract": "To streamline fast-track processing of large data volumes, we have developed\na deep learning approach to deblend seismic data in the shot domain based on a\npractical strategy for generating high-quality training data along with a list\nof data conditioning techniques to improve performance of the data-driven\nmodel. We make use of unblended shot gathers acquired at the end of each sail\nline, to which the access requires no additional time or labor costs beyond the\nblended acquisition. By manually blending these data we obtain training data\nwith good control of the ground truth and fully adapted to the given survey.\nFurthermore, we train a deep neural network using multi-channel inputs that\ninclude adjacent blended shot gathers as additional channels. The prediction of\nthe blending noise is added in as a related and auxiliary task with the main\ntask of the network being the prediction of the primary-source events. Blending\nnoise in the ground truth is scaled down during the training and validation\nprocess due to its excessively strong amplitudes. As part of the process, the\nto-be-deblended shot gathers are aligned by the blending noise. Implementation\non field blended-by-acquisition data demonstrates that introducing the\nsuggested data conditioning steps can considerably reduce the leakage of\nprimary-source events in the deep part of the blended section. The complete\nproposed approach performs almost as well as a conventional algorithm in the\nshallow section and shows great advantage in efficiency. It performs slightly\nworse for larger traveltimes, but still removes the blending noise efficiently.",
      "tldr_zh": "本研究提出了一种基于深度学习的shot domain地震数据去混叠方法，通过利用未混叠shot gathers手动生成高质量训练数据，并结合多通道输入（如相邻混叠shot gathers）和联合任务学习（预测主要源事件和混叠噪声）来提升模型性能。论文还引入了数据条件化技术，包括缩放混叠噪声幅度和对齐shot gathers，以减少主要源事件的泄漏。实验结果显示，该方法在浅层部分表现几乎与传统算法相当，在深层显著降低泄漏，整体处理效率更高，尽管在大旅行时间时略逊一筹，但仍能有效去除混叠噪声。",
      "categories": [
        "physics.geo-ph",
        "cs.AI"
      ],
      "primary_category": "physics.geo-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.08602v1",
      "published_date": "2024-09-13 07:32:31 UTC",
      "updated_date": "2024-09-13 07:32:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:46:45.571008"
    },
    {
      "arxiv_id": "2409.08596v2",
      "title": "Large Language Model Can Transcribe Speech in Multi-Talker Scenarios with Versatile Instructions",
      "title_zh": "大语言模型可以在多说话者场景中使用多功能指令转录语音",
      "authors": [
        "Lingwei Meng",
        "Shujie Hu",
        "Jiawen Kang",
        "Zhaoqing Li",
        "Yuejiao Wang",
        "Wenxuan Wu",
        "Xixin Wu",
        "Xunying Liu",
        "Helen Meng"
      ],
      "abstract": "Recent advancements in large language models (LLMs) have revolutionized\nvarious domains, bringing significant progress and new opportunities. Despite\nprogress in speech-related tasks, LLMs have not been sufficiently explored in\nmulti-talker scenarios. In this work, we present a pioneering effort to\ninvestigate the capability of LLMs in transcribing speech in multi-talker\nenvironments, following versatile instructions related to multi-talker\nautomatic speech recognition (ASR), target talker ASR, and ASR based on\nspecific talker attributes such as sex, occurrence order, language, and keyword\nspoken. Our approach utilizes WavLM and Whisper encoder to extract\nmulti-faceted speech representations that are sensitive to speaker\ncharacteristics and semantic context. These representations are then fed into\nan LLM fine-tuned using LoRA, enabling the capabilities for speech\ncomprehension and transcription. Comprehensive experiments reveal the promising\nperformance of our proposed system, MT-LLM, in cocktail party scenarios,\nhighlighting the potential of LLM to handle speech-related tasks based on user\ninstructions in such complex settings. The code, model, and samples are\navailable at https://github.com/cuhealthybrains/MT-LLM.",
      "tldr_zh": "本文研究了大型语言模型（LLMs）在多说话者场景下进行语音转录的能力，支持多种指令，包括多说话者自动语音识别（ASR）、目标说话者 ASR 以及基于性别、出现顺序、语言和关键词的 ASR。方法利用 WavLM 和 Whisper 编码器提取敏感于说话者特性和语义上下文的语音表示，然后通过 LoRA 微调 LLM，以实现有效的语音理解和转录。实验结果显示，所提出的 MT-LLM 系统在鸡尾酒派对等复杂环境中表现出色，准确率显著提升，证明了 LLMs 处理指令驱动语音任务的潜力。代码、模型和样本已在 GitHub 上公开。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to IEEE ICASSP 2025. Update code link",
      "pdf_url": "http://arxiv.org/pdf/2409.08596v2",
      "published_date": "2024-09-13 07:28:28 UTC",
      "updated_date": "2025-04-02 16:16:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:46:58.355048"
    },
    {
      "arxiv_id": "2409.08595v1",
      "title": "Automatic Generation of Fast and Accurate Performance Models for Deep Neural Network Accelerators",
      "title_zh": "翻译失败",
      "authors": [
        "Konstantin Lübeck",
        "Alexander Louis-Ferdinand Jung",
        "Felix Wedlich",
        "Mika Markus Müller",
        "Federico Nicolás Peccia",
        "Felix Thömmes",
        "Jannik Steinmetz",
        "Valentin Biermaier",
        "Adrian Frischknecht",
        "Paul Palomero Bernardo",
        "Oliver Bringmann"
      ],
      "abstract": "Implementing Deep Neural Networks (DNNs) on resource-constrained edge devices\nis a challenging task that requires tailored hardware accelerator architectures\nand a clear understanding of their performance characteristics when executing\nthe intended AI workload. To facilitate this, we present an automated\ngeneration approach for fast performance models to accurately estimate the\nlatency of a DNN mapped onto systematically modeled and concisely described\naccelerator architectures. Using our accelerator architecture description\nmethod, we modeled representative DNN accelerators such as Gemmini, UltraTrail,\nPlasticine-derived, and a parameterizable systolic array. Together with DNN\nmappings for those modeled architectures, we perform a combined DNN/hardware\ndependency graph analysis, which enables us, in the best case, to evaluate only\n154 loop kernel iterations to estimate the performance for 4.19 billion\ninstructions achieving a significant speedup. We outperform regression and\nanalytical models in terms of mean absolute percentage error (MAPE) compared to\nsimulation results, while being several magnitudes faster than an RTL\nsimulation.",
      "tldr_zh": "本研究提出了一种自动生成快速且准确性能模型的方法，用于估计 Deep Neural Networks (DNNs) 在硬件加速器上的延迟。该方法通过加速器架构描述技术，建模了如 Gemmini、UltraTrail 和 Plasticine-derived 等代表性加速器，并结合 DNN/hardware 依赖图分析，仅需评估少量循环内核迭代（如 154 次）即可高效估计 41.9 亿指令的性能。与回归和分析模型相比，该方法在 Mean Absolute Percentage Error (MAPE) 上表现出色，且比 RTL simulation 快几个数量级，为资源受限边缘设备上的 DNN 实现提供了高效工具。",
      "categories": [
        "cs.PF",
        "cs.AI",
        "cs.AR",
        "cs.LG"
      ],
      "primary_category": "cs.PF",
      "comment": "Accepted version for: ACM Transactions on Embedded Computing Systems",
      "pdf_url": "http://arxiv.org/pdf/2409.08595v1",
      "published_date": "2024-09-13 07:27:55 UTC",
      "updated_date": "2024-09-13 07:27:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:47:08.745828"
    },
    {
      "arxiv_id": "2409.08583v2",
      "title": "LHQ-SVC: Lightweight and High Quality Singing Voice Conversion Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Yubo Huang",
        "Xin Lai",
        "Muyang Ye",
        "Anran Zhu",
        "Zixi Wang",
        "Jingzehua Xu",
        "Shuai Zhang",
        "Zhiyuan Zhou",
        "Weijie Niu"
      ],
      "abstract": "Singing Voice Conversion (SVC) has emerged as a significant subfield of Voice\nConversion (VC), enabling the transformation of one singer's voice into another\nwhile preserving musical elements such as melody, rhythm, and timbre.\nTraditional SVC methods have limitations in terms of audio quality, data\nrequirements, and computational complexity. In this paper, we propose LHQ-SVC,\na lightweight, CPU-compatible model based on the SVC framework and diffusion\nmodel, designed to reduce model size and computational demand without\nsacrificing performance. We incorporate features to improve inference quality,\nand optimize for CPU execution by using performance tuning tools and parallel\ncomputing frameworks. Our experiments demonstrate that LHQ-SVC maintains\ncompetitive performance, with significant improvements in processing speed and\nefficiency across different devices. The results suggest that LHQ-SVC can meet",
      "tldr_zh": "本研究提出LHQ-SVC，一种轻量级且高质量的Singing Voice Conversion (SVC)模型，旨在解决传统SVC方法在音频质量、数据需求和计算复杂度方面的局限性。该模型基于SVC框架和diffusion model，减少了模型大小和计算需求，同时通过加入改进推理质量的特征，并利用性能调优工具和并行计算框架优化CPU执行。实验结果显示，LHQ-SVC在不同设备上保持了竞争性性能，并在处理速度和效率上实现了显著提升，证明其适用于实际应用场景。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted by ICASSP 2025",
      "pdf_url": "http://arxiv.org/pdf/2409.08583v2",
      "published_date": "2024-09-13 07:02:36 UTC",
      "updated_date": "2025-01-17 23:27:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:47:20.542725"
    },
    {
      "arxiv_id": "2409.08580v1",
      "title": "Molecular Graph Representation Learning via Structural Similarity Information",
      "title_zh": "翻译失败",
      "authors": [
        "Chengyu Yao",
        "Hong Huang",
        "Hang Gao",
        "Fengge Wu",
        "Haiming Chen",
        "Junsuo Zhao"
      ],
      "abstract": "Graph Neural Networks (GNNs) have been widely employed for feature\nrepresentation learning in molecular graphs. Therefore, it is crucial to\nenhance the expressiveness of feature representation to ensure the\neffectiveness of GNNs. However, a significant portion of current research\nprimarily focuses on the structural features within individual molecules, often\noverlooking the structural similarity between molecules, which is a crucial\naspect encapsulating rich information on the relationship between molecular\nproperties and structural characteristics. Thus, these approaches fail to\ncapture the rich semantic information at the molecular structure level. To\nbridge this gap, we introduce the \\textbf{Molecular Structural Similarity Motif\nGNN (MSSM-GNN)}, a novel molecular graph representation learning method that\ncan capture structural similarity information among molecules from a global\nperspective. In particular, we propose a specially designed graph that\nleverages graph kernel algorithms to represent the similarity between molecules\nquantitatively. Subsequently, we employ GNNs to learn feature representations\nfrom molecular graphs, aiming to enhance the accuracy of property prediction by\nincorporating additional molecular representation information. Finally, through\na series of experiments conducted on both small-scale and large-scale molecular\ndatasets, we demonstrate that our model consistently outperforms eleven\nstate-of-the-art baselines. The codes are available at\nhttps://github.com/yaoyao-yaoyao-cell/MSSM-GNN.",
      "tldr_zh": "该研究指出，Graph Neural Networks (GNNs) 在分子图表示学习中常忽略分子间的结构相似性，导致无法充分捕获分子属性与结构特征的相关信息，从而影响预测准确性。为解决此问题，作者提出Molecular Structural Similarity Motif GNN (MSSM-GNN)，该方法使用图核算法(graph kernel algorithms)量化分子相似性，构建特殊图并结合GNNs从全局视角学习特征表示，以提升分子属性预测的精确度。通过实验验证，MSSM-GNN在小规模和大规模数据集上优于11个最先进基线模型，证明了其有效性。代码已在GitHub开源。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.08580v1",
      "published_date": "2024-09-13 06:59:10 UTC",
      "updated_date": "2024-09-13 06:59:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:47:32.816512"
    },
    {
      "arxiv_id": "2409.08561v1",
      "title": "Expediting and Elevating Large Language Model Reasoning via Hidden Chain-of-Thought Decoding",
      "title_zh": "通过隐藏链式思维解码加速和提升大语言模型推理",
      "authors": [
        "Tianqiao Liu",
        "Zui Chen",
        "Zitao Liu",
        "Mi Tian",
        "Weiqi Luo"
      ],
      "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in\ntasks requiring reasoning and multi-step problem-solving through the use of\nchain-of-thought (CoT) prompting. However, generating the full CoT process\nresults in significantly longer output sequences, leading to increased\ncomputational costs and latency during inference. To address this challenge, we\npropose a novel approach to compress the CoT process through semantic\nalignment, enabling more efficient decoding while preserving the benefits of\nCoT reasoning. Our method introduces an auxiliary CoT model that learns to\ngenerate and compress the full thought process into a compact special token\nrepresentation semantically aligned with the original CoT output. This\ncompressed representation is then integrated into the input of the Hidden\nChain-of-Thought (HCoT) model. The training process follows a two-stage\nprocedure: First, the CoT model is optimized to generate the compressed token\nrepresentations aligned with the ground-truth CoT outputs using a contrastive\nloss. Subsequently, with the CoT model parameters frozen, the HCoT model is\nfine-tuned to generate accurate subsequent predictions conditioned on the\nprefix instruction and the compressed CoT representations from the CoT model.\nExtensive experiments across three challenging domains - mathematical\nreasoning, agent invocation, and question answering - demonstrate that our\nsemantic compression approach achieves competitive or improved performance\ncompared to the full CoT baseline, while providing significant speedups of at\nleast 1.5x in decoding time. Moreover, incorporating contrastive learning\nobjectives further enhances the quality of the compressed representations,\nleading to better CoT prompting and improved task accuracy. Our work paves the\nway for more efficient exploitation of multi-step reasoning capabilities in\nLLMs across a wide range of applications.",
      "tldr_zh": "本研究提出了一种名为Hidden Chain-of-Thought (HCoT)的解码方法，旨在加速和提升Large Language Models (LLMs)在推理任务中的性能，通过语义对齐压缩传统的Chain-of-Thought (CoT)过程，以减少输出序列长度并降低计算成本。方法引入一个辅助CoT模型，该模型学习生成完整的思考过程并将其压缩成紧凑的特殊标记表示，随后将这些表示集成到HCoT模型的输入中，并采用两阶段训练：首先使用对比损失优化CoT模型的参数，然后冻结其参数并微调HCoT模型以生成准确预测。实验在数学推理、代理调用和问答等三个领域显示，该方法与完整CoT基线相比，实现了至少1.5倍的解码速度提升，同时保持或改善任务准确率，进一步证明了对比学习在提升压缩表示质量方面的作用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.08561v1",
      "published_date": "2024-09-13 06:29:20 UTC",
      "updated_date": "2024-09-13 06:29:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:47:46.702656"
    },
    {
      "arxiv_id": "2409.08543v1",
      "title": "ATFLRec: A Multimodal Recommender System with Audio-Text Fusion and Low-Rank Adaptation via Instruction-Tuned Large Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Zezheng Qin"
      ],
      "abstract": "Recommender Systems (RS) play a pivotal role in boosting user satisfaction by\nproviding personalized product suggestions in domains such as e-commerce and\nentertainment. This study examines the integration of multimodal data text and\naudio into large language models (LLMs) with the aim of enhancing\nrecommendation performance. Traditional text and audio recommenders encounter\nlimitations such as the cold-start problem, and recent advancements in LLMs,\nwhile promising, are computationally expensive. To address these issues,\nLow-Rank Adaptation (LoRA) is introduced, which enhances efficiency without\ncompromising performance. The ATFLRec framework is proposed to integrate audio\nand text modalities into a multimodal recommendation system, utilizing various\nLoRA configurations and modality fusion techniques. Results indicate that\nATFLRec outperforms baseline models, including traditional and graph neural\nnetwork-based approaches, achieving higher AUC scores. Furthermore, separate\nfine-tuning of audio and text data with distinct LoRA modules yields optimal\nperformance, with different pooling methods and Mel filter bank numbers\nsignificantly impacting performance. This research offers valuable insights\ninto optimizing multimodal recommender systems and advancing the integration of\ndiverse data modalities in LLMs.",
      "tldr_zh": "本研究针对推荐系统（RS）的冷启动问题和高计算开销，提出ATFLRec框架，该框架通过音频-文本融合和Low-Rank Adaptation (LoRA)技术，将多模态数据整合到指令微调的大型语言模型（LLMs）中，以提升个性化推荐性能。ATFLRec利用各种LoRA配置和模态融合方法，包括单独微调音频和文本数据，并优化池化方法及Mel滤波器数量。实验结果显示，ATFLRec在AUC分数上优于传统和图神经网络基线模型，提高了推荐准确率，并为优化多模态RS和LLMs数据整合提供了宝贵见解。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.08543v1",
      "published_date": "2024-09-13 05:33:09 UTC",
      "updated_date": "2024-09-13 05:33:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:47:56.978865"
    },
    {
      "arxiv_id": "2409.08537v1",
      "title": "SRE-CNN: A Spatiotemporal Rotation-Equivariant CNN for Cardiac Cine MR Imaging",
      "title_zh": "翻译失败",
      "authors": [
        "Yuliang Zhu",
        "Jing Cheng",
        "Zhuo-Xu Cui",
        "Jianfeng Ren",
        "Chengbo Wang",
        "Dong Liang"
      ],
      "abstract": "Dynamic MR images possess various transformation symmetries,including the\nrotation symmetry of local features within the image and along the temporal\ndimension. Utilizing these symmetries as prior knowledge can facilitate dynamic\nMR imaging with high spatiotemporal resolution. Equivariant CNN is an effective\ntool to leverage the symmetry priors. However, current equivariant CNN methods\nfail to fully exploit these symmetry priors in dynamic MR imaging. In this\nwork, we propose a novel framework of Spatiotemporal Rotation-Equivariant CNN\n(SRE-CNN), spanning from the underlying high-precision filter design to the\nconstruction of the temporal-equivariant convolutional module and imaging\nmodel, to fully harness the rotation symmetries inherent in dynamic MR images.\nThe temporal-equivariant convolutional module enables exploitation the rotation\nsymmetries in both spatial and temporal dimensions, while the high-precision\nconvolutional filter, based on parametrization strategy, enhances the\nutilization of rotation symmetry of local features to improve the\nreconstruction of detailed anatomical structures. Experiments conducted on\nhighly undersampled dynamic cardiac cine data (up to 20X) have demonstrated the\nsuperior performance of our proposed approach, both quantitatively and\nqualitatively.",
      "tldr_zh": "这篇论文提出了 SRE-CNN，一种新型时空旋转等变 CNN 框架，用于心脏电影 MR 成像，以充分利用动态 MR 图像的空间和时间旋转对称性作为先验知识，提高图像的空间和时间分辨率。该框架包括高精度卷积滤波器设计（基于参数化策略）和时间等变卷积模块，能够有效利用局部特征的旋转对称性，提升详细解剖结构的重建质量。实验在高达 20 倍欠采样的动态心脏电影数据上验证了 SRE-CNN 的优越性能，在定量和定性指标上均超过了现有方法。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "Accepted at MICCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.08537v1",
      "published_date": "2024-09-13 04:54:34 UTC",
      "updated_date": "2024-09-13 04:54:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:48:09.452849"
    },
    {
      "arxiv_id": "2409.08530v1",
      "title": "Integration of Mamba and Transformer -- MAT for Long-Short Range Time Series Forecasting with Application to Weather Dynamics",
      "title_zh": "翻译失败",
      "authors": [
        "Wenqing Zhang",
        "Junming Huang",
        "Ruotong Wang",
        "Changsong Wei",
        "Wenqian Huang",
        "Yuxin Qiao"
      ],
      "abstract": "Long-short range time series forecasting is essential for predicting future\ntrends and patterns over extended periods. While deep learning models such as\nTransformers have made significant strides in advancing time series\nforecasting, they often encounter difficulties in capturing long-term\ndependencies and effectively managing sparse semantic features. The state-space\nmodel, Mamba, addresses these issues through its adept handling of selective\ninput and parallel computing, striking a balance between computational\nefficiency and prediction accuracy. This article examines the advantages and\ndisadvantages of both Mamba and Transformer models, and introduces a combined\napproach, MAT, which leverages the strengths of each model to capture unique\nlong-short range dependencies and inherent evolutionary patterns in\nmultivariate time series. Specifically, MAT harnesses the long-range dependency\ncapabilities of Mamba and the short-range characteristics of Transformers.\nExperimental results on benchmark weather datasets demonstrate that MAT\noutperforms existing comparable methods in terms of prediction accuracy,\nscalability, and memory efficiency.",
      "tldr_zh": "本文提出 MAT 模型，将 Mamba 和 Transformer 整合，用于长短期时间序列预测，特别应用于天气动态分析。MAT 利用 Mamba 的长程依赖处理能力与 Transformer 的短程特征捕捉优势，平衡了计算效率和预测准确性。实验结果显示，在基准天气数据集上，MAT 在预测准确性、可扩展性和内存效率方面均优于现有方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "6 pages, 4 figures, to be presented at the 5th International\n  Conference on Electrical, Communication and Computer Engineering (ICECCE)",
      "pdf_url": "http://arxiv.org/pdf/2409.08530v1",
      "published_date": "2024-09-13 04:23:54 UTC",
      "updated_date": "2024-09-13 04:23:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:48:20.336209"
    },
    {
      "arxiv_id": "2409.08514v2",
      "title": "Apollo: Band-sequence Modeling for High-Quality Audio Restoration",
      "title_zh": "翻译失败",
      "authors": [
        "Kai Li",
        "Yi Luo"
      ],
      "abstract": "Audio restoration has become increasingly significant in modern society, not\nonly due to the demand for high-quality auditory experiences enabled by\nadvanced playback devices, but also because the growing capabilities of\ngenerative audio models necessitate high-fidelity audio. Typically, audio\nrestoration is defined as a task of predicting undistorted audio from damaged\ninput, often trained using a GAN framework to balance perception and\ndistortion. Since audio degradation is primarily concentrated in mid- and\nhigh-frequency ranges, especially due to codecs, a key challenge lies in\ndesigning a generator capable of preserving low-frequency information while\naccurately reconstructing high-quality mid- and high-frequency content.\nInspired by recent advancements in high-sample-rate music separation, speech\nenhancement, and audio codec models, we propose Apollo, a generative model\ndesigned for high-sample-rate audio restoration. Apollo employs an explicit\nfrequency band split module to model the relationships between different\nfrequency bands, allowing for more coherent and higher-quality restored audio.\nEvaluated on the MUSDB18-HQ and MoisesDB datasets, Apollo consistently\noutperforms existing SR-GAN models across various bit rates and music genres,\nparticularly excelling in complex scenarios involving mixtures of multiple\ninstruments and vocals. Apollo significantly improves music restoration quality\nwhile maintaining computational efficiency. The source code for Apollo is\npublicly available at https://github.com/JusperLee/Apollo.",
      "tldr_zh": "该论文提出 Apollo 模型，用于高品质音频恢复，针对音频降级主要在中高频段的挑战，通过显式频率带分割模块（explicit frequency band split module）建模不同频率带之间的关系，确保低频信息保留的同时准确重建高频内容。相比传统 GAN 框架，Apollo 灵感来源于高采样率音乐分离和语音增强技术，提高了生成音频的连贯性和质量。在 MUSDB18-HQ 和 MoisesDB 数据集上，Apollo 显著超越现有 SR-GAN 模型，尤其在多乐器和声乐混合的复杂场景中，提升恢复质量并保持计算效率。源代码已在 GitHub 上公开（https://github.com/JusperLee/Apollo）。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted by ICASSP 2025, Demo Page: https://cslikai.cn/Apollo",
      "pdf_url": "http://arxiv.org/pdf/2409.08514v2",
      "published_date": "2024-09-13 03:25:34 UTC",
      "updated_date": "2025-01-07 15:37:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:48:34.038428"
    },
    {
      "arxiv_id": "2409.08487v1",
      "title": "Sub-graph Based Diffusion Model for Link Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Hang Li",
        "Wei Jin",
        "Geri Skenderi",
        "Harry Shomer",
        "Wenzhuo Tang",
        "Wenqi Fan",
        "Jiliang Tang"
      ],
      "abstract": "Denoising Diffusion Probabilistic Models (DDPMs) represent a contemporary\nclass of generative models with exceptional qualities in both synthesis and\nmaximizing the data likelihood. These models work by traversing a forward\nMarkov Chain where data is perturbed, followed by a reverse process where a\nneural network learns to undo the perturbations and recover the original data.\nThere have been increasing efforts exploring the applications of DDPMs in the\ngraph domain. However, most of them have focused on the generative perspective.\nIn this paper, we aim to build a novel generative model for link prediction. In\nparticular, we treat link prediction between a pair of nodes as a conditional\nlikelihood estimation of its enclosing sub-graph. With a dedicated design to\ndecompose the likelihood estimation process via the Bayesian formula, we are\nable to separate the estimation of sub-graph structure and its node features.\nSuch designs allow our model to simultaneously enjoy the advantages of\ninductive learning and the strong generalization capability. Remarkably,\ncomprehensive experiments across various datasets validate that our proposed\nmethod presents numerous advantages: (1) transferability across datasets\nwithout retraining, (2) promising generalization on limited training data, and\n(3) robustness against graph adversarial attacks.",
      "tldr_zh": "本文提出了一种基于子-graph的扩散模型，用于图领域的链接预测（link prediction），以Denoising Diffusion Probabilistic Models (DDPMs)为基础，将预测任务视为一对节点的子-graph条件似然估计。模型通过Bayesian公式分解似然过程，将子-graph结构和节点特征的估计分开，从而实现归纳学习（inductive learning）和强泛化能力。实验在多个数据集上验证了该方法的优势，包括无需重新训练即可在数据集间转移、在有限训练数据上表现良好，以及对图对抗攻击的鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.08487v1",
      "published_date": "2024-09-13 02:23:55 UTC",
      "updated_date": "2024-09-13 02:23:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:48:45.273265"
    },
    {
      "arxiv_id": "2409.08483v1",
      "title": "A BERT-Based Summarization approach for depression detection",
      "title_zh": "翻译失败",
      "authors": [
        "Hossein Salahshoor Gavalan",
        "Mohmmad Naim Rastgoo",
        "Bahareh Nakisa"
      ],
      "abstract": "Depression is a globally prevalent mental disorder with potentially severe\nrepercussions if not addressed, especially in individuals with recurrent\nepisodes. Prior research has shown that early intervention has the potential to\nmitigate or alleviate symptoms of depression. However, implementing such\ninterventions in a real-world setting may pose considerable challenges. A\npromising strategy involves leveraging machine learning and artificial\nintelligence to autonomously detect depression indicators from diverse data\nsources. One of the most widely available and informative data sources is text,\nwhich can reveal a person's mood, thoughts, and feelings. In this context,\nvirtual agents programmed to conduct interviews using clinically validated\nquestionnaires, such as those found in the DAIC-WOZ dataset, offer a robust\nmeans for depression detection through linguistic analysis. Utilizing\nBERT-based models, which are powerful and versatile yet use fewer resources\nthan contemporary large language models, to convert text into numerical\nrepresentations significantly enhances the precision of depression diagnosis.\nThese models adeptly capture complex semantic and syntactic nuances, improving\nthe detection accuracy of depressive symptoms. Given the inherent limitations\nof these models concerning text length, our study proposes text summarization\nas a preprocessing technique to diminish the length and intricacies of input\ntexts. Implementing this method within our uniquely developed framework for\nfeature extraction and classification yielded an F1-score of 0.67 on the test\nset surpassing all prior benchmarks and 0.81 on the validation set exceeding\nmost previous results on the DAIC-WOZ dataset. Furthermore, we have devised a\ndepression lexicon to assess summary quality and relevance. This lexicon\nconstitutes a valuable asset for ongoing research in depression detection.",
      "tldr_zh": "本研究针对抑郁症检测的挑战，提出了一种基于BERT的文本总结方法，以从文本数据（如DAIC-WOZ数据集中的访谈记录）中自动识别抑郁指标。方法包括使用BERT模型将文本转换为数值表示，并通过文本总结作为预处理技术，减少输入文本的长度和复杂性，从而提升模型对语义和句法细节的捕捉。实验结果显示，该框架在DAIC-WOZ测试集上取得了0.67的F1-score，验证集上达0.81，超过了先前基准；此外，研究还开发了depression lexicon作为评估总结质量的工具，为抑郁检测研究提供了新资源。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.08483v1",
      "published_date": "2024-09-13 02:14:34 UTC",
      "updated_date": "2024-09-13 02:14:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:48:56.925729"
    },
    {
      "arxiv_id": "2409.08479v2",
      "title": "Exploring Information Retrieval Landscapes: An Investigation of a Novel Evaluation Techniques and Comparative Document Splitting Methods",
      "title_zh": "翻译失败",
      "authors": [
        "Esmaeil Narimissa",
        "David Raithel"
      ],
      "abstract": "The performance of Retrieval-Augmented Generation (RAG) systems in\ninformation retrieval is significantly influenced by the characteristics of the\ndocuments being processed. In this study, the structured nature of textbooks,\nthe conciseness of articles, and the narrative complexity of novels are shown\nto require distinct retrieval strategies. A comparative evaluation of multiple\ndocument-splitting methods reveals that the Recursive Character Splitter\noutperforms the Token-based Splitter in preserving contextual integrity. A\nnovel evaluation technique is introduced, utilizing an open-source model to\ngenerate a comprehensive dataset of question-and-answer pairs, simulating\nrealistic retrieval scenarios to enhance testing efficiency and metric\nreliability. The evaluation employs weighted scoring metrics, including\nSequenceMatcher, BLEU, METEOR, and BERT Score, to assess the system's accuracy\nand relevance. This approach establishes a refined standard for evaluating the\nprecision of RAG systems, with future research focusing on optimizing chunk and\noverlap sizes to improve retrieval accuracy and efficiency.",
      "tldr_zh": "这篇论文探讨了Retrieval-Augmented Generation (RAG)系统在信息检索中的性能如何受文档特性（如教科书、文章和小说）的影响，并比较了多种文档分割方法。研究发现，Recursive Character Splitter在保留上下文完整性方面优于Token-based Splitter，从而提升了检索策略的适用性。论文引入了一种新颖的评估技术，使用开源模型生成问题-答案对数据集来模拟真实场景，提高了测试效率和指标可靠性。最终，通过加权指标如SequenceMatcher、BLEU、METEOR和BERT Score进行评估，建立了RAG系统精度的改进标准，并建议未来优化chunk和overlap sizes以进一步提升准确性。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "I.2.7; H.3.3"
      ],
      "primary_category": "cs.IR",
      "comment": "This article is 16 pages long and includes detailed comparisons of\n  RAG systems and document splitting techniques",
      "pdf_url": "http://arxiv.org/pdf/2409.08479v2",
      "published_date": "2024-09-13 02:08:47 UTC",
      "updated_date": "2024-09-20 04:52:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:49:10.102333"
    },
    {
      "arxiv_id": "2409.08477v2",
      "title": "Integrating Neural Operators with Diffusion Models Improves Spectral Representation in Turbulence Modeling",
      "title_zh": "整合神经算子与扩散模型以改善湍流建模中的光谱表示",
      "authors": [
        "Vivek Oommen",
        "Aniruddha Bora",
        "Zhen Zhang",
        "George Em Karniadakis"
      ],
      "abstract": "We integrate neural operators with diffusion models to address the spectral\nlimitations of neural operators in surrogate modeling of turbulent flows. While\nneural operators offer computational efficiency, they exhibit deficiencies in\ncapturing high-frequency flow dynamics, resulting in overly smooth\napproximations. To overcome this, we condition diffusion models on neural\noperators to enhance the resolution of turbulent structures. Our approach is\nvalidated for different neural operators on diverse datasets, including a high\nReynolds number jet flow simulation and experimental Schlieren velocimetry. The\nproposed method significantly improves the alignment of predicted energy\nspectra with true distributions compared to neural operators alone. This\nenables the diffusion models to stabilize longer forecasts through\ndiffusion-corrected autoregressive rollouts, as we demonstrate in this work.\nAdditionally, proper orthogonal decomposition analysis demonstrates enhanced\nspectral fidelity in space-time. This work establishes a new paradigm for\ncombining generative models with neural operators to advance surrogate modeling\nof turbulent systems, and it can be used in other scientific applications that\ninvolve microstructure and high-frequency content. See our project page:\nvivekoommen.github.io/NO_DM",
      "tldr_zh": "本研究整合neural operators与diffusion models，旨在解决neural operators在湍流建模中捕捉高频动态的不足，从而提升谱表示的准确性。方法通过将diffusion models条件于neural operators，应用于多种数据集（如高雷诺数喷射流模拟和实验Schlieren测速术），显著改善了预测能量谱与真实分布的匹配度，并通过diffusion-corrected autoregressive rollouts稳定了更长的预测。实验结果显示，该框架增强了时空谱保真度，为代理建模的创新范式奠定基础，可扩展到其他涉及微结构和高频内容的科学应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.flu-dyn"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.08477v2",
      "published_date": "2024-09-13 02:07:20 UTC",
      "updated_date": "2025-02-13 01:09:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:49:21.761741"
    },
    {
      "arxiv_id": "2409.08472v1",
      "title": "An Intent Modeling and Inference Framework for Autonomous and Remotely Piloted Aerial Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Kesav Kaza",
        "Varun Mehta",
        "Hamid Azad",
        "Miodrag Bolic",
        "Iraj Mantegh"
      ],
      "abstract": "An intent modelling and inference framework is presented to assist the\ndefense planning for protecting a geo-fence against unauthorized flights.\nFirst, a novel mathematical definition for the intent of an uncrewed aircraft\nsystem (UAS) is presented. The concepts of critical waypoints and critical\nwaypoint patterns are introduced and associated with a motion process to fully\ncharacterize an intent. This modelling framework consists of representations of\na UAS mission planner, used to plan the aircraft's motion sequence, as well as\na defense planner, defined to protect the geo-fence. It is applicable to\nautonomous, semi-autonomous, and piloted systems in 2D and 3D environments with\nobstacles. The framework is illustrated by defining a library of intents for a\nsecurity application. Detection and tracking of the target are presumed for\nformulating the intent inference problem. Multiple formulations of the decision\nmaker's objective are discussed as part of a deep-learning-based methodology.\nFurther, a multi-modal dynamic model for characterizing the UAS flight is\ndiscussed. This is later utilized to extract features using the interacting\nmultiple model (IMM) filter for training the intent classifier. Finally, as\npart of the simulation study, an attention-based bi-directional long short-term\nmemory (Bi-LSTM) network for intent inference is presented. The simulation\nexperiments illustrate various aspects of the framework, including trajectory\ngeneration, radar measurement simulation, etc., in 2D and 3D environments.",
      "tldr_zh": "该论文提出了一种意图建模和推理框架，用于辅助保护地理围栏免受未授权飞行。框架引入了无人驾驶飞机系统 (UAS) 的数学定义、关键航路点和关键航路点模式，与运动过程相结合，构建了任务规划器和防御规划器，适用于自主、半自主和有人驾驶系统在 2D 和 3D 环境。基于深度学习的意图推理方法，包括多模态动态模型、interacting multiple model (IMM) 过滤器提取特征，以及注意力机制的 Bi-LSTM 网络，实现了意图分类。模拟实验验证了框架的有效性，涵盖轨迹生成、雷达测量等场景，为防御规划提供了可靠工具。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.RO",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "8 pages, 7 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2409.08472v1",
      "published_date": "2024-09-13 01:57:37 UTC",
      "updated_date": "2024-09-13 01:57:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:49:33.598120"
    },
    {
      "arxiv_id": "2409.08466v2",
      "title": "Explaining Datasets in Words: Statistical Models with Natural Language Parameters",
      "title_zh": "用",
      "authors": [
        "Ruiqi Zhong",
        "Heng Wang",
        "Dan Klein",
        "Jacob Steinhardt"
      ],
      "abstract": "To make sense of massive data, we often fit simplified models and then\ninterpret the parameters; for example, we cluster the text embeddings and then\ninterpret the mean parameters of each cluster. However, these parameters are\noften high-dimensional and hard to interpret. To make model parameters directly\ninterpretable, we introduce a family of statistical models -- including\nclustering, time series, and classification models -- parameterized by natural\nlanguage predicates. For example, a cluster of text about COVID could be\nparameterized by the predicate \"discusses COVID\". To learn these statistical\nmodels effectively, we develop a model-agnostic algorithm that optimizes\ncontinuous relaxations of predicate parameters with gradient descent and\ndiscretizes them by prompting language models (LMs). Finally, we apply our\nframework to a wide range of problems: taxonomizing user chat dialogues,\ncharacterizing how they evolve across time, finding categories where one\nlanguage model is better than the other, clustering math problems based on\nsubareas, and explaining visual features in memorable images. Our framework is\nhighly versatile, applicable to both textual and visual domains, can be easily\nsteered to focus on specific properties (e.g. subareas), and explains\nsophisticated concepts that classical methods (e.g. n-gram analysis) struggle\nto produce.",
      "tldr_zh": "本研究提出了一种以自然语言谓词(natural language predicates)作为参数的统计模型家族，包括聚类、时间序列和分类模型，以提升数据集参数的可解释性。研究开发了一个模型无关的算法，通过梯度下降(gradient descent)优化谓词参数的连续松弛版本，并利用语言模型(LMs)提示进行离散化，从而有效学习这些模型。该框架应用于多种场景，如分类用户聊天对话、分析其时间演变、比较语言模型性能、聚类数学问题和解释视觉特征，展示了其通用性、易于引导特定属性以及在处理复杂概念（如n-gram分析难以捕捉的内容）方面的优势。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.08466v2",
      "published_date": "2024-09-13 01:40:20 UTC",
      "updated_date": "2025-01-12 17:23:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:49:45.772129"
    },
    {
      "arxiv_id": "2409.08450v1",
      "title": "Inter Observer Variability Assessment through Ordered Weighted Belief Divergence Measure in MAGDM Application to the Ensemble Classifier Feature Fusion",
      "title_zh": "翻译失败",
      "authors": [
        "Pragya Gupta",
        "Debjani Chakraborty",
        "Debashree Guha"
      ],
      "abstract": "A large number of multi-attribute group decisionmaking (MAGDM) have been\nwidely introduced to obtain consensus results. However, most of the\nmethodologies ignore the conflict among the experts opinions and only consider\nequal or variable priorities of them. Therefore, this study aims to propose an\nEvidential MAGDM method by assessing the inter-observational variability and\nhandling uncertainty that emerges between the experts. The proposed framework\nhas fourfold contributions. First, the basic probability assignment (BPA)\ngeneration method is introduced to consider the inherent characteristics of\neach alternative by computing the degree of belief. Second, the ordered\nweighted belief and plausibility measure is constructed to capture the overall\nintrinsic information of the alternative by assessing the inter-observational\nvariability and addressing the conflicts emerging between the group of experts.\nAn ordered weighted belief divergence measure is constructed to acquire the\nweighted support for each group of experts to obtain the final preference\nrelationship. Finally, we have shown an illustrative example of the proposed\nEvidential MAGDM framework. Further, we have analyzed the interpretation of\nEvidential MAGDM in the real-world application for ensemble classifier feature\nfusion to diagnose retinal disorders using optical coherence tomography images.",
      "tldr_zh": "本研究针对多属性群决策（MAGDM）中专家意见冲突和不确定性问题，提出了一种基于证据的 Evidential MAGDM 方法，通过评估观察者间变异性来处理这些挑战。方法包括引入基本概率分配（BPA）生成机制来量化备选方案的信念度，以及构建有序加权信念差异度量，以捕获专家组的加权支持并获得最终偏好关系。实验示例展示了该框架的应用，并将其应用于集成分类器特征融合，用于诊断视网膜疾病的光学相干断层扫描图像分析中。总的来说，该方法提升了 MAGDM 的鲁棒性和准确性。",
      "categories": [
        "cs.AI",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.08450v1",
      "published_date": "2024-09-13 00:53:00 UTC",
      "updated_date": "2024-09-13 00:53:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:49:57.201817"
    },
    {
      "arxiv_id": "2409.08439v2",
      "title": "Input-to-State Stable Coupled Oscillator Networks for Closed-form Model-based Control in Latent Space",
      "title_zh": "输入到状态稳定的耦合振荡器网络，用于潜在空间中的闭式形式模型控制",
      "authors": [
        "Maximilian Stölzle",
        "Cosimo Della Santina"
      ],
      "abstract": "Even though a variety of methods have been proposed in the literature,\nefficient and effective latent-space control (i.e., control in a learned\nlow-dimensional space) of physical systems remains an open challenge. We argue\nthat a promising avenue is to leverage powerful and well-understood closed-form\nstrategies from control theory literature in combination with learned dynamics,\nsuch as potential-energy shaping. We identify three fundamental shortcomings in\nexisting latent-space models that have so far prevented this powerful\ncombination: (i) they lack the mathematical structure of a physical system,\n(ii) they do not inherently conserve the stability properties of the real\nsystems, (iii) these methods do not have an invertible mapping between input\nand latent-space forcing. This work proposes a novel Coupled Oscillator Network\n(CON) model that simultaneously tackles all these issues. More specifically,\n(i) we show analytically that CON is a Lagrangian system - i.e., it possesses\nwell-defined potential and kinetic energy terms. Then, (ii) we provide formal\nproof of global Input-to-State stability using Lyapunov arguments. Moving to\nthe experimental side, we demonstrate that CON reaches SoA performance when\nlearning complex nonlinear dynamics of mechanical systems directly from images.\nAn additional methodological innovation contributing to achieving this third\ngoal is an approximated closed-form solution for efficient integration of\nnetwork dynamics, which eases efficient training. We tackle (iii) by\napproximating the forcing-to-input mapping with a decoder that is trained to\nreconstruct the input based on the encoded latent space force. Finally, we show\nhow these properties enable latent-space control. We use an integral-saturated\nPID with potential force compensation and demonstrate high-quality performance\non a soft robot using raw pixels as the only feedback information.",
      "tldr_zh": "本文提出了一种 Input-to-State Stable 的 Coupled Oscillator Network (CON) 模型，用于潜在空间的封闭形式模型控制，旨在解决现有方法在物理系统结构、稳定性保留和输入-潜在空间映射可逆性上的三大不足。CON 被证明是一个 Lagrangian 系统，具有明确的势能和动能，并通过 Lyapunov 参数正式证明了其全局稳定性。该模型在实验中从图像直接学习复杂非线性动态，达到了 State-of-the-Art 性能，并通过近似封闭形式解和训练解码器实现了高效集成和控制。最后，作者展示了利用积分饱和 PID 和势能补偿，在软机器人上基于原始像素实现高质量的潜在空间控制。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "38th Conference on Neural Information Processing Systems (NeurIPS\n  2024) spotlight, 49 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.08439v2",
      "published_date": "2024-09-13 00:11:09 UTC",
      "updated_date": "2024-10-13 22:04:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:50:10.364854"
    },
    {
      "arxiv_id": "2409.08435v4",
      "title": "When Context Leads but Parametric Memory Follows in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yufei Tao",
        "Adam Hiatt",
        "Erik Haake",
        "Antonie J. Jetter",
        "Ameeta Agrawal"
      ],
      "abstract": "Large language models (LLMs) have demonstrated remarkable progress in\nleveraging diverse knowledge sources. This study investigates how nine widely\nused LLMs allocate knowledge between local context and global parameters when\nanswering open-ended questions in knowledge-consistent scenarios. We introduce\na novel dataset, WikiAtomic, and systematically vary context sizes to analyze\nhow LLMs prioritize and utilize the provided information and their parametric\nknowledge in knowledge-consistent scenarios. Additionally, we also study their\ntendency to hallucinate under varying context sizes. Our findings reveal\nconsistent patterns across models, including a consistent reliance on both\ncontextual (around 70%) and parametric (around 30%) knowledge, and a decrease\nin hallucinations with increasing context. These insights highlight the\nimportance of more effective context organization and developing models that\nuse input more deterministically for robust performance.",
      "tldr_zh": "本研究调查了九个广泛使用的Large Language Models (LLMs)，探讨它们在知识一致场景下回答开放性问题时，如何在本地上下文和全局参数之间分配知识。研究者引入了新数据集WikiAtomic，并通过系统改变上下文大小，分析模型对提供信息和参数知识的优先利用，以及在不同上下文条件下产生的hallucinations倾向。结果显示，LLMs一致依赖上下文知识（约70%）和参数知识（约30%），并随着上下文增加而减少hallucinations。这些发现强调了优化上下文组织和开发更确定性输入使用的模型，以提升LLMs的鲁棒性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by EMNLP 2024 Main Conference",
      "pdf_url": "http://arxiv.org/pdf/2409.08435v4",
      "published_date": "2024-09-13 00:03:19 UTC",
      "updated_date": "2024-11-21 02:31:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T23:50:20.782918"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 85,
  "processed_papers_count": 85,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-19T23:50:40.139794"
}