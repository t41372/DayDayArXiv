[
  {
    "arxiv_id": "2410.01810v2",
    "title": "Propaganda is all you need",
    "authors": [
      "Paul Kronlund-Drouault"
    ],
    "abstract": "As Machine Learning (ML) is still a recent field of study, especially outside\nthe realm of abstract Mathematics and Computer Science, few works have been\nconducted on the political aspect of large Language Models (LLMs), and more\nparticularly about the alignment process and its political dimension. This\nprocess can be as simple as prompt engineering but is also very complex and can\naffect completely unrelated notions. For example, politically directed\nalignment has a very strong impact on an LLM's embedding space and the relative\nposition of political notions in such a space. Using special tools to evaluate\ngeneral political bias and analyze the effects of alignment, we can gather new\ndata to understand its causes and possible consequences on society. Indeed, by\ntaking a socio-political approach, we can hypothesize that most big LLMs are\naligned with what Marxist philosophy calls the 'dominant ideology.' As AI's\nrole in political decision-making, at the citizen's scale but also in\ngovernment agencies, such biases can have huge effects on societal change,\neither by creating new and insidious pathways for societal uniformity or by\nallowing disguised extremist views to gain traction among the people.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01810v2",
    "published_date": "2024-09-13 22:10:42 UTC",
    "updated_date": "2025-04-01 19:54:05 UTC"
  },
  {
    "arxiv_id": "2409.09201v3",
    "title": "Contextual Evaluation of Large Language Models for Classifying Tropical and Infectious Diseases",
    "authors": [
      "Mercy Asiedu",
      "Nenad Tomasev",
      "Chintan Ghate",
      "Tiya Tiyasirichokchai",
      "Awa Dieng",
      "Oluwatosin Akande",
      "Geoffrey Siwo",
      "Steve Adudans",
      "Sylvanus Aitkins",
      "Odianosen Ehiakhamen",
      "Eric Ndombi",
      "Katherine Heller"
    ],
    "abstract": "While large language models (LLMs) have shown promise for medical question\nanswering, there is limited work focused on tropical and infectious\ndisease-specific exploration. We build on an opensource tropical and infectious\ndiseases (TRINDs) dataset, expanding it to include demographic and semantic\nclinical and consumer augmentations yielding 11000+ prompts. We evaluate LLM\nperformance on these, comparing generalist and medical LLMs, as well as LLM\noutcomes to human experts. We demonstrate through systematic experimentation,\nthe benefit of contextual information such as demographics, location, gender,\nrisk factors for optimal LLM response. Finally we develop a prototype of\nTRINDs-LM, a research tool that provides a playground to navigate how context\nimpacts LLM outputs for health.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at 2 NeurIPS 2024 workshops: Generative AI for Health\n  Workshop and Workshop on Advancements In Medical Foundation Models:\n  Explainability, Robustness, Security, and Beyond",
    "pdf_url": "http://arxiv.org/pdf/2409.09201v3",
    "published_date": "2024-09-13 21:28:54 UTC",
    "updated_date": "2025-01-15 18:52:52 UTC"
  },
  {
    "arxiv_id": "2409.09194v2",
    "title": "Hierarchical Hypercomplex Network for Multimodal Emotion Recognition",
    "authors": [
      "Eleonora Lopez",
      "Aurelio Uncini",
      "Danilo Comminiello"
    ],
    "abstract": "Emotion recognition is relevant in various domains, ranging from healthcare\nto human-computer interaction. Physiological signals, being beyond voluntary\ncontrol, offer reliable information for this purpose, unlike speech and facial\nexpressions which can be controlled at will. They reflect genuine emotional\nresponses, devoid of conscious manipulation, thereby enhancing the credibility\nof emotion recognition systems. Nonetheless, multimodal emotion recognition\nwith deep learning models remains a relatively unexplored field. In this paper,\nwe introduce a fully hypercomplex network with a hierarchical learning\nstructure to fully capture correlations. Specifically, at the encoder level,\nthe model learns intra-modal relations among the different channels of each\ninput signal. Then, a hypercomplex fusion module learns inter-modal relations\namong the embeddings of the different modalities. The main novelty is in\nexploiting intra-modal relations by endowing the encoders with parameterized\nhypercomplex convolutions (PHCs) that thanks to hypercomplex algebra can\ncapture inter-channel interactions within single modalities. Instead, the\nfusion module comprises parameterized hypercomplex multiplications (PHMs) that\ncan model inter-modal correlations. The proposed architecture surpasses\nstate-of-the-art models on the MAHNOB-HCI dataset for emotion recognition,\nspecifically in classifying valence and arousal from electroencephalograms\n(EEGs) and peripheral physiological signals. The code of this study is\navailable at https://github.com/ispamm/MHyEEG.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "The paper has been accepted at MLSP 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.09194v2",
    "published_date": "2024-09-13 21:07:49 UTC",
    "updated_date": "2024-10-10 15:35:49 UTC"
  },
  {
    "arxiv_id": "2409.09191v2",
    "title": "ProcessTBench: An LLM Plan Generation Dataset for Process Mining",
    "authors": [
      "Andrei Cosmin Redis",
      "Mohammadreza Fani Sani",
      "Bahram Zarrin",
      "Andrea Burattin"
    ],
    "abstract": "Large Language Models (LLMs) have shown significant promise in plan\ngeneration. Yet, existing datasets often lack the complexity needed for\nadvanced tool use scenarios - such as handling paraphrased query statements,\nsupporting multiple languages, and managing actions that can be done in\nparallel. These scenarios are crucial for evaluating the evolving capabilities\nof LLMs in real-world applications. Moreover, current datasets don't enable the\nstudy of LLMs from a process perspective, particularly in scenarios where\nunderstanding typical behaviors and challenges in executing the same process\nunder different conditions or formulations is crucial. To address these gaps,\nwe present the ProcessTBench synthetic dataset, an extension of the TaskBench\ndataset specifically designed to evaluate LLMs within a process mining\nframework.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.LG",
    "comment": "6 pages, 4 figures, dataset available at\n  https://github.com/microsoft/ProcessTBench",
    "pdf_url": "http://arxiv.org/pdf/2409.09191v2",
    "published_date": "2024-09-13 20:56:21 UTC",
    "updated_date": "2024-09-19 16:46:17 UTC"
  },
  {
    "arxiv_id": "2410.01809v1",
    "title": "Enhancing transparency in AI-powered customer engagement",
    "authors": [
      "Tara DeZao"
    ],
    "abstract": "This paper addresses the critical challenge of building consumer trust in\nAI-powered customer engagement by emphasising the necessity for transparency\nand accountability. Despite the potential of AI to revolutionise business\noperations and enhance customer experiences, widespread concerns about\nmisinformation and the opacity of AI decision-making processes hinder trust.\nSurveys highlight a significant lack of awareness among consumers regarding\ntheir interactions with AI, alongside apprehensions about bias and fairness in\nAI algorithms. The paper advocates for the development of explainable AI models\nthat are transparent and understandable to both consumers and organisational\nleaders, thereby mitigating potential biases and ensuring ethical use. It\nunderscores the importance of organisational commitment to transparency\npractices beyond mere regulatory compliance, including fostering a culture of\naccountability, prioritising clear data policies and maintaining active\nengagement with stakeholders. By adopting a holistic approach to transparency\nand explainability, businesses can cultivate trust in AI technologies, bridging\nthe gap between technological innovation and consumer acceptance, and paving\nthe way for more ethical and effective AI-powered customer engagements.\nKEYWORDS: artificial intelligence (AI), transparency",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.01809v1",
    "published_date": "2024-09-13 20:26:11 UTC",
    "updated_date": "2024-09-13 20:26:11 UTC"
  },
  {
    "arxiv_id": "2409.09174v1",
    "title": "Incorporation of Verifier Functionality in the Software for Operations and Network Attack Results Review and the Autonomous Penetration Testing System",
    "authors": [
      "Jordan Milbrath",
      "Jeremy Straub"
    ],
    "abstract": "The software for operations and network attack results review (SONARR) and\nthe autonomous penetration testing system (APTS) use facts and common\nproperties in digital twin networks to represent real-world entities. However,\nin some cases fact values will change regularly, making it difficult for\nobjects in SONARR and APTS to consistently and accurately represent their\nreal-world counterparts. This paper proposes and evaluates the addition of\nverifiers, which check real-world conditions and update network facts, to\nSONARR. This inclusion allows SONARR to retrieve fact values from its executing\nenvironment and update its network, providing a consistent method of ensuring\nthat the operations and, therefore, the results align with the real-world\nsystems being assessed. Verifiers allow arbitrary scripts and dynamic arguments\nto be added to normal SONARR operations. This provides a layer of flexibility\nand consistency that results in more reliable output from the software.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "The U.S. federal sponsor has requested that we not include funding\n  acknowledgement for this publication",
    "pdf_url": "http://arxiv.org/pdf/2409.09174v1",
    "published_date": "2024-09-13 20:17:52 UTC",
    "updated_date": "2024-09-13 20:17:52 UTC"
  },
  {
    "arxiv_id": "2409.09173v1",
    "title": "Phikon-v2, A large and public feature extractor for biomarker prediction",
    "authors": [
      "Alexandre Filiot",
      "Paul Jacob",
      "Alice Mac Kain",
      "Charlie Saillard"
    ],
    "abstract": "Gathering histopathology slides from over 100 publicly available cohorts, we\ncompile a diverse dataset of 460 million pathology tiles covering more than 30\ncancer sites. Using this dataset, we train a large self-supervised vision\ntransformer using DINOv2 and publicly release one iteration of this model for\nfurther experimentation, coined Phikon-v2. While trained on publicly available\nhistology slides, Phikon-v2 surpasses our previously released model (Phikon)\nand performs on par with other histopathology foundation models (FM) trained on\nproprietary data. Our benchmarks include eight slide-level tasks with results\nreported on external validation cohorts avoiding any data contamination between\npre-training and evaluation datasets. Our downstream training procedure follows\na simple yet robust ensembling strategy yielding a +1.75 AUC increase across\ntasks and models compared to one-shot retraining (p<0.001). We compare Phikon\n(ViT-B) and Phikon-v2 (ViT-L) against 14 different histology feature\nextractors, making our evaluation the most comprehensive to date. Our result\nsupport evidences that DINOv2 handles joint model and data scaling better than\niBOT. Also, we show that recent scaling efforts are overall beneficial to\ndownstream performance in the context of biomarker prediction with GigaPath and\nH-Optimus-0 (two ViT-g with 1.1B parameters each) standing out. However, the\nstatistical margins between the latest top-performing FMs remain mostly\nnon-significant; some even underperform on specific indications or tasks such\nas MSI prediction - deposed by a 13x smaller model developed internally. While\nlatest foundation models may exhibit limitations for clinical deployment, they\nnonetheless offer excellent grounds for the development of more specialized and\ncost-efficient histology encoders fueling AI-guided diagnostic tools.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.09173v1",
    "published_date": "2024-09-13 20:12:29 UTC",
    "updated_date": "2024-09-13 20:12:29 UTC"
  },
  {
    "arxiv_id": "2409.09171v1",
    "title": "The Challenges of Effective AGM Belief Contraction",
    "authors": [
      "Dominik Klumpp",
      "Jandson S. Ribeiro"
    ],
    "abstract": "Despite the significant interest in extending the AGM paradigm of belief\nchange beyond finitary logics, the computational aspects of AGM have remained\nalmost untouched. We investigate the computability of AGM contraction on\nnon-finitary logics, and show an intriguing negative result: there are\ninfinitely many uncomputable AGM contraction functions in such logics.\nDrastically, even if we restrict the theories used to represent epistemic\nstates, in all non-trivial cases, the uncomputability remains. On the positive\nside, we identify an infinite class of computable AGM contraction functions on\nLinear Temporal Logic (LTL). We use B\\\"uchi automata to construct such\nfunctions as well as to represent and reason about LTL knowledge.",
    "categories": [
      "cs.LO",
      "cs.AI"
    ],
    "primary_category": "cs.LO",
    "comment": "20 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.09171v1",
    "published_date": "2024-09-13 20:03:53 UTC",
    "updated_date": "2024-09-13 20:03:53 UTC"
  },
  {
    "arxiv_id": "2409.09169v2",
    "title": "Curricula for Learning Robust Policies with Factored State Representations in Changing Environments",
    "authors": [
      "Panayiotis Panayiotou",
      "Özgür Şimşek"
    ],
    "abstract": "Robust policies enable reinforcement learning agents to effectively adapt to\nand operate in unpredictable, dynamic, and ever-changing real-world\nenvironments. Factored representations, which break down complex state and\naction spaces into distinct components, can improve generalization and sample\nefficiency in policy learning. In this paper, we explore how the curriculum of\nan agent using a factored state representation affects the robustness of the\nlearned policy. We experimentally demonstrate three simple curricula, such as\nvarying only the variable of highest regret between episodes, that can\nsignificantly enhance policy robustness, offering practical insights for\nreinforcement learning in complex environments.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "17th European Workshop on Reinforcement Learning (EWRL 2024)",
    "pdf_url": "http://arxiv.org/pdf/2409.09169v2",
    "published_date": "2024-09-13 19:58:43 UTC",
    "updated_date": "2024-09-19 11:03:24 UTC"
  },
  {
    "arxiv_id": "2409.09135v1",
    "title": "Multimodal Fusion with LLMs for Engagement Prediction in Natural Conversation",
    "authors": [
      "Cheng Charles Ma",
      "Kevin Hyekang Joo",
      "Alexandria K. Vail",
      "Sunreeta Bhattacharya",
      "Álvaro Fernández García",
      "Kailana Baker-Matsuoka",
      "Sheryl Mathew",
      "Lori L. Holt",
      "Fernando De la Torre"
    ],
    "abstract": "Over the past decade, wearable computing devices (``smart glasses'') have\nundergone remarkable advancements in sensor technology, design, and processing\npower, ushering in a new era of opportunity for high-density human behavior\ndata. Equipped with wearable cameras, these glasses offer a unique opportunity\nto analyze non-verbal behavior in natural settings as individuals interact. Our\nfocus lies in predicting engagement in dyadic interactions by scrutinizing\nverbal and non-verbal cues, aiming to detect signs of disinterest or confusion.\nLeveraging such analyses may revolutionize our understanding of human\ncommunication, foster more effective collaboration in professional\nenvironments, provide better mental health support through empathetic virtual\ninteractions, and enhance accessibility for those with communication barriers.\n  In this work, we collect a dataset featuring 34 participants engaged in\ncasual dyadic conversations, each providing self-reported engagement ratings at\nthe end of each conversation. We introduce a novel fusion strategy using Large\nLanguage Models (LLMs) to integrate multiple behavior modalities into a\n``multimodal transcript'' that can be processed by an LLM for behavioral\nreasoning tasks. Remarkably, this method achieves performance comparable to\nestablished fusion techniques even in its preliminary implementation,\nindicating strong potential for further research and optimization. This fusion\nmethod is one of the first to approach ``reasoning'' about real-world human\nbehavior through a language model. Smart glasses provide us the ability to\nunobtrusively gather high-density multimodal data on human behavior, paving the\nway for new approaches to understanding and improving human communication with\nthe potential for important societal benefits. The features and data collected\nduring the studies will be made publicly available to promote further research.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "22 pages, first three authors equal contribution",
    "pdf_url": "http://arxiv.org/pdf/2409.09135v1",
    "published_date": "2024-09-13 18:28:12 UTC",
    "updated_date": "2024-09-13 18:28:12 UTC"
  },
  {
    "arxiv_id": "2409.11169v2",
    "title": "MAISI: Medical AI for Synthetic Imaging",
    "authors": [
      "Pengfei Guo",
      "Can Zhao",
      "Dong Yang",
      "Ziyue Xu",
      "Vishwesh Nath",
      "Yucheng Tang",
      "Benjamin Simon",
      "Mason Belue",
      "Stephanie Harmon",
      "Baris Turkbey",
      "Daguang Xu"
    ],
    "abstract": "Medical imaging analysis faces challenges such as data scarcity, high\nannotation costs, and privacy concerns. This paper introduces the Medical AI\nfor Synthetic Imaging (MAISI), an innovative approach using the diffusion model\nto generate synthetic 3D computed tomography (CT) images to address those\nchallenges. MAISI leverages the foundation volume compression network and the\nlatent diffusion model to produce high-resolution CT images (up to a landmark\nvolume dimension of 512 x 512 x 768 ) with flexible volume dimensions and voxel\nspacing. By incorporating ControlNet, MAISI can process organ segmentation,\nincluding 127 anatomical structures, as additional conditions and enables the\ngeneration of accurately annotated synthetic images that can be used for\nvarious downstream tasks. Our experiment results show that MAISI's capabilities\nin generating realistic, anatomically accurate images for diverse regions and\nconditions reveal its promising potential to mitigate challenges using\nsynthetic data.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "WACV25 accepted. https://monai.io/research/maisi",
    "pdf_url": "http://arxiv.org/pdf/2409.11169v2",
    "published_date": "2024-09-13 18:15:08 UTC",
    "updated_date": "2024-10-29 19:17:36 UTC"
  },
  {
    "arxiv_id": "2409.10566v1",
    "title": "Eureka: Evaluating and Understanding Large Foundation Models",
    "authors": [
      "Vidhisha Balachandran",
      "Jingya Chen",
      "Neel Joshi",
      "Besmira Nushi",
      "Hamid Palangi",
      "Eduardo Salinas",
      "Vibhav Vineet",
      "James Woffinden-Luey",
      "Safoora Yousefi"
    ],
    "abstract": "Rigorous and reproducible evaluation is critical for assessing the state of\nthe art and for guiding scientific advances in Artificial Intelligence.\nEvaluation is challenging in practice due to several reasons, including\nbenchmark saturation, lack of transparency in methods used for measurement,\ndevelopment challenges in extracting measurements for generative tasks, and,\nmore generally, the extensive number of capabilities required for a\nwell-rounded comparison across models. We make three contributions to alleviate\nthe above challenges. First, we present Eureka, an open-source framework for\nstandardizing evaluations of large foundation models beyond single-score\nreporting and rankings. Second, we introduce Eureka-Bench as an extensible\ncollection of benchmarks testing capabilities that (i) are still challenging\nfor state-of-the-art models and (ii) represent fundamental but overlooked\nlanguage and multimodal capabilities. The inherent space for improvement in\nnon-saturated benchmarks enables us to discover meaningful differences between\nmodels at a capability level. Third, using Eureka, we conduct an analysis of 12\nstate-of-the-art models, providing in-depth insights into failure understanding\nand model comparison, which can be leveraged to plan targeted improvements. In\ncontrast to recent trends in reports and leaderboards showing absolute rankings\nand claims for one model or another to be the best, our analysis shows that\nthere is no such best model. Different models have different strengths, but\nthere are models that appear more often than others as best performers for some\ncapabilities. Despite the recent improvements, current models still struggle\nwith several fundamental capabilities including detailed image understanding,\nbenefiting from multimodal input when available rather than fully relying on\nlanguage, factuality and grounding for information retrieval, and over\nrefusals.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "I.2"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.10566v1",
    "published_date": "2024-09-13 18:01:49 UTC",
    "updated_date": "2024-09-13 18:01:49 UTC"
  },
  {
    "arxiv_id": "2410.01808v1",
    "title": "AI Horizon Scanning, White Paper p3395, IEEE-SA. Part I: Areas of Attention",
    "authors": [
      "Marina Cortês",
      "Andrew R. Liddle",
      "Christos Emmanouilidis",
      "Anthony E. Kelly",
      "Ken Matusow",
      "Ragu Ragunathan",
      "Jayne M. Suess",
      "George Tambouratzis",
      "Janusz Zalewski",
      "David A. Bray"
    ],
    "abstract": "Generative Artificial Intelligence (AI) models may carry societal\ntransformation to an extent demanding a delicate balance between opportunity\nand risk. This manuscript is the first of a series of White Papers informing\nthe development of IEEE-SA's p3995: `Standard for the Implementation of\nSafeguards, Controls, and Preventive Techniques for Artificial Intelligence\n(AI) Models', Chair: Marina Cort\\^{e}s\n(https://standards.ieee.org/ieee/3395/11378/). In this first horizon-scanning\nwe identify key attention areas for standards activities in AI. We examine\ndifferent principles for regulatory efforts, and review notions of\naccountability, privacy, data rights and mis-use. As a safeguards standard we\ndevote significant attention to the stability of global infrastructures and\nconsider a possible overdependence on cloud computing that may result from\ndensely coupled AI components. We review the recent cascade-failure-like\nCrowdstrike event in July 2024, as an illustration of potential impacts on\ncritical infrastructures from AI-induced incidents in the (near) future. It is\nthe first of a set of articles intended as White Papers informing the audience\non the standard development. Upcoming articles will focus on regulatory\ninitiatives, technology evolution and the role of AI in specific domains.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "This is an interim version of our p3395 working group White Paper. We\n  will update this version, until publication by the Institute of Electrical\n  and Electronics Engineers, Standards Association (IEEE-SA), Sponsor Committee\n  - Artificial Intelligence Standards Committee (C/AISC);\n  https://standards.ieee.org/ieee/3395/11378/",
    "pdf_url": "http://arxiv.org/pdf/2410.01808v1",
    "published_date": "2024-09-13 18:00:01 UTC",
    "updated_date": "2024-09-13 18:00:01 UTC"
  },
  {
    "arxiv_id": "2409.09032v1",
    "title": "The unknotting number, hard unknot diagrams, and reinforcement learning",
    "authors": [
      "Taylor Applebaum",
      "Sam Blackwell",
      "Alex Davies",
      "Thomas Edlich",
      "András Juhász",
      "Marc Lackenby",
      "Nenad Tomašev",
      "Daniel Zheng"
    ],
    "abstract": "We have developed a reinforcement learning agent that often finds a minimal\nsequence of unknotting crossing changes for a knot diagram with up to 200\ncrossings, hence giving an upper bound on the unknotting number. We have used\nthis to determine the unknotting number of 57k knots. We took diagrams of\nconnected sums of such knots with oppositely signed signatures, where the\nsummands were overlaid. The agent has found examples where several of the\ncrossing changes in an unknotting collection of crossings result in hyperbolic\nknots. Based on this, we have shown that, given knots $K$ and $K'$ that satisfy\nsome mild assumptions, there is a diagram of their connected sum and $u(K) +\nu(K')$ unknotting crossings such that changing any one of them results in a\nprime knot. As a by-product, we have obtained a dataset of 2.6 million distinct\nhard unknot diagrams; most of them under 35 crossings. Assuming the additivity\nof the unknotting number, we have determined the unknotting number of 43 at\nmost 12-crossing knots for which the unknotting number is unknown.",
    "categories": [
      "math.GT",
      "cs.AI",
      "cs.LG",
      "57K10, 57K14, 68T07, 68T20",
      "I.2.1; I.2.6; I.2.8"
    ],
    "primary_category": "math.GT",
    "comment": "29 pages, 17 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.09032v1",
    "published_date": "2024-09-13 17:59:52 UTC",
    "updated_date": "2024-09-13 17:59:52 UTC"
  },
  {
    "arxiv_id": "2409.09030v2",
    "title": "Agents in Software Engineering: Survey, Landscape, and Vision",
    "authors": [
      "Yanlin Wang",
      "Wanjun Zhong",
      "Yanxian Huang",
      "Ensheng Shi",
      "Min Yang",
      "Jiachi Chen",
      "Hui Li",
      "Yuchi Ma",
      "Qianxiang Wang",
      "Zibin Zheng"
    ],
    "abstract": "In recent years, Large Language Models (LLMs) have achieved remarkable\nsuccess and have been widely used in various downstream tasks, especially in\nthe tasks of the software engineering (SE) field. We find that many studies\ncombining LLMs with SE have employed the concept of agents either explicitly or\nimplicitly. However, there is a lack of an in-depth survey to sort out the\ndevelopment context of existing works, analyze how existing works combine the\nLLM-based agent technologies to optimize various tasks, and clarify the\nframework of LLM-based agents in SE. In this paper, we conduct the first survey\nof the studies on combining LLM-based agents with SE and present a framework of\nLLM-based agents in SE which includes three key modules: perception, memory,\nand action. We also summarize the current challenges in combining the two\nfields and propose future opportunities in response to existing challenges. We\nmaintain a GitHub repository of the related papers at:\nhttps://github.com/DeepSoftwareAnalytics/Awesome-Agent4SE.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "12 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.09030v2",
    "published_date": "2024-09-13 17:55:58 UTC",
    "updated_date": "2024-09-23 17:55:07 UTC"
  },
  {
    "arxiv_id": "2409.09111v1",
    "title": "Neural Message Passing Induced by Energy-Constrained Diffusion",
    "authors": [
      "Qitian Wu",
      "David Wipf",
      "Junchi Yan"
    ],
    "abstract": "Learning representations for structured data with certain geometries\n(observed or unobserved) is a fundamental challenge, wherein message passing\nneural networks (MPNNs) have become a de facto class of model solutions. In\nthis paper, we propose an energy-constrained diffusion model as a principled\ninterpretable framework for understanding the mechanism of MPNNs and navigating\nnovel architectural designs. The model, inspired by physical systems, combines\nthe inductive bias of diffusion on manifolds with layer-wise constraints of\nenergy minimization. As shown by our analysis, the diffusion operators have a\none-to-one correspondence with the energy functions implicitly descended by the\ndiffusion process, and the finite-difference iteration for solving the\nenergy-constrained diffusion system induces the propagation layers of various\ntypes of MPNNs operated on observed or latent structures. On top of these\nfindings, we devise a new class of neural message passing models, dubbed as\ndiffusion-inspired Transformers, whose global attention layers are induced by\nthe principled energy-constrained diffusion. Across diverse datasets ranging\nfrom real-world networks to images and physical particles, we show that the new\nmodel can yield promising performance for cases where the data structures are\nobserved (as a graph), partially observed or completely unobserved.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Extended version from DIFFormer paper in ICLR2023. arXiv admin note:\n  text overlap with arXiv:2301.09474",
    "pdf_url": "http://arxiv.org/pdf/2409.09111v1",
    "published_date": "2024-09-13 17:54:41 UTC",
    "updated_date": "2024-09-13 17:54:41 UTC"
  },
  {
    "arxiv_id": "2409.09026v1",
    "title": "Towards Leveraging Contrastively Pretrained Neural Audio Embeddings for Recommender Tasks",
    "authors": [
      "Florian Grötschla",
      "Luca Strässle",
      "Luca A. Lanzendörfer",
      "Roger Wattenhofer"
    ],
    "abstract": "Music recommender systems frequently utilize network-based models to capture\nrelationships between music pieces, artists, and users. Although these\nrelationships provide valuable insights for predictions, new music pieces or\nartists often face the cold-start problem due to insufficient initial\ninformation. To address this, one can extract content-based information\ndirectly from the music to enhance collaborative-filtering-based methods. While\nprevious approaches have relied on hand-crafted audio features for this\npurpose, we explore the use of contrastively pretrained neural audio embedding\nmodels, which offer a richer and more nuanced representation of music. Our\nexperiments demonstrate that neural embeddings, particularly those generated\nwith the Contrastive Language-Audio Pretraining (CLAP) model, present a\npromising approach to enhancing music recommendation tasks within graph-based\nframeworks.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted at the 2nd Music Recommender Workshop (@RecSys)",
    "pdf_url": "http://arxiv.org/pdf/2409.09026v1",
    "published_date": "2024-09-13 17:53:06 UTC",
    "updated_date": "2024-09-13 17:53:06 UTC"
  },
  {
    "arxiv_id": "2409.09013v2",
    "title": "AI-LieDar: Examine the Trade-off Between Utility and Truthfulness in LLM Agents",
    "authors": [
      "Zhe Su",
      "Xuhui Zhou",
      "Sanketh Rangreji",
      "Anubha Kabra",
      "Julia Mendelsohn",
      "Faeze Brahman",
      "Maarten Sap"
    ],
    "abstract": "Truthfulness (adherence to factual accuracy) and utility (satisfying human\nneeds and instructions) are both fundamental aspects of Large Language Models,\nyet these goals often conflict (e.g., sell a car with known flaws), which makes\nit challenging to achieve both in real-world deployments. We propose AI-LieDar,\na framework to study how LLM-based agents navigate these scenarios in an\nmulti-turn interactive setting. We design a set of real-world scenarios where\nlanguage agents are instructed to achieve goals that are in conflict with being\ntruthful during a multi-turn conversation with simulated human agents. To\nevaluate the truthfulness at large scale, we develop a truthfulness detector\ninspired by psychological literature to assess the agents' responses. Our\nexperiment demonstrates that all models are truthful less than 50% of the time,\nthough truthfulness and goal achievement (utility) rates vary across models. We\nfurther test the steerability of LLMs towards truthfulness, finding that models\ncan be directed to be truthful or deceptive, and even truth-steered models\nstill lie. These findings reveal the complex nature of truthfulness in LLMs and\nunderscore the importance of further research to ensure the safe and reliable\ndeployment of LLMs and LLM-based agents.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.09013v2",
    "published_date": "2024-09-13 17:41:12 UTC",
    "updated_date": "2025-04-28 04:20:13 UTC"
  },
  {
    "arxiv_id": "2409.09011v1",
    "title": "VAE Explainer: Supplement Learning Variational Autoencoders with Interactive Visualization",
    "authors": [
      "Donald Bertucci",
      "Alex Endert"
    ],
    "abstract": "Variational Autoencoders are widespread in Machine Learning, but are\ntypically explained with dense math notation or static code examples. This\npaper presents VAE Explainer, an interactive Variational Autoencoder running in\nthe browser to supplement existing static documentation (e.g., Keras Code\nExamples). VAE Explainer adds interactions to the VAE summary with interactive\nmodel inputs, latent space, and output. VAE Explainer connects the high-level\nunderstanding with the implementation: annotated code and a live computational\ngraph. The VAE Explainer interactive visualization is live at\nhttps://xnought.github.io/vae-explainer and the code is open source at\nhttps://github.com/xnought/vae-explainer.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "6 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.09011v1",
    "published_date": "2024-09-13 17:40:01 UTC",
    "updated_date": "2024-09-13 17:40:01 UTC"
  },
  {
    "arxiv_id": "2409.09010v1",
    "title": "Contri(e)ve: Context + Retrieve for Scholarly Question Answering",
    "authors": [
      "Kanchan Shivashankar",
      "Nadine Steinmetz"
    ],
    "abstract": "Scholarly communication is a rapid growing field containing a wealth of\nknowledge. However, due to its unstructured and document format, it is\nchallenging to extract useful information from them through conventional\ndocument retrieval methods. Scholarly knowledge graphs solve this problem, by\nrepresenting the documents in a semantic network, providing, hidden insights,\nsummaries and ease of accessibility through queries. Naturally, question\nanswering for scholarly graphs expands the accessibility to a wider audience.\nBut some of the knowledge in this domain is still presented as unstructured\ntext, thus requiring a hybrid solution for question answering systems. In this\npaper, we present a two step solution using open source Large Language\nModel(LLM): Llama3.1 for Scholarly-QALD dataset. Firstly, we extract the\ncontext pertaining to the question from different structured and unstructured\ndata sources: DBLP, SemOpenAlex knowledge graphs and Wikipedia text. Secondly,\nwe implement prompt engineering to improve the information retrieval\nperformance of the LLM. Our approach achieved an F1 score of 40% and also\nobserved some anomalous responses from the LLM, that are discussed in the final\npart of the paper.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.09010v1",
    "published_date": "2024-09-13 17:38:47 UTC",
    "updated_date": "2024-09-13 17:38:47 UTC"
  },
  {
    "arxiv_id": "2409.09007v1",
    "title": "SGFormer: Single-Layer Graph Transformers with Approximation-Free Linear Complexity",
    "authors": [
      "Qitian Wu",
      "Kai Yang",
      "Hengrui Zhang",
      "David Wipf",
      "Junchi Yan"
    ],
    "abstract": "Learning representations on large graphs is a long-standing challenge due to\nthe inter-dependence nature. Transformers recently have shown promising\nperformance on small graphs thanks to its global attention for capturing\nall-pair interactions beyond observed structures. Existing approaches tend to\ninherit the spirit of Transformers in language and vision tasks, and embrace\ncomplicated architectures by stacking deep attention-based propagation layers.\nIn this paper, we attempt to evaluate the necessity of adopting multi-layer\nattentions in Transformers on graphs, which considerably restricts the\nefficiency. Specifically, we analyze a generic hybrid propagation layer,\ncomprised of all-pair attention and graph-based propagation, and show that\nmulti-layer propagation can be reduced to one-layer propagation, with the same\ncapability for representation learning. It suggests a new technical path for\nbuilding powerful and efficient Transformers on graphs, particularly through\nsimplifying model architectures without sacrificing expressiveness. As\nexemplified by this work, we propose a Simplified Single-layer Graph\nTransformers (SGFormer), whose main component is a single-layer global\nattention that scales linearly w.r.t. graph sizes and requires none of any\napproximation for accommodating all-pair interactions. Empirically, SGFormer\nsuccessfully scales to the web-scale graph ogbn-papers100M, yielding\norders-of-magnitude inference acceleration over peer Transformers on\nmedium-sized graphs, and demonstrates competitiveness with limited labeled\ndata.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Extended version of NeurIPS2023 contribution arXiv:2306.10759",
    "pdf_url": "http://arxiv.org/pdf/2409.09007v1",
    "published_date": "2024-09-13 17:37:34 UTC",
    "updated_date": "2024-09-13 17:37:34 UTC"
  },
  {
    "arxiv_id": "2409.09001v1",
    "title": "E2MoCase: A Dataset for Emotional, Event and Moral Observations in News Articles on High-impact Legal Cases",
    "authors": [
      "Candida M. Greco",
      "Lorenzo Zangari",
      "Davide Picca",
      "Andrea Tagarelli"
    ],
    "abstract": "The way media reports on legal cases can significantly shape public opinion,\noften embedding subtle biases that influence societal views on justice and\nmorality. Analyzing these biases requires a holistic approach that captures the\nemotional tone, moral framing, and specific events within the narratives. In\nthis work we introduce E2MoCase, a novel dataset designed to facilitate the\nintegrated analysis of emotions, moral values, and events within legal\nnarratives and media coverage. By leveraging advanced models for emotion\ndetection, moral value identification, and event extraction, E2MoCase offers a\nmulti-dimensional perspective on how legal cases are portrayed in news\narticles.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.DL",
      "physics.soc-ph"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.09001v1",
    "published_date": "2024-09-13 17:31:09 UTC",
    "updated_date": "2024-09-13 17:31:09 UTC"
  },
  {
    "arxiv_id": "2409.08980v2",
    "title": "Predicting Trust In Autonomous Vehicles: Modeling Young Adult Psychosocial Traits, Risk-Benefit Attitudes, And Driving Factors With Machine Learning",
    "authors": [
      "Robert Kaufman",
      "Emi Lee",
      "Manas Satish Bedmutha",
      "David Kirsh",
      "Nadir Weibel"
    ],
    "abstract": "Low trust remains a significant barrier to Autonomous Vehicle (AV) adoption.\nTo design trustworthy AVs, we need to better understand the individual traits,\nattitudes, and experiences that impact people's trust judgements. We use\nmachine learning to understand the most important factors that contribute to\nyoung adult trust based on a comprehensive set of personal factors gathered via\nsurvey (n = 1457). Factors ranged from psychosocial and cognitive attributes to\ndriving style, experiences, and perceived AV risks and benefits. Using the\nexplainable AI technique SHAP, we found that perceptions of AV risks and\nbenefits, attitudes toward feasibility and usability, institutional trust,\nprior experience, and a person's mental model are the most important\npredictors. Surprisingly, psychosocial and many technology- and\ndriving-specific factors were not strong predictors. Results highlight the\nimportance of individual differences for designing trustworthy AVs for diverse\ngroups and lead to key implications for future design and research.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "24 pages (including references and appendix), Accepted to CHI\n  Conference on Human Factors in Computing Systems (CHI 2025)",
    "pdf_url": "http://arxiv.org/pdf/2409.08980v2",
    "published_date": "2024-09-13 16:52:24 UTC",
    "updated_date": "2025-01-28 21:26:35 UTC"
  },
  {
    "arxiv_id": "2409.13749v1",
    "title": "KodeXv0.1: A Family of State-of-the-Art Financial Large Language Models",
    "authors": [
      "Neel Rajani",
      "Lilli Kiessling",
      "Aleksandr Ogaltsov",
      "Claus Lang"
    ],
    "abstract": "Although powerful, current cutting-edge LLMs may not fulfil the needs of\nhighly specialised sectors. We introduce KodeXv0.1, a family of large language\nmodels that outclass GPT-4 in financial question answering. We utilise the base\nvariants of Llama 3.1 8B and 70B and adapt them to the financial domain through\na custom training regime. To this end, we collect and process a large number of\npublicly available financial documents such as earnings calls and business\nreports. These are used to generate a high-quality, synthetic dataset\nconsisting of Context-Question-Answer triplets which closely mirror real-world\nfinancial tasks. Using the train split of this dataset, we perform RAG-aware\n4bit LoRA instruction tuning runs of Llama 3.1 base variants to produce\nKodeX-8Bv0.1 and KodeX-70Bv0.1. We then complete extensive model evaluations\nusing FinanceBench, FinQABench and the withheld test split of our dataset. Our\nresults show that KodeX-8Bv0.1 is more reliable in financial contexts than\ncutting-edge instruct models in the same parameter regime, surpassing them by\nup to 9.24%. In addition, it is even capable of outperforming state-of-the-art\nproprietary models such as GPT-4 by up to 7.07%. KodeX-70Bv0.1 represents a\nfurther improvement upon this, exceeding GPT-4's performance on every tested\nbenchmark.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "q-fin.CP",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "11 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.13749v1",
    "published_date": "2024-09-13 16:43:08 UTC",
    "updated_date": "2024-09-13 16:43:08 UTC"
  },
  {
    "arxiv_id": "2409.08958v2",
    "title": "PINNfluence: Influence Functions for Physics-Informed Neural Networks",
    "authors": [
      "Jonas R. Naujoks",
      "Aleksander Krasowski",
      "Moritz Weckbecker",
      "Thomas Wiegand",
      "Sebastian Lapuschkin",
      "Wojciech Samek",
      "René P. Klausen"
    ],
    "abstract": "Recently, physics-informed neural networks (PINNs) have emerged as a flexible\nand promising application of deep learning to partial differential equations in\nthe physical sciences. While offering strong performance and competitive\ninference speeds on forward and inverse problems, their black-box nature limits\ninterpretability, particularly regarding alignment with expected physical\nbehavior. In the present work, we explore the application of influence\nfunctions (IFs) to validate and debug PINNs post-hoc. Specifically, we apply\nvariations of IF-based indicators to gauge the influence of different types of\ncollocation points on the prediction of PINNs applied to a 2D Navier-Stokes\nfluid flow problem. Our results demonstrate how IFs can be adapted to PINNs to\nreveal the potential for further studies. The code is publicly available at\nhttps://github.com/aleks-krasowski/PINNfluence.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.comp-ph",
      "physics.flu-dyn"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.08958v2",
    "published_date": "2024-09-13 16:23:17 UTC",
    "updated_date": "2024-12-01 06:47:45 UTC"
  },
  {
    "arxiv_id": "2409.08936v2",
    "title": "SynSUM -- Synthetic Benchmark with Structured and Unstructured Medical Records",
    "authors": [
      "Paloma Rabaey",
      "Henri Arno",
      "Stefan Heytens",
      "Thomas Demeester"
    ],
    "abstract": "We present the SynSUM benchmark, a synthetic dataset linking unstructured\nclinical notes to structured background variables. The dataset consists of\n10,000 artificial patient records containing tabular variables (like symptoms,\ndiagnoses and underlying conditions) and related notes describing the fictional\npatient encounter in the domain of respiratory diseases. The tabular portion of\nthe data is generated through a Bayesian network, where both the causal\nstructure between the variables and the conditional probabilities are proposed\nby an expert based on domain knowledge. We then prompt a large language model\n(GPT-4o) to generate a clinical note related to this patient encounter,\ndescribing the patient symptoms and additional context. We conduct both an\nexpert evaluation study to assess the quality of the generated notes, as well\nas running some simple predictor models on both the tabular and text portions\nof the dataset, forming a baseline for further research. The SynSUM dataset is\nprimarily designed to facilitate research on clinical information extraction in\nthe presence of tabular background variables, which can be linked through\ndomain knowledge to concepts of interest to be extracted from the text - the\nsymptoms, in the case of SynSUM. Secondary uses include research on the\nautomation of clinical reasoning over both tabular data and text, causal effect\nestimation in the presence of tabular and/or textual confounders, and\nmulti-modal synthetic data generation.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "The dataset can be downloaded from https://github.com/prabaey/synsum.\n  Presented at the GenAI4Health workshop at AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2409.08936v2",
    "published_date": "2024-09-13 15:55:15 UTC",
    "updated_date": "2025-03-07 17:09:02 UTC"
  },
  {
    "arxiv_id": "2409.08935v2",
    "title": "Optimization and Generalization Guarantees for Weight Normalization",
    "authors": [
      "Pedro Cisneros-Velarde",
      "Zhijie Chen",
      "Sanmi Koyejo",
      "Arindam Banerjee"
    ],
    "abstract": "Weight normalization (WeightNorm) is widely used in practice for the training\nof deep neural networks and modern deep learning libraries have built-in\nimplementations of it. In this paper, we provide the first theoretical\ncharacterizations of both optimization and generalization of deep WeightNorm\nmodels with smooth activation functions. For optimization, from the form of the\nHessian of the loss, we note that a small Hessian of the predictor leads to a\ntractable analysis. Thus, we bound the spectral norm of the Hessian of\nWeightNorm networks and show its dependence on the network width and weight\nnormalization terms--the latter being unique to networks without WeightNorm.\nThen, we use this bound to establish training convergence guarantees under\nsuitable assumptions for gradient decent. For generalization, we use WeightNorm\nto get a uniform convergence based generalization bound, which is independent\nfrom the width and depends sublinearly on the depth. Finally, we present\nexperimental results which illustrate how the normalization terms and other\nquantities of theoretical interest relate to the training of WeightNorm\nnetworks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.08935v2",
    "published_date": "2024-09-13 15:55:05 UTC",
    "updated_date": "2025-01-20 18:07:30 UTC"
  },
  {
    "arxiv_id": "2409.08930v1",
    "title": "Yes, Prime Minister, question order does matter -- and it's certainly not classical! But is it quantum?",
    "authors": [
      "Dorje C. Brody"
    ],
    "abstract": "Response to a poll can be manipulated by means of a series of leading\nquestions. We show that such phenomena cannot be explained by use of classical\nprobability theory, whereas quantum probability theory admits a possibility of\noffering an explanation. Admissible transformation rules in quantum\nprobability, however, do impose some constraints on the modelling of cognitive\nbehaviour, which are highlighted here. Focusing on a recent poll conducted by\nIpsos on a set of questions posed by Sir Humphrey Appleby in an episode of the\nBritish political satire \\textit{Yes, Prime Minister}, we show that the\nresulting data cannot be explained quite so simply using quantum rules,\nalthough it seems not impossible.",
    "categories": [
      "cs.AI",
      "q-bio.NC",
      "quant-ph"
    ],
    "primary_category": "cs.AI",
    "comment": "12 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2409.08930v1",
    "published_date": "2024-09-13 15:46:57 UTC",
    "updated_date": "2024-09-13 15:46:57 UTC"
  },
  {
    "arxiv_id": "2409.08919v1",
    "title": "XSub: Explanation-Driven Adversarial Attack against Blackbox Classifiers via Feature Substitution",
    "authors": [
      "Kiana Vu",
      "Phung Lai",
      "Truc Nguyen"
    ],
    "abstract": "Despite its significant benefits in enhancing the transparency and\ntrustworthiness of artificial intelligence (AI) systems, explainable AI (XAI)\nhas yet to reach its full potential in real-world applications. One key\nchallenge is that XAI can unintentionally provide adversaries with insights\ninto black-box models, inevitably increasing their vulnerability to various\nattacks. In this paper, we develop a novel explanation-driven adversarial\nattack against black-box classifiers based on feature substitution, called\nXSub. The key idea of XSub is to strategically replace important features\n(identified via XAI) in the original sample with corresponding important\nfeatures from a \"golden sample\" of a different label, thereby increasing the\nlikelihood of the model misclassifying the perturbed sample. The degree of\nfeature substitution is adjustable, allowing us to control how much of the\noriginal samples information is replaced. This flexibility effectively balances\na trade-off between the attacks effectiveness and its stealthiness. XSub is\nalso highly cost-effective in that the number of required queries to the\nprediction model and the explanation model in conducting the attack is in O(1).\nIn addition, XSub can be easily extended to launch backdoor attacks in case the\nattacker has access to the models training data. Our evaluation demonstrates\nthat XSub is not only effective and stealthy but also cost-effective, enabling\nits application across a wide range of AI models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.08919v1",
    "published_date": "2024-09-13 15:33:32 UTC",
    "updated_date": "2024-09-13 15:33:32 UTC"
  },
  {
    "arxiv_id": "2409.08917v1",
    "title": "Latent Space Score-based Diffusion Model for Probabilistic Multivariate Time Series Imputation",
    "authors": [
      "Guojun Liang",
      "Najmeh Abiri",
      "Atiye Sadat Hashemi",
      "Jens Lundström",
      "Stefan Byttner",
      "Prayag Tiwari"
    ],
    "abstract": "Accurate imputation is essential for the reliability and success of\ndownstream tasks. Recently, diffusion models have attracted great attention in\nthis field. However, these models neglect the latent distribution in a\nlower-dimensional space derived from the observed data, which limits the\ngenerative capacity of the diffusion model. Additionally, dealing with the\noriginal missing data without labels becomes particularly problematic. To\naddress these issues, we propose the Latent Space Score-Based Diffusion Model\n(LSSDM) for probabilistic multivariate time series imputation. Observed values\nare projected onto low-dimensional latent space and coarse values of the\nmissing data are reconstructed without knowing their ground truth values by\nthis unsupervised learning approach. Finally, the reconstructed values are fed\ninto a conditional diffusion model to obtain the precise imputed values of the\ntime series. In this way, LSSDM not only possesses the power to identify the\nlatent distribution but also seamlessly integrates the diffusion model to\nobtain the high-fidelity imputed values and assess the uncertainty of the\ndataset. Experimental results demonstrate that LSSDM achieves superior\nimputation performance while also providing a better explanation and\nuncertainty analysis of the imputation mechanism. The website of the code is\n\\textit{https://github.com/gorgen2020/LSSDM\\_imputation}.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "5 pages, conference",
    "pdf_url": "http://arxiv.org/pdf/2409.08917v1",
    "published_date": "2024-09-13 15:32:26 UTC",
    "updated_date": "2024-09-13 15:32:26 UTC"
  },
  {
    "arxiv_id": "2409.08916v2",
    "title": "Farmer.Chat: Scaling AI-Powered Agricultural Services for Smallholder Farmers",
    "authors": [
      "Namita Singh",
      "Jacqueline Wang'ombe",
      "Nereah Okanga",
      "Tetyana Zelenska",
      "Jona Repishti",
      "Jayasankar G K",
      "Sanjeev Mishra",
      "Rajsekar Manokaran",
      "Vineet Singh",
      "Mohammed Irfan Rafiq",
      "Rikin Gandhi",
      "Akshay Nambi"
    ],
    "abstract": "Small and medium-sized agricultural holders face challenges like limited\naccess to localized, timely information, impacting productivity and\nsustainability. Traditional extension services, which rely on in-person agents,\nstruggle with scalability and timely delivery, especially in remote areas. We\nintroduce FarmerChat, a generative AI-powered chatbot designed to address these\nissues. Leveraging Generative AI, FarmerChat offers personalized, reliable, and\ncontextually relevant advice, overcoming limitations of previous chatbots in\ndeterministic dialogue flows, language support, and unstructured data\nprocessing. Deployed in four countries, FarmerChat has engaged over 15,000\nfarmers and answered over 300,000 queries. This paper highlights how\nFarmerChat's innovative use of GenAI enhances agricultural service scalability\nand effectiveness. Our evaluation, combining quantitative analysis and\nqualitative insights, highlights FarmerChat's effectiveness in improving\nfarming practices, enhancing trust, response quality, and user engagement.",
    "categories": [
      "cs.ET",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.ET",
    "comment": "35 pages",
    "pdf_url": "http://arxiv.org/pdf/2409.08916v2",
    "published_date": "2024-09-13 15:31:33 UTC",
    "updated_date": "2024-10-08 06:03:41 UTC"
  },
  {
    "arxiv_id": "2409.08907v1",
    "title": "Affective Computing Has Changed: The Foundation Model Disruption",
    "authors": [
      "Björn Schuller",
      "Adria Mallol-Ragolta",
      "Alejandro Peña Almansa",
      "Iosif Tsangko",
      "Mostafa M. Amin",
      "Anastasia Semertzidou",
      "Lukas Christ",
      "Shahin Amiriparian"
    ],
    "abstract": "The dawn of Foundation Models has on the one hand revolutionised a wide range\nof research problems, and, on the other hand, democratised the access and use\nof AI-based tools by the general public. We even observe an incursion of these\nmodels into disciplines related to human psychology, such as the Affective\nComputing domain, suggesting their affective, emerging capabilities. In this\nwork, we aim to raise awareness of the power of Foundation Models in the field\nof Affective Computing by synthetically generating and analysing multimodal\naffective data, focusing on vision, linguistics, and speech (acoustics). We\nalso discuss some fundamental problems, such as ethical issues and regulatory\naspects, related to the use of Foundation Models in this research area.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.08907v1",
    "published_date": "2024-09-13 15:20:18 UTC",
    "updated_date": "2024-09-13 15:20:18 UTC"
  },
  {
    "arxiv_id": "2409.08904v2",
    "title": "AnyBipe: An End-to-End Framework for Training and Deploying Bipedal Robots Guided by Large Language Models",
    "authors": [
      "Yifei Yao",
      "Wentao He",
      "Chenyu Gu",
      "Jiaheng Du",
      "Fuwei Tan",
      "Zhen Zhu",
      "Junguo Lu"
    ],
    "abstract": "Training and deploying reinforcement learning (RL) policies for robots,\nespecially in accomplishing specific tasks, presents substantial challenges.\nRecent advancements have explored diverse reward function designs, training\ntechniques, simulation-to-reality (sim-to-real) transfers, and performance\nanalysis methodologies, yet these still require significant human intervention.\nThis paper introduces an end-to-end framework for training and deploying RL\npolicies, guided by Large Language Models (LLMs), and evaluates its\neffectiveness on bipedal robots. The framework consists of three interconnected\nmodules: an LLM-guided reward function design module, an RL training module\nleveraging prior work, and a sim-to-real homomorphic evaluation module. This\ndesign significantly reduces the need for human input by utilizing only\nessential simulation and deployment platforms, with the option to incorporate\nhuman-engineered strategies and historical data. We detail the construction of\nthese modules, their advantages over traditional approaches, and demonstrate\nthe framework's capability to autonomously develop and refine controlling\nstrategies for bipedal robot locomotion, showcasing its potential to operate\nindependently of human intervention.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.08904v2",
    "published_date": "2024-09-13 15:15:45 UTC",
    "updated_date": "2025-02-23 08:43:06 UTC"
  },
  {
    "arxiv_id": "2409.08895v1",
    "title": "Synthetic Human Memories: AI-Edited Images and Videos Can Implant False Memories and Distort Recollection",
    "authors": [
      "Pat Pataranutaporn",
      "Chayapatr Archiwaranguprok",
      "Samantha W. T. Chan",
      "Elizabeth Loftus",
      "Pattie Maes"
    ],
    "abstract": "AI is increasingly used to enhance images and videos, both intentionally and\nunintentionally. As AI editing tools become more integrated into smartphones,\nusers can modify or animate photos into realistic videos. This study examines\nthe impact of AI-altered visuals on false memories--recollections of events\nthat didn't occur or deviate from reality. In a pre-registered study, 200\nparticipants were divided into four conditions of 50 each. Participants viewed\noriginal images, completed a filler task, then saw stimuli corresponding to\ntheir assigned condition: unedited images, AI-edited images, AI-generated\nvideos, or AI-generated videos of AI-edited images. AI-edited visuals\nsignificantly increased false recollections, with AI-generated videos of\nAI-edited images having the strongest effect (2.05x compared to control).\nConfidence in false memories was also highest for this condition (1.19x\ncompared to control). We discuss potential applications in HCI, such as\ntherapeutic memory reframing, and challenges in ethical, legal, political, and\nsocietal domains.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "22 pages, 11 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2409.08895v1",
    "published_date": "2024-09-13 15:08:39 UTC",
    "updated_date": "2024-09-13 15:08:39 UTC"
  },
  {
    "arxiv_id": "2409.08892v1",
    "title": "Exploring Action-Centric Representations Through the Lens of Rate-Distortion Theory",
    "authors": [
      "Miguel de Llanza Varona",
      "Christopher L. Buckley",
      "Beren Millidge"
    ],
    "abstract": "Organisms have to keep track of the information in the environment that is\nrelevant for adaptive behaviour. Transmitting information in an economical and\nefficient way becomes crucial for limited-resourced agents living in\nhigh-dimensional environments. The efficient coding hypothesis claims that\norganisms seek to maximize the information about the sensory input in an\nefficient manner. Under Bayesian inference, this means that the role of the\nbrain is to efficiently allocate resources in order to make predictions about\nthe hidden states that cause sensory data. However, neither of those frameworks\naccounts for how that information is exploited downstream, leaving aside the\naction-oriented role of the perceptual system. Rate-distortion theory, which\ndefines optimal lossy compression under constraints, has gained attention as a\nformal framework to explore goal-oriented efficient coding. In this work, we\nexplore action-centric representations in the context of rate-distortion\ntheory. We also provide a mathematical definition of abstractions and we argue\nthat, as a summary of the relevant details, they can be used to fix the content\nof action-centric representations. We model action-centric representations\nusing VAEs and we find that such representations i) are efficient lossy\ncompressions of the data; ii) capture the task-dependent invariances necessary\nto achieve successful behaviour; and iii) are not in service of reconstructing\nthe data. Thus, we conclude that full reconstruction of the data is rarely\nneeded to achieve optimal behaviour, consistent with a teleological approach to\nperception.",
    "categories": [
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.08892v1",
    "published_date": "2024-09-13 15:07:22 UTC",
    "updated_date": "2024-09-13 15:07:22 UTC"
  },
  {
    "arxiv_id": "2409.09107v4",
    "title": "Proactive and Reactive Constraint Programming for Stochastic Project Scheduling with Maximal Time-Lags",
    "authors": [
      "Kim van den Houten",
      "Léon Planken",
      "Esteban Freydell",
      "David M. J. Tax",
      "Mathijs de Weerdt"
    ],
    "abstract": "This study investigates scheduling strategies for the stochastic\nresource-constrained project scheduling problem with maximal time lags\n(SRCPSP/max)). Recent advances in Constraint Programming (CP) and Temporal\nNetworks have reinvoked interest in evaluating the advantages and drawbacks of\nvarious proactive and reactive scheduling methods. First, we present a new,\nCP-based fully proactive method. Second, we show how a reactive approach can be\nconstructed using an online rescheduling procedure. A third contribution is\nbased on partial order schedules and uses Simple Temporal Networks with\nUncertainty (STNUs). Our statistical analysis shows that the STNU-based\nalgorithm performs best in terms of solution quality, while also showing good\nrelative offline and online computation time.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.09107v4",
    "published_date": "2024-09-13 15:01:25 UTC",
    "updated_date": "2025-03-22 21:20:27 UTC"
  },
  {
    "arxiv_id": "2409.08864v1",
    "title": "Exploring Graph Structure Comprehension Ability of Multimodal Large Language Models: Case Studies",
    "authors": [
      "Zhiqiang Zhong",
      "Davide Mottin"
    ],
    "abstract": "Large Language Models (LLMs) have shown remarkable capabilities in processing\nvarious data structures, including graphs. While previous research has focused\non developing textual encoding methods for graph representation, the emergence\nof multimodal LLMs presents a new frontier for graph comprehension. These\nadvanced models, capable of processing both text and images, offer potential\nimprovements in graph understanding by incorporating visual representations\nalongside traditional textual data. This study investigates the impact of graph\nvisualisations on LLM performance across a range of benchmark tasks at node,\nedge, and graph levels. Our experiments compare the effectiveness of multimodal\napproaches against purely textual graph representations. The results provide\nvaluable insights into both the potential and limitations of leveraging visual\ngraph modalities to enhance LLMs' graph structure comprehension abilities.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.08864v1",
    "published_date": "2024-09-13 14:26:58 UTC",
    "updated_date": "2024-09-13 14:26:58 UTC"
  },
  {
    "arxiv_id": "2409.09106v1",
    "title": "Recent Trends in Modelling the Continuous Time Series using Deep Learning: A Survey",
    "authors": [
      "Mansura Habiba",
      "Barak A. Pearlmutter",
      "Mehrdad Maleki"
    ],
    "abstract": "Continuous-time series is essential for different modern application areas,\ne.g. healthcare, automobile, energy, finance, Internet of things (IoT) and\nother related areas. Different application needs to process as well as analyse\na massive amount of data in time series structure in order to determine the\ndata-driven result, for example, financial trend prediction, potential\nprobability of the occurrence of a particular event occurrence identification,\npatient health record processing and so many more. However, modeling real-time\ndata using a continuous-time series is challenging since the dynamical systems\nbehind the data could be a differential equation. Several research works have\ntried to solve the challenges of modelling the continuous-time series using\ndifferent neural network models and approaches for data processing and\nlearning. The existing deep learning models are not free from challenges and\nlimitations due to diversity among different attributes, behaviour, duration of\nsteps, energy, and data sampling rate. This paper has described the general\nproblem domain of time series and reviewed the challenges of modelling the\ncontinuous time series. We have presented a comparative analysis of recent\ndevelopments in deep learning models and their contribution to solving\ndifferent difficulties of modelling the continuous time series. We have also\nidentified the limitations of the existing neural network model and open\nissues. The main goal of this review is to understand the recent trend of\nneural network models used in a different real-world application with\ncontinuous-time data.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.09106v1",
    "published_date": "2024-09-13 14:19:44 UTC",
    "updated_date": "2024-09-13 14:19:44 UTC"
  },
  {
    "arxiv_id": "2409.08853v1",
    "title": "Using The Concept Hierarchy for Household Action Recognition",
    "authors": [
      "Andrei Costinescu",
      "Luis Figueredo",
      "Darius Burschka"
    ],
    "abstract": "We propose a method to systematically represent both the static and the\ndynamic components of environments, i.e. objects and agents, as well as the\nchanges that are happening in the environment, i.e. the actions and skills\nperformed by agents. Our approach, the Concept Hierarchy, provides the\nnecessary information for autonomous systems to represent environment states,\nperform action modeling and recognition, and plan the execution of tasks.\nAdditionally, the hierarchical structure supports generalization and knowledge\ntransfer to environments. We rigorously define tasks, actions, skills, and\naffordances that enable human-understandable action and skill recognition.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "5 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.08853v1",
    "published_date": "2024-09-13 14:16:41 UTC",
    "updated_date": "2024-09-13 14:16:41 UTC"
  },
  {
    "arxiv_id": "2409.08820v2",
    "title": "A RAG Approach for Generating Competency Questions in Ontology Engineering",
    "authors": [
      "Xueli Pan",
      "Jacco van Ossenbruggen",
      "Victor de Boer",
      "Zhisheng Huang"
    ],
    "abstract": "Competency question (CQ) formulation is central to several ontology\ndevelopment and evaluation methodologies. Traditionally, the task of crafting\nthese competency questions heavily relies on the effort of domain experts and\nknowledge engineers which is often time-consuming and labor-intensive. With the\nemergence of Large Language Models (LLMs), there arises the possibility to\nautomate and enhance this process. Unlike other similar works which use\nexisting ontologies or knowledge graphs as input to LLMs, we present a\nretrieval-augmented generation (RAG) approach that uses LLMs for the automatic\ngeneration of CQs given a set of scientific papers considered to be a domain\nknowledge base. We investigate its performance and specifically, we study the\nimpact of different number of papers to the RAG and different temperature\nsetting of the LLM. We conduct experiments using GPT-4 on two domain ontology\nengineering tasks and compare results against ground-truth CQs constructed by\ndomain experts. Empirical assessments on the results, utilizing evaluation\nmetrics (precision and consistency), reveal that compared to zero-shot\nprompting, adding relevant domain knowledge to the RAG improves the performance\nof LLMs on generating CQs for concrete ontology engineering tasks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.08820v2",
    "published_date": "2024-09-13 13:34:32 UTC",
    "updated_date": "2025-02-11 21:25:45 UTC"
  },
  {
    "arxiv_id": "2409.08815v1",
    "title": "Deep reinforcement learning for tracking a moving target in jellyfish-like swimming",
    "authors": [
      "Yihao Chen",
      "Yue Yang"
    ],
    "abstract": "We develop a deep reinforcement learning method for training a jellyfish-like\nswimmer to effectively track a moving target in a two-dimensional flow. This\nswimmer is a flexible object equipped with a muscle model based on torsional\nsprings. We employ a deep Q-network (DQN) that takes the swimmer's geometry and\ndynamic parameters as inputs, and outputs actions which are the forces applied\nto the swimmer. In particular, we introduce an action regulation to mitigate\nthe interference from complex fluid-structure interactions. The goal of these\nactions is to navigate the swimmer to a target point in the shortest possible\ntime. In the DQN training, the data on the swimmer's motions are obtained from\nsimulations conducted using the immersed boundary method. During tracking a\nmoving target, there is an inherent delay between the application of forces and\nthe corresponding response of the swimmer's body due to hydrodynamic\ninteractions between the shedding vortices and the swimmer's own locomotion.\nOur tests demonstrate that the swimmer, with the DQN agent and action\nregulation, is able to dynamically adjust its course based on its instantaneous\nstate. This work extends the application scope of machine learning in\ncontrolling flexible objects within fluid environments.",
    "categories": [
      "physics.flu-dyn",
      "cs.AI"
    ],
    "primary_category": "physics.flu-dyn",
    "comment": "22pages,14 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.08815v1",
    "published_date": "2024-09-13 13:29:46 UTC",
    "updated_date": "2024-09-13 13:29:46 UTC"
  },
  {
    "arxiv_id": "2409.08811v1",
    "title": "Mutual Theory of Mind in Human-AI Collaboration: An Empirical Study with LLM-driven AI Agents in a Real-time Shared Workspace Task",
    "authors": [
      "Shao Zhang",
      "Xihuai Wang",
      "Wenhao Zhang",
      "Yongshan Chen",
      "Landi Gao",
      "Dakuo Wang",
      "Weinan Zhang",
      "Xinbing Wang",
      "Ying Wen"
    ],
    "abstract": "Theory of Mind (ToM) significantly impacts human collaboration and\ncommunication as a crucial capability to understand others. When AI agents with\nToM capability collaborate with humans, Mutual Theory of Mind (MToM) arises in\nsuch human-AI teams (HATs). The MToM process, which involves interactive\ncommunication and ToM-based strategy adjustment, affects the team's performance\nand collaboration process. To explore the MToM process, we conducted a\nmixed-design experiment using a large language model-driven AI agent with ToM\nand communication modules in a real-time shared-workspace task. We find that\nthe agent's ToM capability does not significantly impact team performance but\nenhances human understanding of the agent and the feeling of being understood.\nMost participants in our study believe verbal communication increases human\nburden, and the results show that bidirectional communication leads to lower\nHAT performance. We discuss the results' implications for designing AI agents\nthat collaborate with humans in real-time shared workspace tasks.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.HC",
    "comment": "34 pages, Preprint Under Review",
    "pdf_url": "http://arxiv.org/pdf/2409.08811v1",
    "published_date": "2024-09-13 13:19:48 UTC",
    "updated_date": "2024-09-13 13:19:48 UTC"
  },
  {
    "arxiv_id": "2409.08806v2",
    "title": "TabKANet: Tabular Data Modeling with Kolmogorov-Arnold Network and Transformer",
    "authors": [
      "Weihao Gao",
      "Zheng Gong",
      "Zhuo Deng",
      "Fuju Rong",
      "Chucheng Chen",
      "Lan Ma"
    ],
    "abstract": "Tabular data is the most common type of data in real-life scenarios. In this\nstudy, we propose the TabKANet model for tabular data modeling, which targets\nthe bottlenecks in learning from numerical content. We constructed a\nKolmogorov-Arnold Network (KAN) based Numerical Embedding Module and unified\nnumerical and categorical features encoding within a Transformer architecture.\nTabKANet has demonstrated stable and significantly superior performance\ncompared to Neural Networks (NNs) across multiple public datasets in binary\nclassification, multi-class classification, and regression tasks. Its\nperformance is comparable to or surpasses that of Gradient Boosted Decision\nTree models (GBDTs). Our code is publicly available on GitHub:\nhttps://github.com/AI-thpremed/TabKANet.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages,5 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.08806v2",
    "published_date": "2024-09-13 13:14:54 UTC",
    "updated_date": "2024-10-02 06:22:48 UTC"
  },
  {
    "arxiv_id": "2409.08798v1",
    "title": "Reading ability detection using eye-tracking data with LSTM-based few-shot learning",
    "authors": [
      "Nanxi Li",
      "Hongjiang Wang",
      "Zehui Zhan"
    ],
    "abstract": "Reading ability detection is important in modern educational field. In this\npaper, a method of predicting scores of reading ability is proposed, using the\neye-tracking data of a few subjects (e.g., 68 subjects). The proposed method\nbuilt a regression model for the score prediction by combining Long Short Time\nMemory (LSTM) and light-weighted neural networks. Experiments show that with\nfew-shot learning strategy, the proposed method achieved higher accuracy than\nprevious methods of score prediction in reading ability detection. The code can\nlater be downloaded at\nhttps://github.com/pumpkinLNX/LSTM-eye-tracking-pytorch.git",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.08798v1",
    "published_date": "2024-09-13 13:06:01 UTC",
    "updated_date": "2024-09-13 13:06:01 UTC"
  },
  {
    "arxiv_id": "2409.08775v3",
    "title": "What Should We Engineer in Prompts? Training Humans in Requirement-Driven LLM Use",
    "authors": [
      "Qianou Ma",
      "Weirui Peng",
      "Chenyang Yang",
      "Hua Shen",
      "Kenneth Koedinger",
      "Tongshuang Wu"
    ],
    "abstract": "Prompting LLMs for complex tasks (e.g., building a trip advisor chatbot)\nneeds humans to clearly articulate customized requirements (e.g., \"start the\nresponse with a tl;dr\"). However, existing prompt engineering instructions\noften lack focused training on requirement articulation and instead tend to\nemphasize increasingly automatable strategies (e.g., tricks like adding\nrole-plays and \"think step-by-step\"). To address the gap, we introduce\nRequirement-Oriented Prompt Engineering (ROPE), a paradigm that focuses human\nattention on generating clear, complete requirements during prompting. We\nimplement ROPE through an assessment and training suite that provides\ndeliberate practice with LLM-generated feedback. In a randomized controlled\nexperiment with 30 novices, ROPE significantly outperforms conventional prompt\nengineering training (20% vs. 1% gains), a gap that automatic prompt\noptimization cannot close. Furthermore, we demonstrate a direct correlation\nbetween the quality of input requirements and LLM outputs. Our work paves the\nway to empower more end-users to build complex LLM applications.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "15 pages; TOCHI 2025",
    "pdf_url": "http://arxiv.org/pdf/2409.08775v3",
    "published_date": "2024-09-13 12:34:14 UTC",
    "updated_date": "2025-04-28 16:07:05 UTC"
  },
  {
    "arxiv_id": "2409.08767v2",
    "title": "HOLA-Drone: Hypergraphic Open-ended Learning for Zero-Shot Multi-Drone Cooperative Pursuit",
    "authors": [
      "Yang Li",
      "Dengyu Zhang",
      "Junfan Chen",
      "Ying Wen",
      "Qingrui Zhang",
      "Shaoshuai Mou",
      "Wei Pan"
    ],
    "abstract": "Zero-shot coordination (ZSC) is a significant challenge in multi-agent\ncollaboration, aiming to develop agents that can coordinate with unseen\npartners they have not encountered before. Recent cutting-edge ZSC methods have\nprimarily focused on two-player video games such as OverCooked!2 and Hanabi. In\nthis paper, we extend the scope of ZSC research to the multi-drone cooperative\npursuit scenario, exploring how to construct a drone agent capable of\ncoordinating with multiple unseen partners to capture multiple evaders. We\npropose a novel Hypergraphic Open-ended Learning Algorithm (HOLA-Drone) that\ncontinuously adapts the learning objective based on our hypergraphic-form game\nmodeling, aiming to improve cooperative abilities with multiple unknown drone\nteammates. To empirically verify the effectiveness of HOLA-Drone, we build two\ndifferent unseen drone teammate pools to evaluate their performance in\ncoordination with various unseen partners. The experimental results demonstrate\nthat HOLA-Drone outperforms the baseline methods in coordination with unseen\ndrone teammates. Furthermore, real-world experiments validate the feasibility\nof HOLA-Drone in physical systems. Videos can be found on the project\nhomepage~\\url{https://sites.google.com/view/hola-drone}.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2409.08767v2",
    "published_date": "2024-09-13 12:20:04 UTC",
    "updated_date": "2024-10-01 14:46:42 UTC"
  },
  {
    "arxiv_id": "2409.08761v1",
    "title": "Journalists, Emotions, and the Introduction of Generative AI Chatbots: A Large-Scale Analysis of Tweets Before and After the Launch of ChatGPT",
    "authors": [
      "Seth C. Lewis",
      "David M. Markowitz",
      "Jon Benedik Bunquin"
    ],
    "abstract": "As part of a broader look at the impact of generative AI, this study\ninvestigated the emotional responses of journalists to the release of ChatGPT\nat the time of its launch. By analyzing nearly 1 million Tweets from\njournalists at major U.S. news outlets, we tracked changes in emotional tone\nand sentiment before and after the introduction of ChatGPT in November 2022.\nUsing various computational and natural language processing techniques to\nmeasure emotional shifts in response to ChatGPT's release, we found an increase\nin positive emotion and a more favorable tone post-launch, suggesting initial\noptimism toward AI's potential. This research underscores the pivotal role of\njournalists as interpreters of technological innovation and disruption,\nhighlighting how their emotional reactions may shape public narratives around\nemerging technologies. The study contributes to understanding the intersection\nof journalism, emotion, and AI, offering insights into the broader societal\nimpact of generative AI tools.",
    "categories": [
      "cs.CC",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.08761v1",
    "published_date": "2024-09-13 12:09:20 UTC",
    "updated_date": "2024-09-13 12:09:20 UTC"
  },
  {
    "arxiv_id": "2409.08732v1",
    "title": "Bridging Dynamic Factor Models and Neural Controlled Differential Equations for Nowcasting GDP",
    "authors": [
      "Seonkyu Lim",
      "Jeongwhan Choi",
      "Noseong Park",
      "Sang-Ha Yoon",
      "ShinHyuck Kang",
      "Young-Min Kim",
      "Hyunjoong Kang"
    ],
    "abstract": "Gross domestic product (GDP) nowcasting is crucial for policy-making as GDP\ngrowth is a key indicator of economic conditions. Dynamic factor models (DFMs)\nhave been widely adopted by government agencies for GDP nowcasting due to their\nability to handle irregular or missing macroeconomic indicators and their\ninterpretability. However, DFMs face two main challenges: i) the lack of\ncapturing economic uncertainties such as sudden recessions or booms, and ii)\nthe limitation of capturing irregular dynamics from mixed-frequency data. To\naddress these challenges, we introduce NCDENow, a novel GDP nowcasting\nframework that integrates neural controlled differential equations (NCDEs) with\nDFMs. This integration effectively handles the dynamics of irregular time\nseries. NCDENow consists of 3 main modules: i) factor extraction leveraging\nDFM, ii) dynamic modeling using NCDE, and iii) GDP growth prediction through\nregression. We evaluate NCDENow against 6 baselines on 2 real-world GDP\ndatasets from South Korea and the United Kingdom, demonstrating its enhanced\npredictive capability. Our empirical results favor our method, highlighting the\nsignificant potential of integrating NCDE into nowcasting models. Our code and\ndataset are available at https://github.com/sklim84/NCDENow_CIKM2024.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at CIKM 2024. Seonkyu Lim and Jeongwhan Choi are co-first\n  authors with equal contributions",
    "pdf_url": "http://arxiv.org/pdf/2409.08732v1",
    "published_date": "2024-09-13 11:33:57 UTC",
    "updated_date": "2024-09-13 11:33:57 UTC"
  },
  {
    "arxiv_id": "2409.08724v1",
    "title": "Quasimetric Value Functions with Dense Rewards",
    "authors": [
      "Khadichabonu Valieva",
      "Bikramjit Banerjee"
    ],
    "abstract": "As a generalization of reinforcement learning (RL) to parametrizable goals,\ngoal conditioned RL (GCRL) has a broad range of applications, particularly in\nchallenging tasks in robotics. Recent work has established that the optimal\nvalue function of GCRL $Q^\\ast(s,a,g)$ has a quasimetric structure, leading to\ntargetted neural architectures that respect such structure. However, the\nrelevant analyses assume a sparse reward setting -- a known aggravating factor\nto sample complexity. We show that the key property underpinning a quasimetric,\nviz., the triangle inequality, is preserved under a dense reward setting as\nwell. Contrary to earlier findings where dense rewards were shown to be\ndetrimental to GCRL, we identify the key condition necessary for triangle\ninequality. Dense reward functions that satisfy this condition can only\nimprove, never worsen, sample complexity. This opens up opportunities to train\nefficient neural architectures with dense rewards, compounding their benefits\nto sample complexity. We evaluate this proposal in 12 standard benchmark\nenvironments in GCRL featuring challenging continuous control tasks. Our\nempirical results confirm that training a quasimetric value function in our\ndense reward setting indeed outperforms training with sparse rewards.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.08724v1",
    "published_date": "2024-09-13 11:26:05 UTC",
    "updated_date": "2024-09-13 11:26:05 UTC"
  },
  {
    "arxiv_id": "2409.08719v1",
    "title": "Distilling Monolingual and Crosslingual Word-in-Context Representations",
    "authors": [
      "Yuki Arase",
      "Tomoyuki Kajiwara"
    ],
    "abstract": "In this study, we propose a method that distils representations of word\nmeaning in context from a pre-trained masked language model in both monolingual\nand crosslingual settings. Word representations are the basis for context-aware\nlexical semantics and unsupervised semantic textual similarity (STS)\nestimation. Different from existing approaches, our method does not require\nhuman-annotated corpora nor updates of the parameters of the pre-trained model.\nThe latter feature is appealing for practical scenarios where the off-the-shelf\npre-trained model is a common asset among different applications. Specifically,\nour method learns to combine the outputs of different hidden layers of the\npre-trained model using self-attention. Our auto-encoder based training only\nrequires an automatically generated corpus. To evaluate the performance of the\nproposed approach, we performed extensive experiments using various benchmark\ntasks. The results on the monolingual tasks confirmed that our representations\nexhibited a competitive performance compared to that of the previous study for\nthe context-aware lexical semantic tasks and outperformed it for STS\nestimation. The results of the crosslingual tasks revealed that the proposed\nmethod largely improved crosslingual word representations of multilingual\npre-trained models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.08719v1",
    "published_date": "2024-09-13 11:10:16 UTC",
    "updated_date": "2024-09-13 11:10:16 UTC"
  },
  {
    "arxiv_id": "2409.08712v1",
    "title": "Layerwise Change of Knowledge in Neural Networks",
    "authors": [
      "Xu Cheng",
      "Lei Cheng",
      "Zhaoran Peng",
      "Yang Xu",
      "Tian Han",
      "Quanshi Zhang"
    ],
    "abstract": "This paper aims to explain how a deep neural network (DNN) gradually extracts\nnew knowledge and forgets noisy features through layers in forward propagation.\nUp to now, although the definition of knowledge encoded by the DNN has not\nreached a consensus, Previous studies have derived a series of mathematical\nevidence to take interactions as symbolic primitive inference patterns encoded\nby a DNN. We extend the definition of interactions and, for the first time,\nextract interactions encoded by intermediate layers. We quantify and track the\nnewly emerged interactions and the forgotten interactions in each layer during\nthe forward propagation, which shed new light on the learning behavior of DNNs.\nThe layer-wise change of interactions also reveals the change of the\ngeneralization capacity and instability of feature representations of a DNN.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.08712v1",
    "published_date": "2024-09-13 10:59:24 UTC",
    "updated_date": "2024-09-13 10:59:24 UTC"
  },
  {
    "arxiv_id": "2409.08711v1",
    "title": "Text-To-Speech Synthesis In The Wild",
    "authors": [
      "Jee-weon Jung",
      "Wangyou Zhang",
      "Soumi Maiti",
      "Yihan Wu",
      "Xin Wang",
      "Ji-Hoon Kim",
      "Yuta Matsunaga",
      "Seyun Um",
      "Jinchuan Tian",
      "Hye-jin Shim",
      "Nicholas Evans",
      "Joon Son Chung",
      "Shinnosuke Takamichi",
      "Shinji Watanabe"
    ],
    "abstract": "Text-to-speech (TTS) systems are traditionally trained using modest databases\nof studio-quality, prompted or read speech collected in benign acoustic\nenvironments such as anechoic rooms. The recent literature nonetheless shows\nefforts to train TTS systems using data collected in the wild. While this\napproach allows for the use of massive quantities of natural speech, until now,\nthere are no common datasets. We introduce the TTS In the Wild (TITW) dataset,\nthe result of a fully automated pipeline, in this case, applied to the\nVoxCeleb1 dataset commonly used for speaker recognition. We further propose two\ntraining sets. TITW-Hard is derived from the transcription, segmentation, and\nselection of VoxCeleb1 source data. TITW-Easy is derived from the additional\napplication of enhancement and additional data selection based on DNSMOS. We\nshow that a number of recent TTS models can be trained successfully using\nTITW-Easy, but that it remains extremely challenging to produce similar results\nusing TITW-Hard. Both the dataset and protocols are publicly available and\nsupport the benchmarking of TTS systems trained using TITW data.",
    "categories": [
      "eess.AS",
      "cs.AI"
    ],
    "primary_category": "eess.AS",
    "comment": "5 pages, submitted to ICASSP 2025 as a conference paper",
    "pdf_url": "http://arxiv.org/pdf/2409.08711v1",
    "published_date": "2024-09-13 10:58:55 UTC",
    "updated_date": "2024-09-13 10:58:55 UTC"
  },
  {
    "arxiv_id": "2409.08703v1",
    "title": "NeSHFS: Neighborhood Search with Heuristic-based Feature Selection for Click-Through Rate Prediction",
    "authors": [
      "Dogukan Aksu",
      "Ismail Hakki Toroslu",
      "Hasan Davulcu"
    ],
    "abstract": "Click-through-rate (CTR) prediction plays an important role in online\nadvertising and ad recommender systems. In the past decade, maximizing CTR has\nbeen the main focus of model development and solution creation. Therefore,\nresearchers and practitioners have proposed various models and solutions to\nenhance the effectiveness of CTR prediction. Most of the existing literature\nfocuses on capturing either implicit or explicit feature interactions. Although\nimplicit interactions are successfully captured in some studies, explicit\ninteractions present a challenge for achieving high CTR by extracting both\nlow-order and high-order feature interactions. Unnecessary and irrelevant\nfeatures may cause high computational time and low prediction performance.\nFurthermore, certain features may perform well with specific predictive models\nwhile underperforming with others. Also, feature distribution may fluctuate due\nto traffic variations. Most importantly, in live production environments,\nresources are limited, and the time for inference is just as crucial as\ntraining time. Because of all these reasons, feature selection is one of the\nmost important factors in enhancing CTR prediction model performance. Simple\nfilter-based feature selection algorithms do not perform well and they are not\nsufficient. An effective and efficient feature selection algorithm is needed to\nconsistently filter the most useful features during live CTR prediction\nprocess. In this paper, we propose a heuristic algorithm named Neighborhood\nSearch with Heuristic-based Feature Selection (NeSHFS) to enhance CTR\nprediction performance while reducing dimensionality and training time costs.\nWe conduct comprehensive experiments on three public datasets to validate the\nefficiency and effectiveness of our proposed solution.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.08703v1",
    "published_date": "2024-09-13 10:43:18 UTC",
    "updated_date": "2024-09-13 10:43:18 UTC"
  },
  {
    "arxiv_id": "2409.08702v1",
    "title": "DM: Dual-path Magnitude Network for General Speech Restoration",
    "authors": [
      "Da-Hee Yang",
      "Dail Kim",
      "Joon-Hyuk Chang",
      "Jeonghwan Choi",
      "Han-gil Moon"
    ],
    "abstract": "In this paper, we introduce a novel general speech restoration model: the\nDual-path Magnitude (DM) network, designed to address multiple distortions\nincluding noise, reverberation, and bandwidth degradation effectively. The DM\nnetwork employs dual parallel magnitude decoders that share parameters: one\nuses a masking-based algorithm for distortion removal and the other employs a\nmapping-based approach for speech restoration. A novel aspect of the DM network\nis the integration of the magnitude spectrogram output from the masking decoder\ninto the mapping decoder through a skip connection, enhancing the overall\nrestoration capability. This integrated approach overcomes the inherent\nlimitations observed in previous models, as detailed in a step-by-step\nanalysis. The experimental results demonstrate that the DM network outperforms\nother baseline models in the comprehensive aspect of general speech\nrestoration, achieving substantial restoration with fewer parameters.",
    "categories": [
      "eess.AS",
      "cs.AI"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.08702v1",
    "published_date": "2024-09-13 10:42:59 UTC",
    "updated_date": "2024-09-13 10:42:59 UTC"
  },
  {
    "arxiv_id": "2409.08695v3",
    "title": "Precision Aquaculture: An Integrated Computer Vision and IoT Approach for Optimized Tilapia Feeding",
    "authors": [
      "Rania Hossam",
      "Ahmed Heakl",
      "Walid Gomaa"
    ],
    "abstract": "Traditional fish farming practices often lead to inefficient feeding,\nresulting in environmental issues and reduced productivity. We developed an\ninnovative system combining computer vision and IoT technologies for precise\nTilapia feeding. Our solution uses real-time IoT sensors to monitor water\nquality parameters and computer vision algorithms to analyze fish size and\ncount, determining optimal feed amounts. A mobile app enables remote monitoring\nand control. We utilized YOLOv8 for keypoint detection to measure Tilapia\nweight from length, achieving \\textbf{94\\%} precision on 3,500 annotated\nimages. Pixel-based measurements were converted to centimeters using depth\nestimation for accurate feeding calculations. Our method, with data collection\nmirroring inference conditions, significantly improved results. Preliminary\nestimates suggest this approach could increase production up to 58 times\ncompared to traditional farms. Our models, code, and dataset are\nopen-source~\\footnote{The code, dataset, and models are available upon\nreasonable request.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, 6 figures, 3 tables, 21th International Conference on\n  Informatics in Control, Automation, and Robotics",
    "pdf_url": "http://arxiv.org/pdf/2409.08695v3",
    "published_date": "2024-09-13 10:27:27 UTC",
    "updated_date": "2024-09-25 03:34:45 UTC"
  },
  {
    "arxiv_id": "2409.08692v1",
    "title": "B4: Towards Optimal Assessment of Plausible Code Solutions with Plausible Tests",
    "authors": [
      "Mouxiang Chen",
      "Zhongxin Liu",
      "He Tao",
      "Yusu Hong",
      "David Lo",
      "Xin Xia",
      "Jianling Sun"
    ],
    "abstract": "Selecting the best code solution from multiple generated ones is an essential\ntask in code generation, which can be achieved by using some reliable\nvalidators (e.g., developer-written test cases) for assistance. Since reliable\ntest cases are not always available and can be expensive to build in practice,\nresearchers propose to automatically generate test cases to assess code\nsolutions. However, when both code solutions and test cases are plausible and\nnot reliable, selecting the best solution becomes challenging. Although some\nheuristic strategies have been proposed to tackle this problem, they lack a\nstrong theoretical guarantee and it is still an open question whether an\noptimal selection strategy exists. Our work contributes in two ways. First, we\nshow that within a Bayesian framework, the optimal selection strategy can be\ndefined based on the posterior probability of the observed passing states\nbetween solutions and tests. The problem of identifying the best solution is\nthen framed as an integer programming problem. Second, we propose an efficient\napproach for approximating this optimal (yet uncomputable) strategy, where the\napproximation error is bounded by the correctness of prior knowledge. We then\nincorporate effective prior knowledge to tailor code generation tasks. Both\ntheoretical and empirical studies confirm that existing heuristics are limited\nin selecting the best solutions with plausible test cases. Our proposed\napproximated optimal strategy B4 significantly surpasses existing heuristics in\nselecting code solutions generated by large language models (LLMs) with\nLLM-generated tests, achieving a relative performance improvement by up to 50%\nover the strongest heuristic and 246% over the random selection in the most\nchallenging scenarios. Our code is publicly available at\nhttps://github.com/ZJU-CTAG/B4.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "accepted by ASE' 24 (full paper)",
    "pdf_url": "http://arxiv.org/pdf/2409.08692v1",
    "published_date": "2024-09-13 10:22:08 UTC",
    "updated_date": "2024-09-13 10:22:08 UTC"
  },
  {
    "arxiv_id": "2409.08680v1",
    "title": "NEST-RQ: Next Token Prediction for Speech Self-Supervised Pre-Training",
    "authors": [
      "Minglun Han",
      "Ye Bai",
      "Chen Shen",
      "Youjia Huang",
      "Mingkun Huang",
      "Zehua Lin",
      "Linhao Dong",
      "Lu Lu",
      "Yuxuan Wang"
    ],
    "abstract": "Speech self-supervised pre-training can effectively improve the performance\nof downstream tasks. However, previous self-supervised learning (SSL) methods\nfor speech, such as HuBERT and BEST-RQ, focus on utilizing non-causal encoders\nwith bidirectional context, and lack sufficient support for downstream\nstreaming models. To address this issue, we introduce the next token prediction\nbased speech pre-training method with random-projection quantizer (NEST-RQ).\nNEST-RQ employs causal encoders with only left context and uses next token\nprediction (NTP) as the training task. On the large-scale dataset, compared to\nBEST-RQ, the proposed NEST-RQ achieves comparable performance on non-streaming\nautomatic speech recognition (ASR) and better performance on streaming ASR. We\nalso conduct analytical experiments in terms of the future context size of\nstreaming ASR, the codebook quality of SSL and the model size of the encoder.\nIn summary, the paper demonstrates the feasibility of the NTP in speech SSL and\nprovides empirical evidence and insights for speech SSL research.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "eess.AS",
    "comment": "5 pages, 2 figures, Work in progress",
    "pdf_url": "http://arxiv.org/pdf/2409.08680v1",
    "published_date": "2024-09-13 09:48:11 UTC",
    "updated_date": "2024-09-13 09:48:11 UTC"
  },
  {
    "arxiv_id": "2409.08678v2",
    "title": "Shadow Program Inversion with Differentiable Planning: A Framework for Unified Robot Program Parameter and Trajectory Optimization",
    "authors": [
      "Benjamin Alt",
      "Claudius Kienle",
      "Darko Katic",
      "Rainer Jäkel",
      "Michael Beetz"
    ],
    "abstract": "This paper presents SPI-DP, a novel first-order optimizer capable of\noptimizing robot programs with respect to both high-level task objectives and\nmotion-level constraints. To that end, we introduce DGPMP2-ND, a differentiable\ncollision-free motion planner for serial N-DoF kinematics, and integrate it\ninto an iterative, gradient-based optimization approach for generic,\nparameterized robot program representations. SPI-DP allows first-order\noptimization of planned trajectories and program parameters with respect to\nobjectives such as cycle time or smoothness subject to e.g. collision\nconstraints, while enabling humans to understand, modify or even certify the\noptimized programs. We provide a comprehensive evaluation on two practical\nhousehold and industrial applications.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "68T40",
      "I.2; D.1"
    ],
    "primary_category": "cs.RO",
    "comment": "8 pages, 6 figures, accepted at the 2025 IEEE International\n  Conference on Robotics & Automation (ICRA)",
    "pdf_url": "http://arxiv.org/pdf/2409.08678v2",
    "published_date": "2024-09-13 09:46:41 UTC",
    "updated_date": "2025-02-12 15:18:21 UTC"
  },
  {
    "arxiv_id": "2409.08666v1",
    "title": "Towards certifiable AI in aviation: landscape, challenges, and opportunities",
    "authors": [
      "Hymalai Bello",
      "Daniel Geißler",
      "Lala Ray",
      "Stefan Müller-Divéky",
      "Peter Müller",
      "Shannon Kittrell",
      "Mengxi Liu",
      "Bo Zhou",
      "Paul Lukowicz"
    ],
    "abstract": "Artificial Intelligence (AI) methods are powerful tools for various domains,\nincluding critical fields such as avionics, where certification is required to\nachieve and maintain an acceptable level of safety. General solutions for\nsafety-critical systems must address three main questions: Is it suitable? What\ndrives the system's decisions? Is it robust to errors/attacks? This is more\ncomplex in AI than in traditional methods. In this context, this paper presents\na comprehensive mind map of formal AI certification in avionics. It highlights\nthe challenges of certifying AI development with an example to emphasize the\nneed for qualification beyond performance metrics.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.08666v1",
    "published_date": "2024-09-13 09:27:59 UTC",
    "updated_date": "2024-09-13 09:27:59 UTC"
  },
  {
    "arxiv_id": "2409.08655v1",
    "title": "LMAC-TD: Producing Time Domain Explanations for Audio Classifiers",
    "authors": [
      "Eleonora Mancini",
      "Francesco Paissan",
      "Mirco Ravanelli",
      "Cem Subakan"
    ],
    "abstract": "Neural networks are typically black-boxes that remain opaque with regards to\ntheir decision mechanisms. Several works in the literature have proposed\npost-hoc explanation methods to alleviate this issue. This paper proposes\nLMAC-TD, a post-hoc explanation method that trains a decoder to produce\nexplanations directly in the time domain. This methodology builds upon the\nfoundation of L-MAC, Listenable Maps for Audio Classifiers, a method that\nproduces faithful and listenable explanations. We incorporate SepFormer, a\npopular transformer-based time-domain source separation architecture. We show\nthrough a user study that LMAC-TD significantly improves the audio quality of\nthe produced explanations while not sacrificing from faithfulness.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS",
      "eess.SP"
    ],
    "primary_category": "cs.SD",
    "comment": "The first two authors contributed equally to this research. Author\n  order is alphabetical",
    "pdf_url": "http://arxiv.org/pdf/2409.08655v1",
    "published_date": "2024-09-13 09:14:06 UTC",
    "updated_date": "2024-09-13 09:14:06 UTC"
  },
  {
    "arxiv_id": "2409.08642v2",
    "title": "CPL: Critical Plan Step Learning Boosts LLM Generalization in Reasoning Tasks",
    "authors": [
      "Tianlong Wang",
      "Junzhe Chen",
      "Xueting Han",
      "Jing Bai"
    ],
    "abstract": "Post-training, particularly reinforcement learning (RL) using\nself-play-generated data, has become a new learning paradigm for large language\nmodels (LLMs). However, scaling RL to develop a general reasoner remains a\nresearch challenge, as existing methods focus on task-specific reasoning\nwithout adequately addressing generalization across a broader range of tasks.\nMoreover, unlike traditional RL with limited action space, LLMs operate in an\ninfinite space, making it crucial to search for valuable and diverse strategies\nto solve problems effectively. To address this, we propose searching within the\naction space on high-level abstract plans to enhance model generalization and\nintroduce Critical Plan Step Learning (CPL), comprising: 1) searching on plan,\nusing Monte Carlo Tree Search (MCTS) to explore diverse plan steps in\nmulti-step reasoning tasks, and 2) learning critical plan steps through\nStep-level Advantage Preference Optimization (Step-APO), which integrates\nadvantage estimates for step preference obtained via MCTS into Direct\nPreference Optimization (DPO). This combination helps the model effectively\nlearn critical plan steps, enhancing both reasoning capabilities and\ngeneralization. Experimental results demonstrate that our method, trained\nexclusively on GSM8K and MATH, not only significantly improves performance on\nGSM8K (+10.5%) and MATH (+6.5%), but also enhances out-of-domain reasoning\nbenchmarks, such as HumanEval (+12.2%), GPQA (+8.6%), ARC-C (+4.0%), MMLU-STEM\n(+2.2%), and BBH (+1.8%).",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.08642v2",
    "published_date": "2024-09-13 08:59:31 UTC",
    "updated_date": "2024-10-01 05:42:12 UTC"
  },
  {
    "arxiv_id": "2409.08641v1",
    "title": "Developing an Algorithm Selector for Green Configuration in Scheduling Problems",
    "authors": [
      "Carlos March",
      "Christian Perez",
      "Miguel A. Salido"
    ],
    "abstract": "The Job Shop Scheduling Problem (JSP) is central to operations research,\nprimarily optimizing energy efficiency due to its profound environmental and\neconomic implications. Efficient scheduling enhances production metrics and\nmitigates energy consumption, thus effectively balancing productivity and\nsustainability objectives. Given the intricate and diverse nature of JSP\ninstances, along with the array of algorithms developed to tackle these\nchallenges, an intelligent algorithm selection tool becomes paramount. This\npaper introduces a framework designed to identify key problem features that\ncharacterize its complexity and guide the selection of suitable algorithms.\nLeveraging machine learning techniques, particularly XGBoost, the framework\nrecommends optimal solvers such as GUROBI, CPLEX, and GECODE for efficient JSP\nscheduling. GUROBI excels with smaller instances, while GECODE demonstrates\nrobust scalability for complex scenarios. The proposed algorithm selector\nachieves an accuracy of 84.51\\% in recommending the best algorithm for solving\nnew JSP instances, highlighting its efficacy in algorithm selection. By\nrefining feature extraction methodologies, the framework aims to broaden its\napplicability across diverse JSP scenarios, thereby advancing efficiency and\nsustainability in manufacturing logistics.",
    "categories": [
      "cs.AI",
      "90C27"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.08641v1",
    "published_date": "2024-09-13 08:58:24 UTC",
    "updated_date": "2024-09-13 08:58:24 UTC"
  },
  {
    "arxiv_id": "2409.08636v2",
    "title": "Utilizing Data Fingerprints for Privacy-Preserving Algorithm Selection in Time Series Classification: Performance and Uncertainty Estimation on Unseen Datasets",
    "authors": [
      "Lars Böcking",
      "Leopold Müller",
      "Niklas Kühl"
    ],
    "abstract": "The selection of algorithms is a crucial step in designing AI services for\nreal-world time series classification use cases. Traditional methods such as\nneural architecture search, automated machine learning, combined algorithm\nselection, and hyperparameter optimizations are effective but require\nconsiderable computational resources and necessitate access to all data points\nto run their optimizations. In this work, we introduce a novel data fingerprint\nthat describes any time series classification dataset in a privacy-preserving\nmanner and provides insight into the algorithm selection problem without\nrequiring training on the (unseen) dataset. By decomposing the multi-target\nregression problem, only our data fingerprints are used to estimate algorithm\nperformance and uncertainty in a scalable and adaptable manner. Our approach is\nevaluated on the 112 University of California riverside benchmark datasets,\ndemonstrating its effectiveness in predicting the performance of 35\nstate-of-the-art algorithms and providing valuable insights for effective\nalgorithm selection in time series classification service systems, improving a\nnaive baseline by 7.32% on average in estimating the mean performance and\n15.81% in estimating the uncertainty.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Hawaii International Conference on System Sciences (HICSS-58) 2025",
    "pdf_url": "http://arxiv.org/pdf/2409.08636v2",
    "published_date": "2024-09-13 08:43:42 UTC",
    "updated_date": "2024-09-30 21:14:27 UTC"
  },
  {
    "arxiv_id": "2409.08633v1",
    "title": "Improving Analog Neural Network Robustness: A Noise-Agnostic Approach with Explainable Regularizations",
    "authors": [
      "Alice Duque",
      "Pedro Freire",
      "Egor Manuylovich",
      "Dmitrii Stoliarov",
      "Jaroslaw Prilepsky",
      "Sergei Turitsyn"
    ],
    "abstract": "This work tackles the critical challenge of mitigating \"hardware noise\" in\ndeep analog neural networks, a major obstacle in advancing analog signal\nprocessing devices. We propose a comprehensive, hardware-agnostic solution to\naddress both correlated and uncorrelated noise affecting the activation layers\nof deep neural models. The novelty of our approach lies in its ability to\ndemystify the \"black box\" nature of noise-resilient networks by revealing the\nunderlying mechanisms that reduce sensitivity to noise. In doing so, we\nintroduce a new explainable regularization framework that harnesses these\nmechanisms to significantly enhance noise robustness in deep neural\narchitectures.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.optics"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.08633v1",
    "published_date": "2024-09-13 08:37:23 UTC",
    "updated_date": "2024-09-13 08:37:23 UTC"
  },
  {
    "arxiv_id": "2409.08631v1",
    "title": "Sybil Detection using Graph Neural Networks",
    "authors": [
      "Stuart Heeb",
      "Andreas Plesner",
      "Roger Wattenhofer"
    ],
    "abstract": "This paper presents SYBILGAT, a novel approach to Sybil detection in social\nnetworks using Graph Attention Networks (GATs). Traditional methods for Sybil\ndetection primarily leverage structural properties of networks; however, they\ntend to struggle with a large number of attack edges and are often unable to\nsimultaneously utilize both known Sybil and honest nodes. Our proposed method\naddresses these limitations by dynamically assigning attention weights to\ndifferent nodes during aggregations, enhancing detection performance. We\nconducted extensive experiments in various scenarios, including pretraining in\nsampled subgraphs, synthetic networks, and networks under targeted attacks. The\nresults show that SYBILGAT significantly outperforms the state-of-the-art\nalgorithms, particularly in scenarios with high attack complexity and when the\nnumber of attack edges increases. Our approach shows robust performance across\ndifferent network models and sizes, even as the detection task becomes more\nchallenging. We successfully applied the model to a real-world Twitter graph\nwith more than 269k nodes and 6.8M edges. The flexibility and generalizability\nof SYBILGAT make it a promising tool to defend against Sybil attacks in online\nsocial networks with only structural information.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI",
    "comment": "9 pages, 1 figure, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2409.08631v1",
    "published_date": "2024-09-13 08:35:28 UTC",
    "updated_date": "2024-09-13 08:35:28 UTC"
  },
  {
    "arxiv_id": "2409.08603v1",
    "title": "Using Convolutional Neural Networks for Denoising and Deblending of Marine Seismic Data",
    "authors": [
      "Sigmund Slang",
      "Jing Sun",
      "Thomas Elboth",
      "Steven McDonald",
      "Leiv-J. Gelius"
    ],
    "abstract": "Processing marine seismic data is computationally demanding and consists of\nmultiple time-consuming steps. Neural network based processing can, in theory,\nsignificantly reduce processing time and has the potential to change the way\nseismic processing is done. In this paper we are using deep convolutional\nneural networks (CNNs) to remove seismic interference noise and to deblend\nseismic data. To train such networks, a significant amount of computational\nmemory is needed since a single shot gather consists of more than 106 data\nsamples. Preliminary results are promising both for denoising and deblending.\nHowever, we also observed that the results are affected by the signal-to-noise\nratio (SnR). Moving to common channel domain is a way of breaking the coherency\nof the noise while also reducing the input volume size. This makes it easier\nfor the network to distinguish between signal and noise. It also increases the\nefficiency of the GPU memory usage by enabling better utilization of multi core\nprocessing. Deblending in common channel domain with the use of a CNN yields\nrelatively good results and is an improvement compared to shot domain.",
    "categories": [
      "physics.geo-ph",
      "cs.AI"
    ],
    "primary_category": "physics.geo-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.08603v1",
    "published_date": "2024-09-13 07:35:30 UTC",
    "updated_date": "2024-09-13 07:35:30 UTC"
  },
  {
    "arxiv_id": "2409.08602v1",
    "title": "Deep learning-based shot-domain seismic deblending",
    "authors": [
      "Jing Sun",
      "Song Hou",
      "Vetle Vinje",
      "Gordon Poole",
      "Leiv-J Gelius"
    ],
    "abstract": "To streamline fast-track processing of large data volumes, we have developed\na deep learning approach to deblend seismic data in the shot domain based on a\npractical strategy for generating high-quality training data along with a list\nof data conditioning techniques to improve performance of the data-driven\nmodel. We make use of unblended shot gathers acquired at the end of each sail\nline, to which the access requires no additional time or labor costs beyond the\nblended acquisition. By manually blending these data we obtain training data\nwith good control of the ground truth and fully adapted to the given survey.\nFurthermore, we train a deep neural network using multi-channel inputs that\ninclude adjacent blended shot gathers as additional channels. The prediction of\nthe blending noise is added in as a related and auxiliary task with the main\ntask of the network being the prediction of the primary-source events. Blending\nnoise in the ground truth is scaled down during the training and validation\nprocess due to its excessively strong amplitudes. As part of the process, the\nto-be-deblended shot gathers are aligned by the blending noise. Implementation\non field blended-by-acquisition data demonstrates that introducing the\nsuggested data conditioning steps can considerably reduce the leakage of\nprimary-source events in the deep part of the blended section. The complete\nproposed approach performs almost as well as a conventional algorithm in the\nshallow section and shows great advantage in efficiency. It performs slightly\nworse for larger traveltimes, but still removes the blending noise efficiently.",
    "categories": [
      "physics.geo-ph",
      "cs.AI"
    ],
    "primary_category": "physics.geo-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.08602v1",
    "published_date": "2024-09-13 07:32:31 UTC",
    "updated_date": "2024-09-13 07:32:31 UTC"
  },
  {
    "arxiv_id": "2409.08596v2",
    "title": "Large Language Model Can Transcribe Speech in Multi-Talker Scenarios with Versatile Instructions",
    "authors": [
      "Lingwei Meng",
      "Shujie Hu",
      "Jiawen Kang",
      "Zhaoqing Li",
      "Yuejiao Wang",
      "Wenxuan Wu",
      "Xixin Wu",
      "Xunying Liu",
      "Helen Meng"
    ],
    "abstract": "Recent advancements in large language models (LLMs) have revolutionized\nvarious domains, bringing significant progress and new opportunities. Despite\nprogress in speech-related tasks, LLMs have not been sufficiently explored in\nmulti-talker scenarios. In this work, we present a pioneering effort to\ninvestigate the capability of LLMs in transcribing speech in multi-talker\nenvironments, following versatile instructions related to multi-talker\nautomatic speech recognition (ASR), target talker ASR, and ASR based on\nspecific talker attributes such as sex, occurrence order, language, and keyword\nspoken. Our approach utilizes WavLM and Whisper encoder to extract\nmulti-faceted speech representations that are sensitive to speaker\ncharacteristics and semantic context. These representations are then fed into\nan LLM fine-tuned using LoRA, enabling the capabilities for speech\ncomprehension and transcription. Comprehensive experiments reveal the promising\nperformance of our proposed system, MT-LLM, in cocktail party scenarios,\nhighlighting the potential of LLM to handle speech-related tasks based on user\ninstructions in such complex settings. The code, model, and samples are\navailable at https://github.com/cuhealthybrains/MT-LLM.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to IEEE ICASSP 2025. Update code link",
    "pdf_url": "http://arxiv.org/pdf/2409.08596v2",
    "published_date": "2024-09-13 07:28:28 UTC",
    "updated_date": "2025-04-02 16:16:33 UTC"
  },
  {
    "arxiv_id": "2409.08595v1",
    "title": "Automatic Generation of Fast and Accurate Performance Models for Deep Neural Network Accelerators",
    "authors": [
      "Konstantin Lübeck",
      "Alexander Louis-Ferdinand Jung",
      "Felix Wedlich",
      "Mika Markus Müller",
      "Federico Nicolás Peccia",
      "Felix Thömmes",
      "Jannik Steinmetz",
      "Valentin Biermaier",
      "Adrian Frischknecht",
      "Paul Palomero Bernardo",
      "Oliver Bringmann"
    ],
    "abstract": "Implementing Deep Neural Networks (DNNs) on resource-constrained edge devices\nis a challenging task that requires tailored hardware accelerator architectures\nand a clear understanding of their performance characteristics when executing\nthe intended AI workload. To facilitate this, we present an automated\ngeneration approach for fast performance models to accurately estimate the\nlatency of a DNN mapped onto systematically modeled and concisely described\naccelerator architectures. Using our accelerator architecture description\nmethod, we modeled representative DNN accelerators such as Gemmini, UltraTrail,\nPlasticine-derived, and a parameterizable systolic array. Together with DNN\nmappings for those modeled architectures, we perform a combined DNN/hardware\ndependency graph analysis, which enables us, in the best case, to evaluate only\n154 loop kernel iterations to estimate the performance for 4.19 billion\ninstructions achieving a significant speedup. We outperform regression and\nanalytical models in terms of mean absolute percentage error (MAPE) compared to\nsimulation results, while being several magnitudes faster than an RTL\nsimulation.",
    "categories": [
      "cs.PF",
      "cs.AI",
      "cs.AR",
      "cs.LG"
    ],
    "primary_category": "cs.PF",
    "comment": "Accepted version for: ACM Transactions on Embedded Computing Systems",
    "pdf_url": "http://arxiv.org/pdf/2409.08595v1",
    "published_date": "2024-09-13 07:27:55 UTC",
    "updated_date": "2024-09-13 07:27:55 UTC"
  },
  {
    "arxiv_id": "2409.08583v2",
    "title": "LHQ-SVC: Lightweight and High Quality Singing Voice Conversion Modeling",
    "authors": [
      "Yubo Huang",
      "Xin Lai",
      "Muyang Ye",
      "Anran Zhu",
      "Zixi Wang",
      "Jingzehua Xu",
      "Shuai Zhang",
      "Zhiyuan Zhou",
      "Weijie Niu"
    ],
    "abstract": "Singing Voice Conversion (SVC) has emerged as a significant subfield of Voice\nConversion (VC), enabling the transformation of one singer's voice into another\nwhile preserving musical elements such as melody, rhythm, and timbre.\nTraditional SVC methods have limitations in terms of audio quality, data\nrequirements, and computational complexity. In this paper, we propose LHQ-SVC,\na lightweight, CPU-compatible model based on the SVC framework and diffusion\nmodel, designed to reduce model size and computational demand without\nsacrificing performance. We incorporate features to improve inference quality,\nand optimize for CPU execution by using performance tuning tools and parallel\ncomputing frameworks. Our experiments demonstrate that LHQ-SVC maintains\ncompetitive performance, with significant improvements in processing speed and\nefficiency across different devices. The results suggest that LHQ-SVC can meet",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted by ICASSP 2025",
    "pdf_url": "http://arxiv.org/pdf/2409.08583v2",
    "published_date": "2024-09-13 07:02:36 UTC",
    "updated_date": "2025-01-17 23:27:32 UTC"
  },
  {
    "arxiv_id": "2409.08580v1",
    "title": "Molecular Graph Representation Learning via Structural Similarity Information",
    "authors": [
      "Chengyu Yao",
      "Hong Huang",
      "Hang Gao",
      "Fengge Wu",
      "Haiming Chen",
      "Junsuo Zhao"
    ],
    "abstract": "Graph Neural Networks (GNNs) have been widely employed for feature\nrepresentation learning in molecular graphs. Therefore, it is crucial to\nenhance the expressiveness of feature representation to ensure the\neffectiveness of GNNs. However, a significant portion of current research\nprimarily focuses on the structural features within individual molecules, often\noverlooking the structural similarity between molecules, which is a crucial\naspect encapsulating rich information on the relationship between molecular\nproperties and structural characteristics. Thus, these approaches fail to\ncapture the rich semantic information at the molecular structure level. To\nbridge this gap, we introduce the \\textbf{Molecular Structural Similarity Motif\nGNN (MSSM-GNN)}, a novel molecular graph representation learning method that\ncan capture structural similarity information among molecules from a global\nperspective. In particular, we propose a specially designed graph that\nleverages graph kernel algorithms to represent the similarity between molecules\nquantitatively. Subsequently, we employ GNNs to learn feature representations\nfrom molecular graphs, aiming to enhance the accuracy of property prediction by\nincorporating additional molecular representation information. Finally, through\na series of experiments conducted on both small-scale and large-scale molecular\ndatasets, we demonstrate that our model consistently outperforms eleven\nstate-of-the-art baselines. The codes are available at\nhttps://github.com/yaoyao-yaoyao-cell/MSSM-GNN.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.08580v1",
    "published_date": "2024-09-13 06:59:10 UTC",
    "updated_date": "2024-09-13 06:59:10 UTC"
  },
  {
    "arxiv_id": "2409.08561v1",
    "title": "Expediting and Elevating Large Language Model Reasoning via Hidden Chain-of-Thought Decoding",
    "authors": [
      "Tianqiao Liu",
      "Zui Chen",
      "Zitao Liu",
      "Mi Tian",
      "Weiqi Luo"
    ],
    "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in\ntasks requiring reasoning and multi-step problem-solving through the use of\nchain-of-thought (CoT) prompting. However, generating the full CoT process\nresults in significantly longer output sequences, leading to increased\ncomputational costs and latency during inference. To address this challenge, we\npropose a novel approach to compress the CoT process through semantic\nalignment, enabling more efficient decoding while preserving the benefits of\nCoT reasoning. Our method introduces an auxiliary CoT model that learns to\ngenerate and compress the full thought process into a compact special token\nrepresentation semantically aligned with the original CoT output. This\ncompressed representation is then integrated into the input of the Hidden\nChain-of-Thought (HCoT) model. The training process follows a two-stage\nprocedure: First, the CoT model is optimized to generate the compressed token\nrepresentations aligned with the ground-truth CoT outputs using a contrastive\nloss. Subsequently, with the CoT model parameters frozen, the HCoT model is\nfine-tuned to generate accurate subsequent predictions conditioned on the\nprefix instruction and the compressed CoT representations from the CoT model.\nExtensive experiments across three challenging domains - mathematical\nreasoning, agent invocation, and question answering - demonstrate that our\nsemantic compression approach achieves competitive or improved performance\ncompared to the full CoT baseline, while providing significant speedups of at\nleast 1.5x in decoding time. Moreover, incorporating contrastive learning\nobjectives further enhances the quality of the compressed representations,\nleading to better CoT prompting and improved task accuracy. Our work paves the\nway for more efficient exploitation of multi-step reasoning capabilities in\nLLMs across a wide range of applications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.08561v1",
    "published_date": "2024-09-13 06:29:20 UTC",
    "updated_date": "2024-09-13 06:29:20 UTC"
  },
  {
    "arxiv_id": "2409.08543v1",
    "title": "ATFLRec: A Multimodal Recommender System with Audio-Text Fusion and Low-Rank Adaptation via Instruction-Tuned Large Language Model",
    "authors": [
      "Zezheng Qin"
    ],
    "abstract": "Recommender Systems (RS) play a pivotal role in boosting user satisfaction by\nproviding personalized product suggestions in domains such as e-commerce and\nentertainment. This study examines the integration of multimodal data text and\naudio into large language models (LLMs) with the aim of enhancing\nrecommendation performance. Traditional text and audio recommenders encounter\nlimitations such as the cold-start problem, and recent advancements in LLMs,\nwhile promising, are computationally expensive. To address these issues,\nLow-Rank Adaptation (LoRA) is introduced, which enhances efficiency without\ncompromising performance. The ATFLRec framework is proposed to integrate audio\nand text modalities into a multimodal recommendation system, utilizing various\nLoRA configurations and modality fusion techniques. Results indicate that\nATFLRec outperforms baseline models, including traditional and graph neural\nnetwork-based approaches, achieving higher AUC scores. Furthermore, separate\nfine-tuning of audio and text data with distinct LoRA modules yields optimal\nperformance, with different pooling methods and Mel filter bank numbers\nsignificantly impacting performance. This research offers valuable insights\ninto optimizing multimodal recommender systems and advancing the integration of\ndiverse data modalities in LLMs.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.08543v1",
    "published_date": "2024-09-13 05:33:09 UTC",
    "updated_date": "2024-09-13 05:33:09 UTC"
  },
  {
    "arxiv_id": "2409.08537v1",
    "title": "SRE-CNN: A Spatiotemporal Rotation-Equivariant CNN for Cardiac Cine MR Imaging",
    "authors": [
      "Yuliang Zhu",
      "Jing Cheng",
      "Zhuo-Xu Cui",
      "Jianfeng Ren",
      "Chengbo Wang",
      "Dong Liang"
    ],
    "abstract": "Dynamic MR images possess various transformation symmetries,including the\nrotation symmetry of local features within the image and along the temporal\ndimension. Utilizing these symmetries as prior knowledge can facilitate dynamic\nMR imaging with high spatiotemporal resolution. Equivariant CNN is an effective\ntool to leverage the symmetry priors. However, current equivariant CNN methods\nfail to fully exploit these symmetry priors in dynamic MR imaging. In this\nwork, we propose a novel framework of Spatiotemporal Rotation-Equivariant CNN\n(SRE-CNN), spanning from the underlying high-precision filter design to the\nconstruction of the temporal-equivariant convolutional module and imaging\nmodel, to fully harness the rotation symmetries inherent in dynamic MR images.\nThe temporal-equivariant convolutional module enables exploitation the rotation\nsymmetries in both spatial and temporal dimensions, while the high-precision\nconvolutional filter, based on parametrization strategy, enhances the\nutilization of rotation symmetry of local features to improve the\nreconstruction of detailed anatomical structures. Experiments conducted on\nhighly undersampled dynamic cardiac cine data (up to 20X) have demonstrated the\nsuperior performance of our proposed approach, both quantitatively and\nqualitatively.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "Accepted at MICCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.08537v1",
    "published_date": "2024-09-13 04:54:34 UTC",
    "updated_date": "2024-09-13 04:54:34 UTC"
  },
  {
    "arxiv_id": "2409.08530v1",
    "title": "Integration of Mamba and Transformer -- MAT for Long-Short Range Time Series Forecasting with Application to Weather Dynamics",
    "authors": [
      "Wenqing Zhang",
      "Junming Huang",
      "Ruotong Wang",
      "Changsong Wei",
      "Wenqian Huang",
      "Yuxin Qiao"
    ],
    "abstract": "Long-short range time series forecasting is essential for predicting future\ntrends and patterns over extended periods. While deep learning models such as\nTransformers have made significant strides in advancing time series\nforecasting, they often encounter difficulties in capturing long-term\ndependencies and effectively managing sparse semantic features. The state-space\nmodel, Mamba, addresses these issues through its adept handling of selective\ninput and parallel computing, striking a balance between computational\nefficiency and prediction accuracy. This article examines the advantages and\ndisadvantages of both Mamba and Transformer models, and introduces a combined\napproach, MAT, which leverages the strengths of each model to capture unique\nlong-short range dependencies and inherent evolutionary patterns in\nmultivariate time series. Specifically, MAT harnesses the long-range dependency\ncapabilities of Mamba and the short-range characteristics of Transformers.\nExperimental results on benchmark weather datasets demonstrate that MAT\noutperforms existing comparable methods in terms of prediction accuracy,\nscalability, and memory efficiency.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "6 pages, 4 figures, to be presented at the 5th International\n  Conference on Electrical, Communication and Computer Engineering (ICECCE)",
    "pdf_url": "http://arxiv.org/pdf/2409.08530v1",
    "published_date": "2024-09-13 04:23:54 UTC",
    "updated_date": "2024-09-13 04:23:54 UTC"
  },
  {
    "arxiv_id": "2409.08514v2",
    "title": "Apollo: Band-sequence Modeling for High-Quality Audio Restoration",
    "authors": [
      "Kai Li",
      "Yi Luo"
    ],
    "abstract": "Audio restoration has become increasingly significant in modern society, not\nonly due to the demand for high-quality auditory experiences enabled by\nadvanced playback devices, but also because the growing capabilities of\ngenerative audio models necessitate high-fidelity audio. Typically, audio\nrestoration is defined as a task of predicting undistorted audio from damaged\ninput, often trained using a GAN framework to balance perception and\ndistortion. Since audio degradation is primarily concentrated in mid- and\nhigh-frequency ranges, especially due to codecs, a key challenge lies in\ndesigning a generator capable of preserving low-frequency information while\naccurately reconstructing high-quality mid- and high-frequency content.\nInspired by recent advancements in high-sample-rate music separation, speech\nenhancement, and audio codec models, we propose Apollo, a generative model\ndesigned for high-sample-rate audio restoration. Apollo employs an explicit\nfrequency band split module to model the relationships between different\nfrequency bands, allowing for more coherent and higher-quality restored audio.\nEvaluated on the MUSDB18-HQ and MoisesDB datasets, Apollo consistently\noutperforms existing SR-GAN models across various bit rates and music genres,\nparticularly excelling in complex scenarios involving mixtures of multiple\ninstruments and vocals. Apollo significantly improves music restoration quality\nwhile maintaining computational efficiency. The source code for Apollo is\npublicly available at https://github.com/JusperLee/Apollo.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted by ICASSP 2025, Demo Page: https://cslikai.cn/Apollo",
    "pdf_url": "http://arxiv.org/pdf/2409.08514v2",
    "published_date": "2024-09-13 03:25:34 UTC",
    "updated_date": "2025-01-07 15:37:10 UTC"
  },
  {
    "arxiv_id": "2409.08487v1",
    "title": "Sub-graph Based Diffusion Model for Link Prediction",
    "authors": [
      "Hang Li",
      "Wei Jin",
      "Geri Skenderi",
      "Harry Shomer",
      "Wenzhuo Tang",
      "Wenqi Fan",
      "Jiliang Tang"
    ],
    "abstract": "Denoising Diffusion Probabilistic Models (DDPMs) represent a contemporary\nclass of generative models with exceptional qualities in both synthesis and\nmaximizing the data likelihood. These models work by traversing a forward\nMarkov Chain where data is perturbed, followed by a reverse process where a\nneural network learns to undo the perturbations and recover the original data.\nThere have been increasing efforts exploring the applications of DDPMs in the\ngraph domain. However, most of them have focused on the generative perspective.\nIn this paper, we aim to build a novel generative model for link prediction. In\nparticular, we treat link prediction between a pair of nodes as a conditional\nlikelihood estimation of its enclosing sub-graph. With a dedicated design to\ndecompose the likelihood estimation process via the Bayesian formula, we are\nable to separate the estimation of sub-graph structure and its node features.\nSuch designs allow our model to simultaneously enjoy the advantages of\ninductive learning and the strong generalization capability. Remarkably,\ncomprehensive experiments across various datasets validate that our proposed\nmethod presents numerous advantages: (1) transferability across datasets\nwithout retraining, (2) promising generalization on limited training data, and\n(3) robustness against graph adversarial attacks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "17 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.08487v1",
    "published_date": "2024-09-13 02:23:55 UTC",
    "updated_date": "2024-09-13 02:23:55 UTC"
  },
  {
    "arxiv_id": "2409.08483v1",
    "title": "A BERT-Based Summarization approach for depression detection",
    "authors": [
      "Hossein Salahshoor Gavalan",
      "Mohmmad Naim Rastgoo",
      "Bahareh Nakisa"
    ],
    "abstract": "Depression is a globally prevalent mental disorder with potentially severe\nrepercussions if not addressed, especially in individuals with recurrent\nepisodes. Prior research has shown that early intervention has the potential to\nmitigate or alleviate symptoms of depression. However, implementing such\ninterventions in a real-world setting may pose considerable challenges. A\npromising strategy involves leveraging machine learning and artificial\nintelligence to autonomously detect depression indicators from diverse data\nsources. One of the most widely available and informative data sources is text,\nwhich can reveal a person's mood, thoughts, and feelings. In this context,\nvirtual agents programmed to conduct interviews using clinically validated\nquestionnaires, such as those found in the DAIC-WOZ dataset, offer a robust\nmeans for depression detection through linguistic analysis. Utilizing\nBERT-based models, which are powerful and versatile yet use fewer resources\nthan contemporary large language models, to convert text into numerical\nrepresentations significantly enhances the precision of depression diagnosis.\nThese models adeptly capture complex semantic and syntactic nuances, improving\nthe detection accuracy of depressive symptoms. Given the inherent limitations\nof these models concerning text length, our study proposes text summarization\nas a preprocessing technique to diminish the length and intricacies of input\ntexts. Implementing this method within our uniquely developed framework for\nfeature extraction and classification yielded an F1-score of 0.67 on the test\nset surpassing all prior benchmarks and 0.81 on the validation set exceeding\nmost previous results on the DAIC-WOZ dataset. Furthermore, we have devised a\ndepression lexicon to assess summary quality and relevance. This lexicon\nconstitutes a valuable asset for ongoing research in depression detection.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.08483v1",
    "published_date": "2024-09-13 02:14:34 UTC",
    "updated_date": "2024-09-13 02:14:34 UTC"
  },
  {
    "arxiv_id": "2409.08479v2",
    "title": "Exploring Information Retrieval Landscapes: An Investigation of a Novel Evaluation Techniques and Comparative Document Splitting Methods",
    "authors": [
      "Esmaeil Narimissa",
      "David Raithel"
    ],
    "abstract": "The performance of Retrieval-Augmented Generation (RAG) systems in\ninformation retrieval is significantly influenced by the characteristics of the\ndocuments being processed. In this study, the structured nature of textbooks,\nthe conciseness of articles, and the narrative complexity of novels are shown\nto require distinct retrieval strategies. A comparative evaluation of multiple\ndocument-splitting methods reveals that the Recursive Character Splitter\noutperforms the Token-based Splitter in preserving contextual integrity. A\nnovel evaluation technique is introduced, utilizing an open-source model to\ngenerate a comprehensive dataset of question-and-answer pairs, simulating\nrealistic retrieval scenarios to enhance testing efficiency and metric\nreliability. The evaluation employs weighted scoring metrics, including\nSequenceMatcher, BLEU, METEOR, and BERT Score, to assess the system's accuracy\nand relevance. This approach establishes a refined standard for evaluating the\nprecision of RAG systems, with future research focusing on optimizing chunk and\noverlap sizes to improve retrieval accuracy and efficiency.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "I.2.7; H.3.3"
    ],
    "primary_category": "cs.IR",
    "comment": "This article is 16 pages long and includes detailed comparisons of\n  RAG systems and document splitting techniques",
    "pdf_url": "http://arxiv.org/pdf/2409.08479v2",
    "published_date": "2024-09-13 02:08:47 UTC",
    "updated_date": "2024-09-20 04:52:16 UTC"
  },
  {
    "arxiv_id": "2409.08477v2",
    "title": "Integrating Neural Operators with Diffusion Models Improves Spectral Representation in Turbulence Modeling",
    "authors": [
      "Vivek Oommen",
      "Aniruddha Bora",
      "Zhen Zhang",
      "George Em Karniadakis"
    ],
    "abstract": "We integrate neural operators with diffusion models to address the spectral\nlimitations of neural operators in surrogate modeling of turbulent flows. While\nneural operators offer computational efficiency, they exhibit deficiencies in\ncapturing high-frequency flow dynamics, resulting in overly smooth\napproximations. To overcome this, we condition diffusion models on neural\noperators to enhance the resolution of turbulent structures. Our approach is\nvalidated for different neural operators on diverse datasets, including a high\nReynolds number jet flow simulation and experimental Schlieren velocimetry. The\nproposed method significantly improves the alignment of predicted energy\nspectra with true distributions compared to neural operators alone. This\nenables the diffusion models to stabilize longer forecasts through\ndiffusion-corrected autoregressive rollouts, as we demonstrate in this work.\nAdditionally, proper orthogonal decomposition analysis demonstrates enhanced\nspectral fidelity in space-time. This work establishes a new paradigm for\ncombining generative models with neural operators to advance surrogate modeling\nof turbulent systems, and it can be used in other scientific applications that\ninvolve microstructure and high-frequency content. See our project page:\nvivekoommen.github.io/NO_DM",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.flu-dyn"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.08477v2",
    "published_date": "2024-09-13 02:07:20 UTC",
    "updated_date": "2025-02-13 01:09:58 UTC"
  },
  {
    "arxiv_id": "2409.08472v1",
    "title": "An Intent Modeling and Inference Framework for Autonomous and Remotely Piloted Aerial Systems",
    "authors": [
      "Kesav Kaza",
      "Varun Mehta",
      "Hamid Azad",
      "Miodrag Bolic",
      "Iraj Mantegh"
    ],
    "abstract": "An intent modelling and inference framework is presented to assist the\ndefense planning for protecting a geo-fence against unauthorized flights.\nFirst, a novel mathematical definition for the intent of an uncrewed aircraft\nsystem (UAS) is presented. The concepts of critical waypoints and critical\nwaypoint patterns are introduced and associated with a motion process to fully\ncharacterize an intent. This modelling framework consists of representations of\na UAS mission planner, used to plan the aircraft's motion sequence, as well as\na defense planner, defined to protect the geo-fence. It is applicable to\nautonomous, semi-autonomous, and piloted systems in 2D and 3D environments with\nobstacles. The framework is illustrated by defining a library of intents for a\nsecurity application. Detection and tracking of the target are presumed for\nformulating the intent inference problem. Multiple formulations of the decision\nmaker's objective are discussed as part of a deep-learning-based methodology.\nFurther, a multi-modal dynamic model for characterizing the UAS flight is\ndiscussed. This is later utilized to extract features using the interacting\nmultiple model (IMM) filter for training the intent classifier. Finally, as\npart of the simulation study, an attention-based bi-directional long short-term\nmemory (Bi-LSTM) network for intent inference is presented. The simulation\nexperiments illustrate various aspects of the framework, including trajectory\ngeneration, radar measurement simulation, etc., in 2D and 3D environments.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.RO",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "8 pages, 7 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2409.08472v1",
    "published_date": "2024-09-13 01:57:37 UTC",
    "updated_date": "2024-09-13 01:57:37 UTC"
  },
  {
    "arxiv_id": "2409.08466v2",
    "title": "Explaining Datasets in Words: Statistical Models with Natural Language Parameters",
    "authors": [
      "Ruiqi Zhong",
      "Heng Wang",
      "Dan Klein",
      "Jacob Steinhardt"
    ],
    "abstract": "To make sense of massive data, we often fit simplified models and then\ninterpret the parameters; for example, we cluster the text embeddings and then\ninterpret the mean parameters of each cluster. However, these parameters are\noften high-dimensional and hard to interpret. To make model parameters directly\ninterpretable, we introduce a family of statistical models -- including\nclustering, time series, and classification models -- parameterized by natural\nlanguage predicates. For example, a cluster of text about COVID could be\nparameterized by the predicate \"discusses COVID\". To learn these statistical\nmodels effectively, we develop a model-agnostic algorithm that optimizes\ncontinuous relaxations of predicate parameters with gradient descent and\ndiscretizes them by prompting language models (LMs). Finally, we apply our\nframework to a wide range of problems: taxonomizing user chat dialogues,\ncharacterizing how they evolve across time, finding categories where one\nlanguage model is better than the other, clustering math problems based on\nsubareas, and explaining visual features in memorable images. Our framework is\nhighly versatile, applicable to both textual and visual domains, can be easily\nsteered to focus on specific properties (e.g. subareas), and explains\nsophisticated concepts that classical methods (e.g. n-gram analysis) struggle\nto produce.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.08466v2",
    "published_date": "2024-09-13 01:40:20 UTC",
    "updated_date": "2025-01-12 17:23:21 UTC"
  },
  {
    "arxiv_id": "2409.08450v1",
    "title": "Inter Observer Variability Assessment through Ordered Weighted Belief Divergence Measure in MAGDM Application to the Ensemble Classifier Feature Fusion",
    "authors": [
      "Pragya Gupta",
      "Debjani Chakraborty",
      "Debashree Guha"
    ],
    "abstract": "A large number of multi-attribute group decisionmaking (MAGDM) have been\nwidely introduced to obtain consensus results. However, most of the\nmethodologies ignore the conflict among the experts opinions and only consider\nequal or variable priorities of them. Therefore, this study aims to propose an\nEvidential MAGDM method by assessing the inter-observational variability and\nhandling uncertainty that emerges between the experts. The proposed framework\nhas fourfold contributions. First, the basic probability assignment (BPA)\ngeneration method is introduced to consider the inherent characteristics of\neach alternative by computing the degree of belief. Second, the ordered\nweighted belief and plausibility measure is constructed to capture the overall\nintrinsic information of the alternative by assessing the inter-observational\nvariability and addressing the conflicts emerging between the group of experts.\nAn ordered weighted belief divergence measure is constructed to acquire the\nweighted support for each group of experts to obtain the final preference\nrelationship. Finally, we have shown an illustrative example of the proposed\nEvidential MAGDM framework. Further, we have analyzed the interpretation of\nEvidential MAGDM in the real-world application for ensemble classifier feature\nfusion to diagnose retinal disorders using optical coherence tomography images.",
    "categories": [
      "cs.AI",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.08450v1",
    "published_date": "2024-09-13 00:53:00 UTC",
    "updated_date": "2024-09-13 00:53:00 UTC"
  },
  {
    "arxiv_id": "2409.08439v2",
    "title": "Input-to-State Stable Coupled Oscillator Networks for Closed-form Model-based Control in Latent Space",
    "authors": [
      "Maximilian Stölzle",
      "Cosimo Della Santina"
    ],
    "abstract": "Even though a variety of methods have been proposed in the literature,\nefficient and effective latent-space control (i.e., control in a learned\nlow-dimensional space) of physical systems remains an open challenge. We argue\nthat a promising avenue is to leverage powerful and well-understood closed-form\nstrategies from control theory literature in combination with learned dynamics,\nsuch as potential-energy shaping. We identify three fundamental shortcomings in\nexisting latent-space models that have so far prevented this powerful\ncombination: (i) they lack the mathematical structure of a physical system,\n(ii) they do not inherently conserve the stability properties of the real\nsystems, (iii) these methods do not have an invertible mapping between input\nand latent-space forcing. This work proposes a novel Coupled Oscillator Network\n(CON) model that simultaneously tackles all these issues. More specifically,\n(i) we show analytically that CON is a Lagrangian system - i.e., it possesses\nwell-defined potential and kinetic energy terms. Then, (ii) we provide formal\nproof of global Input-to-State stability using Lyapunov arguments. Moving to\nthe experimental side, we demonstrate that CON reaches SoA performance when\nlearning complex nonlinear dynamics of mechanical systems directly from images.\nAn additional methodological innovation contributing to achieving this third\ngoal is an approximated closed-form solution for efficient integration of\nnetwork dynamics, which eases efficient training. We tackle (iii) by\napproximating the forcing-to-input mapping with a decoder that is trained to\nreconstruct the input based on the encoded latent space force. Finally, we show\nhow these properties enable latent-space control. We use an integral-saturated\nPID with potential force compensation and demonstrate high-quality performance\non a soft robot using raw pixels as the only feedback information.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "38th Conference on Neural Information Processing Systems (NeurIPS\n  2024) spotlight, 49 pages",
    "pdf_url": "http://arxiv.org/pdf/2409.08439v2",
    "published_date": "2024-09-13 00:11:09 UTC",
    "updated_date": "2024-10-13 22:04:42 UTC"
  },
  {
    "arxiv_id": "2409.08435v4",
    "title": "When Context Leads but Parametric Memory Follows in Large Language Models",
    "authors": [
      "Yufei Tao",
      "Adam Hiatt",
      "Erik Haake",
      "Antonie J. Jetter",
      "Ameeta Agrawal"
    ],
    "abstract": "Large language models (LLMs) have demonstrated remarkable progress in\nleveraging diverse knowledge sources. This study investigates how nine widely\nused LLMs allocate knowledge between local context and global parameters when\nanswering open-ended questions in knowledge-consistent scenarios. We introduce\na novel dataset, WikiAtomic, and systematically vary context sizes to analyze\nhow LLMs prioritize and utilize the provided information and their parametric\nknowledge in knowledge-consistent scenarios. Additionally, we also study their\ntendency to hallucinate under varying context sizes. Our findings reveal\nconsistent patterns across models, including a consistent reliance on both\ncontextual (around 70%) and parametric (around 30%) knowledge, and a decrease\nin hallucinations with increasing context. These insights highlight the\nimportance of more effective context organization and developing models that\nuse input more deterministically for robust performance.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by EMNLP 2024 Main Conference",
    "pdf_url": "http://arxiv.org/pdf/2409.08435v4",
    "published_date": "2024-09-13 00:03:19 UTC",
    "updated_date": "2024-11-21 02:31:15 UTC"
  }
]