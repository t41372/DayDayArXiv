[
  {
    "arxiv_id": "2503.02130v1",
    "title": "Forgetting Transformer: Softmax Attention with a Forget Gate",
    "authors": [
      "Zhixuan Lin",
      "Evgenii Nikishin",
      "Xu Owen He",
      "Aaron Courville"
    ],
    "abstract": "An essential component of modern recurrent sequence models is the forget\ngate. While Transformers do not have an explicit recurrent form, we show that a\nforget gate can be naturally incorporated into Transformers by down-weighting\nthe unnormalized attention scores in a data-dependent way. We name this\nattention mechanism the Forgetting Attention and the resulting model the\nForgetting Transformer (FoX). We show that FoX outperforms the Transformer on\nlong-context language modeling, length extrapolation, and short-context\ndownstream tasks, while performing on par with the Transformer on long-context\ndownstream tasks. Moreover, it is compatible with the FlashAttention algorithm\nand does not require any positional embeddings. Several analyses, including the\nneedle-in-the-haystack test, show that FoX also retains the Transformer's\nsuperior long-context capabilities over recurrent sequence models such as\nMamba-2, HGRN2, and DeltaNet. We also introduce a \"Pro\" block design that\nincorporates some common architectural components in recurrent sequence models\nand find it significantly improves the performance of both FoX and the\nTransformer. Our code is available at\nhttps://github.com/zhixuan-lin/forgetting-transformer.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Published as a conference paper at ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.02130v1",
    "published_date": "2025-03-03 23:35:23 UTC",
    "updated_date": "2025-03-03 23:35:23 UTC"
  },
  {
    "arxiv_id": "2503.02129v1",
    "title": "A Near Complete Nonasymptotic Generalization Theory For Multilayer Neural Networks: Beyond the Bias-Variance Tradeoff",
    "authors": [
      "Hao Yu",
      "Xiangyang Ji"
    ],
    "abstract": "We propose a first near complete (that will make explicit sense in the main\ntext) nonasymptotic generalization theory for multilayer neural networks with\narbitrary Lipschitz activations and general Lipschitz loss functions (with some\nvery mild conditions). In particular, it doens't require the boundness of loss\nfunction, as commonly assumed in the literature. Our theory goes beyond the\nbias-variance tradeoff, aligned with phenomenon typically encountered in deep\nlearning. It is therefore sharp different with other existing nonasymptotic\ngeneralization error bounds for neural networks. More explicitly, we propose an\nexplicit generalization error upper bound for multilayer neural networks with\narbitrary Lipschitz activations $\\sigma$ with $\\sigma(0)=0$ and broad enough\nLipschitz loss functions, without requiring either the width, depth or other\nhyperparameters of the neural network approaching infinity, a specific neural\nnetwork architect (e.g. sparsity, boundness of some norms), a particular\nactivation function, a particular optimization algorithm or boundness of the\nloss function, and with taking the approximation error into consideration.\nGeneral Lipschitz activation can also be accommodated into our framework. A\nfeature of our theory is that it also considers approximation errors.\nFurthermore, we show the near minimax optimality of our theory for multilayer\nReLU networks for regression problems. Notably, our upper bound exhibits the\nfamous double descent phenomenon for such networks, which is the most\ndistinguished characteristic compared with other existing results. This work\nemphasizes a view that many classical results should be improved to embrace the\nunintuitive characteristics of deep learning to get a better understanding of\nit.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.02129v1",
    "published_date": "2025-03-03 23:34:12 UTC",
    "updated_date": "2025-03-03 23:34:12 UTC"
  },
  {
    "arxiv_id": "2503.02123v1",
    "title": "TMIQ: Quantifying Test and Measurement Domain Intelligence in Large Language Models",
    "authors": [
      "Emmanuel A. Olowe",
      "Danial Chitnis"
    ],
    "abstract": "The Test and Measurement domain, known for its strict requirements for\naccuracy and efficiency, is increasingly adopting Generative AI technologies to\nenhance the performance of data analysis, automation, and decision-making\nprocesses. Among these, Large Language Models (LLMs) show significant promise\nfor advancing automation and precision in testing. However, the evaluation of\nLLMs in this specialized area remains insufficiently explored. To address this\ngap, we introduce the Test and Measurement Intelligence Quotient (TMIQ), a\nbenchmark designed to quantitatively assess LLMs across a wide range of\nelectronic engineering tasks. TMIQ offers a comprehensive set of scenarios and\nmetrics for detailed evaluation, including SCPI command matching accuracy,\nranked response evaluation, Chain-of-Thought Reasoning (CoT), and the impact of\noutput formatting variations required by LLMs on performance. In testing\nvarious LLMs, our findings indicate varying levels of proficiency, with exact\nSCPI command match accuracy ranging from around 56% to 73%, and ranked matching\nfirst-position scores achieving around 33% for the best-performing model. We\nalso assess token usage, cost-efficiency, and response times, identifying\ntrade-offs between accuracy and operational efficiency. Additionally, we\npresent a command-line interface (CLI) tool that enables users to generate\ndatasets using the same methodology, allowing for tailored assessments of LLMs.\nTMIQ and the CLI tool provide a rigorous, reproducible means of evaluating LLMs\nfor production environments, facilitating continuous monitoring and identifying\nstrengths and areas for improvement, and driving innovation in their selections\nfor applications within the Test and Measurement industry.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "accepted in IEEE I2MTC 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.02123v1",
    "published_date": "2025-03-03 23:12:49 UTC",
    "updated_date": "2025-03-03 23:12:49 UTC"
  },
  {
    "arxiv_id": "2503.02117v1",
    "title": "Parabolic Continual Learning",
    "authors": [
      "Haoming Yang",
      "Ali Hasan",
      "Vahid Tarokh"
    ],
    "abstract": "Regularizing continual learning techniques is important for anticipating\nalgorithmic behavior under new realizations of data. We introduce a new\napproach to continual learning by imposing the properties of a parabolic\npartial differential equation (PDE) to regularize the expected behavior of the\nloss over time. This class of parabolic PDEs has a number of favorable\nproperties that allow us to analyze the error incurred through forgetting and\nthe error induced through generalization. Specifically, we do this through\nimposing boundary conditions where the boundary is given by a memory buffer. By\nusing the memory buffer as a boundary, we can enforce long term dependencies by\nbounding the expected error by the boundary loss. Finally, we illustrate the\nempirical performance of the method on a series of continual learning tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.02117v1",
    "published_date": "2025-03-03 22:59:13 UTC",
    "updated_date": "2025-03-03 22:59:13 UTC"
  },
  {
    "arxiv_id": "2503.02104v1",
    "title": "Biomedical Foundation Model: A Survey",
    "authors": [
      "Xiangrui Liu",
      "Yuanyuan Zhang",
      "Yingzhou Lu",
      "Changchang Yin",
      "Xiaoling Hu",
      "Xiaoou Liu",
      "Lulu Chen",
      "Sheng Wang",
      "Alexander Rodriguez",
      "Huaxiu Yao",
      "Yezhou Yang",
      "Ping Zhang",
      "Jintai Chen",
      "Tianfan Fu",
      "Xiao Wang"
    ],
    "abstract": "Foundation models, first introduced in 2021, are large-scale pre-trained\nmodels (e.g., large language models (LLMs) and vision-language models (VLMs))\nthat learn from extensive unlabeled datasets through unsupervised methods,\nenabling them to excel in diverse downstream tasks. These models, like GPT, can\nbe adapted to various applications such as question answering and visual\nunderstanding, outperforming task-specific AI models and earning their name due\nto broad applicability across fields. The development of biomedical foundation\nmodels marks a significant milestone in leveraging artificial intelligence (AI)\nto understand complex biological phenomena and advance medical research and\npractice. This survey explores the potential of foundation models across\ndiverse domains within biomedical fields, including computational biology, drug\ndiscovery and development, clinical informatics, medical imaging, and public\nhealth. The purpose of this survey is to inspire ongoing research in the\napplication of foundation models to health science.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.02104v1",
    "published_date": "2025-03-03 22:42:00 UTC",
    "updated_date": "2025-03-03 22:42:00 UTC"
  },
  {
    "arxiv_id": "2503.02102v2",
    "title": "Provable Benefits of Task-Specific Prompts for In-context Learning",
    "authors": [
      "Xiangyu Chang",
      "Yingcong Li",
      "Muti Kara",
      "Samet Oymak",
      "Amit K. Roy-Chowdhury"
    ],
    "abstract": "The in-context learning capabilities of modern language models have motivated\na deeper mathematical understanding of sequence models. A line of recent work\nhas shown that linear attention models can emulate projected gradient descent\niterations to implicitly learn the task vector from the data provided in the\ncontext window. In this work, we consider a novel setting where the global task\ndistribution can be partitioned into a union of conditional task distributions.\nWe then examine the use of task-specific prompts and prediction heads for\nlearning the prior information associated with the conditional task\ndistribution using a one-layer attention model. Our results on loss landscape\nshow that task-specific prompts facilitate a covariance-mean decoupling where\nprompt-tuning explains the conditional mean of the distribution whereas the\nvariance is learned/explained through in-context learning. Incorporating\ntask-specific head further aids this process by entirely decoupling estimation\nof mean and variance components. This covariance-mean perspective similarly\nexplains how jointly training prompt and attention weights can provably help\nover fine-tuning after pretraining.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Proceedings of the 28th International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.02102v2",
    "published_date": "2025-03-03 22:37:03 UTC",
    "updated_date": "2025-03-05 16:18:33 UTC"
  },
  {
    "arxiv_id": "2503.02099v1",
    "title": "LLMs as Educational Analysts: Transforming Multimodal Data Traces into Actionable Reading Assessment Reports",
    "authors": [
      "Eduardo Davalos",
      "Yike Zhang",
      "Namrata Srivastava",
      "Jorge Alberto Salas",
      "Sara McFadden",
      "Sun-Joo Cho",
      "Gautam Biswas",
      "Amanda Goodwin"
    ],
    "abstract": "Reading assessments are essential for enhancing students' comprehension, yet\nmany EdTech applications focus mainly on outcome-based metrics, providing\nlimited insights into student behavior and cognition. This study investigates\nthe use of multimodal data sources -- including eye-tracking data, learning\noutcomes, assessment content, and teaching standards -- to derive meaningful\nreading insights. We employ unsupervised learning techniques to identify\ndistinct reading behavior patterns, and then a large language model (LLM)\nsynthesizes the derived information into actionable reports for educators,\nstreamlining the interpretation process. LLM experts and human educators\nevaluate these reports for clarity, accuracy, relevance, and pedagogical\nusefulness. Our findings indicate that LLMs can effectively function as\neducational analysts, turning diverse data into teacher-friendly insights that\nare well-received by educators. While promising for automating insight\ngeneration, human oversight remains crucial to ensure reliability and fairness.\nThis research advances human-centered AI in education, connecting data-driven\nanalytics with practical classroom applications.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC",
      "I.2.1; I.2.7; K.3.1"
    ],
    "primary_category": "cs.CY",
    "comment": "15 pages, 5 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2503.02099v1",
    "published_date": "2025-03-03 22:34:08 UTC",
    "updated_date": "2025-03-03 22:34:08 UTC"
  },
  {
    "arxiv_id": "2503.02093v1",
    "title": "Correlation to Causation: A Causal Deep Learning Framework for Arctic Sea Ice Prediction",
    "authors": [
      "Emam Hossain",
      "Muhammad Hasan Ferdous",
      "Jianwu Wang",
      "Aneesh Subramanian",
      "Md Osman Gani"
    ],
    "abstract": "Traditional machine learning and deep learning techniques rely on\ncorrelation-based learning, often failing to distinguish spurious associations\nfrom true causal relationships, which limits robustness, interpretability, and\ngeneralizability. To address these challenges, we propose a causality-driven\ndeep learning framework that integrates Multivariate Granger Causality (MVGC)\nand PCMCI+ causal discovery algorithms with a hybrid deep learning\narchitecture. Using 43 years (1979-2021) of daily and monthly Arctic Sea Ice\nExtent (SIE) and ocean-atmospheric datasets, our approach identifies causally\nsignificant factors, prioritizes features with direct influence, reduces\nfeature overhead, and improves computational efficiency. Experiments\ndemonstrate that integrating causal features enhances the deep learning model's\npredictive accuracy and interpretability across multiple lead times. Beyond SIE\nprediction, the proposed framework offers a scalable solution for dynamic,\nhigh-dimensional systems, advancing both theoretical understanding and\npractical applications in predictive modeling.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted for Publication in Causal AI for Robust Decision Making\n  (CARD) Workshop in the International Conference on Pervasive Computing and\n  Communications (PerCom 2025)",
    "pdf_url": "http://arxiv.org/pdf/2503.02093v1",
    "published_date": "2025-03-03 22:24:14 UTC",
    "updated_date": "2025-03-03 22:24:14 UTC"
  },
  {
    "arxiv_id": "2503.05804v1",
    "title": "Holistically Evaluating the Environmental Impact of Creating Language Models",
    "authors": [
      "Jacob Morrison",
      "Clara Na",
      "Jared Fernandez",
      "Tim Dettmers",
      "Emma Strubell",
      "Jesse Dodge"
    ],
    "abstract": "As the performance of artificial intelligence systems has dramatically\nincreased, so too has the environmental impact of creating these systems. While\nmany model developers release estimates of the power consumption and carbon\nemissions from the final training runs for their latest models, there is\ncomparatively little transparency into the impact of model development,\nhardware manufacturing, and total water usage throughout. In this work, we\nestimate the real-world environmental impact of developing a series of language\nmodels, ranging from 20 million to 13 billion active parameters, trained on up\nto 5.6 trillion tokens each. When accounting for hardware manufacturing, model\ndevelopment, and our final training runs, we find that our series of models\nreleased 493 metric tons of carbon emissions, equivalent to powering about 98\nhomes in the United States for one year, and consumed 2.769 million liters of\nwater, equivalent to about 24.5 years of water usage by a person in the United\nStates, even though our data center is extremely water-efficient. We measure\nand report the environmental impact of our model development; to the best of\nour knowledge we are the first to do so for LLMs, and we find that model\ndevelopment, the impact of which is generally not disclosed by most model\ndevelopers, amounted to ~50% of that of training. By looking at detailed time\nseries data for power consumption, we also find that power usage throughout\ntraining is not consistent, fluctuating between ~15% and ~85% of our hardware's\nmaximum power draw, with negative implications for grid-scale planning as\ndemand continues to grow. We close with a discussion on the continued\ndifficulty of estimating the environmental impact of AI systems, and key\ntakeaways for model developers and the public at large.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "ICLR 2025 (spotlight)",
    "pdf_url": "http://arxiv.org/pdf/2503.05804v1",
    "published_date": "2025-03-03 22:16:15 UTC",
    "updated_date": "2025-03-03 22:16:15 UTC"
  },
  {
    "arxiv_id": "2503.02080v1",
    "title": "Linear Representations of Political Perspective Emerge in Large Language Models",
    "authors": [
      "Junsol Kim",
      "James Evans",
      "Aaron Schein"
    ],
    "abstract": "Large language models (LLMs) have demonstrated the ability to generate text\nthat realistically reflects a range of different subjective human perspectives.\nThis paper studies how LLMs are seemingly able to reflect more liberal versus\nmore conservative viewpoints among other political perspectives in American\npolitics. We show that LLMs possess linear representations of political\nperspectives within activation space, wherein more similar perspectives are\nrepresented closer together. To do so, we probe the attention heads across the\nlayers of three open transformer-based LLMs (\\texttt{Llama-2-7b-chat},\n\\texttt{Mistral-7b-instruct}, \\texttt{Vicuna-7b}). We first prompt models to\ngenerate text from the perspectives of different U.S.~lawmakers. We then\nidentify sets of attention heads whose activations linearly predict those\nlawmakers' DW-NOMINATE scores, a widely-used and validated measure of political\nideology. We find that highly predictive heads are primarily located in the\nmiddle layers, often speculated to encode high-level concepts and tasks. Using\nprobes only trained to predict lawmakers' ideology, we then show that the same\nprobes can predict measures of news outlets' slant from the activations of\nmodels prompted to simulate text from those news outlets. These linear probes\nallow us to visualize, interpret, and monitor ideological stances implicitly\nadopted by an LLM as it generates open-ended responses. Finally, we demonstrate\nthat by applying linear interventions to these attention heads, we can steer\nthe model outputs toward a more liberal or conservative stance. Overall, our\nresearch suggests that LLMs possess a high-level linear representation of\nAmerican political ideology and that by leveraging recent advances in\nmechanistic interpretability, we can identify, monitor, and steer the\nsubjective perspective underlying generated text.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Published as a conference paper at ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.02080v1",
    "published_date": "2025-03-03 21:59:01 UTC",
    "updated_date": "2025-03-03 21:59:01 UTC"
  },
  {
    "arxiv_id": "2503.02078v2",
    "title": "Superscopes: Amplifying Internal Feature Representations for Language Model Interpretation",
    "authors": [
      "Jonathan Jacobi",
      "Gal Niv"
    ],
    "abstract": "Understanding and interpreting the internal representations of large language\nmodels (LLMs) remains an open challenge. Patchscopes introduced a method for\nprobing internal activations by patching them into new prompts, prompting\nmodels to self-explain their hidden representations. We introduce Superscopes,\na technique that systematically amplifies superposed features in MLP outputs\n(multilayer perceptron) and hidden states before patching them into new\ncontexts. Inspired by the \"features as directions\" perspective and the\nClassifier-Free Guidance (CFG) approach from diffusion models, Superscopes\namplifies weak but meaningful features, enabling the interpretation of internal\nrepresentations that previous methods failed to explain-all without requiring\nadditional training. This approach provides new insights into how LLMs build\ncontext and represent complex concepts, further advancing mechanistic\ninterpretability.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.02078v2",
    "published_date": "2025-03-03 21:58:12 UTC",
    "updated_date": "2025-03-09 10:27:43 UTC"
  },
  {
    "arxiv_id": "2503.02077v2",
    "title": "M3HF: Multi-agent Reinforcement Learning from Multi-phase Human Feedback of Mixed Quality",
    "authors": [
      "Ziyan Wang",
      "Zhicheng Zhang",
      "Fei Fang",
      "Yali Du"
    ],
    "abstract": "Designing effective reward functions in multi-agent reinforcement learning\n(MARL) is a significant challenge, often leading to suboptimal or misaligned\nbehaviors in complex, coordinated environments. We introduce Multi-agent\nReinforcement Learning from Multi-phase Human Feedback of Mixed Quality (M3HF),\na novel framework that integrates multi-phase human feedback of mixed quality\ninto the MARL training process. By involving humans with diverse expertise\nlevels to provide iterative guidance, M3HF leverages both expert and non-expert\nfeedback to continuously refine agents' policies. During training, we\nstrategically pause agent learning for human evaluation, parse feedback using\nlarge language models to assign it appropriately and update reward functions\nthrough predefined templates and adaptive weight by using weight decay and\nperformance-based adjustments. Our approach enables the integration of nuanced\nhuman insights across various levels of quality, enhancing the interpretability\nand robustness of multi-agent cooperation. Empirical results in challenging\nenvironments demonstrate that M3HF significantly outperforms state-of-the-art\nmethods, effectively addressing the complexities of reward design in MARL and\nenabling broader human participation in the training process.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.MA",
    "comment": "Seventeen pages, four figures",
    "pdf_url": "http://arxiv.org/pdf/2503.02077v2",
    "published_date": "2025-03-03 21:58:10 UTC",
    "updated_date": "2025-03-06 20:50:31 UTC"
  },
  {
    "arxiv_id": "2503.02068v1",
    "title": "Interactive Debugging and Steering of Multi-Agent AI Systems",
    "authors": [
      "Will Epperson",
      "Gagan Bansal",
      "Victor Dibia",
      "Adam Fourney",
      "Jack Gerrits",
      "Erkang Zhu",
      "Saleema Amershi"
    ],
    "abstract": "Fully autonomous teams of LLM-powered AI agents are emerging that collaborate\nto perform complex tasks for users. What challenges do developers face when\ntrying to build and debug these AI agent teams? In formative interviews with\nfive AI agent developers, we identify core challenges: difficulty reviewing\nlong agent conversations to localize errors, lack of support in current tools\nfor interactive debugging, and the need for tool support to iterate on agent\nconfiguration. Based on these needs, we developed an interactive multi-agent\ndebugging tool, AGDebugger, with a UI for browsing and sending messages, the\nability to edit and reset prior agent messages, and an overview visualization\nfor navigating complex message histories. In a two-part user study with 14\nparticipants, we identify common user strategies for steering agents and\nhighlight the importance of interactive message resets for debugging. Our\nstudies deepen understanding of interfaces for debugging increasingly important\nagentic workflows.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.MA",
    "comment": "Published at CHI 25",
    "pdf_url": "http://arxiv.org/pdf/2503.02068v1",
    "published_date": "2025-03-03 21:42:54 UTC",
    "updated_date": "2025-03-03 21:42:54 UTC"
  },
  {
    "arxiv_id": "2503.02067v1",
    "title": "AI persuading AI vs AI persuading Humans: LLMs' Differential Effectiveness in Promoting Pro-Environmental Behavior",
    "authors": [
      "Alexander Doudkin",
      "Pat Pataranutaporn",
      "Pattie Maes"
    ],
    "abstract": "Pro-environmental behavior (PEB) is vital to combat climate change, yet\nturning awareness into intention and action remains elusive. We explore large\nlanguage models (LLMs) as tools to promote PEB, comparing their impact across\n3,200 participants: real humans (n=1,200), simulated humans based on actual\nparticipant data (n=1,200), and fully synthetic personas (n=1,200). All three\nparticipant groups faced personalized or standard chatbots, or static\nstatements, employing four persuasion strategies (moral foundations, future\nself-continuity, action orientation, or \"freestyle\" chosen by the LLM). Results\nreveal a \"synthetic persuasion paradox\": synthetic and simulated agents\nsignificantly affect their post-intervention PEB stance, while human responses\nbarely shift. Simulated participants better approximate human trends but still\noverestimate effects. This disconnect underscores LLM's potential for\npre-evaluating PEB interventions but warns of its limits in predicting\nreal-world behavior. We call for refined synthetic modeling and sustained and\nextended human trials to align conversational AI's promise with tangible\nsustainability outcomes.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "17 pages, 13 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2503.02067v1",
    "published_date": "2025-03-03 21:40:55 UTC",
    "updated_date": "2025-03-03 21:40:55 UTC"
  },
  {
    "arxiv_id": "2503.02065v1",
    "title": "Survey Perspective: The Role of Explainable AI in Threat Intelligence",
    "authors": [
      "Nidhi Rastogi",
      "Devang Dhanuka",
      "Amulya Saxena",
      "Pranjal Mairal",
      "Le Nguyen"
    ],
    "abstract": "The increasing reliance on AI-based security tools in Security Operations\nCenters (SOCs) has transformed threat detection and response, yet analysts\nfrequently struggle with alert overload, false positives, and lack of\ncontextual relevance. The inability to effectively analyze AI-generated\nsecurity alerts lead to inefficiencies in incident response and reduces trust\nin automated decision-making. In this paper, we show results and analysis of\nour investigation of how SOC analysts navigate AI-based alerts, their\nchallenges with current security tools, and how explainability (XAI) integrated\ninto their security workflows has the potential to become an effective decision\nsupport. In this vein, we conducted an industry survey. Using the survey\nresponses, we analyze how security analysts' process, retrieve, and prioritize\nalerts. Our findings indicate that most analysts have not yet adopted\nXAI-integrated tools, but they express high interest in attack attribution,\nconfidence scores, and feature contribution explanations to improve\ninterpretability, and triage efficiency. Based on our findings, we also propose\npractical design recommendations for XAI-enhanced security alert systems,\nenabling AI-based cybersecurity solutions to be more transparent,\ninterpretable, and actionable.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CR",
    "comment": "5 pages, SIGIR Symposium on IR in Practice (SIRIP), 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.02065v1",
    "published_date": "2025-03-03 21:39:15 UTC",
    "updated_date": "2025-03-03 21:39:15 UTC"
  },
  {
    "arxiv_id": "2503.02057v1",
    "title": "Hebbian learning the local structure of language",
    "authors": [
      "P. Myles Eugenio"
    ],
    "abstract": "Learning in the brain is local and unsupervised (Hebbian). We derive the\nfoundations of an effective human language model inspired by these microscopic\nconstraints. It has two parts: (1) a hierarchy of neurons which learns to\ntokenize words from text (whichiswhatyoudowhenyoureadthis); and (2) additional\nneurons which bind the learned symanticless patterns of the tokenizer into a\nsymanticful token (an embedding). The model permits continuous parallel\nlearning without forgetting; and is a powerful tokenizer which performs\nrenormalization group. This allows it to exploit redundancy, such that it\ngenerates tokens which are always decomposable into a basis set (e.g an\nalphabet), and can mix features learned from multiple languages. We find that\nthe structure of this model allows it to learn a natural language morphology\nWITHOUT data. The language data generated by this model predicts the correct\ndistribution of word-forming patterns observed in real languages, and further\ndemonstrates why microscopically human speech is broken up into words. This\nmodel provides the basis for understanding the microscopic origins of language\nand human creativity.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "cs.CL",
    "comment": "10 figures, 14 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.02057v1",
    "published_date": "2025-03-03 21:15:57 UTC",
    "updated_date": "2025-03-03 21:15:57 UTC"
  },
  {
    "arxiv_id": "2503.02053v1",
    "title": "EPEE: Towards Efficient and Effective Foundation Models in Biomedicine",
    "authors": [
      "Zaifu Zhan",
      "Shuang Zhou",
      "Huixue Zhou",
      "Zirui Liu",
      "Rui Zhang"
    ],
    "abstract": "Foundation models, including language models, e.g., GPT, and vision models,\ne.g., CLIP, have significantly advanced numerous biomedical tasks. Despite\nthese advancements, the high inference latency and the \"overthinking\" issues in\nmodel inference impair the efficiency and effectiveness of foundation models,\nthus limiting their application in real-time clinical settings. To address\nthese challenges, we proposed EPEE (Entropy- and Patience-based Early Exiting),\na novel hybrid strategy designed to improve the inference efficiency of\nfoundation models. The core idea was to leverage the strengths of entropy-based\nand patience-based early exiting methods to overcome their respective\nweaknesses. To evaluate EPEE, we conducted experiments on three core biomedical\ntasks-classification, relation extraction, and event extraction-using four\nfoundation models (BERT, ALBERT, GPT-2, and ViT) across twelve datasets,\nincluding clinical notes and medical images. The results showed that EPEE\nsignificantly reduced inference time while maintaining or improving accuracy,\ndemonstrating its adaptability to diverse datasets and tasks. EPEE addressed\ncritical barriers to deploying foundation models in healthcare by balancing\nefficiency and effectiveness. It potentially provided a practical solution for\nreal-time clinical decision-making with foundation models, supporting reliable\nand efficient workflows.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "Submitted to npj Digital Medicine",
    "pdf_url": "http://arxiv.org/pdf/2503.02053v1",
    "published_date": "2025-03-03 21:11:13 UTC",
    "updated_date": "2025-03-03 21:11:13 UTC"
  },
  {
    "arxiv_id": "2503.02048v1",
    "title": "FRMD: Fast Robot Motion Diffusion with Consistency-Distilled Movement Primitives for Smooth Action Generation",
    "authors": [
      "Xirui Shi",
      "Jun Jin"
    ],
    "abstract": "We consider the problem of using diffusion models to generate fast, smooth,\nand temporally consistent robot motions. Although diffusion models have\ndemonstrated superior performance in robot learning due to their task\nscalability and multi-modal flexibility, they suffer from two fundamental\nlimitations: (1) they often produce non-smooth, jerky motions due to their\ninability to capture temporally consistent movement dynamics, and (2) their\niterative sampling process incurs prohibitive latency for many robotic tasks.\nInspired by classic robot motion generation methods such as DMPs and ProMPs,\nwhich capture temporally and spatially consistent dynamic of trajectories using\nlow-dimensional vectors -- and by recent advances in diffusion-based image\ngeneration that use consistency models with probability flow ODEs to accelerate\nthe denoising process, we propose Fast Robot Motion Diffusion (FRMD). FRMD\nuniquely integrates Movement Primitives (MPs) with Consistency Models to enable\nefficient, single-step trajectory generation. By leveraging probabilistic flow\nODEs and consistency distillation, our method models trajectory distributions\nwhile learning a compact, time-continuous motion representation within an\nencoder-decoder architecture. This unified approach eliminates the slow,\nmulti-step denoising process of conventional diffusion models, enabling\nefficient one-step inference and smooth robot motion generation. We extensively\nevaluated our FRMD on the well-recognized Meta-World and ManiSkills Benchmarks,\nranging from simple to more complex manipulation tasks, comparing its\nperformance against state-of-the-art baselines. Our results show that FRMD\ngenerates significantly faster, smoother trajectories while achieving higher\nsuccess rates.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "arXiv admin note: text overlap with arXiv:2406.01586 by other authors",
    "pdf_url": "http://arxiv.org/pdf/2503.02048v1",
    "published_date": "2025-03-03 20:56:39 UTC",
    "updated_date": "2025-03-03 20:56:39 UTC"
  },
  {
    "arxiv_id": "2503.02039v1",
    "title": "Dynamic Search for Inference-Time Alignment in Diffusion Models",
    "authors": [
      "Xiner Li",
      "Masatoshi Uehara",
      "Xingyu Su",
      "Gabriele Scalia",
      "Tommaso Biancalani",
      "Aviv Regev",
      "Sergey Levine",
      "Shuiwang Ji"
    ],
    "abstract": "Diffusion models have shown promising generative capabilities across diverse\ndomains, yet aligning their outputs with desired reward functions remains a\nchallenge, particularly in cases where reward functions are non-differentiable.\nSome gradient-free guidance methods have been developed, but they often\nstruggle to achieve optimal inference-time alignment. In this work, we newly\nframe inference-time alignment in diffusion as a search problem and propose\nDynamic Search for Diffusion (DSearch), which subsamples from denoising\nprocesses and approximates intermediate node rewards. It also dynamically\nadjusts beam width and tree expansion to efficiently explore high-reward\ngenerations. To refine intermediate decisions, DSearch incorporates adaptive\nscheduling based on noise levels and a lookahead heuristic function. We\nvalidate DSearch across multiple domains, including biological sequence design,\nmolecular optimization, and image generation, demonstrating superior reward\noptimization compared to existing approaches.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.02039v1",
    "published_date": "2025-03-03 20:32:05 UTC",
    "updated_date": "2025-03-03 20:32:05 UTC"
  },
  {
    "arxiv_id": "2503.05803v1",
    "title": "Federated Learning Framework via Distributed Mutual Learning",
    "authors": [
      "Yash Gupta"
    ],
    "abstract": "Federated Learning often relies on sharing full or partial model weights,\nwhich can burden network bandwidth and raise privacy risks. We present a\nloss-based alternative using distributed mutual learning. Instead of\ntransmitting weights, clients periodically share their loss predictions on a\npublic test set. Each client then refines its model by combining its local loss\nwith the average Kullback-Leibler divergence over losses from other clients.\nThis collaborative approach both reduces transmission overhead and preserves\ndata privacy. Experiments on a face mask detection task demonstrate that our\nmethod outperforms weight-sharing baselines, achieving higher accuracy on\nunseen data while providing stronger generalization and privacy benefits.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.05803v1",
    "published_date": "2025-03-03 20:15:32 UTC",
    "updated_date": "2025-03-03 20:15:32 UTC"
  },
  {
    "arxiv_id": "2503.02034v1",
    "title": "Abn-BLIP: Abnormality-aligned Bootstrapping Language-Image Pre-training for Pulmonary Embolism Diagnosis and Report Generation from CTPA",
    "authors": [
      "Zhusi Zhong",
      "Yuli Wang",
      "Lulu Bi",
      "Zhuoqi Ma",
      "Sun Ho Ahn",
      "Christopher J. Mullin",
      "Colin F. Greineder",
      "Michael K. Atalay",
      "Scott Collins",
      "Grayson L. Baird",
      "Cheng Ting Lin",
      "Webster Stayman",
      "Todd M. Kolb",
      "Ihab Kamel",
      "Harrison X. Bai",
      "Zhicheng Jiao"
    ],
    "abstract": "Medical imaging plays a pivotal role in modern healthcare, with computed\ntomography pulmonary angiography (CTPA) being a critical tool for diagnosing\npulmonary embolism and other thoracic conditions. However, the complexity of\ninterpreting CTPA scans and generating accurate radiology reports remains a\nsignificant challenge. This paper introduces Abn-BLIP (Abnormality-aligned\nBootstrapping Language-Image Pretraining), an advanced diagnosis model designed\nto align abnormal findings to generate the accuracy and comprehensiveness of\nradiology reports. By leveraging learnable queries and cross-modal attention\nmechanisms, our model demonstrates superior performance in detecting\nabnormalities, reducing missed findings, and generating structured reports\ncompared to existing methods. Our experiments show that Abn-BLIP outperforms\nstate-of-the-art medical vision-language models and 3D report generation\nmethods in both accuracy and clinical relevance. These results highlight the\npotential of integrating multimodal learning strategies for improving radiology\nreporting. The source code is available at https://github.com/zzs95/abn-blip.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.02034v1",
    "published_date": "2025-03-03 20:13:39 UTC",
    "updated_date": "2025-03-03 20:13:39 UTC"
  },
  {
    "arxiv_id": "2503.02032v1",
    "title": "Comparative Analysis of OpenAI GPT-4o and DeepSeek R1 for Scientific Text Categorization Using Prompt Engineering",
    "authors": [
      "Aniruddha Maiti",
      "Samuel Adewumi",
      "Temesgen Alemayehu Tikure",
      "Zichun Wang",
      "Niladri Sengupta",
      "Anastasiia Sukhanova",
      "Ananya Jana"
    ],
    "abstract": "This study examines how large language models categorize sentences from\nscientific papers using prompt engineering. We use two advanced web-based\nmodels, GPT-4o (by OpenAI) and DeepSeek R1, to classify sentences into\npredefined relationship categories. DeepSeek R1 has been tested on benchmark\ndatasets in its technical report. However, its performance in scientific text\ncategorization remains unexplored. To address this gap, we introduce a new\nevaluation method designed specifically for this task. We also compile a\ndataset of cleaned scientific papers from diverse domains. This dataset\nprovides a platform for comparing the two models. Using this dataset, we\nanalyze their effectiveness and consistency in categorization.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ASEE North Central Section 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.02032v1",
    "published_date": "2025-03-03 20:09:35 UTC",
    "updated_date": "2025-03-03 20:09:35 UTC"
  },
  {
    "arxiv_id": "2503.02016v1",
    "title": "Mind the (Belief) Gap: Group Identity in the World of LLMs",
    "authors": [
      "Angana Borah",
      "Marwa Houalla",
      "Rada Mihalcea"
    ],
    "abstract": "Social biases and belief-driven behaviors can significantly impact Large\nLanguage Models (LLMs) decisions on several tasks. As LLMs are increasingly\nused in multi-agent systems for societal simulations, their ability to model\nfundamental group psychological characteristics remains critical yet\nunder-explored. In this study, we present a multi-agent framework that\nsimulates belief congruence, a classical group psychology theory that plays a\ncrucial role in shaping societal interactions and preferences. Our findings\nreveal that LLMs exhibit amplified belief congruence compared to humans, across\ndiverse contexts. We further investigate the implications of this behavior on\ntwo downstream tasks: (1) misinformation dissemination and (2) LLM learning,\nfinding that belief congruence in LLMs increases misinformation dissemination\nand impedes learning. To mitigate these negative impacts, we propose strategies\ninspired by: (1) contact hypothesis, (2) accuracy nudges, and (3) global\ncitizenship framework. Our results show that the best strategies reduce\nmisinformation dissemination by up to 37% and enhance learning by 11%. Bridging\nsocial psychology and AI, our work provides insights to navigate real-world\ninteractions using LLMs while addressing belief-driven biases.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.02016v1",
    "published_date": "2025-03-03 19:50:52 UTC",
    "updated_date": "2025-03-03 19:50:52 UTC"
  },
  {
    "arxiv_id": "2503.02012v2",
    "title": "Pretrained Embeddings as a Behavior Specification Mechanism",
    "authors": [
      "Parv Kapoor",
      "Abigail Hammer",
      "Ashish Kapoor",
      "Karen Leung",
      "Eunsuk Kang"
    ],
    "abstract": "We propose an approach to formally specifying the behavioral properties of\nsystems that rely on a perception model for interactions with the physical\nworld. The key idea is to introduce embeddings -- mathematical representations\nof a real-world concept -- as a first-class construct in a specification\nlanguage, where properties are expressed in terms of distances between a pair\nof ideal and observed embeddings. To realize this approach, we propose a new\ntype of temporal logic called Embedding Temporal Logic (ETL), and describe how\nit can be used to express a wider range of properties about AI-enabled systems\nthan previously possible. We demonstrate the applicability of ETL through a\npreliminary evaluation involving planning tasks in robots that are driven by\nfoundation models; the results are promising, showing that embedding-based\nspecifications can be used to steer a system towards desirable behaviors.",
    "categories": [
      "cs.AI",
      "cs.RO",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "18 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.02012v2",
    "published_date": "2025-03-03 19:41:22 UTC",
    "updated_date": "2025-03-06 14:32:23 UTC"
  },
  {
    "arxiv_id": "2503.02007v1",
    "title": "TactStyle: Generating Tactile Textures with Generative AI for Digital Fabrication",
    "authors": [
      "Faraz Faruqi",
      "Maxine Perroni-Scharf",
      "Jaskaran Singh Walia",
      "Yunyi Zhu",
      "Shuyue Feng",
      "Donald Degraen",
      "Stefanie Mueller"
    ],
    "abstract": "Recent work in Generative AI enables the stylization of 3D models based on\nimage prompts. However, these methods do not incorporate tactile information,\nleading to designs that lack the expected tactile properties. We present\nTactStyle, a system that allows creators to stylize 3D models with images while\nincorporating the expected tactile properties. TactStyle accomplishes this\nusing a modified image-generation model fine-tuned to generate heightfields for\ngiven surface textures. By optimizing 3D model surfaces to embody a generated\ntexture, TactStyle creates models that match the desired style and replicate\nthe tactile experience. We utilize a large-scale dataset of textures to train\nour texture generation model. In a psychophysical experiment, we evaluate the\ntactile qualities of a set of 3D-printed original textures and TactStyle's\ngenerated textures. Our results show that TactStyle successfully generates a\nwide range of tactile features from a single image input, enabling a novel\napproach to haptic design.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.02007v1",
    "published_date": "2025-03-03 19:29:27 UTC",
    "updated_date": "2025-03-03 19:29:27 UTC"
  },
  {
    "arxiv_id": "2503.05802v1",
    "title": "Illuminant and light direction estimation using Wasserstein distance method",
    "authors": [
      "Selcuk Yazar"
    ],
    "abstract": "Illumination estimation remains a pivotal challenge in image processing,\nparticularly for robotics, where robust environmental perception is essential\nunder varying lighting conditions. Traditional approaches, such as RGB\nhistograms and GIST descriptors, often fail in complex scenarios due to their\nsensitivity to illumination changes. This study introduces a novel method\nutilizing the Wasserstein distance, rooted in optimal transport theory, to\nestimate illuminant and light direction in images. Experiments on diverse\nimages indoor scenes, black-and-white photographs, and night images demonstrate\nthe method's efficacy in detecting dominant light sources and estimating their\ndirections, outperforming traditional statistical methods in complex lighting\nenvironments. The approach shows promise for applications in light source\nlocalization, image quality assessment, and object detection enhancement.\nFuture research may explore adaptive thresholding and integrate gradient\nanalysis to enhance accuracy, offering a scalable solution for real-world\nillumination challenges in robotics and beyond.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.05802v1",
    "published_date": "2025-03-03 19:20:09 UTC",
    "updated_date": "2025-03-03 19:20:09 UTC"
  },
  {
    "arxiv_id": "2503.01986v1",
    "title": "Adaptively evaluating models with task elicitation",
    "authors": [
      "Davis Brown",
      "Prithvi Balehannina",
      "Helen Jin",
      "Shreya Havaldar",
      "Hamed Hassani",
      "Eric Wong"
    ],
    "abstract": "Manual curation of evaluation datasets is struggling to keep up with the\nrapidly expanding capabilities and deployment scenarios of language models.\nTowards scalable model profiling, we introduce and validate a framework for\nevaluating LLMs, called Adaptive Evaluations. Adaptive evaluations use\nscaffolded language models (evaluator agents) to search through a target\nmodel's behavior on a domain dataset and create difficult questions (tasks)\nthat can discover and probe the model's failure modes. We find that frontier\nmodels lack consistency when adaptively probed with our framework on a diverse\nsuite of datasets and tasks, including but not limited to legal reasoning,\nforecasting, and online harassment. Generated questions pass human validity\nchecks and often transfer to other models with different capability profiles,\ndemonstrating that adaptive evaluations can also be used to create difficult\ndomain-specific datasets.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01986v1",
    "published_date": "2025-03-03 19:04:10 UTC",
    "updated_date": "2025-03-03 19:04:10 UTC"
  },
  {
    "arxiv_id": "2503.01985v1",
    "title": "Proportionality in Thumbs Up and Down Voting",
    "authors": [
      "Sonja Kraiczy",
      "Georgios Papasotiropoulos",
      "Grzegorz Pierczyński",
      "Piotr Skowron"
    ],
    "abstract": "Consider the decision-making setting where agents elect a panel by expressing\nboth positive and negative preferences. Prominently, in constitutional AI,\ncitizens democratically select a slate of ethical preferences on which a\nfoundation model is to be trained. There, in practice, agents may both approve\nand disapprove of different ethical principles. Proportionality has been\nwell-studied in computational social choice for approval ballots, but its\nmeaning remains unclear when negative sentiments are also considered. In this\nwork, we propose two conceptually distinct approaches to interpret\nproportionality in the presence of up and down votes. The first approach treats\nthe satisfaction from electing candidates and the impact of vetoing them as\ncomparable, leading to combined proportionality guarantees. The second approach\nconsiders veto power separately, introducing guarantees distinct from\ntraditional proportionality. We formalize axioms for each perspective and\nexamine their satisfiability by suitable adaptations of Phragm\\'en's rule,\nProportional Approval Voting rule and the Method of Equal Shares.",
    "categories": [
      "cs.GT",
      "cs.AI"
    ],
    "primary_category": "cs.GT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01985v1",
    "published_date": "2025-03-03 19:02:37 UTC",
    "updated_date": "2025-03-03 19:02:37 UTC"
  },
  {
    "arxiv_id": "2503.01980v1",
    "title": "Recurrence-Enhanced Vision-and-Language Transformers for Robust Multimodal Document Retrieval",
    "authors": [
      "Davide Caffagni",
      "Sara Sarto",
      "Marcella Cornia",
      "Lorenzo Baraldi",
      "Rita Cucchiara"
    ],
    "abstract": "Cross-modal retrieval is gaining increasing efficacy and interest from the\nresearch community, thanks to large-scale training, novel architectural and\nlearning designs, and its application in LLMs and multimodal LLMs. In this\npaper, we move a step forward and design an approach that allows for multimodal\nqueries, composed of both an image and a text, and can search within\ncollections of multimodal documents, where images and text are interleaved. Our\nmodel, ReT, employs multi-level representations extracted from different layers\nof both visual and textual backbones, both at the query and document side. To\nallow for multi-level and cross-modal understanding and feature extraction, ReT\nemploys a novel Transformer-based recurrent cell that integrates both textual\nand visual features at different layers, and leverages sigmoidal gates inspired\nby the classical design of LSTMs. Extensive experiments on M2KR and M-BEIR\nbenchmarks show that ReT achieves state-of-the-art performance across diverse\nsettings. Our source code and trained models are publicly available at\nhttps://github.com/aimagelab/ReT.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.01980v1",
    "published_date": "2025-03-03 19:01:17 UTC",
    "updated_date": "2025-03-03 19:01:17 UTC"
  },
  {
    "arxiv_id": "2503.01839v1",
    "title": "Jailbreaking Safeguarded Text-to-Image Models via Large Language Models",
    "authors": [
      "Zhengyuan Jiang",
      "Yuepeng Hu",
      "Yuchen Yang",
      "Yinzhi Cao",
      "Neil Zhenqiang Gong"
    ],
    "abstract": "Text-to-Image models may generate harmful content, such as pornographic\nimages, particularly when unsafe prompts are submitted. To address this issue,\nsafety filters are often added on top of text-to-image models, or the models\nthemselves are aligned to reduce harmful outputs. However, these defenses\nremain vulnerable when an attacker strategically designs adversarial prompts to\nbypass these safety guardrails. In this work, we propose PromptTune, a method\nto jailbreak text-to-image models with safety guardrails using a fine-tuned\nlarge language model. Unlike other query-based jailbreak attacks that require\nrepeated queries to the target model, our attack generates adversarial prompts\nefficiently after fine-tuning our AttackLLM. We evaluate our method on three\ndatasets of unsafe prompts and against five safety guardrails. Our results\ndemonstrate that our approach effectively bypasses safety guardrails,\noutperforms existing no-box attacks, and also facilitates other query-based\nattacks.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01839v1",
    "published_date": "2025-03-03 18:58:46 UTC",
    "updated_date": "2025-03-03 18:58:46 UTC"
  },
  {
    "arxiv_id": "2503.01836v1",
    "title": "CrowdSelect: Synthetic Instruction Data Selection with Multi-LLM Wisdom",
    "authors": [
      "Yisen Li",
      "Lingfeng Yang",
      "Wenxuan Shen",
      "Pan Zhou",
      "Yao Wan",
      "Weiwei Lin",
      "Dongping Chen"
    ],
    "abstract": "Distilling advanced Large Language Models' instruction-following capabilities\ninto smaller models using a selected subset has become a mainstream approach in\nmodel training. While existing synthetic instruction data selection strategies\nrely mainly on single-dimensional signals (i.e., reward scores, model\nperplexity), they fail to capture the complexity of instruction-following\nacross diverse fields. Therefore, we investigate more diverse signals to\ncapture comprehensive instruction-response pair characteristics and propose\nthree foundational metrics that leverage Multi-LLM wisdom, informed by (1)\ndiverse LLM responses and (2) reward model assessment. Building upon base\nmetrics, we propose CrowdSelect, an integrated metric incorporating a\nclustering-based approach to maintain response diversity. Our comprehensive\nexperiments demonstrate that our foundation metrics consistently improve\nperformance across 4 base models on MT-bench and Arena-Hard. CrowdSelect,\nefficiently incorporating all metrics, achieves state-of-the-art performance in\nboth Full and LoRA fine-tuning, showing improvements of 4.81% on Arena-Hard and\n11.1% on MT-bench with Llama-3.2-3b-instruct. We hope our findings will bring\nvaluable insights for future research in this direction. Code are available at\nhttps://github.com/listentm/crowdselect.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01836v1",
    "published_date": "2025-03-03 18:56:44 UTC",
    "updated_date": "2025-03-03 18:56:44 UTC"
  },
  {
    "arxiv_id": "2503.01829v2",
    "title": "Persuade Me if You Can: A Framework for Evaluating Persuasion Effectiveness and Susceptibility Among Large Language Models",
    "authors": [
      "Nimet Beyza Bozdag",
      "Shuhaib Mehri",
      "Gokhan Tur",
      "Dilek Hakkani-Tür"
    ],
    "abstract": "Large Language Models (LLMs) demonstrate persuasive capabilities that rival\nhuman-level persuasion. While these capabilities can be used for social good,\nthey also present risks of potential misuse. Moreover, LLMs' susceptibility to\npersuasion raises concerns about alignment with ethical principles. To study\nthese dynamics, we introduce Persuade Me If You Can (PMIYC), an automated\nframework for evaluating persuasion through multi-agent interactions. Here,\nPersuader agents engage in multi-turn conversations with the Persuadee agents,\nallowing us to measure LLMs' persuasive effectiveness and their susceptibility\nto persuasion. We conduct comprehensive evaluations across diverse LLMs,\nensuring each model is assessed against others in both subjective and\nmisinformation contexts. We validate the efficacy of our framework through\nhuman evaluations and show alignment with prior work. PMIYC offers a scalable\nalternative to human annotation for studying persuasion in LLMs. Through PMIYC,\nwe find that Llama-3.3-70B and GPT-4o exhibit similar persuasive effectiveness,\noutperforming Claude 3 Haiku by 30%. However, GPT-4o demonstrates over 50%\ngreater resistance to persuasion for misinformation compared to Llama-3.3-70B.\nThese findings provide empirical insights into the persuasive dynamics of LLMs\nand contribute to the development of safer AI systems.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01829v2",
    "published_date": "2025-03-03 18:53:21 UTC",
    "updated_date": "2025-03-06 22:13:20 UTC"
  },
  {
    "arxiv_id": "2503.01822v1",
    "title": "Projecting Assumptions: The Duality Between Sparse Autoencoders and Concept Geometry",
    "authors": [
      "Sai Sumedh R. Hindupur",
      "Ekdeep Singh Lubana",
      "Thomas Fel",
      "Demba Ba"
    ],
    "abstract": "Sparse Autoencoders (SAEs) are widely used to interpret neural networks by\nidentifying meaningful concepts from their representations. However, do SAEs\ntruly uncover all concepts a model relies on, or are they inherently biased\ntoward certain kinds of concepts? We introduce a unified framework that recasts\nSAEs as solutions to a bilevel optimization problem, revealing a fundamental\nchallenge: each SAE imposes structural assumptions about how concepts are\nencoded in model representations, which in turn shapes what it can and cannot\ndetect. This means different SAEs are not interchangeable -- switching\narchitectures can expose entirely new concepts or obscure existing ones. To\nsystematically probe this effect, we evaluate SAEs across a spectrum of\nsettings: from controlled toy models that isolate key variables, to\nsemi-synthetic experiments on real model activations and finally to\nlarge-scale, naturalistic datasets. Across this progression, we examine two\nfundamental properties that real-world concepts often exhibit: heterogeneity in\nintrinsic dimensionality (some concepts are inherently low-dimensional, others\nare not) and nonlinear separability. We show that SAEs fail to recover concepts\nwhen these properties are ignored, and we design a new SAE that explicitly\nincorporates both, enabling the discovery of previously hidden concepts and\nreinforcing our theoretical insights. Our findings challenge the idea of a\nuniversal SAE and underscores the need for architecture-specific choices in\nmodel interpretability. Overall, we argue an SAE does not just reveal concepts\n-- it determines what can be seen at all.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2503.01822v1",
    "published_date": "2025-03-03 18:47:40 UTC",
    "updated_date": "2025-03-03 18:47:40 UTC"
  },
  {
    "arxiv_id": "2503.01820v1",
    "title": "RSQ: Learning from Important Tokens Leads to Better Quantized LLMs",
    "authors": [
      "Yi-Lin Sung",
      "Prateek Yadav",
      "Jialu Li",
      "Jaehong Yoon",
      "Mohit Bansal"
    ],
    "abstract": "Layer-wise quantization is a key technique for efficiently compressing large\nmodels without expensive retraining. Previous methods typically quantize the\nweights of each layer by \"uniformly\" optimizing the layer reconstruction loss\nacross all output tokens. However, in this paper, we demonstrate that\nbetter-quantized models can be obtained by prioritizing learning from important\ntokens (e.g. which have large attention scores). Building on this finding, we\npropose RSQ (Rotate, Scale, then Quantize), which (1) applies rotations\n(orthogonal transformation) to the model to mitigate outliers (those with\nexceptionally large magnitude), (2) scales the token feature based on its\nimportance, and (3) quantizes the model using the GPTQ framework with the\nsecond-order statistics computed by scaled tokens. To compute token importance,\nwe explore both heuristic and dynamic strategies. Based on a thorough analysis\nof all approaches, we adopt attention concentration, which uses attention\nscores of each token as its importance, as the best approach. We demonstrate\nthat RSQ consistently outperforms baseline methods across multiple downstream\ntasks and three model families: LLaMA3, Mistral, and Qwen2.5. Additionally,\nmodels quantized with RSQ achieve superior performance on long-context tasks,\nfurther highlighting its effectiveness. Lastly, RSQ demonstrates\ngeneralizability across various setups, including different model sizes,\ncalibration datasets, bit precisions, and quantization methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Our code is available at https://github.com/ylsung/rsq",
    "pdf_url": "http://arxiv.org/pdf/2503.01820v1",
    "published_date": "2025-03-03 18:46:33 UTC",
    "updated_date": "2025-03-03 18:46:33 UTC"
  },
  {
    "arxiv_id": "2503.01819v1",
    "title": "Do GFlowNets Transfer? Case Study on the Game of 24/42",
    "authors": [
      "Adesh Gupta",
      "Abhinav Kumar",
      "Mansi Gupta",
      "Paras Chopra"
    ],
    "abstract": "Generating diverse solutions is key to human-like reasoning, yet\nautoregressive language models focus on single accurate responses, limiting\ncreativity. GFlowNets optimize solution generation as a flow network, promising\ngreater diversity. Our case study shows their limited zero-shot transferability\nby fine-tuning small and medium-sized large language models on the Game of 24\nand testing them on the Game of 42 datasets. Results revealed that GFlowNets\nstruggle to maintain solution diversity and accuracy, highlighting key\nlimitations in their cross-task generalization and the need for future research\nin improved transfer learning capabilities.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01819v1",
    "published_date": "2025-03-03 18:43:25 UTC",
    "updated_date": "2025-03-03 18:43:25 UTC"
  },
  {
    "arxiv_id": "2503.01814v1",
    "title": "LLMInit: A Free Lunch from Large Language Models for Selective Initialization of Recommendation",
    "authors": [
      "Weizhi Zhang",
      "Liangwei Yang",
      "Wooseong Yang",
      "Henry Peng Zou",
      "Yuqing Liu",
      "Ke Xu",
      "Sourav Medya",
      "Philip S. Yu"
    ],
    "abstract": "Collaborative filtering models, particularly graph-based approaches, have\ndemonstrated strong performance in capturing user-item interactions for\nrecommendation systems. However, they continue to struggle in cold-start and\ndata-sparse scenarios. The emergence of large language models (LLMs) like GPT\nand LLaMA presents new possibilities for enhancing recommendation performance,\nespecially in cold-start settings. Despite their promise, LLMs pose challenges\nrelated to scalability and efficiency due to their high computational demands\nand limited ability to model complex user-item relationships effectively. In\nthis work, we introduce a novel perspective on leveraging LLMs for CF model\ninitialization. Through experiments, we uncover an embedding collapse issue\nwhen scaling CF models to larger embedding dimensions. To effectively harness\nlarge-scale LLM embeddings, we propose innovative selective initialization\nstrategies utilizing random, uniform, and variance-based index sampling. Our\ncomprehensive evaluation on multiple real-world datasets demonstrates\nsignificant performance gains across various CF models while maintaining a\nlower computational cost compared to existing LLM-based recommendation\napproaches.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01814v1",
    "published_date": "2025-03-03 18:41:59 UTC",
    "updated_date": "2025-03-03 18:41:59 UTC"
  },
  {
    "arxiv_id": "2503.01811v1",
    "title": "AutoAdvExBench: Benchmarking autonomous exploitation of adversarial example defenses",
    "authors": [
      "Nicholas Carlini",
      "Javier Rando",
      "Edoardo Debenedetti",
      "Milad Nasr",
      "Florian Tramèr"
    ],
    "abstract": "We introduce AutoAdvExBench, a benchmark to evaluate if large language models\n(LLMs) can autonomously exploit defenses to adversarial examples. Unlike\nexisting security benchmarks that often serve as proxies for real-world tasks,\nbench directly measures LLMs' success on tasks regularly performed by machine\nlearning security experts. This approach offers a significant advantage: if a\nLLM could solve the challenges presented in bench, it would immediately present\npractical utility for adversarial machine learning researchers. We then design\na strong agent that is capable of breaking 75% of CTF-like (\"homework\nexercise\") adversarial example defenses. However, we show that this agent is\nonly able to succeed on 13% of the real-world defenses in our benchmark,\nindicating the large gap between difficulty in attacking \"real\" code, and\nCTF-like code. In contrast, a stronger LLM that can attack 21% of real defenses\nonly succeeds on 54% of CTF-like defenses. We make this benchmark available at\nhttps://github.com/ethz-spylab/AutoAdvExBench.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01811v1",
    "published_date": "2025-03-03 18:39:48 UTC",
    "updated_date": "2025-03-03 18:39:48 UTC"
  },
  {
    "arxiv_id": "2503.01805v1",
    "title": "Depth-Width tradeoffs in Algorithmic Reasoning of Graph Tasks with Transformers",
    "authors": [
      "Gilad Yehudai",
      "Clayton Sanford",
      "Maya Bechler-Speicher",
      "Orr Fischer",
      "Ran Gilad-Bachrach",
      "Amir Globerson"
    ],
    "abstract": "Transformers have revolutionized the field of machine learning. In\nparticular, they can be used to solve complex algorithmic problems, including\ngraph-based tasks. In such algorithmic tasks a key question is what is the\nminimal size of a transformer that can implement a task. Recent work has begun\nto explore this problem for graph-based tasks, showing that for sub-linear\nembedding dimension (i.e., model width) logarithmic depth suffices. However, an\nopen question, which we address here, is what happens if width is allowed to\ngrow linearly. Here we analyze this setting, and provide the surprising result\nthat with linear width, constant depth suffices for solving a host of\ngraph-based problems. This suggests that a moderate increase in width can allow\nmuch shallower models, which are advantageous in terms of inference time. For\nother problems, we show that quadratic width is required. Our results\ndemonstrate the complex and intriguing landscape of transformer implementations\nof graph-based algorithms. We support our theoretical results with empirical\nevaluations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01805v1",
    "published_date": "2025-03-03 18:33:58 UTC",
    "updated_date": "2025-03-03 18:33:58 UTC"
  },
  {
    "arxiv_id": "2503.01804v2",
    "title": "$\\texttt{SEM-CTRL}$: Semantically Controlled Decoding",
    "authors": [
      "Mohammad Albinhassan",
      "Pranava Madhyastha",
      "Alessandra Russo"
    ],
    "abstract": "Ensuring both syntactic and semantic correctness in Large Language Model\n(LLM) outputs remains a significant challenge, despite being critical for\nreal-world deployment. In this paper, we introduce $\\texttt{SEM-CTRL}$, a\nunified approach that enforces rich context-sensitive constraints and task- and\ninstance-specific semantics directly on an LLM decoder. Our approach integrates\ntoken-level MCTS, which is guided by specific syntactic and semantic\nconstraints. The constraints over the desired outputs are expressed using\nAnswer Set Grammars -- a logic-based formalism that generalizes\ncontext-sensitive grammars while incorporating background knowledge to\nrepresent task-specific semantics. We show that our approach guarantees correct\ncompletions for any off-the-shelf LLM without the need for fine-tuning. We\nevaluate $\\texttt{SEM-CTRL}$ on a range of tasks, including synthetic grammar\nsynthesis, combinatorial reasoning, and planning. Our results demonstrate that\n$\\texttt{SEM-CTRL}$ allows small pre-trained LLMs to efficiently outperform\nlarger variants and state-of-the-art reasoning models (e.g., o1-preview) while\nsimultaneously guaranteeing solution correctness.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01804v2",
    "published_date": "2025-03-03 18:33:46 UTC",
    "updated_date": "2025-03-06 16:07:43 UTC"
  },
  {
    "arxiv_id": "2503.01792v1",
    "title": "Generating Counterfactual Explanations Under Temporal Constraints",
    "authors": [
      "Andrei Buliga",
      "Chiara Di Francescomarino",
      "Chiara Ghidini",
      "Marco Montali",
      "Massimiliano Ronzani"
    ],
    "abstract": "Counterfactual explanations are one of the prominent eXplainable Artificial\nIntelligence (XAI) techniques, and suggest changes to input data that could\nalter predictions, leading to more favourable outcomes. Existing counterfactual\nmethods do not readily apply to temporal domains, such as that of process\nmining, where data take the form of traces of activities that must obey to\ntemporal background knowledge expressing which dynamics are possible and which\nnot. Specifically, counterfactuals generated off-the-shelf may violate the\nbackground knowledge, leading to inconsistent explanations. This work tackles\nthis challenge by introducing a novel approach for generating temporally\nconstrained counterfactuals, guaranteed to comply by design with background\nknowledge expressed in Linear Temporal Logic on process traces (LTLp). We do so\nby infusing automata-theoretic techniques for LTLp inside a genetic algorithm\nfor counterfactual generation. The empirical evaluation shows that the\ngenerated counterfactuals are temporally meaningful and more interpretable for\napplications involving temporal dependencies.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.01792v1",
    "published_date": "2025-03-03 18:22:48 UTC",
    "updated_date": "2025-03-03 18:22:48 UTC"
  },
  {
    "arxiv_id": "2503.09613v1",
    "title": "Empowering the Future Workforce: Prioritizing Education for the AI-Accelerated Job Market",
    "authors": [
      "Lisa Amini",
      "Henry F. Korth",
      "Nita Patel",
      "Evan Peck",
      "Ben Zorn"
    ],
    "abstract": "AI's rapid integration into the workplace demands new approaches to workforce\neducation and training and broader AI literacy across disciplines. Coordinated\naction from government, industry, and educational institutions is necessary to\nensure workers can adapt to accelerating technological change.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.09613v1",
    "published_date": "2025-03-03 18:15:45 UTC",
    "updated_date": "2025-03-03 18:15:45 UTC"
  },
  {
    "arxiv_id": "2503.01776v2",
    "title": "Beyond Matryoshka: Revisiting Sparse Coding for Adaptive Representation",
    "authors": [
      "Tiansheng Wen",
      "Yifei Wang",
      "Zequn Zeng",
      "Zhong Peng",
      "Yudi Su",
      "Xinyang Liu",
      "Bo Chen",
      "Hongwei Liu",
      "Stefanie Jegelka",
      "Chenyu You"
    ],
    "abstract": "Many large-scale systems rely on high-quality deep representations\n(embeddings) to facilitate tasks like retrieval, search, and generative\nmodeling. Matryoshka Representation Learning (MRL) recently emerged as a\nsolution for adaptive embedding lengths, but it requires full model retraining\nand suffers from noticeable performance degradations at short lengths. In this\npaper, we show that sparse coding offers a compelling alternative for achieving\nadaptive representation with minimal overhead and higher fidelity. We propose\nContrastive Sparse Representation (CSR), a method that sparsifies pre-trained\nembeddings into a high-dimensional but selectively activated feature space. By\nleveraging lightweight autoencoding and task-aware contrastive objectives, CSR\npreserves semantic quality while allowing flexible, cost-effective inference at\ndifferent sparsity levels. Extensive experiments on image, text, and multimodal\nbenchmarks demonstrate that CSR consistently outperforms MRL in terms of both\naccuracy and retrieval speed-often by large margins-while also cutting training\ntime to a fraction of that required by MRL. Our results establish sparse coding\nas a powerful paradigm for adaptive representation learning in real-world\napplications where efficiency and fidelity are both paramount. Code is\navailable at https://github.com/neilwen987/CSR_Adaptive_Rep",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.IR"
    ],
    "primary_category": "cs.LG",
    "comment": "A novel sparse coding framework designed for learning adaptive\n  representation",
    "pdf_url": "http://arxiv.org/pdf/2503.01776v2",
    "published_date": "2025-03-03 17:59:48 UTC",
    "updated_date": "2025-03-05 17:51:09 UTC"
  },
  {
    "arxiv_id": "2503.01763v1",
    "title": "Retrieval Models Aren't Tool-Savvy: Benchmarking Tool Retrieval for Large Language Models",
    "authors": [
      "Zhengliang Shi",
      "Yuhan Wang",
      "Lingyong Yan",
      "Pengjie Ren",
      "Shuaiqiang Wang",
      "Dawei Yin",
      "Zhaochun Ren"
    ],
    "abstract": "Tool learning aims to augment large language models (LLMs) with diverse\ntools, enabling them to act as agents for solving practical tasks. Due to the\nlimited context length of tool-using LLMs, adopting information retrieval (IR)\nmodels to select useful tools from large toolsets is a critical initial step.\nHowever, the performance of IR models in tool retrieval tasks remains\nunderexplored and unclear. Most tool-use benchmarks simplify this step by\nmanually pre-annotating a small set of relevant tools for each task, which is\nfar from the real-world scenarios. In this paper, we propose ToolRet, a\nheterogeneous tool retrieval benchmark comprising 7.6k diverse retrieval tasks,\nand a corpus of 43k tools, collected from existing datasets. We benchmark six\ntypes of models on ToolRet. Surprisingly, even the models with strong\nperformance in conventional IR benchmarks, exhibit poor performance on ToolRet.\nThis low retrieval quality degrades the task pass rate of tool-use LLMs. As a\nfurther step, we contribute a large-scale training dataset with over 200k\ninstances, which substantially optimizes the tool retrieval ability of IR\nmodels.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01763v1",
    "published_date": "2025-03-03 17:37:16 UTC",
    "updated_date": "2025-03-03 17:37:16 UTC"
  },
  {
    "arxiv_id": "2503.01758v1",
    "title": "Zero-Trust Artificial Intelligence Model Security Based on Moving Target Defense and Content Disarm and Reconstruction",
    "authors": [
      "Daniel Gilkarov",
      "Ran Dubin"
    ],
    "abstract": "This paper examines the challenges in distributing AI models through model\nzoos and file transfer mechanisms. Despite advancements in security measures,\nvulnerabilities persist, necessitating a multi-layered approach to mitigate\nrisks effectively. The physical security of model files is critical, requiring\nstringent access controls and attack prevention solutions. This paper proposes\na novel solution architecture composed of two prevention approaches. The first\nis Content Disarm and Reconstruction (CDR), which focuses on disarming\nserialization attacks that enable attackers to run malicious code as soon as\nthe model is loaded. The second is protecting the model architecture and\nweights from attacks by using Moving Target Defense (MTD), alerting the model\nstructure, and providing verification steps to detect such attacks. The paper\nfocuses on the highly exploitable Pickle and PyTorch file formats. It\ndemonstrates a 100% disarm rate while validated against known AI model\nrepositories and actual malware attacks from the HuggingFace model zoo.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01758v1",
    "published_date": "2025-03-03 17:32:19 UTC",
    "updated_date": "2025-03-03 17:32:19 UTC"
  },
  {
    "arxiv_id": "2503.01751v1",
    "title": "SAKE: Steering Activations for Knowledge Editing",
    "authors": [
      "Marco Scialanga",
      "Thibault Laugel",
      "Vincent Grari",
      "Marcin Detyniecki"
    ],
    "abstract": "As Large Langue Models have been shown to memorize real-world facts, the need\nto update this knowledge in a controlled and efficient manner arises. Designed\nwith these constraints in mind, Knowledge Editing (KE) approaches propose to\nalter specific facts in pretrained models. However, they have been shown to\nsuffer from several limitations, including their lack of contextual robustness\nand their failure to generalize to logical implications related to the fact. To\novercome these issues, we propose SAKE, a steering activation method that\nmodels a fact to be edited as a distribution rather than a single prompt.\nLeveraging Optimal Transport, SAKE alters the LLM behavior over a whole\nfact-related distribution, defined as paraphrases and logical implications.\nSeveral numerical experiments demonstrate the effectiveness of this method:\nSAKE is thus able to perform more robust edits than its existing counterparts.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01751v1",
    "published_date": "2025-03-03 17:20:29 UTC",
    "updated_date": "2025-03-03 17:20:29 UTC"
  },
  {
    "arxiv_id": "2503.01747v2",
    "title": "Position: Don't use the CLT in LLM evals with fewer than a few hundred datapoints",
    "authors": [
      "Sam Bowyer",
      "Laurence Aitchison",
      "Desi R. Ivanova"
    ],
    "abstract": "Rigorous statistical evaluations of large language models (LLMs), including\nvalid error bars and significance testing, are essential for meaningful and\nreliable performance assessment. Currently, when such statistical measures are\nreported, they typically rely on the Central Limit Theorem (CLT). In this\nposition paper, we argue that while CLT-based methods for uncertainty\nquantification are appropriate when benchmarks consist of thousands of\nexamples, they fail to provide adequate uncertainty estimates for LLM\nevaluations that rely on smaller, highly specialized benchmarks. In these\nsmall-data settings, we demonstrate that CLT-based methods perform very poorly,\nusually dramatically underestimating uncertainty (i.e. producing error bars\nthat are too small). We give recommendations for alternative frequentist and\nBayesian methods that are both easy to implement and more appropriate in these\nincreasingly common scenarios. We provide a simple Python library for these\nBayesian methods at https://github.com/sambowyer/bayes_evals .",
    "categories": [
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.AI",
    "comment": "36 pages, 37 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.01747v2",
    "published_date": "2025-03-03 17:15:17 UTC",
    "updated_date": "2025-03-04 11:30:30 UTC"
  },
  {
    "arxiv_id": "2503.01743v2",
    "title": "Phi-4-Mini Technical Report: Compact yet Powerful Multimodal Language Models via Mixture-of-LoRAs",
    "authors": [
      "Microsoft",
      ":",
      "Abdelrahman Abouelenin",
      "Atabak Ashfaq",
      "Adam Atkinson",
      "Hany Awadalla",
      "Nguyen Bach",
      "Jianmin Bao",
      "Alon Benhaim",
      "Martin Cai",
      "Vishrav Chaudhary",
      "Congcong Chen",
      "Dong Chen",
      "Dongdong Chen",
      "Junkun Chen",
      "Weizhu Chen",
      "Yen-Chun Chen",
      "Yi-ling Chen",
      "Qi Dai",
      "Xiyang Dai",
      "Ruchao Fan",
      "Mei Gao",
      "Min Gao",
      "Amit Garg",
      "Abhishek Goswami",
      "Junheng Hao",
      "Amr Hendy",
      "Yuxuan Hu",
      "Xin Jin",
      "Mahmoud Khademi",
      "Dongwoo Kim",
      "Young Jin Kim",
      "Gina Lee",
      "Jinyu Li",
      "Yunsheng Li",
      "Chen Liang",
      "Xihui Lin",
      "Zeqi Lin",
      "Mengchen Liu",
      "Yang Liu",
      "Gilsinia Lopez",
      "Chong Luo",
      "Piyush Madan",
      "Vadim Mazalov",
      "Arindam Mitra",
      "Ali Mousavi",
      "Anh Nguyen",
      "Jing Pan",
      "Daniel Perez-Becker",
      "Jacob Platin",
      "Thomas Portet",
      "Kai Qiu",
      "Bo Ren",
      "Liliang Ren",
      "Sambuddha Roy",
      "Ning Shang",
      "Yelong Shen",
      "Saksham Singhal",
      "Subhojit Som",
      "Xia Song",
      "Tetyana Sych",
      "Praneetha Vaddamanu",
      "Shuohang Wang",
      "Yiming Wang",
      "Zhenghao Wang",
      "Haibin Wu",
      "Haoran Xu",
      "Weijian Xu",
      "Yifan Yang",
      "Ziyi Yang",
      "Donghan Yu",
      "Ishmam Zabir",
      "Jianwen Zhang",
      "Li Lyna Zhang",
      "Yunan Zhang",
      "Xiren Zhou"
    ],
    "abstract": "We introduce Phi-4-Mini and Phi-4-Multimodal, compact yet highly capable\nlanguage and multimodal models. Phi-4-Mini is a 3.8-billion-parameter language\nmodel trained on high-quality web and synthetic data, significantly\noutperforming recent open-source models of similar size and matching the\nperformance of models twice its size on math and coding tasks requiring complex\nreasoning. This achievement is driven by a carefully curated synthetic data\nrecipe emphasizing high-quality math and coding datasets. Compared to its\npredecessor, Phi-3.5-Mini, Phi-4-Mini features an expanded vocabulary size of\n200K tokens to better support multilingual applications, as well as group query\nattention for more efficient long-sequence generation. Phi-4-Multimodal is a\nmultimodal model that integrates text, vision, and speech/audio input\nmodalities into a single model. Its novel modality extension approach leverages\nLoRA adapters and modality-specific routers to allow multiple inference modes\ncombining various modalities without interference. For example, it now ranks\nfirst in the OpenASR leaderboard to date, although the LoRA component of the\nspeech/audio modality has just 460 million parameters. Phi-4-Multimodal\nsupports scenarios involving (vision + language), (vision + speech), and\n(speech/audio) inputs, outperforming larger vision-language and speech-language\nmodels on a wide range of tasks. Additionally, we experiment to further train\nPhi-4-Mini to enhance its reasoning capabilities. Despite its compact\n3.8-billion-parameter size, this experimental version achieves reasoning\nperformance on par with or surpassing significantly larger models, including\nDeepSeek-R1-Distill-Qwen-7B and DeepSeek-R1-Distill-Llama-8B.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "39 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.01743v2",
    "published_date": "2025-03-03 17:05:52 UTC",
    "updated_date": "2025-03-07 09:05:58 UTC"
  },
  {
    "arxiv_id": "2503.01734v1",
    "title": "Adversarial Agents: Black-Box Evasion Attacks with Reinforcement Learning",
    "authors": [
      "Kyle Domico",
      "Jean-Charles Noirot Ferrand",
      "Ryan Sheatsley",
      "Eric Pauley",
      "Josiah Hanna",
      "Patrick McDaniel"
    ],
    "abstract": "Reinforcement learning (RL) offers powerful techniques for solving complex\nsequential decision-making tasks from experience. In this paper, we demonstrate\nhow RL can be applied to adversarial machine learning (AML) to develop a new\nclass of attacks that learn to generate adversarial examples: inputs designed\nto fool machine learning models. Unlike traditional AML methods that craft\nadversarial examples independently, our RL-based approach retains and exploits\npast attack experience to improve future attacks. We formulate adversarial\nexample generation as a Markov Decision Process and evaluate RL's ability to\n(a) learn effective and efficient attack strategies and (b) compete with\nstate-of-the-art AML. On CIFAR-10, our agent increases the success rate of\nadversarial examples by 19.4% and decreases the median number of victim model\nqueries per adversarial example by 53.2% from the start to the end of training.\nIn a head-to-head comparison with a state-of-the-art image attack,\nSquareAttack, our approach enables an adversary to generate adversarial\nexamples with 13.1% more success after 5000 episodes of training. From a\nsecurity perspective, this work demonstrates a powerful new attack vector that\nuses RL to attack ML models efficiently and at scale.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01734v1",
    "published_date": "2025-03-03 16:54:03 UTC",
    "updated_date": "2025-03-03 16:54:03 UTC"
  },
  {
    "arxiv_id": "2503.01722v1",
    "title": "Learning Exposure Mapping Functions for Inferring Heterogeneous Peer Effects",
    "authors": [
      "Shishir Adhikari",
      "Sourav Medya",
      "Elena Zheleva"
    ],
    "abstract": "In causal inference, interference refers to the phenomenon in which the\nactions of peers in a network can influence an individual's outcome. Peer\neffect refers to the difference in counterfactual outcomes of an individual for\ndifferent levels of peer exposure, the extent to which an individual is exposed\nto the treatments, actions, or behaviors of peers. Estimating peer effects\nrequires deciding how to represent peer exposure. Typically, researchers define\nan exposure mapping function that aggregates peer treatments and outputs peer\nexposure. Most existing approaches for defining exposure mapping functions\nassume peer exposure based on the number or fraction of treated peers. Recent\nstudies have investigated more complex functions of peer exposure which capture\nthat different peers can exert different degrees of influence. However, none of\nthese works have explicitly considered the problem of automatically learning\nthe exposure mapping function. In this work, we focus on learning this function\nfor the purpose of estimating heterogeneous peer effects, where heterogeneity\nrefers to the variation in counterfactual outcomes for the same peer exposure\nbut different individual's contexts. We develop EgoNetGNN, a graph neural\nnetwork (GNN)-based method, to automatically learn the appropriate exposure\nmapping function allowing for complex peer influence mechanisms that, in\naddition to peer treatments, can involve the local neighborhood structure and\nedge attributes. We show that GNN models that use peer exposure based on the\nnumber or fraction of treated peers or learn peer exposure naively face\ndifficulty accounting for such influence mechanisms. Our comprehensive\nevaluation on synthetic and semi-synthetic network data shows that our method\nis more robust to different unknown underlying influence mechanisms when\nestimating heterogeneous peer effects when compared to state-of-the-art\nbaselines.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.SI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01722v1",
    "published_date": "2025-03-03 16:37:05 UTC",
    "updated_date": "2025-03-03 16:37:05 UTC"
  },
  {
    "arxiv_id": "2503.01715v2",
    "title": "KeyFace: Expressive Audio-Driven Facial Animation for Long Sequences via KeyFrame Interpolation",
    "authors": [
      "Antoni Bigata",
      "Michał Stypułkowski",
      "Rodrigo Mira",
      "Stella Bounareli",
      "Konstantinos Vougioukas",
      "Zoe Landgraf",
      "Nikita Drobyshev",
      "Maciej Zieba",
      "Stavros Petridis",
      "Maja Pantic"
    ],
    "abstract": "Current audio-driven facial animation methods achieve impressive results for\nshort videos but suffer from error accumulation and identity drift when\nextended to longer durations. Existing methods attempt to mitigate this through\nexternal spatial control, increasing long-term consistency but compromising the\nnaturalness of motion. We propose KeyFace, a novel two-stage diffusion-based\nframework, to address these issues. In the first stage, keyframes are generated\nat a low frame rate, conditioned on audio input and an identity frame, to\ncapture essential facial expressions and movements over extended periods of\ntime. In the second stage, an interpolation model fills in the gaps between\nkeyframes, ensuring smooth transitions and temporal coherence. To further\nenhance realism, we incorporate continuous emotion representations and handle a\nwide range of non-speech vocalizations (NSVs), such as laughter and sighs. We\nalso introduce two new evaluation metrics for assessing lip synchronization and\nNSV generation. Experimental results show that KeyFace outperforms\nstate-of-the-art methods in generating natural, coherent facial animations over\nextended durations, successfully encompassing NSVs and continuous emotions.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.01715v2",
    "published_date": "2025-03-03 16:31:55 UTC",
    "updated_date": "2025-03-19 12:10:34 UTC"
  },
  {
    "arxiv_id": "2503.01714v1",
    "title": "Word Form Matters: LLMs' Semantic Reconstruction under Typoglycemia",
    "authors": [
      "Chenxi Wang",
      "Tianle Gu",
      "Zhongyu Wei",
      "Lang Gao",
      "Zirui Song",
      "Xiuying Chen"
    ],
    "abstract": "Human readers can efficiently comprehend scrambled words, a phenomenon known\nas Typoglycemia, primarily by relying on word form; if word form alone is\ninsufficient, they further utilize contextual cues for interpretation. While\nadvanced large language models (LLMs) exhibit similar abilities, the underlying\nmechanisms remain unclear. To investigate this, we conduct controlled\nexperiments to analyze the roles of word form and contextual information in\nsemantic reconstruction and examine LLM attention patterns. Specifically, we\nfirst propose SemRecScore, a reliable metric to quantify the degree of semantic\nreconstruction, and validate its effectiveness. Using this metric, we study how\nword form and contextual information influence LLMs' semantic reconstruction\nability, identifying word form as the core factor in this process. Furthermore,\nwe analyze how LLMs utilize word form and find that they rely on specialized\nattention heads to extract and process word form information, with this\nmechanism remaining stable across varying levels of word scrambling. This\ndistinction between LLMs' fixed attention patterns primarily focused on word\nform and human readers' adaptive strategy in balancing word form and contextual\ninformation provides insights into enhancing LLM performance by incorporating\nhuman-like, context-aware mechanisms.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "14 pages, 10 figures, submitted to ACL Rolling Review, February 2025\n  cycle, see https://github.com/Aurora-cx/TypoLLM",
    "pdf_url": "http://arxiv.org/pdf/2503.01714v1",
    "published_date": "2025-03-03 16:31:45 UTC",
    "updated_date": "2025-03-03 16:31:45 UTC"
  },
  {
    "arxiv_id": "2503.01713v1",
    "title": "SAGE: A Framework of Precise Retrieval for RAG",
    "authors": [
      "Jintao Zhang",
      "Guoliang Li",
      "Jinyang Su"
    ],
    "abstract": "Retrieval-augmented generation (RAG) has demonstrated significant proficiency\nin conducting question-answering (QA) tasks within a specified corpus.\nNonetheless, numerous failure instances of RAG in QA still exist. These\nfailures are not solely attributable to the limitations of Large Language\nModels (LLMs); instead, they predominantly arise from the retrieval of\ninaccurate information for LLMs due to two limitations: (1) Current RAG methods\nsegment the corpus without considering semantics, making it difficult to find\nrelevant context due to impaired correlation between questions and the\nsegments. (2) There is a trade-off between missing essential context with fewer\ncontext retrieved and getting irrelevant context with more context retrieved.\n  In this paper, we introduce a RAG framework (SAGE), to overcome these\nlimitations. First, to address the segmentation issue without considering\nsemantics, we propose to train a semantic segmentation model. This model is\ntrained to segment the corpus into semantically complete chunks. Second, to\nensure that only the most relevant chunks are retrieved while the irrelevant\nones are ignored, we design a chunk selection algorithm to dynamically select\nchunks based on the decreasing speed of the relevance score, leading to a more\nrelevant selection. Third, to further ensure the precision of the retrieved\nchunks, we propose letting LLMs assess whether retrieved chunks are excessive\nor lacking and then adjust the amount of context accordingly. Experiments show\nthat SAGE outperforms baselines by 61.25% in the quality of QA on average.\nMoreover, by avoiding retrieving noisy context, SAGE lowers the cost of the\ntokens consumed in LLM inference and achieves a 49.41% enhancement in cost\nefficiency on average. Additionally, our work offers valuable insights for\nboosting RAG.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DB",
      "cs.IR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01713v1",
    "published_date": "2025-03-03 16:25:58 UTC",
    "updated_date": "2025-03-03 16:25:58 UTC"
  },
  {
    "arxiv_id": "2503.01710v1",
    "title": "Spark-TTS: An Efficient LLM-Based Text-to-Speech Model with Single-Stream Decoupled Speech Tokens",
    "authors": [
      "Xinsheng Wang",
      "Mingqi Jiang",
      "Ziyang Ma",
      "Ziyu Zhang",
      "Songxiang Liu",
      "Linqin Li",
      "Zheng Liang",
      "Qixi Zheng",
      "Rui Wang",
      "Xiaoqin Feng",
      "Weizhen Bian",
      "Zhen Ye",
      "Sitong Cheng",
      "Ruibin Yuan",
      "Zhixian Zhao",
      "Xinfa Zhu",
      "Jiahao Pan",
      "Liumeng Xue",
      "Pengcheng Zhu",
      "Yunlin Chen",
      "Zhifei Li",
      "Xie Chen",
      "Lei Xie",
      "Yike Guo",
      "Wei Xue"
    ],
    "abstract": "Recent advancements in large language models (LLMs) have driven significant\nprogress in zero-shot text-to-speech (TTS) synthesis. However, existing\nfoundation models rely on multi-stage processing or complex architectures for\npredicting multiple codebooks, limiting efficiency and integration flexibility.\nTo overcome these challenges, we introduce Spark-TTS, a novel system powered by\nBiCodec, a single-stream speech codec that decomposes speech into two\ncomplementary token types: low-bitrate semantic tokens for linguistic content\nand fixed-length global tokens for speaker attributes. This disentangled\nrepresentation, combined with the Qwen2.5 LLM and a chain-of-thought (CoT)\ngeneration approach, enables both coarse-grained control (e.g., gender,\nspeaking style) and fine-grained adjustments (e.g., precise pitch values,\nspeaking rate). To facilitate research in controllable TTS, we introduce\nVoxBox, a meticulously curated 100,000-hour dataset with comprehensive\nattribute annotations. Extensive experiments demonstrate that Spark-TTS not\nonly achieves state-of-the-art zero-shot voice cloning but also generates\nhighly customizable voices that surpass the limitations of reference-based\nsynthesis. Source code, pre-trained models, and audio samples are available at\nhttps://github.com/SparkAudio/Spark-TTS.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Submitted to ACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.01710v1",
    "published_date": "2025-03-03 16:23:10 UTC",
    "updated_date": "2025-03-03 16:23:10 UTC"
  },
  {
    "arxiv_id": "2503.01702v1",
    "title": "Relating Piecewise Linear Kolmogorov Arnold Networks to ReLU Networks",
    "authors": [
      "Nandi Schoots",
      "Mattia Jacopo Villani",
      "Niels uit de Bos"
    ],
    "abstract": "Kolmogorov-Arnold Networks are a new family of neural network architectures\nwhich holds promise for overcoming the curse of dimensionality and has\ninterpretability benefits (arXiv:2404.19756). In this paper, we explore the\nconnection between Kolmogorov Arnold Networks (KANs) with piecewise linear\n(univariate real) functions and ReLU networks. We provide completely explicit\nconstructions to convert a piecewise linear KAN into a ReLU network and vice\nversa.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "accepted to AISTATS 2025; 12 pages including bibliography and\n  appendix",
    "pdf_url": "http://arxiv.org/pdf/2503.01702v1",
    "published_date": "2025-03-03 16:15:56 UTC",
    "updated_date": "2025-03-03 16:15:56 UTC"
  },
  {
    "arxiv_id": "2503.01700v1",
    "title": "Code-as-Symbolic-Planner: Foundation Model-Based Robot Planning via Symbolic Code Generation",
    "authors": [
      "Yongchao Chen",
      "Yilun Hao",
      "Yang Zhang",
      "Chuchu Fan"
    ],
    "abstract": "Recent works have shown great potentials of Large Language Models (LLMs) in\nrobot task and motion planning (TAMP). Current LLM approaches generate text- or\ncode-based reasoning chains with sub-goals and action plans. However, they do\nnot fully leverage LLMs' symbolic computing and code generation capabilities.\nMany robot TAMP tasks involve complex optimization under multiple constraints,\nwhere pure textual reasoning is insufficient. While augmenting LLMs with\npredefined solvers and planners improves performance, it lacks generalization\nacross tasks. Given LLMs' growing coding proficiency, we enhance their TAMP\ncapabilities by steering them to generate code as symbolic planners for\noptimization and constraint verification. Unlike prior work that uses code to\ninterface with robot action modules, we steer LLMs to generate code as solvers,\nplanners, and checkers for TAMP tasks requiring symbolic computing, while still\nleveraging textual reasoning to incorporate common sense. With a multi-round\nguidance and answer evolution framework, the proposed Code-as-Symbolic-Planner\nimproves success rates by average 24.1\\% over best baseline methods across\nseven typical TAMP tasks and three popular LLMs. Code-as-Symbolic-Planner shows\nstrong effectiveness and generalizability across discrete and continuous\nenvironments, 2D/3D simulations and real-world settings, as well as single- and\nmulti-robot tasks with diverse requirements. See our project website\nhttps://yongchao98.github.io/Code-Symbol-Planner/ for prompts, videos, and\ncode.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.RO",
    "comment": "7 pages, 7 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2503.01700v1",
    "published_date": "2025-03-03 16:13:41 UTC",
    "updated_date": "2025-03-03 16:13:41 UTC"
  },
  {
    "arxiv_id": "2503.01676v2",
    "title": "Perceptual Motor Learning with Active Inference Framework for Robust Lateral Control",
    "authors": [
      "Elahe Delavari",
      "John Moore",
      "Junho Hong",
      "Jaerock Kwon"
    ],
    "abstract": "This paper presents a novel Perceptual Motor Learning (PML) framework\nintegrated with Active Inference (AIF) to enhance lateral control in Highly\nAutomated Vehicles (HAVs). PML, inspired by human motor learning, emphasizes\nthe seamless integration of perception and action, enabling efficient\ndecision-making in dynamic environments. Traditional autonomous driving\napproaches--including modular pipelines, imitation learning, and reinforcement\nlearning--struggle with adaptability, generalization, and computational\nefficiency. In contrast, PML with AIF leverages a generative model to minimize\nprediction error (\"surprise\") and actively shape vehicle control based on\nlearned perceptual-motor representations. Our approach unifies deep learning\nwith active inference principles, allowing HAVs to perform lane-keeping\nmaneuvers with minimal data and without extensive retraining across different\nenvironments. Extensive experiments in the CARLA simulator demonstrate that PML\nwith AIF enhances adaptability without increasing computational overhead while\nachieving performance comparable to conventional methods. These findings\nhighlight the potential of PML-driven active inference as a robust alternative\nfor real-world autonomous driving applications.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.RO",
    "comment": "This work has been submitted to IROS 2025 and is currently under\n  review. Supersedes arXiv:2407.07684",
    "pdf_url": "http://arxiv.org/pdf/2503.01676v2",
    "published_date": "2025-03-03 15:49:18 UTC",
    "updated_date": "2025-03-05 01:27:57 UTC"
  },
  {
    "arxiv_id": "2503.01670v1",
    "title": "Evaluating LLMs' Assessment of Mixed-Context Hallucination Through the Lens of Summarization",
    "authors": [
      "Siya Qi",
      "Rui Cao",
      "Yulan He",
      "Zheng Yuan"
    ],
    "abstract": "With the rapid development of large language models (LLMs), LLM-as-a-judge\nhas emerged as a widely adopted approach for text quality evaluation, including\nhallucination evaluation. While previous studies have focused exclusively on\nsingle-context evaluation (e.g., discourse faithfulness or world factuality),\nreal-world hallucinations typically involve mixed contexts, which remains\ninadequately evaluated. In this study, we use summarization as a representative\ntask to comprehensively evaluate LLMs' capability in detecting mixed-context\nhallucinations, specifically distinguishing between factual and non-factual\nhallucinations. Through extensive experiments across direct generation and\nretrieval-based models of varying scales, our main observations are: (1) LLMs'\nintrinsic knowledge introduces inherent biases in hallucination evaluation; (2)\nThese biases particularly impact the detection of factual hallucinations,\nyielding a significant performance bottleneck; (3) The fundamental challenge\nlies in effective knowledge utilization, balancing between LLMs' intrinsic\nknowledge and external context for accurate mixed-context hallucination\nevaluation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages, 5 figures for main body",
    "pdf_url": "http://arxiv.org/pdf/2503.01670v1",
    "published_date": "2025-03-03 15:42:57 UTC",
    "updated_date": "2025-03-03 15:42:57 UTC"
  },
  {
    "arxiv_id": "2503.01669v1",
    "title": "An Efficient Continual Learning Framework for Multivariate Time Series Prediction Tasks with Application to Vehicle State Estimation",
    "authors": [
      "Arvin Hosseinzadeh",
      "Ladan Khoshnevisan",
      "Mohammad Pirani",
      "Shojaeddin Chenouri",
      "Amir Khajepour"
    ],
    "abstract": "In continual time series analysis using neural networks, catastrophic\nforgetting (CF) of previously learned models when training on new data domains\nhas always been a significant challenge. This problem is especially challenging\nin vehicle estimation and control, where new information is sequentially\nintroduced to the model. Unfortunately, existing work on continual learning has\nnot sufficiently addressed the adverse effects of catastrophic forgetting in\ntime series analysis, particularly in multivariate output environments. In this\npaper, we present EM-ReSeleCT (Efficient Multivariate Representative Selection\nfor Continual Learning in Time Series Tasks), an enhanced approach designed to\nhandle continual learning in multivariate environments. Our approach\nstrategically selects representative subsets from old and historical data and\nincorporates memory-based continual learning techniques with an improved\noptimization algorithm to adapt the pre-trained model on new information while\npreserving previously acquired information. Additionally, we develop a\nsequence-to-sequence transformer model (autoregressive model) specifically\ndesigned for vehicle state estimation. Moreover, we propose an uncertainty\nquantification framework using conformal prediction to assess the sensitivity\nof the memory size and to showcase the robustness of the proposed method.\nExperimental results from tests on an electric Equinox vehicle highlight the\nsuperiority of our method in continually learning new information while\nretaining prior knowledge, outperforming state-of-the-art continual learning\nmethods. Furthermore, EM-ReSeleCT significantly reduces training time, a\ncritical advantage in continual learning applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01669v1",
    "published_date": "2025-03-03 15:42:06 UTC",
    "updated_date": "2025-03-03 15:42:06 UTC"
  },
  {
    "arxiv_id": "2503.01658v1",
    "title": "CoPL: Collaborative Preference Learning for Personalizing LLMs",
    "authors": [
      "Youngbin Choi",
      "Seunghyuk Cho",
      "Minjong Lee",
      "MoonJeong Park",
      "Yesong Ko",
      "Jungseul Ok",
      "Dongwoo Kim"
    ],
    "abstract": "Personalizing large language models (LLMs) is important for aligning outputs\nwith diverse user preferences, yet existing methods struggle with flexibility\nand generalization. We propose CoPL (Collaborative Preference Learning), a\ngraph-based collaborative filtering framework that models user-response\nrelationships to enhance preference estimation, particularly in sparse\nannotation settings. By integrating a mixture of LoRA experts, CoPL efficiently\nfine-tunes LLMs while dynamically balancing shared and user-specific\npreferences. Additionally, an optimization-free adaptation strategy enables\ngeneralization to unseen users without fine-tuning. Experiments on\nUltraFeedback-P demonstrate that CoPL outperforms existing personalized reward\nmodels, effectively capturing both common and controversial preferences, making\nit a scalable solution for personalized LLM alignment.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.LG",
    "comment": "13pages, 4 figures, 6tables",
    "pdf_url": "http://arxiv.org/pdf/2503.01658v1",
    "published_date": "2025-03-03 15:32:02 UTC",
    "updated_date": "2025-03-03 15:32:02 UTC"
  },
  {
    "arxiv_id": "2503.01655v1",
    "title": "Enhancing Object Detection Accuracy in Underwater Sonar Images through Deep Learning-based Denoising",
    "authors": [
      "Ziyu Wang",
      "Tao Xue",
      "Yanbin Wang",
      "Jingyuan Li",
      "Haibin Zhang",
      "Zhiqiang Xu",
      "Gaofei Xu"
    ],
    "abstract": "Sonar image object detection is crucial for underwater robotics and other\napplications. However, various types of noise in sonar images can affect the\naccuracy of object detection. Denoising, as a critical preprocessing step, aims\nto remove noise while retaining useful information to improve detection\naccuracy. Although deep learning-based denoising algorithms perform well on\noptical images, their application to underwater sonar images remains\nunderexplored. This paper systematically evaluates the effectiveness of several\ndeep learning-based denoising algorithms, originally designed for optical\nimages, in the context of underwater sonar image object detection. We apply\nnine trained denoising models to images from five open-source sonar datasets,\neach processing different types of noise. We then test the denoised images\nusing four object detection algorithms. The results show that different\ndenoising models have varying effects on detection performance. By combining\nthe strengths of multiple denoising models, the detection results can be\noptimized, thus more effectively suppressing noise. Additionally, we adopt a\nmulti-frame denoising technique, using different outputs generated by multiple\ndenoising models as multiple frames of the same scene for further processing to\nenhance detection accuracy. This method, originally designed for optical\nimages, leverages complementary noise-reduction effects. Experimental results\nshow that denoised sonar images improve the performance of object detection\nalgorithms compared to the original sonar images.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01655v1",
    "published_date": "2025-03-03 15:30:39 UTC",
    "updated_date": "2025-03-03 15:30:39 UTC"
  },
  {
    "arxiv_id": "2503.01653v2",
    "title": "Distilled Prompt Learning for Incomplete Multimodal Survival Prediction",
    "authors": [
      "Yingxue Xu",
      "Fengtao Zhou",
      "Chenyu Zhao",
      "Yihui Wang",
      "Can Yang",
      "Hao Chen"
    ],
    "abstract": "The integration of multimodal data including pathology images and gene\nprofiles is widely applied in precise survival prediction. Despite recent\nadvances in multimodal survival models, collecting complete modalities for\nmultimodal fusion still poses a significant challenge, hindering their\napplication in clinical settings. Current approaches tackling incomplete\nmodalities often fall short, as they typically compensate for only a limited\npart of the knowledge of missing modalities. To address this issue, we propose\na Distilled Prompt Learning framework (DisPro) to utilize the strong robustness\nof Large Language Models (LLMs) to missing modalities, which employs two-stage\nprompting for compensation of comprehensive information for missing modalities.\nIn the first stage, Unimodal Prompting (UniPro) distills the knowledge\ndistribution of each modality, preparing for supplementing modality-specific\nknowledge of the missing modality in the subsequent stage. In the second stage,\nMultimodal Prompting (MultiPro) leverages available modalities as prompts for\nLLMs to infer the missing modality, which provides modality-common information.\nSimultaneously, the unimodal knowledge acquired in the first stage is injected\ninto multimodal inference to compensate for the modality-specific knowledge of\nthe missing modality. Extensive experiments covering various missing scenarios\ndemonstrated the superiority of the proposed method. The code is available at\nhttps://github.com/Innse/DisPro.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by CVPR2025",
    "pdf_url": "http://arxiv.org/pdf/2503.01653v2",
    "published_date": "2025-03-03 15:28:26 UTC",
    "updated_date": "2025-03-24 09:20:07 UTC"
  },
  {
    "arxiv_id": "2503.01646v1",
    "title": "OpenGS-SLAM: Open-Set Dense Semantic SLAM with 3D Gaussian Splatting for Object-Level Scene Understanding",
    "authors": [
      "Dianyi Yang",
      "Yu Gao",
      "Xihan Wang",
      "Yufeng Yue",
      "Yi Yang",
      "Mengyin Fu"
    ],
    "abstract": "Recent advancements in 3D Gaussian Splatting have significantly improved the\nefficiency and quality of dense semantic SLAM. However, previous methods are\ngenerally constrained by limited-category pre-trained classifiers and implicit\nsemantic representation, which hinder their performance in open-set scenarios\nand restrict 3D object-level scene understanding. To address these issues, we\npropose OpenGS-SLAM, an innovative framework that utilizes 3D Gaussian\nrepresentation to perform dense semantic SLAM in open-set environments. Our\nsystem integrates explicit semantic labels derived from 2D foundational models\ninto the 3D Gaussian framework, facilitating robust 3D object-level scene\nunderstanding. We introduce Gaussian Voting Splatting to enable fast 2D label\nmap rendering and scene updating. Additionally, we propose a Confidence-based\n2D Label Consensus method to ensure consistent labeling across multiple views.\nFurthermore, we employ a Segmentation Counter Pruning strategy to improve the\naccuracy of semantic scene representation. Extensive experiments on both\nsynthetic and real-world datasets demonstrate the effectiveness of our method\nin scene understanding, tracking, and mapping, achieving 10 times faster\nsemantic rendering and 2 times lower storage costs compared to existing\nmethods. Project page: https://young-bit.github.io/opengs-github.github.io/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01646v1",
    "published_date": "2025-03-03 15:23:21 UTC",
    "updated_date": "2025-03-03 15:23:21 UTC"
  },
  {
    "arxiv_id": "2503.01642v1",
    "title": "Graph-Augmented Reasoning: Evolving Step-by-Step Knowledge Graph Retrieval for LLM Reasoning",
    "authors": [
      "Wenjie Wu",
      "Yongcheng Jing",
      "Yingjie Wang",
      "Wenbin Hu",
      "Dacheng Tao"
    ],
    "abstract": "Recent large language model (LLM) reasoning, despite its success, suffers\nfrom limited domain knowledge, susceptibility to hallucinations, and\nconstrained reasoning depth, particularly in small-scale models deployed in\nresource-constrained environments. This paper presents the first investigation\ninto integrating step-wise knowledge graph retrieval with step-wise reasoning\nto address these challenges, introducing a novel paradigm termed as\ngraph-augmented reasoning. Our goal is to enable frozen, small-scale LLMs to\nretrieve and process relevant mathematical knowledge in a step-wise manner,\nenhancing their problem-solving abilities without additional training. To this\nend, we propose KG-RAR, a framework centered on process-oriented knowledge\ngraph construction, a hierarchical retrieval strategy, and a universal\npost-retrieval processing and reward model (PRP-RM) that refines retrieved\ninformation and evaluates each reasoning step. Experiments on the Math500 and\nGSM8K benchmarks across six models demonstrate that KG-RAR yields encouraging\nresults, achieving a 20.73\\% relative improvement with Llama-3B on Math500.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01642v1",
    "published_date": "2025-03-03 15:20:41 UTC",
    "updated_date": "2025-03-03 15:20:41 UTC"
  },
  {
    "arxiv_id": "2503.01632v1",
    "title": "CoT-VLM4Tar: Chain-of-Thought Guided Vision-Language Models for Traffic Anomaly Resolution",
    "authors": [
      "Tianchi Ren",
      "Haibo Hu",
      "Jiacheng Zuo",
      "Xinhong Chen",
      "Jianping Wang",
      "Chun Jason Xue",
      "Jen-Ming Wu",
      "Nan Guan"
    ],
    "abstract": "With the acceleration of urbanization, modern urban traffic systems are\nbecoming increasingly complex, leading to frequent traffic anomalies. These\nanomalies encompass not only common traffic jams but also more challenging\nissues such as phantom traffic jams, intersection deadlocks, and accident\nliability analysis, which severely impact traffic flow, vehicular safety, and\noverall transportation efficiency. Currently, existing solutions primarily rely\non manual intervention by traffic police or artificial intelligence-based\ndetection systems. However, these methods often suffer from response delays and\ninconsistent management due to inadequate resources, while AI detection\nsystems, despite enhancing efficiency to some extent, still struggle to handle\ncomplex traffic anomalies in a real-time and precise manner. To address these\nissues, we propose CoT-VLM4Tar: (Chain of Thought Visual-Language Model for\nTraffic Anomaly Resolution), this innovative approach introduces a new\nchain-of-thought to guide the VLM in analyzing, reasoning, and generating\nsolutions for traffic anomalies with greater reasonable and effective solution,\nand to evaluate the performance and effectiveness of our method, we developed a\nclosed-loop testing framework based on the CARLA simulator. Furthermore, to\nensure seamless integration of the solutions generated by the VLM with the\nCARLA simulator, we implement an itegration module that converts these\nsolutions into executable commands. Our results demonstrate the effectiveness\nof VLM in the resolution of real-time traffic anomalies, providing a\nproof-of-concept for its integration into autonomous traffic management\nsystems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01632v1",
    "published_date": "2025-03-03 15:07:25 UTC",
    "updated_date": "2025-03-03 15:07:25 UTC"
  },
  {
    "arxiv_id": "2503.01942v1",
    "title": "Mathematical Foundation of Interpretable Equivariant Surrogate Models",
    "authors": [
      "Jacopo Joy Colombini",
      "Filippo Bonchi",
      "Francesco Giannini",
      "Fosca Giannotti",
      "Roberto Pellungrini",
      "Patrizio Frosini"
    ],
    "abstract": "This paper introduces a rigorous mathematical framework for neural network\nexplainability, and more broadly for the explainability of equivariant\noperators called Group Equivariant Operators (GEOs) based on Group Equivariant\nNon-Expansive Operators (GENEOs) transformations. The central concept involves\nquantifying the distance between GEOs by measuring the non-commutativity of\nspecific diagrams. Additionally, the paper proposes a definition of\ninterpretability of GEOs according to a complexity measure that can be defined\naccording to each user preferences. Moreover, we explore the formal properties\nof this framework and show how it can be applied in classical machine learning\nscenarios, like image classification with convolutional neural networks.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01942v1",
    "published_date": "2025-03-03 15:06:43 UTC",
    "updated_date": "2025-03-03 15:06:43 UTC"
  },
  {
    "arxiv_id": "2503.01630v1",
    "title": "Machine Learners Should Acknowledge the Legal Implications of Large Language Models as Personal Data",
    "authors": [
      "Henrik Nolte",
      "Michèle Finck",
      "Kristof Meding"
    ],
    "abstract": "Does GPT know you? The answer depends on your level of public recognition;\nhowever, if your information was available on a website, the answer is probably\nyes. All Large Language Models (LLMs) memorize training data to some extent. If\nan LLM training corpus includes personal data, it also memorizes personal data.\nDeveloping an LLM typically involves processing personal data, which falls\ndirectly within the scope of data protection laws. If a person is identified or\nidentifiable, the implications are far-reaching: the AI system is subject to EU\nGeneral Data Protection Regulation requirements even after the training phase\nis concluded. To back our arguments: (1.) We reiterate that LLMs output\ntraining data at inference time, be it verbatim or in generalized form. (2.) We\nshow that some LLMs can thus be considered personal data on their own. This\ntriggers a cascade of data protection implications such as data subject rights,\nincluding rights to access, rectification, or erasure. These rights extend to\nthe information embedded with-in the AI model. (3.) This paper argues that\nmachine learning researchers must acknowledge the legal implications of LLMs as\npersonal data throughout the full ML development lifecycle, from data\ncollection and curation to model provision on, e.g., GitHub or Hugging Face.\n(4.) We propose different ways for the ML research community to deal with these\nlegal implications. Our paper serves as a starting point for improving the\nalignment between data protection law and the technical capabilities of LLMs.\nOur findings underscore the need for more interaction between the legal domain\nand the ML community.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01630v1",
    "published_date": "2025-03-03 15:05:48 UTC",
    "updated_date": "2025-03-03 15:05:48 UTC"
  },
  {
    "arxiv_id": "2503.01619v1",
    "title": "Advancing vision-language models in front-end development via data synthesis",
    "authors": [
      "Tong Ge",
      "Yashu Liu",
      "Jieping Ye",
      "Tianyi Li",
      "Chao Wang"
    ],
    "abstract": "Modern front-end (FE) development, especially when leveraging the unique\nfeatures of frameworks like React and Vue, presents distinctive challenges.\nThese include managing modular architectures, ensuring synchronization between\ndata and visual outputs for declarative rendering, and adapting reusable\ncomponents to various scenarios. Such complexities make it particularly\ndifficult for state-of-the-art large vision-language models (VLMs) to generate\naccurate and functional code directly from design images. To address these\nchallenges, we propose a reflective agentic workflow that synthesizes\nhigh-quality image-text data to capture the diverse characteristics of FE\ndevelopment. This workflow automates the extraction of\nself-contained\\footnote{A \\textbf{self-contained} code snippet is one that\nencapsulates all necessary logic, styling, and dependencies, ensuring it\nfunctions independently without requiring external imports or context.} code\nsnippets from real-world projects, renders the corresponding visual outputs,\nand generates detailed descriptions that link design elements to functional\ncode. To further expand the scope and utility of the synthesis, we introduce\nthree data synthesis strategies: Evolution-based synthesis, which enables\nscalable and diverse dataset expansion; Waterfall-Model-based synthesis, which\ngenerates logically coherent code derived from system requirements; and\nAdditive Development synthesis, which iteratively increases the complexity of\nhuman-authored components. We build a large vision-language model, Flame,\ntrained on the synthesized datasets and demonstrate its effectiveness in\ngenerating React code via the $\\text{pass}@k$ metric. Our results suggest that\na code VLM trained to interpret images before code generation may achieve\nbetter performance.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01619v1",
    "published_date": "2025-03-03 14:54:01 UTC",
    "updated_date": "2025-03-03 14:54:01 UTC"
  },
  {
    "arxiv_id": "2503.01606v1",
    "title": "Beyond Prompting: An Efficient Embedding Framework for Open-Domain Question Answering",
    "authors": [
      "Zhanghao Hu",
      "Hanqi Yan",
      "Qingling Zhu",
      "Zhenyi Shen",
      "Yulan He",
      "Lin Gui"
    ],
    "abstract": "Large language models have recently pushed open domain question answering\n(ODQA) to new frontiers. However, prevailing retriever-reader pipelines often\ndepend on multiple rounds of prompt level instructions, leading to high\ncomputational overhead, instability, and suboptimal retrieval coverage. In this\npaper, we propose EmbQA, an embedding-level framework that alleviates these\nshortcomings by enhancing both the retriever and the reader. Specifically, we\nrefine query representations via lightweight linear layers under an\nunsupervised contrastive learning objective, thereby reordering retrieved\npassages to highlight those most likely to contain correct answers.\nAdditionally, we introduce an exploratory embedding that broadens the model's\nlatent semantic space to diversify candidate generation and employs an\nentropy-based selection mechanism to choose the most confident answer\nautomatically. Extensive experiments across three open-source LLMs, three\nretrieval methods, and four ODQA benchmarks demonstrate that EmbQA\nsubstantially outperforms recent baselines in both accuracy and efficiency.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01606v1",
    "published_date": "2025-03-03 14:41:35 UTC",
    "updated_date": "2025-03-03 14:41:35 UTC"
  },
  {
    "arxiv_id": "2503.01603v1",
    "title": "Triple-Stream Deep Feature Selection with Metaheuristic Optimization and Machine Learning for Multi-Stage Hypertensive Retinopathy Diagnosis",
    "authors": [
      "Suleyman Burcin Suyun",
      "Mustafa Yurdakul",
      "Sakir Tasdemir",
      "Serkan Bilic"
    ],
    "abstract": "Hypertensive retinopathy (HR) is a severe eye disease that may cause\npermanent vision loss if not diagnosed early. Traditional diagnostic methods\nare time-consuming and subjective, highlighting the need for an automated,\nreliable system. Existing studies often use a single Deep Learning (DL) model,\nstruggling to distinguish HR stages. This study introduces a three-stage\napproach to enhance HR diagnosis accuracy. Initially, 14 CNN models were\ntested, identifying DenseNet169, MobileNet, and ResNet152 as the most\neffective. DenseNet169 achieved 87.73% accuracy, 87.75% precision, 87.73%\nrecall, 87.67% F1-score, and 0.8359 Cohen's Kappa. MobileNet followed with\n86.40% accuracy, 86.60% precision, 86.40% recall, 86.31% F1-score, and 0.8180\nCohen's Kappa. ResNet152 ranked third with 85.87% accuracy, 86.01% precision,\n85.87% recall, 85.83% F1-score, and 0.8188 Cohen's Kappa. In the second stage,\ndeep features from these models were fused and classified using Machine\nLearning (ML) algorithms (SVM, RF, XGBoost). SVM (sigmoid kernel) performed\nbest with 92.00% accuracy, 91.93% precision, 92.00% recall, 91.91% F1-score,\nand 0.8930 Cohen's Kappa. The third stage applied meta-heuristic optimization\n(GA, ABC, PSO, HHO) for feature selection. HHO yielded 94.66% accuracy,\nprecision, and recall, 94.64% F1-score, and 0.9286 Cohen's Kappa. The proposed\napproach surpassed single CNN models and previous studies in HR diagnosis\naccuracy and generalization.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01603v1",
    "published_date": "2025-03-03 14:39:46 UTC",
    "updated_date": "2025-03-03 14:39:46 UTC"
  },
  {
    "arxiv_id": "2503.01595v1",
    "title": "STAR: Stability-Inducing Weight Perturbation for Continual Learning",
    "authors": [
      "Masih Eskandar",
      "Tooba Imtiaz",
      "Davin Hill",
      "Zifeng Wang",
      "Jennifer Dy"
    ],
    "abstract": "Humans can naturally learn new and varying tasks in a sequential manner.\nContinual learning is a class of learning algorithms that updates its learned\nmodel as it sees new data (on potentially new tasks) in a sequence. A key\nchallenge in continual learning is that as the model is updated to learn new\ntasks, it becomes susceptible to catastrophic forgetting, where knowledge of\npreviously learned tasks is lost. A popular approach to mitigate forgetting\nduring continual learning is to maintain a small buffer of previously-seen\nsamples and to replay them during training. However, this approach is limited\nby the small buffer size, and while forgetting is reduced, it is still present.\nIn this paper, we propose a novel loss function, STAR, that exploits the\nworst-case parameter perturbation that reduces the KL-divergence of model\npredictions with that of its local parameter neighborhood to promote stability\nand alleviate forgetting. STAR can be combined with almost any existing\nrehearsal-based method as a plug-and-play component. We empirically show that\nSTAR consistently improves the performance of existing methods by up to 15%\nacross varying baselines and achieves superior or competitive accuracy to that\nof state-of-the-art methods aimed at improving rehearsal-based continual\nlearning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01595v1",
    "published_date": "2025-03-03 14:32:03 UTC",
    "updated_date": "2025-03-03 14:32:03 UTC"
  },
  {
    "arxiv_id": "2503.01592v1",
    "title": "An Efficient Approach to Detecting Lung Nodules Using Swin Transformer",
    "authors": [
      "Saeed Shakuri",
      "Alireza Rezvanian"
    ],
    "abstract": "Lung cancer has the highest rate of cancer-caused deaths, and early-stage\ndiagnosis could increase the survival rate. Lung nodules are common indicators\nof lung cancer, making their detection crucial. Various lung nodule detection\nmodels exist, but many lack efficiency. Hence, we propose a more efficient\napproach by leveraging 2D CT slices, reducing computational load and complexity\nin training and inference. We employ the tiny version of Swin Transformer to\nbenefit from Vision Transformers (ViT) while maintaining low computational\ncost. A Feature Pyramid Network is added to enhance detection, particularly for\nsmall nodules. Additionally, Transfer Learning is used to accelerate training.\nOur experimental results show that the proposed model outperforms\nstate-of-the-art methods, achieving higher mAP and mAR for small nodules by\n1.3% and 1.6%, respectively. Overall, our model achieves the highest mAP of\n94.7% and mAR of 94.9%.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "19th Iranian Conference on Intelligent Systems (ICIS), IEEE, 2024",
    "pdf_url": "http://arxiv.org/pdf/2503.01592v1",
    "published_date": "2025-03-03 14:30:14 UTC",
    "updated_date": "2025-03-03 14:30:14 UTC"
  },
  {
    "arxiv_id": "2503.01586v1",
    "title": "EliteKV: Scalable KV Cache Compression via RoPE Frequency Selection and Joint Low-Rank Projection",
    "authors": [
      "Yuhao Zhou",
      "Sirui Song",
      "Boyang Liu",
      "Zhiheng Xi",
      "Senjie Jin",
      "Xiaoran Fan",
      "Zhihao Zhang",
      "Wei Li",
      "Xuanjing Huang"
    ],
    "abstract": "Rotary Position Embedding (RoPE) enables each attention head to capture\nmulti-frequency information along the sequence dimension and is widely applied\nin foundation models. However, the nonlinearity introduced by RoPE complicates\noptimization of the key state in the Key-Value (KV) cache for RoPE-based\nattention. Existing KV cache compression methods typically store key state\nbefore rotation and apply the transformation during decoding, introducing\nadditional computational overhead. This paper introduces EliteKV, a flexible\nmodification framework for RoPE-based models supporting variable KV cache\ncompression ratios. EliteKV first identifies the intrinsic frequency preference\nof each head using RoPElite, selectively restoring linearity to certain\ndimensions of key within attention computation. Building on this, joint\nlow-rank compression of key and value enables partial cache sharing.\nExperimental results show that with minimal uptraining on only $0.6\\%$ of the\noriginal training data, RoPE-based models achieve a $75\\%$ reduction in KV\ncache size while preserving performance within a negligible margin.\nFurthermore, EliteKV consistently performs well across models of different\nscales within the same family.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.01586v1",
    "published_date": "2025-03-03 14:26:51 UTC",
    "updated_date": "2025-03-03 14:26:51 UTC"
  },
  {
    "arxiv_id": "2503.01584v1",
    "title": "SENSEI: Semantic Exploration Guided by Foundation Models to Learn Versatile World Models",
    "authors": [
      "Cansu Sancaktar",
      "Christian Gumbsch",
      "Andrii Zadaianchuk",
      "Pavel Kolev",
      "Georg Martius"
    ],
    "abstract": "Exploration is a cornerstone of reinforcement learning (RL). Intrinsic\nmotivation attempts to decouple exploration from external, task-based rewards.\nHowever, established approaches to intrinsic motivation that follow general\nprinciples such as information gain, often only uncover low-level interactions.\nIn contrast, children's play suggests that they engage in meaningful high-level\nbehavior by imitating or interacting with their caregivers. Recent work has\nfocused on using foundation models to inject these semantic biases into\nexploration. However, these methods often rely on unrealistic assumptions, such\nas language-embedded environments or access to high-level actions. We propose\nSEmaNtically Sensible ExploratIon (SENSEI), a framework to equip model-based RL\nagents with an intrinsic motivation for semantically meaningful behavior.\nSENSEI distills a reward signal of interestingness from Vision Language Model\n(VLM) annotations, enabling an agent to predict these rewards through a world\nmodel. Using model-based RL, SENSEI trains an exploration policy that jointly\nmaximizes semantic rewards and uncertainty. We show that in both robotic and\nvideo game-like simulations SENSEI discovers a variety of meaningful behaviors\nfrom image observations and low-level actions. SENSEI provides a general tool\nfor learning from foundation model feedback, a crucial research direction, as\nVLMs become more powerful.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Preprint, under review. Project webpage at\n  https://sites.google.com/view/sensei-paper",
    "pdf_url": "http://arxiv.org/pdf/2503.01584v1",
    "published_date": "2025-03-03 14:26:15 UTC",
    "updated_date": "2025-03-03 14:26:15 UTC"
  },
  {
    "arxiv_id": "2503.01580v1",
    "title": "A Selective Learning Method for Temporal Graph Continual Learning",
    "authors": [
      "Hanmo Liu",
      "Shimin Di",
      "Haoyang Li",
      "Xun Jian",
      "Yue Wang",
      "Lei Chen"
    ],
    "abstract": "Node classification is a key task in temporal graph learning (TGL). Real-life\ntemporal graphs often introduce new node classes over time, but existing TGL\nmethods assume a fixed set of classes. This assumption brings limitations, as\nupdating models with full data is costly, while focusing only on new classes\nresults in forgetting old ones. Graph continual learning (GCL) methods mitigate\nforgetting using old-class subsets but fail to account for their evolution. We\ndefine this novel problem as temporal graph continual learning (TGCL), which\nfocuses on efficiently maintaining up-to-date knowledge of old classes. To\ntackle TGCL, we propose a selective learning framework that substitutes the\nold-class data with its subsets, Learning Towards the Future (LTF). We derive\nan upper bound on the error caused by such replacement and transform it into\nobjectives for selecting and learning subsets that minimize classification\nerror while preserving the distribution of the full old-class data. Experiments\non three real-world datasets validate the effectiveness of LTF on TGCL.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01580v1",
    "published_date": "2025-03-03 14:22:20 UTC",
    "updated_date": "2025-03-03 14:22:20 UTC"
  },
  {
    "arxiv_id": "2503.01941v1",
    "title": "Task Scheduling & Forgetting in Multi-Task Reinforcement Learning",
    "authors": [
      "Marc Speckmann",
      "Theresa Eimer"
    ],
    "abstract": "Reinforcement learning (RL) agents can forget tasks they have previously been\ntrained on. There is a rich body of work on such forgetting effects in humans.\nTherefore we look for commonalities in the forgetting behavior of humans and RL\nagents across tasks and test the viability of forgetting prevention measures\nfrom learning theory in RL. We find that in many cases, RL agents exhibit\nforgetting curves similar to those of humans. Methods like Leitner or SuperMemo\nhave been shown to be effective at counteracting human forgetting, but we\ndemonstrate they do not transfer as well to RL. We identify a likely cause:\nasymmetrical learning and retention patterns between tasks that cannot be\ncaptured by retention-based or performance-based curriculum strategies.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Presented at RLDM 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.01941v1",
    "published_date": "2025-03-03 14:12:52 UTC",
    "updated_date": "2025-03-03 14:12:52 UTC"
  },
  {
    "arxiv_id": "2503.01557v1",
    "title": "MoCFL: Mobile Cluster Federated Learning Framework for Highly Dynamic Network",
    "authors": [
      "Kai Fang",
      "Jiangtao Deng",
      "Chengzu Dong",
      "Usman Naseem",
      "Tongcun Liu",
      "Hailin Feng",
      "Wei Wang"
    ],
    "abstract": "Frequent fluctuations of client nodes in highly dynamic mobile clusters can\nlead to significant changes in feature space distribution and data drift,\nposing substantial challenges to the robustness of existing federated learning\n(FL) strategies. To address these issues, we proposed a mobile cluster\nfederated learning framework (MoCFL). MoCFL enhances feature aggregation by\nintroducing an affinity matrix that quantifies the similarity between local\nfeature extractors from different clients, addressing dynamic data distribution\nchanges caused by frequent client churn and topology changes. Additionally,\nMoCFL integrates historical and current feature information when training the\nglobal classifier, effectively mitigating the catastrophic forgetting problem\nfrequently encountered in mobile scenarios. This synergistic combination\nensures that MoCFL maintains high performance and stability in dynamically\nchanging mobile environments. Experimental results on the UNSW-NB15 dataset\nshow that MoCFL excels in dynamic environments, demonstrating superior\nrobustness and accuracy while maintaining reasonable training costs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 7 figures, conference",
    "pdf_url": "http://arxiv.org/pdf/2503.01557v1",
    "published_date": "2025-03-03 13:59:47 UTC",
    "updated_date": "2025-03-03 13:59:47 UTC"
  },
  {
    "arxiv_id": "2503.01556v1",
    "title": "Effective High-order Graph Representation Learning for Credit Card Fraud Detection",
    "authors": [
      "Yao Zou",
      "Dawei Cheng"
    ],
    "abstract": "Credit card fraud imposes significant costs on both cardholders and issuing\nbanks. Fraudsters often disguise their crimes, such as using legitimate\ntransactions through several benign users to bypass anti-fraud detection.\nExisting graph neural network (GNN) models struggle with learning features of\ncamouflaged, indirect multi-hop transactions due to their inherent\nover-smoothing issues in deep multi-layer aggregation, presenting a major\nchallenge in detecting disguised relationships. Therefore, in this paper, we\npropose a novel High-order Graph Representation Learning model (HOGRL) to avoid\nincorporating excessive noise during the multi-layer aggregation process. In\nparticular, HOGRL learns different orders of \\emph{pure} representations\ndirectly from high-order transaction graphs. We realize this goal by\neffectively constructing high-order transaction graphs first and then learning\nthe \\emph{pure} representations of each order so that the model could identify\nfraudsters' multi-hop indirect transactions via multi-layer \\emph{pure} feature\nlearning. In addition, we introduce a mixture-of-expert attention mechanism to\nautomatically determine the importance of different orders for jointly\noptimizing fraud detection performance. We conduct extensive experiments in\nboth the open source and real-world datasets, the result demonstrates the\nsignificant improvements of our proposed HOGRL compared with state-of-the-art\nfraud detection baselines. HOGRL's superior performance also proves its\neffectiveness in addressing high-order fraud camouflage criminals.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "68T07, 91B06",
      "I.2.6; H.2.8"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 5 figures, accepted at IJCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2503.01556v1",
    "published_date": "2025-03-03 13:59:46 UTC",
    "updated_date": "2025-03-03 13:59:46 UTC"
  },
  {
    "arxiv_id": "2503.01544v1",
    "title": "Compositional Reasoning with Transformers, RNNs, and Chain of Thought",
    "authors": [
      "Gilad Yehudai",
      "Noah Amsel",
      "Joan Bruna"
    ],
    "abstract": "We study and compare the expressive power of transformers, RNNs, and\ntransformers with chain of thought tokens on a simple and natural class of\nproblems we term Compositional Reasoning Questions (CRQ). This family captures\nproblems like evaluating Boolean formulas and multi-step word problems.\nAssuming standard hardness assumptions from circuit complexity and\ncommunication complexity, we prove that none of these three architectures is\ncapable of solving CRQs unless some hyperparameter (depth, embedding dimension,\nand number of chain of thought tokens, respectively) grows with the size of the\ninput. We also provide a construction for each architecture that solves CRQs.\nFor transformers, our construction uses depth that is logarithmic in the\nproblem size. For RNNs, logarithmic embedding dimension is necessary and\nsufficient, so long as the inputs are provided in a certain order. (Otherwise,\na linear dimension is necessary). For transformers with chain of thought, our\nconstruction uses $n$ CoT tokens. These results show that, while CRQs are\ninherently hard, there are several different ways for language models to\novercome this hardness. Even for a single class of problems, each architecture\nhas strengths and weaknesses, and none is strictly better than the others.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01544v1",
    "published_date": "2025-03-03 13:52:45 UTC",
    "updated_date": "2025-03-03 13:52:45 UTC"
  },
  {
    "arxiv_id": "2503.01542v1",
    "title": "Revisiting Large Language Model Pruning using Neuron Semantic Attribution",
    "authors": [
      "Yizhuo Ding",
      "Xinwei Sun",
      "Yanwei Fu",
      "Guosheng Hu"
    ],
    "abstract": "Model pruning technique is vital for accelerating large language models by\nreducing their size and computational requirements. However, the\ngeneralizability of existing pruning methods across diverse datasets and tasks\nremains unclear. Thus, we conduct extensive evaluations on 24 datasets and 4\ntasks using popular pruning methods. Based on these evaluations, we find and\nthen investigate that calibration set greatly affect the performance of pruning\nmethods. In addition, we surprisingly find a significant performance drop of\nexisting pruning methods in sentiment classification tasks. To understand the\nlink between performance drop and pruned neurons, we propose Neuron Semantic\nAttribution, which learns to associate each neuron with specific semantics.\nThis method first makes the unpruned neurons of LLMs explainable.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01542v1",
    "published_date": "2025-03-03 13:52:17 UTC",
    "updated_date": "2025-03-03 13:52:17 UTC"
  },
  {
    "arxiv_id": "2503.01539v1",
    "title": "Pragmatic Inference Chain (PIC) Improving LLMs' Reasoning of Authentic Implicit Toxic Language",
    "authors": [
      "Xi Chen",
      "Shuo Wang"
    ],
    "abstract": "The rapid development of large language models (LLMs) gives rise to ethical\nconcerns about their performance, while opening new avenues for developing\ntoxic language detection techniques. However, LLMs' unethical output and their\ncapability of detecting toxicity have primarily been tested on language data\nthat do not demand complex meaning inference, such as the biased associations\nof 'he' with programmer and 'she' with household. Nowadays toxic language\nadopts a much more creative range of implicit forms, thanks to advanced\ncensorship. In this study, we collect authentic toxic interactions that evade\nonline censorship and that are verified by human annotators as inference\nintensive. To evaluate and improve LLMs' reasoning of the authentic implicit\ntoxic language, we propose a new prompting method, Pragmatic Inference Chain\n(PIC), drawn on interdisciplinary findings from cognitive science and\nlinguistics. The PIC prompting significantly improves the success rate of\nGPT-4o, Llama-3.1-70B-Instruct, and DeepSeek-v2.5 in identifying implicit toxic\nlanguage, compared to both direct prompting and Chain-of-Thought. In addition,\nit also facilitates the models to produce more explicit and coherent reasoning\nprocesses, hence can potentially be generalized to other inference-intensive\ntasks, e.g., understanding humour and metaphors.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "12 pages, 4 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2503.01539v1",
    "published_date": "2025-03-03 13:51:05 UTC",
    "updated_date": "2025-03-03 13:51:05 UTC"
  },
  {
    "arxiv_id": "2503.01536v1",
    "title": "Entailment vs. Verification for Partial-assignment Satisfiability and Enumeration",
    "authors": [
      "Roberto Sebastiani"
    ],
    "abstract": "Many procedures for SAT-related problems, in particular for those requiring\nthe complete enumeration of satisfying truth assignments, rely their efficiency\nand effectiveness on the detection of (possibly small) partial assignments\nsatisfying an input formula. Surprisingly, there seems to be no unique\nuniversally-agreed definition of formula satisfaction by a partial assignment\nin the literature. In this paper we analyze in deep the issue of satisfaction\nby partial assignments, raising a flag about some ambiguities and subtleties of\nthis concept, and investigating their practical consequences. We identify two\nalternative notions that are implicitly used in the literature, namely\nverification and entailment, which coincide if applied to CNF formulas but\ndiffer and present complementary properties if applied to non-CNF or to\nexistentially-quantified formulas. We show that, although the former is easier\nto check and as such is implicitly used by most current search procedures, the\nlatter has better theoretical properties, and can improve the efficiency and\neffectiveness of enumeration procedures.",
    "categories": [
      "cs.LO",
      "cs.AI"
    ],
    "primary_category": "cs.LO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01536v1",
    "published_date": "2025-03-03 13:49:11 UTC",
    "updated_date": "2025-03-03 13:49:11 UTC"
  },
  {
    "arxiv_id": "2503.01508v2",
    "title": "Enabling AI Scientists to Recognize Innovation: A Domain-Agnostic Algorithm for Assessing Novelty",
    "authors": [
      "Yao Wang",
      "Mingxuan Cui",
      "Arthur Jiang"
    ],
    "abstract": "In the pursuit of Artificial General Intelligence (AGI), automating the\ngeneration and evaluation of novel research ideas is a key challenge in\nAI-driven scientific discovery. This paper presents Relative Neighbor Density\n(RND), a domain-agnostic algorithm for novelty assessment in research ideas\nthat overcomes the limitations of existing approaches by comparing an idea's\nlocal density with its adjacent neighbors' densities. We first developed a\nscalable methodology to create test set without expert labeling, addressing a\nfundamental challenge in novelty assessment. Using these test sets, we\ndemonstrate that our RND algorithm achieves state-of-the-art (SOTA) performance\nin computer science (AUROC=0.820) and biomedical research (AUROC=0.765)\ndomains. Most significantly, while SOTA models like Sonnet-3.7 and existing\nmetrics show domain-specific performance degradation, RND maintains consistent\naccuracies across domains by its domain-invariant property, outperforming all\nbenchmarks by a substantial margin (0.795 v.s. 0.597) on cross-domain\nevaluation. These results validate RND as a generalizable solution for\nautomated novelty assessment in scientific research.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01508v2",
    "published_date": "2025-03-03 13:22:39 UTC",
    "updated_date": "2025-03-10 06:21:15 UTC"
  },
  {
    "arxiv_id": "2503.01507v2",
    "title": "Compare different SG-Schemes based on large least square problems",
    "authors": [
      "Ramkrishna Acharya"
    ],
    "abstract": "This study reviews popular stochastic gradient-based schemes based on large\nleast-square problems. These schemes, often called optimizers in machine\nlearning, play a crucial role in finding better model parameters. Hence, this\nstudy focuses on viewing such optimizers with different hyper-parameters and\nanalyzing them based on least square problems. Codes that produced results in\nthis work are available on\nhttps://github.com/q-viper/gradients-based-methods-on-large-least-square.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01507v2",
    "published_date": "2025-03-03 13:22:37 UTC",
    "updated_date": "2025-03-04 08:47:15 UTC"
  },
  {
    "arxiv_id": "2503.01505v1",
    "title": "Lossy Neural Compression for Geospatial Analytics: A Review",
    "authors": [
      "Carlos Gomes",
      "Isabelle Wittmann",
      "Damien Robert",
      "Johannes Jakubik",
      "Tim Reichelt",
      "Michele Martone",
      "Stefano Maurogiovanni",
      "Rikard Vinge",
      "Jonas Hurst",
      "Erik Scheurer",
      "Rocco Sedona",
      "Thomas Brunschwiler",
      "Stefan Kesselheim",
      "Matej Batic",
      "Philip Stier",
      "Jan Dirk Wegner",
      "Gabriele Cavallaro",
      "Edzer Pebesma",
      "Michael Marszalek",
      "Miguel A Belenguer-Plomer",
      "Kennedy Adriko",
      "Paolo Fraccaro",
      "Romeo Kienzler",
      "Rania Briq",
      "Sabrina Benassou",
      "Michele Lazzarini",
      "Conrad M Albrecht"
    ],
    "abstract": "Over the past decades, there has been an explosion in the amount of available\nEarth Observation (EO) data. The unprecedented coverage of the Earth's surface\nand atmosphere by satellite imagery has resulted in large volumes of data that\nmust be transmitted to ground stations, stored in data centers, and distributed\nto end users. Modern Earth System Models (ESMs) face similar challenges,\noperating at high spatial and temporal resolutions, producing petabytes of data\nper simulated day. Data compression has gained relevance over the past decade,\nwith neural compression (NC) emerging from deep learning and information\ntheory, making EO data and ESM outputs ideal candidates due to their abundance\nof unlabeled data. In this review, we outline recent developments in NC applied\nto geospatial data. We introduce the fundamental concepts of NC including\nseminal works in its traditional applications to image and video compression\ndomains with focus on lossy compression. We discuss the unique characteristics\nof EO and ESM data, contrasting them with \"natural images\", and explain the\nadditional challenges and opportunities they present. Moreover, we review\ncurrent applications of NC across various EO modalities and explore the limited\nefforts in ESM compression to date. The advent of self-supervised learning\n(SSL) and foundation models (FM) has advanced methods to efficiently distill\nrepresentations from vast unlabeled data. We connect these developments to NC\nfor EO, highlighting the similarities between the two fields and elaborate on\nthe potential of transferring compressed feature representations for\nmachine--to--machine communication. Based on insights drawn from this review,\nwe devise future directions relevant to applications in EO and ESM.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "physics.geo-ph"
    ],
    "primary_category": "eess.SP",
    "comment": "self-consistent review paper",
    "pdf_url": "http://arxiv.org/pdf/2503.01505v1",
    "published_date": "2025-03-03 13:19:43 UTC",
    "updated_date": "2025-03-03 13:19:43 UTC"
  },
  {
    "arxiv_id": "2503.02905v1",
    "title": "Machine Learning Applications to Diffuse Reflectance Spectroscopy in Optical Diagnosis; A Systematic Review",
    "authors": [
      "Nicola Rossberg",
      "Celina L. Li",
      "Simone Innocente",
      "Stefan Andersson-Engels",
      "Katarzyna Komolibus",
      "Barry O'Sullivan",
      "Andrea Visentin"
    ],
    "abstract": "Diffuse Reflectance Spectroscopy has demonstrated a strong aptitude for\nidentifying and differentiating biological tissues. However, the broadband and\nsmooth nature of these signals require algorithmic processing, as they are\noften difficult for the human eye to distinguish. The implementation of machine\nlearning models for this task has demonstrated high levels of diagnostic\naccuracies and led to a wide range of proposed methodologies for applications\nin various illnesses and conditions. In this systematic review, we summarise\nthe state of the art of these applications, highlight current gaps in research\nand identify future directions. This review was conducted in accordance with\nthe PRISMA guidelines. 77 studies were retrieved and in-depth analysis was\nconducted. It is concluded that diffuse reflectance spectroscopy and machine\nlearning have strong potential for tissue differentiation in clinical\napplications, but more rigorous sample stratification in tandem with in-vivo\nvalidation and explainable algorithm development is required going forward.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "68Txx",
      "J.3"
    ],
    "primary_category": "eess.IV",
    "comment": "52 pages, Preprint, Systematic Review",
    "pdf_url": "http://arxiv.org/pdf/2503.02905v1",
    "published_date": "2025-03-03 13:10:16 UTC",
    "updated_date": "2025-03-03 13:10:16 UTC"
  },
  {
    "arxiv_id": "2503.01496v1",
    "title": "Liger: Linearizing Large Language Models to Gated Recurrent Structures",
    "authors": [
      "Disen Lan",
      "Weigao Sun",
      "Jiaxi Hu",
      "Jusen Du",
      "Yu Cheng"
    ],
    "abstract": "Transformers with linear recurrent modeling offer linear-time training and\nconstant-memory inference. Despite their demonstrated efficiency and\nperformance, pretraining such non-standard architectures from scratch remains\ncostly and risky. The linearization of large language models (LLMs) transforms\npretrained standard models into linear recurrent structures, enabling more\nefficient deployment. However, current linearization methods typically\nintroduce additional feature map modules that require extensive fine-tuning and\noverlook the gating mechanisms used in state-of-the-art linear recurrent\nmodels. To address these issues, this paper presents Liger, short for\nLinearizing LLMs to gated recurrent structures. Liger is a novel approach for\nconverting pretrained LLMs into gated linear recurrent models without adding\nextra parameters. It repurposes the pretrained key matrix weights to construct\ndiverse gating mechanisms, facilitating the formation of various gated\nrecurrent structures while avoiding the need to train additional components\nfrom scratch. Using lightweight fine-tuning with Low-Rank Adaptation (LoRA),\nLiger restores the performance of the linearized gated recurrent models to\nmatch that of the original LLMs. Additionally, we introduce Liger Attention, an\nintra-layer hybrid attention mechanism, which significantly recovers 93\\% of\nthe Transformer-based LLM at 0.02\\% pre-training tokens during the\nlinearization process, achieving competitive results across multiple\nbenchmarks, as validated on models ranging from 1B to 8B parameters. Code is\navailable at https://github.com/OpenSparseLLMs/Linearization.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Technical report, 13 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.01496v1",
    "published_date": "2025-03-03 13:08:00 UTC",
    "updated_date": "2025-03-03 13:08:00 UTC"
  },
  {
    "arxiv_id": "2503.01940v1",
    "title": "AskToAct: Enhancing LLMs Tool Use via Self-Correcting Clarification",
    "authors": [
      "Xuan Zhang",
      "Yongliang Shen",
      "Zhe Zheng",
      "Linjuan Wu",
      "Wenqi Zhang",
      "Yuchen Yan",
      "Qiuying Peng",
      "Jun Wang",
      "Weiming Lu"
    ],
    "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in\ntool learning. In real-world scenarios, user queries are often ambiguous and\nincomplete, requiring effective clarification. However, existing interactive\nclarification approaches face two critical limitations: reliance on manually\nconstructed datasets and lack of error correction mechanisms during multi-turn\nclarification. We present AskToAct, which addresses these challenges by\nexploiting the structural mapping between queries and their tool invocation\nsolutions. Our key insight is that tool parameters naturally represent explicit\nuser intents. By systematically removing key parameters from queries while\nretaining them as ground truth, we enable automated construction of\nhigh-quality training data. We further enhance model robustness by fine-tuning\non error-correction augmented data using selective masking mechanism, enabling\ndynamic error detection during clarification interactions. Comprehensive\nexperiments demonstrate that AskToAct significantly outperforms existing\napproaches, achieving above 79% accuracy in recovering critical unspecified\nintents and enhancing clarification efficiency by an average of 48.34% while\nmaintaining high accuracy in tool invocation. Our framework exhibits robust\nperformance across varying complexity levels and successfully generalizes to\nentirely unseen APIs without additional training, achieving performance\ncomparable to GPT-4 with substantially fewer computational resources.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01940v1",
    "published_date": "2025-03-03 12:55:49 UTC",
    "updated_date": "2025-03-03 12:55:49 UTC"
  },
  {
    "arxiv_id": "2503.01478v5",
    "title": "SePer: Measure Retrieval Utility Through The Lens Of Semantic Perplexity Reduction",
    "authors": [
      "Lu Dai",
      "Yijie Xu",
      "Jinhui Ye",
      "Hao Liu",
      "Hui Xiong"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated improved generation\nperformance by incorporating externally retrieved knowledge, a process known as\nretrieval-augmented generation (RAG). Despite the potential of this approach,\nexisting studies evaluate RAG effectiveness by 1) assessing retrieval and\ngeneration components jointly, which obscures retrieval's distinct\ncontribution, or 2) examining retrievers using traditional metrics such as\nNDCG, which creates a gap in understanding retrieval's true utility in the\noverall generation process. To address the above limitations, in this work, we\nintroduce an automatic evaluation method that measures retrieval quality\nthrough the lens of information gain within the RAG framework. Specifically, we\npropose Semantic Perplexity (SePer), a metric that captures the LLM's internal\nbelief about the correctness of the retrieved information. We quantify the\nutility of retrieval by the extent to which it reduces semantic perplexity\npost-retrieval. Extensive experiments demonstrate that SePer not only aligns\nclosely with human preferences but also offers a more precise and efficient\nevaluation of retrieval utility across diverse RAG scenarios.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "ICLR 2025 Spotlight",
    "pdf_url": "http://arxiv.org/pdf/2503.01478v5",
    "published_date": "2025-03-03 12:37:34 UTC",
    "updated_date": "2025-03-20 11:28:41 UTC"
  },
  {
    "arxiv_id": "2503.01475v1",
    "title": "ProRCA: A Causal Python Package for Actionable Root Cause Analysis in Real-world Business Scenarios",
    "authors": [
      "Ahmed Dawoud",
      "Shravan Talupula"
    ],
    "abstract": "Root Cause Analysis (RCA) is becoming ever more critical as modern systems\ngrow in complexity, volume of data, and interdependencies. While traditional\nRCA methods frequently rely on correlation-based or rule-based techniques,\nthese approaches can prove inadequate in highly dynamic, multi-layered\nenvironments. In this paper, we present a pathway-tracing package built on the\nDoWhy causal inference library. Our method integrates conditional anomaly\nscoring, noise-based attribution, and depth-first path exploration to reveal\nmulti-hop causal chains. By systematically tracing entire causal pathways from\nan observed anomaly back to the initial triggers, our approach provides a\ncomprehensive, end-to-end RCA solution. Experimental evaluations with synthetic\nanomaly injections demonstrate the package's ability to accurately isolate\ntriggers and rank root causes by their overall significance.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01475v1",
    "published_date": "2025-03-03 12:33:17 UTC",
    "updated_date": "2025-03-03 12:33:17 UTC"
  },
  {
    "arxiv_id": "2503.01470v1",
    "title": "Position: Ensuring mutual privacy is necessary for effective external evaluation of proprietary AI systems",
    "authors": [
      "Ben Bucknall",
      "Robert F. Trager",
      "Michael A. Osborne"
    ],
    "abstract": "The external evaluation of AI systems is increasingly recognised as a crucial\napproach for understanding their potential risks. However, facilitating\nexternal evaluation in practice faces significant challenges in balancing\nevaluators' need for system access with AI developers' privacy and security\nconcerns. Additionally, evaluators have reason to protect their own privacy -\nfor example, in order to maintain the integrity of held-out test sets. We refer\nto the challenge of ensuring both developers' and evaluators' privacy as one of\nproviding mutual privacy. In this position paper, we argue that (i) addressing\nthis mutual privacy challenge is essential for effective external evaluation of\nAI systems, and (ii) current methods for facilitating external evaluation\ninadequately address this challenge, particularly when it comes to preserving\nevaluators' privacy. In making these arguments, we formalise the mutual privacy\nproblem; examine the privacy and access requirements of both model owners and\nevaluators; and explore potential solutions to this challenge, including\nthrough the application of cryptographic and hardware-based approaches.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01470v1",
    "published_date": "2025-03-03 12:24:59 UTC",
    "updated_date": "2025-03-03 12:24:59 UTC"
  },
  {
    "arxiv_id": "2503.01464v1",
    "title": "Rethinking Data: Towards Better Performing Domain-Specific Small Language Models",
    "authors": [
      "Boris Nazarov",
      "Darya Frolova",
      "Yackov Lubarsky",
      "Alexei Gaissinski",
      "Pavel Kisilev"
    ],
    "abstract": "Fine-tuning of Large Language Models (LLMs) for downstream tasks, performed\non domain-specific data has shown significant promise. However, commercial use\nof such LLMs is limited by the high computational cost required for their\ndeployment at scale. On the other hand, small Language Models (LMs) are much\nmore cost effective but have subpar performance in a similar setup. This paper\npresents our approach to finetuning a small LM, that reaches high accuracy in\nmultiple choice question answering task. We achieve this by improving data\nquality at each stage of the LM training pipeline. In particular, we start with\ndata structuring resulting in extraction of compact, semantically meaningful\ntext chunks used by a retriever. This allows more efficient knowledge digestion\nby the LM. Further, we improve the retrieved context by training a lightweight\nChunk Re-Ranker (CRR) that generates more accurate relative relevance chunk\nscores. Finally, we improve the model generalization ability by merging the\nmodels fine-tuned with different parameters on different data subsets. We\npresent detailed procedure descriptions, and corresponding experimental\nfindings that show the improvements of each one of the proposed techniques.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01464v1",
    "published_date": "2025-03-03 12:19:12 UTC",
    "updated_date": "2025-03-03 12:19:12 UTC"
  },
  {
    "arxiv_id": "2503.01461v1",
    "title": "Towards Widening The Distillation Bottleneck for Reasoning Models",
    "authors": [
      "Huifeng Yin",
      "Yu Zhao",
      "Minghao Wu",
      "Xuanfan Ni",
      "Bo Zeng",
      "Hao Wang",
      "Tianqi Shi",
      "Liangying Shao",
      "Chenyang Lyu",
      "Longyue Wang",
      "Weihua Luo",
      "Kaifu Zhang"
    ],
    "abstract": "Large Reasoning Models(LRMs) such as OpenAI o1 and DeepSeek-R1 have shown\nremarkable reasoning capabilities by scaling test-time compute and generating\nlong Chain-of-Thought(CoT). Distillation--post-training on LRMs-generated\ndata--is a straightforward yet effective method to enhance the reasoning\nabilities of smaller models, but faces a critical bottleneck: we found that\ndistilled long CoT data poses learning difficulty for small models and leads to\nthe inheritance of biases (i.e. over-thinking) when using Supervised\nFine-tuning(SFT) and Reinforcement Learning(RL) methods. To alleviate this\nbottleneck, we propose constructing tree-based CoT data from scratch via Monte\nCarlo Tree Search(MCTS). We then exploit a set of CoT-aware approaches,\nincluding Thoughts Length Balance, Fine-grained DPO, and Joint Post-training\nObjective, to enhance SFT and RL on the construted data.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01461v1",
    "published_date": "2025-03-03 12:17:36 UTC",
    "updated_date": "2025-03-03 12:17:36 UTC"
  },
  {
    "arxiv_id": "2503.01458v1",
    "title": "SrSv: Integrating Sequential Rollouts with Sequential Value Estimation for Multi-agent Reinforcement Learning",
    "authors": [
      "Xu Wan",
      "Chao Yang",
      "Cheng Yang",
      "Jie Song",
      "Mingyang Sun"
    ],
    "abstract": "Although multi-agent reinforcement learning (MARL) has shown its success\nacross diverse domains, extending its application to large-scale real-world\nsystems still faces significant challenges. Primarily, the high complexity of\nreal-world environments exacerbates the credit assignment problem,\nsubstantially reducing training efficiency. Moreover, the variability of agent\npopulations in large-scale scenarios necessitates scalable decision-making\nmechanisms. To address these challenges, we propose a novel framework:\nSequential rollout with Sequential value estimation (SrSv). This framework aims\nto capture agent interdependence and provide a scalable solution for\ncooperative MARL. Specifically, SrSv leverages the autoregressive property of\nthe Transformer model to handle varying populations through sequential action\nrollout. Furthermore, to capture the interdependence of policy distributions\nand value functions among multiple agents, we introduce an innovative\nsequential value estimation methodology and integrates the value approximation\ninto an attention-based sequential model. We evaluate SrSv on three benchmarks:\nMulti-Agent MuJoCo, StarCraft Multi-Agent Challenge, and DubinsCars.\nExperimental results demonstrate that SrSv significantly outperforms baseline\nmethods in terms of training efficiency without compromising convergence\nperformance. Moreover, when implemented in a large-scale DubinsCar system with\n1,024 agents, our framework surpasses existing benchmarks, highlighting the\nexcellent scalability of SrSv.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01458v1",
    "published_date": "2025-03-03 12:17:18 UTC",
    "updated_date": "2025-03-03 12:17:18 UTC"
  },
  {
    "arxiv_id": "2503.01457v1",
    "title": "Structural Deep Encoding for Table Question Answering",
    "authors": [
      "Raphaël Mouravieff",
      "Benjamin Piwowarski",
      "Sylvain Lamprier"
    ],
    "abstract": "Although Transformers-based architectures excel at processing textual\ninformation, their naive adaptation for tabular data often involves flattening\nthe table structure. This simplification can lead to the loss of essential\ninter-dependencies between rows, columns, and cells, while also posing\nscalability challenges for large tables. To address these issues, prior works\nhave explored special tokens, structured embeddings, and sparse attention\npatterns. In this paper, we conduct a comprehensive analysis of tabular\nencoding techniques, which highlights the crucial role of attention sparsity in\npreserving structural information of tables. We also introduce a set of novel\nsparse attention mask designs for tabular data, that not only enhance\ncomputational efficiency but also preserve structural integrity, leading to\nbetter overall performance.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.01457v1",
    "published_date": "2025-03-03 12:16:43 UTC",
    "updated_date": "2025-03-03 12:16:43 UTC"
  },
  {
    "arxiv_id": "2503.01453v1",
    "title": "AC-Lite : A Lightweight Image Captioning Model for Low-Resource Assamese Language",
    "authors": [
      "Pankaj Choudhury",
      "Yogesh Aggarwal",
      "Prithwijit Guha",
      "Sukumar Nandi"
    ],
    "abstract": "Neural networks have significantly advanced AI applications, yet their\nreal-world adoption remains constrained by high computational demands, hardware\nlimitations, and accessibility challenges. In image captioning, many\nstate-of-the-art models have achieved impressive performances while relying on\nresource-intensive architectures. This made them impractical for deployment on\nresource-constrained devices. This limitation is particularly noticeable for\napplications involving low-resource languages. We demonstrate the case of image\ncaptioning in Assamese language, where lack of effective, scalable systems can\nrestrict the accessibility of AI-based solutions for native Assamese speakers.\nThis work presents AC-Lite, a computationally efficient model for image\ncaptioning in low-resource Assamese language. AC-Lite reduces computational\nrequirements by replacing computation-heavy visual feature extractors like\nFasterRCNN with lightweight ShuffleNetv2x1.5. Additionally, Gated Recurrent\nUnits (GRUs) are used as the caption decoder to further reduce computational\ndemands and model parameters. Furthermore, the integration of bilinear\nattention enhances the model's overall performance. AC-Lite can operate on edge\ndevices, thereby eliminating the need for computation on remote servers. The\nproposed AC-Lite model achieves 82.3 CIDEr score on the COCO-AC dataset with\n1.098 GFLOPs and 25.65M parameters.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01453v1",
    "published_date": "2025-03-03 12:07:52 UTC",
    "updated_date": "2025-03-03 12:07:52 UTC"
  },
  {
    "arxiv_id": "2503.04803v1",
    "title": "An energy-efficient learning solution for the Agile Earth Observation Satellite Scheduling Problem",
    "authors": [
      "Antonio M. Mercado-Martínez",
      "Beatriz Soret",
      "Antonio Jurado-Navas"
    ],
    "abstract": "The Agile Earth Observation Satellite Scheduling Problem (AEOSSP) entails\nfinding the subset of observation targets to be scheduled along the satellite's\norbit while meeting operational constraints of time, energy and memory. The\nproblem of deciding what and when to observe is inherently complex, and becomes\neven more challenging when considering several issues that compromise the\nquality of the captured images, such as cloud occlusion, atmospheric\nturbulence, and image resolution. This paper presents a Deep Reinforcement\nLearning (DRL) approach for addressing the AEOSSP with time-dependent profits,\nintegrating these three factors to optimize the use of energy and memory\nresources. The proposed method involves a dual decision-making process:\nselecting the sequence of targets and determining the optimal observation time\nfor each. Our results demonstrate that the proposed algorithm reduces the\ncapture of images that fail to meet quality requirements by > 60% and\nconsequently decreases energy waste from attitude maneuvers by up to 78%, all\nwhile maintaining strong observation performance.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "This paper has been accepted for presentation at the IEEE\n  International Conference on Machine Learning for Communication and Networking\n  (ICMLCN) Special Sessions 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.04803v1",
    "published_date": "2025-03-03 12:01:27 UTC",
    "updated_date": "2025-03-03 12:01:27 UTC"
  },
  {
    "arxiv_id": "2503.01450v2",
    "title": "POPGym Arcade: Parallel Pixelated POMDPs",
    "authors": [
      "Zekang Wang",
      "Zhe He",
      "Edan Toledo",
      "Steven Morad"
    ],
    "abstract": "We introduce POPGym Arcade, a benchmark consisting of 7 pixel-based\nenvironments each with three difficulties, utilizing a single observation and\naction space. Each environment offers both fully observable and partially\nobservable variants, enabling counterfactual studies on partial observability.\nPOPGym Arcade utilizes JIT compilation on hardware accelerators to achieve\nsubstantial speedups over CPU-bound environments. Moreover, this enables\nPodracer-style architectures to further increase hardware utilization and\ntraining speed. We evaluate memory models on our environments using a Podracer\nvariant of Q learning, and examine the results. Finally, we generate memory\nsaliency maps, uncovering how memories propagate through policies. Our library\nis available at https://github.com/bolt-research/popgym_arcade.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01450v2",
    "published_date": "2025-03-03 11:59:03 UTC",
    "updated_date": "2025-03-04 05:23:52 UTC"
  },
  {
    "arxiv_id": "2503.01442v1",
    "title": "Leveraging LLMs for Mental Health: Detection and Recommendations from Social Discussions",
    "authors": [
      "Vaishali Aggarwal",
      "Sachin Thukral",
      "Krushil Patel",
      "Arnab Chatterjee"
    ],
    "abstract": "Textual data from social platforms captures various aspects of mental health\nthrough discussions around and across issues, while users reach out for help\nand others sympathize and offer support. We propose a comprehensive framework\nthat leverages Natural Language Processing (NLP) and Generative AI techniques\nto identify and assess mental health disorders, detect their severity, and\ncreate recommendations for behavior change and therapeutic interventions based\non users' posts on Reddit.\n  To classify the disorders, we use rule-based labeling methods as well as\nadvanced pre-trained NLP models to extract nuanced semantic features from the\ndata. We fine-tune domain-adapted and generic pre-trained NLP models based on\npredictions from specialized Large Language Models (LLMs) to improve\nclassification accuracy. Our hybrid approach combines the generalization\ncapabilities of pre-trained models with the domain-specific insights captured\nby LLMs, providing an improved understanding of mental health discourse. Our\nfindings highlight the strengths and limitations of each model, offering\nvaluable insights into their practical applicability.\n  This research potentially facilitates early detection and personalized care\nto aid practitioners and aims to facilitate timely interventions and improve\noverall well-being, thereby contributing to the broader field of mental health\nsurveillance and digital health analytics.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.SI",
    "comment": "5 pages, 4 figures, 3 tables, to be published in WI-IAT 2024",
    "pdf_url": "http://arxiv.org/pdf/2503.01442v1",
    "published_date": "2025-03-03 11:48:01 UTC",
    "updated_date": "2025-03-03 11:48:01 UTC"
  },
  {
    "arxiv_id": "2503.01437v1",
    "title": "Eau De $Q$-Network: Adaptive Distillation of Neural Networks in Deep Reinforcement Learning",
    "authors": [
      "Théo Vincent",
      "Tim Faust",
      "Yogesh Tripathi",
      "Jan Peters",
      "Carlo D'Eramo"
    ],
    "abstract": "Recent works have successfully demonstrated that sparse deep reinforcement\nlearning agents can be competitive against their dense counterparts. This opens\nup opportunities for reinforcement learning applications in fields where\ninference time and memory requirements are cost-sensitive or limited by\nhardware. Until now, dense-to-sparse methods have relied on hand-designed\nsparsity schedules that are not synchronized with the agent's learning pace.\nCrucially, the final sparsity level is chosen as a hyperparameter, which\nrequires careful tuning as setting it too high might lead to poor performances.\nIn this work, we address these shortcomings by crafting a dense-to-sparse\nalgorithm that we name Eau De $Q$-Network (EauDeQN). To increase sparsity at\nthe agent's learning pace, we consider multiple online networks with different\nsparsity levels, where each online network is trained from a shared target\nnetwork. At each target update, the online network with the smallest loss is\nchosen as the next target network, while the other networks are replaced by a\npruned version of the chosen network. We evaluate the proposed approach on the\nAtari $2600$ benchmark and the MuJoCo physics simulator, showing that EauDeQN\nreaches high sparsity levels while keeping performances high.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at RLDM",
    "pdf_url": "http://arxiv.org/pdf/2503.01437v1",
    "published_date": "2025-03-03 11:39:03 UTC",
    "updated_date": "2025-03-03 11:39:03 UTC"
  },
  {
    "arxiv_id": "2503.04802v1",
    "title": "The order in speech disorder: a scoping review of state of the art machine learning methods for clinical speech classification",
    "authors": [
      "Birger Moell",
      "Fredrik Sand Aronsson",
      "Per Östberg",
      "Jonas Beskow"
    ],
    "abstract": "Background:Speech patterns have emerged as potential diagnostic markers for\nconditions with varying etiologies. Machine learning (ML) presents an\nopportunity to harness these patterns for accurate disease diagnosis.\n  Objective: This review synthesized findings from studies exploring ML's\ncapability in leveraging speech for the diagnosis of neurological, laryngeal\nand mental disorders.\n  Methods: A systematic examination of 564 articles was conducted with 91\narticles included in the study, which encompassed a wide spectrum of\nconditions, ranging from voice pathologies to mental and neurological\ndisorders. Methods for speech classifications were assessed based on the\nrelevant studies and scored between 0-10 based on the reported diagnostic\naccuracy of their ML models.\n  Results: High diagnostic accuracies were consistently observed for laryngeal\ndisorders, dysarthria, and changes related to speech in Parkinsons disease.\nThese findings indicate the robust potential of speech as a diagnostic tool.\nDisorders like depression, schizophrenia, mild cognitive impairment and\nAlzheimers dementia also demonstrated high accuracies, albeit with some\nvariability across studies. Meanwhile, disorders like OCD and autism\nhighlighted the need for more extensive research to ascertain the relationship\nbetween speech patterns and the respective conditions.\n  Conclusion: ML models utilizing speech patterns demonstrate promising\npotential in diagnosing a range of mental, laryngeal, and neurological\ndisorders. However, the efficacy varies across conditions, and further research\nis needed. The integration of these models into clinical practice could\npotentially revolutionize the evaluation and diagnosis of a number of different\nmedical conditions.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04802v1",
    "published_date": "2025-03-03 11:33:02 UTC",
    "updated_date": "2025-03-03 11:33:02 UTC"
  },
  {
    "arxiv_id": "2503.01424v1",
    "title": "From Hypothesis to Publication: A Comprehensive Survey of AI-Driven Research Support Systems",
    "authors": [
      "Zekun Zhou",
      "Xiaocheng Feng",
      "Lei Huang",
      "Xiachong Feng",
      "Ziyun Song",
      "Ruihan Chen",
      "Liang Zhao",
      "Weitao Ma",
      "Yuxuan Gu",
      "Baoxin Wang",
      "Dayong Wu",
      "Guoping Hu",
      "Ting Liu",
      "Bing Qin"
    ],
    "abstract": "Research is a fundamental process driving the advancement of human\ncivilization, yet it demands substantial time and effort from researchers. In\nrecent years, the rapid development of artificial intelligence (AI)\ntechnologies has inspired researchers to explore how AI can accelerate and\nenhance research. To monitor relevant advancements, this paper presents a\nsystematic review of the progress in this domain. Specifically, we organize the\nrelevant studies into three main categories: hypothesis formulation, hypothesis\nvalidation, and manuscript publication. Hypothesis formulation involves\nknowledge synthesis and hypothesis generation. Hypothesis validation includes\nthe verification of scientific claims, theorem proving, and experiment\nvalidation. Manuscript publication encompasses manuscript writing and the peer\nreview process. Furthermore, we identify and discuss the current challenges\nfaced in these areas, as well as potential future directions for research.\nFinally, we also offer a comprehensive overview of existing benchmarks and\ntools across various domains that support the integration of AI into the\nresearch process. We hope this paper serves as an introduction for beginners\nand fosters future research. Resources have been made publicly available at\nhttps://github.com/zkzhou126/AI-for-Research.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01424v1",
    "published_date": "2025-03-03 11:27:13 UTC",
    "updated_date": "2025-03-03 11:27:13 UTC"
  },
  {
    "arxiv_id": "2503.01422v1",
    "title": "Sampling-Efficient Test-Time Scaling: Self-Estimating the Best-of-N Sampling in Early Decoding",
    "authors": [
      "Yiming Wang",
      "Pei Zhang",
      "Siyuan Huang",
      "Baosong Yang",
      "Zhuosheng Zhang",
      "Fei Huang",
      "Rui Wang"
    ],
    "abstract": "Test-time scaling improves large language model performance by adding extra\ncompute during decoding. Best-of-N (BoN) sampling serves as a common scaling\ntechnique, broadening the search space for finding better solutions from the\nmodel distribution. However, traditional BoN requires N full generations,\nleading to high GPU memory overhead and time latency. Moreover, some methods\ndepend on reward models, adding computational cost and limiting domain\ngeneralization.\n  In this paper, we propose Self-Truncation Best-of-N (ST-BoN), a novel\ndecoding method that avoids fully generating all samplings and eliminates the\nneed for reward models. ST-BoN introduces early sampling consistency to\nestimate the most promising sample, truncating suboptimal ones to free memory\nand accelerate inference. This pushes the sampling-efficient test-time scaling.\nCompared to traditional BoN, ST-BoN can reduce dynamic GPU memory overhead by\nover 90% and time latency by 50%, while achieving comparable or even better\nperformance across reasoning and open-ended domains.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "23 pages, 14 figures, 8 tables",
    "pdf_url": "http://arxiv.org/pdf/2503.01422v1",
    "published_date": "2025-03-03 11:21:01 UTC",
    "updated_date": "2025-03-03 11:21:01 UTC"
  },
  {
    "arxiv_id": "2503.01419v1",
    "title": "Parameter-Efficient Fine-Tuning of Large Language Models via Deconvolution in Subspace",
    "authors": [
      "Jia-Chen Zhang",
      "Yu-Jie Xiong",
      "Chun-Ming Xia",
      "Dong-Hai Zhu",
      "Xi-He Qiu"
    ],
    "abstract": "Large language model (LLM) is considered a milestone towards achieving\nArtificial General Intelligence (AGI). With its advanced emergent capabilities,\nit adapt to a wide range of specific applications. Fine-tuning LLMs for various\ndownstream tasks has become a new paradigm. Low-Rank Adaptation (LoRA) is\nwell-known for its parameter efficiency. It can reduce the number of parameters\nneeded to fine-tune LLMs by several orders of magnitude. However, LoRA-based\napproaches encounter a significant limitation due to the bottleneck imposed by\nrank one decomposition. As the parameters count in LLMs increase, even rank one\ndecomposition might surpass the number of parameters truly necessary for\nhandling more downstream tasks. In this paper, we propose a new method for\nParameter-Efficient Fine-Tuning (PEFT) via deconvolution in subspace, dubbed as\nDCFT. We innovatively use deconvolution to complete details and enhance\nknowledge in subspace incremental matrices, and dynamically control parameters\nby adjusting the kernel size, unconstrained by rank-one decomposition.\nExtensive experiments are conducted to validate the effectiveness of DCFT.\nResults show that compared to LoRA, DCFT achieve an 8$\\times$ reduction in\nparameters, and still achieves highly impressive performance. Our code is\navailable here: https://github.com/Godz-z/DCFT.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "COLING 2025 main conference",
    "pdf_url": "http://arxiv.org/pdf/2503.01419v1",
    "published_date": "2025-03-03 11:15:50 UTC",
    "updated_date": "2025-03-03 11:15:50 UTC"
  },
  {
    "arxiv_id": "2503.01413v2",
    "title": "Building Interval Type-2 Fuzzy Membership Function: A Deck of Cards based Co-constructive Approach",
    "authors": [
      "Bapi Dutta",
      "Diego García-Zamora",
      "José Rui Figueira",
      "Luis Martínez"
    ],
    "abstract": "Since its inception, Fuzzy Set has been widely used to handle uncertainty and\nimprecision in decision-making. However, conventional fuzzy sets, often\nreferred to as type-1 fuzzy sets (T1FSs) have limitations in capturing higher\nlevels of uncertainty, particularly when decision-makers (DMs) express\nhesitation or ambiguity in membership degree. To address this, Interval Type-2\nFuzzy Sets (IT2FSs) have been introduced by incorporating uncertainty in\nmembership degree allocation, which enhanced flexibility in modelling\nsubjective judgments. Despite their advantages, existing IT2FS construction\nmethods often lack active involvement from DMs and that limits the\ninterpretability and effectiveness of decision models. This study proposes a\nsocio-technical co-constructive approach for developing IT2FS models of\nlinguistic terms by facilitating the active involvement of DMs in preference\nelicitation and its application in multicriteria decision-making (MCDM)\nproblems. Our methodology is structured in two phases. The first phase involves\nan interactive process between the DM and the decision analyst, in which a\nmodified version of Deck-of-Cards (DoC) method is proposed to construct T1FS\nmembership functions on a ratio scale. We then extend this method to\nincorporate ambiguity in subjective judgment and that resulted in an IT2FS\nmodel that better captures uncertainty in DM's linguistic assessments. The\nsecond phase formalizes the constructed IT2FS model for application in MCDM by\ndefining an appropriate mathematical representation of such information,\naggregation rules, and an admissible ordering principle. The proposed framework\nenhances the reliability and effectiveness of fuzzy decision-making not only by\naccurately representing DM's personalized semantics of linguistic information.",
    "categories": [
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01413v2",
    "published_date": "2025-03-03 11:08:18 UTC",
    "updated_date": "2025-03-11 15:37:21 UTC"
  },
  {
    "arxiv_id": "2503.01411v1",
    "title": "Learning Actionable World Models for Industrial Process Control",
    "authors": [
      "Peng Yan",
      "Ahmed Abdulkadir",
      "Gerrit A. Schatte",
      "Giulia Aguzzi",
      "Joonsu Gha",
      "Nikola Pascher",
      "Matthias Rosenthal",
      "Yunlong Gao",
      "Benjamin F. Grewe",
      "Thilo Stadelmann"
    ],
    "abstract": "To go from (passive) process monitoring to active process control, an\neffective AI system must learn about the behavior of the complex system from\nvery limited training data, forming an ad-hoc digital twin with respect to\nprocess in- and outputs that captures the consequences of actions on the\nprocess's world. We propose a novel methodology based on learning world models\nthat disentangles process parameters in the learned latent representation,\nallowing for fine-grained control. Representation learning is driven by the\nlatent factors that influence the processes through contrastive learning within\na joint embedding predictive architecture. This makes changes in\nrepresentations predictable from changes in inputs and vice versa, facilitating\ninterpretability of key factors responsible for process variations, paving the\nway for effective control actions to keep the process within operational\nbounds. The effectiveness of our method is validated on the example of plastic\ninjection molding, demonstrating practical relevance in proposing specific\ncontrol actions for a notoriously unstable process.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY",
      "I.2.0; I.2.4"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01411v1",
    "published_date": "2025-03-03 11:05:44 UTC",
    "updated_date": "2025-03-03 11:05:44 UTC"
  },
  {
    "arxiv_id": "2503.01407v2",
    "title": "Divide and Conquer: Heterogeneous Noise Integration for Diffusion-based Adversarial Purification",
    "authors": [
      "Gaozheng Pei",
      "Shaojie Lyu",
      "Gong Chen",
      "Ke Ma",
      "Qianqian Xu",
      "Yingfei Sun",
      "Qingming Huang"
    ],
    "abstract": "Existing diffusion-based purification methods aim to disrupt adversarial\nperturbations by introducing a certain amount of noise through a forward\ndiffusion process, followed by a reverse process to recover clean examples.\nHowever, this approach is fundamentally flawed: the uniform operation of the\nforward process across all pixels compromises normal pixels while attempting to\ncombat adversarial perturbations, resulting in the target model producing\nincorrect predictions. Simply relying on low-intensity noise is insufficient\nfor effective defense. To address this critical issue, we implement a\nheterogeneous purification strategy grounded in the interpretability of neural\nnetworks. Our method decisively applies higher-intensity noise to specific\npixels that the target model focuses on while the remaining pixels are\nsubjected to only low-intensity noise. This requirement motivates us to\nredesign the sampling process of the diffusion model, allowing for the\neffective removal of varying noise levels. Furthermore, to evaluate our method\nagainst strong adaptative attack, our proposed method sharply reduces time cost\nand memory usage through a single-step resampling. The empirical evidence from\nextensive experiments across three datasets demonstrates that our method\noutperforms most current adversarial training and purification techniques by a\nsubstantial margin.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01407v2",
    "published_date": "2025-03-03 11:00:25 UTC",
    "updated_date": "2025-03-24 07:15:05 UTC"
  },
  {
    "arxiv_id": "2503.01394v1",
    "title": "Enhancing Social Media Rumor Detection: A Semantic and Graph Neural Network Approach for the 2024 Global Election",
    "authors": [
      "Liu Yan",
      "Liu Yunpeng",
      "Zhao Liang"
    ],
    "abstract": "The development of social media platforms has revolutionized the speed and\nmanner in which information is disseminated, leading to both beneficial and\ndetrimental effects on society. While these platforms facilitate rapid\ncommunication, they also accelerate the spread of rumors and extremist speech,\nimpacting public perception and behavior significantly. This issue is\nparticularly pronounced during election periods, where the influence of social\nmedia on election outcomes has become a matter of global concern. With the\nunprecedented number of elections in 2024, against this backdrop, the election\necosystem has encountered unprecedented challenges. This study addresses the\nurgent need for effective rumor detection on social media by proposing a novel\nmethod that combines semantic analysis with graph neural networks. We have\nmeticulously collected a dataset from PolitiFact and Twitter, focusing on\npolitically relevant rumors. Our approach involves semantic analysis using a\nfine-tuned BERT model to vectorize text content and construct a directed graph\nwhere tweets and comments are nodes, and interactions are edges. The core of\nour method is a graph neural network, SAGEWithEdgeAttention, which extends the\nGraphSAGE model by incorporating first-order differences as edge attributes and\napplying an attention mechanism to enhance feature aggregation. This innovative\napproach allows for the fine-grained analysis of the complex social network\nstructure, improving rumor detection accuracy. The study concludes that our\nmethod significantly outperforms traditional content analysis and time-based\nmodels, offering a theoretically sound and practically efficient solution.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01394v1",
    "published_date": "2025-03-03 10:49:33 UTC",
    "updated_date": "2025-03-03 10:49:33 UTC"
  },
  {
    "arxiv_id": "2503.01389v1",
    "title": "Learning Conjecturing from Scratch",
    "authors": [
      "Thibault Gauthier",
      "Josef Urban"
    ],
    "abstract": "We develop a self-learning approach for conjecturing of induction predicates\non a dataset of 16197 problems derived from the OEIS. These problems are hard\nfor today's SMT and ATP systems because they require a combination of inductive\nand arithmetical reasoning.\n  Starting from scratch, our approach consists of a feedback loop that iterates\nbetween (i) training a neural translator to learn the correspondence between\nthe problems solved so far and the induction predicates useful for them, (ii)\nusing the trained neural system to generate many new induction predicates for\nthe problems, (iii) fast runs of the z3 prover attempting to prove the problems\nusing the generated predicates, (iv) using heuristics such as predicate size\nand solution speed on the proved problems to choose the best predicates for the\nnext iteration of training.\n  The algorithm discovers on its own many interesting induction predicates,\nultimately solving 5565 problems, compared to 2265 problems solved by CVC5,\nVampire or Z3 in 60 seconds.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.LO",
      "cs.NE",
      "cs.SC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01389v1",
    "published_date": "2025-03-03 10:39:38 UTC",
    "updated_date": "2025-03-03 10:39:38 UTC"
  },
  {
    "arxiv_id": "2503.01386v1",
    "title": "Geo-Semantic-Parsing: AI-powered geoparsing by traversing semantic knowledge graphs",
    "authors": [
      "Leonardo Nizzoli",
      "Marco Avvenuti",
      "Maurizio Tesconi",
      "Stefano Cresci"
    ],
    "abstract": "Online social networks convey rich information about geospatial facets of\nreality. However in most cases, geographic information is not explicit and\nstructured, thus preventing its exploitation in real-time applications. We\naddress this limitation by introducing a novel geoparsing and geotagging\ntechnique called Geo-Semantic-Parsing (GSP). GSP identifies location references\nin free text and extracts the corresponding geographic coordinates. To reach\nthis goal, we employ a semantic annotator to identify relevant portions of the\ninput text and to link them to the corresponding entity in a knowledge graph.\nThen, we devise and experiment with several efficient strategies for traversing\nthe knowledge graph, thus expanding the available set of information for the\ngeoparsing task. Finally, we exploit all available information for learning a\nregression model that selects the best entity with which to geotag the input\ntext. We evaluate GSP on a well-known reference dataset including almost 10k\nevent-related tweets, achieving $F1=0.66$. We extensively compare our results\nwith those of 2 baselines and 3 state-of-the-art geoparsing techniques,\nachieving the best performance. On the same dataset, competitors obtain $F1\n\\leq 0.55$. We conclude by providing in-depth analyses of our results, showing\nthat the overall superior performance of GSP is mainly due to a large\nimprovement in recall, with respect to existing techniques.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.SI"
    ],
    "primary_category": "cs.CL",
    "comment": "Postprint of the article published in the Decision Support Systems\n  journal. Please, cite accordingly",
    "pdf_url": "http://arxiv.org/pdf/2503.01386v1",
    "published_date": "2025-03-03 10:30:23 UTC",
    "updated_date": "2025-03-03 10:30:23 UTC"
  },
  {
    "arxiv_id": "2503.01375v1",
    "title": "Combining Flow Matching and Transformers for Efficient Solution of Bayesian Inverse Problems",
    "authors": [
      "Daniil Sherki",
      "Ivan Oseledets",
      "Ekaterina Muravleva"
    ],
    "abstract": "Solving Bayesian inverse problems efficiently remains a significant challenge\ndue to the complexity of posterior distributions and the computational cost of\ntraditional sampling methods. Given a series of observations and the forward\nmodel, we want to recover the distribution of the parameters, conditioned on\nobserved experimental data. We show, that combining Conditional Flow Mathching\n(CFM) with transformer-based architecture, we can efficiently sample from such\nkind of distribution, conditioned on variable number of observations.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01375v1",
    "published_date": "2025-03-03 10:17:56 UTC",
    "updated_date": "2025-03-03 10:17:56 UTC"
  },
  {
    "arxiv_id": "2503.01372v1",
    "title": "SwiLTra-Bench: The Swiss Legal Translation Benchmark",
    "authors": [
      "Joel Niklaus",
      "Jakob Merane",
      "Luka Nenadic",
      "Sina Ahmadi",
      "Yingqiang Gao",
      "Cyrill A. H. Chevalley",
      "Claude Humbel",
      "Christophe Gösken",
      "Lorenzo Tanzi",
      "Thomas Lüthi",
      "Stefan Palombo",
      "Spencer Poff",
      "Boling Yang",
      "Nan Wu",
      "Matthew Guillod",
      "Robin Mamié",
      "Daniel Brunner",
      "Julio Pereyra",
      "Niko Grupen"
    ],
    "abstract": "In Switzerland legal translation is uniquely important due to the country's\nfour official languages and requirements for multilingual legal documentation.\nHowever, this process traditionally relies on professionals who must be both\nlegal experts and skilled translators -- creating bottlenecks and impacting\neffective access to justice. To address this challenge, we introduce\nSwiLTra-Bench, a comprehensive multilingual benchmark of over 180K aligned\nSwiss legal translation pairs comprising laws, headnotes, and press releases\nacross all Swiss languages along with English, designed to evaluate LLM-based\ntranslation systems. Our systematic evaluation reveals that frontier models\nachieve superior translation performance across all document types, while\nspecialized translation systems excel specifically in laws but under-perform in\nheadnotes. Through rigorous testing and human expert validation, we demonstrate\nthat while fine-tuning open SLMs significantly improves their translation\nquality, they still lag behind the best zero-shot prompted frontier models such\nas Claude-3.5-Sonnet. Additionally, we present SwiLTra-Judge, a specialized LLM\nevaluation system that aligns best with human expert assessments.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "68T50",
      "I.2"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01372v1",
    "published_date": "2025-03-03 10:10:30 UTC",
    "updated_date": "2025-03-03 10:10:30 UTC"
  },
  {
    "arxiv_id": "2503.01353v1",
    "title": "Dendron: Enhancing Human Activity Recognition with On-Device TinyML Learning",
    "authors": [
      "Hazem Hesham Yousef Shalby",
      "Manuel Roveri"
    ],
    "abstract": "Human activity recognition (HAR) is a research field that employs Machine\nLearning (ML) techniques to identify user activities. Recent studies have\nprioritized the development of HAR solutions directly executed on wearable\ndevices, enabling the on-device activity recognition. This approach is\nsupported by the Tiny Machine Learning (TinyML) paradigm, which integrates ML\nwithin embedded devices with limited resources. However, existing approaches in\nthe field lack in the capability for on-device learning of new HAR tasks,\nparticularly when supervised data are scarce. To address this limitation, our\npaper introduces Dendron, a novel TinyML methodology designed to facilitate the\non-device learning of new tasks for HAR, even in conditions of limited\nsupervised data. Experimental results on two public-available datasets and an\noff-the-shelf device (STM32-NUCLEO-F401RE) show the effectiveness and\nefficiency of the proposed solution.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to IEEE SSCI",
    "pdf_url": "http://arxiv.org/pdf/2503.01353v1",
    "published_date": "2025-03-03 09:45:52 UTC",
    "updated_date": "2025-03-03 09:45:52 UTC"
  },
  {
    "arxiv_id": "2503.01345v1",
    "title": "Same Question, Different Words: A Latent Adversarial Framework for Prompt Robustness",
    "authors": [
      "Tingchen Fu",
      "Fazl Barez"
    ],
    "abstract": "Insensitivity to semantically-preserving variations of prompts (paraphrases)\nis crucial for reliable behavior and real-world deployment of large language\nmodels. However, language models exhibit significant performance degradation\nwhen faced with semantically equivalent but differently phrased prompts, and\nexisting solutions either depend on trial-and-error prompt engineering or\nrequire computationally expensive inference-time algorithms. In this study,\nbuilt on the key insight that worst-case prompts exhibit a drift in embedding\nspace, we present Latent Adversarial Paraphrasing (LAP), a dual-loop\nadversarial framework: the inner loop trains a learnable perturbation to serve\nas a \"latent continuous paraphrase\" while preserving semantics through\nLagrangian regulation, and the outer loop optimizes the language model\nparameters on these perturbations. We conduct extensive experiments to\ndemonstrate the effectiveness of LAP across multiple LLM architectures on the\nRobustAlpaca benchmark with a 0.5%-4% absolution improvement on worst-case\nwin-rate compared with vanilla supervised fine-tuning.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01345v1",
    "published_date": "2025-03-03 09:36:50 UTC",
    "updated_date": "2025-03-03 09:36:50 UTC"
  },
  {
    "arxiv_id": "2503.01332v1",
    "title": "Answer, Refuse, or Guess? Investigating Risk-Aware Decision Making in Language Models",
    "authors": [
      "Cheng-Kuang Wu",
      "Zhi Rui Tam",
      "Chieh-Yen Lin",
      "Yun-Nung Chen",
      "Hung-yi Lee"
    ],
    "abstract": "Knowing when to answer or refuse is crucial for safe and reliable\ndecision-making language agents. Although prior work has introduced refusal\nstrategies to boost LMs' reliability, how these models adapt their decisions to\ndifferent risk levels remains underexplored. We formalize the task of\nrisk-aware decision-making, expose critical weaknesses in existing LMs, and\npropose skill-decomposition solutions to mitigate them. Our findings show that\neven cutting-edge LMs--both regular and reasoning models--still require\nexplicit prompt chaining to handle the task effectively, revealing the\nchallenges that must be overcome to achieve truly autonomous decision-making\nagents.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "preprint",
    "pdf_url": "http://arxiv.org/pdf/2503.01332v1",
    "published_date": "2025-03-03 09:16:26 UTC",
    "updated_date": "2025-03-03 09:16:26 UTC"
  },
  {
    "arxiv_id": "2503.01329v1",
    "title": "Neural ODE Transformers: Analyzing Internal Dynamics and Adaptive Fine-tuning",
    "authors": [
      "Anh Tong",
      "Thanh Nguyen-Tang",
      "Dongeun Lee",
      "Duc Nguyen",
      "Toan Tran",
      "David Hall",
      "Cheongwoong Kang",
      "Jaesik Choi"
    ],
    "abstract": "Recent advancements in large language models (LLMs) based on transformer\narchitectures have sparked significant interest in understanding their inner\nworkings. In this paper, we introduce a novel approach to modeling transformer\narchitectures using highly flexible non-autonomous neural ordinary differential\nequations (ODEs). Our proposed model parameterizes all weights of attention and\nfeed-forward blocks through neural networks, expressing these weights as\nfunctions of a continuous layer index. Through spectral analysis of the model's\ndynamics, we uncover an increase in eigenvalue magnitude that challenges the\nweight-sharing assumption prevalent in existing theoretical studies. We also\nleverage the Lyapunov exponent to examine token-level sensitivity, enhancing\nmodel interpretability. Our neural ODE transformer demonstrates performance\ncomparable to or better than vanilla transformers across various configurations\nand datasets, while offering flexible fine-tuning capabilities that can adapt\nto different architectural constraints.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.01329v1",
    "published_date": "2025-03-03 09:12:14 UTC",
    "updated_date": "2025-03-03 09:12:14 UTC"
  },
  {
    "arxiv_id": "2503.01328v1",
    "title": "PipeOffload: Improving Scalability of Pipeline Parallelism with Memory Optimization",
    "authors": [
      "Xinyi Wan",
      "Penghui Qi",
      "Guangxing Huang",
      "Jialin Li",
      "Min Lin"
    ],
    "abstract": "Pipeline parallelism (PP) is widely used for training large language models\n(LLMs), yet its scalability is often constrained by high activation memory\nconsumption as the number of in-flight microbatches grows with the degree of\nPP. In this paper, we focus on addressing this challenge by leveraging the\nunder-explored memory offload strategy in PP. With empirical study, we discover\nthat in the majority of standard configurations, at least half, and potentially\nall, of the activations can be offloaded with negligible overhead. In the cases\nwhere full overload is not possible, we introduce a novel selective offload\nstrategy that decreases peak activation memory in a better-than-linear manner.\nFurthermore, we integrate memory offload with other techniques to jointly\nconsider overall throughput and memory limitation. Our experiments proves that\nthe per-device activation memory effectively reduces with the total number of\nstages, making PP a stronger alternative than TP, offering up to a 19\\%\nacceleration with even lower memory consumption. The implementation is\nopen-sourced at\n\\href{https://github.com/sail-sg/zero-bubble-pipeline-parallelism}{this url}.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01328v1",
    "published_date": "2025-03-03 09:11:06 UTC",
    "updated_date": "2025-03-03 09:11:06 UTC"
  },
  {
    "arxiv_id": "2503.01323v1",
    "title": "CacheQuant: Comprehensively Accelerated Diffusion Models",
    "authors": [
      "Xuewen Liu",
      "Zhikai Li",
      "Qingyi Gu"
    ],
    "abstract": "Diffusion models have gradually gained prominence in the field of image\nsynthesis, showcasing remarkable generative capabilities. Nevertheless, the\nslow inference and complex networks, resulting from redundancy at both temporal\nand structural levels, hinder their low-latency applications in real-world\nscenarios. Current acceleration methods for diffusion models focus separately\non temporal and structural levels. However, independent optimization at each\nlevel to further push the acceleration limits results in significant\nperformance degradation. On the other hand, integrating optimizations at both\nlevels can compound the acceleration effects. Unfortunately, we find that the\noptimizations at these two levels are not entirely orthogonal. Performing\nseparate optimizations and then simply integrating them results in\nunsatisfactory performance. To tackle this issue, we propose CacheQuant, a\nnovel training-free paradigm that comprehensively accelerates diffusion models\nby jointly optimizing model caching and quantization techniques. Specifically,\nwe employ a dynamic programming approach to determine the optimal cache\nschedule, in which the properties of caching and quantization are carefully\nconsidered to minimize errors. Additionally, we propose decoupled error\ncorrection to further mitigate the coupled and accumulated errors step by step.\nExperimental results show that CacheQuant achieves a 5.18 speedup and 4\ncompression for Stable Diffusion on MS-COCO, with only a 0.02 loss in CLIP\nscore. Our code are open-sourced: https://github.com/BienLuky/CacheQuant .",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.01323v1",
    "published_date": "2025-03-03 09:04:51 UTC",
    "updated_date": "2025-03-03 09:04:51 UTC"
  },
  {
    "arxiv_id": "2503.04801v1",
    "title": "Exploring and Evaluating Multimodal Knowledge Reasoning Consistency of Multimodal Large Language Models",
    "authors": [
      "Boyu Jia",
      "Junzhe Zhang",
      "Huixuan Zhang",
      "Xiaojun Wan"
    ],
    "abstract": "In recent years, multimodal large language models (MLLMs) have achieved\nsignificant breakthroughs, enhancing understanding across text and vision.\nHowever, current MLLMs still face challenges in effectively integrating\nknowledge across these modalities during multimodal knowledge reasoning,\nleading to inconsistencies in reasoning outcomes. To systematically explore\nthis issue, we propose four evaluation tasks and construct a new dataset. We\nconduct a series of experiments on this dataset to analyze and compare the\nextent of consistency degradation in multimodal knowledge reasoning within\nMLLMs. Based on the experimental results, we identify factors contributing to\nthe observed degradation in consistency. Our research provides new insights\ninto the challenges of multimodal knowledge reasoning and offers valuable\nguidance for future efforts aimed at improving MLLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04801v1",
    "published_date": "2025-03-03 09:01:51 UTC",
    "updated_date": "2025-03-03 09:01:51 UTC"
  },
  {
    "arxiv_id": "2503.01314v1",
    "title": "Scaling Law Phenomena Across Regression Paradigms: Multiple and Kernel Approaches",
    "authors": [
      "Yifang Chen",
      "Xuyang Guo",
      "Xiaoyu Li",
      "Yingyu Liang",
      "Zhenmei Shi",
      "Zhao Song"
    ],
    "abstract": "Recently, Large Language Models (LLMs) have achieved remarkable success. A\nkey factor behind this success is the scaling law observed by OpenAI.\nSpecifically, for models with Transformer architecture, the test loss exhibits\na power-law relationship with model size, dataset size, and the amount of\ncomputation used in training, demonstrating trends that span more than seven\norders of magnitude. This scaling law challenges traditional machine learning\nwisdom, notably the Oscar Scissors principle, which suggests that an\noverparametrized algorithm will overfit the training datasets, resulting in\npoor test performance. Recent research has also identified the scaling law in\nsimpler machine learning contexts, such as linear regression. However, fully\nexplaining the scaling law in large practical models remains an elusive goal.\nIn this work, we advance our understanding by demonstrating that the scaling\nlaw phenomenon extends to multiple regression and kernel regression settings,\nwhich are significantly more expressive and powerful than linear methods. Our\nanalysis provides deeper insights into the scaling law, potentially enhancing\nour understanding of LLMs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01314v1",
    "published_date": "2025-03-03 08:57:49 UTC",
    "updated_date": "2025-03-03 08:57:49 UTC"
  },
  {
    "arxiv_id": "2503.01306v1",
    "title": "From Claims to Evidence: A Unified Framework and Critical Analysis of CNN vs. Transformer vs. Mamba in Medical Image Segmentation",
    "authors": [
      "Pooya Mohammadi Kazaj",
      "Giovanni Baj",
      "Yazdan Salimi",
      "Anselm W. Stark",
      "Waldo Valenzuela",
      "George CM. Siontis",
      "Habib Zaidi",
      "Mauricio Reyes",
      "Christoph Graeni",
      "Isaac Shiri"
    ],
    "abstract": "While numerous architectures for medical image segmentation have been\nproposed, achieving competitive performance with state-of-the-art models\nnetworks such as nnUNet, still leave room for further innovation. In this work,\nwe introduce nnUZoo, an open source benchmarking framework built upon nnUNet,\nwhich incorporates various deep learning architectures, including CNNs,\nTransformers, and Mamba-based models. Using this framework, we provide a fair\ncomparison to demystify performance claims across different medical image\nsegmentation tasks. Additionally, in an effort to enrich the benchmarking, we\nexplored five new architectures based on Mamba and Transformers, collectively\nnamed X2Net, and integrated them into nnUZoo for further evaluation. The\nproposed models combine the features of conventional U2Net, nnUNet, CNN,\nTransformer, and Mamba layers and architectures, called X2Net (UNETR2Net\n(UNETR), SwT2Net (SwinTransformer), SS2D2Net (SwinUMamba), Alt1DM2Net\n(LightUMamba), and MambaND2Net (MambaND)). We extensively evaluate the\nperformance of different models on six diverse medical image segmentation\ndatasets, including microscopy, ultrasound, CT, MRI, and PET, covering various\nbody parts, organs, and labels. We compare their performance, in terms of dice\nscore and computational efficiency, against their baseline models, U2Net, and\nnnUNet. CNN models like nnUNet and U2Net demonstrated both speed and accuracy,\nmaking them effective choices for medical image segmentation tasks.\nTransformer-based models, while promising for certain imaging modalities,\nexhibited high computational costs. Proposed Mamba-based X2Net architecture\n(SS2D2Net) achieved competitive accuracy with no significantly difference from\nnnUNet and U2Net, while using fewer parameters. However, they required\nsignificantly longer training time, highlighting a trade-off between model\nefficiency and computational cost.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "physics.med-ph"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01306v1",
    "published_date": "2025-03-03 08:44:51 UTC",
    "updated_date": "2025-03-03 08:44:51 UTC"
  },
  {
    "arxiv_id": "2503.01298v1",
    "title": "MINT: Multi-modal Chain of Thought in Unified Generative Models for Enhanced Image Generation",
    "authors": [
      "Yi Wang",
      "Mushui Liu",
      "Wanggui He",
      "Longxiang Zhang",
      "Ziwei Huang",
      "Guanghao Zhang",
      "Fangxun Shu",
      "Zhong Tao",
      "Dong She",
      "Zhelun Yu",
      "Haoyuan Li",
      "Weilong Dai",
      "Mingli Song",
      "Jie Song",
      "Hao Jiang"
    ],
    "abstract": "Unified generative models have demonstrated extraordinary performance in both\ntext and image generation. However, they tend to underperform when generating\nintricate images with various interwoven conditions, which is hard to solely\nrely on straightforward text-to-image generation. In response to this\nchallenge, we introduce MINT, an innovative unified generative model, empowered\nwith native multimodal chain of thought (MCoT) for enhanced image generation\nfor the first time. Firstly, we design Mixture of Transformer Experts\n(MTXpert), an expert-parallel structure that effectively supports both natural\nlanguage generation (NLG) and visual capabilities, while avoiding potential\nmodality conflicts that could hinder the full potential of each modality.\nBuilding on this, we propose an innovative MCoT training paradigm, a\nstep-by-step approach to multimodal thinking, reasoning, and reflection\nspecifically designed to enhance image generation. This paradigm equips MINT\nwith nuanced, element-wise decoupled alignment and a comprehensive\nunderstanding of textual and visual components. Furthermore, it fosters\nadvanced multimodal reasoning and self-reflection, enabling the construction of\nimages that are firmly grounded in the logical relationships between these\nelements. Notably, MINT has been validated to exhibit superior performance\nacross multiple benchmarks for text-to-image (T2I) and image-to-text (I2T)\ntasks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01298v1",
    "published_date": "2025-03-03 08:36:16 UTC",
    "updated_date": "2025-03-03 08:36:16 UTC"
  },
  {
    "arxiv_id": "2503.01294v1",
    "title": "Fine-Grained Controllable Apparel Showcase Image Generation via Garment-Centric Outpainting",
    "authors": [
      "Rong Zhang",
      "Jingnan Wang",
      "Zhiwen Zuo",
      "Jianfeng Dong",
      "Wei Li",
      "Chi Wang",
      "Weiwei Xu",
      "Xun Wang"
    ],
    "abstract": "In this paper, we propose a novel garment-centric outpainting (GCO) framework\nbased on the latent diffusion model (LDM) for fine-grained controllable apparel\nshowcase image generation. The proposed framework aims at customizing a fashion\nmodel wearing a given garment via text prompts and facial images. Different\nfrom existing methods, our framework takes a garment image segmented from a\ndressed mannequin or a person as the input, eliminating the need for learning\ncloth deformation and ensuring faithful preservation of garment details. The\nproposed framework consists of two stages. In the first stage, we introduce a\ngarment-adaptive pose prediction model that generates diverse poses given the\ngarment. Then, in the next stage, we generate apparel showcase images,\nconditioned on the garment and the predicted poses, along with specified text\nprompts and facial images. Notably, a multi-scale appearance customization\nmodule (MS-ACM) is designed to allow both overall and fine-grained text-based\ncontrol over the generated model's appearance. Moreover, we leverage a\nlightweight feature fusion operation without introducing any extra encoders or\nmodules to integrate multiple conditions, which is more efficient. Extensive\nexperiments validate the superior performance of our framework compared to\nstate-of-the-art methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01294v1",
    "published_date": "2025-03-03 08:30:37 UTC",
    "updated_date": "2025-03-03 08:30:37 UTC"
  },
  {
    "arxiv_id": "2503.01290v1",
    "title": "ACTIVA: Amortized Causal Effect Estimation without Graphs via Transformer-based Variational Autoencoder",
    "authors": [
      "Andreas Sauter",
      "Saber Salehkaleybar",
      "Aske Plaat",
      "Erman Acar"
    ],
    "abstract": "Predicting the distribution of outcomes under hypothetical interventions is\ncrucial in domains like healthcare, economics, and policy-making. Current\nmethods often rely on strong assumptions, such as known causal graphs or\nparametric models, and lack amortization across problem instances, limiting\ntheir practicality. We propose a novel transformer-based conditional\nvariational autoencoder architecture, named ACTIVA, that extends causal\ntransformer encoders to predict causal effects as mixtures of Gaussians. Our\nmethod requires no causal graph and predicts interventional distributions given\nonly observational data and a queried intervention. By amortizing over many\nsimulated instances, it enables zero-shot generalization to novel datasets\nwithout retraining. Experiments demonstrate accurate predictions for synthetic\nand semi-synthetic data, showcasing the effectiveness of our graph-free,\namortized causal inference approach.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01290v1",
    "published_date": "2025-03-03 08:28:25 UTC",
    "updated_date": "2025-03-03 08:28:25 UTC"
  },
  {
    "arxiv_id": "2503.01287v1",
    "title": "Robust Simulation-Based Inference under Missing Data via Neural Processes",
    "authors": [
      "Yogesh Verma",
      "Ayush Bharti",
      "Vikas Garg"
    ],
    "abstract": "Simulation-based inference (SBI) methods typically require fully observed\ndata to infer parameters of models with intractable likelihood functions.\nHowever, datasets often contain missing values due to incomplete observations,\ndata corruptions (common in astrophysics), or instrument limitations (e.g., in\nhigh-energy physics applications). In such scenarios, missing data must be\nimputed before applying any SBI method. We formalize the problem of missing\ndata in SBI and demonstrate that naive imputation methods can introduce bias in\nthe estimation of SBI posterior. We also introduce a novel amortized method\nthat addresses this issue by jointly learning the imputation model and the\ninference network within a neural posterior estimation (NPE) framework.\nExtensive empirical results on SBI benchmarks show that our approach provides\nrobust inference outcomes compared to standard baselines for varying levels of\nmissing data. Moreover, we demonstrate the merits of our imputation model on\ntwo real-world bioactivity datasets (Adrenergic and Kinase assays). Code is\navailable at https://github.com/Aalto-QuML/RISE.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.01287v1",
    "published_date": "2025-03-03 08:22:01 UTC",
    "updated_date": "2025-03-03 08:22:01 UTC"
  },
  {
    "arxiv_id": "2503.01273v1",
    "title": "OptMetaOpenFOAM: Large Language Model Driven Chain of Thought for Sensitivity Analysis and Parameter Optimization based on CFD",
    "authors": [
      "Yuxuan Chen",
      "Long Zhang",
      "Xu Zhu",
      "Hua Zhou",
      "Zhuyin Ren"
    ],
    "abstract": "Merging natural language interfaces with computational fluid dynamics (CFD)\nworkflows presents transformative opportunities for both industry and research.\nIn this study, we introduce OptMetaOpenFOAM - a novel framework that bridges\nMetaOpenFOAM with external analysis and optimization tool libraries through a\nlarge language model (LLM)-driven chain-of-thought (COT) methodology. By\nautomating complex CFD tasks via natural language inputs, the framework\nempowers non-expert users to perform sensitivity analyses and parameter\noptimizations with markedly improved efficiency. The test dataset comprises 11\ndistinct CFD analysis or optimization tasks, including a baseline simulation\ntask derived from an OpenFOAM tutorial covering fluid dynamics, combustion, and\nheat transfer. Results confirm that OptMetaOpenFOAM can accurately interpret\nuser requirements expressed in natural language and effectively invoke external\ntool libraries alongside MetaOpenFOAM to complete the tasks. Furthermore,\nvalidation on a non-OpenFOAM tutorial case - namely, a hydrogen combustion\nchamber - demonstrates that a mere 200-character natural language input can\ntrigger a sequence of simulation, postprocessing, analysis, and optimization\ntasks spanning over 2,000 lines of code. These findings underscore the\ntransformative potential of LLM-driven COT methodologies in linking external\ntool for advanced analysis and optimization, positioning OptMetaOpenFOAM as an\neffective tool that streamlines CFD simulations and enhances their convenience\nand efficiency for both industrial and research applications. Code is available\nat https://github.com/Terry-cyx/MetaOpenFOAM.",
    "categories": [
      "cs.AI",
      "physics.flu-dyn"
    ],
    "primary_category": "cs.AI",
    "comment": "26 pages,11 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.01273v1",
    "published_date": "2025-03-03 07:55:43 UTC",
    "updated_date": "2025-03-03 07:55:43 UTC"
  },
  {
    "arxiv_id": "2503.01937v1",
    "title": "Synthetic Tabular Data Detection In the Wild",
    "authors": [
      "G. Charbel N. Kindji",
      "Elisa Fromont",
      "Lina Maria Rojas-Barahona",
      "Tanguy Urvoy"
    ],
    "abstract": "Detecting synthetic tabular data is essential to prevent the distribution of\nfalse or manipulated datasets that could compromise data-driven\ndecision-making. This study explores whether synthetic tabular data can be\nreliably identified across different tables. This challenge is unique to\ntabular data, where structures (such as number of columns, data types, and\nformats) can vary widely from one table to another. We propose four\ntable-agnostic detectors combined with simple preprocessing schemes that we\nevaluate on six evaluation protocols, with different levels of ''wildness''.\nOur results show that cross-table learning on a restricted set of tables is\npossible even with naive preprocessing schemes. They confirm however that\ncross-table transfer (i.e. deployment on a table that has not been seen before)\nis challenging. This suggests that sophisticated encoding schemes are required\nto handle this problem.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DB",
      "cs.NE",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "International Symposium on Intelligent Data Analysis, May 2025,\n  Konstanz, Germany",
    "pdf_url": "http://arxiv.org/pdf/2503.01937v1",
    "published_date": "2025-03-03 07:53:16 UTC",
    "updated_date": "2025-03-03 07:53:16 UTC"
  },
  {
    "arxiv_id": "2503.01936v1",
    "title": "Decision-Focused Fine-Tuning of Time Series Foundation Models for Dispatchable Feeder Optimization",
    "authors": [
      "Maximilian Beichter",
      "Nils Friederich",
      "Janik Pinter",
      "Dorina Werling",
      "Kaleb Phipps",
      "Sebastian Beichter",
      "Oliver Neumann",
      "Ralf Mikut",
      "Veit Hagenmeyer",
      "Benedikt Heidrich"
    ],
    "abstract": "Time series foundation models provide a universal solution for generating\nforecasts to support optimization problems in energy systems. Those foundation\nmodels are typically trained in a prediction-focused manner to maximize\nforecast quality. In contrast, decision-focused learning directly improves the\nresulting value of the forecast in downstream optimization rather than merely\nmaximizing forecasting quality. The practical integration of forecast values\ninto forecasting models is challenging, particularly when addressing complex\napplications with diverse instances, such as buildings. This becomes even more\ncomplicated when instances possess specific characteristics that require\ninstance-specific, tailored predictions to increase the forecast value. To\ntackle this challenge, we use decision-focused fine-tuning within time series\nfoundation models to offer a scalable and efficient solution for\ndecision-focused learning applied to the dispatchable feeder optimization\nproblem. To obtain more robust predictions for scarce building data, we use\nMoirai as a state-of-the-art foundation model, which offers robust and\ngeneralized results with few-shot parameter-efficient fine-tuning. Comparing\nthe decision-focused fine-tuned Moirai with a state-of-the-art classical\nprediction-focused fine-tuning Morai, we observe an improvement of 9.45% in\naverage total daily costs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01936v1",
    "published_date": "2025-03-03 07:47:20 UTC",
    "updated_date": "2025-03-03 07:47:20 UTC"
  },
  {
    "arxiv_id": "2503.01268v1",
    "title": "Multi-Level Collaboration in Model Merging",
    "authors": [
      "Qi Li",
      "Runpeng Yu",
      "Xinchao Wang"
    ],
    "abstract": "Parameter-level model merging is an emerging paradigm in multi-task learning\nwith significant promise. Previous research has explored its connections with\nprediction-level model ensembling-commonly viewed as the upper bound for\nmerging-to reveal the potential of achieving performance consistency between\nthe two. However, this observation relies on certain preconditions, such as\nbeing limited to two models, using ViT-based models, and all models are\nfine-tuned from the same pre-trained checkpoint. To further understand the\nintrinsic connections between model merging and model ensembling, this paper\nexplores an interesting possibility: If these restrictions are removed, can\nperformance consistency still be achieved between merging and ensembling? To\nanswer this question, we first theoretically establish a performance\ncorrelation between merging and ensembling. We find that even when previous\nrestrictions are not met, there is still a way for model merging to attain a\nnear-identical and superior performance similar to that of ensembling. To\nverify whether our findings are practical, we introduce a validation framework\ntermed Neural Ligand (NeuLig). The learning process of NeuLig is meticulously\ndesigned with a specialized loss function supported by theoretical foundations.\nExperimental results demonstrate the robust resilience of NeuLig in terms of\nboth model scale and the number of collaborating models. For instance, for the\ncase involving 5 CLIP-ViT-B/32 models, parameter-level merging achieves the\nsame performance as prediction-level ensembling (merging: 95.44% vs.\nensembling: 95.46%).",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01268v1",
    "published_date": "2025-03-03 07:45:04 UTC",
    "updated_date": "2025-03-03 07:45:04 UTC"
  },
  {
    "arxiv_id": "2503.01266v1",
    "title": "Voice Cloning for Dysarthric Speech Synthesis: Addressing Data Scarcity in Speech-Language Pathology",
    "authors": [
      "Birger Moell",
      "Fredrik Sand Aronsson"
    ],
    "abstract": "This study explores voice cloning to generate synthetic speech replicating\nthe unique patterns of individuals with dysarthria. Using the TORGO dataset, we\naddress data scarcity and privacy challenges in speech-language pathology. Our\ncontributions include demonstrating that voice cloning preserves dysarthric\nspeech characteristics, analyzing differences between real and synthetic data,\nand discussing implications for diagnostics, rehabilitation, and communication.\nWe cloned voices from dysarthric and control speakers using a commercial\nplatform, ensuring gender-matched synthetic voices. A licensed speech-language\npathologist (SLP) evaluated a subset for dysarthria, speaker gender, and\nsynthetic indicators. The SLP correctly identified dysarthria in all cases and\nspeaker gender in 95% but misclassified 30% of synthetic samples as real,\nindicating high realism. Our results suggest synthetic speech effectively\ncaptures disordered characteristics and that voice cloning has advanced to\nproduce high-quality data resembling real speech, even to trained\nprofessionals. This has critical implications for healthcare, where synthetic\ndata can mitigate data scarcity, protect privacy, and enhance AI-driven\ndiagnostics. By enabling the creation of diverse, high-quality speech datasets,\nvoice cloning can improve generalizable models, personalize therapy, and\nadvance assistive technologies for dysarthria.\n  We publicly release our synthetic dataset to foster further research and\ncollaboration, aiming to develop robust models that improve patient outcomes in\nspeech-language pathology.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01266v1",
    "published_date": "2025-03-03 07:44:49 UTC",
    "updated_date": "2025-03-03 07:44:49 UTC"
  },
  {
    "arxiv_id": "2503.01238v1",
    "title": "A Taxonomy for Evaluating Generalist Robot Policies",
    "authors": [
      "Jensen Gao",
      "Suneel Belkhale",
      "Sudeep Dasari",
      "Ashwin Balakrishna",
      "Dhruv Shah",
      "Dorsa Sadigh"
    ],
    "abstract": "Machine learning for robotics promises to unlock generalization to novel\ntasks and environments. Guided by this promise, many recent works have focused\non scaling up robot data collection and developing larger, more expressive\npolicies to achieve this. But how do we measure progress towards this goal of\npolicy generalization in practice? Evaluating and quantifying generalization is\nthe Wild West of modern robotics, with each work proposing and measuring\ndifferent types of generalization in their own, often difficult to reproduce,\nsettings. In this work, our goal is (1) to outline the forms of generalization\nwe believe are important in robot manipulation in a comprehensive and\nfine-grained manner, and (2) to provide reproducible guidelines for measuring\nthese notions of generalization. We first propose STAR-Gen, a taxonomy of\ngeneralization for robot manipulation structured around visual, semantic, and\nbehavioral generalization. We discuss how our taxonomy encompasses most prior\nnotions of generalization in robotics. Next, we instantiate STAR-Gen with a\nconcrete real-world benchmark based on the widely-used Bridge V2 dataset. We\nevaluate a variety of state-of-the-art models on this benchmark to demonstrate\nthe utility of our taxonomy in practice. Our taxonomy of generalization can\nyield many interesting insights into existing models: for example, we observe\nthat current vision-language-action models struggle with various types of\nsemantic generalization, despite the promise of pre-training on internet-scale\nlanguage datasets. We believe STAR-Gen and our guidelines can improve the\ndissemination and evaluation of progress towards generalization in robotics,\nwhich we hope will guide model design and future data collection efforts. We\nprovide videos and demos at our website stargen-taxonomy.github.io.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "25 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.01238v1",
    "published_date": "2025-03-03 07:03:00 UTC",
    "updated_date": "2025-03-03 07:03:00 UTC"
  },
  {
    "arxiv_id": "2503.01236v1",
    "title": "LLM-Advisor: An LLM Benchmark for Cost-efficient Path Planning across Multiple Terrains",
    "authors": [
      "Ling Xiao",
      "Toshihiko Yamasaki"
    ],
    "abstract": "Multi-terrain cost-efficient path planning is a crucial task in robot\nnavigation, requiring the identification of a path from the start to the goal\nthat not only avoids obstacles but also minimizes travel costs. This is\nespecially crucial for real-world applications where robots need to navigate\ndiverse terrains in outdoor environments, where recharging or refueling is\ndifficult. However, there is very limited research on this topic. In this\npaper, we develop a prompt-based approach, LLM-Advisor, which leverages large\nlanguage models (LLMs) as effective advisors for path planning. The LLM-Advisor\nselectively provides suggestions, demonstrating its ability to recognize when\nno modifications are necessary. When suggestions are made, 70.59% of the paths\nsuggested for the A* algorithm, 69.47% for the RRT* algorithm, and 78.70% for\nthe LLM-A* algorithm achieve greater cost efficiency. Since LLM-Advisor may\noccasionally lack common sense in their suggestions, we propose two\nhallucination-mitigation strategies. Furthermore, we experimentally verified\nthat GPT-4o performs poorly in zero-shot path planning, even when terrain\ndescriptions are clearly provided, demonstrating its low spatial awareness. We\nalso experimentally demonstrate that using an LLM as an advisor is more\neffective than directly integrating it into the path-planning loop. Since LLMs\nmay generate hallucinations, using LLMs in the loop of a search-based method\n(such as A*) may lead to a higher number of failed paths, demonstrating that\nour proposed LLM-Advisor is a better choice.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01236v1",
    "published_date": "2025-03-03 07:02:10 UTC",
    "updated_date": "2025-03-03 07:02:10 UTC"
  },
  {
    "arxiv_id": "2503.01232v1",
    "title": "Learning Covariance-Based Multi-Scale Representation of Neuroimaging Measures for Alzheimer Classification",
    "authors": [
      "Seunghun Baek",
      "Injun Choi",
      "Mustafa Dere",
      "Minjeong Kim",
      "Guorong Wu",
      "Won Hwa Kim"
    ],
    "abstract": "Stacking excessive layers in DNN results in highly underdetermined system\nwhen training samples are limited, which is very common in medical\napplications. In this regard, we present a framework capable of deriving an\nefficient high-dimensional space with reasonable increase in model size. This\nis done by utilizing a transform (i.e., convolution) that leverages scale-space\ntheory with covariance structure. The overall model trains on this transform\ntogether with a downstream classifier (i.e., Fully Connected layer) to capture\nthe optimal multi-scale representation of the original data which corresponds\nto task-specific components in a dual space. Experiments on neuroimaging\nmeasures from Alzheimer's Disease Neuroimaging Initiative (ADNI) study show\nthat our model performs better and converges faster than conventional models\neven when the model size is significantly reduced. The trained model is made\ninterpretable using gradient information over the multi-scale transform to\ndelineate personalized AD-specific regions in the brain.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ISBI 2023",
    "pdf_url": "http://arxiv.org/pdf/2503.01232v1",
    "published_date": "2025-03-03 06:55:35 UTC",
    "updated_date": "2025-03-03 06:55:35 UTC"
  },
  {
    "arxiv_id": "2503.04800v1",
    "title": "HoH: A Dynamic Benchmark for Evaluating the Impact of Outdated Information on Retrieval-Augmented Generation",
    "authors": [
      "Jie Ouyang",
      "Tingyue Pan",
      "Mingyue Cheng",
      "Ruiran Yan",
      "Yucong Luo",
      "Jiaying Lin",
      "Qi Liu"
    ],
    "abstract": "While Retrieval-Augmented Generation (RAG) has emerged as an effective\napproach for addressing the knowledge outdating problem in Large Language\nModels (LLMs), it faces a critical challenge: the prevalence of outdated\ninformation in knowledge bases. Current research primarily focuses on\nincorporating up-to-date information, yet the impact of outdated information\ncoexisting in retrieval sources remains inadequately addressed. To bridge this\ngap, we introduce HoH, the first benchmark specifically designed to evaluate\nthe impact of outdated information on RAG. Our benchmark leverages token-level\ndiff algorithms combined with LLM pipelines to efficiently create a large-scale\nQA dataset that accurately captures temporal knowledge evolution in real-world\nfacts. Through comprehensive experiments, we reveal that outdated information\nsignificantly degrades RAG performance in two critical ways: (1) it\nsubstantially reduces response accuracy by distracting models from correct\ninformation, and (2) it can mislead models into generating potentially harmful\noutputs, even when current information is available. Current RAG approaches\nstruggle with both retrieval and generation aspects when handling outdated\ninformation. These findings highlight the urgent need for innovative solutions\nto address the temporal challenges in RAG.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04800v1",
    "published_date": "2025-03-03 06:54:05 UTC",
    "updated_date": "2025-03-03 06:54:05 UTC"
  },
  {
    "arxiv_id": "2503.01220v2",
    "title": "Tera-MIND: Tera-scale mouse brain simulation via spatial mRNA-guided diffusion",
    "authors": [
      "Jiqing Wu",
      "Ingrid Berg",
      "Yawei Li",
      "Ender Konukoglu",
      "Viktor H. Koelzer"
    ],
    "abstract": "Holistic 3D modeling of molecularly defined brain structures is crucial for\nunderstanding complex brain functions. Emerging tissue profiling technologies\nenable the construction of a comprehensive atlas of the mammalian brain with\nsub-cellular resolution and spatially resolved gene expression data. However,\nsuch tera-scale volumetric datasets present significant computational\nchallenges in understanding complex brain functions within their native 3D\nspatial context. Here, we propose the novel generative approach\n$\\textbf{Tera-MIND}$, which can simulate $\\textbf{Tera}$-scale $\\textbf{M}$ouse\nbra$\\textbf{IN}$s in 3D using a patch-based and boundary-aware\n$\\textbf{D}$iffusion model. Taking spatial transcriptomic data as the\nconditional input, we generate virtual mouse brains with comprehensive cellular\nmorphological detail at teravoxel scale. Through the lens of 3D $gene$-$gene$\nself-attention, we identify spatial molecular interactions for key\ntranscriptomic pathways in the murine brain, exemplified by glutamatergic and\ndopaminergic neuronal systems. Importantly, these $in$-$silico$ biological\nfindings are consistent and reproducible across three tera-scale virtual mouse\nbrains. Therefore, Tera-MIND showcases a promising path toward efficient and\ngenerative simulations of whole organ systems for biomedical research. Project\nwebsite: https://musikisomorphie.github.io/Tera-MIND.html",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01220v2",
    "published_date": "2025-03-03 06:37:30 UTC",
    "updated_date": "2025-03-04 06:50:03 UTC"
  },
  {
    "arxiv_id": "2503.04798v1",
    "title": "Advancing MAPF towards the Real World: A Scalable Multi-Agent Realistic Testbed (SMART)",
    "authors": [
      "Jingtian Yan",
      "Zhifei Li",
      "William Kang",
      "Yulun Zhang",
      "Stephen Smith",
      "Jiaoyang Li"
    ],
    "abstract": "We present Scalable Multi-Agent Realistic Testbed (SMART), a realistic and\nefficient software tool for evaluating Multi-Agent Path Finding (MAPF)\nalgorithms. MAPF focuses on planning collision-free paths for a group of\nagents. While state-of-the-art MAPF algorithms can plan paths for hundreds of\nrobots in seconds, they often rely on simplified robot models, making their\nreal-world performance unclear. Researchers typically lack access to hundreds\nof physical robots in laboratory settings to evaluate the algorithms.\nMeanwhile, industrial professionals who lack expertise in MAPF require an\neasy-to-use simulator to efficiently test and understand the performance of\nMAPF algorithms in their specific settings. SMART fills this gap with several\nadvantages: (1) SMART uses a physics-engine-based simulator to create realistic\nsimulation environments, accounting for complex real-world factors such as\nrobot kinodynamics and execution uncertainties, (2) SMART uses an execution\nmonitor framework based on the Action Dependency Graph, facilitating seamless\nintegration with various MAPF algorithms and robot models, and (3) SMART scales\nto thousands of robots. In addition, we use SMART to explore and demonstrate\nresearch questions about the execution of MAPF algorithms in real-world\nscenarios. The code is publicly available at\nhttps://jingtianyan.github.io/publication/2025-smart.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04798v1",
    "published_date": "2025-03-03 05:26:59 UTC",
    "updated_date": "2025-03-03 05:26:59 UTC"
  },
  {
    "arxiv_id": "2503.01935v1",
    "title": "MultiAgentBench: Evaluating the Collaboration and Competition of LLM agents",
    "authors": [
      "Kunlun Zhu",
      "Hongyi Du",
      "Zhaochen Hong",
      "Xiaocheng Yang",
      "Shuyi Guo",
      "Zhe Wang",
      "Zhenhailong Wang",
      "Cheng Qian",
      "Xiangru Tang",
      "Heng Ji",
      "Jiaxuan You"
    ],
    "abstract": "Large Language Models (LLMs) have shown remarkable capabilities as autonomous\nagents, yet existing benchmarks either focus on single-agent tasks or are\nconfined to narrow domains, failing to capture the dynamics of multi-agent\ncoordination and competition. In this paper, we introduce MultiAgentBench, a\ncomprehensive benchmark designed to evaluate LLM-based multi-agent systems\nacross diverse, interactive scenarios. Our framework measures not only task\ncompletion but also the quality of collaboration and competition using novel,\nmilestone-based key performance indicators. Moreover, we evaluate various\ncoordination protocols (including star, chain, tree, and graph topologies) and\ninnovative strategies such as group discussion and cognitive planning. Notably,\ngpt-4o-mini reaches the average highest task score, graph structure performs\nthe best among coordination protocols in the research scenario, and cognitive\nplanning improves milestone achievement rates by 3%. Code and datasets are\npublic available at https://github.com/MultiagentBench/MARBLE.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.MA",
    "comment": "https://github.com/MultiagentBench/MARBLE",
    "pdf_url": "http://arxiv.org/pdf/2503.01935v1",
    "published_date": "2025-03-03 05:18:50 UTC",
    "updated_date": "2025-03-03 05:18:50 UTC"
  },
  {
    "arxiv_id": "2503.05797v1",
    "title": "Fault Localization and State Estimation of Power Grid under Parallel Cyber-Physical Attacks",
    "authors": [
      "Junhao Ren",
      "Kai Zhao",
      "Guangxiao Zhang",
      "Xinghua Liu",
      "Chao Zhai",
      "Gaoxi Xiao"
    ],
    "abstract": "Parallel cyber-physical attacks (PCPA) refer to those attacks on power grids\nby disturbing/cutting off physical transmission lines and meanwhile blocking\ntransmission of measurement data to dwarf or delay the system protection and\nrecovery actions. Such fierce hostile attacks impose critical threats to the\nmodern power grids when there is a fusion of power grids and telecommunication\ntechnologies. In this paper, we investigate the fault diagnosis problem of\nfaulty transmission lines under a broader spectrum of PCPA for a linearized (or\nDC) power flow model. The physical attack mechanism of PCPA includes not only\ndisconnection but also admittance value modification on transmission lines, for\nexample, by invading distributed flexible AC transmission system (D-FACTS). To\ntackle the problem, we first recover the information of voltage phase angles\nwithin the attacked area. Using the information of voltage phase angle and\npower injection of buses, a graph attention network-based fault localization\n(GAT-FL) algorithm is proposed to find the locations of the physical attacks.\nBy capitalizing on the feature extraction capability of the GAT on graph data,\nthe fault localization algorithm outperforms the existing results when under\ncyber attacks, e.g., denial of service (DoS) attacks. A line state\nidentification algorithm is then developed to identify the states of the\ntransmission lines within the attacked area. Specifically, the algorithm\nrestores the power injection of buses within the attacked area and then\nidentities the state of all the transmission lines within the attacked area by\nsolving a linear programming (LP) problem. Experimental simulations are\neffectiveness of the proposed fault diagnosis algorithms.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "10 pages, 3 figures, 5 tables, journal",
    "pdf_url": "http://arxiv.org/pdf/2503.05797v1",
    "published_date": "2025-03-03 05:10:41 UTC",
    "updated_date": "2025-03-03 05:10:41 UTC"
  },
  {
    "arxiv_id": "2503.02897v1",
    "title": "ClipGrader: Leveraging Vision-Language Models for Robust Label Quality Assessment in Object Detection",
    "authors": [
      "Hong Lu",
      "Yali Bian",
      "Rahul C. Shah"
    ],
    "abstract": "High-quality annotations are essential for object detection models, but\nensuring label accuracy - especially for bounding boxes - remains both\nchallenging and costly. This paper introduces ClipGrader, a novel approach that\nleverages vision-language models to automatically assess the accuracy of\nbounding box annotations. By adapting CLIP (Contrastive Language-Image\nPre-training) to evaluate both class label correctness and spatial precision of\nbounding box, ClipGrader offers an effective solution for grading object\ndetection labels. Tested on modified object detection datasets with\nartificially disturbed bounding boxes, ClipGrader achieves 91% accuracy on COCO\nwith a 1.8% false positive rate. Moreover, it maintains 87% accuracy with a\n2.1% false positive rate when trained on just 10% of the COCO data. ClipGrader\nalso scales effectively to larger datasets such as LVIS, achieving 79% accuracy\nacross 1,203 classes. Our experiments demonstrate ClipGrader's ability to\nidentify errors in existing COCO annotations, highlighting its potential for\ndataset refinement. When integrated into a semi-supervised object detection\n(SSOD) model, ClipGrader readily improves the pseudo label quality, helping\nachieve higher mAP (mean Average Precision) throughout the training process.\nClipGrader thus provides a scalable AI-assisted tool for enhancing annotation\nquality control and verifying annotations in large-scale object detection\ndatasets.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.02897v1",
    "published_date": "2025-03-03 05:02:31 UTC",
    "updated_date": "2025-03-03 05:02:31 UTC"
  },
  {
    "arxiv_id": "2503.05796v1",
    "title": "Towards Multi-Stakeholder Evaluation of ML Models: A Crowdsourcing Study on Metric Preferences in Job-matching System",
    "authors": [
      "Takuya Yokota",
      "Yuri Nakao"
    ],
    "abstract": "While machine learning (ML) technology affects diverse stakeholders, there is\nno one-size-fits-all metric to evaluate the quality of outputs, including\nperformance and fairness. Using predetermined metrics without soliciting\nstakeholder opinions is problematic because it leads to an unfair disregard for\nstakeholders in the ML pipeline. In this study, to establish practical ways to\nincorporate diverse stakeholder opinions into the selection of metrics for ML,\nwe investigate participants' preferences for different metrics by using\ncrowdsourcing. We ask 837 participants to choose a better model from two\nhypothetical ML models in a hypothetical job-matching system twenty times and\ncalculate their utility values for seven metrics. To examine the participants'\nfeedback in detail, we divide them into five clusters based on their utility\nvalues and analyze the tendencies of each cluster, including their preferences\nfor metrics and common attributes. Based on the results, we discuss the points\nthat should be considered when selecting appropriate metrics and evaluating ML\nmodels with multiple stakeholders.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "This version of the contribution has been accepted for publication,\n  after peer review (when applicable) but is not the Version of Record and does\n  not reflect post-acceptance improvements, or any corrections. Use of this\n  Accepted Version is subject to the publisher's Accepted Manuscript terms of\n  use\n  https://www.springernature.com/gp/open-research/policies/accepted-manuscript-terms",
    "pdf_url": "http://arxiv.org/pdf/2503.05796v1",
    "published_date": "2025-03-03 04:51:33 UTC",
    "updated_date": "2025-03-03 04:51:33 UTC"
  },
  {
    "arxiv_id": "2503.01176v1",
    "title": "Prognostics and Health Management of Wafer Chemical-Mechanical Polishing System using Autoencoder",
    "authors": [
      "Kart-Leong Lim",
      "Rahul Dutta"
    ],
    "abstract": "The Prognostics and Health Management Data Challenge (PHM) 2016 tracks the\nhealth state of components of a semiconductor wafer polishing process. The\nultimate goal is to develop an ability to predict the measurement on the wafer\nsurface wear through monitoring the components health state. This translates to\ncost saving in large scale production. The PHM dataset contains many time\nseries measurements not utilized by traditional physics based approach. On the\nother hand task, applying a data driven approach such as deep learning to the\nPHM dataset is non-trivial. The main issue with supervised deep learning is\nthat class label is not available to the PHM dataset. Second, the feature space\ntrained by an unsupervised deep learner is not specifically targeted at the\npredictive ability or regression. In this work, we propose using the\nautoencoder based clustering whereby the feature space trained is found to be\nmore suitable for performing regression. This is due to having a more compact\ndistribution of samples respective to their nearest cluster means. We justify\nour claims by comparing the performance of our proposed method on the PHM\ndataset with several baselines such as the autoencoder as well as\nstate-of-the-art approaches.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01176v1",
    "published_date": "2025-03-03 04:48:34 UTC",
    "updated_date": "2025-03-03 04:48:34 UTC"
  },
  {
    "arxiv_id": "2503.01163v1",
    "title": "Bandit-Based Prompt Design Strategy Selection Improves Prompt Optimizers",
    "authors": [
      "Rin Ashizawa",
      "Yoichi Hirose",
      "Nozomu Yoshinari",
      "Kento Uchida",
      "Shinichi Shirakawa"
    ],
    "abstract": "Prompt optimization aims to search for effective prompts that enhance the\nperformance of large language models (LLMs). Although existing prompt\noptimization methods have discovered effective prompts, they often differ from\nsophisticated prompts carefully designed by human experts. Prompt design\nstrategies, representing best practices for improving prompt performance, can\nbe key to improving prompt optimization. Recently, a method termed the\nAutonomous Prompt Engineering Toolbox (APET) has incorporated various prompt\ndesign strategies into the prompt optimization process. In APET, the LLM is\nneeded to implicitly select and apply the appropriate strategies because prompt\ndesign strategies can have negative effects. This implicit selection may be\nsuboptimal due to the limited optimization capabilities of LLMs. This paper\nintroduces Optimizing Prompts with sTrategy Selection (OPTS), which implements\nexplicit selection mechanisms for prompt design. We propose three mechanisms,\nincluding a Thompson sampling-based approach, and integrate them into\nEvoPrompt, a well-known prompt optimizer. Experiments optimizing prompts for\ntwo LLMs, Llama-3-8B-Instruct and GPT-4o mini, were conducted using BIG-Bench\nHard. Our results show that the selection of prompt design strategies improves\nthe performance of EvoPrompt, and the Thompson sampling-based mechanism\nachieves the best overall results. Our experimental code is provided at\nhttps://github.com/shiralab/OPTS .",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01163v1",
    "published_date": "2025-03-03 04:24:04 UTC",
    "updated_date": "2025-03-03 04:24:04 UTC"
  },
  {
    "arxiv_id": "2503.01152v1",
    "title": "STGAN: Spatial-temporal Graph Autoregression Network for Pavement Distress Deterioration Prediction",
    "authors": [
      "Shilin Tong",
      "Difei Wu",
      "Xiaona Liu",
      "Le Zheng",
      "Yuchuan Du",
      "Difan Zou"
    ],
    "abstract": "Pavement distress significantly compromises road integrity and poses risks to\ndrivers. Accurate prediction of pavement distress deterioration is essential\nfor effective road management, cost reduction in maintenance, and improvement\nof traffic safety. However, real-world data on pavement distress is usually\ncollected irregularly, resulting in uneven, asynchronous, and sparse\nspatial-temporal datasets. This hinders the application of existing\nspatial-temporal models, such as DCRNN, since they are only applicable to\nregularly and synchronously collected data. To overcome these challenges, we\npropose the Spatial-Temporal Graph Autoregression Network (STGAN), a novel\ngraph neural network model designed for accurately predicting irregular\npavement distress deterioration using complex spatial-temporal data.\nSpecifically, STGAN integrates the temporal domain into the spatial domain,\ncreating a larger graph where nodes are represented by spatial-temporal tuples\nand edges are formed based on a similarity-based connection mechanism.\nFurthermore, based on the constructed spatiotemporal graph, we formulate\npavement distress deterioration prediction as a graph autoregression task,\ni.e., the graph size increases incrementally and the prediction is performed\nsequentially. This is accomplished by a novel spatial-temporal attention\nmechanism deployed by STGAN. Utilizing the ConTrack dataset, which contains\npavement distress records collected from different locations in Shanghai, we\ndemonstrate the superior performance of STGAN in capturing spatial-temporal\ncorrelations and addressing the aforementioned challenges. Experimental results\nfurther show that STGAN outperforms baseline models, and ablation studies\nconfirm the effectiveness of its novel modules. Our findings contribute to\npromoting proactive road maintenance decision-making and ultimately enhancing\nroad safety and resilience.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "16 pages, 16 figures, 4 tables, accepted by IEEE Transactions on\n  Intelligent Transportation Systems (TITS)",
    "pdf_url": "http://arxiv.org/pdf/2503.01152v1",
    "published_date": "2025-03-03 03:59:34 UTC",
    "updated_date": "2025-03-03 03:59:34 UTC"
  },
  {
    "arxiv_id": "2503.01151v1",
    "title": "ReaderLM-v2: Small Language Model for HTML to Markdown and JSON",
    "authors": [
      "Feng Wang",
      "Zesheng Shi",
      "Bo Wang",
      "Nan Wang",
      "Han Xiao"
    ],
    "abstract": "We present ReaderLM-v2, a compact 1.5 billion parameter language model\ndesigned for efficient web content extraction. Our model processes documents up\nto 512K tokens, transforming messy HTML into clean Markdown or JSON formats\nwith high accuracy -- making it an ideal tool for grounding large language\nmodels. The model's effectiveness results from two key innovations: (1) a\nthree-stage data synthesis pipeline that generates high quality, diverse\ntraining data by iteratively drafting, refining, and critiquing web content\nextraction; and (2) a unified training framework combining continuous\npre-training with multi-objective optimization. Intensive evaluation\ndemonstrates that ReaderLM-v2 outperforms GPT-4o-2024-08-06 and other larger\nmodels by 15-20\\% on carefully curated benchmarks, particularly excelling at\ndocuments exceeding 100K tokens, while maintaining significantly lower\ncomputational requirements.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "68T50",
      "I.2.7; I.2.10"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages, 10-12 refs",
    "pdf_url": "http://arxiv.org/pdf/2503.01151v1",
    "published_date": "2025-03-03 03:57:04 UTC",
    "updated_date": "2025-03-03 03:57:04 UTC"
  },
  {
    "arxiv_id": "2503.01148v1",
    "title": "Dynamic spillovers and investment strategies across artificial intelligence ETFs, artificial intelligence tokens, and green markets",
    "authors": [
      "Ying-Hui Shao",
      "Yan-Hong Yang",
      "Wei-Xing Zhou"
    ],
    "abstract": "This paper investigates the risk spillovers among AI ETFs, AI tokens, and\ngreen markets using the R2 decomposition method. We reveal several key\ninsights. First, the overall transmission connectedness index (TCI) closely\naligns with the contemporaneous TCI, while the lagged TCI is significantly\nlower. Second, AI ETFs and clean energy act as risk transmitters, whereas AI\ntokens and green bond function as risk receivers. Third, AI tokens are\ndifficult to hedge and provide limited hedging ability compared to AI ETFs and\ngreen assets. However, multivariate portfolios effectively reduce AI tokens\ninvestment risk. Among them, the minimum correlation portfolio outperforms the\nminimum variance and minimum connectedness portfolios.",
    "categories": [
      "q-fin.RM",
      "cs.AI"
    ],
    "primary_category": "q-fin.RM",
    "comment": "21 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.01148v1",
    "published_date": "2025-03-03 03:53:33 UTC",
    "updated_date": "2025-03-03 03:53:33 UTC"
  },
  {
    "arxiv_id": "2503.01144v1",
    "title": "One-shot In-context Part Segmentation",
    "authors": [
      "Zhenqi Dai",
      "Ting Liu",
      "Xingxing Zhang",
      "Yunchao Wei",
      "Yanning Zhang"
    ],
    "abstract": "In this paper, we present the One-shot In-context Part Segmentation (OIParts)\nframework, designed to tackle the challenges of part segmentation by leveraging\nvisual foundation models (VFMs). Existing training-based one-shot part\nsegmentation methods that utilize VFMs encounter difficulties when faced with\nscenarios where the one-shot image and test image exhibit significant variance\nin appearance and perspective, or when the object in the test image is\npartially visible. We argue that training on the one-shot example often leads\nto overfitting, thereby compromising the model's generalization capability. Our\nframework offers a novel approach to part segmentation that is training-free,\nflexible, and data-efficient, requiring only a single in-context example for\nprecise segmentation with superior generalization ability. By thoroughly\nexploring the complementary strengths of VFMs, specifically DINOv2 and Stable\nDiffusion, we introduce an adaptive channel selection approach by minimizing\nthe intra-class distance for better exploiting these two features, thereby\nenhancing the discriminatory power of the extracted features for the\nfine-grained parts. We have achieved remarkable segmentation performance across\ndiverse object categories. The OIParts framework not only eliminates the need\nfor extensive labeled data but also demonstrates superior generalization\nability. Through comprehensive experimentation on three benchmark datasets, we\nhave demonstrated the superiority of our proposed method over existing part\nsegmentation approaches in one-shot settings.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.01144v1",
    "published_date": "2025-03-03 03:50:54 UTC",
    "updated_date": "2025-03-03 03:50:54 UTC"
  },
  {
    "arxiv_id": "2503.01141v1",
    "title": "How Well do LLMs Compress Their Own Chain-of-Thought? A Token Complexity Approach",
    "authors": [
      "Ayeong Lee",
      "Ethan Che",
      "Tianyi Peng"
    ],
    "abstract": "Chain-of-thought prompting has emerged as a powerful technique for enabling\nlarge language models (LLMs) to solve complex reasoning tasks. However, these\nreasoning chains can be verbose, raising concerns about efficiency. In\nresponse, recent works have sought to decrease response lengths through simple\nprompting strategies (e.g. 'be concise'). In this work, we conduct the first\nsystematic study of the relationship between reasoning length and model\nperformance across a diverse range of compression instructions (e.g. 'use 10\nwords or less' or 'remove all punctuation'). In doing so, we discover a\nuniversal tradeoff between reasoning length and accuracy that persists across\neven very distinct reasoning chains. We demonstrate that this tradeoff emerges\nfrom a sharp threshold behavior at the question level: each task has an\nintrinsic 'token complexity' - a minimal number of tokens required for\nsuccessful problem-solving. We show how token complexity enables us to compute\ninformation-theoretic limits on the accuracy-compression tradeoff, and find\nthat prompt-based compression strategies operate far from these theoretical\nlimits. This suggests there may be significant room for improvement and our\nframework provides a benchmark to help researchers evaluate progress in\nreasoning efficiency. Our work also highlights the importance of adaptive\ncompression -- giving shorter responses for easier questions -- and we show\nthat token complexity is a useful tool for measuring this capability.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01141v1",
    "published_date": "2025-03-03 03:48:20 UTC",
    "updated_date": "2025-03-03 03:48:20 UTC"
  },
  {
    "arxiv_id": "2503.01139v2",
    "title": "Can Large Language Models Help Experimental Design for Causal Discovery?",
    "authors": [
      "Junyi Li",
      "Yongqiang Chen",
      "Chenxi Liu",
      "Qianyi Cai",
      "Tongliang Liu",
      "Bo Han",
      "Kun Zhang",
      "Hui Xiong"
    ],
    "abstract": "Designing proper experiments and selecting optimal intervention targets is a\nlongstanding problem in scientific or causal discovery. Identifying the\nunderlying causal structure from observational data alone is inherently\ndifficult. Obtaining interventional data, on the other hand, is crucial to\ncausal discovery, yet it is usually expensive and time-consuming to gather\nsufficient interventional data to facilitate causal discovery. Previous\napproaches commonly utilize uncertainty or gradient signals to determine the\nintervention targets. However, numerical-based approaches may yield suboptimal\nresults due to the inaccurate estimation of the guiding signals at the\nbeginning when with limited interventional data. In this work, we investigate a\ndifferent approach, whether we can leverage Large Language Models (LLMs) to\nassist with the intervention targeting in causal discovery by making use of the\nrich world knowledge about the experimental design in LLMs. Specifically, we\npresent Large Language Model Guided Intervention Targeting (LeGIT) -- a robust\nframework that effectively incorporates LLMs to augment existing numerical\napproaches for the intervention targeting in causal discovery. Across 4\nrealistic benchmark scales, LeGIT demonstrates significant improvements and\nrobustness over existing methods and even surpasses humans, which demonstrates\nthe usefulness of LLMs in assisting with experimental design for scientific\ndiscovery.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "stat.ME"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01139v2",
    "published_date": "2025-03-03 03:43:05 UTC",
    "updated_date": "2025-03-04 04:19:03 UTC"
  },
  {
    "arxiv_id": "2503.01134v1",
    "title": "Statistical Tractability of Off-policy Evaluation of History-dependent Policies in POMDPs",
    "authors": [
      "Yuheng Zhang",
      "Nan Jiang"
    ],
    "abstract": "We investigate off-policy evaluation (OPE), a central and fundamental problem\nin reinforcement learning (RL), in the challenging setting of Partially\nObservable Markov Decision Processes (POMDPs) with large observation spaces.\nRecent works of Uehara et al. (2023a); Zhang & Jiang (2024) developed a\nmodel-free framework and identified important coverage assumptions (called\nbelief and outcome coverage) that enable accurate OPE of memoryless policies\nwith polynomial sample complexities, but handling more general target policies\nthat depend on the entire observable history remained an open problem. In this\nwork, we prove information-theoretic hardness for model-free OPE of\nhistory-dependent policies in several settings, characterized by additional\nassumptions imposed on the behavior policy (memoryless vs. history-dependent)\nand/or the state-revealing property of the POMDP (single-step vs. multi-step\nrevealing). We further show that some hardness can be circumvented by a natural\nmodel-based algorithm -- whose analysis has surprisingly eluded the literature\ndespite the algorithm's simplicity -- demonstrating provable separation between\nmodel-free and model-based OPE in POMDPs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01134v1",
    "published_date": "2025-03-03 03:29:05 UTC",
    "updated_date": "2025-03-03 03:29:05 UTC"
  },
  {
    "arxiv_id": "2503.01131v1",
    "title": "Beyond QA Pairs: Assessing Parameter-Efficient Fine-Tuning for Fact Embedding in LLMs",
    "authors": [
      "Shivam Ratnakar",
      "Abhiroop Talasila",
      "Raghav Chamadiya",
      "Nikhil Agarwal",
      "Vinayak K Doifode"
    ],
    "abstract": "This paper presents an extensive examination of Parameter-Efficient\nFine-Tuning (PEFT) for embedding domain specific facts into Large Language\nModels (LLMs), focusing on improving the fine-tuning process by categorizing\nquestion-answer (QA) pairs into Factual and Conceptual classes using a\nBERT-based classifier. Two distinct Llama-2 models are fine-tuned based on\nthese classifications and evaluated using larger models like GPT-3.5 Turbo and\nGemini. Our results indicate that models trained on conceptual datasets\noutperform those trained on factual datasets. Additionally, we compare the\nefficiency of two synthetic fine-tuning dataset generation techniques, D-RAG\nand D-Naive, with D-Naive demonstrating superior performance. Although PEFT has\nshown effectiveness, our research indicates that it may not be the most optimal\nmethod for embedding facts into LLMs. However, it has demonstrated exceptional\nperformance in instruction-based tasks. Our findings are reinforced by a\n1000-sample dataset in the data center domain, where the fine-tuned Llama-2 7B\nmodel significantly outperforms the baseline model in generating product\nrecommendations. Our study highlights the importance of QA pair categorization\nand synthetic dataset generation techniques in enhancing the performance of\nLLMs in specific domains.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Presented at the Workshop on Preparing Good Data for Generative AI:\n  Challenges and Approaches (Good-Data) in conjunction with AAAI 2025. The\n  authors retain the copyright",
    "pdf_url": "http://arxiv.org/pdf/2503.01131v1",
    "published_date": "2025-03-03 03:26:30 UTC",
    "updated_date": "2025-03-03 03:26:30 UTC"
  },
  {
    "arxiv_id": "2503.01126v2",
    "title": "Constrained multi-fidelity Bayesian optimization with automatic stop condition",
    "authors": [
      "Zahra Zanjani Foumani",
      "Ramin Bostanabad"
    ],
    "abstract": "Bayesian optimization (BO) is increasingly employed in critical applications\nto find the optimal design with minimal cost. While BO is known for its sample\nefficiency, relying solely on costly high-fidelity data can still result in\nhigh costs. This is especially the case in constrained search spaces where BO\nmust not only optimize but also ensure feasibility. A related issue in the BO\nliterature is the lack of a systematic stopping criterion. To solve these\nchallenges, we develop a constrained cost-aware multi-fidelity BO (CMFBO)\nframework whose goal is to minimize overall sampling costs by utilizing\ninexpensive low-fidelity sources while ensuring feasibility. In our case, the\nconstraints can change across the data sources and may be even black-box\nfunctions. We also introduce a systematic stopping criterion that addresses the\nlong-lasting issue associated with BO's convergence assessment. Our framework\nis publicly available on GitHub through the GP+ Python package and herein we\nvalidate it's efficacy on multiple benchmark problems.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01126v2",
    "published_date": "2025-03-03 03:13:35 UTC",
    "updated_date": "2025-03-21 22:41:37 UTC"
  },
  {
    "arxiv_id": "2503.01931v1",
    "title": "Adversarial Generative Flow Network for Solving Vehicle Routing Problems",
    "authors": [
      "Ni Zhang",
      "Jingfeng Yang",
      "Zhiguang Cao",
      "Xu Chi"
    ],
    "abstract": "Recent research into solving vehicle routing problems (VRPs) has gained\nsignificant traction, particularly through the application of deep\n(reinforcement) learning for end-to-end solution construction. However, many\ncurrent construction-based neural solvers predominantly utilize Transformer\narchitectures, which can face scalability challenges and struggle to produce\ndiverse solutions. To address these limitations, we introduce a novel framework\nbeyond Transformer-based approaches, i.e., Adversarial Generative Flow Networks\n(AGFN). This framework integrates the generative flow network (GFlowNet)-a\nprobabilistic model inherently adept at generating diverse solutions\n(routes)-with a complementary model for discriminating (or evaluating) the\nsolutions. These models are trained alternately in an adversarial manner to\nimprove the overall solution quality, followed by a proposed hybrid decoding\nmethod to construct the solution. We apply the AGFN framework to solve the\ncapacitated vehicle routing problem (CVRP) and travelling salesman problem\n(TSP), and our experimental results demonstrate that AGFN surpasses the popular\nconstruction-based neural solvers, showcasing strong generalization\ncapabilities on synthetic and real-world benchmark instances.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.01931v1",
    "published_date": "2025-03-03 03:06:56 UTC",
    "updated_date": "2025-03-03 03:06:56 UTC"
  },
  {
    "arxiv_id": "2503.01121v1",
    "title": "Hybrid Metaheuristic Vehicle Routing Problem for Security Dispatch Operations",
    "authors": [
      "Nguyen Gia Hien Vu",
      "Yifan Tang",
      "Rey Lim",
      "G. Gary Wang"
    ],
    "abstract": "This paper investigates the optimization of the Vehicle Routing Problem for\nSecurity Dispatch (VRPSD). VRPSD focuses on security and patrolling\napplications which involve challenging constraints including precise timing and\nstrict time windows. We propose three algorithms based on different\nmetaheuristics, which are Adaptive Large Neighborhood Search (ALNS), Tabu\nSearch (TS), and Threshold Accepting (TA). The first algorithm combines\nsingle-phase ALNS with TA, the second employs a multiphase ALNS with TA, and\nthe third integrates multiphase ALNS, TS, and TA. Experiments are conducted on\nan instance comprising 251 customer requests. The results demonstrate that the\nthird algorithm, the hybrid multiphase ALNS-TS-TA algorithm, delivers the best\nperformance. This approach simultaneously leverages the large-area search\ncapabilities of ALNS for exploration and effectively escapes local optima when\nthe multiphase ALNS is coupled with TS and TA. Furthermore, in our experiments,\nthe hybrid multiphase ALNS-TS-TA algorithm is the only one that shows potential\nfor improving results with increased computation time across all attempts.",
    "categories": [
      "cs.AI",
      "cs.DM",
      "math.OC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01121v1",
    "published_date": "2025-03-03 02:58:49 UTC",
    "updated_date": "2025-03-03 02:58:49 UTC"
  },
  {
    "arxiv_id": "2503.01109v1",
    "title": "FGS-SLAM: Fourier-based Gaussian Splatting for Real-time SLAM with Sparse and Dense Map Fusion",
    "authors": [
      "Yansong Xu",
      "Junlin Li",
      "Wei Zhang",
      "Siyu Chen",
      "Shengyong Zhang",
      "Yuquan Leng",
      "Weijia Zhou"
    ],
    "abstract": "3D gaussian splatting has advanced simultaneous localization and mapping\n(SLAM) technology by enabling real-time positioning and the construction of\nhigh-fidelity maps. However, the uncertainty in gaussian position and\ninitialization parameters introduces challenges, often requiring extensive\niterative convergence and resulting in redundant or insufficient gaussian\nrepresentations. To address this, we introduce a novel adaptive densification\nmethod based on Fourier frequency domain analysis to establish gaussian priors\nfor rapid convergence. Additionally, we propose constructing independent and\nunified sparse and dense maps, where a sparse map supports efficient tracking\nvia Generalized Iterative Closest Point (GICP) and a dense map creates\nhigh-fidelity visual representations. This is the first SLAM system leveraging\nfrequency domain analysis to achieve high-quality gaussian mapping in\nreal-time. Experimental results demonstrate an average frame rate of 36 FPS on\nReplica and TUM RGB-D datasets, achieving competitive accuracy in both\nlocalization and mapping.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01109v1",
    "published_date": "2025-03-03 02:33:39 UTC",
    "updated_date": "2025-03-03 02:33:39 UTC"
  },
  {
    "arxiv_id": "2503.01102v1",
    "title": "Ground contact and reaction force sensing for linear policy control of quadruped robot",
    "authors": [
      "Harshita Mhaske",
      "Aniket Mandhare",
      "Jidong Huang",
      "Yu Bai"
    ],
    "abstract": "Designing robots capable of traversing uneven terrain and overcoming physical\nobstacles has been a longstanding challenge in the field of robotics. Walking\nrobots show promise in this regard due to their agility, redundant DOFs and\nintermittent ground contact of locomoting appendages. However, the complexity\nof walking robots and their numerous DOFs make controlling them extremely\ndifficult and computation heavy. Linear policies trained with reinforcement\nlearning have been shown to perform adequately to enable quadrupedal walking,\nwhile being computationally light weight. The goal of this research is to study\nthe effect of augmentation of observation space of a linear policy with newer\nstate variables on performance of the policy. Since ground contact and reaction\nforces are the primary means of robot-environment interaction, they are\nessential state variables on which the linear policy must be informed.\nExperimental results show that augmenting the observation space with ground\ncontact and reaction force data trains policies with better survivability,\nbetter stability against external disturbances and higher adaptability to\nuntrained conditions.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "5 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.01102v1",
    "published_date": "2025-03-03 02:04:55 UTC",
    "updated_date": "2025-03-03 02:04:55 UTC"
  },
  {
    "arxiv_id": "2503.01100v2",
    "title": "Fence Theorem: Towards Dual-Objective Semantic-Structure Isolation in Preprocessing Phase for 3D Anomaly Detection",
    "authors": [
      "Hanzhe Liang",
      "Jie Zhou",
      "Xuanxin Chen",
      "Tao Dai",
      "Jinbao Wang",
      "Can Gao"
    ],
    "abstract": "3D anomaly detection (AD) is prominent but difficult due to lacking a unified\ntheoretical foundation for preprocessing design. We establish the Fence\nTheorem, formalizing preprocessing as a dual-objective semantic isolator: (1)\nmitigating cross-semantic interference to the greatest extent feasible and (2)\nconfining anomaly judgments to aligned semantic spaces wherever viable, thereby\nestablishing intra-semantic comparability. Any preprocessing approach achieves\nthis goal through a two-stage process of Emantic-Division and\nSpatial-Constraints stage. Through systematic deconstruction, we theoretically\nand experimentally subsume existing preprocessing methods under this theorem\nvia tripartite evidence: qualitative analyses, quantitative studies, and\nmathematical proofs. Guided by the Fence Theorem, we implement Patch3D,\nconsisting of Patch-Cutting and Patch-Matching modules, to segment semantic\nspaces and consolidate similar ones while independently modeling normal\nfeatures within each space. Experiments on Anomaly-ShapeNet and Real3D-AD with\ndifferent settings demonstrate that progressively finer-grained semantic\nalignment in preprocessing directly enhances point-level AD accuracy, providing\ninverse validation of the theorem's causal logic.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01100v2",
    "published_date": "2025-03-03 01:58:11 UTC",
    "updated_date": "2025-03-04 04:33:21 UTC"
  },
  {
    "arxiv_id": "2503.01098v1",
    "title": "SolBench: A Dataset and Benchmark for Evaluating Functional Correctness in Solidity Code Completion and Repair",
    "authors": [
      "Zaoyu Chen",
      "Haoran Qin",
      "Nuo Chen",
      "Xiangyu Zhao",
      "Lei Xue",
      "Xiapu Luo",
      "Xiao-Ming Wu"
    ],
    "abstract": "Smart contracts are crucial programs on blockchains, and their immutability\npost-deployment makes functional correctness vital. Despite progress in code\ncompletion models, benchmarks for Solidity, the primary smart contract\nlanguage, are lacking. Existing metrics like BLEU do not adequately assess the\nfunctional correctness of generated smart contracts. To fill this gap, we\nintroduce SolBench, a benchmark for evaluating the functional correctness of\nSolidity smart contracts generated by code completion models. SolBench includes\n4,178 functions from 1,155 Ethereum-deployed contracts. Testing advanced models\nrevealed challenges in generating correct code without context, as Solidity\nfunctions rely on context-defined variables and interfaces. To address this, we\npropose a Retrieval-Augmented Code Repair framework. In this framework, an\nexecutor verifies functional correctness, and if necessary, an LLM repairs the\ncode using retrieved snippets informed by executor traces. We conduct a\ncomprehensive evaluation of both closed-source and open-source LLMs across\nvarious model sizes and series to assess their performance in smart contract\ncompletion. The results show that code repair and retrieval techniques\neffectively enhance the correctness of smart contract completion while reducing\ncomputational costs.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01098v1",
    "published_date": "2025-03-03 01:55:20 UTC",
    "updated_date": "2025-03-03 01:55:20 UTC"
  },
  {
    "arxiv_id": "2503.01086v1",
    "title": "FAIR: Facilitating Artificial Intelligence Resilience in Manufacturing Industrial Internet",
    "authors": [
      "Yingyan Zeng",
      "Ismini Lourentzou",
      "Xinwei Deng",
      "Ran Jin"
    ],
    "abstract": "Artificial intelligence (AI) systems have been increasingly adopted in the\nManufacturing Industrial Internet (MII). Investigating and enabling the AI\nresilience is very important to alleviate profound impact of AI system failures\nin manufacturing and Industrial Internet of Things (IIoT) operations, leading\nto critical decision making. However, there is a wide knowledge gap in defining\nthe resilience of AI systems and analyzing potential root causes and\ncorresponding mitigation strategies. In this work, we propose a novel framework\nfor investigating the resilience of AI performance over time under hazard\nfactors in data quality, AI pipelines, and the cyber-physical layer. The\nproposed method can facilitate effective diagnosis and mitigation strategies to\nrecover AI performance based on a multimodal multi-head self latent attention\nmodel. The merits of the proposed method are elaborated using an MII testbed of\nconnected Aerosol Jet Printing (AJP) machines, fog nodes, and Cloud with\ninference tasks via AI pipelines.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01086v1",
    "published_date": "2025-03-03 01:17:22 UTC",
    "updated_date": "2025-03-03 01:17:22 UTC"
  },
  {
    "arxiv_id": "2503.01079v1",
    "title": "Depth-Adaptive Graph Neural Networks via Learnable Bakry-'Emery Curvature",
    "authors": [
      "Asela Hevapathige",
      "Ahad N. Zehmakan",
      "Qing Wang"
    ],
    "abstract": "Graph Neural Networks (GNNs) have demonstrated strong representation learning\ncapabilities for graph-based tasks. Recent advances on GNNs leverage geometric\nproperties, such as curvature, to enhance its representation capabilities by\nmodeling complex connectivity patterns and information flow within graphs.\nHowever, most existing approaches focus solely on discrete graph topology,\noverlooking diffusion dynamics and task-specific dependencies essential for\neffective learning. To address this, we propose integrating Bakry-\\'Emery\ncurvature, which captures both structural and task-driven aspects of\ninformation propagation. We develop an efficient, learnable approximation\nstrategy, making curvature computation scalable for large graphs. Furthermore,\nwe introduce an adaptive depth mechanism that dynamically adjusts\nmessage-passing layers per vertex based on its curvature, ensuring efficient\npropagation. Our theoretical analysis establishes a link between curvature and\nfeature distinctiveness, showing that high-curvature vertices require fewer\nlayers, while low-curvature ones benefit from deeper propagation. Extensive\nexperiments on benchmark datasets validate the effectiveness of our approach,\nshowing consistent performance improvements across diverse graph learning\ntasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01079v1",
    "published_date": "2025-03-03 00:48:41 UTC",
    "updated_date": "2025-03-03 00:48:41 UTC"
  },
  {
    "arxiv_id": "2503.01075v1",
    "title": "Tackling Hallucination from Conditional Models for Medical Image Reconstruction with DynamicDPS",
    "authors": [
      "Seunghoi Kim",
      "Henry F. J. Tregidgo",
      "Matteo Figini",
      "Chen Jin",
      "Sarang Joshi",
      "Daniel C. Alexander"
    ],
    "abstract": "Hallucinations are spurious structures not present in the ground truth,\nposing a critical challenge in medical image reconstruction, especially for\ndata-driven conditional models. We hypothesize that combining an unconditional\ndiffusion model with data consistency, trained on a diverse dataset, can reduce\nthese hallucinations. Based on this, we propose DynamicDPS, a diffusion-based\nframework that integrates conditional and unconditional diffusion models to\nenhance low-quality medical images while systematically reducing\nhallucinations. Our approach first generates an initial reconstruction using a\nconditional model, then refines it with an adaptive diffusion-based inverse\nproblem solver. DynamicDPS skips early stage in the reverse process by\nselecting an optimal starting time point per sample and applies Wolfe's line\nsearch for adaptive step sizes, improving both efficiency and image fidelity.\nUsing diffusion priors and data consistency, our method effectively reduces\nhallucinations from any conditional model output. We validate its effectiveness\nin Image Quality Transfer for low-field MRI enhancement. Extensive evaluations\non synthetic and real MR scans, including a downstream task for tissue volume\nestimation, show that DynamicDPS reduces hallucinations, improving relative\nvolume estimation by over 15% for critical tissues while using only 5% of the\nsampling steps required by baseline diffusion models. As a model-agnostic and\nfine-tuning-free approach, DynamicDPS offers a robust solution for\nhallucination reduction in medical imaging. The code will be made publicly\navailable upon publication.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01075v1",
    "published_date": "2025-03-03 00:33:04 UTC",
    "updated_date": "2025-03-03 00:33:04 UTC"
  },
  {
    "arxiv_id": "2503.01069v1",
    "title": "Multi-Agent Reinforcement Learning with Long-Term Performance Objectives for Service Workforce Optimization",
    "authors": [
      "Kareem Eissa",
      "Rayal Prasad",
      "Sarith Mohan",
      "Ankur Kapoor",
      "Dorin Comaniciu",
      "Vivek Singh"
    ],
    "abstract": "Workforce optimization plays a crucial role in efficient organizational\noperations where decision-making may span several different administrative and\ntime scales. For instance, dispatching personnel to immediate service requests\nwhile managing talent acquisition with various expertise sets up a highly\ndynamic optimization problem. Existing work focuses on specific sub-problems\nsuch as resource allocation and facility location, which are solved with\nheuristics like local-search and, more recently, deep reinforcement learning.\nHowever, these may not accurately represent real-world scenarios where such\nsub-problems are not fully independent. Our aim is to fill this gap by creating\na simulator that models a unified workforce optimization problem. Specifically,\nwe designed a modular simulator to support the development of reinforcement\nlearning methods for integrated workforce optimization problems. We focus on\nthree interdependent aspects: personnel dispatch, workforce management, and\npersonnel positioning. The simulator provides configurable parameterizations to\nhelp explore dynamic scenarios with varying levels of stochasticity and\nnon-stationarity. To facilitate benchmarking and ablation studies, we also\ninclude heuristic and RL baselines for the above mentioned aspects.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01069v1",
    "published_date": "2025-03-03 00:16:47 UTC",
    "updated_date": "2025-03-03 00:16:47 UTC"
  },
  {
    "arxiv_id": "2503.01068v1",
    "title": "Language-Guided Object Search in Agricultural Environments",
    "authors": [
      "Advaith Balaji",
      "Saket Pradhan",
      "Dmitry Berenson"
    ],
    "abstract": "Creating robots that can assist in farms and gardens can help reduce the\nmental and physical workload experienced by farm workers. We tackle the problem\nof object search in a farm environment, providing a method that allows a robot\nto semantically reason about the location of an unseen target object among a\nset of previously seen objects in the environment using a Large Language Model\n(LLM). We leverage object-to-object semantic relationships to plan a path\nthrough the environment that will allow us to accurately and efficiently locate\nour target object while also reducing the overall distance traveled, without\nneeding high-level room or area-level semantic relationships. During our\nevaluations, we found that our method outperformed a current state-of-the-art\nbaseline and our ablations. Our offline testing yielded an average path\nefficiency of 84%, reflecting how closely the predicted path aligns with the\nideal path. Upon deploying our system on the Boston Dynamics Spot robot in a\nreal-world farm environment, we found that our system had a success rate of\n80%, with a success weighted by path length of 0.67, which demonstrates a\nreasonable trade-off between task success and path efficiency under real-world\nconditions. The project website can be viewed at\nhttps://adi-balaji.github.io/losae/",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "8 pages, 4 figures, 2 tables, accepted to the 2025 International\n  Conference on Robotics and Automation (ICRA 2025)",
    "pdf_url": "http://arxiv.org/pdf/2503.01068v1",
    "published_date": "2025-03-03 00:15:45 UTC",
    "updated_date": "2025-03-03 00:15:45 UTC"
  },
  {
    "arxiv_id": "2503.01064v1",
    "title": "Scientific Reasoning: Assessment of Multimodal Generative LLMs",
    "authors": [
      "Florian Dreyer",
      "Ekaterina Kolos",
      "Daria Matiash"
    ],
    "abstract": "Large language models (LLMs) can answer questions and reason about complex\ntasks, also from the scientific domain. We assess several multimodal LLMs\n(MLLMs) on ScienceQA and find that Gemini models show the highest accuracy with\nlittle context, and the highest textual similarity to human explanations with\nricher context. Adapter-tuning of smaller MLLMs did not lead to any reliable\nperformance. Training from Gemini outputs consistently underperformed training\nfrom the original data.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01064v1",
    "published_date": "2025-03-03 00:07:22 UTC",
    "updated_date": "2025-03-03 00:07:22 UTC"
  }
]