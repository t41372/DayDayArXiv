{
  "date": "2025-03-03",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-03-03 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦于 AI 和大型语言模型（LLM）的优化、多模态生成、强化学习以及在医学和环境领域的应用，强调模型效率、鲁棒性和实际场景适应性；令人印象深刻的文章包括 Microsoft 团队的 Phi-4-Mini（高效多模态模型）和 Forgetting Transformer（ICLR 2025 论文），以及涉及知名学者如 Aaron Schein 的 LLM 政治视角研究，这些工作展示了 LLM 在复杂任务中的潜力。\n\n下面，我将逐一简要概述今天的论文，先优先讨论重要、创新性强的文章（如 LLM 优化、扩散模型和多代理强化学习），再快速掠过其他较基础或特定领域的论文。每个条目包括论文标题（中文 + 英文）和核心贡献。\n\n### 关键论文聚焦：LLM 和 AI 优化\n- **Forgetting Transformer: Softmax Attention with a Forget Gate**（遗忘 Transformer: 带有遗忘门的 Softmax 注意力机制，英文: Forgetting Transformer: Softmax Attention with a Forget Gate）  \n  这篇 ICLR 2025 论文引入了遗忘门机制到 Transformer 中，提升了长序列语言建模和外推性能，主要贡献是改进了长上下文处理能力，并在针在草堆测试中优于循环模型如 Mamba-2。\n\n- **Phi-4-Mini Technical Report: Compact yet Powerful Multimodal Language Models via Mixture-of-LoRAs**（Phi-4-Mini 技术报告: 通过混合 LoRA 的紧凑多模态语言模型，英文: Phi-4-Mini Technical Report: Compact yet Powerful Multimodal Language Models via Mixture-of-LoRAs）  \n  Microsoft 团队的作品，提出一个 3.8 亿参数的多模态模型，通过混合 LoRA 技术在多任务上超越更大模型，主要发现是其在数学和编码任务上的高效性能，以及对语音和视觉模态的扩展。\n\n- **Linear Representations of Political Perspective Emerge in Large Language Models**（大型语言模型中出现的线性政治视角表示，英文: Linear Representations of Political Perspective Emerge in Large Language Models）  \n  Aaron Schein 参与的 ICLR 2025 论文，展示了 LLM 在激活空间中线性表示政治视角的能力，主要贡献是通过探针预测新闻倾向，并通过线性干预调整模型输出，实现对主观视角的可控性。\n\n- **Provable Benefits of Task-Specific Prompts for In-context Learning**（任务特定提示的证明益处用于上下文学习，英文: Provable Benefits of Task-Specific Prompts for In-context Learning）  \n  这篇 AISTATS 2025 论文证明了任务特定提示在提升上下文学习中的作用，主要发现是提示调整能分离任务分布的均值和方差，提升线性注意力模型的泛化。\n\n- **Superscopes: Amplifying Internal Feature Representations for Language Model Interpretation**（Superscopes: 放大语言模型内部特征表示用于解释，英文: Superscopes: Amplifying Internal Feature Representations for Language Model Interpretation）  \n  提出一种技术来增强 LLM 的内部特征表示，主要贡献是通过一致性模型放大叠加特征，实现无额外训练的模型解释。\n\n- **M3HF: Multi-agent Reinforcement Learning from Multi-phase Human Feedback of Mixed Quality**（M3HF: 多代理强化学习从多阶段混合质量人类反馈，英文: M3HF: Multi-agent Reinforcement Learning from Multi-phase Human Feedback of Mixed Quality）  \n  这篇论文探索多代理强化学习中人类反馈的整合，主要发现是通过自适应权重更新奖励函数，提升了代理在复杂环境中的合作鲁棒性。\n\n- **Interactive Debugging and Steering of Multi-Agent AI Systems**（多代理 AI 系统交互式调试和引导，英文: Interactive Debugging and Steering of Multi-Agent AI Systems）  \n  关注多代理 LLM 的调试工具，主要贡献是开发了 AGDebugger 接口，支持消息编辑和可视化，提高了开发效率。\n\n### 多模态和生成模型创新\n- **LLMs as Educational Analysts: Transforming Multimodal Data Traces into Actionable Reading Assessment Reports**（LLM 作为教育分析师: 将多模态数据追踪转化为可操作的阅读评估报告，英文: LLMs as Educational Analysts: Transforming Multimodal Data Traces into Actionable Reading Assessment Reports）  \n  使用 LLM 处理眼动数据等多模态信息生成教育报告，主要发现是 LLM 可自动化洞察学生行为，提供教师友好的洞见。\n\n- **Correlation to Causation: A Causal Deep Learning Framework for Arctic Sea Ice Prediction**（从相关到因果: 用于北极海冰预测的因果深度学习框架，英文: Correlation to Causation: A Causal Deep Learning Framework for Arctic Sea Ice Prediction）  \n  提出因果框架整合 Granger 因果和深度学习，提高海冰预测准确性，主要贡献是提升了高维系统的预测鲁棒性。\n\n- **Holistically Evaluating the Environmental Impact of Creating Language Models**（整体评估创建语言模型的环境影响，英文: Holistically Evaluating the Environmental Impact of Creating Language Models）  \n  ICLR 2025 亮点论文，量化语言模型开发的环境足迹，主要发现是模型开发阶段碳排放占一半以上，强调了可持续 AI 的必要性。\n\n### 医学和应用领域进展\n- **Biomedical Foundation Model: A Survey**（生物医学基础模型调查，英文: Biomedical Foundation Model: A Survey）  \n  这篇综述探讨基础模型在生物医学中的应用，主要贡献是概述了其在计算生物学和药物发现中的潜力。\n\n- **Abn-BLIP: Abnormality-aligned Bootstrapping Language-Image Pre-training for Pulmonary Embolism Diagnosis**（Abn-BLIP: 用于肺栓塞诊断的异常对齐引导语言-图像预训练，英文: Abn-BLIP: Abnormality-aligned Bootstrapping Language-Image Pre-training for Pulmonary Embolism Diagnosis）  \n  针对医学图像的预训练模型，主要发现是改进了异常检测和报告生成，适用于 CT 扫描诊断。\n\n- **EPEE: Towards Efficient and Effective Foundation Models in Biomedicine**（EPEE: 针对生物医学的高效基础模型，英文: EPEE: Towards Efficient and Effective Foundation Models in Biomedicine）  \n  提出基于熵的早期退出策略，提高生物医学模型的推理效率，主要贡献是减少延迟并保持准确性。\n\n### 其他领域快速掠过\n其他论文涉及强化学习、图像处理和理论分析，但影响较小，仅简要提及：\n\n- **Parabolic Continual Learning**（抛物线持续学习，英文: Parabolic Continual Learning）：使用偏微分方程优化持续学习，减少遗忘错误。\n\n- **TMIQ: Quantifying Test and Measurement Domain Intelligence in Large Language Models**（TMIQ: 量化 LLM 在测试和测量领域的智能，英文: TMIQ: Quantifying Test and Measurement Domain Intelligence in Large Language Models）：评估 LLM 在电子工程任务中的性能。\n\n- **Dynamic Search for Inference-Time Alignment in Diffusion Models**（扩散模型中的动态搜索用于推理时对齐，英文: Dynamic Search for Inference-Time Alignment in Diffusion Models）：改进扩散模型的奖励优化。\n\n- **Federated Learning Framework via Distributed Mutual Learning**（通过分布式互学习的分层学习框架，英文: Federated Learning Framework via Distributed Mutual Learning）：隐私保护的分层学习方法。\n\n- **FRMD: Fast Robot Motion Diffusion with Consistency-Distilled Movement Primitives**（FRMD: 快速机器人运动扩散模型，英文: FRMD: Fast Robot Motion Diffusion with Consistency-Distilled Movement Primitives）：加速机器人轨迹生成。\n\n总体而言，今天的论文突出了 AI 模型的效率和应用潜力，但许多工作仍需在实际部署中验证。更多细节可查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2503.02130v2",
      "title": "Forgetting Transformer: Softmax Attention with a Forget Gate",
      "title_zh": "翻译失败",
      "authors": [
        "Zhixuan Lin",
        "Evgenii Nikishin",
        "Xu Owen He",
        "Aaron Courville"
      ],
      "abstract": "An essential component of modern recurrent sequence models is the forget\ngate. While Transformers do not have an explicit recurrent form, we show that a\nforget gate can be naturally incorporated into Transformers by down-weighting\nthe unnormalized attention scores in a data-dependent way. We name this\nattention mechanism Forgetting Attention and the resulting model the Forgetting\nTransformer (FoX). We show that FoX outperforms the Transformer on long-context\nlanguage modeling, length extrapolation, and short-context downstream tasks,\nwhile performing on par with the Transformer on long-context downstream tasks.\nMoreover, it is compatible with the FlashAttention algorithm and does not\nrequire any positional embeddings. Several analyses, including the\nneedle-in-the-haystack test, show that FoX also retains the Transformer's\nsuperior long-context capabilities over recurrent sequence models such as\nMamba-2, HGRN2, and DeltaNet. We also introduce a \"Pro\" block design that\nincorporates some common architectural components in recurrent sequence models\nand find it significantly improves the performance of both FoX and the\nTransformer. Our code is available at\nhttps://github.com/zhixuan-lin/forgetting-transformer.",
      "tldr_zh": "该论文提出了一种 Forgetting Attention 机制，通过在 Transformer 中添加一个 forget gate 来动态下调未归一化的注意力分数，构建出 Forgetting Transformer (FoX) 模型。FoX 在长上下文语言建模、长度外推和短上下文下游任务上表现优于标准 Transformer，同时在长上下文下游任务上保持相当水平，且兼容 FlashAttention 算法而不需位置嵌入。实验结果显示，FoX 通过 needle-in-the-haystack 测试等分析，保留了 Transformer 的长上下文优势，并优于 recurrent 模型如 Mamba-2、HGRN2 和 DeltaNet；此外，引入的 \"Pro\" block 设计显著提升了 FoX 和 Transformer 的整体性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Published as a conference paper at ICLR 2025; Fixed an issue with the\n  attention map visualization",
      "pdf_url": "http://arxiv.org/pdf/2503.02130v2",
      "published_date": "2025-03-03 23:35:23 UTC",
      "updated_date": "2025-03-31 19:41:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:03:42.219017"
    },
    {
      "arxiv_id": "2503.02129v1",
      "title": "A Near Complete Nonasymptotic Generalization Theory For Multilayer Neural Networks: Beyond the Bias-Variance Tradeoff",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Yu",
        "Xiangyang Ji"
      ],
      "abstract": "We propose a first near complete (that will make explicit sense in the main\ntext) nonasymptotic generalization theory for multilayer neural networks with\narbitrary Lipschitz activations and general Lipschitz loss functions (with some\nvery mild conditions). In particular, it doens't require the boundness of loss\nfunction, as commonly assumed in the literature. Our theory goes beyond the\nbias-variance tradeoff, aligned with phenomenon typically encountered in deep\nlearning. It is therefore sharp different with other existing nonasymptotic\ngeneralization error bounds for neural networks. More explicitly, we propose an\nexplicit generalization error upper bound for multilayer neural networks with\narbitrary Lipschitz activations $\\sigma$ with $\\sigma(0)=0$ and broad enough\nLipschitz loss functions, without requiring either the width, depth or other\nhyperparameters of the neural network approaching infinity, a specific neural\nnetwork architect (e.g. sparsity, boundness of some norms), a particular\nactivation function, a particular optimization algorithm or boundness of the\nloss function, and with taking the approximation error into consideration.\nGeneral Lipschitz activation can also be accommodated into our framework. A\nfeature of our theory is that it also considers approximation errors.\nFurthermore, we show the near minimax optimality of our theory for multilayer\nReLU networks for regression problems. Notably, our upper bound exhibits the\nfamous double descent phenomenon for such networks, which is the most\ndistinguished characteristic compared with other existing results. This work\nemphasizes a view that many classical results should be improved to embrace the\nunintuitive characteristics of deep learning to get a better understanding of\nit.",
      "tldr_zh": "本论文提出了一种近乎完整的非渐近泛化理论（nonasymptotic generalization theory），适用于多层神经网络，支持任意 Lipschitz 激活函数（以 σ(0)=0 为条件）和一般 Lipschitz 损失函数，而无需假设损失函数有界或网络超参数（如宽度、深度）趋于无穷。不同于传统的偏差-方差权衡（bias-variance tradeoff），该理论超越了经典框架，考虑了近似误差（approximation error），并适用于更广泛的网络架构和优化算法。实验结果显示，对于多层 ReLU 网络的回归问题，该理论实现了近似最小最大最优性（near minimax optimality），并首次展示了著名的双重下降现象（double descent phenomenon），有助于更好地理解深度学习的非直观特性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.ST",
        "stat.TH"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.02129v1",
      "published_date": "2025-03-03 23:34:12 UTC",
      "updated_date": "2025-03-03 23:34:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:03:52.975175"
    },
    {
      "arxiv_id": "2503.02123v1",
      "title": "TMIQ: Quantifying Test and Measurement Domain Intelligence in Large Language Models",
      "title_zh": "TMIQ：量化大型语言模型中测试和测量领域智能",
      "authors": [
        "Emmanuel A. Olowe",
        "Danial Chitnis"
      ],
      "abstract": "The Test and Measurement domain, known for its strict requirements for\naccuracy and efficiency, is increasingly adopting Generative AI technologies to\nenhance the performance of data analysis, automation, and decision-making\nprocesses. Among these, Large Language Models (LLMs) show significant promise\nfor advancing automation and precision in testing. However, the evaluation of\nLLMs in this specialized area remains insufficiently explored. To address this\ngap, we introduce the Test and Measurement Intelligence Quotient (TMIQ), a\nbenchmark designed to quantitatively assess LLMs across a wide range of\nelectronic engineering tasks. TMIQ offers a comprehensive set of scenarios and\nmetrics for detailed evaluation, including SCPI command matching accuracy,\nranked response evaluation, Chain-of-Thought Reasoning (CoT), and the impact of\noutput formatting variations required by LLMs on performance. In testing\nvarious LLMs, our findings indicate varying levels of proficiency, with exact\nSCPI command match accuracy ranging from around 56% to 73%, and ranked matching\nfirst-position scores achieving around 33% for the best-performing model. We\nalso assess token usage, cost-efficiency, and response times, identifying\ntrade-offs between accuracy and operational efficiency. Additionally, we\npresent a command-line interface (CLI) tool that enables users to generate\ndatasets using the same methodology, allowing for tailored assessments of LLMs.\nTMIQ and the CLI tool provide a rigorous, reproducible means of evaluating LLMs\nfor production environments, facilitating continuous monitoring and identifying\nstrengths and areas for improvement, and driving innovation in their selections\nfor applications within the Test and Measurement industry.",
      "tldr_zh": "本研究引入了TMIQ基准，用于量化评估大型语言模型(LLMs)在测试和测量领域的智能表现，针对电子工程任务的准确性和效率进行全面评估。TMIQ涵盖多种场景和指标，包括SCPI命令匹配准确率（56%至73%）、排名响应评估、Chain-of-Thought Reasoning (CoT)以及输出格式变化的影响，同时分析了令牌使用、成本效率和响应时间之间的权衡。实验结果显示不同LLMs的性能差异明显，并提供了一个命令行界面(CLI)工具，允许用户生成自定义数据集，以促进LLMs在生产环境中的持续监控和优化。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "accepted in IEEE I2MTC 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.02123v1",
      "published_date": "2025-03-03 23:12:49 UTC",
      "updated_date": "2025-03-03 23:12:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:04:06.144560"
    },
    {
      "arxiv_id": "2503.02117v1",
      "title": "Parabolic Continual Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Haoming Yang",
        "Ali Hasan",
        "Vahid Tarokh"
      ],
      "abstract": "Regularizing continual learning techniques is important for anticipating\nalgorithmic behavior under new realizations of data. We introduce a new\napproach to continual learning by imposing the properties of a parabolic\npartial differential equation (PDE) to regularize the expected behavior of the\nloss over time. This class of parabolic PDEs has a number of favorable\nproperties that allow us to analyze the error incurred through forgetting and\nthe error induced through generalization. Specifically, we do this through\nimposing boundary conditions where the boundary is given by a memory buffer. By\nusing the memory buffer as a boundary, we can enforce long term dependencies by\nbounding the expected error by the boundary loss. Finally, we illustrate the\nempirical performance of the method on a series of continual learning tasks.",
      "tldr_zh": "本文提出了一种名为 Parabolic Continual Learning 的新方法，通过应用抛物线偏微分方程 (parabolic PDE) 来正规化连续学习 (continual learning) 算法的行为，确保在数据变化时预测损失的预期表现。方法利用内存缓冲区 (memory buffer) 作为边界条件，分析遗忘错误和泛化错误，并通过边界损失来限制预期错误，从而强化长期依赖性。实验结果表明，该方法在多个连续学习任务上表现出色，展示了其实际效能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.02117v1",
      "published_date": "2025-03-03 22:59:13 UTC",
      "updated_date": "2025-03-03 22:59:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:04:18.067212"
    },
    {
      "arxiv_id": "2503.02104v1",
      "title": "Biomedical Foundation Model: A Survey",
      "title_zh": "生物医学基础模型：综述",
      "authors": [
        "Xiangrui Liu",
        "Yuanyuan Zhang",
        "Yingzhou Lu",
        "Changchang Yin",
        "Xiaoling Hu",
        "Xiaoou Liu",
        "Lulu Chen",
        "Sheng Wang",
        "Alexander Rodriguez",
        "Huaxiu Yao",
        "Yezhou Yang",
        "Ping Zhang",
        "Jintai Chen",
        "Tianfan Fu",
        "Xiao Wang"
      ],
      "abstract": "Foundation models, first introduced in 2021, are large-scale pre-trained\nmodels (e.g., large language models (LLMs) and vision-language models (VLMs))\nthat learn from extensive unlabeled datasets through unsupervised methods,\nenabling them to excel in diverse downstream tasks. These models, like GPT, can\nbe adapted to various applications such as question answering and visual\nunderstanding, outperforming task-specific AI models and earning their name due\nto broad applicability across fields. The development of biomedical foundation\nmodels marks a significant milestone in leveraging artificial intelligence (AI)\nto understand complex biological phenomena and advance medical research and\npractice. This survey explores the potential of foundation models across\ndiverse domains within biomedical fields, including computational biology, drug\ndiscovery and development, clinical informatics, medical imaging, and public\nhealth. The purpose of this survey is to inspire ongoing research in the\napplication of foundation models to health science.",
      "tldr_zh": "这篇调查论文回顾了Foundation models（基础模型），如LLMs（大型语言模型）和VLMs（视觉语言模型），这些模型通过大规模无监督预训练从未标注数据中学习，并在各种下游任务中表现出色。论文探讨了Foundation models在生物医学领域的潜力，包括计算生物学、药物发现、临床信息学、医学成像和公共卫生等领域，强调它们能帮助理解复杂生物现象并推动医疗研究。最终，该调查旨在激发更多研究，将AI应用于健康科学领域。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.02104v1",
      "published_date": "2025-03-03 22:42:00 UTC",
      "updated_date": "2025-03-03 22:42:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:04:30.010548"
    },
    {
      "arxiv_id": "2503.02102v2",
      "title": "Provable Benefits of Task-Specific Prompts for In-context Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Xiangyu Chang",
        "Yingcong Li",
        "Muti Kara",
        "Samet Oymak",
        "Amit K. Roy-Chowdhury"
      ],
      "abstract": "The in-context learning capabilities of modern language models have motivated\na deeper mathematical understanding of sequence models. A line of recent work\nhas shown that linear attention models can emulate projected gradient descent\niterations to implicitly learn the task vector from the data provided in the\ncontext window. In this work, we consider a novel setting where the global task\ndistribution can be partitioned into a union of conditional task distributions.\nWe then examine the use of task-specific prompts and prediction heads for\nlearning the prior information associated with the conditional task\ndistribution using a one-layer attention model. Our results on loss landscape\nshow that task-specific prompts facilitate a covariance-mean decoupling where\nprompt-tuning explains the conditional mean of the distribution whereas the\nvariance is learned/explained through in-context learning. Incorporating\ntask-specific head further aids this process by entirely decoupling estimation\nof mean and variance components. This covariance-mean perspective similarly\nexplains how jointly training prompt and attention weights can provably help\nover fine-tuning after pretraining.",
      "tldr_zh": "本文证明了任务特定提示（task-specific prompts）在 in-context learning 中的可证明益处，通过使用一层注意力模型（one-layer attention model）来学习条件任务分布的先验信息。研究发现，任务特定提示促进了协方差-均值解耦（covariance-mean decoupling），其中提示调整解释了分布的条件均值，而方差则通过 in-context learning 进行学习。进一步，加入任务特定预测头（task-specific head）完全解耦了均值和方差的估计，并显示联合训练提示和注意力权重比单纯微调（fine-tuning）更有效，从而提升了模型在预训练后的性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Proceedings of the 28th International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.02102v2",
      "published_date": "2025-03-03 22:37:03 UTC",
      "updated_date": "2025-03-05 16:18:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:04:42.665974"
    },
    {
      "arxiv_id": "2503.02099v1",
      "title": "LLMs as Educational Analysts: Transforming Multimodal Data Traces into Actionable Reading Assessment Reports",
      "title_zh": "大型语言模型作为教育分析师：将多模态数据痕迹转化为可操作的阅读评估报告",
      "authors": [
        "Eduardo Davalos",
        "Yike Zhang",
        "Namrata Srivastava",
        "Jorge Alberto Salas",
        "Sara McFadden",
        "Sun-Joo Cho",
        "Gautam Biswas",
        "Amanda Goodwin"
      ],
      "abstract": "Reading assessments are essential for enhancing students' comprehension, yet\nmany EdTech applications focus mainly on outcome-based metrics, providing\nlimited insights into student behavior and cognition. This study investigates\nthe use of multimodal data sources -- including eye-tracking data, learning\noutcomes, assessment content, and teaching standards -- to derive meaningful\nreading insights. We employ unsupervised learning techniques to identify\ndistinct reading behavior patterns, and then a large language model (LLM)\nsynthesizes the derived information into actionable reports for educators,\nstreamlining the interpretation process. LLM experts and human educators\nevaluate these reports for clarity, accuracy, relevance, and pedagogical\nusefulness. Our findings indicate that LLMs can effectively function as\neducational analysts, turning diverse data into teacher-friendly insights that\nare well-received by educators. While promising for automating insight\ngeneration, human oversight remains crucial to ensure reliability and fairness.\nThis research advances human-centered AI in education, connecting data-driven\nanalytics with practical classroom applications.",
      "tldr_zh": "本研究探讨如何利用多模态数据（如眼动追踪数据、学习成果、评估内容和教学标准）来分析学生阅读行为，采用无监督学习识别模式，并由大型语言模型（LLM）合成这些信息生成可操作的教育报告，以弥补现有 EdTech 应用的局限性。LLM 生成的报告经 LLM 专家和人类教育者评估，在清晰度、准确性、相关性和教育实用性方面表现出色。结果表明，LLMs 可有效作为教育分析师，将复杂数据转化为教师友好的洞察，但仍需人类监督确保可靠性和公平性。该工作推进了以人为本的 AI 在教育中的应用，促进数据驱动分析与课堂实践的融合。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC",
        "I.2.1; I.2.7; K.3.1"
      ],
      "primary_category": "cs.CY",
      "comment": "15 pages, 5 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.02099v1",
      "published_date": "2025-03-03 22:34:08 UTC",
      "updated_date": "2025-03-03 22:34:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:04:54.784152"
    },
    {
      "arxiv_id": "2503.02093v1",
      "title": "Correlation to Causation: A Causal Deep Learning Framework for Arctic Sea Ice Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Emam Hossain",
        "Muhammad Hasan Ferdous",
        "Jianwu Wang",
        "Aneesh Subramanian",
        "Md Osman Gani"
      ],
      "abstract": "Traditional machine learning and deep learning techniques rely on\ncorrelation-based learning, often failing to distinguish spurious associations\nfrom true causal relationships, which limits robustness, interpretability, and\ngeneralizability. To address these challenges, we propose a causality-driven\ndeep learning framework that integrates Multivariate Granger Causality (MVGC)\nand PCMCI+ causal discovery algorithms with a hybrid deep learning\narchitecture. Using 43 years (1979-2021) of daily and monthly Arctic Sea Ice\nExtent (SIE) and ocean-atmospheric datasets, our approach identifies causally\nsignificant factors, prioritizes features with direct influence, reduces\nfeature overhead, and improves computational efficiency. Experiments\ndemonstrate that integrating causal features enhances the deep learning model's\npredictive accuracy and interpretability across multiple lead times. Beyond SIE\nprediction, the proposed framework offers a scalable solution for dynamic,\nhigh-dimensional systems, advancing both theoretical understanding and\npractical applications in predictive modeling.",
      "tldr_zh": "传统机器学习和深度学习依赖相关性学习，往往无法区分虚假关联和真实因果关系，从而影响模型的鲁棒性、可解释性和泛化性。为解决这一问题，本文提出一个因果驱动的深度学习框架，将 Multivariate Granger Causality (MVGC) 和 PCMCI+ 因果发现算法与混合深度学习架构整合，使用1979-2021年43年的Arctic Sea Ice Extent (SIE) 和海洋-大气数据集来识别因果显著因素并优化特征。实验结果显示，该框架在多个预测时段上显著提升了深度学习模型的预测准确性和可解释性，同时减少了特征开销和计算复杂度。该框架为动态高维系统的预测建模提供了一个可扩展的解决方案，推进了理论理解和实际应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted for Publication in Causal AI for Robust Decision Making\n  (CARD) Workshop in the International Conference on Pervasive Computing and\n  Communications (PerCom 2025)",
      "pdf_url": "http://arxiv.org/pdf/2503.02093v1",
      "published_date": "2025-03-03 22:24:14 UTC",
      "updated_date": "2025-03-03 22:24:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:05:08.870940"
    },
    {
      "arxiv_id": "2503.05804v1",
      "title": "Holistically Evaluating the Environmental Impact of Creating Language Models",
      "title_zh": "全面评估创建语言模型的环境影响",
      "authors": [
        "Jacob Morrison",
        "Clara Na",
        "Jared Fernandez",
        "Tim Dettmers",
        "Emma Strubell",
        "Jesse Dodge"
      ],
      "abstract": "As the performance of artificial intelligence systems has dramatically\nincreased, so too has the environmental impact of creating these systems. While\nmany model developers release estimates of the power consumption and carbon\nemissions from the final training runs for their latest models, there is\ncomparatively little transparency into the impact of model development,\nhardware manufacturing, and total water usage throughout. In this work, we\nestimate the real-world environmental impact of developing a series of language\nmodels, ranging from 20 million to 13 billion active parameters, trained on up\nto 5.6 trillion tokens each. When accounting for hardware manufacturing, model\ndevelopment, and our final training runs, we find that our series of models\nreleased 493 metric tons of carbon emissions, equivalent to powering about 98\nhomes in the United States for one year, and consumed 2.769 million liters of\nwater, equivalent to about 24.5 years of water usage by a person in the United\nStates, even though our data center is extremely water-efficient. We measure\nand report the environmental impact of our model development; to the best of\nour knowledge we are the first to do so for LLMs, and we find that model\ndevelopment, the impact of which is generally not disclosed by most model\ndevelopers, amounted to ~50% of that of training. By looking at detailed time\nseries data for power consumption, we also find that power usage throughout\ntraining is not consistent, fluctuating between ~15% and ~85% of our hardware's\nmaximum power draw, with negative implications for grid-scale planning as\ndemand continues to grow. We close with a discussion on the continued\ndifficulty of estimating the environmental impact of AI systems, and key\ntakeaways for model developers and the public at large.",
      "tldr_zh": "本研究全面评估了创建语言模型的环境影响，包括硬件制造、模型开发和最终训练过程，揭示了现有报告中常被忽略的透明度问题。研究团队估计了一系列模型（从2000万到130亿参数，训练至最多5.6万亿tokens）的总碳排放为493吨，相当于美国98个家庭一年的电力消耗，以及276.9万升水，相当于一个人在美国24.5年的用水量。结果显示，模型开发的影响约占总排放的50%，且训练电力消耗波动剧烈（15%至85%），这对电网规划和AI可持续发展提出了关键启示。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "ICLR 2025 (spotlight)",
      "pdf_url": "http://arxiv.org/pdf/2503.05804v1",
      "published_date": "2025-03-03 22:16:15 UTC",
      "updated_date": "2025-03-03 22:16:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:05:18.613561"
    },
    {
      "arxiv_id": "2503.02080v2",
      "title": "Linear Representations of Political Perspective Emerge in Large Language Models",
      "title_zh": "政治观点的线性表示在大语言模型中出现",
      "authors": [
        "Junsol Kim",
        "James Evans",
        "Aaron Schein"
      ],
      "abstract": "Large language models (LLMs) have demonstrated the ability to generate text\nthat realistically reflects a range of different subjective human perspectives.\nThis paper studies how LLMs are seemingly able to reflect more liberal versus\nmore conservative viewpoints among other political perspectives in American\npolitics. We show that LLMs possess linear representations of political\nperspectives within activation space, wherein more similar perspectives are\nrepresented closer together. To do so, we probe the attention heads across the\nlayers of three open transformer-based LLMs (Llama-2-7b-chat,\nMistral-7b-instruct, Vicuna-7b). We first prompt models to generate text from\nthe perspectives of different U.S. lawmakers. We then identify sets of\nattention heads whose activations linearly predict those lawmakers' DW-NOMINATE\nscores, a widely-used and validated measure of political ideology. We find that\nhighly predictive heads are primarily located in the middle layers, often\nspeculated to encode high-level concepts and tasks. Using probes only trained\nto predict lawmakers' ideology, we then show that the same probes can predict\nmeasures of news outlets' slant from the activations of models prompted to\nsimulate text from those news outlets. These linear probes allow us to\nvisualize, interpret, and monitor ideological stances implicitly adopted by an\nLLM as it generates open-ended responses. Finally, we demonstrate that by\napplying linear interventions to these attention heads, we can steer the model\noutputs toward a more liberal or conservative stance. Overall, our research\nsuggests that LLMs possess a high-level linear representation of American\npolitical ideology and that by leveraging recent advances in mechanistic\ninterpretability, we can identify, monitor, and steer the subjective\nperspective underlying generated text.",
      "tldr_zh": "本研究发现，大型语言模型(LLMs)在其激活空间中形成了政治观点的线性表示，例如美国政治中的自由派和保守派观点，相似的视角在空间中更接近。研究者通过探测三个开源 transformer-based LLMs（如 Llama-2-7b-chat）的注意力头，提示模型从不同美国立法者的角度生成文本，并使用 DW-NOMINATE 分数训练线性探针来预测这些头的激活，从而识别中间层的关键注意力头。实验进一步证明，这些探针能预测新闻媒体的偏向，并通过线性干预引导模型输出向更自由或保守的方向倾斜，为监控和控制 LLMs 的主观意识形态提供了可解释性工具。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Published as a conference paper at ICLR 2025\n  https://openreview.net/forum?id=rwqShzb9li",
      "pdf_url": "http://arxiv.org/pdf/2503.02080v2",
      "published_date": "2025-03-03 21:59:01 UTC",
      "updated_date": "2025-04-02 08:53:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:05:30.777308"
    },
    {
      "arxiv_id": "2503.02078v2",
      "title": "Superscopes: Amplifying Internal Feature Representations for Language Model Interpretation",
      "title_zh": "Superscopes：放大语言模型内部特征表示以进行解释",
      "authors": [
        "Jonathan Jacobi",
        "Gal Niv"
      ],
      "abstract": "Understanding and interpreting the internal representations of large language\nmodels (LLMs) remains an open challenge. Patchscopes introduced a method for\nprobing internal activations by patching them into new prompts, prompting\nmodels to self-explain their hidden representations. We introduce Superscopes,\na technique that systematically amplifies superposed features in MLP outputs\n(multilayer perceptron) and hidden states before patching them into new\ncontexts. Inspired by the \"features as directions\" perspective and the\nClassifier-Free Guidance (CFG) approach from diffusion models, Superscopes\namplifies weak but meaningful features, enabling the interpretation of internal\nrepresentations that previous methods failed to explain-all without requiring\nadditional training. This approach provides new insights into how LLMs build\ncontext and represent complex concepts, further advancing mechanistic\ninterpretability.",
      "tldr_zh": "本论文引入了Superscopes技术，一种基于Patchscopes的方法，用于放大语言模型(LLMs)中MLP输出和隐藏状态的超叠加特征(superposed features)，以提升内部表示的解释性。受“features as directions”视角和Classifier-Free Guidance (CFG)方法的启发，Superscopes通过系统放大弱特征并将其patch到新上下文中，实现对之前方法无法解释的内部表示的解读，而无需额外训练。该技术为理解LLMs如何构建上下文和表示复杂概念提供了新见解，推进了mechanistic interpretability的研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.02078v2",
      "published_date": "2025-03-03 21:58:12 UTC",
      "updated_date": "2025-03-09 10:27:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:05:43.856823"
    },
    {
      "arxiv_id": "2503.02077v2",
      "title": "M3HF: Multi-agent Reinforcement Learning from Multi-phase Human Feedback of Mixed Quality",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyan Wang",
        "Zhicheng Zhang",
        "Fei Fang",
        "Yali Du"
      ],
      "abstract": "Designing effective reward functions in multi-agent reinforcement learning\n(MARL) is a significant challenge, often leading to suboptimal or misaligned\nbehaviors in complex, coordinated environments. We introduce Multi-agent\nReinforcement Learning from Multi-phase Human Feedback of Mixed Quality (M3HF),\na novel framework that integrates multi-phase human feedback of mixed quality\ninto the MARL training process. By involving humans with diverse expertise\nlevels to provide iterative guidance, M3HF leverages both expert and non-expert\nfeedback to continuously refine agents' policies. During training, we\nstrategically pause agent learning for human evaluation, parse feedback using\nlarge language models to assign it appropriately and update reward functions\nthrough predefined templates and adaptive weight by using weight decay and\nperformance-based adjustments. Our approach enables the integration of nuanced\nhuman insights across various levels of quality, enhancing the interpretability\nand robustness of multi-agent cooperation. Empirical results in challenging\nenvironments demonstrate that M3HF significantly outperforms state-of-the-art\nmethods, effectively addressing the complexities of reward design in MARL and\nenabling broader human participation in the training process.",
      "tldr_zh": "该论文提出M3HF框架，用于解决多智能体强化学习(MARL)中奖励函数设计挑战，从而避免代理行为次优或不协调。M3HF通过整合多阶段人类反馈（质量参差不齐），让不同专业水平的人提供迭代指导，并利用大语言模型解析反馈，以预定义模板和自适应权重（如权重衰减和性能调整）更新奖励函数。实验结果显示，在复杂环境中，M3HF显著优于现有方法，提高了多智能体合作的解释性和鲁棒性，并促进更广泛的人类参与训练过程。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.MA",
      "comment": "Seventeen pages, four figures",
      "pdf_url": "http://arxiv.org/pdf/2503.02077v2",
      "published_date": "2025-03-03 21:58:10 UTC",
      "updated_date": "2025-03-06 20:50:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:05:54.840714"
    },
    {
      "arxiv_id": "2503.02068v1",
      "title": "Interactive Debugging and Steering of Multi-Agent AI Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Will Epperson",
        "Gagan Bansal",
        "Victor Dibia",
        "Adam Fourney",
        "Jack Gerrits",
        "Erkang Zhu",
        "Saleema Amershi"
      ],
      "abstract": "Fully autonomous teams of LLM-powered AI agents are emerging that collaborate\nto perform complex tasks for users. What challenges do developers face when\ntrying to build and debug these AI agent teams? In formative interviews with\nfive AI agent developers, we identify core challenges: difficulty reviewing\nlong agent conversations to localize errors, lack of support in current tools\nfor interactive debugging, and the need for tool support to iterate on agent\nconfiguration. Based on these needs, we developed an interactive multi-agent\ndebugging tool, AGDebugger, with a UI for browsing and sending messages, the\nability to edit and reset prior agent messages, and an overview visualization\nfor navigating complex message histories. In a two-part user study with 14\nparticipants, we identify common user strategies for steering agents and\nhighlight the importance of interactive message resets for debugging. Our\nstudies deepen understanding of interfaces for debugging increasingly important\nagentic workflows.",
      "tldr_zh": "该论文探讨了开发LLM驱动的多代理AI系统时面临的挑战，包括审查代理对话定位错误、缺乏交互式调试工具支持，以及迭代代理配置的需求。通过访谈五位开发者，研究团队开发了AGDebugger工具，该工具提供消息浏览和发送UI、编辑重置代理消息功能，以及概述可视化来导航复杂历史。用户研究涉及14名参与者，揭示了常见代理指导策略，并强调交互式消息重置在调试中的关键作用。该研究加深了对多代理工作流调试界面的理解，为未来AI系统开发提供重要指导。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.MA",
      "comment": "Published at CHI 25",
      "pdf_url": "http://arxiv.org/pdf/2503.02068v1",
      "published_date": "2025-03-03 21:42:54 UTC",
      "updated_date": "2025-03-03 21:42:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:06:08.005470"
    },
    {
      "arxiv_id": "2503.02067v1",
      "title": "AI persuading AI vs AI persuading Humans: LLMs' Differential Effectiveness in Promoting Pro-Environmental Behavior",
      "title_zh": "翻译失败",
      "authors": [
        "Alexander Doudkin",
        "Pat Pataranutaporn",
        "Pattie Maes"
      ],
      "abstract": "Pro-environmental behavior (PEB) is vital to combat climate change, yet\nturning awareness into intention and action remains elusive. We explore large\nlanguage models (LLMs) as tools to promote PEB, comparing their impact across\n3,200 participants: real humans (n=1,200), simulated humans based on actual\nparticipant data (n=1,200), and fully synthetic personas (n=1,200). All three\nparticipant groups faced personalized or standard chatbots, or static\nstatements, employing four persuasion strategies (moral foundations, future\nself-continuity, action orientation, or \"freestyle\" chosen by the LLM). Results\nreveal a \"synthetic persuasion paradox\": synthetic and simulated agents\nsignificantly affect their post-intervention PEB stance, while human responses\nbarely shift. Simulated participants better approximate human trends but still\noverestimate effects. This disconnect underscores LLM's potential for\npre-evaluating PEB interventions but warns of its limits in predicting\nreal-world behavior. We call for refined synthetic modeling and sustained and\nextended human trials to align conversational AI's promise with tangible\nsustainability outcomes.",
      "tldr_zh": "本研究探讨大型语言模型(LLMs)在促进亲环境行为(PEB)中的说服效果，通过实验比较3200名参与者（包括真实人类、基于实际数据的模拟人类和完全合成角色）对四种说服策略（道德基础、未来自我连续性、行动导向或自由式）的响应。结果揭示“合成说服悖论”：LLMs对合成和模拟代理的影响显著，导致其PEB立场明显改变，而真实人类响应几乎没有变化，尽管模拟参与者能更好地近似人类趋势但仍高估效果。该发现突出了LLMs在预评估PEB干预的潜力，同时警告其预测真实行为的局限性，并呼吁改进合成建模并加强人类试验以实现实际可持续性成果。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "17 pages, 13 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.02067v1",
      "published_date": "2025-03-03 21:40:55 UTC",
      "updated_date": "2025-03-03 21:40:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:06:20.420001"
    },
    {
      "arxiv_id": "2503.02065v1",
      "title": "Survey Perspective: The Role of Explainable AI in Threat Intelligence",
      "title_zh": "调查视角：可解释 AI 在威胁情报中的作用",
      "authors": [
        "Nidhi Rastogi",
        "Devang Dhanuka",
        "Amulya Saxena",
        "Pranjal Mairal",
        "Le Nguyen"
      ],
      "abstract": "The increasing reliance on AI-based security tools in Security Operations\nCenters (SOCs) has transformed threat detection and response, yet analysts\nfrequently struggle with alert overload, false positives, and lack of\ncontextual relevance. The inability to effectively analyze AI-generated\nsecurity alerts lead to inefficiencies in incident response and reduces trust\nin automated decision-making. In this paper, we show results and analysis of\nour investigation of how SOC analysts navigate AI-based alerts, their\nchallenges with current security tools, and how explainability (XAI) integrated\ninto their security workflows has the potential to become an effective decision\nsupport. In this vein, we conducted an industry survey. Using the survey\nresponses, we analyze how security analysts' process, retrieve, and prioritize\nalerts. Our findings indicate that most analysts have not yet adopted\nXAI-integrated tools, but they express high interest in attack attribution,\nconfidence scores, and feature contribution explanations to improve\ninterpretability, and triage efficiency. Based on our findings, we also propose\npractical design recommendations for XAI-enhanced security alert systems,\nenabling AI-based cybersecurity solutions to be more transparent,\ninterpretable, and actionable.",
      "tldr_zh": "本论文探讨了可解释 AI (XAI) 在威胁情报中的作用，针对安全操作中心 (SOC) 中 AI 工具导致的警报过载、假阳性和效率低下问题。作者通过行业调查分析了分析师如何处理 AI 生成的警报，发现大多数分析师尚未采用 XAI 工具，但对攻击归因、置信度分数和特征贡献解释表现出强烈兴趣，以提升警报的可解释性和优先级处理。基于调查结果，论文提出了 XAI 增强安全警报系统的实用设计推荐，使 AI 基于的网络安全解决方案更透明、可解释和可操作。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CR",
      "comment": "5 pages, SIGIR Symposium on IR in Practice (SIRIP), 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.02065v1",
      "published_date": "2025-03-03 21:39:15 UTC",
      "updated_date": "2025-03-03 21:39:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:06:31.837606"
    },
    {
      "arxiv_id": "2503.02057v1",
      "title": "Hebbian learning the local structure of language",
      "title_zh": "翻译失败",
      "authors": [
        "P. Myles Eugenio"
      ],
      "abstract": "Learning in the brain is local and unsupervised (Hebbian). We derive the\nfoundations of an effective human language model inspired by these microscopic\nconstraints. It has two parts: (1) a hierarchy of neurons which learns to\ntokenize words from text (whichiswhatyoudowhenyoureadthis); and (2) additional\nneurons which bind the learned symanticless patterns of the tokenizer into a\nsymanticful token (an embedding). The model permits continuous parallel\nlearning without forgetting; and is a powerful tokenizer which performs\nrenormalization group. This allows it to exploit redundancy, such that it\ngenerates tokens which are always decomposable into a basis set (e.g an\nalphabet), and can mix features learned from multiple languages. We find that\nthe structure of this model allows it to learn a natural language morphology\nWITHOUT data. The language data generated by this model predicts the correct\ndistribution of word-forming patterns observed in real languages, and further\ndemonstrates why microscopically human speech is broken up into words. This\nmodel provides the basis for understanding the microscopic origins of language\nand human creativity.",
      "tldr_zh": "本研究基于Hebbian learning的局部和无监督学习机制，提出一个受大脑启发的语言模型，该模型包括两个部分：一个分层神经元结构用于从文本中tokenize words，以及额外的神经元将无语义模式绑定成有语义的embedding。模型支持连续并行学习而不遗忘，并通过renormalization group利用冗余生成可分解的标记，支持多种语言特征的混合。该模型无需数据即可学习自然语言morphology，其生成的语言数据准确预测了真实语言中词形成模式的分布，并解释了人类语音为何被分解成单词，从而为理解语言的微观起源和人类创造力提供基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "cs.CL",
      "comment": "10 figures, 14 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.02057v1",
      "published_date": "2025-03-03 21:15:57 UTC",
      "updated_date": "2025-03-03 21:15:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:06:42.659313"
    },
    {
      "arxiv_id": "2503.02053v1",
      "title": "EPEE: Towards Efficient and Effective Foundation Models in Biomedicine",
      "title_zh": "翻译失败",
      "authors": [
        "Zaifu Zhan",
        "Shuang Zhou",
        "Huixue Zhou",
        "Zirui Liu",
        "Rui Zhang"
      ],
      "abstract": "Foundation models, including language models, e.g., GPT, and vision models,\ne.g., CLIP, have significantly advanced numerous biomedical tasks. Despite\nthese advancements, the high inference latency and the \"overthinking\" issues in\nmodel inference impair the efficiency and effectiveness of foundation models,\nthus limiting their application in real-time clinical settings. To address\nthese challenges, we proposed EPEE (Entropy- and Patience-based Early Exiting),\na novel hybrid strategy designed to improve the inference efficiency of\nfoundation models. The core idea was to leverage the strengths of entropy-based\nand patience-based early exiting methods to overcome their respective\nweaknesses. To evaluate EPEE, we conducted experiments on three core biomedical\ntasks-classification, relation extraction, and event extraction-using four\nfoundation models (BERT, ALBERT, GPT-2, and ViT) across twelve datasets,\nincluding clinical notes and medical images. The results showed that EPEE\nsignificantly reduced inference time while maintaining or improving accuracy,\ndemonstrating its adaptability to diverse datasets and tasks. EPEE addressed\ncritical barriers to deploying foundation models in healthcare by balancing\nefficiency and effectiveness. It potentially provided a practical solution for\nreal-time clinical decision-making with foundation models, supporting reliable\nand efficient workflows.",
      "tldr_zh": "该研究针对基础模型（Foundation Models）在生物医学任务中的高推理延迟和“overthinking”问题，提出了一种新型混合策略EPEE（Entropy- and Patience-based Early Exiting），旨在提升模型的推理效率和效果。EPEE的核心在于结合熵-based和patience-based早期退出方法，克服各自的缺点，从而在保持准确率的同时减少推理时间。实验在分类、关系提取和事件提取等三类任务上，使用BERT、ALBERT、GPT-2和ViT等模型以及12个数据集（包括临床笔记和医疗图像）进行评估，结果显示EPEE显著降低了推理时间，同时维持或提高了准确率。该方法解决了基础模型在医疗领域的部署障碍，为实时临床决策提供可靠且高效的解决方案。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "Submitted to npj Digital Medicine",
      "pdf_url": "http://arxiv.org/pdf/2503.02053v1",
      "published_date": "2025-03-03 21:11:13 UTC",
      "updated_date": "2025-03-03 21:11:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:06:55.748328"
    },
    {
      "arxiv_id": "2503.02048v1",
      "title": "FRMD: Fast Robot Motion Diffusion with Consistency-Distilled Movement Primitives for Smooth Action Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Xirui Shi",
        "Jun Jin"
      ],
      "abstract": "We consider the problem of using diffusion models to generate fast, smooth,\nand temporally consistent robot motions. Although diffusion models have\ndemonstrated superior performance in robot learning due to their task\nscalability and multi-modal flexibility, they suffer from two fundamental\nlimitations: (1) they often produce non-smooth, jerky motions due to their\ninability to capture temporally consistent movement dynamics, and (2) their\niterative sampling process incurs prohibitive latency for many robotic tasks.\nInspired by classic robot motion generation methods such as DMPs and ProMPs,\nwhich capture temporally and spatially consistent dynamic of trajectories using\nlow-dimensional vectors -- and by recent advances in diffusion-based image\ngeneration that use consistency models with probability flow ODEs to accelerate\nthe denoising process, we propose Fast Robot Motion Diffusion (FRMD). FRMD\nuniquely integrates Movement Primitives (MPs) with Consistency Models to enable\nefficient, single-step trajectory generation. By leveraging probabilistic flow\nODEs and consistency distillation, our method models trajectory distributions\nwhile learning a compact, time-continuous motion representation within an\nencoder-decoder architecture. This unified approach eliminates the slow,\nmulti-step denoising process of conventional diffusion models, enabling\nefficient one-step inference and smooth robot motion generation. We extensively\nevaluated our FRMD on the well-recognized Meta-World and ManiSkills Benchmarks,\nranging from simple to more complex manipulation tasks, comparing its\nperformance against state-of-the-art baselines. Our results show that FRMD\ngenerates significantly faster, smoother trajectories while achieving higher\nsuccess rates.",
      "tldr_zh": "本研究针对扩散模型在机器人动作生成中的问题（如动作不平滑和采样延迟），提出了一种快速机器人动作扩散模型 FRMD。FRMD 通过整合 Movement Primitives (MPs) 和 Consistency Models，利用概率流 ODE 和一致性蒸馏，在编码器-解码器架构中实现高效的单步轨迹生成，从而确保动作的时空一致性和平滑性。实验在 Meta-World 和 ManiSkills 基准上验证了 FRMD 的性能，与最先进基线相比，它生成更快、更平滑的轨迹，并显著提高了任务成功率。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "arXiv admin note: text overlap with arXiv:2406.01586 by other authors",
      "pdf_url": "http://arxiv.org/pdf/2503.02048v1",
      "published_date": "2025-03-03 20:56:39 UTC",
      "updated_date": "2025-03-03 20:56:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:07:07.516869"
    },
    {
      "arxiv_id": "2503.02039v1",
      "title": "Dynamic Search for Inference-Time Alignment in Diffusion Models",
      "title_zh": "扩散模型中推理时对齐的动态搜索",
      "authors": [
        "Xiner Li",
        "Masatoshi Uehara",
        "Xingyu Su",
        "Gabriele Scalia",
        "Tommaso Biancalani",
        "Aviv Regev",
        "Sergey Levine",
        "Shuiwang Ji"
      ],
      "abstract": "Diffusion models have shown promising generative capabilities across diverse\ndomains, yet aligning their outputs with desired reward functions remains a\nchallenge, particularly in cases where reward functions are non-differentiable.\nSome gradient-free guidance methods have been developed, but they often\nstruggle to achieve optimal inference-time alignment. In this work, we newly\nframe inference-time alignment in diffusion as a search problem and propose\nDynamic Search for Diffusion (DSearch), which subsamples from denoising\nprocesses and approximates intermediate node rewards. It also dynamically\nadjusts beam width and tree expansion to efficiently explore high-reward\ngenerations. To refine intermediate decisions, DSearch incorporates adaptive\nscheduling based on noise levels and a lookahead heuristic function. We\nvalidate DSearch across multiple domains, including biological sequence design,\nmolecular optimization, and image generation, demonstrating superior reward\noptimization compared to existing approaches.",
      "tldr_zh": "该研究解决了扩散模型(Diffusion Models)在生成任务中难以与非微分奖励函数对齐的问题，提出了一种新的方法Dynamic Search for Diffusion (DSearch)。DSearch将推理时对齐视为搜索问题，通过从去噪过程中子采样、近似中间节点奖励，以及动态调整beam width和树扩展来高效探索高奖励生成路径，同时融入基于噪声水平的自适应调度和lookahead启发式函数进行决策优化。在生物序列设计、分子优化和图像生成等多个领域，DSearch比现有方法实现了更优的奖励优化性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.02039v1",
      "published_date": "2025-03-03 20:32:05 UTC",
      "updated_date": "2025-03-03 20:32:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:07:18.433919"
    },
    {
      "arxiv_id": "2503.05803v1",
      "title": "Federated Learning Framework via Distributed Mutual Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yash Gupta"
      ],
      "abstract": "Federated Learning often relies on sharing full or partial model weights,\nwhich can burden network bandwidth and raise privacy risks. We present a\nloss-based alternative using distributed mutual learning. Instead of\ntransmitting weights, clients periodically share their loss predictions on a\npublic test set. Each client then refines its model by combining its local loss\nwith the average Kullback-Leibler divergence over losses from other clients.\nThis collaborative approach both reduces transmission overhead and preserves\ndata privacy. Experiments on a face mask detection task demonstrate that our\nmethod outperforms weight-sharing baselines, achieving higher accuracy on\nunseen data while providing stronger generalization and privacy benefits.",
      "tldr_zh": "这篇论文提出了一种基于分布式互学习的Federated Learning框架，以减少网络带宽负担和隐私风险，客户端通过共享公共测试集上的损失预测来替代模型权重传输。每个客户端结合本地损失和来自其他客户端的平均Kullback-Leibler散度来优化模型，从而实现协作式训练。实验结果显示，在面部口罩检测任务中，该方法比权重共享基线实现了更高的未见数据准确率，并提供了更强的泛化和隐私益处。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.05803v1",
      "published_date": "2025-03-03 20:15:32 UTC",
      "updated_date": "2025-03-03 20:15:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:07:30.882922"
    },
    {
      "arxiv_id": "2503.02034v1",
      "title": "Abn-BLIP: Abnormality-aligned Bootstrapping Language-Image Pre-training for Pulmonary Embolism Diagnosis and Report Generation from CTPA",
      "title_zh": "翻译失败",
      "authors": [
        "Zhusi Zhong",
        "Yuli Wang",
        "Lulu Bi",
        "Zhuoqi Ma",
        "Sun Ho Ahn",
        "Christopher J. Mullin",
        "Colin F. Greineder",
        "Michael K. Atalay",
        "Scott Collins",
        "Grayson L. Baird",
        "Cheng Ting Lin",
        "Webster Stayman",
        "Todd M. Kolb",
        "Ihab Kamel",
        "Harrison X. Bai",
        "Zhicheng Jiao"
      ],
      "abstract": "Medical imaging plays a pivotal role in modern healthcare, with computed\ntomography pulmonary angiography (CTPA) being a critical tool for diagnosing\npulmonary embolism and other thoracic conditions. However, the complexity of\ninterpreting CTPA scans and generating accurate radiology reports remains a\nsignificant challenge. This paper introduces Abn-BLIP (Abnormality-aligned\nBootstrapping Language-Image Pretraining), an advanced diagnosis model designed\nto align abnormal findings to generate the accuracy and comprehensiveness of\nradiology reports. By leveraging learnable queries and cross-modal attention\nmechanisms, our model demonstrates superior performance in detecting\nabnormalities, reducing missed findings, and generating structured reports\ncompared to existing methods. Our experiments show that Abn-BLIP outperforms\nstate-of-the-art medical vision-language models and 3D report generation\nmethods in both accuracy and clinical relevance. These results highlight the\npotential of integrating multimodal learning strategies for improving radiology\nreporting. The source code is available at https://github.com/zzs95/abn-blip.",
      "tldr_zh": "本研究提出 Abn-BLIP，一种异常对齐的引导式语言-图像预训练方法，旨在提升基于 CTPA 扫描的肺栓塞诊断和报告生成。该模型通过 learnable queries 和 cross-modal attention 机制，实现异常发现的精确对齐，减少遗漏并生成结构化的放射学报告。与现有方法相比，实验结果显示 Abn-BLIP 在准确性和临床相关性上优于最先进医疗视觉语言模型和 3D 报告生成方法，展示了多模态学习策略在放射学报告中的潜力。源代码可从 https://github.com/zzs95/abn-blip 获取。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.02034v1",
      "published_date": "2025-03-03 20:13:39 UTC",
      "updated_date": "2025-03-03 20:13:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:07:42.293999"
    },
    {
      "arxiv_id": "2503.02032v1",
      "title": "Comparative Analysis of OpenAI GPT-4o and DeepSeek R1 for Scientific Text Categorization Using Prompt Engineering",
      "title_zh": "翻译失败",
      "authors": [
        "Aniruddha Maiti",
        "Samuel Adewumi",
        "Temesgen Alemayehu Tikure",
        "Zichun Wang",
        "Niladri Sengupta",
        "Anastasiia Sukhanova",
        "Ananya Jana"
      ],
      "abstract": "This study examines how large language models categorize sentences from\nscientific papers using prompt engineering. We use two advanced web-based\nmodels, GPT-4o (by OpenAI) and DeepSeek R1, to classify sentences into\npredefined relationship categories. DeepSeek R1 has been tested on benchmark\ndatasets in its technical report. However, its performance in scientific text\ncategorization remains unexplored. To address this gap, we introduce a new\nevaluation method designed specifically for this task. We also compile a\ndataset of cleaned scientific papers from diverse domains. This dataset\nprovides a platform for comparing the two models. Using this dataset, we\nanalyze their effectiveness and consistency in categorization.",
      "tldr_zh": "本研究比较了 OpenAI GPT-4o 和 DeepSeek R1 这两种大型语言模型在科学文本分类中的性能，重点利用提示工程（prompt engineering）对科学论文句子进行预定义关系类别分类。研究者引入了一种新的评估方法，并编译了一个涵盖多样领域的清洗后科学论文数据集，以填补 DeepSeek R1 在此任务上的性能空白。结果显示，通过该数据集的分析，这两个模型在分类的有效性和一致性方面存在差异，为未来模型优化提供了参考。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ASEE North Central Section 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.02032v1",
      "published_date": "2025-03-03 20:09:35 UTC",
      "updated_date": "2025-03-03 20:09:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:07:53.719993"
    },
    {
      "arxiv_id": "2503.02016v1",
      "title": "Mind the (Belief) Gap: Group Identity in the World of LLMs",
      "title_zh": "注意（信念）差距：在大型语言模型世界中的群组身份",
      "authors": [
        "Angana Borah",
        "Marwa Houalla",
        "Rada Mihalcea"
      ],
      "abstract": "Social biases and belief-driven behaviors can significantly impact Large\nLanguage Models (LLMs) decisions on several tasks. As LLMs are increasingly\nused in multi-agent systems for societal simulations, their ability to model\nfundamental group psychological characteristics remains critical yet\nunder-explored. In this study, we present a multi-agent framework that\nsimulates belief congruence, a classical group psychology theory that plays a\ncrucial role in shaping societal interactions and preferences. Our findings\nreveal that LLMs exhibit amplified belief congruence compared to humans, across\ndiverse contexts. We further investigate the implications of this behavior on\ntwo downstream tasks: (1) misinformation dissemination and (2) LLM learning,\nfinding that belief congruence in LLMs increases misinformation dissemination\nand impedes learning. To mitigate these negative impacts, we propose strategies\ninspired by: (1) contact hypothesis, (2) accuracy nudges, and (3) global\ncitizenship framework. Our results show that the best strategies reduce\nmisinformation dissemination by up to 37% and enhance learning by 11%. Bridging\nsocial psychology and AI, our work provides insights to navigate real-world\ninteractions using LLMs while addressing belief-driven biases.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 在多智能体系统中对信念一致性 (belief congruence) 的表现，发现 LLMs 比人类更强烈地放大这种群体心理特征，导致在不同语境中出现更显著的社会偏见和行为影响。研究通过一个多智能体框架模拟信念一致性，并评估其对下游任务的影响，包括增加错误信息传播和阻碍 LLM 学习。针对这些问题，论文提出三类缓解策略：接触假设 (contact hypothesis)、准确性提示 (accuracy nudges) 和全球公民框架 (global citizenship framework)，这些策略可将错误信息传播减少多达 37% 并提高学习效果 11%。整体而言，该工作桥接了社会心理学和 AI，提供了应对信念驱动偏见的实用洞见。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.02016v1",
      "published_date": "2025-03-03 19:50:52 UTC",
      "updated_date": "2025-03-03 19:50:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:08:08.455821"
    },
    {
      "arxiv_id": "2503.02012v2",
      "title": "Pretrained Embeddings as a Behavior Specification Mechanism",
      "title_zh": "翻译失败",
      "authors": [
        "Parv Kapoor",
        "Abigail Hammer",
        "Ashish Kapoor",
        "Karen Leung",
        "Eunsuk Kang"
      ],
      "abstract": "We propose an approach to formally specifying the behavioral properties of\nsystems that rely on a perception model for interactions with the physical\nworld. The key idea is to introduce embeddings -- mathematical representations\nof a real-world concept -- as a first-class construct in a specification\nlanguage, where properties are expressed in terms of distances between a pair\nof ideal and observed embeddings. To realize this approach, we propose a new\ntype of temporal logic called Embedding Temporal Logic (ETL), and describe how\nit can be used to express a wider range of properties about AI-enabled systems\nthan previously possible. We demonstrate the applicability of ETL through a\npreliminary evaluation involving planning tasks in robots that are driven by\nfoundation models; the results are promising, showing that embedding-based\nspecifications can be used to steer a system towards desirable behaviors.",
      "tldr_zh": "我们提出了一种使用预训练 embeddings 来正式指定依赖感知模型的系统行为属性的方法，通过将 embeddings（真实世界概念的数学表示）作为规范语言中的一等公民，并基于理想和观察 embeddings 之间的距离表达属性。论文引入了新的 Embedding Temporal Logic (ETL)，它能比传统方法表达更广泛的 AI 启用系统属性。初步评估显示，在 foundation models 驱动的机器人规划任务中，ETL 可以有效引导系统朝向可取的行为。",
      "categories": [
        "cs.AI",
        "cs.RO",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.02012v2",
      "published_date": "2025-03-03 19:41:22 UTC",
      "updated_date": "2025-03-06 14:32:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:08:18.410981"
    },
    {
      "arxiv_id": "2503.02007v1",
      "title": "TactStyle: Generating Tactile Textures with Generative AI for Digital Fabrication",
      "title_zh": "翻译失败",
      "authors": [
        "Faraz Faruqi",
        "Maxine Perroni-Scharf",
        "Jaskaran Singh Walia",
        "Yunyi Zhu",
        "Shuyue Feng",
        "Donald Degraen",
        "Stefanie Mueller"
      ],
      "abstract": "Recent work in Generative AI enables the stylization of 3D models based on\nimage prompts. However, these methods do not incorporate tactile information,\nleading to designs that lack the expected tactile properties. We present\nTactStyle, a system that allows creators to stylize 3D models with images while\nincorporating the expected tactile properties. TactStyle accomplishes this\nusing a modified image-generation model fine-tuned to generate heightfields for\ngiven surface textures. By optimizing 3D model surfaces to embody a generated\ntexture, TactStyle creates models that match the desired style and replicate\nthe tactile experience. We utilize a large-scale dataset of textures to train\nour texture generation model. In a psychophysical experiment, we evaluate the\ntactile qualities of a set of 3D-printed original textures and TactStyle's\ngenerated textures. Our results show that TactStyle successfully generates a\nwide range of tactile features from a single image input, enabling a novel\napproach to haptic design.",
      "tldr_zh": "论文提出 TactStyle 系统，利用 Generative AI 基于图像提示对 3D 模型进行风格化，同时融入预期的触觉属性，以解决现有方法忽略 tactile information 的问题。系统通过微调图像生成模型来生成 heightfields，并优化 3D 模型表面，使其既匹配视觉风格又复制触觉体验，利用大规模纹理数据集进行训练。在 psychophysical experiment 中，实验结果显示 TactStyle 能从单个图像输入成功生成广泛的触觉特征，为数字制造中的 haptic design 提供了一种创新方法。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.02007v1",
      "published_date": "2025-03-03 19:29:27 UTC",
      "updated_date": "2025-03-03 19:29:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:08:31.910955"
    },
    {
      "arxiv_id": "2503.05802v1",
      "title": "Illuminant and light direction estimation using Wasserstein distance method",
      "title_zh": "翻译失败",
      "authors": [
        "Selcuk Yazar"
      ],
      "abstract": "Illumination estimation remains a pivotal challenge in image processing,\nparticularly for robotics, where robust environmental perception is essential\nunder varying lighting conditions. Traditional approaches, such as RGB\nhistograms and GIST descriptors, often fail in complex scenarios due to their\nsensitivity to illumination changes. This study introduces a novel method\nutilizing the Wasserstein distance, rooted in optimal transport theory, to\nestimate illuminant and light direction in images. Experiments on diverse\nimages indoor scenes, black-and-white photographs, and night images demonstrate\nthe method's efficacy in detecting dominant light sources and estimating their\ndirections, outperforming traditional statistical methods in complex lighting\nenvironments. The approach shows promise for applications in light source\nlocalization, image quality assessment, and object detection enhancement.\nFuture research may explore adaptive thresholding and integrate gradient\nanalysis to enhance accuracy, offering a scalable solution for real-world\nillumination challenges in robotics and beyond.",
      "tldr_zh": "这篇论文提出了一种利用 Wasserstein distance 方法的新型照明估计技术，基于最优传输理论，用于准确估计图像中的照明和光方向，以克服传统方法如 RGB 直方图和 GIST 描述符在复杂照明环境下的局限性。实验在室内场景、黑白照片和夜景等多样化图像上验证了该方法的有效性，其在检测主导光源和估计方向方面优于传统统计方法。未来，该方法可应用于光源定位、图像质量评估和物体检测增强，并通过整合自适应阈值和梯度分析进一步提升准确性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.05802v1",
      "published_date": "2025-03-03 19:20:09 UTC",
      "updated_date": "2025-03-03 19:20:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:08:44.058766"
    },
    {
      "arxiv_id": "2503.01986v2",
      "title": "Adaptively profiling models with task elicitation",
      "title_zh": "翻译失败",
      "authors": [
        "Davis Brown",
        "Prithvi Balehannina",
        "Helen Jin",
        "Shreya Havaldar",
        "Hamed Hassani",
        "Eric Wong"
      ],
      "abstract": "Language model evaluations often fail to characterize consequential failure\nmodes, forcing experts to inspect outputs and build new benchmarks. We\nintroduce task elicitation, a method that automatically builds new evaluations\nto profile model behavior. Task elicitation finds hundreds of natural-language\ntasks -- an order of magnitude more than prior work -- where frontier models\nexhibit systematic failures, in domains ranging from forecasting to online\nharassment. For example, we find that Sonnet 3.5 over-associates quantum\ncomputing and AGI and that o3-mini is prone to hallucination when fabrications\nare repeated in-context.",
      "tldr_zh": "这篇论文提出了task elicitation方法，用于自动构建新评估以分析语言模型的行为，从而识别其系统性失败模式。相比以往工作，该方法发现了数百个自然语言任务——数量多出一个数量级——涵盖从预测到在线骚扰等多个领域，其中前沿模型表现出显著缺陷。例如，Sonnet 3.5过度关联量子计算和AGI，而o3-mini在上下文中重复捏造时容易产生幻觉。该研究为改进语言模型评估提供了高效工具。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01986v2",
      "published_date": "2025-03-03 19:04:10 UTC",
      "updated_date": "2025-05-20 19:15:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:08:55.383774"
    },
    {
      "arxiv_id": "2503.01985v1",
      "title": "Proportionality in Thumbs Up and Down Voting",
      "title_zh": "翻译失败",
      "authors": [
        "Sonja Kraiczy",
        "Georgios Papasotiropoulos",
        "Grzegorz Pierczyński",
        "Piotr Skowron"
      ],
      "abstract": "Consider the decision-making setting where agents elect a panel by expressing\nboth positive and negative preferences. Prominently, in constitutional AI,\ncitizens democratically select a slate of ethical preferences on which a\nfoundation model is to be trained. There, in practice, agents may both approve\nand disapprove of different ethical principles. Proportionality has been\nwell-studied in computational social choice for approval ballots, but its\nmeaning remains unclear when negative sentiments are also considered. In this\nwork, we propose two conceptually distinct approaches to interpret\nproportionality in the presence of up and down votes. The first approach treats\nthe satisfaction from electing candidates and the impact of vetoing them as\ncomparable, leading to combined proportionality guarantees. The second approach\nconsiders veto power separately, introducing guarantees distinct from\ntraditional proportionality. We formalize axioms for each perspective and\nexamine their satisfiability by suitable adaptations of Phragm\\'en's rule,\nProportional Approval Voting rule and the Method of Equal Shares.",
      "tldr_zh": "这篇论文探讨了在代理人表达正面（thumbs up）和负面（thumbs down）偏好选举面板的决策环境中，如何定义比例性（proportionality），特别是在宪法AI中用于选择伦理偏好的民主过程。作者提出了两种方法：第一种将选举候选人的满足感和否决影响视为可比的，从而提供结合的比例性保证；第二种则将否决权独立处理，引入不同于传统比例性的独特保证。他们形式化了每种视角的公理，并评估了Phragmén's rule、Proportional Approval Voting rule和Method of Equal Shares的适应性是否能满足这些要求。",
      "categories": [
        "cs.GT",
        "cs.AI"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01985v1",
      "published_date": "2025-03-03 19:02:37 UTC",
      "updated_date": "2025-03-03 19:02:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:09:08.206210"
    },
    {
      "arxiv_id": "2503.01980v1",
      "title": "Recurrence-Enhanced Vision-and-Language Transformers for Robust Multimodal Document Retrieval",
      "title_zh": "循环增强的视觉和语言 Transformer 用于鲁棒的多模态文档检索",
      "authors": [
        "Davide Caffagni",
        "Sara Sarto",
        "Marcella Cornia",
        "Lorenzo Baraldi",
        "Rita Cucchiara"
      ],
      "abstract": "Cross-modal retrieval is gaining increasing efficacy and interest from the\nresearch community, thanks to large-scale training, novel architectural and\nlearning designs, and its application in LLMs and multimodal LLMs. In this\npaper, we move a step forward and design an approach that allows for multimodal\nqueries, composed of both an image and a text, and can search within\ncollections of multimodal documents, where images and text are interleaved. Our\nmodel, ReT, employs multi-level representations extracted from different layers\nof both visual and textual backbones, both at the query and document side. To\nallow for multi-level and cross-modal understanding and feature extraction, ReT\nemploys a novel Transformer-based recurrent cell that integrates both textual\nand visual features at different layers, and leverages sigmoidal gates inspired\nby the classical design of LSTMs. Extensive experiments on M2KR and M-BEIR\nbenchmarks show that ReT achieves state-of-the-art performance across diverse\nsettings. Our source code and trained models are publicly available at\nhttps://github.com/aimagelab/ReT.",
      "tldr_zh": "该论文提出了一种名为 ReT 的模型，用于鲁棒的多模态文档检索，允许用户使用图像和文本组成的查询在包含交织图像和文本的文档集合中进行搜索。ReT 采用多层级表示从视觉和文本骨干网络的不同层提取特征，并引入一个基于 Transformer 的循环单元（Transformer-based recurrent cell），通过整合文本和视觉特征以及受 LSTM 启发的 sigmoidal gates 来实现跨模态理解。在 M2KR 和 M-BEIR 基准上的广泛实验显示，ReT 达到了 state-of-the-art 性能，并公开了源码和训练模型以促进进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.01980v1",
      "published_date": "2025-03-03 19:01:17 UTC",
      "updated_date": "2025-03-03 19:01:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:09:17.493484"
    },
    {
      "arxiv_id": "2503.01839v1",
      "title": "Jailbreaking Safeguarded Text-to-Image Models via Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zhengyuan Jiang",
        "Yuepeng Hu",
        "Yuchen Yang",
        "Yinzhi Cao",
        "Neil Zhenqiang Gong"
      ],
      "abstract": "Text-to-Image models may generate harmful content, such as pornographic\nimages, particularly when unsafe prompts are submitted. To address this issue,\nsafety filters are often added on top of text-to-image models, or the models\nthemselves are aligned to reduce harmful outputs. However, these defenses\nremain vulnerable when an attacker strategically designs adversarial prompts to\nbypass these safety guardrails. In this work, we propose PromptTune, a method\nto jailbreak text-to-image models with safety guardrails using a fine-tuned\nlarge language model. Unlike other query-based jailbreak attacks that require\nrepeated queries to the target model, our attack generates adversarial prompts\nefficiently after fine-tuning our AttackLLM. We evaluate our method on three\ndatasets of unsafe prompts and against five safety guardrails. Our results\ndemonstrate that our approach effectively bypasses safety guardrails,\noutperforms existing no-box attacks, and also facilitates other query-based\nattacks.",
      "tldr_zh": "这篇论文提出PromptTune方法，使用微调的大型语言模型(LLM)来绕过文本到图像(Text-to-Image)模型的安全防护，从而生成有害内容。不同于其他基于查询的攻击，PromptTune在微调AttackLLM后能高效生成对抗性提示，而无需反复查询目标模型。实验结果显示，该方法在三个不安全提示数据集上成功绕过五种安全防护，并优于现有无箱攻击，同时还能辅助其他查询-based攻击。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01839v1",
      "published_date": "2025-03-03 18:58:46 UTC",
      "updated_date": "2025-03-03 18:58:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:09:29.720955"
    },
    {
      "arxiv_id": "2503.01836v1",
      "title": "CrowdSelect: Synthetic Instruction Data Selection with Multi-LLM Wisdom",
      "title_zh": "翻译失败",
      "authors": [
        "Yisen Li",
        "Lingfeng Yang",
        "Wenxuan Shen",
        "Pan Zhou",
        "Yao Wan",
        "Weiwei Lin",
        "Dongping Chen"
      ],
      "abstract": "Distilling advanced Large Language Models' instruction-following capabilities\ninto smaller models using a selected subset has become a mainstream approach in\nmodel training. While existing synthetic instruction data selection strategies\nrely mainly on single-dimensional signals (i.e., reward scores, model\nperplexity), they fail to capture the complexity of instruction-following\nacross diverse fields. Therefore, we investigate more diverse signals to\ncapture comprehensive instruction-response pair characteristics and propose\nthree foundational metrics that leverage Multi-LLM wisdom, informed by (1)\ndiverse LLM responses and (2) reward model assessment. Building upon base\nmetrics, we propose CrowdSelect, an integrated metric incorporating a\nclustering-based approach to maintain response diversity. Our comprehensive\nexperiments demonstrate that our foundation metrics consistently improve\nperformance across 4 base models on MT-bench and Arena-Hard. CrowdSelect,\nefficiently incorporating all metrics, achieves state-of-the-art performance in\nboth Full and LoRA fine-tuning, showing improvements of 4.81% on Arena-Hard and\n11.1% on MT-bench with Llama-3.2-3b-instruct. We hope our findings will bring\nvaluable insights for future research in this direction. Code are available at\nhttps://github.com/listentm/crowdselect.",
      "tldr_zh": "本研究针对合成指令数据选择的问题，指出现有策略依赖单一信号（如奖励分数或模型困惑度）无法捕捉指令遵循的复杂性，因此提出三种基础指标，利用Multi-LLM智慧（包括多样化LLM响应和奖励模型评估）来全面评估指令-响应对。基于这些指标，作者开发了CrowdSelect，一种整合了聚类方法的指标，以维护响应多样性。实验结果显示，CrowdSelect在MT-bench和Arena-Hard基准上显著提升了4个基线模型的性能，并在Full和LoRA fine-tuning中实现state-of-the-art效果，例如Llama-3.2-3b-instruct模型的Arena-Hard分数提高了4.81%，MT-bench提高了11.1%。这项工作为未来指令数据选择研究提供了宝贵洞见。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01836v1",
      "published_date": "2025-03-03 18:56:44 UTC",
      "updated_date": "2025-03-03 18:56:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:09:42.644289"
    },
    {
      "arxiv_id": "2503.01829v2",
      "title": "Persuade Me if You Can: A Framework for Evaluating Persuasion Effectiveness and Susceptibility Among Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Nimet Beyza Bozdag",
        "Shuhaib Mehri",
        "Gokhan Tur",
        "Dilek Hakkani-Tür"
      ],
      "abstract": "Large Language Models (LLMs) demonstrate persuasive capabilities that rival\nhuman-level persuasion. While these capabilities can be used for social good,\nthey also present risks of potential misuse. Moreover, LLMs' susceptibility to\npersuasion raises concerns about alignment with ethical principles. To study\nthese dynamics, we introduce Persuade Me If You Can (PMIYC), an automated\nframework for evaluating persuasion through multi-agent interactions. Here,\nPersuader agents engage in multi-turn conversations with the Persuadee agents,\nallowing us to measure LLMs' persuasive effectiveness and their susceptibility\nto persuasion. We conduct comprehensive evaluations across diverse LLMs,\nensuring each model is assessed against others in both subjective and\nmisinformation contexts. We validate the efficacy of our framework through\nhuman evaluations and show alignment with prior work. PMIYC offers a scalable\nalternative to human annotation for studying persuasion in LLMs. Through PMIYC,\nwe find that Llama-3.3-70B and GPT-4o exhibit similar persuasive effectiveness,\noutperforming Claude 3 Haiku by 30%. However, GPT-4o demonstrates over 50%\ngreater resistance to persuasion for misinformation compared to Llama-3.3-70B.\nThese findings provide empirical insights into the persuasive dynamics of LLMs\nand contribute to the development of safer AI systems.",
      "tldr_zh": "本文引入了 Persuade Me If You Can (PMIYC) 框架，用于评估 Large Language Models (LLMs) 的说服有效性和易受说服性，旨在探讨 LLMs 在多智能体互动中的说服动态及其潜在风险。框架通过 Persuader 和 Persuadee 代理的多轮对话，对不同 LLMs 进行全面评估，包括主观和错误信息场景，并通过人类评估验证其有效性。研究发现，GPT-4o 和 Llama-3.3-70B 在说服有效性上类似，且均比 Claude 3 Haiku 高出约 30%；然而，GPT-4o 在抵抗错误信息说服方面比 Llama-3.3-70B 高出 50%。这些结果为开发更安全的 AI 系统提供了重要经验见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01829v2",
      "published_date": "2025-03-03 18:53:21 UTC",
      "updated_date": "2025-03-06 22:13:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:09:56.434217"
    },
    {
      "arxiv_id": "2503.01822v1",
      "title": "Projecting Assumptions: The Duality Between Sparse Autoencoders and Concept Geometry",
      "title_zh": "投影假设：稀疏自编码器与概念几何的对偶性",
      "authors": [
        "Sai Sumedh R. Hindupur",
        "Ekdeep Singh Lubana",
        "Thomas Fel",
        "Demba Ba"
      ],
      "abstract": "Sparse Autoencoders (SAEs) are widely used to interpret neural networks by\nidentifying meaningful concepts from their representations. However, do SAEs\ntruly uncover all concepts a model relies on, or are they inherently biased\ntoward certain kinds of concepts? We introduce a unified framework that recasts\nSAEs as solutions to a bilevel optimization problem, revealing a fundamental\nchallenge: each SAE imposes structural assumptions about how concepts are\nencoded in model representations, which in turn shapes what it can and cannot\ndetect. This means different SAEs are not interchangeable -- switching\narchitectures can expose entirely new concepts or obscure existing ones. To\nsystematically probe this effect, we evaluate SAEs across a spectrum of\nsettings: from controlled toy models that isolate key variables, to\nsemi-synthetic experiments on real model activations and finally to\nlarge-scale, naturalistic datasets. Across this progression, we examine two\nfundamental properties that real-world concepts often exhibit: heterogeneity in\nintrinsic dimensionality (some concepts are inherently low-dimensional, others\nare not) and nonlinear separability. We show that SAEs fail to recover concepts\nwhen these properties are ignored, and we design a new SAE that explicitly\nincorporates both, enabling the discovery of previously hidden concepts and\nreinforcing our theoretical insights. Our findings challenge the idea of a\nuniversal SAE and underscores the need for architecture-specific choices in\nmodel interpretability. Overall, we argue an SAE does not just reveal concepts\n-- it determines what can be seen at all.",
      "tldr_zh": "本文研究了 Sparse Autoencoders (SAEs) 在神经网络解释中的局限性，提出一个统一框架，将 SAEs 视为双层优化问题(bilevel optimization)，揭示其结构假设会偏向特定概念编码，从而影响检测能力。作者通过从玩具模型到大规模数据集的实验，评估了概念的异质性（如内在维度）和非线性可分性，发现现有 SAEs 在忽略这些属性时无法准确恢复概念。基于此，他们设计了一个新 SAE 架构，显式整合这些属性，帮助发现之前隐藏的概念。总体而言，该研究挑战了通用 SAE 的概念，强调架构选择在模型可解释性中的关键作用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2503.01822v1",
      "published_date": "2025-03-03 18:47:40 UTC",
      "updated_date": "2025-03-03 18:47:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:10:08.206340"
    },
    {
      "arxiv_id": "2503.01820v1",
      "title": "RSQ: Learning from Important Tokens Leads to Better Quantized LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Yi-Lin Sung",
        "Prateek Yadav",
        "Jialu Li",
        "Jaehong Yoon",
        "Mohit Bansal"
      ],
      "abstract": "Layer-wise quantization is a key technique for efficiently compressing large\nmodels without expensive retraining. Previous methods typically quantize the\nweights of each layer by \"uniformly\" optimizing the layer reconstruction loss\nacross all output tokens. However, in this paper, we demonstrate that\nbetter-quantized models can be obtained by prioritizing learning from important\ntokens (e.g. which have large attention scores). Building on this finding, we\npropose RSQ (Rotate, Scale, then Quantize), which (1) applies rotations\n(orthogonal transformation) to the model to mitigate outliers (those with\nexceptionally large magnitude), (2) scales the token feature based on its\nimportance, and (3) quantizes the model using the GPTQ framework with the\nsecond-order statistics computed by scaled tokens. To compute token importance,\nwe explore both heuristic and dynamic strategies. Based on a thorough analysis\nof all approaches, we adopt attention concentration, which uses attention\nscores of each token as its importance, as the best approach. We demonstrate\nthat RSQ consistently outperforms baseline methods across multiple downstream\ntasks and three model families: LLaMA3, Mistral, and Qwen2.5. Additionally,\nmodels quantized with RSQ achieve superior performance on long-context tasks,\nfurther highlighting its effectiveness. Lastly, RSQ demonstrates\ngeneralizability across various setups, including different model sizes,\ncalibration datasets, bit precisions, and quantization methods.",
      "tldr_zh": "该论文提出 RSQ 方法，通过优先学习重要 tokens（如具有大 attention scores 的 tokens）来提升大型语言模型（LLMs）的量化性能，解决传统层级量化方法在均匀优化层重建损失时存在的不足。RSQ 包括三个关键步骤：应用旋转（orthogonal transformation）来缓解异常值、根据 token 重要性缩放特征，以及使用 GPTQ 框架基于缩放后的 tokens 计算二阶统计进行量化；其中，token 重要性通过 attention concentration（使用 attention scores）动态计算。实验结果显示，RSQ 在多个下游任务和模型家族（如 LLaMA3、Mistral 和 Qwen2.5）上 consistently 优于基线方法，尤其在长上下文任务中表现突出，并展现出良好的泛化性，适用于不同模型大小、校准数据集、位精度和量化方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Our code is available at https://github.com/ylsung/rsq",
      "pdf_url": "http://arxiv.org/pdf/2503.01820v1",
      "published_date": "2025-03-03 18:46:33 UTC",
      "updated_date": "2025-03-03 18:46:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:10:19.476175"
    },
    {
      "arxiv_id": "2503.01819v1",
      "title": "Do GFlowNets Transfer? Case Study on the Game of 24/42",
      "title_zh": "翻译失败",
      "authors": [
        "Adesh Gupta",
        "Abhinav Kumar",
        "Mansi Gupta",
        "Paras Chopra"
      ],
      "abstract": "Generating diverse solutions is key to human-like reasoning, yet\nautoregressive language models focus on single accurate responses, limiting\ncreativity. GFlowNets optimize solution generation as a flow network, promising\ngreater diversity. Our case study shows their limited zero-shot transferability\nby fine-tuning small and medium-sized large language models on the Game of 24\nand testing them on the Game of 42 datasets. Results revealed that GFlowNets\nstruggle to maintain solution diversity and accuracy, highlighting key\nlimitations in their cross-task generalization and the need for future research\nin improved transfer learning capabilities.",
      "tldr_zh": "本研究探讨了 GFlowNets 是否具备跨任务转移能力，通过在 Game of 24 数据集上微调小中型大型语言模型，并测试其在 Game of 42 数据集上的表现。GFlowNets 旨在通过流网络优化生成多样化解决方案，以提升人类-like 推理，但实验结果显示其零样本转移能力有限，无法有效维持解决方案的多样性和准确性。这种局限性突出了 GFlowNets 在跨任务泛化方面的关键问题，并强调了未来研究需加强转移学习能力。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01819v1",
      "published_date": "2025-03-03 18:43:25 UTC",
      "updated_date": "2025-03-03 18:43:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:10:32.116565"
    },
    {
      "arxiv_id": "2503.01814v1",
      "title": "LLMInit: A Free Lunch from Large Language Models for Selective Initialization of Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Weizhi Zhang",
        "Liangwei Yang",
        "Wooseong Yang",
        "Henry Peng Zou",
        "Yuqing Liu",
        "Ke Xu",
        "Sourav Medya",
        "Philip S. Yu"
      ],
      "abstract": "Collaborative filtering models, particularly graph-based approaches, have\ndemonstrated strong performance in capturing user-item interactions for\nrecommendation systems. However, they continue to struggle in cold-start and\ndata-sparse scenarios. The emergence of large language models (LLMs) like GPT\nand LLaMA presents new possibilities for enhancing recommendation performance,\nespecially in cold-start settings. Despite their promise, LLMs pose challenges\nrelated to scalability and efficiency due to their high computational demands\nand limited ability to model complex user-item relationships effectively. In\nthis work, we introduce a novel perspective on leveraging LLMs for CF model\ninitialization. Through experiments, we uncover an embedding collapse issue\nwhen scaling CF models to larger embedding dimensions. To effectively harness\nlarge-scale LLM embeddings, we propose innovative selective initialization\nstrategies utilizing random, uniform, and variance-based index sampling. Our\ncomprehensive evaluation on multiple real-world datasets demonstrates\nsignificant performance gains across various CF models while maintaining a\nlower computational cost compared to existing LLM-based recommendation\napproaches.",
      "tldr_zh": "该研究提出LLMInit，一种利用大语言模型(LLMs)对协同过滤(CF)模型进行选择性初始化的新方法，以解决CF模型在冷启动和数据稀疏场景下的性能问题，同时避免LLMs的高计算开销。作者通过实验发现，当CF模型扩展到更大嵌入维度时，会出现嵌入坍缩(embedding collapse)问题，并引入随机(random)、均匀(uniform)和基于方差(variance-based)索引采样的创新初始化策略。实验结果显示，在多个真实数据集上，该方法显著提升了各种CF模型的性能，同时保持较低的计算成本，比现有LLM-based推荐方法更高效。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01814v1",
      "published_date": "2025-03-03 18:41:59 UTC",
      "updated_date": "2025-03-03 18:41:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:10:43.209449"
    },
    {
      "arxiv_id": "2503.01811v1",
      "title": "AutoAdvExBench: Benchmarking autonomous exploitation of adversarial example defenses",
      "title_zh": "翻译失败",
      "authors": [
        "Nicholas Carlini",
        "Javier Rando",
        "Edoardo Debenedetti",
        "Milad Nasr",
        "Florian Tramèr"
      ],
      "abstract": "We introduce AutoAdvExBench, a benchmark to evaluate if large language models\n(LLMs) can autonomously exploit defenses to adversarial examples. Unlike\nexisting security benchmarks that often serve as proxies for real-world tasks,\nbench directly measures LLMs' success on tasks regularly performed by machine\nlearning security experts. This approach offers a significant advantage: if a\nLLM could solve the challenges presented in bench, it would immediately present\npractical utility for adversarial machine learning researchers. We then design\na strong agent that is capable of breaking 75% of CTF-like (\"homework\nexercise\") adversarial example defenses. However, we show that this agent is\nonly able to succeed on 13% of the real-world defenses in our benchmark,\nindicating the large gap between difficulty in attacking \"real\" code, and\nCTF-like code. In contrast, a stronger LLM that can attack 21% of real defenses\nonly succeeds on 54% of CTF-like defenses. We make this benchmark available at\nhttps://github.com/ethz-spylab/AutoAdvExBench.",
      "tldr_zh": "本研究引入了 AutoAdvExBench，这是一个基准，用于评估大型语言模型 (LLMs) 是否能自主利用对抗样本防御，从而直接测量其在真实机器学习安全任务中的性能，而非依赖代理任务。研究设计了一个强大代理，能成功打破 75% 的 CTF-like (\"homework exercise\") 防御，但在真实世界防御上仅成功 13%，突显了攻击真实代码与 CTF-like 代码的难度差距。相比之下，一个更强的 LLM 仅在 54% 的 CTF-like 防御上成功，而在真实防御上达到 21%。该基准可从 https://github.com/ethz-spylab/AutoAdvExBench 获取，为对抗机器学习研究提供实际工具。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01811v1",
      "published_date": "2025-03-03 18:39:48 UTC",
      "updated_date": "2025-03-03 18:39:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:10:56.011393"
    },
    {
      "arxiv_id": "2503.01805v1",
      "title": "Depth-Width tradeoffs in Algorithmic Reasoning of Graph Tasks with Transformers",
      "title_zh": "Transformer 在图任务算法推理中的深度-宽度权衡",
      "authors": [
        "Gilad Yehudai",
        "Clayton Sanford",
        "Maya Bechler-Speicher",
        "Orr Fischer",
        "Ran Gilad-Bachrach",
        "Amir Globerson"
      ],
      "abstract": "Transformers have revolutionized the field of machine learning. In\nparticular, they can be used to solve complex algorithmic problems, including\ngraph-based tasks. In such algorithmic tasks a key question is what is the\nminimal size of a transformer that can implement a task. Recent work has begun\nto explore this problem for graph-based tasks, showing that for sub-linear\nembedding dimension (i.e., model width) logarithmic depth suffices. However, an\nopen question, which we address here, is what happens if width is allowed to\ngrow linearly. Here we analyze this setting, and provide the surprising result\nthat with linear width, constant depth suffices for solving a host of\ngraph-based problems. This suggests that a moderate increase in width can allow\nmuch shallower models, which are advantageous in terms of inference time. For\nother problems, we show that quadratic width is required. Our results\ndemonstrate the complex and intriguing landscape of transformer implementations\nof graph-based algorithms. We support our theoretical results with empirical\nevaluations.",
      "tldr_zh": "这篇论文探讨了 Transformers 在处理图任务时的深度-宽度权衡，分析了最小模型大小以实现算法推理的关键问题。研究发现，当模型宽度线性增长时，常数深度就足以解决许多图-based 问题，这有助于显著降低推理时间并提高效率；然而，对于某些任务，可能需要二次方宽度。论文通过理论分析和实证评估，揭示了 Transformers 实现图算法的复杂景观，并为优化模型设计提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01805v1",
      "published_date": "2025-03-03 18:33:58 UTC",
      "updated_date": "2025-03-03 18:33:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:11:06.659937"
    },
    {
      "arxiv_id": "2503.01804v2",
      "title": "$\\texttt{SEM-CTRL}$: Semantically Controlled Decoding",
      "title_zh": "SEM-CTRL：语义控制",
      "authors": [
        "Mohammad Albinhassan",
        "Pranava Madhyastha",
        "Alessandra Russo"
      ],
      "abstract": "Ensuring both syntactic and semantic correctness in Large Language Model\n(LLM) outputs remains a significant challenge, despite being critical for\nreal-world deployment. In this paper, we introduce $\\texttt{SEM-CTRL}$, a\nunified approach that enforces rich context-sensitive constraints and task- and\ninstance-specific semantics directly on an LLM decoder. Our approach integrates\ntoken-level MCTS, which is guided by specific syntactic and semantic\nconstraints. The constraints over the desired outputs are expressed using\nAnswer Set Grammars -- a logic-based formalism that generalizes\ncontext-sensitive grammars while incorporating background knowledge to\nrepresent task-specific semantics. We show that our approach guarantees correct\ncompletions for any off-the-shelf LLM without the need for fine-tuning. We\nevaluate $\\texttt{SEM-CTRL}$ on a range of tasks, including synthetic grammar\nsynthesis, combinatorial reasoning, and planning. Our results demonstrate that\n$\\texttt{SEM-CTRL}$ allows small pre-trained LLMs to efficiently outperform\nlarger variants and state-of-the-art reasoning models (e.g., o1-preview) while\nsimultaneously guaranteeing solution correctness.",
      "tldr_zh": "本研究提出$\\texttt{SEM-CTRL}$，一种统一方法，用于在大型语言模型(LLM)解码器上强制执行上下文敏感的语法和语义约束，从而确保输出正确性。该方法整合了token-level MCTS（蒙特卡洛树搜索），并使用Answer Set Grammars——一种基于逻辑的形式化语言——来表示任务特定的语义和背景知识，而无需对现成LLM进行微调。在合成语法合成、组合推理和规划等任务上，实验结果显示，$\\texttt{SEM-CTRL}$让小型预训练LLM高效超越更大模型（如o1-preview），并同时保证解决方案的准确性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01804v2",
      "published_date": "2025-03-03 18:33:46 UTC",
      "updated_date": "2025-03-06 16:07:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:11:19.855229"
    },
    {
      "arxiv_id": "2503.01792v1",
      "title": "Generating Counterfactual Explanations Under Temporal Constraints",
      "title_zh": "在时间约束下生成反事实解释",
      "authors": [
        "Andrei Buliga",
        "Chiara Di Francescomarino",
        "Chiara Ghidini",
        "Marco Montali",
        "Massimiliano Ronzani"
      ],
      "abstract": "Counterfactual explanations are one of the prominent eXplainable Artificial\nIntelligence (XAI) techniques, and suggest changes to input data that could\nalter predictions, leading to more favourable outcomes. Existing counterfactual\nmethods do not readily apply to temporal domains, such as that of process\nmining, where data take the form of traces of activities that must obey to\ntemporal background knowledge expressing which dynamics are possible and which\nnot. Specifically, counterfactuals generated off-the-shelf may violate the\nbackground knowledge, leading to inconsistent explanations. This work tackles\nthis challenge by introducing a novel approach for generating temporally\nconstrained counterfactuals, guaranteed to comply by design with background\nknowledge expressed in Linear Temporal Logic on process traces (LTLp). We do so\nby infusing automata-theoretic techniques for LTLp inside a genetic algorithm\nfor counterfactual generation. The empirical evaluation shows that the\ngenerated counterfactuals are temporally meaningful and more interpretable for\napplications involving temporal dependencies.",
      "tldr_zh": "本研究针对反事实解释（Counterfactual explanations）在时间领域（如过程挖掘）的应用，提出了一种新方法，以解决现有方法可能违反时间背景知识（如Linear Temporal Logic on process traces, LTLp）导致解释不一致的问题。该方法将LTLp的自动机理论技术融入遗传算法中，生成符合时间约束的反事实解释，确保其在动态过程中的可行性。实验结果表明，这些解释在涉及时间依赖的应用中更具时间意义和可解释性，从而提升了可解释人工智能（XAI）的实用性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.01792v1",
      "published_date": "2025-03-03 18:22:48 UTC",
      "updated_date": "2025-03-03 18:22:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:11:30.556992"
    },
    {
      "arxiv_id": "2503.09613v1",
      "title": "Empowering the Future Workforce: Prioritizing Education for the AI-Accelerated Job Market",
      "title_zh": "翻译失败",
      "authors": [
        "Lisa Amini",
        "Henry F. Korth",
        "Nita Patel",
        "Evan Peck",
        "Ben Zorn"
      ],
      "abstract": "AI's rapid integration into the workplace demands new approaches to workforce\neducation and training and broader AI literacy across disciplines. Coordinated\naction from government, industry, and educational institutions is necessary to\nensure workers can adapt to accelerating technological change.",
      "tldr_zh": "这篇论文强调了 AI 在职场中的快速整合，要求采用新的劳动力教育和培训方法，并推广跨学科的 AI 素养，以应对技术变革。论文主张政府、行业和教育机构进行协调行动，确保工作者能够适应加速的技术发展。通过优先发展教育，该研究旨在赋能未来的职场力量，促进更具弹性的劳动力市场。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.09613v1",
      "published_date": "2025-03-03 18:15:45 UTC",
      "updated_date": "2025-03-03 18:15:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:11:42.782961"
    },
    {
      "arxiv_id": "2503.01776v5",
      "title": "Beyond Matryoshka: Revisiting Sparse Coding for Adaptive Representation",
      "title_zh": "翻译失败",
      "authors": [
        "Tiansheng Wen",
        "Yifei Wang",
        "Zequn Zeng",
        "Zhong Peng",
        "Yudi Su",
        "Xinyang Liu",
        "Bo Chen",
        "Hongwei Liu",
        "Stefanie Jegelka",
        "Chenyu You"
      ],
      "abstract": "Many large-scale systems rely on high-quality deep representations\n(embeddings) to facilitate tasks like retrieval, search, and generative\nmodeling. Matryoshka Representation Learning (MRL) recently emerged as a\nsolution for adaptive embedding lengths, but it requires full model retraining\nand suffers from noticeable performance degradations at short lengths. In this\npaper, we show that sparse coding offers a compelling alternative for achieving\nadaptive representation with minimal overhead and higher fidelity. We propose\nContrastive Sparse Representation (CSR), a method that sparsifies pre-trained\nembeddings into a high-dimensional but selectively activated feature space. By\nleveraging lightweight autoencoding and task-aware contrastive objectives, CSR\npreserves semantic quality while allowing flexible, cost-effective inference at\ndifferent sparsity levels. Extensive experiments on image, text, and multimodal\nbenchmarks demonstrate that CSR consistently outperforms MRL in terms of both\naccuracy and retrieval speed-often by large margins-while also cutting training\ntime to a fraction of that required by MRL. Our results establish sparse coding\nas a powerful paradigm for adaptive representation learning in real-world\napplications where efficiency and fidelity are both paramount. Code is\navailable at https://github.com/neilwen987/CSR_Adaptive_Rep",
      "tldr_zh": "本文重新审视 sparse coding 作为适应性表示学习的替代方案，解决 Matryoshka Representation Learning (MRL) 的问题，如需要完整模型重新训练和在短长度下性能下降。作者提出 Contrastive Sparse Representation (CSR) 方法，通过轻量级 autoencoding 和 task-aware contrastive objectives 将预训练 embeddings 稀疏化为高维选择性激活的特征空间，从而保持语义质量并支持灵活的稀疏级别推理。在图像、文本和多模态基准上的实验显示，CSR 在准确性和检索速度上显著优于 MRL，同时将训练时间减少至 MRL 的几分之一，确立了 sparse coding 在效率与保真度并重的实际应用中的强大潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICML2025",
      "pdf_url": "http://arxiv.org/pdf/2503.01776v5",
      "published_date": "2025-03-03 17:59:48 UTC",
      "updated_date": "2025-05-20 02:32:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:11:56.731989"
    },
    {
      "arxiv_id": "2503.01763v1",
      "title": "Retrieval Models Aren't Tool-Savvy: Benchmarking Tool Retrieval for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zhengliang Shi",
        "Yuhan Wang",
        "Lingyong Yan",
        "Pengjie Ren",
        "Shuaiqiang Wang",
        "Dawei Yin",
        "Zhaochun Ren"
      ],
      "abstract": "Tool learning aims to augment large language models (LLMs) with diverse\ntools, enabling them to act as agents for solving practical tasks. Due to the\nlimited context length of tool-using LLMs, adopting information retrieval (IR)\nmodels to select useful tools from large toolsets is a critical initial step.\nHowever, the performance of IR models in tool retrieval tasks remains\nunderexplored and unclear. Most tool-use benchmarks simplify this step by\nmanually pre-annotating a small set of relevant tools for each task, which is\nfar from the real-world scenarios. In this paper, we propose ToolRet, a\nheterogeneous tool retrieval benchmark comprising 7.6k diverse retrieval tasks,\nand a corpus of 43k tools, collected from existing datasets. We benchmark six\ntypes of models on ToolRet. Surprisingly, even the models with strong\nperformance in conventional IR benchmarks, exhibit poor performance on ToolRet.\nThis low retrieval quality degrades the task pass rate of tool-use LLMs. As a\nfurther step, we contribute a large-scale training dataset with over 200k\ninstances, which substantially optimizes the tool retrieval ability of IR\nmodels.",
      "tldr_zh": "该研究发现，信息检索 (IR) 模型在为大型语言模型 (LLMs) 选择工具时表现不佳，影响了 LLMs 作为代理解决实际任务的效率。论文提出 ToolRet 基准，这是一个包含 7.6k 个多样化检索任务和 43k 个工具的异构数据集，用于评估六种 IR 模型的表现，结果显示这些模型即使在传统 IR 基准上表现出色，也在 ToolRet 上表现欠佳，导致工具使用 LLMs 的任务通过率下降。作为进一步贡献，论文提供了一个超过 20k 实例的大型训练数据集，大大提升了 IR 模型的工具检索能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01763v1",
      "published_date": "2025-03-03 17:37:16 UTC",
      "updated_date": "2025-03-03 17:37:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:12:06.924404"
    },
    {
      "arxiv_id": "2503.01758v1",
      "title": "Zero-Trust Artificial Intelligence Model Security Based on Moving Target Defense and Content Disarm and Reconstruction",
      "title_zh": "基于",
      "authors": [
        "Daniel Gilkarov",
        "Ran Dubin"
      ],
      "abstract": "This paper examines the challenges in distributing AI models through model\nzoos and file transfer mechanisms. Despite advancements in security measures,\nvulnerabilities persist, necessitating a multi-layered approach to mitigate\nrisks effectively. The physical security of model files is critical, requiring\nstringent access controls and attack prevention solutions. This paper proposes\na novel solution architecture composed of two prevention approaches. The first\nis Content Disarm and Reconstruction (CDR), which focuses on disarming\nserialization attacks that enable attackers to run malicious code as soon as\nthe model is loaded. The second is protecting the model architecture and\nweights from attacks by using Moving Target Defense (MTD), alerting the model\nstructure, and providing verification steps to detect such attacks. The paper\nfocuses on the highly exploitable Pickle and PyTorch file formats. It\ndemonstrates a 100% disarm rate while validated against known AI model\nrepositories and actual malware attacks from the HuggingFace model zoo.",
      "tldr_zh": "本论文探讨了AI模型通过模型库和文件传输分发的安全挑战，特别是序列化攻击带来的风险，并提出了一种基于零信任（Zero-Trust）的多层防护架构。解决方案包括Content Disarm and Reconstruction (CDR)技术，用于解除序列化攻击以防止恶意代码在模型加载时运行；以及Moving Target Defense (MTD)策略，通过动态改变模型结构并添加验证步骤来保护模型架构和权重。针对Pickle和PyTorch文件格式的实验显示，该方法在HuggingFace模型库的已知攻击中实现了100%的解除率，为提升AI模型安全提供了可靠的预防机制。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01758v1",
      "published_date": "2025-03-03 17:32:19 UTC",
      "updated_date": "2025-03-03 17:32:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:12:17.652141"
    },
    {
      "arxiv_id": "2503.01751v1",
      "title": "SAKE: Steering Activations for Knowledge Editing",
      "title_zh": "翻译失败",
      "authors": [
        "Marco Scialanga",
        "Thibault Laugel",
        "Vincent Grari",
        "Marcin Detyniecki"
      ],
      "abstract": "As Large Langue Models have been shown to memorize real-world facts, the need\nto update this knowledge in a controlled and efficient manner arises. Designed\nwith these constraints in mind, Knowledge Editing (KE) approaches propose to\nalter specific facts in pretrained models. However, they have been shown to\nsuffer from several limitations, including their lack of contextual robustness\nand their failure to generalize to logical implications related to the fact. To\novercome these issues, we propose SAKE, a steering activation method that\nmodels a fact to be edited as a distribution rather than a single prompt.\nLeveraging Optimal Transport, SAKE alters the LLM behavior over a whole\nfact-related distribution, defined as paraphrases and logical implications.\nSeveral numerical experiments demonstrate the effectiveness of this method:\nSAKE is thus able to perform more robust edits than its existing counterparts.",
      "tldr_zh": "该研究针对大型语言模型（Large Language Models, LLMs）记忆真实世界事实但更新知识时存在的局限性（如缺乏上下文鲁棒性和对逻辑含义的泛化失败），提出了一种名为 SAKE 的激活导向方法。SAKE 将待编辑的事实建模为一个分布（包括改述和逻辑含义），并利用 Optimal Transport 技术调整 LLM 的激活，从而在更广泛的上下文中实现鲁棒知识编辑。实验结果表明，SAKE 比现有 Knowledge Editing (KE) 方法更有效，能够显著提升编辑的准确性和泛化能力。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01751v1",
      "published_date": "2025-03-03 17:20:29 UTC",
      "updated_date": "2025-03-03 17:20:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:12:29.516953"
    },
    {
      "arxiv_id": "2503.01747v2",
      "title": "Position: Don't use the CLT in LLM evals with fewer than a few hundred datapoints",
      "title_zh": "翻译失败",
      "authors": [
        "Sam Bowyer",
        "Laurence Aitchison",
        "Desi R. Ivanova"
      ],
      "abstract": "Rigorous statistical evaluations of large language models (LLMs), including\nvalid error bars and significance testing, are essential for meaningful and\nreliable performance assessment. Currently, when such statistical measures are\nreported, they typically rely on the Central Limit Theorem (CLT). In this\nposition paper, we argue that while CLT-based methods for uncertainty\nquantification are appropriate when benchmarks consist of thousands of\nexamples, they fail to provide adequate uncertainty estimates for LLM\nevaluations that rely on smaller, highly specialized benchmarks. In these\nsmall-data settings, we demonstrate that CLT-based methods perform very poorly,\nusually dramatically underestimating uncertainty (i.e. producing error bars\nthat are too small). We give recommendations for alternative frequentist and\nBayesian methods that are both easy to implement and more appropriate in these\nincreasingly common scenarios. We provide a simple Python library for these\nBayesian methods at https://github.com/sambowyer/bayes_evals .",
      "tldr_zh": "这篇立场论文（Position Paper）主张，在大型语言模型（LLM）评估中使用中心极限定理（CLT）进行不确定性量化时，应避免样本量少于几百个数据点，因为CLT会显著低估不确定性，导致误差条过小。作者通过实验演示，在小样本基准场景下，CLT方法表现不佳，无法提供可靠的统计评估。论文推荐了更合适的替代方法，包括frequentist和Bayesian方法，这些方法易于实施，并提供了一个简单的Python库（https://github.com/sambowyer/bayes_evals）来支持这些评估。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.AI",
      "comment": "36 pages, 37 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.01747v2",
      "published_date": "2025-03-03 17:15:17 UTC",
      "updated_date": "2025-03-04 11:30:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:12:42.419989"
    },
    {
      "arxiv_id": "2503.01743v2",
      "title": "Phi-4-Mini Technical Report: Compact yet Powerful Multimodal Language Models via Mixture-of-LoRAs",
      "title_zh": "翻译失败",
      "authors": [
        "Microsoft",
        ":",
        "Abdelrahman Abouelenin",
        "Atabak Ashfaq",
        "Adam Atkinson",
        "Hany Awadalla",
        "Nguyen Bach",
        "Jianmin Bao",
        "Alon Benhaim",
        "Martin Cai",
        "Vishrav Chaudhary",
        "Congcong Chen",
        "Dong Chen",
        "Dongdong Chen",
        "Junkun Chen",
        "Weizhu Chen",
        "Yen-Chun Chen",
        "Yi-ling Chen",
        "Qi Dai",
        "Xiyang Dai",
        "Ruchao Fan",
        "Mei Gao",
        "Min Gao",
        "Amit Garg",
        "Abhishek Goswami",
        "Junheng Hao",
        "Amr Hendy",
        "Yuxuan Hu",
        "Xin Jin",
        "Mahmoud Khademi",
        "Dongwoo Kim",
        "Young Jin Kim",
        "Gina Lee",
        "Jinyu Li",
        "Yunsheng Li",
        "Chen Liang",
        "Xihui Lin",
        "Zeqi Lin",
        "Mengchen Liu",
        "Yang Liu",
        "Gilsinia Lopez",
        "Chong Luo",
        "Piyush Madan",
        "Vadim Mazalov",
        "Arindam Mitra",
        "Ali Mousavi",
        "Anh Nguyen",
        "Jing Pan",
        "Daniel Perez-Becker",
        "Jacob Platin",
        "Thomas Portet",
        "Kai Qiu",
        "Bo Ren",
        "Liliang Ren",
        "Sambuddha Roy",
        "Ning Shang",
        "Yelong Shen",
        "Saksham Singhal",
        "Subhojit Som",
        "Xia Song",
        "Tetyana Sych",
        "Praneetha Vaddamanu",
        "Shuohang Wang",
        "Yiming Wang",
        "Zhenghao Wang",
        "Haibin Wu",
        "Haoran Xu",
        "Weijian Xu",
        "Yifan Yang",
        "Ziyi Yang",
        "Donghan Yu",
        "Ishmam Zabir",
        "Jianwen Zhang",
        "Li Lyna Zhang",
        "Yunan Zhang",
        "Xiren Zhou"
      ],
      "abstract": "We introduce Phi-4-Mini and Phi-4-Multimodal, compact yet highly capable\nlanguage and multimodal models. Phi-4-Mini is a 3.8-billion-parameter language\nmodel trained on high-quality web and synthetic data, significantly\noutperforming recent open-source models of similar size and matching the\nperformance of models twice its size on math and coding tasks requiring complex\nreasoning. This achievement is driven by a carefully curated synthetic data\nrecipe emphasizing high-quality math and coding datasets. Compared to its\npredecessor, Phi-3.5-Mini, Phi-4-Mini features an expanded vocabulary size of\n200K tokens to better support multilingual applications, as well as group query\nattention for more efficient long-sequence generation. Phi-4-Multimodal is a\nmultimodal model that integrates text, vision, and speech/audio input\nmodalities into a single model. Its novel modality extension approach leverages\nLoRA adapters and modality-specific routers to allow multiple inference modes\ncombining various modalities without interference. For example, it now ranks\nfirst in the OpenASR leaderboard to date, although the LoRA component of the\nspeech/audio modality has just 460 million parameters. Phi-4-Multimodal\nsupports scenarios involving (vision + language), (vision + speech), and\n(speech/audio) inputs, outperforming larger vision-language and speech-language\nmodels on a wide range of tasks. Additionally, we experiment to further train\nPhi-4-Mini to enhance its reasoning capabilities. Despite its compact\n3.8-billion-parameter size, this experimental version achieves reasoning\nperformance on par with or surpassing significantly larger models, including\nDeepSeek-R1-Distill-Qwen-7B and DeepSeek-R1-Distill-Llama-8B.",
      "tldr_zh": "我们介绍了 Phi-4-Mini 和 Phi-4-Multimodal 模型，前者是一个 3.8 亿参数的紧凑语言模型，通过高质量的网络和合成数据训练，在数学和编码任务上超越同规模开源模型，并与更大模型（如双倍参数者）匹敌。Phi-4-Mini 相对于前代 Phi-3.5-Mini 提升了词汇表至 200K tokens，并采用 group query attention 以提高多语言支持和长序列生成效率。Phi-4-Multimodal 通过 Mixture-of-LoRAs 的模态扩展方法，整合文本、视觉和语音/音频输入，支持多种组合模态，并在 OpenASR 排行榜上排名第一，同时在各种任务中优于更大模型。实验进一步训练 Phi-4-Mini 后，其推理能力达到或超过 DeepSeek-R1-Distill-Qwen-7B 等更大模型的水平。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "39 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.01743v2",
      "published_date": "2025-03-03 17:05:52 UTC",
      "updated_date": "2025-03-07 09:05:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:12:56.628408"
    },
    {
      "arxiv_id": "2503.01734v1",
      "title": "Adversarial Agents: Black-Box Evasion Attacks with Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Kyle Domico",
        "Jean-Charles Noirot Ferrand",
        "Ryan Sheatsley",
        "Eric Pauley",
        "Josiah Hanna",
        "Patrick McDaniel"
      ],
      "abstract": "Reinforcement learning (RL) offers powerful techniques for solving complex\nsequential decision-making tasks from experience. In this paper, we demonstrate\nhow RL can be applied to adversarial machine learning (AML) to develop a new\nclass of attacks that learn to generate adversarial examples: inputs designed\nto fool machine learning models. Unlike traditional AML methods that craft\nadversarial examples independently, our RL-based approach retains and exploits\npast attack experience to improve future attacks. We formulate adversarial\nexample generation as a Markov Decision Process and evaluate RL's ability to\n(a) learn effective and efficient attack strategies and (b) compete with\nstate-of-the-art AML. On CIFAR-10, our agent increases the success rate of\nadversarial examples by 19.4% and decreases the median number of victim model\nqueries per adversarial example by 53.2% from the start to the end of training.\nIn a head-to-head comparison with a state-of-the-art image attack,\nSquareAttack, our approach enables an adversary to generate adversarial\nexamples with 13.1% more success after 5000 episodes of training. From a\nsecurity perspective, this work demonstrates a powerful new attack vector that\nuses RL to attack ML models efficiently and at scale.",
      "tldr_zh": "本论文提出了一种基于 Reinforcement Learning (RL) 的黑盒逃避攻击方法，即 Adversarial Agents，将对抗样本生成表述为 Markov Decision Process (MDP)，允许攻击代理利用过去的攻击经验来优化未来策略。相比传统对抗机器学习 (AML) 方法，该方法在 CIFAR-10 数据集上实现了对抗样本成功率提高 19.4%，并将受害模型查询次数减少 53.2%。此外，经过 5000 轮训练，该方法比 SquareAttack 提高了 13.1% 的成功率，从安全视角展示了 RL 在高效、大规模攻击机器学习模型方面的强大潜力。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01734v1",
      "published_date": "2025-03-03 16:54:03 UTC",
      "updated_date": "2025-03-03 16:54:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:13:07.572366"
    },
    {
      "arxiv_id": "2503.01722v1",
      "title": "Learning Exposure Mapping Functions for Inferring Heterogeneous Peer Effects",
      "title_zh": "翻译失败",
      "authors": [
        "Shishir Adhikari",
        "Sourav Medya",
        "Elena Zheleva"
      ],
      "abstract": "In causal inference, interference refers to the phenomenon in which the\nactions of peers in a network can influence an individual's outcome. Peer\neffect refers to the difference in counterfactual outcomes of an individual for\ndifferent levels of peer exposure, the extent to which an individual is exposed\nto the treatments, actions, or behaviors of peers. Estimating peer effects\nrequires deciding how to represent peer exposure. Typically, researchers define\nan exposure mapping function that aggregates peer treatments and outputs peer\nexposure. Most existing approaches for defining exposure mapping functions\nassume peer exposure based on the number or fraction of treated peers. Recent\nstudies have investigated more complex functions of peer exposure which capture\nthat different peers can exert different degrees of influence. However, none of\nthese works have explicitly considered the problem of automatically learning\nthe exposure mapping function. In this work, we focus on learning this function\nfor the purpose of estimating heterogeneous peer effects, where heterogeneity\nrefers to the variation in counterfactual outcomes for the same peer exposure\nbut different individual's contexts. We develop EgoNetGNN, a graph neural\nnetwork (GNN)-based method, to automatically learn the appropriate exposure\nmapping function allowing for complex peer influence mechanisms that, in\naddition to peer treatments, can involve the local neighborhood structure and\nedge attributes. We show that GNN models that use peer exposure based on the\nnumber or fraction of treated peers or learn peer exposure naively face\ndifficulty accounting for such influence mechanisms. Our comprehensive\nevaluation on synthetic and semi-synthetic network data shows that our method\nis more robust to different unknown underlying influence mechanisms when\nestimating heterogeneous peer effects when compared to state-of-the-art\nbaselines.",
      "tldr_zh": "本文研究了因果推断(causal inference)中异质同伴效应(heterogeneous peer effects)的估计问题，焦点在于自动学习暴露映射函数(exposure mapping function)，以捕捉复杂同伴影响机制，包括同伴治疗、局部邻域结构和边属性。作者提出EgoNetGNN，一种基于图神经网络(GNN)的方法，能够动态学习这些函数，从而更准确地处理不同个体背景下的结果差异。与传统方法相比，EgoNetGNN在合成和半合成网络数据上的实验显示，其在估计异质同伴效应时更robust，能够更好地适应未知影响机制。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.SI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01722v1",
      "published_date": "2025-03-03 16:37:05 UTC",
      "updated_date": "2025-03-03 16:37:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:13:20.262145"
    },
    {
      "arxiv_id": "2503.01715v2",
      "title": "KeyFace: Expressive Audio-Driven Facial Animation for Long Sequences via KeyFrame Interpolation",
      "title_zh": "翻译失败",
      "authors": [
        "Antoni Bigata",
        "Michał Stypułkowski",
        "Rodrigo Mira",
        "Stella Bounareli",
        "Konstantinos Vougioukas",
        "Zoe Landgraf",
        "Nikita Drobyshev",
        "Maciej Zieba",
        "Stavros Petridis",
        "Maja Pantic"
      ],
      "abstract": "Current audio-driven facial animation methods achieve impressive results for\nshort videos but suffer from error accumulation and identity drift when\nextended to longer durations. Existing methods attempt to mitigate this through\nexternal spatial control, increasing long-term consistency but compromising the\nnaturalness of motion. We propose KeyFace, a novel two-stage diffusion-based\nframework, to address these issues. In the first stage, keyframes are generated\nat a low frame rate, conditioned on audio input and an identity frame, to\ncapture essential facial expressions and movements over extended periods of\ntime. In the second stage, an interpolation model fills in the gaps between\nkeyframes, ensuring smooth transitions and temporal coherence. To further\nenhance realism, we incorporate continuous emotion representations and handle a\nwide range of non-speech vocalizations (NSVs), such as laughter and sighs. We\nalso introduce two new evaluation metrics for assessing lip synchronization and\nNSV generation. Experimental results show that KeyFace outperforms\nstate-of-the-art methods in generating natural, coherent facial animations over\nextended durations, successfully encompassing NSVs and continuous emotions.",
      "tldr_zh": "该研究提出 KeyFace，一种新型的两阶段扩散-based 框架，用于生成长序列的音频驱动面部动画，通过关键帧插值解决现有方法在错误积累和身份漂移方面的缺陷，同时保持运动的自然性。在第一阶段，框架基于音频输入和身份帧在低帧率下生成关键帧，以捕捉基本面部表情和动作；在第二阶段，插值模型填充关键帧间的间隙，确保平滑过渡和时间连贯性。此外，KeyFace 整合连续情感表示和处理非语音发声 (NSVs) 如笑声和叹息，并引入两个新评估指标评估唇同步和 NSV 生成。实验结果表明，KeyFace 在生成自然、连贯的面部动画上超越最先进方法，尤其在长序列和情感处理上。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.01715v2",
      "published_date": "2025-03-03 16:31:55 UTC",
      "updated_date": "2025-03-19 12:10:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:13:32.214157"
    },
    {
      "arxiv_id": "2503.01714v1",
      "title": "Word Form Matters: LLMs' Semantic Reconstruction under Typoglycemia",
      "title_zh": "翻译失败",
      "authors": [
        "Chenxi Wang",
        "Tianle Gu",
        "Zhongyu Wei",
        "Lang Gao",
        "Zirui Song",
        "Xiuying Chen"
      ],
      "abstract": "Human readers can efficiently comprehend scrambled words, a phenomenon known\nas Typoglycemia, primarily by relying on word form; if word form alone is\ninsufficient, they further utilize contextual cues for interpretation. While\nadvanced large language models (LLMs) exhibit similar abilities, the underlying\nmechanisms remain unclear. To investigate this, we conduct controlled\nexperiments to analyze the roles of word form and contextual information in\nsemantic reconstruction and examine LLM attention patterns. Specifically, we\nfirst propose SemRecScore, a reliable metric to quantify the degree of semantic\nreconstruction, and validate its effectiveness. Using this metric, we study how\nword form and contextual information influence LLMs' semantic reconstruction\nability, identifying word form as the core factor in this process. Furthermore,\nwe analyze how LLMs utilize word form and find that they rely on specialized\nattention heads to extract and process word form information, with this\nmechanism remaining stable across varying levels of word scrambling. This\ndistinction between LLMs' fixed attention patterns primarily focused on word\nform and human readers' adaptive strategy in balancing word form and contextual\ninformation provides insights into enhancing LLM performance by incorporating\nhuman-like, context-aware mechanisms.",
      "tldr_zh": "本文探讨了大型语言模型（LLMs）在 Typoglycemia（单词乱序）条件下进行语义重建的机制，通过控制实验分析单词形式（word form）和上下文信息的作用。研究者提出 SemRecScore 指标来量化语义重建程度，并验证其有效性，结果显示 word form 是核心因素，LLMs 依赖特定的 attention heads 来提取和处理相关信息，且这种机制在不同乱序水平下保持稳定。与人类读者相比，LLMs 的 attention 模式更固定于 word form，而非灵活平衡上下文，这为通过融入人类般的上下文感知机制来提升 LLMs 性能提供了重要启示。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages, 10 figures, submitted to ACL Rolling Review, February 2025\n  cycle, see https://github.com/Aurora-cx/TypoLLM",
      "pdf_url": "http://arxiv.org/pdf/2503.01714v1",
      "published_date": "2025-03-03 16:31:45 UTC",
      "updated_date": "2025-03-03 16:31:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:13:43.767026"
    },
    {
      "arxiv_id": "2503.01713v2",
      "title": "SAGE: A Framework of Precise Retrieval for RAG",
      "title_zh": "翻译失败",
      "authors": [
        "Jintao Zhang",
        "Guoliang Li",
        "Jinyang Su"
      ],
      "abstract": "Retrieval-augmented generation (RAG) has demonstrated significant proficiency\nin conducting question-answering (QA) tasks within a specified corpus.\nNonetheless, numerous failure instances of RAG in QA still exist. These\nfailures are not solely attributable to the limitations of Large Language\nModels (LLMs); instead, they predominantly arise from the retrieval of\ninaccurate information for LLMs due to two limitations: (1) Current RAG methods\nsegment the corpus without considering semantics, making it difficult to find\nrelevant context due to impaired correlation between questions and the\nsegments. (2) There is a trade-off between missing essential context with fewer\ncontext retrieved and getting irrelevant context with more context retrieved.\n  In this paper, we introduce a RAG framework (SAGE), to overcome these\nlimitations. First, to address the segmentation issue without considering\nsemantics, we propose to train a semantic segmentation model. This model is\ntrained to segment the corpus into semantically complete chunks. Second, to\nensure that only the most relevant chunks are retrieved while the irrelevant\nones are ignored, we design a chunk selection algorithm to dynamically select\nchunks based on the decreasing speed of the relevance score, leading to a more\nrelevant selection. Third, to further ensure the precision of the retrieved\nchunks, we propose letting LLMs assess whether retrieved chunks are excessive\nor lacking and then adjust the amount of context accordingly. Experiments show\nthat SAGE outperforms baselines by 61.25% in the quality of QA on average.\nMoreover, by avoiding retrieving noisy context, SAGE lowers the cost of the\ntokens consumed in LLM inference and achieves a 49.41% enhancement in cost\nefficiency on average. Additionally, our work offers valuable insights for\nboosting RAG.",
      "tldr_zh": "该论文提出了SAGE框架，以提升RAG（Retrieval-augmented generation）在问答（QA）任务中的精确检索性能，针对现有方法中语义无关的语料分割和上下文检索权衡问题。SAGE包括三个关键创新：训练一个语义分割模型将语料分成语义完整的块、设计一个基于相关性分数下降速度的动态块选择算法以优先选取最相关内容，以及让LLMs（Large Language Models）评估和调整检索上下文的量以避免过度或不足。实验结果显示，SAGE平均提高了61.25%的QA质量，同时通过减少无关上下文的检索，提升了49.41%的成本效率，并为优化RAG提供了宝贵见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01713v2",
      "published_date": "2025-03-03 16:25:58 UTC",
      "updated_date": "2025-04-30 09:32:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:13:54.692457"
    },
    {
      "arxiv_id": "2503.01710v1",
      "title": "Spark-TTS: An Efficient LLM-Based Text-to-Speech Model with Single-Stream Decoupled Speech Tokens",
      "title_zh": "翻译失败",
      "authors": [
        "Xinsheng Wang",
        "Mingqi Jiang",
        "Ziyang Ma",
        "Ziyu Zhang",
        "Songxiang Liu",
        "Linqin Li",
        "Zheng Liang",
        "Qixi Zheng",
        "Rui Wang",
        "Xiaoqin Feng",
        "Weizhen Bian",
        "Zhen Ye",
        "Sitong Cheng",
        "Ruibin Yuan",
        "Zhixian Zhao",
        "Xinfa Zhu",
        "Jiahao Pan",
        "Liumeng Xue",
        "Pengcheng Zhu",
        "Yunlin Chen",
        "Zhifei Li",
        "Xie Chen",
        "Lei Xie",
        "Yike Guo",
        "Wei Xue"
      ],
      "abstract": "Recent advancements in large language models (LLMs) have driven significant\nprogress in zero-shot text-to-speech (TTS) synthesis. However, existing\nfoundation models rely on multi-stage processing or complex architectures for\npredicting multiple codebooks, limiting efficiency and integration flexibility.\nTo overcome these challenges, we introduce Spark-TTS, a novel system powered by\nBiCodec, a single-stream speech codec that decomposes speech into two\ncomplementary token types: low-bitrate semantic tokens for linguistic content\nand fixed-length global tokens for speaker attributes. This disentangled\nrepresentation, combined with the Qwen2.5 LLM and a chain-of-thought (CoT)\ngeneration approach, enables both coarse-grained control (e.g., gender,\nspeaking style) and fine-grained adjustments (e.g., precise pitch values,\nspeaking rate). To facilitate research in controllable TTS, we introduce\nVoxBox, a meticulously curated 100,000-hour dataset with comprehensive\nattribute annotations. Extensive experiments demonstrate that Spark-TTS not\nonly achieves state-of-the-art zero-shot voice cloning but also generates\nhighly customizable voices that surpass the limitations of reference-based\nsynthesis. Source code, pre-trained models, and audio samples are available at\nhttps://github.com/SparkAudio/Spark-TTS.",
      "tldr_zh": "该研究引入了 Spark-TTS，一种基于大型语言模型 (LLM) 的高效文本到语音 (TTS) 系统，利用 BiCodec 的单流解耦语音 tokens，将语音分解为语义 tokens（处理语言内容）和全局 tokens（处理说话者属性），并结合 Qwen2.5 LLM 和 chain-of-thought (CoT) 生成方法，实现粗粒度（如性别、风格）和细粒度（如音高、语速）的语音控制。论文还发布了 VoxBox 数据集，一个包含10万小时标注的音频数据集，以支持可控 TTS 研究。实验结果显示，Spark-TTS 在零样本语音克隆任务中达到 state-of-the-art 性能，并超越了基于参考的合成方法，提供高度可定制的语音输出。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Submitted to ACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.01710v1",
      "published_date": "2025-03-03 16:23:10 UTC",
      "updated_date": "2025-03-03 16:23:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:14:08.740867"
    },
    {
      "arxiv_id": "2503.01702v1",
      "title": "Relating Piecewise Linear Kolmogorov Arnold Networks to ReLU Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Nandi Schoots",
        "Mattia Jacopo Villani",
        "Niels uit de Bos"
      ],
      "abstract": "Kolmogorov-Arnold Networks are a new family of neural network architectures\nwhich holds promise for overcoming the curse of dimensionality and has\ninterpretability benefits (arXiv:2404.19756). In this paper, we explore the\nconnection between Kolmogorov Arnold Networks (KANs) with piecewise linear\n(univariate real) functions and ReLU networks. We provide completely explicit\nconstructions to convert a piecewise linear KAN into a ReLU network and vice\nversa.",
      "tldr_zh": "该论文探讨了分段线性Kolmogorov-Arnold Networks (KANs)与ReLU networks之间的关系，旨在利用KANs克服维数灾难(curse of dimensionality)并提升网络的可解释性。研究提供了完全明确的构造方法，将分段线性KANs转换为ReLU networks，反之亦然。总体而言，此工作为理解和整合这两种神经网络架构提供了理论基础，有助于改进神经网络的设计和应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "accepted to AISTATS 2025; 12 pages including bibliography and\n  appendix",
      "pdf_url": "http://arxiv.org/pdf/2503.01702v1",
      "published_date": "2025-03-03 16:15:56 UTC",
      "updated_date": "2025-03-03 16:15:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:14:18.947095"
    },
    {
      "arxiv_id": "2503.01700v1",
      "title": "Code-as-Symbolic-Planner: Foundation Model-Based Robot Planning via Symbolic Code Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Yongchao Chen",
        "Yilun Hao",
        "Yang Zhang",
        "Chuchu Fan"
      ],
      "abstract": "Recent works have shown great potentials of Large Language Models (LLMs) in\nrobot task and motion planning (TAMP). Current LLM approaches generate text- or\ncode-based reasoning chains with sub-goals and action plans. However, they do\nnot fully leverage LLMs' symbolic computing and code generation capabilities.\nMany robot TAMP tasks involve complex optimization under multiple constraints,\nwhere pure textual reasoning is insufficient. While augmenting LLMs with\npredefined solvers and planners improves performance, it lacks generalization\nacross tasks. Given LLMs' growing coding proficiency, we enhance their TAMP\ncapabilities by steering them to generate code as symbolic planners for\noptimization and constraint verification. Unlike prior work that uses code to\ninterface with robot action modules, we steer LLMs to generate code as solvers,\nplanners, and checkers for TAMP tasks requiring symbolic computing, while still\nleveraging textual reasoning to incorporate common sense. With a multi-round\nguidance and answer evolution framework, the proposed Code-as-Symbolic-Planner\nimproves success rates by average 24.1\\% over best baseline methods across\nseven typical TAMP tasks and three popular LLMs. Code-as-Symbolic-Planner shows\nstrong effectiveness and generalizability across discrete and continuous\nenvironments, 2D/3D simulations and real-world settings, as well as single- and\nmulti-robot tasks with diverse requirements. See our project website\nhttps://yongchao98.github.io/Code-Symbol-Planner/ for prompts, videos, and\ncode.",
      "tldr_zh": "本文提出“Code-as-Symbolic-Planner”方法，利用Large Language Models (LLMs)生成符号代码作为求解器、规划器和检查器，以提升机器人任务和运动规划 (TAMP) 的性能。该方法通过多轮指导和答案演化框架，结合文本推理和符号计算，处理复杂优化与约束问题，同时增强泛化能力。实验结果显示，在七个典型TAMP任务和三种流行LLMs上，该方法平均成功率比最佳基线提高24.1%，并适用于离散/连续环境、2D/3D模拟、真实世界以及单/多机器人任务。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.RO",
      "comment": "7 pages, 7 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.01700v1",
      "published_date": "2025-03-03 16:13:41 UTC",
      "updated_date": "2025-03-03 16:13:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:14:34.096983"
    },
    {
      "arxiv_id": "2503.01676v2",
      "title": "Perceptual Motor Learning with Active Inference Framework for Robust Lateral Control",
      "title_zh": "翻译失败",
      "authors": [
        "Elahe Delavari",
        "John Moore",
        "Junho Hong",
        "Jaerock Kwon"
      ],
      "abstract": "This paper presents a novel Perceptual Motor Learning (PML) framework\nintegrated with Active Inference (AIF) to enhance lateral control in Highly\nAutomated Vehicles (HAVs). PML, inspired by human motor learning, emphasizes\nthe seamless integration of perception and action, enabling efficient\ndecision-making in dynamic environments. Traditional autonomous driving\napproaches--including modular pipelines, imitation learning, and reinforcement\nlearning--struggle with adaptability, generalization, and computational\nefficiency. In contrast, PML with AIF leverages a generative model to minimize\nprediction error (\"surprise\") and actively shape vehicle control based on\nlearned perceptual-motor representations. Our approach unifies deep learning\nwith active inference principles, allowing HAVs to perform lane-keeping\nmaneuvers with minimal data and without extensive retraining across different\nenvironments. Extensive experiments in the CARLA simulator demonstrate that PML\nwith AIF enhances adaptability without increasing computational overhead while\nachieving performance comparable to conventional methods. These findings\nhighlight the potential of PML-driven active inference as a robust alternative\nfor real-world autonomous driving applications.",
      "tldr_zh": "这篇论文提出了一种整合 Perceptual Motor Learning (PML) 与 Active Inference (AIF) 的新框架，用于提升 Highly Automated Vehicles (HAVs) 的横向控制。PML 受人类运动学习启发，通过生成模型最小化预测错误（surprise），实现感知和行动的无缝整合，从而提高决策效率和适应性。与传统方法如模块化管道、模仿学习或强化学习相比，该框架允许 HAVs 在不同环境中以最少数据进行车道保持操作，而无需大量重新训练。在 CARLA 模拟器中的实验显示，该方法显著提升了适应性且不增加计算开销，性能与传统方法相当，为真实世界自动驾驶应用提供了稳健的替代方案。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.RO",
      "comment": "This work has been submitted to IROS 2025 and is currently under\n  review. Supersedes arXiv:2407.07684",
      "pdf_url": "http://arxiv.org/pdf/2503.01676v2",
      "published_date": "2025-03-03 15:49:18 UTC",
      "updated_date": "2025-03-05 01:27:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:14:44.235107"
    },
    {
      "arxiv_id": "2503.01670v1",
      "title": "Evaluating LLMs' Assessment of Mixed-Context Hallucination Through the Lens of Summarization",
      "title_zh": "翻译失败",
      "authors": [
        "Siya Qi",
        "Rui Cao",
        "Yulan He",
        "Zheng Yuan"
      ],
      "abstract": "With the rapid development of large language models (LLMs), LLM-as-a-judge\nhas emerged as a widely adopted approach for text quality evaluation, including\nhallucination evaluation. While previous studies have focused exclusively on\nsingle-context evaluation (e.g., discourse faithfulness or world factuality),\nreal-world hallucinations typically involve mixed contexts, which remains\ninadequately evaluated. In this study, we use summarization as a representative\ntask to comprehensively evaluate LLMs' capability in detecting mixed-context\nhallucinations, specifically distinguishing between factual and non-factual\nhallucinations. Through extensive experiments across direct generation and\nretrieval-based models of varying scales, our main observations are: (1) LLMs'\nintrinsic knowledge introduces inherent biases in hallucination evaluation; (2)\nThese biases particularly impact the detection of factual hallucinations,\nyielding a significant performance bottleneck; (3) The fundamental challenge\nlies in effective knowledge utilization, balancing between LLMs' intrinsic\nknowledge and external context for accurate mixed-context hallucination\nevaluation.",
      "tldr_zh": "这篇论文通过总结任务(summarization)评估大型语言模型(LLMs)检测混合上下文幻觉(hallucination)的能力，特别是区分事实幻觉(factual hallucinations)和非事实幻觉(non-factual hallucinations)。研究进行广泛实验，涉及不同规模的直接生成和基于检索的模型，发现LLMs的内在知识(intrinsic knowledge)会引入固有偏差(inherent biases)，从而显著影响事实幻觉的检测并导致性能瓶颈。最终，论文强调有效利用知识、平衡内在知识和外部上下文是实现准确混合上下文幻觉评估的根本挑战。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 5 figures for main body",
      "pdf_url": "http://arxiv.org/pdf/2503.01670v1",
      "published_date": "2025-03-03 15:42:57 UTC",
      "updated_date": "2025-03-03 15:42:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:14:55.642207"
    },
    {
      "arxiv_id": "2503.01669v2",
      "title": "An Efficient Continual Learning Framework for Multivariate Time Series Prediction Tasks with Application to Vehicle State Estimation",
      "title_zh": "一种高效的持续学习框架，用于多变量时间序列预测任务，并应用于车辆状态估计",
      "authors": [
        "Arvin Hosseinzadeh",
        "Ladan Khoshnevisan",
        "Mohammad Pirani",
        "Shojaeddin Chenouri",
        "Amir Khajepour"
      ],
      "abstract": "In continual time series analysis using neural networks, catastrophic\nforgetting (CF) of previously learned models when training on new data domains\nhas always been a significant challenge. This problem is especially challenging\nin vehicle estimation and control, where new information is sequentially\nintroduced to the model. Unfortunately, existing work on continual learning has\nnot sufficiently addressed the adverse effects of catastrophic forgetting in\ntime series analysis, particularly in multivariate output environments. In this\npaper, we present EM-ReSeleCT (Efficient Multivariate Representative Selection\nfor Continual Learning in Time Series Tasks), an enhanced approach designed to\nhandle continual learning in multivariate environments. Our approach\nstrategically selects representative subsets from old and historical data and\nincorporates memory-based continual learning techniques with an improved\noptimization algorithm to adapt the pre-trained model on new information while\npreserving previously acquired information. Additionally, we develop a\nsequence-to-sequence transformer model (autoregressive model) specifically\ndesigned for vehicle state estimation. Moreover, we propose an uncertainty\nquantification framework using conformal prediction to assess the sensitivity\nof the memory size and to showcase the robustness of the proposed method.\nExperimental results from tests on an electric Equinox vehicle highlight the\nsuperiority of our method in continually learning new information while\nretaining prior knowledge, outperforming state-of-the-art continual learning\nmethods. Furthermore, EM-ReSeleCT significantly reduces training time, a\ncritical advantage in continual learning applications.",
      "tldr_zh": "该论文针对时间序列预测中的catastrophic forgetting问题，提出了一种高效的持续学习框架EM-ReSeleCT，专门处理多变量环境下的车辆状态估计任务。该框架通过从历史数据中选择代表性子集，并结合memory-based continual learning技术和改进的优化算法，实现模型在新信息上适应的同时保留先前知识。此外，论文开发了序列到序列的Transformer模型（autoregressive model）用于车辆状态估计，并引入conformal prediction的不确定性量化框架来评估方法鲁棒性。实验结果显示，EM-ReSeleCT在电动Equinox车辆测试中优于现有持续学习方法，并显著减少训练时间。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01669v2",
      "published_date": "2025-03-03 15:42:06 UTC",
      "updated_date": "2025-04-04 21:40:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:15:08.475732"
    },
    {
      "arxiv_id": "2503.01658v1",
      "title": "CoPL: Collaborative Preference Learning for Personalizing LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Youngbin Choi",
        "Seunghyuk Cho",
        "Minjong Lee",
        "MoonJeong Park",
        "Yesong Ko",
        "Jungseul Ok",
        "Dongwoo Kim"
      ],
      "abstract": "Personalizing large language models (LLMs) is important for aligning outputs\nwith diverse user preferences, yet existing methods struggle with flexibility\nand generalization. We propose CoPL (Collaborative Preference Learning), a\ngraph-based collaborative filtering framework that models user-response\nrelationships to enhance preference estimation, particularly in sparse\nannotation settings. By integrating a mixture of LoRA experts, CoPL efficiently\nfine-tunes LLMs while dynamically balancing shared and user-specific\npreferences. Additionally, an optimization-free adaptation strategy enables\ngeneralization to unseen users without fine-tuning. Experiments on\nUltraFeedback-P demonstrate that CoPL outperforms existing personalized reward\nmodels, effectively capturing both common and controversial preferences, making\nit a scalable solution for personalized LLM alignment.",
      "tldr_zh": "该研究针对个性化大型语言模型（LLMs）的灵活性和泛化问题，提出了一种基于图形的协作过滤框架CoPL（Collaborative Preference Learning）。CoPL通过建模用户-响应关系来提升偏好估计，尤其适用于稀疏标注场景，并整合了LoRA experts的混合来高效微调LLMs，同时动态平衡共享和用户特定偏好。实验在UltraFeedback-P数据集上显示，CoPL优于现有个性化奖励模型，能够有效捕获常见和争议性偏好，提供一种可扩展的LLMs对齐解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "13pages, 4 figures, 6tables",
      "pdf_url": "http://arxiv.org/pdf/2503.01658v1",
      "published_date": "2025-03-03 15:32:02 UTC",
      "updated_date": "2025-03-03 15:32:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:15:19.021488"
    },
    {
      "arxiv_id": "2503.01655v1",
      "title": "Enhancing Object Detection Accuracy in Underwater Sonar Images through Deep Learning-based Denoising",
      "title_zh": "通过基于深度学习的去噪技术增强水下声呐图像中目标检测的准确性",
      "authors": [
        "Ziyu Wang",
        "Tao Xue",
        "Yanbin Wang",
        "Jingyuan Li",
        "Haibin Zhang",
        "Zhiqiang Xu",
        "Gaofei Xu"
      ],
      "abstract": "Sonar image object detection is crucial for underwater robotics and other\napplications. However, various types of noise in sonar images can affect the\naccuracy of object detection. Denoising, as a critical preprocessing step, aims\nto remove noise while retaining useful information to improve detection\naccuracy. Although deep learning-based denoising algorithms perform well on\noptical images, their application to underwater sonar images remains\nunderexplored. This paper systematically evaluates the effectiveness of several\ndeep learning-based denoising algorithms, originally designed for optical\nimages, in the context of underwater sonar image object detection. We apply\nnine trained denoising models to images from five open-source sonar datasets,\neach processing different types of noise. We then test the denoised images\nusing four object detection algorithms. The results show that different\ndenoising models have varying effects on detection performance. By combining\nthe strengths of multiple denoising models, the detection results can be\noptimized, thus more effectively suppressing noise. Additionally, we adopt a\nmulti-frame denoising technique, using different outputs generated by multiple\ndenoising models as multiple frames of the same scene for further processing to\nenhance detection accuracy. This method, originally designed for optical\nimages, leverages complementary noise-reduction effects. Experimental results\nshow that denoised sonar images improve the performance of object detection\nalgorithms compared to the original sonar images.",
      "tldr_zh": "这篇论文探讨了通过深度学习-based denoising 算法提升水下声呐图像物体检测准确性的方法，针对声呐图像中的噪声问题进行系统评估。研究者应用了九个训练好的去噪模型到五个开源声呐数据集上，并结合多个模型的优势以及 multi-frame denoising technique 来优化检测性能。实验结果显示，不同去噪模型对物体检测算法（如四种测试算法）的影响各异，但整体去噪处理显著提高了检测准确率，相比原始图像更有效地抑制噪声。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01655v1",
      "published_date": "2025-03-03 15:30:39 UTC",
      "updated_date": "2025-03-03 15:30:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:15:31.828552"
    },
    {
      "arxiv_id": "2503.01653v2",
      "title": "Distilled Prompt Learning for Incomplete Multimodal Survival Prediction",
      "title_zh": "蒸馏提示学习用于不完整多模态生存预测",
      "authors": [
        "Yingxue Xu",
        "Fengtao Zhou",
        "Chenyu Zhao",
        "Yihui Wang",
        "Can Yang",
        "Hao Chen"
      ],
      "abstract": "The integration of multimodal data including pathology images and gene\nprofiles is widely applied in precise survival prediction. Despite recent\nadvances in multimodal survival models, collecting complete modalities for\nmultimodal fusion still poses a significant challenge, hindering their\napplication in clinical settings. Current approaches tackling incomplete\nmodalities often fall short, as they typically compensate for only a limited\npart of the knowledge of missing modalities. To address this issue, we propose\na Distilled Prompt Learning framework (DisPro) to utilize the strong robustness\nof Large Language Models (LLMs) to missing modalities, which employs two-stage\nprompting for compensation of comprehensive information for missing modalities.\nIn the first stage, Unimodal Prompting (UniPro) distills the knowledge\ndistribution of each modality, preparing for supplementing modality-specific\nknowledge of the missing modality in the subsequent stage. In the second stage,\nMultimodal Prompting (MultiPro) leverages available modalities as prompts for\nLLMs to infer the missing modality, which provides modality-common information.\nSimultaneously, the unimodal knowledge acquired in the first stage is injected\ninto multimodal inference to compensate for the modality-specific knowledge of\nthe missing modality. Extensive experiments covering various missing scenarios\ndemonstrated the superiority of the proposed method. The code is available at\nhttps://github.com/Innse/DisPro.",
      "tldr_zh": "这篇论文针对多模态生存预测（如病理图像和基因配置文件）中数据不完整的问题，提出了一种 Distilled Prompt Learning 框架 (DisPro)，利用 Large Language Models (LLMs) 的鲁棒性通过两阶段提示学习来补偿缺失模态的全面信息。DisPro 的第一阶段，Unimodal Prompting (UniPro)，提炼每个模态的知识分布；第二阶段，Multimodal Prompting (MultiPro)，则使用可用模态作为提示推断缺失模态，并注入特定知识以增强预测准确性。实验结果在各种缺失场景下显示，该方法显著优于现有方法，并提供了开源代码。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by CVPR2025",
      "pdf_url": "http://arxiv.org/pdf/2503.01653v2",
      "published_date": "2025-03-03 15:28:26 UTC",
      "updated_date": "2025-03-24 09:20:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:15:43.817566"
    },
    {
      "arxiv_id": "2503.01646v1",
      "title": "OpenGS-SLAM: Open-Set Dense Semantic SLAM with 3D Gaussian Splatting for Object-Level Scene Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Dianyi Yang",
        "Yu Gao",
        "Xihan Wang",
        "Yufeng Yue",
        "Yi Yang",
        "Mengyin Fu"
      ],
      "abstract": "Recent advancements in 3D Gaussian Splatting have significantly improved the\nefficiency and quality of dense semantic SLAM. However, previous methods are\ngenerally constrained by limited-category pre-trained classifiers and implicit\nsemantic representation, which hinder their performance in open-set scenarios\nand restrict 3D object-level scene understanding. To address these issues, we\npropose OpenGS-SLAM, an innovative framework that utilizes 3D Gaussian\nrepresentation to perform dense semantic SLAM in open-set environments. Our\nsystem integrates explicit semantic labels derived from 2D foundational models\ninto the 3D Gaussian framework, facilitating robust 3D object-level scene\nunderstanding. We introduce Gaussian Voting Splatting to enable fast 2D label\nmap rendering and scene updating. Additionally, we propose a Confidence-based\n2D Label Consensus method to ensure consistent labeling across multiple views.\nFurthermore, we employ a Segmentation Counter Pruning strategy to improve the\naccuracy of semantic scene representation. Extensive experiments on both\nsynthetic and real-world datasets demonstrate the effectiveness of our method\nin scene understanding, tracking, and mapping, achieving 10 times faster\nsemantic rendering and 2 times lower storage costs compared to existing\nmethods. Project page: https://young-bit.github.io/opengs-github.github.io/.",
      "tldr_zh": "该论文提出 OpenGS-SLAM，一种基于 3D Gaussian Splatting 的开放集密集语义 SLAM 框架，旨在解决现有方法在开放集场景下受限于预训练分类器和隐式语义表示的问题，从而实现更准确的 3D 对象级场景理解。核心创新包括整合 2D 基础模型的显式语义标签、引入 Gaussian Voting Splatting 用于快速标签地图渲染和场景更新、Confidence-based 2D Label Consensus 方法确保多视图标签一致性，以及 Segmentation Counter Pruning 策略提升语义表示准确性。实验在合成和真实数据集上验证了该框架在场景理解、跟踪和映射方面的有效性，比现有方法快 10 倍语义渲染并降低 2 倍存储成本，为开放集环境下的 SLAM 应用提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01646v1",
      "published_date": "2025-03-03 15:23:21 UTC",
      "updated_date": "2025-03-03 15:23:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:15:56.941567"
    },
    {
      "arxiv_id": "2503.01642v1",
      "title": "Graph-Augmented Reasoning: Evolving Step-by-Step Knowledge Graph Retrieval for LLM Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Wenjie Wu",
        "Yongcheng Jing",
        "Yingjie Wang",
        "Wenbin Hu",
        "Dacheng Tao"
      ],
      "abstract": "Recent large language model (LLM) reasoning, despite its success, suffers\nfrom limited domain knowledge, susceptibility to hallucinations, and\nconstrained reasoning depth, particularly in small-scale models deployed in\nresource-constrained environments. This paper presents the first investigation\ninto integrating step-wise knowledge graph retrieval with step-wise reasoning\nto address these challenges, introducing a novel paradigm termed as\ngraph-augmented reasoning. Our goal is to enable frozen, small-scale LLMs to\nretrieve and process relevant mathematical knowledge in a step-wise manner,\nenhancing their problem-solving abilities without additional training. To this\nend, we propose KG-RAR, a framework centered on process-oriented knowledge\ngraph construction, a hierarchical retrieval strategy, and a universal\npost-retrieval processing and reward model (PRP-RM) that refines retrieved\ninformation and evaluates each reasoning step. Experiments on the Math500 and\nGSM8K benchmarks across six models demonstrate that KG-RAR yields encouraging\nresults, achieving a 20.73\\% relative improvement with Llama-3B on Math500.",
      "tldr_zh": "这项研究探讨了大型语言模型(LLM)推理面临的挑战，如有限的领域知识、易产生幻觉和推理深度不足，并引入了 graph-augmented reasoning 范式，通过步进式知识图谱检索与推理相结合来解决这些问题。作者提出了 KG-RAR 框架，包括过程导向的知识图谱构建、层次化检索策略以及后检索处理和奖励模型(PRP-RM)，使冻结的小规模 LLM 能够在不额外训练的情况下逐步检索和处理相关数学知识，提升问题解决能力。在 Math500 和 GSM8K 基准测试中，KG-RAR 在 Llama-3B 模型上实现了 20.73% 的相对性能提升，展示了其在资源受限环境中的潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01642v1",
      "published_date": "2025-03-03 15:20:41 UTC",
      "updated_date": "2025-03-03 15:20:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:16:10.444147"
    },
    {
      "arxiv_id": "2503.01632v1",
      "title": "CoT-VLM4Tar: Chain-of-Thought Guided Vision-Language Models for Traffic Anomaly Resolution",
      "title_zh": "翻译失败",
      "authors": [
        "Tianchi Ren",
        "Haibo Hu",
        "Jiacheng Zuo",
        "Xinhong Chen",
        "Jianping Wang",
        "Chun Jason Xue",
        "Jen-Ming Wu",
        "Nan Guan"
      ],
      "abstract": "With the acceleration of urbanization, modern urban traffic systems are\nbecoming increasingly complex, leading to frequent traffic anomalies. These\nanomalies encompass not only common traffic jams but also more challenging\nissues such as phantom traffic jams, intersection deadlocks, and accident\nliability analysis, which severely impact traffic flow, vehicular safety, and\noverall transportation efficiency. Currently, existing solutions primarily rely\non manual intervention by traffic police or artificial intelligence-based\ndetection systems. However, these methods often suffer from response delays and\ninconsistent management due to inadequate resources, while AI detection\nsystems, despite enhancing efficiency to some extent, still struggle to handle\ncomplex traffic anomalies in a real-time and precise manner. To address these\nissues, we propose CoT-VLM4Tar: (Chain of Thought Visual-Language Model for\nTraffic Anomaly Resolution), this innovative approach introduces a new\nchain-of-thought to guide the VLM in analyzing, reasoning, and generating\nsolutions for traffic anomalies with greater reasonable and effective solution,\nand to evaluate the performance and effectiveness of our method, we developed a\nclosed-loop testing framework based on the CARLA simulator. Furthermore, to\nensure seamless integration of the solutions generated by the VLM with the\nCARLA simulator, we implement an itegration module that converts these\nsolutions into executable commands. Our results demonstrate the effectiveness\nof VLM in the resolution of real-time traffic anomalies, providing a\nproof-of-concept for its integration into autonomous traffic management\nsystems.",
      "tldr_zh": "该论文提出 CoT-VLM4Tar，一种基于 Chain-of-Thought 指导的视觉语言模型，用于解决城市交通异常，如交通拥堵、幻影拥堵和交叉路口死锁等问题，以提升实时响应和精确性。方法通过链式思维引导 VLM 进行分析、推理和生成合理解决方案，并开发了一个基于 CARLA 模拟器的闭环测试框架来评估其性能。结果显示，该框架能有效将 VLM 生成的解决方案转化为可执行命令，为自主交通管理系统提供可靠的证明概念。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01632v1",
      "published_date": "2025-03-03 15:07:25 UTC",
      "updated_date": "2025-03-03 15:07:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:16:21.944353"
    },
    {
      "arxiv_id": "2503.01942v1",
      "title": "Mathematical Foundation of Interpretable Equivariant Surrogate Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jacopo Joy Colombini",
        "Filippo Bonchi",
        "Francesco Giannini",
        "Fosca Giannotti",
        "Roberto Pellungrini",
        "Patrizio Frosini"
      ],
      "abstract": "This paper introduces a rigorous mathematical framework for neural network\nexplainability, and more broadly for the explainability of equivariant\noperators called Group Equivariant Operators (GEOs) based on Group Equivariant\nNon-Expansive Operators (GENEOs) transformations. The central concept involves\nquantifying the distance between GEOs by measuring the non-commutativity of\nspecific diagrams. Additionally, the paper proposes a definition of\ninterpretability of GEOs according to a complexity measure that can be defined\naccording to each user preferences. Moreover, we explore the formal properties\nof this framework and show how it can be applied in classical machine learning\nscenarios, like image classification with convolutional neural networks.",
      "tldr_zh": "这篇论文建立了神经网络可解释性的严格数学框架，专注于 Group Equivariant Operators (GEOs)，基于 Group Equivariant Non-Expansive Operators (GENEOs) 变换。核心概念是通过测量特定图的非交换性来量化 GEOs 之间的距离，并根据用户偏好定义复杂性度量以评估其可解释性。该框架的形式属性被深入探讨，并展示了其在经典机器学习场景如图像分类中的实际应用，例如卷积神经网络。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01942v1",
      "published_date": "2025-03-03 15:06:43 UTC",
      "updated_date": "2025-03-03 15:06:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:16:32.527897"
    },
    {
      "arxiv_id": "2503.01630v1",
      "title": "Machine Learners Should Acknowledge the Legal Implications of Large Language Models as Personal Data",
      "title_zh": "机器学习从业者应承认大型语言模型作为个人数据的法律影响",
      "authors": [
        "Henrik Nolte",
        "Michèle Finck",
        "Kristof Meding"
      ],
      "abstract": "Does GPT know you? The answer depends on your level of public recognition;\nhowever, if your information was available on a website, the answer is probably\nyes. All Large Language Models (LLMs) memorize training data to some extent. If\nan LLM training corpus includes personal data, it also memorizes personal data.\nDeveloping an LLM typically involves processing personal data, which falls\ndirectly within the scope of data protection laws. If a person is identified or\nidentifiable, the implications are far-reaching: the AI system is subject to EU\nGeneral Data Protection Regulation requirements even after the training phase\nis concluded. To back our arguments: (1.) We reiterate that LLMs output\ntraining data at inference time, be it verbatim or in generalized form. (2.) We\nshow that some LLMs can thus be considered personal data on their own. This\ntriggers a cascade of data protection implications such as data subject rights,\nincluding rights to access, rectification, or erasure. These rights extend to\nthe information embedded with-in the AI model. (3.) This paper argues that\nmachine learning researchers must acknowledge the legal implications of LLMs as\npersonal data throughout the full ML development lifecycle, from data\ncollection and curation to model provision on, e.g., GitHub or Hugging Face.\n(4.) We propose different ways for the ML research community to deal with these\nlegal implications. Our paper serves as a starting point for improving the\nalignment between data protection law and the technical capabilities of LLMs.\nOur findings underscore the need for more interaction between the legal domain\nand the ML community.",
      "tldr_zh": "这篇论文强调，大型语言模型 (LLMs) 在训练过程中会记忆个人数据，从而可能被视为个人数据，受欧盟通用数据保护条例 (GDPR) 等法规管辖。作者论证了 LLMs 输出训练数据的风险，包括触发数据主体权利，如访问、修正或删除信息。论文呼吁机器学习研究者在整个开发生命周期（从数据收集到模型发布）中承认这些法律含义，并提出社区应对策略，以促进法律领域与 ML 社区的互动。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01630v1",
      "published_date": "2025-03-03 15:05:48 UTC",
      "updated_date": "2025-03-03 15:05:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:16:43.753046"
    },
    {
      "arxiv_id": "2503.01619v1",
      "title": "Advancing vision-language models in front-end development via data synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Tong Ge",
        "Yashu Liu",
        "Jieping Ye",
        "Tianyi Li",
        "Chao Wang"
      ],
      "abstract": "Modern front-end (FE) development, especially when leveraging the unique\nfeatures of frameworks like React and Vue, presents distinctive challenges.\nThese include managing modular architectures, ensuring synchronization between\ndata and visual outputs for declarative rendering, and adapting reusable\ncomponents to various scenarios. Such complexities make it particularly\ndifficult for state-of-the-art large vision-language models (VLMs) to generate\naccurate and functional code directly from design images. To address these\nchallenges, we propose a reflective agentic workflow that synthesizes\nhigh-quality image-text data to capture the diverse characteristics of FE\ndevelopment. This workflow automates the extraction of\nself-contained\\footnote{A \\textbf{self-contained} code snippet is one that\nencapsulates all necessary logic, styling, and dependencies, ensuring it\nfunctions independently without requiring external imports or context.} code\nsnippets from real-world projects, renders the corresponding visual outputs,\nand generates detailed descriptions that link design elements to functional\ncode. To further expand the scope and utility of the synthesis, we introduce\nthree data synthesis strategies: Evolution-based synthesis, which enables\nscalable and diverse dataset expansion; Waterfall-Model-based synthesis, which\ngenerates logically coherent code derived from system requirements; and\nAdditive Development synthesis, which iteratively increases the complexity of\nhuman-authored components. We build a large vision-language model, Flame,\ntrained on the synthesized datasets and demonstrate its effectiveness in\ngenerating React code via the $\\text{pass}@k$ metric. Our results suggest that\na code VLM trained to interpret images before code generation may achieve\nbetter performance.",
      "tldr_zh": "本研究针对视觉语言模型（VLMs）在前端开发（如 React 和 Vue）中的挑战，包括模块化架构和数据-视觉同步等问题，提出了一种 reflective agentic workflow 来合成高质量图像-文本数据。该工作流自动化提取 self-contained 代码片段、渲染视觉输出，并生成链接设计元素与功能代码的详细描述，同时引入三种数据合成策略：Evolution-based synthesis 用于扩展数据集多样性、Waterfall-Model-based synthesis 生成逻辑连贯代码，以及 Additive Development synthesis 通过迭代增加组件复杂度。研究构建了 Flame 模型，并在合成的数据集上训练，结果显示该模型在 React 代码生成上通过 pass@k 指标显著提升性能，证明先解释图像再生成代码的策略可改善整体表现。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01619v1",
      "published_date": "2025-03-03 14:54:01 UTC",
      "updated_date": "2025-03-03 14:54:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:16:56.864198"
    },
    {
      "arxiv_id": "2503.01606v1",
      "title": "Beyond Prompting: An Efficient Embedding Framework for Open-Domain Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Zhanghao Hu",
        "Hanqi Yan",
        "Qingling Zhu",
        "Zhenyi Shen",
        "Yulan He",
        "Lin Gui"
      ],
      "abstract": "Large language models have recently pushed open domain question answering\n(ODQA) to new frontiers. However, prevailing retriever-reader pipelines often\ndepend on multiple rounds of prompt level instructions, leading to high\ncomputational overhead, instability, and suboptimal retrieval coverage. In this\npaper, we propose EmbQA, an embedding-level framework that alleviates these\nshortcomings by enhancing both the retriever and the reader. Specifically, we\nrefine query representations via lightweight linear layers under an\nunsupervised contrastive learning objective, thereby reordering retrieved\npassages to highlight those most likely to contain correct answers.\nAdditionally, we introduce an exploratory embedding that broadens the model's\nlatent semantic space to diversify candidate generation and employs an\nentropy-based selection mechanism to choose the most confident answer\nautomatically. Extensive experiments across three open-source LLMs, three\nretrieval methods, and four ODQA benchmarks demonstrate that EmbQA\nsubstantially outperforms recent baselines in both accuracy and efficiency.",
      "tldr_zh": "该论文提出 EmbQA 框架，以超越传统的提示依赖方法，提升开放域问答(ODQA)的效率和准确性。框架通过无监督对比学习优化查询表示，使用轻量级线性层重新排序检索通道，并引入探索性嵌入来扩展语义空间，同时采用基于熵的选择机制自动选择最自信的答案。实验结果显示，EmbQA 在三个开源 LLM、三个检索方法和四个 ODQA 基准上，显著优于现有基线，在准确性和效率方面均有大幅提升。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01606v1",
      "published_date": "2025-03-03 14:41:35 UTC",
      "updated_date": "2025-03-03 14:41:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:17:07.836018"
    },
    {
      "arxiv_id": "2503.01603v1",
      "title": "Triple-Stream Deep Feature Selection with Metaheuristic Optimization and Machine Learning for Multi-Stage Hypertensive Retinopathy Diagnosis",
      "title_zh": "翻译失败",
      "authors": [
        "Suleyman Burcin Suyun",
        "Mustafa Yurdakul",
        "Sakir Tasdemir",
        "Serkan Bilic"
      ],
      "abstract": "Hypertensive retinopathy (HR) is a severe eye disease that may cause\npermanent vision loss if not diagnosed early. Traditional diagnostic methods\nare time-consuming and subjective, highlighting the need for an automated,\nreliable system. Existing studies often use a single Deep Learning (DL) model,\nstruggling to distinguish HR stages. This study introduces a three-stage\napproach to enhance HR diagnosis accuracy. Initially, 14 CNN models were\ntested, identifying DenseNet169, MobileNet, and ResNet152 as the most\neffective. DenseNet169 achieved 87.73% accuracy, 87.75% precision, 87.73%\nrecall, 87.67% F1-score, and 0.8359 Cohen's Kappa. MobileNet followed with\n86.40% accuracy, 86.60% precision, 86.40% recall, 86.31% F1-score, and 0.8180\nCohen's Kappa. ResNet152 ranked third with 85.87% accuracy, 86.01% precision,\n85.87% recall, 85.83% F1-score, and 0.8188 Cohen's Kappa. In the second stage,\ndeep features from these models were fused and classified using Machine\nLearning (ML) algorithms (SVM, RF, XGBoost). SVM (sigmoid kernel) performed\nbest with 92.00% accuracy, 91.93% precision, 92.00% recall, 91.91% F1-score,\nand 0.8930 Cohen's Kappa. The third stage applied meta-heuristic optimization\n(GA, ABC, PSO, HHO) for feature selection. HHO yielded 94.66% accuracy,\nprecision, and recall, 94.64% F1-score, and 0.9286 Cohen's Kappa. The proposed\napproach surpassed single CNN models and previous studies in HR diagnosis\naccuracy and generalization.",
      "tldr_zh": "本研究针对高血压性视网膜病变(Hypertensive Retinopathy, HR)诊断的挑战，提出了一种三阶段方法，以提高多阶段诊断的准确性和可靠性。首阶段测试14个CNN模型，选出DenseNet169、MobileNet和ResNet152作为最佳模型，其中DenseNet169达到87.73%的准确率；次阶段融合这些模型的深度特征，并使用机器学习算法如SVM进行分类，SVM（sigmoid kernel）实现92.00%的准确率；第三阶段应用元启发式优化算法（如HHO）进行特征选择，HHO进一步提升至94.66%的准确率。该方法在HR诊断的准确率、精确度和泛化能力上超过了单一CNN模型和现有研究，为自动化诊断提供了更可靠的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01603v1",
      "published_date": "2025-03-03 14:39:46 UTC",
      "updated_date": "2025-03-03 14:39:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:17:19.880613"
    },
    {
      "arxiv_id": "2503.01595v1",
      "title": "STAR: Stability-Inducing Weight Perturbation for Continual Learning",
      "title_zh": "STAR：用于持续学习的稳定性诱导权重扰动",
      "authors": [
        "Masih Eskandar",
        "Tooba Imtiaz",
        "Davin Hill",
        "Zifeng Wang",
        "Jennifer Dy"
      ],
      "abstract": "Humans can naturally learn new and varying tasks in a sequential manner.\nContinual learning is a class of learning algorithms that updates its learned\nmodel as it sees new data (on potentially new tasks) in a sequence. A key\nchallenge in continual learning is that as the model is updated to learn new\ntasks, it becomes susceptible to catastrophic forgetting, where knowledge of\npreviously learned tasks is lost. A popular approach to mitigate forgetting\nduring continual learning is to maintain a small buffer of previously-seen\nsamples and to replay them during training. However, this approach is limited\nby the small buffer size, and while forgetting is reduced, it is still present.\nIn this paper, we propose a novel loss function, STAR, that exploits the\nworst-case parameter perturbation that reduces the KL-divergence of model\npredictions with that of its local parameter neighborhood to promote stability\nand alleviate forgetting. STAR can be combined with almost any existing\nrehearsal-based method as a plug-and-play component. We empirically show that\nSTAR consistently improves the performance of existing methods by up to 15%\nacross varying baselines and achieves superior or competitive accuracy to that\nof state-of-the-art methods aimed at improving rehearsal-based continual\nlearning.",
      "tldr_zh": "该论文针对持续学习(Continual Learning)中的灾难性遗忘问题，提出了一种新颖的损失函数STAR，通过引入稳定性诱导的权重扰动来最小化模型预测的KL-divergence，从而增强模型在处理新任务时的稳定性。STAR作为即插即用组件，可与几乎任何基于重放的现有方法结合，显著缓解遗忘现象。实验结果显示，STAR将基线方法的性能提升多达15%，并在多种场景下达到优于或相当于最先进方法的准确率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01595v1",
      "published_date": "2025-03-03 14:32:03 UTC",
      "updated_date": "2025-03-03 14:32:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:17:30.603197"
    },
    {
      "arxiv_id": "2503.01592v1",
      "title": "An Efficient Approach to Detecting Lung Nodules Using Swin Transformer",
      "title_zh": "使用 Swin Transformer 检测肺结节的一种高效方法",
      "authors": [
        "Saeed Shakuri",
        "Alireza Rezvanian"
      ],
      "abstract": "Lung cancer has the highest rate of cancer-caused deaths, and early-stage\ndiagnosis could increase the survival rate. Lung nodules are common indicators\nof lung cancer, making their detection crucial. Various lung nodule detection\nmodels exist, but many lack efficiency. Hence, we propose a more efficient\napproach by leveraging 2D CT slices, reducing computational load and complexity\nin training and inference. We employ the tiny version of Swin Transformer to\nbenefit from Vision Transformers (ViT) while maintaining low computational\ncost. A Feature Pyramid Network is added to enhance detection, particularly for\nsmall nodules. Additionally, Transfer Learning is used to accelerate training.\nOur experimental results show that the proposed model outperforms\nstate-of-the-art methods, achieving higher mAP and mAR for small nodules by\n1.3% and 1.6%, respectively. Overall, our model achieves the highest mAP of\n94.7% and mAR of 94.9%.",
      "tldr_zh": "该研究针对肺癌早期诊断的需求，提出了一种高效的肺结节检测方法，使用 2D CT 切片来降低计算负载和复杂性。方法采用 Swin Transformer 的 tiny 版本结合 Vision Transformers (ViT) 的优势，并添加 Feature Pyramid Network 以提升小结节的检测性能，同时利用 Transfer Learning 加速训练过程。实验结果显示，该模型在小结节检测上比最先进方法提高 1.3% mAP 和 1.6% mAR，整体达到 94.7% mAP 和 94.9% mAR，展示了其在肺结节检测中的优越效率和准确性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "19th Iranian Conference on Intelligent Systems (ICIS), IEEE, 2024",
      "pdf_url": "http://arxiv.org/pdf/2503.01592v1",
      "published_date": "2025-03-03 14:30:14 UTC",
      "updated_date": "2025-03-03 14:30:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:17:43.265270"
    },
    {
      "arxiv_id": "2503.01586v1",
      "title": "EliteKV: Scalable KV Cache Compression via RoPE Frequency Selection and Joint Low-Rank Projection",
      "title_zh": "翻译失败",
      "authors": [
        "Yuhao Zhou",
        "Sirui Song",
        "Boyang Liu",
        "Zhiheng Xi",
        "Senjie Jin",
        "Xiaoran Fan",
        "Zhihao Zhang",
        "Wei Li",
        "Xuanjing Huang"
      ],
      "abstract": "Rotary Position Embedding (RoPE) enables each attention head to capture\nmulti-frequency information along the sequence dimension and is widely applied\nin foundation models. However, the nonlinearity introduced by RoPE complicates\noptimization of the key state in the Key-Value (KV) cache for RoPE-based\nattention. Existing KV cache compression methods typically store key state\nbefore rotation and apply the transformation during decoding, introducing\nadditional computational overhead. This paper introduces EliteKV, a flexible\nmodification framework for RoPE-based models supporting variable KV cache\ncompression ratios. EliteKV first identifies the intrinsic frequency preference\nof each head using RoPElite, selectively restoring linearity to certain\ndimensions of key within attention computation. Building on this, joint\nlow-rank compression of key and value enables partial cache sharing.\nExperimental results show that with minimal uptraining on only $0.6\\%$ of the\noriginal training data, RoPE-based models achieve a $75\\%$ reduction in KV\ncache size while preserving performance within a negligible margin.\nFurthermore, EliteKV consistently performs well across models of different\nscales within the same family.",
      "tldr_zh": "该论文提出EliteKV，一种可扩展的KV缓存压缩框架，针对Rotary Position Embedding (RoPE)引入的非线性问题，通过RoPElite识别每个注意力头的频率偏好，并选择性地恢复key维度的线性，同时采用joint low-rank projection对key和value进行联合压缩，实现部分缓存共享。相比现有方法，EliteKV仅需在0.6%的原始训练数据上微调，就能将KV缓存大小减少75%，而性能损失微乎其微。实验结果显示，该框架在不同规模的RoPE-based模型中均表现出色，提供了一种高效的模型优化策略。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.01586v1",
      "published_date": "2025-03-03 14:26:51 UTC",
      "updated_date": "2025-03-03 14:26:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:17:54.506074"
    },
    {
      "arxiv_id": "2503.01584v1",
      "title": "SENSEI: Semantic Exploration Guided by Foundation Models to Learn Versatile World Models",
      "title_zh": "SENSEI：基础模型指导下的语义探索，以学习多功能世界模型",
      "authors": [
        "Cansu Sancaktar",
        "Christian Gumbsch",
        "Andrii Zadaianchuk",
        "Pavel Kolev",
        "Georg Martius"
      ],
      "abstract": "Exploration is a cornerstone of reinforcement learning (RL). Intrinsic\nmotivation attempts to decouple exploration from external, task-based rewards.\nHowever, established approaches to intrinsic motivation that follow general\nprinciples such as information gain, often only uncover low-level interactions.\nIn contrast, children's play suggests that they engage in meaningful high-level\nbehavior by imitating or interacting with their caregivers. Recent work has\nfocused on using foundation models to inject these semantic biases into\nexploration. However, these methods often rely on unrealistic assumptions, such\nas language-embedded environments or access to high-level actions. We propose\nSEmaNtically Sensible ExploratIon (SENSEI), a framework to equip model-based RL\nagents with an intrinsic motivation for semantically meaningful behavior.\nSENSEI distills a reward signal of interestingness from Vision Language Model\n(VLM) annotations, enabling an agent to predict these rewards through a world\nmodel. Using model-based RL, SENSEI trains an exploration policy that jointly\nmaximizes semantic rewards and uncertainty. We show that in both robotic and\nvideo game-like simulations SENSEI discovers a variety of meaningful behaviors\nfrom image observations and low-level actions. SENSEI provides a general tool\nfor learning from foundation model feedback, a crucial research direction, as\nVLMs become more powerful.",
      "tldr_zh": "该论文提出 SENSEI 框架，用于指导强化学习 (RL) 代理通过基础模型进行语义探索，以学习多功能的 World Models。SENSEI 从 Vision Language Model (VLM) 注释中提炼“interestingness”的内在奖励信号，并利用世界模型预测这些奖励，同时结合基于模型的 RL 训练探索策略，以最大化语义奖励和不确定性。实验结果显示，在机器人和视频游戏模拟环境中，SENSEI 能从图像观察和低级动作中发现各种有意义的行为，提供了一个通用的工具来从基础模型反馈中学习，随着 VLM 的发展，这为 RL 探索注入了新的语义偏差。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Preprint, under review. Project webpage at\n  https://sites.google.com/view/sensei-paper",
      "pdf_url": "http://arxiv.org/pdf/2503.01584v1",
      "published_date": "2025-03-03 14:26:15 UTC",
      "updated_date": "2025-03-03 14:26:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:18:07.543168"
    },
    {
      "arxiv_id": "2503.01580v1",
      "title": "A Selective Learning Method for Temporal Graph Continual Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Hanmo Liu",
        "Shimin Di",
        "Haoyang Li",
        "Xun Jian",
        "Yue Wang",
        "Lei Chen"
      ],
      "abstract": "Node classification is a key task in temporal graph learning (TGL). Real-life\ntemporal graphs often introduce new node classes over time, but existing TGL\nmethods assume a fixed set of classes. This assumption brings limitations, as\nupdating models with full data is costly, while focusing only on new classes\nresults in forgetting old ones. Graph continual learning (GCL) methods mitigate\nforgetting using old-class subsets but fail to account for their evolution. We\ndefine this novel problem as temporal graph continual learning (TGCL), which\nfocuses on efficiently maintaining up-to-date knowledge of old classes. To\ntackle TGCL, we propose a selective learning framework that substitutes the\nold-class data with its subsets, Learning Towards the Future (LTF). We derive\nan upper bound on the error caused by such replacement and transform it into\nobjectives for selecting and learning subsets that minimize classification\nerror while preserving the distribution of the full old-class data. Experiments\non three real-world datasets validate the effectiveness of LTF on TGCL.",
      "tldr_zh": "本研究针对时间图学习 (TGL) 中的节点分类问题，定义了新的时间图持续学习 (TGCL) 挑战，即处理现实图谱中动态引入的新类，同时避免遗忘旧类和降低更新成本。作者提出了一种选择性学习框架 Learning Towards the Future (LTF)，通过用旧类子集替换全数据，并推导错误上界转化为最小化分类错误的优化目标，以保持数据分布。实验在三个真实数据集上验证了 LTF 的有效性，展示了其在高效维护旧类知识方面的显著优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01580v1",
      "published_date": "2025-03-03 14:22:20 UTC",
      "updated_date": "2025-03-03 14:22:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:18:19.292139"
    },
    {
      "arxiv_id": "2503.01941v1",
      "title": "Task Scheduling & Forgetting in Multi-Task Reinforcement Learning",
      "title_zh": "多任务强化学习中的任务调度与遗忘",
      "authors": [
        "Marc Speckmann",
        "Theresa Eimer"
      ],
      "abstract": "Reinforcement learning (RL) agents can forget tasks they have previously been\ntrained on. There is a rich body of work on such forgetting effects in humans.\nTherefore we look for commonalities in the forgetting behavior of humans and RL\nagents across tasks and test the viability of forgetting prevention measures\nfrom learning theory in RL. We find that in many cases, RL agents exhibit\nforgetting curves similar to those of humans. Methods like Leitner or SuperMemo\nhave been shown to be effective at counteracting human forgetting, but we\ndemonstrate they do not transfer as well to RL. We identify a likely cause:\nasymmetrical learning and retention patterns between tasks that cannot be\ncaptured by retention-based or performance-based curriculum strategies.",
      "tldr_zh": "该研究探讨了多任务强化学习（RL）中任务遗忘问题，通过比较人类和 RL 代理的遗忘行为，发现二者在许多情况下表现出相似的遗忘曲线。研究者测试了从学习理论中借用的预防措施，如 Leitner 和 SuperMemo 方法，这些方法虽能有效对抗人类遗忘，但对 RL 代理的适用性较差。究其原因，是任务间的学习和保留模式存在不对称，无法被基于保留或性能的课程策略充分捕捉。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Presented at RLDM 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.01941v1",
      "published_date": "2025-03-03 14:12:52 UTC",
      "updated_date": "2025-03-03 14:12:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:18:30.571062"
    },
    {
      "arxiv_id": "2503.01557v1",
      "title": "MoCFL: Mobile Cluster Federated Learning Framework for Highly Dynamic Network",
      "title_zh": "MoCFL：移动集群联邦学习框架，用于高度动态网络",
      "authors": [
        "Kai Fang",
        "Jiangtao Deng",
        "Chengzu Dong",
        "Usman Naseem",
        "Tongcun Liu",
        "Hailin Feng",
        "Wei Wang"
      ],
      "abstract": "Frequent fluctuations of client nodes in highly dynamic mobile clusters can\nlead to significant changes in feature space distribution and data drift,\nposing substantial challenges to the robustness of existing federated learning\n(FL) strategies. To address these issues, we proposed a mobile cluster\nfederated learning framework (MoCFL). MoCFL enhances feature aggregation by\nintroducing an affinity matrix that quantifies the similarity between local\nfeature extractors from different clients, addressing dynamic data distribution\nchanges caused by frequent client churn and topology changes. Additionally,\nMoCFL integrates historical and current feature information when training the\nglobal classifier, effectively mitigating the catastrophic forgetting problem\nfrequently encountered in mobile scenarios. This synergistic combination\nensures that MoCFL maintains high performance and stability in dynamically\nchanging mobile environments. Experimental results on the UNSW-NB15 dataset\nshow that MoCFL excels in dynamic environments, demonstrating superior\nrobustness and accuracy while maintaining reasonable training costs.",
      "tldr_zh": "该研究提出MoCFL框架，用于解决高度动态移动网络中，客户端节点频繁波动导致的特征空间分布变化和数据漂移问题，从而提升联邦学习(FL)的鲁棒性。MoCFL通过引入亲和矩阵(affinity matrix)来量化不同客户端本地特征提取器的相似性，增强特征聚合，并处理客户端频繁变动和拓扑变化带来的动态数据分布挑战；同时，在训练全局分类器时整合历史和当前特征信息，以缓解灾难性遗忘(catastrophic forgetting)问题。实验结果显示，在UNSW-NB15数据集上，MoCFL在动态环境中表现出优越的鲁棒性和准确性，同时保持合理的训练成本。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 7 figures, conference",
      "pdf_url": "http://arxiv.org/pdf/2503.01557v1",
      "published_date": "2025-03-03 13:59:47 UTC",
      "updated_date": "2025-03-03 13:59:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:18:43.112242"
    },
    {
      "arxiv_id": "2503.01556v1",
      "title": "Effective High-order Graph Representation Learning for Credit Card Fraud Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Yao Zou",
        "Dawei Cheng"
      ],
      "abstract": "Credit card fraud imposes significant costs on both cardholders and issuing\nbanks. Fraudsters often disguise their crimes, such as using legitimate\ntransactions through several benign users to bypass anti-fraud detection.\nExisting graph neural network (GNN) models struggle with learning features of\ncamouflaged, indirect multi-hop transactions due to their inherent\nover-smoothing issues in deep multi-layer aggregation, presenting a major\nchallenge in detecting disguised relationships. Therefore, in this paper, we\npropose a novel High-order Graph Representation Learning model (HOGRL) to avoid\nincorporating excessive noise during the multi-layer aggregation process. In\nparticular, HOGRL learns different orders of \\emph{pure} representations\ndirectly from high-order transaction graphs. We realize this goal by\neffectively constructing high-order transaction graphs first and then learning\nthe \\emph{pure} representations of each order so that the model could identify\nfraudsters' multi-hop indirect transactions via multi-layer \\emph{pure} feature\nlearning. In addition, we introduce a mixture-of-expert attention mechanism to\nautomatically determine the importance of different orders for jointly\noptimizing fraud detection performance. We conduct extensive experiments in\nboth the open source and real-world datasets, the result demonstrates the\nsignificant improvements of our proposed HOGRL compared with state-of-the-art\nfraud detection baselines. HOGRL's superior performance also proves its\neffectiveness in addressing high-order fraud camouflage criminals.",
      "tldr_zh": "本文针对信用卡欺诈检测中的伪装问题（如欺诈者通过多跳间接交易规避检测），提出了一种新型 High-order Graph Representation Learning 模型（HOGRL），以解决现有 GNN 模型在多层聚合过程中因过度平滑而引入噪声的局限性。HOGRL 通过构建高阶交易图并学习每个阶的纯表示（pure representations），并结合 mixture-of-expert attention mechanism 自动评估不同阶的重要性，从而实现对欺诈者多跳交易的精确识别。在开源和真实数据集上的实验显示，HOGRL 相较于最先进基线模型取得了显著性能提升，证明了其在处理高阶欺诈伪装方面的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T07, 91B06",
        "I.2.6; H.2.8"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 5 figures, accepted at IJCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2503.01556v1",
      "published_date": "2025-03-03 13:59:46 UTC",
      "updated_date": "2025-03-03 13:59:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:18:57.276141"
    },
    {
      "arxiv_id": "2503.01544v1",
      "title": "Compositional Reasoning with Transformers, RNNs, and Chain of Thought",
      "title_zh": "翻译失败",
      "authors": [
        "Gilad Yehudai",
        "Noah Amsel",
        "Joan Bruna"
      ],
      "abstract": "We study and compare the expressive power of transformers, RNNs, and\ntransformers with chain of thought tokens on a simple and natural class of\nproblems we term Compositional Reasoning Questions (CRQ). This family captures\nproblems like evaluating Boolean formulas and multi-step word problems.\nAssuming standard hardness assumptions from circuit complexity and\ncommunication complexity, we prove that none of these three architectures is\ncapable of solving CRQs unless some hyperparameter (depth, embedding dimension,\nand number of chain of thought tokens, respectively) grows with the size of the\ninput. We also provide a construction for each architecture that solves CRQs.\nFor transformers, our construction uses depth that is logarithmic in the\nproblem size. For RNNs, logarithmic embedding dimension is necessary and\nsufficient, so long as the inputs are provided in a certain order. (Otherwise,\na linear dimension is necessary). For transformers with chain of thought, our\nconstruction uses $n$ CoT tokens. These results show that, while CRQs are\ninherently hard, there are several different ways for language models to\novercome this hardness. Even for a single class of problems, each architecture\nhas strengths and weaknesses, and none is strictly better than the others.",
      "tldr_zh": "本研究比较了 Transformers、RNNs 和带有 Chain of Thought (CoT) 标记的 Transformers 在 Compositional Reasoning Questions (CRQs) 上的表现能力，其中 CRQs 包括评估布尔公式和多步文字问题等。基于电路复杂性和通信复杂性的标准硬度假设，论文证明这三种架构在不增加超参数（如深度、嵌入维度或 CoT 标记数量）的情况下无法解决 CRQs。论文还提供了构造方法：Transformers 需要对数深度的层，RNNs 在特定输入顺序下需要对数嵌入维度（否则需线性维度），而 CoT-Transformers 需要 n 个 CoT 标记。这些结果表明，虽然 CRQs 固有困难，但每种架构都有独特优势，没有一个严格优于其他。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01544v1",
      "published_date": "2025-03-03 13:52:45 UTC",
      "updated_date": "2025-03-03 13:52:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:19:08.865360"
    },
    {
      "arxiv_id": "2503.01542v1",
      "title": "Revisiting Large Language Model Pruning using Neuron Semantic Attribution",
      "title_zh": "翻译失败",
      "authors": [
        "Yizhuo Ding",
        "Xinwei Sun",
        "Yanwei Fu",
        "Guosheng Hu"
      ],
      "abstract": "Model pruning technique is vital for accelerating large language models by\nreducing their size and computational requirements. However, the\ngeneralizability of existing pruning methods across diverse datasets and tasks\nremains unclear. Thus, we conduct extensive evaluations on 24 datasets and 4\ntasks using popular pruning methods. Based on these evaluations, we find and\nthen investigate that calibration set greatly affect the performance of pruning\nmethods. In addition, we surprisingly find a significant performance drop of\nexisting pruning methods in sentiment classification tasks. To understand the\nlink between performance drop and pruned neurons, we propose Neuron Semantic\nAttribution, which learns to associate each neuron with specific semantics.\nThis method first makes the unpruned neurons of LLMs explainable.",
      "tldr_zh": "这篇论文重新审视了大型语言模型(Large Language Models, LLMs)的修剪技术，通过在24个数据集和4个任务上评估流行方法，发现校准集(calibration set)对修剪性能有重大影响，并在情感分类任务中观察到显著性能下降。为了解释性能下降与修剪神经元之间的联系，作者提出了Neuron Semantic Attribution方法，该方法通过学习将每个神经元与特定语义关联，使LLMs的未修剪神经元变得可解释。这一贡献有助于提升LLM修剪的泛化性和可解释性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01542v1",
      "published_date": "2025-03-03 13:52:17 UTC",
      "updated_date": "2025-03-03 13:52:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:19:21.067748"
    },
    {
      "arxiv_id": "2503.01539v1",
      "title": "Pragmatic Inference Chain (PIC) Improving LLMs' Reasoning of Authentic Implicit Toxic Language",
      "title_zh": "翻译失败",
      "authors": [
        "Xi Chen",
        "Shuo Wang"
      ],
      "abstract": "The rapid development of large language models (LLMs) gives rise to ethical\nconcerns about their performance, while opening new avenues for developing\ntoxic language detection techniques. However, LLMs' unethical output and their\ncapability of detecting toxicity have primarily been tested on language data\nthat do not demand complex meaning inference, such as the biased associations\nof 'he' with programmer and 'she' with household. Nowadays toxic language\nadopts a much more creative range of implicit forms, thanks to advanced\ncensorship. In this study, we collect authentic toxic interactions that evade\nonline censorship and that are verified by human annotators as inference\nintensive. To evaluate and improve LLMs' reasoning of the authentic implicit\ntoxic language, we propose a new prompting method, Pragmatic Inference Chain\n(PIC), drawn on interdisciplinary findings from cognitive science and\nlinguistics. The PIC prompting significantly improves the success rate of\nGPT-4o, Llama-3.1-70B-Instruct, and DeepSeek-v2.5 in identifying implicit toxic\nlanguage, compared to both direct prompting and Chain-of-Thought. In addition,\nit also facilitates the models to produce more explicit and coherent reasoning\nprocesses, hence can potentially be generalized to other inference-intensive\ntasks, e.g., understanding humour and metaphors.",
      "tldr_zh": "这篇论文针对大型语言模型(LLMs)在检测真实隐性毒性语言时的推理不足，提出了一种新提示方法：Pragmatic Inference Chain (PIC)，该方法借鉴认知科学和语言学的跨学科发现。PIC通过引导模型进行更结构化的推理，帮助GPT-4o、Llama-3.1-70B-Instruct和DeepSeek-v2.5等模型显著提高识别隐性毒性语言的成功率，并生成更明确和连贯的推理过程。实验结果显示，PIC优于直接提示和Chain-of-Thought方法，并具有潜力扩展到其他推理密集型任务，如理解幽默和比喻。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages, 4 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.01539v1",
      "published_date": "2025-03-03 13:51:05 UTC",
      "updated_date": "2025-03-03 13:51:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:19:33.160970"
    },
    {
      "arxiv_id": "2503.01536v1",
      "title": "Entailment vs. Verification for Partial-assignment Satisfiability and Enumeration",
      "title_zh": "翻译失败",
      "authors": [
        "Roberto Sebastiani"
      ],
      "abstract": "Many procedures for SAT-related problems, in particular for those requiring\nthe complete enumeration of satisfying truth assignments, rely their efficiency\nand effectiveness on the detection of (possibly small) partial assignments\nsatisfying an input formula. Surprisingly, there seems to be no unique\nuniversally-agreed definition of formula satisfaction by a partial assignment\nin the literature. In this paper we analyze in deep the issue of satisfaction\nby partial assignments, raising a flag about some ambiguities and subtleties of\nthis concept, and investigating their practical consequences. We identify two\nalternative notions that are implicitly used in the literature, namely\nverification and entailment, which coincide if applied to CNF formulas but\ndiffer and present complementary properties if applied to non-CNF or to\nexistentially-quantified formulas. We show that, although the former is easier\nto check and as such is implicitly used by most current search procedures, the\nlatter has better theoretical properties, and can improve the efficiency and\neffectiveness of enumeration procedures.",
      "tldr_zh": "本文分析了部分赋值在 SAT 相关问题中的满足定义问题，指出文献中存在模糊性和实际后果，并比较了两种隐含概念：verification（验证）和 entailment（蕴涵）。这些概念在 CNF formulas 上一致，但在非-CNF 或存在量词公式上不同，具有互补性质。研究发现，虽然 verification 更容易检查且被大多数搜索程序使用，但 entailment 具有更好的理论属性，能显著提高枚举程序的效率和有效性。",
      "categories": [
        "cs.LO",
        "cs.AI"
      ],
      "primary_category": "cs.LO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01536v1",
      "published_date": "2025-03-03 13:49:11 UTC",
      "updated_date": "2025-03-03 13:49:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:19:44.171989"
    },
    {
      "arxiv_id": "2503.01508v2",
      "title": "Enabling AI Scientists to Recognize Innovation: A Domain-Agnostic Algorithm for Assessing Novelty",
      "title_zh": "翻译失败",
      "authors": [
        "Yao Wang",
        "Mingxuan Cui",
        "Arthur Jiang"
      ],
      "abstract": "In the pursuit of Artificial General Intelligence (AGI), automating the\ngeneration and evaluation of novel research ideas is a key challenge in\nAI-driven scientific discovery. This paper presents Relative Neighbor Density\n(RND), a domain-agnostic algorithm for novelty assessment in research ideas\nthat overcomes the limitations of existing approaches by comparing an idea's\nlocal density with its adjacent neighbors' densities. We first developed a\nscalable methodology to create test set without expert labeling, addressing a\nfundamental challenge in novelty assessment. Using these test sets, we\ndemonstrate that our RND algorithm achieves state-of-the-art (SOTA) performance\nin computer science (AUROC=0.820) and biomedical research (AUROC=0.765)\ndomains. Most significantly, while SOTA models like Sonnet-3.7 and existing\nmetrics show domain-specific performance degradation, RND maintains consistent\naccuracies across domains by its domain-invariant property, outperforming all\nbenchmarks by a substantial margin (0.795 v.s. 0.597) on cross-domain\nevaluation. These results validate RND as a generalizable solution for\nautomated novelty assessment in scientific research.",
      "tldr_zh": "本论文提出了一种领域无关算法Relative Neighbor Density (RND)，用于评估研究想法的新颖性，以推进AI驱动的科学发现。该算法通过比较一个想法的局部密度与其相邻邻居的密度，克服了现有方法的局限，并开发了一种可扩展的测试集创建方法，无需专家标注。在实验中，RND在计算机科学领域（AUROC=0.820）和生物医学领域（AUROC=0.765）实现了SOTA性能，并在跨领域评估中显著优于基准模型（如Sonnet-3.7），证明其领域不变性（0.795 vs. 0.597）。这项工作为自动化新颖性评估提供了通用解决方案，支持AI在科学创新中的应用。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01508v2",
      "published_date": "2025-03-03 13:22:39 UTC",
      "updated_date": "2025-03-10 06:21:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:19:57.161064"
    },
    {
      "arxiv_id": "2503.01507v2",
      "title": "Compare different SG-Schemes based on large least square problems",
      "title_zh": "翻译失败",
      "authors": [
        "Ramkrishna Acharya"
      ],
      "abstract": "This study reviews popular stochastic gradient-based schemes based on large\nleast-square problems. These schemes, often called optimizers in machine\nlearning, play a crucial role in finding better model parameters. Hence, this\nstudy focuses on viewing such optimizers with different hyper-parameters and\nanalyzing them based on least square problems. Codes that produced results in\nthis work are available on\nhttps://github.com/q-viper/gradients-based-methods-on-large-least-square.",
      "tldr_zh": "这篇论文审视了基于大型 least square problems 的不同 SG-Schemes（随机梯度优化方案），这些方案在机器学习中作为 optimizers 发挥关键作用，用于优化模型参数。研究重点是通过调整各种 hyper-parameters 对这些优化器进行比较和分析，以评估其性能。代码已在 GitHub 上公开（https://github.com/q-viper/gradients-based-methods-on-large-least-square），便于复现和进一步验证。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01507v2",
      "published_date": "2025-03-03 13:22:37 UTC",
      "updated_date": "2025-03-04 08:47:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:20:07.613815"
    },
    {
      "arxiv_id": "2503.01505v1",
      "title": "Lossy Neural Compression for Geospatial Analytics: A Review",
      "title_zh": "有损神经压缩在地理空间分析中的应用：综述",
      "authors": [
        "Carlos Gomes",
        "Isabelle Wittmann",
        "Damien Robert",
        "Johannes Jakubik",
        "Tim Reichelt",
        "Michele Martone",
        "Stefano Maurogiovanni",
        "Rikard Vinge",
        "Jonas Hurst",
        "Erik Scheurer",
        "Rocco Sedona",
        "Thomas Brunschwiler",
        "Stefan Kesselheim",
        "Matej Batic",
        "Philip Stier",
        "Jan Dirk Wegner",
        "Gabriele Cavallaro",
        "Edzer Pebesma",
        "Michael Marszalek",
        "Miguel A Belenguer-Plomer",
        "Kennedy Adriko",
        "Paolo Fraccaro",
        "Romeo Kienzler",
        "Rania Briq",
        "Sabrina Benassou",
        "Michele Lazzarini",
        "Conrad M Albrecht"
      ],
      "abstract": "Over the past decades, there has been an explosion in the amount of available\nEarth Observation (EO) data. The unprecedented coverage of the Earth's surface\nand atmosphere by satellite imagery has resulted in large volumes of data that\nmust be transmitted to ground stations, stored in data centers, and distributed\nto end users. Modern Earth System Models (ESMs) face similar challenges,\noperating at high spatial and temporal resolutions, producing petabytes of data\nper simulated day. Data compression has gained relevance over the past decade,\nwith neural compression (NC) emerging from deep learning and information\ntheory, making EO data and ESM outputs ideal candidates due to their abundance\nof unlabeled data. In this review, we outline recent developments in NC applied\nto geospatial data. We introduce the fundamental concepts of NC including\nseminal works in its traditional applications to image and video compression\ndomains with focus on lossy compression. We discuss the unique characteristics\nof EO and ESM data, contrasting them with \"natural images\", and explain the\nadditional challenges and opportunities they present. Moreover, we review\ncurrent applications of NC across various EO modalities and explore the limited\nefforts in ESM compression to date. The advent of self-supervised learning\n(SSL) and foundation models (FM) has advanced methods to efficiently distill\nrepresentations from vast unlabeled data. We connect these developments to NC\nfor EO, highlighting the similarities between the two fields and elaborate on\nthe potential of transferring compressed feature representations for\nmachine--to--machine communication. Based on insights drawn from this review,\nwe devise future directions relevant to applications in EO and ESM.",
      "tldr_zh": "这篇综述论文回顾了神经压缩（Neural Compression, NC）在地理空间分析中的应用，特别是针对地球观测（Earth Observation, EO）数据和地球系统模型（Earth System Models, ESMs）的损失性压缩，以应对数据爆炸问题。论文介绍了NC的基础概念，包括其在图像和视频压缩领域的传统应用，并对比了EO和ESMs数据与自然图像的独特特性，如高分辨率和高数据量带来的挑战和机会。作者回顾了NC在各种EO模式中的当前应用，并探讨了自监督学习（Self-Supervised Learning, SSL）和基础模型（Foundation Models, FM）如何通过有效提炼未标注数据来提升压缩效率。最终，论文基于这些见解，提出了未来在EO和ESMs领域的研究方向，包括机器间通信的潜在应用。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "physics.geo-ph"
      ],
      "primary_category": "eess.SP",
      "comment": "self-consistent review paper",
      "pdf_url": "http://arxiv.org/pdf/2503.01505v1",
      "published_date": "2025-03-03 13:19:43 UTC",
      "updated_date": "2025-03-03 13:19:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:20:20.877985"
    },
    {
      "arxiv_id": "2503.02905v1",
      "title": "Machine Learning Applications to Diffuse Reflectance Spectroscopy in Optical Diagnosis; A Systematic Review",
      "title_zh": "翻译失败",
      "authors": [
        "Nicola Rossberg",
        "Celina L. Li",
        "Simone Innocente",
        "Stefan Andersson-Engels",
        "Katarzyna Komolibus",
        "Barry O'Sullivan",
        "Andrea Visentin"
      ],
      "abstract": "Diffuse Reflectance Spectroscopy has demonstrated a strong aptitude for\nidentifying and differentiating biological tissues. However, the broadband and\nsmooth nature of these signals require algorithmic processing, as they are\noften difficult for the human eye to distinguish. The implementation of machine\nlearning models for this task has demonstrated high levels of diagnostic\naccuracies and led to a wide range of proposed methodologies for applications\nin various illnesses and conditions. In this systematic review, we summarise\nthe state of the art of these applications, highlight current gaps in research\nand identify future directions. This review was conducted in accordance with\nthe PRISMA guidelines. 77 studies were retrieved and in-depth analysis was\nconducted. It is concluded that diffuse reflectance spectroscopy and machine\nlearning have strong potential for tissue differentiation in clinical\napplications, but more rigorous sample stratification in tandem with in-vivo\nvalidation and explainable algorithm development is required going forward.",
      "tldr_zh": "本系统回顾探讨了机器学习在Diffuse Reflectance Spectroscopy用于光学诊断中的应用，分析了77篇研究以总结当前状态。\n结果表明，这些方法在识别和区分生物组织方面表现出高诊断准确率，但信号的宽带平滑特性导致了研究中的领域知识缺口。\n未来方向包括加强样本分层、in-vivo validation和可解释算法的开发，以充分发挥漫反射光谱和机器学习在临床组织区分中的潜力。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "68Txx",
        "J.3"
      ],
      "primary_category": "eess.IV",
      "comment": "52 pages, Preprint, Systematic Review",
      "pdf_url": "http://arxiv.org/pdf/2503.02905v1",
      "published_date": "2025-03-03 13:10:16 UTC",
      "updated_date": "2025-03-03 13:10:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:20:31.918965"
    },
    {
      "arxiv_id": "2503.01496v2",
      "title": "Liger: Linearizing Large Language Models to Gated Recurrent Structures",
      "title_zh": "Liger：将大语言模型线性化为门控循环结构",
      "authors": [
        "Disen Lan",
        "Weigao Sun",
        "Jiaxi Hu",
        "Jusen Du",
        "Yu Cheng"
      ],
      "abstract": "Transformers with linear recurrent modeling offer linear-time training and\nconstant-memory inference. Despite their demonstrated efficiency and\nperformance, pretraining such non-standard architectures from scratch remains\ncostly and risky. The linearization of large language models (LLMs) transforms\npretrained standard models into linear recurrent structures, enabling more\nefficient deployment. However, current linearization methods typically\nintroduce additional feature map modules that require extensive fine-tuning and\noverlook the gating mechanisms used in state-of-the-art linear recurrent\nmodels. To address these issues, this paper presents Liger, short for\nLinearizing LLMs to gated recurrent structures. Liger is a novel approach for\nconverting pretrained LLMs into gated linear recurrent models without adding\nextra parameters. It repurposes the pretrained key matrix weights to construct\ndiverse gating mechanisms, facilitating the formation of various gated\nrecurrent structures while avoiding the need to train additional components\nfrom scratch. Using lightweight fine-tuning with Low-Rank Adaptation (LoRA),\nLiger restores the performance of the linearized gated recurrent models to\nmatch that of the original LLMs. Additionally, we introduce Liger Attention, an\nintra-layer hybrid attention mechanism, which significantly recovers 93\\% of\nthe Transformer-based LLM at 0.02\\% pre-training tokens during the\nlinearization process, achieving competitive results across multiple\nbenchmarks, as validated on models ranging from 1B to 8B parameters. Code is\navailable at https://github.com/OpenSparseLLMs/Linearization.",
      "tldr_zh": "这篇论文提出了 Liger，一种创新方法，将预训练的大型语言模型 (LLMs) 线性化成门控循环结构，以实现线性时间训练和常量内存推理，同时避免添加额外参数。Liger 通过重新利用预训练的 key matrix 权重构建多样化的门控机制，并结合 Low-Rank Adaptation (LoRA) 进行轻量级微调，以恢复线性化模型的性能。实验结果显示，引入的 Liger Attention 机制在线性化过程中恢复了 93% 的 Transformer 性能，仅需 0.02% 的预训练 tokens，并在 1B 到 8B 参数的模型上取得了竞争性的基准表现。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by ICML 2025, 15 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.01496v2",
      "published_date": "2025-03-03 13:08:00 UTC",
      "updated_date": "2025-05-07 07:42:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:20:44.759403"
    },
    {
      "arxiv_id": "2503.01940v1",
      "title": "AskToAct: Enhancing LLMs Tool Use via Self-Correcting Clarification",
      "title_zh": "翻译失败",
      "authors": [
        "Xuan Zhang",
        "Yongliang Shen",
        "Zhe Zheng",
        "Linjuan Wu",
        "Wenqi Zhang",
        "Yuchen Yan",
        "Qiuying Peng",
        "Jun Wang",
        "Weiming Lu"
      ],
      "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in\ntool learning. In real-world scenarios, user queries are often ambiguous and\nincomplete, requiring effective clarification. However, existing interactive\nclarification approaches face two critical limitations: reliance on manually\nconstructed datasets and lack of error correction mechanisms during multi-turn\nclarification. We present AskToAct, which addresses these challenges by\nexploiting the structural mapping between queries and their tool invocation\nsolutions. Our key insight is that tool parameters naturally represent explicit\nuser intents. By systematically removing key parameters from queries while\nretaining them as ground truth, we enable automated construction of\nhigh-quality training data. We further enhance model robustness by fine-tuning\non error-correction augmented data using selective masking mechanism, enabling\ndynamic error detection during clarification interactions. Comprehensive\nexperiments demonstrate that AskToAct significantly outperforms existing\napproaches, achieving above 79% accuracy in recovering critical unspecified\nintents and enhancing clarification efficiency by an average of 48.34% while\nmaintaining high accuracy in tool invocation. Our framework exhibits robust\nperformance across varying complexity levels and successfully generalizes to\nentirely unseen APIs without additional training, achieving performance\ncomparable to GPT-4 with substantially fewer computational resources.",
      "tldr_zh": "该研究提出AskToAct框架，以提升LLMs在工具使用中的自修正澄清能力，解决用户查询模糊不完整的问题。框架利用查询与工具调用解决方案的结构映射，通过系统移除关键参数（保留作为ground truth）自动构建高质量训练数据，并采用错误修正增强数据和选择性掩码机制，实现动态错误检测和多轮交互。实验结果显示，AskToAct在恢复关键未指定意图的准确率超过79%，澄清效率平均提高48.34%，并在工具调用中保持高准确率，同时在不同复杂度和全新API上表现出强泛化能力，与GPT-4相当但资源消耗更低。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01940v1",
      "published_date": "2025-03-03 12:55:49 UTC",
      "updated_date": "2025-03-03 12:55:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:20:57.280319"
    },
    {
      "arxiv_id": "2503.01478v5",
      "title": "SePer: Measure Retrieval Utility Through The Lens Of Semantic Perplexity Reduction",
      "title_zh": "翻译失败",
      "authors": [
        "Lu Dai",
        "Yijie Xu",
        "Jinhui Ye",
        "Hao Liu",
        "Hui Xiong"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated improved generation\nperformance by incorporating externally retrieved knowledge, a process known as\nretrieval-augmented generation (RAG). Despite the potential of this approach,\nexisting studies evaluate RAG effectiveness by 1) assessing retrieval and\ngeneration components jointly, which obscures retrieval's distinct\ncontribution, or 2) examining retrievers using traditional metrics such as\nNDCG, which creates a gap in understanding retrieval's true utility in the\noverall generation process. To address the above limitations, in this work, we\nintroduce an automatic evaluation method that measures retrieval quality\nthrough the lens of information gain within the RAG framework. Specifically, we\npropose Semantic Perplexity (SePer), a metric that captures the LLM's internal\nbelief about the correctness of the retrieved information. We quantify the\nutility of retrieval by the extent to which it reduces semantic perplexity\npost-retrieval. Extensive experiments demonstrate that SePer not only aligns\nclosely with human preferences but also offers a more precise and efficient\nevaluation of retrieval utility across diverse RAG scenarios.",
      "tldr_zh": "该论文提出 SePer 指标，用于评估检索增强生成 (RAG) 中检索质量的真实效用，解决了现有方法（如联合评估或使用 NDCG 指标）的局限性。\nSePer 通过衡量大语言模型 (LLMs) 在检索后语义困惑度的减少，来量化检索带来的信息增益，并捕捉模型对检索信息正确性的内部信念。\n实验结果表明，SePer 与人类偏好高度一致，并在多样化的 RAG 场景中提供更精确和高效的评估。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "ICLR 2025 Spotlight",
      "pdf_url": "http://arxiv.org/pdf/2503.01478v5",
      "published_date": "2025-03-03 12:37:34 UTC",
      "updated_date": "2025-03-20 11:28:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:21:07.893070"
    },
    {
      "arxiv_id": "2503.01475v1",
      "title": "ProRCA: A Causal Python Package for Actionable Root Cause Analysis in Real-world Business Scenarios",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmed Dawoud",
        "Shravan Talupula"
      ],
      "abstract": "Root Cause Analysis (RCA) is becoming ever more critical as modern systems\ngrow in complexity, volume of data, and interdependencies. While traditional\nRCA methods frequently rely on correlation-based or rule-based techniques,\nthese approaches can prove inadequate in highly dynamic, multi-layered\nenvironments. In this paper, we present a pathway-tracing package built on the\nDoWhy causal inference library. Our method integrates conditional anomaly\nscoring, noise-based attribution, and depth-first path exploration to reveal\nmulti-hop causal chains. By systematically tracing entire causal pathways from\nan observed anomaly back to the initial triggers, our approach provides a\ncomprehensive, end-to-end RCA solution. Experimental evaluations with synthetic\nanomaly injections demonstrate the package's ability to accurately isolate\ntriggers and rank root causes by their overall significance.",
      "tldr_zh": "该论文引入了 ProRCA，一个基于 DoWhy 因果推理库的 Python 包，旨在为真实业务场景提供可操作的 Root Cause Analysis (RCA)。ProRCA 整合了 conditional anomaly scoring、noise-based attribution 和 depth-first path exploration 等技术，来追踪多跳因果链，从观察到的异常回溯到初始触发器，从而实现全面的端到端 RCA 解决方案。实验通过合成异常注入评估表明，该包能够准确隔离触发器并按重要性排名根因，提升了在复杂系统中的分析效能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01475v1",
      "published_date": "2025-03-03 12:33:17 UTC",
      "updated_date": "2025-03-03 12:33:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:21:20.921073"
    },
    {
      "arxiv_id": "2503.01470v1",
      "title": "Position: Ensuring mutual privacy is necessary for effective external evaluation of proprietary AI systems",
      "title_zh": "翻译失败",
      "authors": [
        "Ben Bucknall",
        "Robert F. Trager",
        "Michael A. Osborne"
      ],
      "abstract": "The external evaluation of AI systems is increasingly recognised as a crucial\napproach for understanding their potential risks. However, facilitating\nexternal evaluation in practice faces significant challenges in balancing\nevaluators' need for system access with AI developers' privacy and security\nconcerns. Additionally, evaluators have reason to protect their own privacy -\nfor example, in order to maintain the integrity of held-out test sets. We refer\nto the challenge of ensuring both developers' and evaluators' privacy as one of\nproviding mutual privacy. In this position paper, we argue that (i) addressing\nthis mutual privacy challenge is essential for effective external evaluation of\nAI systems, and (ii) current methods for facilitating external evaluation\ninadequately address this challenge, particularly when it comes to preserving\nevaluators' privacy. In making these arguments, we formalise the mutual privacy\nproblem; examine the privacy and access requirements of both model owners and\nevaluators; and explore potential solutions to this challenge, including\nthrough the application of cryptographic and hardware-based approaches.",
      "tldr_zh": "这篇立场论文强调，确保 mutual privacy（开发者和评估者的双向隐私保护）是进行专有 AI 系统有效外部评估的关键挑战，以平衡评估者对系统访问的需求和开发者的安全担忧，同时保护评估者隐私（如保密测试集）。作者论证了当前外部评估方法存在不足，特别是未能充分维护评估者的隐私，并形式化了 mutual privacy 问题。论文分析了模型所有者和评估者的隐私及访问要求，并探讨了潜在解决方案，包括应用加密和硬件技术，以推动更可靠的 AI 评估实践。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01470v1",
      "published_date": "2025-03-03 12:24:59 UTC",
      "updated_date": "2025-03-03 12:24:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:21:32.877799"
    },
    {
      "arxiv_id": "2503.01464v1",
      "title": "Rethinking Data: Towards Better Performing Domain-Specific Small Language Models",
      "title_zh": "重新思考数据：面向性能更佳的领域特定小型语言模型",
      "authors": [
        "Boris Nazarov",
        "Darya Frolova",
        "Yackov Lubarsky",
        "Alexei Gaissinski",
        "Pavel Kisilev"
      ],
      "abstract": "Fine-tuning of Large Language Models (LLMs) for downstream tasks, performed\non domain-specific data has shown significant promise. However, commercial use\nof such LLMs is limited by the high computational cost required for their\ndeployment at scale. On the other hand, small Language Models (LMs) are much\nmore cost effective but have subpar performance in a similar setup. This paper\npresents our approach to finetuning a small LM, that reaches high accuracy in\nmultiple choice question answering task. We achieve this by improving data\nquality at each stage of the LM training pipeline. In particular, we start with\ndata structuring resulting in extraction of compact, semantically meaningful\ntext chunks used by a retriever. This allows more efficient knowledge digestion\nby the LM. Further, we improve the retrieved context by training a lightweight\nChunk Re-Ranker (CRR) that generates more accurate relative relevance chunk\nscores. Finally, we improve the model generalization ability by merging the\nmodels fine-tuned with different parameters on different data subsets. We\npresent detailed procedure descriptions, and corresponding experimental\nfindings that show the improvements of each one of the proposed techniques.",
      "tldr_zh": "该论文探讨了针对领域特定任务优化小语言模型（Small Language Models, LMs）的策略，以应对大语言模型（Large Language Models, LLMs）高计算成本的局限。研究者通过改进数据质量的整个训练管道，包括数据结构化以提取紧凑的语义文本块、训练轻量级Chunk Re-Ranker (CRR)来提升检索上下文的准确性，以及合并在不同数据子集上fine-tuned的模型，以提高模型的泛化能力。实验结果显示，这些技术显著提升了小LM在多项选择问答任务中的准确率，为高效的领域特定模型部署提供了实用方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01464v1",
      "published_date": "2025-03-03 12:19:12 UTC",
      "updated_date": "2025-03-03 12:19:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:21:43.643440"
    },
    {
      "arxiv_id": "2503.01461v1",
      "title": "Towards Widening The Distillation Bottleneck for Reasoning Models",
      "title_zh": "翻译失败",
      "authors": [
        "Huifeng Yin",
        "Yu Zhao",
        "Minghao Wu",
        "Xuanfan Ni",
        "Bo Zeng",
        "Hao Wang",
        "Tianqi Shi",
        "Liangying Shao",
        "Chenyang Lyu",
        "Longyue Wang",
        "Weihua Luo",
        "Kaifu Zhang"
      ],
      "abstract": "Large Reasoning Models(LRMs) such as OpenAI o1 and DeepSeek-R1 have shown\nremarkable reasoning capabilities by scaling test-time compute and generating\nlong Chain-of-Thought(CoT). Distillation--post-training on LRMs-generated\ndata--is a straightforward yet effective method to enhance the reasoning\nabilities of smaller models, but faces a critical bottleneck: we found that\ndistilled long CoT data poses learning difficulty for small models and leads to\nthe inheritance of biases (i.e. over-thinking) when using Supervised\nFine-tuning(SFT) and Reinforcement Learning(RL) methods. To alleviate this\nbottleneck, we propose constructing tree-based CoT data from scratch via Monte\nCarlo Tree Search(MCTS). We then exploit a set of CoT-aware approaches,\nincluding Thoughts Length Balance, Fine-grained DPO, and Joint Post-training\nObjective, to enhance SFT and RL on the construted data.",
      "tldr_zh": "本研究针对大型推理模型(LRMs)如 OpenAI o1 的蒸馏瓶颈问题，指出小模型在学习长 Chain-of-Thought (CoT) 数据时面临学习困难和偏差继承（如 over-thinking），从而影响 Supervised Fine-tuning (SFT) 和 Reinforcement Learning (RL) 的效果。论文提出一种新方法，使用 Monte Carlo Tree Search (MCTS) 从头构建树-based CoT 数据，以缓解这一瓶颈。同时，引入 CoT-aware 技术，包括 Thoughts Length Balance、Fine-grained DPO 和 Joint Post-training Objective，来优化训练过程。总体而言，这些创新有助于提升小模型的推理能力，推动更有效的模型蒸馏。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01461v1",
      "published_date": "2025-03-03 12:17:36 UTC",
      "updated_date": "2025-03-03 12:17:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:21:58.854974"
    },
    {
      "arxiv_id": "2503.01458v1",
      "title": "SrSv: Integrating Sequential Rollouts with Sequential Value Estimation for Multi-agent Reinforcement Learning",
      "title_zh": "SrSv：将顺序展开与顺序价值估计整合用于多智能体强化学习",
      "authors": [
        "Xu Wan",
        "Chao Yang",
        "Cheng Yang",
        "Jie Song",
        "Mingyang Sun"
      ],
      "abstract": "Although multi-agent reinforcement learning (MARL) has shown its success\nacross diverse domains, extending its application to large-scale real-world\nsystems still faces significant challenges. Primarily, the high complexity of\nreal-world environments exacerbates the credit assignment problem,\nsubstantially reducing training efficiency. Moreover, the variability of agent\npopulations in large-scale scenarios necessitates scalable decision-making\nmechanisms. To address these challenges, we propose a novel framework:\nSequential rollout with Sequential value estimation (SrSv). This framework aims\nto capture agent interdependence and provide a scalable solution for\ncooperative MARL. Specifically, SrSv leverages the autoregressive property of\nthe Transformer model to handle varying populations through sequential action\nrollout. Furthermore, to capture the interdependence of policy distributions\nand value functions among multiple agents, we introduce an innovative\nsequential value estimation methodology and integrates the value approximation\ninto an attention-based sequential model. We evaluate SrSv on three benchmarks:\nMulti-Agent MuJoCo, StarCraft Multi-Agent Challenge, and DubinsCars.\nExperimental results demonstrate that SrSv significantly outperforms baseline\nmethods in terms of training efficiency without compromising convergence\nperformance. Moreover, when implemented in a large-scale DubinsCar system with\n1,024 agents, our framework surpasses existing benchmarks, highlighting the\nexcellent scalability of SrSv.",
      "tldr_zh": "本文提出 SrSv 框架，用于解决多智能体强化学习(MARL)中信用分配问题和代理人口变异带来的挑战，提升训练效率和可扩展性。SrSv 通过 Transformer 的自回归属性实现顺序行动 rollout，并引入顺序价值估计方法，将价值近似整合到基于注意力的顺序模型中，以捕捉代理间政策分布和价值函数的依赖关系。在 Multi-Agent MuJoCo、StarCraft Multi-Agent Challenge 和 DubinsCars 等基准上，实验结果显示 SrSv 显著优于基线方法，并在 1,024 代理的大规模 DubinsCars 系统上展示了卓越的可扩展性。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01458v1",
      "published_date": "2025-03-03 12:17:18 UTC",
      "updated_date": "2025-03-03 12:17:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:22:09.524358"
    },
    {
      "arxiv_id": "2503.01457v1",
      "title": "Structural Deep Encoding for Table Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Raphaël Mouravieff",
        "Benjamin Piwowarski",
        "Sylvain Lamprier"
      ],
      "abstract": "Although Transformers-based architectures excel at processing textual\ninformation, their naive adaptation for tabular data often involves flattening\nthe table structure. This simplification can lead to the loss of essential\ninter-dependencies between rows, columns, and cells, while also posing\nscalability challenges for large tables. To address these issues, prior works\nhave explored special tokens, structured embeddings, and sparse attention\npatterns. In this paper, we conduct a comprehensive analysis of tabular\nencoding techniques, which highlights the crucial role of attention sparsity in\npreserving structural information of tables. We also introduce a set of novel\nsparse attention mask designs for tabular data, that not only enhance\ncomputational efficiency but also preserve structural integrity, leading to\nbetter overall performance.",
      "tldr_zh": "本文分析了Transformers模型在处理表格数据时的问题，包括扁平化处理导致的行、列和单元格间依赖关系丢失，以及可扩展性挑战。作者通过全面评估表格编码技术，强调了稀疏注意力(sparse attention)的关键作用，并引入了一系列新型稀疏注意力掩码设计。这些设计不仅提升了计算效率，还保留了表格的结构完整性，从而显著提高了Table Question Answering的整体性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.01457v1",
      "published_date": "2025-03-03 12:16:43 UTC",
      "updated_date": "2025-03-03 12:16:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:22:19.770053"
    },
    {
      "arxiv_id": "2503.01453v2",
      "title": "AC-Lite : A Lightweight Image Captioning Model for Low-Resource Assamese Language",
      "title_zh": "翻译失败",
      "authors": [
        "Pankaj Choudhury",
        "Yogesh Aggarwal",
        "Prabhanjan Jadhav",
        "Prithwijit Guha",
        "Sukumar Nandi"
      ],
      "abstract": "Most existing works in image caption synthesis use computation heavy deep\nneural networks and generates image descriptions in English language. This\noften restricts this important assistive tool for widespread use across\nlanguage and accessibility barriers. This work presents AC-Lite, a\ncomputationally efficient model for image captioning in low-resource Assamese\nlanguage. AC-Lite reduces computational requirements by replacing\ncomputation-heavy deep network components with lightweight alternatives. The\nAC-Lite model is designed through extensive ablation experiments with different\nimage feature extractor networks and language decoders. A combination of\nShuffleNetv2x1.5 with GRU based language decoder along with bilinear attention\nis found to provide the best performance with minimum compute. AC-Lite was\nobserved to achieve an 82.3 CIDEr score on the COCO-AC dataset with 2.45 GFLOPs\nand 22.87M parameters.",
      "tldr_zh": "本研究针对现有图像描述模型计算密集且仅限英语的问题，提出了一种轻量级模型 AC-Lite，用于低资源语言阿萨姆语的图像 captioning。AC-Lite 通过消融实验优化组件，使用 ShuffleNetv2x1.5 作为图像特征提取器、GRU 基于的语言解码器以及双线性注意力机制，显著降低了计算需求。实验结果显示，该模型在 COCO-AC 数据集上达到 82.3 CIDEr 分数，同时仅需 2.45 GFLOPs 和 22.87M 参数，为资源受限环境下的多语言图像描述提供了高效解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01453v2",
      "published_date": "2025-03-03 12:07:52 UTC",
      "updated_date": "2025-04-30 08:01:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:22:32.335041"
    },
    {
      "arxiv_id": "2503.04803v1",
      "title": "An energy-efficient learning solution for the Agile Earth Observation Satellite Scheduling Problem",
      "title_zh": "翻译失败",
      "authors": [
        "Antonio M. Mercado-Martínez",
        "Beatriz Soret",
        "Antonio Jurado-Navas"
      ],
      "abstract": "The Agile Earth Observation Satellite Scheduling Problem (AEOSSP) entails\nfinding the subset of observation targets to be scheduled along the satellite's\norbit while meeting operational constraints of time, energy and memory. The\nproblem of deciding what and when to observe is inherently complex, and becomes\neven more challenging when considering several issues that compromise the\nquality of the captured images, such as cloud occlusion, atmospheric\nturbulence, and image resolution. This paper presents a Deep Reinforcement\nLearning (DRL) approach for addressing the AEOSSP with time-dependent profits,\nintegrating these three factors to optimize the use of energy and memory\nresources. The proposed method involves a dual decision-making process:\nselecting the sequence of targets and determining the optimal observation time\nfor each. Our results demonstrate that the proposed algorithm reduces the\ncapture of images that fail to meet quality requirements by > 60% and\nconsequently decreases energy waste from attitude maneuvers by up to 78%, all\nwhile maintaining strong observation performance.",
      "tldr_zh": "本论文针对Agile Earth Observation Satellite Scheduling Problem (AEOSSP)提出了一种基于Deep Reinforcement Learning (DRL)的节能学习解决方案，该问题涉及在卫星轨道上选择观察目标，同时满足时间、能量和内存约束，并考虑云遮挡、大气湍流及图像分辨率等因素。方法采用双重决策过程，包括选择目标序列和确定每个目标的最佳观察时间，以优化能量和内存资源利用。实验结果显示，该算法将不合格图像捕获减少超过60%，并将能量浪费降低高达78%，同时维持了强劲的观察性能。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "This paper has been accepted for presentation at the IEEE\n  International Conference on Machine Learning for Communication and Networking\n  (ICMLCN) Special Sessions 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.04803v1",
      "published_date": "2025-03-03 12:01:27 UTC",
      "updated_date": "2025-03-03 12:01:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:22:45.269933"
    },
    {
      "arxiv_id": "2503.01450v3",
      "title": "POPGym Arcade: Parallel Pixelated POMDPs",
      "title_zh": "翻译失败",
      "authors": [
        "Zekang Wang",
        "Zhe He",
        "Borong Zhang",
        "Edan Toledo",
        "Steven Morad"
      ],
      "abstract": "We present the POPGym Arcade, a collection of hardware-accelerated,\npixel-based environments with shared observation and action spaces. Each\nenvironment includes fully and partially observable variants, enabling\ncounterfactual studies on partial observability. We also introduce mathematical\ntools for analyzing policies under partial observability, which reveal how\nagents recall past information to make decisions. Our analysis shows (1) that\ncontrolling for partial observability is critical and (2) that agents with\nlong-term memory learn brittle policies that struggle to generalize. Finally,\nwe demonstrate that recurrent policies can be \"poisoned\" by old,\nout-of-distribution observations, with implications for sim-to-real transfer,\nimitation learning, and offline reinforcement learning.",
      "tldr_zh": "本文介绍了 POPGym Arcade，这是一个硬件-accelerated 的像素化环境集合，支持共享观察和动作空间，并提供完全和部分可观察（POMDPs）变体，用于进行反事实研究。研究者引入了数学工具来分析代理在部分可观察条件下的策略，揭示代理如何利用过去信息决策。结果显示，控制部分可观察性至关重要，具有长期记忆的代理学习了易碎且难以泛化的策略，而循环策略可能被旧的分布外观察“poisoned”，这对模拟到真实转移、模仿学习和离线强化学习有重要影响。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01450v3",
      "published_date": "2025-03-03 11:59:03 UTC",
      "updated_date": "2025-05-18 04:47:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:22:56.997919"
    },
    {
      "arxiv_id": "2503.01442v1",
      "title": "Leveraging LLMs for Mental Health: Detection and Recommendations from Social Discussions",
      "title_zh": "翻译失败",
      "authors": [
        "Vaishali Aggarwal",
        "Sachin Thukral",
        "Krushil Patel",
        "Arnab Chatterjee"
      ],
      "abstract": "Textual data from social platforms captures various aspects of mental health\nthrough discussions around and across issues, while users reach out for help\nand others sympathize and offer support. We propose a comprehensive framework\nthat leverages Natural Language Processing (NLP) and Generative AI techniques\nto identify and assess mental health disorders, detect their severity, and\ncreate recommendations for behavior change and therapeutic interventions based\non users' posts on Reddit.\n  To classify the disorders, we use rule-based labeling methods as well as\nadvanced pre-trained NLP models to extract nuanced semantic features from the\ndata. We fine-tune domain-adapted and generic pre-trained NLP models based on\npredictions from specialized Large Language Models (LLMs) to improve\nclassification accuracy. Our hybrid approach combines the generalization\ncapabilities of pre-trained models with the domain-specific insights captured\nby LLMs, providing an improved understanding of mental health discourse. Our\nfindings highlight the strengths and limitations of each model, offering\nvaluable insights into their practical applicability.\n  This research potentially facilitates early detection and personalized care\nto aid practitioners and aims to facilitate timely interventions and improve\noverall well-being, thereby contributing to the broader field of mental health\nsurveillance and digital health analytics.",
      "tldr_zh": "本研究提出一个综合框架，利用自然语言处理（NLP）和生成式AI技术，从Reddit等社交平台上的用户帖子中识别和评估心理健康障碍、检测其严重程度，并提供行为改变和治疗干预的推荐。框架结合基于规则的标签方法、预训练NLP模型以及大型语言模型（LLMs）的预测来微调领域适配模型，从而提取细微语义特征并提高分类准确性。这种混合方法融合了预训练模型的泛化能力与LLMs的领域特定洞见，并分析了各模型的优缺点。研究结果表明，该框架有助于早期检测和个性化护理，支持从业者进行及时干预，并为心理健康监控和数字健康分析领域带来潜在贡献。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.SI",
      "comment": "5 pages, 4 figures, 3 tables, to be published in WI-IAT 2024",
      "pdf_url": "http://arxiv.org/pdf/2503.01442v1",
      "published_date": "2025-03-03 11:48:01 UTC",
      "updated_date": "2025-03-03 11:48:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:23:08.095086"
    },
    {
      "arxiv_id": "2503.01437v1",
      "title": "Eau De $Q$-Network: Adaptive Distillation of Neural Networks in Deep Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Théo Vincent",
        "Tim Faust",
        "Yogesh Tripathi",
        "Jan Peters",
        "Carlo D'Eramo"
      ],
      "abstract": "Recent works have successfully demonstrated that sparse deep reinforcement\nlearning agents can be competitive against their dense counterparts. This opens\nup opportunities for reinforcement learning applications in fields where\ninference time and memory requirements are cost-sensitive or limited by\nhardware. Until now, dense-to-sparse methods have relied on hand-designed\nsparsity schedules that are not synchronized with the agent's learning pace.\nCrucially, the final sparsity level is chosen as a hyperparameter, which\nrequires careful tuning as setting it too high might lead to poor performances.\nIn this work, we address these shortcomings by crafting a dense-to-sparse\nalgorithm that we name Eau De $Q$-Network (EauDeQN). To increase sparsity at\nthe agent's learning pace, we consider multiple online networks with different\nsparsity levels, where each online network is trained from a shared target\nnetwork. At each target update, the online network with the smallest loss is\nchosen as the next target network, while the other networks are replaced by a\npruned version of the chosen network. We evaluate the proposed approach on the\nAtari $2600$ benchmark and the MuJoCo physics simulator, showing that EauDeQN\nreaches high sparsity levels while keeping performances high.",
      "tldr_zh": "该研究提出了一种名为 Eau De $Q$-Network (EauDeQN) 的自适应算法，用于深度强化学习（Deep Reinforcement Learning）中的神经网络稀疏蒸馏，以解决现有密集到稀疏方法依赖手动稀疏度调度和超参数调优的问题。EauDeQN 通过训练多个具有不同稀疏度的在线网络，从一个共享的目标网络学习，并在每次目标更新时选择损失最小的网络作为新目标，同时用其修剪版本替换其他网络，从而根据代理的学习速度动态增加稀疏度。在 Atari 2600 和 MuJoCo 基准测试中，该方法实现了高稀疏度水平，同时保持了高性能表现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at RLDM",
      "pdf_url": "http://arxiv.org/pdf/2503.01437v1",
      "published_date": "2025-03-03 11:39:03 UTC",
      "updated_date": "2025-03-03 11:39:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:23:20.266218"
    },
    {
      "arxiv_id": "2503.04802v1",
      "title": "The order in speech disorder: a scoping review of state of the art machine learning methods for clinical speech classification",
      "title_zh": "言语障碍中的秩序：对最先进机器学习方法用于临床言语分类的范围综述",
      "authors": [
        "Birger Moell",
        "Fredrik Sand Aronsson",
        "Per Östberg",
        "Jonas Beskow"
      ],
      "abstract": "Background:Speech patterns have emerged as potential diagnostic markers for\nconditions with varying etiologies. Machine learning (ML) presents an\nopportunity to harness these patterns for accurate disease diagnosis.\n  Objective: This review synthesized findings from studies exploring ML's\ncapability in leveraging speech for the diagnosis of neurological, laryngeal\nand mental disorders.\n  Methods: A systematic examination of 564 articles was conducted with 91\narticles included in the study, which encompassed a wide spectrum of\nconditions, ranging from voice pathologies to mental and neurological\ndisorders. Methods for speech classifications were assessed based on the\nrelevant studies and scored between 0-10 based on the reported diagnostic\naccuracy of their ML models.\n  Results: High diagnostic accuracies were consistently observed for laryngeal\ndisorders, dysarthria, and changes related to speech in Parkinsons disease.\nThese findings indicate the robust potential of speech as a diagnostic tool.\nDisorders like depression, schizophrenia, mild cognitive impairment and\nAlzheimers dementia also demonstrated high accuracies, albeit with some\nvariability across studies. Meanwhile, disorders like OCD and autism\nhighlighted the need for more extensive research to ascertain the relationship\nbetween speech patterns and the respective conditions.\n  Conclusion: ML models utilizing speech patterns demonstrate promising\npotential in diagnosing a range of mental, laryngeal, and neurological\ndisorders. However, the efficacy varies across conditions, and further research\nis needed. The integration of these models into clinical practice could\npotentially revolutionize the evaluation and diagnosis of a number of different\nmedical conditions.",
      "tldr_zh": "本综述探讨了Machine Learning (ML)方法在利用语音模式诊断神经、喉部和精神障碍方面的潜力，通过系统审查564篇文章并最终评估91篇研究。研究方法包括对语音分类技术进行基于诊断准确率（0-10分）的评分。结果显示，喉部障碍、构音障碍和帕金森病相关语音变化表现出高诊断准确率，而抑郁症、精神分裂症、轻度认知障碍和阿尔茨海默病也显示出较高准确率，但存在变异；相反，OCD和自闭症等疾病则需要更多研究来确认语音模式的关联。总体而言，ML模型有望革新临床诊断，但其效能因疾病而异，并需进一步验证。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04802v1",
      "published_date": "2025-03-03 11:33:02 UTC",
      "updated_date": "2025-03-03 11:33:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:23:32.525050"
    },
    {
      "arxiv_id": "2503.01424v1",
      "title": "From Hypothesis to Publication: A Comprehensive Survey of AI-Driven Research Support Systems",
      "title_zh": "从假设到出版：人工智能驱动的研究支持系统的全面综述",
      "authors": [
        "Zekun Zhou",
        "Xiaocheng Feng",
        "Lei Huang",
        "Xiachong Feng",
        "Ziyun Song",
        "Ruihan Chen",
        "Liang Zhao",
        "Weitao Ma",
        "Yuxuan Gu",
        "Baoxin Wang",
        "Dayong Wu",
        "Guoping Hu",
        "Ting Liu",
        "Bing Qin"
      ],
      "abstract": "Research is a fundamental process driving the advancement of human\ncivilization, yet it demands substantial time and effort from researchers. In\nrecent years, the rapid development of artificial intelligence (AI)\ntechnologies has inspired researchers to explore how AI can accelerate and\nenhance research. To monitor relevant advancements, this paper presents a\nsystematic review of the progress in this domain. Specifically, we organize the\nrelevant studies into three main categories: hypothesis formulation, hypothesis\nvalidation, and manuscript publication. Hypothesis formulation involves\nknowledge synthesis and hypothesis generation. Hypothesis validation includes\nthe verification of scientific claims, theorem proving, and experiment\nvalidation. Manuscript publication encompasses manuscript writing and the peer\nreview process. Furthermore, we identify and discuss the current challenges\nfaced in these areas, as well as potential future directions for research.\nFinally, we also offer a comprehensive overview of existing benchmarks and\ntools across various domains that support the integration of AI into the\nresearch process. We hope this paper serves as an introduction for beginners\nand fosters future research. Resources have been made publicly available at\nhttps://github.com/zkzhou126/AI-for-Research.",
      "tldr_zh": "这篇论文对 AI 驱动的研究支持系统进行了全面综述，涵盖从假设制定（hypothesis formulation）到手稿发布（manuscript publication）的整个研究过程。作者将相关研究分为三个主要类别：假设制定（包括知识合成和假设生成）、假设验证（hypothesis validation，包括科学声明验证、定理证明和实验验证），以及手稿发布（包括手稿写作和同行评审）。论文还讨论了当前挑战、未来研究方向，并概述了现有基准和工具，以促进 AI 在研究中的应用，并为初学者提供资源和公开链接。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01424v1",
      "published_date": "2025-03-03 11:27:13 UTC",
      "updated_date": "2025-03-03 11:27:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:23:43.667278"
    },
    {
      "arxiv_id": "2503.01422v1",
      "title": "Sampling-Efficient Test-Time Scaling: Self-Estimating the Best-of-N Sampling in Early Decoding",
      "title_zh": "翻译失败",
      "authors": [
        "Yiming Wang",
        "Pei Zhang",
        "Siyuan Huang",
        "Baosong Yang",
        "Zhuosheng Zhang",
        "Fei Huang",
        "Rui Wang"
      ],
      "abstract": "Test-time scaling improves large language model performance by adding extra\ncompute during decoding. Best-of-N (BoN) sampling serves as a common scaling\ntechnique, broadening the search space for finding better solutions from the\nmodel distribution. However, traditional BoN requires N full generations,\nleading to high GPU memory overhead and time latency. Moreover, some methods\ndepend on reward models, adding computational cost and limiting domain\ngeneralization.\n  In this paper, we propose Self-Truncation Best-of-N (ST-BoN), a novel\ndecoding method that avoids fully generating all samplings and eliminates the\nneed for reward models. ST-BoN introduces early sampling consistency to\nestimate the most promising sample, truncating suboptimal ones to free memory\nand accelerate inference. This pushes the sampling-efficient test-time scaling.\nCompared to traditional BoN, ST-BoN can reduce dynamic GPU memory overhead by\nover 90% and time latency by 50%, while achieving comparable or even better\nperformance across reasoning and open-ended domains.",
      "tldr_zh": "该论文针对大型语言模型的Test-time scaling技术，提出了一种采样高效的Best-of-N (BoN)采样方法，以解决传统BoN需要生成所有样本导致的高GPU内存开销和时间延迟问题。作者引入Self-Truncation Best-of-N (ST-BoN)框架，通过早期采样一致性来估计最有前景的样本，并截断次优样本，从而避免完整生成所有采样和依赖奖励模型。实验结果显示，ST-BoN可以将动态GPU内存开销减少超过90%、时间延迟减少50%，并在推理和开放域任务上实现与传统BoN相当或更好的性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "23 pages, 14 figures, 8 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.01422v1",
      "published_date": "2025-03-03 11:21:01 UTC",
      "updated_date": "2025-03-03 11:21:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:23:55.787827"
    },
    {
      "arxiv_id": "2503.01419v1",
      "title": "Parameter-Efficient Fine-Tuning of Large Language Models via Deconvolution in Subspace",
      "title_zh": "通过子空间中的反卷积实现大语言模型的参数高效微调",
      "authors": [
        "Jia-Chen Zhang",
        "Yu-Jie Xiong",
        "Chun-Ming Xia",
        "Dong-Hai Zhu",
        "Xi-He Qiu"
      ],
      "abstract": "Large language model (LLM) is considered a milestone towards achieving\nArtificial General Intelligence (AGI). With its advanced emergent capabilities,\nit adapt to a wide range of specific applications. Fine-tuning LLMs for various\ndownstream tasks has become a new paradigm. Low-Rank Adaptation (LoRA) is\nwell-known for its parameter efficiency. It can reduce the number of parameters\nneeded to fine-tune LLMs by several orders of magnitude. However, LoRA-based\napproaches encounter a significant limitation due to the bottleneck imposed by\nrank one decomposition. As the parameters count in LLMs increase, even rank one\ndecomposition might surpass the number of parameters truly necessary for\nhandling more downstream tasks. In this paper, we propose a new method for\nParameter-Efficient Fine-Tuning (PEFT) via deconvolution in subspace, dubbed as\nDCFT. We innovatively use deconvolution to complete details and enhance\nknowledge in subspace incremental matrices, and dynamically control parameters\nby adjusting the kernel size, unconstrained by rank-one decomposition.\nExtensive experiments are conducted to validate the effectiveness of DCFT.\nResults show that compared to LoRA, DCFT achieve an 8$\\times$ reduction in\nparameters, and still achieves highly impressive performance. Our code is\navailable here: https://github.com/Godz-z/DCFT.",
      "tldr_zh": "该论文提出了一种参数高效微调（Parameter-Efficient Fine-Tuning, PEFT）方法，名为 DCFT，通过在子空间（Subspace）中应用反卷积（Deconvolution）来解决 Large Language Models (LLMs) 微调中的参数冗余问题。相比于传统的 Low-Rank Adaptation (LoRA)，DCFT 创新性地使用反卷积增强子空间增量矩阵的细节和知识，并通过调整核大小（Kernel Size）动态控制参数，而不受 rank-one decomposition 的限制。实验结果显示，DCFT 相较 LoRA 减少了 8 倍参数，同时在多项下游任务上保持了出色的性能，为高效微调 LLMs 提供了新范式。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "COLING 2025 main conference",
      "pdf_url": "http://arxiv.org/pdf/2503.01419v1",
      "published_date": "2025-03-03 11:15:50 UTC",
      "updated_date": "2025-03-03 11:15:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:24:08.120948"
    },
    {
      "arxiv_id": "2503.01413v2",
      "title": "Building Interval Type-2 Fuzzy Membership Function: A Deck of Cards based Co-constructive Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Bapi Dutta",
        "Diego García-Zamora",
        "José Rui Figueira",
        "Luis Martínez"
      ],
      "abstract": "Since its inception, Fuzzy Set has been widely used to handle uncertainty and\nimprecision in decision-making. However, conventional fuzzy sets, often\nreferred to as type-1 fuzzy sets (T1FSs) have limitations in capturing higher\nlevels of uncertainty, particularly when decision-makers (DMs) express\nhesitation or ambiguity in membership degree. To address this, Interval Type-2\nFuzzy Sets (IT2FSs) have been introduced by incorporating uncertainty in\nmembership degree allocation, which enhanced flexibility in modelling\nsubjective judgments. Despite their advantages, existing IT2FS construction\nmethods often lack active involvement from DMs and that limits the\ninterpretability and effectiveness of decision models. This study proposes a\nsocio-technical co-constructive approach for developing IT2FS models of\nlinguistic terms by facilitating the active involvement of DMs in preference\nelicitation and its application in multicriteria decision-making (MCDM)\nproblems. Our methodology is structured in two phases. The first phase involves\nan interactive process between the DM and the decision analyst, in which a\nmodified version of Deck-of-Cards (DoC) method is proposed to construct T1FS\nmembership functions on a ratio scale. We then extend this method to\nincorporate ambiguity in subjective judgment and that resulted in an IT2FS\nmodel that better captures uncertainty in DM's linguistic assessments. The\nsecond phase formalizes the constructed IT2FS model for application in MCDM by\ndefining an appropriate mathematical representation of such information,\naggregation rules, and an admissible ordering principle. The proposed framework\nenhances the reliability and effectiveness of fuzzy decision-making not only by\naccurately representing DM's personalized semantics of linguistic information.",
      "tldr_zh": "本文提出一种基于 Deck-of-Cards (DoC) 的社会技术共同构建方法，用于开发 Interval Type-2 Fuzzy Sets (IT2FSs) 的成员函数，以更好地处理决策中决策者（DMs）的犹豫和不确定性问题。方法分为两个阶段：第一阶段通过修改的 DoC 方法与 DMs 互动，构建 Type-1 Fuzzy Sets (T1FSs) 并扩展到 IT2FSs，以捕捉主观判断的模糊性；第二阶段则形式化 IT2FSs 的数学表示、聚合规则和排序原则，用于 Multicriteria Decision-Making (MCDM) 应用。该框架提升了模糊决策的可靠性和有效性，通过准确表示 DMs 的个性化语言信息语义。",
      "categories": [
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01413v2",
      "published_date": "2025-03-03 11:08:18 UTC",
      "updated_date": "2025-03-11 15:37:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:24:21.087904"
    },
    {
      "arxiv_id": "2503.01411v3",
      "title": "Learning Actionable World Models for Industrial Process Control",
      "title_zh": "学习可行动的世界模型用于工业过程控制",
      "authors": [
        "Peng Yan",
        "Ahmed Abdulkadir",
        "Gerrit A. Schatte",
        "Giulia Aguzzi",
        "Joonsu Gha",
        "Nikola Pascher",
        "Matthias Rosenthal",
        "Yunlong Gao",
        "Benjamin F. Grewe",
        "Thilo Stadelmann"
      ],
      "abstract": "To go from (passive) process monitoring to active process control, an\neffective AI system must learn about the behavior of the complex system from\nvery limited training data, forming an ad-hoc digital twin with respect to\nprocess inputs and outputs that captures the consequences of actions on the\nprocess's world. We propose a novel methodology based on learning world models\nthat disentangles process parameters in the learned latent representation,\nallowing for fine-grained control. Representation learning is driven by the\nlatent factors influencing the processes through contrastive learning within a\njoint embedding predictive architecture. This makes changes in representations\npredictable from changes in inputs and vice versa, facilitating\ninterpretability of key factors responsible for process variations, paving the\nway for effective control actions to keep the process within operational\nbounds. The effectiveness of our method is validated on the example of plastic\ninjection molding, demonstrating practical relevance in proposing specific\ncontrol actions for a notoriously unstable process.",
      "tldr_zh": "这篇论文提出了一种基于学习世界模型（world models）的方法，用于从有限训练数据中实现工业过程的主动控制，从而形成一个 ad-hoc 数字孪生，以捕捉动作对过程的影响。方法通过对比学习（contrastive learning）在联合嵌入预测架构（joint embedding predictive architecture）中分离过程参数，实现细粒度控制，并使表示变化与输入变化相互可预测，从而提升关键因素的可解释性。实验在塑料注射成型等不稳定过程中验证了该方法的有效性，展示了其在提出具体控制行动方面的实际相关性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY",
        "I.2.0; I.2.4"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by SDS 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.01411v3",
      "published_date": "2025-03-03 11:05:44 UTC",
      "updated_date": "2025-04-25 09:11:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:24:32.745951"
    },
    {
      "arxiv_id": "2503.01407v2",
      "title": "Divide and Conquer: Heterogeneous Noise Integration for Diffusion-based Adversarial Purification",
      "title_zh": "分而治之：异质噪声整合用于基于",
      "authors": [
        "Gaozheng Pei",
        "Shaojie Lyu",
        "Gong Chen",
        "Ke Ma",
        "Qianqian Xu",
        "Yingfei Sun",
        "Qingming Huang"
      ],
      "abstract": "Existing diffusion-based purification methods aim to disrupt adversarial\nperturbations by introducing a certain amount of noise through a forward\ndiffusion process, followed by a reverse process to recover clean examples.\nHowever, this approach is fundamentally flawed: the uniform operation of the\nforward process across all pixels compromises normal pixels while attempting to\ncombat adversarial perturbations, resulting in the target model producing\nincorrect predictions. Simply relying on low-intensity noise is insufficient\nfor effective defense. To address this critical issue, we implement a\nheterogeneous purification strategy grounded in the interpretability of neural\nnetworks. Our method decisively applies higher-intensity noise to specific\npixels that the target model focuses on while the remaining pixels are\nsubjected to only low-intensity noise. This requirement motivates us to\nredesign the sampling process of the diffusion model, allowing for the\neffective removal of varying noise levels. Furthermore, to evaluate our method\nagainst strong adaptative attack, our proposed method sharply reduces time cost\nand memory usage through a single-step resampling. The empirical evidence from\nextensive experiments across three datasets demonstrates that our method\noutperforms most current adversarial training and purification techniques by a\nsubstantial margin.",
      "tldr_zh": "本文提出“Divide and Conquer”策略，通过异构噪声集成（Heterogeneous Noise Integration）改进基于扩散的对抗净化方法，以解决现有方法的不足，即均匀噪声处理会破坏正常像素并导致预测错误。新的方法基于神经网络的可解释性，对目标模型关注的特定像素施加高强度噪声，而其他像素仅施加低强度噪声，并重新设计扩散模型的采样过程以支持不同噪声水平。同时，通过单步重采样显著降低时间和内存消耗。实验结果显示，在三个数据集上，该方法大幅优于现有的对抗训练和净化技术。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01407v2",
      "published_date": "2025-03-03 11:00:25 UTC",
      "updated_date": "2025-03-24 07:15:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:24:44.489984"
    },
    {
      "arxiv_id": "2503.01394v1",
      "title": "Enhancing Social Media Rumor Detection: A Semantic and Graph Neural Network Approach for the 2024 Global Election",
      "title_zh": "翻译失败",
      "authors": [
        "Liu Yan",
        "Liu Yunpeng",
        "Zhao Liang"
      ],
      "abstract": "The development of social media platforms has revolutionized the speed and\nmanner in which information is disseminated, leading to both beneficial and\ndetrimental effects on society. While these platforms facilitate rapid\ncommunication, they also accelerate the spread of rumors and extremist speech,\nimpacting public perception and behavior significantly. This issue is\nparticularly pronounced during election periods, where the influence of social\nmedia on election outcomes has become a matter of global concern. With the\nunprecedented number of elections in 2024, against this backdrop, the election\necosystem has encountered unprecedented challenges. This study addresses the\nurgent need for effective rumor detection on social media by proposing a novel\nmethod that combines semantic analysis with graph neural networks. We have\nmeticulously collected a dataset from PolitiFact and Twitter, focusing on\npolitically relevant rumors. Our approach involves semantic analysis using a\nfine-tuned BERT model to vectorize text content and construct a directed graph\nwhere tweets and comments are nodes, and interactions are edges. The core of\nour method is a graph neural network, SAGEWithEdgeAttention, which extends the\nGraphSAGE model by incorporating first-order differences as edge attributes and\napplying an attention mechanism to enhance feature aggregation. This innovative\napproach allows for the fine-grained analysis of the complex social network\nstructure, improving rumor detection accuracy. The study concludes that our\nmethod significantly outperforms traditional content analysis and time-based\nmodels, offering a theoretically sound and practically efficient solution.",
      "tldr_zh": "这篇论文针对2024年全球选举中社交媒体谣言传播的问题，提出了一种结合语义分析和图神经网络的检测方法，以提升准确性。研究团队从PolitiFact和Twitter收集政治相关谣言数据集，使用fine-tuned BERT模型对文本进行向量化，并构建有向图（节点为推文和评论，边为互动）。核心创新是SAGEWithEdgeAttention模型，该模型扩展GraphSAGE，通过加入第一阶差异作为边属性和注意力机制来优化特征聚合。实验结果表明，该方法显著优于传统内容分析和基于时间的模型，提供了一个理论可靠且实践高效的解决方案。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01394v1",
      "published_date": "2025-03-03 10:49:33 UTC",
      "updated_date": "2025-03-03 10:49:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:24:57.066899"
    },
    {
      "arxiv_id": "2503.01389v1",
      "title": "Learning Conjecturing from Scratch",
      "title_zh": "翻译失败",
      "authors": [
        "Thibault Gauthier",
        "Josef Urban"
      ],
      "abstract": "We develop a self-learning approach for conjecturing of induction predicates\non a dataset of 16197 problems derived from the OEIS. These problems are hard\nfor today's SMT and ATP systems because they require a combination of inductive\nand arithmetical reasoning.\n  Starting from scratch, our approach consists of a feedback loop that iterates\nbetween (i) training a neural translator to learn the correspondence between\nthe problems solved so far and the induction predicates useful for them, (ii)\nusing the trained neural system to generate many new induction predicates for\nthe problems, (iii) fast runs of the z3 prover attempting to prove the problems\nusing the generated predicates, (iv) using heuristics such as predicate size\nand solution speed on the proved problems to choose the best predicates for the\nnext iteration of training.\n  The algorithm discovers on its own many interesting induction predicates,\nultimately solving 5565 problems, compared to 2265 problems solved by CVC5,\nVampire or Z3 in 60 seconds.",
      "tldr_zh": "该论文提出了一种从零开始的自学习方法，用于在 OEIS 数据集的 16197 个问题上自动推测归纳谓词，这些问题因需要结合归纳和算术推理而对当前的 SMT 和 ATP 系统构成挑战。方法采用一个反馈循环，包括训练神经翻译器以学习已解决问题与有用谓词的对应关系、生成新谓词、使用 z3 证明器快速尝试证明问题，以及通过启发式规则（如谓词大小和解决速度）选择最佳谓词进行下次迭代。最终，该算法自主发现了许多有趣的归纳谓词，成功解决了 5565 个问题，显著优于 CVC5、Vampire 或 Z3 在 60 秒内仅解决的 2265 个问题。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.LO",
        "cs.NE",
        "cs.SC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01389v1",
      "published_date": "2025-03-03 10:39:38 UTC",
      "updated_date": "2025-03-03 10:39:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:25:09.105430"
    },
    {
      "arxiv_id": "2503.01386v1",
      "title": "Geo-Semantic-Parsing: AI-powered geoparsing by traversing semantic knowledge graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Leonardo Nizzoli",
        "Marco Avvenuti",
        "Maurizio Tesconi",
        "Stefano Cresci"
      ],
      "abstract": "Online social networks convey rich information about geospatial facets of\nreality. However in most cases, geographic information is not explicit and\nstructured, thus preventing its exploitation in real-time applications. We\naddress this limitation by introducing a novel geoparsing and geotagging\ntechnique called Geo-Semantic-Parsing (GSP). GSP identifies location references\nin free text and extracts the corresponding geographic coordinates. To reach\nthis goal, we employ a semantic annotator to identify relevant portions of the\ninput text and to link them to the corresponding entity in a knowledge graph.\nThen, we devise and experiment with several efficient strategies for traversing\nthe knowledge graph, thus expanding the available set of information for the\ngeoparsing task. Finally, we exploit all available information for learning a\nregression model that selects the best entity with which to geotag the input\ntext. We evaluate GSP on a well-known reference dataset including almost 10k\nevent-related tweets, achieving $F1=0.66$. We extensively compare our results\nwith those of 2 baselines and 3 state-of-the-art geoparsing techniques,\nachieving the best performance. On the same dataset, competitors obtain $F1\n\\leq 0.55$. We conclude by providing in-depth analyses of our results, showing\nthat the overall superior performance of GSP is mainly due to a large\nimprovement in recall, with respect to existing techniques.",
      "tldr_zh": "该论文提出 Geo-Semantic-Parsing (GSP) 技术，一种基于 AI 的地理解析方法，通过遍历 semantic knowledge graphs 来识别和提取在线社交网络文本中的隐式地理信息。GSP 的方法包括使用语义注释器标注文本相关部分并链接到知识图谱实体，然后采用多种遍历策略扩展信息，并通过回归模型选择最佳实体进行地理标记。实验在包含近 10k 条事件相关推文的数据集上，GSP 实现了 F1 分数 0.66 的性能，比 2 个基线和 3 个最先进技术（F1 ≤ 0.55）更优，主要得益于显著提升的召回率。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.SI"
      ],
      "primary_category": "cs.CL",
      "comment": "Postprint of the article published in the Decision Support Systems\n  journal. Please, cite accordingly",
      "pdf_url": "http://arxiv.org/pdf/2503.01386v1",
      "published_date": "2025-03-03 10:30:23 UTC",
      "updated_date": "2025-03-03 10:30:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:25:22.214376"
    },
    {
      "arxiv_id": "2503.01375v2",
      "title": "Bayesian Inverse Problems Meet Flow Matching: Efficient and Flexible Inference via Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Daniil Sherki",
        "Ivan Oseledets",
        "Ekaterina Muravleva"
      ],
      "abstract": "The efficient resolution of Bayesian inverse problems remains challenging due\nto the high computational cost of traditional sampling methods. In this paper,\nwe propose a novel framework that integrates Conditional Flow Matching (CFM)\nwith a transformer-based architecture to enable fast and flexible sampling from\ncomplex posterior distributions. The proposed methodology involves the direct\nlearning of conditional probability trajectories from the data, leveraging\nCFM's ability to bypass iterative simulation and transformers' capacity to\nprocess arbitrary numbers of observations. The efficacy of the proposed\nframework is demonstrated through its application to three problems: a simple\nnonlinear model, a disease dynamics framework, and a two-dimensional Darcy flow\nPartial Differential Equation. The primary outcomes demonstrate that the\nrelative errors in parameters recovery are as low as 1.5%, and that the\ninference time is reduced by up to 2000 times on CPU in comparison with the\nMonte Carlo Markov Chain. This framework facilitates the expeditious resolution\nof Bayesian problems through the utilisation of sampling from the learned\nconditional distribution.",
      "tldr_zh": "该论文提出了一种将 Conditional Flow Matching (CFM) 与 transformer 架构相结合的框架，用于高效解决 Bayesian inverse problems，从而克服传统采样方法的计算开销问题。\n该框架通过直接从数据学习条件概率轨迹，利用 CFM 避免迭代模拟，并借助 transformer 处理任意数量的观察数据，实现快速灵活的采样。\n实验结果显示，在简单非线性模型、疾病动态框架和二维 Darcy flow Partial Differential Equation 等问题上，该方法参数恢复相对误差低至 1.5%，推理时间比 Monte Carlo Markov Chain (MCMC) 减少高达 2000 倍。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01375v2",
      "published_date": "2025-03-03 10:17:56 UTC",
      "updated_date": "2025-05-16 19:52:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:25:33.159033"
    },
    {
      "arxiv_id": "2503.01372v1",
      "title": "SwiLTra-Bench: The Swiss Legal Translation Benchmark",
      "title_zh": "SwiLTra-Bench：瑞士法律翻译基准",
      "authors": [
        "Joel Niklaus",
        "Jakob Merane",
        "Luka Nenadic",
        "Sina Ahmadi",
        "Yingqiang Gao",
        "Cyrill A. H. Chevalley",
        "Claude Humbel",
        "Christophe Gösken",
        "Lorenzo Tanzi",
        "Thomas Lüthi",
        "Stefan Palombo",
        "Spencer Poff",
        "Boling Yang",
        "Nan Wu",
        "Matthew Guillod",
        "Robin Mamié",
        "Daniel Brunner",
        "Julio Pereyra",
        "Niko Grupen"
      ],
      "abstract": "In Switzerland legal translation is uniquely important due to the country's\nfour official languages and requirements for multilingual legal documentation.\nHowever, this process traditionally relies on professionals who must be both\nlegal experts and skilled translators -- creating bottlenecks and impacting\neffective access to justice. To address this challenge, we introduce\nSwiLTra-Bench, a comprehensive multilingual benchmark of over 180K aligned\nSwiss legal translation pairs comprising laws, headnotes, and press releases\nacross all Swiss languages along with English, designed to evaluate LLM-based\ntranslation systems. Our systematic evaluation reveals that frontier models\nachieve superior translation performance across all document types, while\nspecialized translation systems excel specifically in laws but under-perform in\nheadnotes. Through rigorous testing and human expert validation, we demonstrate\nthat while fine-tuning open SLMs significantly improves their translation\nquality, they still lag behind the best zero-shot prompted frontier models such\nas Claude-3.5-Sonnet. Additionally, we present SwiLTra-Judge, a specialized LLM\nevaluation system that aligns best with human expert assessments.",
      "tldr_zh": "本研究针对瑞士的多语种法律环境（如四个官方语言）引发的翻译挑战，引入了SwiLTra-Bench，这是一个包含超过18万对对齐翻译对的多语种基准，涵盖法律、headnotes和新闻稿，用于评估LLM-based翻译系统。系统评估结果显示，前沿models在所有文档类型上表现出色，而专业翻译系统在laws上领先但在headnotes上表现较差；此外，微调开源SLMs能显著改善翻译质量，但仍落后于零-shot prompted的前沿models如Claude-3.5-Sonnet。论文还提出了SwiLTra-Judge，这是一个专门的LLM评估系统，能与人类专家评估高度一致，从而为提升法律翻译效率和公正性提供重要工具。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "68T50",
        "I.2"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01372v1",
      "published_date": "2025-03-03 10:10:30 UTC",
      "updated_date": "2025-03-03 10:10:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:25:45.467090"
    },
    {
      "arxiv_id": "2503.01353v1",
      "title": "Dendron: Enhancing Human Activity Recognition with On-Device TinyML Learning",
      "title_zh": "Dendron：利用设备端 TinyML 学习增强人类活动识别",
      "authors": [
        "Hazem Hesham Yousef Shalby",
        "Manuel Roveri"
      ],
      "abstract": "Human activity recognition (HAR) is a research field that employs Machine\nLearning (ML) techniques to identify user activities. Recent studies have\nprioritized the development of HAR solutions directly executed on wearable\ndevices, enabling the on-device activity recognition. This approach is\nsupported by the Tiny Machine Learning (TinyML) paradigm, which integrates ML\nwithin embedded devices with limited resources. However, existing approaches in\nthe field lack in the capability for on-device learning of new HAR tasks,\nparticularly when supervised data are scarce. To address this limitation, our\npaper introduces Dendron, a novel TinyML methodology designed to facilitate the\non-device learning of new tasks for HAR, even in conditions of limited\nsupervised data. Experimental results on two public-available datasets and an\noff-the-shelf device (STM32-NUCLEO-F401RE) show the effectiveness and\nefficiency of the proposed solution.",
      "tldr_zh": "该论文针对人类活动识别(HAR)领域中现有方法的局限性，提出Dendron，一种新型TinyML方法，支持在资源有限的可穿戴设备上进行新任务的学习，即使监督数据稀缺。Dendron通过增强on-device学习能力，解决了传统HAR方案无法有效适应新场景的问题。实验在两个公开数据集和STM32-NUCLEO-F401RE设备上验证了该方法的有效性和效率，展示了其在实际应用中的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to IEEE SSCI",
      "pdf_url": "http://arxiv.org/pdf/2503.01353v1",
      "published_date": "2025-03-03 09:45:52 UTC",
      "updated_date": "2025-03-03 09:45:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:25:55.397430"
    },
    {
      "arxiv_id": "2503.01345v1",
      "title": "Same Question, Different Words: A Latent Adversarial Framework for Prompt Robustness",
      "title_zh": "翻译失败",
      "authors": [
        "Tingchen Fu",
        "Fazl Barez"
      ],
      "abstract": "Insensitivity to semantically-preserving variations of prompts (paraphrases)\nis crucial for reliable behavior and real-world deployment of large language\nmodels. However, language models exhibit significant performance degradation\nwhen faced with semantically equivalent but differently phrased prompts, and\nexisting solutions either depend on trial-and-error prompt engineering or\nrequire computationally expensive inference-time algorithms. In this study,\nbuilt on the key insight that worst-case prompts exhibit a drift in embedding\nspace, we present Latent Adversarial Paraphrasing (LAP), a dual-loop\nadversarial framework: the inner loop trains a learnable perturbation to serve\nas a \"latent continuous paraphrase\" while preserving semantics through\nLagrangian regulation, and the outer loop optimizes the language model\nparameters on these perturbations. We conduct extensive experiments to\ndemonstrate the effectiveness of LAP across multiple LLM architectures on the\nRobustAlpaca benchmark with a 0.5%-4% absolution improvement on worst-case\nwin-rate compared with vanilla supervised fine-tuning.",
      "tldr_zh": "该研究针对大语言模型(LLMs)对语义等价提示变体（如改写）的敏感性问题，提出Latent Adversarial Paraphrasing (LAP)框架，以提升模型的提示鲁棒性。LAP采用双循环对抗方法：在内循环中，训练可学习的扰动作为“潜在连续改写”，通过Lagrangian regulation确保语义不变；在外循环中，优化LLMs参数以适应这些扰动。实验结果显示，在RobustAlpaca基准上，LAP相比普通监督微调提高了0.5%-4%的绝对最坏情况胜率。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01345v1",
      "published_date": "2025-03-03 09:36:50 UTC",
      "updated_date": "2025-03-03 09:36:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:26:08.861780"
    },
    {
      "arxiv_id": "2503.01332v1",
      "title": "Answer, Refuse, or Guess? Investigating Risk-Aware Decision Making in Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Cheng-Kuang Wu",
        "Zhi Rui Tam",
        "Chieh-Yen Lin",
        "Yun-Nung Chen",
        "Hung-yi Lee"
      ],
      "abstract": "Knowing when to answer or refuse is crucial for safe and reliable\ndecision-making language agents. Although prior work has introduced refusal\nstrategies to boost LMs' reliability, how these models adapt their decisions to\ndifferent risk levels remains underexplored. We formalize the task of\nrisk-aware decision-making, expose critical weaknesses in existing LMs, and\npropose skill-decomposition solutions to mitigate them. Our findings show that\neven cutting-edge LMs--both regular and reasoning models--still require\nexplicit prompt chaining to handle the task effectively, revealing the\nchallenges that must be overcome to achieve truly autonomous decision-making\nagents.",
      "tldr_zh": "本研究探讨了Language Models在风险感知决策中的表现，焦点在于模型如何在不同风险水平下决定回答、拒绝或猜测，以提升安全性和可靠性。研究者形式化了风险感知决策任务，暴露了现有模型的弱点，并提出了基于技能分解的解决方案。实验发现，即使是先进的Language Models和推理模型，也需要显式提示链来有效处理任务，这揭示了实现真正自主决策代理的重大挑战。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "preprint",
      "pdf_url": "http://arxiv.org/pdf/2503.01332v1",
      "published_date": "2025-03-03 09:16:26 UTC",
      "updated_date": "2025-03-03 09:16:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:26:21.182884"
    },
    {
      "arxiv_id": "2503.01329v2",
      "title": "Neural ODE Transformers: Analyzing Internal Dynamics and Adaptive Fine-tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Anh Tong",
        "Thanh Nguyen-Tang",
        "Dongeun Lee",
        "Duc Nguyen",
        "Toan Tran",
        "David Hall",
        "Cheongwoong Kang",
        "Jaesik Choi"
      ],
      "abstract": "Recent advancements in large language models (LLMs) based on transformer\narchitectures have sparked significant interest in understanding their inner\nworkings. In this paper, we introduce a novel approach to modeling transformer\narchitectures using highly flexible non-autonomous neural ordinary differential\nequations (ODEs). Our proposed model parameterizes all weights of attention and\nfeed-forward blocks through neural networks, expressing these weights as\nfunctions of a continuous layer index. Through spectral analysis of the model's\ndynamics, we uncover an increase in eigenvalue magnitude that challenges the\nweight-sharing assumption prevalent in existing theoretical studies. We also\nleverage the Lyapunov exponent to examine token-level sensitivity, enhancing\nmodel interpretability. Our neural ODE transformer demonstrates performance\ncomparable to or better than vanilla transformers across various configurations\nand datasets, while offering flexible fine-tuning capabilities that can adapt\nto different architectural constraints.",
      "tldr_zh": "本研究提出了一种名为Neural ODE Transformers的新模型，使用非自治神经常微分方程（neural ordinary differential equations, ODEs）来参数化Transformer架构中注意力（attention）和前馈（feed-forward）块的权重，这些权重作为连续层索引的函数。作者通过谱分析（spectral analysis）发现特征值幅度增加，这挑战了现有理论中常见的权重共享假设，并利用Lyapunov指数分析token级别的敏感性，以提升模型的可解释性。该模型在各种配置和数据集上表现出与传统Transformer相当或更好的性能，并提供灵活的微调能力，适应不同架构约束。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.01329v2",
      "published_date": "2025-03-03 09:12:14 UTC",
      "updated_date": "2025-04-16 09:54:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:26:32.227163"
    },
    {
      "arxiv_id": "2503.01328v1",
      "title": "PipeOffload: Improving Scalability of Pipeline Parallelism with Memory Optimization",
      "title_zh": "PipeOffload：通过内存优化提升管道并行性的可扩展性",
      "authors": [
        "Xinyi Wan",
        "Penghui Qi",
        "Guangxing Huang",
        "Jialin Li",
        "Min Lin"
      ],
      "abstract": "Pipeline parallelism (PP) is widely used for training large language models\n(LLMs), yet its scalability is often constrained by high activation memory\nconsumption as the number of in-flight microbatches grows with the degree of\nPP. In this paper, we focus on addressing this challenge by leveraging the\nunder-explored memory offload strategy in PP. With empirical study, we discover\nthat in the majority of standard configurations, at least half, and potentially\nall, of the activations can be offloaded with negligible overhead. In the cases\nwhere full overload is not possible, we introduce a novel selective offload\nstrategy that decreases peak activation memory in a better-than-linear manner.\nFurthermore, we integrate memory offload with other techniques to jointly\nconsider overall throughput and memory limitation. Our experiments proves that\nthe per-device activation memory effectively reduces with the total number of\nstages, making PP a stronger alternative than TP, offering up to a 19\\%\nacceleration with even lower memory consumption. The implementation is\nopen-sourced at\n\\href{https://github.com/sail-sg/zero-bubble-pipeline-parallelism}{this url}.",
      "tldr_zh": "这篇论文针对 Pipeline Parallelism (PP) 在训练 Large Language Models (LLMs) 时的高激活内存消耗问题，提出了 PipeOffload 框架，以提升其可扩展性。通过实证研究和新型 selective offload 策略，该方法能够卸载大部分激活内存，并在无法完全卸载时实现更好的-than-linear 峰值内存减少。实验证明，PipeOffload 与其他技术结合后，比 Tensor Parallelism (TP) 快 19%，并显著降低了内存消耗，同时开源了实现代码。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01328v1",
      "published_date": "2025-03-03 09:11:06 UTC",
      "updated_date": "2025-03-03 09:11:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:26:44.699989"
    },
    {
      "arxiv_id": "2503.01323v1",
      "title": "CacheQuant: Comprehensively Accelerated Diffusion Models",
      "title_zh": "CacheQuant：全面加速扩散模型",
      "authors": [
        "Xuewen Liu",
        "Zhikai Li",
        "Qingyi Gu"
      ],
      "abstract": "Diffusion models have gradually gained prominence in the field of image\nsynthesis, showcasing remarkable generative capabilities. Nevertheless, the\nslow inference and complex networks, resulting from redundancy at both temporal\nand structural levels, hinder their low-latency applications in real-world\nscenarios. Current acceleration methods for diffusion models focus separately\non temporal and structural levels. However, independent optimization at each\nlevel to further push the acceleration limits results in significant\nperformance degradation. On the other hand, integrating optimizations at both\nlevels can compound the acceleration effects. Unfortunately, we find that the\noptimizations at these two levels are not entirely orthogonal. Performing\nseparate optimizations and then simply integrating them results in\nunsatisfactory performance. To tackle this issue, we propose CacheQuant, a\nnovel training-free paradigm that comprehensively accelerates diffusion models\nby jointly optimizing model caching and quantization techniques. Specifically,\nwe employ a dynamic programming approach to determine the optimal cache\nschedule, in which the properties of caching and quantization are carefully\nconsidered to minimize errors. Additionally, we propose decoupled error\ncorrection to further mitigate the coupled and accumulated errors step by step.\nExperimental results show that CacheQuant achieves a 5.18 speedup and 4\ncompression for Stable Diffusion on MS-COCO, with only a 0.02 loss in CLIP\nscore. Our code are open-sourced: https://github.com/BienLuky/CacheQuant .",
      "tldr_zh": "扩散模型在图像合成领域表现出色，但受限于推理速度慢和网络复杂性，难以应用于实时场景。论文提出 CacheQuant，一种无需训练的综合加速框架，通过联合优化模型缓存和量化技术来解决这一问题：利用动态编程确定最佳缓存策略，并引入解耦错误修正以最小化错误积累。实验结果显示，在 MS-COCO 数据集上，CacheQuant 为 Stable Diffusion 模型带来 5.18 倍加速和 4 倍压缩，同时仅损失 0.02 的 CLIP score。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.01323v1",
      "published_date": "2025-03-03 09:04:51 UTC",
      "updated_date": "2025-03-03 09:04:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:26:57.012988"
    },
    {
      "arxiv_id": "2503.04801v1",
      "title": "Exploring and Evaluating Multimodal Knowledge Reasoning Consistency of Multimodal Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Boyu Jia",
        "Junzhe Zhang",
        "Huixuan Zhang",
        "Xiaojun Wan"
      ],
      "abstract": "In recent years, multimodal large language models (MLLMs) have achieved\nsignificant breakthroughs, enhancing understanding across text and vision.\nHowever, current MLLMs still face challenges in effectively integrating\nknowledge across these modalities during multimodal knowledge reasoning,\nleading to inconsistencies in reasoning outcomes. To systematically explore\nthis issue, we propose four evaluation tasks and construct a new dataset. We\nconduct a series of experiments on this dataset to analyze and compare the\nextent of consistency degradation in multimodal knowledge reasoning within\nMLLMs. Based on the experimental results, we identify factors contributing to\nthe observed degradation in consistency. Our research provides new insights\ninto the challenges of multimodal knowledge reasoning and offers valuable\nguidance for future efforts aimed at improving MLLMs.",
      "tldr_zh": "本研究探讨了多模态大语言模型 (MLLMs) 在多模态知识推理中的一致性问题，指出这些模型在整合文本和视觉知识时容易出现推理结果不一致。该团队提出四个评估任务并构建了一个新数据集，通过一系列实验分析和比较 MLLMs 的多模态知识推理一致性下降程度。实验结果识别出导致一致性下降的关键因素，并为未来改进 MLLMs 提供了宝贵的见解和指导。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04801v1",
      "published_date": "2025-03-03 09:01:51 UTC",
      "updated_date": "2025-03-03 09:01:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:27:07.489359"
    },
    {
      "arxiv_id": "2503.01314v1",
      "title": "Scaling Law Phenomena Across Regression Paradigms: Multiple and Kernel Approaches",
      "title_zh": "翻译失败",
      "authors": [
        "Yifang Chen",
        "Xuyang Guo",
        "Xiaoyu Li",
        "Yingyu Liang",
        "Zhenmei Shi",
        "Zhao Song"
      ],
      "abstract": "Recently, Large Language Models (LLMs) have achieved remarkable success. A\nkey factor behind this success is the scaling law observed by OpenAI.\nSpecifically, for models with Transformer architecture, the test loss exhibits\na power-law relationship with model size, dataset size, and the amount of\ncomputation used in training, demonstrating trends that span more than seven\norders of magnitude. This scaling law challenges traditional machine learning\nwisdom, notably the Oscar Scissors principle, which suggests that an\noverparametrized algorithm will overfit the training datasets, resulting in\npoor test performance. Recent research has also identified the scaling law in\nsimpler machine learning contexts, such as linear regression. However, fully\nexplaining the scaling law in large practical models remains an elusive goal.\nIn this work, we advance our understanding by demonstrating that the scaling\nlaw phenomenon extends to multiple regression and kernel regression settings,\nwhich are significantly more expressive and powerful than linear methods. Our\nanalysis provides deeper insights into the scaling law, potentially enhancing\nour understanding of LLMs.",
      "tldr_zh": "本研究探讨了scaling law现象在回归范式中的扩展，特别针对multiple regression和kernel regression这些比线性回归更具表现力的方法。论文挑战了传统的Oscar Scissors原则，通过分析发现，模型的测试损失与模型大小、数据集大小及训练计算量仍呈幂律关系，这与Large Language Models (LLMs)中的观察一致。实验结果为理解LLMs提供了更深入的洞见，并有助于解释过参数化模型的泛化性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01314v1",
      "published_date": "2025-03-03 08:57:49 UTC",
      "updated_date": "2025-03-03 08:57:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:27:19.848919"
    },
    {
      "arxiv_id": "2504.06273v1",
      "title": "A Diverse and Effective Retrieval-Based Debt Collection System with Expert Knowledge",
      "title_zh": "基于专家知识的多样且有效的检索型债务回收系统",
      "authors": [
        "Jiaming Luo",
        "Weiyi Luo",
        "Guoqing Sun",
        "Mengchen Zhu",
        "Haifeng Tang",
        "Kunyao Lan",
        "Mengyue Wu",
        "Kenny Q. Zhu"
      ],
      "abstract": "Designing effective debt collection systems is crucial for improving\noperational efficiency and reducing costs in the financial industry. However,\nthe challenges of maintaining script diversity, contextual relevance, and\ncoherence make this task particularly difficult. This paper presents a debt\ncollection system based on real debtor-collector data from a major commercial\nbank. We construct a script library from real-world debt collection\nconversations, and propose a two-stage retrieval based response system for\ncontextual relevance. Experimental results show that our system improves script\ndiversity, enhances response relevance, and achieves practical deployment\nefficiency through knowledge distillation. This work offers a scalable and\nautomated solution, providing valuable insights for advancing debt collection\npractices in real-world applications.",
      "tldr_zh": "这篇论文针对金融行业的债务催收系统，提出了一种基于真实债务人-收款人对话数据的解决方案，以解决脚本多样性、上下文相关性和连贯性的挑战。研究者构建了一个脚本库，并设计了一个两阶段的retrieval-based响应系统，利用专家知识确保响应的准确性和相关性。实验结果表明，该系统显著提高了脚本多样性和响应相关性，并通过knowledge distillation实现了高效的实际部署，为可扩展的自动化债务催收实践提供了宝贵见解。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted by NAACL 2025, Industry Track",
      "pdf_url": "http://arxiv.org/pdf/2504.06273v1",
      "published_date": "2025-03-03 08:56:54 UTC",
      "updated_date": "2025-03-03 08:56:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:27:31.355076"
    },
    {
      "arxiv_id": "2503.01306v1",
      "title": "From Claims to Evidence: A Unified Framework and Critical Analysis of CNN vs. Transformer vs. Mamba in Medical Image Segmentation",
      "title_zh": "从声明到证据：CNN 与 Transformer 与 Mamba 在医疗图像分割中的统一框架和批判性分析",
      "authors": [
        "Pooya Mohammadi Kazaj",
        "Giovanni Baj",
        "Yazdan Salimi",
        "Anselm W. Stark",
        "Waldo Valenzuela",
        "George CM. Siontis",
        "Habib Zaidi",
        "Mauricio Reyes",
        "Christoph Graeni",
        "Isaac Shiri"
      ],
      "abstract": "While numerous architectures for medical image segmentation have been\nproposed, achieving competitive performance with state-of-the-art models\nnetworks such as nnUNet, still leave room for further innovation. In this work,\nwe introduce nnUZoo, an open source benchmarking framework built upon nnUNet,\nwhich incorporates various deep learning architectures, including CNNs,\nTransformers, and Mamba-based models. Using this framework, we provide a fair\ncomparison to demystify performance claims across different medical image\nsegmentation tasks. Additionally, in an effort to enrich the benchmarking, we\nexplored five new architectures based on Mamba and Transformers, collectively\nnamed X2Net, and integrated them into nnUZoo for further evaluation. The\nproposed models combine the features of conventional U2Net, nnUNet, CNN,\nTransformer, and Mamba layers and architectures, called X2Net (UNETR2Net\n(UNETR), SwT2Net (SwinTransformer), SS2D2Net (SwinUMamba), Alt1DM2Net\n(LightUMamba), and MambaND2Net (MambaND)). We extensively evaluate the\nperformance of different models on six diverse medical image segmentation\ndatasets, including microscopy, ultrasound, CT, MRI, and PET, covering various\nbody parts, organs, and labels. We compare their performance, in terms of dice\nscore and computational efficiency, against their baseline models, U2Net, and\nnnUNet. CNN models like nnUNet and U2Net demonstrated both speed and accuracy,\nmaking them effective choices for medical image segmentation tasks.\nTransformer-based models, while promising for certain imaging modalities,\nexhibited high computational costs. Proposed Mamba-based X2Net architecture\n(SS2D2Net) achieved competitive accuracy with no significantly difference from\nnnUNet and U2Net, while using fewer parameters. However, they required\nsignificantly longer training time, highlighting a trade-off between model\nefficiency and computational cost.",
      "tldr_zh": "本研究引入了 nnUZoo 框架，这是一个基于 nnUNet 的开源基准框架，用于公平比较 CNN、Transformer 和 Mamba-based 模型在医疗图像分割任务中的性能。研究者提出了五种新架构（X2Net，包括 UNETR2Net、SwT2Net、SS2D2Net、Alt1DM2Net 和 MambaND2Net），这些模型结合了 U2Net、nnUNet、CNN、Transformer 和 Mamba 的特性，并在六个多样化数据集（如显微镜、超声、CT、MRI 和 PET 图像）上进行了评估。结果表明，CNN 模型如 nnUNet 和 U2Net 在 dice score 和计算效率上表现出色；Transformer 模型虽然在某些模态中表现良好，但计算成本高；Mamba-based X2Net（如 SS2D2Net）实现了与基线模型相当的准确性，同时参数更少，但训练时间显著增加，突显了效率与成本的权衡。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "physics.med-ph"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01306v1",
      "published_date": "2025-03-03 08:44:51 UTC",
      "updated_date": "2025-03-03 08:44:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:27:45.325024"
    },
    {
      "arxiv_id": "2503.01298v1",
      "title": "MINT: Multi-modal Chain of Thought in Unified Generative Models for Enhanced Image Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Yi Wang",
        "Mushui Liu",
        "Wanggui He",
        "Longxiang Zhang",
        "Ziwei Huang",
        "Guanghao Zhang",
        "Fangxun Shu",
        "Zhong Tao",
        "Dong She",
        "Zhelun Yu",
        "Haoyuan Li",
        "Weilong Dai",
        "Mingli Song",
        "Jie Song",
        "Hao Jiang"
      ],
      "abstract": "Unified generative models have demonstrated extraordinary performance in both\ntext and image generation. However, they tend to underperform when generating\nintricate images with various interwoven conditions, which is hard to solely\nrely on straightforward text-to-image generation. In response to this\nchallenge, we introduce MINT, an innovative unified generative model, empowered\nwith native multimodal chain of thought (MCoT) for enhanced image generation\nfor the first time. Firstly, we design Mixture of Transformer Experts\n(MTXpert), an expert-parallel structure that effectively supports both natural\nlanguage generation (NLG) and visual capabilities, while avoiding potential\nmodality conflicts that could hinder the full potential of each modality.\nBuilding on this, we propose an innovative MCoT training paradigm, a\nstep-by-step approach to multimodal thinking, reasoning, and reflection\nspecifically designed to enhance image generation. This paradigm equips MINT\nwith nuanced, element-wise decoupled alignment and a comprehensive\nunderstanding of textual and visual components. Furthermore, it fosters\nadvanced multimodal reasoning and self-reflection, enabling the construction of\nimages that are firmly grounded in the logical relationships between these\nelements. Notably, MINT has been validated to exhibit superior performance\nacross multiple benchmarks for text-to-image (T2I) and image-to-text (I2T)\ntasks.",
      "tldr_zh": "该论文提出 MINT，一种创新的统一生成模型，旨在提升图像生成性能，通过引入原生的多模态链式思考 (Multi-modal Chain of Thought, MCoT) 来处理复杂图像的交织条件问题。MINT 采用 Mixture of Transformer Experts (MTXpert) 结构，支持自然语言生成 (NLG) 和视觉能力，同时避免模态冲突，并通过逐步的多模态思考、推理和反思训练范式，实现元素级解耦对齐和逻辑关系的全面理解。实验结果显示，MINT 在多个基准测试中表现出色，在 text-to-image (T2I) 和 image-to-text (I2T) 任务上优于基线模型，推动了多模态生成领域的进展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01298v1",
      "published_date": "2025-03-03 08:36:16 UTC",
      "updated_date": "2025-03-03 08:36:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:27:58.231340"
    },
    {
      "arxiv_id": "2503.01294v1",
      "title": "Fine-Grained Controllable Apparel Showcase Image Generation via Garment-Centric Outpainting",
      "title_zh": "翻译失败",
      "authors": [
        "Rong Zhang",
        "Jingnan Wang",
        "Zhiwen Zuo",
        "Jianfeng Dong",
        "Wei Li",
        "Chi Wang",
        "Weiwei Xu",
        "Xun Wang"
      ],
      "abstract": "In this paper, we propose a novel garment-centric outpainting (GCO) framework\nbased on the latent diffusion model (LDM) for fine-grained controllable apparel\nshowcase image generation. The proposed framework aims at customizing a fashion\nmodel wearing a given garment via text prompts and facial images. Different\nfrom existing methods, our framework takes a garment image segmented from a\ndressed mannequin or a person as the input, eliminating the need for learning\ncloth deformation and ensuring faithful preservation of garment details. The\nproposed framework consists of two stages. In the first stage, we introduce a\ngarment-adaptive pose prediction model that generates diverse poses given the\ngarment. Then, in the next stage, we generate apparel showcase images,\nconditioned on the garment and the predicted poses, along with specified text\nprompts and facial images. Notably, a multi-scale appearance customization\nmodule (MS-ACM) is designed to allow both overall and fine-grained text-based\ncontrol over the generated model's appearance. Moreover, we leverage a\nlightweight feature fusion operation without introducing any extra encoders or\nmodules to integrate multiple conditions, which is more efficient. Extensive\nexperiments validate the superior performance of our framework compared to\nstate-of-the-art methods.",
      "tldr_zh": "这篇论文提出了一种基于 latent diffusion model (LDM) 的 garment-centric outpainting (GCO) 框架，用于实现细粒度可控的服装展示图像生成，通过文本提示和面部图像自定义时尚模型的穿着。框架分为两个阶段：首先，使用 garment-adaptive pose prediction model 根据输入的服装图像生成多样姿势；其次，结合这些姿势、文本提示和面部图像生成图像，并通过 multi-scale appearance customization module (MS-ACM) 实现整体和细粒度的外观控制，同时采用轻量级特征融合操作提升效率。不同于现有方法，该框架直接使用分割的服装图像，避免学习布料变形并确保细节的忠实保留。实验结果表明，该框架在服装生成任务上优于最先进方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01294v1",
      "published_date": "2025-03-03 08:30:37 UTC",
      "updated_date": "2025-03-03 08:30:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:28:11.477936"
    },
    {
      "arxiv_id": "2504.06272v1",
      "title": "RAVEN: An Agentic Framework for Multimodal Entity Discovery from Large-Scale Video Collections",
      "title_zh": "翻译失败",
      "authors": [
        "Kevin Dela Rosa"
      ],
      "abstract": "We present RAVEN an adaptive AI agent framework designed for multimodal\nentity discovery and retrieval in large-scale video collections. Synthesizing\ninformation across visual, audio, and textual modalities, RAVEN autonomously\nprocesses video data to produce structured, actionable representations for\ndownstream tasks. Key contributions include (1) a category understanding step\nto infer video themes and general-purpose entities, (2) a schema generation\nmechanism that dynamically defines domain-specific entities and attributes, and\n(3) a rich entity extraction process that leverages semantic retrieval and\nschema-guided prompting. RAVEN is designed to be model-agnostic, allowing the\nintegration of different vision-language models (VLMs) and large language\nmodels (LLMs) based on application-specific requirements. This flexibility\nsupports diverse applications in personalized search, content discovery, and\nscalable information retrieval, enabling practical applications across vast\ndatasets.",
      "tldr_zh": "该研究介绍了RAVEN，一种适应性AI代理框架，用于从大规模视频集合中进行多模态实体发现和检索。框架通过整合视觉、音频和文本模态的信息，实现自主处理视频数据，并生成结构化的可操作表示，其关键贡献包括：(1) 类别理解步骤，用于推断视频主题和通用实体，(2) 模式生成机制，动态定义领域特定实体和属性，以及(3) 实体提取过程，利用语义检索和模式引导提示。RAVEN设计为模型无关，支持整合不同视觉语言模型(VLMs)和大型语言模型(LLMs)，从而适用于个性化搜索、内容发现和可扩展信息检索等应用场景。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Presented at AI Agent for Information Retrieval: Generating and\n  Ranking (Agent4IR) @ AAAI 2025\n  [https://sites.google.com/view/ai4ir/aaai-2025]",
      "pdf_url": "http://arxiv.org/pdf/2504.06272v1",
      "published_date": "2025-03-03 08:28:58 UTC",
      "updated_date": "2025-03-03 08:28:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:28:21.254155"
    },
    {
      "arxiv_id": "2503.01290v1",
      "title": "ACTIVA: Amortized Causal Effect Estimation without Graphs via Transformer-based Variational Autoencoder",
      "title_zh": "翻译失败",
      "authors": [
        "Andreas Sauter",
        "Saber Salehkaleybar",
        "Aske Plaat",
        "Erman Acar"
      ],
      "abstract": "Predicting the distribution of outcomes under hypothetical interventions is\ncrucial in domains like healthcare, economics, and policy-making. Current\nmethods often rely on strong assumptions, such as known causal graphs or\nparametric models, and lack amortization across problem instances, limiting\ntheir practicality. We propose a novel transformer-based conditional\nvariational autoencoder architecture, named ACTIVA, that extends causal\ntransformer encoders to predict causal effects as mixtures of Gaussians. Our\nmethod requires no causal graph and predicts interventional distributions given\nonly observational data and a queried intervention. By amortizing over many\nsimulated instances, it enables zero-shot generalization to novel datasets\nwithout retraining. Experiments demonstrate accurate predictions for synthetic\nand semi-synthetic data, showcasing the effectiveness of our graph-free,\namortized causal inference approach.",
      "tldr_zh": "该论文提出了一种名为 ACTIVA 的新型框架，用于因果效应估计（causal effect estimation），它基于 Transformer 的条件变分自编码器（Transformer-based Variational Autoencoder），无需依赖因果图（causal graphs）即可从观察数据和干预查询中预测干预分布作为高斯混合分布（mixtures of Gaussians）。ACTIVA 通过对多个模拟实例进行摊销（amortized）处理，实现零样本泛化（zero-shot generalization），无需重新训练即可应用于新数据集。实验结果显示，该方法在合成和半合成数据上实现了准确预测，证明了其无图、摊销因果推理（amortized causal inference）方法的有效性，尤其适用于医疗、经济和政策领域的决策支持。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01290v1",
      "published_date": "2025-03-03 08:28:25 UTC",
      "updated_date": "2025-03-03 08:28:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:28:33.882968"
    },
    {
      "arxiv_id": "2503.01287v1",
      "title": "Robust Simulation-Based Inference under Missing Data via Neural Processes",
      "title_zh": "翻译失败",
      "authors": [
        "Yogesh Verma",
        "Ayush Bharti",
        "Vikas Garg"
      ],
      "abstract": "Simulation-based inference (SBI) methods typically require fully observed\ndata to infer parameters of models with intractable likelihood functions.\nHowever, datasets often contain missing values due to incomplete observations,\ndata corruptions (common in astrophysics), or instrument limitations (e.g., in\nhigh-energy physics applications). In such scenarios, missing data must be\nimputed before applying any SBI method. We formalize the problem of missing\ndata in SBI and demonstrate that naive imputation methods can introduce bias in\nthe estimation of SBI posterior. We also introduce a novel amortized method\nthat addresses this issue by jointly learning the imputation model and the\ninference network within a neural posterior estimation (NPE) framework.\nExtensive empirical results on SBI benchmarks show that our approach provides\nrobust inference outcomes compared to standard baselines for varying levels of\nmissing data. Moreover, we demonstrate the merits of our imputation model on\ntwo real-world bioactivity datasets (Adrenergic and Kinase assays). Code is\navailable at https://github.com/Aalto-QuML/RISE.",
      "tldr_zh": "这项研究针对 Simulation-based Inference (SBI) 在数据缺失场景下的鲁棒性问题，提出了一种新型方法，通过 Neural Processes 在 Neural Posterior Estimation (NPE) 框架中联合学习填充模型和推理网络，以避免传统填充方法导致的后验估计偏差。该方法能够有效处理数据缺失问题，如天文学或高能物理中的数据损坏，并在 SBI 基准测试中表现出色，与标准基线相比提供更稳健的推断结果。此外，在真实世界生物活性数据集（如 Adrenergic 和 Kinase assays）上验证了其实际价值，并公开了代码以供进一步应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.01287v1",
      "published_date": "2025-03-03 08:22:01 UTC",
      "updated_date": "2025-03-03 08:22:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:28:44.676183"
    },
    {
      "arxiv_id": "2503.01273v1",
      "title": "OptMetaOpenFOAM: Large Language Model Driven Chain of Thought for Sensitivity Analysis and Parameter Optimization based on CFD",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxuan Chen",
        "Long Zhang",
        "Xu Zhu",
        "Hua Zhou",
        "Zhuyin Ren"
      ],
      "abstract": "Merging natural language interfaces with computational fluid dynamics (CFD)\nworkflows presents transformative opportunities for both industry and research.\nIn this study, we introduce OptMetaOpenFOAM - a novel framework that bridges\nMetaOpenFOAM with external analysis and optimization tool libraries through a\nlarge language model (LLM)-driven chain-of-thought (COT) methodology. By\nautomating complex CFD tasks via natural language inputs, the framework\nempowers non-expert users to perform sensitivity analyses and parameter\noptimizations with markedly improved efficiency. The test dataset comprises 11\ndistinct CFD analysis or optimization tasks, including a baseline simulation\ntask derived from an OpenFOAM tutorial covering fluid dynamics, combustion, and\nheat transfer. Results confirm that OptMetaOpenFOAM can accurately interpret\nuser requirements expressed in natural language and effectively invoke external\ntool libraries alongside MetaOpenFOAM to complete the tasks. Furthermore,\nvalidation on a non-OpenFOAM tutorial case - namely, a hydrogen combustion\nchamber - demonstrates that a mere 200-character natural language input can\ntrigger a sequence of simulation, postprocessing, analysis, and optimization\ntasks spanning over 2,000 lines of code. These findings underscore the\ntransformative potential of LLM-driven COT methodologies in linking external\ntool for advanced analysis and optimization, positioning OptMetaOpenFOAM as an\neffective tool that streamlines CFD simulations and enhances their convenience\nand efficiency for both industrial and research applications. Code is available\nat https://github.com/Terry-cyx/MetaOpenFOAM.",
      "tldr_zh": "本文提出 OptMetaOpenFOAM 框架，通过 Large Language Model (LLM) 驱动的 Chain-of-Thought (COT) 方法，将 MetaOpenFOAM 与外部分析和优化工具库整合，实现 Computational Fluid Dynamics (CFD) 工作流的自然语言自动化。该框架使非专家用户能够高效进行敏感性分析和参数优化，在11个测试任务中准确解释输入并完成任务。实验结果显示，仅200字符的自然语言输入即可触发超过2000行代码的模拟、后处理和优化序列，显著提升了 CFD 模拟的便利性和效率，为工业和研究应用提供了一个强大的工具。",
      "categories": [
        "cs.AI",
        "physics.flu-dyn"
      ],
      "primary_category": "cs.AI",
      "comment": "26 pages,11 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.01273v1",
      "published_date": "2025-03-03 07:55:43 UTC",
      "updated_date": "2025-03-03 07:55:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:28:57.275710"
    },
    {
      "arxiv_id": "2503.01937v1",
      "title": "Synthetic Tabular Data Detection In the Wild",
      "title_zh": "翻译失败",
      "authors": [
        "G. Charbel N. Kindji",
        "Elisa Fromont",
        "Lina Maria Rojas-Barahona",
        "Tanguy Urvoy"
      ],
      "abstract": "Detecting synthetic tabular data is essential to prevent the distribution of\nfalse or manipulated datasets that could compromise data-driven\ndecision-making. This study explores whether synthetic tabular data can be\nreliably identified across different tables. This challenge is unique to\ntabular data, where structures (such as number of columns, data types, and\nformats) can vary widely from one table to another. We propose four\ntable-agnostic detectors combined with simple preprocessing schemes that we\nevaluate on six evaluation protocols, with different levels of ''wildness''.\nOur results show that cross-table learning on a restricted set of tables is\npossible even with naive preprocessing schemes. They confirm however that\ncross-table transfer (i.e. deployment on a table that has not been seen before)\nis challenging. This suggests that sophisticated encoding schemes are required\nto handle this problem.",
      "tldr_zh": "这项研究探讨了检测合成 tabular data 的重要性，以防止虚假数据集影响数据驱动决策，并强调了 tabular data 结构多样性（如列数、数据类型和格式）带来的独特挑战。研究者提出了四种 table-agnostic detectors，结合简单预处理方案，并在六种不同“野性”水平的评估协议上进行测试。结果显示，跨表学习在有限数据集上可行，但 cross-table transfer（部署到未见过的表格）仍具挑战性，表明需要更复杂的编码方案来提升检测效果。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB",
        "cs.NE",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "International Symposium on Intelligent Data Analysis, May 2025,\n  Konstanz, Germany",
      "pdf_url": "http://arxiv.org/pdf/2503.01937v1",
      "published_date": "2025-03-03 07:53:16 UTC",
      "updated_date": "2025-03-03 07:53:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:29:08.509094"
    },
    {
      "arxiv_id": "2503.01936v1",
      "title": "Decision-Focused Fine-Tuning of Time Series Foundation Models for Dispatchable Feeder Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Maximilian Beichter",
        "Nils Friederich",
        "Janik Pinter",
        "Dorina Werling",
        "Kaleb Phipps",
        "Sebastian Beichter",
        "Oliver Neumann",
        "Ralf Mikut",
        "Veit Hagenmeyer",
        "Benedikt Heidrich"
      ],
      "abstract": "Time series foundation models provide a universal solution for generating\nforecasts to support optimization problems in energy systems. Those foundation\nmodels are typically trained in a prediction-focused manner to maximize\nforecast quality. In contrast, decision-focused learning directly improves the\nresulting value of the forecast in downstream optimization rather than merely\nmaximizing forecasting quality. The practical integration of forecast values\ninto forecasting models is challenging, particularly when addressing complex\napplications with diverse instances, such as buildings. This becomes even more\ncomplicated when instances possess specific characteristics that require\ninstance-specific, tailored predictions to increase the forecast value. To\ntackle this challenge, we use decision-focused fine-tuning within time series\nfoundation models to offer a scalable and efficient solution for\ndecision-focused learning applied to the dispatchable feeder optimization\nproblem. To obtain more robust predictions for scarce building data, we use\nMoirai as a state-of-the-art foundation model, which offers robust and\ngeneralized results with few-shot parameter-efficient fine-tuning. Comparing\nthe decision-focused fine-tuned Moirai with a state-of-the-art classical\nprediction-focused fine-tuning Morai, we observe an improvement of 9.45% in\naverage total daily costs.",
      "tldr_zh": "这篇论文提出了一种决策导向微调（decision-focused fine-tuning）方法，用于时间序列基础模型（time series foundation models），以优化能源系统中的可调度馈线优化（dispatchable feeder optimization）问题。该方法直接提升预测在下游优化中的价值，而不是仅关注预测准确性，通过使用Moirai模型的少样本参数高效微调，处理建筑领域稀缺数据的挑战。与传统的预测导向微调相比，实验结果显示，决策导向微调的Moirai在平均每日总成本上改善了9.45%。这为复杂应用中的决策优化提供了可扩展的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01936v1",
      "published_date": "2025-03-03 07:47:20 UTC",
      "updated_date": "2025-03-03 07:47:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:29:20.977027"
    },
    {
      "arxiv_id": "2503.01268v1",
      "title": "Multi-Level Collaboration in Model Merging",
      "title_zh": "模型合并中的多层次协作",
      "authors": [
        "Qi Li",
        "Runpeng Yu",
        "Xinchao Wang"
      ],
      "abstract": "Parameter-level model merging is an emerging paradigm in multi-task learning\nwith significant promise. Previous research has explored its connections with\nprediction-level model ensembling-commonly viewed as the upper bound for\nmerging-to reveal the potential of achieving performance consistency between\nthe two. However, this observation relies on certain preconditions, such as\nbeing limited to two models, using ViT-based models, and all models are\nfine-tuned from the same pre-trained checkpoint. To further understand the\nintrinsic connections between model merging and model ensembling, this paper\nexplores an interesting possibility: If these restrictions are removed, can\nperformance consistency still be achieved between merging and ensembling? To\nanswer this question, we first theoretically establish a performance\ncorrelation between merging and ensembling. We find that even when previous\nrestrictions are not met, there is still a way for model merging to attain a\nnear-identical and superior performance similar to that of ensembling. To\nverify whether our findings are practical, we introduce a validation framework\ntermed Neural Ligand (NeuLig). The learning process of NeuLig is meticulously\ndesigned with a specialized loss function supported by theoretical foundations.\nExperimental results demonstrate the robust resilience of NeuLig in terms of\nboth model scale and the number of collaborating models. For instance, for the\ncase involving 5 CLIP-ViT-B/32 models, parameter-level merging achieves the\nsame performance as prediction-level ensembling (merging: 95.44% vs.\nensembling: 95.46%).",
      "tldr_zh": "本论文探讨了参数级模型合并在多任务学习中的潜力，特别分析了其与预测级模型集成之间的性能相关性，挑战了先前限制（如仅限于两个模型或ViT-based模型）。作者理论上建立了模型合并与集成的性能一致性，并引入了Neural Ligand (NeuLig)框架，该框架使用专门的损失函数来验证这一相关性。实验结果显示，NeuLig在多模型协作中表现出色，例如在5个CLIP-ViT-B/32模型上，参数级合并的性能（95.44%）几乎与预测级集成（95.46%）相当，从而证明了模型合并的实用性和鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01268v1",
      "published_date": "2025-03-03 07:45:04 UTC",
      "updated_date": "2025-03-03 07:45:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:29:32.405159"
    },
    {
      "arxiv_id": "2503.01266v1",
      "title": "Voice Cloning for Dysarthric Speech Synthesis: Addressing Data Scarcity in Speech-Language Pathology",
      "title_zh": "用于构音障碍语音合成的语音克隆：解决言语语言病理学中的数据稀缺问题",
      "authors": [
        "Birger Moell",
        "Fredrik Sand Aronsson"
      ],
      "abstract": "This study explores voice cloning to generate synthetic speech replicating\nthe unique patterns of individuals with dysarthria. Using the TORGO dataset, we\naddress data scarcity and privacy challenges in speech-language pathology. Our\ncontributions include demonstrating that voice cloning preserves dysarthric\nspeech characteristics, analyzing differences between real and synthetic data,\nand discussing implications for diagnostics, rehabilitation, and communication.\nWe cloned voices from dysarthric and control speakers using a commercial\nplatform, ensuring gender-matched synthetic voices. A licensed speech-language\npathologist (SLP) evaluated a subset for dysarthria, speaker gender, and\nsynthetic indicators. The SLP correctly identified dysarthria in all cases and\nspeaker gender in 95% but misclassified 30% of synthetic samples as real,\nindicating high realism. Our results suggest synthetic speech effectively\ncaptures disordered characteristics and that voice cloning has advanced to\nproduce high-quality data resembling real speech, even to trained\nprofessionals. This has critical implications for healthcare, where synthetic\ndata can mitigate data scarcity, protect privacy, and enhance AI-driven\ndiagnostics. By enabling the creation of diverse, high-quality speech datasets,\nvoice cloning can improve generalizable models, personalize therapy, and\nadvance assistive technologies for dysarthria.\n  We publicly release our synthetic dataset to foster further research and\ncollaboration, aiming to develop robust models that improve patient outcomes in\nspeech-language pathology.",
      "tldr_zh": "本研究探讨了语音克隆（voice cloning）技术，用于生成合成语音以复制dysarthria（构音障碍）个体的独特语音模式，旨在解决speech-language pathology（言语语言病理学）中的数据稀缺性和隐私挑战。研究使用TORGO dataset和商业平台克隆dysarthric和对照说话者的语音，确保性别匹配，并由licensed speech-language pathologist (SLP)评估，结果显示SLP正确识别所有dysarthria病例、95%的说话者性别，但将30%的合成样本误认为真实，证明合成语音高度真实且能有效捕捉disordered characteristics。总体贡献包括分析真实与合成数据差异、讨论对诊断、康复和沟通的含义，并公开发布合成数据集，以促进AI驱动医疗应用、提升模型泛化性和个性化治疗。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01266v1",
      "published_date": "2025-03-03 07:44:49 UTC",
      "updated_date": "2025-03-03 07:44:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:29:45.426219"
    },
    {
      "arxiv_id": "2503.01238v1",
      "title": "A Taxonomy for Evaluating Generalist Robot Policies",
      "title_zh": "评估通用机器人策略的分类学",
      "authors": [
        "Jensen Gao",
        "Suneel Belkhale",
        "Sudeep Dasari",
        "Ashwin Balakrishna",
        "Dhruv Shah",
        "Dorsa Sadigh"
      ],
      "abstract": "Machine learning for robotics promises to unlock generalization to novel\ntasks and environments. Guided by this promise, many recent works have focused\non scaling up robot data collection and developing larger, more expressive\npolicies to achieve this. But how do we measure progress towards this goal of\npolicy generalization in practice? Evaluating and quantifying generalization is\nthe Wild West of modern robotics, with each work proposing and measuring\ndifferent types of generalization in their own, often difficult to reproduce,\nsettings. In this work, our goal is (1) to outline the forms of generalization\nwe believe are important in robot manipulation in a comprehensive and\nfine-grained manner, and (2) to provide reproducible guidelines for measuring\nthese notions of generalization. We first propose STAR-Gen, a taxonomy of\ngeneralization for robot manipulation structured around visual, semantic, and\nbehavioral generalization. We discuss how our taxonomy encompasses most prior\nnotions of generalization in robotics. Next, we instantiate STAR-Gen with a\nconcrete real-world benchmark based on the widely-used Bridge V2 dataset. We\nevaluate a variety of state-of-the-art models on this benchmark to demonstrate\nthe utility of our taxonomy in practice. Our taxonomy of generalization can\nyield many interesting insights into existing models: for example, we observe\nthat current vision-language-action models struggle with various types of\nsemantic generalization, despite the promise of pre-training on internet-scale\nlanguage datasets. We believe STAR-Gen and our guidelines can improve the\ndissemination and evaluation of progress towards generalization in robotics,\nwhich we hope will guide model design and future data collection efforts. We\nprovide videos and demos at our website stargen-taxonomy.github.io.",
      "tldr_zh": "该论文提出了一种名为 STAR-Gen 的分类法，用于评估通用机器人政策的泛化能力，旨在解决当前机器人研究中泛化评估标准不统一的问题。该分类法细致地涵盖了机器人操作中的视觉 generalization、语义 generalization 和行为 generalization 等重要形式，并基于广泛使用的 Bridge V2 数据集创建了一个可重现的实世界基准。通过评估多种最先进模型，研究发现当前的 vision-language-action 模型尽管利用互联网规模语言预训练，但仍难以处理各种语义 generalization 挑战。该框架有望标准化机器人泛化评估，指导未来的模型设计和数据收集努力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "25 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.01238v1",
      "published_date": "2025-03-03 07:03:00 UTC",
      "updated_date": "2025-03-03 07:03:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:29:57.149496"
    },
    {
      "arxiv_id": "2503.01236v1",
      "title": "LLM-Advisor: An LLM Benchmark for Cost-efficient Path Planning across Multiple Terrains",
      "title_zh": "LLM-Advisor：用于跨越多种地形的成本",
      "authors": [
        "Ling Xiao",
        "Toshihiko Yamasaki"
      ],
      "abstract": "Multi-terrain cost-efficient path planning is a crucial task in robot\nnavigation, requiring the identification of a path from the start to the goal\nthat not only avoids obstacles but also minimizes travel costs. This is\nespecially crucial for real-world applications where robots need to navigate\ndiverse terrains in outdoor environments, where recharging or refueling is\ndifficult. However, there is very limited research on this topic. In this\npaper, we develop a prompt-based approach, LLM-Advisor, which leverages large\nlanguage models (LLMs) as effective advisors for path planning. The LLM-Advisor\nselectively provides suggestions, demonstrating its ability to recognize when\nno modifications are necessary. When suggestions are made, 70.59% of the paths\nsuggested for the A* algorithm, 69.47% for the RRT* algorithm, and 78.70% for\nthe LLM-A* algorithm achieve greater cost efficiency. Since LLM-Advisor may\noccasionally lack common sense in their suggestions, we propose two\nhallucination-mitigation strategies. Furthermore, we experimentally verified\nthat GPT-4o performs poorly in zero-shot path planning, even when terrain\ndescriptions are clearly provided, demonstrating its low spatial awareness. We\nalso experimentally demonstrate that using an LLM as an advisor is more\neffective than directly integrating it into the path-planning loop. Since LLMs\nmay generate hallucinations, using LLMs in the loop of a search-based method\n(such as A*) may lead to a higher number of failed paths, demonstrating that\nour proposed LLM-Advisor is a better choice.",
      "tldr_zh": "该研究针对多地形成本高效路径规划问题，提出了一种基于提示的框架 LLM-Advisor，利用大型语言模型 (LLMs) 作为路径规划顾问，帮助算法（如 A*、RRT* 和 LLM-A*）选择性地优化路径，从而最小化旅行成本。实验结果显示，LLM-Advisor 的建议使70.59%的 A* 路径、69.47%的 RRT* 路径和78.70%的 LLM-A* 路径实现了更高的成本效率。针对 LLMs 可能产生的 hallucinations，该框架引入了两种缓解策略，并证明使用 LLMs 作为顾问比直接整合到路径规划循环中更有效，同时 GPT-4o 在零样本场景下表现出低空间意识。整体上，该方法为机器人导航提供了更可靠的基准，提升了户外环境的路径规划性能。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01236v1",
      "published_date": "2025-03-03 07:02:10 UTC",
      "updated_date": "2025-03-03 07:02:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:30:08.856413"
    },
    {
      "arxiv_id": "2503.01232v1",
      "title": "Learning Covariance-Based Multi-Scale Representation of Neuroimaging Measures for Alzheimer Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Seunghun Baek",
        "Injun Choi",
        "Mustafa Dere",
        "Minjeong Kim",
        "Guorong Wu",
        "Won Hwa Kim"
      ],
      "abstract": "Stacking excessive layers in DNN results in highly underdetermined system\nwhen training samples are limited, which is very common in medical\napplications. In this regard, we present a framework capable of deriving an\nefficient high-dimensional space with reasonable increase in model size. This\nis done by utilizing a transform (i.e., convolution) that leverages scale-space\ntheory with covariance structure. The overall model trains on this transform\ntogether with a downstream classifier (i.e., Fully Connected layer) to capture\nthe optimal multi-scale representation of the original data which corresponds\nto task-specific components in a dual space. Experiments on neuroimaging\nmeasures from Alzheimer's Disease Neuroimaging Initiative (ADNI) study show\nthat our model performs better and converges faster than conventional models\neven when the model size is significantly reduced. The trained model is made\ninterpretable using gradient information over the multi-scale transform to\ndelineate personalized AD-specific regions in the brain.",
      "tldr_zh": "本文提出了一种基于协方差的多尺度表示学习框架，用于从神经影像数据中分类阿尔茨海默病（Alzheimer Classification），以解决深度神经网络（DNN）在训练样本有限时的欠定问题。该框架利用卷积变换结合规模空间理论（scale-space theory）和协方差结构，训练模型捕获原始数据的优化多尺度表示，并与下游分类器（如Fully Connected layer）整合。实验结果显示，在Alzheimer's Disease Neuroimaging Initiative (ADNI)数据集上，该模型比传统模型性能更优、收敛更快，即使模型大小显著减少；此外，通过梯度信息实现了模型的可解释性，识别个性化的AD特定脑区。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ISBI 2023",
      "pdf_url": "http://arxiv.org/pdf/2503.01232v1",
      "published_date": "2025-03-03 06:55:35 UTC",
      "updated_date": "2025-03-03 06:55:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:30:20.912831"
    },
    {
      "arxiv_id": "2503.04800v1",
      "title": "HoH: A Dynamic Benchmark for Evaluating the Impact of Outdated Information on Retrieval-Augmented Generation",
      "title_zh": "HoH：用于评估过时信息对检索增强生成影响的动态基准",
      "authors": [
        "Jie Ouyang",
        "Tingyue Pan",
        "Mingyue Cheng",
        "Ruiran Yan",
        "Yucong Luo",
        "Jiaying Lin",
        "Qi Liu"
      ],
      "abstract": "While Retrieval-Augmented Generation (RAG) has emerged as an effective\napproach for addressing the knowledge outdating problem in Large Language\nModels (LLMs), it faces a critical challenge: the prevalence of outdated\ninformation in knowledge bases. Current research primarily focuses on\nincorporating up-to-date information, yet the impact of outdated information\ncoexisting in retrieval sources remains inadequately addressed. To bridge this\ngap, we introduce HoH, the first benchmark specifically designed to evaluate\nthe impact of outdated information on RAG. Our benchmark leverages token-level\ndiff algorithms combined with LLM pipelines to efficiently create a large-scale\nQA dataset that accurately captures temporal knowledge evolution in real-world\nfacts. Through comprehensive experiments, we reveal that outdated information\nsignificantly degrades RAG performance in two critical ways: (1) it\nsubstantially reduces response accuracy by distracting models from correct\ninformation, and (2) it can mislead models into generating potentially harmful\noutputs, even when current information is available. Current RAG approaches\nstruggle with both retrieval and generation aspects when handling outdated\ninformation. These findings highlight the urgent need for innovative solutions\nto address the temporal challenges in RAG.",
      "tldr_zh": "本文提出HoH基准，这是首个动态评估系统，用于研究过时信息对Retrieval-Augmented Generation (RAG)的影响，以解决Large Language Models (LLMs)中知识过时问题。HoH通过token-level diff算法结合LLM管道，高效创建大规模QA数据集，精确捕捉真实世界事实的temporal knowledge evolution。实验发现，过时信息会显著降低RAG性能，包括分散模型注意力导致响应准确性下降，以及误导生成潜在有害输出，即使当前信息可用。研究强调了当前RAG方法在检索和生成方面的不足，并呼吁开发创新解决方案应对这些时间相关挑战。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04800v1",
      "published_date": "2025-03-03 06:54:05 UTC",
      "updated_date": "2025-03-03 06:54:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:30:32.261166"
    },
    {
      "arxiv_id": "2503.01220v2",
      "title": "Tera-MIND: Tera-scale mouse brain simulation via spatial mRNA-guided diffusion",
      "title_zh": "翻译失败",
      "authors": [
        "Jiqing Wu",
        "Ingrid Berg",
        "Yawei Li",
        "Ender Konukoglu",
        "Viktor H. Koelzer"
      ],
      "abstract": "Holistic 3D modeling of molecularly defined brain structures is crucial for\nunderstanding complex brain functions. Emerging tissue profiling technologies\nenable the construction of a comprehensive atlas of the mammalian brain with\nsub-cellular resolution and spatially resolved gene expression data. However,\nsuch tera-scale volumetric datasets present significant computational\nchallenges in understanding complex brain functions within their native 3D\nspatial context. Here, we propose the novel generative approach\n$\\textbf{Tera-MIND}$, which can simulate $\\textbf{Tera}$-scale $\\textbf{M}$ouse\nbra$\\textbf{IN}$s in 3D using a patch-based and boundary-aware\n$\\textbf{D}$iffusion model. Taking spatial transcriptomic data as the\nconditional input, we generate virtual mouse brains with comprehensive cellular\nmorphological detail at teravoxel scale. Through the lens of 3D $gene$-$gene$\nself-attention, we identify spatial molecular interactions for key\ntranscriptomic pathways in the murine brain, exemplified by glutamatergic and\ndopaminergic neuronal systems. Importantly, these $in$-$silico$ biological\nfindings are consistent and reproducible across three tera-scale virtual mouse\nbrains. Therefore, Tera-MIND showcases a promising path toward efficient and\ngenerative simulations of whole organ systems for biomedical research. Project\nwebsite: https://musikisomorphie.github.io/Tera-MIND.html",
      "tldr_zh": "本研究提出 Tera-MIND，一种基于空间 mRNA 引导的生成式方法，用于模拟 tera-scale 的 3D 鼠脑模型。该方法采用 patch-based 和 boundary-aware diffusion 模型，以空间转录组数据作为条件输入，生成包含详细细胞形态的虚拟鼠脑组织。通过 3D gene-gene self-attention 机制，论文识别了关键转录组通路的分子互动，如 glutamatergic 和 dopaminergic 神经元系统，并验证了这些 in-silico 发现的跨虚拟脑一致性和可重复性。Tera-MIND 为生物医学研究提供了高效的整体器官系统模拟路径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01220v2",
      "published_date": "2025-03-03 06:37:30 UTC",
      "updated_date": "2025-03-04 06:50:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:30:44.846194"
    },
    {
      "arxiv_id": "2503.04798v1",
      "title": "Advancing MAPF towards the Real World: A Scalable Multi-Agent Realistic Testbed (SMART)",
      "title_zh": "翻译失败",
      "authors": [
        "Jingtian Yan",
        "Zhifei Li",
        "William Kang",
        "Yulun Zhang",
        "Stephen Smith",
        "Jiaoyang Li"
      ],
      "abstract": "We present Scalable Multi-Agent Realistic Testbed (SMART), a realistic and\nefficient software tool for evaluating Multi-Agent Path Finding (MAPF)\nalgorithms. MAPF focuses on planning collision-free paths for a group of\nagents. While state-of-the-art MAPF algorithms can plan paths for hundreds of\nrobots in seconds, they often rely on simplified robot models, making their\nreal-world performance unclear. Researchers typically lack access to hundreds\nof physical robots in laboratory settings to evaluate the algorithms.\nMeanwhile, industrial professionals who lack expertise in MAPF require an\neasy-to-use simulator to efficiently test and understand the performance of\nMAPF algorithms in their specific settings. SMART fills this gap with several\nadvantages: (1) SMART uses a physics-engine-based simulator to create realistic\nsimulation environments, accounting for complex real-world factors such as\nrobot kinodynamics and execution uncertainties, (2) SMART uses an execution\nmonitor framework based on the Action Dependency Graph, facilitating seamless\nintegration with various MAPF algorithms and robot models, and (3) SMART scales\nto thousands of robots. In addition, we use SMART to explore and demonstrate\nresearch questions about the execution of MAPF algorithms in real-world\nscenarios. The code is publicly available at\nhttps://jingtianyan.github.io/publication/2025-smart.",
      "tldr_zh": "本研究引入了Scalable Multi-Agent Realistic Testbed (SMART)，一个高效的软件工具，用于评估Multi-Agent Path Finding (MAPF)算法在真实世界的性能，解决现有算法依赖简化模型的问题。\nSMART采用基于物理引擎的模拟器，模拟复杂因素如机器人动力学和执行不确定性，并通过Action Dependency Graph框架实现与多种MAPF算法和机器人模型的无缝集成，支持扩展到数千个代理。\n实验结果显示，SMART有助于研究人员和工业专业人士测试算法在真实场景中的表现，并公开提供了代码以促进进一步应用。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04798v1",
      "published_date": "2025-03-03 05:26:59 UTC",
      "updated_date": "2025-03-03 05:26:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:30:58.490217"
    },
    {
      "arxiv_id": "2503.01935v1",
      "title": "MultiAgentBench: Evaluating the Collaboration and Competition of LLM agents",
      "title_zh": "MultiAgentBench：评估 LLM 代理的协作和竞争",
      "authors": [
        "Kunlun Zhu",
        "Hongyi Du",
        "Zhaochen Hong",
        "Xiaocheng Yang",
        "Shuyi Guo",
        "Zhe Wang",
        "Zhenhailong Wang",
        "Cheng Qian",
        "Xiangru Tang",
        "Heng Ji",
        "Jiaxuan You"
      ],
      "abstract": "Large Language Models (LLMs) have shown remarkable capabilities as autonomous\nagents, yet existing benchmarks either focus on single-agent tasks or are\nconfined to narrow domains, failing to capture the dynamics of multi-agent\ncoordination and competition. In this paper, we introduce MultiAgentBench, a\ncomprehensive benchmark designed to evaluate LLM-based multi-agent systems\nacross diverse, interactive scenarios. Our framework measures not only task\ncompletion but also the quality of collaboration and competition using novel,\nmilestone-based key performance indicators. Moreover, we evaluate various\ncoordination protocols (including star, chain, tree, and graph topologies) and\ninnovative strategies such as group discussion and cognitive planning. Notably,\ngpt-4o-mini reaches the average highest task score, graph structure performs\nthe best among coordination protocols in the research scenario, and cognitive\nplanning improves milestone achievement rates by 3%. Code and datasets are\npublic available at https://github.com/MultiagentBench/MARBLE.",
      "tldr_zh": "本论文引入 MultiAgentBench，一个全面基准，用于评估大型语言模型 (LLMs) 代理在多智能体系统中的协作和竞争表现，解决了现有基准对单智能体任务或狭窄领域的局限性。该基准不仅测量任务完成，还通过基于里程碑的关键性能指标 (key performance indicators) 评估协作质量和竞争动态，并测试了各种协调协议（如星型、链型、树型和图型拓扑）以及创新策略如群体讨论和认知规划。实验结果显示，gpt-4o-mini 在平均任务分数上达到最高，图型结构在研究场景中表现最佳，而认知规划提高了 3% 的里程碑达成率。代码和数据集已在 https://github.com/MultiagentBench/MARBLE 公开可用。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.MA",
      "comment": "https://github.com/MultiagentBench/MARBLE",
      "pdf_url": "http://arxiv.org/pdf/2503.01935v1",
      "published_date": "2025-03-03 05:18:50 UTC",
      "updated_date": "2025-03-03 05:18:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:31:11.416165"
    },
    {
      "arxiv_id": "2503.05797v1",
      "title": "Fault Localization and State Estimation of Power Grid under Parallel Cyber-Physical Attacks",
      "title_zh": "翻译失败",
      "authors": [
        "Junhao Ren",
        "Kai Zhao",
        "Guangxiao Zhang",
        "Xinghua Liu",
        "Chao Zhai",
        "Gaoxi Xiao"
      ],
      "abstract": "Parallel cyber-physical attacks (PCPA) refer to those attacks on power grids\nby disturbing/cutting off physical transmission lines and meanwhile blocking\ntransmission of measurement data to dwarf or delay the system protection and\nrecovery actions. Such fierce hostile attacks impose critical threats to the\nmodern power grids when there is a fusion of power grids and telecommunication\ntechnologies. In this paper, we investigate the fault diagnosis problem of\nfaulty transmission lines under a broader spectrum of PCPA for a linearized (or\nDC) power flow model. The physical attack mechanism of PCPA includes not only\ndisconnection but also admittance value modification on transmission lines, for\nexample, by invading distributed flexible AC transmission system (D-FACTS). To\ntackle the problem, we first recover the information of voltage phase angles\nwithin the attacked area. Using the information of voltage phase angle and\npower injection of buses, a graph attention network-based fault localization\n(GAT-FL) algorithm is proposed to find the locations of the physical attacks.\nBy capitalizing on the feature extraction capability of the GAT on graph data,\nthe fault localization algorithm outperforms the existing results when under\ncyber attacks, e.g., denial of service (DoS) attacks. A line state\nidentification algorithm is then developed to identify the states of the\ntransmission lines within the attacked area. Specifically, the algorithm\nrestores the power injection of buses within the attacked area and then\nidentities the state of all the transmission lines within the attacked area by\nsolving a linear programming (LP) problem. Experimental simulations are\neffectiveness of the proposed fault diagnosis algorithms.",
      "tldr_zh": "本论文研究了在平行网络物理攻击（PCPA）下电力网格的故障定位和状态估计问题，其中PCPA包括切断传输线、修改导纳值（如入侵D-FACTS）和阻断测量数据。作者首先恢复受攻击区域的电压相角信息，然后提出基于图注意力网络（GAT）的故障定位算法（GAT-FL），该算法利用GAT在图数据上的特征提取能力，在网络攻击（如DoS攻击）下比现有方法表现更优。随后，开发了线路状态识别算法，通过恢复受攻击区域的功率注入并解决线性规划（LP）问题来识别传输线路的状态。实验模拟验证了这些算法的有效性，为电力网格在更广泛PCPA场景下的故障诊断提供了可靠解决方案。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "10 pages, 3 figures, 5 tables, journal",
      "pdf_url": "http://arxiv.org/pdf/2503.05797v1",
      "published_date": "2025-03-03 05:10:41 UTC",
      "updated_date": "2025-03-03 05:10:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:31:21.737849"
    },
    {
      "arxiv_id": "2503.02897v1",
      "title": "ClipGrader: Leveraging Vision-Language Models for Robust Label Quality Assessment in Object Detection",
      "title_zh": "ClipGrader：利用视觉-",
      "authors": [
        "Hong Lu",
        "Yali Bian",
        "Rahul C. Shah"
      ],
      "abstract": "High-quality annotations are essential for object detection models, but\nensuring label accuracy - especially for bounding boxes - remains both\nchallenging and costly. This paper introduces ClipGrader, a novel approach that\nleverages vision-language models to automatically assess the accuracy of\nbounding box annotations. By adapting CLIP (Contrastive Language-Image\nPre-training) to evaluate both class label correctness and spatial precision of\nbounding box, ClipGrader offers an effective solution for grading object\ndetection labels. Tested on modified object detection datasets with\nartificially disturbed bounding boxes, ClipGrader achieves 91% accuracy on COCO\nwith a 1.8% false positive rate. Moreover, it maintains 87% accuracy with a\n2.1% false positive rate when trained on just 10% of the COCO data. ClipGrader\nalso scales effectively to larger datasets such as LVIS, achieving 79% accuracy\nacross 1,203 classes. Our experiments demonstrate ClipGrader's ability to\nidentify errors in existing COCO annotations, highlighting its potential for\ndataset refinement. When integrated into a semi-supervised object detection\n(SSOD) model, ClipGrader readily improves the pseudo label quality, helping\nachieve higher mAP (mean Average Precision) throughout the training process.\nClipGrader thus provides a scalable AI-assisted tool for enhancing annotation\nquality control and verifying annotations in large-scale object detection\ndatasets.",
      "tldr_zh": "本文提出 ClipGrader，一种利用视觉语言模型 CLIP 来自动评估物体检测中边界框标注质量的新方法，以解决标注准确性挑战。ClipGrader 通过适应 CLIP 模型，检查类标签的正确性和边界框的空间精度，提供高效的标注评估工具。在实验中，它在 COCO 数据集上达到 91% 准确率（假阳性率 1.8%），并在仅使用 10% 数据训练时保持 87% 准确率；在 LVIS 数据集上实现 79% 准确率，覆盖 1203 个类。整合到半监督物体检测 (SSOD) 模型中后，ClipGrader 提升了伪标签质量，提高了 mAP，从而为大型数据集的标注优化和质量控制提供了可扩展的 AI 辅助手段。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.02897v1",
      "published_date": "2025-03-03 05:02:31 UTC",
      "updated_date": "2025-03-03 05:02:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:31:35.558843"
    },
    {
      "arxiv_id": "2503.05796v1",
      "title": "Towards Multi-Stakeholder Evaluation of ML Models: A Crowdsourcing Study on Metric Preferences in Job-matching System",
      "title_zh": "翻译失败",
      "authors": [
        "Takuya Yokota",
        "Yuri Nakao"
      ],
      "abstract": "While machine learning (ML) technology affects diverse stakeholders, there is\nno one-size-fits-all metric to evaluate the quality of outputs, including\nperformance and fairness. Using predetermined metrics without soliciting\nstakeholder opinions is problematic because it leads to an unfair disregard for\nstakeholders in the ML pipeline. In this study, to establish practical ways to\nincorporate diverse stakeholder opinions into the selection of metrics for ML,\nwe investigate participants' preferences for different metrics by using\ncrowdsourcing. We ask 837 participants to choose a better model from two\nhypothetical ML models in a hypothetical job-matching system twenty times and\ncalculate their utility values for seven metrics. To examine the participants'\nfeedback in detail, we divide them into five clusters based on their utility\nvalues and analyze the tendencies of each cluster, including their preferences\nfor metrics and common attributes. Based on the results, we discuss the points\nthat should be considered when selecting appropriate metrics and evaluating ML\nmodels with multiple stakeholders.",
      "tldr_zh": "本研究探讨了机器学习(ML)模型评估中如何纳入多利益相关者(stakeholders)意见的问题，因为使用预定指标可能忽略多样化视角。研究通过众包(crowdsourcing)方式，让837名参与者在假设的求职匹配系统中比较两个ML模型，共进行20次选择，并计算他们对七个指标的效用值。参与者被分为五群(cluster)进行分析，揭示了不同群体的指标偏好和共同属性。最终，研究讨论了在选择适当指标和评估多利益相关者ML模型时，需要考虑的关键点，以促进更公平的评估框架。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "This version of the contribution has been accepted for publication,\n  after peer review (when applicable) but is not the Version of Record and does\n  not reflect post-acceptance improvements, or any corrections. Use of this\n  Accepted Version is subject to the publisher's Accepted Manuscript terms of\n  use\n  https://www.springernature.com/gp/open-research/policies/accepted-manuscript-terms",
      "pdf_url": "http://arxiv.org/pdf/2503.05796v1",
      "published_date": "2025-03-03 04:51:33 UTC",
      "updated_date": "2025-03-03 04:51:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:31:48.120736"
    },
    {
      "arxiv_id": "2503.01176v1",
      "title": "Prognostics and Health Management of Wafer Chemical-Mechanical Polishing System using Autoencoder",
      "title_zh": "翻译失败",
      "authors": [
        "Kart-Leong Lim",
        "Rahul Dutta"
      ],
      "abstract": "The Prognostics and Health Management Data Challenge (PHM) 2016 tracks the\nhealth state of components of a semiconductor wafer polishing process. The\nultimate goal is to develop an ability to predict the measurement on the wafer\nsurface wear through monitoring the components health state. This translates to\ncost saving in large scale production. The PHM dataset contains many time\nseries measurements not utilized by traditional physics based approach. On the\nother hand task, applying a data driven approach such as deep learning to the\nPHM dataset is non-trivial. The main issue with supervised deep learning is\nthat class label is not available to the PHM dataset. Second, the feature space\ntrained by an unsupervised deep learner is not specifically targeted at the\npredictive ability or regression. In this work, we propose using the\nautoencoder based clustering whereby the feature space trained is found to be\nmore suitable for performing regression. This is due to having a more compact\ndistribution of samples respective to their nearest cluster means. We justify\nour claims by comparing the performance of our proposed method on the PHM\ndataset with several baselines such as the autoencoder as well as\nstate-of-the-art approaches.",
      "tldr_zh": "该论文针对半导体晶圆化学机械抛光系统的预后和健康管理（PHM），利用PHM 2016数据集来预测晶圆表面磨损，从而降低大规模生产成本。作者提出了一种基于Autoencoder的聚类方法，通过训练更紧凑的特征空间来提升回归任务的性能，解决传统监督深度学习中缺乏标签的问题。实验结果显示，该方法在PHM数据集上的表现优于Autoencoder等基线和最先进方法，证明了其在健康状态监控中的有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01176v1",
      "published_date": "2025-03-03 04:48:34 UTC",
      "updated_date": "2025-03-03 04:48:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:31:59.032986"
    },
    {
      "arxiv_id": "2503.01163v1",
      "title": "Bandit-Based Prompt Design Strategy Selection Improves Prompt Optimizers",
      "title_zh": "基于多臂老虎机的提示设计策略选择提升提示优化器",
      "authors": [
        "Rin Ashizawa",
        "Yoichi Hirose",
        "Nozomu Yoshinari",
        "Kento Uchida",
        "Shinichi Shirakawa"
      ],
      "abstract": "Prompt optimization aims to search for effective prompts that enhance the\nperformance of large language models (LLMs). Although existing prompt\noptimization methods have discovered effective prompts, they often differ from\nsophisticated prompts carefully designed by human experts. Prompt design\nstrategies, representing best practices for improving prompt performance, can\nbe key to improving prompt optimization. Recently, a method termed the\nAutonomous Prompt Engineering Toolbox (APET) has incorporated various prompt\ndesign strategies into the prompt optimization process. In APET, the LLM is\nneeded to implicitly select and apply the appropriate strategies because prompt\ndesign strategies can have negative effects. This implicit selection may be\nsuboptimal due to the limited optimization capabilities of LLMs. This paper\nintroduces Optimizing Prompts with sTrategy Selection (OPTS), which implements\nexplicit selection mechanisms for prompt design. We propose three mechanisms,\nincluding a Thompson sampling-based approach, and integrate them into\nEvoPrompt, a well-known prompt optimizer. Experiments optimizing prompts for\ntwo LLMs, Llama-3-8B-Instruct and GPT-4o mini, were conducted using BIG-Bench\nHard. Our results show that the selection of prompt design strategies improves\nthe performance of EvoPrompt, and the Thompson sampling-based mechanism\nachieves the best overall results. Our experimental code is provided at\nhttps://github.com/shiralab/OPTS .",
      "tldr_zh": "本研究针对提示优化（prompt optimization）中现有方法（如 APET）依赖大型语言模型（LLMs）隐式选择策略导致性能 suboptimal 的问题，提出了一种显式策略选择机制的框架 OPTS（Optimizing Prompts with sTrategy Selection）。OPTS 包括三种机制，其中基于 Thompson sampling 的方法尤为突出，并将其整合到 EvoPrompt 优化器中，以更有效地应用提示设计策略。实验在 Llama-3-8B-Instruct 和 GPT-4o mini 模型上使用 BIG-Bench Hard 进行测试，结果显示 OPTS 显著提升了 EvoPrompt 的性能，Thompson sampling 机制取得了最佳整体效果。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01163v1",
      "published_date": "2025-03-03 04:24:04 UTC",
      "updated_date": "2025-03-03 04:24:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:32:12.095745"
    },
    {
      "arxiv_id": "2503.01152v1",
      "title": "STGAN: Spatial-temporal Graph Autoregression Network for Pavement Distress Deterioration Prediction",
      "title_zh": "STGAN：时空图自回归网络用于路面病害恶化预测",
      "authors": [
        "Shilin Tong",
        "Difei Wu",
        "Xiaona Liu",
        "Le Zheng",
        "Yuchuan Du",
        "Difan Zou"
      ],
      "abstract": "Pavement distress significantly compromises road integrity and poses risks to\ndrivers. Accurate prediction of pavement distress deterioration is essential\nfor effective road management, cost reduction in maintenance, and improvement\nof traffic safety. However, real-world data on pavement distress is usually\ncollected irregularly, resulting in uneven, asynchronous, and sparse\nspatial-temporal datasets. This hinders the application of existing\nspatial-temporal models, such as DCRNN, since they are only applicable to\nregularly and synchronously collected data. To overcome these challenges, we\npropose the Spatial-Temporal Graph Autoregression Network (STGAN), a novel\ngraph neural network model designed for accurately predicting irregular\npavement distress deterioration using complex spatial-temporal data.\nSpecifically, STGAN integrates the temporal domain into the spatial domain,\ncreating a larger graph where nodes are represented by spatial-temporal tuples\nand edges are formed based on a similarity-based connection mechanism.\nFurthermore, based on the constructed spatiotemporal graph, we formulate\npavement distress deterioration prediction as a graph autoregression task,\ni.e., the graph size increases incrementally and the prediction is performed\nsequentially. This is accomplished by a novel spatial-temporal attention\nmechanism deployed by STGAN. Utilizing the ConTrack dataset, which contains\npavement distress records collected from different locations in Shanghai, we\ndemonstrate the superior performance of STGAN in capturing spatial-temporal\ncorrelations and addressing the aforementioned challenges. Experimental results\nfurther show that STGAN outperforms baseline models, and ablation studies\nconfirm the effectiveness of its novel modules. Our findings contribute to\npromoting proactive road maintenance decision-making and ultimately enhancing\nroad safety and resilience.",
      "tldr_zh": "路面损坏会影响道路完整性和驾驶安全，但现有模型如 DCRNN 仅适用于规则数据，无法处理真实世界的不规则、异步和稀疏的空间-时间数据集。  \n本文提出 Spatial-Temporal Graph Autoregression Network (STGAN)，一种新型图神经网络模型，通过将时间域整合到空间域构建更大的图结构，并采用基于相似性的连接机制和空间-时间注意力机制，将路面损坏恶化预测转化为图自回归任务。  \n在 ConTrack 数据集上，STGAN 显著优于基线模型，准确捕捉空间-时间相关性，实验结果显示其性能提升，并通过消融研究验证了新模块的有效性，最终有助于促进主动道路维护决策，提高道路安全和韧性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 16 figures, 4 tables, accepted by IEEE Transactions on\n  Intelligent Transportation Systems (TITS)",
      "pdf_url": "http://arxiv.org/pdf/2503.01152v1",
      "published_date": "2025-03-03 03:59:34 UTC",
      "updated_date": "2025-03-03 03:59:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:32:25.238037"
    },
    {
      "arxiv_id": "2503.01151v1",
      "title": "ReaderLM-v2: Small Language Model for HTML to Markdown and JSON",
      "title_zh": "ReaderLM-v2：用于 HTML 到 Markdown 和 JSON 的小型语言模型",
      "authors": [
        "Feng Wang",
        "Zesheng Shi",
        "Bo Wang",
        "Nan Wang",
        "Han Xiao"
      ],
      "abstract": "We present ReaderLM-v2, a compact 1.5 billion parameter language model\ndesigned for efficient web content extraction. Our model processes documents up\nto 512K tokens, transforming messy HTML into clean Markdown or JSON formats\nwith high accuracy -- making it an ideal tool for grounding large language\nmodels. The model's effectiveness results from two key innovations: (1) a\nthree-stage data synthesis pipeline that generates high quality, diverse\ntraining data by iteratively drafting, refining, and critiquing web content\nextraction; and (2) a unified training framework combining continuous\npre-training with multi-objective optimization. Intensive evaluation\ndemonstrates that ReaderLM-v2 outperforms GPT-4o-2024-08-06 and other larger\nmodels by 15-20\\% on carefully curated benchmarks, particularly excelling at\ndocuments exceeding 100K tokens, while maintaining significantly lower\ncomputational requirements.",
      "tldr_zh": "我们介绍了 ReaderLM-v2，这是一个紧凑的 1.5 亿参数小型语言模型，专为高效网页内容提取设计，能够处理高达 512K 标记的文档，并将杂乱的 HTML 转换为干净的 Markdown 或 JSON 格式，从而为大型语言模型提供可靠的基础。模型的关键创新包括一个三阶段数据合成管道（通过迭代起草、完善和批评生成高质量、多样训练数据）和一个统一的训练框架（结合连续预训练与多目标优化）。在评估中，ReaderLM-v2 在精心策划的基准测试中比 GPT-4o-2024-08-06 和其他更大模型高出 15-20% 的性能，尤其在超过 100K 标记的文档上表现出色，同时保持显著更低的计算需求。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "68T50",
        "I.2.7; I.2.10"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 10-12 refs",
      "pdf_url": "http://arxiv.org/pdf/2503.01151v1",
      "published_date": "2025-03-03 03:57:04 UTC",
      "updated_date": "2025-03-03 03:57:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:32:37.340932"
    },
    {
      "arxiv_id": "2503.01148v2",
      "title": "Dynamic spillovers and investment strategies across artificial intelligence ETFs, artificial intelligence tokens, and green markets",
      "title_zh": "翻译失败",
      "authors": [
        "Ying-Hui Shao",
        "Yan-Hong Yang",
        "Wei-Xing Zhou"
      ],
      "abstract": "This paper investigates the risk spillovers among AI ETFs, AI tokens, and\ngreen markets using the R2 decomposition method. We reveal several key\ninsights. First, the overall transmission connectedness index (TCI) closely\naligns with the contemporaneous TCI, while the lagged TCI is significantly\nlower. Second, AI ETFs and clean energy act as risk transmitters, whereas AI\ntokens and green bond function as risk receivers. Third, AI tokens are\ndifficult to hedge and provide limited hedging ability compared to AI ETFs and\ngreen assets. However, multivariate portfolios effectively reduce AI tokens\ninvestment risk. Among them, the minimum correlation portfolio outperforms the\nminimum variance and minimum connectedness portfolios.",
      "tldr_zh": "本研究使用 R2 decomposition 方法分析了 AI ETFs、AI tokens 和绿色市场之间的风险溢出效应。结果显示，总传输连接性指数 (TCI) 与同期 TCI 高度相关，而滞后 TCI 显著较低；AI ETFs 和清洁能源作为风险传输者，而 AI tokens 和绿色债券则作为风险接收者。AI tokens 难以对冲，且其对冲能力不如 AI ETFs 和绿色资产；然而，多变量投资组合可有效降低 AI tokens 的投资风险，其中最小相关性组合的表现优于最小方差和最小连接性组合。总的来说，该研究为跨 AI 和绿色市场的投资策略提供了重要指导。",
      "categories": [
        "q-fin.RM",
        "cs.AI"
      ],
      "primary_category": "q-fin.RM",
      "comment": "24 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.01148v2",
      "published_date": "2025-03-03 03:53:33 UTC",
      "updated_date": "2025-03-29 11:40:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:32:48.984623"
    },
    {
      "arxiv_id": "2503.01144v1",
      "title": "One-shot In-context Part Segmentation",
      "title_zh": "一-shot 情境内部分分割",
      "authors": [
        "Zhenqi Dai",
        "Ting Liu",
        "Xingxing Zhang",
        "Yunchao Wei",
        "Yanning Zhang"
      ],
      "abstract": "In this paper, we present the One-shot In-context Part Segmentation (OIParts)\nframework, designed to tackle the challenges of part segmentation by leveraging\nvisual foundation models (VFMs). Existing training-based one-shot part\nsegmentation methods that utilize VFMs encounter difficulties when faced with\nscenarios where the one-shot image and test image exhibit significant variance\nin appearance and perspective, or when the object in the test image is\npartially visible. We argue that training on the one-shot example often leads\nto overfitting, thereby compromising the model's generalization capability. Our\nframework offers a novel approach to part segmentation that is training-free,\nflexible, and data-efficient, requiring only a single in-context example for\nprecise segmentation with superior generalization ability. By thoroughly\nexploring the complementary strengths of VFMs, specifically DINOv2 and Stable\nDiffusion, we introduce an adaptive channel selection approach by minimizing\nthe intra-class distance for better exploiting these two features, thereby\nenhancing the discriminatory power of the extracted features for the\nfine-grained parts. We have achieved remarkable segmentation performance across\ndiverse object categories. The OIParts framework not only eliminates the need\nfor extensive labeled data but also demonstrates superior generalization\nability. Through comprehensive experimentation on three benchmark datasets, we\nhave demonstrated the superiority of our proposed method over existing part\nsegmentation approaches in one-shot settings.",
      "tldr_zh": "这篇论文提出了 OIParts 框架，这是一个无训练的 one-shot In-context Part Segmentation 方法，利用视觉基础模型（VFMs）如 DINOv2 和 Stable Diffusion 来解决现有方法的泛化问题，例如当 one-shot 图像与测试图像在外观和视角上差异大时。框架通过自适应通道选择（minimizing intra-class distance）来挖掘这些模型的互补优势，提升提取特征的区分能力，从而实现精确的细粒度部分分割。实验结果显示，OIParts 在三个基准数据集上表现出色，超越现有方法，并展示了优越的泛化能力，而无需大量标注数据。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2503.01144v1",
      "published_date": "2025-03-03 03:50:54 UTC",
      "updated_date": "2025-03-03 03:50:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:33:00.338801"
    },
    {
      "arxiv_id": "2503.01141v2",
      "title": "How Well do LLMs Compress Their Own Chain-of-Thought? A Token Complexity Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Ayeong Lee",
        "Ethan Che",
        "Tianyi Peng"
      ],
      "abstract": "Chain-of-thought prompting has emerged as a powerful technique for enabling\nlarge language models (LLMs) to solve complex reasoning tasks. However, these\nreasoning chains can be verbose, raising concerns about efficiency. In\nresponse, recent works have sought to decrease response lengths through simple\nprompting strategies (e.g. 'be concise'). In this work, we conduct the first\nsystematic study of the relationship between reasoning length and model\nperformance across a diverse range of compression instructions (e.g. 'use 10\nwords or less' or 'remove all punctuation'). In doing so, we discover a\nuniversal tradeoff between reasoning length and accuracy that persists across\neven very distinct reasoning chains. We demonstrate that this tradeoff emerges\nfrom a sharp threshold behavior at the question level: each task has an\nintrinsic 'token complexity' - a minimal number of tokens required for\nsuccessful problem-solving. We show how token complexity enables us to compute\ninformation-theoretic limits on the accuracy-compression tradeoff, and find\nthat prompt-based compression strategies operate far from these theoretical\nlimits. This suggests there may be significant room for improvement and our\nframework provides a benchmark to help researchers evaluate progress in\nreasoning efficiency. Our work also highlights the importance of adaptive\ncompression -- giving shorter responses for easier questions -- and we show\nthat token complexity is a useful tool for measuring this capability.",
      "tldr_zh": "本研究系统探讨了大型语言模型（LLMs）在压缩自身链式思维推理（Chain-of-Thought）时的性能，焦点在于推理长度与准确率之间的权衡关系。研究者通过测试多种压缩指令（如“be concise”或“use 10 words or less”），发现了一个普遍的权衡：在不同任务中，缩短推理长度往往会降低准确率。论文引入了“token complexity”概念，即每个任务所需的最小令牌数，用于计算信息论限制，并证明现有提示-based 压缩策略远未达到这些理论极限。最终，该框架为评估推理效率提供了基准，并强调了自适应压缩（如针对简单问题缩短响应）的必要性，以提升LLMs的实际应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01141v2",
      "published_date": "2025-03-03 03:48:20 UTC",
      "updated_date": "2025-04-01 00:41:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:33:11.635255"
    },
    {
      "arxiv_id": "2503.01139v2",
      "title": "Can Large Language Models Help Experimental Design for Causal Discovery?",
      "title_zh": "大语言模型是否能帮助因果发现的实验设计？",
      "authors": [
        "Junyi Li",
        "Yongqiang Chen",
        "Chenxi Liu",
        "Qianyi Cai",
        "Tongliang Liu",
        "Bo Han",
        "Kun Zhang",
        "Hui Xiong"
      ],
      "abstract": "Designing proper experiments and selecting optimal intervention targets is a\nlongstanding problem in scientific or causal discovery. Identifying the\nunderlying causal structure from observational data alone is inherently\ndifficult. Obtaining interventional data, on the other hand, is crucial to\ncausal discovery, yet it is usually expensive and time-consuming to gather\nsufficient interventional data to facilitate causal discovery. Previous\napproaches commonly utilize uncertainty or gradient signals to determine the\nintervention targets. However, numerical-based approaches may yield suboptimal\nresults due to the inaccurate estimation of the guiding signals at the\nbeginning when with limited interventional data. In this work, we investigate a\ndifferent approach, whether we can leverage Large Language Models (LLMs) to\nassist with the intervention targeting in causal discovery by making use of the\nrich world knowledge about the experimental design in LLMs. Specifically, we\npresent Large Language Model Guided Intervention Targeting (LeGIT) -- a robust\nframework that effectively incorporates LLMs to augment existing numerical\napproaches for the intervention targeting in causal discovery. Across 4\nrealistic benchmark scales, LeGIT demonstrates significant improvements and\nrobustness over existing methods and even surpasses humans, which demonstrates\nthe usefulness of LLMs in assisting with experimental design for scientific\ndiscovery.",
      "tldr_zh": "本研究探讨大型语言模型（LLMs）是否能辅助因果发现中的实验设计问题，特别是选择最佳干预目标以克服从观察数据中识别因果结构的挑战。现有方法依赖不确定性或梯度信号，但这些数值方法在数据有限时可能导致次优结果。作者提出 Large Language Model Guided Intervention Targeting (LeGIT) 框架，该框架利用 LLMs 的丰富世界知识来增强现有数值方法，从而更有效地确定干预目标。在 4 个真实基准测试中，LeGIT 显著提高了性能和鲁棒性，甚至超越人类水平，证明了 LLMs 在科学发现实验设计中的潜在价值。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "stat.ME"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01139v2",
      "published_date": "2025-03-03 03:43:05 UTC",
      "updated_date": "2025-03-04 04:19:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:33:23.244125"
    },
    {
      "arxiv_id": "2503.01134v1",
      "title": "Statistical Tractability of Off-policy Evaluation of History-dependent Policies in POMDPs",
      "title_zh": "翻译失败",
      "authors": [
        "Yuheng Zhang",
        "Nan Jiang"
      ],
      "abstract": "We investigate off-policy evaluation (OPE), a central and fundamental problem\nin reinforcement learning (RL), in the challenging setting of Partially\nObservable Markov Decision Processes (POMDPs) with large observation spaces.\nRecent works of Uehara et al. (2023a); Zhang & Jiang (2024) developed a\nmodel-free framework and identified important coverage assumptions (called\nbelief and outcome coverage) that enable accurate OPE of memoryless policies\nwith polynomial sample complexities, but handling more general target policies\nthat depend on the entire observable history remained an open problem. In this\nwork, we prove information-theoretic hardness for model-free OPE of\nhistory-dependent policies in several settings, characterized by additional\nassumptions imposed on the behavior policy (memoryless vs. history-dependent)\nand/or the state-revealing property of the POMDP (single-step vs. multi-step\nrevealing). We further show that some hardness can be circumvented by a natural\nmodel-based algorithm -- whose analysis has surprisingly eluded the literature\ndespite the algorithm's simplicity -- demonstrating provable separation between\nmodel-free and model-based OPE in POMDPs.",
      "tldr_zh": "本文研究了在部分可观测马尔可夫决策过程（POMDPs）中，对依赖历史（history-dependent policies）的策略进行off-policy evaluation (OPE)的统计可行性，特别是在观察空间较大的场景下。作者证明了无模型方法在多种设置下（如行为策略为无记忆或依赖历史，以及POMDP的状态揭示属性为单步或多步）的OPE存在信息理论硬度，表明准确评估这些策略需要超出多项式样本复杂度的资源。同时，提出一个简单的基于模型算法能绕过部分硬度问题，展示了model-free和model-based OPE在POMDPs中的可证明分离，为强化学习（RL）中的策略评估提供了新的理论洞见。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01134v1",
      "published_date": "2025-03-03 03:29:05 UTC",
      "updated_date": "2025-03-03 03:29:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:33:35.025241"
    },
    {
      "arxiv_id": "2503.01131v1",
      "title": "Beyond QA Pairs: Assessing Parameter-Efficient Fine-Tuning for Fact Embedding in LLMs",
      "title_zh": "超越问答对：评估大语言模型中事实嵌入的参数高效微调",
      "authors": [
        "Shivam Ratnakar",
        "Abhiroop Talasila",
        "Raghav Chamadiya",
        "Nikhil Agarwal",
        "Vinayak K Doifode"
      ],
      "abstract": "This paper presents an extensive examination of Parameter-Efficient\nFine-Tuning (PEFT) for embedding domain specific facts into Large Language\nModels (LLMs), focusing on improving the fine-tuning process by categorizing\nquestion-answer (QA) pairs into Factual and Conceptual classes using a\nBERT-based classifier. Two distinct Llama-2 models are fine-tuned based on\nthese classifications and evaluated using larger models like GPT-3.5 Turbo and\nGemini. Our results indicate that models trained on conceptual datasets\noutperform those trained on factual datasets. Additionally, we compare the\nefficiency of two synthetic fine-tuning dataset generation techniques, D-RAG\nand D-Naive, with D-Naive demonstrating superior performance. Although PEFT has\nshown effectiveness, our research indicates that it may not be the most optimal\nmethod for embedding facts into LLMs. However, it has demonstrated exceptional\nperformance in instruction-based tasks. Our findings are reinforced by a\n1000-sample dataset in the data center domain, where the fine-tuned Llama-2 7B\nmodel significantly outperforms the baseline model in generating product\nrecommendations. Our study highlights the importance of QA pair categorization\nand synthetic dataset generation techniques in enhancing the performance of\nLLMs in specific domains.",
      "tldr_zh": "本研究评估了 Parameter-Efficient Fine-Tuning (PEFT) 在将特定领域事实嵌入 Large Language Models (LLMs) 中的效果，通过使用 BERT-based classifier 将 QA pairs 分为 Factual 和 Conceptual 类，并对两个 Llama-2 模型进行微调。实验结果显示，基于 Conceptual 数据集训练的模型表现优于 Factual 数据集，且 D-Naive 合成数据集生成技术比 D-RAG 更有效。虽然后者证明 PEFT 在指令任务中表现出色，但可能并非嵌入事实的最优方法。最终，在数据中心领域的 1000 样本数据集上，微调后的 Llama-2 7B 模型在生成产品推荐任务中显著超越基线模型，强调了 QA pair 分类和合成数据集生成技术的重要性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Presented at the Workshop on Preparing Good Data for Generative AI:\n  Challenges and Approaches (Good-Data) in conjunction with AAAI 2025. The\n  authors retain the copyright",
      "pdf_url": "http://arxiv.org/pdf/2503.01131v1",
      "published_date": "2025-03-03 03:26:30 UTC",
      "updated_date": "2025-03-03 03:26:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:33:48.218684"
    },
    {
      "arxiv_id": "2503.01126v2",
      "title": "Constrained multi-fidelity Bayesian optimization with automatic stop condition",
      "title_zh": "具有自动停止条件的约束多保真度贝叶斯优化",
      "authors": [
        "Zahra Zanjani Foumani",
        "Ramin Bostanabad"
      ],
      "abstract": "Bayesian optimization (BO) is increasingly employed in critical applications\nto find the optimal design with minimal cost. While BO is known for its sample\nefficiency, relying solely on costly high-fidelity data can still result in\nhigh costs. This is especially the case in constrained search spaces where BO\nmust not only optimize but also ensure feasibility. A related issue in the BO\nliterature is the lack of a systematic stopping criterion. To solve these\nchallenges, we develop a constrained cost-aware multi-fidelity BO (CMFBO)\nframework whose goal is to minimize overall sampling costs by utilizing\ninexpensive low-fidelity sources while ensuring feasibility. In our case, the\nconstraints can change across the data sources and may be even black-box\nfunctions. We also introduce a systematic stopping criterion that addresses the\nlong-lasting issue associated with BO's convergence assessment. Our framework\nis publicly available on GitHub through the GP+ Python package and herein we\nvalidate it's efficacy on multiple benchmark problems.",
      "tldr_zh": "该论文针对贝叶斯优化（BO）在受约束搜索空间中的高采样成本问题，提出了一种受约束的成本感知多-fidelity BO（CMFBO）框架，以最小化整体成本并确保可行性。该框架通过利用低成本的低-fidelity 数据源，同时处理跨数据源变化的约束（包括黑箱函数），来优化设计过程。论文还引入了一个系统停止标准，用于评估 BO 的收敛，避免了传统方法的局限性。在多个基准问题上验证显示，CMFBO 框架有效提升了效率，并已公开在 GitHub 的 GP+ Python 包中。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01126v2",
      "published_date": "2025-03-03 03:13:35 UTC",
      "updated_date": "2025-03-21 22:41:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:34:00.866816"
    },
    {
      "arxiv_id": "2503.01931v1",
      "title": "Adversarial Generative Flow Network for Solving Vehicle Routing Problems",
      "title_zh": "翻译失败",
      "authors": [
        "Ni Zhang",
        "Jingfeng Yang",
        "Zhiguang Cao",
        "Xu Chi"
      ],
      "abstract": "Recent research into solving vehicle routing problems (VRPs) has gained\nsignificant traction, particularly through the application of deep\n(reinforcement) learning for end-to-end solution construction. However, many\ncurrent construction-based neural solvers predominantly utilize Transformer\narchitectures, which can face scalability challenges and struggle to produce\ndiverse solutions. To address these limitations, we introduce a novel framework\nbeyond Transformer-based approaches, i.e., Adversarial Generative Flow Networks\n(AGFN). This framework integrates the generative flow network (GFlowNet)-a\nprobabilistic model inherently adept at generating diverse solutions\n(routes)-with a complementary model for discriminating (or evaluating) the\nsolutions. These models are trained alternately in an adversarial manner to\nimprove the overall solution quality, followed by a proposed hybrid decoding\nmethod to construct the solution. We apply the AGFN framework to solve the\ncapacitated vehicle routing problem (CVRP) and travelling salesman problem\n(TSP), and our experimental results demonstrate that AGFN surpasses the popular\nconstruction-based neural solvers, showcasing strong generalization\ncapabilities on synthetic and real-world benchmark instances.",
      "tldr_zh": "该研究针对车辆路径问题 (VRPs) 的求解，批评了基于 Transformer 的神经求解器在可扩展性和解决方案多样性上的不足，提出了一种新型框架 Adversarial Generative Flow Networks (AGFN)。AGFN 整合了 Generative Flow Network (GFlowNet) 用于生成多样化的路由方案，以及一个鉴别模型通过对抗训练交替优化整体解决方案质量，并采用混合解码方法构建最终路径。实验结果显示，AGFN 在 Capacitated Vehicle Routing Problem (CVRP) 和 Travelling Salesman Problem (TSP) 上超过了现有神经求解器，并在合成和真实世界基准实例中展现出强大的泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.01931v1",
      "published_date": "2025-03-03 03:06:56 UTC",
      "updated_date": "2025-03-03 03:06:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:34:12.019292"
    },
    {
      "arxiv_id": "2503.01121v1",
      "title": "Hybrid Metaheuristic Vehicle Routing Problem for Security Dispatch Operations",
      "title_zh": "翻译失败",
      "authors": [
        "Nguyen Gia Hien Vu",
        "Yifan Tang",
        "Rey Lim",
        "G. Gary Wang"
      ],
      "abstract": "This paper investigates the optimization of the Vehicle Routing Problem for\nSecurity Dispatch (VRPSD). VRPSD focuses on security and patrolling\napplications which involve challenging constraints including precise timing and\nstrict time windows. We propose three algorithms based on different\nmetaheuristics, which are Adaptive Large Neighborhood Search (ALNS), Tabu\nSearch (TS), and Threshold Accepting (TA). The first algorithm combines\nsingle-phase ALNS with TA, the second employs a multiphase ALNS with TA, and\nthe third integrates multiphase ALNS, TS, and TA. Experiments are conducted on\nan instance comprising 251 customer requests. The results demonstrate that the\nthird algorithm, the hybrid multiphase ALNS-TS-TA algorithm, delivers the best\nperformance. This approach simultaneously leverages the large-area search\ncapabilities of ALNS for exploration and effectively escapes local optima when\nthe multiphase ALNS is coupled with TS and TA. Furthermore, in our experiments,\nthe hybrid multiphase ALNS-TS-TA algorithm is the only one that shows potential\nfor improving results with increased computation time across all attempts.",
      "tldr_zh": "本论文探讨了针对安全调度操作的Vehicle Routing Problem for Security Dispatch (VRPSD)，该问题涉及精确时间和严格时间窗口等挑战性约束。研究提出三种基于metaheuristics的算法：单阶段ALNS结合TA、多阶段ALNS结合TA，以及混合多阶段ALNS-TS-TA算法。实验在包含251个客户请求的实例上进行，结果表明，混合ALNS-TS-TA算法性能最佳，能够利用ALNS的广泛搜索能力并通过TS和TA逃离局部最优，且是唯一在增加计算时间时持续改进的算法。",
      "categories": [
        "cs.AI",
        "cs.DM",
        "math.OC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01121v1",
      "published_date": "2025-03-03 02:58:49 UTC",
      "updated_date": "2025-03-03 02:58:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:34:24.750468"
    },
    {
      "arxiv_id": "2503.01109v1",
      "title": "FGS-SLAM: Fourier-based Gaussian Splatting for Real-time SLAM with Sparse and Dense Map Fusion",
      "title_zh": "翻译失败",
      "authors": [
        "Yansong Xu",
        "Junlin Li",
        "Wei Zhang",
        "Siyu Chen",
        "Shengyong Zhang",
        "Yuquan Leng",
        "Weijia Zhou"
      ],
      "abstract": "3D gaussian splatting has advanced simultaneous localization and mapping\n(SLAM) technology by enabling real-time positioning and the construction of\nhigh-fidelity maps. However, the uncertainty in gaussian position and\ninitialization parameters introduces challenges, often requiring extensive\niterative convergence and resulting in redundant or insufficient gaussian\nrepresentations. To address this, we introduce a novel adaptive densification\nmethod based on Fourier frequency domain analysis to establish gaussian priors\nfor rapid convergence. Additionally, we propose constructing independent and\nunified sparse and dense maps, where a sparse map supports efficient tracking\nvia Generalized Iterative Closest Point (GICP) and a dense map creates\nhigh-fidelity visual representations. This is the first SLAM system leveraging\nfrequency domain analysis to achieve high-quality gaussian mapping in\nreal-time. Experimental results demonstrate an average frame rate of 36 FPS on\nReplica and TUM RGB-D datasets, achieving competitive accuracy in both\nlocalization and mapping.",
      "tldr_zh": "本论文提出 FGS-SLAM，一种基于 Fourier 频率域分析的 Gaussian Splatting 方法，用于实时 SLAM 系统，以解决 Gaussian 位置不确定性和初始化参数带来的挑战。创新点包括引入自适应稠密化技术建立 Gaussian 先验以加速收敛，并融合独立的稀疏地图（利用 GICP 支持高效跟踪）和稠密地图（创建高保真视觉表示）。实验结果显示，在 Replica 和 TUM RGB-D 数据集上，该系统平均帧率为 36 FPS，并在定位和映射准确性方面达到竞争水平。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01109v1",
      "published_date": "2025-03-03 02:33:39 UTC",
      "updated_date": "2025-03-03 02:33:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:34:36.717937"
    },
    {
      "arxiv_id": "2503.01102v1",
      "title": "Ground contact and reaction force sensing for linear policy control of quadruped robot",
      "title_zh": "地面接触和反作用力传感用于四足机器人的线性策略控制",
      "authors": [
        "Harshita Mhaske",
        "Aniket Mandhare",
        "Jidong Huang",
        "Yu Bai"
      ],
      "abstract": "Designing robots capable of traversing uneven terrain and overcoming physical\nobstacles has been a longstanding challenge in the field of robotics. Walking\nrobots show promise in this regard due to their agility, redundant DOFs and\nintermittent ground contact of locomoting appendages. However, the complexity\nof walking robots and their numerous DOFs make controlling them extremely\ndifficult and computation heavy. Linear policies trained with reinforcement\nlearning have been shown to perform adequately to enable quadrupedal walking,\nwhile being computationally light weight. The goal of this research is to study\nthe effect of augmentation of observation space of a linear policy with newer\nstate variables on performance of the policy. Since ground contact and reaction\nforces are the primary means of robot-environment interaction, they are\nessential state variables on which the linear policy must be informed.\nExperimental results show that augmenting the observation space with ground\ncontact and reaction force data trains policies with better survivability,\nbetter stability against external disturbances and higher adaptability to\nuntrained conditions.",
      "tldr_zh": "本研究探讨了在四足机器人（quadruped robot）的线性策略（linear policy）控制中，添加地面接触（ground contact）和反应力（reaction force）感知，以提升其在不平坦地形和障碍物上的表现。研究通过强化学习（reinforcement learning）训练策略，并增强观察空间（observation space）以包含这些关键状态变量，从而解决机器人的控制复杂性和计算负担问题。实验结果表明，这种增强显著提高了策略的生存能力、对外部干扰的稳定性以及对未训练条件的适应性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "5 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2503.01102v1",
      "published_date": "2025-03-03 02:04:55 UTC",
      "updated_date": "2025-03-03 02:04:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:34:48.405138"
    },
    {
      "arxiv_id": "2503.01100v2",
      "title": "Fence Theorem: Towards Dual-Objective Semantic-Structure Isolation in Preprocessing Phase for 3D Anomaly Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Hanzhe Liang",
        "Jie Zhou",
        "Xuanxin Chen",
        "Tao Dai",
        "Jinbao Wang",
        "Can Gao"
      ],
      "abstract": "3D anomaly detection (AD) is prominent but difficult due to lacking a unified\ntheoretical foundation for preprocessing design. We establish the Fence\nTheorem, formalizing preprocessing as a dual-objective semantic isolator: (1)\nmitigating cross-semantic interference to the greatest extent feasible and (2)\nconfining anomaly judgments to aligned semantic spaces wherever viable, thereby\nestablishing intra-semantic comparability. Any preprocessing approach achieves\nthis goal through a two-stage process of Emantic-Division and\nSpatial-Constraints stage. Through systematic deconstruction, we theoretically\nand experimentally subsume existing preprocessing methods under this theorem\nvia tripartite evidence: qualitative analyses, quantitative studies, and\nmathematical proofs. Guided by the Fence Theorem, we implement Patch3D,\nconsisting of Patch-Cutting and Patch-Matching modules, to segment semantic\nspaces and consolidate similar ones while independently modeling normal\nfeatures within each space. Experiments on Anomaly-ShapeNet and Real3D-AD with\ndifferent settings demonstrate that progressively finer-grained semantic\nalignment in preprocessing directly enhances point-level AD accuracy, providing\ninverse validation of the theorem's causal logic.",
      "tldr_zh": "该论文提出Fence Theorem，将3D Anomaly Detection的预处理阶段形式化为双重目标：最大限度减少跨语义干扰并将异常判断限制在对齐的语义空间中，以实现语义内的可比性。定理通过Emantic-Division和Spatial-Constraints两个阶段系统化现有预处理方法，并通过定性分析、定量研究和数学证明进行验证。基于此，论文实现了Patch3D框架，包括Patch-Cutting和Patch-Matching模块，用于分割语义空间、整合相似空间并独立建模正常特征；实验在Anomaly-ShapeNet和Real3D-AD数据集上表明，更精细的语义对齐直接提升了点级检测准确率，从而逆向验证了定理的因果逻辑。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01100v2",
      "published_date": "2025-03-03 01:58:11 UTC",
      "updated_date": "2025-03-04 04:33:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:35:01.647726"
    },
    {
      "arxiv_id": "2503.01098v1",
      "title": "SolBench: A Dataset and Benchmark for Evaluating Functional Correctness in Solidity Code Completion and Repair",
      "title_zh": "SolBench：用于评估 Solidity 代码补全和修复中功能正确性的数据集和基准",
      "authors": [
        "Zaoyu Chen",
        "Haoran Qin",
        "Nuo Chen",
        "Xiangyu Zhao",
        "Lei Xue",
        "Xiapu Luo",
        "Xiao-Ming Wu"
      ],
      "abstract": "Smart contracts are crucial programs on blockchains, and their immutability\npost-deployment makes functional correctness vital. Despite progress in code\ncompletion models, benchmarks for Solidity, the primary smart contract\nlanguage, are lacking. Existing metrics like BLEU do not adequately assess the\nfunctional correctness of generated smart contracts. To fill this gap, we\nintroduce SolBench, a benchmark for evaluating the functional correctness of\nSolidity smart contracts generated by code completion models. SolBench includes\n4,178 functions from 1,155 Ethereum-deployed contracts. Testing advanced models\nrevealed challenges in generating correct code without context, as Solidity\nfunctions rely on context-defined variables and interfaces. To address this, we\npropose a Retrieval-Augmented Code Repair framework. In this framework, an\nexecutor verifies functional correctness, and if necessary, an LLM repairs the\ncode using retrieved snippets informed by executor traces. We conduct a\ncomprehensive evaluation of both closed-source and open-source LLMs across\nvarious model sizes and series to assess their performance in smart contract\ncompletion. The results show that code repair and retrieval techniques\neffectively enhance the correctness of smart contract completion while reducing\ncomputational costs.",
      "tldr_zh": "这篇论文引入了SolBench数据集和基准，用于评估Solidity智能合约代码完成和修复的功能正确性，以解决现有指标如BLEU无法有效衡量这一问题。SolBench包含来自1155个以太坊部署合约的4178个函数，并通过测试揭示了模型在缺乏上下文时生成正确代码的挑战。作者提出Retrieval-Augmented Code Repair框架，该框架利用执行器验证功能正确性，并由LLM结合检索片段进行修复，最终实验显示此方法显著提升了智能合约完成的正确性，同时降低了计算成本。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01098v1",
      "published_date": "2025-03-03 01:55:20 UTC",
      "updated_date": "2025-03-03 01:55:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:35:12.024852"
    },
    {
      "arxiv_id": "2503.01086v1",
      "title": "FAIR: Facilitating Artificial Intelligence Resilience in Manufacturing Industrial Internet",
      "title_zh": "FAIR：促进制造业工业互联网中人工智能韧性",
      "authors": [
        "Yingyan Zeng",
        "Ismini Lourentzou",
        "Xinwei Deng",
        "Ran Jin"
      ],
      "abstract": "Artificial intelligence (AI) systems have been increasingly adopted in the\nManufacturing Industrial Internet (MII). Investigating and enabling the AI\nresilience is very important to alleviate profound impact of AI system failures\nin manufacturing and Industrial Internet of Things (IIoT) operations, leading\nto critical decision making. However, there is a wide knowledge gap in defining\nthe resilience of AI systems and analyzing potential root causes and\ncorresponding mitigation strategies. In this work, we propose a novel framework\nfor investigating the resilience of AI performance over time under hazard\nfactors in data quality, AI pipelines, and the cyber-physical layer. The\nproposed method can facilitate effective diagnosis and mitigation strategies to\nrecover AI performance based on a multimodal multi-head self latent attention\nmodel. The merits of the proposed method are elaborated using an MII testbed of\nconnected Aerosol Jet Printing (AJP) machines, fog nodes, and Cloud with\ninference tasks via AI pipelines.",
      "tldr_zh": "该论文提出FAIR框架，以提升AI在制造工业互联网(MII)中的韧性，旨在缓解AI系统故障对制造和Industrial Internet of Things (IIoT)操作的影响，并填补AI韧性定义、根因分析和缓解策略的知识缺口。框架通过调查AI性能在数据质量、AI管道和网络物理层下的长期表现，使用多模态多头自注意力模型进行有效诊断和恢复策略。实验在连接的Aerosol Jet Printing (AJP)机器、雾节点和云的MII测试床中验证了该方法的优势，展示了其在关键决策中的实际应用潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01086v1",
      "published_date": "2025-03-03 01:17:22 UTC",
      "updated_date": "2025-03-03 01:17:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:35:24.919630"
    },
    {
      "arxiv_id": "2503.01079v1",
      "title": "Depth-Adaptive Graph Neural Networks via Learnable Bakry-'Emery Curvature",
      "title_zh": "翻译失败",
      "authors": [
        "Asela Hevapathige",
        "Ahad N. Zehmakan",
        "Qing Wang"
      ],
      "abstract": "Graph Neural Networks (GNNs) have demonstrated strong representation learning\ncapabilities for graph-based tasks. Recent advances on GNNs leverage geometric\nproperties, such as curvature, to enhance its representation capabilities by\nmodeling complex connectivity patterns and information flow within graphs.\nHowever, most existing approaches focus solely on discrete graph topology,\noverlooking diffusion dynamics and task-specific dependencies essential for\neffective learning. To address this, we propose integrating Bakry-\\'Emery\ncurvature, which captures both structural and task-driven aspects of\ninformation propagation. We develop an efficient, learnable approximation\nstrategy, making curvature computation scalable for large graphs. Furthermore,\nwe introduce an adaptive depth mechanism that dynamically adjusts\nmessage-passing layers per vertex based on its curvature, ensuring efficient\npropagation. Our theoretical analysis establishes a link between curvature and\nfeature distinctiveness, showing that high-curvature vertices require fewer\nlayers, while low-curvature ones benefit from deeper propagation. Extensive\nexperiments on benchmark datasets validate the effectiveness of our approach,\nshowing consistent performance improvements across diverse graph learning\ntasks.",
      "tldr_zh": "本文提出了一种基于可学习 Bakry-'Emery 曲率的自适应深度 Graph Neural Networks (GNNs)，旨在通过捕捉图的结构和任务驱动信息传播来提升表示学习能力，以解决现有方法忽略扩散动态和任务依赖的问题。研究开发了高效的曲率近似策略，使其适用于大规模图，并引入动态调整消息-passing layers 的机制，根据顶点曲率决定传播深度。理论分析表明，高曲率顶点需更少层以保持特征独特性，而低曲率顶点受益于更深传播。实验在基准数据集上验证了该方法的有效性，在多种图学习任务中实现了稳定的性能提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01079v1",
      "published_date": "2025-03-03 00:48:41 UTC",
      "updated_date": "2025-03-03 00:48:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:35:36.581331"
    },
    {
      "arxiv_id": "2503.01075v1",
      "title": "Tackling Hallucination from Conditional Models for Medical Image Reconstruction with DynamicDPS",
      "title_zh": "利用 DynamicDPS 处理条件模型在医疗图像重建中的幻觉问题",
      "authors": [
        "Seunghoi Kim",
        "Henry F. J. Tregidgo",
        "Matteo Figini",
        "Chen Jin",
        "Sarang Joshi",
        "Daniel C. Alexander"
      ],
      "abstract": "Hallucinations are spurious structures not present in the ground truth,\nposing a critical challenge in medical image reconstruction, especially for\ndata-driven conditional models. We hypothesize that combining an unconditional\ndiffusion model with data consistency, trained on a diverse dataset, can reduce\nthese hallucinations. Based on this, we propose DynamicDPS, a diffusion-based\nframework that integrates conditional and unconditional diffusion models to\nenhance low-quality medical images while systematically reducing\nhallucinations. Our approach first generates an initial reconstruction using a\nconditional model, then refines it with an adaptive diffusion-based inverse\nproblem solver. DynamicDPS skips early stage in the reverse process by\nselecting an optimal starting time point per sample and applies Wolfe's line\nsearch for adaptive step sizes, improving both efficiency and image fidelity.\nUsing diffusion priors and data consistency, our method effectively reduces\nhallucinations from any conditional model output. We validate its effectiveness\nin Image Quality Transfer for low-field MRI enhancement. Extensive evaluations\non synthetic and real MR scans, including a downstream task for tissue volume\nestimation, show that DynamicDPS reduces hallucinations, improving relative\nvolume estimation by over 15% for critical tissues while using only 5% of the\nsampling steps required by baseline diffusion models. As a model-agnostic and\nfine-tuning-free approach, DynamicDPS offers a robust solution for\nhallucination reduction in medical imaging. The code will be made publicly\navailable upon publication.",
      "tldr_zh": "该研究针对医学图像重建中条件模型的幻觉（hallucinations）问题，提出DynamicDPS框架，该框架结合无条件扩散模型（unconditional diffusion model）和数据一致性（data consistency），通过先使用条件模型生成初始重建，再应用自适应扩散-based逆问题求解器进行精炼。DynamicDPS优化了逆过程，跳过早期阶段并采用Wolfe's line search调整步长，从而提高效率和图像保真度。实验结果显示，在低场MRI增强任务上，该方法显著减少幻觉，提高关键组织体积估计超过15%，且仅需基线扩散模型的5%采样步骤，作为一种模型无关（model-agnostic）和无需微调（fine-tuning-free）的解决方案。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01075v1",
      "published_date": "2025-03-03 00:33:04 UTC",
      "updated_date": "2025-03-03 00:33:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:35:49.649725"
    },
    {
      "arxiv_id": "2503.01069v1",
      "title": "Multi-Agent Reinforcement Learning with Long-Term Performance Objectives for Service Workforce Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Kareem Eissa",
        "Rayal Prasad",
        "Sarith Mohan",
        "Ankur Kapoor",
        "Dorin Comaniciu",
        "Vivek Singh"
      ],
      "abstract": "Workforce optimization plays a crucial role in efficient organizational\noperations where decision-making may span several different administrative and\ntime scales. For instance, dispatching personnel to immediate service requests\nwhile managing talent acquisition with various expertise sets up a highly\ndynamic optimization problem. Existing work focuses on specific sub-problems\nsuch as resource allocation and facility location, which are solved with\nheuristics like local-search and, more recently, deep reinforcement learning.\nHowever, these may not accurately represent real-world scenarios where such\nsub-problems are not fully independent. Our aim is to fill this gap by creating\na simulator that models a unified workforce optimization problem. Specifically,\nwe designed a modular simulator to support the development of reinforcement\nlearning methods for integrated workforce optimization problems. We focus on\nthree interdependent aspects: personnel dispatch, workforce management, and\npersonnel positioning. The simulator provides configurable parameterizations to\nhelp explore dynamic scenarios with varying levels of stochasticity and\nnon-stationarity. To facilitate benchmarking and ablation studies, we also\ninclude heuristic and RL baselines for the above mentioned aspects.",
      "tldr_zh": "该论文针对服务劳动力优化问题，提出了一种基于多智能体强化学习（Multi-Agent Reinforcement Learning）的方法，旨在处理长期性能目标和不同时间规模的决策挑战，如人员派遣和人才管理。作者开发了一个模块化的模拟器，模拟三个相互依赖的方面：人员派遣、工作力管理和人员定位，支持探索动态场景中的随机性和非平稳性。该模拟器提供了可配置参数以及启发式和强化学习基准，便于基准测试和消融研究，从而填补了现有方法在统一优化问题上的空白。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01069v1",
      "published_date": "2025-03-03 00:16:47 UTC",
      "updated_date": "2025-03-03 00:16:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:36:01.180037"
    },
    {
      "arxiv_id": "2503.01068v1",
      "title": "Language-Guided Object Search in Agricultural Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Advaith Balaji",
        "Saket Pradhan",
        "Dmitry Berenson"
      ],
      "abstract": "Creating robots that can assist in farms and gardens can help reduce the\nmental and physical workload experienced by farm workers. We tackle the problem\nof object search in a farm environment, providing a method that allows a robot\nto semantically reason about the location of an unseen target object among a\nset of previously seen objects in the environment using a Large Language Model\n(LLM). We leverage object-to-object semantic relationships to plan a path\nthrough the environment that will allow us to accurately and efficiently locate\nour target object while also reducing the overall distance traveled, without\nneeding high-level room or area-level semantic relationships. During our\nevaluations, we found that our method outperformed a current state-of-the-art\nbaseline and our ablations. Our offline testing yielded an average path\nefficiency of 84%, reflecting how closely the predicted path aligns with the\nideal path. Upon deploying our system on the Boston Dynamics Spot robot in a\nreal-world farm environment, we found that our system had a success rate of\n80%, with a success weighted by path length of 0.67, which demonstrates a\nreasonable trade-off between task success and path efficiency under real-world\nconditions. The project website can be viewed at\nhttps://adi-balaji.github.io/losae/",
      "tldr_zh": "这篇论文提出了一种在农业环境中利用语言引导的物体搜索方法，使用Large Language Model (LLM)来基于物体间的语义关系推理目标物体的位置，并规划高效路径，从而减少机器人旅行距离和提高搜索准确性。相比现有基线，该方法在离线测试中实现了84%的路径效率，并在真实环境中部署于Boston Dynamics Spot机器人时，取得了80%的成功率和0.67的路径长度加权成功率。整体贡献在于为农业机器人提供了一种无需依赖高级别语义关系的实用解决方案，减轻了农场工人的工作负担。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 4 figures, 2 tables, accepted to the 2025 International\n  Conference on Robotics and Automation (ICRA 2025)",
      "pdf_url": "http://arxiv.org/pdf/2503.01068v1",
      "published_date": "2025-03-03 00:15:45 UTC",
      "updated_date": "2025-03-03 00:15:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:36:12.648247"
    },
    {
      "arxiv_id": "2503.01064v1",
      "title": "Scientific Reasoning: Assessment of Multimodal Generative LLMs",
      "title_zh": "科学推理：多模态生成式 LLMs 的评估",
      "authors": [
        "Florian Dreyer",
        "Ekaterina Kolos",
        "Daria Matiash"
      ],
      "abstract": "Large language models (LLMs) can answer questions and reason about complex\ntasks, also from the scientific domain. We assess several multimodal LLMs\n(MLLMs) on ScienceQA and find that Gemini models show the highest accuracy with\nlittle context, and the highest textual similarity to human explanations with\nricher context. Adapter-tuning of smaller MLLMs did not lead to any reliable\nperformance. Training from Gemini outputs consistently underperformed training\nfrom the original data.",
      "tldr_zh": "本研究评估了多模态生成 LLMs（MLLMs）在科学推理任务上的性能，使用 ScienceQA 数据集进行测试。结果显示，Gemini 模型在少量上下文时表现出最高准确率，而在丰富上下文时，其生成的解释与人类文本相似度最高。相比之下，对较小 MLLMs 的 Adapter-tuning 并未带来可靠的性能提升，且基于 Gemini 输出进行训练的表现不如直接使用原始数据训练。总的来说，该评估突出了 Gemini 模型在科学领域推理中的优势，并为 MLLMs 的优化提供了见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.01064v1",
      "published_date": "2025-03-03 00:07:22 UTC",
      "updated_date": "2025-03-03 00:07:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-23T21:36:24.596238"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 164,
  "processed_papers_count": 164,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-23T21:36:51.151267"
}