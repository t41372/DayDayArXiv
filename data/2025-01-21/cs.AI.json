{
  "date": "2025-01-21",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-01-21 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 和机器学习领域，包括大型语言模型（LLM）的优化、多模态学习和图神经网络的应用，还涉及物理学、医学和计算机视觉等领域。重点在于 LLM 在认知和任务中的潜力，以及多模态模型在视频理解和生成上的进展，令人印象深刻的是 Ziming Liu 和 Max Tegmark 等知名学者的“Physics of Skill Learning”论文，它揭示了神经网络技能学习的物理机制；其他亮点包括 Yilun Zhao 等人提出的 MMVU 基准，用于评估多模态模型在专家级视频理解中的性能。下面，我将挑选最具话题度和影响力的论文进行简要讨论，先从 AI 和 LLM 相关主题入手，再聊图学习和视觉领域，快速掠过其他较次要的论文。\n\n**1. Human-like conceptual representations emerge from language prediction（人类般的概念表示从语言预测中涌现）**  \n这篇论文探讨了大型语言模型（LLMs）是否能像人类一样发展概念表示，主要贡献是通过重新设计反向字典任务，证明 LLMs 可以从语言描述中推导出与人类行为相似的概念结构，并与大脑神经活动模式对齐，发现 LLMs 在没有真实世界基础的情况下也能自然地产生结构化概念表示，这为理解人类认知和提升 AI 智能提供了新工具。\n\n**2. Multi-Modality Transformer for E-Commerce: Inferring User Purchase Intention to Bridge the Query-Product Gap（多模态 Transformer 用于电商：通过推断用户购买意图桥接查询-产品鸿沟）**  \n论文提出 PINCER 模型，用于电商场景的多模态 Transformer，它从点击流数据和产品目录中推断用户意图，主要发现是通过集成外部数据源，提升查询到产品的转换准确性，在真实实验中优于现有方法，为电商推荐系统提供了更高效的特征提取和意图推理策略。\n\n**3. ZKLoRA: Efficient Zero-Knowledge Proofs for LoRA Verification（ZKLoRA：用于 LoRA 验证的高效零知识证明）**  \n这篇工作针对分布式训练环境，开发了 ZKLoRA 协议，用于验证 LoRA 权重兼容性而不暴露私有数据，主要贡献是引入简洁证明和多方推理机制，实现 1-2 秒内模块验证，促进安全协作和知识产权保护。\n\n**6. Advancing the Understanding and Evaluation of AR-Generated Scenes: When Vision-Language Models Shine and Stumble（推进 AR 生成场景的理解和评估：视觉语言模型的优缺点）**  \n论文评估了 GPT、Gemini 和 Claude 等视觉语言模型（VLMs）在 AR 场景识别中的性能，使用 DiverseAR 数据集发现 VLMs 在感知明显对象时准确率高达 93%，但在无缝集成内容上表现较差，主要发现突出了 VLMs 在 AR 评估中的潜力及其局限性。\n\n**19. Learning segmentation from point trajectories（从点轨迹学习分割）**  \n这项研究扩展了基于运动的视频分割，使用长期点轨迹作为监督信号，主要贡献是提出一个损失函数，将轨迹聚类到低秩矩阵中，提升了分割精度，并在关键心理现象上与人类行为对齐。\n\n**20. Physics of Skill Learning（技能学习的物理学）**  \n由 Ziming Liu、Max Tegmark 等知名学者撰写，论文分析神经网络技能学习的“多米诺效应”，提出 Geometry、Resource 和 Domino 模型，主要发现这些模型不仅解释了技能顺序学习，还启发了算法优化，如改进深度学习训练速度。\n\n**21. MMVU: Measuring Expert-Level Multi-Discipline Video Understanding（MMVU：测量专家级多学科视频理解）**  \nYilun Zhao 等人构建了 MMVU 基准，涵盖科学、健康等领域 3000 个问题，主要贡献是评估多模态模型在专家级视频分析中的性能，发现 o1 和 Gemini 2.0 在复杂任务上表现突出，但仍落后于人类。\n\n**23. Video Depth Anything: Consistent Depth Estimation for Super-Long Videos（Video Depth Anything：用于超长视频的一致深度估计）**  \n论文基于 Depth Anything V2 提出新框架，实现超长视频的深度估计，主要发现是通过时序一致性损失和关键帧策略，提升了深度估计的准确性和实时性，适用于任意长视频。\n\n**34. UI-TARS: Pioneering Automated GUI Interaction with Native Agents（UI-TARS：使用原生代理的自动化 GUI 交互开创性方法）**  \n这项工作引入 UI-TARS 框架，支持屏幕截图感知和交互，主要贡献是端到端训练代理模型，显著提升 GUI 任务执行性能，并在 OSWorld 和 AndroidWorld 基准上超越 GPT-4o。\n\n其他论文，如物理学领域的“High-temperature superconductivity in Li$_2$AuH$_6$ mediated by strong electron-phonon coupling under ambient pressure”（Li$_2$AuH$_6$的高温超导性：通过强电子-声子耦合在环境压力下实现），快速提一下，它使用 AI 搜索引擎发现新材料，并证明了声子模式的强耦合作用；医学领域的“Benchmarking Generative AI for Scoring Medical Student Interviews in Objective Structured Clinical Examinations”（生成式 AI 用于评估医学生面试的基准），展示了 LLM 在 OSCE 评估中的潜力，但整体影响力较小，故从简。\n\n总之，今天的论文突显了 AI 在多领域应用的潜力，尤其是 LLM 和多模态学习的创新，但也暴露了模型在复杂场景中的局限性。感兴趣的读者可关注上述关键论文，探索更多细节！",
  "papers": [
    {
      "arxiv_id": "2501.12547v3",
      "title": "Human-like conceptual representations emerge from language prediction",
      "title_zh": "人类般的概念表示从语言预测中涌现",
      "authors": [
        "Ningyu Xu",
        "Qi Zhang",
        "Chao Du",
        "Qiang Luo",
        "Xipeng Qiu",
        "Xuanjing Huang",
        "Menghan Zhang"
      ],
      "abstract": "People acquire concepts through rich physical and social experiences and use\nthem to understand the world. In contrast, large language models (LLMs),\ntrained exclusively through next-token prediction over language data, exhibit\nremarkably human-like behaviors. Are these models developing concepts akin to\nhumans, and if so, how are such concepts represented and organized? To address\nthese questions, we reframed the classic reverse dictionary task to simulate\nhuman concept inference in context and investigated the emergence of human-like\nconceptual representations within LLMs. Our results demonstrate that LLMs can\nflexibly derive concepts from linguistic descriptions in relation to contextual\ncues about other concepts. The derived representations converged towards a\nshared, context-independent structure that effectively predicted human behavior\nacross key psychological phenomena, including computation of similarities,\ncategories and semantic scales. Moreover, these representations aligned well\nwith neural activity patterns in the human brain, even in response to visual\nrather than linguistic stimuli, providing evidence for biological plausibility.\nThese findings establish that structured, human-like conceptual representations\ncan naturally emerge from language prediction without real-world grounding.\nMore broadly, our work positions LLMs as promising computational tools for\nunderstanding complex human cognition and paves the way for better alignment\nbetween artificial and human intelligence.",
      "tldr_zh": "本研究探讨大型语言模型（LLMs）是否能通过next-token prediction从纯语言数据中发展出类似于人类的概念表示。作者重新设计了reverse dictionary task，模拟人类在上下文中的概念推断，测试LLMs从语言描述中推导概念的能力。结果显示，LLMs的概念表示收敛到一个共享的、上下文无关的结构，能够准确预测人类在相似性、类别和语义尺度上的行为，并与人类大脑神经活动模式高度一致。总体而言，这证明了人类-like概念表示可从语言预测中自然出现，无需真实世界的grounding，并为理解人类认知和提升AI与人类智能对齐提供了重要工具。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "51 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.12547v3",
      "published_date": "2025-01-21 23:54:17 UTC",
      "updated_date": "2025-03-24 09:10:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:30:12.436959"
    },
    {
      "arxiv_id": "2501.14826v1",
      "title": "Multi-Modality Transformer for E-Commerce: Inferring User Purchase Intention to Bridge the Query-Product Gap",
      "title_zh": "翻译失败",
      "authors": [
        "Srivatsa Mallapragada",
        "Ying Xie",
        "Varsha Rani Chawan",
        "Zeyad Hailat",
        "Yuanbo Wang"
      ],
      "abstract": "E-commerce click-stream data and product catalogs offer critical user\nbehavior insights and product knowledge. This paper propose a multi-modal\ntransformer termed as PINCER, that leverages the above data sources to\ntransform initial user queries into pseudo-product representations. By tapping\ninto these external data sources, our model can infer users' potential purchase\nintent from their limited queries and capture query relevant product features.\nWe demonstrate our model's superior performance over state-of-the-art\nalternatives on e-commerce online retrieval in both controlled and real-world\nexperiments. Our ablation studies confirm that the proposed transformer\narchitecture and integrated learning strategies enable the mining of key data\nsources to infer purchase intent, extract product features, and enhance the\ntransformation pipeline from queries to more accurate pseudo-product\nrepresentations.",
      "tldr_zh": "本文提出了一种名为 PINCER 的多模态 Transformer 模型，用于电子商务领域，通过整合点击流数据和产品目录，将用户的初始查询转化为伪产品表示，从而推断潜在购买意图并捕获查询相关的产品特征。相比现有技术，PINCER 在受控和真实世界的在线检索实验中表现出色，提升了查询到产品的转换准确性。消融研究证实，该模型的架构和学习策略有效挖掘关键数据来源，增强了购买意图推断和产品特征提取的功能。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "Published in IEEE Big Data Conference 2024, Washington DC",
      "pdf_url": "http://arxiv.org/pdf/2501.14826v1",
      "published_date": "2025-01-21 23:47:39 UTC",
      "updated_date": "2025-01-21 23:47:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:30:23.085743"
    },
    {
      "arxiv_id": "2501.13965v1",
      "title": "ZKLoRA: Efficient Zero-Knowledge Proofs for LoRA Verification",
      "title_zh": "翻译失败",
      "authors": [
        "Bidhan Roy",
        "Peter Potash",
        "Marcos Villagra"
      ],
      "abstract": "Low-Rank Adaptation (LoRA) is a widely adopted method for customizing\nlarge-scale language models. In distributed, untrusted training environments,\nan open source base model user may want to use LoRA weights created by an\nexternal contributor, leading to two requirements: (1) the base model user must\nconfirm that the LoRA weights are effective when paired with the intended base\nmodel, and (2) the LoRA contributor must keep their proprietary weights private\nuntil compensation is assured.\n  We present ZKLoRA, a zero-knowledge verification protocol that relies on\nsuccinct proofs and our novel Multi-Party Inference procedure to verify\nLoRA-base model compatibility without exposing LoRA weights. ZKLoRA produces\ndeterministic correctness guarantees and validates each LoRA module in only 1-2\nseconds on state-of-the-art large language models. This low-latency approach\nenables nearly real-time verification and promotes secure collaboration among\ngeographically decentralized teams and contract-based training pipelines. The\nprotocol ensures that the delivered LoRA module works as claimed, safeguarding\nthe contributor's intellectual property while providing the base model user\nwith verification of compatibility and lineage.",
      "tldr_zh": "该研究针对 Low-Rank Adaptation (LoRA) 在分布式不信任环境中的应用，提出 ZKLoRA 协议，以解决用户验证 LoRA 权重与基模型兼容性，同时保护贡献者专有权重隐私的问题。ZKLoRA 利用简洁证明和新型 Multi-Party Inference 过程，实现零知识验证，确保验证过程无需暴露 LoRA 权重，且每个模块仅需 1-2 秒。实验结果显示，该协议提供确定性正确性保证，支持实时验证，并促进地理分散团队的安全协作和基于合同的训练管道。整体而言，ZKLoRA 提升了 LoRA 的可信度和知识产权保护。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "7 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.13965v1",
      "published_date": "2025-01-21 23:20:33 UTC",
      "updated_date": "2025-01-21 23:20:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:30:34.367870"
    },
    {
      "arxiv_id": "2501.12542v1",
      "title": "Reinforcement Learning Constrained Beam Search for Parameter Optimization of Paper Drying Under Flexible Constraints",
      "title_zh": "翻译失败",
      "authors": [
        "Siyuan Chen",
        "Hanshen Yu",
        "Jamal Yagoobi",
        "Chenhui Shao"
      ],
      "abstract": "Existing approaches to enforcing design constraints in Reinforcement Learning\n(RL) applications often rely on training-time penalties in the reward function\nor training/inference-time invalid action masking, but these methods either\ncannot be modified after training, or are limited in the types of constraints\nthat can be implemented. To address this limitation, we propose Reinforcement\nLearning Constrained Beam Search (RLCBS) for inference-time refinement in\ncombinatorial optimization problems. This method respects flexible,\ninference-time constraints that support exclusion of invalid actions and forced\ninclusion of desired actions, and employs beam search to maximize sequence\nprobability for more sensible constraint incorporation. RLCBS is extensible to\nRL-based planning and optimization problems that do not require real-time\nsolution, and we apply the method to optimize process parameters for a novel\nmodular testbed for paper drying. An RL agent is trained to minimize energy\nconsumption across varying machine speed levels by generating optimal dryer\nmodule and air supply temperature configurations. Our results demonstrate that\nRLCBS outperforms NSGA-II under complex design constraints on drying module\nconfigurations at inference-time, while providing a 2.58-fold or higher speed\nimprovement.",
      "tldr_zh": "这篇论文提出了Reinforcement Learning Constrained Beam Search (RLCBS)，一种用于推理时优化的方法，能够处理灵活约束的组合优化问题，支持排除无效动作和强制包括所需动作，同时通过Beam Search最大化序列概率。RLCBS应用于纸张干燥过程的参数优化，训练RL代理生成最佳的干燥模块和空气供应温度配置，以最小化能源消耗。实验结果表明，RLCBS在复杂约束下优于NSGA-II，提供2.58倍或更高的速度提升。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12542v1",
      "published_date": "2025-01-21 23:16:19 UTC",
      "updated_date": "2025-01-21 23:16:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:30:46.999260"
    },
    {
      "arxiv_id": "2501.17170v1",
      "title": "Benchmarking Randomized Optimization Algorithms on Binary, Permutation, and Combinatorial Problem Landscapes",
      "title_zh": "翻译失败",
      "authors": [
        "Jethro Odeyemi",
        "Wenjun Zhang"
      ],
      "abstract": "In this paper, we evaluate the performance of four randomized optimization\nalgorithms: Randomized Hill Climbing (RHC), Simulated Annealing (SA), Genetic\nAlgorithms (GA), and MIMIC (Mutual Information Maximizing Input Clustering),\nacross three distinct types of problems: binary, permutation, and\ncombinatorial. We systematically compare these algorithms using a set of\nbenchmark fitness functions that highlight the specific challenges and\nrequirements of each problem category. Our study analyzes each algorithm's\neffectiveness based on key performance metrics, including solution quality,\nconvergence speed, computational cost, and robustness. Results show that while\nMIMIC and GA excel in producing high-quality solutions for binary and\ncombinatorial problems, their computational demands vary significantly. RHC and\nSA, while computationally less expensive, demonstrate limited performance in\ncomplex problem landscapes. The findings offer valuable insights into the\ntrade-offs between different optimization strategies and provide practical\nguidance for selecting the appropriate algorithm based on the type of problems,\naccuracy requirements, and computational constraints.",
      "tldr_zh": "本文评估了四个随机优化算法——Randomized Hill Climbing (RHC)、Simulated Annealing (SA)、Genetic Algorithms (GA) 和 MIMIC——在 binary、permutation 和 combinatorial 问题上的性能，通过基准适应度函数系统比较了这些算法在解决方案质量、收敛速度、计算成本和鲁棒性等方面的指标。结果表明，MIMIC 和 GA 在 binary 和 combinatorial 问题上表现出色，能够产生高质量解决方案，但计算需求较高；相比之下，RHC 和 SA 计算开销较小，但在大问题景观中表现有限。该研究提供了宝贵的见解，帮助根据问题类型、准确性要求和计算约束选择合适的优化策略。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.17170v1",
      "published_date": "2025-01-21 23:13:01 UTC",
      "updated_date": "2025-01-21 23:13:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:31:00.197236"
    },
    {
      "arxiv_id": "2501.13964v3",
      "title": "Advancing the Understanding and Evaluation of AR-Generated Scenes: When Vision-Language Models Shine and Stumble",
      "title_zh": "翻译失败",
      "authors": [
        "Lin Duan",
        "Yanming Xiu",
        "Maria Gorlatova"
      ],
      "abstract": "Augmented Reality (AR) enhances the real world by integrating virtual\ncontent, yet ensuring the quality, usability, and safety of AR experiences\npresents significant challenges. Could Vision-Language Models (VLMs) offer a\nsolution for the automated evaluation of AR-generated scenes? Could\nVision-Language Models (VLMs) offer a solution for the automated evaluation of\nAR-generated scenes? In this study, we evaluate the capabilities of three\nstate-of-the-art commercial VLMs -- GPT, Gemini, and Claude -- in identifying\nand describing AR scenes. For this purpose, we use DiverseAR, the first AR\ndataset specifically designed to assess VLMs' ability to analyze virtual\ncontent across a wide range of AR scene complexities. Our findings demonstrate\nthat VLMs are generally capable of perceiving and describing AR scenes,\nachieving a True Positive Rate (TPR) of up to 93% for perception and 71% for\ndescription. While they excel at identifying obvious virtual objects, such as a\nglowing apple, they struggle when faced with seamlessly integrated content,\nsuch as a virtual pot with realistic shadows. Our results highlight both the\nstrengths and the limitations of VLMs in understanding AR scenarios. We\nidentify key factors affecting VLM performance, including virtual content\nplacement, rendering quality, and physical plausibility. This study underscores\nthe potential of VLMs as tools for evaluating the quality of AR experiences.",
      "tldr_zh": "这篇论文评估了视觉语言模型（VLMs）如 GPT、Gemini 和 Claude 在识别和描述增强现实（AR）生成场景的能力，使用了首个专门设计的数据集 DiverseAR 来测试各种场景复杂度。研究发现，VLMs 在感知 AR 场景时真阳性率（TPR）高达 93%，在描述方面达 71%，但它们擅长识别明显虚拟对象（如发光的苹果），却在处理无缝整合内容（如带有真实阴影的虚拟锅）时表现不佳。影响因素包括虚拟内容放置、渲染质量和物理合理性，该研究突出了 VLMs 作为 AR 体验质量自动评估工具的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.13964v3",
      "published_date": "2025-01-21 23:07:03 UTC",
      "updated_date": "2025-02-01 20:27:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:31:11.873819"
    },
    {
      "arxiv_id": "2501.12538v3",
      "title": "Academic case reports lack diversity: Assessing the presence and diversity of sociodemographic and behavioral factors related to Post COVID-19 Condition",
      "title_zh": "学术案例报告缺乏多样性：评估",
      "authors": [
        "Juan Andres Medina Florez",
        "Shaina Raza",
        "Rashida Lynn",
        "Zahra Shakeri",
        "Brendan T. Smith",
        "Elham Dolatabadi"
      ],
      "abstract": "Understanding the prevalence, disparities, and symptom variations of Post\nCOVID-19 Condition (PCC) for vulnerable populations is crucial to improving\ncare and addressing intersecting inequities. This study aims to develop a\ncomprehensive framework for integrating social determinants of health (SDOH)\ninto PCC research by leveraging NLP techniques to analyze disparities and\nvariations in SDOH representation within PCC case reports. Following\nconstruction of a PCC Case Report Corpus, comprising over 7,000 case reports\nfrom the LitCOVID repository, a subset of 709 reports were annotated with 26\ncore SDOH-related entity types using pre-trained named entity recognition (NER)\nmodels, human review, and data augmentation to improve quality, diversity and\nrepresentation of entity types. An NLP pipeline integrating NER, natural\nlanguage inference (NLI), trigram and frequency analyses was developed to\nextract and analyze these entities. Both encoder-only transformer models and\nRNN-based models were assessed for the NER objective.\n  Fine-tuned encoder-only BERT models outperformed traditional RNN-based models\nin generalizability to distinct sentence structures and greater class sparsity.\nExploratory analysis revealed variability in entity richness, with prevalent\nentities like condition, age, and access to care, and underrepresentation of\nsensitive categories like race and housing status. Trigram analysis highlighted\nfrequent co-occurrences among entities, including age, gender, and condition.\nThe NLI objective (entailment and contradiction analysis) showed attributes\nlike \"Experienced violence or abuse\" and \"Has medical insurance\" had high\nentailment rates (82.4%-80.3%), while attributes such as \"Is\nfemale-identifying,\" \"Is married,\" and \"Has a terminal condition\" exhibited\nhigh contradiction rates (70.8%-98.5%).",
      "tldr_zh": "这篇论文评估了 Post COVID-19 Condition (PCC) 病例报告中社会健康决定因素 (SDOH) 的存在和多样性，发现这些报告缺乏对弱势群体的代表性。研究构建了一个包含超过 7,000 个病例报告的语料库，并使用 NLP 技术（如 NER 和 NLI）标注和分析 26 种核心 SDOH 实体，包括年龄、性别和种族等。开发了集成 NER、NLI、三元组和频率分析的 NLP 管道，并发现 Fine-tuned BERT 模型在泛化性和处理稀疏类方面优于 RNN 模型。探索性分析显示某些实体（如年龄和条件）频繁出现，而敏感类别（如种族和住房状况）被低估，且实体间存在常见共现模式。该框架有助于整合 SDOH 到 PCC 研究中，改善医疗不平等和护理质量。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12538v3",
      "published_date": "2025-01-21 23:05:12 UTC",
      "updated_date": "2025-02-24 02:29:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:31:25.712084"
    },
    {
      "arxiv_id": "2501.12536v1",
      "title": "Interaction Dataset of Autonomous Vehicles with Traffic Lights and Signs",
      "title_zh": "自动驾驶车辆与交通灯和交通标志的交互数据集",
      "authors": [
        "Zheng Li",
        "Zhipeng Bao",
        "Haoming Meng",
        "Haotian Shi",
        "Qianwen Li",
        "Handong Yao",
        "Xiaopeng Li"
      ],
      "abstract": "This paper presents the development of a comprehensive dataset capturing\ninteractions between Autonomous Vehicles (AVs) and traffic control devices,\nspecifically traffic lights and stop signs. Derived from the Waymo Motion\ndataset, our work addresses a critical gap in the existing literature by\nproviding real-world trajectory data on how AVs navigate these traffic control\ndevices. We propose a methodology for identifying and extracting relevant\ninteraction trajectory data from the Waymo Motion dataset, incorporating over\n37,000 instances with traffic lights and 44,000 with stop signs. Our\nmethodology includes defining rules to identify various interaction types,\nextracting trajectory data, and applying a wavelet-based denoising method to\nsmooth the acceleration and speed profiles and eliminate anomalous values,\nthereby enhancing the trajectory quality. Quality assessment metrics indicate\nthat trajectories obtained in this study have anomaly proportions in\nacceleration and jerk profiles reduced to near-zero levels across all\ninteraction categories. By making this dataset publicly available, we aim to\naddress the current gap in datasets containing AV interaction behaviors with\ntraffic lights and signs. Based on the organized and published dataset, we can\ngain a more in-depth understanding of AVs' behavior when interacting with\ntraffic lights and signs. This will facilitate research on AV integration into\nexisting transportation infrastructures and networks, supporting the\ndevelopment of more accurate behavioral models and simulation tools.",
      "tldr_zh": "这篇论文基于 Waymo Motion 数据集，开发了一个全面数据集，捕捉自动驾驶车辆 (AVs) 与交通灯和停车标志的互动轨迹，填补了现有文献的空白。研究方法包括定义规则识别不同互动类型、提取超过 37,000 个交通灯实例和 44,000 个停车标志实例的轨迹数据，并应用基于小波的去噪方法平滑加速度和速度配置文件，从而将轨迹中的异常比例降至近零。公开该数据集有助于深入理解 AVs 的行为，支持开发更准确的行为模型和模拟工具，以促进 AVs 与现有交通基础设施的整合。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12536v1",
      "published_date": "2025-01-21 22:59:50 UTC",
      "updated_date": "2025-01-21 22:59:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:31:36.532288"
    },
    {
      "arxiv_id": "2501.12524v2",
      "title": "Efficient Lung Ultrasound Severity Scoring Using Dedicated Feature Extractor",
      "title_zh": "高效的肺超声严重程度评分方法，使用专用的特征提取器",
      "authors": [
        "Jiaqi Guo",
        "Yunan Wu",
        "Evangelos Kaimakamis",
        "Georgios Petmezas",
        "Vasileios E. Papageorgiou",
        "Nicos Maglaveras",
        "Aggelos K. Katsaggelos"
      ],
      "abstract": "With the advent of the COVID-19 pandemic, ultrasound imaging has emerged as a\npromising technique for COVID-19 detection, due to its non-invasive nature,\naffordability, and portability. In response, researchers have focused on\ndeveloping AI-based scoring systems to provide real-time diagnostic support.\nHowever, the limited size and lack of proper annotation in publicly available\nultrasound datasets pose significant challenges for training a robust AI model.\nThis paper proposes MeDiVLAD, a novel pipeline to address the above issue for\nmulti-level lung-ultrasound (LUS) severity scoring. In particular, we leverage\nself-knowledge distillation to pretrain a vision transformer (ViT) without\nlabel and aggregate frame-level features via dual-level VLAD aggregation. We\nshow that with minimal finetuning, MeDiVLAD outperforms conventional\nfully-supervised methods in both frame- and video-level scoring, while offering\nclassification reasoning with exceptional quality. This superior performance\nenables key applications such as the automatic identification of critical lung\npathology areas and provides a robust solution for broader medical video\nclassification tasks.",
      "tldr_zh": "本研究针对COVID-19检测中肺超声（LUS）图像数据集规模有限和标注不足的问题，提出了一种名为MeDiVLAD的创新管道，用于高效的多级LUS严重程度评分。MeDiVLAD通过自知识蒸馏预训练一个视觉Transformer (ViT)模型（无需标签），并采用双级VLAD聚合来整合帧级特征，从而实现最小微调下的高性能。实验结果显示，该方法在帧级和视频级评分上优于传统全监督方法，提供高质量的分类推理，并支持关键应用如自动识别肺病变区域和扩展到其他医疗视频分类任务。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "Accepted by IEEE ISBI 2025 (Selected for oral presentation) 2025/4/15\n  (v2): Corrected a notation error in Figure 2",
      "pdf_url": "http://arxiv.org/pdf/2501.12524v2",
      "published_date": "2025-01-21 22:28:22 UTC",
      "updated_date": "2025-04-15 19:09:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:31:46.396606"
    },
    {
      "arxiv_id": "2501.12521v1",
      "title": "An Empirically-grounded tool for Automatic Prompt Linting and Repair: A Case Study on Bias, Vulnerability, and Optimization in Developer Prompts",
      "title_zh": "翻译失败",
      "authors": [
        "Dhia Elhaq Rzig",
        "Dhruba Jyoti Paul",
        "Kaiser Pister",
        "Jordan Henkel",
        "Foyzul Hassan"
      ],
      "abstract": "The tidal wave of advancements in Large Language Models (LLMs) has led to\ntheir swift integration into application-level logic. Many software systems now\nuse prompts to interact with these black-box models, combining natural language\nwith dynamic values interpolated at runtime, to perform tasks ranging from\nsentiment analysis to question answering. Due to the programmatic and\nstructured natural language aspects of these prompts, we refer to them as\nDeveloper Prompts. Unlike traditional software artifacts, Dev Prompts blend\nnatural language instructions with artificial languages such as programming and\nmarkup languages, thus requiring specialized tools for analysis, distinct from\nclassical software evaluation methods.\n  In response to this need, we introduce PromptDoctor, a tool explicitly\ndesigned to detect and correct issues of Dev Prompts. PromptDoctor identifies\nand addresses problems related to bias, vulnerability, and sub-optimal\nperformance in Dev Prompts, helping mitigate their possible harms. In our\nanalysis of 2,173 Dev Prompts, selected as a representative sample of 40,573\nDev Prompts, we found that 3.46% contained one or more forms of bias, 10.75%\nwere vulnerable to prompt injection attacks. Additionally, 3,310 were amenable\nto automated prompt optimization. To address these issues, we applied\nPromptDoctor to the flawed Dev Prompts we discovered. PromptDoctor de-biased\n68.29% of the biased Dev Prompts, hardened 41.81% of the vulnerable Dev\nPrompts, and improved the performance of 37.1% sub-optimal Dev Prompts.\nFinally, we developed a PromptDoctor VSCode extension, enabling developers to\neasily enhance Dev Prompts in their existing development workflows. The data\nand source code for this work are available at",
      "tldr_zh": "该研究针对Large Language Models (LLMs) 在软件系统中使用的Developer Prompts，引入了PromptDoctor工具，用于自动检测和修复这些提示中的bias、vulnerability和性能优化问题。研究分析了2,173个代表性Developer Prompts，发现3.46%存在bias，10.75%易受prompt injection attacks影响，且3,310个可优化。PromptDoctor成功修复了68.29%的bias提示、41.81%的vulnerability提示和37.1%的性能不佳提示，并开发了VSCode扩展以便开发者无缝集成，从而提升了LLMs应用的可靠性和安全性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12521v1",
      "published_date": "2025-01-21 22:24:03 UTC",
      "updated_date": "2025-01-21 22:24:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:31:59.001207"
    },
    {
      "arxiv_id": "2501.12508v1",
      "title": "The Finite Element Neural Network Method: One Dimensional Study",
      "title_zh": "有限元神经网络方法：一维研究",
      "authors": [
        "Mohammed Abda",
        "Elsa Piollet",
        "Christopher Blake",
        "Frédérick P. Gosselin"
      ],
      "abstract": "The potential of neural networks (NN) in engineering is rooted in their\ncapacity to understand intricate patterns and complex systems, leveraging their\nuniversal nonlinear approximation capabilities and high expressivity.\nMeanwhile, conventional numerical methods, backed by years of meticulous\nrefinement, continue to be the standard for accuracy and dependability.\nBridging these paradigms, this research introduces the finite element neural\nnetwork method (FENNM) within the framework of the Petrov-Galerkin method using\nconvolution operations to approximate the weighted residual of the differential\nequations. The NN generates the global trial solution, while the test functions\nbelong to the Lagrange test function space. FENNM introduces several key\nadvantages. Notably, the weak-form of the differential equations introduces\nflux terms that contribute information to the loss function compared to VPINN,\nhp-VPINN, and cv-PINN. This enables the integration of forcing terms and\nnatural boundary conditions into the loss function similar to conventional\nfinite element method (FEM) solvers, facilitating its optimization, and\nextending its applicability to more complex problems, which will ease\nindustrial adoption. This study will elaborate on the derivation of FENNM,\nhighlighting its similarities with FEM. Additionally, it will provide insights\ninto optimal utilization strategies and user guidelines to ensure\ncost-efficiency. Finally, the study illustrates the robustness and accuracy of\nFENNM by presenting multiple numerical case studies and applying adaptive mesh\nrefinement techniques.",
      "tldr_zh": "这篇论文引入了有限元神经网络方法 (FENNM)，它将神经网络的非线性逼近能力与 Petrov-Galerkin 方法结合，使用卷积操作来近似微分方程的加权残差，从而生成全局试验解。FENNM 的关键优势在于弱形式引入通量项到损失函数中，类似于传统有限元方法 (FEM)，这便于整合强制项和自然边界条件，提高优化效率并扩展到复杂问题。论文阐述了 FENNM 的推导过程、优化策略，并通过多组一维数值案例和自适应网格细化技术，证明了其稳健性和准确性。",
      "categories": [
        "cs.CE",
        "cs.AI"
      ],
      "primary_category": "cs.CE",
      "comment": "27 pages, 13 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.12508v1",
      "published_date": "2025-01-21 21:39:56 UTC",
      "updated_date": "2025-01-21 21:39:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:32:11.345772"
    },
    {
      "arxiv_id": "2501.13962v1",
      "title": "Adaptive Cyber-Attack Detection in IIoT Using Attention-Based LSTM-CNN Models",
      "title_zh": "翻译失败",
      "authors": [
        "Afrah Gueriani",
        "Hamza Kheddar",
        "Ahmed Cherif Mazari"
      ],
      "abstract": "The rapid expansion of the industrial Internet of things (IIoT) has\nintroduced new challenges in securing critical infrastructures against\nsophisticated cyberthreats. This study presents the development and evaluation\nof an advanced Intrusion detection (IDS) based on a hybrid LSTM-convolution\nneural network (CNN)-Attention architecture, specifically designed to detect\nand classify cyberattacks in IIoT environments. The research focuses on two key\nclassification tasks: binary and multi-class classification. The proposed\nmodels was rigorously tested using the Edge-IIoTset dataset. To mitigate the\nclass imbalance in the dataset, the synthetic minority over-sampling technique\n(SMOTE) was employed to generate synthetic samples for the underrepresented\nclasses. This ensured that the model could learn effectively from all classes,\nthereby improving the overall classification performance. Through systematic\nexperimentation, various deep learning (DL) models were compared, ultimately\ndemonstrating that the LSTM-CNN-Attention model consistently outperformed\nothers across key performance metrics. In binary classification, the model\nachieved near-perfect accuracy, while in multi-class classification, it\nmaintained a high accuracy level (99.04%), effectively categorizing different\nattack types with a loss value of 0.0220%.",
      "tldr_zh": "本文提出了一种基于 Attention 的 LSTM-CNN 混合模型，用于适应性检测工业物联网 (IIoT) 环境中的网络攻击，专注于二元分类和多类分类任务。研究团队使用 Edge-IIoTset 数据集进行测试，并采用合成少数过采样技术 (SMOTE) 来缓解数据集中的类别不平衡问题，从而提升模型的学习效果。与其他深度学习模型相比，该模型在关键性能指标上表现出色，在二元分类中实现近乎完美的准确率，而在多类分类中达到99.04%的准确率和0.0220%的损失值。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13962v1",
      "published_date": "2025-01-21 20:52:23 UTC",
      "updated_date": "2025-01-21 20:52:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:32:23.206312"
    },
    {
      "arxiv_id": "2501.12489v2",
      "title": "Large-image Object Detection for Fine-grained Recognition of Punches Patterns in Medieval Panel Painting",
      "title_zh": "翻译失败",
      "authors": [
        "Josh Bruegger",
        "Diana Ioana Catana",
        "Vanja Macovaz",
        "Matias Valdenegro-Toro",
        "Matthia Sabatelli",
        "Marco Zullich"
      ],
      "abstract": "The attribution of the author of an art piece is typically a laborious manual\nprocess, usually relying on subjective evaluations of expert figures. However,\nthere are some situations in which quantitative features of the artwork can\nsupport these evaluations. The extraction of these features can sometimes be\nautomated, for instance, with the use of Machine Learning (ML) techniques. An\nexample of these features is represented by repeated, mechanically impressed\npatterns, called punches, present chiefly in 13th and 14th-century panel\npaintings from Tuscany. Previous research in art history showcased a strong\nconnection between the shapes of punches and specific artists or workshops,\nsuggesting the possibility of using these quantitative cues to support the\nattribution. In the present work, we first collect a dataset of large-scale\nimages of these panel paintings. Then, using YOLOv10, a recent and popular\nobject detection model, we train a ML pipeline to perform object detection on\nthe punches contained in the images. Due to the large size of the images, the\ndetection procedure is split across multiple frames by adopting a\nsliding-window approach with overlaps, after which the predictions are combined\nfor the whole image using a custom non-maximal suppression routine. Our results\nindicate how art historians working in the field can reliably use our method\nfor the identification and extraction of punches.",
      "tldr_zh": "这篇论文针对中世纪托斯卡纳面板画中的 punches 图案，提出了一种基于 YOLOv10 的对象检测方法，以支持艺术品作者归属的定量分析。研究者首先收集了一个大型图像数据集，然后采用滑动窗口方法处理大图像，并结合自定义非极大值抑制（non-maximal suppression）来合并预测结果。实验结果表明，该方法能可靠地识别和提取 punches 图案，为艺术史学家提供客观工具，提升归属过程的准确性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12489v2",
      "published_date": "2025-01-21 20:30:51 UTC",
      "updated_date": "2025-04-24 10:12:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:32:35.388939"
    },
    {
      "arxiv_id": "2501.12487v1",
      "title": "fabSAM: A Farmland Boundary Delineation Method Based on the Segment Anything Model",
      "title_zh": "fabSAM：一种基于 Segment Anything Model 的农田边界划分方法",
      "authors": [
        "Yufeng Xie",
        "Hanzhi Wu",
        "Hongxiang Tong",
        "Lei Xiao",
        "Wenwen Zhou",
        "Ling Li",
        "Thomas Cherico Wanger"
      ],
      "abstract": "Delineating farmland boundaries is essential for agricultural management such\nas crop monitoring and agricultural census. Traditional methods using remote\nsensing imagery have been efficient but limited in generalisation. The Segment\nAnything Model (SAM), known for its impressive zero shot performance, has been\nadapted for remote sensing tasks through prompt learning and fine tuning. Here,\nwe propose a SAM based farmland boundary delineation framework 'fabSAM' that\ncombines a Deeplabv3+ based Prompter and SAM. Also, a fine tuning strategy was\nintroduced to enable SAMs decoder to improve the use of prompt information.\nExperimental results on the AI4Boundaries and AI4SmallFarms datasets have shown\nthat fabSAM has a significant improvement in farmland region identification and\nboundary delineation. Compared to zero shot SAM, fabSAM surpassed it by 23.5%\nand 15.1% in mIOU on the AI4Boundaries and AI4SmallFarms datasets,\nrespectively. For Deeplabv3+, fabSAM outperformed it by 4.9% and 12.5% in mIOU,\nrespectively. These results highlight the effectiveness of fabSAM, which also\nmeans that we can more easily obtain the global farmland region and boundary\nmaps from open source satellite image datasets like Sentinel2.",
      "tldr_zh": "该研究提出了一种基于 Segment Anything Model (SAM) 的农田边界划分方法 fabSAM，旨在提升农业管理中作物监测和普查的效率。fabSAM 结合 Deeplabv3+ 作为 Prompter，并引入微调策略来优化 SAM 的解码器对提示信息的利用，从而改善农田区域识别和边界划分。实验结果显示，在 AI4Boundaries 和 AI4SmallFarms 数据集上，fabSAM 分别比零样本 SAM 提高了 23.5% 和 15.1% 的 mIOU，比 Deeplabv3+ 提高了 4.9% 和 12.5% 的 mIOU，这使得从开源卫星图像如 Sentinel2 中更容易获取精确的农田地图。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12487v1",
      "published_date": "2025-01-21 20:23:22 UTC",
      "updated_date": "2025-01-21 20:23:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:32:47.578856"
    },
    {
      "arxiv_id": "2501.12485v1",
      "title": "R2D2: Remembering, Reflecting and Dynamic Decision Making for Web Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Tenghao Huang",
        "Kinjal Basu",
        "Ibrahim Abdelaziz",
        "Pavan Kapanipathi",
        "Jonathan May",
        "Muhao Chen"
      ],
      "abstract": "The proliferation of web agents necessitates advanced navigation and\ninteraction strategies within complex web environments. Current models often\nstruggle with efficient navigation and action execution due to limited\nvisibility and understanding of web structures. Our proposed R2D2 framework\naddresses these challenges by integrating two paradigms: Remember and Reflect.\nThe Remember paradigm utilizes a replay buffer that aids agents in\nreconstructing the web environment dynamically, thus enabling the formulation\nof a detailed ``map'' of previously visited pages. This helps in reducing\nnavigational errors and optimizing the decision-making process during web\ninteractions. Conversely, the Reflect paradigm allows agents to learn from past\nmistakes by providing a mechanism for error analysis and strategy refinement,\nenhancing overall task performance. We evaluate R2D2 using the WEBARENA\nbenchmark, demonstrating significant improvements over existing methods,\nincluding a 50% reduction in navigation errors and a threefold increase in task\ncompletion rates. Our findings suggest that a combination of memory-enhanced\nnavigation and reflective learning promisingly advances the capabilities of web\nagents, potentially benefiting various applications such as automated customer\nservice and personal digital assistants.",
      "tldr_zh": "该论文提出了 R2D2 框架，用于提升 web 代理在复杂 web 环境中的导航和交互能力，通过整合 Remember paradigm 和 Reflect paradigm 两大机制来解决现有模型的局限性。Remember paradigm 利用 replay buffer 动态重建 web 环境，形成详细的“地图”，从而减少导航错误并优化决策过程；Reflect paradigm 则通过错误分析和策略改进，帮助代理从过去失误中学习，提升整体任务性能。在 WEBARENA 基准测试中，R2D2 相较现有方法实现了导航错误减少 50% 和任务完成率提高三倍，展示了记忆增强导航和反思学习相结合的潜力，可应用于自动客服和个人数字助理等领域。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12485v1",
      "published_date": "2025-01-21 20:21:58 UTC",
      "updated_date": "2025-01-21 20:21:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:33:00.183670"
    },
    {
      "arxiv_id": "2501.12479v1",
      "title": "Degree-Based Logical Adjacency Checking (DBLAC): A Novel Heuristic for Vertex Coloring",
      "title_zh": "翻译失败",
      "authors": [
        "Prashant Verma"
      ],
      "abstract": "Degree Based Logical Adjacency Checking (DBLAC). An efficient coloring of\ngraphs with unique logical AND operations. The logical AND operation shows more\neffective color assignment and fewer number of induced colors in the case of\ncommon edges between vertices. In this work, we provide a detailed theoretical\nanalysis of DBLAC's time and space complexity. It furthermore shows its\neffectiveness through prolonged experiments on standard benchmark graphs. We\ncompare it with existing algorithms, namely DSATUR and Recursive Largest First\n(RLF). Second, we show how DBLAC achieves competitive results with respect to\nboth the number of colors used and runtime performance.",
      "tldr_zh": "这篇论文提出了一种新的图着色启发式算法 Degree-Based Logical Adjacency Checking (DBLAC)，它利用顶点的度数和逻辑 AND 操作来优化颜色分配，尤其在顶点间存在公共边时，能减少诱导颜色数量。论文对 DBLAC 的时间和空间复杂度进行了详细的理论分析，并通过在标准基准图上的实验验证了其有效性。与现有算法 DSATUR 和 Recursive Largest First (RLF) 相比，DBLAC 在颜色使用数量和运行时间性能上表现出竞争优势。",
      "categories": [
        "cs.DM",
        "cs.AI"
      ],
      "primary_category": "cs.DM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12479v1",
      "published_date": "2025-01-21 20:07:22 UTC",
      "updated_date": "2025-01-21 20:07:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:33:11.456604"
    },
    {
      "arxiv_id": "2501.12465v1",
      "title": "Adaptive PII Mitigation Framework for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Shubhi Asthana",
        "Ruchi Mahindru",
        "Bing Zhang",
        "Jorge Sanz"
      ],
      "abstract": "Artificial Intelligence (AI) faces growing challenges from evolving data\nprotection laws and enforcement practices worldwide. Regulations like GDPR and\nCCPA impose strict compliance requirements on Machine Learning (ML) models,\nespecially concerning personal data use. These laws grant individuals rights\nsuch as data correction and deletion, complicating the training and deployment\nof Large Language Models (LLMs) that rely on extensive datasets. Public data\navailability does not guarantee its lawful use for ML, amplifying these\nchallenges.\n  This paper introduces an adaptive system for mitigating risk of Personally\nIdentifiable Information (PII) and Sensitive Personal Information (SPI) in\nLLMs. It dynamically aligns with diverse regulatory frameworks and integrates\nseamlessly into Governance, Risk, and Compliance (GRC) systems. The system uses\nadvanced NLP techniques, context-aware analysis, and policy-driven masking to\nensure regulatory compliance.\n  Benchmarks highlight the system's effectiveness, with an F1 score of 0.95 for\nPassport Numbers, outperforming tools like Microsoft Presidio (0.33) and Amazon\nComprehend (0.54). In human evaluations, the system achieved an average user\ntrust score of 4.6/5, with participants acknowledging its accuracy and\ntransparency. Observations demonstrate stricter anonymization under GDPR\ncompared to CCPA, which permits pseudonymization and user opt-outs. These\nresults validate the system as a scalable and robust solution for enterprise\nprivacy compliance.",
      "tldr_zh": "这篇论文提出了一种自适应框架，用于缓解 Large Language Models (LLMs) 中的 Personally Identifiable Information (PII) 和 Sensitive Personal Information (SPI) 风险，以应对 GDPR 和 CCPA 等数据保护法规的严格要求。框架通过高级 NLP 技术、上下文感知分析和政策驱动的掩码，动态适应各种监管框架并无缝整合到 Governance, Risk, and Compliance (GRC) 系统。实验基准显示，该系统对护照号码的 F1 分数达到 0.95，显著优于 Microsoft Presidio (0.33) 和 Amazon Comprehend (0.54)，并在人类评估中获得 4.6/5 的平均信任分数。结果证明该框架是企业隐私合规的可扩展且稳健解决方案，尤其在 GDPR 下实现更严格的匿名化。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper has been accepted at PPAI-25, the 6th AAAI Workshop on\n  Privacy-Preserving Artificial Intelligence",
      "pdf_url": "http://arxiv.org/pdf/2501.12465v1",
      "published_date": "2025-01-21 19:22:45 UTC",
      "updated_date": "2025-01-21 19:22:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:33:24.856690"
    },
    {
      "arxiv_id": "2501.12456v1",
      "title": "Deploying Privacy Guardrails for LLMs: A Comparative Analysis of Real-World Applications",
      "title_zh": "针对大型语言模型部署隐私保障机制：真实世界应用的比较分析",
      "authors": [
        "Shubhi Asthana",
        "Bing Zhang",
        "Ruchi Mahindru",
        "Chad DeLuca",
        "Anna Lisa Gentile",
        "Sandeep Gopisetty"
      ],
      "abstract": "The adoption of Large Language Models (LLMs) has revolutionized AI\napplications but poses significant challenges in safeguarding user privacy.\nEnsuring compliance with privacy regulations such as GDPR and CCPA while\naddressing nuanced privacy risks requires robust and scalable frameworks. This\npaper presents a detailed study of OneShield Privacy Guard, a framework\ndesigned to mitigate privacy risks in user inputs and LLM outputs across\nenterprise and open-source settings. We analyze two real-world deployments:(1)\na multilingual privacy-preserving system integrated with Data and Model\nFactory, focusing on enterprise-scale data governance; and (2) PR Insights, an\nopen-source repository emphasizing automated triaging and community-driven\nrefinements. In Deployment 1, OneShield achieved a 0.95 F1 score in detecting\nsensitive entities like dates, names, and phone numbers across 26 languages,\noutperforming state-of-the-art tool such as StarPII and Presidio by up to 12\\%.\nDeployment 2, with an average F1 score of 0.86, reduced manual effort by over\n300 hours in three months, accurately flagging 8.25\\% of 1,256 pull requests\nfor privacy risks with enhanced context sensitivity. These results demonstrate\nOneShield's adaptability and efficacy in diverse environments, offering\nactionable insights for context-aware entity recognition, automated compliance,\nand ethical AI adoption. This work advances privacy-preserving frameworks,\nsupporting user trust and compliance across operational contexts.",
      "tldr_zh": "这篇论文分析了在部署 Large Language Models (LLMs) 时面临的隐私挑战，并引入了 OneShield Privacy Guard 框架，以确保遵守 GDPR 和 CCPA 等法规。该框架通过两个真实案例进行评估：(1) 与 Data and Model Factory 集成的企业级多语言系统，实现了 0.95 的 F1 score，在 26 种语言中检测敏感实体（如日期、姓名和电话号码）时比 StarPII 和 Presidio 高出 12%；(2) 开源仓库 PR Insights，平均 F1 score 为 0.86，并减少了超过 300 小时的手动审查工作。这些结果突显了 OneShield 的适应性和有效性，为上下文感知实体识别、自动化合规和道德 AI 采用提供了关键见解。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.CR",
      "comment": "This paper has been accepted at Deployable AI workshop at AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.12456v1",
      "published_date": "2025-01-21 19:04:53 UTC",
      "updated_date": "2025-01-21 19:04:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:33:36.952538"
    },
    {
      "arxiv_id": "2501.12392v1",
      "title": "Learning segmentation from point trajectories",
      "title_zh": "翻译失败",
      "authors": [
        "Laurynas Karazija",
        "Iro Laina",
        "Christian Rupprecht",
        "Andrea Vedaldi"
      ],
      "abstract": "We consider the problem of segmenting objects in videos based on their motion\nand no other forms of supervision. Prior work has often approached this problem\nby using the principle of common fate, namely the fact that the motion of\npoints that belong to the same object is strongly correlated. However, most\nauthors have only considered instantaneous motion from optical flow. In this\nwork, we present a way to train a segmentation network using long-term point\ntrajectories as a supervisory signal to complement optical flow. The key\ndifficulty is that long-term motion, unlike instantaneous motion, is difficult\nto model -- any parametric approximation is unlikely to capture complex motion\npatterns over long periods of time. We instead draw inspiration from subspace\nclustering approaches, proposing a loss function that seeks to group the\ntrajectories into low-rank matrices where the motion of object points can be\napproximately explained as a linear combination of other point tracks. Our\nmethod outperforms the prior art on motion-based segmentation, which shows the\nutility of long-term motion and the effectiveness of our formulation.",
      "tldr_zh": "本文研究了基于运动的无监督视频物体分割问题，使用长期点轨迹（point trajectories）作为监督信号来补充光学流（optical flow）的瞬时运动。受子空间聚类（subspace clustering）启发，该方法提出了一种损失函数（loss function），将轨迹分组到低秩矩阵（low-rank matrices）中，使同一物体的点运动能近似地解释为其他点轨迹的线性组合。实验结果表明，该方法在运动-based segmentation任务上超过了现有技术，证明了长期运动的效用和方法的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "NeurIPS 2024 Spotlight. Project\n  https://www.robots.ox.ac.uk/~vgg/research/lrtl/",
      "pdf_url": "http://arxiv.org/pdf/2501.12392v1",
      "published_date": "2025-01-21 18:59:53 UTC",
      "updated_date": "2025-01-21 18:59:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:33:47.207880"
    },
    {
      "arxiv_id": "2501.12391v1",
      "title": "Physics of Skill Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Ziming Liu",
        "Yizhou Liu",
        "Eric J. Michaud",
        "Jeff Gore",
        "Max Tegmark"
      ],
      "abstract": "We aim to understand physics of skill learning, i.e., how skills are learned\nin neural networks during training. We start by observing the Domino effect,\ni.e., skills are learned sequentially, and notably, some skills kick off\nlearning right after others complete learning, similar to the sequential fall\nof domino cards. To understand the Domino effect and relevant behaviors of\nskill learning, we take physicists' approach of abstraction and simplification.\nWe propose three models with varying complexities -- the Geometry model, the\nResource model, and the Domino model, trading between reality and simplicity.\nThe Domino effect can be reproduced in the Geometry model, whose resource\ninterpretation inspires the Resource model, which can be further simplified to\nthe Domino model. These models present different levels of abstraction and\nsimplification; each is useful to study some aspects of skill learning. The\nGeometry model provides interesting insights into neural scaling laws and\noptimizers; the Resource model sheds light on the learning dynamics of\ncompositional tasks; the Domino model reveals the benefits of modularity. These\nmodels are not only conceptually interesting -- e.g., we show how Chinchilla\nscaling laws can emerge from the Geometry model, but also are useful in\npractice by inspiring algorithmic development -- e.g., we show how simple\nalgorithmic changes, motivated by these toy models, can speed up the training\nof deep learning models.",
      "tldr_zh": "本文研究神经网络中技能学习的物理机制，观察到“Domino effect”现象，即技能以顺序方式学习，且某些技能在其他技能学习完成后立即启动。为解释这一现象，作者提出三个简化模型：Geometry model、Resource model 和 Domino model，这些模型从不同抽象层面揭示技能学习动态，例如Geometry model解释神经网络缩放定律和优化器行为。实验和分析显示，这些模型不仅概念上丰富（如衍生出Chinchilla scaling laws），还可指导算法改进，以加速深度学习模型的训练过程。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.data-an",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "25 pages, 20 figures. Codes are available at\n  https://github.com/KindXiaoming/physics_of_skill_learning",
      "pdf_url": "http://arxiv.org/pdf/2501.12391v1",
      "published_date": "2025-01-21 18:59:49 UTC",
      "updated_date": "2025-01-21 18:59:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:33:59.048819"
    },
    {
      "arxiv_id": "2501.12380v1",
      "title": "MMVU: Measuring Expert-Level Multi-Discipline Video Understanding",
      "title_zh": "MMVU：测量专家级别多学科视频理解",
      "authors": [
        "Yilun Zhao",
        "Lujing Xie",
        "Haowei Zhang",
        "Guo Gan",
        "Yitao Long",
        "Zhiyuan Hu",
        "Tongyan Hu",
        "Weiyuan Chen",
        "Chuhan Li",
        "Junyang Song",
        "Zhijian Xu",
        "Chengye Wang",
        "Weifeng Pan",
        "Ziyao Shangguan",
        "Xiangru Tang",
        "Zhenwen Liang",
        "Yixin Liu",
        "Chen Zhao",
        "Arman Cohan"
      ],
      "abstract": "We introduce MMVU, a comprehensive expert-level, multi-discipline benchmark\nfor evaluating foundation models in video understanding. MMVU includes 3,000\nexpert-annotated questions spanning 27 subjects across four core disciplines:\nScience, Healthcare, Humanities & Social Sciences, and Engineering. Compared to\nprior benchmarks, MMVU features three key advancements. First, it challenges\nmodels to apply domain-specific knowledge and perform expert-level reasoning to\nanalyze specialized-domain videos, moving beyond the basic visual perception\ntypically assessed in current video benchmarks. Second, each example is\nannotated by human experts from scratch. We implement strict data quality\ncontrols to ensure the high quality of the dataset. Finally, each example is\nenriched with expert-annotated reasoning rationals and relevant domain\nknowledge, facilitating in-depth analysis. We conduct an extensive evaluation\nof 32 frontier multimodal foundation models on MMVU. The latest\nSystem-2-capable models, o1 and Gemini 2.0 Flash Thinking, achieve the highest\nperformance among the tested models. However, they still fall short of matching\nhuman expertise. Through in-depth error analyses and case studies, we offer\nactionable insights for future advancements in expert-level,\nknowledge-intensive video understanding for specialized domains.",
      "tldr_zh": "本文提出 MMVU，这是一个专家级、多学科视频理解基准，包含 3000 个专家标注的问题，覆盖 Science, Healthcare, Humanities & Social Sciences 和 Engineering 等 27 个主题。相比现有基准，MMVU 的创新包括要求模型应用领域特定知识进行专家级推理、确保数据高质量标注，以及为每个例子添加专家注解的推理理由和相关领域知识。研究评估了 32 个前沿多模态基础模型，结果显示 o1 和 Gemini 2.0 Flash Thinking 模型表现最佳，但仍未达到人类专家水平。通过深入错误分析和案例研究，该论文提供可操作见解，以推动知识密集型视频理解的未来发展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12380v1",
      "published_date": "2025-01-21 18:56:18 UTC",
      "updated_date": "2025-01-21 18:56:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:34:11.866442"
    },
    {
      "arxiv_id": "2501.12434v1",
      "title": "Enhancing Retrosynthesis with Conformer: A Template-Free Method",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaxi Zhuang",
        "Qian Zhang",
        "Ying Qian"
      ],
      "abstract": "Retrosynthesis plays a crucial role in the fields of organic synthesis and\ndrug development, where the goal is to identify suitable reactants that can\nyield a target product molecule. Although existing methods have achieved\nnotable success, they typically overlook the 3D conformational details and\ninternal spatial organization of molecules. This oversight makes it challenging\nto predict reactants that conform to genuine chemical principles, particularly\nwhen dealing with complex molecular structures, such as polycyclic and\nheteroaromatic compounds. In response to this challenge, we introduce a novel\ntransformer-based, template-free approach that incorporates 3D conformer data\nand spatial information. Our approach includes an Atom-align Fusion module that\nintegrates 3D positional data at the input stage, ensuring correct alignment\nbetween atom tokens and their respective 3D coordinates. Additionally, we\npropose a Distance-weighted Attention mechanism that refines the self-attention\nprocess, constricting the model s focus to relevant atom pairs in 3D space.\nExtensive experiments on the USPTO-50K dataset demonstrate that our model\noutperforms previous template-free methods, setting a new benchmark for the\nfield. A case study further highlights our method s ability to predict\nreasonable and accurate reactants.",
      "tldr_zh": "该研究针对回顾合成中的问题，提出了一种基于 Transformer 的无模板方法，通过整合分子 3D 构象数据和空间信息，解决了现有方法忽略分子内部空间组织的局限性。方法包括 Atom-align Fusion 模块，用于在输入阶段对齐原子标记和 3D 坐标，以及 Distance-weighted Attention 机制，以优化自注意力过程并关注 3D 空间中相关的原子对。在 USPTO-50K 数据集上的实验表明，该模型超越了之前的无模板方法，建立了新基准，并通过案例研究证明了其预测合理且准确的反应物能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12434v1",
      "published_date": "2025-01-21 18:54:16 UTC",
      "updated_date": "2025-01-21 18:54:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:34:22.974816"
    },
    {
      "arxiv_id": "2501.12375v2",
      "title": "Video Depth Anything: Consistent Depth Estimation for Super-Long Videos",
      "title_zh": "翻译失败",
      "authors": [
        "Sili Chen",
        "Hengkai Guo",
        "Shengnan Zhu",
        "Feihu Zhang",
        "Zilong Huang",
        "Jiashi Feng",
        "Bingyi Kang"
      ],
      "abstract": "Depth Anything has achieved remarkable success in monocular depth estimation\nwith strong generalization ability. However, it suffers from temporal\ninconsistency in videos, hindering its practical applications. Various methods\nhave been proposed to alleviate this issue by leveraging video generation\nmodels or introducing priors from optical flow and camera poses. Nonetheless,\nthese methods are only applicable to short videos (< 10 seconds) and require a\ntrade-off between quality and computational efficiency. We propose Video Depth\nAnything for high-quality, consistent depth estimation in super-long videos\n(over several minutes) without sacrificing efficiency. We base our model on\nDepth Anything V2 and replace its head with an efficient spatial-temporal head.\nWe design a straightforward yet effective temporal consistency loss by\nconstraining the temporal depth gradient, eliminating the need for additional\ngeometric priors. The model is trained on a joint dataset of video depth and\nunlabeled images, similar to Depth Anything V2. Moreover, a novel\nkey-frame-based strategy is developed for long video inference. Experiments\nshow that our model can be applied to arbitrarily long videos without\ncompromising quality, consistency, or generalization ability. Comprehensive\nevaluations on multiple video benchmarks demonstrate that our approach sets a\nnew state-of-the-art in zero-shot video depth estimation. We offer models of\ndifferent scales to support a range of scenarios, with our smallest model\ncapable of real-time performance at 30 FPS.",
      "tldr_zh": "本文提出 Video Depth Anything，一种基于 Depth Anything V2 的模型，用于实现超长视频（数分钟以上）的高质量、一致深度估计，而不牺牲计算效率。该模型通过替换为高效的空间-时间头部和设计临时一致性损失（约束临时深度梯度），避免了依赖额外几何先验的需求，并采用基于关键帧的策略进行长视频推理。实验结果显示，该方法在多个视频基准上设置了新的零-shot video depth estimation 状态-of-the-art 水平，支持任意长视频处理，并提供不同规模的模型，最小版本可实现30 FPS 的实时性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://videodepthanything.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2501.12375v2",
      "published_date": "2025-01-21 18:53:30 UTC",
      "updated_date": "2025-01-22 11:33:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:34:35.406861"
    },
    {
      "arxiv_id": "2501.12374v1",
      "title": "Expertise elevates AI usage: experimental evidence comparing laypeople and professional artists",
      "title_zh": "专业知识提升AI使用：比较普通人与专业艺术家的实验证据",
      "authors": [
        "Thomas F. Eisenmann",
        "Andres Karjus",
        "Mar Canet Sola",
        "Levin Brinkmann",
        "Bramantyo Ibrahim Supriyatno",
        "Iyad Rahwan"
      ],
      "abstract": "Novel capacities of generative AI to analyze and generate cultural artifacts\nraise inevitable questions about the nature and value of artistic education and\nhuman expertise. Has AI already leveled the playing field between professional\nartists and laypeople, or do trained artistic expressive capacity, curation\nskills and experience instead enhance the ability to use these new tools? In\nthis pre-registered study, we conduct experimental comparisons between 50\nactive artists and a demographically matched sample of laypeople. We designed\ntwo tasks to approximate artistic practice for testing their capabilities in\nboth faithful and creative image creation: replicating a reference image, and\nmoving as far away as possible from it. We developed a bespoke platform where\nparticipants used a modern text-to-image model to complete both tasks. We also\ncollected and compared participants' sentiments towards AI. On average, artists\nproduced more faithful and creative outputs than their lay counterparts,\nalthough only by a small margin. While AI may ease content creation,\nprofessional expertise is still valuable - even within the confined space of\ngenerative AI itself. Finally, we also explored how well an exemplary\nvision-capable large language model (GPT-4o) would complete the same tasks, if\ngiven the role of an image generation agent, and found it performed on par in\ncopying but outperformed even artists in the creative task. The very best\nresults were still produced by humans in both tasks. These outcomes highlight\nthe importance of integrating artistic skills with AI training to prepare\nartists and other visual professionals for a technologically evolving\nlandscape. We see a potential in collaborative synergy with generative AI,\nwhich could reshape creative industries and education in the arts.",
      "tldr_zh": "这篇论文通过预注册实验比较了50名专业艺术家和匹配的普通人在使用生成式AI进行图像创建时的表现，探讨了AI是否削弱了艺术专长的价值。研究设计了两个任务：忠实复制参考图像和尽可能远离参考图像的创造性生成，使用现代text-to-image模型作为工具。结果显示，艺术家在忠实度和创造性输出上仅略微优于普通人，而GPT-4o在复制任务上与艺术家相当，在创造性任务上甚至表现更好，但人类的最佳成果仍领先。论文强调，专业技能能提升AI的使用效果，并建议将艺术教育与AI训练整合，以适应技术演进的创意产业。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "Eisenmann and Karjus contributed equally to this work and share first\n  authorship",
      "pdf_url": "http://arxiv.org/pdf/2501.12374v1",
      "published_date": "2025-01-21 18:53:21 UTC",
      "updated_date": "2025-01-21 18:53:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:34:47.760747"
    },
    {
      "arxiv_id": "2501.12372v5",
      "title": "Is Long Context All You Need? Leveraging LLM's Extended Context for NL2SQL",
      "title_zh": "翻译失败",
      "authors": [
        "Yeounoh Chung",
        "Gaurav T. Kakkar",
        "Yu Gan",
        "Brenton Milne",
        "Fatma Ozcan"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities across\na range of natural language processing tasks. In particular, improvements in\nreasoning abilities and the expansion of context windows have opened new\navenues for leveraging these powerful models. NL2SQL is challenging in that the\nnatural language question is inherently ambiguous, while the SQL generation\nrequires a precise understanding of complex data schema and semantics. One\napproach to this semantic ambiguous problem is to provide more and sufficient\ncontextual information.\n  In this work, we explore the performance and the latency trade-offs of the\nextended context window (a.k.a., long context) offered by Google's\nstate-of-the-art LLM (\\textit{gemini-1.5-pro}). We study the impact of various\ncontextual information, including column example values, question and SQL query\npairs, user-provided hints, SQL documentation, and schema. To the best of our\nknowledge, this is the first work to study how the extended context window and\nextra contextual information can help NL2SQL generation with respect to both\naccuracy and latency cost. We show that long context LLMs are robust and do not\nget lost in the extended contextual information. Additionally, our long-context\nNL2SQL pipeline based on Google's \\textit{gemini-pro-1.5} achieve strong\nperformances on various benchmark datasets without finetuning and expensive\nself-consistency based techniques.",
      "tldr_zh": "这篇论文探讨了利用大型语言模型(LLM)的扩展上下文窗口（长上下文）来提升 NL2SQL 任务的性能，旨在解决自然语言查询的模糊性和复杂数据模式的挑战。研究团队使用 Google 的 gemini-1.5-pro 模型，评估了多种上下文信息（如列示例值、问题和 SQL 查询对、用户提示、SQL 文档和模式）对生成准确性和延迟成本的影响。结果表明，长上下文 LLM 表现出色，能够稳健处理额外信息，并在各种基准数据集上实现强劲性能，而无需进行微调或昂贵的自一致性技术。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "13 pages, 6 figures, VLDB 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.12372v5",
      "published_date": "2025-01-21 18:52:15 UTC",
      "updated_date": "2025-03-20 17:39:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:34:59.690089"
    },
    {
      "arxiv_id": "2501.12370v2",
      "title": "Parameters vs FLOPs: Scaling Laws for Optimal Sparsity for Mixture-of-Experts Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Samira Abnar",
        "Harshay Shah",
        "Dan Busbridge",
        "Alaaeldin Mohamed Elnouby Ali",
        "Josh Susskind",
        "Vimal Thilak"
      ],
      "abstract": "Scaling the capacity of language models has consistently proven to be a\nreliable approach for improving performance and unlocking new capabilities.\nCapacity can be primarily defined by two dimensions: the number of model\nparameters and the compute per example. While scaling typically involves\nincreasing both, the precise interplay between these factors and their combined\ncontribution to overall capacity remains not fully understood. We explore this\nrelationship in the context of sparse Mixture-of-Experts (MoEs), which allow\nscaling the number of parameters without proportionally increasing the FLOPs\nper example. We investigate how varying the sparsity level, i.e., the fraction\nof inactive parameters, impacts model's performance during pretraining and\ndownstream few-shot evaluation. We find that under different constraints (e.g.,\nparameter size and total training compute), there is an optimal level of\nsparsity that improves both training efficiency and model performance. These\nresults provide a better understanding of the impact of sparsity in scaling\nlaws for MoEs and complement existing works in this area, offering insights for\ndesigning more efficient architectures.",
      "tldr_zh": "该研究探讨了在 Mixture-of-Experts (MoEs) 语言模型中，参数数量（Parameters）和每例计算量（FLOPs）之间的关系，以及稀疏度（Sparsity）对模型性能的影响。作者通过调整稀疏度水平，即非激活参数的比例，分析其在预训练和下游任务中的效果，发现存在一个最优稀疏度，能在参数大小和总训练计算约束下提升训练效率和模型表现。这些发现完善了 MoEs 的 Scaling Laws 理论，为设计更高效的模型架构提供了宝贵洞见。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12370v2",
      "published_date": "2025-01-21 18:51:15 UTC",
      "updated_date": "2025-01-25 02:41:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:35:11.010897"
    },
    {
      "arxiv_id": "2501.12369v2",
      "title": "DARB-Splatting: Generalizing Splatting with Decaying Anisotropic Radial Basis Functions",
      "title_zh": "翻译失败",
      "authors": [
        "Vishagar Arunan",
        "Saeedha Nazar",
        "Hashiru Pramuditha",
        "Vinasirajan Viruthshaan",
        "Sameera Ramasinghe",
        "Simon Lucey",
        "Ranga Rodrigo"
      ],
      "abstract": "Splatting-based 3D reconstruction methods have gained popularity with the\nadvent of 3D Gaussian Splatting, efficiently synthesizing high-quality novel\nviews. These methods commonly resort to using exponential family functions,\nsuch as the Gaussian function, as reconstruction kernels due to their\nanisotropic nature, ease of projection, and differentiability in rasterization.\nHowever, the field remains restricted to variations within the exponential\nfamily, leaving generalized reconstruction kernels largely underexplored,\npartly due to the lack of easy integrability in 3D to 2D projections. In this\nlight, we show that a class of decaying anisotropic radial basis functions\n(DARBFs), which are non-negative functions of the Mahalanobis distance,\nsupports splatting by approximating the Gaussian function's closed-form\nintegration advantage. With this fresh perspective, we demonstrate up to 34%\nfaster convergence during training and a 45% reduction in memory consumption\nacross various DARB reconstruction kernels, while maintaining comparable PSNR,\nSSIM, and LPIPS results. We will make the code available.",
      "tldr_zh": "本研究提出 DARB-Splatting 方法，通过引入 Decaying Anisotropic Radial Basis Functions (DARBFs) 来泛化传统的 splatting 技术，这些函数基于 Mahalanobis distance 的非负形式，支持高效的 3D 到 2D 投影并近似 Gaussian 函数的积分优势。相比现有基于指数族函数的 3D Gaussian Splatting 方法，DARB-Splatting 在训练过程中实现了多达 34% 的收敛速度提升和 45% 的内存消耗减少，同时保持了可比的 PSNR、SSIM 和 LPIPS 性能指标。该方法为 3D 重建提供了更灵活且高效的内核选项，并计划开源代码。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "Link to the project page:\n  https://randomnerds.github.io/darbs.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2501.12369v2",
      "published_date": "2025-01-21 18:49:06 UTC",
      "updated_date": "2025-04-21 10:43:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:35:24.721011"
    },
    {
      "arxiv_id": "2501.12433v2",
      "title": "Owls are wise and foxes are unfaithful: Uncovering animal stereotypes in vision-language models",
      "title_zh": "翻译失败",
      "authors": [
        "Tabinda Aman",
        "Mohammad Nadeem",
        "Shahab Saquib Sohail",
        "Mohammad Anas",
        "Erik Cambria"
      ],
      "abstract": "Animal stereotypes are deeply embedded in human culture and language. They\noften shape our perceptions and expectations of various species. Our study\ninvestigates how animal stereotypes manifest in vision-language models during\nthe task of image generation. Through targeted prompts, we explore whether\nDALL-E perpetuates stereotypical representations of animals, such as \"owls as\nwise,\" \"foxes as unfaithful,\" etc. Our findings reveal significant stereotyped\ninstances where the model consistently generates images aligned with cultural\nbiases. The current work is the first of its kind to examine animal\nstereotyping in vision-language models systematically and to highlight a\ncritical yet underexplored dimension of bias in AI-generated visual content.",
      "tldr_zh": "本研究探讨了动物刻板印象（如“owls as wise”和“foxes as unfaithful”）如何在vision-language models中体现，特别是在图像生成任务中。研究者通过针对性prompts测试DALL-E模型，发现该模型经常生成与文化偏见一致的图像，强化了这些刻板印象。这是首个系统性研究动物刻板印象在AI生成视觉内容中的问题，强调了需要解决这种偏见以提升模型公平性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12433v2",
      "published_date": "2025-01-21 18:41:28 UTC",
      "updated_date": "2025-04-29 05:16:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:35:34.796939"
    },
    {
      "arxiv_id": "2501.12352v3",
      "title": "Test-time regression: a unifying framework for designing sequence models with associative memory",
      "title_zh": "测试时回归：一种用于设计带有关联记忆的序列模型的统一框架",
      "authors": [
        "Ke Alexander Wang",
        "Jiaxin Shi",
        "Emily B. Fox"
      ],
      "abstract": "Sequence models lie at the heart of modern deep learning. However, rapid\nadvancements have produced a diversity of seemingly unrelated architectures,\nsuch as Transformers and recurrent alternatives. In this paper, we introduce a\nunifying framework to understand and derive these sequence models, inspired by\nthe empirical importance of associative recall, the capability to retrieve\ncontextually relevant tokens. We formalize associative recall as a two-step\nprocess, memorization and retrieval, casting memorization as a regression\nproblem. Layers that combine these two steps perform associative recall via\n``test-time regression'' over its input tokens. Prominent layers, including\nlinear attention, state-space models, fast-weight programmers, online learners,\nand softmax attention, arise as special cases defined by three design choices:\nthe regression weights, the regressor function class, and the test-time\noptimization algorithm. Our approach clarifies how linear attention fails to\ncapture inter-token correlations and offers a mathematical justification for\nthe empirical effectiveness of query-key normalization in softmax attention.\nFurther, it illuminates unexplored regions within the design space, which we\nuse to derive novel higher-order generalizations of softmax attention. Beyond\nunification, our work bridges sequence modeling with classic regression\nmethods, a field with extensive literature, paving the way for developing more\npowerful and theoretically principled architectures.",
      "tldr_zh": "本文提出 Test-time regression 框架，作为一种统一方法，用于设计具有关联记忆（associative recall）的序列模型，如 Transformers 和循环替代模型。该框架将关联回忆形式化为记忆化和检索两个步骤，将记忆化视为回归问题，从而通过测试时回归来处理输入令牌间的相关性。研究发现，这一框架解释了 linear attention 的局限性（如无法捕捉令牌间相关性）和 softmax attention 中 query-key normalization 的有效性，并衍生出新型高阶 softmax attention 泛化。通过桥接序列建模与经典回归方法，该工作为开发更强大、理论上更可靠的架构铺平了道路。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12352v3",
      "published_date": "2025-01-21 18:32:31 UTC",
      "updated_date": "2025-05-02 02:07:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:35:47.523073"
    },
    {
      "arxiv_id": "2501.12339v2",
      "title": "Treefix: Enabling Execution with a Tree of Prefixes",
      "title_zh": "翻译失败",
      "authors": [
        "Beatriz Souza",
        "Michael Pradel"
      ],
      "abstract": "The ability to execute code is a prerequisite for various dynamic program\nanalyses. Learning-guided execution has been proposed as an approach to enable\nthe execution of arbitrary code snippets by letting a neural model predict\nlikely values for any missing variables. Although state-of-the-art\nlearning-guided execution approaches, such as LExecutor, can enable the\nexecution of a relative high amount of code, they are limited to predicting a\nrestricted set of possible values and do not use any feedback from previous\nexecutions to execute even more code. This paper presents Treefix, a novel\nlearning-guided execution approach that leverages LLMs to iteratively create\ncode prefixes that enable the execution of a given code snippet. The approach\naddresses the problem in a multi-step fashion, where each step uses feedback\nabout the code snippet and its execution to instruct an LLM to improve a\npreviously generated prefix. This process iteratively creates a tree of\nprefixes, a subset of which is returned to the user as prefixes that maximize\nthe number of executed lines in the code snippet. In our experiments with two\ndatasets of Python code snippets, Treefix achieves 25% and 7% more coverage\nrelative to the current state of the art in learning-guided execution, covering\na total of 84% and 82% of all lines in the code snippets.",
      "tldr_zh": "该研究提出Treefix，一种新型学习引导执行（learning-guided execution）方法，利用大型语言模型（LLMs）迭代生成代码前缀树，以启用任意代码片段的执行。Treefix 通过多步过程，利用代码执行反馈来改进前缀，从而最大化代码覆盖率。实验结果显示，在两个Python代码片段数据集上，Treefix 分别比现有最先进方法提高了25%和7%的覆盖率，总覆盖率达到84%和82%。这为动态程序分析提供了更有效的工具，提升了代码执行的可靠性和效率。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted in research track of the IEEE/ACM International Conference\n  on Software Engineering (ICSE) 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.12339v2",
      "published_date": "2025-01-21 18:13:43 UTC",
      "updated_date": "2025-01-23 12:15:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:35:58.810643"
    },
    {
      "arxiv_id": "2501.12336v1",
      "title": "FuocChuVIP123 at CoMeDi Shared Task: Disagreement Ranking with XLM-Roberta Sentence Embeddings and Deep Neural Regression",
      "title_zh": "翻译失败",
      "authors": [
        "Phuoc Duong Huy Chu"
      ],
      "abstract": "This paper presents results of our system for CoMeDi Shared Task, focusing on\nSubtask 2: Disagreement Ranking. Our system leverages sentence embeddings\ngenerated by the paraphrase-xlm-r-multilingual-v1 model, combined with a deep\nneural regression model incorporating batch normalization and dropout for\nimproved generalization. By predicting the mean of pairwise judgment\ndifferences between annotators, our method explicitly targets disagreement\nranking, diverging from traditional \"gold label\" aggregation approaches. We\noptimized our system with a customized architecture and training procedure,\nachieving competitive performance in Spearman correlation against mean\ndisagreement labels. Our results highlight the importance of robust embeddings,\neffective model architecture, and careful handling of judgment differences for\nranking disagreement in multilingual contexts. These findings provide insights\ninto the use of contextualized representations for ordinal judgment tasks and\nopen avenues for further refinement of disagreement prediction models.",
      "tldr_zh": "这篇论文介绍了 FuocChuVIP123 系统，针对 CoMeDi Shared Task 的 Subtask 2：Disagreement Ranking，通过 XLM-Roberta 的 paraphrase-xlm-r-multilingual-v1 模型生成句子嵌入，并结合深度神经回归模型（包括批标准化和 dropout）来预测注释者之间判断差异的均值。不同于传统的“金标准”聚合方法，该系统专注于直接排名分歧，提高了多语言上下文中的泛化能力。实验结果显示，该系统在 Spearman 相关性上取得了竞争性性能，并突出了稳健嵌入、有效模型架构和处理判断差异的重要性，为序数判断任务的上下文表示提供了宝贵见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at COMEDI shared Task, Workshop at COLING 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.12336v1",
      "published_date": "2025-01-21 18:10:43 UTC",
      "updated_date": "2025-01-21 18:10:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:36:12.312704"
    },
    {
      "arxiv_id": "2501.12332v1",
      "title": "Automatic Labelling with Open-source LLMs using Dynamic Label Schema Integration",
      "title_zh": "开源大语言模型的动态标签模式集成用于自动标注",
      "authors": [
        "Thomas Walshe",
        "Sae Young Moon",
        "Chunyang Xiao",
        "Yawwani Gunawardana",
        "Fran Silavong"
      ],
      "abstract": "Acquiring labelled training data remains a costly task in real world machine\nlearning projects to meet quantity and quality requirements. Recently Large\nLanguage Models (LLMs), notably GPT-4, have shown great promises in labelling\ndata with high accuracy. However, privacy and cost concerns prevent the\nubiquitous use of GPT-4. In this work, we explore effectively leveraging\nopen-source models for automatic labelling. We identify integrating label\nschema as a promising technology but found that naively using the label\ndescription for classification leads to poor performance on high cardinality\ntasks. To address this, we propose Retrieval Augmented Classification (RAC) for\nwhich LLM performs inferences for one label at a time using corresponding label\nschema; we start with the most related label and iterates until a label is\nchosen by the LLM. We show that our method, which dynamically integrates label\ndescription, leads to performance improvements in labelling tasks. We further\nshow that by focusing only on the most promising labels, RAC can trade off\nbetween label quality and coverage - a property we leverage to automatically\nlabel our internal datasets.",
      "tldr_zh": "该论文探讨了使用开源大语言模型（LLMs）进行自动数据标注，以解决传统标注成本高、隐私和费用问题的挑战。作者提出Retrieval Augmented Classification (RAC) 方法，该方法通过动态整合标签模式（label schema），让LLM一次处理一个标签，从最相关的标签开始迭代，从而改善高基数任务的性能。实验结果表明，RAC显著提升了标注准确性，并允许在标签质量和覆盖率之间进行权衡，从而实现内部数据集的自动标注。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2501.12332v1",
      "published_date": "2025-01-21 18:06:54 UTC",
      "updated_date": "2025-01-21 18:06:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:36:22.948818"
    },
    {
      "arxiv_id": "2502.00027v1",
      "title": "Analysis of a Memcapacitor-Based for Neural Network Accelerator Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Ankur Singh",
        "Dowon Kim",
        "Byung-Geun Lee"
      ],
      "abstract": "Data-intensive computing tasks, such as training neural networks, are crucial\nfor artificial intelligence applications but often come with high energy\ndemands. One promising solution is to develop specialized hardware that\ndirectly maps neural networks, utilizing arrays of memristive devices to\nperform parallel multiply-accumulate operations. In our research, we introduce\na novel CMOS-based memcapacitor circuit that is validated using the cadence\ntool. Additionally, we developed the device in Python to facilitate the design\nof a memcapacitive-based accelerator. Our proposed framework employs a crossbar\narray of memcapacitor devices to train a neural network capable of digit\nclassification and CIFAR dataset recognition. We tested the non-ideal\ncharacteristics of the constructed memcapacitor-based neural network. The\nsystem achieved an impressive 98.4% training accuracy in digit recognition and\n94.4% training accuracy in CIFAR recognition, highlighting its effectiveness.\nThis study demonstrates the potential of memcapacitor-based neural network\nsystems in handling classification tasks and sets the stage for further\nadvancements in neuromorphic computing.",
      "tldr_zh": "本文分析了一种基于 memcapacitor 的神经网络加速器框架，以解决数据密集型计算任务（如神经网络训练）的高能耗问题。研究团队开发了 CMOS-based memcapacitor 电路，使用 Cadence 工具验证，并在 Python 中构建了 memcapacitor 设备的 crossbar array，用于训练神经网络进行数字分类和 CIFAR dataset 识别。实验结果显示，该系统在数字识别任务中达到 98.4% 的训练准确率，在 CIFAR 识别中达到 94.4%，突显了其在分类任务中的有效性。该研究为 neuromorphic computing 的发展提供了新基础。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.AR",
      "comment": "11 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.00027v1",
      "published_date": "2025-01-21 18:02:30 UTC",
      "updated_date": "2025-01-21 18:02:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:36:36.222017"
    },
    {
      "arxiv_id": "2501.12326v1",
      "title": "UI-TARS: Pioneering Automated GUI Interaction with Native Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Yujia Qin",
        "Yining Ye",
        "Junjie Fang",
        "Haoming Wang",
        "Shihao Liang",
        "Shizuo Tian",
        "Junda Zhang",
        "Jiahao Li",
        "Yunxin Li",
        "Shijue Huang",
        "Wanjun Zhong",
        "Kuanye Li",
        "Jiale Yang",
        "Yu Miao",
        "Woyu Lin",
        "Longxiang Liu",
        "Xu Jiang",
        "Qianli Ma",
        "Jingyu Li",
        "Xiaojun Xiao",
        "Kai Cai",
        "Chuang Li",
        "Yaowei Zheng",
        "Chaolin Jin",
        "Chen Li",
        "Xiao Zhou",
        "Minchao Wang",
        "Haoli Chen",
        "Zhaojian Li",
        "Haihua Yang",
        "Haifeng Liu",
        "Feng Lin",
        "Tao Peng",
        "Xin Liu",
        "Guang Shi"
      ],
      "abstract": "This paper introduces UI-TARS, a native GUI agent model that solely perceives\nthe screenshots as input and performs human-like interactions (e.g., keyboard\nand mouse operations). Unlike prevailing agent frameworks that depend on\nheavily wrapped commercial models (e.g., GPT-4o) with expert-crafted prompts\nand workflows, UI-TARS is an end-to-end model that outperforms these\nsophisticated frameworks. Experiments demonstrate its superior performance:\nUI-TARS achieves SOTA performance in 10+ GUI agent benchmarks evaluating\nperception, grounding, and GUI task execution. Notably, in the OSWorld\nbenchmark, UI-TARS achieves scores of 24.6 with 50 steps and 22.7 with 15\nsteps, outperforming Claude (22.0 and 14.9 respectively). In AndroidWorld,\nUI-TARS achieves 46.6, surpassing GPT-4o (34.5). UI-TARS incorporates several\nkey innovations: (1) Enhanced Perception: leveraging a large-scale dataset of\nGUI screenshots for context-aware understanding of UI elements and precise\ncaptioning; (2) Unified Action Modeling, which standardizes actions into a\nunified space across platforms and achieves precise grounding and interaction\nthrough large-scale action traces; (3) System-2 Reasoning, which incorporates\ndeliberate reasoning into multi-step decision making, involving multiple\nreasoning patterns such as task decomposition, reflection thinking, milestone\nrecognition, etc. (4) Iterative Training with Reflective Online Traces, which\naddresses the data bottleneck by automatically collecting, filtering, and\nreflectively refining new interaction traces on hundreds of virtual machines.\nThrough iterative training and reflection tuning, UI-TARS continuously learns\nfrom its mistakes and adapts to unforeseen situations with minimal human\nintervention. We also analyze the evolution path of GUI agents to guide the\nfurther development of this domain.",
      "tldr_zh": "本论文引入了 UI-TARS，一种原生 GUI 代理模型，仅通过屏幕截图作为输入，实现类似人类的交互（如键盘和鼠标操作），并作为端到端系统超越依赖商业模型（如 GPT-4o）和专家提示的现有框架。UI-TARS 在 10+ GUI 代理基准测试中达到 SOTA 性能，例如在 OSWorld 基准中得分 24.6（50 步）和 22.7（15 步），优于 Claude，在 AndroidWorld 中得分 46.6，超过 GPT-4o（34.5）。关键创新包括：Enhanced Perception，利用大规模 GUI 截图数据集提升 UI 元素理解；Unified Action Modeling，将动作标准化以实现跨平台精确交互；System-2 Reasoning，融入任务分解和反思思考等多模式推理；以及 Iterative Training with Reflective Online Traces，通过自动收集和反思改进交互数据，在数百台虚拟机上持续学习和适应。通过这些进展，论文还分析了 GUI 代理的演化路径，为领域发展提供指导。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12326v1",
      "published_date": "2025-01-21 17:48:10 UTC",
      "updated_date": "2025-01-21 17:48:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:36:48.332726"
    },
    {
      "arxiv_id": "2501.12300v1",
      "title": "LLM-Assisted Knowledge Graph Completion for Curriculum and Domain Modelling in Personalized Higher Education Recommendations",
      "title_zh": "翻译失败",
      "authors": [
        "Hasan Abu-Rasheed",
        "Constance Jumbo",
        "Rashed Al Amin",
        "Christian Weber",
        "Veit Wiese",
        "Roman Obermaisser",
        "Madjid Fathi"
      ],
      "abstract": "While learning personalization offers great potential for learners, modern\npractices in higher education require a deeper consideration of domain models\nand learning contexts, to develop effective personalization algorithms. This\npaper introduces an innovative approach to higher education curriculum\nmodelling that utilizes large language models (LLMs) for knowledge graph (KG)\ncompletion, with the goal of creating personalized learning-path\nrecommendations. Our research focuses on modelling university subjects and\nlinking their topics to corresponding domain models, enabling the integration\nof learning modules from different faculties and institutions in the student's\nlearning path. Central to our approach is a collaborative process, where LLMs\nassist human experts in extracting high-quality, fine-grained topics from\nlecture materials. We develop a domain, curriculum, and user models for\nuniversity modules and stakeholders. We implement this model to create the KG\nfrom two study modules: Embedded Systems and Development of Embedded Systems\nUsing FPGA. The resulting KG structures the curriculum and links it to the\ndomain models. We evaluate our approach through qualitative expert feedback and\nquantitative graph quality metrics. Domain experts validated the relevance and\naccuracy of the model, while the graph quality metrics measured the structural\nproperties of our KG. Our results show that the LLM-assisted graph completion\napproach enhances the ability to connect related courses across disciplines to\npersonalize the learning experience. Expert feedback also showed high\nacceptance of the proposed collaborative approach for concept extraction and\nclassification.",
      "tldr_zh": "本研究提出了一种利用大型语言模型（LLMs）辅助知识图谱（KG）完成的方法，用于高等教育课程和领域建模，从而实现个性化学习路径推荐。该方法通过LLMs与人类专家协作，从讲座材料中提取高质量细粒度主题，构建了涵盖大学模块的领域、课程和用户模型，并应用于“Embedded Systems”和“Development of Embedded Systems Using FPGA”两个模块。实验结果显示，此方法增强了跨学科课程的连接，提高了学习个性化效果；专家反馈确认了模型的准确性和相关性，并高度认可这种协作提取概念的流程。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted in the IEEE Global Engineering Education Conference\n  (EDUCON2025), London, UK, 22-25 April, 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.12300v1",
      "published_date": "2025-01-21 17:13:13 UTC",
      "updated_date": "2025-01-21 17:13:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:36:58.906946"
    },
    {
      "arxiv_id": "2502.00026v2",
      "title": "Pushing the Limits of BFP on Narrow Precision LLM Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Hui Wang",
        "Yuan Cheng",
        "Xiaomeng Han",
        "Zhengpeng Zhao",
        "Dawei Yang",
        "Zhe Jiang"
      ],
      "abstract": "The substantial computational and memory demands of Large Language Models\n(LLMs) hinder their deployment. Block Floating Point (BFP) has proven effective\nin accelerating linear operations, a cornerstone of LLM workloads. However, as\nsequence lengths grow, nonlinear operations, such as Attention, increasingly\nbecome performance bottlenecks due to their quadratic computational complexity.\nThese nonlinear operations are predominantly executed using inefficient\nfloating-point formats, which renders the system challenging to optimize\nsoftware efficiency and hardware overhead. In this paper, we delve into the\nlimitations and potential of applying BFP to nonlinear operations. Given our\nfindings, we introduce a hardware-software co-design framework (DB-Attn),\nincluding: (i) DBFP, an advanced BFP version, overcomes nonlinear operation\nchallenges with a pivot-focus strategy for diverse data and an adaptive\ngrouping strategy for flexible exponent sharing. (ii) DH-LUT, a novel lookup\ntable algorithm dedicated to accelerating nonlinear operations with DBFP\nformat. (iii) An RTL-level DBFP-based engine is implemented to support DB-Attn,\napplicable to FPGA and ASIC. Results show that DB-Attn provides significant\nperformance improvements with negligible accuracy loss, achieving 74% GPU\nspeedup on Softmax of LLaMA and 10x low overhead performance improvement over\nSOTA designs.",
      "tldr_zh": "这篇论文探讨了Large Language Models (LLMs) 在推理过程中因计算和内存需求而面临的部署挑战，特别是非线性操作（如Attention）成为性能瓶颈的问题。作者提出了一种硬件-软件协同设计框架DB-Attn，包括DBFP（BFP的升级版，利用pivot-focus策略和adaptive grouping策略处理非线性操作）、DH-LUT（一个专用于加速非线性操作的查找表算法），以及RTL-level DBFP-based engine（适用于FPGA和ASIC的硬件实现）。实验结果显示，DB-Attn在几乎不损失准确性的前提下，实现了显著性能提升，例如在LLaMA的Softmax操作上比GPU加速74%，并比现有最先进设计提高10倍的性能。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00026v2",
      "published_date": "2025-01-21 17:10:52 UTC",
      "updated_date": "2025-02-07 12:23:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:37:11.265000"
    },
    {
      "arxiv_id": "2501.12296v2",
      "title": "RALAD: Bridging the Real-to-Sim Domain Gap in Autonomous Driving with Retrieval-Augmented Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jiacheng Zuo",
        "Haibo Hu",
        "Zikang Zhou",
        "Yufei Cui",
        "Ziquan Liu",
        "Jianping Wang",
        "Nan Guan",
        "Jin Wang",
        "Chun Jason Xue"
      ],
      "abstract": "In the pursuit of robust autonomous driving systems, models trained on\nreal-world datasets often struggle to adapt to new environments, particularly\nwhen confronted with corner cases such as extreme weather conditions.\nCollecting these corner cases in the real world is non-trivial, which\nnecessitates the use of simulators for validation. However,the high\ncomputational cost and the domain gap in data distribution have hindered the\nseamless transition between real and simulated driving scenarios. To tackle\nthis challenge, we propose Retrieval-Augmented Learning for Autonomous Driving\n(RALAD), a novel framework designed to bridge the real-to-sim gap at a low\ncost. RALAD features three primary designs, including (1) domain adaptation via\nan enhanced Optimal Transport (OT) method that accounts for both individual and\ngrouped image distances, (2) a simple and unified framework that can be applied\nto various models, and (3) efficient fine-tuning techniques that freeze the\ncomputationally expensive layers while maintaining robustness. Experimental\nresults demonstrate that RALAD compensates for the performance degradation in\nsimulated environments while maintaining accuracy in real-world scenarios\nacross three different models. Taking Cross View as an example, the mIOU and\nmAP metrics in real-world scenarios remain stable before and after RALAD\nfine-tuning, while in simulated environments,the mIOU and mAP metrics are\nimproved by 10.30% and 12.29%, respectively. Moreover, the re-training cost of\nour approach is reduced by approximately 88.1%. Our code is available at\nhttps://github.com/JiachengZuo/RALAD.git.",
      "tldr_zh": "这篇论文提出了 RALAD 框架，利用 Retrieval-Augmented Learning 来桥接自动驾驶领域的真实到模拟域差距，旨在低成本地帮助模型适应极端天气等角落案例。RALAD 的核心设计包括通过增强的 Optimal Transport (OT) 方法处理个体和分组图像距离、提供一个适用于多种模型的统一框架，以及高效微调技术来冻结计算密集层以保持鲁棒性。实验结果显示，在模拟环境中，RALAD 使 Cross View 模型的 mIOU 和 mAP 指标分别提高了 10.30% 和 12.29%，同时维持真实场景的性能稳定，并将重训练成本降低了约 88.1%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12296v2",
      "published_date": "2025-01-21 17:03:06 UTC",
      "updated_date": "2025-03-03 06:45:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:37:23.833694"
    },
    {
      "arxiv_id": "2501.12289v1",
      "title": "Regressor-Guided Image Editing Regulates Emotional Response to Reduce Online Engagement",
      "title_zh": "回归器引导的图像编辑调节情感反应以减少在线互动",
      "authors": [
        "Christoph Gebhardt",
        "Robin Willardt",
        "Seyedmorteza Sadat",
        "Chih-Wei Ning",
        "Andreas Brombach",
        "Jie Song",
        "Otmar Hilliges",
        "Christian Holz"
      ],
      "abstract": "Emotions are known to mediate the relationship between users' content\nconsumption and their online engagement, with heightened emotional intensity\nleading to increased engagement. Building on this insight, we propose three\nregressor-guided image editing approaches aimed at diminishing the emotional\nimpact of images. These include (i) a parameter optimization approach based on\nglobal image transformations known to influence emotions, (ii) an optimization\napproach targeting the style latent space of a generative adversarial network,\nand (iii) a diffusion-based approach employing classifier guidance and\nclassifier-free guidance. Our findings demonstrate that approaches can\neffectively alter the emotional properties of images while maintaining high\nvisual quality. Optimization-based methods primarily adjust low-level\nproperties like color hues and brightness, whereas the diffusion-based approach\nintroduces semantic changes, such as altering appearance or facial expressions.\nNotably, results from a behavioral study reveal that only the diffusion-based\napproach successfully elicits changes in viewers' emotional responses while\npreserving high perceived image quality. In future work, we will investigate\nthe impact of these image adaptations on internet user behavior.",
      "tldr_zh": "本文提出三种 regressor-guided image editing 方法，旨在通过降低图像的情绪影响来减少用户的在线互动。这些方法包括基于全局图像变换的参数优化、针对 generative adversarial network (GAN) 风格潜在空间的优化，以及采用 classifier guidance 和 classifier-free guidance 的 diffusion-based approach。研究结果显示，优化方法主要调整图像的低级属性如颜色和亮度，而 diffusion-based approach 能引入语义变化（如改变外观或面部表情），并在行为研究中成功改变观众的情绪响应，同时保持高视觉质量。未来工作将探讨这些图像适应对互联网用户行为的影响。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CV",
      "comment": "39 pages, 22 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.12289v1",
      "published_date": "2025-01-21 16:59:13 UTC",
      "updated_date": "2025-01-21 16:59:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:37:35.618278"
    },
    {
      "arxiv_id": "2501.12285v1",
      "title": "Implementation of an Asymmetric Adjusted Activation Function for Class Imbalance Credit Scoring",
      "title_zh": "不对称调整激活函数在类别不平衡信用评分中的实现",
      "authors": [
        "Xia Li",
        "Hanghang Zheng",
        "Kunpeng Tao",
        "Mao Mao"
      ],
      "abstract": "Credit scoring is a systematic approach to evaluate a borrower's probability\nof default (PD) on a bank loan. The data associated with such scenarios are\ncharacteristically imbalanced, complicating binary classification owing to the\noften-underestimated cost of misclassification during the classifier's learning\nprocess. Considering the high imbalance ratio (IR) of these datasets, we\nintroduce an innovative yet straightforward optimized activation function by\nincorporating an IR-dependent asymmetric adjusted factor embedded Sigmoid\nactivation function (ASIG). The embedding of ASIG makes the sensitive margin of\nthe Sigmoid function auto-adjustable, depending on the imbalance nature of the\ndatasets distributed, thereby giving the activation function an asymmetric\ncharacteristic that prevents the underrepresentation of the minority class\n(positive samples) during the classifier's learning process. The experimental\nresults show that the ASIG-embedded-classifier outperforms traditional\nclassifiers on datasets across wide-ranging IRs in the downstream\ncredit-scoring task. The algorithm also shows robustness and stability, even\nwhen the IR is ultra-high. Therefore, the algorithm provides a competitive\nalternative in the financial industry, especially in credit scoring, possessing\nthe ability to effectively process highly imbalanced distribution data.",
      "tldr_zh": "该论文针对信用评分数据的不平衡问题，提出了一种创新的激活函数ASIG，即基于不平衡比率(IR)的非对称调整Sigmoid激活函数。ASIG通过自动调整Sigmoid函数的敏感边界，根据数据集的不平衡特性，防止少数类(正样本)被低估，从而提升分类器的学习性能。实验结果表明，ASIG嵌入的分类器在各种IR下的信用评分任务中优于传统方法，并在超高IR场景下表现出色鲁棒性和稳定性，为金融行业处理高不平衡数据提供了一个高效的备选方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-fin.RM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12285v1",
      "published_date": "2025-01-21 16:54:39 UTC",
      "updated_date": "2025-01-21 16:54:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:37:47.634195"
    },
    {
      "arxiv_id": "2501.12432v1",
      "title": "Divide-Then-Aggregate: An Efficient Tool Learning Method via Parallel Tool Invocation",
      "title_zh": "Divide-Then-Aggregate：一种高效的工具学习方法通过并行工具调用",
      "authors": [
        "Dongsheng Zhu",
        "Weixian Shi",
        "Zhengliang Shi",
        "Zhaochun Ren",
        "Shuaiqiang Wang",
        "Lingyong Yan",
        "Dawei Yin"
      ],
      "abstract": "Although current Large Language Models (LLMs) exhibit impressive\ncapabilities, performing complex real-world tasks still requires tool learning.\nMainstream methods, such as CoT/ReAct, rely on step-by-step tool invocation to\ninteract with external environments, but they are limited in perceptual scope\nand lack adequate task-planning capability. To address these limitations, other\nstudies introduce the first Search-based Decision Tree (DFSDT), which still\nsuffers from the high computational cost. In this paper, we introduce a novel\nparallel tool invocation paradigm, DTA-Llama (Divide-Then-Aggregate Llama).\nFirst, we transform traditional tree-based tool search paths into Directed\nAcyclic Graph (DAG) structure, generating a high-quality parallel tool\ninvocation dataset. The DTA-Llama is then trained on the dataset to learn to\niteratively divide the current task into several parallel tool invocation\nsub-tasks and aggregate the invocation results to decide the next actions.\nFurthermore, we introduce an efficient inference framework inspired by the\nProcess/Threads mechanism when applying the DTA-Llama to practical tasks.\nExperimental results show that our approach substantially enhances task\nperformance while reducing token consumption and inference time. Llama2-7B,\nusing our method, is comparable to the official parallel function calling\nmethod of GPT-3.5. The relevant code, dataset, and model weights are available\nat https://corn0205.github.io/",
      "tldr_zh": "本研究针对大型语言模型(LLMs)进行工具学习时存在的感知范围和任务规划限制，提出了一种高效的并行工具调用方法DTA-Llama（Divide-Then-Aggregate Llama）。该方法将传统的树状工具搜索路径转化为有向无环图(DAG)结构，生成高质量数据集，并训练模型学会将任务分解为多个并行工具调用子任务，然后聚合结果以决定下一步行动，同时引入受Process/Threads启发的推理框架来优化实际应用。实验结果显示，DTA-Llama显著提升任务性能，减少令牌消耗和推理时间，其中Llama2-7B模型的表现可与GPT-3.5的官方并行函数调用方法相媲美。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12432v1",
      "published_date": "2025-01-21 16:49:08 UTC",
      "updated_date": "2025-01-21 16:49:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:37:59.790957"
    },
    {
      "arxiv_id": "2501.12431v2",
      "title": "Modality Interactive Mixture-of-Experts for Fake News Detection",
      "title_zh": "模态交互混合专家用于假新闻检测",
      "authors": [
        "Yifan Liu",
        "Yaokun Liu",
        "Zelin Li",
        "Ruichen Yao",
        "Yang Zhang",
        "Dong Wang"
      ],
      "abstract": "The proliferation of fake news on social media platforms disproportionately\nimpacts vulnerable populations, eroding trust, exacerbating inequality, and\namplifying harmful narratives. Detecting fake news in multimodal contexts --\nwhere deceptive content combines text and images -- is particularly challenging\ndue to the nuanced interplay between modalities. Existing multimodal fake news\ndetection methods often emphasize cross-modal consistency but ignore the\ncomplex interactions between text and visual elements, which may complement,\ncontradict, or independently influence the predicted veracity of a post. To\naddress these challenges, we present Modality Interactive Mixture-of-Experts\nfor Fake News Detection (MIMoE-FND), a novel hierarchical Mixture-of-Experts\nframework designed to enhance multimodal fake news detection by explicitly\nmodeling modality interactions through an interaction gating mechanism. Our\napproach models modality interactions by evaluating two key aspects of modality\ninteractions: unimodal prediction agreement and semantic alignment. The\nhierarchical structure of MIMoE-FND allows for distinct learning pathways\ntailored to different fusion scenarios, adapting to the unique characteristics\nof each modality interaction. By tailoring fusion strategies to diverse\nmodality interaction scenarios, MIMoE-FND provides a more robust and nuanced\napproach to multimodal fake news detection. We evaluate our approach on three\nreal-world benchmarks spanning two languages, demonstrating its superior\nperformance compared to state-of-the-art methods. By enhancing the accuracy and\ninterpretability of fake news detection, MIMoE-FND offers a promising tool to\nmitigate the spread of misinformation, with the potential to better safeguard\nvulnerable communities against its harmful effects.",
      "tldr_zh": "该研究针对多模态假新闻检测的挑战，提出了一种新型框架Modality Interactive Mixture-of-Experts for Fake News Detection (MIMoE-FND)，通过交互门控机制显式建模文本和视觉元素的互动，包括单模态预测一致性和语义对齐，以处理模态间的互补、矛盾或独立影响。MIMoE-FND采用分层Mixture-of-Experts结构，提供针对不同融合场景的定制学习路径，提升检测的鲁棒性和细致性。在三个真实世界基准数据集上，该方法在两种语言环境中表现出色，比最先进方法性能更优，并提高了假新闻检测的准确性和可解释性，从而有助于减少错误信息对弱势群体的负面影响。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "I.2.4"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by the Proceedings of the ACM Web Conference 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.12431v2",
      "published_date": "2025-01-21 16:49:00 UTC",
      "updated_date": "2025-02-26 17:20:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:38:11.693798"
    },
    {
      "arxiv_id": "2501.12275v1",
      "title": "With Great Backbones Comes Great Adversarial Transferability",
      "title_zh": "强大的骨干网络带来强大的对抗转移性",
      "authors": [
        "Erik Arakelyan",
        "Karen Hambardzumyan",
        "Davit Papikyan",
        "Pasquale Minervini",
        "Albert Gordo",
        "Isabelle Augenstein",
        "Aram H. Markosyan"
      ],
      "abstract": "Advances in self-supervised learning (SSL) for machine vision have improved\nrepresentation robustness and model performance, giving rise to pre-trained\nbackbones like \\emph{ResNet} and \\emph{ViT} models tuned with SSL methods such\nas \\emph{SimCLR}. Due to the computational and data demands of pre-training,\nthe utilization of such backbones becomes a strenuous necessity. However,\nemploying these backbones may inherit vulnerabilities to adversarial attacks.\nWhile adversarial robustness has been studied under \\emph{white-box} and\n\\emph{black-box} settings, the robustness of models tuned on pre-trained\nbackbones remains largely unexplored. Additionally, the role of tuning\nmeta-information in mitigating exploitation risks is unclear. This work\nsystematically evaluates the adversarial robustness of such models across\n$20,000$ combinations of tuning meta-information, including fine-tuning\ntechniques, backbone families, datasets, and attack types. We propose using\nproxy models to transfer attacks, simulating varying levels of target knowledge\nby fine-tuning these proxies with diverse configurations. Our findings reveal\nthat proxy-based attacks approach the effectiveness of \\emph{white-box}\nmethods, even with minimal tuning knowledge. We also introduce a naive\n\"backbone attack,\" leveraging only the backbone to generate adversarial\nsamples, which outperforms \\emph{black-box} attacks and rivals \\emph{white-box}\nmethods, highlighting critical risks in model-sharing practices. Finally, our\nablations reveal how increasing tuning meta-information impacts attack\ntransferability, measuring each meta-information combination.",
      "tldr_zh": "这篇论文探讨了自监督学习(SSL)调优的预训练骨干网络（如ResNet和ViT）在对抗攻击下的鲁棒性问题，强调这些网络虽然提升了模型性能，但可能继承攻击漏洞。研究者系统评估了20,000种调优元信息组合，包括细调技术、骨干家族、数据集和攻击类型，并提出使用代理模型转移攻击和“backbone attack”方法，仅靠骨干网络生成对抗样本。结果显示，代理攻击的效果接近white-box方法，而backbone attack优于black-box攻击，甚至可媲美white-box水平，揭示了模型共享实践中的潜在风险。最后，通过消融实验，论文量化了增加调优元信息对攻击转移性的影响。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12275v1",
      "published_date": "2025-01-21 16:44:51 UTC",
      "updated_date": "2025-01-21 16:44:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:38:24.552885"
    },
    {
      "arxiv_id": "2501.12273v1",
      "title": "Condor: Enhance LLM Alignment with Knowledge-Driven Data Synthesis and Refinement",
      "title_zh": "Condor：通过知识驱动的数据合成和精炼增强 LLM 对齐",
      "authors": [
        "Maosong Cao",
        "Taolin Zhang",
        "Mo Li",
        "Chuyu Zhang",
        "Yunxin Liu",
        "Haodong Duan",
        "Songyang Zhang",
        "Kai Chen"
      ],
      "abstract": "The quality of Supervised Fine-Tuning (SFT) data plays a critical role in\nenhancing the conversational capabilities of Large Language Models (LLMs).\nHowever, as LLMs become more advanced, the availability of high-quality\nhuman-annotated SFT data has become a significant bottleneck, necessitating a\ngreater reliance on synthetic training data. In this work, we introduce Condor,\na novel two-stage synthetic data generation framework that incorporates World\nKnowledge Tree and Self-Reflection Refinement to produce high-quality SFT data\nat scale. Our experimental results demonstrate that a base model fine-tuned on\nonly 20K Condor-generated samples achieves superior performance compared to\ncounterparts. The additional refinement stage in Condor further enables\niterative self-improvement for LLMs at various scales (up to 72B), validating\nthe effectiveness of our approach. Furthermore, our investigation into the\nscaling for synthetic data in post-training reveals substantial unexplored\npotential for performance improvements, opening promising avenues for future\nresearch.",
      "tldr_zh": "该研究提出Condor框架，通过Knowledge-Driven数据合成和Refinement来提升Large Language Models (LLMs)的对齐性能，以解决Supervised Fine-Tuning (SFT)数据短缺问题。Condor采用两阶段方法：首先利用World Knowledge Tree生成大规模高质量合成数据，其次通过Self-Reflection Refinement进行优化，实现模型的迭代自提升。实验结果显示，仅用20K Condor生成的样本微调的基模型即超越对照组性能，并在多规模LLMs（至72B）上表现出色。该框架还揭示了合成数据扩展在后训练中的巨大潜力，为未来LLM优化研究开辟新路径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Tech Report. Github: https://github.com/InternLM/Condor",
      "pdf_url": "http://arxiv.org/pdf/2501.12273v1",
      "published_date": "2025-01-21 16:44:12 UTC",
      "updated_date": "2025-01-21 16:44:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:38:36.158789"
    },
    {
      "arxiv_id": "2501.12266v1",
      "title": "CBVLM: Training-free Explainable Concept-based Large Vision Language Models for Medical Image Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Cristiano Patrício",
        "Isabel Rio-Torto",
        "Jaime S. Cardoso",
        "Luís F. Teixeira",
        "João C. Neves"
      ],
      "abstract": "The main challenges limiting the adoption of deep learning-based solutions in\nmedical workflows are the availability of annotated data and the lack of\ninterpretability of such systems. Concept Bottleneck Models (CBMs) tackle the\nlatter by constraining the final disease prediction on a set of predefined and\nhuman-interpretable concepts. However, the increased interpretability achieved\nthrough these concept-based explanations implies a higher annotation burden.\nMoreover, if a new concept needs to be added, the whole system needs to be\nretrained. Inspired by the remarkable performance shown by Large\nVision-Language Models (LVLMs) in few-shot settings, we propose a simple, yet\neffective, methodology, CBVLM, which tackles both of the aforementioned\nchallenges. First, for each concept, we prompt the LVLM to answer if the\nconcept is present in the input image. Then, we ask the LVLM to classify the\nimage based on the previous concept predictions. Moreover, in both stages, we\nincorporate a retrieval module responsible for selecting the best examples for\nin-context learning. By grounding the final diagnosis on the predicted\nconcepts, we ensure explainability, and by leveraging the few-shot capabilities\nof LVLMs, we drastically lower the annotation cost. We validate our approach\nwith extensive experiments across four medical datasets and twelve LVLMs (both\ngeneric and medical) and show that CBVLM consistently outperforms CBMs and\ntask-specific supervised methods without requiring any training and using just\na few annotated examples. More information on our project page:\nhttps://cristianopatricio.github.io/CBVLM/.",
      "tldr_zh": "该研究提出 CBVLM，一种无需训练的可解释概念-based 大型视觉语言模型 (LVLMs)，旨在解决医疗图像分类中数据标注负担和模型可解释性不足的挑战。通过提示 LVLM 判断图像中预定义概念的存在，并基于这些概念预测进行分类，同时整合检索模块进行 in-context learning，CBVLM 显著降低了标注成本。实验在四个医疗数据集和十二个 LVLM 上验证，CBVLM  outperform CBMs 和任务特定监督方法，仅需少量标注示例即可实现优异性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "This work has been submitted to the IEEE for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2501.12266v1",
      "published_date": "2025-01-21 16:38:04 UTC",
      "updated_date": "2025-01-21 16:38:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:38:48.118741"
    },
    {
      "arxiv_id": "2501.12231v1",
      "title": "InsTALL: Context-aware Instructional Task Assistance with Multi-modal Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Pha Nguyen",
        "Sailik Sengupta",
        "Girik Malik",
        "Arshit Gupta",
        "Bonan Min"
      ],
      "abstract": "The improved competence of generative models can help building multi-modal\nvirtual assistants that leverage modalities beyond language. By observing\nhumans performing multi-step tasks, one can build assistants that have\nsituational awareness of actions and tasks being performed, enabling them to\ncater assistance based on this understanding. In this paper, we develop a\nContext-aware Instructional Task Assistant with Multi-modal Large Language\nModels (InsTALL) that leverages an online visual stream (e.g. a user's screen\nshare or video recording) and responds in real-time to user queries related to\nthe task at hand. To enable useful assistance, InsTALL 1) trains a multi-modal\nmodel on task videos and paired textual data, and 2) automatically extracts\ntask graph from video data and leverages it at training and inference time. We\nshow InsTALL achieves state-of-the-art performance across proposed sub-tasks\nconsidered for multimodal activity understanding -- task recognition (TR),\naction recognition (AR), next action prediction (AP), and plan prediction (PP)\n-- and outperforms existing baselines on two novel sub-tasks related to\nautomatic error identification.",
      "tldr_zh": "本研究开发了InsTALL，一种基于多模态大语言模型的上下文感知指令任务助手，能够通过观察人类执行多步任务的在线视觉流（如屏幕共享或视频），实现实时响应和个性化协助。InsTALL的方法包括在任务视频和配对文本数据上训练多模态模型，以及自动从视频中提取任务图，并在训练和推理过程中加以利用。实验结果表明，InsTALL在任务识别(TR)、动作识别(AR)、下一个动作预测(AP)和计划预测(PP)等子任务上达到了state-of-the-art性能，并在两个新的自动错误识别子任务上超过了现有基线，为构建智能多模态虚拟助手提供了重要进展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12231v1",
      "published_date": "2025-01-21 15:55:06 UTC",
      "updated_date": "2025-01-21 15:55:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:39:01.165586"
    },
    {
      "arxiv_id": "2501.12430v1",
      "title": "SCFCRC: Simultaneously Counteract Feature Camouflage and Relation Camouflage for Fraud Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaocheng Zhang",
        "Zhuangzhuang Ye",
        "GuoPing Zhao",
        "Jianing Wang",
        "Xiaohong Su"
      ],
      "abstract": "In fraud detection, fraudsters often interact with many benign users,\ncamouflaging their features or relations to hide themselves. Most existing work\nconcentrates solely on either feature camouflage or relation camouflage, or\ndecoupling feature learning and relation learning to avoid the two camouflage\nfrom affecting each other. However, this inadvertently neglects the valuable\ninformation derived from features or relations, which could mutually enhance\ntheir adversarial camouflage strategies. In response to this gap, we propose\nSCFCRC, a Transformer-based fraud detector that Simultaneously Counteract\nFeature Camouflage and Relation Camouflage. SCFCRC consists of two components:\nFeature Camouflage Filter and Relation Camouflage Refiner. The feature\ncamouflage filter utilizes pseudo labels generated through label propagation to\ntrain the filter and uses contrastive learning that combines instance-wise and\nprototype-wise to improve the quality of features. The relation camouflage\nrefiner uses Mixture-of-Experts(MoE) network to disassemble the multi-relations\ngraph into multiple substructures and divide and conquer them to mitigate the\ndegradation of detection performance caused by relation camouflage.\nFurthermore, we introduce a regularization method for MoE to enhance the\nrobustness of the model. Extensive experiments on two fraud detection benchmark\ndatasets demonstrate that our method outperforms state-of-the-art baselines.",
      "tldr_zh": "该研究提出 SCFCRC，一种基于 Transformer 的欺诈检测方法，能够同时对抗特征伪装和关系伪装，从而解决现有方法忽略两者互补信息的局限性。SCFCRC 包括两个核心组件：Feature Camouflage Filter，通过标签传播生成伪标签并结合实例级和原型级的对比学习来提升特征质量；以及 Relation Camouflage Refiner，使用 Mixture-of-Experts (MoE) 网络将多关系图分解成子结构进行分治处理，并引入 MoE 正则化以增强模型鲁棒性。实验结果显示，在两个欺诈检测基准数据集上，SCFCRC 优于最先进基线方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12430v1",
      "published_date": "2025-01-21 15:50:51 UTC",
      "updated_date": "2025-01-21 15:50:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:39:12.255855"
    },
    {
      "arxiv_id": "2501.12222v2",
      "title": "High-temperature superconductivity in Li$_2$AuH$_6$ mediated by strong electron-phonon coupling under ambient pressure",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenfeng Ouyang",
        "Bo-Wen Yao",
        "Xiao-Qi Han",
        "Peng-Jie Guo",
        "Ze-Feng Gao",
        "Zhong-Yi Lu"
      ],
      "abstract": "We used our developed AI search engine~(InvDesFlow) to perform extensive\ninvestigations regarding ambient stable superconducting hydrides. A cubic\nstructure Li$_2$AuH$_6$ with Au-H octahedral motifs is identified to be a\ncandidate. After performing thermodynamical analysis, we provide a feasible\nroute to experimentally synthesize this material via the known LiAu and LiH\ncompounds under ambient pressure. The further first-principles calculations\nsuggest that Li$_2$AuH$_6$ shows a high superconducting transition temperature\n($T_c$) $\\sim$ 140 K under ambient pressure. The H-1$s$ electrons strongly\ncouple with phonon modes of vibrations of Au-H octahedrons as well as\nvibrations of Li atoms, where the latter is not taken seriously in other\npreviously similar cases. Hence, different from previous claims of searching\nmetallic covalent bonds to find high-$T_c$ superconductors, we emphasize here\nthe importance of those phonon modes with strong electron-phonon coupling\n(EPC). And we suggest that one can intercalate atoms into binary or ternary\nhydrides to introduce more potential phonon modes with strong EPC, which is an\neffective approach to find high-$T_c$ superconductors within multicomponent\ncompounds.",
      "tldr_zh": "本研究使用AI搜索引擎InvDesFlow识别出立方结构Li$_2$AuH$_6$作为环境稳定超导氢化物的候选材料，并通过热力学分析提出从LiAu和LiH化合物在环境压力下合成该材料的途径。进一步的第一性原理计算显示，Li$_2$AuH$_6$在环境压力下具有高超导转变温度(T_c)约140 K，主要归因于H-1s电子与Au-H八面体振动以及Li原子振动的强电子-声子耦合(EPC)。该研究强调了强EPC声子模式的importance，而不是仅依赖金属共价键，并建议通过在二元或三元氢化物中插入原子来引入更多强EPC模式，从而有效发现多组分化合物中的高T_c超导体。",
      "categories": [
        "cond-mat.supr-con",
        "cond-mat.mtrl-sci",
        "cs.AI",
        "physics.comp-ph"
      ],
      "primary_category": "cond-mat.supr-con",
      "comment": "6 pages; 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.12222v2",
      "published_date": "2025-01-21 15:48:27 UTC",
      "updated_date": "2025-05-14 02:30:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:39:23.830114"
    },
    {
      "arxiv_id": "2502.00025v3",
      "title": "Leveraging Large Language Models to Enhance Machine Learning Interpretability and Predictive Performance: A Case Study on Emergency Department Returns for Mental Health Patients",
      "title_zh": "利用大型语言模型提升机器学习的解释性和预测性能：一项关于精神健康患者急诊科复诊的案例研究",
      "authors": [
        "Abdulaziz Ahmed",
        "Mohammad Saleem",
        "Mohammed Alzeen",
        "Badari Birur",
        "Rachel E Fargason",
        "Bradley G Burk",
        "Hannah Rose Harkins",
        "Ahmed Alhassan",
        "Mohammed Ali Al-Garadi"
      ],
      "abstract": "Importance: Emergency department (ED) returns for mental health conditions\npose a major healthcare burden, with 24-27% of patients returning within 30\ndays. Traditional machine learning models for predicting these returns often\nlack interpretability for clinical use.\n  Objective: To assess whether integrating large language models (LLMs) with\nmachine learning improves predictive accuracy and clinical interpretability of\nED mental health return risk models.\n  Methods: This retrospective cohort study analyzed 42,464 ED visits for 27,904\nunique mental health patients at an academic medical center in the Deep South\nfrom January 2018 to December 2022.\n  Main Outcomes and Measures: Two primary outcomes were evaluated: (1) 30-day\nED return prediction accuracy and (2) model interpretability using a novel\nLLM-enhanced framework integrating SHAP (SHapley Additive exPlanations) values\nwith clinical knowledge.\n  Results: For chief complaint classification, LLaMA 3 (8B) with 10-shot\nlearning outperformed traditional models (accuracy: 0.882, F1-score: 0.86). In\nSDoH classification, LLM-based models achieved 0.95 accuracy and 0.96 F1-score,\nwith Alcohol, Tobacco, and Substance Abuse performing best (F1: 0.96-0.89),\nwhile Exercise and Home Environment showed lower performance (F1: 0.70-0.67).\nThe LLM-based interpretability framework achieved 99% accuracy in translating\nmodel predictions into clinically relevant explanations. LLM-extracted features\nimproved XGBoost AUC from 0.74 to 0.76 and AUC-PR from 0.58 to 0.61.\n  Conclusions and Relevance: Integrating LLMs with machine learning models\nyielded modest but consistent accuracy gains while significantly enhancing\ninterpretability through automated, clinically relevant explanations. This\napproach provides a framework for translating predictive analytics into\nactionable clinical insights.",
      "tldr_zh": "这篇论文探讨了利用大型语言模型(LLMs)来提升机器学习模型在预测急诊科(ED)精神健康患者30天内返回时的预测准确性和临床可解释性问题。研究通过回顾性分析2018-2022年间42,464次ED就诊记录，结合LLMs与SHAP值框架，改进了特征提取和模型解释。结果显示，LLaMA 3在首席抱怨分类中达到0.882准确率和0.86 F1分数，LLMs提取的特征使XGBoost的AUC从0.74提升到0.76，并实现了99%的临床解释准确率。该方法为将预测分析转化为可行动的临床洞见提供了实用框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00025v3",
      "published_date": "2025-01-21 15:41:20 UTC",
      "updated_date": "2025-02-14 03:10:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:39:37.000428"
    },
    {
      "arxiv_id": "2501.14823v2",
      "title": "Quantifying Energy and Cost Benefits of Hybrid Edge Cloud: Analysis of Traditional and Agentic Workloads",
      "title_zh": "翻译失败",
      "authors": [
        "Siavash Alamouti"
      ],
      "abstract": "This paper examines the workload distribution challenges in centralized cloud\nsystems and demonstrates how Hybrid Edge Cloud (HEC) [1] mitigates these\ninefficiencies. Workloads in cloud environments often follow a Pareto\ndistribution, where a small percentage of tasks consume most resources, leading\nto bottlenecks and energy inefficiencies. By analyzing both traditional\nworkloads reflective of typical IoT and smart device usage and agentic\nworkloads, such as those generated by AI agents, robotics, and autonomous\nsystems, this study quantifies the energy and cost savings enabled by HEC. Our\nfindings reveal that HEC achieves energy savings of up to 75% and cost\nreductions exceeding 80%, even in resource-intensive agentic scenarios. These\nresults highlight the critical role of HEC in enabling scalable,\ncost-effective, and sustainable computing for the next generation of\nintelligent systems.",
      "tldr_zh": "这篇论文探讨了集中式云系统的负载分布挑战，如 Pareto distribution 导致的资源瓶颈和能源低效，并展示了 Hybrid Edge Cloud (HEC) 如何缓解这些问题。通过分析传统工作负载（如 IoT 和智能设备使用）和代理式工作负载（如 AI agents、机器人和自治系统），研究量化了 HEC 的能源和成本效益。结果表明，HEC 可实现高达 75% 的能源节约和超过 80% 的成本降低，即使在资源密集型场景中。总体而言，这强调了 HEC 在推动可扩展、成本有效和可持续计算方面的关键作用。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "13 pages, 2 Tables, 3 Figures",
      "pdf_url": "http://arxiv.org/pdf/2501.14823v2",
      "published_date": "2025-01-21 15:26:43 UTC",
      "updated_date": "2025-01-29 13:51:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:39:47.884648"
    },
    {
      "arxiv_id": "2501.14822v1",
      "title": "Controlling Ensemble Variance in Diffusion Models: An Application for Reanalyses Downscaling",
      "title_zh": "翻译失败",
      "authors": [
        "Fabio Merizzi",
        "Davide Evangelista",
        "Harilaos Loukos"
      ],
      "abstract": "In recent years, diffusion models have emerged as powerful tools for\ngenerating ensemble members in meteorology. In this work, we demonstrate that a\nDenoising Diffusion Implicit Model (DDIM) can effectively control ensemble\nvariance by varying the number of diffusion steps. Introducing a theoretical\nframework, we relate diffusion steps to the variance expressed by the reverse\ndiffusion process. Focusing on reanalysis downscaling, we propose an ensemble\ndiffusion model for the full ERA5-to-CERRA domain, generating\nvariance-calibrated ensemble members for wind speed at full spatial and\ntemporal resolution. Our method aligns global mean variance with a reference\nensemble dataset and ensures spatial variance is distributed in accordance with\nobserved meteorological variability. Additionally, we address the lack of\nensemble information in the CARRA dataset, showcasing the utility of our\napproach for efficient, high-resolution ensemble generation.",
      "tldr_zh": "本文研究了如何通过调整扩散步骤（diffusion steps）来控制扩散模型（diffusion models）中的集合方差（ensemble variance），并引入了一个理论框架将扩散步骤与反向扩散过程的方差相关联。作者提出了一种基于 Denoising Diffusion Implicit Model (DDIM) 的方法，应用于再分析下采样（reanalyses downscaling），为 ERA5-to-CERRA 域生成全空间和时间分辨率的校准风速集合成员，确保全局均方差与参考数据集对齐，并根据气象变异性分布空间方差。该方法还解决了 CARRA 数据集缺乏集合信息的不足，提升了高效高分辨率集合生成的实用性。",
      "categories": [
        "stat.AP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.AP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14822v1",
      "published_date": "2025-01-21 15:02:57 UTC",
      "updated_date": "2025-01-21 15:02:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:40:00.423737"
    },
    {
      "arxiv_id": "2501.12194v1",
      "title": "An End-to-End Approach for Korean Wakeword Systems with Speaker Authentication",
      "title_zh": "一种针对韩语唤醒词系统的端到端方法，包括说话者认证",
      "authors": [
        "Geonwoo Seo"
      ],
      "abstract": "Wakeword detection plays a critical role in enabling AI assistants to listen\nto user voices and interact effectively. However, for languages other than\nEnglish, there is a significant lack of pre-trained wakeword models.\nAdditionally, systems that merely determine the presence of a wakeword can pose\nserious privacy concerns. In this paper, we propose an end-to-end approach that\ntrains wakewords for Non-English languages, particulary Korean, and uses this\nto develop a Voice Authentication model to protect user privacy. Our\nimplementation employs an open-source platform OpenWakeWord, which performs\nwakeword detection using an FCN (Fully-Connected Network) architecture. Once a\nwakeword is detected, our custom-developed code calculates cosine similarity\nfor robust user authentication. Experimental results demonstrate the\neffectiveness of our approach, achieving a 16.79% and a 6.6% Equal Error Rate\n(EER) each in the Wakeword Detection and the Voice Authentication. These\nfindings highlight the model's potential in providing secure and accurate\nwakeword detection and authentication for Korean users.",
      "tldr_zh": "这篇论文提出了一种端到端(end-to-end)方法，用于开发韩语唤醒词(Wakeword)系统，并整合说话者认证(Voice Authentication)以解决隐私问题。方法基于开源平台 OpenWakeWord 和 FCN (Fully-Connected Network) 架构进行唤醒词检测，检测后通过计算余弦相似度(cosine similarity)实现用户认证。实验结果显示，该系统在唤醒词检测和语音认证中的 Equal Error Rate (EER) 分别为 16.79% 和 6.6%，证明了其在提供安全准确的韩语语音交互方面的潜力。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS",
        "I.2.7; I.5.4"
      ],
      "primary_category": "cs.SD",
      "comment": "19 pages, 10 figures, implementation code available at\n  https://github.com/gws8820/securewakeword-model,\n  https://github.com/gws8820/wyoming-securewakeword, demo video at\n  https://www.youtube.com/watch?v=F3AXUbL-i-o",
      "pdf_url": "http://arxiv.org/pdf/2501.12194v1",
      "published_date": "2025-01-21 15:02:31 UTC",
      "updated_date": "2025-01-21 15:02:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:40:12.655704"
    },
    {
      "arxiv_id": "2501.12429v1",
      "title": "Fuel Efficiency Analysis of the Public Transportation System Based on the Gaussian Mixture Model Clustering",
      "title_zh": "基于高斯混合模型聚类的公共交通系统燃料效率分析",
      "authors": [
        "Zhipeng Ma",
        "Bo Nørregaard Jørgensen",
        "Zheng Ma"
      ],
      "abstract": "Public transportation is a major source of greenhouse gas emissions,\nhighlighting the need to improve bus fuel efficiency. Clustering algorithms\nassist in analyzing fuel efficiency by grouping data into clusters, but\nirrelevant features may complicate the analysis and choosing the optimal number\nof clusters remains a challenging task. Therefore, this paper employs the\nGaussian mixture models to cluster the solo fuel-efficiency dataset. Moreover,\nan integration method that combines the Silhouette index, Calinski-Harabasz\nindex, and Davies-Bouldin index is developed to select the optimal cluster\nnumbers. A dataset with 4006 bus trips in North Jutland, Denmark is utilized as\nthe case study. Trips are first split into three groups, then one group is\ndivided further, resulting in four categories: extreme, normal, low, and\nextremely low fuel efficiency. A preliminary study using visualization analysis\nis conducted to investigate how driving behaviors and route conditions affect\nfuel efficiency. The results indicate that both individual driving habits and\nroute characteristics have a significant influence on fuel efficiency.",
      "tldr_zh": "本研究分析了公共交通系统的燃油效率问题，使用 Gaussian Mixture Models (GMM) 进行数据聚类，以应对无关特征干扰和最佳聚类数选择的挑战。研究开发了一种整合方法，结合 Silhouette index、Calinski-Harabasz index 和 Davies-Bouldin index 来确定最优聚类数，并基于丹麦北日德兰的4006次巴士行程数据集，将行程分为四类：extreme、normal、low 和 extremely low fuel efficiency。结果显示，驾驶行为和路线条件对燃油效率有显著影响，为优化公共交通节能策略提供了重要见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12429v1",
      "published_date": "2025-01-21 14:25:29 UTC",
      "updated_date": "2025-01-21 14:25:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:40:23.394903"
    },
    {
      "arxiv_id": "2501.12162v2",
      "title": "AdaServe: Accelerating Multi-SLO LLM Serving with SLO-Customized Speculative Decoding",
      "title_zh": "翻译失败",
      "authors": [
        "Zikun Li",
        "Zhuofu Chen",
        "Remi Delacourt",
        "Gabriele Oliaro",
        "Zeyu Wang",
        "Qinghan Chen",
        "Shuhuai Lin",
        "April Yang",
        "Zhihao Zhang",
        "Zhuoming Chen",
        "Sean Lai",
        "Xinhao Cheng",
        "Xupeng Miao",
        "Zhihao Jia"
      ],
      "abstract": "Modern large language model (LLM) applications exhibit diverse service-level\nobjectives (SLOs), from low-latency requirements in interactive coding\nassistants to more relaxed constraints in data wrangling tasks. Existing LLM\nserving systems, which rely on uniform batching and scheduling strategies,\noften fail to meet these heterogeneous SLOs concurrently. We present AdaServe,\nthe first LLM serving system designed to support efficient multi-SLO serving\nthrough SLO-customized speculative decoding. AdaServe formulates multi-SLO\nserving as a constrained optimization problem and introduces a hardware-aware\nalgorithm that constructs a speculation tree tailored to each request's latency\ntarget. It features a speculate-select-verify pipeline that enables\nfine-grained control over decoding speed while maximizing system throughput.\nAdaServe further adapts to workload variation by dynamically adjusting\nspeculation parameters. Evaluations across diverse workloads show that AdaServe\nreduces SLO violations by up to 4.3$\\times$ and improves goodput by up to\n1.9$\\times$ compared to the best performing baselines, highlighting its\neffectiveness in multi-SLO serving.",
      "tldr_zh": "论文介绍了 AdaServe，一种专为大型语言模型(LLM)服务设计的系统，用于加速多服务级别目标(SLOs)服务，通过 SLO-Customized Speculative Decoding 来处理异构延迟需求。AdaServe 将多-SLO 服务表述为约束优化问题，并采用硬件感知算法构建针对每个请求的推测树，以及 speculate-select-verify 管道，实现对解码速度的细粒度控制，同时最大化系统吞吐量。系统还通过动态调整推测参数来适应工作负载变化。评估结果显示，AdaServe 相较基线减少 SLO 违规高达 4.3 倍，并提高 goodput 达 1.9 倍。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12162v2",
      "published_date": "2025-01-21 14:15:01 UTC",
      "updated_date": "2025-05-17 07:09:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:40:36.943770"
    },
    {
      "arxiv_id": "2501.12149v1",
      "title": "On the practical applicability of modern DFT functionals for chemical computations. Case study of DM21 applicability for geometry optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Kirill Kulaev",
        "Alexander Ryabov",
        "Michael Medvedev",
        "Evgeny Burnaev",
        "Vladimir Vanovskiy"
      ],
      "abstract": "Density functional theory (DFT) is probably the most promising approach for\nquantum chemistry calculations considering its good balance between\ncalculations precision and speed. In recent years, several neural network-based\nfunctionals have been developed for exchange-correlation energy approximation\nin DFT, DM21 developed by Google Deepmind being the most notable between them.\nThis study focuses on evaluating the efficiency of DM21 functional in\npredicting molecular geometries, with a focus on the influence of oscillatory\nbehavior in neural network exchange-correlation functionals. We implemented\ngeometry optimization in PySCF for the DM21 functional in geometry optimization\nproblem, compared its performance with traditional functionals, and tested it\non various benchmarks. Our findings reveal both the potential and the current\nchallenges of using neural network functionals for geometry optimization in\nDFT. We propose a solution extending the practical applicability of such\nfunctionals and allowing to model new substances with their help.",
      "tldr_zh": "这篇论文评估了现代密度泛函理论(DFT)泛函在化学计算中的实际适用性，以Google DeepMind开发的DM21泛函为案例，重点考察其在分子几何优化的性能。研究团队在PySCF框架中实现了DM21泛函，并将其与传统泛函进行比较，通过各种基准测试分析其效率和神经网络泛函的振荡行为问题。结果表明，DM21在预测分子几何方面显示出潜力，但也面临挑战；论文提出了一种解决方案，以扩展此类泛函的实际应用，从而有助于建模新物质。",
      "categories": [
        "physics.comp-ph",
        "cond-mat.mtrl-sci",
        "cs.AI"
      ],
      "primary_category": "physics.comp-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12149v1",
      "published_date": "2025-01-21 14:01:06 UTC",
      "updated_date": "2025-01-21 14:01:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:40:47.512570"
    },
    {
      "arxiv_id": "2501.12147v1",
      "title": "Improving Influence-based Instruction Tuning Data Selection for Balanced Learning of Diverse Capabilities",
      "title_zh": "改进基于影响的指令微调数据选择，以实现多种能力的平衡学习",
      "authors": [
        "Qirun Dai",
        "Dylan Zhang",
        "Jiaqi W. Ma",
        "Hao Peng"
      ],
      "abstract": "Selecting appropriate training data is crucial for effective instruction\nfine-tuning of large language models (LLMs), which aims to (1) elicit strong\ncapabilities, and (2) achieve balanced performance across a diverse range of\ntasks. Influence-based methods show promise in achieving (1) by estimating the\ncontribution of each training example to the model's predictions, but often\nstruggle with (2). Our systematic investigation reveals that this\nunderperformance can be attributed to an inherent bias where certain tasks\nintrinsically have greater influence than others. As a result, data selection\nis often biased towards these tasks, not only hurting the model's performance\non others but also, counterintuitively, harms performance on these\nhigh-influence tasks themselves.\n  As a remedy, we propose BIDS, a Balanced and Influential Data Selection\nalgorithm. BIDS first normalizes influence scores of the training data, and\nthen iteratively balances data selection by choosing the training example with\nthe highest influence on the most underrepresented task. Experiments with both\nLlama-3 and Mistral-v0.3 on seven benchmarks spanning five diverse capabilities\nshow that BIDS consistently outperforms both state-of-the-art influence-based\nalgorithms and other non-influence-based selection frameworks. Surprisingly,\ntraining on a 15% subset selected by BIDS can even outperform full-dataset\ntraining with a much more balanced performance. Our analysis further highlights\nthe importance of both instance-level normalization and iterative optimization\nof selected data for balanced learning of diverse capabilities.",
      "tldr_zh": "这篇论文针对大型语言模型（LLMs）的指令微调数据选择问题，指出现有的 Influence-based 方法虽能提升模型能力，但易导致任务不平衡，因为某些任务的内在影响更大，从而损害整体性能。作者提出 BIDS（Balanced and Influential Data Selection）算法，通过归一化影响分数并迭代选择对最 underrepresented 任务影响最大的训练示例，实现多样能力的平衡学习。在 Llama-3 和 Mistral-v0.3 上的实验显示，BIDS 优于现有 Influence-based 和其他框架，使用 15% 子集训练甚至超过全数据集，且性能更均衡。该研究强调实例级归一化和迭代优化对平衡学习的重要性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12147v1",
      "published_date": "2025-01-21 14:00:43 UTC",
      "updated_date": "2025-01-21 14:00:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:41:00.290970"
    },
    {
      "arxiv_id": "2501.12428v2",
      "title": "SplitQuant: Layer Splitting for Low-Bit Neural Network Quantization",
      "title_zh": "翻译失败",
      "authors": [
        "Jaewoo Song",
        "Fangzhen Lin"
      ],
      "abstract": "Quantization for deep neural networks (DNNs) is the process of mapping the\nparameter values of DNNs from original data types to other data types of lower\nprecision to reduce model sizes and make inference faster. Quantization often\nmaps different original values to a single quantized value because the range of\nthe original values is larger than the range of the quantized values. This\nleads to the degradation of the accuracy of the quantized DNNs. Outliers are a\nmain cause of the degradation of quantization resolution because they enlarge\nthe range of original values. To solve the problem, the percentile method is\noften used to clip outliers. However, clipping the outliers has another problem\nof removing the important and strong signals in the DNNs. This paper proposes\nSplitQuant to keep the outliers and improve the quantization resolution at the\nsame time. SplitQuant narrows down the range of the original values and\nmitigates the effect of outliers by splitting each quantizable layer into three\nmathematically equivalent layers and applies different scaling factors.\nEspecially, weights and biases are clustered into lower, middle and upper\nclusters for optimized split. By preprocessing DNNs with SplitQuant,\nquantization algorithms can achieve better results. SplitQuant was applied on\ntwo BERT-Tiny models and improved the accuracy of INT2 quantization by 3.3%p\nand 2.1%p, achieving accuracies comparable to those of the original FP32\nmodels.",
      "tldr_zh": "本论文提出SplitQuant，一种通过层分割(Layer Splitting)来提升低位量化(Low-Bit Neural Network Quantization)性能的方法，旨在解决深度神经网络(DNNs)量化过程中异常值(Outliers)导致的精度下降问题。SplitQuant将每个可量化层拆分为三个数学等效层，并应用不同的缩放因子来缩小原始值范围，同时通过将权重和偏差聚类(clustered)成lower、middle和upper组，保留重要信号并优化量化分辨率。实验结果显示，在两个BERT-Tiny模型上，SplitQuant将INT2量化的准确率分别提高了3.3%p和2.1%p，使其性能接近原FP32模型水平。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted as a full paper by the 2025 EDGE AI FOUNDATION Austin",
      "pdf_url": "http://arxiv.org/pdf/2501.12428v2",
      "published_date": "2025-01-21 13:53:16 UTC",
      "updated_date": "2025-02-06 12:42:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:41:11.887933"
    },
    {
      "arxiv_id": "2501.12123v1",
      "title": "FedCLEAN: byzantine defense by CLustering Errors of Activation maps in Non-IID federated learning environments",
      "title_zh": "翻译失败",
      "authors": [
        "Mehdi Ben Ghali",
        "Reda Bellafqira",
        "Gouenou Coatrieux"
      ],
      "abstract": "Federated Learning (FL) enables clients to collaboratively train a global\nmodel using their local datasets while reinforcing data privacy. However, FL is\nsusceptible to poisoning attacks. Existing defense mechanisms assume that\nclients' data are independent and identically distributed (IID), making them\nineffective in real-world applications where data are non-IID. This paper\npresents FedCLEAN, the first defense capable of filtering attackers' model\nupdates in a non-IID FL environment. The originality of FedCLEAN is twofold.\nFirst, it relies on a client confidence score derived from the reconstruction\nerrors of each client's model activation maps for a given trigger set, with\nreconstruction errors obtained by means of a Conditional Variational\nAutoencoder trained according to a novel server-side strategy. Second, we\npropose an ad-hoc trust propagation algorithm based on client scores, which\nallows building a cluster of benign clients while flagging potential attackers.\nExperimental results on the datasets MNIST and FashionMNIST demonstrate the\nrobustness of FedCLEAN against Byzantine attackers in non-IID scenarios and a\nclose-to-zero benign client misclassification rate, even in the absence of an\nattack.",
      "tldr_zh": "本研究提出FedCLEAN，一种针对非IID联邦学习（Federated Learning, FL）环境的防御机制，用于对抗Byzantine攻击者。该方法通过计算客户端模型激活映射（activation maps）的重建错误，利用Conditional Variational Autoencoder (CVAE)训练的服务器端策略生成客户端置信度分数，并结合一个基于这些分数的信任传播算法（trust propagation algorithm）构建良性客户端集群，同时标记潜在攻击者。实验在MNIST和FashionMNIST数据集上证明，FedCLEAN在非IID场景下显示出高鲁棒性，对Byzantine攻击者的过滤效果显著，且良性客户端误分类率接近零，即使在无攻击情况下。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "19 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.12123v1",
      "published_date": "2025-01-21 13:37:28 UTC",
      "updated_date": "2025-01-21 13:37:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:41:24.248722"
    },
    {
      "arxiv_id": "2501.12427v1",
      "title": "SafePowerGraph-HIL: Real-Time HIL Validation of Heterogeneous GNNs for Bridging Sim-to-Real Gap in Power Grids",
      "title_zh": "翻译失败",
      "authors": [
        "Aoxiang Ma",
        "Salah Ghamizi",
        "Jun Cao",
        "Pedro Rodriguez"
      ],
      "abstract": "As machine learning (ML) techniques gain prominence in power system research,\nvalidating these methods' effectiveness under real-world conditions requires\nreal-time hardware-in-the-loop (HIL) simulations. HIL simulation platforms\nenable the integration of computational models with physical devices, allowing\nrigorous testing across diverse scenarios critical to system resilience and\nreliability. In this study, we develop a SafePowerGraph-HIL framework that\nutilizes HIL simulations on the IEEE 9-bus system, modeled in Hypersim, to\ngenerate high-fidelity data, which is then transmitted in real-time via SCADA\nto an AWS cloud database before being input into a Heterogeneous Graph Neural\nNetwork (HGNN) model designed for power system state estimation and dynamic\nanalysis. By leveraging Hypersim's capabilities, we simulate complex grid\ninteractions, providing a robust dataset that captures critical parameters for\nHGNN training. The trained HGNN is subsequently validated using newly generated\ndata under varied system conditions, demonstrating accuracy and robustness in\npredicting power system states. The results underscore the potential of\nintegrating HIL with advanced neural network architectures to enhance the\nreal-time operational capabilities of power systems. This approach represents a\nsignificant advancement toward the development of intelligent, adaptive control\nstrategies that support the robustness and resilience of evolving power grids.",
      "tldr_zh": "本文提出 SafePowerGraph-HIL 框架，利用硬件在环 (HIL) 模拟来验证 Heterogeneous Graph Neural Network (HGNN) 在电力系统的实时性能，从而桥接模拟与实际场景的差距。该框架基于 IEEE 9-bus 系统，在 Hypersim 中生成高保真数据，通过 SCADA 实时传输到 AWS 云数据库，并输入 HGNN 模型进行状态估计和动态分析。实验结果显示，训练后的 HGNN 在不同系统条件下表现出色，准确性和鲁棒性显著提升。该方法为开发智能、适应性电力网格控制策略提供了重要进展。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "5 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.12427v1",
      "published_date": "2025-01-21 13:36:38 UTC",
      "updated_date": "2025-01-21 13:36:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:41:36.850857"
    },
    {
      "arxiv_id": "2501.12121v4",
      "title": "Learning Dynamic Representations via An Optimally-Weighted Maximum Mean Discrepancy Optimization Framework for Continual Learning",
      "title_zh": "翻译失败",
      "authors": [
        "KaiHui Huang",
        "RunQing Wu",
        "JinHui Shen",
        "HanYi Zhang",
        "Ling Ge",
        "JiGuo Yu",
        "Fei Ye"
      ],
      "abstract": "Continual learning has emerged as a pivotal area of research, primarily due\nto its advantageous characteristic that allows models to persistently acquire\nand retain information. However, catastrophic forgetting can severely impair\nmodel performance. In this study, we address network forgetting by introducing\na novel framework termed Optimally-Weighted Maximum Mean Discrepancy (OWMMD),\nwhich imposes penalties on representation alterations via a Multi-Level Feature\nMatching Mechanism (MLFMM). Furthermore, we propose an Adaptive Regularization\nOptimization (ARO) strategy to refine the adaptive weight vectors, which\nautonomously assess the significance of each feature layer throughout the\noptimization process, The proposed ARO approach can relieve the\nover-regularization problem and promote the future task learning. We conduct a\ncomprehensive series of experiments, benchmarking our proposed method against\nseveral established baselines. The empirical findings indicate that our\napproach achieves state-of-the-art performance.",
      "tldr_zh": "这篇论文针对持续学习（Continual Learning）中的灾难性遗忘（catastrophic forgetting）问题，提出了一种新框架Optimally-Weighted Maximum Mean Discrepancy (OWMMD)，通过多级特征匹配机制（Multi-Level Feature Matching Mechanism, MLFMM）来惩罚模型表示的变化。论文进一步引入自适应正则化优化（Adaptive Regularization Optimization, ARO）策略，以动态调整权重向量，评估各特征层的importance，缓解过度正则化并提升未来任务的学习能力。实验结果显示，该方法在多项基准测试中优于现有基线，实现了state-of-the-art性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12121v4",
      "published_date": "2025-01-21 13:33:45 UTC",
      "updated_date": "2025-04-13 15:38:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:41:47.684463"
    },
    {
      "arxiv_id": "2501.12116v1",
      "title": "Efficient PINNs: Multi-Head Unimodular Regularization of the Solutions Space",
      "title_zh": "翻译失败",
      "authors": [
        "Pedro Tarancón-Álvarez",
        "Pablo Tejerina-Pérez",
        "Raul Jimenez",
        "Pavlos Protopapas"
      ],
      "abstract": "We present a machine learning framework to facilitate the solution of\nnonlinear multiscale differential equations and, especially, inverse problems\nusing Physics-Informed Neural Networks (PINNs). This framework is based on what\nis called multihead (MH) training, which involves training the network to learn\na general space of all solutions for a given set of equations with certain\nvariability, rather than learning a specific solution of the system. This setup\nis used with a second novel technique that we call Unimodular Regularization\n(UR) of the latent space of solutions. We show that the multihead approach,\ncombined with the regularization, significantly improves the efficiency of\nPINNs by facilitating the transfer learning process thereby enabling the\nfinding of solutions for nonlinear, coupled, and multiscale differential\nequations.",
      "tldr_zh": "本研究提出了一种高效的机器学习框架，用于解决非线性多尺度微分方程，尤其是逆问题，基于 Physics-Informed Neural Networks (PINNs)。框架采用 multihead (MH) 训练方法，让神经网络学习一组方程的全部解空间，而不是特定解，并结合 Unimodular Regularization (UR) 对潜在解空间进行正则化，以提高训练效率。结果显示，这种结合方法显著提升了 PINNs 的性能，便于转移学习，从而更有效地处理非线性、耦合和多尺度微分方程。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "hep-th",
        "math.AP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12116v1",
      "published_date": "2025-01-21 13:25:56 UTC",
      "updated_date": "2025-01-21 13:25:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:41:59.933968"
    },
    {
      "arxiv_id": "2501.13126v2",
      "title": "Preference Curriculum: LLMs Should Always Be Pretrained on Their Preferred Data",
      "title_zh": "偏好课程：大型语言模型应始终在其偏好数据上进行预训练",
      "authors": [
        "Xuemiao Zhang",
        "Liangyu Xu",
        "Feiyu Duan",
        "Yongwei Zhou",
        "Sirui Wang",
        "Rongxiang Weng",
        "Jingang Wang",
        "Xunliang Cai"
      ],
      "abstract": "Large language models (LLMs) generally utilize a consistent data distribution\nthroughout the pretraining process. However, as the model's capability\nimproves, it is intuitive that its data preferences dynamically change,\nindicating the need for pretraining with different data at various training\nstages. To achieve it, we propose the Perplexity Difference (PD) based\nPreference Curriculum learning (PDPC) framework, which always perceives and\nuses the data preferred by LLMs to train and boost them. First, we introduce\nthe PD metric to quantify the difference in how challenging a sample is for\nweak versus strong models. Samples with high PD are more challenging for weak\nmodels to learn and are more suitable to be arranged in the later stage of\npretraining. Second, we propose the preference function to approximate and\npredict the data preference of the LLM at any training step, so as to complete\nthe arrangement of the dataset offline and ensure continuous training without\ninterruption. Experimental results on 1.3B and 3B models demonstrate that PDPC\nsignificantly surpasses baselines. Notably, the 3B model trained on 1T tokens\nachieves an increased average accuracy of over 8.1% across MMLU and CMMLU.",
      "tldr_zh": "这篇论文提出 Preference Curriculum 框架，认为大语言模型（LLMs）应根据其动态变化的数据偏好进行预训练，以优化训练过程。作者引入 Perplexity Difference (PD) 指标来量化样本对弱模型和强模型的难度差异，并使用偏好函数预测模型在不同训练阶段的偏好，从而离线安排数据集确保训练连续性。实验结果显示，PDPC 框架在 1.3B 和 3B 模型上显著优于基线，其中 3B 模型在 1T tokens 训练后，在 MMLU 和 CMMLU 测试集上的平均准确率提升超过 8.1%。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages, 13 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.13126v2",
      "published_date": "2025-01-21 13:12:13 UTC",
      "updated_date": "2025-02-17 11:44:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:42:12.395053"
    },
    {
      "arxiv_id": "2501.12106v3",
      "title": "Can open source large language models be used for tumor documentation in Germany? -- An evaluation on urological doctors' notes",
      "title_zh": "翻译失败",
      "authors": [
        "Stefan Lenz",
        "Arsenij Ustjanzew",
        "Marco Jeray",
        "Meike Ressing",
        "Torsten Panholzer"
      ],
      "abstract": "Tumor documentation in Germany is largely done manually, requiring reading\npatient records and entering data into structured databases. Large language\nmodels (LLMs) could potentially enhance this process by improving efficiency\nand reliability. This evaluation tests eleven different open source LLMs with\nsizes ranging from 1-70 billion model parameters on three basic tasks of the\ntumor documentation process: identifying tumor diagnoses, assigning ICD-10\ncodes, and extracting the date of first diagnosis. For evaluating the LLMs on\nthese tasks, a dataset of annotated text snippets based on anonymized doctors'\nnotes from urology was prepared. Different prompting strategies were used to\ninvestigate the effect of the number of examples in few-shot prompting and to\nexplore the capabilities of the LLMs in general. The models Llama 3.1 8B,\nMistral 7B, and Mistral NeMo 12 B performed comparably well in the tasks.\nModels with less extensive training data or having fewer than 7 billion\nparameters showed notably lower performance, while larger models did not\ndisplay performance gains. Examples from a different medical domain than\nurology could also improve the outcome in few-shot prompting, which\ndemonstrates the ability of LLMs to handle tasks needed for tumor\ndocumentation. Open source LLMs show a strong potential for automating tumor\ndocumentation. Models from 7-12 billion parameters could offer an optimal\nbalance between performance and resource efficiency. With tailored fine-tuning\nand well-designed prompting, these models might become important tools for\nclinical documentation in the future. The code for the evaluation is available\nfrom https://github.com/stefan-m-lenz/UroLlmEval. We also release the dataset\nas a new valuable resource that addresses the shortage of authentic and easily\naccessible benchmarks in German-language medical NLP.",
      "tldr_zh": "这篇论文评估了开源大型语言模型（LLMs）在德国肿瘤文档中的潜力，焦点是基于泌尿科医生笔记的三个任务：识别肿瘤诊断、分配 ICD-10 代码和提取首次诊断日期。研究测试了 11 个规模从 1 到 70 亿参数的 LLMs，使用不同提示策略（如 few-shot prompting）进行实验，结果显示 Llama 3.1 8B、Mistral 7B 和 Mistral NeMo 12B 模型表现最佳，而小型模型效果较差。发现表明，7-12 亿参数的模型提供了最佳性能与资源平衡，且来自其他医疗领域的示例能提升 few-shot prompting 的效果。论文强调开源 LLMs 通过微调和优化提示策略，可能成为未来临床文档的重要工具，并发布了评估代码和新的德语医疗 NLP 数据集。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "53 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.12106v3",
      "published_date": "2025-01-21 12:56:47 UTC",
      "updated_date": "2025-05-09 15:45:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:42:26.060799"
    },
    {
      "arxiv_id": "2501.12104v3",
      "title": "Teacher Encoder-Student Decoder Denoising Guided Segmentation Network for Anomaly Detection",
      "title_zh": "教师编码",
      "authors": [
        "Shixuan Song",
        "Hao Chen",
        "Shu Hu",
        "Xin Wang",
        "Jinrong Hu",
        "Xi Wu"
      ],
      "abstract": "Visual anomaly detection is a highly challenging task, often categorized as a\none-class classification and segmentation problem. Recent studies have\ndemonstrated that the student-teacher (S-T) framework effectively addresses\nthis challenge. However, most S-T frameworks rely solely on pre-trained teacher\nnetworks to guide student networks in learning multi-scale similar features,\noverlooking the potential of the student networks to enhance learning through\nmulti-scale feature fusion. In this study, we propose a novel model named\nPFADSeg, which integrates a pre-trained teacher network, a denoising student\nnetwork with multi-scale feature fusion, and a guided anomaly segmentation\nnetwork into a unified framework. By adopting a unique teacher-encoder and\nstudent-decoder denoising mode, the model improves the student network's\nability to learn from teacher network features. Furthermore, an adaptive\nfeature fusion mechanism is introduced to train a self-supervised segmentation\nnetwork that synthesizes anomaly masks autonomously, significantly increasing\ndetection performance. Evaluated on the MVTec AD dataset, PFADSeg achieves\nstate-of-the-art results with an image-level AUC of 98.9%, a pixel-level mean\nprecision of 76.4%, and an instance-level mean precision of 78.7%.",
      "tldr_zh": "该论文针对视觉异常检测（one-class classification and segmentation）的挑战，提出了一种新型模型PFADSeg，将预训练的Teacher-Encoder网络与Student-Decoder去噪网络相结合，通过多尺度特征融合提升学生网络的学习能力。模型引入自适应特征融合机制，训练自监督分割网络以自主合成异常掩码，从而提高检测性能。在MVTec AD数据集上的实验中，PFADSeg 取得了state-of-the-art结果，包括图像级AUC 98.9%、像素级mean precision 76.4%和实例级mean precision 78.7%。这为改进Student-Teacher框架提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12104v3",
      "published_date": "2025-01-21 12:55:04 UTC",
      "updated_date": "2025-01-24 08:20:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:42:35.931858"
    },
    {
      "arxiv_id": "2501.12102v1",
      "title": "Proxies for Distortion and Consistency with Applications for Real-World Image Restoration",
      "title_zh": "失真",
      "authors": [
        "Sean Man",
        "Guy Ohayon",
        "Ron Raphaeli",
        "Michael Elad"
      ],
      "abstract": "Real-world image restoration deals with the recovery of images suffering from\nan unknown degradation. This task is typically addressed while being given only\ndegraded images, without their corresponding ground-truth versions. In this\nhard setting, designing and evaluating restoration algorithms becomes highly\nchallenging. This paper offers a suite of tools that can serve both the design\nand assessment of real-world image restoration algorithms. Our work starts by\nproposing a trained model that predicts the chain of degradations a given\nreal-world measured input has gone through. We show how this estimator can be\nused to approximate the consistency -- the match between the measurements and\nany proposed recovered image. We also use this estimator as a guiding force for\nthe design of a simple and highly-effective plug-and-play real-world image\nrestoration algorithm, leveraging a pre-trained diffusion-based image prior.\nFurthermore, this work proposes no-reference proxy measures of MSE and LPIPS,\nwhich, without access to the ground-truth images, allow ranking of real-world\nimage restoration algorithms according to their (approximate) MSE and LPIPS.\nThe proposed suite provides a versatile, first of its kind framework for\nevaluating and comparing blind image restoration algorithms in real-world\nscenarios.",
      "tldr_zh": "这篇论文针对真实世界图像恢复问题，提出了一种训练模型来预测输入图像经历的退化链，从而近似评估图像的一致性（consistency）。该模型不仅用于指导设计一个简单有效的即插即用恢复算法，利用预训练的diffusion-based image prior，还作为基础开发无参考代理措施（no-reference proxy measures）来评估MSE和LPIPS。最终，该框架为在真实场景中评估和比较盲图像恢复算法提供了首个多功能工具，提升了算法的设计和性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page in https://man-sean.github.io/elad-website/",
      "pdf_url": "http://arxiv.org/pdf/2501.12102v1",
      "published_date": "2025-01-21 12:49:30 UTC",
      "updated_date": "2025-01-21 12:49:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:42:48.083053"
    },
    {
      "arxiv_id": "2501.12085v1",
      "title": "Scalable Whole Slide Image Representation Using K-Mean Clustering and Fisher Vector Aggregation",
      "title_zh": "翻译失败",
      "authors": [
        "Ravi Kant Gupta",
        "Shounak Das",
        "Ardhendu Sekhar",
        "Amit Sethi"
      ],
      "abstract": "Whole slide images (WSIs) are high-resolution, gigapixel sized images that\npose significant computational challenges for traditional machine learning\nmodels due to their size and heterogeneity.In this paper, we present a scalable\nand efficient methodology for WSI classification by leveraging patch-based\nfeature extraction, clustering, and Fisher vector encoding. Initially, WSIs are\ndivided into fixed size patches, and deep feature embeddings are extracted from\neach patch using a pre-trained convolutional neural network (CNN). These\npatch-level embeddings are subsequently clustered using K-means clustering,\nwhere each cluster aggregates semantically similar regions of the WSI. To\neffectively summarize each cluster, Fisher vector representations are computed\nby modeling the distribution of patch embeddings in each cluster as a\nparametric Gaussian mixture model (GMM). The Fisher vectors from each cluster\nare concatenated into a high-dimensional feature vector, creating a compact and\ninformative representation of the entire WSI. This feature vector is then used\nby a classifier to predict the WSI's diagnostic label. Our method captures\nlocal and global tissue structures and yields robust performance for\nlarge-scale WSI classification, demonstrating superior accuracy and scalability\ncompared to other approaches.",
      "tldr_zh": "本研究针对Whole Slide Image (WSI) 尺寸庞大且异质性的挑战，提出了一种可扩展的分类方法，结合K-Means Clustering和Fisher Vector Aggregation。首先，将WSI分解为固定大小的补丁，使用预训练的CNN提取补丁特征嵌入，然后通过K-Means Clustering聚类相似区域，并利用Fisher Vector编码将每个聚类的补丁分布建模为Gaussian Mixture Model (GMM)，生成紧凑的高维特征向量。该特征向量用于分类器预测WSI的诊断标签，实验结果显示该方法在捕捉局部和全局组织结构方面表现出色，比其他方法具有更高的准确性和可扩展性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12085v1",
      "published_date": "2025-01-21 12:22:15 UTC",
      "updated_date": "2025-01-21 12:22:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:42:59.481715"
    },
    {
      "arxiv_id": "2501.12425v1",
      "title": "Multi-stage intermediate fusion for multimodal learning to classify non-small cell lung cancer subtypes from CT and PET",
      "title_zh": "翻译失败",
      "authors": [
        "Fatih Aksu",
        "Fabrizia Gelardi",
        "Arturo Chiti",
        "Paolo Soda"
      ],
      "abstract": "Accurate classification of histological subtypes of non-small cell lung\ncancer (NSCLC) is essential in the era of precision medicine, yet current\ninvasive techniques are not always feasible and may lead to clinical\ncomplications. This study presents a multi-stage intermediate fusion approach\nto classify NSCLC subtypes from CT and PET images. Our method integrates the\ntwo modalities at different stages of feature extraction, using voxel-wise\nfusion to exploit complementary information across varying abstraction levels\nwhile preserving spatial correlations. We compare our method against unimodal\napproaches using only CT or PET images to demonstrate the benefits of modality\nfusion, and further benchmark it against early and late fusion techniques to\nhighlight the advantages of intermediate fusion during feature extraction.\nAdditionally, we compare our model with the only existing intermediate fusion\nmethod for histological subtype classification using PET/CT images. Our results\ndemonstrate that the proposed method outperforms all alternatives across key\nmetrics, with an accuracy and AUC equal to 0.724 and 0.681, respectively. This\nnon-invasive approach has the potential to significantly improve diagnostic\naccuracy, facilitate more informed treatment decisions, and advance\npersonalized care in lung cancer management.",
      "tldr_zh": "本研究提出了一种多阶段中间融合方法，用于从CT和PET图像非侵入性地分类非小细胞肺癌(NSCLC)亚型，从而解决传统侵入性技术的局限性。该方法在不同特征提取阶段整合两种模态图像，通过体素级(voxel-wise)融合挖掘互补信息并保留空间相关性。相比单模态方法、早融合和晚融合技术，该方法在关键指标上表现出优越性能，准确率(accuracy)和AUC分别达到0.724和0.681。该创新方法有望提升诊断准确性，支持更个性化的肺癌治疗决策。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "q-bio.QM"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12425v1",
      "published_date": "2025-01-21 12:10:00 UTC",
      "updated_date": "2025-01-21 12:10:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:43:12.088797"
    },
    {
      "arxiv_id": "2501.12424v1",
      "title": "Multi-Modality Collaborative Learning for Sentiment Analysis",
      "title_zh": "多模态协作学习用于情感分析",
      "authors": [
        "Shanmin Wang",
        "Chengguang Liu",
        "Qingshan Liu"
      ],
      "abstract": "Multimodal sentiment analysis (MSA) identifies individuals' sentiment states\nin videos by integrating visual, audio, and text modalities. Despite progress\nin existing methods, the inherent modality heterogeneity limits the effective\ncapture of interactive sentiment features across modalities. In this paper, by\nintroducing a Multi-Modality Collaborative Learning (MMCL) framework, we\nfacilitate cross-modal interactions and capture enhanced and complementary\nfeatures from modality-common and modality-specific representations,\nrespectively. Specifically, we design a parameter-free decoupling module and\nseparate uni-modality into modality-common and modality-specific components\nthrough semantics assessment of cross-modal elements. For modality-specific\nrepresentations, inspired by the act-reward mechanism in reinforcement\nlearning, we design policy models to adaptively mine complementary sentiment\nfeatures under the guidance of a joint reward. For modality-common\nrepresentations, intra-modal attention is employed to highlight crucial\ncomponents, playing enhanced roles among modalities. Experimental results,\nincluding superiority evaluations on four databases, effectiveness verification\nof each module, and assessment of complementary features, demonstrate that MMCL\nsuccessfully learns collaborative features across modalities and significantly\nimproves performance. The code can be available at\nhttps://github.com/smwanghhh/MMCL.",
      "tldr_zh": "本研究针对多模态情感分析 (MSA)，提出 Multi-Modality Collaborative Learning (MMCL) 框架，通过整合视觉、音频和文本模态来捕获跨模态互动情感特征，解决现有方法因模态异质性而无法有效提取互补信息的局限性。框架包括一个参数-free decoupling module，将单模态分解为模态-common 和模态-specific 组件，并通过语义评估进行优化；针对模态-specific 表示，受强化学习中 act-reward 机制启发，设计 policy models 来自适应挖掘互补情感特征；针对模态-common 表示，则采用 intra-modal attention 来突出关键组件并增强模态间协作。实验结果显示，MMCL 在四个数据库上显著提升性能，并验证了各模块的有效性和互补特征的贡献，代码已开源。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12424v1",
      "published_date": "2025-01-21 12:06:21 UTC",
      "updated_date": "2025-01-21 12:06:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:43:23.936868"
    },
    {
      "arxiv_id": "2501.12067v1",
      "title": "EDoRA: Efficient Weight-Decomposed Low-Rank Adaptation via Singular Value Decomposition",
      "title_zh": "翻译失败",
      "authors": [
        "Hamid Nasiri",
        "Peter Garraghan"
      ],
      "abstract": "Parameter-efficient fine-tuning methods, such as LoRA, reduces the number of\ntrainable parameters. However, they often suffer from scalability issues and\ndifferences between their learning pattern and full fine-tuning. To overcome\nthese limitations, we propose Efficient Weight-Decomposed Low-Rank Adaptation\n(EDoRA): a novel PEFT method that decomposes pre-trained weights into magnitude\nand directional components. By freezing low-rank matrices, initializing them by\nsingular value decomposition, and introducing a small trainable matrix between\nthem, EDoRA achieves substantial reduction in trainable parameters while\nmaintaining learning capacity. Experimental results on the GLUE benchmark\ndemonstrate that EDoRA achieves competitive or superior performance compared to\nstate-of-the-art methods, such as LoRA and DoRA, with up to 30x fewer trainable\nparameters. This makes EDoRA a highly efficient solution for adapting LLMs to\ndiverse tasks under memory-constrained settings. Code is available at\nhttps://github.com/Hamid-Nasiri/EDoRA .",
      "tldr_zh": "该论文提出了 EDoRA，一种高效的权重分解低秩适应方法，通过 Singular Value Decomposition 将预训练权重分解为幅度和方向组件，以解决现有参数高效微调方法如 LoRA 的可扩展性和学习模式问题。EDoRA 通过冻结低秩矩阵、利用奇异值分解进行初始化，并引入一个小型可训练矩阵，显著减少了可训练参数，同时保持了学习能力。在 GLUE 基准测试中，EDoRA 与 LoRA 和 DoRA 等方法相比，实现了相当或优越的性能，但可训练参数减少高达 30 倍，使其成为适应 LLMs 的高效解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 4 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2501.12067v1",
      "published_date": "2025-01-21 11:42:09 UTC",
      "updated_date": "2025-01-21 11:42:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:43:35.704215"
    },
    {
      "arxiv_id": "2502.15710v1",
      "title": "The Process of Categorical Clipping at the Core of the Genesis of Concepts in Synthetic Neural Cognition",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Pichat",
        "William Pogrund",
        "Armanush Gasparian",
        "Paloma Pichat",
        "Samuel Demarchi",
        "Michael Veillet-Guillem",
        "Martin Corbet",
        "Théo Dasilva"
      ],
      "abstract": "This article investigates, within the field of neuropsychology of artificial\nintelligence, the process of categorical segmentation performed by language\nmodels. This process involves, across different neural layers, the creation of\nnew functional categorical dimensions to analyze the input textual data and\nperform the required tasks. Each neuron in a multilayer perceptron (MLP)\nnetwork is associated with a specific category, generated by three factors\ncarried by the neural aggregation function: categorical priming, categorical\nattention, and categorical phasing. At each new layer, these factors govern the\nformation of new categories derived from the categories of precursor neurons.\nThrough a process of categorical clipping, these new categories are created by\nselectively extracting specific subdimensions from the preceding categories,\nconstructing a distinction between a form and a categorical background. We\nexplore several cognitive characteristics of this synthetic clipping in an\nexploratory manner: categorical reduction, categorical selectivity, separation\nof initial embedding dimensions, and segmentation of categorical zones.",
      "tldr_zh": "这篇论文探讨了人工智能神经心理学领域中，语言模型通过分类剪切(categorical clipping)过程生成概念的核心机制。在多层感知器(MLP)网络中，每个神经元与特定类别相关联，这些类别由三个关键因素驱动：分类启动(categorical priming)、分类注意力(categorical attention)和分类相位(categorical phasing)，这些因素在各层间从前驱神经元的类别中选择性提取子维度，形成形式与分类背景的区分。论文还探索了这种合成剪切的认知特征，包括分类减少(categorical reduction)、分类选择性(categorical selectivity)、初始嵌入维度的分离以及分类区域的分割，作为对神经认知过程的初步分析。整体而言，该研究为理解合成神经认知中的概念生成提供了新见解。",
      "categories": [
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.15710v1",
      "published_date": "2025-01-21 11:32:39 UTC",
      "updated_date": "2025-01-21 11:32:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:43:48.741207"
    },
    {
      "arxiv_id": "2501.12048v1",
      "title": "Adaptive Class Learning to Screen Diabetic Disorders in Fundus Images of Eye",
      "title_zh": "翻译失败",
      "authors": [
        "Shramana Dey",
        "Pallabi Dutta",
        "Riddhasree Bhattacharyya",
        "Surochita Pal",
        "Sushmita Mitra",
        "Rajiv Raman"
      ],
      "abstract": "The prevalence of ocular illnesses is growing globally, presenting a\nsubstantial public health challenge. Early detection and timely intervention\nare crucial for averting visual impairment and enhancing patient prognosis.\nThis research introduces a new framework called Class Extension with Limited\nData (CELD) to train a classifier to categorize retinal fundus images. The\nclassifier is initially trained to identify relevant features concerning\nHealthy and Diabetic Retinopathy (DR) classes and later fine-tuned to adapt to\nthe task of classifying the input images into three classes: Healthy, DR, and\nGlaucoma. This strategy allows the model to gradually enhance its\nclassification capabilities, which is beneficial in situations where there are\nonly a limited number of labeled datasets available. Perturbation methods are\nalso used to identify the input image characteristics responsible for\ninfluencing the models decision-making process. We achieve an overall accuracy\nof 91% on publicly available datasets.",
      "tldr_zh": "本研究提出 CELD（Class Extension with Limited Data）框架，用于训练分类器筛查眼底图像中的糖尿病相关眼部疾病，包括 Healthy、Diabetic Retinopathy (DR) 和 Glaucoma。框架先训练模型识别 Healthy 和 DR 的相关特征，然后微调以扩展到三类分类，从而逐步提升性能，尤其适用于标签数据有限的场景。同时，采用 Perturbation methods 分析图像特征对模型决策的影响。在公开数据集上，该方法实现了 91% 的整体准确率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at International Conference on Pattern Recognition (ICPR)\n  2024",
      "pdf_url": "http://arxiv.org/pdf/2501.12048v1",
      "published_date": "2025-01-21 11:21:16 UTC",
      "updated_date": "2025-01-21 11:21:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:44:00.362579"
    },
    {
      "arxiv_id": "2501.12423v1",
      "title": "FREYR: A Framework for Recognizing and Executing Your Requests",
      "title_zh": "翻译失败",
      "authors": [
        "Roberto Gallotta",
        "Antonios Liapis",
        "Georgios N. Yannakakis"
      ],
      "abstract": "Large language models excel as conversational agents, but their capabilities\ncan be further extended through tool usage, i.e.: executable code, to enhance\nresponse accuracy or address specialized domains. Current approaches to enable\ntool usage often rely on model-specific prompting or fine-tuning a model for\nfunction-calling instructions. Both approaches have notable limitations,\nincluding reduced adaptability to unseen tools and high resource requirements.\nThis paper introduces FREYR, a streamlined framework that modularizes the tool\nusage process into separate steps. Through this decomposition, we show that\nFREYR achieves superior performance compared to conventional tool usage\nmethods. We evaluate FREYR on a set of real-world test cases specific for video\ngame design and compare it against traditional tool usage as provided by the\nOllama API.",
      "tldr_zh": "该论文提出 FREYR 框架，用于识别和执行用户请求，帮助大型语言模型（Large language models）通过工具使用（如可执行代码）提升响应准确性和处理专业领域问题。FREYR 通过将工具使用过程模块化成独立步骤，克服了传统方法的局限性，如模型特定提示和微调带来的适应性差和高资源需求。实验结果显示，FREYR 在视频游戏设计领域的真实测试案例中，性能优于 Ollama API 的传统工具使用方法。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "I.2.1; I.2.7"
      ],
      "primary_category": "cs.SE",
      "comment": "15 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.12423v1",
      "published_date": "2025-01-21 11:08:18 UTC",
      "updated_date": "2025-01-21 11:08:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:44:10.906171"
    },
    {
      "arxiv_id": "2501.12033v1",
      "title": "Harnessing Generative Pre-Trained Transformer for Datacenter Packet Trace Generation",
      "title_zh": "利用生成式预训练变压器进行数据中心数据包跟踪生成",
      "authors": [
        "Chen Griner"
      ],
      "abstract": "Today, the rapid growth of applications reliant on datacenters calls for new\nadvancements to meet the increasing traffic and computational demands. Traffic\ntraces from datacenters are essential for further development and optimization\nof future datacenters. However, traces are rarely released to the public.\nResearchers often use simplified mathematical models that lack the depth needed\nto recreate intricate traffic patterns and, thus, miss optimization\nopportunities found in realistic traffic. In this preliminary work, we\nintroduce DTG-GPT, a packet-level Datacenter Traffic Generator (DTG), based on\nthe generative pre-trained transformer (GPT) architecture used by many\nstate-of-the-art large language models. We train our model on a small set of\navailable traffic traces from different domains and offer a simple methodology\nto evaluate the fidelity of the generated traces to their original\ncounterparts. We show that DTG-GPT can synthesize novel traces that mimic the\nspatiotemporal patterns found in real traffic traces. We further demonstrate\nthat DTG-GPT can generate traces for networks of different scales while\nmaintaining fidelity. Our findings indicate the potential that, in the future,\nsimilar models to DTG-GPT will allow datacenter operators to release traffic\ninformation to the research community via trained GPT models.",
      "tldr_zh": "该研究针对数据中心流量追踪的稀缺问题，提出了一种基于 Generative Pre-Trained Transformer (GPT) 架构的 DTG-GPT 模型，用于生成逼真的数据中心包级别流量追踪。该模型在少量可用流量追踪数据集上训练，并提供简单的方法评估生成追踪与原始追踪的相似度。实验结果显示，DTG-GPT 能合成模仿真实流量时空模式的追踪，并适用于不同规模的网络，为未来数据中心运营商通过训练的 GPT 模型共享流量信息提供了潜力。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "C.2.1"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12033v1",
      "published_date": "2025-01-21 10:55:50 UTC",
      "updated_date": "2025-01-21 10:55:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:44:22.837189"
    },
    {
      "arxiv_id": "2501.13125v2",
      "title": "Generating Plausible Distractors for Multiple-Choice Questions via Student Choice Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Yooseop Lee",
        "Suin Kim",
        "Yohan Jo"
      ],
      "abstract": "In designing multiple-choice questions (MCQs) in education, creating\nplausible distractors is crucial for identifying students' misconceptions and\ngaps in knowledge and accurately assessing their understanding. However, prior\nstudies on distractor generation have not paid sufficient attention to\nenhancing the difficulty of distractors, resulting in reduced effectiveness of\nMCQs. This study presents a pipeline for training a model to generate\ndistractors that are more likely to be selected by students. First, we train a\npairwise ranker to reason about students' misconceptions and assess the\nrelative plausibility of two distractors. Using this model, we create a dataset\nof pairwise distractor ranks and then train a distractor generator via Direct\nPreference Optimization (DPO) to generate more plausible distractors.\nExperiments on computer science subjects (Python, DB, MLDL) demonstrate that\nour pairwise ranker effectively identifies students' potential\nmisunderstandings and achieves ranking accuracy comparable to human experts.\nFurthermore, our distractor generator outperforms several baselines in\ngenerating plausible distractors and produces questions with a higher item\ndiscrimination index (DI).",
      "tldr_zh": "本文提出一种管道，通过预测学生选择来生成更 plausible 的多项选择题 (MCQs) 干扰项 (distractors)，以更好地识别学生的误区和知识缺口，从而提升 MCQs 的评估有效性。方法包括先训练一个 pairwise ranker 来推理学生的潜在误解并评估两个 distractors 的相对 plausibility，然后利用该模型创建数据集，并通过 Direct Preference Optimization (DPO) 训练 distractor generator。实验在计算机科学主题（如 Python、DB 和 MLDL）上显示，该 pairwise ranker 的排名准确率与人类专家相当，而 distractor generator 优于基线模型，能生成更 plausible 的 distractors，并提高了项目区分指数 (DI)。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13125v2",
      "published_date": "2025-01-21 10:20:39 UTC",
      "updated_date": "2025-03-16 06:33:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:44:36.393578"
    },
    {
      "arxiv_id": "2501.12015v1",
      "title": "Full Proportional Justified Representation",
      "title_zh": "翻译失败",
      "authors": [
        "Yusuf Hakan Kalayci",
        "Jiasen Liu",
        "David Kempe"
      ],
      "abstract": "In multiwinner approval voting, forming a committee that proportionally\nrepresents voters' approval ballots is an essential task. The notion of\njustified representation (JR) demands that any large \"cohesive\" group of voters\nshould be proportionally \"represented\". The \"cohesiveness\" is defined in\ndifferent ways; two common ways are the following: (C1) demands that the group\nunanimously approves a set of candidates proportional to its size, while (C2)\nrequires each member to approve at least a fixed fraction of such a set.\nSimilarly, \"representation\" have been considered in different ways: (R1) the\ncoalition's collective utility from the winning set exceeds that of any\nproportionally sized alternative, and (R2) for any proportionally sized\nalternative, at least one member of the coalition derives less utility from it\nthan from the winning set.\n  Three of the four possible combinations have been extensively studied:\n(C1)-(R1) defines Proportional Justified Representation (PJR), (C1)-(R2)\ndefines Extended Justified Representation (EJR), (C2)-(R2) defines Full\nJustified Representation (FJR). All three have merits, but also drawbacks. PJR\nis the weakest notion, and perhaps not sufficiently demanding; EJR may not be\ncompatible with perfect representation; and it is open whether a committee\nsatisfying FJR can be found efficiently.\n  We study the combination (C2)-(R1), which we call Full Proportional Justified\nRepresentation (FPJR). We investigate FPJR's properties and find that it shares\nPJR's advantages over EJR: several proportionality axioms (e.g. priceability,\nperfect representation) imply FPJR and PJR but not EJR. We also find that\nefficient rules like the greedy Monroe rule and the method of equal shares\nsatisfy FPJR, matching a key advantage of EJR over FJR. However, the\nProportional Approval Voting (PAV) rule may violate FPJR, so neither of EJR and\nFPJR implies the other.",
      "tldr_zh": "这篇论文引入了 Full Proportional Justified Representation (FPJR)，一种新的概念，用于多赢者认可投票(multiwinner approval voting)中确保委员会比例代表选民的认可投票。FPJR 结合了凝聚性(C2)——每个成员认可至少固定比例的候选人——和代表性(R1)——群体的集体效用超过任何比例大小的备选，从而解决了现有标准如 Proportional Justified Representation (PJR) 的不足。研究发现，FPJR 与某些比例性公理（如 priceability 和 perfect representation）兼容，并证明高效规则如 greedy Monroe rule 和 method of equal shares 可以满足 FPJR，但 Proportional Approval Voting (PAV) 规则可能违反它。通过这些分析，论文为改进投票系统的公平性和效率提供了新见解。",
      "categories": [
        "cs.GT",
        "cs.AI"
      ],
      "primary_category": "cs.GT",
      "comment": "18 pages, Accepted to AAMAS 25",
      "pdf_url": "http://arxiv.org/pdf/2501.12015v1",
      "published_date": "2025-01-21 10:13:28 UTC",
      "updated_date": "2025-01-21 10:13:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:44:49.831056"
    },
    {
      "arxiv_id": "2501.12422v1",
      "title": "CroMe: Multimodal Fake News Detection using Cross-Modal Tri-Transformer and Metric Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Eunjee Choi",
        "Junhyun Ahn",
        "XinYu Piao",
        "Jong-Kook Kim"
      ],
      "abstract": "Multimodal Fake News Detection has received increasing attention recently.\nExisting methods rely on independently encoded unimodal data and overlook the\nadvantages of capturing intra-modality relationships and integrating\ninter-modal similarities using advanced techniques. To address these issues,\nCross-Modal Tri-Transformer and Metric Learning for Multimodal Fake News\nDetection (CroMe) is proposed. CroMe utilizes Bootstrapping Language-Image\nPre-training with Frozen Image Encoders and Large Language Models (BLIP2) as\nencoders to capture detailed text, image and combined image-text\nrepresentations. The metric learning module employs a proxy anchor method to\ncapture intra-modality relationships while the feature fusion module uses a\nCross-Modal and Tri-Transformer for effective integration. The final fake news\ndetector processes the fused features through a classifier to predict the\nauthenticity of the content. Experiments on datasets show that CroMe excels in\nmultimodal fake news detection.",
      "tldr_zh": "该研究提出 CroMe 框架，用于多模态假新闻检测，旨在解决现有方法忽略模态内关系和模态间相似性的问题。\nCroMe 采用 BLIP2 作为编码器捕捉文本、图像和图像-文本的详细表示，并通过度量学习模块的代理锚点方法（proxy anchor method）处理模态内关系，以及 Cross-Modal Tri-Transformer 进行特征融合。\n最终，框架使用分类器预测内容的真实性，并在实验数据集上表现出色，优于传统方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12422v1",
      "published_date": "2025-01-21 09:36:27 UTC",
      "updated_date": "2025-01-21 09:36:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:44:59.970793"
    },
    {
      "arxiv_id": "2501.11992v1",
      "title": "Survey on Hand Gesture Recognition from Visual Input",
      "title_zh": "翻译失败",
      "authors": [
        "Manousos Linardakis",
        "Iraklis Varlamis",
        "Georgios Th. Papadopoulos"
      ],
      "abstract": "Hand gesture recognition has become an important research area, driven by the\ngrowing demand for human-computer interaction in fields such as sign language\nrecognition, virtual and augmented reality, and robotics. Despite the rapid\ngrowth of the field, there are few surveys that comprehensively cover recent\nresearch developments, available solutions, and benchmark datasets. This survey\naddresses this gap by examining the latest advancements in hand gesture and 3D\nhand pose recognition from various types of camera input data including RGB\nimages, depth images, and videos from monocular or multiview cameras, examining\nthe differing methodological requirements of each approach. Furthermore, an\noverview of widely used datasets is provided, detailing their main\ncharacteristics and application domains. Finally, open challenges such as\nachieving robust recognition in real-world environments, handling occlusions,\nensuring generalization across diverse users, and addressing computational\nefficiency for real-time applications are highlighted to guide future research\ndirections. By synthesizing the objectives, methodologies, and applications of\nrecent studies, this survey offers valuable insights into current trends,\nchallenges, and opportunities for future research in human hand gesture\nrecognition.",
      "tldr_zh": "这篇调查论文综述了基于视觉输入的手势识别领域的研究进展，强调其在人机交互应用（如手语识别、虚拟现实和机器人）中的重要性，并填补了现有调查的空白。论文考察了从 RGB 图像、深度图像和视频等不同相机输入的最新方法，包括手势和 3D hand pose recognition 的差异，并概述了常用基准数据集的特征和应用领域。最终，它突出了关键挑战，如实现真实环境下的鲁棒识别、处理 occlusions、提升用户泛化性和计算效率，为未来研究方向提供了宝贵见解。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.11992v1",
      "published_date": "2025-01-21 09:23:22 UTC",
      "updated_date": "2025-01-21 09:23:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:45:12.287158"
    },
    {
      "arxiv_id": "2501.12421v1",
      "title": "Tackling Small Sample Survival Analysis via Transfer Learning: A Study of Colorectal Cancer Prognosis",
      "title_zh": "翻译失败",
      "authors": [
        "Yonghao Zhao",
        "Changtao Li",
        "Chi Shu",
        "Qingbin Wu",
        "Hong Li",
        "Chuan Xu",
        "Tianrui Li",
        "Ziqiang Wang",
        "Zhipeng Luo",
        "Yazhou He"
      ],
      "abstract": "Survival prognosis is crucial for medical informatics. Practitioners often\nconfront small-sized clinical data, especially cancer patient cases, which can\nbe insufficient to induce useful patterns for survival predictions. This study\ndeals with small sample survival analysis by leveraging transfer learning, a\nuseful machine learning technique that can enhance the target analysis with\nrelated knowledge pre-learned from other data. We propose and develop various\ntransfer learning methods designed for common survival models. For parametric\nmodels such as DeepSurv, Cox-CC (Cox-based neural networks), and DeepHit\n(end-to-end deep learning model), we apply standard transfer learning\ntechniques like pretraining and fine-tuning. For non-parametric models such as\nRandom Survival Forest, we propose a new transfer survival forest (TSF) model\nthat transfers tree structures from source tasks and fine-tunes them with\ntarget data. We evaluated the transfer learning methods on colorectal cancer\n(CRC) prognosis. The source data are 27,379 SEER CRC stage I patients, and the\ntarget data are 728 CRC stage I patients from the West China Hospital. When\nenhanced by transfer learning, Cox-CC's $C^{td}$ value was boosted from 0.7868\nto 0.8111, DeepHit's from 0.8085 to 0.8135, DeepSurv's from 0.7722 to 0.8043,\nand RSF's from 0.7940 to 0.8297 (the highest performance). All models trained\nwith data as small as 50 demonstrated even more significant improvement.\nConclusions: Therefore, the current survival models used for cancer prognosis\ncan be enhanced and improved by properly designed transfer learning techniques.\nThe source code used in this study is available at\nhttps://github.com/YonghaoZhao722/TSF.",
      "tldr_zh": "这篇论文探讨了通过transfer learning解决小样本生存分析问题，针对结直肠癌预后进行研究，以应对临床数据不足的挑战。作者为参数模型如DeepSurv、Cox-CC和DeepHit应用预训练和微调技术，并提出新的transfer survival forest (TSF)模型，用于从源任务转移树结构并在目标数据上微调非参数模型如Random Survival Forest。实验使用SEER数据集（27,379例CRC I期患者）作为源数据和西中国医院数据（728例患者）作为目标数据，结果显示迁移学习显著提升了模型性能，例如Cox-CC的C^td值从0.7868提高到0.8111，尤其在样本量小至50时改善更明显。结论是，适当设计的transfer learning技术可以增强癌症预后生存模型的准确性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.12421v1",
      "published_date": "2025-01-21 08:52:57 UTC",
      "updated_date": "2025-01-21 08:52:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:45:25.488993"
    },
    {
      "arxiv_id": "2501.11977v1",
      "title": "Leveraging Graph Structures and Large Language Models for End-to-End Synthetic Task-Oriented Dialogues",
      "title_zh": "翻译失败",
      "authors": [
        "Maya Medjad",
        "Hugo Imbert",
        "Bruno Yun",
        "Raphaël Szymocha",
        "Frédéric Armetta"
      ],
      "abstract": "Training task-oriented dialogue systems is both costly and time-consuming,\ndue to the need for high-quality datasets encompassing diverse intents.\nTraditional methods depend on extensive human annotation, while recent\nadvancements leverage large language models (LLMs) to generate synthetic data.\nHowever, these approaches often require custom prompts or code, limiting\naccessibility for non-technical users. We introduce GraphTOD, an end-to-end\nframework that simplifies the generation of task-oriented dialogues. Users can\ncreate dialogues by specifying transition graphs in JSON format. Our evaluation\ndemonstrates that GraphTOD generates high-quality dialogues across various\ndomains, significantly lowering the cost and complexity of dataset creation.",
      "tldr_zh": "这篇论文提出了GraphTOD框架，利用图结构(Graph Structures)和大型语言模型(LLMs)，以端到端方式生成合成任务导向对话(Task-Oriented Dialogues)，解决传统数据集创建的成本高和复杂性问题。用户只需通过JSON格式指定过渡图，即可简化对话生成过程，而无需自定义提示或代码。评估结果显示，GraphTOD在多个领域生成高质量对话，显著降低了数据集制作的开销和门槛。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.11977v1",
      "published_date": "2025-01-21 08:51:12 UTC",
      "updated_date": "2025-01-21 08:51:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:45:35.632761"
    },
    {
      "arxiv_id": "2501.11968v1",
      "title": "Bridging Visualization and Optimization: Multimodal Large Language Models on Graph-Structured Combinatorial Optimization",
      "title_zh": "桥接可视化和优化：多模态大型语言模型在图结构组合优化中的应用",
      "authors": [
        "Jie Zhao",
        "Kang Hao Cheong",
        "Witold Pedrycz"
      ],
      "abstract": "Graph-structured combinatorial challenges are inherently difficult due to\ntheir nonlinear and intricate nature, often rendering traditional computational\nmethods ineffective or expensive. However, these challenges can be more\nnaturally tackled by humans through visual representations that harness our\ninnate ability for spatial reasoning. In this study, we propose transforming\ngraphs into images to preserve their higher-order structural features\naccurately, revolutionizing the representation used in solving graph-structured\ncombinatorial tasks. This approach allows machines to emulate human-like\nprocessing in addressing complex combinatorial challenges. By combining the\ninnovative paradigm powered by multimodal large language models (MLLMs) with\nsimple search techniques, we aim to develop a novel and effective framework for\ntackling such problems. Our investigation into MLLMs spanned a variety of\ngraph-based tasks, from combinatorial problems like influence maximization to\nsequential decision-making in network dismantling, as well as addressing six\nfundamental graph-related issues. Our findings demonstrate that MLLMs exhibit\nexceptional spatial intelligence and a distinctive capability for handling\nthese problems, significantly advancing the potential for machines to\ncomprehend and analyze graph-structured data with a depth and intuition akin to\nhuman cognition. These results also imply that integrating MLLMs with simple\noptimization strategies could form a novel and efficient approach for\nnavigating graph-structured combinatorial challenges without complex\nderivations, computationally demanding training and fine-tuning.",
      "tldr_zh": "这篇论文提出了一种创新方法，将图结构转化为图像，以保留其高级结构特征，从而利用 Multimodal Large Language Models (MLLMs) 模拟人类的空间推理来解决复杂的图结构组合优化问题。该方法结合 MLLMs 与简单搜索技术，构建了一个高效框架，应用于影响最大化、网络拆解等任务，以及六种基本图相关问题。研究发现，MLLMs 展现出卓越的空间智能，能够像人类一样深入理解和分析图数据，且无需复杂的衍生、训练或微调，即可显著提升问题解决效率。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.11968v1",
      "published_date": "2025-01-21 08:28:10 UTC",
      "updated_date": "2025-01-21 08:28:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:45:47.880736"
    },
    {
      "arxiv_id": "2501.11960v1",
      "title": "TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection",
      "title_zh": "TAD-Bench：一种用于基于嵌入的文本异常检测的全面基准",
      "authors": [
        "Yang Cao",
        "Sikun Yang",
        "Chen Li",
        "Haolong Xiang",
        "Lianyong Qi",
        "Bo Liu",
        "Rongsheng Li",
        "Ming Liu"
      ],
      "abstract": "Text anomaly detection is crucial for identifying spam, misinformation, and\noffensive language in natural language processing tasks. Despite the growing\nadoption of embedding-based methods, their effectiveness and generalizability\nacross diverse application scenarios remain under-explored. To address this, we\npresent TAD-Bench, a comprehensive benchmark designed to systematically\nevaluate embedding-based approaches for text anomaly detection. TAD-Bench\nintegrates multiple datasets spanning different domains, combining\nstate-of-the-art embeddings from large language models with a variety of\nanomaly detection algorithms. Through extensive experiments, we analyze the\ninterplay between embeddings and detection methods, uncovering their strengths,\nweaknesses, and applicability to different tasks. These findings offer new\nperspectives on building more robust, efficient, and generalizable anomaly\ndetection systems for real-world applications.",
      "tldr_zh": "本文提出 TAD-Bench，这是一个全面基准，用于系统评估基于 embedding 的文本异常检测方法，以解决其有效性和泛化性不足的问题。TAD-Bench 整合了多个跨领域的数据集，结合大型语言模型的 state-of-the-art embeddings 和各种异常检测算法，通过广泛实验分析了嵌入与检测方法之间的互动。研究揭示了这些方法的优势、弱点和适用性，为开发更稳健、高效和泛化性强的文本异常检测系统提供了新视角。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.11960v1",
      "published_date": "2025-01-21 08:13:10 UTC",
      "updated_date": "2025-01-21 08:13:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:46:00.096983"
    },
    {
      "arxiv_id": "2501.17168v3",
      "title": "EvoGP: A GPU-accelerated Framework for Tree-based Genetic Programming",
      "title_zh": "翻译失败",
      "authors": [
        "Lishuang Wang",
        "Zhihong Wu",
        "Kebin Sun",
        "Zhuozhao Li",
        "Ran Cheng"
      ],
      "abstract": "Tree-based Genetic Programming (TGP) is a key evolutionary algorithm widely\nused in symbolic regression, feature engineering, and scientific modeling. Its\nhigh computational demands make GPU acceleration essential for scalable and\nhigh-performance evolutionary computation. However, GPU acceleration of TGP\nfaces three key challenges: inefficient tree encoding, highly heterogeneous\ngenetic operations, and limited parallelism in fitness evaluation. To address\nthese challenges, we introduce EvoGP, a comprehensive GPU-accelerated TGP\nframework. First, we design a tensorized encoding scheme to represent tree with\ndifferent structures as tensors with the same shape, optimizing memory access\nand enabling efficient parallel execution. Second, we propose a unified\nparallel framework for genetic operations by leveraging shared computational\nprimitives and implementing dedicated CUDA kernels for scalable performance.\nThird, we present a fully parallel fitness evaluation strategy for symbolic\nregression, exploiting both population-level and data-level parallelism to\nmaximize GPU utilization. Moreover, we implement a comprehensive library to\nprovide rich algorithm operators and benchmark problems. EvoGP is extensively\ntested on various tasks, including symbolic regression, classification, and\nrobotics control, demonstrating its versatility and effectiveness across\ndiverse application scenarios. Experimental results show that EvoGP achieves up\nto a 140.89x speedup over the state-of-the-art GPU-based TGP implementation,\nwhile maintaining or exceeding the accuracy of baseline methods. EvoGP is\nopen-source and accessible at: https://github.com/EMI-Group/evogp.",
      "tldr_zh": "该论文介绍了 EvoGP，一种针对 Tree-based Genetic Programming (TGP) 的 GPU 加速框架，旨在提升符号回归、特征工程和科学建模等任务的计算效率。通过 tensorized encoding 方案优化树结构表示、统一的并行框架处理高度异构的遗传操作，以及完全并行的 fitness evaluation 策略，EvoGP 成功解决了 TGP 在 GPU 加速中的三大挑战。实验结果显示，EvoGP 在符号回归、分类和机器人控制任务上，比现有 GPU-based TGP 实现快了高达 140.89 倍，同时保持或超过基线方法的准确性。该框架已开源，可在 GitHub 上获取。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.17168v3",
      "published_date": "2025-01-21 07:42:54 UTC",
      "updated_date": "2025-02-02 17:03:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:46:13.666048"
    },
    {
      "arxiv_id": "2501.11937v2",
      "title": "MeshONet: A Generalizable and Efficient Operator Learning Method for Structured Mesh Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Jing Xiao",
        "Xinhai Chen",
        "Qingling Wang",
        "Jie Liu"
      ],
      "abstract": "Mesh generation plays a crucial role in scientific computing. Traditional\nmesh generation methods, such as TFI and PDE-based methods, often struggle to\nachieve a balance between efficiency and mesh quality. To address this\nchallenge, physics-informed intelligent learning methods have recently emerged,\nsignificantly improving generation efficiency while maintaining high mesh\nquality. However, physics-informed methods fail to generalize when applied to\npreviously unseen geometries, as even small changes in the boundary shape\nnecessitate burdensome retraining to adapt to new geometric variations. In this\npaper, we introduce MeshONet, the first generalizable intelligent learning\nmethod for structured mesh generation. The method transforms the mesh\ngeneration task into an operator learning problem with multiple input and\nsolution functions. To effectively overcome the multivariable mapping\nrestriction of operator learning methods, we propose a dual-branch,\nshared-trunk architecture to approximate the mapping between function spaces\nbased on input-output pairs. Experimental results show that MeshONet achieves a\nspeedup of up to four orders of magnitude in generation efficiency over\ntraditional methods. It also enables generalization to different geometries\nwithout retraining, greatly enhancing the practicality of intelligent methods.",
      "tldr_zh": "本文研究了结构化网格生成在科学计算中的关键作用，指出传统方法如 TFI 和 PDE-based methods 难以兼顾效率与网格质量，而现有的物理信息智能学习方法虽提升了效率但无法泛化到新几何形状。论文提出 MeshONet，这是首个可泛化的智能学习方法，将网格生成任务转化为 operator learning 问题，使用双分支共享主干架构来处理多变量函数映射。实验结果表明，MeshONet 比传统方法生成效率提高四个数量级，并能无需重新训练即可适应不同几何形状，大大提升了智能方法的实用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.11937v2",
      "published_date": "2025-01-21 07:27:05 UTC",
      "updated_date": "2025-01-22 03:13:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:46:24.213827"
    },
    {
      "arxiv_id": "2501.11935v3",
      "title": "To Google or To ChatGPT? A Comparison of CS2 Students' Information Gathering Approaches and Outcomes",
      "title_zh": "翻译失败",
      "authors": [
        "Aayush Kumar",
        "Daniel Prol",
        "Amin Alipour",
        "Sruti Srinivasa Ragavan"
      ],
      "abstract": "LLMs such as ChatGPT have been widely adopted by students in higher education\nas tools for learning programming and related concepts. However, it remains\nunclear how effective students are and what strategies students use while\nlearning with LLMs. Since the majority of students' experiences in online\nself-learning have come through using search engines such as Google, evaluating\nAI tools in this context can help us address these gaps. In this mixed methods\nresearch, we conducted an exploratory within-subjects study to understand how\nCS2 students learn programming concepts using both LLMs as well as traditional\nonline methods such as educational websites and videos to examine how students\napproach learning within and across both scenarios. We discovered that students\nfound it easier to learn a more difficult concept using traditional methods\nthan using ChatGPT. We also found that students ask fewer follow-ups and use\nmore keyword-based queries for search engines while their prompts to LLMs tend\nto explicitly ask for information.",
      "tldr_zh": "本研究比较了 CS2 学生使用 LLMs（如 ChatGPT）和传统搜索引擎（如 Google）学习编程概念的策略和效果，旨在评估 AI 工具在在线自学中的作用。采用混合方法研究和探索性内部受试者研究，观察学生在两种场景下的学习行为，包括查询方式和后续互动。结果显示，学生更易通过传统方法（如教育网站和视频）学习困难概念，且在使用搜索引擎时提问更少、依赖关键词查询，而对 LLMs 的提示更倾向于明确请求信息。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.11935v3",
      "published_date": "2025-01-21 07:16:18 UTC",
      "updated_date": "2025-03-22 18:17:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:46:36.020471"
    },
    {
      "arxiv_id": "2501.11927v1",
      "title": "A Lightweight and Interpretable Deepfakes Detection Framework",
      "title_zh": "一种轻量级且可解释的深度伪造检测框架",
      "authors": [
        "Muhammad Umar Farooq",
        "Ali Javed",
        "Khalid Mahmood Malik",
        "Muhammad Anas Raza"
      ],
      "abstract": "The recent realistic creation and dissemination of so-called deepfakes poses\na serious threat to social life, civil rest, and law. Celebrity defaming,\nelection manipulation, and deepfakes as evidence in court of law are few\npotential consequences of deepfakes. The availability of open source trained\nmodels based on modern frameworks such as PyTorch or TensorFlow, video\nmanipulations Apps such as FaceApp and REFACE, and economical computing\ninfrastructure has easen the creation of deepfakes. Most of the existing\ndetectors focus on detecting either face-swap, lip-sync, or puppet master\ndeepfakes, but a unified framework to detect all three types of deepfakes is\nhardly explored. This paper presents a unified framework that exploits the\npower of proposed feature fusion of hybrid facial landmarks and our novel heart\nrate features for detection of all types of deepfakes. We propose novel heart\nrate features and fused them with the facial landmark features to better\nextract the facial artifacts of fake videos and natural variations available in\nthe original videos. We used these features to train a light-weight XGBoost to\nclassify between the deepfake and bonafide videos. We evaluated the performance\nof our framework on the world leaders dataset (WLDR) that contains all types of\ndeepfakes. Experimental results illustrate that the proposed framework offers\nsuperior detection performance over the comparative deepfakes detection\nmethods. Performance comparison of our framework against the LSTM-FCN, a\ncandidate of deep learning model, shows that proposed model achieves similar\nresults, however, it is more interpretable.",
      "tldr_zh": "这篇论文提出一个轻量且可解释的 deepfakes 检测框架，旨在统一检测 face-swap、lip-sync 和 puppet master 等所有类型 deepfakes，以应对其对社会和法律的潜在威胁。框架通过融合 hybrid facial landmarks 和 novel heart rate features 来提取 fake videos 的面部 artifacts 和 original videos 的自然变化，并使用 lightweight XGBoost 模型进行分类。实验结果显示，该框架在 WLDR 数据集上性能优于现有方法，与 LSTM-FCN 模型相当，但更具可解释性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.11927v1",
      "published_date": "2025-01-21 07:03:11 UTC",
      "updated_date": "2025-01-21 07:03:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:46:47.580896"
    },
    {
      "arxiv_id": "2501.11924v1",
      "title": "Make Full Use of Testing Information: An Integrated Accelerated Testing and Evaluation Method for Autonomous Driving Systems",
      "title_zh": "充分利用测试信息：一种用于自动驾驶系统的集成加速测试和评估方法",
      "authors": [
        "Xinzheng Wu",
        "Junyi Chen",
        "Jianfeng Wu",
        "Longgao Zhang",
        "Tian Xia",
        "Yong Shen"
      ],
      "abstract": "Testing and evaluation is an important step before the large-scale\napplication of the autonomous driving systems (ADSs). Based on the three level\nof scenario abstraction theory, a testing can be performed within a logical\nscenario, followed by an evaluation stage which is inputted with the testing\nresults of each concrete scenario generated from the logical parameter space.\nDuring the above process, abundant testing information is produced which is\nbeneficial for comprehensive and accurate evaluations. To make full use of\ntesting information, this paper proposes an Integrated accelerated Testing and\nEvaluation Method (ITEM). Based on a Monte Carlo Tree Search (MCTS) paradigm\nand a dual surrogates testing framework proposed in our previous work, this\npaper applies the intermediate information (i.e., the tree structure, including\nthe affiliation of each historical sampled point with the subspaces and the\nparent-child relationship between subspaces) generated during the testing stage\ninto the evaluation stage to achieve accurate hazardous domain identification.\nMoreover, to better serve this purpose, the UCB calculation method is improved\nto allow the search algorithm to focus more on the hazardous domain boundaries.\nFurther, a stopping condition is constructed based on the convergence of the\nsearch algorithm. Ablation and comparative experiments are then conducted to\nverify the effectiveness of the improvements and the superiority of the\nproposed method. The experimental results show that ITEM could well identify\nthe hazardous domains in both low- and high-dimensional cases, regardless of\nthe shape of the hazardous domains, indicating its generality and potential for\nthe safety evaluation of ADSs.",
      "tldr_zh": "本论文针对自动驾驶系统（ADSs）的测试和评估，提出了一种集成加速测试与评估方法（ITEM），旨在充分利用测试过程中生成的信息（如树结构和子空间关系）来实现危险域的精确识别。ITEM基于Monte Carlo Tree Search (MCTS)范式和双代理测试框架，通过改进UCB计算方法使算法更关注危险域边界，并构建基于搜索算法收敛的停止条件，以提升评估的准确性和效率。实验结果显示，ITEM在低维和高维场景中均能有效识别各种形状的危险域，证明了其普适性和在ADS安全评估中的潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "15 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.11924v1",
      "published_date": "2025-01-21 06:59:25 UTC",
      "updated_date": "2025-01-21 06:59:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:46:59.011033"
    },
    {
      "arxiv_id": "2501.11921v1",
      "title": "Goal-oriented Transmission Scheduling: Structure-guided DRL with a Unified Dual On-policy and Off-policy Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Jiazheng Chen",
        "Wanchun Liu"
      ],
      "abstract": "Goal-oriented communications prioritize application-driven objectives over\ndata accuracy, enabling intelligent next-generation wireless systems. Efficient\nscheduling in multi-device, multi-channel systems poses significant challenges\ndue to high-dimensional state and action spaces. We address these challenges by\nderiving key structural properties of the optimal solution to the goal-oriented\nscheduling problem, incorporating Age of Information (AoI) and channel states.\nSpecifically, we establish the monotonicity of the optimal state value function\n(a measure of long-term system performance) w.r.t. channel states and prove its\nasymptotic convexity w.r.t. AoI states. Additionally, we derive the\nmonotonicity of the optimal policy w.r.t. channel states, advancing the\ntheoretical framework for optimal scheduling. Leveraging these insights, we\npropose the structure-guided unified dual on-off policy DRL (SUDO-DRL), a\nhybrid algorithm that combines the stability of on-policy training with the\nsample efficiency of off-policy methods. Through a novel structural property\nevaluation framework, SUDO-DRL enables effective and scalable training,\naddressing the complexities of large-scale systems. Numerical results show\nSUDO-DRL improves system performance by up to 45% and reduces convergence time\nby 40% compared to state-of-the-art methods. It also effectively handles\nscheduling in much larger systems, where off-policy DRL fails and on-policy\nbenchmarks exhibit significant performance loss, demonstrating its scalability\nand efficacy in goal-oriented communications.",
      "tldr_zh": "这篇论文针对目标导向通信（Goal-oriented communications）中的传输调度问题，推导了最优解的关键结构属性，包括Age of Information (AoI) 和通道状态的单调性，以及AoI状态的渐进凸性，从而推进了理论框架。该研究提出SUDO-DRL算法，一种结合on-policy和off-policy方法的混合深度强化学习（DRL）框架，通过新型结构属性评估机制实现高效、可扩展的训练。实验结果显示，SUDO-DRL比现有方法提高系统性能高达45%，减少收敛时间40%，并在大型多设备系统中表现出显著优势。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SP",
        "eess.SY",
        "math.IT"
      ],
      "primary_category": "cs.IT",
      "comment": "Paper submitted to IEEE",
      "pdf_url": "http://arxiv.org/pdf/2501.11921v1",
      "published_date": "2025-01-21 06:49:06 UTC",
      "updated_date": "2025-01-21 06:49:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:47:11.936072"
    },
    {
      "arxiv_id": "2501.11918v1",
      "title": "LuxVeri at GenAI Detection Task 3: Cross-Domain Detection of AI-Generated Text Using Inverse Perplexity-Weighted Ensemble of Fine-Tuned Transformer Models",
      "title_zh": "翻译失败",
      "authors": [
        "Md Kamrujjaman Mobin",
        "Md Saiful Islam"
      ],
      "abstract": "This paper presents our approach for Task 3 of the GenAI content detection\nworkshop at COLING-2025, focusing on Cross-Domain Machine-Generated Text (MGT)\nDetection. We propose an ensemble of fine-tuned transformer models, enhanced by\ninverse perplexity weighting, to improve classification accuracy across diverse\ntext domains. For Subtask A (Non-Adversarial MGT Detection), we combined a\nfine-tuned RoBERTa-base model with an OpenAI detector-integrated RoBERTa-base\nmodel, achieving an aggregate TPR score of 0.826, ranking 10th out of 23\ndetectors. In Subtask B (Adversarial MGT Detection), our fine-tuned\nRoBERTa-base model achieved a TPR score of 0.801, securing 8th out of 22\ndetectors. Our results demonstrate the effectiveness of inverse\nperplexity-based weighting for enhancing generalization and performance in both\nnon-adversarial and adversarial MGT detection, highlighting the potential for\ntransformer models in cross-domain AI-generated content detection.",
      "tldr_zh": "这篇论文介绍了 LuxVeri 系统，针对 COLING-2025 GenAI 检测任务 3 的跨域 AI 生成文本检测，提出了一种使用 inverse perplexity-weighted ensemble 的 fine-tuned transformer 模型集合，以提升分类准确性。在 Subtask A (Non-Adversarial MGT Detection) 中，他们结合 fine-tuned RoBERTa-base 模型和 OpenAI detector-integrated RoBERTa-base 模型，实现了 TPR score 为 0.826 的成绩，排名 10/23。在 Subtask B (Adversarial MGT Detection) 中，fine-tuned RoBERTa-base 模型的 TPR score 为 0.801，排名 8/22，这些结果突显了 inverse perplexity-based weighting 在提高模型泛化和性能方面的有效性，为跨域 AI 生成内容检测提供了新见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.11918v1",
      "published_date": "2025-01-21 06:46:55 UTC",
      "updated_date": "2025-01-21 06:46:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:47:23.740734"
    },
    {
      "arxiv_id": "2501.11914v1",
      "title": "LuxVeri at GenAI Detection Task 1: Inverse Perplexity Weighted Ensemble for Robust Detection of AI-Generated Text across English and Multilingual Contexts",
      "title_zh": "翻译失败",
      "authors": [
        "Md Kamrujjaman Mobin",
        "Md Saiful Islam"
      ],
      "abstract": "This paper presents a system developed for Task 1 of the COLING 2025 Workshop\non Detecting AI-Generated Content, focusing on the binary classification of\nmachine-generated versus human-written text. Our approach utilizes an ensemble\nof models, with weights assigned according to each model's inverse perplexity,\nto enhance classification accuracy. For the English text detection task, we\ncombined RoBERTa-base, RoBERTa-base with the OpenAI detector, and\nBERT-base-cased, achieving a Macro F1-score of 0.7458, which ranked us 12th out\nof 35 teams. We ensembled RemBERT, XLM-RoBERTa-base, and\nBERT-base-multilingual-case for the multilingual text detection task, employing\nthe same inverse perplexity weighting technique. This resulted in a Macro\nF1-score of 0.7513, positioning us 4th out of 25 teams. Our results demonstrate\nthe effectiveness of inverse perplexity weighting in improving the robustness\nof machine-generated text detection across both monolingual and multilingual\nsettings, highlighting the potential of ensemble methods for this challenging\ntask.",
      "tldr_zh": "本论文介绍了 LuxVeri 系统，用于 COLING 2025 工作坊 Task 1 的 AI 生成文本检测，采用 Inverse Perplexity Weighted Ensemble 方法，通过根据模型的逆困惑度分配权重来提升二元分类（机器生成 vs. 人类撰写文本）的准确性。针对英语任务，该系统结合 RoBERTa-base、RoBERTa-base with OpenAI detector 和 BERT-base-cased 模型，取得了 Macro F1-score 0.7458 的成绩，排名 35 支队伍中的第 12 名。对于多语言任务，则使用 RemBERT、XLM-RoBERTa-base 和 BERT-base-multilingual-cased 模型，实现了 Macro F1-score 0.7513，排名 25 支队伍中的第 4 名。这些结果证明了 Inverse Perplexity 加权技术在单语和多语环境中提升检测鲁棒性的有效性，并突出了 Ensemble 方法在 AI 生成文本识别中的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.11914v1",
      "published_date": "2025-01-21 06:32:32 UTC",
      "updated_date": "2025-01-21 06:32:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:47:36.942903"
    },
    {
      "arxiv_id": "2501.13959v2",
      "title": "Assisting Mathematical Formalization with A Learning-based Premise Retriever",
      "title_zh": "翻译失败",
      "authors": [
        "Yicheng Tao",
        "Haotian Liu",
        "Shanwen Wang",
        "Hongteng Xu"
      ],
      "abstract": "Premise selection is a crucial yet challenging step in mathematical\nformalization, especially for users with limited experience. Due to the lack of\navailable formalization projects, existing approaches that leverage language\nmodels often suffer from data scarcity. In this work, we introduce an\ninnovative method for training a premise retriever to support the formalization\nof mathematics. Our approach employs a BERT model to embed proof states and\npremises into a shared latent space. The retrieval model is trained within a\ncontrastive learning framework and incorporates a domain-specific tokenizer\nalong with a fine-grained similarity computation method. Experimental results\nshow that our model is highly competitive compared to existing baselines,\nachieving strong performance while requiring fewer computational resources.\nPerformance is further enhanced through the integration of a re-ranking module.\nTo streamline the formalization process, we will release a search engine that\nenables users to query Mathlib theorems directly using proof states,\nsignificantly improving accessibility and efficiency. Codes are available at\nhttps://github.com/ruc-ai4math/Premise-Retrieval.",
      "tldr_zh": "该论文针对数学形式化中的前提选择（Premise selection）问题，提出了一种基于学习的检索器，以帮助经验不足的用户。该方法使用BERT模型将证明状态（proof states）和前提（premises）嵌入共享潜在空间，并通过对比学习（contrastive learning）框架结合领域特定标记器（domain-specific tokenizer）和细粒度相似性计算方法进行训练。实验结果显示，该模型在性能上优于现有基线，同时消耗更少计算资源，并通过重新排序模块（re-ranking module）进一步提升效果。该系统将发布一个搜索引擎，允许用户直接使用证明状态查询Mathlib定理，提高数学形式化的可访问性和效率。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13959v2",
      "published_date": "2025-01-21 06:32:25 UTC",
      "updated_date": "2025-03-06 13:51:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:47:49.534395"
    },
    {
      "arxiv_id": "2501.13958v1",
      "title": "A Survey of Graph Retrieval-Augmented Generation for Customized Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Qinggang Zhang",
        "Shengyuan Chen",
        "Yuanchen Bei",
        "Zheng Yuan",
        "Huachi Zhou",
        "Zijin Hong",
        "Junnan Dong",
        "Hao Chen",
        "Yi Chang",
        "Xiao Huang"
      ],
      "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in a\nwide range of tasks, yet their application to specialized domains remains\nchallenging due to the need for deep expertise. Retrieval-augmented generation\n(RAG) has emerged as a promising solution to customize LLMs for professional\nfields by seamlessly integrating external knowledge bases, enabling real-time\naccess to domain-specific expertise during inference. Despite its potential,\ntraditional RAG systems, based on flat text retrieval, face three critical\nchallenges: (i) complex query understanding in professional contexts, (ii)\ndifficulties in knowledge integration across distributed sources, and (iii)\nsystem efficiency bottlenecks at scale. This survey presents a systematic\nanalysis of Graph-based Retrieval-Augmented Generation (GraphRAG), a new\nparadigm that revolutionizes domain-specific LLM applications. GraphRAG\naddresses traditional RAG limitations through three key innovations: (i)\ngraph-structured knowledge representation that explicitly captures entity\nrelationships and domain hierarchies, (ii) efficient graph-based retrieval\ntechniques that enable context-preserving knowledge retrieval with multihop\nreasoning ability, and (iii) structure-aware knowledge integration algorithms\nthat leverage retrieved knowledge for accurate and logical coherent generation\nof LLMs. In this survey, we systematically analyze the technical foundations of\nGraphRAG and examine current implementations across various professional\ndomains, identifying key technical challenges and promising research\ndirections. All the related resources of GraphRAG, including research papers,\nopen-source data, and projects, are collected for the community in\n\\textcolor{blue}{\\url{https://github.com/DEEP-PolyU/Awesome-GraphRAG}}.",
      "tldr_zh": "这篇调查论文探讨了Graph Retrieval-Augmented Generation (GraphRAG)，一种针对定制化Large Language Models (LLMs)的创新框架，用于解决传统Retrieval-Augmented Generation (RAG)系统在专业领域面临的复杂查询理解、知识整合困难和效率瓶颈问题。GraphRAG通过图结构知识表示捕捉实体关系和领域层次、采用高效图-based 检索支持多跳推理，以及使用结构感知算法实现准确的知识整合，从而提升LLMs在专业领域的性能。论文系统分析了GraphRAG的技术基础、当前应用、关键挑战和未来研究方向，并提供了相关资源集合（如论文、数据和开源项目）。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13958v1",
      "published_date": "2025-01-21 06:25:21 UTC",
      "updated_date": "2025-01-21 06:25:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:48:00.176884"
    },
    {
      "arxiv_id": "2501.11909v1",
      "title": "Bridging the Communication Gap: Evaluating AI Labeling Practices for Trustworthy AI Development",
      "title_zh": "弥合沟通鸿沟：评估 AI 标签实践以实现可信赖的 AI 开发",
      "authors": [
        "Raphael Fischer",
        "Magdalena Wischnewski",
        "Alexander van der Staay",
        "Katharina Poitz",
        "Christian Janiesch",
        "Thomas Liebig"
      ],
      "abstract": "As artificial intelligence (AI) becomes integral to economy and society,\ncommunication gaps between developers, users, and stakeholders hinder trust and\ninformed decision-making. High-level AI labels, inspired by frameworks like EU\nenergy labels, have been proposed to make the properties of AI models more\ntransparent. Without requiring deep technical expertise, they can inform on the\ntrade-off between predictive performance and resource efficiency. However, the\npractical benefits and limitations of AI labeling remain underexplored. This\nstudy evaluates AI labeling through qualitative interviews along four key\nresearch questions. Based on thematic analysis and inductive coding, we found a\nbroad range of practitioners to be interested in AI labeling (RQ1). They see\nbenefits for alleviating communication gaps and aiding non-expert\ndecision-makers, however limitations, misunderstandings, and suggestions for\nimprovement were also discussed (RQ2). Compared to other reporting formats,\ninterviewees positively evaluated the reduced complexity of labels, increasing\noverall comprehensibility (RQ3). Trust was influenced most by usability and the\ncredibility of the responsible labeling authority, with mixed preferences for\nself-certification versus third-party certification (RQ4). Our Insights\nhighlight that AI labels pose a trade-off between simplicity and complexity,\nwhich could be resolved by developing customizable and interactive labeling\nframeworks to address diverse user needs. Transparent labeling of resource\nefficiency also nudged interviewee priorities towards paying more attention to\nsustainability aspects during AI development. This study validates AI labels as\na valuable tool for enhancing trust and communication in AI, offering\nactionable guidelines for their refinement and standardization.",
      "tldr_zh": "这篇论文评估了 AI 标签在提升可信赖 AI 开发中的作用，旨在桥接开发者和用户之间的沟通差距，通过高水平标签（如 EU 能源标签）透明化 AI 模型的性能和资源效率权衡。研究采用定性访谈和主题分析，针对四个关键研究问题（RQ1-4）发现：从业者对 AI 标签感兴趣，能缓解沟通障碍并提高可理解性，但也存在局限性，如信任依赖于标签权威和可用性。最终，论文强调 AI 标签作为增强信任和可持续性的工具，提供可定制交互框架的行动指南，以平衡简单性和复杂性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.11909v1",
      "published_date": "2025-01-21 06:00:14 UTC",
      "updated_date": "2025-01-21 06:00:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:48:12.707187"
    },
    {
      "arxiv_id": "2501.13124v1",
      "title": "Debate Helps Weak-to-Strong Generalization",
      "title_zh": "辩论有助于弱到强泛化",
      "authors": [
        "Hao Lang",
        "Fei Huang",
        "Yongbin Li"
      ],
      "abstract": "Common methods for aligning already-capable models with desired behavior rely\non the ability of humans to provide supervision. However, future superhuman\nmodels will surpass the capability of humans. Therefore, humans will only be\nable to weakly supervise superhuman models. This expected deficiency of human\nevaluation would weaken the safety of future AI systems. Scalable oversight and\nweak-to-strong generalization are two complementary approaches to tackle this\nissue. In this paper, we attempt to combine the strengths of these two\napproaches to further improve alignment. Specifically, we investigate ways of\nimproving human supervision with a strong pretrained model and then supervise\nthe strong model with enhanced weak human supervision. To make iterative\nempirical progress, we consider an analogy: can we use a strong model to\nimprove weak model supervision and then use it to supervise the strong model?\nWe empirically test it by finetuning a small weak model on ground truth labels\nwith the additional help from a large strong model, and then finetuning the\nstrong model on labels generated by the weak model. We find that debate can\nassist a weak model in extracting trustworthy information from an untrustworthy\nstrong model, which provides leverage as context on samples when training a\nweak model. We also show that an ensemble of weak models helps exploit long\narguments generated by strong model debaters and obtain a more robust\nsupervision estimate. Extensive experiments on the OpenAI weak-to-strong NLP\nbenchmarks show that the combination approach leads to better alignment, which\nindicates that debate has the potential to help weak-to-strong generalization.",
      "tldr_zh": "本文探讨了在人类监督有限的情况下，如何通过辩论（debate）机制提升弱到强泛化（weak-to-strong generalization），以改善未来超人类模型的安全性。研究结合可扩展监督（scalable oversight）和弱到强方法，使用强模型辅助弱模型从不信任的强模型中提取可信信息，并通过弱模型集成处理长论证以增强监督。实验在 OpenAI 的弱到强 NLP 基准上表明，这种组合方法显著提高了模型 alignment，证明辩论有助于更有效的弱监督过程。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "AAAI2025 Special Track on AI Alignment (Oral presentation)",
      "pdf_url": "http://arxiv.org/pdf/2501.13124v1",
      "published_date": "2025-01-21 05:36:13 UTC",
      "updated_date": "2025-01-21 05:36:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:48:24.080708"
    },
    {
      "arxiv_id": "2501.11900v2",
      "title": "Panoramic Interests: Stylistic-Content Aware Personalized Headline Generation",
      "title_zh": "全景兴趣：风格-内容感知的个性化标题生成",
      "authors": [
        "Junhong Lian",
        "Xiang Ao",
        "Xinyu Liu",
        "Yang Liu",
        "Qing He"
      ],
      "abstract": "Personalized news headline generation aims to provide users with\nattention-grabbing headlines that are tailored to their preferences. Prevailing\nmethods focus on user-oriented content preferences, but most of them overlook\nthe fact that diverse stylistic preferences are integral to users' panoramic\ninterests, leading to suboptimal personalization. In view of this, we propose a\nnovel Stylistic-Content Aware Personalized Headline Generation (SCAPE)\nframework. SCAPE extracts both content and stylistic features from headlines\nwith the aid of large language model (LLM) collaboration. It further adaptively\nintegrates users' long- and short-term interests through a contrastive\nlearning-based hierarchical fusion network. By incorporating the panoramic\ninterests into the headline generator, SCAPE reflects users' stylistic-content\npreferences during the generation process. Extensive experiments on the\nreal-world dataset PENS demonstrate the superiority of SCAPE over baselines.",
      "tldr_zh": "该论文针对个性化新闻标题生成问题，提出了一种新的框架 Stylistic-Content Aware Personalized Headline Generation (SCAPE)，它同时考虑用户的风格和内容偏好，以弥补现有方法忽略风格因素导致的个性化不足。SCAPE 通过大型语言模型 (LLM) 提取标题的风格和内容特征，并采用对比学习-based hierarchical fusion network 适应性地融合用户的长期和短期兴趣，从而在生成过程中融入全景兴趣 (panoramic interests)。实验结果在真实数据集 PENS 上表明，SCAPE 优于基线方法，提供更吸引人的个性化标题。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to The ACM Web Conference 2025 (WWW'25, short paper)",
      "pdf_url": "http://arxiv.org/pdf/2501.11900v2",
      "published_date": "2025-01-21 05:30:20 UTC",
      "updated_date": "2025-01-28 04:04:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:48:35.778550"
    },
    {
      "arxiv_id": "2501.11896v2",
      "title": "Systematic Abductive Reasoning via Diverse Relation Representations in Vector-symbolic Architecture",
      "title_zh": "翻译失败",
      "authors": [
        "Zhong-Hua Sun",
        "Ru-Yuan Zhang",
        "Zonglei Zhen",
        "Da-Hui Wang",
        "Yong-Jie Li",
        "Xiaohong Wan",
        "Hongzhi You"
      ],
      "abstract": "In abstract visual reasoning, monolithic deep learning models suffer from\nlimited interpretability and generalization, while existing neuro-symbolic\napproaches fall short in capturing the diversity and systematicity of\nattributes and relation representations. To address these challenges, we\npropose a Systematic Abductive Reasoning model with diverse relation\nrepresentations (Rel-SAR) in Vector-symbolic Architecture (VSA) to solve\nRaven's Progressive Matrices (RPM). To derive attribute representations with\nsymbolic reasoning potential, we introduce not only various types of atomic\nvectors that represent numeric, periodic and logical semantics, but also the\nstructured high-dimentional representation (SHDR) for the overall Grid\ncomponent. For systematic reasoning, we propose novel numerical and logical\nrelation functions and perform rule abduction and execution in a unified\nframework that integrates these relation representations. Experimental results\ndemonstrate that Rel-SAR achieves significant improvement on RPM tasks and\nexhibits robust out-of-distribution generalization. Rel-SAR leverages the\nsynergy between HD attribute representations and symbolic reasoning to achieve\nsystematic abductive reasoning with both interpretable and computable\nsemantics.",
      "tldr_zh": "本研究针对抽象视觉推理中深度学习模型的可解释性和泛化性不足问题，提出Rel-SAR模型，利用Vector-symbolic Architecture (VSA)来解决Raven's Progressive Matrices (RPM)。该模型引入多样化的关系表示，包括各种原子向量（如数值、周期和逻辑语义）和Structured High-Dimensional Representation (SHDR)，并开发新的数值和逻辑关系函数，在统一框架中进行规则推断和执行。实验结果显示，Rel-SAR在RPM任务上显著提升性能，并展现出强大的分布外泛化能力，实现了可解释且可计算的系统性Abductive Reasoning。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.11896v2",
      "published_date": "2025-01-21 05:17:08 UTC",
      "updated_date": "2025-01-22 03:23:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:48:48.569171"
    },
    {
      "arxiv_id": "2501.17881v1",
      "title": "RayLoc: Wireless Indoor Localization via Fully Differentiable Ray-tracing",
      "title_zh": "翻译失败",
      "authors": [
        "Xueqiang Han",
        "Tianyue Zheng",
        "Tony Xiao Han",
        "Jun Luo"
      ],
      "abstract": "Wireless indoor localization has been a pivotal area of research over the\nlast two decades, becoming a cornerstone for numerous sensing applications.\nHowever, conventional wireless localization methods rely on channel state\ninformation to perform blind modelling and estimation of a limited set of\nlocalization parameters. This oversimplification neglects many sensing scene\ndetails, resulting in suboptimal localization accuracy. To address this\nlimitation, this paper presents a novel approach to wireless indoor\nlocalization by reformulating it as an inverse problem of wireless ray-tracing,\ninferring scene parameters that generates the measured CSI. At the core of our\nsolution is a fully differentiable ray-tracing simulator that enables\nbackpropagation to comprehensive parameters of the sensing scene, allowing for\nprecise localization. To establish a robust localization context, RayLoc\nconstructs a high-fidelity sensing scene by refining coarse-grained background\nmodel. Furthermore, RayLoc overcomes the challenges of sparse gradient and\nlocal minima by convolving the signal generation process with a Gaussian\nkernel. Extensive experiments showcase that RayLoc outperforms traditional\nlocalization baselines and is able to generalize to different sensing\nenvironments.",
      "tldr_zh": "本论文提出 RayLoc，一种创新的无线室内定位方法，将问题重新表述为无线射线追踪的逆问题，通过 fully differentiable ray-tracing 模拟器实现对场景参数的精确推断。RayLoc 通过优化粗糙的背景模型构建高保真度感知场景，并使用高斯核来解决稀疏梯度和局部最小值挑战，从而提升定位准确性。实验结果显示，RayLoc 优于传统依赖 channel state information (CSI) 的基线方法，并在不同感知环境中具有良好的泛化能力。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG",
        "cs.NI"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.17881v1",
      "published_date": "2025-01-21 04:24:36 UTC",
      "updated_date": "2025-01-21 04:24:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:48:59.799554"
    },
    {
      "arxiv_id": "2501.11880v1",
      "title": "Community-Aware Temporal Walks: Parameter-Free Representation Learning on Continuous-Time Dynamic Graphs",
      "title_zh": "社区感知时间游走：连续时间动态图的无参数",
      "authors": [
        "He Yu",
        "Jing Liu"
      ],
      "abstract": "Dynamic graph representation learning plays a crucial role in understanding\nevolving behaviors. However, existing methods often struggle with flexibility,\nadaptability, and the preservation of temporal and structural dynamics. To\naddress these issues, we propose Community-aware Temporal Walks (CTWalks), a\nnovel framework for representation learning on continuous-time dynamic graphs.\nCTWalks integrates three key components: a community-based parameter-free\ntemporal walk sampling mechanism, an anonymization strategy enriched with\ncommunity labels, and an encoding process that leverages continuous temporal\ndynamics modeled via ordinary differential equations (ODEs). This design\nenables precise modeling of both intra- and inter-community interactions,\noffering a fine-grained representation of evolving temporal patterns in\ncontinuous-time dynamic graphs. CTWalks theoretically overcomes locality bias\nin walks and establishes its connection to matrix factorization. Experiments on\nbenchmark datasets demonstrate that CTWalks outperforms established methods in\ntemporal link prediction tasks, achieving higher accuracy while maintaining\nrobustness.",
      "tldr_zh": "本文提出了一种名为 CTWalks 的框架，用于连续时间动态图的表示学习，以解决现有方法在灵活性、适应性和时间结构动态保留方面的不足。CTWalks 整合了基于社区的免参数时间游走采样机制、带有社区标签的匿名化策略，以及利用 ordinary differential equations (ODEs) 建模连续时间动态的编码过程，从而精确捕捉社区内和社区间的互动。实验结果显示，CTWalks 在基准数据集上的时间链接预测任务中，超越了现有方法，实现了更高的准确率和鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.11880v1",
      "published_date": "2025-01-21 04:16:46 UTC",
      "updated_date": "2025-01-21 04:16:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:49:12.492107"
    },
    {
      "arxiv_id": "2501.11877v1",
      "title": "From Drafts to Answers: Unlocking LLM Potential via Aggregation Fine-Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Yafu Li",
        "Zhilin Wang",
        "Tingchen Fu",
        "Ganqu Cui",
        "Sen Yang",
        "Yu Cheng"
      ],
      "abstract": "Scaling data and model size has been proven effective for boosting the\nperformance of large language models. In addition to training-time scaling,\nrecent studies have revealed that increasing test-time computational resources\ncan further improve performance. In this work, we introduce Aggregation\nFine-Tuning (AFT), a supervised finetuning paradigm where the model learns to\nsynthesize multiple draft responses, referred to as proposals, into a single,\nrefined answer, termed aggregation. At inference time, a propose-and-aggregate\nstrategy further boosts performance by iteratively generating proposals and\naggregating them. Empirical evaluations on benchmark datasets show that\nAFT-trained models substantially outperform standard SFT. Notably, an AFT\nmodel, fine-tuned from Llama3.1-8B-Base with only 64k data, achieves a 41.3% LC\nwin rate on AlpacaEval 2, surpassing significantly larger LLMs such as\nLlama3.1-405B-Instruct and GPT4. By combining sequential refinement and\nparallel sampling, the propose-and-aggregate framework scales inference-time\ncomputation in a flexible manner. Overall, These findings position AFT as a\npromising approach to unlocking additional capabilities of LLMs without\nresorting to increasing data volume or model size.",
      "tldr_zh": "本文提出 Aggregation Fine-Tuning (AFT)，一种监督微调方法，让大型语言模型 (LLMs) 学习将多个草稿响应（proposals）合成一个精炼答案（aggregation），从而提升模型性能。AFT 在推理时采用 propose-and-aggregate 策略，通过迭代生成和聚合 proposals，实现灵活的计算资源扩展。实验结果显示，AFT 训练的模型显著优于标准 Supervised Fine-Tuning (SFT)，例如从 Llama3.1-8B-Base 微调的模型仅用 64k 数据，在 AlpacaEval 2 上达到 41.3% LC 胜率，超越了更大模型如 Llama3.1-405B-Instruct 和 GPT4。该方法无需增加数据量或模型规模，即可解锁 LLMs 的额外潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "20 pages; work in progress",
      "pdf_url": "http://arxiv.org/pdf/2501.11877v1",
      "published_date": "2025-01-21 04:11:59 UTC",
      "updated_date": "2025-01-21 04:11:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:49:26.120750"
    },
    {
      "arxiv_id": "2501.13957v2",
      "title": "Benchmarking Generative AI for Scoring Medical Student Interviews in Objective Structured Clinical Examinations (OSCEs)",
      "title_zh": "翻译失败",
      "authors": [
        "Jadon Geathers",
        "Yann Hicke",
        "Colleen Chan",
        "Niroop Rajashekar",
        "Justin Sewell",
        "Susannah Cornes",
        "Rene F. Kizilcec",
        "Dennis Shung"
      ],
      "abstract": "Objective Structured Clinical Examinations (OSCEs) are widely used to assess\nmedical students' communication skills, but scoring interview-based assessments\nis time-consuming and potentially subject to human bias. This study explored\nthe potential of large language models (LLMs) to automate OSCE evaluations\nusing the Master Interview Rating Scale (MIRS). We compared the performance of\nfour state-of-the-art LLMs (GPT-4o, Claude 3.5, Llama 3.1, and Gemini 1.5 Pro)\nin evaluating OSCE transcripts across all 28 items of the MIRS under the\nconditions of zero-shot, chain-of-thought (CoT), few-shot, and multi-step\nprompting. The models were benchmarked against a dataset of 10 OSCE cases with\n174 expert consensus scores available. Model performance was measured using\nthree accuracy metrics (exact, off-by-one, thresholded). Averaging across all\nMIRS items and OSCE cases, LLMs performed with low exact accuracy (0.27 to\n0.44), and moderate to high off-by-one accuracy (0.67 to 0.87) and thresholded\naccuracy (0.75 to 0.88). A zero temperature parameter ensured high intra-rater\nreliability ({\\alpha} = 0.98 for GPT-4o). CoT, few-shot, and multi-step\ntechniques proved valuable when tailored to specific assessment items. The\nperformance was consistent across MIRS items, independent of encounter phases\nand communication domains. We demonstrated the feasibility of AI-assisted OSCE\nevaluation and provided benchmarking of multiple LLMs across multiple prompt\ntechniques. Our work provides a baseline performance assessment for LLMs that\nlays a foundation for future research into automated assessment of clinical\ncommunication skills.",
      "tldr_zh": "本研究评估了大型语言模型 (LLMs) 在 Objective Structured Clinical Examinations (OSCEs) 中自动评分医学生面试的潜力，使用 Master Interview Rating Scale (MIRS) 的28个项目作为标准。研究比较了GPT-4o、Claude 3.5、Llama 3.1和Gemini 1.5 Pro在zero-shot、chain-of-thought (CoT)、few-shot和multi-step prompting条件下的表现，并以10个OSCE案例的174个专家共识分数为基准。结果显示，LLMs的精确准确率较低（0.27-0.44），但误差一格准确率（0.67-0.87）和阈值准确率（0.75-0.88）较高，且不同提示技术可针对特定项目优化性能。该工作证明了AI辅助OSCE评估的可行性，并为未来临床沟通技能自动评估研究提供了基准性能基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages + 3 pages of references, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.13957v2",
      "published_date": "2025-01-21 04:05:45 UTC",
      "updated_date": "2025-05-15 17:09:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:49:38.965250"
    },
    {
      "arxiv_id": "2501.11870v2",
      "title": "Coarse-to-Fine Lightweight Meta-Embedding for ID-Based Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Wang",
        "Haipeng Liu",
        "Zeqian Yi",
        "Biao Qian",
        "Meng Wang"
      ],
      "abstract": "The state-of-the-art recommendation systems have shifted the attention to\nefficient recommendation, e.g., on-device recommendation, under memory\nconstraints. To this end, the existing methods either focused on the\nlightweight embeddings for both users and items, or involved on-device systems\nenjoying the compact embeddings to enhance reusability and reduces space\ncomplexity. However, they focus solely on the coarse granularity of embedding,\nwhile overlook the fine-grained semantic nuances, to adversarially downgrade\nthe efficacy of meta-embeddings in capturing the intricate relationship over\nboth user and item, consequently resulting into the suboptimal recommendations.\nIn this paper, we aim to study how the meta-embedding can efficiently learn\nvaried grained semantics, together with how the fine-grained meta-embedding can\nstrengthen the representation of coarse-grained meta-embedding. To answer these\nquestions, we develop a novel graph neural networks (GNNs) based recommender\nwhere each user and item serves as the node, linked directly to coarse-grained\nvirtual nodes and indirectly to fine-grained virtual nodes, ensuring different\ngrained semantic learning, while disclosing: 1) In contrast to coarse-grained\nsemantics, fine-grained semantics are well captured through sparse\nmeta-embeddings, which adaptively 2) balance the embedding uniqueness and\nmemory constraint. Additionally, the initialization method come up upon\nSparsePCA, along with a soft thresholding activation function to render the\nsparseness of the meta-embeddings. We propose a weight bridging update strategy\nthat focuses on matching each coarse-grained meta-embedding with several\nfine-grained meta-embeddings based on the users/items' semantics. Extensive\nexperiments substantiate our method's superiority over existing baselines. Our\ncode is available at https://github.com/htyjers/C2F-MetaEmbed.",
      "tldr_zh": "本论文针对ID-Based Recommendation中的内存约束问题，指出现有方法仅关注粗粒度嵌入而忽略细粒度语义，导致推荐效果 suboptimal。作者提出一种Coarse-to-Fine Lightweight Meta-Embedding框架，利用图神经网络(GNNs)构建用户和物品节点，直接连接粗粒度虚拟节点并间接连接细粒度虚拟节点，以实现不同粒度语义的学习。框架通过SparsePCA初始化和软阈值激活函数生成稀疏meta-embeddings，平衡嵌入的唯一性和内存限制，并采用weight bridging update策略将粗粒度meta-embedding与多个细粒度meta-embedding匹配。实验结果显示，该方法在多个基准上优于现有基线，证明了其在高效推荐中的有效性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "16 pages, 6 figures, accepted to appear at Science China Information\n  Sciences",
      "pdf_url": "http://arxiv.org/pdf/2501.11870v2",
      "published_date": "2025-01-21 03:56:23 UTC",
      "updated_date": "2025-03-19 01:12:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:49:49.921979"
    },
    {
      "arxiv_id": "2501.13122v1",
      "title": "Zero-Shot Verification-guided Chain of Thoughts",
      "title_zh": "翻译失败",
      "authors": [
        "Jishnu Ray Chowdhury",
        "Cornelia Caragea"
      ],
      "abstract": "Previous works have demonstrated the effectiveness of Chain-of-Thought (COT)\nprompts and verifiers in guiding Large Language Models (LLMs) through the space\nof reasoning. However, most such studies either use a fine-tuned verifier or\nrely on manually handcrafted few-shot examples. In contrast, in this paper, we\nfocus on LLM-based self-verification of self-generated reasoning steps via COT\nprompts in a completely zero-shot regime. To explore this setting, we design a\nnew zero-shot prompt, which we call COT STEP, to aid zero-shot decomposition of\nreasoning steps and design two new zero-shot prompts for LLM-based verifiers.\nWe evaluate the verifiers' ability to classify the correctness of reasoning\nchains and explore different ways to use verifier scores in guiding reasoning\nfor various mathematical and commonsense reasoning tasks with different LLMs.",
      "tldr_zh": "本研究专注于在零样本(zero-shot)设置下，使用大型语言模型(LLMs)进行Chain-of-Thought (COT)推理的自我验证，旨在避免依赖微调验证器或手动样本。作者设计了COT STEP提示来分解推理步骤，并创建了两个新的零样本提示，用于LLM-based验证器评估推理链的正确性。实验探索了不同方式利用验证器分数指导数学和常识推理任务，结果显示该方法提升了LLMs的推理可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13122v1",
      "published_date": "2025-01-21 03:52:54 UTC",
      "updated_date": "2025-01-21 03:52:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:50:00.258249"
    },
    {
      "arxiv_id": "2501.11849v3",
      "title": "Network-informed Prompt Engineering against Organized Astroturf Campaigns under Extreme Class Imbalance",
      "title_zh": "翻译失败",
      "authors": [
        "Nikos Kanakaris",
        "Heng Ping",
        "Xiongye Xiao",
        "Nesreen K. Ahmed",
        "Luca Luceri",
        "Emilio Ferrara",
        "Paul Bogdan"
      ],
      "abstract": "Detecting organized political campaigns is of paramount importance in\nfighting against disinformation on social media. Existing approaches for the\nidentification of such organized actions employ techniques mostly from network\nscience, graph machine learning and natural language processing. Their ultimate\ngoal is to analyze the relationships and interactions (e.g. re-posting) among\nusers and the textual similarities of their posts. Despite their effectiveness\nin recognizing astroturf campaigns, these methods face significant challenges,\nnotably the class imbalance in available training datasets. To mitigate this\nissue, recent methods usually resort to data augmentation or increasing the\nnumber of positive samples, which may not always be feasible or sufficient in\nreal-world settings. Following a different path, in this paper, we propose a\nnovel framework for identifying astroturf campaigns based solely on large\nlanguage models (LLMs), introducing a Balanced Retrieval-Augmented Generation\n(Balanced RAG) component. Our approach first gives both textual information\nconcerning the posts (in our case tweets) and the user interactions of the\nsocial network as input to a language model. Then, through prompt engineering\nand the proposed Balanced RAG method, it effectively detects coordinated\ndisinformation campaigns on X (Twitter). The proposed framework does not\nrequire any training or fine-tuning of the language model. Instead, by\nstrategically harnessing the strengths of prompt engineering and Balanced RAG,\nit facilitates LLMs to overcome the effects of class imbalance and effectively\nidentify coordinated political campaigns. The experimental results demonstrate\nthat by incorporating the proposed prompt engineering and Balanced RAG methods,\nour framework outperforms the traditional graph-based baselines, achieving\n2x-3x improvements in terms of precision, recall and F1 scores.",
      "tldr_zh": "该研究针对社交媒体上组织化astroturf campaigns的检测问题，提出了一种基于大型语言模型(LLMs)的框架，以应对极端类别不平衡的挑战。该框架通过network-informed prompt engineering和Balanced Retrieval-Augmented Generation(Balanced RAG)方法，将推文文本和用户互动信息作为输入，实现无需训练或微调LLM的协调虚假宣传识别。实验结果表明，该方法在精确率、召回率和F1分数上比传统图-based基线提高了2x-3x，为高效的反 disinformation 策略提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.11849v3",
      "published_date": "2025-01-21 03:07:21 UTC",
      "updated_date": "2025-02-18 03:18:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:50:12.083159"
    },
    {
      "arxiv_id": "2501.11847v1",
      "title": "A Survey on Memory-Efficient Large-Scale Model Training in AI for Science",
      "title_zh": "翻译失败",
      "authors": [
        "Kaiyuan Tian",
        "Linbo Qiao",
        "Baihui Liu",
        "Gongqingjian Jiang",
        "Dongsheng Li"
      ],
      "abstract": "Scientific research faces high costs and inefficiencies with traditional\nmethods, but the rise of deep learning and large language models (LLMs) offers\ninnovative solutions. This survey reviews LLM applications across scientific\nfields such as biology, medicine, chemistry, and meteorology, underscoring\ntheir role in advancing research. However, the continuous expansion of model\nsize has led to significant memory demands, hindering further development and\napplication of LLMs for science. To address this, we review memory-efficient\ntraining techniques for LLMs based on the transformer architecture, including\ndistributed training, mixed precision training, and gradient checkpointing.\nUsing AlphaFold 2 as an example, we demonstrate how tailored memory\noptimization methods can reduce storage needs while preserving prediction\naccuracy. We also discuss the challenges of memory optimization in practice and\npotential future directions, hoping to provide valuable insights for\nresearchers and engineers.",
      "tldr_zh": "这篇调查论文探讨了深度学习和大型语言模型（LLMs）在科学领域（如生物、医学、化学和气象学）的应用及其潜力，同时强调了模型规模扩张带来的高内存需求问题。论文回顾了基于 Transformer 架构的内存高效训练技术，包括分布式训练、混合精度训练和梯度检查点，以降低存储需求并保持预测准确性；例如，通过优化 AlphaFold 2，展示了这些方法如何有效减少资源消耗。最终，论文讨论了实际挑战和未来方向，为研究人员和工程师提供优化 LLMs 在科学应用的宝贵见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.11847v1",
      "published_date": "2025-01-21 03:06:30 UTC",
      "updated_date": "2025-01-21 03:06:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:50:23.111611"
    },
    {
      "arxiv_id": "2501.11839v1",
      "title": "Supervised Learning for Analog and RF Circuit Design: Benchmarks and Comparative Insights",
      "title_zh": "监督学习在模拟和射频电路设计中的应用：基准测试和比较见解",
      "authors": [
        "Asal Mehradfar",
        "Xuzhe Zhao",
        "Yue Niu",
        "Sara Babakniya",
        "Mahdi Alesheikh",
        "Hamidreza Aghasi",
        "Salman Avestimehr"
      ],
      "abstract": "Automating analog and radio-frequency (RF) circuit design using machine\nlearning (ML) significantly reduces the time and effort required for parameter\noptimization. This study explores supervised ML-based approaches for designing\ncircuit parameters from performance specifications across various circuit\ntypes, including homogeneous and heterogeneous designs. By evaluating diverse\nML models, from neural networks like transformers to traditional methods like\nrandom forests, we identify the best-performing models for each circuit. Our\nresults show that simpler circuits, such as low-noise amplifiers, achieve\nexceptional accuracy with mean relative errors as low as 0.3% due to their\nlinear parameter-performance relationships. In contrast, complex circuits, like\npower amplifiers and voltage-controlled oscillators, present challenges due to\ntheir non-linear interactions and larger design spaces. For heterogeneous\ncircuits, our approach achieves an 88% reduction in errors with increased\ntraining data, with the receiver achieving a mean relative error as low as\n0.23%, showcasing the scalability and accuracy of the proposed methodology.\nAdditionally, we provide insights into model strengths, with transformers\nexcelling in capturing non-linear mappings and k-nearest neighbors performing\nrobustly in moderately linear parameter spaces, especially in heterogeneous\ncircuits with larger datasets. This work establishes a foundation for extending\nML-driven design automation, enabling more efficient and scalable circuit\ndesign workflows.",
      "tldr_zh": "这篇论文探讨了使用监督机器学习（supervised learning）自动化模拟和射频（RF）电路设计的参数优化过程，通过评估多种模型（如transformer、随机森林和k-nearest neighbors）来处理同质和异质电路。研究发现，简单电路如低噪声放大器可实现平均相对误差低至0.3%，而复杂电路如功率放大器则因非线性交互面临挑战，但通过增加训练数据，异质电路错误可减少88%。总体上，论文比较了模型优势，并为ML驱动的电路设计自动化奠定了高效、可扩展的基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.11839v1",
      "published_date": "2025-01-21 02:48:23 UTC",
      "updated_date": "2025-01-21 02:48:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:50:37.265768"
    },
    {
      "arxiv_id": "2501.11836v1",
      "title": "Data-driven Detection and Evaluation of Damages in Concrete Structures: Using Deep Learning and Computer Vision",
      "title_zh": "翻译失败",
      "authors": [
        "Saeid Ataei",
        "Saeed Adibnazari",
        "Seyyed Taghi Ataei"
      ],
      "abstract": "Structural integrity is vital for maintaining the safety and longevity of\nconcrete infrastructures such as bridges, tunnels, and walls. Traditional\nmethods for detecting damages like cracks and spalls are labor-intensive,\ntime-consuming, and prone to human error. To address these challenges, this\nstudy explores advanced data-driven techniques using deep learning for\nautomated damage detection and analysis. Two state-of-the-art instance\nsegmentation models, YOLO-v7 instance segmentation and Mask R-CNN, were\nevaluated using a dataset comprising 400 images, augmented to 10,995 images\nthrough geometric and color-based transformations to enhance robustness. The\nmodels were trained and validated using a dataset split into 90% training set,\nvalidation and test set 10%. Performance metrics such as precision, recall,\nmean average precision (mAP@0.5), and frames per second (FPS) were used for\nevaluation. YOLO-v7 achieved a superior mAP@0.5 of 96.1% and processed 40 FPS,\noutperforming Mask R-CNN, which achieved a mAP@0.5 of 92.1% with a slower\nprocessing speed of 18 FPS. The findings recommend YOLO-v7 instance\nsegmentation model for real-time, high-speed structural health monitoring,\nwhile Mask R-CNN is better suited for detailed offline assessments. This study\ndemonstrates the potential of deep learning to revolutionize infrastructure\nmaintenance, offering a scalable and efficient solution for automated damage\ndetection.",
      "tldr_zh": "这篇论文探讨了使用深度学习和计算机视觉自动检测混凝土结构损坏（如裂缝和剥落），以克服传统方法的劳动密集和易出错问题。研究评估了 YOLO-v7 和 Mask R-CNN 两个实例分割模型，在一个由 400 张图像增强至 10,995 张的数据集上进行训练（90% 训练集，10% 验证和测试集）。结果显示，YOLO-v7 取得了更高的 mAP@0.5（96.1%）和 FPS（40），优于 Mask R-CNN 的 mAP@0.5（92.1%）和 FPS（18），因此推荐 YOLO-v7 用于实时结构健康监测，而 Mask R-CNN 更适合详细离线评估。该研究展示了深度学习在基础设施维护中的潜力，提供了一个可扩展的自动化解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "68A00 (Primary), 68C02 (Secondary)"
      ],
      "primary_category": "cs.CV",
      "comment": "17 pages, 10 figures. This study focuses on the data-driven detection\n  and evaluation of damages in concrete structures using deep learning and\n  computer vision techniques",
      "pdf_url": "http://arxiv.org/pdf/2501.11836v1",
      "published_date": "2025-01-21 02:44:05 UTC",
      "updated_date": "2025-01-21 02:44:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:50:49.149180"
    },
    {
      "arxiv_id": "2501.11833v1",
      "title": "Is your LLM trapped in a Mental Set? Investigative study on how mental sets affect the reasoning capabilities of LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Saiful Haq",
        "Niyati Chhaya",
        "Piyush Pandey",
        "Pushpak Bhattacharya"
      ],
      "abstract": "In this paper, we present an investigative study on how Mental Sets influence\nthe reasoning capabilities of LLMs. LLMs have excelled in diverse natural\nlanguage processing (NLP) tasks, driven by advancements in parameter-efficient\nfine-tuning (PEFT) and emergent capabilities like in-context learning (ICL).\nFor complex reasoning tasks, selecting the right model for PEFT or ICL is\ncritical, often relying on scores on benchmarks such as MMLU, MATH, and GSM8K.\nHowever, current evaluation methods, based on metrics like F1 Score or\nreasoning chain assessments by larger models, overlook a key dimension:\nadaptability to unfamiliar situations and overcoming entrenched thinking\npatterns. In cognitive psychology, Mental Set refers to the tendency to persist\nwith previously successful strategies, even when they become inefficient - a\nchallenge for problem solving and reasoning. We compare the performance of LLM\nmodels like Llama-3.1-8B-Instruct, Llama-3.1-70B-Instruct and GPT-4o in the\npresence of mental sets. To the best of our knowledge, this is the first study\nto integrate cognitive psychology concepts into the evaluation of LLMs for\ncomplex reasoning tasks, providing deeper insights into their adaptability and\nproblem-solving efficacy.",
      "tldr_zh": "本研究调查了 Mental Sets（心理定势）如何影响大型语言模型（LLMs）的推理能力，指出现有评估方法如基于 MMLU 和 GSM8K 的基准测试忽略了模型在不熟悉情境下的适应性和克服固有思维模式的挑战。研究者比较了 Llama-3.1-8B-Instruct、Llama-3.1-70B-Instruct 和 GPT-4o 的性能，通过 PEFT 和 ICL 等技术进行分析。结果显示，这是首次将认知心理学概念整合到 LLMs 的复杂推理任务评估中，提供更深刻的适应性和问题解决效能洞见。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.11833v1",
      "published_date": "2025-01-21 02:29:15 UTC",
      "updated_date": "2025-01-21 02:29:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:51:00.835045"
    },
    {
      "arxiv_id": "2501.13121v1",
      "title": "Episodic Memories Generation and Evaluation Benchmark for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Alexis Huet",
        "Zied Ben Houidi",
        "Dario Rossi"
      ],
      "abstract": "Episodic memory -- the ability to recall specific events grounded in time and\nspace -- is a cornerstone of human cognition, enabling not only coherent\nstorytelling, but also planning and decision-making. Despite their remarkable\ncapabilities, Large Language Models (LLMs) lack a robust mechanism for episodic\nmemory: we argue that integrating episodic memory capabilities into LLM is\nessential for advancing AI towards human-like cognition, increasing their\npotential to reason consistently and ground their output in real-world episodic\nevents, hence avoiding confabulations. To address this challenge, we introduce\na comprehensive framework to model and evaluate LLM episodic memory\ncapabilities. Drawing inspiration from cognitive science, we develop a\nstructured approach to represent episodic events, encapsulating temporal and\nspatial contexts, involved entities, and detailed descriptions. We synthesize a\nunique episodic memory benchmark, free from contamination, and release open\nsource code and datasets to assess LLM performance across various recall and\nepisodic reasoning tasks. Our evaluation of state-of-the-art models, including\nGPT-4 and Claude variants, Llama 3.1, and o1-mini, reveals that even the most\nadvanced LLMs struggle with episodic memory tasks, particularly when dealing\nwith multiple related events or complex spatio-temporal relationships -- even\nin contexts as short as 10k-100k tokens.",
      "tldr_zh": "本文提出一个框架，用于建模和评估大型语言模型（LLMs）的情景记忆（episodic memory）能力，以提升AI的类人认知、推理一致性和避免虚构输出。该框架借鉴认知科学，采用结构化方法表示情景事件，包括时间、空间、实体和详细描述，并开发了一个免污染的benchmark数据集以及开源代码，用于测试LLMs在回忆和情景推理任务上的表现。实验评估了GPT-4、Claude变体、Llama 3.1和o1-mini等模型，结果显示这些先进LLMs在处理多个相关事件或复杂时空关系时存在显著困难，即使在10k-100k tokens的短上下文环境中。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.13121v1",
      "published_date": "2025-01-21 02:16:13 UTC",
      "updated_date": "2025-01-21 02:16:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:51:13.020796"
    },
    {
      "arxiv_id": "2501.11828v1",
      "title": "Fact-Preserved Personalized News Headline Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhao Yang",
        "Junhong Lian",
        "Xiang Ao"
      ],
      "abstract": "Personalized news headline generation, aiming at generating user-specific\nheadlines based on readers' preferences, burgeons a recent flourishing research\ndirection. Existing studies generally inject a user interest embedding into an\nencoderdecoder headline generator to make the output personalized, while the\nfactual consistency of headlines is inadequate to be verified. In this paper,\nwe propose a framework Fact-Preserved Personalized News Headline Generation\n(short for FPG), to prompt a tradeoff between personalization and consistency.\nIn FPG, the similarity between the candidate news to be exposed and the\nhistorical clicked news is used to give different levels of attention to key\nfacts in the candidate news, and the similarity scores help to learn a\nfact-aware global user embedding. Besides, an additional training procedure\nbased on contrastive learning is devised to further enhance the factual\nconsistency of generated headlines. Extensive experiments conducted on a\nreal-world benchmark PENS validate the superiority of FPG, especially on the\ntradeoff between personalization and factual consistency.",
      "tldr_zh": "这篇论文提出了一种名为 FPG 的框架，用于个性化新闻标题生成，旨在平衡用户偏好与标题的事实一致性。FPG 通过计算候选新闻与历史点击新闻的相似度来调整对关键事实的关注，并学习一个 fact-aware 全局用户嵌入，同时引入基于 contrastive learning 的额外训练过程以提升生成标题的 factual consistency。在 PENS 真实基准数据集上的广泛实验证明，FPG 在个性化与事实一致性权衡方面优于现有方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by IEEE ICDM 2023, Short paper, 6 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.11828v1",
      "published_date": "2025-01-21 02:14:07 UTC",
      "updated_date": "2025-01-21 02:14:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:51:23.950299"
    },
    {
      "arxiv_id": "2501.11827v1",
      "title": "PXGen: A Post-hoc Explainable Method for Generative Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yen-Lung Huang",
        "Ming-Hsi Weng",
        "Hao-Tsung Yang"
      ],
      "abstract": "With the rapid growth of generative AI in numerous applications, explainable\nAI (XAI) plays a crucial role in ensuring the responsible development and\ndeployment of generative AI technologies. XAI has undergone notable\nadvancements and widespread adoption in recent years, reflecting a concerted\npush to enhance the transparency, interpretability, and credibility of AI\nsystems. Recent research emphasizes that a proficient XAI method should adhere\nto a set of criteria, primarily focusing on two key areas. Firstly, it should\nensure the quality and fluidity of explanations, encompassing aspects like\nfaithfulness, plausibility, completeness, and tailoring to individual needs.\nSecondly, the design principle of the XAI system or mechanism should cover the\nfollowing factors such as reliability, resilience, the verifiability of its\noutputs, and the transparency of its algorithm. However, research in XAI for\ngenerative models remains relatively scarce, with little exploration into how\nsuch methods can effectively meet these criteria in that domain. In this work,\nwe propose PXGen, a post-hoc explainable method for generative models. Given a\nmodel that needs to be explained, PXGen prepares two materials for the\nexplanation, the Anchor set and intrinsic & extrinsic criteria. Those materials\nare customizable by users according to their purpose and requirements. Via the\ncalculation of each criterion, each anchor has a set of feature values and\nPXGen provides examplebased explanation methods according to the feature values\namong all the anchors and illustrated and visualized to the users via tractable\nalgorithms such as k-dispersion or k-center.",
      "tldr_zh": "这篇论文提出 PXGen，一种后验（post-hoc）可解释方法，旨在提升生成模型的可解释性（XAI），以满足解释质量（如 faithfulness 和 plausibility）和设计原则（如 reliability 和 resilience）。PXGen 通过准备可自定义的 Anchor set 和 intrinsic & extrinsic criteria，计算每个 anchor 的特征值，并提供基于例子的解释方法。最终，该方法利用算法如 k-dispersion 或 k-center 进行可视化和说明，帮助用户更好地理解和验证生成模型的行为。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.11827v1",
      "published_date": "2025-01-21 02:10:50 UTC",
      "updated_date": "2025-01-21 02:10:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:51:36.513908"
    },
    {
      "arxiv_id": "2501.11823v1",
      "title": "Toward Scalable Graph Unlearning: A Node Influence Maximization based Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Xunkai Li",
        "Bowen Fan",
        "Zhengyu Wu",
        "Zhiyu Li",
        "Rong-Hua Li",
        "Guoren Wang"
      ],
      "abstract": "Machine unlearning, as a pivotal technology for enhancing model robustness\nand data privacy, has garnered significant attention in prevalent web mining\napplications, especially in thriving graph-based scenarios. However, most\nexisting graph unlearning (GU) approaches face significant challenges due to\nthe intricate interactions among web-scale graph elements during the model\ntraining: (1) The gradient-driven node entanglement hinders the complete\nknowledge removal in response to unlearning requests; (2) The billion-level\ngraph elements in the web scenarios present inevitable scalability issues. To\nbreak the above limitations, we open up a new perspective by drawing a\nconnection between GU and conventional social influence maximization. To this\nend, we propose Node Influence Maximization (NIM) through the decoupled\ninfluence propagation model and fine-grained influence function in a scalable\nmanner, which is crafted to be a plug-and-play strategy to identify potential\nnodes affected by unlearning entities. This approach enables offline execution\nindependent of GU, allowing it to be seamlessly integrated into most GU methods\nto improve their unlearning performance. Based on this, we introduce Scalable\nGraph Unlearning (SGU) as a new fine-tuned framework, which balances the\nforgetting and reasoning capability of the unlearned model by entity-specific\noptimizations. Extensive experiments on 14 datasets, including large-scale\nogbn-papers100M, have demonstrated the effectiveness of our approach.\nSpecifically, NIM enhances the forgetting capability of most GU methods, while\nSGU achieves comprehensive SOTA performance and maintains scalability.",
      "tldr_zh": "该论文针对图结构机器卸载（graph unlearning）的可扩展性挑战，提出了一种基于Node Influence Maximization (NIM)的方法，将GU与社会影响最大化联系起来，通过解耦的影响传播模型和细粒度影响函数，识别受卸载实体影响的潜在节点。NIM设计为一个可插拔（plug-and-play）的策略，能独立执行并无缝整合到现有GU方法中，提升遗忘性能；在此基础上，引入Scalable Graph Unlearning (SGU)框架，通过实体特定的优化平衡模型的遗忘和推理能力。在14个数据集上的实验，包括大规模ogbn-papers100M，证明NIM显著提高了GU方法的遗忘效果，而SGU实现了全面的SOTA性能并保持了可扩展性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2501.11823v1",
      "published_date": "2025-01-21 02:02:35 UTC",
      "updated_date": "2025-01-21 02:02:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:51:49.323032"
    },
    {
      "arxiv_id": "2501.11817v1",
      "title": "Toward Effective Digraph Representation Learning: A Magnetic Adaptive Propagation based Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Xunkai Li",
        "Daohan Su",
        "Zhengyu Wu",
        "Guang Zeng",
        "Hongchao Qin",
        "Rong-Hua Li",
        "Guoren Wang"
      ],
      "abstract": "The $q$-parameterized magnetic Laplacian serves as the foundation of directed\ngraph (digraph) convolution, enabling this kind of digraph neural network\n(MagDG) to encode node features and structural insights by complex-domain\nmessage passing. As a generalization of undirected methods, MagDG shows\nsuperior capability in modeling intricate web-scale topology. Despite the great\nsuccess achieved by existing MagDGs, limitations still exist: (1) Hand-crafted\n$q$: The performance of MagDGs depends on selecting an appropriate\n$q$-parameter to construct suitable graph propagation equations in the complex\ndomain. This parameter tuning, driven by downstream tasks, limits model\nflexibility and significantly increases manual effort. (2) Coarse Message\nPassing: Most approaches treat all nodes with the same complex-domain\npropagation and aggregation rules, neglecting their unique digraph contexts.\nThis oversight results in sub-optimal performance. To address the above issues,\nwe propose two key techniques: (1) MAP is crafted to be a plug-and-play\ncomplex-domain propagation optimization strategy in the context of digraph\nlearning, enabling seamless integration into any MagDG to improve predictions\nwhile enjoying high running efficiency. (2) MAP++ is a new digraph learning\nframework, further incorporating a learnable mechanism to achieve adaptively\nedge-wise propagation and node-wise aggregation in the complex domain for\nbetter performance. Extensive experiments on 12 datasets demonstrate that MAP\nenjoys flexibility for it can be incorporated with any MagDG, and scalability\nas it can deal with web-scale digraphs. MAP++ achieves SOTA predictive\nperformance on 4 different downstream tasks.",
      "tldr_zh": "本文针对 directed graph (digraph) 神经网络 (MagDG) 的局限性，提出 Magnetic Adaptive Propagation (MAP) 作为一种 plug-and-play 优化策略，以自动调整复杂域传播，提升预测性能并保持高效运行。同时，MAP++ 框架进一步引入可学习的机制，实现自适应 edge-wise 传播和 node-wise 聚合，解决手动 q-parameter 调整和粗糙消息传递问题。在 12 个数据集上的实验证明，MAP 具有灵活性和可扩展性，能处理 web-scale digraphs，而 MAP++ 在 4 个下游任务上达到 State-of-the-Art (SOTA) 性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by WWW 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.11817v1",
      "published_date": "2025-01-21 01:52:02 UTC",
      "updated_date": "2025-01-21 01:52:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:52:00.843573"
    },
    {
      "arxiv_id": "2501.11799v1",
      "title": "Policy-Adaptable Methods For Resolving Normative Conflicts Through Argumentation and Graph Colouring",
      "title_zh": "政策适应型方法：用于通过论证和图",
      "authors": [
        "Johnny Joyce"
      ],
      "abstract": "In a multi-agent system, one may choose to govern the behaviour of an agent\nby imposing norms, which act as guidelines for how agents should act either all\nof the time or in given situations. However, imposing multiple norms on one or\nmore agents may result in situations where these norms conflict over how the\nagent should behave. In any system with normative conflicts (such as safe\nreinforcement models or systems which monitor safety protocols), one must\ndecide which norms should be followed such that the most important and most\nrelevant norms are maintained. We introduce a new method for resolving\nnormative conflicts through argumentation and graph colouring which is\ncompatible with a variety of normative conflict resolution policies. We prove\nthat this method always creates an admissible set of arguments under\nargumentation semantics, meaning that it produces coherent outputs. We also\nintroduce more robust variants of this method, each building upon their\npredecessor to create a superior output, and we include further mathematical\nproof of their coherence. Our most advanced variant uses the existing concept\nof curtailment, where one norm may supersede another without fully eliminating\nit. The methods we introduce are all compatible with various pre-existing\npolicies for resolving normative conflicts. Empirical evaluations are also\nperformed to compare our algorithms to each other and to others in existing\nliterature.",
      "tldr_zh": "这篇论文提出了一种基于论证（argumentation）和图着色（graph colouring）的灵活方法，用于解决多智能体系统中规范冲突（normative conflicts），该方法兼容多种预定义的冲突解决策略。研究证明，该方法始终生成可接受的论证集（admissible set of arguments），并引入了更高级的变体，如使用 curtailment 概念来部分取代规范，从而提升输出的一致性和鲁棒性。通过实证评估，该方法与现有文献中的算法相比表现出优越性能，为规范冲突管理提供了更可靠的框架。",
      "categories": [
        "cs.AI",
        "cs.LO",
        "math.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "Written and submitted as master's thesis for University of\n  Southampton in 2020",
      "pdf_url": "http://arxiv.org/pdf/2501.11799v1",
      "published_date": "2025-01-21 00:32:49 UTC",
      "updated_date": "2025-01-21 00:32:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:52:11.734686"
    },
    {
      "arxiv_id": "2502.10401v1",
      "title": "You Can't Get There From Here: Redefining Information Science to address our sociotechnical futures",
      "title_zh": "翻译失败",
      "authors": [
        "Scott Humr",
        "Mustafa Canan"
      ],
      "abstract": "Current definitions of Information Science are inadequate to comprehensively\ndescribe the nature of its field of study and for addressing the problems that\nare arising from intelligent technologies. The ubiquitous rise of artificial\nintelligence applications and their impact on society demands the field of\nInformation Science acknowledge the sociotechnical nature of these\ntechnologies. Previous definitions of Information Science over the last six\ndecades have inadequately addressed the environmental, human, and social\naspects of these technologies. This perspective piece advocates for an expanded\ndefinition of Information Science that fully includes the sociotechnical\nimpacts information has on the conduct of research in this field. Proposing an\nexpanded definition of Information Science that includes the sociotechnical\naspects of this field should stimulate both conversation and widen the\ninterdisciplinary lens necessary to address how intelligent technologies may be\nincorporated into society and our lives more fairly.",
      "tldr_zh": "该论文指出，当前的信息科学（Information Science）定义不足以全面描述其研究领域或应对智能技术带来的社会技术（sociotechnical）问题，因为过去的定义忽略了环境、人和社会因素。作者主张扩展信息科学定义，以充分纳入这些社会技术影响，从而促进相关研究的公平开展。这样的重新定义将激发跨学科对话，并有助于更公平地整合智能技术进社会生活中。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "18 pages, information science, artificial intelligence,sociotechnical\n  systems, fairness",
      "pdf_url": "http://arxiv.org/pdf/2502.10401v1",
      "published_date": "2025-01-21 00:30:33 UTC",
      "updated_date": "2025-01-21 00:30:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:52:23.569161"
    },
    {
      "arxiv_id": "2501.16361v1",
      "title": "Large Language Models Meet Graph Neural Networks for Text-Numeric Graph Reasoning",
      "title_zh": "大语言模型与图神经网络用于文本-数值图推理",
      "authors": [
        "Haoran Song",
        "Jiarui Feng",
        "Guangfu Li",
        "Michael Province",
        "Philip Payne",
        "Yixin Chen",
        "Fuhai Li"
      ],
      "abstract": "In real-world scientific discovery, human beings always make use of the\naccumulated prior knowledge with imagination pick select one or a few most\npromising hypotheses from large and noisy data analysis results. In this study,\nwe introduce a new type of graph structure, the text-numeric graph (TNG), which\nis defined as graph entities and associations have both text-attributed\ninformation and numeric information. The TNG is an ideal data structure model\nfor novel scientific discovery via graph reasoning because it integrates\nhuman-understandable textual annotations or prior knowledge, with numeric\nvalues that represent the observed or activation levels of graph entities or\nassociations in different samples. Together both the textual information and\nnumeric values determine the importance of graph entities and associations in\ngraph reasoning for novel scientific knowledge discovery. We further propose\nintegrating large language models (LLMs) and graph neural networks (GNNs) to\nanalyze the TNGs for graph understanding and reasoning. To demonstrate the\nutility, we generated the text-omic(numeric) signaling graphs (TOSG), as one\ntype of TNGs, in which all graphs have the same entities, associations and\nannotations, but have sample-specific entity numeric (omic) values using single\ncell RNAseq (scRNAseq) datasets of different diseases. We proposed joint\nLLM-GNN models for key entity mining and signaling pathway mining on the TOSGs.\nThe evaluation results showed the LLM-GNN and TNGs models significantly improve\nclassification accuracy and network inference. In conclusion, the TNGs and\njoint LLM-GNN models are important approaches for scientific discovery.",
      "tldr_zh": "该研究引入了文本-数值图 (TNG) 作为一种新图结构，用于整合文本信息和数值数据以支持科学发现。论文提出了一种结合大型语言模型 (LLMs) 和图神经网络 (GNNs) 的联合模型，用于分析 TNGs，实现图理解和推理。实验在文本-组学信号图 (TOSG) 上进行，展示了该模型在关键实体挖掘和信号通路挖掘任务中显著提高了分类准确性和网络推断性能。总之，这种方法为基于图推理的科学知识发现提供了重要的新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "29 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.16361v1",
      "published_date": "2025-01-21 00:29:23 UTC",
      "updated_date": "2025-01-21 00:29:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T01:52:35.409096"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 113,
  "processed_papers_count": 113,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-22T01:52:53.802025"
}