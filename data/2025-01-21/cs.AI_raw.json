[
  {
    "arxiv_id": "2501.12547v3",
    "title": "Human-like conceptual representations emerge from language prediction",
    "authors": [
      "Ningyu Xu",
      "Qi Zhang",
      "Chao Du",
      "Qiang Luo",
      "Xipeng Qiu",
      "Xuanjing Huang",
      "Menghan Zhang"
    ],
    "abstract": "People acquire concepts through rich physical and social experiences and use\nthem to understand the world. In contrast, large language models (LLMs),\ntrained exclusively through next-token prediction over language data, exhibit\nremarkably human-like behaviors. Are these models developing concepts akin to\nhumans, and if so, how are such concepts represented and organized? To address\nthese questions, we reframed the classic reverse dictionary task to simulate\nhuman concept inference in context and investigated the emergence of human-like\nconceptual representations within LLMs. Our results demonstrate that LLMs can\nflexibly derive concepts from linguistic descriptions in relation to contextual\ncues about other concepts. The derived representations converged towards a\nshared, context-independent structure that effectively predicted human behavior\nacross key psychological phenomena, including computation of similarities,\ncategories and semantic scales. Moreover, these representations aligned well\nwith neural activity patterns in the human brain, even in response to visual\nrather than linguistic stimuli, providing evidence for biological plausibility.\nThese findings establish that structured, human-like conceptual representations\ncan naturally emerge from language prediction without real-world grounding.\nMore broadly, our work positions LLMs as promising computational tools for\nunderstanding complex human cognition and paves the way for better alignment\nbetween artificial and human intelligence.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "51 pages",
    "pdf_url": "http://arxiv.org/pdf/2501.12547v3",
    "published_date": "2025-01-21 23:54:17 UTC",
    "updated_date": "2025-03-24 09:10:35 UTC"
  },
  {
    "arxiv_id": "2501.14826v1",
    "title": "Multi-Modality Transformer for E-Commerce: Inferring User Purchase Intention to Bridge the Query-Product Gap",
    "authors": [
      "Srivatsa Mallapragada",
      "Ying Xie",
      "Varsha Rani Chawan",
      "Zeyad Hailat",
      "Yuanbo Wang"
    ],
    "abstract": "E-commerce click-stream data and product catalogs offer critical user\nbehavior insights and product knowledge. This paper propose a multi-modal\ntransformer termed as PINCER, that leverages the above data sources to\ntransform initial user queries into pseudo-product representations. By tapping\ninto these external data sources, our model can infer users' potential purchase\nintent from their limited queries and capture query relevant product features.\nWe demonstrate our model's superior performance over state-of-the-art\nalternatives on e-commerce online retrieval in both controlled and real-world\nexperiments. Our ablation studies confirm that the proposed transformer\narchitecture and integrated learning strategies enable the mining of key data\nsources to infer purchase intent, extract product features, and enhance the\ntransformation pipeline from queries to more accurate pseudo-product\nrepresentations.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "Published in IEEE Big Data Conference 2024, Washington DC",
    "pdf_url": "http://arxiv.org/pdf/2501.14826v1",
    "published_date": "2025-01-21 23:47:39 UTC",
    "updated_date": "2025-01-21 23:47:39 UTC"
  },
  {
    "arxiv_id": "2501.13965v1",
    "title": "ZKLoRA: Efficient Zero-Knowledge Proofs for LoRA Verification",
    "authors": [
      "Bidhan Roy",
      "Peter Potash",
      "Marcos Villagra"
    ],
    "abstract": "Low-Rank Adaptation (LoRA) is a widely adopted method for customizing\nlarge-scale language models. In distributed, untrusted training environments,\nan open source base model user may want to use LoRA weights created by an\nexternal contributor, leading to two requirements: (1) the base model user must\nconfirm that the LoRA weights are effective when paired with the intended base\nmodel, and (2) the LoRA contributor must keep their proprietary weights private\nuntil compensation is assured.\n  We present ZKLoRA, a zero-knowledge verification protocol that relies on\nsuccinct proofs and our novel Multi-Party Inference procedure to verify\nLoRA-base model compatibility without exposing LoRA weights. ZKLoRA produces\ndeterministic correctness guarantees and validates each LoRA module in only 1-2\nseconds on state-of-the-art large language models. This low-latency approach\nenables nearly real-time verification and promotes secure collaboration among\ngeographically decentralized teams and contract-based training pipelines. The\nprotocol ensures that the delivered LoRA module works as claimed, safeguarding\nthe contributor's intellectual property while providing the base model user\nwith verification of compatibility and lineage.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "7 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.13965v1",
    "published_date": "2025-01-21 23:20:33 UTC",
    "updated_date": "2025-01-21 23:20:33 UTC"
  },
  {
    "arxiv_id": "2501.12542v1",
    "title": "Reinforcement Learning Constrained Beam Search for Parameter Optimization of Paper Drying Under Flexible Constraints",
    "authors": [
      "Siyuan Chen",
      "Hanshen Yu",
      "Jamal Yagoobi",
      "Chenhui Shao"
    ],
    "abstract": "Existing approaches to enforcing design constraints in Reinforcement Learning\n(RL) applications often rely on training-time penalties in the reward function\nor training/inference-time invalid action masking, but these methods either\ncannot be modified after training, or are limited in the types of constraints\nthat can be implemented. To address this limitation, we propose Reinforcement\nLearning Constrained Beam Search (RLCBS) for inference-time refinement in\ncombinatorial optimization problems. This method respects flexible,\ninference-time constraints that support exclusion of invalid actions and forced\ninclusion of desired actions, and employs beam search to maximize sequence\nprobability for more sensible constraint incorporation. RLCBS is extensible to\nRL-based planning and optimization problems that do not require real-time\nsolution, and we apply the method to optimize process parameters for a novel\nmodular testbed for paper drying. An RL agent is trained to minimize energy\nconsumption across varying machine speed levels by generating optimal dryer\nmodule and air supply temperature configurations. Our results demonstrate that\nRLCBS outperforms NSGA-II under complex design constraints on drying module\nconfigurations at inference-time, while providing a 2.58-fold or higher speed\nimprovement.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12542v1",
    "published_date": "2025-01-21 23:16:19 UTC",
    "updated_date": "2025-01-21 23:16:19 UTC"
  },
  {
    "arxiv_id": "2501.17170v1",
    "title": "Benchmarking Randomized Optimization Algorithms on Binary, Permutation, and Combinatorial Problem Landscapes",
    "authors": [
      "Jethro Odeyemi",
      "Wenjun Zhang"
    ],
    "abstract": "In this paper, we evaluate the performance of four randomized optimization\nalgorithms: Randomized Hill Climbing (RHC), Simulated Annealing (SA), Genetic\nAlgorithms (GA), and MIMIC (Mutual Information Maximizing Input Clustering),\nacross three distinct types of problems: binary, permutation, and\ncombinatorial. We systematically compare these algorithms using a set of\nbenchmark fitness functions that highlight the specific challenges and\nrequirements of each problem category. Our study analyzes each algorithm's\neffectiveness based on key performance metrics, including solution quality,\nconvergence speed, computational cost, and robustness. Results show that while\nMIMIC and GA excel in producing high-quality solutions for binary and\ncombinatorial problems, their computational demands vary significantly. RHC and\nSA, while computationally less expensive, demonstrate limited performance in\ncomplex problem landscapes. The findings offer valuable insights into the\ntrade-offs between different optimization strategies and provide practical\nguidance for selecting the appropriate algorithm based on the type of problems,\naccuracy requirements, and computational constraints.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17170v1",
    "published_date": "2025-01-21 23:13:01 UTC",
    "updated_date": "2025-01-21 23:13:01 UTC"
  },
  {
    "arxiv_id": "2501.13964v3",
    "title": "Advancing the Understanding and Evaluation of AR-Generated Scenes: When Vision-Language Models Shine and Stumble",
    "authors": [
      "Lin Duan",
      "Yanming Xiu",
      "Maria Gorlatova"
    ],
    "abstract": "Augmented Reality (AR) enhances the real world by integrating virtual\ncontent, yet ensuring the quality, usability, and safety of AR experiences\npresents significant challenges. Could Vision-Language Models (VLMs) offer a\nsolution for the automated evaluation of AR-generated scenes? Could\nVision-Language Models (VLMs) offer a solution for the automated evaluation of\nAR-generated scenes? In this study, we evaluate the capabilities of three\nstate-of-the-art commercial VLMs -- GPT, Gemini, and Claude -- in identifying\nand describing AR scenes. For this purpose, we use DiverseAR, the first AR\ndataset specifically designed to assess VLMs' ability to analyze virtual\ncontent across a wide range of AR scene complexities. Our findings demonstrate\nthat VLMs are generally capable of perceiving and describing AR scenes,\nachieving a True Positive Rate (TPR) of up to 93% for perception and 71% for\ndescription. While they excel at identifying obvious virtual objects, such as a\nglowing apple, they struggle when faced with seamlessly integrated content,\nsuch as a virtual pot with realistic shadows. Our results highlight both the\nstrengths and the limitations of VLMs in understanding AR scenarios. We\nidentify key factors affecting VLM performance, including virtual content\nplacement, rendering quality, and physical plausibility. This study underscores\nthe potential of VLMs as tools for evaluating the quality of AR experiences.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CV",
    "comment": "6 pages",
    "pdf_url": "http://arxiv.org/pdf/2501.13964v3",
    "published_date": "2025-01-21 23:07:03 UTC",
    "updated_date": "2025-02-01 20:27:00 UTC"
  },
  {
    "arxiv_id": "2501.12538v3",
    "title": "Academic case reports lack diversity: Assessing the presence and diversity of sociodemographic and behavioral factors related to Post COVID-19 Condition",
    "authors": [
      "Juan Andres Medina Florez",
      "Shaina Raza",
      "Rashida Lynn",
      "Zahra Shakeri",
      "Brendan T. Smith",
      "Elham Dolatabadi"
    ],
    "abstract": "Understanding the prevalence, disparities, and symptom variations of Post\nCOVID-19 Condition (PCC) for vulnerable populations is crucial to improving\ncare and addressing intersecting inequities. This study aims to develop a\ncomprehensive framework for integrating social determinants of health (SDOH)\ninto PCC research by leveraging NLP techniques to analyze disparities and\nvariations in SDOH representation within PCC case reports. Following\nconstruction of a PCC Case Report Corpus, comprising over 7,000 case reports\nfrom the LitCOVID repository, a subset of 709 reports were annotated with 26\ncore SDOH-related entity types using pre-trained named entity recognition (NER)\nmodels, human review, and data augmentation to improve quality, diversity and\nrepresentation of entity types. An NLP pipeline integrating NER, natural\nlanguage inference (NLI), trigram and frequency analyses was developed to\nextract and analyze these entities. Both encoder-only transformer models and\nRNN-based models were assessed for the NER objective.\n  Fine-tuned encoder-only BERT models outperformed traditional RNN-based models\nin generalizability to distinct sentence structures and greater class sparsity.\nExploratory analysis revealed variability in entity richness, with prevalent\nentities like condition, age, and access to care, and underrepresentation of\nsensitive categories like race and housing status. Trigram analysis highlighted\nfrequent co-occurrences among entities, including age, gender, and condition.\nThe NLI objective (entailment and contradiction analysis) showed attributes\nlike \"Experienced violence or abuse\" and \"Has medical insurance\" had high\nentailment rates (82.4%-80.3%), while attributes such as \"Is\nfemale-identifying,\" \"Is married,\" and \"Has a terminal condition\" exhibited\nhigh contradiction rates (70.8%-98.5%).",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12538v3",
    "published_date": "2025-01-21 23:05:12 UTC",
    "updated_date": "2025-02-24 02:29:35 UTC"
  },
  {
    "arxiv_id": "2501.12536v1",
    "title": "Interaction Dataset of Autonomous Vehicles with Traffic Lights and Signs",
    "authors": [
      "Zheng Li",
      "Zhipeng Bao",
      "Haoming Meng",
      "Haotian Shi",
      "Qianwen Li",
      "Handong Yao",
      "Xiaopeng Li"
    ],
    "abstract": "This paper presents the development of a comprehensive dataset capturing\ninteractions between Autonomous Vehicles (AVs) and traffic control devices,\nspecifically traffic lights and stop signs. Derived from the Waymo Motion\ndataset, our work addresses a critical gap in the existing literature by\nproviding real-world trajectory data on how AVs navigate these traffic control\ndevices. We propose a methodology for identifying and extracting relevant\ninteraction trajectory data from the Waymo Motion dataset, incorporating over\n37,000 instances with traffic lights and 44,000 with stop signs. Our\nmethodology includes defining rules to identify various interaction types,\nextracting trajectory data, and applying a wavelet-based denoising method to\nsmooth the acceleration and speed profiles and eliminate anomalous values,\nthereby enhancing the trajectory quality. Quality assessment metrics indicate\nthat trajectories obtained in this study have anomaly proportions in\nacceleration and jerk profiles reduced to near-zero levels across all\ninteraction categories. By making this dataset publicly available, we aim to\naddress the current gap in datasets containing AV interaction behaviors with\ntraffic lights and signs. Based on the organized and published dataset, we can\ngain a more in-depth understanding of AVs' behavior when interacting with\ntraffic lights and signs. This will facilitate research on AV integration into\nexisting transportation infrastructures and networks, supporting the\ndevelopment of more accurate behavioral models and simulation tools.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12536v1",
    "published_date": "2025-01-21 22:59:50 UTC",
    "updated_date": "2025-01-21 22:59:50 UTC"
  },
  {
    "arxiv_id": "2501.12524v2",
    "title": "Efficient Lung Ultrasound Severity Scoring Using Dedicated Feature Extractor",
    "authors": [
      "Jiaqi Guo",
      "Yunan Wu",
      "Evangelos Kaimakamis",
      "Georgios Petmezas",
      "Vasileios E. Papageorgiou",
      "Nicos Maglaveras",
      "Aggelos K. Katsaggelos"
    ],
    "abstract": "With the advent of the COVID-19 pandemic, ultrasound imaging has emerged as a\npromising technique for COVID-19 detection, due to its non-invasive nature,\naffordability, and portability. In response, researchers have focused on\ndeveloping AI-based scoring systems to provide real-time diagnostic support.\nHowever, the limited size and lack of proper annotation in publicly available\nultrasound datasets pose significant challenges for training a robust AI model.\nThis paper proposes MeDiVLAD, a novel pipeline to address the above issue for\nmulti-level lung-ultrasound (LUS) severity scoring. In particular, we leverage\nself-knowledge distillation to pretrain a vision transformer (ViT) without\nlabel and aggregate frame-level features via dual-level VLAD aggregation. We\nshow that with minimal finetuning, MeDiVLAD outperforms conventional\nfully-supervised methods in both frame- and video-level scoring, while offering\nclassification reasoning with exceptional quality. This superior performance\nenables key applications such as the automatic identification of critical lung\npathology areas and provides a robust solution for broader medical video\nclassification tasks.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "Accepted by IEEE ISBI 2025 (Selected for oral presentation) 2025/4/15\n  (v2): Corrected a notation error in Figure 2",
    "pdf_url": "http://arxiv.org/pdf/2501.12524v2",
    "published_date": "2025-01-21 22:28:22 UTC",
    "updated_date": "2025-04-15 19:09:20 UTC"
  },
  {
    "arxiv_id": "2501.12521v1",
    "title": "An Empirically-grounded tool for Automatic Prompt Linting and Repair: A Case Study on Bias, Vulnerability, and Optimization in Developer Prompts",
    "authors": [
      "Dhia Elhaq Rzig",
      "Dhruba Jyoti Paul",
      "Kaiser Pister",
      "Jordan Henkel",
      "Foyzul Hassan"
    ],
    "abstract": "The tidal wave of advancements in Large Language Models (LLMs) has led to\ntheir swift integration into application-level logic. Many software systems now\nuse prompts to interact with these black-box models, combining natural language\nwith dynamic values interpolated at runtime, to perform tasks ranging from\nsentiment analysis to question answering. Due to the programmatic and\nstructured natural language aspects of these prompts, we refer to them as\nDeveloper Prompts. Unlike traditional software artifacts, Dev Prompts blend\nnatural language instructions with artificial languages such as programming and\nmarkup languages, thus requiring specialized tools for analysis, distinct from\nclassical software evaluation methods.\n  In response to this need, we introduce PromptDoctor, a tool explicitly\ndesigned to detect and correct issues of Dev Prompts. PromptDoctor identifies\nand addresses problems related to bias, vulnerability, and sub-optimal\nperformance in Dev Prompts, helping mitigate their possible harms. In our\nanalysis of 2,173 Dev Prompts, selected as a representative sample of 40,573\nDev Prompts, we found that 3.46% contained one or more forms of bias, 10.75%\nwere vulnerable to prompt injection attacks. Additionally, 3,310 were amenable\nto automated prompt optimization. To address these issues, we applied\nPromptDoctor to the flawed Dev Prompts we discovered. PromptDoctor de-biased\n68.29% of the biased Dev Prompts, hardened 41.81% of the vulnerable Dev\nPrompts, and improved the performance of 37.1% sub-optimal Dev Prompts.\nFinally, we developed a PromptDoctor VSCode extension, enabling developers to\neasily enhance Dev Prompts in their existing development workflows. The data\nand source code for this work are available at",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12521v1",
    "published_date": "2025-01-21 22:24:03 UTC",
    "updated_date": "2025-01-21 22:24:03 UTC"
  },
  {
    "arxiv_id": "2501.12508v1",
    "title": "The Finite Element Neural Network Method: One Dimensional Study",
    "authors": [
      "Mohammed Abda",
      "Elsa Piollet",
      "Christopher Blake",
      "Frédérick P. Gosselin"
    ],
    "abstract": "The potential of neural networks (NN) in engineering is rooted in their\ncapacity to understand intricate patterns and complex systems, leveraging their\nuniversal nonlinear approximation capabilities and high expressivity.\nMeanwhile, conventional numerical methods, backed by years of meticulous\nrefinement, continue to be the standard for accuracy and dependability.\nBridging these paradigms, this research introduces the finite element neural\nnetwork method (FENNM) within the framework of the Petrov-Galerkin method using\nconvolution operations to approximate the weighted residual of the differential\nequations. The NN generates the global trial solution, while the test functions\nbelong to the Lagrange test function space. FENNM introduces several key\nadvantages. Notably, the weak-form of the differential equations introduces\nflux terms that contribute information to the loss function compared to VPINN,\nhp-VPINN, and cv-PINN. This enables the integration of forcing terms and\nnatural boundary conditions into the loss function similar to conventional\nfinite element method (FEM) solvers, facilitating its optimization, and\nextending its applicability to more complex problems, which will ease\nindustrial adoption. This study will elaborate on the derivation of FENNM,\nhighlighting its similarities with FEM. Additionally, it will provide insights\ninto optimal utilization strategies and user guidelines to ensure\ncost-efficiency. Finally, the study illustrates the robustness and accuracy of\nFENNM by presenting multiple numerical case studies and applying adaptive mesh\nrefinement techniques.",
    "categories": [
      "cs.CE",
      "cs.AI"
    ],
    "primary_category": "cs.CE",
    "comment": "27 pages, 13 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.12508v1",
    "published_date": "2025-01-21 21:39:56 UTC",
    "updated_date": "2025-01-21 21:39:56 UTC"
  },
  {
    "arxiv_id": "2501.13962v1",
    "title": "Adaptive Cyber-Attack Detection in IIoT Using Attention-Based LSTM-CNN Models",
    "authors": [
      "Afrah Gueriani",
      "Hamza Kheddar",
      "Ahmed Cherif Mazari"
    ],
    "abstract": "The rapid expansion of the industrial Internet of things (IIoT) has\nintroduced new challenges in securing critical infrastructures against\nsophisticated cyberthreats. This study presents the development and evaluation\nof an advanced Intrusion detection (IDS) based on a hybrid LSTM-convolution\nneural network (CNN)-Attention architecture, specifically designed to detect\nand classify cyberattacks in IIoT environments. The research focuses on two key\nclassification tasks: binary and multi-class classification. The proposed\nmodels was rigorously tested using the Edge-IIoTset dataset. To mitigate the\nclass imbalance in the dataset, the synthetic minority over-sampling technique\n(SMOTE) was employed to generate synthetic samples for the underrepresented\nclasses. This ensured that the model could learn effectively from all classes,\nthereby improving the overall classification performance. Through systematic\nexperimentation, various deep learning (DL) models were compared, ultimately\ndemonstrating that the LSTM-CNN-Attention model consistently outperformed\nothers across key performance metrics. In binary classification, the model\nachieved near-perfect accuracy, while in multi-class classification, it\nmaintained a high accuracy level (99.04%), effectively categorizing different\nattack types with a loss value of 0.0220%.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.13962v1",
    "published_date": "2025-01-21 20:52:23 UTC",
    "updated_date": "2025-01-21 20:52:23 UTC"
  },
  {
    "arxiv_id": "2501.12489v2",
    "title": "Large-image Object Detection for Fine-grained Recognition of Punches Patterns in Medieval Panel Painting",
    "authors": [
      "Josh Bruegger",
      "Diana Ioana Catana",
      "Vanja Macovaz",
      "Matias Valdenegro-Toro",
      "Matthia Sabatelli",
      "Marco Zullich"
    ],
    "abstract": "The attribution of the author of an art piece is typically a laborious manual\nprocess, usually relying on subjective evaluations of expert figures. However,\nthere are some situations in which quantitative features of the artwork can\nsupport these evaluations. The extraction of these features can sometimes be\nautomated, for instance, with the use of Machine Learning (ML) techniques. An\nexample of these features is represented by repeated, mechanically impressed\npatterns, called punches, present chiefly in 13th and 14th-century panel\npaintings from Tuscany. Previous research in art history showcased a strong\nconnection between the shapes of punches and specific artists or workshops,\nsuggesting the possibility of using these quantitative cues to support the\nattribution. In the present work, we first collect a dataset of large-scale\nimages of these panel paintings. Then, using YOLOv10, a recent and popular\nobject detection model, we train a ML pipeline to perform object detection on\nthe punches contained in the images. Due to the large size of the images, the\ndetection procedure is split across multiple frames by adopting a\nsliding-window approach with overlaps, after which the predictions are combined\nfor the whole image using a custom non-maximal suppression routine. Our results\nindicate how art historians working in the field can reliably use our method\nfor the identification and extraction of punches.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12489v2",
    "published_date": "2025-01-21 20:30:51 UTC",
    "updated_date": "2025-04-24 10:12:30 UTC"
  },
  {
    "arxiv_id": "2501.12487v1",
    "title": "fabSAM: A Farmland Boundary Delineation Method Based on the Segment Anything Model",
    "authors": [
      "Yufeng Xie",
      "Hanzhi Wu",
      "Hongxiang Tong",
      "Lei Xiao",
      "Wenwen Zhou",
      "Ling Li",
      "Thomas Cherico Wanger"
    ],
    "abstract": "Delineating farmland boundaries is essential for agricultural management such\nas crop monitoring and agricultural census. Traditional methods using remote\nsensing imagery have been efficient but limited in generalisation. The Segment\nAnything Model (SAM), known for its impressive zero shot performance, has been\nadapted for remote sensing tasks through prompt learning and fine tuning. Here,\nwe propose a SAM based farmland boundary delineation framework 'fabSAM' that\ncombines a Deeplabv3+ based Prompter and SAM. Also, a fine tuning strategy was\nintroduced to enable SAMs decoder to improve the use of prompt information.\nExperimental results on the AI4Boundaries and AI4SmallFarms datasets have shown\nthat fabSAM has a significant improvement in farmland region identification and\nboundary delineation. Compared to zero shot SAM, fabSAM surpassed it by 23.5%\nand 15.1% in mIOU on the AI4Boundaries and AI4SmallFarms datasets,\nrespectively. For Deeplabv3+, fabSAM outperformed it by 4.9% and 12.5% in mIOU,\nrespectively. These results highlight the effectiveness of fabSAM, which also\nmeans that we can more easily obtain the global farmland region and boundary\nmaps from open source satellite image datasets like Sentinel2.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12487v1",
    "published_date": "2025-01-21 20:23:22 UTC",
    "updated_date": "2025-01-21 20:23:22 UTC"
  },
  {
    "arxiv_id": "2501.12485v1",
    "title": "R2D2: Remembering, Reflecting and Dynamic Decision Making for Web Agents",
    "authors": [
      "Tenghao Huang",
      "Kinjal Basu",
      "Ibrahim Abdelaziz",
      "Pavan Kapanipathi",
      "Jonathan May",
      "Muhao Chen"
    ],
    "abstract": "The proliferation of web agents necessitates advanced navigation and\ninteraction strategies within complex web environments. Current models often\nstruggle with efficient navigation and action execution due to limited\nvisibility and understanding of web structures. Our proposed R2D2 framework\naddresses these challenges by integrating two paradigms: Remember and Reflect.\nThe Remember paradigm utilizes a replay buffer that aids agents in\nreconstructing the web environment dynamically, thus enabling the formulation\nof a detailed ``map'' of previously visited pages. This helps in reducing\nnavigational errors and optimizing the decision-making process during web\ninteractions. Conversely, the Reflect paradigm allows agents to learn from past\nmistakes by providing a mechanism for error analysis and strategy refinement,\nenhancing overall task performance. We evaluate R2D2 using the WEBARENA\nbenchmark, demonstrating significant improvements over existing methods,\nincluding a 50% reduction in navigation errors and a threefold increase in task\ncompletion rates. Our findings suggest that a combination of memory-enhanced\nnavigation and reflective learning promisingly advances the capabilities of web\nagents, potentially benefiting various applications such as automated customer\nservice and personal digital assistants.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12485v1",
    "published_date": "2025-01-21 20:21:58 UTC",
    "updated_date": "2025-01-21 20:21:58 UTC"
  },
  {
    "arxiv_id": "2501.12479v1",
    "title": "Degree-Based Logical Adjacency Checking (DBLAC): A Novel Heuristic for Vertex Coloring",
    "authors": [
      "Prashant Verma"
    ],
    "abstract": "Degree Based Logical Adjacency Checking (DBLAC). An efficient coloring of\ngraphs with unique logical AND operations. The logical AND operation shows more\neffective color assignment and fewer number of induced colors in the case of\ncommon edges between vertices. In this work, we provide a detailed theoretical\nanalysis of DBLAC's time and space complexity. It furthermore shows its\neffectiveness through prolonged experiments on standard benchmark graphs. We\ncompare it with existing algorithms, namely DSATUR and Recursive Largest First\n(RLF). Second, we show how DBLAC achieves competitive results with respect to\nboth the number of colors used and runtime performance.",
    "categories": [
      "cs.DM",
      "cs.AI"
    ],
    "primary_category": "cs.DM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12479v1",
    "published_date": "2025-01-21 20:07:22 UTC",
    "updated_date": "2025-01-21 20:07:22 UTC"
  },
  {
    "arxiv_id": "2501.12465v1",
    "title": "Adaptive PII Mitigation Framework for Large Language Models",
    "authors": [
      "Shubhi Asthana",
      "Ruchi Mahindru",
      "Bing Zhang",
      "Jorge Sanz"
    ],
    "abstract": "Artificial Intelligence (AI) faces growing challenges from evolving data\nprotection laws and enforcement practices worldwide. Regulations like GDPR and\nCCPA impose strict compliance requirements on Machine Learning (ML) models,\nespecially concerning personal data use. These laws grant individuals rights\nsuch as data correction and deletion, complicating the training and deployment\nof Large Language Models (LLMs) that rely on extensive datasets. Public data\navailability does not guarantee its lawful use for ML, amplifying these\nchallenges.\n  This paper introduces an adaptive system for mitigating risk of Personally\nIdentifiable Information (PII) and Sensitive Personal Information (SPI) in\nLLMs. It dynamically aligns with diverse regulatory frameworks and integrates\nseamlessly into Governance, Risk, and Compliance (GRC) systems. The system uses\nadvanced NLP techniques, context-aware analysis, and policy-driven masking to\nensure regulatory compliance.\n  Benchmarks highlight the system's effectiveness, with an F1 score of 0.95 for\nPassport Numbers, outperforming tools like Microsoft Presidio (0.33) and Amazon\nComprehend (0.54). In human evaluations, the system achieved an average user\ntrust score of 4.6/5, with participants acknowledging its accuracy and\ntransparency. Observations demonstrate stricter anonymization under GDPR\ncompared to CCPA, which permits pseudonymization and user opt-outs. These\nresults validate the system as a scalable and robust solution for enterprise\nprivacy compliance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "This paper has been accepted at PPAI-25, the 6th AAAI Workshop on\n  Privacy-Preserving Artificial Intelligence",
    "pdf_url": "http://arxiv.org/pdf/2501.12465v1",
    "published_date": "2025-01-21 19:22:45 UTC",
    "updated_date": "2025-01-21 19:22:45 UTC"
  },
  {
    "arxiv_id": "2501.12456v1",
    "title": "Deploying Privacy Guardrails for LLMs: A Comparative Analysis of Real-World Applications",
    "authors": [
      "Shubhi Asthana",
      "Bing Zhang",
      "Ruchi Mahindru",
      "Chad DeLuca",
      "Anna Lisa Gentile",
      "Sandeep Gopisetty"
    ],
    "abstract": "The adoption of Large Language Models (LLMs) has revolutionized AI\napplications but poses significant challenges in safeguarding user privacy.\nEnsuring compliance with privacy regulations such as GDPR and CCPA while\naddressing nuanced privacy risks requires robust and scalable frameworks. This\npaper presents a detailed study of OneShield Privacy Guard, a framework\ndesigned to mitigate privacy risks in user inputs and LLM outputs across\nenterprise and open-source settings. We analyze two real-world deployments:(1)\na multilingual privacy-preserving system integrated with Data and Model\nFactory, focusing on enterprise-scale data governance; and (2) PR Insights, an\nopen-source repository emphasizing automated triaging and community-driven\nrefinements. In Deployment 1, OneShield achieved a 0.95 F1 score in detecting\nsensitive entities like dates, names, and phone numbers across 26 languages,\noutperforming state-of-the-art tool such as StarPII and Presidio by up to 12\\%.\nDeployment 2, with an average F1 score of 0.86, reduced manual effort by over\n300 hours in three months, accurately flagging 8.25\\% of 1,256 pull requests\nfor privacy risks with enhanced context sensitivity. These results demonstrate\nOneShield's adaptability and efficacy in diverse environments, offering\nactionable insights for context-aware entity recognition, automated compliance,\nand ethical AI adoption. This work advances privacy-preserving frameworks,\nsupporting user trust and compliance across operational contexts.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG",
      "cs.SE"
    ],
    "primary_category": "cs.CR",
    "comment": "This paper has been accepted at Deployable AI workshop at AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.12456v1",
    "published_date": "2025-01-21 19:04:53 UTC",
    "updated_date": "2025-01-21 19:04:53 UTC"
  },
  {
    "arxiv_id": "2501.12392v1",
    "title": "Learning segmentation from point trajectories",
    "authors": [
      "Laurynas Karazija",
      "Iro Laina",
      "Christian Rupprecht",
      "Andrea Vedaldi"
    ],
    "abstract": "We consider the problem of segmenting objects in videos based on their motion\nand no other forms of supervision. Prior work has often approached this problem\nby using the principle of common fate, namely the fact that the motion of\npoints that belong to the same object is strongly correlated. However, most\nauthors have only considered instantaneous motion from optical flow. In this\nwork, we present a way to train a segmentation network using long-term point\ntrajectories as a supervisory signal to complement optical flow. The key\ndifficulty is that long-term motion, unlike instantaneous motion, is difficult\nto model -- any parametric approximation is unlikely to capture complex motion\npatterns over long periods of time. We instead draw inspiration from subspace\nclustering approaches, proposing a loss function that seeks to group the\ntrajectories into low-rank matrices where the motion of object points can be\napproximately explained as a linear combination of other point tracks. Our\nmethod outperforms the prior art on motion-based segmentation, which shows the\nutility of long-term motion and the effectiveness of our formulation.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "NeurIPS 2024 Spotlight. Project\n  https://www.robots.ox.ac.uk/~vgg/research/lrtl/",
    "pdf_url": "http://arxiv.org/pdf/2501.12392v1",
    "published_date": "2025-01-21 18:59:53 UTC",
    "updated_date": "2025-01-21 18:59:53 UTC"
  },
  {
    "arxiv_id": "2501.12391v1",
    "title": "Physics of Skill Learning",
    "authors": [
      "Ziming Liu",
      "Yizhou Liu",
      "Eric J. Michaud",
      "Jeff Gore",
      "Max Tegmark"
    ],
    "abstract": "We aim to understand physics of skill learning, i.e., how skills are learned\nin neural networks during training. We start by observing the Domino effect,\ni.e., skills are learned sequentially, and notably, some skills kick off\nlearning right after others complete learning, similar to the sequential fall\nof domino cards. To understand the Domino effect and relevant behaviors of\nskill learning, we take physicists' approach of abstraction and simplification.\nWe propose three models with varying complexities -- the Geometry model, the\nResource model, and the Domino model, trading between reality and simplicity.\nThe Domino effect can be reproduced in the Geometry model, whose resource\ninterpretation inspires the Resource model, which can be further simplified to\nthe Domino model. These models present different levels of abstraction and\nsimplification; each is useful to study some aspects of skill learning. The\nGeometry model provides interesting insights into neural scaling laws and\noptimizers; the Resource model sheds light on the learning dynamics of\ncompositional tasks; the Domino model reveals the benefits of modularity. These\nmodels are not only conceptually interesting -- e.g., we show how Chinchilla\nscaling laws can emerge from the Geometry model, but also are useful in\npractice by inspiring algorithmic development -- e.g., we show how simple\nalgorithmic changes, motivated by these toy models, can speed up the training\nof deep learning models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.data-an",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "25 pages, 20 figures. Codes are available at\n  https://github.com/KindXiaoming/physics_of_skill_learning",
    "pdf_url": "http://arxiv.org/pdf/2501.12391v1",
    "published_date": "2025-01-21 18:59:49 UTC",
    "updated_date": "2025-01-21 18:59:49 UTC"
  },
  {
    "arxiv_id": "2501.12380v1",
    "title": "MMVU: Measuring Expert-Level Multi-Discipline Video Understanding",
    "authors": [
      "Yilun Zhao",
      "Lujing Xie",
      "Haowei Zhang",
      "Guo Gan",
      "Yitao Long",
      "Zhiyuan Hu",
      "Tongyan Hu",
      "Weiyuan Chen",
      "Chuhan Li",
      "Junyang Song",
      "Zhijian Xu",
      "Chengye Wang",
      "Weifeng Pan",
      "Ziyao Shangguan",
      "Xiangru Tang",
      "Zhenwen Liang",
      "Yixin Liu",
      "Chen Zhao",
      "Arman Cohan"
    ],
    "abstract": "We introduce MMVU, a comprehensive expert-level, multi-discipline benchmark\nfor evaluating foundation models in video understanding. MMVU includes 3,000\nexpert-annotated questions spanning 27 subjects across four core disciplines:\nScience, Healthcare, Humanities & Social Sciences, and Engineering. Compared to\nprior benchmarks, MMVU features three key advancements. First, it challenges\nmodels to apply domain-specific knowledge and perform expert-level reasoning to\nanalyze specialized-domain videos, moving beyond the basic visual perception\ntypically assessed in current video benchmarks. Second, each example is\nannotated by human experts from scratch. We implement strict data quality\ncontrols to ensure the high quality of the dataset. Finally, each example is\nenriched with expert-annotated reasoning rationals and relevant domain\nknowledge, facilitating in-depth analysis. We conduct an extensive evaluation\nof 32 frontier multimodal foundation models on MMVU. The latest\nSystem-2-capable models, o1 and Gemini 2.0 Flash Thinking, achieve the highest\nperformance among the tested models. However, they still fall short of matching\nhuman expertise. Through in-depth error analyses and case studies, we offer\nactionable insights for future advancements in expert-level,\nknowledge-intensive video understanding for specialized domains.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12380v1",
    "published_date": "2025-01-21 18:56:18 UTC",
    "updated_date": "2025-01-21 18:56:18 UTC"
  },
  {
    "arxiv_id": "2501.12434v1",
    "title": "Enhancing Retrosynthesis with Conformer: A Template-Free Method",
    "authors": [
      "Jiaxi Zhuang",
      "Qian Zhang",
      "Ying Qian"
    ],
    "abstract": "Retrosynthesis plays a crucial role in the fields of organic synthesis and\ndrug development, where the goal is to identify suitable reactants that can\nyield a target product molecule. Although existing methods have achieved\nnotable success, they typically overlook the 3D conformational details and\ninternal spatial organization of molecules. This oversight makes it challenging\nto predict reactants that conform to genuine chemical principles, particularly\nwhen dealing with complex molecular structures, such as polycyclic and\nheteroaromatic compounds. In response to this challenge, we introduce a novel\ntransformer-based, template-free approach that incorporates 3D conformer data\nand spatial information. Our approach includes an Atom-align Fusion module that\nintegrates 3D positional data at the input stage, ensuring correct alignment\nbetween atom tokens and their respective 3D coordinates. Additionally, we\npropose a Distance-weighted Attention mechanism that refines the self-attention\nprocess, constricting the model s focus to relevant atom pairs in 3D space.\nExtensive experiments on the USPTO-50K dataset demonstrate that our model\noutperforms previous template-free methods, setting a new benchmark for the\nfield. A case study further highlights our method s ability to predict\nreasonable and accurate reactants.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12434v1",
    "published_date": "2025-01-21 18:54:16 UTC",
    "updated_date": "2025-01-21 18:54:16 UTC"
  },
  {
    "arxiv_id": "2501.12375v2",
    "title": "Video Depth Anything: Consistent Depth Estimation for Super-Long Videos",
    "authors": [
      "Sili Chen",
      "Hengkai Guo",
      "Shengnan Zhu",
      "Feihu Zhang",
      "Zilong Huang",
      "Jiashi Feng",
      "Bingyi Kang"
    ],
    "abstract": "Depth Anything has achieved remarkable success in monocular depth estimation\nwith strong generalization ability. However, it suffers from temporal\ninconsistency in videos, hindering its practical applications. Various methods\nhave been proposed to alleviate this issue by leveraging video generation\nmodels or introducing priors from optical flow and camera poses. Nonetheless,\nthese methods are only applicable to short videos (< 10 seconds) and require a\ntrade-off between quality and computational efficiency. We propose Video Depth\nAnything for high-quality, consistent depth estimation in super-long videos\n(over several minutes) without sacrificing efficiency. We base our model on\nDepth Anything V2 and replace its head with an efficient spatial-temporal head.\nWe design a straightforward yet effective temporal consistency loss by\nconstraining the temporal depth gradient, eliminating the need for additional\ngeometric priors. The model is trained on a joint dataset of video depth and\nunlabeled images, similar to Depth Anything V2. Moreover, a novel\nkey-frame-based strategy is developed for long video inference. Experiments\nshow that our model can be applied to arbitrarily long videos without\ncompromising quality, consistency, or generalization ability. Comprehensive\nevaluations on multiple video benchmarks demonstrate that our approach sets a\nnew state-of-the-art in zero-shot video depth estimation. We offer models of\ndifferent scales to support a range of scenarios, with our smallest model\ncapable of real-time performance at 30 FPS.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page: https://videodepthanything.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2501.12375v2",
    "published_date": "2025-01-21 18:53:30 UTC",
    "updated_date": "2025-01-22 11:33:54 UTC"
  },
  {
    "arxiv_id": "2501.12374v1",
    "title": "Expertise elevates AI usage: experimental evidence comparing laypeople and professional artists",
    "authors": [
      "Thomas F. Eisenmann",
      "Andres Karjus",
      "Mar Canet Sola",
      "Levin Brinkmann",
      "Bramantyo Ibrahim Supriyatno",
      "Iyad Rahwan"
    ],
    "abstract": "Novel capacities of generative AI to analyze and generate cultural artifacts\nraise inevitable questions about the nature and value of artistic education and\nhuman expertise. Has AI already leveled the playing field between professional\nartists and laypeople, or do trained artistic expressive capacity, curation\nskills and experience instead enhance the ability to use these new tools? In\nthis pre-registered study, we conduct experimental comparisons between 50\nactive artists and a demographically matched sample of laypeople. We designed\ntwo tasks to approximate artistic practice for testing their capabilities in\nboth faithful and creative image creation: replicating a reference image, and\nmoving as far away as possible from it. We developed a bespoke platform where\nparticipants used a modern text-to-image model to complete both tasks. We also\ncollected and compared participants' sentiments towards AI. On average, artists\nproduced more faithful and creative outputs than their lay counterparts,\nalthough only by a small margin. While AI may ease content creation,\nprofessional expertise is still valuable - even within the confined space of\ngenerative AI itself. Finally, we also explored how well an exemplary\nvision-capable large language model (GPT-4o) would complete the same tasks, if\ngiven the role of an image generation agent, and found it performed on par in\ncopying but outperformed even artists in the creative task. The very best\nresults were still produced by humans in both tasks. These outcomes highlight\nthe importance of integrating artistic skills with AI training to prepare\nartists and other visual professionals for a technologically evolving\nlandscape. We see a potential in collaborative synergy with generative AI,\nwhich could reshape creative industries and education in the arts.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "Eisenmann and Karjus contributed equally to this work and share first\n  authorship",
    "pdf_url": "http://arxiv.org/pdf/2501.12374v1",
    "published_date": "2025-01-21 18:53:21 UTC",
    "updated_date": "2025-01-21 18:53:21 UTC"
  },
  {
    "arxiv_id": "2501.12372v5",
    "title": "Is Long Context All You Need? Leveraging LLM's Extended Context for NL2SQL",
    "authors": [
      "Yeounoh Chung",
      "Gaurav T. Kakkar",
      "Yu Gan",
      "Brenton Milne",
      "Fatma Ozcan"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities across\na range of natural language processing tasks. In particular, improvements in\nreasoning abilities and the expansion of context windows have opened new\navenues for leveraging these powerful models. NL2SQL is challenging in that the\nnatural language question is inherently ambiguous, while the SQL generation\nrequires a precise understanding of complex data schema and semantics. One\napproach to this semantic ambiguous problem is to provide more and sufficient\ncontextual information.\n  In this work, we explore the performance and the latency trade-offs of the\nextended context window (a.k.a., long context) offered by Google's\nstate-of-the-art LLM (\\textit{gemini-1.5-pro}). We study the impact of various\ncontextual information, including column example values, question and SQL query\npairs, user-provided hints, SQL documentation, and schema. To the best of our\nknowledge, this is the first work to study how the extended context window and\nextra contextual information can help NL2SQL generation with respect to both\naccuracy and latency cost. We show that long context LLMs are robust and do not\nget lost in the extended contextual information. Additionally, our long-context\nNL2SQL pipeline based on Google's \\textit{gemini-pro-1.5} achieve strong\nperformances on various benchmark datasets without finetuning and expensive\nself-consistency based techniques.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "13 pages, 6 figures, VLDB 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.12372v5",
    "published_date": "2025-01-21 18:52:15 UTC",
    "updated_date": "2025-03-20 17:39:13 UTC"
  },
  {
    "arxiv_id": "2501.12370v2",
    "title": "Parameters vs FLOPs: Scaling Laws for Optimal Sparsity for Mixture-of-Experts Language Models",
    "authors": [
      "Samira Abnar",
      "Harshay Shah",
      "Dan Busbridge",
      "Alaaeldin Mohamed Elnouby Ali",
      "Josh Susskind",
      "Vimal Thilak"
    ],
    "abstract": "Scaling the capacity of language models has consistently proven to be a\nreliable approach for improving performance and unlocking new capabilities.\nCapacity can be primarily defined by two dimensions: the number of model\nparameters and the compute per example. While scaling typically involves\nincreasing both, the precise interplay between these factors and their combined\ncontribution to overall capacity remains not fully understood. We explore this\nrelationship in the context of sparse Mixture-of-Experts (MoEs), which allow\nscaling the number of parameters without proportionally increasing the FLOPs\nper example. We investigate how varying the sparsity level, i.e., the fraction\nof inactive parameters, impacts model's performance during pretraining and\ndownstream few-shot evaluation. We find that under different constraints (e.g.,\nparameter size and total training compute), there is an optimal level of\nsparsity that improves both training efficiency and model performance. These\nresults provide a better understanding of the impact of sparsity in scaling\nlaws for MoEs and complement existing works in this area, offering insights for\ndesigning more efficient architectures.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12370v2",
    "published_date": "2025-01-21 18:51:15 UTC",
    "updated_date": "2025-01-25 02:41:24 UTC"
  },
  {
    "arxiv_id": "2501.12369v2",
    "title": "DARB-Splatting: Generalizing Splatting with Decaying Anisotropic Radial Basis Functions",
    "authors": [
      "Vishagar Arunan",
      "Saeedha Nazar",
      "Hashiru Pramuditha",
      "Vinasirajan Viruthshaan",
      "Sameera Ramasinghe",
      "Simon Lucey",
      "Ranga Rodrigo"
    ],
    "abstract": "Splatting-based 3D reconstruction methods have gained popularity with the\nadvent of 3D Gaussian Splatting, efficiently synthesizing high-quality novel\nviews. These methods commonly resort to using exponential family functions,\nsuch as the Gaussian function, as reconstruction kernels due to their\nanisotropic nature, ease of projection, and differentiability in rasterization.\nHowever, the field remains restricted to variations within the exponential\nfamily, leaving generalized reconstruction kernels largely underexplored,\npartly due to the lack of easy integrability in 3D to 2D projections. In this\nlight, we show that a class of decaying anisotropic radial basis functions\n(DARBFs), which are non-negative functions of the Mahalanobis distance,\nsupports splatting by approximating the Gaussian function's closed-form\nintegration advantage. With this fresh perspective, we demonstrate up to 34%\nfaster convergence during training and a 45% reduction in memory consumption\nacross various DARB reconstruction kernels, while maintaining comparable PSNR,\nSSIM, and LPIPS results. We will make the code available.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "Link to the project page:\n  https://randomnerds.github.io/darbs.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2501.12369v2",
    "published_date": "2025-01-21 18:49:06 UTC",
    "updated_date": "2025-04-21 10:43:56 UTC"
  },
  {
    "arxiv_id": "2501.12433v2",
    "title": "Owls are wise and foxes are unfaithful: Uncovering animal stereotypes in vision-language models",
    "authors": [
      "Tabinda Aman",
      "Mohammad Nadeem",
      "Shahab Saquib Sohail",
      "Mohammad Anas",
      "Erik Cambria"
    ],
    "abstract": "Animal stereotypes are deeply embedded in human culture and language. They\noften shape our perceptions and expectations of various species. Our study\ninvestigates how animal stereotypes manifest in vision-language models during\nthe task of image generation. Through targeted prompts, we explore whether\nDALL-E perpetuates stereotypical representations of animals, such as \"owls as\nwise,\" \"foxes as unfaithful,\" etc. Our findings reveal significant stereotyped\ninstances where the model consistently generates images aligned with cultural\nbiases. The current work is the first of its kind to examine animal\nstereotyping in vision-language models systematically and to highlight a\ncritical yet underexplored dimension of bias in AI-generated visual content.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12433v2",
    "published_date": "2025-01-21 18:41:28 UTC",
    "updated_date": "2025-04-29 05:16:44 UTC"
  },
  {
    "arxiv_id": "2501.12352v3",
    "title": "Test-time regression: a unifying framework for designing sequence models with associative memory",
    "authors": [
      "Ke Alexander Wang",
      "Jiaxin Shi",
      "Emily B. Fox"
    ],
    "abstract": "Sequence models lie at the heart of modern deep learning. However, rapid\nadvancements have produced a diversity of seemingly unrelated architectures,\nsuch as Transformers and recurrent alternatives. In this paper, we introduce a\nunifying framework to understand and derive these sequence models, inspired by\nthe empirical importance of associative recall, the capability to retrieve\ncontextually relevant tokens. We formalize associative recall as a two-step\nprocess, memorization and retrieval, casting memorization as a regression\nproblem. Layers that combine these two steps perform associative recall via\n``test-time regression'' over its input tokens. Prominent layers, including\nlinear attention, state-space models, fast-weight programmers, online learners,\nand softmax attention, arise as special cases defined by three design choices:\nthe regression weights, the regressor function class, and the test-time\noptimization algorithm. Our approach clarifies how linear attention fails to\ncapture inter-token correlations and offers a mathematical justification for\nthe empirical effectiveness of query-key normalization in softmax attention.\nFurther, it illuminates unexplored regions within the design space, which we\nuse to derive novel higher-order generalizations of softmax attention. Beyond\nunification, our work bridges sequence modeling with classic regression\nmethods, a field with extensive literature, paving the way for developing more\npowerful and theoretically principled architectures.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12352v3",
    "published_date": "2025-01-21 18:32:31 UTC",
    "updated_date": "2025-05-02 02:07:05 UTC"
  },
  {
    "arxiv_id": "2501.12339v2",
    "title": "Treefix: Enabling Execution with a Tree of Prefixes",
    "authors": [
      "Beatriz Souza",
      "Michael Pradel"
    ],
    "abstract": "The ability to execute code is a prerequisite for various dynamic program\nanalyses. Learning-guided execution has been proposed as an approach to enable\nthe execution of arbitrary code snippets by letting a neural model predict\nlikely values for any missing variables. Although state-of-the-art\nlearning-guided execution approaches, such as LExecutor, can enable the\nexecution of a relative high amount of code, they are limited to predicting a\nrestricted set of possible values and do not use any feedback from previous\nexecutions to execute even more code. This paper presents Treefix, a novel\nlearning-guided execution approach that leverages LLMs to iteratively create\ncode prefixes that enable the execution of a given code snippet. The approach\naddresses the problem in a multi-step fashion, where each step uses feedback\nabout the code snippet and its execution to instruct an LLM to improve a\npreviously generated prefix. This process iteratively creates a tree of\nprefixes, a subset of which is returned to the user as prefixes that maximize\nthe number of executed lines in the code snippet. In our experiments with two\ndatasets of Python code snippets, Treefix achieves 25% and 7% more coverage\nrelative to the current state of the art in learning-guided execution, covering\na total of 84% and 82% of all lines in the code snippets.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted in research track of the IEEE/ACM International Conference\n  on Software Engineering (ICSE) 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.12339v2",
    "published_date": "2025-01-21 18:13:43 UTC",
    "updated_date": "2025-01-23 12:15:42 UTC"
  },
  {
    "arxiv_id": "2501.12336v1",
    "title": "FuocChuVIP123 at CoMeDi Shared Task: Disagreement Ranking with XLM-Roberta Sentence Embeddings and Deep Neural Regression",
    "authors": [
      "Phuoc Duong Huy Chu"
    ],
    "abstract": "This paper presents results of our system for CoMeDi Shared Task, focusing on\nSubtask 2: Disagreement Ranking. Our system leverages sentence embeddings\ngenerated by the paraphrase-xlm-r-multilingual-v1 model, combined with a deep\nneural regression model incorporating batch normalization and dropout for\nimproved generalization. By predicting the mean of pairwise judgment\ndifferences between annotators, our method explicitly targets disagreement\nranking, diverging from traditional \"gold label\" aggregation approaches. We\noptimized our system with a customized architecture and training procedure,\nachieving competitive performance in Spearman correlation against mean\ndisagreement labels. Our results highlight the importance of robust embeddings,\neffective model architecture, and careful handling of judgment differences for\nranking disagreement in multilingual contexts. These findings provide insights\ninto the use of contextualized representations for ordinal judgment tasks and\nopen avenues for further refinement of disagreement prediction models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at COMEDI shared Task, Workshop at COLING 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.12336v1",
    "published_date": "2025-01-21 18:10:43 UTC",
    "updated_date": "2025-01-21 18:10:43 UTC"
  },
  {
    "arxiv_id": "2501.12332v1",
    "title": "Automatic Labelling with Open-source LLMs using Dynamic Label Schema Integration",
    "authors": [
      "Thomas Walshe",
      "Sae Young Moon",
      "Chunyang Xiao",
      "Yawwani Gunawardana",
      "Fran Silavong"
    ],
    "abstract": "Acquiring labelled training data remains a costly task in real world machine\nlearning projects to meet quantity and quality requirements. Recently Large\nLanguage Models (LLMs), notably GPT-4, have shown great promises in labelling\ndata with high accuracy. However, privacy and cost concerns prevent the\nubiquitous use of GPT-4. In this work, we explore effectively leveraging\nopen-source models for automatic labelling. We identify integrating label\nschema as a promising technology but found that naively using the label\ndescription for classification leads to poor performance on high cardinality\ntasks. To address this, we propose Retrieval Augmented Classification (RAC) for\nwhich LLM performs inferences for one label at a time using corresponding label\nschema; we start with the most related label and iterates until a label is\nchosen by the LLM. We show that our method, which dynamically integrates label\ndescription, leads to performance improvements in labelling tasks. We further\nshow that by focusing only on the most promising labels, RAC can trade off\nbetween label quality and coverage - a property we leverage to automatically\nlabel our internal datasets.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "11 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2501.12332v1",
    "published_date": "2025-01-21 18:06:54 UTC",
    "updated_date": "2025-01-21 18:06:54 UTC"
  },
  {
    "arxiv_id": "2502.00027v1",
    "title": "Analysis of a Memcapacitor-Based for Neural Network Accelerator Framework",
    "authors": [
      "Ankur Singh",
      "Dowon Kim",
      "Byung-Geun Lee"
    ],
    "abstract": "Data-intensive computing tasks, such as training neural networks, are crucial\nfor artificial intelligence applications but often come with high energy\ndemands. One promising solution is to develop specialized hardware that\ndirectly maps neural networks, utilizing arrays of memristive devices to\nperform parallel multiply-accumulate operations. In our research, we introduce\na novel CMOS-based memcapacitor circuit that is validated using the cadence\ntool. Additionally, we developed the device in Python to facilitate the design\nof a memcapacitive-based accelerator. Our proposed framework employs a crossbar\narray of memcapacitor devices to train a neural network capable of digit\nclassification and CIFAR dataset recognition. We tested the non-ideal\ncharacteristics of the constructed memcapacitor-based neural network. The\nsystem achieved an impressive 98.4% training accuracy in digit recognition and\n94.4% training accuracy in CIFAR recognition, highlighting its effectiveness.\nThis study demonstrates the potential of memcapacitor-based neural network\nsystems in handling classification tasks and sets the stage for further\nadvancements in neuromorphic computing.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.AR",
    "comment": "11 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.00027v1",
    "published_date": "2025-01-21 18:02:30 UTC",
    "updated_date": "2025-01-21 18:02:30 UTC"
  },
  {
    "arxiv_id": "2501.12326v1",
    "title": "UI-TARS: Pioneering Automated GUI Interaction with Native Agents",
    "authors": [
      "Yujia Qin",
      "Yining Ye",
      "Junjie Fang",
      "Haoming Wang",
      "Shihao Liang",
      "Shizuo Tian",
      "Junda Zhang",
      "Jiahao Li",
      "Yunxin Li",
      "Shijue Huang",
      "Wanjun Zhong",
      "Kuanye Li",
      "Jiale Yang",
      "Yu Miao",
      "Woyu Lin",
      "Longxiang Liu",
      "Xu Jiang",
      "Qianli Ma",
      "Jingyu Li",
      "Xiaojun Xiao",
      "Kai Cai",
      "Chuang Li",
      "Yaowei Zheng",
      "Chaolin Jin",
      "Chen Li",
      "Xiao Zhou",
      "Minchao Wang",
      "Haoli Chen",
      "Zhaojian Li",
      "Haihua Yang",
      "Haifeng Liu",
      "Feng Lin",
      "Tao Peng",
      "Xin Liu",
      "Guang Shi"
    ],
    "abstract": "This paper introduces UI-TARS, a native GUI agent model that solely perceives\nthe screenshots as input and performs human-like interactions (e.g., keyboard\nand mouse operations). Unlike prevailing agent frameworks that depend on\nheavily wrapped commercial models (e.g., GPT-4o) with expert-crafted prompts\nand workflows, UI-TARS is an end-to-end model that outperforms these\nsophisticated frameworks. Experiments demonstrate its superior performance:\nUI-TARS achieves SOTA performance in 10+ GUI agent benchmarks evaluating\nperception, grounding, and GUI task execution. Notably, in the OSWorld\nbenchmark, UI-TARS achieves scores of 24.6 with 50 steps and 22.7 with 15\nsteps, outperforming Claude (22.0 and 14.9 respectively). In AndroidWorld,\nUI-TARS achieves 46.6, surpassing GPT-4o (34.5). UI-TARS incorporates several\nkey innovations: (1) Enhanced Perception: leveraging a large-scale dataset of\nGUI screenshots for context-aware understanding of UI elements and precise\ncaptioning; (2) Unified Action Modeling, which standardizes actions into a\nunified space across platforms and achieves precise grounding and interaction\nthrough large-scale action traces; (3) System-2 Reasoning, which incorporates\ndeliberate reasoning into multi-step decision making, involving multiple\nreasoning patterns such as task decomposition, reflection thinking, milestone\nrecognition, etc. (4) Iterative Training with Reflective Online Traces, which\naddresses the data bottleneck by automatically collecting, filtering, and\nreflectively refining new interaction traces on hundreds of virtual machines.\nThrough iterative training and reflection tuning, UI-TARS continuously learns\nfrom its mistakes and adapts to unforeseen situations with minimal human\nintervention. We also analyze the evolution path of GUI agents to guide the\nfurther development of this domain.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12326v1",
    "published_date": "2025-01-21 17:48:10 UTC",
    "updated_date": "2025-01-21 17:48:10 UTC"
  },
  {
    "arxiv_id": "2501.12300v1",
    "title": "LLM-Assisted Knowledge Graph Completion for Curriculum and Domain Modelling in Personalized Higher Education Recommendations",
    "authors": [
      "Hasan Abu-Rasheed",
      "Constance Jumbo",
      "Rashed Al Amin",
      "Christian Weber",
      "Veit Wiese",
      "Roman Obermaisser",
      "Madjid Fathi"
    ],
    "abstract": "While learning personalization offers great potential for learners, modern\npractices in higher education require a deeper consideration of domain models\nand learning contexts, to develop effective personalization algorithms. This\npaper introduces an innovative approach to higher education curriculum\nmodelling that utilizes large language models (LLMs) for knowledge graph (KG)\ncompletion, with the goal of creating personalized learning-path\nrecommendations. Our research focuses on modelling university subjects and\nlinking their topics to corresponding domain models, enabling the integration\nof learning modules from different faculties and institutions in the student's\nlearning path. Central to our approach is a collaborative process, where LLMs\nassist human experts in extracting high-quality, fine-grained topics from\nlecture materials. We develop a domain, curriculum, and user models for\nuniversity modules and stakeholders. We implement this model to create the KG\nfrom two study modules: Embedded Systems and Development of Embedded Systems\nUsing FPGA. The resulting KG structures the curriculum and links it to the\ndomain models. We evaluate our approach through qualitative expert feedback and\nquantitative graph quality metrics. Domain experts validated the relevance and\naccuracy of the model, while the graph quality metrics measured the structural\nproperties of our KG. Our results show that the LLM-assisted graph completion\napproach enhances the ability to connect related courses across disciplines to\npersonalize the learning experience. Expert feedback also showed high\nacceptance of the proposed collaborative approach for concept extraction and\nclassification.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted in the IEEE Global Engineering Education Conference\n  (EDUCON2025), London, UK, 22-25 April, 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.12300v1",
    "published_date": "2025-01-21 17:13:13 UTC",
    "updated_date": "2025-01-21 17:13:13 UTC"
  },
  {
    "arxiv_id": "2502.00026v2",
    "title": "Pushing the Limits of BFP on Narrow Precision LLM Inference",
    "authors": [
      "Hui Wang",
      "Yuan Cheng",
      "Xiaomeng Han",
      "Zhengpeng Zhao",
      "Dawei Yang",
      "Zhe Jiang"
    ],
    "abstract": "The substantial computational and memory demands of Large Language Models\n(LLMs) hinder their deployment. Block Floating Point (BFP) has proven effective\nin accelerating linear operations, a cornerstone of LLM workloads. However, as\nsequence lengths grow, nonlinear operations, such as Attention, increasingly\nbecome performance bottlenecks due to their quadratic computational complexity.\nThese nonlinear operations are predominantly executed using inefficient\nfloating-point formats, which renders the system challenging to optimize\nsoftware efficiency and hardware overhead. In this paper, we delve into the\nlimitations and potential of applying BFP to nonlinear operations. Given our\nfindings, we introduce a hardware-software co-design framework (DB-Attn),\nincluding: (i) DBFP, an advanced BFP version, overcomes nonlinear operation\nchallenges with a pivot-focus strategy for diverse data and an adaptive\ngrouping strategy for flexible exponent sharing. (ii) DH-LUT, a novel lookup\ntable algorithm dedicated to accelerating nonlinear operations with DBFP\nformat. (iii) An RTL-level DBFP-based engine is implemented to support DB-Attn,\napplicable to FPGA and ASIC. Results show that DB-Attn provides significant\nperformance improvements with negligible accuracy loss, achieving 74% GPU\nspeedup on Softmax of LLaMA and 10x low overhead performance improvement over\nSOTA designs.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.00026v2",
    "published_date": "2025-01-21 17:10:52 UTC",
    "updated_date": "2025-02-07 12:23:59 UTC"
  },
  {
    "arxiv_id": "2501.12296v2",
    "title": "RALAD: Bridging the Real-to-Sim Domain Gap in Autonomous Driving with Retrieval-Augmented Learning",
    "authors": [
      "Jiacheng Zuo",
      "Haibo Hu",
      "Zikang Zhou",
      "Yufei Cui",
      "Ziquan Liu",
      "Jianping Wang",
      "Nan Guan",
      "Jin Wang",
      "Chun Jason Xue"
    ],
    "abstract": "In the pursuit of robust autonomous driving systems, models trained on\nreal-world datasets often struggle to adapt to new environments, particularly\nwhen confronted with corner cases such as extreme weather conditions.\nCollecting these corner cases in the real world is non-trivial, which\nnecessitates the use of simulators for validation. However,the high\ncomputational cost and the domain gap in data distribution have hindered the\nseamless transition between real and simulated driving scenarios. To tackle\nthis challenge, we propose Retrieval-Augmented Learning for Autonomous Driving\n(RALAD), a novel framework designed to bridge the real-to-sim gap at a low\ncost. RALAD features three primary designs, including (1) domain adaptation via\nan enhanced Optimal Transport (OT) method that accounts for both individual and\ngrouped image distances, (2) a simple and unified framework that can be applied\nto various models, and (3) efficient fine-tuning techniques that freeze the\ncomputationally expensive layers while maintaining robustness. Experimental\nresults demonstrate that RALAD compensates for the performance degradation in\nsimulated environments while maintaining accuracy in real-world scenarios\nacross three different models. Taking Cross View as an example, the mIOU and\nmAP metrics in real-world scenarios remain stable before and after RALAD\nfine-tuning, while in simulated environments,the mIOU and mAP metrics are\nimproved by 10.30% and 12.29%, respectively. Moreover, the re-training cost of\nour approach is reduced by approximately 88.1%. Our code is available at\nhttps://github.com/JiachengZuo/RALAD.git.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12296v2",
    "published_date": "2025-01-21 17:03:06 UTC",
    "updated_date": "2025-03-03 06:45:12 UTC"
  },
  {
    "arxiv_id": "2501.12289v1",
    "title": "Regressor-Guided Image Editing Regulates Emotional Response to Reduce Online Engagement",
    "authors": [
      "Christoph Gebhardt",
      "Robin Willardt",
      "Seyedmorteza Sadat",
      "Chih-Wei Ning",
      "Andreas Brombach",
      "Jie Song",
      "Otmar Hilliges",
      "Christian Holz"
    ],
    "abstract": "Emotions are known to mediate the relationship between users' content\nconsumption and their online engagement, with heightened emotional intensity\nleading to increased engagement. Building on this insight, we propose three\nregressor-guided image editing approaches aimed at diminishing the emotional\nimpact of images. These include (i) a parameter optimization approach based on\nglobal image transformations known to influence emotions, (ii) an optimization\napproach targeting the style latent space of a generative adversarial network,\nand (iii) a diffusion-based approach employing classifier guidance and\nclassifier-free guidance. Our findings demonstrate that approaches can\neffectively alter the emotional properties of images while maintaining high\nvisual quality. Optimization-based methods primarily adjust low-level\nproperties like color hues and brightness, whereas the diffusion-based approach\nintroduces semantic changes, such as altering appearance or facial expressions.\nNotably, results from a behavioral study reveal that only the diffusion-based\napproach successfully elicits changes in viewers' emotional responses while\npreserving high perceived image quality. In future work, we will investigate\nthe impact of these image adaptations on internet user behavior.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CV",
    "comment": "39 pages, 22 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.12289v1",
    "published_date": "2025-01-21 16:59:13 UTC",
    "updated_date": "2025-01-21 16:59:13 UTC"
  },
  {
    "arxiv_id": "2501.12285v1",
    "title": "Implementation of an Asymmetric Adjusted Activation Function for Class Imbalance Credit Scoring",
    "authors": [
      "Xia Li",
      "Hanghang Zheng",
      "Kunpeng Tao",
      "Mao Mao"
    ],
    "abstract": "Credit scoring is a systematic approach to evaluate a borrower's probability\nof default (PD) on a bank loan. The data associated with such scenarios are\ncharacteristically imbalanced, complicating binary classification owing to the\noften-underestimated cost of misclassification during the classifier's learning\nprocess. Considering the high imbalance ratio (IR) of these datasets, we\nintroduce an innovative yet straightforward optimized activation function by\nincorporating an IR-dependent asymmetric adjusted factor embedded Sigmoid\nactivation function (ASIG). The embedding of ASIG makes the sensitive margin of\nthe Sigmoid function auto-adjustable, depending on the imbalance nature of the\ndatasets distributed, thereby giving the activation function an asymmetric\ncharacteristic that prevents the underrepresentation of the minority class\n(positive samples) during the classifier's learning process. The experimental\nresults show that the ASIG-embedded-classifier outperforms traditional\nclassifiers on datasets across wide-ranging IRs in the downstream\ncredit-scoring task. The algorithm also shows robustness and stability, even\nwhen the IR is ultra-high. Therefore, the algorithm provides a competitive\nalternative in the financial industry, especially in credit scoring, possessing\nthe ability to effectively process highly imbalanced distribution data.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-fin.RM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12285v1",
    "published_date": "2025-01-21 16:54:39 UTC",
    "updated_date": "2025-01-21 16:54:39 UTC"
  },
  {
    "arxiv_id": "2501.12432v1",
    "title": "Divide-Then-Aggregate: An Efficient Tool Learning Method via Parallel Tool Invocation",
    "authors": [
      "Dongsheng Zhu",
      "Weixian Shi",
      "Zhengliang Shi",
      "Zhaochun Ren",
      "Shuaiqiang Wang",
      "Lingyong Yan",
      "Dawei Yin"
    ],
    "abstract": "Although current Large Language Models (LLMs) exhibit impressive\ncapabilities, performing complex real-world tasks still requires tool learning.\nMainstream methods, such as CoT/ReAct, rely on step-by-step tool invocation to\ninteract with external environments, but they are limited in perceptual scope\nand lack adequate task-planning capability. To address these limitations, other\nstudies introduce the first Search-based Decision Tree (DFSDT), which still\nsuffers from the high computational cost. In this paper, we introduce a novel\nparallel tool invocation paradigm, DTA-Llama (Divide-Then-Aggregate Llama).\nFirst, we transform traditional tree-based tool search paths into Directed\nAcyclic Graph (DAG) structure, generating a high-quality parallel tool\ninvocation dataset. The DTA-Llama is then trained on the dataset to learn to\niteratively divide the current task into several parallel tool invocation\nsub-tasks and aggregate the invocation results to decide the next actions.\nFurthermore, we introduce an efficient inference framework inspired by the\nProcess/Threads mechanism when applying the DTA-Llama to practical tasks.\nExperimental results show that our approach substantially enhances task\nperformance while reducing token consumption and inference time. Llama2-7B,\nusing our method, is comparable to the official parallel function calling\nmethod of GPT-3.5. The relevant code, dataset, and model weights are available\nat https://corn0205.github.io/",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12432v1",
    "published_date": "2025-01-21 16:49:08 UTC",
    "updated_date": "2025-01-21 16:49:08 UTC"
  },
  {
    "arxiv_id": "2501.12431v2",
    "title": "Modality Interactive Mixture-of-Experts for Fake News Detection",
    "authors": [
      "Yifan Liu",
      "Yaokun Liu",
      "Zelin Li",
      "Ruichen Yao",
      "Yang Zhang",
      "Dong Wang"
    ],
    "abstract": "The proliferation of fake news on social media platforms disproportionately\nimpacts vulnerable populations, eroding trust, exacerbating inequality, and\namplifying harmful narratives. Detecting fake news in multimodal contexts --\nwhere deceptive content combines text and images -- is particularly challenging\ndue to the nuanced interplay between modalities. Existing multimodal fake news\ndetection methods often emphasize cross-modal consistency but ignore the\ncomplex interactions between text and visual elements, which may complement,\ncontradict, or independently influence the predicted veracity of a post. To\naddress these challenges, we present Modality Interactive Mixture-of-Experts\nfor Fake News Detection (MIMoE-FND), a novel hierarchical Mixture-of-Experts\nframework designed to enhance multimodal fake news detection by explicitly\nmodeling modality interactions through an interaction gating mechanism. Our\napproach models modality interactions by evaluating two key aspects of modality\ninteractions: unimodal prediction agreement and semantic alignment. The\nhierarchical structure of MIMoE-FND allows for distinct learning pathways\ntailored to different fusion scenarios, adapting to the unique characteristics\nof each modality interaction. By tailoring fusion strategies to diverse\nmodality interaction scenarios, MIMoE-FND provides a more robust and nuanced\napproach to multimodal fake news detection. We evaluate our approach on three\nreal-world benchmarks spanning two languages, demonstrating its superior\nperformance compared to state-of-the-art methods. By enhancing the accuracy and\ninterpretability of fake news detection, MIMoE-FND offers a promising tool to\nmitigate the spread of misinformation, with the potential to better safeguard\nvulnerable communities against its harmful effects.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "I.2.4"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by the Proceedings of the ACM Web Conference 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.12431v2",
    "published_date": "2025-01-21 16:49:00 UTC",
    "updated_date": "2025-02-26 17:20:53 UTC"
  },
  {
    "arxiv_id": "2501.12275v1",
    "title": "With Great Backbones Comes Great Adversarial Transferability",
    "authors": [
      "Erik Arakelyan",
      "Karen Hambardzumyan",
      "Davit Papikyan",
      "Pasquale Minervini",
      "Albert Gordo",
      "Isabelle Augenstein",
      "Aram H. Markosyan"
    ],
    "abstract": "Advances in self-supervised learning (SSL) for machine vision have improved\nrepresentation robustness and model performance, giving rise to pre-trained\nbackbones like \\emph{ResNet} and \\emph{ViT} models tuned with SSL methods such\nas \\emph{SimCLR}. Due to the computational and data demands of pre-training,\nthe utilization of such backbones becomes a strenuous necessity. However,\nemploying these backbones may inherit vulnerabilities to adversarial attacks.\nWhile adversarial robustness has been studied under \\emph{white-box} and\n\\emph{black-box} settings, the robustness of models tuned on pre-trained\nbackbones remains largely unexplored. Additionally, the role of tuning\nmeta-information in mitigating exploitation risks is unclear. This work\nsystematically evaluates the adversarial robustness of such models across\n$20,000$ combinations of tuning meta-information, including fine-tuning\ntechniques, backbone families, datasets, and attack types. We propose using\nproxy models to transfer attacks, simulating varying levels of target knowledge\nby fine-tuning these proxies with diverse configurations. Our findings reveal\nthat proxy-based attacks approach the effectiveness of \\emph{white-box}\nmethods, even with minimal tuning knowledge. We also introduce a naive\n\"backbone attack,\" leveraging only the backbone to generate adversarial\nsamples, which outperforms \\emph{black-box} attacks and rivals \\emph{white-box}\nmethods, highlighting critical risks in model-sharing practices. Finally, our\nablations reveal how increasing tuning meta-information impacts attack\ntransferability, measuring each meta-information combination.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CR",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12275v1",
    "published_date": "2025-01-21 16:44:51 UTC",
    "updated_date": "2025-01-21 16:44:51 UTC"
  },
  {
    "arxiv_id": "2501.12273v1",
    "title": "Condor: Enhance LLM Alignment with Knowledge-Driven Data Synthesis and Refinement",
    "authors": [
      "Maosong Cao",
      "Taolin Zhang",
      "Mo Li",
      "Chuyu Zhang",
      "Yunxin Liu",
      "Haodong Duan",
      "Songyang Zhang",
      "Kai Chen"
    ],
    "abstract": "The quality of Supervised Fine-Tuning (SFT) data plays a critical role in\nenhancing the conversational capabilities of Large Language Models (LLMs).\nHowever, as LLMs become more advanced, the availability of high-quality\nhuman-annotated SFT data has become a significant bottleneck, necessitating a\ngreater reliance on synthetic training data. In this work, we introduce Condor,\na novel two-stage synthetic data generation framework that incorporates World\nKnowledge Tree and Self-Reflection Refinement to produce high-quality SFT data\nat scale. Our experimental results demonstrate that a base model fine-tuned on\nonly 20K Condor-generated samples achieves superior performance compared to\ncounterparts. The additional refinement stage in Condor further enables\niterative self-improvement for LLMs at various scales (up to 72B), validating\nthe effectiveness of our approach. Furthermore, our investigation into the\nscaling for synthetic data in post-training reveals substantial unexplored\npotential for performance improvements, opening promising avenues for future\nresearch.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Tech Report. Github: https://github.com/InternLM/Condor",
    "pdf_url": "http://arxiv.org/pdf/2501.12273v1",
    "published_date": "2025-01-21 16:44:12 UTC",
    "updated_date": "2025-01-21 16:44:12 UTC"
  },
  {
    "arxiv_id": "2501.12266v1",
    "title": "CBVLM: Training-free Explainable Concept-based Large Vision Language Models for Medical Image Classification",
    "authors": [
      "Cristiano Patrício",
      "Isabel Rio-Torto",
      "Jaime S. Cardoso",
      "Luís F. Teixeira",
      "João C. Neves"
    ],
    "abstract": "The main challenges limiting the adoption of deep learning-based solutions in\nmedical workflows are the availability of annotated data and the lack of\ninterpretability of such systems. Concept Bottleneck Models (CBMs) tackle the\nlatter by constraining the final disease prediction on a set of predefined and\nhuman-interpretable concepts. However, the increased interpretability achieved\nthrough these concept-based explanations implies a higher annotation burden.\nMoreover, if a new concept needs to be added, the whole system needs to be\nretrained. Inspired by the remarkable performance shown by Large\nVision-Language Models (LVLMs) in few-shot settings, we propose a simple, yet\neffective, methodology, CBVLM, which tackles both of the aforementioned\nchallenges. First, for each concept, we prompt the LVLM to answer if the\nconcept is present in the input image. Then, we ask the LVLM to classify the\nimage based on the previous concept predictions. Moreover, in both stages, we\nincorporate a retrieval module responsible for selecting the best examples for\nin-context learning. By grounding the final diagnosis on the predicted\nconcepts, we ensure explainability, and by leveraging the few-shot capabilities\nof LVLMs, we drastically lower the annotation cost. We validate our approach\nwith extensive experiments across four medical datasets and twelve LVLMs (both\ngeneric and medical) and show that CBVLM consistently outperforms CBMs and\ntask-specific supervised methods without requiring any training and using just\na few annotated examples. More information on our project page:\nhttps://cristianopatricio.github.io/CBVLM/.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "This work has been submitted to the IEEE for possible publication",
    "pdf_url": "http://arxiv.org/pdf/2501.12266v1",
    "published_date": "2025-01-21 16:38:04 UTC",
    "updated_date": "2025-01-21 16:38:04 UTC"
  },
  {
    "arxiv_id": "2501.12231v1",
    "title": "InsTALL: Context-aware Instructional Task Assistance with Multi-modal Large Language Models",
    "authors": [
      "Pha Nguyen",
      "Sailik Sengupta",
      "Girik Malik",
      "Arshit Gupta",
      "Bonan Min"
    ],
    "abstract": "The improved competence of generative models can help building multi-modal\nvirtual assistants that leverage modalities beyond language. By observing\nhumans performing multi-step tasks, one can build assistants that have\nsituational awareness of actions and tasks being performed, enabling them to\ncater assistance based on this understanding. In this paper, we develop a\nContext-aware Instructional Task Assistant with Multi-modal Large Language\nModels (InsTALL) that leverages an online visual stream (e.g. a user's screen\nshare or video recording) and responds in real-time to user queries related to\nthe task at hand. To enable useful assistance, InsTALL 1) trains a multi-modal\nmodel on task videos and paired textual data, and 2) automatically extracts\ntask graph from video data and leverages it at training and inference time. We\nshow InsTALL achieves state-of-the-art performance across proposed sub-tasks\nconsidered for multimodal activity understanding -- task recognition (TR),\naction recognition (AR), next action prediction (AP), and plan prediction (PP)\n-- and outperforms existing baselines on two novel sub-tasks related to\nautomatic error identification.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12231v1",
    "published_date": "2025-01-21 15:55:06 UTC",
    "updated_date": "2025-01-21 15:55:06 UTC"
  },
  {
    "arxiv_id": "2501.12430v1",
    "title": "SCFCRC: Simultaneously Counteract Feature Camouflage and Relation Camouflage for Fraud Detection",
    "authors": [
      "Xiaocheng Zhang",
      "Zhuangzhuang Ye",
      "GuoPing Zhao",
      "Jianing Wang",
      "Xiaohong Su"
    ],
    "abstract": "In fraud detection, fraudsters often interact with many benign users,\ncamouflaging their features or relations to hide themselves. Most existing work\nconcentrates solely on either feature camouflage or relation camouflage, or\ndecoupling feature learning and relation learning to avoid the two camouflage\nfrom affecting each other. However, this inadvertently neglects the valuable\ninformation derived from features or relations, which could mutually enhance\ntheir adversarial camouflage strategies. In response to this gap, we propose\nSCFCRC, a Transformer-based fraud detector that Simultaneously Counteract\nFeature Camouflage and Relation Camouflage. SCFCRC consists of two components:\nFeature Camouflage Filter and Relation Camouflage Refiner. The feature\ncamouflage filter utilizes pseudo labels generated through label propagation to\ntrain the filter and uses contrastive learning that combines instance-wise and\nprototype-wise to improve the quality of features. The relation camouflage\nrefiner uses Mixture-of-Experts(MoE) network to disassemble the multi-relations\ngraph into multiple substructures and divide and conquer them to mitigate the\ndegradation of detection performance caused by relation camouflage.\nFurthermore, we introduce a regularization method for MoE to enhance the\nrobustness of the model. Extensive experiments on two fraud detection benchmark\ndatasets demonstrate that our method outperforms state-of-the-art baselines.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12430v1",
    "published_date": "2025-01-21 15:50:51 UTC",
    "updated_date": "2025-01-21 15:50:51 UTC"
  },
  {
    "arxiv_id": "2501.12222v2",
    "title": "High-temperature superconductivity in Li$_2$AuH$_6$ mediated by strong electron-phonon coupling under ambient pressure",
    "authors": [
      "Zhenfeng Ouyang",
      "Bo-Wen Yao",
      "Xiao-Qi Han",
      "Peng-Jie Guo",
      "Ze-Feng Gao",
      "Zhong-Yi Lu"
    ],
    "abstract": "We used our developed AI search engine~(InvDesFlow) to perform extensive\ninvestigations regarding ambient stable superconducting hydrides. A cubic\nstructure Li$_2$AuH$_6$ with Au-H octahedral motifs is identified to be a\ncandidate. After performing thermodynamical analysis, we provide a feasible\nroute to experimentally synthesize this material via the known LiAu and LiH\ncompounds under ambient pressure. The further first-principles calculations\nsuggest that Li$_2$AuH$_6$ shows a high superconducting transition temperature\n($T_c$) $\\sim$ 140 K under ambient pressure. The H-1$s$ electrons strongly\ncouple with phonon modes of vibrations of Au-H octahedrons as well as\nvibrations of Li atoms, where the latter is not taken seriously in other\npreviously similar cases. Hence, different from previous claims of searching\nmetallic covalent bonds to find high-$T_c$ superconductors, we emphasize here\nthe importance of those phonon modes with strong electron-phonon coupling\n(EPC). And we suggest that one can intercalate atoms into binary or ternary\nhydrides to introduce more potential phonon modes with strong EPC, which is an\neffective approach to find high-$T_c$ superconductors within multicomponent\ncompounds.",
    "categories": [
      "cond-mat.supr-con",
      "cond-mat.mtrl-sci",
      "cs.AI",
      "physics.comp-ph"
    ],
    "primary_category": "cond-mat.supr-con",
    "comment": "6 pages; 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.12222v2",
    "published_date": "2025-01-21 15:48:27 UTC",
    "updated_date": "2025-05-14 02:30:29 UTC"
  },
  {
    "arxiv_id": "2502.00025v3",
    "title": "Leveraging Large Language Models to Enhance Machine Learning Interpretability and Predictive Performance: A Case Study on Emergency Department Returns for Mental Health Patients",
    "authors": [
      "Abdulaziz Ahmed",
      "Mohammad Saleem",
      "Mohammed Alzeen",
      "Badari Birur",
      "Rachel E Fargason",
      "Bradley G Burk",
      "Hannah Rose Harkins",
      "Ahmed Alhassan",
      "Mohammed Ali Al-Garadi"
    ],
    "abstract": "Importance: Emergency department (ED) returns for mental health conditions\npose a major healthcare burden, with 24-27% of patients returning within 30\ndays. Traditional machine learning models for predicting these returns often\nlack interpretability for clinical use.\n  Objective: To assess whether integrating large language models (LLMs) with\nmachine learning improves predictive accuracy and clinical interpretability of\nED mental health return risk models.\n  Methods: This retrospective cohort study analyzed 42,464 ED visits for 27,904\nunique mental health patients at an academic medical center in the Deep South\nfrom January 2018 to December 2022.\n  Main Outcomes and Measures: Two primary outcomes were evaluated: (1) 30-day\nED return prediction accuracy and (2) model interpretability using a novel\nLLM-enhanced framework integrating SHAP (SHapley Additive exPlanations) values\nwith clinical knowledge.\n  Results: For chief complaint classification, LLaMA 3 (8B) with 10-shot\nlearning outperformed traditional models (accuracy: 0.882, F1-score: 0.86). In\nSDoH classification, LLM-based models achieved 0.95 accuracy and 0.96 F1-score,\nwith Alcohol, Tobacco, and Substance Abuse performing best (F1: 0.96-0.89),\nwhile Exercise and Home Environment showed lower performance (F1: 0.70-0.67).\nThe LLM-based interpretability framework achieved 99% accuracy in translating\nmodel predictions into clinically relevant explanations. LLM-extracted features\nimproved XGBoost AUC from 0.74 to 0.76 and AUC-PR from 0.58 to 0.61.\n  Conclusions and Relevance: Integrating LLMs with machine learning models\nyielded modest but consistent accuracy gains while significantly enhancing\ninterpretability through automated, clinically relevant explanations. This\napproach provides a framework for translating predictive analytics into\nactionable clinical insights.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.00025v3",
    "published_date": "2025-01-21 15:41:20 UTC",
    "updated_date": "2025-02-14 03:10:58 UTC"
  },
  {
    "arxiv_id": "2501.14823v2",
    "title": "Quantifying Energy and Cost Benefits of Hybrid Edge Cloud: Analysis of Traditional and Agentic Workloads",
    "authors": [
      "Siavash Alamouti"
    ],
    "abstract": "This paper examines the workload distribution challenges in centralized cloud\nsystems and demonstrates how Hybrid Edge Cloud (HEC) [1] mitigates these\ninefficiencies. Workloads in cloud environments often follow a Pareto\ndistribution, where a small percentage of tasks consume most resources, leading\nto bottlenecks and energy inefficiencies. By analyzing both traditional\nworkloads reflective of typical IoT and smart device usage and agentic\nworkloads, such as those generated by AI agents, robotics, and autonomous\nsystems, this study quantifies the energy and cost savings enabled by HEC. Our\nfindings reveal that HEC achieves energy savings of up to 75% and cost\nreductions exceeding 80%, even in resource-intensive agentic scenarios. These\nresults highlight the critical role of HEC in enabling scalable,\ncost-effective, and sustainable computing for the next generation of\nintelligent systems.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "13 pages, 2 Tables, 3 Figures",
    "pdf_url": "http://arxiv.org/pdf/2501.14823v2",
    "published_date": "2025-01-21 15:26:43 UTC",
    "updated_date": "2025-01-29 13:51:39 UTC"
  },
  {
    "arxiv_id": "2501.14822v1",
    "title": "Controlling Ensemble Variance in Diffusion Models: An Application for Reanalyses Downscaling",
    "authors": [
      "Fabio Merizzi",
      "Davide Evangelista",
      "Harilaos Loukos"
    ],
    "abstract": "In recent years, diffusion models have emerged as powerful tools for\ngenerating ensemble members in meteorology. In this work, we demonstrate that a\nDenoising Diffusion Implicit Model (DDIM) can effectively control ensemble\nvariance by varying the number of diffusion steps. Introducing a theoretical\nframework, we relate diffusion steps to the variance expressed by the reverse\ndiffusion process. Focusing on reanalysis downscaling, we propose an ensemble\ndiffusion model for the full ERA5-to-CERRA domain, generating\nvariance-calibrated ensemble members for wind speed at full spatial and\ntemporal resolution. Our method aligns global mean variance with a reference\nensemble dataset and ensures spatial variance is distributed in accordance with\nobserved meteorological variability. Additionally, we address the lack of\nensemble information in the CARRA dataset, showcasing the utility of our\napproach for efficient, high-resolution ensemble generation.",
    "categories": [
      "stat.AP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.AP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.14822v1",
    "published_date": "2025-01-21 15:02:57 UTC",
    "updated_date": "2025-01-21 15:02:57 UTC"
  },
  {
    "arxiv_id": "2501.12194v1",
    "title": "An End-to-End Approach for Korean Wakeword Systems with Speaker Authentication",
    "authors": [
      "Geonwoo Seo"
    ],
    "abstract": "Wakeword detection plays a critical role in enabling AI assistants to listen\nto user voices and interact effectively. However, for languages other than\nEnglish, there is a significant lack of pre-trained wakeword models.\nAdditionally, systems that merely determine the presence of a wakeword can pose\nserious privacy concerns. In this paper, we propose an end-to-end approach that\ntrains wakewords for Non-English languages, particulary Korean, and uses this\nto develop a Voice Authentication model to protect user privacy. Our\nimplementation employs an open-source platform OpenWakeWord, which performs\nwakeword detection using an FCN (Fully-Connected Network) architecture. Once a\nwakeword is detected, our custom-developed code calculates cosine similarity\nfor robust user authentication. Experimental results demonstrate the\neffectiveness of our approach, achieving a 16.79% and a 6.6% Equal Error Rate\n(EER) each in the Wakeword Detection and the Voice Authentication. These\nfindings highlight the model's potential in providing secure and accurate\nwakeword detection and authentication for Korean users.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS",
      "I.2.7; I.5.4"
    ],
    "primary_category": "cs.SD",
    "comment": "19 pages, 10 figures, implementation code available at\n  https://github.com/gws8820/securewakeword-model,\n  https://github.com/gws8820/wyoming-securewakeword, demo video at\n  https://www.youtube.com/watch?v=F3AXUbL-i-o",
    "pdf_url": "http://arxiv.org/pdf/2501.12194v1",
    "published_date": "2025-01-21 15:02:31 UTC",
    "updated_date": "2025-01-21 15:02:31 UTC"
  },
  {
    "arxiv_id": "2501.12429v1",
    "title": "Fuel Efficiency Analysis of the Public Transportation System Based on the Gaussian Mixture Model Clustering",
    "authors": [
      "Zhipeng Ma",
      "Bo Nørregaard Jørgensen",
      "Zheng Ma"
    ],
    "abstract": "Public transportation is a major source of greenhouse gas emissions,\nhighlighting the need to improve bus fuel efficiency. Clustering algorithms\nassist in analyzing fuel efficiency by grouping data into clusters, but\nirrelevant features may complicate the analysis and choosing the optimal number\nof clusters remains a challenging task. Therefore, this paper employs the\nGaussian mixture models to cluster the solo fuel-efficiency dataset. Moreover,\nan integration method that combines the Silhouette index, Calinski-Harabasz\nindex, and Davies-Bouldin index is developed to select the optimal cluster\nnumbers. A dataset with 4006 bus trips in North Jutland, Denmark is utilized as\nthe case study. Trips are first split into three groups, then one group is\ndivided further, resulting in four categories: extreme, normal, low, and\nextremely low fuel efficiency. A preliminary study using visualization analysis\nis conducted to investigate how driving behaviors and route conditions affect\nfuel efficiency. The results indicate that both individual driving habits and\nroute characteristics have a significant influence on fuel efficiency.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12429v1",
    "published_date": "2025-01-21 14:25:29 UTC",
    "updated_date": "2025-01-21 14:25:29 UTC"
  },
  {
    "arxiv_id": "2501.12162v2",
    "title": "AdaServe: Accelerating Multi-SLO LLM Serving with SLO-Customized Speculative Decoding",
    "authors": [
      "Zikun Li",
      "Zhuofu Chen",
      "Remi Delacourt",
      "Gabriele Oliaro",
      "Zeyu Wang",
      "Qinghan Chen",
      "Shuhuai Lin",
      "April Yang",
      "Zhihao Zhang",
      "Zhuoming Chen",
      "Sean Lai",
      "Xinhao Cheng",
      "Xupeng Miao",
      "Zhihao Jia"
    ],
    "abstract": "Modern large language model (LLM) applications exhibit diverse service-level\nobjectives (SLOs), from low-latency requirements in interactive coding\nassistants to more relaxed constraints in data wrangling tasks. Existing LLM\nserving systems, which rely on uniform batching and scheduling strategies,\noften fail to meet these heterogeneous SLOs concurrently. We present AdaServe,\nthe first LLM serving system designed to support efficient multi-SLO serving\nthrough SLO-customized speculative decoding. AdaServe formulates multi-SLO\nserving as a constrained optimization problem and introduces a hardware-aware\nalgorithm that constructs a speculation tree tailored to each request's latency\ntarget. It features a speculate-select-verify pipeline that enables\nfine-grained control over decoding speed while maximizing system throughput.\nAdaServe further adapts to workload variation by dynamically adjusting\nspeculation parameters. Evaluations across diverse workloads show that AdaServe\nreduces SLO violations by up to 4.3$\\times$ and improves goodput by up to\n1.9$\\times$ compared to the best performing baselines, highlighting its\neffectiveness in multi-SLO serving.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DC",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12162v2",
    "published_date": "2025-01-21 14:15:01 UTC",
    "updated_date": "2025-05-17 07:09:10 UTC"
  },
  {
    "arxiv_id": "2501.12149v1",
    "title": "On the practical applicability of modern DFT functionals for chemical computations. Case study of DM21 applicability for geometry optimization",
    "authors": [
      "Kirill Kulaev",
      "Alexander Ryabov",
      "Michael Medvedev",
      "Evgeny Burnaev",
      "Vladimir Vanovskiy"
    ],
    "abstract": "Density functional theory (DFT) is probably the most promising approach for\nquantum chemistry calculations considering its good balance between\ncalculations precision and speed. In recent years, several neural network-based\nfunctionals have been developed for exchange-correlation energy approximation\nin DFT, DM21 developed by Google Deepmind being the most notable between them.\nThis study focuses on evaluating the efficiency of DM21 functional in\npredicting molecular geometries, with a focus on the influence of oscillatory\nbehavior in neural network exchange-correlation functionals. We implemented\ngeometry optimization in PySCF for the DM21 functional in geometry optimization\nproblem, compared its performance with traditional functionals, and tested it\non various benchmarks. Our findings reveal both the potential and the current\nchallenges of using neural network functionals for geometry optimization in\nDFT. We propose a solution extending the practical applicability of such\nfunctionals and allowing to model new substances with their help.",
    "categories": [
      "physics.comp-ph",
      "cond-mat.mtrl-sci",
      "cs.AI"
    ],
    "primary_category": "physics.comp-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12149v1",
    "published_date": "2025-01-21 14:01:06 UTC",
    "updated_date": "2025-01-21 14:01:06 UTC"
  },
  {
    "arxiv_id": "2501.12147v1",
    "title": "Improving Influence-based Instruction Tuning Data Selection for Balanced Learning of Diverse Capabilities",
    "authors": [
      "Qirun Dai",
      "Dylan Zhang",
      "Jiaqi W. Ma",
      "Hao Peng"
    ],
    "abstract": "Selecting appropriate training data is crucial for effective instruction\nfine-tuning of large language models (LLMs), which aims to (1) elicit strong\ncapabilities, and (2) achieve balanced performance across a diverse range of\ntasks. Influence-based methods show promise in achieving (1) by estimating the\ncontribution of each training example to the model's predictions, but often\nstruggle with (2). Our systematic investigation reveals that this\nunderperformance can be attributed to an inherent bias where certain tasks\nintrinsically have greater influence than others. As a result, data selection\nis often biased towards these tasks, not only hurting the model's performance\non others but also, counterintuitively, harms performance on these\nhigh-influence tasks themselves.\n  As a remedy, we propose BIDS, a Balanced and Influential Data Selection\nalgorithm. BIDS first normalizes influence scores of the training data, and\nthen iteratively balances data selection by choosing the training example with\nthe highest influence on the most underrepresented task. Experiments with both\nLlama-3 and Mistral-v0.3 on seven benchmarks spanning five diverse capabilities\nshow that BIDS consistently outperforms both state-of-the-art influence-based\nalgorithms and other non-influence-based selection frameworks. Surprisingly,\ntraining on a 15% subset selected by BIDS can even outperform full-dataset\ntraining with a much more balanced performance. Our analysis further highlights\nthe importance of both instance-level normalization and iterative optimization\nof selected data for balanced learning of diverse capabilities.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12147v1",
    "published_date": "2025-01-21 14:00:43 UTC",
    "updated_date": "2025-01-21 14:00:43 UTC"
  },
  {
    "arxiv_id": "2501.12428v2",
    "title": "SplitQuant: Layer Splitting for Low-Bit Neural Network Quantization",
    "authors": [
      "Jaewoo Song",
      "Fangzhen Lin"
    ],
    "abstract": "Quantization for deep neural networks (DNNs) is the process of mapping the\nparameter values of DNNs from original data types to other data types of lower\nprecision to reduce model sizes and make inference faster. Quantization often\nmaps different original values to a single quantized value because the range of\nthe original values is larger than the range of the quantized values. This\nleads to the degradation of the accuracy of the quantized DNNs. Outliers are a\nmain cause of the degradation of quantization resolution because they enlarge\nthe range of original values. To solve the problem, the percentile method is\noften used to clip outliers. However, clipping the outliers has another problem\nof removing the important and strong signals in the DNNs. This paper proposes\nSplitQuant to keep the outliers and improve the quantization resolution at the\nsame time. SplitQuant narrows down the range of the original values and\nmitigates the effect of outliers by splitting each quantizable layer into three\nmathematically equivalent layers and applies different scaling factors.\nEspecially, weights and biases are clustered into lower, middle and upper\nclusters for optimized split. By preprocessing DNNs with SplitQuant,\nquantization algorithms can achieve better results. SplitQuant was applied on\ntwo BERT-Tiny models and improved the accuracy of INT2 quantization by 3.3%p\nand 2.1%p, achieving accuracies comparable to those of the original FP32\nmodels.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted as a full paper by the 2025 EDGE AI FOUNDATION Austin",
    "pdf_url": "http://arxiv.org/pdf/2501.12428v2",
    "published_date": "2025-01-21 13:53:16 UTC",
    "updated_date": "2025-02-06 12:42:45 UTC"
  },
  {
    "arxiv_id": "2501.12123v1",
    "title": "FedCLEAN: byzantine defense by CLustering Errors of Activation maps in Non-IID federated learning environments",
    "authors": [
      "Mehdi Ben Ghali",
      "Reda Bellafqira",
      "Gouenou Coatrieux"
    ],
    "abstract": "Federated Learning (FL) enables clients to collaboratively train a global\nmodel using their local datasets while reinforcing data privacy. However, FL is\nsusceptible to poisoning attacks. Existing defense mechanisms assume that\nclients' data are independent and identically distributed (IID), making them\nineffective in real-world applications where data are non-IID. This paper\npresents FedCLEAN, the first defense capable of filtering attackers' model\nupdates in a non-IID FL environment. The originality of FedCLEAN is twofold.\nFirst, it relies on a client confidence score derived from the reconstruction\nerrors of each client's model activation maps for a given trigger set, with\nreconstruction errors obtained by means of a Conditional Variational\nAutoencoder trained according to a novel server-side strategy. Second, we\npropose an ad-hoc trust propagation algorithm based on client scores, which\nallows building a cluster of benign clients while flagging potential attackers.\nExperimental results on the datasets MNIST and FashionMNIST demonstrate the\nrobustness of FedCLEAN against Byzantine attackers in non-IID scenarios and a\nclose-to-zero benign client misclassification rate, even in the absence of an\nattack.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "19 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.12123v1",
    "published_date": "2025-01-21 13:37:28 UTC",
    "updated_date": "2025-01-21 13:37:28 UTC"
  },
  {
    "arxiv_id": "2501.12427v1",
    "title": "SafePowerGraph-HIL: Real-Time HIL Validation of Heterogeneous GNNs for Bridging Sim-to-Real Gap in Power Grids",
    "authors": [
      "Aoxiang Ma",
      "Salah Ghamizi",
      "Jun Cao",
      "Pedro Rodriguez"
    ],
    "abstract": "As machine learning (ML) techniques gain prominence in power system research,\nvalidating these methods' effectiveness under real-world conditions requires\nreal-time hardware-in-the-loop (HIL) simulations. HIL simulation platforms\nenable the integration of computational models with physical devices, allowing\nrigorous testing across diverse scenarios critical to system resilience and\nreliability. In this study, we develop a SafePowerGraph-HIL framework that\nutilizes HIL simulations on the IEEE 9-bus system, modeled in Hypersim, to\ngenerate high-fidelity data, which is then transmitted in real-time via SCADA\nto an AWS cloud database before being input into a Heterogeneous Graph Neural\nNetwork (HGNN) model designed for power system state estimation and dynamic\nanalysis. By leveraging Hypersim's capabilities, we simulate complex grid\ninteractions, providing a robust dataset that captures critical parameters for\nHGNN training. The trained HGNN is subsequently validated using newly generated\ndata under varied system conditions, demonstrating accuracy and robustness in\npredicting power system states. The results underscore the potential of\nintegrating HIL with advanced neural network architectures to enhance the\nreal-time operational capabilities of power systems. This approach represents a\nsignificant advancement toward the development of intelligent, adaptive control\nstrategies that support the robustness and resilience of evolving power grids.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "5 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.12427v1",
    "published_date": "2025-01-21 13:36:38 UTC",
    "updated_date": "2025-01-21 13:36:38 UTC"
  },
  {
    "arxiv_id": "2501.12121v4",
    "title": "Learning Dynamic Representations via An Optimally-Weighted Maximum Mean Discrepancy Optimization Framework for Continual Learning",
    "authors": [
      "KaiHui Huang",
      "RunQing Wu",
      "JinHui Shen",
      "HanYi Zhang",
      "Ling Ge",
      "JiGuo Yu",
      "Fei Ye"
    ],
    "abstract": "Continual learning has emerged as a pivotal area of research, primarily due\nto its advantageous characteristic that allows models to persistently acquire\nand retain information. However, catastrophic forgetting can severely impair\nmodel performance. In this study, we address network forgetting by introducing\na novel framework termed Optimally-Weighted Maximum Mean Discrepancy (OWMMD),\nwhich imposes penalties on representation alterations via a Multi-Level Feature\nMatching Mechanism (MLFMM). Furthermore, we propose an Adaptive Regularization\nOptimization (ARO) strategy to refine the adaptive weight vectors, which\nautonomously assess the significance of each feature layer throughout the\noptimization process, The proposed ARO approach can relieve the\nover-regularization problem and promote the future task learning. We conduct a\ncomprehensive series of experiments, benchmarking our proposed method against\nseveral established baselines. The empirical findings indicate that our\napproach achieves state-of-the-art performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12121v4",
    "published_date": "2025-01-21 13:33:45 UTC",
    "updated_date": "2025-04-13 15:38:39 UTC"
  },
  {
    "arxiv_id": "2501.12116v1",
    "title": "Efficient PINNs: Multi-Head Unimodular Regularization of the Solutions Space",
    "authors": [
      "Pedro Tarancón-Álvarez",
      "Pablo Tejerina-Pérez",
      "Raul Jimenez",
      "Pavlos Protopapas"
    ],
    "abstract": "We present a machine learning framework to facilitate the solution of\nnonlinear multiscale differential equations and, especially, inverse problems\nusing Physics-Informed Neural Networks (PINNs). This framework is based on what\nis called multihead (MH) training, which involves training the network to learn\na general space of all solutions for a given set of equations with certain\nvariability, rather than learning a specific solution of the system. This setup\nis used with a second novel technique that we call Unimodular Regularization\n(UR) of the latent space of solutions. We show that the multihead approach,\ncombined with the regularization, significantly improves the efficiency of\nPINNs by facilitating the transfer learning process thereby enabling the\nfinding of solutions for nonlinear, coupled, and multiscale differential\nequations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "hep-th",
      "math.AP"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12116v1",
    "published_date": "2025-01-21 13:25:56 UTC",
    "updated_date": "2025-01-21 13:25:56 UTC"
  },
  {
    "arxiv_id": "2501.13126v2",
    "title": "Preference Curriculum: LLMs Should Always Be Pretrained on Their Preferred Data",
    "authors": [
      "Xuemiao Zhang",
      "Liangyu Xu",
      "Feiyu Duan",
      "Yongwei Zhou",
      "Sirui Wang",
      "Rongxiang Weng",
      "Jingang Wang",
      "Xunliang Cai"
    ],
    "abstract": "Large language models (LLMs) generally utilize a consistent data distribution\nthroughout the pretraining process. However, as the model's capability\nimproves, it is intuitive that its data preferences dynamically change,\nindicating the need for pretraining with different data at various training\nstages. To achieve it, we propose the Perplexity Difference (PD) based\nPreference Curriculum learning (PDPC) framework, which always perceives and\nuses the data preferred by LLMs to train and boost them. First, we introduce\nthe PD metric to quantify the difference in how challenging a sample is for\nweak versus strong models. Samples with high PD are more challenging for weak\nmodels to learn and are more suitable to be arranged in the later stage of\npretraining. Second, we propose the preference function to approximate and\npredict the data preference of the LLM at any training step, so as to complete\nthe arrangement of the dataset offline and ensure continuous training without\ninterruption. Experimental results on 1.3B and 3B models demonstrate that PDPC\nsignificantly surpasses baselines. Notably, the 3B model trained on 1T tokens\nachieves an increased average accuracy of over 8.1% across MMLU and CMMLU.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages, 13 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.13126v2",
    "published_date": "2025-01-21 13:12:13 UTC",
    "updated_date": "2025-02-17 11:44:35 UTC"
  },
  {
    "arxiv_id": "2501.12106v3",
    "title": "Can open source large language models be used for tumor documentation in Germany? -- An evaluation on urological doctors' notes",
    "authors": [
      "Stefan Lenz",
      "Arsenij Ustjanzew",
      "Marco Jeray",
      "Meike Ressing",
      "Torsten Panholzer"
    ],
    "abstract": "Tumor documentation in Germany is largely done manually, requiring reading\npatient records and entering data into structured databases. Large language\nmodels (LLMs) could potentially enhance this process by improving efficiency\nand reliability. This evaluation tests eleven different open source LLMs with\nsizes ranging from 1-70 billion model parameters on three basic tasks of the\ntumor documentation process: identifying tumor diagnoses, assigning ICD-10\ncodes, and extracting the date of first diagnosis. For evaluating the LLMs on\nthese tasks, a dataset of annotated text snippets based on anonymized doctors'\nnotes from urology was prepared. Different prompting strategies were used to\ninvestigate the effect of the number of examples in few-shot prompting and to\nexplore the capabilities of the LLMs in general. The models Llama 3.1 8B,\nMistral 7B, and Mistral NeMo 12 B performed comparably well in the tasks.\nModels with less extensive training data or having fewer than 7 billion\nparameters showed notably lower performance, while larger models did not\ndisplay performance gains. Examples from a different medical domain than\nurology could also improve the outcome in few-shot prompting, which\ndemonstrates the ability of LLMs to handle tasks needed for tumor\ndocumentation. Open source LLMs show a strong potential for automating tumor\ndocumentation. Models from 7-12 billion parameters could offer an optimal\nbalance between performance and resource efficiency. With tailored fine-tuning\nand well-designed prompting, these models might become important tools for\nclinical documentation in the future. The code for the evaluation is available\nfrom https://github.com/stefan-m-lenz/UroLlmEval. We also release the dataset\nas a new valuable resource that addresses the shortage of authentic and easily\naccessible benchmarks in German-language medical NLP.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "53 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.12106v3",
    "published_date": "2025-01-21 12:56:47 UTC",
    "updated_date": "2025-05-09 15:45:53 UTC"
  },
  {
    "arxiv_id": "2501.12104v3",
    "title": "Teacher Encoder-Student Decoder Denoising Guided Segmentation Network for Anomaly Detection",
    "authors": [
      "Shixuan Song",
      "Hao Chen",
      "Shu Hu",
      "Xin Wang",
      "Jinrong Hu",
      "Xi Wu"
    ],
    "abstract": "Visual anomaly detection is a highly challenging task, often categorized as a\none-class classification and segmentation problem. Recent studies have\ndemonstrated that the student-teacher (S-T) framework effectively addresses\nthis challenge. However, most S-T frameworks rely solely on pre-trained teacher\nnetworks to guide student networks in learning multi-scale similar features,\noverlooking the potential of the student networks to enhance learning through\nmulti-scale feature fusion. In this study, we propose a novel model named\nPFADSeg, which integrates a pre-trained teacher network, a denoising student\nnetwork with multi-scale feature fusion, and a guided anomaly segmentation\nnetwork into a unified framework. By adopting a unique teacher-encoder and\nstudent-decoder denoising mode, the model improves the student network's\nability to learn from teacher network features. Furthermore, an adaptive\nfeature fusion mechanism is introduced to train a self-supervised segmentation\nnetwork that synthesizes anomaly masks autonomously, significantly increasing\ndetection performance. Evaluated on the MVTec AD dataset, PFADSeg achieves\nstate-of-the-art results with an image-level AUC of 98.9%, a pixel-level mean\nprecision of 76.4%, and an instance-level mean precision of 78.7%.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12104v3",
    "published_date": "2025-01-21 12:55:04 UTC",
    "updated_date": "2025-01-24 08:20:19 UTC"
  },
  {
    "arxiv_id": "2501.12102v1",
    "title": "Proxies for Distortion and Consistency with Applications for Real-World Image Restoration",
    "authors": [
      "Sean Man",
      "Guy Ohayon",
      "Ron Raphaeli",
      "Michael Elad"
    ],
    "abstract": "Real-world image restoration deals with the recovery of images suffering from\nan unknown degradation. This task is typically addressed while being given only\ndegraded images, without their corresponding ground-truth versions. In this\nhard setting, designing and evaluating restoration algorithms becomes highly\nchallenging. This paper offers a suite of tools that can serve both the design\nand assessment of real-world image restoration algorithms. Our work starts by\nproposing a trained model that predicts the chain of degradations a given\nreal-world measured input has gone through. We show how this estimator can be\nused to approximate the consistency -- the match between the measurements and\nany proposed recovered image. We also use this estimator as a guiding force for\nthe design of a simple and highly-effective plug-and-play real-world image\nrestoration algorithm, leveraging a pre-trained diffusion-based image prior.\nFurthermore, this work proposes no-reference proxy measures of MSE and LPIPS,\nwhich, without access to the ground-truth images, allow ranking of real-world\nimage restoration algorithms according to their (approximate) MSE and LPIPS.\nThe proposed suite provides a versatile, first of its kind framework for\nevaluating and comparing blind image restoration algorithms in real-world\nscenarios.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page in https://man-sean.github.io/elad-website/",
    "pdf_url": "http://arxiv.org/pdf/2501.12102v1",
    "published_date": "2025-01-21 12:49:30 UTC",
    "updated_date": "2025-01-21 12:49:30 UTC"
  },
  {
    "arxiv_id": "2501.12085v1",
    "title": "Scalable Whole Slide Image Representation Using K-Mean Clustering and Fisher Vector Aggregation",
    "authors": [
      "Ravi Kant Gupta",
      "Shounak Das",
      "Ardhendu Sekhar",
      "Amit Sethi"
    ],
    "abstract": "Whole slide images (WSIs) are high-resolution, gigapixel sized images that\npose significant computational challenges for traditional machine learning\nmodels due to their size and heterogeneity.In this paper, we present a scalable\nand efficient methodology for WSI classification by leveraging patch-based\nfeature extraction, clustering, and Fisher vector encoding. Initially, WSIs are\ndivided into fixed size patches, and deep feature embeddings are extracted from\neach patch using a pre-trained convolutional neural network (CNN). These\npatch-level embeddings are subsequently clustered using K-means clustering,\nwhere each cluster aggregates semantically similar regions of the WSI. To\neffectively summarize each cluster, Fisher vector representations are computed\nby modeling the distribution of patch embeddings in each cluster as a\nparametric Gaussian mixture model (GMM). The Fisher vectors from each cluster\nare concatenated into a high-dimensional feature vector, creating a compact and\ninformative representation of the entire WSI. This feature vector is then used\nby a classifier to predict the WSI's diagnostic label. Our method captures\nlocal and global tissue structures and yields robust performance for\nlarge-scale WSI classification, demonstrating superior accuracy and scalability\ncompared to other approaches.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12085v1",
    "published_date": "2025-01-21 12:22:15 UTC",
    "updated_date": "2025-01-21 12:22:15 UTC"
  },
  {
    "arxiv_id": "2501.12425v1",
    "title": "Multi-stage intermediate fusion for multimodal learning to classify non-small cell lung cancer subtypes from CT and PET",
    "authors": [
      "Fatih Aksu",
      "Fabrizia Gelardi",
      "Arturo Chiti",
      "Paolo Soda"
    ],
    "abstract": "Accurate classification of histological subtypes of non-small cell lung\ncancer (NSCLC) is essential in the era of precision medicine, yet current\ninvasive techniques are not always feasible and may lead to clinical\ncomplications. This study presents a multi-stage intermediate fusion approach\nto classify NSCLC subtypes from CT and PET images. Our method integrates the\ntwo modalities at different stages of feature extraction, using voxel-wise\nfusion to exploit complementary information across varying abstraction levels\nwhile preserving spatial correlations. We compare our method against unimodal\napproaches using only CT or PET images to demonstrate the benefits of modality\nfusion, and further benchmark it against early and late fusion techniques to\nhighlight the advantages of intermediate fusion during feature extraction.\nAdditionally, we compare our model with the only existing intermediate fusion\nmethod for histological subtype classification using PET/CT images. Our results\ndemonstrate that the proposed method outperforms all alternatives across key\nmetrics, with an accuracy and AUC equal to 0.724 and 0.681, respectively. This\nnon-invasive approach has the potential to significantly improve diagnostic\naccuracy, facilitate more informed treatment decisions, and advance\npersonalized care in lung cancer management.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "q-bio.QM"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12425v1",
    "published_date": "2025-01-21 12:10:00 UTC",
    "updated_date": "2025-01-21 12:10:00 UTC"
  },
  {
    "arxiv_id": "2501.12424v1",
    "title": "Multi-Modality Collaborative Learning for Sentiment Analysis",
    "authors": [
      "Shanmin Wang",
      "Chengguang Liu",
      "Qingshan Liu"
    ],
    "abstract": "Multimodal sentiment analysis (MSA) identifies individuals' sentiment states\nin videos by integrating visual, audio, and text modalities. Despite progress\nin existing methods, the inherent modality heterogeneity limits the effective\ncapture of interactive sentiment features across modalities. In this paper, by\nintroducing a Multi-Modality Collaborative Learning (MMCL) framework, we\nfacilitate cross-modal interactions and capture enhanced and complementary\nfeatures from modality-common and modality-specific representations,\nrespectively. Specifically, we design a parameter-free decoupling module and\nseparate uni-modality into modality-common and modality-specific components\nthrough semantics assessment of cross-modal elements. For modality-specific\nrepresentations, inspired by the act-reward mechanism in reinforcement\nlearning, we design policy models to adaptively mine complementary sentiment\nfeatures under the guidance of a joint reward. For modality-common\nrepresentations, intra-modal attention is employed to highlight crucial\ncomponents, playing enhanced roles among modalities. Experimental results,\nincluding superiority evaluations on four databases, effectiveness verification\nof each module, and assessment of complementary features, demonstrate that MMCL\nsuccessfully learns collaborative features across modalities and significantly\nimproves performance. The code can be available at\nhttps://github.com/smwanghhh/MMCL.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12424v1",
    "published_date": "2025-01-21 12:06:21 UTC",
    "updated_date": "2025-01-21 12:06:21 UTC"
  },
  {
    "arxiv_id": "2501.12067v1",
    "title": "EDoRA: Efficient Weight-Decomposed Low-Rank Adaptation via Singular Value Decomposition",
    "authors": [
      "Hamid Nasiri",
      "Peter Garraghan"
    ],
    "abstract": "Parameter-efficient fine-tuning methods, such as LoRA, reduces the number of\ntrainable parameters. However, they often suffer from scalability issues and\ndifferences between their learning pattern and full fine-tuning. To overcome\nthese limitations, we propose Efficient Weight-Decomposed Low-Rank Adaptation\n(EDoRA): a novel PEFT method that decomposes pre-trained weights into magnitude\nand directional components. By freezing low-rank matrices, initializing them by\nsingular value decomposition, and introducing a small trainable matrix between\nthem, EDoRA achieves substantial reduction in trainable parameters while\nmaintaining learning capacity. Experimental results on the GLUE benchmark\ndemonstrate that EDoRA achieves competitive or superior performance compared to\nstate-of-the-art methods, such as LoRA and DoRA, with up to 30x fewer trainable\nparameters. This makes EDoRA a highly efficient solution for adapting LLMs to\ndiverse tasks under memory-constrained settings. Code is available at\nhttps://github.com/Hamid-Nasiri/EDoRA .",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 4 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2501.12067v1",
    "published_date": "2025-01-21 11:42:09 UTC",
    "updated_date": "2025-01-21 11:42:09 UTC"
  },
  {
    "arxiv_id": "2502.15710v1",
    "title": "The Process of Categorical Clipping at the Core of the Genesis of Concepts in Synthetic Neural Cognition",
    "authors": [
      "Michael Pichat",
      "William Pogrund",
      "Armanush Gasparian",
      "Paloma Pichat",
      "Samuel Demarchi",
      "Michael Veillet-Guillem",
      "Martin Corbet",
      "Théo Dasilva"
    ],
    "abstract": "This article investigates, within the field of neuropsychology of artificial\nintelligence, the process of categorical segmentation performed by language\nmodels. This process involves, across different neural layers, the creation of\nnew functional categorical dimensions to analyze the input textual data and\nperform the required tasks. Each neuron in a multilayer perceptron (MLP)\nnetwork is associated with a specific category, generated by three factors\ncarried by the neural aggregation function: categorical priming, categorical\nattention, and categorical phasing. At each new layer, these factors govern the\nformation of new categories derived from the categories of precursor neurons.\nThrough a process of categorical clipping, these new categories are created by\nselectively extracting specific subdimensions from the preceding categories,\nconstructing a distinction between a form and a categorical background. We\nexplore several cognitive characteristics of this synthetic clipping in an\nexploratory manner: categorical reduction, categorical selectivity, separation\nof initial embedding dimensions, and segmentation of categorical zones.",
    "categories": [
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15710v1",
    "published_date": "2025-01-21 11:32:39 UTC",
    "updated_date": "2025-01-21 11:32:39 UTC"
  },
  {
    "arxiv_id": "2501.12048v1",
    "title": "Adaptive Class Learning to Screen Diabetic Disorders in Fundus Images of Eye",
    "authors": [
      "Shramana Dey",
      "Pallabi Dutta",
      "Riddhasree Bhattacharyya",
      "Surochita Pal",
      "Sushmita Mitra",
      "Rajiv Raman"
    ],
    "abstract": "The prevalence of ocular illnesses is growing globally, presenting a\nsubstantial public health challenge. Early detection and timely intervention\nare crucial for averting visual impairment and enhancing patient prognosis.\nThis research introduces a new framework called Class Extension with Limited\nData (CELD) to train a classifier to categorize retinal fundus images. The\nclassifier is initially trained to identify relevant features concerning\nHealthy and Diabetic Retinopathy (DR) classes and later fine-tuned to adapt to\nthe task of classifying the input images into three classes: Healthy, DR, and\nGlaucoma. This strategy allows the model to gradually enhance its\nclassification capabilities, which is beneficial in situations where there are\nonly a limited number of labeled datasets available. Perturbation methods are\nalso used to identify the input image characteristics responsible for\ninfluencing the models decision-making process. We achieve an overall accuracy\nof 91% on publicly available datasets.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at International Conference on Pattern Recognition (ICPR)\n  2024",
    "pdf_url": "http://arxiv.org/pdf/2501.12048v1",
    "published_date": "2025-01-21 11:21:16 UTC",
    "updated_date": "2025-01-21 11:21:16 UTC"
  },
  {
    "arxiv_id": "2501.12423v1",
    "title": "FREYR: A Framework for Recognizing and Executing Your Requests",
    "authors": [
      "Roberto Gallotta",
      "Antonios Liapis",
      "Georgios N. Yannakakis"
    ],
    "abstract": "Large language models excel as conversational agents, but their capabilities\ncan be further extended through tool usage, i.e.: executable code, to enhance\nresponse accuracy or address specialized domains. Current approaches to enable\ntool usage often rely on model-specific prompting or fine-tuning a model for\nfunction-calling instructions. Both approaches have notable limitations,\nincluding reduced adaptability to unseen tools and high resource requirements.\nThis paper introduces FREYR, a streamlined framework that modularizes the tool\nusage process into separate steps. Through this decomposition, we show that\nFREYR achieves superior performance compared to conventional tool usage\nmethods. We evaluate FREYR on a set of real-world test cases specific for video\ngame design and compare it against traditional tool usage as provided by the\nOllama API.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "I.2.1; I.2.7"
    ],
    "primary_category": "cs.SE",
    "comment": "15 pages",
    "pdf_url": "http://arxiv.org/pdf/2501.12423v1",
    "published_date": "2025-01-21 11:08:18 UTC",
    "updated_date": "2025-01-21 11:08:18 UTC"
  },
  {
    "arxiv_id": "2501.12033v1",
    "title": "Harnessing Generative Pre-Trained Transformer for Datacenter Packet Trace Generation",
    "authors": [
      "Chen Griner"
    ],
    "abstract": "Today, the rapid growth of applications reliant on datacenters calls for new\nadvancements to meet the increasing traffic and computational demands. Traffic\ntraces from datacenters are essential for further development and optimization\nof future datacenters. However, traces are rarely released to the public.\nResearchers often use simplified mathematical models that lack the depth needed\nto recreate intricate traffic patterns and, thus, miss optimization\nopportunities found in realistic traffic. In this preliminary work, we\nintroduce DTG-GPT, a packet-level Datacenter Traffic Generator (DTG), based on\nthe generative pre-trained transformer (GPT) architecture used by many\nstate-of-the-art large language models. We train our model on a small set of\navailable traffic traces from different domains and offer a simple methodology\nto evaluate the fidelity of the generated traces to their original\ncounterparts. We show that DTG-GPT can synthesize novel traces that mimic the\nspatiotemporal patterns found in real traffic traces. We further demonstrate\nthat DTG-GPT can generate traces for networks of different scales while\nmaintaining fidelity. Our findings indicate the potential that, in the future,\nsimilar models to DTG-GPT will allow datacenter operators to release traffic\ninformation to the research community via trained GPT models.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "C.2.1"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12033v1",
    "published_date": "2025-01-21 10:55:50 UTC",
    "updated_date": "2025-01-21 10:55:50 UTC"
  },
  {
    "arxiv_id": "2501.13125v2",
    "title": "Generating Plausible Distractors for Multiple-Choice Questions via Student Choice Prediction",
    "authors": [
      "Yooseop Lee",
      "Suin Kim",
      "Yohan Jo"
    ],
    "abstract": "In designing multiple-choice questions (MCQs) in education, creating\nplausible distractors is crucial for identifying students' misconceptions and\ngaps in knowledge and accurately assessing their understanding. However, prior\nstudies on distractor generation have not paid sufficient attention to\nenhancing the difficulty of distractors, resulting in reduced effectiveness of\nMCQs. This study presents a pipeline for training a model to generate\ndistractors that are more likely to be selected by students. First, we train a\npairwise ranker to reason about students' misconceptions and assess the\nrelative plausibility of two distractors. Using this model, we create a dataset\nof pairwise distractor ranks and then train a distractor generator via Direct\nPreference Optimization (DPO) to generate more plausible distractors.\nExperiments on computer science subjects (Python, DB, MLDL) demonstrate that\nour pairwise ranker effectively identifies students' potential\nmisunderstandings and achieves ranking accuracy comparable to human experts.\nFurthermore, our distractor generator outperforms several baselines in\ngenerating plausible distractors and produces questions with a higher item\ndiscrimination index (DI).",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.13125v2",
    "published_date": "2025-01-21 10:20:39 UTC",
    "updated_date": "2025-03-16 06:33:02 UTC"
  },
  {
    "arxiv_id": "2501.12015v1",
    "title": "Full Proportional Justified Representation",
    "authors": [
      "Yusuf Hakan Kalayci",
      "Jiasen Liu",
      "David Kempe"
    ],
    "abstract": "In multiwinner approval voting, forming a committee that proportionally\nrepresents voters' approval ballots is an essential task. The notion of\njustified representation (JR) demands that any large \"cohesive\" group of voters\nshould be proportionally \"represented\". The \"cohesiveness\" is defined in\ndifferent ways; two common ways are the following: (C1) demands that the group\nunanimously approves a set of candidates proportional to its size, while (C2)\nrequires each member to approve at least a fixed fraction of such a set.\nSimilarly, \"representation\" have been considered in different ways: (R1) the\ncoalition's collective utility from the winning set exceeds that of any\nproportionally sized alternative, and (R2) for any proportionally sized\nalternative, at least one member of the coalition derives less utility from it\nthan from the winning set.\n  Three of the four possible combinations have been extensively studied:\n(C1)-(R1) defines Proportional Justified Representation (PJR), (C1)-(R2)\ndefines Extended Justified Representation (EJR), (C2)-(R2) defines Full\nJustified Representation (FJR). All three have merits, but also drawbacks. PJR\nis the weakest notion, and perhaps not sufficiently demanding; EJR may not be\ncompatible with perfect representation; and it is open whether a committee\nsatisfying FJR can be found efficiently.\n  We study the combination (C2)-(R1), which we call Full Proportional Justified\nRepresentation (FPJR). We investigate FPJR's properties and find that it shares\nPJR's advantages over EJR: several proportionality axioms (e.g. priceability,\nperfect representation) imply FPJR and PJR but not EJR. We also find that\nefficient rules like the greedy Monroe rule and the method of equal shares\nsatisfy FPJR, matching a key advantage of EJR over FJR. However, the\nProportional Approval Voting (PAV) rule may violate FPJR, so neither of EJR and\nFPJR implies the other.",
    "categories": [
      "cs.GT",
      "cs.AI"
    ],
    "primary_category": "cs.GT",
    "comment": "18 pages, Accepted to AAMAS 25",
    "pdf_url": "http://arxiv.org/pdf/2501.12015v1",
    "published_date": "2025-01-21 10:13:28 UTC",
    "updated_date": "2025-01-21 10:13:28 UTC"
  },
  {
    "arxiv_id": "2501.12422v1",
    "title": "CroMe: Multimodal Fake News Detection using Cross-Modal Tri-Transformer and Metric Learning",
    "authors": [
      "Eunjee Choi",
      "Junhyun Ahn",
      "XinYu Piao",
      "Jong-Kook Kim"
    ],
    "abstract": "Multimodal Fake News Detection has received increasing attention recently.\nExisting methods rely on independently encoded unimodal data and overlook the\nadvantages of capturing intra-modality relationships and integrating\ninter-modal similarities using advanced techniques. To address these issues,\nCross-Modal Tri-Transformer and Metric Learning for Multimodal Fake News\nDetection (CroMe) is proposed. CroMe utilizes Bootstrapping Language-Image\nPre-training with Frozen Image Encoders and Large Language Models (BLIP2) as\nencoders to capture detailed text, image and combined image-text\nrepresentations. The metric learning module employs a proxy anchor method to\ncapture intra-modality relationships while the feature fusion module uses a\nCross-Modal and Tri-Transformer for effective integration. The final fake news\ndetector processes the fused features through a classifier to predict the\nauthenticity of the content. Experiments on datasets show that CroMe excels in\nmultimodal fake news detection.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12422v1",
    "published_date": "2025-01-21 09:36:27 UTC",
    "updated_date": "2025-01-21 09:36:27 UTC"
  },
  {
    "arxiv_id": "2501.11992v1",
    "title": "Survey on Hand Gesture Recognition from Visual Input",
    "authors": [
      "Manousos Linardakis",
      "Iraklis Varlamis",
      "Georgios Th. Papadopoulos"
    ],
    "abstract": "Hand gesture recognition has become an important research area, driven by the\ngrowing demand for human-computer interaction in fields such as sign language\nrecognition, virtual and augmented reality, and robotics. Despite the rapid\ngrowth of the field, there are few surveys that comprehensively cover recent\nresearch developments, available solutions, and benchmark datasets. This survey\naddresses this gap by examining the latest advancements in hand gesture and 3D\nhand pose recognition from various types of camera input data including RGB\nimages, depth images, and videos from monocular or multiview cameras, examining\nthe differing methodological requirements of each approach. Furthermore, an\noverview of widely used datasets is provided, detailing their main\ncharacteristics and application domains. Finally, open challenges such as\nachieving robust recognition in real-world environments, handling occlusions,\nensuring generalization across diverse users, and addressing computational\nefficiency for real-time applications are highlighted to guide future research\ndirections. By synthesizing the objectives, methodologies, and applications of\nrecent studies, this survey offers valuable insights into current trends,\nchallenges, and opportunities for future research in human hand gesture\nrecognition.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.11992v1",
    "published_date": "2025-01-21 09:23:22 UTC",
    "updated_date": "2025-01-21 09:23:22 UTC"
  },
  {
    "arxiv_id": "2501.12421v1",
    "title": "Tackling Small Sample Survival Analysis via Transfer Learning: A Study of Colorectal Cancer Prognosis",
    "authors": [
      "Yonghao Zhao",
      "Changtao Li",
      "Chi Shu",
      "Qingbin Wu",
      "Hong Li",
      "Chuan Xu",
      "Tianrui Li",
      "Ziqiang Wang",
      "Zhipeng Luo",
      "Yazhou He"
    ],
    "abstract": "Survival prognosis is crucial for medical informatics. Practitioners often\nconfront small-sized clinical data, especially cancer patient cases, which can\nbe insufficient to induce useful patterns for survival predictions. This study\ndeals with small sample survival analysis by leveraging transfer learning, a\nuseful machine learning technique that can enhance the target analysis with\nrelated knowledge pre-learned from other data. We propose and develop various\ntransfer learning methods designed for common survival models. For parametric\nmodels such as DeepSurv, Cox-CC (Cox-based neural networks), and DeepHit\n(end-to-end deep learning model), we apply standard transfer learning\ntechniques like pretraining and fine-tuning. For non-parametric models such as\nRandom Survival Forest, we propose a new transfer survival forest (TSF) model\nthat transfers tree structures from source tasks and fine-tunes them with\ntarget data. We evaluated the transfer learning methods on colorectal cancer\n(CRC) prognosis. The source data are 27,379 SEER CRC stage I patients, and the\ntarget data are 728 CRC stage I patients from the West China Hospital. When\nenhanced by transfer learning, Cox-CC's $C^{td}$ value was boosted from 0.7868\nto 0.8111, DeepHit's from 0.8085 to 0.8135, DeepSurv's from 0.7722 to 0.8043,\nand RSF's from 0.7940 to 0.8297 (the highest performance). All models trained\nwith data as small as 50 demonstrated even more significant improvement.\nConclusions: Therefore, the current survival models used for cancer prognosis\ncan be enhanced and improved by properly designed transfer learning techniques.\nThe source code used in this study is available at\nhttps://github.com/YonghaoZhao722/TSF.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12421v1",
    "published_date": "2025-01-21 08:52:57 UTC",
    "updated_date": "2025-01-21 08:52:57 UTC"
  },
  {
    "arxiv_id": "2501.11977v1",
    "title": "Leveraging Graph Structures and Large Language Models for End-to-End Synthetic Task-Oriented Dialogues",
    "authors": [
      "Maya Medjad",
      "Hugo Imbert",
      "Bruno Yun",
      "Raphaël Szymocha",
      "Frédéric Armetta"
    ],
    "abstract": "Training task-oriented dialogue systems is both costly and time-consuming,\ndue to the need for high-quality datasets encompassing diverse intents.\nTraditional methods depend on extensive human annotation, while recent\nadvancements leverage large language models (LLMs) to generate synthetic data.\nHowever, these approaches often require custom prompts or code, limiting\naccessibility for non-technical users. We introduce GraphTOD, an end-to-end\nframework that simplifies the generation of task-oriented dialogues. Users can\ncreate dialogues by specifying transition graphs in JSON format. Our evaluation\ndemonstrates that GraphTOD generates high-quality dialogues across various\ndomains, significantly lowering the cost and complexity of dataset creation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.11977v1",
    "published_date": "2025-01-21 08:51:12 UTC",
    "updated_date": "2025-01-21 08:51:12 UTC"
  },
  {
    "arxiv_id": "2501.11968v1",
    "title": "Bridging Visualization and Optimization: Multimodal Large Language Models on Graph-Structured Combinatorial Optimization",
    "authors": [
      "Jie Zhao",
      "Kang Hao Cheong",
      "Witold Pedrycz"
    ],
    "abstract": "Graph-structured combinatorial challenges are inherently difficult due to\ntheir nonlinear and intricate nature, often rendering traditional computational\nmethods ineffective or expensive. However, these challenges can be more\nnaturally tackled by humans through visual representations that harness our\ninnate ability for spatial reasoning. In this study, we propose transforming\ngraphs into images to preserve their higher-order structural features\naccurately, revolutionizing the representation used in solving graph-structured\ncombinatorial tasks. This approach allows machines to emulate human-like\nprocessing in addressing complex combinatorial challenges. By combining the\ninnovative paradigm powered by multimodal large language models (MLLMs) with\nsimple search techniques, we aim to develop a novel and effective framework for\ntackling such problems. Our investigation into MLLMs spanned a variety of\ngraph-based tasks, from combinatorial problems like influence maximization to\nsequential decision-making in network dismantling, as well as addressing six\nfundamental graph-related issues. Our findings demonstrate that MLLMs exhibit\nexceptional spatial intelligence and a distinctive capability for handling\nthese problems, significantly advancing the potential for machines to\ncomprehend and analyze graph-structured data with a depth and intuition akin to\nhuman cognition. These results also imply that integrating MLLMs with simple\noptimization strategies could form a novel and efficient approach for\nnavigating graph-structured combinatorial challenges without complex\nderivations, computationally demanding training and fine-tuning.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.11968v1",
    "published_date": "2025-01-21 08:28:10 UTC",
    "updated_date": "2025-01-21 08:28:10 UTC"
  },
  {
    "arxiv_id": "2501.11960v1",
    "title": "TAD-Bench: A Comprehensive Benchmark for Embedding-Based Text Anomaly Detection",
    "authors": [
      "Yang Cao",
      "Sikun Yang",
      "Chen Li",
      "Haolong Xiang",
      "Lianyong Qi",
      "Bo Liu",
      "Rongsheng Li",
      "Ming Liu"
    ],
    "abstract": "Text anomaly detection is crucial for identifying spam, misinformation, and\noffensive language in natural language processing tasks. Despite the growing\nadoption of embedding-based methods, their effectiveness and generalizability\nacross diverse application scenarios remain under-explored. To address this, we\npresent TAD-Bench, a comprehensive benchmark designed to systematically\nevaluate embedding-based approaches for text anomaly detection. TAD-Bench\nintegrates multiple datasets spanning different domains, combining\nstate-of-the-art embeddings from large language models with a variety of\nanomaly detection algorithms. Through extensive experiments, we analyze the\ninterplay between embeddings and detection methods, uncovering their strengths,\nweaknesses, and applicability to different tasks. These findings offer new\nperspectives on building more robust, efficient, and generalizable anomaly\ndetection systems for real-world applications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.11960v1",
    "published_date": "2025-01-21 08:13:10 UTC",
    "updated_date": "2025-01-21 08:13:10 UTC"
  },
  {
    "arxiv_id": "2501.17168v3",
    "title": "EvoGP: A GPU-accelerated Framework for Tree-based Genetic Programming",
    "authors": [
      "Lishuang Wang",
      "Zhihong Wu",
      "Kebin Sun",
      "Zhuozhao Li",
      "Ran Cheng"
    ],
    "abstract": "Tree-based Genetic Programming (TGP) is a key evolutionary algorithm widely\nused in symbolic regression, feature engineering, and scientific modeling. Its\nhigh computational demands make GPU acceleration essential for scalable and\nhigh-performance evolutionary computation. However, GPU acceleration of TGP\nfaces three key challenges: inefficient tree encoding, highly heterogeneous\ngenetic operations, and limited parallelism in fitness evaluation. To address\nthese challenges, we introduce EvoGP, a comprehensive GPU-accelerated TGP\nframework. First, we design a tensorized encoding scheme to represent tree with\ndifferent structures as tensors with the same shape, optimizing memory access\nand enabling efficient parallel execution. Second, we propose a unified\nparallel framework for genetic operations by leveraging shared computational\nprimitives and implementing dedicated CUDA kernels for scalable performance.\nThird, we present a fully parallel fitness evaluation strategy for symbolic\nregression, exploiting both population-level and data-level parallelism to\nmaximize GPU utilization. Moreover, we implement a comprehensive library to\nprovide rich algorithm operators and benchmark problems. EvoGP is extensively\ntested on various tasks, including symbolic regression, classification, and\nrobotics control, demonstrating its versatility and effectiveness across\ndiverse application scenarios. Experimental results show that EvoGP achieves up\nto a 140.89x speedup over the state-of-the-art GPU-based TGP implementation,\nwhile maintaining or exceeding the accuracy of baseline methods. EvoGP is\nopen-source and accessible at: https://github.com/EMI-Group/evogp.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17168v3",
    "published_date": "2025-01-21 07:42:54 UTC",
    "updated_date": "2025-02-02 17:03:07 UTC"
  },
  {
    "arxiv_id": "2501.11937v2",
    "title": "MeshONet: A Generalizable and Efficient Operator Learning Method for Structured Mesh Generation",
    "authors": [
      "Jing Xiao",
      "Xinhai Chen",
      "Qingling Wang",
      "Jie Liu"
    ],
    "abstract": "Mesh generation plays a crucial role in scientific computing. Traditional\nmesh generation methods, such as TFI and PDE-based methods, often struggle to\nachieve a balance between efficiency and mesh quality. To address this\nchallenge, physics-informed intelligent learning methods have recently emerged,\nsignificantly improving generation efficiency while maintaining high mesh\nquality. However, physics-informed methods fail to generalize when applied to\npreviously unseen geometries, as even small changes in the boundary shape\nnecessitate burdensome retraining to adapt to new geometric variations. In this\npaper, we introduce MeshONet, the first generalizable intelligent learning\nmethod for structured mesh generation. The method transforms the mesh\ngeneration task into an operator learning problem with multiple input and\nsolution functions. To effectively overcome the multivariable mapping\nrestriction of operator learning methods, we propose a dual-branch,\nshared-trunk architecture to approximate the mapping between function spaces\nbased on input-output pairs. Experimental results show that MeshONet achieves a\nspeedup of up to four orders of magnitude in generation efficiency over\ntraditional methods. It also enables generalization to different geometries\nwithout retraining, greatly enhancing the practicality of intelligent methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.11937v2",
    "published_date": "2025-01-21 07:27:05 UTC",
    "updated_date": "2025-01-22 03:13:23 UTC"
  },
  {
    "arxiv_id": "2501.11935v3",
    "title": "To Google or To ChatGPT? A Comparison of CS2 Students' Information Gathering Approaches and Outcomes",
    "authors": [
      "Aayush Kumar",
      "Daniel Prol",
      "Amin Alipour",
      "Sruti Srinivasa Ragavan"
    ],
    "abstract": "LLMs such as ChatGPT have been widely adopted by students in higher education\nas tools for learning programming and related concepts. However, it remains\nunclear how effective students are and what strategies students use while\nlearning with LLMs. Since the majority of students' experiences in online\nself-learning have come through using search engines such as Google, evaluating\nAI tools in this context can help us address these gaps. In this mixed methods\nresearch, we conducted an exploratory within-subjects study to understand how\nCS2 students learn programming concepts using both LLMs as well as traditional\nonline methods such as educational websites and videos to examine how students\napproach learning within and across both scenarios. We discovered that students\nfound it easier to learn a more difficult concept using traditional methods\nthan using ChatGPT. We also found that students ask fewer follow-ups and use\nmore keyword-based queries for search engines while their prompts to LLMs tend\nto explicitly ask for information.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.11935v3",
    "published_date": "2025-01-21 07:16:18 UTC",
    "updated_date": "2025-03-22 18:17:31 UTC"
  },
  {
    "arxiv_id": "2501.11927v1",
    "title": "A Lightweight and Interpretable Deepfakes Detection Framework",
    "authors": [
      "Muhammad Umar Farooq",
      "Ali Javed",
      "Khalid Mahmood Malik",
      "Muhammad Anas Raza"
    ],
    "abstract": "The recent realistic creation and dissemination of so-called deepfakes poses\na serious threat to social life, civil rest, and law. Celebrity defaming,\nelection manipulation, and deepfakes as evidence in court of law are few\npotential consequences of deepfakes. The availability of open source trained\nmodels based on modern frameworks such as PyTorch or TensorFlow, video\nmanipulations Apps such as FaceApp and REFACE, and economical computing\ninfrastructure has easen the creation of deepfakes. Most of the existing\ndetectors focus on detecting either face-swap, lip-sync, or puppet master\ndeepfakes, but a unified framework to detect all three types of deepfakes is\nhardly explored. This paper presents a unified framework that exploits the\npower of proposed feature fusion of hybrid facial landmarks and our novel heart\nrate features for detection of all types of deepfakes. We propose novel heart\nrate features and fused them with the facial landmark features to better\nextract the facial artifacts of fake videos and natural variations available in\nthe original videos. We used these features to train a light-weight XGBoost to\nclassify between the deepfake and bonafide videos. We evaluated the performance\nof our framework on the world leaders dataset (WLDR) that contains all types of\ndeepfakes. Experimental results illustrate that the proposed framework offers\nsuperior detection performance over the comparative deepfakes detection\nmethods. Performance comparison of our framework against the LSTM-FCN, a\ncandidate of deep learning model, shows that proposed model achieves similar\nresults, however, it is more interpretable.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.11927v1",
    "published_date": "2025-01-21 07:03:11 UTC",
    "updated_date": "2025-01-21 07:03:11 UTC"
  },
  {
    "arxiv_id": "2501.11924v1",
    "title": "Make Full Use of Testing Information: An Integrated Accelerated Testing and Evaluation Method for Autonomous Driving Systems",
    "authors": [
      "Xinzheng Wu",
      "Junyi Chen",
      "Jianfeng Wu",
      "Longgao Zhang",
      "Tian Xia",
      "Yong Shen"
    ],
    "abstract": "Testing and evaluation is an important step before the large-scale\napplication of the autonomous driving systems (ADSs). Based on the three level\nof scenario abstraction theory, a testing can be performed within a logical\nscenario, followed by an evaluation stage which is inputted with the testing\nresults of each concrete scenario generated from the logical parameter space.\nDuring the above process, abundant testing information is produced which is\nbeneficial for comprehensive and accurate evaluations. To make full use of\ntesting information, this paper proposes an Integrated accelerated Testing and\nEvaluation Method (ITEM). Based on a Monte Carlo Tree Search (MCTS) paradigm\nand a dual surrogates testing framework proposed in our previous work, this\npaper applies the intermediate information (i.e., the tree structure, including\nthe affiliation of each historical sampled point with the subspaces and the\nparent-child relationship between subspaces) generated during the testing stage\ninto the evaluation stage to achieve accurate hazardous domain identification.\nMoreover, to better serve this purpose, the UCB calculation method is improved\nto allow the search algorithm to focus more on the hazardous domain boundaries.\nFurther, a stopping condition is constructed based on the convergence of the\nsearch algorithm. Ablation and comparative experiments are then conducted to\nverify the effectiveness of the improvements and the superiority of the\nproposed method. The experimental results show that ITEM could well identify\nthe hazardous domains in both low- and high-dimensional cases, regardless of\nthe shape of the hazardous domains, indicating its generality and potential for\nthe safety evaluation of ADSs.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "15 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.11924v1",
    "published_date": "2025-01-21 06:59:25 UTC",
    "updated_date": "2025-01-21 06:59:25 UTC"
  },
  {
    "arxiv_id": "2501.11921v1",
    "title": "Goal-oriented Transmission Scheduling: Structure-guided DRL with a Unified Dual On-policy and Off-policy Approach",
    "authors": [
      "Jiazheng Chen",
      "Wanchun Liu"
    ],
    "abstract": "Goal-oriented communications prioritize application-driven objectives over\ndata accuracy, enabling intelligent next-generation wireless systems. Efficient\nscheduling in multi-device, multi-channel systems poses significant challenges\ndue to high-dimensional state and action spaces. We address these challenges by\nderiving key structural properties of the optimal solution to the goal-oriented\nscheduling problem, incorporating Age of Information (AoI) and channel states.\nSpecifically, we establish the monotonicity of the optimal state value function\n(a measure of long-term system performance) w.r.t. channel states and prove its\nasymptotic convexity w.r.t. AoI states. Additionally, we derive the\nmonotonicity of the optimal policy w.r.t. channel states, advancing the\ntheoretical framework for optimal scheduling. Leveraging these insights, we\npropose the structure-guided unified dual on-off policy DRL (SUDO-DRL), a\nhybrid algorithm that combines the stability of on-policy training with the\nsample efficiency of off-policy methods. Through a novel structural property\nevaluation framework, SUDO-DRL enables effective and scalable training,\naddressing the complexities of large-scale systems. Numerical results show\nSUDO-DRL improves system performance by up to 45% and reduces convergence time\nby 40% compared to state-of-the-art methods. It also effectively handles\nscheduling in much larger systems, where off-policy DRL fails and on-policy\nbenchmarks exhibit significant performance loss, demonstrating its scalability\nand efficacy in goal-oriented communications.",
    "categories": [
      "cs.IT",
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SP",
      "eess.SY",
      "math.IT"
    ],
    "primary_category": "cs.IT",
    "comment": "Paper submitted to IEEE",
    "pdf_url": "http://arxiv.org/pdf/2501.11921v1",
    "published_date": "2025-01-21 06:49:06 UTC",
    "updated_date": "2025-01-21 06:49:06 UTC"
  },
  {
    "arxiv_id": "2501.11918v1",
    "title": "LuxVeri at GenAI Detection Task 3: Cross-Domain Detection of AI-Generated Text Using Inverse Perplexity-Weighted Ensemble of Fine-Tuned Transformer Models",
    "authors": [
      "Md Kamrujjaman Mobin",
      "Md Saiful Islam"
    ],
    "abstract": "This paper presents our approach for Task 3 of the GenAI content detection\nworkshop at COLING-2025, focusing on Cross-Domain Machine-Generated Text (MGT)\nDetection. We propose an ensemble of fine-tuned transformer models, enhanced by\ninverse perplexity weighting, to improve classification accuracy across diverse\ntext domains. For Subtask A (Non-Adversarial MGT Detection), we combined a\nfine-tuned RoBERTa-base model with an OpenAI detector-integrated RoBERTa-base\nmodel, achieving an aggregate TPR score of 0.826, ranking 10th out of 23\ndetectors. In Subtask B (Adversarial MGT Detection), our fine-tuned\nRoBERTa-base model achieved a TPR score of 0.801, securing 8th out of 22\ndetectors. Our results demonstrate the effectiveness of inverse\nperplexity-based weighting for enhancing generalization and performance in both\nnon-adversarial and adversarial MGT detection, highlighting the potential for\ntransformer models in cross-domain AI-generated content detection.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.11918v1",
    "published_date": "2025-01-21 06:46:55 UTC",
    "updated_date": "2025-01-21 06:46:55 UTC"
  },
  {
    "arxiv_id": "2501.11914v1",
    "title": "LuxVeri at GenAI Detection Task 1: Inverse Perplexity Weighted Ensemble for Robust Detection of AI-Generated Text across English and Multilingual Contexts",
    "authors": [
      "Md Kamrujjaman Mobin",
      "Md Saiful Islam"
    ],
    "abstract": "This paper presents a system developed for Task 1 of the COLING 2025 Workshop\non Detecting AI-Generated Content, focusing on the binary classification of\nmachine-generated versus human-written text. Our approach utilizes an ensemble\nof models, with weights assigned according to each model's inverse perplexity,\nto enhance classification accuracy. For the English text detection task, we\ncombined RoBERTa-base, RoBERTa-base with the OpenAI detector, and\nBERT-base-cased, achieving a Macro F1-score of 0.7458, which ranked us 12th out\nof 35 teams. We ensembled RemBERT, XLM-RoBERTa-base, and\nBERT-base-multilingual-case for the multilingual text detection task, employing\nthe same inverse perplexity weighting technique. This resulted in a Macro\nF1-score of 0.7513, positioning us 4th out of 25 teams. Our results demonstrate\nthe effectiveness of inverse perplexity weighting in improving the robustness\nof machine-generated text detection across both monolingual and multilingual\nsettings, highlighting the potential of ensemble methods for this challenging\ntask.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.11914v1",
    "published_date": "2025-01-21 06:32:32 UTC",
    "updated_date": "2025-01-21 06:32:32 UTC"
  },
  {
    "arxiv_id": "2501.13959v2",
    "title": "Assisting Mathematical Formalization with A Learning-based Premise Retriever",
    "authors": [
      "Yicheng Tao",
      "Haotian Liu",
      "Shanwen Wang",
      "Hongteng Xu"
    ],
    "abstract": "Premise selection is a crucial yet challenging step in mathematical\nformalization, especially for users with limited experience. Due to the lack of\navailable formalization projects, existing approaches that leverage language\nmodels often suffer from data scarcity. In this work, we introduce an\ninnovative method for training a premise retriever to support the formalization\nof mathematics. Our approach employs a BERT model to embed proof states and\npremises into a shared latent space. The retrieval model is trained within a\ncontrastive learning framework and incorporates a domain-specific tokenizer\nalong with a fine-grained similarity computation method. Experimental results\nshow that our model is highly competitive compared to existing baselines,\nachieving strong performance while requiring fewer computational resources.\nPerformance is further enhanced through the integration of a re-ranking module.\nTo streamline the formalization process, we will release a search engine that\nenables users to query Mathlib theorems directly using proof states,\nsignificantly improving accessibility and efficiency. Codes are available at\nhttps://github.com/ruc-ai4math/Premise-Retrieval.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.13959v2",
    "published_date": "2025-01-21 06:32:25 UTC",
    "updated_date": "2025-03-06 13:51:24 UTC"
  },
  {
    "arxiv_id": "2501.13958v1",
    "title": "A Survey of Graph Retrieval-Augmented Generation for Customized Large Language Models",
    "authors": [
      "Qinggang Zhang",
      "Shengyuan Chen",
      "Yuanchen Bei",
      "Zheng Yuan",
      "Huachi Zhou",
      "Zijin Hong",
      "Junnan Dong",
      "Hao Chen",
      "Yi Chang",
      "Xiao Huang"
    ],
    "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in a\nwide range of tasks, yet their application to specialized domains remains\nchallenging due to the need for deep expertise. Retrieval-augmented generation\n(RAG) has emerged as a promising solution to customize LLMs for professional\nfields by seamlessly integrating external knowledge bases, enabling real-time\naccess to domain-specific expertise during inference. Despite its potential,\ntraditional RAG systems, based on flat text retrieval, face three critical\nchallenges: (i) complex query understanding in professional contexts, (ii)\ndifficulties in knowledge integration across distributed sources, and (iii)\nsystem efficiency bottlenecks at scale. This survey presents a systematic\nanalysis of Graph-based Retrieval-Augmented Generation (GraphRAG), a new\nparadigm that revolutionizes domain-specific LLM applications. GraphRAG\naddresses traditional RAG limitations through three key innovations: (i)\ngraph-structured knowledge representation that explicitly captures entity\nrelationships and domain hierarchies, (ii) efficient graph-based retrieval\ntechniques that enable context-preserving knowledge retrieval with multihop\nreasoning ability, and (iii) structure-aware knowledge integration algorithms\nthat leverage retrieved knowledge for accurate and logical coherent generation\nof LLMs. In this survey, we systematically analyze the technical foundations of\nGraphRAG and examine current implementations across various professional\ndomains, identifying key technical challenges and promising research\ndirections. All the related resources of GraphRAG, including research papers,\nopen-source data, and projects, are collected for the community in\n\\textcolor{blue}{\\url{https://github.com/DEEP-PolyU/Awesome-GraphRAG}}.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.13958v1",
    "published_date": "2025-01-21 06:25:21 UTC",
    "updated_date": "2025-01-21 06:25:21 UTC"
  },
  {
    "arxiv_id": "2501.11909v1",
    "title": "Bridging the Communication Gap: Evaluating AI Labeling Practices for Trustworthy AI Development",
    "authors": [
      "Raphael Fischer",
      "Magdalena Wischnewski",
      "Alexander van der Staay",
      "Katharina Poitz",
      "Christian Janiesch",
      "Thomas Liebig"
    ],
    "abstract": "As artificial intelligence (AI) becomes integral to economy and society,\ncommunication gaps between developers, users, and stakeholders hinder trust and\ninformed decision-making. High-level AI labels, inspired by frameworks like EU\nenergy labels, have been proposed to make the properties of AI models more\ntransparent. Without requiring deep technical expertise, they can inform on the\ntrade-off between predictive performance and resource efficiency. However, the\npractical benefits and limitations of AI labeling remain underexplored. This\nstudy evaluates AI labeling through qualitative interviews along four key\nresearch questions. Based on thematic analysis and inductive coding, we found a\nbroad range of practitioners to be interested in AI labeling (RQ1). They see\nbenefits for alleviating communication gaps and aiding non-expert\ndecision-makers, however limitations, misunderstandings, and suggestions for\nimprovement were also discussed (RQ2). Compared to other reporting formats,\ninterviewees positively evaluated the reduced complexity of labels, increasing\noverall comprehensibility (RQ3). Trust was influenced most by usability and the\ncredibility of the responsible labeling authority, with mixed preferences for\nself-certification versus third-party certification (RQ4). Our Insights\nhighlight that AI labels pose a trade-off between simplicity and complexity,\nwhich could be resolved by developing customizable and interactive labeling\nframeworks to address diverse user needs. Transparent labeling of resource\nefficiency also nudged interviewee priorities towards paying more attention to\nsustainability aspects during AI development. This study validates AI labels as\na valuable tool for enhancing trust and communication in AI, offering\nactionable guidelines for their refinement and standardization.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.11909v1",
    "published_date": "2025-01-21 06:00:14 UTC",
    "updated_date": "2025-01-21 06:00:14 UTC"
  },
  {
    "arxiv_id": "2501.13124v1",
    "title": "Debate Helps Weak-to-Strong Generalization",
    "authors": [
      "Hao Lang",
      "Fei Huang",
      "Yongbin Li"
    ],
    "abstract": "Common methods for aligning already-capable models with desired behavior rely\non the ability of humans to provide supervision. However, future superhuman\nmodels will surpass the capability of humans. Therefore, humans will only be\nable to weakly supervise superhuman models. This expected deficiency of human\nevaluation would weaken the safety of future AI systems. Scalable oversight and\nweak-to-strong generalization are two complementary approaches to tackle this\nissue. In this paper, we attempt to combine the strengths of these two\napproaches to further improve alignment. Specifically, we investigate ways of\nimproving human supervision with a strong pretrained model and then supervise\nthe strong model with enhanced weak human supervision. To make iterative\nempirical progress, we consider an analogy: can we use a strong model to\nimprove weak model supervision and then use it to supervise the strong model?\nWe empirically test it by finetuning a small weak model on ground truth labels\nwith the additional help from a large strong model, and then finetuning the\nstrong model on labels generated by the weak model. We find that debate can\nassist a weak model in extracting trustworthy information from an untrustworthy\nstrong model, which provides leverage as context on samples when training a\nweak model. We also show that an ensemble of weak models helps exploit long\narguments generated by strong model debaters and obtain a more robust\nsupervision estimate. Extensive experiments on the OpenAI weak-to-strong NLP\nbenchmarks show that the combination approach leads to better alignment, which\nindicates that debate has the potential to help weak-to-strong generalization.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "AAAI2025 Special Track on AI Alignment (Oral presentation)",
    "pdf_url": "http://arxiv.org/pdf/2501.13124v1",
    "published_date": "2025-01-21 05:36:13 UTC",
    "updated_date": "2025-01-21 05:36:13 UTC"
  },
  {
    "arxiv_id": "2501.11900v2",
    "title": "Panoramic Interests: Stylistic-Content Aware Personalized Headline Generation",
    "authors": [
      "Junhong Lian",
      "Xiang Ao",
      "Xinyu Liu",
      "Yang Liu",
      "Qing He"
    ],
    "abstract": "Personalized news headline generation aims to provide users with\nattention-grabbing headlines that are tailored to their preferences. Prevailing\nmethods focus on user-oriented content preferences, but most of them overlook\nthe fact that diverse stylistic preferences are integral to users' panoramic\ninterests, leading to suboptimal personalization. In view of this, we propose a\nnovel Stylistic-Content Aware Personalized Headline Generation (SCAPE)\nframework. SCAPE extracts both content and stylistic features from headlines\nwith the aid of large language model (LLM) collaboration. It further adaptively\nintegrates users' long- and short-term interests through a contrastive\nlearning-based hierarchical fusion network. By incorporating the panoramic\ninterests into the headline generator, SCAPE reflects users' stylistic-content\npreferences during the generation process. Extensive experiments on the\nreal-world dataset PENS demonstrate the superiority of SCAPE over baselines.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to The ACM Web Conference 2025 (WWW'25, short paper)",
    "pdf_url": "http://arxiv.org/pdf/2501.11900v2",
    "published_date": "2025-01-21 05:30:20 UTC",
    "updated_date": "2025-01-28 04:04:35 UTC"
  },
  {
    "arxiv_id": "2501.11896v2",
    "title": "Systematic Abductive Reasoning via Diverse Relation Representations in Vector-symbolic Architecture",
    "authors": [
      "Zhong-Hua Sun",
      "Ru-Yuan Zhang",
      "Zonglei Zhen",
      "Da-Hui Wang",
      "Yong-Jie Li",
      "Xiaohong Wan",
      "Hongzhi You"
    ],
    "abstract": "In abstract visual reasoning, monolithic deep learning models suffer from\nlimited interpretability and generalization, while existing neuro-symbolic\napproaches fall short in capturing the diversity and systematicity of\nattributes and relation representations. To address these challenges, we\npropose a Systematic Abductive Reasoning model with diverse relation\nrepresentations (Rel-SAR) in Vector-symbolic Architecture (VSA) to solve\nRaven's Progressive Matrices (RPM). To derive attribute representations with\nsymbolic reasoning potential, we introduce not only various types of atomic\nvectors that represent numeric, periodic and logical semantics, but also the\nstructured high-dimentional representation (SHDR) for the overall Grid\ncomponent. For systematic reasoning, we propose novel numerical and logical\nrelation functions and perform rule abduction and execution in a unified\nframework that integrates these relation representations. Experimental results\ndemonstrate that Rel-SAR achieves significant improvement on RPM tasks and\nexhibits robust out-of-distribution generalization. Rel-SAR leverages the\nsynergy between HD attribute representations and symbolic reasoning to achieve\nsystematic abductive reasoning with both interpretable and computable\nsemantics.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.11896v2",
    "published_date": "2025-01-21 05:17:08 UTC",
    "updated_date": "2025-01-22 03:23:22 UTC"
  },
  {
    "arxiv_id": "2501.17881v1",
    "title": "RayLoc: Wireless Indoor Localization via Fully Differentiable Ray-tracing",
    "authors": [
      "Xueqiang Han",
      "Tianyue Zheng",
      "Tony Xiao Han",
      "Jun Luo"
    ],
    "abstract": "Wireless indoor localization has been a pivotal area of research over the\nlast two decades, becoming a cornerstone for numerous sensing applications.\nHowever, conventional wireless localization methods rely on channel state\ninformation to perform blind modelling and estimation of a limited set of\nlocalization parameters. This oversimplification neglects many sensing scene\ndetails, resulting in suboptimal localization accuracy. To address this\nlimitation, this paper presents a novel approach to wireless indoor\nlocalization by reformulating it as an inverse problem of wireless ray-tracing,\ninferring scene parameters that generates the measured CSI. At the core of our\nsolution is a fully differentiable ray-tracing simulator that enables\nbackpropagation to comprehensive parameters of the sensing scene, allowing for\nprecise localization. To establish a robust localization context, RayLoc\nconstructs a high-fidelity sensing scene by refining coarse-grained background\nmodel. Furthermore, RayLoc overcomes the challenges of sparse gradient and\nlocal minima by convolving the signal generation process with a Gaussian\nkernel. Extensive experiments showcase that RayLoc outperforms traditional\nlocalization baselines and is able to generalize to different sensing\nenvironments.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG",
      "cs.NI"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17881v1",
    "published_date": "2025-01-21 04:24:36 UTC",
    "updated_date": "2025-01-21 04:24:36 UTC"
  },
  {
    "arxiv_id": "2501.11880v1",
    "title": "Community-Aware Temporal Walks: Parameter-Free Representation Learning on Continuous-Time Dynamic Graphs",
    "authors": [
      "He Yu",
      "Jing Liu"
    ],
    "abstract": "Dynamic graph representation learning plays a crucial role in understanding\nevolving behaviors. However, existing methods often struggle with flexibility,\nadaptability, and the preservation of temporal and structural dynamics. To\naddress these issues, we propose Community-aware Temporal Walks (CTWalks), a\nnovel framework for representation learning on continuous-time dynamic graphs.\nCTWalks integrates three key components: a community-based parameter-free\ntemporal walk sampling mechanism, an anonymization strategy enriched with\ncommunity labels, and an encoding process that leverages continuous temporal\ndynamics modeled via ordinary differential equations (ODEs). This design\nenables precise modeling of both intra- and inter-community interactions,\noffering a fine-grained representation of evolving temporal patterns in\ncontinuous-time dynamic graphs. CTWalks theoretically overcomes locality bias\nin walks and establishes its connection to matrix factorization. Experiments on\nbenchmark datasets demonstrate that CTWalks outperforms established methods in\ntemporal link prediction tasks, achieving higher accuracy while maintaining\nrobustness.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.11880v1",
    "published_date": "2025-01-21 04:16:46 UTC",
    "updated_date": "2025-01-21 04:16:46 UTC"
  },
  {
    "arxiv_id": "2501.11877v1",
    "title": "From Drafts to Answers: Unlocking LLM Potential via Aggregation Fine-Tuning",
    "authors": [
      "Yafu Li",
      "Zhilin Wang",
      "Tingchen Fu",
      "Ganqu Cui",
      "Sen Yang",
      "Yu Cheng"
    ],
    "abstract": "Scaling data and model size has been proven effective for boosting the\nperformance of large language models. In addition to training-time scaling,\nrecent studies have revealed that increasing test-time computational resources\ncan further improve performance. In this work, we introduce Aggregation\nFine-Tuning (AFT), a supervised finetuning paradigm where the model learns to\nsynthesize multiple draft responses, referred to as proposals, into a single,\nrefined answer, termed aggregation. At inference time, a propose-and-aggregate\nstrategy further boosts performance by iteratively generating proposals and\naggregating them. Empirical evaluations on benchmark datasets show that\nAFT-trained models substantially outperform standard SFT. Notably, an AFT\nmodel, fine-tuned from Llama3.1-8B-Base with only 64k data, achieves a 41.3% LC\nwin rate on AlpacaEval 2, surpassing significantly larger LLMs such as\nLlama3.1-405B-Instruct and GPT4. By combining sequential refinement and\nparallel sampling, the propose-and-aggregate framework scales inference-time\ncomputation in a flexible manner. Overall, These findings position AFT as a\npromising approach to unlocking additional capabilities of LLMs without\nresorting to increasing data volume or model size.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "20 pages; work in progress",
    "pdf_url": "http://arxiv.org/pdf/2501.11877v1",
    "published_date": "2025-01-21 04:11:59 UTC",
    "updated_date": "2025-01-21 04:11:59 UTC"
  },
  {
    "arxiv_id": "2501.13957v2",
    "title": "Benchmarking Generative AI for Scoring Medical Student Interviews in Objective Structured Clinical Examinations (OSCEs)",
    "authors": [
      "Jadon Geathers",
      "Yann Hicke",
      "Colleen Chan",
      "Niroop Rajashekar",
      "Justin Sewell",
      "Susannah Cornes",
      "Rene F. Kizilcec",
      "Dennis Shung"
    ],
    "abstract": "Objective Structured Clinical Examinations (OSCEs) are widely used to assess\nmedical students' communication skills, but scoring interview-based assessments\nis time-consuming and potentially subject to human bias. This study explored\nthe potential of large language models (LLMs) to automate OSCE evaluations\nusing the Master Interview Rating Scale (MIRS). We compared the performance of\nfour state-of-the-art LLMs (GPT-4o, Claude 3.5, Llama 3.1, and Gemini 1.5 Pro)\nin evaluating OSCE transcripts across all 28 items of the MIRS under the\nconditions of zero-shot, chain-of-thought (CoT), few-shot, and multi-step\nprompting. The models were benchmarked against a dataset of 10 OSCE cases with\n174 expert consensus scores available. Model performance was measured using\nthree accuracy metrics (exact, off-by-one, thresholded). Averaging across all\nMIRS items and OSCE cases, LLMs performed with low exact accuracy (0.27 to\n0.44), and moderate to high off-by-one accuracy (0.67 to 0.87) and thresholded\naccuracy (0.75 to 0.88). A zero temperature parameter ensured high intra-rater\nreliability ({\\alpha} = 0.98 for GPT-4o). CoT, few-shot, and multi-step\ntechniques proved valuable when tailored to specific assessment items. The\nperformance was consistent across MIRS items, independent of encounter phases\nand communication domains. We demonstrated the feasibility of AI-assisted OSCE\nevaluation and provided benchmarking of multiple LLMs across multiple prompt\ntechniques. Our work provides a baseline performance assessment for LLMs that\nlays a foundation for future research into automated assessment of clinical\ncommunication skills.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "12 pages + 3 pages of references, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.13957v2",
    "published_date": "2025-01-21 04:05:45 UTC",
    "updated_date": "2025-05-15 17:09:21 UTC"
  },
  {
    "arxiv_id": "2501.11870v2",
    "title": "Coarse-to-Fine Lightweight Meta-Embedding for ID-Based Recommendation",
    "authors": [
      "Yang Wang",
      "Haipeng Liu",
      "Zeqian Yi",
      "Biao Qian",
      "Meng Wang"
    ],
    "abstract": "The state-of-the-art recommendation systems have shifted the attention to\nefficient recommendation, e.g., on-device recommendation, under memory\nconstraints. To this end, the existing methods either focused on the\nlightweight embeddings for both users and items, or involved on-device systems\nenjoying the compact embeddings to enhance reusability and reduces space\ncomplexity. However, they focus solely on the coarse granularity of embedding,\nwhile overlook the fine-grained semantic nuances, to adversarially downgrade\nthe efficacy of meta-embeddings in capturing the intricate relationship over\nboth user and item, consequently resulting into the suboptimal recommendations.\nIn this paper, we aim to study how the meta-embedding can efficiently learn\nvaried grained semantics, together with how the fine-grained meta-embedding can\nstrengthen the representation of coarse-grained meta-embedding. To answer these\nquestions, we develop a novel graph neural networks (GNNs) based recommender\nwhere each user and item serves as the node, linked directly to coarse-grained\nvirtual nodes and indirectly to fine-grained virtual nodes, ensuring different\ngrained semantic learning, while disclosing: 1) In contrast to coarse-grained\nsemantics, fine-grained semantics are well captured through sparse\nmeta-embeddings, which adaptively 2) balance the embedding uniqueness and\nmemory constraint. Additionally, the initialization method come up upon\nSparsePCA, along with a soft thresholding activation function to render the\nsparseness of the meta-embeddings. We propose a weight bridging update strategy\nthat focuses on matching each coarse-grained meta-embedding with several\nfine-grained meta-embeddings based on the users/items' semantics. Extensive\nexperiments substantiate our method's superiority over existing baselines. Our\ncode is available at https://github.com/htyjers/C2F-MetaEmbed.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "16 pages, 6 figures, accepted to appear at Science China Information\n  Sciences",
    "pdf_url": "http://arxiv.org/pdf/2501.11870v2",
    "published_date": "2025-01-21 03:56:23 UTC",
    "updated_date": "2025-03-19 01:12:41 UTC"
  },
  {
    "arxiv_id": "2501.13122v1",
    "title": "Zero-Shot Verification-guided Chain of Thoughts",
    "authors": [
      "Jishnu Ray Chowdhury",
      "Cornelia Caragea"
    ],
    "abstract": "Previous works have demonstrated the effectiveness of Chain-of-Thought (COT)\nprompts and verifiers in guiding Large Language Models (LLMs) through the space\nof reasoning. However, most such studies either use a fine-tuned verifier or\nrely on manually handcrafted few-shot examples. In contrast, in this paper, we\nfocus on LLM-based self-verification of self-generated reasoning steps via COT\nprompts in a completely zero-shot regime. To explore this setting, we design a\nnew zero-shot prompt, which we call COT STEP, to aid zero-shot decomposition of\nreasoning steps and design two new zero-shot prompts for LLM-based verifiers.\nWe evaluate the verifiers' ability to classify the correctness of reasoning\nchains and explore different ways to use verifier scores in guiding reasoning\nfor various mathematical and commonsense reasoning tasks with different LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.13122v1",
    "published_date": "2025-01-21 03:52:54 UTC",
    "updated_date": "2025-01-21 03:52:54 UTC"
  },
  {
    "arxiv_id": "2501.11849v3",
    "title": "Network-informed Prompt Engineering against Organized Astroturf Campaigns under Extreme Class Imbalance",
    "authors": [
      "Nikos Kanakaris",
      "Heng Ping",
      "Xiongye Xiao",
      "Nesreen K. Ahmed",
      "Luca Luceri",
      "Emilio Ferrara",
      "Paul Bogdan"
    ],
    "abstract": "Detecting organized political campaigns is of paramount importance in\nfighting against disinformation on social media. Existing approaches for the\nidentification of such organized actions employ techniques mostly from network\nscience, graph machine learning and natural language processing. Their ultimate\ngoal is to analyze the relationships and interactions (e.g. re-posting) among\nusers and the textual similarities of their posts. Despite their effectiveness\nin recognizing astroturf campaigns, these methods face significant challenges,\nnotably the class imbalance in available training datasets. To mitigate this\nissue, recent methods usually resort to data augmentation or increasing the\nnumber of positive samples, which may not always be feasible or sufficient in\nreal-world settings. Following a different path, in this paper, we propose a\nnovel framework for identifying astroturf campaigns based solely on large\nlanguage models (LLMs), introducing a Balanced Retrieval-Augmented Generation\n(Balanced RAG) component. Our approach first gives both textual information\nconcerning the posts (in our case tweets) and the user interactions of the\nsocial network as input to a language model. Then, through prompt engineering\nand the proposed Balanced RAG method, it effectively detects coordinated\ndisinformation campaigns on X (Twitter). The proposed framework does not\nrequire any training or fine-tuning of the language model. Instead, by\nstrategically harnessing the strengths of prompt engineering and Balanced RAG,\nit facilitates LLMs to overcome the effects of class imbalance and effectively\nidentify coordinated political campaigns. The experimental results demonstrate\nthat by incorporating the proposed prompt engineering and Balanced RAG methods,\nour framework outperforms the traditional graph-based baselines, achieving\n2x-3x improvements in terms of precision, recall and F1 scores.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.11849v3",
    "published_date": "2025-01-21 03:07:21 UTC",
    "updated_date": "2025-02-18 03:18:53 UTC"
  },
  {
    "arxiv_id": "2501.11847v1",
    "title": "A Survey on Memory-Efficient Large-Scale Model Training in AI for Science",
    "authors": [
      "Kaiyuan Tian",
      "Linbo Qiao",
      "Baihui Liu",
      "Gongqingjian Jiang",
      "Dongsheng Li"
    ],
    "abstract": "Scientific research faces high costs and inefficiencies with traditional\nmethods, but the rise of deep learning and large language models (LLMs) offers\ninnovative solutions. This survey reviews LLM applications across scientific\nfields such as biology, medicine, chemistry, and meteorology, underscoring\ntheir role in advancing research. However, the continuous expansion of model\nsize has led to significant memory demands, hindering further development and\napplication of LLMs for science. To address this, we review memory-efficient\ntraining techniques for LLMs based on the transformer architecture, including\ndistributed training, mixed precision training, and gradient checkpointing.\nUsing AlphaFold 2 as an example, we demonstrate how tailored memory\noptimization methods can reduce storage needs while preserving prediction\naccuracy. We also discuss the challenges of memory optimization in practice and\npotential future directions, hoping to provide valuable insights for\nresearchers and engineers.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.11847v1",
    "published_date": "2025-01-21 03:06:30 UTC",
    "updated_date": "2025-01-21 03:06:30 UTC"
  },
  {
    "arxiv_id": "2501.11839v1",
    "title": "Supervised Learning for Analog and RF Circuit Design: Benchmarks and Comparative Insights",
    "authors": [
      "Asal Mehradfar",
      "Xuzhe Zhao",
      "Yue Niu",
      "Sara Babakniya",
      "Mahdi Alesheikh",
      "Hamidreza Aghasi",
      "Salman Avestimehr"
    ],
    "abstract": "Automating analog and radio-frequency (RF) circuit design using machine\nlearning (ML) significantly reduces the time and effort required for parameter\noptimization. This study explores supervised ML-based approaches for designing\ncircuit parameters from performance specifications across various circuit\ntypes, including homogeneous and heterogeneous designs. By evaluating diverse\nML models, from neural networks like transformers to traditional methods like\nrandom forests, we identify the best-performing models for each circuit. Our\nresults show that simpler circuits, such as low-noise amplifiers, achieve\nexceptional accuracy with mean relative errors as low as 0.3% due to their\nlinear parameter-performance relationships. In contrast, complex circuits, like\npower amplifiers and voltage-controlled oscillators, present challenges due to\ntheir non-linear interactions and larger design spaces. For heterogeneous\ncircuits, our approach achieves an 88% reduction in errors with increased\ntraining data, with the receiver achieving a mean relative error as low as\n0.23%, showcasing the scalability and accuracy of the proposed methodology.\nAdditionally, we provide insights into model strengths, with transformers\nexcelling in capturing non-linear mappings and k-nearest neighbors performing\nrobustly in moderately linear parameter spaces, especially in heterogeneous\ncircuits with larger datasets. This work establishes a foundation for extending\nML-driven design automation, enabling more efficient and scalable circuit\ndesign workflows.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.11839v1",
    "published_date": "2025-01-21 02:48:23 UTC",
    "updated_date": "2025-01-21 02:48:23 UTC"
  },
  {
    "arxiv_id": "2501.11836v1",
    "title": "Data-driven Detection and Evaluation of Damages in Concrete Structures: Using Deep Learning and Computer Vision",
    "authors": [
      "Saeid Ataei",
      "Saeed Adibnazari",
      "Seyyed Taghi Ataei"
    ],
    "abstract": "Structural integrity is vital for maintaining the safety and longevity of\nconcrete infrastructures such as bridges, tunnels, and walls. Traditional\nmethods for detecting damages like cracks and spalls are labor-intensive,\ntime-consuming, and prone to human error. To address these challenges, this\nstudy explores advanced data-driven techniques using deep learning for\nautomated damage detection and analysis. Two state-of-the-art instance\nsegmentation models, YOLO-v7 instance segmentation and Mask R-CNN, were\nevaluated using a dataset comprising 400 images, augmented to 10,995 images\nthrough geometric and color-based transformations to enhance robustness. The\nmodels were trained and validated using a dataset split into 90% training set,\nvalidation and test set 10%. Performance metrics such as precision, recall,\nmean average precision (mAP@0.5), and frames per second (FPS) were used for\nevaluation. YOLO-v7 achieved a superior mAP@0.5 of 96.1% and processed 40 FPS,\noutperforming Mask R-CNN, which achieved a mAP@0.5 of 92.1% with a slower\nprocessing speed of 18 FPS. The findings recommend YOLO-v7 instance\nsegmentation model for real-time, high-speed structural health monitoring,\nwhile Mask R-CNN is better suited for detailed offline assessments. This study\ndemonstrates the potential of deep learning to revolutionize infrastructure\nmaintenance, offering a scalable and efficient solution for automated damage\ndetection.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "68A00 (Primary), 68C02 (Secondary)"
    ],
    "primary_category": "cs.CV",
    "comment": "17 pages, 10 figures. This study focuses on the data-driven detection\n  and evaluation of damages in concrete structures using deep learning and\n  computer vision techniques",
    "pdf_url": "http://arxiv.org/pdf/2501.11836v1",
    "published_date": "2025-01-21 02:44:05 UTC",
    "updated_date": "2025-01-21 02:44:05 UTC"
  },
  {
    "arxiv_id": "2501.11833v1",
    "title": "Is your LLM trapped in a Mental Set? Investigative study on how mental sets affect the reasoning capabilities of LLMs",
    "authors": [
      "Saiful Haq",
      "Niyati Chhaya",
      "Piyush Pandey",
      "Pushpak Bhattacharya"
    ],
    "abstract": "In this paper, we present an investigative study on how Mental Sets influence\nthe reasoning capabilities of LLMs. LLMs have excelled in diverse natural\nlanguage processing (NLP) tasks, driven by advancements in parameter-efficient\nfine-tuning (PEFT) and emergent capabilities like in-context learning (ICL).\nFor complex reasoning tasks, selecting the right model for PEFT or ICL is\ncritical, often relying on scores on benchmarks such as MMLU, MATH, and GSM8K.\nHowever, current evaluation methods, based on metrics like F1 Score or\nreasoning chain assessments by larger models, overlook a key dimension:\nadaptability to unfamiliar situations and overcoming entrenched thinking\npatterns. In cognitive psychology, Mental Set refers to the tendency to persist\nwith previously successful strategies, even when they become inefficient - a\nchallenge for problem solving and reasoning. We compare the performance of LLM\nmodels like Llama-3.1-8B-Instruct, Llama-3.1-70B-Instruct and GPT-4o in the\npresence of mental sets. To the best of our knowledge, this is the first study\nto integrate cognitive psychology concepts into the evaluation of LLMs for\ncomplex reasoning tasks, providing deeper insights into their adaptability and\nproblem-solving efficacy.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.11833v1",
    "published_date": "2025-01-21 02:29:15 UTC",
    "updated_date": "2025-01-21 02:29:15 UTC"
  },
  {
    "arxiv_id": "2501.13121v1",
    "title": "Episodic Memories Generation and Evaluation Benchmark for Large Language Models",
    "authors": [
      "Alexis Huet",
      "Zied Ben Houidi",
      "Dario Rossi"
    ],
    "abstract": "Episodic memory -- the ability to recall specific events grounded in time and\nspace -- is a cornerstone of human cognition, enabling not only coherent\nstorytelling, but also planning and decision-making. Despite their remarkable\ncapabilities, Large Language Models (LLMs) lack a robust mechanism for episodic\nmemory: we argue that integrating episodic memory capabilities into LLM is\nessential for advancing AI towards human-like cognition, increasing their\npotential to reason consistently and ground their output in real-world episodic\nevents, hence avoiding confabulations. To address this challenge, we introduce\na comprehensive framework to model and evaluate LLM episodic memory\ncapabilities. Drawing inspiration from cognitive science, we develop a\nstructured approach to represent episodic events, encapsulating temporal and\nspatial contexts, involved entities, and detailed descriptions. We synthesize a\nunique episodic memory benchmark, free from contamination, and release open\nsource code and datasets to assess LLM performance across various recall and\nepisodic reasoning tasks. Our evaluation of state-of-the-art models, including\nGPT-4 and Claude variants, Llama 3.1, and o1-mini, reveals that even the most\nadvanced LLMs struggle with episodic memory tasks, particularly when dealing\nwith multiple related events or complex spatio-temporal relationships -- even\nin contexts as short as 10k-100k tokens.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.13121v1",
    "published_date": "2025-01-21 02:16:13 UTC",
    "updated_date": "2025-01-21 02:16:13 UTC"
  },
  {
    "arxiv_id": "2501.11828v1",
    "title": "Fact-Preserved Personalized News Headline Generation",
    "authors": [
      "Zhao Yang",
      "Junhong Lian",
      "Xiang Ao"
    ],
    "abstract": "Personalized news headline generation, aiming at generating user-specific\nheadlines based on readers' preferences, burgeons a recent flourishing research\ndirection. Existing studies generally inject a user interest embedding into an\nencoderdecoder headline generator to make the output personalized, while the\nfactual consistency of headlines is inadequate to be verified. In this paper,\nwe propose a framework Fact-Preserved Personalized News Headline Generation\n(short for FPG), to prompt a tradeoff between personalization and consistency.\nIn FPG, the similarity between the candidate news to be exposed and the\nhistorical clicked news is used to give different levels of attention to key\nfacts in the candidate news, and the similarity scores help to learn a\nfact-aware global user embedding. Besides, an additional training procedure\nbased on contrastive learning is devised to further enhance the factual\nconsistency of generated headlines. Extensive experiments conducted on a\nreal-world benchmark PENS validate the superiority of FPG, especially on the\ntradeoff between personalization and factual consistency.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by IEEE ICDM 2023, Short paper, 6 pages",
    "pdf_url": "http://arxiv.org/pdf/2501.11828v1",
    "published_date": "2025-01-21 02:14:07 UTC",
    "updated_date": "2025-01-21 02:14:07 UTC"
  },
  {
    "arxiv_id": "2501.11827v1",
    "title": "PXGen: A Post-hoc Explainable Method for Generative Models",
    "authors": [
      "Yen-Lung Huang",
      "Ming-Hsi Weng",
      "Hao-Tsung Yang"
    ],
    "abstract": "With the rapid growth of generative AI in numerous applications, explainable\nAI (XAI) plays a crucial role in ensuring the responsible development and\ndeployment of generative AI technologies. XAI has undergone notable\nadvancements and widespread adoption in recent years, reflecting a concerted\npush to enhance the transparency, interpretability, and credibility of AI\nsystems. Recent research emphasizes that a proficient XAI method should adhere\nto a set of criteria, primarily focusing on two key areas. Firstly, it should\nensure the quality and fluidity of explanations, encompassing aspects like\nfaithfulness, plausibility, completeness, and tailoring to individual needs.\nSecondly, the design principle of the XAI system or mechanism should cover the\nfollowing factors such as reliability, resilience, the verifiability of its\noutputs, and the transparency of its algorithm. However, research in XAI for\ngenerative models remains relatively scarce, with little exploration into how\nsuch methods can effectively meet these criteria in that domain. In this work,\nwe propose PXGen, a post-hoc explainable method for generative models. Given a\nmodel that needs to be explained, PXGen prepares two materials for the\nexplanation, the Anchor set and intrinsic & extrinsic criteria. Those materials\nare customizable by users according to their purpose and requirements. Via the\ncalculation of each criterion, each anchor has a set of feature values and\nPXGen provides examplebased explanation methods according to the feature values\namong all the anchors and illustrated and visualized to the users via tractable\nalgorithms such as k-dispersion or k-center.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.11827v1",
    "published_date": "2025-01-21 02:10:50 UTC",
    "updated_date": "2025-01-21 02:10:50 UTC"
  },
  {
    "arxiv_id": "2501.11823v1",
    "title": "Toward Scalable Graph Unlearning: A Node Influence Maximization based Approach",
    "authors": [
      "Xunkai Li",
      "Bowen Fan",
      "Zhengyu Wu",
      "Zhiyu Li",
      "Rong-Hua Li",
      "Guoren Wang"
    ],
    "abstract": "Machine unlearning, as a pivotal technology for enhancing model robustness\nand data privacy, has garnered significant attention in prevalent web mining\napplications, especially in thriving graph-based scenarios. However, most\nexisting graph unlearning (GU) approaches face significant challenges due to\nthe intricate interactions among web-scale graph elements during the model\ntraining: (1) The gradient-driven node entanglement hinders the complete\nknowledge removal in response to unlearning requests; (2) The billion-level\ngraph elements in the web scenarios present inevitable scalability issues. To\nbreak the above limitations, we open up a new perspective by drawing a\nconnection between GU and conventional social influence maximization. To this\nend, we propose Node Influence Maximization (NIM) through the decoupled\ninfluence propagation model and fine-grained influence function in a scalable\nmanner, which is crafted to be a plug-and-play strategy to identify potential\nnodes affected by unlearning entities. This approach enables offline execution\nindependent of GU, allowing it to be seamlessly integrated into most GU methods\nto improve their unlearning performance. Based on this, we introduce Scalable\nGraph Unlearning (SGU) as a new fine-tuned framework, which balances the\nforgetting and reasoning capability of the unlearned model by entity-specific\noptimizations. Extensive experiments on 14 datasets, including large-scale\nogbn-papers100M, have demonstrated the effectiveness of our approach.\nSpecifically, NIM enhances the forgetting capability of most GU methods, while\nSGU achieves comprehensive SOTA performance and maintains scalability.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DB",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "Under Review",
    "pdf_url": "http://arxiv.org/pdf/2501.11823v1",
    "published_date": "2025-01-21 02:02:35 UTC",
    "updated_date": "2025-01-21 02:02:35 UTC"
  },
  {
    "arxiv_id": "2501.11817v1",
    "title": "Toward Effective Digraph Representation Learning: A Magnetic Adaptive Propagation based Approach",
    "authors": [
      "Xunkai Li",
      "Daohan Su",
      "Zhengyu Wu",
      "Guang Zeng",
      "Hongchao Qin",
      "Rong-Hua Li",
      "Guoren Wang"
    ],
    "abstract": "The $q$-parameterized magnetic Laplacian serves as the foundation of directed\ngraph (digraph) convolution, enabling this kind of digraph neural network\n(MagDG) to encode node features and structural insights by complex-domain\nmessage passing. As a generalization of undirected methods, MagDG shows\nsuperior capability in modeling intricate web-scale topology. Despite the great\nsuccess achieved by existing MagDGs, limitations still exist: (1) Hand-crafted\n$q$: The performance of MagDGs depends on selecting an appropriate\n$q$-parameter to construct suitable graph propagation equations in the complex\ndomain. This parameter tuning, driven by downstream tasks, limits model\nflexibility and significantly increases manual effort. (2) Coarse Message\nPassing: Most approaches treat all nodes with the same complex-domain\npropagation and aggregation rules, neglecting their unique digraph contexts.\nThis oversight results in sub-optimal performance. To address the above issues,\nwe propose two key techniques: (1) MAP is crafted to be a plug-and-play\ncomplex-domain propagation optimization strategy in the context of digraph\nlearning, enabling seamless integration into any MagDG to improve predictions\nwhile enjoying high running efficiency. (2) MAP++ is a new digraph learning\nframework, further incorporating a learnable mechanism to achieve adaptively\nedge-wise propagation and node-wise aggregation in the complex domain for\nbetter performance. Extensive experiments on 12 datasets demonstrate that MAP\nenjoys flexibility for it can be incorporated with any MagDG, and scalability\nas it can deal with web-scale digraphs. MAP++ achieves SOTA predictive\nperformance on 4 different downstream tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DB",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by WWW 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.11817v1",
    "published_date": "2025-01-21 01:52:02 UTC",
    "updated_date": "2025-01-21 01:52:02 UTC"
  },
  {
    "arxiv_id": "2501.11799v1",
    "title": "Policy-Adaptable Methods For Resolving Normative Conflicts Through Argumentation and Graph Colouring",
    "authors": [
      "Johnny Joyce"
    ],
    "abstract": "In a multi-agent system, one may choose to govern the behaviour of an agent\nby imposing norms, which act as guidelines for how agents should act either all\nof the time or in given situations. However, imposing multiple norms on one or\nmore agents may result in situations where these norms conflict over how the\nagent should behave. In any system with normative conflicts (such as safe\nreinforcement models or systems which monitor safety protocols), one must\ndecide which norms should be followed such that the most important and most\nrelevant norms are maintained. We introduce a new method for resolving\nnormative conflicts through argumentation and graph colouring which is\ncompatible with a variety of normative conflict resolution policies. We prove\nthat this method always creates an admissible set of arguments under\nargumentation semantics, meaning that it produces coherent outputs. We also\nintroduce more robust variants of this method, each building upon their\npredecessor to create a superior output, and we include further mathematical\nproof of their coherence. Our most advanced variant uses the existing concept\nof curtailment, where one norm may supersede another without fully eliminating\nit. The methods we introduce are all compatible with various pre-existing\npolicies for resolving normative conflicts. Empirical evaluations are also\nperformed to compare our algorithms to each other and to others in existing\nliterature.",
    "categories": [
      "cs.AI",
      "cs.LO",
      "math.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "Written and submitted as master's thesis for University of\n  Southampton in 2020",
    "pdf_url": "http://arxiv.org/pdf/2501.11799v1",
    "published_date": "2025-01-21 00:32:49 UTC",
    "updated_date": "2025-01-21 00:32:49 UTC"
  },
  {
    "arxiv_id": "2502.10401v1",
    "title": "You Can't Get There From Here: Redefining Information Science to address our sociotechnical futures",
    "authors": [
      "Scott Humr",
      "Mustafa Canan"
    ],
    "abstract": "Current definitions of Information Science are inadequate to comprehensively\ndescribe the nature of its field of study and for addressing the problems that\nare arising from intelligent technologies. The ubiquitous rise of artificial\nintelligence applications and their impact on society demands the field of\nInformation Science acknowledge the sociotechnical nature of these\ntechnologies. Previous definitions of Information Science over the last six\ndecades have inadequately addressed the environmental, human, and social\naspects of these technologies. This perspective piece advocates for an expanded\ndefinition of Information Science that fully includes the sociotechnical\nimpacts information has on the conduct of research in this field. Proposing an\nexpanded definition of Information Science that includes the sociotechnical\naspects of this field should stimulate both conversation and widen the\ninterdisciplinary lens necessary to address how intelligent technologies may be\nincorporated into society and our lives more fairly.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "18 pages, information science, artificial intelligence,sociotechnical\n  systems, fairness",
    "pdf_url": "http://arxiv.org/pdf/2502.10401v1",
    "published_date": "2025-01-21 00:30:33 UTC",
    "updated_date": "2025-01-21 00:30:33 UTC"
  },
  {
    "arxiv_id": "2501.16361v1",
    "title": "Large Language Models Meet Graph Neural Networks for Text-Numeric Graph Reasoning",
    "authors": [
      "Haoran Song",
      "Jiarui Feng",
      "Guangfu Li",
      "Michael Province",
      "Philip Payne",
      "Yixin Chen",
      "Fuhai Li"
    ],
    "abstract": "In real-world scientific discovery, human beings always make use of the\naccumulated prior knowledge with imagination pick select one or a few most\npromising hypotheses from large and noisy data analysis results. In this study,\nwe introduce a new type of graph structure, the text-numeric graph (TNG), which\nis defined as graph entities and associations have both text-attributed\ninformation and numeric information. The TNG is an ideal data structure model\nfor novel scientific discovery via graph reasoning because it integrates\nhuman-understandable textual annotations or prior knowledge, with numeric\nvalues that represent the observed or activation levels of graph entities or\nassociations in different samples. Together both the textual information and\nnumeric values determine the importance of graph entities and associations in\ngraph reasoning for novel scientific knowledge discovery. We further propose\nintegrating large language models (LLMs) and graph neural networks (GNNs) to\nanalyze the TNGs for graph understanding and reasoning. To demonstrate the\nutility, we generated the text-omic(numeric) signaling graphs (TOSG), as one\ntype of TNGs, in which all graphs have the same entities, associations and\nannotations, but have sample-specific entity numeric (omic) values using single\ncell RNAseq (scRNAseq) datasets of different diseases. We proposed joint\nLLM-GNN models for key entity mining and signaling pathway mining on the TOSGs.\nThe evaluation results showed the LLM-GNN and TNGs models significantly improve\nclassification accuracy and network inference. In conclusion, the TNGs and\njoint LLM-GNN models are important approaches for scientific discovery.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "29 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.16361v1",
    "published_date": "2025-01-21 00:29:23 UTC",
    "updated_date": "2025-01-21 00:29:23 UTC"
  }
]