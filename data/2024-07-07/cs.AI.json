{
  "date": "2024-07-07",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-07-07 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 更新了 51 篇论文，主要聚焦 AI 模型优化、机器学习应用和医疗图像处理等领域，其中 IBM 团队的 AI 基础设施论文（第 6 篇）以及 LLM 相关研究（如第 3、13 篇）令人印象深刻，强调了多语言模型的偏见问题和语言表示在推荐系统的潜力，同时一些知名学者和会议（如 NeurIPS、ICLR）论文突显了 AI 在实际场景中的创新与挑战。\n\n下面，我将挑选并简要讨论部分重要论文，先优先聊那些有创新性、话题度高或知名作者的作品，并将相关主题归类。其他较常规的论文（如纯理论回顾或小规模实验）将快速掠过，只列出标题和核心点。\n\n### AI 模型与 LLM 相关（重点讨论，创新性强）\n- **Faux Polyglot: A Study on Information Disparity in Multilingual Large Language Models（《多语言大型语言模型的信息不均衡研究》）**  \n  这篇论文探讨了 LLM 在多语言检索中的系统偏见，发现模型偏向查询语言相同的文档，并在高资源语言中强化主导观点。主要贡献是通过实验揭示了 LLM 可能加剧语言不平等，强调在信息搜索系统中需要关注低资源语言的公平性。\n\n- **Enhancing Hallucination Detection through Perturbation-Based Synthetic Data Generation in System Responses（《通过基于扰动的合成数据生成增强幻觉检测》）**  \n  作者使用自动生成的数据细调 T5 模型，显著提高了幻觉检测的准确性和速度。论文的核心发现是，这种方法超越了现有零样本检测器，适用于快速变化的 LLM 领域，尤其在 ACL 2024 的背景下，具有实际应用潜力。\n\n- **Language Representations Can be What Recommenders Need: Findings and Potentials（《语言表示可用于推荐系统：发现与潜力》）**  \n  这篇 ICLR 2025 论文（作者包括 Xiang Wang）发现，高级语言模型的表示可以通过线性映射直接用于推荐系统，提升了性能。主要贡献是证明了行为建模与语言建模的联系，并提出简单模型可超越传统协同过滤，代码已开源。\n\n- **LTLBench: Towards Benchmarks for Evaluating Temporal Logic Reasoning in Large Language Models（《LTLBench：评估大型语言模型时间逻辑推理的基准》）**  \n  论文引入了一个新基准数据集，用于评估 LLM 的时间推理能力，通过实验显示 LLM 在复杂任务中表现欠佳。主要发现是，增加事件数会加剧难度，这为未来 LLM 评估提供了工具。\n\n### 医疗图像与硬件优化（实用性和影响较大）\n- **Accelerating MRI Uncertainty Estimation with Mask-based Bayesian Neural Network（《使用基于掩码的贝叶斯神经网络加速 MRI 不确定性估计》）**  \n  这篇 ASAP 2024 论文提出算法-硬件联合优化框架，将 IVIM-NET 转化为掩码-based BayesNN，提升了 MRI 分析的可靠性和速度。核心贡献是实验证明了在 FPGA 上实现 7.5 倍于 GPU 的加速，同时保持不确定性校准。\n\n- **FM-OSD: Foundation Model-Enabled One-Shot Detection of Anatomical Landmarks（《FM-OSD：基础模型启用的一次性解剖 landmarks 检测》）**  \n  作者利用视觉基础模型和双分支解码器，仅需一个模板图像即可实现高精度医学图像检测。论文的关键发现是，该方法在无需额外数据的情况下超越了现有技术，适用于 MICCAI 2024 的场景。\n\n- **Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification（《可解释 AI：正常和扩张 ResNet 模型在眼底疾病分类中的比较分析》）**  \n  论文比较了正常和扩张 ResNet 模型，发现扩张版本提高了眼底疾病分类的准确性和计算效率。核心贡献是通过可解释 AI 技术增强了诊断工具的透明度，F1 分数平均达 0.70。\n\n### 其他创新应用与模型优化（快速提及，相关主题归类）\n- **Differentiable Modal Synthesis for Physical Modeling of Planar String Sound and Motion Simulation（《可微模态合成用于平面弦音和运动模拟的物理建模》）**  \n  这篇 NeurIPS 2024 论文引入神经网络框架模拟弦振动，实现了比基线更高的准确性。主要发现是，该模型能解决非线性弦的偏微分方程，代码和演示已公开。\n\n- **The infrastructure powering IBM's Gen AI model development（《驱动 IBM 生成式 AI 模型开发的基础设施》）**  \n  IBM 团队的多作者论文描述了 Vela 和 Blue Vela 等混合云基础设施，支持大规模 AI 训练。核心贡献是展示了如何优化硬件和软件以适应生成式 AI 的需求，强调了高性能和灵活性。\n\n- **BiRoDiff: Diffusion policies for bipedal robot locomotion on unseen terrains（《BiRoDiff：用于双足机器人未知地形行走的扩散策略》）**  \n  论文提出基于扩散模型的实时控制器，支持机器人适应未知地形。主要发现是，该方法在模拟中实现了高效泛化，适用于机器人应用。\n\n对于其他论文，如第9（AI 在业务流程管理的回顾，第9篇《A Review of AI and Machine Learning Contribution in Predictive Business Process Management》）、第11（认知诊断模型调查，第11篇《A Survey of Models for Cognitive Diagnosis》）和第18（网络架构优化，第18篇《EMBANet: A Flexible Efficient Multi-branch Attention Network》），这些更偏向于综述或技术改进，我仅快速掠过：它们提供了 AI 在流程管理和图像任务中的新框架，但细节较常规，不如上述论文话题度高。\n\n总之，今天的更新突显了 AI 在医疗和语言领域的潜力，但也暴露了偏见和泛化挑战。读者可关注 LLM 和硬件优化相关论文，以探索实际应用。更多细节请查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2407.05521v1",
      "title": "Accelerating MRI Uncertainty Estimation with Mask-based Bayesian Neural Network",
      "title_zh": "基于掩码的贝叶斯神经网络加速 MRI",
      "authors": [
        "Zehuan Zhang",
        "Matej Genci",
        "Hongxiang Fan",
        "Andreas Wetscherek",
        "Wayne Luk"
      ],
      "abstract": "Accurate and reliable Magnetic Resonance Imaging (MRI) analysis is\nparticularly important for adaptive radiotherapy, a recent medical advance\ncapable of improving cancer diagnosis and treatment. Recent studies have shown\nthat IVIM-NET, a deep neural network (DNN), can achieve high accuracy in MRI\nanalysis, indicating the potential of deep learning to enhance diagnostic\ncapabilities in healthcare. However, IVIM-NET does not provide calibrated\nuncertainty information needed for reliable and trustworthy predictions in\nhealthcare. Moreover, the expensive computation and memory demands of IVIM-NET\nreduce hardware performance, hindering widespread adoption in realistic\nscenarios. To address these challenges, this paper proposes an\nalgorithm-hardware co-optimization flow for high-performance and reliable MRI\nanalysis. At the algorithm level, a transformation design flow is introduced to\nconvert IVIM-NET to a mask-based Bayesian Neural Network (BayesNN),\nfacilitating reliable and efficient uncertainty estimation. At the hardware\nlevel, we propose an FPGA-based accelerator with several hardware\noptimizations, such as mask-zero skipping and operation reordering.\nExperimental results demonstrate that our co-design approach can satisfy the\nuncertainty requirements of MRI analysis, while achieving 7.5 times and 32.5\ntimes speedup on an Xilinx VU13P FPGA compared to GPU and CPU implementations\nwith reduced power consumption.",
      "tldr_zh": "该论文针对MRI分析中的不确定性估计问题，提出了一种算法-硬件联合优化方案，以提升医疗诊断的可靠性和效率。具体来说，在算法层面，将IVIM-NET转换为基于掩码的Bayesian Neural Network (BayesNN)，从而实现校准的不确定性估计并降低计算需求；在硬件层面，设计了FPGA-based加速器，包括mask-zero skipping和operation reordering等优化。实验结果显示，该方法在Xilinx VU13P FPGA上比GPU快7.5倍、比CPU快32.5倍，同时减少功耗，并满足MRI分析的可靠性要求。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "The 35th IEEE International Conference on Application-specific\n  Systems, Architectures and Processors (ASAP) 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.05521v1",
      "published_date": "2024-07-07 23:57:40 UTC",
      "updated_date": "2024-07-07 23:57:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:12:49.431858"
    },
    {
      "arxiv_id": "2407.05516v2",
      "title": "Differentiable Modal Synthesis for Physical Modeling of Planar String Sound and Motion Simulation",
      "title_zh": "翻译失败",
      "authors": [
        "Jin Woo Lee",
        "Jaehyun Park",
        "Min Jun Choi",
        "Kyogu Lee"
      ],
      "abstract": "While significant advancements have been made in music generation and\ndifferentiable sound synthesis within machine learning and computer audition,\nthe simulation of instrument vibration guided by physical laws has been\nunderexplored. To address this gap, we introduce a novel model for simulating\nthe spatio-temporal motion of nonlinear strings, integrating modal synthesis\nand spectral modeling within a neural network framework. Our model leverages\nphysical properties and fundamental frequencies as inputs, outputting string\nstates across time and space that solve the partial differential equation\ncharacterizing the nonlinear string. Empirical evaluations demonstrate that the\nproposed architecture achieves superior accuracy in string motion simulation\ncompared to existing baseline architectures. The code and demo are available\nonline.",
      "tldr_zh": "本文提出一种新模型，用于模拟非线性弦的时空运动，旨在填补物理定律引导的乐器振动模拟领域的空白。该模型整合了 modal synthesis 和 spectral modeling 到神经网络框架中，以物理属性和基本频率作为输入，输出弦在时间和空间上的状态，从而解决表征非线性弦的部分微分方程。实验评估显示，该架构在弦运动模拟方面比现有基线模型更准确，且相关代码和演示已在线公开。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD",
        "eess.SP"
      ],
      "primary_category": "eess.AS",
      "comment": "38th Conference on Neural Information Processing Systems (NeurIPS\n  2024)",
      "pdf_url": "http://arxiv.org/pdf/2407.05516v2",
      "published_date": "2024-07-07 23:36:51 UTC",
      "updated_date": "2024-10-30 19:54:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:13:01.534633"
    },
    {
      "arxiv_id": "2407.05502v3",
      "title": "Faux Polyglot: A Study on Information Disparity in Multilingual Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Nikhil Sharma",
        "Kenton Murray",
        "Ziang Xiao"
      ],
      "abstract": "Although the multilingual capability of LLMs offers new opportunities to\novercome the language barrier, do these capabilities translate into real-life\nscenarios where linguistic divide and knowledge conflicts between multilingual\nsources are known occurrences? In this paper, we studied LLM's linguistic\npreference in a cross-language RAG-based information search setting. We found\nthat LLMs displayed systemic bias towards information in the same language as\nthe query language in both document retrieval and answer generation.\nFurthermore, in scenarios where no information is in the language of the query,\nLLMs prefer documents in high-resource languages during generation, potentially\nreinforcing the dominant views. Such bias exists for both factual and\nopinion-based queries. Our results highlight the linguistic divide within\nmultilingual LLMs in information search systems. The seemingly beneficial\nmultilingual capability of LLMs may backfire on information parity by\nreinforcing language-specific information cocoons or filter bubbles further\nmarginalizing low-resource views.",
      "tldr_zh": "本研究探讨了多语言大型语言模型（LLMs）在实际信息搜索场景中的偏见问题，特别是跨语言的 RAG-based 设置中。研究发现，LLMs 在文档检索和答案生成过程中系统性地偏向于查询语言相同的语言信息，即使在查询语言无相关数据时，也更倾向于高资源语言的文档，从而可能强化主导观点。这种偏见适用于事实和意见查询，结果表明，LLMs 的多语言能力可能适得其反，加剧信息不平等并强化语言特定的信息茧房（filter bubbles），进一步边缘化低资源语言的视角。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2407.05502v3",
      "published_date": "2024-07-07 21:26:36 UTC",
      "updated_date": "2025-02-11 18:17:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:13:16.788084"
    },
    {
      "arxiv_id": "2407.06237v1",
      "title": "Discounted Pseudocosts in MILP",
      "title_zh": "翻译失败",
      "authors": [
        "Krunal Kishor Patel"
      ],
      "abstract": "In this article, we introduce the concept of discounted pseudocosts, inspired\nby discounted total reward in reinforcement learning, and explore their\napplication in mixed-integer linear programming (MILP). Traditional pseudocosts\nestimate changes in the objective function due to variable bound changes during\nthe branch-and-bound process. By integrating reinforcement learning concepts,\nwe propose a novel approach incorporating a forward-looking perspective into\npseudocost estimation. We present the motivation behind discounted pseudocosts\nand discuss how they represent the anticipated reward for branching after one\nlevel of exploration in the MILP problem space. Initial experiments on MIPLIB\n2017 benchmark instances demonstrate the potential of discounted pseudocosts to\nenhance branching strategies and accelerate the solution process for\nchallenging MILP problems.",
      "tldr_zh": "本论文引入了受强化学习（reinforcement learning）中折扣总奖励启发的折扣伪成本（discounted pseudocosts）概念，并将其应用于混合整数线性规划（MILP）。该方法通过整合前瞻性视角来改进传统伪成本估计，评估分支和边界过程中变量边界变化对目标函数的预期影响，从而代表分支后一级的预期奖励。初步实验在MIPLIB 2017基准实例上显示，这种策略能提升分支策略效率，并加速解决具有挑战性的MILP问题。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "math.OC",
        "90C11 (Primary), 90C10, 90-08 (Secondary)"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06237v1",
      "published_date": "2024-07-07 19:41:38 UTC",
      "updated_date": "2024-07-07 19:41:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:13:24.834097"
    },
    {
      "arxiv_id": "2407.05474v1",
      "title": "Enhancing Hallucination Detection through Perturbation-Based Synthetic Data Generation in System Responses",
      "title_zh": "翻译失败",
      "authors": [
        "Dongxu Zhang",
        "Varun Gangal",
        "Barrett Martin Lattimer",
        "Yi Yang"
      ],
      "abstract": "Detecting hallucinations in large language model (LLM) outputs is pivotal,\nyet traditional fine-tuning for this classification task is impeded by the\nexpensive and quickly outdated annotation process, especially across numerous\nvertical domains and in the face of rapid LLM advancements. In this study, we\nintroduce an approach that automatically generates both faithful and\nhallucinated outputs by rewriting system responses. Experimental findings\ndemonstrate that a T5-base model, fine-tuned on our generated dataset,\nsurpasses state-of-the-art zero-shot detectors and existing synthetic\ngeneration methods in both accuracy and latency, indicating efficacy of our\napproach.",
      "tldr_zh": "本文提出了一种基于扰动的合成数据生成方法，通过重写系统响应自动创建真实和幻觉输出，以提升大型语言模型(LLM)输出中的幻觉检测。该方法解决了传统微调的昂贵注释问题，尤其适用于多个领域和快速发展的LLM环境。实验结果表明，在生成的数据集上微调的T5-base模型，在准确性和延迟方面超过了现有zero-shot detectors和合成生成方法。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "ACL 2024 findings",
      "pdf_url": "http://arxiv.org/pdf/2407.05474v1",
      "published_date": "2024-07-07 19:19:32 UTC",
      "updated_date": "2024-07-07 19:19:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:13:37.379553"
    },
    {
      "arxiv_id": "2407.05467v2",
      "title": "The infrastructure powering IBM's Gen AI model development",
      "title_zh": "翻译失败",
      "authors": [
        "Talia Gershon",
        "Seetharami Seelam",
        "Brian Belgodere",
        "Milton Bonilla",
        "Lan Hoang",
        "Danny Barnett",
        "I-Hsin Chung",
        "Apoorve Mohan",
        "Ming-Hung Chen",
        "Lixiang Luo",
        "Robert Walkup",
        "Constantinos Evangelinos",
        "Shweta Salaria",
        "Marc Dombrowa",
        "Yoonho Park",
        "Apo Kayi",
        "Liran Schour",
        "Alim Alim",
        "Ali Sydney",
        "Pavlos Maniotis",
        "Laurent Schares",
        "Bernard Metzler",
        "Bengi Karacali-Akyamac",
        "Sophia Wen",
        "Tatsuhiro Chiba",
        "Sunyanan Choochotkaew",
        "Takeshi Yoshimura",
        "Claudia Misale",
        "Tonia Elengikal",
        "Kevin O Connor",
        "Zhuoran Liu",
        "Richard Molina",
        "Lars Schneidenbach",
        "James Caden",
        "Christopher Laibinis",
        "Carlos Fonseca",
        "Vasily Tarasov",
        "Swaminathan Sundararaman",
        "Frank Schmuck",
        "Scott Guthridge",
        "Jeremy Cohn",
        "Marc Eshel",
        "Paul Muench",
        "Runyu Liu",
        "William Pointer",
        "Drew Wyskida",
        "Bob Krull",
        "Ray Rose",
        "Brent Wolfe",
        "William Cornejo",
        "John Walter",
        "Colm Malone",
        "Clifford Perucci",
        "Frank Franco",
        "Nigel Hinds",
        "Bob Calio",
        "Pavel Druyan",
        "Robert Kilduff",
        "John Kienle",
        "Connor McStay",
        "Andrew Figueroa",
        "Matthew Connolly",
        "Edie Fost",
        "Gina Roma",
        "Jake Fonseca",
        "Ido Levy",
        "Michele Payne",
        "Ryan Schenkel",
        "Amir Malki",
        "Lion Schneider",
        "Aniruddha Narkhede",
        "Shekeba Moshref",
        "Alexandra Kisin",
        "Olga Dodin",
        "Bill Rippon",
        "Henry Wrieth",
        "John Ganci",
        "Johnny Colino",
        "Donna Habeger-Rose",
        "Rakesh Pandey",
        "Aditya Gidh",
        "Aditya Gaur",
        "Dennis Patterson",
        "Samsuddin Salmani",
        "Rambilas Varma",
        "Rumana Rumana",
        "Shubham Sharma",
        "Aditya Gaur",
        "Mayank Mishra",
        "Rameswar Panda",
        "Aditya Prasad",
        "Matt Stallone",
        "Gaoyuan Zhang",
        "Yikang Shen",
        "David Cox",
        "Ruchir Puri",
        "Dakshi Agrawal",
        "Drew Thorstensen",
        "Joel Belog",
        "Brent Tang",
        "Saurabh Kumar Gupta",
        "Amitabha Biswas",
        "Anup Maheshwari",
        "Eran Gampel",
        "Jason Van Patten",
        "Matthew Runion",
        "Sai Kaki",
        "Yigal Bogin",
        "Brian Reitz",
        "Steve Pritko",
        "Shahan Najam",
        "Surya Nambala",
        "Radhika Chirra",
        "Rick Welp",
        "Frank DiMitri",
        "Felipe Telles",
        "Amilcar Arvelo",
        "King Chu",
        "Ed Seminaro",
        "Andrew Schram",
        "Felix Eickhoff",
        "William Hanson",
        "Eric Mckeever",
        "Michael Light",
        "Dinakaran Joseph",
        "Piyush Chaudhary",
        "Piyush Shivam",
        "Puneet Chaudhary",
        "Wesley Jones",
        "Robert Guthrie",
        "Chris Bostic",
        "Rezaul Islam",
        "Steve Duersch",
        "Wayne Sawdon",
        "John Lewars",
        "Matthew Klos",
        "Michael Spriggs",
        "Bill McMillan",
        "George Gao",
        "Ashish Kamra",
        "Gaurav Singh",
        "Marc Curry",
        "Tushar Katarki",
        "Joe Talerico",
        "Zenghui Shi",
        "Sai Sindhur Malleni",
        "Erwan Gallen"
      ],
      "abstract": "AI Infrastructure plays a key role in the speed and cost-competitiveness of\ndeveloping and deploying advanced AI models. The current demand for powerful AI\ninfrastructure for model training is driven by the emergence of generative AI\nand foundational models, where on occasion thousands of GPUs must cooperate on\na single training job for the model to be trained in a reasonable time.\nDelivering efficient and high-performing AI training requires an end-to-end\nsolution that combines hardware, software and holistic telemetry to cater for\nmultiple types of AI workloads. In this report, we describe IBM's hybrid cloud\ninfrastructure that powers our generative AI model development. This\ninfrastructure includes (1) Vela: an AI-optimized supercomputing capability\ndirectly integrated into the IBM Cloud, delivering scalable, dynamic,\nmulti-tenant and geographically distributed infrastructure for large-scale\nmodel training and other AI workflow steps and (2) Blue Vela: a large-scale,\npurpose-built, on-premises hosting environment that is optimized to support our\nlargest and most ambitious AI model training tasks. Vela provides IBM with the\ndual benefit of high performance for internal use along with the flexibility to\nadapt to an evolving commercial landscape. Blue Vela provides us with the\nbenefits of rapid development of our largest and most ambitious models, as well\nas future-proofing against the evolving model landscape in the industry. Taken\ntogether, they provide IBM with the ability to rapidly innovate in the\ndevelopment of both AI models and commercial offerings.",
      "tldr_zh": "这篇报告讨论了 AI Infrastructure 在开发和部署生成式 AI 模型中的关键作用，强调了硬件、软件和遥测技术的端到端整合，以支持大规模 GPU 协作训练。IBM 引入了混合云基础设施，包括 Vela——一个可扩展、多租户的 AI 优化超级计算系统，集成于 IBM Cloud 用于模型训练和其他 AI 工作流程；以及 Blue Vela——一个大型内部托管环境，专为最复杂的 AI 任务提供高性能支持。这些基础设施相结合，使 IBM 能够在 AI 模型开发和商业应用中实现快速创新和适应性。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "Corresponding Authors: Talia Gershon, Seetharami Seelam,Brian\n  Belgodere, Milton Bonilla",
      "pdf_url": "http://arxiv.org/pdf/2407.05467v2",
      "published_date": "2024-07-07 18:39:33 UTC",
      "updated_date": "2025-01-13 22:53:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:13:50.750023"
    },
    {
      "arxiv_id": "2407.05466v1",
      "title": "Studying the Impact of TensorFlow and PyTorch Bindings on Machine Learning Software Quality",
      "title_zh": "研究 TensorFlow 和 PyTorch 绑定对机器学习软件质量的影响",
      "authors": [
        "Hao Li",
        "Gopi Krishnan Rajbahadur",
        "Cor-Paul Bezemer"
      ],
      "abstract": "Bindings for machine learning frameworks (such as TensorFlow and PyTorch)\nallow developers to integrate a framework's functionality using a programming\nlanguage different from the framework's default language (usually Python). In\nthis paper, we study the impact of using TensorFlow and PyTorch bindings in C#,\nRust, Python and JavaScript on the software quality in terms of correctness\n(training and test accuracy) and time cost (training and inference time) when\ntraining and performing inference on five widely used deep learning models. Our\nexperiments show that a model can be trained in one binding and used for\ninference in another binding for the same framework without losing accuracy.\nOur study is the first to show that using a non-default binding can help\nimprove machine learning software quality from the time cost perspective\ncompared to the default Python binding while still achieving the same level of\ncorrectness.",
      "tldr_zh": "本文研究了TensorFlow和PyTorch绑定的影响，评估了使用C#、Rust、Python和JavaScript等语言整合这些框架时，对机器学习软件质量的冲击，包括正确性（训练和测试accuracy）和时间成本（训练和inference时间）。实验涉及五种常见深度学习模型，结果表明，模型可以在一个binding中训练并在另一个binding中进行inference，而不损失accuracy。首次发现，使用非默认binding（如非Python）可以降低时间成本，同时保持相同的正确性水平，从而提升机器学习软件质量。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05466v1",
      "published_date": "2024-07-07 18:39:27 UTC",
      "updated_date": "2024-07-07 18:39:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:14:01.953767"
    },
    {
      "arxiv_id": "2407.05464v1",
      "title": "Experiments with truth using Machine Learning: Spectral analysis and explainable classification of synthetic, false, and genuine information",
      "title_zh": "翻译失败",
      "authors": [
        "Vishnu S. Pendyala",
        "Madhulika Dutta"
      ],
      "abstract": "Misinformation is still a major societal problem and the arrival of Large\nLanguage Models (LLMs) only added to it. This paper analyzes synthetic, false,\nand genuine information in the form of text from spectral analysis,\nvisualization, and explainability perspectives to find the answer to why the\nproblem is still unsolved despite multiple years of research and a plethora of\nsolutions in the literature. Various embedding techniques on multiple datasets\nare used to represent information for the purpose. The diverse spectral and\nnon-spectral methods used on these embeddings include t-distributed Stochastic\nNeighbor Embedding (t-SNE), Principal Component Analysis (PCA), and Variational\nAutoencoders (VAEs). Classification is done using multiple machine learning\nalgorithms. Local Interpretable Model-Agnostic Explanations (LIME), SHapley\nAdditive exPlanations (SHAP), and Integrated Gradients are used for the\nexplanation of the classification. The analysis and the explanations generated\nshow that misinformation is quite closely intertwined with genuine information\nand the machine learning algorithms are not as effective in separating the two\ndespite the claims in the literature.",
      "tldr_zh": "这篇论文探讨了使用机器学习分析合成、虚假和真实信息（synthetic, false, and genuine information）的挑战，特别是 Large Language Models (LLMs) 加剧的虚假信息问题。研究者通过各种嵌入技术进行信息表示，并应用光谱分析方法（如 t-SNE、PCA 和 VAEs）以及机器学习分类算法，同时利用 LIME、SHAP 和 Integrated Gradients 等解释工具来可视化和解释结果。结果表明，虚假信息与真实信息高度交织，机器学习算法在区分两者时远不如文献中声称的那样有效，这揭示了虚假信息问题持续未解的原因。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05464v1",
      "published_date": "2024-07-07 18:31:09 UTC",
      "updated_date": "2024-07-07 18:31:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:14:16.906084"
    },
    {
      "arxiv_id": "2407.11043v1",
      "title": "A Review of AI and Machine Learning Contribution in Predictive Business Process Management (Process Enhancement and Process Improvement Approaches)",
      "title_zh": "人工智能和机器学习在预测性业务流程管理中的贡献综述（流程增强和流程改进方法）",
      "authors": [
        "Mostafa Abbasi",
        "Rahnuma Islam Nishat",
        "Corey Bond",
        "John Brandon Graham-Knight",
        "Patricia Lasserre",
        "Yves Lucet",
        "Homayoun Najjaran"
      ],
      "abstract": "Purpose- The significance of business processes has fostered a close\ncollaboration between academia and industry. Moreover, the business landscape\nhas witnessed continuous transformation, closely intertwined with technological\nadvancements. Our main goal is to offer researchers and process analysts\ninsights into the latest developments concerning Artificial Intelligence (AI)\nand Machine Learning (ML) to optimize their processes in an organization and\nidentify research gaps and future directions in the field.\nDesign/methodology/approach- In this study, we perform a systematic review of\nacademic literature to investigate the integration of AI/ML in business process\nmanagement (BPM). We categorize the literature according to the BPM life-cycle\nand employ bibliometric and objective-oriented methodology, to analyze related\npapers.\n  Findings- In business process management and process map, AI/ML has made\nsignificant improvements using operational data on process metrics. These\ndevelopments involve two distinct stages: (1) process enhancement, which\nemphasizes analyzing process information and adding descriptions to process\nmodels, and (2) process improvement, which focuses on redesigning processes\nbased on insights derived from analysis. Research limitations/implications-\nWhile this review paper serves to provide an overview of different approaches\nfor addressing process-related challenges, it does not delve deeply into the\nintricacies of fine-grained technical details of each method. This work focuses\non recent papers conducted between 2010 and 2024. Originality/value- This paper\nadopts a pioneering approach by conducting an extensive examination of the\nintegration of AI/ML techniques across the entire process management lifecycle.\nAdditionally, it presents groundbreaking research and introduces AI/ML-enabled\nintegrated tools, further enhancing the insights for future research.",
      "tldr_zh": "这篇综述论文探讨了 AI 和 ML 在预测性业务过程管理(BPM)中的贡献，重点关注过程增强（分析过程信息并描述模型）和过程改进（基于分析重新设计过程）。作者采用系统文献综述、文献计量和目标导向方法，对2010-2024年间相关学术文献进行分类和分析。研究发现，AI/ML 通过操作数据显著提升了BPM的效率，但也指出了研究空白，如缺乏细粒度技术细节，并为未来整合AI/ML工具的BPM研究提供了方向。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.11043v1",
      "published_date": "2024-07-07 18:26:00 UTC",
      "updated_date": "2024-07-07 18:26:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:14:26.204933"
    },
    {
      "arxiv_id": "2407.05461v1",
      "title": "CAV-AD: A Robust Framework for Detection of Anomalous Data and Malicious Sensors in CAV Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Md Sazedur Rahman",
        "Mohamed Elmahallawy",
        "Sanjay Madria",
        "Samuel Frimpong"
      ],
      "abstract": "The adoption of connected and automated vehicles (CAVs) has sparked\nconsiderable interest across diverse industries, including public\ntransportation, underground mining, and agriculture sectors. However, CAVs'\nreliance on sensor readings makes them vulnerable to significant threats.\nManipulating these readings can compromise CAV network security, posing serious\nrisks for malicious activities. Although several anomaly detection (AD)\napproaches for CAV networks are proposed, they often fail to: i) detect\nmultiple anomalies in specific sensor(s) with high accuracy or F1 score, and\nii) identify the specific sensor being attacked. In response, this paper\nproposes a novel framework tailored to CAV networks, called CAV-AD, for\ndistinguishing abnormal readings amidst multiple anomaly data while identifying\nmalicious sensors. Specifically, CAV-AD comprises two main components: i) A\nnovel CNN model architecture called optimized omni-scale CNN (O-OS-CNN), which\noptimally selects the time scale by generating all possible kernel sizes for\ninput time series data; ii) An amplification block to increase the values of\nanomaly readings, enhancing sensitivity for detecting anomalies. Not only that,\nbut CAV-AD integrates the proposed O-OS-CNN with a Kalman filter to instantly\nidentify the malicious sensors. We extensively train CAV-AD using real-world\ndatasets containing both instant and constant attacks, evaluating its\nperformance in detecting intrusions from multiple anomalies, which presents a\nmore challenging scenario. Our results demonstrate that CAV-AD outperforms\nstate-of-the-art methods, achieving an average accuracy of 98% and an average\nF1 score of 89\\%, while accurately identifying the malicious sensors.",
      "tldr_zh": "该研究针对连接和自动驾驶车辆(CAV)网络的安全问题，提出了一种鲁棒框架CAV-AD，用于检测异常数据和识别恶意传感器，以应对现有方法在多异常检测和精确定位方面的不足。CAV-AD的核心组件包括优化全尺度CNN模型(O-OS-CNN)，通过生成所有可能内核大小来处理时间序列数据，以及一个放大块来提升异常读数的值，提高检测敏感性；此外，该框架将O-OS-CNN与Kalman滤波器结合，实现对恶意传感器的即时识别。实验结果显示，CAV-AD在使用真实数据集测试多种攻击场景时，平均准确率达到98%、F1分数为89%，显著优于现有方法，为CAV网络的安全性提供了更可靠的解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05461v1",
      "published_date": "2024-07-07 18:19:03 UTC",
      "updated_date": "2024-07-07 18:19:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:14:37.316057"
    },
    {
      "arxiv_id": "2407.05458v1",
      "title": "A Survey of Models for Cognitive Diagnosis: New Developments and Future Directions",
      "title_zh": "认知诊断模型的综述：新发展与未来方向",
      "authors": [
        "Fei Wang",
        "Weibo Gao",
        "Qi Liu",
        "Jiatong Li",
        "Guanhao Zhao",
        "Zheng Zhang",
        "Zhenya Huang",
        "Mengxiao Zhu",
        "Shijin Wang",
        "Wei Tong",
        "Enhong Chen"
      ],
      "abstract": "Cognitive diagnosis has been developed for decades as an effective\nmeasurement tool to evaluate human cognitive status such as ability level and\nknowledge mastery. It has been applied to a wide range of fields including\neducation, sport, psychological diagnosis, etc. By providing better awareness\nof cognitive status, it can serve as the basis for personalized services such\nas well-designed medical treatment, teaching strategy and vocational training.\nThis paper aims to provide a survey of current models for cognitive diagnosis,\nwith more attention on new developments using machine learning-based methods.\nBy comparing the model structures, parameter estimation algorithms, model\nevaluation methods and applications, we provide a relatively comprehensive\nreview of the recent trends in cognitive diagnosis models. Further, we discuss\nfuture directions that are worthy of exploration. In addition, we release two\nPython libraries: EduData for easy access to some relevant public datasets we\nhave collected, and EduCDM that implements popular CDMs to facilitate both\napplications and research purposes.",
      "tldr_zh": "本论文对认知诊断模型进行了全面调查，重点关注基于机器学习的最新发展，旨在评估人类认知状态如能力水平和知识掌握，并应用于教育、体育和心理诊断等领域。通过比较模型结构、参数估计算法、模型评估方法及实际应用，该研究提供了认知诊断领域的近期趋势回顾，并讨论了值得探索的未来方向。此外，作者发布了两个Python库：EduData用于便捷访问相关数据集，以及EduCDM用于实现流行CDMs（Cognitive Diagnosis Models），以支持应用和研究。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05458v1",
      "published_date": "2024-07-07 18:02:00 UTC",
      "updated_date": "2024-07-07 18:02:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:14:49.832582"
    },
    {
      "arxiv_id": "2407.05449v2",
      "title": "SmurfCat at PAN 2024 TextDetox: Alignment of Multilingual Transformers for Text Detoxification",
      "title_zh": "翻译失败",
      "authors": [
        "Elisei Rykov",
        "Konstantin Zaytsev",
        "Ivan Anisimov",
        "Alexandr Voronin"
      ],
      "abstract": "This paper presents a solution for the Multilingual Text Detoxification task\nin the PAN-2024 competition of the SmurfCat team. Using data augmentation\nthrough machine translation and a special filtering procedure, we collected an\nadditional multilingual parallel dataset for text detoxification. Using the\nobtained data, we fine-tuned several multilingual sequence-to-sequence models,\nsuch as mT0 and Aya, on a text detoxification task. We applied the ORPO\nalignment technique to the final model. Our final model has only 3.7 billion\nparameters and achieves state-of-the-art results for the Ukrainian language and\nnear state-of-the-art results for other languages. In the competition, our team\nachieved first place in the automated evaluation with a score of 0.52 and\nsecond place in the final human evaluation with a score of 0.74.",
      "tldr_zh": "本研究介绍了SmurfCat团队在PAN 2024 TextDetox比赛中的多语言文本净化解决方案，通过机器翻译进行数据增强并采用特殊过滤程序，构建了额外的多语言平行数据集。研究团队使用该数据集微调了多语言序列到序列模型，如mT0和Aya，并应用ORPO对齐技术，最终开发出仅3.7亿参数的模型，在乌克兰语上达到最先进水平，其他语言接近最先进。该模型在比赛中表现突出，在自动评估中获得第一名（分数0.52），在人工评估中获得第二名（分数0.74）。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05449v2",
      "published_date": "2024-07-07 17:19:34 UTC",
      "updated_date": "2024-07-10 14:44:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:15:01.510196"
    },
    {
      "arxiv_id": "2407.05441v4",
      "title": "Language Representations Can be What Recommenders Need: Findings and Potentials",
      "title_zh": "语言表示可以是推荐系统所需的内容：发现与潜力",
      "authors": [
        "Leheng Sheng",
        "An Zhang",
        "Yi Zhang",
        "Yuxin Chen",
        "Xiang Wang",
        "Tat-Seng Chua"
      ],
      "abstract": "Recent studies empirically indicate that language models (LMs) encode rich\nworld knowledge beyond mere semantics, attracting significant attention across\nvarious fields. However, in the recommendation domain, it remains uncertain\nwhether LMs implicitly encode user preference information. Contrary to\nprevailing understanding that LMs and traditional recommenders learn two\ndistinct representation spaces due to the huge gap in language and behavior\nmodeling objectives, this work re-examines such understanding and explores\nextracting a recommendation space directly from the language representation\nspace. Surprisingly, our findings demonstrate that item representations, when\nlinearly mapped from advanced LM representations, yield superior recommendation\nperformance. This outcome suggests the possible homomorphism between the\nadvanced language representation space and an effective item representation\nspace for recommendation, implying that collaborative signals may be implicitly\nencoded within LMs. Motivated by these findings, we explore the possibility of\ndesigning advanced collaborative filtering (CF) models purely based on language\nrepresentations without ID-based embeddings. To be specific, we incorporate\nseveral crucial components to build a simple yet effective model, with item\ntitles as the input. Empirical results show that such a simple model can\noutperform leading ID-based CF models, which sheds light on using language\nrepresentations for better recommendation. Moreover, we systematically analyze\nthis simple model and find several key features for using advanced language\nrepresentations: a good initialization for item representations, zero-shot\nrecommendation abilities, and being aware of user intention. Our findings\nhighlight the connection between language modeling and behavior modeling, which\ncan inspire both natural language processing and recommender system\ncommunities.",
      "tldr_zh": "本研究发现，语言模型 (LMs) 不仅编码了丰富的世界知识，还可能隐式包含用户偏好信息，从而挑战了 LMs 和推荐系统表示空间不同的传统观点。通过从 LMs 表示中线性映射物品表示，研究者实现了优越的推荐性能，表明语言表示空间与推荐表示空间可能存在同态关系。基于此，他们设计了一个简单的协作过滤 (CF) 模型，仅使用物品标题作为输入，而不依赖 ID-based embeddings，该模型在实验中超过了领先的 CF 模型。进一步分析揭示了关键特征，如良好的初始化、零样本 (zero-shot) 推荐能力和用户意图感知，这为自然语言处理 (NLP) 和推荐系统领域提供了新的启发。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "ICLR 2025 (Oral). Codes are available at\n  https://github.com/LehengTHU/AlphaRec",
      "pdf_url": "http://arxiv.org/pdf/2407.05441v4",
      "published_date": "2024-07-07 17:05:24 UTC",
      "updated_date": "2025-04-21 03:45:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:15:18.000932"
    },
    {
      "arxiv_id": "2407.05440v2",
      "title": "Explainable AI: Comparative Analysis of Normal and Dilated ResNet Models for Fundus Disease Classification",
      "title_zh": "可解释AI：标准ResNet和扩张ResNet模型在眼底疾病分类的比较分析",
      "authors": [
        "P. N. Karthikayan",
        "Yoga Sri Varshan V",
        "Hitesh Gupta Kattamuri",
        "Umarani Jayaraman"
      ],
      "abstract": "This paper presents dilated Residual Network (ResNet) models for disease\nclassification from retinal fundus images. Dilated convolution filters are used\nto replace normal convolution filters in the higher layers of the ResNet model\n(dilated ResNet) in order to improve the receptive field compared to the normal\nResNet model for disease classification. This study introduces\ncomputer-assisted diagnostic tools that employ deep learning, enhanced with\nexplainable AI techniques. These techniques aim to make the tool's\ndecision-making process transparent, thereby enabling medical professionals to\nunderstand and trust the AI's diagnostic decision. They are particularly\nrelevant in today's healthcare landscape, where there is a growing demand for\ntransparency in AI applications to ensure their reliability and ethical use.\nThe dilated ResNet is used as a replacement for the normal ResNet to enhance\nthe classification accuracy of retinal eye diseases and reduce the required\ncomputing time. The dataset used in this work is the Ocular Disease Intelligent\nRecognition (ODIR) dataset which is a structured ophthalmic database with eight\nclasses covering most of the common retinal eye diseases. The evaluation\nmetrics used in this work include precision, recall, accuracy, and F1 score. In\nthis work, a comparative study has been made between normal ResNet models and\ndilated ResNet models on five variants namely ResNet-18, ResNet-34, ResNet-50,\nResNet-101, and ResNet-152. The dilated ResNet model shows promising results as\ncompared to normal ResNet with an average F1 score of 0.71, 0.70, 0.69, 0.67,\nand 0.70 respectively for the above respective variants in ODIR multiclass\ndisease classification.",
      "tldr_zh": "本论文比较了正常 ResNet 和 dilated ResNet 模型在视网膜眼底图像疾病分类中的性能，通过在 ResNet 的较高层使用 dilated convolution 过滤器来扩大感受野，提升分类准确率和减少计算时间。研究引入 explainable AI 技术，使 AI 决策过程透明，以增强医疗专业人士的信任和伦理应用。使用 ODIR 数据集（包含八类常见眼病），对 ResNet-18、ResNet-34、ResNet-50、ResNet-101 和 ResNet-152 等五种变体进行评估，结果显示 dilated ResNet 的平均 F1 score 分别为 0.71、0.70、0.69、0.67 和 0.70，比正常 ResNet 模型表现出色。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "Added authors' contributions",
      "pdf_url": "http://arxiv.org/pdf/2407.05440v2",
      "published_date": "2024-07-07 17:03:12 UTC",
      "updated_date": "2024-08-31 20:26:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:15:28.193541"
    },
    {
      "arxiv_id": "2407.05437v1",
      "title": "Enhancing Computer Programming Education with LLMs: A Study on Effective Prompt Engineering for Python Code Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Tianyu Wang",
        "Nianjun Zhou",
        "Zhixiong Chen"
      ],
      "abstract": "Large language models (LLMs) and prompt engineering hold significant\npotential for advancing computer programming education through personalized\ninstruction. This paper explores this potential by investigating three critical\nresearch questions: the systematic categorization of prompt engineering\nstrategies tailored to diverse educational needs, the empowerment of LLMs to\nsolve complex problems beyond their inherent capabilities, and the\nestablishment of a robust framework for evaluating and implementing these\nstrategies. Our methodology involves categorizing programming questions based\non educational requirements, applying various prompt engineering strategies,\nand assessing the effectiveness of LLM-generated responses. Experiments with\nGPT-4, GPT-4o, Llama3-8b, and Mixtral-8x7b models on datasets such as LeetCode\nand USACO reveal that GPT-4o consistently outperforms others, particularly with\nthe \"multi-step\" prompt strategy. The results show that tailored prompt\nstrategies significantly enhance LLM performance, with specific strategies\nrecommended for foundational learning, competition preparation, and advanced\nproblem-solving. This study underscores the crucial role of prompt engineering\nin maximizing the educational benefits of LLMs. By systematically categorizing\nand testing these strategies, we provide a comprehensive framework for both\neducators and students to optimize LLM-based learning experiences. Future\nresearch should focus on refining these strategies and addressing current LLM\nlimitations to further enhance educational outcomes in computer programming\ninstruction.",
      "tldr_zh": "本论文探讨了如何利用大语言模型（LLMs）和提示工程（prompt engineering）提升计算机编程教育，针对Python代码生成提出三个关键研究问题：系统分类提示策略以适应不同教育需求、增强LLMs解决复杂问题的能力，以及建立评估框架。研究方法包括分类编程问题、应用多种提示工程策略，并使用GPT-4、GPT-4o、Llama3-8b和Mixtral-8x7b模型在LeetCode和USACO数据集上进行实验。结果显示，GPT-4o在\"multi-step\"提示策略下表现最佳，定制策略显著提升了LLMs的性能，并为基础学习、竞赛准备和高级问题解决推荐了特定策略。该研究提供了一个全面框架，帮助教育者和学生优化LLMs学习体验，并建议未来研究进一步改进这些策略以克服LLMs的局限性。",
      "categories": [
        "cs.AI",
        "K.3.2; I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.05437v1",
      "published_date": "2024-07-07 16:41:07 UTC",
      "updated_date": "2024-07-07 16:41:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:15:39.515903"
    },
    {
      "arxiv_id": "2407.05434v1",
      "title": "LTLBench: Towards Benchmarks for Evaluating Temporal Logic Reasoning in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Weizhi Tang",
        "Vaishak Belle"
      ],
      "abstract": "Temporal reasoning (TR) is a critical component of artificial intelligence,\nencompassing understanding and processing temporal information and\nrelationships between events. To discover and study the TR ability in Large\nLanguage Models (LLMs), various datasets have been constructed in different\nways for evaluating various aspects of TR ability. Our work proposes a novel\napproach to design and develop a pipeline for constructing datasets to evaluate\nthe TR ability of LLMs by leveraging random directed graph generation, LTL\nformula, and the NuSMV model checker. Based on the pipeline, we have also\nconstructed a dataset as a benchmark, namely LTLBench, consisting of 2,000 TR\nchallenges and evaluated six LLMs with it. Furthermore, we have conducted\nadditional experiments to discover the impact of increasing the number of\nevents and formula operators on the complexity of TR problems and the\nperformance of LLMs. We have demonstrated that although LLMs exhibit some\npromise in handling TR challenges, they still struggle with complex TR. We\nexpect this work can offer insights into TR ability in LLMs while also\nproviding a valuable tool for future TR evaluations.",
      "tldr_zh": "本文提出了一种新管道，用于构建数据集评估Large Language Models (LLMs) 的Temporal Reasoning (TR) 能力，该方法利用随机有向图生成、LTL公式和NuSMV模型检查器来创建TR挑战。基于此管道，他们构建了LTLBench基准数据集，包含2000个TR问题，并评估了六个LLMs的性能。实验结果显示，LLMs在简单TR任务上表现出潜力，但对复杂TR（如增加事件数量和公式运算符）仍存在显著困难。该工作为深入理解LLMs的TR能力并提供未来评估工具提供了重要见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05434v1",
      "published_date": "2024-07-07 16:37:06 UTC",
      "updated_date": "2024-07-07 16:37:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:16:00.630753"
    },
    {
      "arxiv_id": "2407.05424v1",
      "title": "BiRoDiff: Diffusion policies for bipedal robot locomotion on unseen terrains",
      "title_zh": "BiRoDiff：双足机器人未知地形运动的扩散策略",
      "authors": [
        "GVS Mothish",
        "Manan Tayal",
        "Shishir Kolathaya"
      ],
      "abstract": "Locomotion on unknown terrains is essential for bipedal robots to handle\nnovel real-world challenges, thus expanding their utility in disaster response\nand exploration. In this work, we introduce a lightweight framework that learns\na single walking controller that yields locomotion on multiple terrains. We\nhave designed a real-time robot controller based on diffusion models, which not\nonly captures multiple behaviours with different velocities in a single policy\nbut also generalizes well for unseen terrains. Our controller learns with\noffline data, which is better than online learning in aspects like scalability,\nsimplicity in training scheme etc. We have designed and implemented a diffusion\nmodel-based policy controller in simulation on our custom-made Bipedal Robot\nmodel named Stoch BiRo. We have demonstrated its generalization capability and\nhigh frequency control step generation relative to typical generative models,\nwhich require huge onboarding compute.",
      "tldr_zh": "这篇论文介绍了BiRoDiff框架，使用diffusion models为bipedal robots设计一个轻量级的单一行走控制器，实现未知地形(unseen terrains)上的运动。该控制器基于离线数据学习，能够捕捉多种速度行为，并比在线学习更具可扩展性和简单性。在模拟环境中测试于自定义的Stoch BiRo模型上，BiRoDiff展示了出色的generalization capability和高频控制步骤生成，扩展了双足机器人在灾害响应和探索中的应用。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "6 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.05424v1",
      "published_date": "2024-07-07 16:03:33 UTC",
      "updated_date": "2024-07-07 16:03:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:16:01.328810"
    },
    {
      "arxiv_id": "2407.05418v1",
      "title": "EMBANet: A Flexible Efffcient Multi-branch Attention Network",
      "title_zh": "翻译失败",
      "authors": [
        "Keke Zu",
        "Hu Zhang",
        "Jian Lu",
        "Lei Zhang",
        "Chen Xu"
      ],
      "abstract": "This work presents a novel module, namely multi-branch concat (MBC), to\nprocess the input tensor and obtain the multi-scale feature map. The proposed\nMBC module brings new degrees of freedom (DoF) for the design of attention\nnetworks by allowing the type of transformation operators and the number of\nbranches to be flexibly adjusted. Two important transformation operators,\nmultiplex and split, are considered in this work, both of which can represent\nmulti-scale features at a more granular level and increase the range of\nreceptive fields. By integrating the MBC and attention module, a multi-branch\nattention (MBA) module is consequently developed to capture the channel-wise\ninteraction of feature maps for establishing the long-range channel dependency.\nBy substituting the 3x3 convolutions in the bottleneck blocks of the ResNet\nwith the proposed MBA, a novel block namely efficient multi-branch attention\n(EMBA) is obtained, which can be easily plugged into the state-of-the-art\nbackbone CNN models. Furthermore, a new backbone network called EMBANet is\nestablished by stacking the EMBA blocks. The proposed EMBANet is extensively\nevaluated on representative computer vision tasks including: classification,\ndetection, and segmentation. And it demonstrates consistently superior\nperformance over the popular backbones.",
      "tldr_zh": "本文提出了一种新型模块 multi-branch concat (MBC)，允许灵活调整转换操作符（如 multiplex 和 split）以处理输入张量并提取多尺度特征图。基于 MBC 和注意力模块，作者开发了 multi-branch attention (MBA) 模块，并将其整合进 ResNet 的瓶颈块中，形成了 efficient multi-branch attention (EMBA) 块，从而构建了新的骨干网络 EMBANet。实验结果显示，EMBANet 在图像分类、检测和分割等计算机视觉任务上， consistently superior 地超越了流行骨干网络。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05418v1",
      "published_date": "2024-07-07 15:50:01 UTC",
      "updated_date": "2024-07-07 15:50:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:16:14.556998"
    },
    {
      "arxiv_id": "2407.05417v2",
      "title": "See Further for Parameter Efficient Fine-tuning by Standing on the Shoulders of Decomposition",
      "title_zh": "翻译失败",
      "authors": [
        "Chongjie Si",
        "Xiaokang Yang",
        "Wei Shen"
      ],
      "abstract": "The rapid expansion of large foundation models within the pre-training and\nfine-tuning framework has underscored that larger models often yield better\nresults. However, the scaling up of large foundation models has led to soaring\ncosts in fine-tuning and parameter storage, rendering extensive adaptations\nimpractical. This challenge has sparked the development of parameter-efficient\nfine-tuning (PEFT), which focuses on optimizing a select subset of parameters\nwhile keeping the rest fixed, significantly lowering computational and storage\noverheads. While recent years have witnessed a significant success in PEFT, a\ndeep understanding of the fundamental principles behind these methods remains\nunexplored. To this end, here we take the first step to unify all approaches by\ndissecting them from a decomposition perspective. We initiate a comprehensive\nmathematical analysis of these methods, allowing us to delve deeply into their\nunderlying mechanisms, and we explore the reasons behind the variations in\nperformance among different techniques. Furthermore, inspired by our\ntheoretical analysis, we introduce two novel PEFT methods alongside a simple\nyet effective framework designed to enhance the performance of PEFT techniques\nacross various applications. Our empirical validations, conducted across\nmultiple datasets, demonstrate the efficacy of these methods, showcasing both\ntheoretical validity and practical performance improvements under the guidance\nof our analytical findings. We believe our work will deepen researchers'\nunderstanding of PEFT and other techniques, prompting further contemplation and\nadvancing the research across the whole community.",
      "tldr_zh": "本研究探讨了大型基础模型微调的成本挑战，提出从分解视角统一分析参数高效微调（PEFT）方法，以揭示其底层机制和性能差异。作者通过全面数学分析，解释了不同PEFT技术的变异原因，并基于此引入两个新PEFT方法和一个简单有效的框架，提升其在各种应用中的性能。实验在多个数据集上验证了这些方法的有效性，展示了理论分析指导下的实际改进，有望加深研究社区对PEFT的理解并推动相关领域发展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Codes in https://github.com/Chongjie-Si/Subspace-Tuning",
      "pdf_url": "http://arxiv.org/pdf/2407.05417v2",
      "published_date": "2024-07-07 15:44:42 UTC",
      "updated_date": "2024-12-25 11:55:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:16:24.529681"
    },
    {
      "arxiv_id": "2407.05413v3",
      "title": "SBoRA: Low-Rank Adaptation with Regional Weight Updates",
      "title_zh": "翻译失败",
      "authors": [
        "Lai-Man Po",
        "Yuyang Liu",
        "Haoxuan Wu",
        "Tianqi Zhang",
        "Wing-Yin Yu",
        "Zhuohan Wang",
        "Zeyu Jiang",
        "Kun Li"
      ],
      "abstract": "This paper introduces Standard Basis LoRA (SBoRA), a novel\nparameter-efficient fine-tuning approach for Large Language Models that builds\nupon the pioneering works of Low-Rank Adaptation (LoRA) and Orthogonal\nAdaptation. SBoRA reduces the number of trainable parameters by half or doubles\nthe rank with the similar number of trainable parameters as LoRA, while\nimproving learning performance. By utilizing orthogonal standard basis vectors\nto initialize one of the low-rank matrices (either $\\mathbf{A}$ or\n$\\mathbf{B}$), SBoRA facilitates regional weight updates and memory-efficient\nfine-tuning. This results in two variants, SBoRA-FA and SBoRA-FB, where only\none of the matrices is updated, leading to a sparse update matrix\n$\\mathrm{\\Delta} \\mathbf{W}$ with predominantly zero rows or columns.\nConsequently, most of the fine-tuned model's weights\n$(\\mathbf{W}_0+\\mathrm{\\Delta} \\mathbf{W})$ remain unchanged from the\npre-trained weights, akin to the modular organization of the human brain, which\nefficiently adapts to new tasks. Our empirical results demonstrate the\nsuperiority of SBoRA-FA over LoRA in various fine-tuning tasks, including\ncommonsense reasoning and arithmetic reasoning. Furthermore, we evaluate the\neffectiveness of QSBoRA on quantized LLaMA models of varying scales,\nhighlighting its potential for efficient adaptation to new tasks. Code is\navailable at https://github.com/cityuhkai/SBoRA",
      "tldr_zh": "本论文提出 SBoRA，一种基于 Low-Rank Adaptation (LoRA) 和 Orthogonal Adaptation 的参数高效微调方法，能够将可训练参数减少一半或在相同参数下加倍秩，同时提升学习性能。SBoRA 通过使用正交标准基向量初始化低秩矩阵（$\\mathbf{A}$ 或 $\\mathbf{B}$），实现区域权重更新和内存高效微调，生成 SBoRA-FA 和 SBoRA-FB 两种变体，这些变体仅更新一个矩阵，导致更新矩阵 $\\mathrm{\\Delta} \\mathbf{W}$ 稀疏化，大部分权重保持不变。实验结果表明，SBoRA-FA 在常识推理和算术推理任务中优于 LoRA，并在量化 LLaMA 模型上显示出高效适应潜力，代码已在 GitHub 上开源。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.05413v3",
      "published_date": "2024-07-07 15:37:13 UTC",
      "updated_date": "2024-10-09 07:53:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:16:38.763986"
    },
    {
      "arxiv_id": "2407.05412v1",
      "title": "FM-OSD: Foundation Model-Enabled One-Shot Detection of Anatomical Landmarks",
      "title_zh": "翻译失败",
      "authors": [
        "Juzheng Miao",
        "Cheng Chen",
        "Keli Zhang",
        "Jie Chuai",
        "Quanzheng Li",
        "Pheng-Ann Heng"
      ],
      "abstract": "One-shot detection of anatomical landmarks is gaining significant attention\nfor its efficiency in using minimal labeled data to produce promising results.\nHowever, the success of current methods heavily relies on the employment of\nextensive unlabeled data to pre-train an effective feature extractor, which\nlimits their applicability in scenarios where a substantial amount of unlabeled\ndata is unavailable. In this paper, we propose the first foundation\nmodel-enabled one-shot landmark detection (FM-OSD) framework for accurate\nlandmark detection in medical images by utilizing solely a single template\nimage without any additional unlabeled data. Specifically, we use the frozen\nimage encoder of visual foundation models as the feature extractor, and\nintroduce dual-branch global and local feature decoders to increase the\nresolution of extracted features in a coarse to fine manner. The introduced\nfeature decoders are efficiently trained with a distance-aware similarity\nlearning loss to incorporate domain knowledge from the single template image.\nMoreover, a novel bidirectional matching strategy is developed to improve both\nrobustness and accuracy of landmark detection in the case of scattered\nsimilarity map obtained by foundation models. We validate our method on two\npublic anatomical landmark detection datasets. By using solely a single\ntemplate image, our method demonstrates significant superiority over strong\nstate-of-the-art one-shot landmark detection methods.",
      "tldr_zh": "该论文提出FM-OSD框架，这是首个基于foundation model的单模板(one-shot)解剖标志检测方法，能够在无需额外无标签数据的情况下实现医疗图像中标志的准确检测。具体而言，该框架利用视觉foundation model的冻结图像编码器作为特征提取器，并引入双分支全局和局部特征解码器，从粗到细提升特征分辨率，同时采用distance-aware similarity learning loss整合模板图像的领域知识，并开发双向匹配策略(bidirectional matching strategy)来提高检测的鲁棒性和准确性。在两个公开解剖标志检测数据集上，FM-OSD仅使用一个模板图像就显著优于现有最先进的一-shot方法，展示了其高效性和潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at MICCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.05412v1",
      "published_date": "2024-07-07 15:37:02 UTC",
      "updated_date": "2024-07-07 15:37:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:16:51.532661"
    },
    {
      "arxiv_id": "2407.05407v2",
      "title": "CosyVoice: A Scalable Multilingual Zero-shot Text-to-speech Synthesizer based on Supervised Semantic Tokens",
      "title_zh": "CosyVoice：基于监督语义标记的可扩展多语言零样本文本到语音合成器",
      "authors": [
        "Zhihao Du",
        "Qian Chen",
        "Shiliang Zhang",
        "Kai Hu",
        "Heng Lu",
        "Yexin Yang",
        "Hangrui Hu",
        "Siqi Zheng",
        "Yue Gu",
        "Ziyang Ma",
        "Zhifu Gao",
        "Zhijie Yan"
      ],
      "abstract": "Recent years have witnessed a trend that large language model (LLM) based\ntext-to-speech (TTS) emerges into the mainstream due to their high naturalness\nand zero-shot capacity. In this paradigm, speech signals are discretized into\ntoken sequences, which are modeled by an LLM with text as prompts and\nreconstructed by a token-based vocoder to waveforms. Obviously, speech tokens\nplay a critical role in LLM-based TTS models. Current speech tokens are learned\nin an unsupervised manner, which lacks explicit semantic information and\nalignment to the text. In this paper, we propose to represent speech with\nsupervised semantic tokens, which are derived from a multilingual speech\nrecognition model by inserting vector quantization into the encoder. Based on\nthe tokens, we further propose a scalable zero-shot TTS synthesizer, CosyVoice,\nwhich consists of an LLM for text-to-token generation and a conditional flow\nmatching model for token-to-speech synthesis. Experimental results show that\nsupervised semantic tokens significantly outperform existing unsupervised\ntokens in terms of content consistency and speaker similarity for zero-shot\nvoice cloning. Moreover, we find that utilizing large-scale data further\nimproves the synthesis performance, indicating the scalable capacity of\nCosyVoice. To the best of our knowledge, this is the first attempt to involve\nsupervised speech tokens into TTS models.",
      "tldr_zh": "本文提出 CosyVoice，一种基于受监督语义标记的可扩展多语言零-shot 文本到语音 (TTS) 合成器，以解决现有无监督语音标记缺乏语义信息和文本对齐的问题。具体方法包括从多语言语音识别模型的编码器中插入 vector quantization 生成标记，然后利用 large language model (LLM) 进行文本到标记生成，以及条件流匹配模型实现标记到语音合成。实验结果表明，该系统在零-shot 语音克隆中显著提升内容一致性和说话者相似度，使用大规模数据进一步增强了性能，这也是首次将受监督语音标记融入 TTS 模型。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "work in progress. arXiv admin note: substantial text overlap with\n  arXiv:2407.04051",
      "pdf_url": "http://arxiv.org/pdf/2407.05407v2",
      "published_date": "2024-07-07 15:16:19 UTC",
      "updated_date": "2024-07-09 07:42:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:17:09.366394"
    },
    {
      "arxiv_id": "2407.05404v1",
      "title": "iSign: A Benchmark for Indian Sign Language Processing",
      "title_zh": "iSign：印度手语处理的基准",
      "authors": [
        "Abhinav Joshi",
        "Romit Mohanty",
        "Mounika Kanakanti",
        "Andesha Mangla",
        "Sudeep Choudhary",
        "Monali Barbate",
        "Ashutosh Modi"
      ],
      "abstract": "Indian Sign Language has limited resources for developing machine learning\nand data-driven approaches for automated language processing. Though\ntext/audio-based language processing techniques have shown colossal research\ninterest and tremendous improvements in the last few years, Sign Languages\nstill need to catch up due to the need for more resources. To bridge this gap,\nin this work, we propose iSign: a benchmark for Indian Sign Language (ISL)\nProcessing. We make three primary contributions to this work. First, we release\none of the largest ISL-English datasets with more than 118K\nvideo-sentence/phrase pairs. To the best of our knowledge, it is the largest\nsign language dataset available for ISL. Second, we propose multiple\nNLP-specific tasks (including SignVideo2Text, SignPose2Text, Text2Pose, Word\nPrediction, and Sign Semantics) and benchmark them with the baseline models for\neasier access to the research community. Third, we provide detailed insights\ninto the proposed benchmarks with a few linguistic insights into the workings\nof ISL. We streamline the evaluation of Sign Language processing, addressing\nthe gaps in the NLP research community for Sign Languages. We release the\ndataset, tasks, and models via the following website:\nhttps://exploration-lab.github.io/iSign/",
      "tldr_zh": "本论文提出 iSign 基准，用于解决印度手语 (ISL) 处理资源不足的问题，填补了手语在 NLP 领域的空白。主要贡献包括发布一个超过 118K 视频-句子/短语对的 ISL-English 数据集，这是目前最大的 ISL 数据集；其次，定义了多个 NLP 特定任务，如 SignVideo2Text、SignPose2Text、Text2Pose、Word Prediction 和 Sign Semantics，并提供基准模型以便研究社区使用；最后，通过详细分析和语言学见解，展示了 ISL 的特点，并公开了数据集、任务和模型资源。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at ACL 2024 Findings. 18 Pages (9 Pages + References +\n  Appendix)",
      "pdf_url": "http://arxiv.org/pdf/2407.05404v1",
      "published_date": "2024-07-07 15:07:35 UTC",
      "updated_date": "2024-07-07 15:07:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:17:25.883221"
    },
    {
      "arxiv_id": "2407.05399v2",
      "title": "IL-TUR: Benchmark for Indian Legal Text Understanding and Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Abhinav Joshi",
        "Shounak Paul",
        "Akshat Sharma",
        "Pawan Goyal",
        "Saptarshi Ghosh",
        "Ashutosh Modi"
      ],
      "abstract": "Legal systems worldwide are inundated with exponential growth in cases and\ndocuments. There is an imminent need to develop NLP and ML techniques for\nautomatically processing and understanding legal documents to streamline the\nlegal system. However, evaluating and comparing various NLP models designed\nspecifically for the legal domain is challenging. This paper addresses this\nchallenge by proposing IL-TUR: Benchmark for Indian Legal Text Understanding\nand Reasoning. IL-TUR contains monolingual (English, Hindi) and multi-lingual\n(9 Indian languages) domain-specific tasks that address different aspects of\nthe legal system from the point of view of understanding and reasoning over\nIndian legal documents. We present baseline models (including LLM-based) for\neach task, outlining the gap between models and the ground truth. To foster\nfurther research in the legal domain, we create a leaderboard (available at:\nhttps://exploration-lab.github.io/IL-TUR/) where the research community can\nupload and compare legal text understanding systems.",
      "tldr_zh": "本文提出 IL-TUR 基准，用于评估印度法律文本理解和推理，旨在应对法律系统文档激增的挑战，通过 NLP 和 ML 技术实现自动化处理。IL-TUR 包括单语（English 和 Hindi）和多语（9 种印度语言）的特定任务，涵盖法律文档的各种理解和推理方面。研究团队提供了基线模型（如 LLM-based），突出了模型与真实数据的性能差距，并建立了公开排行榜（https://exploration-lab.github.io/IL-TUR/），以鼓励研究社区上传和比较系统。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at ACL 2024 Main Conference; 40 Pages (9 Pages + References\n  + Appendix)",
      "pdf_url": "http://arxiv.org/pdf/2407.05399v2",
      "published_date": "2024-07-07 14:55:04 UTC",
      "updated_date": "2024-11-26 08:48:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:17:27.569750"
    },
    {
      "arxiv_id": "2407.05398v1",
      "title": "A Fair Post-Processing Method based on the MADD Metric for Predictive Student Models",
      "title_zh": "翻译失败",
      "authors": [
        "Mélina Verger",
        "Chunyang Fan",
        "Sébastien Lallé",
        "François Bouchet",
        "Vanda Luengo"
      ],
      "abstract": "Predictive student models are increasingly used in learning environments.\nHowever, due to the rising social impact of their usage, it is now all the more\nimportant for these models to be both sufficiently accurate and fair in their\npredictions. To evaluate algorithmic fairness, a new metric has been developed\nin education, namely the Model Absolute Density Distance (MADD). This metric\nenables us to measure how different a predictive model behaves regarding two\ngroups of students, in order to quantify its algorithmic unfairness. In this\npaper, we thus develop a post-processing method based on this metric, that aims\nat improving the fairness while preserving the accuracy of relevant predictive\nmodels' results. We experiment with our approach on the task of predicting\nstudent success in an online course, using both simulated and real-world\neducational data, and obtain successful results. Our source code and data are\nin open access at https://github.com/melinaverger/MADD .",
      "tldr_zh": "该论文提出了一种基于 MADD Metric 的后处理方法，旨在提升预测学生模型（Predictive Student Models）的公平性，同时保持其预测准确性。MADD Metric 用于量化模型在不同学生群体间的行为差异，从而评估算法不公平性。研究通过实验验证了该方法在预测在线课程学生成功任务上的有效性，使用模拟和真实教育数据取得了成功结果，并开源了代码和数据。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.DM",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.CY",
      "comment": "1st International Tutorial and Workshop on Responsible Knowledge\n  Discovery in Education (RKDE 2023) at ECML PKDD 2023, September 2023, Turino,\n  Italy",
      "pdf_url": "http://arxiv.org/pdf/2407.05398v1",
      "published_date": "2024-07-07 14:53:41 UTC",
      "updated_date": "2024-07-07 14:53:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:17:38.670238"
    },
    {
      "arxiv_id": "2407.05396v2",
      "title": "Evolutionary Trigger Detection and Lightweight Model Repair Based Backdoor Defense",
      "title_zh": "翻译失败",
      "authors": [
        "Qi Zhou",
        "Zipeng Ye",
        "Yubo Tang",
        "Wenjian Luo",
        "Yuhui Shi",
        "Yan Jia"
      ],
      "abstract": "Deep Neural Networks (DNNs) have been widely used in many areas such as\nautonomous driving and face recognition. However, DNN model is fragile to\nbackdoor attack. A backdoor in the DNN model can be activated by a poisoned\ninput with trigger and leads to wrong prediction, which causes serious security\nissues in applications. It is challenging for current defenses to eliminate the\nbackdoor effectively with limited computing resources, especially when the\nsizes and numbers of the triggers are variable as in the physical world. We\npropose an efficient backdoor defense based on evolutionary trigger detection\nand lightweight model repair. In the first phase of our method, CAM-focus\nEvolutionary Trigger Filter (CETF) is proposed for trigger detection. CETF is\nan effective sample-preprocessing based method with the evolutionary algorithm,\nand our experimental results show that CETF not only distinguishes the images\nwith triggers accurately from the clean images, but also can be widely used in\npractice for its simplicity and stability in different backdoor attack\nsituations. In the second phase of our method, we leverage several lightweight\nunlearning methods with the trigger detected by CETF for model repair, which\nalso constructively demonstrate the underlying correlation of the backdoor with\nBatch Normalization layers. Source code will be published after accepted.",
      "tldr_zh": "该研究针对深度神经网络（DNNs）易受后门攻击的问题，提出了一种高效防御方法，包括两个阶段：首先，使用 CAM-focus Evolutionary Trigger Filter (CETF) 基于进化算法进行触发器检测，能准确区分带有触发器的图像与干净图像，并适用于各种攻击场景；其次，通过轻量级 unlearning 方法结合检测到的触发器修复模型，并揭示后门与 Batch Normalization 层的潜在相关性。实验结果证明，该方法在不同后门攻击情况下表现出色，提升了防御的稳定性和有效性。源代码将在论文接受后发布。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "13 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.05396v2",
      "published_date": "2024-07-07 14:50:59 UTC",
      "updated_date": "2024-07-14 08:25:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:17:50.872903"
    },
    {
      "arxiv_id": "2407.05389v1",
      "title": "Image-Conditional Diffusion Transformer for Underwater Image Enhancement",
      "title_zh": "翻译失败",
      "authors": [
        "Xingyang Nie",
        "Su Pan",
        "Xiaoyu Zhai",
        "Shifei Tao",
        "Fengzhong Qu",
        "Biao Wang",
        "Huilin Ge",
        "Guojie Xiao"
      ],
      "abstract": "Underwater image enhancement (UIE) has attracted much attention owing to its\nimportance for underwater operation and marine engineering. Motivated by the\nrecent advance in generative models, we propose a novel UIE method based on\nimage-conditional diffusion transformer (ICDT). Our method takes the degraded\nunderwater image as the conditional input and converts it into latent space\nwhere ICDT is applied. ICDT replaces the conventional U-Net backbone in a\ndenoising diffusion probabilistic model (DDPM) with a transformer, and thus\ninherits favorable properties such as scalability from transformers.\nFurthermore, we train ICDT with a hybrid loss function involving variances to\nachieve better log-likelihoods, which meanwhile significantly accelerates the\nsampling process. We experimentally assess the scalability of ICDTs and compare\nwith prior works in UIE on the Underwater ImageNet dataset. Besides good\nscaling properties, our largest model, ICDT-XL/2, outperforms all comparison\nmethods, achieving state-of-the-art (SOTA) quality of image enhancement.",
      "tldr_zh": "本研究针对水下图像增强(UIE)问题，提出了一种基于图像条件扩散Transformer (ICDT)的新方法，该方法将退化的水下图像作为条件输入，并将其转换到潜在空间中应用ICDT，以替换传统去噪扩散概率模型(DDPM)中的U-Net骨干网络，从而提升模型的可扩展性。ICDT通过混合损失函数训练，包括方差优化，以提高log-likelihood并显著加速采样过程。在Underwater ImageNet数据集上的实验中，ICDT显示出良好的可扩展性，其最大模型ICDT-XL/2在图像增强质量上超越所有现有方法，达到了SOTA水平。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05389v1",
      "published_date": "2024-07-07 14:34:31 UTC",
      "updated_date": "2024-07-07 14:34:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:18:02.679434"
    },
    {
      "arxiv_id": "2407.05385v1",
      "title": "Harmony in Diversity: Merging Neural Networks with Canonical Correlation Analysis",
      "title_zh": "多样性中的和谐：通过 Canonical Correlation Analysis 合并神经网络",
      "authors": [
        "Stefan Horoi",
        "Albert Manuel Orozco Camacho",
        "Eugene Belilovsky",
        "Guy Wolf"
      ],
      "abstract": "Combining the predictions of multiple trained models through ensembling is\ngenerally a good way to improve accuracy by leveraging the different learned\nfeatures of the models, however it comes with high computational and storage\ncosts. Model fusion, the act of merging multiple models into one by combining\ntheir parameters reduces these costs but doesn't work as well in practice.\nIndeed, neural network loss landscapes are high-dimensional and non-convex and\nthe minima found through learning are typically separated by high loss\nbarriers. Numerous recent works have been focused on finding permutations\nmatching one network features to the features of a second one, lowering the\nloss barrier on the linear path between them in parameter space. However,\npermutations are restrictive since they assume a one-to-one mapping between the\ndifferent models' neurons exists. We propose a new model merging algorithm, CCA\nMerge, which is based on Canonical Correlation Analysis and aims to maximize\nthe correlations between linear combinations of the model features. We show\nthat our alignment method leads to better performances than past methods when\naveraging models trained on the same, or differing data splits. We also extend\nthis analysis into the harder setting where more than 2 models are merged, and\nwe find that CCA Merge works significantly better than past methods. Our code\nis publicly available at https://github.com/shoroi/align-n-merge",
      "tldr_zh": "本研究探讨了神经网络模型融合的问题，旨在解决传统集成方法(ensembling)的计算和存储成本高问题，以及现有融合方法因损失景观非凸而效果不佳的局限。作者提出了一种新算法CCA Merge，基于Canonical Correlation Analysis(CCA)，通过最大化模型特征的线性组合之间的相关性，实现更有效的模型参数合并，而不依赖于神经元的一一映射(permutations)。实验结果显示，CCA Merge在合并相同或不同数据分割的模型时，比过去方法性能更优，尤其在融合超过2个模型的复杂场景中表现出显著优势。该方法为高效模型融合提供了新途径，并已在开源代码中实现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Proceedings of the Forty-first International Conference on Machine\n  Learning (ICML 2024)",
      "pdf_url": "http://arxiv.org/pdf/2407.05385v1",
      "published_date": "2024-07-07 14:21:04 UTC",
      "updated_date": "2024-07-07 14:21:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:18:15.058260"
    },
    {
      "arxiv_id": "2407.05379v1",
      "title": "AiGAS-dEVL: An Adaptive Incremental Neural Gas Model for Drifting Data Streams under Extreme Verification Latency",
      "title_zh": "AiGAS-dEVL：一种自适应增量神经气模型，用于极端验证延迟下的漂移数据流",
      "authors": [
        "Maria Arostegi",
        "Miren Nekane Bilbao",
        "Jesus L. Lobo",
        "Javier Del Ser"
      ],
      "abstract": "The ever-growing speed at which data are generated nowadays, together with\nthe substantial cost of labeling processes cause Machine Learning models to\nface scenarios in which data are partially labeled. The extreme case where such\na supervision is indefinitely unavailable is referred to as extreme\nverification latency. On the other hand, in streaming setups data flows are\naffected by exogenous factors that yield non-stationarities in the patterns\n(concept drift), compelling models learned incrementally from the data streams\nto adapt their modeled knowledge to the concepts within the stream. In this\nwork we address the casuistry in which these two conditions occur together, by\nwhich adaptation mechanisms to accommodate drifts within the stream are\nchallenged by the lack of supervision, requiring further mechanisms to track\nthe evolution of concepts in the absence of verification. To this end we\npropose a novel approach, AiGAS-dEVL (Adaptive Incremental neural GAS model for\ndrifting Streams under Extreme Verification Latency), which relies on growing\nneural gas to characterize the distributions of all concepts detected within\nthe stream over time. Our approach exposes that the online analysis of the\nbehavior of these prototypical points over time facilitates the definition of\nthe evolution of concepts in the feature space, the detection of changes in\ntheir behavior, and the design of adaptation policies to mitigate the effect of\nsuch changes in the model. We assess the performance of AiGAS-dEVL over several\nsynthetic datasets, comparing it to that of state-of-the-art approaches\nproposed in the recent past to tackle this stream learning setup. Our results\nreveal that AiGAS-dEVL performs competitively with respect to the rest of\nbaselines, exhibiting a superior adaptability over several datasets in the\nbenchmark while ensuring a simple and interpretable instance-based adaptation\nstrategy.",
      "tldr_zh": "该研究针对数据流中的概念漂移（concept drift）和极端验证延迟（extreme verification latency）问题，提出了一种新型自适应增量神经气模型AiGAS-dEVL。该模型利用growing neural gas来表征数据流中概念的分布，通过在线分析原型点的行为检测概念演变，并设计适应策略以应对缺乏监督的情况。在合成数据集上的实验表明，AiGAS-dEVL与现有基准方法相比表现出色，具有更强的适应性和简单可解释的实例-based适应策略。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE",
        "68T05",
        "I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "26 pages, 3 tables, 4 figures. Under review",
      "pdf_url": "http://arxiv.org/pdf/2407.05379v1",
      "published_date": "2024-07-07 14:04:57 UTC",
      "updated_date": "2024-07-07 14:04:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:18:27.278610"
    },
    {
      "arxiv_id": "2407.05377v1",
      "title": "Collective Innovation in Groups of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Eleni Nisioti",
        "Sebastian Risi",
        "Ida Momennejad",
        "Pierre-Yves Oudeyer",
        "Clément Moulin-Frier"
      ],
      "abstract": "Human culture relies on collective innovation: our ability to continuously\nexplore how existing elements in our environment can be combined to create new\nones. Language is hypothesized to play a key role in human culture, driving\nindividual cognitive capacities and shaping communication. Yet the majority of\nmodels of collective innovation assign no cognitive capacities or language\nabilities to agents. Here, we contribute a computational study of collective\ninnovation where agents are Large Language Models (LLMs) that play Little\nAlchemy 2, a creative video game originally developed for humans that, as we\nargue, captures useful aspects of innovation landscapes not present in previous\ntest-beds. We, first, study an LLM in isolation and discover that it exhibits\nboth useful skills and crucial limitations. We, then, study groups of LLMs that\nshare information related to their behaviour and focus on the effect of social\nconnectivity on collective performance. In agreement with previous human and\ncomputational studies, we observe that groups with dynamic connectivity\nout-compete fully-connected groups. Our work reveals opportunities and\nchallenges for future studies of collective innovation that are becoming\nincreasingly relevant as Generative Artificial Intelligence algorithms and\nhumans innovate alongside each other.",
      "tldr_zh": "本研究探讨了Large Language Models (LLMs)作为代理在集体创新中的表现，通过让它们玩Little Alchemy 2游戏模拟人类创新过程。研究首先分析单个LLM的表现，发现其具备某些有用技能但也存在关键局限，如认知和语言方面的不足。随后，考察LLM群体的互动，强调社会连通性的影响，结果显示动态连通性群体比全连通群体在集体绩效上更具优势，与人类和先前计算研究一致。该工作揭示了AI与人类共同创新的机遇和挑战，为未来相关研究提供重要参考。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05377v1",
      "published_date": "2024-07-07 13:59:46 UTC",
      "updated_date": "2024-07-07 13:59:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:18:39.214024"
    },
    {
      "arxiv_id": "2407.05375v1",
      "title": "Online Drift Detection with Maximum Concept Discrepancy",
      "title_zh": "翻译失败",
      "authors": [
        "Ke Wan",
        "Yi Liang",
        "Susik Yoon"
      ],
      "abstract": "Continuous learning from an immense volume of data streams becomes\nexceptionally critical in the internet era. However, data streams often do not\nconform to the same distribution over time, leading to a phenomenon called\nconcept drift. Since a fixed static model is unreliable for inferring\nconcept-drifted data streams, establishing an adaptive mechanism for detecting\nconcept drift is crucial. Current methods for concept drift detection primarily\nassume that the labels or error rates of downstream models are given and/or\nunderlying statistical properties exist in data streams. These approaches,\nhowever, struggle to address high-dimensional data streams with intricate\nirregular distribution shifts, which are more prevalent in real-world\nscenarios. In this paper, we propose MCD-DD, a novel concept drift detection\nmethod based on maximum concept discrepancy, inspired by the maximum mean\ndiscrepancy. Our method can adaptively identify varying forms of concept drift\nby contrastive learning of concept embeddings without relying on labels or\nstatistical properties. With thorough experiments under synthetic and\nreal-world scenarios, we demonstrate that the proposed method outperforms\nexisting baselines in identifying concept drifts and enables qualitative\nanalysis with high explainability.",
      "tldr_zh": "在数据流持续学习中，概念漂移（concept drift）会导致模型性能下降，现有的检测方法往往依赖标签或错误率，且难以处理高维数据和复杂分布变化。论文提出了一种新方法MCD-DD（基于maximum concept discrepancy），通过对比学习（contrastive learning）概念嵌入（concept embeddings）来适应性识别各种形式的概念漂移，而不需依赖标签或统计属性。实验结果表明，MCD-DD在合成和真实场景下优于现有基线，能够准确检测漂移并提供高可解释性的定性分析。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05375v1",
      "published_date": "2024-07-07 13:57:50 UTC",
      "updated_date": "2024-07-07 13:57:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:18:52.240613"
    },
    {
      "arxiv_id": "2407.05368v1",
      "title": "Music Era Recognition Using Supervised Contrastive Learning and Artist Information",
      "title_zh": "使用监督对比学习和艺术家信息的音乐时代识别",
      "authors": [
        "Qiqi He",
        "Xuchen Song",
        "Weituo Hao",
        "Ju-Chiang Wang",
        "Wei-Tsung Lu",
        "Wei Li"
      ],
      "abstract": "Does popular music from the 60s sound different than that of the 90s? Prior\nstudy has shown that there would exist some variations of patterns and\nregularities related to instrumentation changes and growing loudness across\nmulti-decadal trends. This indicates that perceiving the era of a song from\nmusical features such as audio and artist information is possible. Music era\ninformation can be an important feature for playlist generation and\nrecommendation. However, the release year of a song can be inaccessible in many\ncircumstances. This paper addresses a novel task of music era recognition. We\nformulate the task as a music classification problem and propose solutions\nbased on supervised contrastive learning. An audio-based model is developed to\npredict the era from audio. For the case where the artist information is\navailable, we extend the audio-based model to take multimodal inputs and\ndevelop a framework, called MultiModal Contrastive (MMC) learning, to enhance\nthe training. Experimental result on Million Song Dataset demonstrates that the\naudio-based model achieves 54% in accuracy with a tolerance of 3-years range;\nincorporating the artist information with the MMC framework for training leads\nto 9% improvement further.",
      "tldr_zh": "本研究探讨音乐时代识别任务，利用音乐特征如音频和艺术家信息来预测歌曲的时代，例如区分60年代和90年代的流行音乐。研究将该任务表述为音乐分类问题，提出基于Supervised Contrastive Learning的音频模型来从音频中预测歌曲时代，并扩展为MultiModal Contrastive (MMC)学习框架，以整合多模态输入包括艺术家信息。实验在Million Song Dataset上显示，音频模型的准确率达到54%（容差3年范围），而加入MMC框架后进一步提升9%。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.IR",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05368v1",
      "published_date": "2024-07-07 13:43:55 UTC",
      "updated_date": "2024-07-07 13:43:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:19:02.904844"
    },
    {
      "arxiv_id": "2407.05365v2",
      "title": "ElecBench: a Power Dispatch Evaluation Benchmark for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Xiyuan Zhou",
        "Huan Zhao",
        "Yuheng Cheng",
        "Yuji Cao",
        "Gaoqi Liang",
        "Guolong Liu",
        "Wenxuan Liu",
        "Yan Xu",
        "Junhua Zhao"
      ],
      "abstract": "In response to the urgent demand for grid stability and the complex\nchallenges posed by renewable energy integration and electricity market\ndynamics, the power sector increasingly seeks innovative technological\nsolutions. In this context, large language models (LLMs) have become a key\ntechnology to improve efficiency and promote intelligent progress in the power\nsector with their excellent natural language processing, logical reasoning, and\ngeneralization capabilities. Despite their potential, the absence of a\nperformance evaluation benchmark for LLM in the power sector has limited the\neffective application of these technologies. Addressing this gap, our study\nintroduces \"ElecBench\", an evaluation benchmark of LLMs within the power\nsector. ElecBench aims to overcome the shortcomings of existing evaluation\nbenchmarks by providing comprehensive coverage of sector-specific scenarios,\ndeepening the testing of professional knowledge, and enhancing decision-making\nprecision. The framework categorizes scenarios into general knowledge and\nprofessional business, further divided into six core performance metrics:\nfactuality, logicality, stability, security, fairness, and expressiveness, and\nis subdivided into 24 sub-metrics, offering profound insights into the\ncapabilities and limitations of LLM applications in the power sector. To ensure\ntransparency, we have made the complete test set public, evaluating the\nperformance of eight LLMs across various scenarios and metrics. ElecBench\naspires to serve as the standard benchmark for LLM applications in the power\nsector, supporting continuous updates of scenarios, metrics, and models to\ndrive technological progress and application.",
      "tldr_zh": "这篇论文引入了ElecBench，一种针对大型语言模型(LLMs)在电力行业的性能评估基准，以应对电网稳定、清洁能源整合和市场动态的挑战。ElecBench将评估场景分为一般知识和专业业务两大类，并涵盖六个核心指标（factuality、logicality、stability、security、fairness和expressiveness），进一步细分为24个子指标，以测试LLMs的专业知识和决策精度。研究公开了完整的测试集，并评估了八个LLMs的表现，旨在成为电力领域LLMs应用的标准化基准，支持持续更新以推动技术进步。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05365v2",
      "published_date": "2024-07-07 13:38:05 UTC",
      "updated_date": "2024-08-11 11:11:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:19:16.505870"
    },
    {
      "arxiv_id": "2407.06235v1",
      "title": "Auditing of AI: Legal, Ethical and Technical Approaches",
      "title_zh": "AI 审计：法律、伦理和技术方法",
      "authors": [
        "Jakob Mokander"
      ],
      "abstract": "AI auditing is a rapidly growing field of research and practice. This review\narticle, which doubles as an editorial to Digital Societys topical collection\non Auditing of AI, provides an overview of previous work in the field. Three\nkey points emerge from the review. First, contemporary attempts to audit AI\nsystems have much to learn from how audits have historically been structured\nand conducted in areas like financial accounting, safety engineering and the\nsocial sciences. Second, both policymakers and technology providers have an\ninterest in promoting auditing as an AI governance mechanism. Academic\nresearchers can thus fill an important role by studying the feasibility and\neffectiveness of different AI auditing procedures. Third, AI auditing is an\ninherently multidisciplinary undertaking, to which substantial contributions\nhave been made by computer scientists and engineers as well as social\nscientists, philosophers, legal scholars and industry practitioners. Reflecting\nthis diversity of perspectives, different approaches to AI auditing have\ndifferent affordances and constraints. Specifically, a distinction can be made\nbetween technology-oriented audits, which focus on the properties and\ncapabilities of AI systems, and process oriented audits, which focus on\ntechnology providers governance structures and quality management systems. The\nnext step in the evolution of auditing as an AI governance mechanism, this\narticle concludes, should be the interlinking of these available (and\ncomplementary) approaches into structured and holistic procedures to audit not\nonly how AI systems are designed and used but also how they impact users,\nsocieties and the natural environment in applied settings over time.",
      "tldr_zh": "这篇综述文章概述了AI auditing（AI 审计）领域的现有研究和实践，强调从财务会计、安全工程和社会科学等领域的历史审计方法中汲取经验。文章指出，政策制定者和技术提供者都对将AI auditing作为AI治理机制感兴趣，而学术研究应评估不同审计程序的可行性和有效性；同时，AI auditing是多学科合作，包括计算机科学、社会科学和法律等领域。作者区分了技术导向审计（关注AI系统的属性和能力）和过程导向审计（关注技术提供者的治理结构），并建议将这些方法整合成结构化的整体程序，以评估AI系统的设计、使用及其长期社会和环境影响。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06235v1",
      "published_date": "2024-07-07 12:49:58 UTC",
      "updated_date": "2024-07-07 12:49:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:19:27.841894"
    },
    {
      "arxiv_id": "2407.07918v2",
      "title": "Detecting new obfuscated malware variants: A lightweight and interpretable machine learning approach",
      "title_zh": "翻译失败",
      "authors": [
        "Oladipo A. Madamidola",
        "Felix Ngobigha",
        "Adnane Ez-zizi"
      ],
      "abstract": "Machine learning has been successfully applied in developing malware\ndetection systems, with a primary focus on accuracy, and increasing attention\nto reducing computational overhead and improving model interpretability.\nHowever, an important question remains underexplored: How well can machine\nlearning-based models detect entirely new forms of malware not present in the\ntraining data? In this study, we present a machine learning-based system for\ndetecting obfuscated malware that is not only highly accurate, lightweight and\ninterpretable, but also capable of successfully adapting to new types of\nmalware attacks. Our system is capable of detecting 15 malware subtypes despite\nbeing exclusively trained on one malware subtype, namely the Transponder from\nthe Spyware family. This system was built after training 15 distinct random\nforest-based models, each on a different malware subtype from the\nCIC-MalMem-2022 dataset. These models were evaluated against the entire range\nof malware subtypes, including all unseen malware subtypes. To maintain the\nsystem's streamlined nature, training was confined to the top five most\nimportant features, which also enhanced interpretability. The\nTransponder-focused model exhibited high accuracy, exceeding 99.8%, with an\naverage processing speed of 5.7 microseconds per file. We also illustrate how\nthe Shapley additive explanations technique can facilitate the interpretation\nof the model predictions. Our research contributes to advancing malware\ndetection methodologies, pioneering the feasibility of detecting obfuscated\nmalware by exclusively training a model on a single or a few carefully selected\nmalware subtypes and applying it to detect unseen subtypes.",
      "tldr_zh": "本研究提出了一种轻量级且可解释的机器学习方法，用于检测训练数据中不存在的新型混淆恶意软件(obfuscated malware)，重点解决模型适应性问题。系统基于随机森林(random forest)模型，仅使用前五个最重要的特征(top five most important features)在一种恶意软件子类型(Transponder from the Spyware family)上训练，即可检测15种子类型，包括未见过的变种。实验结果显示，该模型准确率超过99.8%，平均处理速度为5.7微秒每文件，并通过Shapley additive explanations(SHAP)技术提升预测的可解释性。该方法证明了通过针对少数子类型训练的模型即可有效检测新恶意软件变种，从而推进了恶意软件检测领域的创新。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "30 pages (excluding Appendix), 5 figures and 5 tables. Now published\n  in Intelligent Systems with Applications\n  (https://doi.org/10.1016/j.iswa.2024.200472)",
      "pdf_url": "http://arxiv.org/pdf/2407.07918v2",
      "published_date": "2024-07-07 12:41:40 UTC",
      "updated_date": "2025-03-06 12:41:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:19:52.247879"
    },
    {
      "arxiv_id": "2407.06234v1",
      "title": "The US Algorithmic Accountability Act of 2022 vs. The EU Artificial Intelligence Act: What can they learn from each other?",
      "title_zh": "翻译失败",
      "authors": [
        "Jakob Mokander",
        "Prathm Juneja",
        "David Watson",
        "Luciano Floridi"
      ],
      "abstract": "On the whole, the U.S. Algorithmic Accountability Act of 2022 (US AAA) is a\npragmatic approach to balancing the benefits and risks of automated decision\nsystems. Yet there is still room for improvement. This commentary highlights\nhow the US AAA can both inform and learn from the European Artificial\nIntelligence Act (EU AIA).",
      "tldr_zh": "这篇评论比较了美国2022年算法责任法案(US Algorithmic Accountability Act of 2022, US AAA)和欧盟人工智能法案(EU Artificial Intelligence Act, EU AIA)，探讨它们在监管自动化决策系统方面可以互相借鉴的内容。论文认为，US AAA 采用务实的平衡方法，既考虑了系统的益处，也关注了潜在风险，但仍存在改进空间。评论强调，US AAA 可以从EU AIA 的框架中学习，以增强其全面性和有效性，从而更好地应对算法伦理挑战。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "Minds & Machines (2022)",
      "pdf_url": "http://arxiv.org/pdf/2407.06234v1",
      "published_date": "2024-07-07 12:31:13 UTC",
      "updated_date": "2024-07-07 12:31:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:19:52.227763"
    },
    {
      "arxiv_id": "2407.06233v1",
      "title": "AI and Social Theory",
      "title_zh": "AI 与社会理论",
      "authors": [
        "Jakob Mokander",
        "Ralph Schroeder"
      ],
      "abstract": "In this paper, we sketch a programme for AI driven social theory. We begin by\ndefining what we mean by artificial intelligence (AI) in this context. We then\nlay out our model for how AI based models can draw on the growing availability\nof digital data to help test the validity of different social theories based on\ntheir predictive power. In doing so, we use the work of Randall Collins and his\nstate breakdown model to exemplify that, already today, AI based models can\nhelp synthesize knowledge from a variety of sources, reason about the world,\nand apply what is known across a wide range of problems in a systematic way.\nHowever, we also find that AI driven social theory remains subject to a range\nof practical, technical, and epistemological limitations. Most critically,\nexisting AI systems lack three essential capabilities needed to advance social\ntheory in ways that are cumulative, holistic, open-ended, and purposeful. These\nare (1) semanticization, i.e., the ability to develop and operationalize verbal\nconcepts to represent machine-manipulable knowledge, (2) transferability, i.e.,\nthe ability to transfer what has been learned in one context to another, and\n(3) generativity, i.e., the ability to independently create and improve on\nconcepts and models. We argue that if the gaps identified here are addressed by\nfurther research, there is no reason why, in the future, the most advanced\nprogramme in social theory should not be led by AI-driven cumulative advances.",
      "tldr_zh": "本论文提出一个AI驱动的社会理论程序，利用AI模型通过数字数据测试社会理论的有效性，并以Randall Collins的国家崩溃模型为例，展示AI如何合成知识、进行推理并应用于各种问题。作者强调，AI在预测能力上已有潜力，但仍面临实际、技术和认识论限制，特别是缺少semanticization（语义化）、transferability（可转移性）和generativity（生成性）等关键能力，这些缺失阻碍了社会理论的累积、整体性和开放性发展。如果这些问题通过进一步研究得到解决，论文认为AI可能在未来领导社会理论的累进式进展。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.06233v1",
      "published_date": "2024-07-07 12:26:16 UTC",
      "updated_date": "2024-07-07 12:26:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:20:03.576226"
    },
    {
      "arxiv_id": "2407.05341v1",
      "title": "The Switch, the Ladder, and the Matrix: Models for Classifying AI Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Jakob Mokander",
        "Margi Sheth",
        "David Watson",
        "Luciano Floridi"
      ],
      "abstract": "Organisations that design and deploy artificial intelligence (AI) systems\nincreasingly commit themselves to high-level, ethical principles. However,\nthere still exists a gap between principles and practices in AI ethics. One\nmajor obstacle organisations face when attempting to operationalise AI Ethics\nis the lack of a well-defined material scope. Put differently, the question to\nwhich systems and processes AI ethics principles ought to apply remains\nunanswered. Of course, there exists no universally accepted definition of AI,\nand different systems pose different ethical challenges. Nevertheless,\npragmatic problem-solving demands that things should be sorted so that their\ngrouping will promote successful actions for some specific end. In this\narticle, we review and compare previous attempts to classify AI systems for the\npurpose of implementing AI governance in practice. We find that attempts to\nclassify AI systems found in previous literature use one of three mental model.\nThe Switch, i.e., a binary approach according to which systems either are or\nare not considered AI systems depending on their characteristics. The Ladder,\ni.e., a risk-based approach that classifies systems according to the ethical\nrisks they pose. And the Matrix, i.e., a multi-dimensional classification of\nsystems that take various aspects into account, such as context, data input,\nand decision-model. Each of these models for classifying AI systems comes with\nits own set of strengths and weaknesses. By conceptualising different ways of\nclassifying AI systems into simple mental models, we hope to provide\norganisations that design, deploy, or regulate AI systems with the conceptual\ntools needed to operationalise AI governance in practice.",
      "tldr_zh": "该论文探讨了 AI 伦理原则在实践中的应用难题，特别是 AI 系统定义和适用范围的模糊问题。作者回顾并比较了现有文献中 AI 系统分类的尝试，将这些方法归纳为三个心理模型：The Switch（二元分类，根据系统特性判定是否为 AI）、The Ladder（基于风险的分类，按伦理风险水平排序）和The Matrix（多维分类，考虑上下文、数据输入和决策模型等因素）。每个模型都有各自的优缺点，例如 The Switch 简单易用，但可能过于粗糙，而 The Matrix 更全面但复杂。最终，该研究为设计、部署或监管 AI 系统提供概念工具，以实现 AI governance 的实际操作化。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05341v1",
      "published_date": "2024-07-07 12:16:01 UTC",
      "updated_date": "2024-07-07 12:16:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:20:16.217155"
    },
    {
      "arxiv_id": "2407.05339v1",
      "title": "Challenges and Best Practices in Corporate AI Governance:Lessons from the Biopharmaceutical Industry",
      "title_zh": "企业AI治理中的挑战和最佳实践：生物制药行业的经验教训",
      "authors": [
        "Jakob Mökander",
        "Margi Sheth",
        "Mimmi Gersbro-Sundler",
        "Peder Blomgren",
        "Luciano Floridi"
      ],
      "abstract": "While the use of artificial intelligence (AI) systems promises to bring\nsignificant economic and social benefits, it is also coupled with ethical,\nlegal, and technical challenges. Business leaders thus face the question of how\nto best reap the benefits of automation whilst managing the associated risks.\nAs a first step, many companies have committed themselves to various sets of\nethics principles aimed at guiding the design and use of AI systems. So far so\ngood. But how can well-intentioned ethical principles be translated into\neffective practice? And what challenges await companies that attempt to\noperationalize AI governance? In this article, we address these questions by\ndrawing on our first-hand experience of shaping and driving the roll-out of AI\ngovernance within AstraZeneca, a biopharmaceutical company. The examples we\ndiscuss highlight challenges that any organization attempting to operationalize\nAI governance will have to face. These include questions concerning how to\ndefine the material scope of AI governance, how to harmonize standards across\ndecentralized organizations, and how to measure the impact of specific AI\ngovernance initiatives. By showcasing how AstraZeneca managed these operational\nquestions, we hope to provide project managers, CIOs, AI practitioners, and\ndata privacy officers responsible for designing and implementing AI governance\nframeworks within other organizations with generalizable best practices. In\nessence, companies seeking to operationalize AI governance are encouraged to\nbuild on existing policies and governance structures, use pragmatic and\naction-oriented terminology, focus on risk management in development and\nprocurement, and empower employees through continuous education and change\nmanagement.",
      "tldr_zh": "这篇论文探讨了企业在实施AI治理时面临的挑战和最佳实践，特别是基于生物制药行业AstraZeneca的实际经验。作者强调，将AI伦理原则转化为操作实践的难点，包括定义AI governance的适用范围、在分散组织中协调标准，以及评估具体举措的影响。通过分享案例，论文提出可推广的最佳实践：利用现有政策和治理结构、采用实用行动导向的术语、注重开发和采购中的风险管理，以及通过持续教育和变革管理赋能员工。这些见解旨在帮助项目经理、CIO、AI从业者和数据隐私官在其他组织中有效构建AI治理框架。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05339v1",
      "published_date": "2024-07-07 12:01:42 UTC",
      "updated_date": "2024-07-07 12:01:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:20:27.265087"
    },
    {
      "arxiv_id": "2407.05338v1",
      "title": "A Blueprint for Auditing Generative AI",
      "title_zh": "翻译失败",
      "authors": [
        "Jakob Mokander",
        "Justin Curl",
        "Mihir Kshirsagar"
      ],
      "abstract": "The widespread use of generative AI systems is coupled with significant\nethical and social challenges. As a result, policymakers, academic researchers,\nand social advocacy groups have all called for such systems to be audited.\nHowever, existing auditing procedures fail to address the governance challenges\nposed by generative AI systems, which display emergent capabilities and are\nadaptable to a wide range of downstream tasks. In this chapter, we address that\ngap by outlining a novel blueprint for how to audit such systems. Specifically,\nwe propose a three-layered approach, whereby governance audits (of technology\nproviders that design and disseminate generative AI systems), model audits (of\ngenerative AI systems after pre-training but prior to their release), and\napplication audits (of applications based on top of generative AI systems)\ncomplement and inform each other. We show how audits on these three levels,\nwhen conducted in a structured and coordinated manner, can be a feasible and\neffective mechanism for identifying and managing some of the ethical and social\nrisks posed by generative AI systems. That said, it is important to remain\nrealistic about what auditing can reasonably be expected to achieve. For this\nreason, the chapter also discusses the limitations not only of our\nthree-layered approach but also of the prospect of auditing generative AI\nsystems at all. Ultimately, this chapter seeks to expand the methodological\ntoolkit available to technology providers and policymakers who wish to analyse\nand evaluate generative AI systems from technical, ethical, and legal\nperspectives.",
      "tldr_zh": "这篇论文针对生成式 AI 的广泛应用及其引发的伦理和社会风险，提出一个新型审计蓝图，以应对现有审计程序的不足。蓝图采用三层方法，包括 governance audits（针对技术提供者的治理审计）、model audits（针对预训练后模型的审计）和 application audits（针对基于模型的应用审计），这些层相互补充以识别和管理风险。实验和分析表明，这种结构化协调的审计机制可有效评估生成式 AI 系统，但论文也讨论了其局限性，并强调审计在技术、伦理和法律角度的整体潜力。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05338v1",
      "published_date": "2024-07-07 11:56:54 UTC",
      "updated_date": "2024-07-07 11:56:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:20:40.200055"
    },
    {
      "arxiv_id": "2407.05336v1",
      "title": "Artificial intelligence, rationalization, and the limits of control in the public sector: the case of tax policy optimization",
      "title_zh": "人工智能、理性化以及公共部门控制的极限：税政策优化的案例",
      "authors": [
        "Jakob Mokander",
        "Ralph Schroeder"
      ],
      "abstract": "The use of artificial intelligence (AI) in the public sector is best\nunderstood as a continuation and intensification of long standing\nrationalization and bureaucratization processes. Drawing on Weber, we take the\ncore of these processes to be the replacement of traditions with instrumental\nrationality, i.e., the most calculable and efficient way of achieving any given\npolicy objective. In this article, we demonstrate how much of the criticisms,\nboth among the public and in scholarship, directed towards AI systems spring\nfrom well known tensions at the heart of Weberian rationalization. To\nillustrate this point, we introduce a thought experiment whereby AI systems are\nused to optimize tax policy to advance a specific normative end, reducing\neconomic inequality. Our analysis shows that building a machine-like tax system\nthat promotes social and economic equality is possible. However, it also\nhighlights that AI driven policy optimization (i) comes at the exclusion of\nother competing political values, (ii) overrides citizens sense of their\nnoninstrumental obligations to each other, and (iii) undermines the notion of\nhumans as self-determining beings. Contemporary scholarship and advocacy\ndirected towards ensuring that AI systems are legal, ethical, and safe build on\nand reinforce central assumptions that underpin the process of rationalization,\nincluding the modern idea that science can sweep away oppressive systems and\nreplace them with a rule of reason that would rescue humans from moral\ninjustices. That is overly optimistic. Science can only provide the means, they\ncannot dictate the ends. Nonetheless, the use of AI in the public sector can\nalso benefit the institutions and processes of liberal democracies. Most\nimportantly, AI driven policy optimization demands that normative ends are made\nexplicit and formalized, thereby subjecting them to public scrutiny and debate.",
      "tldr_zh": "该论文探讨了人工智能（AI）在公共部门的应用如何延续并强化韦伯（Weber）理论中的理性化和官僚化进程，通过税收政策优化的思想实验进行分析。主要发现是，AI 驱动的政策优化虽能减少经济不平等，但会排除其他政治价值、忽略公民间的非工具性义务，并削弱人类作为自主主体的地位。论文强调，虽然科学仅提供手段而非目的，但 AI 使用能促使规范性目标明确化，从而增强公众审查和民主辩论。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05336v1",
      "published_date": "2024-07-07 11:54:14 UTC",
      "updated_date": "2024-07-07 11:54:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:20:52.544202"
    },
    {
      "arxiv_id": "2407.05333v2",
      "title": "Generating multi-scale NMC particles with radial grain architectures using spatial stochastics and GANs",
      "title_zh": "翻译失败",
      "authors": [
        "Lukas Fuchs",
        "Orkun Furat",
        "Donal P. Finegan",
        "Jeffery Allen",
        "Francois L. E. Usseglio-Viretta",
        "Bertan Ozdogru",
        "Peter J. Weddle",
        "Kandler Smith",
        "Volker Schmidt"
      ],
      "abstract": "Understanding structure-property relationships of Li-ion battery cathodes is\ncrucial for optimizing rate-performance and cycle-life resilience. However,\ncorrelating the morphology of cathode particles, such as in NMC811, and their\ninner grain architecture with electrode performance is challenging,\nparticularly, due to the significant length-scale difference between grain and\nparticle sizes. Experimentally, it is currently not feasible to image such a\nhigh number of particles with full granular detail to achieve representivity. A\nsecond challenge is that sufficiently high-resolution 3D imaging techniques\nremain expensive and are sparsely available at research institutions. To\naddress these challenges, a stereological generative adversarial network\n(GAN)-based model fitting approach is presented that can generate\nrepresentative 3D information from 2D data, enabling characterization of\nmaterials in 3D using cost-effective 2D data. Once calibrated, this multi-scale\nmodel is able to rapidly generate virtual cathode particles that are\nstatistically similar to experimental data, and thus is suitable for virtual\ncharacterization and materials testing through numerical simulations. A large\ndataset of simulated particles with inner grain architecture has been made\npublicly available.",
      "tldr_zh": "该论文针对锂离子电池阴极（如 NMC811）的结构-性能关系研究，提出一种基于空间随机过程（spatial stochastics）和生成对抗网络（GANs）的模型，以生成具有辐射状晶粒架构的多尺度 NMC 颗粒。方法通过从 2D 数据生成代表性的 3D 信息，解决了实验成像中颗粒数量不足和高分辨 3D 技术成本高的挑战。经校准后，该多尺度模型能快速创建统计上相似的虚拟颗粒，支持虚拟表征和数值模拟，并公开了一个包含内部分层架构的模拟颗粒数据集。",
      "categories": [
        "physics.app-ph",
        "cs.AI"
      ],
      "primary_category": "physics.app-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05333v2",
      "published_date": "2024-07-07 11:23:17 UTC",
      "updated_date": "2024-07-19 08:44:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:21:04.914113"
    },
    {
      "arxiv_id": "2407.05330v1",
      "title": "Fast Proxy Experiment Design for Causal Effect Identification",
      "title_zh": "用于因果效应识别的快速代理实验设计",
      "authors": [
        "Sepehr Elahi",
        "Sina Akbari",
        "Jalal Etesami",
        "Negar Kiyavash",
        "Patrick Thiran"
      ],
      "abstract": "Identifying causal effects is a key problem of interest across many\ndisciplines. The two long-standing approaches to estimate causal effects are\nobservational and experimental (randomized) studies. Observational studies can\nsuffer from unmeasured confounding, which may render the causal effects\nunidentifiable. On the other hand, direct experiments on the target variable\nmay be too costly or even infeasible to conduct. A middle ground between these\ntwo approaches is to estimate the causal effect of interest through proxy\nexperiments, which are conducted on variables with a lower cost to intervene on\ncompared to the main target. Akbari et al. [2022] studied this setting and\ndemonstrated that the problem of designing the optimal (minimum-cost)\nexperiment for causal effect identification is NP-complete and provided a naive\nalgorithm that may require solving exponentially many NP-hard problems as a\nsub-routine in the worst case. In this work, we provide a few reformulations of\nthe problem that allow for designing significantly more efficient algorithms to\nsolve it as witnessed by our extensive simulations. Additionally, we study the\nclosely-related problem of designing experiments that enable us to identify a\ngiven effect through valid adjustments sets.",
      "tldr_zh": "这篇论文针对因果效应（causal effect）识别的问题，探讨了在观察研究可能存在未测量混杂因素、而直接实验成本高昂的情况下，使用代理实验（proxy experiments）作为中间方案。作者重新表述了问题，设计了更高效的算法，以最小化实验成本，并通过广泛模拟证明这些算法显著优于之前可能需解决指数级 NP-hard 问题的 naive 方法。主要贡献包括为代理实验设计提供可扩展框架，并扩展到通过有效调整集（valid adjustment sets）识别给定效应的相关问题，从而提升了因果效应的可识别性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05330v1",
      "published_date": "2024-07-07 11:09:38 UTC",
      "updated_date": "2024-07-07 11:09:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:21:16.720606"
    },
    {
      "arxiv_id": "2407.05320v1",
      "title": "KAE: A Property-based Method for Knowledge Graph Alignment and Extension",
      "title_zh": "翻译失败",
      "authors": [
        "Daqian Shi",
        "Xiaoyue Li",
        "Fausto Giunchiglia"
      ],
      "abstract": "A common solution to the semantic heterogeneity problem is to perform\nknowledge graph (KG) extension exploiting the information encoded in one or\nmore candidate KGs, where the alignment between the reference KG and candidate\nKGs is considered the critical procedure. However, existing KG alignment\nmethods mainly rely on entity type (etype) label matching as a prerequisite,\nwhich is poorly performing in practice or not applicable in some cases. In this\npaper, we design a machine learning-based framework for KG extension, including\nan alternative novel property-based alignment approach that allows aligning\netypes on the basis of the properties used to define them. The main intuition\nis that it is properties that intentionally define the etype, and this\ndefinition is independent of the specific label used to name an etype, and of\nthe specific hierarchical schema of KGs. Compared with the state-of-the-art,\nthe experimental results show the validity of the KG alignment approach and the\nsuperiority of the proposed KG extension framework, both quantitatively and\nqualitatively.",
      "tldr_zh": "本研究针对知识图谱（KG）的语义异质性问题，提出了一种基于属性的方法KAE，用于KG对齐和扩展，该框架采用机器学习技术，避免依赖实体类型（etype）标签匹配的局限性。KAE的核心直觉是，通过属性来定义etype，从而实现独立于具体标签和KG层次结构的对齐。实验结果显示，该方法在定量和定性上优于现有状态-of-the-art方法，证明了其有效性和框架的整体优势。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2405.02463",
      "pdf_url": "http://arxiv.org/pdf/2407.05320v1",
      "published_date": "2024-07-07 10:17:03 UTC",
      "updated_date": "2024-07-07 10:17:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:21:27.504400"
    },
    {
      "arxiv_id": "2407.14525v1",
      "title": "Morse Code-Enabled Speech Recognition for Individuals with Visual and Hearing Impairments",
      "title_zh": "翻译失败",
      "authors": [
        "Ritabrata Roy Choudhury"
      ],
      "abstract": "The proposed model aims to develop a speech recognition technology for\nhearing, speech, or cognitively disabled people. All the available technology\nin the field of speech recognition doesn't come with an interface for\ncommunication for people with hearing, speech, or cognitive disabilities. The\nproposed model proposes the speech from the user, is transmitted to the speech\nrecognition layer where it is converted into text and then that text is then\ntransmitted to the morse code conversion layer where the morse code of the\ncorresponding speech is given as the output. The accuracy of the model is\ncompletely dependent on speech recognition, as the morse code conversion is a\nprocess. The model is tested with recorded audio files with different\nparameters. The proposed model's WER and accuracy are both determined to be\n10.18% and 89.82%, respectively.",
      "tldr_zh": "该研究提出了一种基于摩尔斯码的语音识别模型，旨在为有听力、言语或认知障碍的人提供通信接口，以解决现有语音识别技术缺乏针对性支持的问题。模型首先将用户语音转换为文本，然后再将文本转化为对应的摩尔斯码输出，整个过程依赖于语音识别的准确性。在测试中使用录制音频文件后，该模型的 WER 为 10.18%，准确率达到 89.82%，展示了其在辅助残障人士通信方面的潜力。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.SD",
      "comment": "10 pages, 11 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2407.14525v1",
      "published_date": "2024-07-07 09:54:29 UTC",
      "updated_date": "2024-07-07 09:54:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:21:39.366518"
    },
    {
      "arxiv_id": "2407.06230v1",
      "title": "Predicting Word Similarity in Context with Referential Translation Machines",
      "title_zh": "翻译失败",
      "authors": [
        "Ergun Biçici"
      ],
      "abstract": "We identify the similarity between two words in English by casting the task\nas machine translation performance prediction (MTPP) between the words given\nthe context and the distance between their similarities. We use referential\ntranslation machines (RTMs), which allows a common representation for training\nand test sets and stacked machine learning models. RTMs can achieve the top\nresults in Graded Word Similarity in Context (GWSC) task.",
      "tldr_zh": "这篇论文提出了一种新方法，通过机器翻译性能预测 (MTPP) 来评估英语单词在上下文中的相似度，将任务转化为单词间翻译距离的计算。论文使用 Referential Translation Machines (RTMs)，该框架允许训练和测试集共享共同表示，并结合堆叠机器学习模型来提升预测准确性。在 Graded Word Similarity in Context (GWSC) 任务中，RTMs 取得了顶级结果，展示了其在单词相似度预测方面的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages, 3 figures, 8 tables. arXiv admin note: substantial text\n  overlap with arXiv:2407.05154",
      "pdf_url": "http://arxiv.org/pdf/2407.06230v1",
      "published_date": "2024-07-07 09:36:41 UTC",
      "updated_date": "2024-07-07 09:36:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:21:51.951132"
    },
    {
      "arxiv_id": "2407.15320v2",
      "title": "Edge Graph Intelligence: Reciprocally Empowering Edge Networks with Graph Intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Liekang Zeng",
        "Shengyuan Ye",
        "Xu Chen",
        "Xiaoxi Zhang",
        "Ju Ren",
        "Jian Tang",
        "Yang Yang",
        "Xuemin",
        "Shen"
      ],
      "abstract": "Recent years have witnessed a thriving growth of computing facilities\nconnected at the network edge, cultivating edge networks as a fundamental\ninfrastructure for supporting miscellaneous intelligent services.Meanwhile,\nArtificial Intelligence (AI) frontiers have extrapolated to the graph domain\nand promoted Graph Intelligence (GI). Given the inherent relation between\ngraphs and networks, the interdiscipline of graph learning and edge networks,\ni.e., Edge GI or EGI, has revealed a novel interplay between them -- GI aids in\noptimizing edge networks, while edge networks facilitate GI model deployment.\nDriven by this delicate closed-loop, EGI is recognized as a promising solution\nto fully unleash the potential of edge computing power and is garnering growing\nattention. Nevertheless, research on EGI remains nascent, and there is a\nsoaring demand within both the communications and AI communities for a\ndedicated venue to share recent advancements. To this end, this paper promotes\nthe concept of EGI, explores its scope and core principles, and conducts a\ncomprehensive survey concerning recent research efforts on this emerging field.\nSpecifically, this paper introduces and discusses: 1) fundamentals of edge\ncomputing and graph learning,2) emerging techniques centering on the closed\nloop between graph intelligence and edge networks, and 3) open challenges and\nresearch opportunities of future EGI. By bridging the gap across communication,\nnetworking, and graph learning areas, we believe that this survey can garner\nincreased attention, foster meaningful discussions, and inspire further\nresearch ideas in EGI.",
      "tldr_zh": "该论文介绍了Edge Graph Intelligence (EGI)，一种通过图智能(Graph Intelligence)与边缘网络(Edge Networks)相互赋能的创新框架，旨在优化边缘计算能力和部署。论文首先回顾了边缘计算和图学习的 fundamentals，然后探讨了围绕GI和边缘网络的闭环技术，如GI在优化网络方面的应用以及边缘网络在GI模型部署中的作用。最终，论文总结了EGI的开放挑战和研究机会，旨在桥接通信、网络和图学习领域，促进进一步的创新和发展。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG",
        "cs.NI"
      ],
      "primary_category": "cs.DC",
      "comment": "Accepted by IEEE Communications Surveys & Tutorials",
      "pdf_url": "http://arxiv.org/pdf/2407.15320v2",
      "published_date": "2024-07-07 09:25:52 UTC",
      "updated_date": "2025-01-07 06:39:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:22:03.266818"
    },
    {
      "arxiv_id": "2407.05305v2",
      "title": "MINDECHO: Role-Playing Language Agents for Key Opinion Leaders",
      "title_zh": "翻译失败",
      "authors": [
        "Rui Xu",
        "Dakuan Lu",
        "Xiaoyu Tan",
        "Xintao Wang",
        "Siyu Yuan",
        "Jiangjie Chen",
        "Wei Chu",
        "Yinghui Xu"
      ],
      "abstract": "Large language models~(LLMs) have demonstrated impressive performance in\nvarious applications, among which role-playing language agents (RPLAs) have\nengaged a broad user base. Now, there is a growing demand for RPLAs that\nrepresent Key Opinion Leaders (KOLs), \\ie, Internet celebrities who shape the\ntrends and opinions in their domains. However, research in this line remains\nunderexplored. In this paper, we hence introduce MINDECHO, a comprehensive\nframework for the development and evaluation of KOL RPLAs. MINDECHO collects\nKOL data from Internet video transcripts in various professional fields, and\nsynthesizes their conversations leveraging GPT-4. Then, the conversations and\nthe transcripts are used for individualized model training and inference-time\nretrieval, respectively. Our evaluation covers both general dimensions (\\ie,\nknowledge and tones) and fan-centric dimensions for KOLs. Extensive experiments\nvalidate the effectiveness of MINDECHO in developing and evaluating KOL RPLAs.",
      "tldr_zh": "这篇论文引入了 MINDECHO 框架，用于开发和评估代表 Key Opinion Leaders (KOLs) 的角色扮演语言代理 (RPLAs)，以满足用户对这些互联网名人风格代理的需求。框架通过从互联网视频转录中收集 KOL 数据，并利用 GPT-4 合成对话，实现个性化模型训练和推理时的检索增强。实验结果显示，MINDECHO 在知识、语气等一般维度以及粉丝中心维度上表现出色，验证了其在构建 KOL RPLAs 方面的有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05305v2",
      "published_date": "2024-07-07 09:08:33 UTC",
      "updated_date": "2024-10-09 07:19:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:22:17.256911"
    },
    {
      "arxiv_id": "2407.05291v2",
      "title": "WorkArena++: Towards Compositional Planning and Reasoning-based Common Knowledge Work Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Léo Boisvert",
        "Megh Thakkar",
        "Maxime Gasse",
        "Massimo Caccia",
        "Thibault Le Sellier De Chezelles",
        "Quentin Cappart",
        "Nicolas Chapados",
        "Alexandre Lacoste",
        "Alexandre Drouin"
      ],
      "abstract": "The ability of large language models (LLMs) to mimic human-like intelligence\nhas led to a surge in LLM-based autonomous agents. Though recent LLMs seem\ncapable of planning and reasoning given user instructions, their effectiveness\nin applying these capabilities for autonomous task solving remains\nunderexplored. This is especially true in enterprise settings, where automated\nagents hold the promise of a high impact. To fill this gap, we propose\nWorkArena++, a novel benchmark consisting of 682 tasks corresponding to\nrealistic workflows routinely performed by knowledge workers. WorkArena++ is\ndesigned to evaluate the planning, problem-solving, logical/arithmetic\nreasoning, retrieval, and contextual understanding abilities of web agents. Our\nempirical studies across state-of-the-art LLMs and vision-language models\n(VLMs), as well as human workers, reveal several challenges for such models to\nserve as useful assistants in the workplace. In addition to the benchmark, we\nprovide a mechanism to effortlessly generate thousands of ground-truth\nobservation/action traces, which can be used for fine-tuning existing models.\nOverall, we expect this work to serve as a useful resource to help the\ncommunity progress toward capable autonomous agents. The benchmark can be found\nat https://github.com/ServiceNow/WorkArena.",
      "tldr_zh": "本研究提出WorkArena++，一个包含682个任务的基准，用于评估大型语言模型(LLMs)和视觉语言模型(VLMs)处理知识工作者日常工作流程的能力，包括规划、问题解决、逻辑/算术推理、检索和上下文理解。实验结果显示，这些模型在工作场所作为自主代理时面临显著挑战，与人类工作者相比表现欠佳。该基准还提供生成数千个地面实况观察/动作轨迹的机制，以支持模型微调，并旨在推动社区开发更可靠的自主代理。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05291v2",
      "published_date": "2024-07-07 07:15:49 UTC",
      "updated_date": "2025-02-05 21:50:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:22:28.112695"
    },
    {
      "arxiv_id": "2407.05285v4",
      "title": "Mjolnir: Breaking the Shield of Perturbation-Protected Gradients via Adaptive Diffusion",
      "title_zh": "翻译失败",
      "authors": [
        "Xuan Liu",
        "Siqi Cai",
        "Qihua Zhou",
        "Song Guo",
        "Ruibin Li",
        "Kaiwei Lin"
      ],
      "abstract": "Perturbation-based mechanisms, such as differential privacy, mitigate\ngradient leakage attacks by introducing noise into the gradients, thereby\npreventing attackers from reconstructing clients' private data from the leaked\ngradients. However, can gradient perturbation protection mechanisms truly\ndefend against all gradient leakage attacks? In this paper, we present the\nfirst attempt to break the shield of gradient perturbation protection in\nFederated Learning for the extraction of private information. We focus on\ncommon noise distributions, specifically Gaussian and Laplace, and apply our\napproach to DNN and CNN models. We introduce Mjolnir, a perturbation-resilient\ngradient leakage attack that is capable of removing perturbations from\ngradients without requiring additional access to the original model structure\nor external data. Specifically, we leverage the inherent diffusion properties\nof gradient perturbation protection to develop a novel diffusion-based gradient\ndenoising model for Mjolnir. By constructing a surrogate client model that\ncaptures the structure of perturbed gradients, we obtain crucial gradient data\nfor training the diffusion model. We further utilize the insight that\nmonitoring disturbance levels during the reverse diffusion process can enhance\ngradient denoising capabilities, allowing Mjolnir to generate gradients that\nclosely approximate the original, unperturbed versions through adaptive\nsampling steps. Extensive experiments demonstrate that Mjolnir effectively\nrecovers the protected gradients and exposes the Federated Learning process to\nthe threat of gradient leakage, achieving superior performance in gradient\ndenoising and private data recovery.",
      "tldr_zh": "该论文质疑了基于扰动机制（如 differential privacy）的梯度保护是否能有效防御 gradient leakage attacks，在 Federated Learning 中引入噪声以防止攻击者重建私有数据。研究提出 Mjolnir，一种新型的扰动弹性攻击方法，通过自适应扩散模型移除梯度中的噪声，而无需额外访问模型结构或外部数据。具体而言，Mjolnir 利用梯度扰动的扩散特性，构建代理客户端模型并优化反向扩散过程，实现对 Gaussian 和 Laplace 噪声分布的精确去噪。实验结果显示，Mjolnir 在 DNN 和 CNN 模型上显著提升了梯度恢复和私有数据提取性能，暴露了联邦学习的安全隐患。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2407.05285v4",
      "published_date": "2024-07-07 07:06:49 UTC",
      "updated_date": "2025-01-06 14:37:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:22:41.823771"
    },
    {
      "arxiv_id": "2408.00001v1",
      "title": "Replication in Visual Diffusion Models: A Survey and Outlook",
      "title_zh": "视觉扩散模型中的复制：综述与展望",
      "authors": [
        "Wenhao Wang",
        "Yifan Sun",
        "Zongxin Yang",
        "Zhengdong Hu",
        "Zhentao Tan",
        "Yi Yang"
      ],
      "abstract": "Visual diffusion models have revolutionized the field of creative AI,\nproducing high-quality and diverse content. However, they inevitably memorize\ntraining images or videos, subsequently replicating their concepts, content, or\nstyles during inference. This phenomenon raises significant concerns about\nprivacy, security, and copyright within generated outputs. In this survey, we\nprovide the first comprehensive review of replication in visual diffusion\nmodels, marking a novel contribution to the field by systematically\ncategorizing the existing studies into unveiling, understanding, and mitigating\nthis phenomenon. Specifically, unveiling mainly refers to the methods used to\ndetect replication instances. Understanding involves analyzing the underlying\nmechanisms and factors that contribute to this phenomenon. Mitigation focuses\non developing strategies to reduce or eliminate replication. Beyond these\naspects, we also review papers focusing on its real-world influence. For\ninstance, in the context of healthcare, replication is critically worrying due\nto privacy concerns related to patient data. Finally, the paper concludes with\na discussion of the ongoing challenges, such as the difficulty in detecting and\nbenchmarking replication, and outlines future directions including the\ndevelopment of more robust mitigation techniques. By synthesizing insights from\ndiverse studies, this paper aims to equip researchers and practitioners with a\ndeeper understanding at the intersection between AI technology and social good.\nWe release this project at\nhttps://github.com/WangWenhao0716/Awesome-Diffusion-Replication.",
      "tldr_zh": "这篇论文对视觉 diffusion models 中的 replication（复制现象）进行了首次全面调查，强调这些模型在生成高质量内容的同时，会记忆并复制训练数据，从而引发隐私、安全和版权问题。论文系统地将现有研究分类为 unveiling（揭示复制实例的方法）、understanding（分析导致复制的机制和因素）以及 mitigation（开发减少复制的策略），并审查其在现实世界的影响，如医疗保健中患者数据的隐私风险。最终，论文讨论了检测和基准测试的挑战，并概述未来方向，包括更 robust 的缓解技术，以促进 AI 技术与社会善的平衡。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CV",
      "comment": "The first survey focuses on replication in visual diffusion models.\n  This work has been submitted to the IEEE for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2408.00001v1",
      "published_date": "2024-07-07 06:39:16 UTC",
      "updated_date": "2024-07-07 06:39:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:22:54.576087"
    },
    {
      "arxiv_id": "2407.05268v1",
      "title": "Federated Knowledge Transfer Fine-tuning Large Server Model with Resource-Constrained IoT Clients",
      "title_zh": "翻译失败",
      "authors": [
        "Shaoyuan Chen",
        "Linlin You",
        "Rui Liu",
        "Shuo Yu",
        "Ahmed M. Abdelmoniem"
      ],
      "abstract": "The training of large models, involving fine-tuning, faces the scarcity of\nhigh-quality data. Compared to the solutions based on centralized data centers,\nupdating large models in the Internet of Things (IoT) faces challenges in\ncoordinating knowledge from distributed clients by using their private and\nheterogeneous data. To tackle such a challenge, we propose KOALA (Federated\nKnowledge Transfer Fine-tuning Large Server Model with Resource-Constrained IoT\nClients) to impel the training of large models in IoT. Since the resources\nobtained by IoT clients are limited and restricted, it is infeasible to locally\nexecute large models and also update them in a privacy-preserving manner.\nTherefore, we leverage federated learning and knowledge distillation to update\nlarge models through collaboration with their small models, which can run\nlocally at IoT clients to process their private data separately and enable\nlarge-small model knowledge transfer through iterative learning between the\nserver and clients. Moreover, to support clients with similar or different\ncomputing capacities, KOALA is designed with two kinds of large-small model\njoint learning modes, namely to be homogeneous or heterogeneous. Experimental\nresults demonstrate that compared to the conventional approach, our method can\nnot only achieve similar training performance but also significantly reduce the\nneed for local storage and computing power resources.",
      "tldr_zh": "该研究提出了一种名为 KOALA 的框架，用于在资源受限的 IoT 客户端上进行联邦知识转移（Federated Knowledge Transfer），以微调大型服务器模型。该框架通过结合联邦学习（Federated Learning）和知识蒸馏（Knowledge Distillation），让客户端运行小型模型处理私有异构数据，并通过服务器与客户端之间的迭代学习实现知识转移，从而解决分布式数据协调的挑战。KOALA 支持同质（Homogeneous）和异质（Heterogeneous）学习模式，以适应不同客户端的计算能力。实验结果显示，该方法不仅能实现与传统方法相似的训练性能，还显著降低了本地存储和计算资源需求。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05268v1",
      "published_date": "2024-07-07 05:46:01 UTC",
      "updated_date": "2024-07-07 05:46:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:23:05.741335"
    },
    {
      "arxiv_id": "2407.05266v2",
      "title": "CLAMP-ViT: Contrastive Data-Free Learning for Adaptive Post-Training Quantization of ViTs",
      "title_zh": "翻译失败",
      "authors": [
        "Akshat Ramachandran",
        "Souvik Kundu",
        "Tushar Krishna"
      ],
      "abstract": "We present CLAMP-ViT, a data-free post-training quantization method for\nvision transformers (ViTs). We identify the limitations of recent techniques,\nnotably their inability to leverage meaningful inter-patch relationships,\nleading to the generation of simplistic and semantically vague data, impacting\nquantization accuracy. CLAMP-ViT employs a two-stage approach, cyclically\nadapting between data generation and model quantization. Specifically, we\nincorporate a patch-level contrastive learning scheme to generate richer,\nsemantically meaningful data. Furthermore, we leverage contrastive learning in\nlayer-wise evolutionary search for fixed- and mixed-precision quantization to\nidentify optimal quantization parameters while mitigating the effects of a\nnon-smooth loss landscape. Extensive evaluations across various vision tasks\ndemonstrate the superiority of CLAMP-ViT, with performance improvements of up\nto 3% in top-1 accuracy for classification, 0.6 mAP for object detection, and\n1.5 mIoU for segmentation at similar or better compression ratio over existing\nalternatives. Code is available at\nhttps://github.com/georgia-tech-synergy-lab/CLAMP-ViT.git",
      "tldr_zh": "本文提出 CLAMP-ViT，一种基于对比学习（contrastive learning）的无数据后训练量化方法，针对视觉Transformer (ViTs) 的量化问题，解决了现有技术在利用patch间关系方面存在的局限性，导致数据生成简单且语义模糊。CLAMP-ViT 采用两阶段循环适应策略，包括patch-level contrastive learning 生成更丰富的语义数据，以及在层级进化搜索中应用contrastive learning 来优化固定和混合精度量化参数，从而缓解非平滑损失景观的影响。实验评估显示，该方法在各种视觉任务上表现出色，与现有方法相比，分类任务的top-1准确率提高多达3%，物体检测的mAP提高0.6，分割的mIoU提高1.5，同时保持或改善压缩比。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.05266v2",
      "published_date": "2024-07-07 05:39:25 UTC",
      "updated_date": "2024-09-09 00:08:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:23:20.119739"
    },
    {
      "arxiv_id": "2407.05262v2",
      "title": "FastSpiker: Enabling Fast Training for Spiking Neural Networks on Event-based Data through Learning Rate Enhancements for Autonomous Embedded Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Iqra Bano",
        "Rachmad Vidya Wicaksana Putra",
        "Alberto Marchisio",
        "Muhammad Shafique"
      ],
      "abstract": "Autonomous embedded systems (e.g., robots) typically necessitate intelligent\ncomputation with low power/energy processing for completing their tasks. Such\nrequirements can be fulfilled by embodied neuromorphic intelligence with\nspiking neural networks (SNNs) because of their high learning quality (e.g.,\naccuracy) and sparse computation. Here, the employment of event-based data is\npreferred to ensure seamless connectivity between input and processing parts.\nHowever, state-of-the-art SNNs still face a long training time to achieve high\naccuracy, thereby incurring high energy consumption and producing a high rate\nof carbon emission. Toward this, we propose FastSpiker, a novel methodology\nthat enables fast SNN training on event-based data through learning rate\nenhancements targeting autonomous embedded systems. In FastSpiker, we first\ninvestigate the impact of different learning rate policies and their values,\nthen select the ones that quickly offer high accuracy. Afterward, we explore\ndifferent settings for the selected learning rate policies to find the\nappropriate policies through a statistical-based decision. Experimental results\nshow that our FastSpiker offers up to 10.5x faster training time and up to\n88.39% lower carbon emission to achieve higher or comparable accuracy to the\nstate-of-the-art on the event-based automotive dataset (i.e., NCARS). In this\nmanner, our FastSpiker methodology paves the way for green and sustainable\ncomputing in realizing embodied neuromorphic intelligence for autonomous\nembedded systems.",
      "tldr_zh": "该研究针对自主嵌入式系统（如机器人）的低功耗需求，提出FastSpiker方法，以加速Spiking Neural Networks (SNNs)在事件-based数据上的训练，从而减少能耗和碳排放。FastSpiker首先评估不同学习率策略及其值，选择快速实现高准确率的选项，然后通过统计决策优化这些策略的设置。实验结果显示，该方法在NCARS数据集上训练时间缩短高达10.5倍，碳排放降低88.39%，同时实现与现有技术相当或更高的准确率。这种创新为绿色可持续计算铺平道路，促进神经形态智能在自主嵌入式系统中的应用。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.NE",
      "comment": "To appear at the 18th International Conference on Control,\n  Automation, Robotics and Vision (ICARCV), December 2024, Dubai, UAE",
      "pdf_url": "http://arxiv.org/pdf/2407.05262v2",
      "published_date": "2024-07-07 05:17:17 UTC",
      "updated_date": "2024-09-12 18:28:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:23:31.392860"
    },
    {
      "arxiv_id": "2407.05259v1",
      "title": "Multi-scale Conditional Generative Modeling for Microscopic Image Restoration",
      "title_zh": "翻译失败",
      "authors": [
        "Luzhe Huang",
        "Xiongye Xiao",
        "Shixuan Li",
        "Jiawen Sun",
        "Yi Huang",
        "Aydogan Ozcan",
        "Paul Bogdan"
      ],
      "abstract": "The advance of diffusion-based generative models in recent years has\nrevolutionized state-of-the-art (SOTA) techniques in a wide variety of image\nanalysis and synthesis tasks, whereas their adaptation on image restoration,\nparticularly within computational microscopy remains theoretically and\nempirically underexplored. In this research, we introduce a multi-scale\ngenerative model that enhances conditional image restoration through a novel\nexploitation of the Brownian Bridge process within wavelet domain. By\ninitiating the Brownian Bridge diffusion process specifically at the\nlowest-frequency subband and applying generative adversarial networks at\nsubsequent multi-scale high-frequency subbands in the wavelet domain, our\nmethod provides significant acceleration during training and sampling while\nsustaining a high image generation quality and diversity on par with SOTA\ndiffusion models. Experimental results on various computational microscopy and\nimaging tasks confirm our method's robust performance and its considerable\nreduction in its sampling steps and time. This pioneering technique offers an\nefficient image restoration framework that harmonizes efficiency with quality,\nsignifying a major stride in incorporating cutting-edge generative models into\ncomputational microscopy workflows.",
      "tldr_zh": "这篇论文提出了一种多尺度条件生成模型，用于显微镜图像修复，旨在解决扩散模型(diffusion-based generative models)在计算显微镜领域的应用不足问题。该模型通过在小波域(wavelet domain)利用 Brownian Bridge 过程从最低频率子带启动扩散，并在后续高频率子带应用生成对抗网络(GANs)，实现了训练和采样的显著加速，同时保持了与 SOTA diffusion models 相当的图像生成质量和多样性。实验结果证实，该方法在各种计算显微镜任务中表现出色，大大减少了采样步骤和时间，为高效整合先进生成模型到显微镜工作流中提供了重要进展。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05259v1",
      "published_date": "2024-07-07 05:11:00 UTC",
      "updated_date": "2024-07-07 05:11:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:23:42.633561"
    },
    {
      "arxiv_id": "2407.05257v1",
      "title": "OvSW: Overcoming Silent Weights for Accurate Binary Neural Networks",
      "title_zh": "OvSW：克服沉默权重以实现准确的二进制神经网络",
      "authors": [
        "Jingyang Xiang",
        "Zuohui Chen",
        "Siqi Li",
        "Qing Wu",
        "Yong Liu"
      ],
      "abstract": "Binary Neural Networks~(BNNs) have been proven to be highly effective for\ndeploying deep neural networks on mobile and embedded platforms. Most existing\nworks focus on minimizing quantization errors, improving representation\nability, or designing gradient approximations to alleviate gradient mismatch in\nBNNs, while leaving the weight sign flipping, a critical factor for achieving\npowerful BNNs, untouched. In this paper, we investigate the efficiency of\nweight sign updates in BNNs. We observe that, for vanilla BNNs, over 50\\% of\nthe weights remain their signs unchanged during training, and these weights are\nnot only distributed at the tails of the weight distribution but also\nuniversally present in the vicinity of zero. We refer to these weights as\n``silent weights'', which slow down convergence and lead to a significant\naccuracy degradation. Theoretically, we reveal this is due to the independence\nof the BNNs gradient from the latent weight distribution. To address the issue,\nwe propose Overcome Silent Weights~(OvSW). OvSW first employs Adaptive Gradient\nScaling~(AGS) to establish a relationship between the gradient and the latent\nweight distribution, thereby improving the overall efficiency of weight sign\nupdates. Additionally, we design Silence Awareness Decaying~(SAD) to\nautomatically identify ``silent weights'' by tracking weight flipping state,\nand apply an additional penalty to ``silent weights'' to facilitate their\nflipping. By efficiently updating weight signs, our method achieves faster\nconvergence and state-of-the-art performance on CIFAR10 and ImageNet1K dataset\nwith various architectures. For example, OvSW obtains 61.6\\% and 65.5\\% top-1\naccuracy on the ImageNet1K using binarized ResNet18 and ResNet34 architecture\nrespectively. Codes are available at\n\\url{https://github.com/JingyangXiang/OvSW}.",
      "tldr_zh": "该研究针对Binary Neural Networks (BNNs)中“silent weights”问题，即超过50%的权重在训练中保持符号不变，导致收敛缓慢和准确率下降，进行了深入分析。作者提出OvSW方法，包括Adaptive Gradient Scaling (AGS)来建立梯度与潜在权重分布的关系，提高权重符号更新效率，以及Silence Awareness Decaying (SAD)通过跟踪权重翻转状态并施加额外惩罚，促进silent weights的翻转。实验结果显示，OvSW在CIFAR10和ImageNet1K数据集上实现了更快收敛和最先进性能，例如在ImageNet1K上，使用二值化ResNet18和ResNet34分别达到61.6%和65.5%的top-1准确率。该方法为提升BNNs的部署效率和准确性提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by the 18th European Conference on Computer Vision (ECCV\n  2024)",
      "pdf_url": "http://arxiv.org/pdf/2407.05257v1",
      "published_date": "2024-07-07 05:01:20 UTC",
      "updated_date": "2024-07-07 05:01:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:23:55.346985"
    },
    {
      "arxiv_id": "2407.05256v2",
      "title": "Unlocking Textual and Visual Wisdom: Open-Vocabulary 3D Object Detection Enhanced by Comprehensive Guidance from Text and Image",
      "title_zh": "翻译失败",
      "authors": [
        "Pengkun Jiao",
        "Na Zhao",
        "Jingjing Chen",
        "Yu-Gang Jiang"
      ],
      "abstract": "Open-vocabulary 3D object detection (OV-3DDet) aims to localize and recognize\nboth seen and previously unseen object categories within any new 3D scene.\nWhile language and vision foundation models have achieved success in handling\nvarious open-vocabulary tasks with abundant training data, OV-3DDet faces a\nsignificant challenge due to the limited availability of training data.\nAlthough some pioneering efforts have integrated vision-language models (VLM)\nknowledge into OV-3DDet learning, the full potential of these foundational\nmodels has yet to be fully exploited. In this paper, we unlock the textual and\nvisual wisdom to tackle the open-vocabulary 3D detection task by leveraging the\nlanguage and vision foundation models. We leverage a vision foundation model to\nprovide image-wise guidance for discovering novel classes in 3D scenes.\nSpecifically, we utilize a object detection vision foundation model to enable\nthe zero-shot discovery of objects in images, which serves as the initial seeds\nand filtering guidance to identify novel 3D objects. Additionally, to align the\n3D space with the powerful vision-language space, we introduce a hierarchical\nalignment approach, where the 3D feature space is aligned with the\nvision-language feature space using a pre-trained VLM at the instance,\ncategory, and scene levels. Through extensive experimentation, we demonstrate\nsignificant improvements in accuracy and generalization, highlighting the\npotential of foundation models in advancing open-vocabulary 3D object detection\nin real-world scenarios.",
      "tldr_zh": "本文提出一种增强 Open-Vocabulary 3D Object Detection (OV-3DDet) 的方法，通过整合语言和视觉 foundation models 来解决训练数据有限的挑战。方法包括利用视觉 foundation model 进行图像级零-shot 对象发现，作为识别 3D 场景中新型对象的初始种子和过滤指导；同时，引入 hierarchical alignment approach，将 3D 特征空间与预训练的 vision-language model (VLM) 特征空间在实例、类别和场景级别对齐。实验结果显示，该框架显著提高了检测准确性和泛化能力，证明了 foundation models 在真实世界 3D 对象检测中的巨大潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ECCV2024",
      "pdf_url": "http://arxiv.org/pdf/2407.05256v2",
      "published_date": "2024-07-07 04:50:04 UTC",
      "updated_date": "2024-07-17 16:50:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:24:07.077801"
    },
    {
      "arxiv_id": "2407.05244v1",
      "title": "Some Issues in Predictive Ethics Modeling: An Annotated Contrast Set of \"Moral Stories\"",
      "title_zh": "翻译失败",
      "authors": [
        "Ben Fitzgerald"
      ],
      "abstract": "Models like Delphi have been able to label ethical dilemmas as moral or\nimmoral with astonishing accuracy. This paper challenges accuracy as a holistic\nmetric for ethics modeling by identifying issues with translating moral\ndilemmas into text-based input. It demonstrates these issues with contrast sets\nthat substantially reduce the performance of classifiers trained on the dataset\nMoral Stories. Ultimately, we obtain concrete estimates for how much specific\nforms of data misrepresentation harm classifier accuracy. Specifically,\nlabel-changing tweaks to the descriptive content of a situation (as small as\n3-5 words) can reduce classifier accuracy to as low as 51%, almost half the\ninitial accuracy of 99.8%. Associating situations with a misleading social norm\nlowers accuracy to 98.8%, while adding textual bias (i.e. an implication that a\nsituation already fits a certain label) lowers accuracy to 77%.\n  These results suggest not only that many ethics models have substantially\noverfit, but that several precautions are required to ensure that input\naccurately captures a moral dilemma. This paper recommends re-examining the\nstructure of a social norm, training models to ask for context with defeasible\nreasoning, and filtering input for textual bias. Doing so not only gives us the\nfirst concrete estimates of the average cost to accuracy of misrepresenting\nethics data, but gives researchers practical tips for considering these\nestimates in research.",
      "tldr_zh": "这篇论文质疑了像 Delphi 这样的道德建模模型在分类道德困境时的准确性，指出将道德困境转化为文本输入存在问题，可能导致模型过度拟合。作者通过创建注释对比集（annotated contrast sets）来测试这些问题，结果显示：对情境描述的小改动（如3-5个词）可将分类器准确率降至51%，与误导性社会规范关联时准确率降至98.8%，添加文本偏差时降至77%。论文提供了道德数据误表示对准确性的首次具体估计，并建议重新审视社会规范结构、训练模型使用 defeasible reasoning 请求上下文，以及过滤文本偏差，以改进道德建模的鲁棒性。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "This project was a runner-up to the Novel Research prize for the\n  BlueDot Impact course AI Safety Fundamentals. View my contrast set as JSONL,\n  the UI used to generate it, and Emelin et. al.\"s initial paper and code at\n  https://github.com/bfitzgerald3132/MoralStoriesContrastSet",
      "pdf_url": "http://arxiv.org/pdf/2407.05244v1",
      "published_date": "2024-07-07 03:22:49 UTC",
      "updated_date": "2024-07-07 03:22:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:24:18.891053"
    },
    {
      "arxiv_id": "2407.05233v1",
      "title": "Advancing Prompt Recovery in NLP: A Deep Dive into the Integration of Gemma-2b-it and Phi2 Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jianlong Chen",
        "Wei Xu",
        "Zhicheng Ding",
        "Jinxin Xu",
        "Hao Yan",
        "Xinyu Zhang"
      ],
      "abstract": "Prompt recovery, a crucial task in natural language processing, entails the\nreconstruction of prompts or instructions that language models use to convert\ninput text into a specific output. Although pivotal, the design and\neffectiveness of prompts represent a challenging and relatively untapped field\nwithin NLP research. This paper delves into an exhaustive investigation of\nprompt recovery methodologies, employing a spectrum of pre-trained language\nmodels and strategies. Our study is a comparative analysis aimed at gauging the\nefficacy of various models on a benchmark dataset, with the goal of pinpointing\nthe most proficient approach for prompt recovery. Through meticulous\nexperimentation and detailed analysis, we elucidate the outstanding performance\nof the Gemma-2b-it + Phi2 model + Pretrain. This model surpasses its\ncounterparts, showcasing its exceptional capability in accurately\nreconstructing prompts for text transformation tasks. Our findings offer a\nsignificant contribution to the existing knowledge on prompt recovery, shedding\nlight on the intricacies of prompt design and offering insightful perspectives\nfor future innovations in text rewriting and the broader field of natural\nlanguage processing.",
      "tldr_zh": "该论文探讨了自然语言处理（NLP）中的提示恢复（Prompt Recovery）任务，即重建语言模型用于将输入文本转换为特定输出的提示。研究通过比较多种预训练模型和策略，在基准数据集上进行详尽实验，评估了它们的有效性。结果表明，Gemma-2b-it + Phi2 模型 + Pretrain 组合表现出色，显著提高了提示重建的准确性。该发现为提示设计提供了关键见解，并为文本重写和 NLP 领域的未来创新奠定了基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.05233v1",
      "published_date": "2024-07-07 02:15:26 UTC",
      "updated_date": "2024-07-07 02:15:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T04:24:30.437105"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 59,
  "processed_papers_count": 59,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-19T04:24:50.659633"
}