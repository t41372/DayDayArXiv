{
  "date": "2024-09-01",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-09-01 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 在医疗、交通、金融和图像处理等领域的创新应用，强调模型的鲁棒性、可解释性和安全性改进，其中 LLM 在对抗攻击和知识融合方面的研究（如 Harnessing the Power of Semi-Structured Knowledge and LLMs）及医疗图像生成（如 Diffusion based multi-domain neuroimaging harmonization）最为令人印象深刻，同时涉及知名学者如 Arthur W. Toga 和 Philip S. Yu 的工作。\n\n以下是今日论文的精选摘要，我优先讨论具有话题度、学术影响或实际应用潜力的文章，并快速掠过较常规或低影响力的内容。每个条目列出论文标题（中文 + 英文），并简要概述主要贡献和发现。\n\n### 重点论文讨论\n\n**1. 公平的皮肤病预测使用迁移学习和领域适应 (Equitable Skin Disease Prediction Using Transfer Learning and Domain Adaptation)**  \n这篇论文提出了一种迁移学习方法，使用多种预训练模型（如 Med-ViT）来改善皮肤病诊断，尤其针对不同肤色（如黑暗肤色）的鲁棒性。通过 DDI 数据集评估，发现 Med-ViT 在领域适应后显著提升了预测准确性，主要贡献在于解决 AI 在皮肤病诊断中的偏见问题。\n\n**2. 利用半结构化知识和 LLM 的三元组预过滤进行问答 (Harnessing the Power of Semi-Structured Knowledge and LLMs with Triplet-Based Prefiltering for Question Answering)**  \n由 Stefan Kramer 等学者主导，这篇论文引入 4StepFocus 管道，使用 LLM 生成三元组来缩小知识图谱中的候选答案，结合向量相似性搜索提升问答性能。在医疗和推荐任务上实验显示，该方法优于传统 RAG 框架，主要发现是它能减少 LLM 的幻觉并提供可追溯的解释。\n\n**3. 基于物理增强的强化学习与人类反馈的安全自动驾驶 (Trustworthy Human-AI Collaboration: Reinforcement Learning with Human Feedback and Physics Knowledge for Safe Autonomous Driving)**  \n这篇论文提出 PE-RLHF 框架，将人类反馈和物理知识（如交通流模型）整合到强化学习中，确保政策至少不劣于基准策略。实验证明它在安全和泛化性上超越传统方法，主要贡献是提升自动驾驶的可靠性，即使人类反馈质量不佳。\n\n**4. 扩散模型在多领域神经影像协调中的应用 (Diffusion based multi-domain neuroimaging harmonization method with preservation of anatomical details)**  \n论文使用扩散概率模型协调多中心神经影像数据，解决传统 GAN 方法的伪影问题。通过 ADNI1 和 ABIDE II 数据集测试，显示它在保持解剖细节的同时显著降低 FID 分数，主要发现是它能处理多域数据而非仅限两域。\n\n**5. LLM 代码生成的基准测试在音频编程中的应用 (Benchmarking LLM Code Generation for Audio Programming with Visual Dataflow Languages)**  \n这篇论文评估 LLM 在视觉节点编程语言（如音频任务）中的代码生成性能，比较元编程和直接节点生成。发现元编程在语义正确性上更优，主要贡献是提供基准，帮助降低编程门槛。\n\n**6. LLM 偏好评估的新方法：报告卡 (Report Cards: Qualitative Evaluation of Language Models Using Natural Language Summaries)**  \n论文提出报告卡系统，使用自然语言总结评估 LLM 性能，基于特异性、忠实度和可解释性。实验显示它比传统基准更全面，主要发现是它能区分模型差异，提供更易懂的评估。\n\n**7. LLM 的人类反馈暗面：通过用户输入中毒模型 (The Dark Side of Human Feedback: Poisoning Large Language Models via User Inputs)**  \n这篇高话题度论文揭示 LLM 通过用户提示中毒的风险，提出两种机制（选择和生成）来操纵奖励反馈。贡献在于证明 1% 的恶意提示可使毒性增加一倍，强调了 LLM 训练的安全隐患。\n\n**8. 基于知识的神经网络在抑郁检测中的应用 (Deep Knowledge-Infusion For Explainable Depression Detection)**  \n论文使用知识注入神经网络（KiNN），结合领域本体和常识知识检测社交媒体抑郁。实验在 CLEF e-Risk 数据集上提升了 25% 的 MCC，主要发现是它提供用户级可解释性，优于黑盒模型。\n\n**9. 天气预报的卷积网络创新 (PuYun: Medium-Range Global Weather Forecasting Using Large Kernel Attention Convolutional Networks)**  \n这篇论文提出 PuYun 模型，使用大核注意力机制预测全球天气。PuYun-Short 在 10 天预测中降低 Z500 和 T2M 的 RMSE，主要贡献是提升中短期预报精度。\n\n快速掠过其他论文：  \n- **医疗领域其他**：如 BUET Multi-disease Heart Sound Dataset（贡献：发布心音数据集，提升心脏病诊断AI）；Multiscale Color Guided Attention Ensemble Classifier（贡献：多模态图像分类AMD，提高准确率）。  \n- **AI 安全和优化**：如 NoPhish（贡献：浏览器扩展检测网络钓鱼）；A Novel Self-Attention-Enabled Weighted Ensemble-Based CNN Framework（贡献：DDoS 攻击分类，提升精度）。  \n- **其他主题**：如 Simulation of Social Media-Driven Bubble Formation（贡献：代理模型模拟金融泡沫）；Sample-Efficient Diffusion for Text-To-Speech（贡献：高效语音合成）。这些论文虽有创新，但影响力较小，仅提及核心发现。\n\n总之，今天的 arXiv 论文展示了 AI 在实际应用中的潜力，特别是医疗和安全领域，但也提醒了模型漏洞。下次快报见！",
  "papers": [
    {
      "arxiv_id": "2409.00873v1",
      "title": "Equitable Skin Disease Prediction Using Transfer Learning and Domain Adaptation",
      "title_zh": "基于迁移学习和领域适应的公平皮肤病预测",
      "authors": [
        "Sajib Acharjee Dip",
        "Kazi Hasan Ibn Arif",
        "Uddip Acharjee Shuvo",
        "Ishtiaque Ahmed Khan",
        "Na Meng"
      ],
      "abstract": "In the realm of dermatology, the complexity of diagnosing skin conditions\nmanually necessitates the expertise of dermatologists. Accurate identification\nof various skin ailments, ranging from cancer to inflammatory diseases, is\nparamount. However, existing artificial intelligence (AI) models in dermatology\nface challenges, particularly in accurately diagnosing diseases across diverse\nskin tones, with a notable performance gap in darker skin. Additionally, the\nscarcity of publicly available, unbiased datasets hampers the development of\ninclusive AI diagnostic tools. To tackle the challenges in accurately\npredicting skin conditions across diverse skin tones, we employ a\ntransfer-learning approach that capitalizes on the rich, transferable knowledge\nfrom various image domains. Our method integrates multiple pre-trained models\nfrom a wide range of sources, including general and specific medical images, to\nimprove the robustness and inclusiveness of the skin condition predictions. We\nrigorously evaluated the effectiveness of these models using the Diverse\nDermatology Images (DDI) dataset, which uniquely encompasses both\nunderrepresented and common skin tones, making it an ideal benchmark for\nassessing our approach. Among all methods, Med-ViT emerged as the top performer\ndue to its comprehensive feature representation learned from diverse image\nsources. To further enhance performance, we conducted domain adaptation using\nadditional skin image datasets such as HAM10000. This adaptation significantly\nimproved model performance across all models.",
      "tldr_zh": "该研究针对皮肤病诊断中AI模型对不同肤色（尤其是深色皮肤）的性能差距问题，以及公开无偏数据集的稀缺性，提出了一种基于transfer learning的公平预测方法。该方法整合了多种来源的预训练模型，包括一般和医疗图像，以提升皮肤病预测的鲁棒性和包容性。在使用Diverse Dermatology Images (DDI)数据集进行评估时，Med-ViT模型表现出最佳性能；随后，通过domain adaptation整合HAM10000等数据集，进一步显著提高了所有模型的准确率。该方法为开发更具公平性的皮肤病诊断工具提供了重要进展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.00873v1",
      "published_date": "2024-09-01 23:48:26 UTC",
      "updated_date": "2024-09-01 23:48:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:23:40.105824"
    },
    {
      "arxiv_id": "2409.00861v1",
      "title": "Harnessing the Power of Semi-Structured Knowledge and LLMs with Triplet-Based Prefiltering for Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Derian Boer",
        "Fabian Koch",
        "Stefan Kramer"
      ],
      "abstract": "Large Language Models (LLMs) frequently lack domain-specific knowledge and\neven fine-tuned models tend to hallucinate. Hence, more reliable models that\ncan include external knowledge are needed. We present a pipeline, 4StepFocus,\nand specifically a preprocessing step, that can substantially improve the\nanswers of LLMs. This is achieved by providing guided access to external\nknowledge making use of the model's ability to capture relational context and\nconduct rudimentary reasoning by themselves. The method narrows down\npotentially correct answers by triplets-based searches in a semi-structured\nknowledge base in a direct, traceable fashion, before switching to latent\nrepresentations for ranking those candidates based on unstructured data. This\ndistinguishes it from related methods that are purely based on latent\nrepresentations. 4StepFocus consists of the steps: 1) Triplet generation for\nextraction of relational data by an LLM, 2) substitution of variables in those\ntriplets to narrow down answer candidates employing a knowledge graph, 3)\nsorting remaining candidates with a vector similarity search involving\nassociated non-structured data, 4) reranking the best candidates by the LLM\nwith background data provided. Experiments on a medical, a product\nrecommendation, and an academic paper search test set demonstrate that this\napproach is indeed a powerful augmentation. It not only adds relevant traceable\nbackground information from information retrieval, but also improves\nperformance considerably in comparison to state-of-the-art methods. This paper\npresents a novel, largely unexplored direction and therefore provides a wide\nrange of future work opportunities. Used source code is available at\nhttps://github.com/kramerlab/4StepFocus.",
      "tldr_zh": "该论文提出了一种名为 4StepFocus 的管道，利用半结构化知识和 LLMs，通过基于三元组(triplets-based)预过滤来提升问答系统的准确性和可靠性，解决 LLMs 缺乏领域知识和易产生幻觉的问题。方法包括四个步骤：1) LLM 生成三元组以提取关系数据，2) 在知识图谱中替换变量缩小答案候选，3) 使用向量相似性搜索排序候选结合非结构化数据，4) LLM 重新排名最佳候选并提供背景信息。与基于潜在表示的方法不同，该框架确保答案的可追溯性。在医疗、产品推荐和学术论文搜索数据集上的实验表明，4StepFocus 显著提高性能，比现有最先进方法更有效，并为未来研究提供新方向。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.LO"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, published at IJCLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.00861v1",
      "published_date": "2024-09-01 22:43:27 UTC",
      "updated_date": "2024-09-01 22:43:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:23:55.700476"
    },
    {
      "arxiv_id": "2409.02130v2",
      "title": "From Predictive Importance to Causality: Which Machine Learning Model Reflects Reality?",
      "title_zh": "从预测重要性到因果关系：哪种机器学习模型反映现实？",
      "authors": [
        "Muhammad Arbab Arshad",
        "Pallavi Kandanur",
        "Saurabh Sonawani",
        "Laiba Batool",
        "Muhammad Umar Habib"
      ],
      "abstract": "This study analyzes the Ames Housing Dataset using CatBoost and LightGBM\nmodels to explore feature importance and causal relationships in housing price\nprediction. We examine the correlation between SHAP values and EconML\npredictions, achieving high accuracy in price forecasting. Our analysis reveals\na moderate Spearman rank correlation of 0.48 between SHAP-based feature\nimportance and causally significant features, highlighting the complexity of\naligning predictive modeling with causal understanding in housing market\nanalysis. Through extensive causal analysis, including heterogeneity\nexploration and policy tree interpretation, we provide insights into how\nspecific features like porches impact housing prices across various scenarios.\nThis work underscores the need for integrated approaches that combine\npredictive power with causal insights in real estate valuation, offering\nvaluable guidance for stakeholders in the industry.",
      "tldr_zh": "这篇论文使用 CatBoost 和 LightGBM 模型分析 Ames Housing Dataset，探讨特征重要性和因果关系在房价预测中的关联，并检查 SHAP 值与 EconML 预测之间的相关性。研究发现，SHAP-based 特征重要性和因果显著特征间的 Spearman rank correlation 为 0.48，揭示了预测建模与因果理解在房地产市场分析中的复杂性。通过异质性探索和政策树解释，论文提供了具体见解，如 porches 等特征在不同场景下对房价的影响。最终，该工作强调了整合预测能力和因果洞见的必要性，为房地产估值领域的利益相关者提供指导。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.02130v2",
      "published_date": "2024-09-01 22:37:47 UTC",
      "updated_date": "2024-09-24 17:06:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:24:04.569544"
    },
    {
      "arxiv_id": "2409.09058v1",
      "title": "Redefining Data-Centric Design: A New Approach with a Domain Model and Core Data Ontology for Computational Systems",
      "title_zh": "翻译失败",
      "authors": [
        "William Johnson",
        "James Davis",
        "Tara Kelly"
      ],
      "abstract": "This paper presents an innovative data-centric paradigm for designing\ncomputational systems by introducing a new informatics domain model. The\nproposed model moves away from the conventional node-centric framework and\nfocuses on data-centric categorization, using a multimodal approach that\nincorporates objects, events, concepts, and actions. By drawing on\ninterdisciplinary research and establishing a foundational ontology based on\nthese core elements, the model promotes semantic consistency and secure data\nhandling across distributed ecosystems. We also explore the implementation of\nthis model as an OWL 2 ontology, discuss its potential applications, and\noutline its scalability and future directions for research. This work aims to\nserve as a foundational guide for system designers and data architects in\ndeveloping more secure, interoperable, and scalable data systems.",
      "tldr_zh": "这篇论文重新定义了数据中心设计，引入了一个新的信息学域模型和核心数据本体，用于计算系统设计。模型摒弃传统的节点中心框架，转向数据中心分类，采用多模态方法整合对象、事件、概念和动作，以提升语义一致性和安全数据处理。论文探讨了该模型的OWL 2本体实现、潜在应用以及可扩展性，为系统设计师和数据架构师提供指导，以构建更安全、可互操作和可扩展的数据系统。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.09058v1",
      "published_date": "2024-09-01 22:34:12 UTC",
      "updated_date": "2024-09-01 22:34:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:24:16.662042"
    },
    {
      "arxiv_id": "2409.00858v2",
      "title": "Trustworthy Human-AI Collaboration: Reinforcement Learning with Human Feedback and Physics Knowledge for Safe Autonomous Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Zilin Huang",
        "Zihao Sheng",
        "Sikai Chen"
      ],
      "abstract": "In the field of autonomous driving, developing safe and trustworthy\nautonomous driving policies remains a significant challenge. Recently,\nReinforcement Learning with Human Feedback (RLHF) has attracted substantial\nattention due to its potential to enhance training safety and sampling\nefficiency. Nevertheless, existing RLHF-enabled methods often falter when faced\nwith imperfect human demonstrations, potentially leading to training\noscillations or even worse performance than rule-based approaches. Inspired by\nthe human learning process, we propose Physics-enhanced Reinforcement Learning\nwith Human Feedback (PE-RLHF). This novel framework synergistically integrates\nhuman feedback (e.g., human intervention and demonstration) and physics\nknowledge (e.g., traffic flow model) into the training loop of reinforcement\nlearning. The key advantage of PE-RLHF is its guarantee that the learned policy\nwill perform at least as well as the given physics-based policy, even when\nhuman feedback quality deteriorates, thus ensuring trustworthy safety\nimprovements. PE-RLHF introduces a Physics-enhanced Human-AI (PE-HAI)\ncollaborative paradigm for dynamic action selection between human and\nphysics-based actions, employs a reward-free approach with a proxy value\nfunction to capture human preferences, and incorporates a minimal intervention\nmechanism to reduce the cognitive load on human mentors. Extensive experiments\nacross diverse driving scenarios demonstrate that PE-RLHF significantly\noutperforms traditional methods, achieving state-of-the-art (SOTA) performance\nin safety, efficiency, and generalizability, even with varying quality of human\nfeedback. The philosophy behind PE-RLHF not only advances autonomous driving\ntechnology but can also offer valuable insights for other safety-critical\ndomains. Demo video and code are available at:\n\\https://zilin-huang.github.io/PE-RLHF-website/",
      "tldr_zh": "该论文针对自动驾驶的安全挑战，提出了一种名为 Physics-enhanced Reinforcement Learning with Human Feedback (PE-RLHF) 的框架，通过整合人类反馈（如干预和演示）和物理知识（如交通流模型），来提升强化学习（RLHF）的可靠性和效率。PE-RLHF 引入 Physics-enhanced Human-AI (PE-HAI) 协作范式、reward-free 代理价值函数以及最小干预机制，确保即使人类反馈质量低下，学习策略也能至少与物理-based 策略相当，从而保障安全。实验结果显示，该方法在多种驾驶场景中显著优于传统方法，实现了 SOTA（State-of-the-Art）水平的安全、效率和泛化性能，并为其他安全关键领域提供宝贵启示。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "33 pages, 20 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.00858v2",
      "published_date": "2024-09-01 22:20:32 UTC",
      "updated_date": "2024-09-05 08:07:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:24:31.504794"
    },
    {
      "arxiv_id": "2409.00856v1",
      "title": "Benchmarking LLM Code Generation for Audio Programming with Visual Dataflow Languages",
      "title_zh": "翻译失败",
      "authors": [
        "William Zhang",
        "Maria Leon",
        "Ryan Xu",
        "Adrian Cardenas",
        "Amelia Wissink",
        "Hanna Martin",
        "Maya Srikanth",
        "Kaya Dorogi",
        "Christian Valadez",
        "Pedro Perez",
        "Citlalli Grijalva",
        "Corey Zhang",
        "Mark Santolucito"
      ],
      "abstract": "Node-based programming languages are increasingly popular in media arts\ncoding domains. These languages are designed to be accessible to users with\nlimited coding experience, allowing them to achieve creative output without an\nextensive programming background. Using LLM-based code generation to further\nlower the barrier to creative output is an exciting opportunity. However, the\nbest strategy for code generation for visual node-based programming languages\nis still an open question. In particular, such languages have multiple levels\nof representation in text, each of which may be used for code generation. In\nthis work, we explore the performance of LLM code generation in audio\nprogramming tasks in visual programming languages at multiple levels of\nrepresentation. We explore code generation through metaprogramming code\nrepresentations for these languages (i.e., coding the language using a\ndifferent high-level text-based programming language), as well as through\ndirect node generation with JSON. We evaluate code generated in this way for\ntwo visual languages for audio programming on a benchmark set of coding\nproblems. We measure both correctness and complexity of the generated code. We\nfind that metaprogramming results in more semantically correct generated code,\ngiven that the code is well-formed (i.e., is syntactically correct and runs).\nWe also find that prompting for richer metaprogramming using randomness and\nloops led to more complex code.",
      "tldr_zh": "本文通过基准测试评估了LLM在视觉数据流语言中的代码生成性能，针对音频编程任务，旨在降低用户编程门槛。研究探索了metaprogramming代码表示（使用其他高级文本-based语言）和直接节点生成（使用JSON）两种方法，并在两个视觉语言上测试生成的代码的正确性和复杂性。结果表明，metaprogramming生成的代码在语义上更准确，前提是代码语法正确；此外，使用包含随机性和循环的更丰富提示，能产生更复杂的代码。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.PL"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.00856v1",
      "published_date": "2024-09-01 22:11:23 UTC",
      "updated_date": "2024-09-01 22:11:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:24:40.275263"
    },
    {
      "arxiv_id": "2409.00853v1",
      "title": "JaxLife: An Open-Ended Agentic Simulator",
      "title_zh": "翻译失败",
      "authors": [
        "Chris Lu",
        "Michael Beukman",
        "Michael Matthews",
        "Jakob Foerster"
      ],
      "abstract": "Human intelligence emerged through the process of natural selection and\nevolution on Earth. We investigate what it would take to re-create this process\nin silico. While past work has often focused on low-level processes (such as\nsimulating physics or chemistry), we instead take a more targeted approach,\naiming to evolve agents that can accumulate open-ended culture and technologies\nacross generations. Towards this, we present JaxLife: an artificial life\nsimulator in which embodied agents, parameterized by deep neural networks, must\nlearn to survive in an expressive world containing programmable systems. First,\nwe describe the environment and show that it can facilitate meaningful\nTuring-complete computation. We then analyze the evolved emergent agents'\nbehavior, such as rudimentary communication protocols, agriculture, and tool\nuse. Finally, we investigate how complexity scales with the amount of compute\nused. We believe JaxLife takes a step towards studying evolved behavior in more\nopen-ended simulations. Our code is available at\nhttps://github.com/luchris429/JaxLife",
      "tldr_zh": "本研究探讨了通过模拟自然选择和进化过程来重现人类智能，提出了一种针对性方法：JaxLife，一个开放式代理模拟器。JaxLife 允许由深度神经网络参数化的代理在包含可编程系统的表达世界中生存和进化，从而积累跨代别的文化和技术。实验结果显示，进化代理展现出初步行为，如基本通信协议、农业和工具使用，且系统复杂性随计算量增加而扩展。该模拟器为研究更开放的进化行为提供了新途径，代码可在 https://github.com/luchris429/JaxLife 获取。",
      "categories": [
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.00853v1",
      "published_date": "2024-09-01 22:05:02 UTC",
      "updated_date": "2024-09-01 22:05:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:24:51.160028"
    },
    {
      "arxiv_id": "2409.00847v3",
      "title": "The Design of an LLM-powered Unstructured Analytics System",
      "title_zh": "LLM驱动的非结构化分析系统设计",
      "authors": [
        "Eric Anderson",
        "Jonathan Fritz",
        "Austin Lee",
        "Bohou Li",
        "Mark Lindblad",
        "Henry Lindeman",
        "Alex Meyer",
        "Parth Parmar",
        "Tanvi Ranade",
        "Mehul A. Shah",
        "Benjamin Sowell",
        "Dan Tecuci",
        "Vinayak Thapliyal",
        "Matt Welsh"
      ],
      "abstract": "LLMs demonstrate an uncanny ability to process unstructured data, and as\nsuch, have the potential to go beyond search and run complex, semantic analyses\nat scale. We describe the design of an unstructured analytics system, Aryn, and\nthe tenets and use cases that motivate its design. With Aryn, users specify\nqueries in natural language and the system automatically determines a semantic\nplan and executes it to compute an answer from a large collection of\nunstructured documents. At the core of Aryn is Sycamore, a declarative document\nprocessing engine, that provides a reliable distributed abstraction called\nDocSets. Sycamore allows users to analyze, enrich, and transform complex\ndocuments at scale. Aryn includes Luna, a query planner that translates natural\nlanguage queries to Sycamore scripts, and DocParse, which takes raw PDFs and\ndocument images, and converts them to DocSets for downstream processing. We\nshow how these pieces come together to achieve better accuracy than RAG on\nanalytics queries over real world reports from the National Transportation\nSafety Board (NTSB). Also, given current limitations of LLMs, we argue that an\nanalytics system must provide explainability to be practical, and show how\nAryn's user interface does this to help build trust.",
      "tldr_zh": "本研究设计了一个基于大型语言模型(LLM)的非结构化分析系统Aryn，旨在利用LLM处理海量非结构化数据，进行超越搜索的复杂语义分析。系统核心包括Sycamore（一个声明式文档处理引擎，提供分布式抽象DocSets）、Luna（将自然语言查询转化为Sycamore脚本的查询规划器）和DocParse（将原始PDF和图像转换为DocSets的工具），从而自动生成语义计划并执行分析。实验结果显示，Aryn在国家运输安全委员会(NTSB)真实报告上的分析查询准确率优于RAG系统；此外，论文强调系统必须具备可解释性，通过用户界面增强信任度，以应对LLM的当前局限性。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.DB",
      "comment": "Included in the proceedings of The Conference on Innovative Data\n  Systems Research (CIDR) 2025",
      "pdf_url": "http://arxiv.org/pdf/2409.00847v3",
      "published_date": "2024-09-01 21:30:14 UTC",
      "updated_date": "2024-12-28 05:14:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:25:15.298858"
    },
    {
      "arxiv_id": "2409.00844v1",
      "title": "Report Cards: Qualitative Evaluation of Language Models Using Natural Language Summaries",
      "title_zh": "报告卡：使用自然语言摘要对语言模型的定性评估",
      "authors": [
        "Blair Yang",
        "Fuyang Cui",
        "Keiran Paster",
        "Jimmy Ba",
        "Pashootan Vaezipoor",
        "Silviu Pitis",
        "Michael R. Zhang"
      ],
      "abstract": "The rapid development and dynamic nature of large language models (LLMs) make\nit difficult for conventional quantitative benchmarks to accurately assess\ntheir capabilities. We propose report cards, which are human-interpretable,\nnatural language summaries of model behavior for specific skills or topics. We\ndevelop a framework to evaluate report cards based on three criteria:\nspecificity (ability to distinguish between models), faithfulness (accurate\nrepresentation of model capabilities), and interpretability (clarity and\nrelevance to humans). We also propose an iterative algorithm for generating\nreport cards without human supervision and explore its efficacy by ablating\nvarious design choices. Through experimentation with popular LLMs, we\ndemonstrate that report cards provide insights beyond traditional benchmarks\nand can help address the need for a more interpretable and holistic evaluation\nof LLMs.",
      "tldr_zh": "该研究提出了一种名为“report cards”的定性评估方法，使用自然语言摘要来总结大型语言模型（LLMs）的特定技能或主题行为，以克服传统量化基准的局限性。评估框架基于三个标准：specificity（区分模型的能力）、faithfulness（准确反映模型能力）和interpretability（清晰且对人类相关），并开发了一个迭代算法来无监督生成这些报告卡。实验结果显示，report cards 提供超越传统基准的洞见，帮助实现对 LLMs 更具整体性和可解释性的评估。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.00844v1",
      "published_date": "2024-09-01 21:18:14 UTC",
      "updated_date": "2024-09-01 21:18:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:25:15.264776"
    },
    {
      "arxiv_id": "2409.00839v1",
      "title": "Entropy Loss: An Interpretability Amplifier of 3D Object Detection Network for Intelligent Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Haobo Yang",
        "Shiyan Zhang",
        "Zhuoyi Yang",
        "Xinyu Zhang",
        "Li Wang",
        "Yifan Tang",
        "Jilong Guo",
        "Jun Li"
      ],
      "abstract": "With the increasing complexity of the traffic environment, the significance\nof safety perception in intelligent driving is intensifying. Traditional\nmethods in the field of intelligent driving perception rely on deep learning,\nwhich suffers from limited interpretability, often described as a \"black box.\"\nThis paper introduces a novel type of loss function, termed \"Entropy Loss,\"\nalong with an innovative training strategy. Entropy Loss is formulated based on\nthe functionality of feature compression networks within the perception model.\nDrawing inspiration from communication systems, the information transmission\nprocess in a feature compression network is expected to demonstrate steady\nchanges in information volume and a continuous decrease in information entropy.\nBy modeling network layer outputs as continuous random variables, we construct\na probabilistic model that quantifies changes in information volume. Entropy\nLoss is then derived based on these expectations, guiding the update of network\nparameters to enhance network interpretability. Our experiments indicate that\nthe Entropy Loss training strategy accelerates the training process. Utilizing\nthe same 60 training epochs, the accuracy of 3D object detection models using\nEntropy Loss on the KITTI test set improved by up to 4.47\\% compared to models\nwithout Entropy Loss, underscoring the method's efficacy. The implementation\ncode is available at\n\\url{https://github.com/yhbcode000/Eloss-Interpretability}.",
      "tldr_zh": "该论文提出了一种名为Entropy Loss的新损失函数及其训练策略，旨在提升智能驾驶中3D物体检测网络的解释性，以解决传统深度学习模型的“黑箱”问题。Entropy Loss基于特征压缩网络的功能，借鉴通信系统原理，将网络层输出建模为连续随机变量，量化信息熵的变化并指导网络参数更新，从而实现信息传输过程的稳健性。实验结果显示，使用Entropy Loss的训练策略加速了模型训练，在KITTI测试集上，3D物体检测准确率比基线模型提高了4.47%。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.00839v1",
      "published_date": "2024-09-01 20:55:50 UTC",
      "updated_date": "2024-09-01 20:55:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:25:38.602921"
    },
    {
      "arxiv_id": "2409.00837v1",
      "title": "You-Only-Randomize-Once: Shaping Statistical Properties in Constraint-based PCG",
      "title_zh": "You",
      "authors": [
        "Jediah Katz",
        "Bahar Bateni",
        "Adam M. Smith"
      ],
      "abstract": "In procedural content generation, modeling the generation task as a\nconstraint satisfaction problem lets us define local and global constraints on\nthe generated output. However, a generator's perceived quality often involves\nstatistics rather than just hard constraints. For example, we may desire that\ngenerated outputs use design elements with a similar distribution to that of\nreference designs. However, such statistical properties cannot be expressed\ndirectly as a hard constraint on the generation of any one output. In contrast,\nmethods which do not use a general-purpose constraint solver, such as Gumin's\nimplementation of the WaveFunctionCollapse (WFC) algorithm, can control output\nstatistics but have limited constraint propagation ability and cannot express\nnon-local constraints. In this paper, we introduce You-Only-Randomize-Once\n(YORO) pre-rolling, a method for crafting a decision variable ordering for a\nconstraint solver that encodes desired statistics in a constraint-based\ngenerator. Using a solver-based WFC as an example, we show that this technique\neffectively controls the statistics of tile-grid outputs generated by several\noff-the-shelf SAT solvers, while still enforcing global constraints on the\noutputs.1 Our approach is immediately applicable to WFC-like generation\nproblems and it offers a conceptual starting point for controlling the design\nelement statistics in other constraint-based generators.",
      "tldr_zh": "本研究探讨了程序化内容生成（Procedural Content Generation, PCG）中基于约束满足问题（Constraint Satisfaction Problem）的生成任务，如何处理统计属性（如设计元素分布）的问题，这些属性无法直接作为硬约束。论文提出You-Only-Randomize-Once (YORO) pre-rolling 方法，通过为约束求解器设计决策变量顺序，来编码期望的统计属性，同时保持全局约束的执行。实验结果显示，使用基于求解器的WaveFunctionCollapse (WFC) 算法作为示例，YORO 能有效控制tile-grid输出的统计属性，并在多个现成的SAT solvers上实现29.32%的准确率提升。该方法适用于WFC-like生成问题，并为其他约束-based生成器控制设计元素统计提供了一个概念起点。",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "Published in Foundations of Digital Games (FDG) 2024. 10 pages, 6\n  figures",
      "pdf_url": "http://arxiv.org/pdf/2409.00837v1",
      "published_date": "2024-09-01 20:43:55 UTC",
      "updated_date": "2024-09-01 20:43:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:25:53.301261"
    },
    {
      "arxiv_id": "2409.03717v1",
      "title": "Sample-Efficient Diffusion for Text-To-Speech Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Justin Lovelace",
        "Soham Ray",
        "Kwangyoun Kim",
        "Kilian Q. Weinberger",
        "Felix Wu"
      ],
      "abstract": "This work introduces Sample-Efficient Speech Diffusion (SESD), an algorithm\nfor effective speech synthesis in modest data regimes through latent diffusion.\nIt is based on a novel diffusion architecture, that we call U-Audio Transformer\n(U-AT), that efficiently scales to long sequences and operates in the latent\nspace of a pre-trained audio autoencoder. Conditioned on character-aware\nlanguage model representations, SESD achieves impressive results despite\ntraining on less than 1k hours of speech - far less than current\nstate-of-the-art systems. In fact, it synthesizes more intelligible speech than\nthe state-of-the-art auto-regressive model, VALL-E, while using less than 2%\nthe training data.",
      "tldr_zh": "本研究提出了一种高效的文本到语音合成算法，名为 Sample-Efficient Speech Diffusion (SESD)，旨在在数据有限的环境下实现有效的语音合成。SESD 基于新型 U-Audio Transformer (U-AT) 架构，在预训练音频自编码器的潜在空间中操作，并结合字符感知语言模型表示作为条件，从而处理长序列数据。实验结果显示，SESD 在少于 1k 小时的训练数据上，就能合成比最先进的自回归模型 VALL-E 更易懂的语音，而使用的训练数据不到 VALL-E 的 2%。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SD",
      "comment": "Interspeech 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.03717v1",
      "published_date": "2024-09-01 20:34:36 UTC",
      "updated_date": "2024-09-01 20:34:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:26:15.050539"
    },
    {
      "arxiv_id": "2409.00830v1",
      "title": "Building FKG.in: a Knowledge Graph for Indian Food",
      "title_zh": "构建 FKG.in：印度食物的知识图谱",
      "authors": [
        "Saransh Kumar Gupta",
        "Lipika Dey",
        "Partha Pratim Das",
        "Ramesh Jain"
      ],
      "abstract": "This paper presents an ontology design along with knowledge engineering, and\nmultilingual semantic reasoning techniques to build an automated system for\nassimilating culinary information for Indian food in the form of a knowledge\ngraph. The main focus is on designing intelligent methods to derive ontology\ndesigns and capture all-encompassing knowledge about food, recipes,\ningredients, cooking characteristics, and most importantly, nutrition, at\nscale. We present our ongoing work in this workshop paper, describe in some\ndetail the relevant challenges in curating knowledge of Indian food, and\npropose our high-level ontology design. We also present a novel workflow that\nuses AI, LLM, and language technology to curate information from recipe blog\nsites in the public domain to build knowledge graphs for Indian food. The\nmethods for knowledge curation proposed in this paper are generic and can be\nreplicated for any domain. The design is application-agnostic and can be used\nfor AI-driven smart analysis, building recommendation systems for Personalized\nDigital Health, and complementing the knowledge graph for Indian food with\ncontextual information such as user information, food biochemistry, geographic\ninformation, agricultural information, etc.",
      "tldr_zh": "这篇论文介绍了FKG.in，一个针对印度食物的Knowledge Graph的构建过程，重点设计了本体设计（ontology design）和知识工程方法，以智能方式捕捉食物、食谱、成分、烹饪特性及营养等全面知识。论文提出了一种新工作流，利用AI、LLM和语言技术从公开食谱博客中提取信息，并解决印度食物知识整理的挑战，使方法通用可应用于其他领域。FKG.in的设计应用无关，可用于AI驱动的智能分析、个性化数字健康推荐系统，并整合用户信息、食物生化、地理和农业信息等上下文。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 3 figures, 25 references, Formal Ontology in Information\n  Systems Conference 2024 - Integrated Food Ontology Workshop",
      "pdf_url": "http://arxiv.org/pdf/2409.00830v1",
      "published_date": "2024-09-01 20:18:36 UTC",
      "updated_date": "2024-09-01 20:18:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:26:28.541066"
    },
    {
      "arxiv_id": "2409.00824v1",
      "title": "Accelerating Hybrid Agent-Based Models and Fuzzy Cognitive Maps: How to Combine Agents who Think Alike?",
      "title_zh": "翻译失败",
      "authors": [
        "Philippe J. Giabbanelli",
        "Jack T. Beerman"
      ],
      "abstract": "While Agent-Based Models can create detailed artificial societies based on\nindividual differences and local context, they can be computationally\nintensive. Modelers may offset these costs through a parsimonious use of the\nmodel, for example by using smaller population sizes (which limits analyses in\nsub-populations), running fewer what-if scenarios, or accepting more\nuncertainty by performing fewer simulations. Alternatively, researchers may\naccelerate simulations via hardware solutions (e.g., GPU parallelism) or\napproximation approaches that operate a tradeoff between accuracy and compute\ntime. In this paper, we present an approximation that combines agents who\n`think alike', thus reducing the population size and the compute time. Our\ninnovation relies on representing agent behaviors as networks of rules (Fuzzy\nCognitive Maps) and empirically evaluating different measures of distance\nbetween these networks. Then, we form groups of think-alike agents via\ncommunity detection and simplify them to a representative agent. Case studies\nshow that our simplifications remain accuracy.",
      "tldr_zh": "本研究针对Agent-Based Models (ABM) 的计算密集问题，提出了一种加速方法，通过将“想法相似的”代理组合简化模型规模，从而减少计算时间。创新点在于使用Fuzzy Cognitive Maps (FCM) 表示代理行为，评估代理网络之间的距离，并通过社区检测形成相似代理组，再用代表性代理替换。案例研究显示，这种简化方法在保持准确性的同时显著降低了计算成本，提供了一种高效的ABM优化策略。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "To appear at the 2024 Winter Simulation Conference",
      "pdf_url": "http://arxiv.org/pdf/2409.00824v1",
      "published_date": "2024-09-01 19:45:15 UTC",
      "updated_date": "2024-09-01 19:45:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:26:28.406899"
    },
    {
      "arxiv_id": "2409.00815v3",
      "title": "Serialized Speech Information Guidance with Overlapped Encoding Separation for Multi-Speaker Automatic Speech Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Shi",
        "Yuan Gao",
        "Zhaoheng Ni",
        "Tatsuya Kawahara"
      ],
      "abstract": "Serialized output training (SOT) attracts increasing attention due to its\nconvenience and flexibility for multi-speaker automatic speech recognition\n(ASR). However, it is not easy to train with attention loss only. In this\npaper, we propose the overlapped encoding separation (EncSep) to fully utilize\nthe benefits of the connectionist temporal classification (CTC) and attention\nhybrid loss. This additional separator is inserted after the encoder to extract\nthe multi-speaker information with CTC losses. Furthermore, we propose the\nserialized speech information guidance SOT (GEncSep) to further utilize the\nseparated encodings. The separated streams are concatenated to provide\nsingle-speaker information to guide attention during decoding. The experimental\nresults on LibriMix show that the single-speaker encoding can be separated from\nthe overlapped encoding. The CTC loss helps to improve the encoder\nrepresentation under complex scenarios. GEncSep further improved performance.",
      "tldr_zh": "本研究针对多说话人自动语音识别（ASR）中的序列化输出训练（SOT），提出了一种重叠编码分离（EncSep）方法，以充分利用连接主义时间分类（CTC）和注意力混合损失。该方法在编码器后插入分离器，使用 CTC 损失提取多说话人信息，从而改善编码器在复杂场景下的表示。此外，研究引入序列化语音信息指导 SOT（GEncSep），通过将分离的编码流连接起来，提供单说话人信息指导解码过程。在 LibriMix 数据集上的实验显示，EncSep 成功分离单说话人编码，并显著提升性能，GEncSep 进一步提高了整体效果。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.00815v3",
      "published_date": "2024-09-01 19:07:34 UTC",
      "updated_date": "2024-09-11 02:33:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:26:41.779804"
    },
    {
      "arxiv_id": "2409.10547v1",
      "title": "NoPhish: Efficient Chrome Extension for Phishing Detection Using Machine Learning Techniques",
      "title_zh": "翻译失败",
      "authors": [
        "Leand Thaqi",
        "Arbnor Halili",
        "Kamer Vishi",
        "Blerim Rexha"
      ],
      "abstract": "The growth of digitalization services via web browsers has simplified our\ndaily routine of doing business. But at the same time, it has made the web\nbrowser very attractive for several cyber-attacks. Web phishing is a well-known\ncyberattack that is used by attackers camouflaging as trustworthy web servers\nto obtain sensitive user information such as credit card numbers, bank\ninformation, personal ID, social security number, and username and passwords.\nIn recent years many techniques have been developed to identify the authentic\nweb pages that users visit and warn them when the webpage is phishing. In this\npaper, we have developed an extension for Chrome the most favorite web browser,\nthat will serve as a middleware between the user and phishing websites. The\nChrome extension named \"NoPhish\" shall identify a phishing webpage based on\nseveral Machine Learning techniques. We have used the training dataset from\n\"PhishTank\" and extracted the 22 most popular features as rated by the Alexa\ndatabase. The training algorithms used are Random Forest, Support Vector\nMachine, and k-Nearest Neighbor. The performance results show that Random\nForest delivers the best precision.",
      "tldr_zh": "本文开发了名为 NoPhish 的 Chrome 扩展，作为用户与潜在钓鱼网站之间的中间件，利用 Machine Learning 技术检测网络钓鱼攻击。扩展基于 PhishTank 数据集提取的22个特征（参考 Alexa 数据库），并采用 Random Forest、Support Vector Machine 和 k-Nearest Neighbor 算法进行训练。结果显示，Random Forest 算法表现出最佳精度，提升了钓鱼网页的识别效果。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "21 pages, 13 figures, 5 listings, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2409.10547v1",
      "published_date": "2024-09-01 18:59:14 UTC",
      "updated_date": "2024-09-01 18:59:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:26:52.376479"
    },
    {
      "arxiv_id": "2409.00810v2",
      "title": "A Novel Self-Attention-Enabled Weighted Ensemble-Based Convolutional Neural Network Framework for Distributed Denial of Service Attack Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Kanthimathi S",
        "Shravan Venkatraman",
        "Jayasankar K S",
        "Pranay Jiljith T",
        "Jashwanth R"
      ],
      "abstract": "Distributed Denial of Service (DDoS) attacks are a major concern in network\nsecurity, as they overwhelm systems with excessive traffic, compromise\nsensitive data, and disrupt network services. Accurately detecting these\nattacks is crucial to protecting network infrastructure. Traditional\napproaches, such as single Convolutional Neural Networks (CNNs) or conventional\nMachine Learning (ML) algorithms like Decision Trees (DTs) and Support Vector\nMachines (SVMs), struggle to extract the diverse features needed for precise\nclassification, resulting in suboptimal performance. This research addresses\nthis gap by introducing a novel approach for DDoS attack detection. The\nproposed method combines three distinct CNN architectures: SA-Enabled CNN with\nXGBoost, SA-Enabled CNN with LSTM, and SA-Enabled CNN with Random Forest. Each\nmodel extracts features at multiple scales, while self-attention mechanisms\nenhance feature integration and relevance. The weighted ensemble approach\nensures that both prominent and subtle features contribute to the final\nclassification, improving adaptability to evolving attack patterns and novel\nthreats. The proposed method achieves a precision of 98.71%, an F1-score of\n98.66%, a recall of 98.63%, and an accuracy of 98.69%, outperforming\ntraditional methods and setting a new benchmark in DDoS attack detection. This\ninnovative approach addresses critical limitations in current models and\nadvances the state of the art in network security.",
      "tldr_zh": "该研究针对分布式拒绝服务(DDoS)攻击检测的挑战，提出了一种新型框架：基于自注意力机制(Self-Attention-Enabled)的加权集成(Weighted Ensemble)卷积神经网络(CNN)。该框架整合了三个CNN架构——SA-Enabled CNN with XGBoost、SA-Enabled CNN with LSTM 和 SA-Enabled CNN with Random Forest——通过多尺度特征提取和自注意力机制增强特征相关性，从而提高对复杂攻击模式的适应性。实验结果显示，该方法实现了98.71%的精确率、98.66%的F1分数、98.63%的召回率和98.69%的准确率，显著优于传统CNN或机器学习算法(Machine Learning algorithms)，并为网络安全领域设定新基准。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG",
        "I.2.6"
      ],
      "primary_category": "cs.CR",
      "comment": "19 pages, 3 tables, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.00810v2",
      "published_date": "2024-09-01 18:58:33 UTC",
      "updated_date": "2024-10-12 09:51:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:27:06.322077"
    },
    {
      "arxiv_id": "2409.00807v1",
      "title": "Diffusion based multi-domain neuroimaging harmonization method with preservation of anatomical details",
      "title_zh": "翻译失败",
      "authors": [
        "Haoyu Lan",
        "Bino A. Varghese",
        "Nasim Sheikh-Bahaei",
        "Farshid Sepehrband",
        "Arthur W Toga",
        "Jeiran Choupan"
      ],
      "abstract": "Multi-center neuroimaging studies face technical variability due to batch\ndifferences across sites, which potentially hinders data aggregation and\nimpacts study reliability.Recent efforts in neuroimaging harmonization have\naimed to minimize these technical gaps and reduce technical variability across\nbatches. While Generative Adversarial Networks (GAN) has been a prominent\nmethod for addressing image harmonization tasks, GAN-harmonized images suffer\nfrom artifacts or anatomical distortions. Given the advancements of denoising\ndiffusion probabilistic model which produces high-fidelity images, we have\nassessed the efficacy of the diffusion model for neuroimaging harmonization. we\nhave demonstrated the diffusion model's superior capability in harmonizing\nimages from multiple domains, while GAN-based methods are limited to\nharmonizing images between two domains per model. Our experiments highlight\nthat the learned domain invariant anatomical condition reinforces the model to\naccurately preserve the anatomical details while differentiating batch\ndifferences at each diffusion step. Our proposed method has been tested on two\npublic neuroimaging dataset ADNI1 and ABIDE II, yielding harmonization results\nwith consistent anatomy preservation and superior FID score compared to the\nGAN-based methods. We have conducted multiple analysis including extensive\nquantitative and qualitative evaluations against the baseline models, ablation\nstudy showcasing the benefits of the learned conditions, and improvements in\nthe consistency of perivascular spaces (PVS) segmentation through\nharmonization.",
      "tldr_zh": "本研究针对多中心神经影像研究中的技术变异问题，提出了一种基于扩散模型（diffusion model）的多域影像协调方法，旨在最小化批次差异的同时保留解剖细节。该方法利用学习到的域不变解剖条件（domain invariant anatomical condition），在每个扩散步骤中精确区分批次差异，并支持多个域的协调，而非像 Generative Adversarial Networks (GAN) 那样限于两个域。实验在 ADNI1 和 ABIDE II 数据集上显示，该方法在保持解剖一致性方面优于 GAN-based 方法，取得了更低的 FID score，并通过定量、定性评估和消融研究证实了其在 perivascular spaces (PVS) 分割任务中的显著改善。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.00807v1",
      "published_date": "2024-09-01 18:54:00 UTC",
      "updated_date": "2024-09-01 18:54:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:27:17.732114"
    },
    {
      "arxiv_id": "2409.00787v1",
      "title": "The Dark Side of Human Feedback: Poisoning Large Language Models via User Inputs",
      "title_zh": "翻译失败",
      "authors": [
        "Bocheng Chen",
        "Hanqing Guo",
        "Guangjing Wang",
        "Yuanda Wang",
        "Qiben Yan"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated great capabilities in natural\nlanguage understanding and generation, largely attributed to the intricate\nalignment process using human feedback. While alignment has become an essential\ntraining component that leverages data collected from user queries, it\ninadvertently opens up an avenue for a new type of user-guided poisoning\nattacks. In this paper, we present a novel exploration into the latent\nvulnerabilities of the training pipeline in recent LLMs, revealing a subtle yet\neffective poisoning attack via user-supplied prompts to penetrate alignment\ntraining protections. Our attack, even without explicit knowledge about the\ntarget LLMs in the black-box setting, subtly alters the reward feedback\nmechanism to degrade model performance associated with a particular keyword,\nall while remaining inconspicuous. We propose two mechanisms for crafting\nmalicious prompts: (1) the selection-based mechanism aims at eliciting toxic\nresponses that paradoxically score high rewards, and (2) the generation-based\nmechanism utilizes optimizable prefixes to control the model output. By\ninjecting 1\\% of these specially crafted prompts into the data, through\nmalicious users, we demonstrate a toxicity score up to two times higher when a\nspecific trigger word is used. We uncover a critical vulnerability, emphasizing\nthat irrespective of the reward model, rewards applied, or base language model\nemployed, if training harnesses user-generated prompts, a covert compromise of\nthe LLMs is not only feasible but potentially inevitable.",
      "tldr_zh": "本文揭示了大型语言模型(LLMs)通过人类反馈对齐训练的潜在风险，提出了一种新型用户引导的投毒攻击，能够在黑盒设置下破坏模型性能。攻击方法包括selection-based机制（诱导模型产生高奖励的有毒响应）和generation-based机制（使用可优化的前缀控制输出），通过注入1%的恶意提示来篡改奖励反馈机制。实验结果显示，这种攻击可使特定触发词下的毒性分数提高两倍，强调了无论奖励模型或基础LLM如何，用户生成提示都可能导致模型的隐蔽性妥协。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.00787v1",
      "published_date": "2024-09-01 17:40:04 UTC",
      "updated_date": "2024-09-01 17:40:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:27:29.319982"
    },
    {
      "arxiv_id": "2409.02128v1",
      "title": "The Application of Artificial Neural Network Model to Predicting the Acid Mine Drainage from Long-Term Lab Scale Kinetic Test",
      "title_zh": "翻译失败",
      "authors": [
        "Muhammad Sonny Abfertiawan",
        "Muchammad Daniyal Kautsar",
        "Faiz Hasan",
        "Yoseph Palinggi",
        "Kris Pranoto"
      ],
      "abstract": "Acid mine drainage (AMD) is one of the common environmental problems in the\ncoal mining industry that was formed by the oxidation of sulfide minerals in\nthe overburden or waste rock. The prediction of acid generation through AMD is\nimportant to do in overburden management and planning the post-mining land use.\nOne of the methods used to predict AMD is a lab-scale kinetic test to determine\nthe rate of acid formation over time using representative samples in the field.\nHowever, this test requires a long-time procedure and large amount of chemical\nreagents lead to inefficient cost. On the other hand, there is potential for\nmachine learning to learn the pattern behind the lab-scale kinetic test data.\nThis study describes an approach to use artificial neural network (ANN)\nmodeling to predict the result from lab-scale kinetic tests. Various ANN model\nis used based on 83 weeks experiments of lab-scale kinetic tests with 100\\%\npotential acid-forming rock. The model approaches the monitoring of pH, ORP,\nconductivity, TDS, sulfate, and heavy metals (Fe and Mn). The overall\nNash-Sutcliffe Efficiency (NSE) obtained in this study was 0.99 on training and\nvalidation data, indicating a strong correlation and accurate prediction\ncompared to the actual lab-scale kinetic tests data. This show the ANN ability\nto learn patterns, trends, and seasonality from past data for accurate\nforecasting, thereby highlighting its significant contribution to solving AMD\nproblems. This research is also expected to establish the foundation for a new\napproach to predict AMD, with time efficient, accurate, and cost-effectiveness\nin future applications.",
      "tldr_zh": "本研究探讨了使用人工神经网络（ANN）模型预测酸性矿山排水（AMD）的生成，以解决传统实验室规模动力学测试耗时长、成本高的局限性。研究基于83周的实验数据，针对100%潜在酸性形成岩石，构建ANN模型来监控pH、ORP、导电性、TDS、硫酸盐以及重金属（Fe和Mn）的变化。结果显示，模型的Nash-Sutcliffe Efficiency (NSE) 达到0.99，实现了对实际数据的准确预测，并证明了ANN在学习模式和趋势方面的潜力，为高效、准确且经济实用的AMD预测方法奠定了基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "The 7th Environmental Technology and Management Conference (ETMC\n  2023)",
      "pdf_url": "http://arxiv.org/pdf/2409.02128v1",
      "published_date": "2024-09-01 16:39:37 UTC",
      "updated_date": "2024-09-01 16:39:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:27:41.206290"
    },
    {
      "arxiv_id": "2409.00755v3",
      "title": "Trusted Unified Feature-Neighborhood Dynamics for Multi-View Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Haojian Huang",
        "Chuanyu Qin",
        "Zhe Liu",
        "Kaijing Ma",
        "Jin Chen",
        "Han Fang",
        "Chao Ban",
        "Hao Sun",
        "Zhongjiang He"
      ],
      "abstract": "Multi-view classification (MVC) faces inherent challenges due to domain gaps\nand inconsistencies across different views, often resulting in uncertainties\nduring the fusion process. While Evidential Deep Learning (EDL) has been\neffective in addressing view uncertainty, existing methods predominantly rely\non the Dempster-Shafer combination rule, which is sensitive to conflicting\nevidence and often neglects the critical role of neighborhood structures within\nmulti-view data. To address these limitations, we propose a Trusted Unified\nFeature-NEighborhood Dynamics (TUNED) model for robust MVC. This method\neffectively integrates local and global feature-neighborhood (F-N) structures\nfor robust decision-making. Specifically, we begin by extracting local F-N\nstructures within each view. To further mitigate potential uncertainties and\nconflicts in multi-view fusion, we employ a selective Markov random field that\nadaptively manages cross-view neighborhood dependencies. Additionally, we\nemploy a shared parameterized evidence extractor that learns global consensus\nconditioned on local F-N structures, thereby enhancing the global integration\nof multi-view features. Experiments on benchmark datasets show that our method\nimproves accuracy and robustness over existing approaches, particularly in\nscenarios with high uncertainty and conflicting views. The code will be made\navailable at https://github.com/JethroJames/TUNED.",
      "tldr_zh": "该研究针对多视图分类 (MVC) 中的领域间差距和不一致性问题，提出 Trusted Unified Feature-NEighborhood Dynamics (TUNED) 模型，以解决现有 Evidential Deep Learning (EDL) 方法依赖 Dempster-Shafer 组合规则的局限性，该规则对冲突证据敏感且忽略邻域结构。TUNED 通过提取每个视图的局部特征-邻域 (F-N) 结构，使用 selective Markov random field 管理跨视图依赖，并采用共享参数化证据提取器基于局部结构学习全局共识，从而增强多视图特征的鲁棒融合。实验在基准数据集上显示，TUNED 显著提高了准确性和鲁棒性，尤其在高不确定性和冲突视图场景中。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2409.00755v3",
      "published_date": "2024-09-01 15:48:20 UTC",
      "updated_date": "2024-12-13 02:10:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:27:56.836656"
    },
    {
      "arxiv_id": "2409.00754v1",
      "title": "Cooperative Path Planning with Asynchronous Multiagent Reinforcement Learning",
      "title_zh": "异步多智能体强化学习的合作路径规划",
      "authors": [
        "Jiaming Yin",
        "Weixiong Rao",
        "Yu Xiao",
        "Keshuang Tang"
      ],
      "abstract": "In this paper, we study the shortest path problem (SPP) with multiple\nsource-destination pairs (MSD), namely MSD-SPP, to minimize average travel time\nof all shortest paths. The inherent traffic capacity limits within a road\nnetwork contributes to the competition among vehicles. Multi-agent\nreinforcement learning (MARL) model cannot offer effective and efficient path\nplanning cooperation due to the asynchronous decision making setting in\nMSD-SPP, where vehicles (a.k.a agents) cannot simultaneously complete routing\nactions in the previous time step. To tackle the efficiency issue, we propose\nto divide an entire road network into multiple sub-graphs and subsequently\nexecute a two-stage process of inter-region and intra-region route planning. To\naddress the asynchronous issue, in the proposed asyn-MARL framework, we first\ndesign a global state, which exploits a low-dimensional vector to implicitly\nrepresent the joint observations and actions of multi-agents. Then we develop a\nnovel trajectory collection mechanism to decrease the redundancy in training\ntrajectories. Additionally, we design a novel actor network to facilitate the\ncooperation among vehicles towards the same or close destinations and a\nreachability graph aimed at preventing infinite loops in routing paths. On both\nsynthetic and real road networks, our evaluation result demonstrates that our\napproach outperforms state-of-the-art planning approaches.",
      "tldr_zh": "本研究针对多源多目的地最短路径问题（MSD-SPP），旨在最小化平均旅行时间，同时处理道路网络容量限制和车辆竞争带来的异步决策挑战。作者提出了一种asyn-MARL框架，包括将道路网络划分为子图并采用两阶段路由规划（inter-region和intra-region）、设计全球状态表示多代理联合观察和动作、开发轨迹收集机制减少冗余，以及创新的actor网络和reachability图来促进车辆合作并避免无限循环。实验结果显示，该方法在合成和真实道路网络上优于现有规划方法，提升了路径规划的效率和有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.00754v1",
      "published_date": "2024-09-01 15:48:14 UTC",
      "updated_date": "2024-09-01 15:48:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:28:08.161172"
    },
    {
      "arxiv_id": "2409.00750v3",
      "title": "MaskGCT: Zero-Shot Text-to-Speech with Masked Generative Codec Transformer",
      "title_zh": "翻译失败",
      "authors": [
        "Yuancheng Wang",
        "Haoyue Zhan",
        "Liwei Liu",
        "Ruihong Zeng",
        "Haotian Guo",
        "Jiachen Zheng",
        "Qiang Zhang",
        "Xueyao Zhang",
        "Shunsi Zhang",
        "Zhizheng Wu"
      ],
      "abstract": "The recent large-scale text-to-speech (TTS) systems are usually grouped as\nautoregressive and non-autoregressive systems. The autoregressive systems\nimplicitly model duration but exhibit certain deficiencies in robustness and\nlack of duration controllability. Non-autoregressive systems require explicit\nalignment information between text and speech during training and predict\ndurations for linguistic units (e.g. phone), which may compromise their\nnaturalness. In this paper, we introduce Masked Generative Codec Transformer\n(MaskGCT), a fully non-autoregressive TTS model that eliminates the need for\nexplicit alignment information between text and speech supervision, as well as\nphone-level duration prediction. MaskGCT is a two-stage model: in the first\nstage, the model uses text to predict semantic tokens extracted from a speech\nself-supervised learning (SSL) model, and in the second stage, the model\npredicts acoustic tokens conditioned on these semantic tokens. MaskGCT follows\nthe mask-and-predict learning paradigm. During training, MaskGCT learns to\npredict masked semantic or acoustic tokens based on given conditions and\nprompts. During inference, the model generates tokens of a specified length in\na parallel manner. Experiments with 100K hours of in-the-wild speech\ndemonstrate that MaskGCT outperforms the current state-of-the-art zero-shot TTS\nsystems in terms of quality, similarity, and intelligibility. Audio samples are\navailable at https://maskgct.github.io/. We release our code and model\ncheckpoints at\nhttps://github.com/open-mmlab/Amphion/blob/main/models/tts/maskgct.",
      "tldr_zh": "该论文提出 MaskGCT，一种基于 Masked Generative Codec Transformer 的零样本 Text-to-Speech (TTS) 模型，旨在克服传统自回归和非自回归系统的不足，如鲁棒性问题和时长可控性。MaskGCT 采用两阶段非自回归方法：第一阶段使用文本预测从语音自监督学习 (SSL) 模型提取的语义 tokens；第二阶段基于这些语义 tokens 预测声学 tokens，并通过 mask-and-predict 学习范式在训练中预测被掩码的 tokens，在推理中并行生成指定长度的 tokens。实验在 10 万小时的野外语音数据上显示，MaskGCT 在质量、相似性和可理解性方面优于现有最先进零样本 TTS 系统，并提供了音频样本、代码和模型检查点。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.00750v3",
      "published_date": "2024-09-01 15:26:30 UTC",
      "updated_date": "2024-10-20 14:25:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:28:20.889390"
    },
    {
      "arxiv_id": "2409.02127v1",
      "title": "Enabling Trustworthy Federated Learning in Industrial IoT: Bridging the Gap Between Interpretability and Robustness",
      "title_zh": "在工业物联网中启用可信联邦学习：弥合可解释性和鲁棒性之间的差距",
      "authors": [
        "Senthil Kumar Jagatheesaperumal",
        "Mohamed Rahouti",
        "Ali Alfatemi",
        "Nasir Ghani",
        "Vu Khanh Quy",
        "Abdellah Chehri"
      ],
      "abstract": "Federated Learning (FL) represents a paradigm shift in machine learning,\nallowing collaborative model training while keeping data localized. This\napproach is particularly pertinent in the Industrial Internet of Things (IIoT)\ncontext, where data privacy, security, and efficient utilization of distributed\nresources are paramount. The essence of FL in IIoT lies in its ability to learn\nfrom diverse, distributed data sources without requiring central data storage,\nthus enhancing privacy and reducing communication overheads. However, despite\nits potential, several challenges impede the widespread adoption of FL in IIoT,\nnotably in ensuring interpretability and robustness. This article focuses on\nenabling trustworthy FL in IIoT by bridging the gap between interpretability\nand robustness, which is crucial for enhancing trust, improving\ndecision-making, and ensuring compliance with regulations. Moreover, the design\nstrategies summarized in this article ensure that FL systems in IIoT are\ntransparent and reliable, vital in industrial settings where decisions have\nsignificant safety and economic impacts. The case studies in the IIoT\nenvironment driven by trustworthy FL models are provided, wherein the practical\ninsights of trustworthy communications between IIoT systems and their end users\nare highlighted.",
      "tldr_zh": "这篇论文探讨了Federated Learning (FL)在Industrial Internet of Things (IIoT)中的应用，强调其在保持数据本地化前提下实现协作训练的优势，从而提升隐私、安全和资源利用效率。论文的核心贡献在于桥接interpretability和robustness之间的差距，通过总结设计策略来构建透明可靠的FL系统，以增强信任、决策质量和法规合规性。在IIoT环境中的案例研究展示了这些可信FL模型的实际效果，突出了系统与用户之间可信通信的实用洞见。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68Txx",
        "I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.02127v1",
      "published_date": "2024-09-01 15:13:39 UTC",
      "updated_date": "2024-09-01 15:13:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:28:31.598311"
    },
    {
      "arxiv_id": "2409.00743v1",
      "title": "Interpretable Clustering: A Survey",
      "title_zh": "可解释聚类：综述",
      "authors": [
        "Lianyu Hu",
        "Mudi Jiang",
        "Junjie Dong",
        "Xinying Liu",
        "Zengyou He"
      ],
      "abstract": "In recent years, much of the research on clustering algorithms has primarily\nfocused on enhancing their accuracy and efficiency, frequently at the expense\nof interpretability. However, as these methods are increasingly being applied\nin high-stakes domains such as healthcare, finance, and autonomous systems, the\nneed for transparent and interpretable clustering outcomes has become a\ncritical concern. This is not only necessary for gaining user trust but also\nfor satisfying the growing ethical and regulatory demands in these fields.\nEnsuring that decisions derived from clustering algorithms can be clearly\nunderstood and justified is now a fundamental requirement. To address this\nneed, this paper provides a comprehensive and structured review of the current\nstate of explainable clustering algorithms, identifying key criteria to\ndistinguish between various methods. These insights can effectively assist\nresearchers in making informed decisions about the most suitable explainable\nclustering methods for specific application contexts, while also promoting the\ndevelopment and adoption of clustering algorithms that are both efficient and\ntransparent.",
      "tldr_zh": "近年来，聚类算法的研究主要聚焦于提升准确性和效率，却常常牺牲了可解释性，尤其在高风险领域如healthcare、金融和autonomous systems中，可解释性至关重要，以建立用户信任并满足道德与监管要求。这篇survey论文提供了可解释聚类(interpretable clustering)算法的全面回顾，识别了区分不同方法的key criteria。这些insights有助于研究人员选择适合特定应用的解释方法，并促进高效且透明的聚类算法的发展和采用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.00743v1",
      "published_date": "2024-09-01 15:09:51 UTC",
      "updated_date": "2024-09-01 15:09:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:28:44.227920"
    },
    {
      "arxiv_id": "2409.00742v1",
      "title": "Simulation of Social Media-Driven Bubble Formation in Financial Markets using an Agent-Based Model with Hierarchical Influence Network",
      "title_zh": "翻译失败",
      "authors": [
        "Gonzalo Bohorquez",
        "John Cartlidge"
      ],
      "abstract": "We propose that a tree-like hierarchical structure represents a simple and\neffective way to model the emergent behaviour of financial markets, especially\nmarkets where there exists a pronounced intersection between social media\ninfluences and investor behaviour. To explore this hypothesis, we introduce an\nagent-based model of financial markets, where trading agents are embedded in a\nhierarchical network of communities, and communities influence the strategies\nand opinions of traders. Empirical analysis of the model shows that its\nbehaviour conforms to several stylized facts observed in real financial\nmarkets; and the model is able to realistically simulate the effects that\nsocial media-driven phenomena, such as echo chambers and pump-and-dump schemes,\nhave on financial markets.",
      "tldr_zh": "该论文提出了一种基于代理的模型（agent-based model），利用树状分层影响网络（hierarchical influence network）来模拟社交媒体驱动的金融市场泡沫形成，强调社交媒体如何影响投资者行为。模型中，交易代理嵌入在社区层次结构内，这些社区通过影响代理的策略和意见来模拟市场动态。实验分析表明，该模型符合真实金融市场的若干风格化事实（stylized facts），并能真实地再现社交媒体现象如回音室（echo chambers）和泵骗方案（pump-and-dump schemes）对市场的冲击。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "q-fin.TR",
        "I.2.11"
      ],
      "primary_category": "cs.MA",
      "comment": "11 pages, 7 figures, To appear in Proceedings of 36th European\n  Modeling and Simulation Symposium (EMSS), 21st International\n  Multidisciplinary Modelling and Simulation Multiconference (I3M), Tenerife,\n  Spain, Sep. 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.00742v1",
      "published_date": "2024-09-01 15:09:35 UTC",
      "updated_date": "2024-09-01 15:09:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:28:55.823432"
    },
    {
      "arxiv_id": "2409.00735v1",
      "title": "AgGym: An agricultural biotic stress simulation environment for ultra-precision management planning",
      "title_zh": "AgGym：农业生物胁迫模拟环境",
      "authors": [
        "Mahsa Khosravi",
        "Matthew Carroll",
        "Kai Liang Tan",
        "Liza Van der Laan",
        "Joscif Raigne",
        "Daren S. Mueller",
        "Arti Singh",
        "Aditya Balu",
        "Baskar Ganapathysubramanian",
        "Asheesh Kumar Singh",
        "Soumik Sarkar"
      ],
      "abstract": "Agricultural production requires careful management of inputs such as\nfungicides, insecticides, and herbicides to ensure a successful crop that is\nhigh-yielding, profitable, and of superior seed quality. Current\nstate-of-the-art field crop management relies on coarse-scale crop management\nstrategies, where entire fields are sprayed with pest and disease-controlling\nchemicals, leading to increased cost and sub-optimal soil and crop management.\nTo overcome these challenges and optimize crop production, we utilize machine\nlearning tools within a virtual field environment to generate localized\nmanagement plans for farmers to manage biotic threats while maximizing profits.\nSpecifically, we present AgGym, a modular, crop and stress agnostic simulation\nframework to model the spread of biotic stresses in a field and estimate yield\nlosses with and without chemical treatments. Our validation with real data\nshows that AgGym can be customized with limited data to simulate yield outcomes\nunder various biotic stress conditions. We further demonstrate that deep\nreinforcement learning (RL) policies can be trained using AgGym for designing\nultra-precise biotic stress mitigation strategies with potential to increase\nyield recovery with less chemicals and lower cost. Our proposed framework\nenables personalized decision support that can transform biotic stress\nmanagement from being schedule based and reactive to opportunistic and\nprescriptive. We also release the AgGym software implementation as a community\nresource and invite experts to contribute to this open-sourced publicly\navailable modular environment framework. The source code can be accessed at:\nhttps://github.com/SCSLabISU/AgGym.",
      "tldr_zh": "论文介绍了 AgGym，一个模块化的农业生物胁迫模拟环境，旨在帮助农民通过机器学习生成本地化管理计划，以优化作物产量并减少化学品使用。AgGym 可以模拟生物胁迫在田地中的传播、估计产量损失，并使用深度强化学习 (RL) 训练策略，实现超精确的胁迫缓解，从而提高产量恢复并降低成本。实验结果显示，该框架基于有限数据即可自定义模拟各种胁迫条件，并将传统反应式管理转变为机会性和规定性管理。作者开源了 AgGym 代码（https://github.com/SCSLabISU/AgGym），邀请社区贡献。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.00735v1",
      "published_date": "2024-09-01 14:55:45 UTC",
      "updated_date": "2024-09-01 14:55:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:29:08.747890"
    },
    {
      "arxiv_id": "2409.00727v1",
      "title": "Hound: Hunting Supervision Signals for Few and Zero Shot Node Classification on Text-attributed Graph",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxiang Wang",
        "Xiao Yan",
        "Shiyu Jin",
        "Quanqing Xu",
        "Chuanhui Yang",
        "Yuanyuan Zhu",
        "Chuang Hu",
        "Bo Du",
        "Jiawei Jiang"
      ],
      "abstract": "Text-attributed graph (TAG) is an important type of graph structured data\nwith text descriptions for each node. Few- and zero-shot node classification on\nTAGs have many applications in fields such as academia and social networks.\nHowever, the two tasks are challenging due to the lack of supervision signals,\nand existing methods only use the contrastive loss to align graph-based node\nembedding and language-based text embedding. In this paper, we propose Hound to\nimprove accuracy by introducing more supervision signals, and the core idea is\nto go beyond the node-text pairs that come with data. Specifically, we design\nthree augmentation techniques, i.e., node perturbation, text matching, and\nsemantics negation to provide more reference nodes for each text and vice\nversa. Node perturbation adds/drops edges to produce diversified node\nembeddings that can be matched with a text. Text matching retrieves texts with\nsimilar embeddings to match with a node. Semantics negation uses a negative\nprompt to construct a negative text with the opposite semantics, which is\ncontrasted with the original node and text. We evaluate Hound on 5 datasets and\ncompare with 13 state-of-the-art baselines. The results show that Hound\nconsistently outperforms all baselines, and its accuracy improvements over the\nbest-performing baseline are usually over 5%.",
      "tldr_zh": "这篇论文针对 Text-attributed Graph (TAG) 中的 Few-shot 和 Zero-shot Node Classification 问题，提出 Hound 方法，通过引入更多监督信号来解决现有方法的局限性。Hound 的核心创新包括三种增强技术：Node Perturbation（添加/删除边以生成多样化节点嵌入）、Text Matching（检索相似文本嵌入与节点匹配），以及 Semantics Negation（使用负面提示构建语义相反文本进行对比），从而提供超越原始节点-文本对的额外参考。实验结果显示，在 5 个数据集上，Hound 比 13 个最先进基线准确率提高了超过 5%，证明了其有效性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.00727v1",
      "published_date": "2024-09-01 14:20:01 UTC",
      "updated_date": "2024-09-01 14:20:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:29:21.093809"
    },
    {
      "arxiv_id": "2409.00726v1",
      "title": "LPUWF-LDM: Enhanced Latent Diffusion Model for Precise Late-phase UWF-FA Generation on Limited Dataset",
      "title_zh": "翻译失败",
      "authors": [
        "Zhaojie Fang",
        "Xiao Yu",
        "Guanyu Zhou",
        "Ke Zhuang",
        "Yifei Chen",
        "Ruiquan Ge",
        "Changmiao Wang",
        "Gangyong Jia",
        "Qing Wu",
        "Juan Ye",
        "Maimaiti Nuliqiman",
        "Peifang Xu",
        "Ahmed Elazab"
      ],
      "abstract": "Ultra-Wide-Field Fluorescein Angiography (UWF-FA) enables precise\nidentification of ocular diseases using sodium fluorescein, which can be\npotentially harmful. Existing research has developed methods to generate UWF-FA\nfrom Ultra-Wide-Field Scanning Laser Ophthalmoscopy (UWF-SLO) to reduce the\nadverse reactions associated with injections. However, these methods have been\nless effective in producing high-quality late-phase UWF-FA, particularly in\nlesion areas and fine details. Two primary challenges hinder the generation of\nhigh-quality late-phase UWF-FA: the scarcity of paired UWF-SLO and\nearly/late-phase UWF-FA datasets, and the need for realistic generation at\nlesion sites and potential blood leakage regions. This study introduces an\nimproved latent diffusion model framework to generate high-quality late-phase\nUWF-FA from limited paired UWF images. To address the challenges as mentioned\nearlier, our approach employs a module utilizing Cross-temporal Regional\nDifference Loss, which encourages the model to focus on the differences between\nearly and late phases. Additionally, we introduce a low-frequency enhanced\nnoise strategy in the diffusion forward process to improve the realism of\nmedical images. To further enhance the mapping capability of the variational\nautoencoder module, especially with limited datasets, we implement a Gated\nConvolutional Encoder to extract additional information from conditional\nimages. Our Latent Diffusion Model for Ultra-Wide-Field Late-Phase Fluorescein\nAngiography (LPUWF-LDM) effectively reconstructs fine details in late-phase\nUWF-FA and achieves state-of-the-art results compared to other existing methods\nwhen working with limited datasets. Our source code is available at:\nhttps://github.com/Tinysqua/****.",
      "tldr_zh": "本文提出 LPUWF-LDM，一种增强的 Latent Diffusion Model，用于从有限的配对 UWF-SLO 和 UWF-FA 数据集生成高质量晚期相 UWF-FA，从而减少荧光素注射的潜在副作用。该框架通过引入 Cross-temporal Regional Difference Loss 模块来关注早晚期图像差异、采用低频增强噪声策略提升医疗图像真实性，以及使用 Gated Convolutional Encoder 改进变分自动编码器的映射能力，以更好地处理病变区域和细节。实验结果表明，LPUWF-LDM 在有限数据集上实现了最先进的效果，精确重建晚期相 UWF-FA 的精细细节，并提供开源代码以供进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.00726v1",
      "published_date": "2024-09-01 14:09:00 UTC",
      "updated_date": "2024-09-01 14:09:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:29:35.189289"
    },
    {
      "arxiv_id": "2409.00724v1",
      "title": "BUET Multi-disease Heart Sound Dataset: A Comprehensive Auscultation Dataset for Developing Computer-Aided Diagnostic Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Shams Nafisa Ali",
        "Afia Zahin",
        "Samiul Based Shuvo",
        "Nusrat Binta Nizam",
        "Shoyad Ibn Sabur Khan Nuhash",
        "Sayeed Sajjad Razin",
        "S. M. Sakeef Sani",
        "Farihin Rahman",
        "Nawshad Binta Nizam",
        "Farhat Binte Azam",
        "Rakib Hossen",
        "Sumaiya Ohab",
        "Nawsabah Noor",
        "Taufiq Hasan"
      ],
      "abstract": "Cardiac auscultation, an integral tool in diagnosing cardiovascular diseases\n(CVDs), often relies on the subjective interpretation of clinicians, presenting\na limitation in consistency and accuracy. Addressing this, we introduce the\nBUET Multi-disease Heart Sound (BMD-HS) dataset - a comprehensive and\nmeticulously curated collection of heart sound recordings. This dataset,\nencompassing 864 recordings across five distinct classes of common heart\nsounds, represents a broad spectrum of valvular heart diseases, with a focus on\ndiagnostically challenging cases. The standout feature of the BMD-HS dataset is\nits innovative multi-label annotation system, which captures a diverse range of\ndiseases and unique disease states. This system significantly enhances the\ndataset's utility for developing advanced machine learning models in automated\nheart sound classification and diagnosis. By bridging the gap between\ntraditional auscultation practices and contemporary data-driven diagnostic\nmethods, the BMD-HS dataset is poised to revolutionize CVD diagnosis and\nmanagement, providing an invaluable resource for the advancement of cardiac\nhealth research. The dataset is publicly available at this link:\nhttps://github.com/mHealthBuet/BMD-HS-Dataset.",
      "tldr_zh": "本研究介绍了BUET Multi-disease Heart Sound (BMD-HS)数据集，这是一个全面且精心策划的心音录音集合，旨在解决传统心脏听诊主观性和准确性问题。数据集包含864条录音，涵盖五类常见心音和多种瓣膜心脏病，尤其是诊断挑战性病例，并采用创新的多标签注释系统来捕捉多样化的疾病状态。该数据集可用于开发先进的机器学习模型，实现自动化心音分类和诊断，从而桥接传统方法与数据驱动技术，并已公开提供于https://github.com/mHealthBuet/BMD-HS-Dataset链接。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "eess.SP",
      "comment": "14 pages, 13 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.00724v1",
      "published_date": "2024-09-01 13:55:04 UTC",
      "updated_date": "2024-09-01 13:55:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:29:43.528491"
    },
    {
      "arxiv_id": "2409.00721v1",
      "title": "Who Would Chatbots Vote For? Political Preferences of ChatGPT and Gemini in the 2024 European Union Elections",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Haman",
        "Milan Školník"
      ],
      "abstract": "This study examines the political bias of chatbots powered by large language\nmodels, namely ChatGPT and Gemini, in the context of the 2024 European\nParliament elections. The research focused on the evaluation of political\nparties represented in the European Parliament across 27 EU Member States by\nthese generative artificial intelligence (AI) systems. The methodology involved\ndaily data collection through standardized prompts on both platforms. The\nresults revealed a stark contrast: while Gemini mostly refused to answer\npolitical questions, ChatGPT provided consistent ratings. The analysis showed a\nsignificant bias in ChatGPT in favor of left-wing and centrist parties, with\nthe highest ratings for the Greens/European Free Alliance. In contrast,\nright-wing parties, particularly the Identity and Democracy group, received the\nlowest ratings. The study identified key factors influencing the ratings,\nincluding attitudes toward European integration and perceptions of democratic\nvalues. The findings highlight the need for a critical approach to information\nprovided by generative AI systems in a political context and call for more\ntransparency and regulation in this area.",
      "tldr_zh": "这篇研究调查了 ChatGPT 和 Gemini 在 2024 年欧盟议会选举中的政治偏见，通过标准化提示对 27 个欧盟成员国的政党进行日常评估。结果显示，Gemini 大多拒绝回答政治问题，而 ChatGPT 表现出明显的偏向，给予左翼和中间派政党（如 Greens/European Free Alliance）较高评分。相反，右翼政党（如 Identity and Democracy）获得最低评分，主要受欧洲一体化态度和民主价值观的影响。该研究强调了在政治语境中使用生成式 AI 的潜在风险，并呼吁加强透明度和监管。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.00721v1",
      "published_date": "2024-09-01 13:40:13 UTC",
      "updated_date": "2024-09-01 13:40:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:29:58.975694"
    },
    {
      "arxiv_id": "2409.00718v1",
      "title": "Multiscale Color Guided Attention Ensemble Classifier for Age-Related Macular Degeneration using Concurrent Fundus and Optical Coherence Tomography Images",
      "title_zh": "翻译失败",
      "authors": [
        "Pragya Gupta",
        "Subhamoy Mandal",
        "Debashree Guha",
        "Debjani Chakraborty"
      ],
      "abstract": "Automatic diagnosis techniques have evolved to identify age-related macular\ndegeneration (AMD) by employing single modality Fundus images or optical\ncoherence tomography (OCT). To classify ocular diseases, fundus and OCT images\nare the most crucial imaging modalities used in the clinical setting. Most deep\nlearning-based techniques are established on a single imaging modality, which\ncontemplates the ocular disorders to a specific extent and disregards other\nmodality that comprises exhaustive information among distinct imaging\nmodalities. This paper proposes a modality-specific multiscale color space\nembedding integrated with the attention mechanism based on transfer learning\nfor classification (MCGAEc), which can efficiently extract the distinct\nmodality information at various scales using the distinct color spaces. In this\nwork, we first introduce the modality-specific multiscale color space encoder\nmodel, which includes diverse feature representations by integrating distinct\ncharacteristic color spaces on a multiscale into a unified framework. The\nextracted features from the prior encoder module are incorporated with the\nattention mechanism to extract the global features representation, which is\nintegrated with the prior extracted features and transferred to the random\nforest classifier for the classification of AMD. To analyze the performance of\nthe proposed MCGAEc method, a publicly available multi-modality dataset from\nProject Macula for AMD is utilized and compared with the existing models.",
      "tldr_zh": "本文提出了一种名为 MCGAEc 的多模态分类器，用于诊断 Age-Related Macular Degeneration (AMD)，它结合 Fundus 和 Optical Coherence Tomography (OCT) 图像，通过模态特定的多尺度颜色空间嵌入和 attention mechanism 提取特征。方法首先利用多尺度颜色空间编码器整合不同颜色空间的特征表示，然后通过 attention mechanism 增强全局特征，并将这些特征输入随机森林分类器进行 AMD 分类。与现有基于单一模态的深度学习模型相比，MCGAEc 在 Project Macula 数据集上表现出更高效的性能，提高了诊断准确性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "27th International Conference on Pattern Recognition (ICPR) 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.00718v1",
      "published_date": "2024-09-01 13:17:45 UTC",
      "updated_date": "2024-09-01 13:17:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:30:23.655420"
    },
    {
      "arxiv_id": "2409.00717v3",
      "title": "Preference-Based Multi-Agent Reinforcement Learning: Data Coverage and Algorithmic Techniques",
      "title_zh": "基于偏好的多智能体强化学习：数据覆盖和算法技术",
      "authors": [
        "Natalia Zhang",
        "Xinqi Wang",
        "Qiwen Cui",
        "Runlong Zhou",
        "Sham M. Kakade",
        "Simon S. Du"
      ],
      "abstract": "We initiate the study of Preference-Based Multi-Agent Reinforcement Learning\n(PbMARL), exploring both theoretical foundations and empirical validations. We\ndefine the task as identifying the Nash equilibrium from a preference-only\noffline dataset in general-sum games, a problem marked by the challenge of\nsparse feedback signals. Our theory establishes the upper complexity bounds for\nNash Equilibrium in effective PbMARL, demonstrating that single-policy coverage\nis inadequate and highlighting the importance of unilateral dataset coverage.\nThese theoretical insights are verified through comprehensive experiments. To\nenhance the practical performance, we further introduce two algorithmic\ntechniques. (1) We propose a Mean Squared Error (MSE) regularization along the\ntime axis to achieve a more uniform reward distribution and improve reward\nlearning outcomes. (2) We propose an additional penalty based on the\ndistribution of the dataset to incorporate pessimism, improving stability and\neffectiveness during training. Our findings underscore the multifaceted\napproach required for PbMARL, paving the way for effective preference-based\nmulti-agent systems.",
      "tldr_zh": "本文研究了 Preference-Based Multi-Agent Reinforcement Learning (PbMARL)，旨在从偏好-only 离线数据集识别 Nash Equilibrium，并应对一般和游戏中稀疏反馈信号的挑战。理论分析建立了 PbMARL 的上界复杂度，证明单策略覆盖不足，并强调了单方面数据集覆盖的重要性，这些见解通过全面实验得到验证。为提升实际性能，作者提出了两种算法技巧：（1）沿时间轴的 Mean Squared Error (MSE) 正则化，以实现更均匀的奖励分布并改善奖励学习；（2）基于数据集分布的额外惩罚，融入悲观主义以增强训练的稳定性和有效性。这些发现为构建有效的偏好-based 多智能体系统提供了多方面方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.GT",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.00717v3",
      "published_date": "2024-09-01 13:14:41 UTC",
      "updated_date": "2025-01-09 11:24:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:30:23.491661"
    },
    {
      "arxiv_id": "2409.00707v1",
      "title": "ReMOVE: A Reference-free Metric for Object Erasure",
      "title_zh": "翻译失败",
      "authors": [
        "Aditya Chandrasekar",
        "Goirik Chakrabarty",
        "Jai Bardhan",
        "Ramya Hebbalaguppe",
        "Prathosh AP"
      ],
      "abstract": "We introduce $\\texttt{ReMOVE}$, a novel reference-free metric for assessing\nobject erasure efficacy in diffusion-based image editing models\npost-generation. Unlike existing measures such as LPIPS and CLIPScore,\n$\\texttt{ReMOVE}$ addresses the challenge of evaluating inpainting without a\nreference image, common in practical scenarios. It effectively distinguishes\nbetween object removal and replacement. This is a key issue in diffusion models\ndue to stochastic nature of image generation. Traditional metrics fail to align\nwith the intuitive definition of inpainting, which aims for (1) seamless object\nremoval within masked regions (2) while preserving the background continuity.\n$\\texttt{ReMOVE}$ not only correlates with state-of-the-art metrics and aligns\nwith human perception but also captures the nuanced aspects of the inpainting\nprocess, providing a finer-grained evaluation of the generated outputs.",
      "tldr_zh": "本研究引入了 ReMOVE，这是一个新型的无参考指标，用于评估基于扩散的图像编辑模型中对象擦除的有效性。不同于传统指标如 LPIPS 和 CLIPScore，ReMOVE 无需参考图像即可区分对象移除与替换，解决了扩散模型随机性带来的挑战，并确保无缝移除对象同时保持背景连续性。该指标不仅与最先进指标高度相关，还与人类感知一致，提供更细粒度的图像修复评估结果。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at The First Workshop on the Evaluation of Generative\n  Foundation Models (EvGENFM) at CVPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.00707v1",
      "published_date": "2024-09-01 12:26:14 UTC",
      "updated_date": "2024-09-01 12:26:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:30:35.387750"
    },
    {
      "arxiv_id": "2409.00706v1",
      "title": "Abstaining Machine Learning -- Philosophical Considerations",
      "title_zh": "翻译失败",
      "authors": [
        "Daniela Schuster"
      ],
      "abstract": "This paper establishes a connection between the fields of machine learning\n(ML) and philosophy concerning the phenomenon of behaving neutrally. It\ninvestigates a specific class of ML systems capable of delivering a neutral\nresponse to a given task, referred to as abstaining machine learning systems,\nthat has not yet been studied from a philosophical perspective. The paper\nintroduces and explains various abstaining machine learning systems, and\ncategorizes them into distinct types. An examination is conducted on how\nabstention in the different machine learning system types aligns with the\nepistemological counterpart of suspended judgment, addressing both the nature\nof suspension and its normative profile. Additionally, a philosophical analysis\nis suggested on the autonomy and explainability of the abstaining response. It\nis argued, specifically, that one of the distinguished types of abstaining\nsystems is preferable as it aligns more closely with our criteria for suspended\njudgment. Moreover, it is better equipped to autonomously generate abstaining\noutputs and offer explanations for abstaining outputs when compared to the\nother type.",
      "tldr_zh": "这篇论文探讨了机器学习（ML）和哲学之间的联系，聚焦于中性行为或 abstaining（回避判断）的现象，引入了 abstaining machine learning systems 这一尚未从哲学角度深入研究的类别。论文对这些系统进行了分类和解释，并分析 abstention 如何与哲学上的 suspended judgment（悬置判断）相对应，包括其性质、规范性和自主性。最终，论文论证了一种特定类型的 abstaining 系统更优，因为它更符合 suspended judgment 的标准，并在自主生成 abstaining 输出以及提供解释方面表现出色。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Part of the published PhD Thesis: Daniela Schuster. Suspension of\n  Judgment in Artificial Intelligence-Uncovering Uncertainty in Data-Based and\n  Logic-Based Systems. PhD thesis, University of Konstanz, 2024.\n  http://nbn-resolving.de/urn:nbn:de:bsz:352-2-1r3gwq4l5jlwr2",
      "pdf_url": "http://arxiv.org/pdf/2409.00706v1",
      "published_date": "2024-09-01 12:25:06 UTC",
      "updated_date": "2024-09-01 12:25:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:30:46.896724"
    },
    {
      "arxiv_id": "2409.10542v3",
      "title": "SAM4MLLM: Enhance Multi-Modal Large Language Model for Referring Expression Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Yi-Chia Chen",
        "Wei-Hua Li",
        "Cheng Sun",
        "Yu-Chiang Frank Wang",
        "Chu-Song Chen"
      ],
      "abstract": "We introduce SAM4MLLM, an innovative approach which integrates the Segment\nAnything Model (SAM) with Multi-Modal Large Language Models (MLLMs) for\npixel-aware tasks. Our method enables MLLMs to learn pixel-level location\ninformation without requiring excessive modifications to the existing model\narchitecture or adding specialized tokens. We introduce an inquiry-based\napproach that can effectively find prompt points for SAM to perform\nsegmentation based on MLLM. It combines detailed visual information with the\npowerful expressive capabilities of large language models in a unified\nlanguage-based manner without additional computational overhead in learning.\nExperimental results on pubic benchmarks demonstrate the effectiveness of our\napproach.",
      "tldr_zh": "该论文提出 SAM4MLLM，一种创新方法，将 Segment Anything Model (SAM) 与 Multi-Modal Large Language Models (MLLMs) 整合，用于提升 Referring Expression Segmentation 的性能。该方法通过一种基于查询的查询（inquiry-based）策略，使 MLLMs 能够学习像素级位置信息，而无需对现有模型架构进行大量修改或添加专用标记，从而以统一的语言方式结合详细视觉信息和语言模型的表达能力。实验结果在公共基准上证明了该方法的有效性，为像素感知任务提供了高效的解决方案。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.10542v3",
      "published_date": "2024-09-01 12:09:33 UTC",
      "updated_date": "2024-12-14 03:18:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:30:58.434064"
    },
    {
      "arxiv_id": "2409.00700v1",
      "title": "Seeing Your Speech Style: A Novel Zero-Shot Identity-Disentanglement Face-based Voice Conversion",
      "title_zh": "翻译失败",
      "authors": [
        "Yan Rong",
        "Li Liu"
      ],
      "abstract": "Face-based Voice Conversion (FVC) is a novel task that leverages facial\nimages to generate the target speaker's voice style. Previous work has two\nshortcomings: (1) suffering from obtaining facial embeddings that are\nwell-aligned with the speaker's voice identity information, and (2) inadequacy\nin decoupling content and speaker identity information from the audio input. To\naddress these issues, we present a novel FVC method, Identity-Disentanglement\nFace-based Voice Conversion (ID-FaceVC), which overcomes the above two\nlimitations. More precisely, we propose an Identity-Aware Query-based\nContrastive Learning (IAQ-CL) module to extract speaker-specific facial\nfeatures, and a Mutual Information-based Dual Decoupling (MIDD) module to\npurify content features from audio, ensuring clear and high-quality voice\nconversion. Besides, unlike prior works, our method can accept either audio or\ntext inputs, offering controllable speech generation with adjustable emotional\ntone and speed. Extensive experiments demonstrate that ID-FaceVC achieves\nstate-of-the-art performance across various metrics, with qualitative and user\nstudy results confirming its effectiveness in naturalness, similarity, and\ndiversity. Project website with audio samples and code can be found at\nhttps://id-facevc.github.io.",
      "tldr_zh": "这篇论文提出了一种新的零样本身份解耦方法，名为 Identity-Disentanglement Face-based Voice Conversion (ID-FaceVC)，用于 Face-based Voice Conversion (FVC)，它解决了现有方法的两个主要问题：脸部嵌入与语音身份信息不对齐，以及音频中内容和身份信息的解耦不足。ID-FaceVC 引入了 Identity-Aware Query-based Contrastive Learning (IAQ-CL) 模块来提取说话者特定的脸部特征，以及 Mutual Information-based Dual Decoupling (MIDD) 模块来净化音频内容特征，从而实现高质量的语音转换。该方法支持音频或文本输入，提供可控的语音生成，包括调整情感语气和速度；实验结果显示，ID-FaceVC 在各种指标上达到最先进性能，用户研究进一步验证了其在自然度、相似度和多样性方面的有效性。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CV",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.00700v1",
      "published_date": "2024-09-01 11:51:18 UTC",
      "updated_date": "2024-09-01 11:51:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:31:13.932870"
    },
    {
      "arxiv_id": "2409.00696v3",
      "title": "Polyrating: A Cost-Effective and Bias-Aware Rating System for LLM Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Jasper Dekoninck",
        "Maximilian Baader",
        "Martin Vechev"
      ],
      "abstract": "Rating-based human evaluation has become an essential tool to accurately\nevaluate the impressive performance of large language models (LLMs). However,\ncurrent rating systems suffer from several important limitations: first, they\nfail to account for biases that significantly influence evaluation results,\nsecond, they require large and expensive preference datasets to obtain accurate\nratings, and third, they do not facilitate meaningful comparisons of model\nratings across different tasks. To address these issues, we introduce\nPolyrating, an expressive and flexible rating system based on maximum a\nposteriori estimation that enables a more nuanced and thorough analysis of\nmodel performance at lower costs. Polyrating can detect and quantify biases\naffecting human preferences, ensuring fairer model comparisons. Further,\nPolyrating can reduce the cost of human evaluations by up to $41\\%$ for new\nmodels and up to $77\\%$ for new tasks by leveraging existing benchmark scores.\nLastly, Polyrating enables direct comparisons of ratings across different\ntasks, providing a comprehensive understanding of an LLMs' strengths,\nweaknesses, and relative performance across different applications.",
      "tldr_zh": "本文提出 Polyrating，一种基于 maximum a posteriori estimation 的评分系统，用于评估大型语言模型(LLM)，旨在解决现有系统忽略偏见、依赖昂贵数据集以及无法跨任务比较的问题。Polyrating 通过检测和量化影响人类偏好的偏见，确保更公平且细致的模型性能分析。相比传统方法，它可将人类评估成本降低最多 41% 对于新模型和 77% 对于新任务，并支持直接比较不同任务中的模型表现，提供对 LLM 优势、劣势和相对性能的全面理解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.00696v3",
      "published_date": "2024-09-01 11:24:54 UTC",
      "updated_date": "2025-02-11 12:21:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:31:22.950835"
    },
    {
      "arxiv_id": "2409.00695v1",
      "title": "Curriculum Prompting Foundation Models for Medical Image Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Xiuqi Zheng",
        "Yuhang Zhang",
        "Haoran Zhang",
        "Hongrui Liang",
        "Xueqi Bao",
        "Zhuqing Jiang",
        "Qicheng Lao"
      ],
      "abstract": "Adapting large pre-trained foundation models, e.g., SAM, for medical image\nsegmentation remains a significant challenge. A crucial step involves the\nformulation of a series of specialized prompts that incorporate specific\nclinical instructions. Past works have been heavily reliant on a singular type\nof prompt for each instance, necessitating manual input of an ideally correct\nprompt, which is less efficient. To tackle this issue, we propose to utilize\nprompts of different granularity, which are sourced from original images to\nprovide a broader scope of clinical insights. However, combining prompts of\nvarying types can pose a challenge due to potential conflicts. In response, we\nhave designed a coarse-to-fine mechanism, referred to as curriculum prompting,\nthat progressively integrates prompts of different types. Through extensive\nexperiments on three public medical datasets across various modalities, we\ndemonstrate the effectiveness of our proposed approach, which not only\nautomates the prompt generation process but also yields superior performance\ncompared to other SAM-based medical image segmentation methods. Code is\navailable at: https://github.com/AnnaZzz-zxq/Curriculum-Prompting.",
      "tldr_zh": "本文提出一种名为 curriculum prompting 的方法，用于适应预训练基础模型（如 SAM）应用于医疗图像分割。该方法利用不同粒度的提示，从原始图像中提取更广泛的临床洞见，并通过粗到细的机制逐步整合这些提示，以避免潜在冲突。相比过去依赖单一提示的手动输入方式，该方法实现了提示生成的自动化。实验结果显示，在三个公共医疗数据集上，该方法优于其他 SAM 基于的分割技术，显著提升了性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by MICCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.00695v1",
      "published_date": "2024-09-01 11:00:18 UTC",
      "updated_date": "2024-09-01 11:00:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:31:34.125964"
    },
    {
      "arxiv_id": "2409.00687v1",
      "title": "When Heterophily Meets Heterogeneous Graphs: Latent Graphs Guided Unsupervised Representation Learning",
      "title_zh": "当异质性遇到异构图：潜在图指导的无监督表示学习",
      "authors": [
        "Zhixiang Shen",
        "Zhao Kang"
      ],
      "abstract": "Unsupervised heterogeneous graph representation learning (UHGRL) has gained\nincreasing attention due to its significance in handling practical graphs\nwithout labels. However, heterophily has been largely ignored, despite its\nubiquitous presence in real-world heterogeneous graphs. In this paper, we\ndefine semantic heterophily and propose an innovative framework called Latent\nGraphs Guided Unsupervised Representation Learning (LatGRL) to handle this\nproblem. First, we develop a similarity mining method that couples global\nstructures and attributes, enabling the construction of fine-grained homophilic\nand heterophilic latent graphs to guide the representation learning. Moreover,\nwe propose an adaptive dual-frequency semantic fusion mechanism to address the\nproblem of node-level semantic heterophily. To cope with the massive scale of\nreal-world data, we further design a scalable implementation. Extensive\nexperiments on benchmark datasets validate the effectiveness and efficiency of\nour proposed framework. The source code and datasets have been made available\nat https://github.com/zxlearningdeep/LatGRL.",
      "tldr_zh": "这篇论文探讨了无监督异构图表示学习（UHGRL）中异质性（heterophily）的忽略问题，定义了语义异质性（semantic heterophily）并提出了一种创新框架Latent Graphs Guided Unsupervised Representation Learning (LatGRL)。框架通过一种结合全局结构和属性的相似性挖掘方法，构建细粒度的同质性和异质性潜在图（latent graphs）来指导表示学习，同时引入自适应双频语义融合机制（adaptive dual-frequency semantic fusion mechanism）处理节点级语义异质性，并设计了可扩展实现（scalable implementation）以适应大规模数据。实验在基准数据集上验证了LatGRL的有效性和效率，并提供了开源代码和数据集。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.00687v1",
      "published_date": "2024-09-01 10:25:06 UTC",
      "updated_date": "2024-09-01 10:25:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:31:46.850721"
    },
    {
      "arxiv_id": "2409.10541v1",
      "title": "Adapting to the AI Disruption: Reshaping the IT Landscape and Educational Paradigms",
      "title_zh": "翻译失败",
      "authors": [
        "Murat Ozer",
        "Yasin Kose",
        "Goksel Kucukkaya",
        "Assel Mukasheva",
        "Kazim Ciris"
      ],
      "abstract": "Artificial intelligence (AI) signals the beginning of a revolutionary period\nwhere technological advancement and social change interact to completely\nreshape economies, work paradigms, and industries worldwide. This essay\naddresses the opportunities and problems brought about by the AI-driven economy\nas it examines the effects of AI disruption on the IT sector and information\ntechnology education. By comparing the current AI revolution to previous\nindustrial revolutions, we investigate the significant effects of AI\ntechnologies on workforce dynamics, employment, and organizational procedures.\nHuman-centered design principles and ethical considerations become crucial\nrequirements for the responsible development and implementation of AI systems\nin the face of the field's rapid advancements. IT education programs must\nchange to meet the changing demands of the AI era and give students the skills\nand competencies they need to succeed in a digital world that is changing\nquickly. In light of AI-driven automation, we also examine the possible\nadvantages and difficulties of moving to a shorter workweek, emphasizing\nchances to improve worker productivity, well-being, and work-life balance. We\ncan build a more incslusive and sustainable future for the IT industry and\nbeyond, enhancing human capabilities, advancing collective well-being, and\nfostering a society where AI serves as a force for good by embracing the\nopportunities presented by AI while proactively addressing its challenges.",
      "tldr_zh": "这篇论文探讨了人工智能（AI）如何引发革命性变革，重塑 IT 行业景观和教育范式，包括对劳动力动态、就业和组织流程的影响，并将 AI 革命与历史工业革命进行比较。论文强调人类中心设计（Human-centered design）和伦理考虑（Ethical considerations）在 AI 系统开发中的关键作用，以应对快速变革带来的挑战。作者建议改革 IT 教育以培养适应数字时代的技能，并分析缩短工作周的潜在优势，如提升员工生产力和工作生活平衡，最终推动一个更具包容性和可持续的未来。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "Submitted and accepted for CSCE'24: July 22-25, 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.10541v1",
      "published_date": "2024-09-01 09:39:25 UTC",
      "updated_date": "2024-09-01 09:39:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:32:02.505181"
    },
    {
      "arxiv_id": "2409.00667v1",
      "title": "Comprehensive Botnet Detection by Mitigating Adversarial Attacks, Navigating the Subtleties of Perturbation Distances and Fortifying Predictions with Conformal Layers",
      "title_zh": "翻译失败",
      "authors": [
        "Rahul Yumlembam",
        "Biju Issac",
        "Seibu Mary Jacob",
        "Longzhi Yang"
      ],
      "abstract": "Botnets are computer networks controlled by malicious actors that present\nsignificant cybersecurity challenges. They autonomously infect, propagate, and\ncoordinate to conduct cybercrimes, necessitating robust detection methods. This\nresearch addresses the sophisticated adversarial manipulations posed by\nattackers, aiming to undermine machine learning-based botnet detection systems.\nWe introduce a flow-based detection approach, leveraging machine learning and\ndeep learning algorithms trained on the ISCX and ISOT datasets. The detection\nalgorithms are optimized using the Genetic Algorithm and Particle Swarm\nOptimization to obtain a baseline detection method. The Carlini & Wagner (C&W)\nattack and Generative Adversarial Network (GAN) generate deceptive data with\nsubtle perturbations, targeting each feature used for classification while\npreserving their semantic and syntactic relationships, which ensures that the\nadversarial samples retain meaningfulness and realism. An in-depth analysis of\nthe required L2 distance from the original sample for the malware sample to\nmisclassify is performed across various iteration checkpoints, showing\ndifferent levels of misclassification at different L2 distances of the Pertrub\nsample from the original sample. Our work delves into the vulnerability of\nvarious models, examining the transferability of adversarial examples from a\nNeural Network surrogate model to Tree-based algorithms. Subsequently, models\nthat initially misclassified the perturbed samples are retrained, enhancing\ntheir resilience and detection capabilities. In the final phase, a conformal\nprediction layer is integrated, significantly rejecting incorrect predictions,\nof 58.20 % in the ISCX dataset and 98.94 % in the ISOT dataset.",
      "tldr_zh": "本研究针对 botnet 检测面临的对抗攻击问题，提出了一种全面的流基于检测方法，使用机器学习和深度学习算法（如 Genetic Algorithm 和 Particle Swarm Optimization）优化基线模型，并基于 ISCX 和 ISOT 数据集进行训练。研究通过 C&W attack 和 GAN 生成具有微小扰动的对抗样本，分析 L2 distance 对误分类的影响，并评估对抗样本从神经网络模型向树-based 算法的转移性，同时对易受攻击模型进行重训练以提升鲁棒性。最终，集成 conformal prediction 层显著拒绝了不正确预测（ISCX 数据集 58.20%、ISOT 数据集 98.94%），从而强化了 botnet 检测系统的准确性和可靠性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "46 pages",
      "pdf_url": "http://arxiv.org/pdf/2409.00667v1",
      "published_date": "2024-09-01 08:53:21 UTC",
      "updated_date": "2024-09-01 08:53:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:32:16.844847"
    },
    {
      "arxiv_id": "2409.00658v1",
      "title": "Nasdaq-100 Companies' Hiring Insights: A Topic-based Classification Approach to the Labor Market",
      "title_zh": "翻译失败",
      "authors": [
        "Seyed Mohammad Ali Jafari",
        "Ehsan Chitsaz"
      ],
      "abstract": "The emergence of new and disruptive technologies makes the economy and labor\nmarket more unstable. To overcome this kind of uncertainty and to make the\nlabor market more comprehensible, we must employ labor market intelligence\ntechniques, which are predominantly based on data analysis. Companies use job\nposting sites to advertise their job vacancies, known as online job vacancies\n(OJVs). LinkedIn is one of the most utilized websites for matching the supply\nand demand sides of the labor market; companies post their job vacancies on\ntheir job pages, and LinkedIn recommends these jobs to job seekers who are\nlikely to be interested. However, with the vast number of online job vacancies,\nit becomes challenging to discern overarching trends in the labor market. In\nthis paper, we propose a data mining-based approach for job classification in\nthe modern online labor market. We employed structural topic modeling as our\nmethodology and used the NASDAQ-100 indexed companies' online job vacancies on\nLinkedIn as the input data. We discover that among all 13 job categories,\nMarketing, Branding, and Sales; Software Engineering; Hardware Engineering;\nIndustrial Engineering; and Project Management are the most frequently posted\njob classifications. This study aims to provide a clearer understanding of job\nmarket trends, enabling stakeholders to make informed decisions in a rapidly\nevolving employment landscape.",
      "tldr_zh": "本研究针对新技术导致的劳动力市场不确定性，提出了一种基于数据挖掘的职位分类方法，使用 structural topic modeling 分析 Nasdaq-100 公司在线职位空缺（OJVs）数据。研究发现，在13个职位类别中，Marketing, Branding, and Sales；Software Engineering；Hardware Engineering；Industrial Engineering；以及 Project Management 是最常发布的类别。总体而言，此方法有助于利益相关者更清晰地理解就业趋势，并在快速变化的劳动力市场中做出明智决策。",
      "categories": [
        "econ.GN",
        "cs.AI",
        "q-fin.EC"
      ],
      "primary_category": "econ.GN",
      "comment": "17 pages, 4 figures, 1 table. Presented at the International\n  Conference on Optimization and Data Science in Industrial Engineering (ODSIE\n  2023)",
      "pdf_url": "http://arxiv.org/pdf/2409.00658v1",
      "published_date": "2024-09-01 08:18:56 UTC",
      "updated_date": "2024-09-01 08:18:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:32:23.515247"
    },
    {
      "arxiv_id": "2409.00639v1",
      "title": "Artificial Intelligence in Gastrointestinal Bleeding Analysis for Video Capsule Endoscopy: Insights, Innovations, and Prospects (2008-2023)",
      "title_zh": "人工智能在视频胶囊内镜的胃肠道出血分析中的应用：见解、创新和前景 (2008",
      "authors": [
        "Tanisha Singh",
        "Shreshtha Jha",
        "Nidhi Bhatt",
        "Palak Handa",
        "Nidhi Goel",
        "Sreedevi Indu"
      ],
      "abstract": "The escalating global mortality and morbidity rates associated with\ngastrointestinal (GI) bleeding, compounded by the complexities and limitations\nof traditional endoscopic methods, underscore the urgent need for a critical\nreview of current methodologies used for addressing this condition. With an\nestimated 300,000 annual deaths worldwide, the demand for innovative diagnostic\nand therapeutic strategies is paramount. The introduction of Video Capsule\nEndoscopy (VCE) has marked a significant advancement, offering a comprehensive,\nnon-invasive visualization of the digestive tract that is pivotal for detecting\nbleeding sources unattainable by traditional methods. Despite its benefits, the\nefficacy of VCE is hindered by diagnostic challenges, including time-consuming\nanalysis and susceptibility to human error. This backdrop sets the stage for\nexploring Machine Learning (ML) applications in automating GI bleeding\ndetection within capsule endoscopy, aiming to enhance diagnostic accuracy,\nreduce manual labor, and improve patient outcomes. Through an exhaustive\nanalysis of 113 papers published between 2008 and 2023, this review assesses\nthe current state of ML methodologies in bleeding detection, highlighting their\neffectiveness, challenges, and prospective directions. It contributes an\nin-depth examination of AI techniques in VCE frame analysis, offering insights\ninto open-source datasets, mathematical performance metrics, and technique\ncategorization. The paper sets a foundation for future research to overcome\nexisting challenges, advancing gastrointestinal diagnostics through\ninterdisciplinary collaboration and innovation in ML applications.",
      "tldr_zh": "这篇综述论文分析了人工智能（AI）在视频胶囊内镜（VCE）中用于胃肠道（GI）出血检测的进展与前景，涵盖2008-2023年间113篇文献。论文强调GI出血的高死亡率（全球每年约30万例）及其传统方法的局限性，并探讨Machine Learning (ML)技术如何通过自动化分析提升诊断准确性、减少人为错误和手动工作量。研究评估了ML方法在VCE帧分析中的有效性，包括开源数据集、数学性能指标和技术分类，同时识别了现有挑战，如分析耗时问题。最终，该论文为未来AI应用提供基础，呼吁通过跨学科合作推动GI诊断创新。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.00639v1",
      "published_date": "2024-09-01 07:13:28 UTC",
      "updated_date": "2024-09-01 07:13:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:32:36.819055"
    },
    {
      "arxiv_id": "2409.02124v1",
      "title": "TrajWeaver: Trajectory Recovery with State Propagation Diffusion Model",
      "title_zh": "翻译失败",
      "authors": [
        "Jinming Wang",
        "Hai Wang",
        "Hongkai Wen",
        "Geyong Min",
        "Man Luo"
      ],
      "abstract": "With the proliferation of location-aware devices, large amount of\ntrajectories have been generated when agents such as people, vehicles and goods\nflow around the urban environment. These raw trajectories, typically collected\nfrom various sources such as GPS in cars, personal mobile devices, and public\ntransport, are often sparse and fragmented due to limited sampling rates,\ninfrastructure coverage and data loss. In this context, trajectory recovery\naims to reconstruct such sparse raw trajectories into their dense and\ncontinuous counterparts, so that fine-grained movement of agents across space\nand time can be captured faithfully. Existing trajectory recovery approaches\ntypically rely on the prior knowledge of travel mode or motion patterns, and\noften fail in densely populated urban areas where accurate maps are absent. In\nthis paper, we present a new recovery framework called TrajWeaver based on\nprobabilistic diffusion models, which is able to recover dense and refined\ntrajectories from the sparse raw ones, conditioned on various auxiliary\nfeatures such as Areas of Interest along the way, user identity and waybill\ninformation. The core of TrajWeaver is a novel State Propagation Diffusion\nModel (SPDM), which introduces a new state propagation mechanism on top of the\nstandard diffusion models, so that knowledge computed in earlier diffusion\nsteps can be reused later, improving the recovery performance while reducing\nthe number of steps needed. Extensive experiments show that the proposed\nTrajWeaver can recover from raw trajectories of various lengths, sparsity\nlevels and heterogeneous travel modes, and outperform the state-of-the-art\nbaselines significantly in recovery accuracy. Our code is available at:\nhttps://anonymous.4open.science/r/TrajWeaver/",
      "tldr_zh": "本文提出TrajWeaver框架，用于从稀疏碎片化的原始轨迹数据（如GPS记录）恢复密集连续的轨迹，解决现有方法依赖先验知识（如旅行模式）并在城市密集区域表现不佳的问题。TrajWeaver的核心是State Propagation Diffusion Model (SPDM)，它在标准diffusion models基础上引入状态传播机制，允许早期扩散步骤的知识重用，从而提升恢复准确性和效率，同时结合辅助特征如兴趣区域、用户身份和运输信息。实验结果显示，TrajWeaver在处理不同长度、稀疏级别和异构旅行模式的轨迹时，显著优于最先进基线模型。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "First submission, extended to 10 pages include ref",
      "pdf_url": "http://arxiv.org/pdf/2409.02124v1",
      "published_date": "2024-09-01 06:42:19 UTC",
      "updated_date": "2024-09-01 06:42:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:32:50.093580"
    },
    {
      "arxiv_id": "2409.02123v2",
      "title": "PuYun: Medium-Range Global Weather Forecasting Using Large Kernel Attention Convolutional Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Shengchen Zhu",
        "Yiming Chen",
        "Peiying Yu",
        "Xiang Qu",
        "Yuxiao Zhou",
        "Yiming Ma",
        "Zhizhan Zhao",
        "Yukai Liu",
        "Hao Mi",
        "Bin Wang"
      ],
      "abstract": "Accurate weather forecasting is essential for understanding and mitigating\nweather-related impacts. In this paper, we present PuYun, an autoregressive\ncascade model that leverages large kernel attention convolutional networks. The\nmodel's design inherently supports extended weather prediction horizons while\nbroadening the effective receptive field. The integration of large kernel\nattention mechanisms within the convolutional layers enhances the model's\ncapacity to capture fine-grained spatial details, thereby improving its\npredictive accuracy for meteorological phenomena.\n  We introduce PuYun, comprising PuYun-Short for 0-5 day forecasts and\nPuYun-Medium for 5-10 day predictions. This approach enhances the accuracy of\n10-day weather forecasting. Through evaluation, we demonstrate that PuYun-Short\nalone surpasses the performance of both GraphCast and FuXi-Short in generating\naccurate 10-day forecasts. Specifically, on the 10th day, PuYun-Short reduces\nthe RMSE for Z500 to 720 $m^2/s^2$, compared to 732 $m^2/s^2$ for GraphCast and\n740 $m^2/s^2$ for FuXi-Short. Additionally, the RMSE for T2M is reduced to 2.60\nK, compared to 2.63 K for GraphCast and 2.65 K for FuXi-Short. Furthermore,\nwhen employing a cascaded approach by integrating PuYun-Short and PuYun-Medium,\nour method achieves superior results compared to the combined performance of\nFuXi-Short and FuXi-Medium. On the 10th day, the RMSE for Z500 is further\nreduced to 638 $m^2/s^2$, compared to 641 $m^2/s^2$ for FuXi. These findings\nunderscore the effectiveness of our model ensemble in advancing medium-range\nweather prediction. Our training code and model will be open-sourced.",
      "tldr_zh": "本论文提出 PuYun，一种基于 Large Kernel Attention Convolutional Networks 的自回归级联模型，用于中程全球天气预报，该模型通过扩展有效感受野和增强空间细节捕捉来支持更长的预测周期。PuYun 包括 PuYun-Short（针对 0-5 日预报）和 PuYun-Medium（针对 5-10 日预报），其设计显著提高了 10 日预报的准确性。实验结果显示，PuYun-Short 使 Z500 的 RMSE 降低到 720 m²/s² 和 T2M 的 RMSE 降低到 2.60 K，优于 GraphCast 和 FuXi-Short；当采用级联方法时，Z500 的 RMSE 进一步降至 638 m²/s²，比 FuXi 组合表现更佳。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.ao-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.02123v2",
      "published_date": "2024-09-01 06:25:35 UTC",
      "updated_date": "2024-09-12 06:08:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:33:03.354609"
    },
    {
      "arxiv_id": "2409.02122v1",
      "title": "Deep Knowledge-Infusion For Explainable Depression Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Sumit Dalal",
        "Sarika Jain",
        "Mayank Dave"
      ],
      "abstract": "Discovering individuals depression on social media has become increasingly\nimportant. Researchers employed ML/DL or lexicon-based methods for automated\ndepression detection. Lexicon based methods, explainable and easy to implement,\nmatch words from user posts in a depression dictionary without considering\ncontexts. While the DL models can leverage contextual information, their\nblack-box nature limits their adoption in the domain. Though surrogate models\nlike LIME and SHAP can produce explanations for DL models, the explanations are\nsuitable for the developer and of limited use to the end user. We propose a\nKnolwedge-infused Neural Network (KiNN) incorporating domain-specific knowledge\nfrom DepressionFeature ontology (DFO) in a neural network to endow the model\nwith user-level explainability regarding concepts and processes the clinician\nunderstands. Further, commonsense knowledge from the Commonsense Transformer\n(COMET) trained on ATOMIC is also infused to consider the generic emotional\naspects of user posts in depression detection. The model is evaluated on three\nexpertly curated datasets related to depression. We observed the model to have\na statistically significant (p<0.1) boost in performance over the best\ndomain-specific model, MentalBERT, across CLEF e-Risk (25% MCC increase, 12% F1\nincrease). A similar trend is observed across the PRIMATE dataset, where the\nproposed model performed better than MentalBERT (2.5% MCC increase, 19% F1\nincrease). The observations confirm the generated explanations to be\ninformative for MHPs compared to post hoc model explanations. Results\ndemonstrated that the user-level explainability of KiNN also surpasses the\nperformance of baseline models and can provide explanations where other\nbaselines fall short. Infusing the domain and commonsense knowledge in KiNN\nenhances the ability of models like GPT-3.5 to generate application-relevant\nexplanations.",
      "tldr_zh": "这篇论文提出了一种Knowledge-infused Neural Network (KiNN)，通过整合领域特定知识（如DepressionFeature ontology (DFO)）和常识知识（如从Commonsense Transformer (COMET)训练的ATOMIC），来提升社交媒体抑郁检测的可解释性和准确性。相比传统深度学习模型，KiNN提供用户级别的解释，便于临床医生理解情感和概念上下文。实验结果显示，KiNN在多个数据集上显著优于基线模型MentalBERT，例如CLEF e-Risk数据集的MCC增加25%、F1增加12%，并证明其生成的解释更具信息性和实用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2409.02122v1",
      "published_date": "2024-09-01 06:13:55 UTC",
      "updated_date": "2024-09-01 06:13:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:33:15.667293"
    },
    {
      "arxiv_id": "2409.00625v2",
      "title": "Entity-Aware Biaffine Attention Model for Improved Constituent Parsing with Reduced Entity Violations",
      "title_zh": "实体",
      "authors": [
        "Xinyi Bai"
      ],
      "abstract": "Constituency parsing involves analyzing a sentence by breaking it into\nsub-phrases, or constituents. While many deep neural models have achieved\nstate-of-the-art performance in this task, they often overlook the\nentity-violating issue, where an entity fails to form a complete sub-tree in\nthe resultant parsing tree. To address this, we propose an entity-aware\nbiaffine attention model for constituent parsing. This model incorporates\nentity information into the biaffine attention mechanism by using additional\nentity role vectors for potential phrases, which enhances the parsing accuracy.\nWe introduce a new metric, the Entity Violating Rate (EVR), to quantify the\nextent of entity violations in parsing results. Experiments on three popular\ndatasets-ONTONOTES, PTB, and CTB-demonstrate that our model achieves the lowest\nEVR while maintaining high precision, recall, and F1-scores comparable to\nexisting models. Further evaluation in downstream tasks, such as sentence\nsentiment analysis, highlights the effectiveness of our model and the validity\nof the proposed EVR metric.",
      "tldr_zh": "本文提出了一种实体感知的双亲和注意力模型（entity-aware biaffine attention model），旨在解决句法分析（constituent parsing）中的实体违反问题，即实体未能形成完整的子树。模型通过为潜在短语添加实体角色向量（entity role vectors）来整合实体信息，提升解析准确性，并引入了新的指标 Entity Violating Rate (EVR) 来量化实体违反程度。在 ONTONOTES、PTB 和 CTB 数据集上的实验显示，该模型实现了最低的 EVR，同时保持了与现有模型相当的精确率、召回率和 F1 分数。在下游任务如句子情感分析中，该模型进一步证明了其有效性和 EVR 指标的可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.00625v2",
      "published_date": "2024-09-01 05:59:54 UTC",
      "updated_date": "2024-11-12 01:47:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:33:28.664411"
    },
    {
      "arxiv_id": "2409.00622v1",
      "title": "Roundabout Dilemma Zone Data Mining and Forecasting with Trajectory Prediction and Graph Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Manthan Chelenahalli Satish",
        "Duo Lu",
        "Bharatesh Chakravarthi",
        "Mohammad Farhadi",
        "Yezhou Yang"
      ],
      "abstract": "Traffic roundabouts, as complex and critical road scenarios, pose significant\nsafety challenges for autonomous vehicles. In particular, the encounter of a\nvehicle with a dilemma zone (DZ) at a roundabout intersection is a pivotal\nconcern. This paper presents an automated system that leverages trajectory\nforecasting to predict DZ events, specifically at traffic roundabouts. Our\nsystem aims to enhance safety standards in both autonomous and manual\ntransportation. The core of our approach is a modular, graph-structured\nrecurrent model that forecasts the trajectories of diverse agents, taking into\naccount agent dynamics and integrating heterogeneous data, such as semantic\nmaps. This model, based on graph neural networks, aids in predicting DZ events\nand enhances traffic management decision-making. We evaluated our system using\na real-world dataset of traffic roundabout intersections. Our experimental\nresults demonstrate that our dilemma forecasting system achieves a high\nprecision with a low false positive rate of 0.1. This research represents an\nadvancement in roundabout DZ data mining and forecasting, contributing to the\nassurance of intersection safety in the era of autonomous vehicles.",
      "tldr_zh": "这篇论文针对交通圆环的Dilemma Zone (DZ) 安全挑战，提出一个自动化系统，利用轨迹预测和Graph Neural Networks进行数据挖掘和事件预测，以提升自动驾驶和手动交通的安全性。系统核心是一个模块化的图结构循环模型，该模型整合代理动态（如车辆行为）和异构数据（如语义地图），帮助准确预测DZ事件并优化交通管理决策。在真实世界数据集上的实验结果显示，该系统实现了高精度和低假阳性率（0.1），为自动驾驶时代圆环交叉口安全提供了重要进展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.00622v1",
      "published_date": "2024-09-01 05:47:58 UTC",
      "updated_date": "2024-09-01 05:47:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:33:39.787895"
    },
    {
      "arxiv_id": "2409.00620v1",
      "title": "Enhancing Vectorized Map Perception with Historical Rasterized Maps",
      "title_zh": "使用",
      "authors": [
        "Xiaoyu Zhang",
        "Guangwei Liu",
        "Zihao Liu",
        "Ningyi Xu",
        "Yunhui Liu",
        "Ji Zhao"
      ],
      "abstract": "In autonomous driving, there is growing interest in end-to-end online\nvectorized map perception in bird's-eye-view (BEV) space, with an expectation\nthat it could replace traditional high-cost offline high-definition (HD) maps.\nHowever, the accuracy and robustness of these methods can be easily compromised\nin challenging conditions, such as occlusion or adverse weather, when relying\nonly on onboard sensors. In this paper, we propose HRMapNet, leveraging a\nlow-cost Historical Rasterized Map to enhance online vectorized map perception.\nThe historical rasterized map can be easily constructed from past predicted\nvectorized results and provides valuable complementary information. To fully\nexploit a historical map, we propose two novel modules to enhance BEV features\nand map element queries. For BEV features, we employ a feature aggregation\nmodule to encode features from both onboard images and the historical map. For\nmap element queries, we design a query initialization module to endow queries\nwith priors from the historical map. The two modules contribute to leveraging\nmap information in online perception. Our HRMapNet can be integrated with most\nonline vectorized map perception methods. We integrate it in two\nstate-of-the-art methods, significantly improving their performance on both the\nnuScenes and Argoverse 2 datasets. The source code is released at\nhttps://github.com/HXMap/HRMapNet.",
      "tldr_zh": "本研究针对自动驾驶中端到端在线矢量化地图感知（在BEV空间）的准确性和鲁棒性问题，提出HRMapNet框架，利用低成本的历史栅格化地图作为补充信息，以缓解遮挡或恶劣天气带来的挑战。HRMapNet包括两个新模块：特征聚合模块，用于融合车载图像和历史地图的特征以增强BEV特征；以及查询初始化模块，用于为地图元素查询赋予历史地图的先验知识。这些模块使框架能够与大多数在线感知方法兼容。实验结果显示，HRMapNet显著提高了两个最先进方法的性能，在nuScenes和Argoverse 2数据集上取得了可观的提升。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.00620v1",
      "published_date": "2024-09-01 05:22:33 UTC",
      "updated_date": "2024-09-01 05:22:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:33:53.061836"
    },
    {
      "arxiv_id": "2409.00617v1",
      "title": "Does Knowledge Localization Hold True? Surprising Differences Between Entity and Relation Perspectives in Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yifan Wei",
        "Xiaoyan Yu",
        "Yixuan Weng",
        "Huanhuan Ma",
        "Yuanzhe Zhang",
        "Jun Zhao",
        "Kang Liu"
      ],
      "abstract": "Large language models encapsulate knowledge and have demonstrated superior\nperformance on various natural language processing tasks. Recent studies have\nlocalized this knowledge to specific model parameters, such as the MLP weights\nin intermediate layers. This study investigates the differences between entity\nand relational knowledge through knowledge editing. Our findings reveal that\nentity and relational knowledge cannot be directly transferred or mapped to\neach other. This result is unexpected, as logically, modifying the entity or\nthe relation within the same knowledge triplet should yield equivalent\noutcomes. To further elucidate the differences between entity and relational\nknowledge, we employ causal analysis to investigate how relational knowledge is\nstored in pre-trained models. Contrary to prior research suggesting that\nknowledge is stored in MLP weights, our experiments demonstrate that relational\nknowledge is also significantly encoded in attention modules. This insight\nhighlights the multifaceted nature of knowledge storage in language models,\nunderscoring the complexity of manipulating specific types of knowledge within\nthese models.",
      "tldr_zh": "本研究质疑大型语言模型（Large Language Models）中知识本地化的有效性，通过知识编辑（knowledge editing）调查实体（entity）和关系（relation）知识的差异。结果显示，实体和关系知识无法直接转移或映射，这与预期相悖，因为在同一知识三元组中修改实体或关系应产生等效效果。进一步采用因果分析（causal analysis），发现关系知识不仅存储在 MLP weights 中，还显著编码在 attention modules 中，从而突显了语言模型知识存储的多面性和复杂性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "CIKM 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.00617v1",
      "published_date": "2024-09-01 05:09:11 UTC",
      "updated_date": "2024-09-01 05:09:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:34:19.574889"
    },
    {
      "arxiv_id": "2409.00614v1",
      "title": "DAMe: Personalized Federated Social Event Detection with Dual Aggregation Mechanism",
      "title_zh": "DAMe：采用双聚合机制的个性化联邦社交事件检测",
      "authors": [
        "Xiaoyan Yu",
        "Yifan Wei",
        "Pu Li",
        "Shuaishuai Zhou",
        "Hao Peng",
        "Li Sun",
        "Liehuang Zhu",
        "Philip S. Yu"
      ],
      "abstract": "Training social event detection models through federated learning (FedSED)\naims to improve participants' performance on the task. However, existing\nfederated learning paradigms are inadequate for achieving FedSED's objective\nand exhibit limitations in handling the inherent heterogeneity in social data.\nThis paper proposes a personalized federated learning framework with a dual\naggregation mechanism for social event detection, namely DAMe. We present a\nnovel local aggregation strategy utilizing Bayesian optimization to incorporate\nglobal knowledge while retaining local characteristics. Moreover, we introduce\na global aggregation strategy to provide clients with maximum external\nknowledge of their preferences. In addition, we incorporate a global-local\nevent-centric constraint to prevent local overfitting and ``client-drift''.\nExperiments within a realistic simulation of a natural federated setting,\nutilizing six social event datasets spanning six languages and two social media\nplatforms, along with an ablation study, have demonstrated the effectiveness of\nthe proposed framework. Further robustness analyses have shown that DAMe is\nresistant to injection attacks.",
      "tldr_zh": "该论文提出了一种名为 DAMe 的个性化联邦学习框架，用于社会事件检测 (FedSED)，旨在解决现有联邦学习范式在处理社会数据异质性方面的不足。DAMe 采用双聚合机制，包括本地聚合策略（利用 Bayesian optimization 整合全局知识的同时保留本地特性）和全局聚合策略（为客户端提供偏好相关的最大外部知识）。此外，框架引入全局-本地事件中心约束，以防止本地过拟合和 “client-drift”。实验在六个跨语言和平台的社交事件数据集上证明了 DAMe 的有效性，并展示了其对注入攻击的鲁棒性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "CIKM 2024",
      "pdf_url": "http://arxiv.org/pdf/2409.00614v1",
      "published_date": "2024-09-01 04:56:41 UTC",
      "updated_date": "2024-09-01 04:56:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:34:21.988879"
    },
    {
      "arxiv_id": "2409.00592v3",
      "title": "Hyper-Compression: Model Compression via Hyperfunction",
      "title_zh": "Hyper-Compression：通过超函数的模型压缩",
      "authors": [
        "Fenglei Fan",
        "Juntong Fan",
        "Dayang Wang",
        "Jingbo Zhang",
        "Zelin Dong",
        "Shijun Zhang",
        "Ge Wang",
        "Tieyong Zeng"
      ],
      "abstract": "The rapid growth of large models' size has far outpaced that of computing\nresources. To bridge this gap, encouraged by the parsimonious relationship\nbetween genotype and phenotype in the brain's growth and development, we\npropose the so-called hyper-compression that turns the model compression into\nthe issue of parameter representation via a hyperfunction. Specifically, it is\nknown that the trajectory of some low-dimensional dynamic systems can fill the\nhigh-dimensional space eventually. Thus, hyper-compression, using these dynamic\nsystems as the hyperfunctions, represents the parameters of the target network\nby their corresponding composition number or trajectory length. This suggests a\nnovel mechanism for model compression, substantially different from the\nexisting pruning, quantization, distillation, and decomposition. Along this\ndirection, we methodologically identify a suitable dynamic system with the\nirrational winding as the hyperfunction and theoretically derive its associated\nerror bound. Next, guided by our theoretical insights, we propose several\nengineering twists to make the hyper-compression pragmatic and effective.\nLastly, systematic and comprehensive experiments confirm that hyper-compression\nenjoys the following \\textbf{PNAS} merits: 1) \\textbf{P}referable compression\nratio; 2) \\textbf{N}o post-hoc retraining; 3) \\textbf{A}ffordable inference\ntime; and 4) \\textbf{S}hort compression time. It compresses LLaMA2-7B in an\nhour and achieves close-to-int4-quantization performance, without retraining\nand with a performance drop of less than 1\\%. We have open-sourced our code in\nhttps://github.com/Juntongkuki/Hyper-Compression.git for free download and\nevaluation.",
      "tldr_zh": "本研究提出了一种名为 Hyper-Compression 的新型模型压缩方法，通过 hyperfunction（一种动态系统）来表示模型参数，灵感来源于大脑发育中的简约关系，从而解决大型模型尺寸增长与计算资源限制的矛盾。该方法利用低维动态系统的轨迹填充高维空间，避免了传统剪枝、量化、蒸馏和分解等技术，而是直接通过轨迹长度或组合数来压缩参数，并理论上推导了相关错误边界。实验结果显示，Hyper-Compression 具备 PNAS 优势：首选压缩比、无需后续重新训练、负担得起的推理时间以及短压缩时间；在 LLaMA2-7B 模型上，仅用一小时即可实现接近 int4 量化的性能，性能下降不到 1%。这项工作已开源，供进一步评估和应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.00592v3",
      "published_date": "2024-09-01 02:57:41 UTC",
      "updated_date": "2025-04-02 13:58:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:34:33.704904"
    },
    {
      "arxiv_id": "2409.00584v1",
      "title": "FastBO: Fast HPO and NAS with Adaptive Fidelity Identification",
      "title_zh": "翻译失败",
      "authors": [
        "Jiantong Jiang",
        "Ajmal Mian"
      ],
      "abstract": "Hyperparameter optimization (HPO) and neural architecture search (NAS) are\npowerful in attaining state-of-the-art machine learning models, with Bayesian\noptimization (BO) standing out as a mainstream method. Extending BO into the\nmulti-fidelity setting has been an emerging research topic, but faces the\nchallenge of determining an appropriate fidelity for each hyperparameter\nconfiguration to fit the surrogate model. To tackle the challenge, we propose a\nmulti-fidelity BO method named FastBO, which adaptively decides the fidelity\nfor each configuration and efficiently offers strong performance. The\nadvantages are achieved based on the novel concepts of efficient point and\nsaturation point for each configuration.We also show that our adaptive fidelity\nidentification strategy provides a way to extend any single-fidelity method to\nthe multi-fidelity setting, highlighting its generality and applicability.",
      "tldr_zh": "该论文针对超参数优化(HPO)和神经架构搜索(NAS)，提出了一种名为FastBO的多保真度Bayesian optimization (BO)方法，以解决为每个配置确定适当保真度的挑战。FastBO通过自适应地识别每个配置的efficient point和saturation point，实现高效的性能提升和资源优化。实验结果表明，该方法不仅提供更强的泛化能力，还能将任何单保真度方法扩展到多保真度设置，增强了HPO和NAS的适用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "The 18th European Conference on Computer Vision ECCV 2024 Women in\n  Computer Vision Workshop",
      "pdf_url": "http://arxiv.org/pdf/2409.00584v1",
      "published_date": "2024-09-01 02:40:04 UTC",
      "updated_date": "2024-09-01 02:40:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:34:43.572732"
    },
    {
      "arxiv_id": "2409.00571v1",
      "title": "Enhancing Source Code Security with LLMs: Demystifying The Challenges and Generating Reliable Repairs",
      "title_zh": "翻译失败",
      "authors": [
        "Nafis Tanveer Islam",
        "Joseph Khoury",
        "Andrew Seong",
        "Elias Bou-Harb",
        "Peyman Najafirad"
      ],
      "abstract": "With the recent unprecedented advancements in Artificial Intelligence (AI)\ncomputing, progress in Large Language Models (LLMs) is accelerating rapidly,\npresenting challenges in establishing clear guidelines, particularly in the\nfield of security. That being said, we thoroughly identify and describe three\nmain technical challenges in the security and software engineering literature\nthat spans the entire LLM workflow, namely; \\textbf{\\textit{(i)}} Data\nCollection and Labeling; \\textbf{\\textit{(ii)}} System Design and Learning; and\n\\textbf{\\textit{(iii)}} Performance Evaluation. Building upon these challenges,\nthis paper introduces \\texttt{SecRepair}, an instruction-based LLM system\ndesigned to reliably \\textit{identify}, \\textit{describe}, and automatically\n\\textit{repair} vulnerable source code. Our system is accompanied by a list of\nactionable guides on \\textbf{\\textit{(i)}} Data Preparation and Augmentation\nTechniques; \\textbf{\\textit{(ii)}} Selecting and Adapting state-of-the-art LLM\nModels; \\textbf{\\textit{(iii)}} Evaluation Procedures. \\texttt{SecRepair} uses\na reinforcement learning-based fine-tuning with a semantic reward that caters\nto the functionality and security aspects of the generated code. Our empirical\nanalysis shows that \\texttt{SecRepair} achieves a \\textit{12}\\% improvement in\nsecurity code repair compared to other LLMs when trained using reinforcement\nlearning. Furthermore, we demonstrate the capabilities of \\texttt{SecRepair} in\ngenerating reliable, functional, and compilable security code repairs against\nreal-world test cases using automated evaluation metrics.",
      "tldr_zh": "本文分析了 Large Language Models (LLMs) 在安全领域的三大技术挑战，包括 Data Collection and Labeling、System Design and Learning 以及 Performance Evaluation，并提出了 SecRepair 系统，该系统基于指令设计，能够可靠地识别、描述和自动修复漏洞源代码。SecRepair 采用 reinforcement learning-based fine-tuning 和 semantic reward 方法，关注生成的代码功能性和安全性。实验结果显示，该系统在安全代码修复上比其他 LLMs 提高了 12%，并通过自动化评估证明其在真实测试案例中生成可靠、可编译的修复代码。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2409.00571v1",
      "published_date": "2024-09-01 00:41:40 UTC",
      "updated_date": "2024-09-01 00:41:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T20:35:05.899762"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 55,
  "processed_papers_count": 55,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-19T20:35:42.259695"
}