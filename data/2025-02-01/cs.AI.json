{
  "date": "2025-02-01",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-02-01 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 72 篇论文，主要聚焦于 AI 和机器学习领域，尤其是大型语言模型 (LLM) 的优化、安全和应用，如多模态模型、多代理强化学习以及视觉处理创新。重点包括 RPGBench 基准评估 LLM 在角色扮演游戏中的性能，以及 Fast Vision Mamba 的加速技术；令人印象深刻的文章有 Mu Li 和 Alex Smola 等知名学者参与的 RPGBENCH，以及 Yixuan Li 等人提出的信息理论框架；这些论文突显了 LLM 在实际应用中的潜力，同时强调了安全性和效率挑战。\n\n### 重点论文解析\n我们先聊聊几篇重要且话题度高的论文，这些文章涉及 LLM 优化、AI 安全和多模态处理，展示了前沿创新。\n\n1. **RPGBENCH: Evaluating Large Language Models as Role-Playing Game Engines**  \n   这篇论文由 Pengfei Yu 等作者（包括知名学者 Mu Li 和 Alex Smola）提出，提交给 ICML 2025。核心贡献是引入 RPGBench 基准，用于评估 LLM 在文本角色扮演游戏中的表现，包括 Game Creation 和 Game Simulation 任务。发现现有 LLM 能生成吸引人的故事，但难以维持一致的游戏机制，尤其在复杂场景。该工作为 LLM 在交互式叙事中的创意与一致性提供新标准，强调了 LLM 平衡创新性和规则性的潜在影响。\n\n2. **Fast Vision Mamba: Pooling Spatial Dimensions for Accelerated Processing**  \n   作者 Saarthak Kapse 等来自 insitro，代码已开源。论文提出 FastVim 框架，通过交替池化图像维度减少 State Space Models (SSMs) 的计算步骤，实现图像处理速度提升高达 72.5%。主要发现是，在分类、分割和检测任务中，FastVim 保持了性能，同时显著提高了吞吐量。该方法挑战了传统 Vision Transformers 的复杂性，提供高效视觉模型的实用路径。\n\n3. **Robust Knowledge Distillation in Federated Learning: Counteracting Backdoor Attacks**  \n   作者 Ebtisaam Alharbi 等提出 RKD 机制，用于联邦学习 (Federated Learning) 中抵御后门攻击。核心创新是整合聚类和模型选择过滤恶意更新，然后通过知识蒸馏 (Knowledge Distillation) 构建可靠全局模型。实验显示，RKD 在各种场景下优于现有方法，显著降低了威胁，同时保持高性能。该论文突出了隐私保护在分布式学习中的重要性。\n\n4. **Defense Against the Dark Prompts: Mitigating Best-of-N Jailbreaking with Prompt Evaluation**  \n   作者 Stuart Armstrong 等开发 DATDP 算法，针对 LLM 的越狱攻击。贡献在于使用评估 LLM 检查提示的危险性，实现 99.8% 的攻击阻挡率，而无需依赖大型模型。发现即使使用较小模型（如 Claude 或 LLaMa-3-8B），也能显著提升 LLM 安全性。该工作为 LLM 部署提供即时、低成本的安全策略，强调了防范操纵性输入的实际价值。\n\n5. **Understanding Multimodal LLMs Under Distribution Shifts: An Information-Theoretic Approach**  \n   作者 Changdae Oh 和 Yixuan Li 等从信息理论视角提出框架，量化多模态 LLM 在分布偏移下的风险。核心是引入 Effective Mutual Information (EMI) 指标，并通过实验验证了其在 61 个场景中的有效性。该论文首次理论化 LLM 的鲁棒性，揭示了视觉和文本差异对模型的影响，为可靠的多模态应用提供基准。\n\n### 其他相关论文简述\n接下来快速掠过其他论文，聚焦于 AI、机器学习和应用领域的亮点，相关主题如 LLM 优化、强化学习和多模态处理。以下按主题归类，避免冗长。\n\n- **LLM 优化与推理（相关性高）**：  \n  - **Bridging Internal Probability and Self-Consistency for Effective and Efficient LLM Reasoning**（论文标题：Bridging Internal Probability and Self-Consistency...）：提出 RPC 方法提升 LLM 推理效率，通过优化概率一致性减少错误，实验在七个基准上显著改善性能。  \n  - **Pause-Tuning for Long-Context Comprehension**（论文标题：Pause-Tuning for Long-Context Comprehension...）：引入暂停调优技术解决 LLM 的“Lost-in-the-Middle”问题，实验显示 LLaMA 模型在长上下文任务中提升 10.61%。  \n  - **MQuant: Unleashing the Inference Potential of Multimodal Large Language Models via Full Static Quantization**（论文标题：MQuant...）：开发量化框架优化多模态 LLM，减少推理延迟达 30%，在五种模型上保持精度。\n\n- **AI 安全与联邦学习（话题度强）**：  \n  - **Data Overvaluation Attack and Truthful Data Valuation**（论文标题：Data Overvaluation Attack and Truthful Data Valuation...）：分析联邦学习中的数据过估攻击，提出 Truth-Shapley 指标确保真实评估，强调隐私保护。  \n  - **Enhance Learning Efficiency of Oblique Decision Tree via Feature Concatenation**（论文标题：Enhance Learning Efficiency of Oblique Decision Tree...）：改进决策树学习，理论证明其泛化优势，适用于高效分类。\n\n- **多模态与应用（实际影响大）**：  \n  - **Generating crossmodal gene expression from cancer histopathology improves multimodal AI predictions**（论文标题：Generating crossmodal gene expression...）：使用扩散模型合成基因表达，提升癌症诊断准确性，提供开源代码。  \n  - **Milmer: a Framework for Multiple Instance Learning based Multimodal Emotion Recognition**（论文标题：Milmer...）：融合面部和 EEG 信号的框架，实现 96.72% 的情感识别准确率，适用于 HCI。  \n  - **Semantic Communication based on Generative AI**（论文标题：Semantic Communication based on Generative AI...）：PhD 论文，提出基于生成模型的图像压缩方法，提高带宽效率。\n\n其他论文如 **Evolutionary Power-Aware Routing in VANETs**（车辆网络路由优化）和 **Life-Cycle Emissions of AI Hardware**（AI 硬件生命周期排放分析）等，虽有实际价值，但相对次要，这里仅简要提及：它们分别探讨了网络优化和环境影响，未见重大突破，故不展开。\n\n总之，今天的 arXiv 更新突显了 AI 领域的快速迭代，LLM 的安全和效率优化是核心趋势。感兴趣的读者可关注上述关键论文，探索更多创新应用！（本快报基于摘要提炼，完整内容请查阅 arXiv。）",
  "papers": [
    {
      "arxiv_id": "2502.00595v1",
      "title": "RPGBENCH: Evaluating Large Language Models as Role-Playing Game Engines",
      "title_zh": "RPGBENCH：评估大语言模型作为角色扮演游戏引擎",
      "authors": [
        "Pengfei Yu",
        "Dongming Shen",
        "Silin Meng",
        "Jaewon Lee",
        "Weisu Yin",
        "Andrea Yaoyun Cui",
        "Zhenlin Xu",
        "Yi Zhu",
        "Xingjian Shi",
        "Mu Li",
        "Alex Smola"
      ],
      "abstract": "We present RPGBench, the first benchmark designed to evaluate large language\nmodels (LLMs) as text-based role-playing game (RPG) engines. RPGBench comprises\ntwo core tasks: Game Creation (GC) and Game Simulation (GS). In GC, an LLM must\ncraft a valid and playable RPG world using a structured event-state\nrepresentation, ensuring logical coherence and proper termination conditions.\nIn GS, the LLM simulates interactive gameplay across multiple rounds while\nconsistently updating states and enforcing game rules. To comprehensively\nassess performance, RPGBench integrates objective and subjective evaluation\nmethodologies. Objective measures verify adherence to event mechanics and check\nvariable updates without requiring human intervention. Subjective measures,\nsuch as content interestingness, action quality, and role-playing capability,\nare evaluated via an LLM-as-a-judge framework, where a strong LLM grades each\ncandidate's outputs. Empirical results demonstrate that state-of-the-art LLMs\ncan produce engaging stories but often struggle to implement consistent,\nverifiable game mechanics, particularly in long or complex scenarios. By\ncombining structured, rule-based assessments with LLM-based judgments, RPGBench\nprovides a new standard for evaluating how well LLMs can balance creativity,\ncoherence, and complexity in text-based RPGs, opening avenues for more\nimmersive and controllable interactive storytelling.",
      "tldr_zh": "我们介绍了 RPGBench，这是第一个专为评估大型语言模型 (LLMs) 作为文本-based 角色扮演游戏 (RPG) 引擎而设计的基准。\nRPGBench 包含两个核心任务：Game Creation (GC)，要求 LLM 创建结构化的、可玩的 RPG 世界，确保逻辑一致性和终止条件；以及 Game Simulation (GS)，模拟多轮互动游戏并更新状态以执行规则。\n通过整合客观评估（如事件机制和变量更新检查）和主观评估（如 LLM-as-a-judge 对内容趣味性、动作质量和角色扮演能力的评分），实验结果显示当前最先进的 LLMs 擅长生成引人入胜的故事，但往往在复杂场景中难以实现一致、可验证的游戏机制，为提升 LLMs 在互动故事中的创造力和可控性提供了新标准。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Submitted to ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.00595v1",
      "published_date": "2025-02-01 23:40:24 UTC",
      "updated_date": "2025-02-01 23:40:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:31:15.740225"
    },
    {
      "arxiv_id": "2502.04341v1",
      "title": "Comparative Analysis of Community Detection Algorithms on the SNAP Social Circles Dataset",
      "title_zh": "翻译失败",
      "authors": [
        "Yash Malode",
        "Amit Aylani",
        "Arvind Bhardwaj",
        "Deepak Hajoary"
      ],
      "abstract": "In network research, Community Detection has always been a topic of\nsignificant interest in network science, with numerous papers and algorithms\nproposing to uncover the underlying structures within networks. In this paper,\nwe conduct a comparative analysis of several prominent community detection\nalgorithms applied to the SNAP Social Circles Dataset, derived from the\nFacebook Social Media network. The algorithms implemented include Louvain,\nGirvan-Newman, Spectral Clustering, K-Means Clustering, etc. We evaluate the\nperformance of these algorithms based on various metrics such as modularity,\nnormalized cut-ratio, silhouette score, compactness, and separability. Our\nfindings reveal insights into the effectiveness of each algorithm in detecting\nvarious meaningful communities within the social network, shedding light on\ntheir strength and limitations. This research contributes to the understanding\nof community detection methods and provides valuable guidance for their\napplication in analyzing real-world social networks.",
      "tldr_zh": "本文对 Louvain、Girvan-Newman、Spectral Clustering 和 K-Means Clustering 等社区检测算法在 SNAP Social Circles Dataset（基于 Facebook 社交网络）上的性能进行了比较分析。研究使用 modularity、normalized cut-ratio、silhouette score、compactness 和 separability 等指标评估这些算法的效能。结果显示，每种算法在识别社交网络社区方面各有优势和局限性，为理解社区检测方法并指导真实世界社交网络分析提供了宝贵见解。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "Presented at IDEA2k24: https://ideaconference.in/ Submitted to\n  Springer Lecture Notes in Electrical Engineering series\n  (https://www.springer.com/series/7818)",
      "pdf_url": "http://arxiv.org/pdf/2502.04341v1",
      "published_date": "2025-02-01 23:38:09 UTC",
      "updated_date": "2025-02-01 23:38:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:31:25.043064"
    },
    {
      "arxiv_id": "2502.00594v1",
      "title": "Fast Vision Mamba: Pooling Spatial Dimensions for Accelerated Processing",
      "title_zh": "翻译失败",
      "authors": [
        "Saarthak Kapse",
        "Robin Betz",
        "Srinivasan Sivanandan"
      ],
      "abstract": "State Space Models (SSMs) with selective scan (Mamba) have been adapted into\nefficient vision models. Mamba, unlike Vision Transformers, achieves linear\ncomplexity for token interactions through a recurrent hidden state process.\nThis sequential processing is enhanced by a parallel scan algorithm, which\nreduces the computational time of recurrent steps from $L$ sequential steps to\n$log(L)$ parallel steps with respect to the number of input tokens ($L$). In\nthis work, we propose Fast Vision Mamba (FastVim), that further reduces the\ncomputational time of the SSM block by reducing the number of recurrent steps\nin Vision Mamba models while still retaining model performance. By alternately\npooling tokens along image dimensions across Mamba blocks, we obtain a\n2$\\times$ reduction in the number of parallel steps in SSM block. Our model\noffers up to $72.5\\%$ speedup in inference speed compared to baseline Vision\nMamba models on high resolution (2048$\\times$2048) images. Our experiments\ndemonstrate state-of-the-art performance with dramatically improved throughput\nin a range of tasks such as image classification, cell perturbation prediction,\nsegmentation, and object detection. Code is made available at\nhttps://github.com/insitro/FastVim",
      "tldr_zh": "本文提出Fast Vision Mamba (FastVim)，一种改进的视觉模型，通过在SSMs块中交替池化图像空间维度来减少递归步骤，从而加速处理，同时保持模型性能。该方法将SSMs块的并行步骤减少2倍，实现高达72.5%的推理速度提升，尤其在高分辨率(2048×2048)图像上。实验结果显示，FastVim在图像分类、细胞扰动预测、分割和物体检测等任务中表现出最先进性能和显著提高的吞吐量，代码已开源于https://github.com/insitro/FastVim。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "20 pages, 15 figures, https://github.com/insitro/FastVim",
      "pdf_url": "http://arxiv.org/pdf/2502.00594v1",
      "published_date": "2025-02-01 23:35:20 UTC",
      "updated_date": "2025-02-01 23:35:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:31:38.309756"
    },
    {
      "arxiv_id": "2502.00587v2",
      "title": "Robust Knowledge Distillation in Federated Learning: Counteracting Backdoor Attacks",
      "title_zh": "鲁棒知识蒸馏：联邦学习中的后门攻击对抗",
      "authors": [
        "Ebtisaam Alharbi",
        "Leandro Soriano Marcolino",
        "Qiang Ni",
        "Antonios Gouglidis"
      ],
      "abstract": "Federated Learning (FL) enables collaborative model training across multiple\ndevices while preserving data privacy. However, it remains susceptible to\nbackdoor attacks, where malicious participants can compromise the global model.\nExisting defence methods are limited by strict assumptions on data\nheterogeneity (Non-Independent and Identically Distributed data) and the\nproportion of malicious clients, reducing their practicality and effectiveness.\nTo overcome these limitations, we propose Robust Knowledge Distillation (RKD),\na novel defence mechanism that enhances model integrity without relying on\nrestrictive assumptions. RKD integrates clustering and model selection\ntechniques to identify and filter out malicious updates, forming a reliable\nensemble of models. It then employs knowledge distillation to transfer the\ncollective insights from this ensemble to a global model. Extensive evaluations\ndemonstrate that RKD effectively mitigates backdoor threats while maintaining\nhigh model performance, outperforming current state-of-the-art defence methods\nacross various scenarios.",
      "tldr_zh": "本研究针对 Federated Learning (FL) 中 backdoor attacks 的问题，提出了一种新型防御机制 Robust Knowledge Distillation (RKD)，它无需依赖数据异质性 (Non-IID) 或恶意客户端比例的严格假设，从而提升实用性。RKD 通过整合 clustering 和 model selection 技术来识别并过滤恶意更新，形成可靠的模型集合，然后利用 knowledge distillation 将这些集合的知识转移到全局模型中。实验评估显示，RKD 有效缓解 backdoor 威胁，同时在各种场景下保持高模型性能，并优于现有最先进防御方法。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00587v2",
      "published_date": "2025-02-01 22:57:08 UTC",
      "updated_date": "2025-02-25 11:42:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:31:50.362979"
    },
    {
      "arxiv_id": "2502.00580v1",
      "title": "Defense Against the Dark Prompts: Mitigating Best-of-N Jailbreaking with Prompt Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Stuart Armstrong",
        "Matija Franklin",
        "Connor Stevens",
        "Rebecca Gorman"
      ],
      "abstract": "Recent work showed Best-of-N (BoN) jailbreaking using repeated use of random\naugmentations (such as capitalization, punctuation, etc) is effective against\nall major large language models (LLMs). We have found that $100\\%$ of the BoN\npaper's successful jailbreaks (confidence interval $[99.65\\%, 100.00\\%]$) and\n$99.8\\%$ of successful jailbreaks in our replication (confidence interval\n$[99.28\\%, 99.98\\%]$) were blocked with our Defense Against The Dark Prompts\n(DATDP) method. The DATDP algorithm works by repeatedly utilizing an evaluation\nLLM to evaluate a prompt for dangerous or manipulative behaviors--unlike some\nother approaches, DATDP also explicitly looks for jailbreaking attempts--until\na robust safety rating is generated. This success persisted even when utilizing\nsmaller LLMs to power the evaluation (Claude and LLaMa-3-8B-instruct proved\nalmost equally capable). These results show that, though language models are\nsensitive to seemingly innocuous changes to inputs, they seem also capable of\nsuccessfully evaluating the dangers of these inputs. Versions of DATDP can\ntherefore be added cheaply to generative AI systems to produce an immediate\nsignificant increase in safety.",
      "tldr_zh": "该研究针对 Best-of-N 越狱攻击提出 Defense Against The Dark Prompts (DATDP) 方法，该算法通过反复使用评估 LLM 检查提示中的危险或操纵行为，包括显式检测越狱尝试，从而生成稳健的安全评级。实验结果显示，DATDP 成功阻挡了 100% 的 BoN 论文中攻击和 99.8% 的复制实验中攻击，即使使用较小模型如 Claude 或 LLaMa-3-8B-instruct 也能保持高效率。这些发现证明了 LLMs 在评估输入危险方面的能力，并为生成式 AI 系统提供了一种廉价且有效的安全提升方式。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "I.2.0"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00580v1",
      "published_date": "2025-02-01 22:26:30 UTC",
      "updated_date": "2025-02-01 22:26:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:32:02.297575"
    },
    {
      "arxiv_id": "2502.00577v1",
      "title": "Understanding Multimodal LLMs Under Distribution Shifts: An Information-Theoretic Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Changdae Oh",
        "Zhen Fang",
        "Shawn Im",
        "Xuefeng Du",
        "Yixuan Li"
      ],
      "abstract": "Multimodal large language models (MLLMs) have shown promising capabilities\nbut struggle under distribution shifts, where evaluation data differ from\ninstruction tuning distributions. Although previous works have provided\nempirical evaluations, we argue that establishing a formal framework that can\ncharacterize and quantify the risk of MLLMs is necessary to ensure the safe and\nreliable application of MLLMs in the real world. By taking an\ninformation-theoretic perspective, we propose the first theoretical framework\nthat enables the quantification of the maximum risk of MLLMs under distribution\nshifts. Central to our framework is the introduction of Effective Mutual\nInformation (EMI), a principled metric that quantifies the relevance between\ninput queries and model responses. We derive an upper bound for the EMI\ndifference between in-distribution (ID) and out-of-distribution (OOD) data,\nconnecting it to visual and textual distributional discrepancies. Extensive\nexperiments on real benchmark datasets, spanning 61 shift scenarios empirically\nvalidate our theoretical insights.",
      "tldr_zh": "本研究探讨多模态大语言模型 (Multimodal LLMs) 在分布偏移 (distribution shifts) 下的表现问题，提出一个基于信息论 (Information-Theoretic Approach) 的首个理论框架，用于量化 MLLMs 的最大风险。核心贡献是引入 Effective Mutual Information (EMI) 指标来衡量输入查询与模型响应之间的相关性，并推导了 EMI 在分布内 (in-distribution, ID) 和分布外 (out-of-distribution, OOD) 数据之间差异的上界，该上界与视觉和文本分布差异相关联。通过在真实基准数据集上进行的广泛实验，涵盖61种偏移场景，研究验证了理论见解的有效性，为确保 MLLMs 在现实世界的安全可靠应用提供了基础。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00577v1",
      "published_date": "2025-02-01 22:06:56 UTC",
      "updated_date": "2025-02-01 22:06:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:32:13.383156"
    },
    {
      "arxiv_id": "2502.01675v1",
      "title": "Semantic Communication based on Generative AI: A New Approach to Image Compression and Edge Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Francesco Pezone"
      ],
      "abstract": "As digital technologies advance, communication networks face challenges in\nhandling the vast data generated by intelligent devices. Autonomous vehicles,\nsmart sensors, and IoT systems necessitate new paradigms. This thesis addresses\nthese challenges by integrating semantic communication and generative models\nfor optimized image compression and edge network resource allocation. Unlike\nbit-centric systems, semantic communication prioritizes transmitting meaningful\ndata specifically selected to convey the meaning rather than obtain a faithful\nrepresentation of the original data. The communication infrastructure can\nbenefit to significant improvements in bandwidth efficiency and latency\nreduction. Central to this work is the design of semantic-preserving image\ncompression using Generative Adversarial Networks and Denoising Diffusion\nProbabilistic Models. These models compress images by encoding only\nsemantically relevant features, allowing for high-quality reconstruction with\nminimal transmission. Additionally, a Goal-Oriented edge network optimization\nframework is introduced, leveraging the Information Bottleneck principle and\nstochastic optimization to dynamically allocate resources and enhance\nefficiency. By integrating semantic communication into edge networks, this\napproach balances computational efficiency and communication effectiveness,\nmaking it suitable for real-time applications. The thesis compares\nsemantic-aware models with conventional image compression techniques using\nclassical and semantic evaluation metrics. Results demonstrate the potential of\ncombining generative AI and semantic communication to create more efficient\nsemantic-goal-oriented communication networks that meet the demands of modern\ndata-driven applications.",
      "tldr_zh": "这篇论文提出了一种基于生成式 AI 的语义通信新方法，用于优化图像压缩和边缘网络资源分配，以应对智能设备生成的大量数据挑战。核心技术包括使用 Generative Adversarial Networks 和 Denoising Diffusion Probabilistic Models 进行语义保留图像压缩，仅编码相关特征以实现高效传输和高质量重建；同时引入基于 Information Bottleneck 原理的 Goal-Oriented 边缘网络优化框架，通过随机优化动态分配资源，提升通信效率。实验结果显示，该方法在经典和语义评估指标上优于传统压缩技术，提高了带宽利用率和降低了延迟，为实时数据驱动应用提供了高效解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "PhD thesis",
      "pdf_url": "http://arxiv.org/pdf/2502.01675v1",
      "published_date": "2025-02-01 21:48:31 UTC",
      "updated_date": "2025-02-01 21:48:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:32:35.452441"
    },
    {
      "arxiv_id": "2502.20405v1",
      "title": "Pause-Tuning for Long-Context Comprehension: A Lightweight Approach to LLM Attention Recalibration",
      "title_zh": "翻译失败",
      "authors": [
        "James Begin",
        "Namit Agrawal",
        "Eshan Singh",
        "Yicheng Fu",
        "Sean O'Brien",
        "Vasu Sharma",
        "Kevin Zhu"
      ],
      "abstract": "LLMs have demonstrated remarkable proficiency in understanding tasks but\ncontinue to struggle with long-context comprehension, particularly with content\nlocated in the middle of extensive inputs. This limitation, known as the\nLost-in-the-Middle (LITM) problem, hinders models from fully processing and\nutilizing information across lengthy contexts. To address this issue, we\nintroduce pause-tuning, a technique that redistributes attention to enhance\ncomprehension of long-context inputs. Our approach involves fine-tuning\nlanguage models on datasets with artificially inserted pause tokens, which\nserve to segment the input into smaller, more manageable parts. We evaluate\npause-tuning against alternative approaches using the Needle-in-a-Haystack\nbenchmark, where models must retrieve information embedded within contexts of\nup to 128K tokens. Experimental results demonstrate significant performance\ngains, with the LLaMA 3.2 3B Instruct model and the LLaMA 3.1 8B Instruct model\nimproving by 10.61% and 3.57% respectively on average, suggesting that\npause-tuning successfully enhances attention redistribution and improves\nlong-context retention. The code and data are available at\nhttps://anonymous.4open.science/r/LITM-PauseTokens-7357.",
      "tldr_zh": "该研究针对大型语言模型(LLM)处理长上下文时存在的Lost-in-the-Middle (LITM)问题，提出了一种轻量级方法pause-tuning，通过在输入中插入pause tokens来分割文本并重新分配注意力，从而提升模型对长上下文的理解能力。研究在Needle-in-a-Haystack基准测试中评估了该方法，模型需在高达128K tokens的上下文中检索信息。实验结果显示，LLaMA 3.2 3B Instruct模型平均性能提升10.61%，LLaMA 3.1 8B Instruct模型提升3.57%，证明pause-tuning有效改善了注意力重校准和长上下文保留。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.20405v1",
      "published_date": "2025-02-01 21:47:15 UTC",
      "updated_date": "2025-02-01 21:47:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:32:37.215877"
    },
    {
      "arxiv_id": "2502.00568v3",
      "title": "Generating crossmodal gene expression from cancer histopathology improves multimodal AI predictions",
      "title_zh": "翻译失败",
      "authors": [
        "Samiran Dey",
        "Christopher R. S. Banerji",
        "Partha Basuchowdhuri",
        "Sanjoy K. Saha",
        "Deepak Parashar",
        "Tapabrata Chakraborti"
      ],
      "abstract": "Emerging research has highlighted that artificial intelligence based\nmultimodal fusion of digital pathology and transcriptomic features can improve\ncancer diagnosis (grading/subtyping) and prognosis (survival risk) prediction.\nHowever, such direct fusion for joint decision is impractical in real clinical\nsettings, where histopathology is still the gold standard for diagnosis and\ntranscriptomic tests are rarely requested, at least in the public healthcare\nsystem. With our novel diffusion based crossmodal generative AI model PathGen,\nwe show that genomic expressions synthesized from digital histopathology\njointly predicts cancer grading and patient survival risk with high accuracy\n(state-of-the-art performance), certainty (through conformal coverage\nguarantee) and interpretability (through distributed attention maps). PathGen\ncode is available for open use by the research community through GitHub at\nhttps://github.com/Samiran-Dey/PathGen.",
      "tldr_zh": "本研究提出PathGen，一种基于扩散模型的跨模态生成AI方法，能够从癌症组织病理图像生成基因表达，从而提升多模态AI在癌症诊断和预后预测中的性能。不同于直接融合病理和转录组数据的传统方法，PathGen通过合成基因表达来联合预测癌症分级和患者生存风险，实现最先进准确率、高确定性（通过conformal coverage保证）和可解释性（通过distributed attention maps）。该模型已在GitHub开源，适用于临床场景中病理学为主的实际应用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00568v3",
      "published_date": "2025-02-01 21:28:30 UTC",
      "updated_date": "2025-02-11 12:25:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:32:49.068598"
    },
    {
      "arxiv_id": "2502.00567v1",
      "title": "Lessons for GenAI Literacy From a Field Study of Human-GenAI Augmentation in the Workplace",
      "title_zh": "翻译失败",
      "authors": [
        "Aditya Johri",
        "Johannes Schleiss",
        "Nupoor Ranade"
      ],
      "abstract": "Generative artificial intelligence (GenAI) is increasingly becoming a part of\nwork practices across the technology industry and being used across a range of\nindustries. This has necessitated the need to better understand how GenAI is\nbeing used by professionals in the field so that we can better prepare students\nfor the workforce. An improved understanding of the use of GenAI in practice\ncan help provide guidance on the design of GenAI literacy efforts including how\nto integrate it within courses and curriculum, what aspects of GenAI to teach,\nand even how to teach it. This paper presents a field study that compares the\nuse of GenAI across three different functions - product development, software\nengineering, and digital content creation - to identify how GenAI is currently\nbeing used in the industry. This study takes a human augmentation approach with\na focus on human cognition and addresses three research questions: how is GenAI\naugmenting work practices; what knowledge is important and how are workers\nlearning; and what are the implications for training the future workforce.\nFindings show a wide variance in the use of GenAI and in the level of computing\nknowledge of users. In some industries GenAI is being used in a highly\ntechnical manner with deployment of fine-tuned models across domains. Whereas\nin others, only off-the-shelf applications are being used for generating\ncontent. This means that the need for what to know about GenAI varies, and so\ndoes the background knowledge needed to utilize it. For the purposes of\nteaching and learning, our findings indicated that different levels of GenAI\nunderstanding needs to be integrated into courses. From a faculty perspective,\nthe work has implications for training faculty so that they are aware of the\nadvances and how students are possibly, as early adopters, already using GenAI\nto augment their learning practices.",
      "tldr_zh": "这篇论文通过实地研究探讨了生成式人工智能 (GenAI) 在职场中的应用，比较了产品开发、软件工程和数字内容创作三个领域中 GenAI 如何增强人类工作实践。研究发现，GenAI 的使用方式差异显著，从高度技术化的微调模型部署到简单的内容生成工具，这反映了用户计算知识水平的多样性，并突出了不同领域对相关知识的需求。论文强调，应将不同水平的 GenAI 理解整合到课程中，并为教师提供培训指导，以帮助学生适应职场需求和新兴技术趋势。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "Pre-print, paper accepted at IEEE EDUCON2025",
      "pdf_url": "http://arxiv.org/pdf/2502.00567v1",
      "published_date": "2025-02-01 21:26:31 UTC",
      "updated_date": "2025-02-01 21:26:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:33:01.158839"
    },
    {
      "arxiv_id": "2502.00547v1",
      "title": "Milmer: a Framework for Multiple Instance Learning based Multimodal Emotion Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Zaitian Wang",
        "Jian He",
        "Yu Liang",
        "Xiyuan Hu",
        "Tianhao Peng",
        "Kaixin Wang",
        "Jiakai Wang",
        "Chenlong Zhang",
        "Weili Zhang",
        "Shuang Niu",
        "Xiaoyang Xie"
      ],
      "abstract": "Emotions play a crucial role in human behavior and decision-making, making\nemotion recognition a key area of interest in human-computer interaction (HCI).\nThis study addresses the challenges of emotion recognition by integrating\nfacial expression analysis with electroencephalogram (EEG) signals, introducing\na novel multimodal framework-Milmer. The proposed framework employs a\ntransformer-based fusion approach to effectively integrate visual and\nphysiological modalities. It consists of an EEG preprocessing module, a facial\nfeature extraction and balancing module, and a cross-modal fusion module. To\nenhance visual feature extraction, we fine-tune a pre-trained Swin Transformer\non emotion-related datasets. Additionally, a cross-attention mechanism is\nintroduced to balance token representation across modalities, ensuring\neffective feature integration. A key innovation of this work is the adoption of\na multiple instance learning (MIL) approach, which extracts meaningful\ninformation from multiple facial expression images over time, capturing\ncritical temporal dynamics often overlooked in previous studies. Extensive\nexperiments conducted on the DEAP dataset demonstrate the superiority of the\nproposed framework, achieving a classification accuracy of 96.72% in the\nfour-class emotion recognition task. Ablation studies further validate the\ncontributions of each module, highlighting the significance of advanced feature\nextraction and fusion strategies in enhancing emotion recognition performance.\nOur code are available at https://github.com/liangyubuaa/Milmer.",
      "tldr_zh": "本文提出 Milmer 框架，一种基于 Multiple Instance Learning (MIL) 的多模态情感识别方法，整合面部表情分析和 EEG 信号，以解决传统方法的局限性。该框架包括 EEG 预处理模块、fine-tuned Swin Transformer 的面部特征提取和平衡模块，以及跨模态融合模块（采用 cross-attention 机制），从而有效捕捉时间动态信息。在 DEAP 数据集上，Milmer 在四分类情感识别任务中实现 96.72% 的准确率，消融实验进一步证实了各模块的贡献。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00547v1",
      "published_date": "2025-02-01 20:32:57 UTC",
      "updated_date": "2025-02-01 20:32:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:33:14.288847"
    },
    {
      "arxiv_id": "2502.00545v1",
      "title": "Integrating Frequency Guidance into Multi-source Domain Generalization for Bearing Fault Diagnosis",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaotong Tu",
        "Chenyu Ma",
        "Qingyao Wu",
        "Yinhao Liu",
        "Hongyang Zhang"
      ],
      "abstract": "Recent generalizable fault diagnosis researches have effectively tackled the\ndistributional shift between unseen working conditions. Most of them mainly\nfocus on learning domain-invariant representation through feature-level\nmethods. However, the increasing numbers of unseen domains may lead to\ndomain-invariant features contain instance-level spurious correlations, which\nimpact the previous models' generalizable ability. To address the limitations,\nwe propose the Fourier-based Augmentation Reconstruction Network, namely\nFARNet.The methods are motivated by the observation that the Fourier phase\ncomponent and amplitude component preserve different semantic information of\nthe signals, which can be employed in domain augmentation techniques. The\nnetwork comprises an amplitude spectrum sub-network and a phase spectrum\nsub-network, sequentially reducing the discrepancy between the source and\ntarget domains. To construct a more robust generalized model, we employ a\nmulti-source domain data augmentation strategy in the frequency domain.\nSpecifically, a Frequency-Spatial Interaction Module (FSIM) is introduced to\nhandle global information and local spatial features, promoting representation\nlearning between the two sub-networks. To refine the decision boundary of our\nmodel output compared to conventional triplet loss, we propose a manifold\ntriplet loss to contribute to generalization. Through extensive experiments on\nthe CWRU and SJTU datasets, FARNet demonstrates effective performance and\nachieves superior results compared to current cross-domain approaches on the\nbenchmarks.",
      "tldr_zh": "本研究针对轴承故障诊断中多源域泛化问题，提出了一种名为 Fourier-based Augmentation Reconstruction Network (FARNet) 的方法，以解决领域不变表示可能存在的实例级虚假相关性。FARNet 通过幅度谱子网络和相位谱子网络减少源域与目标域间的差异，并引入 Frequency-Spatial Interaction Module (FSIM) 来处理全局和局部空间特征，同时采用 manifold triplet loss 优化决策边界以提升模型泛化能力。在 CWRU 和 SJTU 数据集上的实验显示，FARNet 比现有跨域方法取得了显著优越的性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00545v1",
      "published_date": "2025-02-01 20:23:03 UTC",
      "updated_date": "2025-02-01 20:23:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:33:25.824903"
    },
    {
      "arxiv_id": "2502.01673v2",
      "title": "Multilingual State Space Models for Structured Question Answering in Indic Languages",
      "title_zh": "翻译失败",
      "authors": [
        "Arpita Vats",
        "Rahul Raja",
        "Mrinal Mathur",
        "Vinija Jain",
        "Aman Chadha"
      ],
      "abstract": "The diversity and complexity of Indic languages present unique challenges for\nnatural language processing (NLP) tasks, particularly in the domain of question\nanswering (QA).To address these challenges, this paper explores the application\nof State Space Models (SSMs),to build efficient and contextually aware QA\nsystems tailored for Indic languages. SSMs are particularly suited for this\ntask due to their ability to model long-term and short-term dependencies in\nsequential data, making them well-equipped to handle the rich morphology,\ncomplex syntax, and contextual intricacies characteristic of Indian languages.\nWe evaluated multiple SSM architectures across diverse datasets representing\nvarious Indic languages and conducted a comparative analysis of their\nperformance. Our results demonstrate that these models effectively capture\nlinguistic subtleties, leading to significant improvements in question\ninterpretation, context alignment, and answer generation. This work represents\nthe first application of SSMs to question answering tasks in Indic languages,\nestablishing a foundational benchmark for future research in this domain. We\npropose enhancements to existing SSM frameworks, optimizing their applicability\nto low-resource settings and multilingual scenarios prevalent in Indic\nlanguages.",
      "tldr_zh": "这篇论文探讨了 State Space Models (SSMs) 在 Indic 语言结构化问答（Question Answering, QA）中的应用，以应对这些语言的多样性、复杂语法和形态挑战。SSMs 通过建模序列数据的长期和短期依赖，能够有效处理 Indic 语言的上下文细微差别，并在问题解释、上下文对齐和答案生成方面表现出色。研究评估了多种 SSM 架构在不同 Indic 语言数据集上的性能，结果显示其性能比传统方法显著提升。论文首次将 SSMs 应用于 Indic 语言 QA 任务，建立基准并提出框架优化，以适应低资源和多语言场景。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at NAACL",
      "pdf_url": "http://arxiv.org/pdf/2502.01673v2",
      "published_date": "2025-02-01 19:53:02 UTC",
      "updated_date": "2025-04-24 04:40:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:33:38.404883"
    },
    {
      "arxiv_id": "2502.01672v1",
      "title": "Doubly Robust Monte Carlo Tree Search",
      "title_zh": "翻译失败",
      "authors": [
        "Manqing Liu",
        "Andrew L. Beam"
      ],
      "abstract": "We present Doubly Robust Monte Carlo Tree Search (DR-MCTS), a novel algorithm\nthat integrates Doubly Robust (DR) off-policy estimation into Monte Carlo Tree\nSearch (MCTS) to enhance sample efficiency and decision quality in complex\nenvironments. Our approach introduces a hybrid estimator that combines MCTS\nrollouts with DR estimation, offering theoretical guarantees of unbiasedness\nand variance reduction under specified conditions. Empirical evaluations in\nTic-Tac-Toe and the partially observable VirtualHome environment demonstrate\nDR-MCTS's superior performance over standard MCTS. In Tic-Tac-Toe, DR-MCTS\nachieves an 88% win rate compared to a 10% win rate for standard MCTS. In\ncompound VirtualHome tasks, DR-MCTS attains a 20.7% success rate versus 10.3%\nfor standard MCTS. Our scaling analysis reveals that DR-MCTS exhibits better\nsample efficiency, notably outperforming standard MCTS with larger language\nmodels while using a smaller model. These results underscore DR-MCTS's\npotential for efficient decision-making in complex, real-world scenarios where\nsample efficiency is paramount.",
      "tldr_zh": "本研究提出了一种名为 Doubly Robust Monte Carlo Tree Search (DR-MCTS) 的新算法，将 Doubly Robust (DR) off-policy estimation 整合到 Monte Carlo Tree Search (MCTS) 中，以提升复杂环境下的样本效率和决策质量。DR-MCTS 采用混合估计算法，结合 MCTS 的 rollout 和 DR 估计，提供无偏性和方差减少的理论保证。实验结果显示，在 Tic-Tac-Toe 游戏中，DR-MCTS 的胜率达到 88%，远超标准 MCTS 的 10%；在部分可观察的 VirtualHome 环境中，DR-MCTS 的成功率达 20.7%，相比标准 MCTS 的 10.3% 显著提升。该算法在样本效率方面表现出色，尤其适合使用较小模型处理真实世界的复杂决策场景。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01672v1",
      "published_date": "2025-02-01 19:32:46 UTC",
      "updated_date": "2025-02-01 19:32:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:33:49.969825"
    },
    {
      "arxiv_id": "2503.04733v1",
      "title": "Ethics of generative AI and manipulation: a design-oriented research agenda",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Klenk"
      ],
      "abstract": "Generative AI enables automated, effective manipulation at scale. Despite the\ngrowing general ethical discussion around generative AI, the specific\nmanipulation risks remain inadequately investigated. This article outlines\nessential inquiries encompassing conceptual, empirical, and design dimensions\nof manipulation, pivotal for comprehending and curbing manipulation risks. By\nhighlighting these questions, the article underscores the necessity of an\nappropriate conceptualisation of manipulation to ensure the responsible\ndevelopment of Generative AI technologies.",
      "tldr_zh": "这篇论文探讨了Generative AI在伦理方面的挑战，特别是它如何实现大规模的自动化操纵。尽管Generative AI的总体伦理讨论日益增多，但具体的操纵风险尚未得到充分研究。文章提出一个以设计为导向的研究议程，概述了操纵的概念、实证和设计维度中的关键问题，以帮助理解和缓解这些风险。最终，该研究强调了正确概念化操纵的重要性，以确保Generative AI技术的负责任发展。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04733v1",
      "published_date": "2025-02-01 19:18:59 UTC",
      "updated_date": "2025-02-01 19:18:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:35:14.872066"
    },
    {
      "arxiv_id": "2502.00530v1",
      "title": "Generic Multimodal Spatially Graph Network for Spatially Embedded Network Representation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Xudong Fan",
        "Jürgen Hackl"
      ],
      "abstract": "Spatially embedded networks (SENs) represent a special type of complex graph,\nwhose topologies are constrained by the networks' embedded spatial\nenvironments. The graph representation of such networks is thereby influenced\nby the embedded spatial features of both nodes and edges. Accurate network\nrepresentation of the graph structure and graph features is a fundamental task\nfor various graph-related tasks. In this study, a Generic Multimodal Spatially\nGraph Convolutional Network (GMu-SGCN) is developed for efficient\nrepresentation of spatially embedded networks. The developed GMu-SGCN model has\nthe ability to learn the node connection pattern via multimodal node and edge\nfeatures. In order to evaluate the developed model, a river network dataset and\na power network dataset have been used as test beds. The river network\nrepresents the naturally developed SENs, whereas the power network represents a\nman-made network. Both types of networks are heavily constrained by the spatial\nenvironments and uncertainties from nature. Comprehensive evaluation analysis\nshows the developed GMu-SGCN can improve accuracy of the edge existence\nprediction task by 37.1\\% compared to a GraphSAGE model which only considers\nthe node's position feature in a power network test bed. Our model demonstrates\nthe importance of considering the multidimensional spatial feature for\nspatially embedded network representation.",
      "tldr_zh": "本研究针对 Spatially Embedded Networks (SENs) 提出了一种 Generic Multimodal Spatially Graph Convolutional Network (GMu-SGCN) 模型，用于高效学习受空间环境约束的网络表示，该模型通过整合多模态节点和边特征来捕捉节点连接模式。实验使用河流网络和电力网络数据集作为测试基准，结果显示 GMu-SGCN 在电力网络的边存在预测任务中比 GraphSAGE 模型提高了 37.1% 的准确率。总体而言，该模型强调了考虑多维空间特征对 SENs 表示学习的重要性，为复杂图相关任务提供了新方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00530v1",
      "published_date": "2025-02-01 19:05:48 UTC",
      "updated_date": "2025-02-01 19:05:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:34:14.287146"
    },
    {
      "arxiv_id": "2502.00511v2",
      "title": "Bridging Internal Probability and Self-Consistency for Effective and Efficient LLM Reasoning",
      "title_zh": "桥接内部概率和自一致性以实现有效和高效的 LLM 推理",
      "authors": [
        "Zhi Zhou",
        "Tan Yuhao",
        "Zenan Li",
        "Yuan Yao",
        "Lan-Zhe Guo",
        "Xiaoxing Ma",
        "Yu-Feng Li"
      ],
      "abstract": "Recent advancements in large language models (LLMs) have demonstrated\nremarkable reasoning capabilities. However, single-shot inference often yields\nunreliable results for complex reasoning tasks, leading researchers to explore\nmultiple reasoning paths through methods such as perplexity and\nself-consistency. In this paper, we present the first theoretical error\ndecomposition analysis of these techniques, breaking down their error into\nestimation error and model error. Our analysis reveals a fundamental trade-off:\nperplexity methods suffer from substantial model error due to the absence of a\nproper consistency function, while self-consistency exhibits high estimation\nerror due to a slow error convergence rate. To overcome these limitations, we\npropose Reasoning-Pruning Perplexity Consistency (RPC). This approach combines\nPerplexity Consistency, which seamlessly integrates LLM perplexity with\nself-consistency, and Reasoning Pruning, which eliminates low-probability\nreasoning paths to effectively prevent the degeneration of estimation error\nreduction. Theoretical analysis demonstrates that RPC not only accelerates the\nconvergence rate of estimation error to an exponential level but also holds\nstrong potential for further reducing model error. Extensive empirical\nevaluations on seven benchmark datasets confirm that RPC can significantly\nimprove reasoning performance, sample efficiency, and confidence reliability.",
      "tldr_zh": "本研究分析了大型语言模型 (LLMs) 在复杂推理任务中单次推理不可靠的问题，并对现有方法如 perplexity 和 self-consistency 进行了理论错误分解，揭示了 perplexity 方法的模型错误高和 self-consistency 的估计错误收敛慢的权衡。针对这些局限，论文提出了一种新方法 Reasoning-Pruning Perplexity Consistency (RPC)，它结合 Perplexity Consistency 与 Reasoning Pruning 来加速估计错误的指数级收敛并潜在减少模型错误。实验结果显示，RPC 在七个基准数据集上显著提升了推理性能、样本效率和置信可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Preliminary work",
      "pdf_url": "http://arxiv.org/pdf/2502.00511v2",
      "published_date": "2025-02-01 18:09:49 UTC",
      "updated_date": "2025-02-13 07:35:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:35:14.603672"
    },
    {
      "arxiv_id": "2502.00510v2",
      "title": "Who's the MVP? A Game-Theoretic Evaluation Benchmark for Modular Attribution in LLM Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Yingxuan Yang",
        "Bo Huang",
        "Siyuan Qi",
        "Chao Feng",
        "Haoyi Hu",
        "Yuxuan Zhu",
        "Jinbo Hu",
        "Haoran Zhao",
        "Ziyi He",
        "Xiao Liu",
        "Zongyu Wang",
        "Lin Qiu",
        "Xuezhi Cao",
        "Xunliang Cai",
        "Yong Yu",
        "Weinan Zhang"
      ],
      "abstract": "Large Language Model (LLM) agents frameworks often employ modular\narchitectures, incorporating components such as planning, reasoning, action\nexecution, and reflection to tackle complex tasks. However, quantifying the\ncontribution of each module to overall system performance remains a significant\nchallenge, impeding optimization and interpretability. To address this, we\nintroduce CapaBench (Capability-level Assessment Benchmark), an evaluation\nframework grounded in cooperative game theory's Shapley Value, which\nsystematically measures the marginal impact of individual modules and their\ninteractions within an agent's architecture. By replacing default modules with\ntest variants across all possible combinations, CapaBench provides a principle\nmethod for attributing performance contributions. Key contributions include:\n(1) We are the first to propose a Shapley Value-based methodology for\nquantifying the contributions of capabilities in LLM agents; (2) Modules with\nhigh Shapley Values consistently lead to predictable performance gains when\ncombined, enabling targeted optimization; and (3) We build a multi-round\ndataset of over 1,500 entries spanning diverse domains and practical task\nscenarios, enabling comprehensive evaluation of agent capabilities. CapaBench\nbridges the gap between component-level evaluation and holistic system\nassessment, providing actionable insights for optimizing modular LLM agents and\nadvancing their deployment in complex, real-world scenarios.",
      "tldr_zh": "该论文针对大型语言模型（LLM）代理的模块化架构（如规划、推理和行动执行）中，量化模块贡献的挑战，引入了基于合作博弈理论的Shapley Value框架——CapaBench。CapaBench通过替换模块的默认版本并测试所有组合，系统测量每个模块的边际影响及其交互作用，从而实现性能贡献的精确归因。关键贡献包括：首次提出Shapley Value方法量化LLM代理能力、发现高Shapley Value模块可预测性能提升以指导优化，以及构建一个超过1500条的多轮数据集，覆盖多样领域和任务场景。该框架桥接了组件级评估与整体系统评估，提供可操作洞见，推动LLM代理在复杂现实场景中的部署。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00510v2",
      "published_date": "2025-02-01 18:07:34 UTC",
      "updated_date": "2025-02-16 12:34:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:34:37.535937"
    },
    {
      "arxiv_id": "2502.00507v2",
      "title": "A statistically consistent measure of Semantic Variability using Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yi Liu"
      ],
      "abstract": "To address the issue of variability in the output generated by a language\nmodel, we present a measure of semantic variability that is statistically\nconsistent under mild assumptions. This measure, denoted as semantic spectral\nentropy, is a easy to implement algorithm that requires just off the shelf\nlanguage models. We put very few restrictions on the language models and we\nhave shown in a clear simulation studies that such method can generate accurate\nmetric despite randomness that arise from the language models.",
      "tldr_zh": "本文提出了一种统计上一致的语义变异性（semantic variability）度量，名为 semantic spectral entropy，用于评估语言模型的输出变异性问题。  \n该度量基于一个易于实现的算法，仅需现成的 language models，并在温和假设下保持统计一致性，对模型的限制较少。  \n通过模拟研究，证明即使 language models 存在随机性，该方法仍能生成准确的度量结果。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00507v2",
      "published_date": "2025-02-01 17:55:58 UTC",
      "updated_date": "2025-02-11 16:39:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:34:48.658895"
    },
    {
      "arxiv_id": "2502.00501v1",
      "title": "Optimizing Feature Selection in Causal Inference: A Three-Stage Computational Framework for Unbiased Estimation",
      "title_zh": "在因果推断中优化特征选择：一种三阶段计算框架用于无偏估计",
      "authors": [
        "Tianyu Yang",
        "Md. Noor-E-Alam"
      ],
      "abstract": "Feature selection is an important but challenging task in causal inference\nfor obtaining unbiased estimates of causal quantities. Properly selected\nfeatures in causal inference not only significantly reduce the time required to\nimplement a matching algorithm but, more importantly, can also reduce the bias\nand variance when estimating causal quantities. When feature selection\ntechniques are applied in causal inference, the crucial criterion is to select\nvariables that, when used for matching, can achieve an unbiased and robust\nestimation of causal quantities. Recent research suggests that balancing only\non treatment-associated variables introduces bias while balancing on spurious\nvariables increases variance. To address this issue, we propose an enhanced\nthree-stage framework that shows a significant improvement in selecting the\ndesired subset of variables compared to the existing state-of-the-art feature\nselection framework for causal inference, resulting in lower bias and variance\nin estimating the causal quantity. We evaluated our proposed framework using a\nstate-of-the-art synthetic data across various settings and observed superior\nperformance within a feasible computation time, ensuring scalability for\nlarge-scale datasets. Finally, to demonstrate the applicability of our proposed\nmethodology using large-scale real-world data, we evaluated an important US\nhealthcare policy related to the opioid epidemic crisis: whether opioid use\ndisorder has a causal relationship with suicidal behavior.",
      "tldr_zh": "该论文提出一个三阶段计算框架，用于优化因果推理中的特征选择，从而实现无偏估计。该框架通过改进变量选择过程，避免仅平衡治疗相关变量导致的偏差或平衡虚假变量增加的方差，与现有方法相比显著降低了估计中的偏差和方差。在合成数据上的实验显示，该框架在各种设置下表现出色，计算时间可行，并扩展适用于大规模数据集；此外，该方法应用于真实世界数据，评估了阿片类药物使用障碍(opioid use disorder)与自杀行为之间的因果关系，证明了其实际价值。",
      "categories": [
        "stat.ME",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "stat.ME",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00501v1",
      "published_date": "2025-02-01 17:47:28 UTC",
      "updated_date": "2025-02-01 17:47:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:35:46.357218"
    },
    {
      "arxiv_id": "2502.00500v2",
      "title": "Video Latent Flow Matching: Optimal Polynomial Projections for Video Interpolation and Extrapolation",
      "title_zh": "视频潜在流动匹配：用于视频插值和外推的最优多项式投影",
      "authors": [
        "Yang Cao",
        "Zhao Song",
        "Chiwun Yang"
      ],
      "abstract": "This paper considers an efficient video modeling process called Video Latent\nFlow Matching (VLFM). Unlike prior works, which randomly sampled latent patches\nfor video generation, our method relies on current strong pre-trained image\ngeneration models, modeling a certain caption-guided flow of latent patches\nthat can be decoded to time-dependent video frames. We first speculate multiple\nimages of a video are differentiable with respect to time in some latent space.\nBased on this conjecture, we introduce the HiPPO framework to approximate the\noptimal projection for polynomials to generate the probability path. Our\napproach gains the theoretical benefits of the bounded universal approximation\nerror and timescale robustness. Moreover, VLFM processes the interpolation and\nextrapolation abilities for video generation with arbitrary frame rates. We\nconduct experiments on several text-to-video datasets to showcase the\neffectiveness of our method.",
      "tldr_zh": "本论文提出了一种高效视频建模方法，名为 Video Latent Flow Matching (VLFM)，它基于现有的预训练图像生成模型，通过建模潜在空间中隐变量块的流动来生成时间相关的视频帧。VLFM 假设视频图像在潜在空间中对时间可微，并利用 HiPPO 框架近似最优多项式投影，以实现概率路径的生成，从而获得 bounded universal approximation error 和 timescale robustness 的理论优势。该方法支持视频 interpolation 和 extrapolation，能处理任意帧率的视频生成，并在多个文本到视频数据集上的实验中证明了其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "39 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.00500v2",
      "published_date": "2025-02-01 17:40:11 UTC",
      "updated_date": "2025-02-04 15:19:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:35:58.172258"
    },
    {
      "arxiv_id": "2502.00499v1",
      "title": "Discovering Directly-Follows Graph Model for Acyclic Processes",
      "title_zh": "翻译失败",
      "authors": [
        "Nikita Shaimov",
        "Irina Lomazova",
        "Alexey Mitsyuk"
      ],
      "abstract": "Process mining is the common name for a range of methods and approaches aimed\nat analysing and improving processes. Specifically, methods that aim to derive\nprocess models from event logs fall under the category of process discovery.\nWithin the range of processes, acyclic processes form a distinct category. In\nsuch processes, previously performed actions are not repeated, forming chains\nof unique actions. However, due to differences in the order of actions,\nexisting process discovery methods can provide models containing cycles even if\na process is acyclic. This paper presents a new process discovery algorithm\nthat allows to discover acyclic DFG models for acyclic processes. A model is\ndiscovered by partitioning an event log into parts that provide acyclic DFG\nmodels and merging them while avoiding the formation of cycles. The resulting\nalgorithm was tested both on real-life and artificial event logs. Absence of\ncycles improves model visual clarity and precision, also allowing to apply\ncycle-sensitive methods or visualisations to the model.",
      "tldr_zh": "这篇论文针对无环过程（acyclic processes），提出了一种新算法，用于从事件日志中发现无环的直接跟随图（DFG）模型，以解决现有过程发现（process discovery）方法可能生成循环模型的问题。该算法通过将事件日志分区成提供无环 DFG 模型的部分，然后合并这些部分，同时避免循环的形成，提高了模型的可视清晰度和精确性。在真实和人工事件日志上的测试表明，该方法能提升过程挖掘（process mining）的整体效果，并支持循环敏感的方法或可视化。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "24 pages, 15 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.00499v1",
      "published_date": "2025-02-01 17:39:28 UTC",
      "updated_date": "2025-02-01 17:39:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:36:09.975795"
    },
    {
      "arxiv_id": "2502.00498v1",
      "title": "MetaOpenFOAM 2.0: Large Language Model Driven Chain of Thought for Automating CFD Simulation and Post-Processing",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxuan Chen",
        "Xu Zhu",
        "Hua Zhou",
        "Zhuyin Ren"
      ],
      "abstract": "Computational Fluid Dynamics (CFD) is widely used in aerospace, energy, and\nbiology to model fluid flow, heat transfer, and chemical reactions. While Large\nLanguage Models (LLMs) have transformed various domains, their application in\nCFD remains limited, particularly for complex tasks like post-processing. To\nbridge this gap, we introduce MetaOpenFOAM 2.0, which leverages Chain of\nThought (COT) decomposition and iterative verification to enhance accessibility\nfor non-expert users through natural language inputs. Tested on a new benchmark\ncovering simulation (fluid flow, heat transfer, combustion) and post-processing\n(extraction, visualization), MetaOpenFOAM 2.0 achieved an Executability score\nof 6.3/7 and a pass rate of 86.9%, significantly outperforming MetaOpenFOAM 1.0\n(2.1/7, 0%). Additionally, it proved cost-efficient, averaging $0.15 per case.\nAn ablation study confirmed that COT-driven decomposition and iterative\nrefinement substantially improved task performance. Furthermore, scaling laws\nshowed that increasing COT steps enhanced accuracy while raising token usage,\naligning with LLM post-training scaling trends. These results highlight the\ntransformative potential of LLMs in automating CFD workflows for industrial and\nresearch applications. Code is available at\nhttps://github.com/Terry-cyx/MetaOpenFOAM",
      "tldr_zh": "本研究引入了 MetaOpenFOAM 2.0，一种基于 Large Language Models (LLMs) 驱动的 Chain of Thought (COT) 分解和迭代验证框架，旨在自动化 Computational Fluid Dynamics (CFD) 模拟和后处理任务，从而提升非专家用户通过自然语言输入的访问性。该框架在涵盖流体流动、热传递、燃烧模拟以及提取、可视化后处理的基准测试中，实现了 Executability 得分 6.3/7 和成功率 86.9%，显著优于前代 MetaOpenFOAM 1.0（2.1/7 和 0%）。消融研究证实，COT 分解和迭代改进是性能提升的关键因素，而缩放定律显示增加 COT 步骤能提高准确性但会增加令牌使用，平均每案例成本仅为 0.15 美元。这些结果突显了 LLMs 在自动化 CFD 工作流中的变革潜力，适用于工业和研究应用。",
      "categories": [
        "cs.AI",
        "physics.comp-ph"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages,11 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.00498v1",
      "published_date": "2025-02-01 17:31:25 UTC",
      "updated_date": "2025-02-01 17:31:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:36:23.346631"
    },
    {
      "arxiv_id": "2502.01671v1",
      "title": "Life-Cycle Emissions of AI Hardware: A Cradle-To-Grave Approach and Generational Trends",
      "title_zh": "翻译失败",
      "authors": [
        "Ian Schneider",
        "Hui Xu",
        "Stephan Benecke",
        "David Patterson",
        "Keguo Huang",
        "Parthasarathy Ranganathan",
        "Cooper Elsworth"
      ],
      "abstract": "Specialized hardware accelerators aid the rapid advancement of artificial\nintelligence (AI), and their efficiency impacts AI's environmental\nsustainability. This study presents the first publication of a comprehensive AI\naccelerator life-cycle assessment (LCA) of greenhouse gas emissions, including\nthe first publication of manufacturing emissions of an AI accelerator.\n  Our analysis of five Tensor Processing Units (TPUs) encompasses all stages of\nthe hardware lifespan - from raw material extraction, manufacturing, and\ndisposal, to energy consumption during development, deployment, and serving of\nAI models. Using first-party data, it offers the most comprehensive evaluation\nto date of AI hardware's environmental impact. We include detailed descriptions\nof our LCA to act as a tutorial, road map, and inspiration for other computer\nengineers to perform similar LCAs to help us all understand the environmental\nimpacts of our chips and of AI.\n  A byproduct of this study is the new metric compute carbon intensity (CCI)\nthat is helpful in evaluating AI hardware sustainability and in estimating the\ncarbon footprint of training and inference. This study shows that CCI improves\n3x from TPU v4i to TPU v6e.\n  Moreover, while this paper's focus is on hardware, software advancements\nleverage and amplify these gains.",
      "tldr_zh": "这篇论文首次对 AI 硬件进行了全面的生命周期评估 (LCA)，采用摇篮到坟墓 (cradle-to-grave) 方法，分析了五种 Tensor Processing Units (TPUs) 的温室气体排放，包括从原材料提取、制造到处置，以及 AI 模型开发和部署期间的能源消耗。研究引入了新的指标计算碳强度 (CCI)，用于评估 AI 硬件的可持续性，并发现从 TPU v4i 到 TPU v6e，CCI 改善了 3 倍。论文还提供了详细的 LCA 教程，作为指南，鼓励计算机工程师进行类似评估，并强调软件进步能放大硬件的环保收益。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01671v1",
      "published_date": "2025-02-01 17:26:19 UTC",
      "updated_date": "2025-02-01 17:26:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:36:34.327733"
    },
    {
      "arxiv_id": "2502.00495v1",
      "title": "Looking into the Future of Health-Care Services: Can Life-Like Agents Change the Future of Health-Care Services?",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammad Saleh Torkestani",
        "Robert Davis",
        "Abdolhossein Sarrafzadeh"
      ],
      "abstract": "Time constraints on doctor patient interaction and restricted access to\nspecialists under the managed care system led to increasingly referring to\ncomputers as a medical information source and a self-health-care management\ntool. However, research show that less than 40% of information seekers\nindicated that online information helped them to make a decision about their\nhealth. Searching multiple web sites that need basic computer skills, lack of\ninteraction and no face to face interaction in most search engines and some\nsocial issues, led us to develop a specialized life-like agent that would\novercome mentioned problems.",
      "tldr_zh": "该研究探讨了医疗服务未来的挑战，包括医生与患者互动时间有限以及访问专家的限制，导致人们转向计算机作为医疗信息来源和自我健康管理工具。然而，研究显示，仅不到40%的求助者表示在线信息有助于健康决策，主要由于需要基本计算机技能、缺乏互动和无面对面交流等社会问题。为解决这些问题，作者开发了一个专门的life-like agent，提供更具互动性的医疗支持，旨在提升健康决策的效率和用户体验。总的来说，该代理可能改变医疗服务的未来，提供更个性化和可访问的健康解决方案。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "6 pages, 2 figures, 3rd International Conference on Machine Learning\n  and Computing (ICMLC 2011): February 26-28, 2011, Singapore",
      "pdf_url": "http://arxiv.org/pdf/2502.00495v1",
      "published_date": "2025-02-01 17:11:49 UTC",
      "updated_date": "2025-02-01 17:11:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:36:45.192832"
    },
    {
      "arxiv_id": "2502.00494v2",
      "title": "Data Overvaluation Attack and Truthful Data Valuation",
      "title_zh": "翻译失败",
      "authors": [
        "Shuyuan Zheng",
        "Sudong Cai",
        "Chuan Xiao",
        "Yang Cao",
        "Jianbin Qin",
        "Masatoshi Yoshikawa",
        "Makoto Onizuka"
      ],
      "abstract": "In collaborative machine learning, data valuation, i.e., evaluating the\ncontribution of each client' data to the machine learning model, has become a\ncritical task for incentivizing and selecting positive data contributions.\nHowever, existing studies often assume that clients engage in data valuation\ntruthfully, overlooking the practical motivation for clients to exaggerate\ntheir contributions. To unlock this threat, this paper introduces the first\ndata overvaluation attack, enabling strategic clients to have their data\nsignificantly overvalued. Furthermore, we propose a truthful data valuation\nmetric, named Truth-Shapley. Truth-Shapley is the unique metric that guarantees\nsome promising axioms for data valuation while ensuring that clients' optimal\nstrategy is to perform truthful data valuation. Our experiments demonstrate the\nvulnerability of existing data valuation metrics to the data overvaluation\nattack and validate the robustness and effectiveness of Truth-Shapley.",
      "tldr_zh": "这篇论文探讨了协作机器学习中数据估值的关键问题，指出现有方法假设客户端会诚实参与，但实际中客户端可能通过数据过估值攻击（data overvaluation attack）来夸大其数据贡献，从而影响模型激励和选择。作者引入了首个数据过估值攻击框架，并提出了一种新颖的Truth-Shapley指标，该指标是唯一满足数据估值公理（如Shapley相关属性）并确保客户端最佳策略为真实数据估值的方案。实验验证显示，现有数据估值指标易受攻击，而Truth-Shapley在鲁棒性和有效性方面表现出色。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00494v2",
      "published_date": "2025-02-01 17:05:37 UTC",
      "updated_date": "2025-02-04 08:36:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:36:57.472874"
    },
    {
      "arxiv_id": "2502.01669v1",
      "title": "Addressing Delayed Feedback in Conversion Rate Prediction via Influence Functions",
      "title_zh": "翻译失败",
      "authors": [
        "Chenlu Ding",
        "Jiancan Wu",
        "Yancheng Yuan",
        "Junfeng Fang",
        "Cunchun Li",
        "Xiang Wang",
        "Xiangnan He"
      ],
      "abstract": "In the realm of online digital advertising, conversion rate (CVR) prediction\nplays a pivotal role in maximizing revenue under cost-per-conversion (CPA)\nmodels, where advertisers are charged only when users complete specific\nactions, such as making a purchase. A major challenge in CVR prediction lies in\nthe delayed feedback problem-conversions may occur hours or even weeks after\ninitial user interactions. This delay complicates model training, as recent\ndata may be incomplete, leading to biases and diminished performance. Although\nexisting methods attempt to address this issue, they often fall short in\nadapting to evolving user behaviors and depend on auxiliary models, which\nintroduces computational inefficiencies and the risk of model inconsistency. In\nthis work, we propose an Influence Function-empowered framework for Delayed\nFeedback Modeling (IF-DFM). IF-DFM leverages influence functions to estimate\nhow newly acquired and delayed conversion data impact model parameters,\nenabling efficient parameter updates without the need for full retraining.\nAdditionally, we present a scalable algorithm that efficiently computes\nparameter updates by reframing the inverse Hessian-vector product as an\noptimization problem, striking a balance between computational efficiency and\neffectiveness. Extensive experiments on benchmark datasets demonstrate that\nIF-DFM consistently surpasses state-of-the-art methods, significantly enhancing\nboth prediction accuracy and model adaptability.",
      "tldr_zh": "该论文针对在线数字广告中转换率 (CVR) 预测的延迟反馈问题，提出了一种基于 Influence Functions 的框架（IF-DFM），通过估计新数据和延迟转换数据对模型参数的影响，实现高效参数更新，而无需完整重训。IF-DFM 还引入了一个可扩展算法，将逆Hessian-向量乘积转化为优化问题，以平衡计算效率和性能。实验结果显示，该框架在基准数据集上显著超越现有方法，提高了预测准确性和模型适应性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01669v1",
      "published_date": "2025-02-01 16:23:13 UTC",
      "updated_date": "2025-02-01 16:23:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:37:09.265072"
    },
    {
      "arxiv_id": "2502.01667v1",
      "title": "Refining Alignment Framework for Diffusion Models with Intermediate-Step Preference Ranking",
      "title_zh": "利用中间步骤偏",
      "authors": [
        "Jie Ren",
        "Yuhang Zhang",
        "Dongrui Liu",
        "Xiaopeng Zhang",
        "Qi Tian"
      ],
      "abstract": "Direct preference optimization (DPO) has shown success in aligning diffusion\nmodels with human preference. Previous approaches typically assume a consistent\npreference label between final generations and noisy samples at intermediate\nsteps, and directly apply DPO to these noisy samples for fine-tuning. However,\nwe theoretically identify inherent issues in this assumption and its impacts on\nthe effectiveness of preference alignment. We first demonstrate the inherent\nissues from two perspectives: gradient direction and preference order, and then\npropose a Tailored Preference Optimization (TailorPO) framework for aligning\ndiffusion models with human preference, underpinned by some theoretical\ninsights. Our approach directly ranks intermediate noisy samples based on their\nstep-wise reward, and effectively resolves the gradient direction issues\nthrough a simple yet efficient design. Additionally, we incorporate the\ngradient guidance of diffusion models into preference alignment to further\nenhance the optimization effectiveness. Experimental results demonstrate that\nour method significantly improves the model's ability to generate aesthetically\npleasing and human-preferred images.",
      "tldr_zh": "本研究发现，直接偏好优化(DPO)方法在对扩散模型(diffusion models)进行偏好对齐时，假设最终生成和中间噪声样本具有一致偏好标签会导致梯度方向和偏好顺序问题，从而影响优化效果。论文提出Tailored Preference Optimization (TailorPO)框架，通过基于步-wise reward直接对中间噪声样本进行排名，并整合扩散模型的梯度指导，解决了这些问题并提升了优化效率。实验结果显示，该方法显著提高了模型生成美观且符合人类偏好的图像能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01667v1",
      "published_date": "2025-02-01 16:08:43 UTC",
      "updated_date": "2025-02-01 16:08:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:37:20.861732"
    },
    {
      "arxiv_id": "2502.00465v1",
      "title": "Enhance Learning Efficiency of Oblique Decision Tree via Feature Concatenation",
      "title_zh": "通过特征连接提升斜决策树的学习效率",
      "authors": [
        "Shen-Huan Lyu",
        "Yi-Xiao He",
        "Yanyan Wang",
        "Zhihao Qu",
        "Bin Tang",
        "Baoliu Ye"
      ],
      "abstract": "Oblique Decision Tree (ODT) separates the feature space by linear\nprojections, as opposed to the conventional Decision Tree (DT) that forces\naxis-parallel splits. ODT has been proven to have a stronger representation\nability than DT, as it provides a way to create shallower tree structures while\nstill approximating complex decision boundaries. However, its learning\nefficiency is still insufficient, since the linear projections cannot be\ntransmitted to the child nodes, resulting in a waste of model parameters. In\nthis work, we propose an enhanced ODT method with Feature Concatenation\n(\\texttt{FC-ODT}), which enables in-model feature transformation to transmit\nthe projections along the decision paths. Theoretically, we prove that our\nmethod enjoys a faster consistency rate w.r.t. the tree depth, indicating that\nour method possesses a significant advantage in generalization performance,\nespecially for shallow trees. Experiments show that \\texttt{FC-ODT} can\noutperform the other state-of-the-art decision trees with a limited tree depth.",
      "tldr_zh": "该论文探讨了Oblique Decision Tree (ODT)，它通过线性投影分割特征空间，比传统的Decision Tree (DT)更具表示能力，但学习效率不足。作者提出了一种增强方法Feature Concatenation (FC-ODT)，通过在模型内传输线性投影来沿决策路径传递特征变换，从而提高参数利用效率。理论上，FC-ODT证明了在树深度方面具有更快的consistency rate，提升了泛化性能，尤其适用于浅层树结构。实验结果显示，FC-ODT在有限树深度下优于其他state-of-the-art决策树。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00465v1",
      "published_date": "2025-02-01 15:49:18 UTC",
      "updated_date": "2025-02-01 15:49:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:37:33.047536"
    },
    {
      "arxiv_id": "2502.00459v2",
      "title": "AudioGenX: Explainability on Text-to-Audio Generative Models",
      "title_zh": "翻译失败",
      "authors": [
        "Hyunju Kang",
        "Geonhee Han",
        "Yoonjae Jeong",
        "Hogun Park"
      ],
      "abstract": "Text-to-audio generation models (TAG) have achieved significant advances in\ngenerating audio conditioned on text descriptions. However, a critical\nchallenge lies in the lack of transparency regarding how each textual input\nimpacts the generated audio. To address this issue, we introduce AudioGenX, an\nExplainable AI (XAI) method that provides explanations for text-to-audio\ngeneration models by highlighting the importance of input tokens. AudioGenX\noptimizes an Explainer by leveraging factual and counterfactual objective\nfunctions to provide faithful explanations at the audio token level. This\nmethod offers a detailed and comprehensive understanding of the relationship\nbetween text inputs and audio outputs, enhancing both the explainability and\ntrustworthiness of TAG models. Extensive experiments demonstrate the\neffectiveness of AudioGenX in producing faithful explanations, benchmarked\nagainst existing methods using novel evaluation metrics specifically designed\nfor audio generation tasks.",
      "tldr_zh": "该研究针对文本到音频生成模型（Text-to-Audio Generation, TAG）的透明性问题，提出了AudioGenX，一种Explainable AI (XAI)方法，用于突出输入文本标记的重要性以提供解释。AudioGenX通过优化一个Explainer，利用事实和反事实目标函数，在音频标记级别生成忠实的解释，从而揭示文本输入与音频输出之间的关系，并提升模型的可解释性和可信度。实验结果显示，AudioGenX在音频生成任务中比现有方法更有效，并通过专门设计的评估指标进行了基准测试。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "14 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.00459v2",
      "published_date": "2025-02-01 15:37:42 UTC",
      "updated_date": "2025-02-04 04:00:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:37:44.902130"
    },
    {
      "arxiv_id": "2502.00451v1",
      "title": "Towards Privacy-aware Mental Health AI Models: Advances, Challenges, and Opportunities",
      "title_zh": "迈向隐私感知的心理健康AI模型：进展、挑战和机会",
      "authors": [
        "Aishik Mandal",
        "Tanmoy Chakraborty",
        "Iryna Gurevych"
      ],
      "abstract": "Mental illness is a widespread and debilitating condition with substantial\nsocietal and personal costs. Traditional diagnostic and treatment approaches,\nsuch as self-reported questionnaires and psychotherapy sessions, often impose\nsignificant burdens on both patients and clinicians, limiting accessibility and\nefficiency. Recent advances in Artificial Intelligence (AI), particularly in\nNatural Language Processing and multimodal techniques, hold great potential for\nrecognizing and addressing conditions such as depression, anxiety, bipolar\ndisorder, schizophrenia, and post-traumatic stress disorder. However, privacy\nconcerns, including the risk of sensitive data leakage from datasets and\ntrained models, remain a critical barrier to deploying these AI systems in\nreal-world clinical settings. These challenges are amplified in multimodal\nmethods, where personal identifiers such as voice and facial data can be\nmisused. This paper presents a critical and comprehensive study of the privacy\nchallenges associated with developing and deploying AI models for mental\nhealth. We further prescribe potential solutions, including data anonymization,\nsynthetic data generation, and privacy-preserving model training, to strengthen\nprivacy safeguards in practical applications. Additionally, we discuss\nevaluation frameworks to assess the privacy-utility trade-offs in these\napproaches. By addressing these challenges, our work aims to advance the\ndevelopment of reliable, privacy-aware AI tools to support clinical\ndecision-making and improve mental health outcomes.",
      "tldr_zh": "该论文探讨了AI在心理健康领域的应用潜力，特别是Natural Language Processing和multimodal techniques在识别和处理精神疾病（如抑郁、焦虑等）方面的进展，但强调了数据泄露等隐私挑战，尤其是涉及语音和面部数据的multimodal方法。作者分析了这些挑战，并提出解决方案，包括data anonymization、synthetic data generation和privacy-preserving model training，以增强AI模型的隐私保护。论文还讨论了评估框架来平衡隐私与实用性，最终旨在推动可靠的隐私意识AI工具，支持临床决策并改善心理健康结果。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.00451v1",
      "published_date": "2025-02-01 15:10:02 UTC",
      "updated_date": "2025-02-01 15:10:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:37:57.698144"
    },
    {
      "arxiv_id": "2502.10417v1",
      "title": "Evolutionary Power-Aware Routing in VANETs using Monte-Carlo Simulation",
      "title_zh": "翻译失败",
      "authors": [
        "J. Toutouh",
        "S. Nesmachnow",
        "E. Alba"
      ],
      "abstract": "This work addresses the reduction of power consumption of the AODV routing\nprotocol in vehicular networks as an optimization problem. Nowadays, network\ndesigners focus on energy-aware communication protocols, specially to deploy\nwireless networks. Here, we introduce an automatic method to search for\nenergy-efficient AODV configurations by using an evolutionary algorithm and\nparallel Monte-Carlo simulations to improve the accuracy of the evaluation of\ntentative solutions. The experimental results demonstrate that significant\npower consumption improvements over the standard configuration can be attained,\nwith no noteworthy loss in the quality of service.",
      "tldr_zh": "这篇论文将AODV路由协议在VANETs中的功耗减少视为优化问题，提出了一种使用evolutionary algorithm结合并行Monte-Carlo simulations的自动方法来搜索能量高效的AODV配置。实验结果显示，该方法相对于标准配置显著降低了功耗，同时未造成服务质量的显著损失。该研究为无线网络设计提供了能量感知的改进策略。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.NE",
      "comment": "Accepted and presented in 2012 International Conference on High\n  Performance Computing & Simulation (HPCS), Madrid, Spain, 2012",
      "pdf_url": "http://arxiv.org/pdf/2502.10417v1",
      "published_date": "2025-02-01 14:29:31 UTC",
      "updated_date": "2025-02-01 14:29:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:38:08.562049"
    },
    {
      "arxiv_id": "2502.00443v2",
      "title": "Model-Free Predictive Control: Introductory Algebraic Calculations, and a Comparison with HEOL and ANNs",
      "title_zh": "无模型",
      "authors": [
        "Cédric Join",
        "Emmanuel Delaleau",
        "Michel Fliess"
      ],
      "abstract": "Model predictive control (MPC) is a popular control engineering practice, but\nrequires a sound knowledge of the model. Model-free predictive control (MFPC),\na burning issue today, also related to reinforcement learning (RL) in AI, is\nreformulated here via a linear differential equation with constant\ncoefficients, thanks to a new perspective on optimal control combined with\nrecent advances in the field of model-free control (MFC). It is replacing\nDynamic Programming, the Hamilton-Jacobi-Bellman equation, and Pontryagin's\nMaximum Principle. The computing burden is low. The implementation is\nstraightforward. Two nonlinear examples, a chemical reactor and a two tank\nsystem, are illustrating our approach. A comparison with the HEOL setting,\nwhere some expertise of the process model is needed, shows only a slight\nsuperiority of the later. A recent identification of the two tank system via a\ncomplex ANN architecture might indicate that a full modeling and the\ncorresponding machine learning mechanism are not always necessary neither in\ncontrol, nor, more generally, in AI.",
      "tldr_zh": "这篇论文重新表述了模型无关预测控制(MFPC)，将其表述为一个线性微分方程，通过结合最优控制的新视角和模型无关控制(MFC)的最新进展，取代了动态规划、Hamilton-Jacobi-Bellman 方程和 Pontryagin's Maximum Principle。方法计算负担低，实现简单，并通过化学反应器和两个水箱系统的非线性例子进行验证。与 HEOL 框架比较显示，HEOL 略微优越，但需要部分过程模型知识。论文还指出，使用复杂的 ANNs 架构进行系统识别可能并不总是必要，这为控制工程和强化学习(RL)领域提供了更高效的替代方案。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY",
        "49J99",
        "I.2.8"
      ],
      "primary_category": "eess.SY",
      "comment": "Joint IFAC Conference: SSSC, TDS, COSY -- Gif-sur-Vette, France, 30\n  June-2 July 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.00443v2",
      "published_date": "2025-02-01 14:23:34 UTC",
      "updated_date": "2025-04-22 07:35:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:38:22.291071"
    },
    {
      "arxiv_id": "2502.00434v1",
      "title": "Compilation and Fast Model Counting beyond CNF",
      "title_zh": "超越 CNF 的编译与快速模型计数",
      "authors": [
        "Alexis de Colnet",
        "Stefan Szeider",
        "Tianwei Zhang"
      ],
      "abstract": "Circuits in deterministic decomposable negation normal form (d-DNNF) are\nrepresentations of Boolean functions that enable linear-time model counting.\nThis paper strengthens our theoretical knowledge of what classes of functions\ncan be efficiently transformed, or compiled, into d-DNNF. Our main contribution\nis the fixed-parameter tractable (FPT) compilation of conjunctions of specific\nconstraints parameterized by incidence treewidth. This subsumes the known\nresult for CNF. The constraints in question are all functions representable by\nconstant-width ordered binary decision diagrams (OBDDs) for all variable\norderings. For instance, this includes parity constraints and cardinality\nconstraints with constant threshold. The running time of the FPT compilation is\nsingly exponential in the incidence treewidth but hides large constants in the\nexponent. To balance that, we give a more efficient FPT algorithm for model\ncounting that applies to a sub-family of the constraints and does not require\ncompilation.",
      "tldr_zh": "这篇论文扩展了布尔函数的编译理论，展示了如何将超出 CNF 的特定约束合取高效编译成 d-DNNF 电路，以实现线性时间的模型计数。主要贡献是提出一种固定参数可计算（FPT）算法，参数化于 incidence treewidth，能够处理所有可以用常量宽度 OBDDs 表示的函数，例如 parity 约束和具有常量阈值的 cardinality 约束。该算法的运行时间为单指数于 incidence treewidth，但包含较大的常量。为了提高效率，论文还提供了一个更优化的 FPT 模型计数算法，适用于这些约束的子集，且无需编译。",
      "categories": [
        "cs.CC",
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.CC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00434v1",
      "published_date": "2025-02-01 14:00:04 UTC",
      "updated_date": "2025-02-01 14:00:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:38:34.455993"
    },
    {
      "arxiv_id": "2502.00425v1",
      "title": "MQuant: Unleashing the Inference Potential of Multimodal Large Language Models via Full Static Quantization",
      "title_zh": "MQuant：通过完全静态量化释放多模态大语言模型的推理潜力",
      "authors": [
        "JiangYong Yu",
        "Sifan Zhou",
        "Dawei Yang",
        "Shuo Wang",
        "Shuoyu Li",
        "Xing Hu",
        "Chen Xu",
        "Zukang Xu",
        "Changyong Shu",
        "Zhihang Yuan"
      ],
      "abstract": "Multimodal large language models (MLLMs) have garnered widespread attention\ndue to their ability to understand multimodal input. However, their large\nparameter sizes and substantial computational demands severely hinder their\npractical deployment and application.While quantization is an effective way to\nreduce model size and inference latency, its application to MLLMs remains\nunderexplored. In this paper, we propose MQuant, a post-training quantization\n(PTQ) framework designed to tackle the unique challenges of multimodal large\nlanguage models (MLLMs). Conventional quantization often struggles with MLLMs\nbecause of (a) high inference latency from large visual token counts, (b)\ndistributional disparities between visual and textual tokens, and (c) extreme\noutliers introduced by Hadamard-based transformations. To address these issues,\nMQuant introduces: Modality-Specific Static Quantization (MSQ), assigning\ndistinct static scales for visual vs. textual tokens; Attention-Invariant\nFlexible Switching (AIFS), reordering tokens to preserve casual attention while\neliminating expensive token-wise scale computations; Rotation Magnitude\nSuppression (RMS), mitigating weight outliers arising from online Hadamard\nrotations. On five mainstream MLLMs (including Qwen-VL, MiniCPM-V, CogVLM2),\nMQuant under W4A8 achieves near-floating-point accuracy (<1% degradation) while\nreducing inference latency by up to 30%, significantly outperforming existing\nPTQ baselines. Our MQuant effectively bridges the gap for efficient and\naccurate MLLMs inference in resource-constrained devices. Code will be\nreleased.",
      "tldr_zh": "本文提出 MQuant，一种后训练量化(PTQ)框架，旨在解决多模态大语言模型(MLLMs)的高参数规模和计算需求问题，通过Modality-Specific Static Quantization (MSQ)、Attention-Invariant Flexible Switching (AIFS) 和 Rotation Magnitude Suppression (RMS) 等技术，分别处理视觉文本标记分布差异、高延迟和Hadamard变换异常值。MQuant 在五个主流 MLLMs（如 Qwen-VL 和 CogVLM2）上实现了 W4A8 量化，保持近乎浮点精度（<1% 下降），并将推理延迟降低高达 30%，显著优于现有 PTQ 基线。该框架为 MLLMs 在资源受限设备上的高效部署提供了关键支持。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "First quantization solution for Multimodal large language models\n  applicable to 5 mainstream MLLMs",
      "pdf_url": "http://arxiv.org/pdf/2502.00425v1",
      "published_date": "2025-02-01 13:08:02 UTC",
      "updated_date": "2025-02-01 13:08:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:38:47.149889"
    },
    {
      "arxiv_id": "2502.00415v1",
      "title": "MarketSenseAI 2.0: Enhancing Stock Analysis through LLM Agents",
      "title_zh": "MarketSenseAI 2.0：通过 LLM 代理增强股票分析",
      "authors": [
        "George Fatouros",
        "Kostas Metaxas",
        "John Soldatos",
        "Manos Karathanassis"
      ],
      "abstract": "MarketSenseAI is a novel framework for holistic stock analysis which\nleverages Large Language Models (LLMs) to process financial news, historical\nprices, company fundamentals and the macroeconomic environment to support\ndecision making in stock analysis and selection. In this paper, we present the\nlatest advancements on MarketSenseAI, driven by rapid technological expansion\nin LLMs. Through a novel architecture combining Retrieval-Augmented Generation\nand LLM agents, the framework processes SEC filings and earnings calls, while\nenriching macroeconomic analysis through systematic processing of diverse\ninstitutional reports. We demonstrate a significant improvement in fundamental\nanalysis accuracy over the previous version. Empirical evaluation on S\\&P 100\nstocks over two years (2023-2024) shows MarketSenseAI achieving cumulative\nreturns of 125.9% compared to the index return of 73.5%, while maintaining\ncomparable risk profiles. Further validation on S\\&P 500 stocks during 2024\ndemonstrates the framework's scalability, delivering a 33.8% higher Sortino\nratio than the market. This work marks a significant advancement in applying\nLLM technology to financial analysis, offering insights into the robustness of\nLLM-driven investment strategies.",
      "tldr_zh": "本研究介绍了 MarketSenseAI 2.0，一种通过 Large Language Models (LLMs) 代理增强股票分析的框架，能够处理金融新闻、历史价格、公司基本面和宏观经济环境，支持决策制定。框架采用 Retrieval-Augmented Generation (RAG) 和 LLM agents 的新型架构，系统处理 SEC filings、earnings calls 以及机构报告，从而显著提高了基本面分析的准确性。在实证评估中，该框架在 S&P 100 股票上（2023-2024）实现了 125.9% 的累积回报，远超指数的 73.5%，并保持类似风险水平；此外，在 S&P 500 股票上的测试显示，Sortino ratio 高出市场 33.8%，证明了其可扩展性。该工作标志着 LLM 技术在金融分析中的重大进展，展示了 LLM 驱动投资策略的稳健性和潜力。",
      "categories": [
        "q-fin.CP",
        "cs.AI",
        "cs.CL",
        "cs.MA",
        "q-fin.PM",
        "68T07, 68T50, 91G10, 91G15",
        "I.2.1; I.2.7; J.4"
      ],
      "primary_category": "q-fin.CP",
      "comment": "25 pages, 7 figures, Under review at Financial Innovation (FIN)",
      "pdf_url": "http://arxiv.org/pdf/2502.00415v1",
      "published_date": "2025-02-01 12:33:23 UTC",
      "updated_date": "2025-02-01 12:33:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:38:57.776898"
    },
    {
      "arxiv_id": "2502.00409v2",
      "title": "Doing More with Less -- Implementing Routing Strategies in Large Language Model-Based Systems: An Extended Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Clovis Varangot-Reille",
        "Christophe Bouvard",
        "Antoine Gourru",
        "Mathieu Ciancone",
        "Marion Schaeffer",
        "François Jacquenet"
      ],
      "abstract": "Large Language Models (LLM)-based systems, i.e. interconnected elements that\ninclude an LLM as a central component (e.g., conversational agents), are\ntypically monolithic static architectures that rely on a single LLM for all\nuser queries. However, they often require different preprocessing strategies,\nlevels of reasoning, or knowledge. Generalist LLMs (e.g. GPT-4) trained on very\nlarge multi-topic corpora can perform well in a variety of tasks. They require\nsignificant financial, energy, and hardware resources that may not be justified\nfor basic tasks. This implies potentially investing in unnecessary costs for a\ngiven query. To overcome this problem, a routing mechanism routes user queries\nto the most suitable components, such as smaller LLMs or experts in specific\ntopics. This approach may improve response quality while minimising costs.\nRouting can be expanded to other components of the conversational agent\narchitecture, such as the selection of optimal embedding strategies. This paper\nexplores key considerations for integrating routing into LLM-based systems,\nfocusing on resource management, cost definition, and strategy selection. Our\nmain contributions include a formalisation of the problem, a novel taxonomy of\nexisting approaches emphasising relevance and resource efficiency, and a\ncomparative analysis of these strategies in relation to industry practices.\nFinally, we identify critical challenges and directions for future research.",
      "tldr_zh": "这篇论文调查了在 Large Language Models (LLM)-based 系统中实施路由策略的方法，旨在解决单一 LLM 架构的资源浪费问题，例如过度依赖通用模型（如 GPT-4）导致的成本和能耗增加。论文提出路由机制（routing mechanism）将用户查询路由到最合适的组件，如更小规模的 LLM 或特定主题专家，从而提升响应质量并优化资源管理。关键贡献包括对问题的形式化（formalisation of the problem）、一个新颖的分类法（novel taxonomy）强调相关性和资源效率，以及对现有策略的比较分析。最终，论文识别了关键挑战和未来研究方向，以指导 LLM 系统的发展。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00409v2",
      "published_date": "2025-02-01 12:08:38 UTC",
      "updated_date": "2025-02-04 09:12:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:39:10.296856"
    },
    {
      "arxiv_id": "2502.00407v1",
      "title": "Causal Abstraction Learning based on the Semantic Embedding Principle",
      "title_zh": "基于语义嵌入原则的因果抽象学习",
      "authors": [
        "Gabriele D'Acunto",
        "Fabio Massimo Zennaro",
        "Yorgos Felekis",
        "Paolo Di Lorenzo"
      ],
      "abstract": "Structural causal models (SCMs) allow us to investigate complex systems at\nmultiple levels of resolution. The causal abstraction (CA) framework formalizes\nthe mapping between high- and low-level SCMs. We address CA learning in a\nchallenging and realistic setting, where SCMs are inaccessible, interventional\ndata is unavailable, and sample data is misaligned. A key principle of our\nframework is $\\textit{semantic embedding}$, formalized as the high-level\ndistribution lying on a subspace of the low-level one. This principle naturally\nlinks linear CA to the geometry of the $\\textit{Stiefel manifold}$. We present\na category-theoretic approach to SCMs that enables the learning of a CA by\nfinding a morphism between the low- and high-level probability measures,\nadhering to the semantic embedding principle. Consequently, we formulate a\ngeneral CA learning problem. As an application, we solve the latter problem for\nlinear CA; considering Gaussian measures and the Kullback-Leibler divergence as\nan objective. Given the nonconvexity of the learning task, we develop three\nalgorithms building upon existing paradigms for Riemannian optimization. We\ndemonstrate that the proposed methods succeed on both synthetic and real-world\nbrain data with different degrees of prior information about the structure of\nCA.",
      "tldr_zh": "这篇论文基于语义嵌入原则，提出了一种学习因果抽象(CA)框架，用于结构因果模型(SCMs)之间的高低层映射，特别是在SCMs不可访问、缺乏干预数据且样本数据不对齐的现实场景下。论文将语义嵌入形式化为高层次分布位于低层次分布子空间，并通过范畴论方法寻找概率测度的形态(morphism)，从而制定了通用的CA学习问题。针对线性CA，研究开发了三个基于Riemannian优化的算法，使用高斯测度和Kullback-Leibler散度作为优化目标，并在合成和真实脑数据上验证了方法的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00407v1",
      "published_date": "2025-02-01 11:54:44 UTC",
      "updated_date": "2025-02-01 11:54:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:39:22.296897"
    },
    {
      "arxiv_id": "2502.00406v1",
      "title": "ALU: Agentic LLM Unlearning",
      "title_zh": "翻译失败",
      "authors": [
        "Debdeep Sanyal",
        "Murari Mandal"
      ],
      "abstract": "Information removal or suppression in large language models (LLMs) is a\ndesired functionality, useful in AI regulation, legal compliance, safety, and\nprivacy. LLM unlearning methods aim to remove information on demand from LLMs.\nCurrent LLM unlearning methods struggle to balance the unlearning efficacy and\nutility due to the competing nature of these objectives. Keeping the unlearning\nprocess computationally feasible without assuming access to the model weights\nis an overlooked area. We present the first agentic LLM unlearning (ALU)\nmethod, a multi-agent, retrain-free, model-agnostic approach to LLM unlearning\nthat achieves effective unlearning while preserving the utility. Our ALU\nframework unlearns by involving multiple LLM agents, each designed for a\nspecific step in the unlearning process, without the need to update model\nweights for any of the agents in the framework. Users can easily request any\nset of unlearning instances in any sequence, and ALU seamlessly adapts in real\ntime. This is facilitated without requiring any changes in the underlying LLM\nmodel. Through extensive experiments on established benchmarks (TOFU, WMDP,\nWPU) and jailbreaking techniques (many shot, target masking, other languages),\nwe demonstrate that ALU consistently stands out as the most robust LLM\nunlearning framework among current state-of-the-art methods while incurring a\nlow constant-time cost. We further highlight ALU's superior performance\ncompared to existing methods when evaluated at scale. Specifically, ALU is\nassessed on up to 1000 unlearning targets, exceeding the evaluation scope of\nall previously proposed LLM unlearning methods.",
      "tldr_zh": "该研究提出ALU（Agentic LLM Unlearning），一种多智能体、免重新训练且模型无关的框架，旨在从大型语言模型（LLMs）中有效移除指定信息，同时平衡卸载效能和模型效用。ALU通过多个专门LLM智能体处理卸载过程的各个步骤，用户可随时请求卸载实例并实现实时适应，而无需修改模型权重或访问模型参数。在TOFU、WMDP和WPU等基准测试中，ALU在面对越狱技术时表现出最强的鲁棒性，并在大规模评估（如1000个卸载目标）中优于现有方法，仅需低常数时间成本。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00406v1",
      "published_date": "2025-02-01 11:45:44 UTC",
      "updated_date": "2025-02-01 11:45:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:39:33.627718"
    },
    {
      "arxiv_id": "2502.00401v1",
      "title": "Spectro-Riemannian Graph Neural Networks",
      "title_zh": "谱-黎曼图神经网络",
      "authors": [
        "Karish Grover",
        "Haiyang Yu",
        "Xiang Song",
        "Qi Zhu",
        "Han Xie",
        "Vassilis N. Ioannidis",
        "Christos Faloutsos"
      ],
      "abstract": "Can integrating spectral and curvature signals unlock new potential in graph\nrepresentation learning? Non-Euclidean geometries, particularly Riemannian\nmanifolds such as hyperbolic (negative curvature) and spherical (positive\ncurvature), offer powerful inductive biases for embedding complex graph\nstructures like scale-free, hierarchical, and cyclic patterns. Meanwhile,\nspectral filtering excels at processing signal variations across graphs, making\nit effective in homophilic and heterophilic settings. Leveraging both can\nsignificantly enhance the learned representations. To this end, we propose\nSpectro-Riemannian Graph Neural Networks (CUSP) - the first graph\nrepresentation learning paradigm that unifies both CUrvature (geometric) and\nSPectral insights. CUSP is a mixed-curvature spectral GNN that learns spectral\nfilters to optimize node embeddings in products of constant-curvature manifolds\n(hyperbolic, spherical, and Euclidean). Specifically, CUSP introduces three\nnovel components: (a) Cusp Laplacian, an extension of the traditional graph\nLaplacian based on Ollivier-Ricci curvature, designed to capture the curvature\nsignals better; (b) Cusp Filtering, which employs multiple Riemannian graph\nfilters to obtain cues from various bands in the eigenspectrum; and (c) Cusp\nPooling, a hierarchical attention mechanism combined with a curvature-based\npositional encoding to assess the relative importance of differently curved\nsubstructures in our graph. Empirical evaluation across eight homophilic and\nheterophilic datasets demonstrates the superiority of CUSP in node\nclassification and link prediction tasks, with a gain of up to 5.3% over\nstate-of-the-art models.",
      "tldr_zh": "本研究探讨了整合光谱信号和曲率信号以提升图表示学习的效果，提出了一种新的框架：Spectro-Riemannian Graph Neural Networks (CUSP)。CUSP 是一种混合曲率光谱 GNN，通过三个创新组件——Cusp Laplacian（基于 Ollivier-Ricci 曲率的图 Laplacian 扩展）、Cusp Filtering（使用多个 Riemannian 图过滤器从 eigenspectrum 不同频带获取信息）和 Cusp Pooling（结合层次注意力机制和曲率-based 定位编码）——来优化节点嵌入在双曲、球面和欧氏流形的产品中。实验结果显示，在八个同质和异质数据集上，CUSP 在节点分类和链接预测任务中比最先进模型提升高达 5.3%，证明了其在处理复杂图结构方面的优越性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.00401v1",
      "published_date": "2025-02-01 11:31:01 UTC",
      "updated_date": "2025-02-01 11:31:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:39:46.220233"
    },
    {
      "arxiv_id": "2502.00385v2",
      "title": "The Impact of Persona-based Political Perspectives on Hateful Content Detection",
      "title_zh": "基于角色的政治观点对仇恨内容检测的影响",
      "authors": [
        "Stefano Civelli",
        "Pietro Bernardelle",
        "Gianluca Demartini"
      ],
      "abstract": "While pretraining language models with politically diverse content has been\nshown to improve downstream task fairness, such approaches require significant\ncomputational resources often inaccessible to many researchers and\norganizations. Recent work has established that persona-based prompting can\nintroduce political diversity in model outputs without additional training.\nHowever, it remains unclear whether such prompting strategies can achieve\nresults comparable to political pretraining for downstream tasks. We\ninvestigate this question using persona-based prompting strategies in\nmultimodal hate-speech detection tasks, specifically focusing on hate speech in\nmemes. Our analysis reveals that when mapping personas onto a political compass\nand measuring persona agreement, inherent political positioning has\nsurprisingly little correlation with classification decisions. Notably, this\nlack of correlation persists even when personas are explicitly injected with\nstronger ideological descriptors. Our findings suggest that while LLMs can\nexhibit political biases in their responses to direct political questions,\nthese biases may have less impact on practical classification tasks than\npreviously assumed. This raises important questions about the necessity of\ncomputationally expensive political pretraining for achieving fair performance\nin downstream tasks.",
      "tldr_zh": "本研究探讨了基于角色（persona-based prompting）的提示策略是否能在仇恨内容检测任务中实现与政治预训练（political pretraining）相当的效果，而无需额外计算资源。研究聚焦于多模态仇恨言论检测（hate-speech detection），特别是 memes，通过将角色映射到政治罗盘（political compass）并分析角色一致性。结果显示，内在政治定位与分类决策的相关性很低，即使注入更强的意识形态描述，LLMs 的政治偏见对实际任务影响有限。这表明，进行计算密集型政治预训练可能并非必要，以实现下游任务的公平性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Companion Proceedings of the ACM Web Conference 2025 (WWW\n  Companion'25)",
      "pdf_url": "http://arxiv.org/pdf/2502.00385v2",
      "published_date": "2025-02-01 09:53:17 UTC",
      "updated_date": "2025-02-26 03:23:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:39:58.017979"
    },
    {
      "arxiv_id": "2502.00382v1",
      "title": "Masked Generative Nested Transformers with Decode Time Scaling",
      "title_zh": "带有解码时缩放的遮罩生成嵌套Transformer",
      "authors": [
        "Sahil Goyal",
        "Debapriya Tula",
        "Gagan Jain",
        "Pradeep Shenoy",
        "Prateek Jain",
        "Sujoy Paul"
      ],
      "abstract": "Recent advances in visual generation have made significant strides in\nproducing content of exceptional quality. However, most methods suffer from a\nfundamental problem - a bottleneck of inference computational efficiency. Most\nof these algorithms involve multiple passes over a transformer model to\ngenerate tokens or denoise inputs. However, the model size is kept consistent\nthroughout all iterations, which makes it computationally expensive. In this\nwork, we aim to address this issue primarily through two key ideas - (a) not\nall parts of the generation process need equal compute, and we design a decode\ntime model scaling schedule to utilize compute effectively, and (b) we can\ncache and reuse some of the computation. Combining these two ideas leads to\nusing smaller models to process more tokens while large models process fewer\ntokens. These different-sized models do not increase the parameter size, as\nthey share parameters. We rigorously experiment with ImageNet256$\\times$256 ,\nUCF101, and Kinetics600 to showcase the efficacy of the proposed method for\nimage/video generation and frame prediction. Our experiments show that with\nalmost $3\\times$ less compute than baseline, our model obtains competitive\nperformance.",
      "tldr_zh": "本文提出 Masked Generative Nested Transformers with Decode Time Scaling 方法，针对视觉生成任务中的推理计算效率瓶颈，通过设计解码时模型缩放调度和计算缓存重用，实现不同大小模型的动态分配，这些模型共享参数以避免增加总体参数量。主要创新包括使用较小模型处理更多令牌，而较大模型处理较少令牌，从而有效利用计算资源。在 ImageNet256×256、UCF101 和 Kinetics600 数据集上的实验显示，该方法在图像/视频生成和帧预测任务中，与基线相比几乎减少 3 倍计算量，却取得了竞争性的性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00382v1",
      "published_date": "2025-02-01 09:41:01 UTC",
      "updated_date": "2025-02-01 09:41:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:40:10.049268"
    },
    {
      "arxiv_id": "2502.00379v4",
      "title": "Latent Action Learning Requires Supervision in the Presence of Distractors",
      "title_zh": "潜在动作学习在干扰因素存在时需要监督",
      "authors": [
        "Alexander Nikulin",
        "Ilya Zisman",
        "Denis Tarasov",
        "Nikita Lyubaykin",
        "Andrei Polubarov",
        "Igor Kiselev",
        "Vladislav Kurenkov"
      ],
      "abstract": "Recently, latent action learning, pioneered by Latent Action Policies (LAPO),\nhave shown remarkable pre-training efficiency on observation-only data,\noffering potential for leveraging vast amounts of video available on the web\nfor embodied AI. However, prior work has focused on distractor-free data, where\nchanges between observations are primarily explained by ground-truth actions.\nUnfortunately, real-world videos contain action-correlated distractors that may\nhinder latent action learning. Using Distracting Control Suite (DCS) we\nempirically investigate the effect of distractors on latent action learning and\ndemonstrate that LAPO struggle in such scenario. We propose LAOM, a simple LAPO\nmodification that improves the quality of latent actions by 8x, as measured by\nlinear probing. Importantly, we show that providing supervision with\nground-truth actions, as few as 2.5% of the full dataset, during latent action\nlearning improves downstream performance by 4.2x on average. Our findings\nsuggest that integrating supervision during Latent Action Models (LAM) training\nis critical in the presence of distractors, challenging the conventional\npipeline of first learning LAM and only then decoding from latent to\nground-truth actions.",
      "tldr_zh": "本研究探讨了在存在干扰物时，潜在动作学习（Latent Action Learning）的挑战，特别是以 Latent Action Policies (LAPO) 为代表的方法。实验使用 Distracting Control Suite (DCS) 发现，LAPO 在包含行动相关干扰的真实视频场景中表现不佳，导致学习效率降低。作者提出 LAOM，这是一种简单的 LAPO 修改，通过优化潜在动作质量，使其线性探测性能提高 8 倍。进一步发现，提供少量监督（如仅 2.5% 数据集的真实动作）能在潜在动作学习过程中显著提升下游性能，平均提高 4.2 倍。这些结果表明，在有干扰环境下，Latent Action Models (LAM) 训练需整合监督，这挑战了传统的先学习 LAM 再解码流程。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "ICML 2025, Poster, Source code: https://github.com/dunnolab/laom",
      "pdf_url": "http://arxiv.org/pdf/2502.00379v4",
      "published_date": "2025-02-01 09:35:51 UTC",
      "updated_date": "2025-05-20 13:10:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:40:22.990705"
    },
    {
      "arxiv_id": "2502.00377v1",
      "title": "When End-to-End is Overkill: Rethinking Cascaded Speech-to-Text Translation",
      "title_zh": "翻译失败",
      "authors": [
        "Anna Min",
        "Chenxu Hu",
        "Yi Ren",
        "Hang Zhao"
      ],
      "abstract": "Though end-to-end speech-to-text translation has been a great success, we\nargue that the cascaded speech-to-text translation model still has its place,\nwhich is usually criticized for the error propagation between automatic speech\nrecognition (ASR) and machine translation (MT) models. In this paper, we\nexplore the benefits of incorporating multiple candidates from ASR and\nself-supervised speech features into MT. Our analysis reveals that the primary\ncause of cascading errors stems from the increased divergence between similar\nsamples in the speech domain when mapped to the text domain. By including\nmultiple candidates and self-supervised speech features, our approach allows\nthe machine translation model to choose the right words and ensure precise\ntranslation using various speech samples. This strategy minimizes error spread\nand takes advantage of large ASR and MT datasets, along with pre-trained ASR/MT\nmodels, while addressing associated issues.",
      "tldr_zh": "该论文重新审视级联语音到文本翻译（Cascaded Speech-to-Text Translation），认为尽管端到端方法成功，但级联模型（结合ASR和MT）仍有优势，因为错误传播主要源于语音域到文本域的样本发散问题。作者提出一种方法，通过整合多个ASR候选和自监督语音特征到MT模型中，帮助模型选择正确词汇并确保精确翻译，从而最小化错误传播。实验结果显示，这种策略充分利用了大型ASR和MT数据集及预训练模型，显著提升了翻译性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.MM",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00377v1",
      "published_date": "2025-02-01 09:29:21 UTC",
      "updated_date": "2025-02-01 09:29:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:40:33.547687"
    },
    {
      "arxiv_id": "2502.00365v1",
      "title": "What should an AI assessor optimise for?",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Romero-Alvarado",
        "Fernando Martínez-Plumed",
        "José Hernández-Orallo"
      ],
      "abstract": "An AI assessor is an external, ideally indepen-dent system that predicts an\nindicator, e.g., a loss value, of another AI system. Assessors can lever-age\ninformation from the test results of many other AI systems and have the\nflexibility of be-ing trained on any loss function or scoring rule: from\nsquared error to toxicity metrics. Here we address the question: is it always\noptimal to train the assessor for the target metric? Or could it be better to\ntrain for a different metric and then map predictions back to the target\nmetric? Us-ing twenty regression and classification problems with tabular data,\nwe experimentally explore this question for, respectively, regression losses\nand classification scores with monotonic and non-monotonic mappings and find\nthat, contrary to intuition, optimising for more informative met-rics is not\ngenerally better. Surprisingly, some monotonic transformations are promising.\nFor example, the logistic loss is useful for minimis-ing absolute or quadratic\nerrors in regression, and the logarithmic score helps maximise quadratic or\nspherical scores in classification.",
      "tldr_zh": "本研究探讨了AI评估器（AI assessor）在预测其他AI系统的指标（如损失值）时，应该优化什么目标。作者通过20个回归和分类问题（使用表格数据）进行实验，比较了直接针对目标指标训练评估器与训练其他指标后映射回目标指标的策略。结果显示，与直觉相反，优化更具信息性的指标并不总是最佳选择；例如，logistic loss在回归中有助于最小化绝对或二次错误，而logarithmic score在分类中可提升二次或球形分数的最大化。这些发现为设计更有效的AI评估器提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00365v1",
      "published_date": "2025-02-01 08:41:57 UTC",
      "updated_date": "2025-02-01 08:41:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:40:45.472957"
    },
    {
      "arxiv_id": "2502.00358v2",
      "title": "Do Audio-Visual Segmentation Models Truly Segment Sounding Objects?",
      "title_zh": "音频-视觉分割模型是否真正分割发声物体？",
      "authors": [
        "Jia Li",
        "Wenjie Zhao",
        "Ziru Huang",
        "Yunhui Guo",
        "Yapeng Tian"
      ],
      "abstract": "Unlike traditional visual segmentation, audio-visual segmentation (AVS)\nrequires the model not only to identify and segment objects but also to\ndetermine whether they are sound sources. Recent AVS approaches, leveraging\ntransformer architectures and powerful foundation models like SAM, have\nachieved impressive performance on standard benchmarks. Yet, an important\nquestion remains: Do these models genuinely integrate audio-visual cues to\nsegment sounding objects? In this paper, we systematically investigate this\nissue in the context of robust AVS. Our study reveals a fundamental bias in\ncurrent methods: they tend to generate segmentation masks based predominantly\non visual salience, irrespective of the audio context. This bias results in\nunreliable predictions when sounds are absent or irrelevant. To address this\nchallenge, we introduce AVSBench-Robust, a comprehensive benchmark\nincorporating diverse negative audio scenarios including silence, ambient\nnoise, and off-screen sounds. We also propose a simple yet effective approach\ncombining balanced training with negative samples and classifier-guided\nsimilarity learning. Our extensive experiments show that state-of-theart AVS\nmethods consistently fail under negative audio conditions, demonstrating the\nprevalence of visual bias. In contrast, our approach achieves remarkable\nimprovements in both standard metrics and robustness measures, maintaining\nnear-perfect false positive rates while preserving highquality segmentation\nperformance.",
      "tldr_zh": "本研究质疑当前音频-视觉分割（AVS）模型是否真正整合音频和视觉线索来分割发出声音的对象，发现这些模型主要依赖视觉显著性，导致在音频缺失或无关场景下预测不可靠。作者引入了AVSBench-Robust基准测试，涵盖静音、环境噪音和屏幕外声音等负面音频场景，以评估模型的鲁棒性。同时，他们提出了一种简单方法，结合平衡训练（使用负面样本）和分类器引导的相似性学习，来缓解视觉偏差问题。实验结果显示，现有的AVS方法在负面音频条件下表现不佳，而新方法显著提升了标准指标和鲁棒性，保持了低假阳性率和高分割质量。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "cs.MM",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00358v2",
      "published_date": "2025-02-01 07:40:29 UTC",
      "updated_date": "2025-02-20 22:37:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:40:58.201617"
    },
    {
      "arxiv_id": "2502.00354v1",
      "title": "PM-MOE: Mixture of Experts on Private Model Parameters for Personalized Federated Learning",
      "title_zh": "PM-MOE：私有模型参数上的混合专家用于个性化联邦学习",
      "authors": [
        "Yu Feng",
        "Yangli-ao Geng",
        "Yifan Zhu",
        "Zongfu Han",
        "Xie Yu",
        "Kaiwen Xue",
        "Haoran Luo",
        "Mengyang Sun",
        "Guangwei Zhang",
        "Meina Song"
      ],
      "abstract": "Federated learning (FL) has gained widespread attention for its\nprivacy-preserving and collaborative learning capabilities. Due to significant\nstatistical heterogeneity, traditional FL struggles to generalize a shared\nmodel across diverse data domains. Personalized federated learning addresses\nthis issue by dividing the model into a globally shared part and a locally\nprivate part, with the local model correcting representation biases introduced\nby the global model. Nevertheless, locally converged parameters more accurately\ncapture domain-specific knowledge, and current methods overlook the potential\nbenefits of these parameters. To address these limitations, we propose PM-MoE\narchitecture. This architecture integrates a mixture of personalized modules\nand an energy-based personalized modules denoising, enabling each client to\nselect beneficial personalized parameters from other clients. We applied the\nPM-MoE architecture to nine recent model-split-based personalized federated\nlearning algorithms, achieving performance improvements with minimal additional\ntraining. Extensive experiments on six widely adopted datasets and two\nheterogeneity settings validate the effectiveness of our approach. The source\ncode is available at \\url{https://github.com/dannis97500/PM-MOE}.",
      "tldr_zh": "该研究针对联邦学习（Federated Learning, FL）在统计异质性数据域上泛化能力不足的问题，提出了一种PM-MOE架构，将Mixture of Experts (MoE)应用于私有模型参数，以实现个性化联邦学习（Personalized Federated Learning）。PM-MOE通过整合混合个性化模块和基于能量的个性化模块去噪机制，允许每个客户端从其他客户端选择有益的参数，从而更好地捕捉领域特定知识。实验结果显示，该架构应用于九种基于模型分割的算法后，在六个数据集和两种异质性设置上实现了性能提升，同时仅需最小额外训练。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00354v1",
      "published_date": "2025-02-01 07:20:21 UTC",
      "updated_date": "2025-02-01 07:20:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:41:09.570413"
    },
    {
      "arxiv_id": "2502.00352v1",
      "title": "A Differentiated Reward Method for Reinforcement Learning based Multi-Vehicle Cooperative Decision-Making Algorithms",
      "title_zh": "一种针对基于强化学习的多车辆合作决策算法的差异化奖励方法",
      "authors": [
        "Ye Han",
        "Lijun Zhang",
        "Dejian Meng"
      ],
      "abstract": "Reinforcement learning (RL) shows great potential for optimizing\nmulti-vehicle cooperative driving strategies through the state-action-reward\nfeedback loop, but it still faces challenges such as low sample efficiency.\nThis paper proposes a differentiated reward method based on steady-state\ntransition systems, which incorporates state transition gradient information\ninto the reward design by analyzing traffic flow characteristics, aiming to\noptimize action selection and policy learning in multi-vehicle cooperative\ndecision-making. The performance of the proposed method is validated in RL\nalgorithms such as MAPPO, MADQN, and QMIX under varying autonomous vehicle\npenetration. The results show that the differentiated reward method\nsignificantly accelerates training convergence and outperforms centering reward\nand others in terms of traffic efficiency, safety, and action rationality.\nAdditionally, the method demonstrates strong scalability and environmental\nadaptability, providing a novel approach for multi-agent cooperative\ndecision-making in complex traffic scenarios.",
      "tldr_zh": "本论文提出了一种基于稳态转换系统的差异化奖励方法，用于强化学习（RL）中的多车辆合作决策优化，通过分析交通流特性将状态转换梯度信息融入奖励设计，以提升动作选择和策略学习的效率。该方法在 MAPPO、MADQN 和 QMIX 等 RL 算法中进行验证，并在不同自动车辆渗透率场景下表现出色。实验结果显示，该方法显著加速训练收敛，并在交通效率、安全性和动作合理性方面优于传统中心奖励方法。此外，该方法具备强扩展性和环境适应性，为复杂交通场景的多代理合作决策提供了创新途径。",
      "categories": [
        "cs.AI",
        "cs.MA",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 3 figures, submitted to IEEE IV 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.00352v1",
      "published_date": "2025-02-01 07:16:15 UTC",
      "updated_date": "2025-02-01 07:16:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:41:22.066896"
    },
    {
      "arxiv_id": "2502.00351v2",
      "title": "Multi-Order Hyperbolic Graph Convolution and Aggregated Attention for Social Event Detection",
      "title_zh": "多阶超曲面图卷积和聚合注意力用于",
      "authors": [
        "Yao Liu",
        "Zhilan Liu",
        "Tien Ping Tan",
        "Yuxin Li"
      ],
      "abstract": "Social event detection (SED) is a task focused on identifying specific\nreal-world events and has broad applications across various domains. It is\nintegral to many mobile applications with social features, including major\nplatforms like Twitter, Weibo, and Facebook. By enabling the analysis of social\nevents, SED provides valuable insights for businesses to understand consumer\npreferences and supports public services in handling emergencies and disaster\nmanagement. Due to the hierarchical structure of event detection data,\ntraditional approaches in Euclidean space often fall short in capturing the\ncomplexity of such relationships. While existing methods in both Euclidean and\nhyperbolic spaces have shown promising results, they tend to overlook\nmulti-order relationships between events. To address these limitations, this\npaper introduces a novel framework, Multi-Order Hyperbolic Graph Convolution\nwith Aggregated Attention (MOHGCAA), designed to enhance the performance of\nSED. Experimental results demonstrate significant improvements under both\nsupervised and unsupervised settings. To further validate the effectiveness and\nrobustness of the proposed framework, we conducted extensive evaluations across\nmultiple datasets, confirming its superiority in tackling common challenges in\nsocial event detection.",
      "tldr_zh": "这篇论文针对社会事件检测（Social Event Detection, SED）的问题，提出了一种新框架Multi-Order Hyperbolic Graph Convolution with Aggregated Attention (MOHGCAA)，旨在捕捉事件数据的层次结构和多阶关系。MOHGCAA 通过结合多阶双曲图卷积和聚合注意力机制，解决了传统欧氏空间方法和现有方法的局限性。实验结果显示，该框架在监督和无监督设置下显著提升了 SED 性能，并在多个数据集上验证了其有效性和鲁棒性。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00351v2",
      "published_date": "2025-02-01 07:15:40 UTC",
      "updated_date": "2025-02-10 10:08:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:41:33.091574"
    },
    {
      "arxiv_id": "2502.00350v1",
      "title": "OrcaLoca: An LLM Agent Framework for Software Issue Localization",
      "title_zh": "翻译失败",
      "authors": [
        "Zhongming Yu",
        "Hejia Zhang",
        "Yujie Zhao",
        "Hanxian Huang",
        "Matrix Yao",
        "Ke Ding",
        "Jishen Zhao"
      ],
      "abstract": "Recent developments in Large Language Model (LLM) agents are revolutionizing\nAutonomous Software Engineering (ASE), enabling automated coding, problem\nfixes, and feature improvements. However, localization -- precisely identifying\nsoftware problems by navigating to relevant code sections -- remains a\nsignificant challenge. Current approaches often yield suboptimal results due to\na lack of effective integration between LLM agents and precise code search\nmechanisms. This paper introduces OrcaLoca, an LLM agent framework that\nimproves accuracy for software issue localization by integrating priority-based\nscheduling for LLM-guided action, action decomposition with relevance scoring,\nand distance-aware context pruning. Experimental results demonstrate that\nOrcaLoca becomes the new open-source state-of-the-art (SOTA) in function match\nrate (65.33%) on SWE-bench Lite. It also improves the final resolved rate of an\nopen-source framework by 6.33 percentage points through its patch generation\nintegration.",
      "tldr_zh": "这篇论文介绍了 OrcaLoca，一种 LLM 代理框架，旨在解决软件问题定位的挑战，通过整合优先级-based 调度、行动分解与相关性评分，以及 distance-aware 上下文修剪，提升 LLM 代理与代码搜索机制的有效结合。OrcaLoca 在 SWE-bench Lite 上实现了函数匹配率65.33%的开源 SOTA 水平，并通过补丁生成整合，提高了开源框架的最终解决率6.33个百分点。该框架为自主软件工程（ASE）中的问题定位和修复提供了更准确、可扩展的解决方案。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00350v1",
      "published_date": "2025-02-01 07:15:03 UTC",
      "updated_date": "2025-02-01 07:15:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:41:46.191710"
    },
    {
      "arxiv_id": "2502.00346v1",
      "title": "Actor Critic with Experience Replay-based automatic treatment planning for prostate cancer intensity modulated radiotherapy",
      "title_zh": "翻译失败",
      "authors": [
        "Md Mainul Abrar",
        "Parvat Sapkota",
        "Damon Sprouts",
        "Xun Jia",
        "Yujie Chi"
      ],
      "abstract": "Background: Real-time treatment planning in IMRT is challenging due to\ncomplex beam interactions. AI has improved automation, but existing models\nrequire large, high-quality datasets and lack universal applicability. Deep\nreinforcement learning (DRL) offers a promising alternative by mimicking human\ntrial-and-error planning.\n  Purpose: Develop a stochastic policy-based DRL agent for automatic treatment\nplanning with efficient training, broad applicability, and robustness against\nadversarial attacks using Fast Gradient Sign Method (FGSM).\n  Methods: Using the Actor-Critic with Experience Replay (ACER) architecture,\nthe agent tunes treatment planning parameters (TPPs) in inverse planning.\nTraining is based on prostate cancer IMRT cases, using dose-volume histograms\n(DVHs) as input. The model is trained on a single patient case, validated on\ntwo independent cases, and tested on 300+ plans across three datasets. Plan\nquality is assessed using ProKnow scores, and robustness is tested against\nadversarial attacks.\n  Results: Despite training on a single case, the model generalizes well.\nBefore ACER-based planning, the mean plan score was 6.20$\\pm$1.84; after,\n93.09% of cases achieved a perfect score of 9, with a mean of 8.93$\\pm$0.27.\nThe agent effectively prioritizes optimal TPP tuning and remains robust against\nadversarial attacks.\n  Conclusions: The ACER-based DRL agent enables efficient, high-quality\ntreatment planning in prostate cancer IMRT, demonstrating strong\ngeneralizability and robustness.",
      "tldr_zh": "本研究开发了一种基于Actor-Critic with Experience Replay (ACER)架构的深度强化学习(DRL)代理，用于前列腺癌强度调制放射治疗(IMRT)的自动治疗规划，旨在解决传统模型数据需求大和通用性差的问题。该代理通过调整治疗规划参数(TPPs)并使用剂量-体积直方图(DVHs)作为输入，在单个患者病例上训练后，成功泛化到300多个计划上。结果显示，规划后93.09%的病例达到完美ProKnow分数（平均8.93±0.27），并对Fast Gradient Sign Method (FGSM)攻击表现出强鲁棒性。该方法证明了DRL在高效、高质量IMRT治疗规划中的潜力，提供了一种模仿人类试错的可靠替代方案。",
      "categories": [
        "physics.med-ph",
        "cs.AI",
        "cs.LG",
        "92C50 (Primary) 68T07 (Secondary)",
        "I.2.1; J.2; J.3"
      ],
      "primary_category": "physics.med-ph",
      "comment": "27 Pages, 8 Figures, 4 Tables",
      "pdf_url": "http://arxiv.org/pdf/2502.00346v1",
      "published_date": "2025-02-01 07:09:40 UTC",
      "updated_date": "2025-02-01 07:09:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:41:59.177269"
    },
    {
      "arxiv_id": "2502.00345v1",
      "title": "The Composite Task Challenge for Cooperative Multi-Agent Reinforcement Learning",
      "title_zh": "用于合作多智能体强化学习的复合任务挑战",
      "authors": [
        "Yurui Li",
        "Yuxuan Chen",
        "Li Zhang",
        "Shijian Li",
        "Gang Pan"
      ],
      "abstract": "The significant role of division of labor (DOL) in promoting cooperation is\nwidely recognized in real-world applications.Many cooperative multi-agent\nreinforcement learning (MARL) methods have incorporated the concept of DOL to\nimprove cooperation among agents.However, the tasks used in existing testbeds\ntypically correspond to tasks where DOL is often not a necessary feature for\nachieving optimal policies.Additionally, the full utilize of DOL concept in\nMARL methods remains unrealized due to the absence of appropriate tasks.To\nenhance the generality and applicability of MARL methods in real-world\nscenarios, there is a necessary to develop tasks that demand multi-agent DOL\nand cooperation.In this paper, we propose a series of tasks designed to meet\nthese requirements, drawing on real-world rules as the guidance for their\ndesign.We guarantee that DOL and cooperation are necessary condition for\ncompleting tasks and introduce three factors to expand the diversity of\nproposed tasks to cover more realistic situations.We evaluate 10 cooperative\nMARL methods on the proposed tasks.The results indicate that all baselines\nperform poorly on these tasks.To further validate the solvability of these\ntasks, we also propose simplified variants of proposed tasks.Experimental\nresults show that baselines are able to handle these simplified variants,\nproviding evidence of the solvability of the proposed tasks.The source files is\navailable at https://github.com/Yurui-Li/CTC.",
      "tldr_zh": "这篇论文强调了分工（Division of Labor, DOL）在合作多智能体强化学习（Cooperative MARL）中的关键作用，但指出现有任务往往不强制要求DOL来实现最优策略。为解决这一问题，研究者提出了一系列复合任务挑战，这些任务基于现实世界规则设计，确保DOL和合作是完成任务的必要条件，并引入三个因素来增强任务多样性。实验评估了10种MARL方法，结果显示基线模型在这些任务上表现不佳，但在简化变体上表现出色，证明了任务设计的合理性和可解决性。源代码可在GitHub上获取。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00345v1",
      "published_date": "2025-02-01 07:07:08 UTC",
      "updated_date": "2025-02-01 07:07:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:42:09.827039"
    },
    {
      "arxiv_id": "2503.17365v2",
      "title": "How Effective Is Constitutional AI in Small LLMs? A Study on DeepSeek-R1 and Its Peers",
      "title_zh": "翻译失败",
      "authors": [
        "Antonio-Gabriel Chacón Menke",
        "Phan Xuan Tan"
      ],
      "abstract": "Recent incidents highlight safety risks in Large Language Models (LLMs),\nmotivating research into alignment methods like Constitutional AI (CAI). This\npaper explores CAI's self-critique mechanism on small, uncensored 7-9B\nparameter models: DeepSeek-R1-8B, Gemma-2-9B, Llama 3.1-8B, and Qwen2.5-7B. We\nshow that while Llama-based models exhibited significant harm reduction through\nself-critique, other architectures demonstrated less improvement in harm\ndetection after abliteration. These results suggest CAI's effectiveness may\nvary depending on model architecture and reasoning capabilities.",
      "tldr_zh": "这篇论文探讨了Constitutional AI (CAI) 在小型Large Language Models (LLMs)中的有效性，特别针对7-9B参数的未审查模型如DeepSeek-R1-8B、Gemma-2-9B、Llama 3.1-8B和Qwen2.5-7B，通过self-critique机制进行测试。研究发现，Llama-based模型显示出显著的危害减少，而其他架构的模型在危害检测方面改善有限。这些结果表明，CAI的有效性取决于模型的架构和推理能力，可能为LLM的安全对齐提供重要启示。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.17365v2",
      "published_date": "2025-02-01 06:58:27 UTC",
      "updated_date": "2025-04-11 09:18:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:42:23.961964"
    },
    {
      "arxiv_id": "2502.00334v2",
      "title": "UGPhysics: A Comprehensive Benchmark for Undergraduate Physics Reasoning with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Xin Xu",
        "Qiyun Xu",
        "Tong Xiao",
        "Tianhao Chen",
        "Yuchen Yan",
        "Jiaxin Zhang",
        "Shizhe Diao",
        "Can Yang",
        "Yang Wang"
      ],
      "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in\nsolving complex reasoning tasks, particularly in mathematics. However, the\ndomain of physics reasoning presents unique challenges that have received\nsignificantly less attention. Existing benchmarks often fall short in\nevaluating LLMs' abilities on the breadth and depth of undergraduate-level\nphysics, underscoring the need for a comprehensive evaluation. To fill this\ngap, we introduce UGPhysics, a large-scale and comprehensive benchmark\nspecifically designed to evaluate UnderGraduate-level Physics (UGPhysics)\nreasoning with LLMs. UGPhysics includes 5,520 undergraduate-level physics\nproblems in both English and Chinese, covering 13 subjects with seven different\nanswer types and four distinct physics reasoning skills, all rigorously\nscreened for data leakage. Additionally, we develop a Model-Assistant\nRule-based Judgment (MARJ) pipeline specifically tailored for assessing answer\ncorrectness of physics problems, ensuring accurate evaluation. Our evaluation\nof 31 leading LLMs shows that the highest overall accuracy, 49.8% (achieved by\nOpenAI-o1-mini), emphasizes the necessity for models with stronger physics\nreasoning skills, beyond math abilities. We hope UGPhysics, along with MARJ,\nwill drive future advancements in AI for physics reasoning. Codes and data are\navailable at https://github.com/YangLabHKUST/UGPhysics .",
      "tldr_zh": "本研究介绍了 UGPhysics，这是一个大规模的基准测试，旨在评估大型语言模型 (LLMs) 在本科物理推理方面的能力，以填补现有基准的不足。UGPhysics 包含 5,520 个本科物理问题，覆盖 13 个科目、七种答案类型和四种物理推理技能，并提供英文和中文版本，同时经过严格的数据泄漏筛查。研究团队开发了 Model-Assistant Rule-based Judgment (MARJ) 管道，用于精确评估答案正确性。在对 31 个领先 LLMs 的评估中，OpenAI-o1-mini 取得了最高的整体准确率 49.8%，这突显了模型需进一步提升物理推理能力。希望 UGPhysics 和 MARJ 能推动 AI 在物理领域的发展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.00334v2",
      "published_date": "2025-02-01 06:42:02 UTC",
      "updated_date": "2025-02-05 11:36:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:42:34.272600"
    },
    {
      "arxiv_id": "2502.06802v1",
      "title": "Solving the Content Gap in Roblox Game Recommendations: LLM-Based Profile Generation and Reranking",
      "title_zh": "翻译失败",
      "authors": [
        "Chen Wang",
        "Xiaokai Wei",
        "Yexi Jiang",
        "Frank Ong",
        "Kevin Gao",
        "Xiao Yu",
        "Zheng Hui",
        "Se-eun Yoon",
        "Philip Yu",
        "Michelle Gong"
      ],
      "abstract": "With the vast and dynamic user-generated content on Roblox, creating\neffective game recommendations requires a deep understanding of game content.\nTraditional recommendation models struggle with the inconsistent and sparse\nnature of game text features such as titles and descriptions. Recent\nadvancements in large language models (LLMs) offer opportunities to enhance\nrecommendation systems by analyzing in-game text data. This paper addresses two\nchallenges: generating high-quality, structured text features for games without\nextensive human annotation, and validating these features to ensure they\nimprove recommendation relevance. We propose an approach that extracts in-game\ntext and uses LLMs to infer attributes such as genre and gameplay objectives\nfrom raw player interactions. Additionally, we introduce an LLM-based\nre-ranking mechanism to assess the effectiveness of the generated text\nfeatures, enhancing personalization and user satisfaction. Beyond\nrecommendations, our approach supports applications such as user\nengagement-based integrity detection, already deployed in production. This\nscalable framework demonstrates the potential of in-game text understanding to\nimprove recommendation quality on Roblox and adapt recommendations to its\nunique, user-generated ecosystem.",
      "tldr_zh": "这篇论文针对 Roblox 平台游戏推荐中的内容差距问题，提出一种基于大型语言模型(LLM)的解决方案，包括自动生成高质量结构化游戏文本特征（如游戏类型和目标），以解决传统模型对稀疏文本的处理难题。方法涉及从玩家互动中提取文本数据，利用 LLM 推断属性，并引入 LLM-based re-ranking 机制来提升推荐的个性化与相关性。实验结果显示，该框架显著提高了推荐质量，并在生产环境中支持用户参与度完整性检测，证明了其在用户生成内容生态中的可扩展性。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06802v1",
      "published_date": "2025-02-01 06:30:56 UTC",
      "updated_date": "2025-02-01 06:30:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:42:47.032631"
    },
    {
      "arxiv_id": "2502.00330v1",
      "title": "From Few to Many: Self-Improving Many-Shot Reasoners Through Iterative Optimization and Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Xingchen Wan",
        "Han Zhou",
        "Ruoxi Sun",
        "Hootan Nakhost",
        "Ke Jiang",
        "Sercan Ö. Arık"
      ],
      "abstract": "Recent advances in long-context large language models (LLMs) have led to the\nemerging paradigm of many-shot in-context learning (ICL), where it is observed\nthat scaling many more demonstrating examples beyond the conventional few-shot\nsetup in the context can lead to performance benefits. However, despite its\npromise, it is unclear what aspects dominate the benefits and whether simply\nscaling to more examples is the most effective way of improving many-shot ICL.\nIn this work, we first provide an analysis of the factors driving many-shot\nICL, and we find that 1) many-shot performance can still be attributed to often\na few disproportionately influential examples and 2) identifying such\ninfluential examples (\"optimize\") and using them as demonstrations to\nregenerate new examples (\"generate\") can lead to further improvements. Inspired\nby the findings, we propose BRIDGE, an algorithm that alternates between the\noptimize step with Bayesian optimization to discover the influential sets of\nexamples and the generate step to reuse this set to expand the reasoning paths\nof the examples back to the many-shot regime automatically. On Gemini, Claude,\nand Mistral LLMs of different sizes, we show that BRIDGE to significant\nimprovements across a diverse set of tasks, including symbolic reasoning,\nnumerical reasoning, and code generation.",
      "tldr_zh": "该研究分析了长上下文大语言模型（LLMs）中的 many-shot in-context learning (ICL)，发现其性能主要依赖于少数有影响力（influential）的示例，而非简单地增加示例数量。作者提出 BRIDGE 算法，通过交替进行优化步骤（使用 Bayesian optimization 识别关键示例集）和生成步骤（利用这些示例自动扩展为多示例），实现对 many-shot 推理器的自我改进。在 Gemini、Claude 和 Mistral 等不同规模的 LLMs 上，BRIDGE 在符号推理、数值推理和代码生成等任务中取得了显著性能提升。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Expanded version of the ICLR 2025 paper",
      "pdf_url": "http://arxiv.org/pdf/2502.00330v1",
      "published_date": "2025-02-01 06:23:24 UTC",
      "updated_date": "2025-02-01 06:23:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:42:58.480966"
    },
    {
      "arxiv_id": "2502.00329v1",
      "title": "CoddLLM: Empowering Large Language Models for Data Analytics",
      "title_zh": "CoddLL",
      "authors": [
        "Jiani Zhang",
        "Hengrui Zhang",
        "Rishav Chakravarti",
        "Yiqun Hu",
        "Patrick Ng",
        "Asterios Katsifodimos",
        "Huzefa Rangwala",
        "George Karypis",
        "Alon Halevy"
      ],
      "abstract": "Large Language Models (LLMs) have the potential to revolutionize data\nanalytics by simplifying tasks such as data discovery and SQL query synthesis\nthrough natural language interactions. This work serves as a pivotal first step\ntoward the development of foundation models explicitly designed for data\nanalytics applications. To propel this vision forward, we unveil a new data\nrecipe for post-training LLMs, enhancing their comprehension of data management\nand empowering them to tackle complex real-world analytics tasks. Specifically,\nour innovative approach includes a scalable synthetic data generation method\nthat enables the creation of a broad spectrum of topics centered on data\nrepresentation and manipulation. Furthermore, we introduce two new tasks that\nseamlessly bridge tables and text. We show that such tasks can enhance models'\nunderstanding of schema creation and the nuanced translation between natural\nlanguage and tabular data. Leveraging this data recipe, we post-train a new\nfoundation model, named CoddLLM, based on Mistral-NeMo-12B. To assess the\nlanguage understanding and reasoning capabilities of LLMs in the realm of data\nanalytics, we contribute AnalyticsMMLU, a benchmark containing thousands of\nmultiple-choice questions on databases, data analysis, and machine learning.\nOur focus on data discovery, has resulted in the contribution of three\ncomprehensive benchmarks that address both database and data lake scenarios.\nCoddLLM not only excels in performance but also sets a new standard, achieving\nthe highest average accuracy across eight datasets. It outperforms\nGPT-3.5-Turbo on AnalyticsMMLU, exceeding GPT-4o by 12.1% in table selection\nand showing an average improvement of 24.9% in Text-to-SQL compared to the base\nmodel.",
      "tldr_zh": "这篇论文介绍了 CoddLLM，一种通过后训练 Large Language Models (LLMs) 来增强数据分析能力的框架，旨在简化数据发现和 SQL 查询合成等任务。研究团队提出了一种可扩展的合成数据生成方法和新任务，以桥接表格和文本数据，提升模型对 schema 创建以及自然语言到表格数据的理解。实验结果显示，CoddLLM 在 AnalyticsMMLU 基准上超越 GPT-3.5-Turbo，并在表选择任务中比 GPT-4o 高 12.1%，Text-to-SQL 任务平均改善 24.9%。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00329v1",
      "published_date": "2025-02-01 06:03:55 UTC",
      "updated_date": "2025-02-01 06:03:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:43:11.287155"
    },
    {
      "arxiv_id": "2502.01662v1",
      "title": "Speculative Ensemble: Fast Large Language Model Ensemble via Speculation",
      "title_zh": "翻译失败",
      "authors": [
        "Jiale Fu",
        "Yuchu Jiang",
        "Junkai Chen",
        "Jiaming Fan",
        "Xin Geng",
        "Xu Yang"
      ],
      "abstract": "Ensemble methods enhance Large Language Models (LLMs) by combining multiple\nmodels but suffer from high computational costs. In this paper, we introduce\nSpeculative Ensemble, a novel framework that accelerates LLM ensembles without\nsacrificing performance, inspired by Speculative Decoding-where a small\nproposal model generates tokens sequentially, and a larger target model\nverifies them in parallel. Our approach builds on two key insights: (1) the\nverification distribution can be the ensemble distribution of both the proposal\nand target models, and (2) alternating each model as the proposer and verifier\ncan further enhance efficiency. We generalize this method to ensembles with n\nmodels and theoretically prove that SE is never slower than a standard\nensemble, typically achieving faster speed. Extensive experiments demonstrate\nspeed improvements of 1.11x-2.23x over standard ensemble techniques without\ncompromising generation quality. Our code is available at\nhttps://github.com/Kamichanw/Speculative-Ensemble/",
      "tldr_zh": "这篇论文提出了Speculative Ensemble，一种高效的Large Language Models (LLMs) ensemble框架，旨在通过借鉴Speculative Decoding的机制来解决传统ensemble方法的高计算成本问题。该框架的核心创新包括：(1) 使用提案模型生成tokens，并将验证分布扩展为提案和目标模型的ensemble分布；(2) 交替模型角色作为proposer和verifier，以进一步提升效率，并推广到n模型的ensemble系统。理论证明显示，Speculative Ensemble从不比标准ensemble慢，通常更快；实验结果在多种场景下实现了1.11x-2.23x的速度提升，同时保持了生成质量不变。代码已在GitHub上开源。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01662v1",
      "published_date": "2025-02-01 05:22:11 UTC",
      "updated_date": "2025-02-01 05:22:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:43:22.332357"
    },
    {
      "arxiv_id": "2502.00321v4",
      "title": "MIM: Multi-modal Content Interest Modeling Paradigm for User Behavior Modeling",
      "title_zh": "MIM：多模态内容兴趣建模范式用于用户行为建模",
      "authors": [
        "Bencheng Yan",
        "Si Chen",
        "Shichang Jia",
        "Jianyu Liu",
        "Yueran Liu",
        "Chenghan Fu",
        "Wanxian Guan",
        "Hui Zhao",
        "Xiang Zhang",
        "Kai Zhang",
        "Wenbo Su",
        "Pengjie Wang",
        "Jian Xu",
        "Bo Zheng",
        "Baolin Liu"
      ],
      "abstract": "Click-Through Rate (CTR) prediction is a crucial task in recommendation\nsystems, online searches, and advertising platforms, where accurately capturing\nusers' real interests in content is essential for performance. However,\nexisting methods heavily rely on ID embeddings, which fail to reflect users'\ntrue preferences for content such as images and titles. This limitation becomes\nparticularly evident in cold-start and long-tail scenarios, where traditional\napproaches struggle to deliver effective results. To address these challenges,\nwe propose a novel Multi-modal Content Interest Modeling paradigm (MIM), which\nconsists of three key stages: Pre-training, Content-Interest-Aware Supervised\nFine-Tuning (C-SFT), and Content-Interest-Aware UBM (CiUBM). The pre-training\nstage adapts foundational models to domain-specific data, enabling the\nextraction of high-quality multi-modal embeddings. The C-SFT stage bridges the\nsemantic gap between content and user interests by leveraging user behavior\nsignals to guide the alignment of embeddings with user preferences. Finally,\nthe CiUBM stage integrates multi-modal embeddings and ID-based collaborative\nfiltering signals into a unified framework. Comprehensive offline experiments\nand online A/B tests conducted on the Taobao, one of the world's largest\ne-commerce platforms, demonstrated the effectiveness and efficiency of MIM\nmethod. The method has been successfully deployed online, achieving a\nsignificant increase of +14.14% in CTR and +4.12% in RPM, showcasing its\nindustrial applicability and substantial impact on platform performance. To\npromote further research, we have publicly released the code and dataset at\nhttps://pan.quark.cn/s/8fc8ec3e74f3.",
      "tldr_zh": "这篇论文提出了一种名为 MIM 的多模态内容兴趣建模范式，用于提升推荐系统中的 Click-Through Rate (CTR) 预测，通过捕捉用户对图像和标题等多模态内容的真实偏好，特别是在冷启动和长尾场景中。MIM 包括三个关键阶段：Pre-training 以适应领域数据并提取高质量多模态嵌入、Content-Interest-Aware Supervised Fine-Tuning (C-SFT) 以利用用户行为信号桥接内容与兴趣的语义差距，以及 Content-Interest-Aware UBM (CiUBM) 以整合多模态嵌入和基于 ID 的协同过滤信号。实验结果显示，在 Taobao 平台上部署后，MIM 实现了 CTR 提升 14.14% 和 RPM 提升 4.12%，证明了其在工业环境中的有效性和实际影响。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00321v4",
      "published_date": "2025-02-01 05:06:21 UTC",
      "updated_date": "2025-02-23 15:40:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:43:35.454498"
    },
    {
      "arxiv_id": "2502.00313v1",
      "title": "Distributive Fairness in Large Language Models: Evaluating Alignment with Human Values",
      "title_zh": "大型语言模型中的分配公平：评估与人类价值观的对齐",
      "authors": [
        "Hadi Hosseini",
        "Samarth Khanna"
      ],
      "abstract": "The growing interest in employing large language models (LLMs) for\ndecision-making in social and economic contexts has raised questions about\ntheir potential to function as agents in these domains. A significant number of\nsocietal problems involve the distribution of resources, where fairness, along\nwith economic efficiency, play a critical role in the desirability of outcomes.\nIn this paper, we examine whether LLM responses adhere to fundamental fairness\nconcepts such as equitability, envy-freeness, and Rawlsian maximin, and\ninvestigate their alignment with human preferences. We evaluate the performance\nof several LLMs, providing a comparative benchmark of their ability to reflect\nthese measures. Our results demonstrate a lack of alignment between current LLM\nresponses and human distributional preferences. Moreover, LLMs are unable to\nutilize money as a transferable resource to mitigate inequality. Nonetheless,\nwe demonstrate a stark contrast when (some) LLMs are tasked with selecting from\na predefined menu of options rather than generating one. In addition, we\nanalyze the robustness of LLM responses to variations in semantic factors (e.g.\nintentions or personas) or non-semantic prompting changes (e.g. templates or\norderings). Finally, we highlight potential strategies aimed at enhancing the\nalignment of LLM behavior with well-established fairness concepts.",
      "tldr_zh": "这篇论文评估了大型语言模型 (LLMs) 在社会和经济决策中的公平性，特别检查其是否遵守 equitability、envy-freeness 和 Rawlsian maximin 等核心公平概念，并与人类分配偏好进行对齐比较。研究发现，当前 LLMs 与人类偏好存在明显不一致，无法有效利用金钱等可转移资源来缓解不平等，但当从预定义选项中选择时，某些模型表现更佳。论文还分析了 LLMs 对语义（如意图或角色）和非语义（如提示模板）变化的鲁棒性，并提出了增强模型与公平概念对齐的潜在策略。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.CL",
        "cs.MA"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00313v1",
      "published_date": "2025-02-01 04:24:47 UTC",
      "updated_date": "2025-02-01 04:24:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:43:47.092770"
    },
    {
      "arxiv_id": "2502.00310v1",
      "title": "SigWavNet: Learning Multiresolution Signal Wavelet Network for Speech Emotion Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Alaa Nfissi",
        "Wassim Bouachir",
        "Nizar Bouguila",
        "Brian Mishara"
      ],
      "abstract": "In the field of human-computer interaction and psychological assessment,\nspeech emotion recognition (SER) plays an important role in deciphering\nemotional states from speech signals. Despite advancements, challenges persist\ndue to system complexity, feature distinctiveness issues, and noise\ninterference. This paper introduces a new end-to-end (E2E) deep learning\nmulti-resolution framework for SER, addressing these limitations by extracting\nmeaningful representations directly from raw waveform speech signals. By\nleveraging the properties of the fast discrete wavelet transform (FDWT),\nincluding the cascade algorithm, conjugate quadrature filter, and coefficient\ndenoising, our approach introduces a learnable model for both wavelet bases and\ndenoising through deep learning techniques. The framework incorporates an\nactivation function for learnable asymmetric hard thresholding of wavelet\ncoefficients. Our approach exploits the capabilities of wavelets for effective\nlocalization in both time and frequency domains. We then combine\none-dimensional dilated convolutional neural networks (1D dilated CNN) with a\nspatial attention layer and bidirectional gated recurrent units (Bi-GRU) with a\ntemporal attention layer to efficiently capture the nuanced spatial and\ntemporal characteristics of emotional features. By handling variable-length\nspeech without segmentation and eliminating the need for pre or\npost-processing, the proposed model outperformed state-of-the-art methods on\nIEMOCAP and EMO-DB datasets. The source code of this paper is shared on the\nGithub repository:\nhttps://github.com/alaaNfissi/SigWavNet-Learning-Multiresolution-Signal-Wavelet-Network-for-Speech-Emotion-Recognition.",
      "tldr_zh": "本文提出 SigWavNet，一种端到端 (E2E) 深度学习多分辨率框架，用于 Speech Emotion Recognition (SER)，旨在从原始波形语音信号中直接提取有意义的特征，以解决系统复杂性、特征区分和噪声干扰等问题。框架利用 fast discrete wavelet transform (FDWT) 的特性，包括级联算法、共轭正交滤波器和可学习的波形基与去噪机制，并结合 1D dilated CNN、空间注意力层、Bi-GRU 和时间注意力层，来捕捉情感特征的空间和时间特性。SigWavNet 支持处理可变长度的语音信号，无需预处理或后处理，并在 IEMOCAP 和 EMO-DB 数据集上超越了现有最先进方法，源代码已在 GitHub 上公开。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "eess.AS",
        "I.2.7; I.2.6; I.2.1; I.2.0"
      ],
      "primary_category": "cs.SD",
      "comment": "Published in: IEEE Transactions on Affective Computing",
      "pdf_url": "http://arxiv.org/pdf/2502.00310v1",
      "published_date": "2025-02-01 04:18:06 UTC",
      "updated_date": "2025-02-01 04:18:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:44:00.431883"
    },
    {
      "arxiv_id": "2502.00306v1",
      "title": "Riddle Me This! Stealthy Membership Inference for Retrieval-Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Ali Naseh",
        "Yuefeng Peng",
        "Anshuman Suri",
        "Harsh Chaudhari",
        "Alina Oprea",
        "Amir Houmansadr"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) enables Large Language Models (LLMs) to\ngenerate grounded responses by leveraging external knowledge databases without\naltering model parameters. Although the absence of weight tuning prevents\nleakage via model parameters, it introduces the risk of inference adversaries\nexploiting retrieved documents in the model's context. Existing methods for\nmembership inference and data extraction often rely on jailbreaking or\ncarefully crafted unnatural queries, which can be easily detected or thwarted\nwith query rewriting techniques common in RAG systems. In this work, we present\nInterrogation Attack (IA), a membership inference technique targeting documents\nin the RAG datastore. By crafting natural-text queries that are answerable only\nwith the target document's presence, our approach demonstrates successful\ninference with just 30 queries while remaining stealthy; straightforward\ndetectors identify adversarial prompts from existing methods up to ~76x more\nfrequently than those generated by our attack. We observe a 2x improvement in\nTPR@1%FPR over prior inference attacks across diverse RAG configurations, all\nwhile costing less than $0.02 per document inference.",
      "tldr_zh": "本研究针对 Retrieval-Augmented Generation (RAG) 系统，提出了一种隐秘的成员推理攻击方法 Interrogation Attack (IA)，旨在检测 RAG 数据存储中的文档是否存在，而不依赖于易被发现的非自然查询。IA 通过设计仅在目标文档存在时才能回答的自然文本查询，实现高效推理，仅需 30 个查询即可成功，同时规避检测——现有方法的对抗提示被检测频率高达 76 倍。实验结果显示，IA 在多种 RAG 配置中，将 TPR@1%FPR 提高了 2 倍，且每文档推理成本低于 0.02 美元，为评估 RAG 系统的隐私风险提供了新工具。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00306v1",
      "published_date": "2025-02-01 04:01:18 UTC",
      "updated_date": "2025-02-01 04:01:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:44:11.847388"
    },
    {
      "arxiv_id": "2502.00305v1",
      "title": "DEUCE: Dual-diversity Enhancement and Uncertainty-awareness for Cold-start Active Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaxin Guo",
        "C. L. Philip Chen",
        "Shuzhen Li",
        "Tong Zhang"
      ],
      "abstract": "Cold-start active learning (CSAL) selects valuable instances from an\nunlabeled dataset for manual annotation. It provides high-quality data at a low\nannotation cost for label-scarce text classification. However, existing CSAL\nmethods overlook weak classes and hard representative examples, resulting in\nbiased learning. To address these issues, this paper proposes a novel\ndual-diversity enhancing and uncertainty-aware (DEUCE) framework for CSAL.\nSpecifically, DEUCE leverages a pretrained language model (PLM) to efficiently\nextract textual representations, class predictions, and predictive uncertainty.\nThen, it constructs a Dual-Neighbor Graph (DNG) to combine information on both\ntextual diversity and class diversity, ensuring a balanced data distribution.\nIt further propagates uncertainty information via density-based clustering to\nselect hard representative instances. DEUCE performs well in selecting\nclass-balanced and hard representative data by dual-diversity and\ninformativeness. Experiments on six NLP datasets demonstrate the superiority\nand efficiency of DEUCE.",
      "tldr_zh": "本文提出 DEUCE 框架，用于改进冷启动主动学习 (CSAL)，通过双重多样性增强和不确定性感知，解决现有方法忽略弱类和难代表性例子导致的偏置问题。DEUCE 利用预训练语言模型 (PLM) 提取文本表示、类预测和预测不确定性，并构建 Dual-Neighbor Graph (DNG) 来结合文本多样性和类多样性，确保数据分布平衡；同时，通过基于密度的聚类传播不确定性信息，选择硬代表性实例。实验在六个 NLP 数据集上证明，DEUCE 在选择类平衡和高信息性数据方面表现出优越性和高效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "I.2.6; I.2.7; I.5.1; H.3.1; H.3.3"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages, 3 figures, 12 tables. Accepted manuscript by TACL. For\n  published version by MIT Press, see\n  https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00731/125950",
      "pdf_url": "http://arxiv.org/pdf/2502.00305v1",
      "published_date": "2025-02-01 04:00:03 UTC",
      "updated_date": "2025-02-01 04:00:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:44:23.378426"
    },
    {
      "arxiv_id": "2502.00304v1",
      "title": "HoP: Homeomorphic Polar Learning for Hard Constrained Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Ke Deng",
        "Hanwen Zhang",
        "Jin Lu",
        "Haijian Sun"
      ],
      "abstract": "Constrained optimization demands highly efficient solvers which promotes the\ndevelopment of learn-to-optimize (L2O) approaches. As a data-driven method, L2O\nleverages neural networks to efficiently produce approximate solutions.\nHowever, a significant challenge remains in ensuring both optimality and\nfeasibility of neural networks' output. To tackle this issue, we introduce\nHomeomorphic Polar Learning (HoP) to solve the star-convex hard-constrained\noptimization by embedding homeomorphic mapping in neural networks. The\nbijective structure enables end-to-end training without extra penalty or\ncorrection. For performance evaluation, we evaluate HoP's performance across a\nvariety of synthetic optimization tasks and real-world applications in wireless\ncommunications. In all cases, HoP achieves solutions closer to the optimum than\nexisting L2O methods while strictly maintaining feasibility.",
      "tldr_zh": "该论文提出Homeomorphic Polar Learning (HoP)，一种用于解决星凸硬约束优化的方法，通过在神经网络中嵌入同胚映射（homeomorphic mapping），确保输出既最优又可行，从而克服传统学习优化 (L2O) 方法的挑战。HoP 利用双射结构实现端到端训练，无需额外惩罚或修正机制。在合成优化任务和无线通信应用中，实验结果显示，HoP 比现有 L2O 方法更接近最优解，同时严格保持可行性，为高效约束优化提供了新框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "in submission",
      "pdf_url": "http://arxiv.org/pdf/2502.00304v1",
      "published_date": "2025-02-01 03:59:15 UTC",
      "updated_date": "2025-02-01 03:59:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:44:34.592734"
    },
    {
      "arxiv_id": "2502.00302v2",
      "title": "Learning to Fuse Temporal Proximity Networks: A Case Study in Chimpanzee Social Interactions",
      "title_zh": "翻译失败",
      "authors": [
        "Yixuan He",
        "Aaron Sandel",
        "David Wipf",
        "Mihai Cucuringu",
        "John Mitani",
        "Gesine Reinert"
      ],
      "abstract": "How can we identify groups of primate individuals which could be conjectured\nto drive social structure? To address this question, one of us has collected a\ntime series of data for social interactions between chimpanzees. Here we use a\nnetwork representation, leading to the task of combining these data into a time\nseries of a single weighted network per time stamp, where different proximities\nshould be given different weights reflecting their relative importance. We\noptimize these proximity-type weights in a principled way, using an innovative\nloss function which rewards structural consistency across time. The approach is\nempirically validated by carefully designed synthetic data. Using statistical\ntests, we provide a way of identifying groups of individuals that stay related\nfor a significant length of time. Applying the approach to the chimpanzee data\nset, we detect cliques in the animal social network time series, which can be\nvalidated by real-world intuition from prior research and qualitative\nobservations by chimpanzee experts.",
      "tldr_zh": "该研究探讨了如何通过融合时间序列网络（Temporal Proximity Networks）来识别驱动灵长类社会结构的群体，以黑猩猩社会互动为例。研究提出了一种创新方法，通过优化不同邻近性（proximity）的权重，使用一个奖励结构一致性的损失函数（loss function），将多时间戳数据整合成加权网络。方法在合成数据上得到实证验证，并在黑猩猩数据集上检测到持续稳定的派系（cliques），这些发现与先前的研究和专家观察相符，从而为理解动物社会动态提供了新工具。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "math.OC",
        "math.ST",
        "stat.TH"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00302v2",
      "published_date": "2025-02-01 03:51:22 UTC",
      "updated_date": "2025-05-12 08:07:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:44:46.589151"
    },
    {
      "arxiv_id": "2502.00290v5",
      "title": "Estimating LLM Uncertainty with Evidence",
      "title_zh": "基于证据的 LLM 不确定性估计",
      "authors": [
        "Huan Ma",
        "Jingdong Chen",
        "Joey Tianyi Zhou",
        "Guangyu Wang",
        "Changqing Zhang"
      ],
      "abstract": "Over the past few years, Large Language Models (LLMs) have developed rapidly\nand are widely applied in various domains. However, LLMs face the issue of\nhallucinations, generating responses that may be unreliable when the models\nlack relevant knowledge. To be aware of potential hallucinations, uncertainty\nestimation methods have been introduced, and most of them have confirmed that\nreliability lies in critical tokens. However, probability-based methods perform\npoorly in identifying token reliability, limiting their practical utility. In\nthis paper, we reveal that the probability-based method fails to estimate token\nreliability due to the loss of evidence strength information which is\naccumulated in the training stage. Therefore, we present Logits-induced token\nuncertainty (LogTokU), a framework for estimating decoupled token uncertainty\nin LLMs, enabling real-time uncertainty estimation without requiring multiple\nsampling processes. We employ evidence modeling to implement LogTokU and use\nthe estimated uncertainty to guide downstream tasks. The experimental results\ndemonstrate that LogTokU has significant effectiveness and promise.",
      "tldr_zh": "这篇论文针对 Large Language Models (LLMs) 的 hallucination 问题，揭示了传统 probability-based uncertainty estimation 方法因丢失训练阶段的 evidence strength 信息而无法准确评估 token 可靠性。作者提出 Logits-induced token uncertainty (LogTokU) 框架，通过 evidence modeling 实现解耦的 token uncertainty 估计，支持实时计算且无需多次采样，并将其应用于指导下游任务。实验结果证明，LogTokU 在有效性和实用性方面表现出显著优势。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00290v5",
      "published_date": "2025-02-01 03:18:02 UTC",
      "updated_date": "2025-05-09 05:37:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:44:58.787887"
    },
    {
      "arxiv_id": "2502.00281v1",
      "title": "Sigmoid Self-Attention is Better than Softmax Self-Attention: A Mixture-of-Experts Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Fanqi Yan",
        "Huy Nguyen",
        "Pedram Akbarian",
        "Nhat Ho",
        "Alessandro Rinaldo"
      ],
      "abstract": "At the core of the popular Transformer architecture is the self-attention\nmechanism, which dynamically assigns softmax weights to each input token so\nthat the model can focus on the most salient information. However, the softmax\nstructure slows down the attention computation due to its row-wise nature, and\ninherently introduces competition among tokens: as the weight assigned to one\ntoken increases, the weights of others decrease. This competitive dynamic may\nnarrow the focus of self-attention to a limited set of features, potentially\noverlooking other informative characteristics. Recent experimental studies have\nshown that using the element-wise sigmoid function helps eliminate token\ncompetition and reduce the computational overhead. Despite these promising\nempirical results, a rigorous comparison between sigmoid and softmax\nself-attention mechanisms remains absent in the literature. This paper closes\nthis gap by theoretically demonstrating that sigmoid self-attention is more\nsample-efficient than its softmax counterpart. Toward that goal, we illustrate\nthat each row of the self-attention matrix can be represented as a mixture of\nexperts. Our analysis shows that ''experts'' in sigmoid self-attention require\nsignificantly less data to achieve the same approximation error as those in\nsoftmax self-attention. We corroborate our theoretical findings through\nextensive experiments on both synthetic and real-world datasets.",
      "tldr_zh": "本论文比较了 sigmoid 和 softmax 自注意力机制，指出 softmax 的竞争性动态可能导致计算开销增加并忽略部分信息，而 sigmoid 则能消除竞争并提高效率。从 Mixture-of-Experts 的视角出发，作者理论证明了 sigmoid 自注意力在样本效率上优于 softmax 自注意力，因为其“experts”需要更少的数据来实现相同的近似误差。该结论通过合成和真实数据集的广泛实验得到验证，展示了 sigmoid 自注意力在 Transformer 架构中的潜在优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Fanqi Yan, Huy Nguyen contributed equally to this work. 51 pages, 2\n  figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.00281v1",
      "published_date": "2025-02-01 02:36:14 UTC",
      "updated_date": "2025-02-01 02:36:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:45:10.297939"
    },
    {
      "arxiv_id": "2502.00270v2",
      "title": "DUET: Optimizing Training Data Mixtures via Feedback from Unseen Evaluation Tasks",
      "title_zh": "DUET：通过来自未见评估任务的反馈优化训练数据混合",
      "authors": [
        "Zhiliang Chen",
        "Gregory Kang Ruey Lau",
        "Chuan-Sheng Foo",
        "Bryan Kian Hsiang Low"
      ],
      "abstract": "The performance of an LLM depends heavily on the relevance of its training\ndata to the downstream evaluation task. However, in practice, the data involved\nin an unseen evaluation task is often unknown (e.g., conversations between an\nLLM and a user are end-to-end encrypted). Hence, it is unclear what data are\nrelevant for fine-tuning the LLM to maximize its performance on the specific\nunseen evaluation task. Instead, one can only deploy the LLM on the unseen task\nto gather multiple rounds of feedback on how well the model performs (e.g.,\nuser ratings). This novel setting offers a refreshing perspective towards\noptimizing training data mixtures via feedback from an unseen evaluation task,\nwhich prior data mixing and selection works do not consider. Our paper presents\nDUET, a novel global-to-local algorithm that interleaves influence function as\na data selection method with Bayesian optimization to optimize data mixture via\nfeedback from a specific unseen evaluation task. By analyzing DUET's cumulative\nregret, we theoretically show that DUET converges to the optimal training data\nmixture for an unseen task even without any data knowledge of the task.\nFinally, our experiments across a variety of language tasks demonstrate that\nDUET outperforms existing data selection and mixing methods in the unseen-task\nsetting.",
      "tldr_zh": "这篇论文提出了 DUET，一种创新算法，用于通过未知评估任务的反馈优化大型语言模型（LLM）的训练数据混合，从而提升模型性能。DUET 采用全局到局部的策略，将 influence function 作为数据选择方法，与 Bayesian optimization 交替使用，即使没有任务数据知识也能有效调整数据混合。理论分析证明了 DUET 的累积遗憾使其收敛到最优训练数据混合。实验结果显示，在多种语言任务中，DUET 优于现有数据选择和混合方法，显著提高了模型在未知任务上的表现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00270v2",
      "published_date": "2025-02-01 01:52:32 UTC",
      "updated_date": "2025-05-18 13:39:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:45:23.073129"
    },
    {
      "arxiv_id": "2502.00262v3",
      "title": "INSIGHT: Enhancing Autonomous Driving Safety through Vision-Language Models on Context-Aware Hazard Detection and Edge Case Evaluation",
      "title_zh": "INSIGHT：通过视觉语言模型在上下文感知危险检测和边缘案例评估中增强自动驾驶安全",
      "authors": [
        "Dianwei Chen",
        "Zifan Zhang",
        "Yuchen Liu",
        "Xianfeng Terry Yang"
      ],
      "abstract": "Autonomous driving systems face significant challenges in handling\nunpredictable edge-case scenarios, such as adversarial pedestrian movements,\ndangerous vehicle maneuvers, and sudden environmental changes. Current\nend-to-end driving models struggle with generalization to these rare events due\nto limitations in traditional detection and prediction approaches. To address\nthis, we propose INSIGHT (Integration of Semantic and Visual Inputs for\nGeneralized Hazard Tracking), a hierarchical vision-language model (VLM)\nframework designed to enhance hazard detection and edge-case evaluation. By\nusing multimodal data fusion, our approach integrates semantic and visual\nrepresentations, enabling precise interpretation of driving scenarios and\naccurate forecasting of potential dangers. Through supervised fine-tuning of\nVLMs, we optimize spatial hazard localization using attention-based mechanisms\nand coordinate regression techniques. Experimental results on the BDD100K\ndataset demonstrate a substantial improvement in hazard prediction\nstraightforwardness and accuracy over existing models, achieving a notable\nincrease in generalization performance. This advancement enhances the\nrobustness and safety of autonomous driving systems, ensuring improved\nsituational awareness and potential decision-making in complex real-world\nscenarios.",
      "tldr_zh": "本文提出 INSIGHT 框架，一种基于 Vision-Language Models (VLMs) 的分层结构，用于提升自动驾驶系统的安全性，通过上下文感知危险检测和边缘场景评估，解决传统模型在处理不可预测事件（如危险行人行为和环境变化）时的泛化问题。该框架采用多模态数据融合整合语义和视觉表示，并通过监督微调、注意力机制和坐标回归技术优化空间危险定位。实验在 BDD100K 数据集上显示，INSIGHT 显著提高了危险预测的准确性和泛化性能，增强了系统的鲁棒性、安全性和实时决策能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00262v3",
      "published_date": "2025-02-01 01:43:53 UTC",
      "updated_date": "2025-05-16 17:26:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:45:36.183807"
    },
    {
      "arxiv_id": "2503.15517v1",
      "title": "Analysis of AI Effectiveness in Reducing Human Errors in Processing Transportation Requests",
      "title_zh": "翻译失败",
      "authors": [
        "Oleksandr Korostin"
      ],
      "abstract": "This article examines the characteristics of human errors in processing\ntransportation requests. The role of artificial intelligence (AI) in maritime\ntransportation is explored. The main methods and technologies used for\nautomating and optimizing the handling of transportation requests are analyzed,\nalong with their impact on reducing the number of errors. Examples of\nsuccessful AI implementation in large companies are provided, confirming the\npositive influence of these technologies on overall operational efficiency and\ncustomer service levels.",
      "tldr_zh": "这篇论文分析了处理运输请求中人为错误的特征，并探讨了人工智能(AI)在海运领域的应用及其作用。主要方法包括评估自动化和优化技术，这些技术显著减少了错误数量，并提升了整体运营效率和客户服务水平。研究通过大型公司成功实施AI的案例证实了其正面影响。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "I.2.0"
      ],
      "primary_category": "cs.HC",
      "comment": "4 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2503.15517v1",
      "published_date": "2025-02-01 01:26:14 UTC",
      "updated_date": "2025-02-01 01:26:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:47:48.787513"
    },
    {
      "arxiv_id": "2502.00241v1",
      "title": "Mordal: Automated Pretrained Model Selection for Vision Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Shiqi He",
        "Insu Jang",
        "Mosharaf Chowdhury"
      ],
      "abstract": "Incorporating multiple modalities into large language models (LLMs) is a\npowerful way to enhance their understanding of non-textual data, enabling them\nto perform multimodal tasks. Vision language models (VLMs) form the fastest\ngrowing category of multimodal models because of their many practical use\ncases, including in healthcare, robotics, and accessibility. Unfortunately,\neven though different VLMs in the literature demonstrate impressive visual\ncapabilities in different benchmarks, they are handcrafted by human experts;\nthere is no automated framework to create task-specific multimodal models.\n  We introduce Mordal, an automated multimodal model search framework that\nefficiently finds the best VLM for a user-defined task without manual\nintervention. Mordal achieves this both by reducing the number of candidates to\nconsider during the search process and by minimizing the time required to\nevaluate each remaining candidate. Our evaluation shows that Mordal can find\nthe best VLM for a given problem using up to $8.9\\times$--$11.6\\times$ lower\nGPU hours than grid search. In the process of our evaluation, we have also\ndiscovered new VLMs that outperform their state-of-the-art counterparts.",
      "tldr_zh": "该论文引入了Mordal，一种自动化框架，用于为视觉语言模型(VLMs)选择最佳预训练模型，从而无需人工干预即可针对用户定义的任务构建特定多模态模型。Mordal通过减少候选模型的数量和优化每个候选的评估时间来提高搜索效率。实验结果表明，该框架比传统网格搜索节省了8.9倍到11.6倍的GPU时间，并在评估过程中发现了新VLMs，这些模型超过了现有最先进模型的性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00241v1",
      "published_date": "2025-02-01 00:41:29 UTC",
      "updated_date": "2025-02-01 00:41:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:48:00.089109"
    },
    {
      "arxiv_id": "2502.00232v1",
      "title": "A Hybrid Random Forest and CNN Framework for Tile-Wise Oil-Water Classification in Hyperspectral Images",
      "title_zh": "一种混合随机森林和 CNN 框架，用于高光谱图像的基于平铺的油水分类",
      "authors": [
        "Mehdi Nickzamir",
        "Seyed Mohammad Sheikh Ahamdi Gandab"
      ],
      "abstract": "A novel hybrid Random Forest and Convolutional Neural Network (CNN) framework\nis presented for oil-water classification in hyperspectral images (HSI). To\naddress the challenge of preserving spatial context, the images were divided\ninto smaller, non-overlapping tiles, which served as the basis for training,\nvalidation, and testing. Random Forest demonstrated strong performance in\npixel-wise classification, outperforming models such as XGBoost,\nAttention-Based U-Net, and HybridSN. However, Random Forest loses spatial\ncontext, limiting its ability to fully exploit the spatial relationships in\nhyperspectral data. To improve performance, a CNN was trained on the\nprobability maps generated by the Random Forest, leveraging the CNN's capacity\nto incorporate spatial context. The hybrid approach achieved 7.6% improvement\nin recall (to 0.85), 2.4% improvement in F1 score (to 0.84), and 0.54%\nimprovement in AUC (to 0.99) compared to the baseline. These results highlight\nthe effectiveness of combining probabilistic outputs with spatial feature\nlearning for context-aware analysis of hyperspectral images.",
      "tldr_zh": "本文提出了一种混合 Random Forest 和 CNN 框架，用于高光谱图像 (HSI) 中基于图块的油水分类，以更好地保留空间上下文。框架首先使用 Random Forest 进行像素级分类，表现优于 XGBoost、Attention-Based U-Net 和 HybridSN，然后通过 CNN 在其生成的概率地图上训练，以整合空间关系。实验结果显示，该混合方法相比基线模型，召回率提高了 7.6%（至 0.85）、F1 分数提高了 2.4%（至 0.84）、AUC 提高了 0.54%（至 0.99）。这一方法突出了结合概率输出和空间特征学习的有效性，为 HSI 的上下文感知分析提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00232v1",
      "published_date": "2025-02-01 00:13:06 UTC",
      "updated_date": "2025-02-01 00:13:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T05:48:13.227028"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 72,
  "processed_papers_count": 72,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-22T05:48:31.249122"
}