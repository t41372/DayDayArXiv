[
  {
    "arxiv_id": "2502.00595v1",
    "title": "RPGBENCH: Evaluating Large Language Models as Role-Playing Game Engines",
    "authors": [
      "Pengfei Yu",
      "Dongming Shen",
      "Silin Meng",
      "Jaewon Lee",
      "Weisu Yin",
      "Andrea Yaoyun Cui",
      "Zhenlin Xu",
      "Yi Zhu",
      "Xingjian Shi",
      "Mu Li",
      "Alex Smola"
    ],
    "abstract": "We present RPGBench, the first benchmark designed to evaluate large language\nmodels (LLMs) as text-based role-playing game (RPG) engines. RPGBench comprises\ntwo core tasks: Game Creation (GC) and Game Simulation (GS). In GC, an LLM must\ncraft a valid and playable RPG world using a structured event-state\nrepresentation, ensuring logical coherence and proper termination conditions.\nIn GS, the LLM simulates interactive gameplay across multiple rounds while\nconsistently updating states and enforcing game rules. To comprehensively\nassess performance, RPGBench integrates objective and subjective evaluation\nmethodologies. Objective measures verify adherence to event mechanics and check\nvariable updates without requiring human intervention. Subjective measures,\nsuch as content interestingness, action quality, and role-playing capability,\nare evaluated via an LLM-as-a-judge framework, where a strong LLM grades each\ncandidate's outputs. Empirical results demonstrate that state-of-the-art LLMs\ncan produce engaging stories but often struggle to implement consistent,\nverifiable game mechanics, particularly in long or complex scenarios. By\ncombining structured, rule-based assessments with LLM-based judgments, RPGBench\nprovides a new standard for evaluating how well LLMs can balance creativity,\ncoherence, and complexity in text-based RPGs, opening avenues for more\nimmersive and controllable interactive storytelling.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Submitted to ICML 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.00595v1",
    "published_date": "2025-02-01 23:40:24 UTC",
    "updated_date": "2025-02-01 23:40:24 UTC"
  },
  {
    "arxiv_id": "2502.04341v1",
    "title": "Comparative Analysis of Community Detection Algorithms on the SNAP Social Circles Dataset",
    "authors": [
      "Yash Malode",
      "Amit Aylani",
      "Arvind Bhardwaj",
      "Deepak Hajoary"
    ],
    "abstract": "In network research, Community Detection has always been a topic of\nsignificant interest in network science, with numerous papers and algorithms\nproposing to uncover the underlying structures within networks. In this paper,\nwe conduct a comparative analysis of several prominent community detection\nalgorithms applied to the SNAP Social Circles Dataset, derived from the\nFacebook Social Media network. The algorithms implemented include Louvain,\nGirvan-Newman, Spectral Clustering, K-Means Clustering, etc. We evaluate the\nperformance of these algorithms based on various metrics such as modularity,\nnormalized cut-ratio, silhouette score, compactness, and separability. Our\nfindings reveal insights into the effectiveness of each algorithm in detecting\nvarious meaningful communities within the social network, shedding light on\ntheir strength and limitations. This research contributes to the understanding\nof community detection methods and provides valuable guidance for their\napplication in analyzing real-world social networks.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI",
    "comment": "Presented at IDEA2k24: https://ideaconference.in/ Submitted to\n  Springer Lecture Notes in Electrical Engineering series\n  (https://www.springer.com/series/7818)",
    "pdf_url": "http://arxiv.org/pdf/2502.04341v1",
    "published_date": "2025-02-01 23:38:09 UTC",
    "updated_date": "2025-02-01 23:38:09 UTC"
  },
  {
    "arxiv_id": "2502.00594v1",
    "title": "Fast Vision Mamba: Pooling Spatial Dimensions for Accelerated Processing",
    "authors": [
      "Saarthak Kapse",
      "Robin Betz",
      "Srinivasan Sivanandan"
    ],
    "abstract": "State Space Models (SSMs) with selective scan (Mamba) have been adapted into\nefficient vision models. Mamba, unlike Vision Transformers, achieves linear\ncomplexity for token interactions through a recurrent hidden state process.\nThis sequential processing is enhanced by a parallel scan algorithm, which\nreduces the computational time of recurrent steps from $L$ sequential steps to\n$log(L)$ parallel steps with respect to the number of input tokens ($L$). In\nthis work, we propose Fast Vision Mamba (FastVim), that further reduces the\ncomputational time of the SSM block by reducing the number of recurrent steps\nin Vision Mamba models while still retaining model performance. By alternately\npooling tokens along image dimensions across Mamba blocks, we obtain a\n2$\\times$ reduction in the number of parallel steps in SSM block. Our model\noffers up to $72.5\\%$ speedup in inference speed compared to baseline Vision\nMamba models on high resolution (2048$\\times$2048) images. Our experiments\ndemonstrate state-of-the-art performance with dramatically improved throughput\nin a range of tasks such as image classification, cell perturbation prediction,\nsegmentation, and object detection. Code is made available at\nhttps://github.com/insitro/FastVim",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "20 pages, 15 figures, https://github.com/insitro/FastVim",
    "pdf_url": "http://arxiv.org/pdf/2502.00594v1",
    "published_date": "2025-02-01 23:35:20 UTC",
    "updated_date": "2025-02-01 23:35:20 UTC"
  },
  {
    "arxiv_id": "2502.00587v2",
    "title": "Robust Knowledge Distillation in Federated Learning: Counteracting Backdoor Attacks",
    "authors": [
      "Ebtisaam Alharbi",
      "Leandro Soriano Marcolino",
      "Qiang Ni",
      "Antonios Gouglidis"
    ],
    "abstract": "Federated Learning (FL) enables collaborative model training across multiple\ndevices while preserving data privacy. However, it remains susceptible to\nbackdoor attacks, where malicious participants can compromise the global model.\nExisting defence methods are limited by strict assumptions on data\nheterogeneity (Non-Independent and Identically Distributed data) and the\nproportion of malicious clients, reducing their practicality and effectiveness.\nTo overcome these limitations, we propose Robust Knowledge Distillation (RKD),\na novel defence mechanism that enhances model integrity without relying on\nrestrictive assumptions. RKD integrates clustering and model selection\ntechniques to identify and filter out malicious updates, forming a reliable\nensemble of models. It then employs knowledge distillation to transfer the\ncollective insights from this ensemble to a global model. Extensive evaluations\ndemonstrate that RKD effectively mitigates backdoor threats while maintaining\nhigh model performance, outperforming current state-of-the-art defence methods\nacross various scenarios.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.00587v2",
    "published_date": "2025-02-01 22:57:08 UTC",
    "updated_date": "2025-02-25 11:42:39 UTC"
  },
  {
    "arxiv_id": "2502.00580v1",
    "title": "Defense Against the Dark Prompts: Mitigating Best-of-N Jailbreaking with Prompt Evaluation",
    "authors": [
      "Stuart Armstrong",
      "Matija Franklin",
      "Connor Stevens",
      "Rebecca Gorman"
    ],
    "abstract": "Recent work showed Best-of-N (BoN) jailbreaking using repeated use of random\naugmentations (such as capitalization, punctuation, etc) is effective against\nall major large language models (LLMs). We have found that $100\\%$ of the BoN\npaper's successful jailbreaks (confidence interval $[99.65\\%, 100.00\\%]$) and\n$99.8\\%$ of successful jailbreaks in our replication (confidence interval\n$[99.28\\%, 99.98\\%]$) were blocked with our Defense Against The Dark Prompts\n(DATDP) method. The DATDP algorithm works by repeatedly utilizing an evaluation\nLLM to evaluate a prompt for dangerous or manipulative behaviors--unlike some\nother approaches, DATDP also explicitly looks for jailbreaking attempts--until\na robust safety rating is generated. This success persisted even when utilizing\nsmaller LLMs to power the evaluation (Claude and LLaMa-3-8B-instruct proved\nalmost equally capable). These results show that, though language models are\nsensitive to seemingly innocuous changes to inputs, they seem also capable of\nsuccessfully evaluating the dangers of these inputs. Versions of DATDP can\ntherefore be added cheaply to generative AI systems to produce an immediate\nsignificant increase in safety.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "I.2.0"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.00580v1",
    "published_date": "2025-02-01 22:26:30 UTC",
    "updated_date": "2025-02-01 22:26:30 UTC"
  },
  {
    "arxiv_id": "2502.00577v1",
    "title": "Understanding Multimodal LLMs Under Distribution Shifts: An Information-Theoretic Approach",
    "authors": [
      "Changdae Oh",
      "Zhen Fang",
      "Shawn Im",
      "Xuefeng Du",
      "Yixuan Li"
    ],
    "abstract": "Multimodal large language models (MLLMs) have shown promising capabilities\nbut struggle under distribution shifts, where evaluation data differ from\ninstruction tuning distributions. Although previous works have provided\nempirical evaluations, we argue that establishing a formal framework that can\ncharacterize and quantify the risk of MLLMs is necessary to ensure the safe and\nreliable application of MLLMs in the real world. By taking an\ninformation-theoretic perspective, we propose the first theoretical framework\nthat enables the quantification of the maximum risk of MLLMs under distribution\nshifts. Central to our framework is the introduction of Effective Mutual\nInformation (EMI), a principled metric that quantifies the relevance between\ninput queries and model responses. We derive an upper bound for the EMI\ndifference between in-distribution (ID) and out-of-distribution (OOD) data,\nconnecting it to visual and textual distributional discrepancies. Extensive\nexperiments on real benchmark datasets, spanning 61 shift scenarios empirically\nvalidate our theoretical insights.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.00577v1",
    "published_date": "2025-02-01 22:06:56 UTC",
    "updated_date": "2025-02-01 22:06:56 UTC"
  },
  {
    "arxiv_id": "2502.01675v1",
    "title": "Semantic Communication based on Generative AI: A New Approach to Image Compression and Edge Optimization",
    "authors": [
      "Francesco Pezone"
    ],
    "abstract": "As digital technologies advance, communication networks face challenges in\nhandling the vast data generated by intelligent devices. Autonomous vehicles,\nsmart sensors, and IoT systems necessitate new paradigms. This thesis addresses\nthese challenges by integrating semantic communication and generative models\nfor optimized image compression and edge network resource allocation. Unlike\nbit-centric systems, semantic communication prioritizes transmitting meaningful\ndata specifically selected to convey the meaning rather than obtain a faithful\nrepresentation of the original data. The communication infrastructure can\nbenefit to significant improvements in bandwidth efficiency and latency\nreduction. Central to this work is the design of semantic-preserving image\ncompression using Generative Adversarial Networks and Denoising Diffusion\nProbabilistic Models. These models compress images by encoding only\nsemantically relevant features, allowing for high-quality reconstruction with\nminimal transmission. Additionally, a Goal-Oriented edge network optimization\nframework is introduced, leveraging the Information Bottleneck principle and\nstochastic optimization to dynamically allocate resources and enhance\nefficiency. By integrating semantic communication into edge networks, this\napproach balances computational efficiency and communication effectiveness,\nmaking it suitable for real-time applications. The thesis compares\nsemantic-aware models with conventional image compression techniques using\nclassical and semantic evaluation metrics. Results demonstrate the potential of\ncombining generative AI and semantic communication to create more efficient\nsemantic-goal-oriented communication networks that meet the demands of modern\ndata-driven applications.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "PhD thesis",
    "pdf_url": "http://arxiv.org/pdf/2502.01675v1",
    "published_date": "2025-02-01 21:48:31 UTC",
    "updated_date": "2025-02-01 21:48:31 UTC"
  },
  {
    "arxiv_id": "2502.20405v1",
    "title": "Pause-Tuning for Long-Context Comprehension: A Lightweight Approach to LLM Attention Recalibration",
    "authors": [
      "James Begin",
      "Namit Agrawal",
      "Eshan Singh",
      "Yicheng Fu",
      "Sean O'Brien",
      "Vasu Sharma",
      "Kevin Zhu"
    ],
    "abstract": "LLMs have demonstrated remarkable proficiency in understanding tasks but\ncontinue to struggle with long-context comprehension, particularly with content\nlocated in the middle of extensive inputs. This limitation, known as the\nLost-in-the-Middle (LITM) problem, hinders models from fully processing and\nutilizing information across lengthy contexts. To address this issue, we\nintroduce pause-tuning, a technique that redistributes attention to enhance\ncomprehension of long-context inputs. Our approach involves fine-tuning\nlanguage models on datasets with artificially inserted pause tokens, which\nserve to segment the input into smaller, more manageable parts. We evaluate\npause-tuning against alternative approaches using the Needle-in-a-Haystack\nbenchmark, where models must retrieve information embedded within contexts of\nup to 128K tokens. Experimental results demonstrate significant performance\ngains, with the LLaMA 3.2 3B Instruct model and the LLaMA 3.1 8B Instruct model\nimproving by 10.61% and 3.57% respectively on average, suggesting that\npause-tuning successfully enhances attention redistribution and improves\nlong-context retention. The code and data are available at\nhttps://anonymous.4open.science/r/LITM-PauseTokens-7357.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.20405v1",
    "published_date": "2025-02-01 21:47:15 UTC",
    "updated_date": "2025-02-01 21:47:15 UTC"
  },
  {
    "arxiv_id": "2502.00568v3",
    "title": "Generating crossmodal gene expression from cancer histopathology improves multimodal AI predictions",
    "authors": [
      "Samiran Dey",
      "Christopher R. S. Banerji",
      "Partha Basuchowdhuri",
      "Sanjoy K. Saha",
      "Deepak Parashar",
      "Tapabrata Chakraborti"
    ],
    "abstract": "Emerging research has highlighted that artificial intelligence based\nmultimodal fusion of digital pathology and transcriptomic features can improve\ncancer diagnosis (grading/subtyping) and prognosis (survival risk) prediction.\nHowever, such direct fusion for joint decision is impractical in real clinical\nsettings, where histopathology is still the gold standard for diagnosis and\ntranscriptomic tests are rarely requested, at least in the public healthcare\nsystem. With our novel diffusion based crossmodal generative AI model PathGen,\nwe show that genomic expressions synthesized from digital histopathology\njointly predicts cancer grading and patient survival risk with high accuracy\n(state-of-the-art performance), certainty (through conformal coverage\nguarantee) and interpretability (through distributed attention maps). PathGen\ncode is available for open use by the research community through GitHub at\nhttps://github.com/Samiran-Dey/PathGen.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.00568v3",
    "published_date": "2025-02-01 21:28:30 UTC",
    "updated_date": "2025-02-11 12:25:42 UTC"
  },
  {
    "arxiv_id": "2502.00567v1",
    "title": "Lessons for GenAI Literacy From a Field Study of Human-GenAI Augmentation in the Workplace",
    "authors": [
      "Aditya Johri",
      "Johannes Schleiss",
      "Nupoor Ranade"
    ],
    "abstract": "Generative artificial intelligence (GenAI) is increasingly becoming a part of\nwork practices across the technology industry and being used across a range of\nindustries. This has necessitated the need to better understand how GenAI is\nbeing used by professionals in the field so that we can better prepare students\nfor the workforce. An improved understanding of the use of GenAI in practice\ncan help provide guidance on the design of GenAI literacy efforts including how\nto integrate it within courses and curriculum, what aspects of GenAI to teach,\nand even how to teach it. This paper presents a field study that compares the\nuse of GenAI across three different functions - product development, software\nengineering, and digital content creation - to identify how GenAI is currently\nbeing used in the industry. This study takes a human augmentation approach with\na focus on human cognition and addresses three research questions: how is GenAI\naugmenting work practices; what knowledge is important and how are workers\nlearning; and what are the implications for training the future workforce.\nFindings show a wide variance in the use of GenAI and in the level of computing\nknowledge of users. In some industries GenAI is being used in a highly\ntechnical manner with deployment of fine-tuned models across domains. Whereas\nin others, only off-the-shelf applications are being used for generating\ncontent. This means that the need for what to know about GenAI varies, and so\ndoes the background knowledge needed to utilize it. For the purposes of\nteaching and learning, our findings indicated that different levels of GenAI\nunderstanding needs to be integrated into courses. From a faculty perspective,\nthe work has implications for training faculty so that they are aware of the\nadvances and how students are possibly, as early adopters, already using GenAI\nto augment their learning practices.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "Pre-print, paper accepted at IEEE EDUCON2025",
    "pdf_url": "http://arxiv.org/pdf/2502.00567v1",
    "published_date": "2025-02-01 21:26:31 UTC",
    "updated_date": "2025-02-01 21:26:31 UTC"
  },
  {
    "arxiv_id": "2502.00547v1",
    "title": "Milmer: a Framework for Multiple Instance Learning based Multimodal Emotion Recognition",
    "authors": [
      "Zaitian Wang",
      "Jian He",
      "Yu Liang",
      "Xiyuan Hu",
      "Tianhao Peng",
      "Kaixin Wang",
      "Jiakai Wang",
      "Chenlong Zhang",
      "Weili Zhang",
      "Shuang Niu",
      "Xiaoyang Xie"
    ],
    "abstract": "Emotions play a crucial role in human behavior and decision-making, making\nemotion recognition a key area of interest in human-computer interaction (HCI).\nThis study addresses the challenges of emotion recognition by integrating\nfacial expression analysis with electroencephalogram (EEG) signals, introducing\na novel multimodal framework-Milmer. The proposed framework employs a\ntransformer-based fusion approach to effectively integrate visual and\nphysiological modalities. It consists of an EEG preprocessing module, a facial\nfeature extraction and balancing module, and a cross-modal fusion module. To\nenhance visual feature extraction, we fine-tune a pre-trained Swin Transformer\non emotion-related datasets. Additionally, a cross-attention mechanism is\nintroduced to balance token representation across modalities, ensuring\neffective feature integration. A key innovation of this work is the adoption of\na multiple instance learning (MIL) approach, which extracts meaningful\ninformation from multiple facial expression images over time, capturing\ncritical temporal dynamics often overlooked in previous studies. Extensive\nexperiments conducted on the DEAP dataset demonstrate the superiority of the\nproposed framework, achieving a classification accuracy of 96.72% in the\nfour-class emotion recognition task. Ablation studies further validate the\ncontributions of each module, highlighting the significance of advanced feature\nextraction and fusion strategies in enhancing emotion recognition performance.\nOur code are available at https://github.com/liangyubuaa/Milmer.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.00547v1",
    "published_date": "2025-02-01 20:32:57 UTC",
    "updated_date": "2025-02-01 20:32:57 UTC"
  },
  {
    "arxiv_id": "2502.00545v1",
    "title": "Integrating Frequency Guidance into Multi-source Domain Generalization for Bearing Fault Diagnosis",
    "authors": [
      "Xiaotong Tu",
      "Chenyu Ma",
      "Qingyao Wu",
      "Yinhao Liu",
      "Hongyang Zhang"
    ],
    "abstract": "Recent generalizable fault diagnosis researches have effectively tackled the\ndistributional shift between unseen working conditions. Most of them mainly\nfocus on learning domain-invariant representation through feature-level\nmethods. However, the increasing numbers of unseen domains may lead to\ndomain-invariant features contain instance-level spurious correlations, which\nimpact the previous models' generalizable ability. To address the limitations,\nwe propose the Fourier-based Augmentation Reconstruction Network, namely\nFARNet.The methods are motivated by the observation that the Fourier phase\ncomponent and amplitude component preserve different semantic information of\nthe signals, which can be employed in domain augmentation techniques. The\nnetwork comprises an amplitude spectrum sub-network and a phase spectrum\nsub-network, sequentially reducing the discrepancy between the source and\ntarget domains. To construct a more robust generalized model, we employ a\nmulti-source domain data augmentation strategy in the frequency domain.\nSpecifically, a Frequency-Spatial Interaction Module (FSIM) is introduced to\nhandle global information and local spatial features, promoting representation\nlearning between the two sub-networks. To refine the decision boundary of our\nmodel output compared to conventional triplet loss, we propose a manifold\ntriplet loss to contribute to generalization. Through extensive experiments on\nthe CWRU and SJTU datasets, FARNet demonstrates effective performance and\nachieves superior results compared to current cross-domain approaches on the\nbenchmarks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.00545v1",
    "published_date": "2025-02-01 20:23:03 UTC",
    "updated_date": "2025-02-01 20:23:03 UTC"
  },
  {
    "arxiv_id": "2502.01673v2",
    "title": "Multilingual State Space Models for Structured Question Answering in Indic Languages",
    "authors": [
      "Arpita Vats",
      "Rahul Raja",
      "Mrinal Mathur",
      "Vinija Jain",
      "Aman Chadha"
    ],
    "abstract": "The diversity and complexity of Indic languages present unique challenges for\nnatural language processing (NLP) tasks, particularly in the domain of question\nanswering (QA).To address these challenges, this paper explores the application\nof State Space Models (SSMs),to build efficient and contextually aware QA\nsystems tailored for Indic languages. SSMs are particularly suited for this\ntask due to their ability to model long-term and short-term dependencies in\nsequential data, making them well-equipped to handle the rich morphology,\ncomplex syntax, and contextual intricacies characteristic of Indian languages.\nWe evaluated multiple SSM architectures across diverse datasets representing\nvarious Indic languages and conducted a comparative analysis of their\nperformance. Our results demonstrate that these models effectively capture\nlinguistic subtleties, leading to significant improvements in question\ninterpretation, context alignment, and answer generation. This work represents\nthe first application of SSMs to question answering tasks in Indic languages,\nestablishing a foundational benchmark for future research in this domain. We\npropose enhancements to existing SSM frameworks, optimizing their applicability\nto low-resource settings and multilingual scenarios prevalent in Indic\nlanguages.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at NAACL",
    "pdf_url": "http://arxiv.org/pdf/2502.01673v2",
    "published_date": "2025-02-01 19:53:02 UTC",
    "updated_date": "2025-04-24 04:40:35 UTC"
  },
  {
    "arxiv_id": "2502.01672v1",
    "title": "Doubly Robust Monte Carlo Tree Search",
    "authors": [
      "Manqing Liu",
      "Andrew L. Beam"
    ],
    "abstract": "We present Doubly Robust Monte Carlo Tree Search (DR-MCTS), a novel algorithm\nthat integrates Doubly Robust (DR) off-policy estimation into Monte Carlo Tree\nSearch (MCTS) to enhance sample efficiency and decision quality in complex\nenvironments. Our approach introduces a hybrid estimator that combines MCTS\nrollouts with DR estimation, offering theoretical guarantees of unbiasedness\nand variance reduction under specified conditions. Empirical evaluations in\nTic-Tac-Toe and the partially observable VirtualHome environment demonstrate\nDR-MCTS's superior performance over standard MCTS. In Tic-Tac-Toe, DR-MCTS\nachieves an 88% win rate compared to a 10% win rate for standard MCTS. In\ncompound VirtualHome tasks, DR-MCTS attains a 20.7% success rate versus 10.3%\nfor standard MCTS. Our scaling analysis reveals that DR-MCTS exhibits better\nsample efficiency, notably outperforming standard MCTS with larger language\nmodels while using a smaller model. These results underscore DR-MCTS's\npotential for efficient decision-making in complex, real-world scenarios where\nsample efficiency is paramount.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01672v1",
    "published_date": "2025-02-01 19:32:46 UTC",
    "updated_date": "2025-02-01 19:32:46 UTC"
  },
  {
    "arxiv_id": "2503.04733v1",
    "title": "Ethics of generative AI and manipulation: a design-oriented research agenda",
    "authors": [
      "Michael Klenk"
    ],
    "abstract": "Generative AI enables automated, effective manipulation at scale. Despite the\ngrowing general ethical discussion around generative AI, the specific\nmanipulation risks remain inadequately investigated. This article outlines\nessential inquiries encompassing conceptual, empirical, and design dimensions\nof manipulation, pivotal for comprehending and curbing manipulation risks. By\nhighlighting these questions, the article underscores the necessity of an\nappropriate conceptualisation of manipulation to ensure the responsible\ndevelopment of Generative AI technologies.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04733v1",
    "published_date": "2025-02-01 19:18:59 UTC",
    "updated_date": "2025-02-01 19:18:59 UTC"
  },
  {
    "arxiv_id": "2502.00530v1",
    "title": "Generic Multimodal Spatially Graph Network for Spatially Embedded Network Representation Learning",
    "authors": [
      "Xudong Fan",
      "JÃ¼rgen Hackl"
    ],
    "abstract": "Spatially embedded networks (SENs) represent a special type of complex graph,\nwhose topologies are constrained by the networks' embedded spatial\nenvironments. The graph representation of such networks is thereby influenced\nby the embedded spatial features of both nodes and edges. Accurate network\nrepresentation of the graph structure and graph features is a fundamental task\nfor various graph-related tasks. In this study, a Generic Multimodal Spatially\nGraph Convolutional Network (GMu-SGCN) is developed for efficient\nrepresentation of spatially embedded networks. The developed GMu-SGCN model has\nthe ability to learn the node connection pattern via multimodal node and edge\nfeatures. In order to evaluate the developed model, a river network dataset and\na power network dataset have been used as test beds. The river network\nrepresents the naturally developed SENs, whereas the power network represents a\nman-made network. Both types of networks are heavily constrained by the spatial\nenvironments and uncertainties from nature. Comprehensive evaluation analysis\nshows the developed GMu-SGCN can improve accuracy of the edge existence\nprediction task by 37.1\\% compared to a GraphSAGE model which only considers\nthe node's position feature in a power network test bed. Our model demonstrates\nthe importance of considering the multidimensional spatial feature for\nspatially embedded network representation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.00530v1",
    "published_date": "2025-02-01 19:05:48 UTC",
    "updated_date": "2025-02-01 19:05:48 UTC"
  },
  {
    "arxiv_id": "2502.00511v2",
    "title": "Bridging Internal Probability and Self-Consistency for Effective and Efficient LLM Reasoning",
    "authors": [
      "Zhi Zhou",
      "Tan Yuhao",
      "Zenan Li",
      "Yuan Yao",
      "Lan-Zhe Guo",
      "Xiaoxing Ma",
      "Yu-Feng Li"
    ],
    "abstract": "Recent advancements in large language models (LLMs) have demonstrated\nremarkable reasoning capabilities. However, single-shot inference often yields\nunreliable results for complex reasoning tasks, leading researchers to explore\nmultiple reasoning paths through methods such as perplexity and\nself-consistency. In this paper, we present the first theoretical error\ndecomposition analysis of these techniques, breaking down their error into\nestimation error and model error. Our analysis reveals a fundamental trade-off:\nperplexity methods suffer from substantial model error due to the absence of a\nproper consistency function, while self-consistency exhibits high estimation\nerror due to a slow error convergence rate. To overcome these limitations, we\npropose Reasoning-Pruning Perplexity Consistency (RPC). This approach combines\nPerplexity Consistency, which seamlessly integrates LLM perplexity with\nself-consistency, and Reasoning Pruning, which eliminates low-probability\nreasoning paths to effectively prevent the degeneration of estimation error\nreduction. Theoretical analysis demonstrates that RPC not only accelerates the\nconvergence rate of estimation error to an exponential level but also holds\nstrong potential for further reducing model error. Extensive empirical\nevaluations on seven benchmark datasets confirm that RPC can significantly\nimprove reasoning performance, sample efficiency, and confidence reliability.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Preliminary work",
    "pdf_url": "http://arxiv.org/pdf/2502.00511v2",
    "published_date": "2025-02-01 18:09:49 UTC",
    "updated_date": "2025-02-13 07:35:08 UTC"
  },
  {
    "arxiv_id": "2502.00510v2",
    "title": "Who's the MVP? A Game-Theoretic Evaluation Benchmark for Modular Attribution in LLM Agents",
    "authors": [
      "Yingxuan Yang",
      "Bo Huang",
      "Siyuan Qi",
      "Chao Feng",
      "Haoyi Hu",
      "Yuxuan Zhu",
      "Jinbo Hu",
      "Haoran Zhao",
      "Ziyi He",
      "Xiao Liu",
      "Zongyu Wang",
      "Lin Qiu",
      "Xuezhi Cao",
      "Xunliang Cai",
      "Yong Yu",
      "Weinan Zhang"
    ],
    "abstract": "Large Language Model (LLM) agents frameworks often employ modular\narchitectures, incorporating components such as planning, reasoning, action\nexecution, and reflection to tackle complex tasks. However, quantifying the\ncontribution of each module to overall system performance remains a significant\nchallenge, impeding optimization and interpretability. To address this, we\nintroduce CapaBench (Capability-level Assessment Benchmark), an evaluation\nframework grounded in cooperative game theory's Shapley Value, which\nsystematically measures the marginal impact of individual modules and their\ninteractions within an agent's architecture. By replacing default modules with\ntest variants across all possible combinations, CapaBench provides a principle\nmethod for attributing performance contributions. Key contributions include:\n(1) We are the first to propose a Shapley Value-based methodology for\nquantifying the contributions of capabilities in LLM agents; (2) Modules with\nhigh Shapley Values consistently lead to predictable performance gains when\ncombined, enabling targeted optimization; and (3) We build a multi-round\ndataset of over 1,500 entries spanning diverse domains and practical task\nscenarios, enabling comprehensive evaluation of agent capabilities. CapaBench\nbridges the gap between component-level evaluation and holistic system\nassessment, providing actionable insights for optimizing modular LLM agents and\nadvancing their deployment in complex, real-world scenarios.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.00510v2",
    "published_date": "2025-02-01 18:07:34 UTC",
    "updated_date": "2025-02-16 12:34:47 UTC"
  },
  {
    "arxiv_id": "2502.00507v2",
    "title": "A statistically consistent measure of Semantic Variability using Language Models",
    "authors": [
      "Yi Liu"
    ],
    "abstract": "To address the issue of variability in the output generated by a language\nmodel, we present a measure of semantic variability that is statistically\nconsistent under mild assumptions. This measure, denoted as semantic spectral\nentropy, is a easy to implement algorithm that requires just off the shelf\nlanguage models. We put very few restrictions on the language models and we\nhave shown in a clear simulation studies that such method can generate accurate\nmetric despite randomness that arise from the language models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.00507v2",
    "published_date": "2025-02-01 17:55:58 UTC",
    "updated_date": "2025-02-11 16:39:55 UTC"
  },
  {
    "arxiv_id": "2502.00501v1",
    "title": "Optimizing Feature Selection in Causal Inference: A Three-Stage Computational Framework for Unbiased Estimation",
    "authors": [
      "Tianyu Yang",
      "Md. Noor-E-Alam"
    ],
    "abstract": "Feature selection is an important but challenging task in causal inference\nfor obtaining unbiased estimates of causal quantities. Properly selected\nfeatures in causal inference not only significantly reduce the time required to\nimplement a matching algorithm but, more importantly, can also reduce the bias\nand variance when estimating causal quantities. When feature selection\ntechniques are applied in causal inference, the crucial criterion is to select\nvariables that, when used for matching, can achieve an unbiased and robust\nestimation of causal quantities. Recent research suggests that balancing only\non treatment-associated variables introduces bias while balancing on spurious\nvariables increases variance. To address this issue, we propose an enhanced\nthree-stage framework that shows a significant improvement in selecting the\ndesired subset of variables compared to the existing state-of-the-art feature\nselection framework for causal inference, resulting in lower bias and variance\nin estimating the causal quantity. We evaluated our proposed framework using a\nstate-of-the-art synthetic data across various settings and observed superior\nperformance within a feasible computation time, ensuring scalability for\nlarge-scale datasets. Finally, to demonstrate the applicability of our proposed\nmethodology using large-scale real-world data, we evaluated an important US\nhealthcare policy related to the opioid epidemic crisis: whether opioid use\ndisorder has a causal relationship with suicidal behavior.",
    "categories": [
      "stat.ME",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "stat.ME",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.00501v1",
    "published_date": "2025-02-01 17:47:28 UTC",
    "updated_date": "2025-02-01 17:47:28 UTC"
  },
  {
    "arxiv_id": "2502.00500v2",
    "title": "Video Latent Flow Matching: Optimal Polynomial Projections for Video Interpolation and Extrapolation",
    "authors": [
      "Yang Cao",
      "Zhao Song",
      "Chiwun Yang"
    ],
    "abstract": "This paper considers an efficient video modeling process called Video Latent\nFlow Matching (VLFM). Unlike prior works, which randomly sampled latent patches\nfor video generation, our method relies on current strong pre-trained image\ngeneration models, modeling a certain caption-guided flow of latent patches\nthat can be decoded to time-dependent video frames. We first speculate multiple\nimages of a video are differentiable with respect to time in some latent space.\nBased on this conjecture, we introduce the HiPPO framework to approximate the\noptimal projection for polynomials to generate the probability path. Our\napproach gains the theoretical benefits of the bounded universal approximation\nerror and timescale robustness. Moreover, VLFM processes the interpolation and\nextrapolation abilities for video generation with arbitrary frame rates. We\nconduct experiments on several text-to-video datasets to showcase the\neffectiveness of our method.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "39 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.00500v2",
    "published_date": "2025-02-01 17:40:11 UTC",
    "updated_date": "2025-02-04 15:19:12 UTC"
  },
  {
    "arxiv_id": "2502.00499v1",
    "title": "Discovering Directly-Follows Graph Model for Acyclic Processes",
    "authors": [
      "Nikita Shaimov",
      "Irina Lomazova",
      "Alexey Mitsyuk"
    ],
    "abstract": "Process mining is the common name for a range of methods and approaches aimed\nat analysing and improving processes. Specifically, methods that aim to derive\nprocess models from event logs fall under the category of process discovery.\nWithin the range of processes, acyclic processes form a distinct category. In\nsuch processes, previously performed actions are not repeated, forming chains\nof unique actions. However, due to differences in the order of actions,\nexisting process discovery methods can provide models containing cycles even if\na process is acyclic. This paper presents a new process discovery algorithm\nthat allows to discover acyclic DFG models for acyclic processes. A model is\ndiscovered by partitioning an event log into parts that provide acyclic DFG\nmodels and merging them while avoiding the formation of cycles. The resulting\nalgorithm was tested both on real-life and artificial event logs. Absence of\ncycles improves model visual clarity and precision, also allowing to apply\ncycle-sensitive methods or visualisations to the model.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "24 pages, 15 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.00499v1",
    "published_date": "2025-02-01 17:39:28 UTC",
    "updated_date": "2025-02-01 17:39:28 UTC"
  },
  {
    "arxiv_id": "2502.00498v1",
    "title": "MetaOpenFOAM 2.0: Large Language Model Driven Chain of Thought for Automating CFD Simulation and Post-Processing",
    "authors": [
      "Yuxuan Chen",
      "Xu Zhu",
      "Hua Zhou",
      "Zhuyin Ren"
    ],
    "abstract": "Computational Fluid Dynamics (CFD) is widely used in aerospace, energy, and\nbiology to model fluid flow, heat transfer, and chemical reactions. While Large\nLanguage Models (LLMs) have transformed various domains, their application in\nCFD remains limited, particularly for complex tasks like post-processing. To\nbridge this gap, we introduce MetaOpenFOAM 2.0, which leverages Chain of\nThought (COT) decomposition and iterative verification to enhance accessibility\nfor non-expert users through natural language inputs. Tested on a new benchmark\ncovering simulation (fluid flow, heat transfer, combustion) and post-processing\n(extraction, visualization), MetaOpenFOAM 2.0 achieved an Executability score\nof 6.3/7 and a pass rate of 86.9%, significantly outperforming MetaOpenFOAM 1.0\n(2.1/7, 0%). Additionally, it proved cost-efficient, averaging $0.15 per case.\nAn ablation study confirmed that COT-driven decomposition and iterative\nrefinement substantially improved task performance. Furthermore, scaling laws\nshowed that increasing COT steps enhanced accuracy while raising token usage,\naligning with LLM post-training scaling trends. These results highlight the\ntransformative potential of LLMs in automating CFD workflows for industrial and\nresearch applications. Code is available at\nhttps://github.com/Terry-cyx/MetaOpenFOAM",
    "categories": [
      "cs.AI",
      "physics.comp-ph"
    ],
    "primary_category": "cs.AI",
    "comment": "16 pages,11 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.00498v1",
    "published_date": "2025-02-01 17:31:25 UTC",
    "updated_date": "2025-02-01 17:31:25 UTC"
  },
  {
    "arxiv_id": "2502.01671v1",
    "title": "Life-Cycle Emissions of AI Hardware: A Cradle-To-Grave Approach and Generational Trends",
    "authors": [
      "Ian Schneider",
      "Hui Xu",
      "Stephan Benecke",
      "David Patterson",
      "Keguo Huang",
      "Parthasarathy Ranganathan",
      "Cooper Elsworth"
    ],
    "abstract": "Specialized hardware accelerators aid the rapid advancement of artificial\nintelligence (AI), and their efficiency impacts AI's environmental\nsustainability. This study presents the first publication of a comprehensive AI\naccelerator life-cycle assessment (LCA) of greenhouse gas emissions, including\nthe first publication of manufacturing emissions of an AI accelerator.\n  Our analysis of five Tensor Processing Units (TPUs) encompasses all stages of\nthe hardware lifespan - from raw material extraction, manufacturing, and\ndisposal, to energy consumption during development, deployment, and serving of\nAI models. Using first-party data, it offers the most comprehensive evaluation\nto date of AI hardware's environmental impact. We include detailed descriptions\nof our LCA to act as a tutorial, road map, and inspiration for other computer\nengineers to perform similar LCAs to help us all understand the environmental\nimpacts of our chips and of AI.\n  A byproduct of this study is the new metric compute carbon intensity (CCI)\nthat is helpful in evaluating AI hardware sustainability and in estimating the\ncarbon footprint of training and inference. This study shows that CCI improves\n3x from TPU v4i to TPU v6e.\n  Moreover, while this paper's focus is on hardware, software advancements\nleverage and amplify these gains.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01671v1",
    "published_date": "2025-02-01 17:26:19 UTC",
    "updated_date": "2025-02-01 17:26:19 UTC"
  },
  {
    "arxiv_id": "2502.00495v1",
    "title": "Looking into the Future of Health-Care Services: Can Life-Like Agents Change the Future of Health-Care Services?",
    "authors": [
      "Mohammad Saleh Torkestani",
      "Robert Davis",
      "Abdolhossein Sarrafzadeh"
    ],
    "abstract": "Time constraints on doctor patient interaction and restricted access to\nspecialists under the managed care system led to increasingly referring to\ncomputers as a medical information source and a self-health-care management\ntool. However, research show that less than 40% of information seekers\nindicated that online information helped them to make a decision about their\nhealth. Searching multiple web sites that need basic computer skills, lack of\ninteraction and no face to face interaction in most search engines and some\nsocial issues, led us to develop a specialized life-like agent that would\novercome mentioned problems.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "6 pages, 2 figures, 3rd International Conference on Machine Learning\n  and Computing (ICMLC 2011): February 26-28, 2011, Singapore",
    "pdf_url": "http://arxiv.org/pdf/2502.00495v1",
    "published_date": "2025-02-01 17:11:49 UTC",
    "updated_date": "2025-02-01 17:11:49 UTC"
  },
  {
    "arxiv_id": "2502.00494v2",
    "title": "Data Overvaluation Attack and Truthful Data Valuation",
    "authors": [
      "Shuyuan Zheng",
      "Sudong Cai",
      "Chuan Xiao",
      "Yang Cao",
      "Jianbin Qin",
      "Masatoshi Yoshikawa",
      "Makoto Onizuka"
    ],
    "abstract": "In collaborative machine learning, data valuation, i.e., evaluating the\ncontribution of each client' data to the machine learning model, has become a\ncritical task for incentivizing and selecting positive data contributions.\nHowever, existing studies often assume that clients engage in data valuation\ntruthfully, overlooking the practical motivation for clients to exaggerate\ntheir contributions. To unlock this threat, this paper introduces the first\ndata overvaluation attack, enabling strategic clients to have their data\nsignificantly overvalued. Furthermore, we propose a truthful data valuation\nmetric, named Truth-Shapley. Truth-Shapley is the unique metric that guarantees\nsome promising axioms for data valuation while ensuring that clients' optimal\nstrategy is to perform truthful data valuation. Our experiments demonstrate the\nvulnerability of existing data valuation metrics to the data overvaluation\nattack and validate the robustness and effectiveness of Truth-Shapley.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.00494v2",
    "published_date": "2025-02-01 17:05:37 UTC",
    "updated_date": "2025-02-04 08:36:53 UTC"
  },
  {
    "arxiv_id": "2502.01669v1",
    "title": "Addressing Delayed Feedback in Conversion Rate Prediction via Influence Functions",
    "authors": [
      "Chenlu Ding",
      "Jiancan Wu",
      "Yancheng Yuan",
      "Junfeng Fang",
      "Cunchun Li",
      "Xiang Wang",
      "Xiangnan He"
    ],
    "abstract": "In the realm of online digital advertising, conversion rate (CVR) prediction\nplays a pivotal role in maximizing revenue under cost-per-conversion (CPA)\nmodels, where advertisers are charged only when users complete specific\nactions, such as making a purchase. A major challenge in CVR prediction lies in\nthe delayed feedback problem-conversions may occur hours or even weeks after\ninitial user interactions. This delay complicates model training, as recent\ndata may be incomplete, leading to biases and diminished performance. Although\nexisting methods attempt to address this issue, they often fall short in\nadapting to evolving user behaviors and depend on auxiliary models, which\nintroduces computational inefficiencies and the risk of model inconsistency. In\nthis work, we propose an Influence Function-empowered framework for Delayed\nFeedback Modeling (IF-DFM). IF-DFM leverages influence functions to estimate\nhow newly acquired and delayed conversion data impact model parameters,\nenabling efficient parameter updates without the need for full retraining.\nAdditionally, we present a scalable algorithm that efficiently computes\nparameter updates by reframing the inverse Hessian-vector product as an\noptimization problem, striking a balance between computational efficiency and\neffectiveness. Extensive experiments on benchmark datasets demonstrate that\nIF-DFM consistently surpasses state-of-the-art methods, significantly enhancing\nboth prediction accuracy and model adaptability.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01669v1",
    "published_date": "2025-02-01 16:23:13 UTC",
    "updated_date": "2025-02-01 16:23:13 UTC"
  },
  {
    "arxiv_id": "2502.01667v1",
    "title": "Refining Alignment Framework for Diffusion Models with Intermediate-Step Preference Ranking",
    "authors": [
      "Jie Ren",
      "Yuhang Zhang",
      "Dongrui Liu",
      "Xiaopeng Zhang",
      "Qi Tian"
    ],
    "abstract": "Direct preference optimization (DPO) has shown success in aligning diffusion\nmodels with human preference. Previous approaches typically assume a consistent\npreference label between final generations and noisy samples at intermediate\nsteps, and directly apply DPO to these noisy samples for fine-tuning. However,\nwe theoretically identify inherent issues in this assumption and its impacts on\nthe effectiveness of preference alignment. We first demonstrate the inherent\nissues from two perspectives: gradient direction and preference order, and then\npropose a Tailored Preference Optimization (TailorPO) framework for aligning\ndiffusion models with human preference, underpinned by some theoretical\ninsights. Our approach directly ranks intermediate noisy samples based on their\nstep-wise reward, and effectively resolves the gradient direction issues\nthrough a simple yet efficient design. Additionally, we incorporate the\ngradient guidance of diffusion models into preference alignment to further\nenhance the optimization effectiveness. Experimental results demonstrate that\nour method significantly improves the model's ability to generate aesthetically\npleasing and human-preferred images.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01667v1",
    "published_date": "2025-02-01 16:08:43 UTC",
    "updated_date": "2025-02-01 16:08:43 UTC"
  },
  {
    "arxiv_id": "2502.00465v1",
    "title": "Enhance Learning Efficiency of Oblique Decision Tree via Feature Concatenation",
    "authors": [
      "Shen-Huan Lyu",
      "Yi-Xiao He",
      "Yanyan Wang",
      "Zhihao Qu",
      "Bin Tang",
      "Baoliu Ye"
    ],
    "abstract": "Oblique Decision Tree (ODT) separates the feature space by linear\nprojections, as opposed to the conventional Decision Tree (DT) that forces\naxis-parallel splits. ODT has been proven to have a stronger representation\nability than DT, as it provides a way to create shallower tree structures while\nstill approximating complex decision boundaries. However, its learning\nefficiency is still insufficient, since the linear projections cannot be\ntransmitted to the child nodes, resulting in a waste of model parameters. In\nthis work, we propose an enhanced ODT method with Feature Concatenation\n(\\texttt{FC-ODT}), which enables in-model feature transformation to transmit\nthe projections along the decision paths. Theoretically, we prove that our\nmethod enjoys a faster consistency rate w.r.t. the tree depth, indicating that\nour method possesses a significant advantage in generalization performance,\nespecially for shallow trees. Experiments show that \\texttt{FC-ODT} can\noutperform the other state-of-the-art decision trees with a limited tree depth.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.00465v1",
    "published_date": "2025-02-01 15:49:18 UTC",
    "updated_date": "2025-02-01 15:49:18 UTC"
  },
  {
    "arxiv_id": "2502.00459v2",
    "title": "AudioGenX: Explainability on Text-to-Audio Generative Models",
    "authors": [
      "Hyunju Kang",
      "Geonhee Han",
      "Yoonjae Jeong",
      "Hogun Park"
    ],
    "abstract": "Text-to-audio generation models (TAG) have achieved significant advances in\ngenerating audio conditioned on text descriptions. However, a critical\nchallenge lies in the lack of transparency regarding how each textual input\nimpacts the generated audio. To address this issue, we introduce AudioGenX, an\nExplainable AI (XAI) method that provides explanations for text-to-audio\ngeneration models by highlighting the importance of input tokens. AudioGenX\noptimizes an Explainer by leveraging factual and counterfactual objective\nfunctions to provide faithful explanations at the audio token level. This\nmethod offers a detailed and comprehensive understanding of the relationship\nbetween text inputs and audio outputs, enhancing both the explainability and\ntrustworthiness of TAG models. Extensive experiments demonstrate the\neffectiveness of AudioGenX in producing faithful explanations, benchmarked\nagainst existing methods using novel evaluation metrics specifically designed\nfor audio generation tasks.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "14 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.00459v2",
    "published_date": "2025-02-01 15:37:42 UTC",
    "updated_date": "2025-02-04 04:00:01 UTC"
  },
  {
    "arxiv_id": "2502.00451v1",
    "title": "Towards Privacy-aware Mental Health AI Models: Advances, Challenges, and Opportunities",
    "authors": [
      "Aishik Mandal",
      "Tanmoy Chakraborty",
      "Iryna Gurevych"
    ],
    "abstract": "Mental illness is a widespread and debilitating condition with substantial\nsocietal and personal costs. Traditional diagnostic and treatment approaches,\nsuch as self-reported questionnaires and psychotherapy sessions, often impose\nsignificant burdens on both patients and clinicians, limiting accessibility and\nefficiency. Recent advances in Artificial Intelligence (AI), particularly in\nNatural Language Processing and multimodal techniques, hold great potential for\nrecognizing and addressing conditions such as depression, anxiety, bipolar\ndisorder, schizophrenia, and post-traumatic stress disorder. However, privacy\nconcerns, including the risk of sensitive data leakage from datasets and\ntrained models, remain a critical barrier to deploying these AI systems in\nreal-world clinical settings. These challenges are amplified in multimodal\nmethods, where personal identifiers such as voice and facial data can be\nmisused. This paper presents a critical and comprehensive study of the privacy\nchallenges associated with developing and deploying AI models for mental\nhealth. We further prescribe potential solutions, including data anonymization,\nsynthetic data generation, and privacy-preserving model training, to strengthen\nprivacy safeguards in practical applications. Additionally, we discuss\nevaluation frameworks to assess the privacy-utility trade-offs in these\napproaches. By addressing these challenges, our work aims to advance the\ndevelopment of reliable, privacy-aware AI tools to support clinical\ndecision-making and improve mental health outcomes.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.00451v1",
    "published_date": "2025-02-01 15:10:02 UTC",
    "updated_date": "2025-02-01 15:10:02 UTC"
  },
  {
    "arxiv_id": "2502.10417v1",
    "title": "Evolutionary Power-Aware Routing in VANETs using Monte-Carlo Simulation",
    "authors": [
      "J. Toutouh",
      "S. Nesmachnow",
      "E. Alba"
    ],
    "abstract": "This work addresses the reduction of power consumption of the AODV routing\nprotocol in vehicular networks as an optimization problem. Nowadays, network\ndesigners focus on energy-aware communication protocols, specially to deploy\nwireless networks. Here, we introduce an automatic method to search for\nenergy-efficient AODV configurations by using an evolutionary algorithm and\nparallel Monte-Carlo simulations to improve the accuracy of the evaluation of\ntentative solutions. The experimental results demonstrate that significant\npower consumption improvements over the standard configuration can be attained,\nwith no noteworthy loss in the quality of service.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.NE",
    "comment": "Accepted and presented in 2012 International Conference on High\n  Performance Computing & Simulation (HPCS), Madrid, Spain, 2012",
    "pdf_url": "http://arxiv.org/pdf/2502.10417v1",
    "published_date": "2025-02-01 14:29:31 UTC",
    "updated_date": "2025-02-01 14:29:31 UTC"
  },
  {
    "arxiv_id": "2502.00443v2",
    "title": "Model-Free Predictive Control: Introductory Algebraic Calculations, and a Comparison with HEOL and ANNs",
    "authors": [
      "CÃ©dric Join",
      "Emmanuel Delaleau",
      "Michel Fliess"
    ],
    "abstract": "Model predictive control (MPC) is a popular control engineering practice, but\nrequires a sound knowledge of the model. Model-free predictive control (MFPC),\na burning issue today, also related to reinforcement learning (RL) in AI, is\nreformulated here via a linear differential equation with constant\ncoefficients, thanks to a new perspective on optimal control combined with\nrecent advances in the field of model-free control (MFC). It is replacing\nDynamic Programming, the Hamilton-Jacobi-Bellman equation, and Pontryagin's\nMaximum Principle. The computing burden is low. The implementation is\nstraightforward. Two nonlinear examples, a chemical reactor and a two tank\nsystem, are illustrating our approach. A comparison with the HEOL setting,\nwhere some expertise of the process model is needed, shows only a slight\nsuperiority of the later. A recent identification of the two tank system via a\ncomplex ANN architecture might indicate that a full modeling and the\ncorresponding machine learning mechanism are not always necessary neither in\ncontrol, nor, more generally, in AI.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY",
      "49J99",
      "I.2.8"
    ],
    "primary_category": "eess.SY",
    "comment": "Joint IFAC Conference: SSSC, TDS, COSY -- Gif-sur-Vette, France, 30\n  June-2 July 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.00443v2",
    "published_date": "2025-02-01 14:23:34 UTC",
    "updated_date": "2025-04-22 07:35:01 UTC"
  },
  {
    "arxiv_id": "2502.00434v1",
    "title": "Compilation and Fast Model Counting beyond CNF",
    "authors": [
      "Alexis de Colnet",
      "Stefan Szeider",
      "Tianwei Zhang"
    ],
    "abstract": "Circuits in deterministic decomposable negation normal form (d-DNNF) are\nrepresentations of Boolean functions that enable linear-time model counting.\nThis paper strengthens our theoretical knowledge of what classes of functions\ncan be efficiently transformed, or compiled, into d-DNNF. Our main contribution\nis the fixed-parameter tractable (FPT) compilation of conjunctions of specific\nconstraints parameterized by incidence treewidth. This subsumes the known\nresult for CNF. The constraints in question are all functions representable by\nconstant-width ordered binary decision diagrams (OBDDs) for all variable\norderings. For instance, this includes parity constraints and cardinality\nconstraints with constant threshold. The running time of the FPT compilation is\nsingly exponential in the incidence treewidth but hides large constants in the\nexponent. To balance that, we give a more efficient FPT algorithm for model\ncounting that applies to a sub-family of the constraints and does not require\ncompilation.",
    "categories": [
      "cs.CC",
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.CC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.00434v1",
    "published_date": "2025-02-01 14:00:04 UTC",
    "updated_date": "2025-02-01 14:00:04 UTC"
  },
  {
    "arxiv_id": "2502.00425v1",
    "title": "MQuant: Unleashing the Inference Potential of Multimodal Large Language Models via Full Static Quantization",
    "authors": [
      "JiangYong Yu",
      "Sifan Zhou",
      "Dawei Yang",
      "Shuo Wang",
      "Shuoyu Li",
      "Xing Hu",
      "Chen Xu",
      "Zukang Xu",
      "Changyong Shu",
      "Zhihang Yuan"
    ],
    "abstract": "Multimodal large language models (MLLMs) have garnered widespread attention\ndue to their ability to understand multimodal input. However, their large\nparameter sizes and substantial computational demands severely hinder their\npractical deployment and application.While quantization is an effective way to\nreduce model size and inference latency, its application to MLLMs remains\nunderexplored. In this paper, we propose MQuant, a post-training quantization\n(PTQ) framework designed to tackle the unique challenges of multimodal large\nlanguage models (MLLMs). Conventional quantization often struggles with MLLMs\nbecause of (a) high inference latency from large visual token counts, (b)\ndistributional disparities between visual and textual tokens, and (c) extreme\noutliers introduced by Hadamard-based transformations. To address these issues,\nMQuant introduces: Modality-Specific Static Quantization (MSQ), assigning\ndistinct static scales for visual vs. textual tokens; Attention-Invariant\nFlexible Switching (AIFS), reordering tokens to preserve casual attention while\neliminating expensive token-wise scale computations; Rotation Magnitude\nSuppression (RMS), mitigating weight outliers arising from online Hadamard\nrotations. On five mainstream MLLMs (including Qwen-VL, MiniCPM-V, CogVLM2),\nMQuant under W4A8 achieves near-floating-point accuracy (<1% degradation) while\nreducing inference latency by up to 30%, significantly outperforming existing\nPTQ baselines. Our MQuant effectively bridges the gap for efficient and\naccurate MLLMs inference in resource-constrained devices. Code will be\nreleased.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "First quantization solution for Multimodal large language models\n  applicable to 5 mainstream MLLMs",
    "pdf_url": "http://arxiv.org/pdf/2502.00425v1",
    "published_date": "2025-02-01 13:08:02 UTC",
    "updated_date": "2025-02-01 13:08:02 UTC"
  },
  {
    "arxiv_id": "2502.00415v1",
    "title": "MarketSenseAI 2.0: Enhancing Stock Analysis through LLM Agents",
    "authors": [
      "George Fatouros",
      "Kostas Metaxas",
      "John Soldatos",
      "Manos Karathanassis"
    ],
    "abstract": "MarketSenseAI is a novel framework for holistic stock analysis which\nleverages Large Language Models (LLMs) to process financial news, historical\nprices, company fundamentals and the macroeconomic environment to support\ndecision making in stock analysis and selection. In this paper, we present the\nlatest advancements on MarketSenseAI, driven by rapid technological expansion\nin LLMs. Through a novel architecture combining Retrieval-Augmented Generation\nand LLM agents, the framework processes SEC filings and earnings calls, while\nenriching macroeconomic analysis through systematic processing of diverse\ninstitutional reports. We demonstrate a significant improvement in fundamental\nanalysis accuracy over the previous version. Empirical evaluation on S\\&P 100\nstocks over two years (2023-2024) shows MarketSenseAI achieving cumulative\nreturns of 125.9% compared to the index return of 73.5%, while maintaining\ncomparable risk profiles. Further validation on S\\&P 500 stocks during 2024\ndemonstrates the framework's scalability, delivering a 33.8% higher Sortino\nratio than the market. This work marks a significant advancement in applying\nLLM technology to financial analysis, offering insights into the robustness of\nLLM-driven investment strategies.",
    "categories": [
      "q-fin.CP",
      "cs.AI",
      "cs.CL",
      "cs.MA",
      "q-fin.PM",
      "68T07, 68T50, 91G10, 91G15",
      "I.2.1; I.2.7; J.4"
    ],
    "primary_category": "q-fin.CP",
    "comment": "25 pages, 7 figures, Under review at Financial Innovation (FIN)",
    "pdf_url": "http://arxiv.org/pdf/2502.00415v1",
    "published_date": "2025-02-01 12:33:23 UTC",
    "updated_date": "2025-02-01 12:33:23 UTC"
  },
  {
    "arxiv_id": "2502.00409v2",
    "title": "Doing More with Less -- Implementing Routing Strategies in Large Language Model-Based Systems: An Extended Survey",
    "authors": [
      "Clovis Varangot-Reille",
      "Christophe Bouvard",
      "Antoine Gourru",
      "Mathieu Ciancone",
      "Marion Schaeffer",
      "FranÃ§ois Jacquenet"
    ],
    "abstract": "Large Language Models (LLM)-based systems, i.e. interconnected elements that\ninclude an LLM as a central component (e.g., conversational agents), are\ntypically monolithic static architectures that rely on a single LLM for all\nuser queries. However, they often require different preprocessing strategies,\nlevels of reasoning, or knowledge. Generalist LLMs (e.g. GPT-4) trained on very\nlarge multi-topic corpora can perform well in a variety of tasks. They require\nsignificant financial, energy, and hardware resources that may not be justified\nfor basic tasks. This implies potentially investing in unnecessary costs for a\ngiven query. To overcome this problem, a routing mechanism routes user queries\nto the most suitable components, such as smaller LLMs or experts in specific\ntopics. This approach may improve response quality while minimising costs.\nRouting can be expanded to other components of the conversational agent\narchitecture, such as the selection of optimal embedding strategies. This paper\nexplores key considerations for integrating routing into LLM-based systems,\nfocusing on resource management, cost definition, and strategy selection. Our\nmain contributions include a formalisation of the problem, a novel taxonomy of\nexisting approaches emphasising relevance and resource efficiency, and a\ncomparative analysis of these strategies in relation to industry practices.\nFinally, we identify critical challenges and directions for future research.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.00409v2",
    "published_date": "2025-02-01 12:08:38 UTC",
    "updated_date": "2025-02-04 09:12:03 UTC"
  },
  {
    "arxiv_id": "2502.00407v1",
    "title": "Causal Abstraction Learning based on the Semantic Embedding Principle",
    "authors": [
      "Gabriele D'Acunto",
      "Fabio Massimo Zennaro",
      "Yorgos Felekis",
      "Paolo Di Lorenzo"
    ],
    "abstract": "Structural causal models (SCMs) allow us to investigate complex systems at\nmultiple levels of resolution. The causal abstraction (CA) framework formalizes\nthe mapping between high- and low-level SCMs. We address CA learning in a\nchallenging and realistic setting, where SCMs are inaccessible, interventional\ndata is unavailable, and sample data is misaligned. A key principle of our\nframework is $\\textit{semantic embedding}$, formalized as the high-level\ndistribution lying on a subspace of the low-level one. This principle naturally\nlinks linear CA to the geometry of the $\\textit{Stiefel manifold}$. We present\na category-theoretic approach to SCMs that enables the learning of a CA by\nfinding a morphism between the low- and high-level probability measures,\nadhering to the semantic embedding principle. Consequently, we formulate a\ngeneral CA learning problem. As an application, we solve the latter problem for\nlinear CA; considering Gaussian measures and the Kullback-Leibler divergence as\nan objective. Given the nonconvexity of the learning task, we develop three\nalgorithms building upon existing paradigms for Riemannian optimization. We\ndemonstrate that the proposed methods succeed on both synthetic and real-world\nbrain data with different degrees of prior information about the structure of\nCA.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.00407v1",
    "published_date": "2025-02-01 11:54:44 UTC",
    "updated_date": "2025-02-01 11:54:44 UTC"
  },
  {
    "arxiv_id": "2502.00406v1",
    "title": "ALU: Agentic LLM Unlearning",
    "authors": [
      "Debdeep Sanyal",
      "Murari Mandal"
    ],
    "abstract": "Information removal or suppression in large language models (LLMs) is a\ndesired functionality, useful in AI regulation, legal compliance, safety, and\nprivacy. LLM unlearning methods aim to remove information on demand from LLMs.\nCurrent LLM unlearning methods struggle to balance the unlearning efficacy and\nutility due to the competing nature of these objectives. Keeping the unlearning\nprocess computationally feasible without assuming access to the model weights\nis an overlooked area. We present the first agentic LLM unlearning (ALU)\nmethod, a multi-agent, retrain-free, model-agnostic approach to LLM unlearning\nthat achieves effective unlearning while preserving the utility. Our ALU\nframework unlearns by involving multiple LLM agents, each designed for a\nspecific step in the unlearning process, without the need to update model\nweights for any of the agents in the framework. Users can easily request any\nset of unlearning instances in any sequence, and ALU seamlessly adapts in real\ntime. This is facilitated without requiring any changes in the underlying LLM\nmodel. Through extensive experiments on established benchmarks (TOFU, WMDP,\nWPU) and jailbreaking techniques (many shot, target masking, other languages),\nwe demonstrate that ALU consistently stands out as the most robust LLM\nunlearning framework among current state-of-the-art methods while incurring a\nlow constant-time cost. We further highlight ALU's superior performance\ncompared to existing methods when evaluated at scale. Specifically, ALU is\nassessed on up to 1000 unlearning targets, exceeding the evaluation scope of\nall previously proposed LLM unlearning methods.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.00406v1",
    "published_date": "2025-02-01 11:45:44 UTC",
    "updated_date": "2025-02-01 11:45:44 UTC"
  },
  {
    "arxiv_id": "2502.00401v1",
    "title": "Spectro-Riemannian Graph Neural Networks",
    "authors": [
      "Karish Grover",
      "Haiyang Yu",
      "Xiang Song",
      "Qi Zhu",
      "Han Xie",
      "Vassilis N. Ioannidis",
      "Christos Faloutsos"
    ],
    "abstract": "Can integrating spectral and curvature signals unlock new potential in graph\nrepresentation learning? Non-Euclidean geometries, particularly Riemannian\nmanifolds such as hyperbolic (negative curvature) and spherical (positive\ncurvature), offer powerful inductive biases for embedding complex graph\nstructures like scale-free, hierarchical, and cyclic patterns. Meanwhile,\nspectral filtering excels at processing signal variations across graphs, making\nit effective in homophilic and heterophilic settings. Leveraging both can\nsignificantly enhance the learned representations. To this end, we propose\nSpectro-Riemannian Graph Neural Networks (CUSP) - the first graph\nrepresentation learning paradigm that unifies both CUrvature (geometric) and\nSPectral insights. CUSP is a mixed-curvature spectral GNN that learns spectral\nfilters to optimize node embeddings in products of constant-curvature manifolds\n(hyperbolic, spherical, and Euclidean). Specifically, CUSP introduces three\nnovel components: (a) Cusp Laplacian, an extension of the traditional graph\nLaplacian based on Ollivier-Ricci curvature, designed to capture the curvature\nsignals better; (b) Cusp Filtering, which employs multiple Riemannian graph\nfilters to obtain cues from various bands in the eigenspectrum; and (c) Cusp\nPooling, a hierarchical attention mechanism combined with a curvature-based\npositional encoding to assess the relative importance of differently curved\nsubstructures in our graph. Empirical evaluation across eight homophilic and\nheterophilic datasets demonstrates the superiority of CUSP in node\nclassification and link prediction tasks, with a gain of up to 5.3% over\nstate-of-the-art models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.00401v1",
    "published_date": "2025-02-01 11:31:01 UTC",
    "updated_date": "2025-02-01 11:31:01 UTC"
  },
  {
    "arxiv_id": "2502.00385v2",
    "title": "The Impact of Persona-based Political Perspectives on Hateful Content Detection",
    "authors": [
      "Stefano Civelli",
      "Pietro Bernardelle",
      "Gianluca Demartini"
    ],
    "abstract": "While pretraining language models with politically diverse content has been\nshown to improve downstream task fairness, such approaches require significant\ncomputational resources often inaccessible to many researchers and\norganizations. Recent work has established that persona-based prompting can\nintroduce political diversity in model outputs without additional training.\nHowever, it remains unclear whether such prompting strategies can achieve\nresults comparable to political pretraining for downstream tasks. We\ninvestigate this question using persona-based prompting strategies in\nmultimodal hate-speech detection tasks, specifically focusing on hate speech in\nmemes. Our analysis reveals that when mapping personas onto a political compass\nand measuring persona agreement, inherent political positioning has\nsurprisingly little correlation with classification decisions. Notably, this\nlack of correlation persists even when personas are explicitly injected with\nstronger ideological descriptors. Our findings suggest that while LLMs can\nexhibit political biases in their responses to direct political questions,\nthese biases may have less impact on practical classification tasks than\npreviously assumed. This raises important questions about the necessity of\ncomputationally expensive political pretraining for achieving fair performance\nin downstream tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Companion Proceedings of the ACM Web Conference 2025 (WWW\n  Companion'25)",
    "pdf_url": "http://arxiv.org/pdf/2502.00385v2",
    "published_date": "2025-02-01 09:53:17 UTC",
    "updated_date": "2025-02-26 03:23:41 UTC"
  },
  {
    "arxiv_id": "2502.00382v1",
    "title": "Masked Generative Nested Transformers with Decode Time Scaling",
    "authors": [
      "Sahil Goyal",
      "Debapriya Tula",
      "Gagan Jain",
      "Pradeep Shenoy",
      "Prateek Jain",
      "Sujoy Paul"
    ],
    "abstract": "Recent advances in visual generation have made significant strides in\nproducing content of exceptional quality. However, most methods suffer from a\nfundamental problem - a bottleneck of inference computational efficiency. Most\nof these algorithms involve multiple passes over a transformer model to\ngenerate tokens or denoise inputs. However, the model size is kept consistent\nthroughout all iterations, which makes it computationally expensive. In this\nwork, we aim to address this issue primarily through two key ideas - (a) not\nall parts of the generation process need equal compute, and we design a decode\ntime model scaling schedule to utilize compute effectively, and (b) we can\ncache and reuse some of the computation. Combining these two ideas leads to\nusing smaller models to process more tokens while large models process fewer\ntokens. These different-sized models do not increase the parameter size, as\nthey share parameters. We rigorously experiment with ImageNet256$\\times$256 ,\nUCF101, and Kinetics600 to showcase the efficacy of the proposed method for\nimage/video generation and frame prediction. Our experiments show that with\nalmost $3\\times$ less compute than baseline, our model obtains competitive\nperformance.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.00382v1",
    "published_date": "2025-02-01 09:41:01 UTC",
    "updated_date": "2025-02-01 09:41:01 UTC"
  },
  {
    "arxiv_id": "2502.00379v4",
    "title": "Latent Action Learning Requires Supervision in the Presence of Distractors",
    "authors": [
      "Alexander Nikulin",
      "Ilya Zisman",
      "Denis Tarasov",
      "Nikita Lyubaykin",
      "Andrei Polubarov",
      "Igor Kiselev",
      "Vladislav Kurenkov"
    ],
    "abstract": "Recently, latent action learning, pioneered by Latent Action Policies (LAPO),\nhave shown remarkable pre-training efficiency on observation-only data,\noffering potential for leveraging vast amounts of video available on the web\nfor embodied AI. However, prior work has focused on distractor-free data, where\nchanges between observations are primarily explained by ground-truth actions.\nUnfortunately, real-world videos contain action-correlated distractors that may\nhinder latent action learning. Using Distracting Control Suite (DCS) we\nempirically investigate the effect of distractors on latent action learning and\ndemonstrate that LAPO struggle in such scenario. We propose LAOM, a simple LAPO\nmodification that improves the quality of latent actions by 8x, as measured by\nlinear probing. Importantly, we show that providing supervision with\nground-truth actions, as few as 2.5% of the full dataset, during latent action\nlearning improves downstream performance by 4.2x on average. Our findings\nsuggest that integrating supervision during Latent Action Models (LAM) training\nis critical in the presence of distractors, challenging the conventional\npipeline of first learning LAM and only then decoding from latent to\nground-truth actions.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "ICML 2025, Poster, Source code: https://github.com/dunnolab/laom",
    "pdf_url": "http://arxiv.org/pdf/2502.00379v4",
    "published_date": "2025-02-01 09:35:51 UTC",
    "updated_date": "2025-05-20 13:10:54 UTC"
  },
  {
    "arxiv_id": "2502.00377v1",
    "title": "When End-to-End is Overkill: Rethinking Cascaded Speech-to-Text Translation",
    "authors": [
      "Anna Min",
      "Chenxu Hu",
      "Yi Ren",
      "Hang Zhao"
    ],
    "abstract": "Though end-to-end speech-to-text translation has been a great success, we\nargue that the cascaded speech-to-text translation model still has its place,\nwhich is usually criticized for the error propagation between automatic speech\nrecognition (ASR) and machine translation (MT) models. In this paper, we\nexplore the benefits of incorporating multiple candidates from ASR and\nself-supervised speech features into MT. Our analysis reveals that the primary\ncause of cascading errors stems from the increased divergence between similar\nsamples in the speech domain when mapped to the text domain. By including\nmultiple candidates and self-supervised speech features, our approach allows\nthe machine translation model to choose the right words and ensure precise\ntranslation using various speech samples. This strategy minimizes error spread\nand takes advantage of large ASR and MT datasets, along with pre-trained ASR/MT\nmodels, while addressing associated issues.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.MM",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.00377v1",
    "published_date": "2025-02-01 09:29:21 UTC",
    "updated_date": "2025-02-01 09:29:21 UTC"
  },
  {
    "arxiv_id": "2502.00365v1",
    "title": "What should an AI assessor optimise for?",
    "authors": [
      "Daniel Romero-Alvarado",
      "Fernando MartÃ­nez-Plumed",
      "JosÃ© HernÃ¡ndez-Orallo"
    ],
    "abstract": "An AI assessor is an external, ideally indepen-dent system that predicts an\nindicator, e.g., a loss value, of another AI system. Assessors can lever-age\ninformation from the test results of many other AI systems and have the\nflexibility of be-ing trained on any loss function or scoring rule: from\nsquared error to toxicity metrics. Here we address the question: is it always\noptimal to train the assessor for the target metric? Or could it be better to\ntrain for a different metric and then map predictions back to the target\nmetric? Us-ing twenty regression and classification problems with tabular data,\nwe experimentally explore this question for, respectively, regression losses\nand classification scores with monotonic and non-monotonic mappings and find\nthat, contrary to intuition, optimising for more informative met-rics is not\ngenerally better. Surprisingly, some monotonic transformations are promising.\nFor example, the logistic loss is useful for minimis-ing absolute or quadratic\nerrors in regression, and the logarithmic score helps maximise quadratic or\nspherical scores in classification.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.00365v1",
    "published_date": "2025-02-01 08:41:57 UTC",
    "updated_date": "2025-02-01 08:41:57 UTC"
  },
  {
    "arxiv_id": "2502.00358v2",
    "title": "Do Audio-Visual Segmentation Models Truly Segment Sounding Objects?",
    "authors": [
      "Jia Li",
      "Wenjie Zhao",
      "Ziru Huang",
      "Yunhui Guo",
      "Yapeng Tian"
    ],
    "abstract": "Unlike traditional visual segmentation, audio-visual segmentation (AVS)\nrequires the model not only to identify and segment objects but also to\ndetermine whether they are sound sources. Recent AVS approaches, leveraging\ntransformer architectures and powerful foundation models like SAM, have\nachieved impressive performance on standard benchmarks. Yet, an important\nquestion remains: Do these models genuinely integrate audio-visual cues to\nsegment sounding objects? In this paper, we systematically investigate this\nissue in the context of robust AVS. Our study reveals a fundamental bias in\ncurrent methods: they tend to generate segmentation masks based predominantly\non visual salience, irrespective of the audio context. This bias results in\nunreliable predictions when sounds are absent or irrelevant. To address this\nchallenge, we introduce AVSBench-Robust, a comprehensive benchmark\nincorporating diverse negative audio scenarios including silence, ambient\nnoise, and off-screen sounds. We also propose a simple yet effective approach\ncombining balanced training with negative samples and classifier-guided\nsimilarity learning. Our extensive experiments show that state-of-theart AVS\nmethods consistently fail under negative audio conditions, demonstrating the\nprevalence of visual bias. In contrast, our approach achieves remarkable\nimprovements in both standard metrics and robustness measures, maintaining\nnear-perfect false positive rates while preserving highquality segmentation\nperformance.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.00358v2",
    "published_date": "2025-02-01 07:40:29 UTC",
    "updated_date": "2025-02-20 22:37:12 UTC"
  },
  {
    "arxiv_id": "2502.00354v1",
    "title": "PM-MOE: Mixture of Experts on Private Model Parameters for Personalized Federated Learning",
    "authors": [
      "Yu Feng",
      "Yangli-ao Geng",
      "Yifan Zhu",
      "Zongfu Han",
      "Xie Yu",
      "Kaiwen Xue",
      "Haoran Luo",
      "Mengyang Sun",
      "Guangwei Zhang",
      "Meina Song"
    ],
    "abstract": "Federated learning (FL) has gained widespread attention for its\nprivacy-preserving and collaborative learning capabilities. Due to significant\nstatistical heterogeneity, traditional FL struggles to generalize a shared\nmodel across diverse data domains. Personalized federated learning addresses\nthis issue by dividing the model into a globally shared part and a locally\nprivate part, with the local model correcting representation biases introduced\nby the global model. Nevertheless, locally converged parameters more accurately\ncapture domain-specific knowledge, and current methods overlook the potential\nbenefits of these parameters. To address these limitations, we propose PM-MoE\narchitecture. This architecture integrates a mixture of personalized modules\nand an energy-based personalized modules denoising, enabling each client to\nselect beneficial personalized parameters from other clients. We applied the\nPM-MoE architecture to nine recent model-split-based personalized federated\nlearning algorithms, achieving performance improvements with minimal additional\ntraining. Extensive experiments on six widely adopted datasets and two\nheterogeneity settings validate the effectiveness of our approach. The source\ncode is available at \\url{https://github.com/dannis97500/PM-MOE}.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.00354v1",
    "published_date": "2025-02-01 07:20:21 UTC",
    "updated_date": "2025-02-01 07:20:21 UTC"
  },
  {
    "arxiv_id": "2502.00352v1",
    "title": "A Differentiated Reward Method for Reinforcement Learning based Multi-Vehicle Cooperative Decision-Making Algorithms",
    "authors": [
      "Ye Han",
      "Lijun Zhang",
      "Dejian Meng"
    ],
    "abstract": "Reinforcement learning (RL) shows great potential for optimizing\nmulti-vehicle cooperative driving strategies through the state-action-reward\nfeedback loop, but it still faces challenges such as low sample efficiency.\nThis paper proposes a differentiated reward method based on steady-state\ntransition systems, which incorporates state transition gradient information\ninto the reward design by analyzing traffic flow characteristics, aiming to\noptimize action selection and policy learning in multi-vehicle cooperative\ndecision-making. The performance of the proposed method is validated in RL\nalgorithms such as MAPPO, MADQN, and QMIX under varying autonomous vehicle\npenetration. The results show that the differentiated reward method\nsignificantly accelerates training convergence and outperforms centering reward\nand others in terms of traffic efficiency, safety, and action rationality.\nAdditionally, the method demonstrates strong scalability and environmental\nadaptability, providing a novel approach for multi-agent cooperative\ndecision-making in complex traffic scenarios.",
    "categories": [
      "cs.AI",
      "cs.MA",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages, 3 figures, submitted to IEEE IV 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.00352v1",
    "published_date": "2025-02-01 07:16:15 UTC",
    "updated_date": "2025-02-01 07:16:15 UTC"
  },
  {
    "arxiv_id": "2502.00351v2",
    "title": "Multi-Order Hyperbolic Graph Convolution and Aggregated Attention for Social Event Detection",
    "authors": [
      "Yao Liu",
      "Zhilan Liu",
      "Tien Ping Tan",
      "Yuxin Li"
    ],
    "abstract": "Social event detection (SED) is a task focused on identifying specific\nreal-world events and has broad applications across various domains. It is\nintegral to many mobile applications with social features, including major\nplatforms like Twitter, Weibo, and Facebook. By enabling the analysis of social\nevents, SED provides valuable insights for businesses to understand consumer\npreferences and supports public services in handling emergencies and disaster\nmanagement. Due to the hierarchical structure of event detection data,\ntraditional approaches in Euclidean space often fall short in capturing the\ncomplexity of such relationships. While existing methods in both Euclidean and\nhyperbolic spaces have shown promising results, they tend to overlook\nmulti-order relationships between events. To address these limitations, this\npaper introduces a novel framework, Multi-Order Hyperbolic Graph Convolution\nwith Aggregated Attention (MOHGCAA), designed to enhance the performance of\nSED. Experimental results demonstrate significant improvements under both\nsupervised and unsupervised settings. To further validate the effectiveness and\nrobustness of the proposed framework, we conducted extensive evaluations across\nmultiple datasets, confirming its superiority in tackling common challenges in\nsocial event detection.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.00351v2",
    "published_date": "2025-02-01 07:15:40 UTC",
    "updated_date": "2025-02-10 10:08:51 UTC"
  },
  {
    "arxiv_id": "2502.00350v1",
    "title": "OrcaLoca: An LLM Agent Framework for Software Issue Localization",
    "authors": [
      "Zhongming Yu",
      "Hejia Zhang",
      "Yujie Zhao",
      "Hanxian Huang",
      "Matrix Yao",
      "Ke Ding",
      "Jishen Zhao"
    ],
    "abstract": "Recent developments in Large Language Model (LLM) agents are revolutionizing\nAutonomous Software Engineering (ASE), enabling automated coding, problem\nfixes, and feature improvements. However, localization -- precisely identifying\nsoftware problems by navigating to relevant code sections -- remains a\nsignificant challenge. Current approaches often yield suboptimal results due to\na lack of effective integration between LLM agents and precise code search\nmechanisms. This paper introduces OrcaLoca, an LLM agent framework that\nimproves accuracy for software issue localization by integrating priority-based\nscheduling for LLM-guided action, action decomposition with relevance scoring,\nand distance-aware context pruning. Experimental results demonstrate that\nOrcaLoca becomes the new open-source state-of-the-art (SOTA) in function match\nrate (65.33%) on SWE-bench Lite. It also improves the final resolved rate of an\nopen-source framework by 6.33 percentage points through its patch generation\nintegration.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.00350v1",
    "published_date": "2025-02-01 07:15:03 UTC",
    "updated_date": "2025-02-01 07:15:03 UTC"
  },
  {
    "arxiv_id": "2502.00346v1",
    "title": "Actor Critic with Experience Replay-based automatic treatment planning for prostate cancer intensity modulated radiotherapy",
    "authors": [
      "Md Mainul Abrar",
      "Parvat Sapkota",
      "Damon Sprouts",
      "Xun Jia",
      "Yujie Chi"
    ],
    "abstract": "Background: Real-time treatment planning in IMRT is challenging due to\ncomplex beam interactions. AI has improved automation, but existing models\nrequire large, high-quality datasets and lack universal applicability. Deep\nreinforcement learning (DRL) offers a promising alternative by mimicking human\ntrial-and-error planning.\n  Purpose: Develop a stochastic policy-based DRL agent for automatic treatment\nplanning with efficient training, broad applicability, and robustness against\nadversarial attacks using Fast Gradient Sign Method (FGSM).\n  Methods: Using the Actor-Critic with Experience Replay (ACER) architecture,\nthe agent tunes treatment planning parameters (TPPs) in inverse planning.\nTraining is based on prostate cancer IMRT cases, using dose-volume histograms\n(DVHs) as input. The model is trained on a single patient case, validated on\ntwo independent cases, and tested on 300+ plans across three datasets. Plan\nquality is assessed using ProKnow scores, and robustness is tested against\nadversarial attacks.\n  Results: Despite training on a single case, the model generalizes well.\nBefore ACER-based planning, the mean plan score was 6.20$\\pm$1.84; after,\n93.09% of cases achieved a perfect score of 9, with a mean of 8.93$\\pm$0.27.\nThe agent effectively prioritizes optimal TPP tuning and remains robust against\nadversarial attacks.\n  Conclusions: The ACER-based DRL agent enables efficient, high-quality\ntreatment planning in prostate cancer IMRT, demonstrating strong\ngeneralizability and robustness.",
    "categories": [
      "physics.med-ph",
      "cs.AI",
      "cs.LG",
      "92C50 (Primary) 68T07 (Secondary)",
      "I.2.1; J.2; J.3"
    ],
    "primary_category": "physics.med-ph",
    "comment": "27 Pages, 8 Figures, 4 Tables",
    "pdf_url": "http://arxiv.org/pdf/2502.00346v1",
    "published_date": "2025-02-01 07:09:40 UTC",
    "updated_date": "2025-02-01 07:09:40 UTC"
  },
  {
    "arxiv_id": "2502.00345v1",
    "title": "The Composite Task Challenge for Cooperative Multi-Agent Reinforcement Learning",
    "authors": [
      "Yurui Li",
      "Yuxuan Chen",
      "Li Zhang",
      "Shijian Li",
      "Gang Pan"
    ],
    "abstract": "The significant role of division of labor (DOL) in promoting cooperation is\nwidely recognized in real-world applications.Many cooperative multi-agent\nreinforcement learning (MARL) methods have incorporated the concept of DOL to\nimprove cooperation among agents.However, the tasks used in existing testbeds\ntypically correspond to tasks where DOL is often not a necessary feature for\nachieving optimal policies.Additionally, the full utilize of DOL concept in\nMARL methods remains unrealized due to the absence of appropriate tasks.To\nenhance the generality and applicability of MARL methods in real-world\nscenarios, there is a necessary to develop tasks that demand multi-agent DOL\nand cooperation.In this paper, we propose a series of tasks designed to meet\nthese requirements, drawing on real-world rules as the guidance for their\ndesign.We guarantee that DOL and cooperation are necessary condition for\ncompleting tasks and introduce three factors to expand the diversity of\nproposed tasks to cover more realistic situations.We evaluate 10 cooperative\nMARL methods on the proposed tasks.The results indicate that all baselines\nperform poorly on these tasks.To further validate the solvability of these\ntasks, we also propose simplified variants of proposed tasks.Experimental\nresults show that baselines are able to handle these simplified variants,\nproviding evidence of the solvability of the proposed tasks.The source files is\navailable at https://github.com/Yurui-Li/CTC.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.00345v1",
    "published_date": "2025-02-01 07:07:08 UTC",
    "updated_date": "2025-02-01 07:07:08 UTC"
  },
  {
    "arxiv_id": "2503.17365v2",
    "title": "How Effective Is Constitutional AI in Small LLMs? A Study on DeepSeek-R1 and Its Peers",
    "authors": [
      "Antonio-Gabriel ChacÃ³n Menke",
      "Phan Xuan Tan"
    ],
    "abstract": "Recent incidents highlight safety risks in Large Language Models (LLMs),\nmotivating research into alignment methods like Constitutional AI (CAI). This\npaper explores CAI's self-critique mechanism on small, uncensored 7-9B\nparameter models: DeepSeek-R1-8B, Gemma-2-9B, Llama 3.1-8B, and Qwen2.5-7B. We\nshow that while Llama-based models exhibited significant harm reduction through\nself-critique, other architectures demonstrated less improvement in harm\ndetection after abliteration. These results suggest CAI's effectiveness may\nvary depending on model architecture and reasoning capabilities.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.17365v2",
    "published_date": "2025-02-01 06:58:27 UTC",
    "updated_date": "2025-04-11 09:18:53 UTC"
  },
  {
    "arxiv_id": "2502.00334v2",
    "title": "UGPhysics: A Comprehensive Benchmark for Undergraduate Physics Reasoning with Large Language Models",
    "authors": [
      "Xin Xu",
      "Qiyun Xu",
      "Tong Xiao",
      "Tianhao Chen",
      "Yuchen Yan",
      "Jiaxin Zhang",
      "Shizhe Diao",
      "Can Yang",
      "Yang Wang"
    ],
    "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities in\nsolving complex reasoning tasks, particularly in mathematics. However, the\ndomain of physics reasoning presents unique challenges that have received\nsignificantly less attention. Existing benchmarks often fall short in\nevaluating LLMs' abilities on the breadth and depth of undergraduate-level\nphysics, underscoring the need for a comprehensive evaluation. To fill this\ngap, we introduce UGPhysics, a large-scale and comprehensive benchmark\nspecifically designed to evaluate UnderGraduate-level Physics (UGPhysics)\nreasoning with LLMs. UGPhysics includes 5,520 undergraduate-level physics\nproblems in both English and Chinese, covering 13 subjects with seven different\nanswer types and four distinct physics reasoning skills, all rigorously\nscreened for data leakage. Additionally, we develop a Model-Assistant\nRule-based Judgment (MARJ) pipeline specifically tailored for assessing answer\ncorrectness of physics problems, ensuring accurate evaluation. Our evaluation\nof 31 leading LLMs shows that the highest overall accuracy, 49.8% (achieved by\nOpenAI-o1-mini), emphasizes the necessity for models with stronger physics\nreasoning skills, beyond math abilities. We hope UGPhysics, along with MARJ,\nwill drive future advancements in AI for physics reasoning. Codes and data are\navailable at https://github.com/YangLabHKUST/UGPhysics .",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.00334v2",
    "published_date": "2025-02-01 06:42:02 UTC",
    "updated_date": "2025-02-05 11:36:53 UTC"
  },
  {
    "arxiv_id": "2502.06802v1",
    "title": "Solving the Content Gap in Roblox Game Recommendations: LLM-Based Profile Generation and Reranking",
    "authors": [
      "Chen Wang",
      "Xiaokai Wei",
      "Yexi Jiang",
      "Frank Ong",
      "Kevin Gao",
      "Xiao Yu",
      "Zheng Hui",
      "Se-eun Yoon",
      "Philip Yu",
      "Michelle Gong"
    ],
    "abstract": "With the vast and dynamic user-generated content on Roblox, creating\neffective game recommendations requires a deep understanding of game content.\nTraditional recommendation models struggle with the inconsistent and sparse\nnature of game text features such as titles and descriptions. Recent\nadvancements in large language models (LLMs) offer opportunities to enhance\nrecommendation systems by analyzing in-game text data. This paper addresses two\nchallenges: generating high-quality, structured text features for games without\nextensive human annotation, and validating these features to ensure they\nimprove recommendation relevance. We propose an approach that extracts in-game\ntext and uses LLMs to infer attributes such as genre and gameplay objectives\nfrom raw player interactions. Additionally, we introduce an LLM-based\nre-ranking mechanism to assess the effectiveness of the generated text\nfeatures, enhancing personalization and user satisfaction. Beyond\nrecommendations, our approach supports applications such as user\nengagement-based integrity detection, already deployed in production. This\nscalable framework demonstrates the potential of in-game text understanding to\nimprove recommendation quality on Roblox and adapt recommendations to its\nunique, user-generated ecosystem.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.06802v1",
    "published_date": "2025-02-01 06:30:56 UTC",
    "updated_date": "2025-02-01 06:30:56 UTC"
  },
  {
    "arxiv_id": "2502.00330v1",
    "title": "From Few to Many: Self-Improving Many-Shot Reasoners Through Iterative Optimization and Generation",
    "authors": [
      "Xingchen Wan",
      "Han Zhou",
      "Ruoxi Sun",
      "Hootan Nakhost",
      "Ke Jiang",
      "Sercan Ã. ArÄ±k"
    ],
    "abstract": "Recent advances in long-context large language models (LLMs) have led to the\nemerging paradigm of many-shot in-context learning (ICL), where it is observed\nthat scaling many more demonstrating examples beyond the conventional few-shot\nsetup in the context can lead to performance benefits. However, despite its\npromise, it is unclear what aspects dominate the benefits and whether simply\nscaling to more examples is the most effective way of improving many-shot ICL.\nIn this work, we first provide an analysis of the factors driving many-shot\nICL, and we find that 1) many-shot performance can still be attributed to often\na few disproportionately influential examples and 2) identifying such\ninfluential examples (\"optimize\") and using them as demonstrations to\nregenerate new examples (\"generate\") can lead to further improvements. Inspired\nby the findings, we propose BRIDGE, an algorithm that alternates between the\noptimize step with Bayesian optimization to discover the influential sets of\nexamples and the generate step to reuse this set to expand the reasoning paths\nof the examples back to the many-shot regime automatically. On Gemini, Claude,\nand Mistral LLMs of different sizes, we show that BRIDGE to significant\nimprovements across a diverse set of tasks, including symbolic reasoning,\nnumerical reasoning, and code generation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Expanded version of the ICLR 2025 paper",
    "pdf_url": "http://arxiv.org/pdf/2502.00330v1",
    "published_date": "2025-02-01 06:23:24 UTC",
    "updated_date": "2025-02-01 06:23:24 UTC"
  },
  {
    "arxiv_id": "2502.00329v1",
    "title": "CoddLLM: Empowering Large Language Models for Data Analytics",
    "authors": [
      "Jiani Zhang",
      "Hengrui Zhang",
      "Rishav Chakravarti",
      "Yiqun Hu",
      "Patrick Ng",
      "Asterios Katsifodimos",
      "Huzefa Rangwala",
      "George Karypis",
      "Alon Halevy"
    ],
    "abstract": "Large Language Models (LLMs) have the potential to revolutionize data\nanalytics by simplifying tasks such as data discovery and SQL query synthesis\nthrough natural language interactions. This work serves as a pivotal first step\ntoward the development of foundation models explicitly designed for data\nanalytics applications. To propel this vision forward, we unveil a new data\nrecipe for post-training LLMs, enhancing their comprehension of data management\nand empowering them to tackle complex real-world analytics tasks. Specifically,\nour innovative approach includes a scalable synthetic data generation method\nthat enables the creation of a broad spectrum of topics centered on data\nrepresentation and manipulation. Furthermore, we introduce two new tasks that\nseamlessly bridge tables and text. We show that such tasks can enhance models'\nunderstanding of schema creation and the nuanced translation between natural\nlanguage and tabular data. Leveraging this data recipe, we post-train a new\nfoundation model, named CoddLLM, based on Mistral-NeMo-12B. To assess the\nlanguage understanding and reasoning capabilities of LLMs in the realm of data\nanalytics, we contribute AnalyticsMMLU, a benchmark containing thousands of\nmultiple-choice questions on databases, data analysis, and machine learning.\nOur focus on data discovery, has resulted in the contribution of three\ncomprehensive benchmarks that address both database and data lake scenarios.\nCoddLLM not only excels in performance but also sets a new standard, achieving\nthe highest average accuracy across eight datasets. It outperforms\nGPT-3.5-Turbo on AnalyticsMMLU, exceeding GPT-4o by 12.1% in table selection\nand showing an average improvement of 24.9% in Text-to-SQL compared to the base\nmodel.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.00329v1",
    "published_date": "2025-02-01 06:03:55 UTC",
    "updated_date": "2025-02-01 06:03:55 UTC"
  },
  {
    "arxiv_id": "2502.01662v1",
    "title": "Speculative Ensemble: Fast Large Language Model Ensemble via Speculation",
    "authors": [
      "Jiale Fu",
      "Yuchu Jiang",
      "Junkai Chen",
      "Jiaming Fan",
      "Xin Geng",
      "Xu Yang"
    ],
    "abstract": "Ensemble methods enhance Large Language Models (LLMs) by combining multiple\nmodels but suffer from high computational costs. In this paper, we introduce\nSpeculative Ensemble, a novel framework that accelerates LLM ensembles without\nsacrificing performance, inspired by Speculative Decoding-where a small\nproposal model generates tokens sequentially, and a larger target model\nverifies them in parallel. Our approach builds on two key insights: (1) the\nverification distribution can be the ensemble distribution of both the proposal\nand target models, and (2) alternating each model as the proposer and verifier\ncan further enhance efficiency. We generalize this method to ensembles with n\nmodels and theoretically prove that SE is never slower than a standard\nensemble, typically achieving faster speed. Extensive experiments demonstrate\nspeed improvements of 1.11x-2.23x over standard ensemble techniques without\ncompromising generation quality. Our code is available at\nhttps://github.com/Kamichanw/Speculative-Ensemble/",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01662v1",
    "published_date": "2025-02-01 05:22:11 UTC",
    "updated_date": "2025-02-01 05:22:11 UTC"
  },
  {
    "arxiv_id": "2502.00321v4",
    "title": "MIM: Multi-modal Content Interest Modeling Paradigm for User Behavior Modeling",
    "authors": [
      "Bencheng Yan",
      "Si Chen",
      "Shichang Jia",
      "Jianyu Liu",
      "Yueran Liu",
      "Chenghan Fu",
      "Wanxian Guan",
      "Hui Zhao",
      "Xiang Zhang",
      "Kai Zhang",
      "Wenbo Su",
      "Pengjie Wang",
      "Jian Xu",
      "Bo Zheng",
      "Baolin Liu"
    ],
    "abstract": "Click-Through Rate (CTR) prediction is a crucial task in recommendation\nsystems, online searches, and advertising platforms, where accurately capturing\nusers' real interests in content is essential for performance. However,\nexisting methods heavily rely on ID embeddings, which fail to reflect users'\ntrue preferences for content such as images and titles. This limitation becomes\nparticularly evident in cold-start and long-tail scenarios, where traditional\napproaches struggle to deliver effective results. To address these challenges,\nwe propose a novel Multi-modal Content Interest Modeling paradigm (MIM), which\nconsists of three key stages: Pre-training, Content-Interest-Aware Supervised\nFine-Tuning (C-SFT), and Content-Interest-Aware UBM (CiUBM). The pre-training\nstage adapts foundational models to domain-specific data, enabling the\nextraction of high-quality multi-modal embeddings. The C-SFT stage bridges the\nsemantic gap between content and user interests by leveraging user behavior\nsignals to guide the alignment of embeddings with user preferences. Finally,\nthe CiUBM stage integrates multi-modal embeddings and ID-based collaborative\nfiltering signals into a unified framework. Comprehensive offline experiments\nand online A/B tests conducted on the Taobao, one of the world's largest\ne-commerce platforms, demonstrated the effectiveness and efficiency of MIM\nmethod. The method has been successfully deployed online, achieving a\nsignificant increase of +14.14% in CTR and +4.12% in RPM, showcasing its\nindustrial applicability and substantial impact on platform performance. To\npromote further research, we have publicly released the code and dataset at\nhttps://pan.quark.cn/s/8fc8ec3e74f3.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.00321v4",
    "published_date": "2025-02-01 05:06:21 UTC",
    "updated_date": "2025-02-23 15:40:03 UTC"
  },
  {
    "arxiv_id": "2502.00313v1",
    "title": "Distributive Fairness in Large Language Models: Evaluating Alignment with Human Values",
    "authors": [
      "Hadi Hosseini",
      "Samarth Khanna"
    ],
    "abstract": "The growing interest in employing large language models (LLMs) for\ndecision-making in social and economic contexts has raised questions about\ntheir potential to function as agents in these domains. A significant number of\nsocietal problems involve the distribution of resources, where fairness, along\nwith economic efficiency, play a critical role in the desirability of outcomes.\nIn this paper, we examine whether LLM responses adhere to fundamental fairness\nconcepts such as equitability, envy-freeness, and Rawlsian maximin, and\ninvestigate their alignment with human preferences. We evaluate the performance\nof several LLMs, providing a comparative benchmark of their ability to reflect\nthese measures. Our results demonstrate a lack of alignment between current LLM\nresponses and human distributional preferences. Moreover, LLMs are unable to\nutilize money as a transferable resource to mitigate inequality. Nonetheless,\nwe demonstrate a stark contrast when (some) LLMs are tasked with selecting from\na predefined menu of options rather than generating one. In addition, we\nanalyze the robustness of LLM responses to variations in semantic factors (e.g.\nintentions or personas) or non-semantic prompting changes (e.g. templates or\norderings). Finally, we highlight potential strategies aimed at enhancing the\nalignment of LLM behavior with well-established fairness concepts.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.CL",
      "cs.MA"
    ],
    "primary_category": "cs.GT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.00313v1",
    "published_date": "2025-02-01 04:24:47 UTC",
    "updated_date": "2025-02-01 04:24:47 UTC"
  },
  {
    "arxiv_id": "2502.00310v1",
    "title": "SigWavNet: Learning Multiresolution Signal Wavelet Network for Speech Emotion Recognition",
    "authors": [
      "Alaa Nfissi",
      "Wassim Bouachir",
      "Nizar Bouguila",
      "Brian Mishara"
    ],
    "abstract": "In the field of human-computer interaction and psychological assessment,\nspeech emotion recognition (SER) plays an important role in deciphering\nemotional states from speech signals. Despite advancements, challenges persist\ndue to system complexity, feature distinctiveness issues, and noise\ninterference. This paper introduces a new end-to-end (E2E) deep learning\nmulti-resolution framework for SER, addressing these limitations by extracting\nmeaningful representations directly from raw waveform speech signals. By\nleveraging the properties of the fast discrete wavelet transform (FDWT),\nincluding the cascade algorithm, conjugate quadrature filter, and coefficient\ndenoising, our approach introduces a learnable model for both wavelet bases and\ndenoising through deep learning techniques. The framework incorporates an\nactivation function for learnable asymmetric hard thresholding of wavelet\ncoefficients. Our approach exploits the capabilities of wavelets for effective\nlocalization in both time and frequency domains. We then combine\none-dimensional dilated convolutional neural networks (1D dilated CNN) with a\nspatial attention layer and bidirectional gated recurrent units (Bi-GRU) with a\ntemporal attention layer to efficiently capture the nuanced spatial and\ntemporal characteristics of emotional features. By handling variable-length\nspeech without segmentation and eliminating the need for pre or\npost-processing, the proposed model outperformed state-of-the-art methods on\nIEMOCAP and EMO-DB datasets. The source code of this paper is shared on the\nGithub repository:\nhttps://github.com/alaaNfissi/SigWavNet-Learning-Multiresolution-Signal-Wavelet-Network-for-Speech-Emotion-Recognition.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL",
      "eess.AS",
      "I.2.7; I.2.6; I.2.1; I.2.0"
    ],
    "primary_category": "cs.SD",
    "comment": "Published in: IEEE Transactions on Affective Computing",
    "pdf_url": "http://arxiv.org/pdf/2502.00310v1",
    "published_date": "2025-02-01 04:18:06 UTC",
    "updated_date": "2025-02-01 04:18:06 UTC"
  },
  {
    "arxiv_id": "2502.00306v1",
    "title": "Riddle Me This! Stealthy Membership Inference for Retrieval-Augmented Generation",
    "authors": [
      "Ali Naseh",
      "Yuefeng Peng",
      "Anshuman Suri",
      "Harsh Chaudhari",
      "Alina Oprea",
      "Amir Houmansadr"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) enables Large Language Models (LLMs) to\ngenerate grounded responses by leveraging external knowledge databases without\naltering model parameters. Although the absence of weight tuning prevents\nleakage via model parameters, it introduces the risk of inference adversaries\nexploiting retrieved documents in the model's context. Existing methods for\nmembership inference and data extraction often rely on jailbreaking or\ncarefully crafted unnatural queries, which can be easily detected or thwarted\nwith query rewriting techniques common in RAG systems. In this work, we present\nInterrogation Attack (IA), a membership inference technique targeting documents\nin the RAG datastore. By crafting natural-text queries that are answerable only\nwith the target document's presence, our approach demonstrates successful\ninference with just 30 queries while remaining stealthy; straightforward\ndetectors identify adversarial prompts from existing methods up to ~76x more\nfrequently than those generated by our attack. We observe a 2x improvement in\nTPR@1%FPR over prior inference attacks across diverse RAG configurations, all\nwhile costing less than $0.02 per document inference.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.00306v1",
    "published_date": "2025-02-01 04:01:18 UTC",
    "updated_date": "2025-02-01 04:01:18 UTC"
  },
  {
    "arxiv_id": "2502.00305v1",
    "title": "DEUCE: Dual-diversity Enhancement and Uncertainty-awareness for Cold-start Active Learning",
    "authors": [
      "Jiaxin Guo",
      "C. L. Philip Chen",
      "Shuzhen Li",
      "Tong Zhang"
    ],
    "abstract": "Cold-start active learning (CSAL) selects valuable instances from an\nunlabeled dataset for manual annotation. It provides high-quality data at a low\nannotation cost for label-scarce text classification. However, existing CSAL\nmethods overlook weak classes and hard representative examples, resulting in\nbiased learning. To address these issues, this paper proposes a novel\ndual-diversity enhancing and uncertainty-aware (DEUCE) framework for CSAL.\nSpecifically, DEUCE leverages a pretrained language model (PLM) to efficiently\nextract textual representations, class predictions, and predictive uncertainty.\nThen, it constructs a Dual-Neighbor Graph (DNG) to combine information on both\ntextual diversity and class diversity, ensuring a balanced data distribution.\nIt further propagates uncertainty information via density-based clustering to\nselect hard representative instances. DEUCE performs well in selecting\nclass-balanced and hard representative data by dual-diversity and\ninformativeness. Experiments on six NLP datasets demonstrate the superiority\nand efficiency of DEUCE.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "I.2.6; I.2.7; I.5.1; H.3.1; H.3.3"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages, 3 figures, 12 tables. Accepted manuscript by TACL. For\n  published version by MIT Press, see\n  https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00731/125950",
    "pdf_url": "http://arxiv.org/pdf/2502.00305v1",
    "published_date": "2025-02-01 04:00:03 UTC",
    "updated_date": "2025-02-01 04:00:03 UTC"
  },
  {
    "arxiv_id": "2502.00304v1",
    "title": "HoP: Homeomorphic Polar Learning for Hard Constrained Optimization",
    "authors": [
      "Ke Deng",
      "Hanwen Zhang",
      "Jin Lu",
      "Haijian Sun"
    ],
    "abstract": "Constrained optimization demands highly efficient solvers which promotes the\ndevelopment of learn-to-optimize (L2O) approaches. As a data-driven method, L2O\nleverages neural networks to efficiently produce approximate solutions.\nHowever, a significant challenge remains in ensuring both optimality and\nfeasibility of neural networks' output. To tackle this issue, we introduce\nHomeomorphic Polar Learning (HoP) to solve the star-convex hard-constrained\noptimization by embedding homeomorphic mapping in neural networks. The\nbijective structure enables end-to-end training without extra penalty or\ncorrection. For performance evaluation, we evaluate HoP's performance across a\nvariety of synthetic optimization tasks and real-world applications in wireless\ncommunications. In all cases, HoP achieves solutions closer to the optimum than\nexisting L2O methods while strictly maintaining feasibility.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "in submission",
    "pdf_url": "http://arxiv.org/pdf/2502.00304v1",
    "published_date": "2025-02-01 03:59:15 UTC",
    "updated_date": "2025-02-01 03:59:15 UTC"
  },
  {
    "arxiv_id": "2502.00302v2",
    "title": "Learning to Fuse Temporal Proximity Networks: A Case Study in Chimpanzee Social Interactions",
    "authors": [
      "Yixuan He",
      "Aaron Sandel",
      "David Wipf",
      "Mihai Cucuringu",
      "John Mitani",
      "Gesine Reinert"
    ],
    "abstract": "How can we identify groups of primate individuals which could be conjectured\nto drive social structure? To address this question, one of us has collected a\ntime series of data for social interactions between chimpanzees. Here we use a\nnetwork representation, leading to the task of combining these data into a time\nseries of a single weighted network per time stamp, where different proximities\nshould be given different weights reflecting their relative importance. We\noptimize these proximity-type weights in a principled way, using an innovative\nloss function which rewards structural consistency across time. The approach is\nempirically validated by carefully designed synthetic data. Using statistical\ntests, we provide a way of identifying groups of individuals that stay related\nfor a significant length of time. Applying the approach to the chimpanzee data\nset, we detect cliques in the animal social network time series, which can be\nvalidated by real-world intuition from prior research and qualitative\nobservations by chimpanzee experts.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "math.OC",
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.00302v2",
    "published_date": "2025-02-01 03:51:22 UTC",
    "updated_date": "2025-05-12 08:07:11 UTC"
  },
  {
    "arxiv_id": "2502.00290v5",
    "title": "Estimating LLM Uncertainty with Evidence",
    "authors": [
      "Huan Ma",
      "Jingdong Chen",
      "Joey Tianyi Zhou",
      "Guangyu Wang",
      "Changqing Zhang"
    ],
    "abstract": "Over the past few years, Large Language Models (LLMs) have developed rapidly\nand are widely applied in various domains. However, LLMs face the issue of\nhallucinations, generating responses that may be unreliable when the models\nlack relevant knowledge. To be aware of potential hallucinations, uncertainty\nestimation methods have been introduced, and most of them have confirmed that\nreliability lies in critical tokens. However, probability-based methods perform\npoorly in identifying token reliability, limiting their practical utility. In\nthis paper, we reveal that the probability-based method fails to estimate token\nreliability due to the loss of evidence strength information which is\naccumulated in the training stage. Therefore, we present Logits-induced token\nuncertainty (LogTokU), a framework for estimating decoupled token uncertainty\nin LLMs, enabling real-time uncertainty estimation without requiring multiple\nsampling processes. We employ evidence modeling to implement LogTokU and use\nthe estimated uncertainty to guide downstream tasks. The experimental results\ndemonstrate that LogTokU has significant effectiveness and promise.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.00290v5",
    "published_date": "2025-02-01 03:18:02 UTC",
    "updated_date": "2025-05-09 05:37:54 UTC"
  },
  {
    "arxiv_id": "2502.00281v1",
    "title": "Sigmoid Self-Attention is Better than Softmax Self-Attention: A Mixture-of-Experts Perspective",
    "authors": [
      "Fanqi Yan",
      "Huy Nguyen",
      "Pedram Akbarian",
      "Nhat Ho",
      "Alessandro Rinaldo"
    ],
    "abstract": "At the core of the popular Transformer architecture is the self-attention\nmechanism, which dynamically assigns softmax weights to each input token so\nthat the model can focus on the most salient information. However, the softmax\nstructure slows down the attention computation due to its row-wise nature, and\ninherently introduces competition among tokens: as the weight assigned to one\ntoken increases, the weights of others decrease. This competitive dynamic may\nnarrow the focus of self-attention to a limited set of features, potentially\noverlooking other informative characteristics. Recent experimental studies have\nshown that using the element-wise sigmoid function helps eliminate token\ncompetition and reduce the computational overhead. Despite these promising\nempirical results, a rigorous comparison between sigmoid and softmax\nself-attention mechanisms remains absent in the literature. This paper closes\nthis gap by theoretically demonstrating that sigmoid self-attention is more\nsample-efficient than its softmax counterpart. Toward that goal, we illustrate\nthat each row of the self-attention matrix can be represented as a mixture of\nexperts. Our analysis shows that ''experts'' in sigmoid self-attention require\nsignificantly less data to achieve the same approximation error as those in\nsoftmax self-attention. We corroborate our theoretical findings through\nextensive experiments on both synthetic and real-world datasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Fanqi Yan, Huy Nguyen contributed equally to this work. 51 pages, 2\n  figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.00281v1",
    "published_date": "2025-02-01 02:36:14 UTC",
    "updated_date": "2025-02-01 02:36:14 UTC"
  },
  {
    "arxiv_id": "2502.00270v2",
    "title": "DUET: Optimizing Training Data Mixtures via Feedback from Unseen Evaluation Tasks",
    "authors": [
      "Zhiliang Chen",
      "Gregory Kang Ruey Lau",
      "Chuan-Sheng Foo",
      "Bryan Kian Hsiang Low"
    ],
    "abstract": "The performance of an LLM depends heavily on the relevance of its training\ndata to the downstream evaluation task. However, in practice, the data involved\nin an unseen evaluation task is often unknown (e.g., conversations between an\nLLM and a user are end-to-end encrypted). Hence, it is unclear what data are\nrelevant for fine-tuning the LLM to maximize its performance on the specific\nunseen evaluation task. Instead, one can only deploy the LLM on the unseen task\nto gather multiple rounds of feedback on how well the model performs (e.g.,\nuser ratings). This novel setting offers a refreshing perspective towards\noptimizing training data mixtures via feedback from an unseen evaluation task,\nwhich prior data mixing and selection works do not consider. Our paper presents\nDUET, a novel global-to-local algorithm that interleaves influence function as\na data selection method with Bayesian optimization to optimize data mixture via\nfeedback from a specific unseen evaluation task. By analyzing DUET's cumulative\nregret, we theoretically show that DUET converges to the optimal training data\nmixture for an unseen task even without any data knowledge of the task.\nFinally, our experiments across a variety of language tasks demonstrate that\nDUET outperforms existing data selection and mixing methods in the unseen-task\nsetting.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.00270v2",
    "published_date": "2025-02-01 01:52:32 UTC",
    "updated_date": "2025-05-18 13:39:08 UTC"
  },
  {
    "arxiv_id": "2502.00262v3",
    "title": "INSIGHT: Enhancing Autonomous Driving Safety through Vision-Language Models on Context-Aware Hazard Detection and Edge Case Evaluation",
    "authors": [
      "Dianwei Chen",
      "Zifan Zhang",
      "Yuchen Liu",
      "Xianfeng Terry Yang"
    ],
    "abstract": "Autonomous driving systems face significant challenges in handling\nunpredictable edge-case scenarios, such as adversarial pedestrian movements,\ndangerous vehicle maneuvers, and sudden environmental changes. Current\nend-to-end driving models struggle with generalization to these rare events due\nto limitations in traditional detection and prediction approaches. To address\nthis, we propose INSIGHT (Integration of Semantic and Visual Inputs for\nGeneralized Hazard Tracking), a hierarchical vision-language model (VLM)\nframework designed to enhance hazard detection and edge-case evaluation. By\nusing multimodal data fusion, our approach integrates semantic and visual\nrepresentations, enabling precise interpretation of driving scenarios and\naccurate forecasting of potential dangers. Through supervised fine-tuning of\nVLMs, we optimize spatial hazard localization using attention-based mechanisms\nand coordinate regression techniques. Experimental results on the BDD100K\ndataset demonstrate a substantial improvement in hazard prediction\nstraightforwardness and accuracy over existing models, achieving a notable\nincrease in generalization performance. This advancement enhances the\nrobustness and safety of autonomous driving systems, ensuring improved\nsituational awareness and potential decision-making in complex real-world\nscenarios.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.00262v3",
    "published_date": "2025-02-01 01:43:53 UTC",
    "updated_date": "2025-05-16 17:26:42 UTC"
  },
  {
    "arxiv_id": "2503.15517v1",
    "title": "Analysis of AI Effectiveness in Reducing Human Errors in Processing Transportation Requests",
    "authors": [
      "Oleksandr Korostin"
    ],
    "abstract": "This article examines the characteristics of human errors in processing\ntransportation requests. The role of artificial intelligence (AI) in maritime\ntransportation is explored. The main methods and technologies used for\nautomating and optimizing the handling of transportation requests are analyzed,\nalong with their impact on reducing the number of errors. Examples of\nsuccessful AI implementation in large companies are provided, confirming the\npositive influence of these technologies on overall operational efficiency and\ncustomer service levels.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "I.2.0"
    ],
    "primary_category": "cs.HC",
    "comment": "4 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2503.15517v1",
    "published_date": "2025-02-01 01:26:14 UTC",
    "updated_date": "2025-02-01 01:26:14 UTC"
  },
  {
    "arxiv_id": "2502.00241v1",
    "title": "Mordal: Automated Pretrained Model Selection for Vision Language Models",
    "authors": [
      "Shiqi He",
      "Insu Jang",
      "Mosharaf Chowdhury"
    ],
    "abstract": "Incorporating multiple modalities into large language models (LLMs) is a\npowerful way to enhance their understanding of non-textual data, enabling them\nto perform multimodal tasks. Vision language models (VLMs) form the fastest\ngrowing category of multimodal models because of their many practical use\ncases, including in healthcare, robotics, and accessibility. Unfortunately,\neven though different VLMs in the literature demonstrate impressive visual\ncapabilities in different benchmarks, they are handcrafted by human experts;\nthere is no automated framework to create task-specific multimodal models.\n  We introduce Mordal, an automated multimodal model search framework that\nefficiently finds the best VLM for a user-defined task without manual\nintervention. Mordal achieves this both by reducing the number of candidates to\nconsider during the search process and by minimizing the time required to\nevaluate each remaining candidate. Our evaluation shows that Mordal can find\nthe best VLM for a given problem using up to $8.9\\times$--$11.6\\times$ lower\nGPU hours than grid search. In the process of our evaluation, we have also\ndiscovered new VLMs that outperform their state-of-the-art counterparts.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.00241v1",
    "published_date": "2025-02-01 00:41:29 UTC",
    "updated_date": "2025-02-01 00:41:29 UTC"
  },
  {
    "arxiv_id": "2502.00232v1",
    "title": "A Hybrid Random Forest and CNN Framework for Tile-Wise Oil-Water Classification in Hyperspectral Images",
    "authors": [
      "Mehdi Nickzamir",
      "Seyed Mohammad Sheikh Ahamdi Gandab"
    ],
    "abstract": "A novel hybrid Random Forest and Convolutional Neural Network (CNN) framework\nis presented for oil-water classification in hyperspectral images (HSI). To\naddress the challenge of preserving spatial context, the images were divided\ninto smaller, non-overlapping tiles, which served as the basis for training,\nvalidation, and testing. Random Forest demonstrated strong performance in\npixel-wise classification, outperforming models such as XGBoost,\nAttention-Based U-Net, and HybridSN. However, Random Forest loses spatial\ncontext, limiting its ability to fully exploit the spatial relationships in\nhyperspectral data. To improve performance, a CNN was trained on the\nprobability maps generated by the Random Forest, leveraging the CNN's capacity\nto incorporate spatial context. The hybrid approach achieved 7.6% improvement\nin recall (to 0.85), 2.4% improvement in F1 score (to 0.84), and 0.54%\nimprovement in AUC (to 0.99) compared to the baseline. These results highlight\nthe effectiveness of combining probabilistic outputs with spatial feature\nlearning for context-aware analysis of hyperspectral images.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.00232v1",
    "published_date": "2025-02-01 00:13:06 UTC",
    "updated_date": "2025-02-01 00:13:06 UTC"
  }
]