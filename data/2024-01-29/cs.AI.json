{
  "date": "2024-01-29",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-01-29 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 110 篇论文，主要聚焦于 AI 模型优化（如 LLM 的公平性和鲁棒性）、强化学习、图像处理和 Federated Learning 等领域。重点包括 LLM 在对话和决策中的应用潜力，以及新颖的图神经网络和扩散模型方法；令人印象深刻的文章有那些探索 LLM 偏差和高效训练的，如由知名学者（如 OpenAI 相关团队）推动的“Reducing Selection Bias in Large Language Models”，展示了 AI 安全领域的进展。\n\n下面，我挑选并简要讨论几篇重要的、话题度高的论文，先从 LLM 和 AI 安全入手，再聊强化学习和图像处理相关的内容，最后快速掠过其他论文。重点论文优先选择那些有潜在实际影响或创新贡献的。\n\n**1. Reducing Selection Bias in Large Language Models (减少大型语言模型中的选择偏差)  \n**  \n这篇论文探讨了如何减少 LLM 中的选择偏差，核心贡献是通过实验分析偏差在不同任务中的影响，并提出一种改进方法来提升模型的鲁棒性。发现即使在有限信息下，LLM 也能通过优化学习策略实现更公平的输出，这对 AI 伦理和实际应用（如搜索和决策）有重要启示。\n\n**2. LLMs as On-demand Customizable Service (LLM 作为按需可定制服务)  \n**  \n作者提出了一种分层架构，使 LLM 更易部署在异构设备上，核心发现是通过“分层”方法实现计算资源与应用需求的平衡，显著提升了 LLM 的可访问性和效率。这篇话题度高，因为它解决了 LLM 在实际场景（如 IoT 设备）中的可扩展性问题，作者包括知名研究者，如 Shubhra Kanti Karmaker。\n\n**3. SelectLLM: Can LLMs Select Important Instructions to Annotate? (SelectLLM：LLM 是否能选择重要指令进行标注？)  \n**  \n这篇论文引入 SelectLLM 框架，利用 LLM 进行指令选择和聚类，核心贡献是提升了少样本指令微调的效率和多样性。实验显示，该方法在 AlpacaEval2 和 MT-Bench 上优于基线，突出了 LLM 在标注任务中的潜力，对于减少人类标注工作量有实际价值。\n\n**4. A Linguistic Comparison between Human and ChatGPT-Generated Conversations (人类与 ChatGPT 生成对话的语言比较)  \n**  \n作者使用 LIWC 分析对比了人类和 ChatGPT-3.5 生成的对话，核心发现是 ChatGPT 在社交过程和积极情感上表现出“更像人类”，但在变异性和真实性上逊色。这篇论文由知名学者如 Arun Ross 参与，提供了 LLM 语言能力的深入洞见，对检测 AI 生成内容有重要启示。\n\n**5. Diffusion Facial Forgery Detection (扩散模型的虚假面部检测)  \n**  \n论文提出 DiFF 数据集和基于扩散模型的检测框架，核心贡献是通过合成数据提升了对虚假面部图像的检测准确性，实验显示在各种条件下准确率低于 30%，突出了扩散模型在图像安全中的挑战。这对防伪技术有现实影响。\n\n**6. Attention-based Reinforcement Learning for Combinatorial Optimization: Application to Job Shop Scheduling Problem (基于注意力的强化学习在组合优化中的应用：应用于作业车间调度问题)  \n**  \n作者开发了一种结合策略梯度和 Transformer 的强化学习方法，核心发现是训练的模型能泛化到更大规模问题，并优于传统启发式规则。这在工业调度领域有显著潜力，展示了强化学习在实际优化问题中的高效性。\n\n**7. FedFair^3: Unlocking Threefold Fairness in Federated Learning (FedFair^3：在联邦学习中解锁三重公平性)  \n**  \n这篇论文提出 FedFair^3 框架，核心贡献是通过公平客户端选择和参与轮次优化，实现数据分布和设备属性的公平，实验显示在非独立同分布数据上准确率方差降低 54.78%。这对隐私保护的联邦学习有重要进展，尤其在医疗等敏感领域。\n\n**8. Leveraging Professional Radiologists' Expertise to Enhance LLMs' Evaluation for Radiology Reports (利用专业放射科医生的专业知识提升 LLM 在放射报告中的评估)  \n**  \n作者结合 LLM 和放射专家的反馈，核心发现是通过 In-Context Learning 和回归模型，提升了报告评估的准确性，优于传统指标如 METEOR。这篇论文由知名学者如 Zhiyong Lu 参与，对医疗 AI 的可靠性和泛化有启发。\n\n其他论文包括一些强化学习（如“Autoencoder-Based Domain Learning”）、图像生成（如“Prompt4Vis”）和图神经网络（如“Graph Reduction”）的研究，但这些相对较基础或领域特定，我这里就快速掠过。总体而言，今天的更新强调了 AI 模型的实用性和伦理挑战，LLM 相关论文尤其值得关注。如果你对特定领域感兴趣，建议查看这些论文的完整摘要。明天的快报见！",
  "papers": [
    {
      "arxiv_id": "2401.16618v1",
      "title": "A comparison of RL-based and PID controllers for 6-DOF swimming robots: hybrid underwater object tracking",
      "title_zh": "翻译失败",
      "authors": [
        "Faraz Lotfi",
        "Khalil Virji",
        "Nicholas Dudek",
        "Gregory Dudek"
      ],
      "abstract": "In this paper, we present an exploration and assessment of employing a\ncentralized deep Q-network (DQN) controller as a substitute for the prevalent\nuse of PID controllers in the context of 6DOF swimming robots. Our primary\nfocus centers on illustrating this transition with the specific case of\nunderwater object tracking. DQN offers advantages such as data efficiency and\noff-policy learning, while remaining simpler to implement than other\nreinforcement learning methods. Given the absence of a dynamic model for our\nrobot, we propose an RL agent to control this multi-input-multi-output (MIMO)\nsystem, where a centralized controller may offer more robust control than\ndistinct PIDs. Our approach involves initially using classical controllers for\nsafe exploration, then gradually shifting to DQN to take full control of the\nrobot.\n  We divide the underwater tracking task into vision and control modules. We\nuse established methods for vision-based tracking and introduce a centralized\nDQN controller. By transmitting bounding box data from the vision module to the\ncontrol module, we enable adaptation to various objects and effortless vision\nsystem replacement. Furthermore, dealing with low-dimensional data facilitates\ncost-effective online learning for the controller. Our experiments, conducted\nwithin a Unity-based simulator, validate the effectiveness of a centralized RL\nagent over separated PID controllers, showcasing the applicability of our\nframework for training the underwater RL agent and improved performance\ncompared to traditional control methods. The code for both real and simulation\nimplementations is at https://github.com/FARAZLOTFI/underwater-object-tracking.",
      "tldr_zh": "本论文比较了基于强化学习（RL）的深度 Q 网络 (DQN) 控制器与传统 PID 控制器在 6-DOF 游泳机器人上的应用，焦点是混合水下物体追踪任务。研究提出一种方法，先使用经典控制器进行安全探索，然后过渡到中心化 DQN 控制器来管理多输入多输出 (MIMO) 系统，并将任务分为视觉模块（处理物体追踪）和控制模块（DQN 决策），以实现高效适应和在线学习。实验结果显示，在 Unity 模拟器中，DQN 控制器比分离 PID 控制器表现出色，提高了追踪性能，并验证了该框架的有效性，相关代码已在 GitHub 上公开。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.16618v1",
      "published_date": "2024-01-29 23:14:15 UTC",
      "updated_date": "2024-01-29 23:14:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:59:21.501940"
    },
    {
      "arxiv_id": "2402.01746v1",
      "title": "3DG: A Framework for Using Generative AI for Handling Sparse Learner Performance Data From Intelligent Tutoring Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Liang Zhang",
        "Jionghao Lin",
        "Conrad Borchers",
        "Meng Cao",
        "Xiangen Hu"
      ],
      "abstract": "Learning performance data (e.g., quiz scores and attempts) is significant for\nunderstanding learner engagement and knowledge mastery level. However, the\nlearning performance data collected from Intelligent Tutoring Systems (ITSs)\noften suffers from sparsity, impacting the accuracy of learner modeling and\nknowledge assessments. To address this, we introduce the 3DG framework\n(3-Dimensional tensor for Densification and Generation), a novel approach\ncombining tensor factorization with advanced generative models, including\nGenerative Adversarial Network (GAN) and Generative Pre-trained Transformer\n(GPT), for enhanced data imputation and augmentation. The framework operates by\nfirst representing the data as a three-dimensional tensor, capturing dimensions\nof learners, questions, and attempts. It then densifies the data through tensor\nfactorization and augments it using Generative AI models, tailored to\nindividual learning patterns identified via clustering. Applied to data from an\nAutoTutor lesson by the Center for the Study of Adult Literacy (CSAL), the 3DG\nframework effectively generated scalable, personalized simulations of learning\nperformance. Comparative analysis revealed GAN's superior reliability over\nGPT-4 in this context, underscoring its potential in addressing data sparsity\nchallenges in ITSs and contributing to the advancement of personalized\neducational technology.",
      "tldr_zh": "该论文提出 3DG framework，一种结合张量分解 (tensor factorization) 和生成模型（如 Generative Adversarial Network (GAN) 和 Generative Pre-trained Transformer (GPT)）的框架，用于处理 Intelligent Tutoring Systems (ITSs) 中稀疏的学习表现数据（如测验分数和尝试）。框架首先将数据表示为三维张量（包括学习者、问题和尝试维度），然后通过张量分解进行数据稠密化，并利用生成模型基于聚类识别的学习模式进行个性化数据增强。实验在 Center for the Study of Adult Literacy (CSAL) 的 AutoTutor 课程数据上验证，显示 GAN 在可靠性上优于 GPT-4，从而有效缓解数据稀疏问题，并推动个性化教育技术的进步。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01746v1",
      "published_date": "2024-01-29 22:34:01 UTC",
      "updated_date": "2024-01-29 22:34:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:59:34.300066"
    },
    {
      "arxiv_id": "2401.16587v3",
      "title": "A Linguistic Comparison between Human and ChatGPT-Generated Conversations",
      "title_zh": "人类与 ChatGPT 生成对话的语言学比较",
      "authors": [
        "Morgan Sandler",
        "Hyesun Choung",
        "Arun Ross",
        "Prabu David"
      ],
      "abstract": "This study explores linguistic differences between human and LLM-generated\ndialogues, using 19.5K dialogues generated by ChatGPT-3.5 as a companion to the\nEmpathicDialogues dataset. The research employs Linguistic Inquiry and Word\nCount (LIWC) analysis, comparing ChatGPT-generated conversations with human\nconversations across 118 linguistic categories. Results show greater\nvariability and authenticity in human dialogues, but ChatGPT excels in\ncategories such as social processes, analytical style, cognition, attentional\nfocus, and positive emotional tone, reinforcing recent findings of LLMs being\n\"more human than human.\" However, no significant difference was found in\npositive or negative affect between ChatGPT and human dialogues. Classifier\nanalysis of dialogue embeddings indicates implicit coding of the valence of\naffect despite no explicit mention of affect in the conversations. The research\nalso contributes a novel, companion ChatGPT-generated dataset of conversations\nbetween two independent chatbots, which were designed to replicate a corpus of\nhuman conversations available for open access and used widely in AI research on\nlanguage modeling. Our findings enhance understanding of ChatGPT's linguistic\ncapabilities and inform ongoing efforts to distinguish between human and\nLLM-generated text, which is critical in detecting AI-generated fakes,\nmisinformation, and disinformation.",
      "tldr_zh": "本研究比较了人类对话和 ChatGPT 生成对话的语言差异，使用 LIWC 分析对 19.5K 条 ChatGPT-3.5 生成对话（基于 EmpathicDialogues 数据集）进行评估，涵盖 118 个语言类别。结果显示，人类对话表现出更高的变异性和真实性，而 ChatGPT 在社交过程、分析风格、认知、注意力焦点和积极情感语气方面表现更优，支持 LLMs “比人类更像人类”的观点。分类器分析进一步揭示，即使对话中未明确提及情感，其嵌入中仍隐含了情感正负性编码；该研究贡献了一个新 ChatGPT 生成对话数据集，并有助于区分人类和 AI 生成文本，以防范假新闻和信息误导。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "Proceedings of the 4th International Conference on Pattern\n  Recognition and Artificial Intelligence (ICPRAI), Jeju, Korea, 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.16587v3",
      "published_date": "2024-01-29 21:43:27 UTC",
      "updated_date": "2024-04-26 01:16:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:59:46.810950"
    },
    {
      "arxiv_id": "2401.16580v2",
      "title": "Attention-based Reinforcement Learning for Combinatorial Optimization: Application to Job Shop Scheduling Problem",
      "title_zh": "翻译失败",
      "authors": [
        "Jaejin Lee",
        "Seho Kee",
        "Mani Janakiram",
        "George Runger"
      ],
      "abstract": "Job shop scheduling problems represent a significant and complex facet of\ncombinatorial optimization problems, which have traditionally been addressed\nthrough either exact or approximate solution methodologies. However, the\npractical application of these solutions is often challenged due to the\ncomplexity of real-world problems. Even when utilizing an approximate solution\napproach, the time required to identify a near-optimal solution can be\nprohibitively extensive, and the solutions derived are generally not applicable\nto new problems. This study proposes an innovative attention-based\nreinforcement learning method specifically designed for the category of job\nshop scheduling problems. This method integrates a policy gradient\nreinforcement learning approach with a modified transformer architecture. A key\nfinding of this research is the ability of our trained learners within the\nproposed method to be repurposed for larger-scale problems that were not part\nof the initial training set. Furthermore, empirical evidence demonstrates that\nour approach surpasses the results of recent studies and outperforms commonly\nimplemented heuristic rules. This suggests that our method offers a promising\navenue for future research and practical application in the field of job shop\nscheduling problems.",
      "tldr_zh": "本文针对作业车间调度问题（Job Shop Scheduling Problem）提出了一种创新的基于注意力的强化学习（Attention-based Reinforcement Learning）方法，以解决传统精确或近似解决方案在实际应用中的复杂性和泛化性问题。该方法整合了策略梯度强化学习（Policy Gradient）和修改后的Transformer架构，能够高效生成近优解决方案。研究的关键发现是，训练好的模型可以扩展到未包含在初始训练集中的更大规模问题，并通过实验证明其性能优于现有研究和常用启发式规则。这为作业车间调度问题的未来研究和实际应用提供了有前景的途径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.16580v2",
      "published_date": "2024-01-29 21:31:54 UTC",
      "updated_date": "2024-03-18 17:57:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:59:57.370094"
    },
    {
      "arxiv_id": "2401.16578v3",
      "title": "Leveraging Professional Radiologists' Expertise to Enhance LLMs' Evaluation for Radiology Reports",
      "title_zh": "利用专业放射科医生的专长提升LLMs对放射学报告的评估",
      "authors": [
        "Qingqing Zhu",
        "Xiuying Chen",
        "Qiao Jin",
        "Benjamin Hou",
        "Tejas Sudharshan Mathai",
        "Pritam Mukherjee",
        "Xin Gao",
        "Ronald M Summers",
        "Zhiyong Lu"
      ],
      "abstract": "In radiology, Artificial Intelligence (AI) has significantly advanced report\ngeneration, but automatic evaluation of these AI-produced reports remains\nchallenging. Current metrics, such as Conventional Natural Language Generation\n(NLG) and Clinical Efficacy (CE), often fall short in capturing the semantic\nintricacies of clinical contexts or overemphasize clinical details, undermining\nreport clarity. To overcome these issues, our proposed method synergizes the\nexpertise of professional radiologists with Large Language Models (LLMs), like\nGPT-3.5 and GPT-4 1. Utilizing In-Context Instruction Learning (ICIL) and Chain\nof Thought (CoT) reasoning, our approach aligns LLM evaluations with\nradiologist standards, enabling detailed comparisons between human and AI\ngenerated reports. This is further enhanced by a Regression model that\naggregates sentence evaluation scores. Experimental results show that our\n\"Detailed GPT-4 (5-shot)\" model achieves a 0.48 score, outperforming the METEOR\nmetric by 0.19, while our \"Regressed GPT-4\" model shows even greater alignment\nwith expert evaluations, exceeding the best existing metric by a 0.35 margin.\nMoreover, the robustness of our explanations has been validated through a\nthorough iterative strategy. We plan to publicly release annotations from\nradiology experts, setting a new standard for accuracy in future assessments.\nThis underscores the potential of our approach in enhancing the quality\nassessment of AI-driven medical reports.",
      "tldr_zh": "本文提出一种方法，利用专业放射学家的专业知识增强 Large Language Models (LLMs) 如 GPT-3.5 和 GPT-4 对放射学报告的评估，解决现有指标如 Conventional Natural Language Generation (NLG) 和 Clinical Efficacy (CE) 在捕捉临床语义和报告清晰度方面的不足。方法采用 In-Context Instruction Learning (ICIL) 和 Chain of Thought (CoT) 推理，使 LLM 评估与放射学家标准对齐，并通过一个回归模型聚合句子评估分数。实验结果显示，Detailed GPT-4 (5-shot) 模型得分 0.48，比 METEOR 高 0.19，而 Regressed GPT-4 模型与专家评估对齐度更高，领先现有最佳指标 0.35 分。该方法验证了鲁棒性，并计划公开放射学专家注释，以提升 AI 驱动医疗报告的质量评估标准。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.16578v3",
      "published_date": "2024-01-29 21:24:43 UTC",
      "updated_date": "2024-02-17 03:07:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:00:11.345816"
    },
    {
      "arxiv_id": "2401.16577v1",
      "title": "LLMs as On-demand Customizable Service",
      "title_zh": "LLMs 作为按需可定制服务",
      "authors": [
        "Souvika Sarkar",
        "Mohammad Fakhruddin Babar",
        "Monowar Hasan",
        "Shubhra Kanti Karmaker"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable language\nunderstanding and generation capabilities. However, training, deploying, and\naccessing these models pose notable challenges, including resource-intensive\ndemands, extended training durations, and scalability issues. To address these\nissues, we introduce a concept of hierarchical, distributed LLM architecture\nthat aims at enhancing the accessibility and deployability of LLMs across\nheterogeneous computing platforms, including general-purpose computers (e.g.,\nlaptops) and IoT-style devices (e.g., embedded systems). By introducing a\n\"layered\" approach, the proposed architecture enables on-demand accessibility\nto LLMs as a customizable service. This approach also ensures optimal\ntrade-offs between the available computational resources and the user's\napplication needs. We envision that the concept of hierarchical LLM will\nempower extensive, crowd-sourced user bases to harness the capabilities of\nLLMs, thereby fostering advancements in AI technology in general.",
      "tldr_zh": "该研究针对大型语言模型（LLMs）的训练、部署和访问挑战（如资源密集型、训练时间长和可扩展性问题），提出了一种分层、分布式 LLM 架构，以提升 LLMs 在异构计算平台（如笔记本电脑和 IoT 设备）上的可访问性和可部署性。通过“分层”方法，该架构实现 LLMs 作为可定制服务的按需访问，并优化计算资源与用户应用需求的权衡。我们预见，这种分层 LLM 概念将使广泛的用户基础能够利用 LLMs，推动 AI 技术整体进步。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.16577v1",
      "published_date": "2024-01-29 21:24:10 UTC",
      "updated_date": "2024-01-29 21:24:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:00:20.682265"
    },
    {
      "arxiv_id": "2401.16569v1",
      "title": "Autoencoder-Based Domain Learning for Semantic Communication with Conceptual Spaces",
      "title_zh": "翻译失败",
      "authors": [
        "Dylan Wheeler",
        "Balasubramaniam Natarajan"
      ],
      "abstract": "Communication with the goal of accurately conveying meaning, rather than\naccurately transmitting symbols, has become an area of growing interest. This\nparadigm, termed semantic communication, typically leverages modern\ndevelopments in artificial intelligence and machine learning to improve the\nefficiency and robustness of communication systems. However, a standard model\nfor capturing and quantifying the details of \"meaning\" is lacking, with many\nleading approaches to semantic communication adopting a black-box framework\nwith little understanding of what exactly the model is learning. One solution\nis to utilize the conceptual spaces framework, which models meaning explicitly\nin a geometric manner. Though prior work studying semantic communication with\nconceptual spaces has shown promising results, these previous attempts involve\nhand-crafting a conceptual space model, severely limiting the scalability and\npracticality of the approach. In this work, we develop a framework for learning\na domain of a conceptual space model using only the raw data with high-level\nproperty labels. In experiments using the MNIST and CelebA datasets, we show\nthat the domains learned using the framework maintain semantic similarity\nrelations and possess interpretable dimensions.",
      "tldr_zh": "该论文针对语义通信（Semantic Communication）中缺乏标准意义模型和黑箱学习问题，提出了一种基于自编码器（Autoencoder）的框架，用于自动学习概念空间（Conceptual Spaces）的领域。框架仅使用原始数据和高水平属性标签，避免了以往手工制作模型的局限性，提高了可扩展性和实用性。在 MNIST 和 CelebA 数据集的实验中，该方法成功维持了语义相似性（Semantic Similarity）关系，并实现了可解释的维度（Interpretable Dimensions）。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "eess.IV"
      ],
      "primary_category": "cs.LG",
      "comment": "6 pages, 5 figures. This work has been submitted to the IEEE for\n  possible publication",
      "pdf_url": "http://arxiv.org/pdf/2401.16569v1",
      "published_date": "2024-01-29 21:08:33 UTC",
      "updated_date": "2024-01-29 21:08:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:00:34.546763"
    },
    {
      "arxiv_id": "2401.16561v1",
      "title": "Multi-class Regret Detection in Hindi Devanagari Script",
      "title_zh": "翻译失败",
      "authors": [
        "Renuka Sharma",
        "Sushama Nagpal",
        "Sangeeta Sabharwal",
        "Sabur Butt"
      ],
      "abstract": "The number of Hindi speakers on social media has increased dramatically in\nrecent years. Regret is a common emotional experience in our everyday life.\nMany speakers on social media, share their regretful experiences and opinions\nregularly. It might cause a re-evaluation of one's choices and a desire to make\na different option if given the chance. As a result, knowing the source of\nregret is critical for investigating its impact on behavior and\ndecision-making. This study focuses on regret and how it is expressed,\nspecifically in Hindi, on various social media platforms. In our study, we\npresent a novel dataset from three different sources, where each sentence has\nbeen manually classified into one of three classes \"Regret by action\", \"Regret\nby inaction\", and \"No regret\". Next, we use this dataset to investigate the\nlinguistic expressions of regret in Hindi text and also identify the textual\ndomains that are most frequently associated with regret. Our findings indicate\nthat individuals on social media platforms frequently express regret for both\npast inactions and actions, particularly within the domain of interpersonal\nrelationships. We use a pre-trained BERT model to generate word embeddings for\nthe Hindi dataset and also compare deep learning models with conventional\nmachine learning models in order to demonstrate accuracy. Our results show that\nBERT embedding with CNN consistently surpassed other models. This described the\neffectiveness of BERT for conveying the context and meaning of words in the\nregret domain.",
      "tldr_zh": "本研究探讨了Hindi Devanagari脚本中多类遗憾（Regret）检测，针对社交媒体上Hindi用户的遗憾表达进行分析。研究者构建了一个新数据集，从三个来源收集的句子，并手动分类为“Regret by action”（行动后悔）、“Regret by inaction”（inaction后悔）和“No regret”（无后悔），重点考察了遗憾在人际关系领域的常见性。使用预训练的BERT模型生成词嵌入，并比较深度学习模型（如BERT结合CNN）和传统机器学习模型，结果显示BERT embedding与CNN的组合在准确性上表现出色，证明了其在捕捉遗憾语境的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.16561v1",
      "published_date": "2024-01-29 20:58:43 UTC",
      "updated_date": "2024-01-29 20:58:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:00:44.872893"
    },
    {
      "arxiv_id": "2401.16553v7",
      "title": "SelectLLM: Can LLMs Select Important Instructions to Annotate?",
      "title_zh": "SelectLLM：大语言模型能否选择重要的指令进行标注？",
      "authors": [
        "Ritik Sachin Parkar",
        "Jaehyung Kim",
        "Jong Inn Park",
        "Dongyeop Kang"
      ],
      "abstract": "Instruction tuning benefits from large and diverse datasets; however,\ncreating such datasets involves a high cost of human labeling. While synthetic\ndatasets generated by large language models (LLMs) have partly solved this\nissue, they often contain low-quality data. One effective solution is\nselectively annotating unlabelled instructions, especially given the relative\nease of acquiring unlabeled instructions or texts from various sources.\nHowever, how to select unlabelled instructions is not well-explored, especially\nin the context of LLMs. Therefore, we introduce SelectLLM, an alternative\nframework that leverages the capabilities of LLMs to select unlabeled\ninstructions more effectively. Specifically, SelectLLM consists of two key\nsteps: Coreset-based clustering of unlabelled instructions for enlarging\ndiversity and prompting of LLM to identify the most beneficial instructions\nwithin each cluster. We evaluate SelectLLM on AlpacaEval2 and MT-Bench,\ndemonstrating its ability to outperform state-of-the-art methods like\nAlpagasus. In addition, we compare the performance and compatibility of\nSelectLLM with various LLMs, such as ChatGPT, LLaMA-3.1-70B, and Gemma-2-27b.\nSelectLLM's adaptability and robustness are further evidenced by its ability to\nmaintain high performance across both human and synthetic datasets. All code\nand data are publicly available (https://github.com/minnesotanlp/select-llm).",
      "tldr_zh": "该研究探讨了大型语言模型（LLMs）是否能有效选择重要的未标注指令来提升指令微调数据集的质量和多样性，以降低人工标注成本。SelectLLM 框架通过 Coreset-based clustering 聚类未标注指令以增加多样性，并利用 LLM 提示在每个聚类中识别最有益的指令。实验结果显示，SelectLLM 在 AlpacaEval2 和 MT-Bench 上优于 Alpagasus，且与 ChatGPT、LLaMA-3.1-70B 和 Gemma-2-27b 等模型兼容，证明其在人类和合成数据集上的适应性和鲁棒性，所有代码和数据已公开（https://github.com/minnesotanlp/select-llm）。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "First Authors: Ritik Sachin Parkar and Jaehyung Kim | Second Author:\n  Jong Inn Park | PI: Dongyeop Kang",
      "pdf_url": "http://arxiv.org/pdf/2401.16553v7",
      "published_date": "2024-01-29 20:44:10 UTC",
      "updated_date": "2024-08-27 17:57:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:00:58.989893"
    },
    {
      "arxiv_id": "2401.16541v1",
      "title": "GuReT: Distinguishing Guilt and Regret related Text",
      "title_zh": "翻译失败",
      "authors": [
        "Sabur Butt",
        "Fazlourrahman Balouchzahi",
        "Abdul Gafar Manuel Meque",
        "Maaz Amjad",
        "Hector G. Ceballos Cancino",
        "Grigori Sidorov",
        "Alexander Gelbukh"
      ],
      "abstract": "The intricate relationship between human decision-making and emotions,\nparticularly guilt and regret, has significant implications on behavior and\nwell-being. Yet, these emotions subtle distinctions and interplay are often\noverlooked in computational models. This paper introduces a dataset tailored to\ndissect the relationship between guilt and regret and their unique textual\nmarkers, filling a notable gap in affective computing research. Our approach\ntreats guilt and regret recognition as a binary classification task and employs\nthree machine learning and six transformer-based deep learning techniques to\nbenchmark the newly created dataset. The study further implements innovative\nreasoning methods like chain-of-thought and tree-of-thought to assess the\nmodels interpretive logic. The results indicate a clear performance edge for\ntransformer-based models, achieving a 90.4% macro F1 score compared to the\n85.3% scored by the best machine learning classifier, demonstrating their\nsuperior capability in distinguishing complex emotional states.",
      "tldr_zh": "这篇论文引入了GuReT数据集，用于区分内疚(Guilt)和遗憾(Regret)相关的文本标记，填补了情感计算研究中对这些情绪细微差别的空白。研究将内疚和遗憾识别视为二元分类任务，采用三种机器学习和六种基于Transformer的深度学习模型进行基准测试，并运用Chain-of-Thought和Tree-of-Thought推理方法来评估模型的解释逻辑。结果表明，Transformer-based模型表现出色，宏F1分数达到90.4%，比最佳机器学习分类器的85.3%高出显著优势，证明其在处理复杂情绪状态方面的优越性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.16541v1",
      "published_date": "2024-01-29 20:20:44 UTC",
      "updated_date": "2024-01-29 20:20:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:01:10.333912"
    },
    {
      "arxiv_id": "2402.00066v1",
      "title": "TrackGPT -- A generative pre-trained transformer for cross-domain entity trajectory forecasting",
      "title_zh": "TrackGPT：一种用于跨领域实体轨迹预测的生成式预训练变换器",
      "authors": [
        "Nicholas Stroh"
      ],
      "abstract": "The forecasting of entity trajectories at future points in time is a critical\ncapability gap in applications across both Commercial and Defense sectors.\nTransformers, and specifically Generative Pre-trained Transformer (GPT)\nnetworks have recently revolutionized several fields of Artificial\nIntelligence, most notably Natural Language Processing (NLP) with the advent of\nLarge Language Models (LLM) like OpenAI's ChatGPT. In this research paper, we\nintroduce TrackGPT, a GPT-based model for entity trajectory forecasting that\nhas shown utility across both maritime and air domains, and we expect to\nperform well in others. TrackGPT stands as a pioneering GPT model capable of\nproducing accurate predictions across diverse entity time series datasets,\ndemonstrating proficiency in generating both long-term forecasts with sustained\naccuracy and short-term forecasts with high precision. We present benchmarks\nagainst state-of-the-art deep learning techniques, showing that TrackGPT's\nforecasting capability excels in terms of accuracy, reliability, and\nmodularity. Importantly, TrackGPT achieves these results while remaining\ndomain-agnostic and requiring minimal data features (only location and time)\ncompared to models achieving similar performance. In conclusion, our findings\nunderscore the immense potential of applying GPT architectures to the task of\nentity trajectory forecasting, exemplified by the innovative TrackGPT model.",
      "tldr_zh": "本研究引入了TrackGPT，一种基于Generative Pre-trained Transformer (GPT)架构的模型，用于跨领域实体轨迹预测，适用于商业和国防领域。该模型仅需位置和时间数据，即可实现领域无关的预测，并在海洋和航空等领域表现出色，能够生成高精度的短期和长期预测。与现有深度学习技术相比，TrackGPT在准确性、可靠性和模块性上表现出显著优势，基准测试显示其性能领先。总之，该工作证明了GPT架构在实体轨迹预测中的巨大潜力，为相关应用提供了创新解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T07"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.00066v1",
      "published_date": "2024-01-29 20:05:14 UTC",
      "updated_date": "2024-01-29 20:05:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:01:22.381276"
    },
    {
      "arxiv_id": "2401.16521v1",
      "title": "Validation, Robustness, and Accuracy of Perturbation-Based Sensitivity Analysis Methods for Time-Series Deep Learning Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zhengguang Wang"
      ],
      "abstract": "This work undertakes studies to evaluate Interpretability Methods for\nTime-Series Deep Learning. Sensitivity analysis assesses how input changes\naffect the output, constituting a key component of interpretation. Among the\npost-hoc interpretation methods such as back-propagation, perturbation, and\napproximation, my work will investigate perturbation-based sensitivity Analysis\nmethods on modern Transformer models to benchmark their performances.\nSpecifically, my work answers three research questions: 1) Do different\nsensitivity analysis (SA) methods yield comparable outputs and attribute\nimportance rankings? 2) Using the same sensitivity analysis method, do\ndifferent Deep Learning (DL) models impact the output of the sensitivity\nanalysis? 3) How well do the results from sensitivity analysis methods align\nwith the ground truth?",
      "tldr_zh": "这篇论文评估了基于扰动的敏感性分析(SA)方法在时间序列深度学习模型中的有效性、鲁棒性和准确性。研究重点是针对现代Transformer模型，通过实验回答三个关键问题：1) 不同SA方法是否产生可比的输出和属性重要性排名；2) 使用相同SA方法时，不同Deep Learning (DL) 模型是否影响分析结果；3) SA方法的输出与ground truth 的契合度如何。这些发现为时间序列模型的可解释性提供了重要基准，帮助提升模型的可靠性和透明度。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.16521v1",
      "published_date": "2024-01-29 19:51:50 UTC",
      "updated_date": "2024-01-29 19:51:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:01:36.163838"
    },
    {
      "arxiv_id": "2401.16501v1",
      "title": "AFSD-Physics: Exploring the governing equations of temperature evolution during additive friction stir deposition by a human-AI teaming approach",
      "title_zh": "翻译失败",
      "authors": [
        "Tony Shi",
        "Mason Ma",
        "Jiajie Wu",
        "Chase Post",
        "Elijah Charles",
        "Tony Schmitz"
      ],
      "abstract": "This paper presents a modeling effort to explore the underlying physics of\ntemperature evolution during additive friction stir deposition (AFSD) by a\nhuman-AI teaming approach. AFSD is an emerging solid-state additive\nmanufacturing technology that deposits materials without melting. However, both\nprocess modeling and modeling of the AFSD tool are at an early stage. In this\npaper, a human-AI teaming approach is proposed to combine models based on first\nprinciples with AI. The resulting human-informed machine learning method,\ndenoted as AFSD-Physics, can effectively learn the governing equations of\ntemperature evolution at the tool and the build from in-process measurements.\nExperiments are designed and conducted to collect in-process measurements for\nthe deposition of aluminum 7075 with a total of 30 layers. The acquired\ngoverning equations are physically interpretable models with low computational\ncost and high accuracy. Model predictions show good agreement with the\nmeasurements. Experimental validation with new process parameters demonstrates\nthe model's generalizability and potential for use in tool temperature control\nand process optimization.",
      "tldr_zh": "这篇论文提出了一种名为 AFSD-Physics 的方法，通过人类-AI 团队协作，结合基于第一原理的模型和 AI，探索增材摩擦搅拌沉积(AFSD)过程中的温度演变控制方程。AFSD 是一种新兴的固态增材制造技术，该方法从过程测量中有效学习这些方程，并在铝 7075 材料堆积 30 层的实验中验证。结果表明，获得的方程具有物理可解释性、低计算成本和高准确性，并展示了良好的预测性能和泛化能力，可用于工具温度控制和过程优化。",
      "categories": [
        "cs.LG",
        "cond-mat.mtrl-sci",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.16501v1",
      "published_date": "2024-01-29 19:17:42 UTC",
      "updated_date": "2024-01-29 19:17:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:01:48.185126"
    },
    {
      "arxiv_id": "2401.16421v2",
      "title": "Two Stones Hit One Bird: Bilevel Positional Encoding for Better Length Extrapolation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenyu He",
        "Guhao Feng",
        "Shengjie Luo",
        "Kai Yang",
        "Liwei Wang",
        "Jingjing Xu",
        "Zhi Zhang",
        "Hongxia Yang",
        "Di He"
      ],
      "abstract": "In this work, we leverage the intrinsic segmentation of language sequences\nand design a new positional encoding method called Bilevel Positional Encoding\n(BiPE). For each position, our BiPE blends an intra-segment encoding and an\ninter-segment encoding. The intra-segment encoding identifies the locations\nwithin a segment and helps the model capture the semantic information therein\nvia absolute positional encoding. The inter-segment encoding specifies the\nsegment index, models the relationships between segments, and aims to improve\nextrapolation capabilities via relative positional encoding. Theoretical\nanalysis shows this disentanglement of positional information makes learning\nmore effective. The empirical results also show that our BiPE has superior\nlength extrapolation capabilities across a wide range of tasks in diverse text\nmodalities.",
      "tldr_zh": "本研究提出了 Bilevel Positional Encoding (BiPE)，一种新的位置编码方法，旨在通过利用语言序列的内在分段特性来提升模型的长度外推能力。BiPE 将每个位置的编码分为 intra-segment encoding（用于识别段内位置并通过绝对位置编码捕捉语义信息）和 inter-segment encoding（用于指定段索引并通过相对位置编码建模段间关系）。这种位置信息的分离在理论分析中被证明能使学习更有效，而实验结果显示 BiPE 在各种任务和文本模式下表现出优越的长度外推性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages, 7 figures, 8 tables; ICML 2024 Camera Ready version; Code:\n  https://github.com/zhenyuhe00/BiPE",
      "pdf_url": "http://arxiv.org/pdf/2401.16421v2",
      "published_date": "2024-01-29 18:59:07 UTC",
      "updated_date": "2024-06-17 06:18:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:01:59.913770"
    },
    {
      "arxiv_id": "2401.17123v1",
      "title": "Unsupervised Discovery of Steerable Factors When Graph Deep Generative Models Are Entangled",
      "title_zh": "当图深度生成模型纠缠时，无监督发现可操控因素",
      "authors": [
        "Shengchao Liu",
        "Chengpeng Wang",
        "Jiarui Lu",
        "Weili Nie",
        "Hanchen Wang",
        "Zhuoxinran Li",
        "Bolei Zhou",
        "Jian Tang"
      ],
      "abstract": "Deep generative models (DGMs) have been widely developed for graph data.\nHowever, much less investigation has been carried out on understanding the\nlatent space of such pretrained graph DGMs. These understandings possess the\npotential to provide constructive guidelines for crucial tasks, such as graph\ncontrollable generation. Thus in this work, we are interested in studying this\nproblem and propose GraphCG, a method for the unsupervised discovery of\nsteerable factors in the latent space of pretrained graph DGMs. We first\nexamine the representation space of three pretrained graph DGMs with six\ndisentanglement metrics, and we observe that the pretrained representation\nspace is entangled. Motivated by this observation, GraphCG learns the steerable\nfactors via maximizing the mutual information between semantic-rich directions,\nwhere the controlled graph moving along the same direction will share the same\nsteerable factors. We quantitatively verify that GraphCG outperforms four\ncompetitive baselines on two graph DGMs pretrained on two molecule datasets.\nAdditionally, we qualitatively illustrate seven steerable factors learned by\nGraphCG on five pretrained DGMs over five graph datasets, including two for\nmolecules and three for point clouds.",
      "tldr_zh": "该论文探讨了预训练图深度生成模型(DGMs)的潜在空间纠缠问题，提出GraphCG方法，用于无监督发现可操控因素(steerable factors)，以支持图可控生成任务。GraphCG通过最大化语义丰富方向之间的互信息，确保沿着同一方向移动的图共享相同的可操控因素，并对三个预训练图DGMs的表示空间进行分析。实验结果显示，GraphCG在两个分子数据集上优于四个竞争基线，并在五个图数据集（包括分子和点云）上定性和定量验证了七个可操控因素的发现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.17123v1",
      "published_date": "2024-01-29 18:53:34 UTC",
      "updated_date": "2024-01-29 18:53:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:02:11.960232"
    },
    {
      "arxiv_id": "2401.16412v4",
      "title": "Learning to Manipulate under Limited Information",
      "title_zh": "翻译失败",
      "authors": [
        "Wesley H. Holliday",
        "Alexander Kristoffersen",
        "Eric Pacuit"
      ],
      "abstract": "By classic results in social choice theory, any reasonable preferential\nvoting method sometimes gives individuals an incentive to report an insincere\npreference. The extent to which different voting methods are more or less\nresistant to such strategic manipulation has become a key consideration for\ncomparing voting methods. Here we measure resistance to manipulation by whether\nneural networks of various sizes can learn to profitably manipulate a given\nvoting method in expectation, given different types of limited information\nabout how other voters will vote. We trained over 100,000 neural networks of 26\nsizes to manipulate against 8 different voting methods, under 6 types of\nlimited information, in committee-sized elections with 5-21 voters and 3-6\ncandidates. We find that some voting methods, such as Borda, are highly\nmanipulable by networks with limited information, while others, such as Instant\nRunoff, are not, despite being quite profitably manipulated by an ideal\nmanipulator with full information. For the three probability models for\nelections that we use, the overall least manipulable of the 8 methods we study\nare Condorcet methods, namely Minimax and Split Cycle.",
      "tldr_zh": "该研究利用神经网络评估不同投票方法的抗操纵性，基于社会选择理论（social choice theory）探讨个体在有限信息下报告虚假偏好的动机。研究者训练超过10万个神经网络（不同大小），针对8种投票方法（如Borda和Instant Runoff）在6种有限信息类型下模拟5-21选民和3-6候选人的选举。结果显示，Borda方法在有限信息下高度易于操纵，而Instant Runoff尽管在完全信息下易操纵，但在有限情况下更具抵抗力。对于三种选举概率模型，Condorcet方法（如Minimax和Split Cycle）被证明是最不容易被操纵的。",
      "categories": [
        "cs.AI",
        "cs.GT",
        "cs.LG",
        "cs.MA",
        "econ.TH",
        "91B12, 91B14, 91B10, 68T07",
        "I.2.6; I.2.11"
      ],
      "primary_category": "cs.AI",
      "comment": "Final version for Proceedings of the 39th Annual AAAI Conference on\n  Artificial Intelligence (AAAI-25)",
      "pdf_url": "http://arxiv.org/pdf/2401.16412v4",
      "published_date": "2024-01-29 18:49:50 UTC",
      "updated_date": "2025-02-22 21:33:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:02:23.659969"
    },
    {
      "arxiv_id": "2401.16467v2",
      "title": "ReGAL: Refactoring Programs to Discover Generalizable Abstractions",
      "title_zh": "翻译失败",
      "authors": [
        "Elias Stengel-Eskin",
        "Archiki Prasad",
        "Mohit Bansal"
      ],
      "abstract": "While large language models (LLMs) are increasingly being used for program\nsynthesis, they lack the global view needed to develop useful abstractions;\nthey generally predict programs one at a time, often repeating the same\nfunctionality. Generating redundant code from scratch is both inefficient and\nerror-prone. To address this, we propose Refactoring for Generalizable\nAbstraction Learning (ReGAL), a gradient-free method for learning a library of\nreusable functions via code refactorization, i.e., restructuring code without\nchanging its execution output. ReGAL learns from a small set of existing\nprograms, iteratively verifying and refining its abstractions via execution. We\nfind that the shared function libraries discovered by ReGAL make programs\neasier to predict across diverse domains. On five datasets -- LOGO graphics\ngeneration, Date reasoning, TextCraft (a Minecraft-based text-game) MATH, and\nTabMWP -- both open-source and proprietary LLMs improve in accuracy when\npredicting programs with ReGAL functions. For CodeLlama-13B, ReGAL results in\nabsolute accuracy increases of 11.5% on LOGO, 26.1% on date understanding, and\n8.1% on TextCraft, outperforming GPT-3.5 in two of three domains. Our analysis\nreveals ReGAL's abstractions encapsulate frequently-used subroutines as well as\nenvironment dynamics.",
      "tldr_zh": "本研究提出ReGAL，一种无梯度方法，通过代码重构(refactoring)从现有程序中学习可重用函数库，从而帮助大型语言模型(LLMs)发现可泛化抽象，避免重复生成冗余代码。ReGAL从一小套程序出发，采用迭代验证和完善机制，确保抽象在执行输出上保持不变。实验在五个数据集上（LOGO 图形生成、Date 推理、TextCraft、MATH 和 TabMWP）显示，使用ReGAL函数后，LLMs的程序预测准确率显著提升，例如CodeLlama-13B在LOGO上提高11.5%、在日期理解上提高26.1%，并在两个领域超越GPT-3.5。这些抽象有效地封装了频繁使用的子程序和环境动态，提升了程序合成的效率和可靠性。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.PL"
      ],
      "primary_category": "cs.SE",
      "comment": "ICML 2024 Camera-Ready; First two authors contributed equally; Code:\n  https://github.com/esteng/regal_program_learning",
      "pdf_url": "http://arxiv.org/pdf/2401.16467v2",
      "published_date": "2024-01-29 18:45:30 UTC",
      "updated_date": "2024-06-06 17:31:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:02:36.271748"
    },
    {
      "arxiv_id": "2401.16405v2",
      "title": "Scaling Sparse Fine-Tuning to Large Language Models",
      "title_zh": "扩展稀疏微",
      "authors": [
        "Alan Ansell",
        "Ivan Vulić",
        "Hannah Sterz",
        "Anna Korhonen",
        "Edoardo M. Ponti"
      ],
      "abstract": "Large Language Models (LLMs) are difficult to fully fine-tune (e.g., with\ninstructions or human feedback) due to their sheer number of parameters. A\nfamily of parameter-efficient sparse fine-tuning methods have proven promising\nin terms of performance but their memory requirements increase proportionally\nto the size of the LLMs. In this work, we scale sparse fine-tuning to\nstate-of-the-art LLMs like LLaMA 2 7B and 13B. We propose SpIEL, a novel sparse\nfine-tuning method which, for a desired density level, maintains an array of\nparameter indices and the deltas of these parameters relative to their\npretrained values. It iterates over: (a) updating the active deltas, (b)\npruning indices (based on the change of magnitude of their deltas) and (c)\nregrowth of indices. For regrowth, we explore two criteria based on either the\naccumulated gradients of a few candidate parameters or their approximate\nmomenta estimated using the efficient SM3 optimizer. We experiment with\ninstruction-tuning of LLMs on standard dataset mixtures, finding that SpIEL is\noften superior to popular parameter-efficient fine-tuning methods like LoRA\n(low-rank adaptation) in terms of performance and comparable in terms of run\ntime. We additionally show that SpIEL is compatible with both quantization and\nefficient optimizers, to facilitate scaling to ever-larger model sizes. We\nrelease the code for SpIEL at https://github.com/AlanAnsell/peft and for the\ninstruction-tuning experiments at https://github.com/ducdauge/sft-llm.",
      "tldr_zh": "该研究解决了大型语言模型 (LLMs) 由于参数众多而难以完全微调的问题，提出了一种新型稀疏微调方法 SpIEL，以实现高效扩展。SpIEL 通过维护参数索引数组和这些参数相对于预训练值的增量（deltas），并迭代更新活跃增量、基于增量变化幅度修剪索引，以及使用累积梯度或 SM3 优化器的近似动量进行重新增长。实验结果显示，在 LLaMA 2 7B 和 13B 等模型的指令微调任务上，SpIEL 通常优于 LoRA 在性能方面，同时运行时间相当，且兼容量化技术和高效优化器。该方法为处理更大规模模型提供了可扩展框架，并公开了代码实现。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.16405v2",
      "published_date": "2024-01-29 18:43:49 UTC",
      "updated_date": "2024-02-02 14:53:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:02:49.267745"
    },
    {
      "arxiv_id": "2401.16402v1",
      "title": "A Survey on Visual Anomaly Detection: Challenge, Approach, and Prospect",
      "title_zh": "视觉异常检测的综述：挑战、方法和前景",
      "authors": [
        "Yunkang Cao",
        "Xiaohao Xu",
        "Jiangning Zhang",
        "Yuqi Cheng",
        "Xiaonan Huang",
        "Guansong Pang",
        "Weiming Shen"
      ],
      "abstract": "Visual Anomaly Detection (VAD) endeavors to pinpoint deviations from the\nconcept of normality in visual data, widely applied across diverse domains,\ne.g., industrial defect inspection, and medical lesion detection. This survey\ncomprehensively examines recent advancements in VAD by identifying three\nprimary challenges: 1) scarcity of training data, 2) diversity of visual\nmodalities, and 3) complexity of hierarchical anomalies. Starting with a brief\noverview of the VAD background and its generic concept definitions, we\nprogressively categorize, emphasize, and discuss the latest VAD progress from\nthe perspective of sample number, data modality, and anomaly hierarchy. Through\nan in-depth analysis of the VAD field, we finally summarize future developments\nfor VAD and conclude the key findings and contributions of this survey.",
      "tldr_zh": "这篇调查论文综述了 Visual Anomaly Detection (VAD) 的最新进展，旨在识别视觉数据中异常的挑战和方法，广泛应用于工业缺陷检查和医疗病变检测等领域。论文重点讨论了三大主要挑战：训练数据的稀缺性、视觉模态的多样性以及层次异常的复杂性，并从样本数量、数据模态和异常层次的视角对 VAD 的进展进行分类和分析。最终，论文总结了 VAD 的未来发展方向，并强调了其关键发现和贡献。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Work in progress. Yunkang Cao, Xiaohao Xu, and Jiangning Zhang\n  contribute equally to this work",
      "pdf_url": "http://arxiv.org/pdf/2401.16402v1",
      "published_date": "2024-01-29 18:41:21 UTC",
      "updated_date": "2024-01-29 18:41:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:02:58.530522"
    },
    {
      "arxiv_id": "2401.16398v1",
      "title": "Zero-shot Imitation Policy via Search in Demonstration Dataset",
      "title_zh": "翻译失败",
      "authors": [
        "Federco Malato",
        "Florian Leopold",
        "Andrew Melnik",
        "Ville Hautamaki"
      ],
      "abstract": "Behavioral cloning uses a dataset of demonstrations to learn a policy. To\novercome computationally expensive training procedures and address the policy\nadaptation problem, we propose to use latent spaces of pre-trained foundation\nmodels to index a demonstration dataset, instantly access similar relevant\nexperiences, and copy behavior from these situations. Actions from a selected\nsimilar situation can be performed by the agent until representations of the\nagent's current situation and the selected experience diverge in the latent\nspace. Thus, we formulate our control problem as a dynamic search problem over\na dataset of experts' demonstrations. We test our approach on BASALT\nMineRL-dataset in the latent representation of a Video Pre-Training model. We\ncompare our model to state-of-the-art, Imitation Learning-based Minecraft\nagents. Our approach can effectively recover meaningful demonstrations and show\nhuman-like behavior of an agent in the Minecraft environment in a wide variety\nof scenarios. Experimental results reveal that performance of our search-based\napproach clearly wins in terms of accuracy and perceptual evaluation over\nlearning-based models.",
      "tldr_zh": "本文提出了一种零-shot Imitation Policy，通过在演示数据集的潜在空间（latent spaces）中进行动态搜索，克服了Behavioral Cloning的训练开销和策略适应问题。该方法利用预训练基础模型（如Video Pre-Training model）的表示来索引数据集，快速访问相似的专家演示并复制行为，直至代理当前情况与选定经验在潜在空间中分歧。实验在BASALT MineRL数据集上进行，结果显示该搜索-based方法在准确性和感知评估上优于现有的Imitation Learning模型，并在Minecraft环境中实现了类似人类的代理行为。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.16398v1",
      "published_date": "2024-01-29 18:38:29 UTC",
      "updated_date": "2024-01-29 18:38:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:03:12.830157"
    },
    {
      "arxiv_id": "2401.16367v1",
      "title": "TQCompressor: improving tensor decomposition methods in neural networks via permutations",
      "title_zh": "TQCompressor：通过置换改进神经网络中的张量分解方法",
      "authors": [
        "V. Abronin",
        "A. Naumov",
        "D. Mazur",
        "D. Bystrov",
        "K. Tsarova",
        "Ar. Melnikov",
        "I. Oseledets",
        "S. Dolgov",
        "R. Brasher",
        "M. Perelshtein"
      ],
      "abstract": "We introduce TQCompressor, a novel method for neural network model\ncompression with improved tensor decompositions. We explore the challenges\nposed by the computational and storage demands of pre-trained language models\nin NLP tasks and propose a permutation-based enhancement to Kronecker\ndecomposition. This enhancement makes it possible to reduce loss in model\nexpressivity which is usually associated with factorization. We demonstrate\nthis method applied to the GPT-2$_{small}$. The result of the compression is\nTQCompressedGPT-2 model, featuring 81 mln. parameters compared to 124 mln. in\nthe GPT-2$_{small}$. We make TQCompressedGPT-2 publicly available. We further\nenhance the performance of the TQCompressedGPT-2 through a training strategy\ninvolving multi-step knowledge distillation, using only a 3.1% of the\nOpenWebText. TQCompressedGPT-2 surpasses DistilGPT-2 and KnGPT-2 in comparative\nevaluations, marking an advancement in the efficient and effective deployment\nof models in resource-constrained environments.",
      "tldr_zh": "本研究引入了 TQCompressor，一种新型神经网络模型压缩方法，通过基于 permutations 的增强来改进 tensor decompositions，特别是 Kronecker decomposition，从而减少模型因子分解带来的表达能力损失。研究者将此方法应用于 GPT-2$_{small}$，开发出 TQCompressedGPT-2 模型，将参数从 124 百万减少到 81 百万，并通过多步 knowledge distillation 训练策略（仅使用 OpenWebText 的 3.1% 数据）提升性能。实验结果显示，TQCompressedGPT-2 在比较评估中超越了 DistilGPT-2 和 KnGPT-2，在资源受限环境中实现了更高效的模型部署。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.16367v1",
      "published_date": "2024-01-29 18:07:56 UTC",
      "updated_date": "2024-01-29 18:07:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:03:25.408137"
    },
    {
      "arxiv_id": "2401.16352v4",
      "title": "Adversarial Training on Purification (AToP): Advancing Both Robustness and Generalization",
      "title_zh": "翻译失败",
      "authors": [
        "Guang Lin",
        "Chao Li",
        "Jianhai Zhang",
        "Toshihisa Tanaka",
        "Qibin Zhao"
      ],
      "abstract": "The deep neural networks are known to be vulnerable to well-designed\nadversarial attacks. The most successful defense technique based on adversarial\ntraining (AT) can achieve optimal robustness against particular attacks but\ncannot generalize well to unseen attacks. Another effective defense technique\nbased on adversarial purification (AP) can enhance generalization but cannot\nachieve optimal robustness. Meanwhile, both methods share one common limitation\non the degraded standard accuracy. To mitigate these issues, we propose a novel\npipeline to acquire the robust purifier model, named Adversarial Training on\nPurification (AToP), which comprises two components: perturbation destruction\nby random transforms (RT) and purifier model fine-tuned (FT) by adversarial\nloss. RT is essential to avoid overlearning to known attacks, resulting in the\nrobustness generalization to unseen attacks, and FT is essential for the\nimprovement of robustness. To evaluate our method in an efficient and scalable\nway, we conduct extensive experiments on CIFAR-10, CIFAR-100, and ImageNette to\ndemonstrate that our method achieves optimal robustness and exhibits\ngeneralization ability against unseen attacks.",
      "tldr_zh": "深度神经网络容易受到对抗性攻击，现有的Adversarial Training (AT)方法虽能提供最佳鲁棒性但对未知攻击的泛化性较差，而Adversarial Purification (AP)则增强了泛化性却无法达到最优鲁棒性，且两者均会降低标准准确率。论文提出了一种新方法Adversarial Training on Purification (AToP)，包括通过随机变换(Perturbation destruction by random transforms, RT)破坏扰动以避免过度学习已知攻击，以及通过对抗性损失微调净化器模型(Purifier model fine-tuned, FT)来提升鲁棒性。在CIFAR-10、CIFAR-100和ImageNette数据集上的实验证明，AToP不仅实现了最优鲁棒性，还展示了良好的泛化能力，对未知攻击表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.16352v4",
      "published_date": "2024-01-29 17:56:42 UTC",
      "updated_date": "2024-08-23 06:08:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:03:39.994823"
    },
    {
      "arxiv_id": "2401.16350v1",
      "title": "FedFair^3: Unlocking Threefold Fairness in Federated Learning",
      "title_zh": "FedFair^3：实现联邦学习中的三重公平",
      "authors": [
        "Simin Javaherian",
        "Sanjeev Panta",
        "Shelby Williams",
        "Md Sirajul Islam",
        "Li Chen"
      ],
      "abstract": "Federated Learning (FL) is an emerging paradigm in machine learning without\nexposing clients' raw data. In practical scenarios with numerous clients,\nencouraging fair and efficient client participation in federated learning is of\nutmost importance, which is also challenging given the heterogeneity in data\ndistribution and device properties. Existing works have proposed different\nclient-selection methods that consider fairness; however, they fail to select\nclients with high utilities while simultaneously achieving fair accuracy\nlevels. In this paper, we propose a fair client-selection approach that unlocks\nthreefold fairness in federated learning. In addition to having a fair\nclient-selection strategy, we enforce an equitable number of rounds for client\nparticipation and ensure a fair accuracy distribution over the clients. The\nexperimental results demonstrate that FedFair^3, in comparison to the\nstate-of-the-art baselines, achieves 18.15% less accuracy variance on the IID\ndata and 54.78% on the non-IID data, without decreasing the global accuracy.\nFurthermore, it shows 24.36% less wall-clock training time on average.",
      "tldr_zh": "该论文提出 FedFair^3，一种新型客户端选择方法，用于 Federated Learning 中解决数据分布和设备异质性带来的公平性挑战。该方法实现三重公平性，包括公平的客户端选择策略、确保每个客户端公平参与训练轮次，以及实现客户端间准确度分布的均衡。实验结果显示，与现有基线相比，FedFair^3 在 IID 数据上准确度方差减少 18.15%，在 non-IID 数据上减少 54.78%，同时保持全局准确度不变，并平均减少 24.36% 的训练时间。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.16350v1",
      "published_date": "2024-01-29 17:56:15 UTC",
      "updated_date": "2024-01-29 17:56:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:03:49.560939"
    },
    {
      "arxiv_id": "2401.16335v1",
      "title": "Iterative Data Smoothing: Mitigating Reward Overfitting and Overoptimization in RLHF",
      "title_zh": "翻译失败",
      "authors": [
        "Banghua Zhu",
        "Michael I. Jordan",
        "Jiantao Jiao"
      ],
      "abstract": "Reinforcement Learning from Human Feedback (RLHF) is a pivotal technique that\naligns language models closely with human-centric values. The initial phase of\nRLHF involves learning human values using a reward model from ranking data. It\nis observed that the performance of the reward model degrades after one epoch\nof training, and optimizing too much against the learned reward model\neventually hinders the true objective. This paper delves into these issues,\nleveraging the theoretical insights to design improved reward learning\nalgorithm termed 'Iterative Data Smoothing' (IDS). The core idea is that during\neach training epoch, we not only update the model with the data, but also\nupdate the date using the model, replacing hard labels with soft labels. Our\nempirical findings highlight the superior performance of this approach over the\ntraditional methods.",
      "tldr_zh": "该论文探讨了 Reinforcement Learning from Human Feedback (RLHF) 中奖励模型训练后性能下降和过度优化的问题，这些问题会导致模型偏离真实目标。作者提出 Iterative Data Smoothing (IDS) 算法，该方法在每个训练周期中，不仅更新模型，还利用模型对数据进行平滑处理，将硬标签转换为软标签，以提升模型鲁棒性。实验结果表明，IDS 相较于传统方法表现出色，能够有效缓解奖励过度优化并改善整体性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.16335v1",
      "published_date": "2024-01-29 17:43:42 UTC",
      "updated_date": "2024-01-29 17:43:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:04:01.663116"
    },
    {
      "arxiv_id": "2401.16332v4",
      "title": "Tradeoffs Between Alignment and Helpfulness in Language Models with Representation Engineering",
      "title_zh": "翻译失败",
      "authors": [
        "Yotam Wolf",
        "Noam Wies",
        "Dorin Shteyman",
        "Binyamin Rothberg",
        "Yoav Levine",
        "Amnon Shashua"
      ],
      "abstract": "Language model alignment has become an important component of AI safety,\nallowing safe interactions between humans and language models, by enhancing\ndesired behaviors and inhibiting undesired ones. It is often done by tuning the\nmodel or inserting preset aligning prompts. Recently, representation\nengineering, a method which alters the model's behavior via changing its\nrepresentations post-training, was shown to be effective in aligning LLMs (Zou\net al., 2023a). Representation engineering yields gains in alignment oriented\ntasks such as resistance to adversarial attacks and reduction of social biases,\nbut was also shown to cause a decrease in the ability of the model to perform\nbasic tasks. In this paper we study the tradeoff between the increase in\nalignment and decrease in helpfulness of the model. We propose a theoretical\nframework which provides bounds for these two quantities, and demonstrate their\nrelevance empirically. First, we find that under the conditions of our\nframework, alignment can be guaranteed with representation engineering, and at\nthe same time that helpfulness is harmed in the process. Second, we show that\nhelpfulness is harmed quadratically with the norm of the representation\nengineering vector, while the alignment increases linearly with it, indicating\na regime in which it is efficient to use representation engineering. We\nvalidate our findings empirically, and chart the boundaries to the usefulness\nof representation engineering for alignment.",
      "tldr_zh": "该论文探讨了在语言模型中使用 representation engineering 进行 alignment（对齐）时，与 helpfulness（帮助性）之间的权衡问题。作者提出一个理论框架，提供 alignment 提升和 helpfulness 降低的界限，并通过实验验证了其相关性。研究发现，representation engineering 可以保证 alignment 的线性增加，但会导致 helpfulness 与工程向量范数成二次方下降，从而识别出高效应用的特定区域。该框架有助于指导 representation engineering 在实际模型优化中的应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.16332v4",
      "published_date": "2024-01-29 17:38:14 UTC",
      "updated_date": "2024-10-03 13:40:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:04:12.664854"
    },
    {
      "arxiv_id": "2402.14021v1",
      "title": "Betting on what is neither verifiable nor falsifiable",
      "title_zh": "投注于既不可验证也不可证伪的事物",
      "authors": [
        "Abhimanyu Pallavi Sudhir",
        "Long Tran-Thanh"
      ],
      "abstract": "Prediction markets are useful for estimating probabilities of claims whose\ntruth will be revealed at some fixed time -- this includes questions about the\nvalues of real-world events (i.e. statistical uncertainty), and questions about\nthe values of primitive recursive functions (i.e. logical or algorithmic\nuncertainty). However, they cannot be directly applied to questions without a\nfixed resolution criterion, and real-world applications of prediction markets\nto such questions often amount to predicting not whether a sentence is true,\nbut whether it will be proven. Such questions could be represented by countable\nunions or intersections of more basic events, or as First-Order-Logic sentences\non the Arithmetical Hierarchy (or even beyond FOL, as hyperarithmetical\nsentences). In this paper, we propose an approach to betting on such events via\noptions, or equivalently as bets on the outcome of a\n\"verification-falsification game\". Our work thus acts as an alternative to the\nexisting framework of Garrabrant induction for logical uncertainty, and relates\nto the stance known as constructivism in the philosophy of mathematics;\nfurthermore it has broader implications for philosophy and mathematical logic.",
      "tldr_zh": "该论文探讨了预测市场（prediction markets）在处理不可验证或不可证伪声明时的局限性，这些声明包括可数联合事件或 First-Order-Logic 句子上的问题，而非固定分辨标准的真实事件。作者提出一种新方法，通过期权（options）或“verification-falsification game”来实现对这些事件的下注，从而解决逻辑不确定性（logical uncertainty）。这一方法作为 Garrabrant induction 的替代方案，与数学哲学中的建构主义（constructivism）相关，并为哲学和数学逻辑领域提供了更广泛的启示。实验和理论分析表明，此框架扩展了预测市场的应用潜力。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.LO",
        "91B26 (Primary), 03F03 (Secondary)",
        "F.4.1; I.2.11"
      ],
      "primary_category": "cs.GT",
      "comment": "15 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.14021v1",
      "published_date": "2024-01-29 17:30:34 UTC",
      "updated_date": "2024-01-29 17:30:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:04:25.042533"
    },
    {
      "arxiv_id": "2402.01744v4",
      "title": "Unveiling Molecular Moieties through Hierarchical Grad-CAM Graph Explainability",
      "title_zh": "通过分层 Grad-CAM 图解释性揭示分子片",
      "authors": [
        "Salvatore Contino",
        "Paolo Sortino",
        "Maria Rita Gulotta",
        "Ugo Perricone",
        "Roberto Pirrone"
      ],
      "abstract": "Background: Virtual Screening (VS) has become an essential tool in drug\ndiscovery, enabling the rapid and cost-effective identification of potential\nbioactive molecules. Among recent advancements, Graph Neural Networks (GNNs)\nhave gained prominence for their ability to model complex molecular structures\nusing graph-based representations. However, the integration of explainable\nmethods to elucidate the specific contributions of molecular substructures to\nbiological activity remains a significant challenge. This limitation hampers\nboth the interpretability of predictive models and the rational design of novel\ntherapeutics.\\\\ Results: We trained 20 GNN models on a dataset of small\nmolecules with the goal of predicting their activity on 20 distinct protein\ntargets from the Kinase family. These classifiers achieved state-of-the-art\nperformance in virtual screening tasks, demonstrating high accuracy and\nrobustness on different targets. Building upon these models, we implemented the\nHierarchical Grad-CAM graph Explainer (HGE) framework, enabling an in-depth\nanalysis of the molecular moieties driving protein-ligand binding\nstabilization. HGE exploits Grad-CAM explanations at the atom, ring, and\nwhole-molecule levels, leveraging the message-passing mechanism to highlight\nthe most relevant chemical moieties. Validation against experimental data from\nthe literature confirmed the ability of the explainer to recognize a molecular\npattern of drugs and correctly annotate them to the known target. Conclusion:\nOur approach may represent a valid support to shorten both the screening and\nthe hit discovery process. Detailed knowledge of the molecular substructures\nthat play a role in the binding process can help the computational chemist to\ngain insights into the structure optimization, as well as in drug repurposing\ntasks.",
      "tldr_zh": "这篇论文针对虚拟筛选（Virtual Screening, VS）中的解释性挑战，训练了20个Graph Neural Networks (GNNs)模型来预测小分子对激酶家族蛋白靶点的活性，这些模型在预测任务中表现出色。作者开发了Hierarchical Grad-CAM graph Explainer (HGE)框架，利用Grad-CAM在原子、环和整个分子级别分析分子部分对蛋白-配体结合的影响，从而突出关键化学结构。实验验证显示，HGE能准确识别分子模式并与文献数据一致，最终有助于加速药物筛选过程、结构优化和药物再利用。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG",
        "q-bio.MN"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01744v4",
      "published_date": "2024-01-29 17:23:25 UTC",
      "updated_date": "2025-04-17 12:16:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:04:39.663791"
    },
    {
      "arxiv_id": "2401.16318v2",
      "title": "Defining and Extracting generalizable interaction primitives from DNNs",
      "title_zh": "翻译失败",
      "authors": [
        "Lu Chen",
        "Siyu Lou",
        "Benhao Huang",
        "Quanshi Zhang"
      ],
      "abstract": "Faithfully summarizing the knowledge encoded by a deep neural network (DNN)\ninto a few symbolic primitive patterns without losing much information\nrepresents a core challenge in explainable AI. To this end, Ren et al. (2024)\nhave derived a series of theorems to prove that the inference score of a DNN\ncan be explained as a small set of interactions between input variables.\nHowever, the lack of generalization power makes it still hard to consider such\ninteractions as faithful primitive patterns encoded by the DNN. Therefore,\ngiven different DNNs trained for the same task, we develop a new method to\nextract interactions that are shared by these DNNs. Experiments show that the\nextracted interactions can better reflect common knowledge shared by different\nDNNs.",
      "tldr_zh": "这篇论文针对可解释AI的核心挑战，提出了一种从深度神经网络(DNNs)中定义和提取可泛化交互原语的方法，以忠实总结DNN编码的知识。基于Ren et al. (2024)的理论，该方法通过分析为同一任务训练的不同DNNs，提取共享的交互模式，从而提升这些交互的泛化能力。实验结果表明，提取的交互原语更能准确反映不同DNNs的共同知识。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.16318v2",
      "published_date": "2024-01-29 17:21:41 UTC",
      "updated_date": "2024-09-13 12:27:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:04:49.489919"
    },
    {
      "arxiv_id": "2402.01743v1",
      "title": "The Reasoning Under Uncertainty Trap: A Structural AI Risk",
      "title_zh": "不确定性下推理的陷阱：一种结构性的 AI 风险",
      "authors": [
        "Toby D. Pilditch"
      ],
      "abstract": "This report examines a novel risk associated with current (and projected) AI\ntools. Making effective decisions about future actions requires us to reason\nunder uncertainty (RUU), and doing so is essential to many critical real world\nproblems. Overfaced by this challenge, there is growing demand for AI tools\nlike LLMs to assist decision-makers. Having evidenced this demand and the\nincentives behind it, we expose a growing risk: we 1) do not currently\nsufficiently understand LLM capabilities in this regard, and 2) have no\nguarantees of performance given fundamental computational explosiveness and\ndeep uncertainty constraints on accuracy. This report provides an exposition of\nwhat makes RUU so challenging for both humans and machines, and relates these\ndifficulties to prospective AI timelines and capabilities. Having established\nthis current potential misuse risk, we go on to expose how this seemingly\nadditive risk (more misuse additively contributed to potential harm) in fact\nhas multiplicative properties. Specifically, we detail how this misuse risk\nconnects to a wider network of underlying structural risks (e.g., shifting\nincentives, limited transparency, and feedback loops) to produce non-linear\nharms. We go on to provide a solutions roadmap that targets multiple leverage\npoints in the structure of the problem. This includes recommendations for all\ninvolved actors (prospective users, developers, and policy-makers) and enfolds\ninsights from areas including Decision-making Under Deep Uncertainty and\ncomplex systems theory. We argue this report serves not only to raise awareness\n(and subsequently mitigate/correct) of a current, novel AI risk, but also\nawareness of the underlying class of structural risks by illustrating how their\ninterconnected nature poses twin-dangers of camouflaging their presence, whilst\namplifying their potential effects.",
      "tldr_zh": "这篇报告探讨了 AI 在处理不确定性推理（Reasoning Under Uncertainty, RUU）时的结构性风险，强调当前和未来 AI 工具（如 LLMs）在辅助决策中可能导致的误用问题，因为我们对它们的性能缺乏充分理解，且受计算爆炸性和不确定性约束。报告分析了 RUU 的挑战如何与 AI 时间线和能力相关联，并揭示这种风险具有乘法效应，与更广泛的结构性风险（如激励转移、透明度有限和反馈循环）互动，产生非线性危害。最终，它提供了解决方案路线图，包括针对用户、开发者和政策制定者的建议，融入不确定性决策和复杂系统理论，以提高风险意识并缓解潜在影响。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "51 pages (excluding references), 7 chapters, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.01743v1",
      "published_date": "2024-01-29 17:16:57 UTC",
      "updated_date": "2024-01-29 17:16:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:05:02.705766"
    },
    {
      "arxiv_id": "2401.16310v3",
      "title": "An Insight into Security Code Review with LLMs: Capabilities, Obstacles and Influential Factors",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaxin Yu",
        "Peng Liang",
        "Yujia Fu",
        "Amjed Tahir",
        "Mojtaba Shahin",
        "Chong Wang",
        "Yangxiao Cai"
      ],
      "abstract": "Security code review is a time-consuming and labor-intensive process\ntypically requiring integration with automated security defect detection tools.\nHowever, existing security analysis tools struggle with poor generalization,\nhigh false positive rates, and coarse detection granularity. Large Language\nModels (LLMs) have been considered promising candidates for addressing those\nchallenges. In this study, we conducted an empirical study to explore the\npotential of LLMs in detecting security defects during code review.\nSpecifically, we evaluated the performance of six LLMs under five different\nprompts and compared them with state-of-theart static analysis tools. We also\nperformed linguistic and regression analyses for the best-performing LLM to\nidentify quality problems in its responses and factors influencing its\nperformance. Our findings show that: (1) existing pre-trained LLMs have limited\ncapability in security code review but? significantly outperform the\nstate-of-the-art static analysis tools. (2) GPT-4 performs best among all LLMs\nwhen provided with a CWE list for reference. (3) GPT-4 frequently generates\nresponses that are verbose or not compliant with the task requirements given in\nthe prompts. (4) GPT-4 is more adept at identifying security defects in code\nfiles with fewer tokens, containing functional logic, or written by developers\nwith less involvement in the project.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)在安全代码审查中的能力、障碍和影响因素，旨在解决现有静态分析工具的泛化差、假阳性率高和检测粒度粗等问题。通过实证研究，评估了六种 LLMs 在五种不同提示下的性能，并与最先进的静态分析工具进行比较，同时对表现最佳的 GPT-4 进行了语言和回归分析。研究发现，现有的预训练 LLMs 在安全代码审查中能力有限，但显著优于传统工具。GPT-4 在提供 CWE 列表参考时表现最佳，但经常生成冗长或不遵守任务要求的响应。此外，GPT-4 在处理 token 较少的代码、包含功能逻辑的代码或由项目参与度低的开发者编写的代码时，更擅长识别安全缺陷。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "26 pages, 5 images, 7 tables, Manuscript submitted to a journal\n  (2024)",
      "pdf_url": "http://arxiv.org/pdf/2401.16310v3",
      "published_date": "2024-01-29 17:13:44 UTC",
      "updated_date": "2024-10-04 18:02:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:05:15.953708"
    },
    {
      "arxiv_id": "2401.16299v1",
      "title": "Enhancing Molecular Property Prediction with Auxiliary Learning and Task-Specific Adaptation",
      "title_zh": "通过辅助学习和任务特定适应增强分子属性预测",
      "authors": [
        "Vishal Dey",
        "Xia Ning"
      ],
      "abstract": "Pretrained Graph Neural Networks have been widely adopted for various\nmolecular property prediction tasks. Despite their ability to encode structural\nand relational features of molecules, traditional fine-tuning of such\npretrained GNNs on the target task can lead to poor generalization. To address\nthis, we explore the adaptation of pretrained GNNs to the target task by\njointly training them with multiple auxiliary tasks. This could enable the GNNs\nto learn both general and task-specific features, which may benefit the target\ntask. However, a major challenge is to determine the relatedness of auxiliary\ntasks with the target task. To address this, we investigate multiple strategies\nto measure the relevance of auxiliary tasks and integrate such tasks by\nadaptively combining task gradients or by learning task weights via bi-level\noptimization. Additionally, we propose a novel gradient surgery-based approach,\nRotation of Conflicting Gradients ($\\mathtt{RCGrad}$), that learns to align\nconflicting auxiliary task gradients through rotation. Our experiments with\nstate-of-the-art pretrained GNNs demonstrate the efficacy of our proposed\nmethods, with improvements of up to 7.7% over fine-tuning. This suggests that\nincorporating auxiliary tasks along with target task fine-tuning can be an\neffective way to improve the generalizability of pretrained GNNs for molecular\nproperty prediction.",
      "tldr_zh": "该研究针对预训练 Graph Neural Networks (GNNs) 在分子属性预测中的泛化问题，提出通过辅助学习和任务特定适应来提升模型性能。具体方法包括联合训练多个辅助任务，并采用多种策略（如自适应结合任务梯度或双层优化）来评估和整合任务相关性；同时，引入了新颖的梯度手术方法 Rotation of Conflicting Gradients (RCGrad)，通过旋转对齐冲突梯度。实验结果显示，该方法在最先进的预训练 GNNs 上比传统 fine-tuning 提高了多达 7.7% 的性能，证明了辅助任务在改善分子属性预测泛化能力方面的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.16299v1",
      "published_date": "2024-01-29 17:00:28 UTC",
      "updated_date": "2024-01-29 17:00:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:05:30.522753"
    },
    {
      "arxiv_id": "2401.16298v1",
      "title": "Breaking the Barrier: Selective Uncertainty-based Active Learning for Medical Image Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Siteng Ma",
        "Haochang Wu",
        "Aonghus Lawlor",
        "Ruihai Dong"
      ],
      "abstract": "Active learning (AL) has found wide applications in medical image\nsegmentation, aiming to alleviate the annotation workload and enhance\nperformance. Conventional uncertainty-based AL methods, such as entropy and\nBayesian, often rely on an aggregate of all pixel-level metrics. However, in\nimbalanced settings, these methods tend to neglect the significance of target\nregions, eg., lesions, and tumors. Moreover, uncertainty-based selection\nintroduces redundancy. These factors lead to unsatisfactory performance, and in\nmany cases, even underperform random sampling. To solve this problem, we\nintroduce a novel approach called the Selective Uncertainty-based AL, avoiding\nthe conventional practice of summing up the metrics of all pixels. Through a\nfiltering process, our strategy prioritizes pixels within target areas and\nthose near decision boundaries. This resolves the aforementioned disregard for\ntarget areas and redundancy. Our method showed substantial improvements across\nfive different uncertainty-based methods and two distinct datasets, utilizing\nfewer labeled data to reach the supervised baseline and consistently achieving\nthe highest overall performance. Our code is available at\nhttps://github.com/HelenMa9998/Selective\\_Uncertainty\\_AL.",
      "tldr_zh": "这篇论文针对医疗图像分割中的 Active Learning (AL) 问题，提出了一种新型 Selective Uncertainty-based AL 方法，以解决传统不确定性-based 方法（如 entropy 和 Bayesian）在不平衡设置下忽略目标区域（如病变、肿瘤）和引入冗余的问题。新的方法通过过滤过程优先选择目标区域内的像素和决策边界附近的像素，从而避免了简单汇总所有像素指标的弊端。实验结果显示，该方法在五个不确定性-based 方法和两个数据集上实现了显著改进，使用更少的标注数据就达到监督基线，并 consistently 取得了最高整体性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.16298v1",
      "published_date": "2024-01-29 16:59:39 UTC",
      "updated_date": "2024-01-29 16:59:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:05:41.169699"
    },
    {
      "arxiv_id": "2401.16294v1",
      "title": "Dual feature-based and example-based explanation methods",
      "title_zh": "翻译失败",
      "authors": [
        "Andrei V. Konstantinov",
        "Boris V. Kozlov",
        "Stanislav R. Kirpichenko",
        "Lev V. Utkin"
      ],
      "abstract": "A new approach to the local and global explanation is proposed. It is based\non selecting a convex hull constructed for the finite number of points around\nan explained instance. The convex hull allows us to consider a dual\nrepresentation of instances in the form of convex combinations of extreme\npoints of a produced polytope. Instead of perturbing new instances in the\nEuclidean feature space, vectors of convex combination coefficients are\nuniformly generated from the unit simplex, and they form a new dual dataset. A\ndual linear surrogate model is trained on the dual dataset. The explanation\nfeature importance values are computed by means of simple matrix calculations.\nThe approach can be regarded as a modification of the well-known model LIME.\nThe dual representation inherently allows us to get the example-based\nexplanation. The neural additive model is also considered as a tool for\nimplementing the example-based explanation approach. Many numerical experiments\nwith real datasets are performed for studying the approach. The code of\nproposed algorithms is available.",
      "tldr_zh": "本论文提出了一种新的局部和全局解释方法，基于在解释实例周围构建的凸包（convex hull），通过凸组合表示实例，并生成双重数据集（dual dataset）。该方法从单位单纯形（unit simplex）均匀生成凸组合系数向量，在双重数据集上训练双重线性代理模型（dual linear surrogate model），并通过矩阵计算获取特征重要性值，作为对LIME模型的改进。论文还整合神经加性模型（neural additive model）来实现基于例子的解释（example-based explanation）。通过多项使用真实数据集的数值实验，验证了方法的有效性，并公开了算法代码。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.16294v1",
      "published_date": "2024-01-29 16:53:04 UTC",
      "updated_date": "2024-01-29 16:53:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:05:54.062108"
    },
    {
      "arxiv_id": "2401.16293v1",
      "title": "Textual Entailment for Effective Triple Validation in Object Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Andrés García-Silva",
        "Cristian Berrío",
        "José Manuel Gómez-Pérez"
      ],
      "abstract": "Knowledge base population seeks to expand knowledge graphs with facts that\nare typically extracted from a text corpus. Recently, language models\npretrained on large corpora have been shown to contain factual knowledge that\ncan be retrieved using cloze-style strategies. Such approach enables zero-shot\nrecall of facts, showing competitive results in object prediction compared to\nsupervised baselines. However, prompt-based fact retrieval can be brittle and\nheavily depend on the prompts and context used, which may produce results that\nare unintended or hallucinatory.We propose to use textual entailment to\nvalidate facts extracted from language models through cloze statements. Our\nresults show that triple validation based on textual entailment improves\nlanguage model predictions in different training regimes. Furthermore, we show\nthat entailment-based triple validation is also effective to validate candidate\nfacts extracted from other sources including existing knowledge graphs and text\npassages where named entities are recognized.",
      "tldr_zh": "这篇论文针对知识库填充（knowledge base population）中的对象预测问题，提出使用文本蕴涵（textual entailment）来验证从语言模型通过填空式策略（cloze-style strategies）提取的三元组（triples）。该方法有效缓解了提示依赖和幻觉问题，提高了语言模型在不同训练模式下的预测准确性。实验结果进一步表明，这种基于文本蕴涵的验证机制也能应用于从现有知识图谱和包含命名实体的文本段落中提取的候选事实。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DL"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ISWC'23 - The International Semantic Web Conference",
      "pdf_url": "http://arxiv.org/pdf/2401.16293v1",
      "published_date": "2024-01-29 16:50:56 UTC",
      "updated_date": "2024-01-29 16:50:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:06:05.752990"
    },
    {
      "arxiv_id": "2401.16287v1",
      "title": "GAPS: Geometry-Aware Problem Solver",
      "title_zh": "GAPS：几何感知问题求解器",
      "authors": [
        "Jiaxin Zhang",
        "Yinghui Jiang",
        "Yashar Moshfeghi"
      ],
      "abstract": "Geometry problem solving presents a formidable challenge within the NLP\ncommunity. Existing approaches often rely on models designed for solving math\nword problems, neglecting the unique characteristics of geometry math problems.\nAdditionally, the current research predominantly focuses on geometry\ncalculation problems, while overlooking other essential aspects like proving.\nIn this study, we address these limitations by proposing the Geometry-Aware\nProblem Solver (GAPS) model. GAPS is specifically designed to generate solution\nprograms for geometry math problems of various types with the help of its\nunique problem-type classifier. To achieve this, GAPS treats the solution\nprogram as a composition of operators and operands, segregating their\ngeneration processes. Furthermore, we introduce the geometry elements\nenhancement method, which enhances the ability of GAPS to recognize geometry\nelements accurately. By leveraging these improvements, GAPS showcases\nremarkable performance in resolving geometry math problems. Our experiments\nconducted on the UniGeo dataset demonstrate the superiority of GAPS over the\nstate-of-the-art model, Geoformer. Specifically, GAPS achieves an accuracy\nimprovement of more than 5.3% for calculation tasks and an impressive 41.1% for\nproving tasks. Notably, GAPS achieves an impressive accuracy of 97.5% on\nproving problems, representing a significant advancement in solving geometry\nproving tasks.",
      "tldr_zh": "本研究针对几何问题解决在NLP领域的挑战，提出GAPS（Geometry-Aware Problem Solver）模型，以解决现有方法忽略几何问题的独特特性（如证明任务）的问题。GAPS通过问题类型分类器将解决方案程序分解为操作符和操作数的生成过程，并引入几何元素增强方法，提高了对几何元素的识别准确性。在UniGeo数据集上的实验中，GAPS相较于最先进模型Geoformer，在计算任务上准确率提升超过5.3%，在证明任务上提升41.1%，并达到97.5%的证明任务准确率，展示了其显著优势。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.16287v1",
      "published_date": "2024-01-29 16:48:34 UTC",
      "updated_date": "2024-01-29 16:48:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:06:16.844400"
    },
    {
      "arxiv_id": "2401.16285v1",
      "title": "Capturing Pertinent Symbolic Features for Enhanced Content-Based Misinformation Detection",
      "title_zh": "捕获相关符号特征以增强基于内容的错误信息检测",
      "authors": [
        "Flavio Merenda",
        "José Manuel Gómez-Pérez"
      ],
      "abstract": "Preventing the spread of misinformation is challenging. The detection of\nmisleading content presents a significant hurdle due to its extreme linguistic\nand domain variability. Content-based models have managed to identify deceptive\nlanguage by learning representations from textual data such as social media\nposts and web articles. However, aggregating representative samples of this\nheterogeneous phenomenon and implementing effective real-world applications is\nstill elusive. Based on analytical work on the language of misinformation, this\npaper analyzes the linguistic attributes that characterize this phenomenon and\nhow representative of such features some of the most popular misinformation\ndatasets are. We demonstrate that the appropriate use of pertinent symbolic\nknowledge in combination with neural language models is helpful in detecting\nmisleading content. Our results achieve state-of-the-art performance in\nmisinformation datasets across the board, showing that our approach offers a\nvalid and robust alternative to multi-task transfer learning without requiring\nany additional training data. Furthermore, our results show evidence that\nstructured knowledge can provide the extra boost required to address a complex\nand unpredictable real-world problem like misinformation detection, not only in\nterms of accuracy but also time efficiency and resource utilization.",
      "tldr_zh": "这篇论文分析了误信息的语言属性及其在流行数据集中的代表性，提出了一种结合相关symbolic features与neural language models的检测方法，以提升基于内容的误信息识别能力。该方法无需额外训练数据，即可实现跨数据集的state-of-the-art性能，并证明了结构化知识在处理语言变异性方面的优势。结果显示，该方法不仅提高了准确性，还改善了时间效率和资源利用，提供了比多任务转移学习更鲁棒的替代方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at K-CAP'23: The 12th Knowledge Capture Conference",
      "pdf_url": "http://arxiv.org/pdf/2401.16285v1",
      "published_date": "2024-01-29 16:42:34 UTC",
      "updated_date": "2024-01-29 16:42:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:06:29.461672"
    },
    {
      "arxiv_id": "2401.16282v1",
      "title": "MAPLE: Micro Analysis of Pairwise Language Evolution for Few-Shot Claim Verification",
      "title_zh": "翻译失败",
      "authors": [
        "Xia Zeng",
        "Arkaitz Zubiaga"
      ],
      "abstract": "Claim verification is an essential step in the automated fact-checking\npipeline which assesses the veracity of a claim against a piece of evidence. In\nthis work, we explore the potential of few-shot claim verification, where only\nvery limited data is available for supervision. We propose MAPLE (Micro\nAnalysis of Pairwise Language Evolution), a pioneering approach that explores\nthe alignment between a claim and its evidence with a small seq2seq model and a\nnovel semantic measure. Its innovative utilization of micro language evolution\npath leverages unlabelled pairwise data to facilitate claim verification while\nimposing low demand on data annotations and computing resources. MAPLE\ndemonstrates significant performance improvements over SOTA baselines SEED, PET\nand LLaMA 2 across three fact-checking datasets: FEVER, Climate FEVER, and\nSciFact. Data and code are available here: https://github.com/XiaZeng0223/MAPLE",
      "tldr_zh": "这篇论文提出了 MAPLE，一种用于少样本声明验证（few-shot claim verification）的创新方法，通过一个小 seq2seq 模型和新型语义度量，分析声明与证据之间的对齐。MAPLE 利用微语言演化路径（micro language evolution path）来处理未标记的成对数据，从而减少了对数据注释和计算资源的需求。实验结果显示，MAPLE 在 FEVER、Climate FEVER 和 SciFact 数据集上，显著超过了 SOTA 基线如 SEED、PET 和 LLaMA 2 的性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "accepted by EACL Findings 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.16282v1",
      "published_date": "2024-01-29 16:39:39 UTC",
      "updated_date": "2024-01-29 16:39:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:06:41.011217"
    },
    {
      "arxiv_id": "2402.01742v1",
      "title": "Towards Optimizing the Costs of LLM Usage",
      "title_zh": "翻译失败",
      "authors": [
        "Shivanshu Shekhar",
        "Tanishq Dubey",
        "Koyel Mukherjee",
        "Apoorv Saxena",
        "Atharv Tyagi",
        "Nishanth Kotla"
      ],
      "abstract": "Generative AI and LLMs in particular are heavily used nowadays for various\ndocument processing tasks such as question answering and summarization.\nHowever, different LLMs come with different capabilities for different tasks as\nwell as with different costs, tokenization, and latency. In fact, enterprises\nare already incurring huge costs of operating or using LLMs for their\nrespective use cases.\n  In this work, we propose optimizing the usage costs of LLMs by estimating\ntheir output quality (without actually invoking the LLMs), and then solving an\noptimization routine for the LLM selection to either keep costs under a budget,\nor minimize the costs, in a quality and latency aware manner. We propose a\nmodel to predict the output quality of LLMs on document processing tasks like\nsummarization, followed by an LP rounding algorithm to optimize the selection\nof LLMs. We study optimization problems trading off the quality and costs, both\ntheoretically and empirically. We further propose a sentence simplification\nmodel for reducing the number of tokens in a controlled manner. Additionally,\nwe propose several deterministic heuristics for reducing tokens in a quality\naware manner, and study the related optimization problem of applying the\nheuristics optimizing the quality and cost trade-off. We perform extensive\nempirical validation of our methods on not only enterprise datasets but also on\nopen-source datasets, annotated by us, and show that we perform much better\ncompared to closest baselines. Our methods reduce costs by 40%- 90% while\nimproving quality by 4%-7%. We will release the annotated open source datasets\nto the community for further research and exploration.",
      "tldr_zh": "本研究针对生成AI和LLMs在文档处理任务（如问答和总结）中的高成本问题，提出了一种优化LLMs使用成本的方法，通过预测输出质量（无需实际调用LLMs）并使用LP rounding算法来选择LLMs，从而在质量和延迟aware的情况下控制预算或最小化成本。方法包括构建一个预测LLMs输出质量的模型、提出句子简化模型以及几类确定性启发式方法，以减少令牌数并优化质量-成本权衡。实验结果显示，该方法在企业数据集和开源数据集上比基线方案减少成本40%-90%，同时提高质量4%-7%，并将注释的开源数据集发布以促进进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages + Appendix, Total 12 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.01742v1",
      "published_date": "2024-01-29 16:36:31 UTC",
      "updated_date": "2024-01-29 16:36:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:06:53.671975"
    },
    {
      "arxiv_id": "2402.00065v1",
      "title": "A technical note for the 91-clauses SAT resolution with Indirect QAOA based approach",
      "title_zh": "翻译失败",
      "authors": [
        "Gerard Fleury",
        "Philippe Lacomme"
      ],
      "abstract": "This paper addresses the resolution of the 3-SAT problem using a QAOA-like\napproach. The chosen principle involves modeling the solution ranks of the\n3-SAT problem, which, in this particular case, directly represent a solution.\nThis results in a highly compact circuit with few gates, enabling the modeling\nof large-sized 3-SAT problems. Numerical experimentation demonstrates that the\napproach can solve instances composed of 91 clauses and 20 variables with an\nimplementation based on Qiskit.",
      "tldr_zh": "这篇论文提出了一种基于 Indirect QAOA 的方法，用于解决 3-SAT 问题，通过建模解决方案排名来直接表示解，从而创建高度紧凑的电路，减少门数以处理大型实例。相比传统方法，该方法显著提高了对大规模 3-SAT 问题的适用性。实验结果显示，使用 Qiskit 实现，该方法成功解决了包含 91 个子句和 20 个变量的实例。",
      "categories": [
        "cs.AI",
        "quant-ph"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.00065v1",
      "published_date": "2024-01-29 16:29:35 UTC",
      "updated_date": "2024-01-29 16:29:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:07:04.791119"
    },
    {
      "arxiv_id": "2401.16270v2",
      "title": "Capturing Knowledge Graphs and Rules with Octagon Embeddings",
      "title_zh": "翻译失败",
      "authors": [
        "Victor Charpenay",
        "Steven Schockaert"
      ],
      "abstract": "Region based knowledge graph embeddings represent relations as geometric\nregions. This has the advantage that the rules which are captured by the model\nare made explicit, making it straightforward to incorporate prior knowledge and\nto inspect learned models. Unfortunately, existing approaches are severely\nrestricted in their ability to model relational composition, and hence also\ntheir ability to model rules, thus failing to deliver on the main promise of\nregion based models. With the aim of addressing these limitations, we\ninvestigate regions which are composed of axis-aligned octagons. Such octagons\nare particularly easy to work with, as intersections and compositions can be\nstraightforwardly computed, while they are still sufficiently expressive to\nmodel arbitrary knowledge graphs. Among others, we also show that our octagon\nembeddings can properly capture a non-trivial class of rule bases. Finally, we\nshow that our model achieves competitive experimental results.",
      "tldr_zh": "该论文提出了一种基于轴对齐八边形(octagon embeddings)的知识图嵌入方法，以克服现有region based knowledge graph embeddings在关系组合和规则建模方面的局限性。相比传统方法，该方法通过简单计算交集和组合来显式捕获规则，并能表达任意知识图。实验结果表明，该模型能有效处理非平凡的规则集，并在性能上与竞争模型相当。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted for IJCAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.16270v2",
      "published_date": "2024-01-29 16:18:54 UTC",
      "updated_date": "2024-06-18 15:29:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:07:17.294762"
    },
    {
      "arxiv_id": "2401.16258v1",
      "title": "MosquIoT: A System Based on IoT and Machine Learning for the Monitoring of Aedes aegypti (Diptera: Culicidae)",
      "title_zh": "翻译失败",
      "authors": [
        "Javier Aira",
        "Teresa Olivares Montes",
        "Francisco M. Delicado",
        "Darìo Vezzani"
      ],
      "abstract": "Millions of people around the world are infected with mosquito-borne diseases\neach year. One of the most dangerous species is Aedes aegypti, the main vector\nof viruses such as dengue, yellow fever, chikungunya, and Zika, among others.\nMosquito prevention and eradication campaigns are essential to avoid major\npublic health consequences. In this respect, entomological surveillance is an\nimportant tool. At present, this traditional monitoring tool is executed\nmanually and requires digital transformation to help authorities make better\ndecisions, improve their planning efforts, speed up execution, and better\nmanage available resources. Therefore, new technological tools based on proven\ntechniques need to be designed and developed. However, such tools should also\nbe cost-effective, autonomous, reliable, and easy to implement, and should be\nenabled by connectivity and multi-platform software applications. This paper\npresents the design, development, and testing of an innovative system named\nMosquIoT. It is based on traditional ovitraps with embedded Internet of Things\n(IoT) and Tiny Machine Learning (TinyML) technologies, which enable the\ndetection and quantification of Ae. aegypti eggs. This innovative and promising\nsolution may help dynamically understand the behavior of Ae. aegypti\npopulations in cities, shifting from the current reactive entomological\nmonitoring model to a proactive and predictive digital one.",
      "tldr_zh": "本文提出MosquIoT系统，利用IoT（Internet of Things）和TinyML（Tiny Machine Learning）技术对传统ovitraps进行升级，以监测Aedes aegypti蚊子的卵子数量。系统旨在解决当前手动蚊虫监测的局限性，提供自主、可靠且易于实施的解决方案，帮助动态分析蚊子种群行为。相比传统方法，MosquIoT可实现从反应式监测转向主动预测式模式，提升公共卫生决策效率和资源管理。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.16258v1",
      "published_date": "2024-01-29 16:08:18 UTC",
      "updated_date": "2024-01-29 16:08:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:07:31.032572"
    },
    {
      "arxiv_id": "2402.01741v2",
      "title": "Development and Testing of a Novel Large Language Model-Based Clinical Decision Support Systems for Medication Safety in 12 Clinical Specialties",
      "title_zh": "翻译失败",
      "authors": [
        "Jasmine Chiat Ling Ong",
        "Liyuan Jin",
        "Kabilan Elangovan",
        "Gilbert Yong San Lim",
        "Daniel Yan Zheng Lim",
        "Gerald Gui Ren Sng",
        "Yuhe Ke",
        "Joshua Yi Min Tung",
        "Ryan Jian Zhong",
        "Christopher Ming Yao Koh",
        "Keane Zhi Hao Lee",
        "Xiang Chen",
        "Jack Kian Chng",
        "Aung Than",
        "Ken Junyang Goh",
        "Daniel Shu Wei Ting"
      ],
      "abstract": "Importance: We introduce a novel Retrieval Augmented Generation (RAG)-Large\nLanguage Model (LLM) framework as a Clinical Decision Support Systems (CDSS) to\nsupport safe medication prescription.\n  Objective: To evaluate the efficacy of LLM-based CDSS in correctly\nidentifying medication errors in different patient case vignettes from diverse\nmedical and surgical sub-disciplines, against a human expert panel derived\nground truth. We compared performance for under 2 different CDSS practical\nhealthcare integration modalities: LLM-based CDSS alone (fully autonomous mode)\nvs junior pharmacist + LLM-based CDSS (co-pilot, assistive mode).\n  Design, Setting, and Participants: Utilizing a RAG model with\nstate-of-the-art medically-related LLMs (GPT-4, Gemini Pro 1.0 and Med-PaLM 2),\nthis study used 61 prescribing error scenarios embedded into 23 complex\nclinical vignettes across 12 different medical and surgical specialties. A\nmultidisciplinary expert panel assessed these cases for Drug-Related Problems\n(DRPs) using the PCNE classification and graded severity / potential for harm\nusing revised NCC MERP medication error index. We compared.\n  Results RAG-LLM performed better compared to LLM alone. When employed in a\nco-pilot mode, accuracy, recall, and F1 scores were optimized, indicating\neffectiveness in identifying moderate to severe DRPs. The accuracy of DRP\ndetection with RAG-LLM improved in several categories but at the expense of\nlower precision.\n  Conclusions This study established that a RAG-LLM based CDSS significantly\nboosts the accuracy of medication error identification when used alongside\njunior pharmacists (co-pilot), with notable improvements in detecting severe\nDRPs. This study also illuminates the comparative performance of current\nstate-of-the-art LLMs in RAG-based CDSS systems.",
      "tldr_zh": "本研究开发并测试了一个基于 Retrieval Augmented Generation (RAG) 和 Large Language Model (LLM) 的新型 Clinical Decision Support Systems (CDSS)，旨在提升12个临床专业的药物安全处方支持。研究评估了该系统在识别药物相关问题 (DRPs) 方面的效能，使用61个处方错误场景嵌入23个复杂临床案例，并与人类专家标准比较两种模式：完全自主模式和初级药剂师辅助的协同模式 (co-pilot)。结果显示，RAG-LLM 在协同模式下表现优异，提高了准确率、召回率和 F1 分数，尤其在检测中度到严重 DRPs 时，但精确率有所降低。总体结论是，该 CDSS 与初级药剂师结合可显著提升药物错误识别准确性，并突显了不同 LLM（如 GPT-4 和 Med-PaLM 2）的比较性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01741v2",
      "published_date": "2024-01-29 16:03:29 UTC",
      "updated_date": "2024-02-17 21:13:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:07:43.221791"
    },
    {
      "arxiv_id": "2401.16251v3",
      "title": "Cross-silo Federated Learning with Record-level Personalized Differential Privacy",
      "title_zh": "翻译失败",
      "authors": [
        "Junxu Liu",
        "Jian Lou",
        "Li Xiong",
        "Jinfei Liu",
        "Xiaofeng Meng"
      ],
      "abstract": "Federated learning (FL) enhanced by differential privacy has emerged as a\npopular approach to better safeguard the privacy of client-side data by\nprotecting clients' contributions during the training process. Existing\nsolutions typically assume a uniform privacy budget for all records and provide\none-size-fits-all solutions that may not be adequate to meet each record's\nprivacy requirement. In this paper, we explore the uncharted territory of\ncross-silo FL with record-level personalized differential privacy. We devise a\nnovel framework named \\textit{rPDP-FL}, employing a two-stage hybrid sampling\nscheme with both uniform client-level sampling and non-uniform record-level\nsampling to accommodate varying privacy requirements.\n  A critical and non-trivial problem is how to determine the ideal per-record\nsampling probability $q$ given the personalized privacy budget $\\varepsilon$.\nWe introduce a versatile solution named \\textit{Simulation-CurveFitting},\nallowing us to uncover a significant insight into the nonlinear correlation\nbetween $q$ and $\\varepsilon$ and derive an elegant mathematical model to\ntackle the problem. Our evaluation demonstrates that our solution can provide\nsignificant performance gains over the baselines that do not consider\npersonalized privacy preservation.",
      "tldr_zh": "该论文探讨了跨库联邦学习（Cross-silo Federated Learning）中记录级个性化差分隐私（Record-level Personalized Differential Privacy），以解决现有方法忽略记录间隐私需求差异的问题。作者提出了一种名为 rPDP-FL 的框架，采用两阶段混合采样方案，包括统一客户端级采样和非统一记录级采样，以适应个性化隐私预算。论文引入 Simulation-CurveFitting 方法，揭示采样概率 q 与隐私预算 ε 之间的非线性相关性，并通过数学模型优化了该过程；实验结果显示，该方法相较于不考虑个性化隐私的基线，实现了显著的性能提升。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "15 pages, 8 figures, accepted by CCS'2024",
      "pdf_url": "http://arxiv.org/pdf/2401.16251v3",
      "published_date": "2024-01-29 16:01:46 UTC",
      "updated_date": "2024-06-29 14:58:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:07:54.742858"
    },
    {
      "arxiv_id": "2402.01740v3",
      "title": "Reducing Selection Bias in Large Language Models",
      "title_zh": "在大型语言模型中减少选择偏差",
      "authors": [
        "J. E. Eicher",
        "R. F. Irgolič"
      ],
      "abstract": "Large Language Models (LLMs) like gpt-3.5-turbo-0613 and claude-instant-1.2\nare vital in interpreting and executing semantic tasks. Unfortunately, these\nmodels' inherent biases adversely affect their performance Particularly\naffected is object selection from lists; a fundamental operation in digital\nnavigation and decision-making. This research critically examines these biases\nand quantifies the effects on a representative list selection task. To explore\nthese biases, we experiment manipulating temperature, list length, object\nidentity, object type, prompt complexity, and model. We isolated and measured\nthe influence of the biases on selection behavior. Our findings show that bias\nstructure is strongly dependent on the model, with object type modulating the\nmagnitude of the effect. With a strong primacy effect, causing the first\nobjects in a list to be disproportionately represented in outputs. The usage of\nguard rails, a prompt engineering method of ensuring a response structure,\nincreases bias and decreases instruction adherence when to a selection task.\nThe bias is ablated when the guard rail step is separated from the list\nsampling step, lowering the complexity of each individual task. We provide LLM\napplications and theoretically suggest that LLMs experience a form of cognitive\nload that is compensated for with bias.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）如 GPT-3.5 和 Claude 在对象选择任务中的选择偏差问题，这些偏差会导致列表中对象（如首位效应）被过度选择，并影响模型性能。研究通过实验操纵温度、列表长度、对象身份、对象类型、提示复杂性和模型等因素，量化了偏差的影响，发现偏差强烈依赖于模型和对象类型，使用守 rails（提示工程方法）会加剧偏差并降低指令遵守性。作者建议将guard rails步骤与列表采样步骤分离，以降低任务复杂性并减少偏差，并理论上提出LLMs可能因认知负载而产生补偿性偏差，为改进LLMs应用提供实用指导。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.0"
      ],
      "primary_category": "cs.CL",
      "comment": "28 pages, 23 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.01740v3",
      "published_date": "2024-01-29 15:43:23 UTC",
      "updated_date": "2024-06-15 13:23:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:08:07.303718"
    },
    {
      "arxiv_id": "2401.16240v2",
      "title": "Combining Hierachical VAEs with LLMs for clinically meaningful timeline summarisation in social media",
      "title_zh": "翻译失败",
      "authors": [
        "Jiayu Song",
        "Jenny Chim",
        "Adam Tsakalidis",
        "Julia Ive",
        "Dana Atzil-Slonim",
        "Maria Liakata"
      ],
      "abstract": "We introduce a hybrid abstractive summarisation approach combining\nhierarchical VAE with LLMs (LlaMA-2) to produce clinically meaningful summaries\nfrom social media user timelines, appropriate for mental health monitoring. The\nsummaries combine two different narrative points of view: clinical insights in\nthird person useful for a clinician are generated by feeding into an LLM\nspecialised clinical prompts, and importantly, a temporally sensitive\nabstractive summary of the user's timeline in first person, generated by a\nnovel hierarchical variational autoencoder, TH-VAE. We assess the generated\nsummaries via automatic evaluation against expert summaries and via human\nevaluation with clinical experts, showing that timeline summarisation by TH-VAE\nresults in more factual and logically coherent summaries rich in clinical\nutility and superior to LLM-only approaches in capturing changes over time.",
      "tldr_zh": "该研究提出了一种结合 Hierarchical VAEs 和 LLMs（LlaMA-2）的混合抽象总结方法，用于从社交媒体用户时间线生成临床相关的总结，以支持心理健康监测。方法包括使用新型 Hierarchical VAE（TH-VAE）生成第一人称的时序敏感摘要，以及通过 LLM 响应专业临床提示产生第三人称的临床见解。实验结果显示，这种方法生成的总结在事实性和逻辑连贯性上优于纯 LLM 方案，更好地捕捉时间变化，并经由自动评估和临床专家的人类评估证实其临床实用价值。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.16240v2",
      "published_date": "2024-01-29 15:42:57 UTC",
      "updated_date": "2024-02-16 12:42:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:08:18.092835"
    },
    {
      "arxiv_id": "2401.16215v1",
      "title": "Learning big logical rules by joining small rules",
      "title_zh": "翻译失败",
      "authors": [
        "Céline Hocquette",
        "Andreas Niskanen",
        "Rolf Morel",
        "Matti Järvisalo",
        "Andrew Cropper"
      ],
      "abstract": "A major challenge in inductive logic programming is learning big rules. To\naddress this challenge, we introduce an approach where we join small rules to\nlearn big rules. We implement our approach in a constraint-driven system and\nuse constraint solvers to efficiently join rules. Our experiments on many\ndomains, including game playing and drug design, show that our approach can (i)\nlearn rules with more than 100 literals, and (ii) drastically outperform\nexisting approaches in terms of predictive accuracies.",
      "tldr_zh": "本论文针对归纳逻辑编程(inductive logic programming)中学习大规则的挑战，提出了一种通过连接小规则来学习大规则的方法。\n该方法在约束驱动系统(constraint-driven system)中实现，并利用约束求解器(constraint solvers)来高效地连接规则。\n实验结果显示，该方法能在游戏和药物设计等领域学习超过100个字面的规则，并在预测准确性上大幅超过现有方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.16215v1",
      "published_date": "2024-01-29 15:09:40 UTC",
      "updated_date": "2024-01-29 15:09:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:08:30.700082"
    },
    {
      "arxiv_id": "2401.16209v1",
      "title": "MultiMUC: Multilingual Template Filling on MUC-4",
      "title_zh": "翻译失败",
      "authors": [
        "William Gantt",
        "Shabnam Behzad",
        "Hannah YoungEun An",
        "Yunmo Chen",
        "Aaron Steven White",
        "Benjamin Van Durme",
        "Mahsa Yarmohammadi"
      ],
      "abstract": "We introduce MultiMUC, the first multilingual parallel corpus for template\nfilling, comprising translations of the classic MUC-4 template filling\nbenchmark into five languages: Arabic, Chinese, Farsi, Korean, and Russian. We\nobtain automatic translations from a strong multilingual machine translation\nsystem and manually project the original English annotations into each target\nlanguage. For all languages, we also provide human translations for sentences\nin the dev and test splits that contain annotated template arguments. Finally,\nwe present baselines on MultiMUC both with state-of-the-art template filling\nmodels and with ChatGPT.",
      "tldr_zh": "本文引入MultiMUC，这是第一个多语言平行语料库，用于template filling任务，将经典的MUC-4基准翻译成阿拉伯语、中文、波斯语、韩语和俄语。翻译过程采用强有力的multilingual machine translation系统自动完成，并通过手动投影原始英文标注到目标语言；对于dev和test集中的包含annotated template arguments的句子，还提供了人工翻译。最终，作者在MultiMUC上进行了baselines测试，使用state-of-the-art template filling模型和ChatGPT，以评估其性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.16209v1",
      "published_date": "2024-01-29 15:02:24 UTC",
      "updated_date": "2024-01-29 15:02:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:08:43.467603"
    },
    {
      "arxiv_id": "2401.16198v1",
      "title": "Contracting with a Learning Agent",
      "title_zh": "翻译失败",
      "authors": [
        "Guru Guruganesh",
        "Yoav Kolumbus",
        "Jon Schneider",
        "Inbal Talgam-Cohen",
        "Emmanouil-Vasileios Vlatakis-Gkaragkounis",
        "Joshua R. Wang",
        "S. Matthew Weinberg"
      ],
      "abstract": "Many real-life contractual relations differ completely from the clean, static\nmodel at the heart of principal-agent theory. Typically, they involve repeated\nstrategic interactions of the principal and agent, taking place under\nuncertainty and over time. While appealing in theory, players seldom use\ncomplex dynamic strategies in practice, often preferring to circumvent\ncomplexity and approach uncertainty through learning. We initiate the study of\nrepeated contracts with a learning agent, focusing on agents who achieve\nno-regret outcomes.\n  Optimizing against a no-regret agent is a known open problem in general\ngames; we achieve an optimal solution to this problem for a canonical contract\nsetting, in which the agent's choice among multiple actions leads to\nsuccess/failure. The solution has a surprisingly simple structure: for some\n$\\alpha > 0$, initially offer the agent a linear contract with scalar $\\alpha$,\nthen switch to offering a linear contract with scalar $0$. This switch causes\nthe agent to ``free-fall'' through their action space and during this time\nprovides the principal with non-zero reward at zero cost. Despite apparent\nexploitation of the agent, this dynamic contract can leave \\emph{both} players\nbetter off compared to the best static contract. Our results generalize beyond\nsuccess/failure, to arbitrary non-linear contracts which the principal rescales\ndynamically.\n  Finally, we quantify the dependence of our results on knowledge of the time\nhorizon, and are the first to address this consideration in the study of\nstrategizing against learning agents.",
      "tldr_zh": "这篇论文探讨了现实委托代理合同的动态特性，强调代理人通过学习实现无后悔(no-regret)结果，而非使用复杂策略。研究提出了一种优化策略：在经典成功/失败合同设置中，初始提供带有标量 α > 0 的线性合同，然后切换到标量 0 的合同，使代理人“自由落体”并为委托人带来非零回报。结果显示，这种动态合同可使双方比最佳静态合同受益，并推广到任意非线性合同，同时首次量化了时间地平线对策略的影响。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.LG",
        "econ.TH"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.16198v1",
      "published_date": "2024-01-29 14:53:22 UTC",
      "updated_date": "2024-01-29 14:53:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:08:55.060833"
    },
    {
      "arxiv_id": "2401.16190v1",
      "title": "AI prediction of cardiovascular events using opportunistic epicardial adipose tissue assessments from CT calcium score",
      "title_zh": "翻译失败",
      "authors": [
        "Tao Hu",
        "Joshua Freeze",
        "Prerna Singh",
        "Justin Kim",
        "Yingnan Song",
        "Hao Wu",
        "Juhwan Lee",
        "Sadeer Al-Kindi",
        "Sanjay Rajagopalan",
        "David L. Wilson",
        "Ammar Hoori"
      ],
      "abstract": "Background: Recent studies have used basic epicardial adipose tissue (EAT)\nassessments (e.g., volume and mean HU) to predict risk of\natherosclerosis-related, major adverse cardiovascular events (MACE).\nObjectives: Create novel, hand-crafted EAT features, 'fat-omics', to capture\nthe pathophysiology of EAT and improve MACE prediction. Methods: We segmented\nEAT using a previously-validated deep learning method with optional manual\ncorrection. We extracted 148 radiomic features (morphological, spatial, and\nintensity) and used Cox elastic-net for feature reduction and prediction of\nMACE. Results: Traditional fat features gave marginal prediction\n(EAT-volume/EAT-mean-HU/ BMI gave C-index 0.53/0.55/0.57, respectively).\nSignificant improvement was obtained with 15 fat-omics features (C-index=0.69,\ntest set). High-risk features included\nvolume-of-voxels-having-elevated-HU-[-50, -30-HU] and HU-negative-skewness,\nboth of which assess high HU, which as been implicated in fat inflammation.\nOther high-risk features include kurtosis-of-EAT-thickness, reflecting the\nheterogeneity of thicknesses, and EAT-volume-in-the-top-25%-of-the-heart,\nemphasizing adipose near the proximal coronary arteries. Kaplan-Meyer plots of\nCox-identified, high- and low-risk patients were well separated with the median\nof the fat-omics risk, while high-risk group having HR 2.4 times that of the\nlow-risk group (P<0.001). Conclusion: Preliminary findings indicate an\nopportunity to use more finely tuned, explainable assessments on EAT for\nimproved cardiovascular risk prediction.",
      "tldr_zh": "本研究旨在通过创建新型的“fat-omics”特征来改善心血管事件（MACE）的预测，利用CT钙评分中的epicardial adipose tissue (EAT)评估。研究者使用深度学习方法分割EAT，并提取148个辐射组学特征（包括形态、空间和强度特征），随后采用Cox elastic-net模型进行特征筛选和MACE预测。结果显示，传统EAT特征（如体积和平均HU）的预测性能有限（C-index为0.53-0.57），而fat-omics特征显著提升了准确性（C-index达0.69测试集），并识别出高风险指标如volume-of-voxels-having-elevated-HU-[-50, -30-HU]和HU-negative-skewness。初步结论表明，这种更精细、可解释的EAT评估方法为心血管风险预测提供了新机遇。",
      "categories": [
        "q-bio.QM",
        "cs.AI"
      ],
      "primary_category": "q-bio.QM",
      "comment": "7 pages, 1 central illustration, 6 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2401.16190v1",
      "published_date": "2024-01-29 14:42:06 UTC",
      "updated_date": "2024-01-29 14:42:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:09:08.320996"
    },
    {
      "arxiv_id": "2401.16462v1",
      "title": "Supervised Contrastive Learning based Dual-Mixer Model for Remaining Useful Life Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "En Fu",
        "Yanyan Hu",
        "Kaixiang Peng",
        "Yuxin Chu"
      ],
      "abstract": "The problem of the Remaining Useful Life (RUL) prediction, aiming at\nproviding an accurate estimate of the remaining time from the current\npredicting moment to the complete failure of the device, has gained significant\nattention from researchers in recent years. In this paper, to overcome the\nshortcomings of rigid combination for temporal and spatial features in most\nexisting RUL prediction approaches, a spatial-temporal homogeneous feature\nextractor, named Dual-Mixer model, is firstly proposed. Flexible layer-wise\nprogressive feature fusion is employed to ensure the homogeneity of\nspatial-temporal features and enhance the prediction accuracy. Secondly, the\nFeature Space Global Relationship Invariance (FSGRI) training method is\nintroduced based on supervised contrastive learning. This method maintains the\nconsistency of relationships among sample features with their degradation\npatterns during model training, simplifying the subsequently regression task in\nthe output layer and improving the model's performance in RUL prediction.\nFinally, the effectiveness of the proposed method is validated through\ncomparisons with other latest research works on the C-MAPSS dataset. The\nDual-Mixer model demonstrates superiority across most metrics, while the FSGRI\ntraining method shows an average improvement of 7.00% and 2.41% in RMSE and\nMAPE, respectively, for all baseline models. Our experiments and model code are\npublicly available at https://github.com/fuen1590/PhmDeepLearningProjects.",
      "tldr_zh": "这篇论文针对 Remaining Useful Life (RUL) 预测问题，提出了一种基于 Supervised Contrastive Learning 的 Dual-Mixer 模型，以精确估计设备从当前时刻到完全失效的剩余时间。Dual-Mixer 模型作为一种空间-时间同质特征提取器，通过灵活的层级式渐进特征融合，确保空间和时间特征的均匀性，从而提升预测准确性。同时，引入 Feature Space Global Relationship Invariance (FSGRI) 训练方法，利用监督对比学习维护样本特征与退化模式的关系一致性，简化后续回归任务并优化模型性能。在 C-MAPSS 数据集上的实验显示，Dual-Mixer 模型在大多数指标上优于现有方法，而 FSGRI 训练方法使基线模型的 RMSE 和 MAPE 平均改善 7.00% 和 2.41%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.16462v1",
      "published_date": "2024-01-29 14:38:44 UTC",
      "updated_date": "2024-01-29 14:38:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:09:19.445781"
    },
    {
      "arxiv_id": "2401.16186v1",
      "title": "An Empirical Study on Usage and Perceptions of LLMs in a Software Engineering Project",
      "title_zh": "翻译失败",
      "authors": [
        "Sanka Rasnayaka",
        "Guanlin Wang",
        "Ridwan Shariffdeen",
        "Ganesh Neelakanta Iyer"
      ],
      "abstract": "Large Language Models (LLMs) represent a leap in artificial intelligence,\nexcelling in tasks using human language(s). Although the main focus of\ngeneral-purpose LLMs is not code generation, they have shown promising results\nin the domain. However, the usefulness of LLMs in an academic software\nengineering project has not been fully explored yet. In this study, we explore\nthe usefulness of LLMs for 214 students working in teams consisting of up to\nsix members. Notably, in the academic course through which this study is\nconducted, students were encouraged to integrate LLMs into their development\ntool-chain, in contrast to most other academic courses that explicitly prohibit\nthe use of LLMs.\n  In this paper, we analyze the AI-generated code, prompts used for code\ngeneration, and the human intervention levels to integrate the code into the\ncode base. We also conduct a perception study to gain insights into the\nperceived usefulness, influencing factors, and future outlook of LLM from a\ncomputer science student's perspective. Our findings suggest that LLMs can play\na crucial role in the early stages of software development, especially in\ngenerating foundational code structures, and helping with syntax and error\ndebugging. These insights provide us with a framework on how to effectively\nutilize LLMs as a tool to enhance the productivity of software engineering\nstudents, and highlight the necessity of shifting the educational focus toward\npreparing students for successful human-AI collaboration.",
      "tldr_zh": "这篇论文通过实证研究探讨了大型语言模型（LLMs）在软件工程项目中的实际使用和学生感知，涉及214名学生在团队合作中的应用。研究方法包括分析AI生成的代码、用于代码生成的提示，以及人类干预水平，同时开展了对学生有用性、影响因素和未来展望的感知调查。结果表明，LLMs在软件开发的早期阶段（如生成基础代码结构和语法错误调试）发挥关键作用，能显著提升生产力。该研究为有效利用LLMs作为工具提供了框架，并强调教育应转向培养学生的AI-人类协作能力。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "D.2.3"
      ],
      "primary_category": "cs.SE",
      "comment": "8 pages, 6 figures, accepted for publication at the LLM4Code workshop\n  @ ICSE 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.16186v1",
      "published_date": "2024-01-29 14:32:32 UTC",
      "updated_date": "2024-01-29 14:32:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:09:33.865838"
    },
    {
      "arxiv_id": "2401.16185v3",
      "title": "LLM4Vuln: A Unified Evaluation Framework for Decoupling and Enhancing LLMs' Vulnerability Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Yuqiang Sun",
        "Daoyuan Wu",
        "Yue Xue",
        "Han Liu",
        "Wei Ma",
        "Lyuye Zhang",
        "Yang Liu",
        "Yingjiu Li"
      ],
      "abstract": "Large language models (LLMs) have demonstrated significant potential in\nvarious tasks, including those requiring human-level intelligence, such as\nvulnerability detection. However, recent efforts to use LLMs for vulnerability\ndetection remain preliminary, as they lack a deep understanding of whether a\nsubject LLM's vulnerability reasoning capability stems from the model itself or\nfrom external aids such as knowledge retrieval and tooling support.\n  In this paper, we aim to decouple LLMs' vulnerability reasoning from other\ncapabilities, such as vulnerability knowledge adoption, context information\nretrieval, and advanced prompt schemes. We introduce LLM4Vuln, a unified\nevaluation framework that separates and assesses LLMs' vulnerability reasoning\ncapabilities and examines improvements when combined with other enhancements.\n  We conduct controlled experiments using 147 ground-truth vulnerabilities and\n147 non-vulnerable cases in Solidity, Java and C/C++, testing them in a total\nof 3,528 scenarios across four LLMs (GPT-3.5, GPT-4, Phi-3, and Llama 3). Our\nfindings reveal the varying impacts of knowledge enhancement, context\nsupplementation, and prompt schemes. We also identify 14 zero-day\nvulnerabilities in four pilot bug bounty programs, resulting in $3,576 in\nbounties.",
      "tldr_zh": "该研究提出LLM4Vuln，一种统一的评估框架，用于分离和增强大型语言模型（LLMs）的漏洞推理能力，旨在区分模型自身的推理能力与外部辅助（如知识检索和提示方案）的贡献。框架通过控制实验测试了147个真实漏洞和147个非漏洞案例，共计3528个场景，涉及GPT-3.5、GPT-4、Phi-3和Llama 3等模型。结果显示，知识增强、上下文补充和提示方案对推理能力有不同影响，并成功识别了14个zero-day vulnerabilities，在四个漏洞赏金程序中获得3576美元的bounties。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CR",
      "comment": "This is a technical report by Nanyang Technological University.\n  Updated to support Solidity, Java and C/C++",
      "pdf_url": "http://arxiv.org/pdf/2401.16185v3",
      "published_date": "2024-01-29 14:32:27 UTC",
      "updated_date": "2025-01-13 06:10:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:09:45.229970"
    },
    {
      "arxiv_id": "2401.16182v1",
      "title": "LLaMandement: Large Language Models for Summarization of French Legislative Proposals",
      "title_zh": "翻译失败",
      "authors": [
        "Joseph Gesnouin",
        "Yannis Tannier",
        "Christophe Gomes Da Silva",
        "Hatim Tapory",
        "Camille Brier",
        "Hugo Simon",
        "Raphael Rozenberg",
        "Hermann Woehrel",
        "Mehdi El Yakaabi",
        "Thomas Binder",
        "Guillaume Marie",
        "Emilie Caron",
        "Mathile Nogueira",
        "Thomas Fontas",
        "Laure Puydebois",
        "Marie Theophile",
        "Stephane Morandi",
        "Mael Petit",
        "David Creissac",
        "Pauline Ennouchy",
        "Elise Valetoux",
        "Celine Visade",
        "Severine Balloux",
        "Emmanuel Cortes",
        "Pierre-Etienne Devineau",
        "Ulrich Tan",
        "Esther Mac Namara",
        "Su Yang"
      ],
      "abstract": "This report introduces LLaMandement, a state-of-the-art Large Language Model,\nfine-tuned by the French government and designed to enhance the efficiency and\nefficacy of processing parliamentary sessions (including the production of\nbench memoranda and documents required for interministerial meetings) by\ngenerating neutral summaries of legislative proposals. Addressing the\nadministrative challenges of manually processing a growing volume of\nlegislative amendments, LLaMandement stands as a significant legal\ntechnological milestone, providing a solution that exceeds the scalability of\ntraditional human efforts while matching the robustness of a specialized legal\ndrafter. We release all our fine-tuned models and training data to the\ncommunity.",
      "tldr_zh": "该研究介绍了 LLaMandement，一种由法国政府 fine-tuned 的 Large Language Models，用于生成法国立法提案的中立摘要，以提高议会会议处理的效率，包括制作备忘录和部门间会议文件。LLaMandement 解决了手动处理日益增长的立法修正案的行政挑战，提供了一个可扩展的解决方案，其性能与专业法律起草者的稳健性相当。研究团队还发布了所有 fine-tuned 模型和训练数据，以促进社区共享和进一步发展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "21 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.16182v1",
      "published_date": "2024-01-29 14:23:51 UTC",
      "updated_date": "2024-01-29 14:23:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:09:55.975295"
    },
    {
      "arxiv_id": "2401.16176v1",
      "title": "A Survey on Structure-Preserving Graph Transformers",
      "title_zh": "结构保留图 Transformer 的综述",
      "authors": [
        "Van Thuy Hoang",
        "O-Joun Lee"
      ],
      "abstract": "The transformer architecture has shown remarkable success in various domains,\nsuch as natural language processing and computer vision. When it comes to graph\nlearning, transformers are required not only to capture the interactions\nbetween pairs of nodes but also to preserve graph structures connoting the\nunderlying relations and proximity between them, showing the expressive power\nto capture different graph structures. Accordingly, various\nstructure-preserving graph transformers have been proposed and widely used for\nvarious tasks, such as graph-level tasks in bioinformatics and\nchemoinformatics. However, strategies related to graph structure preservation\nhave not been well organized and systematized in the literature. In this paper,\nwe provide a comprehensive overview of structure-preserving graph transformers\nand generalize these methods from the perspective of their design objective.\nFirst, we divide strategies into four main groups: node feature modulation,\ncontext node sampling, graph rewriting, and transformer architecture\nimprovements. We then further divide the strategies according to the coverage\nand goals of graph structure preservation. Furthermore, we also discuss\nchallenges and future directions for graph transformer models to preserve the\ngraph structure and understand the nature of graphs.",
      "tldr_zh": "这篇论文对结构-preserving graph transformers 进行了全面调查，旨在探讨 Transformer 架构在图学习中的应用，特别是如何保留图结构以捕捉节点间关系和邻近性。作者将结构保留策略分为四大类：node feature modulation、context node sampling、graph rewriting 和 transformer architecture improvements，并根据覆盖范围和目标进一步细分这些方法。论文系统化地概述了这些策略在生物信息学和化学信息学等图级任务中的应用，同时讨论了当前挑战和未来方向，以提升图变换器对图结构的理解和表达能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "12",
      "pdf_url": "http://arxiv.org/pdf/2401.16176v1",
      "published_date": "2024-01-29 14:18:09 UTC",
      "updated_date": "2024-01-29 14:18:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:10:08.087884"
    },
    {
      "arxiv_id": "2401.16157v1",
      "title": "Spatial-Aware Latent Initialization for Controllable Image Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Wenqiang Sun",
        "Teng Li",
        "Zehong Lin",
        "Jun Zhang"
      ],
      "abstract": "Recently, text-to-image diffusion models have demonstrated impressive ability\nto generate high-quality images conditioned on the textual input. However,\nthese models struggle to accurately adhere to textual instructions regarding\nspatial layout information. While previous research has primarily focused on\naligning cross-attention maps with layout conditions, they overlook the impact\nof the initialization noise on the layout guidance. To achieve better layout\ncontrol, we propose leveraging a spatial-aware initialization noise during the\ndenoising process. Specifically, we find that the inverted reference image with\nfinite inversion steps contains valuable spatial awareness regarding the\nobject's position, resulting in similar layouts in the generated images. Based\non this observation, we develop an open-vocabulary framework to customize a\nspatial-aware initialization noise for each layout condition. Without modifying\nother modules except the initialization noise, our approach can be seamlessly\nintegrated as a plug-and-play module within other training-free layout guidance\nframeworks. We evaluate our approach quantitatively and qualitatively on the\navailable Stable Diffusion model and COCO dataset. Equipped with the\nspatial-aware latent initialization, our method significantly improves the\neffectiveness of layout guidance while preserving high-quality content.",
      "tldr_zh": "本文研究了文本到图像扩散模型（text-to-image diffusion models）在处理文本中空间布局信息时的局限性，提出了一种空间感知潜在初始化（Spatial-Aware Latent Initialization）方法来提升图像生成的布局控制。方法通过有限步的反转参考图像生成包含物体位置信息的初始化噪声，并开发了一个开源词汇框架（open-vocabulary framework）来为每个布局条件定制该噪声，作为即插即用模块集成到现有框架中。实验结果显示，该方法在 Stable Diffusion 模型和 COCO 数据集上显著提高了布局指导的有效性，同时保持了高质量图像内容。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.16157v1",
      "published_date": "2024-01-29 13:42:01 UTC",
      "updated_date": "2024-01-29 13:42:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:10:22.447287"
    },
    {
      "arxiv_id": "2401.16144v1",
      "title": "Divide and Conquer: Rethinking the Training Paradigm of Neural Radiance Fields",
      "title_zh": "翻译失败",
      "authors": [
        "Rongkai Ma",
        "Leo Lebrat",
        "Rodrigo Santa Cruz",
        "Gil Avraham",
        "Yan Zuo",
        "Clinton Fookes",
        "Olivier Salvado"
      ],
      "abstract": "Neural radiance fields (NeRFs) have exhibited potential in synthesizing\nhigh-fidelity views of 3D scenes but the standard training paradigm of NeRF\npresupposes an equal importance for each image in the training set. This\nassumption poses a significant challenge for rendering specific views\npresenting intricate geometries, thereby resulting in suboptimal performance.\nIn this paper, we take a closer look at the implications of the current\ntraining paradigm and redesign this for more superior rendering quality by\nNeRFs. Dividing input views into multiple groups based on their visual\nsimilarities and training individual models on each of these groups enables\neach model to specialize on specific regions without sacrificing speed or\nefficiency. Subsequently, the knowledge of these specialized models is\naggregated into a single entity via a teacher-student distillation paradigm,\nenabling spatial efficiency for online render-ing. Empirically, we evaluate our\nnovel training framework on two publicly available datasets, namely NeRF\nsynthetic and Tanks&Temples. Our evaluation demonstrates that our DaC training\npipeline enhances the rendering quality of a state-of-the-art baseline model\nwhile exhibiting convergence to a superior minimum.",
      "tldr_zh": "本论文重新审视了 Neural Radiance Fields (NeRFs) 的标准训练范式，认为其假设所有训练图像同等重要，导致处理复杂几何视图时渲染性能不佳。作者提出 Divide and Conquer 框架，将输入视图基于视觉相似性分组，并在每个组上训练单独的模型，使其专注于特定区域，同时保持速度和效率。随后，通过 teacher-student distillation 范式聚合这些模型的知识，形成一个空间高效的实体，支持在线渲染。实验在 NeRF synthetic 和 Tanks&Temples 数据集上验证，该方法显著提升了基线模型的渲染质量，并实现了更优的收敛性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.16144v1",
      "published_date": "2024-01-29 13:23:34 UTC",
      "updated_date": "2024-01-29 13:23:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:10:33.433609"
    },
    {
      "arxiv_id": "2401.16137v1",
      "title": "X-PEFT: eXtremely Parameter-Efficient Fine-Tuning for Extreme Multi-Profile Scenarios",
      "title_zh": "翻译失败",
      "authors": [
        "Namju Kwak",
        "Taesup Kim"
      ],
      "abstract": "Parameter-efficient fine-tuning (PEFT) techniques, such as adapter tuning,\naim to fine-tune a pre-trained language model (PLM) using a minimal number of\nparameters for a specific task or profile. Although adapter tuning provides\nincreased parameter efficiency compared to full-model fine-tuning, it\nintroduces a small set of additional parameters attached to a PLM for each\nprofile. This can become problematic in practical applications with multiple\nprofiles, particularly when a significant increase in the number of profiles\nlinearly boosts the total number of additional parameters. To mitigate this\nissue, we introduce X-PEFT, a novel PEFT method that leverages a multitude of\ngiven adapters by fine-tuning an extremely small set of compact tensors for a\nnew profile, which serve as binary masks to adaptively select the given\nadapters. To efficiently validate our proposed method, we implement it using a\nlarge number of trained or untrained (random) adapters. We evaluate the\nperformance of X-PEFT through LaMP and GLUE tasks and demonstrate that it\neither matches or surpasses the effectiveness of conventional adapter tuning,\ndespite reducing the memory requirements per profile by a factor of 10,000\ncompared to it.",
      "tldr_zh": "该研究针对参数高效微调 (PEFT) 技术（如 adapter tuning）在多 profile 场景下参数数量急剧增加的问题，提出了一种极致高效的 X-PEFT 方法。X-PEFT 通过微调一小套紧凑张量作为二进制掩码，来适应性地选择现有 adapters，从而显著减少新 profile 的参数需求。实验在 LaMP 和 GLUE 任务上显示，X-PEFT 与传统 adapter tuning 性能相当或优于后者，同时将每个 profile 的内存需求降低 10,000 倍。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.16137v1",
      "published_date": "2024-01-29 13:13:32 UTC",
      "updated_date": "2024-01-29 13:13:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:10:43.992584"
    },
    {
      "arxiv_id": "2401.16136v1",
      "title": "Neural Network Training on Encrypted Data with TFHE",
      "title_zh": "翻译失败",
      "authors": [
        "Luis Montero",
        "Jordan Frery",
        "Celia Kherfallah",
        "Roman Bredehoft",
        "Andrei Stoian"
      ],
      "abstract": "We present an approach to outsourcing of training neural networks while\npreserving data confidentiality from malicious parties. We use fully\nhomomorphic encryption to build a unified training approach that works on\nencrypted data and learns quantized neural network models. The data can be\nhorizontally or vertically split between multiple parties, enabling\ncollaboration on confidential data. We train logistic regression and\nmulti-layer perceptrons on several datasets.",
      "tldr_zh": "本论文提出了一种使用 TFHE（Fully Homomorphic Encryption）在加密数据上训练神经网络的方法，以保护数据机密性免受恶意方侵害。该方法构建了一个统一训练框架，支持对量化神经网络模型进行训练，并允许数据在多个方之间水平或垂直分割，实现机密数据的协作。实验结果显示，该方法成功应用于逻辑回归（Logistic Regression）和多层感知器（Multi-Layer Perceptrons）模型的训练，并在多个数据集上验证了其有效性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.16136v1",
      "published_date": "2024-01-29 13:07:08 UTC",
      "updated_date": "2024-01-29 13:07:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:10:55.878525"
    },
    {
      "arxiv_id": "2401.16124v2",
      "title": "On the generalization of learned constraints for ASP solving in temporal domains",
      "title_zh": "关于学到约束在时间域中用于 ASP 求解的泛化",
      "authors": [
        "Javier Romero",
        "Torsten Schaub",
        "Klaus Strauch"
      ],
      "abstract": "The representation of a dynamic problem in ASP usually boils down to using\ncopies of variables and constraints, one for each time stamp, no matter whether\nit is directly encoded or via an action or temporal language. The\nmultiplication of variables and constraints is commonly done during grounding\nand the solver is completely ignorant about the temporal relationship among the\ndifferent instances. On the other hand, a key factor in the performance of\ntoday's ASP solvers is conflict-driven constraint learning. Our question is now\nwhether a constraint learned for particular time steps can be generalized and\nreused at other time stamps, and ultimately whether this enhances the overall\nsolver performance on temporal problems. Knowing full well the domain of time,\nwe study conditions under which learned dynamic constraints can be generalized.\nWe propose a simple translation of the original logic program such that, for\nthe translated programs, the learned constraints can be generalized to other\ntime points. Additionally, we identify a property of temporal problems that\nallows us to generalize all learned constraints to all time steps. It turns out\nthat this property is satisfied by many planning problems. Finally, we\nempirically evaluate the impact of adding the generalized constraints to an ASP\nsolver. Under consideration in Theory and Practice of Logic Programming (TPLP).",
      "tldr_zh": "该论文探讨了在Answer Set Programming (ASP)求解器中，如何将为特定时间步骤学到的约束泛化到其他时间戳，以提升处理时间域问题的性能。研究者提出了一种简单翻译原逻辑程序的方法，使学到的动态约束能够适用于其他时间点，并识别了一个属性，该属性允许所有约束在许多规划问题中实现全时间泛化。实验结果显示，在ASP求解器中添加这些泛化约束后，整体性能得到显著改善，为时间相关ASP问题的优化提供了新途径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "41 pages, 2 figures, Under consideration in Theory and Practice of\n  Logic Programming (TPLP)",
      "pdf_url": "http://arxiv.org/pdf/2401.16124v2",
      "published_date": "2024-01-29 12:49:09 UTC",
      "updated_date": "2024-10-15 11:19:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:11:08.420787"
    },
    {
      "arxiv_id": "2401.16123v2",
      "title": "Looking for a better fit? An Incremental Learning Multimodal Object Referencing Framework adapting to Individual Drivers",
      "title_zh": "翻译失败",
      "authors": [
        "Amr Gomaa",
        "Guillermo Reyes",
        "Michael Feld",
        "Antonio Krüger"
      ],
      "abstract": "The rapid advancement of the automotive industry towards automated and\nsemi-automated vehicles has rendered traditional methods of vehicle\ninteraction, such as touch-based and voice command systems, inadequate for a\nwidening range of non-driving related tasks, such as referencing objects\noutside of the vehicle. Consequently, research has shifted toward gestural\ninput (e.g., hand, gaze, and head pose gestures) as a more suitable mode of\ninteraction during driving. However, due to the dynamic nature of driving and\nindividual variation, there are significant differences in drivers' gestural\ninput performance. While, in theory, this inherent variability could be\nmoderated by substantial data-driven machine learning models, prevalent\nmethodologies lean towards constrained, single-instance trained models for\nobject referencing. These models show a limited capacity to continuously adapt\nto the divergent behaviors of individual drivers and the variety of driving\nscenarios. To address this, we propose \\textit{IcRegress}, a novel\nregression-based incremental learning approach that adapts to changing behavior\nand the unique characteristics of drivers engaged in the dual task of driving\nand referencing objects. We suggest a more personalized and adaptable solution\nfor multimodal gestural interfaces, employing continuous lifelong learning to\nenhance driver experience, safety, and convenience. Our approach was evaluated\nusing an outside-the-vehicle object referencing use case, highlighting the\nsuperiority of the incremental learning models adapted over a single trained\nmodel across various driver traits such as handedness, driving experience, and\nnumerous driving conditions. Finally, to facilitate reproducibility, ease\ndeployment, and promote further research, we offer our approach as an\nopen-source framework at \\url{https://github.com/amrgomaaelhady/IcRegress}.",
      "tldr_zh": "该研究针对汽车自动化时代中驾驶员的多模态手势交互（如手势、注视和头部姿势）问题，提出了一种名为IcRegress的回归-based incremental learning框架，以适应个体驾驶员的行为变化和独特特性。框架通过连续终身学习机制，实现对驾驶员手性、经验和各种驾驶场景的个性化适应，旨在提升对象引用任务的准确性和整体驾驶体验。实验结果显示，IcRegress在车辆外对象引用场景中比单实例训练模型表现出色，平均表现优于基准模型，并提供开源框架（https://github.com/amrgomaaelhady/IcRegress）以促进进一步研究和部署。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted for publication in the Proceedings of the 29th International\n  Conference on Intelligent User Interfaces (IUI'24), March 18--21, 2024, in\n  Greenville, SC, USA",
      "pdf_url": "http://arxiv.org/pdf/2401.16123v2",
      "published_date": "2024-01-29 12:48:56 UTC",
      "updated_date": "2024-02-07 11:25:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:11:22.607857"
    },
    {
      "arxiv_id": "2401.16119v2",
      "title": "Triple Disentangled Representation Learning for Multimodal Affective Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Ying Zhou",
        "Xuefeng Liang",
        "Han Chen",
        "Yin Zhao",
        "Xin Chen",
        "Lida Yu"
      ],
      "abstract": "Multimodal learning has exhibited a significant advantage in affective\nanalysis tasks owing to the comprehensive information of various modalities,\nparticularly the complementary information. Thus, many emerging studies focus\non disentangling the modality-invariant and modality-specific representations\nfrom input data and then fusing them for prediction. However, our study shows\nthat modality-specific representations may contain information that is\nirrelevant or conflicting with the tasks, which downgrades the effectiveness of\nlearned multimodal representations. We revisit the disentanglement issue, and\npropose a novel triple disentanglement approach, TriDiRA, which disentangles\nthe modality-invariant, effective modality-specific and ineffective\nmodality-specific representations from input data. By fusing only the\nmodality-invariant and effective modality-specific representations, TriDiRA can\nsignificantly alleviate the impact of irrelevant and conflicting information\nacross modalities during model training. Extensive experiments conducted on\nfour benchmark datasets demonstrate the effectiveness and generalization of our\ntriple disentanglement, which outperforms SOTA methods.",
      "tldr_zh": "本研究针对多模态学习在情感分析中的挑战，指出现有的模态分离方法可能引入无关或冲突信息，从而影响模态不变（modality-invariant）和模态特定（modality-specific）表示的有效性。论文提出了一种新型三重分离方法TriDiRA，它从输入数据中分离出模态不变、有效模态特定和无效模态特定表示，并仅融合前两者以减少跨模态干扰。实验在四个基准数据集上表明，TriDiRA 优于 SOTA 方法，展示了其有效性和泛化能力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.16119v2",
      "published_date": "2024-01-29 12:45:27 UTC",
      "updated_date": "2024-04-08 08:19:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:11:35.690970"
    },
    {
      "arxiv_id": "2401.16107v1",
      "title": "Beyond Direct Diagnosis: LLM-based Multi-Specialist Agent Consultation for Automatic Diagnosis",
      "title_zh": "超越直接诊断：基于LLM的多专家代理咨询用于自动诊断",
      "authors": [
        "Haochun Wang",
        "Sendong Zhao",
        "Zewen Qiang",
        "Nuwa Xi",
        "Bing Qin",
        "Ting Liu"
      ],
      "abstract": "Automatic diagnosis is a significant application of AI in healthcare, where\ndiagnoses are generated based on the symptom description of patients. Previous\nworks have approached this task directly by modeling the relationship between\nthe normalized symptoms and all possible diseases. However, in the clinical\ndiagnostic process, patients are initially consulted by a general practitioner\nand, if necessary, referred to specialists in specific domains for a more\ncomprehensive evaluation. The final diagnosis often emerges from a\ncollaborative consultation among medical specialist groups. Recently, large\nlanguage models have shown impressive capabilities in natural language\nunderstanding. In this study, we adopt tuning-free LLM-based agents as medical\npractitioners and propose the Agent-derived Multi-Specialist Consultation\n(AMSC) framework to model the diagnosis process in the real world by adaptively\nfusing probability distributions of agents over potential diseases.\nExperimental results demonstrate the superiority of our approach compared with\nbaselines. Notably, our approach requires significantly less parameter updating\nand training time, enhancing efficiency and practical utility. Furthermore, we\ndelve into a novel perspective on the role of implicit symptoms within the\ncontext of automatic diagnosis.",
      "tldr_zh": "该研究批评了传统自动诊断方法直接建模症状与疾病关系的局限性，并提出Agent-derived Multi-Specialist Consultation (AMSC)框架，使用tuning-free LLM-based agents模拟现实临床过程，由多专家代理自适应融合概率分布进行诊断。实验结果表明，该方法比基线模型表现出色，同时显著减少参数更新和训练时间，提升了效率。论文还从新视角探讨了隐性症状在自动诊断中的作用，为医疗AI应用提供了更全面的见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.16107v1",
      "published_date": "2024-01-29 12:25:30 UTC",
      "updated_date": "2024-01-29 12:25:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:11:48.059102"
    },
    {
      "arxiv_id": "2401.16102v1",
      "title": "Flexible Parallel Neural Network Architecture Model for Early Prediction of Lithium Battery Life",
      "title_zh": "灵活并行神经网络架构模型用于锂电池寿命的早期预测",
      "authors": [
        "Lidang Jiang",
        "Zhuoxiang Li",
        "Changyan Hu",
        "Qingsong Huang",
        "Ge He"
      ],
      "abstract": "The early prediction of battery life (EPBL) is vital for enhancing the\nefficiency and extending the lifespan of lithium batteries. Traditional models\nwith fixed architectures often encounter underfitting or overfitting issues due\nto the diverse data distributions in different EPBL tasks. An interpretable\ndeep learning model of flexible parallel neural network (FPNN) is proposed,\nwhich includes an InceptionBlock, a 3D convolutional neural network (CNN), a 2D\nCNN, and a dual-stream network. The proposed model effectively extracts\nelectrochemical features from video-like formatted data using the 3D CNN and\nachieves advanced multi-scale feature abstraction through the InceptionBlock.\nThe FPNN can adaptively adjust the number of InceptionBlocks to flexibly handle\ntasks of varying complexity in EPBL. The test on the MIT dataset shows that the\nFPNN model achieves outstanding predictive accuracy in EPBL tasks, with MAPEs\nof 2.47%, 1.29%, 1.08%, and 0.88% when the input cyclic data volumes are 10,\n20, 30, and 40, respectively. The interpretability of the FPNN is mainly\nreflected in its flexible unit structure and parameter selection: its diverse\nbranching structure enables the model to capture features at different scales,\nthus allowing the machine to learn informative features. The approach presented\nherein provides an accurate, adaptable, and comprehensible solution for early\nlife prediction of lithium batteries, opening new possibilities in the field of\nbattery health monitoring.",
      "tldr_zh": "本研究针对锂电池寿命早期预测（EPBL）中的欠拟合或过拟合问题，提出了一种可解释的深度学习模型Flexible Parallel Neural Network (FPNN)，该模型整合了InceptionBlock、3D CNN、2D CNN 和双流网络，以高效提取视频格式数据的电化学特征并实现多尺度特征抽象。FPNN 通过自适应调整InceptionBlocks 的数量，灵活处理不同复杂度的EPBL 任务。实验在MIT 数据集上显示，该模型的预测准确率出色，输入循环数据量分别为10、20、30 和40 时，MAPE 值分别为2.47%、1.29%、1.08% 和0.88%。这种灵活的结构和参数选择增强了模型的可解释性，为锂电池健康监测提供了一个准确、可适应且易懂的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.16102v1",
      "published_date": "2024-01-29 12:20:17 UTC",
      "updated_date": "2024-01-29 12:20:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:12:00.203759"
    },
    {
      "arxiv_id": "2402.03948v1",
      "title": "Identifying Student Profiles Within Online Judge Systems Using Explainable Artificial Intelligence",
      "title_zh": "利用可解释人工智能识别在线评判系统中的学生",
      "authors": [
        "Juan Ramón Rico-Juan",
        "Víctor M. Sánchez-Cartagena",
        "Jose J. Valero-Mas",
        "Antonio Javier Gallego"
      ],
      "abstract": "Online Judge (OJ) systems are typically considered within programming-related\ncourses as they yield fast and objective assessments of the code developed by\nthe students. Such an evaluation generally provides a single decision based on\na rubric, most commonly whether the submission successfully accomplished the\nassignment. Nevertheless, since in an educational context such information may\nbe deemed insufficient, it would be beneficial for both the student and the\ninstructor to receive additional feedback about the overall development of the\ntask. This work aims to tackle this limitation by considering the further\nexploitation of the information gathered by the OJ and automatically inferring\nfeedback for both the student and the instructor. More precisely, we consider\nthe use of learning-based schemes -- particularly, multi-instance learning\n(MIL) and classical machine learning formulations -- to model student behavior.\nBesides, explainable artificial intelligence (XAI) is contemplated to provide\nhuman-understandable feedback. The proposal has been evaluated considering a\ncase of study comprising 2500 submissions from roughly 90 different students\nfrom a programming-related course in a computer science degree. The results\nobtained validate the proposal: The model is capable of significantly\npredicting the user outcome (either passing or failing the assignment) solely\nbased on the behavioral pattern inferred by the submissions provided to the OJ.\nMoreover, the proposal is able to identify prone-to-fail student groups and\nprofiles as well as other relevant information, which eventually serves as\nfeedback to both the student and the instructor.",
      "tldr_zh": "本文提出了一种利用可解释人工智能 (XAI) 的方法，来分析 Online Judge (OJ) 系统中的学生提交数据，以识别学生行为模式并提供额外反馈。研究采用多实例学习 (MIL) 和经典机器学习技术来建模学生行为，从而自动推断学生在编程任务中的表现和潜在问题。在一个案例研究中，涉及约90名学生的2500个提交，模型显著预测了学生是否通过任务，并成功识别容易失败的学生群体和配置文件，为学生和教师提供可理解的反馈支持。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.03948v1",
      "published_date": "2024-01-29 12:11:30 UTC",
      "updated_date": "2024-01-29 12:11:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:12:11.942771"
    },
    {
      "arxiv_id": "2402.01739v2",
      "title": "OpenMoE: An Early Effort on Open Mixture-of-Experts Language Models",
      "title_zh": "OpenMoE：开源混合专家语言模型的早期努力",
      "authors": [
        "Fuzhao Xue",
        "Zian Zheng",
        "Yao Fu",
        "Jinjie Ni",
        "Zangwei Zheng",
        "Wangchunshu Zhou",
        "Yang You"
      ],
      "abstract": "To help the open-source community have a better understanding of\nMixture-of-Experts (MoE) based large language models (LLMs), we train and\nrelease OpenMoE, a series of fully open-sourced and reproducible decoder-only\nMoE LLMs, ranging from 650M to 34B parameters and trained on up to over 1T\ntokens. Our investigation confirms that MoE-based LLMs can offer a more\nfavorable cost-effectiveness trade-off than dense LLMs, highlighting the\npotential effectiveness for future LLM development.\n  One more important contribution of this study is an in-depth analysis of the\nrouting mechanisms within our OpenMoE models, leading to three significant\nfindings: Context-Independent Specialization, Early Routing Learning, and\nDrop-towards-the-End. We discovered that routing decisions in MoE models are\npredominantly based on token IDs, with minimal context relevance. The\ntoken-to-expert assignments are determined early in the pre-training phase and\nremain largely unchanged. This imperfect routing can result in performance\ndegradation, particularly in sequential tasks like multi-turn conversations,\nwhere tokens appearing later in a sequence are more likely to be dropped.\nFinally, we rethink our design based on the above-mentioned observations and\nanalysis. To facilitate future MoE LLM development, we propose potential\nstrategies for mitigating the issues we found and further improving\noff-the-shelf MoE LLM designs.",
      "tldr_zh": "本研究训练并开源了OpenMoE系列模型，这些是完全开源且可复现的decoder-only Mixture-of-Experts (MoE) LLMs，从650M到34B参数，使用超过1T tokens训练，并证明MoE-based LLMs在成本效益上优于dense LLMs。研究通过深入分析routing mechanisms，揭示了三个关键发现：Context-Independent Specialization（路由决策主要基于token IDs而非上下文）、Early Routing Learning（分配在预训练早期就固定）和Drop-towards-the-End（序列后期tokens更容易被丢弃），这些问题可能导致多轮对话等任务的性能下降。最后，基于这些观察，论文提出策略来缓解routing缺陷，并为未来MoE LLM设计提供改进建议。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01739v2",
      "published_date": "2024-01-29 12:05:02 UTC",
      "updated_date": "2024-03-27 10:21:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:12:24.494974"
    },
    {
      "arxiv_id": "2401.16094v1",
      "title": "Federated unsupervised random forest for privacy-preserving patient stratification",
      "title_zh": "联邦无监督随机森林用于隐私保护患者分层",
      "authors": [
        "Bastian Pfeifer",
        "Christel Sirocchi",
        "Marcus D. Bloice",
        "Markus Kreuzthaler",
        "Martin Urschler"
      ],
      "abstract": "In the realm of precision medicine, effective patient stratification and\ndisease subtyping demand innovative methodologies tailored for multi-omics\ndata. Clustering techniques applied to multi-omics data have become\ninstrumental in identifying distinct subgroups of patients, enabling a\nfiner-grained understanding of disease variability. This work establishes a\npowerful framework for advancing precision medicine through unsupervised\nrandom-forest-based clustering and federated computing. We introduce a novel\nmulti-omics clustering approach utilizing unsupervised random-forests. The\nunsupervised nature of the random forest enables the determination of\ncluster-specific feature importance, unraveling key molecular contributors to\ndistinct patient groups. Moreover, our methodology is designed for federated\nexecution, a crucial aspect in the medical domain where privacy concerns are\nparamount. We have validated our approach on machine learning benchmark data\nsets as well as on cancer data from The Cancer Genome Atlas (TCGA). Our method\nis competitive with the state-of-the-art in terms of disease subtyping, but at\nthe same time substantially improves the cluster interpretability. Experiments\nindicate that local clustering performance can be improved through federated\ncomputing.",
      "tldr_zh": "这篇论文提出了一种基于 unsupervised random forest 的多组学聚类方法，用于精准医学中的患者分层和疾病亚型识别，强调通过 federated computing 实现隐私保护。方法利用 unsupervised random forest 的无监督特性来确定集群特定的特征重要性，从而揭示关键分子贡献者，并在 TCGA 癌症数据等数据集上进行了验证。与最先进方法相比，该方法在疾病亚型性能上具有竞争力，同时显著提高了集群的可解释性，且 federated computing 能提升本地聚类效果。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.16094v1",
      "published_date": "2024-01-29 12:04:14 UTC",
      "updated_date": "2024-01-29 12:04:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:12:35.161003"
    },
    {
      "arxiv_id": "2403.08783v1",
      "title": "Image-Text Out-Of-Context Detection Using Synthetic Multimodal Misinformation",
      "title_zh": "翻译失败",
      "authors": [
        "Fatma Shalabi",
        "Huy H. Nguyen",
        "Hichem Felouat",
        "Ching-Chun Chang",
        "Isao Echizen"
      ],
      "abstract": "Misinformation has become a major challenge in the era of increasing digital\ninformation, requiring the development of effective detection methods. We have\ninvestigated a novel approach to Out-Of-Context detection (OOCD) that uses\nsynthetic data generation. We created a dataset specifically designed for OOCD\nand developed an efficient detector for accurate classification. Our\nexperimental findings validate the use of synthetic data generation and\ndemonstrate its efficacy in addressing the data limitations associated with\nOOCD. The dataset and detector should serve as valuable resources for future\nresearch and the development of robust misinformation detection systems.",
      "tldr_zh": "本研究针对图像-文本Out-Of-Context（OOC）问题提出了一种使用合成多模态虚假信息的方法，以应对数字时代虚假信息挑战。研究者创建了一个专门的OOCD数据集，并开发了一个高效的检测器，通过合成数据生成解决了数据短缺的问题。实验结果验证了该方法的有效性，证明了其在提高OOCD分类准确性方面的优势，并为未来虚假信息检测系统的开发提供了宝贵资源。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 2 figures, conference",
      "pdf_url": "http://arxiv.org/pdf/2403.08783v1",
      "published_date": "2024-01-29 11:55:14 UTC",
      "updated_date": "2024-01-29 11:55:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:12:46.708891"
    },
    {
      "arxiv_id": "2402.00064v1",
      "title": "Merging plans with incomplete knowledge about actions and goals through an agent-based reputation system",
      "title_zh": "翻译失败",
      "authors": [
        "Javier Carbo",
        "Jose M Molina",
        "Miguel A Patricio"
      ],
      "abstract": "Managing transition plans is one of the major problems of people with\ncognitive disabilities. Therefore, finding an automated way to generate such\nplans would be a helpful tool for this community. In this paper we have\nspecifically proposed and compared different alternative ways to merge plans\nformed by sequences of actions of unknown similarities between goals and\nactions executed by several operator agents which cooperate between them\napplying such actions over some passive elements (node agents) that require\nadditional executions of another plan after some time of use. Such ignorance of\nthe similarities between plan actions and goals would justify the use of a\ndistributed recommendation system that would provide an useful plan to be\napplied for a certain goal to a given operator agent, generated from the known\nresults of previous executions of different plans by other operator agents.\nHere we provide the general framework of execution (agent system), and the\ndifferent merging algorithms applied to this problem. The proposed agent system\nwould act as an useful cognitive assistant for people with intelectual\ndisabilities such as autism.",
      "tldr_zh": "该论文针对认知障碍者（如自闭症患者）管理过渡计划的难题，提出了一种基于代理（agent-based）的声誉系统，用于在行动和目标相似性未知的情况下合并多个操作agents的计划序列。系统结合分布式推荐系统，从先前计划执行的结果中生成新的实用计划，并比较了不同合并算法以优化过程。最终，该框架可作为认知助手，提供自动化支持，帮助用户处理被动元素（node agents）的后续执行需求。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.00064v1",
      "published_date": "2024-01-29 11:34:59 UTC",
      "updated_date": "2024-01-29 11:34:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:13:00.322712"
    },
    {
      "arxiv_id": "2403.09668v1",
      "title": "Trustworthy Automated Driving through Qualitative Scene Understanding and Explanations",
      "title_zh": "翻译失败",
      "authors": [
        "Nassim Belmecheri",
        "Arnaud Gotlieb",
        "Nadjib Lazaar",
        "Helge Spieker"
      ],
      "abstract": "We present the Qualitative Explainable Graph (QXG): a unified symbolic and\nqualitative representation for scene understanding in urban mobility. QXG\nenables the interpretation of an automated vehicle's environment using sensor\ndata and machine learning models. It leverages spatio-temporal graphs and\nqualitative constraints to extract scene semantics from raw sensor inputs, such\nas LiDAR and camera data, offering an intelligible scene model. Crucially, QXG\ncan be incrementally constructed in real-time, making it a versatile tool for\nin-vehicle explanations and real-time decision-making across various sensor\ntypes. Our research showcases the transformative potential of QXG, particularly\nin the context of automated driving, where it elucidates decision rationales by\nlinking the graph with vehicle actions. These explanations serve diverse\npurposes, from informing passengers and alerting vulnerable road users (VRUs)\nto enabling post-analysis of prior behaviours.",
      "tldr_zh": "该研究提出了一种名为 Qualitative Explainable Graph (QXG) 的统一符号和定性表示，用于城市交通场景理解，提升自动驾驶的可信度。QXG 通过时空图和定性约束，从传感器数据（如 LiDAR 和相机数据）中提取场景语义，并支持实时增量构建，实现可解释的场景模型和决策过程。实验结果显示，QXG 能将场景图与车辆动作关联，提供多样化解释，如告知乘客、警报 Vulnerable Road Users (VRUs) 和事后行为分析，从而促进可靠的自动驾驶决策。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Transport Research Arena (TRA) 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.09668v1",
      "published_date": "2024-01-29 11:20:19 UTC",
      "updated_date": "2024-01-29 11:20:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:13:12.754685"
    },
    {
      "arxiv_id": "2401.16461v3",
      "title": "Norm Enforcement with a Soft Touch: Faster Emergence, Happier Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Sz-Ting Tzeng",
        "Nirav Ajmeri",
        "Munindar P. Singh"
      ],
      "abstract": "A multiagent system is a society of autonomous agents whose interactions can\nbe regulated via social norms. In general, the norms of a society are not\nhardcoded but emerge from the agents' interactions. Specifically, how the\nagents in a society react to each other's behavior and respond to the reactions\nof others determines which norms emerge in the society. We think of these\nreactions by an agent to the satisfactory or unsatisfactory behaviors of\nanother agent as communications from the first agent to the second agent.\nUnderstanding these communications is a kind of social intelligence: these\ncommunications provide natural drivers for norm emergence by pushing agents\ntoward certain behaviors, which can become established as norms. Whereas it is\nwell-known that sanctioning can lead to the emergence of norms, we posit that a\nbroader kind of social intelligence can prove more effective in promoting\ncooperation in a multiagent system.\n  Accordingly, we develop Nest, a framework that models social intelligence via\na wider variety of communications and understanding of them than in previous\nwork. To evaluate Nest, we develop a simulated pandemic environment and conduct\nsimulation experiments to compare Nest with baselines considering a combination\nof three kinds of social communication: sanction, tell, and hint.\n  We find that societies formed of Nest agents achieve norms faster. Moreover,\nNest agents effectively avoid undesirable consequences, which are negative\nsanctions and deviation from goals, and yield higher satisfaction for\nthemselves than baseline agents despite requiring only an equivalent amount of\ninformation.",
      "tldr_zh": "该论文探讨了多智能体系统(multiagent system)中社会规范(norm)的涌现问题，提出 Nest 框架，通过更广泛的社交沟通形式（包括 sanction、tell 和 hint）来模拟代理间的互动，促进规范的更快形成。相比基线模型，Nest 框架在模拟大流行环境中的实验显示，代理能够更高效地避免负面制裁和目标偏差，同时实现更高的满意度，而所需信息量相当。该研究强调，扩展社交智能可以更有效地推动合作和规范执行。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.MA",
      "comment": "12 pages, 11 figures, 5 tables (and supplementary material with code\n  availability and additional results), accepted at AAMAS 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.16461v3",
      "published_date": "2024-01-29 11:09:45 UTC",
      "updated_date": "2024-03-05 10:58:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:13:23.415100"
    },
    {
      "arxiv_id": "2401.16045v1",
      "title": "Type-based Neural Link Prediction Adapter for Complex Query Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Lingning Song",
        "Yi Zu",
        "Shan Lu",
        "Jieyue He"
      ],
      "abstract": "Answering complex logical queries on incomplete knowledge graphs (KGs) is a\nfundamental and challenging task in multi-hop reasoning. Recent work defines\nthis task as an end-to-end optimization problem, which significantly reduces\nthe training cost and enhances the generalization of the model by a pretrained\nlink predictors for query answering. However, most existing proposals ignore\nthe critical semantic knowledge inherently available in KGs, such as type\ninformation, which could help answer complex logical queries. To this end, we\npropose TypE-based Neural Link Prediction Adapter (TENLPA), a novel model that\nconstructs type-based entity-relation graphs to discover the latent\nrelationships between entities and relations by leveraging type information in\nKGs. Meanwhile, in order to effectively combine type information with complex\nlogical queries, an adaptive learning mechanism is introduced, which is trained\nby back-propagating during the complex query answering process to achieve\nadaptive adjustment of neural link predictors. Experiments on 3 standard\ndatasets show that TENLPA model achieves state-of-the-art performance on\ncomplex query answering with good generalization and robustness.",
      "tldr_zh": "该论文针对不完整的知识图谱（KGs）上回答复杂逻辑查询（complex logical queries）的问题，提出了一种新型模型TypE-based Neural Link Prediction Adapter (TENLPA)。TENLPA 通过构建基于类型信息的实体-关系图（type-based entity-relation graphs）来挖掘实体和关系间的潜在联系，并引入自适应学习机制，通过反向传播训练动态调整神经链接预测器，以有效整合类型信息。实验结果显示，该模型在3个标准数据集上实现了state-of-the-art性能，并展现出优秀的generalization和robustness。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.16045v1",
      "published_date": "2024-01-29 10:54:28 UTC",
      "updated_date": "2024-01-29 10:54:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:13:38.802583"
    },
    {
      "arxiv_id": "2402.07909v1",
      "title": "Prompt4Vis: Prompting Large Language Models with Example Mining and Schema Filtering for Tabular Data Visualization",
      "title_zh": "翻译失败",
      "authors": [
        "Shuaimin Li",
        "Xuanang Chen",
        "Yuanfeng Song",
        "Yunze Song",
        "Chen Zhang"
      ],
      "abstract": "Data visualization (DV) systems are increasingly recognized for their\nprofound capability to uncover insights from vast datasets, gaining attention\nacross both industry and academia. Crafting data queries is an essential\nprocess within certain declarative visualization languages (DVLs, e.g.,\nVega-Lite, EChart.). The evolution of natural language processing (NLP)\ntechnologies has streamlined the use of natural language interfaces to\nvisualize tabular data, offering a more accessible and intuitive user\nexperience. However, current methods for converting natural language questions\ninto data visualization queries, such as Seq2Vis, ncNet, and RGVisNet, despite\nutilizing complex neural network architectures, still fall short of\nexpectations and have great room for improvement.\n  Large language models (LLMs) such as ChatGPT and GPT-4, have established new\nbenchmarks in a variety of NLP tasks, fundamentally altering the landscape of\nthe field. Inspired by these advancements, we introduce a novel framework,\nPrompt4Vis, leveraging LLMs and in-context learning to enhance the performance\nof generating data visualization from natural language. Prompt4Vis comprises\ntwo key components: (1) a multi-objective example mining module, designed to\nfind out the truly effective examples that strengthen the LLM's in-context\nlearning capabilities for text-to-vis; (2) a schema filtering module, which is\nproposed to simplify the schema of the database. Extensive experiments through\n5-fold cross-validation on the NVBench dataset demonstrate the superiority of\nPrompt4Vis, which notably surpasses the state-of-the-art (SOTA) RGVisNet by\napproximately 35.9% and 71.3% on dev and test sets, respectively. To the best\nof our knowledge, Prompt4Vis is the first work that introduces in-context\nlearning into the text-to-vis for generating data visualization queries.",
      "tldr_zh": "这篇论文提出了 Prompt4Vis 框架，利用 Large Language Models (LLMs) 和 in-context learning 来提升从自然语言到表格数据可视化的生成性能，解决现有方法如 Seq2Vis 和 RGVisNet 在处理数据查询方面的不足。框架的核心组件包括多目标示例挖掘模块，用于筛选有效的示例以强化 LLMs 的学习能力，以及模式过滤模块，用于简化数据库的 schema。实验结果显示，在 NVBench 数据集的 5-fold cross-validation 中，Prompt4Vis 比 SOTA 方法 RGVisNet 分别在开发集和测试集上提高了约 35.9% 和 71.3% 的性能；这是首个将 in-context learning 应用于文本到可视化 (text-to-vis) 领域的创新工作。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.DB"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.07909v1",
      "published_date": "2024-01-29 10:23:47 UTC",
      "updated_date": "2024-01-29 10:23:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:13:51.398246"
    },
    {
      "arxiv_id": "2401.16024v1",
      "title": "Probabilistic Abduction for Visual Abstract Reasoning via Learning Rules in Vector-symbolic Architectures",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Hersche",
        "Francesco di Stefano",
        "Thomas Hofmann",
        "Abu Sebastian",
        "Abbas Rahimi"
      ],
      "abstract": "Abstract reasoning is a cornerstone of human intelligence, and replicating it\nwith artificial intelligence (AI) presents an ongoing challenge. This study\nfocuses on efficiently solving Raven's progressive matrices (RPM), a visual\ntest for assessing abstract reasoning abilities, by using distributed\ncomputation and operators provided by vector-symbolic architectures (VSA).\nInstead of hard-coding the rule formulations associated with RPMs, our approach\ncan learn the VSA rule formulations (hence the name Learn-VRF) with just one\npass through the training data. Yet, our approach, with compact parameters,\nremains transparent and interpretable. Learn-VRF yields accurate predictions on\nI-RAVEN's in-distribution data, and exhibits strong out-of-distribution\ncapabilities concerning unseen attribute-rule pairs, significantly\noutperforming pure connectionist baselines including large language models. Our\ncode is available at\nhttps://github.com/IBM/learn-vector-symbolic-architectures-rule-formulations.",
      "tldr_zh": "本研究提出了一种基于向量符号架构 (VSA) 的 Learn-VRF 方法，用于通过学习规则实现视觉抽象推理，特别是解决 Raven's progressive matrices (RPM) 测试。不同于硬编码规则，该方法只需一次训练数据遍历即可学习 VSA 规则，确保模型参数紧凑且保持透明性与可解释性。在 I-RAVEN 数据集上，Learn-VRF 实现了准确的分布内预测，并在分布外（包括未见属性-规则对）表现出色，大幅超越纯连接主义基线模型，如大型语言模型。该方法为高效的人工智能抽象推理提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted in NeurIPS 2023 Workshop on MATH-AI",
      "pdf_url": "http://arxiv.org/pdf/2401.16024v1",
      "published_date": "2024-01-29 10:17:18 UTC",
      "updated_date": "2024-01-29 10:17:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:13:59.975187"
    },
    {
      "arxiv_id": "2401.16458v3",
      "title": "Credit Risk Meets Large Language Models: Building a Risk Indicator from Loan Descriptions in P2P Lending",
      "title_zh": "翻译失败",
      "authors": [
        "Mario Sanz-Guerrero",
        "Javier Arroyo"
      ],
      "abstract": "Peer-to-peer (P2P) lending connects borrowers and lenders through online\nplatforms but suffers from significant information asymmetry, as lenders often\nlack sufficient data to assess borrowers' creditworthiness. This paper\naddresses this challenge by leveraging BERT, a Large Language Model (LLM) known\nfor its ability to capture contextual nuances in text, to generate a risk score\nbased on borrowers' loan descriptions using a dataset from the Lending Club\nplatform. We fine-tune BERT to distinguish between defaulted and non-defaulted\nloans using the loan descriptions provided by the borrowers. The resulting\nBERT-generated risk score is then integrated as an additional feature into an\nXGBoost classifier used at the loan granting stage, where decision-makers have\nlimited information available to guide their decisions. This integration\nenhances predictive performance, with improvements in balanced accuracy and\nAUC, highlighting the value of textual features in complementing traditional\ninputs. Moreover, we find that the incorporation of the BERT score alters how\nclassification models utilize traditional input variables, with these changes\nvarying by loan purpose. These findings suggest that BERT discerns meaningful\npatterns in loan descriptions, encompassing borrower-specific features,\nspecific purposes, and linguistic characteristics. However, the inherent\nopacity of LLMs and their potential biases underscore the need for transparent\nframeworks to ensure regulatory compliance and foster trust. Overall, this\nstudy demonstrates how LLM-derived insights interact with traditional features\nin credit risk modeling, opening new avenues to enhance the explainability and\nfairness of these models.",
      "tldr_zh": "本研究针对 P2P 贷款平台的信息不对称问题，利用 BERT（一种大型语言模型）从借款人的贷款描述中生成风险分数，通过微调 BERT 来区分违约和非违约贷款。  \n随后，将生成的 BERT 风险分数整合到 XGBoost 分类器中，作为额外特征，提升了预测性能，包括平衡准确率和 AUC 的改善。  \n研究发现，BERT 能识别贷款描述中的借款人特征、目的和语言模式，从而改变模型对传统变量的利用方式，但也强调了 LLM 的不透明性和潜在偏见，需要透明框架来促进公平性和合规性。",
      "categories": [
        "q-fin.RM",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "q-fin.RM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.16458v3",
      "published_date": "2024-01-29 10:11:05 UTC",
      "updated_date": "2025-03-23 09:42:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:14:13.803722"
    },
    {
      "arxiv_id": "2401.16013v4",
      "title": "SERL: A Software Suite for Sample-Efficient Robotic Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jianlan Luo",
        "Zheyuan Hu",
        "Charles Xu",
        "You Liang Tan",
        "Jacob Berg",
        "Archit Sharma",
        "Stefan Schaal",
        "Chelsea Finn",
        "Abhishek Gupta",
        "Sergey Levine"
      ],
      "abstract": "In recent years, significant progress has been made in the field of robotic\nreinforcement learning (RL), enabling methods that handle complex image\nobservations, train in the real world, and incorporate auxiliary data, such as\ndemonstrations and prior experience. However, despite these advances, robotic\nRL remains hard to use. It is acknowledged among practitioners that the\nparticular implementation details of these algorithms are often just as\nimportant (if not more so) for performance as the choice of algorithm. We posit\nthat a significant challenge to widespread adoption of robotic RL, as well as\nfurther development of robotic RL methods, is the comparative inaccessibility\nof such methods. To address this challenge, we developed a carefully\nimplemented library containing a sample efficient off-policy deep RL method,\ntogether with methods for computing rewards and resetting the environment, a\nhigh-quality controller for a widely-adopted robot, and a number of challenging\nexample tasks. We provide this library as a resource for the community,\ndescribe its design choices, and present experimental results. Perhaps\nsurprisingly, we find that our implementation can achieve very efficient\nlearning, acquiring policies for PCB board assembly, cable routing, and object\nrelocation between 25 to 50 minutes of training per policy on average,\nimproving over state-of-the-art results reported for similar tasks in the\nliterature. These policies achieve perfect or near-perfect success rates,\nextreme robustness even under perturbations, and exhibit emergent recovery and\ncorrection behaviors. We hope that these promising results and our high-quality\nopen-source implementation will provide a tool for the robotics community to\nfacilitate further developments in robotic RL. Our code, documentation, and\nvideos can be found at https://serl-robot.github.io/",
      "tldr_zh": "这篇论文介绍了 SERL，一种针对样本高效机器人强化学习 (Robotic Reinforcement Learning) 的软件套件，旨在解决算法实现细节对性能的影响问题。SERL 包括一个样本高效的离线策略深度 RL 方法、奖励计算机制、环境重置工具，以及一个高质量的机器人控制器，并提供了多个挑战性任务如 PCB 板组装和电缆路由。实验结果显示，该套件能在 25 到 50 分钟的训练时间内获得高成功率和鲁棒性的策略，甚至表现出紧急恢复行为。SERL 的开源实现有望促进机器人 RL 社区的发展，提供可复现的资源。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "ICRA 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.16013v4",
      "published_date": "2024-01-29 10:01:10 UTC",
      "updated_date": "2025-03-20 09:13:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:14:25.672079"
    },
    {
      "arxiv_id": "2401.16011v1",
      "title": "GPS: Graph Contrastive Learning via Multi-scale Augmented Views from Adversarial Pooling",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Ju",
        "Yiyang Gu",
        "Zhengyang Mao",
        "Ziyue Qiao",
        "Yifang Qin",
        "Xiao Luo",
        "Hui Xiong",
        "Ming Zhang"
      ],
      "abstract": "Self-supervised graph representation learning has recently shown considerable\npromise in a range of fields, including bioinformatics and social networks. A\nlarge number of graph contrastive learning approaches have shown promising\nperformance for representation learning on graphs, which train models by\nmaximizing agreement between original graphs and their augmented views (i.e.,\npositive views). Unfortunately, these methods usually involve pre-defined\naugmentation strategies based on the knowledge of human experts. Moreover,\nthese strategies may fail to generate challenging positive views to provide\nsufficient supervision signals. In this paper, we present a novel approach\nnamed Graph Pooling ContraSt (GPS) to address these issues. Motivated by the\nfact that graph pooling can adaptively coarsen the graph with the removal of\nredundancy, we rethink graph pooling and leverage it to automatically generate\nmulti-scale positive views with varying emphasis on providing challenging\npositives and preserving semantics, i.e., strongly-augmented view and\nweakly-augmented view. Then, we incorporate both views into a joint contrastive\nlearning framework with similarity learning and consistency learning, where our\npooling module is adversarially trained with respect to the encoder for\nadversarial robustness. Experiments on twelve datasets on both graph\nclassification and transfer learning tasks verify the superiority of the\nproposed method over its counterparts.",
      "tldr_zh": "该论文提出了一种名为 GPS 的自监督图表示学习方法（Self-supervised graph representation learning），通过对抗池化（Adversarial Pooling）生成多尺度增强视图（Multi-scale Augmented Views），以解决传统图对比学习（Graph Contrastive Learning）依赖预定义策略并缺乏挑战性正样本的问题。GPS 利用图池化（Graph Pooling）自动创建强增强视图和弱增强视图，并将它们整合到联合对比学习框架中，包括相似性学习和一致性学习，同时通过对抗训练增强模型鲁棒性。实验在 12 个数据集上的图分类和迁移学习任务中表明，GPS 比现有方法表现出显著优势。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by SCIENCE CHINA Information Sciences (SCIS 2024)",
      "pdf_url": "http://arxiv.org/pdf/2401.16011v1",
      "published_date": "2024-01-29 10:00:53 UTC",
      "updated_date": "2024-01-29 10:00:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:14:36.756764"
    },
    {
      "arxiv_id": "2401.16457v2",
      "title": "Effective Controllable Bias Mitigation for Classification and Retrieval using Gate Adapters",
      "title_zh": "翻译失败",
      "authors": [
        "Shahed Masoudian",
        "Cornelia Volaucnik",
        "Markus Schedl",
        "Navid Rekabsaz"
      ],
      "abstract": "Bias mitigation of Language Models has been the topic of many studies with a\nrecent focus on learning separate modules like adapters for on-demand\ndebiasing. Besides optimizing for a modularized debiased model, it is often\ncritical in practice to control the degree of bias reduction at inference time,\ne.g., in order to tune for a desired performance-fairness trade-off in search\nresults or to control the strength of debiasing in classification tasks. In\nthis paper, we introduce Controllable Gate Adapter (ConGater), a novel modular\ngating mechanism with adjustable sensitivity parameters, which allows for a\ngradual transition from the biased state of the model to the fully debiased\nversion at inference time. We demonstrate ConGater performance by (1)\nconducting adversarial debiasing experiments with three different models on\nthree classification tasks with four protected attributes, and (2) reducing the\nbias of search results through fairness list-wise regularization to enable\nadjusting a trade-off between performance and fairness metrics. Our experiments\non the classification tasks show that compared to baselines of the same\ncaliber, ConGater can maintain higher task performance while containing less\ninformation regarding the attributes. Our results on the retrieval task show\nthat the fully debiased ConGater can achieve the same fairness performance\nwhile maintaining more than twice as high task performance than recent strong\nbaselines. Overall, besides strong performance ConGater enables the continuous\ntransitioning between biased and debiased states of models, enhancing\npersonalization of use and interpretability through controllability.",
      "tldr_zh": "本论文提出了一种有效的可控偏见缓解方法，使用 Gate Adapters 构建 Controllable Gate Adapter (ConGater)，允许在语言模型中通过可调节敏感度参数实现从偏见状态到完全去偏的 gradual transition，从而在分类和检索任务中调整性能与公平性 trade-off。ConGater 通过模块化门控机制结合 adversarial debiasing，在三个分类任务和四个保护属性上进行实验，结果显示它比基线模型保持更高任务性能，同时减少了属性相关信息。在检索任务上，通过 fairness list-wise regularization，ConGater 实现了与强基线相同的公平性能，但任务性能提升超过两倍以上，整体增强了模型的可解释性和个性化应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "Paper is accepted to main proceedings of EACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.16457v2",
      "published_date": "2024-01-29 09:15:50 UTC",
      "updated_date": "2024-02-19 07:54:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:14:50.779672"
    },
    {
      "arxiv_id": "2402.01737v3",
      "title": "Assistive Large Language Model Agents for Socially-Aware Negotiation Dialogues",
      "title_zh": "翻译失败",
      "authors": [
        "Yuncheng Hua",
        "Lizhen Qu",
        "Gholamreza Haffari"
      ],
      "abstract": "We develop assistive agents based on Large Language Models (LLMs) that aid\ninterlocutors in business negotiations. Specifically, we simulate business\nnegotiations by letting two LLM-based agents engage in role play. A third LLM\nacts as a remediator agent to rewrite utterances violating norms for improving\nnegotiation outcomes. We introduce a simple tuning-free and label-free\nIn-Context Learning (ICL) method to identify high-quality ICL exemplars for the\nremediator, where we propose a novel select criteria, called value impact, to\nmeasure the quality of the negotiation outcomes. We provide rich empirical\nevidence to demonstrate its effectiveness in negotiations across three\ndifferent negotiation topics. We have released our source code and the\ngenerated dataset at: https://github.com/tk1363704/SADAS.",
      "tldr_zh": "本文开发了基于 Large Language Models (LLMs) 的辅助代理，用于提升社会意识的谈判对话效果，这些代理通过模拟商业谈判让两个 LLM 代理进行角色扮演，并引入一个修复代理来重写违反规范的 utterances，以改善谈判结果。同时，该研究提出了一种无调优、无标签的 In-Context Learning (ICL) 方法，使用 value impact 标准来选择高质量的 ICL 示例。实验在三个不同谈判主题上提供了丰富的实证证据，证明了该框架的有效性，并开源了代码和数据集。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "28 pages, 3 figures, 14 tables; The paper has been published in the\n  Findings of the Association for Computational Linguistics: EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.01737v3",
      "published_date": "2024-01-29 09:07:40 UTC",
      "updated_date": "2025-02-17 08:44:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:15:01.288807"
    },
    {
      "arxiv_id": "2401.15970v2",
      "title": "HEQuant: Marrying Homomorphic Encryption and Quantization for Communication-Efficient Private Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Tianshi Xu",
        "Meng Li",
        "Runsheng Wang"
      ],
      "abstract": "Secure two-party computation with homomorphic encryption (HE) protects data\nprivacy with a formal security guarantee but suffers from high communication\noverhead. While previous works, e.g., Cheetah, Iron, etc, have proposed\nefficient HE-based protocols for different neural network (NN) operations, they\nstill assume high precision, e.g., fixed point 37 bit, for the NN operations\nand ignore NNs' native robustness against quantization error. In this paper, we\npropose HEQuant, which features low-precision-quantization-aware optimization\nfor the HE-based protocols. We observe the benefit of a naive combination of\nquantization and HE quickly saturates as bit precision goes down. Hence, to\nfurther improve communication efficiency, we propose a series of optimizations,\nincluding an intra-coefficient packing algorithm and a quantization-aware\ntiling algorithm, to simultaneously reduce the number and precision of the\ntransferred data. Compared with prior-art HE-based protocols, e.g., CrypTFlow2,\nCheetah, Iron, etc, HEQuant achieves $3.5\\sim 23.4\\times$ communication\nreduction and $3.0\\sim 9.3\\times$ latency reduction. Meanwhile, when compared\nwith prior-art network optimization frameworks, e.g., SENet, SNL, etc, HEQuant\nalso achieves $3.1\\sim 3.6\\times$ communication reduction.",
      "tldr_zh": "本论文提出 HEQuant 框架，将同态加密 (HE) 与量化技术结合，旨在解决 HE 在安全两方计算中高通信开销的问题，同时利用神经网络 (NN) 对量化错误的鲁棒性。HEQuant 通过低精度量化感知优化、intra-coefficient packing 算法和量化感知 tiling 算法，显著减少传输数据数量和精度。与现有协议如 CrypTFlow2、Cheetah 和 Iron 相比，HEQuant 实现了 3.5~23.4 倍的通信减少和 3.0~9.3 倍的延迟减少；与网络优化框架如 SENet 和 SNL 相比，也取得了 3.1~3.6 倍的通信减少，从而提升了私有推理的效率。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.15970v2",
      "published_date": "2024-01-29 08:59:05 UTC",
      "updated_date": "2024-01-31 02:11:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:15:14.970255"
    },
    {
      "arxiv_id": "2401.15969v2",
      "title": "Routers in Vision Mixture of Experts: An Empirical Study",
      "title_zh": "视觉混合专家中的路由器：实证研究",
      "authors": [
        "Tianlin Liu",
        "Mathieu Blondel",
        "Carlos Riquelme",
        "Joan Puigcerver"
      ],
      "abstract": "Mixture-of-Experts (MoE) models are a promising way to scale up model\ncapacity without significantly increasing computational cost. A key component\nof MoEs is the router, which decides which subset of parameters (experts)\nprocess which feature embeddings (tokens). In this paper, we present a\ncomprehensive study of routers in MoEs for computer vision tasks. We introduce\na unified MoE formulation that subsumes different MoEs with two parametric\nrouting tensors. This formulation covers both sparse MoE, which uses a binary\nor hard assignment between experts and tokens, and soft MoE, which uses a soft\nassignment between experts and weighted combinations of tokens. Routers for\nsparse MoEs can be further grouped into two variants: Token Choice, which\nmatches experts to each token, and Expert Choice, which matches tokens to each\nexpert. We conduct head-to-head experiments with 6 different routers, including\nexisting routers from prior work and new ones we introduce. We show that (i)\nmany routers originally developed for language modeling can be adapted to\nperform strongly in vision tasks, (ii) in sparse MoE, Expert Choice routers\ngenerally outperform Token Choice routers, and (iii) soft MoEs generally\noutperform sparse MoEs with a fixed compute budget. These results provide new\ninsights regarding the crucial role of routers in vision MoE models.",
      "tldr_zh": "这篇论文通过实证研究探讨了Mixture-of-Experts (MoE)模型在视觉任务中的路由器（routers）作用，提出一个统一的MoE公式来涵盖sparse MoE和soft MoE两种形式。研究比较了6种路由器，包括从语言模型移植的现有路由器和新引入的变体，结果显示许多路由器可有效适应视觉任务。关键发现包括：在sparse MoE中，Expert Choice路由器通常优于Token Choice路由器，而soft MoEs在固定计算预算下整体表现优于sparse MoEs。这些结果强调了路由器在视觉MoE模型中的核心重要性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.15969v2",
      "published_date": "2024-01-29 08:58:07 UTC",
      "updated_date": "2024-04-18 18:48:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:15:26.063022"
    },
    {
      "arxiv_id": "2402.01736v1",
      "title": "SADAS: A Dialogue Assistant System Towards Remediating Norm Violations in Bilingual Socio-Cultural Conversations",
      "title_zh": "翻译失败",
      "authors": [
        "Yuncheng Hua",
        "Zhuang Li",
        "Linhao Luo",
        "Kadek Ananta Satriadi",
        "Tao Feng",
        "Haolan Zhan",
        "Lizhen Qu",
        "Suraj Sharma",
        "Ingrid Zukerman",
        "Zhaleh Semnani-Azad",
        "Gholamreza Haffari"
      ],
      "abstract": "In today's globalized world, bridging the cultural divide is more critical\nthan ever for forging meaningful connections. The Socially-Aware Dialogue\nAssistant System (SADAS) is our answer to this global challenge, and it's\ndesigned to ensure that conversations between individuals from diverse cultural\nbackgrounds unfold with respect and understanding. Our system's novel\narchitecture includes: (1) identifying the categories of norms present in the\ndialogue, (2) detecting potential norm violations, (3) evaluating the severity\nof these violations, (4) implementing targeted remedies to rectify the\nbreaches, and (5) articulates the rationale behind these corrective actions. We\nemploy a series of State-Of-The-Art (SOTA) techniques to build different\nmodules, and conduct numerous experiments to select the most suitable backbone\nmodel for each of the modules. We also design a human preference experiment to\nvalidate the overall performance of the system. We will open-source our system\n(including source code, tools and applications), hoping to advance future\nresearch. A demo video of our system can be found\nat:~\\url{https://youtu.be/JqetWkfsejk}. We have released our code and software\nat:~\\url{https://github.com/AnonymousEACLDemo/SADAS}.",
      "tldr_zh": "本研究提出SADAS系统，这是一个针对双语社会文化对话的对话助手，旨在识别和修复规范违规，促进跨文化交流与理解。系统架构包括五个关键模块：识别对话中的规范类别、检测潜在违规、评估违规严重性、实施针对性修复，以及解释修复理由，并采用State-Of-The-Art (SOTA) 技术通过实验优化各模块。实验结果显示，SADAS在人类偏好测试中表现出色，将开源代码和工具以推进未来研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.01736v1",
      "published_date": "2024-01-29 08:54:21 UTC",
      "updated_date": "2024-01-29 08:54:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:15:39.488995"
    },
    {
      "arxiv_id": "2401.15966v1",
      "title": "Response Generation for Cognitive Behavioral Therapy with Large Language Models: Comparative Study with Socratic Questioning",
      "title_zh": "翻译失败",
      "authors": [
        "Kenta Izumi",
        "Hiroki Tanaka",
        "Kazuhiro Shidara",
        "Hiroyoshi Adachi",
        "Daisuke Kanayama",
        "Takashi Kudo",
        "Satoshi Nakamura"
      ],
      "abstract": "Dialogue systems controlled by predefined or rule-based scenarios derived\nfrom counseling techniques, such as cognitive behavioral therapy (CBT), play an\nimportant role in mental health apps. Despite the need for responsible\nresponses, it is conceivable that using the newly emerging LLMs to generate\ncontextually relevant utterances will enhance these apps. In this study, we\nconstruct dialogue modules based on a CBT scenario focused on conventional\nSocratic questioning using two kinds of LLMs: a Transformer-based dialogue\nmodel further trained with a social media empathetic counseling dataset,\nprovided by Osaka Prefecture (OsakaED), and GPT-4, a state-of-the art LLM\ncreated by OpenAI. By comparing systems that use LLM-generated responses with\nthose that do not, we investigate the impact of generated responses on\nsubjective evaluations such as mood change, cognitive change, and dialogue\nquality (e.g., empathy). As a result, no notable improvements are observed when\nusing the OsakaED model. When using GPT-4, the amount of mood change, empathy,\nand other dialogue qualities improve significantly. Results suggest that GPT-4\npossesses a high counseling ability. However, they also indicate that even when\nusing a dialogue model trained with a human counseling dataset, it does not\nnecessarily yield better outcomes compared to scenario-based dialogues. While\npresenting LLM-generated responses, including GPT-4, and having them interact\ndirectly with users in real-life mental health care services may raise ethical\nissues, it is still possible for human professionals to produce example\nresponses or response templates using LLMs in advance in systems that use\nrules, scenarios, or example responses.",
      "tldr_zh": "本研究比较了使用大型语言模型（LLMs）生成认知行为疗法（CBT）响应的效果，焦点在于基于苏格拉底式提问的对话模块，采用OsakaED模型（基于Transformer并用同理心咨询数据集训练）和GPT-4进行构建。研究通过主观评估（如情绪变化、认知变化和对话质量）对比LLMs生成响应与非生成系统的差异，结果显示OsakaED模型未带来显著改善，而GPT-4显著提升了情绪变化、同理心和其他对话质量，表明其具有较高的咨询能力。尽管LLMs在实际心理健康服务中可能引发伦理问题，该研究建议人类专业人士可利用LLMs预先创建响应模板以辅助规则或场景-based系统。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by IWSDS2024",
      "pdf_url": "http://arxiv.org/pdf/2401.15966v1",
      "published_date": "2024-01-29 08:53:41 UTC",
      "updated_date": "2024-01-29 08:53:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:15:52.282861"
    },
    {
      "arxiv_id": "2401.15963v3",
      "title": "NoFunEval: Funny How Code LMs Falter on Requirements Beyond Functional Correctness",
      "title_zh": "翻译失败",
      "authors": [
        "Manav Singhal",
        "Tushar Aggarwal",
        "Abhijeet Awasthi",
        "Nagarajan Natarajan",
        "Aditya Kanade"
      ],
      "abstract": "Existing evaluation benchmarks of language models of code (code LMs) focus\nalmost exclusively on whether the LMs can generate functionally-correct code.\nIn real-world software engineering, developers think beyond functional\ncorrectness. They have requirements on \"how\" a functionality should be\nimplemented to meet overall system design objectives like efficiency, security,\nand maintainability. They would also trust the code LMs more if the LMs\ndemonstrate robust understanding of such requirements.\n  We propose a new benchmark NoFunEval to evaluate code LMs on non-functional\nrequirements and simple classification instances for both functional and\nnon-functional requirements. We propose a prompting method, Coding Concepts\n(CoCo), as a way for a developer to communicate the domain knowledge to the\nLMs. We conduct an extensive evaluation of 27 code LMs. Our finding is that LMs\ngenerally falter when tested on our benchmark, hinting at fundamental\nblindspots in their training setups. Surprisingly, even the classification\naccuracy on functional-correctness instances derived from the popular HumanEval\nbenchmark is low, calling in question the depth of their comprehension and the\nsource of their success in generating functionally-correct code in the first\nplace. We release our benchmark and evaluation scripts publicly at\nhttps://aka.ms/NoFunEval.",
      "tldr_zh": "该论文提出 NoFunEval 基准，用于评估代码 LMs（code LMs）在非功能性要求（如效率、安全和可维护性）上的表现，同时包括功能正确性和简单分类任务。作者引入了 Coding Concepts (CoCo) 提示方法，帮助开发者将领域知识传达给模型，并对 27 个代码 LMs 进行了广泛评估。结果显示，这些模型在 NoFunEval 基准上表现不佳，甚至在基于 HumanEval 的功能正确性实例上分类准确率较低，揭示了模型训练设置中的根本盲点，并质疑了其生成正确代码的真正理解深度。作者已公开基准和评估脚本以促进进一步研究。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted at COLM'24",
      "pdf_url": "http://arxiv.org/pdf/2401.15963v3",
      "published_date": "2024-01-29 08:47:31 UTC",
      "updated_date": "2024-09-29 05:03:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:16:04.631741"
    },
    {
      "arxiv_id": "2401.15957v1",
      "title": "Scalable Federated Unlearning via Isolated and Coded Sharding",
      "title_zh": "翻译失败",
      "authors": [
        "Yijing Lin",
        "Zhipeng Gao",
        "Hongyang Du",
        "Dusit Niyato",
        "Gui Gui",
        "Shuguang Cui",
        "Jinke Ren"
      ],
      "abstract": "Federated unlearning has emerged as a promising paradigm to erase the\nclient-level data effect without affecting the performance of collaborative\nlearning models. However, the federated unlearning process often introduces\nextensive storage overhead and consumes substantial computational resources,\nthus hindering its implementation in practice. To address this issue, this\npaper proposes a scalable federated unlearning framework based on isolated\nsharding and coded computing. We first divide distributed clients into multiple\nisolated shards across stages to reduce the number of clients being affected.\nThen, to reduce the storage overhead of the central server, we develop a coded\ncomputing mechanism by compressing the model parameters across different\nshards. In addition, we provide the theoretical analysis of time efficiency and\nstorage effectiveness for the isolated and coded sharding. Finally, extensive\nexperiments on two typical learning tasks, i.e., classification and generation,\ndemonstrate that our proposed framework can achieve better performance than\nthree state-of-the-art frameworks in terms of accuracy, retraining time,\nstorage overhead, and F1 scores for resisting membership inference attacks.",
      "tldr_zh": "这篇论文提出了一种基于 Isolated Sharding 和 Coded Computing 的可扩展 Federated Unlearning 框架，以解决传统方法在删除客户端数据影响时面临的存储开销和计算资源消耗问题。框架通过将分布式客户端分成多个隔离的 shards 来减少受影响客户端的数量，并采用编码机制压缩模型参数，从而降低中央服务器的存储负担。实验结果显示，该框架在分类和生成任务上比现有方法在准确率、重训时间、存储开销以及抵抗成员推理攻击的 F1 分数方面均表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.15957v1",
      "published_date": "2024-01-29 08:41:45 UTC",
      "updated_date": "2024-01-29 08:41:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:16:14.954907"
    },
    {
      "arxiv_id": "2402.01735v2",
      "title": "VIALM: A Survey and Benchmark of Visually Impaired Assistance with Large Models",
      "title_zh": "VIALM：使用大型模型的视觉障碍者辅助调查与基准测试",
      "authors": [
        "Yi Zhao",
        "Yilin Zhang",
        "Rong Xiang",
        "Jing Li",
        "Hillming Li"
      ],
      "abstract": "Visually Impaired Assistance (VIA) aims to automatically help the visually\nimpaired (VI) handle daily activities. The advancement of VIA primarily depends\non developments in Computer Vision (CV) and Natural Language Processing (NLP),\nboth of which exhibit cutting-edge paradigms with large models (LMs).\nFurthermore, LMs have shown exceptional multimodal abilities to tackle\nchallenging physically-grounded tasks such as embodied robots. To investigate\nthe potential and limitations of state-of-the-art (SOTA) LMs' capabilities in\nVIA applications, we present an extensive study for the task of VIA with LMs\n(VIALM). In this task, given an image illustrating the physical environments\nand a linguistic request from a VI user, VIALM aims to output step-by-step\nguidance to assist the VI user in fulfilling the request grounded in the\nenvironment. The study consists of a survey reviewing recent LM research and\nbenchmark experiments examining selected LMs' capabilities in VIA. The results\nindicate that while LMs can potentially benefit VIA, their output cannot be\nwell environment-grounded (i.e., 25.7% GPT-4's responses) and lacks\nfine-grained guidance (i.e., 32.1% GPT-4's responses).",
      "tldr_zh": "这篇论文介绍了 VIALM，这是一个针对视觉障碍辅助 (VIA) 的调查和基准测试，评估大型模型 (LMs) 在处理图像环境和语言请求时的潜力。研究定义了 VIALM 任务，要求模型输出基于环境的步-by-步 指导，以帮助视觉障碍用户完成日常活动。结果显示，虽然 LMs 可为 VIA 带来益处，但其输出存在不接地问题（例如，25.7% GPT-4 响应）和缺乏细粒度指导（例如，32.1% GPT-4 响应），突显了当前模型的局限性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "under review",
      "pdf_url": "http://arxiv.org/pdf/2402.01735v2",
      "published_date": "2024-01-29 08:28:32 UTC",
      "updated_date": "2024-02-10 14:08:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:16:28.470839"
    },
    {
      "arxiv_id": "2401.15952v1",
      "title": "A Class-aware Optimal Transport Approach with Higher-Order Moment Matching for Unsupervised Domain Adaptation",
      "title_zh": "一种类感知最",
      "authors": [
        "Tuan Nguyen",
        "Van Nguyen",
        "Trung Le",
        "He Zhao",
        "Quan Hung Tran",
        "Dinh Phung"
      ],
      "abstract": "Unsupervised domain adaptation (UDA) aims to transfer knowledge from a\nlabeled source domain to an unlabeled target domain. In this paper, we\nintroduce a novel approach called class-aware optimal transport (OT), which\nmeasures the OT distance between a distribution over the source\nclass-conditional distributions and a mixture of source and target data\ndistribution. Our class-aware OT leverages a cost function that determines the\nmatching extent between a given data example and a source class-conditional\ndistribution. By optimizing this cost function, we find the optimal matching\nbetween target examples and source class-conditional distributions, effectively\naddressing the data and label shifts that occur between the two domains. To\nhandle the class-aware OT efficiently, we propose an amortization solution that\nemploys deep neural networks to formulate the transportation probabilities and\nthe cost function. Additionally, we propose minimizing class-aware Higher-order\nMoment Matching (HMM) to align the corresponding class regions on the source\nand target domains. The class-aware HMM component offers an economical\ncomputational approach for accurately evaluating the HMM distance between the\ntwo distributions. Extensive experiments on benchmark datasets demonstrate that\nour proposed method significantly outperforms existing state-of-the-art\nbaselines.",
      "tldr_zh": "本文提出了一种class-aware optimal transport (OT)方法，用于Unsupervised Domain Adaptation (UDA)，通过测量源域类条件分布与源-目标数据分布之间的OT距离，并优化成本函数来实现目标样本与源类条件分布的最优匹配，从而处理数据和标签偏移。方法还引入了class-aware Higher-order Moment Matching (HMM)组件，以高效计算并对齐源和目标域的类区域。实验在基准数据集上表明，该方法显著优于现有最先进基线。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages",
      "pdf_url": "http://arxiv.org/pdf/2401.15952v1",
      "published_date": "2024-01-29 08:27:31 UTC",
      "updated_date": "2024-01-29 08:27:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:16:39.681330"
    },
    {
      "arxiv_id": "2401.15944v1",
      "title": "Bridging the Domain Gap: A Simple Domain Matching Method for Reference-based Image Super-Resolution in Remote Sensing",
      "title_zh": "翻译失败",
      "authors": [
        "Jeongho Min",
        "Yejun Lee",
        "Dongyoung Kim",
        "Jaejun Yoo"
      ],
      "abstract": "Recently, reference-based image super-resolution (RefSR) has shown excellent\nperformance in image super-resolution (SR) tasks. The main idea of RefSR is to\nutilize additional information from the reference (Ref) image to recover the\nhigh-frequency components in low-resolution (LR) images. By transferring\nrelevant textures through feature matching, RefSR models outperform existing\nsingle image super-resolution (SISR) models. However, their performance\nsignificantly declines when a domain gap between Ref and LR images exists,\nwhich often occurs in real-world scenarios, such as satellite imaging. In this\nletter, we introduce a Domain Matching (DM) module that can be seamlessly\nintegrated with existing RefSR models to enhance their performance in a\nplug-and-play manner. To the best of our knowledge, we are the first to explore\nDomain Matching-based RefSR in remote sensing image processing. Our analysis\nreveals that their domain gaps often occur in different satellites, and our\nmodel effectively addresses these challenges, whereas existing models struggle.\nOur experiments demonstrate that the proposed DM module improves SR performance\nboth qualitatively and quantitatively for remote sensing super-resolution\ntasks.",
      "tldr_zh": "这项研究针对参考图像超分辨率 (RefSR) 在遥感领域的挑战，提出了一种简单的 Domain Matching (DM) 模块，用于桥接参考图像 (Ref) 和低分辨率 (LR) 图像之间的领域差距。\nDM 模块以插件式方式无缝集成到现有 RefSR 模型中，通过特征匹配转移相关纹理，从而提升模型在真实场景（如不同卫星图像）下的性能。\n实验结果表明，该方法在遥感超分辨率任务中实现了定性和定量上的显著改进，是首个探索 Domain Matching-based RefSR 在遥感图像处理中的工作。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to IEEE GRSL 2023",
      "pdf_url": "http://arxiv.org/pdf/2401.15944v1",
      "published_date": "2024-01-29 08:10:00 UTC",
      "updated_date": "2024-01-29 08:10:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:16:51.643251"
    },
    {
      "arxiv_id": "2401.15935v4",
      "title": "MLEM: Generative and Contrastive Learning as Distinct Modalities for Event Sequences",
      "title_zh": "翻译失败",
      "authors": [
        "Viktor Moskvoretskii",
        "Dmitry Osin",
        "Egor Shvetsov",
        "Igor Udovichenko",
        "Maxim Zhelnin",
        "Andrey Dukhovny",
        "Anna Zhimerikina",
        "Evgeny Burnaev"
      ],
      "abstract": "This study explores the application of self-supervised learning techniques\nfor event sequences. It is a key modality in various applications such as\nbanking, e-commerce, and healthcare. However, there is limited research on\nself-supervised learning for event sequences, and methods from other domains\nlike images, texts, and speech may not easily transfer. To determine the most\nsuitable approach, we conduct a detailed comparative analysis of previously\nidentified best-performing methods. We find that neither the contrastive nor\ngenerative method is superior. Our assessment includes classifying event\nsequences, predicting the next event, and evaluating embedding quality. These\nresults further highlight the potential benefits of combining both methods.\nGiven the lack of research on hybrid models in this domain, we initially adapt\nthe baseline model from another domain. However, upon observing its\nunderperformance, we develop a novel method called the Multimodal-Learning\nEvent Model (MLEM). MLEM treats contrastive learning and generative modeling as\ndistinct yet complementary modalities, aligning their embeddings. The results\nof our study demonstrate that combining contrastive and generative approaches\ninto one procedure with MLEM achieves superior performance across multiple\nmetrics.",
      "tldr_zh": "本研究探讨了自监督学习在事件序列上的应用，针对银行、电商和医疗等领域，但发现现有方法（如图像或文本领域）不易转移。通过对比分析对比学习和生成式学习，发现两者各有优势，且结合可带来潜在益处；为此，开发了新模型 MLEM，将 contrastive learning 和 generative modeling 视为互补模式，并对齐它们的嵌入。实验结果显示，MLEM 在事件序列分类、下一事件预测和嵌入质量评估等多项指标上，显著优于单一方法或基线模型。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.15935v4",
      "published_date": "2024-01-29 07:50:28 UTC",
      "updated_date": "2024-07-03 09:28:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:17:02.586504"
    },
    {
      "arxiv_id": "2401.15931v2",
      "title": "EmoDM: A Diffusion Model for Evolutionary Multi-objective Optimization",
      "title_zh": "EmoDM：一种用于进化多目标优化的扩散模型",
      "authors": [
        "Xueming Yan",
        "Yaochu Jin"
      ],
      "abstract": "Evolutionary algorithms have been successful in solving multi-objective\noptimization problems (MOPs). However, as a class of population-based search\nmethodology, evolutionary algorithms require a large number of evaluations of\nthe objective functions, preventing them from being applied to a wide range of\nexpensive MOPs. To tackle the above challenge, this work proposes for the first\ntime a diffusion model that can learn to perform evolutionary multi-objective\nsearch, called EmoDM. This is achieved by treating the reversed convergence\nprocess of evolutionary search as the forward diffusion and learn the noise\ndistributions from previously solved evolutionary optimization tasks. The\npre-trained EmoDM can then generate a set of non-dominated solutions for a new\nMOP by means of its reverse diffusion without further evolutionary search,\nthereby significantly reducing the required function evaluations. To enhance\nthe scalability of EmoDM, a mutual entropy-based attention mechanism is\nintroduced to capture the decision variables that are most important for the\nobjectives. Experimental results demonstrate the competitiveness of EmoDM in\nterms of both the search performance and computational efficiency compared with\nstate-of-the-art evolutionary algorithms in solving MOPs having up to 5000\ndecision variables. The pre-trained EmoDM is shown to generalize well to unseen\nproblems, revealing its strong potential as a general and efficient MOP solver.",
      "tldr_zh": "本文提出 EmoDM，一种创新的 Diffusion Model，用于进化多目标优化 (Evolutionary Multi-objective Optimization)，旨在解决传统进化算法在昂贵多目标优化问题 (MOPs) 中需大量函数评估的挑战。EmoDM 通过将进化搜索的逆向收敛过程视为前向扩散，并从先前任务中学习噪声分布，实现预训练后直接生成非支配解，从而显著减少函数评估；此外，引入基于 mutual entropy 的注意力机制来捕获关键决策变量，提升模型的可扩展性。实验结果表明，EmoDM 在搜索性能和计算效率上与最先进进化算法相当，可处理多达 5000 个决策变量的 MOPs，并对未见过的问题表现出良好的泛化能力，作为高效的通用 MOP 求解器。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.15931v2",
      "published_date": "2024-01-29 07:41:44 UTC",
      "updated_date": "2024-08-15 05:00:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:17:16.681253"
    },
    {
      "arxiv_id": "2401.15914v2",
      "title": "Overcoming the Pitfalls of Vision-Language Model Finetuning for OOD Generalization",
      "title_zh": "克服视觉语言模型微调的陷阱以实现 OOD 泛化",
      "authors": [
        "Yuhang Zang",
        "Hanlin Goh",
        "Josh Susskind",
        "Chen Huang"
      ],
      "abstract": "Existing vision-language models exhibit strong generalization on a variety of\nvisual domains and tasks. However, such models mainly perform zero-shot\nrecognition in a closed-set manner, and thus struggle to handle open-domain\nvisual concepts by design. There are recent finetuning methods, such as prompt\nlearning, that not only study the discrimination between in-distribution (ID)\nand out-of-distribution (OOD) samples, but also show some improvements in both\nID and OOD accuracies. In this paper, we first demonstrate that vision-language\nmodels, after long enough finetuning but without proper regularization, tend to\noverfit the known classes in the given dataset, with degraded performance on\nunknown classes. Then we propose a novel approach OGEN to address this pitfall,\nwith the main focus on improving the OOD GENeralization of finetuned models.\nSpecifically, a class-conditional feature generator is introduced to synthesize\nOOD features using just the class name of any unknown class. Such synthesized\nfeatures will provide useful knowledge about unknowns and help regularize the\ndecision boundary between ID and OOD data when optimized jointly. Equally\nimportant is our adaptive self-distillation mechanism to regularize our feature\ngeneration model during joint optimization, i.e., adaptively transferring\nknowledge between model states to further prevent overfitting. Experiments\nvalidate that our method yields convincing gains in OOD generalization\nperformance in different settings. Code: https://github.com/apple/ml-ogen.",
      "tldr_zh": "现有视觉语言模型(Vision-Language Models) 在微调后往往过拟合已知类，导致对未知类的 OOD Generalization 性能下降。论文提出了一种新方法 OGEN，通过引入类条件特征生成器，利用未知类的类名合成 OOD 特征，并在联合优化中正规化 ID 和 OOD 数据之间的决策边界。同时，OGEN 采用自适应自蒸馏机制来防止特征生成模型过拟合。实验结果表明，该方法在不同设置下显著提升了 OOD 泛化性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.15914v2",
      "published_date": "2024-01-29 06:57:48 UTC",
      "updated_date": "2024-04-16 03:25:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:17:28.796695"
    },
    {
      "arxiv_id": "2401.16454v1",
      "title": "KAUCUS: Knowledge Augmented User Simulators for Training Language Model Assistants",
      "title_zh": "KAUCUS：知识增强用户模拟器用于训练语言模型助手",
      "authors": [
        "Kaustubh D. Dhole"
      ],
      "abstract": "An effective multi-turn instruction-following assistant can be developed by\ncreating a simulator that can generate useful interaction data. Apart from\nrelying on its intrinsic weights, an ideal user simulator should also be able\nto bootstrap external knowledge rapidly in its raw form to simulate the\nmultifarious diversity of text available over the internet. Previous user\nsimulators generally lacked diversity, were mostly closed domain, and\nnecessitated rigid schema making them inefficient to rapidly scale to\nincorporate external knowledge. In this regard, we introduce, Kaucus, a\nKnowledge-Augmented User Simulator framework, to outline a process of creating\ndiverse user simulators, that can seamlessly exploit external knowledge as well\nas benefit downstream assistant model training. Through two GPT-J based\nsimulators viz., a Retrieval Augmented Simulator and a Summary Controlled\nSimulator we generate diverse simulator-assistant interactions. Through reward\nand preference model-based evaluations, we find that these interactions serve\nas useful training data and create more helpful downstream assistants. We also\nfind that incorporating knowledge through retrieval augmentation or summary\ncontrol helps create better assistants.",
      "tldr_zh": "本研究提出KAUCUS，一种知识增强的用户模拟器框架，用于生成多样化的交互数据以训练语言模型助手。KAUCUS通过两种基于GPT-J的模拟器——Retrieval Augmented Simulator和Summary Controlled Simulator——无缝整合外部知识，模拟互联网文本的多样性和复杂性。实验结果显示，这些模拟器生成的交互数据在奖励和偏好模型评估中表现优异，能显著提升下游助手的帮助性；此外，采用检索增强或摘要控制等知识整合方法有助于创建更有效的助手。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.IR",
        "I.2.7; H.3.3"
      ],
      "primary_category": "cs.HC",
      "comment": "Simulation of Conversational Intelligence in Chat, EACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.16454v1",
      "published_date": "2024-01-29 06:57:02 UTC",
      "updated_date": "2024-01-29 06:57:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:17:41.537686"
    },
    {
      "arxiv_id": "2402.01733v1",
      "title": "Development and Testing of Retrieval Augmented Generation in Large Language Models -- A Case Study Report",
      "title_zh": "翻译失败",
      "authors": [
        "YuHe Ke",
        "Liyuan Jin",
        "Kabilan Elangovan",
        "Hairil Rizal Abdullah",
        "Nan Liu",
        "Alex Tiong Heng Sia",
        "Chai Rick Soh",
        "Joshua Yi Min Tung",
        "Jasmine Chiat Ling Ong",
        "Daniel Shu Wei Ting"
      ],
      "abstract": "Purpose: Large Language Models (LLMs) hold significant promise for medical\napplications. Retrieval Augmented Generation (RAG) emerges as a promising\napproach for customizing domain knowledge in LLMs. This case study presents the\ndevelopment and evaluation of an LLM-RAG pipeline tailored for healthcare,\nfocusing specifically on preoperative medicine.\n  Methods: We developed an LLM-RAG model using 35 preoperative guidelines and\ntested it against human-generated responses, with a total of 1260 responses\nevaluated. The RAG process involved converting clinical documents into text\nusing Python-based frameworks like LangChain and Llamaindex, and processing\nthese texts into chunks for embedding and retrieval. Vector storage techniques\nand selected embedding models to optimize data retrieval, using Pinecone for\nvector storage with a dimensionality of 1536 and cosine similarity for loss\nmetrics. Human-generated answers, provided by junior doctors, were used as a\ncomparison.\n  Results: The LLM-RAG model generated answers within an average of 15-20\nseconds, significantly faster than the 10 minutes typically required by humans.\nAmong the basic LLMs, GPT4.0 exhibited the best accuracy of 80.1%. This\naccuracy was further increased to 91.4% when the model was enhanced with RAG.\nCompared to the human-generated instructions, which had an accuracy of 86.3%,\nthe performance of the GPT4.0 RAG model demonstrated non-inferiority (p=0.610).\n  Conclusions: In this case study, we demonstrated a LLM-RAG model for\nhealthcare implementation. The pipeline shows the advantages of grounded\nknowledge, upgradability, and scalability as important aspects of healthcare\nLLM deployment.",
      "tldr_zh": "本研究开发并评估了一个针对医疗领域的 Retrieval Augmented Generation (RAG) 管道，专注于术前医学，以增强 Large Language Models (LLMs) 的领域知识定制。方法包括使用 Python 框架如 LangChain 和 Llamaindex 将 35 份术前指南转换为文本块，进行嵌入和检索存储（利用 Pinecone 向量存储，维度 1536 和余弦相似度），并与人类生成的 1260 个响应进行比较。结果显示，RAG 增强的 GPT4.0 模型准确率从 80.1% 提高到 91.4%，生成答案时间仅需 15-20 秒，比人类 10 分钟快，且表现不劣于人类准确率 86.3%（p=0.610）。总之，该管道突出了 RAG 在医疗 LLMs 部署中的优势，包括 grounded knowledge、upgradability 和 scalability。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NA",
      "pdf_url": "http://arxiv.org/pdf/2402.01733v1",
      "published_date": "2024-01-29 06:49:53 UTC",
      "updated_date": "2024-01-29 06:49:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:17:57.839833"
    },
    {
      "arxiv_id": "2401.15911v3",
      "title": "Distribution-consistency Structural Causal Models",
      "title_zh": "分布一致性结构因果模型",
      "authors": [
        "Heyang Gong",
        "Chaochao Lu",
        "Yu Zhang"
      ],
      "abstract": "In the field of causal modeling, potential outcomes (PO) and structural\ncausal models (SCMs) stand as the predominant frameworks. However, these\nframeworks face notable challenges in practically modeling counterfactuals,\nformalized as parameters of the joint distribution of potential outcomes.\nCounterfactual reasoning holds paramount importance in contemporary\ndecision-making processes, especially in scenarios that demand personalized\nincentives based on the joint values of $(Y(0), Y(1))$. This paper begins with\nan investigation of the PO and SCM frameworks for modeling counterfactuals.\nThrough the analysis, we identify an inherent model capacity limitation, termed\nas the ``degenerative counterfactual problem'', emerging from the consistency\nrule that is the cornerstone of both frameworks. To address this limitation, we\nintroduce a novel \\textit{distribution-consistency} assumption, and in\nalignment with it, we propose the Distribution-consistency Structural Causal\nModels (DiscoSCMs) offering enhanced capabilities to model counterfactuals. To\nconcretely reveal the enhanced model capacity, we introduce a new identifiable\ncausal parameter, \\textit{the probability of consistency}, which holds\npractical significance within DiscoSCM alone, showcased with a personalized\nincentive example. Furthermore, we provide a comprehensive set of theoretical\nresults about the ``Ladder of Causation'' within the DiscoSCM framework. We\nhope it opens new avenues for future research of counterfactual modeling,\nultimately enhancing our understanding of causality and its real-world\napplications.",
      "tldr_zh": "本论文分析了潜在结果（Potential Outcomes, PO）和结构因果模型（Structural Causal Models, SCMs）在建模反事实时面临的“degenerative counterfactual problem”，该问题源于一致性规则（consistency rule），导致这些框架在处理联合潜在结果分布时能力不足。作者引入了新的分布一致性（distribution-consistency）假设，并提出分布一致性结构因果模型（Distribution-consistency Structural Causal Models, DiscoSCMs），以增强反事实建模的能力。论文还定义了一个新的可识别因果参数——“the probability of consistency”，并通过个性化激励示例展示其实际应用，同时提供了关于“the Ladder of Causation”的全面理论结果。这些创新有望推进反事实建模的研究，并提升因果关系的实际应用。",
      "categories": [
        "cs.AI",
        "math.ST",
        "stat.TH"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.15911v3",
      "published_date": "2024-01-29 06:46:15 UTC",
      "updated_date": "2024-03-23 02:15:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:18:06.032571"
    },
    {
      "arxiv_id": "2401.16453v1",
      "title": "Hybrid Transformer and Spatial-Temporal Self-Supervised Learning for Long-term Traffic Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Wang Zhu",
        "Doudou Zhang",
        "Baichao Long",
        "Jianli Xiao"
      ],
      "abstract": "Long-term traffic prediction has always been a challenging task due to its\ndynamic temporal dependencies and complex spatial dependencies. In this paper,\nwe propose a model that combines hybrid Transformer and spatio-temporal\nself-supervised learning. The model enhances its robustness by applying\nadaptive data augmentation techniques at the sequence-level and graph-level of\nthe traffic data. It utilizes Transformer to overcome the limitations of\nrecurrent neural networks in capturing long-term sequences, and employs\nChebyshev polynomial graph convolution to capture complex spatial dependencies.\nFurthermore, considering the impact of spatio-temporal heterogeneity on traffic\nspeed, we design two self-supervised learning tasks to model the temporal and\nspatial heterogeneity, thereby improving the accuracy and generalization\nability of the model. Experimental evaluations are conducted on two real-world\ndatasets, PeMS04 and PeMS08, and the results are visualized and analyzed,\ndemonstrating the superior performance of the proposed model.",
      "tldr_zh": "该论文针对长期交通预测中的动态时间依赖性和复杂空间依赖性问题，提出了一种结合混合Transformer和时空自监督学习(Self-Supervised Learning)的模型。该模型通过序列级和图级自适应数据增强技术提升鲁棒性，利用Transformer克服RNN在捕捉长序列的局限性，并采用Chebyshev polynomial graph convolution来捕获空间依赖性。此外，设计了两个自监督任务来建模时间和空间异质性，从而提高模型的准确性和泛化能力。实验在PeMS04和PeMS08真实数据集上验证，显示了该模型的优越性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "22 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.16453v1",
      "published_date": "2024-01-29 06:17:23 UTC",
      "updated_date": "2024-01-29 06:17:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:18:17.726149"
    },
    {
      "arxiv_id": "2401.17129v1",
      "title": "Enhanced Sound Event Localization and Detection in Real 360-degree audio-visual soundscapes",
      "title_zh": "在真实360度音频-视觉声景中的增强声音事件定位和检测",
      "authors": [
        "Adrian S. Roman",
        "Baladithya Balamurugan",
        "Rithik Pothuganti"
      ],
      "abstract": "This technical report details our work towards building an enhanced\naudio-visual sound event localization and detection (SELD) network. We build on\ntop of the audio-only SELDnet23 model and adapt it to be audio-visual by\nmerging both audio and video information prior to the gated recurrent unit\n(GRU) of the audio-only network. Our model leverages YOLO and DETIC object\ndetectors. We also build a framework that implements audio-visual data\naugmentation and audio-visual synthetic data generation. We deliver an\naudio-visual SELDnet system that outperforms the existing audio-visual SELD\nbaseline.",
      "tldr_zh": "这篇论文提出了一种增强的音频-视觉声事件定位和检测 (SELD) 网络，旨在处理真实 360 度音频-视觉场景。研究团队基于音频-only SELDnet23 模型，将音频和视频信息在 gated recurrent unit (GRU) 之前合并，并利用 YOLO 和 DETIC 对象检测器进行信息融合，同时开发了音频-视觉数据增强和合成数据生成框架。实验结果显示，该系统在性能上超过了现有的音频-视觉 SELD 基线。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.17129v1",
      "published_date": "2024-01-29 06:05:23 UTC",
      "updated_date": "2024-01-29 06:05:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:18:30.533108"
    },
    {
      "arxiv_id": "2401.16452v3",
      "title": "Context-Former: Stitching via Latent Conditioned Sequence Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Ziqi Zhang",
        "Jingzehua Xu",
        "Jinxin Liu",
        "Zifeng Zhuang",
        "Donglin Wang",
        "Miao Liu",
        "Shuai Zhang"
      ],
      "abstract": "Offline reinforcement learning (RL) algorithms can learn better\ndecision-making compared to behavior policies by stitching the suboptimal\ntrajectories to derive more optimal ones. Meanwhile, Decision Transformer (DT)\nabstracts the RL as sequence modeling, showcasing competitive performance on\noffline RL benchmarks. However, recent studies demonstrate that DT lacks of\nstitching capacity, thus exploiting stitching capability for DT is vital to\nfurther improve its performance. In order to endow stitching capability to DT,\nwe abstract trajectory stitching as expert matching and introduce our approach,\nContextFormer, which integrates contextual information-based imitation learning\n(IL) and sequence modeling to stitch sub-optimal trajectory fragments by\nemulating the representations of a limited number of expert trajectories. To\nvalidate our approach, we conduct experiments from two perspectives: 1) We\nconduct extensive experiments on D4RL benchmarks under the settings of IL, and\nexperimental results demonstrate ContextFormer can achieve competitive\nperformance in multiple IL settings. 2) More importantly, we conduct a\ncomparison of ContextFormer with various competitive DT variants using\nidentical training datasets. The experimental results unveiled ContextFormer's\nsuperiority, as it outperformed all other variants, showcasing its remarkable\nperformance.",
      "tldr_zh": "该论文提出 ContextFormer，一种通过潜在条件序列建模的方法，来增强 Decision Transformer (DT) 在离线强化学习 (Offline RL) 中的轨迹拼接能力。具体而言，ContextFormer 将轨迹拼接抽象为专家匹配，并结合上下文信息-based 模仿学习 (IL) 来模仿有限专家轨迹的表示，从而从次优轨迹片段中生成更优决策。在 D4RL 基准上的实验表明，ContextFormer 在多种 IL 设置中表现出色，并在与 DT 变体的比较中，使用相同训练数据集时，显著优于所有其他变体。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.16452v3",
      "published_date": "2024-01-29 06:05:14 UTC",
      "updated_date": "2024-05-27 08:38:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:18:43.456942"
    },
    {
      "arxiv_id": "2401.15896v2",
      "title": "M2-Encoder: Advancing Bilingual Image-Text Understanding by Large-scale Efficient Pretraining",
      "title_zh": "翻译失败",
      "authors": [
        "Qingpei Guo",
        "Furong Xu",
        "Hanxiao Zhang",
        "Wang Ren",
        "Ziping Ma",
        "Lin Ju",
        "Jian Wang",
        "Jingdong Chen",
        "Ming Yang"
      ],
      "abstract": "Vision-language foundation models like CLIP have revolutionized the field of\nartificial intelligence. Nevertheless, VLM models supporting multi-language,\ne.g., in both Chinese and English, have lagged due to the relative scarcity of\nlarge-scale pretraining datasets. Toward this end, we introduce a comprehensive\nbilingual (Chinese-English) dataset BM-6B with over 6 billion image-text pairs,\naimed at enhancing multimodal foundation models to well understand images in\nboth languages. To handle such a scale of dataset, we propose a novel grouped\naggregation approach for image-text contrastive loss computation, which reduces\nthe communication overhead and GPU memory demands significantly, facilitating a\n60% increase in training speed. We pretrain a series of bilingual image-text\nfoundation models with an enhanced fine-grained understanding ability on BM-6B,\nthe resulting models, dubbed as $M^2$-Encoders (pronounced \"M-Square\"), set new\nbenchmarks in both languages for multimodal retrieval and classification tasks.\nNotably, Our largest $M^2$-Encoder-10B model has achieved top-1 accuracies of\n88.5% on ImageNet and 80.7% on ImageNet-CN under a zero-shot classification\nsetting, surpassing previously reported SoTA methods by 2.2% and 21.1%,\nrespectively. The $M^2$-Encoder series represents one of the most comprehensive\nbilingual image-text foundation models to date, so we are making it available\nto the research community for further exploration and development.",
      "tldr_zh": "该研究针对多语言视觉语言模型（如 CLIP）的预训练数据集稀缺问题，构建了一个大规模双语（中英）数据集 BM-6B，包含超过 6 亿图像-文本对，以提升模型对双语图像的理解能力。论文提出了一种新型 grouped aggregation approach，用于图像-文本对比损失计算，显著减少通信开销和 GPU 内存需求，从而提高训练速度 60%。基于 BM-6B 数据集，研究团队预训练了 M²-Encoder 系列模型，这些模型在多模态检索和分类任务上表现出色，尤其在零样本分类中，最大的 M²-Encoder-10B 模型在 ImageNet 上达到 88.5% 的 top-1 准确率，在 ImageNet-CN 上达到 80.7%，分别超越现有最先进方法 2.2% 和 21.1%。该系列模型作为全面的双语图像-文本基础模型，已开源以供研究社区进一步开发。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.15896v2",
      "published_date": "2024-01-29 05:43:33 UTC",
      "updated_date": "2024-02-04 04:30:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:18:56.160475"
    },
    {
      "arxiv_id": "2401.15894v2",
      "title": "Enhancing Topological Dependencies in Spatio-Temporal Graphs with Cycle Message Passing Blocks",
      "title_zh": "翻译失败",
      "authors": [
        "Minho Lee",
        "Yun Young Choi",
        "Sun Woo Park",
        "Seunghwan Lee",
        "Joohwan Ko",
        "Jaeyoung Hong"
      ],
      "abstract": "Graph Neural Networks (GNNs) and Transformer-based models have been\nincreasingly adopted to learn the complex vector representations of\nspatio-temporal graphs, capturing intricate spatio-temporal dependencies\ncrucial for applications such as traffic datasets. Although many existing\nmethods utilize multi-head attention mechanisms and message-passing neural\nnetworks (MPNNs) to capture both spatial and temporal relations, these\napproaches encode temporal and spatial relations independently, and reflect the\ngraph's topological characteristics in a limited manner. In this work, we\nintroduce the Cycle to Mixer (Cy2Mixer), a novel spatio-temporal GNN based on\ntopological non-trivial invariants of spatio-temporal graphs with gated\nmulti-layer perceptrons (gMLP). The Cy2Mixer is composed of three blocks based\non MLPs: A temporal block for capturing temporal properties, a message-passing\nblock for encapsulating spatial information, and a cycle message-passing block\nfor enriching topological information through cyclic subgraphs. We bolster the\neffectiveness of Cy2Mixer with mathematical evidence emphasizing that our cycle\nmessage-passing block is capable of offering differentiated information to the\ndeep learning model compared to the message-passing block. Furthermore,\nempirical evaluations substantiate the efficacy of the Cy2Mixer, demonstrating\nstate-of-the-art performances across various spatio-temporal benchmark\ndatasets. The source code is available at\n\\url{https://github.com/leemingo/cy2mixer}.",
      "tldr_zh": "该论文提出了一种新型时空图神经网络（Spatio-Temporal GNN）模型Cycle to Mixer (Cy2Mixer)，旨在通过拓扑非平凡不变性（topological non-trivial invariants）和门控多层感知器（gated multi-layer perceptrons, gMLP）来增强时空图中的拓扑依赖。Cy2Mixer 由三个基于 MLP 的块组成：temporal block 捕捉时间属性、message-passing block 封装空间信息，以及 cycle message-passing block 通过循环子图丰富拓扑信息。数学证据证明 cycle message-passing block 能提供与传统 message-passing neural networks (MPNNs) 不同的信息，而实验结果显示该模型在各种时空基准数据集上达到了最先进性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Proceedings of the Third Learning on Graphs Conference (LoG 2024)",
      "pdf_url": "http://arxiv.org/pdf/2401.15894v2",
      "published_date": "2024-01-29 05:26:17 UTC",
      "updated_date": "2024-12-05 19:59:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:19:08.453293"
    },
    {
      "arxiv_id": "2401.15889v2",
      "title": "Sliced Wasserstein with Random-Path Projecting Directions",
      "title_zh": "翻译失败",
      "authors": [
        "Khai Nguyen",
        "Shujian Zhang",
        "Tam Le",
        "Nhat Ho"
      ],
      "abstract": "Slicing distribution selection has been used as an effective technique to\nimprove the performance of parameter estimators based on minimizing sliced\nWasserstein distance in applications. Previous works either utilize expensive\noptimization to select the slicing distribution or use slicing distributions\nthat require expensive sampling methods. In this work, we propose an\noptimization-free slicing distribution that provides a fast sampling for the\nMonte Carlo estimation of expectation. In particular, we introduce the\nrandom-path projecting direction (RPD) which is constructed by leveraging the\nnormalized difference between two random vectors following the two input\nmeasures. From the RPD, we derive the random-path slicing distribution (RPSD)\nand two variants of sliced Wasserstein, i.e., the Random-Path Projection Sliced\nWasserstein (RPSW) and the Importance Weighted Random-Path Projection Sliced\nWasserstein (IWRPSW). We then discuss the topological, statistical, and\ncomputational properties of RPSW and IWRPSW. Finally, we showcase the favorable\nperformance of RPSW and IWRPSW in gradient flow and the training of denoising\ndiffusion generative models on images.",
      "tldr_zh": "本文提出了一种优化-free 的 slicing distribution，名为 random-path slicing distribution (RPSD)，通过利用两个输入测度的随机向量的归一化差构建 random-path projecting direction (RPD)，以实现 Monte Carlo 估计的快速采样，从而提升基于 sliced Wasserstein 距离的参数估计性能。基于 RPSD，该研究派生出两种新变体：Random-Path Projection Sliced Wasserstein (RPSW) 和 Importance Weighted Random-Path Projection Sliced Wasserstein (IWRPSW)。实验结果表明，RPSW 和 IWRPSW 在梯度流以及训练去噪扩散生成模型上表现出色，具有优异的拓扑、统计和计算属性。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "Accepted to ICML 2024, 21 pages, 5 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2401.15889v2",
      "published_date": "2024-01-29 04:59:30 UTC",
      "updated_date": "2024-05-09 03:48:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:19:19.366179"
    },
    {
      "arxiv_id": "2401.15872v1",
      "title": "A Deep Q-Network Based on Radial Basis Functions for Multi-Echelon Inventory Management",
      "title_zh": "翻译失败",
      "authors": [
        "Liqiang Cheng",
        "Jun Luo",
        "Weiwei Fan",
        "Yidong Zhang",
        "Yuan Li"
      ],
      "abstract": "This paper addresses a multi-echelon inventory management problem with a\ncomplex network topology where deriving optimal ordering decisions is\ndifficult. Deep reinforcement learning (DRL) has recently shown potential in\nsolving such problems, while designing the neural networks in DRL remains a\nchallenge. In order to address this, a DRL model is developed whose Q-network\nis based on radial basis functions. The approach can be more easily constructed\ncompared to classic DRL models based on neural networks, thus alleviating the\ncomputational burden of hyperparameter tuning. Through a series of simulation\nexperiments, the superior performance of this approach is demonstrated compared\nto the simple base-stock policy, producing a better policy in the multi-echelon\nsystem and competitive performance in the serial system where the base-stock\npolicy is optimal. In addition, the approach outperforms current DRL\napproaches.",
      "tldr_zh": "这篇论文针对多层级库存管理(Multi-Echelon Inventory Management)问题，提出了一种基于径向基函数(Radial Basis Functions)的Deep Q-Network，用于处理复杂网络拓扑下的优化订购决策。相比传统深度强化学习(DRL)模型，该方法更易构建，显著降低了超参数调整的计算负担。通过模拟实验，证明该方法优于基础库存政策(base-stock policy)，在多层级系统中提供更好的策略，在串行系统中与最优策略竞争，并整体超越现有DRL方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.15872v1",
      "published_date": "2024-01-29 04:11:56 UTC",
      "updated_date": "2024-01-29 04:11:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:19:30.564056"
    },
    {
      "arxiv_id": "2401.15863v1",
      "title": "Importance-Aware Adaptive Dataset Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Guang Li",
        "Ren Togo",
        "Takahiro Ogawa",
        "Miki Haseyama"
      ],
      "abstract": "Herein, we propose a novel dataset distillation method for constructing small\ninformative datasets that preserve the information of the large original\ndatasets. The development of deep learning models is enabled by the\navailability of large-scale datasets. Despite unprecedented success,\nlarge-scale datasets considerably increase the storage and transmission costs,\nresulting in a cumbersome model training process. Moreover, using raw data for\ntraining raises privacy and copyright concerns. To address these issues, a new\ntask named dataset distillation has been introduced, aiming to synthesize a\ncompact dataset that retains the essential information from the large original\ndataset. State-of-the-art (SOTA) dataset distillation methods have been\nproposed by matching gradients or network parameters obtained during training\non real and synthetic datasets. The contribution of different network\nparameters to the distillation process varies, and uniformly treating them\nleads to degraded distillation performance. Based on this observation, we\npropose an importance-aware adaptive dataset distillation (IADD) method that\ncan improve distillation performance by automatically assigning importance\nweights to different network parameters during distillation, thereby\nsynthesizing more robust distilled datasets. IADD demonstrates superior\nperformance over other SOTA dataset distillation methods based on parameter\nmatching on multiple benchmark datasets and outperforms them in terms of\ncross-architecture generalization. In addition, the analysis of self-adaptive\nweights demonstrates the effectiveness of IADD. Furthermore, the effectiveness\nof IADD is validated in a real-world medical application such as COVID-19\ndetection.",
      "tldr_zh": "本论文提出了一种名为 Importance-Aware Adaptive Dataset Distillation (IADD) 的新型数据集蒸馏方法，旨在合成小型信息丰富的数据集，以保留大型原始数据集的核心信息，同时解决存储传输成本高、隐私和版权问题。IADD 通过自动为不同网络参数分配重要性权重，避免了传统方法均匀对待参数导致的性能下降，从而提升数据集蒸馏的鲁棒性。实验结果表明，IADD 在多个基准数据集上优于现有 SOTA 方法，并在跨架构泛化方面表现出色，并在实际应用如 COVID-19 检测中验证了其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Published as a journal paper in Elsevier Neural Networks",
      "pdf_url": "http://arxiv.org/pdf/2401.15863v1",
      "published_date": "2024-01-29 03:29:39 UTC",
      "updated_date": "2024-01-29 03:29:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:19:43.940586"
    },
    {
      "arxiv_id": "2401.15861v4",
      "title": "BPDec: Unveiling the Potential of Masked Language Modeling Decoder in BERT pretraining",
      "title_zh": "BPDec：揭示 BERT 预训练中掩码语言建模解码器的潜力",
      "authors": [
        "Wen Liang",
        "Youzhi Liang"
      ],
      "abstract": "BERT (Bidirectional Encoder Representations from Transformers) has\nrevolutionized the field of natural language processing through its exceptional\nperformance on numerous tasks. Yet, the majority of researchers have mainly\nconcentrated on enhancements related to the model structure, such as relative\nposition embedding and more efficient attention mechanisms. Others have delved\ninto pretraining tricks associated with Masked Language Modeling, including\nwhole word masking. DeBERTa introduced an enhanced decoder adapted for BERT's\nencoder model for pretraining, proving to be highly effective. We argue that\nthe design and research around enhanced masked language modeling decoders have\nbeen underappreciated. In this paper, we propose several designs of enhanced\ndecoders and introduce BPDec (BERT Pretraining Decoder), a novel method for\nmodeling training. Typically, a pretrained BERT model is fine-tuned for\nspecific Natural Language Understanding (NLU) tasks. In our approach, we\nutilize the original BERT model as the encoder, making only changes to the\ndecoder without altering the encoder. This approach does not necessitate\nextensive modifications to the encoder architecture and can be seamlessly\nintegrated into existing fine-tuning pipelines and services, offering an\nefficient and effective enhancement strategy. Compared to other methods, while\nwe also incur a moderate training cost for the decoder during the pretraining\nprocess, our approach does not introduce additional training costs during the\nfine-tuning phase. We test multiple enhanced decoder structures after\npretraining and evaluate their performance on the GLUE tasks and SQuAD tasks.\nOur results demonstrate that BPDec, having only undergone subtle refinements to\nthe model structure during pretraining, significantly enhances model\nperformance without escalating the finetuning cost, inference time and serving\nbudget.",
      "tldr_zh": "该论文指出，现有的BERT预训练研究主要关注模型结构和Masked Language Modeling技巧，而忽略了对解码器的优化。作者提出BPDec，一种新方法，仅在预训练阶段增强解码器设计，使用原始BERT作为编码器，从而避免对编码器进行修改。实验结果显示，BPDec在GLUE和SQuAD任务上显著提升了模型性能，同时不增加微调成本、推理时间和服务预算，为高效的BERT改进提供了可行策略。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.15861v4",
      "published_date": "2024-01-29 03:25:11 UTC",
      "updated_date": "2024-12-09 23:47:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:19:56.729827"
    },
    {
      "arxiv_id": "2401.15859v1",
      "title": "Diffusion Facial Forgery Detection",
      "title_zh": "扩散人脸伪造检测",
      "authors": [
        "Harry Cheng",
        "Yangyang Guo",
        "Tianyi Wang",
        "Liqiang Nie",
        "Mohan Kankanhalli"
      ],
      "abstract": "Detecting diffusion-generated images has recently grown into an emerging\nresearch area. Existing diffusion-based datasets predominantly focus on general\nimage generation. However, facial forgeries, which pose a more severe social\nrisk, have remained less explored thus far. To address this gap, this paper\nintroduces DiFF, a comprehensive dataset dedicated to face-focused\ndiffusion-generated images. DiFF comprises over 500,000 images that are\nsynthesized using thirteen distinct generation methods under four conditions.\nIn particular, this dataset leverages 30,000 carefully collected textual and\nvisual prompts, ensuring the synthesis of images with both high fidelity and\nsemantic consistency. We conduct extensive experiments on the DiFF dataset via\na human test and several representative forgery detection methods. The results\ndemonstrate that the binary detection accuracy of both human observers and\nautomated detectors often falls below 30%, shedding light on the challenges in\ndetecting diffusion-generated facial forgeries. Furthermore, we propose an edge\ngraph regularization approach to effectively enhance the generalization\ncapability of existing detectors.",
      "tldr_zh": "本文提出 DiFF 数据集，用于检测扩散-generated 面部伪造图像，该数据集包含超过 50 万张图像，由 13 种生成方法在 4 种条件下合成，并基于 30,000 个文本和视觉提示确保图像的高保真度和语义一致性。实验结果显示，人类测试和现有 forgery detection 方法的二元检测准确率通常低于 30%，突显了该领域的挑战。作者进一步提出边缘图正则化（edge graph regularization）方法，以提升检测器的泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "The dataset will be released at\n  \\url{https://github.com/xaCheng1996/DiFF}",
      "pdf_url": "http://arxiv.org/pdf/2401.15859v1",
      "published_date": "2024-01-29 03:20:19 UTC",
      "updated_date": "2024-01-29 03:20:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:20:08.473882"
    },
    {
      "arxiv_id": "2401.15856v2",
      "title": "The Indoor-Training Effect: unexpected gains from distribution shifts in the transition function",
      "title_zh": "室内训练效应：转移函数中分布偏移",
      "authors": [
        "Serena Bono",
        "Spandan Madan",
        "Ishaan Grover",
        "Mao Yasueda",
        "Cynthia Breazeal",
        "Hanspeter Pfister",
        "Gabriel Kreiman"
      ],
      "abstract": "Is it better to perform tennis training in a pristine indoor environment or a\nnoisy outdoor one? To model this problem, here we investigate whether shifts in\nthe transition probabilities between the training and testing environments in\nreinforcement learning problems can lead to better performance under certain\nconditions. We generate new Markov Decision Processes (MDPs) starting from a\ngiven MDP, by adding quantifiable, parametric noise into the transition\nfunction. We refer to this process as Noise Injection and the resulting\nenvironments as {\\delta}-environments. This process allows us to create\nvariations of the same environment with quantitative control over noise serving\nas a metric of distance between environments. Conventional wisdom suggests that\ntraining and testing on the same MDP should yield the best results. In stark\ncontrast, we observe that agents can perform better when trained on the\nnoise-free environment and tested on the noisy {\\delta}-environments, compared\nto training and testing on the same {\\delta}-environments. We confirm that this\nfinding extends beyond noise variations: it is possible to showcase the same\nphenomenon in ATARI game variations including varying Ghost behaviour in\nPacMan, and Paddle behaviour in Pong. We demonstrate this intriguing behaviour\nacross 60 different variations of ATARI games, including PacMan, Pong, and\nBreakout. We refer to this phenomenon as the Indoor-Training Effect. Code to\nreproduce our experiments and to implement Noise Injection can be found at\nhttps://bit.ly/3X6CTYk.",
      "tldr_zh": "本文研究了强化学习中，训练环境转移函数的分布偏移是否能意外提升性能，类似于在无噪音室内环境训练网球代理可能优于在噪音室外环境训练。作者引入 Noise Injection 方法，在 Markov Decision Processes (MDPs) 中添加参数化噪声，创建 δ-environments，以量化环境差异。实验结果显示，代理在无噪音环境训练后，在有噪音 δ-environments 测试时，表现比在相同环境训练测试更好，这一 Indoor-Training Effect 在 60 个 ATARI 游戏变体（如 PacMan 和 Pong）上得到验证。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.15856v2",
      "published_date": "2024-01-29 03:07:04 UTC",
      "updated_date": "2025-01-08 16:31:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:20:20.081902"
    },
    {
      "arxiv_id": "2401.15847v3",
      "title": "Muffin or Chihuahua? Challenging Multimodal Large Language Models with Multipanel VQA",
      "title_zh": "翻译失败",
      "authors": [
        "Yue Fan",
        "Jing Gu",
        "Kaiwen Zhou",
        "Qianqi Yan",
        "Shan Jiang",
        "Ching-Chen Kuo",
        "Xinze Guan",
        "Xin Eric Wang"
      ],
      "abstract": "Multipanel images, commonly seen as web screenshots, posters, etc., pervade\nour daily lives. These images, characterized by their composition of multiple\nsubfigures in distinct layouts, effectively convey information to people.\nToward building advanced multimodal AI applications, such as agents that\nunderstand complex scenes and navigate through webpages, the skill of\nmultipanel visual reasoning is essential, and a comprehensive evaluation of\nmodels in this regard is important. Therefore, we introduce Multipanel Visual\nQuestion Answering (MultipanelVQA), a novel benchmark comprising 6,600 triplets\nof questions, answers, and multipanel images that specifically challenge models\nin comprehending multipanel images. Our evaluation shows that questions in the\nMultipanelVQA benchmark pose significant challenges to the state-of-the-art\nMultimodal Large Language Models (MLLMs) tested, even though humans can attain\napproximately 99% accuracy on these questions. Distinctively, the MultipanelVQA\nbenchmark features synthetically generated multipanel images specifically\ncrafted to isolate and assess the impact of various factors, such as the\nlayout, on MLLMs' multipanel image comprehension abilities. As a result, in\naddition to benchmarking the capabilities of MLLMs in understanding multipanel\nimages, we analyze various factors of the multipanel image that affect MLLMs'\nperformance with synthetic data and offer insights for enhancement. Code and\ndata are released at https://sites.google.com/view/multipanelvqa/home.",
      "tldr_zh": "该研究引入了MultipanelVQA基准数据集，包含6,600个问题-答案-多面板图像的三元组，用于评估多模态大型语言模型(MLLMs)在理解多面板图像（如网页截图或海报）方面的能力。MultipanelVQA通过合成生成的多面板图像，隔离并测试因素如布局对模型性能的影响，结果显示最先进的MLLMs在该基准上表现远逊于人类（人类准确率约99%）。论文分析了这些因素对MLLMs的影响，并提供改进见解，以推动多模态AI在复杂场景推理中的发展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.15847v3",
      "published_date": "2024-01-29 02:43:40 UTC",
      "updated_date": "2024-06-27 15:38:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:20:33.391996"
    },
    {
      "arxiv_id": "2401.15842v2",
      "title": "LCV2: An Efficient Pretraining-Free Framework for Grounded Visual Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Yuhan Chen",
        "Lumei Su",
        "Lihua Chen",
        "Zhiwei Lin"
      ],
      "abstract": "In this paper, the LCV2 modular method is proposed for the Grounded Visual\nQuestion Answering task in the vision-language multimodal domain. This approach\nrelies on a frozen large language model (LLM) as intermediate mediator between\nthe off-the-shelf VQA model and the off-the-shelf visual grounding (VG) model,\nwhere the LLM transforms and conveys textual information between the two\nmodules based on a designed prompt. LCV2 establish an integrated plug-and-play\nframework without the need for any pre-training process. This framework can be\ndeployed for VQA Grounding tasks under low computational resources. The\nmodularized model within the framework allows application with various\nstate-of-the-art pre-trained models, exhibiting significant potential to be\nadvance with the times. Experimental implementations were conducted under\nconstrained computational and memory resources, evaluating the proposed\nmethod's performance on benchmark datasets including GQA, CLEVR, and\nVizWiz-VQA-Grounding. Comparative analyses with baseline methods demonstrate\nthe robust competitiveness of LCV2.",
      "tldr_zh": "本论文提出 LCV2，一种高效的无预训练框架，用于 Grounded Visual Question Answering 任务。该框架利用冻结的 LLM 作为中介，连接现成的 VQA 模型和视觉 grounding (VG) 模型，通过设计的提示实现文本信息转换，支持即插即用部署。实验在 GQA、CLEVR 和 VizWiz-VQA-Grounding 等基准数据集上显示，LCV2 在低计算资源条件下表现出色，与基线方法相比具有显著竞争力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "21 pages,9 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.15842v2",
      "published_date": "2024-01-29 02:32:25 UTC",
      "updated_date": "2024-03-23 02:46:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:20:43.424678"
    },
    {
      "arxiv_id": "2401.15834v1",
      "title": "Few and Fewer: Learning Better from Few Examples Using Fewer Base Classes",
      "title_zh": "少与更少：使用更少的基类从少量示例中实现更好的学习",
      "authors": [
        "Raphael Lafargue",
        "Yassir Bendou",
        "Bastien Pasdeloup",
        "Jean-Philippe Diguet",
        "Ian Reid",
        "Vincent Gripon",
        "Jack Valmadre"
      ],
      "abstract": "When training data is scarce, it is common to make use of a feature extractor\nthat has been pre-trained on a large base dataset, either by fine-tuning its\nparameters on the ``target'' dataset or by directly adopting its representation\nas features for a simple classifier. Fine-tuning is ineffective for few-shot\nlearning, since the target dataset contains only a handful of examples.\nHowever, directly adopting the features without fine-tuning relies on the base\nand target distributions being similar enough that these features achieve\nseparability and generalization. This paper investigates whether better\nfeatures for the target dataset can be obtained by training on fewer base\nclasses, seeking to identify a more useful base dataset for a given task.We\nconsider cross-domain few-shot image classification in eight different domains\nfrom Meta-Dataset and entertain multiple real-world settings (domain-informed,\ntask-informed and uninformed) where progressively less detail is known about\nthe target task. To our knowledge, this is the first demonstration that\nfine-tuning on a subset of carefully selected base classes can significantly\nimprove few-shot learning. Our contributions are simple and intuitive methods\nthat can be implemented in any few-shot solution. We also give insights into\nthe conditions in which these solutions are likely to provide a boost in\naccuracy. We release the code to reproduce all experiments from this paper on\nGitHub. https://github.com/RafLaf/Few-and-Fewer.git",
      "tldr_zh": "这篇论文探讨了少样本学习(few-shot learning)中的挑战，即如何通过使用更少的基类(base classes)来获得更好的特征提取效果，以提高目标任务的分类性能。作者提出简单直观的方法，通过在Meta-Dataset的八个不同领域中微调(fine-tuning)仔细选择的基类子集，显著提升了跨域图像分类的准确率，并在域知情、任务知情和无知情等真实场景下进行了验证。该方法首次证明，使用更少的基类可以改善少样本学习的泛化能力，并提供了见解和开源代码，帮助识别适合的应用条件。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "68T",
        "I.2; I.4; I.5"
      ],
      "primary_category": "cs.CV",
      "comment": "9.5 pages + bibliography and supplementary material",
      "pdf_url": "http://arxiv.org/pdf/2401.15834v1",
      "published_date": "2024-01-29 01:52:49 UTC",
      "updated_date": "2024-01-29 01:52:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:20:56.969943"
    },
    {
      "arxiv_id": "2402.03358v4",
      "title": "A Comprehensive Survey on Graph Reduction: Sparsification, Coarsening, and Condensation",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammad Hashemi",
        "Shengbo Gong",
        "Juntong Ni",
        "Wenqi Fan",
        "B. Aditya Prakash",
        "Wei Jin"
      ],
      "abstract": "Many real-world datasets can be naturally represented as graphs, spanning a\nwide range of domains. However, the increasing complexity and size of graph\ndatasets present significant challenges for analysis and computation. In\nresponse, graph reduction, or graph summarization, has gained prominence for\nsimplifying large graphs while preserving essential properties. In this survey,\nwe aim to provide a comprehensive understanding of graph reduction methods,\nincluding graph sparsification, graph coarsening, and graph condensation.\nSpecifically, we establish a unified definition for these methods and introduce\na hierarchical taxonomy to categorize the challenges they address. Our survey\nthen systematically reviews the technical details of these methods and\nemphasizes their practical applications across diverse scenarios. Furthermore,\nwe outline critical research directions to ensure the continued effectiveness\nof graph reduction techniques, as well as provide a comprehensive paper list at\n\\url{https://github.com/Emory-Melody/awesome-graph-reduction}. We hope this\nsurvey will bridge literature gaps and propel the advancement of this promising\nfield.",
      "tldr_zh": "这篇调查论文全面审视了图简化（graph reduction）技术，包括图稀疏化（graph sparsification）、图粗化（graph coarsening）和图浓缩（graph condensation），旨在简化大型图数据集的同时保留关键属性。作者建立了这些方法的统一定义，并引入了分层分类法来分类它们所解决的挑战，如图分析的复杂性和规模问题。论文系统回顾了这些技术的细节及其在多样化场景中的实际应用，并概述了关键研究方向，以推动该领域的进步。同时，提供了一个全面的论文列表（https://github.com/Emory-Melody/awesome-graph-reduction），桥接了文献空白。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.DS",
        "cs.LG"
      ],
      "primary_category": "cs.SI",
      "comment": "Accepted by IJCAI 2024 (This ArXiv version is a long version of our\n  IJCAI paper)",
      "pdf_url": "http://arxiv.org/pdf/2402.03358v4",
      "published_date": "2024-01-29 01:19:09 UTC",
      "updated_date": "2024-06-29 13:07:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:21:07.607620"
    },
    {
      "arxiv_id": "2401.15820v1",
      "title": "Knowledge-Aware Neuron Interpretation for Scene Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Yong Guan",
        "Freddy Lecue",
        "Jiaoyan Chen",
        "Ru Li",
        "Jeff Z. Pan"
      ],
      "abstract": "Although neural models have achieved remarkable performance, they still\nencounter doubts due to the intransparency. To this end, model prediction\nexplanation is attracting more and more attentions. However, current methods\nrarely incorporate external knowledge and still suffer from three limitations:\n(1) Neglecting concept completeness. Merely selecting concepts may not\nsufficient for prediction. (2) Lacking concept fusion. Failure to merge\nsemantically-equivalent concepts. (3) Difficult in manipulating model behavior.\nLack of verification for explanation on original model. To address these\nissues, we propose a novel knowledge-aware neuron interpretation framework to\nexplain model predictions for image scene classification. Specifically, for\nconcept completeness, we present core concepts of a scene based on knowledge\ngraph, ConceptNet, to gauge the completeness of concepts. Our method,\nincorporating complete concepts, effectively provides better prediction\nexplanations compared to baselines. Furthermore, for concept fusion, we\nintroduce a knowledge graph-based method known as Concept Filtering, which\nproduces over 23% point gain on neuron behaviors for neuron interpretation. At\nlast, we propose Model Manipulation, which aims to study whether the core\nconcepts based on ConceptNet could be employed to manipulate model behavior.\nThe results show that core concepts can effectively improve the performance of\noriginal model by over 26%.",
      "tldr_zh": "该研究针对神经模型在图像场景分类中的透明度问题，提出了一种知识感知神经元解释框架，以解决当前方法的三个限制：忽略概念完整性、缺乏概念融合以及难以操纵模型行为。具体而言，该框架利用知识图谱 ConceptNet 来提取场景的核心概念，确保概念完整性；引入 Concept Filtering 方法融合语义相等概念，提升神经元解释效果超过23%；并通过 Model Manipulation 技术，使用核心概念操纵模型行为，提高原模型性能超过26%。实验结果表明，该方法比基线模型提供更全面的预测解释，并显著提升了模型的可解释性和准确性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to AAAI2024",
      "pdf_url": "http://arxiv.org/pdf/2401.15820v1",
      "published_date": "2024-01-29 01:00:17 UTC",
      "updated_date": "2024-01-29 01:00:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:21:20.165967"
    },
    {
      "arxiv_id": "2401.15810v1",
      "title": "Green Runner: A tool for efficient deep learning component selection",
      "title_zh": "Green Runner：一种用于高效深度学习组件选择的工具",
      "authors": [
        "Jai Kannan"
      ],
      "abstract": "For software that relies on machine-learned functionality, model selection is\nkey to finding the right model for the task with desired performance\ncharacteristics. Evaluating a model requires developers to i) select from many\nmodels (e.g. the Hugging face model repository), ii) select evaluation metrics\nand training strategy, and iii) tailor trade-offs based on the problem domain.\nHowever, current evaluation approaches are either ad-hoc resulting in\nsub-optimal model selection or brute force leading to wasted compute. In this\nwork, we present \\toolname, a novel tool to automatically select and evaluate\nmodels based on the application scenario provided in natural language. We\nleverage the reasoning capabilities of large language models to propose a\ntraining strategy and extract desired trade-offs from a problem description.\n\\toolname~features a resource-efficient experimentation engine that integrates\nconstraints and trade-offs based on the problem into the model selection\nprocess. Our preliminary evaluation demonstrates that \\toolname{} is both\nefficient and accurate compared to ad-hoc evaluations and brute force. This\nwork presents an important step toward energy-efficient tools to help reduce\nthe environmental impact caused by the growing demand for software with\nmachine-learned functionality.",
      "tldr_zh": "本研究引入了Green Runner，一种高效工具，用于自动选择和评估深度学习组件，以优化机器学习模型的性能和资源使用。Green Runner 利用大型语言模型的推理能力，从自然语言问题描述中提取训练策略和权衡因素，并整合一个资源高效的实验引擎来处理约束和权衡。该工具在初步评估中显示出比临时评估和暴力穷举方法更高的效率和准确性，最终有助于减少软件中机器学习功能对环境的影响，促进能源节约。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.15810v1",
      "published_date": "2024-01-29 00:15:50 UTC",
      "updated_date": "2024-01-29 00:15:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T01:21:30.963561"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 110,
  "processed_papers_count": 110,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-17T01:21:53.174269"
}