[
  {
    "arxiv_id": "2401.16618v1",
    "title": "A comparison of RL-based and PID controllers for 6-DOF swimming robots: hybrid underwater object tracking",
    "authors": [
      "Faraz Lotfi",
      "Khalil Virji",
      "Nicholas Dudek",
      "Gregory Dudek"
    ],
    "abstract": "In this paper, we present an exploration and assessment of employing a\ncentralized deep Q-network (DQN) controller as a substitute for the prevalent\nuse of PID controllers in the context of 6DOF swimming robots. Our primary\nfocus centers on illustrating this transition with the specific case of\nunderwater object tracking. DQN offers advantages such as data efficiency and\noff-policy learning, while remaining simpler to implement than other\nreinforcement learning methods. Given the absence of a dynamic model for our\nrobot, we propose an RL agent to control this multi-input-multi-output (MIMO)\nsystem, where a centralized controller may offer more robust control than\ndistinct PIDs. Our approach involves initially using classical controllers for\nsafe exploration, then gradually shifting to DQN to take full control of the\nrobot.\n  We divide the underwater tracking task into vision and control modules. We\nuse established methods for vision-based tracking and introduce a centralized\nDQN controller. By transmitting bounding box data from the vision module to the\ncontrol module, we enable adaptation to various objects and effortless vision\nsystem replacement. Furthermore, dealing with low-dimensional data facilitates\ncost-effective online learning for the controller. Our experiments, conducted\nwithin a Unity-based simulator, validate the effectiveness of a centralized RL\nagent over separated PID controllers, showcasing the applicability of our\nframework for training the underwater RL agent and improved performance\ncompared to traditional control methods. The code for both real and simulation\nimplementations is at https://github.com/FARAZLOTFI/underwater-object-tracking.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.16618v1",
    "published_date": "2024-01-29 23:14:15 UTC",
    "updated_date": "2024-01-29 23:14:15 UTC"
  },
  {
    "arxiv_id": "2402.01746v1",
    "title": "3DG: A Framework for Using Generative AI for Handling Sparse Learner Performance Data From Intelligent Tutoring Systems",
    "authors": [
      "Liang Zhang",
      "Jionghao Lin",
      "Conrad Borchers",
      "Meng Cao",
      "Xiangen Hu"
    ],
    "abstract": "Learning performance data (e.g., quiz scores and attempts) is significant for\nunderstanding learner engagement and knowledge mastery level. However, the\nlearning performance data collected from Intelligent Tutoring Systems (ITSs)\noften suffers from sparsity, impacting the accuracy of learner modeling and\nknowledge assessments. To address this, we introduce the 3DG framework\n(3-Dimensional tensor for Densification and Generation), a novel approach\ncombining tensor factorization with advanced generative models, including\nGenerative Adversarial Network (GAN) and Generative Pre-trained Transformer\n(GPT), for enhanced data imputation and augmentation. The framework operates by\nfirst representing the data as a three-dimensional tensor, capturing dimensions\nof learners, questions, and attempts. It then densifies the data through tensor\nfactorization and augments it using Generative AI models, tailored to\nindividual learning patterns identified via clustering. Applied to data from an\nAutoTutor lesson by the Center for the Study of Adult Literacy (CSAL), the 3DG\nframework effectively generated scalable, personalized simulations of learning\nperformance. Comparative analysis revealed GAN's superior reliability over\nGPT-4 in this context, underscoring its potential in addressing data sparsity\nchallenges in ITSs and contributing to the advancement of personalized\neducational technology.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01746v1",
    "published_date": "2024-01-29 22:34:01 UTC",
    "updated_date": "2024-01-29 22:34:01 UTC"
  },
  {
    "arxiv_id": "2401.16587v3",
    "title": "A Linguistic Comparison between Human and ChatGPT-Generated Conversations",
    "authors": [
      "Morgan Sandler",
      "Hyesun Choung",
      "Arun Ross",
      "Prabu David"
    ],
    "abstract": "This study explores linguistic differences between human and LLM-generated\ndialogues, using 19.5K dialogues generated by ChatGPT-3.5 as a companion to the\nEmpathicDialogues dataset. The research employs Linguistic Inquiry and Word\nCount (LIWC) analysis, comparing ChatGPT-generated conversations with human\nconversations across 118 linguistic categories. Results show greater\nvariability and authenticity in human dialogues, but ChatGPT excels in\ncategories such as social processes, analytical style, cognition, attentional\nfocus, and positive emotional tone, reinforcing recent findings of LLMs being\n\"more human than human.\" However, no significant difference was found in\npositive or negative affect between ChatGPT and human dialogues. Classifier\nanalysis of dialogue embeddings indicates implicit coding of the valence of\naffect despite no explicit mention of affect in the conversations. The research\nalso contributes a novel, companion ChatGPT-generated dataset of conversations\nbetween two independent chatbots, which were designed to replicate a corpus of\nhuman conversations available for open access and used widely in AI research on\nlanguage modeling. Our findings enhance understanding of ChatGPT's linguistic\ncapabilities and inform ongoing efforts to distinguish between human and\nLLM-generated text, which is critical in detecting AI-generated fakes,\nmisinformation, and disinformation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "Proceedings of the 4th International Conference on Pattern\n  Recognition and Artificial Intelligence (ICPRAI), Jeju, Korea, 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.16587v3",
    "published_date": "2024-01-29 21:43:27 UTC",
    "updated_date": "2024-04-26 01:16:35 UTC"
  },
  {
    "arxiv_id": "2401.16580v2",
    "title": "Attention-based Reinforcement Learning for Combinatorial Optimization: Application to Job Shop Scheduling Problem",
    "authors": [
      "Jaejin Lee",
      "Seho Kee",
      "Mani Janakiram",
      "George Runger"
    ],
    "abstract": "Job shop scheduling problems represent a significant and complex facet of\ncombinatorial optimization problems, which have traditionally been addressed\nthrough either exact or approximate solution methodologies. However, the\npractical application of these solutions is often challenged due to the\ncomplexity of real-world problems. Even when utilizing an approximate solution\napproach, the time required to identify a near-optimal solution can be\nprohibitively extensive, and the solutions derived are generally not applicable\nto new problems. This study proposes an innovative attention-based\nreinforcement learning method specifically designed for the category of job\nshop scheduling problems. This method integrates a policy gradient\nreinforcement learning approach with a modified transformer architecture. A key\nfinding of this research is the ability of our trained learners within the\nproposed method to be repurposed for larger-scale problems that were not part\nof the initial training set. Furthermore, empirical evidence demonstrates that\nour approach surpasses the results of recent studies and outperforms commonly\nimplemented heuristic rules. This suggests that our method offers a promising\navenue for future research and practical application in the field of job shop\nscheduling problems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.16580v2",
    "published_date": "2024-01-29 21:31:54 UTC",
    "updated_date": "2024-03-18 17:57:22 UTC"
  },
  {
    "arxiv_id": "2401.16578v3",
    "title": "Leveraging Professional Radiologists' Expertise to Enhance LLMs' Evaluation for Radiology Reports",
    "authors": [
      "Qingqing Zhu",
      "Xiuying Chen",
      "Qiao Jin",
      "Benjamin Hou",
      "Tejas Sudharshan Mathai",
      "Pritam Mukherjee",
      "Xin Gao",
      "Ronald M Summers",
      "Zhiyong Lu"
    ],
    "abstract": "In radiology, Artificial Intelligence (AI) has significantly advanced report\ngeneration, but automatic evaluation of these AI-produced reports remains\nchallenging. Current metrics, such as Conventional Natural Language Generation\n(NLG) and Clinical Efficacy (CE), often fall short in capturing the semantic\nintricacies of clinical contexts or overemphasize clinical details, undermining\nreport clarity. To overcome these issues, our proposed method synergizes the\nexpertise of professional radiologists with Large Language Models (LLMs), like\nGPT-3.5 and GPT-4 1. Utilizing In-Context Instruction Learning (ICIL) and Chain\nof Thought (CoT) reasoning, our approach aligns LLM evaluations with\nradiologist standards, enabling detailed comparisons between human and AI\ngenerated reports. This is further enhanced by a Regression model that\naggregates sentence evaluation scores. Experimental results show that our\n\"Detailed GPT-4 (5-shot)\" model achieves a 0.48 score, outperforming the METEOR\nmetric by 0.19, while our \"Regressed GPT-4\" model shows even greater alignment\nwith expert evaluations, exceeding the best existing metric by a 0.35 margin.\nMoreover, the robustness of our explanations has been validated through a\nthorough iterative strategy. We plan to publicly release annotations from\nradiology experts, setting a new standard for accuracy in future assessments.\nThis underscores the potential of our approach in enhancing the quality\nassessment of AI-driven medical reports.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.16578v3",
    "published_date": "2024-01-29 21:24:43 UTC",
    "updated_date": "2024-02-17 03:07:00 UTC"
  },
  {
    "arxiv_id": "2401.16577v1",
    "title": "LLMs as On-demand Customizable Service",
    "authors": [
      "Souvika Sarkar",
      "Mohammad Fakhruddin Babar",
      "Monowar Hasan",
      "Shubhra Kanti Karmaker"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable language\nunderstanding and generation capabilities. However, training, deploying, and\naccessing these models pose notable challenges, including resource-intensive\ndemands, extended training durations, and scalability issues. To address these\nissues, we introduce a concept of hierarchical, distributed LLM architecture\nthat aims at enhancing the accessibility and deployability of LLMs across\nheterogeneous computing platforms, including general-purpose computers (e.g.,\nlaptops) and IoT-style devices (e.g., embedded systems). By introducing a\n\"layered\" approach, the proposed architecture enables on-demand accessibility\nto LLMs as a customizable service. This approach also ensures optimal\ntrade-offs between the available computational resources and the user's\napplication needs. We envision that the concept of hierarchical LLM will\nempower extensive, crowd-sourced user bases to harness the capabilities of\nLLMs, thereby fostering advancements in AI technology in general.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.16577v1",
    "published_date": "2024-01-29 21:24:10 UTC",
    "updated_date": "2024-01-29 21:24:10 UTC"
  },
  {
    "arxiv_id": "2401.16569v1",
    "title": "Autoencoder-Based Domain Learning for Semantic Communication with Conceptual Spaces",
    "authors": [
      "Dylan Wheeler",
      "Balasubramaniam Natarajan"
    ],
    "abstract": "Communication with the goal of accurately conveying meaning, rather than\naccurately transmitting symbols, has become an area of growing interest. This\nparadigm, termed semantic communication, typically leverages modern\ndevelopments in artificial intelligence and machine learning to improve the\nefficiency and robustness of communication systems. However, a standard model\nfor capturing and quantifying the details of \"meaning\" is lacking, with many\nleading approaches to semantic communication adopting a black-box framework\nwith little understanding of what exactly the model is learning. One solution\nis to utilize the conceptual spaces framework, which models meaning explicitly\nin a geometric manner. Though prior work studying semantic communication with\nconceptual spaces has shown promising results, these previous attempts involve\nhand-crafting a conceptual space model, severely limiting the scalability and\npracticality of the approach. In this work, we develop a framework for learning\na domain of a conceptual space model using only the raw data with high-level\nproperty labels. In experiments using the MNIST and CelebA datasets, we show\nthat the domains learned using the framework maintain semantic similarity\nrelations and possess interpretable dimensions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "eess.IV"
    ],
    "primary_category": "cs.LG",
    "comment": "6 pages, 5 figures. This work has been submitted to the IEEE for\n  possible publication",
    "pdf_url": "http://arxiv.org/pdf/2401.16569v1",
    "published_date": "2024-01-29 21:08:33 UTC",
    "updated_date": "2024-01-29 21:08:33 UTC"
  },
  {
    "arxiv_id": "2401.16561v1",
    "title": "Multi-class Regret Detection in Hindi Devanagari Script",
    "authors": [
      "Renuka Sharma",
      "Sushama Nagpal",
      "Sangeeta Sabharwal",
      "Sabur Butt"
    ],
    "abstract": "The number of Hindi speakers on social media has increased dramatically in\nrecent years. Regret is a common emotional experience in our everyday life.\nMany speakers on social media, share their regretful experiences and opinions\nregularly. It might cause a re-evaluation of one's choices and a desire to make\na different option if given the chance. As a result, knowing the source of\nregret is critical for investigating its impact on behavior and\ndecision-making. This study focuses on regret and how it is expressed,\nspecifically in Hindi, on various social media platforms. In our study, we\npresent a novel dataset from three different sources, where each sentence has\nbeen manually classified into one of three classes \"Regret by action\", \"Regret\nby inaction\", and \"No regret\". Next, we use this dataset to investigate the\nlinguistic expressions of regret in Hindi text and also identify the textual\ndomains that are most frequently associated with regret. Our findings indicate\nthat individuals on social media platforms frequently express regret for both\npast inactions and actions, particularly within the domain of interpersonal\nrelationships. We use a pre-trained BERT model to generate word embeddings for\nthe Hindi dataset and also compare deep learning models with conventional\nmachine learning models in order to demonstrate accuracy. Our results show that\nBERT embedding with CNN consistently surpassed other models. This described the\neffectiveness of BERT for conveying the context and meaning of words in the\nregret domain.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.16561v1",
    "published_date": "2024-01-29 20:58:43 UTC",
    "updated_date": "2024-01-29 20:58:43 UTC"
  },
  {
    "arxiv_id": "2401.16553v7",
    "title": "SelectLLM: Can LLMs Select Important Instructions to Annotate?",
    "authors": [
      "Ritik Sachin Parkar",
      "Jaehyung Kim",
      "Jong Inn Park",
      "Dongyeop Kang"
    ],
    "abstract": "Instruction tuning benefits from large and diverse datasets; however,\ncreating such datasets involves a high cost of human labeling. While synthetic\ndatasets generated by large language models (LLMs) have partly solved this\nissue, they often contain low-quality data. One effective solution is\nselectively annotating unlabelled instructions, especially given the relative\nease of acquiring unlabeled instructions or texts from various sources.\nHowever, how to select unlabelled instructions is not well-explored, especially\nin the context of LLMs. Therefore, we introduce SelectLLM, an alternative\nframework that leverages the capabilities of LLMs to select unlabeled\ninstructions more effectively. Specifically, SelectLLM consists of two key\nsteps: Coreset-based clustering of unlabelled instructions for enlarging\ndiversity and prompting of LLM to identify the most beneficial instructions\nwithin each cluster. We evaluate SelectLLM on AlpacaEval2 and MT-Bench,\ndemonstrating its ability to outperform state-of-the-art methods like\nAlpagasus. In addition, we compare the performance and compatibility of\nSelectLLM with various LLMs, such as ChatGPT, LLaMA-3.1-70B, and Gemma-2-27b.\nSelectLLM's adaptability and robustness are further evidenced by its ability to\nmaintain high performance across both human and synthetic datasets. All code\nand data are publicly available (https://github.com/minnesotanlp/select-llm).",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "First Authors: Ritik Sachin Parkar and Jaehyung Kim | Second Author:\n  Jong Inn Park | PI: Dongyeop Kang",
    "pdf_url": "http://arxiv.org/pdf/2401.16553v7",
    "published_date": "2024-01-29 20:44:10 UTC",
    "updated_date": "2024-08-27 17:57:07 UTC"
  },
  {
    "arxiv_id": "2401.16541v1",
    "title": "GuReT: Distinguishing Guilt and Regret related Text",
    "authors": [
      "Sabur Butt",
      "Fazlourrahman Balouchzahi",
      "Abdul Gafar Manuel Meque",
      "Maaz Amjad",
      "Hector G. Ceballos Cancino",
      "Grigori Sidorov",
      "Alexander Gelbukh"
    ],
    "abstract": "The intricate relationship between human decision-making and emotions,\nparticularly guilt and regret, has significant implications on behavior and\nwell-being. Yet, these emotions subtle distinctions and interplay are often\noverlooked in computational models. This paper introduces a dataset tailored to\ndissect the relationship between guilt and regret and their unique textual\nmarkers, filling a notable gap in affective computing research. Our approach\ntreats guilt and regret recognition as a binary classification task and employs\nthree machine learning and six transformer-based deep learning techniques to\nbenchmark the newly created dataset. The study further implements innovative\nreasoning methods like chain-of-thought and tree-of-thought to assess the\nmodels interpretive logic. The results indicate a clear performance edge for\ntransformer-based models, achieving a 90.4% macro F1 score compared to the\n85.3% scored by the best machine learning classifier, demonstrating their\nsuperior capability in distinguishing complex emotional states.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.16541v1",
    "published_date": "2024-01-29 20:20:44 UTC",
    "updated_date": "2024-01-29 20:20:44 UTC"
  },
  {
    "arxiv_id": "2402.00066v1",
    "title": "TrackGPT -- A generative pre-trained transformer for cross-domain entity trajectory forecasting",
    "authors": [
      "Nicholas Stroh"
    ],
    "abstract": "The forecasting of entity trajectories at future points in time is a critical\ncapability gap in applications across both Commercial and Defense sectors.\nTransformers, and specifically Generative Pre-trained Transformer (GPT)\nnetworks have recently revolutionized several fields of Artificial\nIntelligence, most notably Natural Language Processing (NLP) with the advent of\nLarge Language Models (LLM) like OpenAI's ChatGPT. In this research paper, we\nintroduce TrackGPT, a GPT-based model for entity trajectory forecasting that\nhas shown utility across both maritime and air domains, and we expect to\nperform well in others. TrackGPT stands as a pioneering GPT model capable of\nproducing accurate predictions across diverse entity time series datasets,\ndemonstrating proficiency in generating both long-term forecasts with sustained\naccuracy and short-term forecasts with high precision. We present benchmarks\nagainst state-of-the-art deep learning techniques, showing that TrackGPT's\nforecasting capability excels in terms of accuracy, reliability, and\nmodularity. Importantly, TrackGPT achieves these results while remaining\ndomain-agnostic and requiring minimal data features (only location and time)\ncompared to models achieving similar performance. In conclusion, our findings\nunderscore the immense potential of applying GPT architectures to the task of\nentity trajectory forecasting, exemplified by the innovative TrackGPT model.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "68T07"
    ],
    "primary_category": "cs.LG",
    "comment": "16 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.00066v1",
    "published_date": "2024-01-29 20:05:14 UTC",
    "updated_date": "2024-01-29 20:05:14 UTC"
  },
  {
    "arxiv_id": "2401.16521v1",
    "title": "Validation, Robustness, and Accuracy of Perturbation-Based Sensitivity Analysis Methods for Time-Series Deep Learning Models",
    "authors": [
      "Zhengguang Wang"
    ],
    "abstract": "This work undertakes studies to evaluate Interpretability Methods for\nTime-Series Deep Learning. Sensitivity analysis assesses how input changes\naffect the output, constituting a key component of interpretation. Among the\npost-hoc interpretation methods such as back-propagation, perturbation, and\napproximation, my work will investigate perturbation-based sensitivity Analysis\nmethods on modern Transformer models to benchmark their performances.\nSpecifically, my work answers three research questions: 1) Do different\nsensitivity analysis (SA) methods yield comparable outputs and attribute\nimportance rankings? 2) Using the same sensitivity analysis method, do\ndifferent Deep Learning (DL) models impact the output of the sensitivity\nanalysis? 3) How well do the results from sensitivity analysis methods align\nwith the ground truth?",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.16521v1",
    "published_date": "2024-01-29 19:51:50 UTC",
    "updated_date": "2024-01-29 19:51:50 UTC"
  },
  {
    "arxiv_id": "2401.16501v1",
    "title": "AFSD-Physics: Exploring the governing equations of temperature evolution during additive friction stir deposition by a human-AI teaming approach",
    "authors": [
      "Tony Shi",
      "Mason Ma",
      "Jiajie Wu",
      "Chase Post",
      "Elijah Charles",
      "Tony Schmitz"
    ],
    "abstract": "This paper presents a modeling effort to explore the underlying physics of\ntemperature evolution during additive friction stir deposition (AFSD) by a\nhuman-AI teaming approach. AFSD is an emerging solid-state additive\nmanufacturing technology that deposits materials without melting. However, both\nprocess modeling and modeling of the AFSD tool are at an early stage. In this\npaper, a human-AI teaming approach is proposed to combine models based on first\nprinciples with AI. The resulting human-informed machine learning method,\ndenoted as AFSD-Physics, can effectively learn the governing equations of\ntemperature evolution at the tool and the build from in-process measurements.\nExperiments are designed and conducted to collect in-process measurements for\nthe deposition of aluminum 7075 with a total of 30 layers. The acquired\ngoverning equations are physically interpretable models with low computational\ncost and high accuracy. Model predictions show good agreement with the\nmeasurements. Experimental validation with new process parameters demonstrates\nthe model's generalizability and potential for use in tool temperature control\nand process optimization.",
    "categories": [
      "cs.LG",
      "cond-mat.mtrl-sci",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.16501v1",
    "published_date": "2024-01-29 19:17:42 UTC",
    "updated_date": "2024-01-29 19:17:42 UTC"
  },
  {
    "arxiv_id": "2401.16421v2",
    "title": "Two Stones Hit One Bird: Bilevel Positional Encoding for Better Length Extrapolation",
    "authors": [
      "Zhenyu He",
      "Guhao Feng",
      "Shengjie Luo",
      "Kai Yang",
      "Liwei Wang",
      "Jingjing Xu",
      "Zhi Zhang",
      "Hongxia Yang",
      "Di He"
    ],
    "abstract": "In this work, we leverage the intrinsic segmentation of language sequences\nand design a new positional encoding method called Bilevel Positional Encoding\n(BiPE). For each position, our BiPE blends an intra-segment encoding and an\ninter-segment encoding. The intra-segment encoding identifies the locations\nwithin a segment and helps the model capture the semantic information therein\nvia absolute positional encoding. The inter-segment encoding specifies the\nsegment index, models the relationships between segments, and aims to improve\nextrapolation capabilities via relative positional encoding. Theoretical\nanalysis shows this disentanglement of positional information makes learning\nmore effective. The empirical results also show that our BiPE has superior\nlength extrapolation capabilities across a wide range of tasks in diverse text\nmodalities.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "17 pages, 7 figures, 8 tables; ICML 2024 Camera Ready version; Code:\n  https://github.com/zhenyuhe00/BiPE",
    "pdf_url": "http://arxiv.org/pdf/2401.16421v2",
    "published_date": "2024-01-29 18:59:07 UTC",
    "updated_date": "2024-06-17 06:18:13 UTC"
  },
  {
    "arxiv_id": "2401.17123v1",
    "title": "Unsupervised Discovery of Steerable Factors When Graph Deep Generative Models Are Entangled",
    "authors": [
      "Shengchao Liu",
      "Chengpeng Wang",
      "Jiarui Lu",
      "Weili Nie",
      "Hanchen Wang",
      "Zhuoxinran Li",
      "Bolei Zhou",
      "Jian Tang"
    ],
    "abstract": "Deep generative models (DGMs) have been widely developed for graph data.\nHowever, much less investigation has been carried out on understanding the\nlatent space of such pretrained graph DGMs. These understandings possess the\npotential to provide constructive guidelines for crucial tasks, such as graph\ncontrollable generation. Thus in this work, we are interested in studying this\nproblem and propose GraphCG, a method for the unsupervised discovery of\nsteerable factors in the latent space of pretrained graph DGMs. We first\nexamine the representation space of three pretrained graph DGMs with six\ndisentanglement metrics, and we observe that the pretrained representation\nspace is entangled. Motivated by this observation, GraphCG learns the steerable\nfactors via maximizing the mutual information between semantic-rich directions,\nwhere the controlled graph moving along the same direction will share the same\nsteerable factors. We quantitatively verify that GraphCG outperforms four\ncompetitive baselines on two graph DGMs pretrained on two molecule datasets.\nAdditionally, we qualitatively illustrate seven steerable factors learned by\nGraphCG on five pretrained DGMs over five graph datasets, including two for\nmolecules and three for point clouds.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.17123v1",
    "published_date": "2024-01-29 18:53:34 UTC",
    "updated_date": "2024-01-29 18:53:34 UTC"
  },
  {
    "arxiv_id": "2401.16412v4",
    "title": "Learning to Manipulate under Limited Information",
    "authors": [
      "Wesley H. Holliday",
      "Alexander Kristoffersen",
      "Eric Pacuit"
    ],
    "abstract": "By classic results in social choice theory, any reasonable preferential\nvoting method sometimes gives individuals an incentive to report an insincere\npreference. The extent to which different voting methods are more or less\nresistant to such strategic manipulation has become a key consideration for\ncomparing voting methods. Here we measure resistance to manipulation by whether\nneural networks of various sizes can learn to profitably manipulate a given\nvoting method in expectation, given different types of limited information\nabout how other voters will vote. We trained over 100,000 neural networks of 26\nsizes to manipulate against 8 different voting methods, under 6 types of\nlimited information, in committee-sized elections with 5-21 voters and 3-6\ncandidates. We find that some voting methods, such as Borda, are highly\nmanipulable by networks with limited information, while others, such as Instant\nRunoff, are not, despite being quite profitably manipulated by an ideal\nmanipulator with full information. For the three probability models for\nelections that we use, the overall least manipulable of the 8 methods we study\nare Condorcet methods, namely Minimax and Split Cycle.",
    "categories": [
      "cs.AI",
      "cs.GT",
      "cs.LG",
      "cs.MA",
      "econ.TH",
      "91B12, 91B14, 91B10, 68T07",
      "I.2.6; I.2.11"
    ],
    "primary_category": "cs.AI",
    "comment": "Final version for Proceedings of the 39th Annual AAAI Conference on\n  Artificial Intelligence (AAAI-25)",
    "pdf_url": "http://arxiv.org/pdf/2401.16412v4",
    "published_date": "2024-01-29 18:49:50 UTC",
    "updated_date": "2025-02-22 21:33:28 UTC"
  },
  {
    "arxiv_id": "2401.16467v2",
    "title": "ReGAL: Refactoring Programs to Discover Generalizable Abstractions",
    "authors": [
      "Elias Stengel-Eskin",
      "Archiki Prasad",
      "Mohit Bansal"
    ],
    "abstract": "While large language models (LLMs) are increasingly being used for program\nsynthesis, they lack the global view needed to develop useful abstractions;\nthey generally predict programs one at a time, often repeating the same\nfunctionality. Generating redundant code from scratch is both inefficient and\nerror-prone. To address this, we propose Refactoring for Generalizable\nAbstraction Learning (ReGAL), a gradient-free method for learning a library of\nreusable functions via code refactorization, i.e., restructuring code without\nchanging its execution output. ReGAL learns from a small set of existing\nprograms, iteratively verifying and refining its abstractions via execution. We\nfind that the shared function libraries discovered by ReGAL make programs\neasier to predict across diverse domains. On five datasets -- LOGO graphics\ngeneration, Date reasoning, TextCraft (a Minecraft-based text-game) MATH, and\nTabMWP -- both open-source and proprietary LLMs improve in accuracy when\npredicting programs with ReGAL functions. For CodeLlama-13B, ReGAL results in\nabsolute accuracy increases of 11.5% on LOGO, 26.1% on date understanding, and\n8.1% on TextCraft, outperforming GPT-3.5 in two of three domains. Our analysis\nreveals ReGAL's abstractions encapsulate frequently-used subroutines as well as\nenvironment dynamics.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.PL"
    ],
    "primary_category": "cs.SE",
    "comment": "ICML 2024 Camera-Ready; First two authors contributed equally; Code:\n  https://github.com/esteng/regal_program_learning",
    "pdf_url": "http://arxiv.org/pdf/2401.16467v2",
    "published_date": "2024-01-29 18:45:30 UTC",
    "updated_date": "2024-06-06 17:31:07 UTC"
  },
  {
    "arxiv_id": "2401.16405v2",
    "title": "Scaling Sparse Fine-Tuning to Large Language Models",
    "authors": [
      "Alan Ansell",
      "Ivan Vulić",
      "Hannah Sterz",
      "Anna Korhonen",
      "Edoardo M. Ponti"
    ],
    "abstract": "Large Language Models (LLMs) are difficult to fully fine-tune (e.g., with\ninstructions or human feedback) due to their sheer number of parameters. A\nfamily of parameter-efficient sparse fine-tuning methods have proven promising\nin terms of performance but their memory requirements increase proportionally\nto the size of the LLMs. In this work, we scale sparse fine-tuning to\nstate-of-the-art LLMs like LLaMA 2 7B and 13B. We propose SpIEL, a novel sparse\nfine-tuning method which, for a desired density level, maintains an array of\nparameter indices and the deltas of these parameters relative to their\npretrained values. It iterates over: (a) updating the active deltas, (b)\npruning indices (based on the change of magnitude of their deltas) and (c)\nregrowth of indices. For regrowth, we explore two criteria based on either the\naccumulated gradients of a few candidate parameters or their approximate\nmomenta estimated using the efficient SM3 optimizer. We experiment with\ninstruction-tuning of LLMs on standard dataset mixtures, finding that SpIEL is\noften superior to popular parameter-efficient fine-tuning methods like LoRA\n(low-rank adaptation) in terms of performance and comparable in terms of run\ntime. We additionally show that SpIEL is compatible with both quantization and\nefficient optimizers, to facilitate scaling to ever-larger model sizes. We\nrelease the code for SpIEL at https://github.com/AlanAnsell/peft and for the\ninstruction-tuning experiments at https://github.com/ducdauge/sft-llm.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.16405v2",
    "published_date": "2024-01-29 18:43:49 UTC",
    "updated_date": "2024-02-02 14:53:14 UTC"
  },
  {
    "arxiv_id": "2401.16402v1",
    "title": "A Survey on Visual Anomaly Detection: Challenge, Approach, and Prospect",
    "authors": [
      "Yunkang Cao",
      "Xiaohao Xu",
      "Jiangning Zhang",
      "Yuqi Cheng",
      "Xiaonan Huang",
      "Guansong Pang",
      "Weiming Shen"
    ],
    "abstract": "Visual Anomaly Detection (VAD) endeavors to pinpoint deviations from the\nconcept of normality in visual data, widely applied across diverse domains,\ne.g., industrial defect inspection, and medical lesion detection. This survey\ncomprehensively examines recent advancements in VAD by identifying three\nprimary challenges: 1) scarcity of training data, 2) diversity of visual\nmodalities, and 3) complexity of hierarchical anomalies. Starting with a brief\noverview of the VAD background and its generic concept definitions, we\nprogressively categorize, emphasize, and discuss the latest VAD progress from\nthe perspective of sample number, data modality, and anomaly hierarchy. Through\nan in-depth analysis of the VAD field, we finally summarize future developments\nfor VAD and conclude the key findings and contributions of this survey.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Work in progress. Yunkang Cao, Xiaohao Xu, and Jiangning Zhang\n  contribute equally to this work",
    "pdf_url": "http://arxiv.org/pdf/2401.16402v1",
    "published_date": "2024-01-29 18:41:21 UTC",
    "updated_date": "2024-01-29 18:41:21 UTC"
  },
  {
    "arxiv_id": "2401.16398v1",
    "title": "Zero-shot Imitation Policy via Search in Demonstration Dataset",
    "authors": [
      "Federco Malato",
      "Florian Leopold",
      "Andrew Melnik",
      "Ville Hautamaki"
    ],
    "abstract": "Behavioral cloning uses a dataset of demonstrations to learn a policy. To\novercome computationally expensive training procedures and address the policy\nadaptation problem, we propose to use latent spaces of pre-trained foundation\nmodels to index a demonstration dataset, instantly access similar relevant\nexperiences, and copy behavior from these situations. Actions from a selected\nsimilar situation can be performed by the agent until representations of the\nagent's current situation and the selected experience diverge in the latent\nspace. Thus, we formulate our control problem as a dynamic search problem over\na dataset of experts' demonstrations. We test our approach on BASALT\nMineRL-dataset in the latent representation of a Video Pre-Training model. We\ncompare our model to state-of-the-art, Imitation Learning-based Minecraft\nagents. Our approach can effectively recover meaningful demonstrations and show\nhuman-like behavior of an agent in the Minecraft environment in a wide variety\nof scenarios. Experimental results reveal that performance of our search-based\napproach clearly wins in terms of accuracy and perceptual evaluation over\nlearning-based models.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.16398v1",
    "published_date": "2024-01-29 18:38:29 UTC",
    "updated_date": "2024-01-29 18:38:29 UTC"
  },
  {
    "arxiv_id": "2401.16367v1",
    "title": "TQCompressor: improving tensor decomposition methods in neural networks via permutations",
    "authors": [
      "V. Abronin",
      "A. Naumov",
      "D. Mazur",
      "D. Bystrov",
      "K. Tsarova",
      "Ar. Melnikov",
      "I. Oseledets",
      "S. Dolgov",
      "R. Brasher",
      "M. Perelshtein"
    ],
    "abstract": "We introduce TQCompressor, a novel method for neural network model\ncompression with improved tensor decompositions. We explore the challenges\nposed by the computational and storage demands of pre-trained language models\nin NLP tasks and propose a permutation-based enhancement to Kronecker\ndecomposition. This enhancement makes it possible to reduce loss in model\nexpressivity which is usually associated with factorization. We demonstrate\nthis method applied to the GPT-2$_{small}$. The result of the compression is\nTQCompressedGPT-2 model, featuring 81 mln. parameters compared to 124 mln. in\nthe GPT-2$_{small}$. We make TQCompressedGPT-2 publicly available. We further\nenhance the performance of the TQCompressedGPT-2 through a training strategy\ninvolving multi-step knowledge distillation, using only a 3.1% of the\nOpenWebText. TQCompressedGPT-2 surpasses DistilGPT-2 and KnGPT-2 in comparative\nevaluations, marking an advancement in the efficient and effective deployment\nof models in resource-constrained environments.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.16367v1",
    "published_date": "2024-01-29 18:07:56 UTC",
    "updated_date": "2024-01-29 18:07:56 UTC"
  },
  {
    "arxiv_id": "2401.16352v4",
    "title": "Adversarial Training on Purification (AToP): Advancing Both Robustness and Generalization",
    "authors": [
      "Guang Lin",
      "Chao Li",
      "Jianhai Zhang",
      "Toshihisa Tanaka",
      "Qibin Zhao"
    ],
    "abstract": "The deep neural networks are known to be vulnerable to well-designed\nadversarial attacks. The most successful defense technique based on adversarial\ntraining (AT) can achieve optimal robustness against particular attacks but\ncannot generalize well to unseen attacks. Another effective defense technique\nbased on adversarial purification (AP) can enhance generalization but cannot\nachieve optimal robustness. Meanwhile, both methods share one common limitation\non the degraded standard accuracy. To mitigate these issues, we propose a novel\npipeline to acquire the robust purifier model, named Adversarial Training on\nPurification (AToP), which comprises two components: perturbation destruction\nby random transforms (RT) and purifier model fine-tuned (FT) by adversarial\nloss. RT is essential to avoid overlearning to known attacks, resulting in the\nrobustness generalization to unseen attacks, and FT is essential for the\nimprovement of robustness. To evaluate our method in an efficient and scalable\nway, we conduct extensive experiments on CIFAR-10, CIFAR-100, and ImageNette to\ndemonstrate that our method achieves optimal robustness and exhibits\ngeneralization ability against unseen attacks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.16352v4",
    "published_date": "2024-01-29 17:56:42 UTC",
    "updated_date": "2024-08-23 06:08:14 UTC"
  },
  {
    "arxiv_id": "2401.16350v1",
    "title": "FedFair^3: Unlocking Threefold Fairness in Federated Learning",
    "authors": [
      "Simin Javaherian",
      "Sanjeev Panta",
      "Shelby Williams",
      "Md Sirajul Islam",
      "Li Chen"
    ],
    "abstract": "Federated Learning (FL) is an emerging paradigm in machine learning without\nexposing clients' raw data. In practical scenarios with numerous clients,\nencouraging fair and efficient client participation in federated learning is of\nutmost importance, which is also challenging given the heterogeneity in data\ndistribution and device properties. Existing works have proposed different\nclient-selection methods that consider fairness; however, they fail to select\nclients with high utilities while simultaneously achieving fair accuracy\nlevels. In this paper, we propose a fair client-selection approach that unlocks\nthreefold fairness in federated learning. In addition to having a fair\nclient-selection strategy, we enforce an equitable number of rounds for client\nparticipation and ensure a fair accuracy distribution over the clients. The\nexperimental results demonstrate that FedFair^3, in comparison to the\nstate-of-the-art baselines, achieves 18.15% less accuracy variance on the IID\ndata and 54.78% on the non-IID data, without decreasing the global accuracy.\nFurthermore, it shows 24.36% less wall-clock training time on average.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.16350v1",
    "published_date": "2024-01-29 17:56:15 UTC",
    "updated_date": "2024-01-29 17:56:15 UTC"
  },
  {
    "arxiv_id": "2401.16335v1",
    "title": "Iterative Data Smoothing: Mitigating Reward Overfitting and Overoptimization in RLHF",
    "authors": [
      "Banghua Zhu",
      "Michael I. Jordan",
      "Jiantao Jiao"
    ],
    "abstract": "Reinforcement Learning from Human Feedback (RLHF) is a pivotal technique that\naligns language models closely with human-centric values. The initial phase of\nRLHF involves learning human values using a reward model from ranking data. It\nis observed that the performance of the reward model degrades after one epoch\nof training, and optimizing too much against the learned reward model\neventually hinders the true objective. This paper delves into these issues,\nleveraging the theoretical insights to design improved reward learning\nalgorithm termed 'Iterative Data Smoothing' (IDS). The core idea is that during\neach training epoch, we not only update the model with the data, but also\nupdate the date using the model, replacing hard labels with soft labels. Our\nempirical findings highlight the superior performance of this approach over the\ntraditional methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.16335v1",
    "published_date": "2024-01-29 17:43:42 UTC",
    "updated_date": "2024-01-29 17:43:42 UTC"
  },
  {
    "arxiv_id": "2401.16332v4",
    "title": "Tradeoffs Between Alignment and Helpfulness in Language Models with Representation Engineering",
    "authors": [
      "Yotam Wolf",
      "Noam Wies",
      "Dorin Shteyman",
      "Binyamin Rothberg",
      "Yoav Levine",
      "Amnon Shashua"
    ],
    "abstract": "Language model alignment has become an important component of AI safety,\nallowing safe interactions between humans and language models, by enhancing\ndesired behaviors and inhibiting undesired ones. It is often done by tuning the\nmodel or inserting preset aligning prompts. Recently, representation\nengineering, a method which alters the model's behavior via changing its\nrepresentations post-training, was shown to be effective in aligning LLMs (Zou\net al., 2023a). Representation engineering yields gains in alignment oriented\ntasks such as resistance to adversarial attacks and reduction of social biases,\nbut was also shown to cause a decrease in the ability of the model to perform\nbasic tasks. In this paper we study the tradeoff between the increase in\nalignment and decrease in helpfulness of the model. We propose a theoretical\nframework which provides bounds for these two quantities, and demonstrate their\nrelevance empirically. First, we find that under the conditions of our\nframework, alignment can be guaranteed with representation engineering, and at\nthe same time that helpfulness is harmed in the process. Second, we show that\nhelpfulness is harmed quadratically with the norm of the representation\nengineering vector, while the alignment increases linearly with it, indicating\na regime in which it is efficient to use representation engineering. We\nvalidate our findings empirically, and chart the boundaries to the usefulness\nof representation engineering for alignment.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.16332v4",
    "published_date": "2024-01-29 17:38:14 UTC",
    "updated_date": "2024-10-03 13:40:39 UTC"
  },
  {
    "arxiv_id": "2402.14021v1",
    "title": "Betting on what is neither verifiable nor falsifiable",
    "authors": [
      "Abhimanyu Pallavi Sudhir",
      "Long Tran-Thanh"
    ],
    "abstract": "Prediction markets are useful for estimating probabilities of claims whose\ntruth will be revealed at some fixed time -- this includes questions about the\nvalues of real-world events (i.e. statistical uncertainty), and questions about\nthe values of primitive recursive functions (i.e. logical or algorithmic\nuncertainty). However, they cannot be directly applied to questions without a\nfixed resolution criterion, and real-world applications of prediction markets\nto such questions often amount to predicting not whether a sentence is true,\nbut whether it will be proven. Such questions could be represented by countable\nunions or intersections of more basic events, or as First-Order-Logic sentences\non the Arithmetical Hierarchy (or even beyond FOL, as hyperarithmetical\nsentences). In this paper, we propose an approach to betting on such events via\noptions, or equivalently as bets on the outcome of a\n\"verification-falsification game\". Our work thus acts as an alternative to the\nexisting framework of Garrabrant induction for logical uncertainty, and relates\nto the stance known as constructivism in the philosophy of mathematics;\nfurthermore it has broader implications for philosophy and mathematical logic.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.LO",
      "91B26 (Primary), 03F03 (Secondary)",
      "F.4.1; I.2.11"
    ],
    "primary_category": "cs.GT",
    "comment": "15 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.14021v1",
    "published_date": "2024-01-29 17:30:34 UTC",
    "updated_date": "2024-01-29 17:30:34 UTC"
  },
  {
    "arxiv_id": "2402.01744v4",
    "title": "Unveiling Molecular Moieties through Hierarchical Grad-CAM Graph Explainability",
    "authors": [
      "Salvatore Contino",
      "Paolo Sortino",
      "Maria Rita Gulotta",
      "Ugo Perricone",
      "Roberto Pirrone"
    ],
    "abstract": "Background: Virtual Screening (VS) has become an essential tool in drug\ndiscovery, enabling the rapid and cost-effective identification of potential\nbioactive molecules. Among recent advancements, Graph Neural Networks (GNNs)\nhave gained prominence for their ability to model complex molecular structures\nusing graph-based representations. However, the integration of explainable\nmethods to elucidate the specific contributions of molecular substructures to\nbiological activity remains a significant challenge. This limitation hampers\nboth the interpretability of predictive models and the rational design of novel\ntherapeutics.\\\\ Results: We trained 20 GNN models on a dataset of small\nmolecules with the goal of predicting their activity on 20 distinct protein\ntargets from the Kinase family. These classifiers achieved state-of-the-art\nperformance in virtual screening tasks, demonstrating high accuracy and\nrobustness on different targets. Building upon these models, we implemented the\nHierarchical Grad-CAM graph Explainer (HGE) framework, enabling an in-depth\nanalysis of the molecular moieties driving protein-ligand binding\nstabilization. HGE exploits Grad-CAM explanations at the atom, ring, and\nwhole-molecule levels, leveraging the message-passing mechanism to highlight\nthe most relevant chemical moieties. Validation against experimental data from\nthe literature confirmed the ability of the explainer to recognize a molecular\npattern of drugs and correctly annotate them to the known target. Conclusion:\nOur approach may represent a valid support to shorten both the screening and\nthe hit discovery process. Detailed knowledge of the molecular substructures\nthat play a role in the binding process can help the computational chemist to\ngain insights into the structure optimization, as well as in drug repurposing\ntasks.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG",
      "q-bio.MN"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01744v4",
    "published_date": "2024-01-29 17:23:25 UTC",
    "updated_date": "2025-04-17 12:16:35 UTC"
  },
  {
    "arxiv_id": "2401.16318v2",
    "title": "Defining and Extracting generalizable interaction primitives from DNNs",
    "authors": [
      "Lu Chen",
      "Siyu Lou",
      "Benhao Huang",
      "Quanshi Zhang"
    ],
    "abstract": "Faithfully summarizing the knowledge encoded by a deep neural network (DNN)\ninto a few symbolic primitive patterns without losing much information\nrepresents a core challenge in explainable AI. To this end, Ren et al. (2024)\nhave derived a series of theorems to prove that the inference score of a DNN\ncan be explained as a small set of interactions between input variables.\nHowever, the lack of generalization power makes it still hard to consider such\ninteractions as faithful primitive patterns encoded by the DNN. Therefore,\ngiven different DNNs trained for the same task, we develop a new method to\nextract interactions that are shared by these DNNs. Experiments show that the\nextracted interactions can better reflect common knowledge shared by different\nDNNs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.16318v2",
    "published_date": "2024-01-29 17:21:41 UTC",
    "updated_date": "2024-09-13 12:27:44 UTC"
  },
  {
    "arxiv_id": "2402.01743v1",
    "title": "The Reasoning Under Uncertainty Trap: A Structural AI Risk",
    "authors": [
      "Toby D. Pilditch"
    ],
    "abstract": "This report examines a novel risk associated with current (and projected) AI\ntools. Making effective decisions about future actions requires us to reason\nunder uncertainty (RUU), and doing so is essential to many critical real world\nproblems. Overfaced by this challenge, there is growing demand for AI tools\nlike LLMs to assist decision-makers. Having evidenced this demand and the\nincentives behind it, we expose a growing risk: we 1) do not currently\nsufficiently understand LLM capabilities in this regard, and 2) have no\nguarantees of performance given fundamental computational explosiveness and\ndeep uncertainty constraints on accuracy. This report provides an exposition of\nwhat makes RUU so challenging for both humans and machines, and relates these\ndifficulties to prospective AI timelines and capabilities. Having established\nthis current potential misuse risk, we go on to expose how this seemingly\nadditive risk (more misuse additively contributed to potential harm) in fact\nhas multiplicative properties. Specifically, we detail how this misuse risk\nconnects to a wider network of underlying structural risks (e.g., shifting\nincentives, limited transparency, and feedback loops) to produce non-linear\nharms. We go on to provide a solutions roadmap that targets multiple leverage\npoints in the structure of the problem. This includes recommendations for all\ninvolved actors (prospective users, developers, and policy-makers) and enfolds\ninsights from areas including Decision-making Under Deep Uncertainty and\ncomplex systems theory. We argue this report serves not only to raise awareness\n(and subsequently mitigate/correct) of a current, novel AI risk, but also\nawareness of the underlying class of structural risks by illustrating how their\ninterconnected nature poses twin-dangers of camouflaging their presence, whilst\namplifying their potential effects.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "51 pages (excluding references), 7 chapters, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.01743v1",
    "published_date": "2024-01-29 17:16:57 UTC",
    "updated_date": "2024-01-29 17:16:57 UTC"
  },
  {
    "arxiv_id": "2401.16310v3",
    "title": "An Insight into Security Code Review with LLMs: Capabilities, Obstacles and Influential Factors",
    "authors": [
      "Jiaxin Yu",
      "Peng Liang",
      "Yujia Fu",
      "Amjed Tahir",
      "Mojtaba Shahin",
      "Chong Wang",
      "Yangxiao Cai"
    ],
    "abstract": "Security code review is a time-consuming and labor-intensive process\ntypically requiring integration with automated security defect detection tools.\nHowever, existing security analysis tools struggle with poor generalization,\nhigh false positive rates, and coarse detection granularity. Large Language\nModels (LLMs) have been considered promising candidates for addressing those\nchallenges. In this study, we conducted an empirical study to explore the\npotential of LLMs in detecting security defects during code review.\nSpecifically, we evaluated the performance of six LLMs under five different\nprompts and compared them with state-of-theart static analysis tools. We also\nperformed linguistic and regression analyses for the best-performing LLM to\nidentify quality problems in its responses and factors influencing its\nperformance. Our findings show that: (1) existing pre-trained LLMs have limited\ncapability in security code review but? significantly outperform the\nstate-of-the-art static analysis tools. (2) GPT-4 performs best among all LLMs\nwhen provided with a CWE list for reference. (3) GPT-4 frequently generates\nresponses that are verbose or not compliant with the task requirements given in\nthe prompts. (4) GPT-4 is more adept at identifying security defects in code\nfiles with fewer tokens, containing functional logic, or written by developers\nwith less involvement in the project.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "26 pages, 5 images, 7 tables, Manuscript submitted to a journal\n  (2024)",
    "pdf_url": "http://arxiv.org/pdf/2401.16310v3",
    "published_date": "2024-01-29 17:13:44 UTC",
    "updated_date": "2024-10-04 18:02:55 UTC"
  },
  {
    "arxiv_id": "2401.16299v1",
    "title": "Enhancing Molecular Property Prediction with Auxiliary Learning and Task-Specific Adaptation",
    "authors": [
      "Vishal Dey",
      "Xia Ning"
    ],
    "abstract": "Pretrained Graph Neural Networks have been widely adopted for various\nmolecular property prediction tasks. Despite their ability to encode structural\nand relational features of molecules, traditional fine-tuning of such\npretrained GNNs on the target task can lead to poor generalization. To address\nthis, we explore the adaptation of pretrained GNNs to the target task by\njointly training them with multiple auxiliary tasks. This could enable the GNNs\nto learn both general and task-specific features, which may benefit the target\ntask. However, a major challenge is to determine the relatedness of auxiliary\ntasks with the target task. To address this, we investigate multiple strategies\nto measure the relevance of auxiliary tasks and integrate such tasks by\nadaptively combining task gradients or by learning task weights via bi-level\noptimization. Additionally, we propose a novel gradient surgery-based approach,\nRotation of Conflicting Gradients ($\\mathtt{RCGrad}$), that learns to align\nconflicting auxiliary task gradients through rotation. Our experiments with\nstate-of-the-art pretrained GNNs demonstrate the efficacy of our proposed\nmethods, with improvements of up to 7.7% over fine-tuning. This suggests that\nincorporating auxiliary tasks along with target task fine-tuning can be an\neffective way to improve the generalizability of pretrained GNNs for molecular\nproperty prediction.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.16299v1",
    "published_date": "2024-01-29 17:00:28 UTC",
    "updated_date": "2024-01-29 17:00:28 UTC"
  },
  {
    "arxiv_id": "2401.16298v1",
    "title": "Breaking the Barrier: Selective Uncertainty-based Active Learning for Medical Image Segmentation",
    "authors": [
      "Siteng Ma",
      "Haochang Wu",
      "Aonghus Lawlor",
      "Ruihai Dong"
    ],
    "abstract": "Active learning (AL) has found wide applications in medical image\nsegmentation, aiming to alleviate the annotation workload and enhance\nperformance. Conventional uncertainty-based AL methods, such as entropy and\nBayesian, often rely on an aggregate of all pixel-level metrics. However, in\nimbalanced settings, these methods tend to neglect the significance of target\nregions, eg., lesions, and tumors. Moreover, uncertainty-based selection\nintroduces redundancy. These factors lead to unsatisfactory performance, and in\nmany cases, even underperform random sampling. To solve this problem, we\nintroduce a novel approach called the Selective Uncertainty-based AL, avoiding\nthe conventional practice of summing up the metrics of all pixels. Through a\nfiltering process, our strategy prioritizes pixels within target areas and\nthose near decision boundaries. This resolves the aforementioned disregard for\ntarget areas and redundancy. Our method showed substantial improvements across\nfive different uncertainty-based methods and two distinct datasets, utilizing\nfewer labeled data to reach the supervised baseline and consistently achieving\nthe highest overall performance. Our code is available at\nhttps://github.com/HelenMa9998/Selective\\_Uncertainty\\_AL.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.16298v1",
    "published_date": "2024-01-29 16:59:39 UTC",
    "updated_date": "2024-01-29 16:59:39 UTC"
  },
  {
    "arxiv_id": "2401.16294v1",
    "title": "Dual feature-based and example-based explanation methods",
    "authors": [
      "Andrei V. Konstantinov",
      "Boris V. Kozlov",
      "Stanislav R. Kirpichenko",
      "Lev V. Utkin"
    ],
    "abstract": "A new approach to the local and global explanation is proposed. It is based\non selecting a convex hull constructed for the finite number of points around\nan explained instance. The convex hull allows us to consider a dual\nrepresentation of instances in the form of convex combinations of extreme\npoints of a produced polytope. Instead of perturbing new instances in the\nEuclidean feature space, vectors of convex combination coefficients are\nuniformly generated from the unit simplex, and they form a new dual dataset. A\ndual linear surrogate model is trained on the dual dataset. The explanation\nfeature importance values are computed by means of simple matrix calculations.\nThe approach can be regarded as a modification of the well-known model LIME.\nThe dual representation inherently allows us to get the example-based\nexplanation. The neural additive model is also considered as a tool for\nimplementing the example-based explanation approach. Many numerical experiments\nwith real datasets are performed for studying the approach. The code of\nproposed algorithms is available.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.16294v1",
    "published_date": "2024-01-29 16:53:04 UTC",
    "updated_date": "2024-01-29 16:53:04 UTC"
  },
  {
    "arxiv_id": "2401.16293v1",
    "title": "Textual Entailment for Effective Triple Validation in Object Prediction",
    "authors": [
      "Andrés García-Silva",
      "Cristian Berrío",
      "José Manuel Gómez-Pérez"
    ],
    "abstract": "Knowledge base population seeks to expand knowledge graphs with facts that\nare typically extracted from a text corpus. Recently, language models\npretrained on large corpora have been shown to contain factual knowledge that\ncan be retrieved using cloze-style strategies. Such approach enables zero-shot\nrecall of facts, showing competitive results in object prediction compared to\nsupervised baselines. However, prompt-based fact retrieval can be brittle and\nheavily depend on the prompts and context used, which may produce results that\nare unintended or hallucinatory.We propose to use textual entailment to\nvalidate facts extracted from language models through cloze statements. Our\nresults show that triple validation based on textual entailment improves\nlanguage model predictions in different training regimes. Furthermore, we show\nthat entailment-based triple validation is also effective to validate candidate\nfacts extracted from other sources including existing knowledge graphs and text\npassages where named entities are recognized.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DL"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ISWC'23 - The International Semantic Web Conference",
    "pdf_url": "http://arxiv.org/pdf/2401.16293v1",
    "published_date": "2024-01-29 16:50:56 UTC",
    "updated_date": "2024-01-29 16:50:56 UTC"
  },
  {
    "arxiv_id": "2401.16287v1",
    "title": "GAPS: Geometry-Aware Problem Solver",
    "authors": [
      "Jiaxin Zhang",
      "Yinghui Jiang",
      "Yashar Moshfeghi"
    ],
    "abstract": "Geometry problem solving presents a formidable challenge within the NLP\ncommunity. Existing approaches often rely on models designed for solving math\nword problems, neglecting the unique characteristics of geometry math problems.\nAdditionally, the current research predominantly focuses on geometry\ncalculation problems, while overlooking other essential aspects like proving.\nIn this study, we address these limitations by proposing the Geometry-Aware\nProblem Solver (GAPS) model. GAPS is specifically designed to generate solution\nprograms for geometry math problems of various types with the help of its\nunique problem-type classifier. To achieve this, GAPS treats the solution\nprogram as a composition of operators and operands, segregating their\ngeneration processes. Furthermore, we introduce the geometry elements\nenhancement method, which enhances the ability of GAPS to recognize geometry\nelements accurately. By leveraging these improvements, GAPS showcases\nremarkable performance in resolving geometry math problems. Our experiments\nconducted on the UniGeo dataset demonstrate the superiority of GAPS over the\nstate-of-the-art model, Geoformer. Specifically, GAPS achieves an accuracy\nimprovement of more than 5.3% for calculation tasks and an impressive 41.1% for\nproving tasks. Notably, GAPS achieves an impressive accuracy of 97.5% on\nproving problems, representing a significant advancement in solving geometry\nproving tasks.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.16287v1",
    "published_date": "2024-01-29 16:48:34 UTC",
    "updated_date": "2024-01-29 16:48:34 UTC"
  },
  {
    "arxiv_id": "2401.16285v1",
    "title": "Capturing Pertinent Symbolic Features for Enhanced Content-Based Misinformation Detection",
    "authors": [
      "Flavio Merenda",
      "José Manuel Gómez-Pérez"
    ],
    "abstract": "Preventing the spread of misinformation is challenging. The detection of\nmisleading content presents a significant hurdle due to its extreme linguistic\nand domain variability. Content-based models have managed to identify deceptive\nlanguage by learning representations from textual data such as social media\nposts and web articles. However, aggregating representative samples of this\nheterogeneous phenomenon and implementing effective real-world applications is\nstill elusive. Based on analytical work on the language of misinformation, this\npaper analyzes the linguistic attributes that characterize this phenomenon and\nhow representative of such features some of the most popular misinformation\ndatasets are. We demonstrate that the appropriate use of pertinent symbolic\nknowledge in combination with neural language models is helpful in detecting\nmisleading content. Our results achieve state-of-the-art performance in\nmisinformation datasets across the board, showing that our approach offers a\nvalid and robust alternative to multi-task transfer learning without requiring\nany additional training data. Furthermore, our results show evidence that\nstructured knowledge can provide the extra boost required to address a complex\nand unpredictable real-world problem like misinformation detection, not only in\nterms of accuracy but also time efficiency and resource utilization.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at K-CAP'23: The 12th Knowledge Capture Conference",
    "pdf_url": "http://arxiv.org/pdf/2401.16285v1",
    "published_date": "2024-01-29 16:42:34 UTC",
    "updated_date": "2024-01-29 16:42:34 UTC"
  },
  {
    "arxiv_id": "2401.16282v1",
    "title": "MAPLE: Micro Analysis of Pairwise Language Evolution for Few-Shot Claim Verification",
    "authors": [
      "Xia Zeng",
      "Arkaitz Zubiaga"
    ],
    "abstract": "Claim verification is an essential step in the automated fact-checking\npipeline which assesses the veracity of a claim against a piece of evidence. In\nthis work, we explore the potential of few-shot claim verification, where only\nvery limited data is available for supervision. We propose MAPLE (Micro\nAnalysis of Pairwise Language Evolution), a pioneering approach that explores\nthe alignment between a claim and its evidence with a small seq2seq model and a\nnovel semantic measure. Its innovative utilization of micro language evolution\npath leverages unlabelled pairwise data to facilitate claim verification while\nimposing low demand on data annotations and computing resources. MAPLE\ndemonstrates significant performance improvements over SOTA baselines SEED, PET\nand LLaMA 2 across three fact-checking datasets: FEVER, Climate FEVER, and\nSciFact. Data and code are available here: https://github.com/XiaZeng0223/MAPLE",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "accepted by EACL Findings 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.16282v1",
    "published_date": "2024-01-29 16:39:39 UTC",
    "updated_date": "2024-01-29 16:39:39 UTC"
  },
  {
    "arxiv_id": "2402.01742v1",
    "title": "Towards Optimizing the Costs of LLM Usage",
    "authors": [
      "Shivanshu Shekhar",
      "Tanishq Dubey",
      "Koyel Mukherjee",
      "Apoorv Saxena",
      "Atharv Tyagi",
      "Nishanth Kotla"
    ],
    "abstract": "Generative AI and LLMs in particular are heavily used nowadays for various\ndocument processing tasks such as question answering and summarization.\nHowever, different LLMs come with different capabilities for different tasks as\nwell as with different costs, tokenization, and latency. In fact, enterprises\nare already incurring huge costs of operating or using LLMs for their\nrespective use cases.\n  In this work, we propose optimizing the usage costs of LLMs by estimating\ntheir output quality (without actually invoking the LLMs), and then solving an\noptimization routine for the LLM selection to either keep costs under a budget,\nor minimize the costs, in a quality and latency aware manner. We propose a\nmodel to predict the output quality of LLMs on document processing tasks like\nsummarization, followed by an LP rounding algorithm to optimize the selection\nof LLMs. We study optimization problems trading off the quality and costs, both\ntheoretically and empirically. We further propose a sentence simplification\nmodel for reducing the number of tokens in a controlled manner. Additionally,\nwe propose several deterministic heuristics for reducing tokens in a quality\naware manner, and study the related optimization problem of applying the\nheuristics optimizing the quality and cost trade-off. We perform extensive\nempirical validation of our methods on not only enterprise datasets but also on\nopen-source datasets, annotated by us, and show that we perform much better\ncompared to closest baselines. Our methods reduce costs by 40%- 90% while\nimproving quality by 4%-7%. We will release the annotated open source datasets\nto the community for further research and exploration.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages + Appendix, Total 12 pages",
    "pdf_url": "http://arxiv.org/pdf/2402.01742v1",
    "published_date": "2024-01-29 16:36:31 UTC",
    "updated_date": "2024-01-29 16:36:31 UTC"
  },
  {
    "arxiv_id": "2402.00065v1",
    "title": "A technical note for the 91-clauses SAT resolution with Indirect QAOA based approach",
    "authors": [
      "Gerard Fleury",
      "Philippe Lacomme"
    ],
    "abstract": "This paper addresses the resolution of the 3-SAT problem using a QAOA-like\napproach. The chosen principle involves modeling the solution ranks of the\n3-SAT problem, which, in this particular case, directly represent a solution.\nThis results in a highly compact circuit with few gates, enabling the modeling\nof large-sized 3-SAT problems. Numerical experimentation demonstrates that the\napproach can solve instances composed of 91 clauses and 20 variables with an\nimplementation based on Qiskit.",
    "categories": [
      "cs.AI",
      "quant-ph"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00065v1",
    "published_date": "2024-01-29 16:29:35 UTC",
    "updated_date": "2024-01-29 16:29:35 UTC"
  },
  {
    "arxiv_id": "2401.16270v2",
    "title": "Capturing Knowledge Graphs and Rules with Octagon Embeddings",
    "authors": [
      "Victor Charpenay",
      "Steven Schockaert"
    ],
    "abstract": "Region based knowledge graph embeddings represent relations as geometric\nregions. This has the advantage that the rules which are captured by the model\nare made explicit, making it straightforward to incorporate prior knowledge and\nto inspect learned models. Unfortunately, existing approaches are severely\nrestricted in their ability to model relational composition, and hence also\ntheir ability to model rules, thus failing to deliver on the main promise of\nregion based models. With the aim of addressing these limitations, we\ninvestigate regions which are composed of axis-aligned octagons. Such octagons\nare particularly easy to work with, as intersections and compositions can be\nstraightforwardly computed, while they are still sufficiently expressive to\nmodel arbitrary knowledge graphs. Among others, we also show that our octagon\nembeddings can properly capture a non-trivial class of rule bases. Finally, we\nshow that our model achieves competitive experimental results.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted for IJCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.16270v2",
    "published_date": "2024-01-29 16:18:54 UTC",
    "updated_date": "2024-06-18 15:29:55 UTC"
  },
  {
    "arxiv_id": "2401.16258v1",
    "title": "MosquIoT: A System Based on IoT and Machine Learning for the Monitoring of Aedes aegypti (Diptera: Culicidae)",
    "authors": [
      "Javier Aira",
      "Teresa Olivares Montes",
      "Francisco M. Delicado",
      "Darìo Vezzani"
    ],
    "abstract": "Millions of people around the world are infected with mosquito-borne diseases\neach year. One of the most dangerous species is Aedes aegypti, the main vector\nof viruses such as dengue, yellow fever, chikungunya, and Zika, among others.\nMosquito prevention and eradication campaigns are essential to avoid major\npublic health consequences. In this respect, entomological surveillance is an\nimportant tool. At present, this traditional monitoring tool is executed\nmanually and requires digital transformation to help authorities make better\ndecisions, improve their planning efforts, speed up execution, and better\nmanage available resources. Therefore, new technological tools based on proven\ntechniques need to be designed and developed. However, such tools should also\nbe cost-effective, autonomous, reliable, and easy to implement, and should be\nenabled by connectivity and multi-platform software applications. This paper\npresents the design, development, and testing of an innovative system named\nMosquIoT. It is based on traditional ovitraps with embedded Internet of Things\n(IoT) and Tiny Machine Learning (TinyML) technologies, which enable the\ndetection and quantification of Ae. aegypti eggs. This innovative and promising\nsolution may help dynamically understand the behavior of Ae. aegypti\npopulations in cities, shifting from the current reactive entomological\nmonitoring model to a proactive and predictive digital one.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.16258v1",
    "published_date": "2024-01-29 16:08:18 UTC",
    "updated_date": "2024-01-29 16:08:18 UTC"
  },
  {
    "arxiv_id": "2402.01741v2",
    "title": "Development and Testing of a Novel Large Language Model-Based Clinical Decision Support Systems for Medication Safety in 12 Clinical Specialties",
    "authors": [
      "Jasmine Chiat Ling Ong",
      "Liyuan Jin",
      "Kabilan Elangovan",
      "Gilbert Yong San Lim",
      "Daniel Yan Zheng Lim",
      "Gerald Gui Ren Sng",
      "Yuhe Ke",
      "Joshua Yi Min Tung",
      "Ryan Jian Zhong",
      "Christopher Ming Yao Koh",
      "Keane Zhi Hao Lee",
      "Xiang Chen",
      "Jack Kian Chng",
      "Aung Than",
      "Ken Junyang Goh",
      "Daniel Shu Wei Ting"
    ],
    "abstract": "Importance: We introduce a novel Retrieval Augmented Generation (RAG)-Large\nLanguage Model (LLM) framework as a Clinical Decision Support Systems (CDSS) to\nsupport safe medication prescription.\n  Objective: To evaluate the efficacy of LLM-based CDSS in correctly\nidentifying medication errors in different patient case vignettes from diverse\nmedical and surgical sub-disciplines, against a human expert panel derived\nground truth. We compared performance for under 2 different CDSS practical\nhealthcare integration modalities: LLM-based CDSS alone (fully autonomous mode)\nvs junior pharmacist + LLM-based CDSS (co-pilot, assistive mode).\n  Design, Setting, and Participants: Utilizing a RAG model with\nstate-of-the-art medically-related LLMs (GPT-4, Gemini Pro 1.0 and Med-PaLM 2),\nthis study used 61 prescribing error scenarios embedded into 23 complex\nclinical vignettes across 12 different medical and surgical specialties. A\nmultidisciplinary expert panel assessed these cases for Drug-Related Problems\n(DRPs) using the PCNE classification and graded severity / potential for harm\nusing revised NCC MERP medication error index. We compared.\n  Results RAG-LLM performed better compared to LLM alone. When employed in a\nco-pilot mode, accuracy, recall, and F1 scores were optimized, indicating\neffectiveness in identifying moderate to severe DRPs. The accuracy of DRP\ndetection with RAG-LLM improved in several categories but at the expense of\nlower precision.\n  Conclusions This study established that a RAG-LLM based CDSS significantly\nboosts the accuracy of medication error identification when used alongside\njunior pharmacists (co-pilot), with notable improvements in detecting severe\nDRPs. This study also illuminates the comparative performance of current\nstate-of-the-art LLMs in RAG-based CDSS systems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01741v2",
    "published_date": "2024-01-29 16:03:29 UTC",
    "updated_date": "2024-02-17 21:13:16 UTC"
  },
  {
    "arxiv_id": "2401.16251v3",
    "title": "Cross-silo Federated Learning with Record-level Personalized Differential Privacy",
    "authors": [
      "Junxu Liu",
      "Jian Lou",
      "Li Xiong",
      "Jinfei Liu",
      "Xiaofeng Meng"
    ],
    "abstract": "Federated learning (FL) enhanced by differential privacy has emerged as a\npopular approach to better safeguard the privacy of client-side data by\nprotecting clients' contributions during the training process. Existing\nsolutions typically assume a uniform privacy budget for all records and provide\none-size-fits-all solutions that may not be adequate to meet each record's\nprivacy requirement. In this paper, we explore the uncharted territory of\ncross-silo FL with record-level personalized differential privacy. We devise a\nnovel framework named \\textit{rPDP-FL}, employing a two-stage hybrid sampling\nscheme with both uniform client-level sampling and non-uniform record-level\nsampling to accommodate varying privacy requirements.\n  A critical and non-trivial problem is how to determine the ideal per-record\nsampling probability $q$ given the personalized privacy budget $\\varepsilon$.\nWe introduce a versatile solution named \\textit{Simulation-CurveFitting},\nallowing us to uncover a significant insight into the nonlinear correlation\nbetween $q$ and $\\varepsilon$ and derive an elegant mathematical model to\ntackle the problem. Our evaluation demonstrates that our solution can provide\nsignificant performance gains over the baselines that do not consider\npersonalized privacy preservation.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "15 pages, 8 figures, accepted by CCS'2024",
    "pdf_url": "http://arxiv.org/pdf/2401.16251v3",
    "published_date": "2024-01-29 16:01:46 UTC",
    "updated_date": "2024-06-29 14:58:30 UTC"
  },
  {
    "arxiv_id": "2402.01740v3",
    "title": "Reducing Selection Bias in Large Language Models",
    "authors": [
      "J. E. Eicher",
      "R. F. Irgolič"
    ],
    "abstract": "Large Language Models (LLMs) like gpt-3.5-turbo-0613 and claude-instant-1.2\nare vital in interpreting and executing semantic tasks. Unfortunately, these\nmodels' inherent biases adversely affect their performance Particularly\naffected is object selection from lists; a fundamental operation in digital\nnavigation and decision-making. This research critically examines these biases\nand quantifies the effects on a representative list selection task. To explore\nthese biases, we experiment manipulating temperature, list length, object\nidentity, object type, prompt complexity, and model. We isolated and measured\nthe influence of the biases on selection behavior. Our findings show that bias\nstructure is strongly dependent on the model, with object type modulating the\nmagnitude of the effect. With a strong primacy effect, causing the first\nobjects in a list to be disproportionately represented in outputs. The usage of\nguard rails, a prompt engineering method of ensuring a response structure,\nincreases bias and decreases instruction adherence when to a selection task.\nThe bias is ablated when the guard rail step is separated from the list\nsampling step, lowering the complexity of each individual task. We provide LLM\napplications and theoretically suggest that LLMs experience a form of cognitive\nload that is compensated for with bias.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.0"
    ],
    "primary_category": "cs.CL",
    "comment": "28 pages, 23 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.01740v3",
    "published_date": "2024-01-29 15:43:23 UTC",
    "updated_date": "2024-06-15 13:23:21 UTC"
  },
  {
    "arxiv_id": "2401.16240v2",
    "title": "Combining Hierachical VAEs with LLMs for clinically meaningful timeline summarisation in social media",
    "authors": [
      "Jiayu Song",
      "Jenny Chim",
      "Adam Tsakalidis",
      "Julia Ive",
      "Dana Atzil-Slonim",
      "Maria Liakata"
    ],
    "abstract": "We introduce a hybrid abstractive summarisation approach combining\nhierarchical VAE with LLMs (LlaMA-2) to produce clinically meaningful summaries\nfrom social media user timelines, appropriate for mental health monitoring. The\nsummaries combine two different narrative points of view: clinical insights in\nthird person useful for a clinician are generated by feeding into an LLM\nspecialised clinical prompts, and importantly, a temporally sensitive\nabstractive summary of the user's timeline in first person, generated by a\nnovel hierarchical variational autoencoder, TH-VAE. We assess the generated\nsummaries via automatic evaluation against expert summaries and via human\nevaluation with clinical experts, showing that timeline summarisation by TH-VAE\nresults in more factual and logically coherent summaries rich in clinical\nutility and superior to LLM-only approaches in capturing changes over time.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.16240v2",
    "published_date": "2024-01-29 15:42:57 UTC",
    "updated_date": "2024-02-16 12:42:28 UTC"
  },
  {
    "arxiv_id": "2401.16215v1",
    "title": "Learning big logical rules by joining small rules",
    "authors": [
      "Céline Hocquette",
      "Andreas Niskanen",
      "Rolf Morel",
      "Matti Järvisalo",
      "Andrew Cropper"
    ],
    "abstract": "A major challenge in inductive logic programming is learning big rules. To\naddress this challenge, we introduce an approach where we join small rules to\nlearn big rules. We implement our approach in a constraint-driven system and\nuse constraint solvers to efficiently join rules. Our experiments on many\ndomains, including game playing and drug design, show that our approach can (i)\nlearn rules with more than 100 literals, and (ii) drastically outperform\nexisting approaches in terms of predictive accuracies.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.16215v1",
    "published_date": "2024-01-29 15:09:40 UTC",
    "updated_date": "2024-01-29 15:09:40 UTC"
  },
  {
    "arxiv_id": "2401.16209v1",
    "title": "MultiMUC: Multilingual Template Filling on MUC-4",
    "authors": [
      "William Gantt",
      "Shabnam Behzad",
      "Hannah YoungEun An",
      "Yunmo Chen",
      "Aaron Steven White",
      "Benjamin Van Durme",
      "Mahsa Yarmohammadi"
    ],
    "abstract": "We introduce MultiMUC, the first multilingual parallel corpus for template\nfilling, comprising translations of the classic MUC-4 template filling\nbenchmark into five languages: Arabic, Chinese, Farsi, Korean, and Russian. We\nobtain automatic translations from a strong multilingual machine translation\nsystem and manually project the original English annotations into each target\nlanguage. For all languages, we also provide human translations for sentences\nin the dev and test splits that contain annotated template arguments. Finally,\nwe present baselines on MultiMUC both with state-of-the-art template filling\nmodels and with ChatGPT.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "EACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.16209v1",
    "published_date": "2024-01-29 15:02:24 UTC",
    "updated_date": "2024-01-29 15:02:24 UTC"
  },
  {
    "arxiv_id": "2401.16198v1",
    "title": "Contracting with a Learning Agent",
    "authors": [
      "Guru Guruganesh",
      "Yoav Kolumbus",
      "Jon Schneider",
      "Inbal Talgam-Cohen",
      "Emmanouil-Vasileios Vlatakis-Gkaragkounis",
      "Joshua R. Wang",
      "S. Matthew Weinberg"
    ],
    "abstract": "Many real-life contractual relations differ completely from the clean, static\nmodel at the heart of principal-agent theory. Typically, they involve repeated\nstrategic interactions of the principal and agent, taking place under\nuncertainty and over time. While appealing in theory, players seldom use\ncomplex dynamic strategies in practice, often preferring to circumvent\ncomplexity and approach uncertainty through learning. We initiate the study of\nrepeated contracts with a learning agent, focusing on agents who achieve\nno-regret outcomes.\n  Optimizing against a no-regret agent is a known open problem in general\ngames; we achieve an optimal solution to this problem for a canonical contract\nsetting, in which the agent's choice among multiple actions leads to\nsuccess/failure. The solution has a surprisingly simple structure: for some\n$\\alpha > 0$, initially offer the agent a linear contract with scalar $\\alpha$,\nthen switch to offering a linear contract with scalar $0$. This switch causes\nthe agent to ``free-fall'' through their action space and during this time\nprovides the principal with non-zero reward at zero cost. Despite apparent\nexploitation of the agent, this dynamic contract can leave \\emph{both} players\nbetter off compared to the best static contract. Our results generalize beyond\nsuccess/failure, to arbitrary non-linear contracts which the principal rescales\ndynamically.\n  Finally, we quantify the dependence of our results on knowledge of the time\nhorizon, and are the first to address this consideration in the study of\nstrategizing against learning agents.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.LG",
      "econ.TH"
    ],
    "primary_category": "cs.GT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.16198v1",
    "published_date": "2024-01-29 14:53:22 UTC",
    "updated_date": "2024-01-29 14:53:22 UTC"
  },
  {
    "arxiv_id": "2401.16190v1",
    "title": "AI prediction of cardiovascular events using opportunistic epicardial adipose tissue assessments from CT calcium score",
    "authors": [
      "Tao Hu",
      "Joshua Freeze",
      "Prerna Singh",
      "Justin Kim",
      "Yingnan Song",
      "Hao Wu",
      "Juhwan Lee",
      "Sadeer Al-Kindi",
      "Sanjay Rajagopalan",
      "David L. Wilson",
      "Ammar Hoori"
    ],
    "abstract": "Background: Recent studies have used basic epicardial adipose tissue (EAT)\nassessments (e.g., volume and mean HU) to predict risk of\natherosclerosis-related, major adverse cardiovascular events (MACE).\nObjectives: Create novel, hand-crafted EAT features, 'fat-omics', to capture\nthe pathophysiology of EAT and improve MACE prediction. Methods: We segmented\nEAT using a previously-validated deep learning method with optional manual\ncorrection. We extracted 148 radiomic features (morphological, spatial, and\nintensity) and used Cox elastic-net for feature reduction and prediction of\nMACE. Results: Traditional fat features gave marginal prediction\n(EAT-volume/EAT-mean-HU/ BMI gave C-index 0.53/0.55/0.57, respectively).\nSignificant improvement was obtained with 15 fat-omics features (C-index=0.69,\ntest set). High-risk features included\nvolume-of-voxels-having-elevated-HU-[-50, -30-HU] and HU-negative-skewness,\nboth of which assess high HU, which as been implicated in fat inflammation.\nOther high-risk features include kurtosis-of-EAT-thickness, reflecting the\nheterogeneity of thicknesses, and EAT-volume-in-the-top-25%-of-the-heart,\nemphasizing adipose near the proximal coronary arteries. Kaplan-Meyer plots of\nCox-identified, high- and low-risk patients were well separated with the median\nof the fat-omics risk, while high-risk group having HR 2.4 times that of the\nlow-risk group (P<0.001). Conclusion: Preliminary findings indicate an\nopportunity to use more finely tuned, explainable assessments on EAT for\nimproved cardiovascular risk prediction.",
    "categories": [
      "q-bio.QM",
      "cs.AI"
    ],
    "primary_category": "q-bio.QM",
    "comment": "7 pages, 1 central illustration, 6 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2401.16190v1",
    "published_date": "2024-01-29 14:42:06 UTC",
    "updated_date": "2024-01-29 14:42:06 UTC"
  },
  {
    "arxiv_id": "2401.16462v1",
    "title": "Supervised Contrastive Learning based Dual-Mixer Model for Remaining Useful Life Prediction",
    "authors": [
      "En Fu",
      "Yanyan Hu",
      "Kaixiang Peng",
      "Yuxin Chu"
    ],
    "abstract": "The problem of the Remaining Useful Life (RUL) prediction, aiming at\nproviding an accurate estimate of the remaining time from the current\npredicting moment to the complete failure of the device, has gained significant\nattention from researchers in recent years. In this paper, to overcome the\nshortcomings of rigid combination for temporal and spatial features in most\nexisting RUL prediction approaches, a spatial-temporal homogeneous feature\nextractor, named Dual-Mixer model, is firstly proposed. Flexible layer-wise\nprogressive feature fusion is employed to ensure the homogeneity of\nspatial-temporal features and enhance the prediction accuracy. Secondly, the\nFeature Space Global Relationship Invariance (FSGRI) training method is\nintroduced based on supervised contrastive learning. This method maintains the\nconsistency of relationships among sample features with their degradation\npatterns during model training, simplifying the subsequently regression task in\nthe output layer and improving the model's performance in RUL prediction.\nFinally, the effectiveness of the proposed method is validated through\ncomparisons with other latest research works on the C-MAPSS dataset. The\nDual-Mixer model demonstrates superiority across most metrics, while the FSGRI\ntraining method shows an average improvement of 7.00% and 2.41% in RMSE and\nMAPE, respectively, for all baseline models. Our experiments and model code are\npublicly available at https://github.com/fuen1590/PhmDeepLearningProjects.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.16462v1",
    "published_date": "2024-01-29 14:38:44 UTC",
    "updated_date": "2024-01-29 14:38:44 UTC"
  },
  {
    "arxiv_id": "2401.16186v1",
    "title": "An Empirical Study on Usage and Perceptions of LLMs in a Software Engineering Project",
    "authors": [
      "Sanka Rasnayaka",
      "Guanlin Wang",
      "Ridwan Shariffdeen",
      "Ganesh Neelakanta Iyer"
    ],
    "abstract": "Large Language Models (LLMs) represent a leap in artificial intelligence,\nexcelling in tasks using human language(s). Although the main focus of\ngeneral-purpose LLMs is not code generation, they have shown promising results\nin the domain. However, the usefulness of LLMs in an academic software\nengineering project has not been fully explored yet. In this study, we explore\nthe usefulness of LLMs for 214 students working in teams consisting of up to\nsix members. Notably, in the academic course through which this study is\nconducted, students were encouraged to integrate LLMs into their development\ntool-chain, in contrast to most other academic courses that explicitly prohibit\nthe use of LLMs.\n  In this paper, we analyze the AI-generated code, prompts used for code\ngeneration, and the human intervention levels to integrate the code into the\ncode base. We also conduct a perception study to gain insights into the\nperceived usefulness, influencing factors, and future outlook of LLM from a\ncomputer science student's perspective. Our findings suggest that LLMs can play\na crucial role in the early stages of software development, especially in\ngenerating foundational code structures, and helping with syntax and error\ndebugging. These insights provide us with a framework on how to effectively\nutilize LLMs as a tool to enhance the productivity of software engineering\nstudents, and highlight the necessity of shifting the educational focus toward\npreparing students for successful human-AI collaboration.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "D.2.3"
    ],
    "primary_category": "cs.SE",
    "comment": "8 pages, 6 figures, accepted for publication at the LLM4Code workshop\n  @ ICSE 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.16186v1",
    "published_date": "2024-01-29 14:32:32 UTC",
    "updated_date": "2024-01-29 14:32:32 UTC"
  },
  {
    "arxiv_id": "2401.16185v3",
    "title": "LLM4Vuln: A Unified Evaluation Framework for Decoupling and Enhancing LLMs' Vulnerability Reasoning",
    "authors": [
      "Yuqiang Sun",
      "Daoyuan Wu",
      "Yue Xue",
      "Han Liu",
      "Wei Ma",
      "Lyuye Zhang",
      "Yang Liu",
      "Yingjiu Li"
    ],
    "abstract": "Large language models (LLMs) have demonstrated significant potential in\nvarious tasks, including those requiring human-level intelligence, such as\nvulnerability detection. However, recent efforts to use LLMs for vulnerability\ndetection remain preliminary, as they lack a deep understanding of whether a\nsubject LLM's vulnerability reasoning capability stems from the model itself or\nfrom external aids such as knowledge retrieval and tooling support.\n  In this paper, we aim to decouple LLMs' vulnerability reasoning from other\ncapabilities, such as vulnerability knowledge adoption, context information\nretrieval, and advanced prompt schemes. We introduce LLM4Vuln, a unified\nevaluation framework that separates and assesses LLMs' vulnerability reasoning\ncapabilities and examines improvements when combined with other enhancements.\n  We conduct controlled experiments using 147 ground-truth vulnerabilities and\n147 non-vulnerable cases in Solidity, Java and C/C++, testing them in a total\nof 3,528 scenarios across four LLMs (GPT-3.5, GPT-4, Phi-3, and Llama 3). Our\nfindings reveal the varying impacts of knowledge enhancement, context\nsupplementation, and prompt schemes. We also identify 14 zero-day\nvulnerabilities in four pilot bug bounty programs, resulting in $3,576 in\nbounties.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CR",
    "comment": "This is a technical report by Nanyang Technological University.\n  Updated to support Solidity, Java and C/C++",
    "pdf_url": "http://arxiv.org/pdf/2401.16185v3",
    "published_date": "2024-01-29 14:32:27 UTC",
    "updated_date": "2025-01-13 06:10:24 UTC"
  },
  {
    "arxiv_id": "2401.16182v1",
    "title": "LLaMandement: Large Language Models for Summarization of French Legislative Proposals",
    "authors": [
      "Joseph Gesnouin",
      "Yannis Tannier",
      "Christophe Gomes Da Silva",
      "Hatim Tapory",
      "Camille Brier",
      "Hugo Simon",
      "Raphael Rozenberg",
      "Hermann Woehrel",
      "Mehdi El Yakaabi",
      "Thomas Binder",
      "Guillaume Marie",
      "Emilie Caron",
      "Mathile Nogueira",
      "Thomas Fontas",
      "Laure Puydebois",
      "Marie Theophile",
      "Stephane Morandi",
      "Mael Petit",
      "David Creissac",
      "Pauline Ennouchy",
      "Elise Valetoux",
      "Celine Visade",
      "Severine Balloux",
      "Emmanuel Cortes",
      "Pierre-Etienne Devineau",
      "Ulrich Tan",
      "Esther Mac Namara",
      "Su Yang"
    ],
    "abstract": "This report introduces LLaMandement, a state-of-the-art Large Language Model,\nfine-tuned by the French government and designed to enhance the efficiency and\nefficacy of processing parliamentary sessions (including the production of\nbench memoranda and documents required for interministerial meetings) by\ngenerating neutral summaries of legislative proposals. Addressing the\nadministrative challenges of manually processing a growing volume of\nlegislative amendments, LLaMandement stands as a significant legal\ntechnological milestone, providing a solution that exceeds the scalability of\ntraditional human efforts while matching the robustness of a specialized legal\ndrafter. We release all our fine-tuned models and training data to the\ncommunity.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "21 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2401.16182v1",
    "published_date": "2024-01-29 14:23:51 UTC",
    "updated_date": "2024-01-29 14:23:51 UTC"
  },
  {
    "arxiv_id": "2401.16176v1",
    "title": "A Survey on Structure-Preserving Graph Transformers",
    "authors": [
      "Van Thuy Hoang",
      "O-Joun Lee"
    ],
    "abstract": "The transformer architecture has shown remarkable success in various domains,\nsuch as natural language processing and computer vision. When it comes to graph\nlearning, transformers are required not only to capture the interactions\nbetween pairs of nodes but also to preserve graph structures connoting the\nunderlying relations and proximity between them, showing the expressive power\nto capture different graph structures. Accordingly, various\nstructure-preserving graph transformers have been proposed and widely used for\nvarious tasks, such as graph-level tasks in bioinformatics and\nchemoinformatics. However, strategies related to graph structure preservation\nhave not been well organized and systematized in the literature. In this paper,\nwe provide a comprehensive overview of structure-preserving graph transformers\nand generalize these methods from the perspective of their design objective.\nFirst, we divide strategies into four main groups: node feature modulation,\ncontext node sampling, graph rewriting, and transformer architecture\nimprovements. We then further divide the strategies according to the coverage\nand goals of graph structure preservation. Furthermore, we also discuss\nchallenges and future directions for graph transformer models to preserve the\ngraph structure and understand the nature of graphs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "12",
    "pdf_url": "http://arxiv.org/pdf/2401.16176v1",
    "published_date": "2024-01-29 14:18:09 UTC",
    "updated_date": "2024-01-29 14:18:09 UTC"
  },
  {
    "arxiv_id": "2401.16157v1",
    "title": "Spatial-Aware Latent Initialization for Controllable Image Generation",
    "authors": [
      "Wenqiang Sun",
      "Teng Li",
      "Zehong Lin",
      "Jun Zhang"
    ],
    "abstract": "Recently, text-to-image diffusion models have demonstrated impressive ability\nto generate high-quality images conditioned on the textual input. However,\nthese models struggle to accurately adhere to textual instructions regarding\nspatial layout information. While previous research has primarily focused on\naligning cross-attention maps with layout conditions, they overlook the impact\nof the initialization noise on the layout guidance. To achieve better layout\ncontrol, we propose leveraging a spatial-aware initialization noise during the\ndenoising process. Specifically, we find that the inverted reference image with\nfinite inversion steps contains valuable spatial awareness regarding the\nobject's position, resulting in similar layouts in the generated images. Based\non this observation, we develop an open-vocabulary framework to customize a\nspatial-aware initialization noise for each layout condition. Without modifying\nother modules except the initialization noise, our approach can be seamlessly\nintegrated as a plug-and-play module within other training-free layout guidance\nframeworks. We evaluate our approach quantitatively and qualitatively on the\navailable Stable Diffusion model and COCO dataset. Equipped with the\nspatial-aware latent initialization, our method significantly improves the\neffectiveness of layout guidance while preserving high-quality content.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.16157v1",
    "published_date": "2024-01-29 13:42:01 UTC",
    "updated_date": "2024-01-29 13:42:01 UTC"
  },
  {
    "arxiv_id": "2401.16144v1",
    "title": "Divide and Conquer: Rethinking the Training Paradigm of Neural Radiance Fields",
    "authors": [
      "Rongkai Ma",
      "Leo Lebrat",
      "Rodrigo Santa Cruz",
      "Gil Avraham",
      "Yan Zuo",
      "Clinton Fookes",
      "Olivier Salvado"
    ],
    "abstract": "Neural radiance fields (NeRFs) have exhibited potential in synthesizing\nhigh-fidelity views of 3D scenes but the standard training paradigm of NeRF\npresupposes an equal importance for each image in the training set. This\nassumption poses a significant challenge for rendering specific views\npresenting intricate geometries, thereby resulting in suboptimal performance.\nIn this paper, we take a closer look at the implications of the current\ntraining paradigm and redesign this for more superior rendering quality by\nNeRFs. Dividing input views into multiple groups based on their visual\nsimilarities and training individual models on each of these groups enables\neach model to specialize on specific regions without sacrificing speed or\nefficiency. Subsequently, the knowledge of these specialized models is\naggregated into a single entity via a teacher-student distillation paradigm,\nenabling spatial efficiency for online render-ing. Empirically, we evaluate our\nnovel training framework on two publicly available datasets, namely NeRF\nsynthetic and Tanks&Temples. Our evaluation demonstrates that our DaC training\npipeline enhances the rendering quality of a state-of-the-art baseline model\nwhile exhibiting convergence to a superior minimum.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.16144v1",
    "published_date": "2024-01-29 13:23:34 UTC",
    "updated_date": "2024-01-29 13:23:34 UTC"
  },
  {
    "arxiv_id": "2401.16137v1",
    "title": "X-PEFT: eXtremely Parameter-Efficient Fine-Tuning for Extreme Multi-Profile Scenarios",
    "authors": [
      "Namju Kwak",
      "Taesup Kim"
    ],
    "abstract": "Parameter-efficient fine-tuning (PEFT) techniques, such as adapter tuning,\naim to fine-tune a pre-trained language model (PLM) using a minimal number of\nparameters for a specific task or profile. Although adapter tuning provides\nincreased parameter efficiency compared to full-model fine-tuning, it\nintroduces a small set of additional parameters attached to a PLM for each\nprofile. This can become problematic in practical applications with multiple\nprofiles, particularly when a significant increase in the number of profiles\nlinearly boosts the total number of additional parameters. To mitigate this\nissue, we introduce X-PEFT, a novel PEFT method that leverages a multitude of\ngiven adapters by fine-tuning an extremely small set of compact tensors for a\nnew profile, which serve as binary masks to adaptively select the given\nadapters. To efficiently validate our proposed method, we implement it using a\nlarge number of trained or untrained (random) adapters. We evaluate the\nperformance of X-PEFT through LaMP and GLUE tasks and demonstrate that it\neither matches or surpasses the effectiveness of conventional adapter tuning,\ndespite reducing the memory requirements per profile by a factor of 10,000\ncompared to it.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.16137v1",
    "published_date": "2024-01-29 13:13:32 UTC",
    "updated_date": "2024-01-29 13:13:32 UTC"
  },
  {
    "arxiv_id": "2401.16136v1",
    "title": "Neural Network Training on Encrypted Data with TFHE",
    "authors": [
      "Luis Montero",
      "Jordan Frery",
      "Celia Kherfallah",
      "Roman Bredehoft",
      "Andrei Stoian"
    ],
    "abstract": "We present an approach to outsourcing of training neural networks while\npreserving data confidentiality from malicious parties. We use fully\nhomomorphic encryption to build a unified training approach that works on\nencrypted data and learns quantized neural network models. The data can be\nhorizontally or vertically split between multiple parties, enabling\ncollaboration on confidential data. We train logistic regression and\nmulti-layer perceptrons on several datasets.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.16136v1",
    "published_date": "2024-01-29 13:07:08 UTC",
    "updated_date": "2024-01-29 13:07:08 UTC"
  },
  {
    "arxiv_id": "2401.16124v2",
    "title": "On the generalization of learned constraints for ASP solving in temporal domains",
    "authors": [
      "Javier Romero",
      "Torsten Schaub",
      "Klaus Strauch"
    ],
    "abstract": "The representation of a dynamic problem in ASP usually boils down to using\ncopies of variables and constraints, one for each time stamp, no matter whether\nit is directly encoded or via an action or temporal language. The\nmultiplication of variables and constraints is commonly done during grounding\nand the solver is completely ignorant about the temporal relationship among the\ndifferent instances. On the other hand, a key factor in the performance of\ntoday's ASP solvers is conflict-driven constraint learning. Our question is now\nwhether a constraint learned for particular time steps can be generalized and\nreused at other time stamps, and ultimately whether this enhances the overall\nsolver performance on temporal problems. Knowing full well the domain of time,\nwe study conditions under which learned dynamic constraints can be generalized.\nWe propose a simple translation of the original logic program such that, for\nthe translated programs, the learned constraints can be generalized to other\ntime points. Additionally, we identify a property of temporal problems that\nallows us to generalize all learned constraints to all time steps. It turns out\nthat this property is satisfied by many planning problems. Finally, we\nempirically evaluate the impact of adding the generalized constraints to an ASP\nsolver. Under consideration in Theory and Practice of Logic Programming (TPLP).",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "41 pages, 2 figures, Under consideration in Theory and Practice of\n  Logic Programming (TPLP)",
    "pdf_url": "http://arxiv.org/pdf/2401.16124v2",
    "published_date": "2024-01-29 12:49:09 UTC",
    "updated_date": "2024-10-15 11:19:21 UTC"
  },
  {
    "arxiv_id": "2401.16123v2",
    "title": "Looking for a better fit? An Incremental Learning Multimodal Object Referencing Framework adapting to Individual Drivers",
    "authors": [
      "Amr Gomaa",
      "Guillermo Reyes",
      "Michael Feld",
      "Antonio Krüger"
    ],
    "abstract": "The rapid advancement of the automotive industry towards automated and\nsemi-automated vehicles has rendered traditional methods of vehicle\ninteraction, such as touch-based and voice command systems, inadequate for a\nwidening range of non-driving related tasks, such as referencing objects\noutside of the vehicle. Consequently, research has shifted toward gestural\ninput (e.g., hand, gaze, and head pose gestures) as a more suitable mode of\ninteraction during driving. However, due to the dynamic nature of driving and\nindividual variation, there are significant differences in drivers' gestural\ninput performance. While, in theory, this inherent variability could be\nmoderated by substantial data-driven machine learning models, prevalent\nmethodologies lean towards constrained, single-instance trained models for\nobject referencing. These models show a limited capacity to continuously adapt\nto the divergent behaviors of individual drivers and the variety of driving\nscenarios. To address this, we propose \\textit{IcRegress}, a novel\nregression-based incremental learning approach that adapts to changing behavior\nand the unique characteristics of drivers engaged in the dual task of driving\nand referencing objects. We suggest a more personalized and adaptable solution\nfor multimodal gestural interfaces, employing continuous lifelong learning to\nenhance driver experience, safety, and convenience. Our approach was evaluated\nusing an outside-the-vehicle object referencing use case, highlighting the\nsuperiority of the incremental learning models adapted over a single trained\nmodel across various driver traits such as handedness, driving experience, and\nnumerous driving conditions. Finally, to facilitate reproducibility, ease\ndeployment, and promote further research, we offer our approach as an\nopen-source framework at \\url{https://github.com/amrgomaaelhady/IcRegress}.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted for publication in the Proceedings of the 29th International\n  Conference on Intelligent User Interfaces (IUI'24), March 18--21, 2024, in\n  Greenville, SC, USA",
    "pdf_url": "http://arxiv.org/pdf/2401.16123v2",
    "published_date": "2024-01-29 12:48:56 UTC",
    "updated_date": "2024-02-07 11:25:28 UTC"
  },
  {
    "arxiv_id": "2401.16119v2",
    "title": "Triple Disentangled Representation Learning for Multimodal Affective Analysis",
    "authors": [
      "Ying Zhou",
      "Xuefeng Liang",
      "Han Chen",
      "Yin Zhao",
      "Xin Chen",
      "Lida Yu"
    ],
    "abstract": "Multimodal learning has exhibited a significant advantage in affective\nanalysis tasks owing to the comprehensive information of various modalities,\nparticularly the complementary information. Thus, many emerging studies focus\non disentangling the modality-invariant and modality-specific representations\nfrom input data and then fusing them for prediction. However, our study shows\nthat modality-specific representations may contain information that is\nirrelevant or conflicting with the tasks, which downgrades the effectiveness of\nlearned multimodal representations. We revisit the disentanglement issue, and\npropose a novel triple disentanglement approach, TriDiRA, which disentangles\nthe modality-invariant, effective modality-specific and ineffective\nmodality-specific representations from input data. By fusing only the\nmodality-invariant and effective modality-specific representations, TriDiRA can\nsignificantly alleviate the impact of irrelevant and conflicting information\nacross modalities during model training. Extensive experiments conducted on\nfour benchmark datasets demonstrate the effectiveness and generalization of our\ntriple disentanglement, which outperforms SOTA methods.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2401.16119v2",
    "published_date": "2024-01-29 12:45:27 UTC",
    "updated_date": "2024-04-08 08:19:19 UTC"
  },
  {
    "arxiv_id": "2401.16107v1",
    "title": "Beyond Direct Diagnosis: LLM-based Multi-Specialist Agent Consultation for Automatic Diagnosis",
    "authors": [
      "Haochun Wang",
      "Sendong Zhao",
      "Zewen Qiang",
      "Nuwa Xi",
      "Bing Qin",
      "Ting Liu"
    ],
    "abstract": "Automatic diagnosis is a significant application of AI in healthcare, where\ndiagnoses are generated based on the symptom description of patients. Previous\nworks have approached this task directly by modeling the relationship between\nthe normalized symptoms and all possible diseases. However, in the clinical\ndiagnostic process, patients are initially consulted by a general practitioner\nand, if necessary, referred to specialists in specific domains for a more\ncomprehensive evaluation. The final diagnosis often emerges from a\ncollaborative consultation among medical specialist groups. Recently, large\nlanguage models have shown impressive capabilities in natural language\nunderstanding. In this study, we adopt tuning-free LLM-based agents as medical\npractitioners and propose the Agent-derived Multi-Specialist Consultation\n(AMSC) framework to model the diagnosis process in the real world by adaptively\nfusing probability distributions of agents over potential diseases.\nExperimental results demonstrate the superiority of our approach compared with\nbaselines. Notably, our approach requires significantly less parameter updating\nand training time, enhancing efficiency and practical utility. Furthermore, we\ndelve into a novel perspective on the role of implicit symptoms within the\ncontext of automatic diagnosis.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.16107v1",
    "published_date": "2024-01-29 12:25:30 UTC",
    "updated_date": "2024-01-29 12:25:30 UTC"
  },
  {
    "arxiv_id": "2401.16102v1",
    "title": "Flexible Parallel Neural Network Architecture Model for Early Prediction of Lithium Battery Life",
    "authors": [
      "Lidang Jiang",
      "Zhuoxiang Li",
      "Changyan Hu",
      "Qingsong Huang",
      "Ge He"
    ],
    "abstract": "The early prediction of battery life (EPBL) is vital for enhancing the\nefficiency and extending the lifespan of lithium batteries. Traditional models\nwith fixed architectures often encounter underfitting or overfitting issues due\nto the diverse data distributions in different EPBL tasks. An interpretable\ndeep learning model of flexible parallel neural network (FPNN) is proposed,\nwhich includes an InceptionBlock, a 3D convolutional neural network (CNN), a 2D\nCNN, and a dual-stream network. The proposed model effectively extracts\nelectrochemical features from video-like formatted data using the 3D CNN and\nachieves advanced multi-scale feature abstraction through the InceptionBlock.\nThe FPNN can adaptively adjust the number of InceptionBlocks to flexibly handle\ntasks of varying complexity in EPBL. The test on the MIT dataset shows that the\nFPNN model achieves outstanding predictive accuracy in EPBL tasks, with MAPEs\nof 2.47%, 1.29%, 1.08%, and 0.88% when the input cyclic data volumes are 10,\n20, 30, and 40, respectively. The interpretability of the FPNN is mainly\nreflected in its flexible unit structure and parameter selection: its diverse\nbranching structure enables the model to capture features at different scales,\nthus allowing the machine to learn informative features. The approach presented\nherein provides an accurate, adaptable, and comprehensible solution for early\nlife prediction of lithium batteries, opening new possibilities in the field of\nbattery health monitoring.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.16102v1",
    "published_date": "2024-01-29 12:20:17 UTC",
    "updated_date": "2024-01-29 12:20:17 UTC"
  },
  {
    "arxiv_id": "2402.03948v1",
    "title": "Identifying Student Profiles Within Online Judge Systems Using Explainable Artificial Intelligence",
    "authors": [
      "Juan Ramón Rico-Juan",
      "Víctor M. Sánchez-Cartagena",
      "Jose J. Valero-Mas",
      "Antonio Javier Gallego"
    ],
    "abstract": "Online Judge (OJ) systems are typically considered within programming-related\ncourses as they yield fast and objective assessments of the code developed by\nthe students. Such an evaluation generally provides a single decision based on\na rubric, most commonly whether the submission successfully accomplished the\nassignment. Nevertheless, since in an educational context such information may\nbe deemed insufficient, it would be beneficial for both the student and the\ninstructor to receive additional feedback about the overall development of the\ntask. This work aims to tackle this limitation by considering the further\nexploitation of the information gathered by the OJ and automatically inferring\nfeedback for both the student and the instructor. More precisely, we consider\nthe use of learning-based schemes -- particularly, multi-instance learning\n(MIL) and classical machine learning formulations -- to model student behavior.\nBesides, explainable artificial intelligence (XAI) is contemplated to provide\nhuman-understandable feedback. The proposal has been evaluated considering a\ncase of study comprising 2500 submissions from roughly 90 different students\nfrom a programming-related course in a computer science degree. The results\nobtained validate the proposal: The model is capable of significantly\npredicting the user outcome (either passing or failing the assignment) solely\nbased on the behavioral pattern inferred by the submissions provided to the OJ.\nMoreover, the proposal is able to identify prone-to-fail student groups and\nprofiles as well as other relevant information, which eventually serves as\nfeedback to both the student and the instructor.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03948v1",
    "published_date": "2024-01-29 12:11:30 UTC",
    "updated_date": "2024-01-29 12:11:30 UTC"
  },
  {
    "arxiv_id": "2402.01739v2",
    "title": "OpenMoE: An Early Effort on Open Mixture-of-Experts Language Models",
    "authors": [
      "Fuzhao Xue",
      "Zian Zheng",
      "Yao Fu",
      "Jinjie Ni",
      "Zangwei Zheng",
      "Wangchunshu Zhou",
      "Yang You"
    ],
    "abstract": "To help the open-source community have a better understanding of\nMixture-of-Experts (MoE) based large language models (LLMs), we train and\nrelease OpenMoE, a series of fully open-sourced and reproducible decoder-only\nMoE LLMs, ranging from 650M to 34B parameters and trained on up to over 1T\ntokens. Our investigation confirms that MoE-based LLMs can offer a more\nfavorable cost-effectiveness trade-off than dense LLMs, highlighting the\npotential effectiveness for future LLM development.\n  One more important contribution of this study is an in-depth analysis of the\nrouting mechanisms within our OpenMoE models, leading to three significant\nfindings: Context-Independent Specialization, Early Routing Learning, and\nDrop-towards-the-End. We discovered that routing decisions in MoE models are\npredominantly based on token IDs, with minimal context relevance. The\ntoken-to-expert assignments are determined early in the pre-training phase and\nremain largely unchanged. This imperfect routing can result in performance\ndegradation, particularly in sequential tasks like multi-turn conversations,\nwhere tokens appearing later in a sequence are more likely to be dropped.\nFinally, we rethink our design based on the above-mentioned observations and\nanalysis. To facilitate future MoE LLM development, we propose potential\nstrategies for mitigating the issues we found and further improving\noff-the-shelf MoE LLM designs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DC",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01739v2",
    "published_date": "2024-01-29 12:05:02 UTC",
    "updated_date": "2024-03-27 10:21:24 UTC"
  },
  {
    "arxiv_id": "2401.16094v1",
    "title": "Federated unsupervised random forest for privacy-preserving patient stratification",
    "authors": [
      "Bastian Pfeifer",
      "Christel Sirocchi",
      "Marcus D. Bloice",
      "Markus Kreuzthaler",
      "Martin Urschler"
    ],
    "abstract": "In the realm of precision medicine, effective patient stratification and\ndisease subtyping demand innovative methodologies tailored for multi-omics\ndata. Clustering techniques applied to multi-omics data have become\ninstrumental in identifying distinct subgroups of patients, enabling a\nfiner-grained understanding of disease variability. This work establishes a\npowerful framework for advancing precision medicine through unsupervised\nrandom-forest-based clustering and federated computing. We introduce a novel\nmulti-omics clustering approach utilizing unsupervised random-forests. The\nunsupervised nature of the random forest enables the determination of\ncluster-specific feature importance, unraveling key molecular contributors to\ndistinct patient groups. Moreover, our methodology is designed for federated\nexecution, a crucial aspect in the medical domain where privacy concerns are\nparamount. We have validated our approach on machine learning benchmark data\nsets as well as on cancer data from The Cancer Genome Atlas (TCGA). Our method\nis competitive with the state-of-the-art in terms of disease subtyping, but at\nthe same time substantially improves the cluster interpretability. Experiments\nindicate that local clustering performance can be improved through federated\ncomputing.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.16094v1",
    "published_date": "2024-01-29 12:04:14 UTC",
    "updated_date": "2024-01-29 12:04:14 UTC"
  },
  {
    "arxiv_id": "2403.08783v1",
    "title": "Image-Text Out-Of-Context Detection Using Synthetic Multimodal Misinformation",
    "authors": [
      "Fatma Shalabi",
      "Huy H. Nguyen",
      "Hichem Felouat",
      "Ching-Chun Chang",
      "Isao Echizen"
    ],
    "abstract": "Misinformation has become a major challenge in the era of increasing digital\ninformation, requiring the development of effective detection methods. We have\ninvestigated a novel approach to Out-Of-Context detection (OOCD) that uses\nsynthetic data generation. We created a dataset specifically designed for OOCD\nand developed an efficient detector for accurate classification. Our\nexperimental findings validate the use of synthetic data generation and\ndemonstrate its efficacy in addressing the data limitations associated with\nOOCD. The dataset and detector should serve as valuable resources for future\nresearch and the development of robust misinformation detection systems.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, 2 figures, conference",
    "pdf_url": "http://arxiv.org/pdf/2403.08783v1",
    "published_date": "2024-01-29 11:55:14 UTC",
    "updated_date": "2024-01-29 11:55:14 UTC"
  },
  {
    "arxiv_id": "2402.00064v1",
    "title": "Merging plans with incomplete knowledge about actions and goals through an agent-based reputation system",
    "authors": [
      "Javier Carbo",
      "Jose M Molina",
      "Miguel A Patricio"
    ],
    "abstract": "Managing transition plans is one of the major problems of people with\ncognitive disabilities. Therefore, finding an automated way to generate such\nplans would be a helpful tool for this community. In this paper we have\nspecifically proposed and compared different alternative ways to merge plans\nformed by sequences of actions of unknown similarities between goals and\nactions executed by several operator agents which cooperate between them\napplying such actions over some passive elements (node agents) that require\nadditional executions of another plan after some time of use. Such ignorance of\nthe similarities between plan actions and goals would justify the use of a\ndistributed recommendation system that would provide an useful plan to be\napplied for a certain goal to a given operator agent, generated from the known\nresults of previous executions of different plans by other operator agents.\nHere we provide the general framework of execution (agent system), and the\ndifferent merging algorithms applied to this problem. The proposed agent system\nwould act as an useful cognitive assistant for people with intelectual\ndisabilities such as autism.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00064v1",
    "published_date": "2024-01-29 11:34:59 UTC",
    "updated_date": "2024-01-29 11:34:59 UTC"
  },
  {
    "arxiv_id": "2403.09668v1",
    "title": "Trustworthy Automated Driving through Qualitative Scene Understanding and Explanations",
    "authors": [
      "Nassim Belmecheri",
      "Arnaud Gotlieb",
      "Nadjib Lazaar",
      "Helge Spieker"
    ],
    "abstract": "We present the Qualitative Explainable Graph (QXG): a unified symbolic and\nqualitative representation for scene understanding in urban mobility. QXG\nenables the interpretation of an automated vehicle's environment using sensor\ndata and machine learning models. It leverages spatio-temporal graphs and\nqualitative constraints to extract scene semantics from raw sensor inputs, such\nas LiDAR and camera data, offering an intelligible scene model. Crucially, QXG\ncan be incrementally constructed in real-time, making it a versatile tool for\nin-vehicle explanations and real-time decision-making across various sensor\ntypes. Our research showcases the transformative potential of QXG, particularly\nin the context of automated driving, where it elucidates decision rationales by\nlinking the graph with vehicle actions. These explanations serve diverse\npurposes, from informing passengers and alerting vulnerable road users (VRUs)\nto enabling post-analysis of prior behaviours.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Transport Research Arena (TRA) 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.09668v1",
    "published_date": "2024-01-29 11:20:19 UTC",
    "updated_date": "2024-01-29 11:20:19 UTC"
  },
  {
    "arxiv_id": "2401.16461v3",
    "title": "Norm Enforcement with a Soft Touch: Faster Emergence, Happier Agents",
    "authors": [
      "Sz-Ting Tzeng",
      "Nirav Ajmeri",
      "Munindar P. Singh"
    ],
    "abstract": "A multiagent system is a society of autonomous agents whose interactions can\nbe regulated via social norms. In general, the norms of a society are not\nhardcoded but emerge from the agents' interactions. Specifically, how the\nagents in a society react to each other's behavior and respond to the reactions\nof others determines which norms emerge in the society. We think of these\nreactions by an agent to the satisfactory or unsatisfactory behaviors of\nanother agent as communications from the first agent to the second agent.\nUnderstanding these communications is a kind of social intelligence: these\ncommunications provide natural drivers for norm emergence by pushing agents\ntoward certain behaviors, which can become established as norms. Whereas it is\nwell-known that sanctioning can lead to the emergence of norms, we posit that a\nbroader kind of social intelligence can prove more effective in promoting\ncooperation in a multiagent system.\n  Accordingly, we develop Nest, a framework that models social intelligence via\na wider variety of communications and understanding of them than in previous\nwork. To evaluate Nest, we develop a simulated pandemic environment and conduct\nsimulation experiments to compare Nest with baselines considering a combination\nof three kinds of social communication: sanction, tell, and hint.\n  We find that societies formed of Nest agents achieve norms faster. Moreover,\nNest agents effectively avoid undesirable consequences, which are negative\nsanctions and deviation from goals, and yield higher satisfaction for\nthemselves than baseline agents despite requiring only an equivalent amount of\ninformation.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.MA",
    "comment": "12 pages, 11 figures, 5 tables (and supplementary material with code\n  availability and additional results), accepted at AAMAS 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.16461v3",
    "published_date": "2024-01-29 11:09:45 UTC",
    "updated_date": "2024-03-05 10:58:33 UTC"
  },
  {
    "arxiv_id": "2401.16045v1",
    "title": "Type-based Neural Link Prediction Adapter for Complex Query Answering",
    "authors": [
      "Lingning Song",
      "Yi Zu",
      "Shan Lu",
      "Jieyue He"
    ],
    "abstract": "Answering complex logical queries on incomplete knowledge graphs (KGs) is a\nfundamental and challenging task in multi-hop reasoning. Recent work defines\nthis task as an end-to-end optimization problem, which significantly reduces\nthe training cost and enhances the generalization of the model by a pretrained\nlink predictors for query answering. However, most existing proposals ignore\nthe critical semantic knowledge inherently available in KGs, such as type\ninformation, which could help answer complex logical queries. To this end, we\npropose TypE-based Neural Link Prediction Adapter (TENLPA), a novel model that\nconstructs type-based entity-relation graphs to discover the latent\nrelationships between entities and relations by leveraging type information in\nKGs. Meanwhile, in order to effectively combine type information with complex\nlogical queries, an adaptive learning mechanism is introduced, which is trained\nby back-propagating during the complex query answering process to achieve\nadaptive adjustment of neural link predictors. Experiments on 3 standard\ndatasets show that TENLPA model achieves state-of-the-art performance on\ncomplex query answering with good generalization and robustness.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "11 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2401.16045v1",
    "published_date": "2024-01-29 10:54:28 UTC",
    "updated_date": "2024-01-29 10:54:28 UTC"
  },
  {
    "arxiv_id": "2402.07909v1",
    "title": "Prompt4Vis: Prompting Large Language Models with Example Mining and Schema Filtering for Tabular Data Visualization",
    "authors": [
      "Shuaimin Li",
      "Xuanang Chen",
      "Yuanfeng Song",
      "Yunze Song",
      "Chen Zhang"
    ],
    "abstract": "Data visualization (DV) systems are increasingly recognized for their\nprofound capability to uncover insights from vast datasets, gaining attention\nacross both industry and academia. Crafting data queries is an essential\nprocess within certain declarative visualization languages (DVLs, e.g.,\nVega-Lite, EChart.). The evolution of natural language processing (NLP)\ntechnologies has streamlined the use of natural language interfaces to\nvisualize tabular data, offering a more accessible and intuitive user\nexperience. However, current methods for converting natural language questions\ninto data visualization queries, such as Seq2Vis, ncNet, and RGVisNet, despite\nutilizing complex neural network architectures, still fall short of\nexpectations and have great room for improvement.\n  Large language models (LLMs) such as ChatGPT and GPT-4, have established new\nbenchmarks in a variety of NLP tasks, fundamentally altering the landscape of\nthe field. Inspired by these advancements, we introduce a novel framework,\nPrompt4Vis, leveraging LLMs and in-context learning to enhance the performance\nof generating data visualization from natural language. Prompt4Vis comprises\ntwo key components: (1) a multi-objective example mining module, designed to\nfind out the truly effective examples that strengthen the LLM's in-context\nlearning capabilities for text-to-vis; (2) a schema filtering module, which is\nproposed to simplify the schema of the database. Extensive experiments through\n5-fold cross-validation on the NVBench dataset demonstrate the superiority of\nPrompt4Vis, which notably surpasses the state-of-the-art (SOTA) RGVisNet by\napproximately 35.9% and 71.3% on dev and test sets, respectively. To the best\nof our knowledge, Prompt4Vis is the first work that introduces in-context\nlearning into the text-to-vis for generating data visualization queries.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL",
      "cs.DB"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.07909v1",
    "published_date": "2024-01-29 10:23:47 UTC",
    "updated_date": "2024-01-29 10:23:47 UTC"
  },
  {
    "arxiv_id": "2401.16024v1",
    "title": "Probabilistic Abduction for Visual Abstract Reasoning via Learning Rules in Vector-symbolic Architectures",
    "authors": [
      "Michael Hersche",
      "Francesco di Stefano",
      "Thomas Hofmann",
      "Abu Sebastian",
      "Abbas Rahimi"
    ],
    "abstract": "Abstract reasoning is a cornerstone of human intelligence, and replicating it\nwith artificial intelligence (AI) presents an ongoing challenge. This study\nfocuses on efficiently solving Raven's progressive matrices (RPM), a visual\ntest for assessing abstract reasoning abilities, by using distributed\ncomputation and operators provided by vector-symbolic architectures (VSA).\nInstead of hard-coding the rule formulations associated with RPMs, our approach\ncan learn the VSA rule formulations (hence the name Learn-VRF) with just one\npass through the training data. Yet, our approach, with compact parameters,\nremains transparent and interpretable. Learn-VRF yields accurate predictions on\nI-RAVEN's in-distribution data, and exhibits strong out-of-distribution\ncapabilities concerning unseen attribute-rule pairs, significantly\noutperforming pure connectionist baselines including large language models. Our\ncode is available at\nhttps://github.com/IBM/learn-vector-symbolic-architectures-rule-formulations.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted in NeurIPS 2023 Workshop on MATH-AI",
    "pdf_url": "http://arxiv.org/pdf/2401.16024v1",
    "published_date": "2024-01-29 10:17:18 UTC",
    "updated_date": "2024-01-29 10:17:18 UTC"
  },
  {
    "arxiv_id": "2401.16458v3",
    "title": "Credit Risk Meets Large Language Models: Building a Risk Indicator from Loan Descriptions in P2P Lending",
    "authors": [
      "Mario Sanz-Guerrero",
      "Javier Arroyo"
    ],
    "abstract": "Peer-to-peer (P2P) lending connects borrowers and lenders through online\nplatforms but suffers from significant information asymmetry, as lenders often\nlack sufficient data to assess borrowers' creditworthiness. This paper\naddresses this challenge by leveraging BERT, a Large Language Model (LLM) known\nfor its ability to capture contextual nuances in text, to generate a risk score\nbased on borrowers' loan descriptions using a dataset from the Lending Club\nplatform. We fine-tune BERT to distinguish between defaulted and non-defaulted\nloans using the loan descriptions provided by the borrowers. The resulting\nBERT-generated risk score is then integrated as an additional feature into an\nXGBoost classifier used at the loan granting stage, where decision-makers have\nlimited information available to guide their decisions. This integration\nenhances predictive performance, with improvements in balanced accuracy and\nAUC, highlighting the value of textual features in complementing traditional\ninputs. Moreover, we find that the incorporation of the BERT score alters how\nclassification models utilize traditional input variables, with these changes\nvarying by loan purpose. These findings suggest that BERT discerns meaningful\npatterns in loan descriptions, encompassing borrower-specific features,\nspecific purposes, and linguistic characteristics. However, the inherent\nopacity of LLMs and their potential biases underscore the need for transparent\nframeworks to ensure regulatory compliance and foster trust. Overall, this\nstudy demonstrates how LLM-derived insights interact with traditional features\nin credit risk modeling, opening new avenues to enhance the explainability and\nfairness of these models.",
    "categories": [
      "q-fin.RM",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "q-fin.RM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.16458v3",
    "published_date": "2024-01-29 10:11:05 UTC",
    "updated_date": "2025-03-23 09:42:11 UTC"
  },
  {
    "arxiv_id": "2401.16013v4",
    "title": "SERL: A Software Suite for Sample-Efficient Robotic Reinforcement Learning",
    "authors": [
      "Jianlan Luo",
      "Zheyuan Hu",
      "Charles Xu",
      "You Liang Tan",
      "Jacob Berg",
      "Archit Sharma",
      "Stefan Schaal",
      "Chelsea Finn",
      "Abhishek Gupta",
      "Sergey Levine"
    ],
    "abstract": "In recent years, significant progress has been made in the field of robotic\nreinforcement learning (RL), enabling methods that handle complex image\nobservations, train in the real world, and incorporate auxiliary data, such as\ndemonstrations and prior experience. However, despite these advances, robotic\nRL remains hard to use. It is acknowledged among practitioners that the\nparticular implementation details of these algorithms are often just as\nimportant (if not more so) for performance as the choice of algorithm. We posit\nthat a significant challenge to widespread adoption of robotic RL, as well as\nfurther development of robotic RL methods, is the comparative inaccessibility\nof such methods. To address this challenge, we developed a carefully\nimplemented library containing a sample efficient off-policy deep RL method,\ntogether with methods for computing rewards and resetting the environment, a\nhigh-quality controller for a widely-adopted robot, and a number of challenging\nexample tasks. We provide this library as a resource for the community,\ndescribe its design choices, and present experimental results. Perhaps\nsurprisingly, we find that our implementation can achieve very efficient\nlearning, acquiring policies for PCB board assembly, cable routing, and object\nrelocation between 25 to 50 minutes of training per policy on average,\nimproving over state-of-the-art results reported for similar tasks in the\nliterature. These policies achieve perfect or near-perfect success rates,\nextreme robustness even under perturbations, and exhibit emergent recovery and\ncorrection behaviors. We hope that these promising results and our high-quality\nopen-source implementation will provide a tool for the robotics community to\nfacilitate further developments in robotic RL. Our code, documentation, and\nvideos can be found at https://serl-robot.github.io/",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "ICRA 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.16013v4",
    "published_date": "2024-01-29 10:01:10 UTC",
    "updated_date": "2025-03-20 09:13:10 UTC"
  },
  {
    "arxiv_id": "2401.16011v1",
    "title": "GPS: Graph Contrastive Learning via Multi-scale Augmented Views from Adversarial Pooling",
    "authors": [
      "Wei Ju",
      "Yiyang Gu",
      "Zhengyang Mao",
      "Ziyue Qiao",
      "Yifang Qin",
      "Xiao Luo",
      "Hui Xiong",
      "Ming Zhang"
    ],
    "abstract": "Self-supervised graph representation learning has recently shown considerable\npromise in a range of fields, including bioinformatics and social networks. A\nlarge number of graph contrastive learning approaches have shown promising\nperformance for representation learning on graphs, which train models by\nmaximizing agreement between original graphs and their augmented views (i.e.,\npositive views). Unfortunately, these methods usually involve pre-defined\naugmentation strategies based on the knowledge of human experts. Moreover,\nthese strategies may fail to generate challenging positive views to provide\nsufficient supervision signals. In this paper, we present a novel approach\nnamed Graph Pooling ContraSt (GPS) to address these issues. Motivated by the\nfact that graph pooling can adaptively coarsen the graph with the removal of\nredundancy, we rethink graph pooling and leverage it to automatically generate\nmulti-scale positive views with varying emphasis on providing challenging\npositives and preserving semantics, i.e., strongly-augmented view and\nweakly-augmented view. Then, we incorporate both views into a joint contrastive\nlearning framework with similarity learning and consistency learning, where our\npooling module is adversarially trained with respect to the encoder for\nadversarial robustness. Experiments on twelve datasets on both graph\nclassification and transfer learning tasks verify the superiority of the\nproposed method over its counterparts.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by SCIENCE CHINA Information Sciences (SCIS 2024)",
    "pdf_url": "http://arxiv.org/pdf/2401.16011v1",
    "published_date": "2024-01-29 10:00:53 UTC",
    "updated_date": "2024-01-29 10:00:53 UTC"
  },
  {
    "arxiv_id": "2401.16457v2",
    "title": "Effective Controllable Bias Mitigation for Classification and Retrieval using Gate Adapters",
    "authors": [
      "Shahed Masoudian",
      "Cornelia Volaucnik",
      "Markus Schedl",
      "Navid Rekabsaz"
    ],
    "abstract": "Bias mitigation of Language Models has been the topic of many studies with a\nrecent focus on learning separate modules like adapters for on-demand\ndebiasing. Besides optimizing for a modularized debiased model, it is often\ncritical in practice to control the degree of bias reduction at inference time,\ne.g., in order to tune for a desired performance-fairness trade-off in search\nresults or to control the strength of debiasing in classification tasks. In\nthis paper, we introduce Controllable Gate Adapter (ConGater), a novel modular\ngating mechanism with adjustable sensitivity parameters, which allows for a\ngradual transition from the biased state of the model to the fully debiased\nversion at inference time. We demonstrate ConGater performance by (1)\nconducting adversarial debiasing experiments with three different models on\nthree classification tasks with four protected attributes, and (2) reducing the\nbias of search results through fairness list-wise regularization to enable\nadjusting a trade-off between performance and fairness metrics. Our experiments\non the classification tasks show that compared to baselines of the same\ncaliber, ConGater can maintain higher task performance while containing less\ninformation regarding the attributes. Our results on the retrieval task show\nthat the fully debiased ConGater can achieve the same fairness performance\nwhile maintaining more than twice as high task performance than recent strong\nbaselines. Overall, besides strong performance ConGater enables the continuous\ntransitioning between biased and debiased states of models, enhancing\npersonalization of use and interpretability through controllability.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "Paper is accepted to main proceedings of EACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.16457v2",
    "published_date": "2024-01-29 09:15:50 UTC",
    "updated_date": "2024-02-19 07:54:52 UTC"
  },
  {
    "arxiv_id": "2402.01737v3",
    "title": "Assistive Large Language Model Agents for Socially-Aware Negotiation Dialogues",
    "authors": [
      "Yuncheng Hua",
      "Lizhen Qu",
      "Gholamreza Haffari"
    ],
    "abstract": "We develop assistive agents based on Large Language Models (LLMs) that aid\ninterlocutors in business negotiations. Specifically, we simulate business\nnegotiations by letting two LLM-based agents engage in role play. A third LLM\nacts as a remediator agent to rewrite utterances violating norms for improving\nnegotiation outcomes. We introduce a simple tuning-free and label-free\nIn-Context Learning (ICL) method to identify high-quality ICL exemplars for the\nremediator, where we propose a novel select criteria, called value impact, to\nmeasure the quality of the negotiation outcomes. We provide rich empirical\nevidence to demonstrate its effectiveness in negotiations across three\ndifferent negotiation topics. We have released our source code and the\ngenerated dataset at: https://github.com/tk1363704/SADAS.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "28 pages, 3 figures, 14 tables; The paper has been published in the\n  Findings of the Association for Computational Linguistics: EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2402.01737v3",
    "published_date": "2024-01-29 09:07:40 UTC",
    "updated_date": "2025-02-17 08:44:36 UTC"
  },
  {
    "arxiv_id": "2401.15970v2",
    "title": "HEQuant: Marrying Homomorphic Encryption and Quantization for Communication-Efficient Private Inference",
    "authors": [
      "Tianshi Xu",
      "Meng Li",
      "Runsheng Wang"
    ],
    "abstract": "Secure two-party computation with homomorphic encryption (HE) protects data\nprivacy with a formal security guarantee but suffers from high communication\noverhead. While previous works, e.g., Cheetah, Iron, etc, have proposed\nefficient HE-based protocols for different neural network (NN) operations, they\nstill assume high precision, e.g., fixed point 37 bit, for the NN operations\nand ignore NNs' native robustness against quantization error. In this paper, we\npropose HEQuant, which features low-precision-quantization-aware optimization\nfor the HE-based protocols. We observe the benefit of a naive combination of\nquantization and HE quickly saturates as bit precision goes down. Hence, to\nfurther improve communication efficiency, we propose a series of optimizations,\nincluding an intra-coefficient packing algorithm and a quantization-aware\ntiling algorithm, to simultaneously reduce the number and precision of the\ntransferred data. Compared with prior-art HE-based protocols, e.g., CrypTFlow2,\nCheetah, Iron, etc, HEQuant achieves $3.5\\sim 23.4\\times$ communication\nreduction and $3.0\\sim 9.3\\times$ latency reduction. Meanwhile, when compared\nwith prior-art network optimization frameworks, e.g., SENet, SNL, etc, HEQuant\nalso achieves $3.1\\sim 3.6\\times$ communication reduction.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.15970v2",
    "published_date": "2024-01-29 08:59:05 UTC",
    "updated_date": "2024-01-31 02:11:46 UTC"
  },
  {
    "arxiv_id": "2401.15969v2",
    "title": "Routers in Vision Mixture of Experts: An Empirical Study",
    "authors": [
      "Tianlin Liu",
      "Mathieu Blondel",
      "Carlos Riquelme",
      "Joan Puigcerver"
    ],
    "abstract": "Mixture-of-Experts (MoE) models are a promising way to scale up model\ncapacity without significantly increasing computational cost. A key component\nof MoEs is the router, which decides which subset of parameters (experts)\nprocess which feature embeddings (tokens). In this paper, we present a\ncomprehensive study of routers in MoEs for computer vision tasks. We introduce\na unified MoE formulation that subsumes different MoEs with two parametric\nrouting tensors. This formulation covers both sparse MoE, which uses a binary\nor hard assignment between experts and tokens, and soft MoE, which uses a soft\nassignment between experts and weighted combinations of tokens. Routers for\nsparse MoEs can be further grouped into two variants: Token Choice, which\nmatches experts to each token, and Expert Choice, which matches tokens to each\nexpert. We conduct head-to-head experiments with 6 different routers, including\nexisting routers from prior work and new ones we introduce. We show that (i)\nmany routers originally developed for language modeling can be adapted to\nperform strongly in vision tasks, (ii) in sparse MoE, Expert Choice routers\ngenerally outperform Token Choice routers, and (iii) soft MoEs generally\noutperform sparse MoEs with a fixed compute budget. These results provide new\ninsights regarding the crucial role of routers in vision MoE models.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.15969v2",
    "published_date": "2024-01-29 08:58:07 UTC",
    "updated_date": "2024-04-18 18:48:31 UTC"
  },
  {
    "arxiv_id": "2402.01736v1",
    "title": "SADAS: A Dialogue Assistant System Towards Remediating Norm Violations in Bilingual Socio-Cultural Conversations",
    "authors": [
      "Yuncheng Hua",
      "Zhuang Li",
      "Linhao Luo",
      "Kadek Ananta Satriadi",
      "Tao Feng",
      "Haolan Zhan",
      "Lizhen Qu",
      "Suraj Sharma",
      "Ingrid Zukerman",
      "Zhaleh Semnani-Azad",
      "Gholamreza Haffari"
    ],
    "abstract": "In today's globalized world, bridging the cultural divide is more critical\nthan ever for forging meaningful connections. The Socially-Aware Dialogue\nAssistant System (SADAS) is our answer to this global challenge, and it's\ndesigned to ensure that conversations between individuals from diverse cultural\nbackgrounds unfold with respect and understanding. Our system's novel\narchitecture includes: (1) identifying the categories of norms present in the\ndialogue, (2) detecting potential norm violations, (3) evaluating the severity\nof these violations, (4) implementing targeted remedies to rectify the\nbreaches, and (5) articulates the rationale behind these corrective actions. We\nemploy a series of State-Of-The-Art (SOTA) techniques to build different\nmodules, and conduct numerous experiments to select the most suitable backbone\nmodel for each of the modules. We also design a human preference experiment to\nvalidate the overall performance of the system. We will open-source our system\n(including source code, tools and applications), hoping to advance future\nresearch. A demo video of our system can be found\nat:~\\url{https://youtu.be/JqetWkfsejk}. We have released our code and software\nat:~\\url{https://github.com/AnonymousEACLDemo/SADAS}.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2402.01736v1",
    "published_date": "2024-01-29 08:54:21 UTC",
    "updated_date": "2024-01-29 08:54:21 UTC"
  },
  {
    "arxiv_id": "2401.15966v1",
    "title": "Response Generation for Cognitive Behavioral Therapy with Large Language Models: Comparative Study with Socratic Questioning",
    "authors": [
      "Kenta Izumi",
      "Hiroki Tanaka",
      "Kazuhiro Shidara",
      "Hiroyoshi Adachi",
      "Daisuke Kanayama",
      "Takashi Kudo",
      "Satoshi Nakamura"
    ],
    "abstract": "Dialogue systems controlled by predefined or rule-based scenarios derived\nfrom counseling techniques, such as cognitive behavioral therapy (CBT), play an\nimportant role in mental health apps. Despite the need for responsible\nresponses, it is conceivable that using the newly emerging LLMs to generate\ncontextually relevant utterances will enhance these apps. In this study, we\nconstruct dialogue modules based on a CBT scenario focused on conventional\nSocratic questioning using two kinds of LLMs: a Transformer-based dialogue\nmodel further trained with a social media empathetic counseling dataset,\nprovided by Osaka Prefecture (OsakaED), and GPT-4, a state-of-the art LLM\ncreated by OpenAI. By comparing systems that use LLM-generated responses with\nthose that do not, we investigate the impact of generated responses on\nsubjective evaluations such as mood change, cognitive change, and dialogue\nquality (e.g., empathy). As a result, no notable improvements are observed when\nusing the OsakaED model. When using GPT-4, the amount of mood change, empathy,\nand other dialogue qualities improve significantly. Results suggest that GPT-4\npossesses a high counseling ability. However, they also indicate that even when\nusing a dialogue model trained with a human counseling dataset, it does not\nnecessarily yield better outcomes compared to scenario-based dialogues. While\npresenting LLM-generated responses, including GPT-4, and having them interact\ndirectly with users in real-life mental health care services may raise ethical\nissues, it is still possible for human professionals to produce example\nresponses or response templates using LLMs in advance in systems that use\nrules, scenarios, or example responses.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by IWSDS2024",
    "pdf_url": "http://arxiv.org/pdf/2401.15966v1",
    "published_date": "2024-01-29 08:53:41 UTC",
    "updated_date": "2024-01-29 08:53:41 UTC"
  },
  {
    "arxiv_id": "2401.15963v3",
    "title": "NoFunEval: Funny How Code LMs Falter on Requirements Beyond Functional Correctness",
    "authors": [
      "Manav Singhal",
      "Tushar Aggarwal",
      "Abhijeet Awasthi",
      "Nagarajan Natarajan",
      "Aditya Kanade"
    ],
    "abstract": "Existing evaluation benchmarks of language models of code (code LMs) focus\nalmost exclusively on whether the LMs can generate functionally-correct code.\nIn real-world software engineering, developers think beyond functional\ncorrectness. They have requirements on \"how\" a functionality should be\nimplemented to meet overall system design objectives like efficiency, security,\nand maintainability. They would also trust the code LMs more if the LMs\ndemonstrate robust understanding of such requirements.\n  We propose a new benchmark NoFunEval to evaluate code LMs on non-functional\nrequirements and simple classification instances for both functional and\nnon-functional requirements. We propose a prompting method, Coding Concepts\n(CoCo), as a way for a developer to communicate the domain knowledge to the\nLMs. We conduct an extensive evaluation of 27 code LMs. Our finding is that LMs\ngenerally falter when tested on our benchmark, hinting at fundamental\nblindspots in their training setups. Surprisingly, even the classification\naccuracy on functional-correctness instances derived from the popular HumanEval\nbenchmark is low, calling in question the depth of their comprehension and the\nsource of their success in generating functionally-correct code in the first\nplace. We release our benchmark and evaluation scripts publicly at\nhttps://aka.ms/NoFunEval.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted at COLM'24",
    "pdf_url": "http://arxiv.org/pdf/2401.15963v3",
    "published_date": "2024-01-29 08:47:31 UTC",
    "updated_date": "2024-09-29 05:03:25 UTC"
  },
  {
    "arxiv_id": "2401.15957v1",
    "title": "Scalable Federated Unlearning via Isolated and Coded Sharding",
    "authors": [
      "Yijing Lin",
      "Zhipeng Gao",
      "Hongyang Du",
      "Dusit Niyato",
      "Gui Gui",
      "Shuguang Cui",
      "Jinke Ren"
    ],
    "abstract": "Federated unlearning has emerged as a promising paradigm to erase the\nclient-level data effect without affecting the performance of collaborative\nlearning models. However, the federated unlearning process often introduces\nextensive storage overhead and consumes substantial computational resources,\nthus hindering its implementation in practice. To address this issue, this\npaper proposes a scalable federated unlearning framework based on isolated\nsharding and coded computing. We first divide distributed clients into multiple\nisolated shards across stages to reduce the number of clients being affected.\nThen, to reduce the storage overhead of the central server, we develop a coded\ncomputing mechanism by compressing the model parameters across different\nshards. In addition, we provide the theoretical analysis of time efficiency and\nstorage effectiveness for the isolated and coded sharding. Finally, extensive\nexperiments on two typical learning tasks, i.e., classification and generation,\ndemonstrate that our proposed framework can achieve better performance than\nthree state-of-the-art frameworks in terms of accuracy, retraining time,\nstorage overhead, and F1 scores for resisting membership inference attacks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.15957v1",
    "published_date": "2024-01-29 08:41:45 UTC",
    "updated_date": "2024-01-29 08:41:45 UTC"
  },
  {
    "arxiv_id": "2402.01735v2",
    "title": "VIALM: A Survey and Benchmark of Visually Impaired Assistance with Large Models",
    "authors": [
      "Yi Zhao",
      "Yilin Zhang",
      "Rong Xiang",
      "Jing Li",
      "Hillming Li"
    ],
    "abstract": "Visually Impaired Assistance (VIA) aims to automatically help the visually\nimpaired (VI) handle daily activities. The advancement of VIA primarily depends\non developments in Computer Vision (CV) and Natural Language Processing (NLP),\nboth of which exhibit cutting-edge paradigms with large models (LMs).\nFurthermore, LMs have shown exceptional multimodal abilities to tackle\nchallenging physically-grounded tasks such as embodied robots. To investigate\nthe potential and limitations of state-of-the-art (SOTA) LMs' capabilities in\nVIA applications, we present an extensive study for the task of VIA with LMs\n(VIALM). In this task, given an image illustrating the physical environments\nand a linguistic request from a VI user, VIALM aims to output step-by-step\nguidance to assist the VI user in fulfilling the request grounded in the\nenvironment. The study consists of a survey reviewing recent LM research and\nbenchmark experiments examining selected LMs' capabilities in VIA. The results\nindicate that while LMs can potentially benefit VIA, their output cannot be\nwell environment-grounded (i.e., 25.7% GPT-4's responses) and lacks\nfine-grained guidance (i.e., 32.1% GPT-4's responses).",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "under review",
    "pdf_url": "http://arxiv.org/pdf/2402.01735v2",
    "published_date": "2024-01-29 08:28:32 UTC",
    "updated_date": "2024-02-10 14:08:55 UTC"
  },
  {
    "arxiv_id": "2401.15952v1",
    "title": "A Class-aware Optimal Transport Approach with Higher-Order Moment Matching for Unsupervised Domain Adaptation",
    "authors": [
      "Tuan Nguyen",
      "Van Nguyen",
      "Trung Le",
      "He Zhao",
      "Quan Hung Tran",
      "Dinh Phung"
    ],
    "abstract": "Unsupervised domain adaptation (UDA) aims to transfer knowledge from a\nlabeled source domain to an unlabeled target domain. In this paper, we\nintroduce a novel approach called class-aware optimal transport (OT), which\nmeasures the OT distance between a distribution over the source\nclass-conditional distributions and a mixture of source and target data\ndistribution. Our class-aware OT leverages a cost function that determines the\nmatching extent between a given data example and a source class-conditional\ndistribution. By optimizing this cost function, we find the optimal matching\nbetween target examples and source class-conditional distributions, effectively\naddressing the data and label shifts that occur between the two domains. To\nhandle the class-aware OT efficiently, we propose an amortization solution that\nemploys deep neural networks to formulate the transportation probabilities and\nthe cost function. Additionally, we propose minimizing class-aware Higher-order\nMoment Matching (HMM) to align the corresponding class regions on the source\nand target domains. The class-aware HMM component offers an economical\ncomputational approach for accurately evaluating the HMM distance between the\ntwo distributions. Extensive experiments on benchmark datasets demonstrate that\nour proposed method significantly outperforms existing state-of-the-art\nbaselines.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "18 pages",
    "pdf_url": "http://arxiv.org/pdf/2401.15952v1",
    "published_date": "2024-01-29 08:27:31 UTC",
    "updated_date": "2024-01-29 08:27:31 UTC"
  },
  {
    "arxiv_id": "2401.15944v1",
    "title": "Bridging the Domain Gap: A Simple Domain Matching Method for Reference-based Image Super-Resolution in Remote Sensing",
    "authors": [
      "Jeongho Min",
      "Yejun Lee",
      "Dongyoung Kim",
      "Jaejun Yoo"
    ],
    "abstract": "Recently, reference-based image super-resolution (RefSR) has shown excellent\nperformance in image super-resolution (SR) tasks. The main idea of RefSR is to\nutilize additional information from the reference (Ref) image to recover the\nhigh-frequency components in low-resolution (LR) images. By transferring\nrelevant textures through feature matching, RefSR models outperform existing\nsingle image super-resolution (SISR) models. However, their performance\nsignificantly declines when a domain gap between Ref and LR images exists,\nwhich often occurs in real-world scenarios, such as satellite imaging. In this\nletter, we introduce a Domain Matching (DM) module that can be seamlessly\nintegrated with existing RefSR models to enhance their performance in a\nplug-and-play manner. To the best of our knowledge, we are the first to explore\nDomain Matching-based RefSR in remote sensing image processing. Our analysis\nreveals that their domain gaps often occur in different satellites, and our\nmodel effectively addresses these challenges, whereas existing models struggle.\nOur experiments demonstrate that the proposed DM module improves SR performance\nboth qualitatively and quantitatively for remote sensing super-resolution\ntasks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to IEEE GRSL 2023",
    "pdf_url": "http://arxiv.org/pdf/2401.15944v1",
    "published_date": "2024-01-29 08:10:00 UTC",
    "updated_date": "2024-01-29 08:10:00 UTC"
  },
  {
    "arxiv_id": "2401.15935v4",
    "title": "MLEM: Generative and Contrastive Learning as Distinct Modalities for Event Sequences",
    "authors": [
      "Viktor Moskvoretskii",
      "Dmitry Osin",
      "Egor Shvetsov",
      "Igor Udovichenko",
      "Maxim Zhelnin",
      "Andrey Dukhovny",
      "Anna Zhimerikina",
      "Evgeny Burnaev"
    ],
    "abstract": "This study explores the application of self-supervised learning techniques\nfor event sequences. It is a key modality in various applications such as\nbanking, e-commerce, and healthcare. However, there is limited research on\nself-supervised learning for event sequences, and methods from other domains\nlike images, texts, and speech may not easily transfer. To determine the most\nsuitable approach, we conduct a detailed comparative analysis of previously\nidentified best-performing methods. We find that neither the contrastive nor\ngenerative method is superior. Our assessment includes classifying event\nsequences, predicting the next event, and evaluating embedding quality. These\nresults further highlight the potential benefits of combining both methods.\nGiven the lack of research on hybrid models in this domain, we initially adapt\nthe baseline model from another domain. However, upon observing its\nunderperformance, we develop a novel method called the Multimodal-Learning\nEvent Model (MLEM). MLEM treats contrastive learning and generative modeling as\ndistinct yet complementary modalities, aligning their embeddings. The results\nof our study demonstrate that combining contrastive and generative approaches\ninto one procedure with MLEM achieves superior performance across multiple\nmetrics.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2401.15935v4",
    "published_date": "2024-01-29 07:50:28 UTC",
    "updated_date": "2024-07-03 09:28:50 UTC"
  },
  {
    "arxiv_id": "2401.15931v2",
    "title": "EmoDM: A Diffusion Model for Evolutionary Multi-objective Optimization",
    "authors": [
      "Xueming Yan",
      "Yaochu Jin"
    ],
    "abstract": "Evolutionary algorithms have been successful in solving multi-objective\noptimization problems (MOPs). However, as a class of population-based search\nmethodology, evolutionary algorithms require a large number of evaluations of\nthe objective functions, preventing them from being applied to a wide range of\nexpensive MOPs. To tackle the above challenge, this work proposes for the first\ntime a diffusion model that can learn to perform evolutionary multi-objective\nsearch, called EmoDM. This is achieved by treating the reversed convergence\nprocess of evolutionary search as the forward diffusion and learn the noise\ndistributions from previously solved evolutionary optimization tasks. The\npre-trained EmoDM can then generate a set of non-dominated solutions for a new\nMOP by means of its reverse diffusion without further evolutionary search,\nthereby significantly reducing the required function evaluations. To enhance\nthe scalability of EmoDM, a mutual entropy-based attention mechanism is\nintroduced to capture the decision variables that are most important for the\nobjectives. Experimental results demonstrate the competitiveness of EmoDM in\nterms of both the search performance and computational efficiency compared with\nstate-of-the-art evolutionary algorithms in solving MOPs having up to 5000\ndecision variables. The pre-trained EmoDM is shown to generalize well to unseen\nproblems, revealing its strong potential as a general and efficient MOP solver.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.15931v2",
    "published_date": "2024-01-29 07:41:44 UTC",
    "updated_date": "2024-08-15 05:00:45 UTC"
  },
  {
    "arxiv_id": "2401.15914v2",
    "title": "Overcoming the Pitfalls of Vision-Language Model Finetuning for OOD Generalization",
    "authors": [
      "Yuhang Zang",
      "Hanlin Goh",
      "Josh Susskind",
      "Chen Huang"
    ],
    "abstract": "Existing vision-language models exhibit strong generalization on a variety of\nvisual domains and tasks. However, such models mainly perform zero-shot\nrecognition in a closed-set manner, and thus struggle to handle open-domain\nvisual concepts by design. There are recent finetuning methods, such as prompt\nlearning, that not only study the discrimination between in-distribution (ID)\nand out-of-distribution (OOD) samples, but also show some improvements in both\nID and OOD accuracies. In this paper, we first demonstrate that vision-language\nmodels, after long enough finetuning but without proper regularization, tend to\noverfit the known classes in the given dataset, with degraded performance on\nunknown classes. Then we propose a novel approach OGEN to address this pitfall,\nwith the main focus on improving the OOD GENeralization of finetuned models.\nSpecifically, a class-conditional feature generator is introduced to synthesize\nOOD features using just the class name of any unknown class. Such synthesized\nfeatures will provide useful knowledge about unknowns and help regularize the\ndecision boundary between ID and OOD data when optimized jointly. Equally\nimportant is our adaptive self-distillation mechanism to regularize our feature\ngeneration model during joint optimization, i.e., adaptively transferring\nknowledge between model states to further prevent overfitting. Experiments\nvalidate that our method yields convincing gains in OOD generalization\nperformance in different settings. Code: https://github.com/apple/ml-ogen.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "ICLR 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.15914v2",
    "published_date": "2024-01-29 06:57:48 UTC",
    "updated_date": "2024-04-16 03:25:25 UTC"
  },
  {
    "arxiv_id": "2401.16454v1",
    "title": "KAUCUS: Knowledge Augmented User Simulators for Training Language Model Assistants",
    "authors": [
      "Kaustubh D. Dhole"
    ],
    "abstract": "An effective multi-turn instruction-following assistant can be developed by\ncreating a simulator that can generate useful interaction data. Apart from\nrelying on its intrinsic weights, an ideal user simulator should also be able\nto bootstrap external knowledge rapidly in its raw form to simulate the\nmultifarious diversity of text available over the internet. Previous user\nsimulators generally lacked diversity, were mostly closed domain, and\nnecessitated rigid schema making them inefficient to rapidly scale to\nincorporate external knowledge. In this regard, we introduce, Kaucus, a\nKnowledge-Augmented User Simulator framework, to outline a process of creating\ndiverse user simulators, that can seamlessly exploit external knowledge as well\nas benefit downstream assistant model training. Through two GPT-J based\nsimulators viz., a Retrieval Augmented Simulator and a Summary Controlled\nSimulator we generate diverse simulator-assistant interactions. Through reward\nand preference model-based evaluations, we find that these interactions serve\nas useful training data and create more helpful downstream assistants. We also\nfind that incorporating knowledge through retrieval augmentation or summary\ncontrol helps create better assistants.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL",
      "cs.IR",
      "I.2.7; H.3.3"
    ],
    "primary_category": "cs.HC",
    "comment": "Simulation of Conversational Intelligence in Chat, EACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.16454v1",
    "published_date": "2024-01-29 06:57:02 UTC",
    "updated_date": "2024-01-29 06:57:02 UTC"
  },
  {
    "arxiv_id": "2402.01733v1",
    "title": "Development and Testing of Retrieval Augmented Generation in Large Language Models -- A Case Study Report",
    "authors": [
      "YuHe Ke",
      "Liyuan Jin",
      "Kabilan Elangovan",
      "Hairil Rizal Abdullah",
      "Nan Liu",
      "Alex Tiong Heng Sia",
      "Chai Rick Soh",
      "Joshua Yi Min Tung",
      "Jasmine Chiat Ling Ong",
      "Daniel Shu Wei Ting"
    ],
    "abstract": "Purpose: Large Language Models (LLMs) hold significant promise for medical\napplications. Retrieval Augmented Generation (RAG) emerges as a promising\napproach for customizing domain knowledge in LLMs. This case study presents the\ndevelopment and evaluation of an LLM-RAG pipeline tailored for healthcare,\nfocusing specifically on preoperative medicine.\n  Methods: We developed an LLM-RAG model using 35 preoperative guidelines and\ntested it against human-generated responses, with a total of 1260 responses\nevaluated. The RAG process involved converting clinical documents into text\nusing Python-based frameworks like LangChain and Llamaindex, and processing\nthese texts into chunks for embedding and retrieval. Vector storage techniques\nand selected embedding models to optimize data retrieval, using Pinecone for\nvector storage with a dimensionality of 1536 and cosine similarity for loss\nmetrics. Human-generated answers, provided by junior doctors, were used as a\ncomparison.\n  Results: The LLM-RAG model generated answers within an average of 15-20\nseconds, significantly faster than the 10 minutes typically required by humans.\nAmong the basic LLMs, GPT4.0 exhibited the best accuracy of 80.1%. This\naccuracy was further increased to 91.4% when the model was enhanced with RAG.\nCompared to the human-generated instructions, which had an accuracy of 86.3%,\nthe performance of the GPT4.0 RAG model demonstrated non-inferiority (p=0.610).\n  Conclusions: In this case study, we demonstrated a LLM-RAG model for\nhealthcare implementation. The pipeline shows the advantages of grounded\nknowledge, upgradability, and scalability as important aspects of healthcare\nLLM deployment.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "NA",
    "pdf_url": "http://arxiv.org/pdf/2402.01733v1",
    "published_date": "2024-01-29 06:49:53 UTC",
    "updated_date": "2024-01-29 06:49:53 UTC"
  },
  {
    "arxiv_id": "2401.15911v3",
    "title": "Distribution-consistency Structural Causal Models",
    "authors": [
      "Heyang Gong",
      "Chaochao Lu",
      "Yu Zhang"
    ],
    "abstract": "In the field of causal modeling, potential outcomes (PO) and structural\ncausal models (SCMs) stand as the predominant frameworks. However, these\nframeworks face notable challenges in practically modeling counterfactuals,\nformalized as parameters of the joint distribution of potential outcomes.\nCounterfactual reasoning holds paramount importance in contemporary\ndecision-making processes, especially in scenarios that demand personalized\nincentives based on the joint values of $(Y(0), Y(1))$. This paper begins with\nan investigation of the PO and SCM frameworks for modeling counterfactuals.\nThrough the analysis, we identify an inherent model capacity limitation, termed\nas the ``degenerative counterfactual problem'', emerging from the consistency\nrule that is the cornerstone of both frameworks. To address this limitation, we\nintroduce a novel \\textit{distribution-consistency} assumption, and in\nalignment with it, we propose the Distribution-consistency Structural Causal\nModels (DiscoSCMs) offering enhanced capabilities to model counterfactuals. To\nconcretely reveal the enhanced model capacity, we introduce a new identifiable\ncausal parameter, \\textit{the probability of consistency}, which holds\npractical significance within DiscoSCM alone, showcased with a personalized\nincentive example. Furthermore, we provide a comprehensive set of theoretical\nresults about the ``Ladder of Causation'' within the DiscoSCM framework. We\nhope it opens new avenues for future research of counterfactual modeling,\nultimately enhancing our understanding of causality and its real-world\napplications.",
    "categories": [
      "cs.AI",
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.15911v3",
    "published_date": "2024-01-29 06:46:15 UTC",
    "updated_date": "2024-03-23 02:15:31 UTC"
  },
  {
    "arxiv_id": "2401.16453v1",
    "title": "Hybrid Transformer and Spatial-Temporal Self-Supervised Learning for Long-term Traffic Prediction",
    "authors": [
      "Wang Zhu",
      "Doudou Zhang",
      "Baichao Long",
      "Jianli Xiao"
    ],
    "abstract": "Long-term traffic prediction has always been a challenging task due to its\ndynamic temporal dependencies and complex spatial dependencies. In this paper,\nwe propose a model that combines hybrid Transformer and spatio-temporal\nself-supervised learning. The model enhances its robustness by applying\nadaptive data augmentation techniques at the sequence-level and graph-level of\nthe traffic data. It utilizes Transformer to overcome the limitations of\nrecurrent neural networks in capturing long-term sequences, and employs\nChebyshev polynomial graph convolution to capture complex spatial dependencies.\nFurthermore, considering the impact of spatio-temporal heterogeneity on traffic\nspeed, we design two self-supervised learning tasks to model the temporal and\nspatial heterogeneity, thereby improving the accuracy and generalization\nability of the model. Experimental evaluations are conducted on two real-world\ndatasets, PeMS04 and PeMS08, and the results are visualized and analyzed,\ndemonstrating the superior performance of the proposed model.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "22 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2401.16453v1",
    "published_date": "2024-01-29 06:17:23 UTC",
    "updated_date": "2024-01-29 06:17:23 UTC"
  },
  {
    "arxiv_id": "2401.17129v1",
    "title": "Enhanced Sound Event Localization and Detection in Real 360-degree audio-visual soundscapes",
    "authors": [
      "Adrian S. Roman",
      "Baladithya Balamurugan",
      "Rithik Pothuganti"
    ],
    "abstract": "This technical report details our work towards building an enhanced\naudio-visual sound event localization and detection (SELD) network. We build on\ntop of the audio-only SELDnet23 model and adapt it to be audio-visual by\nmerging both audio and video information prior to the gated recurrent unit\n(GRU) of the audio-only network. Our model leverages YOLO and DETIC object\ndetectors. We also build a framework that implements audio-visual data\naugmentation and audio-visual synthetic data generation. We deliver an\naudio-visual SELDnet system that outperforms the existing audio-visual SELD\nbaseline.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.17129v1",
    "published_date": "2024-01-29 06:05:23 UTC",
    "updated_date": "2024-01-29 06:05:23 UTC"
  },
  {
    "arxiv_id": "2401.16452v3",
    "title": "Context-Former: Stitching via Latent Conditioned Sequence Modeling",
    "authors": [
      "Ziqi Zhang",
      "Jingzehua Xu",
      "Jinxin Liu",
      "Zifeng Zhuang",
      "Donglin Wang",
      "Miao Liu",
      "Shuai Zhang"
    ],
    "abstract": "Offline reinforcement learning (RL) algorithms can learn better\ndecision-making compared to behavior policies by stitching the suboptimal\ntrajectories to derive more optimal ones. Meanwhile, Decision Transformer (DT)\nabstracts the RL as sequence modeling, showcasing competitive performance on\noffline RL benchmarks. However, recent studies demonstrate that DT lacks of\nstitching capacity, thus exploiting stitching capability for DT is vital to\nfurther improve its performance. In order to endow stitching capability to DT,\nwe abstract trajectory stitching as expert matching and introduce our approach,\nContextFormer, which integrates contextual information-based imitation learning\n(IL) and sequence modeling to stitch sub-optimal trajectory fragments by\nemulating the representations of a limited number of expert trajectories. To\nvalidate our approach, we conduct experiments from two perspectives: 1) We\nconduct extensive experiments on D4RL benchmarks under the settings of IL, and\nexperimental results demonstrate ContextFormer can achieve competitive\nperformance in multiple IL settings. 2) More importantly, we conduct a\ncomparison of ContextFormer with various competitive DT variants using\nidentical training datasets. The experimental results unveiled ContextFormer's\nsuperiority, as it outperformed all other variants, showcasing its remarkable\nperformance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.16452v3",
    "published_date": "2024-01-29 06:05:14 UTC",
    "updated_date": "2024-05-27 08:38:18 UTC"
  },
  {
    "arxiv_id": "2401.15896v2",
    "title": "M2-Encoder: Advancing Bilingual Image-Text Understanding by Large-scale Efficient Pretraining",
    "authors": [
      "Qingpei Guo",
      "Furong Xu",
      "Hanxiao Zhang",
      "Wang Ren",
      "Ziping Ma",
      "Lin Ju",
      "Jian Wang",
      "Jingdong Chen",
      "Ming Yang"
    ],
    "abstract": "Vision-language foundation models like CLIP have revolutionized the field of\nartificial intelligence. Nevertheless, VLM models supporting multi-language,\ne.g., in both Chinese and English, have lagged due to the relative scarcity of\nlarge-scale pretraining datasets. Toward this end, we introduce a comprehensive\nbilingual (Chinese-English) dataset BM-6B with over 6 billion image-text pairs,\naimed at enhancing multimodal foundation models to well understand images in\nboth languages. To handle such a scale of dataset, we propose a novel grouped\naggregation approach for image-text contrastive loss computation, which reduces\nthe communication overhead and GPU memory demands significantly, facilitating a\n60% increase in training speed. We pretrain a series of bilingual image-text\nfoundation models with an enhanced fine-grained understanding ability on BM-6B,\nthe resulting models, dubbed as $M^2$-Encoders (pronounced \"M-Square\"), set new\nbenchmarks in both languages for multimodal retrieval and classification tasks.\nNotably, Our largest $M^2$-Encoder-10B model has achieved top-1 accuracies of\n88.5% on ImageNet and 80.7% on ImageNet-CN under a zero-shot classification\nsetting, surpassing previously reported SoTA methods by 2.2% and 21.1%,\nrespectively. The $M^2$-Encoder series represents one of the most comprehensive\nbilingual image-text foundation models to date, so we are making it available\nto the research community for further exploration and development.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.15896v2",
    "published_date": "2024-01-29 05:43:33 UTC",
    "updated_date": "2024-02-04 04:30:07 UTC"
  },
  {
    "arxiv_id": "2401.15894v2",
    "title": "Enhancing Topological Dependencies in Spatio-Temporal Graphs with Cycle Message Passing Blocks",
    "authors": [
      "Minho Lee",
      "Yun Young Choi",
      "Sun Woo Park",
      "Seunghwan Lee",
      "Joohwan Ko",
      "Jaeyoung Hong"
    ],
    "abstract": "Graph Neural Networks (GNNs) and Transformer-based models have been\nincreasingly adopted to learn the complex vector representations of\nspatio-temporal graphs, capturing intricate spatio-temporal dependencies\ncrucial for applications such as traffic datasets. Although many existing\nmethods utilize multi-head attention mechanisms and message-passing neural\nnetworks (MPNNs) to capture both spatial and temporal relations, these\napproaches encode temporal and spatial relations independently, and reflect the\ngraph's topological characteristics in a limited manner. In this work, we\nintroduce the Cycle to Mixer (Cy2Mixer), a novel spatio-temporal GNN based on\ntopological non-trivial invariants of spatio-temporal graphs with gated\nmulti-layer perceptrons (gMLP). The Cy2Mixer is composed of three blocks based\non MLPs: A temporal block for capturing temporal properties, a message-passing\nblock for encapsulating spatial information, and a cycle message-passing block\nfor enriching topological information through cyclic subgraphs. We bolster the\neffectiveness of Cy2Mixer with mathematical evidence emphasizing that our cycle\nmessage-passing block is capable of offering differentiated information to the\ndeep learning model compared to the message-passing block. Furthermore,\nempirical evaluations substantiate the efficacy of the Cy2Mixer, demonstrating\nstate-of-the-art performances across various spatio-temporal benchmark\ndatasets. The source code is available at\n\\url{https://github.com/leemingo/cy2mixer}.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Proceedings of the Third Learning on Graphs Conference (LoG 2024)",
    "pdf_url": "http://arxiv.org/pdf/2401.15894v2",
    "published_date": "2024-01-29 05:26:17 UTC",
    "updated_date": "2024-12-05 19:59:15 UTC"
  },
  {
    "arxiv_id": "2401.15889v2",
    "title": "Sliced Wasserstein with Random-Path Projecting Directions",
    "authors": [
      "Khai Nguyen",
      "Shujian Zhang",
      "Tam Le",
      "Nhat Ho"
    ],
    "abstract": "Slicing distribution selection has been used as an effective technique to\nimprove the performance of parameter estimators based on minimizing sliced\nWasserstein distance in applications. Previous works either utilize expensive\noptimization to select the slicing distribution or use slicing distributions\nthat require expensive sampling methods. In this work, we propose an\noptimization-free slicing distribution that provides a fast sampling for the\nMonte Carlo estimation of expectation. In particular, we introduce the\nrandom-path projecting direction (RPD) which is constructed by leveraging the\nnormalized difference between two random vectors following the two input\nmeasures. From the RPD, we derive the random-path slicing distribution (RPSD)\nand two variants of sliced Wasserstein, i.e., the Random-Path Projection Sliced\nWasserstein (RPSW) and the Importance Weighted Random-Path Projection Sliced\nWasserstein (IWRPSW). We then discuss the topological, statistical, and\ncomputational properties of RPSW and IWRPSW. Finally, we showcase the favorable\nperformance of RPSW and IWRPSW in gradient flow and the training of denoising\ndiffusion generative models on images.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "Accepted to ICML 2024, 21 pages, 5 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2401.15889v2",
    "published_date": "2024-01-29 04:59:30 UTC",
    "updated_date": "2024-05-09 03:48:05 UTC"
  },
  {
    "arxiv_id": "2401.15872v1",
    "title": "A Deep Q-Network Based on Radial Basis Functions for Multi-Echelon Inventory Management",
    "authors": [
      "Liqiang Cheng",
      "Jun Luo",
      "Weiwei Fan",
      "Yidong Zhang",
      "Yuan Li"
    ],
    "abstract": "This paper addresses a multi-echelon inventory management problem with a\ncomplex network topology where deriving optimal ordering decisions is\ndifficult. Deep reinforcement learning (DRL) has recently shown potential in\nsolving such problems, while designing the neural networks in DRL remains a\nchallenge. In order to address this, a DRL model is developed whose Q-network\nis based on radial basis functions. The approach can be more easily constructed\ncompared to classic DRL models based on neural networks, thus alleviating the\ncomputational burden of hyperparameter tuning. Through a series of simulation\nexperiments, the superior performance of this approach is demonstrated compared\nto the simple base-stock policy, producing a better policy in the multi-echelon\nsystem and competitive performance in the serial system where the base-stock\npolicy is optimal. In addition, the approach outperforms current DRL\napproaches.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.15872v1",
    "published_date": "2024-01-29 04:11:56 UTC",
    "updated_date": "2024-01-29 04:11:56 UTC"
  },
  {
    "arxiv_id": "2401.15863v1",
    "title": "Importance-Aware Adaptive Dataset Distillation",
    "authors": [
      "Guang Li",
      "Ren Togo",
      "Takahiro Ogawa",
      "Miki Haseyama"
    ],
    "abstract": "Herein, we propose a novel dataset distillation method for constructing small\ninformative datasets that preserve the information of the large original\ndatasets. The development of deep learning models is enabled by the\navailability of large-scale datasets. Despite unprecedented success,\nlarge-scale datasets considerably increase the storage and transmission costs,\nresulting in a cumbersome model training process. Moreover, using raw data for\ntraining raises privacy and copyright concerns. To address these issues, a new\ntask named dataset distillation has been introduced, aiming to synthesize a\ncompact dataset that retains the essential information from the large original\ndataset. State-of-the-art (SOTA) dataset distillation methods have been\nproposed by matching gradients or network parameters obtained during training\non real and synthetic datasets. The contribution of different network\nparameters to the distillation process varies, and uniformly treating them\nleads to degraded distillation performance. Based on this observation, we\npropose an importance-aware adaptive dataset distillation (IADD) method that\ncan improve distillation performance by automatically assigning importance\nweights to different network parameters during distillation, thereby\nsynthesizing more robust distilled datasets. IADD demonstrates superior\nperformance over other SOTA dataset distillation methods based on parameter\nmatching on multiple benchmark datasets and outperforms them in terms of\ncross-architecture generalization. In addition, the analysis of self-adaptive\nweights demonstrates the effectiveness of IADD. Furthermore, the effectiveness\nof IADD is validated in a real-world medical application such as COVID-19\ndetection.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Published as a journal paper in Elsevier Neural Networks",
    "pdf_url": "http://arxiv.org/pdf/2401.15863v1",
    "published_date": "2024-01-29 03:29:39 UTC",
    "updated_date": "2024-01-29 03:29:39 UTC"
  },
  {
    "arxiv_id": "2401.15861v4",
    "title": "BPDec: Unveiling the Potential of Masked Language Modeling Decoder in BERT pretraining",
    "authors": [
      "Wen Liang",
      "Youzhi Liang"
    ],
    "abstract": "BERT (Bidirectional Encoder Representations from Transformers) has\nrevolutionized the field of natural language processing through its exceptional\nperformance on numerous tasks. Yet, the majority of researchers have mainly\nconcentrated on enhancements related to the model structure, such as relative\nposition embedding and more efficient attention mechanisms. Others have delved\ninto pretraining tricks associated with Masked Language Modeling, including\nwhole word masking. DeBERTa introduced an enhanced decoder adapted for BERT's\nencoder model for pretraining, proving to be highly effective. We argue that\nthe design and research around enhanced masked language modeling decoders have\nbeen underappreciated. In this paper, we propose several designs of enhanced\ndecoders and introduce BPDec (BERT Pretraining Decoder), a novel method for\nmodeling training. Typically, a pretrained BERT model is fine-tuned for\nspecific Natural Language Understanding (NLU) tasks. In our approach, we\nutilize the original BERT model as the encoder, making only changes to the\ndecoder without altering the encoder. This approach does not necessitate\nextensive modifications to the encoder architecture and can be seamlessly\nintegrated into existing fine-tuning pipelines and services, offering an\nefficient and effective enhancement strategy. Compared to other methods, while\nwe also incur a moderate training cost for the decoder during the pretraining\nprocess, our approach does not introduce additional training costs during the\nfine-tuning phase. We test multiple enhanced decoder structures after\npretraining and evaluate their performance on the GLUE tasks and SQuAD tasks.\nOur results demonstrate that BPDec, having only undergone subtle refinements to\nthe model structure during pretraining, significantly enhances model\nperformance without escalating the finetuning cost, inference time and serving\nbudget.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.15861v4",
    "published_date": "2024-01-29 03:25:11 UTC",
    "updated_date": "2024-12-09 23:47:46 UTC"
  },
  {
    "arxiv_id": "2401.15859v1",
    "title": "Diffusion Facial Forgery Detection",
    "authors": [
      "Harry Cheng",
      "Yangyang Guo",
      "Tianyi Wang",
      "Liqiang Nie",
      "Mohan Kankanhalli"
    ],
    "abstract": "Detecting diffusion-generated images has recently grown into an emerging\nresearch area. Existing diffusion-based datasets predominantly focus on general\nimage generation. However, facial forgeries, which pose a more severe social\nrisk, have remained less explored thus far. To address this gap, this paper\nintroduces DiFF, a comprehensive dataset dedicated to face-focused\ndiffusion-generated images. DiFF comprises over 500,000 images that are\nsynthesized using thirteen distinct generation methods under four conditions.\nIn particular, this dataset leverages 30,000 carefully collected textual and\nvisual prompts, ensuring the synthesis of images with both high fidelity and\nsemantic consistency. We conduct extensive experiments on the DiFF dataset via\na human test and several representative forgery detection methods. The results\ndemonstrate that the binary detection accuracy of both human observers and\nautomated detectors often falls below 30%, shedding light on the challenges in\ndetecting diffusion-generated facial forgeries. Furthermore, we propose an edge\ngraph regularization approach to effectively enhance the generalization\ncapability of existing detectors.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "The dataset will be released at\n  \\url{https://github.com/xaCheng1996/DiFF}",
    "pdf_url": "http://arxiv.org/pdf/2401.15859v1",
    "published_date": "2024-01-29 03:20:19 UTC",
    "updated_date": "2024-01-29 03:20:19 UTC"
  },
  {
    "arxiv_id": "2401.15856v2",
    "title": "The Indoor-Training Effect: unexpected gains from distribution shifts in the transition function",
    "authors": [
      "Serena Bono",
      "Spandan Madan",
      "Ishaan Grover",
      "Mao Yasueda",
      "Cynthia Breazeal",
      "Hanspeter Pfister",
      "Gabriel Kreiman"
    ],
    "abstract": "Is it better to perform tennis training in a pristine indoor environment or a\nnoisy outdoor one? To model this problem, here we investigate whether shifts in\nthe transition probabilities between the training and testing environments in\nreinforcement learning problems can lead to better performance under certain\nconditions. We generate new Markov Decision Processes (MDPs) starting from a\ngiven MDP, by adding quantifiable, parametric noise into the transition\nfunction. We refer to this process as Noise Injection and the resulting\nenvironments as {\\delta}-environments. This process allows us to create\nvariations of the same environment with quantitative control over noise serving\nas a metric of distance between environments. Conventional wisdom suggests that\ntraining and testing on the same MDP should yield the best results. In stark\ncontrast, we observe that agents can perform better when trained on the\nnoise-free environment and tested on the noisy {\\delta}-environments, compared\nto training and testing on the same {\\delta}-environments. We confirm that this\nfinding extends beyond noise variations: it is possible to showcase the same\nphenomenon in ATARI game variations including varying Ghost behaviour in\nPacMan, and Paddle behaviour in Pong. We demonstrate this intriguing behaviour\nacross 60 different variations of ATARI games, including PacMan, Pong, and\nBreakout. We refer to this phenomenon as the Indoor-Training Effect. Code to\nreproduce our experiments and to implement Noise Injection can be found at\nhttps://bit.ly/3X6CTYk.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.15856v2",
    "published_date": "2024-01-29 03:07:04 UTC",
    "updated_date": "2025-01-08 16:31:06 UTC"
  },
  {
    "arxiv_id": "2401.15847v3",
    "title": "Muffin or Chihuahua? Challenging Multimodal Large Language Models with Multipanel VQA",
    "authors": [
      "Yue Fan",
      "Jing Gu",
      "Kaiwen Zhou",
      "Qianqi Yan",
      "Shan Jiang",
      "Ching-Chen Kuo",
      "Xinze Guan",
      "Xin Eric Wang"
    ],
    "abstract": "Multipanel images, commonly seen as web screenshots, posters, etc., pervade\nour daily lives. These images, characterized by their composition of multiple\nsubfigures in distinct layouts, effectively convey information to people.\nToward building advanced multimodal AI applications, such as agents that\nunderstand complex scenes and navigate through webpages, the skill of\nmultipanel visual reasoning is essential, and a comprehensive evaluation of\nmodels in this regard is important. Therefore, we introduce Multipanel Visual\nQuestion Answering (MultipanelVQA), a novel benchmark comprising 6,600 triplets\nof questions, answers, and multipanel images that specifically challenge models\nin comprehending multipanel images. Our evaluation shows that questions in the\nMultipanelVQA benchmark pose significant challenges to the state-of-the-art\nMultimodal Large Language Models (MLLMs) tested, even though humans can attain\napproximately 99% accuracy on these questions. Distinctively, the MultipanelVQA\nbenchmark features synthetically generated multipanel images specifically\ncrafted to isolate and assess the impact of various factors, such as the\nlayout, on MLLMs' multipanel image comprehension abilities. As a result, in\naddition to benchmarking the capabilities of MLLMs in understanding multipanel\nimages, we analyze various factors of the multipanel image that affect MLLMs'\nperformance with synthetic data and offer insights for enhancement. Code and\ndata are released at https://sites.google.com/view/multipanelvqa/home.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.15847v3",
    "published_date": "2024-01-29 02:43:40 UTC",
    "updated_date": "2024-06-27 15:38:17 UTC"
  },
  {
    "arxiv_id": "2401.15842v2",
    "title": "LCV2: An Efficient Pretraining-Free Framework for Grounded Visual Question Answering",
    "authors": [
      "Yuhan Chen",
      "Lumei Su",
      "Lihua Chen",
      "Zhiwei Lin"
    ],
    "abstract": "In this paper, the LCV2 modular method is proposed for the Grounded Visual\nQuestion Answering task in the vision-language multimodal domain. This approach\nrelies on a frozen large language model (LLM) as intermediate mediator between\nthe off-the-shelf VQA model and the off-the-shelf visual grounding (VG) model,\nwhere the LLM transforms and conveys textual information between the two\nmodules based on a designed prompt. LCV2 establish an integrated plug-and-play\nframework without the need for any pre-training process. This framework can be\ndeployed for VQA Grounding tasks under low computational resources. The\nmodularized model within the framework allows application with various\nstate-of-the-art pre-trained models, exhibiting significant potential to be\nadvance with the times. Experimental implementations were conducted under\nconstrained computational and memory resources, evaluating the proposed\nmethod's performance on benchmark datasets including GQA, CLEVR, and\nVizWiz-VQA-Grounding. Comparative analyses with baseline methods demonstrate\nthe robust competitiveness of LCV2.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "21 pages,9 figures",
    "pdf_url": "http://arxiv.org/pdf/2401.15842v2",
    "published_date": "2024-01-29 02:32:25 UTC",
    "updated_date": "2024-03-23 02:46:54 UTC"
  },
  {
    "arxiv_id": "2401.15834v1",
    "title": "Few and Fewer: Learning Better from Few Examples Using Fewer Base Classes",
    "authors": [
      "Raphael Lafargue",
      "Yassir Bendou",
      "Bastien Pasdeloup",
      "Jean-Philippe Diguet",
      "Ian Reid",
      "Vincent Gripon",
      "Jack Valmadre"
    ],
    "abstract": "When training data is scarce, it is common to make use of a feature extractor\nthat has been pre-trained on a large base dataset, either by fine-tuning its\nparameters on the ``target'' dataset or by directly adopting its representation\nas features for a simple classifier. Fine-tuning is ineffective for few-shot\nlearning, since the target dataset contains only a handful of examples.\nHowever, directly adopting the features without fine-tuning relies on the base\nand target distributions being similar enough that these features achieve\nseparability and generalization. This paper investigates whether better\nfeatures for the target dataset can be obtained by training on fewer base\nclasses, seeking to identify a more useful base dataset for a given task.We\nconsider cross-domain few-shot image classification in eight different domains\nfrom Meta-Dataset and entertain multiple real-world settings (domain-informed,\ntask-informed and uninformed) where progressively less detail is known about\nthe target task. To our knowledge, this is the first demonstration that\nfine-tuning on a subset of carefully selected base classes can significantly\nimprove few-shot learning. Our contributions are simple and intuitive methods\nthat can be implemented in any few-shot solution. We also give insights into\nthe conditions in which these solutions are likely to provide a boost in\naccuracy. We release the code to reproduce all experiments from this paper on\nGitHub. https://github.com/RafLaf/Few-and-Fewer.git",
    "categories": [
      "cs.CV",
      "cs.AI",
      "68T",
      "I.2; I.4; I.5"
    ],
    "primary_category": "cs.CV",
    "comment": "9.5 pages + bibliography and supplementary material",
    "pdf_url": "http://arxiv.org/pdf/2401.15834v1",
    "published_date": "2024-01-29 01:52:49 UTC",
    "updated_date": "2024-01-29 01:52:49 UTC"
  },
  {
    "arxiv_id": "2402.03358v4",
    "title": "A Comprehensive Survey on Graph Reduction: Sparsification, Coarsening, and Condensation",
    "authors": [
      "Mohammad Hashemi",
      "Shengbo Gong",
      "Juntong Ni",
      "Wenqi Fan",
      "B. Aditya Prakash",
      "Wei Jin"
    ],
    "abstract": "Many real-world datasets can be naturally represented as graphs, spanning a\nwide range of domains. However, the increasing complexity and size of graph\ndatasets present significant challenges for analysis and computation. In\nresponse, graph reduction, or graph summarization, has gained prominence for\nsimplifying large graphs while preserving essential properties. In this survey,\nwe aim to provide a comprehensive understanding of graph reduction methods,\nincluding graph sparsification, graph coarsening, and graph condensation.\nSpecifically, we establish a unified definition for these methods and introduce\na hierarchical taxonomy to categorize the challenges they address. Our survey\nthen systematically reviews the technical details of these methods and\nemphasizes their practical applications across diverse scenarios. Furthermore,\nwe outline critical research directions to ensure the continued effectiveness\nof graph reduction techniques, as well as provide a comprehensive paper list at\n\\url{https://github.com/Emory-Melody/awesome-graph-reduction}. We hope this\nsurvey will bridge literature gaps and propel the advancement of this promising\nfield.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.DS",
      "cs.LG"
    ],
    "primary_category": "cs.SI",
    "comment": "Accepted by IJCAI 2024 (This ArXiv version is a long version of our\n  IJCAI paper)",
    "pdf_url": "http://arxiv.org/pdf/2402.03358v4",
    "published_date": "2024-01-29 01:19:09 UTC",
    "updated_date": "2024-06-29 13:07:00 UTC"
  },
  {
    "arxiv_id": "2401.15820v1",
    "title": "Knowledge-Aware Neuron Interpretation for Scene Classification",
    "authors": [
      "Yong Guan",
      "Freddy Lecue",
      "Jiaoyan Chen",
      "Ru Li",
      "Jeff Z. Pan"
    ],
    "abstract": "Although neural models have achieved remarkable performance, they still\nencounter doubts due to the intransparency. To this end, model prediction\nexplanation is attracting more and more attentions. However, current methods\nrarely incorporate external knowledge and still suffer from three limitations:\n(1) Neglecting concept completeness. Merely selecting concepts may not\nsufficient for prediction. (2) Lacking concept fusion. Failure to merge\nsemantically-equivalent concepts. (3) Difficult in manipulating model behavior.\nLack of verification for explanation on original model. To address these\nissues, we propose a novel knowledge-aware neuron interpretation framework to\nexplain model predictions for image scene classification. Specifically, for\nconcept completeness, we present core concepts of a scene based on knowledge\ngraph, ConceptNet, to gauge the completeness of concepts. Our method,\nincorporating complete concepts, effectively provides better prediction\nexplanations compared to baselines. Furthermore, for concept fusion, we\nintroduce a knowledge graph-based method known as Concept Filtering, which\nproduces over 23% point gain on neuron behaviors for neuron interpretation. At\nlast, we propose Model Manipulation, which aims to study whether the core\nconcepts based on ConceptNet could be employed to manipulate model behavior.\nThe results show that core concepts can effectively improve the performance of\noriginal model by over 26%.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to AAAI2024",
    "pdf_url": "http://arxiv.org/pdf/2401.15820v1",
    "published_date": "2024-01-29 01:00:17 UTC",
    "updated_date": "2024-01-29 01:00:17 UTC"
  },
  {
    "arxiv_id": "2401.15810v1",
    "title": "Green Runner: A tool for efficient deep learning component selection",
    "authors": [
      "Jai Kannan"
    ],
    "abstract": "For software that relies on machine-learned functionality, model selection is\nkey to finding the right model for the task with desired performance\ncharacteristics. Evaluating a model requires developers to i) select from many\nmodels (e.g. the Hugging face model repository), ii) select evaluation metrics\nand training strategy, and iii) tailor trade-offs based on the problem domain.\nHowever, current evaluation approaches are either ad-hoc resulting in\nsub-optimal model selection or brute force leading to wasted compute. In this\nwork, we present \\toolname, a novel tool to automatically select and evaluate\nmodels based on the application scenario provided in natural language. We\nleverage the reasoning capabilities of large language models to propose a\ntraining strategy and extract desired trade-offs from a problem description.\n\\toolname~features a resource-efficient experimentation engine that integrates\nconstraints and trade-offs based on the problem into the model selection\nprocess. Our preliminary evaluation demonstrates that \\toolname{} is both\nefficient and accurate compared to ad-hoc evaluations and brute force. This\nwork presents an important step toward energy-efficient tools to help reduce\nthe environmental impact caused by the growing demand for software with\nmachine-learned functionality.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.15810v1",
    "published_date": "2024-01-29 00:15:50 UTC",
    "updated_date": "2024-01-29 00:15:50 UTC"
  }
]