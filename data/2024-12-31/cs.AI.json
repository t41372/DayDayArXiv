{
  "date": "2024-12-31",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-12-31 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 论文聚焦 AI 模型优化、多模态学习、医疗诊断和知识图谱等领域，重点探讨大型语言模型（LLMs）的鲁棒性、生成能力和应用潜力，令人印象深刻的文章包括 LLM 在医疗问答中的创新（如 LLM-MedQA）和自动驾驶场景生成（如 DreamDrive），以及知名学者如 Yongqun He 参与的传染病本体研究。\n\n下面，我挑选并简要讨论几篇重要、话题性强的论文，先从 AI 和 LLMs 相关的高影响力文章入手，再快速触及医疗和应用领域的亮点，其他较常规或小众论文（如优化算法或特定领域实验）则一笔带过，以控制篇幅。\n\n**1. Grade Inflation in Generative Models（生成模型中的评分膨胀问题）**  \n这篇论文揭示了生成模型（如扩散模型）在评估合成数据质量时存在的“评分膨胀”问题，主要贡献是提出 equidensity 评分（如 Eden 分数）来避免传统 equipoint 分数的偏差，并证明它更符合人类感知。该发现对生成模型的鲁棒评估有重要启示，尤其在 AI 应用中提升可靠性。\n\n**7. LLM-MedQA: Enhancing Medical Question Answering through Case Studies in Large Language Models（LLM-MedQA：通过案例研究提升大型语言模型的医疗问答能力）**  \n作者 Hang Yang 等利用 Llama3.1 模型的多代理架构，提出一种零样本学习方法来改善医疗问答，核心是生成类似案例增强理解。论文发现该方法在 MedQA 数据集上提升 7% 的准确率和 F1 分数，具有实际医疗应用潜力，突显 LLMs 在复杂推理中的价值。\n\n**9. DreamDrive: Generative 4D Scene Modeling from Street View Images（DreamDrive：基于街景图像的生成式 4D 场景建模）**  \n该论文由 Marco Pavone 和 Yue Wang 等知名学者主导，引入视频扩散模型结合高斯表示，生成 3D 一致的自动驾驶视频。关键贡献是实现从街景图像到动态场景的通用合成，并提升感知和规划任务的性能，对自动驾驶领域有显著影响。\n\n**12. Are the Values of LLMs Structurally Aligned with Humans? A Causal Perspective（LLMs 的价值观是否与人类结构对齐？从因果视角分析）**  \n论文探索 LLMs 价值观的因果图结构，提出基于提示和稀疏自编码器的微调方法缓解偏差。主要发现是尽管对齐训练存在差异，LLMs 可通过因果图指导实现更人性化的决策，这对 AI 伦理和安全有深远启示。\n\n**14. Re-evaluating Automatic LLM System Ranking for Alignment with Human Preference（重新评估自动 LLM 系统排名以对齐人类偏好）**  \n作者如 Jonathan Bragg 参与，分析 LLM 评估框架的组件（如输入集和聚合方法），推荐优化策略以提升排名准确性。论文强调实例级性能不等同于系统级效果，对 LLM 基准测试和部署有实际指导意义。\n\n**40. Low-Rank Adaptation for Foundation Models: A Comprehensive Review（基础模型的低秩适应：全面综述）**  \n这篇综述覆盖低秩适应（LoRA）在基础模型（如 LLMs）的应用，讨论其在参数高效微调中的优势。核心发现是 LoRA 提升了模型的可迁移性和效率，是 AI 研究者优化大型模型的实用工具。\n\n**4. Efficient Standardization of Clinical Notes using Large Language Models（使用大型语言模型高效标准化临床笔记）**  \n论文提出 LLM 方法处理临床笔记的语法错误和缩写，平均每篇笔记修正 4.9 个语法问题和 15.8 个缩写。主要贡献是提升笔记的可读性和互操作性（如 FHIR 格式），对医疗数据处理有直接应用价值。\n\n**27. Pan-infection Foundation Framework Enables Multiple Pathogen Prediction（泛感染基础框架实现多病原预测）**  \n作者包括 Yongqun He，这篇论文构建大型转录组数据集，开发知识蒸馏模型预测多种病原（如细菌和病毒）。关键发现是模型在无监督数据上实现高准确率（AUC=0.99），为传染病诊断提供新框架。\n\n其他论文，如农业检测、模糊模型或编程语言效率等，较常规或领域特定，我仅快速提及：例如，\"Leaf diseases detection using deep learning methods\"（叶病检测使用深度学习方法）利用 CNN 提升作物病害检测准确性；\"PyMilo\"（Python 库用于 ML I/O）提供安全模型序列化工具。这些虽有实用性，但影响力有限，故不展开讨论。\n\n总之，今天的论文突显 AI 模型在实际应用中的潜力，尤其 LLMs 的优化和医疗整合，值得关注相关领域的从业者。更多细节可查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2501.00669v1",
      "title": "Leaf diseases detection using deep learning methods",
      "title_zh": "使用深度学习方法的叶片疾病检测",
      "authors": [
        "El Houcine El Fatimi"
      ],
      "abstract": "This study, our main topic is to devlop a new deep-learning approachs for\nplant leaf disease identification and detection using leaf image datasets. We\nalso discussed the challenges facing current methods of leaf disease detection\nand how deep learning may be used to overcome these challenges and enhance the\naccuracy of disease detection. Therefore, we have proposed a novel method for\nthe detection of various leaf diseases in crops, along with the identification\nand description of an efficient network architecture that encompasses\nhyperparameters and optimization methods. The effectiveness of different\narchitectures was compared and evaluated to see the best architecture\nconfiguration and to create an effective model that can quickly detect leaf\ndisease. In addition to the work done on pre-trained models, we proposed a new\nmodel based on CNN, which provides an efficient method for identifying and\ndetecting plant leaf disease. Furthermore, we evaluated the efficacy of our\nmodel and compared the results to those of some pre-trained state-of-the-art\narchitectures.",
      "tldr_zh": "本文提出了一种新的深度学习方法，用于基于叶图像数据集识别和检测植物叶病害，并讨论了当前方法的挑战及其如何通过深度学习得到克服，以提升检测准确性。该方法包括一个基于 CNN 的高效网络架构，涵盖超参数和优化策略，并通过比较不同架构来确定最佳配置。实验结果显示，该新模型在叶病害检测性能上优于现有预训练的先进架构。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "252 pages , 42 images",
      "pdf_url": "http://arxiv.org/pdf/2501.00669v1",
      "published_date": "2024-12-31 22:56:19 UTC",
      "updated_date": "2024-12-31 22:56:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:01:07.185843"
    },
    {
      "arxiv_id": "2501.00664v3",
      "title": "Grade Inflation in Generative Models",
      "title_zh": "生成模型中的分数膨胀",
      "authors": [
        "Phuc Nguyen",
        "Miao Li",
        "Alexandra Morgan",
        "Rima Arnaout",
        "Ramy Arnaout"
      ],
      "abstract": "Generative models hold great potential, but only if one can trust the\nevaluation of the data they generate. We show that many commonly used quality\nscores for comparing two-dimensional distributions of synthetic vs.\nground-truth data give better results than they should, a phenomenon we call\nthe \"grade inflation problem.\" We show that the correlation score, Jaccard\nscore, earth-mover's score, and Kullback-Leibler (relative-entropy) score all\nsuffer grade inflation. We propose that any score that values all datapoints\nequally, as these do, will also exhibit grade inflation; we refer to such\nscores as \"equipoint\" scores. We introduce the concept of \"equidensity\" scores,\nand present the Eden score, to our knowledge the first example of such a score.\nWe found that Eden avoids grade inflation and agrees better with human\nperception of goodness-of-fit than the equipoint scores above. We propose that\nany reasonable equidensity score will avoid grade inflation. We identify a\nconnection between equidensity scores and R\\'enyi entropy of negative order. We\nconclude that equidensity scores are likely to outperform equipoint scores for\ngenerative models, and for comparing low-dimensional distributions more\ngenerally.",
      "tldr_zh": "本研究揭示了生成模型（generative models）在评估合成数据质量时存在的grade inflation问题，即常用分数如correlation score、Jaccard score、earth-mover's score和Kullback-Leibler score等“equipoint” scores往往过度高估性能，因为它们平等对待所有数据点。作者提出“equidensity” scores的概念，并引入Eden score作为首个示例，该分数避免了grade inflation，并与人类对拟合度的感知更一致。实验结果显示，equidensity scores通过与Rényi entropy of negative order的关联，在生成模型和低维分布比较中可能优于equipoint scores，从而为更可靠的模型评估提供新路径。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 6 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2501.00664v3",
      "published_date": "2024-12-31 22:34:54 UTC",
      "updated_date": "2025-01-22 21:15:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:01:20.902860"
    },
    {
      "arxiv_id": "2501.00663v1",
      "title": "Titans: Learning to Memorize at Test Time",
      "title_zh": "翻译失败",
      "authors": [
        "Ali Behrouz",
        "Peilin Zhong",
        "Vahab Mirrokni"
      ],
      "abstract": "Over more than a decade there has been an extensive research effort on how to\neffectively utilize recurrent models and attention. While recurrent models aim\nto compress the data into a fixed-size memory (called hidden state), attention\nallows attending to the entire context window, capturing the direct\ndependencies of all tokens. This more accurate modeling of dependencies,\nhowever, comes with a quadratic cost, limiting the model to a fixed-length\ncontext. We present a new neural long-term memory module that learns to\nmemorize historical context and helps attention to attend to the current\ncontext while utilizing long past information. We show that this neural memory\nhas the advantage of fast parallelizable training while maintaining a fast\ninference. From a memory perspective, we argue that attention due to its\nlimited context but accurate dependency modeling performs as a short-term\nmemory, while neural memory due to its ability to memorize the data, acts as a\nlong-term, more persistent, memory. Based on these two modules, we introduce a\nnew family of architectures, called Titans, and present three variants to\naddress how one can effectively incorporate memory into this architecture. Our\nexperimental results on language modeling, common-sense reasoning, genomics,\nand time series tasks show that Titans are more effective than Transformers and\nrecent modern linear recurrent models. They further can effectively scale to\nlarger than 2M context window size with higher accuracy in needle-in-haystack\ntasks compared to baselines.",
      "tldr_zh": "该论文提出了一种新的神经长期记忆模块，帮助注意力机制（attention）在测试时学习记忆历史上下文，同时关注当前信息，从而克服注意力机制的上下文长度限制和计算成本。论文将注意力视为短期记忆，而新模块则作为长期记忆，引入Titans架构家族及其三个变体，用于有效整合这些记忆组件。在语言建模、常识推理、基因组学和时间序列任务上，Titans比Transformer和现代线性循环模型表现出色，并能扩展到超过2M的上下文窗口大小，在针在干草堆（needle-in-haystack）任务中实现更高的准确率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00663v1",
      "published_date": "2024-12-31 22:32:03 UTC",
      "updated_date": "2024-12-31 22:32:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:02:51.681749"
    },
    {
      "arxiv_id": "2501.00644v1",
      "title": "Efficient Standardization of Clinical Notes using Large Language Models",
      "title_zh": "利用大型语言模型高效标准化临床笔记",
      "authors": [
        "Daniel B. Hier",
        "Michael D. Carrithers",
        "Thanh Son Do",
        "Tayo Obafemi-Ajayi"
      ],
      "abstract": "Clinician notes are a rich source of patient information but often contain\ninconsistencies due to varied writing styles, colloquialisms, abbreviations,\nmedical jargon, grammatical errors, and non-standard formatting. These\ninconsistencies hinder the extraction of meaningful data from electronic health\nrecords (EHRs), posing challenges for quality improvement, population health,\nprecision medicine, decision support, and research.\n  We present a large language model approach to standardizing a corpus of 1,618\nclinical notes. Standardization corrected an average of $4.9 +/- 1.8$\ngrammatical errors, $3.3 +/- 5.2$ spelling errors, converted $3.1 +/- 3.0$\nnon-standard terms to standard terminology, and expanded $15.8 +/- 9.1$\nabbreviations and acronyms per note. Additionally, notes were re-organized into\ncanonical sections with standardized headings. This process prepared notes for\nkey concept extraction, mapping to medical ontologies, and conversion to\ninteroperable data formats such as FHIR.\n  Expert review of randomly sampled notes found no significant data loss after\nstandardization. This proof-of-concept study demonstrates that standardization\nof clinical notes can improve their readability, consistency, and usability,\nwhile also facilitating their conversion into interoperable data formats.",
      "tldr_zh": "本研究针对临床笔记中的不一致问题（如写作风格多样、缩写、医学术语和语法错误），提出了一种使用 Large Language Models 的标准化方法，处理了 1,618 份笔记。标准化过程每份笔记平均修正了 4.9 ± 1.8 个语法错误、3.3 ± 5.2 个拼写错误、将 3.1 ± 3.0 个非标准术语转换为标准术语，并扩展了 15.8 ± 9.1 个缩写，同时重新组织笔记结构并添加标准标题。实验结果显示，此方法提高了笔记的可读性、一致性和可用性，且专家审查确认无显著数据丢失，为后续的关键概念提取、映射到 medical ontologies 和转换为 FHIR 等可互操作格式提供了基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "92",
        "J.3; I.2"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00644v1",
      "published_date": "2024-12-31 20:52:40 UTC",
      "updated_date": "2024-12-31 20:52:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:01:44.554695"
    },
    {
      "arxiv_id": "2501.00642v1",
      "title": "Enabling New HDLs with Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Mark Zakharov",
        "Farzaneh Rabiei Kashanaki",
        "Jose Renau"
      ],
      "abstract": "Large Language Models (LLMs) based agents are transforming the programming\nlanguage landscape by facilitating learning for beginners, enabling code\ngeneration, and optimizing documentation workflows. Hardware Description\nLanguages (HDLs), with their smaller user community, stand to benefit\nsignificantly from the application of LLMs as tools for learning new HDLs. This\npaper investigates the challenges and solutions of enabling LLMs for HDLs,\nparticularly for HDLs that LLMs have not been previously trained on. This work\nintroduces HDLAgent, an AI agent optimized for LLMs with limited knowledge of\nvarious HDLs. It significantly enhances off-the-shelf LLMs.",
      "tldr_zh": "本研究探讨了大型语言模型 (LLMs) 基于的代理如何提升硬件描述语言 (HDLs) 的学习、代码生成和文档优化，特别针对用户社区较小的 HDLs。论文分析了为 LLMs 启用新 HDLs 的挑战，包括模型对未训练语言的知识限制，并提出解决方案。核心贡献是引入 HDLAgent，这是一个针对 LLMs 知识有限的 HDLs 优化的 AI 代理，能够显著提升现成 LLMs 的性能。总体而言，该工作为扩展 LLMs 到更多专业领域提供了新路径。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.LG",
        "cs.PL"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00642v1",
      "published_date": "2024-12-31 20:37:20 UTC",
      "updated_date": "2024-12-31 20:37:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:01:55.021885"
    },
    {
      "arxiv_id": "2501.01994v1",
      "title": "Fuzzy Model Identification and Self Learning with Smooth Compositions",
      "title_zh": "翻译失败",
      "authors": [
        "Ebrahim Navid Sadjadi",
        "Jesus Garcia",
        "Jose M. Molina",
        "Akbar Hashemi Borzabadi",
        "Monireh Asadi Abchouyeh"
      ],
      "abstract": "This paper develops a smooth model identification and self-learning strategy\nfor dynamic systems taking into account possible parameter variations and\nuncertainties. We have tried to solve the problem such that the model follows\nthe changes and variations in the system on a continuous and smooth surface.\nRunning the model to adaptively gain the optimum values of the parameters on a\nsmooth surface would facilitate further improvements in the application of\nother derivative based optimization control algorithms such as MPC or robust\ncontrol algorithms to achieve a combined modeling-control scheme. Compared to\nthe earlier works on the smooth fuzzy modeling structures, we could reach a\ndesired trade-off between the model optimality and the computational load. The\nproposed method has been evaluated on a test problem as well as the non-linear\ndynamic of a chemical process.",
      "tldr_zh": "该论文提出了一种平滑模糊模型识别（Fuzzy Model Identification）和自学习策略，用于处理动态系统的参数变化和不确定性，通过在连续平滑表面上运行模型来适应系统变化。相比以往的平滑模糊建模结构，该方法在模型最优性和计算负载之间实现了理想权衡，便于与其他衍生优化控制算法如MPC（Model Predictive Control）或鲁棒控制算法结合。研究通过测试问题和化学过程的非线性动态进行了评估，验证了策略的有效性。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.01994v1",
      "published_date": "2024-12-31 20:19:02 UTC",
      "updated_date": "2024-12-31 20:19:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:03:04.033917"
    },
    {
      "arxiv_id": "2501.05464v2",
      "title": "LLM-MedQA: Enhancing Medical Question Answering through Case Studies in Large Language Models",
      "title_zh": "LLM-MedQA：通过在大语言模型中进行案例研究增强医疗问答系统",
      "authors": [
        "Hang Yang",
        "Hao Chen",
        "Hui Guo",
        "Yineng Chen",
        "Ching-Sheng Lin",
        "Shu Hu",
        "Jinrong Hu",
        "Xi Wu",
        "Xin Wang"
      ],
      "abstract": "Accurate and efficient question-answering systems are essential for\ndelivering high-quality patient care in the medical field. While Large Language\nModels (LLMs) have made remarkable strides across various domains, they\ncontinue to face significant challenges in medical question answering,\nparticularly in understanding domain-specific terminologies and performing\ncomplex reasoning. These limitations undermine their effectiveness in critical\nmedical applications. To address these issues, we propose a novel approach\nincorporating similar case generation within a multi-agent medical\nquestion-answering (MedQA) system. Specifically, we leverage the Llama3.1:70B\nmodel, a state-of-the-art LLM, in a multi-agent architecture to enhance\nperformance on the MedQA dataset using zero-shot learning. Our method\ncapitalizes on the model's inherent medical knowledge and reasoning\ncapabilities, eliminating the need for additional training data. Experimental\nresults show substantial performance gains over existing benchmark models, with\nimprovements of 7% in both accuracy and F1-score across various medical QA\ntasks. Furthermore, we examine the model's interpretability and reliability in\naddressing complex medical queries. This research not only offers a robust\nsolution for medical question answering but also establishes a foundation for\nbroader applications of LLMs in the medical domain.",
      "tldr_zh": "本研究针对 Large Language Models (LLMs) 在医疗问答中的挑战，如理解领域术语和复杂推理，提出了一种新型多智能体系统 LLM-MedQA，通过生成类似案例来增强性能。\n该系统利用 Llama3.1:70B 模型进行零样本学习，无需额外训练数据，即可提升问答准确性。\n实验结果显示，在 MedQA 数据集上，准确性和 F1 分数均提高了 7%，并改善了模型的可解释性和可靠性。\n这项工作为 LLMs 在医疗领域的更广泛应用提供了稳健基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.05464v2",
      "published_date": "2024-12-31 19:55:45 UTC",
      "updated_date": "2025-01-18 05:53:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:02:20.423407"
    },
    {
      "arxiv_id": "2501.00619v1",
      "title": "A Study on Context Length and Efficient Transformers for Biomedical Image Analysis",
      "title_zh": "生物医学图像分析中上下文长度与高效Transformer的研究",
      "authors": [
        "Sarah M. Hooper",
        "Hui Xue"
      ],
      "abstract": "Biomedical imaging modalities often produce high-resolution,\nmulti-dimensional images that pose computational challenges for deep neural\nnetworks. These computational challenges are compounded when training\ntransformers due to the self-attention operator, which scales quadratically\nwith context length. Recent developments in long-context models have potential\nto alleviate these difficulties and enable more efficient application of\ntransformers to large biomedical images, although a systematic evaluation on\nthis topic is lacking. In this study, we investigate the impact of context\nlength on biomedical image analysis and we evaluate the performance of recently\nproposed long-context models. We first curate a suite of biomedical imaging\ndatasets, including 2D and 3D data for segmentation, denoising, and\nclassification tasks. We then analyze the impact of context length on network\nperformance using the Vision Transformer and Swin Transformer by varying patch\nsize and attention window size. Our findings reveal a strong relationship\nbetween context length and performance, particularly for pixel-level prediction\ntasks. Finally, we show that recent long-context models demonstrate significant\nimprovements in efficiency while maintaining comparable performance, though we\nhighlight where gaps remain. This work underscores the potential and challenges\nof using long-context models in biomedical imaging.",
      "tldr_zh": "这篇论文研究了上下文长度（context length）对生物医学图像分析的影响，并评估了高效 Transformer 模型的性能，以应对高分辨率图像的计算挑战。作者整理了包括2D和3D数据的生物医学图像数据集，用于分割、去噪和分类任务，并通过调整 Vision Transformer 和 Swin Transformer 的 patch size 和 attention window size 分析了上下文长度与网络性能的关系。结果显示，上下文长度与性能有强烈关联，尤其在像素级预测任务中，而最近的长上下文模型显著提高了效率，同时保持了可比性能，但仍存在一些改进空间。该研究强调了长上下文模型在生物医学成像中的潜力和挑战。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Published at ML4H 2024",
      "pdf_url": "http://arxiv.org/pdf/2501.00619v1",
      "published_date": "2024-12-31 19:38:38 UTC",
      "updated_date": "2024-12-31 19:38:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:02:33.127822"
    },
    {
      "arxiv_id": "2501.00601v2",
      "title": "DreamDrive: Generative 4D Scene Modeling from Street View Images",
      "title_zh": "DreamDrive: 基于街景图像的生成式4D场景建模",
      "authors": [
        "Jiageng Mao",
        "Boyi Li",
        "Boris Ivanovic",
        "Yuxiao Chen",
        "Yan Wang",
        "Yurong You",
        "Chaowei Xiao",
        "Danfei Xu",
        "Marco Pavone",
        "Yue Wang"
      ],
      "abstract": "Synthesizing photo-realistic visual observations from an ego vehicle's\ndriving trajectory is a critical step towards scalable training of self-driving\nmodels. Reconstruction-based methods create 3D scenes from driving logs and\nsynthesize geometry-consistent driving videos through neural rendering, but\ntheir dependence on costly object annotations limits their ability to\ngeneralize to in-the-wild driving scenarios. On the other hand, generative\nmodels can synthesize action-conditioned driving videos in a more generalizable\nway but often struggle with maintaining 3D visual consistency. In this paper,\nwe present DreamDrive, a 4D spatial-temporal scene generation approach that\ncombines the merits of generation and reconstruction, to synthesize\ngeneralizable 4D driving scenes and dynamic driving videos with 3D consistency.\nSpecifically, we leverage the generative power of video diffusion models to\nsynthesize a sequence of visual references and further elevate them to 4D with\na novel hybrid Gaussian representation. Given a driving trajectory, we then\nrender 3D-consistent driving videos via Gaussian splatting. The use of\ngenerative priors allows our method to produce high-quality 4D scenes from\nin-the-wild driving data, while neural rendering ensures 3D-consistent video\ngeneration from the 4D scenes. Extensive experiments on nuScenes and street\nview images demonstrate that DreamDrive can generate controllable and\ngeneralizable 4D driving scenes, synthesize novel views of driving videos with\nhigh fidelity and 3D consistency, decompose static and dynamic elements in a\nself-supervised manner, and enhance perception and planning tasks for\nautonomous driving.",
      "tldr_zh": "本文提出 DreamDrive，一种从街景图像生成 4D 场景建模的方法，旨在合成 photo-realistic 驾驶视频以支持自动驾驶模型的扩展训练。DreamDrive 结合视频 diffusion models 生成视觉序列，并通过 hybrid Gaussian representation 提升至 4D 场景，随后利用 Gaussian splatting 渲染出 3D 一致的动态视频。实验在 nuScenes 和街景图像数据集上表明，该方法能生成可控的 4D 场景、高保真度的视频，并自监督方式分解静态和动态元素，从而提升自动驾驶的感知和规划任务。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://pointscoder.github.io/DreamDrive/",
      "pdf_url": "http://arxiv.org/pdf/2501.00601v2",
      "published_date": "2024-12-31 18:59:57 UTC",
      "updated_date": "2025-01-03 20:06:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:02:43.964916"
    },
    {
      "arxiv_id": "2501.00599v3",
      "title": "VideoRefer Suite: Advancing Spatial-Temporal Object Understanding with Video LLM",
      "title_zh": "翻译失败",
      "authors": [
        "Yuqian Yuan",
        "Hang Zhang",
        "Wentong Li",
        "Zesen Cheng",
        "Boqiang Zhang",
        "Long Li",
        "Xin Li",
        "Deli Zhao",
        "Wenqiao Zhang",
        "Yueting Zhuang",
        "Jianke Zhu",
        "Lidong Bing"
      ],
      "abstract": "Video Large Language Models (Video LLMs) have recently exhibited remarkable\ncapabilities in general video understanding. However, they mainly focus on\nholistic comprehension and struggle with capturing fine-grained spatial and\ntemporal details. Besides, the lack of high-quality object-level video\ninstruction data and a comprehensive benchmark further hinders their\nadvancements. To tackle these challenges, we introduce the VideoRefer Suite to\nempower Video LLM for finer-level spatial-temporal video understanding, i.e.,\nenabling perception and reasoning on any objects throughout the video.\nSpecially, we thoroughly develop VideoRefer Suite across three essential\naspects: dataset, model, and benchmark. Firstly, we introduce a multi-agent\ndata engine to meticulously curate a large-scale, high-quality object-level\nvideo instruction dataset, termed VideoRefer-700K. Next, we present the\nVideoRefer model, which equips a versatile spatial-temporal object encoder to\ncapture precise regional and sequential representations. Finally, we\nmeticulously create a VideoRefer-Bench to comprehensively assess the\nspatial-temporal understanding capability of a Video LLM, evaluating it across\nvarious aspects. Extensive experiments and analyses demonstrate that our\nVideoRefer model not only achieves promising performance on video referring\nbenchmarks but also facilitates general video understanding capabilities.",
      "tldr_zh": "该研究指出，Video LLMs 在整体视频理解方面表现出色，但存在捕捉细粒度空间-时间细节的不足，以及缺乏高质量对象级视频指令数据和全面基准的问题。为此，研究团队引入了 VideoRefer Suite，包括一个大规模高质量数据集 VideoRefer-700K（使用多智能体数据引擎构建）、一个配备多功能空间-时间对象编码器的 VideoRefer 模型，以及一个全面评估框架 VideoRefer-Bench。实验结果显示，VideoRefer 模型在视频引用基准上取得了显著性能提升，并增强了整体视频理解能力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "17 pages, 14 figures, technical report",
      "pdf_url": "http://arxiv.org/pdf/2501.00599v3",
      "published_date": "2024-12-31 18:56:46 UTC",
      "updated_date": "2025-03-25 08:10:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:02:55.758858"
    },
    {
      "arxiv_id": "2501.00595v1",
      "title": "Unbiased GNN Learning via Fairness-Aware Subgraph Diffusion",
      "title_zh": "基于公平感知子图扩散的无偏 GNN 学习",
      "authors": [
        "Abdullah Alchihabi",
        "Yuhong Guo"
      ],
      "abstract": "Graph Neural Networks (GNNs) have demonstrated remarkable efficacy in\ntackling a wide array of graph-related tasks across diverse domains. However, a\nsignificant challenge lies in their propensity to generate biased predictions,\nparticularly with respect to sensitive node attributes such as age and gender.\nThese biases, inherent in many machine learning models, are amplified in GNNs\ndue to the message-passing mechanism, which allows nodes to influence each\nother, rendering the task of making fair predictions notably challenging. This\nissue is particularly pertinent in critical domains where model fairness holds\nparamount importance. In this paper, we propose a novel generative\nFairness-Aware Subgraph Diffusion (FASD) method for unbiased GNN learning. The\nmethod initiates by strategically sampling small subgraphs from the original\nlarge input graph, and then proceeds to conduct subgraph debiasing via\ngenerative fairness-aware graph diffusion processes based on stochastic\ndifferential equations (SDEs). To effectively diffuse unfairness in the input\ndata, we introduce additional adversary bias perturbations to the subgraphs\nduring the forward diffusion process, and train score-based models to predict\nthese applied perturbations, enabling them to learn the underlying dynamics of\nthe biases present in the data. Subsequently, the trained score-based models\nare utilized to further debias the original subgraph samples through the\nreverse diffusion process. Finally, FASD induces fair node predictions on the\ninput graph by performing standard GNN learning on the debiased subgraphs.\nExperimental results demonstrate the superior performance of the proposed\nmethod over state-of-the-art Fair GNN baselines across multiple benchmark\ndatasets.",
      "tldr_zh": "本论文针对图神经网络(GNNs)在处理敏感节点属性（如年龄和性别）时产生的偏见问题，提出了一种新型生成式Fairness-Aware Subgraph Diffusion (FASD)方法，以实现无偏GNN学习。该方法首先从原始图中采样子图，然后通过基于随机微分方程(SDEs)的公平感知图扩散过程添加对手偏置扰动，并训练基于分数的模型来预测并逆转这些扰动，从而对子图进行去偏置处理。最终，在去偏置子图上进行标准GNN学习，以生成公平的节点预测。实验结果显示，FASD在多个基准数据集上优于现有Fair GNN基线方法，显著提升了模型的公平性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00595v1",
      "published_date": "2024-12-31 18:48:30 UTC",
      "updated_date": "2024-12-31 18:48:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:03:15.917891"
    },
    {
      "arxiv_id": "2501.00581v2",
      "title": "Are the Values of LLMs Structurally Aligned with Humans? A Causal Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Yipeng Kang",
        "Junqi Wang",
        "Yexin Li",
        "Mengmeng Wang",
        "Wenming Tu",
        "Quansen Wang",
        "Hengli Li",
        "Tingjun Wu",
        "Xue Feng",
        "Fangwei Zhong",
        "Zilong Zheng"
      ],
      "abstract": "As large language models (LLMs) become increasingly integrated into critical\napplications, aligning their behavior with human values presents significant\nchallenges. Current methods, such as Reinforcement Learning from Human Feedback\n(RLHF), typically focus on a limited set of coarse-grained values and are\nresource-intensive. Moreover, the correlations between these values remain\nimplicit, leading to unclear explanations for value-steering outcomes. Our work\nargues that a latent causal value graph underlies the value dimensions of LLMs\nand that, despite alignment training, this structure remains significantly\ndifferent from human value systems. We leverage these causal value graphs to\nguide two lightweight value-steering methods: role-based prompting and sparse\nautoencoder (SAE) steering, effectively mitigating unexpected side effects.\nFurthermore, SAE provides a more fine-grained approach to value steering.\nExperiments on Gemma-2B-IT and Llama3-8B-IT demonstrate the effectiveness and\ncontrollability of our methods.",
      "tldr_zh": "本研究从因果视角探讨大型语言模型(LLMs)的价值观是否与人类结构对齐，发现尽管经过对齐训练，如Reinforcement Learning from Human Feedback (RLHF)，LLMs的潜在因果价值图(causal value graph)仍与人类价值系统存在显著差异，导致解释和控制挑战。作者提出两种轻量级价值引导方法：基于角色的提示(role-based prompting)和稀疏自动编码器(SAE)引导，利用因果价值图来减轻意外副作用，其中SAE提供更细粒度的控制。实验在Gemma-2B-IT和Llama3-8B-IT模型上验证了这些方法的有效性和可控性，展示了改进LLMs价值观对齐的可行性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00581v2",
      "published_date": "2024-12-31 18:12:05 UTC",
      "updated_date": "2025-02-23 16:33:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:03:27.710848"
    },
    {
      "arxiv_id": "2501.00562v2",
      "title": "An Overview and Discussion on Using Large Language Models for Implementation Generation of Solutions to Open-Ended Problems",
      "title_zh": "关于使用大语言模型生成开放性问题解决方案实现的概述与讨论",
      "authors": [
        "Hashmath Shaik",
        "Alex Doboli"
      ],
      "abstract": "Large Language Models offer new opportunities to devise automated\nimplementation generation methods that can tackle problem solving activities\nbeyond traditional methods, which require algorithmic specifications and can\nuse only static domain knowledge, like performance metrics and libraries of\nbasic building blocks. Large Language Models could support creating new methods\nto support problem solving activities for open-ended problems, like problem\nframing, exploring possible solving approaches, feature elaboration and\ncombination, more advanced implementation assessment, and handling unexpected\nsituations. This report summarized the current work on Large Language Models,\nincluding model prompting, Reinforcement Learning, and Retrieval-Augmented\nGeneration. Future research requirements were also discussed.",
      "tldr_zh": "这篇论文概述了使用大型语言模型（Large Language Models）生成开放性问题（open-ended problems）解决方案的潜力，强调 LLMs 能超越传统方法，通过动态支持问题框架、探索解决途径、特征阐述和组合、实施评估以及处理意外情况。论文总结了当前相关工作，包括模型提示（model prompting）、强化学习（Reinforcement Learning）和检索增强生成（Retrieval-Augmented Generation）。此外，它讨论了未来研究需求，以进一步提升 LLMs 在自动化问题解决中的应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00562v2",
      "published_date": "2024-12-31 17:48:33 UTC",
      "updated_date": "2025-01-03 06:28:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:05:32.409530"
    },
    {
      "arxiv_id": "2501.00560v2",
      "title": "Re-evaluating Automatic LLM System Ranking for Alignment with Human Preference",
      "title_zh": "重新评估自动 LLM 系统排名以实现与人类偏好的对齐",
      "authors": [
        "Mingqi Gao",
        "Yixin Liu",
        "Xinyu Hu",
        "Xiaojun Wan",
        "Jonathan Bragg",
        "Arman Cohan"
      ],
      "abstract": "Evaluating and ranking the capabilities of different LLMs is crucial for\nunderstanding their performance and alignment with human preferences. Due to\nthe high cost and time-consuming nature of human evaluations, an automatic LLM\nbencher (i.e., an automatic evaluation framework that aims to rank LLMs based\non their alignment with human preferences) is indispensable. An automatic LLM\nbencher consists of four components: the input set (e.g., a user instruction),\nthe evaluation model (e.g., an LLM), the evaluation type (e.g., pairwise\ncomparison), and the aggregation method (e.g., the ELO rating system). However,\nprevious work has not thoroughly explored how to select these components or how\ntheir different combinations influence the results. In this work, through\ncontrolled experiments, we provide a series of recommendations on how to choose\neach component to better automate the evaluation of LLMs. Furthermore, we\ndiscovered that when evaluating LLMs with similar performance, the performance\nof the automatic LLM bencher declines sharply, underscoring the limitations of\ncurrent benchers and calling for future work. Lastly, we found that the\nevaluation models' performance at the instance level (e.g., the accuracy of\nselecting the best output) does not always align with their effectiveness when\nused as a component of a bencher, highlighting the importance of dedicated\nsystem-level evaluation of benchers.",
      "tldr_zh": "这篇论文重新评估了自动LLM系统排名框架，以更好地与人类偏好对齐。作者通过控制实验探讨了自动LLM bencher的四个组件（输入集、评估模型、评估类型如配对比较，以及聚合方法如ELO rating system）的选择及其组合影响。研究发现，当评估性能相似的LLM时，bencher的性能急剧下降，并强调模型的实例级别性能（如选择最佳输出准确性）不一定与系统级别有效性一致，从而为未来优化自动评估框架提供了重要推荐。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Findings of NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.00560v2",
      "published_date": "2024-12-31 17:46:51 UTC",
      "updated_date": "2025-02-11 10:02:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:03:51.536051"
    },
    {
      "arxiv_id": "2501.00559v1",
      "title": "AraSTEM: A Native Arabic Multiple Choice Question Benchmark for Evaluating LLMs Knowledge In STEM Subjects",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmad Mustapha",
        "Hadi Al-Khansa",
        "Hadi Al-Mubasher",
        "Aya Mourad",
        "Ranam Hamoud",
        "Hasan El-Husseini",
        "Marwah Al-Sakkaf",
        "Mariette Awad"
      ],
      "abstract": "Large Language Models (LLMs) have shown remarkable capabilities, not only in\ngenerating human-like text, but also in acquiring knowledge. This highlights\nthe need to go beyond the typical Natural Language Processing downstream\nbenchmarks and asses the various aspects of LLMs including knowledge and\nreasoning. Numerous benchmarks have been developed to evaluate LLMs knowledge,\nbut they predominantly focus on the English language. Given that many LLMs are\nmultilingual, relying solely on benchmarking English knowledge is insufficient.\nTo address this issue, we introduce AraSTEM, a new Arabic multiple-choice\nquestion dataset aimed at evaluating LLMs knowledge in STEM subjects. The\ndataset spans a range of topics at different levels which requires models to\ndemonstrate a deep understanding of scientific Arabic in order to achieve high\naccuracy. Our findings show that publicly available models of varying sizes\nstruggle with this dataset, and underscores the need for more localized\nlanguage models. The dataset is freely accessible on Hugging Face.",
      "tldr_zh": "这篇论文引入了 AraSTEM，这是一个原生阿拉伯语多项选择题基准，用于评估大语言模型 (LLMs) 在 STEM 科目中的知识水平。数据集涵盖多种主题和难度级别，要求模型对科学阿拉伯语有深入理解，以实现高准确率。研究发现，现有的公开 LLMs 在 AraSTEM 上表现不佳，突显了开发更多本地化语言模型的必要性。该数据集已在 Hugging Face 上免费提供，旨在推动多语言知识评估的进步。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00559v1",
      "published_date": "2024-12-31 17:45:12 UTC",
      "updated_date": "2024-12-31 17:45:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:04:03.079898"
    },
    {
      "arxiv_id": "2501.00555v1",
      "title": "Monty Hall and Optimized Conformal Prediction to Improve Decision-Making with LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Harit Vishwakarma",
        "Alan Mishler",
        "Thomas Cook",
        "Niccolò Dalmasso",
        "Natraj Raman",
        "Sumitra Ganesh"
      ],
      "abstract": "Large language models (LLMs) are empowering decision-making in several\napplications, including tool or API usage and answering multiple-choice\nquestions (MCQs). However, they often make overconfident, incorrect\npredictions, which can be risky in high-stakes settings like healthcare and\nfinance. To mitigate these risks, recent works have used conformal prediction\n(CP), a model-agnostic framework for distribution-free uncertainty\nquantification. CP transforms a \\emph{score function} into prediction sets that\ncontain the true answer with high probability. While CP provides this coverage\nguarantee for arbitrary scores, the score quality significantly impacts\nprediction set sizes. Prior works have relied on LLM logits or other heuristic\nscores, lacking quality guarantees. We address this limitation by introducing\nCP-OPT, an optimization framework to learn scores that minimize set sizes while\nmaintaining coverage. Furthermore, inspired by the Monty Hall problem, we\nextend CP's utility beyond uncertainty quantification to improve accuracy. We\npropose \\emph{conformal revision of questions} (CROQ) to revise the problem by\nnarrowing down the available choices to those in the prediction set. The\ncoverage guarantee of CP ensures that the correct choice is in the revised\nquestion prompt with high probability, while the smaller number of choices\nincreases the LLM's chances of answering it correctly. Experiments on MMLU,\nToolAlpaca, and TruthfulQA datasets with Gemma-2, Llama-3 and Phi-3 models show\nthat CP-OPT significantly reduces set sizes while maintaining coverage, and\nCROQ improves accuracy over the standard inference, especially when paired with\nCP-OPT scores. Together, CP-OPT and CROQ offer a robust framework for improving\nboth the safety and accuracy of LLM-driven decision-making.",
      "tldr_zh": "该研究针对大型语言模型(LLMs)在决策应用中的过度自信错误问题，引入了优化框架CP-OPT，通过优化分数函数来最小化预测集大小，同时保持Conformal Prediction(CP)的覆盖率保证。受Monty Hall问题启发，论文提出Conformal Revision of Questions(CROQ)方法，通过缩小问题选择范围来提升LLMs的准确性，确保正确答案高概率包含在修订提示中。实验在MMLU、ToolAlpaca和TruthfulQA数据集上使用Gemma-2、Llama-3和Phi-3模型表明，CP-OPT显著减少了预测集大小，而CROQ进一步提高了准确性，提供了一个更安全可靠的LLMs决策框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.AP",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00555v1",
      "published_date": "2024-12-31 17:33:12 UTC",
      "updated_date": "2024-12-31 17:33:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:04:16.169651"
    },
    {
      "arxiv_id": "2501.05463v1",
      "title": "Proof Recommendation System for the HOL4 Theorem Prover",
      "title_zh": "翻译失败",
      "authors": [
        "Nour Dekhil",
        "Adnan Rashid",
        "Sofiene Tahar"
      ],
      "abstract": "We introduce a proof recommender system for the HOL4 theorem prover. Our tool\nis built upon a transformer-based model [2] designed specifically to provide\nproof assistance in HOL4. The model is trained to discern theorem proving\npatterns from extensive libraries of HOL4 containing proofs of theorems.\nConsequently, it can accurately predict the next tactic(s) (proof step(s))\nbased on the history of previously employed tactics. The tool operates by\nreading a given sequence of tactics already used in a proof process (in our\ncase, it contains at least three tactics), referred to as the current proof\nstate, and provides recommendations for the next optimal proof step(s).",
      "tldr_zh": "本研究提出了一种针对 HOL4 定理证明器的证明推荐系统，利用 Transformer-based 模型从 HOL4 的庞大证明库中学习定理证明模式。系统通过分析当前的 proof state（至少包含三个 tactics 的序列），准确预测下一个最佳证明步骤，从而辅助用户进行高效的定理证明。该工具有望提升定理证明过程的自动化和准确性，为形式化验证领域提供实用支持。",
      "categories": [
        "cs.LO",
        "cs.AI"
      ],
      "primary_category": "cs.LO",
      "comment": "Conference on Artificial Intelligence and Theorem Proving (AITP),\n  Aussois, France, 2024",
      "pdf_url": "http://arxiv.org/pdf/2501.05463v1",
      "published_date": "2024-12-31 17:13:59 UTC",
      "updated_date": "2024-12-31 17:13:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:04:27.204170"
    },
    {
      "arxiv_id": "2501.00539v2",
      "title": "MCP-Solver: Integrating Language Models with Constraint Programming Systems",
      "title_zh": "MCP-Solver：将",
      "authors": [
        "Stefan Szeider"
      ],
      "abstract": "The MCP Solver bridges Large Language Models (LLMs) with symbolic solvers\nthrough the Model Context Protocol (MCP), an open-source standard for AI system\nintegration. Providing LLMs access to formal solving and reasoning capabilities\naddresses their key deficiency while leveraging their strengths. Our\nimplementation offers interfaces for constraint programming (Minizinc),\npropositional satisfiability (PySAT), and SAT modulo Theories (Python Z3). The\nsystem employs an editing approach with iterated validation to ensure model\nconsistency during modifications and enable structured refinement.",
      "tldr_zh": "该论文提出MCP-Solver，通过Model Context Protocol (MCP)——一个开源标准，将Large Language Models (LLMs)与符号求解器集成，以弥补LLMs在形式求解和推理方面的不足，同时发挥其优势。系统提供接口支持约束编程(Minizinc)、命题可满足性(PySAT)和SAT modulo Theories(Python Z3)，允许LLMs访问这些工具。采用编辑方法和迭代验证，确保模型修改的一致性和结构化改进，从而提升AI系统的整体性能和可靠性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00539v2",
      "published_date": "2024-12-31 16:49:27 UTC",
      "updated_date": "2025-04-06 08:39:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:04:39.621862"
    },
    {
      "arxiv_id": "2501.00537v1",
      "title": "Extending XReason: Formal Explanations for Adversarial Detection",
      "title_zh": "扩展 XReason：对抗检测的形式化解释",
      "authors": [
        "Amira Jemaa",
        "Adnan Rashid",
        "Sofiene Tahar"
      ],
      "abstract": "Explainable Artificial Intelligence (XAI) plays an important role in\nimproving the transparency and reliability of complex machine learning models,\nespecially in critical domains such as cybersecurity. Despite the prevalence of\nheuristic interpretation methods such as SHAP and LIME, these techniques often\nlack formal guarantees and may produce inconsistent local explanations. To\nfulfill this need, few tools have emerged that use formal methods to provide\nformal explanations. Among these, XReason uses a SAT solver to generate formal\ninstance-level explanation for XGBoost models. In this paper, we extend the\nXReason tool to support LightGBM models as well as class-level explanations.\nAdditionally, we implement a mechanism to generate and detect adversarial\nexamples in XReason. We evaluate the efficiency and accuracy of our approach on\nthe CICIDS-2017 dataset, a widely used benchmark for detecting network attacks.",
      "tldr_zh": "该论文扩展了XReason工具，使用正式方法（如SAT求解器）为机器学习模型提供可靠的解释，旨在解决传统启发式方法如SHAP和LIME的不足，例如缺乏正式保证和解释不一致性。主要贡献包括支持LightGBM模型、添加类级解释功能，以及实现对抗样本(adversarial examples)的生成和检测机制。在CICIDS-2017数据集上的实验评估了该方法的效率和准确性，为XAI在网络安全等关键领域的应用提供了更可信的解决方案。",
      "categories": [
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "International Congress on Information and Communication Technology\n  (ICICT), Lecture Notes in Networks and Systems (LNNS), Springer, 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.00537v1",
      "published_date": "2024-12-31 16:45:03 UTC",
      "updated_date": "2024-12-31 16:45:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:04:50.455868"
    },
    {
      "arxiv_id": "2501.01463v1",
      "title": "Goal Recognition using Actor-Critic Optimization",
      "title_zh": "基于 Actor-Critic 优化的目标识别",
      "authors": [
        "Ben Nageris",
        "Felipe Meneguzzi",
        "Reuth Mirsky"
      ],
      "abstract": "Goal Recognition aims to infer an agent's goal from a sequence of\nobservations. Existing approaches often rely on manually engineered domains and\ndiscrete representations. Deep Recognition using Actor-Critic Optimization\n(DRACO) is a novel approach based on deep reinforcement learning that overcomes\nthese limitations by providing two key contributions. First, it is the first\ngoal recognition algorithm that learns a set of policy networks from\nunstructured data and uses them for inference. Second, DRACO introduces new\nmetrics for assessing goal hypotheses through continuous policy\nrepresentations. DRACO achieves state-of-the-art performance for goal\nrecognition in discrete settings while not using the structured inputs used by\nexisting approaches. Moreover, it outperforms these approaches in more\nchallenging, continuous settings at substantially reduced costs in both\ncomputing and memory. Together, these results showcase the robustness of the\nnew algorithm, bridging traditional goal recognition and deep reinforcement\nlearning.",
      "tldr_zh": "该论文提出了一种名为 DRACO 的新方法，用于 Goal Recognition，通过 Actor-Critic Optimization 基于深度强化学习，从观察序列中推断代理的目标。该方法的关键贡献包括：首次从非结构化数据学习一组 policy networks 用于推断，以及引入新的指标来评估目标假设，通过 continuous policy representations 实现更精确的评估。实验结果显示，DRACO 在离散设置中达到 state-of-the-art 性能，而在更具挑战性的连续设置中表现更优，且显著降低了计算和内存成本，从而桥接了传统 Goal Recognition 与深度强化学习。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.01463v1",
      "published_date": "2024-12-31 16:44:20 UTC",
      "updated_date": "2024-12-31 16:44:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:05:02.749008"
    },
    {
      "arxiv_id": "2501.00530v2",
      "title": "Superposition in Transformers: A Novel Way of Building Mixture of Experts",
      "title_zh": "翻译失败",
      "authors": [
        "Ayoub Ben Chaliah",
        "Hela Dellagi"
      ],
      "abstract": "Catastrophic forgetting remains a major challenge when adapting large\nlanguage models (LLMs) to new tasks or domains. Conventional fine-tuning often\noverwrites existing knowledge, causing performance degradation on original\ntasks. We introduce Superposition in Transformers, a novel architecture that\nleverages autoencoders to superimpose the hidden representations of a base\nmodel and a fine-tuned model within a shared parameter space. By using\nB-spline-based blending coefficients and autoencoders that adaptively\nreconstruct hidden states based on the input data distribution, our method\neffectively mitigates catastrophic forgetting and enables a new paradigm of\n\"in-model\" superposition. This approach preserves original model capabilities\nwhile allowing compact domain-specific expertise to be added, and it supports\ndynamic switching between model states during inference.",
      "tldr_zh": "该研究针对大型语言模型（LLMs）在适应新任务时面临的灾难性遗忘（Catastrophic forgetting）问题，提出了一种新型架构Superposition in Transformers，利用autoencoders在共享参数空间中叠加基模型和微调模型的隐藏表示。方法通过B-spline-based blending coefficients和自适应重构隐藏状态，根据输入数据分布动态调整模型行为，从而有效缓解遗忘问题。实验结果显示，这种“in-model”叠加范式能保留原模型能力，同时添加紧凑的领域特定专业知识，并支持推理时的动态切换。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00530v2",
      "published_date": "2024-12-31 16:28:23 UTC",
      "updated_date": "2025-01-06 23:02:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:06:59.703570"
    },
    {
      "arxiv_id": "2501.00528v1",
      "title": "PyMilo: A Python Library for ML I/O",
      "title_zh": "翻译失败",
      "authors": [
        "AmirHosein Rostami",
        "Sepand Haghighi",
        "Sadra Sabouri",
        "Alireza Zolanvari"
      ],
      "abstract": "PyMilo is an open-source Python package that addresses the limitations of\nexisting Machine Learning (ML) model storage formats by providing a\ntransparent, reliable, and safe method for exporting and deploying trained\nmodels. Current formats, such as pickle and other binary formats, have\nsignificant problems, such as reliability, safety, and transparency issues. In\ncontrast, PyMilo serializes ML models in a transparent non-executable format,\nenabling straightforward and safe model exchange, while also facilitating the\ndeserialization and deployment of exported models in production environments.\nThis package aims to provide a seamless, end-to-end solution for the\nexportation and importation of pre-trained ML models, which simplifies the\nmodel development and deployment pipeline.",
      "tldr_zh": "PyMilo是一个开源Python库，旨在解决现有Machine Learning (ML)模型存储格式（如pickle和其他二进制格式）的可靠性、安全性和透明性问题。通过采用透明的非可执行格式序列化模型，PyMilo提供了一种简单、安全的模型导出和部署方法。用户可以轻松实现模型交换、反序列化和生产环境部署，从而简化ML模型的开发和部署流程。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages, 5 figures, 2 tables, 3 code blocks",
      "pdf_url": "http://arxiv.org/pdf/2501.00528v1",
      "published_date": "2024-12-31 16:27:46 UTC",
      "updated_date": "2024-12-31 16:27:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:05:54.353831"
    },
    {
      "arxiv_id": "2501.00522v1",
      "title": "TinyHelen's First Curriculum: Training and Evaluating Tiny Language Models in a Simpler Language Environment",
      "title_zh": "TinyHelen 的第一课程：训练和评估小型语言模型于",
      "authors": [
        "Ke Yang",
        "Volodymyr Kindratenko",
        "ChengXiang Zhai"
      ],
      "abstract": "Training language models (LMs) and their application agents is increasingly\ncostly due to large datasets and models, making test failures difficult to\nbear. Simplified language environments serve as primordial training and testing\ngrounds, retaining essential commonsense and communication skills but in a more\ndigestible form, potentially enhancing the learning efficiency of LMs, and thus\nreducing the required model size and data volume for effective training and\nevaluation. In these simplified language environments, workable strategies for\nsmall models, datasets, and agents may be adaptable to larger models, datasets,\nand agents in complex language environments.\n  To create such environments, we focus on two aspects: i) minimizing language\ndataset noise and complexity, and ii) preserving the essential text\ndistribution characteristics. Unlike previous methods, we propose a pipeline to\nrefine text data by eliminating noise, minimizing vocabulary, and maintaining\ngenre-specific patterns (e.g., for books, conversation, code, etc.).\nImplementing this pipeline with large LMs, we have created a leaner suite of LM\ntraining and evaluation datasets: 71M Leaner-Pretrain, 7M Leaner-Instruct,\nLeaner-Glue for assessing linguistic proficiency, and Leaner-Eval for testing\ninstruction-following ability.\n  Our experiments show that leaner pre-training boosts LM learning efficiency.\nTiny LMs trained on these datasets outperform those trained on original\ndatasets in instruction-following across different language granularity levels.\nMoreover, the Leaner-Pretrain dataset's alignment with conventional large LM\ntraining sets enables resource-optimized analysis of how learning objectives,\nmodel architectures, and training techniques impact performance on language\nmodeling and downstream tasks. Our code and datasets are available at\nhttps://github.com/EmpathYang/TinyHelen.git.",
      "tldr_zh": "本文提出一种简化语言环境（TinyHelen's First Curriculum），旨在降低语言模型（LMs）训练成本，通过精炼文本数据（如消除噪声、减少词汇量并保持类型模式）创建了新的数据集，包括71M Leaner-Pretrain、7M Leaner-Instruct、Leaner-Glue和Leaner-Eval，用于训练和评估小型语言模型（Tiny LMs）。实验显示，在这些简化数据集上训练的Tiny LMs在指令遵循任务中比原始数据集表现更好，提升了学习效率。总之，该方法允许资源优化分析学习目标、模型架构和训练技术对性能的影响，并提供了开源代码和数据集以供进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00522v1",
      "published_date": "2024-12-31 16:08:15 UTC",
      "updated_date": "2024-12-31 16:08:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:06:08.292182"
    },
    {
      "arxiv_id": "2501.00517v1",
      "title": "A Method for Enhancing the Safety of Large Model Generation Based on Multi-dimensional Attack and Defense",
      "title_zh": "翻译失败",
      "authors": [
        "Keke Zhai"
      ],
      "abstract": "Currently, large models are prone to generating harmful content when faced\nwith complex attack instructions, significantly reducing their defensive\ncapabilities. To address this issue, this paper proposes a method based on\nconstructing data aligned with multi-dimensional attack defense to enhance the\ngenerative security of large models. The core of our method lies in improving\nthe effectiveness of safe alignment learning for large models by innova-tively\nincreasing the diversity of attack instruction dimensions and the accuracy of\ngenerat-ing safe responses. To validate the effectiveness of our method, beyond\nexisting security evaluation benchmarks, we additionally designed new security\nevaluation benchmarks and conducted comparative experiments using Llama3.2 as\nthe baseline model. The final ex-perimental results demonstrate that our method\ncan significantly improve the generative security of large models under complex\ninstructional attacks, while also maintaining and enhancing the models' general\ncapabilities.",
      "tldr_zh": "这篇论文针对大型模型（large models）在面对复杂攻击指令时易生成有害内容的问题，提出了一种基于多维度攻击和防御的方法，以构建对齐数据来提升模型的生成安全性。方法的核心在于创新性地增加攻击指令维度的多样性和安全响应生成的准确性，从而改善大型模型的安全对齐学习（safe alignment learning）。实验结果显示，使用 Llama3.2 作为基线模型，该方法显著提高了模型在复杂指令攻击下的安全性，同时维持并增强了其一般能力。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00517v1",
      "published_date": "2024-12-31 16:01:25 UTC",
      "updated_date": "2024-12-31 16:01:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:06:20.071970"
    },
    {
      "arxiv_id": "2501.00514v1",
      "title": "H-Net: A Multitask Architecture for Simultaneous 3D Force Estimation and Stereo Semantic Segmentation in Intracardiac Catheters",
      "title_zh": "翻译失败",
      "authors": [
        "Pedram Fekri",
        "Mehrdad Zadeh",
        "Javad Dargahi"
      ],
      "abstract": "The success rate of catheterization procedures is closely linked to the\nsensory data provided to the surgeon. Vision-based deep learning models can\ndeliver both tactile and visual information in a sensor-free manner, while also\nbeing cost-effective to produce. Given the complexity of these models for\ndevices with limited computational resources, research has focused on force\nestimation and catheter segmentation separately. However, there is a lack of a\ncomprehensive architecture capable of simultaneously segmenting the catheter\nfrom two different angles and estimating the applied forces in 3D. To bridge\nthis gap, this work proposes a novel, lightweight, multi-input, multi-output\nencoder-decoder-based architecture. It is designed to segment the catheter from\ntwo points of view and concurrently measure the applied forces in the x, y, and\nz directions. This network processes two simultaneous X-Ray images, intended to\nbe fed by a biplane fluoroscopy system, showing a catheter's deflection from\ndifferent angles. It uses two parallel sub-networks with shared parameters to\noutput two segmentation maps corresponding to the inputs. Additionally, it\nleverages stereo vision to estimate the applied forces at the catheter's tip in\n3D. The architecture features two input channels, two classification heads for\nsegmentation, and a regression head for force estimation through a single\nend-to-end architecture. The output of all heads was assessed and compared with\nthe literature, demonstrating state-of-the-art performance in both segmentation\nand force estimation. To the best of the authors' knowledge, this is the first\ntime such a model has been proposed",
      "tldr_zh": "本研究提出了一种名为H-Net的多任务架构，用于同时实现导管立体语义分割(Stereo Semantic Segmentation)和3D Force Estimation在心脏内导管(Intracardiac Catheters)中的应用。该架构采用轻量级多输入多输出编码器-解码器设计，处理来自双平面荧光透视系统的两个X-Ray图像，通过两个共享参数的并行子网络生成对应的分割地图，并利用立体视觉技术估计导管尖端的x、y和z方向施加力。实验结果显示，H-Net在分割和力估计任务上达到了最先进的状态-of-the-art性能，与现有文献相比显著提升；这是首次提出的此类端到端模型，为无传感器心脏导管手术提供高效的视觉和触觉信息。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00514v1",
      "published_date": "2024-12-31 15:55:13 UTC",
      "updated_date": "2024-12-31 15:55:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:08:31.912044"
    },
    {
      "arxiv_id": "2501.00502v1",
      "title": "Exploring Physics-Informed Neural Networks for Crop Yield Loss Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Miro Miranda",
        "Marcela Charfuelan",
        "Andreas Dengel"
      ],
      "abstract": "In response to climate change, assessing crop productivity under extreme\nweather conditions is essential to enhance food security. Crop simulation\nmodels, which align with physical processes, offer explainability but often\nperform poorly. Conversely, machine learning (ML) models for crop modeling are\npowerful and scalable yet operate as black boxes and lack adherence to crop\ngrowths physical principles. To bridge this gap, we propose a novel method that\ncombines the strengths of both approaches by estimating the water use and the\ncrop sensitivity to water scarcity at the pixel level. This approach enables\nyield loss estimation grounded in physical principles by sequentially solving\nthe equation for crop yield response to water scarcity, using an enhanced loss\nfunction. Leveraging Sentinel-2 satellite imagery, climate data, simulated\nwater use data, and pixel-level yield data, our model demonstrates high\naccuracy, achieving an R2 of up to 0.77, matching or surpassing\nstate-of-the-art models like RNNs and Transformers. Additionally, it provides\ninterpretable and physical consistent outputs, supporting industry,\npolicymakers, and farmers in adapting to extreme weather conditions.",
      "tldr_zh": "该研究探讨了Physics-Informed Neural Networks在作物产量损失预测中的应用，以应对气候变化对极端天气下作物生产力的影响。方法结合作物模拟模型的物理解释性和机器学习的可扩展性，通过估算像素级水使用和作物对缺水的敏感性，并使用增强损失函数顺序求解产量响应方程。利用Sentinel-2卫星图像、气候数据和像素级产量数据，该模型实现了R2高达0.77的准确率，优于RNNs和Transformers等基准模型，并提供可解释且符合物理原则的输出，支持行业决策者及农民适应极端天气。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "6 pages, 2 figures, NeurIPS 2024 Workshop on Tackling Climate Change\n  with Machine Learning",
      "pdf_url": "http://arxiv.org/pdf/2501.00502v1",
      "published_date": "2024-12-31 15:21:50 UTC",
      "updated_date": "2024-12-31 15:21:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:06:43.986916"
    },
    {
      "arxiv_id": "2501.01462v1",
      "title": "Pan-infection Foundation Framework Enables Multiple Pathogen Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Lingrui Zhang",
        "Haonan Wu",
        "Nana Jin",
        "Chenqing Zheng",
        "Jize Xie",
        "Qitai Cai",
        "Jun Wang",
        "Qin Cao",
        "Xubin Zheng",
        "Jiankun Wang",
        "Lixin Cheng"
      ],
      "abstract": "Host-response-based diagnostics can improve the accuracy of diagnosing\nbacterial and viral infections, thereby reducing inappropriate antibiotic\nprescriptions. However, the existing cohorts with limited sample size and\ncoarse infections types are unable to support the exploration of an accurate\nand generalizable diagnostic model. Here, we curate the largest infection\nhost-response transcriptome data, including 11,247 samples across 89 blood\ntranscriptome datasets from 13 countries and 21 platforms. We build a\ndiagnostic model for pathogen prediction starting from a pan-infection model as\nfoundation (AUC = 0.97) based on the pan-infection dataset. Then, we utilize\nknowledge distillation to efficiently transfer the insights from this \"teacher\"\nmodel to four lightweight pathogen \"student\" models, i.e., staphylococcal\ninfection (AUC = 0.99), streptococcal infection (AUC = 0.94), HIV infection\n(AUC = 0.93), and RSV infection (AUC = 0.94), as well as a sepsis \"student\"\nmodel (AUC = 0.99). The proposed knowledge distillation framework not only\nfacilitates the diagnosis of pathogens using pan-infection data, but also\nenables an across-disease study from pan-infection to sepsis. Moreover, the\nframework enables high-degree lightweight design of diagnostic models, which is\nexpected to be adaptively deployed in clinical settings.",
      "tldr_zh": "本研究针对基于宿主反应的诊断模型，解决了现有数据样本量有限和感染类型粗糙的问题，通过整理最大的感染宿主反应转录组数据（包括11,247个样本来自89个数据集），构建了一个pan-infection基础模型（AUC=0.97）用于病原体预测。利用knowledge distillation技术，从该“teacher”模型转移知识到轻量级“student”模型，包括staphylococcal infection（AUC=0.99）、streptococcal infection（AUC=0.94）、HIV infection（AUC=0.93）、RSV infection（AUC=0.94）和sepsis（AUC=0.99）。该框架不仅提升了诊断准确性，支持从pan-infection到sepsis的跨疾病研究，还实现了高程度的模型轻量化，便于临床环境部署。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.GN"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.01462v1",
      "published_date": "2024-12-31 14:34:53 UTC",
      "updated_date": "2024-12-31 14:34:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:06:57.817575"
    },
    {
      "arxiv_id": "2501.00461v1",
      "title": "Efficient support ticket resolution using Knowledge Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Sherwin Varghese",
        "James Tian"
      ],
      "abstract": "A review of over 160,000 customer cases indicates that about 90% of time is\nspent by the product support for solving around 10% of subset of tickets where\na trivial solution may not exist. Many of these challenging cases require the\nsupport of several engineers working together within a \"swarm\", and some also\nneed to go to development support as bugs. These challenging customer issues\nrepresent a major opportunity for machine learning and knowledge graph that\nidentifies the ideal engineer / group of engineers(swarm) that can best address\nthe solution, reducing the wait times for the customer. The concrete ML task we\nconsider here is a learning-to-rank(LTR) task that given an incident and a set\nof engineers currently assigned to the incident (which might be the empty set\nin the non-swarming context), produce a ranked list of engineers best fit to\nhelp resolve that incident. To calculate the rankings, we may consider a wide\nvariety of input features including the incident description provided by the\ncustomer, the affected component(s), engineer ratings of their expertise,\nknowledge base article text written by engineers, response to customer text\nwritten by engineers, and historic swarming data. The central hypothesis test\nis that by including a holistic set of contextual data around which cases an\nengineer has solved, we can significantly improve the LTR algorithm over\nbenchmark models. The article proposes a novel approach of modelling Knowledge\nGraph embeddings from multiple data sources, including the swarm information.\nThe results obtained proves that by incorporating this additional context, we\ncan improve the recommendations significantly over traditional machine learning\nmethods like TF-IDF.",
      "tldr_zh": "这篇论文针对支持票证处理中的挑战，分析发现90%的处理时间用于10%的复杂案例，这些案例往往需要多个工程师协作（swarm）。论文提出一种基于知识图谱（Knowledge Graphs）的学习到排名（LTR）方法，利用事件描述、工程师专业评分、历史数据等多源特征来生成最佳工程师排名列表。核心创新在于从多个数据源建模知识图谱嵌入，包括swarm信息，从而显著提升推荐准确性。实验结果显示，该方法比传统机器学习方法如TF-IDF取得了更好的性能，减少了客户等待时间。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00461v1",
      "published_date": "2024-12-31 14:21:05 UTC",
      "updated_date": "2024-12-31 14:21:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:07:09.041685"
    },
    {
      "arxiv_id": "2501.00457v1",
      "title": "Differentiable Prompt Learning for Vision Language Models",
      "title_zh": "可微提示学习用于视觉语言模型",
      "authors": [
        "Zhenhan Huang",
        "Tejaswini Pedapati",
        "Pin-Yu Chen",
        "Jianxi Gao"
      ],
      "abstract": "Prompt learning is an effective way to exploit the potential of large-scale\npre-trained foundational models. Continuous prompts parameterize context tokens\nin prompts by turning them into differentiable vectors. Deep continuous prompts\ninsert prompts not only in the input but also in the intermediate hidden\nrepresentations. Manually designed deep continuous prompts exhibit a remarkable\nimprovement compared to the zero-shot pre-trained model on downstream tasks.\nHow to automate the continuous prompt design is an underexplored area, and a\nfundamental question arises, is manually designed deep prompt strategy optimal?\nTo answer this question, we propose a method dubbed differentiable prompt\nlearning (DPL). The DPL method is formulated as an optimization problem to\nautomatically determine the optimal context length of the prompt to be added to\neach layer, where the objective is to maximize the performance. We test the DPL\nmethod on the pre-trained CLIP. We empirically find that by using only limited\ndata, our DPL method can find deep continuous prompt configuration with high\nconfidence. The performance on the downstream tasks exhibits the superiority of\nthe automatic design: our method boosts the average test accuracy by 2.60% on\n11 datasets compared to baseline methods. Besides, our method focuses only on\nthe prompt configuration (i.e. context length for each layer), which means that\nour method is compatible with the baseline methods that have sophisticated\ndesigns to boost the performance. The DPL method can be deployed to large\nlanguage models or computer vision models at no cost.",
      "tldr_zh": "这篇论文提出了一种可微提示学习(Differentiable Prompt Learning, DPL)方法，用于优化视觉语言模型的深层连续提示(DP)，以自动化提示设计并解决手动设计是否最优的问题。DPL 将提示配置表述为一个优化问题，目标是最大化下游任务性能，通过自动确定每个层的最佳上下文长度。实验在预训练的 CLIP 模型上进行，结果显示，使用有限数据，DPL 比基线方法平均提高测试准确率 2.60%，并可免费与其他方法兼容，适用于大型语言模型或计算机视觉模型。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00457v1",
      "published_date": "2024-12-31 14:13:28 UTC",
      "updated_date": "2024-12-31 14:13:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:07:20.715403"
    },
    {
      "arxiv_id": "2501.00449v1",
      "title": "Do Students with Different Personality Traits Demonstrate Different Physiological Signals in Video-based Learning?",
      "title_zh": "不同性格特征的学生在基于视频的学习中是否表现出不同的生理信号？",
      "authors": [
        "Chun-Hsiung Tseng",
        "Hao-Chiang Koong Lin",
        "Yung-Hui Chen",
        "Jia-Rou Lin",
        "Andrew Chih-Wei Huang"
      ],
      "abstract": "Past researches show that personality trait is a strong predictor for ones\nacademic performance. Today, mature and verified marker systems for assessing\npersonality traits already exist. However, marker systems-based assessing\nmethods have their own limitations. For example, dishonest responses cannot be\navoided. In this research, the goal is to develop a method that can overcome\nthe limitations. The proposed method will rely on physiological signals for the\nassessment. Thirty participants have participated in this experiment. Based on\nthe statistical results, we found that there are correlations between students\npersonality traits and their physiological signal change when learning via\nvideos. Specifically, we found that participants degree of extraversion,\nagreeableness, conscientiousness, and openness to experiences are correlated\nwith the variance of heart rates, the variance of GSR values, and the skewness\nof voice frequencies, etc.",
      "tldr_zh": "本研究探讨了学生人格特质（如extraversion、agreeableness、conscientiousness和openness to experiences）是否会影响他们在视频学习中的physiological signals，旨在克服传统评估方法（如问卷）的局限性，例如不诚实回答的问题。研究招募了30名参与者，通过分析他们的生理信号变化（如心率方差、GSR值方差和声音频率偏度）来评估人格特质。结果显示，特定人格特质与这些生理信号变化存在显著相关性，为基于生理信号的更可靠人格评估提供新方法。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00449v1",
      "published_date": "2024-12-31 14:00:32 UTC",
      "updated_date": "2024-12-31 14:00:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:07:31.719499"
    },
    {
      "arxiv_id": "2501.14776v1",
      "title": "Green AI: Which Programming Language Consumes the Most?",
      "title_zh": "翻译失败",
      "authors": [
        "Niccolò Marini",
        "Leonardo Pampaloni",
        "Filippo Di Martino",
        "Roberto Verdecchia",
        "Enrico Vicario"
      ],
      "abstract": "AI is demanding an evergrowing portion of environmental resources. Despite\ntheir potential impact on AI environmental sustainability, the role that\nprogramming languages play in AI (in)efficiency is to date still unknown. With\nthis study, we aim to understand the impact that programming languages can have\non AI environmental sustainability. To achieve our goal, we conduct a\ncontrolled empirical experiment by considering five programming languages (C++,\nJava, Python, MATLAB, and R), seven AI algorithms (KNN, SVC, AdaBoost, decision\ntree, logistic regression, naive bayses, and random forest), three popular\ndatasets, and the training and inference phases. The collected results show\nthat programming languages have a considerable impact on AI environmental\nsustainability. Compiled and semi-compiled languages (C++, Java) consistently\nconsume less than interpreted languages (Python, MATLAB, R), which require up\nto 54x more energy. Some languages are cumulatively more efficient in training,\nwhile others in inference. Which programming language consumes the most highly\ndepends on the algorithm considered. Ultimately, algorithm implementation might\nbe the most determining factor in Green AI, regardless of the language used. As\nconclusion, while making AI more environmentally sustainable is paramount, a\ntrade-off between energy efficiency and implementation ease should always be\nconsidered. Green AI can be achieved without the need of completely disrupting\nthe development practices and technologies currently in place.",
      "tldr_zh": "这篇论文探讨了编程语言对 AI 环境可持续性的影响，通过控制实验比较了 C++、Java、Python、MATLAB 和 R 在七种 AI 算法（如 KNN、SVC 和随机森林）上的能源消耗，涉及训练和推理阶段。结果显示，编译语言（如 C++ 和 Java）比解释语言（如 Python）更高效，前者能源消耗可低至后者的1/54，且语言效率高度依赖于具体算法。论文强调，算法实现是 Green AI 的关键因素，而非语言本身，并建议在能源效率和开发便利性之间权衡，以实现可持续 AI 发展而不需大幅改变现有实践。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.CY",
      "comment": "Accepted at International Workshop on Green and Sustainable Software\n  (GREENS), 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.14776v1",
      "published_date": "2024-12-31 13:53:57 UTC",
      "updated_date": "2024-12-31 13:53:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:08:43.681231"
    },
    {
      "arxiv_id": "2501.00444v1",
      "title": "Knowledge-aware equation discovery with automated background knowledge extraction",
      "title_zh": "知识感知的方程发现：结合自动背景知识提取",
      "authors": [
        "Elizaveta Ivanchik",
        "Alexander Hvatov"
      ],
      "abstract": "In differential equation discovery algorithms, a priori expert knowledge is\nmainly used implicitly to constrain the form of the expected equation, making\nit impossible for the algorithm to truly discover equations. Instead, most\ndifferential equation discovery algorithms try to recover the coefficients for\na known structure. In this paper, we describe an algorithm that allows the\ndiscovery of unknown equations using automatically or manually extracted\nbackground knowledge. Instead of imposing rigid constraints, we modify the\nstructure space so that certain terms are likely to appear within the crossover\nand mutation operators. In this way, we mimic expertly chosen terms while\npreserving the possibility of obtaining any equation form. The paper shows that\nthe extraction and use of knowledge allows it to outperform the SINDy algorithm\nin terms of search stability and robustness. Synthetic examples are given for\nBurgers, wave, and Korteweg--De Vries equations.",
      "tldr_zh": "本文提出了一种知识感知的微分方程发现算法，通过自动或手动提取背景知识来发现未知方程，而非仅恢复已知结构的系数。该算法通过修改结构空间，使特定术语在交叉和变异操作中更可能出现，从而模拟专家知识的同时保留灵活性。实验结果显示，该方法在搜索稳定性和鲁棒性上优于SINDy算法，并通过Burgers、wave和Korteweg--De Vries方程的合成例子进行了验证。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00444v1",
      "published_date": "2024-12-31 13:51:31 UTC",
      "updated_date": "2024-12-31 13:51:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:08:55.005006"
    },
    {
      "arxiv_id": "2501.01992v1",
      "title": "Disagree and Commit: Degrees of Argumentation-based Agreements",
      "title_zh": "翻译失败",
      "authors": [
        "Timotheus Kampik",
        "Juan Carlos Nieves"
      ],
      "abstract": "In cooperative human decision-making, agreements are often not total; a\npartial degree of agreement is sufficient to commit to a decision and move on,\nas long as one is somewhat confident that the involved parties are likely to\nstand by their commitment in the future, given no drastic unexpected changes.\nIn this paper, we introduce the notion of agreement scenarios that allow\nartificial autonomous agents to reach such agreements, using formal models of\nargumentation, in particular abstract argumentation and value-based\nargumentation. We introduce the notions of degrees of satisfaction and\n(minimum, mean, and median) agreement, as well as a measure of the impact a\nvalue in a value-based argumentation framework has on these notions. We then\nanalyze how degrees of agreement are affected when agreement scenarios are\nexpanded with new information, to shed light on the reliability of partial\nagreements in dynamic scenarios. An implementation of the introduced concepts\nis provided as part of an argumentation-based reasoning software library.",
      "tldr_zh": "这篇论文探讨了在合作决策中，通过部分协议（degrees of agreement）来推进决策的机制，即使各方不完全同意，只要未来遵守的可能性较高即可。论文引入agreement scenarios的概念，使用abstract argumentation和value-based argumentation框架，定义了degrees of satisfaction以及minimum, mean和median agreement等度量，并评估value在框架中的影响。研究分析了当新信息加入时协议程度的变化，以评估部分协议在动态场景中的可靠性，并提供了一个argumentation-based reasoning软件库的实现。",
      "categories": [
        "cs.AI",
        "cs.LO",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "To appear eventually in the Autonomous Agents and Multi-Agent Systems\n  journal",
      "pdf_url": "http://arxiv.org/pdf/2501.01992v1",
      "published_date": "2024-12-31 12:49:58 UTC",
      "updated_date": "2024-12-31 12:49:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:11:00.613812"
    },
    {
      "arxiv_id": "2501.00418v1",
      "title": "Generalizing Trust: Weak-to-Strong Trustworthiness in Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Martin Pawelczyk",
        "Lillian Sun",
        "Zhenting Qi",
        "Aounon Kumar",
        "Himabindu Lakkaraju"
      ],
      "abstract": "The rapid proliferation of generative AI, especially large language models,\nhas led to their integration into a variety of applications. A key phenomenon\nknown as weak-to-strong generalization - where a strong model trained on a weak\nmodel's outputs surpasses the weak model in task performance - has gained\nsignificant attention. Yet, whether critical trustworthiness properties such as\nrobustness, fairness, and privacy can generalize similarly remains an open\nquestion. In this work, we study this question by examining if a stronger model\ncan inherit trustworthiness properties when fine-tuned on a weaker model's\noutputs, a process we term weak-to-strong trustworthiness generalization. To\naddress this, we introduce two foundational training strategies: 1) Weak\nTrustworthiness Finetuning (Weak TFT), which leverages trustworthiness\nregularization during the fine-tuning of the weak model, and 2) Weak and\nWeak-to-Strong Trustworthiness Finetuning (Weak+WTS TFT), which extends\nregularization to both weak and strong models. Our experimental evaluation on\nreal-world datasets reveals that while some trustworthiness properties, such as\nfairness, adversarial, and OOD robustness, show significant improvement in\ntransfer when both models were regularized, others like privacy do not exhibit\nsigns of weak-to-strong trustworthiness. As the first study to explore\ntrustworthiness generalization via weak-to-strong generalization, our work\nprovides valuable insights into the potential and limitations of weak-to-strong\ngeneralization.",
      "tldr_zh": "本研究探讨了语言模型中weak-to-strong generalization是否适用于关键信任属性，如robustness、fairness和privacy，即强模型通过在弱模型输出上微调是否能继承这些属性。作者引入了两种训练策略：Weak Trustworthiness Finetuning (Weak TFT)，在弱模型微调时应用信任正则化；以及Weak and Weak-to-Strong Trustworthiness Finetuning (Weak+WTS TFT)，扩展正则化到强模型。实验结果显示，在真实数据集上，fairness、adversarial robustness和OOD robustness等属性在双模型正则化时显著改善，但privacy属性未显示弱到强转移，作为首次此类研究，该工作揭示了weak-to-strong generalization的潜力与局限性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "The first two authors contributed equally",
      "pdf_url": "http://arxiv.org/pdf/2501.00418v1",
      "published_date": "2024-12-31 12:40:02 UTC",
      "updated_date": "2024-12-31 12:40:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:11:12.972283"
    },
    {
      "arxiv_id": "2501.00398v2",
      "title": "TSPE: Task-Specific Prompt Ensemble for Improved Zero-Shot Audio Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Nishit Anand",
        "Ashish Seth",
        "Ramani Duraiswami",
        "Dinesh Manocha"
      ],
      "abstract": "Audio-language models (ALMs) excel in zero-shot audio classification, a task\nwhere models classify previously unseen audio clips at test time by leveraging\ndescriptive natural language prompts. We introduce TSPE (Task-Specific Prompt\nEnsemble), a simple, training-free hard prompting method that boosts ALEs'\nzero-shot performance by customizing prompts for diverse audio classification\ntasks. Rather than using generic template-based prompts like \"Sound of a car\"\nwe generate context-rich prompts, such as \"Sound of a car coming from a\ntunnel\". Specifically, we leverage label information to identify suitable sound\nattributes, such as \"loud\" and \"feeble\", and appropriate sound sources, such as\n\"tunnel\" and \"street\" and incorporate this information into the prompts used by\nAudio-Language Models (ALMs) for audio classification. Further, to enhance\naudio-text alignment, we perform prompt ensemble across TSPE-generated\ntask-specific prompts. When evaluated on 12 diverse audio classification\ndatasets, TSPE improves performance across ALMs by showing an absolute\nimprovement of 1.23-16.36% over vanilla zero-shot evaluation.",
      "tldr_zh": "本研究提出 TSPE（Task-Specific Prompt Ensemble），一种无需训练的硬提示方法，用于提升 Audio-Language Models (ALMs) 在零样本音频分类中的性能。TSPE 通过利用标签信息生成任务特定的丰富提示，例如添加声学属性（如 \"loud\" 和 \"feeble\"）及声源（如 \"tunnel\" 和 \"street\"），并进行提示集成以增强音频-文本对齐，从而超越通用模板提示。实验结果显示，在12个音频分类数据集上，TSPE 使 ALMs 的性能绝对提升1.23-16.36%。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted to SALMA Workshop ICASSP 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.00398v2",
      "published_date": "2024-12-31 11:27:17 UTC",
      "updated_date": "2025-04-03 01:09:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:09:31.760094"
    },
    {
      "arxiv_id": "2501.00397v1",
      "title": "Efficient Relational Context Perception for Knowledge Graph Completion",
      "title_zh": "用于知识图谱补全的效率关系上下文感知",
      "authors": [
        "Wenkai Tu",
        "Guojia Wan",
        "Zhengchun Shang",
        "Bo Du"
      ],
      "abstract": "Knowledge Graphs (KGs) provide a structured representation of knowledge but\noften suffer from challenges of incompleteness. To address this, link\nprediction or knowledge graph completion (KGC) aims to infer missing new facts\nbased on existing facts in KGs. Previous knowledge graph embedding models are\nlimited in their ability to capture expressive features, especially when\ncompared to deeper, multi-layer models. These approaches also assign a single\nstatic embedding to each entity and relation, disregarding the fact that\nentities and relations can exhibit different behaviors in varying graph\ncontexts. Due to complex context over a fact triple of a KG, existing methods\nhave to leverage complex non-linear context encoder, like transformer, to\nproject entity and relation into low dimensional representations, resulting in\nhigh computation cost. To overcome these limitations, we propose Triple\nReceptance Perception (TRP) architecture to model sequential information,\nenabling the learning of dynamic context of entities and relations. Then we use\ntensor decomposition to calculate triple scores, providing robust relational\ndecoding capabilities. This integration allows for more expressive\nrepresentations. Experiments on benchmark datasets such as YAGO3-10, UMLS,\nFB15k, and FB13 in link prediction and triple classification tasks demonstrate\nthat our method performs better than several state-of-the-art models, proving\nthe effectiveness of the integration.",
      "tldr_zh": "本研究针对知识图谱（KGs）的补全问题（Knowledge Graph Completion, KGC），指出现有嵌入模型无法捕捉足够的表达特征，且实体和关系使用静态嵌入，忽略了不同上下文下的动态变化，导致计算成本高。作者提出 Triple Receptance Perception (TRP) 架构来建模序列信息，学习实体和关系的动态上下文，并结合张量分解（tensor decomposition）计算三元组分数，以实现更具表达性的表示。实验在 YAGO3-10、UMLS、FB15k 和 FB13 等基准数据集上显示，该方法在链接预测（link prediction）和三元组分类（triple classification）任务中优于现有最先进模型，证明了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00397v1",
      "published_date": "2024-12-31 11:25:58 UTC",
      "updated_date": "2024-12-31 11:25:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:09:43.048659"
    },
    {
      "arxiv_id": "2501.00383v2",
      "title": "Proactive Conversational Agents with Inner Thoughts",
      "title_zh": "翻译失败",
      "authors": [
        "Xingyu Bruce Liu",
        "Shitao Fang",
        "Weiyan Shi",
        "Chien-Sheng Wu",
        "Takeo Igarashi",
        "Xiang Anthony Chen"
      ],
      "abstract": "One of the long-standing aspirations in conversational AI is to allow them to\nautonomously take initiatives in conversations, i.e., being proactive. This is\nespecially challenging for multi-party conversations. Prior NLP research\nfocused mainly on predicting the next speaker from contexts like preceding\nconversations. In this paper, we demonstrate the limitations of such methods\nand rethink what it means for AI to be proactive in multi-party, human-AI\nconversations. We propose that just like humans, rather than merely reacting to\nturn-taking cues, a proactive AI formulates its own inner thoughts during a\nconversation, and seeks the right moment to contribute. Through a formative\nstudy with 24 participants and inspiration from linguistics and cognitive\npsychology, we introduce the Inner Thoughts framework. Our framework equips AI\nwith a continuous, covert train of thoughts in parallel to the overt\ncommunication process, which enables it to proactively engage by modeling its\nintrinsic motivation to express these thoughts. We instantiated this framework\ninto two real-time systems: an AI playground web app and a chatbot. Through a\ntechnical evaluation and user studies with human participants, our framework\nsignificantly surpasses existing baselines on aspects like anthropomorphism,\ncoherence, intelligence, and turn-taking appropriateness.",
      "tldr_zh": "该论文探讨了conversational AI在multi-party conversations中主动发起行动的挑战，指出现有方法仅依赖上下文预测下一个发言者存在局限。论文提出Inner Thoughts框架，模拟人类认知过程，让AI在对话中生成连续的隐性思考，并根据内在动机主动选择表达时机。实验结果显示，该框架通过两个实时系统（AI playground web app和聊天机器人）的实现，在拟人化、一致性和智能等方面显著优于基线，提升了AI的整体表现。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00383v2",
      "published_date": "2024-12-31 10:41:56 UTC",
      "updated_date": "2025-02-18 08:53:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:09:56.596911"
    },
    {
      "arxiv_id": "2501.00382v1",
      "title": "Adventures in Demand Analysis Using AI",
      "title_zh": "翻译失败",
      "authors": [
        "Philipp Bach",
        "Victor Chernozhukov",
        "Sven Klaassen",
        "Martin Spindler",
        "Jan Teichert-Kluge",
        "Suhas Vijaykumar"
      ],
      "abstract": "This paper advances empirical demand analysis by integrating multimodal\nproduct representations derived from artificial intelligence (AI). Using a\ndetailed dataset of toy cars on \\textit{Amazon.com}, we combine text\ndescriptions, images, and tabular covariates to represent each product using\ntransformer-based embedding models. These embeddings capture nuanced\nattributes, such as quality, branding, and visual characteristics, that\ntraditional methods often struggle to summarize. Moreover, we fine-tune these\nembeddings for causal inference tasks. We show that the resulting embeddings\nsubstantially improve the predictive accuracy of sales ranks and prices and\nthat they lead to more credible causal estimates of price elasticity. Notably,\nwe uncover strong heterogeneity in price elasticity driven by these\nproduct-specific features. Our findings illustrate that AI-driven\nrepresentations can enrich and modernize empirical demand analysis. The\ninsights generated may also prove valuable for applied causal inference more\nbroadly.",
      "tldr_zh": "本研究利用人工智能（AI）整合多模态产品表示，推进经验需求分析。研究者使用 Amazon.com 的玩具车数据集，通过 transformer-based embedding models 结合文本描述、图像和表格协变量，捕捉质量、品牌和视觉特征等细微属性。结果显示，这些嵌入模型显著提升了销售排名和价格的预测准确性，并为因果推理任务提供了更可靠的价格弹性估计。论文还揭示了由产品特定特征驱动的价格弹性异质性。这些发现证明，AI 驱动的表示方法能丰富和现代化需求分析，并为更广泛的 applied causal inference 带来价值。",
      "categories": [
        "econ.GN",
        "cs.AI",
        "q-fin.EC",
        "stat.AP",
        "stat.ML"
      ],
      "primary_category": "econ.GN",
      "comment": "42 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.00382v1",
      "published_date": "2024-12-31 10:33:10 UTC",
      "updated_date": "2024-12-31 10:33:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:12:01.048913"
    },
    {
      "arxiv_id": "2501.00368v3",
      "title": "Design Optimizer for Soft Growing Robot Manipulators in Three-Dimensional Environments",
      "title_zh": "三维环境下的软体",
      "authors": [
        "Ahmet Astar",
        "Ozan Nurcan",
        "Erk Demirel",
        "Emir Ozen",
        "Ozan Kutlar",
        "Fabio Stroppa"
      ],
      "abstract": "Soft growing robots are novel devices that mimic plant-like growth for\nnavigation in cluttered or dangerous environments. Their ability to adapt to\nsurroundings, combined with advancements in actuation and manufacturing\ntechnologies, allows them to perform specialized manipulation tasks. This work\npresents an approach for design optimization of soft growing robots;\nspecifically, the three-dimensional extension of the optimizer designed for\nplanar manipulators. This tool is intended to be used by engineers and robot\nenthusiasts before manufacturing their robot: it suggests the optimal size of\nthe robot for solving a specific task. The design process models a\nmulti-objective optimization problem to refine a soft manipulator's kinematic\nchain. Thanks to the novel Rank Partitioning algorithm integrated into\nEvolutionary Computation (EC) algorithms, this method achieves high precision\nin reaching targets and is efficient in resource usage. Results show\nsignificantly high performance in solving three-dimensional tasks, whereas\ncomparative experiments indicate that the optimizer features robust output when\ntested with different EC algorithms, particularly genetic algorithms.",
      "tldr_zh": "本文提出了一种针对三维环境的软生长机器人机械臂设计优化器，作为平面优化器的扩展，帮助工程师在制造前确定最佳机器人尺寸。优化过程通过建模多目标优化问题，并集成 Rank Partitioning 算法到 Evolutionary Computation (EC) 算法中，实现了高精度目标到达和资源高效。实验结果显示，该优化器在三维任务中表现出色，并在与不同 EC 算法（如 genetic algorithms）的比较中，展现出强大的鲁棒性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.RO",
      "comment": "17 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.00368v3",
      "published_date": "2024-12-31 09:44:18 UTC",
      "updated_date": "2025-01-23 07:04:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:10:19.114669"
    },
    {
      "arxiv_id": "2501.00365v1",
      "title": "Low-Rank Adaptation for Foundation Models: A Comprehensive Review",
      "title_zh": "翻译失败",
      "authors": [
        "Menglin Yang",
        "Jialin Chen",
        "Yifei Zhang",
        "Jiahong Liu",
        "Jiasheng Zhang",
        "Qiyao Ma",
        "Harshit Verma",
        "Qianru Zhang",
        "Min Zhou",
        "Irwin King",
        "Rex Ying"
      ],
      "abstract": "The rapid advancement of foundation modelslarge-scale neural networks trained\non diverse, extensive datasetshas revolutionized artificial intelligence,\nenabling unprecedented advancements across domains such as natural language\nprocessing, computer vision, and scientific discovery. However, the substantial\nparameter count of these models, often reaching billions or trillions, poses\nsignificant challenges in adapting them to specific downstream tasks. Low-Rank\nAdaptation (LoRA) has emerged as a highly promising approach for mitigating\nthese challenges, offering a parameter-efficient mechanism to fine-tune\nfoundation models with minimal computational overhead. This survey provides the\nfirst comprehensive review of LoRA techniques beyond large Language Models to\ngeneral foundation models, including recent techniques foundations, emerging\nfrontiers and applications of low-rank adaptation across multiple domains.\nFinally, this survey discusses key challenges and future research directions in\ntheoretical understanding, scalability, and robustness. This survey serves as a\nvaluable resource for researchers and practitioners working with efficient\nfoundation model adaptation.",
      "tldr_zh": "这篇论文对 Low-Rank Adaptation (LoRA) 进行了全面综述，聚焦于其在基础模型（如大型神经网络）中的应用，以高效微调这些模型适应特定下游任务。LoRA 通过参数高效机制减少计算开销，适用于自然语言处理、计算机视觉和科学发现等领域，并涵盖了其技术基础、新兴前沿和实际应用。论文还讨论了关键挑战，包括理论理解、可扩展性和鲁棒性，并为未来研究方向提供了宝贵见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00365v1",
      "published_date": "2024-12-31 09:38:55 UTC",
      "updated_date": "2024-12-31 09:38:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:10:31.333885"
    },
    {
      "arxiv_id": "2501.00364v3",
      "title": "FORM: Learning Expressive and Transferable First-Order Logic Reward Machines",
      "title_zh": "翻译失败",
      "authors": [
        "Leo Ardon",
        "Daniel Furelos-Blanco",
        "Roko Parac",
        "Alessandra Russo"
      ],
      "abstract": "Reward machines (RMs) are an effective approach for addressing non-Markovian\nrewards in reinforcement learning (RL) through finite-state machines.\nTraditional RMs, which label edges with propositional logic formulae, inherit\nthe limited expressivity of propositional logic. This limitation hinders the\nlearnability and transferability of RMs since complex tasks will require\nnumerous states and edges. To overcome these challenges, we propose First-Order\nReward Machines ($\\texttt{FORM}$s), which use first-order logic to label edges,\nresulting in more compact and transferable RMs. We introduce a novel method for\n$\\textbf{learning}$ $\\texttt{FORM}$s and a multi-agent formulation for\n$\\textbf{exploiting}$ them and facilitate their transferability, where multiple\nagents collaboratively learn policies for a shared $\\texttt{FORM}$. Our\nexperimental results demonstrate the scalability of $\\texttt{FORM}$s with\nrespect to traditional RMs. Specifically, we show that $\\texttt{FORM}$s can be\neffectively learnt for tasks where traditional RM learning approaches fail. We\nalso show significant improvements in learning speed and task transferability\nthanks to the multi-agent learning framework and the abstraction provided by\nthe first-order language.",
      "tldr_zh": "本论文提出 First-Order Reward Machines (FORMs)，一种使用一阶逻辑标签边的强化学习框架，以解决传统 Reward Machines 在表达性有限问题上导致的状态和边数量过多的挑战。\n他们引入了一种新颖的学习方法和多智能体框架，让多个代理协同学习共享的 FORM，从而提升其可转移性和整体效率。\n实验结果表明，FORMs 在复杂任务上比传统方法更具可扩展性，能够在传统 Reward Machines 失败的场景中有效学习，并显著改善学习速度和任务转移能力。",
      "categories": [
        "cs.AI",
        "cs.FL",
        "cs.LO",
        "cs.SC"
      ],
      "primary_category": "cs.AI",
      "comment": "AAMAS'25",
      "pdf_url": "http://arxiv.org/pdf/2501.00364v3",
      "published_date": "2024-12-31 09:31:15 UTC",
      "updated_date": "2025-02-28 17:13:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:12:12.890513"
    },
    {
      "arxiv_id": "2501.00363v2",
      "title": "SPDZCoder: Combining Expert Knowledge with LLMs for Generating Privacy-Computing Code",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoning Dong",
        "Peilin Xin",
        "Jia Li",
        "Wei Xu"
      ],
      "abstract": "Privacy computing receives increasing attention but writing privacy computing\ncode remains challenging for developers due to limited library functions,\nnecessitating function implementation from scratch, and data-oblivious\nrequirement, contradicting intuitive thinking and usual practices of\nprogrammers. Automating the generation of privacy computing code with Large\nLanguage Models can streamline development effort and lower the barrier to\nusing privacy computing frameworks. However, existing LLMs still encounter\nchallenges in code translation for privacy-preserving computation, such as\ntranslating Python to MP-SPDZ, due to the scarcity of MP-SPDZ data required for\neffective pre-training or fine-tuning. Moreover, the lack of a benchmark\nfurther complicates the evaluation of translation quality. To address the\nlimitations, this work proposes SPDZCoder, a rule-based framework that combines\nLLMs with expert knowledge for generating privacy-computing code without\nrequiring additional training data. Specifically, SPDZCoder employ a rigorous\nprocedure for collecting high-quality expert knowledge to represent the\nsemantic-expressing differences between Python and MP-SPDZ, and to derive\ntransformation rules for translating Python to MP-SPDZ based on these\nknowledge. Then, SPDZCoder progressively converts Python code into MP-SPDZ code\nusing transformation rules in a three stage pipeline. To evaluate SPDZCoder, we\nmanually constructed a benchmark dataset, SPDZEval, which comprises six data\nsplits, each representing a distinct class of challenging tasks in MP-SPDZ\nimplementation. Extensive experiments show that SPDZCoder achieves superior\nperformance, significantly surpassing baselines in pass@1 and pass@2.\nSpecifically, SPDZCoder attains an overall correctness of 85.94% and 92.01% in\npass@1 and pass@2, respectively, whereas the best-performing baseline achieves\n63.58% and 76.36%, respectively.",
      "tldr_zh": "该论文提出 SPDZCoder 框架，通过结合专家知识和大型语言模型 (LLMs)，自动生成隐私计算代码，解决开发者面临的库函数有限、函数从零实现以及数据无关性要求等挑战。框架采用规则-based 方法，收集高品质专家知识以派生 Python 到 MP-SPDZ 的转换规则，并通过三阶段管道逐步转换代码，同时构建了基准数据集 SPDZEval 包含六类挑战任务。实验结果显示，SPDZCoder 在 pass@1 和 pass@2 上分别达到 85.94% 和 92.01% 的正确率，显著优于最佳基线模型（63.58% 和 76.36%）。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00363v2",
      "published_date": "2024-12-31 09:29:38 UTC",
      "updated_date": "2025-03-21 12:52:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:12:26.284246"
    },
    {
      "arxiv_id": "2501.00353v1",
      "title": "RAG-Instruct: Boosting LLMs with Diverse Retrieval-Augmented Instructions",
      "title_zh": "翻译失败",
      "authors": [
        "Wanlong Liu",
        "Junying Chen",
        "Ke Ji",
        "Li Zhou",
        "Wenyu Chen",
        "Benyou Wang"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a key paradigm for\nenhancing large language models (LLMs) by incorporating external knowledge.\nHowever, current RAG methods face two limitations: (1) they only cover limited\nRAG scenarios. (2) They suffer from limited task diversity due to the lack of a\ngeneral RAG dataset. To address these limitations, we propose RAG-Instruct, a\ngeneral method for synthesizing diverse and high-quality RAG instruction data\nbased on any source corpus. Our approach leverages (1) five RAG paradigms,\nwhich encompass diverse query-document relationships, and (2) instruction\nsimulation, which enhances instruction diversity and quality by utilizing the\nstrengths of existing instruction datasets. Using this method, we construct a\n40K instruction dataset from Wikipedia, comprehensively covering diverse RAG\nscenarios and tasks. Experiments demonstrate that RAG-Instruct effectively\nenhances LLMs' RAG capabilities, achieving strong zero-shot performance and\nsignificantly outperforming various RAG baselines across a diverse set of\ntasks. RAG-Instruct is publicly available at\nhttps://github.com/FreedomIntelligence/RAG-Instruct.",
      "tldr_zh": "该论文提出RAG-Instruct，一种通用方法，用于从任何源语料合成多样、高质量的RAG指令数据，以解决现有RAG方法在覆盖场景和任务多样性上的局限性。该方法结合五种RAG范式（涵盖不同查询-文档关系）和指令模拟（利用现有指令数据集提升多样性与质量），并基于Wikipedia构建了40K指令数据集，全面覆盖各种RAG场景和任务。实验结果显示，RAG-Instruct显著提升LLMs的RAG能力，在零样本设置下表现优异，并超越多种RAG基线。项目已开源在https://github.com/FreedomIntelligence/RAG-Instruct。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00353v1",
      "published_date": "2024-12-31 09:00:51 UTC",
      "updated_date": "2024-12-31 09:00:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:12:37.535928"
    },
    {
      "arxiv_id": "2501.00348v1",
      "title": "Temporal Information Reconstruction and Non-Aligned Residual in Spiking Neural Networks for Speech Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Qi Zhang",
        "Huamin Wang",
        "Hangchi Shen",
        "Shukai Duan",
        "Shiping Wen",
        "Tingwen Huang"
      ],
      "abstract": "Recently, it can be noticed that most models based on spiking neural networks\n(SNNs) only use a same level temporal resolution to deal with speech\nclassification problems, which makes these models cannot learn the information\nof input data at different temporal scales. Additionally, owing to the\ndifferent time lengths of the data before and after the sub-modules of many\nmodels, the effective residual connections cannot be applied to optimize the\ntraining processes of these models.To solve these problems, on the one hand, we\nreconstruct the temporal dimension of the audio spectrum to propose a novel\nmethod named as Temporal Reconstruction (TR) by referring the hierarchical\nprocessing process of the human brain for understanding speech. Then, the\nreconstructed SNN model with TR can learn the information of input data at\ndifferent temporal scales and model more comprehensive semantic information\nfrom audio data because it enables the networks to learn the information of\ninput data at different temporal resolutions. On the other hand, we propose the\nNon-Aligned Residual (NAR) method by analyzing the audio data, which allows the\nresidual connection can be used in two audio data with different time lengths.\nWe have conducted plentiful experiments on the Spiking Speech Commands (SSC),\nthe Spiking Heidelberg Digits (SHD), and the Google Speech Commands v0.02 (GSC)\ndatasets. According to the experiment results, we have achieved the\nstate-of-the-art (SOTA) result 81.02\\% on SSC for the test classification\naccuracy of all SNN models, and we have obtained the SOTA result 96.04\\% on SHD\nfor the classification accuracy of all models.",
      "tldr_zh": "本文针对基于 Spiking Neural Networks (SNNs) 的语音分类模型存在的时序分辨率单一问题和残差连接应用限制，提出了两种创新方法：Temporal Reconstruction (TR) 和 Non-Aligned Residual (NAR)。TR 通过参考人类大脑的层次化处理过程，重构音频谱的时序维度，使模型能够学习不同时序尺度的信息，从而更全面地建模语义细节；NAR 则通过分析音频数据，实现了残差连接在长度不一的数据间的应用，以优化训练过程。在 Spiking Speech Commands (SSC)、Spiking Heidelberg Digits (SHD) 和 Google Speech Commands (GSC) 数据集上的实验中，该方法取得了 SOTA 性能，在 SSC 上达到 81.02% 的测试分类准确率，在 SHD 上达到 96.04%。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "9 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.00348v1",
      "published_date": "2024-12-31 08:52:40 UTC",
      "updated_date": "2024-12-31 08:52:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:12:49.721587"
    },
    {
      "arxiv_id": "2501.00346v1",
      "title": "CNC: Cross-modal Normality Constraint for Unsupervised Multi-class Anomaly Detection",
      "title_zh": "CNC：跨模态正常",
      "authors": [
        "Xiaolei Wang",
        "Xiaoyang Wang",
        "Huihui Bai",
        "Eng Gee Lim",
        "Jimin Xiao"
      ],
      "abstract": "Existing unsupervised distillation-based methods rely on the differences\nbetween encoded and decoded features to locate abnormal regions in test images.\nHowever, the decoder trained only on normal samples still reconstructs abnormal\npatch features well, degrading performance. This issue is particularly\npronounced in unsupervised multi-class anomaly detection tasks. We attribute\nthis behavior to over-generalization(OG) of decoder: the significantly\nincreasing diversity of patch patterns in multi-class training enhances the\nmodel generalization on normal patches, but also inadvertently broadens its\ngeneralization to abnormal patches. To mitigate OG, we propose a novel approach\nthat leverages class-agnostic learnable prompts to capture common textual\nnormality across various visual patterns, and then apply them to guide the\ndecoded features towards a normal textual representation, suppressing\nover-generalization of the decoder on abnormal patterns. To further improve\nperformance, we also introduce a gated mixture-of-experts module to specialize\nin handling diverse patch patterns and reduce mutual interference between them\nin multi-class training. Our method achieves competitive performance on the\nMVTec AD and VisA datasets, demonstrating its effectiveness.",
      "tldr_zh": "本文提出CNC框架，用于解决无监督多类异常检测中的过度泛化（over-generalization）问题，该问题导致解码器在仅用正常样本训练时仍能重构异常区域。方法利用class-agnostic learnable prompts捕捉跨模态的常见文本正常性，并引导解码特征朝向正常表示，从而抑制对异常模式的泛化。同时，引入gated mixture-of-experts模块来处理多样化补丁模式并减少其相互干扰。在MVTec AD和VisA数据集上，该方法实现了竞争性的性能表现。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.00346v1",
      "published_date": "2024-12-31 08:43:44 UTC",
      "updated_date": "2024-12-31 08:43:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:13:01.363140"
    },
    {
      "arxiv_id": "2501.00343v1",
      "title": "Chunk-Distilled Language Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Yanhong Li",
        "Karen Livescu",
        "Jiawei Zhou"
      ],
      "abstract": "We introduce Chunk-Distilled Language Modeling (CD-LM), an approach to text\ngeneration that addresses two challenges in current large language models\n(LLMs): the inefficiency of token-level generation, and the difficulty of\nadapting to new data and knowledge. Our method combines deep network-based LLMs\nwith a straightforward retrieval module, which allows the generation of\nmulti-token text chunks at a single decoding step. Our retrieval framework\nenables flexible construction of model- or domain-specific datastores, either\nleveraging the internal knowledge of existing models, or incorporating expert\ninsights from human-annotated corpora. This adaptability allows for enhanced\ncontrol over the language model's distribution without necessitating additional\ntraining. We present the CD-LM formulation along with performance metrics\ndemonstrating its ability to improve language model performance and efficiency\nacross a diverse set of downstream tasks. Code and data will be made publicly\navailable.",
      "tldr_zh": "我们引入了 Chunk-Distilled Language Modeling (CD-LM)，一种文本生成方法，旨在解决大型语言模型 (LLMs) 在 token-level 生成的低效性和适应新数据知识的挑战。该方法结合深度网络-based LLMs 和一个简单检索模块，允许在单个解码步骤中生成多-token 文本块，并通过灵活构建模型或领域特定的 datastores 来整合内部知识或人类标注的语料库，从而增强对语言模型分布的控制，而无需额外训练。实验结果显示，CD-LM 在各种下游任务中显著提高了语言模型的性能和效率。代码和数据将公开可用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00343v1",
      "published_date": "2024-12-31 08:32:15 UTC",
      "updated_date": "2024-12-31 08:32:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:13:13.210115"
    },
    {
      "arxiv_id": "2501.00334v1",
      "title": "Loss-Aware Curriculum Learning for Chinese Grammatical Error Correction",
      "title_zh": "翻译失败",
      "authors": [
        "Ding Zhang",
        "Yangning Li",
        "Lichen Bai",
        "Hao Zhang",
        "Yinghui Li",
        "Haiye Lin",
        "Hai-Tao Zheng",
        "Xin Su",
        "Zifei Shan"
      ],
      "abstract": "Chinese grammatical error correction (CGEC) aims to detect and correct errors\nin the input Chinese sentences. Recently, Pre-trained Language Models (PLMS)\nhave been employed to improve the performance. However, current approaches\nignore that correction difficulty varies across different instances and treat\nthese samples equally, enhancing the challenge of model learning. To address\nthis problem, we propose a multi-granularity Curriculum Learning (CL)\nframework. Specifically, we first calculate the correction difficulty of these\nsamples and feed them into the model from easy to hard batch by batch. Then\nInstance-Level CL is employed to help the model optimize in the appropriate\ndirection automatically by regulating the loss function. Extensive experimental\nresults and comprehensive analyses of various datasets prove the effectiveness\nof our method.",
      "tldr_zh": "这篇论文针对 Chinese Grammatical Error Correction (CGEC) 问题，提出了一种 Loss-Aware Curriculum Learning (CL) 框架，以解决现有基于 Pre-trained Language Models (PLMs) 的方法忽略样本修正难度差异的问题。该框架通过多粒度策略，首先计算样本难度并按从易到难的顺序喂入模型，然后采用 Instance-Level CL 来调节损失函数，实现模型的自动优化。实验结果在各种数据集上证明了该方法的有效性，提高了 CGEC 的整体性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ICASSP 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.00334v1",
      "published_date": "2024-12-31 08:11:49 UTC",
      "updated_date": "2024-12-31 08:11:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:14:06.703770"
    },
    {
      "arxiv_id": "2501.01991v2",
      "title": "A Hybrid Deep Learning and Model-Checking Framework for Accurate Brain Tumor Detection and Validation",
      "title_zh": "翻译失败",
      "authors": [
        "Elhoucine Elfatimi",
        "Lahcen El Fatimi",
        "Hanifa Bouchaneb"
      ],
      "abstract": "Model checking, a formal verification technique, ensures systems meet\npredefined requirements, playing a crucial role in minimizing errors and\nenhancing quality during development. This paper introduces a novel hybrid\nframework integrating model checking with deep learning for brain tumor\ndetection and validation in medical imaging. By combining model-checking\nprinciples with CNN-based feature extraction and K-FCM clustering for\nsegmentation, the proposed approach enhances the reliability of tumor detection\nand segmentation. Experimental results highlight the framework's effectiveness,\nachieving 98\\% accuracy, 96.15\\% precision, and 100\\% recall, demonstrating its\npotential as a robust tool for advanced medical image analysis.",
      "tldr_zh": "这篇论文提出了一种新型混合框架，将模型 checking 与深度学习相结合，用于脑肿瘤检测和验证，以提高医疗图像分析的可靠性和准确性。该框架整合了模型 checking 原则、基于 CNN 的特征提取以及 K-FCM 聚类算法来进行肿瘤分割和检测。实验结果显示，该方法在脑肿瘤识别中取得了98% 的准确率、96.15% 的精确率和100% 的召回率，展示了其作为先进医疗图像分析工具的强大潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.2.6; I.4.6"
      ],
      "primary_category": "cs.CV",
      "comment": "22 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.01991v2",
      "published_date": "2024-12-31 08:09:08 UTC",
      "updated_date": "2025-04-29 21:24:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:13:36.667918"
    },
    {
      "arxiv_id": "2501.00330v1",
      "title": "Exploring the Implicit Semantic Ability of Multimodal Large Language Models: A Pilot Study on Entity Set Expansion",
      "title_zh": "探索多模态大语言模型的隐式语义能力：实体集扩展的初步研究",
      "authors": [
        "Hebin Wang",
        "Yangning Li",
        "Yinghui Li",
        "Hai-Tao Zheng",
        "Wenhao Jiang",
        "Hong-Gee Kim"
      ],
      "abstract": "The rapid development of multimodal large language models (MLLMs) has brought\nsignificant improvements to a wide range of tasks in real-world applications.\nHowever, LLMs still exhibit certain limitations in extracting implicit semantic\ninformation. In this paper, we apply MLLMs to the Multi-modal Entity Set\nExpansion (MESE) task, which aims to expand a handful of seed entities with new\nentities belonging to the same semantic class, and multi-modal information is\nprovided with each entity. We explore the capabilities of MLLMs to understand\nimplicit semantic information at the entity-level granularity through the MESE\ntask, introducing a listwise ranking method LUSAR that maps local scores to\nglobal rankings. Our LUSAR demonstrates significant improvements in MLLM's\nperformance on the MESE task, marking the first use of generative MLLM for ESE\ntasks and extending the applicability of listwise ranking.",
      "tldr_zh": "本研究探索了多模态大型语言模型 (MLLMs) 在提取隐式语义信息方面的能力，通过一个试点研究聚焦于多模态实体集扩展 (MESE) 任务，该任务旨在从少量种子实体扩展出属于同一语义类的实体，并利用多模态信息。研究者引入了列表式排名方法 LUSAR，将局部分数映射到全局排名，以提升 MLLMs 在实体级粒度理解隐式语义的能力。实验结果显示，LUSAR 显著提高了 MLLMs 在 MESE 任务上的性能，这是首次将生成式 MLLM 应用于实体集扩展 (ESE) 任务，并扩展了列表式排名的适用性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "ICASSP 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.00330v1",
      "published_date": "2024-12-31 08:03:48 UTC",
      "updated_date": "2024-12-31 08:03:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:14:11.281905"
    },
    {
      "arxiv_id": "2501.14775v1",
      "title": "Hybrid Firefly-Genetic Algorithm for Single and Multi-dimensional 0-1 Knapsack Problems",
      "title_zh": "翻译失败",
      "authors": [
        "Aswathi Malanthara",
        "Ishaan R Kale"
      ],
      "abstract": "This paper addresses the challenges faced by algorithms, such as the Firefly\nAlgorithm (FA) and the Genetic Algorithm (GA), in constrained optimization\nproblems. While both algorithms perform well for unconstrained problems, their\neffectiveness diminishes when constraints are introduced due to limitations in\nexploration, exploitation, and constraint handling. To overcome these\nchallenges, a hybrid FAGA algorithm is proposed, combining the strengths of\nboth algorithms. The hybrid algorithm is validated by solving unconstrained\nbenchmark functions and constrained optimization problems, including design\nengineering problems and combinatorial problems such as the 0-1 Knapsack\nProblem. The proposed algorithm delivers improved solution accuracy and\ncomputational efficiency compared to conventional optimization algorithm. This\npaper outlines the development and structure of the hybrid algorithm and\ndemonstrates its effectiveness in handling complex optimization problems.",
      "tldr_zh": "本研究针对 Firefly Algorithm (FA) 和 Genetic Algorithm (GA) 在约束优化问题中的局限性（如探索、利用和约束处理不足），提出了一种混合 FAGA 算法，将 FA 和 GA 的优势相结合。FAGA 算法通过整合两者的特性，应用于无约束基准函数、设计工程问题以及单维和多维 0-1 Knapsack Problem 等场景。实验结果显示，该算法相较于传统优化算法，显著提高了解决方案的准确性和计算效率，为处理复杂优化问题提供了更有效的工具。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14775v1",
      "published_date": "2024-12-31 08:03:15 UTC",
      "updated_date": "2024-12-31 08:03:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:14:17.612696"
    },
    {
      "arxiv_id": "2501.01458v1",
      "title": "GAN-TAT: A Novel Framework Using Protein Interaction Networks in Druggable Gene Identification",
      "title_zh": "GAN-TAT：一种利用蛋白质互作网络的可药物化基因识别新框架",
      "authors": [
        "George Yuanji Wang",
        "Srisharan Murugesan",
        "Aditya Prince Rohatgi"
      ],
      "abstract": "Identifying druggable genes is essential for developing effective\npharmaceuticals. With the availability of extensive, high-quality data,\ncomputational methods have become a significant asset. Protein Interaction\nNetwork (PIN) is valuable but challenging to implement due to its high\ndimensionality and sparsity. Previous methods relied on indirect integration,\nleading to resolution loss. This study proposes GAN-TAT, a framework utilizing\nan advanced graph embedding technology, ImGAGN, to directly integrate PIN for\ndruggable gene inference work. Tested on three Pharos datasets, GAN-TAT\nachieved the highest AUC-ROC score of 0.951 on Tclin. Further evaluation shows\nthat GAN-TAT's predictions are supported by clinical evidence, highlighting its\npotential practical applications in pharmacogenomics. This research represents\na methodological attempt with the direct utilization of PIN, expanding\npotential new solutions for developing drug targets. The source code of GAN-TAT\nis available at (https://github.com/george-yuanji-wang/GAN-TAT).",
      "tldr_zh": "本研究提出GAN-TAT框架，利用蛋白质相互作用网络(PIN)来识别可药物化基因，解决传统方法在高维和稀疏数据上的间接整合问题。框架采用先进的图嵌入技术ImGAGN，直接整合PIN进行基因推断，并在三个Pharos数据集上进行测试，获得最高AUC-ROC分数0.951（在Tclin上）。结果显示，GAN-TAT的预测得到临床证据支持，具有潜在的应用价值，为药物靶点开发提供新方法。源代码可从GitHub获取。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "4 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.01458v1",
      "published_date": "2024-12-31 07:37:34 UTC",
      "updated_date": "2024-12-31 07:37:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:14:29.912561"
    },
    {
      "arxiv_id": "2501.00321v1",
      "title": "OCRBench v2: An Improved Benchmark for Evaluating Large Multimodal Models on Visual Text Localization and Reasoning",
      "title_zh": "OCRBench v2：评估大型多模态模型在视觉文本定位和推理方面的改进基准",
      "authors": [
        "Ling Fu",
        "Biao Yang",
        "Zhebin Kuang",
        "Jiajun Song",
        "Yuzhe Li",
        "Linghao Zhu",
        "Qidi Luo",
        "Xinyu Wang",
        "Hao Lu",
        "Mingxin Huang",
        "Zhang Li",
        "Guozhi Tang",
        "Bin Shan",
        "Chunhui Lin",
        "Qi Liu",
        "Binghong Wu",
        "Hao Feng",
        "Hao Liu",
        "Can Huang",
        "Jingqun Tang",
        "Wei Chen",
        "Lianwen Jin",
        "Yuliang Liu",
        "Xiang Bai"
      ],
      "abstract": "Scoring the Optical Character Recognition (OCR) capabilities of Large\nMultimodal Models (LMMs) has witnessed growing interest recently. Existing\nbenchmarks have highlighted the impressive performance of LMMs in text\nrecognition; however, their abilities on certain challenging tasks, such as\ntext localization, handwritten content extraction, and logical reasoning,\nremain underexplored. To bridge this gap, we introduce OCRBench v2, a\nlarge-scale bilingual text-centric benchmark with currently the most\ncomprehensive set of tasks (4x more tasks than the previous multi-scene\nbenchmark OCRBench), the widest coverage of scenarios (31 diverse scenarios\nincluding street scene, receipt, formula, diagram, and so on), and thorough\nevaluation metrics, with a total of 10,000 human-verified question-answering\npairs and a high proportion of difficult samples. After carefully benchmarking\nstate-of-the-art LMMs on OCRBench v2, we find that 20 out of 22 LMMs score\nbelow 50 (100 in total) and suffer from five-type limitations, including less\nfrequently encountered text recognition, fine-grained perception, layout\nperception, complex element parsing, and logical reasoning. The benchmark and\nevaluation scripts are available at\nhttps://github.com/Yuliang-liu/MultimodalOCR.",
      "tldr_zh": "本文介绍了 OCRBench v2，这是一个改进的大型双语文本中心基准，用于评估大型多模态模型 (LMMs) 在视觉文本定位和推理方面的能力。相比现有基准，OCRBench v2 包含更多任务（4 倍于之前）、更广泛的场景（31 个多样场景，如街景、收据和公式等），以及全面的评估指标，总计 10,000 个人工验证的问题回答对，其中包括大量困难样本。通过测试 22 个最先进 LMMs，发现 20 个模型得分低于 50（满分 100），暴露了五类限制：不常见文本识别、细粒度感知、布局感知、复杂元素解析和逻辑推理。该基准及其评估脚本可在 GitHub 上获取。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00321v1",
      "published_date": "2024-12-31 07:32:35 UTC",
      "updated_date": "2024-12-31 07:32:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:16:11.619736"
    },
    {
      "arxiv_id": "2501.00320v2",
      "title": "Autonomous Alignment with Human Value on Altruism through Considerate Self-imagination and Theory of Mind",
      "title_zh": "翻译失败",
      "authors": [
        "Haibo Tong",
        "Enmeng Lu",
        "Yinqian Sun",
        "Zhengqiang Han",
        "Chao Liu",
        "Feifei Zhao",
        "Yi Zeng"
      ],
      "abstract": "With the widespread application of Artificial Intelligence (AI) in human\nsociety, enabling AI to autonomously align with human values has become a\npressing issue to ensure its sustainable development and benefit to humanity.\nOne of the most important aspects of aligning with human values is the\nnecessity for agents to autonomously make altruistic, safe, and ethical\ndecisions, considering and caring for human well-being. Current AI extremely\npursues absolute superiority in certain tasks, remaining indifferent to the\nsurrounding environment and other agents, which has led to numerous safety\nrisks. Altruistic behavior in human society originates from humans' capacity\nfor empathizing others, known as Theory of Mind (ToM), combined with predictive\nimaginative interactions before taking action to produce thoughtful and\naltruistic behaviors. Inspired by this, we are committed to endow agents with\nconsiderate self-imagination and ToM capabilities, driving them through\nimplicit intrinsic motivations to autonomously align with human altruistic\nvalues. By integrating ToM within the imaginative space, agents keep an eye on\nthe well-being of other agents in real time, proactively anticipate potential\nrisks to themselves and others, and make thoughtful altruistic decisions that\nbalance negative effects on the environment. The ancient Chinese story of Sima\nGuang Smashes the Vat illustrates the moral behavior of the young Sima Guang\nsmashed a vat to save a child who had accidentally fallen into it, which is an\nexcellent reference scenario for this paper. We design an experimental scenario\nsimilar to Sima Guang Smashes the Vat and its variants with different\ncomplexities, which reflects the trade-offs and comprehensive considerations\nbetween self-goals, altruistic rescue, and avoiding negative side effects.",
      "tldr_zh": "该论文探讨了如何使AI自主对齐人类利他主义（Altruism）价值观，以确保其安全和道德决策。作者提出通过整合Theory of Mind (ToM)与considerate self-imagination能力，让AI在想象空间中实时监控他人福祉、预测潜在风险，并基于隐含内在动机做出平衡自利与利他的决策。实验设计了类似“司马光砸缸”（Sima Guang Smashes the Vat）的场景及其变体，测试AI在处理自我目标、救援他人和避免负面影响时的权衡。总体而言，该方法为AI实现自主伦理对齐提供了新框架，提升了其在复杂社会环境中的可靠性和安全性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00320v2",
      "published_date": "2024-12-31 07:31:46 UTC",
      "updated_date": "2025-01-07 09:25:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:16:54.624857"
    },
    {
      "arxiv_id": "2501.08585v1",
      "title": "A Systematic Review of Machine Learning Methods for Multimodal EEG Data in Clinical Application",
      "title_zh": "针对多模态 EEG 数据在临床应用的机器学习方法系统综述",
      "authors": [
        "Siqi Zhao",
        "Wangyang Li",
        "Xiru Wang",
        "Stevie Foglia",
        "Hongzhao Tan",
        "Bohan Zhang",
        "Ameer Hamoodi",
        "Aimee Nelson",
        "Zhen Gao"
      ],
      "abstract": "Machine learning (ML) and deep learning (DL) techniques have been widely\napplied to analyze electroencephalography (EEG) signals for disease diagnosis\nand brain-computer interfaces (BCI). The integration of multimodal data has\nbeen shown to enhance the accuracy of ML and DL models. Combining EEG with\nother modalities can improve clinical decision-making by addressing complex\ntasks in clinical populations. This systematic literature review explores the\nuse of multimodal EEG data in ML and DL models for clinical applications. A\ncomprehensive search was conducted across PubMed, Web of Science, and Google\nScholar, yielding 16 relevant studies after three rounds of filtering. These\nstudies demonstrate the application of multimodal EEG data in addressing\nclinical challenges, including neuropsychiatric disorders, neurological\nconditions (e.g., seizure detection), neurodevelopmental disorders (e.g.,\nautism spectrum disorder), and sleep stage classification. Data fusion occurred\nat three levels: signal, feature, and decision levels. The most commonly used\nML models were support vector machines (SVM) and decision trees. Notably, 11\nout of the 16 studies reported improvements in model accuracy with multimodal\nEEG data. This review highlights the potential of multimodal EEG-based ML\nmodels in enhancing clinical diagnostics and problem-solving.",
      "tldr_zh": "本文对机器学习（ML）和深度学习（DL）技术在多模态脑电图（EEG）数据临床应用中的方法进行了系统综述，通过搜索PubMed、Web of Science和Google Scholar筛选出16个相关研究。研究涉及神经精神障碍（如癫痫检测）、神经病变和睡眠阶段分类等领域，数据融合发生在信号、特征和决策层面，最常用模型包括支持向量机（SVM）和决策树。结果显示，11个研究报告了多模态EEG数据显著提高了模型准确性，强调了其在增强临床决策和诊断方面的潜力。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "This paper includes 4 figures, 6 tables, and totals 18 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.08585v1",
      "published_date": "2024-12-31 07:20:56 UTC",
      "updated_date": "2024-12-31 07:20:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:15:07.910701"
    },
    {
      "arxiv_id": "2501.00312v1",
      "title": "M2I2: Learning Efficient Multi-Agent Communication via Masked State Modeling and Intention Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Chuxiong Sun",
        "Peng He",
        "Qirui Ji",
        "Zehua Zang",
        "Jiangmeng Li",
        "Rui Wang",
        "Wei Wang"
      ],
      "abstract": "Communication is essential in coordinating the behaviors of multiple agents.\nHowever, existing methods primarily emphasize content, timing, and partners for\ninformation sharing, often neglecting the critical aspect of integrating shared\ninformation. This gap can significantly impact agents' ability to understand\nand respond to complex, uncertain interactions, thus affecting overall\ncommunication efficiency. To address this issue, we introduce M2I2, a novel\nframework designed to enhance the agents' capabilities to assimilate and\nutilize received information effectively. M2I2 equips agents with advanced\ncapabilities for masked state modeling and joint-action prediction, enriching\ntheir perception of environmental uncertainties and facilitating the\nanticipation of teammates' intentions. This approach ensures that agents are\nfurnished with both comprehensive and relevant information, bolstering more\ninformed and synergistic behaviors. Moreover, we propose a Dimensional Rational\nNetwork, innovatively trained via a meta-learning paradigm, to identify the\nimportance of dimensional pieces of information, evaluating their contributions\nto decision-making and auxiliary tasks. Then, we implement an importance-based\nheuristic for selective information masking and sharing. This strategy\noptimizes the efficiency of masked state modeling and the rationale behind\ninformation sharing. We evaluate M2I2 across diverse multi-agent tasks, the\nresults demonstrate its superior performance, efficiency, and generalization\ncapabilities, over existing state-of-the-art methods in various complex\nscenarios.",
      "tldr_zh": "该研究针对多代理通信中的信息整合问题，提出M2I2框架，以提升代理对环境不确定性和队友意图的感知能力。M2I2通过masked state modeling和joint-action prediction，帮助代理有效吸收共享信息并预测意图，同时引入Dimensional Rational Network，利用元学习(meta-learning)评估信息维度的决策贡献，并实现基于重要性的启发式策略优化信息掩盖和共享。实验结果显示，M2I2在多种多代理任务中表现出色，显著超越现有方法，在性能、效率和泛化能力方面均有提升。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00312v1",
      "published_date": "2024-12-31 07:07:28 UTC",
      "updated_date": "2024-12-31 07:07:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:15:59.550224"
    },
    {
      "arxiv_id": "2501.00307v1",
      "title": "Fast and Interpretable Mixed-Integer Linear Program Solving by Learning Model Reduction",
      "title_zh": "通过学习模型简化实现的快速且可解释的混合整数线性规划求解",
      "authors": [
        "Yixuan Li",
        "Can Chen",
        "Jiajun Li",
        "Jiahui Duan",
        "Xiongwei Han",
        "Tao Zhong",
        "Vincent Chau",
        "Weiwei Wu",
        "Wanyuan Wang"
      ],
      "abstract": "By exploiting the correlation between the structure and the solution of\nMixed-Integer Linear Programming (MILP), Machine Learning (ML) has become a\npromising method for solving large-scale MILP problems. Existing ML-based MILP\nsolvers mainly focus on end-to-end solution learning, which suffers from the\nscalability issue due to the high dimensionality of the solution space. Instead\nof directly learning the optimal solution, this paper aims to learn a reduced\nand equivalent model of the original MILP as an intermediate step. The reduced\nmodel often corresponds to interpretable operations and is much simpler,\nenabling us to solve large-scale MILP problems much faster than existing\ncommercial solvers. However, current approaches rely only on the optimal\nreduced model, overlooking the significant preference information of all\nreduced models. To address this issue, this paper proposes a preference-based\nmodel reduction learning method, which considers the relative performance\n(i.e., objective cost and constraint feasibility) of all reduced models on each\nMILP instance as preferences. We also introduce an attention mechanism to\ncapture and represent preference information, which helps improve the\nperformance of model reduction learning tasks. Moreover, we propose a SetCover\nbased pruning method to control the number of reduced models (i.e., labels),\nthereby simplifying the learning process. Evaluation on real-world MILP\nproblems shows that 1) compared to the state-of-the-art model reduction ML\nmethods, our method obtains nearly 20% improvement on solution accuracy, and 2)\ncompared to the commercial solver Gurobi, two to four orders of magnitude\nspeedups are achieved.",
      "tldr_zh": "本研究提出了一种基于机器学习 (ML) 的方法，用于加速和解释 Mixed-Integer Linear Programming (MILP) 问题的求解，通过学习一个减少的等价模型作为中间步骤，以解决现有端到端方法的扩展性问题。该方法引入基于偏好的模型减少学习框架，考虑所有减少模型的相对性能（如目标成本和约束可行性），并利用注意力机制捕捉偏好信息，同时采用基于 SetCover 的修剪方法来简化学习过程。实验结果显示，与最先进的方法相比，该方法在解决方案准确率上提高了近 20%，并比商业求解器 Gurobi 快 2 到 4 个数量级。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00307v1",
      "published_date": "2024-12-31 06:50:42 UTC",
      "updated_date": "2024-12-31 06:50:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:16:04.744771"
    },
    {
      "arxiv_id": "2501.00298v1",
      "title": "Enhancing Deployment-Time Predictive Model Robustness for Code Analysis and Optimization",
      "title_zh": "增强部署时预测模型的鲁棒性",
      "authors": [
        "Huanting Wang",
        "Patrick Lenihan",
        "Zheng Wang"
      ],
      "abstract": "Supervised machine learning techniques have shown promising results in code\nanalysis and optimization problems. However, a learning-based solution can be\nbrittle because minor changes in hardware or application workloads -- such as\nfacing a new CPU architecture or code pattern -- may jeopardize decision\naccuracy, ultimately undermining model robustness. We introduce Prom, an\nopen-source library to enhance the robustness and performance of predictive\nmodels against such changes during deployment. Prom achieves this by using\nstatistical assessments to identify test samples prone to mispredictions and\nusing feedback on these samples to improve a deployed model. We showcase Prom\nby applying it to 13 representative machine learning models across 5 code\nanalysis and optimization tasks. Our extensive evaluation demonstrates that\nProm can successfully identify an average of 96% (up to 100%) of\nmispredictions. By relabeling up to 5% of the Prom-identified samples through\nincremental learning, Prom can help a deployed model achieve a performance\ncomparable to that attained during its model training phase.",
      "tldr_zh": "这篇论文介绍了 Prom，一个开源库，旨在提升机器学习模型在代码分析和优化任务中的部署时鲁棒性，以应对硬件或工作负载变化导致的准确性下降。Prom 通过统计评估识别易出错的测试样本，并利用反馈和增量学习对这些样本进行重新标记，从而改进模型性能。在 13 个代表性模型和 5 个任务的实验中，Prom 成功识别了平均 96%（最高 100%）的错误预测，通过重新标记最多 5% 的样本，使模型性能恢复到训练时的水平。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00298v1",
      "published_date": "2024-12-31 06:17:03 UTC",
      "updated_date": "2024-12-31 06:17:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:15:54.465919"
    },
    {
      "arxiv_id": "2501.00296v1",
      "title": "Predicate Invention from Pixels via Pretrained Vision-Language Models",
      "title_zh": "通过预训练视觉语言模型从像素中发明谓词",
      "authors": [
        "Ashay Athalye",
        "Nishanth Kumar",
        "Tom Silver",
        "Yichao Liang",
        "Tomás Lozano-Pérez",
        "Leslie Pack Kaelbling"
      ],
      "abstract": "Our aim is to learn to solve long-horizon decision-making problems in\nhighly-variable, combinatorially-complex robotics domains given raw sensor\ninput in the form of images. Previous work has shown that one way to achieve\nthis aim is to learn a structured abstract transition model in the form of\nsymbolic predicates and operators, and then plan within this model to solve\nnovel tasks at test time. However, these learned models do not ground directly\ninto pixels from just a handful of demonstrations. In this work, we propose to\ninvent predicates that operate directly over input images by leveraging the\ncapabilities of pretrained vision-language models (VLMs). Our key idea is that,\ngiven a set of demonstrations, a VLM can be used to propose a set of predicates\nthat are potentially relevant for decision-making and then to determine the\ntruth values of these predicates in both the given demonstrations and new image\ninputs. We build upon an existing framework for predicate invention, which\ngenerates feature-based predicates operating on object-centric states, to also\ngenerate visual predicates that operate on images. Experimentally, we show that\nour approach -- pix2pred -- is able to invent semantically meaningful\npredicates that enable generalization to novel, complex, and long-horizon tasks\nacross two simulated robotic environments.",
      "tldr_zh": "这篇论文提出了一种方法，即利用预训练的 Vision-Language Models (VLMs) 从像素直接发明谓词，以解决长时决策问题在高度可变、组合复杂机器人领域的挑战。关键想法是基于少量演示，让 VLM 提出潜在相关的谓词，并评估这些谓词在演示和新图像中的真值，从而扩展现有谓词发明框架到图像操作。实验结果显示，该方法（pix2pred）在两个模拟机器人环境中成功发明语义有意义的谓词，实现对新颖、复杂和长时任务的泛化。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Workshop on Planning in the Era of LLMs (LM4Plan @ AAAI 2025)",
      "pdf_url": "http://arxiv.org/pdf/2501.00296v1",
      "published_date": "2024-12-31 06:14:16 UTC",
      "updated_date": "2024-12-31 06:14:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:17:01.144737"
    },
    {
      "arxiv_id": "2501.00289v2",
      "title": "Dual Diffusion for Unified Image Generation and Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Zijie Li",
        "Henry Li",
        "Yichun Shi",
        "Amir Barati Farimani",
        "Yuval Kluger",
        "Linjie Yang",
        "Peng Wang"
      ],
      "abstract": "Diffusion models have gained tremendous success in text-to-image generation,\nyet still lag behind with visual understanding tasks, an area dominated by\nautoregressive vision-language models. We propose a large-scale and fully\nend-to-end diffusion model for multi-modal understanding and generation that\nsignificantly improves on existing diffusion-based multimodal models, and is\nthe first of its kind to support the full suite of vision-language modeling\ncapabilities. Inspired by the multimodal diffusion transformer (MM-DiT) and\nrecent advances in discrete diffusion language modeling, we leverage a\ncross-modal maximum likelihood estimation framework that simultaneously trains\nthe conditional likelihoods of both images and text jointly under a single loss\nfunction, which is back-propagated through both branches of the diffusion\ntransformer. The resulting model is highly flexible and capable of a wide range\nof tasks including image generation, captioning, and visual question answering.\nOur model attained competitive performance compared to recent unified image\nunderstanding and generation models, demonstrating the potential of multimodal\ndiffusion modeling as a promising alternative to autoregressive next-token\nprediction models.",
      "tldr_zh": "该研究提出了一种统一的Dual Diffusion模型，用于图像生成和理解任务，旨在提升diffusion models在视觉语言任务中的性能，同时挑战autoregressive vision-language models的主导地位。\n模型基于MM-DiT和离散diffusion语言建模，采用跨模态最大似然估计框架，在单一损失函数下联合训练图像和文本的条件似然，实现端到端的多模态处理。\n该模型支持图像生成、标题生成和视觉问答等多种任务，并在性能上与现有统一模型竞争，展示了多模态diffusion建模作为autoregressive next-token prediction的潜在替代方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00289v2",
      "published_date": "2024-12-31 05:49:00 UTC",
      "updated_date": "2025-04-01 19:09:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:16:42.702459"
    },
    {
      "arxiv_id": "2501.00277v1",
      "title": "Efficient Human-in-the-Loop Active Learning: A Novel Framework for Data Labeling in AI Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Yiran Huang",
        "Jian-Feng Yang",
        "Haoda Fu"
      ],
      "abstract": "Modern AI algorithms require labeled data. In real world, majority of data\nare unlabeled. Labeling the data are costly. this is particularly true for some\nareas requiring special skills, such as reading radiology images by physicians.\nTo most efficiently use expert's time for the data labeling, one promising\napproach is human-in-the-loop active learning algorithm. In this work, we\npropose a novel active learning framework with significant potential for\napplication in modern AI systems. Unlike the traditional active learning\nmethods, which only focus on determining which data point should be labeled,\nour framework also introduces an innovative perspective on incorporating\ndifferent query scheme. We propose a model to integrate the information from\ndifferent types of queries. Based on this model, our active learning frame can\nautomatically determine how the next question is queried. We further developed\na data driven exploration and exploitation framework into our active learning\nmethod. This method can be embedded in numerous active learning algorithms.\nThrough simulations on five real-world datasets, including a highly complex\nreal image task, our proposed active learning framework exhibits higher\naccuracy and lower loss compared to other methods.",
      "tldr_zh": "该论文提出了一种高效的 Human-in-the-Loop Active Learning 框架，用于优化 AI 系统中的数据标记过程，尤其针对未标记数据成本高昂的领域，如放射图像分析。该框架不仅选择需要标记的数据点，还创新性地整合不同查询方案，并通过一个模型自动决定下一个查询策略，同时引入数据驱动的探索和利用机制，以提升主动学习算法的灵活性。在五个真实世界数据集上的模拟实验中，该框架显示出比传统方法更高的准确性和更低的损失，具有广泛的实际应用潜力。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00277v1",
      "published_date": "2024-12-31 05:12:51 UTC",
      "updated_date": "2024-12-31 05:12:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:17:07.734122"
    },
    {
      "arxiv_id": "2501.01457v1",
      "title": "Reinforcing Thinking through Reasoning-Enhanced Reward Models",
      "title_zh": "翻译失败",
      "authors": [
        "Diji Yang",
        "Linda Zeng",
        "Kezhen Chen",
        "Yi Zhang"
      ],
      "abstract": "Large Language Models (LLMs) exhibit great potential in complex multi-step\nreasoning through inference-time thinking but still struggle with deciding when\nto stop thinking due to limited self-awareness about their knowledge\nboundaries. While human preference alignment has shown extraordinary\nopportunities, expensive labeling challenges adherence to scaling law. Language\nmodel self-critique, as an alternative to using human-labeled reasoning data,\nis questioned with its inherited biases. This work addresses these challenges\nby distilling the LLM's own reasoning processes into synthetic behavioral data,\neliminating the need for manual labeling of intermediate steps. Building on\nthis concept, we propose Distillation-Reinforcement-Reasoning (DRR), a\nthree-step framework that leverages the LLM's inherent behaviors as external\nfeedback by first generating behavioral data using the Reasoner (LLM) to\nreflect its reasoning capabilities, then training a lightweight discriminative\nreward model (DM) on behavioral data, and finally deploying the DM at inference\ntime to assist the Reasoner's decision-making. Experiments on multiple\nbenchmarks show that the DRR framework outperforms self-critique approaches\nwithout relying on additional complex data annotation. Benefiting from\nlightweight design, ease of replication, and adaptability, DRR is applicable to\na wide range of LLM-centric tasks.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)在多步推理中存在的决策问题，特别是缺乏自知之明，无法判断何时停止思考，并指出了人类偏好对齐和自评方法的局限性。为解决这些挑战，作者提出Distillation-Reinforcement-Reasoning (DRR)框架，该框架通过蒸馏LLMs的推理过程生成合成行为数据，然后训练一个轻量级判别奖励模型(DM)，并在推理时使用DM辅助Reasoner的决策过程，从而无需手动标注。实验结果显示，DRR在多个基准上优于自评方法，提供更高的性能，同时其轻量级设计、易复制性和适应性使其适用于广泛的LLM相关任务。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.01457v1",
      "published_date": "2024-12-31 04:50:15 UTC",
      "updated_date": "2024-12-31 04:50:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:17:20.348777"
    },
    {
      "arxiv_id": "2501.00264v1",
      "title": "Enhancing Wireless Sensor Network Security through Integration with the ServiceNow Cloud Platform",
      "title_zh": "通过与 ServiceNow 云平台的整合增强无线传感器网络安全",
      "authors": [
        "Syed Atif Ali",
        "Salwa Din"
      ],
      "abstract": "Wireless Sensor Networks (WSNs) continue to experience rapid developments and\nintegration into modern-day applications. Overall, WSNs collect and process\nrelevant data through sensors or nodes and communicate with different networks\nfor superior information management. Nevertheless, a primary concern relative\nto WSNs is security. Considering the high constraints on throughput, battery,\nprocessing power, and memory, typical security procedures present limitations\nfor application in WSNs. This research focuses on the integration of WSNs with\nthe cloud platform, specifically to address these security risks. The cloud\nplatform also adopts a security-driven approach and has attracted many\napplications across various sectors globally. This research specifically\nexplores how cloud computing could be exploited to impede Denial of Service\nattacks from endangering WSNs. WSNs are now deployed in various low-powered\napplications, including disaster management, homeland security, battlefield\nsurveillance, agriculture, and the healthcare industry. WSNs are distinguished\nfrom traditional networks by the numerous wireless connected sensors being\ndeployed to conduct an assigned task. In testing scenarios, the size of WSNs\nranges from a few to several thousand. The overarching requirements of WSNs\ninclude rapid processing of collected data, low-cost installation and\nmaintenance, and low latency in network operations. Given that a substantial\namount of WSN applications are used in high-risk and volatile environments,\nthey must effectively address security concerns. This includes the secure\nmovement, storage, and communication of data through networks, an environment\nin which WSNs are notably vulnerable. The limitations of WSNs have meant that\nthey are predominantly used in unsecured applications despite positive\nadvancements. This study explores methods for integrating the WSN with the\ncloud.",
      "tldr_zh": "本研究探讨了通过将 Wireless Sensor Networks (WSNs) 与 ServiceNow 云平台集成，以提升其安全性的方法。WSNs 因资源限制（如电池和处理能力）而难以应用传统安全措施，因此论文重点分析了如何利用云计算来防范 Denial of Service (DoS) 攻击，确保数据在传输、存储和通信过程中的安全性。该方法针对 WSNs 在高风险环境（如灾害管理、医疗和战场监控）的应用，提供低成本、低延迟的解决方案，并为未来 WSNs 部署提供了潜在改进路径。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "68M18"
      ],
      "primary_category": "cs.CR",
      "comment": "17 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.00264v1",
      "published_date": "2024-12-31 04:17:17 UTC",
      "updated_date": "2024-12-31 04:17:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:17:31.413961"
    },
    {
      "arxiv_id": "2501.00261v1",
      "title": "Collaborative Approaches to Enhancing Smart Vehicle Cybersecurity by AI-Driven Threat Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Syed Atif Ali",
        "Salwa Din"
      ],
      "abstract": "The introduction sets the stage for exploring collaborative approaches to\nbolstering smart vehicle cybersecurity through AI-driven threat detection. As\nthe automotive industry increasingly adopts connected and automated vehicles\n(CAVs), the need for robust cybersecurity measures becomes paramount. With the\nemergence of new vulnerabilities and security requirements, the integration of\nadvanced technologies such as 5G networks, blockchain, and quantum computing\npresents promising avenues for enhancing CAV cybersecurity . Additionally, the\nroadmap for cybersecurity in autonomous vehicles emphasizes the importance of\nefficient intrusion detection systems and AI-based techniques, along with the\nintegration of secure hardware, software stacks, and advanced threat\nintelligence to address cybersecurity challenges in future autonomous vehicles.",
      "tldr_zh": "这篇论文探讨了通过协作方法和 AI 驱动的威胁检测来增强智能车辆 (CAVs) 网络安全的策略。随着汽车行业采用连接和自动车辆，网络安全需求日益紧迫。论文强调整合新技术，如 5G networks、blockchain 和 quantum computing，以应对新漏洞，并提出使用入侵检测系统、AI-based 技术以及安全硬件和软件堆栈的路线图。这些方法有助于构建高效的威胁情报系统，提高未来自主车辆的网络安全水平。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "C.2.1 Network Architecture and Design"
      ],
      "primary_category": "cs.CR",
      "comment": "7 Pages",
      "pdf_url": "http://arxiv.org/pdf/2501.00261v1",
      "published_date": "2024-12-31 04:08:42 UTC",
      "updated_date": "2024-12-31 04:08:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:17:43.318752"
    },
    {
      "arxiv_id": "2501.00254v1",
      "title": "Automatically Planning Optimal Parallel Strategy for Large Language Models",
      "title_zh": "自动规划大型语言模型的最优并行策略",
      "authors": [
        "Zongbiao Li",
        "Xiezhao Li",
        "Yinghao Cui",
        "Yijun Chen",
        "Zhixuan Gu",
        "Yuxuan Liu",
        "Wenbo Zhu",
        "Fei Jia",
        "Ke Liu",
        "Qifeng Li",
        "Junyao Zhan",
        "Jiangtao Zhou",
        "Chenxi Zhang",
        "Qike Liu"
      ],
      "abstract": "The number of parameters in large-scale language models based on transformers\nis gradually increasing, and the scale of computing clusters is also growing.\nThe technology of quickly mobilizing large amounts of computing resources for\nparallel computing is becoming increasingly important. In this paper, we\npropose an automatic parallel algorithm that automatically plans the parallel\nstrategy with maximum throughput based on model and hardware information. By\ndecoupling the training time into computation, communication, and overlap, we\nestablished a training duration simulation model. Based on this simulation\nmodel, we prune the parallel solution space to shorten the search time\nrequired. The multi-node experiment results show that the algorithm can\nestimate the parallel training duration in real time with an average accuracy\nof 96%. In our test, the recommendation strategy provided by the algorithm is\nalways globally optimal.",
      "tldr_zh": "这篇论文提出了一种自动并行算法，用于根据模型和硬件信息规划 large language models 的最优 parallel strategy，以最大化 throughput。算法通过将训练时间分解为 computation、communication 和 overlap，建立了一个训练持续时间模拟模型，并修剪 parallel solution space 来缩短搜索时间。实验结果显示，该算法能实时估计并行训练持续时间，平均准确率达到96%，且推荐的策略始终是全局最优的。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00254v1",
      "published_date": "2024-12-31 03:51:14 UTC",
      "updated_date": "2024-12-31 03:51:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:19:25.736915"
    },
    {
      "arxiv_id": "2501.00241v1",
      "title": "Exploring Variability in Fine-Tuned Models for Text Classification with DistilBERT",
      "title_zh": "使用 DistilBERT 探索文本分类微调模型中的变异性",
      "authors": [
        "Giuliano Lorenzoni",
        "Ivens Portugal",
        "Paulo Alencar",
        "Donald Cowan"
      ],
      "abstract": "This study evaluates fine-tuning strategies for text classification using the\nDistilBERT model, specifically the\ndistilbert-base-uncased-finetuned-sst-2-english variant. Through structured\nexperiments, we examine the influence of hyperparameters such as learning rate,\nbatch size, and epochs on accuracy, F1-score, and loss. Polynomial regression\nanalyses capture foundational and incremental impacts of these hyperparameters,\nfocusing on fine-tuning adjustments relative to a baseline model.\n  Results reveal variability in metrics due to hyperparameter configurations,\nshowing trade-offs among performance metrics. For example, a higher learning\nrate reduces loss in relative analysis (p=0.027) but challenges accuracy\nimprovements. Meanwhile, batch size significantly impacts accuracy and F1-score\nin absolute regression (p=0.028 and p=0.005) but has limited influence on loss\noptimization (p=0.170). The interaction between epochs and batch size maximizes\nF1-score (p=0.001), underscoring the importance of hyperparameter interplay.\n  These findings highlight the need for fine-tuning strategies addressing\nnon-linear hyperparameter interactions to balance performance across metrics.\nSuch variability and metric trade-offs are relevant for tasks beyond text\nclassification, including NLP and computer vision. This analysis informs\nfine-tuning strategies for large language models and promotes adaptive designs\nfor broader model applicability.",
      "tldr_zh": "本研究探讨了使用 DistilBERT（具体为 distilbert-base-uncased-finetuned-sst-2-english 变体）进行文本分类时的微调策略，通过结构化实验分析学习率、batch size 和 epochs 等超参数对 accuracy、F1-score 和 loss 的影响。结果显示，超参数配置导致指标显著变异，例如更高学习率可降低 loss（p=0.027），但可能损害 accuracy，而 batch size 对 accuracy 和 F1-score 有显著影响（p=0.028 和 p=0.005），epochs 与 batch size 的互动可最大化 F1-score（p=0.001）。这些发现强调了处理非线性超参数互动的重要性，以平衡性能指标，并为大语言模型的微调策略提供指导，适用于文本分类以外的 NLP 和计算机视觉任务。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00241v1",
      "published_date": "2024-12-31 03:16:15 UTC",
      "updated_date": "2024-12-31 03:16:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:18:08.136364"
    },
    {
      "arxiv_id": "2501.01989v1",
      "title": "CRRG-CLIP: Automatic Generation of Chest Radiology Reports and Classification of Chest Radiographs",
      "title_zh": "翻译失败",
      "authors": [
        "Jianfei Xu",
        "Thanet Markchom",
        "Huizhi Liang"
      ],
      "abstract": "The complexity of stacked imaging and the massive number of radiographs make\nwriting radiology reports complex and inefficient. Even highly experienced\nradiologists struggle to maintain accuracy and consistency in interpreting\nradiographs under prolonged high-intensity work. To address these issues, this\nwork proposes the CRRG-CLIP Model (Chest Radiology Report Generation and\nRadiograph Classification Model), an end-to-end model for automated report\ngeneration and radiograph classification. The model consists of two modules:\nthe radiology report generation module and the radiograph classification\nmodule. The generation module uses Faster R-CNN to identify anatomical regions\nin radiographs, a binary classifier to select key regions, and GPT-2 to\ngenerate semantically coherent reports. The classification module uses the\nunsupervised Contrastive Language Image Pretraining (CLIP) model, addressing\nthe challenges of high-cost labelled datasets and insufficient features. The\nresults show that the generation module performs comparably to high-performance\nbaseline models on BLEU, METEOR, and ROUGE-L metrics, and outperformed the\nGPT-4o model on BLEU-2, BLEU-3, BLEU-4, and ROUGE-L metrics. The classification\nmodule significantly surpasses the state-of-the-art model in AUC and Accuracy.\nThis demonstrates that the proposed model achieves high accuracy, readability,\nand fluency in report generation, while multimodal contrastive training with\nunlabelled radiograph-report pairs enhances classification performance.",
      "tldr_zh": "本研究提出 CRRG-CLIP 模型，一个端到端系统，用于自动生成胸部放射学报告和分类放射图，以解决放射报告生成过程中的复杂性和低效性问题。模型由两个模块组成：报告生成模块使用 Faster R-CNN 识别解剖区域、二元分类器选择关键区域，以及 GPT-2 生成语义连贯的报告；放射图分类模块则采用无监督的 CLIP 模型，处理标注数据集成本高和特征不足的挑战。实验结果显示，生成模块在 BLEU、METEOR 和 ROUGE-L 指标上与高性能基线相当，并优于 GPT-4o；在 AUC 和 Accuracy 指标上，分类模块显著超越最先进模型。该模型提升了报告的准确性、可读性和流畅性，并通过多模态对比训练利用无标签数据增强了分类性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.01989v1",
      "published_date": "2024-12-31 03:07:27 UTC",
      "updated_date": "2024-12-31 03:07:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:18:22.719651"
    },
    {
      "arxiv_id": "2501.00230v2",
      "title": "Federated Deep Subspace Clustering",
      "title_zh": "联邦深度子空间聚类",
      "authors": [
        "Yupei Zhang",
        "Ruojia Feng",
        "Yifei Wang",
        "Xuequn Shang"
      ],
      "abstract": "This paper introduces FDSC, a private-protected subspace clustering (SC)\napproach with federated learning (FC) schema. In each client, there is a deep\nsubspace clustering network accounting for grouping the isolated data, composed\nof a encode network, a self-expressive layer, and a decode network. FDSC is\nachieved by uploading the encode network to communicate with other clients in\nthe server. Besides, FDSC is also enhanced by preserving the local neighborhood\nrelationship in each client. With the effects of federated learning and\nlocality preservation, the learned data features from the encoder are boosted\nso as to enhance the self-expressiveness learning and result in better\nclustering performance. Experiments test FDSC on public datasets and compare\nwith other clustering methods, demonstrating the effectiveness of FDSC.",
      "tldr_zh": "本论文引入了 FDSC，一种基于联邦学习 (FL) 的隐私保护子空间聚类 (SC) 方法，用于处理分布式数据聚类问题。FDSC 在每个客户端部署一个深度子空间聚类网络，包括 encode network、自表达层和 decode network，通过上传 encode network 到服务器实现客户端间通信，同时保留局部邻域关系以提升特征学习。得益于联邦学习和局部性保留机制，该方法增强了自表达学习能力，从而提高了聚类性能。实验在公共数据集上与其它聚类方法比较，证明了 FDSC 的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "68T07",
        "I.5.3"
      ],
      "primary_category": "cs.LG",
      "comment": "8pages,4 figures, 4 Tables",
      "pdf_url": "http://arxiv.org/pdf/2501.00230v2",
      "published_date": "2024-12-31 02:46:29 UTC",
      "updated_date": "2025-01-16 02:28:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:18:31.175816"
    },
    {
      "arxiv_id": "2501.01454v3",
      "title": "A Fourfold Pathogen Reference Ontology Suite",
      "title_zh": "翻译失败",
      "authors": [
        "Shane Babcock",
        "Carter Benson",
        "Giacomo De Colle",
        "Sydney Cohen",
        "Alexander D. Diehl",
        "Ram A. N. R. Challa",
        "Ray Mavrovich",
        "Joshua Billig",
        "Anthony Huffman",
        "Yongqun He",
        "John Beverley"
      ],
      "abstract": "Infectious diseases remain a critical global health challenge, and the\nintegration of standardized ontologies plays a vital role in managing related\ndata. The Infectious Disease Ontology (IDO) and its extensions, such as the\nCoronavirus Infectious Disease Ontology (CIDO), are essential for organizing\nand disseminating information related to infectious diseases. The COVID-19\npandemic highlighted the need for updating IDO and its virus-specific\nextensions. There is an additional need to update IDO extensions specific to\nbacteria, fungus, and parasite infectious diseases. We adopt the \"hub and\nspoke\" methodology to generate pathogen-specific extensions of IDO: Virus\nInfectious Disease Ontology (VIDO), Bacteria Infectious Disease Ontology\n(BIDO), Mycosis Infectious Disease Ontology (MIDO), and Parasite Infectious\nDisease Ontology (PIDO). The creation of pathogen-specific reference ontologies\nadvances modularization and reusability of infectious disease data within the\nIDO ecosystem. Future work will focus on further refining these ontologies,\ncreating new extensions, and developing application ontologies based on them,\nin line with ongoing efforts to standardize biological and biomedical\nterminologies for improved data sharing and analysis.",
      "tldr_zh": "该研究针对传染病数据管理的需求，更新了Infectious Disease Ontology (IDO)及其扩展，利用“hub and spoke”方法开发了四个病原体特定本体：Virus Infectious Disease Ontology (VIDO)、Bacteria Infectious Disease Ontology (BIDO)、Mycosis Infectious Disease Ontology (MIDO) 和 Parasite Infectious Disease Ontology (PIDO)。这些扩展提升了传染病数据的模块化和可重用性，特别是在COVID-19疫情的背景下。未来工作将进一步完善这些本体、创建新扩展，并开发基于它们的应用本体，以标准化生物和生物医学术语，促进数据共享和分析。",
      "categories": [
        "q-bio.OT",
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "q-bio.OT",
      "comment": "25 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.01454v3",
      "published_date": "2024-12-31 02:34:49 UTC",
      "updated_date": "2025-04-24 20:50:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:19:19.367879"
    },
    {
      "arxiv_id": "2501.00226v1",
      "title": "Generative Emergent Communication: Large Language Model is a Collective World Model",
      "title_zh": "生成式涌现通信：大型语言模型是一种集体世界模型",
      "authors": [
        "Tadahiro Taniguchi",
        "Ryo Ueda",
        "Tomoaki Nakamura",
        "Masahiro Suzuki",
        "Akira Taniguchi"
      ],
      "abstract": "This study proposes a unifying theoretical framework called generative\nemergent communication (generative EmCom) that bridges emergent communication,\nworld models, and large language models (LLMs) through the lens of collective\npredictive coding (CPC). The proposed framework formalizes the emergence of\nlanguage and symbol systems through decentralized Bayesian inference across\nmultiple agents, extending beyond conventional discriminative model-based\napproaches to emergent communication. This study makes the following two key\ncontributions: First, we propose generative EmCom as a novel framework for\nunderstanding emergent communication, demonstrating how communication emergence\nin multi-agent reinforcement learning (MARL) can be derived from control as\ninference while clarifying its relationship to conventional discriminative\napproaches. Second, we propose a mathematical formulation showing the\ninterpretation of LLMs as collective world models that integrate multiple\nagents' experiences through CPC. The framework provides a unified theoretical\nfoundation for understanding how shared symbol systems emerge through\ncollective predictive coding processes, bridging individual cognitive\ndevelopment and societal language evolution. Through mathematical formulations\nand discussion on prior works, we demonstrate how this framework explains\nfundamental aspects of language emergence and offers practical insights for\nunderstanding LLMs and developing sophisticated AI systems for improving\nhuman-AI interaction and multi-agent systems.",
      "tldr_zh": "这篇论文提出了一种统一的理论框架generative emergent communication (generative EmCom)，通过collective predictive coding (CPC)将emergent communication、世界模型和大型语言模型(LLMs)联系起来，解释了语言和符号系统的分散式Bayesian推理机制。论文的主要贡献包括：第一，将generative EmCom应用于多智能体强化学习(MARL)，从control as inference角度导出通信的出现，并与传统discriminative方法进行比较；第二，提供数学公式，将LLMs视为collective world models，通过CPC整合多个智能体的经验。总体而言，该框架为理解语言的个体认知发展和社会演化提供了基础，并为提升人机交互和多智能体系统的发展提供实际见解。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00226v1",
      "published_date": "2024-12-31 02:23:10 UTC",
      "updated_date": "2024-12-31 02:23:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:19:02.000452"
    },
    {
      "arxiv_id": "2501.00224v1",
      "title": "Extracting effective solutions hidden in large language models via generated comprehensive specialists: case studies in developing electronic devices",
      "title_zh": "翻译失败",
      "authors": [
        "Hikari Tomita",
        "Nobuhiro Nakamura",
        "Shoichi Ishida",
        "Toshio Kamiya",
        "Kei Terayama"
      ],
      "abstract": "Recently, many studies have increasingly explored the use of large language\nmodels (LLMs) to generate research ideas and scientific hypotheses. However,\nreal-world research and development often require solving complex,\ninterdisciplinary challenges where solutions may not be readily found through\nexisting knowledge related to the problem. Therefore, it is desirable to\nleverage the vast, comprehensive knowledge of LLMs to generate effective,\nbreakthrough solutions by integrating various perspectives from other\ndisciplines. Here, we propose SELLM (Solution Enumeration via comprehensive\nList and LLM), a framework leveraging LLMs and structured guidance using MECE\n(Mutually Exclusive, Collectively Exhaustive) principles, such as International\nPatent Classification (IPC) and the periodic table of elements. SELLM\nsystematically constructs comprehensive expert agents from the list to generate\ncross-disciplinary and effective solutions. To evaluate SELLM's practicality,\nwe applied it to two challenges: improving light extraction in organic\nlight-emitting diode (OLED) lighting and developing electrodes for\nnext-generation memory materials. The results demonstrate that SELLM\nsignificantly facilitates the generation of effective solutions compared to\ncases without specific customization or effort, showcasing the potential of\nSELLM to enable LLMs to generate effective solutions even for challenging\nproblems.",
      "tldr_zh": "本研究探讨了如何从大型语言模型 (LLMs) 中提取有效的解决方案，针对复杂跨学科问题提出 SELLM (Solution Enumeration via comprehensive List and LLM) 框架。SELLM 利用 MECE (Mutually Exclusive, Collectively Exhaustive) 原则，如 International Patent Classification (IPC) 和元素周期表，构建综合专家代理来系统生成跨领域解决方案。研究通过两个实际案例验证了框架的实用性，包括改善有机发光二极管 (OLED) 照明的光提取效率和开发下一代记忆材料电极。结果显示，SELLM 相较于无定制方法显著提升了解决方案的生成效果，展示了 LLMs 在解决挑战性问题的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.00224v1",
      "published_date": "2024-12-31 02:20:56 UTC",
      "updated_date": "2024-12-31 02:20:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:21:15.564236"
    },
    {
      "arxiv_id": "2501.00223v1",
      "title": "CancerKG.ORG A Web-scale, Interactive, Verifiable Knowledge Graph-LLM Hybrid for Assisting with Optimal Cancer Treatment and Care",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Gubanov",
        "Anna Pyayt",
        "Aleksandra Karolak"
      ],
      "abstract": "Here, we describe one of the first Web-scale hybrid Knowledge Graph\n(KG)-Large Language Model (LLM), populated with the latest peer-reviewed\nmedical knowledge on colorectal Cancer. It is currently being evaluated to\nassist with both medical research and clinical information retrieval tasks at\nMoffitt Cancer Center, which is one of the top Cancer centers in the U.S. and\nin the world. Our hybrid is remarkable as it serves the user needs better than\njust an LLM, KG or a search-engine in isolation. LLMs as is are known to\nexhibit hallucinations and catastrophic forgetting as well as are trained on\noutdated corpora. The state of the art KGs, such as PrimeKG, cBioPortal,\nChEMBL, NCBI, and other require manual curation, hence are quickly getting\nstale. CancerKG is unsupervised and is capable of automatically ingesting and\norganizing the latest medical findings. To alleviate the LLMs shortcomings, the\nverified KG serves as a Retrieval Augmented Generation (RAG) guardrail.\nCancerKG exhibits 5 different advanced user interfaces, each tailored to serve\ndifferent data modalities better and more convenient for the user.",
      "tldr_zh": "本文介绍了CancerKG.ORG，一个Web-scale的混合系统，结合Knowledge Graph (KG) 和 Large Language Model (LLM)，用于辅助结直肠癌的治疗和护理。该系统通过无监督方式自动摄取并组织最新同行评审医疗知识，并采用Retrieval Augmented Generation (RAG) 技术来缓解LLM的幻觉和过时问题，提供比独立LLM、KG或搜索引擎更优的表现。CancerKG.ORG 配备5种高级用户界面，针对不同数据模式提升用户交互，并在Moffitt Cancer Center的评估中展示其在医疗研究和临床信息检索中的潜力。",
      "categories": [
        "cs.AI",
        "cs.IR",
        "cs.LG",
        "68T09"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00223v1",
      "published_date": "2024-12-31 02:19:16 UTC",
      "updated_date": "2024-12-31 02:19:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:22:21.207899"
    },
    {
      "arxiv_id": "2501.00217v1",
      "title": "The Potential of LLMs in Automating Software Testing: From Generation to Reporting",
      "title_zh": "LLMs 在自动化软件测试中的",
      "authors": [
        "Betim Sherifi",
        "Khaled Slhoub",
        "Fitzroy Nembhard"
      ],
      "abstract": "Having a high quality software is essential in software engineering, which\nrequires robust validation and verification processes during testing\nactivities. Manual testing, while effective, can be time consuming and costly,\nleading to an increased demand for automated methods. Recent advancements in\nLarge Language Models (LLMs) have significantly influenced software\nengineering, particularly in areas like requirements analysis, test automation,\nand debugging. This paper explores an agent-oriented approach to automated\nsoftware testing, using LLMs to reduce human intervention and enhance testing\nefficiency. The proposed framework integrates LLMs to generate unit tests,\nvisualize call graphs, and automate test execution and reporting. Evaluations\nacross multiple applications in Python and Java demonstrate the system's high\ntest coverage and efficient operation. This research underscores the potential\nof LLM-powered agents to streamline software testing workflows while addressing\nchallenges in scalability and accuracy.",
      "tldr_zh": "这篇论文探讨了 Large Language Models (LLMs) 在软件测试自动化中的潜力，旨在通过减少人为干预来提升测试效率。提出的框架采用代理导向的方法，整合 LLMs 生成单元测试、可视化调用图、自动化测试执行和报告。实验评估在 Python 和 Java 的多个应用中显示了高测试覆盖率和高效操作，同时解决了可扩展性和准确性的挑战。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "6 pages, 3 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2501.00217v1",
      "published_date": "2024-12-31 02:06:46 UTC",
      "updated_date": "2024-12-31 02:06:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:22:30.279976"
    },
    {
      "arxiv_id": "2501.00210v2",
      "title": "Debunking the CUDA Myth Towards GPU-based AI Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Yunjae Lee",
        "Juntaek Lim",
        "Jehyeon Bang",
        "Eunyeong Cho",
        "Huijong Jeong",
        "Taesu Kim",
        "Hyungjun Kim",
        "Joonhyung Lee",
        "Jinseop Im",
        "Ranggi Hwang",
        "Se Jung Kwon",
        "Dongsoo Lee",
        "Minsoo Rhu"
      ],
      "abstract": "This paper presents a comprehensive evaluation of Intel Gaudi NPUs as an\nalternative to NVIDIA GPUs, which is currently the de facto standard in AI\nsystem design. First, we create a suite of microbenchmarks to compare Intel\nGaudi-2 with NVIDIA A100, showing that Gaudi-2 achieves competitive performance\nnot only in primitive AI compute, memory, and communication operations but also\nin executing several important AI workloads end-to-end. We then assess Gaudi\nNPU's programmability by discussing several software-level optimization\nstrategies to employ for implementing critical FBGEMM operators and vLLM,\nevaluating their efficiency against GPU-optimized counterparts. Results\nindicate that Gaudi-2 achieves energy efficiency comparable to A100, though\nthere are notable areas for improvement in terms of software maturity. Overall,\nwe conclude that, with effective integration into high-level AI frameworks,\nGaudi NPUs could challenge NVIDIA GPU's dominance in the AI server market,\nthough further improvements are necessary to fully compete with NVIDIA's robust\nsoftware ecosystem.",
      "tldr_zh": "这篇论文评估了Intel Gaudi NPUs作为NVIDIA GPUs在AI系统设计中的替代方案，旨在挑战NVIDIA的CUDA主导地位。研究者通过创建微基准测试套件，比较了Intel Gaudi-2与NVIDIA A100在AI计算、内存、通信操作以及端到端工作负载上的性能，发现Gaudi-2表现出竞争性表现，并在能效方面与A100相当。论文还探讨了软件级优化策略，如实现FBGEMM操作符和vLLM，以评估Gaudi NPU的可编程性，结果显示虽然软件成熟度有待提升，但Gaudi NPUs若有效集成到高级AI框架中，可能颠覆NVIDIA在AI服务器市场的垄断地位。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.DC",
      "comment": "Accepted for publication at the 52nd IEEE/ACM International Symposium\n  on Computer Architecture (ISCA-52), 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.00210v2",
      "published_date": "2024-12-31 01:24:52 UTC",
      "updated_date": "2025-03-22 02:32:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:22:26.142847"
    },
    {
      "arxiv_id": "2501.00208v1",
      "title": "An Empirical Evaluation of Large Language Models on Consumer Health Questions",
      "title_zh": "翻译失败",
      "authors": [
        "Moaiz Abrar",
        "Yusuf Sermet",
        "Ibrahim Demir"
      ],
      "abstract": "This study evaluates the performance of several Large Language Models (LLMs)\non MedRedQA, a dataset of consumer-based medical questions and answers by\nverified experts extracted from the AskDocs subreddit. While LLMs have shown\nproficiency in clinical question answering (QA) benchmarks, their effectiveness\non real-world, consumer-based, medical questions remains less understood.\nMedRedQA presents unique challenges, such as informal language and the need for\nprecise responses suited to non-specialist queries. To assess model\nperformance, responses were generated using five LLMs: GPT-4o mini, Llama 3.1:\n70B, Mistral-123B, Mistral-7B, and Gemini-Flash. A cross-evaluation method was\nused, where each model evaluated its responses as well as those of others to\nminimize bias. The results indicated that GPT-4o mini achieved the highest\nalignment with expert responses according to four out of the five models'\njudges, while Mistral-7B scored lowest according to three out of five models'\njudges. This study highlights the potential and limitations of current LLMs for\nconsumer health medical question answering, indicating avenues for further\ndevelopment.",
      "tldr_zh": "本研究评估了多个 Large Language Models (LLMs) 在 MedRedQA 数据集上的表现，该数据集包含来自 AskDocs subreddit 的消费者医疗问题及其专家答案，以检验 LLMs 处理真实世界、非正式语言查询的能力。研究方法涉及使用 GPT-4o mini、Llama 3.1: 70B、Mistral-123B、Mistral-7B 和 Gemini-Flash 等模型生成响应，并采用交叉评估策略，让每个模型评估自身和其他模型的输出，以减少偏见。结果显示，GPT-4o mini 被四个模型评为最符合专家响应，而 Mistral-7B 被三个模型评为最低；这突出了 LLMs 在消费者健康问答中的潜力和局限性，并为未来模型开发提供了方向。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00208v1",
      "published_date": "2024-12-31 01:08:15 UTC",
      "updated_date": "2024-12-31 01:08:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:22:04.157923"
    },
    {
      "arxiv_id": "2501.00199v1",
      "title": "GPT-4 on Clinic Depression Assessment: An LLM-Based Pilot Study",
      "title_zh": "翻译失败",
      "authors": [
        "Giuliano Lorenzoni",
        "Pedro Elkind Velmovitsky",
        "Paulo Alencar",
        "Donald Cowan"
      ],
      "abstract": "Depression has impacted millions of people worldwide and has become one of\nthe most prevalent mental disorders. Early mental disorder detection can lead\nto cost savings for public health agencies and avoid the onset of other major\ncomorbidities. Additionally, the shortage of specialized personnel is a\ncritical issue because clinical depression diagnosis is highly dependent on\nexpert professionals and is time consuming.\n  In this study, we explore the use of GPT-4 for clinical depression assessment\nbased on transcript analysis. We examine the model's ability to classify\npatient interviews into binary categories: depressed and not depressed. A\ncomparative analysis is conducted considering prompt complexity (e.g., using\nboth simple and complex prompts) as well as varied temperature settings to\nassess the impact of prompt complexity and randomness on the model's\nperformance.\n  Results indicate that GPT-4 exhibits considerable variability in accuracy and\nF1-Score across configurations, with optimal performance observed at lower\ntemperature values (0.0-0.2) for complex prompts. However, beyond a certain\nthreshold (temperature >= 0.3), the relationship between randomness and\nperformance becomes unpredictable, diminishing the gains from prompt\ncomplexity.\n  These findings suggest that, while GPT-4 shows promise for clinical\nassessment, the configuration of the prompts and model parameters requires\ncareful calibration to ensure consistent results. This preliminary study\ncontributes to understanding the dynamics between prompt engineering and large\nlanguage models, offering insights for future development of AI-powered tools\nin clinical settings.",
      "tldr_zh": "本研究探讨了使用GPT-4进行临床抑郁评估，通过分析患者访谈转录，将其分类为抑郁或非抑郁，以解决专业人员短缺和诊断耗时的问题。研究比较了不同提示复杂性（如简单和复杂提示）和温度设置的影响，结果显示GPT-4在较低温度（0.0-0.2）下结合复杂提示时，准确性和F1-Score表现最佳，但温度达到0.3或更高时，性能变得不可预测。总体而言，此初步LLM-based研究强调了提示工程的重要性，并为开发AI辅助临床工具提供了宝贵见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00199v1",
      "published_date": "2024-12-31 00:32:43 UTC",
      "updated_date": "2024-12-31 00:32:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:22:45.935953"
    },
    {
      "arxiv_id": "2501.03254v1",
      "title": "Advanced Displacement Magnitude Prediction in Multi-Material Architected Lattice Structure Beams Using Physics Informed Neural Network Architecture",
      "title_zh": "翻译失败",
      "authors": [
        "Akshansh Mishra"
      ],
      "abstract": "This paper proposes an innovative method for predicting deformation in\narchitected lattice structures that combines Physics-Informed Neural Networks\n(PINNs) with finite element analysis. A thorough study was carried out on\nFCC-based lattice beams utilizing five different materials (Structural Steel,\nAA6061, AA7075, Ti6Al4V, and Inconel 718) under varied edge loads (1000-10000\nN). The PINN model blends data-driven learning with physics-based limitations\nvia a proprietary loss function, resulting in much higher prediction accuracy\nthan linear regression. PINN outperforms linear regression, achieving greater\nR-square (0.7923 vs 0.5686) and lower error metrics (MSE: 0.00017417 vs\n0.00036187). Among the materials examined, AA6061 had the highest displacement\nsensitivity (0.1014 mm at maximum load), while Inconel718 had better structural\nstability.",
      "tldr_zh": "本论文提出了一种创新方法，使用 Physics-Informed Neural Networks (PINNs) 结合有限元分析，来预测多材料架构化格子结构梁（基于 FCC）的变形，研究对象包括五种材料（Structural Steel、AA6061、AA7075、Ti6Al4V 和 Inconel 718）在1000-10000 N边缘负载下的表现。PINN 模型通过专有损失函数融合数据驱动学习和物理约束，显著提高了预测准确性，与线性回归相比，其 R-square 值提升至0.7923（线性回归为0.5686），MSE 也降低至0.00017417（线性回归为0.00036187）。研究发现，AA6061 显示出最高的位移敏感性（最大负载下0.1014 mm），而 Inconel 718 具有更好的结构稳定性，为工程应用中的变形预测提供了更可靠的工具。",
      "categories": [
        "cs.AI",
        "cond-mat.mtrl-sci",
        "cs.CE",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "34 pages, 19 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.03254v1",
      "published_date": "2024-12-31 00:15:58 UTC",
      "updated_date": "2024-12-31 00:15:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:23:22.632996"
    },
    {
      "arxiv_id": "2501.00195v1",
      "title": "Towards Unraveling and Improving Generalization in World Models",
      "title_zh": "翻译失败",
      "authors": [
        "Qiaoyi Fang",
        "Weiyu Du",
        "Hang Wang",
        "Junshan Zhang"
      ],
      "abstract": "World models have recently emerged as a promising approach to reinforcement\nlearning (RL), achieving state-of-the-art performance across a wide range of\nvisual control tasks. This work aims to obtain a deep understanding of the\nrobustness and generalization capabilities of world models. Thus motivated, we\ndevelop a stochastic differential equation formulation by treating the world\nmodel learning as a stochastic dynamical system, and characterize the impact of\nlatent representation errors on robustness and generalization, for both cases\nwith zero-drift representation errors and with non-zero-drift representation\nerrors. Our somewhat surprising findings, based on both theoretic and\nexperimental studies, reveal that for the case with zero drift, modest latent\nrepresentation errors can in fact function as implicit regularization and hence\nresult in improved robustness. We further propose a Jacobian regularization\nscheme to mitigate the compounding error propagation effects of non-zero drift,\nthereby enhancing training stability and robustness. Our experimental studies\ncorroborate that this regularization approach not only stabilizes training but\nalso accelerates convergence and improves accuracy of long-horizon prediction.",
      "tldr_zh": "该研究旨在深入理解世界模型（world models）在强化学习（RL）中的鲁棒性和泛化能力，通过将世界模型学习视为随机微分方程（stochastic differential equation）框架来分析潜在表示错误（latent representation errors）的冲击。研究发现，对于零漂移错误情况，适度的错误可作为隐式正则化，从而提升鲁棒性；针对非零漂移错误，则提出雅可比正则化（Jacobian regularization）方案，以减轻错误传播效应。实验结果显示，该方案不仅稳定训练过程、加速收敛，还提高了长horizon预测的准确性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "An earlier version of this paper was submitted to NeurIPS and\n  received ratings of (7, 6, 6). The reviewers' comments and the original draft\n  are available at OpenReview. This version contains minor modifications based\n  on that submission",
      "pdf_url": "http://arxiv.org/pdf/2501.00195v1",
      "published_date": "2024-12-31 00:15:43 UTC",
      "updated_date": "2024-12-31 00:15:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:23:28.362771"
    },
    {
      "arxiv_id": "2501.00190v2",
      "title": "SepsisCalc: Integrating Clinical Calculators into Early Sepsis Prediction via Dynamic Temporal Graph Construction",
      "title_zh": "翻译失败",
      "authors": [
        "Changchang Yin",
        "Shihan Fu",
        "Bingsheng Yao",
        "Thai-Hoang Pham",
        "Weidan Cao",
        "Dakuo Wang",
        "Jeffrey Caterino",
        "Ping Zhang"
      ],
      "abstract": "Sepsis is an organ dysfunction caused by a deregulated immune response to an\ninfection. Early sepsis prediction and identification allow for timely\nintervention, leading to improved clinical outcomes. Clinical calculators\n(e.g., the six-organ dysfunction assessment of SOFA) play a vital role in\nsepsis identification within clinicians' workflow, providing evidence-based\nrisk assessments essential for sepsis diagnosis. However, artificial\nintelligence (AI) sepsis prediction models typically generate a single sepsis\nrisk score without incorporating clinical calculators for assessing organ\ndysfunctions, making the models less convincing and transparent to clinicians.\nTo bridge the gap, we propose to mimic clinicians' workflow with a novel\nframework SepsisCalc to integrate clinical calculators into the predictive\nmodel, yielding a clinically transparent and precise model for utilization in\nclinical settings. Practically, clinical calculators usually combine\ninformation from multiple component variables in Electronic Health Records\n(EHR), and might not be applicable when the variables are (partially) missing.\nWe mitigate this issue by representing EHRs as temporal graphs and integrating\na learning module to dynamically add the accurately estimated calculator to the\ngraphs. Experimental results on real-world datasets show that the proposed\nmodel outperforms state-of-the-art methods on sepsis prediction tasks.\nMoreover, we developed a system to identify organ dysfunctions and potential\nsepsis risks, providing a human-AI interaction tool for deployment, which can\nhelp clinicians understand the prediction outputs and prepare timely\ninterventions for the corresponding dysfunctions, paving the way for actionable\nclinical decision-making support for early intervention.",
      "tldr_zh": "本文提出SepsisCalc框架，旨在将临床计算器（如SOFA）整合到脓毒症（Sepsis）早期预测模型中，以提升模型的临床透明度和准确性。通过动态时间图（Dynamic Temporal Graph Construction）表示EHR数据，并使用学习模块动态估算缺失变量，该框架模仿临床工作流程进行预测。实验在真实数据集上显示，SepsisCalc优于现有AI方法，并开发了人机交互系统，帮助临床医生识别器官功能障碍并及时干预，促进可行动的临床决策。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00190v2",
      "published_date": "2024-12-31 00:02:07 UTC",
      "updated_date": "2025-01-09 20:00:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T19:23:10.066133"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 78,
  "processed_papers_count": 78,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-21T19:23:44.173953"
}