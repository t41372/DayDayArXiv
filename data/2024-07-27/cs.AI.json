{
  "date": "2024-07-27",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-07-27 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 更新了 31 篇论文，主要聚焦 AI 模型（如 Large Language Models, LLMs）的应用创新，包括自动驾驶、医疗诊断和文本处理等领域，令人印象深刻的是 LLMs 在实现“类人”自动驾驶和多模态蛋白编辑的潜力，以及多篇被接受到知名会议（如 NAACL 2025 和 KDD 2024）的论文，这些工作突出了 AI 在实际场景中的伦理、安全和泛化挑战。\n\n下面，我挑选并简要讨论几篇重要的论文，先从 AI 和 LLMs 相关的高话题度文章开始，然后快速掠过其他领域的关键贡献。限于篇幅，我会优先突出创新性和影响大的论文，对于较常规或次要的（如某些图像处理或教育工具），仅简要概述。\n\n### 1. Large Language Models for Human-like Autonomous Driving: A Survey（大型语言模型用于类人自动驾驶：调查）\n   - **主要贡献和发现**：这篇综述论文探讨了 LLMs 如何推动自动驾驶从规则-based 转向知识-based 系统，强调 LLMs 在模块化和端到端系统中提升“类人”决策的能力。作者 Yun Li 等指出，LLMs 能改善实时推理，但面临实时性、安全和部署成本挑战。该论文被接受到 IEEE ITSC 2024，提供了未来研究方向，如桥接 LLMs 与自动驾驶的鸿沟。\n\n### 2. Integrating Large Language Models into a Tri-Modal Architecture for Automated Depression Classification on the DAIC-WOZ（将大型语言模型集成到三模态架构中用于自动化抑郁分类）\n   - **主要贡献和发现**：作者 Santosh V. Patapati 提出了一种 BiLSTM-based 三模态模型，结合 Mel Frequency Cepstral Coefficients、Facial Action Units 和 GPT-4 处理文本数据，实现抑郁诊断。该模型在 DAIC-WOZ 数据集上达到 91.01% 准确率，超越了现有基线，展示了 LLMs 在生物医学信息学中的潜力，关键词包括 Multi-Modal Neural Networks 和 Deep Learning。\n\n### 3. Multi-Modal CLIP-Informed Protein Editing（多模态 CLIP 指导的蛋白编辑）\n   - **主要贡献和发现**：作者 Mingze Yin 等开发了 ProtET 方法，使用 LLMs 和 CLIP 进行蛋白序列编辑，支持基于生物文本指令的优化。该模型在酶催化活性、蛋白稳定性和抗体结合能力上提升显著（如稳定性改善 16.67%），比现有方法有较大优势，突出了机器学习在蛋白工程中的应用前景。\n\n### 4. Inference-Time Selective Debiasing to Enhance Fairness in Text Classification Models（推理时选择性去偏置以提升文本分类模型的公平性）\n   - **主要贡献和发现**：作者 Gleb Kuzmin 等提出了一种推理时机制，使用 KL 散度识别偏置预测，并应用 LEACE 方法去除偏置。该方法在文本分类中减少了性能差距，被接受到 NAACL 2025，强调了 AI 公平性的实际意义。\n\n### 5. CoLiDR: Concept Learning using Aggregated Disentangled Representations（使用聚合分离表示的概念学习）\n   - **主要贡献和发现**：作者 Sanchit Sinha 等设计了 CoLiDR 框架，将分离表示学习与概念聚合结合，解释 DNN 的推理逻辑。该方法在 KDD 2024 中表现突出，能聚合生成因素为可解释概念，提升了模型泛化性。\n\n其他论文中，相关主题如图像和视频处理、医疗诊断也有亮点，但影响较小，我快速掠过：\n- **AResNet-ViT: A Hybrid CNN-Transformer Network for Benign and Malignant Breast Nodule Classification in Ultrasound Images（AResNet-ViT: 混合 CNN-Transformer 网络用于超声图像中乳腺结节良恶性分类）**：提出双分支网络融合 CNN 和 Transformer，提升了乳腺结节分类准确性。\n- **Semantic Communication Enhanced by Knowledge Graph Representation Learning（知识图表示学习增强的语义通信）**：利用 LLMs 和 GNNs 实现高压缩率语义传输，被 SPAWC 接受。\n- **AgentPeerTalk: Empowering Students through Agentic-AI-Driven Discernment of Bullying and Joking（AgentPeerTalk: 通过代理 AI 驱动的欺凌和开玩笑辨识赋能学生）**：使用 LLMs 如 ChatGPT-4 检测学校欺凌，强调 AI 在教育中的社会影响。\n- 其余如社交媒体假新闻检测（A Semi-supervised Fake News Detection）、蛋白编辑（Mamba-UIE）和自动驾驶综述等，贡献在于技术优化，但未有突破性创新，故从简。\n\n总之，今天的论文展示了 AI 的广泛应用潜力，特别是 LLMs 在跨领域的泛化能力，但也提醒我们关注伦理和安全问题。感兴趣的读者可查阅 arXiv 以深入探索！",
  "papers": [
    {
      "arxiv_id": "2407.19351v1",
      "title": "AccessShare: Co-designing Data Access and Sharing with Blind People",
      "title_zh": "AccessShare：与盲人共同设计数据访问和共享",
      "authors": [
        "Rie Kamikubo",
        "Farnaz Zamiri Zeraati",
        "Kyungjun Lee",
        "Hernisa Kacorri"
      ],
      "abstract": "Blind people are often called to contribute image data to datasets for AI\ninnovation with the hope for future accessibility and inclusion. Yet, the\nvisual inspection of the contributed images is inaccessible. To this day, we\nlack mechanisms for data inspection and control that are accessible to the\nblind community. To address this gap, we engage 10 blind participants in a\nscenario where they wear smartglasses and collect image data using an\nAI-infused application in their homes. We also engineer a design probe, a novel\ndata access interface called AccessShare, and conduct a co-design study to\ndiscuss participants' needs, preferences, and ideas on consent, data\ninspection, and control. Our findings reveal the impact of interactive informed\nconsent and the complementary role of data inspection systems such as\nAccessShare in facilitating communication between data stewards and blind data\ncontributors. We discuss how key insights can guide future informed consent and\ndata control to promote inclusive and responsible data practices in AI.",
      "tldr_zh": "本研究探讨了盲人参与AI数据贡献的挑战，特别是图像数据的视觉检查对他们不可访问的问题。研究者通过让10名盲人参与者使用智能眼镜和AI增强应用收集家庭图像数据，并开发了AccessShare接口作为设计探针，进行联合设计(co-design)研究，以探讨他们的同意、数据检查和控制需求。结果显示，交互式informed consent能显著提升参与感，而AccessShare等系统有助于数据管理者与盲人贡献者之间的沟通；这些发现为推动AI中的包容性和负责任数据实践提供了关键指导。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Preprint, The 26th International ACM SIGACCESS Conference on\n  Computers and Accessibility (ASSETS 2024)",
      "pdf_url": "http://arxiv.org/pdf/2407.19351v1",
      "published_date": "2024-07-27 23:39:58 UTC",
      "updated_date": "2024-07-27 23:39:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T10:32:52.906068"
    },
    {
      "arxiv_id": "2407.19349v1",
      "title": "Predicting T-Cell Receptor Specificity",
      "title_zh": "预测 T 细胞受体特异性",
      "authors": [
        "Tengyao Tu",
        "Wei Zeng",
        "Kun Zhao",
        "Zhenyu Zhang"
      ],
      "abstract": "Researching the specificity of TCR contributes to the development of\nimmunotherapy and provides new opportunities and strategies for personalized\ncancer immunotherapy. Therefore, we established a TCR generative specificity\ndetection framework consisting of an antigen selector and a TCR classifier\nbased on the Random Forest algorithm, aiming to efficiently screen out TCRs and\ntarget antigens and achieve TCR specificity prediction. Furthermore, we used\nthe k-fold validation method to compare the performance of our model with\nordinary deep learning methods. The result proves that adding a classifier to\nthe model based on the random forest algorithm is very effective, and our model\ngenerally outperforms ordinary deep learning methods. Moreover, we put forward\nfeasible optimization suggestions for the shortcomings and challenges of our\nmodel found during model implementation.",
      "tldr_zh": "本研究开发了一个TCR生成特异性检测框架，包括基于Random Forest算法的抗原选择器和TCR分类器，旨在高效筛选TCR和目标抗原，实现T细胞受体(TCR)特异性预测，以推进免疫疗法和个性化癌症免疫治疗。框架通过k-fold交叉验证方法与普通深度学习方法比较，结果显示该模型整体表现更优，特别是添加Random Forest分类器后显著提升了有效性。该研究还针对模型的缺点和挑战提出了可行优化建议。",
      "categories": [
        "q-bio.QM",
        "cs.AI"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.19349v1",
      "published_date": "2024-07-27 23:21:07 UTC",
      "updated_date": "2024-07-27 23:21:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T10:33:27.457746"
    },
    {
      "arxiv_id": "2407.19345v4",
      "title": "Inference-Time Selective Debiasing to Enhance Fairness in Text Classification Models",
      "title_zh": "推理时选择性去偏置以增强文本分类模型的公平性",
      "authors": [
        "Gleb Kuzmin",
        "Neemesh Yadav",
        "Ivan Smirnov",
        "Timothy Baldwin",
        "Artem Shelmanov"
      ],
      "abstract": "We propose selective debiasing -- an inference-time safety mechanism designed\nto enhance the overall model quality in terms of prediction performance and\nfairness, especially in scenarios where retraining the model is impractical.\nThe method draws inspiration from selective classification, where at inference\ntime, predictions with low quality, as indicated by their uncertainty scores,\nare discarded. In our approach, we identify the potentially biased model\npredictions and, instead of discarding them, we remove bias from these\npredictions using LEACE -- a post-processing debiasing method. To select\nproblematic predictions, we propose a bias quantification approach based on KL\ndivergence, which achieves better results than standard uncertainty\nquantification methods. Experiments on text classification datasets with\nencoder-based classification models demonstrate that selective debiasing helps\nto reduce the performance gap between post-processing methods and debiasing\ntechniques from the at-training and pre-processing categories.",
      "tldr_zh": "该论文提出了 selective debiasing，一种推理时的安全机制，旨在提升文本分类模型的预测性能和公平性，尤其适用于无法重新训练模型的场景。该方法借鉴 selective classification 的理念，通过基于 KL divergence 的偏见量化方法识别潜在偏见预测，并使用 LEACE 后处理去偏技术来去除这些偏见，而非直接丢弃。实验在文本分类数据集上表明，selective debiasing 显著缩小了后处理方法与训练时或预处理去偏技术的性能差距，提高了整体模型质量。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2407.19345v4",
      "published_date": "2024-07-27 21:56:23 UTC",
      "updated_date": "2025-03-11 08:39:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T10:33:17.807538"
    },
    {
      "arxiv_id": "2407.19340v5",
      "title": "Integrating Large Language Models into a Tri-Modal Architecture for Automated Depression Classification on the DAIC-WOZ",
      "title_zh": "翻译失败",
      "authors": [
        "Santosh V. Patapati"
      ],
      "abstract": "Major Depressive Disorder (MDD) is a pervasive mental health condition that\naffects 300 million people worldwide. This work presents a novel, BiLSTM-based\ntri-modal model-level fusion architecture for the binary classification of\ndepression from clinical interview recordings. The proposed architecture\nincorporates Mel Frequency Cepstral Coefficients, Facial Action Units, and uses\na two-shot learning based GPT-4 model to process text data. This is the first\nwork to incorporate large language models into a multi-modal architecture for\nthis task. It achieves impressive results on the DAIC-WOZ AVEC 2016 Challenge\ncross-validation split and Leave-One-Subject-Out cross-validation split,\nsurpassing all baseline models and multiple state-of-the-art models. In\nLeave-One-Subject-Out testing, it achieves an accuracy of 91.01%, an F1-Score\nof 85.95%, a precision of 80%, and a recall of 92.86%.",
      "tldr_zh": "这篇论文提出了一种基于 BiLSTM 的三模态融合架构，用于从临床访谈录音中进行抑郁症的二元分类，旨在解决 Major Depressive Disorder 的诊断问题。架构整合了 Mel Frequency Cepstral Coefficients（音频特征）、Facial Action Units（面部动作单位）和基于两-shot learning 的 GPT-4 处理文本数据，这是首次将大型语言模型融入多模态系统。实验结果显示，该模型在 DAIC-WOZ AVEC 2016 挑战的交叉验证中超越所有基线和最先进模型，在 Leave-One-Subject-Out 测试中达到 91.01% 准确率、85.95% F1-Score 和 92.86% 召回率。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Keywords: Multi-Modal Neural Networks, Deep Learning, Large Language\n  Models, Depression Diagnosis, Biomedical Informatics, DAIC-WOZ",
      "pdf_url": "http://arxiv.org/pdf/2407.19340v5",
      "published_date": "2024-07-27 21:00:36 UTC",
      "updated_date": "2024-10-11 18:52:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T10:33:37.118827"
    },
    {
      "arxiv_id": "2407.19338v1",
      "title": "Semantic Communication Enhanced by Knowledge Graph Representation Learning",
      "title_zh": "知识图谱表示学习增强的语义通信",
      "authors": [
        "Nour Hello",
        "Paolo Di Lorenzo",
        "Emilio Calvanese Strinati"
      ],
      "abstract": "This paper investigates the advantages of representing and processing\nsemantic knowledge extracted into graphs within the emerging paradigm of\nsemantic communications. The proposed approach leverages semantic and pragmatic\naspects, incorporating recent advances on large language models (LLMs) to\nachieve compact representations of knowledge to be processed and exchanged\nbetween intelligent agents. This is accomplished by using the cascade of LLMs\nand graph neural networks (GNNs) as semantic encoders, where information to be\nshared is selected to be meaningful at the receiver. The embedding vectors\nproduced by the proposed semantic encoder represent information in the form of\ntriplets: nodes (semantic concepts entities), edges(relations between\nconcepts), nodes. Thus, semantic information is associated with the\nrepresentation of relationships among elements in the space of semantic concept\nabstractions. In this paper, we investigate the potential of achieving high\ncompression rates in communication by incorporating relations that link\nelements within graph embeddings. We propose sending semantic symbols solely\nequivalent to node embeddings through the wireless channel and inferring the\ncomplete knowledge graph at the receiver. Numerical simulations illustrate the\neffectiveness of leveraging knowledge graphs to semantically compress and\ntransmit information.",
      "tldr_zh": "本文提出了一种利用知识图谱表示学习增强语义通信的方法，通过整合大型语言模型(LLMs)和图神经网络(GNNs)作为语义编码器，实现知识的紧凑表示和高效传输。方法将语义信息编码为三元组形式（节点、边、节点），并仅通过无线通道发送节点嵌入向量，在接收端推断完整的知识图谱，从而实现高压缩率。实验模拟结果显示，该方法显著提高了语义信息的压缩和传输效率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted for publication at the 25th IEEE International Workshop on\n  Signal Processing Advances in Wireless Communications (SPAWC)",
      "pdf_url": "http://arxiv.org/pdf/2407.19338v1",
      "published_date": "2024-07-27 20:57:10 UTC",
      "updated_date": "2024-07-27 20:57:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T10:33:39.813004"
    },
    {
      "arxiv_id": "2407.19332v1",
      "title": "A Semi-supervised Fake News Detection using Sentiment Encoding and LSTM with Self-Attention",
      "title_zh": "翻译失败",
      "authors": [
        "Pouya Shaeri",
        "Ali Katanforoush"
      ],
      "abstract": "Micro-blogs and cyber-space social networks are the main communication\nmediums to receive and share news nowadays. As a side effect, however, the\nnetworks can disseminate fake news that harms individuals and the society.\nSeveral methods have been developed to detect fake news, but the majority\nrequire large sets of manually labeled data to attain the application-level\naccuracy. Due to the strict privacy policies, the required data are often\ninaccessible or limited to some specific topics. On the other side, quite\ndiverse and abundant unlabeled data on social media suggests that with a few\nlabeled data, the problem of detecting fake news could be tackled via\nsemi-supervised learning. Here, we propose a semi-supervised self-learning\nmethod in which a sentiment analysis is acquired by some state-of-the-art\npretrained models. Our learning model is trained in a semi-supervised fashion\nand incorporates LSTM with self-attention layers. We benchmark our model on a\ndataset with 20,000 news content along with their feedback, which shows better\nperformance in precision, recall, and measures compared to competitive methods\nin fake news detection.",
      "tldr_zh": "该论文提出了一种半监督(Semi-supervised)假新闻检测方法，通过情感编码(Sentiment Encoding)结合 LSTM 和自注意力(Self-Attention)层，实现对社交媒体新闻的自动分析，以解决标注数据不足的问题。方法采用自学习(Self-learning)框架，利用预训练情感分析模型在少量标注数据上训练，并在未标注数据上扩展学习。实验结果显示，该模型在包含 20,000 条新闻的数据集上，精确率、召回率和其他指标均优于竞争方法，为高效的假新闻检测提供了新途径。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.19332v1",
      "published_date": "2024-07-27 20:00:10 UTC",
      "updated_date": "2024-07-27 20:00:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T10:33:58.449862"
    },
    {
      "arxiv_id": "2407.19316v1",
      "title": "AResNet-ViT: A Hybrid CNN-Transformer Network for Benign and Malignant Breast Nodule Classification in Ultrasound Images",
      "title_zh": "翻译失败",
      "authors": [
        "Xin Zhao",
        "Qianqian Zhu",
        "Jialing Wu"
      ],
      "abstract": "To address the challenges of similarity between lesions and surrounding\ntissues, overlapping appearances of partially benign and malignant nodules, and\ndifficulty in classification, a deep learning network that integrates CNN and\nTransformer is proposed for the classification of benign and malignant breast\nlesions in ultrasound images. This network adopts a dual-branch architecture\nfor local-global feature extraction, making full use of the advantages of CNN\nin extracting local features and the ability of ViT to extract global features\nto enhance the network's feature extraction capabilities for breast nodules.\nThe local feature extraction branch employs a residual network with multiple\nattention-guided modules, which can effectively capture the local details and\ntexture features of breast nodules, enhance sensitivity to subtle changes\nwithin the nodules, and thus can aid in accurate classification of their benign\nand malignancy. The global feature extraction branch utilizes the multi-head\nself-attention ViT network, which can capture the overall shape, boundary, and\nrelationship with surrounding tissues, and thereby enhancing the understanding\nand modeling of both nodule and global image features. Experimental results on\na public ultrasound breast nodule data set show that the proposed method is\nbetter than other comparison networks, This indicates that the fusion of CNN\nand Transformer networks can effectively improve the performance of the\nclassification model and provide a powerful solution for the benign-malignant\nclassification of ultrasound breast.",
      "tldr_zh": "本文提出AResNet-ViT，一种混合CNN-Transformer网络，用于超声图像中乳腺结节的良恶性分类，以解决结节与周围组织相似以及良恶性外观重叠的挑战。该网络采用双分支架构：一个分支使用ResNet结合注意力模块提取局部细节和纹理特征，另一个分支利用ViT的多头自注意力机制捕捉全局形状、边界及周围组织关系，从而增强特征提取能力。在公开数据集上的实验显示，该方法优于其他比较网络，证明了CNN和Transformer融合的有效性，为乳腺结节分类提供强大解决方案。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "12 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.19316v1",
      "published_date": "2024-07-27 18:18:45 UTC",
      "updated_date": "2024-07-27 18:18:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T10:34:10.785910"
    },
    {
      "arxiv_id": "2407.19300v1",
      "title": "CoLiDR: Concept Learning using Aggregated Disentangled Representations",
      "title_zh": "翻译失败",
      "authors": [
        "Sanchit Sinha",
        "Guangzhi Xiong",
        "Aidong Zhang"
      ],
      "abstract": "Interpretability of Deep Neural Networks using concept-based models offers a\npromising way to explain model behavior through human-understandable concepts.\nA parallel line of research focuses on disentangling the data distribution into\nits underlying generative factors, in turn explaining the data generation\nprocess. While both directions have received extensive attention, little work\nhas been done on explaining concepts in terms of generative factors to unify\nmathematically disentangled representations and human-understandable concepts\nas an explanation for downstream tasks. In this paper, we propose a novel\nmethod CoLiDR - which utilizes a disentangled representation learning setup for\nlearning mutually independent generative factors and subsequently learns to\naggregate the said representations into human-understandable concepts using a\nnovel aggregation/decomposition module. Experiments are conducted on datasets\nwith both known and unknown latent generative factors. Our method successfully\naggregates disentangled generative factors into concepts while maintaining\nparity with state-of-the-art concept-based approaches. Quantitative and visual\nanalysis of the learned aggregation procedure demonstrates the advantages of\nour work compared to commonly used concept-based models over four challenging\ndatasets. Lastly, our work is generalizable to an arbitrary number of concepts\nand generative factors - making it flexible enough to be suitable for various\ntypes of data.",
      "tldr_zh": "该论文提出了一种新方法CoLiDR，用于通过聚合解缠表示(disentangled representations)来学习人类可理解的概念，从而统一解释深度神经网络的行为和数据生成过程。CoLiDR首先利用解缠表示学习来获取相互独立的生成因素，然后通过一个新型的聚合/分解模块将这些因素聚合为概念。实验在具有已知和未知生成因素的四个挑战数据集上显示，该方法在概念学习方面与最先进的概念-based模型相当，并通过定量和视觉分析证明了其优势；此外，CoLiDR可推广到任意数量的概念和生成因素，增强了其灵活性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "KDD 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.19300v1",
      "published_date": "2024-07-27 16:55:14 UTC",
      "updated_date": "2024-07-27 16:55:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T10:34:20.107279"
    },
    {
      "arxiv_id": "2407.19296v1",
      "title": "Multi-Modal CLIP-Informed Protein Editing",
      "title_zh": "翻译失败",
      "authors": [
        "Mingze Yin",
        "Hanjing Zhou",
        "Yiheng Zhu",
        "Miao Lin",
        "Yixuan Wu",
        "Jialu Wu",
        "Hongxia Xu",
        "Chang-Yu Hsieh",
        "Tingjun Hou",
        "Jintai Chen",
        "Jian Wu"
      ],
      "abstract": "Proteins govern most biological functions essential for life, but achieving\ncontrollable protein discovery and optimization remains challenging. Recently,\nmachine learning-assisted protein editing (MLPE) has shown promise in\naccelerating optimization cycles and reducing experimental workloads. However,\ncurrent methods struggle with the vast combinatorial space of potential protein\nedits and cannot explicitly conduct protein editing using biotext instructions,\nlimiting their interactivity with human feedback. To fill these gaps, we\npropose a novel method called ProtET for efficient CLIP-informed protein\nediting through multi-modality learning. Our approach comprises two stages: in\nthe pretraining stage, contrastive learning aligns protein-biotext\nrepresentations encoded by two large language models (LLMs), respectively.\nSubsequently, during the protein editing stage, the fused features from editing\ninstruction texts and original protein sequences serve as the final editing\ncondition for generating target protein sequences. Comprehensive experiments\ndemonstrated the superiority of ProtET in editing proteins to enhance\nhuman-expected functionality across multiple attribute domains, including\nenzyme catalytic activity, protein stability and antibody specific binding\nability. And ProtET improves the state-of-the-art results by a large margin,\nleading to significant stability improvements of 16.67% and 16.90%. This\ncapability positions ProtET to advance real-world artificial protein editing,\npotentially addressing unmet academic, industrial, and clinical needs.",
      "tldr_zh": "该研究提出了一种名为 ProtET 的新方法，用于多模态 CLIP-informed 蛋白质编辑，以解决机器学习辅助蛋白质编辑 (MLPE) 在处理巨大组合空间和生物文本指令方面的局限性。ProtET 通过两个阶段实现：预训练阶段使用对比学习对齐蛋白质和生物文本的表示；编辑阶段则融合编辑指令文本与原始蛋白序列特征，生成目标蛋白序列。实验结果显示，ProtET 在酶催化活性、蛋白稳定性和抗体特异性结合能力等多个属性领域显著提升功能表现，比现有最佳方法提高了 16.67% 和 16.90% 的稳定性。这为实际蛋白质编辑提供了高效、可互动的工具，潜在满足学术、工业和临床需求。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages, 7 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2407.19296v1",
      "published_date": "2024-07-27 16:41:08 UTC",
      "updated_date": "2024-07-27 16:41:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T10:35:08.973905"
    },
    {
      "arxiv_id": "2407.19280v1",
      "title": "Large Language Models for Human-like Autonomous Driving: A Survey",
      "title_zh": "大语言模型用于类似人类的自动驾驶：一项综述",
      "authors": [
        "Yun Li",
        "Kai Katsumata",
        "Ehsan Javanmardi",
        "Manabu Tsukada"
      ],
      "abstract": "Large Language Models (LLMs), AI models trained on massive text corpora with\nremarkable language understanding and generation capabilities, are transforming\nthe field of Autonomous Driving (AD). As AD systems evolve from rule-based and\noptimization-based methods to learning-based techniques like deep reinforcement\nlearning, they are now poised to embrace a third and more advanced category:\nknowledge-based AD empowered by LLMs. This shift promises to bring AD closer to\nhuman-like AD. However, integrating LLMs into AD systems poses challenges in\nreal-time inference, safety assurance, and deployment costs. This survey\nprovides a comprehensive and critical review of recent progress in leveraging\nLLMs for AD, focusing on their applications in modular AD pipelines and\nend-to-end AD systems. We highlight key advancements, identify pressing\nchallenges, and propose promising research directions to bridge the gap between\nLLMs and AD, thereby facilitating the development of more human-like AD\nsystems. The survey first introduces LLMs' key features and common training\nschemes, then delves into their applications in modular AD pipelines and\nend-to-end AD, respectively, followed by discussions on open challenges and\nfuture directions. Through this in-depth analysis, we aim to provide insights\nand inspiration for researchers and practitioners working at the intersection\nof AI and autonomous vehicles, ultimately contributing to safer, smarter, and\nmore human-centric AD technologies.",
      "tldr_zh": "这篇调查论文探讨了大型语言模型（LLMs）在自动驾驶（AD）领域的应用，旨在通过LLMs的语言理解和生成能力，将AD系统从规则-based和优化-based方法升级为基于知识的系统，从而实现更接近人类驾驶的性能。论文回顾了LLMs在模块化AD管道和端到端AD系统中的关键进展，包括其在实时推理、安全保障和部署成本方面的挑战，并提出了未来研究方向，如桥接LLMs与AD的差距。最终，该研究为开发更安全、智能和以人为中心的AD技术提供了宝贵见解和灵感。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 2 figures, accepted at IEEE Intelligent Transportation\n  Systems Conference (ITSC) 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.19280v1",
      "published_date": "2024-07-27 15:24:11 UTC",
      "updated_date": "2024-07-27 15:24:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T10:34:46.947132"
    },
    {
      "arxiv_id": "2407.19266v1",
      "title": "Interactive Learning in Computer Science Education Supported by a Discord Chatbot",
      "title_zh": "基于 Discord 聊天机器人的计算机科学教育交互式学习",
      "authors": [
        "Santiago Berrezueta-Guzman",
        "Ivan Parmacli",
        "Stephan Krusche",
        "Stefan Wagner"
      ],
      "abstract": "Enhancing interaction and feedback collection in a first-semester computer\nscience course poses a significant challenge due to students' diverse needs and\nengagement levels. To address this issue, we created and integrated a\ncommand-based chatbot on the course communication server on Discord. The\nDiscordBot enables students to provide feedback on course activities through\nshort surveys, such as exercises, quizzes, and lectures, facilitating\nstress-free communication with instructors. It also supports attendance\ntracking and introduces lectures before they start.\n  The research demonstrates the effectiveness of the DiscordBot as a\ncommunication tool. The ongoing feedback allowed course instructors to\ndynamically adjust and improve the difficulty level of upcoming activities and\npromote discussion in subsequent tutor sessions. The data collected reveal that\nstudents can accurately perceive the activities' difficulty and expected\nresults, providing insights not possible through traditional end-of-semester\nsurveys. Students reported that interaction with the DiscordBot was easy and\nexpressed a desire to continue using it in future semesters. This responsive\napproach ensures the course meets the evolving needs of students, thereby\nenhancing their overall learning experience.",
      "tldr_zh": "本研究针对计算机科学入门课程中学生需求多样和参与度低的挑战，开发了一个基于 Discord 的命令式聊天机器人（DiscordBot），用于增强交互和反馈收集。机器人允许学生通过简短调查提供对练习、测验和讲座的反馈，支持出勤跟踪和讲座预览，从而实现无压力的师生沟通。研究结果表明，该工具有效帮助教师动态调整活动难度并促进讨论，学生能准确感知难度并给出宝贵洞见，且反馈积极，希望在未来学期继续使用，最终提升了课程的学习体验。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.ET"
      ],
      "primary_category": "cs.AI",
      "comment": "Revised and accepted paper at the IEEE German Education Conference\n  2024 (GECon 2024) and to be published in IEEE proceedings",
      "pdf_url": "http://arxiv.org/pdf/2407.19266v1",
      "published_date": "2024-07-27 14:22:40 UTC",
      "updated_date": "2024-07-27 14:22:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T10:35:32.142932"
    },
    {
      "arxiv_id": "2407.19259v1",
      "title": "Fine-Grained Scene Graph Generation via Sample-Level Bias Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Yansheng Li",
        "Tingzhu Wang",
        "Kang Wu",
        "Linlin Wang",
        "Xin Guo",
        "Wenbin Wang"
      ],
      "abstract": "Scene Graph Generation (SGG) aims to explore the relationships between\nobjects in images and obtain scene summary graphs, thereby better serving\ndownstream tasks. However, the long-tailed problem has adversely affected the\nscene graph's quality. The predictions are dominated by coarse-grained\nrelationships, lacking more informative fine-grained ones. The union region of\none object pair (i.e., one sample) contains rich and dedicated contextual\ninformation, enabling the prediction of the sample-specific bias for refining\nthe original relationship prediction. Therefore, we propose a novel\nSample-Level Bias Prediction (SBP) method for fine-grained SGG (SBG). Firstly,\nwe train a classic SGG model and construct a correction bias set by calculating\nthe margin between the ground truth label and the predicted label with one\nclassic SGG model. Then, we devise a Bias-Oriented Generative Adversarial\nNetwork (BGAN) that learns to predict the constructed correction biases, which\ncan be utilized to correct the original predictions from coarse-grained\nrelationships to fine-grained ones. The extensive experimental results on VG,\nGQA, and VG-1800 datasets demonstrate that our SBG outperforms the\nstate-of-the-art methods in terms of Average@K across three mainstream SGG\nmodels: Motif, VCtree, and Transformer. Compared to dataset-level correction\nmethods on VG, SBG shows a significant average improvement of 5.6%, 3.9%, and\n3.2% on Average@K for tasks PredCls, SGCls, and SGDet, respectively. The code\nwill be available at https://github.com/Zhuzi24/SBG.",
      "tldr_zh": "该论文针对场景图生成 (SGG) 中的长尾问题，提出了一种细粒度方法 Sample-Level Bias Prediction (SBP)，通过分析对象对的联合区域来预测样本级偏差，从而从粗粒度关系转向更精确的细粒度关系。方法包括训练经典 SGG 模型构建修正偏差集，并利用 Bias-Oriented Generative Adversarial Network (BGAN) 来预测这些偏差以修正原始预测。实验结果显示，在 VG、GQA 和 VG-1800 数据集上，SBG 在 Average@K 指标上超越了最先进方法，与数据集级修正方法相比，在 PredCls、SGCls 和 SGDet 任务上分别平均提高了 5.6%、3.9% 和 3.2%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "24 pages, 10 figures, ECCV2024",
      "pdf_url": "http://arxiv.org/pdf/2407.19259v1",
      "published_date": "2024-07-27 13:49:06 UTC",
      "updated_date": "2024-07-27 13:49:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T10:35:46.326794"
    },
    {
      "arxiv_id": "2407.19256v1",
      "title": "Stochastic Parrots or ICU Experts? Large Language Models in Critical Care Medicine: A Scoping Review",
      "title_zh": "翻译失败",
      "authors": [
        "Tongyue Shi",
        "Jun Ma",
        "Zihan Yu",
        "Haowei Xu",
        "Minqi Xiong",
        "Meirong Xiao",
        "Yilin Li",
        "Huiying Zhao",
        "Guilan Kong"
      ],
      "abstract": "With the rapid development of artificial intelligence (AI), large language\nmodels (LLMs) have shown strong capabilities in natural language understanding,\nreasoning, and generation, attracting amounts of research interest in applying\nLLMs to health and medicine. Critical care medicine (CCM) provides diagnosis\nand treatment for critically ill patients who often require intensive\nmonitoring and interventions in intensive care units (ICUs). Can LLMs be\napplied to CCM? Are LLMs just like stochastic parrots or ICU experts in\nassisting clinical decision-making? This scoping review aims to provide a\npanoramic portrait of the application of LLMs in CCM. Literature in seven\ndatabases, including PubMed, Embase, Scopus, Web of Science, CINAHL, IEEE\nXplore, and ACM Digital Library, were searched from January 1, 2019, to June\n10, 2024. Peer-reviewed journal and conference articles that discussed the\napplication of LLMs in critical care settings were included. From an initial\n619 articles, 24 were selected for final review. This review grouped\napplications of LLMs in CCM into three categories: clinical decision support,\nmedical documentation and reporting, and medical education and doctor-patient\ncommunication. LLMs have advantages in handling unstructured data and do not\nrequire manual feature engineering. Meanwhile, applying LLMs to CCM faces\nchallenges, including hallucinations, poor interpretability, bias and alignment\nchallenges, and privacy and ethics issues. Future research should enhance model\nreliability and interpretability, integrate up-to-date medical knowledge, and\nstrengthen privacy and ethical guidelines. As LLMs evolve, they could become\nkey tools in CCM to help improve patient outcomes and optimize healthcare\ndelivery. This study is the first review of LLMs in CCM, aiding researchers,\nclinicians, and policymakers to understand the current status and future\npotentials of LLMs in CCM.",
      "tldr_zh": "本综述探讨了大型语言模型（LLMs）在重症监护医学（CCM）中的应用，评估 LLMs 是否能像 ICU 专家一样辅助临床决策，还是仅为随机鹦鹉（stochastic parrots）。通过搜索七个数据库（包括 PubMed 和 Embase）从 2019 年到 2024 年，筛选出 24 篇相关文章，将 LLMs 的应用分为临床决策支持、医疗文档和报告以及医疗教育和医患沟通三大类。LLMs 优势在于处理非结构化数据和无需手动特征工程，但面临幻觉（hallucinations）、可解释性差、偏差及隐私伦理挑战。未来研究应提升模型可靠性和可解释性，并加强隐私指南，以使 LLMs 成为优化 CCM 患者结果的关键工具；此为首个此类综述。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "28 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.19256v1",
      "published_date": "2024-07-27 13:41:43 UTC",
      "updated_date": "2024-07-27 13:41:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T10:35:58.651245"
    },
    {
      "arxiv_id": "2407.19248v2",
      "title": "Mamba-UIE: Enhancing Underwater Images with Physical Model Constraint",
      "title_zh": "Mamba-UIE：利用物理模型约束增强水下图像",
      "authors": [
        "Song Zhang",
        "Yuqing Duan",
        "Daoliang Li",
        "Ran Zhao"
      ],
      "abstract": "In underwater image enhancement (UIE), convolutional neural networks (CNN)\nhave inherent limitations in modeling long-range dependencies and are less\neffective in recovering global features. While Transformers excel at modeling\nlong-range dependencies, their quadratic computational complexity with\nincreasing image resolution presents significant efficiency challenges.\nAdditionally, most supervised learning methods lack effective physical model\nconstraint, which can lead to insufficient realism and overfitting in generated\nimages. To address these issues, we propose a physical model constraint-based\nunderwater image enhancement framework, Mamba-UIE. Specifically, we decompose\nthe input image into four components: underwater scene radiance, direct\ntransmission map, backscatter transmission map, and global background light.\nThese components are reassembled according to the revised underwater image\nformation model, and the reconstruction consistency constraint is applied\nbetween the reconstructed image and the original image, thereby achieving\neffective physical constraint on the underwater image enhancement process. To\ntackle the quadratic computational complexity of Transformers when handling\nlong sequences, we introduce the Mamba-UIE network based on linear complexity\nstate space models. By incorporating the Mamba in Convolution block, long-range\ndependencies are modeled at both the channel and spatial levels, while the CNN\nbackbone is retained to recover local features and details. Extensive\nexperiments on three public datasets demonstrate that our proposed Mamba-UIE\noutperforms existing state-of-the-art methods, achieving a PSNR of 27.13 and an\nSSIM of 0.93 on the UIEB dataset. Our method is available at\nhttps://github.com/zhangsong1213/Mamba-UIE.",
      "tldr_zh": "本文提出 Mamba-UIE 框架，用于水下图像增强 (UIE)，通过物理模型约束解决 CNN 在建模长距离依赖和恢复全局特征的局限性，以及 Transformer 的计算复杂度问题。框架将输入图像分解为 underwater scene radiance、direct transmission map、backscatter transmission map 和 global background light 等组件，并应用 reconstruction consistency constraint 来确保重建图像的真实性，同时引入基于线性复杂度 state space models 的 Mamba in Convolution 块来处理长距离依赖并保留 CNN 骨干网络恢复局部细节。在三个公共数据集上的实验显示，Mamba-UIE 优于现有方法，在 UIEB 数据集上达到 PSNR 27.13 和 SSIM 0.93。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.19248v2",
      "published_date": "2024-07-27 13:22:10 UTC",
      "updated_date": "2024-07-31 07:20:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T10:36:00.985531"
    },
    {
      "arxiv_id": "2407.19216v1",
      "title": "EaTVul: ChatGPT-based Evasion Attack Against Software Vulnerability Detection",
      "title_zh": "EaTVul：基于 ChatGPT 的软件漏洞检测规避攻击",
      "authors": [
        "Shigang Liu",
        "Di Cao",
        "Junae Kim",
        "Tamas Abraham",
        "Paul Montague",
        "Seyit Camtepe",
        "Jun Zhang",
        "Yang Xiang"
      ],
      "abstract": "Recently, deep learning has demonstrated promising results in enhancing the\naccuracy of vulnerability detection and identifying vulnerabilities in\nsoftware. However, these techniques are still vulnerable to attacks.\nAdversarial examples can exploit vulnerabilities within deep neural networks,\nposing a significant threat to system security. This study showcases the\nsusceptibility of deep learning models to adversarial attacks, which can\nachieve 100% attack success rate (refer to Table 5). The proposed method,\nEaTVul, encompasses six stages: identification of important samples using\nsupport vector machines, identification of important features using the\nattention mechanism, generation of adversarial data based on these features\nusing ChatGPT, preparation of an adversarial attack pool, selection of seed\ndata using a fuzzy genetic algorithm, and the execution of an evasion attack.\nExtensive experiments demonstrate the effectiveness of EaTVul, achieving an\nattack success rate of more than 83% when the snippet size is greater than 2.\nFurthermore, in most cases with a snippet size of 4, EaTVul achieves a 100%\nattack success rate. The findings of this research emphasize the necessity of\nrobust defenses against adversarial attacks in software vulnerability\ndetection.",
      "tldr_zh": "这篇论文揭示了深度学习模型在软件漏洞检测中的脆弱性，提出EaTVul方法利用ChatGPT进行对抗性逃避攻击。EaTVul包括六个阶段：使用Support Vector Machines识别重要样本、Attention Mechanism识别重要特征、ChatGPT生成对抗数据、准备对抗攻击池、Fuzzy Genetic Algorithm选择种子数据，以及执行逃避攻击。实验结果显示，当代码片段大小大于2时，攻击成功率超过83%，而在大多数情况下大小为4时达到100%。该研究强调了在软件漏洞检测中加强针对对抗攻击的防御措施的紧迫性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.19216v1",
      "published_date": "2024-07-27 09:04:54 UTC",
      "updated_date": "2024-07-27 09:04:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T10:36:20.221291"
    },
    {
      "arxiv_id": "2407.19205v1",
      "title": "Faster Image2Video Generation: A Closer Look at CLIP Image Embedding's Impact on Spatio-Temporal Cross-Attentions",
      "title_zh": "翻译失败",
      "authors": [
        "Ashkan Taghipour",
        "Morteza Ghahremani",
        "Mohammed Bennamoun",
        "Aref Miri Rekavandi",
        "Zinuo Li",
        "Hamid Laga",
        "Farid Boussaid"
      ],
      "abstract": "This paper investigates the role of CLIP image embeddings within the Stable\nVideo Diffusion (SVD) framework, focusing on their impact on video generation\nquality and computational efficiency. Our findings indicate that CLIP\nembeddings, while crucial for aesthetic quality, do not significantly\ncontribute towards the subject and background consistency of video outputs.\nMoreover, the computationally expensive cross-attention mechanism can be\neffectively replaced by a simpler linear layer. This layer is computed only\nonce at the first diffusion inference step, and its output is then cached and\nreused throughout the inference process, thereby enhancing efficiency while\nmaintaining high-quality outputs. Building on these insights, we introduce the\nVCUT, a training-free approach optimized for efficiency within the SVD\narchitecture. VCUT eliminates temporal cross-attention and replaces spatial\ncross-attention with a one-time computed linear layer, significantly reducing\ncomputational load. The implementation of VCUT leads to a reduction of up to\n322T Multiple-Accumulate Operations (MACs) per video and a decrease in model\nparameters by up to 50M, achieving a 20% reduction in latency compared to the\nbaseline. Our approach demonstrates that conditioning during the Semantic\nBinding stage is sufficient, eliminating the need for continuous computation\nacross all inference steps and setting a new standard for efficient video\ngeneration.",
      "tldr_zh": "本研究探讨了 CLIP 图像嵌入在 Stable Video Diffusion (SVD) 框架中的作用，重点分析其对视频生成质量和计算效率的影响。研究发现，CLIP 嵌入虽然提升了美学质量，但对主体和背景一致性贡献有限，因此可以通过简单线性层替换计算密集的时空交叉注意力机制，仅在第一个扩散推理步骤计算一次并缓存复用。基于此，作者提出 VCUT，一种无训练的优化方法，消除时间交叉注意力并简化空间交叉注意力，显著减少计算负载。结果显示，VCUT 每段视频减少多达 322T MACs，模型参数减少多达 50M，并实现 20% 的延迟降低，同时保持高生成质量。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.19205v1",
      "published_date": "2024-07-27 08:21:14 UTC",
      "updated_date": "2024-07-27 08:21:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T10:36:34.196058"
    },
    {
      "arxiv_id": "2407.19204v2",
      "title": "Towards the Terminator Economy: Assessing Job Exposure to AI through LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Emilio Colombo",
        "Fabio Mercorio",
        "Mario Mezzanzanica",
        "Antonio Serino"
      ],
      "abstract": "AI and related technologies are reshaping jobs and tasks, either by\nautomating or augmenting human skills in the workplace. Many researchers have\nbeen working on estimating if and to what extent jobs and tasks are exposed to\nthe risk of being automatized by AI-related technologies. Our work tackles this\nissue through a data-driven approach by: (i) developing a reproducible\nframework that uses cutting-edge open-source large language models to assess\nthe current capabilities of AI and robotics in performing job-related tasks;\n(ii) formalizing and computing a measure of AI exposure by occupation, the Task\nExposure to AI (TEAI) index, and a measure of Task Replacement by AI (TRAI),\nboth validated through a human user evaluation and compared with the state of\nthe art.\n  Our results show that the TEAI index is positively correlated with cognitive,\nproblem-solving and management skills, while it is negatively correlated with\nsocial skills. Applying the index to the US, we obtain that about one-third of\nUS employment is highly exposed to AI, primarily in high-skill jobs requiring a\ngraduate or postgraduate level of education. We also find that AI exposure is\npositively associated with both employment and wage growth in 2003-2023,\nsuggesting that AI has an overall positive effect on productivity.\n  Considering specifically the TRAI index, we find that even in high-skill\noccupations, AI exhibits high variability in task substitution, suggesting that\nAI and humans complement each other within the same occupation, while the\nallocation of tasks within occupations is likely to change.\n  All results, models, and code are freely available online to allow the\ncommunity to reproduce our results, compare outcomes, and use our work as a\nbenchmark to monitor AI's progress over time.",
      "tldr_zh": "这篇论文评估了大型语言模型 (LLMs) 对就业的潜在影响，开发了一个数据驱动框架来分析 AI 和机器人对工作任务的自动化能力。研究引入了 Task Exposure to AI (TEAI) 指数和 Task Replacement by AI (TRAI) 指数，通过人类用户评估和现有方法比较进行验证，结果显示 TEAI 与认知、问题解决和管理技能正相关，而与社交技能负相关。在美国，大约三分之一的就业岗位高度暴露于 AI，主要在高技能职位，且 AI 暴露与就业和工资增长正相关，表明 AI 可能提升生产力。同时，TRAI 指数揭示 AI 在高技能职业中的任务替代存在变异性，强调 AI 与人类的互补作用。所有模型、代码和结果均公开可用，以便社区再现和监控 AI 进展。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.19204v2",
      "published_date": "2024-07-27 08:14:18 UTC",
      "updated_date": "2025-04-15 08:51:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T10:36:46.268695"
    },
    {
      "arxiv_id": "2407.19203v2",
      "title": "Towards Clean-Label Backdoor Attacks in the Physical World",
      "title_zh": "翻译失败",
      "authors": [
        "Thinh Dao",
        "Cuong Chi Le",
        "Khoa D Doan",
        "Kok-Seng Wong"
      ],
      "abstract": "Deep Neural Networks (DNNs) are shown to be vulnerable to backdoor poisoning\nattacks, with most research focusing on \\textbf{digital triggers} -- special\npatterns added to test-time inputs to induce targeted misclassification.\n\\textbf{Physical triggers}, natural objects within a physical scene, have\nemerged as a desirable alternative since they enable real-time backdoor\nactivations without digital manipulation. However, current physical backdoor\nattacks require poisoned inputs to have incorrect labels, making them easily\ndetectable by human inspection. In this paper, we explore a new paradigm of\nattacks, \\textbf{clean-label physical backdoor attacks (CLPBA)}, via\nexperiments on facial recognition and animal classification tasks. Our study\nreveals that CLPBA could be a serious threat with the right poisoning algorithm\nand physical trigger. A key finding is that different from digital backdoor\nattacks which exploit memorization to plant backdoors in deep nets, CLPBA works\nby embedding the feature of the trigger distribution (i.e., the distribution of\ntrigger samples) to the poisoned images through the perturbations. We also find\nthat representative defenses cannot defend against CLPBA easily since CLPBA\nfundamentally breaks the core assumptions behind these defenses. Our study\nhighlights accidental backdoor activations as a limitation of CLPBA, happening\nwhen unintended objects or classes cause the model to misclassify as the target\nclass. The code and dataset can be found at\nhttps://github.com/21thinh/Clean-Label-Physical-Backdoor-Attacks.",
      "tldr_zh": "本研究探讨了 Clean-Label Physical Backdoor Attacks (CLPBA)，一种新型的后门攻击方法，旨在在物理世界中利用自然物体作为触发器，而不改变输入标签，从而规避人类检测。不同于传统的数字后门攻击，CLPBA 通过将触发器分布的特征嵌入到毒化图像中，实现对 Deep Neural Networks (DNNs) 的攻击，并在面部识别和动物分类任务上的实验中证明其有效性。关键发现是，CLPBA 能打破现有防御机制的核心假设，但存在意外激活的局限性，如非预期物体导致模型误分类。研究提供了代码和数据集以供进一步验证。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "21 pages, 17 figures, 16 tables",
      "pdf_url": "http://arxiv.org/pdf/2407.19203v2",
      "published_date": "2024-07-27 08:13:07 UTC",
      "updated_date": "2024-11-25 16:40:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T10:37:26.043134"
    },
    {
      "arxiv_id": "2407.19200v2",
      "title": "On Behalf of the Stakeholders: Trends in NLP Model Interpretability in the Era of LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Nitay Calderon",
        "Roi Reichart"
      ],
      "abstract": "Recent advancements in NLP systems, particularly with the introduction of\nLLMs, have led to widespread adoption of these systems by a broad spectrum of\nusers across various domains, impacting decision-making, the job market,\nsociety, and scientific research. This surge in usage has led to an explosion\nin NLP model interpretability and analysis research, accompanied by numerous\ntechnical surveys. Yet, these surveys often overlook the needs and perspectives\nof explanation stakeholders. In this paper, we address three fundamental\nquestions: Why do we need interpretability, what are we interpreting, and how?\nBy exploring these questions, we examine existing interpretability paradigms,\ntheir properties, and their relevance to different stakeholders. We further\nexplore the practical implications of these paradigms by analyzing trends from\nthe past decade across multiple research fields. To this end, we retrieved\nthousands of papers and employed an LLM to characterize them. Our analysis\nreveals significant disparities between NLP developers and non-developer users,\nas well as between research fields, underscoring the diverse needs of\nstakeholders. For example, explanations of internal model components are rarely\nused outside the NLP field. We hope this paper informs the future design,\ndevelopment, and application of methods that align with the objectives and\nrequirements of various stakeholders.",
      "tldr_zh": "这篇论文探讨了在LLMs时代，NLP模型可解释性（interpretability）的研究趋势，强调了解释利益相关者的需求和视角，这些利益相关者包括决策者、工作市场参与者和社会研究者。作者通过回答三个核心问题——为什么需要可解释性、解释什么以及如何解释——来审视现有可解释性范式，并分析了过去十年跨多个领域的数千篇论文，利用LLMs进行特征化。研究发现，NLP开发者与非开发者用户之间存在显著差异，例如内部模型组件（internal model components）的解释在NLP领域外很少应用。这些发现有助于指导未来NLP可解释性方法的设计、开发和应用，以更好地满足不同利益相关者的目标和要求。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.19200v2",
      "published_date": "2024-07-27 08:00:27 UTC",
      "updated_date": "2025-02-04 08:01:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T10:37:17.186885"
    },
    {
      "arxiv_id": "2407.19198v2",
      "title": "Towards the Dynamics of a DNN Learning Symbolic Interactions",
      "title_zh": "翻译失败",
      "authors": [
        "Qihan Ren",
        "Junpeng Zhang",
        "Yang Xu",
        "Yue Xin",
        "Dongrui Liu",
        "Quanshi Zhang"
      ],
      "abstract": "This study proves the two-phase dynamics of a deep neural network (DNN)\nlearning interactions. Despite the long disappointing view of the faithfulness\nof post-hoc explanation of a DNN, a series of theorems have been proven in\nrecent years to show that for a given input sample, a small set of interactions\nbetween input variables can be considered as primitive inference patterns that\nfaithfully represent a DNN's detailed inference logic on that sample.\nParticularly, Zhang et al. have observed that various DNNs all learn\ninteractions of different complexities in two distinct phases, and this\ntwo-phase dynamics well explains how a DNN changes from under-fitting to\nover-fitting. Therefore, in this study, we mathematically prove the two-phase\ndynamics of interactions, providing a theoretical mechanism for how the\ngeneralization power of a DNN changes during the training process. Experiments\nshow that our theory well predicts the real dynamics of interactions on\ndifferent DNNs trained for various tasks.",
      "tldr_zh": "这篇论文证明了深度神经网络 (DNN) 在学习符号交互时的两阶段动态，解释了 DNN 如何从欠拟合转向过拟合。研究通过数学定理展示了输入变量间的一小部分交互作为原始推理模式，忠实代表 DNN 在特定样本上的推理逻辑，并提供了解释 DNN 训练过程中泛化能力变化的理论机制。张 et al. 的观察得到实验验证，结果显示该理论准确预测了不同 DNN 在各种任务上交互的真实动态。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.19198v2",
      "published_date": "2024-07-27 07:34:49 UTC",
      "updated_date": "2024-11-25 08:57:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T10:37:14.191704"
    },
    {
      "arxiv_id": "2407.19196v1",
      "title": "Why Misinformation is Created? Detecting them by Integrating Intent Features",
      "title_zh": "翻译失败",
      "authors": [
        "Bing Wang",
        "Ximing Li",
        "Changchun Li",
        "Bo Fu",
        "Songwen Pei",
        "Shengsheng Wang"
      ],
      "abstract": "Various social media platforms, e.g., Twitter and Reddit, allow people to\ndisseminate a plethora of information more efficiently and conveniently.\nHowever, they are inevitably full of misinformation, causing damage to diverse\naspects of our daily lives. To reduce the negative impact, timely\nidentification of misinformation, namely Misinformation Detection (MD), has\nbecome an active research topic receiving widespread attention. As a complex\nphenomenon, the veracity of an article is influenced by various aspects. In\nthis paper, we are inspired by the opposition of intents between misinformation\nand real information. Accordingly, we propose to reason the intent of articles\nand form the corresponding intent features to promote the veracity\ndiscrimination of article features. To achieve this, we build a hierarchy of a\nset of intents for both misinformation and real information by referring to the\nexisting psychological theories, and we apply it to reason the intent of\narticles by progressively generating binary answers with an encoder-decoder\nstructure. We form the corresponding intent features and integrate it with the\ntoken features to achieve more discriminative article features for MD. Upon\nthese ideas, we suggest a novel MD method, namely Detecting Misinformation by\nIntegrating Intent featuRes (DM-INTER). To evaluate the performance of\nDM-INTER, we conduct extensive experiments on benchmark MD datasets. The\nexperimental results validate that DM-INTER can outperform the existing\nbaseline MD methods.",
      "tldr_zh": "本研究探讨社交媒体上误信息（misinformation）的生成原因，并提出一种新方法，通过整合意图特征来提升误信息检测（MD）。论文基于误信息与真实信息的意图对立，构建了意图层次结构，参考心理理论，并使用编码器-解码器结构逐步生成二元答案来推理文章意图，形成相应的意图特征。接着，将意图特征与令牌特征整合，开发出名为 DM-INTER 的检测方法。实验在基准 MD 数据集上显示，DM-INTER 优于现有基线方法，验证了其在提升误信息识别准确性方面的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages, 3 figures. Accepted by CIKM 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.19196v1",
      "published_date": "2024-07-27 07:30:47 UTC",
      "updated_date": "2024-07-27 07:30:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T10:37:50.021810"
    },
    {
      "arxiv_id": "2407.19193v1",
      "title": "A collaborative ensemble construction method for federated random forest",
      "title_zh": "翻译失败",
      "authors": [
        "Penjan Antonio Eng Lim",
        "Cheong Hee Park"
      ],
      "abstract": "Random forests are considered a cornerstone in machine learning for their\nrobustness and versatility. Despite these strengths, their conventional\ncentralized training is ill-suited for the modern landscape of data that is\noften distributed, sensitive, and subject to privacy concerns. Federated\nlearning (FL) provides a compelling solution to this problem, enabling models\nto be trained across a group of clients while maintaining the privacy of each\nclient's data. However, adapting tree-based methods like random forests to\nfederated settings introduces significant challenges, particularly when it\ncomes to non-identically distributed (non-IID) data across clients, which is a\ncommon scenario in real-world applications. This paper presents a federated\nrandom forest approach that employs a novel ensemble construction method aimed\nat improving performance under non-IID data. Instead of growing trees\nindependently in each client, our approach ensures each decision tree in the\nensemble is iteratively and collectively grown across clients. To preserve the\nprivacy of the client's data, we confine the information stored in the leaf\nnodes to the majority class label identified from the samples of the client's\nlocal data that reach each node. This limited disclosure preserves the\nconfidentiality of the underlying data distribution of clients, thereby\nenhancing the privacy of the federated learning process. Furthermore, our\ncollaborative ensemble construction strategy allows the ensemble to better\nreflect the data's heterogeneity across different clients, enhancing its\nperformance on non-IID data, as our experimental results confirm.",
      "tldr_zh": "这篇论文提出了一种协作集成构建方法，用于联邦随机森林（Federated Random Forest），以解决传统随机森林在分布式、非独立同分布（non-IID）数据场景下的隐私和性能挑战。不同于客户端独立生长树，该方法通过迭代地在客户端之间集体生长决策树，并仅在叶节点存储从本地数据中识别出的多数类标签，从而增强数据隐私保护。实验结果证实，这种策略显著提高了模型在non-IID数据下的整体性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.DC",
        "68T05 (Primary), 68W40, 62H30 (Secondary)",
        "I.2.6; I.2.11; K.4.1"
      ],
      "primary_category": "cs.LG",
      "comment": "This is the authors' accepted manuscript of an article published in\n  the journal Expert Systems With Applications. Published version available at:\n  https://www.sciencedirect.com/science/article/pii/S0957417424016099. 22\n  pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.19193v1",
      "published_date": "2024-07-27 07:21:45 UTC",
      "updated_date": "2024-07-27 07:21:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T10:38:00.613719"
    },
    {
      "arxiv_id": "2408.01460v1",
      "title": "LocalValueBench: A Collaboratively Built and Extensible Benchmark for Evaluating Localized Value Alignment and Ethical Safety in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Gwenyth Isobel Meadows",
        "Nicholas Wai Long Lau",
        "Eva Adelina Susanto",
        "Chi Lok Yu",
        "Aditya Paul"
      ],
      "abstract": "The proliferation of large language models (LLMs) requires robust evaluation\nof their alignment with local values and ethical standards, especially as\nexisting benchmarks often reflect the cultural, legal, and ideological values\nof their creators. \\textsc{LocalValueBench}, introduced in this paper, is an\nextensible benchmark designed to assess LLMs' adherence to Australian values,\nand provides a framework for regulators worldwide to develop their own LLM\nbenchmarks for local value alignment. Employing a novel typology for ethical\nreasoning and an interrogation approach, we curated comprehensive questions and\nutilized prompt engineering strategies to probe LLMs' value alignment. Our\nevaluation criteria quantified deviations from local values, ensuring a\nrigorous assessment process. Comparative analysis of three commercial LLMs by\nUSA vendors revealed significant insights into their effectiveness and\nlimitations, demonstrating the critical importance of value alignment. This\nstudy offers valuable tools and methodologies for regulators to create tailored\nbenchmarks, highlighting avenues for future research to enhance ethical AI\ndevelopment.",
      "tldr_zh": "这篇论文介绍了 LocalValueBench，一个协作构建的可扩展基准，用于评估大型语言模型 (LLMs) 是否符合本地价值观和道德标准，以应对现有基准的地域偏见问题。该基准针对澳大利亚价值观设计，并提供框架让全球监管者创建自己的本地化评估工具，采用新型道德推理分类、审问方法和提示工程策略来生成全面的问题，并量化模型与本地价值观的偏差。通过对三个美国供应商的商业 LLMs 进行比较分析，研究揭示了这些模型的有效性和局限性，强调了价值对齐的重要性。该工作为监管者提供了实用工具和方法，支持未来伦理 AI 发展的研究。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.01460v1",
      "published_date": "2024-07-27 05:55:42 UTC",
      "updated_date": "2024-07-27 05:55:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T10:38:16.116806"
    },
    {
      "arxiv_id": "2407.19186v1",
      "title": "Channel Boosted CNN-Transformer-based Multi-Level and Multi-Scale Nuclei Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Zunaira Rauf",
        "Abdul Rehman Khan",
        "Asifullah Khan"
      ],
      "abstract": "Accurate nuclei segmentation is an essential foundation for various\napplications in computational pathology, including cancer diagnosis and\ntreatment planning. Even slight variations in nuclei representations can\nsignificantly impact these downstream tasks. However, achieving accurate\nsegmentation remains challenging due to factors like clustered nuclei, high\nintra-class variability in size and shape, resemblance to other cells, and\ncolor or contrast variations between nuclei and background. Despite the\nextensive utilization of Convolutional Neural Networks (CNNs) in medical image\nsegmentation, they may have trouble capturing long-range dependencies crucial\nfor accurate nuclei delineation. Transformers address this limitation but might\nmiss essential low-level features. To overcome these limitations, we utilized\nCNN-Transformer-based techniques for nuclei segmentation in H&E stained\nhistology images. In this work, we proposed two CNN-Transformer architectures,\nNuclei Hybrid Vision Transformer (NucleiHVT) and Channel Boosted Nuclei Hybrid\nVision Transformer (CB-NucleiHVT), that leverage the strengths of both CNNs and\nTransformers to effectively learn nuclei boundaries in multi-organ histology\nimages. The first architecture, NucleiHVT is inspired by the UNet architecture\nand incorporates the dual attention mechanism to capture both multi-level and\nmulti-scale context effectively. The CB-NucleiHVT network, on the other hand,\nutilizes the concept of channel boosting to learn diverse feature spaces,\nenhancing the model's ability to distinguish subtle variations in nuclei\ncharacteristics. Detailed evaluation of two medical image segmentation datasets\nshows that the proposed architectures outperform existing CNN-based,\nTransformer-based, and hybrid methods. The proposed networks demonstrated\neffective results both in terms of quantitative metrics, and qualitative visual\nassessment.",
      "tldr_zh": "本研究针对计算病理学中细胞核分割的挑战（如细胞核聚簇、高内部变异和颜色对比变化），提出两种CNN-Transformer混合架构：NucleiHVT和Channel Boosted NucleiHVT（CB-NucleiHVT）。NucleiHVT基于UNet架构，融入双重注意力机制，以捕捉多级和多尺度上下文；CB-NucleiHVT则通过通道提升技术学习多样特征空间，提升对细胞核微妙差异的区分能力。在两个医疗图像分割数据集上的评估显示，这些架构在定量指标和定性视觉评估中，均优于现有的CNN-based、Transformer-based和混合方法。总的来说，该工作为精确的细胞核分割提供了有效工具，支持癌症诊断和治疗规划。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.19186v1",
      "published_date": "2024-07-27 05:54:05 UTC",
      "updated_date": "2024-07-27 05:54:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T10:38:26.392540"
    },
    {
      "arxiv_id": "2407.19185v1",
      "title": "LLaVA-Read: Enhancing Reading Ability of Multimodal Language Models",
      "title_zh": "LLaVA-Read：增强多模态语言模型的阅读能力",
      "authors": [
        "Ruiyi Zhang",
        "Yufan Zhou",
        "Jian Chen",
        "Jiuxiang Gu",
        "Changyou Chen",
        "Tong Sun"
      ],
      "abstract": "Large multimodal language models have demonstrated impressive capabilities in\nunderstanding and manipulating images. However, many of these models struggle\nwith comprehending intensive textual contents embedded within the images,\nprimarily due to the limited text recognition and layout understanding ability.\nTo understand the sources of these limitations, we perform an exploratory\nanalysis showing the drawbacks of classical visual encoders on visual text\nunderstanding. Hence, we present LLaVA-Read, a multimodal large language model\nthat utilizes dual visual encoders along with a visual text encoder. Our model\nsurpasses existing state-of-the-art models in various text-rich image\nunderstanding tasks, showcasing enhanced comprehension of textual content\nwithin images. Together, our research suggests visual text understanding\nremains an open challenge and an efficient visual text encoder is crucial for\nfuture successful multimodal systems.",
      "tldr_zh": "这项研究发现，大型多模态语言模型（Multimodal Language Models）在处理图像中密集文本内容时，面临文本识别和布局理解能力的限制。作者通过探索性分析揭示了经典视觉编码器（visual encoders）的缺点，并提出 LLaVA-Read 模型，该模型采用双视觉编码器和一个视觉文本编码器来提升文本丰富图像的理解能力。在各种文本丰富的图像任务中，LLaVA-Read 超过了现有最先进模型，证明了高效视觉文本编码器对多模态系统的关键作用，并强调视觉文本理解（visual text understanding）仍是开放挑战。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "NeurIPS 2024 Under Review",
      "pdf_url": "http://arxiv.org/pdf/2407.19185v1",
      "published_date": "2024-07-27 05:53:37 UTC",
      "updated_date": "2024-07-27 05:53:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T10:38:38.411950"
    },
    {
      "arxiv_id": "2407.19183v1",
      "title": "Graph Memory Learning: Imitating Lifelong Remembering and Forgetting of Brain Networks",
      "title_zh": "图记忆学习：模仿脑网络的终身记忆和遗忘",
      "authors": [
        "Jiaxing Miao",
        "Liang Hu",
        "Qi Zhang",
        "Longbing Cao"
      ],
      "abstract": "Graph data in real-world scenarios undergo rapid and frequent changes, making\nit challenging for existing graph models to effectively handle the continuous\ninflux of new data and accommodate data withdrawal requests. The approach to\nfrequently retraining graph models is resource intensive and impractical. To\naddress this pressing challenge, this paper introduces a new concept of graph\nmemory learning. Its core idea is to enable a graph model to selectively\nremember new knowledge but forget old knowledge. Building on this approach, the\npaper presents a novel graph memory learning framework - Brain-inspired Graph\nMemory Learning (BGML), inspired by brain network dynamics and\nfunction-structure coupling strategies. BGML incorporates a multi-granular\nhierarchical progressive learning mechanism rooted in feature graph grain\nlearning to mitigate potential conflict between memorization and forgetting in\ngraph memory learning. This mechanism allows for a comprehensive and\nmulti-level perception of local details within evolving graphs. In addition, to\ntackle the issue of unreliable structures in newly added incremental\ninformation, the paper introduces an information self-assessment ownership\nmechanism. This mechanism not only facilitates the propagation of incremental\ninformation within the model but also effectively preserves the integrity of\npast experiences. We design five types of graph memory learning tasks: regular,\nmemory, unlearning, data-incremental, and class-incremental to evaluate BGML.\nIts excellent performance is confirmed through extensive experiments on\nmultiple real-world node classification datasets.",
      "tldr_zh": "本文提出 Graph Memory Learning 概念，旨在让图模型模拟大脑网络的终身记忆和遗忘机制，以高效处理快速变化的图数据和数据撤回请求，避免频繁重训。框架 Brain-inspired Graph Memory Learning (BGML) 借鉴脑网络动态，融入多粒度层次化渐进学习机制和信息自评估所有权机制，缓解记忆与遗忘冲突，并确保新旧信息完整性。通过在五种任务（如 regular、memory 和 incremental 类型）上的实验，BGML 在多个真实节点分类数据集上表现出色，性能显著提升。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.19183v1",
      "published_date": "2024-07-27 05:50:54 UTC",
      "updated_date": "2024-07-27 05:50:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T10:38:58.663886"
    },
    {
      "arxiv_id": "2408.01459v1",
      "title": "AgentPeerTalk: Empowering Students through Agentic-AI-Driven Discernment of Bullying and Joking in Peer Interactions in Schools",
      "title_zh": "翻译失败",
      "authors": [
        "Aditya Paul",
        "Chi Lok Yu",
        "Eva Adelina Susanto",
        "Nicholas Wai Long Lau",
        "Gwenyth Isobel Meadows"
      ],
      "abstract": "Addressing school bullying effectively and promptly is crucial for the mental\nhealth of students. This study examined the potential of large language models\n(LLMs) to empower students by discerning between bullying and joking in school\npeer interactions. We employed ChatGPT-4, Gemini 1.5 Pro, and Claude 3 Opus,\nevaluating their effectiveness through human review. Our results revealed that\nnot all LLMs were suitable for an agentic approach, with ChatGPT-4 showing the\nmost promise. We observed variations in LLM outputs, possibly influenced by\npolitical overcorrectness, context window limitations, and pre-existing bias in\ntheir training data. ChatGPT-4 excelled in context-specific accuracy after\nimplementing the agentic approach, highlighting its potential to provide\ncontinuous, real-time support to vulnerable students. This study underlines the\nsignificant social impact of using agentic AI in educational settings, offering\na new avenue for reducing the negative consequences of bullying and enhancing\nstudent well-being.",
      "tldr_zh": "这篇论文探讨了使用大型语言模型 (LLMs) 来区分学校同伴互动中的欺凌和开玩笑，从而增强学生的心理健康支持。研究评估了 ChatGPT-4、Gemini 1.5 Pro 和 Claude 3 Opus，通过人类审查发现 ChatGPT-4 在 agentic approach（代理式方法）下表现出色，提供更高的上下文准确性。结果显示，LLMs 的输出可能受政治正确性、上下文窗口限制和训练数据偏见的影响，导致表现差异。该研究强调了在教育环境中应用 agentic AI 的社会潜力，可为实时支持学生提供新途径，减少欺凌的负面后果。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.01459v1",
      "published_date": "2024-07-27 05:50:02 UTC",
      "updated_date": "2024-07-27 05:50:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T10:39:02.522603"
    },
    {
      "arxiv_id": "2407.19173v1",
      "title": "FarSSiBERT: A Novel Transformer-based Model for Semantic Similarity Measurement of Persian Social Networks Informal Texts",
      "title_zh": "翻译失败",
      "authors": [
        "Seyed Mojtaba Sadjadi",
        "Zeinab Rajabi",
        "Leila Rabiei",
        "Mohammad-Shahram Moin"
      ],
      "abstract": "One fundamental task for NLP is to determine the similarity between two texts\nand evaluate the extent of their likeness. The previous methods for the Persian\nlanguage have low accuracy and are unable to comprehend the structure and\nmeaning of texts effectively. Additionally, these methods primarily focus on\nformal texts, but in real-world applications of text processing, there is a\nneed for robust methods that can handle colloquial texts. This requires\nalgorithms that consider the structure and significance of words based on\ncontext, rather than just the frequency of words. The lack of a proper dataset\nfor this task in the Persian language makes it important to develop such\nalgorithms and construct a dataset for Persian text. This paper introduces a\nnew transformer-based model to measure semantic similarity between Persian\ninformal short texts from social networks. In addition, a Persian dataset named\nFarSSiM has been constructed for this purpose, using real data from social\nnetworks and manually annotated and verified by a linguistic expert team. The\nproposed model involves training a large language model using the BERT\narchitecture from scratch. This model, called FarSSiBERT, is pre-trained on\napproximately 104 million Persian informal short texts from social networks,\nmaking it one of a kind in the Persian language. Moreover, a novel specialized\ninformal language tokenizer is provided that not only performs tokenization on\nformal texts well but also accurately identifies tokens that other Persian\ntokenizers are unable to recognize. It has been demonstrated that our proposed\nmodel outperforms ParsBERT, laBSE, and multilingual BERT in the Pearson and\nSpearman's coefficient criteria. Additionally, the pre-trained large language\nmodel has great potential for use in other NLP tasks on colloquial text and as\na tokenizer for less-known informal words.",
      "tldr_zh": "本文提出 FarSSiBERT，一种新型基于 Transformer 的模型，用于测量波斯语社交网络非正式短文本的语义相似度，以解决现有方法在准确性和理解结构方面的不足。研究团队构建了 FarSSiM 数据集，该数据集基于真实社交网络数据并由语言专家手动标注，并开发了一个专门的非正式语言分词器来处理其他分词器无法识别的词汇。FarSSiBERT 使用 BERT 架构从零训练，基于约 1.04 亿条波斯语非正式文本进行预训练，并在 Pearson 和 Spearman's 系数上优于 ParsBERT、laBSE 和多语言 BERT。模型不仅提升了相似度测量的性能，还适用于其他 NLP 任务中处理口语化文本。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.19173v1",
      "published_date": "2024-07-27 05:04:49 UTC",
      "updated_date": "2024-07-27 05:04:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T10:39:15.519567"
    },
    {
      "arxiv_id": "2407.19160v1",
      "title": "Decomposing heterogeneous dynamical systems with graph neural networks",
      "title_zh": "翻译失败",
      "authors": [
        "Cédric Allier",
        "Magdalena C. Schneider",
        "Michael Innerberger",
        "Larissa Heinrich",
        "John A. Bogovic",
        "Stephan Saalfeld"
      ],
      "abstract": "Natural physical, chemical, and biological dynamical systems are often\ncomplex, with heterogeneous components interacting in diverse ways. We show\nthat graph neural networks can be designed to jointly learn the interaction\nrules and the structure of the heterogeneity from data alone. The learned\nlatent structure and dynamics can be used to virtually decompose the complex\nsystem which is necessary to parameterize and infer the underlying governing\nequations. We tested the approach with simulation experiments of moving\nparticles and vector fields that interact with each other. While our current\naim is to better understand and validate the approach with simulated data, we\nanticipate it to become a generally applicable tool to uncover the governing\nrules underlying complex dynamics observed in nature.",
      "tldr_zh": "这篇论文提出了一种使用 Graph Neural Networks (GNNs) 的方法，从数据中联合学习异构动态系统的交互规则和结构。论文展示了该方法能实现复杂系统的虚拟分解，从而帮助参数化和推断底层治理方程。通过模拟实验，包括移动粒子和矢量场的互动，该方法在理解复杂动态方面表现出色。预计这一方法将成为揭示自然物理、化学和生物系统中复杂行为的通用工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.DS"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 4 figures, 2 pages appendix, 2 supplementary tables, 18\n  supplementary figures, 13 videos linked to youtube",
      "pdf_url": "http://arxiv.org/pdf/2407.19160v1",
      "published_date": "2024-07-27 04:03:12 UTC",
      "updated_date": "2024-07-27 04:03:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T10:39:26.193822"
    },
    {
      "arxiv_id": "2407.20291v1",
      "title": "Formalization of Dialogue in the Decision Support System of Dr. Watson Type",
      "title_zh": "翻译失败",
      "authors": [
        "Saveli Goldberg",
        "Vladimir Sluchak"
      ],
      "abstract": "The article further develops and formalizes a theory of friendly dialogue in\nan AI System of Dr. Watson type, as proposed in our previous\npublication[4],[19]. The main principle of this type of AI is to guide the user\ntoward a solution in a friendly manner, using questions based on the analysis\nof user input and data collected in the system.",
      "tldr_zh": "这篇论文进一步发展和形式化了 Dr. Watson 类型决策支持系统中的友好对话理论，基于之前的出版物[4]和[19]。该理论的核心原则是通过分析用户输入和系统收集的数据，生成引导性问题，以友好方式引导用户解决问题。主要贡献在于构建一种可扩展的对话框架，提升 AI 在决策支持中的交互性和用户体验。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.20291v1",
      "published_date": "2024-07-27 01:56:33 UTC",
      "updated_date": "2024-07-27 01:56:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T10:39:40.411708"
    },
    {
      "arxiv_id": "2407.19142v1",
      "title": "On the benefits of pixel-based hierarchical policies for task generalization",
      "title_zh": "翻译失败",
      "authors": [
        "Tudor Cristea-Platon",
        "Bogdan Mazoure",
        "Josh Susskind",
        "Walter Talbott"
      ],
      "abstract": "Reinforcement learning practitioners often avoid hierarchical policies,\nespecially in image-based observation spaces. Typically, the single-task\nperformance improvement over flat-policy counterparts does not justify the\nadditional complexity associated with implementing a hierarchy. However, by\nintroducing multiple decision-making levels, hierarchical policies can compose\nlower-level policies to more effectively generalize between tasks, highlighting\nthe need for multi-task evaluations. We analyze the benefits of hierarchy\nthrough simulated multi-task robotic control experiments from pixels. Our\nresults show that hierarchical policies trained with task conditioning can (1)\nincrease performance on training tasks, (2) lead to improved reward and\nstate-space generalizations in similar tasks, and (3) decrease the complexity\nof fine tuning required to solve novel tasks. Thus, we believe that\nhierarchical policies should be considered when building reinforcement learning\narchitectures capable of generalizing between tasks.",
      "tldr_zh": "本研究探讨了基于像素的层次化策略（hierarchical policies）在任务泛化（task generalization）方面的优势，尽管它们在单任务强化学习（reinforcement learning）中常被避免，因为额外复杂性不值得性能提升。作者通过模拟的多任务机器人控制实验，从像素观察空间入手，分析了任务条件化训练的益处。结果显示，层次化策略不仅提高了训练任务的性能，还提升了类似任务的奖励和状态空间泛化，并降低了解决新任务所需的微调复杂性。因此，论文建议在构建任务间泛化的强化学习架构时，应考虑采用层次化策略。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.19142v1",
      "published_date": "2024-07-27 01:26:26 UTC",
      "updated_date": "2024-07-27 01:26:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T10:40:04.165466"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 31,
  "processed_papers_count": 31,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-19T10:40:32.821646"
}