{
  "date": "2024-12-23",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-12-23 的 arXiv 中文 TLDR 快报！\n\n今天的 arXiv 论文主要聚焦于 AI 模型的优化、安全性、多模态应用和实际领域部署，突出大型语言模型（LLMs）在视频生成、医疗诊断和知识图谱中的潜力，同时探讨了神经网络的理论边界和解释性挑战。令人印象深刻的是，如 \"Large Language Model Safety\" 等论文提供了对 LLM 安全的全方位分析，而 \"FFA Sora\" 等在医疗图像模拟方面的创新展示了 AI 的实际价值。\n\n下面，我挑选并简要讨论了部分重要、话题性强的论文，先从 AI 和多模态领域入手，再聊医疗应用和理论创新，其他次要论文（如一些纯实验或重复性工作）将快速掠过。\n\n**1. Large Language Model Safety: A Holistic Survey (大型语言模型的安全性：一个整体调查)**  \n这篇由 Herve Debar 等学者撰写的综述论文，系统分析了 LLM 在价值失调、鲁棒性和滥用等方面的安全风险，并提出了多角度缓解策略。主要贡献是构建了一个全面框架，强调技术解决方案、伦理考虑和治理框架的结合，发现 LLM 在敏感领域（如医疗和金融）需要更强的行为保障。\n\n**2. Enhancing Multi-Text Long Video Generation Consistency without Tuning: Time-Frequency Analysis, Prompt Alignment, and Theory (无需微调的增强多文本长视频生成一致性：时频分析、提示对齐和理论)**  \nYing-Jui Tseng 等提出的方法通过时频分析和提示对齐优化视频生成一致性。主要发现是，该框架在多文本提示下显著提升视频平滑度和场景过渡，同时提供理论保证，适用于复杂多模态任务。\n\n**3. VidTwin: Video VAE with Decoupled Structure and Dynamics (VidTwin：解耦结构和动态的视频变分自编码器)**  \nYuchi Wang 等的工作引入了视频 VAE 模型，将视频分解为结构和动态潜在空间。主要贡献是提高了视频生成的质量和效率，实验显示在高分辨率场景下性能领先。\n\n**4. FFA Sora, video generation as fundus fluorescein angiography simulator (FFA Sora：视频生成作为眼底荧光血管造影模拟器)**  \nMingguang He 等学者开发的模型使用扩散变分自编码器模拟医疗图像生成。主要发现是通过文本提示生成高质量眼底图像，准确率达 81.43%，并解决了隐私保护问题，适用于医疗教育。\n\n**5. QTSeg: A Query Token-Based Dual-Mix Attention Framework with Multi-Level Feature Distribution for Medical Image Segmentation (QTSeg：基于查询标记的双混合注意力框架，用于多级特征分布的医疗图像分割)**  \nPhuong-Nam Tran 等提出的框架结合 CNN 和 Transformer 优化医疗图像分割。主要贡献是双重注意力机制提升了分割精度，并在多个数据集上超越现有方法。\n\n**6. BrainMAP: Learning Multiple Activation Pathways in Brain Networks (BrainMAP：学习脑网络中的多激活路径)**  \nSong Wang 等的工作使用图神经网络（GNN）分析脑 fMRI 数据。主要发现是改进了脑活动建模，实验显示在脑区激活路径上表现出色，提升了神经科学应用。\n\n**7. Markov Process-Based Graph Convolutional Networks for Entity Classification in Knowledge Graphs (基于 Markov 过程的图卷积网络，用于知识图谱实体分类)**  \nJohannes Mäkelburg 等提出的方法将 Markov 过程融入 GNN 中，用于知识图谱实体分类。主要贡献是提高了分类准确性和鲁棒性，实验证明在复杂图谱中性能优越。\n\n**8. BenCzechMark: A Czech-centric Multitask and Multimetric Benchmark for Large Language Models with Duel Scoring Mechanism (BenCzechMark：以捷克语为中心的多任务多指标 LLM 基准，带有双重评分机制)**  \nMartin Fajcik 等学者构建的基准数据集针对捷克语 LLM 评估。主要发现是改进了多任务评估体系，并发布了首个大规模捷克语语料库，推动了非英语 LLM 研究。\n\n**9. Theoretical Constraints on the Expressive Power of RoPE-based Tensor Attention Transformers (RoPE-based 张量注意力 Transformer 的表达能力理论约束)**  \nXiaoyu Li 等的工作分析了 Rotary Position Embedding (RoPE) 在 Transformer 中的理论限制。主要贡献是证明了在特定条件下 RoPE 无法解决某些问题，提供对模型扩展性的新洞见。\n\n其他论文，如一些交通预测或图像处理工作（如 \"Integrated Learning and Optimization for Congestion Management\"），虽有实际应用价值，但相对常规，我这里快速掠过：它们主要优化了资源管理和预测算法，但未带来突破性创新。\n\n总之，今天的论文强调了 AI 模型在安全和实际应用中的潜力，相关代码和数据集已在论文中开源，有兴趣的读者可深入探索。更多细节请查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2412.18048v1",
      "title": "Fair Knowledge Tracing in Second Language Acquisition",
      "title_zh": "第二语言习得中的公平知识追踪",
      "authors": [
        "Weitao Tang",
        "Guanliang Chen",
        "Shuaishuai Zu",
        "Jiangyi Luo"
      ],
      "abstract": "In second-language acquisition, predictive modeling aids educators in\nimplementing diverse teaching strategies, attracting significant research\nattention. However, while model accuracy is widely explored, model fairness\nremains under-examined. Model fairness ensures equitable treatment of groups,\npreventing unintentional biases based on attributes such as gender, ethnicity,\nor economic background. A fair model should produce impartial outcomes that do\nnot systematically disadvantage any group.\n  This study evaluates the fairness of two predictive models using the Duolingo\ndataset's en\\_es (English learners speaking Spanish), es\\_en (Spanish learners\nspeaking English), and fr\\_en (French learners speaking English) tracks. We\nanalyze: 1. Algorithmic fairness across platforms (iOS, Android, Web). 2.\nAlgorithmic fairness between developed and developing countries.\n  Key findings include: 1. Deep learning outperforms machine learning in\nsecond-language knowledge tracing due to improved accuracy and fairness. 2.\nBoth models favor mobile users over non-mobile users. 3. Machine learning\nexhibits stronger bias against developing countries compared to deep learning.\n4. Deep learning strikes a better balance of fairness and accuracy in the\nen\\_es and es\\_en tracks, while machine learning is more suitable for fr\\_en.\n  This study highlights the importance of addressing fairness in predictive\nmodels to ensure equitable educational strategies across platforms and regions.",
      "tldr_zh": "本研究探讨了第二语言习得中预测模型的公平性问题，使用Duolingo数据集的en_es、es_en和fr_en轨道，评估了两个模型在跨平台（iOS、Android、Web）和发达与发展中国家间的Algorithmic fairness。结果显示，Deep learning在准确性和公平性上优于Machine learning，但两者均偏向移动用户，且Machine learning对发展中国家的偏见更强；在en_es和es_en轨道，Deep learning在公平与准确性间取得更好平衡，而fr_en轨道更适合Machine learning。该研究强调了在预测模型中处理公平性的必要性，以确保教育策略的公平性和包容性。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18048v1",
      "published_date": "2024-12-23 23:47:40 UTC",
      "updated_date": "2024-12-23 23:47:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:36:06.800198"
    },
    {
      "arxiv_id": "2412.18047v3",
      "title": "Uncertainty-Aware Critic Augmentation for Hierarchical Multi-Agent EV Charging Control",
      "title_zh": "翻译失败",
      "authors": [
        "Lo Pang-Yun Ting",
        "Ali Şenol",
        "Huan-Yang Wang",
        "Hsu-Chao Lai",
        "Kun-Ta Chuang",
        "Huan Liu"
      ],
      "abstract": "The advanced bidirectional EV charging and discharging technology, aimed at\nsupporting grid stability and emergency operations, has driven a growing\ninterest in workplace applications. It not only reduces electricity expenses\nbut also enhances the resilience in handling practical matters, such as peak\npower limitation, fluctuating energy prices, and unpredictable EV departures.\nConsidering these factors systematically can benefit energy efficiency in\noffice buildings and for EV users simultaneously. To employ AI to address these\nissues, we propose HUCA, a novel real-time charging control for regulating\nenergy demands for both the building and EVs. HUCA employs hierarchical\nactor-critic networks to dynamically reduce electricity costs in buildings,\naccounting for the needs of EV charging in the dynamic pricing scenario. To\ntackle the uncertain EV departures, we introduce a new critic augmentation to\naccount for departure uncertainties in evaluating the charging decisions, while\nmaintaining the robustness of the charging control. Experiments on real-world\nelectricity datasets under both simulated certain and uncertain departure\nscenarios demonstrate that HUCA outperforms baselines in terms of total\nelectricity costs while maintaining competitive performance in fulfilling EV\ncharging requirements. A case study also manifests that HUCA effectively\nbalances energy supply between the building and EVs based on real-time\ninformation, showcasing its potential as a key AI-driven solution for vehicle\ncharging control.",
      "tldr_zh": "这篇论文提出 HUCA，一种分层多智能体 EV 充电控制系统，旨在动态降低建筑物电力成本，同时处理 EV 充电需求的不确定性，如不可预测的离场和波动能源价格。HUCA 采用分层 actor-critic 网络，并引入 uncertainty-aware critic augmentation 来评估充电决策，确保系统的稳健性和准确性。实验在真实数据集上显示，HUCA 在模拟确定和不确定场景中优于基线模型，总电力成本降低，同时有效平衡建筑和 EV 的能源供应，展示了其作为 AI 驱动充电解决方案的潜力。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18047v3",
      "published_date": "2024-12-23 23:45:45 UTC",
      "updated_date": "2025-02-17 11:19:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:36:18.069198"
    },
    {
      "arxiv_id": "2412.18046v1",
      "title": "Emoji Retrieval from Gibberish or Garbled Social Media Text: A Novel Methodology and A Case Study",
      "title_zh": "翻译失败",
      "authors": [
        "Shuqi Cui",
        "Nirmalya Thakur",
        "Audrey Poon"
      ],
      "abstract": "Emojis are widely used across social media platforms but are often lost in\nnoisy or garbled text, posing challenges for data analysis and machine\nlearning. Conventional preprocessing approaches recommend removing such text,\nrisking the loss of emojis and their contextual meaning. This paper proposes a\nthree-step reverse-engineering methodology to retrieve emojis from garbled text\nin social media posts. The methodology also identifies reasons for the\ngeneration of such text during social media data mining. To evaluate its\neffectiveness, the approach was applied to 509,248 Tweets about the Mpox\noutbreak, a dataset referenced in about 30 prior works that failed to retrieve\nemojis from garbled text. Our method retrieved 157,748 emojis from 76,914\nTweets. Improvements in text readability and coherence were demonstrated\nthrough metrics such as Flesch Reading Ease, Flesch-Kincaid Grade Level,\nColeman-Liau Index, Automated Readability Index, Dale-Chall Readability Score,\nText Standard, and Reading Time. Additionally, the frequency of individual\nemojis and their patterns of usage in these Tweets were analyzed, and the\nresults are presented.",
      "tldr_zh": "本研究提出了一种新型三步反向工程方法，用于从社交媒体的乱码或乱码文本中检索Emojis，同时识别生成这些文本的原因。该方法避免了传统预处理方式删除乱码文本导致的Emojis和上下文丢失问题，并在509,248条关于Mpox疫情的Tweets数据集上进行评估，成功检索了157,748个Emojis来自76,914条Tweets。通过Flesch Reading Ease、Flesch-Kincaid Grade Level、Coleman-Liau Index等可读性指标，展示了文本可读性和连贯性的显著提升。最后，该研究分析了Emojis的频率和使用模式，为社交媒体数据分析和机器学习提供了更有效的工具。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.LG",
        "I.2.7; I.2.8; I.5.4; K.4.2; H.2.8; I.2.6"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18046v1",
      "published_date": "2024-12-23 23:44:13 UTC",
      "updated_date": "2024-12-23 23:44:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:36:29.238236"
    },
    {
      "arxiv_id": "2412.18043v1",
      "title": "Aligning AI Research with the Needs of Clinical Coding Workflows: Eight Recommendations Based on US Data Analysis and Critical Review",
      "title_zh": "翻译失败",
      "authors": [
        "Yidong Gan",
        "Maciej Rybinski",
        "Ben Hachey",
        "Jonathan K. Kummerfeld"
      ],
      "abstract": "Clinical coding is crucial for healthcare billing and data analysis. Manual\nclinical coding is labour-intensive and error-prone, which has motivated\nresearch towards full automation of the process. However, our analysis, based\non US English electronic health records and automated coding research using\nthese records, shows that widely used evaluation methods are not aligned with\nreal clinical contexts. For example, evaluations that focus on the top 50 most\ncommon codes are an oversimplification, as there are thousands of codes used in\npractice. This position paper aims to align AI coding research more closely\nwith practical challenges of clinical coding. Based on our analysis, we offer\neight specific recommendations, suggesting ways to improve current evaluation\nmethods. Additionally, we propose new AI-based methods beyond automated coding,\nsuggesting alternative approaches to assist clinical coders in their workflows.",
      "tldr_zh": "这篇论文分析了临床编码在医疗计费和数据分析中的关键作用，并指出手动编码耗时易错，推动了AI自动化的研究。然而，基于美国英语电子健康记录的数据分析显示，当前AI编码研究的评估方法（如仅关注前50个常见代码）与实际临床环境脱节，因为实际涉及数千个代码。该论文提供八个具体推荐，以改进评估方法，使AI研究更贴近临床挑战；此外，还提出新的AI-based methods，作为辅助临床编码员工作流程的替代方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "We received a meta-review score of 5 in ARR October 2024",
      "pdf_url": "http://arxiv.org/pdf/2412.18043v1",
      "published_date": "2024-12-23 23:39:05 UTC",
      "updated_date": "2024-12-23 23:39:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:36:40.407311"
    },
    {
      "arxiv_id": "2412.18040v1",
      "title": "Theoretical Constraints on the Expressive Power of $\\mathsf{RoPE}$-based Tensor Attention Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoyu Li",
        "Yingyu Liang",
        "Zhenmei Shi",
        "Zhao Song",
        "Mingda Wan"
      ],
      "abstract": "Tensor Attention extends traditional attention mechanisms by capturing\nhigh-order correlations across multiple modalities, addressing the limitations\nof classical matrix-based attention. Meanwhile, Rotary Position Embedding\n($\\mathsf{RoPE}$) has shown superior performance in encoding positional\ninformation in long-context scenarios, significantly enhancing transformer\nmodels' expressiveness. Despite these empirical successes, the theoretical\nlimitations of these technologies remain underexplored. In this study, we\nanalyze the circuit complexity of Tensor Attention and $\\mathsf{RoPE}$-based\nTensor Attention, showing that with polynomial precision, constant-depth\nlayers, and linear or sublinear hidden dimension, they cannot solve fixed\nmembership problems or $(A_{F,r})^*$ closure problems, under the assumption\nthat $\\mathsf{TC}^0 \\neq \\mathsf{NC}^1$. These findings highlight a gap between\nthe empirical performance and theoretical constraints of Tensor Attention and\n$\\mathsf{RoPE}$-based Tensor Attention Transformers, offering insights that\ncould guide the development of more theoretically grounded approaches to\nTransformer model design and scaling.",
      "tldr_zh": "本研究分析了Tensor Attention和$\\mathsf{RoPE}$-based Tensor Attention Transformers的理论限制，Tensor Attention通过捕捉多模态高阶相关性扩展了传统注意力机制，而$\\mathsf{RoPE}$则在长上下文场景中提升了位置编码的表达能力。研究通过电路复杂度评估发现，在多项式精度、常量深度层以及线性或次线性隐藏维度的条件下，这些机制无法解决固定成员问题或$(A_{F,r})^*$闭包问题，假设$\\mathsf{TC}^0 \\neq \\mathsf{NC}^1$。这些发现揭示了经验性能与理论约束之间的差距，并为开发更具理论基础的Transformer模型设计和扩展提供指导。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CC",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18040v1",
      "published_date": "2024-12-23 23:26:07 UTC",
      "updated_date": "2024-12-23 23:26:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:36:53.855905"
    },
    {
      "arxiv_id": "2412.18038v1",
      "title": "AA-SGAN: Adversarially Augmented Social GAN with Synthetic Data",
      "title_zh": "翻译失败",
      "authors": [
        "Mirko Zaffaroni",
        "Federico Signoretta",
        "Marco Grangetto",
        "Attilio Fiandrotti"
      ],
      "abstract": "Accurately predicting pedestrian trajectories is crucial in applications such\nas autonomous driving or service robotics, to name a few. Deep generative\nmodels achieve top performance in this task, assuming enough labelled\ntrajectories are available for training. To this end, large amounts of\nsynthetically generated, labelled trajectories exist (e.g., generated by video\ngames). However, such trajectories are not meant to represent pedestrian motion\nrealistically and are ineffective at training a predictive model. We propose a\nmethod and an architecture to augment synthetic trajectories at training time\nand with an adversarial approach. We show that trajectory augmentation at\ntraining time unleashes significant gains when a state-of-the-art generative\nmodel is evaluated over real-world trajectories.",
      "tldr_zh": "该论文针对行人轨迹预测问题（如自动驾驶应用），提出AA-SGAN（Adversarially Augmented Social GAN）框架，通过对抗式方法在训练时增强合成数据。AA-SGAN利用合成轨迹的丰富性，结合对抗训练来模拟真实行人运动，从而解决合成数据不真实导致的模型性能问题。实验结果表明，该方法显著提升了深度生成模型在真实世界轨迹上的预测准确性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18038v1",
      "published_date": "2024-12-23 23:17:44 UTC",
      "updated_date": "2024-12-23 23:17:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:37:04.871991"
    },
    {
      "arxiv_id": "2412.18036v2",
      "title": "Explainability in Neural Networks for Natural Language Processing Tasks",
      "title_zh": "神经网络在自然语言处理任务中的可解释性",
      "authors": [
        "Melkamu Mersha",
        "Mingiziem Bitewa",
        "Tsion Abay",
        "Jugal Kalita"
      ],
      "abstract": "Neural networks are widely regarded as black-box models, creating significant\nchallenges in understanding their inner workings, especially in natural\nlanguage processing (NLP) applications. To address this opacity, model\nexplanation techniques like Local Interpretable Model-Agnostic Explanations\n(LIME) have emerged as essential tools for providing insights into the behavior\nof these complex systems. This study leverages LIME to interpret a multi-layer\nperceptron (MLP) neural network trained on a text classification task. By\nanalyzing the contribution of individual features to model predictions, the\nLIME approach enhances interpretability and supports informed decision-making.\nDespite its effectiveness in offering localized explanations, LIME has\nlimitations in capturing global patterns and feature interactions. This\nresearch highlights the strengths and shortcomings of LIME and proposes\ndirections for future work to achieve more comprehensive interpretability in\nneural NLP models.",
      "tldr_zh": "这篇论文探讨了神经网络在自然语言处理(NLP)任务中的可解释性问题，将神经网络视为黑盒模型，并使用Local Interpretable Model-Agnostic Explanations (LIME)技术来解释多层感知器(MLP)模型的行为。研究通过分析单个特征对文本分类预测的贡献，提升了模型的可解释性和决策支持能力。论文突出了LIME在提供局部解释方面的优势，同时指出了其在捕捉全局模式和特征交互方面的局限性，并提出未来工作方向以实现更全面的神经NLP模型可解释性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18036v2",
      "published_date": "2024-12-23 23:09:56 UTC",
      "updated_date": "2025-01-08 19:44:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:37:17.096788"
    },
    {
      "arxiv_id": "2412.18639v1",
      "title": "A Grounded Observer Framework for Establishing Guardrails for Foundation Models in Socially Sensitive Domains",
      "title_zh": "翻译失败",
      "authors": [
        "Rebecca Ramnauth",
        "Dražen Brščić",
        "Brian Scassellati"
      ],
      "abstract": "As foundation models increasingly permeate sensitive domains such as\nhealthcare, finance, and mental health, ensuring their behavior meets desired\noutcomes and social expectations becomes critical. Given the complexities of\nthese high-dimensional models, traditional techniques for constraining agent\nbehavior, which typically rely on low-dimensional, discrete state and action\nspaces, cannot be directly applied. Drawing inspiration from robotic action\nselection techniques, we propose the grounded observer framework for\nconstraining foundation model behavior that offers both behavioral guarantees\nand real-time variability. This method leverages real-time assessment of\nlow-level behavioral characteristics to dynamically adjust model actions and\nprovide contextual feedback. To demonstrate this, we develop a system capable\nof sustaining contextually appropriate, casual conversations (\"small talk\"),\nwhich we then apply to a robot for novel, unscripted interactions with humans.\nFinally, we discuss potential applications of the framework for other social\ncontexts and areas for further research.",
      "tldr_zh": "该研究针对基础模型（foundation models）在社会敏感领域（如医疗、金融和心理健康）中的行为约束问题，提出了一种grounded observer framework。该框架借鉴机器人行动选择技术，通过实时评估低级行为特征来动态调整模型动作，提供行为保证和实时可变性。研究者开发了一个系统，支持上下文适当的随意对话（small talk），并应用于机器人进行新颖、非脚本化的人机互动。最后，该框架的潜在应用扩展到其他社会情境，并指出了进一步研究的领域。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "arXiv admin note: text overlap with arXiv:2412.18023",
      "pdf_url": "http://arxiv.org/pdf/2412.18639v1",
      "published_date": "2024-12-23 22:57:05 UTC",
      "updated_date": "2024-12-23 22:57:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:37:29.098144"
    },
    {
      "arxiv_id": "2412.18023v1",
      "title": "More than Chit-Chat: Developing Robots for Small-Talk Interactions",
      "title_zh": "翻译失败",
      "authors": [
        "Rebecca Ramnauth",
        "Dražen Brščić",
        "Brian Scassellati"
      ],
      "abstract": "Beyond mere formality, small talk plays a pivotal role in social dynamics,\nserving as a verbal handshake for building rapport and understanding. For\nconversational AI and social robots, the ability to engage in small talk\nenhances their perceived sociability, leading to more comfortable and natural\nuser interactions. In this study, we evaluate the capacity of current Large\nLanguage Models (LLMs) to drive the small talk of a social robot and identify\nkey areas for improvement. We introduce a novel method that autonomously\ngenerates feedback and ensures LLM-generated responses align with small talk\nconventions. Through several evaluations -- involving chatbot interactions and\nhuman-robot interactions -- we demonstrate the system's effectiveness in\nguiding LLM-generated responses toward realistic, human-like, and natural\nsmall-talk exchanges.",
      "tldr_zh": "这篇论文探讨了小谈（small talk）在社交动态中的关键作用，特别是如何提升对话AI和社交机器人的用户互动体验。研究评估了当前Large Language Models (LLMs) 在驱动机器人小谈方面的表现，并识别了改进的重点领域。作者提出了一种新方法，通过自主生成反馈来确保LLMs生成的响应符合小谈的自然约定。实验结果显示，该系统在聊天机器人互动和人机互动中有效，显著提高了小谈的真实性和人性化水平。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18023v1",
      "published_date": "2024-12-23 22:35:38 UTC",
      "updated_date": "2024-12-23 22:35:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:37:41.368062"
    },
    {
      "arxiv_id": "2412.18022v1",
      "title": "Trustworthy and Efficient LLMs Meet Databases",
      "title_zh": "翻译失败",
      "authors": [
        "Kyoungmin Kim",
        "Anastasia Ailamaki"
      ],
      "abstract": "In the rapidly evolving AI era with large language models (LLMs) at the core,\nmaking LLMs more trustworthy and efficient, especially in output generation\n(inference), has gained significant attention. This is to reduce plausible but\nfaulty LLM outputs (a.k.a hallucinations) and meet the highly increased\ninference demands. This tutorial explores such efforts and makes them\ntransparent to the database community. Understanding these efforts is essential\nin harnessing LLMs in database tasks and adapting database techniques to LLMs.\nFurthermore, we delve into the synergy between LLMs and databases, highlighting\nnew opportunities and challenges in their intersection. This tutorial aims to\nshare with database researchers and practitioners essential concepts and\nstrategies around LLMs, reduce the unfamiliarity of LLMs, and inspire joining\nin the intersection between LLMs and databases.",
      "tldr_zh": "本教程探讨如何提升大型语言模型(LLMs)的可信性和效率，特别是减少幻觉并满足推理需求，以适应数据库任务。该教程针对数据库社区，详细解释相关努力，包括LLMs与数据库的协同作用，并突出二者交叉领域的机会和挑战。通过分享核心概念和策略，该教程旨在降低对LLMs的陌生感，并激励研究者参与这一交叉领域的研究和应用。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18022v1",
      "published_date": "2024-12-23 22:34:40 UTC",
      "updated_date": "2024-12-23 22:34:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:38:06.437064"
    },
    {
      "arxiv_id": "2412.18003v2",
      "title": "Integrated Learning and Optimization for Congestion Management and Profit Maximization in Real-Time Electricity Market",
      "title_zh": "整合学习与优化用于实时电力市场的拥塞管理和利润最大化",
      "authors": [
        "Imran Pervez",
        "Ricardo Pinto Lima",
        "Omar Knio"
      ],
      "abstract": "We develop novel integrated learning and optimization (ILO) methodologies to\nsolve economic dispatch (ED) and DC optimal power flow (DCOPF) problems for\nbetter economic operation. The optimization problem for ED is formulated with\nload being an unknown parameter while DCOPF consists of load and power transfer\ndistribution factor (PTDF) matrix as unknown parameters. PTDF represents the\nincremental variations of real power on transmission lines which occur due to\nreal power transfers between two regions. These values represent a linearized\napproximation of power flows over the transmission lines. We develop novel ILO\nformulations to solve post-hoc penalties in electricity market and line\ncongestion problems using ED and DCOPF optimization formulations. Our proposed\nmethodologies capture the real-time electricity market and line congestion\nbehavior to train the regret function which eventually train unknown loads at\ndifferent buses and line PTDF matrix to achieve the afore-mentioned post-hoc\ngoals. The proposed methodology is compared to sequential learning and\noptimization (SLO) which train load and PTDF forecasts for accuracy rather than\neconomic operation. Our experimentation prove the superiority of ILO in\nminimizing the post-hoc penalties in electricity markets and minimizing the\nline congestion thereby improving the economic operation with noticeable\namount.",
      "tldr_zh": "本研究提出了一种集成学习和优化 (ILO) 方法，用于解决实时电力市场的经济调度 (ED) 和 DC 最佳功率流 (DCOPF) 问题，其中负载和 PTDF 矩阵作为未知参数。ILO 通过训练遗憾函数来捕捉实时市场行为和线路拥堵，实现后验惩罚最小化和经济操作优化。实验结果显示，ILO 相较于顺序学习和优化 (SLO) 方法，在减少电力市场惩罚和缓解线路拥堵方面表现出显著优势，从而提升了整体经济效率。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18003v2",
      "published_date": "2024-12-23 21:53:06 UTC",
      "updated_date": "2025-01-06 05:46:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:38:17.879870"
    },
    {
      "arxiv_id": "2412.17998v2",
      "title": "WavePulse: Real-time Content Analytics of Radio Livestreams",
      "title_zh": "WavePulse：广播直播流的实时内容分析",
      "authors": [
        "Govind Mittal",
        "Sarthak Gupta",
        "Shruti Wagle",
        "Chirag Chopra",
        "Anthony J DeMattee",
        "Nasir Memon",
        "Mustaque Ahamad",
        "Chinmay Hegde"
      ],
      "abstract": "Radio remains a pervasive medium for mass information dissemination, with\nAM/FM stations reaching more Americans than either smartphone-based social\nnetworking or live television. Increasingly, radio broadcasts are also streamed\nonline and accessed over the Internet. We present WavePulse, a framework that\nrecords, documents, and analyzes radio content in real-time. While our\nframework is generally applicable, we showcase the efficacy of WavePulse in a\ncollaborative project with a team of political scientists focusing on the 2024\nPresidential Elections. We use WavePulse to monitor livestreams of 396 news\nradio stations over a period of three months, processing close to 500,000 hours\nof audio streams. These streams were converted into time-stamped, diarized\ntranscripts and analyzed to track answer key political science questions at\nboth the national and state levels. Our analysis revealed how local issues\ninteracted with national trends, providing insights into information flow. Our\nresults demonstrate WavePulse's efficacy in capturing and analyzing content\nfrom radio livestreams sourced from the Web. Code and dataset can be accessed\nat \\url{https://wave-pulse.io}.",
      "tldr_zh": "WavePulse 是一个实时记录、文档化和分析广播内容的框架，针对 AM/FM 广播和在线流媒体的广泛应用。研究团队使用该框架监控了 396 个新闻广播电台的直播，处理近 50 万小时音频，将其转换为时间戳和对话分离的转录文本，并分析关键政治问题，如 2024 年总统选举中的本地问题与国家趋势互动。结果显示，WavePulse 有效捕捉了信息流动的洞见，为大规模广播内容分析提供了可扩展工具。代码和数据集可通过 https://wave-pulse.io 访问。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "To appear at The Web Conference (WWW) 2025. 20 Pages, 24 figures.\n  Access code and dataset at https://wave-pulse.io",
      "pdf_url": "http://arxiv.org/pdf/2412.17998v2",
      "published_date": "2024-12-23 21:42:31 UTC",
      "updated_date": "2025-01-29 17:17:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:38:30.949984"
    },
    {
      "arxiv_id": "2501.00034v1",
      "title": "Time Series Feature Redundancy Paradox: An Empirical Study Based on Mortgage Default Prediction",
      "title_zh": "时间序列特征冗余悖论：基于抵押贷款违约预测的实证研究",
      "authors": [
        "Chengyue Huang",
        "Yahe Yang"
      ],
      "abstract": "With the widespread application of machine learning in financial risk\nmanagement, conventional wisdom suggests that longer training periods and more\nfeature variables contribute to improved model performance. This paper,\nfocusing on mortgage default prediction, empirically discovers a phenomenon\nthat contradicts traditional knowledge: in time series prediction, increased\ntraining data timespan and additional non-critical features actually lead to\nsignificant deterioration in prediction effectiveness. Using Fannie Mae's\nmortgage data, the study compares predictive performance across different time\nwindow lengths (2012-2022) and feature combinations, revealing that shorter\ntime windows (such as single-year periods) paired with carefully selected key\nfeatures yield superior prediction results. The experimental results indicate\nthat extended time spans may introduce noise from historical data and outdated\nmarket patterns, while excessive non-critical features interfere with the\nmodel's learning of core default factors. This research not only challenges the\ntraditional \"more is better\" approach in data modeling but also provides new\ninsights and practical guidance for feature selection and time window\noptimization in financial risk prediction.",
      "tldr_zh": "本研究揭示了时间序列预测中的“特征冗余悖论”（Feature Redundancy Paradox），即在抵押贷款违约预测中，更长的训练数据时长和更多非关键特征变量会显著降低模型性能，挑战了传统的“more is better”观点。研究者使用Fannie Mae的抵押贷款数据，比较了不同时间窗口（2012-2022年）和特征组合的预测效果，发现较短的时间窗口（如单年期）结合精心选择的key features能获得更优结果。实验结果表明，延长时窗可能引入历史噪声和过时市场模式，而过多的non-critical features会干扰模型对核心违约因素的学习，从而为金融风险预测中的feature selection和time window optimization提供新见解和实用指导。",
      "categories": [
        "q-fin.ST",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-fin.ST",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00034v1",
      "published_date": "2024-12-23 21:28:32 UTC",
      "updated_date": "2024-12-23 21:28:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:38:41.674007"
    },
    {
      "arxiv_id": "2412.17993v1",
      "title": "Multi-Agent Path Finding in Continuous Spaces with Projected Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jinhao Liang",
        "Jacob K. Christopher",
        "Sven Koenig",
        "Ferdinando Fioretto"
      ],
      "abstract": "Multi-Agent Path Finding (MAPF) is a fundamental problem in robotics,\nrequiring the computation of collision-free paths for multiple agents moving\nfrom their respective start to goal positions. Coordinating multiple agents in\na shared environment poses significant challenges, especially in continuous\nspaces where traditional optimization algorithms struggle with scalability.\nMoreover, these algorithms often depend on discretized representations of the\nenvironment, which can be impractical in image-based or high-dimensional\nsettings. Recently, diffusion models have shown promise in single-agent path\nplanning, capturing complex trajectory distributions and generating smooth\npaths that navigate continuous, high-dimensional spaces. However, directly\nextending diffusion models to MAPF introduces new challenges since these models\nstruggle to ensure constraint feasibility, such as inter-agent collision\navoidance. To overcome this limitation, this work proposes a novel approach\nthat integrates constrained optimization with diffusion models for MAPF in\ncontinuous spaces. This unique combination directly produces feasible\nmulti-agent trajectories that respect collision avoidance and kinematic\nconstraints. The effectiveness of our approach is demonstrated across various\nchallenging simulated scenarios of varying dimensionality.",
      "tldr_zh": "这篇论文解决了 Multi-Agent Path Finding (MAPF) 在连续空间中的挑战，该问题涉及为多个代理计算无碰撞路径，但传统优化算法在可扩展性和高维环境中表现不佳。作者提出了一种创新方法，将约束优化与 diffusion models 整合，直接生成可行的多代理轨迹，确保碰撞避免和运动学约束。实验结果显示，该方法在各种挑战性模拟场景中有效，证明了其在机器人学中的潜力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17993v1",
      "published_date": "2024-12-23 21:27:19 UTC",
      "updated_date": "2024-12-23 21:27:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:38:54.374778"
    },
    {
      "arxiv_id": "2412.17984v1",
      "title": "ICPR 2024 Competition on Domain Adaptation and GEneralization for Character Classification (DAGECC)",
      "title_zh": "翻译失败",
      "authors": [
        "Sofia Marino",
        "Jennifer Vandoni",
        "Emanuel Aldea",
        "Ichraq Lemghari",
        "Sylvie Le Hégarat-Mascle",
        "Frédéric Jurie"
      ],
      "abstract": "In this companion paper for the DAGECC (Domain Adaptation and GEneralization\nfor Character Classification) competition organized within the frame of the\nICPR 2024 conference, we present the general context of the tasks we proposed\nto the community, we introduce the data that were prepared for the competition\nand we provide a summary of the results along with a description of the top\nthree winning entries. The competition was centered around domain adaptation\nand generalization, and our core aim is to foster interest and facilitate\nadvancement on these topics by providing a high-quality, lightweight, real\nworld dataset able to support fast prototyping and validation of novel ideas.",
      "tldr_zh": "这篇论文介绍了 ICPR 2024 会议中的 DAGECC 竞赛（Domain Adaptation and GEneralization for Character Classification），聚焦于领域适应和泛化在字符分类任务中的应用。论文详细阐述了竞赛的任务背景、准备的高质量轻量级真实世界数据集，以及这些数据集如何支持快速原型设计和验证新想法。最终，论文总结了竞赛结果并描述了前三名参赛者的方法，为推动这些领域的研究提供了宝贵资源。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Companion paper for the ICPR 2024 Competition on Domain Adaptation\n  and GEneralization for Character Classification (DAGECC)",
      "pdf_url": "http://arxiv.org/pdf/2412.17984v1",
      "published_date": "2024-12-23 21:06:08 UTC",
      "updated_date": "2024-12-23 21:06:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:39:06.018309"
    },
    {
      "arxiv_id": "2412.17977v1",
      "title": "TNNGen: Automated Design of Neuromorphic Sensory Processing Units for Time-Series Clustering",
      "title_zh": "翻译失败",
      "authors": [
        "Prabhu Vellaisamy",
        "Harideep Nair",
        "Vamsikrishna Ratnakaram",
        "Dhruv Gupta",
        "John Paul Shen"
      ],
      "abstract": "Temporal Neural Networks (TNNs), a special class of spiking neural networks,\ndraw inspiration from the neocortex in utilizing spike-timings for information\nprocessing. Recent works proposed a microarchitecture framework and custom\nmacro suite for designing highly energy-efficient application-specific TNNs.\nThese recent works rely on manual hardware design, a labor-intensive and\ntime-consuming process. Further, there is no open-source functional simulation\nframework for TNNs. This paper introduces TNNGen, a pioneering effort towards\nthe automated design of TNNs from PyTorch software models to post-layout\nnetlists. TNNGen comprises a novel PyTorch functional simulator (for TNN\nmodeling and application exploration) coupled with a Python-based hardware\ngenerator (for PyTorch-to-RTL and RTL-to-Layout conversions). Seven\nrepresentative TNN designs for time-series signal clustering across diverse\nsensory modalities are simulated and their post-layout hardware complexity and\ndesign runtimes are assessed to demonstrate the effectiveness of TNNGen. We\nalso highlight TNNGen's ability to accurately forecast silicon metrics without\nrunning hardware process flow.",
      "tldr_zh": "本文提出 TNNGen，一种自动化设计框架，用于 Temporal Neural Networks (TNNs) 的神经形态感官处理单元，针对时序信号聚类问题。该框架整合了一个 PyTorch 功能模拟器（用于 TNN 建模和应用探索）和一个 Python 硬件生成器（实现 PyTorch 到 RTL 以及 RTL 到布局的转换），以取代手动设计流程。通过七个代表性 TNN 设计，评估了后布局硬件复杂性、设计运行时间，并证明了 TNNGen 能准确预测硅指标，而无需实际硬件流程。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.AR",
      "comment": "Published in IEEE Transactions on Circuits and Systems II: Express\n  Briefs, May 2024",
      "pdf_url": "http://arxiv.org/pdf/2412.17977v1",
      "published_date": "2024-12-23 20:46:53 UTC",
      "updated_date": "2024-12-23 20:46:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:39:18.890126"
    },
    {
      "arxiv_id": "2412.17975v1",
      "title": "Improving Sickle Cell Disease Classification: A Fusion of Conventional Classifiers, Segmented Images, and Convolutional Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Victor Júnio Alcântara Cardoso",
        "Rodrigo Moreira",
        "João Fernando Mari",
        "Larissa Ferreira Rodrigues Moreira"
      ],
      "abstract": "Sickle cell anemia, which is characterized by abnormal erythrocyte\nmorphology, can be detected using microscopic images. Computational techniques\nin medicine enhance the diagnosis and treatment efficiency. However, many\ncomputational techniques, particularly those based on Convolutional Neural\nNetworks (CNNs), require high resources and time for training, highlighting the\nresearch opportunities in methods with low computational overhead. In this\npaper, we propose a novel approach combining conventional classifiers,\nsegmented images, and CNNs for the automated classification of sickle cell\ndisease. We evaluated the impact of segmented images on classification,\nproviding insight into deep learning integration. Our results demonstrate that\nusing segmented images and CNN features with an SVM achieves an accuracy of\n96.80%. This finding is relevant for computationally efficient scenarios,\npaving the way for future research and advancements in medical-image analysis.",
      "tldr_zh": "本研究针对镰状细胞贫血的检测问题，提出了一种结合传统分类器、分段图像和Convolutional Neural Networks (CNNs)的创新方法，以提高分类准确率并降低计算开销。该方法评估了分段图像对分类的影响，通过整合CNN特征与SVM（支持向量机）进行分类，实现了96.80%的准确率。该方法适用于计算资源有限的场景，为医疗图像分析的未来发展提供了高效途径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "14 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.17975v1",
      "published_date": "2024-12-23 20:42:15 UTC",
      "updated_date": "2024-12-23 20:42:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:39:29.256612"
    },
    {
      "arxiv_id": "2412.17967v1",
      "title": "Towards Cognitive Service Delivery on B5G through AIaaS Architecture",
      "title_zh": "翻译失败",
      "authors": [
        "Larissa F. Rodrigues Moreira",
        "Rodrigo Moreira",
        "Flávio de Oliveira Silva",
        "André R. Backes"
      ],
      "abstract": "Artificial Intelligence (AI) is pivotal in advancing mobile network systems\nby facilitating smart capabilities and automation. The transition from 4G to 5G\nhas substantial implications for AI in consolidating a network predominantly\ngeared towards business verticals. In this context, 3GPP has specified and\nintroduced the Network Data Analytics Function (NWDAF) entity at the network's\ncore to provide insights based on AI algorithms to benefit network\norchestration. This paper proposes a framework for evolving NWDAF that presents\nthe interfaces necessary to further empower the core network with AI\ncapabilities B5G and 6G. In addition, we identify a set of research directions\nfor realizing a distributed e-NWDAF.",
      "tldr_zh": "这篇论文探讨了 AI 在移动网络系统中的关键作用，特别是从 4G 到 5G 的转变，以及 3GPP 引入的 Network Data Analytics Function (NWDAF) 来提供基于 AI 的网络洞见。论文提出一个框架来演进 NWDAF，通过 AIaaS Architecture 定义必要的接口，以增强 B5G 和 6G 核心网络的 AI 能力。论文还识别了实现分布式 e-NWDAF 的研究方向，为未来网络自动化和智能服务交付提供指导。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.17967v1",
      "published_date": "2024-12-23 20:30:29 UTC",
      "updated_date": "2024-12-23 20:30:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:39:41.992870"
    },
    {
      "arxiv_id": "2412.17966v1",
      "title": "tuGEMM: Area-Power-Efficient Temporal Unary GEMM Architecture for Low-Precision Edge AI",
      "title_zh": "翻译失败",
      "authors": [
        "Harideep Nair",
        "Prabhu Vellaisamy",
        "Albert Chen",
        "Joseph Finn",
        "Anna Li",
        "Manav Trivedi",
        "John Paul Shen"
      ],
      "abstract": "General matrix multiplication (GEMM) is a ubiquitous computing\nkernel/algorithm for data processing in diverse applications, including\nartificial intelligence (AI) and deep learning (DL). Recent shift towards edge\ncomputing has inspired GEMM architectures based on unary computing, which are\npredominantly stochastic and rate-coded systems. This paper proposes a novel\nGEMM architecture based on temporal-coding, called tuGEMM, that performs exact\ncomputation. We introduce two variants of tuGEMM, serial and parallel, with\ndistinct area/power-latency trade-offs. Post-synthesis Power-Performance-Area\n(PPA) in 45 nm CMOS are reported for 2-bit, 4-bit, and 8-bit computations. The\ndesigns illustrate significant advantages in area-power efficiency over\nstate-of-the-art stochastic unary systems especially at low precisions, e.g.\nincurring just 0.03 mm^2 and 9 mW for 4 bits, and 0.01 mm^2 and 4 mW for 2\nbits. This makes tuGEMM ideal for power constrained mobile and edge devices\nperforming always-on real-time sensory processing.",
      "tldr_zh": "本文提出了一种基于 temporal-coding 的 GEMM 架构，名为 tuGEMM，旨在为低精度边缘 AI 提供高效、精确的矩阵乘法计算。tuGEMM 包括串行和并行两种变体，能够优化面积-功耗与延迟的权衡，并在 45 nm CMOS 工艺下实现显著优势，例如 4-bit 计算仅需 0.03 mm² 和 9 mW，2-bit 计算仅需 0.01 mm² 和 4 mW。相比现有随机一元系统，tuGEMM 在低精度场景下提升了面积-功耗效率，使其特别适合于功耗受限的移动和边缘设备，用于始终在线的实时传感器处理。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AR",
      "comment": "Published in 2023 IEEE International Symposium on Circuits and\n  Systems (ISCAS), Monterey, CA, USA, 2023",
      "pdf_url": "http://arxiv.org/pdf/2412.17966v1",
      "published_date": "2024-12-23 20:30:28 UTC",
      "updated_date": "2024-12-23 20:30:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:39:55.530558"
    },
    {
      "arxiv_id": "2412.17965v2",
      "title": "LMV-RPA: Large Model Voting-based Robotic Process Automation",
      "title_zh": "LMV-RPA：基于大型模型投票的机器人流程自动化",
      "authors": [
        "Osama Abdellatif",
        "Ahmed Ayman",
        "Ali Hamdi"
      ],
      "abstract": "Automating high-volume unstructured data processing is essential for\noperational efficiency. Optical Character Recognition (OCR) is critical but\noften struggles with accuracy and efficiency in complex layouts and ambiguous\ntext. These challenges are especially pronounced in large-scale tasks requiring\nboth speed and precision. This paper introduces LMV-RPA, a Large Model\nVoting-based Robotic Process Automation system to enhance OCR workflows.\nLMV-RPA integrates outputs from OCR engines such as Paddle OCR, Tesseract OCR,\nEasy OCR, and DocTR with Large Language Models (LLMs) like LLaMA 3 and\nGemini-1.5-pro. Using a majority voting mechanism, it processes OCR outputs\ninto structured JSON formats, improving accuracy, particularly in complex\nlayouts. The multi-phase pipeline processes text extracted by OCR engines\nthrough LLMs, combining results to ensure the most accurate outputs. LMV-RPA\nachieves 99 percent accuracy in OCR tasks, surpassing baseline models with 94\npercent, while reducing processing time by 80 percent. Benchmark evaluations\nconfirm its scalability and demonstrate that LMV-RPA offers a faster, more\nreliable, and efficient solution for automating large-scale document processing\ntasks.",
      "tldr_zh": "本文提出 LMV-RPA，一种基于大型模型投票的机器人过程自动化系统，旨在解决 OCR 在处理复杂布局和模糊文本时的准确性和效率问题。系统整合多种 OCR 引擎（如 Paddle OCR、Tesseract OCR）和大型语言模型（LLMs，如 LLaMA 3 和 Gemini-1.5-pro），通过多数投票机制处理输出并转换为结构化的 JSON 格式，从而提升多阶段文本处理的可靠性。实验结果显示，LMV-RPA 在 OCR 任务中达到 99% 的准确率，比基线模型的 94% 高出 5%，并将处理时间减少 80%，证明其在大规模文档处理中的可扩展性和高效性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.RO",
      "comment": "12 pages, 1 figures, 1 algorithm",
      "pdf_url": "http://arxiv.org/pdf/2412.17965v2",
      "published_date": "2024-12-23 20:28:22 UTC",
      "updated_date": "2025-04-28 15:54:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:40:07.202982"
    },
    {
      "arxiv_id": "2412.17964v1",
      "title": "Dynamic Multi-Agent Orchestration and Retrieval for Multi-Source Question-Answer Systems using Large Language Models",
      "title_zh": "动态多智能体编排与检索，用于使用大语言模型的多源问答系统",
      "authors": [
        "Antony Seabra",
        "Claudio Cavalcante",
        "Joao Nepomuceno",
        "Lucas Lago",
        "Nicolaas Ruberg",
        "Sergio Lifschitz"
      ],
      "abstract": "We propose a methodology that combines several advanced techniques in Large\nLanguage Model (LLM) retrieval to support the development of robust,\nmulti-source question-answer systems. This methodology is designed to integrate\ninformation from diverse data sources, including unstructured documents (PDFs)\nand structured databases, through a coordinated multi-agent orchestration and\ndynamic retrieval approach. Our methodology leverages specialized agents-such\nas SQL agents, Retrieval-Augmented Generation (RAG) agents, and router agents -\nthat dynamically select the most appropriate retrieval strategy based on the\nnature of each query. To further improve accuracy and contextual relevance, we\nemploy dynamic prompt engineering, which adapts in real time to query-specific\ncontexts. The methodology's effectiveness is demonstrated within the domain of\nContract Management, where complex queries often require seamless interaction\nbetween unstructured and structured data. Our results indicate that this\napproach enhances response accuracy and relevance, offering a versatile and\nscalable framework for developing question-answer systems that can operate\nacross various domains and data sources.",
      "tldr_zh": "该论文提出了一种动态多智能体编排和检索方法，用于利用 Large Language Models (LLMs) 构建鲁棒的多源问答系统，该方法整合了来自非结构化文档（如 PDFs）和结构化数据库的信息。关键组件包括 SQL agents、Retrieval-Augmented Generation (RAG) agents 和 router agents，这些智能体根据查询性质动态选择最佳检索策略，并结合动态提示工程以提升响应的准确性和上下文相关性。在合同管理领域进行验证，结果显示该方法显著提高了响应质量，并提供了一个通用的、可扩展框架，适用于各种领域和数据源。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "International Conference on NLP, AI, Computer Science & Engineering\n  (NLAICSE 2024)",
      "pdf_url": "http://arxiv.org/pdf/2412.17964v1",
      "published_date": "2024-12-23 20:28:20 UTC",
      "updated_date": "2024-12-23 20:28:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:40:18.645842"
    },
    {
      "arxiv_id": "2412.17959v1",
      "title": "Analysis of Transferred Pre-Trained Deep Convolution Neural Networks in Breast Masses Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Qusay Shihab Hamad",
        "Hussein Samma",
        "Shahrel Azmin Suandi"
      ],
      "abstract": "Breast cancer detection based on pre-trained convolution neural network (CNN)\nhas gained much interest among other conventional computer-based systems. In\nthe past few years, CNN technology has been the most promising way to find\ncancer in mammogram scans. In this paper, the effect of layer freezing in a\npre-trained CNN is investigated for breast cancer detection by classifying\nmammogram images as benign or malignant. Different VGG19 scenarios have been\nexamined based on the number of convolution layer blocks that have been frozen.\nThere are a total of six scenarios in this study. The primary benefits of this\nresearch are twofold: it improves the model's ability to detect breast cancer\ncases and it reduces the training time of VGG19 by freezing certain layers.To\nevaluate the performance of these scenarios, 1693 microbiological images of\nbenign and malignant breast cancers were utilized. According to the reported\nresults, the best recognition rate was obtained from a frozen first block of\nVGG19 with a sensitivity of 95.64 %, while the training of the entire VGG19\nyielded 94.48%.",
      "tldr_zh": "这篇论文分析了使用预训练的深度卷积神经网络(CNN)进行乳腺肿块识别，特别是通过转移学习和层冻结技术来检测乳腺X光图像中的良性和恶性病变。研究者考察了VGG19的六种不同场景，基于冻结卷积层块的数量，以优化模型性能。结果显示，冻结VGG19的第一个块取得了最高的敏感度(95.64%)，比训练整个网络(94.48%)略有提升，同时显著减少了训练时间，为乳腺癌检测提供了更高效的方法。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "Its a conference paper; the full proceeding is avalible at\n  https://icogoia.utem.edu.my/proceedings.html",
      "pdf_url": "http://arxiv.org/pdf/2412.17959v1",
      "published_date": "2024-12-23 20:16:45 UTC",
      "updated_date": "2024-12-23 20:16:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:40:31.172917"
    },
    {
      "arxiv_id": "2412.17957v2",
      "title": "ArchComplete: Autoregressive 3D Architectural Design Generation with Hierarchical Diffusion-Based Upsampling",
      "title_zh": "翻译失败",
      "authors": [
        "S. Rasoulzadeh",
        "M. Bank",
        "I. Kovacic",
        "K. Schinegger",
        "S. Rutzinger",
        "M. Wimmer"
      ],
      "abstract": "Recent advances in 3D generative models have shown promising results but\noften fall short in capturing the complexity of architectural geometries and\ntopologies and fine geometric details at high resolutions. To tackle this, we\npresent ArchComplete, a two-stage voxel-based 3D generative pipeline consisting\nof a vector-quantised model, whose composition is modelled with an\nautoregressive transformer for generating coarse shapes, followed by a\nhierarchical upsampling strategy for further enrichment with fine structures\nand details. Key to our pipeline is (i) learning a contextually rich codebook\nof local patch embeddings, optimised alongside a 2.5D perceptual loss that\ncaptures global spatial correspondence of projections onto three axis-aligned\northogonal planes, and (ii) redefining upsampling as a set of conditional\ndiffusion models learning from a hierarchy of randomly cropped coarse-to-fine\nlocal volumetric patches. Trained on our introduced dataset of 3D house models\nwith fully modelled exterior and interior, ArchComplete autoregressively\ngenerates models at the resolution of $64^{3}$ and progressively refines them\nup to $512^{3}$, with voxel sizes as small as $ \\approx 9\\text{cm}$.\nArchComplete solves a variety of tasks, including genetic interpolation and\nvariation, unconditional synthesis, shape and plan-drawing completion, as well\nas geometric detailisation, while achieving state-of-the-art performance in\nquality, diversity, and computational efficiency.",
      "tldr_zh": "本文提出ArchComplete，一种两阶段的体素(voxel)-based 3D建筑设计生成框架，利用vector-quantised模型和autoregressive transformer生成粗糙形状，然后通过hierarchical diffusion-based upsampling策略添加精细结构和细节。关键创新包括学习上下文丰富的局部patch嵌入代码书，并结合2.5D感知损失和条件扩散模型从粗到细优化局部体素patch，以捕捉全局空间对应。训练于新引入的3D房屋模型数据集，该框架从64^3分辨率逐步提升到512^3，实现state-of-the-art性能，在质量、多样性和计算效率上表现出色，并支持任务如无条件合成和几何细节化。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "14 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.17957v2",
      "published_date": "2024-12-23 20:13:27 UTC",
      "updated_date": "2025-02-13 21:57:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:40:43.144866"
    },
    {
      "arxiv_id": "2412.17953v1",
      "title": "Adaptive Signal Analysis for Automated Subsurface Defect Detection Using Impact Echo in Concrete Slabs",
      "title_zh": "翻译失败",
      "authors": [
        "Deepthi Pavurala",
        "Duoduo Liao",
        "Chaithra Reddy Pasunuru"
      ],
      "abstract": "This pilot study presents a novel, automated, and scalable methodology for\ndetecting and evaluating subsurface defect-prone regions in concrete slabs\nusing Impact Echo (IE) signal analysis. The approach integrates advanced signal\nprocessing, clustering, and visual analytics to identify subsurface anomalies.\nA unique adaptive thresholding method tailors frequency-based defect\nidentification to the distinct material properties of each slab. The\nmethodology generates frequency maps, binary masks, and k-means cluster maps to\nautomatically classify defect and non-defect regions. Key visualizations,\nincluding 3D surface plots, cluster maps, and contour plots, are employed to\nanalyze spatial frequency distributions and highlight structural anomalies. The\nstudy utilizes a labeled dataset constructed at the Federal Highway\nAdministration (FHWA) Advanced Sensing Technology Nondestructive Evaluation\nLaboratory. Evaluations involve ground-truth masking, comparing the generated\ndefect maps with top-view binary masks derived from the information provided by\nthe FHWA. The performance metrics, specifically F1-scores and AUC-ROC, achieve\nvalues of up to 0.95 and 0.83, respectively. The results demonstrate the\nrobustness of the methodology, consistently identifying defect-prone areas with\nminimal false positives and few missed defects. Adaptive frequency thresholding\nensures flexibility in addressing variations across slabs, providing a scalable\nframework for detecting structural anomalies. Additionally, the methodology is\nadaptable to other frequency-based signals due to its generalizable\nthresholding mechanism and holds potential for integrating multimodal sensor\nfusion. This automated and scalable pipeline minimizes manual intervention,\nensuring accurate and efficient defect detection, further advancing\nNon-Destructive Evaluation (NDE) techniques.",
      "tldr_zh": "本研究提出了一种自动化、可扩展的方法，使用 Impact Echo (IE) 信号分析检测混凝土板中的地下缺陷，该方法整合了高级信号处理、聚类（如 k-means）和可视化工具（如 3D 表面图和轮廓图），并采用自适应阈值技术根据材料特性自动分类缺陷区域。实验在 Federal Highway Administration (FHWA) 的标记数据集上进行，取得了 F1-score 最高 0.95 和 AUC-ROC 最高 0.83 的性能指标，展示了其鲁棒性、减少假阳性和漏检的能力。该框架灵活可扩展，可应用于其他频率-based 信号并支持多模态传感器融合，从而提升非破坏性评估 (NDE) 技术的效率和准确性。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.SP",
      "comment": "Accepted by IEEE Big Data 2024",
      "pdf_url": "http://arxiv.org/pdf/2412.17953v1",
      "published_date": "2024-12-23 20:05:53 UTC",
      "updated_date": "2024-12-23 20:05:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:40:55.780914"
    },
    {
      "arxiv_id": "2412.17948v1",
      "title": "Study of the Proper NNUE Dataset",
      "title_zh": "合适的 NNUE 数据集的研究",
      "authors": [
        "Daniel Tan",
        "Neftali Watkinson Medina"
      ],
      "abstract": "NNUE (Efficiently Updatable Neural Networks) has revolutionized chess engine\ndevelopment, with nearly all top engines adopting NNUE models to maintain\ncompetitive performance. A key challenge in NNUE training is the creation of\nhigh-quality datasets, particularly in complex domains like chess, where\ntactical and strategic evaluations are essential. However, methods for\nconstructing effective datasets remain poorly understood and under-documented.\nIn this paper, we propose an algorithm for generating and filtering datasets\ncomposed of \"quiet\" positions that are stable and free from tactical\nvolatility. Our approach provides a clear methodology for dataset creation,\nwhich can be replicated and generalized across various evaluation functions.\nTesting demonstrates significant improvements in engine performance, confirming\nthe effectiveness of our method.",
      "tldr_zh": "NNUE（Efficiently Updatable Neural Networks）在国际象棋引擎开发中扮演关键角色，但构建高质量数据集的挑战依然存在，尤其是需要处理战术和战略评估。本文提出了一种算法，用于生成和过滤由稳定“quiet”位置组成的数据集，确保这些位置免受战术波动影响，并提供可复制的通用方法。测试结果显示，该方法显著提升了引擎性能，为其他评估函数的优化提供了重要参考。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "I.2.0"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.17948v1",
      "published_date": "2024-12-23 20:02:17 UTC",
      "updated_date": "2024-12-23 20:02:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:41:06.284525"
    },
    {
      "arxiv_id": "2412.17944v1",
      "title": "Surveillance Capitalism Revealed: Tracing The Hidden World Of Web Data Collection",
      "title_zh": "翻译失败",
      "authors": [
        "Antony Seabra de Medeiros",
        "Luiz Afonso Glatzl Junior",
        "Sergio Lifschitz"
      ],
      "abstract": "This study investigates the mechanisms of Surveillance Capitalism, focusing\non personal data transfer during web navigation and searching. Analyzing\nnetwork traffic reveals how various entities track and harvest digital\nfootprints. The research reveals specific data types exchanged between users\nand web services, emphasizing the sophisticated algorithms involved in these\nprocesses. We present concrete evidence of data harvesting practices and\npropose strategies for enhancing data protection and transparency. Our findings\nhighlight the need for robust data protection frameworks and ethical data usage\nto address privacy concerns in the digital age.",
      "tldr_zh": "这篇论文揭示了Surveillance Capitalism的机制，通过分析network traffic，追踪网络导航和搜索过程中个人数据的传输与收集。研究发现，各种实体使用复杂算法来跟踪和收获数字足迹，并提供了具体数据类型交换的实证证据。作者提出增强数据保护和透明度的策略，强调需要robust的数据保护框架和ethical数据使用，以应对数字时代的隐私挑战。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "SBBD 2024 - Simp\\'osio Brasileiro de Banco de Dados",
      "pdf_url": "http://arxiv.org/pdf/2412.17944v1",
      "published_date": "2024-12-23 19:55:20 UTC",
      "updated_date": "2024-12-23 19:55:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:41:18.064261"
    },
    {
      "arxiv_id": "2412.17942v1",
      "title": "Contrato360 2.0: A Document and Database-Driven Question-Answer System using Large Language Models and Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Antony Seabra",
        "Claudio Cavalcante",
        "Joao Nepomuceno",
        "Lucas Lago",
        "Nicolaas Ruberg",
        "Sergio Lifschitz"
      ],
      "abstract": "We present a question-and-answer (Q\\&A) application designed to support the\ncontract management process by leveraging combined information from contract\ndocuments (PDFs) and data retrieved from contract management systems\n(database). This data is processed by a large language model (LLM) to provide\nprecise and relevant answers. The accuracy of these responses is further\nenhanced through the use of Retrieval-Augmented Generation (RAG), text-to-SQL\ntechniques, and agents that dynamically orchestrate the workflow. These\ntechniques eliminate the need to retrain the language model. Additionally, we\nemployed Prompt Engineering to fine-tune the focus of responses. Our findings\ndemonstrate that this multi-agent orchestration and combination of techniques\nsignificantly improve the relevance and accuracy of the answers, offering a\npromising direction for future information systems.",
      "tldr_zh": "本研究介绍了Contrato360 2.0，一种基于文档和数据库的问答系统，利用大型语言模型（LLM）结合合同文件（PDF）和数据库数据，提供精确的相关答案。该系统采用Retrieval-Augmented Generation (RAG)、text-to-SQL 技术以及代理（agents）动态编排工作流，并通过Prompt Engineering优化响应焦点，从而无需重新训练LLM。结果显示，这种多代理方法显著提升了答案的相关性和准确性，为未来信息系统的开发提供了有前景的方向。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "KDIR 2024 - Knowledge Discovery and Information Retrieval",
      "pdf_url": "http://arxiv.org/pdf/2412.17942v1",
      "published_date": "2024-12-23 19:54:28 UTC",
      "updated_date": "2024-12-23 19:54:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:43:24.365066"
    },
    {
      "arxiv_id": "2412.17933v1",
      "title": "BenCzechMark : A Czech-centric Multitask and Multimetric Benchmark for Large Language Models with Duel Scoring Mechanism",
      "title_zh": "翻译失败",
      "authors": [
        "Martin Fajcik",
        "Martin Docekal",
        "Jan Dolezal",
        "Karel Ondrej",
        "Karel Beneš",
        "Jan Kapsa",
        "Pavel Smrz",
        "Alexander Polok",
        "Michal Hradis",
        "Zuzana Neverilova",
        "Ales Horak",
        "Radoslav Sabol",
        "Michal Stefanik",
        "Adam Jirkovsky",
        "David Adamczyk",
        "Petr Hyner",
        "Jan Hula",
        "Hynek Kydlicek"
      ],
      "abstract": "We present BenCzechMark (BCM), the first comprehensive Czech language\nbenchmark designed for large language models, offering diverse tasks, multiple\ntask formats, and multiple evaluation metrics. Its scoring system is grounded\nin statistical significance theory and uses aggregation across tasks inspired\nby social preference theory. Our benchmark encompasses 50 challenging tasks,\nwith corresponding test datasets, primarily in native Czech, with 11 newly\ncollected ones. These tasks span 8 categories and cover diverse domains,\nincluding historical Czech news, essays from pupils or language learners, and\nspoken word.\n  Furthermore, we collect and clean BUT-Large Czech Collection, the largest\npublicly available clean Czech language corpus, and use it for (i)\ncontamination analysis, (ii) continuous pretraining of the first Czech-centric\n7B language model, with Czech-specific tokenization. We use our model as a\nbaseline for comparison with publicly available multilingual models. Lastly, we\nrelease and maintain a leaderboard, with existing 44 model submissions, where\nnew model submissions can be made at\nhttps://huggingface.co/spaces/CZLC/BenCzechMark.",
      "tldr_zh": "本研究引入了BenCzechMark（BCM），这是首个针对捷克语的大型语言模型（Large Language Models）基准测试，涵盖50个挑战性任务、多种任务格式和评估指标，并采用基于统计显著性理论的双重评分机制。基准测试主要使用原生捷克语，涉及8个类别和多样领域，如历史新闻、学生作文和口语，其中包括11个新收集的数据集。该团队还构建了最大的公开捷克语语料库BUT-Large Czech Collection，用于污染分析和预训练首个捷克语中心的7B语言模型，该模型采用捷克语特定标记化，并作为基准与其他多语言模型比较。最终，他们发布了排行榜，目前已有44个模型提交，可供进一步评估和比较。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "first version",
      "pdf_url": "http://arxiv.org/pdf/2412.17933v1",
      "published_date": "2024-12-23 19:45:20 UTC",
      "updated_date": "2024-12-23 19:45:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:41:43.584709"
    },
    {
      "arxiv_id": "2412.17920v2",
      "title": "Causal Composition Diffusion Model for Closed-loop Traffic Generation",
      "title_zh": "因果组合扩散模型用于闭环交通生成",
      "authors": [
        "Haohong Lin",
        "Xin Huang",
        "Tung Phan-Minh",
        "David S. Hayden",
        "Huan Zhang",
        "Ding Zhao",
        "Siddhartha Srinivasa",
        "Eric M. Wolff",
        "Hongge Chen"
      ],
      "abstract": "Simulation is critical for safety evaluation in autonomous driving,\nparticularly in capturing complex interactive behaviors. However, generating\nrealistic and controllable traffic scenarios in long-tail situations remains a\nsignificant challenge. Existing generative models suffer from the conflicting\nobjective between user-defined controllability and realism constraints, which\nis amplified in safety-critical contexts. In this work, we introduce the Causal\nCompositional Diffusion Model (CCDiff), a structure-guided diffusion framework\nto address these challenges. We first formulate the learning of controllable\nand realistic closed-loop simulation as a constrained optimization problem.\nThen, CCDiff maximizes controllability while adhering to realism by\nautomatically identifying and injecting causal structures directly into the\ndiffusion process, providing structured guidance to enhance both realism and\ncontrollability. Through rigorous evaluations on benchmark datasets and in a\nclosed-loop simulator, CCDiff demonstrates substantial gains over\nstate-of-the-art approaches in generating realistic and user-preferred\ntrajectories. Our results show CCDiff's effectiveness in extracting and\nleveraging causal structures, showing improved closed-loop performance based on\nkey metrics such as collision rate, off-road rate, FDE, and comfort.",
      "tldr_zh": "该论文针对自动驾驶模拟中生成真实且可控的闭环交通场景问题，提出Causal Compositional Diffusion Model (CCDiff)，一个结构引导的扩散框架，将问题表述为约束优化问题，并通过自动识别和注入因果结构到扩散过程中，提升真实性和可控性。CCDiff在基准数据集和闭环模拟器上的评估显示，与现有方法相比，它显著提高了轨迹生成的性能，包括降低了碰撞率、离路率和FDE (Final Displacement Error)，并提升了舒适度指标。该方法为安全关键场景下的交通模拟提供了更可靠的解决方案。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17920v2",
      "published_date": "2024-12-23 19:20:29 UTC",
      "updated_date": "2025-02-05 16:08:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:41:56.522050"
    },
    {
      "arxiv_id": "2412.17910v1",
      "title": "A Novel Approach to Balance Convenience and Nutrition in Meals With Long-Term Group Recommendations and Reasoning on Multimodal Recipes and its Implementation in BEACON",
      "title_zh": "翻译失败",
      "authors": [
        "Vansh Nagpal",
        "Siva Likitha Valluru",
        "Kausik Lakkaraju",
        "Nitin Gupta",
        "Zach Abdulrahman",
        "Andrew Davison",
        "Biplav Srivastava"
      ],
      "abstract": "\"A common decision made by people, whether healthy or with health conditions,\nis choosing meals like breakfast, lunch, and dinner, comprising combinations of\nfoods for appetizer, main course, side dishes, desserts, and beverages. Often,\nthis decision involves tradeoffs between nutritious choices (e.g., salt and\nsugar levels, nutrition content) and convenience (e.g., cost and accessibility,\ncuisine type, food source type). We present a data-driven solution for meal\nrecommendations that considers customizable meal configurations and time\nhorizons. This solution balances user preferences while accounting for food\nconstituents and cooking processes. Our contributions include introducing\ngoodness measures, a recipe conversion method from text to the recently\nintroduced multimodal rich recipe representation (R3) format, learning methods\nusing contextual bandits that show promising preliminary results, and the\nprototype, usage-inspired, BEACON system.\"",
      "tldr_zh": "本文提出了一种新方法，用于平衡餐食的便利性（如成本和可及性）和营养性（如盐糖水平和营养含量），通过长期群体推荐和对多模态食谱的推理。关键贡献包括引入goodness measures作为评估指标、开发从文本到R3格式的食谱转换方法、采用contextual bandits学习算法来优化推荐，并实现BEACON系统的原型。实验显示，该方法在考虑用户偏好和食物成分烹饪过程的基础上，展现出有前景的初步结果。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2406.13714",
      "pdf_url": "http://arxiv.org/pdf/2412.17910v1",
      "published_date": "2024-12-23 19:05:27 UTC",
      "updated_date": "2024-12-23 19:05:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:42:08.424733"
    },
    {
      "arxiv_id": "2412.17807v1",
      "title": "Cross-View Referring Multi-Object Tracking",
      "title_zh": "跨视图引用多对象跟踪",
      "authors": [
        "Sijia Chen",
        "En Yu",
        "Wenbing Tao"
      ],
      "abstract": "Referring Multi-Object Tracking (RMOT) is an important topic in the current\ntracking field. Its task form is to guide the tracker to track objects that\nmatch the language description. Current research mainly focuses on referring\nmulti-object tracking under single-view, which refers to a view sequence or\nmultiple unrelated view sequences. However, in the single-view, some\nappearances of objects are easily invisible, resulting in incorrect matching of\nobjects with the language description. In this work, we propose a new task,\ncalled Cross-view Referring Multi-Object Tracking (CRMOT). It introduces the\ncross-view to obtain the appearances of objects from multiple views, avoiding\nthe problem of the invisible appearances of objects in RMOT task. CRMOT is a\nmore challenging task of accurately tracking the objects that match the\nlanguage description and maintaining the identity consistency of objects in\neach cross-view. To advance CRMOT task, we construct a cross-view referring\nmulti-object tracking benchmark based on CAMPUS and DIVOTrack datasets, named\nCRTrack. Specifically, it provides 13 different scenes and 221 language\ndescriptions. Furthermore, we propose an end-to-end cross-view referring\nmulti-object tracking method, named CRTracker. Extensive experiments on the\nCRTrack benchmark verify the effectiveness of our method. The dataset and code\nare available at https://github.com/chen-si-jia/CRMOT.",
      "tldr_zh": "本论文提出一个新任务Cross-view Referring Multi-Object Tracking (CRMOT)，旨在通过多视图获取物体外观，解决传统Referring Multi-Object Tracking (RMOT)中单视图导致物体不可见的问题，从而实现更准确的语言描述匹配和物体身份一致性维护。论文构建了一个基于CAMPUS和DIVOTrack数据集的基准CRTrack，提供13个不同场景和221个语言描述，以推进CRMOT研究。同时，作者提出了一种端到端方法CRTracker，通过整合跨视图信息进行多物体追踪。实验在CRTrack基准上验证了CRTracker的有效性，数据集和代码已在GitHub上公开。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by AAAI 2025!",
      "pdf_url": "http://arxiv.org/pdf/2412.17807v1",
      "published_date": "2024-12-23 18:58:39 UTC",
      "updated_date": "2024-12-23 18:58:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:43:35.413835"
    },
    {
      "arxiv_id": "2412.17799v2",
      "title": "Automating the Search for Artificial Life with Foundation Models",
      "title_zh": "利用基础模型自动搜索人工生命",
      "authors": [
        "Akarsh Kumar",
        "Chris Lu",
        "Louis Kirsch",
        "Yujin Tang",
        "Kenneth O. Stanley",
        "Phillip Isola",
        "David Ha"
      ],
      "abstract": "With the recent Nobel Prize awarded for radical advances in protein\ndiscovery, foundation models (FMs) for exploring large combinatorial spaces\npromise to revolutionize many scientific fields. Artificial Life (ALife) has\nnot yet integrated FMs, thus presenting a major opportunity for the field to\nalleviate the historical burden of relying chiefly on manual design and\ntrial-and-error to discover the configurations of lifelike simulations. This\npaper presents, for the first time, a successful realization of this\nopportunity using vision-language FMs. The proposed approach, called Automated\nSearch for Artificial Life (ASAL), (1) finds simulations that produce target\nphenomena, (2) discovers simulations that generate temporally open-ended\nnovelty, and (3) illuminates an entire space of interestingly diverse\nsimulations. Because of the generality of FMs, ASAL works effectively across a\ndiverse range of ALife substrates including Boids, Particle Life, Game of Life,\nLenia, and Neural Cellular Automata. A major result highlighting the potential\nof this technique is the discovery of previously unseen Lenia and Boids\nlifeforms, as well as cellular automata that are open-ended like Conway's Game\nof Life. Additionally, the use of FMs allows for the quantification of\npreviously qualitative phenomena in a human-aligned way. This new paradigm\npromises to accelerate ALife research beyond what is possible through human\ningenuity alone.",
      "tldr_zh": "这篇论文提出了一种名为 Automated Search for Artificial Life (ASAL) 的方法，利用 Foundation Models (FMs) 自动化人工生命 (ALife) 模拟的搜索过程，以取代传统的手动设计和试错。ASAL 能够识别产生目标现象的模拟、发现生成持续新颖性的开放式模拟，并揭示多样化的模拟空间，在 Boids、Particle Life、Game of Life、Lenia 和 Neural Cellular Automata 等多种 ALife 底座上表现出色。关键发现包括新颖的 Lenia 和 Boids 生命形式，以及类似于 Conway's Game of Life 的开放式细胞自动机，此外还实现了对定性现象的人类一致量化。整体而言，这种新范式有望加速 ALife 研究，超越人类智慧的局限性。",
      "categories": [
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "30 pages, 19 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.17799v2",
      "published_date": "2024-12-23 18:57:00 UTC",
      "updated_date": "2025-05-16 21:19:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:45:40.640795"
    },
    {
      "arxiv_id": "2412.17797v1",
      "title": "Observation Interference in Partially Observable Assistance Games",
      "title_zh": "部分可观察辅助博弈中的观察干扰",
      "authors": [
        "Scott Emmons",
        "Caspar Oesterheld",
        "Vincent Conitzer",
        "Stuart Russell"
      ],
      "abstract": "We study partially observable assistance games (POAGs), a model of the\nhuman-AI value alignment problem which allows the human and the AI assistant to\nhave partial observations. Motivated by concerns of AI deception, we study a\nqualitatively new phenomenon made possible by partial observability: would an\nAI assistant ever have an incentive to interfere with the human's observations?\nFirst, we prove that sometimes an optimal assistant must take\nobservation-interfering actions, even when the human is playing optimally, and\neven when there are otherwise-equivalent actions available that do not\ninterfere with observations. Though this result seems to contradict the classic\ntheorem from single-agent decision making that the value of perfect information\nis nonnegative, we resolve this seeming contradiction by developing a notion of\ninterference defined on entire policies. This can be viewed as an extension of\nthe classic result that the value of perfect information is nonnegative into\nthe cooperative multiagent setting. Second, we prove that if the human is\nsimply making decisions based on their immediate outcomes, the assistant might\nneed to interfere with observations as a way to query the human's preferences.\nWe show that this incentive for interference goes away if the human is playing\noptimally, or if we introduce a communication channel for the human to\ncommunicate their preferences to the assistant. Third, we show that if the\nhuman acts according to the Boltzmann model of irrationality, this can create\nan incentive for the assistant to interfere with observations. Finally, we use\nan experimental model to analyze tradeoffs faced by the AI assistant in\npractice when considering whether or not to take observation-interfering\nactions.",
      "tldr_zh": "本研究探讨了部分可观察辅助游戏（POAGs），一个用于建模人类-AI 值对齐问题的框架，焦点在于AI 助理是否会因部分可观察性而有动机干扰人类的观察。作者证明，即使人类决策最优，AI 仍可能需要采取 observation-interfering actions，尽管有等效的非干扰选项可用，并通过扩展完美信息价值的经典定理到合作多代理设置来解决这一矛盾。其次，研究显示，如果人类基于即时结果决策，AI 可能需干扰观察以查询偏好，但此激励在人类最优决策或引入通信渠道时会消失；此外，人类若遵循Boltzmann 模型的非理性行为，也会引发AI 的干扰动机。最后，通过实验模型，论文分析了AI 在实际场景中权衡干扰行动的权衡取舍，为理解AI 潜在欺骗行为提供了新洞见。",
      "categories": [
        "cs.AI",
        "cs.GT",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17797v1",
      "published_date": "2024-12-23 18:53:33 UTC",
      "updated_date": "2024-12-23 18:53:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:44:00.745830"
    },
    {
      "arxiv_id": "2412.17780v3",
      "title": "PepTune: De Novo Generation of Therapeutic Peptides with Multi-Objective-Guided Discrete Diffusion",
      "title_zh": "翻译失败",
      "authors": [
        "Sophia Tang",
        "Yinuo Zhang",
        "Pranam Chatterjee"
      ],
      "abstract": "Peptide therapeutics, a major class of medicines, have achieved remarkable\nsuccess across diseases such as diabetes and cancer, with landmark examples\nsuch as GLP-1 receptor agonists revolutionizing the treatment of type-2\ndiabetes and obesity. Despite their success, designing peptides that satisfy\nmultiple conflicting objectives, such as target binding affinity, solubility,\nand membrane permeability, remains a major challenge. Classical drug\ndevelopment and structure-based design are ineffective for such tasks, as they\nfail to optimize global functional properties critical for therapeutic\nefficacy. Existing generative frameworks are largely limited to continuous\nspaces, unconditioned outputs, or single-objective guidance, making them\nunsuitable for discrete sequence optimization across multiple properties. To\naddress this, we present PepTune, a multi-objective discrete diffusion model\nfor the simultaneous generation and optimization of therapeutic peptide SMILES.\nBuilt on the Masked Discrete Language Model (MDLM) framework, PepTune ensures\nvalid peptide structures with state-dependent masking schedules and\npenalty-based objectives. To guide the diffusion process, we propose a Monte\nCarlo Tree Search (MCTS)-based strategy that balances exploration and\nexploitation to iteratively refine Pareto-optimal sequences. MCTS integrates\nclassifier-based rewards with search-tree expansion, overcoming gradient\nestimation challenges and data sparsity inherent to discrete spaces. Using\nPepTune, we generate diverse, chemically-modified peptides optimized for\nmultiple therapeutic properties, including target binding affinity, membrane\npermeability, solubility, hemolysis, and non-fouling characteristics on various\ndisease-relevant targets. In total, our results demonstrate that MCTS-guided\ndiscrete diffusion is a powerful and modular approach for multi-objective\nsequence design in discrete state spaces.",
      "tldr_zh": "本文提出 PepTune，一种多目标引导的离散扩散模型，用于从头生成治疗肽（Therapeutic Peptides），旨在同时优化多个冲突目标，如目标结合亲和力（target binding affinity）、可溶性（solubility）和膜渗透性（membrane permeability）。该模型基于 Masked Discrete Language Model (MDLM) 框架，通过状态依赖的掩码调度和惩罚机制确保生成有效的肽 SMILES 序列。Monte Carlo Tree Search (MCTS) 策略被用于引导扩散过程，平衡探索和利用，并集成分类器奖励来克服离散空间的梯度估计挑战和数据稀疏问题。实验结果显示，PepTune 成功生成了多样化的化学修饰肽，在多种疾病相关目标上优化了治疗特性，如结合亲和力、膜渗透性和非污染特性，证明了这一方法在多目标序列设计中的强大性和模块性。",
      "categories": [
        "q-bio.BM",
        "cs.AI"
      ],
      "primary_category": "q-bio.BM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17780v3",
      "published_date": "2024-12-23 18:38:49 UTC",
      "updated_date": "2025-01-01 15:34:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:44:13.537868"
    },
    {
      "arxiv_id": "2412.17778v1",
      "title": "An Investigation on the Potential of KAN in Speech Enhancement",
      "title_zh": "翻译失败",
      "authors": [
        "Haoyang Li",
        "Yuchen Hu",
        "Chen Chen",
        "Eng Siong Chng"
      ],
      "abstract": "High-fidelity speech enhancement often requires sophisticated modeling to\ncapture intricate, multiscale patterns. Standard activation functions, while\nintroducing nonlinearity, lack the flexibility to fully address this\ncomplexity. Kolmogorov-Arnold Networks (KAN), an emerging methodology that\nemploys learnable activation functions on graph edges, present a promising\nalternative. This work investigates two novel KAN variants based on rational\nand radial basis functions for speech enhancement. We integrate the rational\nvariant into the 1D CNN blocks of Demucs and the GRU-Transformer blocks of\nMP-SENet, while the radial variant is adapted to the 2D CNN-based decoders of\nMP-SENet. Experiments on the VoiceBank-DEMAND dataset show that replacing\nstandard activations with KAN-based activations improves speech quality across\nboth the time-domain and time-frequency domain methods with minimal impact on\nmodel size and FLOP, underscoring KAN's potential to improve speech enhancement\nmodels.",
      "tldr_zh": "这篇论文探讨了Kolmogorov-Arnold Networks (KAN) 在语音增强中的潜力，提出两种新变体：基于有理函数和径向基函数的激活函数，以更好地捕捉语音的多尺度模式。研究将有理变体整合到Demucs的1D CNN块和MP-SENet的GRU-Transformer块中，并将径向变体应用于MP-SENet的2D CNN解码器。实验在VoiceBank-DEMAND数据集上显示，使用KAN激活函数显著提高了语音质量，在时域和时频域方法上表现更优，同时对模型大小和FLOP的影响最小，这突显了KAN在提升语音增强模型方面的潜力。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.AS",
      "comment": "5 pages, 2 figure, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2412.17778v1",
      "published_date": "2024-12-23 18:38:32 UTC",
      "updated_date": "2024-12-23 18:38:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:44:25.468964"
    },
    {
      "arxiv_id": "2412.17759v1",
      "title": "Survey of Large Multimodal Model Datasets, Application Categories and Taxonomy",
      "title_zh": "翻译失败",
      "authors": [
        "Priyaranjan Pattnayak",
        "Hitesh Laxmichand Patel",
        "Bhargava Kumar",
        "Amit Agarwal",
        "Ishan Banerjee",
        "Srikant Panda",
        "Tejaswini Kumar"
      ],
      "abstract": "Multimodal learning, a rapidly evolving field in artificial intelligence,\nseeks to construct more versatile and robust systems by integrating and\nanalyzing diverse types of data, including text, images, audio, and video.\nInspired by the human ability to assimilate information through many senses,\nthis method enables applications such as text-to-video conversion, visual\nquestion answering, and image captioning. Recent developments in datasets that\nsupport multimodal language models (MLLMs) are highlighted in this overview.\nLarge-scale multimodal datasets are essential because they allow for thorough\ntesting and training of these models. With an emphasis on their contributions\nto the discipline, the study examines a variety of datasets, including those\nfor training, domain-specific tasks, and real-world applications. It also\nemphasizes how crucial benchmark datasets are for assessing models' performance\nin a range of scenarios, scalability, and applicability. Since multimodal\nlearning is always changing, overcoming these obstacles will help AI research\nand applications reach new heights.",
      "tldr_zh": "这篇论文对多模态学习（multimodal learning）领域进行了调查，重点概述了支持大型多模态语言模型（MLLMs）的关键数据集、应用类别和分类体系。论文强调了这些数据集在模型训练、领域特定任务和实际应用中的作用，特别是基准数据集（benchmark datasets）在评估模型性能、可扩展性和适用性方面的核心贡献。通过分析多样化数据类型（如文本、图像、音频和视频），研究发现多模态学习正快速发展，克服现有挑战将进一步推动AI研究和应用创新。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17759v1",
      "published_date": "2024-12-23 18:15:19 UTC",
      "updated_date": "2024-12-23 18:15:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:44:35.225594"
    },
    {
      "arxiv_id": "2412.17758v1",
      "title": "In Case You Missed It: ARC 'Challenge' Is Not That Challenging",
      "title_zh": "翻译失败",
      "authors": [
        "Łukasz Borchmann"
      ],
      "abstract": "ARC Challenge appears more difficult than ARC Easy for modern LLMs primarily\ndue to an evaluation setup that prevents direct comparison of answer choices\nrather than inherent complexity. Although some researchers have quietly shifted\nto a more appropriate scheme over the last year, the implications of this\nchange have yet to be widely acknowledged. We highlight this overlooked shift,\nshow how similar evaluation practices falsely imply reasoning deficits in other\nbenchmarks, and demonstrate that fairer methods dramatically reduce performance\ngaps (e.g. on SIQA) and even yield superhuman results (OpenBookQA). In doing\nso, we reveal how evaluation shapes perceived difficulty and offer guidelines\nto ensure that multiple-choice evaluations accurately reflect actual model\ncapabilities.",
      "tldr_zh": "该论文质疑了 ARC Challenge 测试的难度，认为其对现代大型语言模型 (LLMs) 而言并非源于内在复杂性，而是评估设置的问题，例如无法直接比较答案选项。尽管一些研究者已转向更合适的评估方案，但这一变化尚未被广泛认可。作者通过分析类似评估实践，展示了它们如何错误地暗示模型在其他基准（如 SIQA）上的推理缺陷，并证明采用更公平的方法能显著缩小性能差距，甚至在 OpenBookQA 上实现超人性能。最后，论文提供指导，确保多项选择评估更准确地反映模型的实际能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17758v1",
      "published_date": "2024-12-23 18:14:36 UTC",
      "updated_date": "2024-12-23 18:14:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:44:47.082466"
    },
    {
      "arxiv_id": "2412.17747v1",
      "title": "Deliberation in Latent Space via Differentiable Cache Augmentation",
      "title_zh": "通过可微缓存增强在潜在空间中的审议",
      "authors": [
        "Luyang Liu",
        "Jonas Pfeiffer",
        "Jiaxing Wu",
        "Jun Xie",
        "Arthur Szlam"
      ],
      "abstract": "Techniques enabling large language models (LLMs) to \"think more\" by\ngenerating and attending to intermediate reasoning steps have shown promise in\nsolving complex problems. However, the standard approaches generate sequences\nof discrete tokens immediately before responding, and so they can incur\nsignificant latency costs and be challenging to optimize. In this work, we\ndemonstrate that a frozen LLM can be augmented with an offline coprocessor that\noperates on the model's key-value (kv) cache. This coprocessor augments the\ncache with a set of latent embeddings designed to improve the fidelity of\nsubsequent decoding. We train this coprocessor using the language modeling loss\nfrom the decoder on standard pretraining data, while keeping the decoder itself\nfrozen. This approach enables the model to learn, in an end-to-end\ndifferentiable fashion, how to distill additional computation into its\nkv-cache. Because the decoder remains unchanged, the coprocessor can operate\noffline and asynchronously, and the language model can function normally if the\ncoprocessor is unavailable or if a given cache is deemed not to require extra\ncomputation. We show experimentally that when a cache is augmented, the decoder\nachieves lower perplexity on numerous subsequent tokens. Furthermore, even\nwithout any task-specific training, our experiments demonstrate that cache\naugmentation consistently reduces perplexity and improves performance across a\nrange of reasoning-intensive tasks.",
      "tldr_zh": "该论文探讨了如何让大型语言模型（LLMs）通过生成中间推理步骤来提升复杂问题解决能力，但现有方法因生成离散标记序列而导致延迟和优化挑战。作者提出一种创新方法，使用冻结的 LLM 结合离线协处理器，在模型的 key-value (kv) cache 中添加潜在嵌入，以提高后续解码的保真度。该协处理器通过端到端可微训练，使用语言建模损失在标准预训练数据上优化，确保模型在无需额外计算时也能正常运行。实验结果表明，cache 增强后，解码器的 perplexity 显著降低，并在多种推理密集型任务中提升了性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17747v1",
      "published_date": "2024-12-23 18:02:25 UTC",
      "updated_date": "2024-12-23 18:02:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:46:40.153197"
    },
    {
      "arxiv_id": "2412.17744v1",
      "title": "RepoTransBench: A Real-World Benchmark for Repository-Level Code Translation",
      "title_zh": "RepoTransBench：一个真实世界的仓库级别代码翻译基准",
      "authors": [
        "Yanli Wang",
        "Yanlin Wang",
        "Suiquan Wang",
        "Daya Guo",
        "Jiachi Chen",
        "John Grundy",
        "Xilin Liu",
        "Yuchi Ma",
        "Mingzhi Mao",
        "Hongyu Zhang",
        "Zibin Zheng"
      ],
      "abstract": "Repository-level code translation refers to translating an entire code\nrepository from one programming language to another while preserving the\nfunctionality of the source repository. Many benchmarks have been proposed to\nevaluate the performance of such code translators. However, previous benchmarks\nmostly provide fine-grained samples, focusing at either code snippet, function,\nor file-level code translation. Such benchmarks do not accurately reflect\nreal-world demands, where entire repositories often need to be translated,\ninvolving longer code length and more complex functionalities. To address this\ngap, we propose a new benchmark, named RepoTransBench, which is a real-world\nrepository-level code translation benchmark with an automatically executable\ntest suite. We conduct experiments on RepoTransBench to evaluate the\ntranslation performance of 11 advanced LLMs. We find that the Success@1 score\n(test success in one attempt) of the best-performing LLM is only 7.33%. To\nfurther explore the potential of LLMs for repository-level code translation, we\nprovide LLMs with error-related feedback to perform iterative debugging and\nobserve an average 7.09% improvement on Success@1. However, even with this\nimprovement, the Success@1 score of the best-performing LLM is only 21%, which\nmay not meet the need for reliable automatic repository-level code translation.\nFinally, we conduct a detailed error analysis and highlight current LLMs'\ndeficiencies in repository-level code translation, which could provide a\nreference for further improvements.",
      "tldr_zh": "这篇论文提出了RepoTransBench，一个真实世界的仓库级代码翻译基准，用于评估将整个代码仓库从一种编程语言翻译成另一种的同时保持功能完整。该基准包括自动可执行的测试套件，以弥补现有基准对细粒度样本（如代码片段或文件级）的局限性。实验评估了11个高级LLMs的翻译性能，发现最佳模型的Success@1得分仅为7.33%，而通过提供错误反馈进行迭代调试，成功率平均提高了7.09%，但仍仅达21%，不足以满足可靠的自动翻译需求。最后，论文进行了详细的错误分析，突出了LLMs在仓库级翻译中的不足，为进一步改进提供了参考。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17744v1",
      "published_date": "2024-12-23 17:52:10 UTC",
      "updated_date": "2024-12-23 17:52:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:45:12.851122"
    },
    {
      "arxiv_id": "2412.17739v3",
      "title": "Fourier Position Embedding: Enhancing Attention's Periodic Extension for Length Generalization",
      "title_zh": "翻译失败",
      "authors": [
        "Ermo Hua",
        "Che Jiang",
        "Xingtai Lv",
        "Kaiyan Zhang",
        "Ning Ding",
        "Youbang Sun",
        "Biqing Qi",
        "Yuchen Fan",
        "Xuekai Zhu",
        "Bowen Zhou"
      ],
      "abstract": "Extending the context length of Language Models (LMs) by improving Rotary\nPosition Embedding (RoPE) has become a trend. While existing works mainly\naddress RoPE's limitations within attention mechanism, this paper provides an\nanalysis across nearly all parts of LMs, uncovering their adverse effects on\nlength generalization for RoPE-based attention. Using Discrete Signal\nProcessing theory, we show that RoPE enables periodic attention by implicitly\nachieving Non-Uniform Discrete Fourier Transform. However, this periodicity is\nundermined by the spectral damage caused by: 1) linear layers and activation\nfunctions outside of attention; 2) insufficiently trained frequency components\nbrought by time-domain truncation. Building on our observations, we propose\nFourier Position Embedding (FoPE), which enhances attention's frequency-domain\nproperties to improve both its periodic extension and length generalization.\nFoPE constructs Fourier Series and zero-outs the destructive frequency\ncomponents, increasing model robustness against the spectrum damage.\nExperiments across various model scales and benchmarks show that, within\nvarying context windows, FoPE maintains a more stable performance compared to\nRoPE and ALiBi. Several analyses and ablations bring further support to our\nmethod and theoretical modeling.",
      "tldr_zh": "本论文分析了Rotary Position Embedding (RoPE)在语言模型(LMs)中的长度泛化问题，使用Discrete Signal Processing理论揭示了RoPE通过隐式实现Non-Uniform Discrete Fourier Transform启用周期性注意力，但受线性层、激活函数和训练不足导致的谱损伤影响。针对这些问题，作者提出Fourier Position Embedding (FoPE)，通过构建Fourier Series并消除破坏性频率组件来增强注意力的频率域属性，从而改善周期扩展和长度泛化。实验在不同模型规模和基准上表明，FoPE在各种上下文窗口下比RoPE和ALiBi更稳定，并通过分析和消融实验验证了其有效性。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.17739v3",
      "published_date": "2024-12-23 17:44:01 UTC",
      "updated_date": "2025-05-06 07:47:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:45:25.083943"
    },
    {
      "arxiv_id": "2412.17729v1",
      "title": "Chumor 2.0: Towards Benchmarking Chinese Humor Understanding",
      "title_zh": "Ch",
      "authors": [
        "Ruiqi He",
        "Yushu He",
        "Longju Bai",
        "Jiarui Liu",
        "Zhenjie Sun",
        "Zenghao Tang",
        "He Wang",
        "Hanchen Xia",
        "Rada Mihalcea",
        "Naihao Deng"
      ],
      "abstract": "Existing humor datasets and evaluations predominantly focus on English,\nleaving limited resources for culturally nuanced humor in non-English languages\nlike Chinese. To address this gap, we construct Chumor, the first Chinese humor\nexplanation dataset that exceeds the size of existing humor datasets. Chumor is\nsourced from Ruo Zhi Ba, a Chinese Reddit-like platform known for sharing\nintellectually challenging and culturally specific jokes. We test ten LLMs\nthrough direct and chain-of-thought prompting, revealing that Chumor poses\nsignificant challenges to existing LLMs, with their accuracy slightly above\nrandom and far below human. In addition, our analysis highlights that\nhuman-annotated humor explanations are significantly better than those\ngenerated by GPT-4o and ERNIE-4-turbo. We release Chumor at\nhttps://huggingface.co/datasets/dnaihao/Chumor, our project page is at\nhttps://dnaihao.github.io/Chumor-dataset/, our leaderboard is at\nhttps://huggingface.co/spaces/dnaihao/Chumor, and our codebase is at\nhttps://github.com/dnaihao/Chumor-dataset.",
      "tldr_zh": "本文构建了Chumor，这是首个规模超过现有幽默数据集的中文幽默解释数据集，旨在填补英语主导的幽默资源空白，并针对文化特异性笑话（如来自Ruo Zhi Ba平台的智力挑战性笑话）进行评估。研究测试了十个LLMs（Large Language Models）通过直接提示和chain-of-thought prompting，结果显示这些模型在Chumor上的准确率仅略高于随机水平，且远低于人类水平。进一步分析表明，人类标注的幽默解释明显优于GPT-4o和ERNIE-4-turbo生成的解释。该数据集及其相关资源已在https://huggingface.co/datasets/dnaihao/Chumor等平台发布，以推动中文幽默理解的基准测试。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2406.12754",
      "pdf_url": "http://arxiv.org/pdf/2412.17729v1",
      "published_date": "2024-12-23 17:19:58 UTC",
      "updated_date": "2024-12-23 17:19:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:46:53.298574"
    },
    {
      "arxiv_id": "2412.17726v2",
      "title": "VidTwin: Video VAE with Decoupled Structure and Dynamics",
      "title_zh": "翻译失败",
      "authors": [
        "Yuchi Wang",
        "Junliang Guo",
        "Xinyi Xie",
        "Tianyu He",
        "Xu Sun",
        "Jiang Bian"
      ],
      "abstract": "Recent advancements in video autoencoders (Video AEs) have significantly\nimproved the quality and efficiency of video generation. In this paper, we\npropose a novel and compact video autoencoder, VidTwin, that decouples video\ninto two distinct latent spaces: Structure latent vectors, which capture\noverall content and global movement, and Dynamics latent vectors, which\nrepresent fine-grained details and rapid movements. Specifically, our approach\nleverages an Encoder-Decoder backbone, augmented with two submodules for\nextracting these latent spaces, respectively. The first submodule employs a\nQ-Former to extract low-frequency motion trends, followed by downsampling\nblocks to remove redundant content details. The second averages the latent\nvectors along the spatial dimension to capture rapid motion. Extensive\nexperiments show that VidTwin achieves a high compression rate of 0.20% with\nhigh reconstruction quality (PSNR of 28.14 on the MCL-JCV dataset), and\nperforms efficiently and effectively in downstream generative tasks. Moreover,\nour model demonstrates explainability and scalability, paving the way for\nfuture research in video latent representation and generation. Check our\nproject page for more details: https://vidtwin.github.io/.",
      "tldr_zh": "本研究提出了一种新型视频自编码器 VidTwin，它基于 Video VAE 将视频解耦成两个独立潜在空间：Structure latent vectors（捕捉整体内容和全局运动）和 Dynamics latent vectors（代表细粒度细节和快速运动）。VidTwin 采用 Encoder-Decoder 骨干，并通过两个子模块实现提取：第一个子模块使用 Q-Former 提取低频运动趋势并通过降采样块移除冗余细节，第二个子模块沿空间维度平均潜在向量以捕捉快速运动。实验结果显示，VidTwin 实现了 0.20% 的高压缩率，并在 MCL-JCV 数据集上达到 PSNR 28.14 的重建质量，同时在下游生成任务中表现出色，具有良好的可解释性和可扩展性，从而为视频潜在表示和生成领域提供了新方向。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR 2025; Project page: https://vidtwin.github.io/;\n  Code: https://github.com/microsoft/VidTok/tree/main/vidtwin",
      "pdf_url": "http://arxiv.org/pdf/2412.17726v2",
      "published_date": "2024-12-23 17:16:58 UTC",
      "updated_date": "2025-03-28 17:32:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:47:04.141180"
    },
    {
      "arxiv_id": "2412.17707v2",
      "title": "SMAC-Hard: Enabling Mixed Opponent Strategy Script and Self-play on SMAC",
      "title_zh": "SMAC-Hard：在 SMAC 上实现混合对手策略脚本和自对弈",
      "authors": [
        "Yue Deng",
        "Yan Yu",
        "Weiyu Ma",
        "Zirui Wang",
        "Wenhui Zhu",
        "Jian Zhao",
        "Yin Zhang"
      ],
      "abstract": "The availability of challenging simulation environments is pivotal for\nadvancing the field of Multi-Agent Reinforcement Learning (MARL). In\ncooperative MARL settings, the StarCraft Multi-Agent Challenge (SMAC) has\ngained prominence as a benchmark for algorithms following centralized training\nwith decentralized execution paradigm. However, with continual advancements in\nSMAC, many algorithms now exhibit near-optimal performance, complicating the\nevaluation of their true effectiveness. To alleviate this problem, in this\nwork, we highlight a critical issue: the default opponent policy in these\nenvironments lacks sufficient diversity, leading MARL algorithms to overfit and\nexploit unintended vulnerabilities rather than learning robust strategies. To\novercome these limitations, we propose SMAC-HARD, a novel benchmark designed to\nenhance training robustness and evaluation comprehensiveness. SMAC-HARD\nsupports customizable opponent strategies, randomization of adversarial\npolicies, and interfaces for MARL self-play, enabling agents to generalize to\nvarying opponent behaviors and improve model stability. Furthermore, we\nintroduce a black-box testing framework wherein agents are trained without\nexposure to the edited opponent scripts but are tested against these scripts to\nevaluate the policy coverage and adaptability of MARL algorithms. We conduct\nextensive evaluations of widely used and state-of-the-art algorithms on\nSMAC-HARD, revealing the substantial challenges posed by edited and mixed\nstrategy opponents. Additionally, the black-box strategy tests illustrate the\ndifficulty of transferring learned policies to unseen adversaries. We envision\nSMAC-HARD as a critical step toward benchmarking the next generation of MARL\nalgorithms, fostering progress in self-play methods for multi-agent systems.\nOur code is available at https://github.com/devindeng94/smac-hard.",
      "tldr_zh": "本研究针对多智能体强化学习(MARL)领域的StarCraft Multi-Agent Challenge (SMAC)基准问题，提出SMAC-Hard框架，以解决默认对手策略缺乏多样性导致算法过拟合的问题。SMAC-Hard支持自定义对手策略、随机化对手行为以及MARL self-play接口，通过黑盒测试框架评估代理在未见对手下的策略覆盖和适应性。实验结果显示，在SMAC-Hard上测试的流行算法面临显著挑战，特别是面对混合策略对手时表现不佳，从而推动了MARL算法，尤其是自对弈方法的进步。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17707v2",
      "published_date": "2024-12-23 16:36:21 UTC",
      "updated_date": "2024-12-24 16:16:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:47:15.627341"
    },
    {
      "arxiv_id": "2412.17692v2",
      "title": "FedTLU: Federated Learning with Targeted Layer Updates",
      "title_zh": "翻译失败",
      "authors": [
        "Jong-Ik Park",
        "Carlee Joe-Wong"
      ],
      "abstract": "Federated learning (FL) addresses privacy concerns in training language\nmodels by enabling multiple clients to contribute to the training, without\nsending their data to others. However, non-IID (identically and independently\ndistributed) data across clients often limits FL's performance. This issue is\nespecially challenging during model fine-tuning, as noise due to variations in\nclients' data distributions can harm model convergence near stationary points.\nThis paper proposes a targeted layer update strategy for fine-tuning in FL.\nInstead of randomly updating layers of the language model, as often done in\npractice, we use a scoring mechanism to identify and update the most critical\nlayers, avoiding excessively noisy or even poisoned updates by freezing the\nparameters in other layers. We show in extensive experiments that our method\nimproves convergence and performance in non-IID settings, offering a more\nefficient approach to fine-tuning federated language models.",
      "tldr_zh": "本论文提出FedTLU，一种针对联邦学习(Federated Learning)中层更新的策略，旨在解决非IID数据(non-IID data)导致的模型微调问题，从而提升性能和收敛性。该方法使用评分机制(scoring mechanism)来识别并更新语言模型中最关键的层，同时冻结其他层，以避免数据分布差异带来的噪声或恶意更新。在广泛实验中，FedTLU在非IID设置下显著提高了模型的收敛速度和整体表现，为高效的联邦学习微调提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17692v2",
      "published_date": "2024-12-23 16:17:46 UTC",
      "updated_date": "2025-01-26 05:21:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:47:27.624598"
    },
    {
      "arxiv_id": "2412.17686v1",
      "title": "Large Language Model Safety: A Holistic Survey",
      "title_zh": "大型语言模型安全：一个整体综述",
      "authors": [
        "Dan Shi",
        "Tianhao Shen",
        "Yufei Huang",
        "Zhigen Li",
        "Yongqi Leng",
        "Renren Jin",
        "Chuang Liu",
        "Xinwei Wu",
        "Zishan Guo",
        "Linhao Yu",
        "Ling Shi",
        "Bojian Jiang",
        "Deyi Xiong"
      ],
      "abstract": "The rapid development and deployment of large language models (LLMs) have\nintroduced a new frontier in artificial intelligence, marked by unprecedented\ncapabilities in natural language understanding and generation. However, the\nincreasing integration of these models into critical applications raises\nsubstantial safety concerns, necessitating a thorough examination of their\npotential risks and associated mitigation strategies.\n  This survey provides a comprehensive overview of the current landscape of LLM\nsafety, covering four major categories: value misalignment, robustness to\nadversarial attacks, misuse, and autonomous AI risks. In addition to the\ncomprehensive review of the mitigation methodologies and evaluation resources\non these four aspects, we further explore four topics related to LLM safety:\nthe safety implications of LLM agents, the role of interpretability in\nenhancing LLM safety, the technology roadmaps proposed and abided by a list of\nAI companies and institutes for LLM safety, and AI governance aimed at LLM\nsafety with discussions on international cooperation, policy proposals, and\nprospective regulatory directions.\n  Our findings underscore the necessity for a proactive, multifaceted approach\nto LLM safety, emphasizing the integration of technical solutions, ethical\nconsiderations, and robust governance frameworks. This survey is intended to\nserve as a foundational resource for academy researchers, industry\npractitioners, and policymakers, offering insights into the challenges and\nopportunities associated with the safe integration of LLMs into society.\nUltimately, it seeks to contribute to the safe and beneficial development of\nLLMs, aligning with the overarching goal of harnessing AI for societal\nadvancement and well-being. A curated list of related papers has been publicly\navailable at https://github.com/tjunlp-lab/Awesome-LLM-Safety-Papers.",
      "tldr_zh": "这篇调查论文对大型语言模型（LLMs）的安全问题进行了全面审视，涵盖四个主要类别：value misalignment、对对抗性攻击的robustness、misuse和autonomous AI risks，并回顾了相应的缓解方法、评估资源和相关主题，如LLM agents的作用、interpretability的重要性、技术roadmaps以及AI governance策略。论文强调需要采用主动的多方面方法，包括技术解决方案、伦理考虑和稳健治理框架，以应对LLMs的安全挑战。最终，该研究为学术研究者、行业从业者和政策制定者提供了一个基础资源，促进LLMs的安全且有益发展。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "158 pages, 18 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.17686v1",
      "published_date": "2024-12-23 16:11:27 UTC",
      "updated_date": "2024-12-23 16:11:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:47:40.490671"
    },
    {
      "arxiv_id": "2412.17891v1",
      "title": "The Power of Adaptation: Boosting In-Context Learning through Adaptive Prompting",
      "title_zh": "翻译失败",
      "authors": [
        "Shuzhang Cai",
        "Twumasi Mensah-Boateng",
        "Xander Kuksov",
        "Jing Yuan",
        "Shaojie Tang"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated exceptional abilities across a\nbroad range of language-related tasks, including generating solutions to\ncomplex reasoning problems. An effective technique to enhance LLM performance\nis in-context learning, which encourages a step-by-step reasoning process by\nincluding explanatory examples to guide the model's responses. However,\nselecting appropriate exemplars for the model poses a challenge, as each\ndataset demands a distinct set of exemplars to enable the LLM to learn\neffectively and perform well on the test set. Current studies often rely on\nuncertainty- or diversity-based selection strategies to select exemplars for\nannotation and to improve model learning. However, these studies typically\nemploy a non-adaptive approach, selecting a set of exemplars all at once. We\nargue that this non-adaptive strategy may result in a set of exemplars with\nhigh redundancy in terms of the knowledge covered, ultimately reducing their\noverall informativeness. To address this limitation, we propose\n\\textsc{Adaptive-Prompt}, a novel method that adaptively selects exemplars by\nleveraging model feedback from previously chosen exemplars. Experimental\nresults show that \\textsc{Adaptive-Prompt} significantly enhances LLM\nperformance across a variety of reasoning tasks.",
      "tldr_zh": "大型语言模型 (LLMs) 通过 in-context learning 可以提升其在复杂推理任务中的表现，但现有方法往往采用非自适应策略，如 uncertainty- 或 diversity-based 选择，造成 exemplars 冗余并降低信息价值。论文提出 Adaptive-Prompt，一种新型方法，通过利用模型对之前选择的 exemplars 的反馈，实现自适应选择示例。实验结果表明，Adaptive-Prompt 在多种推理任务上显著提升了 LLM 的性能，为更高效的上下文学习提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17891v1",
      "published_date": "2024-12-23 15:49:43 UTC",
      "updated_date": "2024-12-23 15:49:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:47:52.355249"
    },
    {
      "arxiv_id": "2412.17654v1",
      "title": "Enhanced Temporal Processing in Spiking Neural Networks for Static Object Detection Using 3D Convolutions",
      "title_zh": "翻译失败",
      "authors": [
        "Huaxu He"
      ],
      "abstract": "Spiking Neural Networks (SNNs) are a class of network models capable of\nprocessing spatiotemporal information, with event-driven characteristics and\nenergy efficiency advantages. Recently, directly trained SNNs have shown\npotential to match or surpass the performance of traditional Artificial Neural\nNetworks (ANNs) in classification tasks. However, in object detection tasks,\ndirectly trained SNNs still exhibit a significant performance gap compared to\nANNs when tested on frame-based static object datasets (such as COCO2017).\nTherefore, bridging this performance gap and enabling directly trained SNNs to\nachieve performance comparable to ANNs on these static datasets has become one\nof the key challenges in the development of SNNs.To address this challenge,\nthis paper focuses on enhancing the SNN's unique ability to process\nspatiotemporal information. Spiking neurons, as the core components of SNNs,\nfacilitate the exchange of information between different temporal channels\nduring the process of converting input floating-point data into binary spike\nsignals. However, existing neuron models still have certain limitations in the\ncommunication of temporal information. Some studies have even suggested that\ndisabling the backpropagation in the time dimension during SNN training can\nstill yield good training results. To improve the SNN handling of temporal\ninformation, this paper proposes replacing traditional 2D convolutions with 3D\nconvolutions, thus directly incorporating temporal information into the\nconvolutional process. Additionally, temporal information recurrence mechanism\nis introduced within the neurons to further enhance the neurons' efficiency in\nutilizing temporal information.Experimental results show that the proposed\nmethod enables directly trained SNNs to achieve performance levels comparable\nto ANNs on the COCO2017 and VOC datasets.",
      "tldr_zh": "这篇论文针对 Spiking Neural Networks (SNNs) 在静态物体检测任务（如 COCO2017 数据集）上的性能落后于 Artificial Neural Networks (ANNs) 的问题，提出了一种增强时间处理的方法。作者将传统的 2D convolutions 替换为 3D convolutions，以直接整合时空信息，并引入 temporal information recurrence mechanism 来提升神经元对时间信号的利用效率。实验结果表明，该方法使直接训练的 SNNs 在 COCO2017 和 VOC 数据集上实现了与 ANNs 相当的检测性能。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17654v1",
      "published_date": "2024-12-23 15:32:26 UTC",
      "updated_date": "2024-12-23 15:32:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:48:03.695007"
    },
    {
      "arxiv_id": "2412.17651v1",
      "title": "Detecting anxiety and depression in dialogues: a multi-label and explainable approach",
      "title_zh": "翻译失败",
      "authors": [
        "Francisco de Arriba-Pérez",
        "Silvia García-Méndez"
      ],
      "abstract": "Anxiety and depression are the most common mental health issues worldwide,\naffecting a non-negligible part of the population. Accordingly, stakeholders,\nincluding governments' health systems, are developing new strategies to promote\nearly detection and prevention from a holistic perspective (i.e., addressing\nseveral disorders simultaneously). In this work, an entirely novel system for\nthe multi-label classification of anxiety and depression is proposed. The input\ndata consists of dialogues from user interactions with an assistant chatbot.\nAnother relevant contribution lies in using Large Language Models (LLMs) for\nfeature extraction, provided the complexity and variability of language. The\ncombination of LLMs, given their high capability for language understanding,\nand Machine Learning (ML) models, provided their contextual knowledge about the\nclassification problem thanks to the labeled data, constitute a promising\napproach towards mental health assessment. To promote the solution's\ntrustworthiness, reliability, and accountability, explainability descriptions\nof the model's decision are provided in a graphical dashboard. Experimental\nresults on a real dataset attain 90 % accuracy, improving those in the prior\nliterature. The ultimate objective is to contribute in an accessible and\nscalable way before formal treatment occurs in the healthcare systems.",
      "tldr_zh": "这篇论文提出了一种多标签分类方法，用于检测对话中焦虑和抑郁症状，输入数据来自用户与聊天机器人的互动。方法结合 Large Language Models (LLMs) 进行特征提取，并与 Machine Learning (ML) 模型集成，以处理语言的复杂性和提升分类准确性，同时通过图形仪表板提供 explainable 解释以增强系统可信度。在真实数据集上，该系统达到了90%准确率，比现有文献有所改进，最终目标是通过可访问和可扩展的方式促进心理健康早期检测和预防。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17651v1",
      "published_date": "2024-12-23 15:29:46 UTC",
      "updated_date": "2024-12-23 15:29:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:48:16.660833"
    },
    {
      "arxiv_id": "2412.17647v1",
      "title": "An Adaptive Framework for Multi-View Clustering Leveraging Conditional Entropy Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Lijian Li"
      ],
      "abstract": "Multi-view clustering (MVC) has emerged as a powerful technique for\nextracting valuable insights from data characterized by multiple perspectives\nor modalities. Despite significant advancements, existing MVC methods struggle\nwith effectively quantifying the consistency and complementarity among views,\nand are particularly susceptible to the adverse effects of noisy views, known\nas the Noisy-View Drawback (NVD). To address these challenges, we propose\nCE-MVC, a novel framework that integrates an adaptive weighting algorithm with\na parameter-decoupled deep model. Leveraging the concept of conditional entropy\nand normalized mutual information, CE-MVC quantitatively assesses and weights\nthe informative contribution of each view, facilitating the construction of\nrobust unified representations. The parameter-decoupled design enables\nindependent processing of each view, effectively mitigating the influence of\nnoise and enhancing overall clustering performance. Extensive experiments\ndemonstrate that CE-MVC outperforms existing approaches, offering a more\nresilient and accurate solution for multi-view clustering tasks.",
      "tldr_zh": "本文提出 CE-MVC，一种自适应框架，用于解决 Multi-view clustering (MVC) 中视图一致性和互补性量化不足，以及 Noisy-View Drawback (NVD) 带来的噪声影响问题。该框架通过利用 conditional entropy 和 normalized mutual information 来评估并权重每个视图的贡献，并采用 parameter-decoupled deep model 独立处理视图，从而构建更鲁棒的统一表示。实验结果显示，CE-MVC 在多视图聚类任务中显著优于现有方法，提供更高的准确性和可靠性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17647v1",
      "published_date": "2024-12-23 15:21:55 UTC",
      "updated_date": "2024-12-23 15:21:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:48:27.969661"
    },
    {
      "arxiv_id": "2412.17643v1",
      "title": "Advances in Machine Learning Research Using Knowledge Graphs",
      "title_zh": "利用知识图谱的机器学习研究进展",
      "authors": [
        "Jing Si",
        "Jianfei Xu"
      ],
      "abstract": "The study uses CSSCI-indexed literature from the China National Knowledge\nInfrastructure (CNKI) database as the data source. It utilizes the CiteSpace\nvisualization software to draw knowledge graphs on aspects such as\ninstitutional collaboration and keyword co-occurrence. This analysis provides\ninsights into the current state of research and emerging trends in the field of\nmachine learning in China. Additionally, it identifies the challenges faced in\nthe field of machine learning research and offers suggestions that could serve\nas valuable references for future research.",
      "tldr_zh": "本研究利用 CNKI 数据库中的 CSSCI 文献作为数据源，通过 CiteSpace 软件绘制知识图谱，分析机构合作和关键词共现等方面，以揭示中国机器学习研究领域的当前状态和新兴趋势。  \n该分析识别了机器学习研究面临的挑战，包括数据和技术方面的限制，并提供了针对这些问题的建议。  \n总体而言，此工作为未来机器学习研究提供了宝贵参考，推动了 Knowledge Graphs 在该领域的应用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17643v1",
      "published_date": "2024-12-23 15:20:01 UTC",
      "updated_date": "2024-12-23 15:20:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:48:39.233115"
    },
    {
      "arxiv_id": "2412.17637v1",
      "title": "SCBench: A Sports Commentary Benchmark for Video LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Kuangzhi Ge",
        "Lingjun Chen",
        "Kevin Zhang",
        "Yulin Luo",
        "Tianyu Shi",
        "Liaoyuan Fan",
        "Xiang Li",
        "Guanqun Wang",
        "Shanghang Zhang"
      ],
      "abstract": "Recently, significant advances have been made in Video Large Language Models\n(Video LLMs) in both academia and industry. However, methods to evaluate and\nbenchmark the performance of different Video LLMs, especially their\nfine-grained, temporal visual capabilities, remain very limited. On one hand,\ncurrent benchmarks use relatively simple videos (e.g., subtitled movie clips)\nwhere the model can understand the entire video by processing just a few\nframes. On the other hand, their datasets lack diversity in task format,\ncomprising only QA or multi-choice QA, which overlooks the models' capacity for\ngenerating in-depth and precise texts. Sports videos, which feature intricate\nvisual information, sequential events, and emotionally charged commentary,\npresent a critical challenge for Video LLMs, making sports commentary an ideal\nbenchmarking task. Inspired by these challenges, we propose a novel task:\nsports video commentary generation, developed $\\textbf{SCBench}$ for Video\nLLMs. To construct such a benchmark, we introduce (1) $\\textbf{SCORES}$, a\nsix-dimensional metric specifically designed for our task, upon which we\npropose a GPT-based evaluation method, and (2) $\\textbf{CommentarySet}$, a\ndataset consisting of 5,775 annotated video clips and ground-truth labels\ntailored to our metric. Based on SCBench, we conduct comprehensive evaluations\non multiple Video LLMs (e.g. VILA, Video-LLaVA, etc.) and chain-of-thought\nbaseline methods. Our results found that InternVL-Chat-2 achieves the best\nperformance with 5.44, surpassing the second-best by 1.04. Our work provides a\nfresh perspective for future research, aiming to enhance models' overall\ncapabilities in complex visual understanding tasks. Our dataset will be\nreleased soon.",
      "tldr_zh": "该论文提出 SCBench，一种针对 Video LLMs 的体育评论基准，旨在解决现有评估方法在细粒度时间视觉能力和任务多样性上的局限性，例如简单视频和单一 QA 格式。SCBench 包括 SCORES（一个六维指标）和 CommentarySet（一个包含 5,775 个标注视频剪辑的数据集），并采用 GPT-based 评估方法来生成和评估体育视频评论。实验结果显示，InternVL-Chat-2 以 5.44 分的成绩领先其他模型（如 VILA 和 Video-LLaVA），为提升 Video LLMs 在复杂视觉理解任务中的整体能力提供了新研究视角。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17637v1",
      "published_date": "2024-12-23 15:13:56 UTC",
      "updated_date": "2024-12-23 15:13:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:48:52.861882"
    },
    {
      "arxiv_id": "2412.17632v2",
      "title": "D-Judge: How Far Are We? Evaluating the Discrepancies Between AI-synthesized Images and Natural Images through Multimodal Guidance",
      "title_zh": "D-Judge：我们还有多远？通过多模态指导评估 AI 合成图像与自然图像之间的差异",
      "authors": [
        "Renyang Liu",
        "Ziyu Lyu",
        "Wei Zhou",
        "See-Kiong Ng"
      ],
      "abstract": "In Artificial Intelligence Generated Content (AIGC), distinguishing\nAI-synthesized images from natural ones remains a key challenge. Despite\nadvancements in generative models, significant discrepancies persist. To\nsystematically investigate and quantify these discrepancies, we introduce an\nAI-Natural Image Discrepancy accessing benchmark (\\textit{D-Judge}) aimed at\naddressing the critical question: \\textit{how far are AI-generated images\n(AIGIs) from truly realistic images?} We construct \\textit{D-ANI}, a dataset\nwith 5,000 natural images and over 440,000 AIGIs generated by nine models using\nText-to-Image (T2I), Image-to-Image (I2I), and Text and Image-to-Image (TI2I)\nprompts. Our framework evaluates the discrepancy across five dimensions: naive\nimage quality, semantic alignment, aesthetic appeal, downstream applicability,\nand human validation. Results reveal notable gaps, emphasizing the importance\nof aligning metrics with human judgment. Source code and datasets are available\nat https://shorturl.at/l83W2.",
      "tldr_zh": "这篇论文引入了 D-Judge 基准，用于评估 AI 生成图像 (AIGIs) 与自然图像之间的差异，旨在回答 AI 图像距离真正真实性有多远的问题。研究构建了 D-ANI 数据集，包括 5000 张自然图像和超过 44 万张由九个模型生成的 AIGIs，通过 Text-to-Image (T2I)、Image-to-Image (I2I) 和 Text and Image-to-Image (TI2I) 提示进行生成。评估涵盖五个维度：naive 图像质量、语义对齐、美学吸引力、下游适用性和人类验证，结果显示显著差距，并强调评估指标应与人类判断保持一致。源代码和数据集已公开可用，以推动进一步研究。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.MM"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17632v2",
      "published_date": "2024-12-23 15:08:08 UTC",
      "updated_date": "2025-03-30 03:52:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:49:04.690901"
    },
    {
      "arxiv_id": "2412.17629v2",
      "title": "Graph Neural Networks Are Evolutionary Algorithms",
      "title_zh": "图神经网络是进化算法",
      "authors": [
        "Kaichen Ouyang",
        "Shengwei Fu"
      ],
      "abstract": "In this paper, we reveal the intrinsic duality between graph neural networks\n(GNNs) and evolutionary algorithms (EAs), bridging two traditionally distinct\nfields. Building on this insight, we propose Graph Neural Evolution (GNE), a\nnovel evolutionary algorithm that models individuals as nodes in a graph and\nleverages designed frequency-domain filters to balance global exploration and\nlocal exploitation. Through the use of these filters, GNE aggregates\nhigh-frequency (diversity-enhancing) and low-frequency (stability-promoting)\ninformation, transforming EAs into interpretable and tunable mechanisms in the\nfrequency domain. Extensive experiments on benchmark functions demonstrate that\nGNE consistently outperforms state-of-the-art algorithms such as GA, DE,\nCMA-ES, SDAES, and RL-SHADE, excelling in complex landscapes, optimal solution\nshifts, and noisy environments. Its robustness, adaptability, and superior\nconvergence highlight its practical and theoretical value. Beyond optimization,\nGNE establishes a conceptual and mathematical foundation linking EAs and GNNs,\noffering new perspectives for both fields. Its framework encourages the\ndevelopment of task-adaptive filters and hybrid approaches for EAs, while its\ninsights can inspire advances in GNNs, such as improved global information\npropagation and mitigation of oversmoothing. GNE's versatility extends to\nsolving challenges in machine learning, including hyperparameter tuning and\nneural architecture search, as well as real-world applications in engineering\nand operations research. By uniting the dynamics of EAs with the structural\ninsights of GNNs, this work provides a foundation for interdisciplinary\ninnovation, paving the way for scalable and interpretable solutions to complex\noptimization problems.",
      "tldr_zh": "本研究揭示了图神经网络（GNNs）和进化算法（EAs）之间的内在二元性，并据此提出了一种新型算法Graph Neural Evolution (GNE)，将个体建模为图中的节点，并利用频率域过滤器平衡全局探索和高频多样性与低频稳定性的聚合。GNE 通过这些过滤器使 EAs 变得更可解释和可调，在基准函数实验中显著优于 GA、DE、CMA-ES、SDAES 和 RL-SHADE，尤其在复杂景观、优化偏移和噪声环境中表现出色。总体而言，该工作为 EAs 和 GNNs 提供了概念与数学基础，促进交叉创新，并扩展到机器学习（如超参数调优和神经架构搜索）以及工程实际应用。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "31 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.17629v2",
      "published_date": "2024-12-23 15:06:37 UTC",
      "updated_date": "2024-12-24 13:27:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:49:15.943764"
    },
    {
      "arxiv_id": "2412.17616v1",
      "title": "Facial Expression Analysis and Its Potentials in IoT Systems: A Contemporary Survey",
      "title_zh": "面部表情分析及其在 IoT 系统中的潜力：当代综述",
      "authors": [
        "Zixuan Shanggua",
        "Yanjie Dong",
        "Song Guo",
        "Victor C. M. Leung",
        "M. Jamal Deen",
        "Xiping Hu"
      ],
      "abstract": "Facial expressions convey human emotions and can be categorized into\nmacro-expressions (MaEs) and micro-expressions (MiEs) based on duration and\nintensity. While MaEs are voluntary and easily recognized, MiEs are\ninvoluntary, rapid, and can reveal concealed emotions. The integration of\nfacial expression analysis with Internet-of-Thing (IoT) systems has significant\npotential across diverse scenarios. IoT-enhanced MaE analysis enables real-time\nmonitoring of patient emotions, facilitating improved mental health care in\nsmart healthcare. Similarly, IoT-based MiE detection enhances surveillance\naccuracy and threat detection in smart security. This work aims at providing a\ncomprehensive overview of research progress in facial expression analysis and\nexplores its integration with IoT systems. We discuss the distinctions between\nour work and existing surveys, elaborate on advancements in MaE and MiE\ntechniques across various learning paradigms, and examine their potential\napplications in IoT. We highlight challenges and future directions for the\nconvergence of facial expression-based technologies and IoT systems, aiming to\nfoster innovation in this domain. By presenting recent developments and\npractical applications, this study offers a systematic understanding of how\nfacial expression analysis can enhance IoT systems in healthcare, security, and\nbeyond.",
      "tldr_zh": "这篇调查论文概述了面部表情分析（包括宏观表情 MaEs 和微观表情 MiEs）的最新进展，其中 MaEs 是自愿且易识别的，而 MiEs 则为非自愿的快速反应，能揭示隐藏情绪。论文探讨了将面部表情分析与 IoT 系统整合的潜力，例如在智能医疗中实现实时患者情绪监控，以及在智能安全中提升威胁检测准确性。不同于现有调查，本文详细比较了 MaEs 和 MiEs 在各种学习范式的技术进展，并分析了实际应用挑战及未来方向，以促进这一领域的创新。最终，研究强调这种融合能显著增强 IoT 系统在医疗、安全及其他领域的性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17616v1",
      "published_date": "2024-12-23 14:41:01 UTC",
      "updated_date": "2024-12-23 14:41:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:49:29.084872"
    },
    {
      "arxiv_id": "2412.17614v1",
      "title": "Emerging Security Challenges of Large Language Models",
      "title_zh": "大型语言模型的新兴安全挑战",
      "authors": [
        "Herve Debar",
        "Sven Dietrich",
        "Pavel Laskov",
        "Emil C. Lupu",
        "Eirini Ntoutsi"
      ],
      "abstract": "Large language models (LLMs) have achieved record adoption in a short period\nof time across many different sectors including high importance areas such as\neducation [4] and healthcare [23]. LLMs are open-ended models trained on\ndiverse data without being tailored for specific downstream tasks, enabling\nbroad applicability across various domains. They are commonly used for text\ngeneration, but also widely used to assist with code generation [3], and even\nanalysis of security information, as Microsoft Security Copilot demonstrates\n[18]. Traditional Machine Learning (ML) models are vulnerable to adversarial\nattacks [9]. So the concerns on the potential security implications of such\nwide scale adoption of LLMs have led to the creation of this working group on\nthe security of LLMs. During the Dagstuhl seminar on \"Network Attack Detection\nand Defense - AI-Powered Threats and Responses\", the working group discussions\nfocused on the vulnerability of LLMs to adversarial attacks, rather than their\npotential use in generating malware or enabling cyberattacks. Although we note\nthe potential threat represented by the latter, the role of the LLMs in such\nuses is mostly as an accelerator for development, similar to what it is in\nbenign use. To make the analysis more specific, the working group employed\nChatGPT as a concrete example of an LLM and addressed the following points,\nwhich also form the structure of this report: 1. How do LLMs differ in\nvulnerabilities from traditional ML models? 2. What are the attack objectives\nin LLMs? 3. How complex it is to assess the risks posed by the vulnerabilities\nof LLMs? 4. What is the supply chain in LLMs, how data flow in and out of\nsystems and what are the security implications? We conclude with an overview of\nopen challenges and outlook.",
      "tldr_zh": "这篇论文探讨了Large Language Models (LLMs) 的新兴安全挑战，强调这些模型在教育和医疗等领域广泛采用后，可能面临的vulnerability和adversarial attacks问题，与传统Machine Learning (ML) 模型相比，LLMs 由于其开放式训练和多领域适用性而具有独特的风险。研究通过一个工作组讨论，以ChatGPT为例，分析了LLMs的攻击目标、风险评估复杂性和供应链安全，包括数据流动的安全含义。最终，论文总结了这些挑战的开放问题，并展望了未来应对策略。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "A version of this appeared in the larger Dagstuhl seminar 23431\n  report (https://doi.org/10.4230/DagRep.13.10.90)",
      "pdf_url": "http://arxiv.org/pdf/2412.17614v1",
      "published_date": "2024-12-23 14:36:37 UTC",
      "updated_date": "2024-12-23 14:36:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:49:39.844180"
    },
    {
      "arxiv_id": "2412.17601v2",
      "title": "AFANet: Adaptive Frequency-Aware Network for Weakly-Supervised Few-Shot Semantic Segmentation",
      "title_zh": "AFANet：自适应频率感知网络用于弱监督少样本语义分割",
      "authors": [
        "Jiaqi Ma",
        "Guo-Sen Xie",
        "Fang Zhao",
        "Zechao Li"
      ],
      "abstract": "Few-shot learning aims to recognize novel concepts by leveraging prior\nknowledge learned from a few samples. However, for visually intensive tasks\nsuch as few-shot semantic segmentation, pixel-level annotations are\ntime-consuming and costly. Therefore, in this paper, we utilize the more\nchallenging image-level annotations and propose an adaptive frequency-aware\nnetwork (AFANet) for weakly-supervised few-shot semantic segmentation (WFSS).\nSpecifically, we first propose a cross-granularity frequency-aware module (CFM)\nthat decouples RGB images into high-frequency and low-frequency distributions\nand further optimizes semantic structural information by realigning them.\nUnlike most existing WFSS methods using the textual information from the\nmulti-modal language-vision model, e.g., CLIP, in an offline learning manner,\nwe further propose a CLIP-guided spatial-adapter module (CSM), which performs\nspatial domain adaptive transformation on textual information through online\nlearning, thus providing enriched cross-modal semantic information for CFM.\nExtensive experiments on the Pascal-5\\textsuperscript{i} and\nCOCO-20\\textsuperscript{i} datasets demonstrate that AFANet has achieved\nstate-of-the-art performance. The code is available at\nhttps://github.com/jarch-ma/AFANet.",
      "tldr_zh": "本论文针对弱监督少样本语义分割（Weakly-Supervised Few-Shot Semantic Segmentation）提出AFANet框架，利用image-level标注来减少标注成本，避免了昂贵的像素级标注。\nAFANet的核心组件包括跨粒度频率感知模块（CFM），该模块将RGB图像分解为高频和低频分布，并通过重新对齐优化语义结构信息；以及CLIP引导的空间适配器模块（CSM），通过在线学习对CLIP的文本信息进行空间域自适应变换，提供丰富的跨模态语义支持。\n实验结果显示，AFANet在Pascal-5^i和COCO-20^i数据集上达到了最先进性能，证明了其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by TMM 2024",
      "pdf_url": "http://arxiv.org/pdf/2412.17601v2",
      "published_date": "2024-12-23 14:20:07 UTC",
      "updated_date": "2024-12-25 01:42:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:49:52.348422"
    },
    {
      "arxiv_id": "2412.17596v3",
      "title": "LiveIdeaBench: Evaluating LLMs' Divergent Thinking for Scientific Idea Generation with Minimal Context",
      "title_zh": "LiveIdeaBench：使用最小上下文评估大型语言模型的发散性思维以生成科学创意",
      "authors": [
        "Kai Ruan",
        "Xuan Wang",
        "Jixiang Hong",
        "Peng Wang",
        "Yang Liu",
        "Hao Sun"
      ],
      "abstract": "While Large Language Models (LLMs) demonstrate remarkable capabilities in\nscientific tasks such as literature analysis and experimental design (e.g.,\naccurately extracting key findings from papers or generating coherent\nexperimental procedures), existing evaluation benchmarks primarily assess\nperformance using rich contextual inputs. We introduce LiveIdeaBench, a\ncomprehensive benchmark evaluating LLMs' scientific idea generation by\nassessing divergent thinking capabilities using single-keyword prompts. Drawing\nfrom Guilford's creativity theory, our benchmark employs a dynamic panel of\nstate-of-the-art LLMs to assess generated ideas across five key dimensions:\noriginality, feasibility, fluency, flexibility, and clarity. Through extensive\nexperimentation with over 40 leading models across 1,180 keywords spanning 22\nscientific domains, we reveal that the scientific idea generation capabilities\nmeasured by our benchmark, are poorly predicted by standard metrics of general\nintelligence. Our results demonstrate that models like QwQ-32B-preview achieve\ncreative performance comparable to top-tier models such as\nclaude-3.7-sonnet:thinking, despite significant gaps in their general\nintelligence scores. These findings highlight the need for specialized\nevaluation benchmarks for scientific idea generation and suggest that enhancing\nthese idea generation capabilities in LLMs may require different training\nstrategies than those used for improving general problem-solving abilities,\npotentially enabling a wider range of AI tools tailored for different stages of\nthe scientific process.",
      "tldr_zh": "本论文引入LiveIdeaBench，这是一个全面基准，用于评估大型语言模型（LLMs）在最小上下文（如单关键词提示）下的科学想法生成能力，焦点在于发散性思维。基准基于Guilford's creativity theory，通过动态LLMs面板评估生成的想法在原创性、feasibility、fluency、flexibility和clarity五个维度上。实验涉及40多个领先模型和1180个关键词，跨越22个科学领域，结果显示科学想法生成性能与一般智能指标相关性低，例如QwQ-32B-preview在创造性表现上可媲美claude-3.7-sonnet。研究强调需要专门的评估基准，并建议采用不同的训练策略来提升LLMs的想法生成能力，从而开发适用于科学过程各阶段的AI工具。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Updated manuscript and title",
      "pdf_url": "http://arxiv.org/pdf/2412.17596v3",
      "published_date": "2024-12-23 14:13:44 UTC",
      "updated_date": "2025-04-28 06:12:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:50:04.819188"
    },
    {
      "arxiv_id": "2412.17595v1",
      "title": "V$^2$-SfMLearner: Learning Monocular Depth and Ego-motion for Multimodal Wireless Capsule Endoscopy",
      "title_zh": "翻译失败",
      "authors": [
        "Long Bai",
        "Beilei Cui",
        "Liangyu Wang",
        "Yanheng Li",
        "Shilong Yao",
        "Sishen Yuan",
        "Yanan Wu",
        "Yang Zhang",
        "Max Q. -H. Meng",
        "Zhen Li",
        "Weiping Ding",
        "Hongliang Ren"
      ],
      "abstract": "Deep learning can predict depth maps and capsule ego-motion from capsule\nendoscopy videos, aiding in 3D scene reconstruction and lesion localization.\nHowever, the collisions of the capsule endoscopies within the gastrointestinal\ntract cause vibration perturbations in the training data. Existing solutions\nfocus solely on vision-based processing, neglecting other auxiliary signals\nlike vibrations that could reduce noise and improve performance. Therefore, we\npropose V$^2$-SfMLearner, a multimodal approach integrating vibration signals\ninto vision-based depth and capsule motion estimation for monocular capsule\nendoscopy. We construct a multimodal capsule endoscopy dataset containing\nvibration and visual signals, and our artificial intelligence solution develops\nan unsupervised method using vision-vibration signals, effectively eliminating\nvibration perturbations through multimodal learning. Specifically, we carefully\ndesign a vibration network branch and a Fourier fusion module, to detect and\nmitigate vibration noises. The fusion framework is compatible with popular\nvision-only algorithms. Extensive validation on the multimodal dataset\ndemonstrates superior performance and robustness against vision-only\nalgorithms. Without the need for large external equipment, our V$^2$-SfMLearner\nhas the potential for integration into clinical capsule robots, providing\nreal-time and dependable digestive examination tools. The findings show promise\nfor practical implementation in clinical settings, enhancing the diagnostic\ncapabilities of doctors.",
      "tldr_zh": "本文提出 V$^2$-SfMLearner，一种多模态框架，用于从单目胶囊内镜视频中学习 monocular depth 和 ego-motion，帮助3D场景重建和病变定位，同时整合振动信号以减少训练数据中的碰撞干扰。方法包括构建一个包含振动和视觉信号的多模态数据集，并设计振动网络分支和 Fourier 融合模块，通过无监督多模态学习有效检测和缓解振动噪声。该框架兼容现有视觉-only 算法，并在数据集上验证显示出比基线方法高性能和更强鲁棒性，具有潜力集成到临床胶囊机器人中，提供实时可靠的消化检查工具。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "To appear in IEEE Transactions on Automation Science and Engineering\n  (IEEE TASE)",
      "pdf_url": "http://arxiv.org/pdf/2412.17595v1",
      "published_date": "2024-12-23 14:11:30 UTC",
      "updated_date": "2024-12-23 14:11:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:50:17.016165"
    },
    {
      "arxiv_id": "2412.17589v1",
      "title": "PC Agent: While You Sleep, AI Works -- A Cognitive Journey into Digital World",
      "title_zh": "PC Agent: 当你睡觉时，AI 在工作——进入数字世界的认知之旅",
      "authors": [
        "Yanheng He",
        "Jiahe Jin",
        "Shijie Xia",
        "Jiadi Su",
        "Runze Fan",
        "Haoyang Zou",
        "Xiangkun Hu",
        "Pengfei Liu"
      ],
      "abstract": "Imagine a world where AI can handle your work while you sleep - organizing\nyour research materials, drafting a report, or creating a presentation you need\nfor tomorrow. However, while current digital agents can perform simple tasks,\nthey are far from capable of handling the complex real-world work that humans\nroutinely perform. We present PC Agent, an AI system that demonstrates a\ncrucial step toward this vision through human cognition transfer. Our key\ninsight is that the path from executing simple \"tasks\" to handling complex\n\"work\" lies in efficiently capturing and learning from human cognitive\nprocesses during computer use. To validate this hypothesis, we introduce three\nkey innovations: (1) PC Tracker, a lightweight infrastructure that efficiently\ncollects high-quality human-computer interaction trajectories with complete\ncognitive context; (2) a two-stage cognition completion pipeline that\ntransforms raw interaction data into rich cognitive trajectories by completing\naction semantics and thought processes; and (3) a multi-agent system combining\na planning agent for decision-making with a grounding agent for robust visual\ngrounding. Our preliminary experiments in PowerPoint presentation creation\nreveal that complex digital work capabilities can be achieved with a small\namount of high-quality cognitive data - PC Agent, trained on just 133 cognitive\ntrajectories, can handle sophisticated work scenarios involving up to 50 steps\nacross multiple applications. This demonstrates the data efficiency of our\napproach, highlighting that the key to training capable digital agents lies in\ncollecting human cognitive data. By open-sourcing our complete framework,\nincluding the data collection infrastructure and cognition completion methods,\nwe aim to lower the barriers for the research community to develop truly\ncapable digital agents.",
      "tldr_zh": "该论文提出 PC Agent，一种 AI 系统，通过人类认知转移，实现 AI 在用户睡眠时处理复杂数字工作的愿景。核心创新包括：PC Tracker 用于高效收集高质量的人机交互轨迹、两阶段 cognition completion pipeline 将原始数据转化为丰富的认知轨迹，以及 multi-agent system 结合规划智能体和 grounding 智能体进行决策和视觉定位。实验结果显示，PC Agent 仅基于 133 个认知轨迹，就能处理多达 50 步的复杂任务，如 PowerPoint 演示文稿创建，突显了方法的 数据效率，并通过开源框架降低开发真正能干数字代理的门槛。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17589v1",
      "published_date": "2024-12-23 14:02:12 UTC",
      "updated_date": "2024-12-23 14:02:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:50:29.036884"
    },
    {
      "arxiv_id": "2412.17587v1",
      "title": "Improved Cotton Leaf Disease Classification Using Parameter-Efficient Deep Learning Framework",
      "title_zh": "改进的棉叶疾病分类：使用参数高效深度学习框架",
      "authors": [
        "Aswini Kumar Patra",
        "Tejashwini Gajurel"
      ],
      "abstract": "Cotton crops, often called \"white gold,\" face significant production\nchallenges, primarily due to various leaf-affecting diseases. As a major global\nsource of fiber, timely and accurate disease identification is crucial to\nensure optimal yields and maintain crop health. While deep learning and machine\nlearning techniques have been explored to address this challenge, there remains\na gap in developing lightweight models with fewer parameters which could be\ncomputationally effective for agricultural practitioners. To address this, we\npropose an innovative deep learning framework integrating a subset of trainable\nlayers from MobileNet, transfer learning, data augmentation, a learning rate\ndecay schedule, model checkpoints, and early stopping mechanisms. Our model\ndemonstrates exceptional performance, accurately classifying seven cotton\ndisease types with an overall accuracy of 98.42% and class-wise precision\nranging from 96% to 100%. This results in significantly enhanced efficiency,\nsurpassing recent approaches in accuracy and model complexity. The existing\nmodels in the literature have yet to attain such high accuracy, even when\ntested on data sets with fewer disease types. The substantial performance\nimprovement, combined with the lightweight nature of the model, makes it\npractically suitable for real-world applications in smart farming. By offering\na high-performing and efficient solution, our framework can potentially address\nchallenges in cotton cultivation, contributing to sustainable agricultural\npractices.",
      "tldr_zh": "该研究针对棉花作物叶部疾病的识别挑战，提出了一种参数高效的深度学习框架，旨在开发轻量级模型以提升计算效率。框架整合了 MobileNet 的部分可训练层、transfer learning、data augmentation、学习率衰减、模型检查点和提前停止机制，能够准确分类七种棉花疾病。实验结果显示，该模型的总准确率达到98.42%，类别精度在96%至100%之间，并显著超越现有方法在准确性和模型复杂度上的表现，为智能农业和可持续耕作提供实用解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "4 figures, 3 Tables",
      "pdf_url": "http://arxiv.org/pdf/2412.17587v1",
      "published_date": "2024-12-23 14:01:10 UTC",
      "updated_date": "2024-12-23 14:01:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:50:38.781278"
    },
    {
      "arxiv_id": "2412.17574v2",
      "title": "HumanVBench: Exploring Human-Centric Video Understanding Capabilities of MLLMs with Synthetic Benchmark Data",
      "title_zh": "HumanVBench：利用合成",
      "authors": [
        "Ting Zhou",
        "Daoyuan Chen",
        "Qirui Jiao",
        "Bolin Ding",
        "Yaliang Li",
        "Ying Shen"
      ],
      "abstract": "In the domain of Multimodal Large Language Models (MLLMs), achieving\nhuman-centric video understanding remains a formidable challenge. Existing\nbenchmarks primarily emphasize object and action recognition, often neglecting\nthe intricate nuances of human emotions, behaviors, and speech-visual alignment\nwithin video content. We present HumanVBench, an innovative benchmark\nmeticulously crafted to bridge these gaps in the evaluation of video MLLMs.\nHumanVBench comprises 16 carefully designed tasks that explore two primary\ndimensions: inner emotion and outer manifestations, spanning static and\ndynamic, basic and complex, as well as single-modal and cross-modal aspects.\nWith two advanced automated pipelines for video annotation and\ndistractor-included QA generation, HumanVBench utilizes diverse\nstate-of-the-art (SOTA) techniques to streamline benchmark data synthesis and\nquality assessment, minimizing human annotation dependency tailored to\nhuman-centric multimodal attributes. A comprehensive evaluation across 22 SOTA\nvideo MLLMs reveals notable limitations in current performance, especially in\ncross-modal and emotion perception, underscoring the necessity for further\nrefinement toward achieving more human-like understanding. HumanVBench is\nopen-sourced to facilitate future advancements and real-world applications in\nvideo MLLMs.",
      "tldr_zh": "该研究提出了 HumanVBench，一种专注于人类中心视频理解的合成基准，用于评估多模态大语言模型(MLLMs)的能力，以弥补现有基准对人类情感、行为和语音-视觉对齐的忽视。HumanVBench 包含 16 个精心设计的任务，涵盖内部情感和外部表现的静态/动态、基本/复杂以及单模态/跨模态方面，并通过先进的自动化视频标注和 QA 生成管道利用 SOTA 技术合成数据，减少了对人工标注的依赖。对 22 个 SOTA 视频 MLLMs 的全面评估显示，这些模型在跨模态和情感感知方面存在显著局限性，突显了进一步改进的必要性。该基准已开源，以促进 MLLMs 在真实世界应用的进步。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "22 pages, 23 figures, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2412.17574v2",
      "published_date": "2024-12-23 13:45:56 UTC",
      "updated_date": "2025-03-12 03:42:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:50:53.175013"
    },
    {
      "arxiv_id": "2412.17572v1",
      "title": "Empathetic Response in Audio-Visual Conversations Using Emotion Preference Optimization and MambaCompressor",
      "title_zh": "翻译失败",
      "authors": [
        "Yeonju Kim",
        "Se Jin Park",
        "Yong Man Ro"
      ],
      "abstract": "Chatbot research is advancing with the growing importance of chatbots in\nfields that require human interactions, such as customer support and mental\nhealth care. Despite these advancements, chatbots still face significant\nchallenges in understanding subtle nuances and managing long conversation\nhistories. To address these issues, our study introduces a dual approach:\nfirstly, we employ Emotional Preference Optimization (EPO) to train chatbots\nnot only with correct responses but also with counter-emotional responses-those\nthat are contextually similar but emotionally divergent. This training enables\nthe model to discern fine nuance distinctions between correct and\ncounter-emotional responses, thereby enhancing the quality of its responses.\nSecondly, we introduce MambaCompressor to effectively compress and manage\nextensive conversation histories, significantly reducing time and memory\ncomplexities while improving the chatbot's contextual understanding. Our\ncomprehensive experiments across multiple datasets demonstrate that our model\nsignificantly outperforms existing models in generating empathetic responses\nand efficiently managing lengthy dialogues.",
      "tldr_zh": "该研究针对聊天机器人（chatbots）在音频-视觉对话中的挑战，提出了一种双重方法来提升移情响应能力。首先，引入 Emotional Preference Optimization (EPO) 训练策略，通过对比正确响应和反情感响应（counter-emotional responses），帮助模型更好地辨别细微情感差异，从而提高响应质量。其次，开发了 MambaCompressor 技术，用于高效压缩和管理长对话历史，降低时间和内存复杂度，并增强上下文理解。实验结果显示，该模型在多个数据集上显著优于现有模型，在生成移情响应和处理复杂对话方面表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17572v1",
      "published_date": "2024-12-23 13:44:51 UTC",
      "updated_date": "2024-12-23 13:44:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:51:03.174893"
    },
    {
      "arxiv_id": "2412.17566v1",
      "title": "The Dynamic Duo of Collaborative Masking and Target for Advanced Masked Autoencoder Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Shentong Mo"
      ],
      "abstract": "Masked autoencoders (MAE) have recently succeeded in self-supervised vision\nrepresentation learning. Previous work mainly applied custom-designed (e.g.,\nrandom, block-wise) masking or teacher (e.g., CLIP)-guided masking and targets.\nHowever, they ignore the potential role of the self-training (student) model in\ngiving feedback to the teacher for masking and targets. In this work, we\npresent to integrate Collaborative Masking and Targets for boosting Masked\nAutoEncoders, namely CMT-MAE. Specifically, CMT-MAE leverages a simple\ncollaborative masking mechanism through linear aggregation across attentions\nfrom both teacher and student models. We further propose using the output\nfeatures from those two models as the collaborative target of the decoder. Our\nsimple and effective framework pre-trained on ImageNet-1K achieves\nstate-of-the-art linear probing and fine-tuning performance. In particular,\nusing ViT-base, we improve the fine-tuning results of the vanilla MAE from\n83.6% to 85.7%.",
      "tldr_zh": "本文提出 CMT-MAE，一种先进的 Masked Autoencoders (MAE) 框架，通过整合 Collaborative Masking and Targets 来提升自监督视觉表示学习。具体方法包括线性聚合教师和学生模型的注意力生成协作掩码，并使用两者的输出特征作为解码器的协作目标。在 ImageNet-1K 上预训练，CMT-MAE 使用 ViT-base 模型将微调准确率从 83.6% 提高到 85.7%，实现了最先进的性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.IV",
        "eess.SP"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17566v1",
      "published_date": "2024-12-23 13:37:26 UTC",
      "updated_date": "2024-12-23 13:37:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:51:16.460394"
    },
    {
      "arxiv_id": "2412.17565v1",
      "title": "Evaluation of Bio-Inspired Models under Different Learning Settings For Energy Efficiency in Network Traffic Prediction",
      "title_zh": "在不同学习设置下对生物启发模型的评估，用于网络流量预测中的能源效率",
      "authors": [
        "Theodoros Tsiolakis",
        "Nikolaos Pavlidis",
        "Vasileios Perifanis",
        "Pavlos Efraimidis"
      ],
      "abstract": "Cellular traffic forecasting is a critical task that enables network\noperators to efficiently allocate resources and address anomalies in rapidly\nevolving environments. The exponential growth of data collected from base\nstations poses significant challenges to processing and analysis. While machine\nlearning (ML) algorithms have emerged as powerful tools for handling these\nlarge datasets and providing accurate predictions, their environmental impact,\nparticularly in terms of energy consumption, is often overlooked in favor of\ntheir predictive capabilities. This study investigates the potential of two\nbio-inspired models: Spiking Neural Networks (SNNs) and Reservoir Computing\nthrough Echo State Networks (ESNs) for cellular traffic forecasting. The\nevaluation focuses on both their predictive performance and energy efficiency.\nThese models are implemented in both centralized and federated settings to\nanalyze their effectiveness and energy consumption in decentralized systems.\nAdditionally, we compare bio-inspired models with traditional architectures,\nsuch as Convolutional Neural Networks (CNNs) and Multi-Layer Perceptrons\n(MLPs), to provide a comprehensive evaluation. Using data collected from three\ndiverse locations in Barcelona, Spain, we examine the trade-offs between\npredictive accuracy and energy demands across these approaches. The results\nindicate that bio-inspired models, such as SNNs and ESNs, can achieve\nsignificant energy savings while maintaining predictive accuracy comparable to\ntraditional architectures. Furthermore, federated implementations were tested\nto evaluate their energy efficiency in decentralized settings compared to\ncentralized systems, particularly in combination with bio-inspired models.\nThese findings offer valuable insights into the potential of bio-inspired\nmodels for sustainable and privacy-preserving cellular traffic forecasting.",
      "tldr_zh": "这篇论文评估了生物启发模型 Spiking Neural Networks (SNNs) 和 Echo State Networks (ESNs) 在蜂窝流量预测中的预测性能和能效，旨在解决传统机器学习算法的能源消耗问题。研究在集中式和联邦式学习设置下测试这些模型，并与传统架构如 Convolutional Neural Networks (CNNs) 和 Multi-Layer Perceptrons (MLPs) 进行比较，使用巴塞罗那三个地点的真实数据进行验证。结果表明，SNNs 和 ESNs 能够实现显著的能源节省，同时保持与传统模型相当的预测准确性。总体上，这为可持续且隐私保护的蜂窝流量预测提供了重要见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.17565v1",
      "published_date": "2024-12-23 13:35:53 UTC",
      "updated_date": "2024-12-23 13:35:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:51:29.269676"
    },
    {
      "arxiv_id": "2412.17548v1",
      "title": "Resource-Aware Arabic LLM Creation: Model Adaptation, Integration, and Multi-Domain Testing",
      "title_zh": "翻译失败",
      "authors": [
        "Prakash Aryan"
      ],
      "abstract": "This paper presents a novel approach to fine-tuning the Qwen2-1.5B model for\nArabic language processing using Quantized Low-Rank Adaptation (QLoRA) on a\nsystem with only 4GB VRAM. We detail the process of adapting this large\nlanguage model to the Arabic domain, using diverse datasets including Bactrian,\nOpenAssistant, and Wikipedia Arabic corpora. Our methodology involves custom\ndata preprocessing, model configuration, and training optimization techniques\nsuch as gradient accumulation and mixed-precision training. We address specific\nchallenges in Arabic NLP, including morphological complexity, dialectal\nvariations, and diacritical mark handling. Experimental results over 10,000\ntraining steps show significant performance improvements, with the final loss\nconverging to 0.1083. We provide comprehensive analysis of GPU memory usage,\ntraining dynamics, and model evaluation across various Arabic language tasks,\nincluding text classification, question answering, and dialect identification.\nThe fine-tuned model demonstrates robustness to input perturbations and\nimproved handling of Arabic-specific linguistic phenomena. This research\ncontributes to multilingual AI by demonstrating a resource-efficient approach\nfor creating specialized language models, potentially democratizing access to\nadvanced NLP technologies for diverse linguistic communities. Our work paves\nthe way for future research in low-resource language adaptation and efficient\nfine-tuning of large language models.",
      "tldr_zh": "本研究提出了一种资源高效的方法，使用 Quantized Low-Rank Adaptation (QLoRA) 在仅 4GB VRAM 的系统中微调 Qwen2-1.5B 模型，以适应阿拉伯语处理。方法包括自定义数据预处理、模型配置以及训练优化技术，如梯度积累和混合精度训练，针对阿拉伯语的形态复杂性、方言变体和 diacritical marks 等挑战。实验结果显示，经过 10,000 训练步骤，模型损失降至 0.1083，并在文本分类、问答和方言识别等任务上表现出显著性能提升。总体而言，此工作为多语言 AI 提供了一种民主化的低资源语言适应策略，促进了高效 LLM 微调的未来研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17548v1",
      "published_date": "2024-12-23 13:08:48 UTC",
      "updated_date": "2024-12-23 13:08:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:51:40.146941"
    },
    {
      "arxiv_id": "2412.17544v1",
      "title": "Retention Score: Quantifying Jailbreak Risks for Vision Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zaitang Li",
        "Pin-Yu Chen",
        "Tsung-Yi Ho"
      ],
      "abstract": "The emergence of Vision-Language Models (VLMs) is a significant advancement\nin integrating computer vision with Large Language Models (LLMs) to enhance\nmulti-modal machine learning capabilities. However, this progress has also made\nVLMs vulnerable to sophisticated adversarial attacks, raising concerns about\ntheir reliability. The objective of this paper is to assess the resilience of\nVLMs against jailbreak attacks that can compromise model safety compliance and\nresult in harmful outputs. To evaluate a VLM's ability to maintain its\nrobustness against adversarial input perturbations, we propose a novel metric\ncalled the \\textbf{Retention Score}. Retention Score is a multi-modal\nevaluation metric that includes Retention-I and Retention-T scores for\nquantifying jailbreak risks in visual and textual components of VLMs. Our\nprocess involves generating synthetic image-text pairs using a conditional\ndiffusion model. These pairs are then predicted for toxicity score by a VLM\nalongside a toxicity judgment classifier. By calculating the margin in toxicity\nscores, we can quantify the robustness of the VLM in an attack-agnostic manner.\nOur work has four main contributions. First, we prove that Retention Score can\nserve as a certified robustness metric. Second, we demonstrate that most VLMs\nwith visual components are less robust against jailbreak attacks than the\ncorresponding plain VLMs. Additionally, we evaluate black-box VLM APIs and find\nthat the security settings in Google Gemini significantly affect the score and\nrobustness. Moreover, the robustness of GPT4V is similar to the medium settings\nof Gemini. Finally, our approach offers a time-efficient alternative to\nexisting adversarial attack methods and provides consistent model robustness\nrankings when evaluated on VLMs including MiniGPT-4, InstructBLIP, and LLaVA.",
      "tldr_zh": "本文提出 Retention Score 指标，用于量化 Vision-Language Models (VLMs) 对 jailbreak 攻击的鲁棒性，该指标包括 Retention-I 和 Retention-T 得分，分别针对视觉和文本组件，通过生成合成图像-文本对并计算毒性分数差异来评估模型的抗攻击能力。研究证明 Retention Score 可以作为认证的鲁棒性指标，并发现大多数带有视觉组件的 VLMs 比纯文本 Large Language Models (LLMs) 更脆弱。实验评估了黑盒 VLM APIs，如 Google Gemini 的安全设置会显著影响分数，而 GPT4V 的鲁棒性类似于 Gemini 的中等设置。该方法提供了一个高效、攻击无关的替代方案，能在多种 VLMs（如 MiniGPT-4、InstructBLIP 和 LLaVA）上给出一致的鲁棒性排名。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 8 figures, AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.17544v1",
      "published_date": "2024-12-23 13:05:51 UTC",
      "updated_date": "2024-12-23 13:05:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:51:53.307750"
    },
    {
      "arxiv_id": "2412.17541v3",
      "title": "Concept Discovery in Deep Neural Networks for Explainable Face Anti-Spoofing",
      "title_zh": "深度神经网络中的概念发现，用于可解释的人脸防伪",
      "authors": [
        "Haoyuan Zhang",
        "Xiangyu Zhu",
        "Li Gao",
        "Guoying Zhao",
        "Zhen Lei"
      ],
      "abstract": "With the rapid growth usage of face recognition in people's daily life, face\nanti-spoofing becomes increasingly important to avoid malicious attacks. Recent\nface anti-spoofing models can reach a high classification accuracy on multiple\ndatasets but these models can only tell people \"this face is fake\" while\nlacking the explanation to answer \"why it is fake\". Such a system undermines\ntrustworthiness and causes user confusion, as it denies their requests without\nproviding any explanations. In this paper, we incorporate XAI into face\nanti-spoofing and propose a new problem termed X-FAS (eXplainable Face\nAnti-Spoofing) empowering face anti-spoofing models to provide an explanation.\nWe propose SPED (SPoofing Evidence Discovery), an X-FAS method which can\ndiscover spoof concepts and provide reliable explanations on the basis of\ndiscovered concepts. To evaluate the quality of X-FAS methods, we propose an\nX-FAS benchmark with annotated spoofing evidence by experts. We analyze SPED\nexplanations on face anti-spoofing dataset and compare SPED quantitatively and\nqualitatively with previous XAI methods on proposed X-FAS benchmark.\nExperimental results demonstrate SPED's ability to generate reliable\nexplanations.",
      "tldr_zh": "这篇论文探讨了面部反欺骗（Face Anti-Spoofing）模型的解释性问题，指出现有模型虽能准确识别假脸，但无法解释“为什么是假的”，从而影响用户信任。作者提出一个新问题 X-FAS（eXplainable Face Anti-Spoofing），并开发了 SPED（SPoofing Evidence Discovery）方法，该方法利用深度神经网络中的概念发现（Concept Discovery）来识别欺骗证据并生成可靠解释。为了评估 X-FAS 方法，论文建立了一个专家标注的基准数据集，并通过定量和定性实验证明 SPED 比传统 XAI 方法更有效。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "keywords: explainable artificial intelligence, face anti-spoofing,\n  explainable face anti-spoofing, interpretable",
      "pdf_url": "http://arxiv.org/pdf/2412.17541v3",
      "published_date": "2024-12-23 13:03:51 UTC",
      "updated_date": "2025-01-05 04:42:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:52:03.736202"
    },
    {
      "arxiv_id": "2412.17534v2",
      "title": "CiteBART: Learning to Generate Citations for Local Citation Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Ege Yiğit Çelik",
        "Selma Tekir"
      ],
      "abstract": "Local citation recommendation (LCR) suggests a set of papers for a citation\nplaceholder within a given context. The task has evolved as generative\napproaches have become more promising than the traditional pre-fetch and\nre-rank-based state-of-the-art approaches. This paper introduces\ncitation-specific pre-training within an encoder-decoder architecture, where\nauthor-date citation tokens are masked to learn to reconstruct them to fulfill\nLCR. There are two variants for this pre-training. In the local context-only\nbase scheme (CiteBART-Base), the citation token in a local context is masked to\nlearn to predict the citation. The global version (CiteBART-Global) extends the\nlocal context with the citing paper's title and abstract to enrich the learning\nsignal. CiteBART-Global achieves state-of-the-art performance on LCR benchmarks\nexcept for the FullTextPeerRead dataset, which is quite small to see the\nadvantage of generative pre-training. The effect is significant in the larger\nbenchmarks, e.g., Refseer and ArXiv., with the Refseer benchmark-trained model\nemerging as the best-performing model. We perform comprehensive experiments,\nincluding an ablation study, a qualitative analysis, and a taxonomy of\nhallucinations with detailed statistics. Our analyses confirm that\nCiteBART-Global has a cross-dataset generalization capability; the macro\nhallucination rate (MaHR) at the top-3 predictions is 4\\%, and when the\nground-truth is in the top-k prediction list, the hallucination tendency in the\nother predictions drops significantly.",
      "tldr_zh": "本论文提出 CiteBART，一种基于编码器-解码器架构的模型，用于本地引用推荐 (LCR)，通过掩码作者-日期引用标记来学习生成上下文相关的引用建议。模型有两个变体：CiteBART-Base 仅使用本地上下文进行预训练，而 CiteBART-Global 扩展到包括引用论文的标题和摘要，以增强学习信号。实验结果显示，CiteBART-Global 在 Refseer 和 ArXiv 等较大基准上达到最先进性能，表现出色跨数据集泛化能力，且顶层-3 预测的宏观幻觉率 (MaHR) 仅为 4%。这项工作通过全面消融研究和定性分析，证实了生成式预训练在 LCR 任务中的显著优势。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "17 pages, 2 figures, 10 tables",
      "pdf_url": "http://arxiv.org/pdf/2412.17534v2",
      "published_date": "2024-12-23 12:58:30 UTC",
      "updated_date": "2025-04-09 20:23:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:52:16.832425"
    },
    {
      "arxiv_id": "2412.17531v1",
      "title": "Double Landmines: Invisible Textual Backdoor Attacks based on Dual-Trigger",
      "title_zh": "Double Landmines：",
      "authors": [
        "Yang Hou",
        "Qiuling Yue",
        "Lujia Chai",
        "Guozhao Liao",
        "Wenbao Han",
        "Wei Ou"
      ],
      "abstract": "At present, all textual backdoor attack methods are based on single triggers:\nfor example, inserting specific content into the text to activate the backdoor;\nor changing the abstract text features. The former is easier to be identified\nby existing defense strategies due to its obvious characteristics; the latter,\nalthough improved in invisibility, has certain shortcomings in terms of attack\nperformance, construction of poisoned datasets, and selection of the final\npoisoning rate. On this basis, this paper innovatively proposes a Dual-Trigger\nbackdoor attack based on syntax and mood, and optimizes the construction of the\npoisoned dataset and the selection strategy of the final poisoning rate. A\nlarge number of experimental results show that this method significantly\noutperforms the previous methods based on abstract features in attack\nperformance, and achieves comparable attack performance (almost 100% attack\nsuccess rate) with the insertion-based method. In addition, the two trigger\nmechanisms included in this method can be activated independently in the\napplication phase of the model, which not only improves the flexibility of the\ntrigger style, but also enhances its robustness against defense strategies.\nThese results profoundly reveal that textual backdoor attacks are extremely\nharmful and provide a new perspective for security protection in this field.",
      "tldr_zh": "本文提出了一种基于双触发器(Dual-Trigger)的隐形文本后门攻击方法，结合语法和情绪触发器，以克服现有单一触发器方法的缺陷，如易检测或性能不足。优化了中毒数据集的构建和中毒率选择策略，使其攻击性能显著优于基于抽象特征的方法，并与插入-based方法实现几乎100%的攻击成功率。该方法允许两个触发机制独立激活，提高了攻击的灵活性和对防御策略的鲁棒性，同时揭示了文本后门攻击的潜在危害，并为该领域的安全保护提供了新视角。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17531v1",
      "published_date": "2024-12-23 12:56:30 UTC",
      "updated_date": "2024-12-23 12:56:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:52:28.611806"
    },
    {
      "arxiv_id": "2412.17527v1",
      "title": "Enhancing Cancer Diagnosis with Explainable & Trustworthy Deep Learning Models",
      "title_zh": "翻译失败",
      "authors": [
        "Badaru I. Olumuyiwa",
        "The Anh Han",
        "Zia U. Shamszaman"
      ],
      "abstract": "This research presents an innovative approach to cancer diagnosis and\nprediction using explainable Artificial Intelligence (XAI) and deep learning\ntechniques. With cancer causing nearly 10 million deaths globally in 2020,\nearly and accurate diagnosis is crucial. Traditional methods often face\nchallenges in cost, accuracy, and efficiency. Our study develops an AI model\nthat provides precise outcomes and clear insights into its decision-making\nprocess, addressing the \"black box\" problem of deep learning models. By\nemploying XAI techniques, we enhance interpretability and transparency,\nbuilding trust among healthcare professionals and patients. Our approach\nleverages neural networks to analyse extensive datasets, identifying patterns\nfor cancer detection. This model has the potential to revolutionise diagnosis\nby improving accuracy, accessibility, and clarity in medical decision-making,\npossibly leading to earlier detection and more personalised treatment\nstrategies. Furthermore, it could democratise access to high-quality\ndiagnostics, particularly in resource-limited settings, contributing to global\nhealth equity. The model's applications extend beyond cancer diagnosis,\npotentially transforming various aspects of medical decision-making and saving\nmillions of lives worldwide.",
      "tldr_zh": "这篇论文提出了一种创新方法，使用可解释人工智能(XAI)和深度学习技术来提升癌症诊断和预测的准确性与可靠性。研究开发了一个AI模型，通过神经网络分析大量数据集，识别癌症模式并提供决策过程的透明解释，从而解决深度学习模型的“黑箱”问题，并增强医疗专业人士和患者的信任。该方法有望提高诊断效率、促进早期检测和个性化治疗，并在资源有限地区实现全球健康公平，潜在地扩展到其他医疗决策领域以拯救更多生命。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17527v1",
      "published_date": "2024-12-23 12:50:47 UTC",
      "updated_date": "2024-12-23 12:50:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:52:40.117883"
    },
    {
      "arxiv_id": "2412.17524v1",
      "title": "STAHGNet: Modeling Hybrid-grained Heterogenous Dependency Efficiently for Traffic Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Jiyao Wang",
        "Zehua Peng",
        "Yijia Zhang",
        "Dengbo He",
        "Lei Chen"
      ],
      "abstract": "Traffic flow prediction plays a critical role in the intelligent\ntransportation system, and it is also a challenging task because of the\nunderlying complex Spatio-temporal patterns and heterogeneities evolving across\ntime. However, most present works mostly concentrate on solely capturing\nSpatial-temporal dependency or extracting implicit similarity graphs, but the\nhybrid-granularity evolution is ignored in their modeling process. In this\npaper, we proposed a novel data-driven end-to-end framework, named\nSpatio-Temporal Aware Hybrid Graph Network (STAHGNet), to couple the\nhybrid-grained heterogeneous correlations in series simultaneously through an\nelaborately Hybrid Graph Attention Module (HGAT) and Coarse-granularity\nTemporal Graph (CTG) generator. Furthermore, an automotive feature engineering\nwith domain knowledge and a random neighbor sampling strategy is utilized to\nimprove efficiency and reduce computational complexity. The MAE, RMSE, and MAPE\nare used for evaluation metrics. Tested on four real-life datasets, our\nproposal outperforms eight classical baselines and four state-of-the-art (SOTA)\nmethods (e.g., MAE 14.82 on PeMSD3; MAE 18.92 on PeMSD4). Besides, extensive\nexperiments and visualizations verify the effectiveness of each component in\nSTAHGNet. In terms of computational cost, STAHGNet saves at least four times\nthe space compared to the previous SOTA models. The proposed model will be\nbeneficial for more efficient TFP as well as intelligent transport system\nconstruction.",
      "tldr_zh": "该论文提出了一种新型数据驱动端到端框架 STAHGNet，用于高效建模交通预测中的混合粒度异质依赖（Hybrid-grained Heterogenous Dependency），以捕捉复杂时空模式和异质性演化。STAHGNet 通过 Hybrid Graph Attention Module (HGAT) 和 Coarse-granularity Temporal Graph (CTG) 生成器，同时处理混合粒度的异质相关性，并结合自动特征工程、领域知识和随机邻居采样策略来提升计算效率。实验结果显示，该框架在四个真实数据集上（如 PeMSD3 上 MAE 14.82）优于八个经典基线和四个 SOTA 方法，同时在计算成本上节省至少四倍空间，为智能交通系统的交通流量预测（TFP）提供了更高效的解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by Neural Computing and Applications",
      "pdf_url": "http://arxiv.org/pdf/2412.17524v1",
      "published_date": "2024-12-23 12:48:10 UTC",
      "updated_date": "2024-12-23 12:48:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:52:53.281805"
    },
    {
      "arxiv_id": "2412.17523v2",
      "title": "Constructing Fair Latent Space for Intersection of Fairness and Explainability",
      "title_zh": "构建公平潜在空间",
      "authors": [
        "Hyungjun Joo",
        "Hyeonggeun Han",
        "Sehwan Kim",
        "Sangwoo Hong",
        "Jungwoo Lee"
      ],
      "abstract": "As the use of machine learning models has increased, numerous studies have\naimed to enhance fairness. However, research on the intersection of fairness\nand explainability remains insufficient, leading to potential issues in gaining\nthe trust of actual users. Here, we propose a novel module that constructs a\nfair latent space, enabling faithful explanation while ensuring fairness. The\nfair latent space is constructed by disentangling and redistributing labels and\nsensitive attributes, allowing the generation of counterfactual explanations\nfor each type of information. Our module is attached to a pretrained generative\nmodel, transforming its biased latent space into a fair latent space.\nAdditionally, since only the module needs to be trained, there are advantages\nin terms of time and cost savings, without the need to train the entire\ngenerative model. We validate the fair latent space with various fairness\nmetrics and demonstrate that our approach can effectively provide explanations\nfor biased decisions and assurances of fairness.",
      "tldr_zh": "该研究针对机器学习模型中公平性和可解释性交集的不足，提出了一种新模块，用于构建 fair latent space，以实现忠实的解释同时确保公平。该模块通过 disentangling and redistributing 标签和敏感属性，生成 counterfactual explanations，并附加到预训练的生成模型上，从而将偏置的潜在空间转化为公平的潜在空间。由于只需训练该模块，而非整个模型，该方法在时间和成本上具有显著优势。实验结果显示，该方法在各种 fairness metrics 上表现出色，能够有效解释偏置决策并提供公平性保证。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 5 figures, accepted in AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.17523v2",
      "published_date": "2024-12-23 12:47:04 UTC",
      "updated_date": "2025-01-20 05:44:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:53:03.512968"
    },
    {
      "arxiv_id": "2412.17512v1",
      "title": "BEE: Metric-Adapted Explanations via Baseline Exploration-Exploitation",
      "title_zh": "翻译失败",
      "authors": [
        "Oren Barkan",
        "Yehonatan Elisha",
        "Jonathan Weill",
        "Noam Koenigstein"
      ],
      "abstract": "Two prominent challenges in explainability research involve 1) the nuanced\nevaluation of explanations and 2) the modeling of missing information through\nbaseline representations. The existing literature introduces diverse evaluation\nmetrics, each scrutinizing the quality of explanations through distinct lenses.\nAdditionally, various baseline representations have been proposed, each\nmodeling the notion of missingness differently. Yet, a consensus on the\nultimate evaluation metric and baseline representation remains elusive. This\nwork acknowledges the diversity in explanation metrics and baselines,\ndemonstrating that different metrics exhibit preferences for distinct\nexplanation maps resulting from the utilization of different baseline\nrepresentations and distributions. To address the diversity in metrics and\naccommodate the variety of baseline representations in a unified manner, we\npropose Baseline Exploration-Exploitation (BEE) - a path-integration method\nthat introduces randomness to the integration process by modeling the baseline\nas a learned random tensor. This tensor follows a learned mixture of baseline\ndistributions optimized through a contextual exploration-exploitation procedure\nto enhance performance on the specific metric of interest. By resampling the\nbaseline from the learned distribution, BEE generates a comprehensive set of\nexplanation maps, facilitating the selection of the best-performing explanation\nmap in this broad set for the given metric. Extensive evaluations across\nvarious model architectures showcase the superior performance of BEE in\ncomparison to state-of-the-art explanation methods on a variety of objective\nevaluation metrics.",
      "tldr_zh": "本研究针对解释性研究中的两大挑战——解释评估的细致性和通过基线表示建模缺失信息——指出不同评估指标偏好不同的解释映射和基线分布。论文提出 Baseline Exploration-Exploitation (BEE) 方法，这是一种路径积分技术，将基线建模为一个学习的随机张量，并通过上下文 exploration-exploitation 过程优化混合分布，以生成全面的解释映射集。最终，BEE 允许选择最佳解释映射，并在各种模型架构和客观评估指标上表现出色，优于现有状态-of-the-art 方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.17512v1",
      "published_date": "2024-12-23 12:19:03 UTC",
      "updated_date": "2024-12-23 12:19:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:53:16.309715"
    },
    {
      "arxiv_id": "2412.17504v2",
      "title": "An Evaluation Framework for Product Images Background Inpainting based on Human Feedback and Product Consistency",
      "title_zh": "基于人类反馈和产品一致性的产品图像背景修复评估框架",
      "authors": [
        "Yuqi Liang",
        "Jun Luo",
        "Xiaoxi Guo",
        "Jianqi Bi"
      ],
      "abstract": "In product advertising applications, the automated inpainting of backgrounds\nutilizing AI techniques in product images has emerged as a significant task.\nHowever, the techniques still suffer from issues such as inappropriate\nbackground and inconsistent product in generated product images, and existing\napproaches for evaluating the quality of generated product images are mostly\ninconsistent with human feedback causing the evaluation for this task to depend\non manual annotation. To relieve the issues above, this paper proposes Human\nFeedback and Product Consistency (HFPC), which can automatically assess the\ngenerated product images based on two modules. Firstly, to solve inappropriate\nbackgrounds, human feedback on 44,000 automated inpainting product images is\ncollected to train a reward model based on multi-modal features extracted from\nBLIP and comparative learning. Secondly, to filter generated product images\ncontaining inconsistent products, a fine-tuned segmentation model is employed\nto segment the product of the original and generated product images and then\ncompare the differences between the above two. Extensive experiments have\ndemonstrated that HFPC can effectively evaluate the quality of generated\nproduct images and significantly reduce the expense of manual annotation.\nMoreover, HFPC achieves state-of-the-art(96.4% in precision) in comparison to\nother open-source visual-quality-assessment models. Dataset and code are\navailable at:\nhttps://github.com/created-Bi/background_inpainting_products_dataset",
      "tldr_zh": "本论文提出了一种名为HFPC的评估框架，用于评估AI自动修复产品图像背景的质量，旨在解决生成的背景不合适和产品不一致的问题，同时减少对手动标注的依赖。框架包括两个模块：首先，通过收集对44,000张图像的人类反馈，训练基于BLIP和对比学习的奖励模型来评估背景适宜性；其次，使用微调的分割模型比较原始和生成图像中的产品差异，以过滤不一致的产品。实验证明，HFPC在精度上达到96.4%，优于其他开源视觉质量评估模型，并显著降低了评估开销。数据集和代码可从指定GitHub仓库获取。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "accepted by AAAI2025",
      "pdf_url": "http://arxiv.org/pdf/2412.17504v2",
      "published_date": "2024-12-23 12:03:35 UTC",
      "updated_date": "2024-12-24 03:21:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:53:27.498694"
    },
    {
      "arxiv_id": "2412.17888v1",
      "title": "Stability Bounds for the Unfolded Forward-Backward Algorithm",
      "title_zh": "展开的前向-后向算法的稳定性界限",
      "authors": [
        "Emilie Chouzenoux",
        "Cecile Della Valle",
        "Jean-Christophe Pesquet"
      ],
      "abstract": "We consider a neural network architecture designed to solve inverse problems\nwhere the degradation operator is linear and known. This architecture is\nconstructed by unrolling a forward-backward algorithm derived from the\nminimization of an objective function that combines a data-fidelity term, a\nTikhonov-type regularization term, and a potentially nonsmooth convex penalty.\nThe robustness of this inversion method to input perturbations is analyzed\ntheoretically. Ensuring robustness complies with the principles of inverse\nproblem theory, as it ensures both the continuity of the inversion method and\nthe resilience to small noise - a critical property given the known\nvulnerability of deep neural networks to adversarial perturbations. A key\nnovelty of our work lies in examining the robustness of the proposed network to\nperturbations in its bias, which represents the observed data in the inverse\nproblem. Additionally, we provide numerical illustrations of the analytical\nLipschitz bounds derived in our analysis.",
      "tldr_zh": "本研究探讨了针对线性已知退化操作符的逆问题，提出了一种通过展开 forward-backward algorithm 构建的神经网络架构，以最小化一个结合数据保真项、Tikhonov-type regularization 项和非光滑凸惩罚项的目标函数。论文理论分析了该架构对输入扰动的鲁棒性，确保方法的连续性和对噪声的抵抗力，解决了深度神经网络易受对抗性扰动的影响。创新点在于考察网络对偏差（即观测数据）扰动的鲁棒性，并通过数值示例验证了分析得到的 Lipschitz bounds。总的来说，该工作为逆问题求解提供了更可靠的框架。",
      "categories": [
        "math.OC",
        "cs.AI"
      ],
      "primary_category": "math.OC",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2105.15044",
      "pdf_url": "http://arxiv.org/pdf/2412.17888v1",
      "published_date": "2024-12-23 11:55:41 UTC",
      "updated_date": "2024-12-23 11:55:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:53:40.055800"
    },
    {
      "arxiv_id": "2412.17498v3",
      "title": "DRT: Deep Reasoning Translation via Long Chain-of-Thought",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaan Wang",
        "Fandong Meng",
        "Yunlong Liang",
        "Jie Zhou"
      ],
      "abstract": "Recently, O1-like models have emerged as representative examples,\nillustrating the effectiveness of long chain-of-thought (CoT) in reasoning\ntasks such as math and coding tasks. In this paper, we introduce DRT, an\nattempt to bring the success of long CoT to neural machine translation (MT).\nSpecifically, in view of the literature books that might involve similes and\nmetaphors, translating these texts to a target language is very difficult in\npractice due to cultural differences. In such cases, literal translation often\nfails to convey the intended meaning effectively. Even for professional human\ntranslators, considerable thought must be given to preserving semantics\nthroughout the translation process. To simulate LLMs' long thought ability in\nMT, we first mine sentences containing similes or metaphors from existing\nliterature books, and then develop a multi-agent framework to translate these\nsentences via long thought. In the multi-agent framework, a translator is used\nto iteratively translate the source sentence under the suggestions provided by\nan advisor. To ensure the effectiveness of the long thoughts, an evaluator is\nalso employed to quantify the translation quality in each round. In this way,\nwe collect tens of thousands of long-thought MT data, which is used to train\nour DRT. Using Qwen2.5 and LLama-3.1 as the backbones, DRT models can learn the\nthought process during machine translation, and outperform vanilla LLMs as well\nas LLMs which are simply fine-tuning on the paired sentences without long\nthought, showing its effectiveness.",
      "tldr_zh": "本文提出 DRT（Deep Reasoning Translation via Long Chain-of-Thought），一种将长链式思维（long CoT）应用于神经机器翻译（MT）的框架，旨在解决文学文本中比喻和隐喻的翻译挑战，尤其在文化差异导致直译失败的情况下。方法包括从文学书籍中挖掘相关句子，并采用多智能体框架（translator、advisor 和 evaluator），通过迭代翻译、建议和质量评估生成数万个长思考数据。实验结果显示，使用 Qwen2.5 和 Llama-3.1 作为骨干的 DRT 模型学会了思考过程，并在翻译性能上优于仅微调的基线模型，证明了其有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17498v3",
      "published_date": "2024-12-23 11:55:33 UTC",
      "updated_date": "2025-02-10 11:35:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:53:52.698268"
    },
    {
      "arxiv_id": "2412.17490v1",
      "title": "A Toolkit for Virtual Reality Data Collection",
      "title_zh": "翻译失败",
      "authors": [
        "Tim Rolff",
        "Niklas Hypki",
        "Markus Lappe",
        "Frank Steinicke"
      ],
      "abstract": "Due to the still relatively low number of users, acquiring large-scale and\nmultidimensional virtual reality datasets remains a significant challenge.\nConsequently, VR datasets comparable in size to state-of-the-art collections in\nnatural language processing or computer vision are rare or absent. However, the\navailability of such datasets could unlock groundbreaking advancements in\ndeep-learning, psychological modeling, and data analysis in the context of VR.\nIn this paper, we present a versatile data collection toolkit designed to\nfacilitate the capturing of extensive VR datasets. Our toolkit seamlessly\nintegrates with any device, either directly via OpenXR or through the use of a\nvirtual device. Additionally, we introduce a robust data collection pipeline\nthat emphasizes ethical practices (e.g., ensuring data protection and\nregulation) and ensures a standardized, reproducible methodology.",
      "tldr_zh": "该论文指出，由于虚拟现实（VR）用户数量有限，大规模多维VR数据集的获取仍面临挑战，导致此类数据集在深度学习、心理建模和数据分析领域较为稀缺。本文提出一个多功能的数据收集工具包，能够与任何设备无缝集成，通过OpenXR或虚拟设备实现高效数据捕获。该工具包还引入了一个稳健的数据收集管道，强调伦理实践（如数据保护和法规遵守），并确保标准化和可重复性。该方法有望推动VR相关研究的重大进展。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17490v1",
      "published_date": "2024-12-23 11:39:26 UTC",
      "updated_date": "2024-12-23 11:39:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:54:03.442597"
    },
    {
      "arxiv_id": "2412.17487v1",
      "title": "DeepMF: Deep Motion Factorization for Closed-Loop Safety-Critical Driving Scenario Simulation",
      "title_zh": "DeepMF：深度运动因子分解用于闭环安全关键驾驶场景模拟",
      "authors": [
        "Yizhe Li",
        "Linrui Zhang",
        "Xueqian Wang",
        "Houde Liu",
        "Bin Liang"
      ],
      "abstract": "Safety-critical traffic scenarios are of great practical relevance to\nevaluating the robustness of autonomous driving (AD) systems. Given that these\nlong-tail events are extremely rare in real-world traffic data, there is a\ngrowing body of work dedicated to the automatic traffic scenario generation.\nHowever, nearly all existing algorithms for generating safety-critical\nscenarios rely on snippets of previously recorded traffic events, transforming\nnormal traffic flow into accident-prone situations directly. In other words,\nsafety-critical traffic scenario generation is hindsight and not applicable to\nnewly encountered and open-ended traffic events.In this paper, we propose the\nDeep Motion Factorization (DeepMF) framework, which extends static\nsafety-critical driving scenario generation to closed-loop and interactive\nadversarial traffic simulation. DeepMF casts safety-critical traffic simulation\nas a Bayesian factorization that includes the assignment of hazardous traffic\nparticipants, the motion prediction of selected opponents, the reaction\nestimation of autonomous vehicle (AV) and the probability estimation of the\naccident occur. All the aforementioned terms are calculated using decoupled\ndeep neural networks, with inputs limited to the current observation and\nhistorical states. Consequently, DeepMF can effectively and efficiently\nsimulate safety-critical traffic scenarios at any triggered time and for any\nduration by maximizing the compounded posterior probability of traffic risk.\nExtensive experiments demonstrate that DeepMF excels in terms of risk\nmanagement, flexibility, and diversity, showcasing outstanding performance in\nsimulating a wide range of realistic, high-risk traffic scenarios.",
      "tldr_zh": "该论文提出DeepMF框架，用于生成闭环和交互式对抗的自动驾驶安全关键场景模拟，以解决现有方法依赖历史事件且无法处理新遇事件的局限性。DeepMF将模拟过程建模为Bayesian factorization，包括危险参与者分配、对手运动预测、自动车辆反应估计以及事故概率计算，所有这些均由解耦的深度神经网络基于当前观察和历史状态实现。通过最大化交通风险的后验概率，框架能高效触发并模拟任意时长的安全关键场景。实验结果显示，DeepMF在风险管理、灵活性和多样性方面表现出色，能够生成广泛的真实高风险交通场景。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17487v1",
      "published_date": "2024-12-23 11:30:24 UTC",
      "updated_date": "2024-12-23 11:30:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:54:17.033542"
    },
    {
      "arxiv_id": "2412.17486v1",
      "title": "Is ChatGPT Massively Used by Students Nowadays? A Survey on the Use of Large Language Models such as ChatGPT in Educational Settings",
      "title_zh": "翻译失败",
      "authors": [
        "Jérémie Sublime",
        "Ilaria Renna"
      ],
      "abstract": "The rapid adoption of Generative AI (GenAI) based on Large Language Models\n(LLMs) such as ChatGPT has recently and profoundly impacted education, offering\ntransformative opportunities while raising significant concerns. In this study\nwe present the results of a survey that investigates how 395 students aged 13\nto 25 years old in France and Italy integrate LLMs into their educational\nroutines.\n  Key findings include the widespread use of these tools across all age groups\nand disciplines, with older students and male students demonstrating higher\nusage frequencies, particularly in scientific contexts. The results also show\ngender disparities, raising concerns about an emerging AI literacy and\ntechnological gender gap. Additionally, while most students utilise LLMs\nconstructively, the lack of systematic proofreading and critical evaluation\namong younger users suggests potential risks to cognitive skills development,\nincluding critical thinking and foundational knowledge. The survey results\nunderscore the need for educational institutions to adapt their curricula to\nintegrate AI tools effectively, promoting ethical use, critical thinking, and\nawareness of AI limitations and environmental costs. This paper provides\nactionable recommendations for fostering equitable and effective cohabitation\nof LLMs and education while addressing emerging challenges.",
      "tldr_zh": "这篇论文通过对395名13-25岁法国和意大利学生的调查，探讨了Large Language Models (LLMs)如ChatGPT在教育环境中的使用情况。调查结果显示，LLMs在所有年龄组和学科中广泛应用，年长学生和男性学生使用频率更高，尤其在科学领域，同时暴露了性别差异和潜在的AI literacy及技术性别差距。尽管大多数学生积极利用这些工具，但年轻用户缺乏系统校对和批判性评估，可能损害批判性思维和基础知识发展。论文提出行动able建议，呼吁教育机构调整课程，促进LLMs的道德使用、认识AI的局限性及环境成本，以实现公平有效的教育整合。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "33 pages + references",
      "pdf_url": "http://arxiv.org/pdf/2412.17486v1",
      "published_date": "2024-12-23 11:29:44 UTC",
      "updated_date": "2024-12-23 11:29:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:54:28.147723"
    },
    {
      "arxiv_id": "2412.17484v1",
      "title": "Power- and Fragmentation-aware Online Scheduling for GPU Datacenters",
      "title_zh": "翻译失败",
      "authors": [
        "Francesco Lettich",
        "Emanuele Carlini",
        "Franco Maria Nardini",
        "Raffaele Perego",
        "Salvatore Trani"
      ],
      "abstract": "The rise of Artificial Intelligence and Large Language Models is driving\nincreased GPU usage in data centers for complex training and inference tasks,\nimpacting operational costs, energy demands, and the environmental footprint of\nlarge-scale computing infrastructures. This work addresses the online\nscheduling problem in GPU datacenters, which involves scheduling tasks without\nknowledge of their future arrivals. We focus on two objectives: minimizing GPU\nfragmentation and reducing power consumption. GPU fragmentation occurs when\npartial GPU allocations hinder the efficient use of remaining resources,\nespecially as the datacenter nears full capacity. A recent scheduling policy,\nFragmentation Gradient Descent (FGD), leverages a fragmentation metric to\naddress this issue. Reducing power consumption is also crucial due to the\nsignificant power demands of GPUs. To this end, we propose PWR, a novel\nscheduling policy to minimize power usage by selecting power-efficient GPU and\nCPU combinations. This involves a simplified model for measuring power\nconsumption integrated into a Kubernetes score plugin. Through an extensive\nexperimental evaluation in a simulated cluster, we show how PWR, when combined\nwith FGD, achieves a balanced trade-off between reducing power consumption and\nminimizing GPU fragmentation.",
      "tldr_zh": "该研究针对 GPU 数据中心的在线调度问题，旨在最小化 GPU fragmentation 和减少功耗，以应对 AI 模型训练和推理带来的高能源需求和环境影响。作者提出 PWR 调度策略，通过选择功耗高效的 GPU 和 CPU 组合，并整合一个简化功耗模型到 Kubernetes 评分插件中，与现有的 Fragmentation Gradient Descent (FGD) 相结合，实现资源利用的优化。实验结果显示，在模拟集群中，PWR 与 FGD 结合后，在降低功耗的同时有效减少了 GPU 碎片化，实现了两者的平衡 tradeoff。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "This work has been submitted to the IEEE for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2412.17484v1",
      "published_date": "2024-12-23 11:27:17 UTC",
      "updated_date": "2024-12-23 11:27:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:54:39.452698"
    },
    {
      "arxiv_id": "2412.17478v1",
      "title": "Signal Transformation for Effective Multi-Channel Signal Processing",
      "title_zh": "信号变换用于有效的多通道信号处理",
      "authors": [
        "Sunil Kumar Kopparapu"
      ],
      "abstract": "Electroencephalography (EEG) is an non-invasive method to record the\nelectrical activity of the brain. The EEG signals are low bandwidth and\nrecorded from multiple electrodes simultaneously in a time synchronized manner.\nTypical EEG signal processing involves extracting features from all the\nindividual channels separately and then fusing these features for downstream\napplications. In this paper, we propose a signal transformation, using basic\nsignal processing, to combine the individual channels of a low-bandwidth\nsignal, like the EEG into a single-channel high-bandwidth signal, like audio.\nFurther this signal transformation is bi-directional, namely the high-bandwidth\nsingle-channel can be transformed to generate the individual low-bandwidth\nsignals without any loss of information. Such a transformation when applied to\nEEG signals overcomes the need to process multiple signals and allows for a\nsingle-channel processing. The advantage of this signal transformation is that\nit allows the use of pre-trained single-channel pre-trained models, for\nmulti-channel signal processing and analysis. We further show the utility of\nthe signal transformation on publicly available EEG dataset.",
      "tldr_zh": "这篇论文针对多通道低带宽信号如 EEG（Electroencephalography）的处理挑战，提出了一种信号转换方法，使用基本信号处理将多个通道合并成一个高带宽单通道信号（如音频）。该转换是双向的，能够无损还原原始信号，从而简化处理过程，并允许使用预训练的单通道模型进行多通道信号分析。论文在公开 EEG 数据集上验证了这种信号转换的有效性，提升了信号处理的效率和实用性。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "5 Figures",
      "pdf_url": "http://arxiv.org/pdf/2412.17478v1",
      "published_date": "2024-12-23 11:09:53 UTC",
      "updated_date": "2024-12-23 11:09:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:54:52.018948"
    },
    {
      "arxiv_id": "2501.14756v1",
      "title": "Towards An Automated AI Act FRIA Tool That Can Reuse GDPR's DPIA",
      "title_zh": "翻译失败",
      "authors": [
        "Tytti Rintamaki",
        "Harshvardhan J. Pandit"
      ],
      "abstract": "The AI Act introduces the obligation to conduct a Fundamental Rights Impact\nAssessment (FRIA), with the possibility to reuse a Data Protection Impact\nAssessment (DPIA), and requires the EU Commission to create of an automated\ntool to support the FRIA process. In this article, we provide our novel\nexploration of the DPIA and FRIA as information processes to enable the\ncreation of automated tools. We first investigate the information involved in\nDPIA and FRIA, and then use this to align the two to state where a DPIA can be\nreused in a FRIA. We then present the FRIA as a 5-step process and discuss the\nrole of an automated tool for each step. Our work provides the necessary\nfoundation for creating and managing information for FRIA and supporting it\nthrough an automated tool as required by the AI Act.",
      "tldr_zh": "该研究探讨了 AI Act 要求进行的 Fundamental Rights Impact Assessment (FRIA)，并允许重用 GDPR 的 Data Protection Impact Assessment (DPIA)，以支持欧盟委员会创建自动化工具。通过调查 DPIA 和 FRIA 涉及的信息，该文对两者进行比对，明确了 DPIA 在 FRIA 中的可重用性，并将 FRIA 定义为一个 5 步过程。最终，该工作为 FRIA 的信息管理和自动化工具的开发提供了必要基础，促进 AI Act 的合规执行。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "Presented at CLAIRvoyant (ConventicLE on Artificial Intelligence\n  Regulation) Workshop 2024",
      "pdf_url": "http://arxiv.org/pdf/2501.14756v1",
      "published_date": "2024-12-23 10:46:55 UTC",
      "updated_date": "2024-12-23 10:46:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:56:57.223607"
    },
    {
      "arxiv_id": "2412.17468v1",
      "title": "Line Graph Vietoris-Rips Persistence Diagram for Topological Graph Representation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jaesun Shin",
        "Eunjoo Jeon",
        "Taewon Cho",
        "Namkyeong Cho",
        "Youngjune Gwon"
      ],
      "abstract": "While message passing graph neural networks result in informative node\nembeddings, they may suffer from describing the topological properties of\ngraphs. To this end, node filtration has been widely used as an attempt to\nobtain the topological information of a graph using persistence diagrams.\nHowever, these attempts have faced the problem of losing node embedding\ninformation, which in turn prevents them from providing a more expressive graph\nrepresentation. To tackle this issue, we shift our focus to edge filtration and\nintroduce a novel edge filtration-based persistence diagram, named Topological\nEdge Diagram (TED), which is mathematically proven to preserve node embedding\ninformation as well as contain additional topological information. To implement\nTED, we propose a neural network based algorithm, named Line Graph\nVietoris-Rips (LGVR) Persistence Diagram, that extracts edge information by\ntransforming a graph into its line graph. Through LGVR, we propose two model\nframeworks that can be applied to any message passing GNNs, and prove that they\nare strictly more powerful than Weisfeiler-Lehman type colorings. Finally we\nempirically validate superior performance of our models on several graph\nclassification and regression benchmarks.",
      "tldr_zh": "本论文针对消息传递图神经网络（message passing graph neural networks）在捕捉图拓扑属性时的不足，提出了一种基于边过滤（edge filtration）的持久性图，名为 Topological Edge Diagram (TED)，它能保留节点嵌入信息并融入额外拓扑细节。论文引入 Line Graph Vietoris-Rips (LGVR) Persistence Diagram 算法，通过将图转换为线图（line graph）来提取边信息，并基于此开发了两类可应用于任何 message passing GNNs 的模型框架，这些框架被证明比 Weisfeiler-Lehman 类型着色更强大。在多个图分类和回归基准上，实验结果显示了模型的优越性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.AT"
      ],
      "primary_category": "cs.LG",
      "comment": "36 pages. Accepted to Journal of Machine Learning Research",
      "pdf_url": "http://arxiv.org/pdf/2412.17468v1",
      "published_date": "2024-12-23 10:46:44 UTC",
      "updated_date": "2024-12-23 10:46:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:55:17.057152"
    },
    {
      "arxiv_id": "2412.17458v1",
      "title": "Progressive Boundary Guided Anomaly Synthesis for Industrial Anomaly Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Qiyu Chen",
        "Huiyuan Luo",
        "Han Gao",
        "Chengkan Lv",
        "Zhengtao Zhang"
      ],
      "abstract": "Unsupervised anomaly detection methods can identify surface defects in\nindustrial images by leveraging only normal samples for training. Due to the\nrisk of overfitting when learning from a single class, anomaly synthesis\nstrategies are introduced to enhance detection capability by generating\nartificial anomalies. However, existing strategies heavily rely on anomalous\ntextures from auxiliary datasets. Moreover, their limitations in the coverage\nand directionality of anomaly synthesis may result in a failure to capture\nuseful information and lead to significant redundancy. To address these issues,\nwe propose a novel Progressive Boundary-guided Anomaly Synthesis (PBAS)\nstrategy, which can directionally synthesize crucial feature-level anomalies\nwithout auxiliary textures. It consists of three core components: Approximate\nBoundary Learning (ABL), Anomaly Feature Synthesis (AFS), and Refined Boundary\nOptimization (RBO). To make the distribution of normal samples more compact,\nABL first learns an approximate decision boundary by center constraint, which\nimproves the center initialization through feature alignment. AFS then\ndirectionally synthesizes anomalies with more flexible scales guided by the\nhypersphere distribution of normal features. Since the boundary is so loose\nthat it may contain real anomalies, RBO refines the decision boundary through\nthe binary classification of artificial anomalies and normal features.\nExperimental results show that our method achieves state-of-the-art performance\nand the fastest detection speed on three widely used industrial datasets,\nincluding MVTec AD, VisA, and MPDD. The code will be available at:\nhttps://github.com/cqylunlun/PBAS.",
      "tldr_zh": "本文提出了一种 Progressive Boundary-guided Anomaly Synthesis (PBAS) 策略，用于工业图像的无监督异常检测，通过方向性地合成特征级异常来避免依赖辅助数据集。PBAS 包括三个核心组件：Approximate Boundary Learning (ABL) 用于通过中心约束学习紧凑的决策边界、Anomaly Feature Synthesis (AFS) 在正常特征的超球体分布指导下合成灵活尺度的异常，以及 Refined Boundary Optimization (RBO) 通过二分类优化边界以排除潜在真实异常。实验结果显示，该方法在 MVTec AD、VisA 和 MPDD 数据集上实现了最先进性能和最快检测速度，显著提升了异常检测的效率和准确性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by IEEE Transactions on Circuits and Systems for Video\n  Technology",
      "pdf_url": "http://arxiv.org/pdf/2412.17458v1",
      "published_date": "2024-12-23 10:26:26 UTC",
      "updated_date": "2024-12-23 10:26:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:55:28.503032"
    },
    {
      "arxiv_id": "2412.17456v1",
      "title": "Developmental Predictive Coding Model for Early Infancy Mono and Bilingual Vocal Continual Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaodan Chen",
        "Alexandre Pitti",
        "Mathias Quoy",
        "Nancy F Chen"
      ],
      "abstract": "Understanding how infants perceive speech sounds and language structures is\nstill an open problem. Previous research in artificial neural networks has\nmainly focused on large dataset-dependent generative models, aiming to\nreplicate language-related phenomena such as ''perceptual narrowing''. In this\npaper, we propose a novel approach using a small-sized generative neural\nnetwork equipped with a continual learning mechanism based on predictive coding\nfor mono-and bilingual speech sound learning (referred to as language sound\nacquisition during ''critical period'') and a compositional optimization\nmechanism for generation where no learning is involved (later infancy sound\nimitation). Our model prioritizes interpretability and demonstrates the\nadvantages of online learning: Unlike deep networks requiring substantial\noffline training, our model continuously updates with new data, making it\nadaptable and responsive to changing inputs. Through experiments, we\ndemonstrate that if second language acquisition occurs during later infancy,\nthe challenges associated with learning a foreign language after the critical\nperiod amplify, replicating the perceptual narrowing effect.",
      "tldr_zh": "本研究提出了一种基于预测编码（predictive coding）的开发模型，用于模拟婴儿早期单语和双语语音的持续学习（continual learning），以探索婴儿如何感知语音和语言结构。模型采用小型生成神经网络，结合持续学习机制来处理“critical period”中的语言音获取，以及一个不涉及学习的组合优化（compositional optimization）机制来模仿后期婴儿的语音生成，从而强调模型的可解释性和在线学习优势。实验结果显示，如果第二语言习得发生在后期婴儿期，学习外语的难度会显著增加，从而成功复制了“perceptual narrowing”现象，为理解婴儿语言发展提供了新见解。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17456v1",
      "published_date": "2024-12-23 10:23:47 UTC",
      "updated_date": "2024-12-23 10:23:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:55:39.979918"
    },
    {
      "arxiv_id": "2412.17451v1",
      "title": "Diving into Self-Evolving Training for Multimodal Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Liu",
        "Junlong Li",
        "Xiwen Zhang",
        "Fan Zhou",
        "Yu Cheng",
        "Junxian He"
      ],
      "abstract": "Reasoning ability is essential for Large Multimodal Models (LMMs). In the\nabsence of multimodal chain-of-thought annotated data, self-evolving training,\nwhere the model learns from its own outputs, has emerged as an effective and\nscalable approach for enhancing reasoning abilities. Despite its growing usage,\na comprehensive understanding of self-evolving training, particularly in the\ncontext of multimodal reasoning, remains limited. In this paper, we delve into\nthe intricacies of self-evolving training for multimodal reasoning, pinpointing\nthree key factors: Training Method, Reward Model, and Prompt Variation. We\nsystematically examine each factor and explore how various configurations\naffect the training's effectiveness. Our analysis leads to a set of best\npractices for each factor, aimed at optimizing multimodal reasoning.\nFurthermore, we explore the Self-Evolution Dynamics during training and the\nimpact of automatic balancing mechanisms in boosting performance. After all the\ninvestigations, we present a final recipe for self-evolving training in\nmultimodal reasoning, encapsulating these design choices into a framework we\ncall MSTaR (Multimodal Self-evolving Training for Reasoning), which is\nuniversally effective for models with different sizes on various benchmarks,\ne.g., surpassing the pre-evolved model significantly on 5 multimodal reasoning\nbenchmarks without using additional human annotations, as demonstrated on\nMiniCPM-V-2.5 (8B), Phi-3.5-Vision (4B) and InternVL2 (2B). We believe this\nstudy fills a significant gap in the understanding of self-evolving training\nfor multimodal reasoning and offers a robust framework for future research. Our\npolicy and reward models, as well as the collected data, is released to\nfacilitate further investigation in multimodal reasoning.",
      "tldr_zh": "该论文深入探讨了自演化训练(Self-evolving training)如何提升 Large Multimodal Models (LMMs) 的多模态推理(multimodal reasoning)能力，特别是通过分析三个关键因素：Training Method、Reward Model 和 Prompt Variation。研究者系统地考察了这些因素的最佳实践，并揭示了自演化动态(Self-Evolution Dynamics)及其自动平衡机制对性能的提升作用。最终，他们提出 MSTaR (Multimodal Self-evolving Training for Reasoning) 框架，该框架在不同规模的模型（如 MiniCPM-V-2.5 和 Phi-3.5-Vision）上显著超越基准，在 5 个多模态推理基准上取得改进，而无需额外人类标注，并开源了相关模型和数据以促进进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Project Page: https://mstar-lmm.github.io",
      "pdf_url": "http://arxiv.org/pdf/2412.17451v1",
      "published_date": "2024-12-23 10:18:41 UTC",
      "updated_date": "2024-12-23 10:18:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:55:52.718924"
    },
    {
      "arxiv_id": "2412.17449v1",
      "title": "Applying LLM and Topic Modelling in Psychotherapeutic Contexts",
      "title_zh": "在心理治疗情境中应用LLM和主题建模",
      "authors": [
        "Alexander Vanin",
        "Vadim Bolshev",
        "Anastasia Panfilova"
      ],
      "abstract": "This study explores the use of Large language models to analyze therapist\nremarks in a psychotherapeutic setting. The paper focuses on the application of\nBERTopic, a machine learning-based topic modeling tool, to the dialogue of two\ndifferent groups of therapists (classical and modern), which makes it possible\nto identify and describe a set of topics that consistently emerge across these\ngroups. The paper describes in detail the chosen algorithm for BERTopic, which\nincluded creating a vector space from a corpus of therapist remarks, reducing\nits dimensionality, clustering the space, and creating and optimizing topic\nrepresentation. Along with the automatic topical modeling by the BERTopic, the\nresearch involved an expert assessment of the findings and manual topic\nstructure optimization. The topic modeling results highlighted the most common\nand stable topics in therapists speech, offering insights into how language\npatterns in therapy develop and remain stable across different therapeutic\nstyles. This work contributes to the growing field of machine learning in\npsychotherapy by demonstrating the potential of automated methods to improve\nboth the practice and training of therapists. The study highlights the value of\ntopic modeling as a tool for gaining a deeper understanding of therapeutic\ndialogue and offers new opportunities for improving therapeutic effectiveness\nand clinical supervision.",
      "tldr_zh": "本研究运用大型语言模型(LLM)和BERTopic主题建模工具，分析两组心理治疗师（经典和现代）的对话，以识别并描述这些组中一致出现的主题。研究详细阐述了BERTopic的算法流程，包括从治疗师言论语料创建向量空间、降维、聚类，以及结合专家评估进行主题表示优化。结果突出了治疗师演讲中最常见和稳定的主题，揭示了语言模式在不同治疗风格中的发展和稳定性，并证明了自动化方法在提升心理治疗实践、训练和临床监督方面的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.7, J.4"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.17449v1",
      "published_date": "2024-12-23 10:14:32 UTC",
      "updated_date": "2024-12-23 10:14:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:56:04.214771"
    },
    {
      "arxiv_id": "2412.17440v1",
      "title": "The Role of XAI in Transforming Aeronautics and Aerospace Systems",
      "title_zh": "XAI 在航空和航天系统转型中的作用",
      "authors": [
        "Francisco Javier Cantero Zorita",
        "Mikel Galafate",
        "Javier M. Moguerza",
        "Isaac Martín de Diego",
        "M. Teresa Gonzalez",
        "Gema Gutierrez Peña"
      ],
      "abstract": "Recent advancements in Artificial Intelligence (AI) have transformed\ndecision-making in aeronautics and aerospace. These advancements in AI have\nbrought with them the need to understand the reasons behind the predictions\ngenerated by AI systems and models, particularly by professionals in these\nsectors. In this context, the emergence of eXplainable Artificial Intelligence\n(XAI) has helped bridge the gap between professionals in the aeronautical and\naerospace sectors and the AI systems and models they work with. For this\nreason, this paper provides a review of the concept of XAI is carried out\ndefining the term and the objectives it aims to achieve. Additionally, the\npaper discusses the types of models defined within it and the properties these\nmodels must fulfill to be considered transparent, as well as the post-hoc\ntechniques used to understand AI systems and models after their training.\nFinally, various application areas within the aeronautical and aerospace\nsectors will be presented, highlighting how XAI is used in these fields to help\nprofessionals understand the functioning of AI systems and models.",
      "tldr_zh": "这篇论文探讨了可解释人工智能(XAI)在航空和航天领域的关键作用，旨在帮助专业人士理解AI系统的决策过程。论文首先定义了XAI的概念及其目标，包括提升AI模型的透明度和可解释性，并讨论了XAI中的模型类型、透明属性以及后训练的后验解释技术。最终，论文概述了XAI在航空和航天行业的各种应用，如辅助决策和系统分析，从而桥接了专业人士与AI系统之间的鸿沟。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17440v1",
      "published_date": "2024-12-23 10:02:17 UTC",
      "updated_date": "2024-12-23 10:02:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:56:14.031548"
    },
    {
      "arxiv_id": "2412.17438v2",
      "title": "Markov Process-Based Graph Convolutional Networks for Entity Classification in Knowledge Graphs",
      "title_zh": "基于Markov过程的图卷积网络用于知识图谱中的实体分类",
      "authors": [
        "Johannes Mäkelburg",
        "Yiwen Peng",
        "Mehwish Alam",
        "Tobias Weller",
        "Maribel Acosta"
      ],
      "abstract": "Despite the vast amount of information encoded in Knowledge Graphs (KGs),\ninformation about the class affiliation of entities remains often incomplete.\nGraph Convolutional Networks (GCNs) have been shown to be effective predictors\nof complete information about the class affiliation of entities in KGs.\nHowever, these models do not learn the class affiliation of entities in KGs\nincorporating the complexity of the task, which negatively affects the models\nprediction capabilities. To address this problem, we introduce a Markov\nprocess-based architecture into well-known GCN architectures. This end-to-end\nnetwork learns the prediction of class affiliation of entities in KGs within a\nMarkov process. The number of computational steps is learned during training\nusing a geometric distribution. At the same time, the loss function combines\ninsights from the field of evidential learning. The experiments show a\nperformance improvement over existing models in several studied architectures\nand datasets. Based on the chosen hyperparameters for the geometric\ndistribution, the expected number of computation steps can be adjusted to\nimprove efficiency and accuracy during training.",
      "tldr_zh": "本文提出了一种基于 Markov 过程的图卷积网络 (GCNs) 架构，用于知识图谱 (KGs) 中实体分类任务，以解决现有模型未充分考虑任务复杂性导致预测能力不足的问题。该端到端网络在 Markov 过程内学习实体类别预测，并使用几何分布 (geometric distribution) 动态调整计算步骤，同时结合证据学习 (evidential learning) 的损失函数进行优化。实验结果显示，该方法在多种架构和数据集上实现了性能提升。通过调整几何分布的超参数，可以平衡训练过程中的计算效率和准确性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17438v2",
      "published_date": "2024-12-23 09:59:49 UTC",
      "updated_date": "2024-12-27 11:49:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:56:28.273944"
    },
    {
      "arxiv_id": "2412.17432v1",
      "title": "Neural Continuous-Time Supermartingale Certificates",
      "title_zh": "翻译失败",
      "authors": [
        "Grigory Neustroev",
        "Mirco Giacobbe",
        "Anna Lukina"
      ],
      "abstract": "We introduce for the first time a neural-certificate framework for\ncontinuous-time stochastic dynamical systems. Autonomous learning systems in\nthe physical world demand continuous-time reasoning, yet existing learnable\ncertificates for probabilistic verification assume discretization of the time\ncontinuum. Inspired by the success of training neural Lyapunov certificates for\ndeterministic continuous-time systems and neural supermartingale certificates\nfor stochastic discrete-time systems, we propose a framework that bridges the\ngap between continuous-time and probabilistic neural certification for\ndynamical systems under complex requirements. Our method combines machine\nlearning and symbolic reasoning to produce formally certified bounds on the\nprobabilities that a nonlinear system satisfies specifications of reachability,\navoidance, and persistence. We present both the theoretical justification and\nthe algorithmic implementation of our framework and showcase its efficacy on\npopular benchmarks.",
      "tldr_zh": "本研究首次提出神经连续时间超鞅证书（Neural Continuous-Time Supermartingale Certificates）框架，用于连续时间随机动力系统的概率验证，解决了现有方法依赖时间离散化的局限性。该框架受神经Lyapunov证书和神经超鞅证书的启发，结合机器学习和符号推理，生成正式认证的概率边界，以评估非线性系统在可达性（reachability）、避免性（avoidance）和持久性（persistence）规范下的表现。实验结果在流行基准上验证了框架的有效性，为复杂动力系统的可靠认证提供了理论基础和算法实现。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17432v1",
      "published_date": "2024-12-23 09:51:54 UTC",
      "updated_date": "2024-12-23 09:51:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:56:39.783497"
    },
    {
      "arxiv_id": "2412.17415v2",
      "title": "VidCtx: Context-aware Video Question Answering with Image Models",
      "title_zh": "翻译失败",
      "authors": [
        "Andreas Goulas",
        "Vasileios Mezaris",
        "Ioannis Patras"
      ],
      "abstract": "To address computational and memory limitations of Large Multimodal Models in\nthe Video Question-Answering task, several recent methods extract textual\nrepresentations per frame (e.g., by captioning) and feed them to a Large\nLanguage Model (LLM) that processes them to produce the final response.\nHowever, in this way, the LLM does not have access to visual information and\noften has to process repetitive textual descriptions of nearby frames. To\naddress those shortcomings, in this paper, we introduce VidCtx, a novel\ntraining-free VideoQA framework which integrates both modalities, i.e. both\nvisual information from input frames and textual descriptions of others frames\nthat give the appropriate context. More specifically, in the proposed framework\na pre-trained Large Multimodal Model (LMM) is prompted to extract at regular\nintervals, question-aware textual descriptions (captions) of video frames.\nThose will be used as context when the same LMM will be prompted to answer the\nquestion at hand given as input a) a certain frame, b) the question and c) the\ncontext/caption of an appropriate frame. To avoid redundant information, we\nchose as context the descriptions of distant frames. Finally, a simple yet\neffective max pooling mechanism is used to aggregate the frame-level decisions.\nThis methodology enables the model to focus on the relevant segments of the\nvideo and scale to a high number of frames. Experiments show that VidCtx\nachieves competitive performance among approaches that rely on open models on\nthree public Video QA benchmarks, NExT-QA, IntentQA and STAR. Our code is\navailable at https://github.com/IDT-ITI/VidCtx.",
      "tldr_zh": "为了解决大型多模态模型在 Video Question Answering (VideoQA) 任务中的计算和内存限制，论文提出 VidCtx，一个无需训练的框架，该框架整合视觉信息和文本描述，避免处理重复内容。VidCtx 使用预训练的 Large Multimodal Model (LMM) 在固定间隔提取问题相关的帧标题作为上下文，然后基于特定帧、问题和远帧描述进行回答，并通过最大池化机制聚合帧级决策。实验结果显示，VidCtx 在 NExT-QA、IntentQA 和 STAR 等公开基准上，与依赖开源模型的方法相比，表现出色，并能扩展到高帧数视频。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted in IEEE ICME 2025. This is the authors' accepted version",
      "pdf_url": "http://arxiv.org/pdf/2412.17415v2",
      "published_date": "2024-12-23 09:26:38 UTC",
      "updated_date": "2025-04-07 11:20:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:59:10.000003"
    },
    {
      "arxiv_id": "2412.17411v2",
      "title": "Pretraining with random noise for uncertainty calibration",
      "title_zh": "随机噪声预训练用于不确定性校准",
      "authors": [
        "Jeonghwan Cheon",
        "Se-Bum Paik"
      ],
      "abstract": "Uncertainty calibration is crucial for various machine learning applications,\nyet it remains challenging. Many models exhibit hallucinations - confident yet\ninaccurate responses - due to miscalibrated confidence. Here, we show that the\ncommon practice of random initialization in deep learning, often considered a\nstandard technique, is an underlying cause of this miscalibration, leading to\nexcessively high confidence in untrained networks. Our method, inspired by\ndevelopmental neuroscience, addresses this issue by simply pretraining networks\nwith random noise and labels, reducing overconfidence and bringing initial\nconfidence levels closer to chance. This ensures optimal calibration, aligning\nconfidence with accuracy during subsequent data training, without the need for\nadditional pre- or post-processing. Pre-calibrated networks excel at\nidentifying \"unknown data,\" showing low confidence for out-of-distribution\ninputs, thereby resolving confidence miscalibration.",
      "tldr_zh": "该研究发现，深度学习中常见的随机初始化会导致模型不确定性校准不当，表现为过度自信和幻觉问题。作者提出一种简单方法：通过用随机噪声和标签预训练网络，受发育神经科学启发，来降低初始置信度，使其接近随机水平，从而无需额外处理即可实现置信度与准确性的对齐。实验结果显示，这种预校准的网络在识别“未知数据”（out-of-distribution inputs）时表现出色，显著提高了模型的可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17411v2",
      "published_date": "2024-12-23 09:22:00 UTC",
      "updated_date": "2025-03-27 12:34:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:57:19.672570"
    },
    {
      "arxiv_id": "2412.17404v2",
      "title": "BrainMAP: Learning Multiple Activation Pathways in Brain Networks",
      "title_zh": "BrainMAP：学习脑网络中的多个激活通路",
      "authors": [
        "Song Wang",
        "Zhenyu Lei",
        "Zhen Tan",
        "Jiaqi Ding",
        "Xinyu Zhao",
        "Yushun Dong",
        "Guorong Wu",
        "Tianlong Chen",
        "Chen Chen",
        "Aiying Zhang",
        "Jundong Li"
      ],
      "abstract": "Functional Magnetic Resonance Image (fMRI) is commonly employed to study\nhuman brain activity, since it offers insight into the relationship between\nfunctional fluctuations and human behavior. To enhance analysis and\ncomprehension of brain activity, Graph Neural Networks (GNNs) have been widely\napplied to the analysis of functional connectivities (FC) derived from fMRI\ndata, due to their ability to capture the synergistic interactions among brain\nregions. However, in the human brain, performing complex tasks typically\ninvolves the activation of certain pathways, which could be represented as\npaths across graphs. As such, conventional GNNs struggle to learn from these\npathways due to the long-range dependencies of multiple pathways. To address\nthese challenges, we introduce a novel framework BrainMAP to learn Multiple\nActivation Pathways in Brain networks. BrainMAP leverages sequential models to\nidentify long-range correlations among sequentialized brain regions and\nincorporates an aggregation module based on Mixture of Experts (MoE) to learn\nfrom multiple pathways. Our comprehensive experiments highlight BrainMAP's\nsuperior performance. Furthermore, our framework enables explanatory analyses\nof crucial brain regions involved in tasks. Our code is provided at\nhttps://github.com/LzyFischer/Graph-Mamba.",
      "tldr_zh": "本文提出 BrainMAP 框架，用于学习脑网络中的多个激活路径，解决传统 Graph Neural Networks (GNNs) 在处理 Functional Magnetic Resonance Image (fMRI) 数据时面临的 long-range dependencies 挑战。BrainMAP 结合顺序模型来识别脑区序列的长程相关性，并采用基于 Mixture of Experts (MoE) 的聚合模块来从多路径中提取信息。实验结果表明，该框架在性能上优于现有方法，并支持对任务中关键脑区的解释性分析。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.17404v2",
      "published_date": "2024-12-23 09:13:35 UTC",
      "updated_date": "2025-02-01 04:50:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:57:32.217867"
    },
    {
      "arxiv_id": "2412.17387v3",
      "title": "Singular Value Scaling: Efficient Generative Model Compression via Pruned Weights Refinement",
      "title_zh": "翻译失败",
      "authors": [
        "Hyeonjin Kim",
        "Jaejun Yoo"
      ],
      "abstract": "While pruning methods effectively maintain model performance without extra\ntraining costs, they often focus solely on preserving crucial connections,\noverlooking the impact of pruned weights on subsequent fine-tuning or\ndistillation, leading to inefficiencies. Moreover, most compression techniques\nfor generative models have been developed primarily for GANs, tailored to\nspecific architectures like StyleGAN, and research into compressing Diffusion\nmodels has just begun. Even more, these methods are often applicable only to\nGANs or Diffusion models, highlighting the need for approaches that work across\nboth model types. In this paper, we introduce Singular Value Scaling (SVS), a\nversatile technique for refining pruned weights, applicable to both model\ntypes. Our analysis reveals that pruned weights often exhibit dominant singular\nvectors, hindering fine-tuning efficiency and leading to suboptimal performance\ncompared to random initialization. Our method enhances weight initialization by\nminimizing the disparities between singular values of pruned weights, thereby\nimproving the fine-tuning process. This approach not only guides the compressed\nmodel toward superior solutions but also significantly speeds up fine-tuning.\nExtensive experiments on StyleGAN2, StyleGAN3 and DDPM demonstrate that SVS\nimproves compression performance across model types without additional training\ncosts. Our code is available at:\nhttps://github.com/LAIT-CVLab/Singular-Value-Scaling.",
      "tldr_zh": "本研究针对生成模型（如 GANs 和 Diffusion 模型）的剪枝方法存在的效率问题，提出 Singular Value Scaling (SVS)，一种通用的剪枝权重精炼技术，适用于多种模型类型。SVS 通过分析剪枝权重的奇异向量差异，并最小化奇异值之间的不均衡，来优化权重初始化，从而提升后续微调的效率和性能。实验在 StyleGAN2、StyleGAN3 和 DDPM 上表明，SVS 显著提高了压缩性能，同时无需额外训练成本，为跨模型类型的生成模型压缩提供了高效解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.17387v3",
      "published_date": "2024-12-23 08:40:08 UTC",
      "updated_date": "2025-03-31 11:10:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:57:44.225358"
    },
    {
      "arxiv_id": "2501.14755v1",
      "title": "Data-Juicer 2.0: Cloud-Scale Adaptive Data Processing for Foundation Models",
      "title_zh": "Data-Juicer 2.0：云规模自适应数据处理基础模型",
      "authors": [
        "Daoyuan Chen",
        "Yilun Huang",
        "Xuchen Pan",
        "Nana Jiang",
        "Haibin Wang",
        "Ce Ge",
        "Yushuo Chen",
        "Wenhao Zhang",
        "Zhijian Ma",
        "Yilei Zhang",
        "Jun Huang",
        "Wei Lin",
        "Yaliang Li",
        "Bolin Ding",
        "Jingren Zhou"
      ],
      "abstract": "The burgeoning field of foundation models necessitates advanced data\nprocessing mechanisms capable of harnessing vast valuable data with varied\ntypes utilized by these models. Nevertheless, the current landscape presents\nunique challenges that traditional data processing frameworks cannot handle\neffectively, especially with multimodal intricacies. In response, we present\nData-Juicer 2.0, a new system offering fruitful data processing capabilities\nbacked by over a hundred operators spanning various modalities like text,\nimage, audio, and video. With seamless compatibility and dedicated optimization\nto popular dataset hubs like Hugging Face and computing engines like Ray,\nData-Juicer 2.0 enhances its predecessor in both usability, efficiency, and\nprogrammability. It features an easily accessible user interface layer that\nsupports decoupled Python interactions, RESTful APIs, and conversational\ncommands. Alongside this, it contains a core runtime layer optimized for\nadaptive execution and management across different dataset scales, processing\ndemands, and computational environments, while shielding unnecessary system\ndetails. Extensive empirical evaluations demonstrate Data-Juicer 2.0's\nremarkable performance and scalability, highlighting its capability to\nefficiently process tens of billions of data samples with tens of thousands of\nCPU cores. The system is publicly available, actively maintained, and broadly\nadopted in diverse research endeavors, practical applications, and real-world\nproducts such as Alibaba Cloud PAI.",
      "tldr_zh": "本文介绍了 Data-Juicer 2.0，一种针对 Foundation Models 的云规模自适应数据处理系统，旨在高效处理多模态数据（如文本、图像、音频和视频）的挑战。系统提供了超过一百种操作符，并优化了与 Hugging Face 和 Ray 等平台的兼容性，包括用户界面层（如 Python 交互、RESTful APIs 和对话命令）和核心运行时层，以适应不同数据规模和计算环境。实验评估显示，Data-Juicer 2.0 能够高效处理数十亿数据样本和数万个 CPU 核心，并已在研究、应用和产品（如 Alibaba Cloud PAI）中广泛采用。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "16 pages, 9 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2501.14755v1",
      "published_date": "2024-12-23 08:29:57 UTC",
      "updated_date": "2024-12-23 08:29:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:57:57.417273"
    },
    {
      "arxiv_id": "2412.17377v1",
      "title": "A Plug-and-Play Physical Motion Restoration Approach for In-the-Wild High-Difficulty Motions",
      "title_zh": "一种即插即用的物理运动恢复方法，用于野外高难度动作",
      "authors": [
        "Youliang Zhang",
        "Ronghui Li",
        "Yachao Zhang",
        "Liang Pan",
        "Jingbo Wang",
        "Yebin Liu",
        "Xiu Li"
      ],
      "abstract": "Extracting physically plausible 3D human motion from videos is a critical\ntask. Although existing simulation-based motion imitation methods can enhance\nthe physical quality of daily motions estimated from monocular video capture,\nextending this capability to high-difficulty motions remains an open challenge.\nThis can be attributed to some flawed motion clips in video-based motion\ncapture results and the inherent complexity in modeling high-difficulty\nmotions. Therefore, sensing the advantage of segmentation in localizing human\nbody, we introduce a mask-based motion correction module (MCM) that leverages\nmotion context and video mask to repair flawed motions, producing\nimitation-friendly motions; and propose a physics-based motion transfer module\n(PTM), which employs a pretrain and adapt approach for motion imitation,\nimproving physical plausibility with the ability to handle in-the-wild and\nchallenging motions. Our approach is designed as a plug-and-play module to\nphysically refine the video motion capture results, including high-difficulty\nin-the-wild motions. Finally, to validate our approach, we collected a\nchallenging in-the-wild test set to establish a benchmark, and our method has\ndemonstrated effectiveness on both the new benchmark and existing public\ndatasets.https://physicalmotionrestoration.github.io",
      "tldr_zh": "本文提出了一种plug-and-play的物理动作恢复方法，旨在从视频中提取物理合理的3D人体动作，特别是针对in-the-wild的高难度动作，以解决现有模拟方法在复杂场景中的局限性。该方法包括mask-based motion correction module (MCM)，利用动作上下文和视频掩码修复错误动作；以及physics-based motion transfer module (PTM)，通过预训练和适配策略提升动作模仿的物理可信度。实验结果显示，该方法在自建的挑战性基准测试集和现有公共数据集上表现出色，显著改善了动作捕捉的准确性和适用性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17377v1",
      "published_date": "2024-12-23 08:26:00 UTC",
      "updated_date": "2024-12-23 08:26:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:58:09.838222"
    },
    {
      "arxiv_id": "2412.17373v1",
      "title": "FRTP: Federating Route Search Records to Enhance Long-term Traffic Prediction",
      "title_zh": "FRTP：联邦化路线搜索记录以增强长期交通预测",
      "authors": [
        "Hangli Ge",
        "Xiaojie Yang",
        "Itsuki Matsunaga",
        "Dizhi Huang",
        "Noboru Koshizuka"
      ],
      "abstract": "Accurate traffic prediction, especially predicting traffic conditions several\ndays in advance is essential for intelligent transportation systems (ITS). Such\npredictions enable mid- and long-term traffic optimization, which is crucial\nfor efficient transportation planning. However, the inclusion of diverse\nexternal features, alongside the complexities of spatial relationships and\ntemporal uncertainties, significantly increases the complexity of forecasting\nmodels. Additionally, traditional approaches have handled data preprocessing\nseparately from the learning model, leading to inefficiencies caused by\nrepeated trials of preprocessing and training. In this study, we propose a\nfederated architecture capable of learning directly from raw data with varying\nfeatures and time granularities or lengths. The model adopts a unified design\nthat accommodates different feature types, time scales, and temporal periods.\nOur experiments focus on federating route search records and begin by\nprocessing raw data within the model framework. Unlike traditional models, this\napproach integrates the data federation phase into the learning process,\nenabling compatibility with various time frequencies and input/output\nconfigurations. The accuracy of the proposed model is demonstrated through\nevaluations using diverse learning patterns and parameter settings. The results\nshow that online search log data is useful for forecasting long-term traffic,\nhighlighting the model's adaptability and efficiency.",
      "tldr_zh": "本研究提出FRTP框架，通过联邦化路线搜索记录（Federating Route Search Records）来提升长期交通预测的准确性，旨在解决传统模型在处理多样外部特征、空间关系和时间不确定性时的低效问题。FRTP采用统一的联邦架构，直接从原始数据学习，支持不同特征类型、时间粒度和长度，并将数据预处理与学习过程整合，实现了更高的兼容性和效率。在实验中，该模型使用路线搜索记录进行评估，结果显示其在各种学习模式和参数设置下表现出色，证明在线搜索日志数据对长期交通预测的实用价值，并突显了框架的适应性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by IEEE BigData 2024",
      "pdf_url": "http://arxiv.org/pdf/2412.17373v1",
      "published_date": "2024-12-23 08:14:20 UTC",
      "updated_date": "2024-12-23 08:14:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:58:20.281057"
    },
    {
      "arxiv_id": "2412.17365v1",
      "title": "Boosting LLM via Learning from Data Iteratively and Selectively",
      "title_zh": "翻译失败",
      "authors": [
        "Qi Jia",
        "Siyu Ren",
        "Ziheng Qin",
        "Fuzhao Xue",
        "Jinjie Ni",
        "Yang You"
      ],
      "abstract": "Datasets nowadays are generally constructed from multiple sources and using\ndifferent synthetic techniques, making data de-noising and de-duplication\ncrucial before being used for post-training. In this work, we propose to\nperform instruction tuning by iterative data selection (\\ApproachName{}). We\nmeasure the quality of a sample from complexity and diversity simultaneously.\nInstead of calculating the complexity score once for all before fine-tuning, we\nhighlight the importance of updating this model-specific score during\nfine-tuning to accurately accommodate the dynamic changes of the model. On the\nother hand, the diversity score is defined on top of the samples' responses\nunder the consideration of their informativeness. IterIT integrates the\nstrengths of both worlds by iteratively updating the complexity score for the\ntop-ranked samples and greedily selecting the ones with the highest\ncomplexity-diversity score. Experiments on multiple instruction-tuning data\ndemonstrate consistent improvements of IterIT over strong baselines. Moreover,\nour approach also generalizes well to domain-specific scenarios and different\nbackbone models. All resources will be available at\nhttps://github.com/JiaQiSJTU/IterIT.",
      "tldr_zh": "该论文提出了一种名为 IterIT 的指令调整方法，通过迭代和选择性学习数据来提升大语言模型(LLM)的性能，以解决数据集去噪和去重问题。方法同时评估样本的复杂性和多样性，其中复杂性分数在微调过程中动态更新，而多样性分数基于样本响应的信息性；IterIT 然后迭代选择最高分数的样本进行训练。实验结果显示，该方法在多个指令调整数据集上比强基线模型表现出显著改善，并能泛化到特定领域和不同骨干模型。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17365v1",
      "published_date": "2024-12-23 08:01:24 UTC",
      "updated_date": "2024-12-23 08:01:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:58:32.245926"
    },
    {
      "arxiv_id": "2412.17364v1",
      "title": "Efficient fine-tuning methodology of text embedding models for information retrieval: contrastive learning penalty (clp)",
      "title_zh": "翻译失败",
      "authors": [
        "Jeongsu Yu"
      ],
      "abstract": "Text embedding models play a crucial role in natural language processing,\nparticularly in information retrieval, and their importance is further\nhighlighted with the recent utilization of RAG (Retrieval- Augmented\nGeneration). This study presents an efficient fine-tuning methodology\nencompassing data selection, loss function, and model architecture to enhance\nthe information retrieval performance of pre-trained text embedding models. In\nparticular, this study proposes a novel Contrastive Learning Penalty function\nthat overcomes the limitations of existing Contrastive Learning. The proposed\nmethodology achieves significant performance improvements over existing methods\nin document retrieval tasks. This study is expected to contribute to improving\nthe performance of information retrieval systems through fine-tuning of text\nembedding models. The code for this study can be found at\nhttps://github.com/CreaLabs/Enhanced-BGE-M3-with-CLP-and-MoE, and the\nbest-performing model can be found at https://huggingface.co/CreaLabs.",
      "tldr_zh": "这篇论文提出了一种高效的微调方法，用于提升文本嵌入模型在信息检索中的性能，特别是结合 Retrieval-Augmented Generation (RAG)。该方法包括数据选择、损失函数设计和模型架构优化，重点引入了新型 Contrastive Learning Penalty (CLP) 函数，以克服现有 Contrastive Learning 的局限性。实验结果显示，该方法在文档检索任务中显著优于现有基准，并为信息检索系统性能改进提供贡献；相关代码和最佳模型可通过 GitHub 和 Hugging Face 访问。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "68T50, 68P20",
        "H.3.3; I.2.7"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17364v1",
      "published_date": "2024-12-23 07:55:22 UTC",
      "updated_date": "2024-12-23 07:55:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:58:44.568609"
    },
    {
      "arxiv_id": "2412.17346v1",
      "title": "FFA Sora, video generation as fundus fluorescein angiography simulator",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyuan Wu",
        "Lili Wang",
        "Ruoyu Chen",
        "Bowen Liu",
        "Weiyi Zhang",
        "Xi Yang",
        "Yifan Feng",
        "Mingguang He",
        "Danli Shi"
      ],
      "abstract": "Fundus fluorescein angiography (FFA) is critical for diagnosing retinal\nvascular diseases, but beginners often struggle with image interpretation. This\nstudy develops FFA Sora, a text-to-video model that converts FFA reports into\ndynamic videos via a Wavelet-Flow Variational Autoencoder (WF-VAE) and a\ndiffusion transformer (DiT). Trained on an anonymized dataset, FFA Sora\naccurately simulates disease features from the input text, as confirmed by\nobjective metrics: Frechet Video Distance (FVD) = 329.78, Learned Perceptual\nImage Patch Similarity (LPIPS) = 0.48, and Visual-question-answering Score\n(VQAScore) = 0.61. Specific evaluations showed acceptable alignment between the\ngenerated videos and textual prompts, with BERTScore of 0.35. Additionally, the\nmodel demonstrated strong privacy-preserving performance in retrieval\nevaluations, achieving an average Recall@K of 0.073. Human assessments\nindicated satisfactory visual quality, with an average score of 1.570(scale: 1\n= best, 5 = worst). This model addresses privacy concerns associated with\nsharing large-scale FFA data and enhances medical education.",
      "tldr_zh": "该研究开发了FFA Sora，一种文本到视频模型，用于模拟Fundus Fluorescein Angiography (FFA)报告，旨在帮助初学者更好地理解视网膜血管疾病诊断。模型结合Wavelet-Flow Variational Autoencoder (WF-VAE)和diffusion transformer (DiT)，在匿名数据集上训练，能够准确生成动态视频并模拟疾病特征。评估结果显示，模型在Frechet Video Distance (FVD)=329.78、Learned Perceptual Image Patch Similarity (LPIPS)=0.48和Visual-question-answering Score (VQAScore)=0.61等方面表现出色，文本对齐指标BERTScore=0.35，且隐私保护表现强劲（Recall@K=0.073）。总体而言，FFA Sora解决了大规模FFA数据共享的隐私问题，并提升了医学教育效果。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "24 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.17346v1",
      "published_date": "2024-12-23 07:18:13 UTC",
      "updated_date": "2024-12-23 07:18:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:58:58.057126"
    },
    {
      "arxiv_id": "2412.17339v1",
      "title": "MineAgent: Towards Remote-Sensing Mineral Exploration with Multimodal Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Beibei Yu",
        "Tao Shen",
        "Hongbin Na",
        "Ling Chen",
        "Denqi Li"
      ],
      "abstract": "Remote-sensing mineral exploration is critical for identifying economically\nviable mineral deposits, yet it poses significant challenges for multimodal\nlarge language models (MLLMs). These include limitations in domain-specific\ngeological knowledge and difficulties in reasoning across multiple\nremote-sensing images, further exacerbating long-context issues. To address\nthese, we present MineAgent, a modular framework leveraging hierarchical\njudging and decision-making modules to improve multi-image reasoning and\nspatial-spectral integration. Complementing this, we propose MineBench, a\nbenchmark specific for evaluating MLLMs in domain-specific mineral exploration\ntasks using geological and hyperspectral data. Extensive experiments\ndemonstrate the effectiveness of MineAgent, highlighting its potential to\nadvance MLLMs in remote-sensing mineral exploration.",
      "tldr_zh": "本研究针对多模态大语言模型(MLLMs)在遥感矿物勘探中的领域特定地质知识缺口和多图像推理挑战，提出了MineAgent框架。该框架采用模块化设计，包括分层判断和决策模块，以改善多图像推理和空间-光谱整合能力。此外，研究开发了MineBench基准，用于评估MLLMs在地质和超光谱数据下的矿物勘探任务表现。实验结果证明了MineAgent的有效性，展示了其在遥感矿物勘探领域的潜力。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17339v1",
      "published_date": "2024-12-23 07:08:14 UTC",
      "updated_date": "2024-12-23 07:08:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:59:23.007861"
    },
    {
      "arxiv_id": "2412.17338v1",
      "title": "Enhancing Topic Interpretability for Neural Topic Modeling through Topic-wise Contrastive Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Xin Gao",
        "Yang Lin",
        "Ruiqing Li",
        "Yasha Wang",
        "Xu Chu",
        "Xinyu Ma",
        "Hailong Yu"
      ],
      "abstract": "Data mining and knowledge discovery are essential aspects of extracting\nvaluable insights from vast datasets. Neural topic models (NTMs) have emerged\nas a valuable unsupervised tool in this field. However, the predominant\nobjective in NTMs, which aims to discover topics maximizing data likelihood,\noften lacks alignment with the central goals of data mining and knowledge\ndiscovery which is to reveal interpretable insights from large data\nrepositories. Overemphasizing likelihood maximization without incorporating\ntopic regularization can lead to an overly expansive latent space for topic\nmodeling. In this paper, we present an innovative approach to NTMs that\naddresses this misalignment by introducing contrastive learning measures to\nassess topic interpretability. We propose a novel NTM framework, named\nContraTopic, that integrates a differentiable regularizer capable of evaluating\nmultiple facets of topic interpretability throughout the training process. Our\nregularizer adopts a unique topic-wise contrastive methodology, fostering both\ninternal coherence within topics and clear external distinctions among them.\nComprehensive experiments conducted on three diverse datasets demonstrate that\nour approach consistently produces topics with superior interpretability\ncompared to state-of-the-art NTMs.",
      "tldr_zh": "本论文指出，神经主题模型（NTMs）在追求数据似然性最大化时，往往忽略了主题的可解释性，导致知识发现效率低下。为解决这一问题，研究提出ContraTopic框架，该框架通过引入主题-wise对比学习作为可微分正则化器，提升主题的内部连贯性和外部区分度。实验在三个不同数据集上验证，ContraTopic比现有最先进NTMs生成更具可解释性的主题结果。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17338v1",
      "published_date": "2024-12-23 07:07:06 UTC",
      "updated_date": "2024-12-23 07:07:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:59:33.877970"
    },
    {
      "arxiv_id": "2412.17336v1",
      "title": "APEX$^2$: Adaptive and Extreme Summarization for Personalized Knowledge Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Zihao Li",
        "Dongqi Fu",
        "Mengting Ai",
        "Jingrui He"
      ],
      "abstract": "Knowledge graphs (KGs), which store an extensive number of relational facts,\nserve various applications. Recently, personalized knowledge graphs (PKGs) have\nemerged as a solution to optimize storage costs by customizing their content to\nalign with users' specific interests within particular domains. In the real\nworld, on one hand, user queries and their underlying interests are inherently\nevolving, requiring PKGs to adapt continuously; on the other hand, the\nsummarization is constantly expected to be as small as possible in terms of\nstorage cost. However, the existing PKG summarization methods implicitly assume\nthat the user's interests are constant and do not shift. Furthermore, when the\nsize constraint of PKG is extremely small, the existing methods cannot\ndistinguish which facts are more of immediate interest and guarantee the\nutility of the summarized PKG. To address these limitations, we propose\nAPEX$^2$, a highly scalable PKG summarization framework designed with robust\ntheoretical guarantees to excel in adaptive summarization tasks with extremely\nsmall size constraints. To be specific, after constructing an initial PKG,\nAPEX$^2$ continuously tracks the interest shift and adjusts the previous\nsummary. We evaluate APEX$^2$ under an evolving query setting on benchmark KGs\ncontaining up to 12 million triples, summarizing with compression ratios $\\leq\n0.1\\%$. The experiments show that APEX outperforms state-of-the-art baselines\nin terms of both query-answering accuracy and efficiency.",
      "tldr_zh": "本论文提出 APEX² 框架，用于个性化知识图谱 (PKGs) 的适应性和极端总结，以应对用户兴趣动态变化和极小存储成本需求。APEX² 在构建初始 PKG 后，通过持续跟踪兴趣转移并调整总结，确保在极端压缩比 (≤ 0.1%) 下维持高实用性，并提供理论保证。实验结果显示，该框架在包含多达 1200 万三元组的基准 Knowledge Graphs (KGs) 上，比现有方法在查询回答准确性和效率方面表现出显著优势。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB",
        "cs.SC"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by KDD 2025. 27 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.17336v1",
      "published_date": "2024-12-23 07:02:06 UTC",
      "updated_date": "2024-12-23 07:02:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:59:45.856146"
    },
    {
      "arxiv_id": "2412.17334v1",
      "title": "Complete Implementation of WXF Chinese Chess Rules",
      "title_zh": "WXF 象棋规则的完整实现",
      "authors": [
        "Daniel Tan",
        "Neftali Watkinson Medina"
      ],
      "abstract": "Unlike repetitions in Western Chess where all repetitions are draws,\nrepetitions in Chinese Chess could result in a win, draw, or loss depending on\nthe kind of repetition being made by both players. One of the biggest hurdles\nfacing Chinese Chess application development is a proper system for judging\ngames correctly. This paper introduces a complete algorithm for ruling the WXF\nrules correctly in all 110 example cases found in the WXF manual. We introduce\nseveral novel optimizations for speeding up the repetition handling without\ncompromising the program correctness. This algorithm is usable in engines, and\nwe saw a total increase in playing strength by +10 point rating increase, or an\nincreased 5% winrate when integrating this approach into our prototype engine.",
      "tldr_zh": "这篇论文针对中式象棋的 WXF 规则，开发了一个完整的算法来正确处理重复局面，这些规则与国际象棋不同，可能导致胜、和或负。\n算法涵盖了 WXF 手册中的所有 110 个示例案例，并引入了几种新优化方法，以加速重复局面的判断而不影响程序正确性。\n实验结果显示，将此算法集成到原型引擎中，提升了引擎实力，评分增加了 10 分，胜率提高了 5%。",
      "categories": [
        "cs.AI",
        "I.2.0"
      ],
      "primary_category": "cs.AI",
      "comment": "19 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.17334v1",
      "published_date": "2024-12-23 06:56:50 UTC",
      "updated_date": "2024-12-23 06:56:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T16:59:56.827795"
    },
    {
      "arxiv_id": "2412.17333v1",
      "title": "Broadband Ground Motion Synthesis by Diffusion Model with Minimal Condition",
      "title_zh": "翻译失败",
      "authors": [
        "Jaeheun Jung",
        "Jaehyuk Lee",
        "Chang-Hae Jung",
        "Hanyoung Kim",
        "Bosung Jung",
        "Donghun Lee"
      ],
      "abstract": "Earthquakes are rare. Hence there is a fundamental call for reliable methods\nto generate realistic ground motion data for data-driven approaches in\nseismology. Recent GAN-based methods fall short of the call, as the methods\neither require special information such as geological traits or generate subpar\nwaveforms that fail to satisfy seismological constraints such as phase arrival\ntimes. We propose a specialized Latent Diffusion Model (LDM) that reliably\ngenerates realistic waveforms after learning from real earthquake data with\nminimal conditions: location and magnitude. We also design a domain-specific\ntraining method that exploits the traits of earthquake dataset: multiple\nobserved waveforms time-aligned and paired to each earthquake source that are\ntagged with seismological metadata comprised of earthquake magnitude, depth of\nfocus, and the locations of epicenter and seismometers. We construct the\ntime-aligned earthquake dataset using Southern California Earthquake Data\nCenter (SCEDC) API, and train our model with the dataset and our proposed\ntraining method for performance evaluation. Our model surpasses all comparable\ndata-driven methods in various test criteria not only from waveform generation\ndomain but also from seismology such as phase arrival time, GMPE analysis, and\nspectrum analysis. Our result opens new future research directions for deep\nlearning applications in seismology.",
      "tldr_zh": "本文提出了一种基于Latent Diffusion Model (LDM)的地动波形合成方法，仅需位置和震级作为最小条件，就能生成真实地震波形，解决了现有GAN方法依赖特殊信息或无法满足地震学约束的问题。研究者设计了特定领域的训练策略，利用地震数据集的特点（如时间对齐的波形和元数据），并使用Southern California Earthquake Data Center (SCEDC) API构建数据集。实验结果显示，该模型在波形生成、相到达时间、GMPE分析和频谱分析等标准上超越了其他数据驱动方法。该创新为地震学中的深度学习应用开辟了新研究方向。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.geo-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17333v1",
      "published_date": "2024-12-23 06:56:28 UTC",
      "updated_date": "2024-12-23 06:56:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:00:10.201832"
    },
    {
      "arxiv_id": "2412.18635v1",
      "title": "Edge-AI for Agriculture: Lightweight Vision Models for Disease Detection in Resource-Limited Settings",
      "title_zh": "翻译失败",
      "authors": [
        "Harsh Joshi"
      ],
      "abstract": "This research paper presents the development of a lightweight and efficient\ncomputer vision pipeline aimed at assisting farmers in detecting orange\ndiseases using minimal resources. The proposed system integrates advanced\nobject detection, classification, and segmentation models, optimized for\ndeployment on edge devices, ensuring functionality in resource-limited\nenvironments. The study evaluates the performance of various state-of-the-art\nmodels, focusing on their accuracy, computational efficiency, and\ngeneralization capabilities. Notable findings include the Vision Transformer\nachieving 96 accuracy in orange species classification and the lightweight\nYOLOv8-S model demonstrating exceptional object detection performance with\nminimal computational overhead. The research highlights the potential of modern\ndeep learning architectures to address critical agricultural challenges,\nemphasizing the importance of model complexity versus practical utility. Future\nwork will explore expanding datasets, model compression techniques, and\nfederated learning to enhance the applicability of these systems in diverse\nagricultural contexts, ultimately contributing to more sustainable farming\npractices.",
      "tldr_zh": "本文提出了一种轻量级计算机视觉管道，用于在资源有限的环境中帮助农民检测橙子疾病，该系统整合了先进的物体检测、分类和分割模型，并优化了部署在边缘设备上的性能。研究评估了多种最先进模型的表现，结果显示Vision Transformer在橙子物种分类中达到96%的准确率，而YOLOv8-S模型在物体检测方面表现出色，同时保持了最低的计算开销。总体上，该工作突出了现代深度学习架构在解决农业挑战中的潜力，并计划通过扩展数据集、模型压缩和联邦学习来提升其在可持续农业中的实际应用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.18635v1",
      "published_date": "2024-12-23 06:48:50 UTC",
      "updated_date": "2024-12-23 06:48:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:02:22.419111"
    },
    {
      "arxiv_id": "2412.17330v1",
      "title": "EcoSearch: A Constant-Delay Best-First Search Algorithm for Program Synthesis",
      "title_zh": "EcoSearch：一种用于程序合成的常量延迟最佳优先搜索算法",
      "authors": [
        "Théo Matricon",
        "Nathanaël Fijalkow",
        "Guillaume Lagarde"
      ],
      "abstract": "Many approaches to program synthesis perform a combinatorial search within a\nlarge space of programs to find one that satisfies a given specification. To\ntame the search space blowup, previous works introduced probabilistic and\nneural approaches to guide this combinatorial search by inducing heuristic cost\nfunctions. Best-first search algorithms ensure to search in the exact order\ninduced by the cost function, significantly reducing the portion of the program\nspace to be explored. We present a new best-first search algorithm called\nEcoSearch, which is the first constant-delay algorithm for pre-generation cost\nfunction: the amount of compute required between outputting two programs is\nconstant, and in particular does not increase over time. This key property\nyields important speedups: we observe that EcoSearch outperforms its\npredecessors on two classic domains.",
      "tldr_zh": "本文提出了一种名为 EcoSearch 的新算法，用于程序合成（Program Synthesis），它是第一个针对预生成成本函数（pre-generation cost function）的恒定延迟 Best-First Search 算法。该算法确保在输出两个程序之间所需的计算量保持不变，从而显著减少搜索空间并提高效率。与先前方法相比，EcoSearch 在两个经典领域表现出色，实现了重要加速。总体上，这为引导组合搜索提供了更有效的框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.LG",
      "comment": "Extended version of AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.17330v1",
      "published_date": "2024-12-23 06:48:47 UTC",
      "updated_date": "2024-12-23 06:48:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:00:33.143972"
    },
    {
      "arxiv_id": "2412.17323v3",
      "title": "xPatch: Dual-Stream Time Series Forecasting with Exponential Seasonal-Trend Decomposition",
      "title_zh": "xPatch：指数季节趋势分解的双流时间序列预测",
      "authors": [
        "Artyom Stitsyuk",
        "Jaesik Choi"
      ],
      "abstract": "In recent years, the application of transformer-based models in time-series\nforecasting has received significant attention. While often demonstrating\npromising results, the transformer architecture encounters challenges in fully\nexploiting the temporal relations within time series data due to its attention\nmechanism. In this work, we design eXponential Patch (xPatch for short), a\nnovel dual-stream architecture that utilizes exponential decomposition.\nInspired by the classical exponential smoothing approaches, xPatch introduces\nthe innovative seasonal-trend exponential decomposition module. Additionally,\nwe propose a dual-flow architecture that consists of an MLP-based linear stream\nand a CNN-based non-linear stream. This model investigates the benefits of\nemploying patching and channel-independence techniques within a non-transformer\nmodel. Finally, we develop a robust arctangent loss function and a sigmoid\nlearning rate adjustment scheme, which prevent overfitting and boost\nforecasting performance. The code is available at the following repository:\nhttps://github.com/stitsyuk/xPatch.",
      "tldr_zh": "本研究针对Transformer模型在时间序列预测中无法充分利用时间关系的挑战，提出了一种新型架构xPatch，该架构采用指数季节趋势分解模块，并设计了双流结构，包括基于MLP的线性流和基于CNN的非线性流，以探索patching和channel-independence技术的好处。xPatch受到经典指数平滑方法的启发，能够更有效地处理时间序列数据。此外，论文开发了arctangent损失函数和sigmoid学习率调整方案，以防止过拟合并提升预测性能，为时间序列预测提供了更鲁棒的非Transformer替代方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17323v3",
      "published_date": "2024-12-23 06:32:59 UTC",
      "updated_date": "2025-02-11 05:49:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:00:45.384846"
    },
    {
      "arxiv_id": "2412.17321v1",
      "title": "Assessing Human Editing Effort on LLM-Generated Texts via Compression-Based Edit Distance",
      "title_zh": "通过基于压缩的编辑距离评估LLM生成文本上的人类编辑努力",
      "authors": [
        "Nicolas Devatine",
        "Louis Abraham"
      ],
      "abstract": "Assessing the extent of human edits on texts generated by Large Language\nModels (LLMs) is crucial to understanding the human-AI interactions and\nimproving the quality of automated text generation systems. Existing edit\ndistance metrics, such as Levenshtein, BLEU, ROUGE, and TER, often fail to\naccurately measure the effort required for post-editing, especially when edits\ninvolve substantial modifications, such as block operations. In this paper, we\nintroduce a novel compression-based edit distance metric grounded in the\nLempel-Ziv-77 algorithm, designed to quantify the amount of post-editing\napplied to LLM-generated texts. Our method leverages the properties of text\ncompression to measure the informational difference between the original and\nedited texts. Through experiments on real-world human edits datasets, we\ndemonstrate that our proposed metric is highly correlated with actual edit time\nand effort. We also show that LLMs exhibit an implicit understanding of editing\nspeed, that aligns well with our metric. Furthermore, we compare our metric\nwith existing ones, highlighting its advantages in capturing complex edits with\nlinear computational efficiency. Our code and data are available at:\nhttps://github.com/NDV-tiime/CompressionDistance",
      "tldr_zh": "本文提出了一种基于 Lempel-Ziv-77 算法的压缩编辑距离指标，用于评估人类对 Large Language Models (LLMs) 生成文本的编辑努力，以更好地理解人机交互并提升文本生成系统质量。  \n与传统指标如 Levenshtein、BLEU、ROUGE 和 TER 相比，该方法利用文本压缩特性来量化原始文本与编辑文本之间的信息差异，尤其适用于处理大块修改。  \n实验结果显示，该指标与实际编辑时间和努力高度相关，且 LLMs 隐式理解编辑速度，与该指标一致。  \n此外，该指标在捕捉复杂编辑时具有显著优势，同时保持线性计算效率，并提供了开源代码和数据集。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17321v1",
      "published_date": "2024-12-23 06:29:25 UTC",
      "updated_date": "2024-12-23 06:29:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:00:58.480917"
    },
    {
      "arxiv_id": "2412.17883v1",
      "title": "In Defence of Post-hoc Explainability",
      "title_zh": "翻译失败",
      "authors": [
        "Nick Oh"
      ],
      "abstract": "The widespread adoption of machine learning in scientific research has\ncreated a fundamental tension between model opacity and scientific\nunderstanding. Whilst some advocate for intrinsically interpretable models, we\nintroduce Computational Interpretabilism (CI) as a philosophical framework for\npost-hoc interpretability in scientific AI. Drawing parallels with human\nexpertise, where post-hoc rationalisation coexists with reliable performance,\nCI establishes that scientific knowledge emerges through structured model\ninterpretation when properly bounded by empirical validation. Through mediated\nunderstanding and bounded factivity, we demonstrate how post-hoc methods\nachieve epistemically justified insights without requiring complete mechanical\ntransparency, resolving tensions between model complexity and scientific\ncomprehension.",
      "tldr_zh": "该论文探讨了机器学习在科学研究中的应用所引发的模型不透明与科学理解之间的冲突，主张支持后验解释性（post-hoc explainability）。作者引入了 Computational Interpretabilism (CI) 作为一种哲学框架，借鉴人类专家的后验合理化，强调科学知识可以通过结构化的模型解释产生，前提是受到经验验证的约束。通过中介理解（mediated understanding）和有限事实性（bounded factivity），CI 证明后验方法能提供 epistemically justified insights，而无需模型完全机械透明，从而化解了模型复杂性与科学理解的张力。总的来说，该框架为科学 AI 中的解释性提供了新的哲学基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Presented at the Interpretable AI: Past, Present, and Future Workshop\n  at NeurIPS 2024 (non-archival)",
      "pdf_url": "http://arxiv.org/pdf/2412.17883v1",
      "published_date": "2024-12-23 06:22:03 UTC",
      "updated_date": "2024-12-23 06:22:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:03:02.786649"
    },
    {
      "arxiv_id": "2412.17316v2",
      "title": "Fast Gradient Computation for RoPE Attention in Almost Linear Time",
      "title_zh": "RoPE 注意力机制的快速",
      "authors": [
        "Yifang Chen",
        "Jiayan Huo",
        "Xiaoyu Li",
        "Yingyu Liang",
        "Zhenmei Shi",
        "Zhao Song"
      ],
      "abstract": "The Rotary Position Embedding (RoPE) mechanism has become a powerful\nenhancement to the Transformer architecture, which enables models to capture\ntoken relationships when encoding positional information. However, the RoPE\nmechanisms make the computations of attention mechanisms more complicated,\nwhich makes efficient algorithms challenging. Earlier research introduced\nalmost linear time, i.e., $n^{1+o(1)}$ where $n$ is the number of input tokens,\nalgorithms for the forward computation under specific parameter settings.\nHowever, achieving a subquadratic time algorithm for other parameter regimes\nremains impossible unless the widely accepted Strong Exponential Time\nHypothesis (SETH) is disproven. In this work, we develop the first almost\nlinear time algorithm for backward computations in the RoPE-based attention\nunder bounded entries. Our approach builds on recent advancements in fast RoPE\nattention computations, utilizing a novel combination of the polynomial method\nand the Fast Fourier Transform. Furthermore, we show that with lower bounds\nderived from the SETH, the bounded entry condition is necessary for\nsubquadratic performance.",
      "tldr_zh": "该论文探讨了在 Rotary Position Embedding (RoPE) 注意力机制下，实现几乎线性时间（n^{1+o(1)}）的梯度计算问题，以应对 Transformer 架构中位置编码计算的复杂性。现有研究仅在前向计算特定参数下实现了类似效率，但后向计算在其他设置下受 Strong Exponential Time Hypothesis (SETH) 限制，无法达到亚二次时间。本文首次提出了一种基于多项式方法和 Fast Fourier Transform (FFT) 的算法，在条目有界条件下，实现 RoPE 注意力机制的后向计算几乎线性时间性能。实验和理论分析证明，该有界条目条件是实现亚二次性能的必要条件，为高效 Transformer 模型优化提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CC",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17316v2",
      "published_date": "2024-12-23 06:20:22 UTC",
      "updated_date": "2024-12-31 06:53:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:03:14.158731"
    },
    {
      "arxiv_id": "2412.17315v1",
      "title": "CodeV: Issue Resolving with Visual Data",
      "title_zh": "CodeV：利用视觉数据进行 Issue 解决",
      "authors": [
        "Linhao Zhang",
        "Daoguang Zan",
        "Quanshun Yang",
        "Zhirong Huang",
        "Dong Chen",
        "Bo Shen",
        "Tianyu Liu",
        "Yongshun Gong",
        "Pengjie Huang",
        "Xudong Lu",
        "Guangtai Liang",
        "Lizhen Cui",
        "Qianxiang Wang"
      ],
      "abstract": "Large Language Models (LLMs) have advanced rapidly in recent years, with\ntheir applications in software engineering expanding to more complex\nrepository-level tasks. GitHub issue resolving is a key challenge among these\ntasks. While recent approaches have made progress on this task, they focus on\ntextual data within issues, neglecting visual data. However, this visual data\nis crucial for resolving issues as it conveys additional knowledge that text\nalone cannot. We propose CodeV, the first approach to leveraging visual data to\nenhance the issue-resolving capabilities of LLMs. CodeV resolves each issue by\nfollowing a two-phase process: data processing and patch generation. To\nevaluate CodeV, we construct a benchmark for visual issue resolving, namely\nVisual SWE-bench. Through extensive experiments, we demonstrate the\neffectiveness of CodeV, as well as provide valuable insights into leveraging\nvisual data to resolve GitHub issues.",
      "tldr_zh": "本研究指出，现有的Large Language Models (LLMs)在处理GitHub issue resolving时忽略了视觉数据，而视觉数据能提供文本无法传达的额外知识。论文提出CodeV，这是一个首创的方法，通过两阶段过程（数据处理和patch生成）来利用视觉数据增强LLMs的issue-resolving能力。为评估CodeV，研究者构建了Visual SWE-bench基准，并通过广泛实验证明了其有效性，同时提供了关于整合视觉数据的宝贵见解。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "https://github.com/luolin101/CodeV",
      "pdf_url": "http://arxiv.org/pdf/2412.17315v1",
      "published_date": "2024-12-23 06:17:11 UTC",
      "updated_date": "2024-12-23 06:17:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:03:25.945281"
    },
    {
      "arxiv_id": "2412.17310v1",
      "title": "Popularity Estimation and New Bundle Generation using Content and Context based Embeddings",
      "title_zh": "翻译失败",
      "authors": [
        "Ashutosh Nayak",
        "Prajwal NJ",
        "Sameeksha Keshav",
        "Kavitha S. N.",
        "Roja Reddy",
        "Rajasekhara Reddy Duvvuru Muni"
      ],
      "abstract": "Recommender systems create enormous value for businesses and their consumers.\nThey increase revenue for businesses while improving the consumer experience by\nrecommending relevant products amidst huge product base. Product bundling is an\nexciting development in the field of product recommendations. It aims at\ngenerating new bundles and recommending exciting and relevant bundles to their\nconsumers. Unlike traditional recommender systems that recommend single items\nto consumers, product bundling aims at targeting a bundle, or a set of items,\nto the consumers. While bundle recommendation has attracted significant\nresearch interest recently, extant literature on bundle generation is scarce.\nMoreover, metrics to identify if a bundle is popular or not is not well\nstudied. In this work, we aim to fulfill this gap by introducing new bundle\npopularity metrics based on sales, consumer experience and item diversity in a\nbundle. We use these metrics in the methodology proposed in this paper to\ngenerate new bundles for mobile games using content aware and context aware\nembeddings. We use opensource Steam Games dataset for our analysis. Our\nexperiments indicate that we can generate new bundles that can outperform the\nexisting bundles on the popularity metrics by 32% - 44%. Our experiments are\ncomputationally efficient and the proposed methodology is generic that can be\nextended to other bundling problems e.g. product bundling, music bundling.",
      "tldr_zh": "本文针对推荐系统中的产品捆绑问题，引入了基于销售、消费者体验和物品多样性的新流行度指标，以填补现有研究的空白。研究提出了一种利用 content aware and context aware embeddings 的方法，生成新捆绑包，并使用开源 Steam Games 数据集进行实验。结果显示，新生成的捆绑包在流行度指标上比现有捆绑包提升32%-44%，且该方法计算高效，可泛化应用于其他领域如产品捆绑或音乐捆绑。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17310v1",
      "published_date": "2024-12-23 06:04:14 UTC",
      "updated_date": "2024-12-23 06:04:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:03:38.883704"
    },
    {
      "arxiv_id": "2412.17304v2",
      "title": "On the Feasibility of Vision-Language Models for Time-Series Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Vinay Prithyani",
        "Mohsin Mohammed",
        "Richa Gadgil",
        "Ricardo Buitrago",
        "Vinija Jain",
        "Aman Chadha"
      ],
      "abstract": "We build upon time-series classification by leveraging the capabilities of\nVision Language Models (VLMs). We find that VLMs produce competitive results\nafter two or less epochs of fine-tuning. We develop a novel approach that\nincorporates graphical data representations as images in conjunction with\nnumerical data. This approach is rooted in the hypothesis that graphical\nrepresentations can provide additional contextual information that numerical\ndata alone may not capture. Additionally, providing a graphical representation\ncan circumvent issues such as limited context length faced by LLMs. To further\nadvance this work, we implemented a scalable end-to-end pipeline for training\non different scenarios, allowing us to isolate the most effective strategies\nfor transferring learning capabilities from LLMs to Time Series Classification\n(TSC) tasks. Our approach works with univariate and multivariate time-series\ndata. In addition, we conduct extensive and practical experiments to show how\nthis approach works for time-series classification and generative labels.",
      "tldr_zh": "本文探讨了 Vision Language Models (VLMs) 在时间序列分类 (TSC) 任务中的可行性，发现 VLMs 经过少于两个 epoch 的微调即可获得竞争性结果。研究提出了一种新方法，将图形数据表示为图像与数字数据结合，利用图形表示提供额外上下文信息，并避免 LLMs 的上下文长度限制问题。该方法通过一个可扩展的端到端训练管道，适用于单变量和多变量时间序列数据，并通过广泛实验证明了其在分类和生成标签方面的有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17304v2",
      "published_date": "2024-12-23 05:52:17 UTC",
      "updated_date": "2025-01-17 23:02:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:03:50.755647"
    },
    {
      "arxiv_id": "2412.17301v1",
      "title": "Dynamic Scheduling Strategies for Resource Optimization in Computing Environments",
      "title_zh": "计算环境中的资源优化动态调度策略",
      "authors": [
        "Xiaoye Wang"
      ],
      "abstract": "The rapid development of cloud-native architecture has promoted the\nwidespread application of container technology, but the optimization problems\nin container scheduling and resource management still face many challenges.\nThis paper proposes a container scheduling method based on multi-objective\noptimization, which aims to balance key performance indicators such as resource\nutilization, load balancing and task completion efficiency. By introducing\noptimization models and heuristic algorithms, the scheduling strategy is\ncomprehensively improved, and experimental verification is carried out using\nthe real Google Cluster Data dataset. The experimental results show that\ncompared with traditional static rule algorithms and heuristic algorithms, the\noptimized scheduling scheme shows significant advantages in resource\nutilization, load balancing and burst task completion efficiency. This shows\nthat the proposed method can effectively improve resource management efficiency\nand ensure service quality and system stability in complex dynamic cloud\nenvironments. At the same time, this paper also explores the future development\ndirection of scheduling algorithms in multi-tenant environments, heterogeneous\ncloud computing, and cross-edge and cloud collaborative computing scenarios,\nand proposes research prospects for energy consumption optimization, adaptive\nscheduling and fairness. The research results not only provide a theoretical\nbasis and practical reference for container scheduling under cloud-native\narchitecture, but also lay a foundation for further realizing intelligent and\nefficient resource management.",
      "tldr_zh": "本论文提出了一种基于 multi-objective optimization 的容器调度方法，旨在平衡资源利用率、负载均衡和任务完成效率，以应对云原生架构中资源管理面临的挑战。通过引入优化模型和 heuristic algorithms，该方法对调度策略进行全面改进，并使用 Google Cluster Data 数据集进行实验验证。实验结果显示，与传统静态规则算法和启发式算法相比，该方案在资源利用率、负载均衡和突发任务完成效率方面提高了显著优势。该研究为云原生环境下的容器调度提供了理论基础和实践参考，并探讨了未来在多租户环境、异构云计算和跨边缘云协作场景中的发展方向，如能耗优化和适应性调度。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17301v1",
      "published_date": "2024-12-23 05:43:17 UTC",
      "updated_date": "2024-12-23 05:43:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:04:04.150992"
    },
    {
      "arxiv_id": "2412.17292v1",
      "title": "AV-EmoDialog: Chat with Audio-Visual Users Leveraging Emotional Cues",
      "title_zh": "翻译失败",
      "authors": [
        "Se Jin Park",
        "Yeonju Kim",
        "Hyeongseop Rha",
        "Bella Godiva",
        "Yong Man Ro"
      ],
      "abstract": "In human communication, both verbal and non-verbal cues play a crucial role\nin conveying emotions, intentions, and meaning beyond words alone. These\nnon-linguistic information, such as facial expressions, eye contact, voice\ntone, and pitch, are fundamental elements of effective interactions, enriching\nconversations by adding emotional and contextual depth. Recognizing the\nimportance of non-linguistic content in communication, we present AV-EmoDialog,\na dialogue system designed to exploit verbal and non-verbal information from\nusers' audio-visual inputs to generate more responsive and empathetic\ninteractions. AV-EmoDialog systematically exploits the emotional cues in\naudio-visual dialogues; extracting speech content and emotional tones from\nspeech, analyzing fine-grained facial expressions from visuals, and integrating\nthese cues to generate emotionally aware responses in an end-to-end manner.\nThrough extensive experiments, we validate that the proposed AV-EmoDialog\noutperforms existing multimodal LLMs in generating not only emotionally\nappropriate but also contextually appropriate responses.",
      "tldr_zh": "该研究提出 AV-EmoDialog 系统，利用用户音频-视觉输入中的语言和非语言线索（如面部表情、语音语气）来生成更具响应性和同理心的对话响应。系统通过从语音中提取内容及情感语气、从视觉中分析细粒度面部表情，并端到端整合这些情感线索，实现情感感知的对话生成。实验结果表明，AV-EmoDialog 在情感适当性和上下文相关性上优于现有多模态 LLMs，为更自然的人机互动提供了新方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17292v1",
      "published_date": "2024-12-23 05:24:26 UTC",
      "updated_date": "2024-12-23 05:24:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:04:14.634568"
    },
    {
      "arxiv_id": "2412.17288v1",
      "title": "Multi-Modal Grounded Planning and Efficient Replanning For Learning Embodied Agents with A Few Examples",
      "title_zh": "翻译失败",
      "authors": [
        "Taewoong Kim",
        "Byeonghwi Kim",
        "Jonghyun Choi"
      ],
      "abstract": "Learning a perception and reasoning module for robotic assistants to plan\nsteps to perform complex tasks based on natural language instructions often\nrequires large free-form language annotations, especially for short high-level\ninstructions. To reduce the cost of annotation, large language models (LLMs)\nare used as a planner with few data. However, when elaborating the steps, even\nthe state-of-the-art planner that uses LLMs mostly relies on linguistic common\nsense, often neglecting the status of the environment at command reception,\nresulting in inappropriate plans. To generate plans grounded in the\nenvironment, we propose FLARE (Few-shot Language with environmental Adaptive\nReplanning Embodied agent), which improves task planning using both language\ncommand and environmental perception. As language instructions often contain\nambiguities or incorrect expressions, we additionally propose to correct the\nmistakes using visual cues from the agent. The proposed scheme allows us to use\na few language pairs thanks to the visual cues and outperforms state-of-the-art\napproaches. Our code is available at https://github.com/snumprlab/flare.",
      "tldr_zh": "这篇论文提出 FLARE（Few-shot Language with environmental Adaptive Replanning Embodied agent）框架，用于少样本学习中的机器人代理，通过多模态基础规划和高效重规划，结合语言命令和环境感知来生成更准确的任务计划。FLARE 利用视觉线索纠正语言指令中的歧义或错误，从而减少对大量语言注释的需求。实验结果表明，该方法优于现有技术，在机器人任务执行中显著提升了性能，并提供了开源代码以供进一步研究。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "AAAI 2025 (Project page: https://twoongg.github.io/projects/flare/)",
      "pdf_url": "http://arxiv.org/pdf/2412.17288v1",
      "published_date": "2024-12-23 05:20:01 UTC",
      "updated_date": "2024-12-23 05:20:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:04:26.500097"
    },
    {
      "arxiv_id": "2412.17287v1",
      "title": "LLM4AD: A Platform for Algorithm Design with Large Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Fei Liu",
        "Rui Zhang",
        "Zhuoliang Xie",
        "Rui Sun",
        "Kai Li",
        "Xi Lin",
        "Zhenkun Wang",
        "Zhichao Lu",
        "Qingfu Zhang"
      ],
      "abstract": "We introduce LLM4AD, a unified Python platform for algorithm design (AD) with\nlarge language models (LLMs). LLM4AD is a generic framework with modularized\nblocks for search methods, algorithm design tasks, and LLM interface. The\nplatform integrates numerous key methods and supports a wide range of algorithm\ndesign tasks across various domains including optimization, machine learning,\nand scientific discovery. We have also designed a unified evaluation sandbox to\nensure a secure and robust assessment of algorithms. Additionally, we have\ncompiled a comprehensive suite of support resources, including tutorials,\nexamples, a user manual, online resources, and a dedicated graphical user\ninterface (GUI) to enhance the usage of LLM4AD. We believe this platform will\nserve as a valuable tool for fostering future development in the merging\nresearch direction of LLM-assisted algorithm design.",
      "tldr_zh": "本研究引入了 LLM4AD，这是一个统一的 Python 平台，用于借助大型语言模型 (LLMs) 进行算法设计 (AD)。平台采用模块化的块设计，支持多种搜索方法、算法设计任务以及 LLM 接口，涵盖优化、机器学习和科学发现等领域的任务。LLM4AD 还集成了一个安全的统一评估沙箱，以及丰富的支持资源如教程、示例、手册、在线资源和图形用户界面 (GUI)。该平台有望成为促进 LLM 辅助算法设计研究的宝贵工具。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17287v1",
      "published_date": "2024-12-23 05:12:54 UTC",
      "updated_date": "2024-12-23 05:12:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:04:38.464000"
    },
    {
      "arxiv_id": "2412.17285v1",
      "title": "Enabling Time-series Foundation Model for Building Energy Forecasting via Contrastive Curriculum Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Rui Liang",
        "Yang Deng",
        "Donghua Xie",
        "Fang He",
        "Dan Wang"
      ],
      "abstract": "Advances in time-series forecasting are driving a shift from conventional\nmachine learning models to foundation models (FMs) that are trained with\ngeneralized knowledge. However, existing FMs still perform poorly in the energy\nfields, such as building energy forecasting (BEF). This paper studies the\nadaptation of FM to BEF tasks. We demonstrate the shortcomings of fine-tuning\nFM straightforwardly from both the perspectives of FM and the data. To overcome\nthese limitations, we propose a new \\textit{contrastive curriculum\nlearning}-based training method. Our method optimizes the ordering of training\ndata in the context of TSFM adaptation. Experiments show that our method can\nimprove the zero/few-shot performance by 14.6\\% compared to the existing FMs.\nOur code and new TSFM will be available at <Anonymous Github Repo>.",
      "tldr_zh": "该论文探讨了如何将时间序列基础模型(FMs)适应到建筑能源预测(BEF)任务中，指出现有FMs在能源领域表现不佳，主要由于直接微调的局限性。作者提出了一种基于对比课程学习(contrastive curriculum learning)的训练方法，通过优化训练数据的顺序来提升TSFM的适应性。实验结果显示，该方法将零/少样本性能提高了14.6%，为时间序列预测在能源领域的应用提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17285v1",
      "published_date": "2024-12-23 05:07:06 UTC",
      "updated_date": "2024-12-23 05:07:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:04:52.060828"
    },
    {
      "arxiv_id": "2412.17265v1",
      "title": "Evaluating the Design Features of an Intelligent Tutoring System for Advanced Mathematics Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Ying Fang",
        "Bo He",
        "Zhi Liu",
        "Sannyuya Liu",
        "Zhonghua Yan",
        "Jianwen Sun"
      ],
      "abstract": "Xiaomai is an intelligent tutoring system (ITS) designed to help Chinese\ncollege students in learning advanced mathematics and preparing for the\ngraduate school math entrance exam. This study investigates two distinctive\nfeatures within Xiaomai: the incorporation of free-response questions with\nautomatic feedback and the metacognitive element of reflecting on self-made\nerrors.",
      "tldr_zh": "本研究评估了Xiaomai智能辅导系统（ITS）的设计特征，该系统旨在帮助中国大学生学习高级数学并准备研究生入学考试。研究重点调查了两个独特元素：自由回答问题（free-response questions）结合自动反馈，以及反思自我错误的元认知元素（metacognitive element）。通过这些特征，Xiaomai提升了学生的学习体验和自我改进能力，为高级数学教育提供了一个有效的工具。",
      "categories": [
        "cs.MS",
        "cs.AI",
        "cs.CY",
        "math.HO"
      ],
      "primary_category": "cs.MS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17265v1",
      "published_date": "2024-12-23 04:22:05 UTC",
      "updated_date": "2024-12-23 04:22:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:05:04.121788"
    },
    {
      "arxiv_id": "2412.17256v2",
      "title": "B-STaR: Monitoring and Balancing Exploration and Exploitation in Self-Taught Reasoners",
      "title_zh": "翻译失败",
      "authors": [
        "Weihao Zeng",
        "Yuzhen Huang",
        "Lulu Zhao",
        "Yijun Wang",
        "Zifei Shan",
        "Junxian He"
      ],
      "abstract": "In the absence of extensive human-annotated data for complex reasoning tasks,\nself-improvement -- where models are trained on their own outputs -- has\nemerged as a primary method for enhancing performance. However, the critical\nfactors underlying the mechanism of these iterative self-improving methods\nremain poorly understood, such as under what conditions self-improvement is\neffective, and what are the bottlenecks in the current iterations. In this\nwork, we identify and propose methods to monitor two pivotal factors in this\niterative process: (1) the model's ability to generate sufficiently diverse\nresponses (exploration); and (2) the effectiveness of external rewards in\ndistinguishing high-quality candidates from lower-quality ones (exploitation).\nUsing mathematical reasoning as a case study, we begin with a quantitative\nanalysis to track the dynamics of exploration and exploitation, discovering\nthat a model's exploratory capabilities rapidly deteriorate over iterations,\nand the effectiveness of exploiting external rewards diminishes as well.\nMotivated by these findings, we introduce B-STaR, a Self-Taught Reasoning\nframework that autonomously adjusts configurations across iterations to Balance\nexploration and exploitation, thereby optimizing the self-improving\neffectiveness based on the current policy model and available rewards. Our\nexperiments on mathematical reasoning, coding, and commonsense reasoning\ndemonstrate that B-STaR not only enhances the model's exploratory capabilities\nthroughout training but also achieves a more effective balance between\nexploration and exploitation, leading to superior performance.",
      "tldr_zh": "该研究探讨了在缺乏人类标注数据的情况下，自提升(self-improvement)方法的局限性，特别关注模型在迭代过程中的探索(exploration)和利用(exploitation)动态。通过量化分析发现，exploration能力快速下降，而exploitation的有效性也随之减弱。论文引入B-STaR框架，这是一种Self-Taught Reasoning系统，能自主调整配置以平衡exploration和exploitation，从而优化训练效果。实验在数学推理、编码和常识推理任务上显示，B-STaR显著提升了模型性能和exploration能力。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Published as a conference paper at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.17256v2",
      "published_date": "2024-12-23 03:58:34 UTC",
      "updated_date": "2025-03-04 06:29:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:05:14.960568"
    },
    {
      "arxiv_id": "2412.17255v1",
      "title": "Unlocking Cross-Lingual Sentiment Analysis through Emoji Interpretation: A Multimodal Generative AI Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Rafid Ishrak Jahan",
        "Heng Fan",
        "Haihua Chen",
        "Yunhe Feng"
      ],
      "abstract": "Emojis have become ubiquitous in online communication, serving as a universal\nmedium to convey emotions and decorative elements. Their widespread use\ntranscends language and cultural barriers, enhancing understanding and\nfostering more inclusive interactions. While existing work gained valuable\ninsight into emojis understanding, exploring emojis' capability to serve as a\nuniversal sentiment indicator leveraging large language models (LLMs) has not\nbeen thoroughly examined. Our study aims to investigate the capacity of emojis\nto serve as reliable sentiment markers through LLMs across languages and\ncultures. We leveraged the multimodal capabilities of ChatGPT to explore the\nsentiments of various representations of emojis and evaluated how well\nemoji-conveyed sentiment aligned with text sentiment on a multi-lingual dataset\ncollected from 32 countries. Our analysis reveals that the accuracy of\nLLM-based emoji-conveyed sentiment is 81.43%, underscoring emojis' significant\npotential to serve as a universal sentiment marker. We also found a consistent\ntrend that the accuracy of sentiment conveyed by emojis increased as the number\nof emojis grew in text. The results reinforce the potential of emojis to serve\nas global sentiment indicators, offering insight into fields such as\ncross-lingual and cross-cultural sentiment analysis on social media platforms.\nCode: https://github.com/ResponsibleAILab/emoji-universal-sentiment.",
      "tldr_zh": "本文提出了一种多模态生成 AI 方法，通过 emojis 的解释来实现跨语言情感分析（Cross-Lingual Sentiment Analysis）。研究利用 LLMs 如 ChatGPT 评估 emojis 作为情感标记的可靠性，在从 32 个国家收集的多语言数据集上进行测试，结果显示 emojis 传达的情感准确率达到 81.43%。此外，研究发现文本中 emojis 数量越多，情感准确率越高，这强化了 emojis 作为全球情感指标的潜力，并为社交媒体的跨文化情感分析提供了新见解。Code: https://github.com/ResponsibleAILab/emoji-universal-sentiment。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17255v1",
      "published_date": "2024-12-23 03:57:45 UTC",
      "updated_date": "2024-12-23 03:57:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:05:27.575840"
    },
    {
      "arxiv_id": "2412.17254v1",
      "title": "Enhancing Multi-Text Long Video Generation Consistency without Tuning: Time-Frequency Analysis, Prompt Alignment, and Theory",
      "title_zh": "翻译失败",
      "authors": [
        "Xingyao Li",
        "Fengzhuo Zhang",
        "Jiachun Pan",
        "Yunlong Hou",
        "Vincent Y. F. Tan",
        "Zhuoran Yang"
      ],
      "abstract": "Despite the considerable progress achieved in the long video generation\nproblem, there is still significant room to improve the consistency of the\nvideos, particularly in terms of smoothness and transitions between scenes. We\naddress these issues to enhance the consistency and coherence of videos\ngenerated with either single or multiple prompts. We propose the Time-frequency\nbased temporal Attention Reweighting Algorithm (TiARA), which meticulously\nedits the attention score matrix based on the Discrete Short-Time Fourier\nTransform. Our method is supported by a theoretical guarantee, the\nfirst-of-its-kind for frequency-based methods in diffusion models. For videos\ngenerated by multiple prompts, we further investigate key factors affecting\nprompt interpolation quality and propose PromptBlend, an advanced prompt\ninterpolation pipeline. The efficacy of our proposed method is validated via\nextensive experimental results, exhibiting consistent and impressive\nimprovements over baseline methods. The code will be released upon acceptance.",
      "tldr_zh": "这篇论文针对长视频生成中的一致性问题（如平滑性和场景过渡），提出不需微调的方法来提升单提示或多提示视频的连贯性。核心贡献包括 TiARA（Time-frequency based temporal Attention Reweighting Algorithm），它利用 Discrete Short-Time Fourier Transform 编辑注意力分数矩阵，并首次为频率-based 方法在扩散模型中提供理论保证。对于多提示视频，作者开发了 PromptBlend 管道，通过优化提示插值来改善生成质量。实验结果显示，该方法在各种基准上比基线方法表现出显著改进，验证了其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "34 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.17254v1",
      "published_date": "2024-12-23 03:56:27 UTC",
      "updated_date": "2024-12-23 03:56:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:05:39.599577"
    },
    {
      "arxiv_id": "2501.00032v1",
      "title": "Highly Optimized Kernels and Fine-Grained Codebooks for LLM Inference on Arm CPUs",
      "title_zh": "翻译失败",
      "authors": [
        "Dibakar Gope",
        "David Mansell",
        "Danny Loh",
        "Ian Bratt"
      ],
      "abstract": "Large language models (LLMs) have transformed the way we think about language\nunderstanding and generation, enthralling both researchers and developers.\nHowever, deploying LLMs for inference has been a significant challenge due to\ntheir unprecedented size and resource requirements. While quantizing model\nweights to sub-byte precision has emerged as a promising solution to ease\nmemory pressure, the group quantization formats commonly used for LLM\nquantization have significant compute overheads and a resource-intensive\ndequantization process. As a result, a higher proportion of compute\ninstructions do not perform multiplies, i.e., real work, rendering them\nunsuitable for meeting the required latency requirements for LLMs deployed on\ncommodity CPUs. In this work, we propose a set of highly optimized kernels to\naccelerate LLM inference and unleash the full potential of CPUs, particularly\nArm CPUs. These kernels amortize the cost of loading the operands and the cost\nof weight unpacking across multiple output rows. This, along with the\nintroduction of an optimized interleaved group data layout for weights and\ndecompression path optimizations to reduce unnecessary operations and\ndequantization overhead while maximizing the use of vector and matrix multiply\noperations, significantly improves the efficiency of MAC operations.\nFurthermore, we present a groupwise non-uniform codebook-based quantization\nmethod for ultra-low-precision quantization of LLMs to better match non-uniform\npatterns in their weight distributions, demonstrating better throughput during\ntoken generation while ensuring better quality than the state-of-the-art.\nApplying these improvements to 4-bit LLMs results in a 3-3.2x improvement in\nprompt processing and a 2x improvement in autoregressive decoding on Arm CPUs,\ncompared to LLaMA.cpp-based solution. The optimized kernels are available at\nhttps://github.com/ggerganov/llama.cpp.",
      "tldr_zh": "该论文针对大型语言模型(LLMs)在Arm CPUs上的推理挑战，提出一组高度优化的kernels，以摊销操作数加载和权重解包成本，并引入优化交错组数据布局和解压缩路径，显著提升MAC操作效率。同时，论文引入了一种组wise非均匀codebook-based量化方法，用于超低精度量化，以更好地匹配权重分布的非均匀模式，确保质量和吞吐量。实验结果显示，对4-bit LLMs，该优化在Arm CPUs上实现提示处理速度提高3-3.2倍，autoregressive解码提高2倍，优于LLaMA.cpp解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00032v1",
      "published_date": "2024-12-23 03:44:29 UTC",
      "updated_date": "2024-12-23 03:44:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:05:52.391564"
    },
    {
      "arxiv_id": "2412.17243v1",
      "title": "\"From Unseen Needs to Classroom Solutions\": Exploring AI Literacy Challenges & Opportunities with Project-based Learning Toolkit in K-12 Education",
      "title_zh": "翻译失败",
      "authors": [
        "Hanqi Li",
        "Ruiwei Xiao",
        "Hsuan Nieu",
        "Ying-Jui Tseng",
        "Guanze Liao"
      ],
      "abstract": "As artificial intelligence (AI) becomes increasingly central to various\nfields, there is a growing need to equip K-12 students with AI literacy skills\nthat extend beyond computer science. This paper explores the integration of a\nProject-Based Learning (PBL) AI toolkit into diverse subject areas, aimed at\nhelping educators teach AI concepts more effectively. Through interviews and\nco-design sessions with K-12 teachers, we examined current AI literacy levels\nand how teachers adapt AI tools like the AI Art Lab, AI Music Studio, and AI\nChatbot into their course designs. While teachers appreciated the potential of\nAI tools to foster creativity and critical thinking, they also expressed\nconcerns about the accuracy, trustworthiness, and ethical implications of\nAI-generated content. Our findings reveal the challenges teachers face,\nincluding limited resources, varying student and instructor skill levels, and\nthe need for scalable, adaptable AI tools. This research contributes insights\nthat can inform the development of AI curricula tailored to diverse educational\ncontexts.",
      "tldr_zh": "这篇论文探讨了在 K-12 教育中，使用 Project-Based Learning (PBL) AI 工具（如 AI Art Lab、AI Music Studio 和 AI Chatbot）来提升 AI Literacy 的挑战与机会，通过教师访谈和共同设计会议进行研究。研究发现，教师认可这些工具能促进学生的创造力和批判性思考，但也担忧 AI 生成内容的准确性、trustworthiness 和伦理问题。论文揭示了资源有限、学生和教师技能水平不一等挑战，并为开发可扩展、适应不同教育环境的 AI 课程提供宝贵见解。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to AAAI2025",
      "pdf_url": "http://arxiv.org/pdf/2412.17243v1",
      "published_date": "2024-12-23 03:31:02 UTC",
      "updated_date": "2024-12-23 03:31:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:06:03.829175"
    },
    {
      "arxiv_id": "2412.17242v3",
      "title": "On the Generalization and Adaptation Ability of Machine-Generated Text Detectors in Academic Writing",
      "title_zh": "翻译失败",
      "authors": [
        "Yule Liu",
        "Zhiyuan Zhong",
        "Yifan Liao",
        "Zhen Sun",
        "Jingyi Zheng",
        "Jiaheng Wei",
        "Qingyuan Gong",
        "Fenghua Tong",
        "Yang Chen",
        "Yang Zhang",
        "Xinlei He"
      ],
      "abstract": "The rising popularity of large language models (LLMs) has raised concerns\nabout machine-generated text (MGT), particularly in academic settings, where\nissues like plagiarism and misinformation are prevalent. As a result,\ndeveloping a highly generalizable and adaptable MGT detection system has become\nan urgent priority. Given that LLMs are most commonly misused in academic\nwriting, this work investigates the generalization and adaptation capabilities\nof MGT detectors in three key aspects specific to academic writing: First, we\nconstruct MGT-Acedemic, a large-scale dataset comprising over 336M tokens and\n749K samples. MGT-Acedemic focuses on academic writing, featuring human-written\ntexts (HWTs) and MGTs across STEM, Humanities, and Social Sciences, paired with\nan extensible code framework for efficient benchmarking. Second, we benchmark\nthe performance of various detectors for binary classification and attribution\ntasks in both in-domain and cross-domain settings. This benchmark reveals the\noften-overlooked challenges of attribution tasks. Third, we introduce a novel\nattribution task where models have to adapt to new classes over time without\n(or with very limited) access to prior training data in both few-shot and\nmany-shot scenarios. We implement eight different adapting techniques to\nimprove the performance and highlight the inherent complexity of the task. Our\nfindings provide insights into the generalization and adaptation ability of MGT\ndetectors across diverse scenarios and lay the foundation for building robust,\nadaptive detection systems. The code framework is available at\nhttps://github.com/Y-L-LIU/MGTBench-2.0.",
      "tldr_zh": "本研究探讨了机器生成文本（MGT）检测器在学术写作中的泛化与适应能力，针对大型语言模型（LLMs）滥用引发的剽窃和错误信息等问题。研究者构建了大规模数据集 MGT-Academic，包含超过336M tokens和749K样本，涵盖STEM、人文和社会科学领域，并提供可扩展的基准测试框架。论文对各种检测器进行了二元分类和归因任务的性能评估，在域内和跨域设置中揭示了归因任务的挑战。随后，引入了一个新颖的归因任务，测试模型在few-shot和many-shot场景下适应新类别的能力，并通过八种适应技术提升性能。研究结果为开发稳健的MGT检测系统提供了关键洞见和基础。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17242v3",
      "published_date": "2024-12-23 03:30:34 UTC",
      "updated_date": "2025-03-03 03:08:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:06:16.501509"
    },
    {
      "arxiv_id": "2412.17241v2",
      "title": "QTSeg: A Query Token-Based Dual-Mix Attention Framework with Multi-Level Feature Distribution for Medical Image Segmentation",
      "title_zh": "QTSeg：一种基于查询令牌的双混合注意力框架，带有多级特征分布，用于医学图像分割",
      "authors": [
        "Phuong-Nam Tran",
        "Nhat Truong Pham",
        "Duc Ngoc Minh Dang",
        "Eui-Nam Huh",
        "Choong Seon Hong"
      ],
      "abstract": "Medical image segmentation plays a crucial role in assisting healthcare\nprofessionals with accurate diagnoses and enabling automated diagnostic\nprocesses. Traditional convolutional neural networks (CNNs) often struggle with\ncapturing long-range dependencies, while transformer-based architectures,\ndespite their effectiveness, come with increased computational complexity.\nRecent efforts have focused on combining CNNs and transformers to balance\nperformance and efficiency, but existing approaches still face challenges in\nachieving high segmentation accuracy while maintaining low computational costs.\nFurthermore, many methods underutilize the CNN encoder's capability to capture\nlocal spatial information, concentrating primarily on mitigating long-range\ndependency issues. To address these limitations, we propose QTSeg, a novel\narchitecture for medical image segmentation that effectively integrates local\nand global information. QTSeg features a dual-mix attention decoder designed to\nenhance segmentation performance through: (1) a cross-attention mechanism for\nimproved feature alignment, (2) a spatial attention module to capture\nlong-range dependencies, and (3) a channel attention block to learn\ninter-channel relationships. Additionally, we introduce a multi-level feature\ndistribution module, which adaptively balances feature propagation between the\nencoder and decoder, further boosting performance. Extensive experiments on\nfive publicly available datasets covering diverse segmentation tasks, including\nlesion, polyp, breast cancer, cell, and retinal vessel segmentation,\ndemonstrate that QTSeg outperforms state-of-the-art methods across multiple\nevaluation metrics while maintaining lower computational costs. Our\nimplementation can be found at: https://github.com/tpnam0901/QTSeg (v1.0.0)",
      "tldr_zh": "本研究提出QTSeg，一种基于查询标记的双重混合注意力框架，用于医疗图像分割，旨在解决传统CNN捕捉长距离依赖不足以及Transformer计算复杂度高的挑战。QTSeg通过双重混合注意力解码器整合本地和全局信息，包括cross-attention机制用于特征对齐、spatial attention模块捕捉长距离依赖，以及channel attention块学习通道间关系；此外，还引入多级特征分布模块来自适应平衡编码器和解码器之间的特征传播。实验在五个公开数据集上（涵盖病变、多发性、乳腺癌、细胞和视网膜血管分割任务）显示，QTSeg在多个评估指标上优于现有最先进方法，同时保持较低的计算成本。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17241v2",
      "published_date": "2024-12-23 03:22:44 UTC",
      "updated_date": "2025-02-14 04:03:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:06:27.840038"
    },
    {
      "arxiv_id": "2412.17240v1",
      "title": "Rethinking Cancer Gene Identification through Graph Anomaly Analysis",
      "title_zh": "通过图异常分析重新审视癌症基因识别",
      "authors": [
        "Yilong Zang",
        "Lingfei Ren",
        "Yue Li",
        "Zhikang Wang",
        "David Antony Selby",
        "Zheng Wang",
        "Sebastian Josef Vollmer",
        "Hongzhi Yin",
        "Jiangning Song",
        "Junhang Wu"
      ],
      "abstract": "Graph neural networks (GNNs) have shown promise in integrating\nprotein-protein interaction (PPI) networks for identifying cancer genes in\nrecent studies. However, due to the insufficient modeling of the biological\ninformation in PPI networks, more faithfully depiction of complex protein\ninteraction patterns for cancer genes within the graph structure remains\nlargely unexplored. This study takes a pioneering step toward bridging\nbiological anomalies in protein interactions caused by cancer genes to\nstatistical graph anomaly. We find a unique graph anomaly exhibited by cancer\ngenes, namely weight heterogeneity, which manifests as significantly higher\nvariance in edge weights of cancer gene nodes within the graph. Additionally,\nfrom the spectral perspective, we demonstrate that the weight heterogeneity\ncould lead to the \"flattening out\" of spectral energy, with a concentration\ntowards the extremes of the spectrum. Building on these insights, we propose\nthe HIerarchical-Perspective Graph Neural Network (HIPGNN) that not only\ndetermines spectral energy distribution variations on the spectral perspective,\nbut also perceives detailed protein interaction context on the spatial\nperspective. Extensive experiments are conducted on two reprocessed datasets\nSTRINGdb and CPDB, and the experimental results demonstrate the superiority of\nHIPGNN.",
      "tldr_zh": "该研究重新审视了通过图异常分析识别癌症基因的方法，指出现有Graph Neural Networks (GNNs) 在整合Protein-Protein Interaction (PPI) 网络时未能充分建模生物信息。研究发现癌症基因在图结构中表现出独特的weight heterogeneity，即癌症基因节点的边权重方差显著更高，并从谱视角证明这会导致谱能量分布“flattening out”，能量集中在谱的两端。基于这些洞见，提出HIerarchical-Perspective Graph Neural Network (HIPGNN)，该模型同时在谱视角分析能量分布变化和在空间视角感知详细的蛋白互动上下文。在STRINGdb和CPDB数据集上的广泛实验显示，HIPGNN优于基线模型，证明了其有效性。",
      "categories": [
        "cs.CE",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.CE",
      "comment": "It has been accepted by the AAAI 2025 conference",
      "pdf_url": "http://arxiv.org/pdf/2412.17240v1",
      "published_date": "2024-12-23 03:21:24 UTC",
      "updated_date": "2024-12-23 03:21:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:06:39.704911"
    },
    {
      "arxiv_id": "2412.17228v1",
      "title": "MatchMiner-AI: An Open-Source Solution for Cancer Clinical Trial Matching",
      "title_zh": "MatchMiner-AI：癌症临床试验匹配的开源解决方案",
      "authors": [
        "Ethan Cerami",
        "Pavel Trukhanov",
        "Morgan A. Paul",
        "Michael J. Hassett",
        "Irbaz B. Riaz",
        "James Lindsay",
        "Emily Mallaber",
        "Harry Klein",
        "Gufran Gungor",
        "Matthew Galvin",
        "Stephen C. Van Nostrand",
        "Joyce Yu",
        "Tali Mazor",
        "Kenneth L. Kehl"
      ],
      "abstract": "Clinical trials drive improvements in cancer treatments and outcomes.\nHowever, most adults with cancer do not participate in trials, and trials often\nfail to enroll enough patients to answer their scientific questions. Artificial\nintelligence could accelerate matching of patients to appropriate clinical\ntrials. Here, we describe the development and evaluation of the MatchMiner-AI\npipeline for clinical trial searching and ranking. MatchMiner-AI focuses on\nmatching patients to potential trials based on core criteria describing\nclinical \"spaces,\" or disease contexts, targeted by a trial. It aims to\naccelerate the human work of identifying potential matches, not to fully\nautomate trial screening. The pipeline includes modules for extraction of key\ninformation from a patient's longitudinal electronic health record; rapid\nranking of candidate trial-patient matches based on embeddings in vector space;\nand classification of whether a candidate match represents a reasonable\nclinical consideration. Code and synthetic data are available at\nhttps://huggingface.co/ksg-dfci/MatchMiner-AI . Model weights based on\nsynthetic data are available at https://huggingface.co/ksg-dfci/TrialSpace and\nhttps://huggingface.co/ksg-dfci/TrialChecker . A simple cancer clinical trial\nsearch engine to demonstrate pipeline components is available at\nhttps://huggingface.co/spaces/ksg-dfci/trial_search_alpha .",
      "tldr_zh": "这篇论文介绍了 MatchMiner-AI，一种开源 AI 解决方案，旨在加速癌症患者与临床试验的匹配，以解决患者参与率低和试验招募不足的问题。该系统通过从患者纵向 electronic health record 中提取关键信息、基于 vector space embeddings 进行候选匹配快速排名，以及分类模块判断匹配的临床合理性，来辅助人类筛选过程，而非完全自动化。实验评估显示，MatchMiner-AI 有效提升了匹配效率，并提供了代码、合成数据和模型权重（如在 Hugging Face 上），以促进进一步应用和发展。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17228v1",
      "published_date": "2024-12-23 02:44:35 UTC",
      "updated_date": "2024-12-23 02:44:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:06:51.765057"
    },
    {
      "arxiv_id": "2412.17197v1",
      "title": "Q-LIME $π$: A Quantum-Inspired Extension to LIME",
      "title_zh": "翻译失败",
      "authors": [
        "Nelson Colón Vargas"
      ],
      "abstract": "Machine learning models offer powerful predictive capabilities but often lack\ntransparency. Local Interpretable Model-agnostic Explanations (LIME) addresses\nthis by perturbing features and measuring their impact on a model's output. In\ntext-based tasks, LIME typically removes present words (bits set to 1) to\nidentify high-impact tokens. We propose \\textbf{Q-LIME $\\pi$} (Quantum LIME\n$\\pi$), a quantum-inspired extension of LIME that encodes a binary feature\nvector in a quantum state, leveraging superposition and interference to explore\nlocal neighborhoods more efficiently. Our method focuses on flipping bits from\n$1 \\rightarrow 0$ to emulate LIME's ``removal'' strategy, and can be extended\nto $0 \\rightarrow 1$ where adding features is relevant. Experiments on subsets\nof the IMDb dataset demonstrate that Q-LIME $\\pi$ often achieves near-identical\ntop-feature rankings compared to classical LIME while exhibiting lower runtime\nin small- to moderate-dimensional feature spaces. This quantum-classical hybrid\napproach thus provides a new pathway for interpretable AI, suggesting that,\nwith further improvements in quantum hardware and methods, quantum parallelism\nmay facilitate more efficient local explanations for high-dimensional data.",
      "tldr_zh": "本研究提出 Q-LIME π，一种受量子启发的扩展，针对传统 Local Interpretable Model-agnostic Explanations (LIME) 在解释机器学习模型时存在的效率问题。Q-LIME π 通过将二进制特征向量编码到量子状态，利用 superposition 和 interference 来更高效地探索局部邻域，焦点是翻转位从 1 到 0 以模拟特征移除策略，并可扩展到 0 到 1 的情况。在 IMDb 数据集子集的实验中，Q-LIME π 实现了与经典 LIME 相似的顶级特征排名，同时在小到中等维度特征空间中显著降低了运行时间。该量子-经典混合方法为可解释 AI 提供了新途径，展示了量子并行性在处理高维数据局部解释方面的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17197v1",
      "published_date": "2024-12-23 00:20:11 UTC",
      "updated_date": "2024-12-23 00:20:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T17:07:04.190898"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 130,
  "processed_papers_count": 130,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-21T17:07:21.578111"
}