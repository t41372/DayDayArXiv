[
  {
    "arxiv_id": "2412.18048v1",
    "title": "Fair Knowledge Tracing in Second Language Acquisition",
    "authors": [
      "Weitao Tang",
      "Guanliang Chen",
      "Shuaishuai Zu",
      "Jiangyi Luo"
    ],
    "abstract": "In second-language acquisition, predictive modeling aids educators in\nimplementing diverse teaching strategies, attracting significant research\nattention. However, while model accuracy is widely explored, model fairness\nremains under-examined. Model fairness ensures equitable treatment of groups,\npreventing unintentional biases based on attributes such as gender, ethnicity,\nor economic background. A fair model should produce impartial outcomes that do\nnot systematically disadvantage any group.\n  This study evaluates the fairness of two predictive models using the Duolingo\ndataset's en\\_es (English learners speaking Spanish), es\\_en (Spanish learners\nspeaking English), and fr\\_en (French learners speaking English) tracks. We\nanalyze: 1. Algorithmic fairness across platforms (iOS, Android, Web). 2.\nAlgorithmic fairness between developed and developing countries.\n  Key findings include: 1. Deep learning outperforms machine learning in\nsecond-language knowledge tracing due to improved accuracy and fairness. 2.\nBoth models favor mobile users over non-mobile users. 3. Machine learning\nexhibits stronger bias against developing countries compared to deep learning.\n4. Deep learning strikes a better balance of fairness and accuracy in the\nen\\_es and es\\_en tracks, while machine learning is more suitable for fr\\_en.\n  This study highlights the importance of addressing fairness in predictive\nmodels to ensure equitable educational strategies across platforms and regions.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.18048v1",
    "published_date": "2024-12-23 23:47:40 UTC",
    "updated_date": "2024-12-23 23:47:40 UTC"
  },
  {
    "arxiv_id": "2412.18047v3",
    "title": "Uncertainty-Aware Critic Augmentation for Hierarchical Multi-Agent EV Charging Control",
    "authors": [
      "Lo Pang-Yun Ting",
      "Ali Şenol",
      "Huan-Yang Wang",
      "Hsu-Chao Lai",
      "Kun-Ta Chuang",
      "Huan Liu"
    ],
    "abstract": "The advanced bidirectional EV charging and discharging technology, aimed at\nsupporting grid stability and emergency operations, has driven a growing\ninterest in workplace applications. It not only reduces electricity expenses\nbut also enhances the resilience in handling practical matters, such as peak\npower limitation, fluctuating energy prices, and unpredictable EV departures.\nConsidering these factors systematically can benefit energy efficiency in\noffice buildings and for EV users simultaneously. To employ AI to address these\nissues, we propose HUCA, a novel real-time charging control for regulating\nenergy demands for both the building and EVs. HUCA employs hierarchical\nactor-critic networks to dynamically reduce electricity costs in buildings,\naccounting for the needs of EV charging in the dynamic pricing scenario. To\ntackle the uncertain EV departures, we introduce a new critic augmentation to\naccount for departure uncertainties in evaluating the charging decisions, while\nmaintaining the robustness of the charging control. Experiments on real-world\nelectricity datasets under both simulated certain and uncertain departure\nscenarios demonstrate that HUCA outperforms baselines in terms of total\nelectricity costs while maintaining competitive performance in fulfilling EV\ncharging requirements. A case study also manifests that HUCA effectively\nbalances energy supply between the building and EVs based on real-time\ninformation, showcasing its potential as a key AI-driven solution for vehicle\ncharging control.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.18047v3",
    "published_date": "2024-12-23 23:45:45 UTC",
    "updated_date": "2025-02-17 11:19:13 UTC"
  },
  {
    "arxiv_id": "2412.18046v1",
    "title": "Emoji Retrieval from Gibberish or Garbled Social Media Text: A Novel Methodology and A Case Study",
    "authors": [
      "Shuqi Cui",
      "Nirmalya Thakur",
      "Audrey Poon"
    ],
    "abstract": "Emojis are widely used across social media platforms but are often lost in\nnoisy or garbled text, posing challenges for data analysis and machine\nlearning. Conventional preprocessing approaches recommend removing such text,\nrisking the loss of emojis and their contextual meaning. This paper proposes a\nthree-step reverse-engineering methodology to retrieve emojis from garbled text\nin social media posts. The methodology also identifies reasons for the\ngeneration of such text during social media data mining. To evaluate its\neffectiveness, the approach was applied to 509,248 Tweets about the Mpox\noutbreak, a dataset referenced in about 30 prior works that failed to retrieve\nemojis from garbled text. Our method retrieved 157,748 emojis from 76,914\nTweets. Improvements in text readability and coherence were demonstrated\nthrough metrics such as Flesch Reading Ease, Flesch-Kincaid Grade Level,\nColeman-Liau Index, Automated Readability Index, Dale-Chall Readability Score,\nText Standard, and Reading Time. Additionally, the frequency of individual\nemojis and their patterns of usage in these Tweets were analyzed, and the\nresults are presented.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "cs.LG",
      "I.2.7; I.2.8; I.5.4; K.4.2; H.2.8; I.2.6"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.18046v1",
    "published_date": "2024-12-23 23:44:13 UTC",
    "updated_date": "2024-12-23 23:44:13 UTC"
  },
  {
    "arxiv_id": "2412.18043v1",
    "title": "Aligning AI Research with the Needs of Clinical Coding Workflows: Eight Recommendations Based on US Data Analysis and Critical Review",
    "authors": [
      "Yidong Gan",
      "Maciej Rybinski",
      "Ben Hachey",
      "Jonathan K. Kummerfeld"
    ],
    "abstract": "Clinical coding is crucial for healthcare billing and data analysis. Manual\nclinical coding is labour-intensive and error-prone, which has motivated\nresearch towards full automation of the process. However, our analysis, based\non US English electronic health records and automated coding research using\nthese records, shows that widely used evaluation methods are not aligned with\nreal clinical contexts. For example, evaluations that focus on the top 50 most\ncommon codes are an oversimplification, as there are thousands of codes used in\npractice. This position paper aims to align AI coding research more closely\nwith practical challenges of clinical coding. Based on our analysis, we offer\neight specific recommendations, suggesting ways to improve current evaluation\nmethods. Additionally, we propose new AI-based methods beyond automated coding,\nsuggesting alternative approaches to assist clinical coders in their workflows.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "We received a meta-review score of 5 in ARR October 2024",
    "pdf_url": "http://arxiv.org/pdf/2412.18043v1",
    "published_date": "2024-12-23 23:39:05 UTC",
    "updated_date": "2024-12-23 23:39:05 UTC"
  },
  {
    "arxiv_id": "2412.18040v1",
    "title": "Theoretical Constraints on the Expressive Power of $\\mathsf{RoPE}$-based Tensor Attention Transformers",
    "authors": [
      "Xiaoyu Li",
      "Yingyu Liang",
      "Zhenmei Shi",
      "Zhao Song",
      "Mingda Wan"
    ],
    "abstract": "Tensor Attention extends traditional attention mechanisms by capturing\nhigh-order correlations across multiple modalities, addressing the limitations\nof classical matrix-based attention. Meanwhile, Rotary Position Embedding\n($\\mathsf{RoPE}$) has shown superior performance in encoding positional\ninformation in long-context scenarios, significantly enhancing transformer\nmodels' expressiveness. Despite these empirical successes, the theoretical\nlimitations of these technologies remain underexplored. In this study, we\nanalyze the circuit complexity of Tensor Attention and $\\mathsf{RoPE}$-based\nTensor Attention, showing that with polynomial precision, constant-depth\nlayers, and linear or sublinear hidden dimension, they cannot solve fixed\nmembership problems or $(A_{F,r})^*$ closure problems, under the assumption\nthat $\\mathsf{TC}^0 \\neq \\mathsf{NC}^1$. These findings highlight a gap between\nthe empirical performance and theoretical constraints of Tensor Attention and\n$\\mathsf{RoPE}$-based Tensor Attention Transformers, offering insights that\ncould guide the development of more theoretically grounded approaches to\nTransformer model design and scaling.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CC",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.18040v1",
    "published_date": "2024-12-23 23:26:07 UTC",
    "updated_date": "2024-12-23 23:26:07 UTC"
  },
  {
    "arxiv_id": "2412.18038v1",
    "title": "AA-SGAN: Adversarially Augmented Social GAN with Synthetic Data",
    "authors": [
      "Mirko Zaffaroni",
      "Federico Signoretta",
      "Marco Grangetto",
      "Attilio Fiandrotti"
    ],
    "abstract": "Accurately predicting pedestrian trajectories is crucial in applications such\nas autonomous driving or service robotics, to name a few. Deep generative\nmodels achieve top performance in this task, assuming enough labelled\ntrajectories are available for training. To this end, large amounts of\nsynthetically generated, labelled trajectories exist (e.g., generated by video\ngames). However, such trajectories are not meant to represent pedestrian motion\nrealistically and are ineffective at training a predictive model. We propose a\nmethod and an architecture to augment synthetic trajectories at training time\nand with an adversarial approach. We show that trajectory augmentation at\ntraining time unleashes significant gains when a state-of-the-art generative\nmodel is evaluated over real-world trajectories.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.18038v1",
    "published_date": "2024-12-23 23:17:44 UTC",
    "updated_date": "2024-12-23 23:17:44 UTC"
  },
  {
    "arxiv_id": "2412.18036v2",
    "title": "Explainability in Neural Networks for Natural Language Processing Tasks",
    "authors": [
      "Melkamu Mersha",
      "Mingiziem Bitewa",
      "Tsion Abay",
      "Jugal Kalita"
    ],
    "abstract": "Neural networks are widely regarded as black-box models, creating significant\nchallenges in understanding their inner workings, especially in natural\nlanguage processing (NLP) applications. To address this opacity, model\nexplanation techniques like Local Interpretable Model-Agnostic Explanations\n(LIME) have emerged as essential tools for providing insights into the behavior\nof these complex systems. This study leverages LIME to interpret a multi-layer\nperceptron (MLP) neural network trained on a text classification task. By\nanalyzing the contribution of individual features to model predictions, the\nLIME approach enhances interpretability and supports informed decision-making.\nDespite its effectiveness in offering localized explanations, LIME has\nlimitations in capturing global patterns and feature interactions. This\nresearch highlights the strengths and shortcomings of LIME and proposes\ndirections for future work to achieve more comprehensive interpretability in\nneural NLP models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.18036v2",
    "published_date": "2024-12-23 23:09:56 UTC",
    "updated_date": "2025-01-08 19:44:56 UTC"
  },
  {
    "arxiv_id": "2412.18639v1",
    "title": "A Grounded Observer Framework for Establishing Guardrails for Foundation Models in Socially Sensitive Domains",
    "authors": [
      "Rebecca Ramnauth",
      "Dražen Brščić",
      "Brian Scassellati"
    ],
    "abstract": "As foundation models increasingly permeate sensitive domains such as\nhealthcare, finance, and mental health, ensuring their behavior meets desired\noutcomes and social expectations becomes critical. Given the complexities of\nthese high-dimensional models, traditional techniques for constraining agent\nbehavior, which typically rely on low-dimensional, discrete state and action\nspaces, cannot be directly applied. Drawing inspiration from robotic action\nselection techniques, we propose the grounded observer framework for\nconstraining foundation model behavior that offers both behavioral guarantees\nand real-time variability. This method leverages real-time assessment of\nlow-level behavioral characteristics to dynamically adjust model actions and\nprovide contextual feedback. To demonstrate this, we develop a system capable\nof sustaining contextually appropriate, casual conversations (\"small talk\"),\nwhich we then apply to a robot for novel, unscripted interactions with humans.\nFinally, we discuss potential applications of the framework for other social\ncontexts and areas for further research.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "arXiv admin note: text overlap with arXiv:2412.18023",
    "pdf_url": "http://arxiv.org/pdf/2412.18639v1",
    "published_date": "2024-12-23 22:57:05 UTC",
    "updated_date": "2024-12-23 22:57:05 UTC"
  },
  {
    "arxiv_id": "2412.18023v1",
    "title": "More than Chit-Chat: Developing Robots for Small-Talk Interactions",
    "authors": [
      "Rebecca Ramnauth",
      "Dražen Brščić",
      "Brian Scassellati"
    ],
    "abstract": "Beyond mere formality, small talk plays a pivotal role in social dynamics,\nserving as a verbal handshake for building rapport and understanding. For\nconversational AI and social robots, the ability to engage in small talk\nenhances their perceived sociability, leading to more comfortable and natural\nuser interactions. In this study, we evaluate the capacity of current Large\nLanguage Models (LLMs) to drive the small talk of a social robot and identify\nkey areas for improvement. We introduce a novel method that autonomously\ngenerates feedback and ensures LLM-generated responses align with small talk\nconventions. Through several evaluations -- involving chatbot interactions and\nhuman-robot interactions -- we demonstrate the system's effectiveness in\nguiding LLM-generated responses toward realistic, human-like, and natural\nsmall-talk exchanges.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.18023v1",
    "published_date": "2024-12-23 22:35:38 UTC",
    "updated_date": "2024-12-23 22:35:38 UTC"
  },
  {
    "arxiv_id": "2412.18022v1",
    "title": "Trustworthy and Efficient LLMs Meet Databases",
    "authors": [
      "Kyoungmin Kim",
      "Anastasia Ailamaki"
    ],
    "abstract": "In the rapidly evolving AI era with large language models (LLMs) at the core,\nmaking LLMs more trustworthy and efficient, especially in output generation\n(inference), has gained significant attention. This is to reduce plausible but\nfaulty LLM outputs (a.k.a hallucinations) and meet the highly increased\ninference demands. This tutorial explores such efforts and makes them\ntransparent to the database community. Understanding these efforts is essential\nin harnessing LLMs in database tasks and adapting database techniques to LLMs.\nFurthermore, we delve into the synergy between LLMs and databases, highlighting\nnew opportunities and challenges in their intersection. This tutorial aims to\nshare with database researchers and practitioners essential concepts and\nstrategies around LLMs, reduce the unfamiliarity of LLMs, and inspire joining\nin the intersection between LLMs and databases.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.18022v1",
    "published_date": "2024-12-23 22:34:40 UTC",
    "updated_date": "2024-12-23 22:34:40 UTC"
  },
  {
    "arxiv_id": "2412.18003v2",
    "title": "Integrated Learning and Optimization for Congestion Management and Profit Maximization in Real-Time Electricity Market",
    "authors": [
      "Imran Pervez",
      "Ricardo Pinto Lima",
      "Omar Knio"
    ],
    "abstract": "We develop novel integrated learning and optimization (ILO) methodologies to\nsolve economic dispatch (ED) and DC optimal power flow (DCOPF) problems for\nbetter economic operation. The optimization problem for ED is formulated with\nload being an unknown parameter while DCOPF consists of load and power transfer\ndistribution factor (PTDF) matrix as unknown parameters. PTDF represents the\nincremental variations of real power on transmission lines which occur due to\nreal power transfers between two regions. These values represent a linearized\napproximation of power flows over the transmission lines. We develop novel ILO\nformulations to solve post-hoc penalties in electricity market and line\ncongestion problems using ED and DCOPF optimization formulations. Our proposed\nmethodologies capture the real-time electricity market and line congestion\nbehavior to train the regret function which eventually train unknown loads at\ndifferent buses and line PTDF matrix to achieve the afore-mentioned post-hoc\ngoals. The proposed methodology is compared to sequential learning and\noptimization (SLO) which train load and PTDF forecasts for accuracy rather than\neconomic operation. Our experimentation prove the superiority of ILO in\nminimizing the post-hoc penalties in electricity markets and minimizing the\nline congestion thereby improving the economic operation with noticeable\namount.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.18003v2",
    "published_date": "2024-12-23 21:53:06 UTC",
    "updated_date": "2025-01-06 05:46:18 UTC"
  },
  {
    "arxiv_id": "2412.17998v2",
    "title": "WavePulse: Real-time Content Analytics of Radio Livestreams",
    "authors": [
      "Govind Mittal",
      "Sarthak Gupta",
      "Shruti Wagle",
      "Chirag Chopra",
      "Anthony J DeMattee",
      "Nasir Memon",
      "Mustaque Ahamad",
      "Chinmay Hegde"
    ],
    "abstract": "Radio remains a pervasive medium for mass information dissemination, with\nAM/FM stations reaching more Americans than either smartphone-based social\nnetworking or live television. Increasingly, radio broadcasts are also streamed\nonline and accessed over the Internet. We present WavePulse, a framework that\nrecords, documents, and analyzes radio content in real-time. While our\nframework is generally applicable, we showcase the efficacy of WavePulse in a\ncollaborative project with a team of political scientists focusing on the 2024\nPresidential Elections. We use WavePulse to monitor livestreams of 396 news\nradio stations over a period of three months, processing close to 500,000 hours\nof audio streams. These streams were converted into time-stamped, diarized\ntranscripts and analyzed to track answer key political science questions at\nboth the national and state levels. Our analysis revealed how local issues\ninteracted with national trends, providing insights into information flow. Our\nresults demonstrate WavePulse's efficacy in capturing and analyzing content\nfrom radio livestreams sourced from the Web. Code and dataset can be accessed\nat \\url{https://wave-pulse.io}.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "To appear at The Web Conference (WWW) 2025. 20 Pages, 24 figures.\n  Access code and dataset at https://wave-pulse.io",
    "pdf_url": "http://arxiv.org/pdf/2412.17998v2",
    "published_date": "2024-12-23 21:42:31 UTC",
    "updated_date": "2025-01-29 17:17:56 UTC"
  },
  {
    "arxiv_id": "2501.00034v1",
    "title": "Time Series Feature Redundancy Paradox: An Empirical Study Based on Mortgage Default Prediction",
    "authors": [
      "Chengyue Huang",
      "Yahe Yang"
    ],
    "abstract": "With the widespread application of machine learning in financial risk\nmanagement, conventional wisdom suggests that longer training periods and more\nfeature variables contribute to improved model performance. This paper,\nfocusing on mortgage default prediction, empirically discovers a phenomenon\nthat contradicts traditional knowledge: in time series prediction, increased\ntraining data timespan and additional non-critical features actually lead to\nsignificant deterioration in prediction effectiveness. Using Fannie Mae's\nmortgage data, the study compares predictive performance across different time\nwindow lengths (2012-2022) and feature combinations, revealing that shorter\ntime windows (such as single-year periods) paired with carefully selected key\nfeatures yield superior prediction results. The experimental results indicate\nthat extended time spans may introduce noise from historical data and outdated\nmarket patterns, while excessive non-critical features interfere with the\nmodel's learning of core default factors. This research not only challenges the\ntraditional \"more is better\" approach in data modeling but also provides new\ninsights and practical guidance for feature selection and time window\noptimization in financial risk prediction.",
    "categories": [
      "q-fin.ST",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-fin.ST",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.00034v1",
    "published_date": "2024-12-23 21:28:32 UTC",
    "updated_date": "2024-12-23 21:28:32 UTC"
  },
  {
    "arxiv_id": "2412.17993v1",
    "title": "Multi-Agent Path Finding in Continuous Spaces with Projected Diffusion Models",
    "authors": [
      "Jinhao Liang",
      "Jacob K. Christopher",
      "Sven Koenig",
      "Ferdinando Fioretto"
    ],
    "abstract": "Multi-Agent Path Finding (MAPF) is a fundamental problem in robotics,\nrequiring the computation of collision-free paths for multiple agents moving\nfrom their respective start to goal positions. Coordinating multiple agents in\na shared environment poses significant challenges, especially in continuous\nspaces where traditional optimization algorithms struggle with scalability.\nMoreover, these algorithms often depend on discretized representations of the\nenvironment, which can be impractical in image-based or high-dimensional\nsettings. Recently, diffusion models have shown promise in single-agent path\nplanning, capturing complex trajectory distributions and generating smooth\npaths that navigate continuous, high-dimensional spaces. However, directly\nextending diffusion models to MAPF introduces new challenges since these models\nstruggle to ensure constraint feasibility, such as inter-agent collision\navoidance. To overcome this limitation, this work proposes a novel approach\nthat integrates constrained optimization with diffusion models for MAPF in\ncontinuous spaces. This unique combination directly produces feasible\nmulti-agent trajectories that respect collision avoidance and kinematic\nconstraints. The effectiveness of our approach is demonstrated across various\nchallenging simulated scenarios of varying dimensionality.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17993v1",
    "published_date": "2024-12-23 21:27:19 UTC",
    "updated_date": "2024-12-23 21:27:19 UTC"
  },
  {
    "arxiv_id": "2412.17984v1",
    "title": "ICPR 2024 Competition on Domain Adaptation and GEneralization for Character Classification (DAGECC)",
    "authors": [
      "Sofia Marino",
      "Jennifer Vandoni",
      "Emanuel Aldea",
      "Ichraq Lemghari",
      "Sylvie Le Hégarat-Mascle",
      "Frédéric Jurie"
    ],
    "abstract": "In this companion paper for the DAGECC (Domain Adaptation and GEneralization\nfor Character Classification) competition organized within the frame of the\nICPR 2024 conference, we present the general context of the tasks we proposed\nto the community, we introduce the data that were prepared for the competition\nand we provide a summary of the results along with a description of the top\nthree winning entries. The competition was centered around domain adaptation\nand generalization, and our core aim is to foster interest and facilitate\nadvancement on these topics by providing a high-quality, lightweight, real\nworld dataset able to support fast prototyping and validation of novel ideas.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Companion paper for the ICPR 2024 Competition on Domain Adaptation\n  and GEneralization for Character Classification (DAGECC)",
    "pdf_url": "http://arxiv.org/pdf/2412.17984v1",
    "published_date": "2024-12-23 21:06:08 UTC",
    "updated_date": "2024-12-23 21:06:08 UTC"
  },
  {
    "arxiv_id": "2412.17977v1",
    "title": "TNNGen: Automated Design of Neuromorphic Sensory Processing Units for Time-Series Clustering",
    "authors": [
      "Prabhu Vellaisamy",
      "Harideep Nair",
      "Vamsikrishna Ratnakaram",
      "Dhruv Gupta",
      "John Paul Shen"
    ],
    "abstract": "Temporal Neural Networks (TNNs), a special class of spiking neural networks,\ndraw inspiration from the neocortex in utilizing spike-timings for information\nprocessing. Recent works proposed a microarchitecture framework and custom\nmacro suite for designing highly energy-efficient application-specific TNNs.\nThese recent works rely on manual hardware design, a labor-intensive and\ntime-consuming process. Further, there is no open-source functional simulation\nframework for TNNs. This paper introduces TNNGen, a pioneering effort towards\nthe automated design of TNNs from PyTorch software models to post-layout\nnetlists. TNNGen comprises a novel PyTorch functional simulator (for TNN\nmodeling and application exploration) coupled with a Python-based hardware\ngenerator (for PyTorch-to-RTL and RTL-to-Layout conversions). Seven\nrepresentative TNN designs for time-series signal clustering across diverse\nsensory modalities are simulated and their post-layout hardware complexity and\ndesign runtimes are assessed to demonstrate the effectiveness of TNNGen. We\nalso highlight TNNGen's ability to accurately forecast silicon metrics without\nrunning hardware process flow.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.AR",
    "comment": "Published in IEEE Transactions on Circuits and Systems II: Express\n  Briefs, May 2024",
    "pdf_url": "http://arxiv.org/pdf/2412.17977v1",
    "published_date": "2024-12-23 20:46:53 UTC",
    "updated_date": "2024-12-23 20:46:53 UTC"
  },
  {
    "arxiv_id": "2412.17975v1",
    "title": "Improving Sickle Cell Disease Classification: A Fusion of Conventional Classifiers, Segmented Images, and Convolutional Neural Networks",
    "authors": [
      "Victor Júnio Alcântara Cardoso",
      "Rodrigo Moreira",
      "João Fernando Mari",
      "Larissa Ferreira Rodrigues Moreira"
    ],
    "abstract": "Sickle cell anemia, which is characterized by abnormal erythrocyte\nmorphology, can be detected using microscopic images. Computational techniques\nin medicine enhance the diagnosis and treatment efficiency. However, many\ncomputational techniques, particularly those based on Convolutional Neural\nNetworks (CNNs), require high resources and time for training, highlighting the\nresearch opportunities in methods with low computational overhead. In this\npaper, we propose a novel approach combining conventional classifiers,\nsegmented images, and CNNs for the automated classification of sickle cell\ndisease. We evaluated the impact of segmented images on classification,\nproviding insight into deep learning integration. Our results demonstrate that\nusing segmented images and CNN features with an SVM achieves an accuracy of\n96.80%. This finding is relevant for computationally efficient scenarios,\npaving the way for future research and advancements in medical-image analysis.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "14 pages",
    "pdf_url": "http://arxiv.org/pdf/2412.17975v1",
    "published_date": "2024-12-23 20:42:15 UTC",
    "updated_date": "2024-12-23 20:42:15 UTC"
  },
  {
    "arxiv_id": "2412.17967v1",
    "title": "Towards Cognitive Service Delivery on B5G through AIaaS Architecture",
    "authors": [
      "Larissa F. Rodrigues Moreira",
      "Rodrigo Moreira",
      "Flávio de Oliveira Silva",
      "André R. Backes"
    ],
    "abstract": "Artificial Intelligence (AI) is pivotal in advancing mobile network systems\nby facilitating smart capabilities and automation. The transition from 4G to 5G\nhas substantial implications for AI in consolidating a network predominantly\ngeared towards business verticals. In this context, 3GPP has specified and\nintroduced the Network Data Analytics Function (NWDAF) entity at the network's\ncore to provide insights based on AI algorithms to benefit network\norchestration. This paper proposes a framework for evolving NWDAF that presents\nthe interfaces necessary to further empower the core network with AI\ncapabilities B5G and 6G. In addition, we identify a set of research directions\nfor realizing a distributed e-NWDAF.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "8 pages",
    "pdf_url": "http://arxiv.org/pdf/2412.17967v1",
    "published_date": "2024-12-23 20:30:29 UTC",
    "updated_date": "2024-12-23 20:30:29 UTC"
  },
  {
    "arxiv_id": "2412.17966v1",
    "title": "tuGEMM: Area-Power-Efficient Temporal Unary GEMM Architecture for Low-Precision Edge AI",
    "authors": [
      "Harideep Nair",
      "Prabhu Vellaisamy",
      "Albert Chen",
      "Joseph Finn",
      "Anna Li",
      "Manav Trivedi",
      "John Paul Shen"
    ],
    "abstract": "General matrix multiplication (GEMM) is a ubiquitous computing\nkernel/algorithm for data processing in diverse applications, including\nartificial intelligence (AI) and deep learning (DL). Recent shift towards edge\ncomputing has inspired GEMM architectures based on unary computing, which are\npredominantly stochastic and rate-coded systems. This paper proposes a novel\nGEMM architecture based on temporal-coding, called tuGEMM, that performs exact\ncomputation. We introduce two variants of tuGEMM, serial and parallel, with\ndistinct area/power-latency trade-offs. Post-synthesis Power-Performance-Area\n(PPA) in 45 nm CMOS are reported for 2-bit, 4-bit, and 8-bit computations. The\ndesigns illustrate significant advantages in area-power efficiency over\nstate-of-the-art stochastic unary systems especially at low precisions, e.g.\nincurring just 0.03 mm^2 and 9 mW for 4 bits, and 0.01 mm^2 and 4 mW for 2\nbits. This makes tuGEMM ideal for power constrained mobile and edge devices\nperforming always-on real-time sensory processing.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AR",
    "comment": "Published in 2023 IEEE International Symposium on Circuits and\n  Systems (ISCAS), Monterey, CA, USA, 2023",
    "pdf_url": "http://arxiv.org/pdf/2412.17966v1",
    "published_date": "2024-12-23 20:30:28 UTC",
    "updated_date": "2024-12-23 20:30:28 UTC"
  },
  {
    "arxiv_id": "2412.17965v2",
    "title": "LMV-RPA: Large Model Voting-based Robotic Process Automation",
    "authors": [
      "Osama Abdellatif",
      "Ahmed Ayman",
      "Ali Hamdi"
    ],
    "abstract": "Automating high-volume unstructured data processing is essential for\noperational efficiency. Optical Character Recognition (OCR) is critical but\noften struggles with accuracy and efficiency in complex layouts and ambiguous\ntext. These challenges are especially pronounced in large-scale tasks requiring\nboth speed and precision. This paper introduces LMV-RPA, a Large Model\nVoting-based Robotic Process Automation system to enhance OCR workflows.\nLMV-RPA integrates outputs from OCR engines such as Paddle OCR, Tesseract OCR,\nEasy OCR, and DocTR with Large Language Models (LLMs) like LLaMA 3 and\nGemini-1.5-pro. Using a majority voting mechanism, it processes OCR outputs\ninto structured JSON formats, improving accuracy, particularly in complex\nlayouts. The multi-phase pipeline processes text extracted by OCR engines\nthrough LLMs, combining results to ensure the most accurate outputs. LMV-RPA\nachieves 99 percent accuracy in OCR tasks, surpassing baseline models with 94\npercent, while reducing processing time by 80 percent. Benchmark evaluations\nconfirm its scalability and demonstrate that LMV-RPA offers a faster, more\nreliable, and efficient solution for automating large-scale document processing\ntasks.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.RO",
    "comment": "12 pages, 1 figures, 1 algorithm",
    "pdf_url": "http://arxiv.org/pdf/2412.17965v2",
    "published_date": "2024-12-23 20:28:22 UTC",
    "updated_date": "2025-04-28 15:54:16 UTC"
  },
  {
    "arxiv_id": "2412.17964v1",
    "title": "Dynamic Multi-Agent Orchestration and Retrieval for Multi-Source Question-Answer Systems using Large Language Models",
    "authors": [
      "Antony Seabra",
      "Claudio Cavalcante",
      "Joao Nepomuceno",
      "Lucas Lago",
      "Nicolaas Ruberg",
      "Sergio Lifschitz"
    ],
    "abstract": "We propose a methodology that combines several advanced techniques in Large\nLanguage Model (LLM) retrieval to support the development of robust,\nmulti-source question-answer systems. This methodology is designed to integrate\ninformation from diverse data sources, including unstructured documents (PDFs)\nand structured databases, through a coordinated multi-agent orchestration and\ndynamic retrieval approach. Our methodology leverages specialized agents-such\nas SQL agents, Retrieval-Augmented Generation (RAG) agents, and router agents -\nthat dynamically select the most appropriate retrieval strategy based on the\nnature of each query. To further improve accuracy and contextual relevance, we\nemploy dynamic prompt engineering, which adapts in real time to query-specific\ncontexts. The methodology's effectiveness is demonstrated within the domain of\nContract Management, where complex queries often require seamless interaction\nbetween unstructured and structured data. Our results indicate that this\napproach enhances response accuracy and relevance, offering a versatile and\nscalable framework for developing question-answer systems that can operate\nacross various domains and data sources.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "International Conference on NLP, AI, Computer Science & Engineering\n  (NLAICSE 2024)",
    "pdf_url": "http://arxiv.org/pdf/2412.17964v1",
    "published_date": "2024-12-23 20:28:20 UTC",
    "updated_date": "2024-12-23 20:28:20 UTC"
  },
  {
    "arxiv_id": "2412.17959v1",
    "title": "Analysis of Transferred Pre-Trained Deep Convolution Neural Networks in Breast Masses Recognition",
    "authors": [
      "Qusay Shihab Hamad",
      "Hussein Samma",
      "Shahrel Azmin Suandi"
    ],
    "abstract": "Breast cancer detection based on pre-trained convolution neural network (CNN)\nhas gained much interest among other conventional computer-based systems. In\nthe past few years, CNN technology has been the most promising way to find\ncancer in mammogram scans. In this paper, the effect of layer freezing in a\npre-trained CNN is investigated for breast cancer detection by classifying\nmammogram images as benign or malignant. Different VGG19 scenarios have been\nexamined based on the number of convolution layer blocks that have been frozen.\nThere are a total of six scenarios in this study. The primary benefits of this\nresearch are twofold: it improves the model's ability to detect breast cancer\ncases and it reduces the training time of VGG19 by freezing certain layers.To\nevaluate the performance of these scenarios, 1693 microbiological images of\nbenign and malignant breast cancers were utilized. According to the reported\nresults, the best recognition rate was obtained from a frozen first block of\nVGG19 with a sensitivity of 95.64 %, while the training of the entire VGG19\nyielded 94.48%.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "Its a conference paper; the full proceeding is avalible at\n  https://icogoia.utem.edu.my/proceedings.html",
    "pdf_url": "http://arxiv.org/pdf/2412.17959v1",
    "published_date": "2024-12-23 20:16:45 UTC",
    "updated_date": "2024-12-23 20:16:45 UTC"
  },
  {
    "arxiv_id": "2412.17957v2",
    "title": "ArchComplete: Autoregressive 3D Architectural Design Generation with Hierarchical Diffusion-Based Upsampling",
    "authors": [
      "S. Rasoulzadeh",
      "M. Bank",
      "I. Kovacic",
      "K. Schinegger",
      "S. Rutzinger",
      "M. Wimmer"
    ],
    "abstract": "Recent advances in 3D generative models have shown promising results but\noften fall short in capturing the complexity of architectural geometries and\ntopologies and fine geometric details at high resolutions. To tackle this, we\npresent ArchComplete, a two-stage voxel-based 3D generative pipeline consisting\nof a vector-quantised model, whose composition is modelled with an\nautoregressive transformer for generating coarse shapes, followed by a\nhierarchical upsampling strategy for further enrichment with fine structures\nand details. Key to our pipeline is (i) learning a contextually rich codebook\nof local patch embeddings, optimised alongside a 2.5D perceptual loss that\ncaptures global spatial correspondence of projections onto three axis-aligned\northogonal planes, and (ii) redefining upsampling as a set of conditional\ndiffusion models learning from a hierarchy of randomly cropped coarse-to-fine\nlocal volumetric patches. Trained on our introduced dataset of 3D house models\nwith fully modelled exterior and interior, ArchComplete autoregressively\ngenerates models at the resolution of $64^{3}$ and progressively refines them\nup to $512^{3}$, with voxel sizes as small as $ \\approx 9\\text{cm}$.\nArchComplete solves a variety of tasks, including genetic interpolation and\nvariation, unconditional synthesis, shape and plan-drawing completion, as well\nas geometric detailisation, while achieving state-of-the-art performance in\nquality, diversity, and computational efficiency.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "14 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.17957v2",
    "published_date": "2024-12-23 20:13:27 UTC",
    "updated_date": "2025-02-13 21:57:44 UTC"
  },
  {
    "arxiv_id": "2412.17953v1",
    "title": "Adaptive Signal Analysis for Automated Subsurface Defect Detection Using Impact Echo in Concrete Slabs",
    "authors": [
      "Deepthi Pavurala",
      "Duoduo Liao",
      "Chaithra Reddy Pasunuru"
    ],
    "abstract": "This pilot study presents a novel, automated, and scalable methodology for\ndetecting and evaluating subsurface defect-prone regions in concrete slabs\nusing Impact Echo (IE) signal analysis. The approach integrates advanced signal\nprocessing, clustering, and visual analytics to identify subsurface anomalies.\nA unique adaptive thresholding method tailors frequency-based defect\nidentification to the distinct material properties of each slab. The\nmethodology generates frequency maps, binary masks, and k-means cluster maps to\nautomatically classify defect and non-defect regions. Key visualizations,\nincluding 3D surface plots, cluster maps, and contour plots, are employed to\nanalyze spatial frequency distributions and highlight structural anomalies. The\nstudy utilizes a labeled dataset constructed at the Federal Highway\nAdministration (FHWA) Advanced Sensing Technology Nondestructive Evaluation\nLaboratory. Evaluations involve ground-truth masking, comparing the generated\ndefect maps with top-view binary masks derived from the information provided by\nthe FHWA. The performance metrics, specifically F1-scores and AUC-ROC, achieve\nvalues of up to 0.95 and 0.83, respectively. The results demonstrate the\nrobustness of the methodology, consistently identifying defect-prone areas with\nminimal false positives and few missed defects. Adaptive frequency thresholding\nensures flexibility in addressing variations across slabs, providing a scalable\nframework for detecting structural anomalies. Additionally, the methodology is\nadaptable to other frequency-based signals due to its generalizable\nthresholding mechanism and holds potential for integrating multimodal sensor\nfusion. This automated and scalable pipeline minimizes manual intervention,\nensuring accurate and efficient defect detection, further advancing\nNon-Destructive Evaluation (NDE) techniques.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.SP",
    "comment": "Accepted by IEEE Big Data 2024",
    "pdf_url": "http://arxiv.org/pdf/2412.17953v1",
    "published_date": "2024-12-23 20:05:53 UTC",
    "updated_date": "2024-12-23 20:05:53 UTC"
  },
  {
    "arxiv_id": "2412.17948v1",
    "title": "Study of the Proper NNUE Dataset",
    "authors": [
      "Daniel Tan",
      "Neftali Watkinson Medina"
    ],
    "abstract": "NNUE (Efficiently Updatable Neural Networks) has revolutionized chess engine\ndevelopment, with nearly all top engines adopting NNUE models to maintain\ncompetitive performance. A key challenge in NNUE training is the creation of\nhigh-quality datasets, particularly in complex domains like chess, where\ntactical and strategic evaluations are essential. However, methods for\nconstructing effective datasets remain poorly understood and under-documented.\nIn this paper, we propose an algorithm for generating and filtering datasets\ncomposed of \"quiet\" positions that are stable and free from tactical\nvolatility. Our approach provides a clear methodology for dataset creation,\nwhich can be replicated and generalized across various evaluation functions.\nTesting demonstrates significant improvements in engine performance, confirming\nthe effectiveness of our method.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "I.2.0"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.17948v1",
    "published_date": "2024-12-23 20:02:17 UTC",
    "updated_date": "2024-12-23 20:02:17 UTC"
  },
  {
    "arxiv_id": "2412.17944v1",
    "title": "Surveillance Capitalism Revealed: Tracing The Hidden World Of Web Data Collection",
    "authors": [
      "Antony Seabra de Medeiros",
      "Luiz Afonso Glatzl Junior",
      "Sergio Lifschitz"
    ],
    "abstract": "This study investigates the mechanisms of Surveillance Capitalism, focusing\non personal data transfer during web navigation and searching. Analyzing\nnetwork traffic reveals how various entities track and harvest digital\nfootprints. The research reveals specific data types exchanged between users\nand web services, emphasizing the sophisticated algorithms involved in these\nprocesses. We present concrete evidence of data harvesting practices and\npropose strategies for enhancing data protection and transparency. Our findings\nhighlight the need for robust data protection frameworks and ethical data usage\nto address privacy concerns in the digital age.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "SBBD 2024 - Simp\\'osio Brasileiro de Banco de Dados",
    "pdf_url": "http://arxiv.org/pdf/2412.17944v1",
    "published_date": "2024-12-23 19:55:20 UTC",
    "updated_date": "2024-12-23 19:55:20 UTC"
  },
  {
    "arxiv_id": "2412.17942v1",
    "title": "Contrato360 2.0: A Document and Database-Driven Question-Answer System using Large Language Models and Agents",
    "authors": [
      "Antony Seabra",
      "Claudio Cavalcante",
      "Joao Nepomuceno",
      "Lucas Lago",
      "Nicolaas Ruberg",
      "Sergio Lifschitz"
    ],
    "abstract": "We present a question-and-answer (Q\\&A) application designed to support the\ncontract management process by leveraging combined information from contract\ndocuments (PDFs) and data retrieved from contract management systems\n(database). This data is processed by a large language model (LLM) to provide\nprecise and relevant answers. The accuracy of these responses is further\nenhanced through the use of Retrieval-Augmented Generation (RAG), text-to-SQL\ntechniques, and agents that dynamically orchestrate the workflow. These\ntechniques eliminate the need to retrain the language model. Additionally, we\nemployed Prompt Engineering to fine-tune the focus of responses. Our findings\ndemonstrate that this multi-agent orchestration and combination of techniques\nsignificantly improve the relevance and accuracy of the answers, offering a\npromising direction for future information systems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "KDIR 2024 - Knowledge Discovery and Information Retrieval",
    "pdf_url": "http://arxiv.org/pdf/2412.17942v1",
    "published_date": "2024-12-23 19:54:28 UTC",
    "updated_date": "2024-12-23 19:54:28 UTC"
  },
  {
    "arxiv_id": "2412.17933v1",
    "title": "BenCzechMark : A Czech-centric Multitask and Multimetric Benchmark for Large Language Models with Duel Scoring Mechanism",
    "authors": [
      "Martin Fajcik",
      "Martin Docekal",
      "Jan Dolezal",
      "Karel Ondrej",
      "Karel Beneš",
      "Jan Kapsa",
      "Pavel Smrz",
      "Alexander Polok",
      "Michal Hradis",
      "Zuzana Neverilova",
      "Ales Horak",
      "Radoslav Sabol",
      "Michal Stefanik",
      "Adam Jirkovsky",
      "David Adamczyk",
      "Petr Hyner",
      "Jan Hula",
      "Hynek Kydlicek"
    ],
    "abstract": "We present BenCzechMark (BCM), the first comprehensive Czech language\nbenchmark designed for large language models, offering diverse tasks, multiple\ntask formats, and multiple evaluation metrics. Its scoring system is grounded\nin statistical significance theory and uses aggregation across tasks inspired\nby social preference theory. Our benchmark encompasses 50 challenging tasks,\nwith corresponding test datasets, primarily in native Czech, with 11 newly\ncollected ones. These tasks span 8 categories and cover diverse domains,\nincluding historical Czech news, essays from pupils or language learners, and\nspoken word.\n  Furthermore, we collect and clean BUT-Large Czech Collection, the largest\npublicly available clean Czech language corpus, and use it for (i)\ncontamination analysis, (ii) continuous pretraining of the first Czech-centric\n7B language model, with Czech-specific tokenization. We use our model as a\nbaseline for comparison with publicly available multilingual models. Lastly, we\nrelease and maintain a leaderboard, with existing 44 model submissions, where\nnew model submissions can be made at\nhttps://huggingface.co/spaces/CZLC/BenCzechMark.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "first version",
    "pdf_url": "http://arxiv.org/pdf/2412.17933v1",
    "published_date": "2024-12-23 19:45:20 UTC",
    "updated_date": "2024-12-23 19:45:20 UTC"
  },
  {
    "arxiv_id": "2412.17920v2",
    "title": "Causal Composition Diffusion Model for Closed-loop Traffic Generation",
    "authors": [
      "Haohong Lin",
      "Xin Huang",
      "Tung Phan-Minh",
      "David S. Hayden",
      "Huan Zhang",
      "Ding Zhao",
      "Siddhartha Srinivasa",
      "Eric M. Wolff",
      "Hongge Chen"
    ],
    "abstract": "Simulation is critical for safety evaluation in autonomous driving,\nparticularly in capturing complex interactive behaviors. However, generating\nrealistic and controllable traffic scenarios in long-tail situations remains a\nsignificant challenge. Existing generative models suffer from the conflicting\nobjective between user-defined controllability and realism constraints, which\nis amplified in safety-critical contexts. In this work, we introduce the Causal\nCompositional Diffusion Model (CCDiff), a structure-guided diffusion framework\nto address these challenges. We first formulate the learning of controllable\nand realistic closed-loop simulation as a constrained optimization problem.\nThen, CCDiff maximizes controllability while adhering to realism by\nautomatically identifying and injecting causal structures directly into the\ndiffusion process, providing structured guidance to enhance both realism and\ncontrollability. Through rigorous evaluations on benchmark datasets and in a\nclosed-loop simulator, CCDiff demonstrates substantial gains over\nstate-of-the-art approaches in generating realistic and user-preferred\ntrajectories. Our results show CCDiff's effectiveness in extracting and\nleveraging causal structures, showing improved closed-loop performance based on\nkey metrics such as collision rate, off-road rate, FDE, and comfort.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17920v2",
    "published_date": "2024-12-23 19:20:29 UTC",
    "updated_date": "2025-02-05 16:08:12 UTC"
  },
  {
    "arxiv_id": "2412.17910v1",
    "title": "A Novel Approach to Balance Convenience and Nutrition in Meals With Long-Term Group Recommendations and Reasoning on Multimodal Recipes and its Implementation in BEACON",
    "authors": [
      "Vansh Nagpal",
      "Siva Likitha Valluru",
      "Kausik Lakkaraju",
      "Nitin Gupta",
      "Zach Abdulrahman",
      "Andrew Davison",
      "Biplav Srivastava"
    ],
    "abstract": "\"A common decision made by people, whether healthy or with health conditions,\nis choosing meals like breakfast, lunch, and dinner, comprising combinations of\nfoods for appetizer, main course, side dishes, desserts, and beverages. Often,\nthis decision involves tradeoffs between nutritious choices (e.g., salt and\nsugar levels, nutrition content) and convenience (e.g., cost and accessibility,\ncuisine type, food source type). We present a data-driven solution for meal\nrecommendations that considers customizable meal configurations and time\nhorizons. This solution balances user preferences while accounting for food\nconstituents and cooking processes. Our contributions include introducing\ngoodness measures, a recipe conversion method from text to the recently\nintroduced multimodal rich recipe representation (R3) format, learning methods\nusing contextual bandits that show promising preliminary results, and the\nprototype, usage-inspired, BEACON system.\"",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "arXiv admin note: substantial text overlap with arXiv:2406.13714",
    "pdf_url": "http://arxiv.org/pdf/2412.17910v1",
    "published_date": "2024-12-23 19:05:27 UTC",
    "updated_date": "2024-12-23 19:05:27 UTC"
  },
  {
    "arxiv_id": "2412.17807v1",
    "title": "Cross-View Referring Multi-Object Tracking",
    "authors": [
      "Sijia Chen",
      "En Yu",
      "Wenbing Tao"
    ],
    "abstract": "Referring Multi-Object Tracking (RMOT) is an important topic in the current\ntracking field. Its task form is to guide the tracker to track objects that\nmatch the language description. Current research mainly focuses on referring\nmulti-object tracking under single-view, which refers to a view sequence or\nmultiple unrelated view sequences. However, in the single-view, some\nappearances of objects are easily invisible, resulting in incorrect matching of\nobjects with the language description. In this work, we propose a new task,\ncalled Cross-view Referring Multi-Object Tracking (CRMOT). It introduces the\ncross-view to obtain the appearances of objects from multiple views, avoiding\nthe problem of the invisible appearances of objects in RMOT task. CRMOT is a\nmore challenging task of accurately tracking the objects that match the\nlanguage description and maintaining the identity consistency of objects in\neach cross-view. To advance CRMOT task, we construct a cross-view referring\nmulti-object tracking benchmark based on CAMPUS and DIVOTrack datasets, named\nCRTrack. Specifically, it provides 13 different scenes and 221 language\ndescriptions. Furthermore, we propose an end-to-end cross-view referring\nmulti-object tracking method, named CRTracker. Extensive experiments on the\nCRTrack benchmark verify the effectiveness of our method. The dataset and code\nare available at https://github.com/chen-si-jia/CRMOT.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by AAAI 2025!",
    "pdf_url": "http://arxiv.org/pdf/2412.17807v1",
    "published_date": "2024-12-23 18:58:39 UTC",
    "updated_date": "2024-12-23 18:58:39 UTC"
  },
  {
    "arxiv_id": "2412.17799v2",
    "title": "Automating the Search for Artificial Life with Foundation Models",
    "authors": [
      "Akarsh Kumar",
      "Chris Lu",
      "Louis Kirsch",
      "Yujin Tang",
      "Kenneth O. Stanley",
      "Phillip Isola",
      "David Ha"
    ],
    "abstract": "With the recent Nobel Prize awarded for radical advances in protein\ndiscovery, foundation models (FMs) for exploring large combinatorial spaces\npromise to revolutionize many scientific fields. Artificial Life (ALife) has\nnot yet integrated FMs, thus presenting a major opportunity for the field to\nalleviate the historical burden of relying chiefly on manual design and\ntrial-and-error to discover the configurations of lifelike simulations. This\npaper presents, for the first time, a successful realization of this\nopportunity using vision-language FMs. The proposed approach, called Automated\nSearch for Artificial Life (ASAL), (1) finds simulations that produce target\nphenomena, (2) discovers simulations that generate temporally open-ended\nnovelty, and (3) illuminates an entire space of interestingly diverse\nsimulations. Because of the generality of FMs, ASAL works effectively across a\ndiverse range of ALife substrates including Boids, Particle Life, Game of Life,\nLenia, and Neural Cellular Automata. A major result highlighting the potential\nof this technique is the discovery of previously unseen Lenia and Boids\nlifeforms, as well as cellular automata that are open-ended like Conway's Game\nof Life. Additionally, the use of FMs allows for the quantification of\npreviously qualitative phenomena in a human-aligned way. This new paradigm\npromises to accelerate ALife research beyond what is possible through human\ningenuity alone.",
    "categories": [
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.AI",
    "comment": "30 pages, 19 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.17799v2",
    "published_date": "2024-12-23 18:57:00 UTC",
    "updated_date": "2025-05-16 21:19:02 UTC"
  },
  {
    "arxiv_id": "2412.17797v1",
    "title": "Observation Interference in Partially Observable Assistance Games",
    "authors": [
      "Scott Emmons",
      "Caspar Oesterheld",
      "Vincent Conitzer",
      "Stuart Russell"
    ],
    "abstract": "We study partially observable assistance games (POAGs), a model of the\nhuman-AI value alignment problem which allows the human and the AI assistant to\nhave partial observations. Motivated by concerns of AI deception, we study a\nqualitatively new phenomenon made possible by partial observability: would an\nAI assistant ever have an incentive to interfere with the human's observations?\nFirst, we prove that sometimes an optimal assistant must take\nobservation-interfering actions, even when the human is playing optimally, and\neven when there are otherwise-equivalent actions available that do not\ninterfere with observations. Though this result seems to contradict the classic\ntheorem from single-agent decision making that the value of perfect information\nis nonnegative, we resolve this seeming contradiction by developing a notion of\ninterference defined on entire policies. This can be viewed as an extension of\nthe classic result that the value of perfect information is nonnegative into\nthe cooperative multiagent setting. Second, we prove that if the human is\nsimply making decisions based on their immediate outcomes, the assistant might\nneed to interfere with observations as a way to query the human's preferences.\nWe show that this incentive for interference goes away if the human is playing\noptimally, or if we introduce a communication channel for the human to\ncommunicate their preferences to the assistant. Third, we show that if the\nhuman acts according to the Boltzmann model of irrationality, this can create\nan incentive for the assistant to interfere with observations. Finally, we use\nan experimental model to analyze tradeoffs faced by the AI assistant in\npractice when considering whether or not to take observation-interfering\nactions.",
    "categories": [
      "cs.AI",
      "cs.GT",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17797v1",
    "published_date": "2024-12-23 18:53:33 UTC",
    "updated_date": "2024-12-23 18:53:33 UTC"
  },
  {
    "arxiv_id": "2412.17780v3",
    "title": "PepTune: De Novo Generation of Therapeutic Peptides with Multi-Objective-Guided Discrete Diffusion",
    "authors": [
      "Sophia Tang",
      "Yinuo Zhang",
      "Pranam Chatterjee"
    ],
    "abstract": "Peptide therapeutics, a major class of medicines, have achieved remarkable\nsuccess across diseases such as diabetes and cancer, with landmark examples\nsuch as GLP-1 receptor agonists revolutionizing the treatment of type-2\ndiabetes and obesity. Despite their success, designing peptides that satisfy\nmultiple conflicting objectives, such as target binding affinity, solubility,\nand membrane permeability, remains a major challenge. Classical drug\ndevelopment and structure-based design are ineffective for such tasks, as they\nfail to optimize global functional properties critical for therapeutic\nefficacy. Existing generative frameworks are largely limited to continuous\nspaces, unconditioned outputs, or single-objective guidance, making them\nunsuitable for discrete sequence optimization across multiple properties. To\naddress this, we present PepTune, a multi-objective discrete diffusion model\nfor the simultaneous generation and optimization of therapeutic peptide SMILES.\nBuilt on the Masked Discrete Language Model (MDLM) framework, PepTune ensures\nvalid peptide structures with state-dependent masking schedules and\npenalty-based objectives. To guide the diffusion process, we propose a Monte\nCarlo Tree Search (MCTS)-based strategy that balances exploration and\nexploitation to iteratively refine Pareto-optimal sequences. MCTS integrates\nclassifier-based rewards with search-tree expansion, overcoming gradient\nestimation challenges and data sparsity inherent to discrete spaces. Using\nPepTune, we generate diverse, chemically-modified peptides optimized for\nmultiple therapeutic properties, including target binding affinity, membrane\npermeability, solubility, hemolysis, and non-fouling characteristics on various\ndisease-relevant targets. In total, our results demonstrate that MCTS-guided\ndiscrete diffusion is a powerful and modular approach for multi-objective\nsequence design in discrete state spaces.",
    "categories": [
      "q-bio.BM",
      "cs.AI"
    ],
    "primary_category": "q-bio.BM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17780v3",
    "published_date": "2024-12-23 18:38:49 UTC",
    "updated_date": "2025-01-01 15:34:56 UTC"
  },
  {
    "arxiv_id": "2412.17778v1",
    "title": "An Investigation on the Potential of KAN in Speech Enhancement",
    "authors": [
      "Haoyang Li",
      "Yuchen Hu",
      "Chen Chen",
      "Eng Siong Chng"
    ],
    "abstract": "High-fidelity speech enhancement often requires sophisticated modeling to\ncapture intricate, multiscale patterns. Standard activation functions, while\nintroducing nonlinearity, lack the flexibility to fully address this\ncomplexity. Kolmogorov-Arnold Networks (KAN), an emerging methodology that\nemploys learnable activation functions on graph edges, present a promising\nalternative. This work investigates two novel KAN variants based on rational\nand radial basis functions for speech enhancement. We integrate the rational\nvariant into the 1D CNN blocks of Demucs and the GRU-Transformer blocks of\nMP-SENet, while the radial variant is adapted to the 2D CNN-based decoders of\nMP-SENet. Experiments on the VoiceBank-DEMAND dataset show that replacing\nstandard activations with KAN-based activations improves speech quality across\nboth the time-domain and time-frequency domain methods with minimal impact on\nmodel size and FLOP, underscoring KAN's potential to improve speech enhancement\nmodels.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.AS",
    "comment": "5 pages, 2 figure, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2412.17778v1",
    "published_date": "2024-12-23 18:38:32 UTC",
    "updated_date": "2024-12-23 18:38:32 UTC"
  },
  {
    "arxiv_id": "2412.17759v1",
    "title": "Survey of Large Multimodal Model Datasets, Application Categories and Taxonomy",
    "authors": [
      "Priyaranjan Pattnayak",
      "Hitesh Laxmichand Patel",
      "Bhargava Kumar",
      "Amit Agarwal",
      "Ishan Banerjee",
      "Srikant Panda",
      "Tejaswini Kumar"
    ],
    "abstract": "Multimodal learning, a rapidly evolving field in artificial intelligence,\nseeks to construct more versatile and robust systems by integrating and\nanalyzing diverse types of data, including text, images, audio, and video.\nInspired by the human ability to assimilate information through many senses,\nthis method enables applications such as text-to-video conversion, visual\nquestion answering, and image captioning. Recent developments in datasets that\nsupport multimodal language models (MLLMs) are highlighted in this overview.\nLarge-scale multimodal datasets are essential because they allow for thorough\ntesting and training of these models. With an emphasis on their contributions\nto the discipline, the study examines a variety of datasets, including those\nfor training, domain-specific tasks, and real-world applications. It also\nemphasizes how crucial benchmark datasets are for assessing models' performance\nin a range of scenarios, scalability, and applicability. Since multimodal\nlearning is always changing, overcoming these obstacles will help AI research\nand applications reach new heights.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17759v1",
    "published_date": "2024-12-23 18:15:19 UTC",
    "updated_date": "2024-12-23 18:15:19 UTC"
  },
  {
    "arxiv_id": "2412.17758v1",
    "title": "In Case You Missed It: ARC 'Challenge' Is Not That Challenging",
    "authors": [
      "Łukasz Borchmann"
    ],
    "abstract": "ARC Challenge appears more difficult than ARC Easy for modern LLMs primarily\ndue to an evaluation setup that prevents direct comparison of answer choices\nrather than inherent complexity. Although some researchers have quietly shifted\nto a more appropriate scheme over the last year, the implications of this\nchange have yet to be widely acknowledged. We highlight this overlooked shift,\nshow how similar evaluation practices falsely imply reasoning deficits in other\nbenchmarks, and demonstrate that fairer methods dramatically reduce performance\ngaps (e.g. on SIQA) and even yield superhuman results (OpenBookQA). In doing\nso, we reveal how evaluation shapes perceived difficulty and offer guidelines\nto ensure that multiple-choice evaluations accurately reflect actual model\ncapabilities.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17758v1",
    "published_date": "2024-12-23 18:14:36 UTC",
    "updated_date": "2024-12-23 18:14:36 UTC"
  },
  {
    "arxiv_id": "2412.17747v1",
    "title": "Deliberation in Latent Space via Differentiable Cache Augmentation",
    "authors": [
      "Luyang Liu",
      "Jonas Pfeiffer",
      "Jiaxing Wu",
      "Jun Xie",
      "Arthur Szlam"
    ],
    "abstract": "Techniques enabling large language models (LLMs) to \"think more\" by\ngenerating and attending to intermediate reasoning steps have shown promise in\nsolving complex problems. However, the standard approaches generate sequences\nof discrete tokens immediately before responding, and so they can incur\nsignificant latency costs and be challenging to optimize. In this work, we\ndemonstrate that a frozen LLM can be augmented with an offline coprocessor that\noperates on the model's key-value (kv) cache. This coprocessor augments the\ncache with a set of latent embeddings designed to improve the fidelity of\nsubsequent decoding. We train this coprocessor using the language modeling loss\nfrom the decoder on standard pretraining data, while keeping the decoder itself\nfrozen. This approach enables the model to learn, in an end-to-end\ndifferentiable fashion, how to distill additional computation into its\nkv-cache. Because the decoder remains unchanged, the coprocessor can operate\noffline and asynchronously, and the language model can function normally if the\ncoprocessor is unavailable or if a given cache is deemed not to require extra\ncomputation. We show experimentally that when a cache is augmented, the decoder\nachieves lower perplexity on numerous subsequent tokens. Furthermore, even\nwithout any task-specific training, our experiments demonstrate that cache\naugmentation consistently reduces perplexity and improves performance across a\nrange of reasoning-intensive tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17747v1",
    "published_date": "2024-12-23 18:02:25 UTC",
    "updated_date": "2024-12-23 18:02:25 UTC"
  },
  {
    "arxiv_id": "2412.17744v1",
    "title": "RepoTransBench: A Real-World Benchmark for Repository-Level Code Translation",
    "authors": [
      "Yanli Wang",
      "Yanlin Wang",
      "Suiquan Wang",
      "Daya Guo",
      "Jiachi Chen",
      "John Grundy",
      "Xilin Liu",
      "Yuchi Ma",
      "Mingzhi Mao",
      "Hongyu Zhang",
      "Zibin Zheng"
    ],
    "abstract": "Repository-level code translation refers to translating an entire code\nrepository from one programming language to another while preserving the\nfunctionality of the source repository. Many benchmarks have been proposed to\nevaluate the performance of such code translators. However, previous benchmarks\nmostly provide fine-grained samples, focusing at either code snippet, function,\nor file-level code translation. Such benchmarks do not accurately reflect\nreal-world demands, where entire repositories often need to be translated,\ninvolving longer code length and more complex functionalities. To address this\ngap, we propose a new benchmark, named RepoTransBench, which is a real-world\nrepository-level code translation benchmark with an automatically executable\ntest suite. We conduct experiments on RepoTransBench to evaluate the\ntranslation performance of 11 advanced LLMs. We find that the Success@1 score\n(test success in one attempt) of the best-performing LLM is only 7.33%. To\nfurther explore the potential of LLMs for repository-level code translation, we\nprovide LLMs with error-related feedback to perform iterative debugging and\nobserve an average 7.09% improvement on Success@1. However, even with this\nimprovement, the Success@1 score of the best-performing LLM is only 21%, which\nmay not meet the need for reliable automatic repository-level code translation.\nFinally, we conduct a detailed error analysis and highlight current LLMs'\ndeficiencies in repository-level code translation, which could provide a\nreference for further improvements.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17744v1",
    "published_date": "2024-12-23 17:52:10 UTC",
    "updated_date": "2024-12-23 17:52:10 UTC"
  },
  {
    "arxiv_id": "2412.17739v3",
    "title": "Fourier Position Embedding: Enhancing Attention's Periodic Extension for Length Generalization",
    "authors": [
      "Ermo Hua",
      "Che Jiang",
      "Xingtai Lv",
      "Kaiyan Zhang",
      "Ning Ding",
      "Youbang Sun",
      "Biqing Qi",
      "Yuchen Fan",
      "Xuekai Zhu",
      "Bowen Zhou"
    ],
    "abstract": "Extending the context length of Language Models (LMs) by improving Rotary\nPosition Embedding (RoPE) has become a trend. While existing works mainly\naddress RoPE's limitations within attention mechanism, this paper provides an\nanalysis across nearly all parts of LMs, uncovering their adverse effects on\nlength generalization for RoPE-based attention. Using Discrete Signal\nProcessing theory, we show that RoPE enables periodic attention by implicitly\nachieving Non-Uniform Discrete Fourier Transform. However, this periodicity is\nundermined by the spectral damage caused by: 1) linear layers and activation\nfunctions outside of attention; 2) insufficiently trained frequency components\nbrought by time-domain truncation. Building on our observations, we propose\nFourier Position Embedding (FoPE), which enhances attention's frequency-domain\nproperties to improve both its periodic extension and length generalization.\nFoPE constructs Fourier Series and zero-outs the destructive frequency\ncomponents, increasing model robustness against the spectrum damage.\nExperiments across various model scales and benchmarks show that, within\nvarying context windows, FoPE maintains a more stable performance compared to\nRoPE and ALiBi. Several analyses and ablations bring further support to our\nmethod and theoretical modeling.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to ICML 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.17739v3",
    "published_date": "2024-12-23 17:44:01 UTC",
    "updated_date": "2025-05-06 07:47:40 UTC"
  },
  {
    "arxiv_id": "2412.17729v1",
    "title": "Chumor 2.0: Towards Benchmarking Chinese Humor Understanding",
    "authors": [
      "Ruiqi He",
      "Yushu He",
      "Longju Bai",
      "Jiarui Liu",
      "Zhenjie Sun",
      "Zenghao Tang",
      "He Wang",
      "Hanchen Xia",
      "Rada Mihalcea",
      "Naihao Deng"
    ],
    "abstract": "Existing humor datasets and evaluations predominantly focus on English,\nleaving limited resources for culturally nuanced humor in non-English languages\nlike Chinese. To address this gap, we construct Chumor, the first Chinese humor\nexplanation dataset that exceeds the size of existing humor datasets. Chumor is\nsourced from Ruo Zhi Ba, a Chinese Reddit-like platform known for sharing\nintellectually challenging and culturally specific jokes. We test ten LLMs\nthrough direct and chain-of-thought prompting, revealing that Chumor poses\nsignificant challenges to existing LLMs, with their accuracy slightly above\nrandom and far below human. In addition, our analysis highlights that\nhuman-annotated humor explanations are significantly better than those\ngenerated by GPT-4o and ERNIE-4-turbo. We release Chumor at\nhttps://huggingface.co/datasets/dnaihao/Chumor, our project page is at\nhttps://dnaihao.github.io/Chumor-dataset/, our leaderboard is at\nhttps://huggingface.co/spaces/dnaihao/Chumor, and our codebase is at\nhttps://github.com/dnaihao/Chumor-dataset.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "arXiv admin note: substantial text overlap with arXiv:2406.12754",
    "pdf_url": "http://arxiv.org/pdf/2412.17729v1",
    "published_date": "2024-12-23 17:19:58 UTC",
    "updated_date": "2024-12-23 17:19:58 UTC"
  },
  {
    "arxiv_id": "2412.17726v2",
    "title": "VidTwin: Video VAE with Decoupled Structure and Dynamics",
    "authors": [
      "Yuchi Wang",
      "Junliang Guo",
      "Xinyi Xie",
      "Tianyu He",
      "Xu Sun",
      "Jiang Bian"
    ],
    "abstract": "Recent advancements in video autoencoders (Video AEs) have significantly\nimproved the quality and efficiency of video generation. In this paper, we\npropose a novel and compact video autoencoder, VidTwin, that decouples video\ninto two distinct latent spaces: Structure latent vectors, which capture\noverall content and global movement, and Dynamics latent vectors, which\nrepresent fine-grained details and rapid movements. Specifically, our approach\nleverages an Encoder-Decoder backbone, augmented with two submodules for\nextracting these latent spaces, respectively. The first submodule employs a\nQ-Former to extract low-frequency motion trends, followed by downsampling\nblocks to remove redundant content details. The second averages the latent\nvectors along the spatial dimension to capture rapid motion. Extensive\nexperiments show that VidTwin achieves a high compression rate of 0.20% with\nhigh reconstruction quality (PSNR of 28.14 on the MCL-JCV dataset), and\nperforms efficiently and effectively in downstream generative tasks. Moreover,\nour model demonstrates explainability and scalability, paving the way for\nfuture research in video latent representation and generation. Check our\nproject page for more details: https://vidtwin.github.io/.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by CVPR 2025; Project page: https://vidtwin.github.io/;\n  Code: https://github.com/microsoft/VidTok/tree/main/vidtwin",
    "pdf_url": "http://arxiv.org/pdf/2412.17726v2",
    "published_date": "2024-12-23 17:16:58 UTC",
    "updated_date": "2025-03-28 17:32:31 UTC"
  },
  {
    "arxiv_id": "2412.17707v2",
    "title": "SMAC-Hard: Enabling Mixed Opponent Strategy Script and Self-play on SMAC",
    "authors": [
      "Yue Deng",
      "Yan Yu",
      "Weiyu Ma",
      "Zirui Wang",
      "Wenhui Zhu",
      "Jian Zhao",
      "Yin Zhang"
    ],
    "abstract": "The availability of challenging simulation environments is pivotal for\nadvancing the field of Multi-Agent Reinforcement Learning (MARL). In\ncooperative MARL settings, the StarCraft Multi-Agent Challenge (SMAC) has\ngained prominence as a benchmark for algorithms following centralized training\nwith decentralized execution paradigm. However, with continual advancements in\nSMAC, many algorithms now exhibit near-optimal performance, complicating the\nevaluation of their true effectiveness. To alleviate this problem, in this\nwork, we highlight a critical issue: the default opponent policy in these\nenvironments lacks sufficient diversity, leading MARL algorithms to overfit and\nexploit unintended vulnerabilities rather than learning robust strategies. To\novercome these limitations, we propose SMAC-HARD, a novel benchmark designed to\nenhance training robustness and evaluation comprehensiveness. SMAC-HARD\nsupports customizable opponent strategies, randomization of adversarial\npolicies, and interfaces for MARL self-play, enabling agents to generalize to\nvarying opponent behaviors and improve model stability. Furthermore, we\nintroduce a black-box testing framework wherein agents are trained without\nexposure to the edited opponent scripts but are tested against these scripts to\nevaluate the policy coverage and adaptability of MARL algorithms. We conduct\nextensive evaluations of widely used and state-of-the-art algorithms on\nSMAC-HARD, revealing the substantial challenges posed by edited and mixed\nstrategy opponents. Additionally, the black-box strategy tests illustrate the\ndifficulty of transferring learned policies to unseen adversaries. We envision\nSMAC-HARD as a critical step toward benchmarking the next generation of MARL\nalgorithms, fostering progress in self-play methods for multi-agent systems.\nOur code is available at https://github.com/devindeng94/smac-hard.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17707v2",
    "published_date": "2024-12-23 16:36:21 UTC",
    "updated_date": "2024-12-24 16:16:34 UTC"
  },
  {
    "arxiv_id": "2412.17692v2",
    "title": "FedTLU: Federated Learning with Targeted Layer Updates",
    "authors": [
      "Jong-Ik Park",
      "Carlee Joe-Wong"
    ],
    "abstract": "Federated learning (FL) addresses privacy concerns in training language\nmodels by enabling multiple clients to contribute to the training, without\nsending their data to others. However, non-IID (identically and independently\ndistributed) data across clients often limits FL's performance. This issue is\nespecially challenging during model fine-tuning, as noise due to variations in\nclients' data distributions can harm model convergence near stationary points.\nThis paper proposes a targeted layer update strategy for fine-tuning in FL.\nInstead of randomly updating layers of the language model, as often done in\npractice, we use a scoring mechanism to identify and update the most critical\nlayers, avoiding excessively noisy or even poisoned updates by freezing the\nparameters in other layers. We show in extensive experiments that our method\nimproves convergence and performance in non-IID settings, offering a more\nefficient approach to fine-tuning federated language models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17692v2",
    "published_date": "2024-12-23 16:17:46 UTC",
    "updated_date": "2025-01-26 05:21:54 UTC"
  },
  {
    "arxiv_id": "2412.17686v1",
    "title": "Large Language Model Safety: A Holistic Survey",
    "authors": [
      "Dan Shi",
      "Tianhao Shen",
      "Yufei Huang",
      "Zhigen Li",
      "Yongqi Leng",
      "Renren Jin",
      "Chuang Liu",
      "Xinwei Wu",
      "Zishan Guo",
      "Linhao Yu",
      "Ling Shi",
      "Bojian Jiang",
      "Deyi Xiong"
    ],
    "abstract": "The rapid development and deployment of large language models (LLMs) have\nintroduced a new frontier in artificial intelligence, marked by unprecedented\ncapabilities in natural language understanding and generation. However, the\nincreasing integration of these models into critical applications raises\nsubstantial safety concerns, necessitating a thorough examination of their\npotential risks and associated mitigation strategies.\n  This survey provides a comprehensive overview of the current landscape of LLM\nsafety, covering four major categories: value misalignment, robustness to\nadversarial attacks, misuse, and autonomous AI risks. In addition to the\ncomprehensive review of the mitigation methodologies and evaluation resources\non these four aspects, we further explore four topics related to LLM safety:\nthe safety implications of LLM agents, the role of interpretability in\nenhancing LLM safety, the technology roadmaps proposed and abided by a list of\nAI companies and institutes for LLM safety, and AI governance aimed at LLM\nsafety with discussions on international cooperation, policy proposals, and\nprospective regulatory directions.\n  Our findings underscore the necessity for a proactive, multifaceted approach\nto LLM safety, emphasizing the integration of technical solutions, ethical\nconsiderations, and robust governance frameworks. This survey is intended to\nserve as a foundational resource for academy researchers, industry\npractitioners, and policymakers, offering insights into the challenges and\nopportunities associated with the safe integration of LLMs into society.\nUltimately, it seeks to contribute to the safe and beneficial development of\nLLMs, aligning with the overarching goal of harnessing AI for societal\nadvancement and well-being. A curated list of related papers has been publicly\navailable at https://github.com/tjunlp-lab/Awesome-LLM-Safety-Papers.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "158 pages, 18 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.17686v1",
    "published_date": "2024-12-23 16:11:27 UTC",
    "updated_date": "2024-12-23 16:11:27 UTC"
  },
  {
    "arxiv_id": "2412.17891v1",
    "title": "The Power of Adaptation: Boosting In-Context Learning through Adaptive Prompting",
    "authors": [
      "Shuzhang Cai",
      "Twumasi Mensah-Boateng",
      "Xander Kuksov",
      "Jing Yuan",
      "Shaojie Tang"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated exceptional abilities across a\nbroad range of language-related tasks, including generating solutions to\ncomplex reasoning problems. An effective technique to enhance LLM performance\nis in-context learning, which encourages a step-by-step reasoning process by\nincluding explanatory examples to guide the model's responses. However,\nselecting appropriate exemplars for the model poses a challenge, as each\ndataset demands a distinct set of exemplars to enable the LLM to learn\neffectively and perform well on the test set. Current studies often rely on\nuncertainty- or diversity-based selection strategies to select exemplars for\nannotation and to improve model learning. However, these studies typically\nemploy a non-adaptive approach, selecting a set of exemplars all at once. We\nargue that this non-adaptive strategy may result in a set of exemplars with\nhigh redundancy in terms of the knowledge covered, ultimately reducing their\noverall informativeness. To address this limitation, we propose\n\\textsc{Adaptive-Prompt}, a novel method that adaptively selects exemplars by\nleveraging model feedback from previously chosen exemplars. Experimental\nresults show that \\textsc{Adaptive-Prompt} significantly enhances LLM\nperformance across a variety of reasoning tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17891v1",
    "published_date": "2024-12-23 15:49:43 UTC",
    "updated_date": "2024-12-23 15:49:43 UTC"
  },
  {
    "arxiv_id": "2412.17654v1",
    "title": "Enhanced Temporal Processing in Spiking Neural Networks for Static Object Detection Using 3D Convolutions",
    "authors": [
      "Huaxu He"
    ],
    "abstract": "Spiking Neural Networks (SNNs) are a class of network models capable of\nprocessing spatiotemporal information, with event-driven characteristics and\nenergy efficiency advantages. Recently, directly trained SNNs have shown\npotential to match or surpass the performance of traditional Artificial Neural\nNetworks (ANNs) in classification tasks. However, in object detection tasks,\ndirectly trained SNNs still exhibit a significant performance gap compared to\nANNs when tested on frame-based static object datasets (such as COCO2017).\nTherefore, bridging this performance gap and enabling directly trained SNNs to\nachieve performance comparable to ANNs on these static datasets has become one\nof the key challenges in the development of SNNs.To address this challenge,\nthis paper focuses on enhancing the SNN's unique ability to process\nspatiotemporal information. Spiking neurons, as the core components of SNNs,\nfacilitate the exchange of information between different temporal channels\nduring the process of converting input floating-point data into binary spike\nsignals. However, existing neuron models still have certain limitations in the\ncommunication of temporal information. Some studies have even suggested that\ndisabling the backpropagation in the time dimension during SNN training can\nstill yield good training results. To improve the SNN handling of temporal\ninformation, this paper proposes replacing traditional 2D convolutions with 3D\nconvolutions, thus directly incorporating temporal information into the\nconvolutional process. Additionally, temporal information recurrence mechanism\nis introduced within the neurons to further enhance the neurons' efficiency in\nutilizing temporal information.Experimental results show that the proposed\nmethod enables directly trained SNNs to achieve performance levels comparable\nto ANNs on the COCO2017 and VOC datasets.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.NE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17654v1",
    "published_date": "2024-12-23 15:32:26 UTC",
    "updated_date": "2024-12-23 15:32:26 UTC"
  },
  {
    "arxiv_id": "2412.17651v1",
    "title": "Detecting anxiety and depression in dialogues: a multi-label and explainable approach",
    "authors": [
      "Francisco de Arriba-Pérez",
      "Silvia García-Méndez"
    ],
    "abstract": "Anxiety and depression are the most common mental health issues worldwide,\naffecting a non-negligible part of the population. Accordingly, stakeholders,\nincluding governments' health systems, are developing new strategies to promote\nearly detection and prevention from a holistic perspective (i.e., addressing\nseveral disorders simultaneously). In this work, an entirely novel system for\nthe multi-label classification of anxiety and depression is proposed. The input\ndata consists of dialogues from user interactions with an assistant chatbot.\nAnother relevant contribution lies in using Large Language Models (LLMs) for\nfeature extraction, provided the complexity and variability of language. The\ncombination of LLMs, given their high capability for language understanding,\nand Machine Learning (ML) models, provided their contextual knowledge about the\nclassification problem thanks to the labeled data, constitute a promising\napproach towards mental health assessment. To promote the solution's\ntrustworthiness, reliability, and accountability, explainability descriptions\nof the model's decision are provided in a graphical dashboard. Experimental\nresults on a real dataset attain 90 % accuracy, improving those in the prior\nliterature. The ultimate objective is to contribute in an accessible and\nscalable way before formal treatment occurs in the healthcare systems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17651v1",
    "published_date": "2024-12-23 15:29:46 UTC",
    "updated_date": "2024-12-23 15:29:46 UTC"
  },
  {
    "arxiv_id": "2412.17647v1",
    "title": "An Adaptive Framework for Multi-View Clustering Leveraging Conditional Entropy Optimization",
    "authors": [
      "Lijian Li"
    ],
    "abstract": "Multi-view clustering (MVC) has emerged as a powerful technique for\nextracting valuable insights from data characterized by multiple perspectives\nor modalities. Despite significant advancements, existing MVC methods struggle\nwith effectively quantifying the consistency and complementarity among views,\nand are particularly susceptible to the adverse effects of noisy views, known\nas the Noisy-View Drawback (NVD). To address these challenges, we propose\nCE-MVC, a novel framework that integrates an adaptive weighting algorithm with\na parameter-decoupled deep model. Leveraging the concept of conditional entropy\nand normalized mutual information, CE-MVC quantitatively assesses and weights\nthe informative contribution of each view, facilitating the construction of\nrobust unified representations. The parameter-decoupled design enables\nindependent processing of each view, effectively mitigating the influence of\nnoise and enhancing overall clustering performance. Extensive experiments\ndemonstrate that CE-MVC outperforms existing approaches, offering a more\nresilient and accurate solution for multi-view clustering tasks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17647v1",
    "published_date": "2024-12-23 15:21:55 UTC",
    "updated_date": "2024-12-23 15:21:55 UTC"
  },
  {
    "arxiv_id": "2412.17643v1",
    "title": "Advances in Machine Learning Research Using Knowledge Graphs",
    "authors": [
      "Jing Si",
      "Jianfei Xu"
    ],
    "abstract": "The study uses CSSCI-indexed literature from the China National Knowledge\nInfrastructure (CNKI) database as the data source. It utilizes the CiteSpace\nvisualization software to draw knowledge graphs on aspects such as\ninstitutional collaboration and keyword co-occurrence. This analysis provides\ninsights into the current state of research and emerging trends in the field of\nmachine learning in China. Additionally, it identifies the challenges faced in\nthe field of machine learning research and offers suggestions that could serve\nas valuable references for future research.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17643v1",
    "published_date": "2024-12-23 15:20:01 UTC",
    "updated_date": "2024-12-23 15:20:01 UTC"
  },
  {
    "arxiv_id": "2412.17637v1",
    "title": "SCBench: A Sports Commentary Benchmark for Video LLMs",
    "authors": [
      "Kuangzhi Ge",
      "Lingjun Chen",
      "Kevin Zhang",
      "Yulin Luo",
      "Tianyu Shi",
      "Liaoyuan Fan",
      "Xiang Li",
      "Guanqun Wang",
      "Shanghang Zhang"
    ],
    "abstract": "Recently, significant advances have been made in Video Large Language Models\n(Video LLMs) in both academia and industry. However, methods to evaluate and\nbenchmark the performance of different Video LLMs, especially their\nfine-grained, temporal visual capabilities, remain very limited. On one hand,\ncurrent benchmarks use relatively simple videos (e.g., subtitled movie clips)\nwhere the model can understand the entire video by processing just a few\nframes. On the other hand, their datasets lack diversity in task format,\ncomprising only QA or multi-choice QA, which overlooks the models' capacity for\ngenerating in-depth and precise texts. Sports videos, which feature intricate\nvisual information, sequential events, and emotionally charged commentary,\npresent a critical challenge for Video LLMs, making sports commentary an ideal\nbenchmarking task. Inspired by these challenges, we propose a novel task:\nsports video commentary generation, developed $\\textbf{SCBench}$ for Video\nLLMs. To construct such a benchmark, we introduce (1) $\\textbf{SCORES}$, a\nsix-dimensional metric specifically designed for our task, upon which we\npropose a GPT-based evaluation method, and (2) $\\textbf{CommentarySet}$, a\ndataset consisting of 5,775 annotated video clips and ground-truth labels\ntailored to our metric. Based on SCBench, we conduct comprehensive evaluations\non multiple Video LLMs (e.g. VILA, Video-LLaVA, etc.) and chain-of-thought\nbaseline methods. Our results found that InternVL-Chat-2 achieves the best\nperformance with 5.44, surpassing the second-best by 1.04. Our work provides a\nfresh perspective for future research, aiming to enhance models' overall\ncapabilities in complex visual understanding tasks. Our dataset will be\nreleased soon.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17637v1",
    "published_date": "2024-12-23 15:13:56 UTC",
    "updated_date": "2024-12-23 15:13:56 UTC"
  },
  {
    "arxiv_id": "2412.17632v2",
    "title": "D-Judge: How Far Are We? Evaluating the Discrepancies Between AI-synthesized Images and Natural Images through Multimodal Guidance",
    "authors": [
      "Renyang Liu",
      "Ziyu Lyu",
      "Wei Zhou",
      "See-Kiong Ng"
    ],
    "abstract": "In Artificial Intelligence Generated Content (AIGC), distinguishing\nAI-synthesized images from natural ones remains a key challenge. Despite\nadvancements in generative models, significant discrepancies persist. To\nsystematically investigate and quantify these discrepancies, we introduce an\nAI-Natural Image Discrepancy accessing benchmark (\\textit{D-Judge}) aimed at\naddressing the critical question: \\textit{how far are AI-generated images\n(AIGIs) from truly realistic images?} We construct \\textit{D-ANI}, a dataset\nwith 5,000 natural images and over 440,000 AIGIs generated by nine models using\nText-to-Image (T2I), Image-to-Image (I2I), and Text and Image-to-Image (TI2I)\nprompts. Our framework evaluates the discrepancy across five dimensions: naive\nimage quality, semantic alignment, aesthetic appeal, downstream applicability,\nand human validation. Results reveal notable gaps, emphasizing the importance\nof aligning metrics with human judgment. Source code and datasets are available\nat https://shorturl.at/l83W2.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.MM"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17632v2",
    "published_date": "2024-12-23 15:08:08 UTC",
    "updated_date": "2025-03-30 03:52:12 UTC"
  },
  {
    "arxiv_id": "2412.17629v2",
    "title": "Graph Neural Networks Are Evolutionary Algorithms",
    "authors": [
      "Kaichen Ouyang",
      "Shengwei Fu"
    ],
    "abstract": "In this paper, we reveal the intrinsic duality between graph neural networks\n(GNNs) and evolutionary algorithms (EAs), bridging two traditionally distinct\nfields. Building on this insight, we propose Graph Neural Evolution (GNE), a\nnovel evolutionary algorithm that models individuals as nodes in a graph and\nleverages designed frequency-domain filters to balance global exploration and\nlocal exploitation. Through the use of these filters, GNE aggregates\nhigh-frequency (diversity-enhancing) and low-frequency (stability-promoting)\ninformation, transforming EAs into interpretable and tunable mechanisms in the\nfrequency domain. Extensive experiments on benchmark functions demonstrate that\nGNE consistently outperforms state-of-the-art algorithms such as GA, DE,\nCMA-ES, SDAES, and RL-SHADE, excelling in complex landscapes, optimal solution\nshifts, and noisy environments. Its robustness, adaptability, and superior\nconvergence highlight its practical and theoretical value. Beyond optimization,\nGNE establishes a conceptual and mathematical foundation linking EAs and GNNs,\noffering new perspectives for both fields. Its framework encourages the\ndevelopment of task-adaptive filters and hybrid approaches for EAs, while its\ninsights can inspire advances in GNNs, such as improved global information\npropagation and mitigation of oversmoothing. GNE's versatility extends to\nsolving challenges in machine learning, including hyperparameter tuning and\nneural architecture search, as well as real-world applications in engineering\nand operations research. By uniting the dynamics of EAs with the structural\ninsights of GNNs, this work provides a foundation for interdisciplinary\ninnovation, paving the way for scalable and interpretable solutions to complex\noptimization problems.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "31 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.17629v2",
    "published_date": "2024-12-23 15:06:37 UTC",
    "updated_date": "2024-12-24 13:27:44 UTC"
  },
  {
    "arxiv_id": "2412.17616v1",
    "title": "Facial Expression Analysis and Its Potentials in IoT Systems: A Contemporary Survey",
    "authors": [
      "Zixuan Shanggua",
      "Yanjie Dong",
      "Song Guo",
      "Victor C. M. Leung",
      "M. Jamal Deen",
      "Xiping Hu"
    ],
    "abstract": "Facial expressions convey human emotions and can be categorized into\nmacro-expressions (MaEs) and micro-expressions (MiEs) based on duration and\nintensity. While MaEs are voluntary and easily recognized, MiEs are\ninvoluntary, rapid, and can reveal concealed emotions. The integration of\nfacial expression analysis with Internet-of-Thing (IoT) systems has significant\npotential across diverse scenarios. IoT-enhanced MaE analysis enables real-time\nmonitoring of patient emotions, facilitating improved mental health care in\nsmart healthcare. Similarly, IoT-based MiE detection enhances surveillance\naccuracy and threat detection in smart security. This work aims at providing a\ncomprehensive overview of research progress in facial expression analysis and\nexplores its integration with IoT systems. We discuss the distinctions between\nour work and existing surveys, elaborate on advancements in MaE and MiE\ntechniques across various learning paradigms, and examine their potential\napplications in IoT. We highlight challenges and future directions for the\nconvergence of facial expression-based technologies and IoT systems, aiming to\nfoster innovation in this domain. By presenting recent developments and\npractical applications, this study offers a systematic understanding of how\nfacial expression analysis can enhance IoT systems in healthcare, security, and\nbeyond.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17616v1",
    "published_date": "2024-12-23 14:41:01 UTC",
    "updated_date": "2024-12-23 14:41:01 UTC"
  },
  {
    "arxiv_id": "2412.17614v1",
    "title": "Emerging Security Challenges of Large Language Models",
    "authors": [
      "Herve Debar",
      "Sven Dietrich",
      "Pavel Laskov",
      "Emil C. Lupu",
      "Eirini Ntoutsi"
    ],
    "abstract": "Large language models (LLMs) have achieved record adoption in a short period\nof time across many different sectors including high importance areas such as\neducation [4] and healthcare [23]. LLMs are open-ended models trained on\ndiverse data without being tailored for specific downstream tasks, enabling\nbroad applicability across various domains. They are commonly used for text\ngeneration, but also widely used to assist with code generation [3], and even\nanalysis of security information, as Microsoft Security Copilot demonstrates\n[18]. Traditional Machine Learning (ML) models are vulnerable to adversarial\nattacks [9]. So the concerns on the potential security implications of such\nwide scale adoption of LLMs have led to the creation of this working group on\nthe security of LLMs. During the Dagstuhl seminar on \"Network Attack Detection\nand Defense - AI-Powered Threats and Responses\", the working group discussions\nfocused on the vulnerability of LLMs to adversarial attacks, rather than their\npotential use in generating malware or enabling cyberattacks. Although we note\nthe potential threat represented by the latter, the role of the LLMs in such\nuses is mostly as an accelerator for development, similar to what it is in\nbenign use. To make the analysis more specific, the working group employed\nChatGPT as a concrete example of an LLM and addressed the following points,\nwhich also form the structure of this report: 1. How do LLMs differ in\nvulnerabilities from traditional ML models? 2. What are the attack objectives\nin LLMs? 3. How complex it is to assess the risks posed by the vulnerabilities\nof LLMs? 4. What is the supply chain in LLMs, how data flow in and out of\nsystems and what are the security implications? We conclude with an overview of\nopen challenges and outlook.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "A version of this appeared in the larger Dagstuhl seminar 23431\n  report (https://doi.org/10.4230/DagRep.13.10.90)",
    "pdf_url": "http://arxiv.org/pdf/2412.17614v1",
    "published_date": "2024-12-23 14:36:37 UTC",
    "updated_date": "2024-12-23 14:36:37 UTC"
  },
  {
    "arxiv_id": "2412.17601v2",
    "title": "AFANet: Adaptive Frequency-Aware Network for Weakly-Supervised Few-Shot Semantic Segmentation",
    "authors": [
      "Jiaqi Ma",
      "Guo-Sen Xie",
      "Fang Zhao",
      "Zechao Li"
    ],
    "abstract": "Few-shot learning aims to recognize novel concepts by leveraging prior\nknowledge learned from a few samples. However, for visually intensive tasks\nsuch as few-shot semantic segmentation, pixel-level annotations are\ntime-consuming and costly. Therefore, in this paper, we utilize the more\nchallenging image-level annotations and propose an adaptive frequency-aware\nnetwork (AFANet) for weakly-supervised few-shot semantic segmentation (WFSS).\nSpecifically, we first propose a cross-granularity frequency-aware module (CFM)\nthat decouples RGB images into high-frequency and low-frequency distributions\nand further optimizes semantic structural information by realigning them.\nUnlike most existing WFSS methods using the textual information from the\nmulti-modal language-vision model, e.g., CLIP, in an offline learning manner,\nwe further propose a CLIP-guided spatial-adapter module (CSM), which performs\nspatial domain adaptive transformation on textual information through online\nlearning, thus providing enriched cross-modal semantic information for CFM.\nExtensive experiments on the Pascal-5\\textsuperscript{i} and\nCOCO-20\\textsuperscript{i} datasets demonstrate that AFANet has achieved\nstate-of-the-art performance. The code is available at\nhttps://github.com/jarch-ma/AFANet.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by TMM 2024",
    "pdf_url": "http://arxiv.org/pdf/2412.17601v2",
    "published_date": "2024-12-23 14:20:07 UTC",
    "updated_date": "2024-12-25 01:42:31 UTC"
  },
  {
    "arxiv_id": "2412.17596v3",
    "title": "LiveIdeaBench: Evaluating LLMs' Divergent Thinking for Scientific Idea Generation with Minimal Context",
    "authors": [
      "Kai Ruan",
      "Xuan Wang",
      "Jixiang Hong",
      "Peng Wang",
      "Yang Liu",
      "Hao Sun"
    ],
    "abstract": "While Large Language Models (LLMs) demonstrate remarkable capabilities in\nscientific tasks such as literature analysis and experimental design (e.g.,\naccurately extracting key findings from papers or generating coherent\nexperimental procedures), existing evaluation benchmarks primarily assess\nperformance using rich contextual inputs. We introduce LiveIdeaBench, a\ncomprehensive benchmark evaluating LLMs' scientific idea generation by\nassessing divergent thinking capabilities using single-keyword prompts. Drawing\nfrom Guilford's creativity theory, our benchmark employs a dynamic panel of\nstate-of-the-art LLMs to assess generated ideas across five key dimensions:\noriginality, feasibility, fluency, flexibility, and clarity. Through extensive\nexperimentation with over 40 leading models across 1,180 keywords spanning 22\nscientific domains, we reveal that the scientific idea generation capabilities\nmeasured by our benchmark, are poorly predicted by standard metrics of general\nintelligence. Our results demonstrate that models like QwQ-32B-preview achieve\ncreative performance comparable to top-tier models such as\nclaude-3.7-sonnet:thinking, despite significant gaps in their general\nintelligence scores. These findings highlight the need for specialized\nevaluation benchmarks for scientific idea generation and suggest that enhancing\nthese idea generation capabilities in LLMs may require different training\nstrategies than those used for improving general problem-solving abilities,\npotentially enabling a wider range of AI tools tailored for different stages of\nthe scientific process.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Updated manuscript and title",
    "pdf_url": "http://arxiv.org/pdf/2412.17596v3",
    "published_date": "2024-12-23 14:13:44 UTC",
    "updated_date": "2025-04-28 06:12:14 UTC"
  },
  {
    "arxiv_id": "2412.17595v1",
    "title": "V$^2$-SfMLearner: Learning Monocular Depth and Ego-motion for Multimodal Wireless Capsule Endoscopy",
    "authors": [
      "Long Bai",
      "Beilei Cui",
      "Liangyu Wang",
      "Yanheng Li",
      "Shilong Yao",
      "Sishen Yuan",
      "Yanan Wu",
      "Yang Zhang",
      "Max Q. -H. Meng",
      "Zhen Li",
      "Weiping Ding",
      "Hongliang Ren"
    ],
    "abstract": "Deep learning can predict depth maps and capsule ego-motion from capsule\nendoscopy videos, aiding in 3D scene reconstruction and lesion localization.\nHowever, the collisions of the capsule endoscopies within the gastrointestinal\ntract cause vibration perturbations in the training data. Existing solutions\nfocus solely on vision-based processing, neglecting other auxiliary signals\nlike vibrations that could reduce noise and improve performance. Therefore, we\npropose V$^2$-SfMLearner, a multimodal approach integrating vibration signals\ninto vision-based depth and capsule motion estimation for monocular capsule\nendoscopy. We construct a multimodal capsule endoscopy dataset containing\nvibration and visual signals, and our artificial intelligence solution develops\nan unsupervised method using vision-vibration signals, effectively eliminating\nvibration perturbations through multimodal learning. Specifically, we carefully\ndesign a vibration network branch and a Fourier fusion module, to detect and\nmitigate vibration noises. The fusion framework is compatible with popular\nvision-only algorithms. Extensive validation on the multimodal dataset\ndemonstrates superior performance and robustness against vision-only\nalgorithms. Without the need for large external equipment, our V$^2$-SfMLearner\nhas the potential for integration into clinical capsule robots, providing\nreal-time and dependable digestive examination tools. The findings show promise\nfor practical implementation in clinical settings, enhancing the diagnostic\ncapabilities of doctors.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "To appear in IEEE Transactions on Automation Science and Engineering\n  (IEEE TASE)",
    "pdf_url": "http://arxiv.org/pdf/2412.17595v1",
    "published_date": "2024-12-23 14:11:30 UTC",
    "updated_date": "2024-12-23 14:11:30 UTC"
  },
  {
    "arxiv_id": "2412.17589v1",
    "title": "PC Agent: While You Sleep, AI Works -- A Cognitive Journey into Digital World",
    "authors": [
      "Yanheng He",
      "Jiahe Jin",
      "Shijie Xia",
      "Jiadi Su",
      "Runze Fan",
      "Haoyang Zou",
      "Xiangkun Hu",
      "Pengfei Liu"
    ],
    "abstract": "Imagine a world where AI can handle your work while you sleep - organizing\nyour research materials, drafting a report, or creating a presentation you need\nfor tomorrow. However, while current digital agents can perform simple tasks,\nthey are far from capable of handling the complex real-world work that humans\nroutinely perform. We present PC Agent, an AI system that demonstrates a\ncrucial step toward this vision through human cognition transfer. Our key\ninsight is that the path from executing simple \"tasks\" to handling complex\n\"work\" lies in efficiently capturing and learning from human cognitive\nprocesses during computer use. To validate this hypothesis, we introduce three\nkey innovations: (1) PC Tracker, a lightweight infrastructure that efficiently\ncollects high-quality human-computer interaction trajectories with complete\ncognitive context; (2) a two-stage cognition completion pipeline that\ntransforms raw interaction data into rich cognitive trajectories by completing\naction semantics and thought processes; and (3) a multi-agent system combining\na planning agent for decision-making with a grounding agent for robust visual\ngrounding. Our preliminary experiments in PowerPoint presentation creation\nreveal that complex digital work capabilities can be achieved with a small\namount of high-quality cognitive data - PC Agent, trained on just 133 cognitive\ntrajectories, can handle sophisticated work scenarios involving up to 50 steps\nacross multiple applications. This demonstrates the data efficiency of our\napproach, highlighting that the key to training capable digital agents lies in\ncollecting human cognitive data. By open-sourcing our complete framework,\nincluding the data collection infrastructure and cognition completion methods,\nwe aim to lower the barriers for the research community to develop truly\ncapable digital agents.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17589v1",
    "published_date": "2024-12-23 14:02:12 UTC",
    "updated_date": "2024-12-23 14:02:12 UTC"
  },
  {
    "arxiv_id": "2412.17587v1",
    "title": "Improved Cotton Leaf Disease Classification Using Parameter-Efficient Deep Learning Framework",
    "authors": [
      "Aswini Kumar Patra",
      "Tejashwini Gajurel"
    ],
    "abstract": "Cotton crops, often called \"white gold,\" face significant production\nchallenges, primarily due to various leaf-affecting diseases. As a major global\nsource of fiber, timely and accurate disease identification is crucial to\nensure optimal yields and maintain crop health. While deep learning and machine\nlearning techniques have been explored to address this challenge, there remains\na gap in developing lightweight models with fewer parameters which could be\ncomputationally effective for agricultural practitioners. To address this, we\npropose an innovative deep learning framework integrating a subset of trainable\nlayers from MobileNet, transfer learning, data augmentation, a learning rate\ndecay schedule, model checkpoints, and early stopping mechanisms. Our model\ndemonstrates exceptional performance, accurately classifying seven cotton\ndisease types with an overall accuracy of 98.42% and class-wise precision\nranging from 96% to 100%. This results in significantly enhanced efficiency,\nsurpassing recent approaches in accuracy and model complexity. The existing\nmodels in the literature have yet to attain such high accuracy, even when\ntested on data sets with fewer disease types. The substantial performance\nimprovement, combined with the lightweight nature of the model, makes it\npractically suitable for real-world applications in smart farming. By offering\na high-performing and efficient solution, our framework can potentially address\nchallenges in cotton cultivation, contributing to sustainable agricultural\npractices.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "4 figures, 3 Tables",
    "pdf_url": "http://arxiv.org/pdf/2412.17587v1",
    "published_date": "2024-12-23 14:01:10 UTC",
    "updated_date": "2024-12-23 14:01:10 UTC"
  },
  {
    "arxiv_id": "2412.17574v2",
    "title": "HumanVBench: Exploring Human-Centric Video Understanding Capabilities of MLLMs with Synthetic Benchmark Data",
    "authors": [
      "Ting Zhou",
      "Daoyuan Chen",
      "Qirui Jiao",
      "Bolin Ding",
      "Yaliang Li",
      "Ying Shen"
    ],
    "abstract": "In the domain of Multimodal Large Language Models (MLLMs), achieving\nhuman-centric video understanding remains a formidable challenge. Existing\nbenchmarks primarily emphasize object and action recognition, often neglecting\nthe intricate nuances of human emotions, behaviors, and speech-visual alignment\nwithin video content. We present HumanVBench, an innovative benchmark\nmeticulously crafted to bridge these gaps in the evaluation of video MLLMs.\nHumanVBench comprises 16 carefully designed tasks that explore two primary\ndimensions: inner emotion and outer manifestations, spanning static and\ndynamic, basic and complex, as well as single-modal and cross-modal aspects.\nWith two advanced automated pipelines for video annotation and\ndistractor-included QA generation, HumanVBench utilizes diverse\nstate-of-the-art (SOTA) techniques to streamline benchmark data synthesis and\nquality assessment, minimizing human annotation dependency tailored to\nhuman-centric multimodal attributes. A comprehensive evaluation across 22 SOTA\nvideo MLLMs reveals notable limitations in current performance, especially in\ncross-modal and emotion perception, underscoring the necessity for further\nrefinement toward achieving more human-like understanding. HumanVBench is\nopen-sourced to facilitate future advancements and real-world applications in\nvideo MLLMs.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "22 pages, 23 figures, 7 tables",
    "pdf_url": "http://arxiv.org/pdf/2412.17574v2",
    "published_date": "2024-12-23 13:45:56 UTC",
    "updated_date": "2025-03-12 03:42:48 UTC"
  },
  {
    "arxiv_id": "2412.17572v1",
    "title": "Empathetic Response in Audio-Visual Conversations Using Emotion Preference Optimization and MambaCompressor",
    "authors": [
      "Yeonju Kim",
      "Se Jin Park",
      "Yong Man Ro"
    ],
    "abstract": "Chatbot research is advancing with the growing importance of chatbots in\nfields that require human interactions, such as customer support and mental\nhealth care. Despite these advancements, chatbots still face significant\nchallenges in understanding subtle nuances and managing long conversation\nhistories. To address these issues, our study introduces a dual approach:\nfirstly, we employ Emotional Preference Optimization (EPO) to train chatbots\nnot only with correct responses but also with counter-emotional responses-those\nthat are contextually similar but emotionally divergent. This training enables\nthe model to discern fine nuance distinctions between correct and\ncounter-emotional responses, thereby enhancing the quality of its responses.\nSecondly, we introduce MambaCompressor to effectively compress and manage\nextensive conversation histories, significantly reducing time and memory\ncomplexities while improving the chatbot's contextual understanding. Our\ncomprehensive experiments across multiple datasets demonstrate that our model\nsignificantly outperforms existing models in generating empathetic responses\nand efficiently managing lengthy dialogues.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17572v1",
    "published_date": "2024-12-23 13:44:51 UTC",
    "updated_date": "2024-12-23 13:44:51 UTC"
  },
  {
    "arxiv_id": "2412.17566v1",
    "title": "The Dynamic Duo of Collaborative Masking and Target for Advanced Masked Autoencoder Learning",
    "authors": [
      "Shentong Mo"
    ],
    "abstract": "Masked autoencoders (MAE) have recently succeeded in self-supervised vision\nrepresentation learning. Previous work mainly applied custom-designed (e.g.,\nrandom, block-wise) masking or teacher (e.g., CLIP)-guided masking and targets.\nHowever, they ignore the potential role of the self-training (student) model in\ngiving feedback to the teacher for masking and targets. In this work, we\npresent to integrate Collaborative Masking and Targets for boosting Masked\nAutoEncoders, namely CMT-MAE. Specifically, CMT-MAE leverages a simple\ncollaborative masking mechanism through linear aggregation across attentions\nfrom both teacher and student models. We further propose using the output\nfeatures from those two models as the collaborative target of the decoder. Our\nsimple and effective framework pre-trained on ImageNet-1K achieves\nstate-of-the-art linear probing and fine-tuning performance. In particular,\nusing ViT-base, we improve the fine-tuning results of the vanilla MAE from\n83.6% to 85.7%.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "eess.IV",
      "eess.SP"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17566v1",
    "published_date": "2024-12-23 13:37:26 UTC",
    "updated_date": "2024-12-23 13:37:26 UTC"
  },
  {
    "arxiv_id": "2412.17565v1",
    "title": "Evaluation of Bio-Inspired Models under Different Learning Settings For Energy Efficiency in Network Traffic Prediction",
    "authors": [
      "Theodoros Tsiolakis",
      "Nikolaos Pavlidis",
      "Vasileios Perifanis",
      "Pavlos Efraimidis"
    ],
    "abstract": "Cellular traffic forecasting is a critical task that enables network\noperators to efficiently allocate resources and address anomalies in rapidly\nevolving environments. The exponential growth of data collected from base\nstations poses significant challenges to processing and analysis. While machine\nlearning (ML) algorithms have emerged as powerful tools for handling these\nlarge datasets and providing accurate predictions, their environmental impact,\nparticularly in terms of energy consumption, is often overlooked in favor of\ntheir predictive capabilities. This study investigates the potential of two\nbio-inspired models: Spiking Neural Networks (SNNs) and Reservoir Computing\nthrough Echo State Networks (ESNs) for cellular traffic forecasting. The\nevaluation focuses on both their predictive performance and energy efficiency.\nThese models are implemented in both centralized and federated settings to\nanalyze their effectiveness and energy consumption in decentralized systems.\nAdditionally, we compare bio-inspired models with traditional architectures,\nsuch as Convolutional Neural Networks (CNNs) and Multi-Layer Perceptrons\n(MLPs), to provide a comprehensive evaluation. Using data collected from three\ndiverse locations in Barcelona, Spain, we examine the trade-offs between\npredictive accuracy and energy demands across these approaches. The results\nindicate that bio-inspired models, such as SNNs and ESNs, can achieve\nsignificant energy savings while maintaining predictive accuracy comparable to\ntraditional architectures. Furthermore, federated implementations were tested\nto evaluate their energy efficiency in decentralized settings compared to\ncentralized systems, particularly in combination with bio-inspired models.\nThese findings offer valuable insights into the potential of bio-inspired\nmodels for sustainable and privacy-preserving cellular traffic forecasting.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "18 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.17565v1",
    "published_date": "2024-12-23 13:35:53 UTC",
    "updated_date": "2024-12-23 13:35:53 UTC"
  },
  {
    "arxiv_id": "2412.17548v1",
    "title": "Resource-Aware Arabic LLM Creation: Model Adaptation, Integration, and Multi-Domain Testing",
    "authors": [
      "Prakash Aryan"
    ],
    "abstract": "This paper presents a novel approach to fine-tuning the Qwen2-1.5B model for\nArabic language processing using Quantized Low-Rank Adaptation (QLoRA) on a\nsystem with only 4GB VRAM. We detail the process of adapting this large\nlanguage model to the Arabic domain, using diverse datasets including Bactrian,\nOpenAssistant, and Wikipedia Arabic corpora. Our methodology involves custom\ndata preprocessing, model configuration, and training optimization techniques\nsuch as gradient accumulation and mixed-precision training. We address specific\nchallenges in Arabic NLP, including morphological complexity, dialectal\nvariations, and diacritical mark handling. Experimental results over 10,000\ntraining steps show significant performance improvements, with the final loss\nconverging to 0.1083. We provide comprehensive analysis of GPU memory usage,\ntraining dynamics, and model evaluation across various Arabic language tasks,\nincluding text classification, question answering, and dialect identification.\nThe fine-tuned model demonstrates robustness to input perturbations and\nimproved handling of Arabic-specific linguistic phenomena. This research\ncontributes to multilingual AI by demonstrating a resource-efficient approach\nfor creating specialized language models, potentially democratizing access to\nadvanced NLP technologies for diverse linguistic communities. Our work paves\nthe way for future research in low-resource language adaptation and efficient\nfine-tuning of large language models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17548v1",
    "published_date": "2024-12-23 13:08:48 UTC",
    "updated_date": "2024-12-23 13:08:48 UTC"
  },
  {
    "arxiv_id": "2412.17544v1",
    "title": "Retention Score: Quantifying Jailbreak Risks for Vision Language Models",
    "authors": [
      "Zaitang Li",
      "Pin-Yu Chen",
      "Tsung-Yi Ho"
    ],
    "abstract": "The emergence of Vision-Language Models (VLMs) is a significant advancement\nin integrating computer vision with Large Language Models (LLMs) to enhance\nmulti-modal machine learning capabilities. However, this progress has also made\nVLMs vulnerable to sophisticated adversarial attacks, raising concerns about\ntheir reliability. The objective of this paper is to assess the resilience of\nVLMs against jailbreak attacks that can compromise model safety compliance and\nresult in harmful outputs. To evaluate a VLM's ability to maintain its\nrobustness against adversarial input perturbations, we propose a novel metric\ncalled the \\textbf{Retention Score}. Retention Score is a multi-modal\nevaluation metric that includes Retention-I and Retention-T scores for\nquantifying jailbreak risks in visual and textual components of VLMs. Our\nprocess involves generating synthetic image-text pairs using a conditional\ndiffusion model. These pairs are then predicted for toxicity score by a VLM\nalongside a toxicity judgment classifier. By calculating the margin in toxicity\nscores, we can quantify the robustness of the VLM in an attack-agnostic manner.\nOur work has four main contributions. First, we prove that Retention Score can\nserve as a certified robustness metric. Second, we demonstrate that most VLMs\nwith visual components are less robust against jailbreak attacks than the\ncorresponding plain VLMs. Additionally, we evaluate black-box VLM APIs and find\nthat the security settings in Google Gemini significantly affect the score and\nrobustness. Moreover, the robustness of GPT4V is similar to the medium settings\nof Gemini. Finally, our approach offers a time-efficient alternative to\nexisting adversarial attack methods and provides consistent model robustness\nrankings when evaluated on VLMs including MiniGPT-4, InstructBLIP, and LLaVA.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages, 8 figures, AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.17544v1",
    "published_date": "2024-12-23 13:05:51 UTC",
    "updated_date": "2024-12-23 13:05:51 UTC"
  },
  {
    "arxiv_id": "2412.17541v3",
    "title": "Concept Discovery in Deep Neural Networks for Explainable Face Anti-Spoofing",
    "authors": [
      "Haoyuan Zhang",
      "Xiangyu Zhu",
      "Li Gao",
      "Guoying Zhao",
      "Zhen Lei"
    ],
    "abstract": "With the rapid growth usage of face recognition in people's daily life, face\nanti-spoofing becomes increasingly important to avoid malicious attacks. Recent\nface anti-spoofing models can reach a high classification accuracy on multiple\ndatasets but these models can only tell people \"this face is fake\" while\nlacking the explanation to answer \"why it is fake\". Such a system undermines\ntrustworthiness and causes user confusion, as it denies their requests without\nproviding any explanations. In this paper, we incorporate XAI into face\nanti-spoofing and propose a new problem termed X-FAS (eXplainable Face\nAnti-Spoofing) empowering face anti-spoofing models to provide an explanation.\nWe propose SPED (SPoofing Evidence Discovery), an X-FAS method which can\ndiscover spoof concepts and provide reliable explanations on the basis of\ndiscovered concepts. To evaluate the quality of X-FAS methods, we propose an\nX-FAS benchmark with annotated spoofing evidence by experts. We analyze SPED\nexplanations on face anti-spoofing dataset and compare SPED quantitatively and\nqualitatively with previous XAI methods on proposed X-FAS benchmark.\nExperimental results demonstrate SPED's ability to generate reliable\nexplanations.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "keywords: explainable artificial intelligence, face anti-spoofing,\n  explainable face anti-spoofing, interpretable",
    "pdf_url": "http://arxiv.org/pdf/2412.17541v3",
    "published_date": "2024-12-23 13:03:51 UTC",
    "updated_date": "2025-01-05 04:42:03 UTC"
  },
  {
    "arxiv_id": "2412.17534v2",
    "title": "CiteBART: Learning to Generate Citations for Local Citation Recommendation",
    "authors": [
      "Ege Yiğit Çelik",
      "Selma Tekir"
    ],
    "abstract": "Local citation recommendation (LCR) suggests a set of papers for a citation\nplaceholder within a given context. The task has evolved as generative\napproaches have become more promising than the traditional pre-fetch and\nre-rank-based state-of-the-art approaches. This paper introduces\ncitation-specific pre-training within an encoder-decoder architecture, where\nauthor-date citation tokens are masked to learn to reconstruct them to fulfill\nLCR. There are two variants for this pre-training. In the local context-only\nbase scheme (CiteBART-Base), the citation token in a local context is masked to\nlearn to predict the citation. The global version (CiteBART-Global) extends the\nlocal context with the citing paper's title and abstract to enrich the learning\nsignal. CiteBART-Global achieves state-of-the-art performance on LCR benchmarks\nexcept for the FullTextPeerRead dataset, which is quite small to see the\nadvantage of generative pre-training. The effect is significant in the larger\nbenchmarks, e.g., Refseer and ArXiv., with the Refseer benchmark-trained model\nemerging as the best-performing model. We perform comprehensive experiments,\nincluding an ablation study, a qualitative analysis, and a taxonomy of\nhallucinations with detailed statistics. Our analyses confirm that\nCiteBART-Global has a cross-dataset generalization capability; the macro\nhallucination rate (MaHR) at the top-3 predictions is 4\\%, and when the\nground-truth is in the top-k prediction list, the hallucination tendency in the\nother predictions drops significantly.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "17 pages, 2 figures, 10 tables",
    "pdf_url": "http://arxiv.org/pdf/2412.17534v2",
    "published_date": "2024-12-23 12:58:30 UTC",
    "updated_date": "2025-04-09 20:23:16 UTC"
  },
  {
    "arxiv_id": "2412.17531v1",
    "title": "Double Landmines: Invisible Textual Backdoor Attacks based on Dual-Trigger",
    "authors": [
      "Yang Hou",
      "Qiuling Yue",
      "Lujia Chai",
      "Guozhao Liao",
      "Wenbao Han",
      "Wei Ou"
    ],
    "abstract": "At present, all textual backdoor attack methods are based on single triggers:\nfor example, inserting specific content into the text to activate the backdoor;\nor changing the abstract text features. The former is easier to be identified\nby existing defense strategies due to its obvious characteristics; the latter,\nalthough improved in invisibility, has certain shortcomings in terms of attack\nperformance, construction of poisoned datasets, and selection of the final\npoisoning rate. On this basis, this paper innovatively proposes a Dual-Trigger\nbackdoor attack based on syntax and mood, and optimizes the construction of the\npoisoned dataset and the selection strategy of the final poisoning rate. A\nlarge number of experimental results show that this method significantly\noutperforms the previous methods based on abstract features in attack\nperformance, and achieves comparable attack performance (almost 100% attack\nsuccess rate) with the insertion-based method. In addition, the two trigger\nmechanisms included in this method can be activated independently in the\napplication phase of the model, which not only improves the flexibility of the\ntrigger style, but also enhances its robustness against defense strategies.\nThese results profoundly reveal that textual backdoor attacks are extremely\nharmful and provide a new perspective for security protection in this field.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17531v1",
    "published_date": "2024-12-23 12:56:30 UTC",
    "updated_date": "2024-12-23 12:56:30 UTC"
  },
  {
    "arxiv_id": "2412.17527v1",
    "title": "Enhancing Cancer Diagnosis with Explainable & Trustworthy Deep Learning Models",
    "authors": [
      "Badaru I. Olumuyiwa",
      "The Anh Han",
      "Zia U. Shamszaman"
    ],
    "abstract": "This research presents an innovative approach to cancer diagnosis and\nprediction using explainable Artificial Intelligence (XAI) and deep learning\ntechniques. With cancer causing nearly 10 million deaths globally in 2020,\nearly and accurate diagnosis is crucial. Traditional methods often face\nchallenges in cost, accuracy, and efficiency. Our study develops an AI model\nthat provides precise outcomes and clear insights into its decision-making\nprocess, addressing the \"black box\" problem of deep learning models. By\nemploying XAI techniques, we enhance interpretability and transparency,\nbuilding trust among healthcare professionals and patients. Our approach\nleverages neural networks to analyse extensive datasets, identifying patterns\nfor cancer detection. This model has the potential to revolutionise diagnosis\nby improving accuracy, accessibility, and clarity in medical decision-making,\npossibly leading to earlier detection and more personalised treatment\nstrategies. Furthermore, it could democratise access to high-quality\ndiagnostics, particularly in resource-limited settings, contributing to global\nhealth equity. The model's applications extend beyond cancer diagnosis,\npotentially transforming various aspects of medical decision-making and saving\nmillions of lives worldwide.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17527v1",
    "published_date": "2024-12-23 12:50:47 UTC",
    "updated_date": "2024-12-23 12:50:47 UTC"
  },
  {
    "arxiv_id": "2412.17524v1",
    "title": "STAHGNet: Modeling Hybrid-grained Heterogenous Dependency Efficiently for Traffic Prediction",
    "authors": [
      "Jiyao Wang",
      "Zehua Peng",
      "Yijia Zhang",
      "Dengbo He",
      "Lei Chen"
    ],
    "abstract": "Traffic flow prediction plays a critical role in the intelligent\ntransportation system, and it is also a challenging task because of the\nunderlying complex Spatio-temporal patterns and heterogeneities evolving across\ntime. However, most present works mostly concentrate on solely capturing\nSpatial-temporal dependency or extracting implicit similarity graphs, but the\nhybrid-granularity evolution is ignored in their modeling process. In this\npaper, we proposed a novel data-driven end-to-end framework, named\nSpatio-Temporal Aware Hybrid Graph Network (STAHGNet), to couple the\nhybrid-grained heterogeneous correlations in series simultaneously through an\nelaborately Hybrid Graph Attention Module (HGAT) and Coarse-granularity\nTemporal Graph (CTG) generator. Furthermore, an automotive feature engineering\nwith domain knowledge and a random neighbor sampling strategy is utilized to\nimprove efficiency and reduce computational complexity. The MAE, RMSE, and MAPE\nare used for evaluation metrics. Tested on four real-life datasets, our\nproposal outperforms eight classical baselines and four state-of-the-art (SOTA)\nmethods (e.g., MAE 14.82 on PeMSD3; MAE 18.92 on PeMSD4). Besides, extensive\nexperiments and visualizations verify the effectiveness of each component in\nSTAHGNet. In terms of computational cost, STAHGNet saves at least four times\nthe space compared to the previous SOTA models. The proposed model will be\nbeneficial for more efficient TFP as well as intelligent transport system\nconstruction.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by Neural Computing and Applications",
    "pdf_url": "http://arxiv.org/pdf/2412.17524v1",
    "published_date": "2024-12-23 12:48:10 UTC",
    "updated_date": "2024-12-23 12:48:10 UTC"
  },
  {
    "arxiv_id": "2412.17523v2",
    "title": "Constructing Fair Latent Space for Intersection of Fairness and Explainability",
    "authors": [
      "Hyungjun Joo",
      "Hyeonggeun Han",
      "Sehwan Kim",
      "Sangwoo Hong",
      "Jungwoo Lee"
    ],
    "abstract": "As the use of machine learning models has increased, numerous studies have\naimed to enhance fairness. However, research on the intersection of fairness\nand explainability remains insufficient, leading to potential issues in gaining\nthe trust of actual users. Here, we propose a novel module that constructs a\nfair latent space, enabling faithful explanation while ensuring fairness. The\nfair latent space is constructed by disentangling and redistributing labels and\nsensitive attributes, allowing the generation of counterfactual explanations\nfor each type of information. Our module is attached to a pretrained generative\nmodel, transforming its biased latent space into a fair latent space.\nAdditionally, since only the module needs to be trained, there are advantages\nin terms of time and cost savings, without the need to train the entire\ngenerative model. We validate the fair latent space with various fairness\nmetrics and demonstrate that our approach can effectively provide explanations\nfor biased decisions and assurances of fairness.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, 5 figures, accepted in AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.17523v2",
    "published_date": "2024-12-23 12:47:04 UTC",
    "updated_date": "2025-01-20 05:44:07 UTC"
  },
  {
    "arxiv_id": "2412.17512v1",
    "title": "BEE: Metric-Adapted Explanations via Baseline Exploration-Exploitation",
    "authors": [
      "Oren Barkan",
      "Yehonatan Elisha",
      "Jonathan Weill",
      "Noam Koenigstein"
    ],
    "abstract": "Two prominent challenges in explainability research involve 1) the nuanced\nevaluation of explanations and 2) the modeling of missing information through\nbaseline representations. The existing literature introduces diverse evaluation\nmetrics, each scrutinizing the quality of explanations through distinct lenses.\nAdditionally, various baseline representations have been proposed, each\nmodeling the notion of missingness differently. Yet, a consensus on the\nultimate evaluation metric and baseline representation remains elusive. This\nwork acknowledges the diversity in explanation metrics and baselines,\ndemonstrating that different metrics exhibit preferences for distinct\nexplanation maps resulting from the utilization of different baseline\nrepresentations and distributions. To address the diversity in metrics and\naccommodate the variety of baseline representations in a unified manner, we\npropose Baseline Exploration-Exploitation (BEE) - a path-integration method\nthat introduces randomness to the integration process by modeling the baseline\nas a learned random tensor. This tensor follows a learned mixture of baseline\ndistributions optimized through a contextual exploration-exploitation procedure\nto enhance performance on the specific metric of interest. By resampling the\nbaseline from the learned distribution, BEE generates a comprehensive set of\nexplanation maps, facilitating the selection of the best-performing explanation\nmap in this broad set for the given metric. Extensive evaluations across\nvarious model architectures showcase the superior performance of BEE in\ncomparison to state-of-the-art explanation methods on a variety of objective\nevaluation metrics.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.17512v1",
    "published_date": "2024-12-23 12:19:03 UTC",
    "updated_date": "2024-12-23 12:19:03 UTC"
  },
  {
    "arxiv_id": "2412.17504v2",
    "title": "An Evaluation Framework for Product Images Background Inpainting based on Human Feedback and Product Consistency",
    "authors": [
      "Yuqi Liang",
      "Jun Luo",
      "Xiaoxi Guo",
      "Jianqi Bi"
    ],
    "abstract": "In product advertising applications, the automated inpainting of backgrounds\nutilizing AI techniques in product images has emerged as a significant task.\nHowever, the techniques still suffer from issues such as inappropriate\nbackground and inconsistent product in generated product images, and existing\napproaches for evaluating the quality of generated product images are mostly\ninconsistent with human feedback causing the evaluation for this task to depend\non manual annotation. To relieve the issues above, this paper proposes Human\nFeedback and Product Consistency (HFPC), which can automatically assess the\ngenerated product images based on two modules. Firstly, to solve inappropriate\nbackgrounds, human feedback on 44,000 automated inpainting product images is\ncollected to train a reward model based on multi-modal features extracted from\nBLIP and comparative learning. Secondly, to filter generated product images\ncontaining inconsistent products, a fine-tuned segmentation model is employed\nto segment the product of the original and generated product images and then\ncompare the differences between the above two. Extensive experiments have\ndemonstrated that HFPC can effectively evaluate the quality of generated\nproduct images and significantly reduce the expense of manual annotation.\nMoreover, HFPC achieves state-of-the-art(96.4% in precision) in comparison to\nother open-source visual-quality-assessment models. Dataset and code are\navailable at:\nhttps://github.com/created-Bi/background_inpainting_products_dataset",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "accepted by AAAI2025",
    "pdf_url": "http://arxiv.org/pdf/2412.17504v2",
    "published_date": "2024-12-23 12:03:35 UTC",
    "updated_date": "2024-12-24 03:21:40 UTC"
  },
  {
    "arxiv_id": "2412.17888v1",
    "title": "Stability Bounds for the Unfolded Forward-Backward Algorithm",
    "authors": [
      "Emilie Chouzenoux",
      "Cecile Della Valle",
      "Jean-Christophe Pesquet"
    ],
    "abstract": "We consider a neural network architecture designed to solve inverse problems\nwhere the degradation operator is linear and known. This architecture is\nconstructed by unrolling a forward-backward algorithm derived from the\nminimization of an objective function that combines a data-fidelity term, a\nTikhonov-type regularization term, and a potentially nonsmooth convex penalty.\nThe robustness of this inversion method to input perturbations is analyzed\ntheoretically. Ensuring robustness complies with the principles of inverse\nproblem theory, as it ensures both the continuity of the inversion method and\nthe resilience to small noise - a critical property given the known\nvulnerability of deep neural networks to adversarial perturbations. A key\nnovelty of our work lies in examining the robustness of the proposed network to\nperturbations in its bias, which represents the observed data in the inverse\nproblem. Additionally, we provide numerical illustrations of the analytical\nLipschitz bounds derived in our analysis.",
    "categories": [
      "math.OC",
      "cs.AI"
    ],
    "primary_category": "math.OC",
    "comment": "arXiv admin note: substantial text overlap with arXiv:2105.15044",
    "pdf_url": "http://arxiv.org/pdf/2412.17888v1",
    "published_date": "2024-12-23 11:55:41 UTC",
    "updated_date": "2024-12-23 11:55:41 UTC"
  },
  {
    "arxiv_id": "2412.17498v3",
    "title": "DRT: Deep Reasoning Translation via Long Chain-of-Thought",
    "authors": [
      "Jiaan Wang",
      "Fandong Meng",
      "Yunlong Liang",
      "Jie Zhou"
    ],
    "abstract": "Recently, O1-like models have emerged as representative examples,\nillustrating the effectiveness of long chain-of-thought (CoT) in reasoning\ntasks such as math and coding tasks. In this paper, we introduce DRT, an\nattempt to bring the success of long CoT to neural machine translation (MT).\nSpecifically, in view of the literature books that might involve similes and\nmetaphors, translating these texts to a target language is very difficult in\npractice due to cultural differences. In such cases, literal translation often\nfails to convey the intended meaning effectively. Even for professional human\ntranslators, considerable thought must be given to preserving semantics\nthroughout the translation process. To simulate LLMs' long thought ability in\nMT, we first mine sentences containing similes or metaphors from existing\nliterature books, and then develop a multi-agent framework to translate these\nsentences via long thought. In the multi-agent framework, a translator is used\nto iteratively translate the source sentence under the suggestions provided by\nan advisor. To ensure the effectiveness of the long thoughts, an evaluator is\nalso employed to quantify the translation quality in each round. In this way,\nwe collect tens of thousands of long-thought MT data, which is used to train\nour DRT. Using Qwen2.5 and LLama-3.1 as the backbones, DRT models can learn the\nthought process during machine translation, and outperform vanilla LLMs as well\nas LLMs which are simply fine-tuning on the paired sentences without long\nthought, showing its effectiveness.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17498v3",
    "published_date": "2024-12-23 11:55:33 UTC",
    "updated_date": "2025-02-10 11:35:28 UTC"
  },
  {
    "arxiv_id": "2412.17490v1",
    "title": "A Toolkit for Virtual Reality Data Collection",
    "authors": [
      "Tim Rolff",
      "Niklas Hypki",
      "Markus Lappe",
      "Frank Steinicke"
    ],
    "abstract": "Due to the still relatively low number of users, acquiring large-scale and\nmultidimensional virtual reality datasets remains a significant challenge.\nConsequently, VR datasets comparable in size to state-of-the-art collections in\nnatural language processing or computer vision are rare or absent. However, the\navailability of such datasets could unlock groundbreaking advancements in\ndeep-learning, psychological modeling, and data analysis in the context of VR.\nIn this paper, we present a versatile data collection toolkit designed to\nfacilitate the capturing of extensive VR datasets. Our toolkit seamlessly\nintegrates with any device, either directly via OpenXR or through the use of a\nvirtual device. Additionally, we introduce a robust data collection pipeline\nthat emphasizes ethical practices (e.g., ensuring data protection and\nregulation) and ensures a standardized, reproducible methodology.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17490v1",
    "published_date": "2024-12-23 11:39:26 UTC",
    "updated_date": "2024-12-23 11:39:26 UTC"
  },
  {
    "arxiv_id": "2412.17487v1",
    "title": "DeepMF: Deep Motion Factorization for Closed-Loop Safety-Critical Driving Scenario Simulation",
    "authors": [
      "Yizhe Li",
      "Linrui Zhang",
      "Xueqian Wang",
      "Houde Liu",
      "Bin Liang"
    ],
    "abstract": "Safety-critical traffic scenarios are of great practical relevance to\nevaluating the robustness of autonomous driving (AD) systems. Given that these\nlong-tail events are extremely rare in real-world traffic data, there is a\ngrowing body of work dedicated to the automatic traffic scenario generation.\nHowever, nearly all existing algorithms for generating safety-critical\nscenarios rely on snippets of previously recorded traffic events, transforming\nnormal traffic flow into accident-prone situations directly. In other words,\nsafety-critical traffic scenario generation is hindsight and not applicable to\nnewly encountered and open-ended traffic events.In this paper, we propose the\nDeep Motion Factorization (DeepMF) framework, which extends static\nsafety-critical driving scenario generation to closed-loop and interactive\nadversarial traffic simulation. DeepMF casts safety-critical traffic simulation\nas a Bayesian factorization that includes the assignment of hazardous traffic\nparticipants, the motion prediction of selected opponents, the reaction\nestimation of autonomous vehicle (AV) and the probability estimation of the\naccident occur. All the aforementioned terms are calculated using decoupled\ndeep neural networks, with inputs limited to the current observation and\nhistorical states. Consequently, DeepMF can effectively and efficiently\nsimulate safety-critical traffic scenarios at any triggered time and for any\nduration by maximizing the compounded posterior probability of traffic risk.\nExtensive experiments demonstrate that DeepMF excels in terms of risk\nmanagement, flexibility, and diversity, showcasing outstanding performance in\nsimulating a wide range of realistic, high-risk traffic scenarios.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17487v1",
    "published_date": "2024-12-23 11:30:24 UTC",
    "updated_date": "2024-12-23 11:30:24 UTC"
  },
  {
    "arxiv_id": "2412.17486v1",
    "title": "Is ChatGPT Massively Used by Students Nowadays? A Survey on the Use of Large Language Models such as ChatGPT in Educational Settings",
    "authors": [
      "Jérémie Sublime",
      "Ilaria Renna"
    ],
    "abstract": "The rapid adoption of Generative AI (GenAI) based on Large Language Models\n(LLMs) such as ChatGPT has recently and profoundly impacted education, offering\ntransformative opportunities while raising significant concerns. In this study\nwe present the results of a survey that investigates how 395 students aged 13\nto 25 years old in France and Italy integrate LLMs into their educational\nroutines.\n  Key findings include the widespread use of these tools across all age groups\nand disciplines, with older students and male students demonstrating higher\nusage frequencies, particularly in scientific contexts. The results also show\ngender disparities, raising concerns about an emerging AI literacy and\ntechnological gender gap. Additionally, while most students utilise LLMs\nconstructively, the lack of systematic proofreading and critical evaluation\namong younger users suggests potential risks to cognitive skills development,\nincluding critical thinking and foundational knowledge. The survey results\nunderscore the need for educational institutions to adapt their curricula to\nintegrate AI tools effectively, promoting ethical use, critical thinking, and\nawareness of AI limitations and environmental costs. This paper provides\nactionable recommendations for fostering equitable and effective cohabitation\nof LLMs and education while addressing emerging challenges.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "33 pages + references",
    "pdf_url": "http://arxiv.org/pdf/2412.17486v1",
    "published_date": "2024-12-23 11:29:44 UTC",
    "updated_date": "2024-12-23 11:29:44 UTC"
  },
  {
    "arxiv_id": "2412.17484v1",
    "title": "Power- and Fragmentation-aware Online Scheduling for GPU Datacenters",
    "authors": [
      "Francesco Lettich",
      "Emanuele Carlini",
      "Franco Maria Nardini",
      "Raffaele Perego",
      "Salvatore Trani"
    ],
    "abstract": "The rise of Artificial Intelligence and Large Language Models is driving\nincreased GPU usage in data centers for complex training and inference tasks,\nimpacting operational costs, energy demands, and the environmental footprint of\nlarge-scale computing infrastructures. This work addresses the online\nscheduling problem in GPU datacenters, which involves scheduling tasks without\nknowledge of their future arrivals. We focus on two objectives: minimizing GPU\nfragmentation and reducing power consumption. GPU fragmentation occurs when\npartial GPU allocations hinder the efficient use of remaining resources,\nespecially as the datacenter nears full capacity. A recent scheduling policy,\nFragmentation Gradient Descent (FGD), leverages a fragmentation metric to\naddress this issue. Reducing power consumption is also crucial due to the\nsignificant power demands of GPUs. To this end, we propose PWR, a novel\nscheduling policy to minimize power usage by selecting power-efficient GPU and\nCPU combinations. This involves a simplified model for measuring power\nconsumption integrated into a Kubernetes score plugin. Through an extensive\nexperimental evaluation in a simulated cluster, we show how PWR, when combined\nwith FGD, achieves a balanced trade-off between reducing power consumption and\nminimizing GPU fragmentation.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "This work has been submitted to the IEEE for possible publication",
    "pdf_url": "http://arxiv.org/pdf/2412.17484v1",
    "published_date": "2024-12-23 11:27:17 UTC",
    "updated_date": "2024-12-23 11:27:17 UTC"
  },
  {
    "arxiv_id": "2412.17478v1",
    "title": "Signal Transformation for Effective Multi-Channel Signal Processing",
    "authors": [
      "Sunil Kumar Kopparapu"
    ],
    "abstract": "Electroencephalography (EEG) is an non-invasive method to record the\nelectrical activity of the brain. The EEG signals are low bandwidth and\nrecorded from multiple electrodes simultaneously in a time synchronized manner.\nTypical EEG signal processing involves extracting features from all the\nindividual channels separately and then fusing these features for downstream\napplications. In this paper, we propose a signal transformation, using basic\nsignal processing, to combine the individual channels of a low-bandwidth\nsignal, like the EEG into a single-channel high-bandwidth signal, like audio.\nFurther this signal transformation is bi-directional, namely the high-bandwidth\nsingle-channel can be transformed to generate the individual low-bandwidth\nsignals without any loss of information. Such a transformation when applied to\nEEG signals overcomes the need to process multiple signals and allows for a\nsingle-channel processing. The advantage of this signal transformation is that\nit allows the use of pre-trained single-channel pre-trained models, for\nmulti-channel signal processing and analysis. We further show the utility of\nthe signal transformation on publicly available EEG dataset.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "5 Figures",
    "pdf_url": "http://arxiv.org/pdf/2412.17478v1",
    "published_date": "2024-12-23 11:09:53 UTC",
    "updated_date": "2024-12-23 11:09:53 UTC"
  },
  {
    "arxiv_id": "2501.14756v1",
    "title": "Towards An Automated AI Act FRIA Tool That Can Reuse GDPR's DPIA",
    "authors": [
      "Tytti Rintamaki",
      "Harshvardhan J. Pandit"
    ],
    "abstract": "The AI Act introduces the obligation to conduct a Fundamental Rights Impact\nAssessment (FRIA), with the possibility to reuse a Data Protection Impact\nAssessment (DPIA), and requires the EU Commission to create of an automated\ntool to support the FRIA process. In this article, we provide our novel\nexploration of the DPIA and FRIA as information processes to enable the\ncreation of automated tools. We first investigate the information involved in\nDPIA and FRIA, and then use this to align the two to state where a DPIA can be\nreused in a FRIA. We then present the FRIA as a 5-step process and discuss the\nrole of an automated tool for each step. Our work provides the necessary\nfoundation for creating and managing information for FRIA and supporting it\nthrough an automated tool as required by the AI Act.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "Presented at CLAIRvoyant (ConventicLE on Artificial Intelligence\n  Regulation) Workshop 2024",
    "pdf_url": "http://arxiv.org/pdf/2501.14756v1",
    "published_date": "2024-12-23 10:46:55 UTC",
    "updated_date": "2024-12-23 10:46:55 UTC"
  },
  {
    "arxiv_id": "2412.17468v1",
    "title": "Line Graph Vietoris-Rips Persistence Diagram for Topological Graph Representation Learning",
    "authors": [
      "Jaesun Shin",
      "Eunjoo Jeon",
      "Taewon Cho",
      "Namkyeong Cho",
      "Youngjune Gwon"
    ],
    "abstract": "While message passing graph neural networks result in informative node\nembeddings, they may suffer from describing the topological properties of\ngraphs. To this end, node filtration has been widely used as an attempt to\nobtain the topological information of a graph using persistence diagrams.\nHowever, these attempts have faced the problem of losing node embedding\ninformation, which in turn prevents them from providing a more expressive graph\nrepresentation. To tackle this issue, we shift our focus to edge filtration and\nintroduce a novel edge filtration-based persistence diagram, named Topological\nEdge Diagram (TED), which is mathematically proven to preserve node embedding\ninformation as well as contain additional topological information. To implement\nTED, we propose a neural network based algorithm, named Line Graph\nVietoris-Rips (LGVR) Persistence Diagram, that extracts edge information by\ntransforming a graph into its line graph. Through LGVR, we propose two model\nframeworks that can be applied to any message passing GNNs, and prove that they\nare strictly more powerful than Weisfeiler-Lehman type colorings. Finally we\nempirically validate superior performance of our models on several graph\nclassification and regression benchmarks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.AT"
    ],
    "primary_category": "cs.LG",
    "comment": "36 pages. Accepted to Journal of Machine Learning Research",
    "pdf_url": "http://arxiv.org/pdf/2412.17468v1",
    "published_date": "2024-12-23 10:46:44 UTC",
    "updated_date": "2024-12-23 10:46:44 UTC"
  },
  {
    "arxiv_id": "2412.17458v1",
    "title": "Progressive Boundary Guided Anomaly Synthesis for Industrial Anomaly Detection",
    "authors": [
      "Qiyu Chen",
      "Huiyuan Luo",
      "Han Gao",
      "Chengkan Lv",
      "Zhengtao Zhang"
    ],
    "abstract": "Unsupervised anomaly detection methods can identify surface defects in\nindustrial images by leveraging only normal samples for training. Due to the\nrisk of overfitting when learning from a single class, anomaly synthesis\nstrategies are introduced to enhance detection capability by generating\nartificial anomalies. However, existing strategies heavily rely on anomalous\ntextures from auxiliary datasets. Moreover, their limitations in the coverage\nand directionality of anomaly synthesis may result in a failure to capture\nuseful information and lead to significant redundancy. To address these issues,\nwe propose a novel Progressive Boundary-guided Anomaly Synthesis (PBAS)\nstrategy, which can directionally synthesize crucial feature-level anomalies\nwithout auxiliary textures. It consists of three core components: Approximate\nBoundary Learning (ABL), Anomaly Feature Synthesis (AFS), and Refined Boundary\nOptimization (RBO). To make the distribution of normal samples more compact,\nABL first learns an approximate decision boundary by center constraint, which\nimproves the center initialization through feature alignment. AFS then\ndirectionally synthesizes anomalies with more flexible scales guided by the\nhypersphere distribution of normal features. Since the boundary is so loose\nthat it may contain real anomalies, RBO refines the decision boundary through\nthe binary classification of artificial anomalies and normal features.\nExperimental results show that our method achieves state-of-the-art performance\nand the fastest detection speed on three widely used industrial datasets,\nincluding MVTec AD, VisA, and MPDD. The code will be available at:\nhttps://github.com/cqylunlun/PBAS.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by IEEE Transactions on Circuits and Systems for Video\n  Technology",
    "pdf_url": "http://arxiv.org/pdf/2412.17458v1",
    "published_date": "2024-12-23 10:26:26 UTC",
    "updated_date": "2024-12-23 10:26:26 UTC"
  },
  {
    "arxiv_id": "2412.17456v1",
    "title": "Developmental Predictive Coding Model for Early Infancy Mono and Bilingual Vocal Continual Learning",
    "authors": [
      "Xiaodan Chen",
      "Alexandre Pitti",
      "Mathias Quoy",
      "Nancy F Chen"
    ],
    "abstract": "Understanding how infants perceive speech sounds and language structures is\nstill an open problem. Previous research in artificial neural networks has\nmainly focused on large dataset-dependent generative models, aiming to\nreplicate language-related phenomena such as ''perceptual narrowing''. In this\npaper, we propose a novel approach using a small-sized generative neural\nnetwork equipped with a continual learning mechanism based on predictive coding\nfor mono-and bilingual speech sound learning (referred to as language sound\nacquisition during ''critical period'') and a compositional optimization\nmechanism for generation where no learning is involved (later infancy sound\nimitation). Our model prioritizes interpretability and demonstrates the\nadvantages of online learning: Unlike deep networks requiring substantial\noffline training, our model continuously updates with new data, making it\nadaptable and responsive to changing inputs. Through experiments, we\ndemonstrate that if second language acquisition occurs during later infancy,\nthe challenges associated with learning a foreign language after the critical\nperiod amplify, replicating the perceptual narrowing effect.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17456v1",
    "published_date": "2024-12-23 10:23:47 UTC",
    "updated_date": "2024-12-23 10:23:47 UTC"
  },
  {
    "arxiv_id": "2412.17451v1",
    "title": "Diving into Self-Evolving Training for Multimodal Reasoning",
    "authors": [
      "Wei Liu",
      "Junlong Li",
      "Xiwen Zhang",
      "Fan Zhou",
      "Yu Cheng",
      "Junxian He"
    ],
    "abstract": "Reasoning ability is essential for Large Multimodal Models (LMMs). In the\nabsence of multimodal chain-of-thought annotated data, self-evolving training,\nwhere the model learns from its own outputs, has emerged as an effective and\nscalable approach for enhancing reasoning abilities. Despite its growing usage,\na comprehensive understanding of self-evolving training, particularly in the\ncontext of multimodal reasoning, remains limited. In this paper, we delve into\nthe intricacies of self-evolving training for multimodal reasoning, pinpointing\nthree key factors: Training Method, Reward Model, and Prompt Variation. We\nsystematically examine each factor and explore how various configurations\naffect the training's effectiveness. Our analysis leads to a set of best\npractices for each factor, aimed at optimizing multimodal reasoning.\nFurthermore, we explore the Self-Evolution Dynamics during training and the\nimpact of automatic balancing mechanisms in boosting performance. After all the\ninvestigations, we present a final recipe for self-evolving training in\nmultimodal reasoning, encapsulating these design choices into a framework we\ncall MSTaR (Multimodal Self-evolving Training for Reasoning), which is\nuniversally effective for models with different sizes on various benchmarks,\ne.g., surpassing the pre-evolved model significantly on 5 multimodal reasoning\nbenchmarks without using additional human annotations, as demonstrated on\nMiniCPM-V-2.5 (8B), Phi-3.5-Vision (4B) and InternVL2 (2B). We believe this\nstudy fills a significant gap in the understanding of self-evolving training\nfor multimodal reasoning and offers a robust framework for future research. Our\npolicy and reward models, as well as the collected data, is released to\nfacilitate further investigation in multimodal reasoning.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Project Page: https://mstar-lmm.github.io",
    "pdf_url": "http://arxiv.org/pdf/2412.17451v1",
    "published_date": "2024-12-23 10:18:41 UTC",
    "updated_date": "2024-12-23 10:18:41 UTC"
  },
  {
    "arxiv_id": "2412.17449v1",
    "title": "Applying LLM and Topic Modelling in Psychotherapeutic Contexts",
    "authors": [
      "Alexander Vanin",
      "Vadim Bolshev",
      "Anastasia Panfilova"
    ],
    "abstract": "This study explores the use of Large language models to analyze therapist\nremarks in a psychotherapeutic setting. The paper focuses on the application of\nBERTopic, a machine learning-based topic modeling tool, to the dialogue of two\ndifferent groups of therapists (classical and modern), which makes it possible\nto identify and describe a set of topics that consistently emerge across these\ngroups. The paper describes in detail the chosen algorithm for BERTopic, which\nincluded creating a vector space from a corpus of therapist remarks, reducing\nits dimensionality, clustering the space, and creating and optimizing topic\nrepresentation. Along with the automatic topical modeling by the BERTopic, the\nresearch involved an expert assessment of the findings and manual topic\nstructure optimization. The topic modeling results highlighted the most common\nand stable topics in therapists speech, offering insights into how language\npatterns in therapy develop and remain stable across different therapeutic\nstyles. This work contributes to the growing field of machine learning in\npsychotherapy by demonstrating the potential of automated methods to improve\nboth the practice and training of therapists. The study highlights the value of\ntopic modeling as a tool for gaining a deeper understanding of therapeutic\ndialogue and offers new opportunities for improving therapeutic effectiveness\nand clinical supervision.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.7, J.4"
    ],
    "primary_category": "cs.LG",
    "comment": "18 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.17449v1",
    "published_date": "2024-12-23 10:14:32 UTC",
    "updated_date": "2024-12-23 10:14:32 UTC"
  },
  {
    "arxiv_id": "2412.17440v1",
    "title": "The Role of XAI in Transforming Aeronautics and Aerospace Systems",
    "authors": [
      "Francisco Javier Cantero Zorita",
      "Mikel Galafate",
      "Javier M. Moguerza",
      "Isaac Martín de Diego",
      "M. Teresa Gonzalez",
      "Gema Gutierrez Peña"
    ],
    "abstract": "Recent advancements in Artificial Intelligence (AI) have transformed\ndecision-making in aeronautics and aerospace. These advancements in AI have\nbrought with them the need to understand the reasons behind the predictions\ngenerated by AI systems and models, particularly by professionals in these\nsectors. In this context, the emergence of eXplainable Artificial Intelligence\n(XAI) has helped bridge the gap between professionals in the aeronautical and\naerospace sectors and the AI systems and models they work with. For this\nreason, this paper provides a review of the concept of XAI is carried out\ndefining the term and the objectives it aims to achieve. Additionally, the\npaper discusses the types of models defined within it and the properties these\nmodels must fulfill to be considered transparent, as well as the post-hoc\ntechniques used to understand AI systems and models after their training.\nFinally, various application areas within the aeronautical and aerospace\nsectors will be presented, highlighting how XAI is used in these fields to help\nprofessionals understand the functioning of AI systems and models.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17440v1",
    "published_date": "2024-12-23 10:02:17 UTC",
    "updated_date": "2024-12-23 10:02:17 UTC"
  },
  {
    "arxiv_id": "2412.17438v2",
    "title": "Markov Process-Based Graph Convolutional Networks for Entity Classification in Knowledge Graphs",
    "authors": [
      "Johannes Mäkelburg",
      "Yiwen Peng",
      "Mehwish Alam",
      "Tobias Weller",
      "Maribel Acosta"
    ],
    "abstract": "Despite the vast amount of information encoded in Knowledge Graphs (KGs),\ninformation about the class affiliation of entities remains often incomplete.\nGraph Convolutional Networks (GCNs) have been shown to be effective predictors\nof complete information about the class affiliation of entities in KGs.\nHowever, these models do not learn the class affiliation of entities in KGs\nincorporating the complexity of the task, which negatively affects the models\nprediction capabilities. To address this problem, we introduce a Markov\nprocess-based architecture into well-known GCN architectures. This end-to-end\nnetwork learns the prediction of class affiliation of entities in KGs within a\nMarkov process. The number of computational steps is learned during training\nusing a geometric distribution. At the same time, the loss function combines\ninsights from the field of evidential learning. The experiments show a\nperformance improvement over existing models in several studied architectures\nand datasets. Based on the chosen hyperparameters for the geometric\ndistribution, the expected number of computation steps can be adjusted to\nimprove efficiency and accuracy during training.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17438v2",
    "published_date": "2024-12-23 09:59:49 UTC",
    "updated_date": "2024-12-27 11:49:53 UTC"
  },
  {
    "arxiv_id": "2412.17432v1",
    "title": "Neural Continuous-Time Supermartingale Certificates",
    "authors": [
      "Grigory Neustroev",
      "Mirco Giacobbe",
      "Anna Lukina"
    ],
    "abstract": "We introduce for the first time a neural-certificate framework for\ncontinuous-time stochastic dynamical systems. Autonomous learning systems in\nthe physical world demand continuous-time reasoning, yet existing learnable\ncertificates for probabilistic verification assume discretization of the time\ncontinuum. Inspired by the success of training neural Lyapunov certificates for\ndeterministic continuous-time systems and neural supermartingale certificates\nfor stochastic discrete-time systems, we propose a framework that bridges the\ngap between continuous-time and probabilistic neural certification for\ndynamical systems under complex requirements. Our method combines machine\nlearning and symbolic reasoning to produce formally certified bounds on the\nprobabilities that a nonlinear system satisfies specifications of reachability,\navoidance, and persistence. We present both the theoretical justification and\nthe algorithmic implementation of our framework and showcase its efficacy on\npopular benchmarks.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17432v1",
    "published_date": "2024-12-23 09:51:54 UTC",
    "updated_date": "2024-12-23 09:51:54 UTC"
  },
  {
    "arxiv_id": "2412.17415v2",
    "title": "VidCtx: Context-aware Video Question Answering with Image Models",
    "authors": [
      "Andreas Goulas",
      "Vasileios Mezaris",
      "Ioannis Patras"
    ],
    "abstract": "To address computational and memory limitations of Large Multimodal Models in\nthe Video Question-Answering task, several recent methods extract textual\nrepresentations per frame (e.g., by captioning) and feed them to a Large\nLanguage Model (LLM) that processes them to produce the final response.\nHowever, in this way, the LLM does not have access to visual information and\noften has to process repetitive textual descriptions of nearby frames. To\naddress those shortcomings, in this paper, we introduce VidCtx, a novel\ntraining-free VideoQA framework which integrates both modalities, i.e. both\nvisual information from input frames and textual descriptions of others frames\nthat give the appropriate context. More specifically, in the proposed framework\na pre-trained Large Multimodal Model (LMM) is prompted to extract at regular\nintervals, question-aware textual descriptions (captions) of video frames.\nThose will be used as context when the same LMM will be prompted to answer the\nquestion at hand given as input a) a certain frame, b) the question and c) the\ncontext/caption of an appropriate frame. To avoid redundant information, we\nchose as context the descriptions of distant frames. Finally, a simple yet\neffective max pooling mechanism is used to aggregate the frame-level decisions.\nThis methodology enables the model to focus on the relevant segments of the\nvideo and scale to a high number of frames. Experiments show that VidCtx\nachieves competitive performance among approaches that rely on open models on\nthree public Video QA benchmarks, NExT-QA, IntentQA and STAR. Our code is\navailable at https://github.com/IDT-ITI/VidCtx.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted in IEEE ICME 2025. This is the authors' accepted version",
    "pdf_url": "http://arxiv.org/pdf/2412.17415v2",
    "published_date": "2024-12-23 09:26:38 UTC",
    "updated_date": "2025-04-07 11:20:37 UTC"
  },
  {
    "arxiv_id": "2412.17411v2",
    "title": "Pretraining with random noise for uncertainty calibration",
    "authors": [
      "Jeonghwan Cheon",
      "Se-Bum Paik"
    ],
    "abstract": "Uncertainty calibration is crucial for various machine learning applications,\nyet it remains challenging. Many models exhibit hallucinations - confident yet\ninaccurate responses - due to miscalibrated confidence. Here, we show that the\ncommon practice of random initialization in deep learning, often considered a\nstandard technique, is an underlying cause of this miscalibration, leading to\nexcessively high confidence in untrained networks. Our method, inspired by\ndevelopmental neuroscience, addresses this issue by simply pretraining networks\nwith random noise and labels, reducing overconfidence and bringing initial\nconfidence levels closer to chance. This ensures optimal calibration, aligning\nconfidence with accuracy during subsequent data training, without the need for\nadditional pre- or post-processing. Pre-calibrated networks excel at\nidentifying \"unknown data,\" showing low confidence for out-of-distribution\ninputs, thereby resolving confidence miscalibration.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17411v2",
    "published_date": "2024-12-23 09:22:00 UTC",
    "updated_date": "2025-03-27 12:34:23 UTC"
  },
  {
    "arxiv_id": "2412.17404v2",
    "title": "BrainMAP: Learning Multiple Activation Pathways in Brain Networks",
    "authors": [
      "Song Wang",
      "Zhenyu Lei",
      "Zhen Tan",
      "Jiaqi Ding",
      "Xinyu Zhao",
      "Yushun Dong",
      "Guorong Wu",
      "Tianlong Chen",
      "Chen Chen",
      "Aiying Zhang",
      "Jundong Li"
    ],
    "abstract": "Functional Magnetic Resonance Image (fMRI) is commonly employed to study\nhuman brain activity, since it offers insight into the relationship between\nfunctional fluctuations and human behavior. To enhance analysis and\ncomprehension of brain activity, Graph Neural Networks (GNNs) have been widely\napplied to the analysis of functional connectivities (FC) derived from fMRI\ndata, due to their ability to capture the synergistic interactions among brain\nregions. However, in the human brain, performing complex tasks typically\ninvolves the activation of certain pathways, which could be represented as\npaths across graphs. As such, conventional GNNs struggle to learn from these\npathways due to the long-range dependencies of multiple pathways. To address\nthese challenges, we introduce a novel framework BrainMAP to learn Multiple\nActivation Pathways in Brain networks. BrainMAP leverages sequential models to\nidentify long-range correlations among sequentialized brain regions and\nincorporates an aggregation module based on Mixture of Experts (MoE) to learn\nfrom multiple pathways. Our comprehensive experiments highlight BrainMAP's\nsuperior performance. Furthermore, our framework enables explanatory analyses\nof crucial brain regions involved in tasks. Our code is provided at\nhttps://github.com/LzyFischer/Graph-Mamba.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.17404v2",
    "published_date": "2024-12-23 09:13:35 UTC",
    "updated_date": "2025-02-01 04:50:59 UTC"
  },
  {
    "arxiv_id": "2412.17387v3",
    "title": "Singular Value Scaling: Efficient Generative Model Compression via Pruned Weights Refinement",
    "authors": [
      "Hyeonjin Kim",
      "Jaejun Yoo"
    ],
    "abstract": "While pruning methods effectively maintain model performance without extra\ntraining costs, they often focus solely on preserving crucial connections,\noverlooking the impact of pruned weights on subsequent fine-tuning or\ndistillation, leading to inefficiencies. Moreover, most compression techniques\nfor generative models have been developed primarily for GANs, tailored to\nspecific architectures like StyleGAN, and research into compressing Diffusion\nmodels has just begun. Even more, these methods are often applicable only to\nGANs or Diffusion models, highlighting the need for approaches that work across\nboth model types. In this paper, we introduce Singular Value Scaling (SVS), a\nversatile technique for refining pruned weights, applicable to both model\ntypes. Our analysis reveals that pruned weights often exhibit dominant singular\nvectors, hindering fine-tuning efficiency and leading to suboptimal performance\ncompared to random initialization. Our method enhances weight initialization by\nminimizing the disparities between singular values of pruned weights, thereby\nimproving the fine-tuning process. This approach not only guides the compressed\nmodel toward superior solutions but also significantly speeds up fine-tuning.\nExtensive experiments on StyleGAN2, StyleGAN3 and DDPM demonstrate that SVS\nimproves compression performance across model types without additional training\ncosts. Our code is available at:\nhttps://github.com/LAIT-CVLab/Singular-Value-Scaling.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.17387v3",
    "published_date": "2024-12-23 08:40:08 UTC",
    "updated_date": "2025-03-31 11:10:55 UTC"
  },
  {
    "arxiv_id": "2501.14755v1",
    "title": "Data-Juicer 2.0: Cloud-Scale Adaptive Data Processing for Foundation Models",
    "authors": [
      "Daoyuan Chen",
      "Yilun Huang",
      "Xuchen Pan",
      "Nana Jiang",
      "Haibin Wang",
      "Ce Ge",
      "Yushuo Chen",
      "Wenhao Zhang",
      "Zhijian Ma",
      "Yilei Zhang",
      "Jun Huang",
      "Wei Lin",
      "Yaliang Li",
      "Bolin Ding",
      "Jingren Zhou"
    ],
    "abstract": "The burgeoning field of foundation models necessitates advanced data\nprocessing mechanisms capable of harnessing vast valuable data with varied\ntypes utilized by these models. Nevertheless, the current landscape presents\nunique challenges that traditional data processing frameworks cannot handle\neffectively, especially with multimodal intricacies. In response, we present\nData-Juicer 2.0, a new system offering fruitful data processing capabilities\nbacked by over a hundred operators spanning various modalities like text,\nimage, audio, and video. With seamless compatibility and dedicated optimization\nto popular dataset hubs like Hugging Face and computing engines like Ray,\nData-Juicer 2.0 enhances its predecessor in both usability, efficiency, and\nprogrammability. It features an easily accessible user interface layer that\nsupports decoupled Python interactions, RESTful APIs, and conversational\ncommands. Alongside this, it contains a core runtime layer optimized for\nadaptive execution and management across different dataset scales, processing\ndemands, and computational environments, while shielding unnecessary system\ndetails. Extensive empirical evaluations demonstrate Data-Juicer 2.0's\nremarkable performance and scalability, highlighting its capability to\nefficiently process tens of billions of data samples with tens of thousands of\nCPU cores. The system is publicly available, actively maintained, and broadly\nadopted in diverse research endeavors, practical applications, and real-world\nproducts such as Alibaba Cloud PAI.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "16 pages, 9 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2501.14755v1",
    "published_date": "2024-12-23 08:29:57 UTC",
    "updated_date": "2024-12-23 08:29:57 UTC"
  },
  {
    "arxiv_id": "2412.17377v1",
    "title": "A Plug-and-Play Physical Motion Restoration Approach for In-the-Wild High-Difficulty Motions",
    "authors": [
      "Youliang Zhang",
      "Ronghui Li",
      "Yachao Zhang",
      "Liang Pan",
      "Jingbo Wang",
      "Yebin Liu",
      "Xiu Li"
    ],
    "abstract": "Extracting physically plausible 3D human motion from videos is a critical\ntask. Although existing simulation-based motion imitation methods can enhance\nthe physical quality of daily motions estimated from monocular video capture,\nextending this capability to high-difficulty motions remains an open challenge.\nThis can be attributed to some flawed motion clips in video-based motion\ncapture results and the inherent complexity in modeling high-difficulty\nmotions. Therefore, sensing the advantage of segmentation in localizing human\nbody, we introduce a mask-based motion correction module (MCM) that leverages\nmotion context and video mask to repair flawed motions, producing\nimitation-friendly motions; and propose a physics-based motion transfer module\n(PTM), which employs a pretrain and adapt approach for motion imitation,\nimproving physical plausibility with the ability to handle in-the-wild and\nchallenging motions. Our approach is designed as a plug-and-play module to\nphysically refine the video motion capture results, including high-difficulty\nin-the-wild motions. Finally, to validate our approach, we collected a\nchallenging in-the-wild test set to establish a benchmark, and our method has\ndemonstrated effectiveness on both the new benchmark and existing public\ndatasets.https://physicalmotionrestoration.github.io",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17377v1",
    "published_date": "2024-12-23 08:26:00 UTC",
    "updated_date": "2024-12-23 08:26:00 UTC"
  },
  {
    "arxiv_id": "2412.17373v1",
    "title": "FRTP: Federating Route Search Records to Enhance Long-term Traffic Prediction",
    "authors": [
      "Hangli Ge",
      "Xiaojie Yang",
      "Itsuki Matsunaga",
      "Dizhi Huang",
      "Noboru Koshizuka"
    ],
    "abstract": "Accurate traffic prediction, especially predicting traffic conditions several\ndays in advance is essential for intelligent transportation systems (ITS). Such\npredictions enable mid- and long-term traffic optimization, which is crucial\nfor efficient transportation planning. However, the inclusion of diverse\nexternal features, alongside the complexities of spatial relationships and\ntemporal uncertainties, significantly increases the complexity of forecasting\nmodels. Additionally, traditional approaches have handled data preprocessing\nseparately from the learning model, leading to inefficiencies caused by\nrepeated trials of preprocessing and training. In this study, we propose a\nfederated architecture capable of learning directly from raw data with varying\nfeatures and time granularities or lengths. The model adopts a unified design\nthat accommodates different feature types, time scales, and temporal periods.\nOur experiments focus on federating route search records and begin by\nprocessing raw data within the model framework. Unlike traditional models, this\napproach integrates the data federation phase into the learning process,\nenabling compatibility with various time frequencies and input/output\nconfigurations. The accuracy of the proposed model is demonstrated through\nevaluations using diverse learning patterns and parameter settings. The results\nshow that online search log data is useful for forecasting long-term traffic,\nhighlighting the model's adaptability and efficiency.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by IEEE BigData 2024",
    "pdf_url": "http://arxiv.org/pdf/2412.17373v1",
    "published_date": "2024-12-23 08:14:20 UTC",
    "updated_date": "2024-12-23 08:14:20 UTC"
  },
  {
    "arxiv_id": "2412.17365v1",
    "title": "Boosting LLM via Learning from Data Iteratively and Selectively",
    "authors": [
      "Qi Jia",
      "Siyu Ren",
      "Ziheng Qin",
      "Fuzhao Xue",
      "Jinjie Ni",
      "Yang You"
    ],
    "abstract": "Datasets nowadays are generally constructed from multiple sources and using\ndifferent synthetic techniques, making data de-noising and de-duplication\ncrucial before being used for post-training. In this work, we propose to\nperform instruction tuning by iterative data selection (\\ApproachName{}). We\nmeasure the quality of a sample from complexity and diversity simultaneously.\nInstead of calculating the complexity score once for all before fine-tuning, we\nhighlight the importance of updating this model-specific score during\nfine-tuning to accurately accommodate the dynamic changes of the model. On the\nother hand, the diversity score is defined on top of the samples' responses\nunder the consideration of their informativeness. IterIT integrates the\nstrengths of both worlds by iteratively updating the complexity score for the\ntop-ranked samples and greedily selecting the ones with the highest\ncomplexity-diversity score. Experiments on multiple instruction-tuning data\ndemonstrate consistent improvements of IterIT over strong baselines. Moreover,\nour approach also generalizes well to domain-specific scenarios and different\nbackbone models. All resources will be available at\nhttps://github.com/JiaQiSJTU/IterIT.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17365v1",
    "published_date": "2024-12-23 08:01:24 UTC",
    "updated_date": "2024-12-23 08:01:24 UTC"
  },
  {
    "arxiv_id": "2412.17364v1",
    "title": "Efficient fine-tuning methodology of text embedding models for information retrieval: contrastive learning penalty (clp)",
    "authors": [
      "Jeongsu Yu"
    ],
    "abstract": "Text embedding models play a crucial role in natural language processing,\nparticularly in information retrieval, and their importance is further\nhighlighted with the recent utilization of RAG (Retrieval- Augmented\nGeneration). This study presents an efficient fine-tuning methodology\nencompassing data selection, loss function, and model architecture to enhance\nthe information retrieval performance of pre-trained text embedding models. In\nparticular, this study proposes a novel Contrastive Learning Penalty function\nthat overcomes the limitations of existing Contrastive Learning. The proposed\nmethodology achieves significant performance improvements over existing methods\nin document retrieval tasks. This study is expected to contribute to improving\nthe performance of information retrieval systems through fine-tuning of text\nembedding models. The code for this study can be found at\nhttps://github.com/CreaLabs/Enhanced-BGE-M3-with-CLP-and-MoE, and the\nbest-performing model can be found at https://huggingface.co/CreaLabs.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "68T50, 68P20",
      "H.3.3; I.2.7"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17364v1",
    "published_date": "2024-12-23 07:55:22 UTC",
    "updated_date": "2024-12-23 07:55:22 UTC"
  },
  {
    "arxiv_id": "2412.17346v1",
    "title": "FFA Sora, video generation as fundus fluorescein angiography simulator",
    "authors": [
      "Xinyuan Wu",
      "Lili Wang",
      "Ruoyu Chen",
      "Bowen Liu",
      "Weiyi Zhang",
      "Xi Yang",
      "Yifan Feng",
      "Mingguang He",
      "Danli Shi"
    ],
    "abstract": "Fundus fluorescein angiography (FFA) is critical for diagnosing retinal\nvascular diseases, but beginners often struggle with image interpretation. This\nstudy develops FFA Sora, a text-to-video model that converts FFA reports into\ndynamic videos via a Wavelet-Flow Variational Autoencoder (WF-VAE) and a\ndiffusion transformer (DiT). Trained on an anonymized dataset, FFA Sora\naccurately simulates disease features from the input text, as confirmed by\nobjective metrics: Frechet Video Distance (FVD) = 329.78, Learned Perceptual\nImage Patch Similarity (LPIPS) = 0.48, and Visual-question-answering Score\n(VQAScore) = 0.61. Specific evaluations showed acceptable alignment between the\ngenerated videos and textual prompts, with BERTScore of 0.35. Additionally, the\nmodel demonstrated strong privacy-preserving performance in retrieval\nevaluations, achieving an average Recall@K of 0.073. Human assessments\nindicated satisfactory visual quality, with an average score of 1.570(scale: 1\n= best, 5 = worst). This model addresses privacy concerns associated with\nsharing large-scale FFA data and enhances medical education.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "24 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.17346v1",
    "published_date": "2024-12-23 07:18:13 UTC",
    "updated_date": "2024-12-23 07:18:13 UTC"
  },
  {
    "arxiv_id": "2412.17339v1",
    "title": "MineAgent: Towards Remote-Sensing Mineral Exploration with Multimodal Large Language Models",
    "authors": [
      "Beibei Yu",
      "Tao Shen",
      "Hongbin Na",
      "Ling Chen",
      "Denqi Li"
    ],
    "abstract": "Remote-sensing mineral exploration is critical for identifying economically\nviable mineral deposits, yet it poses significant challenges for multimodal\nlarge language models (MLLMs). These include limitations in domain-specific\ngeological knowledge and difficulties in reasoning across multiple\nremote-sensing images, further exacerbating long-context issues. To address\nthese, we present MineAgent, a modular framework leveraging hierarchical\njudging and decision-making modules to improve multi-image reasoning and\nspatial-spectral integration. Complementing this, we propose MineBench, a\nbenchmark specific for evaluating MLLMs in domain-specific mineral exploration\ntasks using geological and hyperspectral data. Extensive experiments\ndemonstrate the effectiveness of MineAgent, highlighting its potential to\nadvance MLLMs in remote-sensing mineral exploration.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17339v1",
    "published_date": "2024-12-23 07:08:14 UTC",
    "updated_date": "2024-12-23 07:08:14 UTC"
  },
  {
    "arxiv_id": "2412.17338v1",
    "title": "Enhancing Topic Interpretability for Neural Topic Modeling through Topic-wise Contrastive Learning",
    "authors": [
      "Xin Gao",
      "Yang Lin",
      "Ruiqing Li",
      "Yasha Wang",
      "Xu Chu",
      "Xinyu Ma",
      "Hailong Yu"
    ],
    "abstract": "Data mining and knowledge discovery are essential aspects of extracting\nvaluable insights from vast datasets. Neural topic models (NTMs) have emerged\nas a valuable unsupervised tool in this field. However, the predominant\nobjective in NTMs, which aims to discover topics maximizing data likelihood,\noften lacks alignment with the central goals of data mining and knowledge\ndiscovery which is to reveal interpretable insights from large data\nrepositories. Overemphasizing likelihood maximization without incorporating\ntopic regularization can lead to an overly expansive latent space for topic\nmodeling. In this paper, we present an innovative approach to NTMs that\naddresses this misalignment by introducing contrastive learning measures to\nassess topic interpretability. We propose a novel NTM framework, named\nContraTopic, that integrates a differentiable regularizer capable of evaluating\nmultiple facets of topic interpretability throughout the training process. Our\nregularizer adopts a unique topic-wise contrastive methodology, fostering both\ninternal coherence within topics and clear external distinctions among them.\nComprehensive experiments conducted on three diverse datasets demonstrate that\nour approach consistently produces topics with superior interpretability\ncompared to state-of-the-art NTMs.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17338v1",
    "published_date": "2024-12-23 07:07:06 UTC",
    "updated_date": "2024-12-23 07:07:06 UTC"
  },
  {
    "arxiv_id": "2412.17336v1",
    "title": "APEX$^2$: Adaptive and Extreme Summarization for Personalized Knowledge Graphs",
    "authors": [
      "Zihao Li",
      "Dongqi Fu",
      "Mengting Ai",
      "Jingrui He"
    ],
    "abstract": "Knowledge graphs (KGs), which store an extensive number of relational facts,\nserve various applications. Recently, personalized knowledge graphs (PKGs) have\nemerged as a solution to optimize storage costs by customizing their content to\nalign with users' specific interests within particular domains. In the real\nworld, on one hand, user queries and their underlying interests are inherently\nevolving, requiring PKGs to adapt continuously; on the other hand, the\nsummarization is constantly expected to be as small as possible in terms of\nstorage cost. However, the existing PKG summarization methods implicitly assume\nthat the user's interests are constant and do not shift. Furthermore, when the\nsize constraint of PKG is extremely small, the existing methods cannot\ndistinguish which facts are more of immediate interest and guarantee the\nutility of the summarized PKG. To address these limitations, we propose\nAPEX$^2$, a highly scalable PKG summarization framework designed with robust\ntheoretical guarantees to excel in adaptive summarization tasks with extremely\nsmall size constraints. To be specific, after constructing an initial PKG,\nAPEX$^2$ continuously tracks the interest shift and adjusts the previous\nsummary. We evaluate APEX$^2$ under an evolving query setting on benchmark KGs\ncontaining up to 12 million triples, summarizing with compression ratios $\\leq\n0.1\\%$. The experiments show that APEX outperforms state-of-the-art baselines\nin terms of both query-answering accuracy and efficiency.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DB",
      "cs.SC"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by KDD 2025. 27 pages",
    "pdf_url": "http://arxiv.org/pdf/2412.17336v1",
    "published_date": "2024-12-23 07:02:06 UTC",
    "updated_date": "2024-12-23 07:02:06 UTC"
  },
  {
    "arxiv_id": "2412.17334v1",
    "title": "Complete Implementation of WXF Chinese Chess Rules",
    "authors": [
      "Daniel Tan",
      "Neftali Watkinson Medina"
    ],
    "abstract": "Unlike repetitions in Western Chess where all repetitions are draws,\nrepetitions in Chinese Chess could result in a win, draw, or loss depending on\nthe kind of repetition being made by both players. One of the biggest hurdles\nfacing Chinese Chess application development is a proper system for judging\ngames correctly. This paper introduces a complete algorithm for ruling the WXF\nrules correctly in all 110 example cases found in the WXF manual. We introduce\nseveral novel optimizations for speeding up the repetition handling without\ncompromising the program correctness. This algorithm is usable in engines, and\nwe saw a total increase in playing strength by +10 point rating increase, or an\nincreased 5% winrate when integrating this approach into our prototype engine.",
    "categories": [
      "cs.AI",
      "I.2.0"
    ],
    "primary_category": "cs.AI",
    "comment": "19 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.17334v1",
    "published_date": "2024-12-23 06:56:50 UTC",
    "updated_date": "2024-12-23 06:56:50 UTC"
  },
  {
    "arxiv_id": "2412.17333v1",
    "title": "Broadband Ground Motion Synthesis by Diffusion Model with Minimal Condition",
    "authors": [
      "Jaeheun Jung",
      "Jaehyuk Lee",
      "Chang-Hae Jung",
      "Hanyoung Kim",
      "Bosung Jung",
      "Donghun Lee"
    ],
    "abstract": "Earthquakes are rare. Hence there is a fundamental call for reliable methods\nto generate realistic ground motion data for data-driven approaches in\nseismology. Recent GAN-based methods fall short of the call, as the methods\neither require special information such as geological traits or generate subpar\nwaveforms that fail to satisfy seismological constraints such as phase arrival\ntimes. We propose a specialized Latent Diffusion Model (LDM) that reliably\ngenerates realistic waveforms after learning from real earthquake data with\nminimal conditions: location and magnitude. We also design a domain-specific\ntraining method that exploits the traits of earthquake dataset: multiple\nobserved waveforms time-aligned and paired to each earthquake source that are\ntagged with seismological metadata comprised of earthquake magnitude, depth of\nfocus, and the locations of epicenter and seismometers. We construct the\ntime-aligned earthquake dataset using Southern California Earthquake Data\nCenter (SCEDC) API, and train our model with the dataset and our proposed\ntraining method for performance evaluation. Our model surpasses all comparable\ndata-driven methods in various test criteria not only from waveform generation\ndomain but also from seismology such as phase arrival time, GMPE analysis, and\nspectrum analysis. Our result opens new future research directions for deep\nlearning applications in seismology.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.geo-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17333v1",
    "published_date": "2024-12-23 06:56:28 UTC",
    "updated_date": "2024-12-23 06:56:28 UTC"
  },
  {
    "arxiv_id": "2412.18635v1",
    "title": "Edge-AI for Agriculture: Lightweight Vision Models for Disease Detection in Resource-Limited Settings",
    "authors": [
      "Harsh Joshi"
    ],
    "abstract": "This research paper presents the development of a lightweight and efficient\ncomputer vision pipeline aimed at assisting farmers in detecting orange\ndiseases using minimal resources. The proposed system integrates advanced\nobject detection, classification, and segmentation models, optimized for\ndeployment on edge devices, ensuring functionality in resource-limited\nenvironments. The study evaluates the performance of various state-of-the-art\nmodels, focusing on their accuracy, computational efficiency, and\ngeneralization capabilities. Notable findings include the Vision Transformer\nachieving 96 accuracy in orange species classification and the lightweight\nYOLOv8-S model demonstrating exceptional object detection performance with\nminimal computational overhead. The research highlights the potential of modern\ndeep learning architectures to address critical agricultural challenges,\nemphasizing the importance of model complexity versus practical utility. Future\nwork will explore expanding datasets, model compression techniques, and\nfederated learning to enhance the applicability of these systems in diverse\nagricultural contexts, ultimately contributing to more sustainable farming\npractices.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.18635v1",
    "published_date": "2024-12-23 06:48:50 UTC",
    "updated_date": "2024-12-23 06:48:50 UTC"
  },
  {
    "arxiv_id": "2412.17330v1",
    "title": "EcoSearch: A Constant-Delay Best-First Search Algorithm for Program Synthesis",
    "authors": [
      "Théo Matricon",
      "Nathanaël Fijalkow",
      "Guillaume Lagarde"
    ],
    "abstract": "Many approaches to program synthesis perform a combinatorial search within a\nlarge space of programs to find one that satisfies a given specification. To\ntame the search space blowup, previous works introduced probabilistic and\nneural approaches to guide this combinatorial search by inducing heuristic cost\nfunctions. Best-first search algorithms ensure to search in the exact order\ninduced by the cost function, significantly reducing the portion of the program\nspace to be explored. We present a new best-first search algorithm called\nEcoSearch, which is the first constant-delay algorithm for pre-generation cost\nfunction: the amount of compute required between outputting two programs is\nconstant, and in particular does not increase over time. This key property\nyields important speedups: we observe that EcoSearch outperforms its\npredecessors on two classic domains.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.LG",
    "comment": "Extended version of AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.17330v1",
    "published_date": "2024-12-23 06:48:47 UTC",
    "updated_date": "2024-12-23 06:48:47 UTC"
  },
  {
    "arxiv_id": "2412.17323v3",
    "title": "xPatch: Dual-Stream Time Series Forecasting with Exponential Seasonal-Trend Decomposition",
    "authors": [
      "Artyom Stitsyuk",
      "Jaesik Choi"
    ],
    "abstract": "In recent years, the application of transformer-based models in time-series\nforecasting has received significant attention. While often demonstrating\npromising results, the transformer architecture encounters challenges in fully\nexploiting the temporal relations within time series data due to its attention\nmechanism. In this work, we design eXponential Patch (xPatch for short), a\nnovel dual-stream architecture that utilizes exponential decomposition.\nInspired by the classical exponential smoothing approaches, xPatch introduces\nthe innovative seasonal-trend exponential decomposition module. Additionally,\nwe propose a dual-flow architecture that consists of an MLP-based linear stream\nand a CNN-based non-linear stream. This model investigates the benefits of\nemploying patching and channel-independence techniques within a non-transformer\nmodel. Finally, we develop a robust arctangent loss function and a sigmoid\nlearning rate adjustment scheme, which prevent overfitting and boost\nforecasting performance. The code is available at the following repository:\nhttps://github.com/stitsyuk/xPatch.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17323v3",
    "published_date": "2024-12-23 06:32:59 UTC",
    "updated_date": "2025-02-11 05:49:47 UTC"
  },
  {
    "arxiv_id": "2412.17321v1",
    "title": "Assessing Human Editing Effort on LLM-Generated Texts via Compression-Based Edit Distance",
    "authors": [
      "Nicolas Devatine",
      "Louis Abraham"
    ],
    "abstract": "Assessing the extent of human edits on texts generated by Large Language\nModels (LLMs) is crucial to understanding the human-AI interactions and\nimproving the quality of automated text generation systems. Existing edit\ndistance metrics, such as Levenshtein, BLEU, ROUGE, and TER, often fail to\naccurately measure the effort required for post-editing, especially when edits\ninvolve substantial modifications, such as block operations. In this paper, we\nintroduce a novel compression-based edit distance metric grounded in the\nLempel-Ziv-77 algorithm, designed to quantify the amount of post-editing\napplied to LLM-generated texts. Our method leverages the properties of text\ncompression to measure the informational difference between the original and\nedited texts. Through experiments on real-world human edits datasets, we\ndemonstrate that our proposed metric is highly correlated with actual edit time\nand effort. We also show that LLMs exhibit an implicit understanding of editing\nspeed, that aligns well with our metric. Furthermore, we compare our metric\nwith existing ones, highlighting its advantages in capturing complex edits with\nlinear computational efficiency. Our code and data are available at:\nhttps://github.com/NDV-tiime/CompressionDistance",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17321v1",
    "published_date": "2024-12-23 06:29:25 UTC",
    "updated_date": "2024-12-23 06:29:25 UTC"
  },
  {
    "arxiv_id": "2412.17883v1",
    "title": "In Defence of Post-hoc Explainability",
    "authors": [
      "Nick Oh"
    ],
    "abstract": "The widespread adoption of machine learning in scientific research has\ncreated a fundamental tension between model opacity and scientific\nunderstanding. Whilst some advocate for intrinsically interpretable models, we\nintroduce Computational Interpretabilism (CI) as a philosophical framework for\npost-hoc interpretability in scientific AI. Drawing parallels with human\nexpertise, where post-hoc rationalisation coexists with reliable performance,\nCI establishes that scientific knowledge emerges through structured model\ninterpretation when properly bounded by empirical validation. Through mediated\nunderstanding and bounded factivity, we demonstrate how post-hoc methods\nachieve epistemically justified insights without requiring complete mechanical\ntransparency, resolving tensions between model complexity and scientific\ncomprehension.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Presented at the Interpretable AI: Past, Present, and Future Workshop\n  at NeurIPS 2024 (non-archival)",
    "pdf_url": "http://arxiv.org/pdf/2412.17883v1",
    "published_date": "2024-12-23 06:22:03 UTC",
    "updated_date": "2024-12-23 06:22:03 UTC"
  },
  {
    "arxiv_id": "2412.17316v2",
    "title": "Fast Gradient Computation for RoPE Attention in Almost Linear Time",
    "authors": [
      "Yifang Chen",
      "Jiayan Huo",
      "Xiaoyu Li",
      "Yingyu Liang",
      "Zhenmei Shi",
      "Zhao Song"
    ],
    "abstract": "The Rotary Position Embedding (RoPE) mechanism has become a powerful\nenhancement to the Transformer architecture, which enables models to capture\ntoken relationships when encoding positional information. However, the RoPE\nmechanisms make the computations of attention mechanisms more complicated,\nwhich makes efficient algorithms challenging. Earlier research introduced\nalmost linear time, i.e., $n^{1+o(1)}$ where $n$ is the number of input tokens,\nalgorithms for the forward computation under specific parameter settings.\nHowever, achieving a subquadratic time algorithm for other parameter regimes\nremains impossible unless the widely accepted Strong Exponential Time\nHypothesis (SETH) is disproven. In this work, we develop the first almost\nlinear time algorithm for backward computations in the RoPE-based attention\nunder bounded entries. Our approach builds on recent advancements in fast RoPE\nattention computations, utilizing a novel combination of the polynomial method\nand the Fast Fourier Transform. Furthermore, we show that with lower bounds\nderived from the SETH, the bounded entry condition is necessary for\nsubquadratic performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CC",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17316v2",
    "published_date": "2024-12-23 06:20:22 UTC",
    "updated_date": "2024-12-31 06:53:40 UTC"
  },
  {
    "arxiv_id": "2412.17315v1",
    "title": "CodeV: Issue Resolving with Visual Data",
    "authors": [
      "Linhao Zhang",
      "Daoguang Zan",
      "Quanshun Yang",
      "Zhirong Huang",
      "Dong Chen",
      "Bo Shen",
      "Tianyu Liu",
      "Yongshun Gong",
      "Pengjie Huang",
      "Xudong Lu",
      "Guangtai Liang",
      "Lizhen Cui",
      "Qianxiang Wang"
    ],
    "abstract": "Large Language Models (LLMs) have advanced rapidly in recent years, with\ntheir applications in software engineering expanding to more complex\nrepository-level tasks. GitHub issue resolving is a key challenge among these\ntasks. While recent approaches have made progress on this task, they focus on\ntextual data within issues, neglecting visual data. However, this visual data\nis crucial for resolving issues as it conveys additional knowledge that text\nalone cannot. We propose CodeV, the first approach to leveraging visual data to\nenhance the issue-resolving capabilities of LLMs. CodeV resolves each issue by\nfollowing a two-phase process: data processing and patch generation. To\nevaluate CodeV, we construct a benchmark for visual issue resolving, namely\nVisual SWE-bench. Through extensive experiments, we demonstrate the\neffectiveness of CodeV, as well as provide valuable insights into leveraging\nvisual data to resolve GitHub issues.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "https://github.com/luolin101/CodeV",
    "pdf_url": "http://arxiv.org/pdf/2412.17315v1",
    "published_date": "2024-12-23 06:17:11 UTC",
    "updated_date": "2024-12-23 06:17:11 UTC"
  },
  {
    "arxiv_id": "2412.17310v1",
    "title": "Popularity Estimation and New Bundle Generation using Content and Context based Embeddings",
    "authors": [
      "Ashutosh Nayak",
      "Prajwal NJ",
      "Sameeksha Keshav",
      "Kavitha S. N.",
      "Roja Reddy",
      "Rajasekhara Reddy Duvvuru Muni"
    ],
    "abstract": "Recommender systems create enormous value for businesses and their consumers.\nThey increase revenue for businesses while improving the consumer experience by\nrecommending relevant products amidst huge product base. Product bundling is an\nexciting development in the field of product recommendations. It aims at\ngenerating new bundles and recommending exciting and relevant bundles to their\nconsumers. Unlike traditional recommender systems that recommend single items\nto consumers, product bundling aims at targeting a bundle, or a set of items,\nto the consumers. While bundle recommendation has attracted significant\nresearch interest recently, extant literature on bundle generation is scarce.\nMoreover, metrics to identify if a bundle is popular or not is not well\nstudied. In this work, we aim to fulfill this gap by introducing new bundle\npopularity metrics based on sales, consumer experience and item diversity in a\nbundle. We use these metrics in the methodology proposed in this paper to\ngenerate new bundles for mobile games using content aware and context aware\nembeddings. We use opensource Steam Games dataset for our analysis. Our\nexperiments indicate that we can generate new bundles that can outperform the\nexisting bundles on the popularity metrics by 32% - 44%. Our experiments are\ncomputationally efficient and the proposed methodology is generic that can be\nextended to other bundling problems e.g. product bundling, music bundling.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17310v1",
    "published_date": "2024-12-23 06:04:14 UTC",
    "updated_date": "2024-12-23 06:04:14 UTC"
  },
  {
    "arxiv_id": "2412.17304v2",
    "title": "On the Feasibility of Vision-Language Models for Time-Series Classification",
    "authors": [
      "Vinay Prithyani",
      "Mohsin Mohammed",
      "Richa Gadgil",
      "Ricardo Buitrago",
      "Vinija Jain",
      "Aman Chadha"
    ],
    "abstract": "We build upon time-series classification by leveraging the capabilities of\nVision Language Models (VLMs). We find that VLMs produce competitive results\nafter two or less epochs of fine-tuning. We develop a novel approach that\nincorporates graphical data representations as images in conjunction with\nnumerical data. This approach is rooted in the hypothesis that graphical\nrepresentations can provide additional contextual information that numerical\ndata alone may not capture. Additionally, providing a graphical representation\ncan circumvent issues such as limited context length faced by LLMs. To further\nadvance this work, we implemented a scalable end-to-end pipeline for training\non different scenarios, allowing us to isolate the most effective strategies\nfor transferring learning capabilities from LLMs to Time Series Classification\n(TSC) tasks. Our approach works with univariate and multivariate time-series\ndata. In addition, we conduct extensive and practical experiments to show how\nthis approach works for time-series classification and generative labels.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17304v2",
    "published_date": "2024-12-23 05:52:17 UTC",
    "updated_date": "2025-01-17 23:02:52 UTC"
  },
  {
    "arxiv_id": "2412.17301v1",
    "title": "Dynamic Scheduling Strategies for Resource Optimization in Computing Environments",
    "authors": [
      "Xiaoye Wang"
    ],
    "abstract": "The rapid development of cloud-native architecture has promoted the\nwidespread application of container technology, but the optimization problems\nin container scheduling and resource management still face many challenges.\nThis paper proposes a container scheduling method based on multi-objective\noptimization, which aims to balance key performance indicators such as resource\nutilization, load balancing and task completion efficiency. By introducing\noptimization models and heuristic algorithms, the scheduling strategy is\ncomprehensively improved, and experimental verification is carried out using\nthe real Google Cluster Data dataset. The experimental results show that\ncompared with traditional static rule algorithms and heuristic algorithms, the\noptimized scheduling scheme shows significant advantages in resource\nutilization, load balancing and burst task completion efficiency. This shows\nthat the proposed method can effectively improve resource management efficiency\nand ensure service quality and system stability in complex dynamic cloud\nenvironments. At the same time, this paper also explores the future development\ndirection of scheduling algorithms in multi-tenant environments, heterogeneous\ncloud computing, and cross-edge and cloud collaborative computing scenarios,\nand proposes research prospects for energy consumption optimization, adaptive\nscheduling and fairness. The research results not only provide a theoretical\nbasis and practical reference for container scheduling under cloud-native\narchitecture, but also lay a foundation for further realizing intelligent and\nefficient resource management.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17301v1",
    "published_date": "2024-12-23 05:43:17 UTC",
    "updated_date": "2024-12-23 05:43:17 UTC"
  },
  {
    "arxiv_id": "2412.17292v1",
    "title": "AV-EmoDialog: Chat with Audio-Visual Users Leveraging Emotional Cues",
    "authors": [
      "Se Jin Park",
      "Yeonju Kim",
      "Hyeongseop Rha",
      "Bella Godiva",
      "Yong Man Ro"
    ],
    "abstract": "In human communication, both verbal and non-verbal cues play a crucial role\nin conveying emotions, intentions, and meaning beyond words alone. These\nnon-linguistic information, such as facial expressions, eye contact, voice\ntone, and pitch, are fundamental elements of effective interactions, enriching\nconversations by adding emotional and contextual depth. Recognizing the\nimportance of non-linguistic content in communication, we present AV-EmoDialog,\na dialogue system designed to exploit verbal and non-verbal information from\nusers' audio-visual inputs to generate more responsive and empathetic\ninteractions. AV-EmoDialog systematically exploits the emotional cues in\naudio-visual dialogues; extracting speech content and emotional tones from\nspeech, analyzing fine-grained facial expressions from visuals, and integrating\nthese cues to generate emotionally aware responses in an end-to-end manner.\nThrough extensive experiments, we validate that the proposed AV-EmoDialog\noutperforms existing multimodal LLMs in generating not only emotionally\nappropriate but also contextually appropriate responses.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17292v1",
    "published_date": "2024-12-23 05:24:26 UTC",
    "updated_date": "2024-12-23 05:24:26 UTC"
  },
  {
    "arxiv_id": "2412.17288v1",
    "title": "Multi-Modal Grounded Planning and Efficient Replanning For Learning Embodied Agents with A Few Examples",
    "authors": [
      "Taewoong Kim",
      "Byeonghwi Kim",
      "Jonghyun Choi"
    ],
    "abstract": "Learning a perception and reasoning module for robotic assistants to plan\nsteps to perform complex tasks based on natural language instructions often\nrequires large free-form language annotations, especially for short high-level\ninstructions. To reduce the cost of annotation, large language models (LLMs)\nare used as a planner with few data. However, when elaborating the steps, even\nthe state-of-the-art planner that uses LLMs mostly relies on linguistic common\nsense, often neglecting the status of the environment at command reception,\nresulting in inappropriate plans. To generate plans grounded in the\nenvironment, we propose FLARE (Few-shot Language with environmental Adaptive\nReplanning Embodied agent), which improves task planning using both language\ncommand and environmental perception. As language instructions often contain\nambiguities or incorrect expressions, we additionally propose to correct the\nmistakes using visual cues from the agent. The proposed scheme allows us to use\na few language pairs thanks to the visual cues and outperforms state-of-the-art\napproaches. Our code is available at https://github.com/snumprlab/flare.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "AAAI 2025 (Project page: https://twoongg.github.io/projects/flare/)",
    "pdf_url": "http://arxiv.org/pdf/2412.17288v1",
    "published_date": "2024-12-23 05:20:01 UTC",
    "updated_date": "2024-12-23 05:20:01 UTC"
  },
  {
    "arxiv_id": "2412.17287v1",
    "title": "LLM4AD: A Platform for Algorithm Design with Large Language Model",
    "authors": [
      "Fei Liu",
      "Rui Zhang",
      "Zhuoliang Xie",
      "Rui Sun",
      "Kai Li",
      "Xi Lin",
      "Zhenkun Wang",
      "Zhichao Lu",
      "Qingfu Zhang"
    ],
    "abstract": "We introduce LLM4AD, a unified Python platform for algorithm design (AD) with\nlarge language models (LLMs). LLM4AD is a generic framework with modularized\nblocks for search methods, algorithm design tasks, and LLM interface. The\nplatform integrates numerous key methods and supports a wide range of algorithm\ndesign tasks across various domains including optimization, machine learning,\nand scientific discovery. We have also designed a unified evaluation sandbox to\nensure a secure and robust assessment of algorithms. Additionally, we have\ncompiled a comprehensive suite of support resources, including tutorials,\nexamples, a user manual, online resources, and a dedicated graphical user\ninterface (GUI) to enhance the usage of LLM4AD. We believe this platform will\nserve as a valuable tool for fostering future development in the merging\nresearch direction of LLM-assisted algorithm design.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17287v1",
    "published_date": "2024-12-23 05:12:54 UTC",
    "updated_date": "2024-12-23 05:12:54 UTC"
  },
  {
    "arxiv_id": "2412.17285v1",
    "title": "Enabling Time-series Foundation Model for Building Energy Forecasting via Contrastive Curriculum Learning",
    "authors": [
      "Rui Liang",
      "Yang Deng",
      "Donghua Xie",
      "Fang He",
      "Dan Wang"
    ],
    "abstract": "Advances in time-series forecasting are driving a shift from conventional\nmachine learning models to foundation models (FMs) that are trained with\ngeneralized knowledge. However, existing FMs still perform poorly in the energy\nfields, such as building energy forecasting (BEF). This paper studies the\nadaptation of FM to BEF tasks. We demonstrate the shortcomings of fine-tuning\nFM straightforwardly from both the perspectives of FM and the data. To overcome\nthese limitations, we propose a new \\textit{contrastive curriculum\nlearning}-based training method. Our method optimizes the ordering of training\ndata in the context of TSFM adaptation. Experiments show that our method can\nimprove the zero/few-shot performance by 14.6\\% compared to the existing FMs.\nOur code and new TSFM will be available at <Anonymous Github Repo>.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17285v1",
    "published_date": "2024-12-23 05:07:06 UTC",
    "updated_date": "2024-12-23 05:07:06 UTC"
  },
  {
    "arxiv_id": "2412.17265v1",
    "title": "Evaluating the Design Features of an Intelligent Tutoring System for Advanced Mathematics Learning",
    "authors": [
      "Ying Fang",
      "Bo He",
      "Zhi Liu",
      "Sannyuya Liu",
      "Zhonghua Yan",
      "Jianwen Sun"
    ],
    "abstract": "Xiaomai is an intelligent tutoring system (ITS) designed to help Chinese\ncollege students in learning advanced mathematics and preparing for the\ngraduate school math entrance exam. This study investigates two distinctive\nfeatures within Xiaomai: the incorporation of free-response questions with\nautomatic feedback and the metacognitive element of reflecting on self-made\nerrors.",
    "categories": [
      "cs.MS",
      "cs.AI",
      "cs.CY",
      "math.HO"
    ],
    "primary_category": "cs.MS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17265v1",
    "published_date": "2024-12-23 04:22:05 UTC",
    "updated_date": "2024-12-23 04:22:05 UTC"
  },
  {
    "arxiv_id": "2412.17256v2",
    "title": "B-STaR: Monitoring and Balancing Exploration and Exploitation in Self-Taught Reasoners",
    "authors": [
      "Weihao Zeng",
      "Yuzhen Huang",
      "Lulu Zhao",
      "Yijun Wang",
      "Zifei Shan",
      "Junxian He"
    ],
    "abstract": "In the absence of extensive human-annotated data for complex reasoning tasks,\nself-improvement -- where models are trained on their own outputs -- has\nemerged as a primary method for enhancing performance. However, the critical\nfactors underlying the mechanism of these iterative self-improving methods\nremain poorly understood, such as under what conditions self-improvement is\neffective, and what are the bottlenecks in the current iterations. In this\nwork, we identify and propose methods to monitor two pivotal factors in this\niterative process: (1) the model's ability to generate sufficiently diverse\nresponses (exploration); and (2) the effectiveness of external rewards in\ndistinguishing high-quality candidates from lower-quality ones (exploitation).\nUsing mathematical reasoning as a case study, we begin with a quantitative\nanalysis to track the dynamics of exploration and exploitation, discovering\nthat a model's exploratory capabilities rapidly deteriorate over iterations,\nand the effectiveness of exploiting external rewards diminishes as well.\nMotivated by these findings, we introduce B-STaR, a Self-Taught Reasoning\nframework that autonomously adjusts configurations across iterations to Balance\nexploration and exploitation, thereby optimizing the self-improving\neffectiveness based on the current policy model and available rewards. Our\nexperiments on mathematical reasoning, coding, and commonsense reasoning\ndemonstrate that B-STaR not only enhances the model's exploratory capabilities\nthroughout training but also achieves a more effective balance between\nexploration and exploitation, leading to superior performance.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Published as a conference paper at ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2412.17256v2",
    "published_date": "2024-12-23 03:58:34 UTC",
    "updated_date": "2025-03-04 06:29:50 UTC"
  },
  {
    "arxiv_id": "2412.17255v1",
    "title": "Unlocking Cross-Lingual Sentiment Analysis through Emoji Interpretation: A Multimodal Generative AI Approach",
    "authors": [
      "Rafid Ishrak Jahan",
      "Heng Fan",
      "Haihua Chen",
      "Yunhe Feng"
    ],
    "abstract": "Emojis have become ubiquitous in online communication, serving as a universal\nmedium to convey emotions and decorative elements. Their widespread use\ntranscends language and cultural barriers, enhancing understanding and\nfostering more inclusive interactions. While existing work gained valuable\ninsight into emojis understanding, exploring emojis' capability to serve as a\nuniversal sentiment indicator leveraging large language models (LLMs) has not\nbeen thoroughly examined. Our study aims to investigate the capacity of emojis\nto serve as reliable sentiment markers through LLMs across languages and\ncultures. We leveraged the multimodal capabilities of ChatGPT to explore the\nsentiments of various representations of emojis and evaluated how well\nemoji-conveyed sentiment aligned with text sentiment on a multi-lingual dataset\ncollected from 32 countries. Our analysis reveals that the accuracy of\nLLM-based emoji-conveyed sentiment is 81.43%, underscoring emojis' significant\npotential to serve as a universal sentiment marker. We also found a consistent\ntrend that the accuracy of sentiment conveyed by emojis increased as the number\nof emojis grew in text. The results reinforce the potential of emojis to serve\nas global sentiment indicators, offering insight into fields such as\ncross-lingual and cross-cultural sentiment analysis on social media platforms.\nCode: https://github.com/ResponsibleAILab/emoji-universal-sentiment.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17255v1",
    "published_date": "2024-12-23 03:57:45 UTC",
    "updated_date": "2024-12-23 03:57:45 UTC"
  },
  {
    "arxiv_id": "2412.17254v1",
    "title": "Enhancing Multi-Text Long Video Generation Consistency without Tuning: Time-Frequency Analysis, Prompt Alignment, and Theory",
    "authors": [
      "Xingyao Li",
      "Fengzhuo Zhang",
      "Jiachun Pan",
      "Yunlong Hou",
      "Vincent Y. F. Tan",
      "Zhuoran Yang"
    ],
    "abstract": "Despite the considerable progress achieved in the long video generation\nproblem, there is still significant room to improve the consistency of the\nvideos, particularly in terms of smoothness and transitions between scenes. We\naddress these issues to enhance the consistency and coherence of videos\ngenerated with either single or multiple prompts. We propose the Time-frequency\nbased temporal Attention Reweighting Algorithm (TiARA), which meticulously\nedits the attention score matrix based on the Discrete Short-Time Fourier\nTransform. Our method is supported by a theoretical guarantee, the\nfirst-of-its-kind for frequency-based methods in diffusion models. For videos\ngenerated by multiple prompts, we further investigate key factors affecting\nprompt interpolation quality and propose PromptBlend, an advanced prompt\ninterpolation pipeline. The efficacy of our proposed method is validated via\nextensive experimental results, exhibiting consistent and impressive\nimprovements over baseline methods. The code will be released upon acceptance.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "34 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2412.17254v1",
    "published_date": "2024-12-23 03:56:27 UTC",
    "updated_date": "2024-12-23 03:56:27 UTC"
  },
  {
    "arxiv_id": "2501.00032v1",
    "title": "Highly Optimized Kernels and Fine-Grained Codebooks for LLM Inference on Arm CPUs",
    "authors": [
      "Dibakar Gope",
      "David Mansell",
      "Danny Loh",
      "Ian Bratt"
    ],
    "abstract": "Large language models (LLMs) have transformed the way we think about language\nunderstanding and generation, enthralling both researchers and developers.\nHowever, deploying LLMs for inference has been a significant challenge due to\ntheir unprecedented size and resource requirements. While quantizing model\nweights to sub-byte precision has emerged as a promising solution to ease\nmemory pressure, the group quantization formats commonly used for LLM\nquantization have significant compute overheads and a resource-intensive\ndequantization process. As a result, a higher proportion of compute\ninstructions do not perform multiplies, i.e., real work, rendering them\nunsuitable for meeting the required latency requirements for LLMs deployed on\ncommodity CPUs. In this work, we propose a set of highly optimized kernels to\naccelerate LLM inference and unleash the full potential of CPUs, particularly\nArm CPUs. These kernels amortize the cost of loading the operands and the cost\nof weight unpacking across multiple output rows. This, along with the\nintroduction of an optimized interleaved group data layout for weights and\ndecompression path optimizations to reduce unnecessary operations and\ndequantization overhead while maximizing the use of vector and matrix multiply\noperations, significantly improves the efficiency of MAC operations.\nFurthermore, we present a groupwise non-uniform codebook-based quantization\nmethod for ultra-low-precision quantization of LLMs to better match non-uniform\npatterns in their weight distributions, demonstrating better throughput during\ntoken generation while ensuring better quality than the state-of-the-art.\nApplying these improvements to 4-bit LLMs results in a 3-3.2x improvement in\nprompt processing and a 2x improvement in autoregressive decoding on Arm CPUs,\ncompared to LLaMA.cpp-based solution. The optimized kernels are available at\nhttps://github.com/ggerganov/llama.cpp.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.AR",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.00032v1",
    "published_date": "2024-12-23 03:44:29 UTC",
    "updated_date": "2024-12-23 03:44:29 UTC"
  },
  {
    "arxiv_id": "2412.17243v1",
    "title": "\"From Unseen Needs to Classroom Solutions\": Exploring AI Literacy Challenges & Opportunities with Project-based Learning Toolkit in K-12 Education",
    "authors": [
      "Hanqi Li",
      "Ruiwei Xiao",
      "Hsuan Nieu",
      "Ying-Jui Tseng",
      "Guanze Liao"
    ],
    "abstract": "As artificial intelligence (AI) becomes increasingly central to various\nfields, there is a growing need to equip K-12 students with AI literacy skills\nthat extend beyond computer science. This paper explores the integration of a\nProject-Based Learning (PBL) AI toolkit into diverse subject areas, aimed at\nhelping educators teach AI concepts more effectively. Through interviews and\nco-design sessions with K-12 teachers, we examined current AI literacy levels\nand how teachers adapt AI tools like the AI Art Lab, AI Music Studio, and AI\nChatbot into their course designs. While teachers appreciated the potential of\nAI tools to foster creativity and critical thinking, they also expressed\nconcerns about the accuracy, trustworthiness, and ethical implications of\nAI-generated content. Our findings reveal the challenges teachers face,\nincluding limited resources, varying student and instructor skill levels, and\nthe need for scalable, adaptable AI tools. This research contributes insights\nthat can inform the development of AI curricula tailored to diverse educational\ncontexts.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to AAAI2025",
    "pdf_url": "http://arxiv.org/pdf/2412.17243v1",
    "published_date": "2024-12-23 03:31:02 UTC",
    "updated_date": "2024-12-23 03:31:02 UTC"
  },
  {
    "arxiv_id": "2412.17242v3",
    "title": "On the Generalization and Adaptation Ability of Machine-Generated Text Detectors in Academic Writing",
    "authors": [
      "Yule Liu",
      "Zhiyuan Zhong",
      "Yifan Liao",
      "Zhen Sun",
      "Jingyi Zheng",
      "Jiaheng Wei",
      "Qingyuan Gong",
      "Fenghua Tong",
      "Yang Chen",
      "Yang Zhang",
      "Xinlei He"
    ],
    "abstract": "The rising popularity of large language models (LLMs) has raised concerns\nabout machine-generated text (MGT), particularly in academic settings, where\nissues like plagiarism and misinformation are prevalent. As a result,\ndeveloping a highly generalizable and adaptable MGT detection system has become\nan urgent priority. Given that LLMs are most commonly misused in academic\nwriting, this work investigates the generalization and adaptation capabilities\nof MGT detectors in three key aspects specific to academic writing: First, we\nconstruct MGT-Acedemic, a large-scale dataset comprising over 336M tokens and\n749K samples. MGT-Acedemic focuses on academic writing, featuring human-written\ntexts (HWTs) and MGTs across STEM, Humanities, and Social Sciences, paired with\nan extensible code framework for efficient benchmarking. Second, we benchmark\nthe performance of various detectors for binary classification and attribution\ntasks in both in-domain and cross-domain settings. This benchmark reveals the\noften-overlooked challenges of attribution tasks. Third, we introduce a novel\nattribution task where models have to adapt to new classes over time without\n(or with very limited) access to prior training data in both few-shot and\nmany-shot scenarios. We implement eight different adapting techniques to\nimprove the performance and highlight the inherent complexity of the task. Our\nfindings provide insights into the generalization and adaptation ability of MGT\ndetectors across diverse scenarios and lay the foundation for building robust,\nadaptive detection systems. The code framework is available at\nhttps://github.com/Y-L-LIU/MGTBench-2.0.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17242v3",
    "published_date": "2024-12-23 03:30:34 UTC",
    "updated_date": "2025-03-03 03:08:43 UTC"
  },
  {
    "arxiv_id": "2412.17241v2",
    "title": "QTSeg: A Query Token-Based Dual-Mix Attention Framework with Multi-Level Feature Distribution for Medical Image Segmentation",
    "authors": [
      "Phuong-Nam Tran",
      "Nhat Truong Pham",
      "Duc Ngoc Minh Dang",
      "Eui-Nam Huh",
      "Choong Seon Hong"
    ],
    "abstract": "Medical image segmentation plays a crucial role in assisting healthcare\nprofessionals with accurate diagnoses and enabling automated diagnostic\nprocesses. Traditional convolutional neural networks (CNNs) often struggle with\ncapturing long-range dependencies, while transformer-based architectures,\ndespite their effectiveness, come with increased computational complexity.\nRecent efforts have focused on combining CNNs and transformers to balance\nperformance and efficiency, but existing approaches still face challenges in\nachieving high segmentation accuracy while maintaining low computational costs.\nFurthermore, many methods underutilize the CNN encoder's capability to capture\nlocal spatial information, concentrating primarily on mitigating long-range\ndependency issues. To address these limitations, we propose QTSeg, a novel\narchitecture for medical image segmentation that effectively integrates local\nand global information. QTSeg features a dual-mix attention decoder designed to\nenhance segmentation performance through: (1) a cross-attention mechanism for\nimproved feature alignment, (2) a spatial attention module to capture\nlong-range dependencies, and (3) a channel attention block to learn\ninter-channel relationships. Additionally, we introduce a multi-level feature\ndistribution module, which adaptively balances feature propagation between the\nencoder and decoder, further boosting performance. Extensive experiments on\nfive publicly available datasets covering diverse segmentation tasks, including\nlesion, polyp, breast cancer, cell, and retinal vessel segmentation,\ndemonstrate that QTSeg outperforms state-of-the-art methods across multiple\nevaluation metrics while maintaining lower computational costs. Our\nimplementation can be found at: https://github.com/tpnam0901/QTSeg (v1.0.0)",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17241v2",
    "published_date": "2024-12-23 03:22:44 UTC",
    "updated_date": "2025-02-14 04:03:10 UTC"
  },
  {
    "arxiv_id": "2412.17240v1",
    "title": "Rethinking Cancer Gene Identification through Graph Anomaly Analysis",
    "authors": [
      "Yilong Zang",
      "Lingfei Ren",
      "Yue Li",
      "Zhikang Wang",
      "David Antony Selby",
      "Zheng Wang",
      "Sebastian Josef Vollmer",
      "Hongzhi Yin",
      "Jiangning Song",
      "Junhang Wu"
    ],
    "abstract": "Graph neural networks (GNNs) have shown promise in integrating\nprotein-protein interaction (PPI) networks for identifying cancer genes in\nrecent studies. However, due to the insufficient modeling of the biological\ninformation in PPI networks, more faithfully depiction of complex protein\ninteraction patterns for cancer genes within the graph structure remains\nlargely unexplored. This study takes a pioneering step toward bridging\nbiological anomalies in protein interactions caused by cancer genes to\nstatistical graph anomaly. We find a unique graph anomaly exhibited by cancer\ngenes, namely weight heterogeneity, which manifests as significantly higher\nvariance in edge weights of cancer gene nodes within the graph. Additionally,\nfrom the spectral perspective, we demonstrate that the weight heterogeneity\ncould lead to the \"flattening out\" of spectral energy, with a concentration\ntowards the extremes of the spectrum. Building on these insights, we propose\nthe HIerarchical-Perspective Graph Neural Network (HIPGNN) that not only\ndetermines spectral energy distribution variations on the spectral perspective,\nbut also perceives detailed protein interaction context on the spatial\nperspective. Extensive experiments are conducted on two reprocessed datasets\nSTRINGdb and CPDB, and the experimental results demonstrate the superiority of\nHIPGNN.",
    "categories": [
      "cs.CE",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.CE",
    "comment": "It has been accepted by the AAAI 2025 conference",
    "pdf_url": "http://arxiv.org/pdf/2412.17240v1",
    "published_date": "2024-12-23 03:21:24 UTC",
    "updated_date": "2024-12-23 03:21:24 UTC"
  },
  {
    "arxiv_id": "2412.17228v1",
    "title": "MatchMiner-AI: An Open-Source Solution for Cancer Clinical Trial Matching",
    "authors": [
      "Ethan Cerami",
      "Pavel Trukhanov",
      "Morgan A. Paul",
      "Michael J. Hassett",
      "Irbaz B. Riaz",
      "James Lindsay",
      "Emily Mallaber",
      "Harry Klein",
      "Gufran Gungor",
      "Matthew Galvin",
      "Stephen C. Van Nostrand",
      "Joyce Yu",
      "Tali Mazor",
      "Kenneth L. Kehl"
    ],
    "abstract": "Clinical trials drive improvements in cancer treatments and outcomes.\nHowever, most adults with cancer do not participate in trials, and trials often\nfail to enroll enough patients to answer their scientific questions. Artificial\nintelligence could accelerate matching of patients to appropriate clinical\ntrials. Here, we describe the development and evaluation of the MatchMiner-AI\npipeline for clinical trial searching and ranking. MatchMiner-AI focuses on\nmatching patients to potential trials based on core criteria describing\nclinical \"spaces,\" or disease contexts, targeted by a trial. It aims to\naccelerate the human work of identifying potential matches, not to fully\nautomate trial screening. The pipeline includes modules for extraction of key\ninformation from a patient's longitudinal electronic health record; rapid\nranking of candidate trial-patient matches based on embeddings in vector space;\nand classification of whether a candidate match represents a reasonable\nclinical consideration. Code and synthetic data are available at\nhttps://huggingface.co/ksg-dfci/MatchMiner-AI . Model weights based on\nsynthetic data are available at https://huggingface.co/ksg-dfci/TrialSpace and\nhttps://huggingface.co/ksg-dfci/TrialChecker . A simple cancer clinical trial\nsearch engine to demonstrate pipeline components is available at\nhttps://huggingface.co/spaces/ksg-dfci/trial_search_alpha .",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17228v1",
    "published_date": "2024-12-23 02:44:35 UTC",
    "updated_date": "2024-12-23 02:44:35 UTC"
  },
  {
    "arxiv_id": "2412.17197v1",
    "title": "Q-LIME $π$: A Quantum-Inspired Extension to LIME",
    "authors": [
      "Nelson Colón Vargas"
    ],
    "abstract": "Machine learning models offer powerful predictive capabilities but often lack\ntransparency. Local Interpretable Model-agnostic Explanations (LIME) addresses\nthis by perturbing features and measuring their impact on a model's output. In\ntext-based tasks, LIME typically removes present words (bits set to 1) to\nidentify high-impact tokens. We propose \\textbf{Q-LIME $\\pi$} (Quantum LIME\n$\\pi$), a quantum-inspired extension of LIME that encodes a binary feature\nvector in a quantum state, leveraging superposition and interference to explore\nlocal neighborhoods more efficiently. Our method focuses on flipping bits from\n$1 \\rightarrow 0$ to emulate LIME's ``removal'' strategy, and can be extended\nto $0 \\rightarrow 1$ where adding features is relevant. Experiments on subsets\nof the IMDb dataset demonstrate that Q-LIME $\\pi$ often achieves near-identical\ntop-feature rankings compared to classical LIME while exhibiting lower runtime\nin small- to moderate-dimensional feature spaces. This quantum-classical hybrid\napproach thus provides a new pathway for interpretable AI, suggesting that,\nwith further improvements in quantum hardware and methods, quantum parallelism\nmay facilitate more efficient local explanations for high-dimensional data.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2412.17197v1",
    "published_date": "2024-12-23 00:20:11 UTC",
    "updated_date": "2024-12-23 00:20:11 UTC"
  }
]