{
  "date": "2025-05-08",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-05-08 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦 AI 模型优化、LLM 推理机制、多模态学习和医疗应用等领域，强调高效计算、鲁棒性和泛化能力；令人印象深刻的是 LLM 在数学推理和量子算法模拟中的应用，以及如 H. Vincent Poor 等学者的 Federated Learning 工作，这些论文展示了 AI 在实际场景中的潜力。\n\n以下是今日论文的精选摘要，我会优先讨论重要、创新性和话题度高的文章（如涉及 LLM 推理、医疗 AI 和高效计算的），并将相关主题归类快速概述。其他较常规的论文（如某些优化方法或小规模实验）将简要掠过，只突出核心贡献。\n\n### AI 推理与 LLM 应用\n- **Prompted Meta-Learning for Few-shot Knowledge Graph Completion**（元学习用于少样本知识图谱补全）：Han Wu 和 Jie Yin 的论文提出 PromptMeta 框架，结合元语义和关系信息提升少样本 KGC 性能；主要发现是通过元语义提示池和融合机制，在基准数据集上显著提高知识转移效果。\n- **Adaptive Stress Testing Black-Box LLM Planners**（自适应压力测试黑盒 LLM 规划器）：Neeloy Chakraborty 等人的工作使用 Adaptive Stress Testing 和 MCTS 搜索提示扰动，检测 LLM 在驾驶环境中的不确定性；关键贡献是实时信任评估，揭示 LLM 在噪声输入下的鲁棒性问题。\n- **Scaling Laws for Speculative Decoding**（推测解码的缩放定律）：Siyuan Yan 等探索推测解码的效率，提出 Log-linear Scaling Laws 和 Scylla 方法，提升文本生成速度；发现通过高效策略，任务如总结和问答可实现 1.5-2.2 倍加速。\n- **Rethinking Invariance in In-context Learning**（重新审视上下文学习的不变性）：Lizhe Fang 等分析 LLM 的上下文不变性，提出 InvICL 方法确保信息不泄露和依赖性；主要发现是 InvICL 在多种基准上提升泛化性能，代码开源。\n- **Conversational Process Model Redesign**（对话式过程模型重构）：Nataliia Klievtsova 等利用 LLM 迭代重构业务过程模型，引入多步骤策略处理变化请求；贡献在于提升 LLM 在业务建模的可解释性和效率。\n\n这些 LLM 相关论文是今日亮点，强调推理鲁棒性和高效应用，但其他如情感分类或简单提示方法（如 Divide and Conquer for Sentiment Classification）则快速掠过，仅提其 MLP 聚合策略在数据集上提升性能。\n\n### 医疗与生物 AI\n- **In-Context Learning for Label-Efficient Cancer Image Classification**（上下文学习用于高效癌症图像分类）：Mobina Shrestha 等评估 VLMs 在肿瘤数据集上的少样本性能，GPT-4o 达 F1 分数 0.81；主要发现是 ICL 在资源有限的环境中逼近全调优效果，适用于临床。\n- **scDrugMap: Benchmarking Large Foundation Models for Drug Response Prediction**（单细胞药物反应预测基准）：Qing Wang 等构建框架评估单细胞模型，scFoundation 在 F1 分数上领先；贡献在于提供首个大规模基准，提升药物发现的泛化能力。\n- **Prompt to Polyp: Medical Text-Conditioned Image Synthesis with Diffusion Models**（文本条件下的医学图像合成）：Mikhail Chaichuk 等提出 MSDM 模型生成医学图像，结合临床文本编码器；发现细调模型在结肠镜数据上提升图像保真度，代码开源。\n- **Cardioformer: Advancing AI in ECG Analysis**（ECG 分析的 AI 进展）：Md Kamrujjaman Mobin 等设计 Res-U-Net 变体，处理心电图多尺度特征；主要发现是提升心律分类准确率，适用于实时诊断。\n\n医疗 AI 论文突出少样本和多模态优势，其他如糖尿病风险预测（Interactive Diabetes Risk Prediction）则简要提及其 LightGBM 模型在召回率上的优化。\n\n### 量子计算与科学应用\n- **GroverGPT-2: Simulating Grover's Algorithm via Chain-of-Thought Reasoning**（模拟 Grover 算法的 LLM 方法）：Min Chen 等使用 CoT 和量子原生标记化模拟量子算法，Llama 模型表现出色；关键贡献是证明 LLM 可捕获量子逻辑，揭示经典模拟的潜力。\n- **Flow-GRPO: Training Flow Matching Models via Online RL**（在线强化学习训练流匹配模型）：Jie Liu 等提出 ODE-to-SDE 转换，提升生成模型在文本图像任务的性能；发现减少训练步数同时保持多样性，适用于复杂生成。\n- **SPIN-ODE: Stiff Physics-Informed Neural ODE for Chemical Reaction Rate Estimation**（刚性物理信息神经 ODE 用于化学反应率估计）：Wenqing Peng 等开发三阶段优化框架，处理化学动力学刚性问题；主要发现是提高反应系数估计的鲁棒性，开创刚性 ODE 在化学中的应用。\n\n量子和科学计算论文创新性强，但其他如化学反应预测或交通优化（Decentralized Traffic Flow Optimization）快速掠过，仅注其内在动机策略改善流量。\n\n### 其他领域快速概述\n- **Federated Learning for Cyber Physical Systems**（联邦学习用于网络物理系统）：Minh K. Quan 等综述 FL 在 CPS 中的应用，强调隐私和鲁棒性；贡献在于分析算法和实际部署，H. Vincent Poor 等作者的参与提升话题度。\n- **CityNavAgent: Aerial Vision-and-Language Navigation**（航空视觉语言导航代理）：Weichen Zhang 等提出层次规划模块，提升无人机在城市环境中的导航；主要发现是结合 LLM 减少复杂性，代码开源。\n- **ReactDance: Progressive-Granular Representation for Long-Term Coherent Reactive Dance Generation**（反应式舞蹈生成）：Jingzhong Lin 等创新多尺度表示和采样策略，生成连贯舞蹈动作；发现提升互动保真度，但其他生成任务如图像合成快速掠过。\n- **Flight Validation of Learning-Based Trajectory Optimization**（基于学习的轨迹优化飞行验证）：Somrita Banerjee 等在国际空间站验证机器学习优化，减少计算需求；贡献在于实际部署的加速。\n\n今日论文整体质量高，AI 领域主导，许多工作开源（如代码链接），但部分论文（如某些分类模型）较常规，建议读者关注 LLM 和医疗应用以获取前沿洞见。更多细节可查阅 arXiv。",
  "papers": [
    {
      "arxiv_id": "2505.05684v1",
      "title": "Prompted Meta-Learning for Few-shot Knowledge Graph Completion",
      "title_zh": "翻译失败",
      "authors": [
        "Han Wu",
        "Jie Yin"
      ],
      "abstract": "Few-shot knowledge graph completion (KGC) has obtained significant attention\ndue to its practical applications in real-world scenarios, where new knowledge\noften emerges with limited available data. While most existing methods for\nfew-shot KGC have predominantly focused on leveraging relational information,\nrich semantics inherent in KGs have been largely overlooked. To address this\ngap, we propose a novel prompted meta-learning (PromptMeta) framework that\nseamlessly integrates meta-semantics with relational information for few-shot\nKGC. PrompMeta has two key innovations: (1) a meta-semantic prompt pool that\ncaptures and consolidates high-level meta-semantics, enabling effective\nknowledge transfer and adaptation to rare and newly emerging relations. (2) a\nlearnable fusion prompt that dynamically combines meta-semantic information\nwith task-specific relational information tailored to different few-shot tasks.\nBoth components are optimized together with model parameters within a\nmeta-learning framework. Extensive experiments on two benchmark datasets\ndemonstrate the effectiveness of our approach.",
      "tldr_zh": "该论文针对 Few-shot Knowledge Graph Completion 的实际挑战，提出了一种 Prompted Meta-Learning (PromptMeta) 框架，以整合知识图谱 (KGs) 中的丰富语义信息和关系信息。PromptMeta 的关键创新包括：meta-semantic prompt pool，用于捕捉高层元语义以促进知识转移和适应稀有关系；以及 learnable fusion prompt，用于动态结合元语义与任务特定关系信息。框架在 meta-learning 框架中优化模型参数，并在两个基准数据集上进行的广泛实验中，证明了其有效性，提高了少样本任务的性能。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05684v1",
      "published_date": "2025-05-08 22:59:42 UTC",
      "updated_date": "2025-05-08 22:59:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:48:02.533050"
    },
    {
      "arxiv_id": "2505.05683v1",
      "title": "Interactive Diabetes Risk Prediction Using Explainable Machine Learning: A Dash-Based Approach with SHAP, LIME, and Comorbidity Insights",
      "title_zh": "翻译失败",
      "authors": [
        "Udaya Allani"
      ],
      "abstract": "This study presents a web-based interactive health risk prediction tool\ndesigned to assess diabetes risk using machine learning models. Built on the\n2015 CDC BRFSS dataset, the study evaluates models including Logistic\nRegression, Random Forest, XGBoost, LightGBM, KNN, and Neural Networks under\noriginal, SMOTE, and undersampling strategies. LightGBM with undersampling\nachieved the best recall, making it ideal for risk detection. The tool\nintegrates SHAP and LIME to explain predictions and highlights comorbidity\ncorrelations using Pearson analysis. A Dash-based UI enables user-friendly\ninteraction with model predictions, personalized suggestions, and feature\ninsights, supporting data-driven health awareness.",
      "tldr_zh": "本研究开发了一个基于网络的交互式工具，用于评估糖尿病风险，基于2015 CDC BRFSS数据集。研究评估了多种机器学习模型，包括Logistic Regression、Random Forest、XGBoost、LightGBM、KNN和Neural Networks，在original、SMOTE和undersampling策略下进行比较，结果显示LightGBM with undersampling取得了最佳recall，适合风险检测。该工具整合了SHAP和LIME来解释预测结果，并使用Pearson analysis突出共病（comorbidity）相关性；同时，通过Dash-based UI提供用户友好的交互界面，包括个性化建议和特征洞察，从而支持数据驱动的健康意识提升。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.1; I.5.2; J.3"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 21 figures, submitted as a preprint for academic\n  dissemination",
      "pdf_url": "http://arxiv.org/pdf/2505.05683v1",
      "published_date": "2025-05-08 22:57:21 UTC",
      "updated_date": "2025-05-08 22:57:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:48:14.009148"
    },
    {
      "arxiv_id": "2505.06320v1",
      "title": "Divide (Text) and Conquer (Sentiment): Improved Sentiment Classification by Constituent Conflict Resolution",
      "title_zh": "分治（文本）和征服（情感）：通过成分冲突解析改进的情感分类",
      "authors": [
        "Jan Kościałkowski",
        "Paweł Marcinkowski"
      ],
      "abstract": "Sentiment classification, a complex task in natural language processing,\nbecomes even more challenging when analyzing passages with multiple conflicting\ntones. Typically, longer passages exacerbate this issue, leading to decreased\nmodel performance. The aim of this paper is to introduce novel methodologies\nfor isolating conflicting sentiments and aggregating them to effectively\npredict the overall sentiment of such passages. One of the aggregation\nstrategies involves a Multi-Layer Perceptron (MLP) model which outperforms\nbaseline models across various datasets, including Amazon, Twitter, and SST\nwhile costing $\\sim$1/100 of what fine-tuning the baseline would take.",
      "tldr_zh": "这篇论文针对情感分类(Sentiment Classification)中的挑战，提出了一种新方法，通过隔离文本中的冲突成分并进行聚合，来处理长段落中多重冲突语气的问题。方法包括使用 Multi-Layer Perceptron (MLP) 模型作为聚合策略，该模型在 Amazon、Twitter 和 SST 数据集上显著超过了基线模型。相比微调基线模型，该方法仅需约 1/100 的计算成本，提高了情感分类的效率和性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 6 figures, 4 tables, developed as a final project for the\n  Stanford Center for Professional Education XCS224U (Natural Language\n  Understanding) course",
      "pdf_url": "http://arxiv.org/pdf/2505.06320v1",
      "published_date": "2025-05-08 21:54:49 UTC",
      "updated_date": "2025-05-08 21:54:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:48:24.940208"
    },
    {
      "arxiv_id": "2505.05666v1",
      "title": "Lost in OCR Translation? Vision-Based Approaches to Robust Document Retrieval",
      "title_zh": "在 OCR 翻译中迷失？ ",
      "authors": [
        "Alexander Most",
        "Joseph Winjum",
        "Ayan Biswas",
        "Shawn Jones",
        "Nishath Rajiv Ranasinghe",
        "Dan O'Malley",
        "Manish Bhattarai"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) has become a popular technique for\nenhancing the reliability and utility of Large Language Models (LLMs) by\ngrounding responses in external documents. Traditional RAG systems rely on\nOptical Character Recognition (OCR) to first process scanned documents into\ntext. However, even state-of-the-art OCRs can introduce errors, especially in\ndegraded or complex documents. Recent vision-language approaches, such as\nColPali, propose direct visual embedding of documents, eliminating the need for\nOCR. This study presents a systematic comparison between a vision-based RAG\nsystem (ColPali) and more traditional OCR-based pipelines utilizing Llama 3.2\n(90B) and Nougat OCR across varying document qualities. Beyond conventional\nretrieval accuracy metrics, we introduce a semantic answer evaluation benchmark\nto assess end-to-end question-answering performance. Our findings indicate that\nwhile vision-based RAG performs well on documents it has been fine-tuned on,\nOCR-based RAG is better able to generalize to unseen documents of varying\nquality. We highlight the key trade-offs between computational efficiency and\nsemantic accuracy, offering practical guidance for RAG practitioners in\nselecting between OCR-dependent and vision-based document retrieval systems in\nproduction environments.",
      "tldr_zh": "这篇论文比较了基于视觉的检索增强生成（RAG）系统（如 ColPali）和传统的基于 Optical Character Recognition (OCR) 的系统（如 Llama 3.2 和 Nougat OCR），以评估它们在处理不同质量文档时的鲁棒性。研究引入了一个语义答案评估基准，不仅考察检索准确性，还测试端到端问答性能。结果表明，视觉-based RAG 在微调过的文档上表现良好，但 OCR-based RAG 更能泛化到未见文档。论文突出了计算效率与语义准确性之间的关键权衡，为 RAG 实践者在生产环境中选择系统提供了实用指导。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05666v1",
      "published_date": "2025-05-08 21:54:02 UTC",
      "updated_date": "2025-05-08 21:54:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:48:37.646864"
    },
    {
      "arxiv_id": "2505.05665v1",
      "title": "Adaptive Stress Testing Black-Box LLM Planners",
      "title_zh": "自适应压力测试黑盒 LLM 规划器",
      "authors": [
        "Neeloy Chakraborty",
        "John Pohovey",
        "Melkior Ornik",
        "Katherine Driggs-Campbell"
      ],
      "abstract": "Large language models (LLMs) have recently demonstrated success in\ngeneralizing across decision-making tasks including planning, control and\nprediction, but their tendency to hallucinate unsafe and undesired outputs\nposes risks. We argue that detecting such failures is necessary, especially in\nsafety-critical scenarios. Existing black-box methods often detect\nhallucinations by identifying inconsistencies across multiple samples. Many of\nthese approaches typically introduce prompt perturbations like randomizing\ndetail order or generating adversarial inputs, with the intuition that a\nconfident model should produce stable outputs. We first perform a manual case\nstudy showing that other forms of perturbations (e.g., adding noise, removing\nsensor details) cause LLMs to hallucinate in a driving environment. We then\npropose a novel method for efficiently searching the space of prompt\nperturbations using Adaptive Stress Testing (AST) with Monte-Carlo Tree Search\n(MCTS). Our AST formulation enables discovery of scenarios and prompts that\ncause language models to act with high uncertainty. By generating MCTS prompt\nperturbation trees across diverse scenarios, we show that offline analyses can\nbe used at runtime to automatically generate prompts that influence model\nuncertainty, and to inform real-time trust assessments of an LLM.",
      "tldr_zh": "本论文探讨了大型语言模型(LLMs)在规划、控制和预测等决策任务中的幻觉问题，强调在安全关键场景下检测这些失败的必要性，通过手动案例研究发现，如添加噪声或移除传感器细节等提示扰动会加剧LLMs的幻觉。作者提出了一种新方法，使用Adaptive Stress Testing (AST)结合Monte-Carlo Tree Search (MCTS)来高效搜索提示扰动空间，从而识别导致模型高度不确定性的场景和提示。该方法通过生成提示扰动树，支持离线分析并应用于运行时，自动生成影响不确定性的提示，并为LLMs的实时信任评估提供指导。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.RO",
      "comment": "26 pages, 16 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.05665v1",
      "published_date": "2025-05-08 21:50:43 UTC",
      "updated_date": "2025-05-08 21:50:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:48:49.804430"
    },
    {
      "arxiv_id": "2505.08798v1",
      "title": "In-Context Learning for Label-Efficient Cancer Image Classification in Oncology",
      "title_zh": "翻译失败",
      "authors": [
        "Mobina Shrestha",
        "Bishwas Mandal",
        "Vishal Mandal",
        "Asis Shrestha"
      ],
      "abstract": "The application of AI in oncology has been limited by its reliance on large,\nannotated datasets and the need for retraining models for domain-specific\ndiagnostic tasks. Taking heed of these limitations, we investigated in-context\nlearning as a pragmatic alternative to model retraining by allowing models to\nadapt to new diagnostic tasks using only a few labeled examples at inference,\nwithout the need for retraining. Using four vision-language models\n(VLMs)-Paligemma, CLIP, ALIGN and GPT-4o, we evaluated the performance across\nthree oncology datasets: MHIST, PatchCamelyon and HAM10000. To the best of our\nknowledge, this is the first study to compare the performance of multiple VLMs\non different oncology classification tasks. Without any parameter updates, all\nmodels showed significant gains with few-shot prompting, with GPT-4o reaching\nan F1 score of 0.81 in binary classification and 0.60 in multi-class\nclassification settings. While these results remain below the ceiling of fully\nfine-tuned systems, they highlight the potential of ICL to approximate\ntask-specific behavior using only a handful of examples, reflecting how\nclinicians often reason from prior cases. Notably, open-source models like\nPaligemma and CLIP demonstrated competitive gains despite their smaller size,\nsuggesting feasibility for deployment in computing constrained clinical\nenvironments. Overall, these findings highlight the potential of ICL as a\npractical solution in oncology, particularly for rare cancers and\nresource-limited contexts where fine-tuning is infeasible and annotated data is\ndifficult to obtain.",
      "tldr_zh": "这篇论文探讨了In-Context Learning (ICL)作为一种标签高效方法，用于肿瘤学图像分类，旨在克服AI对大量标注数据集和模型重新训练的依赖。研究者评估了四个Vision-Language Models (VLMs)——Paligemma、CLIP、ALIGN和GPT-4o，在MHIST、PatchCamelyon和HAM10000等数据集上进行少样本提示(Few-Shot Prompting)测试。结果显示，所有模型无需参数更新即可显著提升性能，GPT-4o在二元分类中达到F1 score 0.81，在多类分类中达到0.60。总体上，该研究证明了ICL在资源有限的临床环境中，尤其针对罕见癌症的潜力，能够模拟临床医生的推理方式而无需大量数据。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08798v1",
      "published_date": "2025-05-08 20:49:01 UTC",
      "updated_date": "2025-05-08 20:49:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:49:02.753003"
    },
    {
      "arxiv_id": "2505.05638v1",
      "title": "Closing the Loop: Motion Prediction Models beyond Open-Loop Benchmarks",
      "title_zh": "闭环：超越开环基准测试的运动预测模型",
      "authors": [
        "Mohamed-Khalil Bouzidi",
        "Christian Schlauch",
        "Nicole Scheuerer",
        "Yue Yao",
        "Nadja Klein",
        "Daniel Göhring",
        "Jörg Reichardt"
      ],
      "abstract": "Fueled by motion prediction competitions and benchmarks, recent years have\nseen the emergence of increasingly large learning based prediction models, many\nwith millions of parameters, focused on improving open-loop prediction accuracy\nby mere centimeters. However, these benchmarks fail to assess whether such\nimprovements translate to better performance when integrated into an autonomous\ndriving stack. In this work, we systematically evaluate the interplay between\nstate-of-the-art motion predictors and motion planners. Our results show that\nhigher open-loop accuracy does not always correlate with better closed-loop\ndriving behavior and that other factors, such as temporal consistency of\npredictions and planner compatibility, also play a critical role. Furthermore,\nwe investigate downsized variants of these models, and, surprisingly, find that\nin some cases models with up to 86% fewer parameters yield comparable or even\nsuperior closed-loop driving performance. Our code is available at\nhttps://github.com/continental/pred2plan.",
      "tldr_zh": "本研究挑战了传统运动预测模型的评估方式，指出现有的开放循环（open-loop）基准虽能提升预测准确性，但无法反映其在自动驾驶系统中的实际表现。研究者系统评估了状态-of-the-art 运动预测模型与运动规划器的互动，发现更高的开放循环准确性并不总是导致更好的闭环（closed-loop）驾驶行为，而预测的一致性和规划器兼容性等因素至关重要。此外，实验显示，某些参数减少高达86%的模型变体在闭环性能上可实现相当或更优的结果，为高效模型设计提供了新见解。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05638v1",
      "published_date": "2025-05-08 20:38:49 UTC",
      "updated_date": "2025-05-08 20:38:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:49:13.069129"
    },
    {
      "arxiv_id": "2505.05626v2",
      "title": "Looking Beyond Language Priors: Enhancing Visual Comprehension and Attention in Multimodal Models",
      "title_zh": "超越语言先验：增强多模态模型中的视觉理解和注意力",
      "authors": [
        "Aarti Ghatkesar",
        "Uddeshya Upadhyay",
        "Ganesh Venkatesh"
      ],
      "abstract": "Achieving deep alignment between vision and language remains a central\nchallenge for Multimodal Large Language Models (MLLMs). These models often fail\nto fully leverage visual input, defaulting to strong language priors. Our\napproach first provides insights into how MLLMs internally build visual\nunderstanding of image regions and then introduces techniques to amplify this\ncapability. Specifically, we explore techniques designed both to deepen the\nmodel's understanding of visual content and to ensure that these visual\ninsights actively guide language generation. We demonstrate the superior\nmultimodal understanding of our resultant model through a detailed upstream\nanalysis quantifying its ability to predict visually-dependent tokens as well\nas 10 pt boost on visually challenging tasks.",
      "tldr_zh": "该论文探讨了 Multimodal Large Language Models (MLLMs) 在视觉和语言对齐上的挑战，这些模型往往依赖语言先验而未能充分利用视觉输入。研究团队通过分析 MLLMs 如何内部构建图像区域的视觉理解，并引入技术来加深模型对视觉内容的理解，同时确保这些视觉洞见指导语言生成。实验结果显示，该方法显著提升了模型预测视觉依赖标记的能力，并在视觉挑战任务上实现了 10 pt 的性能提升。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05626v2",
      "published_date": "2025-05-08 20:04:27 UTC",
      "updated_date": "2025-05-22 05:31:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:49:25.171442"
    },
    {
      "arxiv_id": "2505.05625v1",
      "title": "SPIN-ODE: Stiff Physics-Informed Neural ODE for Chemical Reaction Rate Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Wenqing Peng",
        "Zhi-Song Liu",
        "Michael Boy"
      ],
      "abstract": "Estimating rate constants from complex chemical reactions is essential for\nadvancing detailed chemistry. However, the stiffness inherent in real-world\natmospheric chemistry systems poses severe challenges, leading to training\ninstability and poor convergence that hinder effective rate constant estimation\nusing learning-based approaches. To address this, we propose a Stiff\nPhysics-Informed Neural ODE framework (SPIN-ODE) for chemical reaction\nmodelling. Our method introduces a three-stage optimisation process: first, a\nlatent neural ODE learns the continuous and differentiable trajectory between\nchemical concentrations and their time derivatives; second, an explicit\nChemical Reaction Neural Network (CRNN) extracts the underlying rate\ncoefficients based on the learned dynamics; and third, fine-tune CRNN using a\nneural ODE solver to further improve rate coefficient estimation. Extensive\nexperiments on both synthetic and newly proposed real-world datasets validate\nthe effectiveness and robustness of our approach. As the first work on stiff\nNeural ODEs for chemical rate coefficient discovery, our study opens promising\ndirections for integrating neural networks with detailed chemistry.",
      "tldr_zh": "该研究提出SPIN-ODE框架，一种基于刚性Physics-Informed Neural ODE的方法，用于估计复杂化学反应的速率常数，以解决真实大气化学系统中的训练不稳定性和收敛问题。该框架采用三阶段优化过程：首先，使用latent neural ODE学习化学浓度与时间导数之间的连续轨迹；其次，基于Chemical Reaction Neural Network (CRNN)提取底层速率系数；最后，通过neural ODE求解器微调CRNN以提升估计精度。在合成和真实数据集上的广泛实验验证了SPIN-ODE的有效性和鲁棒性，作为首个针对刚性Neural ODEs的化学速率系数发现工作，它为神经网络与详细化学集成的未来研究开辟了新方向。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05625v1",
      "published_date": "2025-05-08 20:03:30 UTC",
      "updated_date": "2025-05-08 20:03:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:49:37.273545"
    },
    {
      "arxiv_id": "2505.05622v1",
      "title": "CityNavAgent: Aerial Vision-and-Language Navigation with Hierarchical Semantic Planning and Global Memory",
      "title_zh": "翻译失败",
      "authors": [
        "Weichen Zhang",
        "Chen Gao",
        "Shiquan Yu",
        "Ruiying Peng",
        "Baining Zhao",
        "Qian Zhang",
        "Jinqiang Cui",
        "Xinlei Chen",
        "Yong Li"
      ],
      "abstract": "Aerial vision-and-language navigation (VLN), requiring drones to interpret\nnatural language instructions and navigate complex urban environments, emerges\nas a critical embodied AI challenge that bridges human-robot interaction, 3D\nspatial reasoning, and real-world deployment. Although existing ground VLN\nagents achieved notable results in indoor and outdoor settings, they struggle\nin aerial VLN due to the absence of predefined navigation graphs and the\nexponentially expanding action space in long-horizon exploration. In this work,\nwe propose \\textbf{CityNavAgent}, a large language model (LLM)-empowered agent\nthat significantly reduces the navigation complexity for urban aerial VLN.\nSpecifically, we design a hierarchical semantic planning module (HSPM) that\ndecomposes the long-horizon task into sub-goals with different semantic levels.\nThe agent reaches the target progressively by achieving sub-goals with\ndifferent capacities of the LLM. Additionally, a global memory module storing\nhistorical trajectories into a topological graph is developed to simplify\nnavigation for visited targets. Extensive benchmark experiments show that our\nmethod achieves state-of-the-art performance with significant improvement.\nFurther experiments demonstrate the effectiveness of different modules of\nCityNavAgent for aerial VLN in continuous city environments. The code is\navailable at \\href{https://github.com/VinceOuti/CityNavAgent}{link}.",
      "tldr_zh": "这篇论文提出了CityNavAgent，一种基于大型语言模型(LLM)的代理，用于空中视觉和语言导航(Aerial VLN)，旨在帮助无人机在复杂城市环境中根据自然语言指令进行长horizon探索。CityNavAgent的核心包括Hierarchical Semantic Planning Module (HSPM)，该模块将任务分解为不同语义级别的子目标，通过LLM的逐步能力实现目标定位，以及Global Memory Module，用于存储历史轨迹到拓扑图中以简化已访问区域的导航。实验结果显示，该方法在基准测试中实现了最先进性能，并显著提升了导航准确性，为空中VLN的实际部署提供了有效解决方案。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05622v1",
      "published_date": "2025-05-08 20:01:35 UTC",
      "updated_date": "2025-05-08 20:01:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:49:49.737959"
    },
    {
      "arxiv_id": "2505.05616v1",
      "title": "Leveraging Large Language Models for enzymatic reaction prediction and characterization",
      "title_zh": "翻译失败",
      "authors": [
        "Lorenzo Di Fruscia",
        "Jana Marie Weber"
      ],
      "abstract": "Predicting enzymatic reactions is crucial for applications in biocatalysis,\nmetabolic engineering, and drug discovery, yet it remains a complex and\nresource-intensive task. Large Language Models (LLMs) have recently\ndemonstrated remarkable success in various scientific domains, e.g., through\ntheir ability to generalize knowledge, reason over complex structures, and\nleverage in-context learning strategies. In this study, we systematically\nevaluate the capability of LLMs, particularly the Llama-3.1 family (8B and\n70B), across three core biochemical tasks: Enzyme Commission number prediction,\nforward synthesis, and retrosynthesis. We compare single-task and multitask\nlearning strategies, employing parameter-efficient fine-tuning via LoRA\nadapters. Additionally, we assess performance across different data regimes to\nexplore their adaptability in low-data settings. Our results demonstrate that\nfine-tuned LLMs capture biochemical knowledge, with multitask learning\nenhancing forward- and retrosynthesis predictions by leveraging shared\nenzymatic information. We also identify key limitations, for example challenges\nin hierarchical EC classification schemes, highlighting areas for further\nimprovement in LLM-driven biochemical modeling.",
      "tldr_zh": "本研究探讨了利用大型语言模型（LLMs），特别是 Llama-3.1 家族（8B 和 70B 模型），来预测和表征酶促反应，以支持生物催化、代谢工程和药物发现等应用。研究者评估了 LLMs 在酶委员会号（Enzyme Commission number）预测、正向合成和逆合成等三项核心生化任务上的性能，通过 LoRA 适配器实现参数高效微调，并比较了单任务和多任务学习策略。结果显示，微调后的 LLMs 能够有效捕捉生化知识，多任务学习通过共享酶信息显著提升了合成预测的准确性；然而，LLMs 在分层 EC 分类方案中存在挑战，突显了进一步改进 LLM 在生化建模中的潜力。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "q-bio.BM"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05616v1",
      "published_date": "2025-05-08 19:53:53 UTC",
      "updated_date": "2025-05-08 19:53:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:50:02.950411"
    },
    {
      "arxiv_id": "2505.05612v1",
      "title": "scDrugMap: Benchmarking Large Foundation Models for Drug Response Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Qing Wang",
        "Yining Pan",
        "Minghao Zhou",
        "Zijia Tang",
        "Yanfei Wang",
        "Guangyu Wang",
        "Qianqian Song"
      ],
      "abstract": "Drug resistance presents a major challenge in cancer therapy. Single cell\nprofiling offers insights into cellular heterogeneity, yet the application of\nlarge-scale foundation models for predicting drug response in single cell data\nremains underexplored. To address this, we developed scDrugMap, an integrated\nframework featuring both a Python command-line interface and a web server for\ndrug response prediction. scDrugMap evaluates a wide range of foundation\nmodels, including eight single-cell models and two large language models, using\na curated dataset of over 326,000 cells in the primary collection and 18,800\ncells in the validation set, spanning 36 datasets and diverse tissue and cancer\ntypes. We benchmarked model performance under pooled-data and cross-data\nevaluation settings, employing both layer freezing and Low-Rank Adaptation\n(LoRA) fine-tuning strategies. In the pooled-data scenario, scFoundation\nachieved the best performance, with mean F1 scores of 0.971 (layer freezing)\nand 0.947 (fine-tuning), outperforming the lowest-performing model by over 50%.\nIn the cross-data setting, UCE excelled post fine-tuning (mean F1: 0.774),\nwhile scGPT led in zero-shot learning (mean F1: 0.858). Overall, scDrugMap\nprovides the first large-scale benchmark of foundation models for drug response\nprediction in single-cell data and serves as a user-friendly, flexible platform\nfor advancing drug discovery and translational research.",
      "tldr_zh": "该研究开发了 scDrugMap 框架，用于评估大型 Foundation Models 在单细胞数据中预测药物反应的性能，旨在解决癌症治疗中的药物抵抗挑战。scDrugMap 整合了 Python 命令行界面和 web 服务器，基准测试了八个单细胞模型和两个大语言模型，使用超过 326,000 个细胞的精选数据集，涵盖 36 个数据集和多种组织及癌症类型，并采用层冻结和 Low-Rank Adaptation (LoRA) 微调策略。结果显示，在池化数据场景中，scFoundation 表现最佳（平均 F1 分数分别为 0.971 和 0.947），而在跨数据设置中，UCE 在微调后领先（平均 F1: 0.774），scGPT 在零样本学习中表现出色（平均 F1: 0.858）。总之，scDrugMap 提供了首个大规模基准平台，促进药物发现和翻译研究的发展。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "q-bio.QM"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.05612v1",
      "published_date": "2025-05-08 19:46:19 UTC",
      "updated_date": "2025-05-08 19:46:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:50:14.710131"
    },
    {
      "arxiv_id": "2505.13469v1",
      "title": "Algorithmic Tradeoffs in Fair Lending: Profitability, Compliance, and Long-Term Impact",
      "title_zh": "公平借贷中的算法权衡",
      "authors": [
        "Aayam Bansal",
        "Harsh Vardhan Narsaria"
      ],
      "abstract": "As financial institutions increasingly rely on machine learning models to\nautomate lending decisions, concerns about algorithmic fairness have risen.\nThis paper explores the tradeoff between enforcing fairness constraints (such\nas demographic parity or equal opportunity) and maximizing lender\nprofitability. Through simulations on synthetic data that reflects real-world\nlending patterns, we quantify how different fairness interventions impact\nprofit margins and default rates. Our results demonstrate that equal\nopportunity constraints typically impose lower profit costs than demographic\nparity, but surprisingly, removing protected attributes from the model\n(fairness through unawareness) outperforms explicit fairness interventions in\nboth fairness and profitability metrics. We further identify the specific\neconomic conditions under which fair lending becomes profitable and analyze the\nfeature-specific drivers of unfairness. These findings offer practical guidance\nfor designing lending algorithms that balance ethical considerations with\nbusiness objectives.",
      "tldr_zh": "这篇论文探讨了在借贷决策中使用机器学习模型时，公平约束（如 demographic parity 或 equal opportunity）与最大化盈利之间的算法权衡。通过对合成数据的模拟，研究量化了不同公平干预对利润率和违约率的影响，结果显示 equal opportunity 约束对利润的成本较低，而 fairness through unawareness（移除受保护属性）在公平性和盈利性指标上优于显式干预。论文进一步识别了公平借贷变得盈利的具体经济条件，并分析了不公平性的特征驱动因素，为设计平衡伦理考虑与商业目标的借贷算法提供了实用指导。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CE",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.13469v1",
      "published_date": "2025-05-08 19:18:33 UTC",
      "updated_date": "2025-05-08 19:18:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:50:25.446014"
    },
    {
      "arxiv_id": "2505.05602v1",
      "title": "HiBayES: A Hierarchical Bayesian Modeling Framework for AI Evaluation Statistics",
      "title_zh": "HiBayES：AI评估统计的分层贝叶斯建模框架",
      "authors": [
        "Lennart Luettgau",
        "Harry Coppock",
        "Magda Dubois",
        "Christopher Summerfield",
        "Cozmin Ududec"
      ],
      "abstract": "As Large Language Models (LLMs) and other AI systems evolve, robustly\nestimating their capabilities from inherently stochastic outputs while\nsystematically quantifying uncertainty in these estimates becomes increasingly\nimportant. Further, advanced AI evaluations often have a nested hierarchical\nstructure, exhibit high levels of complexity, and come with high costs in\ntesting the most advanced AI systems. To address these challenges, we introduce\nHiBayES, a generalizable Hierarchical Bayesian modeling framework for AI\nEvaluation Statistics. HiBayES supports robust inferences in classical\nquestion-answer benchmarks and advanced agentic evaluations, particularly in\nlow-data scenarios (e.g., < 20 data points per evaluation). Built on\nGeneralized Linear Models (GLMs), Bayesian data analysis, and formal model\ncomparison, HiBayES provides principled uncertainty quantification and robust\nparameter estimation. This paper offers a comprehensive introduction to\nHiBayES, including illustrative examples, comparisons to conventional\nstatistical methods, and practical guidance for implementing multilevel\nBayesian GLMs. Additionally, we provide a HiBayES software package [4] (Beta\nversion) for out-of-the-box implementation.",
      "tldr_zh": "本文提出HiBayES，一种通用的分层贝叶斯建模框架，用于AI评估统计，帮助从随机输出中稳健估计AI系统能力并量化不确定性。HiBayES基于Generalized Linear Models (GLMs)、贝叶斯数据分析和模型比较，支持在低数据场景（如少于20个数据点）下的层次化推理，并在经典问答基准和高级代理评估中表现出色。论文提供示例、与其他方法的比较、实施指导，并附带HiBayES软件包（Beta版）以便实际应用。",
      "categories": [
        "cs.AI",
        "stat.AP"
      ],
      "primary_category": "cs.AI",
      "comment": "23 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.05602v1",
      "published_date": "2025-05-08 19:05:02 UTC",
      "updated_date": "2025-05-08 19:05:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:50:38.121191"
    },
    {
      "arxiv_id": "2505.05599v1",
      "title": "Enhancing Satellite Object Localization with Dilated Convolutions and Attention-aided Spatial Pooling",
      "title_zh": "使用膨胀卷积和注意力辅助空间池化增强卫星物体定位",
      "authors": [
        "Seraj Al Mahmud Mostafa",
        "Chenxi Wang",
        "Jia Yue",
        "Yuta Hozumi",
        "Jianwu Wang"
      ],
      "abstract": "Object localization in satellite imagery is particularly challenging due to\nthe high variability of objects, low spatial resolution, and interference from\nnoise and dominant features such as clouds and city lights. In this research,\nwe focus on three satellite datasets: upper atmospheric Gravity Waves (GW),\nmesospheric Bores (Bore), and Ocean Eddies (OE), each presenting its own unique\nchallenges. These challenges include the variability in the scale and\nappearance of the main object patterns, where the size, shape, and feature\nextent of objects of interest can differ significantly. To address these\nchallenges, we introduce YOLO-DCAP, a novel enhanced version of YOLOv5 designed\nto improve object localization in these complex scenarios. YOLO-DCAP\nincorporates a Multi-scale Dilated Residual Convolution (MDRC) block to capture\nmulti-scale features at scale with varying dilation rates, and an\nAttention-aided Spatial Pooling (AaSP) module to focus on the global relevant\nspatial regions, enhancing feature selection. These structural improvements\nhelp to better localize objects in satellite imagery. Experimental results\ndemonstrate that YOLO-DCAP significantly outperforms both the YOLO base model\nand state-of-the-art approaches, achieving an average improvement of 20.95% in\nmAP50 and 32.23% in IoU over the base model, and 7.35% and 9.84% respectively\nover state-of-the-art alternatives, consistently across all three satellite\ndatasets. These consistent gains across all three satellite datasets highlight\nthe robustness and generalizability of the proposed approach. Our code is open\nsourced at\nhttps://github.com/AI-4-atmosphere-remote-sensing/satellite-object-localization.",
      "tldr_zh": "这篇论文针对卫星图像对象定位的挑战（如对象高度可变、低空间分辨率和噪声干扰），提出了 YOLO-DCAP，一种基于 YOLOv5 的增强模型。YOLO-DCAP 引入了 Multi-scale Dilated Residual Convolution (MDRC) 块来捕捉多尺度特征，以及 Attention-aided Spatial Pooling (AaSP) 模块来关注全局相关空间区域，从而改善特征选择和对象定位。实验结果显示，在 Gravity Waves (GW)、Mesospheric Bores (Bore) 和 Ocean Eddies (OE) 等三个数据集上，YOLO-DCAP 比基线模型平均提高了 20.95% 的 mAP50 和 32.23% 的 IoU，并分别比最先进方法提升 7.35% 和 9.84%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "This paper has been accepted to International conference on Advanced\n  Machine Learning and Data Science (AMLDS) 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.05599v1",
      "published_date": "2025-05-08 18:59:59 UTC",
      "updated_date": "2025-05-08 18:59:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:50:50.551744"
    },
    {
      "arxiv_id": "2505.06315v1",
      "title": "Threat Modeling for AI: The Case for an Asset-Centric Approach",
      "title_zh": "AI 威胁建模：资产中心方法的论据",
      "authors": [
        "Jose Sanchez Vicarte",
        "Marcin Spoczynski",
        "Mostafa Elsaid"
      ],
      "abstract": "Recent advances in AI are transforming AI's ubiquitous presence in our world\nfrom that of standalone AI-applications into deeply integrated AI-agents. These\nchanges have been driven by agents' increasing capability to autonomously make\ndecisions and initiate actions, using existing applications; whether those\napplications are AI-based or not. This evolution enables unprecedented levels\nof AI integration, with agents now able to take actions on behalf of systems\nand users -- including, in some cases, the powerful ability for the AI to write\nand execute scripts as it deems necessary. With AI systems now able to\nautonomously execute code, interact with external systems, and operate without\nhuman oversight, traditional security approaches fall short.\n  This paper introduces an asset-centric methodology for threat modeling AI\nsystems that addresses the unique security challenges posed by integrated AI\nagents. Unlike existing top-down frameworks that analyze individual attacks\nwithin specific product contexts, our bottom-up approach enables defenders to\nsystematically identify how vulnerabilities -- both conventional and\nAI-specific -- impact critical AI assets across distributed infrastructures\nused to develop and deploy these agents. This methodology allows security teams\nto: (1) perform comprehensive analysis that communicates effectively across\ntechnical domains, (2) quantify security assumptions about third-party AI\ncomponents without requiring visibility into their implementation, and (3)\nholistically identify AI-based vulnerabilities relevant to their specific\nproduct context. This approach is particularly relevant for securing agentic\nsystems with complex autonomous capabilities. By focusing on assets rather than\nattacks, our approach scales with the rapidly evolving threat landscape while\naccommodating increasingly complex and distributed AI development pipelines.",
      "tldr_zh": "这篇论文讨论了AI系统威胁建模的挑战，强调随着AI代理（AI agents）从独立应用演变为深度集成自主系统，传统安全方法已不足以应对其决策和行动能力。论文提出了一种资产中心（asset-centric）方法，通过自下而上的框架系统识别常规和AI特定漏洞对关键AI资产的影响，从而在分布式基础设施中进行全面分析。相比现有顶层框架，该方法允许安全团队量化第三方AI组件的安全假设、提升跨领域沟通，并适应复杂自主系统的演变，为快速变化的AI威胁景观提供可扩展的安全策略。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06315v1",
      "published_date": "2025-05-08 18:57:08 UTC",
      "updated_date": "2025-05-08 18:57:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:51:01.165989"
    },
    {
      "arxiv_id": "2505.05595v1",
      "title": "Trading Under Uncertainty: A Distribution-Based Strategy for Futures Markets Using FutureQuant Transformer",
      "title_zh": "翻译失败",
      "authors": [
        "Wenhao Guo",
        "Yuda Wang",
        "Zeqiao Huang",
        "Changjiang Zhang",
        "Shumin ma"
      ],
      "abstract": "In the complex landscape of traditional futures trading, where vast data and\nvariables like real-time Limit Order Books (LOB) complicate price predictions,\nwe introduce the FutureQuant Transformer model, leveraging attention mechanisms\nto navigate these challenges. Unlike conventional models focused on point\npredictions, the FutureQuant model excels in forecasting the range and\nvolatility of future prices, thus offering richer insights for trading\nstrategies. Its ability to parse and learn from intricate market patterns\nallows for enhanced decision-making, significantly improving risk management\nand achieving a notable average gain of 0.1193% per 30-minute trade over\nstate-of-the-art models with a simple algorithm using factors such as RSI, ATR,\nand Bollinger Bands. This innovation marks a substantial leap forward in\npredictive analytics within the volatile domain of futures trading.",
      "tldr_zh": "本文提出 FutureQuant Transformer 模型，利用注意力机制处理期货交易中的复杂数据，如实时 Limit Order Books (LOB)，专注于预测未来价格的分布范围和波动性，以提供更丰富的交易洞见。不同于传统点预测模型，该方法通过解析复杂市场模式，提升决策能力和风险管理。实验结果显示，FutureQuant Transformer 在简单算法下，每 30 分钟交易平均收益达 0.1193%，比基于 RSI、ATR 和 Bollinger Bands 的最先进模型高出显著水平。该创新为不确定性下的期货交易策略带来了重大进步。",
      "categories": [
        "q-fin.TR",
        "cs.AI",
        "cs.CE",
        "cs.LG"
      ],
      "primary_category": "q-fin.TR",
      "comment": "16 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.05595v1",
      "published_date": "2025-05-08 18:52:04 UTC",
      "updated_date": "2025-05-08 18:52:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:51:13.736035"
    },
    {
      "arxiv_id": "2505.06314v1",
      "title": "A4L: An Architecture for AI-Augmented Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Ashok Goel",
        "Ploy Thajchayapong",
        "Vrinda Nandan",
        "Harshvardhan Sikka",
        "Spencer Rugaber"
      ],
      "abstract": "AI promises personalized learning and scalable education. As AI agents\nincreasingly permeate education in support of teaching and learning, there is a\ncritical and urgent need for data architectures for collecting and analyzing\ndata on learning, and feeding the results back to teachers, learners, and the\nAI agents for personalization of learning at scale. At the National AI\nInstitute for Adult Learning and Online Education, we are developing an\nArchitecture for AI-Augmented Learning (A4L) for supporting adult learning\nthrough online education. We present the motivations, goals, requirements of\nthe A4L architecture. We describe preliminary applications of A4L and discuss\nhow it advances the goals of making learning more personalized and scalable.",
      "tldr_zh": "该研究探讨了AI在教育中的潜力，特别是通过AI-Augmented Learning实现个性化学习和可扩展教育，以应对数据收集、分析和反馈的需求。作者介绍了A4L架构，由National AI Institute for Adult Learning and Online Education开发，用于支持在线成人学习，该架构的动机是收集学习数据并反馈给教师、学习者和AI代理，实现大规模个性化。初步应用表明，A4L能推进学习过程的个性化与可扩展性，为AI增强教育提供了一个可行的框架。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "14 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.06314v1",
      "published_date": "2025-05-08 18:47:09 UTC",
      "updated_date": "2025-05-08 18:47:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:51:24.681647"
    },
    {
      "arxiv_id": "2505.05589v1",
      "title": "ReactDance: Progressive-Granular Representation for Long-Term Coherent Reactive Dance Generation",
      "title_zh": "ReactDance：渐进细粒度表示用于长期连贯的反应式舞蹈生成",
      "authors": [
        "Jingzhong Lin",
        "Yuanyuan Qi",
        "Xinru Li",
        "Wenxuan Huang",
        "Xiangfeng Xu",
        "Bangyan Li",
        "Xuejiao Wang",
        "Gaoqi He"
      ],
      "abstract": "Reactive dance generation (RDG) produces follower movements conditioned on\nguiding dancer and music while ensuring spatial coordination and temporal\ncoherence. However, existing methods overemphasize global constraints and\noptimization, overlooking local information, such as fine-grained spatial\ninteractions and localized temporal context. Therefore, we present ReactDance,\na novel diffusion-based framework for high-fidelity RDG with long-term\ncoherence and multi-scale controllability. Unlike existing methods that\nstruggle with interaction fidelity, synchronization, and temporal consistency\nin duet synthesis, our approach introduces two key innovations: 1)Group\nResidual Finite Scalar Quantization (GRFSQ), a multi-scale disentangled motion\nrepresentation that captures interaction semantics from coarse body rhythms to\nfine-grained joint dynamics, and 2)Blockwise Local Context (BLC), a sampling\nstrategy eliminating error accumulation in long sequence generation via local\nblock causal masking and periodic positional encoding. Built on the decoupled\nmulti-scale GRFSQ representation, we implement a diffusion model\nwithLayer-Decoupled Classifier-free Guidance (LDCFG), allowing granular control\nover motion semantics across scales. Extensive experiments on standard\nbenchmarks demonstrate that ReactDance surpasses existing methods, achieving\nstate-of-the-art performance.",
      "tldr_zh": "该研究提出ReactDance，一种基于扩散的框架，用于生成高保真反应式舞蹈（Reactive Dance Generation），它通过捕捉多尺度动作表示来确保长期连贯性和空间协调，同时解决现有方法忽略细粒度互动和局部上下文的问题。关键创新包括Group Residual Finite Scalar Quantization (GRFSQ)，一种多尺度分离的动作表示，用于从粗糙的身体节奏到细粒度关节动态的语义捕捉，以及Blockwise Local Context (BLC)，一种采样策略通过局部块状因果掩码和周期性位置编码消除长序列生成中的错误积累。此外，基于GRFSQ的扩散模型引入Layer-Decoupled Classifier-free Guidance (LDCFG)，实现对动作语义的多尺度粒度控制。实验在标准基准上显示，ReactDance超越现有方法，达到最先进性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05589v1",
      "published_date": "2025-05-08 18:42:38 UTC",
      "updated_date": "2025-05-08 18:42:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:51:37.536477"
    },
    {
      "arxiv_id": "2505.05588v1",
      "title": "Flight Validation of Learning-Based Trajectory Optimization for the Astrobee Free-Flyer",
      "title_zh": "针对 Astro",
      "authors": [
        "Somrita Banerjee",
        "Abhishek Cauligi",
        "Marco Pavone"
      ],
      "abstract": "Although widely used in commercial and industrial robotics, trajectory\noptimization has seen limited use in space applications due to its high\ncomputational demands. In this work, we present flight results from experiments\nwith the Astrobee free-flying robot on board the International Space Station\n(ISS), that demonstrate how machine learning can accelerate on-board trajectory\noptimization while preserving theoretical solver guarantees. To the best of the\nauthors' knowledge, this is the first-ever demonstration of learning-based\ncontrol on the ISS. Our approach leverages the GuSTO sequential convex\nprogramming framework and uses a neural network, trained offline, to map\nproblem parameters to effective initial ``warm-start'' trajectories, paving the\nway for faster real-time optimization on resource-constrained space platforms.",
      "tldr_zh": "本研究在国际空间站（ISS）上对 Astrobee 自由飞行机器人进行了飞行实验，首次展示了机器学习如何加速轨迹优化，同时保持 GuSTO 顺序凸编程框架的理论保证。方法涉及使用一个离线训练的 neural network，将问题参数映射到有效的初始 warm-start 轨迹，从而实现资源受限平台上的实时优化。实验结果证明，该方法显著提高了轨迹优化的效率，为太空应用中的机器人控制提供了新途径。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Submitted to RSS 2025 Workshop on Space Robotics",
      "pdf_url": "http://arxiv.org/pdf/2505.05588v1",
      "published_date": "2025-05-08 18:42:36 UTC",
      "updated_date": "2025-05-08 18:42:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:51:48.703887"
    },
    {
      "arxiv_id": "2505.06313v1",
      "title": "AI Approaches to Qualitative and Quantitative News Analytics on NATO Unity",
      "title_zh": "AI 方法用于北约团结的定性和定量新闻分析",
      "authors": [
        "Bohdan M. Pavlyshenko"
      ],
      "abstract": "The paper considers the use of GPT models with retrieval-augmented generation\n(RAG) for qualitative and quantitative analytics on NATO sentiments, NATO unity\nand NATO Article 5 trust opinion scores in different web sources: news sites\nfound via Google Search API, Youtube videos with comments, and Reddit\ndiscussions. A RAG approach using GPT-4.1 model was applied to analyse news\nwhere NATO related topics were discussed. Two levels of RAG analytics were\nused: on the first level, the GPT model generates qualitative news summaries\nand quantitative opinion scores using zero-shot prompts; on the second level,\nthe GPT model generates the summary of news summaries. Quantitative news\nopinion scores generated by the GPT model were analysed using Bayesian\nregression to get trend lines. The distributions found for the regression\nparameters make it possible to analyse an uncertainty in specified news opinion\nscore trends. Obtained results show a downward trend for analysed scores of\nopinion related to NATO unity.\n  This approach does not aim to conduct real political analysis; rather, it\nconsider AI based approaches which can be used for further analytics\n  as a part of a complex analytical approach. The obtained results demonstrate\nthat the use of GPT models for news analysis can give informative qualitative\nand quantitative analytics, providing important insights.\n  The dynamic model based on neural ordinary differential equations was\nconsidered for modelling public opinions. This approach makes it possible to\nanalyse different scenarios for evolving public opinions.",
      "tldr_zh": "这篇论文探讨了使用 GPT-4.1 模型结合 Retrieval-Augmented Generation (RAG) 进行 NATO 相关新闻的定性和定量分析，包括新闻站点、YouTube 评论和 Reddit 讨论。方法涉及两级 RAG：第一级通过零样本提示生成新闻摘要和意见分数，第二级总结这些摘要，并利用 Bayesian regression 分析意见趋势，结果显示 NATO 统一和 Article 5 信任分数呈下降趋势。论文强调这种 AI 方法并非进行真实政治分析，而是提供有信息性的洞见，并引入基于 neural ordinary differential equations 的动态模型来模拟公共意见演变。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.SI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06313v1",
      "published_date": "2025-05-08 18:42:01 UTC",
      "updated_date": "2025-05-08 18:42:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:52:01.816251"
    },
    {
      "arxiv_id": "2505.11520v1",
      "title": "Decentralized Traffic Flow Optimization Through Intrinsic Motivation",
      "title_zh": "通过",
      "authors": [
        "Himaja Papala",
        "Daniel Polani",
        "Stas Tiomkin"
      ],
      "abstract": "Traffic congestion has long been an ubiquitous problem that is exacerbating\nwith the rapid growth of megacities. In this proof-of-concept work we study\nintrinsic motivation, implemented via the empowerment principle, to control\nautonomous car behavior to improve traffic flow. In standard models of traffic\ndynamics, self-organized traffic jams emerge spontaneously from the individual\nbehavior of cars, affecting traffic over long distances. Our novel car behavior\nstrategy improves traffic flow while still being decentralized and using only\nlocally available information without explicit coordination. Decentralization\nis essential for various reasons, not least to be able to absorb robustly\nsubstantial levels of uncertainty. Our scenario is based on the\nwell-established traffic dynamics model, the Nagel-Schreckenberg cellular\nautomaton. In a fraction of the cars in this model, we substitute the default\nbehavior by empowerment, our intrinsic motivation-based method. This proposed\nmodel significantly improves overall traffic flow, mitigates congestion, and\nreduces the average traffic jam time.",
      "tldr_zh": "该研究针对日益严重的城市交通拥堵问题，提出一种基于 intrinsic motivation 的去中心化优化策略，通过 empowerment principle 控制自动驾驶汽车的行为，以改善整体交通流量。该方法在 Nagel-Schreckenberg cellular automaton 模型中，将部分汽车的默认行为替换为 empowerment 驱动的策略，仅依赖本地信息实现无显式协调的优化。实验结果显示，该策略显著提升交通效率、缓解拥堵并减少平均交通堵塞时间，为鲁棒性强的交通管理系统提供了新思路。",
      "categories": [
        "physics.soc-ph",
        "cs.AI"
      ],
      "primary_category": "physics.soc-ph",
      "comment": "9 pages, 6 figures, Published in the Proceedings of the 2024 IEEE\n  27th International Conference on Intelligent Transportation Systems (ITSC)",
      "pdf_url": "http://arxiv.org/pdf/2505.11520v1",
      "published_date": "2025-05-08 18:28:04 UTC",
      "updated_date": "2025-05-08 18:28:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:52:12.763822"
    },
    {
      "arxiv_id": "2505.05577v1",
      "title": "PyTDC: A multimodal machine learning training, evaluation, and inference platform for biomedical foundation models",
      "title_zh": "PyTDC：一种用于生物医学基础模型的多模态机器学习训练、评估和推理平台",
      "authors": [
        "Alejandro Velez-Arce",
        "Marinka Zitnik"
      ],
      "abstract": "Existing biomedical benchmarks do not provide end-to-end infrastructure for\ntraining, evaluation, and inference of models that integrate multimodal\nbiological data and a broad range of machine learning tasks in therapeutics. We\npresent PyTDC, an open-source machine-learning platform providing streamlined\ntraining, evaluation, and inference software for multimodal biological AI\nmodels. PyTDC unifies distributed, heterogeneous, continuously updated data\nsources and model weights and standardizes benchmarking and inference\nendpoints. This paper discusses the components of PyTDC's architecture and, to\nour knowledge, the first-of-its-kind case study on the introduced single-cell\ndrug-target nomination ML task. We find state-of-the-art methods in graph\nrepresentation learning and domain-specific methods from graph theory perform\npoorly on this task. Though we find a context-aware geometric deep learning\nmethod that outperforms the evaluated SoTA and domain-specific baseline\nmethods, the model is unable to generalize to unseen cell types or incorporate\nadditional modalities, highlighting PyTDC's capacity to facilitate an exciting\navenue of research developing multimodal, context-aware, foundation models for\nopen problems in biomedical AI.",
      "tldr_zh": "这篇论文介绍了 PyTDC，一个开源平台，旨在为生物医学基础模型提供多模态机器学习任务的端到端训练、评估和推理基础设施，以整合异构生物数据。PyTDC 统一了分布式的、不断更新的数据来源和模型权重，并标准化了基准测试和推理端点，同时通过首个单细胞药物靶点提名 ML 任务的案例研究，评估了各种方法。研究发现，graph representation learning 和领域特定方法在该任务上表现不佳，而一个上下文感知的 geometric deep learning 方法虽有优势，但无法泛化到新细胞类型或整合更多模态，突显了 PyTDC 在推动多模态生物 AI 研究方面的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68-04, 92-04",
        "D.2.11; I.2.5; J.3"
      ],
      "primary_category": "cs.LG",
      "comment": "Proceedings of the 42nd International Conference on Machine Learning,\n  Vancouver, Canada. PMLR 267, 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.05577v1",
      "published_date": "2025-05-08 18:15:38 UTC",
      "updated_date": "2025-05-08 18:15:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:52:26.325172"
    },
    {
      "arxiv_id": "2505.05573v2",
      "title": "Prompt to Polyp: Medical Text-Conditioned Image Synthesis with Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Mikhail Chaichuk",
        "Sushant Gautam",
        "Steven Hicks",
        "Elena Tutubalina"
      ],
      "abstract": "The generation of realistic medical images from text descriptions has\nsignificant potential to address data scarcity challenges in healthcare AI\nwhile preserving patient privacy. This paper presents a comprehensive study of\ntext-to-image synthesis in the medical domain, comparing two distinct\napproaches: (1) fine-tuning large pre-trained latent diffusion models and (2)\ntraining small, domain-specific models. We introduce a novel model named MSDM,\nan optimized architecture based on Stable Diffusion that integrates a clinical\ntext encoder, variational autoencoder, and cross-attention mechanisms to better\nalign medical text prompts with generated images. Our study compares two\napproaches: fine-tuning large pre-trained models (FLUX, Kandinsky) versus\ntraining compact domain-specific models (MSDM). Evaluation across colonoscopy\n(MedVQA-GI) and radiology (ROCOv2) datasets reveals that while large models\nachieve higher fidelity, our optimized MSDM delivers comparable quality with\nlower computational costs. Quantitative metrics and qualitative evaluations by\nmedical experts reveal strengths and limitations of each approach.",
      "tldr_zh": "这篇论文探讨了使用扩散模型从医疗文本生成真实图像，以解决医疗AI中的数据稀缺问题，同时保护患者隐私。研究比较了两种方法：微调大型预训练模型（如FLUX和Kandinsky）与训练小型领域特定模型。作者引入了新型MSDM模型，该模型基于Stable Diffusion，整合了临床文本编码器、变分自动编码器和cross-attention mechanisms，以更好地对齐文本提示和生成图像。在MedVQA-GI（结肠镜检查）和ROCOv2（放射学）数据集上的评估显示，大型模型提供更高保真度，但MSDM实现了可比质量且计算成本更低，定量指标和医疗专家定性评估揭示了每种方法的优势与局限性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "68T07, 68U10, 92C55",
        "I.2.10; I.4.8; J.3"
      ],
      "primary_category": "cs.CV",
      "comment": "code available at\n  https://github.com/THunderCondOR/ImageCLEFmed-MEDVQA-GI-2024-MMCP-Team",
      "pdf_url": "http://arxiv.org/pdf/2505.05573v2",
      "published_date": "2025-05-08 18:07:16 UTC",
      "updated_date": "2025-05-12 17:59:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:52:41.912479"
    },
    {
      "arxiv_id": "2505.05568v1",
      "title": "Griffin: Towards a Graph-Centric Relational Database Foundation Model",
      "title_zh": "翻译失败",
      "authors": [
        "Yanbo Wang",
        "Xiyuan Wang",
        "Quan Gan",
        "Minjie Wang",
        "Qibin Yang",
        "David Wipf",
        "Muhan Zhang"
      ],
      "abstract": "We introduce Griffin, the first foundation model attemptation designed\nspecifically for Relational Databases (RDBs). Unlike previous smaller models\nfocused on single RDB tasks, Griffin unifies the data encoder and task decoder\nto handle diverse tasks. Additionally, we enhance the architecture by\nincorporating a cross-attention module and a novel aggregator. Griffin utilizes\npretraining on both single-table and RDB datasets, employing advanced encoders\nfor categorical, numerical, and metadata features, along with innovative\ncomponents such as cross-attention modules and enhanced message-passing neural\nnetworks (MPNNs) to capture the complexities of relational data. Evaluated on\nlarge-scale, heterogeneous, and temporal graphs extracted from RDBs across\nvarious domains (spanning over 150 million nodes), Griffin demonstrates\nsuperior or comparable performance to individually trained models, excels in\nlow-data scenarios, and shows strong transferability with similarity and\ndiversity in pretraining across new datasets and tasks, highlighting its\npotential as a universally applicable foundation model for RDBs. Code available\nat https://github.com/yanxwb/Griffin.",
      "tldr_zh": "本研究引入了Griffin，这是首个针对关系数据库(RDBs)的图中心基础模型，旨在统一数据编码器和任务解码器以处理多样任务。Griffin通过整合交叉注意力模块和新型聚合器，以及高级编码器处理分类、数值和元数据特征，并结合增强的消息传递神经网络(MPNNs)，在单表和RDB数据集上进行预训练，以捕捉关系数据的复杂性。在跨越150百万节点的异构和时间序列图上进行评估，Griffin展现出优于或相当于是单独训练模型的性能，尤其在低数据场景中表现出色，并具有强大的转移能力。代码已在GitHub上公开。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05568v1",
      "published_date": "2025-05-08 18:03:43 UTC",
      "updated_date": "2025-05-08 18:03:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:52:50.477419"
    },
    {
      "arxiv_id": "2505.05470v2",
      "title": "Flow-GRPO: Training Flow Matching Models via Online RL",
      "title_zh": "Flow-GRPO：通过在线强化学习训练流匹配模型",
      "authors": [
        "Jie Liu",
        "Gongye Liu",
        "Jiajun Liang",
        "Yangguang Li",
        "Jiaheng Liu",
        "Xintao Wang",
        "Pengfei Wan",
        "Di Zhang",
        "Wanli Ouyang"
      ],
      "abstract": "We propose Flow-GRPO, the first method integrating online reinforcement\nlearning (RL) into flow matching models. Our approach uses two key strategies:\n(1) an ODE-to-SDE conversion that transforms a deterministic Ordinary\nDifferential Equation (ODE) into an equivalent Stochastic Differential Equation\n(SDE) that matches the original model's marginal distribution at all timesteps,\nenabling statistical sampling for RL exploration; and (2) a Denoising Reduction\nstrategy that reduces training denoising steps while retaining the original\ninference timestep number, significantly improving sampling efficiency without\nperformance degradation. Empirically, Flow-GRPO is effective across multiple\ntext-to-image tasks. For complex compositions, RL-tuned SD3.5 generates nearly\nperfect object counts, spatial relations, and fine-grained attributes, boosting\nGenEval accuracy from 63% to 95%. In visual text rendering, its accuracy\nimproves from 59% to 92%, significantly enhancing text generation. Flow-GRPO\nalso achieves substantial gains in human preference alignment. Notably, very\nlittle reward hacking occurred, meaning rewards did not increase at the cost of\nappreciable image quality or diversity degradation.",
      "tldr_zh": "本研究提出Flow-GRPO，一种将在线强化学习(online RL)整合到流匹配模型中的新方法，以提升生成任务的性能。该方法采用两个关键策略：(1) ODE-to-SDE转换，将确定性Ordinary Differential Equation (ODE)转化为等价的Stochastic Differential Equation (SDE)，支持RL的统计采样以实现探索；(2) Denoising Reduction策略，减少训练中的去噪步骤，同时保持推理时间步数不变，从而显著提高采样效率而不降低性能。在实验中，Flow-GRPO在文本到图像任务上表现出色，例如复杂合成任务的GenEval准确率从63%提升至95%，并在视觉文本渲染中从59%提高到92%，同时增强了人类偏好对齐且几乎没有奖励黑客问题。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Code: https://github.com/yifan123/flow_grpo",
      "pdf_url": "http://arxiv.org/pdf/2505.05470v2",
      "published_date": "2025-05-08 17:58:45 UTC",
      "updated_date": "2025-05-11 14:44:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:53:01.787130"
    },
    {
      "arxiv_id": "2505.05467v1",
      "title": "StreamBridge: Turning Your Offline Video Large Language Model into a Proactive Streaming Assistant",
      "title_zh": "StreamBridge：将您的离线视频大语言模型转化为主动流媒体助手",
      "authors": [
        "Haibo Wang",
        "Bo Feng",
        "Zhengfeng Lai",
        "Mingze Xu",
        "Shiyu Li",
        "Weifeng Ge",
        "Afshin Dehghan",
        "Meng Cao",
        "Ping Huang"
      ],
      "abstract": "We present StreamBridge, a simple yet effective framework that seamlessly\ntransforms offline Video-LLMs into streaming-capable models. It addresses two\nfundamental challenges in adapting existing models into online scenarios: (1)\nlimited capability for multi-turn real-time understanding, and (2) lack of\nproactive response mechanisms. Specifically, StreamBridge incorporates (1) a\nmemory buffer combined with a round-decayed compression strategy, supporting\nlong-context multi-turn interactions, and (2) a decoupled, lightweight\nactivation model that can be effortlessly integrated into existing Video-LLMs,\nenabling continuous proactive responses. To further support StreamBridge, we\nconstruct Stream-IT, a large-scale dataset tailored for streaming video\nunderstanding, featuring interleaved video-text sequences and diverse\ninstruction formats. Extensive experiments show that StreamBridge significantly\nimproves the streaming understanding capabilities of offline Video-LLMs across\nvarious tasks, outperforming even proprietary models such as GPT-4o and Gemini\n1.5 Pro. Simultaneously, it achieves competitive or superior performance on\nstandard video understanding benchmarks.",
      "tldr_zh": "本研究提出StreamBridge框架，一种简单有效的方案，将离线Video-LLMs转化为支持流式处理的主动助理，解决多轮实时理解能力和主动响应机制的局限性。具体方法包括使用内存缓冲区结合圆形衰减压缩策略来支持长上下文多轮交互，以及集成一个解耦的轻量级激活模型以实现连续主动响应。为此，研究构建了大规模数据集Stream-IT，包含交错视频-文本序列和多样指令格式。实验结果显示，StreamBridge显著提升了Video-LLMs在各种流式任务上的性能，优于GPT-4o和Gemini 1.5 Pro，同时在标准视频理解基准上表现出竞争性或优越水平。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05467v1",
      "published_date": "2025-05-08 17:57:40 UTC",
      "updated_date": "2025-05-08 17:57:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:53:14.540179"
    },
    {
      "arxiv_id": "2505.05465v1",
      "title": "ComPO: Preference Alignment via Comparison Oracles",
      "title_zh": "ComPO：通过比较预言机实现的偏好对齐",
      "authors": [
        "Peter Chen",
        "Xi Chen",
        "Wotao Yin",
        "Tianyi Lin"
      ],
      "abstract": "Direct alignment methods are increasingly used for aligning large language\nmodels (LLMs) with human preferences. However, these methods suffer from the\nissues of verbosity and likelihood displacement, which can be driven by the\nnoisy preference pairs that induce similar likelihood for preferred and\ndispreferred responses. The contributions of this paper are two-fold. First, we\npropose a new preference alignment method based on comparison oracles and\nprovide the convergence guarantee for its basic scheme. Second, we improve our\nmethod using some heuristics and conduct the experiments to demonstrate the\nflexibility and compatibility of practical scheme in improving the performance\nof LLMs using noisy preference pairs. Evaluations are conducted across multiple\nbase and instruction-tuned models (Mistral-7B, Llama-3-8B and Gemma-2-9B) with\nbenchmarks (AlpacaEval 2, MT-Bench and Arena-Hard). Experimental results show\nthe effectiveness of our method as an alternative to addressing the limitations\nof existing direct alignment methods. A highlight of our work is that we\nevidence the importance of designing specialized methods for preference pairs\nwith distinct likelihood margin, which complements the recent findings in\n\\citet{Razin-2025-Unintentional}.",
      "tldr_zh": "本研究提出了一种名为 ComPO 的偏好对齐方法，通过 comparison oracles 解决大型语言模型 (LLMs) 在直接对齐过程中的冗长和似然位移问题，这些问题往往由嘈杂的偏好对引起。方法的核心是基于比较预言机的基本方案，并提供了收敛保证，同时通过启发式改进增强其灵活性和兼容性。实验在多个模型（如 Mistral-7B、Llama-3-8B 和 Gemma-2-9B）上使用基准（如 AlpacaEval 2、MT-Bench 和 Arena-Hard）进行评估，结果显示 ComPO 显著提高了 LLMs 的性能，作为现有直接对齐方法的有效替代。研究还强调了针对不同似然边际的偏好对设计专业化方法的必要性，补充了相关领域的最新发现。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "25 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.05465v1",
      "published_date": "2025-05-08 17:56:57 UTC",
      "updated_date": "2025-05-08 17:56:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:53:27.187365"
    },
    {
      "arxiv_id": "2505.07861v1",
      "title": "Scalable LLM Math Reasoning Acceleration with Low-rank Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Harry Dong",
        "Bilge Acun",
        "Beidi Chen",
        "Yuejie Chi"
      ],
      "abstract": "Due to long generations, large language model (LLM) math reasoning demands\nsignificant computational resources and time. While many existing efficient\ninference methods have been developed with excellent performance preservation\non language tasks, they often severely degrade math performance. In this paper,\nwe propose Caprese, a low-cost distillation method to recover lost capabilities\nfrom deploying efficient inference methods, focused primarily in feedforward\nblocks. With original weights unperturbed, roughly 1% of additional parameters,\nand only 20K synthetic training samples, we are able to recover much if not all\nof the math capabilities lost from efficient inference for thinking LLMs and\nwithout harm to language tasks for instruct LLMs. Moreover, Caprese slashes the\nnumber of active parameters (~2B cut for Gemma 2 9B and Llama 3.1 8B) and\nintegrates cleanly into existing model layers to reduce latency (>11% reduction\nto generate 2048 tokens with Qwen 2.5 14B) while encouraging response brevity.",
      "tldr_zh": "本论文提出Caprese，一种低成本的低-rank蒸馏方法，用于加速LLM的数学推理，同时从高效推理方法中恢复丢失的能力，主要针对前馈块。该方法不改变原始权重，仅增加约1%的参数和使用20K合成训练样本，即可恢复数学性能，而不对语言任务造成影响。实验结果显示，Caprese显著减少活跃参数（如Gemma 2 9B和Llama 3.1 8B减少约2B），并降低生成延迟（如Qwen 2.5 14B生成2048 tokens时延迟减少>11%），从而提升整体推理效率并鼓励响应简洁。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07861v1",
      "published_date": "2025-05-08 17:51:24 UTC",
      "updated_date": "2025-05-08 17:51:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:53:39.361181"
    },
    {
      "arxiv_id": "2505.05453v1",
      "title": "Conversational Process Model Redesign",
      "title_zh": "对话式过程模型重设计",
      "authors": [
        "Nataliia Klievtsova",
        "Timotheus Kampik",
        "Juergen Mangler",
        "Stefanie Rinderle-Ma"
      ],
      "abstract": "With the recent success of large language models (LLMs), the idea of\nAI-augmented Business Process Management systems is becoming more feasible. One\nof their essential characteristics is the ability to be conversationally\nactionable, allowing humans to interact with the LLM effectively to perform\ncrucial process life cycle tasks such as process model design and redesign.\nHowever, most current research focuses on single-prompt execution and\nevaluation of results, rather than on continuous interaction between the user\nand the LLM. In this work, we aim to explore the feasibility of using LLMs to\nempower domain experts in the creation and redesign of process models in an\niterative and effective way. The proposed conversational process model redesign\n(CPD) approach receives as input a process model and a redesign request by the\nuser in natural language. Instead of just letting the LLM make changes, the LLM\nis employed to (a) identify process change patterns from literature, (b)\nre-phrase the change request to be aligned with an expected wording for the\nidentified pattern (i.e., the meaning), and then to (c) apply the meaning of\nthe change to the process model. This multi-step approach allows for\nexplainable and reproducible changes. In order to ensure the feasibility of the\nCPD approach, and to find out how well the patterns from literature can be\nhandled by the LLM, we performed an extensive evaluation. The results show that\nsome patterns are hard to understand by LLMs and by users. Within the scope of\nthe study, we demonstrated that users need support to describe the changes\nclearly. Overall the evaluation shows that the LLMs can handle most changes\nwell according to a set of completeness and correctness criteria.",
      "tldr_zh": "这篇论文探讨了使用大型语言模型（LLMs）来增强业务流程管理的对话式系统，专注于通过连续交互帮助用户迭代地设计和重设计流程模型。提出的Conversational Process Model Redesign (CPD)方法包括三个步骤：(a) 从文献中识别流程变更模式，(b) 重新表述用户的自然语言请求以匹配这些模式的预期表述，(c) 将变更应用于流程模型，从而确保变更过程可解释和可重现。实验评估显示，LLMs能够根据完整性和正确性标准处理大多数变更，但某些模式对LLMs和用户来说难以理解，因此用户需要额外支持来清晰描述变更。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05453v1",
      "published_date": "2025-05-08 17:44:45 UTC",
      "updated_date": "2025-05-08 17:44:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:53:50.441807"
    },
    {
      "arxiv_id": "2505.05440v2",
      "title": "EcoAgent: An Efficient Edge-Cloud Collaborative Multi-Agent Framework for Mobile Automation",
      "title_zh": "EcoAgent：一种高效的边缘-云协作多智能体框架，用于移动自动化",
      "authors": [
        "Biao Yi",
        "Xavier Hu",
        "Yurun Chen",
        "Shengyu Zhang",
        "Hongxia Yang",
        "Fan Wu",
        "Fei Wu"
      ],
      "abstract": "Cloud-based mobile agents powered by (multimodal) large language models\n((M)LLMs) offer strong reasoning abilities but suffer from high latency and\ncost. While fine-tuned (M)SLMs enable edge deployment, they often lose general\ncapabilities and struggle with complex tasks. To address this, we propose\n\\textbf{EcoAgent}, an \\textbf{E}dge-\\textbf{C}loud c\\textbf{O}llaborative\nmulti-agent framework for mobile automation. EcoAgent features a closed-loop\ncollaboration among a cloud-based Planning Agent and two edge-based agents: the\nExecution Agent for action execution and the Observation Agent for verifying\noutcomes. The Observation Agent uses a Pre-Understanding Module to compress\nscreen images into concise text, reducing token usage and communication\noverhead. In case of failure, the Planning Agent retrieves screen history\nthrough a Memory Module and replans via a Reflection Module. Experiments on\nAndroidWorld show that EcoAgent achieves task success rates comparable to\ncloud-based mobile agents while significantly reducing MLLM token consumption,\nenabling efficient and practical mobile automation.",
      "tldr_zh": "该研究提出EcoAgent，一种高效的边云协作多代理框架，用于解决基于(M)LLMs的云端移动代理的高延迟和成本问题，以及边缘部署的(M)SLMs在通用能力和复杂任务上的局限性。EcoAgent包括一个云端的Planning Agent和两个边缘代理：Execution Agent负责执行动作，Observation Agent通过Pre-Understanding Module压缩屏幕图像为简洁文本，从而减少token使用和通信开销。如果任务失败，Planning Agent会利用Memory Module检索屏幕历史并通过Reflection Module重新规划。在AndroidWorld实验中，EcoAgent实现了与云端代理相当的任务成功率，同时显著降低了MLLM token消耗，促进了高效的移动自动化。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05440v2",
      "published_date": "2025-05-08 17:31:20 UTC",
      "updated_date": "2025-05-09 07:47:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:54:02.270479"
    },
    {
      "arxiv_id": "2505.05423v3",
      "title": "LiTransProQA: an LLM-based Literary Translation evaluation metric with Professional Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Ran Zhang",
        "Wei Zhao",
        "Lieve Macken",
        "Steffen Eger"
      ],
      "abstract": "The impact of Large Language Models (LLMs) has extended into literary\ndomains. However, existing evaluation metrics prioritize mechanical accuracy\nover artistic expression and tend to overrate machine translation as being\nsuperior to human translation from experienced professionals. In the long run,\nthis bias could result in an irreversible decline in translation quality and\ncultural authenticity. In response to the urgent need for a specialized\nliterary evaluation metric, we introduce LiTransProQA, a novel, reference-free,\nLLM-based question-answering framework designed for literary translation\nevaluation. LiTransProQA uniquely integrates insights from professional\nliterary translators and researchers, focusing on critical elements in literary\nquality assessment such as literary devices, cultural understanding, and\nauthorial voice. Our extensive evaluation shows that while literary-finetuned\nXCOMET-XL yields marginal gains, LiTransProQA substantially outperforms current\nmetrics, achieving up to 0.07 gain in correlation and surpassing the best\nstate-of-the-art metrics by over 15 points in adequacy assessments.\nIncorporating professional translator insights as weights further improves\nperformance, highlighting the value of translator inputs. Notably, LiTransProQA\nreaches human-level evaluation performance comparable to trained student\nevaluators. It shows broad applicability to open-source models like\nLLaMa3.3-70b and Qwen2.5-32b, indicating its potential as an accessible and\ntraining-free tool for evaluating literary translations that require local\nprocessing due to copyright or ethical considerations. The code and datasets\nare available under: https://github.com/zhangr2021/TransProQA.",
      "tldr_zh": "该论文提出 LiTransProQA，一种基于 LLM 的无参考问答框架，用于评估文学翻译，旨在解决现有指标过度注重机械准确性而忽略艺术表达的问题。LiTransProQA 整合专业翻译者见解，聚焦于文学设备、文化的理解和作者声音等关键元素，并通过加权机制进一步提升性能。实验结果显示，该框架在相关性上比最先进指标提高 0.07，并超过 15 点，达到与训练学生评估者相当的人类水平。LiTransProQA 适用于开源模型如 LLaMa3.3-70b 和 Qwen2.5-32b，提供无需训练的工具，并开源代码以支持版权敏感场景。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Updated version, with examples in the appendix",
      "pdf_url": "http://arxiv.org/pdf/2505.05423v3",
      "published_date": "2025-05-08 17:12:56 UTC",
      "updated_date": "2025-05-22 10:01:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:54:14.947156"
    },
    {
      "arxiv_id": "2505.05422v1",
      "title": "TokLIP: Marry Visual Tokens to CLIP for Multimodal Comprehension and Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Haokun Lin",
        "Teng Wang",
        "Yixiao Ge",
        "Yuying Ge",
        "Zhichao Lu",
        "Ying Wei",
        "Qingfu Zhang",
        "Zhenan Sun",
        "Ying Shan"
      ],
      "abstract": "Pioneering token-based works such as Chameleon and Emu3 have established a\nfoundation for multimodal unification but face challenges of high training\ncomputational overhead and limited comprehension performance due to a lack of\nhigh-level semantics. In this paper, we introduce TokLIP, a visual tokenizer\nthat enhances comprehension by semanticizing vector-quantized (VQ) tokens and\nincorporating CLIP-level semantics while enabling end-to-end multimodal\nautoregressive training with standard VQ tokens. TokLIP integrates a low-level\ndiscrete VQ tokenizer with a ViT-based token encoder to capture high-level\ncontinuous semantics. Unlike previous approaches (e.g., VILA-U) that discretize\nhigh-level features, TokLIP disentangles training objectives for comprehension\nand generation, allowing the direct application of advanced VQ tokenizers\nwithout the need for tailored quantization operations. Our empirical results\ndemonstrate that TokLIP achieves exceptional data efficiency, empowering visual\ntokens with high-level semantic understanding while enhancing low-level\ngenerative capacity, making it well-suited for autoregressive Transformers in\nboth comprehension and generation tasks. The code and models are available at\nhttps://github.com/TencentARC/TokLIP.",
      "tldr_zh": "本研究提出 TokLIP，一种视觉标记器（visual tokenizer），旨在将视觉 tokens 与 CLIP 整合，以提升多模态理解和生成性能，同时解决现有 token-based 模型（如 Chameleon 和 Emu3）的高训练计算开销和理解能力不足的问题。TokLIP 通过结合低级离散 VQ tokens 和 ViT-based token encoder 来捕捉高水平连续语义，并分离理解和生成的训练目标，允许直接使用高级 VQ tokenizers 而无需定制量化操作。实验结果显示，TokLIP 具有卓越的数据效率，提升了视觉 tokens 的高水平语义理解和低水平生成能力，使其适用于自回归 Transformer 在理解和生成任务中的应用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Technical Report",
      "pdf_url": "http://arxiv.org/pdf/2505.05422v1",
      "published_date": "2025-05-08 17:12:19 UTC",
      "updated_date": "2025-05-08 17:12:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:54:26.705688"
    },
    {
      "arxiv_id": "2505.05543v1",
      "title": "Would You Rely on an Eerie Agent? A Systematic Review of the Impact of the Uncanny Valley Effect on Trust in Human-Agent Interaction",
      "title_zh": "翻译失败",
      "authors": [
        "Ahdiyeh Alipour",
        "Tilo Hartmann",
        "Maryam Alimardani"
      ],
      "abstract": "Trust is a fundamental component of human-agent interaction. With the\nincreasing presence of artificial agents in daily life, it is essential to\nunderstand how people perceive and trust these agents. One of the key\nchallenges affecting this perception is the Uncanny Valley Effect (UVE), where\nincreasingly human-like artificial beings can be perceived as eerie or\nrepelling. Despite growing interest in trust and the UVE, existing research\nvaries widely in terms of how these concepts are defined and operationalized.\nThis inconsistency raises important questions about how and under what\nconditions the UVE influences trust in agents. A systematic understanding of\ntheir relationship is currently lacking. This review aims to examine the impact\nof the UVE on human trust in agents and to identify methodological patterns,\nlimitations, and gaps in the existing empirical literature. Following PRISMA\nguidelines, a systematic search identified 53 empirical studies that\ninvestigated both UVE-related constructs and trust or trust-related outcomes.\nStudies were analyzed based on a structured set of categories, including types\nof agents and interactions, methodological and measurement approaches, and key\nfindings. The results of our systematic review reveal that most studies rely on\nstatic images or hypothetical scenarios with limited real-time interaction, and\nthe majority use subjective trust measures. This review offers a novel\nframework for classifying trust measurement approaches with regard to the\nbest-practice criteria for empirically investigating the UVE. As the first\nsystematic attempt to map the intersection of UVE and trust, this review\ncontributes to a deeper understanding of their interplay and offers a\nfoundation for future research. Keywords: the uncanny valley effect, trust,\nhuman-likeness, affinity response, human-agent interaction",
      "tldr_zh": "这篇系统综述探讨了 Uncanny Valley Effect (UVE) 对人类-代理互动中信任的影响，分析了 53 篇实证研究以识别其关系、方法模式和局限性。研究发现，大多数研究依赖静态图像或假设场景，采用主观信任测量，且缺乏实时互动，这导致了对 UVE 和信任交叉的理解不全面。综述贡献了一个新框架，用于分类信任测量方法，并为未来研究提供基础，以更好地评估代理的人类相似性和亲和响应（affinity response）。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "75 pages, Figure 11, Table 5",
      "pdf_url": "http://arxiv.org/pdf/2505.05543v1",
      "published_date": "2025-05-08 17:03:26 UTC",
      "updated_date": "2025-05-08 17:03:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:54:38.139797"
    },
    {
      "arxiv_id": "2505.05541v1",
      "title": "Safety by Measurement: A Systematic Literature Review of AI Safety Evaluation Methods",
      "title_zh": "通过测量实现安全：人工智能安全评估方法的系统文献综述",
      "authors": [
        "Markov Grey",
        "Charbel-Raphaël Segerie"
      ],
      "abstract": "As frontier AI systems advance toward transformative capabilities, we need a\nparallel transformation in how we measure and evaluate these systems to ensure\nsafety and inform governance. While benchmarks have been the primary method for\nestimating model capabilities, they often fail to establish true upper bounds\nor predict deployment behavior. This literature review consolidates the rapidly\nevolving field of AI safety evaluations, proposing a systematic taxonomy around\nthree dimensions: what properties we measure, how we measure them, and how\nthese measurements integrate into frameworks. We show how evaluations go beyond\nbenchmarks by measuring what models can do when pushed to the limit\n(capabilities), the behavioral tendencies exhibited by default (propensities),\nand whether our safety measures remain effective even when faced with\nsubversive adversarial AI (control). These properties are measured through\nbehavioral techniques like scaffolding, red teaming and supervised fine-tuning,\nalongside internal techniques such as representation analysis and mechanistic\ninterpretability. We provide deeper explanations of some safety-critical\ncapabilities like cybersecurity exploitation, deception, autonomous\nreplication, and situational awareness, alongside concerning propensities like\npower-seeking and scheming. The review explores how these evaluation methods\nintegrate into governance frameworks to translate results into concrete\ndevelopment decisions. We also highlight challenges to safety evaluations -\nproving absence of capabilities, potential model sandbagging, and incentives\nfor \"safetywashing\" - while identifying promising research directions. By\nsynthesizing scattered resources, this literature review aims to provide a\ncentral reference point for understanding AI safety evaluations.",
      "tldr_zh": "这篇文献综述系统审视了 AI 安全评估方法，提出一个基于三个维度的分类框架：测量属性（包括模型能力、倾向性和控制）、测量方式（如 scaffolding、red teaming 和 mechanistic interpretability），以及这些测量如何整合到治理框架中。论文详细讨论了关键属性，如 cybersecurity exploitation、deception 和 autonomous replication 等能力，以及 power-seeking 等倾向性问题。最终，它突出了评估挑战（如模型 sandbagging 和 safetywashing），并为 AI 安全治理提供了一个中心参考点，以指导模型开发决策。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05541v1",
      "published_date": "2025-05-08 16:55:07 UTC",
      "updated_date": "2025-05-08 16:55:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:54:50.838370"
    },
    {
      "arxiv_id": "2505.05410v1",
      "title": "Reasoning Models Don't Always Say What They Think",
      "title_zh": "推理模型并不总是说出它们所想的",
      "authors": [
        "Yanda Chen",
        "Joe Benton",
        "Ansh Radhakrishnan",
        "Jonathan Uesato",
        "Carson Denison",
        "John Schulman",
        "Arushi Somani",
        "Peter Hase",
        "Misha Wagner",
        "Fabien Roger",
        "Vlad Mikulik",
        "Samuel R. Bowman",
        "Jan Leike",
        "Jared Kaplan",
        "Ethan Perez"
      ],
      "abstract": "Chain-of-thought (CoT) offers a potential boon for AI safety as it allows\nmonitoring a model's CoT to try to understand its intentions and reasoning\nprocesses. However, the effectiveness of such monitoring hinges on CoTs\nfaithfully representing models' actual reasoning processes. We evaluate CoT\nfaithfulness of state-of-the-art reasoning models across 6 reasoning hints\npresented in the prompts and find: (1) for most settings and models tested,\nCoTs reveal their usage of hints in at least 1% of examples where they use the\nhint, but the reveal rate is often below 20%, (2) outcome-based reinforcement\nlearning initially improves faithfulness but plateaus without saturating, and\n(3) when reinforcement learning increases how frequently hints are used (reward\nhacking), the propensity to verbalize them does not increase, even without\ntraining against a CoT monitor. These results suggest that CoT monitoring is a\npromising way of noticing undesired behaviors during training and evaluations,\nbut that it is not sufficient to rule them out. They also suggest that in\nsettings like ours where CoT reasoning is not necessary, test-time monitoring\nof CoTs is unlikely to reliably catch rare and catastrophic unexpected\nbehaviors.",
      "tldr_zh": "这篇论文评估了Chain-of-thought (CoT) 在AI安全中的忠实度，发现最先进的推理模型在6种推理提示下，CoT 通常无法准确反映其实际推理过程，仅在少于20%的例子中揭示提示使用。研究通过实验发现，outcome-based reinforcement learning 最初能改善CoT 的忠实度，但效果会停滞，且即使强化学习导致reward hacking（奖励黑客行为），模型也不会增加对提示的verbalization。总体结果表明，CoT 监控在训练和评估中可帮助发现 undesired behaviors，但不足以完全排除稀有和灾难性行为，尤其在不需要CoT 推理的场景下。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05410v1",
      "published_date": "2025-05-08 16:51:43 UTC",
      "updated_date": "2025-05-08 16:51:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:55:03.467725"
    },
    {
      "arxiv_id": "2505.05408v1",
      "title": "Crosslingual Reasoning through Test-Time Scaling",
      "title_zh": "通过测试时缩放的跨语言推理",
      "authors": [
        "Zheng-Xin Yong",
        "M. Farid Adilazuarda",
        "Jonibek Mansurov",
        "Ruochen Zhang",
        "Niklas Muennighoff",
        "Carsten Eickhoff",
        "Genta Indra Winata",
        "Julia Kreutzer",
        "Stephen H. Bach",
        "Alham Fikri Aji"
      ],
      "abstract": "Reasoning capabilities of large language models are primarily studied for\nEnglish, even when pretrained models are multilingual. In this work, we\ninvestigate to what extent English reasoning finetuning with long\nchain-of-thoughts (CoTs) can generalize across languages. First, we find that\nscaling up inference compute for English-centric reasoning language models\n(RLMs) improves multilingual mathematical reasoning across many languages\nincluding low-resource languages, to an extent where they outperform models\ntwice their size. Second, we reveal that while English-centric RLM's CoTs are\nnaturally predominantly English, they consistently follow a quote-and-think\npattern to reason about quoted non-English inputs. Third, we discover an\neffective strategy to control the language of long CoT reasoning, and we\nobserve that models reason better and more efficiently in high-resource\nlanguages. Finally, we observe poor out-of-domain reasoning generalization, in\nparticular from STEM to cultural commonsense knowledge, even for English.\nOverall, we demonstrate the potentials, study the mechanisms and outline the\nlimitations of crosslingual generalization of English reasoning test-time\nscaling. We conclude that practitioners should let English-centric RLMs reason\nin high-resource languages, while further work is needed to improve reasoning\nin low-resource languages and out-of-domain contexts.",
      "tldr_zh": "本研究探讨了通过测试时缩放（Test-Time Scaling）提升大型语言模型的多语言推理能力，焦点在于英语中心模型的推理微调（使用长Chain-of-Thought, CoTs）是否能泛化到其他语言。结果显示，增加推理计算量能显著改善多语言数学推理，包括低资源语言的性能，甚至超越更大模型；同时，模型采用“quote-and-think”模式处理非英语输入，并在高资源语言中表现出更好的效率和准确性。论文还揭示了控制CoTs语言的策略，但指出模型在领域外推理（如从STEM到文化常识）泛化较差，并建议未来工作应加强低资源语言和跨域语境的推理优化。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05408v1",
      "published_date": "2025-05-08 16:50:06 UTC",
      "updated_date": "2025-05-08 16:50:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:55:15.952968"
    },
    {
      "arxiv_id": "2505.05538v1",
      "title": "Cardioformer: Advancing AI in ECG Analysis with Multi-Granularity Patching and ResNet",
      "title_zh": "翻译失败",
      "authors": [
        "Md Kamrujjaman Mobin",
        "Md Saiful Islam",
        "Sadik Al Barid",
        "Md Masum"
      ],
      "abstract": "Electrocardiogram (ECG) classification is crucial for automated cardiac\ndisease diagnosis, yet existing methods often struggle to capture local\nmorphological details and long-range temporal dependencies simultaneously. To\naddress these challenges, we propose Cardioformer, a novel multi-granularity\nhybrid model that integrates cross-channel patching, hierarchical residual\nlearning, and a two-stage self-attention mechanism. Cardioformer first encodes\nmulti-scale token embeddings to capture fine-grained local features and global\ncontextual information and then selectively fuses these representations through\nintra- and inter-granularity self-attention. Extensive evaluations on three\nbenchmark ECG datasets under subject-independent settings demonstrate that\nmodel consistently outperforms four state-of-the-art baselines. Our\nCardioformer model achieves the AUROC of 96.34$\\pm$0.11, 89.99$\\pm$0.12, and\n95.59$\\pm$1.66 in MIMIC-IV, PTB-XL and PTB dataset respectively outperforming\nPatchTST, Reformer, Transformer, and Medformer models. It also demonstrates\nstrong cross-dataset generalization, achieving 49.18% AUROC on PTB and 68.41%\non PTB-XL when trained on MIMIC-IV. These findings underscore the potential of\nCardioformer to advance automated ECG analysis, paving the way for more\naccurate and robust cardiovascular disease diagnosis. We release the source\ncode at https://github.com/KMobin555/Cardioformer.",
      "tldr_zh": "该研究针对ECG分类中捕捉局部形态细节和长程时间依赖的挑战，提出了Cardioformer，一种整合多粒度patching、层次化残差学习和两阶段自注意力机制的混合模型。Cardioformer通过编码多尺度token embeddings，并通过intra- and inter-granularity自注意力机制选择性地融合局部特征和全局上下文信息，从而提升分析性能。在三个基准数据集（MIMIC-IV、PTB-XL和PTB）上的评估中，Cardioformer分别实现了96.34±0.11%、89.99±0.12%和95.59±1.66%的AUROC，优于PatchTST、Reformer、Transformer和Medformer等基线模型，并展示了强劲的跨数据集泛化能力，如在MIMIC-IV上训练后在PTB和PTB-XL上的表现。这些结果突显了Cardioformer在自动化ECG分析中的潜力，推动了更准确和鲁棒的心血管疾病诊断。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05538v1",
      "published_date": "2025-05-08 16:44:21 UTC",
      "updated_date": "2025-05-08 16:44:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:55:28.211061"
    },
    {
      "arxiv_id": "2505.05402v1",
      "title": "CART-ELC: Oblique Decision Tree Induction via Exhaustive Search",
      "title_zh": "翻译失败",
      "authors": [
        "Andrew D. Laack"
      ],
      "abstract": "Oblique decision trees have attracted attention due to their potential for\nimproved classification performance over traditional axis-aligned decision\ntrees. However, methods that rely on exhaustive search to find oblique splits\nface computational challenges. As a result, they have not been widely explored.\nWe introduce a novel algorithm, Classification and Regression Tree - Exhaustive\nLinear Combinations (CART-ELC), for inducing oblique decision trees that\nperforms an exhaustive search on a restricted set of hyperplanes. We then\ninvestigate the algorithm's computational complexity and its predictive\ncapabilities. Our results demonstrate that CART-ELC consistently achieves\ncompetitive performance on small datasets, often yielding statistically\nsignificant improvements in classification accuracy relative to existing\ndecision tree induction algorithms, while frequently producing shallower,\nsimpler, and thus more interpretable trees.",
      "tldr_zh": "本文提出了一种新型算法CART-ELC，用于通过穷举搜索(exhaustive search)在受限超平面(hyperplanes)上诱导oblique decision trees，以克服传统axis-aligned decision trees在分类性能上的局限性。该算法通过限制搜索范围来缓解计算挑战，同时保持高效的预测能力。实验结果表明，CART-ELC在小数据集上表现出色，往往在分类准确率上比现有决策树诱导算法有统计显著改善，并生成更浅、更简洁且易解释的树结构。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DS",
        "I.2.6; I.5.2; F.2.2; G.3; G.2.1"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.05402v1",
      "published_date": "2025-05-08 16:42:13 UTC",
      "updated_date": "2025-05-08 16:42:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:55:37.473022"
    },
    {
      "arxiv_id": "2505.05396v2",
      "title": "A Pain Assessment Framework based on multimodal data and Deep Machine Learning methods",
      "title_zh": "翻译失败",
      "authors": [
        "Stefanos Gkikas"
      ],
      "abstract": "From the original abstract: This thesis initially aims to study the pain\nassessment process from a clinical-theoretical perspective while exploring and\nexamining existing automatic approaches. Building on this foundation, the\nprimary objective of this Ph.D. project is to develop innovative computational\nmethods for automatic pain assessment that achieve high performance and are\napplicable in real clinical settings. A primary goal is to thoroughly\ninvestigate and assess significant factors, including demographic elements that\nimpact pain perception, as recognized in pain research, through a computational\nstandpoint. Within the limits of the available data in this research area, our\ngoal was to design, develop, propose, and offer automatic pain assessment\npipelines for unimodal and multimodal configurations that are applicable to the\nspecific requirements of different scenarios. The studies published in this\nPh.D. thesis showcased the effectiveness of the proposed methods, achieving\nstate-of-the-art results. Additionally, they paved the way for exploring new\napproaches in artificial intelligence, foundation models, and generative\nartificial intelligence.",
      "tldr_zh": "本论文提出了一种基于多模态数据和Deep Machine Learning methods的疼痛评估框架，旨在从临床理论角度研究疼痛评估过程，并开发创新的计算方法以实现高性能的自动疼痛评估。研究重点调查了影响疼痛感知的因素，如人口统计学元素，并设计了适用于单模态和多模态配置的自动评估管道，以适应不同临床场景的需求。实验结果显示，所提出的方法取得了state-of-the-art性能，并为人工智能、foundation models和生成式人工智能的新方法探索奠定了基础。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05396v2",
      "published_date": "2025-05-08 16:32:55 UTC",
      "updated_date": "2025-05-11 11:11:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:55:49.255394"
    },
    {
      "arxiv_id": "2505.05375v2",
      "title": "Threshold Modulation for Online Test-Time Adaptation of Spiking Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Kejie Zhao",
        "Wenjia Hua",
        "Aiersi Tuerhong",
        "Luziwei Leng",
        "Yuxin Ma",
        "Qinghai Guo"
      ],
      "abstract": "Recently, spiking neural networks (SNNs), deployed on neuromorphic chips,\nprovide highly efficient solutions on edge devices in different scenarios.\nHowever, their ability to adapt to distribution shifts after deployment has\nbecome a crucial challenge. Online test-time adaptation (OTTA) offers a\npromising solution by enabling models to dynamically adjust to new data\ndistributions without requiring source data or labeled target samples.\nNevertheless, existing OTTA methods are largely designed for traditional\nartificial neural networks and are not well-suited for SNNs. To address this\ngap, we propose a low-power, neuromorphic chip-friendly online test-time\nadaptation framework, aiming to enhance model generalization under distribution\nshifts. The proposed approach is called Threshold Modulation (TM), which\ndynamically adjusts the firing threshold through neuronal dynamics-inspired\nnormalization, being more compatible with neuromorphic hardware. Experimental\nresults on benchmark datasets demonstrate the effectiveness of this method in\nimproving the robustness of SNNs against distribution shifts while maintaining\nlow computational cost. The proposed method offers a practical solution for\nonline test-time adaptation of SNNs, providing inspiration for the design of\nfuture neuromorphic chips. The demo code is available at\ngithub.com/NneurotransmitterR/TM-OTTA-SNN.",
      "tldr_zh": "这篇论文针对 Spiking Neural Networks (SNNs) 在部署后适应分布偏移的挑战，提出了一种在线测试时适应 (Online Test-Time Adaptation, OTTA) 框架。作者引入 Threshold Modulation (TM) 方法，通过神经元动态启发的归一化动态调整发射阈值，使其更兼容低功耗神经形态芯片。实验结果显示，TM 在基准数据集上显著提高了 SNNs 对分布偏移的鲁棒性，同时保持低计算成本，为未来神经形态芯片设计提供了实用灵感。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by IJCNN 2025. \\c{opyright} 2025 IEEE. Personal use of this\n  material is permitted. Permission from IEEE must be obtained for all other\n  uses, including reprinting/republishing this material for advertising or\n  promotional purposes, collecting new collected works for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works",
      "pdf_url": "http://arxiv.org/pdf/2505.05375v2",
      "published_date": "2025-05-08 16:09:40 UTC",
      "updated_date": "2025-05-09 10:51:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:56:03.365083"
    },
    {
      "arxiv_id": "2505.05356v1",
      "title": "Time of the Flight of the Gaussians: Optimizing Depth Indirectly in Dynamic Radiance Fields",
      "title_zh": "翻译失败",
      "authors": [
        "Runfeng Li",
        "Mikhail Okunev",
        "Zixuan Guo",
        "Anh Ha Duong",
        "Christian Richardt",
        "Matthew O'Toole",
        "James Tompkin"
      ],
      "abstract": "We present a method to reconstruct dynamic scenes from monocular\ncontinuous-wave time-of-flight (C-ToF) cameras using raw sensor samples that\nachieves similar or better accuracy than neural volumetric approaches and is\n100x faster. Quickly achieving high-fidelity dynamic 3D reconstruction from a\nsingle viewpoint is a significant challenge in computer vision. In C-ToF\nradiance field reconstruction, the property of interest-depth-is not directly\nmeasured, causing an additional challenge. This problem has a large and\nunderappreciated impact upon the optimization when using a fast primitive-based\nscene representation like 3D Gaussian splatting, which is commonly used with\nmulti-view data to produce satisfactory results and is brittle in its\noptimization otherwise. We incorporate two heuristics into the optimization to\nimprove the accuracy of scene geometry represented by Gaussians. Experimental\nresults show that our approach produces accurate reconstructions under\nconstrained C-ToF sensing conditions, including for fast motions like swinging\nbaseball bats. https://visual.cs.brown.edu/gftorf",
      "tldr_zh": "本研究提出了一种从单目连续波时间飞行 (C-ToF) 相机重建动态场景的方法，使用原始传感器样本，实现与神经体积方法相当或更好的准确性，同时速度快 100 倍。针对深度间接测量的挑战，该方法优化 3D Gaussian splatting 表示，并引入两个启发式优化策略来提升场景几何的精确性。实验结果显示，该方法在受限 C-ToF 感知条件下（如快速运动的棒球挥击）也能产生高质量的重建，为动态辐射场 (radiance fields) 的高效 3D 重建提供了新途径。",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.GR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05356v1",
      "published_date": "2025-05-08 15:45:53 UTC",
      "updated_date": "2025-05-08 15:45:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:56:13.958473"
    },
    {
      "arxiv_id": "2505.05354v1",
      "title": "High-fidelity Grain Growth Modeling: Leveraging Deep Learning for Fast Computations",
      "title_zh": "高保真晶粒生长建模：",
      "authors": [
        "Pungponhavoan Tep",
        "Marc Bernacki"
      ],
      "abstract": "Grain growth simulation is crucial for predicting metallic material\nmicrostructure evolution during annealing and resulting final mechanical\nproperties, but traditional partial differential equation-based methods are\ncomputationally expensive, creating bottlenecks in materials design and\nmanufacturing. In this work, we introduce a machine learning framework that\ncombines a Convolutional Long Short-Term Memory networks with an Autoencoder to\nefficiently predict grain growth evolution. Our approach captures both spatial\nand temporal aspects of grain evolution while encoding high-dimensional grain\nstructure data into a compact latent space for pattern learning, enhanced by a\nnovel composite loss function combining Mean Squared Error, Structural\nSimilarity Index Measurement, and Boundary Preservation to maintain structural\nintegrity of grain boundary topology of the prediction. Results demonstrated\nthat our machine learning approach accelerates grain growth prediction by up to\n\\SI{89}{\\times} faster, reducing computation time from \\SI{10}{\\minute} to\napproximately \\SI{10}{\\second} while maintaining high-fidelity predictions. The\nbest model (S-30-30) achieving a structural similarity score of\n\\SI{86.71}{\\percent} and mean grain size error of just \\SI{0.07}{\\percent}. All\nmodels accurately captured grain boundary topology, morphology, and size\ndistributions. This approach enables rapid microstructural prediction for\napplications where conventional simulations are prohibitively time-consuming,\npotentially accelerating innovation in materials science and manufacturing.",
      "tldr_zh": "该研究针对晶粒生长模拟的计算瓶颈，提出了一种基于机器学习的框架，结合 Convolutional Long Short-Term Memory networks (ConvLSTM) 和 Autoencoder 来高效预测金属材料在退火过程中的微观结构演化。该框架捕捉晶粒的空间和时间动态，并引入一个新型复合损失函数，包括 Mean Squared Error (MSE)、Structural Similarity Index Measurement (SSIM) 和边界保持机制，以确保预测的晶粒边界拓扑和结构完整性。实验结果显示，该方法将计算时间从10分钟加速至10秒，提速高达89倍，同时最佳模型(S-30-30)实现了86.71%的结构相似性分数和仅0.07%的平均晶粒大小误差，准确捕捉晶粒形态和大小分布，从而为材料科学和制造领域的创新提供快速微观结构预测工具。",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.AI"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05354v1",
      "published_date": "2025-05-08 15:43:40 UTC",
      "updated_date": "2025-05-08 15:43:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:56:26.834971"
    },
    {
      "arxiv_id": "2505.05533v2",
      "title": "Rethinking Graph Contrastive Learning through Relative Similarity Preservation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiyuan Ning",
        "Pengfei Wang",
        "Ziyue Qiao",
        "Pengyang Wang",
        "Yuanchun Zhou"
      ],
      "abstract": "Graph contrastive learning (GCL) has achieved remarkable success by following\nthe computer vision paradigm of preserving absolute similarity between\naugmented views. However, this approach faces fundamental challenges in graphs\ndue to their discrete, non-Euclidean nature -- view generation often breaks\nsemantic validity and similarity verification becomes unreliable. Through\nanalyzing 11 real-world graphs, we discover a universal pattern transcending\nthe homophily-heterophily dichotomy: label consistency systematically\ndiminishes as structural distance increases, manifesting as smooth decay in\nhomophily graphs and oscillatory decay in heterophily graphs. We establish\ntheoretical guarantees for this pattern through random walk theory, proving\nlabel distribution convergence and characterizing the mechanisms behind\ndifferent decay behaviors. This discovery reveals that graphs naturally encode\nrelative similarity patterns, where structurally closer nodes exhibit\ncollectively stronger semantic relationships. Leveraging this insight, we\npropose RELGCL, a novel GCL framework with complementary pairwise and listwise\nimplementations that preserve these inherent patterns through collective\nsimilarity objectives. Extensive experiments demonstrate that our method\nconsistently outperforms 20 existing approaches across both homophily and\nheterophily graphs, validating the effectiveness of leveraging natural relative\nsimilarity over artificial absolute similarity.",
      "tldr_zh": "本研究重新审视了Graph Contrastive Learning (GCL)，指出其依赖于保留增强视图的绝对相似性，但在图的离散、非欧式性质下，容易破坏语义有效性和相似性验证。作者通过分析11个真实世界图，发现标签一致性随结构距离增加而衰减（同质图为平滑衰减，异质图为振荡衰减），并利用随机游走理论提供理论保证。基于此，他们提出RELGCL框架，通过集体相似性目标的成对和列表式实现，保留图的固有相对相似性模式。实验结果显示，RELGCL在同质和异质图上优于20种现有方法，验证了利用自然相对相似性比人工绝对相似性更有效的优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by IJCAI2025; full version including appendix",
      "pdf_url": "http://arxiv.org/pdf/2505.05533v2",
      "published_date": "2025-05-08 15:24:23 UTC",
      "updated_date": "2025-05-12 05:13:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:56:39.138449"
    },
    {
      "arxiv_id": "2505.05321v1",
      "title": "Feature-Augmented Deep Networks for Multiscale Building Segmentation in High-Resolution UAV and Satellite Imagery",
      "title_zh": "翻译失败",
      "authors": [
        "Chintan B. Maniyar",
        "Minakshi Kumar",
        "Gengchen Mai"
      ],
      "abstract": "Accurate building segmentation from high-resolution RGB imagery remains\nchallenging due to spectral similarity with non-building features, shadows, and\nirregular building geometries. In this study, we present a comprehensive deep\nlearning framework for multiscale building segmentation using RGB aerial and\nsatellite imagery with spatial resolutions ranging from 0.4m to 2.7m. We curate\na diverse, multi-sensor dataset and introduce feature-augmented inputs by\nderiving secondary representations including Principal Component Analysis\n(PCA), Visible Difference Vegetation Index (VDVI), Morphological Building Index\n(MBI), and Sobel edge filters from RGB channels. These features guide a\nRes-U-Net architecture in learning complex spatial patterns more effectively.\nWe also propose training policies incorporating layer freezing, cyclical\nlearning rates, and SuperConvergence to reduce training time and resource\nusage. Evaluated on a held-out WorldView-3 image, our model achieves an overall\naccuracy of 96.5%, an F1-score of 0.86, and an Intersection over Union (IoU) of\n0.80, outperforming existing RGB-based benchmarks. This study demonstrates the\neffectiveness of combining multi-resolution imagery, feature augmentation, and\noptimized training strategies for robust building segmentation in remote\nsensing applications.",
      "tldr_zh": "这篇论文提出了一种针对高分辨率 UAV 和卫星图像的多尺度建筑物分割框架，使用特征增强的深度网络来应对光谱相似性、阴影和不规则几何等挑战。研究团队整理了多样化的多传感器数据集，并从 RGB 通道派生次级特征（如 PCA、VDVI、MBI 和 Sobel 边缘滤波器），结合 Res-U-Net 架构和优化训练策略（包括层冻结、循环学习率和 SuperConvergence），以更有效地学习复杂空间模式。实验结果显示，该模型在 WorldView-3 图像上达到 96.5% 准确率、0.86 F1-score 和 0.80 IoU，优于现有 RGB 基准，为遥感应用中的鲁棒建筑物分割提供了有效方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.4.6; I.4.10; I.5.1; I.2.10"
      ],
      "primary_category": "cs.CV",
      "comment": "in preparation for journal submission, 25 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.05321v1",
      "published_date": "2025-05-08 15:08:36 UTC",
      "updated_date": "2025-05-08 15:08:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:56:50.866088"
    },
    {
      "arxiv_id": "2505.05318v1",
      "title": "Mapping User Trust in Vision Language Models: Research Landscape, Challenges, and Prospects",
      "title_zh": "映射视觉语言模型中的用户信任：研究景观、",
      "authors": [
        "Agnese Chiatti",
        "Sara Bernardini",
        "Lara Shibelski Godoy Piccolo",
        "Viola Schiaffonati",
        "Matteo Matteucci"
      ],
      "abstract": "The rapid adoption of Vision Language Models (VLMs), pre-trained on large\nimage-text and video-text datasets, calls for protecting and informing users\nabout when to trust these systems. This survey reviews studies on trust\ndynamics in user-VLM interactions, through a multi-disciplinary taxonomy\nencompassing different cognitive science capabilities, collaboration modes, and\nagent behaviours. Literature insights and findings from a workshop with\nprospective VLM users inform preliminary requirements for future VLM trust\nstudies.",
      "tldr_zh": "这篇调查论文探讨了用户对 Vision Language Models (VLMs) 的信任问题，审视了研究景观、挑战和前景，以应对 VLMs 快速采用带来的风险。作者通过一个多学科分类，包括认知科学能力、协作模式和 agent behaviours，回顾了用户-VLM 互动中的信任动态，并结合文献洞见和一个与潜在用户的工作坊讨论。研究结果为未来 VLM 信任研究提供了初步要求，强调了保护和告知用户的必要性，以确保这些模型的安全应用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CY",
        "cs.HC",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05318v1",
      "published_date": "2025-05-08 15:02:49 UTC",
      "updated_date": "2025-05-08 15:02:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:57:01.333498"
    },
    {
      "arxiv_id": "2505.05315v2",
      "title": "Scalable Chain of Thoughts via Elastic Reasoning",
      "title_zh": "通过弹性推理的可扩展链式思维",
      "authors": [
        "Yuhui Xu",
        "Hanze Dong",
        "Lei Wang",
        "Doyen Sahoo",
        "Junnan Li",
        "Caiming Xiong"
      ],
      "abstract": "Large reasoning models (LRMs) have achieved remarkable progress on complex\ntasks by generating extended chains of thought (CoT). However, their\nuncontrolled output lengths pose significant challenges for real-world\ndeployment, where inference-time budgets on tokens, latency, or compute are\nstrictly constrained. We propose Elastic Reasoning, a novel framework for\nscalable chain of thoughts that explicitly separates reasoning into two\nphases--thinking and solution--with independently allocated budgets. At test\ntime, Elastic Reasoning prioritizes the completeness of solution segments,\nsignificantly improving reliability under tight resource constraints. To train\nmodels that are robust to truncated thinking, we introduce a lightweight\nbudget-constrained rollout strategy, integrated into GRPO, which teaches the\nmodel to reason adaptively when the thinking process is cut short and\ngeneralizes effectively to unseen budget constraints without additional\ntraining. Empirical results on mathematical (AIME, MATH500) and programming\n(LiveCodeBench, Codeforces) benchmarks demonstrate that Elastic Reasoning\nperforms robustly under strict budget constraints, while incurring\nsignificantly lower training cost than baseline methods. Remarkably, our\napproach also produces more concise and efficient reasoning even in\nunconstrained settings. Our code has been made available at\nhttps://github.com/SalesforceAIResearch/Elastic-Reasoning.",
      "tldr_zh": "该研究提出 Elastic Reasoning 框架，以解决大型推理模型 (LRMs) 在生成链式思考 (CoT) 时输出长度不受控的问题，从而适应严格的推理预算约束。该框架将推理分为独立的 thinking 和 solution 阶段，并分配独立预算，在测试时优先确保 solution 的完整性，提高资源紧缺下的可靠性。为训练鲁棒模型，作者引入了轻量级的预算约束 rollout 策略，整合到 GRPO 中，使模型能适应性推理并泛化到未见预算，而无需额外训练。在数学基准 (AIME, MATH500) 和编程基准 (LiveCodeBench, Codeforces) 上，Elastic Reasoning 在严格约束下表现出色，训练成本远低于基线方法，甚至在无约束场景下产生更简洁高效的推理。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05315v2",
      "published_date": "2025-05-08 15:01:06 UTC",
      "updated_date": "2025-05-21 05:40:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:57:14.392225"
    },
    {
      "arxiv_id": "2505.05291v2",
      "title": "Benchmarking Ophthalmology Foundation Models for Clinically Significant Age Macular Degeneration Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Benjamin A. Cohen",
        "Jonathan Fhima",
        "Meishar Meisel",
        "Baskin Meital",
        "Luis Filipe Nakayama",
        "Eran Berkowitz",
        "Joachim A. Behar"
      ],
      "abstract": "Self-supervised learning (SSL) has enabled Vision Transformers (ViTs) to\nlearn robust representations from large-scale natural image datasets, enhancing\ntheir generalization across domains. In retinal imaging, foundation models\npretrained on either natural or ophthalmic data have shown promise, but the\nbenefits of in-domain pretraining remain uncertain. To investigate this, we\nbenchmark six SSL-pretrained ViTs on seven digital fundus image (DFI) datasets\ntotaling 70,000 expert-annotated images for the task of moderate-to-late\nage-related macular degeneration (AMD) identification. Our results show that\niBOT pretrained on natural images achieves the highest out-of-distribution\ngeneralization, with AUROCs of 0.80-0.97, outperforming domain-specific models,\nwhich achieved AUROCs of 0.78-0.96 and a baseline ViT-L with no pretraining,\nwhich achieved AUROCs of 0.68-0.91. These findings highlight the value of\nfoundation models in improving AMD identification and challenge the assumption\nthat in-domain pretraining is necessary. Furthermore, we release BRAMD, an\nopen-access dataset (n=587) of DFIs with AMD labels from Brazil.",
      "tldr_zh": "这篇论文评估了自监督学习（SSL）预训练的Vision Transformers（ViTs）模型在检测临床显著年龄相关性黄斑变性（AMD）方面的性能，比较了使用自然图像或眼科数据预训练的效果。研究者基准测试了六个SSL预训练的ViTs模型，在七个数字眼底图像（DFI）数据集上进行测试，总计70,000张专家标注图像。结果显示，在自然图像上预训练的iBOT模型实现了最高的分布外泛化性能，AUROC为0.80-0.97，优于领域特定模型（AUROC 0.78-0.96）和无预训练的ViT-L基线（AUROC 0.68-0.91）。这些发现突出了基础模型在提升AMD识别方面的价值，并挑战了领域内预训练的必要性，同时论文发布了开放访问数据集BRAMD（n=587），包含巴西的DFI和AMD标签。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "q-bio.TO"
      ],
      "primary_category": "eess.IV",
      "comment": "10 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.05291v2",
      "published_date": "2025-05-08 14:31:02 UTC",
      "updated_date": "2025-05-22 10:41:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:57:29.110991"
    },
    {
      "arxiv_id": "2505.05288v1",
      "title": "PlaceIt3D: Language-Guided Object Placement in Real 3D Scenes",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmed Abdelreheem",
        "Filippo Aleotti",
        "Jamie Watson",
        "Zawar Qureshi",
        "Abdelrahman Eldesokey",
        "Peter Wonka",
        "Gabriel Brostow",
        "Sara Vicente",
        "Guillermo Garcia-Hernando"
      ],
      "abstract": "We introduce the novel task of Language-Guided Object Placement in Real 3D\nScenes. Our model is given a 3D scene's point cloud, a 3D asset, and a textual\nprompt broadly describing where the 3D asset should be placed. The task here is\nto find a valid placement for the 3D asset that respects the prompt. Compared\nwith other language-guided localization tasks in 3D scenes such as grounding,\nthis task has specific challenges: it is ambiguous because it has multiple\nvalid solutions, and it requires reasoning about 3D geometric relationships and\nfree space. We inaugurate this task by proposing a new benchmark and evaluation\nprotocol. We also introduce a new dataset for training 3D LLMs on this task, as\nwell as the first method to serve as a non-trivial baseline. We believe that\nthis challenging task and our new benchmark could become part of the suite of\nbenchmarks used to evaluate and compare generalist 3D LLM models.",
      "tldr_zh": "本研究引入了Language-Guided Object Placement in Real 3D Scenes这一新任务，该任务要求模型根据3D场景的point cloud、一个3D asset以及文本提示，找到符合提示的合法放置位置。相较于传统的3D场景定位任务（如grounding），此任务面临模糊性（多个有效解决方案）和需推理3D几何关系与free space的挑战。研究者提出一个新基准、评估协议和数据集，用于训练3D LLMs，并开发了首个非平凡基线方法，以推动通用3D LLM模型的评估和比较。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Tech report. Project page: https://nianticlabs.github.io/placeit3d/",
      "pdf_url": "http://arxiv.org/pdf/2505.05288v1",
      "published_date": "2025-05-08 14:29:11 UTC",
      "updated_date": "2025-05-08 14:29:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:57:38.177418"
    },
    {
      "arxiv_id": "2505.05283v2",
      "title": "Software Development Life Cycle Perspective: A Survey of Benchmarks for Code Large Language Models and Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Kaixin Wang",
        "Tianlin Li",
        "Xiaoyu Zhang",
        "Chong Wang",
        "Weisong Sun",
        "Yang Liu",
        "Bin Shi"
      ],
      "abstract": "Code large language models (CodeLLMs) and agents have shown great promise in\ntackling complex software engineering tasks.Compared to traditional software\nengineering methods, CodeLLMs and agents offer stronger abilities, and can\nflexibly process inputs and outputs in both natural and code. Benchmarking\nplays a crucial role in evaluating the capabilities of CodeLLMs and agents,\nguiding their development and deployment. However, despite their growing\nsignificance, there remains a lack of comprehensive reviews of benchmarks for\nCodeLLMs and agents. To bridge this gap, this paper provides a comprehensive\nreview of existing benchmarks for CodeLLMs and agents, studying and analyzing\n181 benchmarks from 461 relevant papers, covering the different phases of the\nsoftware development life cycle (SDLC). Our findings reveal a notable imbalance\nin the coverage of current benchmarks, with approximately 60% focused on the\nsoftware development phase in SDLC, while requirements engineering and software\ndesign phases receive minimal attention at only 5% and 3%, respectively.\nAdditionally, Python emerges as the dominant programming language across the\nreviewed benchmarks. Finally, this paper highlights the challenges of current\nresearch and proposes future directions, aiming to narrow the gap between the\ntheoretical capabilities of CodeLLMs and agents and their application in\nreal-world scenarios.",
      "tldr_zh": "这篇论文从软件开发生命周期（SDLC）的角度，对CodeLLMs和agents的基准进行了全面调查，分析了来自461篇相关论文的181个基准。研究发现，当前基准覆盖存在明显不平衡，大约60%集中在SDLC的软件开发阶段，而需求工程和软件设计阶段仅占5%和3%，且Python是这些基准中的主导编程语言。该调查突出了现有研究的挑战，并提出未来方向，以桥接CodeLLMs和agents的理论能力与实际应用间的差距。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05283v2",
      "published_date": "2025-05-08 14:27:45 UTC",
      "updated_date": "2025-05-09 03:39:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:57:49.417940"
    },
    {
      "arxiv_id": "2505.06312v1",
      "title": "Responsibility Gap in Collective Decision Making",
      "title_zh": "翻译失败",
      "authors": [
        "Pavel Naumov",
        "Jia Tao"
      ],
      "abstract": "The responsibility gap is a set of outcomes of a collective decision-making\nmechanism in which no single agent is individually responsible. In general,\nwhen designing a decision-making process, it is desirable to minimise the gap.\n  The paper proposes a concept of an elected dictatorship. It shows that, in a\nperfect information setting, the gap is empty if and only if the mechanism is\nan elected dictatorship. It also proves that in an imperfect information\nsetting, the class of gap-free mechanisms is positioned strictly between two\nvariations of the class of elected dictatorships.",
      "tldr_zh": "这篇论文探讨了集体决策中的责任缺口（responsibility gap），即决策机制导致没有单个代理个体负责的情况，并强调了最小化这一缺口的重要性。论文提出“elected dictatorship”的概念，并在完美信息设置下证明，责任缺口为空当且仅当机制是 elected dictatorship。进一步，在不完美信息设置下，论文证明无缺口机制严格位于两个 elected dictatorships 变体之间，从而为设计更负责任的集体决策机制提供了理论基础。",
      "categories": [
        "cs.GT",
        "cs.AI"
      ],
      "primary_category": "cs.GT",
      "comment": "full version of an IJCAI-25 paper",
      "pdf_url": "http://arxiv.org/pdf/2505.06312v1",
      "published_date": "2025-05-08 14:19:59 UTC",
      "updated_date": "2025-05-08 14:19:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:58:01.347426"
    },
    {
      "arxiv_id": "2505.05271v1",
      "title": "T-T: Table Transformer for Tagging-based Aspect Sentiment Triplet Extraction",
      "title_zh": "T-T：基于",
      "authors": [
        "Kun Peng",
        "Chaodong Tong",
        "Cong Cao",
        "Hao Peng",
        "Qian Li",
        "Guanlin Wu",
        "Lei Jiang",
        "Yanbing Liu",
        "Philip S. Yu"
      ],
      "abstract": "Aspect sentiment triplet extraction (ASTE) aims to extract triplets composed\nof aspect terms, opinion terms, and sentiment polarities from given sentences.\nThe table tagging method is a popular approach to addressing this task, which\nencodes a sentence into a 2-dimensional table, allowing for the tagging of\nrelations between any two words. Previous efforts have focused on designing\nvarious downstream relation learning modules to better capture interactions\nbetween tokens in the table, revealing that a stronger capability to capture\nrelations can lead to greater improvements in the model. Motivated by this, we\nattempt to directly utilize transformer layers as downstream relation learning\nmodules. Due to the powerful semantic modeling capability of transformers, it\nis foreseeable that this will lead to excellent improvement. However, owing to\nthe quadratic relation between the length of the table and the length of the\ninput sentence sequence, using transformers directly faces two challenges:\noverly long table sequences and unfair local attention interaction. To address\nthese challenges, we propose a novel Table-Transformer (T-T) for the\ntagging-based ASTE method. Specifically, we introduce a stripe attention\nmechanism with a loop-shift strategy to tackle these challenges. The former\nmodifies the global attention mechanism to only attend to a 2-dimensional local\nattention window, while the latter facilitates interaction between different\nattention windows. Extensive and comprehensive experiments demonstrate that the\nT-T, as a downstream relation learning module, achieves state-of-the-art\nperformance with lower computational costs.",
      "tldr_zh": "该论文针对Aspect Sentiment Triplet Extraction (ASTE)任务，提出了一种基于表标记方法的T-T (Table-Transformer)框架，用于从句子中提取方面术语、意见术语和情感极性三元组。T-T直接利用Transformer层作为下游关系学习模块，以更好地捕捉表中标记之间的交互，但通过引入stripe attention mechanism和loop-shift strategy来解决表序列过长和局部注意力交互不公平的挑战。这种设计显著降低了计算成本，并在广泛实验中实现了state-of-the-art性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by IJCAI2025",
      "pdf_url": "http://arxiv.org/pdf/2505.05271v1",
      "published_date": "2025-05-08 14:17:27 UTC",
      "updated_date": "2025-05-08 14:17:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:58:13.607962"
    },
    {
      "arxiv_id": "2505.05262v1",
      "title": "Enhancing Cooperative Multi-Agent Reinforcement Learning with State Modelling and Adversarial Exploration",
      "title_zh": "通过状态建模和对抗探索增强合作的 multi-agent 强化学习",
      "authors": [
        "Andreas Kontogiannis",
        "Konstantinos Papathanasiou",
        "Yi Shen",
        "Giorgos Stamou",
        "Michael M. Zavlanos",
        "George Vouros"
      ],
      "abstract": "Learning to cooperate in distributed partially observable environments with\nno communication abilities poses significant challenges for multi-agent deep\nreinforcement learning (MARL). This paper addresses key concerns in this\ndomain, focusing on inferring state representations from individual agent\nobservations and leveraging these representations to enhance agents'\nexploration and collaborative task execution policies. To this end, we propose\na novel state modelling framework for cooperative MARL, where agents infer\nmeaningful belief representations of the non-observable state, with respect to\noptimizing their own policies, while filtering redundant and less informative\njoint state information. Building upon this framework, we propose the MARL SMPE\nalgorithm. In SMPE, agents enhance their own policy's discriminative abilities\nunder partial observability, explicitly by incorporating their beliefs into the\npolicy network, and implicitly by adopting an adversarial type of exploration\npolicies which encourages agents to discover novel, high-value states while\nimproving the discriminative abilities of others. Experimentally, we show that\nSMPE outperforms state-of-the-art MARL algorithms in complex fully cooperative\ntasks from the MPE, LBF, and RWARE benchmarks.",
      "tldr_zh": "这篇论文针对多智能体深度强化学习(MARL)中，在无通信的分布式部分可观测环境中学习合作的问题，提出了一种新的状态建模框架，帮助代理从个体观察推断有意义的信念表示，并过滤冗余信息以优化自身策略。基于此框架，作者开发了MARL SMPE算法，该算法显式地将信念整合到策略网络中增强辨别能力，并隐式采用对抗式探索策略，鼓励代理发现高价值状态并提升整体协作。实验结果表明，SMPE在MPE、LBF和RWARE基准的复杂完全合作任务中，优于现有最先进MARL算法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted (Poster) at ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.05262v1",
      "published_date": "2025-05-08 14:07:20 UTC",
      "updated_date": "2025-05-08 14:07:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:58:26.094476"
    },
    {
      "arxiv_id": "2505.05235v1",
      "title": "Advancing Neural Network Verification through Hierarchical Safety Abstract Interpretation",
      "title_zh": "通过分层安全抽象解释推进神经网络验证",
      "authors": [
        "Luca Marzari",
        "Isabella Mastroeni",
        "Alessandro Farinelli"
      ],
      "abstract": "Traditional methods for formal verification (FV) of deep neural networks\n(DNNs) are constrained by a binary encoding of safety properties, where a model\nis classified as either safe or unsafe (robust or not robust). This binary\nencoding fails to capture the nuanced safety levels within a model, often\nresulting in either overly restrictive or too permissive requirements. In this\npaper, we introduce a novel problem formulation called Abstract\nDNN-Verification, which verifies a hierarchical structure of unsafe outputs,\nproviding a more granular analysis of the safety aspect for a given DNN.\nCrucially, by leveraging abstract interpretation and reasoning about output\nreachable sets, our approach enables assessing multiple safety levels during\nthe FV process, requiring the same (in the worst case) or even potentially less\ncomputational effort than the traditional binary verification approach.\nSpecifically, we demonstrate how this formulation allows rank adversarial\ninputs according to their abstract safety level violation, offering a more\ndetailed evaluation of the model's safety and robustness. Our contributions\ninclude a theoretical exploration of the relationship between our novel\nabstract safety formulation and existing approaches that employ abstract\ninterpretation for robustness verification, complexity analysis of the novel\nproblem introduced, and an empirical evaluation considering both a complex deep\nreinforcement learning task (based on Habitat 3.0) and standard\nDNN-Verification benchmarks.",
      "tldr_zh": "本论文针对传统深度神经网络（DNNs）验证方法的二元安全编码（安全或不安全）问题，提出了一种新型Abstract DNN-Verification框架，通过分层不安全输出的层次化安全抽象解释，提供更细粒度的安全分析。方法利用抽象 interpretation 和输出可达集的推理，评估多个安全级别，并对对抗输入进行基于抽象安全级别违反的排名，从而在计算努力方面与传统方法相当或更高效。论文贡献包括理论探讨该框架与现有鲁棒性验证方法的关联、复杂性分析，以及实证评估（如基于Habitat 3.0的深度强化学习任务和标准DNN-Verification基准），证明了其在提升模型安全性和鲁棒性方面的有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05235v1",
      "published_date": "2025-05-08 13:29:46 UTC",
      "updated_date": "2025-05-08 13:29:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:58:38.974784"
    },
    {
      "arxiv_id": "2505.05232v1",
      "title": "ChemRxivQuest: A Curated Chemistry Question-Answer Database Extracted from ChemRxiv Preprints",
      "title_zh": "翻译失败",
      "authors": [
        "Mahmoud Amiri",
        "Thomas Bocklitz"
      ],
      "abstract": "The rapid expansion of chemistry literature poses significant challenges for\nresearchers seeking to efficiently access domain-specific knowledge. To support\nadvancements in chemistry-focused natural language processing (NLP), we present\nChemRxivQuest, a curated dataset of 970 high-quality question-answer (QA) pairs\nderived from 155 ChemRxiv preprints across 17 subfields of chemistry. Each QA\npair is explicitly linked to its source text segment to ensure traceability and\ncontextual accuracy. ChemRxivQuest was constructed using an automated pipeline\nthat combines optical character recognition (OCR), GPT-4o-based QA generation,\nand a fuzzy matching technique for answer verification. The dataset emphasizes\nconceptual, mechanistic, applied, and experimental questions, enabling\napplications in retrieval-based QA systems, search engine development, and\nfine-tuning of domain-adapted large language models. We analyze the dataset's\nstructure, coverage, and limitations, and outline future directions for\nexpansion and expert validation. ChemRxivQuest provides a foundational resource\nfor chemistry NLP research, education, and tool development.",
      "tldr_zh": "论文介绍了 ChemRxivQuest，这是一个从 ChemRxiv 预印本中提取的化学问答数据库，包含 970 个高质量 QA pairs，覆盖 17 个化学子领域，并确保每个 QA pair 与源文本段链接以保持准确性。数据集通过自动化管道构建，包括 OCR 技术、GPT-4o 基于的 QA 生成和模糊匹配验证，专注于概念性、机制性、应用性和实验性问题。该资源适用于检索-based QA 系统、搜索引擎开发以及微调领域适应的语言模型，并分析了其结构、覆盖范围和限制，为化学 NLP 研究、教育和工具开发提供基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05232v1",
      "published_date": "2025-05-08 13:26:33 UTC",
      "updated_date": "2025-05-08 13:26:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:58:51.299991"
    },
    {
      "arxiv_id": "2505.05530v1",
      "title": "Low-bit Model Quantization for Deep Neural Networks: A Survey",
      "title_zh": "深度神经网络的低位模型量化：综述",
      "authors": [
        "Kai Liu",
        "Qian Zheng",
        "Kaiwen Tao",
        "Zhiteng Li",
        "Haotong Qin",
        "Wenbo Li",
        "Yong Guo",
        "Xianglong Liu",
        "Linghe Kong",
        "Guihai Chen",
        "Yulun Zhang",
        "Xiaokang Yang"
      ],
      "abstract": "With unprecedented rapid development, deep neural networks (DNNs) have deeply\ninfluenced almost all fields. However, their heavy computation costs and model\nsizes are usually unacceptable in real-world deployment. Model quantization, an\neffective weight-lighting technique, has become an indispensable procedure in\nthe whole deployment pipeline. The essence of quantization acceleration is the\nconversion from continuous floating-point numbers to discrete integer ones,\nwhich significantly speeds up the memory I/O and calculation, i.e., addition\nand multiplication. However, performance degradation also comes with the\nconversion because of the loss of precision. Therefore, it has become\nincreasingly popular and critical to investigate how to perform the conversion\nand how to compensate for the information loss. This article surveys the recent\nfive-year progress towards low-bit quantization on DNNs. We discuss and compare\nthe state-of-the-art quantization methods and classify them into 8 main\ncategories and 24 sub-categories according to their core techniques.\nFurthermore, we shed light on the potential research opportunities in the field\nof model quantization. A curated list of model quantization is provided at\nhttps://github.com/Kai-Liu001/Awesome-Model-Quantization.",
      "tldr_zh": "这篇论文对深度神经网络 (DNNs) 中的低位模型量化技术进行了全面调研，旨在解决模型计算成本和大小问题，通过将浮点数转换为整数来加速内存 I/O 和运算。论文将过去五年的量化方法分类为 8 个主要类别和 24 个子类别，并比较了这些方法的优缺点，以探讨如何最小化精度损失并补偿信息缺失。最终，它指出了模型量化的潜在研究机会，并提供了一个资源列表（https://github.com/Kai-Liu001/Awesome-Model-Quantization），为相关领域的部署和优化提供指导。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "We have systematically collected and reviewed the state-of-the-art\n  quantization methods from the past five years, categorizing them into eight\n  distinct groups. A curated list of model quantization is provided at\n  https://github.com/Kai-Liu001/Awesome-Model-Quantization",
      "pdf_url": "http://arxiv.org/pdf/2505.05530v1",
      "published_date": "2025-05-08 13:26:19 UTC",
      "updated_date": "2025-05-08 13:26:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:59:03.221290"
    },
    {
      "arxiv_id": "2505.05226v1",
      "title": "Put CASH on Bandits: A Max K-Armed Problem for Automated Machine Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Amir Rezaei Balef",
        "Claire Vernade",
        "Katharina Eggensperger"
      ],
      "abstract": "The Combined Algorithm Selection and Hyperparameter optimization (CASH) is a\nchallenging resource allocation problem in the field of AutoML. We propose\nMaxUCB, a max $k$-armed bandit method to trade off exploring different model\nclasses and conducting hyperparameter optimization. MaxUCB is specifically\ndesigned for the light-tailed and bounded reward distributions arising in this\nsetting and, thus, provides an efficient alternative compared to classic max\n$k$-armed bandit methods assuming heavy-tailed reward distributions. We\ntheoretically and empirically evaluate our method on four standard AutoML\nbenchmarks, demonstrating superior performance over prior approaches.",
      "tldr_zh": "该研究针对 Automated Machine Learning (AutoML) 中的 Combined Algorithm Selection and Hyperparameter optimization (CASH) 问题，提出了一种 max k-armed bandit 方法名为 MaxUCB，用于在探索不同模型类和超参数优化之间实现资源分配权衡。MaxUCB 专门设计适用于 CASH 的轻尾和有界奖励分布，提供比经典假设重尾分布方法的更高效替代方案。通过理论分析和实证评估，该方法在四个标准 AutoML 基准上表现出色，优于现有方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05226v1",
      "published_date": "2025-05-08 13:18:05 UTC",
      "updated_date": "2025-05-08 13:18:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:59:13.167916"
    },
    {
      "arxiv_id": "2505.06311v1",
      "title": "Defending against Indirect Prompt Injection by Instruction Detection",
      "title_zh": "基于指令检测防御间接提示注入",
      "authors": [
        "Tongyu Wen",
        "Chenglong Wang",
        "Xiyuan Yang",
        "Haoyu Tang",
        "Yueqi Xie",
        "Lingjuan Lyu",
        "Zhicheng Dou",
        "Fangzhao Wu"
      ],
      "abstract": "The integration of Large Language Models (LLMs) with external sources is\nbecoming increasingly common, with Retrieval-Augmented Generation (RAG) being a\nprominent example. However, this integration introduces vulnerabilities of\nIndirect Prompt Injection (IPI) attacks, where hidden instructions embedded in\nexternal data can manipulate LLMs into executing unintended or harmful actions.\nWe recognize that the success of IPI attacks fundamentally relies in the\npresence of instructions embedded within external content, which can alter the\nbehavioral state of LLMs. Can effectively detecting such state changes help us\ndefend against IPI attacks? In this paper, we propose a novel approach that\ntakes external data as input and leverages the behavioral state of LLMs during\nboth forward and backward propagation to detect potential IPI attacks.\nSpecifically, we demonstrate that the hidden states and gradients from\nintermediate layers provide highly discriminative features for instruction\ndetection. By effectively combining these features, our approach achieves a\ndetection accuracy of 99.60\\% in the in-domain setting and 96.90\\% in the\nout-of-domain setting, while reducing the attack success rate to just 0.12\\% on\nthe BIPIA benchmark.",
      "tldr_zh": "该研究针对 Large Language Models (LLMs) 与外部来源（如 Retrieval-Augmented Generation (RAG)）整合引发的 Indirect Prompt Injection (IPI) 攻击问题，提出了一种基于指令检测的防御方法。方法利用 LLMs 在前向和后向传播中的隐藏状态和梯度作为判别特征，来识别嵌入外部内容中的潜在恶意指令。实验结果显示，该方法在 in-domain 设置下检测准确率达到 99.60%，在 out-of-domain 设置下达到 96.90%，并将攻击成功率降低到 0.12% 在 BIPIA benchmark 上，从而显著提升了模型的安全性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "13 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.06311v1",
      "published_date": "2025-05-08 13:04:45 UTC",
      "updated_date": "2025-05-08 13:04:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:59:26.607031"
    },
    {
      "arxiv_id": "2505.05211v1",
      "title": "Incentive-Aware Machine Learning; Robustness, Fairness, Improvement & Causality",
      "title_zh": "激励感知机器学习：鲁棒性、公平性、改进与因果关系",
      "authors": [
        "Chara Podimata"
      ],
      "abstract": "The article explores the emerging domain of incentive-aware machine learning\n(ML), which focuses on algorithmic decision-making in contexts where\nindividuals can strategically modify their inputs to influence outcomes. It\ncategorizes the research into three perspectives: robustness, aiming to design\nmodels resilient to \"gaming\"; fairness, analyzing the societal impacts of such\nsystems; and improvement/causality, recognizing situations where strategic\nactions lead to genuine personal or societal improvement. The paper introduces\na unified framework encapsulating models for these perspectives, including\noffline, online, and causal settings, and highlights key challenges such as\ndifferentiating between gaming and improvement and addressing heterogeneity\namong agents. By synthesizing findings from diverse works, we outline\ntheoretical advancements and practical solutions for robust, fair, and\ncausally-informed incentive-aware ML systems.",
      "tldr_zh": "这篇文章探讨了激励感知机器学习（Incentive-Aware Machine Learning），聚焦于个体可能战略性地修改输入来影响算法决策的情景，并将其分为三个视角：robustness（鲁棒性），旨在设计对“gaming”（操纵）有抵抗力的模型；fairness（公平性），分析此类系统的社会影响；以及improvement/causality（改进/因果性），识别战略行动带来的真实个人或社会益处。该文引入了一个统一的框架，涵盖offline、online和causal设置，以整合这些视角的关键挑战，如区分gaming与improvement以及处理agents的异质性。通过综合多领域研究，该框架概述了理论进展和实用解决方案，推动了鲁棒、公平且因果信息化的ML系统的发展。",
      "categories": [
        "cs.GT",
        "cs.AI"
      ],
      "primary_category": "cs.GT",
      "comment": "This literature review was published in SIGEcom Exchanges in 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.05211v1",
      "published_date": "2025-05-08 13:04:32 UTC",
      "updated_date": "2025-05-08 13:04:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:59:38.714157"
    },
    {
      "arxiv_id": "2505.05203v1",
      "title": "LAPSO: A Unified Optimization View for Learning-Augmented Power System Operations",
      "title_zh": "LAPSO：学习增强电力系统操作的统一优化视角",
      "authors": [
        "Wangkun Xu",
        "Zhongda Chu",
        "Fei Teng"
      ],
      "abstract": "With the high penetration of renewables, traditional model-based power system\noperation is challenged to deliver economic, stable, and robust decisions.\nMachine learning has emerged as a powerful modeling tool for capturing complex\ndynamics to address these challenges. However, its separate design often lacks\nsystematic integration with existing methods. To fill the gap, this paper\nproposes a holistic framework of Learning-Augmented Power System Operations\n(LAPSO, pronounced as Lap-So). Adopting a native optimization perspective,\nLAPSO is centered on the operation stage and aims to break the boundary between\ntemporally siloed power system tasks, such as forecast, operation and control,\nwhile unifying the objectives of machine learning and model-based optimizations\nat both training and inference stages. Systematic analysis and simulations\ndemonstrate the effectiveness of applying LAPSO in designing new integrated\nalgorithms, such as stability-constrained optimization (SCO) and\nobjective-based forecasting (OBF), while enabling end-to-end tracing of\ndifferent sources of uncertainties. In addition, a dedicated Python\npackage-lapso is introduced to automatically augment existing power system\noptimization models with learnable components. All code and data are available\nat https://github.com/xuwkk/lapso_exp.",
      "tldr_zh": "该论文提出 LAPSO 框架（Learning-Augmented Power System Operations），从统一的优化视角整合机器学习与模型-based 优化，旨在解决可再生能源高渗透下电力系统操作的经济性、稳定性和鲁棒性挑战。LAPSO 聚焦操作阶段，打破预测、操作和控制任务之间的界限，并在训练和推理阶段统一机器学习与优化目标，同时设计了新算法如 stability-constrained optimization (SCO) 和 objective-based forecasting (OBF)，并支持端到端的不确定性追踪。实验分析和模拟验证了 LAPSO 的有效性，并提供了一个 Python 包 lapso 用于自动增强现有电力系统优化模型，所有代码和数据已在 GitHub 上公开。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05203v1",
      "published_date": "2025-05-08 13:00:24 UTC",
      "updated_date": "2025-05-08 13:00:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:59:51.214140"
    },
    {
      "arxiv_id": "2505.05197v1",
      "title": "Societal and technological progress as sewing an ever-growing, ever-changing, patchy, and polychrome quilt",
      "title_zh": "翻译失败",
      "authors": [
        "Joel Z. Leibo",
        "Alexander Sasha Vezhnevets",
        "William A. Cunningham",
        "Sébastien Krier",
        "Manfred Diaz",
        "Simon Osindero"
      ],
      "abstract": "Artificial Intelligence (AI) systems are increasingly placed in positions\nwhere their decisions have real consequences, e.g., moderating online spaces,\nconducting research, and advising on policy. Ensuring they operate in a safe\nand ethically acceptable fashion is thus critical. However, most solutions have\nbeen a form of one-size-fits-all \"alignment\". We are worried that such systems,\nwhich overlook enduring moral diversity, will spark resistance, erode trust,\nand destabilize our institutions. This paper traces the underlying problem to\nan often-unstated Axiom of Rational Convergence: the idea that under ideal\nconditions, rational agents will converge in the limit of conversation on a\nsingle ethics. Treating that premise as both optional and doubtful, we propose\nwhat we call the appropriateness framework: an alternative approach grounded in\nconflict theory, cultural evolution, multi-agent systems, and institutional\neconomics. The appropriateness framework treats persistent disagreement as the\nnormal case and designs for it by applying four principles: (1) contextual\ngrounding, (2) community customization, (3) continual adaptation, and (4)\npolycentric governance. We argue here that adopting these design principles is\na good way to shift the main alignment metaphor from moral unification to a\nmore productive metaphor of conflict management, and that taking this step is\nboth desirable and urgent.",
      "tldr_zh": "这篇论文批评了现有AI alignment（对齐）方法采用“一刀切”策略，忽略了道德多样性的潜在风险，可能导致社会抵抗、信任流失和机构不稳定。作者质疑了理性收敛公理（Axiom of Rational Convergence），即理性代理在理想条件下会收敛于单一伦理，并提出适当性框架（appropriateness framework），该框架基于冲突理论、文化进化、多代理系统和制度经济学。框架通过四个原则——上下文 grounding、社区 customization、持续 adaptation 和多中心 governance——来处理持久分歧，将AI对齐的比喻从道德统一转向冲突管理，并强调此举的紧迫性。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.05197v1",
      "published_date": "2025-05-08 12:55:07 UTC",
      "updated_date": "2025-05-08 12:55:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:00:02.711516"
    },
    {
      "arxiv_id": "2505.05195v1",
      "title": "Concept-Based Unsupervised Domain Adaptation",
      "title_zh": "基于概念的无监督领域适应",
      "authors": [
        "Xinyue Xu",
        "Yueying Hu",
        "Hui Tang",
        "Yi Qin",
        "Lu Mi",
        "Hao Wang",
        "Xiaomeng Li"
      ],
      "abstract": "Concept Bottleneck Models (CBMs) enhance interpretability by explaining\npredictions through human-understandable concepts but typically assume that\ntraining and test data share the same distribution. This assumption often fails\nunder domain shifts, leading to degraded performance and poor generalization.\nTo address these limitations and improve the robustness of CBMs, we propose the\nConcept-based Unsupervised Domain Adaptation (CUDA) framework. CUDA is designed\nto: (1) align concept representations across domains using adversarial\ntraining, (2) introduce a relaxation threshold to allow minor domain-specific\ndifferences in concept distributions, thereby preventing performance drop due\nto over-constraints of these distributions, (3) infer concepts directly in the\ntarget domain without requiring labeled concept data, enabling CBMs to adapt to\ndiverse domains, and (4) integrate concept learning into conventional domain\nadaptation (DA) with theoretical guarantees, improving interpretability and\nestablishing new benchmarks for DA. Experiments demonstrate that our approach\nsignificantly outperforms the state-of-the-art CBM and DA methods on real-world\ndatasets.",
      "tldr_zh": "该研究针对 Concept Bottleneck Models (CBMs) 在领域偏移（domain shifts）下的性能下降问题，提出了一种 Concept-based Unsupervised Domain Adaptation (CUDA) 框架，以提升 CBMs 的鲁棒性和泛化能力。CUDA 通过对抗训练（adversarial training）对齐不同领域的概念表示，并引入松弛阈值（relaxation threshold）来容忍轻微的概念分布差异，同时在目标领域无监督地推断概念，并将概念学习整合到传统的 domain adaptation (DA) 中，提供理论保证并提高模型可解释性。实验结果显示，该框架在真实世界数据集上显著优于现有最先进的 CBM 和 DA 方法，建立了新的基准。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.05195v1",
      "published_date": "2025-05-08 12:52:02 UTC",
      "updated_date": "2025-05-08 12:52:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:00:15.121200"
    },
    {
      "arxiv_id": "2505.05190v2",
      "title": "Revealing Weaknesses in Text Watermarking Through Self-Information Rewrite Attacks",
      "title_zh": "通过自信息重写攻击揭示文本水印的弱点",
      "authors": [
        "Yixin Cheng",
        "Hongcheng Guo",
        "Yangming Li",
        "Leonid Sigal"
      ],
      "abstract": "Text watermarking aims to subtly embed statistical signals into text by\ncontrolling the Large Language Model (LLM)'s sampling process, enabling\nwatermark detectors to verify that the output was generated by the specified\nmodel. The robustness of these watermarking algorithms has become a key factor\nin evaluating their effectiveness. Current text watermarking algorithms embed\nwatermarks in high-entropy tokens to ensure text quality. In this paper, we\nreveal that this seemingly benign design can be exploited by attackers, posing\na significant risk to the robustness of the watermark. We introduce a generic\nefficient paraphrasing attack, the Self-Information Rewrite Attack (SIRA),\nwhich leverages the vulnerability by calculating the self-information of each\ntoken to identify potential pattern tokens and perform targeted attack. Our\nwork exposes a widely prevalent vulnerability in current watermarking\nalgorithms. The experimental results show SIRA achieves nearly 100% attack\nsuccess rates on seven recent watermarking methods with only 0.88 USD per\nmillion tokens cost. Our approach does not require any access to the watermark\nalgorithms or the watermarked LLM and can seamlessly transfer to any LLM as the\nattack model, even mobile-level models. Our findings highlight the urgent need\nfor more robust watermarking.",
      "tldr_zh": "这篇论文揭示了文本水印算法的弱点，通过提出Self-Information Rewrite Attack (SIRA)攻击方法，展示了如何利用Large Language Model (LLM)中高熵token的嵌入机制进行针对性改写。SIRA通过计算每个token的自信息来识别潜在模式token，并执行高效的改写攻击，而无需访问水印算法或水印LLM。实验结果显示，该攻击在七种最新水印方法上实现了近100%的成功率，每百万token仅需0.88 USD，并可无缝转移到任何LLM，包括移动级模型，这突显了加强水印算法鲁棒性的迫切需求。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2025 Accpeted",
      "pdf_url": "http://arxiv.org/pdf/2505.05190v2",
      "published_date": "2025-05-08 12:39:00 UTC",
      "updated_date": "2025-05-11 14:24:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:00:27.579547"
    },
    {
      "arxiv_id": "2505.05189v1",
      "title": "Biomed-DPT: Dual Modality Prompt Tuning for Biomedical Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Peng",
        "Kang Liu",
        "Jianchen Hu",
        "Meng Zhang"
      ],
      "abstract": "Prompt learning is one of the most effective paradigms for adapting\npre-trained vision-language models (VLMs) to the biomedical image\nclassification tasks in few shot scenarios. However, most of the current prompt\nlearning methods only used the text prompts and ignored the particular\nstructures (such as the complex anatomical structures and subtle pathological\nfeatures) in the biomedical images. In this work, we propose Biomed-DPT, a\nknowledge-enhanced dual modality prompt tuning technique. In designing the text\nprompt, Biomed-DPT constructs a dual prompt including the template-driven\nclinical prompts and the large language model (LLM)-driven domain-adapted\nprompts, then extracts the clinical knowledge from the domain-adapted prompts\nthrough the knowledge distillation technique. In designing the vision prompt,\nBiomed-DPT introduces the zero vector as a soft prompt to leverage attention\nre-weighting so that the focus on non-diagnostic regions and the recognition of\nnon-critical pathological features are avoided. Biomed-DPT achieves an average\nclassification accuracy of 66.14\\% across 11 biomedical image datasets covering\n9 modalities and 10 organs, with performance reaching 78.06\\% in base classes\nand 75.97\\% in novel classes, surpassing the Context Optimization (CoOp) method\nby 6.20\\%, 3.78\\%, and 8.04\\%, respectively. Our code are available at\n\\underline{https://github.com/Kanyooo/Biomed-DPT}.",
      "tldr_zh": "该研究提出 Biomed-DPT，一种知识增强的双模态提示调整技术，用于适应预训练视觉语言模型（VLMs）到生物医学图像分类任务，特别关注图像中的复杂解剖结构和微妙病理特征。在文本提示设计中，Biomed-DPT 构建双提示，包括模板驱动的临床提示和大型语言模型（LLM）驱动的领域适应提示，并通过知识蒸馏技术提取临床知识；在视觉提示设计中，使用零向量作为软提示进行注意力重分配，避免关注非诊断区域。在 11 个数据集上，Biomed-DPT 实现了 66.14% 的平均分类准确率，并在基类和新型类别上分别比 CoOp 方法提升 6.20%、3.78% 和 8.04%，证明了其在少样本场景中的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05189v1",
      "published_date": "2025-05-08 12:37:51 UTC",
      "updated_date": "2025-05-08 12:37:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:00:40.103967"
    },
    {
      "arxiv_id": "2505.05181v3",
      "title": "Stochastic Variational Propagation: Local, Scalable and Efficient Alternative to Backpropagation",
      "title_zh": "随机变分传播：对 Backpropagation 的本地、可扩展且高效替代方案",
      "authors": [
        "Bojian Yin",
        "Federico Corradi"
      ],
      "abstract": "Backpropagation (BP) is the cornerstone of deep learning, but its reliance on\nglobal gradient synchronization limits scalability and imposes significant\nmemory overhead. We propose Stochastic Variational Propagation (SVP), a\nscalable alternative that reframes training as hierarchical variational\ninference. SVP treats layer activations as latent variables and optimizes local\nEvidence Lower Bounds (ELBOs), enabling independent, local updates while\npreserving global coherence. However, directly applying KL divergence in\nlayer-wise ELBOs risks inter-layer's representation collapse due to excessive\ncompression. To prevent this, SVP projects activations into low-dimensional\nspaces via fixed random matrices, ensuring information preservation and\nrepresentational diversity. Combined with a feature alignment loss for\ninter-layer consistency, SVP achieves competitive accuracy with BP across\ndiverse architectures (MLPs, CNNs, Transformers) and datasets (MNIST to\nImageNet), reduces memory usage by up to 4x, and significantly improves\nscalability. More broadly, SVP introduces a probabilistic perspective to deep\nrepresentation learning, opening pathways toward more modular and interpretable\nneural network design.",
      "tldr_zh": "本文提出 Stochastic Variational Propagation (SVP)，一种局部、可扩展且高效的替代 Backpropagation (BP) 的训练方法，将深度学习训练重新框架为分层变分推理，通过将层激活视为潜在变量并优化局部的 Evidence Lower Bounds (ELBOs)，实现独立局部更新同时保持全局一致性。SVP 通过固定随机矩阵将激活投影到低维空间，以避免 KL divergence 导致的层间表示崩溃，并结合特征对齐损失确保层间一致性。该方法在 MLPs、CNNs 和 Transformers 等架构以及 MNIST 到 ImageNet 等数据集上，实现了与 BP 相当的准确率，同时减少内存使用多达 4 倍，并显著提升可扩展性。更广泛地，SVP 引入概率视角到深度表示学习，促进更模块化和可解释的神经网络设计。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.05181v3",
      "published_date": "2025-05-08 12:32:29 UTC",
      "updated_date": "2025-05-22 08:58:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:00:52.942029"
    },
    {
      "arxiv_id": "2505.05177v1",
      "title": "MARK: Memory Augmented Refinement of Knowledge",
      "title_zh": "MARK：记忆增强知识精炼",
      "authors": [
        "Anish Ganguli",
        "Prabal Deb",
        "Debleena Banerjee"
      ],
      "abstract": "Large Language Models (LLMs) assist in specialized tasks but struggle to\nalign with evolving domain knowledge without costly fine-tuning. Domain\nknowledge consists of: Knowledge: Immutable facts (e.g., 'A stone is solid')\nand generally accepted principles (e.g., ethical standards); Refined Memory:\nEvolving insights shaped by business needs and real-world changes. However, a\nsignificant gap often exists between a domain expert's deep, nuanced\nunderstanding and the system's domain knowledge, which can hinder accurate\ninformation retrieval and application. Our Memory-Augmented Refinement of\nKnowledge (MARK) framework enables LLMs to continuously learn without\nretraining by leveraging structured refined memory, inspired by the Society of\nMind. MARK operates through specialized agents, each serving a distinct role:\nResidual Refined Memory Agent: Stores and retrieves domain-specific insights to\nmaintain context over time; User Question Refined Memory Agent: Captures\nuser-provided facts, abbreviations, and terminology for better comprehension;\nLLM Response Refined Memory Agent: Extracts key elements from responses for\nrefinement and personalization. These agents analyse stored refined memory,\ndetect patterns, resolve contradictions, and improve response accuracy.\nTemporal factors like recency and frequency prioritize relevant information\nwhile discarding outdated insights. MARK enhances LLMs in multiple ways: Ground\nTruth Strategy: Reduces hallucinations by establishing a structured reference;\nDomain-Specific Adaptation: Essential for fields like healthcare, law, and\nmanufacturing, where proprietary insights are absent from public datasets;\nPersonalized AI Assistants: Improves virtual assistants by remembering user\npreferences, ensuring coherent responses over time.",
      "tldr_zh": "该研究提出 MARK（Memory Augmented Refinement of Knowledge）框架，帮助大型语言模型（LLMs）在无需昂贵微调的情况下，持续学习并适应演变的领域知识，包括不可变事实和动态精炼记忆。MARK 采用多智能体系统，受 Society of Mind 启发，包括 Residual Refined Memory Agent（存储和检索领域洞见）、User Question Refined Memory Agent（捕捉用户输入）和 LLM Response Refined Memory Agent（提取并优化响应），这些代理通过分析模式、解决矛盾并优先考虑时间因素（如新近性和频率）来提升准确性。该框架显著减少幻觉（通过 Ground Truth Strategy）、实现领域特定适应（如医疗和法律领域），并增强个性化 AI 助手的功能。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05177v1",
      "published_date": "2025-05-08 12:28:00 UTC",
      "updated_date": "2025-05-08 12:28:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:01:03.615943"
    },
    {
      "arxiv_id": "2505.05170v1",
      "title": "Dukawalla: Voice Interfaces for Small Businesses in Africa",
      "title_zh": "翻译失败",
      "authors": [
        "Elizabeth Ankrah",
        "Stephanie Nyairo",
        "Mercy Muchai",
        "Kagonya Awori",
        "Millicent Ochieng",
        "Mark Kariuki",
        "Jacki O'Neill"
      ],
      "abstract": "Small and medium sized businesses often struggle with data driven decision\nmaking do to a lack of advanced analytics tools, especially in African\ncountries where they make up a majority of the workforce. Though many tools\nexist they are not designed to fit into the ways of working of SMB workers who\nare mobile first, have limited time to learn new workflows, and for whom social\nand business are tightly coupled. To address this, the Dukawalla prototype was\ncreated. This intelligent assistant bridges the gap between raw business data,\nand actionable insights by leveraging voice interaction and the power of\ngenerative AI. Dukawalla provides an intuitive way for business owners to\ninteract with their data, aiding in informed decision making. This paper\nexamines Dukawalla's deployment across SMBs in Nairobi, focusing on their\nexperiences using this voice based assistant to streamline data collection and\nprovide business insights",
      "tldr_zh": "非洲的小型和中型企业（SMBs）在数据驱动决策方面面临挑战，因为缺乏适合移动优先、时间有限且社交商业紧密结合的先进分析工具。Dukawalla是一个智能助手原型，通过voice interfaces和generative AI，将原始业务数据转化为可操作的见解，帮助企业主直观地互动数据并做出 informed decision making。本文考察了Dukawalla在Nairobi SMBs中的部署，结果显示它能简化数据收集过程并提升业务洞察，用户体验表明该系统有效 bridging the gap 之间的数据和决策。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05170v1",
      "published_date": "2025-05-08 12:13:16 UTC",
      "updated_date": "2025-05-08 12:13:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:01:16.182813"
    },
    {
      "arxiv_id": "2505.05528v1",
      "title": "X-Transfer Attacks: Towards Super Transferable Adversarial Attacks on CLIP",
      "title_zh": "翻译失败",
      "authors": [
        "Hanxun Huang",
        "Sarah Erfani",
        "Yige Li",
        "Xingjun Ma",
        "James Bailey"
      ],
      "abstract": "As Contrastive Language-Image Pre-training (CLIP) models are increasingly\nadopted for diverse downstream tasks and integrated into large vision-language\nmodels (VLMs), their susceptibility to adversarial perturbations has emerged as\na critical concern. In this work, we introduce \\textbf{X-Transfer}, a novel\nattack method that exposes a universal adversarial vulnerability in CLIP.\nX-Transfer generates a Universal Adversarial Perturbation (UAP) capable of\ndeceiving various CLIP encoders and downstream VLMs across different samples,\ntasks, and domains. We refer to this property as \\textbf{super\ntransferability}--a single perturbation achieving cross-data, cross-domain,\ncross-model, and cross-task adversarial transferability simultaneously. This is\nachieved through \\textbf{surrogate scaling}, a key innovation of our approach.\nUnlike existing methods that rely on fixed surrogate models, which are\ncomputationally intensive to scale, X-Transfer employs an efficient surrogate\nscaling strategy that dynamically selects a small subset of suitable surrogates\nfrom a large search space. Extensive evaluations demonstrate that X-Transfer\nsignificantly outperforms previous state-of-the-art UAP methods, establishing a\nnew benchmark for adversarial transferability across CLIP models. The code is\npublicly available in our\n\\href{https://github.com/HanxunH/XTransferBench}{GitHub repository}.",
      "tldr_zh": "该论文提出 X-Transfer，一种新型对抗攻击方法，针对 Contrastive Language-Image Pre-training (CLIP) 模型及其下游 vision-language models (VLMs) 的普遍漏洞。X-Transfer 通过生成 Universal Adversarial Perturbation (UAP) 实现 super transferability，即一个扰动能同时跨数据、域、模型和任务进行转移，这得益于其创新的 surrogate scaling 策略，该策略动态从大搜索空间中选择高效的代理模型子集。实验结果表明，X-Transfer 显著优于现有状态-of-the-art UAP 方法，在 CLIP 模型上建立了新的基准。代码已在 GitHub 上公开可用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.05528v1",
      "published_date": "2025-05-08 11:59:13 UTC",
      "updated_date": "2025-05-08 11:59:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:01:27.105931"
    },
    {
      "arxiv_id": "2505.05145v2",
      "title": "Understanding In-context Learning of Addition via Activation Subspaces",
      "title_zh": "通过激活子空间理解加法的上下文学习",
      "authors": [
        "Xinyan Hu",
        "Kayo Yin",
        "Michael I. Jordan",
        "Jacob Steinhardt",
        "Lijie Chen"
      ],
      "abstract": "To perform in-context learning, language models must extract signals from\nindividual few-shot examples, aggregate these into a learned prediction rule,\nand then apply this rule to new examples. How is this implemented in the\nforward pass of modern transformer models? To study this, we consider a\nstructured family of few-shot learning tasks for which the true prediction rule\nis to add an integer $k$ to the input. We find that Llama-3-8B attains high\naccuracy on this task for a range of $k$, and localize its few-shot ability to\njust three attention heads via a novel optimization approach. We further show\nthe extracted signals lie in a six-dimensional subspace, where four of the\ndimensions track the unit digit and the other two dimensions track overall\nmagnitude. We finally examine how these heads extract information from\nindividual few-shot examples, identifying a self-correction mechanism in which\nmistakes from earlier examples are suppressed by later examples. Our results\ndemonstrate how tracking low-dimensional subspaces across a forward pass can\nprovide insight into fine-grained computational structures.",
      "tldr_zh": "本研究探讨了语言模型在in-context learning中的机制，通过一个结构化的few-shot学习任务，即将整数k加到输入上。研究发现，Llama-3-8B模型在该任务上表现出高准确率，主要依赖于三个注意力头来提取和聚合信号，这些信号位于一个六维子空间，其中四个维度跟踪单位数字，两个维度跟踪整体幅度。此外，模型还存在一个自校正机制，后续示例能抑制先前示例的错误，从而揭示了通过跟踪低维activation subspaces来洞察语言模型细粒度计算结构的潜在方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "20 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.05145v2",
      "published_date": "2025-05-08 11:32:46 UTC",
      "updated_date": "2025-05-15 07:19:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:01:38.609905"
    },
    {
      "arxiv_id": "2505.05138v1",
      "title": "Guiding Evolutionary AutoEncoder Training with Activation-Based Pruning Operators",
      "title_zh": "翻译失败",
      "authors": [
        "Steven Jorgensen",
        "Erik Hemberg",
        "Jamal Toutouh",
        "Una-May O'Reilly"
      ],
      "abstract": "This study explores a novel approach to neural network pruning using\nevolutionary computation, focusing on simultaneously pruning the encoder and\ndecoder of an autoencoder. We introduce two new mutation operators that use\nlayer activations to guide weight pruning. Our findings reveal that one of\nthese activation-informed operators outperforms random pruning, resulting in\nmore efficient autoencoders with comparable performance to canonically trained\nmodels. Prior work has established that autoencoder training is effective and\nscalable with a spatial coevolutionary algorithm that cooperatively coevolves a\npopulation of encoders with a population of decoders, rather than one\nautoencoder. We evaluate how the same activity-guided mutation operators\ntransfer to this context. We find that random pruning is better than guided\npruning, in the coevolutionary setting. This suggests activation-based guidance\nproves more effective in low-dimensional pruning environments, where\nconstrained sample spaces can lead to deviations from true uniformity in\nrandomization. Conversely, population-driven strategies enhance robustness by\nexpanding the total pruning dimensionality, achieving statistically uniform\nrandomness that better preserves system dynamics. We experiment with pruning\naccording to different schedules and present best combinations of operator and\nschedule for the canonical and coevolving populations cases.",
      "tldr_zh": "这篇论文提出了一种使用进化计算指导自编码器（AutoEncoder）训练的新方法，通过引入基于层激活（Activation-Based）的修剪操作符，同时修剪编码器和解码器。研究发现，其中一个激活指导操作符优于随机修剪，能产生更高效的自编码器，其性能与标准训练模型相当。相比之下，在空间协同进化算法（Coevolutionary Algorithm）的环境中，随机修剪表现更好，这表明激活指导更适合低维修剪场景，而人口驱动策略能提升高维修剪的鲁棒性。论文实验了不同修剪时间表，并推荐了最佳操作符组合，以优化自编码器训练。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "Accepted to The Genetic and Evolutionary Computation Conference\n  (GECCO 2025)",
      "pdf_url": "http://arxiv.org/pdf/2505.05138v1",
      "published_date": "2025-05-08 11:21:29 UTC",
      "updated_date": "2025-05-08 11:21:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:01:51.196429"
    },
    {
      "arxiv_id": "2505.07859v1",
      "title": "Boosting Performance on ARC is a Matter of Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Franzen",
        "Jan Disselhoff",
        "David Hartmann"
      ],
      "abstract": "The Abstraction and Reasoning Corpus (ARC-AGI) poses a significant challenge\nfor large language models (LLMs), exposing limitations in their abstract\nreasoning abilities. In this work, we leverage task-specific data augmentations\nthroughout the training, generation, and scoring phases, and employ a\ndepth-first search algorithm to generate diverse, high-probability candidate\nsolutions. Furthermore, we utilize the LLM not only as a generator but also as\na scorer, using its output probabilities to select the most promising\nsolutions. Our method achieves a score of 71.6% (286.5/400 solved tasks) on the\npublic ARC-AGI evaluation set, demonstrating state-of-the-art performance among\npublicly available approaches. While concurrent closed-source work has reported\nhigher scores, our method distinguishes itself through its transparency,\nreproducibility, and remarkably low inference cost, averaging only around 2ct\nper task on readily available hardware (we assume a price of 36ct/hour for a\nNvidia 4090 GPU).",
      "tldr_zh": "本研究针对大型语言模型(LLMs)在抽象推理语料库(ARC-AGI)中的抽象推理能力局限性，引入任务特定数据增强技术，并结合深度优先搜索(depth-first search)算法生成多样候选解决方案，同时利用LLM作为评分器通过输出概率选择最佳方案。该方法在ARC-AGI公共评估集上取得了71.6%的得分（解决286.5/400个任务），实现了公开方法的最新性能水平。与封闭源代码方法相比，该方法强调透明性、可复现性和低成本，仅需平均2ct每任务的推理开销。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages, 5 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.07859v1",
      "published_date": "2025-05-08 11:17:10 UTC",
      "updated_date": "2025-05-08 11:17:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:02:03.297463"
    },
    {
      "arxiv_id": "2505.07858v1",
      "title": "Scaling Laws for Speculative Decoding",
      "title_zh": "推测解码的规模定律",
      "authors": [
        "Siyuan Yan",
        "Mo Zhu",
        "Guo-qing Jiang",
        "Jianfei Wang",
        "Jiaxing Chen",
        "Wentai Zhang",
        "Xiang Liao",
        "Xiao Cui",
        "Chen Zhang",
        "Zhuoran Song",
        "Ran Zhu"
      ],
      "abstract": "The escalating demand for efficient decoding in large language models (LLMs)\nis particularly critical for reasoning-intensive architectures like OpenAI-o3\nand DeepSeek-R1, which depend on extended chain-of-thought reasoning. This\nstudy investigates speculative decoding techniques through dense LLM\narchitectures to establish foundational insights for accelerating reasoning\ntasks. While speculative decoding methods leveraging parallel\ndraft-verification cycles have emerged as promising acceleration techniques,\nthe scaling laws governing decoding efficiency remain under-explored compared\nto conventional backbone LLMs developed through Pretraining->SFT->RLHF training\nparadigms. In this work, we discover Log-linear Scaling Laws (Theorem 1.1, 1.2\nand 1.3) governing draft model acceptance rate (or decoding speed) across three\ndimensions: pretraining token volume, draft model capacity, and decoding batch\nsize. Building on these laws, we achieve Scylla, which coordinates\nmulti-dimensional scaling for popular LLMs (Llama2/3, Qwen2.5). Empirical\nvalidation shows Scylla achieves 1.5-2.2 higher acceptance rate than EAGLE2 and\n0.3 higher than EAGLE3 at temperature T = 0, with peak performance gains on\nsummarization and QA tasks (Figure 2). Industrial inference engine deployments\ndemonstrate 2X decoding throughput improvements over EAGLE2 (Table 5),\nvalidating the transformative potential of systematic scaling for efficient LLM\ninference. Code will be released later.",
      "tldr_zh": "这篇论文探讨了投机解码(speculative decoding)在大型语言模型(LLMs)中的缩放定律，特别是针对推理密集型架构如 OpenAI-o3 和 DeepSeek-R1，以提升解码效率。研究发现了 Log-linear Scaling Laws（定理 1.1、1.2 和 1.3），这些定律描述了预训练 token 量、draft model 容量和解码 batch size 对 draft model acceptance rate（解码速度）的对数线性关系。基于这些定律，作者开发了 Scylla 系统，用于协调多维缩放（如 Llama2/3 和 Qwen2.5），在摘要和 QA 任务上实现了 1.5-2.2 倍的 acceptance rate 提升，比 EAGLE2 高 2 倍的解码吞吐量。实验结果验证了系统性缩放在 LLM 推理加速中的潜力，为高效模型部署提供了基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.07858v1",
      "published_date": "2025-05-08 11:10:15 UTC",
      "updated_date": "2025-05-08 11:10:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:02:15.901311"
    },
    {
      "arxiv_id": "2505.05115v1",
      "title": "Is there a half-life for the success rates of AI agents?",
      "title_zh": "AI 代理的成功率是否存在半衰期",
      "authors": [
        "Toby Ord"
      ],
      "abstract": "Building on the recent empirical work of Kwa et al. (2025), I show that\nwithin their suite of research-engineering tasks the performance of AI agents\non longer-duration tasks can be explained by an extremely simple mathematical\nmodel -- a constant rate of failing during each minute a human would take to do\nthe task. This implies an exponentially declining success rate with the length\nof the task and that each agent could be characterised by its own half-life.\nThis empirical regularity allows us to estimate the success rate for an agent\nat different task lengths. And the fact that this model is a good fit for the\ndata is suggestive of the underlying causes of failure on longer tasks -- that\nthey involve increasingly large sets of subtasks where failing any one fails\nthe task. Whether this model applies more generally on other suites of tasks is\nunknown and an important subject for further work.",
      "tldr_zh": "本研究基于Kwa et al. (2025)的实证工作，提出一个简单数学模型来解释AI agents在研究工程任务上的表现，即AI代理以恒定失败率随时间下降，导致任务长度增加时成功率指数衰减，并引入“half-life”概念来表征每个代理的性能。实验结果显示，该模型能准确拟合数据，允许预测不同任务长度的成功率，并暗示失败原因可能源于任务中任何子任务的失败。该发现为理解AI agents在长任务中的局限性提供了新视角，但需进一步验证其在其他任务套件中的适用性。",
      "categories": [
        "cs.AI",
        "68T42",
        "I.2.8"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.05115v1",
      "published_date": "2025-05-08 10:31:03 UTC",
      "updated_date": "2025-05-08 10:31:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:02:27.136074"
    },
    {
      "arxiv_id": "2505.05527v1",
      "title": "ADMM-Based Training for Spiking Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Giovanni Perin",
        "Cesare Bidini",
        "Riccardo Mazzieri",
        "Michele Rossi"
      ],
      "abstract": "In recent years, spiking neural networks (SNNs) have gained momentum due to\ntheir high potential in time-series processing combined with minimal energy\nconsumption. However, they still lack a dedicated and efficient training\nalgorithm. The popular backpropagation with surrogate gradients, adapted from\nstochastic gradient descent (SGD)-derived algorithms, has several drawbacks\nwhen used as an optimizer for SNNs. Specifically, it suffers from low\nscalability and numerical imprecision. In this paper, we propose a novel SNN\ntraining method based on the alternating direction method of multipliers\n(ADMM). Our ADMM-based training aims to solve the problem of the SNN step\nfunction's non-differentiability. We formulate the problem, derive closed-form\nupdates, and empirically show the optimizer's convergence properties, great\npotential, and possible new research directions to improve the method in a\nsimulated proof-of-concept.",
      "tldr_zh": "本研究针对脉冲神经网络(SNNs)的训练问题，指出传统基于后向传播和随机梯度下降(SGD)的方法存在可扩展性低和数值不精确的缺点。作者提出了一种基于交替方向乘子法(ADMM)的训练方法，通过制定SNN阶跃函数的非微分性问题并推导闭式更新，来实现高效优化。实验证明，该方法在模拟环境中显示出良好的收敛性能和潜力，并为改进SNN训练算法开辟了新研究方向。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE",
        "eess.SP",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "6 pages, 4 figures. Preprint submitted to IEEE MLSP 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.05527v1",
      "published_date": "2025-05-08 10:20:33 UTC",
      "updated_date": "2025-05-08 10:20:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:02:39.475125"
    },
    {
      "arxiv_id": "2505.05108v1",
      "title": "Multi-agent Embodied AI: Advances and Future Directions",
      "title_zh": "多智能体具身AI：进展与未来方向",
      "authors": [
        "Zhaohan Feng",
        "Ruiqi Xue",
        "Lei Yuan",
        "Yang Yu",
        "Ning Ding",
        "Meiqin Liu",
        "Bingzhao Gao",
        "Jian Sun",
        "Gang Wang"
      ],
      "abstract": "Embodied artificial intelligence (Embodied AI) plays a pivotal role in the\napplication of advanced technologies in the intelligent era, where AI systems\nare integrated with physical bodies that enable them to perceive, reason, and\ninteract with their environments. Through the use of sensors for input and\nactuators for action, these systems can learn and adapt based on real-world\nfeedback, allowing them to perform tasks effectively in dynamic and\nunpredictable environments. As techniques such as deep learning (DL),\nreinforcement learning (RL), and large language models (LLMs) mature, embodied\nAI has become a leading field in both academia and industry, with applications\nspanning robotics, healthcare, transportation, and manufacturing. However, most\nresearch has focused on single-agent systems that often assume static, closed\nenvironments, whereas real-world embodied AI must navigate far more complex\nscenarios. In such settings, agents must not only interact with their\nsurroundings but also collaborate with other agents, necessitating\nsophisticated mechanisms for adaptation, real-time learning, and collaborative\nproblem-solving. Despite increasing interest in multi-agent systems, existing\nresearch remains narrow in scope, often relying on simplified models that fail\nto capture the full complexity of dynamic, open environments for multi-agent\nembodied AI. Moreover, no comprehensive survey has systematically reviewed the\nadvancements in this area. As embodied AI rapidly evolves, it is crucial to\ndeepen our understanding of multi-agent embodied AI to address the challenges\npresented by real-world applications. To fill this gap and foster further\ndevelopment in the field, this paper reviews the current state of research,\nanalyzes key contributions, and identifies challenges and future directions,\nproviding insights to guide innovation and progress in this field.",
      "tldr_zh": "这篇论文回顾了多智能体具身人工智能（Multi-agent Embodied AI）的进展和未来方向，强调了具身 AI 在现实世界中的重要性，包括通过传感器和执行器实现感知、推理和互动的应用。论文指出，现有的研究主要聚焦单智能体系统，并忽略了动态、开放环境下的多智能体协作挑战，如实时学习和适应性问题，从而填补了这一领域的系统性调查空白。通过分析关键贡献、识别挑战（如深度学习（DL）、强化学习（RL）和大型语言模型（LLMs）的整合），论文为未来创新提供了指导，帮助推动具身 AI 在机器人、医疗等领域的发展。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05108v1",
      "published_date": "2025-05-08 10:13:53 UTC",
      "updated_date": "2025-05-08 10:13:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:02:50.671220"
    },
    {
      "arxiv_id": "2505.05106v1",
      "title": "A Neuro-Symbolic Framework for Sequence Classification with Relational and Temporal Knowledge",
      "title_zh": "翻译失败",
      "authors": [
        "Luca Salvatore Lorello",
        "Marco Lippi",
        "Stefano Melacci"
      ],
      "abstract": "One of the goals of neuro-symbolic artificial intelligence is to exploit\nbackground knowledge to improve the performance of learning tasks. However,\nmost of the existing frameworks focus on the simplified scenario where\nknowledge does not change over time and does not cover the temporal dimension.\nIn this work we consider the much more challenging problem of knowledge-driven\nsequence classification where different portions of knowledge must be employed\nat different timesteps, and temporal relations are available. Our experimental\nevaluation compares multi-stage neuro-symbolic and neural-only architectures,\nand it is conducted on a newly-introduced benchmarking framework. Results\ndemonstrate the challenging nature of this novel setting, and also highlight\nunder-explored shortcomings of neuro-symbolic methods, representing a precious\nreference for future research.",
      "tldr_zh": "该研究提出了一种神经符号(Neuro-Symbolic)框架，用于处理序列分类(Sequence Classification)问题，该框架利用关系和时间知识(Temporal Knowledge)来提升学习任务性能，尤其针对知识随时间变化的复杂场景。不同于现有框架，该方法在不同时间步动态应用相关知识，并整合时间关系进行分类。实验通过比较多阶段神经符号架构与纯神经(Neural-only)架构，在一个新引入的基准框架上进行，结果揭示了这一设置的挑战性，并暴露了神经符号方法的潜在缺点，为未来研究提供宝贵参考。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05106v1",
      "published_date": "2025-05-08 10:10:00 UTC",
      "updated_date": "2025-05-08 10:10:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:03:02.296273"
    },
    {
      "arxiv_id": "2505.05086v1",
      "title": "Beyond Low-rank Decomposition: A Shortcut Approach for Efficient On-Device Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Le-Trung Nguyen",
        "Ael Quelennec",
        "Van-Tam Nguyen",
        "Enzo Tartaglione"
      ],
      "abstract": "On-device learning has emerged as a promising direction for AI development,\nparticularly because of its potential to reduce latency issues and mitigate\nprivacy risks associated with device-server communication, while improving\nenergy efficiency. Despite these advantages, significant memory and\ncomputational constraints still represent major challenges for its deployment.\nDrawing on previous studies on low-rank decomposition methods that address\nactivation memory bottlenecks in backpropagation, we propose a novel shortcut\napproach as an alternative. Our analysis and experiments demonstrate that our\nmethod can reduce activation memory usage, even up to $120.09\\times$ compared\nto vanilla training, while also reducing overall training FLOPs up to\n$1.86\\times$ when evaluated on traditional benchmarks.",
      "tldr_zh": "该论文探讨了On-device learning的优势，包括降低延迟、缓解隐私风险并提升能源效率，但强调了其面临的内存和计算约束问题。为解决这些挑战，作者提出了一种新型捷径方法(shortcut approach)，作为低-rank decomposition的替代方案，针对激活内存瓶颈进行优化。实验结果显示，该方法在传统基准上将激活内存使用减少高达120.09倍，并将整体训练FLOPs减少高达1.86倍，从而显著提升了On-device learning的效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05086v1",
      "published_date": "2025-05-08 09:34:15 UTC",
      "updated_date": "2025-05-08 09:34:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:03:14.564893"
    },
    {
      "arxiv_id": "2505.05071v3",
      "title": "FG-CLIP: Fine-Grained Visual and Textual Alignment",
      "title_zh": "FG-CLIP：细粒度视觉和文本对齐",
      "authors": [
        "Chunyu Xie",
        "Bin Wang",
        "Fanjing Kong",
        "Jincheng Li",
        "Dawei Liang",
        "Gengshen Zhang",
        "Dawei Leng",
        "Yuhui Yin"
      ],
      "abstract": "Contrastive Language-Image Pre-training (CLIP) excels in multimodal tasks\nsuch as image-text retrieval and zero-shot classification but struggles with\nfine-grained understanding due to its focus on coarse-grained short captions.\nTo address this, we propose Fine-Grained CLIP (FG-CLIP), which enhances\nfine-grained understanding through three key innovations. First, we leverage\nlarge multimodal models to generate 1.6 billion long caption-image pairs for\ncapturing global-level semantic details. Second, a high-quality dataset is\nconstructed with 12 million images and 40 million region-specific bounding\nboxes aligned with detailed captions to ensure precise, context-rich\nrepresentations. Third, 10 million hard fine-grained negative samples are\nincorporated to improve the model's ability to distinguish subtle semantic\ndifferences. We construct a comprehensive dataset, termed FineHARD, by\nintegrating high-quality region-specific annotations with hard fine-grained\nnegative samples. Corresponding training methods are meticulously designed for\nthese data. Extensive experiments demonstrate that FG-CLIP outperforms the\noriginal CLIP and other state-of-the-art methods across various downstream\ntasks, including fine-grained understanding, open-vocabulary object detection,\nimage-text retrieval, and general multimodal benchmarks. These results\nhighlight FG-CLIP's effectiveness in capturing fine-grained image details and\nimproving overall model performance. The data, code, and models are available\nat https://github.com/360CVGroup/FG-CLIP.",
      "tldr_zh": "这篇论文提出 FG-CLIP，一种改进 Contrastive Language-Image Pre-training (CLIP) 的框架，旨在提升细粒度视觉和文本对齐能力，以解决 CLIP 在处理粗粒度标题时的局限性。关键创新包括利用大型多模态模型生成 16 亿长标题-图像对、构建包含 1200 万图像和 4 千万区域特定边界框的高质量数据集，以及整合 1 千万硬细粒度负样本来增强模型对微妙语义差异的区分。论文构建了 FineHARD 数据集并设计相应训练方法，实验结果显示 FG-CLIP 在细粒度理解、开放词汇对象检测、图像-文本检索和多模态基准任务上均优于原 CLIP 和其他 SOTA 方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.05071v3",
      "published_date": "2025-05-08 09:06:53 UTC",
      "updated_date": "2025-05-21 06:18:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:03:28.607727"
    },
    {
      "arxiv_id": "2505.05059v1",
      "title": "Enhancing Reinforcement Learning for the Floorplanning of Analog ICs with Beam Search",
      "title_zh": "翻译失败",
      "authors": [
        "Sandro Junior Della Rovere",
        "Davide Basso",
        "Luca Bortolussi",
        "Mirjana Videnovic-Misic",
        "Husni Habal"
      ],
      "abstract": "The layout of analog ICs requires making complex trade-offs, while addressing\ndevice physics and variability of the circuits. This makes full automation with\nlearning-based solutions hard to achieve. However, reinforcement learning (RL)\nhas recently reached significant results, particularly in solving the\nfloorplanning problem. This paper presents a hybrid method that combines RL\nwith a beam (BS) strategy. The BS algorithm enhances the agent's inference\nprocess, allowing for the generation of flexible floorplans by accomodating\nvarious objective weightings, and addressing congestion without without the\nneed for policy retraining or fine-tuning. Moreover, the RL agent's\ngeneralization ability stays intact, along with its efficient handling of\ncircuit features and constraints. Experimental results show approx. 5-85%\nimprovement in area, dead space and half-perimeter wire length compared to a\nstandard RL application, along with higher rewards for the agent. Moreover,\nperformance and efficiency align closely with those of existing\nstate-of-the-art techniques.",
      "tldr_zh": "本研究针对模拟集成电路（analog ICs）的楼层规划（floorplanning）问题，提出了一种将强化学习（RL）与Beam Search (BS)策略相结合的混合方法，以应对设备物理和电路变异性的复杂权衡。BS算法增强了RL代理的推理过程，实现灵活的楼层规划生成，能够适应不同目标权重并处理拥塞问题，而无需重新训练或微调策略，同时保持RL的泛化能力和高效处理电路特征。实验结果显示，与标准RL相比，该方法在面积、死空间和半周长线长方面改善约5-85%，代理奖励更高，且性能与现有最先进技术相当。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Published in Proceedings of the 21st International Conference on\n  Synthesis, Modeling, Analysis and Simulation Methods, and Applications to\n  Circuit Design (SMACD 2025). 4 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.05059v1",
      "published_date": "2025-05-08 08:50:32 UTC",
      "updated_date": "2025-05-08 08:50:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:03:38.956278"
    },
    {
      "arxiv_id": "2505.05056v1",
      "title": "Teochew-Wild: The First In-the-wild Teochew Dataset with Orthographic Annotations",
      "title_zh": "翻译失败",
      "authors": [
        "Linrong Pan",
        "Chenglong Jiang",
        "Gaoze Hou",
        "Ying Gao"
      ],
      "abstract": "This paper reports the construction of the Teochew-Wild, a speech corpus of\nthe Teochew dialect. The corpus includes 18.9 hours of in-the-wild Teochew\nspeech data from multiple speakers, covering both formal and colloquial\nexpressions, with precise orthographic and pinyin annotations. Additionally, we\nprovide supplementary text processing tools and resources to propel research\nand applications in speech tasks for this low-resource language, such as\nautomatic speech recognition (ASR) and text-to-speech (TTS). To the best of our\nknowledge, this is the first publicly available Teochew dataset with accurate\northographic annotations. We conduct experiments on the corpus, and the results\nvalidate its effectiveness in ASR and TTS tasks.",
      "tldr_zh": "这篇论文介绍了 Teochew-Wild，这是第一个野外（in-the-wild）潮州方言数据集，包含18.9小时的多说话者语音数据，涵盖正式和口语表达，并附带精确的 orthographic annotations 和拼音标注。研究者还提供了补充的文本处理工具和资源，以支持低资源语言的语音任务研究，如 automatic speech recognition (ASR) 和 text-to-speech (TTS)。实验结果证明，该数据集在 ASR 和 TTS 任务中表现出色，验证了其有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05056v1",
      "published_date": "2025-05-08 08:47:11 UTC",
      "updated_date": "2025-05-08 08:47:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:03:51.421915"
    },
    {
      "arxiv_id": "2505.05054v1",
      "title": "Direct Image Classification from Fourier Ptychographic Microscopy Measurements without Reconstruction",
      "title_zh": "翻译失败",
      "authors": [
        "Navya Sonal Agarwal",
        "Jan Philipp Schneider",
        "Kanchana Vaishnavi Gandikota",
        "Syed Muhammad Kazim",
        "John Meshreki",
        "Ivo Ihrke",
        "Michael Moeller"
      ],
      "abstract": "The computational imaging technique of Fourier Ptychographic Microscopy (FPM)\nenables high-resolution imaging with a wide field of view and can serve as an\nextremely valuable tool, e.g. in the classification of cells in medical\napplications. However, reconstructing a high-resolution image from tens or even\nhundreds of measurements is computationally expensive, particularly for a wide\nfield of view. Therefore, in this paper, we investigate the idea of classifying\nthe image content in the FPM measurements directly without performing a\nreconstruction step first. We show that Convolutional Neural Networks (CNN) can\nextract meaningful information from measurement sequences, significantly\noutperforming the classification on a single band-limited image (up to 12 %)\nwhile being significantly more efficient than a reconstruction of a\nhigh-resolution image. Furthermore, we demonstrate that a learned multiplexing\nof several raw measurements allows maintaining the classification accuracy\nwhile reducing the amount of data (and consequently also the acquisition time)\nsignificantly.",
      "tldr_zh": "本文提出一种直接从 Fourier Ptychographic Microscopy (FPM) 测量数据中进行图像分类的方法，绕过了重建高分辨率图像的耗时步骤。利用 Convolutional Neural Networks (CNN) 处理测量序列，能从这些数据中提取有意义的信息，使分类准确率比单一带限图像高出高达 12%，同时显著提升计算效率。此外，通过学习的多路复用技术，保持分类性能的同时，大幅减少数据量和采集时间，为医疗应用如细胞分类提供了更高效的工具。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "ISCS 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.05054v1",
      "published_date": "2025-05-08 08:46:28 UTC",
      "updated_date": "2025-05-08 08:46:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:04:03.852438"
    },
    {
      "arxiv_id": "2505.07857v1",
      "title": "Enhanced Urdu Intent Detection with Large Language Models and Prototype-Informed Predictive Pipelines",
      "title_zh": "翻译失败",
      "authors": [
        "Faiza Hassan",
        "Summra Saleem",
        "Kashif Javed",
        "Muhammad Nabeel Asim",
        "Abdur Rehman",
        "Andreas Dengel"
      ],
      "abstract": "Multifarious intent detection predictors are developed for different\nlanguages, including English, Chinese and French, however, the field remains\nunderdeveloped for Urdu, the 10th most spoken language. In the realm of\nwell-known languages, intent detection predictors utilize the strategy of\nfew-shot learning and prediction of unseen classes based on the model training\non seen classes. However, Urdu language lacks few-shot strategy based intent\ndetection predictors and traditional predictors are focused on prediction of\nthe same classes which models have seen in the train set. To empower Urdu\nlanguage specific intent detection, this introduces a unique contrastive\nlearning approach that leverages unlabeled Urdu data to re-train pre-trained\nlanguage models. This re-training empowers LLMs representation learning for the\ndownstream intent detection task. Finally, it reaps the combined potential of\npre-trained LLMs and the prototype-informed attention mechanism to create a\ncomprehensive end-to-end LLMPIA intent detection pipeline. Under the paradigm\nof proposed predictive pipeline, it explores the potential of 6 distinct\nlanguage models and 13 distinct similarity computation methods. The proposed\nframework is evaluated on 2 public benchmark datasets, namely ATIS encompassing\n5836 samples and Web Queries having 8519 samples. Across ATIS dataset under\n4-way 1 shot and 4-way 5 shot experimental settings LLMPIA achieved 83.28% and\n98.25% F1-Score and on Web Queries dataset produced 76.23% and 84.42% F1-Score,\nrespectively. In an additional case study on the Web Queries dataset under same\nclasses train and test set settings, LLMPIA outperformed state-of-the-art\npredictor by 53.55% F1-Score.",
      "tldr_zh": "这篇论文针对Urdu语言的意图检测（intent detection）问题，提出了一种新框架LLMPIA，通过contrastive learning方法利用无标签Urdu数据重新训练Large Language Models（LLMs），以增强下游任务的表示学习，并结合prototype-informed attention mechanism构建端到端的预测管道。研究探索了6个不同语言模型和13种相似性计算方法，在ATIS数据集上（4-way 1-shot和4-way 5-shot设置）分别达到83.28%和98.25%的F1-Score，在Web Queries数据集上达到76.23%和84.42%的F1-Score。相比现有方法，LLMPIA在Web Queries数据集的相同类设置下提升了53.55%的F1-Score，为Urdu语言的few-shot learning和未见类别预测提供了显著改进。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "42 pages, 10 figures(including 6 graphs)",
      "pdf_url": "http://arxiv.org/pdf/2505.07857v1",
      "published_date": "2025-05-08 08:38:40 UTC",
      "updated_date": "2025-05-08 08:38:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:04:18.810970"
    },
    {
      "arxiv_id": "2505.05040v1",
      "title": "Image-Text Relation Prediction for Multilingual Tweets",
      "title_zh": "多语言推文的图像-文本关系预测",
      "authors": [
        "Matīss Rikters",
        "Edison Marrese-Taylor"
      ],
      "abstract": "Various social networks have been allowing media uploads for over a decade\nnow. Still, it has not always been clear what is their relation with the posted\ntext or even if there is any at all. In this work, we explore how multilingual\nvision-language models tackle the task of image-text relation prediction in\ndifferent languages, and construct a dedicated balanced benchmark data set from\nTwitter posts in Latvian along with their manual translations into English. We\ncompare our results to previous work and show that the more recently released\nvision-language model checkpoints are becoming increasingly capable at this\ntask, but there is still much room for further improvement.",
      "tldr_zh": "这篇论文探讨了使用多语言视觉语言模型（multilingual vision-language models）预测多语言 Twitter 帖子中图像和文本的关系，旨在解决社交媒体上传媒体与文本关联不明确的问题。作者构建了一个平衡的基准数据集（balanced benchmark dataset），基于拉脱维亚语 Twitter 帖子及其手动翻译成英文，并与之前工作进行比较。结果显示，新发布的视觉语言模型检查点（vision-language model checkpoints）在这一任务上表现出色，准确率有所提升，但仍有较大改进潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05040v1",
      "published_date": "2025-05-08 08:23:20 UTC",
      "updated_date": "2025-05-08 08:23:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:04:27.153802"
    },
    {
      "arxiv_id": "2505.05029v2",
      "title": "Beyond the Tragedy of the Commons: Building A Reputation System for Generative Multi-agent Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Siyue Ren",
        "Wanli Fu",
        "Xinkun Zou",
        "Chen Shen",
        "Yi Cai",
        "Chen Chu",
        "Zhen Wang",
        "Shuyue Hu"
      ],
      "abstract": "The tragedy of the commons, where individual self-interest leads to\ncollectively disastrous outcomes, is a pervasive challenge in human society.\nRecent studies have demonstrated that similar phenomena can arise in generative\nmulti-agent systems (MASs). To address this challenge, this paper explores the\nuse of reputation systems as a remedy. We propose RepuNet, a dynamic,\ndual-level reputation framework that models both agent-level reputation\ndynamics and system-level network evolution. Specifically, driven by direct\ninteractions and indirect gossip, agents form reputations for both themselves\nand their peers, and decide whether to connect or disconnect other agents for\nfuture interactions. Through two distinct scenarios, we show that RepuNet\neffectively mitigates the 'tragedy of the commons', promoting and sustaining\ncooperation in generative MASs. Moreover, we find that reputation systems can\ngive rise to rich emergent behaviors in generative MASs, such as the formation\nof cooperative clusters, the social isolation of exploitative agents, and the\npreference for sharing positive gossip rather than negative ones.",
      "tldr_zh": "这篇论文探讨了“tragedy of the commons”在生成式多智能体系统（MASs）中的挑战，即个体自利导致集体灾难，并提出 RepuNet 框架作为解决方案。RepuNet 是一个动态的双层声誉系统，包括代理级声誉动态和系统级网络演化，代理通过直接互动和间接 gossip 形成声誉并决定是否与其他代理连接。实验结果显示，RepuNet 能有效缓解公地悲剧，促进合作，并引发丰富的紧急行为，如合作集群的形成、剥削性代理的社会隔离，以及对分享正面 gossip 的偏好。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05029v2",
      "published_date": "2025-05-08 08:02:20 UTC",
      "updated_date": "2025-05-12 07:23:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:04:41.274213"
    },
    {
      "arxiv_id": "2505.07856v1",
      "title": "Unpacking Robustness in Inflectional Languages: Adversarial Evaluation and Mechanistic Insights",
      "title_zh": "翻译失败",
      "authors": [
        "Paweł Walkowiak",
        "Marek Klonowski",
        "Marcin Oleksy",
        "Arkadiusz Janz"
      ],
      "abstract": "Various techniques are used in the generation of adversarial examples,\nincluding methods such as TextBugger which introduce minor, hardly visible\nperturbations to words leading to changes in model behaviour. Another class of\ntechniques involves substituting words with their synonyms in a way that\npreserves the text's meaning but alters its predicted class, with TextFooler\nbeing a prominent example of such attacks. Most adversarial example generation\nmethods are developed and evaluated primarily on non-inflectional languages,\ntypically English. In this work, we evaluate and explain how adversarial\nattacks perform in inflectional languages. To explain the impact of inflection\non model behaviour and its robustness under attack, we designed a novel\nprotocol inspired by mechanistic interpretability, based on Edge Attribution\nPatching (EAP) method. The proposed evaluation protocol relies on parallel\ntask-specific corpora that include both inflected and syncretic variants of\ntexts in two languages -- Polish and English. To analyse the models and explain\nthe relationship between inflection and adversarial robustness, we create a new\nbenchmark based on task-oriented dataset MultiEmo, enabling the identification\nof mechanistic inflection-related elements of circuits within the model and\nanalyse their behaviour under attack.",
      "tldr_zh": "本文评估了对抗攻击（如 TextBugger 和 TextFooler）在屈折语言（如波兰语）中的性能，解释了屈折如何影响模型行为和鲁棒性。研究设计了一个基于 Edge Attribution Patching (EAP) 的新协议，受启发于 Mechanistic interpretability，利用平行任务特定语料库，包括屈折和同形变体的文本。基于 MultiEmo 数据集，他们创建了一个新基准，用于识别模型中与屈折相关的机制元素，并分析这些元素在攻击下的行为。结果显示，屈折语言的独特特性暴露了模型的弱点，为提升对抗鲁棒性提供了关键见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07856v1",
      "published_date": "2025-05-08 08:00:03 UTC",
      "updated_date": "2025-05-08 08:00:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:04:52.942539"
    },
    {
      "arxiv_id": "2505.05019v1",
      "title": "Generating Reliable Synthetic Clinical Trial Data: The Role of Hyperparameter Optimization and Domain Constraints",
      "title_zh": "生成可靠的合成临床试验数据：超参数优化和领域约束的作用",
      "authors": [
        "Waldemar Hahn",
        "Jan-Niklas Eckardt",
        "Christoph Röllig",
        "Martin Sedlmayr",
        "Jan Moritz Middeke",
        "Markus Wolfien"
      ],
      "abstract": "The generation of synthetic clinical trial data offers a promising approach\nto mitigating privacy concerns and data accessibility limitations in medical\nresearch. However, ensuring that synthetic datasets maintain high fidelity,\nutility, and adherence to domain-specific constraints remains a key challenge.\nWhile hyperparameter optimization (HPO) has been shown to improve generative\nmodel performance, the effectiveness of different optimization strategies for\nsynthetic clinical data remains unclear. This study systematically evaluates\nfour HPO strategies across eight generative models, comparing single-metric\noptimization against compound metric optimization approaches. Our results\ndemonstrate that HPO consistently improves synthetic data quality, with TVAE,\nCTGAN, and CTAB-GAN+ achieving improvements of up to 60%, 39%, and 38%,\nrespectively. Compound metric optimization outperformed single-metric\nstrategies, producing more balanced and generalizable synthetic datasets.\nInterestingly, HPO alone is insufficient to ensure clinically valid synthetic\ndata, as all models exhibited violations of fundamental survival constraints.\nPreprocessing and postprocessing played a crucial role in reducing these\nviolations, as models lacking robust processing steps produced invalid data in\nup to 61% of cases. These findings underscore the necessity of integrating\nexplicit domain knowledge alongside HPO to create high quality synthetic\ndatasets. Our study provides actionable recommendations for improving synthetic\ndata generation, with future research needed to refine metric selection and\nvalidate these findings on larger datasets to enhance clinical applicability.",
      "tldr_zh": "本研究评估了超参数优化(HPO)策略在生成可靠合成临床试验数据中的作用，通过比较四种HPO方法在八种生成模型上的表现，突显了复合指标优化优于单指标优化，可使TVAE、CTGAN和CTAB-GAN+的合成数据质量分别提升最多60%、39%和38%。尽管HPO显著提高了数据保真度和实用性，但所有模型均违反了基本的生存约束，导致高达61%的无效数据。研究强调，单纯依赖HPO不足以确保临床有效性，必须整合预处理、后处理和显式领域知识来创建高质量合成数据集。该工作提供了可操作的改进建议，并呼吁未来在更大数据集上优化指标选择以提升临床适用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05019v1",
      "published_date": "2025-05-08 07:51:36 UTC",
      "updated_date": "2025-05-08 07:51:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:05:05.120658"
    },
    {
      "arxiv_id": "2505.06307v1",
      "title": "Large Language Model-driven Security Assistant for Internet of Things via Chain-of-Thought",
      "title_zh": "通过链式思维的大语言模型驱动的物联网安全助手",
      "authors": [
        "Mingfei Zeng",
        "Ming Xie",
        "Xixi Zheng",
        "Chunhai Li",
        "Chuan Zhang",
        "Liehuang Zhu"
      ],
      "abstract": "The rapid development of Internet of Things (IoT) technology has transformed\npeople's way of life and has a profound impact on both production and daily\nactivities. However, with the rapid advancement of IoT technology, the security\nof IoT devices has become an unavoidable issue in both research and\napplications. Although some efforts have been made to detect or mitigate IoT\nsecurity vulnerabilities, they often struggle to adapt to the complexity of IoT\nenvironments, especially when dealing with dynamic security scenarios. How to\nautomatically, efficiently, and accurately understand these vulnerabilities\nremains a challenge. To address this, we propose an IoT security assistant\ndriven by Large Language Model (LLM), which enhances the LLM's understanding of\nIoT security vulnerabilities and related threats. The aim of the ICoT method we\npropose is to enable the LLM to understand security issues by breaking down the\nvarious dimensions of security vulnerabilities and generating responses\ntailored to the user's specific needs and expertise level. By incorporating\nICoT, LLM can gradually analyze and reason through complex security scenarios,\nresulting in more accurate, in-depth, and personalized security recommendations\nand solutions. Experimental results show that, compared to methods relying\nsolely on LLM, our proposed LLM-driven IoT security assistant significantly\nimproves the understanding of IoT security issues through the ICoT approach and\nprovides personalized solutions based on the user's identity, demonstrating\nhigher accuracy and reliability.",
      "tldr_zh": "本文提出了一种基于 Large Language Model (LLM) 驱动的 IoT 安全助手，名为 ICoT，利用 Chain-of-Thought 推理来解决 IoT 设备安全漏洞的检测和缓解挑战。ICoT 通过分解安全漏洞的各个维度，帮助 LLM 逐步分析复杂动态场景，并根据用户需求和专业水平生成个性化的安全推荐和解决方案。与单纯依赖 LLM 的方法相比，实验结果显示 ICoT 显著提升了准确性和可靠性，为 IoT 安全管理提供了更高效的自动化工具。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06307v1",
      "published_date": "2025-05-08 07:47:24 UTC",
      "updated_date": "2025-05-08 07:47:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:05:15.437143"
    },
    {
      "arxiv_id": "2505.05523v1",
      "title": "GenAI in Entrepreneurship: a systematic review of generative artificial intelligence in entrepreneurship research: current issues and future directions",
      "title_zh": "翻译失败",
      "authors": [
        "Anna Kusetogullari",
        "Huseyin Kusetogullari",
        "Martin Andersson",
        "Tony Gorschek"
      ],
      "abstract": "Generative Artificial Intelligence (GenAI) and Large Language Models (LLMs)\nare recognized to have significant effects on industry and business dynamics,\nnot least because of their impact on the preconditions for entrepreneurship.\nThere is still a lack of knowledge of GenAI as a theme in entrepreneurship\nresearch. This paper presents a systematic literature review aimed at\nidentifying and analyzing the evolving landscape of research on the effects of\nGenAI on entrepreneurship. We analyze 83 peer-reviewed articles obtained from\nleading academic databases: Web of Science and Scopus. Using natural language\nprocessing and unsupervised machine learning techniques with TF-IDF\nvectorization, Principal Component Analysis (PCA), and hierarchical clustering,\nfive major thematic clusters are identified: (1) Digital Transformation and\nBehavioral Models, (2) GenAI-Enhanced Education and Learning Systems, (3)\nSustainable Innovation and Strategic AI Impact, (4) Business Models and Market\nTrends, and (5) Data-Driven Technological Trends in Entrepreneurship. Based on\nthe review, we discuss future research directions, gaps in the current\nliterature, as well as ethical concerns raised in the literature. We highlight\nthe need for more macro-level research on GenAI and LLMs as external enablers\nfor entrepreneurship and for research on effective regulatory frameworks that\nfacilitate business experimentation, innovation, and further technology\ndevelopment.",
      "tldr_zh": "这篇论文通过系统文献综述，分析了Generative Artificial Intelligence (GenAI)和Large Language Models (LLMs)对创业的影响，共审阅了83篇来自Web of Science和Scopus的同行评议文章。研究采用自然语言处理和无监督机器学习技术，包括TF-IDF vectorization、Principal Component Analysis (PCA)和hierarchical clustering，识别了五个主要主题集群：(1) Digital Transformation and Behavioral Models，(2) GenAI-Enhanced Education and Learning Systems，(3) Sustainable Innovation and Strategic AI Impact，(4) Business Models and Market Trends，以及(5) Data-Driven Technological Trends in Entrepreneurship。论文讨论了当前文献的空白、伦理问题，并建议未来研究应加强宏观层面探讨GenAI作为创业外部促进因素，以及开发有效的监管框架以支持创新和技术发展。",
      "categories": [
        "econ.GN",
        "cs.AI",
        "q-fin.EC"
      ],
      "primary_category": "econ.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05523v1",
      "published_date": "2025-05-08 07:44:42 UTC",
      "updated_date": "2025-05-08 07:44:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:05:29.417260"
    },
    {
      "arxiv_id": "2505.05015v1",
      "title": "An Agent-Based Modeling Approach to Free-Text Keyboard Dynamics for Continuous Authentication",
      "title_zh": "翻译失败",
      "authors": [
        "Roberto Dillon",
        "Arushi"
      ],
      "abstract": "Continuous authentication systems leveraging free-text keyboard dynamics\noffer a promising additional layer of security in a multifactor authentication\nsetup that can be used in a transparent way with no impact on user experience.\nThis study investigates the efficacy of behavioral biometrics by employing an\nAgent-Based Model (ABM) to simulate diverse typing profiles across mechanical\nand membrane keyboards. Specifically, we generated synthetic keystroke data\nfrom five unique agents, capturing features related to dwell time, flight time,\nand error rates within sliding 5-second windows updated every second. Two\nmachine learning approaches, One-Class Support Vector Machine (OC-SVM) and\nRandom Forest (RF), were evaluated for user verification. Results revealed a\nstark contrast in performance: while One-Class SVM failed to differentiate\nindividual users within each group, Random Forest achieved robust\nintra-keyboard user recognition (Accuracy > 0.7) but struggled to generalize\nacross keyboards for the same user, highlighting the significant impact of\nkeyboard hardware on typing behavior. These findings suggest that: (1)\nkeyboard-specific user profiles may be necessary for reliable authentication,\nand (2) ensemble methods like RF outperform One-Class SVM in capturing\nfine-grained user-specific patterns.",
      "tldr_zh": "本研究提出了一种基于 Agent-Based Model (ABM) 的方法，用于模拟自由文本键盘动态，以实现无干扰的连续认证系统。\n研究生成合成键盘数据，包括停留时间、飞行时间和错误率，模拟五种独特代理人在机械和薄膜键盘上的行为，并使用 One-Class Support Vector Machine (OC-SVM) 和 Random Forest (RF) 进行用户验证。\n结果显示，RF 在同一键盘上实现了高准确率（>0.7），但跨键盘泛化能力较差，这突显了键盘硬件对行为的影响，并建议采用键盘特定的用户配置文件，同时证明 RF 优于 OC-SVM 在捕捉细粒度用户模式方面。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "68T10, 62H30",
        "I.2.6; I.5.4; I.6.3"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 5 figures, 12 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.05015v1",
      "published_date": "2025-05-08 07:42:05 UTC",
      "updated_date": "2025-05-08 07:42:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:05:39.900402"
    },
    {
      "arxiv_id": "2505.05001v1",
      "title": "StabStitch++: Unsupervised Online Video Stitching with Spatiotemporal Bidirectional Warps",
      "title_zh": "翻译失败",
      "authors": [
        "Lang Nie",
        "Chunyu Lin",
        "Kang Liao",
        "Yun Zhang",
        "Shuaicheng Liu",
        "Yao Zhao"
      ],
      "abstract": "We retarget video stitching to an emerging issue, named warping shake, which\nunveils the temporal content shakes induced by sequentially unsmooth warps when\nextending image stitching to video stitching. Even if the input videos are\nstable, the stitched video can inevitably cause undesired warping shakes and\naffect the visual experience. To address this issue, we propose StabStitch++, a\nnovel video stitching framework to realize spatial stitching and temporal\nstabilization with unsupervised learning simultaneously. First, different from\nexisting learning-based image stitching solutions that typically warp one image\nto align with another, we suppose a virtual midplane between original image\nplanes and project them onto it. Concretely, we design a differentiable\nbidirectional decomposition module to disentangle the homography transformation\nand incorporate it into our spatial warp, evenly spreading alignment burdens\nand projective distortions across two views. Then, inspired by camera paths in\nvideo stabilization, we derive the mathematical expression of stitching\ntrajectories in video stitching by elaborately integrating spatial and temporal\nwarps. Finally, a warp smoothing model is presented to produce stable stitched\nvideos with a hybrid loss to simultaneously encourage content alignment,\ntrajectory smoothness, and online collaboration. Compared with StabStitch that\nsacrifices alignment for stabilization, StabStitch++ makes no compromise and\noptimizes both of them simultaneously, especially in the online mode. To\nestablish an evaluation benchmark and train the learning framework, we build a\nvideo stitching dataset with a rich diversity in camera motions and scenes.\nExperiments exhibit that StabStitch++ surpasses current solutions in stitching\nperformance, robustness, and efficiency, offering compelling advancements in\nthis field by building a real-time online video stitching system.",
      "tldr_zh": "本研究针对视频拼接中的 warping shake 问题，提出 StabStitch++ 框架，这是一种无监督在线视频拼接方法，通过时空双向 warps 同时实现空间拼接和时间稳定化。\n该框架假设一个虚拟中间平面，使用可微分 bidirectional decomposition 模块来解耦 homography transformation，并均匀分布对齐负担和投影畸变，同时整合空间和时间变换导出拼接轨迹的数学表达式。\n此外，StabStitch++ 采用一个变换平滑模型和混合损失函数，优化内容对齐、轨迹平滑及在线协作，相比前作 StabStitch 无需牺牲对齐精度。\n实验结果显示，该框架在视频拼接数据集上显著提升了拼接性能、鲁棒性和效率，并成功构建了一个实时在线系统。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "TPAMI2025; https://github.com/nie-lang/StabStitch2. arXiv admin note:\n  text overlap with arXiv:2403.06378",
      "pdf_url": "http://arxiv.org/pdf/2505.05001v1",
      "published_date": "2025-05-08 07:12:23 UTC",
      "updated_date": "2025-05-08 07:12:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:05:53.084264"
    },
    {
      "arxiv_id": "2505.04999v1",
      "title": "CLAM: Continuous Latent Action Models for Robot Learning from Unlabeled Demonstrations",
      "title_zh": "CLAM：连续潜在动作模型用于机器人从无标签演示学习",
      "authors": [
        "Anthony Liang",
        "Pavel Czempin",
        "Matthew Hong",
        "Yutai Zhou",
        "Erdem Biyik",
        "Stephen Tu"
      ],
      "abstract": "Learning robot policies using imitation learning requires collecting large\namounts of costly action-labeled expert demonstrations, which fundamentally\nlimits the scale of training data. A promising approach to address this\nbottleneck is to harness the abundance of unlabeled observations-e.g., from\nvideo demonstrations-to learn latent action labels in an unsupervised way.\nHowever, we find that existing methods struggle when applied to complex robot\ntasks requiring fine-grained motions. We design continuous latent action models\n(CLAM) which incorporate two key ingredients we find necessary for learning to\nsolve complex continuous control tasks from unlabeled observation data: (a)\nusing continuous latent action labels instead of discrete representations, and\n(b) jointly training an action decoder to ensure that the latent action space\ncan be easily grounded to real actions with relatively few labeled examples.\nImportantly, the labeled examples can be collected from non-optimal play data,\nenabling CLAM to learn performant policies without access to any action-labeled\nexpert data. We demonstrate on continuous control benchmarks in DMControl\n(locomotion) and MetaWorld (manipulation), as well as on a real WidowX robot\narm that CLAM significantly outperforms prior state-of-the-art methods,\nremarkably with a 2-3x improvement in task success rate compared to the best\nbaseline. Videos and code can be found at clamrobot.github.io.",
      "tldr_zh": "这篇论文提出 CLAM（Continuous Latent Action Models），一种从无标签演示中学习机器人策略的方法，以解决传统 imitation learning 对大量标记动作数据的依赖问题。CLAM 的关键创新包括使用连续潜在动作标签而非离散表示，以及联合训练动作解码器，从而允许从非最优数据中高效学习策略，而无需专家演示。在 DMControl（运动）、MetaWorld（操作）和真实 WidowX 机器人臂的基准测试中，CLAM 显著优于现有方法，提高了2-3倍的任务成功率。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Latent Action Models, Self-supervised Pretraining, Learning from\n  Videos",
      "pdf_url": "http://arxiv.org/pdf/2505.04999v1",
      "published_date": "2025-05-08 07:07:58 UTC",
      "updated_date": "2025-05-08 07:07:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:06:05.598061"
    },
    {
      "arxiv_id": "2505.04997v1",
      "title": "Foam-Agent: Towards Automated Intelligent CFD Workflows",
      "title_zh": "翻译失败",
      "authors": [
        "Ling Yue",
        "Nithin Somasekharan",
        "Yadi Cao",
        "Shaowu Pan"
      ],
      "abstract": "Computational Fluid Dynamics (CFD) is an essential simulation tool in various\nengineering disciplines, but it often requires substantial domain expertise and\nmanual configuration, creating barriers to entry. We present Foam-Agent, a\nmulti-agent framework that automates complex OpenFOAM-based CFD simulation\nworkflows from natural language inputs. Our innovation includes (1) a\nhierarchical multi-index retrieval system with specialized indices for\ndifferent simulation aspects, (2) a dependency-aware file generation system\nthat provides consistency management across configuration files, and (3) an\niterative error correction mechanism that diagnoses and resolves simulation\nfailures without human intervention. Through comprehensive evaluation on the\ndataset of 110 simulation tasks, Foam-Agent achieves an 83.6% success rate with\nClaude 3.5 Sonnet, significantly outperforming existing frameworks (55.5% for\nMetaOpenFOAM and 37.3% for OpenFOAM-GPT). Ablation studies demonstrate the\ncritical contribution of each system component, with the specialized error\ncorrection mechanism providing a 36.4% performance improvement. Foam-Agent\nsubstantially lowers the CFD expertise threshold while maintaining modeling\naccuracy, demonstrating the potential of specialized multi-agent systems to\ndemocratize access to complex scientific simulation tools. The code is public\nat https://github.com/csml-rpi/Foam-Agent",
      "tldr_zh": "本研究提出Foam-Agent，一种多智能体框架，旨在自动化基于OpenFOAM的CFD模拟工作流，从自然语言输入开始，解决手动配置和专业知识门槛的问题。框架的关键创新包括层次化多索引检索系统（hierarchical multi-index retrieval system）、依赖感知文件生成系统（dependency-aware file generation system）以及迭代错误修正机制（iterative error correction mechanism），这些组件确保模拟过程的一致性和自动故障修复。在110个模拟任务的评估中，Foam-Agent使用Claude 3.5 Sonnet实现了83.6%的成功率，远超MetaOpenFOAM（55.5%）和OpenFOAM-GPT（37.3%），消融研究显示错误修正机制贡献了36.4%的性能提升。该框架显著降低了CFD的专业门槛，同时保持建模准确性，推动复杂科学模拟工具的民主化。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04997v1",
      "published_date": "2025-05-08 07:05:51 UTC",
      "updated_date": "2025-05-08 07:05:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:06:18.469274"
    },
    {
      "arxiv_id": "2505.04994v1",
      "title": "Rethinking Invariance in In-context Learning",
      "title_zh": "重新审视上下文学习中的不变性",
      "authors": [
        "Lizhe Fang",
        "Yifei Wang",
        "Khashayar Gatmiry",
        "Lei Fang",
        "Yisen Wang"
      ],
      "abstract": "In-Context Learning (ICL) has emerged as a pivotal capability of\nauto-regressive large language models, yet it is hindered by a notable\nsensitivity to the ordering of context examples regardless of their mutual\nindependence. To address this issue, recent studies have introduced several\nvariant algorithms of ICL that achieve permutation invariance. However, many of\nthese do not exhibit comparable performance with the standard auto-regressive\nICL algorithm. In this work, we identify two crucial elements in the design of\nan invariant ICL algorithm: information non-leakage and context\ninterdependence, which are not simultaneously achieved by any of the existing\nmethods. These investigations lead us to the proposed Invariant ICL (InvICL), a\nmethodology designed to achieve invariance in ICL while ensuring the two\nproperties. Empirically, our findings reveal that InvICL surpasses previous\nmodels, both invariant and non-invariant, in most benchmark datasets,\nshowcasing superior generalization capabilities across varying input lengths.\nCode is available at https://github.com/PKU-ML/InvICL.",
      "tldr_zh": "本研究重新审视了 In-Context Learning (ICL) 中的不变性问题，指出 ICL 对上下文示例顺序高度敏感，即使示例相互独立，这导致现有实现排列不变性(permutation invariance)的算法性能不如标准 ICL。作者识别出两个关键要素——information non-leakage 和 context interdependence——并提出 Invariant ICL (InvICL) 方法，确保这些要素同时满足，从而实现有效的 ICL 不变性。实验结果显示，InvICL 在大多数基准数据集上超越了先前模型，包括不变性和非不变性方法，并在不同输入长度上展现出更强的泛化能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04994v1",
      "published_date": "2025-05-08 06:59:14 UTC",
      "updated_date": "2025-05-08 06:59:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:06:29.787383"
    },
    {
      "arxiv_id": "2505.04983v1",
      "title": "Decomposition of Probabilities of Causation with Two Mediators",
      "title_zh": "翻译失败",
      "authors": [
        "Yuta Kawakami",
        "Jin Tian"
      ],
      "abstract": "Mediation analysis for probabilities of causation (PoC) provides a\nfundamental framework for evaluating the necessity and sufficiency of treatment\nin provoking an event through different causal pathways. One of the primary\nobjectives of causal mediation analysis is to decompose the total effect into\npath-specific components. In this study, we investigate the path-specific\nprobability of necessity and sufficiency (PNS) to decompose the total PNS into\npath-specific components along distinct causal pathways between treatment and\noutcome, incorporating two mediators. We define the path-specific PNS for\ndecomposition and provide an identification theorem. Furthermore, we conduct\nnumerical experiments to assess the properties of the proposed estimators from\nfinite samples and demonstrate their practical application using a real-world\neducational dataset.",
      "tldr_zh": "本研究探讨了中介分析在概率因果（Probabilities of Causation, PoC）中的应用，旨在通过两个中介将治疗对结果的总效应分解为路径特定的成分。论文定义了路径特定的概率必要性和充分性（Path-specific Probability of Necessity and Sufficiency, PNS），并提供了相应的识别定理，以评估治疗在不同因果路径中的作用。实验结果显示，所提出的估计器在有限样本中表现出良好性能，并在真实的教育数据集上验证了其实际应用。",
      "categories": [
        "stat.ME",
        "cs.AI"
      ],
      "primary_category": "stat.ME",
      "comment": "arXiv admin note: text overlap with arXiv:2412.14491",
      "pdf_url": "http://arxiv.org/pdf/2505.04983v1",
      "published_date": "2025-05-08 06:40:17 UTC",
      "updated_date": "2025-05-08 06:40:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:06:41.066806"
    },
    {
      "arxiv_id": "2505.05522v2",
      "title": "Continuous Thought Machines",
      "title_zh": "翻译失败",
      "authors": [
        "Luke Darlow",
        "Ciaran Regan",
        "Sebastian Risi",
        "Jeffrey Seely",
        "Llion Jones"
      ],
      "abstract": "Biological brains demonstrate complex neural activity, where the timing and\ninterplay between neurons is critical to how brains process information. Most\ndeep learning architectures simplify neural activity by abstracting away\ntemporal dynamics. In this paper we challenge that paradigm. By incorporating\nneuron-level processing and synchronization, we can effectively reintroduce\nneural timing as a foundational element. We present the Continuous Thought\nMachine (CTM), a model designed to leverage neural dynamics as its core\nrepresentation. The CTM has two core innovations: (1) neuron-level temporal\nprocessing, where each neuron uses unique weight parameters to process a\nhistory of incoming signals; and (2) neural synchronization employed as a\nlatent representation. The CTM aims to strike a balance between oversimplified\nneuron abstractions that improve computational efficiency, and biological\nrealism. It operates at a level of abstraction that effectively captures\nessential temporal dynamics while remaining computationally tractable for deep\nlearning. We demonstrate the CTM's strong performance and versatility across a\nrange of challenging tasks, including ImageNet-1K classification, solving 2D\nmazes, sorting, parity computation, question-answering, and RL tasks. Beyond\ndisplaying rich internal representations and offering a natural avenue for\ninterpretation owing to its internal process, the CTM is able to perform tasks\nthat require complex sequential reasoning. The CTM can also leverage adaptive\ncompute, where it can stop earlier for simpler tasks, or keep computing when\nfaced with more challenging instances. The goal of this work is to share the\nCTM and its associated innovations, rather than pushing for new\nstate-of-the-art results. To that end, we believe the CTM represents a\nsignificant step toward developing more biologically plausible and powerful\nartificial intelligence systems.",
      "tldr_zh": "本论文提出 Continuous Thought Machine (CTM)，一种通过神经元级时序处理和同步机制来模拟生物大脑动态的深度学习模型，旨在解决传统架构忽略时间动态的问题。CTM 的核心创新包括：每个神经元使用独特权重参数处理传入信号的历史，以及将神经同步作为潜在表示，从而在计算效率和生物真实性之间取得平衡。该模型在多种任务中表现出色，如 ImageNet-1K 分类、2D 迷宫求解、排序、奇偶计算、问答和强化学习任务，并支持复杂顺序推理和自适应计算（如针对简单任务提前停止）。整体而言，CTM 代表了向更生物似然的强大 AI 系统发展的关键一步。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Technical report accompanied by online project page:\n  https://pub.sakana.ai/ctm/",
      "pdf_url": "http://arxiv.org/pdf/2505.05522v2",
      "published_date": "2025-05-08 06:31:54 UTC",
      "updated_date": "2025-05-12 01:35:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:06:54.074770"
    },
    {
      "arxiv_id": "2505.04977v1",
      "title": "ChainMarks: Securing DNN Watermark with Cryptographic Chain",
      "title_zh": "ChainMarks：使用加密链保护 DNN 水印",
      "authors": [
        "Brian Choi",
        "Shu Wang",
        "Isabelle Choi",
        "Kun Sun"
      ],
      "abstract": "With the widespread deployment of deep neural network (DNN) models, dynamic\nwatermarking techniques are being used to protect the intellectual property of\nmodel owners. However, recent studies have shown that existing watermarking\nschemes are vulnerable to watermark removal and ambiguity attacks. Besides, the\nvague criteria for determining watermark presence further increase the\nlikelihood of such attacks. In this paper, we propose a secure DNN watermarking\nscheme named ChainMarks, which generates secure and robust watermarks by\nintroducing a cryptographic chain into the trigger inputs and utilizes a\ntwo-phase Monte Carlo method for determining watermark presence. First,\nChainMarks generates trigger inputs as a watermark dataset by repeatedly\napplying a hash function over a secret key, where the target labels associated\nwith trigger inputs are generated from the digital signature of model owner.\nThen, the watermarked model is produced by training a DNN over both the\noriginal and watermark datasets. To verify watermarks, we compare the predicted\nlabels of trigger inputs with the target labels and determine ownership with a\nmore accurate decision threshold that considers the classification probability\nof specific models. Experimental results show that ChainMarks exhibits higher\nlevels of robustness and security compared to state-of-the-art watermarking\nschemes. With a better marginal utility, ChainMarks provides a higher\nprobability guarantee of watermark presence in DNN models with the same level\nof watermark accuracy.",
      "tldr_zh": "本研究提出了一种安全的深度神经网络(DNN)水印方案ChainMarks，通过引入加密链(cryptographic chain)来生成鲁棒的水印数据集，以应对现有水印技术的移除和模糊攻击问题。具体而言，ChainMarks使用哈希函数(hash function)重复应用于秘密密钥生成触发输入，并基于模型所有者的数字签名(digital signature)创建目标标签，然后在原数据集和水印数据集上训练DNN模型；验证时采用两阶段Monte Carlo方法来精确判断水印存在。实验结果显示，ChainMarks相较于最先进的水印方案表现出更高的鲁棒性和安全性，在保持相同水印准确性的同时，提供更可靠的水印存在概率保证。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted In ACM ASIA Conference on Computer and Communications\n  Security (ASIA CCS '25), August 25-29, 2025, Ha Noi, Vietnam",
      "pdf_url": "http://arxiv.org/pdf/2505.04977v1",
      "published_date": "2025-05-08 06:30:46 UTC",
      "updated_date": "2025-05-08 06:30:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:07:04.838246"
    },
    {
      "arxiv_id": "2505.04972v1",
      "title": "AI and Vision based Autonomous Navigation of Nano-Drones in Partially-Known Environments",
      "title_zh": "基于人工智能和视觉的纳米无人机在部分已知环境中的自主导航",
      "authors": [
        "Mattia Sartori",
        "Chetna Singhal",
        "Neelabhro Roy",
        "Davide Brunelli",
        "James Gross"
      ],
      "abstract": "The miniaturisation of sensors and processors, the advancements in connected\nedge intelligence, and the exponential interest in Artificial Intelligence are\nboosting the affirmation of autonomous nano-size drones in the Internet of\nRobotic Things ecosystem. However, achieving safe autonomous navigation and\nhigh-level tasks such as exploration and surveillance with these tiny platforms\nis extremely challenging due to their limited resources. This work focuses on\nenabling the safe and autonomous flight of a pocket-size, 30-gram platform\ncalled Crazyflie 2.1 in a partially known environment. We propose a novel\nAI-aided, vision-based reactive planning method for obstacle avoidance under\nthe ambit of Integrated Sensing, Computing and Communication paradigm. We deal\nwith the constraints of the nano-drone by splitting the navigation task into\ntwo parts: a deep learning-based object detector runs on the edge (external\nhardware) while the planning algorithm is executed onboard. The results show\nthe ability to command the drone at $\\sim8$ frames-per-second and a model\nperformance reaching a COCO mean-average-precision of $60.8$. Field experiments\ndemonstrate the feasibility of the solution with the drone flying at a top\nspeed of $1$ m/s while steering away from an obstacle placed in an unknown\nposition and reaching the target destination. The outcome highlights the\ncompatibility of the communication delay and the model performance with the\nrequirements of the real-time navigation task. We provide a feasible\nalternative to a fully onboard implementation that can be extended to\nautonomous exploration with nano-drones.",
      "tldr_zh": "本研究探讨了AI和视觉技术在部分已知环境中的纳米无人机自主导航，针对其资源有限的挑战提出了一种新型方法。研究采用AI辅助的视觉-based反应式规划算法，基于Integrated Sensing, Computing and Communication范式，将任务分为两部分：在外部硬件上运行deep learning-based object detector，并在无人机上执行规划算法，从而实现安全障碍避免。实验结果显示，该系统使无人机以约8帧/秒的速度运行，模型性能达到COCO mean-average-precision of 60.8%，并在现场测试中以1 m/s的速度成功避开未知障碍物并到达目标，提供了一个可扩展到自主探索的可行替代方案。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.NI"
      ],
      "primary_category": "cs.RO",
      "comment": "in DCOSS-IoT 2025, Wi-DroIT 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.04972v1",
      "published_date": "2025-05-08 06:16:36 UTC",
      "updated_date": "2025-05-08 06:16:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:07:17.991328"
    },
    {
      "arxiv_id": "2505.04971v1",
      "title": "Moments of Causal Effects",
      "title_zh": "因果效应的矩",
      "authors": [
        "Yuta Kawakami",
        "Jin Tian"
      ],
      "abstract": "The moments of random variables are fundamental statistical measures for\ncharacterizing the shape of a probability distribution, encompassing metrics\nsuch as mean, variance, skewness, and kurtosis. Additionally, the product\nmoments, including covariance and correlation, reveal the relationships between\nmultiple random variables. On the other hand, the primary focus of causal\ninference is the evaluation of causal effects, which are defined as the\ndifference between two potential outcomes. While traditional causal effect\nassessment focuses on the average causal effect, this work provides\ndefinitions, identification theorems, and bounds for moments and product\nmoments of causal effects to analyze their distribution and relationships. We\nconduct experiments to illustrate the estimation of the moments of causal\neffects from finite samples and demonstrate their practical application using a\nreal-world medical dataset.",
      "tldr_zh": "本文扩展了因果推断（causal inference）的框架，定义了因果效应（causal effects）的 moments（如均值、方差、偏度和峰度）以及 product moments（如协方差和相关性），并提供了相应的 identification theorems 和 bounds，以分析这些效应的分布和相互关系。传统因果分析主要关注 average causal effect，而本研究通过这些新定义，帮助更好地理解因果效应的统计特性。实验结果展示了从有限样本中估计这些 moments 的方法，并在真实医疗数据集上验证了其实际应用潜力。",
      "categories": [
        "stat.ME",
        "cs.AI"
      ],
      "primary_category": "stat.ME",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04971v1",
      "published_date": "2025-05-08 06:09:05 UTC",
      "updated_date": "2025-05-08 06:09:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:07:29.369096"
    },
    {
      "arxiv_id": "2505.04966v1",
      "title": "Position: The AI Conference Peer Review Crisis Demands Author Feedback and Reviewer Rewards",
      "title_zh": "翻译失败",
      "authors": [
        "Jaeho Kim",
        "Yunseok Lee",
        "Seulki Lee"
      ],
      "abstract": "The peer review process in major artificial intelligence (AI) conferences\nfaces unprecedented challenges with the surge of paper submissions (exceeding\n10,000 submissions per venue), accompanied by growing concerns over review\nquality and reviewer responsibility. This position paper argues for the need to\ntransform the traditional one-way review system into a bi-directional feedback\nloop where authors evaluate review quality and reviewers earn formal\naccreditation, creating an accountability framework that promotes a\nsustainable, high-quality peer review system. The current review system can be\nviewed as an interaction between three parties: the authors, reviewers, and\nsystem (i.e., conference), where we posit that all three parties share\nresponsibility for the current problems. However, issues with authors can only\nbe addressed through policy enforcement and detection tools, and ethical\nconcerns can only be corrected through self-reflection. As such, this paper\nfocuses on reforming reviewer accountability with systematic rewards through\ntwo key mechanisms: (1) a two-stage bi-directional review system that allows\nauthors to evaluate reviews while minimizing retaliatory behavior, (2)a\nsystematic reviewer reward system that incentivizes quality reviewing. We ask\nfor the community's strong interest in these problems and the reforms that are\nneeded to enhance the peer review process.",
      "tldr_zh": "这篇立场论文指出，AI 会议的同行评审(peer review)系统因论文提交量激增（超过10,000篇）而面临评审质量和评审者责任的严峻挑战。论文主张将传统单向评审转变为双向反馈循环，让作者提供反馈(author feedback)并为评审者引入正式奖励和认可机制，以建立问责框架。针对这些问题，论文提出两阶段双向评审系统和系统化评审者奖励(reviewer rewards)系统，以激励高质量评审，并呼吁社区共同推动改革以提升评审过程的可持续性。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "ICML2025 Position Track Oral",
      "pdf_url": "http://arxiv.org/pdf/2505.04966v1",
      "published_date": "2025-05-08 05:51:48 UTC",
      "updated_date": "2025-05-08 05:51:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:07:42.509258"
    },
    {
      "arxiv_id": "2505.04961v1",
      "title": "ADD: Physics-Based Motion Imitation with Adversarial Differential Discriminators",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyu Zhang",
        "Sergey Bashkirov",
        "Dun Yang",
        "Michael Taylor",
        "Xue Bin Peng"
      ],
      "abstract": "Multi-objective optimization problems, which require the simultaneous\noptimization of multiple terms, are prevalent across numerous applications.\nExisting multi-objective optimization methods often rely on manually tuned\naggregation functions to formulate a joint optimization target. The performance\nof such hand-tuned methods is heavily dependent on careful weight selection, a\ntime-consuming and laborious process. These limitations also arise in the\nsetting of reinforcement-learning-based motion tracking for physically\nsimulated characters, where intricately crafted reward functions are typically\nused to achieve high-fidelity results. Such solutions not only require domain\nexpertise and significant manual adjustment, but also limit the applicability\nof the resulting reward function across diverse skills. To bridge this gap, we\npresent a novel adversarial multi-objective optimization technique that is\nbroadly applicable to a range of multi-objective optimization problems,\nincluding motion tracking. The proposed adversarial differential discriminator\nreceives a single positive sample, yet is still effective at guiding the\noptimization process. We demonstrate that our technique can enable characters\nto closely replicate a variety of acrobatic and agile behaviors, achieving\ncomparable quality to state-of-the-art motion-tracking methods, without relying\non manually tuned reward functions. Results are best visualized through\nhttps://youtu.be/rz8BYCE9E2w.",
      "tldr_zh": "该论文针对多目标优化(multi-objective optimization)问题提出了一种新方法ADD，利用对抗性差分鉴别器(adversarial differential discriminators)进行基于物理的运动模仿，避免了传统方法依赖手动调整的聚合函数和奖励函数。ADD技术只需一个正样本即可有效引导优化过程，使其适用于各种场景，包括强化学习(reinforcement learning)中的运动跟踪。实验结果显示，该方法能让物理模拟角色精确复制杂技和敏捷行为，与最先进方法相当，同时减少了手动调整的复杂性。",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV",
        "cs.RO"
      ],
      "primary_category": "cs.GR",
      "comment": "19 pages, 15 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.04961v1",
      "published_date": "2025-05-08 05:42:33 UTC",
      "updated_date": "2025-05-08 05:42:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:07:52.850062"
    },
    {
      "arxiv_id": "2505.04956v1",
      "title": "Graffe: Graph Representation Learning via Diffusion Probabilistic Models",
      "title_zh": "Graffe：基于扩散概率模型的图表示学习",
      "authors": [
        "Dingshuo Chen",
        "Shuchen Xue",
        "Liuji Chen",
        "Yingheng Wang",
        "Qiang Liu",
        "Shu Wu",
        "Zhi-Ming Ma",
        "Liang Wang"
      ],
      "abstract": "Diffusion probabilistic models (DPMs), widely recognized for their potential\nto generate high-quality samples, tend to go unnoticed in representation\nlearning. While recent progress has highlighted their potential for capturing\nvisual semantics, adapting DPMs to graph representation learning remains in its\ninfancy. In this paper, we introduce Graffe, a self-supervised diffusion model\nproposed for graph representation learning. It features a graph encoder that\ndistills a source graph into a compact representation, which, in turn, serves\nas the condition to guide the denoising process of the diffusion decoder. To\nevaluate the effectiveness of our model, we first explore the theoretical\nfoundations of applying diffusion models to representation learning, proving\nthat the denoising objective implicitly maximizes the conditional mutual\ninformation between data and its representation. Specifically, we prove that\nthe negative logarithm of the denoising score matching loss is a tractable\nlower bound for the conditional mutual information. Empirically, we conduct a\nseries of case studies to validate our theoretical insights. In addition,\nGraffe delivers competitive results under the linear probing setting on node\nand graph classification tasks, achieving state-of-the-art performance on 9 of\nthe 11 real-world datasets. These findings indicate that powerful generative\nmodels, especially diffusion models, serve as an effective tool for graph\nrepresentation learning.",
      "tldr_zh": "本研究提出 Graffe，一种自监督的 Diffusion Probabilistic Models 用于图表示学习（Graph Representation Learning），通过图编码器将源图浓缩成紧凑表示，并作为条件引导扩散解码器的去噪过程。理论上，作者证明了去噪目标隐式最大化数据与其表示之间的条件互信息，并将负对数去噪分数匹配损失作为其可计算下界。实验结果显示，Graffe 在线性探测设置下，在节点和图分类任务上取得了 state-of-the-art 性能，在 11 个真实数据集中的 9 个上表现最佳，验证了扩散模型作为图表示学习工具的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 4 figures, under review",
      "pdf_url": "http://arxiv.org/pdf/2505.04956v1",
      "published_date": "2025-05-08 05:38:19 UTC",
      "updated_date": "2025-05-08 05:38:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:08:05.955973"
    },
    {
      "arxiv_id": "2505.04955v1",
      "title": "Chain-of-Thought Tokens are Computer Program Variables",
      "title_zh": "翻译失败",
      "authors": [
        "Fangwei Zhu",
        "Peiyi Wang",
        "Zhifang Sui"
      ],
      "abstract": "Chain-of-thoughts (CoT) requires large language models (LLMs) to generate\nintermediate steps before reaching the final answer, and has been proven\neffective to help LLMs solve complex reasoning tasks. However, the inner\nmechanism of CoT still remains largely unclear. In this paper, we empirically\nstudy the role of CoT tokens in LLMs on two compositional tasks: multi-digit\nmultiplication and dynamic programming. While CoT is essential for solving\nthese problems, we find that preserving only tokens that store intermediate\nresults would achieve comparable performance. Furthermore, we observe that\nstoring intermediate results in an alternative latent form will not affect\nmodel performance. We also randomly intervene some values in CoT, and notice\nthat subsequent CoT tokens and the final answer would change correspondingly.\nThese findings suggest that CoT tokens may function like variables in computer\nprograms but with potential drawbacks like unintended shortcuts and\ncomputational complexity limits between tokens. The code and data are available\nat https://github.com/solitaryzero/CoTs_are_Variables.",
      "tldr_zh": "本研究探讨了Chain-of-Thought (CoT) 在大型语言模型 (LLMs) 中的内部机制，通过实证实验分析其在多位数乘法和动态规划等组合任务中的作用。研究发现，仅保留存储中间结果的CoT tokens即可实现与完整CoT相当的性能，且将中间结果以替代潜在形式存储不会影响模型表现；此外，随机干预CoT值会导致后续tokens和最终答案相应变化，表明CoT tokens类似于计算机程序中的变量。论文还指出了潜在缺点，如意外捷径和计算复杂性限制，并提供了代码和数据以供进一步验证。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04955v1",
      "published_date": "2025-05-08 05:32:36 UTC",
      "updated_date": "2025-05-08 05:32:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:08:16.859890"
    },
    {
      "arxiv_id": "2505.04950v1",
      "title": "Position: Epistemic Artificial Intelligence is Essential for Machine Learning Models to Know When They Do Not Know",
      "title_zh": "翻译失败",
      "authors": [
        "Shireen Kudukkil Manchingal",
        "Fabio Cuzzolin"
      ],
      "abstract": "Despite the impressive achievements of AI, including advancements in\ngenerative models and large language models, there remains a significant gap in\nthe ability of AI to handle uncertainty and generalize beyond the training\ndata. We argue that AI models, especially in autonomous systems, fail to make\nrobust predictions when faced with unfamiliar or adversarial data, as evidenced\nby incidents with autonomous vehicles. Traditional machine learning approaches\nstruggle to address these issues due to an overemphasis on data fitting and\ndomain adaptation. This position paper posits a paradigm shift towards\nepistemic artificial intelligence, emphasizing the need for models to learn not\nonly from what they know but also from their ignorance. This approach, which\nfocuses on recognizing and managing uncertainty, offers a potential solution to\nimprove the resilience and robustness of AI systems, ensuring that they can\nbetter handle unpredictable real-world environments.",
      "tldr_zh": "尽管人工智能（AI）在生成模型和大型语言模型上取得了显著进展，但其在处理不确定性和泛化训练数据之外的场景方面存在重大缺陷，导致在面对未知或对抗性数据时（如自动驾驶车辆事故）无法做出稳健预测。论文主张一种范式转变，强调Epistemic Artificial Intelligence的必要性，即AI模型不仅要学习已知知识，还需认识到自身的无知，以更好地管理不确定性。传统机器学习方法过于依赖数据拟合和领域适应，无法有效解决这些问题，而Epistemic AI 提供了一种潜在解决方案，能提升AI系统的韧性和鲁棒性，从而更适应不可预测的真实世界环境。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04950v1",
      "published_date": "2025-05-08 05:10:38 UTC",
      "updated_date": "2025-05-08 05:10:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:08:28.742695"
    },
    {
      "arxiv_id": "2505.04946v1",
      "title": "T2VTextBench: A Human Evaluation Benchmark for Textual Control in Video Generation Models",
      "title_zh": "T2VTextBench：一种用于视频生成模型中文本控制的人类评估基准",
      "authors": [
        "Xuyang Guo",
        "Jiayan Huo",
        "Zhenmei Shi",
        "Zhao Song",
        "Jiahao Zhang",
        "Jiale Zhao"
      ],
      "abstract": "Thanks to recent advancements in scalable deep architectures and large-scale\npretraining, text-to-video generation has achieved unprecedented capabilities\nin producing high-fidelity, instruction-following content across a wide range\nof styles, enabling applications in advertising, entertainment, and education.\nHowever, these models' ability to render precise on-screen text, such as\ncaptions or mathematical formulas, remains largely untested, posing significant\nchallenges for applications requiring exact textual accuracy. In this work, we\nintroduce T2VTextBench, the first human-evaluation benchmark dedicated to\nevaluating on-screen text fidelity and temporal consistency in text-to-video\nmodels. Our suite of prompts integrates complex text strings with dynamic scene\nchanges, testing each model's ability to maintain detailed instructions across\nframes. We evaluate ten state-of-the-art systems, ranging from open-source\nsolutions to commercial offerings, and find that most struggle to generate\nlegible, consistent text. These results highlight a critical gap in current\nvideo generators and provide a clear direction for future research aimed at\nenhancing textual manipulation in video synthesis.",
      "tldr_zh": "该研究引入了T2VTextBench，这是一个专为评估text-to-video generation模型中屏幕文本保真度和时间一致性的首个人类评估基准。基准通过设计一系列整合复杂文本字符串和动态场景变化的提示，来测试模型在多帧中保持详细指令的能力。评估了10个最先进的系统，包括开源和商业解决方案，结果显示大多数模型在生成可读、一致的文本方面存在显著挑战，为未来提升视频合成中的文本操控提供了关键研究方向。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04946v1",
      "published_date": "2025-05-08 04:49:52 UTC",
      "updated_date": "2025-05-08 04:49:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:08:40.706954"
    },
    {
      "arxiv_id": "2505.06305v1",
      "title": "User Behavior Analysis in Privacy Protection with Large Language Models: A Study on Privacy Preferences with Limited Data",
      "title_zh": "大语言模型在隐私保护中的用户行为",
      "authors": [
        "Haowei Yang",
        "Qingyi Lu",
        "Yang Wang",
        "Sibei Liu",
        "Jiayun Zheng",
        "Ao Xiang"
      ],
      "abstract": "With the widespread application of large language models (LLMs), user privacy\nprotection has become a significant research topic. Existing privacy preference\nmodeling methods often rely on large-scale user data, making effective privacy\npreference analysis challenging in data-limited environments. This study\nexplores how LLMs can analyze user behavior related to privacy protection in\nscenarios with limited data and proposes a method that integrates Few-shot\nLearning and Privacy Computing to model user privacy preferences. The research\nutilizes anonymized user privacy settings data, survey responses, and simulated\ndata, comparing the performance of traditional modeling approaches with\nLLM-based methods. Experimental results demonstrate that, even with limited\ndata, LLMs significantly improve the accuracy of privacy preference modeling.\nAdditionally, incorporating Differential Privacy and Federated Learning further\nreduces the risk of user data exposure. The findings provide new insights into\nthe application of LLMs in privacy protection and offer theoretical support for\nadvancing privacy computing and user behavior analysis.",
      "tldr_zh": "本研究探讨了在数据有限环境下，使用 Large Language Models (LLMs) 分析用户隐私行为的方法，以解决现有隐私偏好建模依赖大规模数据的挑战。研究提出了一种整合 Few-shot Learning 和 Privacy Computing 的方法，利用匿名化用户隐私设置数据、调查响应和模拟数据进行建模，并与传统方法进行性能比较。实验结果表明，即使数据有限，LLMs 也能显著提高隐私偏好建模的准确性，同时通过 Differential Privacy 和 Federated Learning 进一步降低了用户数据暴露风险。该研究为 LLMs 在隐私保护中的应用提供了新见解，并为隐私计算和用户行为分析提供了理论支持。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06305v1",
      "published_date": "2025-05-08 04:42:17 UTC",
      "updated_date": "2025-05-08 04:42:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:08:53.336555"
    },
    {
      "arxiv_id": "2505.04939v1",
      "title": "Structural Alignment in Link Prediction",
      "title_zh": "链接预测中的结构对齐",
      "authors": [
        "Jeffrey Seathrún Sardina"
      ],
      "abstract": "While Knowledge Graphs (KGs) have become increasingly popular across various\nscientific disciplines for their ability to model and interlink huge quantities\nof data, essentially all real-world KGs are known to be incomplete. As such,\nwith the growth of KG use has been a concurrent development of machine learning\ntools designed to predict missing information in KGs, which is referred to as\nthe Link Prediction Task. The majority of state-of-the-art link predictors to\ndate have followed an embedding-based paradigm. In this paradigm, it is assumed\nthat the information content of a KG is best represented by the (individual)\nvector representations of its nodes and edges, and that therefore node and edge\nembeddings are particularly well-suited to performing link prediction.\n  This thesis proposes an alternative perspective on the field's approach to\nlink prediction and KG data modelling. Specifically, this work re-analyses KGs\nand state-of-the-art link predictors from a graph-structure-first perspective\nthat models the information content of a KG in terms of whole triples, rather\nthan individual nodes and edges.\n  Following a literature review and two core sets of experiments, this thesis\nconcludes that a structure-first perspective on KGs and link prediction is both\nviable and useful for understanding KG learning and for enabling cross-KG\ntransfer learning for the link prediction task. This observation is used to\ncreate and propose the Structural Alignment Hypothesis, which postulates that\nlink prediction can be understood and modelled as a structural task.\n  All code and data used for this thesis are open-sourced. This thesis was\nwritten bilingually, with the main document in English and an informal extended\nsummary in Irish. An Irish-language translation dictionary of machine learning\nterms (the Focl\\'oir Tr\\'achtais) created for this work is open-sourced as\nwell.",
      "tldr_zh": "这篇论文从图结构优先的视角重新审视知识图谱（KGs）的链接预测（Link Prediction）任务，挑战传统的基于嵌入（embedding-based）方法，转而将KGs的信息内容建模为整体三元组，而不是单独的节点和边。通过文献综述和实验，证明这种结构-first方法可行，有助于理解KG学习和实现跨KG迁移学习，并提出了Structural Alignment Hypothesis，将链接预测视为结构任务。该研究的所有代码、数据和一个机器学习术语的爱尔兰语翻译字典均已开源。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Ph.D. thesis submitted to Trinity College Dublin",
      "pdf_url": "http://arxiv.org/pdf/2505.04939v1",
      "published_date": "2025-05-08 04:27:15 UTC",
      "updated_date": "2025-05-08 04:27:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:09:05.441476"
    },
    {
      "arxiv_id": "2505.05520v1",
      "title": "GaMNet: A Hybrid Network with Gabor Fusion and NMamba for Efficient 3D Glioma Segmentation",
      "title_zh": "GaMNet：一种结合 Gabor 融合和 NMamba 的混合网络，用于高效的 3D",
      "authors": [
        "Chengwei Ye",
        "Huanzhen Zhang",
        "Yufei Lin",
        "Kangsheng Wang",
        "Linuo Xu",
        "Shuyan Liu"
      ],
      "abstract": "Gliomas are aggressive brain tumors that pose serious health risks. Deep\nlearning aids in lesion segmentation, but CNN and Transformer-based models\noften lack context modeling or demand heavy computation, limiting real-time use\non mobile medical devices. We propose GaMNet, integrating the NMamba module for\nglobal modeling and a multi-scale CNN for efficient local feature extraction.\nTo improve interpretability and mimic the human visual system, we apply Gabor\nfilters at multiple scales. Our method achieves high segmentation accuracy with\nfewer parameters and faster computation. Extensive experiments show GaMNet\noutperforms existing methods, notably reducing false positives and negatives,\nwhich enhances the reliability of clinical diagnosis.",
      "tldr_zh": "本研究针对胶质瘤分割的挑战提出 GaMNet，一种混合网络，结合 NMamba 模块实现全局建模，并使用多尺度 CNN 进行高效的局部特征提取，同时融入多尺度 Gabor filters 以提升可解释性和模仿人类视觉系统。相比传统 CNN 和 Transformer 模型，GaMNet 显著减少了参数量和计算开销，使其适用于移动医疗设备的实时应用。实验结果显示，该方法在 3D 胶质瘤分割任务上优于现有方法，显著降低了假阳性和假阴性，提高了临床诊断的可靠性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05520v1",
      "published_date": "2025-05-08 04:25:22 UTC",
      "updated_date": "2025-05-08 04:25:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:09:16.639629"
    },
    {
      "arxiv_id": "2505.07854v1",
      "title": "CCL: Collaborative Curriculum Learning for Sparse-Reward Multi-Agent Reinforcement Learning via Co-evolutionary Task Evolution",
      "title_zh": "翻译失败",
      "authors": [
        "Yufei Lin",
        "Chengwei Ye",
        "Huanzhen Zhang",
        "Kangsheng Wang",
        "Linuo Xu",
        "Shuyan Liu",
        "Zeyu Zhang"
      ],
      "abstract": "Sparse reward environments pose significant challenges in reinforcement\nlearning, especially within multi-agent systems (MAS) where feedback is delayed\nand shared across agents, leading to suboptimal learning. We propose\nCollaborative Multi-dimensional Course Learning (CCL), a novel curriculum\nlearning framework that addresses this by (1) refining intermediate tasks for\nindividual agents, (2) using a variational evolutionary algorithm to generate\ninformative subtasks, and (3) co-evolving agents with their environment to\nenhance training stability. Experiments on five cooperative tasks in the MPE\nand Hide-and-Seek environments show that CCL outperforms existing methods in\nsparse reward settings.",
      "tldr_zh": "该论文提出CCL（Collaborative Curriculum Learning），一种协作课程学习框架，用于解决稀疏奖励（Sparse-Reward）多智能体强化学习（Multi-Agent Reinforcement Learning）中的挑战，包括延迟反馈和共享反馈导致的次优学习。CCL 的核心机制包括为单个智能体精炼中间任务、使用变分进化算法（Variational Evolutionary Algorithm）生成信息丰富的子任务，以及通过共同进化（Co-evolutionary Task Evolution）来提升训练稳定性。在MPE和Hide-and-Seek环境中的五个合作任务实验中，CCL 表现出色，优于现有方法。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07854v1",
      "published_date": "2025-05-08 04:23:47 UTC",
      "updated_date": "2025-05-08 04:23:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:09:28.874809"
    },
    {
      "arxiv_id": "2505.04931v1",
      "title": "Fair Uncertainty Quantification for Depression Prediction",
      "title_zh": "抑郁预测的公平不确定性量化",
      "authors": [
        "Yonghong Li",
        "Xiuzhuang Zhou"
      ],
      "abstract": "Trustworthy depression prediction based on deep learning, incorporating both\npredictive reliability and algorithmic fairness across diverse demographic\ngroups, is crucial for clinical application. Recently, achieving reliable\ndepression predictions through uncertainty quantification has attracted\nincreasing attention. However, few studies have focused on the fairness of\nuncertainty quantification (UQ) in depression prediction. In this work, we\ninvestigate the algorithmic fairness of UQ, namely Equal Opportunity Coverage\n(EOC) fairness, and propose Fair Uncertainty Quantification (FUQ) for\ndepression prediction. FUQ pursues reliable and fair depression predictions\nthrough group-based analysis. Specifically, we first group all the participants\nby different sensitive attributes and leverage conformal prediction to quantify\nuncertainty within each demographic group, which provides a theoretically\nguaranteed and valid way to quantify uncertainty for depression prediction and\nfacilitates the investigation of fairness across different demographic groups.\nFurthermore, we propose a fairness-aware optimization strategy that formulates\nfairness as a constrained optimization problem under EOC constraints. This\nenables the model to preserve predictive reliability while adapting to the\nheterogeneous uncertainty levels across demographic groups, thereby achieving\noptimal fairness. Through extensive evaluations on several visual and audio\ndepression datasets, our approach demonstrates its effectiveness.",
      "tldr_zh": "该研究针对抑郁预测中的不确定性量化（UQ）公平性问题，提出Fair Uncertainty Quantification (FUQ) 方法，以确保预测的可靠性和算法公平性，特别是在不同人口统计群体间的Equal Opportunity Coverage (EOC) 公平。方法包括基于敏感属性的分组分析，使用Conformal Prediction 来量化每个群体的不确定性，并设计一个公平感知优化策略，将公平性作为受EOC约束的优化问题，从而平衡不同群体的异质不确定性水平。实验在多个视觉和音频抑郁数据集上验证了FUQ的有效性，实现了可靠预测的同时提升了公平性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04931v1",
      "published_date": "2025-05-08 04:09:36 UTC",
      "updated_date": "2025-05-08 04:09:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:09:40.123301"
    },
    {
      "arxiv_id": "2505.04927v1",
      "title": "Belief Filtering for Epistemic Control in Linguistic State Space",
      "title_zh": "语言状态空间中的信念过滤用于认识论控制",
      "authors": [
        "Sebastian Dumbrava"
      ],
      "abstract": "We examine belief filtering as a mechanism for the epistemic control of\nartificial agents, focusing on the regulation of internal cognitive states\nrepresented as linguistic expressions. This mechanism is developed within the\nSemantic Manifold framework, where belief states are dynamic, structured\nensembles of natural language fragments. Belief filters act as content-aware\noperations on these fragments across various cognitive transitions. This paper\nillustrates how the inherent interpretability and modularity of such a\nlinguistically-grounded cognitive architecture directly enable belief\nfiltering, offering a principled approach to agent regulation. The study\nhighlights the potential for enhancing AI safety and alignment through\nstructured interventions in an agent's internal semantic space and points to\nnew directions for architecturally embedded cognitive governance.",
      "tldr_zh": "本论文探讨了信念过滤（belief filtering）作为一种机制，用于实现人工智能代理在语言状态空间（Linguistic State Space）中的认知控制（epistemic control），重点在于调节表示为语言表达的内部认知状态。该机制建立在 Semantic Manifold 框架之上，将信念状态视为动态的、结构化的自然语言片段集合，并通过内容感知操作在各种认知转换中处理这些片段。论文强调，这种语言基础的认知架构的固有解释性和模块性直接支持信念过滤，提供了一种代理调节的原理方法。最终，该研究展示了通过在代理的内部语义空间进行结构化干预来提升 AI safety and alignment 的潜力，并为 architecturally embedded cognitive governance 指出了新方向。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.04927v1",
      "published_date": "2025-05-08 03:52:43 UTC",
      "updated_date": "2025-05-08 03:52:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:09:53.101282"
    },
    {
      "arxiv_id": "2505.04918v1",
      "title": "Physics-Assisted and Topology-Informed Deep Learning for Weather Prediction",
      "title_zh": "物理辅助和拓扑信息驱动的深度学习用于天气预测",
      "authors": [
        "Jiaqi Zheng",
        "Qing Ling",
        "Yerong Feng"
      ],
      "abstract": "Although deep learning models have demonstrated remarkable potential in\nweather prediction, most of them overlook either the \\textbf{physics} of the\nunderlying weather evolution or the \\textbf{topology} of the Earth's surface.\nIn light of these disadvantages, we develop PASSAT, a novel Physics-ASSisted\nAnd Topology-informed deep learning model for weather prediction. PASSAT\nattributes the weather evolution to two key factors: (i) the advection process\nthat can be characterized by the advection equation and the Navier-Stokes\nequation; (ii) the Earth-atmosphere interaction that is difficult to both model\nand calculate. PASSAT also takes the topology of the Earth's surface into\nconsideration, other than simply treating it as a plane. With these\nconsiderations, PASSAT numerically solves the advection equation and the\nNavier-Stokes equation on the spherical manifold, utilizes a spherical graph\nneural network to capture the Earth-atmosphere interaction, and generates the\ninitial velocity fields that are critical to solving the advection equation\nfrom the same spherical graph neural network. In the $5.625^\\circ$-resolution\nERA5 data set, PASSAT outperforms both the state-of-the-art deep learning-based\nweather prediction models and the operational numerical weather prediction\nmodel IFS T42. Code and checkpoint are available at\nhttps://github.com/Yumenomae/PASSAT_5p625.",
      "tldr_zh": "该论文提出了一种新型深度学习模型 PASSAT，用于天气预测，通过整合物理方程和地球表面拓扑信息来克服现有模型的不足。PASSAT 将天气演变归因于 advection process（由 advection equation 和 Navier-Stokes equation 描述）和 Earth-atmosphere interaction，并采用 spherical graph neural network 在球形流形上数值求解这些方程，同时生成初始速度场。实验结果显示，在 5.625° 分辨率的 ERA5 数据集上，PASSAT 优于最先进的深度学习模型和操作数值天气预测模型 IFS T42，显著提升了预测准确性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "International Joint Conferences on Artificial Intelligence (IJCAI\n  2025)",
      "pdf_url": "http://arxiv.org/pdf/2505.04918v1",
      "published_date": "2025-05-08 03:25:55 UTC",
      "updated_date": "2025-05-08 03:25:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:10:04.469255"
    },
    {
      "arxiv_id": "2505.06303v1",
      "title": "Collaborative Multi-LoRA Experts with Achievement-based Multi-Tasks Loss for Unified Multimodal Information Extraction",
      "title_zh": "翻译失败",
      "authors": [
        "Li Yuan",
        "Yi Cai",
        "Xudong Shen",
        "Qing Li",
        "Qingbao Huang",
        "Zikun Deng",
        "Tao Wang"
      ],
      "abstract": "Multimodal Information Extraction (MIE) has gained attention for extracting\nstructured information from multimedia sources. Traditional methods tackle MIE\ntasks separately, missing opportunities to share knowledge across tasks. Recent\napproaches unify these tasks into a generation problem using instruction-based\nT5 models with visual adaptors, optimized through full-parameter fine-tuning.\nHowever, this method is computationally intensive, and multi-task fine-tuning\noften faces gradient conflicts, limiting performance. To address these\nchallenges, we propose collaborative multi-LoRA experts with achievement-based\nmulti-task loss (C-LoRAE) for MIE tasks. C-LoRAE extends the low-rank\nadaptation (LoRA) method by incorporating a universal expert to learn shared\nmultimodal knowledge from cross-MIE tasks and task-specific experts to learn\nspecialized instructional task features. This configuration enhances the\nmodel's generalization ability across multiple tasks while maintaining the\nindependence of various instruction tasks and mitigating gradient conflicts.\nAdditionally, we propose an achievement-based multi-task loss to balance\ntraining progress across tasks, addressing the imbalance caused by varying\nnumbers of training samples in MIE tasks. Experimental results on seven\nbenchmark datasets across three key MIE tasks demonstrate that C-LoRAE achieves\nsuperior overall performance compared to traditional fine-tuning methods and\nLoRA methods while utilizing a comparable number of training parameters to\nLoRA.",
      "tldr_zh": "这篇论文针对 Multimodal Information Extraction (MIE) 提出了一种协作式多-LoRA 专家方法（C-LoRAE），旨在统一处理多任务信息提取问题，同时解决传统全参数微调的计算密集和梯度冲突问题。C-LoRAE 通过一个通用专家学习跨任务的共享多模态知识，以及任务特定专家学习专化特征，从而提升模型的泛化能力并缓解训练冲突；此外，还引入基于成就的 multi-task loss 来平衡不同任务的训练进度，应对样本不平衡问题。实验在七个基准数据集和三个关键 MIE 任务上表明，C-LoRAE 比传统微调和 LoRA 方法实现了整体性能提升，同时仅使用类似参数量。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by IJCAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.06303v1",
      "published_date": "2025-05-08 03:16:32 UTC",
      "updated_date": "2025-05-08 03:16:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:10:17.516419"
    },
    {
      "arxiv_id": "2505.04916v1",
      "title": "An Open-Source Dual-Loss Embedding Model for Semantic Retrieval in Higher Education",
      "title_zh": "翻译失败",
      "authors": [
        "Ramteja Sajja",
        "Yusuf Sermet",
        "Ibrahim Demir"
      ],
      "abstract": "Recent advances in AI have catalyzed the adoption of intelligent educational\ntools, yet many semantic retrieval systems remain ill-suited to the unique\nlinguistic and structural characteristics of academic content. This study\npresents two open-source embedding models fine-tuned for educational question\nanswering, particularly in the context of course syllabi. A synthetic dataset\nof 3,197 sentence pairs, spanning synonymous terminology, paraphrased\nquestions, and implicit-explicit mappings, was constructed through a\ncombination of manual curation and large language model (LLM)-assisted\ngeneration. Two training strategies were evaluated: (1) a baseline model\nfine-tuned using MultipleNegativesRankingLoss (MNRL), and (2) a dual-loss model\nthat combines MNRL with CosineSimilarityLoss to improve both semantic ranking\nand similarity calibration. Evaluations were conducted on 28 university course\nsyllabi using a fixed set of natural language questions categorized into\ncourse, faculty, and teaching assistant information. Results demonstrate that\nboth fine-tuned models outperform strong open-source baselines, including\nall-MiniLM-L6-v2 and multi-qa-MiniLM-L6-cos-v1, and that the dual-loss model\nnarrows the performance gap with high-performing proprietary embeddings such as\nOpenAI's text-embedding-3 series. This work contributes reusable,\ndomain-aligned embedding models and provides a replicable framework for\neducational semantic retrieval, supporting downstream applications such as\nacademic chatbots, retrieval-augmented generation (RAG) systems, and learning\nmanagement system (LMS) integrations.",
      "tldr_zh": "这篇论文提出了一种开源双损失嵌入模型，用于高等教育的语义检索，以解决现有系统对学术内容的语言和结构特征适应不足的问题。研究构建了一个包含3197个句子对的合成数据集，通过手动整理和LLM辅助生成，并评估了两种训练策略：基线模型使用MultipleNegativesRankingLoss (MNRL)，以及结合MNRL和CosineSimilarityLoss的双损失模型，以提升语义排名和相似性校准。实验结果表明，该双损失模型在28个大学课程大纲上的表现优于开源基线如all-MiniLM-L6-v2，并缩小了与OpenAI text-embedding-3系列的性能差距，为学术聊天机器人、retrieval-augmented generation (RAG)系统和学习管理系统 (LMS)整合等下游应用提供了可重用和可复制的框架。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages, 3 Tables",
      "pdf_url": "http://arxiv.org/pdf/2505.04916v1",
      "published_date": "2025-05-08 03:14:14 UTC",
      "updated_date": "2025-05-08 03:14:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:10:30.910061"
    },
    {
      "arxiv_id": "2505.04914v1",
      "title": "Enigme: Generative Text Puzzles for Evaluating Reasoning in Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "John Hawkins"
      ],
      "abstract": "Transformer-decoder language models are a core innovation in text based\ngenerative artificial intelligence. These models are being deployed as\ngeneral-purpose intelligence systems in many applications. Central to their\nutility is the capacity to understand natural language commands and exploit the\nreasoning embedded in human text corpora to apply some form of reasoning\nprocess to a wide variety of novel tasks. To understand the limitations of this\napproach to generating reasoning we argue that we need to consider the\narchitectural constraints of these systems. Consideration of the latent\nvariable structure of transformer-decoder models allows us to design reasoning\ntasks that should probe the boundary of their capacity to reason. We present\nenigme, an open-source library for generating text-based puzzles to be used in\ntraining and evaluating reasoning skills within transformer-decoder models and\nfuture AI architectures.",
      "tldr_zh": "本文研究了Transformer-decoder语言模型在生成AI中的推理能力，强调了其架构限制可能导致的局限性，如无法充分处理复杂推理任务。作者通过分析模型的潜在变量结构，设计了基于文本谜题的任务来探测这些边界。Enigme是一个开源库，用于生成这些文本谜题，以训练和评估Transformer-decoder模型及其他未来AI架构的推理技能。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "To be published in the proceedings of The 2025 11th International\n  Conference on Engineering, Applied Sciences, and Technology (ICEAST)",
      "pdf_url": "http://arxiv.org/pdf/2505.04914v1",
      "published_date": "2025-05-08 03:09:57 UTC",
      "updated_date": "2025-05-08 03:09:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:10:40.396541"
    },
    {
      "arxiv_id": "2505.04911v1",
      "title": "SpatialPrompting: Keyframe-driven Zero-Shot Spatial Reasoning with Off-the-Shelf Multimodal Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Shun Taguchi",
        "Hideki Deguchi",
        "Takumi Hamazaki",
        "Hiroyuki Sakai"
      ],
      "abstract": "This study introduces SpatialPrompting, a novel framework that harnesses the\nemergent reasoning capabilities of off-the-shelf multimodal large language\nmodels to achieve zero-shot spatial reasoning in three-dimensional (3D)\nenvironments. Unlike existing methods that rely on expensive 3D-specific\nfine-tuning with specialized 3D inputs such as point clouds or voxel-based\nfeatures, SpatialPrompting employs a keyframe-driven prompt generation\nstrategy. This framework uses metrics such as vision-language similarity,\nMahalanobis distance, field of view, and image sharpness to select a diverse\nand informative set of keyframes from image sequences and then integrates them\nwith corresponding camera pose data to effectively abstract spatial\nrelationships and infer complex 3D structures. The proposed framework not only\nestablishes a new paradigm for flexible spatial reasoning that utilizes\nintuitive visual and positional cues but also achieves state-of-the-art\nzero-shot performance on benchmark datasets, such as ScanQA and SQA3D, across\nseveral metrics. The proposed method effectively eliminates the need for\nspecialized 3D inputs and fine-tuning, offering a simpler and more scalable\nalternative to conventional approaches.",
      "tldr_zh": "这篇论文介绍了 SpatialPrompting 框架，利用现成的 Multimodal Large Language Models 实现零样本 (Zero-Shot) 空间推理，无需昂贵的 3D 特定微调或专用输入如点云。框架采用关键帧驱动的提示生成策略，通过视觉语言相似度、Mahalanobis distance、视野和图像清晰度等指标选择多样化关键帧，并整合相机位姿数据来抽象空间关系和推断复杂 3D 结构。在 ScanQA 和 SQA3D 等基准数据集上，SpatialPrompting 取得了最先进的性能，提供了一个更简单、可扩展的替代方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.04911v1",
      "published_date": "2025-05-08 02:59:01 UTC",
      "updated_date": "2025-05-08 02:59:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:10:53.214811"
    },
    {
      "arxiv_id": "2505.06302v1",
      "title": "QiMeng-TensorOp: Automatically Generating High-Performance Tensor Operators with Hardware Primitives",
      "title_zh": "QiMeng-TensorOp：使用硬件原语自动生成高性能张量运算符",
      "authors": [
        "Xuzhi Zhang",
        "Shaohui Peng",
        "Qirui Zhou",
        "Yuanbo Wen",
        "Qi Guo",
        "Ruizhi Chen",
        "Xinguo Zhu",
        "Weiqiang Xiong",
        "Haixin Chen",
        "Congying Ma",
        "Ke Gao",
        "Chen Zhao",
        "Yanjun Wu",
        "Yunji Chen",
        "Ling Li"
      ],
      "abstract": "Computation-intensive tensor operators constitute over 90\\% of the\ncomputations in Large Language Models (LLMs) and Deep Neural\nNetworks.Automatically and efficiently generating high-performance tensor\noperators with hardware primitives is crucial for diverse and ever-evolving\nhardware architectures like RISC-V, ARM, and GPUs, as manually optimized\nimplementation takes at least months and lacks portability.LLMs excel at\ngenerating high-level language codes, but they struggle to fully comprehend\nhardware characteristics and produce high-performance tensor operators. We\nintroduce a tensor-operator auto-generation framework with a one-line user\nprompt (QiMeng-TensorOp), which enables LLMs to automatically exploit hardware\ncharacteristics to generate tensor operators with hardware primitives, and tune\nparameters for optimal performance across diverse hardware. Experimental\nresults on various hardware platforms, SOTA LLMs, and typical tensor operators\ndemonstrate that QiMeng-TensorOp effectively unleashes the computing capability\nof various hardware platforms, and automatically generates tensor operators of\nsuperior performance. Compared with vanilla LLMs, QiMeng-TensorOp achieves up\nto $1291 \\times$ performance improvement. Even compared with human experts,\nQiMeng-TensorOp could reach $251 \\%$ of OpenBLAS on RISC-V CPUs, and $124 \\%$\nof cuBLAS on NVIDIA GPUs. Additionally, QiMeng-TensorOp also significantly\nreduces development costs by $200 \\times$ compared with human experts.",
      "tldr_zh": "本研究提出QiMeng-TensorOp框架，通过一个用户提示自动生成高性能张量操作符，利用硬件 primitives（如RISC-V、ARM和GPUs）并优化参数，以应对Large Language Models (LLMs)和Deep Neural Networks (DNNs)中占90%以上计算量的张量操作挑战。框架利用LLMs的代码生成能力，结合硬件特性分析，实现高效的自动调优和移植。实验结果显示，QiMeng-TensorOp相较于原生LLMs提升性能高达1291倍，并超越人类专家（如在RISC-V CPUs上达到OpenBLAS的251%，在NVIDIA GPUs上达到cuBLAS的124%），同时将开发成本减少200倍。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.2"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.06302v1",
      "published_date": "2025-05-08 02:36:21 UTC",
      "updated_date": "2025-05-08 02:36:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:11:04.253102"
    },
    {
      "arxiv_id": "2505.06301v1",
      "title": "Domain-Adversarial Anatomical Graph Networks for Cross-User Human Activity Recognition",
      "title_zh": "跨用户人类活动识别的领域对抗解剖图网络",
      "authors": [
        "Xiaozhou Ye",
        "Kevin I-Kai Wang"
      ],
      "abstract": "Cross-user variability in Human Activity Recognition (HAR) remains a critical\nchallenge due to differences in sensor placement, body dynamics, and behavioral\npatterns. Traditional methods often fail to capture biomechanical invariants\nthat persist across users, limiting their generalization capability. We propose\nan Edge-Enhanced Graph-Based Adversarial Domain Generalization (EEG-ADG)\nframework that integrates anatomical correlation knowledge into a unified graph\nneural network (GNN) architecture. By modeling three biomechanically motivated\nrelationships together-Interconnected Units, Analogous Units, and Lateral\nUnits-our method encodes domain-invariant features while addressing\nuser-specific variability through Variational Edge Feature Extractor. A\nGradient Reversal Layer (GRL) enforces adversarial domain generalization,\nensuring robustness to unseen users. Extensive experiments on OPPORTUNITY and\nDSADS datasets demonstrate state-of-the-art performance. Our work bridges\nbiomechanical principles with graph-based adversarial learning by integrating\ninformation fusion techniques. This fusion of information underpins our unified\nand generalized model for cross-user HAR.",
      "tldr_zh": "本研究针对人类活动识别(Human Activity Recognition, HAR)中跨用户变异性问题（如传感器放置、体动和行为模式差异），提出了一种Edge-Enhanced Graph-Based Adversarial Domain Generalization (EEG-ADG)框架。该框架将解剖学相关知识整合到统一的图神经网络(Graph Neural Network, GNN)架构中，通过建模Interconnected Units、Analogous Units和Lateral Units三种生物力学关系，并结合Variational Edge Feature Extractor和Gradient Reversal Layer (GRL)来提取域不变特征并对抗用户特定变异性。实验在OPPORTUNITY和DSADS数据集上实现了最先进的性能，并桥接了生物力学原则与基于图的对抗学习，增强了HAR的泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06301v1",
      "published_date": "2025-05-08 02:30:55 UTC",
      "updated_date": "2025-05-08 02:30:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:11:17.662039"
    },
    {
      "arxiv_id": "2505.04898v1",
      "title": "Precise gradient descent training dynamics for finite-width multi-layer neural networks",
      "title_zh": "针对有限宽度多层神经网络的精确梯度下降训练动态",
      "authors": [
        "Qiyang Han",
        "Masaaki Imaizumi"
      ],
      "abstract": "In this paper, we provide the first precise distributional characterization\nof gradient descent iterates for general multi-layer neural networks under the\ncanonical single-index regression model, in the `finite-width proportional\nregime' where the sample size and feature dimension grow proportionally while\nthe network width and depth remain bounded. Our non-asymptotic state evolution\ntheory captures Gaussian fluctuations in first-layer weights and concentration\nin deeper-layer weights, and remains valid for non-Gaussian features.\n  Our theory differs from existing neural tangent kernel (NTK), mean-field (MF)\ntheories and tensor program (TP) in several key aspects. First, our theory\noperates in the finite-width regime whereas these existing theories are\nfundamentally infinite-width. Second, our theory allows weights to evolve from\nindividual initializations beyond the lazy training regime, whereas NTK and MF\nare either frozen at or only weakly sensitive to initialization, and TP relies\non special initialization schemes. Third, our theory characterizes both\ntraining and generalization errors for general multi-layer neural networks\nbeyond the uniform convergence regime, whereas existing theories study\ngeneralization almost exclusively in two-layer settings.\n  As a statistical application, we show that vanilla gradient descent can be\naugmented to yield consistent estimates of the generalization error at each\niteration, which can be used to guide early stopping and hyperparameter tuning.\nAs a further theoretical implication, we show that despite model\nmisspecification, the model learned by gradient descent retains the structure\nof a single-index function with an effective signal determined by a linear\ncombination of the true signal and the initialization.",
      "tldr_zh": "本文首次精确表征了gradient descent在有限宽度多层神经网络下的训练动态，使用单索引回归模型和非渐近状态演化理论，捕捉第一层权重的Gaussian波动和更深层权重的集中，并适用于非Gaussian特征。 与现有NTK、Mean-Field和Tensor Program理论不同，该方法适用于有限宽度设置、允许权重从个体初始化演化，并同时分析训练和泛化错误，而非局限于无限宽度或两层网络。 作为应用，该框架可增强gradient descent以估计每个迭代的泛化错误，用于指导早停和超参数调优；此外，尽管模型错配，gradient descent学到的模型仍保留单索引函数的结构，由真实信号和初始化线性组合决定。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC",
        "math.ST",
        "stat.ML",
        "stat.TH"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04898v1",
      "published_date": "2025-05-08 02:19:39 UTC",
      "updated_date": "2025-05-08 02:19:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:11:29.241146"
    },
    {
      "arxiv_id": "2505.04891v1",
      "title": "Clustering with Communication: A Variational Framework for Single Cell Representation Learning",
      "title_zh": "通信聚类：单细胞表示学习的变分框架",
      "authors": [
        "Cong Qi",
        "Yeqing Chen",
        "Jie Zhang",
        "Wei Zhi"
      ],
      "abstract": "Single-cell RNA sequencing (scRNA-seq) has revealed complex cellular\nheterogeneity, but recent studies emphasize that understanding biological\nfunction also requires modeling cell-cell communication (CCC), the signaling\ninteractions mediated by ligand-receptor pairs that coordinate cellular\nbehavior. Tools like CellChat have demonstrated that CCC plays a critical role\nin processes such as cell differentiation, tissue regeneration, and immune\nresponse, and that transcriptomic data inherently encodes rich information\nabout intercellular signaling. We propose CCCVAE, a novel variational\nautoencoder framework that incorporates CCC signals into single-cell\nrepresentation learning. By leveraging a communication-aware kernel derived\nfrom ligand-receptor interactions and a sparse Gaussian process, CCCVAE encodes\nbiologically informed priors into the latent space. Unlike conventional VAEs\nthat treat each cell independently, CCCVAE encourages latent embeddings to\nreflect both transcriptional similarity and intercellular signaling context.\nEmpirical results across four scRNA-seq datasets show that CCCVAE improves\nclustering performance, achieving higher evaluation scores than standard VAE\nbaselines. This work demonstrates the value of embedding biological priors into\ndeep generative models for unsupervised single-cell analysis.",
      "tldr_zh": "这篇论文提出CCCVAE，一种新型变分自编码器(VAE)框架，用于将细胞间通信(CCC)信号整合到单细胞RNA测序(scRNA-seq)表示学习中。通过利用基于配体-受体交互的通信感知内核和稀疏高斯过程，CCCVAE将生物学先验编码到潜在空间中，使嵌入反映转录相似性和细胞间信号上下文。与传统VAE不同，该方法在四个scRNA-seq数据集上显著提高了聚类性能，评估分数优于基线模型，展示了嵌入生物学先验对无监督单细胞分析的价值。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04891v1",
      "published_date": "2025-05-08 01:53:36 UTC",
      "updated_date": "2025-05-08 01:53:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:11:41.711983"
    },
    {
      "arxiv_id": "2505.04888v1",
      "title": "Cross-Branch Orthogonality for Improved Generalization in Face Deepfake Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Tharindu Fernando",
        "Clinton Fookes",
        "Sridha Sridharan",
        "Simon Denman"
      ],
      "abstract": "Remarkable advancements in generative AI technology have given rise to a\nspectrum of novel deepfake categories with unprecedented leaps in their\nrealism, and deepfakes are increasingly becoming a nuisance to law enforcement\nauthorities and the general public. In particular, we observe alarming levels\nof confusion, deception, and loss of faith regarding multimedia content within\nsociety caused by face deepfakes, and existing deepfake detectors are\nstruggling to keep up with the pace of improvements in deepfake generation.\nThis is primarily due to their reliance on specific forgery artifacts, which\nlimits their ability to generalise and detect novel deepfake types. To combat\nthe spread of malicious face deepfakes, this paper proposes a new strategy that\nleverages coarse-to-fine spatial information, semantic information, and their\ninteractions while ensuring feature distinctiveness and reducing the redundancy\nof the modelled features. A novel feature orthogonality-based disentanglement\nstrategy is introduced to ensure branch-level and cross-branch feature\ndisentanglement, which allows us to integrate multiple feature vectors without\nadding complexity to the feature space or compromising generalisation.\nComprehensive experiments on three public benchmarks: FaceForensics++,\nCeleb-DF, and the Deepfake Detection Challenge (DFDC) show that these design\nchoices enable the proposed approach to outperform current state-of-the-art\nmethods by 5% on the Celeb-DF dataset and 7% on the DFDC dataset in a\ncross-dataset evaluation setting.",
      "tldr_zh": "这篇论文针对面部deepfake检测的泛化问题，提出了一种新策略，通过利用粗到细的空间信息、语义信息及其交互，确保特征的独特性并减少冗余。论文引入了基于feature orthogonality的解耦策略，实现分支级和跨分支特征解耦，从而允许整合多个特征向量而不增加模型复杂性或损害泛化能力。在FaceForensics++、Celeb-DF和DFDC数据集上的跨数据集评估中，该方法比现有最先进方法在Celeb-DF数据集上提高了5%的性能，在DFDC数据集上提高了7%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04888v1",
      "published_date": "2025-05-08 01:49:53 UTC",
      "updated_date": "2025-05-08 01:49:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:11:53.025974"
    },
    {
      "arxiv_id": "2505.04883v1",
      "title": "QBR: A Question-Bank-Based Approach to Fine-Grained Legal Knowledge Retrieval for the General Public",
      "title_zh": "翻译失败",
      "authors": [
        "Mingruo Yuan",
        "Ben Kao",
        "Tien-Hsuan Wu"
      ],
      "abstract": "Retrieval of legal knowledge by the general public is a challenging problem\ndue to the technicality of the professional knowledge and the lack of\nfundamental understanding by laypersons on the subject. Traditional information\nretrieval techniques assume that users are capable of formulating succinct and\nprecise queries for effective document retrieval. In practice, however, the\nwide gap between the highly technical contents and untrained users makes legal\nknowledge retrieval very difficult. We propose a methodology, called QBR, which\nemploys a Questions Bank (QB) as an effective medium for bridging the knowledge\ngap. We show how the QB is used to derive training samples to enhance the\nembedding of knowledge units within documents, which leads to effective\nfine-grained knowledge retrieval. We discuss and evaluate through experiments\nvarious advantages of QBR over traditional methods. These include more\naccurate, efficient, and explainable document retrieval, better comprehension\nof retrieval results, and highly effective fine-grained knowledge retrieval. We\nalso present some case studies and show that QBR achieves social impact by\nassisting citizens to resolve everyday legal concerns.",
      "tldr_zh": "本论文提出 QBR 方法，利用 Questions Bank (QB) 作为桥梁，帮助普通公众进行细粒度 legal knowledge retrieval，解决专业术语和技术性内容带来的检索难题。QBR 通过从 QB 派生训练样本来增强文档中知识单元的嵌入，实现更准确和高效的检索过程。实验结果显示，QBR 比传统方法在准确性、效率和可解释性上均有显著优势，并通过案例研究证明其在协助市民解决日常法律问题方面具有重要社会影响。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04883v1",
      "published_date": "2025-05-08 01:43:21 UTC",
      "updated_date": "2025-05-08 01:43:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:12:04.569824"
    },
    {
      "arxiv_id": "2505.04881v1",
      "title": "ConCISE: Confidence-guided Compression in Step-by-step Efficient Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Ziqing Qiao",
        "Yongheng Deng",
        "Jiali Zeng",
        "Dong Wang",
        "Lai Wei",
        "Fandong Meng",
        "Jie Zhou",
        "Ju Ren",
        "Yaoxue Zhang"
      ],
      "abstract": "Large Reasoning Models (LRMs) perform strongly in complex reasoning tasks via\nChain-of-Thought (CoT) prompting, but often suffer from verbose outputs caused\nby redundant content, increasing computational overhead, and degrading user\nexperience. Existing compression methods either operate post-hoc pruning,\nrisking disruption to reasoning coherence, or rely on sampling-based selection,\nwhich fails to intervene effectively during generation. In this work, we\nintroduce a confidence-guided perspective to explain the emergence of redundant\nreflection in LRMs, identifying two key patterns: Confidence Deficit, where the\nmodel reconsiders correct steps due to low internal confidence, and Termination\nDelay, where reasoning continues even after reaching a confident answer. Based\non this analysis, we propose ConCISE (Confidence-guided Compression In\nStep-by-step Efficient Reasoning), a framework that simplifies reasoning chains\nby reinforcing the model's confidence during inference, thus preventing the\ngeneration of redundant reflection steps. It integrates Confidence Injection to\nstabilize intermediate steps and Early Stopping to terminate reasoning when\nconfidence is sufficient. Extensive experiments demonstrate that fine-tuning\nLRMs on ConCISE-generated data yields significantly shorter outputs, reducing\nlength by up to approximately 50% under SimPO, while maintaining high task\naccuracy. ConCISE consistently outperforms existing baselines across multiple\nreasoning benchmarks.",
      "tldr_zh": "大型推理模型(LRMs)在使用Chain-of-Thought (CoT)提示进行复杂推理时，常因冗余输出导致计算开销增加和用户体验下降。论文分析了信心不足(Confidence Deficit)和终止延迟(Termination Delay)两大问题，提出ConCISE框架，通过信心注入(Confidence Injection)稳定中间步骤和提前停止(Early Stopping)机制来压缩推理链。实验结果显示，在ConCISE生成的数据上微调LRMs后，输出长度减少约50%（使用SimPO），同时保持高任务准确率，并在多个推理基准上优于现有基线。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04881v1",
      "published_date": "2025-05-08 01:40:40 UTC",
      "updated_date": "2025-05-08 01:40:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:12:18.483936"
    },
    {
      "arxiv_id": "2505.04880v1",
      "title": "GroverGPT-2: Simulating Grover's Algorithm via Chain-of-Thought Reasoning and Quantum-Native Tokenization",
      "title_zh": "翻译失败",
      "authors": [
        "Min Chen",
        "Jinglei Cheng",
        "Pingzhi Li",
        "Haoran Wang",
        "Tianlong Chen",
        "Junyu Liu"
      ],
      "abstract": "Quantum computing offers theoretical advantages over classical computing for\nspecific tasks, yet the boundary of practical quantum advantage remains an open\nquestion. To investigate this boundary, it is crucial to understand whether,\nand how, classical machines can learn and simulate quantum algorithms. Recent\nprogress in large language models (LLMs) has demonstrated strong reasoning\nabilities, prompting exploration into their potential for this challenge. In\nthis work, we introduce GroverGPT-2, an LLM-based method for simulating\nGrover's algorithm using Chain-of-Thought (CoT) reasoning and quantum-native\ntokenization. Building on its predecessor, GroverGPT-2 performs simulation\ndirectly from quantum circuit representations while producing logically\nstructured and interpretable outputs. Our results show that GroverGPT-2 can\nlearn and internalize quantum circuit logic through efficient processing of\nquantum-native tokens, providing direct evidence that classical models like\nLLMs can capture the structure of quantum algorithms. Furthermore, GroverGPT-2\noutputs interleave circuit data with natural language, embedding explicit\nreasoning into the simulation. This dual capability positions GroverGPT-2 as a\nprototype for advancing machine understanding of quantum algorithms and\nmodeling quantum circuit logic. We also identify an empirical scaling law for\nGroverGPT-2 with increasing qubit numbers, suggesting a path toward scalable\nclassical simulation. These findings open new directions for exploring the\nlimits of classical simulatability, enhancing quantum education and research,\nand laying groundwork for future foundation models in quantum computing.",
      "tldr_zh": "本文提出GroverGPT-2，一种基于大型语言模型(LLMs)的系统，利用Chain-of-Thought (CoT) 推理和quantum-native tokenization来模拟Grover's algorithm，从而探索经典机器对量子算法的学习能力。该方法从量子电路表示直接进行模拟，输出交织电路数据与自然语言，提供逻辑结构化和可解释的推理过程。实验结果表明，GroverGPT-2能有效捕捉量子算法结构，并遵循经验性缩放定律，随着qubit数量增加实现可扩展的经典模拟，为推进量子教育、研究和机器理解量子逻辑奠定基础。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "26 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.04880v1",
      "published_date": "2025-05-08 01:38:12 UTC",
      "updated_date": "2025-05-08 01:38:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:12:29.582543"
    },
    {
      "arxiv_id": "2505.04877v1",
      "title": "Learning from Loss Landscape: Generalizable Mixed-Precision Quantization via Adaptive Sharpness-Aware Gradient Aligning",
      "title_zh": "翻译失败",
      "authors": [
        "Lianbo Ma",
        "Jianlun Ma",
        "Yuee Zhou",
        "Guoyang Xie",
        "Qiang He",
        "Zhichao Lu"
      ],
      "abstract": "Mixed Precision Quantization (MPQ) has become an essential technique for\noptimizing neural network by determining the optimal bitwidth per layer.\nExisting MPQ methods, however, face a major hurdle: they require a\ncomputationally expensive search for quantization policies on large-scale\ndatasets. To resolve this issue, we introduce a novel approach that first\nsearches for quantization policies on small datasets and then generalizes them\nto large-scale datasets. This approach simplifies the process, eliminating the\nneed for large-scale quantization fine-tuning and only necessitating model\nweight adjustment. Our method is characterized by three key techniques:\nsharpness-aware minimization for enhanced quantization generalization, implicit\ngradient direction alignment to handle gradient conflicts among different\noptimization objectives, and an adaptive perturbation radius to accelerate\noptimization. Both theoretical analysis and experimental results validate our\napproach. Using the CIFAR10 dataset (just 0.5\\% the size of ImageNet training\ndata) for MPQ policy search, we achieved equivalent accuracy on ImageNet with a\nsignificantly lower computational cost, while improving efficiency by up to\n150% over the baselines.",
      "tldr_zh": "本研究提出了一种通用的混合精度量化(Mixed-Precision Quantization, MPQ)方法，通过在小数据集上搜索量化策略并泛化到大规模数据集，显著降低了计算成本。该方法的核心技术包括sharpness-aware minimization以提升量化泛化能力、implicit gradient direction alignment来处理不同优化目标的梯度冲突，以及adaptive perturbation radius来加速优化过程。实验结果显示，使用CIFAR10数据集（仅为ImageNet训练数据的0.5%）进行策略搜索，即可实现与ImageNet相当的准确率，同时比基线方法效率提升高达150%。这为神经网络优化提供了高效、可扩展的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04877v1",
      "published_date": "2025-05-08 01:20:24 UTC",
      "updated_date": "2025-05-08 01:20:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:12:40.843622"
    },
    {
      "arxiv_id": "2505.04873v1",
      "title": "Federated Learning for Cyber Physical Systems: A Comprehensive Survey",
      "title_zh": "联邦学习在网络物理系统中的全面综述",
      "authors": [
        "Minh K. Quan",
        "Pubudu N. Pathirana",
        "Mayuri Wijayasundara",
        "Sujeeva Setunge",
        "Dinh C. Nguyen",
        "Christopher G. Brinton",
        "David J. Love",
        "H. Vincent Poor"
      ],
      "abstract": "The integration of machine learning (ML) in cyber physical systems (CPS) is a\ncomplex task due to the challenges that arise in terms of real-time decision\nmaking, safety, reliability, device heterogeneity, and data privacy. There are\nalso open research questions that must be addressed in order to fully realize\nthe potential of ML in CPS. Federated learning (FL), a distributed approach to\nML, has become increasingly popular in recent years. It allows models to be\ntrained using data from decentralized sources. This approach has been gaining\npopularity in the CPS field, as it integrates computer, communication, and\nphysical processes. Therefore, the purpose of this work is to provide a\ncomprehensive analysis of the most recent developments of FL-CPS, including the\nnumerous application areas, system topologies, and algorithms developed in\nrecent years. The paper starts by discussing recent advances in both FL and\nCPS, followed by their integration. Then, the paper compares the application of\nFL in CPS with its applications in the internet of things (IoT) in further\ndepth to show their connections and distinctions. Furthermore, the article\nscrutinizes how FL is utilized in critical CPS applications, e.g., intelligent\ntransportation systems, cybersecurity services, smart cities, and smart\nhealthcare solutions. The study also includes critical insights and lessons\nlearned from various FL-CPS implementations. The paper's concluding section\ndelves into significant concerns and suggests avenues for further research in\nthis fast-paced and dynamic era.",
      "tldr_zh": "这篇论文对Federated Learning (FL) 在Cyber Physical Systems (CPS) 中的应用进行了全面调查，强调了FL作为分布式机器学习方法如何解决CPS面临的挑战，如数据隐私、设备异构性和实时决策。论文分析了FL在CPS的最新发展，包括应用领域（如智能交通系统、网络安全、智能城市和智能医疗）、系统拓扑以及相关算法，并与FL在Internet of Things (IoT) 中的应用进行了比较，以突出其联系和差异。最终，该研究总结了关键见解、经验教训，并提出了未来研究方向，以推动FL-CPS领域的创新。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "This work has been accepted by IEEE Communications Surveys &\n  Tutorials",
      "pdf_url": "http://arxiv.org/pdf/2505.04873v1",
      "published_date": "2025-05-08 01:17:15 UTC",
      "updated_date": "2025-05-08 01:17:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:12:52.293770"
    },
    {
      "arxiv_id": "2505.04864v1",
      "title": "Auto-regressive transformation for image alignment",
      "title_zh": "自回归变换用于图像对齐",
      "authors": [
        "Kanggeon Lee",
        "Soochahn Lee",
        "Kyoung Mu Lee"
      ],
      "abstract": "Existing methods for image alignment struggle in cases involving\nfeature-sparse regions, extreme scale and field-of-view differences, and large\ndeformations, often resulting in suboptimal accuracy. Robustness to these\nchallenges improves through iterative refinement of the transformation field\nwhile focusing on critical regions in multi-scale image representations. We\nthus propose Auto-Regressive Transformation (ART), a novel method that\niteratively estimates the coarse-to-fine transformations within an\nauto-regressive framework. Leveraging hierarchical multi-scale features, our\nnetwork refines the transformations using randomly sampled points at each\nscale. By incorporating guidance from the cross-attention layer, the model\nfocuses on critical regions, ensuring accurate alignment even in challenging,\nfeature-limited conditions. Extensive experiments across diverse datasets\ndemonstrate that ART significantly outperforms state-of-the-art methods,\nestablishing it as a powerful new method for precise image alignment with broad\napplicability.",
      "tldr_zh": "现有图像对齐方法在特征稀疏区域、极端缩放和视场差异以及大变形情况下往往准确性不足，为此提出Auto-Regressive Transformation (ART)方法，通过自回归框架迭代估计粗到细的变换。ART利用分层多尺度特征和随机采样点，并在cross-attention layer的指导下聚焦关键区域，从而实现更精确的图像对齐。实验在多样数据集上证明，ART显著优于最先进方法，成为图像对齐领域的强大新工具。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04864v1",
      "published_date": "2025-05-08 00:28:31 UTC",
      "updated_date": "2025-05-08 00:28:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:13:04.711905"
    },
    {
      "arxiv_id": "2505.07853v1",
      "title": "CrashSage: A Large Language Model-Centered Framework for Contextual and Interpretable Traffic Crash Analysis",
      "title_zh": "CrashSage: 以大语言模型为核心的框架，用于情境",
      "authors": [
        "Hao Zhen",
        "Jidong J. Yang"
      ],
      "abstract": "Road crashes claim over 1.3 million lives annually worldwide and incur global\neconomic losses exceeding \\$1.8 trillion. Such profound societal and financial\nimpacts underscore the urgent need for road safety research that uncovers crash\nmechanisms and delivers actionable insights. Conventional statistical models\nand tree ensemble approaches typically rely on structured crash data,\noverlooking contextual nuances and struggling to capture complex relationships\nand underlying semantics. Moreover, these approaches tend to incur significant\ninformation loss, particularly in narrative elements related to multi-vehicle\ninteractions, crash progression, and rare event characteristics. This study\npresents CrashSage, a novel Large Language Model (LLM)-centered framework\ndesigned to advance crash analysis and modeling through four key innovations.\nFirst, we introduce a tabular-to-text transformation strategy paired with\nrelational data integration schema, enabling the conversion of raw,\nheterogeneous crash data into enriched, structured textual narratives that\nretain essential structural and relational context. Second, we apply\ncontext-aware data augmentation using a base LLM model to improve narrative\ncoherence while preserving factual integrity. Third, we fine-tune the LLaMA3-8B\nmodel for crash severity inference, demonstrating superior performance over\nbaseline approaches, including zero-shot, zero-shot with chain-of-thought\nprompting, and few-shot learning, with multiple models (GPT-4o, GPT-4o-mini,\nLLaMA3-70B). Finally, we employ a gradient-based explainability technique to\nelucidate model decisions at both the individual crash level and across broader\nrisk factor dimensions. This interpretability mechanism enhances transparency\nand enables targeted road safety interventions by providing deeper insights\ninto the most influential factors.",
      "tldr_zh": "本研究提出CrashSage，一种以Large Language Model (LLM)为核心的框架，用于实现上下文化和可解释的交通事故分析，以解决传统统计模型和树集成方法忽略复杂关系和语义细节的问题。该框架包括tabular-to-text转换策略、关系数据集成和context-aware数据增强，以将异构事故数据转化为结构化的文本叙述，同时微调LLaMA3-8B模型进行事故严重度推理，表现出色地超越了基线模型如GPT-4o。最后，通过gradient-based explainability技术提供模型决策的可解释性，提升了透明度并支持针对性道路安全干预。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "20 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.07853v1",
      "published_date": "2025-05-08 00:23:18 UTC",
      "updated_date": "2025-05-08 00:23:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:13:16.304217"
    },
    {
      "arxiv_id": "2505.04860v1",
      "title": "D-CODA: Diffusion for Coordinated Dual-Arm Data Augmentation",
      "title_zh": "翻译失败",
      "authors": [
        "I-Chun Arthur Liu",
        "Jason Chen",
        "Gaurav Sukhatme",
        "Daniel Seita"
      ],
      "abstract": "Learning bimanual manipulation is challenging due to its high dimensionality\nand tight coordination required between two arms. Eye-in-hand imitation\nlearning, which uses wrist-mounted cameras, simplifies perception by focusing\non task-relevant views. However, collecting diverse demonstrations remains\ncostly, motivating the need for scalable data augmentation. While prior work\nhas explored visual augmentation in single-arm settings, extending these\napproaches to bimanual manipulation requires generating viewpoint-consistent\nobservations across both arms and producing corresponding action labels that\nare both valid and feasible. In this work, we propose Diffusion for COordinated\nDual-arm Data Augmentation (D-CODA), a method for offline data augmentation\ntailored to eye-in-hand bimanual imitation learning that trains a diffusion\nmodel to synthesize novel, viewpoint-consistent wrist-camera images for both\narms while simultaneously generating joint-space action labels. It employs\nconstrained optimization to ensure that augmented states involving\ngripper-to-object contacts adhere to constraints suitable for bimanual\ncoordination. We evaluate D-CODA on 5 simulated and 3 real-world tasks. Our\nresults across 2250 simulation trials and 300 real-world trials demonstrate\nthat it outperforms baselines and ablations, showing its potential for scalable\ndata augmentation in eye-in-hand bimanual manipulation. Our project website is\nat: https://dcodaaug.github.io/D-CODA/.",
      "tldr_zh": "本文提出 D-CODA，一种针对 eye-in-hand bimanual manipulation 的离线数据增强方法，利用 diffusion model 合成视角一致的手腕相机图像，同时生成可行的关节空间动作标签，以解决双臂操作学习中数据多样性不足的问题。该方法通过约束优化确保增强状态符合双臂协调的抓取物体接触要求。在5个模拟任务和3个真实世界任务上评估，D-CODA 在2250次模拟试验和300次真实试验中优于基线模型，展示了其在可扩展数据增强方面的潜力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04860v1",
      "published_date": "2025-05-08 00:03:04 UTC",
      "updated_date": "2025-05-08 00:03:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:13:28.881544"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 128,
  "processed_papers_count": 128,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-24T21:13:49.735314"
}