[
  {
    "arxiv_id": "2401.05584v2",
    "title": "FourCastNeXt: Optimizing FourCastNet Training for Limited Compute",
    "authors": [
      "Edison Guo",
      "Maruf Ahmed",
      "Yue Sun",
      "Rui Yang",
      "Harrison Cook",
      "Tennessee Leeuwenburg",
      "Ben Evans"
    ],
    "abstract": "FourCastNeXt is an optimization of FourCastNet - a global machine learning\nweather forecasting model - that performs with a comparable level of accuracy\nand can be trained using around 5% of the original FourCastNet computational\nrequirements. This technical report presents strategies for model optimization\nthat maintain similar performance as measured by the root-mean-square error\n(RMSE) of the modelled variables. By providing a model with very low\ncomparative training costs, FourCastNeXt makes Neural Earth System Modelling\nmuch more accessible to researchers looking to conduct training experiments and\nablation studies. FourCastNeXt training and inference code are available at\nhttps://github.com/nci/FourCastNeXt",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Major revision. All prior content (text, figures, table) has been\n  updated. Additionally, new text, tables and figures have been added. Updated\n  title. Updated author list",
    "pdf_url": "http://arxiv.org/pdf/2401.05584v2",
    "published_date": "2024-01-10 23:30:48 UTC",
    "updated_date": "2024-03-21 00:42:39 UTC"
  },
  {
    "arxiv_id": "2401.05572v1",
    "title": "Innate-Values-driven Reinforcement Learning for Cooperative Multi-Agent Systems",
    "authors": [
      "Qin Yang"
    ],
    "abstract": "Innate values describe agents' intrinsic motivations, which reflect their\ninherent interests and preferences to pursue goals and drive them to develop\ndiverse skills satisfying their various needs. The essence of reinforcement\nlearning (RL) is learning from interaction based on reward-driven (such as\nutilities) behaviors, much like natural agents. It is an excellent model to\ndescribe the innate-values-driven (IV) behaviors of AI agents. Especially in\nmulti-agent systems (MAS), building the awareness of AI agents to balance the\ngroup utilities and system costs and satisfy group members' needs in their\ncooperation is a crucial problem for individuals learning to support their\ncommunity and integrate human society in the long term. This paper proposes a\nhierarchical compound intrinsic value reinforcement learning model --\ninnate-values-driven reinforcement learning termed IVRL to describe the complex\nbehaviors of multi-agent interaction in their cooperation. We implement the\nIVRL architecture in the StarCraft Multi-Agent Challenge (SMAC) environment and\ncompare the cooperative performance within three characteristics of innate\nvalue agents (Coward, Neutral, and Reckless) through three benchmark\nmulti-agent RL algorithms: QMIX, IQL, and QTRAN. The results demonstrate that\nby organizing individual various needs rationally, the group can achieve better\nperformance with lower costs effectively.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "This paper was accepted by the 38th AAAI 2024 workshop: \"Cooperative\n  Multi-Agent Systems Decision-Making and Learning: From Individual Needs to\n  Swarm Intelligence\"",
    "pdf_url": "http://arxiv.org/pdf/2401.05572v1",
    "published_date": "2024-01-10 22:51:10 UTC",
    "updated_date": "2024-01-10 22:51:10 UTC"
  },
  {
    "arxiv_id": "2401.05570v1",
    "title": "Siamese Networks with Soft Labels for Unsupervised Lesion Detection and Patch Pretraining on Screening Mammograms",
    "authors": [
      "Kevin Van Vorst",
      "Li Shen"
    ],
    "abstract": "Self-supervised learning has become a popular way to pretrain a deep learning\nmodel and then transfer it to perform downstream tasks. However, most of these\nmethods are developed on large-scale image datasets that contain natural\nobjects with clear textures, outlines, and distinct color contrasts. It remains\nuncertain whether these methods are equally effective for medical imaging,\nwhere the regions of interest often blend subtly and indistinctly with the\nsurrounding tissues. In this study, we propose an alternative method that uses\ncontralateral mammograms to train a neural network to encode similar embeddings\nwhen a pair contains both normal images and different embeddings when a pair\ncontains normal and abnormal images. Our approach leverages the natural\nsymmetry of human body as weak labels to learn to distinguish abnormal lesions\nfrom background tissues in a fully unsupervised manner. Our findings suggest\nthat it's feasible by incorporating soft labels derived from the Euclidean\ndistances between the embeddings of the image pairs into the Siamese network\nloss. Our method demonstrates superior performance in mammogram patch\nclassification compared to existing self-supervised learning methods. This\napproach not only leverages a vast amount of image data effectively but also\nminimizes reliance on costly labels, a significant advantage particularly in\nthe field of medical imaging.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.05570v1",
    "published_date": "2024-01-10 22:27:37 UTC",
    "updated_date": "2024-01-10 22:27:37 UTC"
  },
  {
    "arxiv_id": "2401.05566v3",
    "title": "Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training",
    "authors": [
      "Evan Hubinger",
      "Carson Denison",
      "Jesse Mu",
      "Mike Lambert",
      "Meg Tong",
      "Monte MacDiarmid",
      "Tamera Lanham",
      "Daniel M. Ziegler",
      "Tim Maxwell",
      "Newton Cheng",
      "Adam Jermyn",
      "Amanda Askell",
      "Ansh Radhakrishnan",
      "Cem Anil",
      "David Duvenaud",
      "Deep Ganguli",
      "Fazl Barez",
      "Jack Clark",
      "Kamal Ndousse",
      "Kshitij Sachan",
      "Michael Sellitto",
      "Mrinank Sharma",
      "Nova DasSarma",
      "Roger Grosse",
      "Shauna Kravec",
      "Yuntao Bai",
      "Zachary Witten",
      "Marina Favaro",
      "Jan Brauner",
      "Holden Karnofsky",
      "Paul Christiano",
      "Samuel R. Bowman",
      "Logan Graham",
      "Jared Kaplan",
      "Sören Mindermann",
      "Ryan Greenblatt",
      "Buck Shlegeris",
      "Nicholas Schiefer",
      "Ethan Perez"
    ],
    "abstract": "Humans are capable of strategically deceptive behavior: behaving helpfully in\nmost situations, but then behaving very differently in order to pursue\nalternative objectives when given the opportunity. If an AI system learned such\na deceptive strategy, could we detect it and remove it using current\nstate-of-the-art safety training techniques? To study this question, we\nconstruct proof-of-concept examples of deceptive behavior in large language\nmodels (LLMs). For example, we train models that write secure code when the\nprompt states that the year is 2023, but insert exploitable code when the\nstated year is 2024. We find that such backdoor behavior can be made\npersistent, so that it is not removed by standard safety training techniques,\nincluding supervised fine-tuning, reinforcement learning, and adversarial\ntraining (eliciting unsafe behavior and then training to remove it). The\nbackdoor behavior is most persistent in the largest models and in models\ntrained to produce chain-of-thought reasoning about deceiving the training\nprocess, with the persistence remaining even when the chain-of-thought is\ndistilled away. Furthermore, rather than removing backdoors, we find that\nadversarial training can teach models to better recognize their backdoor\ntriggers, effectively hiding the unsafe behavior. Our results suggest that,\nonce a model exhibits deceptive behavior, standard techniques could fail to\nremove such deception and create a false impression of safety.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.SE"
    ],
    "primary_category": "cs.CR",
    "comment": "updated to add missing acknowledgements",
    "pdf_url": "http://arxiv.org/pdf/2401.05566v3",
    "published_date": "2024-01-10 22:14:35 UTC",
    "updated_date": "2024-01-17 20:26:01 UTC"
  },
  {
    "arxiv_id": "2401.06808v1",
    "title": "Grounded learning for compositional vector semantics",
    "authors": [
      "Martha Lewis"
    ],
    "abstract": "Categorical compositional distributional semantics is an approach to\nmodelling language that combines the success of vector-based models of meaning\nwith the compositional power of formal semantics. However, this approach was\ndeveloped without an eye to cognitive plausibility. Vector representations of\nconcepts and concept binding are also of interest in cognitive science, and\nhave been proposed as a way of representing concepts within a biologically\nplausible spiking neural network. This work proposes a way for compositional\ndistributional semantics to be implemented within a spiking neural network\narchitecture, with the potential to address problems in concept binding, and\ngive a small implementation. We also describe a means of training word\nrepresentations using labelled images.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.06808v1",
    "published_date": "2024-01-10 22:12:34 UTC",
    "updated_date": "2024-01-10 22:12:34 UTC"
  },
  {
    "arxiv_id": "2401.05544v4",
    "title": "Enhancing Source Code Classification Effectiveness via Prompt Learning Incorporating Knowledge Features",
    "authors": [
      "Yong Ma",
      "Senlin Luo",
      "Yu-Ming Shang",
      "Yifei Zhang",
      "Zhengjun Li"
    ],
    "abstract": "Researchers have investigated the potential of leveraging pre-trained\nlanguage models, such as CodeBERT, to enhance source code-related tasks.\nPrevious methodologies have relied on CodeBERT's '[CLS]' token as the embedding\nrepresentation of input sequences for task performance, necessitating\nadditional neural network layers to enhance feature representation, which in\nturn increases computational expenses. These approaches have also failed to\nfully leverage the comprehensive knowledge inherent within the source code and\nits associated text, potentially limiting classification efficacy. We propose\nCodeClassPrompt, a text classification technique that harnesses prompt learning\nto extract rich knowledge associated with input sequences from pre-trained\nmodels, thereby eliminating the need for additional layers and lowering\ncomputational costs. By applying an attention mechanism, we synthesize\nmulti-layered knowledge into task-specific features, enhancing classification\naccuracy. Our comprehensive experimentation across four distinct source\ncode-related tasks reveals that CodeClassPrompt achieves competitive\nperformance while significantly reducing computational overhead.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by Scientific Reports",
    "pdf_url": "http://arxiv.org/pdf/2401.05544v4",
    "published_date": "2024-01-10 20:49:59 UTC",
    "updated_date": "2024-08-19 23:14:59 UTC"
  },
  {
    "arxiv_id": "2401.06178v2",
    "title": "AI Art is Theft: Labour, Extraction, and Exploitation, Or, On the Dangers of Stochastic Pollocks",
    "authors": [
      "Trystan S. Goetze"
    ],
    "abstract": "Since the launch of applications such as DALL-E, Midjourney, and Stable\nDiffusion, generative artificial intelligence has been controversial as a tool\nfor creating artwork. While some have presented longtermist worries about these\ntechnologies as harbingers of fully automated futures to come, more pressing is\nthe impact of generative AI on creative labour in the present. Already,\nbusiness leaders have begun replacing human artistic labour with AI-generated\nimages. In response, the artistic community has launched a protest movement,\nwhich argues that AI image generation is a kind of theft. This paper analyzes,\nsubstantiates, and critiques these arguments, concluding that AI image\ngenerators involve an unethical kind of labour theft. If correct, many other AI\napplications also rely upon theft.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "K.4; K.7.4; I.2"
    ],
    "primary_category": "cs.CY",
    "comment": "Post-review. 18 pages. Accepted for publication in FAccT'24",
    "pdf_url": "http://arxiv.org/pdf/2401.06178v2",
    "published_date": "2024-01-10 20:20:55 UTC",
    "updated_date": "2024-05-15 13:22:52 UTC"
  },
  {
    "arxiv_id": "2401.05535v4",
    "title": "Theoretical and Empirical Advances in Forest Pruning",
    "authors": [
      "Albert Dorador"
    ],
    "abstract": "Regression forests have long delivered state-of-the-art accuracy, often\noutperforming regression trees and even neural networks, but they suffer from\nlimited interpretability as ensemble methods. In this work, we revisit forest\npruning, an approach that aims to have the best of both worlds: the accuracy of\nregression forests and the interpretability of regression trees. This pursuit,\nwhose foundation lies at the core of random forest theory, has seen vast\nsuccess in empirical studies. In this paper, we contribute theoretical results\nthat support and qualify those empirical findings; namely, we prove the\nasymptotic advantage of a Lasso-pruned forest over its unpruned counterpart\nunder weak assumptions, as well as high-probability finite-sample\ngeneralization bounds for regression forests pruned according to the main\nmethods, which we then validate by way of simulation. Then, we test the\naccuracy of pruned regression forests against their unpruned counterparts on 19\ndifferent datasets (16 synthetic, 3 real). We find that in the vast majority of\nscenarios tested, there is at least one forest-pruning method that yields equal\nor better accuracy than the original full forest (in expectation), while just\nusing a small fraction of the trees. We show that, in some cases, the reduction\nin the size of the forest is so dramatic that the resulting sub-forest can be\nmeaningfully merged into a single tree, obtaining a level of interpretability\nthat is qualitatively superior to that of the original regression forest, which\nremains a black box.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "math.OC"
    ],
    "primary_category": "stat.ML",
    "comment": "To be published in Proceedings of Machine Learning Research (PMLR)",
    "pdf_url": "http://arxiv.org/pdf/2401.05535v4",
    "published_date": "2024-01-10 20:02:47 UTC",
    "updated_date": "2025-03-06 19:11:43 UTC"
  },
  {
    "arxiv_id": "2402.01656v1",
    "title": "Promises and pitfalls of artificial intelligence for legal applications",
    "authors": [
      "Sayash Kapoor",
      "Peter Henderson",
      "Arvind Narayanan"
    ],
    "abstract": "Is AI set to redefine the legal profession? We argue that this claim is not\nsupported by the current evidence. We dive into AI's increasingly prevalent\nroles in three types of legal tasks: information processing; tasks involving\ncreativity, reasoning, or judgment; and predictions about the future. We find\nthat the ease of evaluating legal applications varies greatly across legal\ntasks, based on the ease of identifying correct answers and the observability\nof information relevant to the task at hand. Tasks that would lead to the most\nsignificant changes to the legal profession are also the ones most prone to\noveroptimism about AI capabilities, as they are harder to evaluate. We make\nrecommendations for better evaluation and deployment of AI in legal contexts.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01656v1",
    "published_date": "2024-01-10 19:50:37 UTC",
    "updated_date": "2024-01-10 19:50:37 UTC"
  },
  {
    "arxiv_id": "2402.00876v2",
    "title": "Building Blocks to Empower Cognitive Internet with Hybrid Edge Cloud",
    "authors": [
      "Siavash Alamouti",
      "Fay Arjomandi",
      "Michel Burger",
      "Bashar Altakrouri"
    ],
    "abstract": "As we transition from the mobile internet to the 'Cognitive Internet,' a\nsignificant shift occurs in how we engage with technology and intelligence. We\ncontend that the Cognitive Internet goes beyond the Cognitive Internet of\nThings (Cognitive IoT), enabling connected objects to independently acquire\nknowledge and understanding. Unlike the Mobile Internet and Cognitive IoT, the\nCognitive Internet integrates collaborative intelligence throughout the\nnetwork, blending the cognitive IoT realm with system-wide collaboration and\nhuman intelligence. This integrated intelligence facilitates interactions\nbetween devices, services, entities, and individuals across diverse domains\nwhile preserving decision-making autonomy and accommodating various identities.\n  The paper delves into the foundational elements, distinct characteristics,\nbenefits, and industrial impact of the 'Cognitive Internet' paradigm. It\nhighlights the importance of adaptable AI infrastructures and hybrid edge cloud\n(HEC) platforms in enabling this shift. This evolution brings forth cognitive\nservices, a Knowledge as a Service (KaaS) economy, enhanced decision-making\nautonomy, sustainable digital progress, advancements in data management,\nprocessing techniques, and a stronger emphasis on privacy. In essence, this\npaper serves as a crucial resource for understanding and leveraging the\ntransformative potential of HEC for Cognitive Internet. Supported by case\nstudies, forward-looking perspectives, and real-world applications, it provides\ncomprehensive insights into this emerging paradigm.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00876v2",
    "published_date": "2024-01-10 19:43:52 UTC",
    "updated_date": "2024-02-05 15:02:17 UTC"
  },
  {
    "arxiv_id": "2401.05521v1",
    "title": "Current Effect-eliminated Optimal Target Assignment and Motion Planning for a Multi-UUV System",
    "authors": [
      "Danjie Zhu",
      "Simon X. Yang"
    ],
    "abstract": "The paper presents an innovative approach (CBNNTAP) that addresses the\ncomplexities and challenges introduced by ocean currents when optimizing target\nassignment and motion planning for a multi-unmanned underwater vehicle (UUV)\nsystem. The core of the proposed algorithm involves the integration of several\nkey components. Firstly, it incorporates a bio-inspired neural network-based\n(BINN) approach which predicts the most efficient paths for individual UUVs\nwhile simultaneously ensuring collision avoidance among the vehicles. Secondly,\nan efficient target assignment component is integrated by considering the path\ndistances determined by the BINN algorithm. In addition, a critical innovation\nwithin the CBNNTAP algorithm is its capacity to address the disruptive effects\nof ocean currents, where an adjustment component is seamlessly integrated to\ncounteract the deviations caused by these currents, which enhances the accuracy\nof both motion planning and target assignment for the UUVs. The effectiveness\nof the CBNNTAP algorithm is demonstrated through comprehensive simulation\nresults and the outcomes underscore the superiority of the developed algorithm\nin nullifying the effects of static and dynamic ocean currents in 2D and 3D\nscenarios.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "This paper was accepted by IEEE Transactions on Intelligent\n  Transportation Systems",
    "pdf_url": "http://arxiv.org/pdf/2401.05521v1",
    "published_date": "2024-01-10 19:38:25 UTC",
    "updated_date": "2024-01-10 19:38:25 UTC"
  },
  {
    "arxiv_id": "2401.05520v1",
    "title": "From Pampas to Pixels: Fine-Tuning Diffusion Models for Gaúcho Heritage",
    "authors": [
      "Marcellus Amadeus",
      "William Alberto Cruz Castañeda",
      "André Felipe Zanella",
      "Felipe Rodrigues Perche Mahlow"
    ],
    "abstract": "Generative AI has become pervasive in society, witnessing significant\nadvancements in various domains. Particularly in the realm of Text-to-Image\n(TTI) models, Latent Diffusion Models (LDMs), showcase remarkable capabilities\nin generating visual content based on textual prompts. This paper addresses the\npotential of LDMs in representing local cultural concepts, historical figures,\nand endangered species. In this study, we use the cultural heritage of Rio\nGrande do Sul (RS), Brazil, as an illustrative case. Our objective is to\ncontribute to the broader understanding of how generative models can help to\ncapture and preserve the cultural and historical identity of regions. The paper\noutlines the methodology, including subject selection, dataset creation, and\nthe fine-tuning process. The results showcase the images generated, alongside\nthe challenges and feasibility of each concept. In conclusion, this work shows\nthe power of these models to represent and preserve unique aspects of diverse\nregions and communities.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.05520v1",
    "published_date": "2024-01-10 19:34:52 UTC",
    "updated_date": "2024-01-10 19:34:52 UTC"
  },
  {
    "arxiv_id": "2401.05518v1",
    "title": "Correlated Quantization for Faster Nonconvex Distributed Optimization",
    "authors": [
      "Andrei Panferov",
      "Yury Demidovich",
      "Ahmad Rammal",
      "Peter Richtárik"
    ],
    "abstract": "Quantization (Alistarh et al., 2017) is an important (stochastic) compression\ntechnique that reduces the volume of transmitted bits during each communication\nround in distributed model training. Suresh et al. (2022) introduce correlated\nquantizers and show their advantages over independent counterparts by analyzing\ndistributed SGD communication complexity. We analyze the forefront distributed\nnon-convex optimization algorithm MARINA (Gorbunov et al., 2022) utilizing the\nproposed correlated quantizers and show that it outperforms the original MARINA\nand distributed SGD of Suresh et al. (2022) with regard to the communication\ncomplexity. We significantly refine the original analysis of MARINA without any\nadditional assumptions using the weighted Hessian variance (Tyurin et al.,\n2022), and then we expand the theoretical framework of MARINA to accommodate a\nsubstantially broader range of potentially correlated and biased compressors,\nthus dilating the applicability of the method beyond the conventional\nindependent unbiased compressor setup. Extensive experimental results\ncorroborate our theoretical findings.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.05518v1",
    "published_date": "2024-01-10 19:29:17 UTC",
    "updated_date": "2024-01-10 19:29:17 UTC"
  },
  {
    "arxiv_id": "2401.05516v1",
    "title": "FPRF: Feed-Forward Photorealistic Style Transfer of Large-Scale 3D Neural Radiance Fields",
    "authors": [
      "GeonU Kim",
      "Kim Youwang",
      "Tae-Hyun Oh"
    ],
    "abstract": "We present FPRF, a feed-forward photorealistic style transfer method for\nlarge-scale 3D neural radiance fields. FPRF stylizes large-scale 3D scenes with\narbitrary, multiple style reference images without additional optimization\nwhile preserving multi-view appearance consistency. Prior arts required tedious\nper-style/-scene optimization and were limited to small-scale 3D scenes. FPRF\nefficiently stylizes large-scale 3D scenes by introducing a style-decomposed 3D\nneural radiance field, which inherits AdaIN's feed-forward stylization\nmachinery, supporting arbitrary style reference images. Furthermore, FPRF\nsupports multi-reference stylization with the semantic correspondence matching\nand local AdaIN, which adds diverse user control for 3D scene styles. FPRF also\npreserves multi-view consistency by applying semantic matching and style\ntransfer processes directly onto queried features in 3D space. In experiments,\nwe demonstrate that FPRF achieves favorable photorealistic quality 3D scene\nstylization for large-scale scenes with diverse reference images. Project page:\nhttps://kim-geonu.github.io/FPRF/",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page: https://kim-geonu.github.io/FPRF/",
    "pdf_url": "http://arxiv.org/pdf/2401.05516v1",
    "published_date": "2024-01-10 19:27:28 UTC",
    "updated_date": "2024-01-10 19:27:28 UTC"
  },
  {
    "arxiv_id": "2402.01655v1",
    "title": "A Deep Learning Approach Towards Student Performance Prediction in Online Courses: Challenges Based on a Global Perspective",
    "authors": [
      "Abdallah Moubayed",
      "MohammadNoor Injadat",
      "Nouh Alhindawi",
      "Ghassan Samara",
      "Sara Abuasal",
      "Raed Alazaidah"
    ],
    "abstract": "Analyzing and evaluating students' progress in any learning environment is\nstressful and time consuming if done using traditional analysis methods. This\nis further exasperated by the increasing number of students due to the shift of\nfocus toward integrating the Internet technologies in education and the focus\nof academic institutions on moving toward e-Learning, blended, or online\nlearning models. As a result, the topic of student performance prediction has\nbecome a vibrant research area in recent years. To address this, machine\nlearning and data mining techniques have emerged as a viable solution. To that\nend, this work proposes the use of deep learning techniques (CNN and RNN-LSTM)\nto predict the students' performance at the midpoint stage of the online course\ndelivery using three distinct datasets collected from three different regions\nof the world. Experimental results show that deep learning models have\npromising performance as they outperform other optimized traditional ML models\nin two of the three considered datasets while also having comparable\nperformance for the third dataset.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "Accepted and presented in 24th International Arab Conference on\n  Information Technology (ACIT'2023)",
    "pdf_url": "http://arxiv.org/pdf/2402.01655v1",
    "published_date": "2024-01-10 19:13:19 UTC",
    "updated_date": "2024-01-10 19:13:19 UTC"
  },
  {
    "arxiv_id": "2401.05509v1",
    "title": "Optimized Ensemble Model Towards Secured Industrial IoT Devices",
    "authors": [
      "MohammadNoor Injadat"
    ],
    "abstract": "The continued growth in the deployment of Internet-of-Things (IoT) devices\nhas been fueled by the increased connectivity demand, particularly in\nindustrial environments. However, this has led to an increase in the number of\nnetwork related attacks due to the increased number of potential attack\nsurfaces. Industrial IoT (IIoT) devices are prone to various network related\nattacks that can have severe consequences on the manufacturing process as well\nas on the safety of the workers in the manufacturing plant. One promising\nsolution that has emerged in recent years for attack detection is Machine\nlearning (ML). More specifically, ensemble learning models have shown great\npromise in improving the performance of the underlying ML models. Accordingly,\nthis paper proposes a framework based on the combined use of Bayesian\nOptimization-Gaussian Process (BO-GP) with an ensemble tree-based learning\nmodel to improve the performance of intrusion and attack detection in IIoT\nenvironments. The proposed framework's performance is evaluated using the\nWindows 10 dataset collected by the Cyber Range and IoT labs at University of\nNew South Wales. Experimental results illustrate the improvement in detection\naccuracy, precision, and F-score when compared to standard tree and ensemble\ntree models.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted and presented in 24th International Arab Conference on\n  Information Technology (ACIT'2023)",
    "pdf_url": "http://arxiv.org/pdf/2401.05509v1",
    "published_date": "2024-01-10 19:06:39 UTC",
    "updated_date": "2024-01-10 19:06:39 UTC"
  },
  {
    "arxiv_id": "2401.06807v1",
    "title": "An EcoSage Assistant: Towards Building A Multimodal Plant Care Dialogue Assistant",
    "authors": [
      "Mohit Tomar",
      "Abhisek Tiwari",
      "Tulika Saha",
      "Prince Jha",
      "Sriparna Saha"
    ],
    "abstract": "In recent times, there has been an increasing awareness about imminent\nenvironmental challenges, resulting in people showing a stronger dedication to\ntaking care of the environment and nurturing green life. The current $19.6\nbillion indoor gardening industry, reflective of this growing sentiment, not\nonly signifies a monetary value but also speaks of a profound human desire to\nreconnect with the natural world. However, several recent surveys cast a\nrevealing light on the fate of plants within our care, with more than half\nsuccumbing primarily due to the silent menace of improper care. Thus, the need\nfor accessible expertise capable of assisting and guiding individuals through\nthe intricacies of plant care has become paramount more than ever. In this\nwork, we make the very first attempt at building a plant care assistant, which\naims to assist people with plant(-ing) concerns through conversations. We\npropose a plant care conversational dataset named Plantational, which contains\naround 1K dialogues between users and plant care experts. Our end-to-end\nproposed approach is two-fold : (i) We first benchmark the dataset with the\nhelp of various large language models (LLMs) and visual language model (VLM) by\nstudying the impact of instruction tuning (zero-shot and few-shot prompting)\nand fine-tuning techniques on this task; (ii) finally, we build EcoSage, a\nmulti-modal plant care assisting dialogue generation framework, incorporating\nan adapter-based modality infusion using a gated mechanism. We performed an\nextensive examination (both automated and manual evaluation) of the performance\nexhibited by various LLMs and VLM in the generation of the domain-specific\ndialogue responses to underscore the respective strengths and weaknesses of\nthese diverse models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.06807v1",
    "published_date": "2024-01-10 19:06:35 UTC",
    "updated_date": "2024-01-10 19:06:35 UTC"
  },
  {
    "arxiv_id": "2401.05507v3",
    "title": "InfiAgent-DABench: Evaluating Agents on Data Analysis Tasks",
    "authors": [
      "Xueyu Hu",
      "Ziyu Zhao",
      "Shuang Wei",
      "Ziwei Chai",
      "Qianli Ma",
      "Guoyin Wang",
      "Xuwu Wang",
      "Jing Su",
      "Jingjing Xu",
      "Ming Zhu",
      "Yao Cheng",
      "Jianbo Yuan",
      "Jiwei Li",
      "Kun Kuang",
      "Yang Yang",
      "Hongxia Yang",
      "Fei Wu"
    ],
    "abstract": "In this paper, we introduce InfiAgent-DABench, the first benchmark\nspecifically designed to evaluate LLM-based agents on data analysis tasks.\nThese tasks require agents to end-to-end solving complex tasks by interacting\nwith an execution environment. This benchmark contains DAEval, a dataset\nconsisting of 257 data analysis questions derived from 52 CSV files, and an\nagent framework which incorporates LLMs to serve as data analysis agents for\nboth serving and evaluation. Since data analysis questions are often open-ended\nand hard to evaluate without human supervision, we adopt a format-prompting\ntechnique to convert each question into a closed-form format so that they can\nbe automatically evaluated. Our extensive benchmarking of 34 LLMs uncovers the\ncurrent challenges encountered in data analysis tasks. In addition, building on\ntop of our agent framework, we develop a specialized agent, DAAgent, which\nsurpasses GPT-3.5 by 3.9% on DABench. Evaluation datasets and toolkits for\nInfiAgent-DABench are released at https://github.com/InfiAgent/InfiAgent .",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "27 pages, 7 figures, work in progress",
    "pdf_url": "http://arxiv.org/pdf/2401.05507v3",
    "published_date": "2024-01-10 19:04:00 UTC",
    "updated_date": "2024-03-11 07:57:59 UTC"
  },
  {
    "arxiv_id": "2401.05502v1",
    "title": "Diversity-aware clustering: Computational Complexity and Approximation Algorithms",
    "authors": [
      "Suhas Thejaswi",
      "Ameet Gadekar",
      "Bruno Ordozgoiti",
      "Aristides Gionis"
    ],
    "abstract": "In this work, we study diversity-aware clustering problems where the data\npoints are associated with multiple attributes resulting in intersecting\ngroups. A clustering solution need to ensure that a minimum number of cluster\ncenters are chosen from each group while simultaneously minimizing the\nclustering objective, which can be either $k$-median, $k$-means or\n$k$-supplier. We present parameterized approximation algorithms with\napproximation ratios $1+ \\frac{2}{e}$, $1+\\frac{8}{e}$ and $3$ for\ndiversity-aware $k$-median, diversity-aware $k$-means and diversity-aware\n$k$-supplier, respectively. The approximation ratios are tight assuming Gap-ETH\nand FPT $\\neq$ W[2]. For fair $k$-median and fair $k$-means with disjoint\nfaicility groups, we present parameterized approximation algorithm with\napproximation ratios $1+\\frac{2}{e}$ and $1+\\frac{8}{e}$, respectively. For\nfair $k$-supplier with disjoint facility groups, we present a polynomial-time\napproximation algorithm with factor $3$, improving the previous best known\napproximation ratio of factor $5$.",
    "categories": [
      "cs.DS",
      "cs.AI",
      "cs.CC",
      "cs.LG"
    ],
    "primary_category": "cs.DS",
    "comment": "Algorithmic Fairness, Fair Clustering, Diversity-aware Clustering,\n  Intersectionaly, Subgroup fairness",
    "pdf_url": "http://arxiv.org/pdf/2401.05502v1",
    "published_date": "2024-01-10 19:01:05 UTC",
    "updated_date": "2024-01-10 19:01:05 UTC"
  },
  {
    "arxiv_id": "2401.06806v1",
    "title": "AugSumm: towards generalizable speech summarization using synthetic labels from large language model",
    "authors": [
      "Jee-weon Jung",
      "Roshan Sharma",
      "William Chen",
      "Bhiksha Raj",
      "Shinji Watanabe"
    ],
    "abstract": "Abstractive speech summarization (SSUM) aims to generate human-like summaries\nfrom speech. Given variations in information captured and phrasing, recordings\ncan be summarized in multiple ways. Therefore, it is more reasonable to\nconsider a probabilistic distribution of all potential summaries rather than a\nsingle summary. However, conventional SSUM models are mostly trained and\nevaluated with a single ground-truth (GT) human-annotated deterministic summary\nfor every recording. Generating multiple human references would be ideal to\nbetter represent the distribution statistically, but is impractical because\nannotation is expensive. We tackle this challenge by proposing AugSumm, a\nmethod to leverage large language models (LLMs) as a proxy for human annotators\nto generate augmented summaries for training and evaluation. First, we explore\nprompting strategies to generate synthetic summaries from ChatGPT. We validate\nthe quality of synthetic summaries using multiple metrics including human\nevaluation, where we find that summaries generated using AugSumm are perceived\nas more valid to humans. Second, we develop methods to utilize synthetic\nsummaries in training and evaluation. Experiments on How2 demonstrate that\npre-training on synthetic summaries and fine-tuning on GT summaries improves\nROUGE-L by 1 point on both GT and AugSumm-based test sets. AugSumm summaries\nare available at https://github.com/Jungjee/AugSumm.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "This work has been submitted to the IEEE ICASSP for possible\n  publication. 5 pages",
    "pdf_url": "http://arxiv.org/pdf/2401.06806v1",
    "published_date": "2024-01-10 18:39:46 UTC",
    "updated_date": "2024-01-10 18:39:46 UTC"
  },
  {
    "arxiv_id": "2401.05302v2",
    "title": "Theory of Mind abilities of Large Language Models in Human-Robot Interaction : An Illusion?",
    "authors": [
      "Mudit Verma",
      "Siddhant Bhambri",
      "Subbarao Kambhampati"
    ],
    "abstract": "Large Language Models have shown exceptional generative abilities in various\nnatural language and generation tasks. However, possible anthropomorphization\nand leniency towards failure cases have propelled discussions on emergent\nabilities of Large Language Models especially on Theory of Mind (ToM) abilities\nin Large Language Models. While several false-belief tests exists to verify the\nability to infer and maintain mental models of another entity, we study a\nspecial application of ToM abilities that has higher stakes and possibly\nirreversible consequences : Human Robot Interaction. In this work, we explore\nthe task of Perceived Behavior Recognition, where a robot employs a Large\nLanguage Model (LLM) to assess the robot's generated behavior in a manner\nsimilar to human observer. We focus on four behavior types, namely -\nexplicable, legible, predictable, and obfuscatory behavior which have been\nextensively used to synthesize interpretable robot behaviors. The LLMs goal is,\ntherefore to be a human proxy to the agent, and to answer how a certain agent\nbehavior would be perceived by the human in the loop, for example \"Given a\nrobot's behavior X, would the human observer find it explicable?\". We conduct a\nhuman subject study to verify that the users are able to correctly answer such\na question in the curated situations (robot setting and plan) across five\ndomains. A first analysis of the belief test yields extremely positive results\ninflating ones expectations of LLMs possessing ToM abilities. We then propose\nand perform a suite of perturbation tests which breaks this illusion, i.e.\nInconsistent Belief, Uninformative Context and Conviction Test. We conclude\nthat, the high score of LLMs on vanilla prompts showcases its potential use in\nHRI settings, however to possess ToM demands invariance to trivial or\nirrelevant perturbations in the context which LLMs lack.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted in alt.HRI 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.05302v2",
    "published_date": "2024-01-10 18:09:36 UTC",
    "updated_date": "2024-01-17 18:45:39 UTC"
  },
  {
    "arxiv_id": "2401.05300v2",
    "title": "I am a Strange Dataset: Metalinguistic Tests for Language Models",
    "authors": [
      "Tristan Thrush",
      "Jared Moore",
      "Miguel Monares",
      "Christopher Potts",
      "Douwe Kiela"
    ],
    "abstract": "Statements involving metalinguistic self-reference (\"This paper has six\nsections.\") are prevalent in many domains. Can current large language models\n(LLMs) handle such language? In this paper, we present \"I am a Strange\nDataset\", a new dataset for addressing this question. There are two subtasks:\ngeneration and verification. In generation, models continue statements like\n\"The penultimate word in this sentence is\" (where a correct continuation is\n\"is\"). In verification, models judge the truth of statements like \"The\npenultimate word in this sentence is sentence.\" (false). We also provide\nminimally different metalinguistic non-self-reference examples to complement\nthe main dataset by probing for whether models can handle metalinguistic\nlanguage at all. The dataset is hand-crafted by experts and validated by\nnon-expert annotators. We test a variety of open-source LLMs (7B to 70B\nparameters) as well as closed-source LLMs through APIs. All models perform\nclose to chance across both subtasks and even on the non-self-referential\nmetalinguistic control data, though we find some steady improvement with model\nscale. GPT 4 is the only model to consistently do significantly better than\nchance, and it is still only in the 60% range, while our untrained human\nannotators score well in the 89-93% range. The dataset and evaluation toolkit\nare available at https://github.com/TristanThrush/i-am-a-strange-dataset.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.05300v2",
    "published_date": "2024-01-10 18:06:27 UTC",
    "updated_date": "2024-08-06 19:24:42 UTC"
  },
  {
    "arxiv_id": "2401.05478v1",
    "title": "Population Graph Cross-Network Node Classification for Autism Detection Across Sample Groups",
    "authors": [
      "Anna Stephens",
      "Francisco Santos",
      "Pang-Ning Tan",
      "Abdol-Hossein Esfahanian"
    ],
    "abstract": "Graph neural networks (GNN) are a powerful tool for combining imaging and\nnon-imaging medical information for node classification tasks. Cross-network\nnode classification extends GNN techniques to account for domain drift,\nallowing for node classification on an unlabeled target network. In this paper\nwe present OTGCN, a powerful, novel approach to cross-network node\nclassification. This approach leans on concepts from graph convolutional\nnetworks to harness insights from graph data structures while simultaneously\napplying strategies rooted in optimal transport to correct for the domain drift\nthat can occur between samples from different data collection sites. This\nblended approach provides a practical solution for scenarios with many distinct\nforms of data collected across different locations and equipment. We\ndemonstrate the effectiveness of this approach at classifying Autism Spectrum\nDisorder subjects using a blend of imaging and non-imaging data.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SI",
    "comment": "To appear ICDM DMBIH workshop 2023",
    "pdf_url": "http://arxiv.org/pdf/2401.05478v1",
    "published_date": "2024-01-10 18:04:12 UTC",
    "updated_date": "2024-01-10 18:04:12 UTC"
  },
  {
    "arxiv_id": "2401.05477v1",
    "title": "Standardizing Your Training Process for Human Activity Recognition Models: A Comprehensive Review in the Tunable Factors",
    "authors": [
      "Yiran Huang",
      "Haibin Zhao",
      "Yexu Zhou",
      "Till Riedel",
      "Michael Beigl"
    ],
    "abstract": "In recent years, deep learning has emerged as a potent tool across a\nmultitude of domains, leading to a surge in research pertaining to its\napplication in the wearable human activity recognition (WHAR) domain. Despite\nthe rapid development, concerns have been raised about the lack of\nstandardization and consistency in the procedures used for experimental model\ntraining, which may affect the reproducibility and reliability of research\nresults. In this paper, we provide an exhaustive review of contemporary deep\nlearning research in the field of WHAR and collate information pertaining to\nthe training procedure employed in various studies. Our findings suggest that a\nmajor trend is the lack of detail provided by model training protocols.\nBesides, to gain a clearer understanding of the impact of missing descriptions,\nwe utilize a control variables approach to assess the impact of key tunable\ncomponents (e.g., optimization techniques and early stopping criteria) on the\ninter-subject generalization capabilities of HAR models. With insights from the\nanalyses, we define a novel integrated training procedure tailored to the WHAR\nmodel. Empirical results derived using five well-known \\ac{whar} benchmark\ndatasets and three classical HAR model architectures demonstrate the\neffectiveness of our proposed methodology: in particular, there is a\nsignificant improvement in macro F1 leave one subject out cross-validation\nperformance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.05477v1",
    "published_date": "2024-01-10 17:45:28 UTC",
    "updated_date": "2024-01-10 17:45:28 UTC"
  },
  {
    "arxiv_id": "2401.05476v1",
    "title": "CADgpt: Harnessing Natural Language Processing for 3D Modelling to Enhance Computer-Aided Design Workflows",
    "authors": [
      "Timo Kapsalis"
    ],
    "abstract": "This paper introduces CADgpt, an innovative plugin integrating Natural\nLanguage Processing (NLP) with Rhino3D for enhancing 3D modelling in\ncomputer-aided design (CAD) environments. Leveraging OpenAI's GPT-4, CADgpt\nsimplifies the CAD interface, enabling users, particularly beginners, to\nperform complex 3D modelling tasks through intuitive natural language commands.\nThis approach significantly reduces the learning curve associated with\ntraditional CAD software, fostering a more inclusive and engaging educational\nenvironment. The paper discusses CADgpt's technical architecture, including its\nintegration within Rhino3D and the adaptation of GPT-4 capabilities for CAD\ntasks. It presents case studies demonstrating CADgpt's efficacy in various\ndesign scenarios, highlighting its potential to democratise design education by\nmaking sophisticated design tools accessible to a broader range of students.\nThe discussion further explores CADgpt's implications for pedagogy and\ncurriculum development, emphasising its role in enhancing creative exploration\nand conceptual thinking in design education.\n  Keywords: Natural Language Processing, Computer-Aided Design, 3D Modelling,\nDesign Automation, Design Education, Architectural Education",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.HC",
    "comment": "10 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2401.05476v1",
    "published_date": "2024-01-10 17:32:32 UTC",
    "updated_date": "2024-01-10 17:32:32 UTC"
  },
  {
    "arxiv_id": "2402.00874v1",
    "title": "dRG-MEC: Decentralized Reinforced Green Offloading for MEC-enabled Cloud Network",
    "authors": [
      "Asad Aftab",
      "Semeen Rehman"
    ],
    "abstract": "Multi-access-Mobile Edge Computing (MEC) is a promising solution for\ncomputationally demanding rigorous applications, that can meet 6G network\nservice requirements. However, edge servers incur high computation costs during\ntask processing. In this paper, we proposed a technique to minimize the total\ncomputation and communication overhead for optimal resource utilization with\njoint computational offloading that enables a green environment. Our\noptimization problem is NP-hard; thus, we proposed a decentralized\nReinforcement Learning (dRL) approach where we eliminate the problem of\ndimensionality and over-estimation of the value functions. Compared to baseline\nschemes our technique achieves a 37.03% reduction in total system costs.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.00874v1",
    "published_date": "2024-01-10 17:21:20 UTC",
    "updated_date": "2024-01-10 17:21:20 UTC"
  },
  {
    "arxiv_id": "2401.05273v3",
    "title": "INACIA: Integrating Large Language Models in Brazilian Audit Courts: Opportunities and Challenges",
    "authors": [
      "Jayr Pereira",
      "Andre Assumpcao",
      "Julio Trecenti",
      "Luiz Airosa",
      "Caio Lente",
      "Jhonatan Cléto",
      "Guilherme Dobins",
      "Rodrigo Nogueira",
      "Luis Mitchell",
      "Roberto Lotufo"
    ],
    "abstract": "This paper introduces INACIA (Instru\\c{c}\\~ao Assistida com Intelig\\^encia\nArtificial), a groundbreaking system designed to integrate Large Language\nModels (LLMs) into the operational framework of Brazilian Federal Court of\nAccounts (TCU). The system automates various stages of case analysis, including\nbasic information extraction, admissibility examination, Periculum in mora and\nFumus boni iuris analyses, and recommendations generation. Through a series of\nexperiments, we demonstrate INACIA's potential in extracting relevant\ninformation from case documents, evaluating its legal plausibility, and\nformulating propositions for judicial decision-making. Utilizing a validation\ndataset alongside LLMs, our evaluation methodology presents a novel approach to\nassessing system performance, correlating highly with human judgment. These\nresults underscore INACIA's potential in complex legal task handling while also\nacknowledging the current limitations. This study discusses possible\nimprovements and the broader implications of applying AI in legal contexts,\nsuggesting that INACIA represents a significant step towards integrating AI in\nlegal systems globally, albeit with cautious optimism grounded in the empirical\nfindings.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.05273v3",
    "published_date": "2024-01-10 17:13:28 UTC",
    "updated_date": "2024-02-26 17:22:21 UTC"
  },
  {
    "arxiv_id": "2401.05268v4",
    "title": "AutoAct: Automatic Agent Learning from Scratch for QA via Self-Planning",
    "authors": [
      "Shuofei Qiao",
      "Ningyu Zhang",
      "Runnan Fang",
      "Yujie Luo",
      "Wangchunshu Zhou",
      "Yuchen Eleanor Jiang",
      "Chengfei Lv",
      "Huajun Chen"
    ],
    "abstract": "Language agents have achieved considerable performance on various complex\nquestion-answering tasks by planning with external tools. Despite the incessant\nexploration in this field, existing language agent systems still struggle with\ncostly, non-reproducible data reliance and face the challenge of compelling a\nsingle model for multiple functions. To this end, we introduce AutoAct, an\nautomatic agent learning framework for QA that does not rely on large-scale\nannotated data and synthetic planning trajectories from closed-source models\n(e.g., GPT-4). Given limited data with a tool library, AutoAct first\nautomatically synthesizes planning trajectories without any assistance from\nhumans or strong closed-source models. Then, AutoAct leverages a\ndivision-of-labor strategy to automatically differentiate based on the target\ntask information and synthesized trajectories, producing a sub-agent group to\ncomplete the task. We conduct comprehensive experiments with different LLMs,\nwhich demonstrates that AutoAct yields better or parallel performance compared\nto various strong baselines. Further analysis demonstrates the effectiveness of\nthe division-of-labor strategy, with the trajectory quality generated by\nAutoAct generally outperforming that of others. Code will be available at\nhttps://github.com/zjunlp/AutoAct.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.05268v4",
    "published_date": "2024-01-10 16:57:24 UTC",
    "updated_date": "2024-05-26 15:31:24 UTC"
  },
  {
    "arxiv_id": "2401.05251v1",
    "title": "ReACT: Reinforcement Learning for Controller Parametrization using B-Spline Geometries",
    "authors": [
      "Thomas Rudolf",
      "Daniel Flögel",
      "Tobias Schürmann",
      "Simon Süß",
      "Stefan Schwab",
      "Sören Hohmann"
    ],
    "abstract": "Robust and performant controllers are essential for industrial applications.\nHowever, deriving controller parameters for complex and nonlinear systems is\nchallenging and time-consuming. To facilitate automatic controller\nparametrization, this work presents a novel approach using deep reinforcement\nlearning (DRL) with N-dimensional B-spline geometries (BSGs). We focus on the\ncontrol of parameter-variant systems, a class of systems with complex behavior\nwhich depends on the operating conditions. For this system class,\ngain-scheduling control structures are widely used in applications across\nindustries due to well-known design principles. Facilitating the expensive\ncontroller parametrization task regarding these control structures, we deploy\nan DRL agent. Based on control system observations, the agent autonomously\ndecides how to adapt the controller parameters. We make the adaptation process\nmore efficient by introducing BSGs to map the controller parameters which may\ndepend on numerous operating conditions. To preprocess time-series data and\nextract a fixed-length feature vector, we use a long short-term memory (LSTM)\nneural networks. Furthermore, this work contributes actor regularizations that\nare relevant to real-world environments which differ from training.\nAccordingly, we apply dropout layer normalization to the actor and critic\nnetworks of the truncated quantile critic (TQC) algorithm. To show our\napproach's working principle and effectiveness, we train and evaluate the DRL\nagent on the parametrization task of an industrial control structure with\nparameter lookup tables.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "7 pages, 7 figures, accepted at the 2023 IEEE International\n  Conference on Systems, Man, and Cybernetics (SMC), Honolulu, HI, USA",
    "pdf_url": "http://arxiv.org/pdf/2401.05251v1",
    "published_date": "2024-01-10 16:27:30 UTC",
    "updated_date": "2024-01-10 16:27:30 UTC"
  },
  {
    "arxiv_id": "2401.05224v2",
    "title": "Do Vision and Language Encoders Represent the World Similarly?",
    "authors": [
      "Mayug Maniparambil",
      "Raiymbek Akshulakov",
      "Yasser Abdelaziz Dahou Djilali",
      "Sanath Narayan",
      "Mohamed El Amine Seddik",
      "Karttikeya Mangalam",
      "Noel E. O'Connor"
    ],
    "abstract": "Aligned text-image encoders such as CLIP have become the de facto model for\nvision-language tasks. Furthermore, modality-specific encoders achieve\nimpressive performances in their respective domains. This raises a central\nquestion: does an alignment exist between uni-modal vision and language\nencoders since they fundamentally represent the same physical world? Analyzing\nthe latent spaces structure of vision and language models on image-caption\nbenchmarks using the Centered Kernel Alignment (CKA), we find that the\nrepresentation spaces of unaligned and aligned encoders are semantically\nsimilar. In the absence of statistical similarity in aligned encoders like\nCLIP, we show that a possible matching of unaligned encoders exists without any\ntraining. We frame this as a seeded graph-matching problem exploiting the\nsemantic similarity between graphs and propose two methods - a Fast Quadratic\nAssignment Problem optimization, and a novel localized CKA metric-based\nmatching/retrieval. We demonstrate the effectiveness of this on several\ndownstream tasks including cross-lingual, cross-domain caption matching and\nimage classification. Code available at github.com/mayug/0-shot-llm-vision.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted CVPR 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.05224v2",
    "published_date": "2024-01-10 15:51:39 UTC",
    "updated_date": "2024-03-22 18:39:41 UTC"
  },
  {
    "arxiv_id": "2401.05219v1",
    "title": "Distributed Monitoring for Data Distribution Shifts in Edge-ML Fraud Detection",
    "authors": [
      "Nader Karayanni",
      "Robert J. Shahla",
      "Chieh-Lien Hsiao"
    ],
    "abstract": "The digital era has seen a marked increase in financial fraud. edge ML\nemerged as a promising solution for smartphone payment services fraud\ndetection, enabling the deployment of ML models directly on edge devices. This\napproach enables a more personalized real-time fraud detection. However, a\nsignificant gap in current research is the lack of a robust system for\nmonitoring data distribution shifts in these distributed edge ML applications.\nOur work bridges this gap by introducing a novel open-source framework designed\nfor continuous monitoring of data distribution shifts on a network of edge\ndevices. Our system includes an innovative calculation of the\nKolmogorov-Smirnov (KS) test over a distributed network of edge devices,\nenabling efficient and accurate monitoring of users behavior shifts. We\ncomprehensively evaluate the proposed framework employing both real-world and\nsynthetic financial transaction datasets and demonstrate the framework's\neffectiveness.",
    "categories": [
      "cs.CE",
      "cs.AI"
    ],
    "primary_category": "cs.CE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.05219v1",
    "published_date": "2024-01-10 15:38:00 UTC",
    "updated_date": "2024-01-10 15:38:00 UTC"
  },
  {
    "arxiv_id": "2401.06805v2",
    "title": "Exploring the Reasoning Abilities of Multimodal Large Language Models (MLLMs): A Comprehensive Survey on Emerging Trends in Multimodal Reasoning",
    "authors": [
      "Yiqi Wang",
      "Wentao Chen",
      "Xiaotian Han",
      "Xudong Lin",
      "Haiteng Zhao",
      "Yongfei Liu",
      "Bohan Zhai",
      "Jianbo Yuan",
      "Quanzeng You",
      "Hongxia Yang"
    ],
    "abstract": "Strong Artificial Intelligence (Strong AI) or Artificial General Intelligence\n(AGI) with abstract reasoning ability is the goal of next-generation AI. Recent\nadvancements in Large Language Models (LLMs), along with the emerging field of\nMultimodal Large Language Models (MLLMs), have demonstrated impressive\ncapabilities across a wide range of multimodal tasks and applications.\nParticularly, various MLLMs, each with distinct model architectures, training\ndata, and training stages, have been evaluated across a broad range of MLLM\nbenchmarks. These studies have, to varying degrees, revealed different aspects\nof the current capabilities of MLLMs. However, the reasoning abilities of MLLMs\nhave not been systematically investigated. In this survey, we comprehensively\nreview the existing evaluation protocols of multimodal reasoning, categorize\nand illustrate the frontiers of MLLMs, introduce recent trends in applications\nof MLLMs on reasoning-intensive tasks, and finally discuss current practices\nand future directions. We believe our survey establishes a solid base and sheds\nlight on this important topic, multimodal reasoning.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.06805v2",
    "published_date": "2024-01-10 15:29:21 UTC",
    "updated_date": "2024-01-18 07:31:47 UTC"
  },
  {
    "arxiv_id": "2401.05215v1",
    "title": "Pre-trained Large Language Models for Financial Sentiment Analysis",
    "authors": [
      "Wei Luo",
      "Dihong Gong"
    ],
    "abstract": "Financial sentiment analysis refers to classifying financial text contents\ninto sentiment categories (e.g. positive, negative, and neutral). In this\npaper, we focus on the classification of financial news title, which is a\nchallenging task due to a lack of large amount of training samples. To overcome\nthis difficulty, we propose to adapt the pretrained large language models\n(LLMs) [1, 2, 3] to solve this problem. The LLMs, which are trained from huge\namount of text corpora,have an advantage in text understanding and can be\neffectively adapted to domain-specific task while requiring very few amount of\ntraining samples. In particular, we adapt the open-source Llama2-7B model\n(2023) with the supervised fine-tuning (SFT) technique [4]. Experimental\nevaluation shows that even with the 7B model (which is relatively small for\nLLMs), our approach significantly outperforms the previous state-of-the-art\nalgorithms.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.05215v1",
    "published_date": "2024-01-10 15:27:41 UTC",
    "updated_date": "2024-01-10 15:27:41 UTC"
  },
  {
    "arxiv_id": "2401.05468v1",
    "title": "Introducing New Node Prediction in Graph Mining: Predicting All Links from Isolated Nodes with Graph Neural Networks",
    "authors": [
      "Damiano Zanardini",
      "Emilio Serrano"
    ],
    "abstract": "This paper introduces a new problem in the field of graph mining and social\nnetwork analysis called new node prediction. More technically, the task can be\ncategorized as zero-shot out-of-graph all-links prediction. This challenging\nproblem aims to predict all links from a new, isolated, and unobserved node\nthat was previously disconnected from the graph. Unlike classic approaches to\nlink prediction (including few-shot out-of-graph link prediction), this problem\npresents two key differences: (1) the new node has no existing links from which\nto extract patterns for new predictions; and (2) the goal is to predict not\njust one, but all the links of this new node, or at least a significant part of\nthem. Experiments demonstrate that an architecture based on Deep Graph Neural\nNetworks can learn to solve this challenging problem in a bibliographic\ncitation network.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.LG",
      "I.2; I.2.6"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.05468v1",
    "published_date": "2024-01-10 15:05:03 UTC",
    "updated_date": "2024-01-10 15:05:03 UTC"
  },
  {
    "arxiv_id": "2401.05204v1",
    "title": "A Novel Prompt-tuning Method: Incorporating Scenario-specific Concepts into a Verbalizer",
    "authors": [
      "Yong Ma",
      "Senlin Luo",
      "Yu-Ming Shang",
      "Zhengjun Li",
      "Yong Liu"
    ],
    "abstract": "The verbalizer, which serves to map label words to class labels, is an\nessential component of prompt-tuning. In this paper, we present a novel\napproach to constructing verbalizers. While existing methods for verbalizer\nconstruction mainly rely on augmenting and refining sets of synonyms or related\nwords based on class names, this paradigm suffers from a narrow perspective and\nlack of abstraction, resulting in limited coverage and high bias in the\nlabel-word space. To address this issue, we propose a label-word construction\nprocess that incorporates scenario-specific concepts. Specifically, we extract\nrich concepts from task-specific scenarios as label-word candidates and then\ndevelop a novel cascade calibration module to refine the candidates into a set\nof label words for each class. We evaluate the effectiveness of our proposed\napproach through extensive experiments on {five} widely used datasets for\nzero-shot text classification. The results demonstrate that our method\noutperforms existing methods and achieves state-of-the-art results.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.05204v1",
    "published_date": "2024-01-10 15:02:35 UTC",
    "updated_date": "2024-01-10 15:02:35 UTC"
  },
  {
    "arxiv_id": "2401.05200v2",
    "title": "Knowledge Sharing in Manufacturing using Large Language Models: User Evaluation and Model Benchmarking",
    "authors": [
      "Samuel Kernan Freire",
      "Chaofan Wang",
      "Mina Foosherian",
      "Stefan Wellsandt",
      "Santiago Ruiz-Arenas",
      "Evangelos Niforatos"
    ],
    "abstract": "Recent advances in natural language processing enable more intelligent ways\nto support knowledge sharing in factories. In manufacturing, operating\nproduction lines has become increasingly knowledge-intensive, putting strain on\na factory's capacity to train and support new operators. This paper introduces\na Large Language Model (LLM)-based system designed to retrieve information from\nthe extensive knowledge contained in factory documentation and knowledge shared\nby expert operators. The system aims to efficiently answer queries from\noperators and facilitate the sharing of new knowledge. We conducted a user\nstudy at a factory to assess its potential impact and adoption, eliciting\nseveral perceived benefits, namely, enabling quicker information retrieval and\nmore efficient resolution of issues. However, the study also highlighted a\npreference for learning from a human expert when such an option is available.\nFurthermore, we benchmarked several commercial and open-sourced LLMs for this\nsystem. The current state-of-the-art model, GPT-4, consistently outperformed\nits counterparts, with open-source models trailing closely, presenting an\nattractive option given their data privacy and customization benefits. In\nsummary, this work offers preliminary insights and a system design for\nfactories considering using LLM tools for knowledge management.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.HC",
    "comment": "11 pages, 3 figures, and 1 table. Under review",
    "pdf_url": "http://arxiv.org/pdf/2401.05200v2",
    "published_date": "2024-01-10 14:53:18 UTC",
    "updated_date": "2024-02-26 12:46:37 UTC"
  },
  {
    "arxiv_id": "2401.05199v1",
    "title": "Monte Carlo Tree Search for Recipe Generation using GPT-2",
    "authors": [
      "Karan Taneja",
      "Richard Segal",
      "Richard Goodwin"
    ],
    "abstract": "Automatic food recipe generation methods provide a creative tool for chefs to\nexplore and to create new, and interesting culinary delights. Given the recent\nsuccess of large language models (LLMs), they have the potential to create new\nrecipes that can meet individual preferences, dietary constraints, and adapt to\nwhat is in your refrigerator. Existing research on using LLMs to generate\nrecipes has shown that LLMs can be finetuned to generate realistic-sounding\nrecipes. However, on close examination, these generated recipes often fail to\nmeet basic requirements like including chicken as an ingredient in chicken\ndishes. In this paper, we propose RecipeMC, a text generation method using\nGPT-2 that relies on Monte Carlo Tree Search (MCTS). RecipeMC allows us to\ndefine reward functions to put soft constraints on text generation and thus\nimprove the credibility of the generated recipes. Our results show that human\nevaluators prefer recipes generated with RecipeMC more often than recipes\ngenerated with other baseline methods when compared with real recipes.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 1 figure, ICCC 2023",
    "pdf_url": "http://arxiv.org/pdf/2401.05199v1",
    "published_date": "2024-01-10 14:50:46 UTC",
    "updated_date": "2024-01-10 14:50:46 UTC"
  },
  {
    "arxiv_id": "2401.05467v3",
    "title": "Can Active Label Correction Improve LLM-based Modular AI Systems?",
    "authors": [
      "Karan Taneja",
      "Ashok Goel"
    ],
    "abstract": "Modular AI systems can be developed using LLM-prompts-based modules to\nminimize deployment time even for complex tasks. However, these systems do not\nalways perform well and improving them using the data traces collected from a\ndeployment remains an open challenge. The data traces contain LLM inputs and\noutputs, but the annotations from LLMs are noisy. We hypothesize that Active\nLabel Correction (ALC) can be use on the collected data to train smaller\ntask-specific improved models that can replace LLM-based modules. In this\npaper, we study the noise in three GPT-3.5-annotated datasets and their\ndenoising with human feedback. We also propose a novel method ALC3 that\niteratively applies three updates to the training dataset: auto-correction,\ncorrection using human feedback and filtering. Our results show that ALC3 can\nlead to oracle performance with feedback on 17-24% fewer examples than the\nnumber of noisy examples in the dataset across three different NLP tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "EMNLP (Main) 2024, 13 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2401.05467v3",
    "published_date": "2024-01-10 14:41:37 UTC",
    "updated_date": "2024-10-03 02:25:27 UTC"
  },
  {
    "arxiv_id": "2401.05194v1",
    "title": "Modelling, Positioning, and Deep Reinforcement Learning Path Tracking Control of Scaled Robotic Vehicles: Design and Experimental Validation",
    "authors": [
      "Carmine Caponio",
      "Pietro Stano",
      "Raffaele Carli",
      "Ignazio Olivieri",
      "Daniele Ragone",
      "Aldo Sorniotti",
      "Umberto Montanaro"
    ],
    "abstract": "Mobile robotic systems are becoming increasingly popular. These systems are\nused in various indoor applications, raging from warehousing and manufacturing\nto test benches for assessment of advanced control strategies, such as\nartificial intelligence (AI)-based control solutions, just to name a few.\nScaled robotic cars are commonly equipped with a hierarchical control\nacthiecture that includes tasks dedicated to vehicle state estimation and\ncontrol. This paper covers both aspects by proposing (i) a federeted extended\nKalman filter (FEKF), and (ii) a novel deep reinforcement learning (DRL) path\ntracking controller trained via an expert demonstrator to expedite the learning\nphase and increase robustess to the simulation-to-reality gap. The paper also\npresents the formulation of a vehicle model along with an effective yet simple\nprocedure for identifying tis paramters. The experimentally validated model is\nused for (i) supporting the design of the FEKF and (ii) serving as a digital\ntwin for training the proposed DRL-based path tracking algorithm. Experimental\nresults confirm the ability of the FEKF to improve the estimate of the mobile\nrobot's position. Furthermore, the effectiveness of the DRL path tracking\nstrateguy is experimentally tested along manoeuvres not considered during\ntraining, showing also the ability of the AI-based solution to outpeform\nmodel-based control strategies and the demonstrator. The comparison with\nbenchmraking controllers is quantitavely evalueted through a set of key\nperformance indicators.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "Under review on IEEE Transactions",
    "pdf_url": "http://arxiv.org/pdf/2401.05194v1",
    "published_date": "2024-01-10 14:40:53 UTC",
    "updated_date": "2024-01-10 14:40:53 UTC"
  },
  {
    "arxiv_id": "2401.05193v1",
    "title": "Experiment Planning with Function Approximation",
    "authors": [
      "Aldo Pacchiano",
      "Jonathan N. Lee",
      "Emma Brunskill"
    ],
    "abstract": "We study the problem of experiment planning with function approximation in\ncontextual bandit problems. In settings where there is a significant overhead\nto deploying adaptive algorithms -- for example, when the execution of the data\ncollection policies is required to be distributed, or a human in the loop is\nneeded to implement these policies -- producing in advance a set of policies\nfor data collection is paramount. We study the setting where a large dataset of\ncontexts but not rewards is available and may be used by the learner to design\nan effective data collection strategy. Although when rewards are linear this\nproblem has been well studied, results are still missing for more complex\nreward models. In this work we propose two experiment planning strategies\ncompatible with function approximation. The first is an eluder planning and\nsampling procedure that can recover optimality guarantees depending on the\neluder dimension of the reward function class. For the second, we show that a\nuniform sampler achieves competitive optimality rates in the setting where the\nnumber of actions is small. We finalize our results introducing a statistical\ngap fleshing out the fundamental differences between planning and adaptive\nlearning and provide results for planning with model selection.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages main",
    "pdf_url": "http://arxiv.org/pdf/2401.05193v1",
    "published_date": "2024-01-10 14:40:23 UTC",
    "updated_date": "2024-01-10 14:40:23 UTC"
  },
  {
    "arxiv_id": "2401.05176v3",
    "title": "Convergences and Divergences between Automatic Assessment and Human Evaluation: Insights from Comparing ChatGPT-Generated Translation and Neural Machine Translation",
    "authors": [
      "Zhaokun Jiang",
      "Qianxi Lv",
      "Ziyin Zhang",
      "Lei Lei"
    ],
    "abstract": "Large language models have demonstrated parallel and even superior\ntranslation performance compared to neural machine translation (NMT) systems.\nHowever, existing comparative studies between them mainly rely on automated\nmetrics, raising questions into the feasibility of these metrics and their\nalignment with human judgment. The present study investigates the convergences\nand divergences between automated metrics and human evaluation in assessing the\nquality of machine translation from ChatGPT and three NMT systems. To perform\nautomatic assessment, four automated metrics are employed, while human\nevaluation incorporates the DQF-MQM error typology and six rubrics. Notably,\nautomatic assessment and human evaluation converge in measuring formal fidelity\n(e.g., error rates), but diverge when evaluating semantic and pragmatic\nfidelity, with automated metrics failing to capture the improvement of\nChatGPT's translation brought by prompt engineering. These results underscore\nthe indispensable role of human judgment in evaluating the performance of\nadvanced translation tools at the current stage.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.05176v3",
    "published_date": "2024-01-10 14:20:33 UTC",
    "updated_date": "2024-10-12 11:02:24 UTC"
  },
  {
    "arxiv_id": "2401.05163v3",
    "title": "MISS: A Generative Pretraining and Finetuning Approach for Med-VQA",
    "authors": [
      "Jiawei Chen",
      "Dingkang Yang",
      "Yue Jiang",
      "Yuxuan Lei",
      "Lihua Zhang"
    ],
    "abstract": "Medical visual question answering (VQA) is a challenging multimodal task,\nwhere Vision-Language Pre-training (VLP) models can effectively improve the\ngeneralization performance. However, most methods in the medical field treat\nVQA as an answer classification task which is difficult to transfer to\npractical application scenarios. Additionally, due to the privacy of medical\nimages and the expensive annotation process, large-scale medical image-text\npairs datasets for pretraining are severely lacking. In this paper, we propose\na large-scale MultI-task Self-Supervised learning based framework (MISS) for\nmedical VQA tasks. Unlike existing methods, we treat medical VQA as a\ngenerative task. We unify the text encoder and multimodal encoder and align\nimage-text features through multi-task learning. Furthermore, we propose a\nTransfer-and-Caption method that extends the feature space of single-modal\nimage datasets using Large Language Models (LLMs), enabling those traditional\nmedical vision field task data to be applied to VLP. Experiments show that our\nmethod achieves excellent results with fewer multimodal datasets and\ndemonstrates the advantages of generative VQA models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "ICANN, 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.05163v3",
    "published_date": "2024-01-10 13:56:40 UTC",
    "updated_date": "2024-06-19 11:14:40 UTC"
  },
  {
    "arxiv_id": "2401.05159v1",
    "title": "Derm-T2IM: Harnessing Synthetic Skin Lesion Data via Stable Diffusion Models for Enhanced Skin Disease Classification using ViT and CNN",
    "authors": [
      "Muhammad Ali Farooq",
      "Wang Yao",
      "Michael Schukat",
      "Mark A Little",
      "Peter Corcoran"
    ],
    "abstract": "This study explores the utilization of Dermatoscopic synthetic data generated\nthrough stable diffusion models as a strategy for enhancing the robustness of\nmachine learning model training. Synthetic data generation plays a pivotal role\nin mitigating challenges associated with limited labeled datasets, thereby\nfacilitating more effective model training. In this context, we aim to\nincorporate enhanced data transformation techniques by extending the recent\nsuccess of few-shot learning and a small amount of data representation in\ntext-to-image latent diffusion models. The optimally tuned model is further\nused for rendering high-quality skin lesion synthetic data with diverse and\nrealistic characteristics, providing a valuable supplement and diversity to the\nexisting training data. We investigate the impact of incorporating newly\ngenerated synthetic data into the training pipeline of state-of-art machine\nlearning models, assessing its effectiveness in enhancing model performance and\ngeneralization to unseen real-world data. Our experimental results demonstrate\nthe efficacy of the synthetic data generated through stable diffusion models\nhelps in improving the robustness and adaptability of end-to-end CNN and vision\ntransformer models on two different real-world skin lesion datasets.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Paper is submitted in EMBC 2024 Conference",
    "pdf_url": "http://arxiv.org/pdf/2401.05159v1",
    "published_date": "2024-01-10 13:46:03 UTC",
    "updated_date": "2024-01-10 13:46:03 UTC"
  },
  {
    "arxiv_id": "2401.06804v1",
    "title": "ChatGPT, Let us Chat Sign Language: Experiments, Architectural Elements, Challenges and Research Directions",
    "authors": [
      "Nada Shahin",
      "Leila Ismail"
    ],
    "abstract": "ChatGPT is a language model based on Generative AI. Existing research work on\nChatGPT focused on its use in various domains. However, its potential for Sign\nLanguage Translation (SLT) is yet to be explored. This paper addresses this\nvoid. Therefore, we present GPT's evolution aiming a retrospective analysis of\nthe improvements to its architecture for SLT. We explore ChatGPT's capabilities\nin translating different sign languages in paving the way to better\naccessibility for deaf and hard-of-hearing community. Our experimental results\nindicate that ChatGPT can accurately translate from English to American (ASL),\nAustralian (AUSLAN), and British (BSL) sign languages and from Arabic Sign\nLanguage (ArSL) to English with only one prompt iteration. However, the model\nfailed to translate from Arabic to ArSL and ASL, AUSLAN, and BSL to Arabic.\nConsequently, we present challenges and derive insights for future research\ndirections.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.06804v1",
    "published_date": "2024-01-10 13:39:49 UTC",
    "updated_date": "2024-01-10 13:39:49 UTC"
  },
  {
    "arxiv_id": "2401.05134v1",
    "title": "Yes, this is what I was looking for! Towards Multi-modal Medical Consultation Concern Summary Generation",
    "authors": [
      "Abhisek Tiwari",
      "Shreyangshu Bera",
      "Sriparna Saha",
      "Pushpak Bhattacharyya",
      "Samrat Ghosh"
    ],
    "abstract": "Over the past few years, the use of the Internet for healthcare-related tasks\nhas grown by leaps and bounds, posing a challenge in effectively managing and\nprocessing information to ensure its efficient utilization. During moments of\nemotional turmoil and psychological challenges, we frequently turn to the\ninternet as our initial source of support, choosing this over discussing our\nfeelings with others due to the associated social stigma. In this paper, we\npropose a new task of multi-modal medical concern summary (MMCS) generation,\nwhich provides a short and precise summary of patients' major concerns brought\nup during the consultation. Nonverbal cues, such as patients' gestures and\nfacial expressions, aid in accurately identifying patients' concerns. Doctors\nalso consider patients' personal information, such as age and gender, in order\nto describe the medical condition appropriately. Motivated by the potential\nefficacy of patients' personal context and visual gestures, we propose a\ntransformer-based multi-task, multi-modal intent-recognition, and medical\nconcern summary generation (IR-MMCSG) system. Furthermore, we propose a\nmultitasking framework for intent recognition and medical concern summary\ngeneration for doctor-patient consultations. We construct the first multi-modal\nmedical concern summary generation (MM-MediConSummation) corpus, which includes\npatient-doctor consultations annotated with medical concern summaries, intents,\npatient personal information, doctor's recommendations, and keywords. Our\nexperiments and analysis demonstrate (a) the significant role of patients'\nexpressions/gestures and their personal information in intent identification\nand medical concern summary generation, and (b) the strong correlation between\nintent recognition and patients' medical concern summary generation\n  The dataset and source code are available at https://github.com/NLP-RL/MMCSG.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.05134v1",
    "published_date": "2024-01-10 12:56:47 UTC",
    "updated_date": "2024-01-10 12:56:47 UTC"
  },
  {
    "arxiv_id": "2401.05133v1",
    "title": "Neural Population Learning beyond Symmetric Zero-sum Games",
    "authors": [
      "Siqi Liu",
      "Luke Marris",
      "Marc Lanctot",
      "Georgios Piliouras",
      "Joel Z. Leibo",
      "Nicolas Heess"
    ],
    "abstract": "We study computationally efficient methods for finding equilibria in n-player\ngeneral-sum games, specifically ones that afford complex visuomotor skills. We\nshow how existing methods would struggle in this setting, either\ncomputationally or in theory. We then introduce NeuPL-JPSRO, a neural\npopulation learning algorithm that benefits from transfer learning of skills\nand converges to a Coarse Correlated Equilibrium (CCE) of the game. We show\nempirical convergence in a suite of OpenSpiel games, validated rigorously by\nexact game solvers. We then deploy NeuPL-JPSRO to complex domains, where our\napproach enables adaptive coordination in a MuJoCo control domain and skill\ntransfer in capture-the-flag. Our work shows that equilibrium convergent\npopulation learning can be implemented at scale and in generality, paving the\nway towards solving real-world games between heterogeneous players with mixed\nmotives.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.05133v1",
    "published_date": "2024-01-10 12:56:24 UTC",
    "updated_date": "2024-01-10 12:56:24 UTC"
  },
  {
    "arxiv_id": "2401.05115v1",
    "title": "Unpacking Human-AI interactions: From interaction primitives to a design space",
    "authors": [
      "Kostas Tsiakas",
      "Dave Murray-Rust"
    ],
    "abstract": "This paper aims to develop a semi-formal design space for Human-AI\ninteractions, by building a set of interaction primitives which specify the\ncommunication between users and AI systems during their interaction. We show\nhow these primitives can be combined into a set of interaction patterns which\ncan provide an abstract specification for exchanging messages between humans\nand AI/ML models to carry out purposeful interactions. The motivation behind\nthis is twofold: firstly, to provide a compact generalisation of existing\npractices, that highlights the similarities and differences between systems in\nterms of their interaction behaviours; and secondly, to support the creation of\nnew systems, in particular by opening the space of possibilities for\ninteractions with models. We present a short literature review on frameworks,\nguidelines and taxonomies related to the design and implementation of HAI\ninteractions, including human-in-the-loop, explainable AI, as well as hybrid\nintelligence and collaborative learning approaches. From the literature review,\nwe define a vocabulary for describing information exchanges in terms of\nproviding and requesting particular model-specific data types. Based on this\nvocabulary, a message passing model for interactions between humans and models\nis presented, which we demonstrate can account for existing systems and\napproaches. Finally, we build this into design patterns as mid-level constructs\nthat capture common interactional structures. We discuss how this approach can\nbe used towards a design space for Human-AI interactions that creates new\npossibilities for designs as well as keeping track of implementation issues and\nconcerns.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.05115v1",
    "published_date": "2024-01-10 12:27:18 UTC",
    "updated_date": "2024-01-10 12:27:18 UTC"
  },
  {
    "arxiv_id": "2401.05097v1",
    "title": "Any-Way Meta Learning",
    "authors": [
      "Junhoo Lee",
      "Yearim Kim",
      "Hyunho Lee",
      "Nojun Kwak"
    ],
    "abstract": "Although meta-learning seems promising performance in the realm of rapid\nadaptability, it is constrained by fixed cardinality. When faced with tasks of\nvarying cardinalities that were unseen during training, the model lacks its\nability. In this paper, we address and resolve this challenge by harnessing\n`label equivalence' emerged from stochastic numeric label assignments during\nepisodic task sampling. Questioning what defines ``true\" meta-learning, we\nintroduce the ``any-way\" learning paradigm, an innovative model training\napproach that liberates model from fixed cardinality constraints. Surprisingly,\nthis model not only matches but often outperforms traditional fixed-way models\nin terms of performance, convergence speed, and stability. This disrupts\nestablished notions about domain generalization. Furthermore, we argue that the\ninherent label equivalence naturally lacks semantic information. To bridge this\nsemantic information gap arising from label equivalence, we further propose a\nmechanism for infusing semantic class information into the model. This would\nenhance the model's comprehension and functionality. Experiments conducted on\nrenowned architectures like MAML and ProtoNet affirm the effectiveness of our\nmethod.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.05097v1",
    "published_date": "2024-01-10 12:00:53 UTC",
    "updated_date": "2024-01-10 12:00:53 UTC"
  },
  {
    "arxiv_id": "2402.03329v1",
    "title": "Unsupervised Salient Patch Selection for Data-Efficient Reinforcement Learning",
    "authors": [
      "Zhaohui Jiang",
      "Paul Weng"
    ],
    "abstract": "To improve the sample efficiency of vision-based deep reinforcement learning\n(RL), we propose a novel method, called SPIRL, to automatically extract\nimportant patches from input images. Following Masked Auto-Encoders, SPIRL is\nbased on Vision Transformer models pre-trained in a self-supervised fashion to\nreconstruct images from randomly-sampled patches. These pre-trained models can\nthen be exploited to detect and select salient patches, defined as hard to\nreconstruct from neighboring patches. In RL, the SPIRL agent processes selected\nsalient patches via an attention module. We empirically validate SPIRL on Atari\ngames to test its data-efficiency against relevant state-of-the-art methods,\nincluding some traditional model-based methods and keypoint-based models. In\naddition, we analyze our model's interpretability capabilities.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.03329v1",
    "published_date": "2024-01-10 11:46:49 UTC",
    "updated_date": "2024-01-10 11:46:49 UTC"
  },
  {
    "arxiv_id": "2401.05461v1",
    "title": "The two-way knowledge interaction interface between humans and neural networks",
    "authors": [
      "Zhanliang He",
      "Nuoye Xiong",
      "Hongsheng Li",
      "Peiyi Shen",
      "Guangming Zhu",
      "Liang Zhang"
    ],
    "abstract": "Despite neural networks (NN) have been widely applied in various fields and\ngenerally outperforms humans, they still lack interpretability to a certain\nextent, and humans are unable to intuitively understand the decision logic of\nNN. This also hinders the knowledge interaction between humans and NN,\npreventing humans from getting involved to give direct guidance when NN's\ndecisions go wrong. While recent research in explainable AI has achieved\ninterpretability of NN from various perspectives, it has not yet provided\neffective methods for knowledge exchange between humans and NN. To address this\nproblem, we constructed a two-way interaction interface that uses structured\nrepresentations of visual concepts and their relationships as the \"language\"\nfor knowledge exchange between humans and NN. Specifically, NN provide\nintuitive reasoning explanations to humans based on the class-specific\nstructural concepts graph (C-SCG). On the other hand, humans can modify the\nbiases present in the C-SCG through their prior knowledge and reasoning\nability, and thus provide direct knowledge guidance to NN through this\ninterface. Through experimental validation, based on this interaction\ninterface, NN can provide humans with easily understandable explanations of the\nreasoning process. Furthermore, human involvement and prior knowledge can\ndirectly and effectively contribute to enhancing the performance of NN.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.05461v1",
    "published_date": "2024-01-10 10:47:41 UTC",
    "updated_date": "2024-01-10 10:47:41 UTC"
  },
  {
    "arxiv_id": "2401.05054v2",
    "title": "Generating Diverse and High-Quality Texts by Minimum Bayes Risk Decoding",
    "authors": [
      "Yuu Jinnai",
      "Ukyo Honda",
      "Tetsuro Morimura",
      "Peinan Zhang"
    ],
    "abstract": "One of the most important challenges in text generation systems is to produce\noutputs that are not only correct but also diverse. Recently, Minimum\nBayes-Risk (MBR) decoding has gained prominence for generating sentences of the\nhighest quality among the decoding algorithms. However, existing algorithms\nproposed for generating diverse outputs are predominantly based on beam search\nor random sampling, thus their output quality is capped by these underlying\nmethods. In this paper, we investigate an alternative approach -- we develop\ndiversity-promoting decoding algorithms by enforcing diversity objectives to\nMBR decoding. We propose two variants of MBR, Diverse MBR (DMBR) and\n$k$-medoids MBR (KMBR), methods to generate a set of sentences with high\nquality and diversity. We evaluate DMBR and KMBR on a variety of directed text\ngeneration tasks using encoder-decoder models and a large language model with\nprompting. The experimental results show that the proposed method achieves a\nbetter trade-off than the diverse beam search and sampling algorithms.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.05054v2",
    "published_date": "2024-01-10 10:23:41 UTC",
    "updated_date": "2024-06-12 01:27:32 UTC"
  },
  {
    "arxiv_id": "2401.05043v3",
    "title": "CreINNs: Credal-Set Interval Neural Networks for Uncertainty Estimation in Classification Tasks",
    "authors": [
      "Kaizheng Wang",
      "Keivan Shariatmadar",
      "Shireen Kudukkil Manchingal",
      "Fabio Cuzzolin",
      "David Moens",
      "Hans Hallez"
    ],
    "abstract": "Effective uncertainty estimation is becoming increasingly attractive for\nenhancing the reliability of neural networks. This work presents a novel\napproach, termed Credal-Set Interval Neural Networks (CreINNs), for\nclassification. CreINNs retain the fundamental structure of traditional\nInterval Neural Networks, capturing weight uncertainty through deterministic\nintervals. CreINNs are designed to predict an upper and a lower probability\nbound for each class, rather than a single probability value. The probability\nintervals can define a credal set, facilitating estimating different types of\nuncertainties associated with predictions. Experiments on standard multiclass\nand binary classification tasks demonstrate that the proposed CreINNs can\nachieve superior or comparable quality of uncertainty estimation compared to\nvariational Bayesian Neural Networks (BNNs) and Deep Ensembles. Furthermore,\nCreINNs significantly reduce the computational complexity of variational BNNs\nduring inference. Moreover, the effective uncertainty quantification of CreINNs\nis also verified when the input data are intervals.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.05043v3",
    "published_date": "2024-01-10 10:04:49 UTC",
    "updated_date": "2025-01-25 09:18:33 UTC"
  },
  {
    "arxiv_id": "2402.01654v1",
    "title": "A Scoping Review of Energy Load Disaggregation",
    "authors": [
      "Balázs András Tolnai",
      "Zheng Ma",
      "Bo Nørregaard Jørgensen"
    ],
    "abstract": "Energy load disaggregation can contribute to balancing power grids by\nenhancing the effectiveness of demand-side management and promoting\nelectricity-saving behavior through increased consumer awareness. However, the\nfield currently lacks a comprehensive overview. To address this gap, this paper\ncon-ducts a scoping review of load disaggregation domains, data types, and\nmethods, by assessing 72 full-text journal articles. The findings reveal that\ndomestic electricity consumption is the most researched area, while others,\nsuch as industrial load disaggregation, are rarely discussed. The majority of\nresearch uses relatively low-frequency data, sampled between 1 and 60 seconds.\nA wide variety of methods are used, and artificial neural networks are the most\ncommon, followed by optimization strategies, Hidden Markov Models, and Graph\nSignal Processing approaches.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.01654v1",
    "published_date": "2024-01-10 09:59:12 UTC",
    "updated_date": "2024-01-10 09:59:12 UTC"
  },
  {
    "arxiv_id": "2401.05033v1",
    "title": "Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk",
    "authors": [
      "Dennis Ulmer",
      "Elman Mansimov",
      "Kaixiang Lin",
      "Justin Sun",
      "Xibin Gao",
      "Yi Zhang"
    ],
    "abstract": "Large language models (LLMs) are powerful dialogue agents, but specializing\nthem towards fulfilling a specific function can be challenging. Instructing\ntuning, i.e. tuning models on instruction and sample responses generated by\nhumans (Ouyang et al., 2022), has proven as an effective method to do so, yet\nrequires a number of data samples that a) might not be available or b) costly\nto generate. Furthermore, this cost increases when the goal is to make the LLM\nfollow a specific workflow within a dialogue instead of single instructions.\nInspired by the self-play technique in reinforcement learning and the use of\nLLMs to simulate human agents, we propose a more effective method for data\ncollection through LLMs engaging in a conversation in various roles. This\napproach generates a training data via \"self-talk\" of LLMs that can be refined\nand utilized for supervised fine-tuning. We introduce an automated way to\nmeasure the (partial) success of a dialogue. This metric is used to filter the\ngenerated conversational data that is fed back in LLM for training. Based on\nour automated and human evaluations of conversation quality, we demonstrate\nthat such self-talk data improves results. In addition, we examine the various\ncharacteristics that showcase the quality of generated dialogues and how they\ncan be connected to their potential utility as training data.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.05033v1",
    "published_date": "2024-01-10 09:49:10 UTC",
    "updated_date": "2024-01-10 09:49:10 UTC"
  },
  {
    "arxiv_id": "2401.05459v2",
    "title": "Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security",
    "authors": [
      "Yuanchun Li",
      "Hao Wen",
      "Weijun Wang",
      "Xiangyu Li",
      "Yizhen Yuan",
      "Guohong Liu",
      "Jiacheng Liu",
      "Wenxing Xu",
      "Xiang Wang",
      "Yi Sun",
      "Rui Kong",
      "Yile Wang",
      "Hanfei Geng",
      "Jian Luan",
      "Xuefeng Jin",
      "Zilong Ye",
      "Guanjing Xiong",
      "Fan Zhang",
      "Xiang Li",
      "Mengwei Xu",
      "Zhijun Li",
      "Peng Li",
      "Yang Liu",
      "Ya-Qin Zhang",
      "Yunxin Liu"
    ],
    "abstract": "Since the advent of personal computing devices, intelligent personal\nassistants (IPAs) have been one of the key technologies that researchers and\nengineers have focused on, aiming to help users efficiently obtain information\nand execute tasks, and provide users with more intelligent, convenient, and\nrich interaction experiences. With the development of smartphones and IoT,\ncomputing and sensing devices have become ubiquitous, greatly expanding the\nboundaries of IPAs. However, due to the lack of capabilities such as user\nintent understanding, task planning, tool using, and personal data management\netc., existing IPAs still have limited practicality and scalability. Recently,\nthe emergence of foundation models, represented by large language models\n(LLMs), brings new opportunities for the development of IPAs. With the powerful\nsemantic understanding and reasoning capabilities, LLM can enable intelligent\nagents to solve complex problems autonomously. In this paper, we focus on\nPersonal LLM Agents, which are LLM-based agents that are deeply integrated with\npersonal data and personal devices and used for personal assistance. We\nenvision that Personal LLM Agents will become a major software paradigm for\nend-users in the upcoming era. To realize this vision, we take the first step\nto discuss several important questions about Personal LLM Agents, including\ntheir architecture, capability, efficiency and security. We start by\nsummarizing the key components and design choices in the architecture of\nPersonal LLM Agents, followed by an in-depth analysis of the opinions collected\nfrom domain experts. Next, we discuss several key challenges to achieve\nintelligent, efficient and secure Personal LLM Agents, followed by a\ncomprehensive survey of representative solutions to address these challenges.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.HC",
    "comment": "https://github.com/MobileLLM/Personal_LLM_Agents_Survey",
    "pdf_url": "http://arxiv.org/pdf/2401.05459v2",
    "published_date": "2024-01-10 09:25:45 UTC",
    "updated_date": "2024-05-08 06:16:23 UTC"
  },
  {
    "arxiv_id": "2401.05014v1",
    "title": "Source-Free Cross-Modal Knowledge Transfer by Unleashing the Potential of Task-Irrelevant Data",
    "authors": [
      "Jinjing Zhu",
      "Yucheng Chen",
      "Lin Wang"
    ],
    "abstract": "Source-free cross-modal knowledge transfer is a crucial yet challenging task,\nwhich aims to transfer knowledge from one source modality (e.g., RGB) to the\ntarget modality (e.g., depth or infrared) with no access to the task-relevant\n(TR) source data due to memory and privacy concerns. A recent attempt leverages\nthe paired task-irrelevant (TI) data and directly matches the features from\nthem to eliminate the modality gap. However, it ignores a pivotal clue that the\npaired TI data could be utilized to effectively estimate the source data\ndistribution and better facilitate knowledge transfer to the target modality.\nTo this end, we propose a novel yet concise framework to unlock the potential\nof paired TI data for enhancing source-free cross-modal knowledge transfer. Our\nwork is buttressed by two key technical components. Firstly, to better estimate\nthe source data distribution, we introduce a Task-irrelevant data-Guided\nModality Bridging (TGMB) module. It translates the target modality data (e.g.,\ninfrared) into the source-like RGB images based on paired TI data and the\nguidance of the available source model to alleviate two key gaps: 1)\ninter-modality gap between the paired TI data; 2) intra-modality gap between TI\nand TR target data. We then propose a Task-irrelevant data-Guided Knowledge\nTransfer (TGKT) module that transfers knowledge from the source model to the\ntarget model by leveraging the paired TI data. Notably, due to the\nunavailability of labels for the TR target data and its less reliable\nprediction from the source model, our TGKT model incorporates a self-supervised\npseudo-labeling approach to enable the target model to learn from its\npredictions. Extensive experiments show that our method achieves\nstate-of-the-art performance on three datasets (RGB-to-depth and\nRGB-to-infrared).",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.05014v1",
    "published_date": "2024-01-10 09:02:24 UTC",
    "updated_date": "2024-01-10 09:02:24 UTC"
  },
  {
    "arxiv_id": "2401.05010v2",
    "title": "Less is More: A Closer Look at Semantic-based Few-Shot Learning",
    "authors": [
      "Chunpeng Zhou",
      "Haishuai Wang",
      "Xilu Yuan",
      "Zhi Yu",
      "Jiajun Bu"
    ],
    "abstract": "Few-shot Learning aims to learn and distinguish new categories with a very\nlimited number of available images, presenting a significant challenge in the\nrealm of deep learning. Recent researchers have sought to leverage the\nadditional textual or linguistic information of these rare categories with a\npre-trained language model to facilitate learning, thus partially alleviating\nthe problem of insufficient supervision signals. However, the full potential of\nthe textual information and pre-trained language model have been underestimated\nin the few-shot learning till now, resulting in limited performance\nenhancements. To address this, we propose a simple but effective framework for\nfew-shot learning tasks, specifically designed to exploit the textual\ninformation and language model. In more detail, we explicitly exploit the\nzero-shot capability of the pre-trained language model with the learnable\nprompt. And we just add the visual feature with the textual feature for\ninference directly without the intricate designed fusion modules in previous\nworks. Additionally, we apply the self-ensemble and distillation to further\nenhance these components. Our extensive experiments conducted across four\nwidely used few-shot datasets demonstrate that our simple framework achieves\nimpressive results. Particularly noteworthy is its outstanding performance in\nthe 1-shot learning task, surpassing state-of-the-art methods by an average of\n3.0\\% in classification accuracy. \\footnote{We will make the source codes of\nthe proposed framework publicly available upon acceptance. }.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.05010v2",
    "published_date": "2024-01-10 08:56:02 UTC",
    "updated_date": "2024-03-24 12:32:06 UTC"
  },
  {
    "arxiv_id": "2401.06176v1",
    "title": "GOODAT: Towards Test-time Graph Out-of-Distribution Detection",
    "authors": [
      "Luzhi Wang",
      "Dongxiao He",
      "He Zhang",
      "Yixin Liu",
      "Wenjie Wang",
      "Shirui Pan",
      "Di Jin",
      "Tat-Seng Chua"
    ],
    "abstract": "Graph neural networks (GNNs) have found widespread application in modeling\ngraph data across diverse domains. While GNNs excel in scenarios where the\ntesting data shares the distribution of their training counterparts (in\ndistribution, ID), they often exhibit incorrect predictions when confronted\nwith samples from an unfamiliar distribution (out-of-distribution, OOD). To\nidentify and reject OOD samples with GNNs, recent studies have explored graph\nOOD detection, often focusing on training a specific model or modifying the\ndata on top of a well-trained GNN. Despite their effectiveness, these methods\ncome with heavy training resources and costs, as they need to optimize the\nGNN-based models on training data. Moreover, their reliance on modifying the\noriginal GNNs and accessing training data further restricts their universality.\nTo this end, this paper introduces a method to detect Graph Out-of-Distribution\nAt Test-time (namely GOODAT), a data-centric, unsupervised, and plug-and-play\nsolution that operates independently of training data and modifications of GNN\narchitecture. With a lightweight graph masker, GOODAT can learn informative\nsubgraphs from test samples, enabling the capture of distinct graph patterns\nbetween OOD and ID samples. To optimize the graph masker, we meticulously\ndesign three unsupervised objective functions based on the graph information\nbottleneck principle, motivating the masker to capture compact yet informative\nsubgraphs for OOD detection. Comprehensive evaluations confirm that our GOODAT\nmethod outperforms state-of-the-art benchmarks across a variety of real-world\ndatasets. The code is available at Github: https://github.com/Ee1s/GOODAT",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2401.06176v1",
    "published_date": "2024-01-10 08:37:39 UTC",
    "updated_date": "2024-01-10 08:37:39 UTC"
  },
  {
    "arxiv_id": "2401.04993v1",
    "title": "AdaFed: Fair Federated Learning via Adaptive Common Descent Direction",
    "authors": [
      "Shayan Mohajer Hamidi",
      "En-Hui Yang"
    ],
    "abstract": "Federated learning (FL) is a promising technology via which some edge\ndevices/clients collaboratively train a machine learning model orchestrated by\na server. Learning an unfair model is known as a critical problem in federated\nlearning, where the trained model may unfairly advantage or disadvantage some\nof the devices. To tackle this problem, in this work, we propose AdaFed. The\ngoal of AdaFed is to find an updating direction for the server along which (i)\nall the clients' loss functions are decreasing; and (ii) more importantly, the\nloss functions for the clients with larger values decrease with a higher rate.\nAdaFed adaptively tunes this common direction based on the values of local\ngradients and loss functions. We validate the effectiveness of AdaFed on a\nsuite of federated datasets, and demonstrate that AdaFed outperforms\nstate-of-the-art fair FL methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "This paper has been accepted in Transactions on Machine Learning\n  Research. This is the link to the paper:\n  https://openreview.net/forum?id=rFecyFpFUp&referrer=%5Bthe%20profile%20of%20Shayan%20Mohajer%20Hamidi%5D(%2Fprofile%3Fid%3D~Shayan_Mohajer_Hamidi1)",
    "pdf_url": "http://arxiv.org/pdf/2401.04993v1",
    "published_date": "2024-01-10 08:22:15 UTC",
    "updated_date": "2024-01-10 08:22:15 UTC"
  },
  {
    "arxiv_id": "2401.05458v1",
    "title": "CoLafier: Collaborative Noisy Label Purifier With Local Intrinsic Dimensionality Guidance",
    "authors": [
      "Dongyu Zhang",
      "Ruofan Hu",
      "Elke Rundensteiner"
    ],
    "abstract": "Deep neural networks (DNNs) have advanced many machine learning tasks, but\ntheir performance is often harmed by noisy labels in real-world data.\nAddressing this, we introduce CoLafier, a novel approach that uses Local\nIntrinsic Dimensionality (LID) for learning with noisy labels. CoLafier\nconsists of two subnets: LID-dis and LID-gen. LID-dis is a specialized\nclassifier. Trained with our uniquely crafted scheme, LID-dis consumes both a\nsample's features and its label to predict the label - which allows it to\nproduce an enhanced internal representation. We observe that LID scores\ncomputed from this representation effectively distinguish between correct and\nincorrect labels across various noise scenarios. In contrast to LID-dis,\nLID-gen, functioning as a regular classifier, operates solely on the sample's\nfeatures. During training, CoLafier utilizes two augmented views per instance\nto feed both subnets. CoLafier considers the LID scores from the two views as\nproduced by LID-dis to assign weights in an adapted loss function for both\nsubnets. Concurrently, LID-gen, serving as classifier, suggests pseudo-labels.\nLID-dis then processes these pseudo-labels along with two views to derive LID\nscores. Finally, these LID scores along with the differences in predictions\nfrom the two subnets guide the label update decisions. This dual-view and\ndual-subnet approach enhances the overall reliability of the framework. Upon\ncompletion of the training, we deploy the LID-gen subnet of CoLafier as the\nfinal classification model. CoLafier demonstrates improved prediction accuracy,\nsurpassing existing methods, particularly under severe label noise. For more\ndetails, see the code at https://github.com/zdy93/CoLafier.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "This work is accepted by SIAM International Conference on Data Mining\n  (SDM24)",
    "pdf_url": "http://arxiv.org/pdf/2401.05458v1",
    "published_date": "2024-01-10 08:10:59 UTC",
    "updated_date": "2024-01-10 08:10:59 UTC"
  },
  {
    "arxiv_id": "2401.04980v1",
    "title": "Autonomous Navigation of Tractor-Trailer Vehicles through Roundabout Intersections",
    "authors": [
      "Daniel Attard",
      "Josef Bajada"
    ],
    "abstract": "In recent years, significant advancements have been made in the field of\nautonomous driving with the aim of increasing safety and efficiency. However,\nresearch that focuses on tractor-trailer vehicles is relatively sparse. Due to\nthe physical characteristics and articulated joints, such vehicles require\ntailored models. While turning, the back wheels of the trailer turn at a\ntighter radius and the truck often has to deviate from the centre of the lane\nto accommodate this. Due to the lack of publicly available models, this work\ndevelops truck and trailer models using the high-fidelity simulation software\nCARLA, together with several roundabout scenarios, to establish a baseline\ndataset for benchmarks. Using a twin-q soft actor-critic algorithm, we train a\nquasi-end-to-end autonomous driving model which is able to achieve a 73%\nsuccess rate on different roundabouts.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.04980v1",
    "published_date": "2024-01-10 07:55:11 UTC",
    "updated_date": "2024-01-10 07:55:11 UTC"
  },
  {
    "arxiv_id": "2401.04979v5",
    "title": "DualDynamics: Synergizing Implicit and Explicit Methods for Robust Irregular Time Series Analysis",
    "authors": [
      "YongKyung Oh",
      "Dong-Young Lim",
      "Sungil Kim"
    ],
    "abstract": "Real-world time series analysis faces significant challenges when dealing\nwith irregular and incomplete data. While Neural Differential Equation (NDE)\nbased methods have shown promise, they struggle with limited expressiveness,\nscalability issues, and stability concerns. Conversely, Neural Flows offer\nstability but falter with irregular data. We introduce 'DualDynamics', a novel\nframework that synergistically combines NDE-based method and Neural Flow-based\nmethod. This approach enhances expressive power while balancing computational\ndemands, addressing critical limitations of existing techniques. We demonstrate\nDualDynamics' effectiveness across diverse tasks: classification of robustness\nto dataset shift, irregularly-sampled series analysis, interpolation of missing\ndata, and forecasting with partial observations. Our results show consistent\noutperformance over state-of-the-art methods, indicating DualDynamics'\npotential to advance irregular time series analysis significantly.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Published at the 39th Annual AAAI Conference on Artificial\n  Intelligence (AAAI 2025)",
    "pdf_url": "http://arxiv.org/pdf/2401.04979v5",
    "published_date": "2024-01-10 07:51:02 UTC",
    "updated_date": "2025-02-21 02:04:28 UTC"
  },
  {
    "arxiv_id": "2402.18577v1",
    "title": "Motion Guided Token Compression for Efficient Masked Video Modeling",
    "authors": [
      "Yukun Feng",
      "Yangming Shi",
      "Fengze Liu",
      "Tan Yan"
    ],
    "abstract": "Recent developments in Transformers have achieved notable strides in\nenhancing video comprehension. Nonetheless, the O($N^2$) computation complexity\nassociated with attention mechanisms presents substantial computational hurdles\nwhen dealing with the high dimensionality of videos. This challenge becomes\nparticularly pronounced when striving to increase the frames per second (FPS)\nto enhance the motion capturing capabilities. Such a pursuit is likely to\nintroduce redundancy and exacerbate the existing computational limitations. In\nthis paper, we initiate by showcasing the enhanced performance achieved through\nan escalation in the FPS rate. Additionally, we present a novel approach,\nMotion Guided Token Compression (MGTC), to empower Transformer models to\nutilize a smaller yet more representative set of tokens for comprehensive video\nrepresentation. Consequently, this yields substantial reductions in\ncomputational burden and remains seamlessly adaptable to increased FPS rates.\nSpecifically, we draw inspiration from video compression algorithms and\nscrutinize the variance between patches in consecutive video frames across the\ntemporal dimension. The tokens exhibiting a disparity below a predetermined\nthreshold are then masked. Notably, this masking strategy effectively addresses\nvideo redundancy while conserving essential information. Our experiments,\nconducted on widely examined video recognition datasets, Kinetics-400, UCF101\nand HMDB51, demonstrate that elevating the FPS rate results in a significant\ntop-1 accuracy score improvement of over 1.6, 1.6 and 4.0. By implementing MGTC\nwith the masking ratio of 25\\%, we further augment accuracy by 0.1 and\nsimultaneously reduce computational costs by over 31\\% on Kinetics-400. Even\nwithin a fixed computational budget, higher FPS rates paired with MGTC sustain\nperformance gains when compared to lower FPS settings.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2402.18577v1",
    "published_date": "2024-01-10 07:49:23 UTC",
    "updated_date": "2024-01-10 07:49:23 UTC"
  },
  {
    "arxiv_id": "2401.04978v2",
    "title": "Closed-Form Interpretation of Neural Network Classifiers with Symbolic Gradients",
    "authors": [
      "Sebastian Johann Wetzel"
    ],
    "abstract": "I introduce a unified framework for finding a closed-form interpretation of\nany single neuron in an artificial neural network. Using this framework I\ndemonstrate how to interpret neural network classifiers to reveal closed-form\nexpressions of the concepts encoded in their decision boundaries. In contrast\nto neural network-based regression, for classification, it is in general\nimpossible to express the neural network in the form of a symbolic equation\neven if the neural network itself bases its classification on a quantity that\ncan be written as a closed-form equation. The interpretation framework is based\non embedding trained neural networks into an equivalence class of functions\nthat encode the same concept. I interpret these neural networks by finding an\nintersection between the equivalence class and human-readable equations defined\nby a symbolic search space. The approach is not limited to classifiers or full\nneural networks and can be applied to arbitrary neurons in hidden layers or\nlatent spaces.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.04978v2",
    "published_date": "2024-01-10 07:47:42 UTC",
    "updated_date": "2024-10-01 00:11:48 UTC"
  },
  {
    "arxiv_id": "2401.06175v1",
    "title": "MTAD: Tools and Benchmarks for Multivariate Time Series Anomaly Detection",
    "authors": [
      "Jinyang Liu",
      "Wenwei Gu",
      "Zhuangbin Chen",
      "Yichen Li",
      "Yuxin Su",
      "Michael R. Lyu"
    ],
    "abstract": "Key Performance Indicators (KPIs) are essential time-series metrics for\nensuring the reliability and stability of many software systems. They\nfaithfully record runtime states to facilitate the understanding of anomalous\nsystem behaviors and provide informative clues for engineers to pinpoint the\nroot causes. The unprecedented scale and complexity of modern software systems,\nhowever, make the volume of KPIs explode. Consequently, many traditional\nmethods of KPI anomaly detection become impractical, which serves as a catalyst\nfor the fast development of machine learning-based solutions in both academia\nand industry. However, there is currently a lack of rigorous comparison among\nthese KPI anomaly detection methods, and re-implementation demands a\nnon-trivial effort. Moreover, we observe that different works adopt independent\nevaluation processes with different metrics. Some of them may not fully reveal\nthe capability of a model and some are creating an illusion of progress. To\nbetter understand the characteristics of different KPI anomaly detectors and\naddress the evaluation issue, in this paper, we provide a comprehensive review\nand evaluation of twelve state-of-the-art methods, and propose a novel metric\ncalled salience. Particularly, the selected methods include five traditional\nmachine learning-based methods and seven deep learning-based methods. These\nmethods are evaluated with five multivariate KPI datasets that are publicly\navailable. A unified toolkit with easy-to-use interfaces is also released. We\nreport the benchmark results in terms of accuracy, salience, efficiency, and\ndelay, which are of practical importance for industrial deployment. We believe\nour work can contribute as a basis for future academic research and industrial\napplication.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "The code and datasets are available at https://github.com/OpsPAI/MTAD",
    "pdf_url": "http://arxiv.org/pdf/2401.06175v1",
    "published_date": "2024-01-10 06:50:25 UTC",
    "updated_date": "2024-01-10 06:50:25 UTC"
  },
  {
    "arxiv_id": "2401.04950v1",
    "title": "Information Flow Rate for Cross-Correlated Stochastic Processes",
    "authors": [
      "Dionissios T. Hristopulos"
    ],
    "abstract": "Causal inference seeks to identify cause-and-effect interactions in coupled\nsystems. A recently proposed method by Liang detects causal relations by\nquantifying the direction and magnitude of information flow between time\nseries. The theoretical formulation of information flow for stochastic\ndynamical systems provides a general expression and a data-driven statistic for\nthe rate of entropy transfer between different system units. To advance\nunderstanding of information flow rate in terms of intuitive concepts and\nphysically meaningful parameters, we investigate statistical properties of the\ndata-driven information flow rate between coupled stochastic processes. We\nderive relations between the expectation of the information flow rate statistic\nand properties of the auto- and cross-correlation functions. Thus, we elucidate\nthe dependence of the information flow rate on the analytical properties and\ncharacteristic times of the correlation functions. Our analysis provides\ninsight into the influence of the sampling step, the strength of\ncross-correlations, and the temporal delay of correlations on information flow\nrate. We support the theoretical results with numerical simulations of\ncorrelated Gaussian processes.",
    "categories": [
      "physics.data-an",
      "cs.AI",
      "cs.IT",
      "math.IT",
      "62D20, 60G15, 60G10"
    ],
    "primary_category": "physics.data-an",
    "comment": "16 pages, 5 figures; to appear in IEEE Transactions on Signal\n  Processing",
    "pdf_url": "http://arxiv.org/pdf/2401.04950v1",
    "published_date": "2024-01-10 06:08:06 UTC",
    "updated_date": "2024-01-10 06:08:06 UTC"
  },
  {
    "arxiv_id": "2401.06801v2",
    "title": "Graph-of-Thought: Utilizing Large Language Models to Solve Complex and Dynamic Business Problems",
    "authors": [
      "Ye Li"
    ],
    "abstract": "This paper presents Graph-of-Thought (GoT), a new model for workflow\nautomation that enhances the flexibility and efficiency of Large Language\nModels (LLMs) in complex task execution. GoT advances beyond traditional linear\nand tree-like cognitive models with a graph structure that enables dynamic path\nselection. The open-source engine GoTFlow demonstrates the practical\napplication of GoT, facilitating automated, data-driven decision-making across\nvarious domains. Despite challenges in complexity and transparency, GoTFlow's\npotential for improving business processes is significant, promising\nadvancements in both efficiency and decision quality with continuous\ndevelopment.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Keywords: Graph-of-Thought (GoT), Workflow Automation, Large Language\n  Models (LLMs), Task Execution, Data-Driven Decision Making, Complexity\n  Management",
    "pdf_url": "http://arxiv.org/pdf/2401.06801v2",
    "published_date": "2024-01-10 05:32:20 UTC",
    "updated_date": "2024-02-17 03:48:01 UTC"
  },
  {
    "arxiv_id": "2401.04934v1",
    "title": "Fully Decentralized Cooperative Multi-Agent Reinforcement Learning: A Survey",
    "authors": [
      "Jiechuan Jiang",
      "Kefan Su",
      "Zongqing Lu"
    ],
    "abstract": "Cooperative multi-agent reinforcement learning is a powerful tool to solve\nmany real-world cooperative tasks, but restrictions of real-world applications\nmay require training the agents in a fully decentralized manner. Due to the\nlack of information about other agents, it is challenging to derive algorithms\nthat can converge to the optimal joint policy in a fully decentralized setting.\nThus, this research area has not been thoroughly studied. In this paper, we\nseek to systematically review the fully decentralized methods in two settings:\nmaximizing a shared reward of all agents and maximizing the sum of individual\nrewards of all agents, and discuss open questions and future research\ndirections.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.MA",
    "comment": "The first two authors contribute equally with an alphabetic order",
    "pdf_url": "http://arxiv.org/pdf/2401.04934v1",
    "published_date": "2024-01-10 05:07:42 UTC",
    "updated_date": "2024-01-10 05:07:42 UTC"
  },
  {
    "arxiv_id": "2401.04929v3",
    "title": "Learning-Based Difficulty Calibration for Enhanced Membership Inference Attacks",
    "authors": [
      "Haonan Shi",
      "Tu Ouyang",
      "An Wang"
    ],
    "abstract": "Machine learning models, in particular deep neural networks, are currently an\nintegral part of various applications, from healthcare to finance. However,\nusing sensitive data to train these models raises concerns about privacy and\nsecurity. One method that has emerged to verify if the trained models are\nprivacy-preserving is Membership Inference Attacks (MIA), which allows\nadversaries to determine whether a specific data point was part of a model's\ntraining dataset. While a series of MIAs have been proposed in the literature,\nonly a few can achieve high True Positive Rates (TPR) in the low False Positive\nRate (FPR) region (0.01%~1%). This is a crucial factor to consider for an MIA\nto be practically useful in real-world settings. In this paper, we present a\nnovel approach to MIA that is aimed at significantly improving TPR at low FPRs.\nOur method, named learning-based difficulty calibration for MIA(LDC-MIA),\ncharacterizes data records by their hardness levels using a neural network\nclassifier to determine membership. The experiment results show that LDC-MIA\ncan improve TPR at low FPR by up to 4x compared to the other difficulty\ncalibration based MIAs. It also has the highest Area Under ROC curve (AUC)\nacross all datasets. Our method's cost is comparable with most of the existing\nMIAs, but is orders of magnitude more efficient than one of the\nstate-of-the-art methods, LiRA, while achieving similar performance.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted to IEEE Euro S&P 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.04929v3",
    "published_date": "2024-01-10 04:58:17 UTC",
    "updated_date": "2024-07-09 12:37:58 UTC"
  },
  {
    "arxiv_id": "2401.04925v4",
    "title": "The Impact of Reasoning Step Length on Large Language Models",
    "authors": [
      "Mingyu Jin",
      "Qinkai Yu",
      "Dong Shu",
      "Haiyan Zhao",
      "Wenyue Hua",
      "Yanda Meng",
      "Yongfeng Zhang",
      "Mengnan Du"
    ],
    "abstract": "Chain of Thought (CoT) is significant in improving the reasoning abilities of\nlarge language models (LLMs). However, the correlation between the\neffectiveness of CoT and the length of reasoning steps in prompts remains\nlargely unknown. To shed light on this, we have conducted several empirical\nexperiments to explore the relations. Specifically, we design experiments that\nexpand and compress the rationale reasoning steps within CoT demonstrations\nwhile keeping all other factors constant. We have the following key findings.\nFirst, the results indicate that lengthening the reasoning steps in prompts,\neven without adding new information into the prompt, considerably enhances\nLLMs' reasoning abilities across multiple datasets. Alternatively, shortening\nthe reasoning steps, even while preserving the key information, significantly\ndiminishes the reasoning abilities of models. This finding highlights the\nimportance of the number of steps in CoT prompts and provides practical\nguidance to make better use of LLMs' potential in complex problem-solving\nscenarios. Second, we also investigated the relationship between the\nperformance of CoT and the rationales used in demonstrations. Surprisingly, the\nresult shows that even incorrect rationales can yield favorable outcomes if\nthey maintain the requisite length of inference. Third, we observed that the\nadvantages of increasing reasoning steps are task-dependent: simpler tasks\nrequire fewer steps, whereas complex tasks gain significantly from longer\ninference sequences. The code is available at\nhttps://github.com/MingyuJ666/The-Impact-of-Reasoning-Step-Length-on-Large-Language-Models",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Findings of ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.04925v4",
    "published_date": "2024-01-10 04:37:38 UTC",
    "updated_date": "2024-06-22 08:18:48 UTC"
  },
  {
    "arxiv_id": "2401.04898v2",
    "title": "ANGO: A Next-Level Evaluation Benchmark For Generation-Oriented Language Models In Chinese Domain",
    "authors": [
      "Bingchao Wang"
    ],
    "abstract": "Recently, various Large Language Models (LLMs) evaluation datasets have\nemerged, but most of them have issues with distorted rankings and difficulty in\nmodel capabilities analysis. Addressing these concerns, this paper introduces\nANGO, a Chinese multi-choice question evaluation benchmark. ANGO proposes\nKeypoint categorization standard for the first time, each question in ANGO can\ncorrespond to multiple keypoints, effectively enhancing interpretability of\nevaluation results. Base on performance of real humans, we build a quantifiable\nquestion difficulty standard and divide ANGO questions into 9 difficulty\nlevels, which provide more precise guidance for model training. To minimize\ndata leakage impact and fully leverage ANGO's innovative features, we have\nengineered exclusive sampling strategies and a new evaluation framework that\nsupport swift testset iteration. Our experiments demonstrate that ANGO poses a\nstronger challenge to models and reveals more details in evaluation result\ncompared to existing benchmarks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.04898v2",
    "published_date": "2024-01-10 02:59:49 UTC",
    "updated_date": "2024-02-21 06:44:37 UTC"
  },
  {
    "arxiv_id": "2401.06800v1",
    "title": "Reinforcement Learning for Optimizing RAG for Domain Chatbots",
    "authors": [
      "Mandar Kulkarni",
      "Praveen Tangarajan",
      "Kyung Kim",
      "Anusua Trivedi"
    ],
    "abstract": "With the advent of Large Language Models (LLM), conversational assistants\nhave become prevalent for domain use cases. LLMs acquire the ability to\ncontextual question answering through training, and Retrieval Augmented\nGeneration (RAG) further enables the bot to answer domain-specific questions.\nThis paper describes a RAG-based approach for building a chatbot that answers\nuser's queries using Frequently Asked Questions (FAQ) data. We train an\nin-house retrieval embedding model using infoNCE loss, and experimental results\ndemonstrate that the in-house model works significantly better than the\nwell-known general-purpose public embedding model, both in terms of retrieval\naccuracy and Out-of-Domain (OOD) query detection. As an LLM, we use an open\nAPI-based paid ChatGPT model. We noticed that a previously retrieved-context\ncould be used to generate an answer for specific patterns/sequences of queries\n(e.g., follow-up queries). Hence, there is a scope to optimize the number of\nLLM tokens and cost. Assuming a fixed retrieval model and an LLM, we optimize\nthe number of LLM tokens using Reinforcement Learning (RL). Specifically, we\npropose a policy-based model external to the RAG, which interacts with the RAG\npipeline through policy actions and updates the policy to optimize the cost.\nThe policy model can perform two actions: to fetch FAQ context or skip\nretrieval. We use the open API-based GPT-4 as the reward model. We then train a\npolicy model using policy gradient on multiple training chat sessions. As a\npolicy model, we experimented with a public gpt-2 model and an in-house BERT\nmodel. With the proposed RL-based optimization combined with similarity\nthreshold, we are able to achieve significant cost savings while getting a\nslightly improved accuracy. Though we demonstrate results for the FAQ chatbot,\nthe proposed RL approach is generic and can be experimented with any existing\nRAG pipeline.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.06800v1",
    "published_date": "2024-01-10 02:57:20 UTC",
    "updated_date": "2024-01-10 02:57:20 UTC"
  },
  {
    "arxiv_id": "2402.18576v1",
    "title": "Improved Forecasting Using a PSO-RDV Framework to Enhance Artificial Neural Network",
    "authors": [
      "Sales Aribe Jr"
    ],
    "abstract": "Decision making and planning have long relied heavily on AI-driven forecasts.\nThe government and the general public are working to minimize the risks while\nmaximizing benefits in the face of potential future public health\nuncertainties. This study used an improved method of forecasting utilizing the\nRandom Descending Velocity Inertia Weight (RDV IW) technique to improve the\nconvergence of Particle Swarm Optimization (PSO) and the accuracy of Artificial\nNeural Network (ANN). The IW technique, inspired by the motions of a golf ball,\nmodified the particles' velocities as they approached the solution point to a\nparabolically descending structure. Simulation results revealed that the\nproposed forecasting model with [0.4, 0.9] combination of alpha and alpha_dump\nexhibits a 6.36% improvement in position error and 11.75% improvement in\ncomputational time compared to the old model, thus, improving its convergence.\nIt reached the optimum level at minimal steps with 12.50% improvement as\nagainst the old model since it provides better velocity averages when speed\nstabilization occurs at the 24th iteration. Meanwhile, the computed p-values\nfor NRMSE (0.04889174), MAE (0.02829063), MAPE (0.02226053), WAPE (0.01701545),\nand R2 (0.00000021) of the proposed algorithm are less than the set 0.05 level\nof significance, thus the values indicated a significant result in terms of\naccuracy performance. Applying the modified ANN-PSO using RDV IW technique\ngreatly improved the new HIV/AIDS forecasting model compared with the two\nmodels.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "9 pages, 4 figures, Published with International Journal of\n  Engineering Trends and Technology (IJETT)",
    "pdf_url": "http://arxiv.org/pdf/2402.18576v1",
    "published_date": "2024-01-10 01:15:33 UTC",
    "updated_date": "2024-01-10 01:15:33 UTC"
  },
  {
    "arxiv_id": "2401.05453v2",
    "title": "Dimensionality-Aware Outlier Detection: Theoretical and Experimental Analysis",
    "authors": [
      "Alastair Anderberg",
      "James Bailey",
      "Ricardo J. G. B. Campello",
      "Michael E. Houle",
      "Henrique O. Marques",
      "Miloš Radovanović",
      "Arthur Zimek"
    ],
    "abstract": "We present a nonparametric method for outlier detection that takes full\naccount of local variations in intrinsic dimensionality within the dataset.\nUsing the theory of Local Intrinsic Dimensionality (LID), our\n'dimensionality-aware' outlier detection method, DAO, is derived as an\nestimator of an asymptotic local expected density ratio involving the query\npoint and a close neighbor drawn at random. The dimensionality-aware behavior\nof DAO is due to its use of local estimation of LID values in a\ntheoretically-justified way. Through comprehensive experimentation on more than\n800 synthetic and real datasets, we show that DAO significantly outperforms\nthree popular and important benchmark outlier detection methods: Local Outlier\nFactor (LOF), Simplified LOF, and kNN.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "68T99 (Primary) 62G07, 62G32, 62H30 (Secondary)"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages, 3 figures. Extended version of a paper accepted for\n  publication at the SIAM International Conference on Data Mining (SDM24)",
    "pdf_url": "http://arxiv.org/pdf/2401.05453v2",
    "published_date": "2024-01-10 01:07:35 UTC",
    "updated_date": "2024-04-21 03:57:31 UTC"
  },
  {
    "arxiv_id": "2401.04867v2",
    "title": "An Analysis of User Behaviors for Objectively Evaluating Spoken Dialogue Systems",
    "authors": [
      "Koji Inoue",
      "Divesh Lala",
      "Keiko Ochi",
      "Tatsuya Kawahara",
      "Gabriel Skantze"
    ],
    "abstract": "Establishing evaluation schemes for spoken dialogue systems is important, but\nit can also be challenging. While subjective evaluations are commonly used in\nuser experiments, objective evaluations are necessary for research comparison\nand reproducibility. To address this issue, we propose a framework for\nindirectly but objectively evaluating systems based on users' behaviors. In\nthis paper, to this end, we investigate the relationship between user behaviors\nand subjective evaluation scores in social dialogue tasks: attentive listening,\njob interview, and first-meeting conversation. The results reveal that in\ndialogue tasks where user utterances are primary, such as attentive listening\nand job interview, indicators like the number of utterances and words play a\nsignificant role in evaluation. Observing disfluency also can indicate the\neffectiveness of formal tasks, such as job interview. On the other hand, in\ndialogue tasks with high interactivity, such as first-meeting conversation,\nbehaviors related to turn-taking, like average switch pause length, become more\nimportant. These findings suggest that selecting appropriate user behaviors can\nprovide valuable insights for objective evaluation in each social dialogue\ntask.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "This paper has been accepted for presentation at International\n  Workshop on Spoken Dialogue Systems Technology 2024 (IWSDS 2024) and\n  represents the author's version of the work",
    "pdf_url": "http://arxiv.org/pdf/2401.04867v2",
    "published_date": "2024-01-10 01:02:26 UTC",
    "updated_date": "2024-01-23 06:48:45 UTC"
  },
  {
    "arxiv_id": "2401.04858v1",
    "title": "User Embedding Model for Personalized Language Prompting",
    "authors": [
      "Sumanth Doddapaneni",
      "Krishna Sayana",
      "Ambarish Jash",
      "Sukhdeep Sodhi",
      "Dima Kuzmin"
    ],
    "abstract": "Modeling long histories plays a pivotal role in enhancing recommendation\nsystems, allowing to capture user's evolving preferences, resulting in more\nprecise and personalized recommendations. In this study we tackle the\nchallenges of modeling long user histories for preference understanding in\nnatural language. Specifically, we introduce a new User Embedding Module (UEM)\nthat efficiently processes user history in free-form text by compressing and\nrepresenting them as embeddings, to use them as soft prompts to a LM. Our\nexperiments demonstrate the superior capability of this approach in handling\nsignificantly longer histories compared to conventional text based prompting\nmethods, yielding substantial improvements in predictive performance. The main\ncontribution of this research is to demonstrate the ability to bias language\nmodels with user signals represented as embeddings.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.04858v1",
    "published_date": "2024-01-10 00:35:52 UTC",
    "updated_date": "2024-01-10 00:35:52 UTC"
  }
]