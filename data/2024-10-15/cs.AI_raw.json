[
  {
    "arxiv_id": "2410.12124v1",
    "title": "Affordance-Centric Policy Learning: Sample Efficient and Generalisable Robot Policy Learning using Affordance-Centric Task Frames",
    "authors": [
      "Krishan Rana",
      "Jad Abou-Chakra",
      "Sourav Garg",
      "Robert Lee",
      "Ian Reid",
      "Niko Suenderhauf"
    ],
    "abstract": "Affordances are central to robotic manipulation, where most tasks can be\nsimplified to interactions with task-specific regions on objects. By focusing\non these key regions, we can abstract away task-irrelevant information,\nsimplifying the learning process, and enhancing generalisation. In this paper,\nwe propose an affordance-centric policy-learning approach that centres and\nappropriately \\textit{orients} a \\textit{task frame} on these affordance\nregions allowing us to achieve both \\textbf{intra-category invariance} -- where\npolicies can generalise across different instances within the same object\ncategory -- and \\textbf{spatial invariance} -- which enables consistent\nperformance regardless of object placement in the environment. We propose a\nmethod to leverage existing generalist large vision models to extract and track\nthese affordance frames, and demonstrate that our approach can learn\nmanipulation tasks using behaviour cloning from as little as 10 demonstrations,\nwith equivalent generalisation to an image-based policy trained on 305\ndemonstrations. We provide video demonstrations on our project site:\nhttps://affordance-policy.github.io.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Video can be found on our project website:\n  https://affordance-policy.github.io",
    "pdf_url": "http://arxiv.org/pdf/2410.12124v1",
    "published_date": "2024-10-15 23:57:35 UTC",
    "updated_date": "2024-10-15 23:57:35 UTC"
  },
  {
    "arxiv_id": "2410.12112v2",
    "title": "Planning Anything with Rigor: General-Purpose Zero-Shot Planning with LLM-based Formalized Programming",
    "authors": [
      "Yilun Hao",
      "Yang Zhang",
      "Chuchu Fan"
    ],
    "abstract": "While large language models (LLMs) have recently demonstrated strong\npotential in solving planning problems, there is a trade-off between\nflexibility and complexity. LLMs, as zero-shot planners themselves, are still\nnot capable of directly generating valid plans for complex planning problems\nsuch as multi-constraint or long-horizon tasks. On the other hand, many\nframeworks aiming to solve complex planning problems often rely on\ntask-specific preparatory efforts, such as task-specific in-context examples\nand pre-defined critics/verifiers, which limits their cross-task generalization\ncapability. In this paper, we tackle these challenges by observing that the\ncore of many planning problems lies in optimization problems: searching for the\noptimal solution (best plan) with goals subject to constraints (preconditions\nand effects of decisions). With LLMs' commonsense, reasoning, and programming\ncapabilities, this opens up the possibilities of a universal LLM-based approach\nto planning problems. Inspired by this observation, we propose LLMFP, a\ngeneral-purpose framework that leverages LLMs to capture key information from\nplanning problems and formally formulate and solve them as optimization\nproblems from scratch, with no task-specific examples needed. We apply LLMFP to\n9 planning problems, ranging from multi-constraint decision making to\nmulti-step planning problems, and demonstrate that LLMFP achieves on average\n83.7% and 86.8% optimal rate across 9 tasks for GPT-4o and Claude 3.5 Sonnet,\nsignificantly outperforming the best baseline (direct planning with OpenAI\no1-preview) with 37.6% and 40.7% improvements. We also validate components of\nLLMFP with ablation experiments and analyzed the underlying success and failure\nreasons. Project page: https://sites.google.com/view/llmfp.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "57 pages, 25 figures, 15 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.12112v2",
    "published_date": "2024-10-15 23:20:54 UTC",
    "updated_date": "2025-01-29 16:31:53 UTC"
  },
  {
    "arxiv_id": "2410.12107v1",
    "title": "Just-In-Time Software Defect Prediction via Bi-modal Change Representation Learning",
    "authors": [
      "Yuze Jiang",
      "Beijun Shen",
      "Xiaodong Gu"
    ],
    "abstract": "For predicting software defects at an early stage, researchers have proposed\njust-in-time defect prediction (JIT-DP) to identify potential defects in code\ncommits. The prevailing approaches train models to represent code changes in\nhistory commits and utilize the learned representations to predict the presence\nof defects in the latest commit. However, existing models merely learn editions\nin source code, without considering the natural language intentions behind the\nchanges. This limitation hinders their ability to capture deeper semantics. To\naddress this, we introduce a novel bi-modal change pre-training model called\nBiCC-BERT. BiCC-BERT is pre-trained on a code change corpus to learn bi-modal\nsemantic representations. To incorporate commit messages from the corpus, we\ndesign a novel pre-training objective called Replaced Message Identification\n(RMI), which learns the semantic association between commit messages and code\nchanges. Subsequently, we integrate BiCC-BERT into JIT-DP and propose a new\ndefect prediction approach -- JIT-BiCC. By leveraging the bi-modal\nrepresentations from BiCC-BERT, JIT-BiCC captures more profound change\nsemantics. We train JIT-BiCC using 27,391 code changes and compare its\nperformance with 8 state-of-the-art JIT-DP approaches. The results demonstrate\nthat JIT-BiCC outperforms all baselines, achieving a 10.8% improvement in\nF1-score. This highlights its effectiveness in learning the bi-modal semantics\nfor JIT-DP.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted by JSS (The Journal of Systems & Software)",
    "pdf_url": "http://arxiv.org/pdf/2410.12107v1",
    "published_date": "2024-10-15 23:13:29 UTC",
    "updated_date": "2024-10-15 23:13:29 UTC"
  },
  {
    "arxiv_id": "2410.12101v2",
    "title": "The Persian Rug: solving toy models of superposition using large-scale symmetries",
    "authors": [
      "Aditya Cowsik",
      "Kfir Dolev",
      "Alex Infanger"
    ],
    "abstract": "We present a complete mechanistic description of the algorithm learned by a\nminimal non-linear sparse data autoencoder in the limit of large input\ndimension. The model, originally presented in arXiv:2209.10652, compresses\nsparse data vectors through a linear layer and decompresses using another\nlinear layer followed by a ReLU activation. We notice that when the data is\npermutation symmetric (no input feature is privileged) large models reliably\nlearn an algorithm that is sensitive to individual weights only through their\nlarge-scale statistics. For these models, the loss function becomes\nanalytically tractable. Using this understanding, we give the explicit scalings\nof the loss at high sparsity, and show that the model is near-optimal among\nrecently proposed architectures. In particular, changing or adding to the\nactivation function any elementwise or filtering operation can at best improve\nthe model's performance by a constant factor. Finally, we forward-engineer a\nmodel with the requisite symmetries and show that its loss precisely matches\nthat of the trained models. Unlike the trained model weights, the low\nrandomness in the artificial weights results in miraculous fractal structures\nresembling a Persian rug, to which the algorithm is oblivious. Our work\ncontributes to neural network interpretability by introducing techniques for\nunderstanding the structure of autoencoders. Code to reproduce our results can\nbe found at https://github.com/KfirD/PersianRug .",
    "categories": [
      "cs.LG",
      "cond-mat.dis-nn",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Improved arguments, presentation. No changes to results",
    "pdf_url": "http://arxiv.org/pdf/2410.12101v2",
    "published_date": "2024-10-15 22:52:45 UTC",
    "updated_date": "2024-10-22 17:48:56 UTC"
  },
  {
    "arxiv_id": "2410.12096v1",
    "title": "Bridging Large Language Models and Graph Structure Learning Models for Robust Representation Learning",
    "authors": [
      "Guangxin Su",
      "Yifan Zhu",
      "Wenjie Zhang",
      "Hanchen Wang",
      "Ying Zhang"
    ],
    "abstract": "Graph representation learning, involving both node features and graph\nstructures, is crucial for real-world applications but often encounters\npervasive noise. State-of-the-art methods typically address noise by focusing\nseparately on node features with large language models (LLMs) and on graph\nstructures with graph structure learning models (GSLMs). In this paper, we\nintroduce LangGSL, a robust framework that integrates the complementary\nstrengths of pre-trained language models and GSLMs to jointly enhance both node\nfeature and graph structure learning. In LangGSL, we first leverage LLMs to\nfilter noise in the raw data and extract valuable cleaned information as\nfeatures, enhancing the synergy of downstream models. During the mutual\nlearning phase in LangGSL, the core idea is to leverage the relatively small\nlanguage model (LM) to process local attributes and generate reliable\npseudo-labels and informative node embeddings, which are then integrated into\nthe GSLM's prediction phase. This approach enriches the global context and\nenhances overall performance. Meanwhile, GSLM refines the evolving graph\nstructure constructed from the LM's output, offering updated labels back to the\nLM as additional guidance, thus facilitating a more effective mutual learning\nprocess. The LM and GSLM work synergistically, complementing each other's\nstrengths and offsetting weaknesses within a variational information-maximizing\nframework, resulting in enhanced node features and a more robust graph\nstructure. Extensive experiments on diverse graph datasets of varying scales\nand across different task scenarios demonstrate the scalability and\neffectiveness of the proposed approach.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Graph structure learning, Graph representation learning, Large\n  language models, Graph neural networks",
    "pdf_url": "http://arxiv.org/pdf/2410.12096v1",
    "published_date": "2024-10-15 22:43:32 UTC",
    "updated_date": "2024-10-15 22:43:32 UTC"
  },
  {
    "arxiv_id": "2410.12091v1",
    "title": "Generative AI's aggregated knowledge versus web-based curated knowledge",
    "authors": [
      "Ted Selker",
      "Yunzi Wu"
    ],
    "abstract": "his paper explores what kinds of questions are best served by the way\ngenerative AI (GenAI) using Large Language Models(LLMs) that aggregate and\npackage knowledge, and when traditional curated web-sourced search results\nserve users better.\n  An experiment compared product searches using ChatGPT, Google search engine,\nor both helped us understand more about the compelling nature of generated\nresponses. The experiment showed GenAI can speed up some explorations and\ndecisions. We describe how search can deepen the testing of facts, logic, and\ncontext. We show where existing and emerging knowledge paradigms can help\nknowledge exploration in different ways.\n  Experimenting with searches, our probes showed the value for curated web\nsearch provides for very specific, less popularly-known knowledge. GenAI\nexcelled at bringing together knowledge for broad, relatively well-known\ntopics. The value of curated and aggregated knowledge for different kinds of\nknowledge reflected in different user goals. We developed a taxonomy to\ndistinguishing when users are best served by these two approaches.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "19 pages, 19 references, 8 pages of appendices, 15 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.12091v1",
    "published_date": "2024-10-15 22:17:45 UTC",
    "updated_date": "2024-10-15 22:17:45 UTC"
  },
  {
    "arxiv_id": "2410.12085v2",
    "title": "Data-adaptive Differentially Private Prompt Synthesis for In-Context Learning",
    "authors": [
      "Fengyu Gao",
      "Ruida Zhou",
      "Tianhao Wang",
      "Cong Shen",
      "Jing Yang"
    ],
    "abstract": "Large Language Models (LLMs) rely on the contextual information embedded in\nexamples/demonstrations to perform in-context learning (ICL). To mitigate the\nrisk of LLMs potentially leaking private information contained in examples in\nthe prompt, we introduce a novel data-adaptive differentially private algorithm\ncalled AdaDPSyn to generate synthetic examples from the private dataset and\nthen use these synthetic examples to perform ICL. The objective of AdaDPSyn is\nto adaptively adjust the noise level in the data synthesis mechanism according\nto the inherent statistical properties of the data, thereby preserving high ICL\naccuracy while maintaining formal differential privacy guarantees. A key\ninnovation in AdaDPSyn is the Precision-Focused Iterative Radius Reduction\ntechnique, which dynamically refines the aggregation radius - the scope of data\ngrouping for noise addition - based on patterns observed in data clustering,\nthereby minimizing the amount of additive noise. We conduct extensive\nexperiments on standard benchmarks and compare AdaDPSyn with DP few-shot\ngeneration algorithm (Tang et al., 2023). The experiments demonstrate that\nAdaDPSyn not only outperforms DP few-shot generation, but also maintains high\naccuracy levels close to those of non-private baselines, providing an effective\nsolution for ICL with privacy protection.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted to ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.12085v2",
    "published_date": "2024-10-15 22:06:30 UTC",
    "updated_date": "2025-03-02 06:29:15 UTC"
  },
  {
    "arxiv_id": "2410.19793v1",
    "title": "Single-word Auditory Attention Decoding Using Deep Learning Model",
    "authors": [
      "Nhan Duc Thanh Nguyen",
      "Huy Phan",
      "Kaare Mikkelsen",
      "Preben Kidmose"
    ],
    "abstract": "Identifying auditory attention by comparing auditory stimuli and\ncorresponding brain responses, is known as auditory attention decoding (AAD).\nThe majority of AAD algorithms utilize the so-called envelope entrainment\nmechanism, whereby auditory attention is identified by how the envelope of the\nauditory stream drives variation in the electroencephalography (EEG) signal.\nHowever, neural processing can also be decoded based on endogenous cognitive\nresponses, in this case, neural responses evoked by attention to specific words\nin a speech stream. This approach is largely unexplored in the field of AAD but\nleads to a single-word auditory attention decoding problem in which an epoch of\nan EEG signal timed to a specific word is labeled as attended or unattended.\nThis paper presents a deep learning approach, based on EEGNet, to address this\nchallenge. We conducted a subject-independent evaluation on an event-based AAD\ndataset with three different paradigms: word category oddball, word category\nwith competing speakers, and competing speech streams with targets. The results\ndemonstrate that the adapted model is capable of exploiting cognitive-related\nspatiotemporal EEG features and achieving at least 58% accuracy on the most\nrealistic competing paradigm for the unseen subjects. To our knowledge, this is\nthe first study dealing with this problem.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.HC",
      "cs.SD",
      "eess.AS",
      "q-bio.NC"
    ],
    "primary_category": "eess.SP",
    "comment": "5 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.19793v1",
    "published_date": "2024-10-15 21:57:19 UTC",
    "updated_date": "2024-10-15 21:57:19 UTC"
  },
  {
    "arxiv_id": "2410.23299v1",
    "title": "FVEval: Understanding Language Model Capabilities in Formal Verification of Digital Hardware",
    "authors": [
      "Minwoo Kang",
      "Mingjie Liu",
      "Ghaith Bany Hamad",
      "Syed Suhaib",
      "Haoxing Ren"
    ],
    "abstract": "The remarkable reasoning and code generation capabilities of large language\nmodels (LLMs) have spurred significant interest in applying LLMs to enable task\nautomation in digital chip design. In particular, recent work has investigated\nearly ideas of applying these models to formal verification (FV), an approach\nto verifying hardware implementations that can provide strong guarantees of\nconfidence but demands significant amounts of human effort. While the value of\nLLM-driven automation is evident, our understanding of model performance,\nhowever, has been hindered by the lack of holistic evaluation. In response, we\npresent FVEval, the first comprehensive benchmark and evaluation framework for\ncharacterizing LLM performance in tasks pertaining to FV. The benchmark\nconsists of three sub-tasks that measure LLM capabilities at different levels:\nfrom the generation of SystemVerilog assertions (SVAs) given natural language\ndescriptions to reasoning about the design RTL and suggesting assertions\ndirectly without additional human input. As test instances, we present both\ncollections of expert-written verification collateral and methodologies to\nscalably generate synthetic examples aligned with industrial FV workflows. A\nwide range of existing LLMs, both proprietary and open-source, are evaluated\nagainst FVEval, based on which we investigate where today's LLMs stand and how\nwe might further enable their application toward improving productivity in\ndigital FV. Our benchmark and evaluation code is available at\n\\url{https://github.com/NVlabs/FVEval}.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.23299v1",
    "published_date": "2024-10-15 21:48:57 UTC",
    "updated_date": "2024-10-15 21:48:57 UTC"
  },
  {
    "arxiv_id": "2410.12075v2",
    "title": "WeatherDG: LLM-assisted Diffusion Model for Procedural Weather Generation in Domain-Generalized Semantic Segmentation",
    "authors": [
      "Chenghao Qian",
      "Yuhu Guo",
      "Yuhong Mo",
      "Wenjing Li"
    ],
    "abstract": "In this work, we propose a novel approach, namely WeatherDG, that can\ngenerate realistic, weather-diverse, and driving-screen images based on the\ncooperation of two foundation models, i.e, Stable Diffusion (SD) and Large\nLanguage Model (LLM). Specifically, we first fine-tune the SD with source data,\naligning the content and layout of generated samples with real-world driving\nscenarios. Then, we propose a procedural prompt generation method based on LLM,\nwhich can enrich scenario descriptions and help SD automatically generate more\ndiverse, detailed images. In addition, we introduce a balanced generation\nstrategy, which encourages the SD to generate high-quality objects of tailed\nclasses under various weather conditions, such as riders and motorcycles. This\nsegmentation-model-agnostic method can improve the generalization ability of\nexisting models by additionally adapting them with the generated synthetic\ndata. Experiments on three challenging datasets show that our method can\nsignificantly improve the segmentation performance of different\nstate-of-the-art models on target domains. Notably, in the setting of\n''Cityscapes to ACDC'', our method improves the baseline HRDA by 13.9% in mIoU.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12075v2",
    "published_date": "2024-10-15 21:29:26 UTC",
    "updated_date": "2024-12-30 13:34:23 UTC"
  },
  {
    "arxiv_id": "2410.12068v1",
    "title": "V3D-SLAM: Robust RGB-D SLAM in Dynamic Environments with 3D Semantic Geometry Voting",
    "authors": [
      "Tuan Dang",
      "Khang Nguyen",
      "Mandfred Huber"
    ],
    "abstract": "Simultaneous localization and mapping (SLAM) in highly dynamic environments\nis challenging due to the correlation complexity between moving objects and the\ncamera pose. Many methods have been proposed to deal with this problem;\nhowever, the moving properties of dynamic objects with a moving camera remain\nunclear. Therefore, to improve SLAM's performance, minimizing disruptive events\nof moving objects with a physical understanding of 3D shapes and dynamics of\nobjects is needed. In this paper, we propose a robust method, V3D-SLAM, to\nremove moving objects via two lightweight re-evaluation stages, including\nidentifying potentially moving and static objects using a spatial-reasoned\nHough voting mechanism and refining static objects by detecting dynamic noise\ncaused by intra-object motions using Chamfer distances as similarity\nmeasurements. Our experiment on the TUM RGB-D benchmark on dynamic sequences\nwith ground-truth camera trajectories showed that our methods outperform the\nmost recent state-of-the-art SLAM methods. Our source code is available at\nhttps://github.com/tuantdang/v3d-slam.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12068v1",
    "published_date": "2024-10-15 21:08:08 UTC",
    "updated_date": "2024-10-15 21:08:08 UTC"
  },
  {
    "arxiv_id": "2410.14724v1",
    "title": "A Phenomenological AI Foundation Model for Physical Signals",
    "authors": [
      "Jaime Lien",
      "Laura I. Galindez Olascoaga",
      "Hasan Dogan",
      "Nicholas Gillian",
      "Brandon Barbello",
      "Leonardo Giusti",
      "Ivan Poupyrev"
    ],
    "abstract": "The objective of this work is to develop an AI foundation model for physical\nsignals that can generalize across diverse phenomena, domains, applications,\nand sensing apparatuses. We propose a phenomenological approach and framework\nfor creating and validating such AI foundation models. Based on this framework,\nwe developed and trained a model on 0.59 billion samples of cross-modal sensor\nmeasurements, ranging from electrical current to fluid flow to optical sensors.\nNotably, no prior knowledge of physical laws or inductive biases were\nintroduced into the model. Through several real-world experiments, we\ndemonstrate that a single foundation model could effectively encode and predict\nphysical behaviors, such as mechanical motion and thermodynamics, including\nphenomena not seen in training. The model also scales across physical processes\nof varying complexity, from tracking the trajectory of a simple spring-mass\nsystem to forecasting large electrical grid dynamics. This work highlights the\npotential of building a unified AI foundation model for diverse physical world\nprocesses.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.14724v1",
    "published_date": "2024-10-15 21:03:53 UTC",
    "updated_date": "2024-10-15 21:03:53 UTC"
  },
  {
    "arxiv_id": "2410.12062v1",
    "title": "MFC-EQ: Mean-Field Control with Envelope Q-Learning for Moving Decentralized Agents in Formation",
    "authors": [
      "Qiushi Lin",
      "Hang Ma"
    ],
    "abstract": "We study a decentralized version of Moving Agents in Formation (MAiF), a\nvariant of Multi-Agent Path Finding aiming to plan collision-free paths for\nmultiple agents with the dual objectives of reaching their goals quickly while\nmaintaining a desired formation. The agents must balance these objectives under\nconditions of partial observation and limited communication. The formation\nmaintenance depends on the joint state of all agents, whose dimensionality\nincreases exponentially with the number of agents, rendering the learning\nprocess intractable. Additionally, learning a single policy that can\naccommodate different linear preferences for these two objectives presents a\nsignificant challenge. In this paper, we propose Mean-Field Control with\nEnvelop $Q$-learning (MFC-EQ), a scalable and adaptable learning framework for\nthis bi-objective multi-agent problem. We approximate the dynamics of all\nagents using mean-field theory while learning a universal preference-agnostic\npolicy through envelop $Q$-learning. Our empirical evaluation of MFC-EQ across\nnumerous instances shows that it outperforms state-of-the-art centralized MAiF\nbaselines. Furthermore, MFC-EQ effectively handles more complex scenarios where\nthe desired formation changes dynamically -- a challenge that existing MAiF\nplanners cannot address.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted to IROS 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.12062v1",
    "published_date": "2024-10-15 20:59:47 UTC",
    "updated_date": "2024-10-15 20:59:47 UTC"
  },
  {
    "arxiv_id": "2410.12061v2",
    "title": "CrediRAG: Network-Augmented Credibility-Based Retrieval for Misinformation Detection in Reddit",
    "authors": [
      "Ashwin Ram",
      "Yigit Ege Bayiz",
      "Arash Amini",
      "Mustafa Munir",
      "Radu Marculescu"
    ],
    "abstract": "Fake news threatens democracy and exacerbates the polarization and divisions\nin society; therefore, accurately detecting online misinformation is the\nfoundation of addressing this issue. We present CrediRAG, the first fake news\ndetection model that combines language models with access to a rich external\npolitical knowledge base with a dense social network to detect fake news across\nsocial media at scale. CrediRAG uses a news retriever to initially assign a\nmisinformation score to each post based on the source credibility of similar\nnews articles to the post title content. CrediRAG then improves the initial\nretrieval estimations through a novel weighted post-to-post network connected\nbased on shared commenters and weighted by the average stance of all shared\ncommenters across every pair of posts. We achieve 11% increase in the F1-score\nin detecting misinformative posts over state-of-the-art methods. Extensive\nexperiments conducted on curated real-world Reddit data of over 200,000 posts\ndemonstrate the superior performance of CrediRAG on existing baselines. Thus,\nour approach offers a more accurate and scalable solution to combat the spread\nof fake news across social media platforms.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12061v2",
    "published_date": "2024-10-15 20:58:42 UTC",
    "updated_date": "2024-10-26 20:27:22 UTC"
  },
  {
    "arxiv_id": "2410.12057v2",
    "title": "Large-scale cloze evaluation reveals that token prediction tasks are neither lexically nor semantically aligned",
    "authors": [
      "Cassandra L. Jacobs",
      "Loïc Grobol",
      "Alvin Tsang"
    ],
    "abstract": "In this work we compare the generative behavior at the next token prediction\nlevel in several language models by comparing them to human productions in the\ncloze task. We find that while large models trained for longer are typically\nbetter estimators of human productions, but they reliably under-estimate the\nprobabilities of human responses, over-rank rare responses, under-rank top\nresponses, and produce highly distinct semantic spaces. Altogether, this work\ndemonstrates in a tractable, interpretable domain that LM generations can not\nbe used as replacements of or models of the cloze task.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12057v2",
    "published_date": "2024-10-15 20:52:09 UTC",
    "updated_date": "2024-10-28 17:45:56 UTC"
  },
  {
    "arxiv_id": "2410.12051v1",
    "title": "Enabling Data-Driven and Empathetic Interactions: A Context-Aware 3D Virtual Agent in Mixed Reality for Enhanced Financial Customer Experience",
    "authors": [
      "Cindy Xu",
      "Mengyu Chen",
      "Pranav Deshpande",
      "Elvir Azanli",
      "Runqing Yang",
      "Joseph Ligman"
    ],
    "abstract": "In this paper, we introduce a novel system designed to enhance customer\nservice in the financial and retail sectors through a context-aware 3D virtual\nagent, utilizing Mixed Reality (MR) and Vision Language Models (VLMs). Our\napproach focuses on enabling data-driven and empathetic interactions that\nensure customer satisfaction by introducing situational awareness of the\nphysical location, personalized interactions based on customer profiles, and\nrigorous privacy and security standards. We discuss our design considerations\ncritical for deployment in real-world customer service environments, addressing\nchallenges in user data management and sensitive information handling. We also\noutline the system architecture and key features unique to banking and retail\nenvironments. Our work demonstrates the potential of integrating MR and VLMs in\nservice industries, offering practical insights in customer service delivery\nwhile maintaining high standards of security and personalization.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.ET",
      "cs.MM",
      "H.5.1; K.4.3"
    ],
    "primary_category": "cs.HC",
    "comment": "to appear at 1st Workshop on Intelligent XR: Harnessing AI for\n  Next-Generation XR User Experiences at International Symposium on Mixed and\n  Augmented Reality (ISMAR) 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.12051v1",
    "published_date": "2024-10-15 20:41:10 UTC",
    "updated_date": "2024-10-15 20:41:10 UTC"
  },
  {
    "arxiv_id": "2410.12049v4",
    "title": "Sabiá-3 Technical Report",
    "authors": [
      "Hugo Abonizio",
      "Thales Sales Almeida",
      "Thiago Laitz",
      "Roseval Malaquias Junior",
      "Giovana Kerche Bonás",
      "Rodrigo Nogueira",
      "Ramon Pires"
    ],
    "abstract": "This report presents Sabi\\'a-3, our new flagship language model, and\nSabiazinho-3, a more cost-effective sibling. The models were trained on a large\nbrazilian-centric corpus. Evaluations across diverse professional and academic\nbenchmarks show a strong performance on Portuguese and Brazil-related tasks.\nSabi\\'a-3 shows large improvements in comparison to our previous best of model,\nSabia-2 Medium, especially in reasoning-intensive tasks. Notably, Sabi\\'a-3's\naverage performance matches frontier LLMs, while it is offered at a three to\nfour times lower cost per token, reinforcing the benefits of domain\nspecialization.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12049v4",
    "published_date": "2024-10-15 20:37:34 UTC",
    "updated_date": "2025-04-01 12:19:49 UTC"
  },
  {
    "arxiv_id": "2410.12040v1",
    "title": "Concept-Reversed Winograd Schema Challenge: Evaluating and Improving Robust Reasoning in Large Language Models via Abstraction",
    "authors": [
      "Kaiqiao Han",
      "Tianqing Fang",
      "Zhaowei Wang",
      "Yangqiu Song",
      "Mark Steedman"
    ],
    "abstract": "While Large Language Models (LLMs) have showcased remarkable proficiency in\nreasoning, there is still a concern about hallucinations and unreliable\nreasoning issues due to semantic associations and superficial logical chains.\nTo evaluate the extent to which LLMs perform robust reasoning instead of\nrelying on superficial logical chains, we propose a new evaluation dataset, the\nConcept-Reversed Winograd Schema Challenge (CR-WSC), based on the famous\nWinograd Schema Challenge (WSC) dataset. By simply reversing the concepts to\nthose that are more associated with the wrong answer, we find that the\nperformance of LLMs drops significantly despite the rationale of reasoning\nremaining the same. Furthermore, we propose Abstraction-of-Thought (AoT), a\nnovel prompt method for recovering adversarial cases to normal cases using\nconceptual abstraction to improve LLMs' robustness and consistency in\nreasoning, as demonstrated by experiments on CR-WSC.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12040v1",
    "published_date": "2024-10-15 20:19:27 UTC",
    "updated_date": "2024-10-15 20:19:27 UTC"
  },
  {
    "arxiv_id": "2410.12034v1",
    "title": "A Survey on Deep Tabular Learning",
    "authors": [
      "Shriyank Somvanshi",
      "Subasish Das",
      "Syed Aaqib Javed",
      "Gian Antariksa",
      "Ahmed Hossain"
    ],
    "abstract": "Tabular data, widely used in industries like healthcare, finance, and\ntransportation, presents unique challenges for deep learning due to its\nheterogeneous nature and lack of spatial structure. This survey reviews the\nevolution of deep learning models for tabular data, from early fully connected\nnetworks (FCNs) to advanced architectures like TabNet, SAINT, TabTranSELU, and\nMambaNet. These models incorporate attention mechanisms, feature embeddings,\nand hybrid architectures to address tabular data complexities. TabNet uses\nsequential attention for instance-wise feature selection, improving\ninterpretability, while SAINT combines self-attention and intersample attention\nto capture complex interactions across features and data points, both advancing\nscalability and reducing computational overhead. Hybrid architectures such as\nTabTransformer and FT-Transformer integrate attention mechanisms with\nmulti-layer perceptrons (MLPs) to handle categorical and numerical data, with\nFT-Transformer adapting transformers for tabular datasets. Research continues\nto balance performance and efficiency for large datasets. Graph-based models\nlike GNN4TDL and GANDALF combine neural networks with decision trees or graph\nstructures, enhancing feature representation and mitigating overfitting in\nsmall datasets through advanced regularization techniques. Diffusion-based\nmodels like the Tabular Denoising Diffusion Probabilistic Model (TabDDPM)\ngenerate synthetic data to address data scarcity, improving model robustness.\nSimilarly, models like TabPFN and Ptab leverage pre-trained language models,\nincorporating transfer learning and self-supervised techniques into tabular\ntasks. This survey highlights key advancements and outlines future research\ndirections on scalability, generalization, and interpretability in diverse\ntabular data applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "43 pages, 18 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.12034v1",
    "published_date": "2024-10-15 20:08:08 UTC",
    "updated_date": "2024-10-15 20:08:08 UTC"
  },
  {
    "arxiv_id": "2410.12031v1",
    "title": "A Learning Search Algorithm for the Restricted Longest Common Subsequence Problem",
    "authors": [
      "Marko Djukanović",
      "Jaume Reixach",
      "Ana Nikolikj",
      "Tome Eftimov",
      "Aleksandar Kartelj",
      "Christian Blum"
    ],
    "abstract": "This paper addresses the Restricted Longest Common Subsequence (RLCS)\nproblem, an extension of the well-known Longest Common Subsequence (LCS)\nproblem. This problem has significant applications in bioinformatics,\nparticularly for identifying similarities and discovering mutual patterns and\nimportant motifs among DNA, RNA, and protein sequences. Building on recent\nadvancements in solving this problem through a general search framework, this\npaper introduces two novel heuristic approaches designed to enhance the search\nprocess by steering it towards promising regions in the search space. The first\nheuristic employs a probabilistic model to evaluate partial solutions during\nthe search process. The second heuristic is based on a neural network model\ntrained offline using a genetic algorithm. A key aspect of this approach is\nextracting problem-specific features of partial solutions and the complete\nproblem instance. An effective hybrid method, referred to as the learning beam\nsearch, is developed by combining the trained neural network model with a beam\nsearch framework. An important contribution of this paper is found in the\ngeneration of real-world instances where scientific abstracts serve as input\nstrings, and a set of frequently occurring academic words from the literature\nare used as restricted patterns. Comprehensive experimental evaluations\ndemonstrate the effectiveness of the proposed approaches in solving the RLCS\nproblem. Finally, an empirical explainability analysis is applied to the\nobtained results. In this way, key feature combinations and their respective\ncontributions to the success or failure of the algorithms across different\nproblem types are identified.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "33 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.12031v1",
    "published_date": "2024-10-15 20:02:15 UTC",
    "updated_date": "2024-10-15 20:02:15 UTC"
  },
  {
    "arxiv_id": "2410.12013v1",
    "title": "MoE-Pruner: Pruning Mixture-of-Experts Large Language Model using the Hints from Its Router",
    "authors": [
      "Yanyue Xie",
      "Zhi Zhang",
      "Ding Zhou",
      "Cong Xie",
      "Ziang Song",
      "Xin Liu",
      "Yanzhi Wang",
      "Xue Lin",
      "An Xu"
    ],
    "abstract": "Mixture-of-Experts (MoE) architectures face challenges such as high memory\nconsumption and redundancy in experts. Pruning MoE can reduce network weights\nwhile maintaining model performance. Motivated by the recent observation of\nemergent large magnitude features in Large Language Models (LLM) and MoE\nrouting policy, we propose MoE-Pruner, a method that prunes weights with the\nsmallest magnitudes multiplied by the corresponding input activations and\nrouter weights, on each output neuron. Our pruning method is one-shot,\nrequiring no retraining or weight updates. We evaluate our method on\nMixtral-8x7B and Mixtral-8x22B across multiple language benchmarks.\nExperimental results show that our pruning method significantly outperforms\nstate-of-the-art LLM pruning methods. Furthermore, our pruned MoE models can\nbenefit from a pretrained teacher model through expert-wise knowledge\ndistillation, improving performance post-pruning. Experimental results\ndemonstrate that the Mixtral-8x7B model with 50% sparsity maintains 99% of the\nperformance of the original model after the expert-wise knowledge distillation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12013v1",
    "published_date": "2024-10-15 19:22:27 UTC",
    "updated_date": "2024-10-15 19:22:27 UTC"
  },
  {
    "arxiv_id": "2410.12010v3",
    "title": "Bias Similarity Across Large Language Models",
    "authors": [
      "Hyejun Jeong",
      "Shiqing Ma",
      "Amir Houmansadr"
    ],
    "abstract": "Bias in Large Language Models remains a critical concern as these systems are\nincreasingly deployed in high-stakes applications. Yet most fairness\nevaluations rely on scalar metrics or single-model analysis, overlooking how\nbiases align -- or diverge -- across model families, scales, and tuning\nstrategies. In this work, we reframe bias similarity as a form of functional\nsimilarity and evaluate 24 LLMs from four major families on over one million\nstructured prompts spanning four bias dimensions. Our findings uncover that\nfairness is not strongly determined by model size, architecture, instruction\ntuning, or openness. Instead, bias behaviors are highly context-dependent and\nstructurally persistent, often resistant to current alignment techniques.\nContrary to common assumptions, we find that open-source models frequently\nmatch or outperform proprietary models in both fairness and utility. These\nresults call into question the default reliance on proprietary systems and\nhighlight the need for behaviorally grounded, model-specific audits to better\nunderstand how bias manifests and endures across the LLM landscape.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "under review",
    "pdf_url": "http://arxiv.org/pdf/2410.12010v3",
    "published_date": "2024-10-15 19:21:14 UTC",
    "updated_date": "2025-05-17 09:53:28 UTC"
  },
  {
    "arxiv_id": "2410.12006v1",
    "title": "Beyond Labels: A Self-Supervised Framework with Masked Autoencoders and Random Cropping for Breast Cancer Subtype Classification",
    "authors": [
      "Annalisa Chiocchetti",
      "Marco Dossena",
      "Christopher Irwin",
      "Luigi Portinale"
    ],
    "abstract": "This work contributes to breast cancer sub-type classification using\nhistopathological images. We utilize masked autoencoders (MAEs) to learn a\nself-supervised embedding tailored for computer vision tasks in this domain.\nThis embedding captures informative representations of histopathological data,\nfacilitating feature learning without extensive labeled datasets. During\npre-training, we investigate employing a random crop technique to generate a\nlarge dataset from WSIs automatically. Additionally, we assess the performance\nof linear probes for multi-class classification tasks of cancer sub-types using\nthe representations learnt by the MAE. Our approach aims to achieve strong\nperformance on downstream tasks by leveraging the complementary strengths of\nViTs and autoencoders. We evaluate our model's performance on the BRACS dataset\nand compare it with existing benchmarks.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12006v1",
    "published_date": "2024-10-15 19:13:05 UTC",
    "updated_date": "2024-10-15 19:13:05 UTC"
  },
  {
    "arxiv_id": "2410.11985v1",
    "title": "The Fair Language Model Paradox",
    "authors": [
      "Andrea Pinto",
      "Tomer Galanti",
      "Randall Balestriero"
    ],
    "abstract": "Large Language Models (LLMs) are widely deployed in real-world applications,\nyet little is known about their training dynamics at the token level.\nEvaluation typically relies on aggregated training loss, measured at the batch\nlevel, which overlooks subtle per-token biases arising from (i) varying\ntoken-level dynamics and (ii) structural biases introduced by hyperparameters.\nWhile weight decay is commonly used to stabilize training, we reveal that it\nsilently introduces performance biases detectable only at the token level. In\nfact, we empirically show across different dataset sizes, model architectures\nand sizes ranging from 270M to 3B parameters that as weight decay increases,\nlow-frequency tokens are disproportionately depreciated. This is particularly\nconcerning, as these neglected low-frequency tokens represent the vast majority\nof the token distribution in most languages, calling for novel regularization\ntechniques that ensure fairness across all available tokens.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11985v1",
    "published_date": "2024-10-15 18:47:12 UTC",
    "updated_date": "2024-10-15 18:47:12 UTC"
  },
  {
    "arxiv_id": "2410.11977v4",
    "title": "Generative AI Policies under the Microscope: How CS Conferences Are Navigating the New Frontier in Scholarly Writing",
    "authors": [
      "Mahjabin Nahar",
      "Sian Lee",
      "Rebekah Guillen",
      "Dongwon Lee"
    ],
    "abstract": "As the use of Generative AI (Gen-AI) in scholarly writing and peer reviews\ncontinues to rise, it is essential for the computing field to establish and\nadopt clear Gen-AI policies. This study examines the landscape of Gen-AI\npolicies across 64 major Computer Science conferences and offers\nrecommendations for promoting more effective and responsible use of Gen-AI in\nthe field.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "Accepted and to appear in Communications of the ACM (CACM) in 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.11977v4",
    "published_date": "2024-10-15 18:33:42 UTC",
    "updated_date": "2025-03-12 17:10:33 UTC"
  },
  {
    "arxiv_id": "2410.12881v2",
    "title": "MIND: Math Informed syNthetic Dialogues for Pretraining LLMs",
    "authors": [
      "Syeda Nahida Akter",
      "Shrimai Prabhumoye",
      "John Kamalu",
      "Sanjeev Satheesh",
      "Eric Nyberg",
      "Mostofa Patwary",
      "Mohammad Shoeybi",
      "Bryan Catanzaro"
    ],
    "abstract": "The utility of synthetic data to enhance pretraining data quality and hence\nto improve downstream task accuracy has been widely explored in recent large\nlanguage models (LLMs). Yet, these approaches fall inadequate in complex,\nmulti-hop and mathematical reasoning tasks as the synthetic data typically\nfails to add complementary knowledge to the existing raw corpus. In this work,\nwe propose a novel large-scale and diverse Math Informed syNthetic Dialogue\n(MIND) generation method that improves the mathematical reasoning ability of\nLLMs. Specifically, using MIND, we generate synthetic conversations based on\nOpenWebMath (OWM), resulting in a new math corpus, MIND-OWM. Our experiments\nwith different conversational settings reveal that incorporating knowledge gaps\nbetween dialog participants is essential for generating high-quality math data.\nWe further identify an effective way to format and integrate synthetic and raw\ndata during pretraining to maximize the gain in mathematical reasoning,\nemphasizing the need to restructure raw data rather than use it as-is. Compared\nto pretraining just on raw data, a model pretrained on MIND-OWM shows\nsignificant boost in mathematical reasoning (GSM8K: +13.42%, MATH: +2.30%),\nincluding superior performance in specialized knowledge (MMLU: +4.55%,\nMMLU-STEM: +4.28%) and general purpose reasoning tasks (GENERAL REASONING:\n+2.51%).",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "31 pages, 5 figures, 14 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.12881v2",
    "published_date": "2024-10-15 18:25:53 UTC",
    "updated_date": "2025-04-25 03:14:33 UTC"
  },
  {
    "arxiv_id": "2410.11971v2",
    "title": "DDIL: Diversity Enhancing Diffusion Distillation With Imitation Learning",
    "authors": [
      "Risheek Garrepalli",
      "Shweta Mahajan",
      "Munawar Hayat",
      "Fatih Porikli"
    ],
    "abstract": "Diffusion models excel at generative modeling (e.g., text-to-image) but\nsampling requires multiple denoising network passes, limiting practicality.\nEfforts such as progressive distillation or consistency distillation have shown\npromise by reducing the number of passes at the expense of quality of the\ngenerated samples. In this work we identify co-variate shift as one of reason\nfor poor performance of multi-step distilled models from compounding error at\ninference time. To address co-variate shift, we formulate diffusion\ndistillation within imitation learning (DDIL) framework and enhance training\ndistribution for distilling diffusion models on both data distribution (forward\ndiffusion) and student induced distributions (backward diffusion). Training on\ndata distribution helps to diversify the generations by preserving marginal\ndata distribution and training on student distribution addresses compounding\nerror by correcting covariate shift. In addition, we adopt reflected diffusion\nformulation for distillation and demonstrate improved performance, stable\ntraining across different distillation methods. We show that DDIL consistency\nimproves on baseline algorithms of progressive distillation (PD), Latent\nconsistency models (LCM) and Distribution Matching Distillation (DMD2).",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11971v2",
    "published_date": "2024-10-15 18:21:47 UTC",
    "updated_date": "2025-03-29 03:05:52 UTC"
  },
  {
    "arxiv_id": "2410.12880v3",
    "title": "Navigating the Cultural Kaleidoscope: A Hitchhiker's Guide to Sensitivity in Large Language Models",
    "authors": [
      "Somnath Banerjee",
      "Sayan Layek",
      "Hari Shrawgi",
      "Rajarshi Mandal",
      "Avik Halder",
      "Shanu Kumar",
      "Sagnik Basu",
      "Parag Agrawal",
      "Rima Hazra",
      "Animesh Mukherjee"
    ],
    "abstract": "As LLMs are increasingly deployed in global applications, the importance of\ncultural sensitivity becomes paramount, ensuring that users from diverse\nbackgrounds feel respected and understood. Cultural harm can arise when these\nmodels fail to align with specific cultural norms, resulting in\nmisrepresentations or violations of cultural values. This work addresses the\nchallenges of ensuring cultural sensitivity in LLMs, especially in\nsmall-parameter models that often lack the extensive training data needed to\ncapture global cultural nuances. We present two key contributions: (1) A\ncultural harm test dataset, created to assess model outputs across different\ncultural contexts through scenarios that expose potential cultural\ninsensitivities, and (2) A culturally aligned preference dataset, aimed at\nrestoring cultural sensitivity through fine-tuning based on feedback from\ndiverse annotators. These datasets facilitate the evaluation and enhancement of\nLLMs, ensuring their ethical and safe deployment across different cultural\nlandscapes. Our results show that integrating culturally aligned feedback leads\nto a marked improvement in model behavior, significantly reducing the\nlikelihood of generating culturally insensitive or harmful content. Ultimately,\nthis work paves the way for more inclusive and respectful AI systems, fostering\na future where LLMs can safely and ethically navigate the complexities of\ndiverse cultural landscapes.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at NAACL 2025 (Main track). [Project\n  Page](https://neuralsentinel.github.io/KaleidoCulture/)",
    "pdf_url": "http://arxiv.org/pdf/2410.12880v3",
    "published_date": "2024-10-15 18:13:10 UTC",
    "updated_date": "2025-01-24 18:56:07 UTC"
  },
  {
    "arxiv_id": "2410.11963v1",
    "title": "CtrlSynth: Controllable Image Text Synthesis for Data-Efficient Multimodal Learning",
    "authors": [
      "Qingqing Cao",
      "Mahyar Najibi",
      "Sachin Mehta"
    ],
    "abstract": "Pretraining robust vision or multimodal foundation models (e.g., CLIP) relies\non large-scale datasets that may be noisy, potentially misaligned, and have\nlong-tail distributions. Previous works have shown promising results in\naugmenting datasets by generating synthetic samples. However, they only support\ndomain-specific ad hoc use cases (e.g., either image or text only, but not\nboth), and are limited in data diversity due to a lack of fine-grained control\nover the synthesis process. In this paper, we design a \\emph{controllable}\nimage-text synthesis pipeline, CtrlSynth, for data-efficient and robust\nmultimodal learning. The key idea is to decompose the visual semantics of an\nimage into basic elements, apply user-specified control policies (e.g., remove,\nadd, or replace operations), and recompose them to synthesize images or texts.\nThe decompose and recompose feature in CtrlSynth allows users to control data\nsynthesis in a fine-grained manner by defining customized control policies to\nmanipulate the basic elements. CtrlSynth leverages the capabilities of\npretrained foundation models such as large language models or diffusion models\nto reason and recompose basic elements such that synthetic samples are natural\nand composed in diverse ways. CtrlSynth is a closed-loop, training-free, and\nmodular framework, making it easy to support different pretrained models. With\nextensive experiments on 31 datasets spanning different vision and\nvision-language tasks, we show that CtrlSynth substantially improves zero-shot\nclassification, image-text retrieval, and compositional reasoning performance\nof CLIP models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11963v1",
    "published_date": "2024-10-15 18:06:41 UTC",
    "updated_date": "2024-10-15 18:06:41 UTC"
  },
  {
    "arxiv_id": "2410.11842v1",
    "title": "MoH: Multi-Head Attention as Mixture-of-Head Attention",
    "authors": [
      "Peng Jin",
      "Bo Zhu",
      "Li Yuan",
      "Shuicheng Yan"
    ],
    "abstract": "In this work, we upgrade the multi-head attention mechanism, the core of the\nTransformer model, to improve efficiency while maintaining or surpassing the\nprevious accuracy level. We show that multi-head attention can be expressed in\nthe summation form. Drawing on the insight that not all attention heads hold\nequal significance, we propose Mixture-of-Head attention (MoH), a new\narchitecture that treats attention heads as experts in the Mixture-of-Experts\n(MoE) mechanism. MoH has two significant advantages: First, MoH enables each\ntoken to select the appropriate attention heads, enhancing inference efficiency\nwithout compromising accuracy or increasing the number of parameters. Second,\nMoH replaces the standard summation in multi-head attention with a weighted\nsummation, introducing flexibility to the attention mechanism and unlocking\nextra performance potential. Extensive experiments on ViT, DiT, and LLMs\ndemonstrate that MoH outperforms multi-head attention by using only 50%-90% of\nthe attention heads. Moreover, we demonstrate that pre-trained multi-head\nattention models, such as LLaMA3-8B, can be further continue-tuned into our MoH\nmodels. Notably, MoH-LLaMA3-8B achieves an average accuracy of 64.0% across 14\nbenchmarks, outperforming LLaMA3-8B by 2.4% by utilizing only 75% of the\nattention heads. We believe the proposed MoH is a promising alternative to\nmulti-head attention and provides a strong foundation for developing advanced\nand efficient attention-based models.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "23 pages, code: https://github.com/SkyworkAI/MoH",
    "pdf_url": "http://arxiv.org/pdf/2410.11842v1",
    "published_date": "2024-10-15 17:59:44 UTC",
    "updated_date": "2024-10-15 17:59:44 UTC"
  },
  {
    "arxiv_id": "2410.11841v2",
    "title": "GaVaMoE: Gaussian-Variational Gated Mixture of Experts for Explainable Recommendation",
    "authors": [
      "Fei Tang",
      "Yongliang Shen",
      "Hang Zhang",
      "Zeqi Tan",
      "Wenqi Zhang",
      "Zhibiao Huang",
      "Kaitao Song",
      "Weiming Lu",
      "Yueting Zhuang"
    ],
    "abstract": "Large language model-based explainable recommendation (LLM-based ER) systems\nshow promise in generating human-like explanations for recommendations.\nHowever, they face challenges in modeling user-item collaborative preferences,\npersonalizing explanations, and handling sparse user-item interactions. To\naddress these issues, we propose GaVaMoE, a novel Gaussian-Variational Gated\nMixture of Experts framework for explainable recommendation. GaVaMoE introduces\ntwo key components: (1) a rating reconstruction module that employs Variational\nAutoencoder (VAE) with a Gaussian Mixture Model (GMM) to capture complex\nuser-item collaborative preferences, serving as a pre-trained multi-gating\nmechanism; and (2) a set of fine-grained expert models coupled with the\nmulti-gating mechanism for generating highly personalized explanations. The VAE\ncomponent models latent factors in user-item interactions, while the GMM\nclusters users with similar behaviors. Each cluster corresponds to a gate in\nthe multi-gating mechanism, routing user-item pairs to appropriate expert\nmodels. This architecture enables GaVaMoE to generate tailored explanations for\nspecific user types and preferences, mitigating data sparsity by leveraging\nuser similarities. Extensive experiments on three real-world datasets\ndemonstrate that GaVaMoE significantly outperforms existing methods in\nexplanation quality, personalization, and consistency. Notably, GaVaMoE\nexhibits robust performance in scenarios with sparse user-item interactions,\nmaintaining high-quality explanations even for users with limited historical\ndata.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11841v2",
    "published_date": "2024-10-15 17:59:30 UTC",
    "updated_date": "2025-03-04 01:02:11 UTC"
  },
  {
    "arxiv_id": "2410.11840v1",
    "title": "A Hitchhiker's Guide to Scaling Law Estimation",
    "authors": [
      "Leshem Choshen",
      "Yang Zhang",
      "Jacob Andreas"
    ],
    "abstract": "Scaling laws predict the loss of a target machine learning model by\nextrapolating from easier-to-train models with fewer parameters or smaller\ntraining sets. This provides an efficient way for practitioners and researchers\nalike to compare pretraining decisions involving optimizers, datasets, and\nmodel architectures. Despite the widespread use of scaling laws to model the\ndynamics of language model training, there has been little work on\nunderstanding how to best estimate and interpret them. We collect (and release)\na large-scale dataset containing losses and downstream evaluations for 485\npreviously published pretrained models. We use these to estimate more than 1000\nscaling laws, then derive a set of best practices for estimating scaling laws\nin new model families. We find that fitting scaling laws to intermediate\ncheckpoints of training runs (and not just their final losses) substantially\nimproves accuracy, and that -- all else equal -- estimates of performance are\ngenerally most accurate when derived from other models of similar sizes.\nHowever, because there is a significant degree of variability across model\nseeds, training multiple small models is sometimes more useful than training a\nsingle large one. Moreover, while different model families differ scaling\nbehavior, they are often similar enough that a target model's behavior can be\npredicted from a single model with the same architecture, along with scaling\nparameter estimates derived from other model families.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11840v1",
    "published_date": "2024-10-15 17:59:10 UTC",
    "updated_date": "2024-10-15 17:59:10 UTC"
  },
  {
    "arxiv_id": "2410.11833v1",
    "title": "Mitigating Suboptimality of Deterministic Policy Gradients in Complex Q-functions",
    "authors": [
      "Ayush Jain",
      "Norio Kosaka",
      "Xinhu Li",
      "Kyung-Min Kim",
      "Erdem Bıyık",
      "Joseph J. Lim"
    ],
    "abstract": "In reinforcement learning, off-policy actor-critic approaches like DDPG and\nTD3 are based on the deterministic policy gradient. Herein, the Q-function is\ntrained from off-policy environment data and the actor (policy) is trained to\nmaximize the Q-function via gradient ascent. We observe that in complex tasks\nlike dexterous manipulation and restricted locomotion, the Q-value is a complex\nfunction of action, having several local optima or discontinuities. This poses\na challenge for gradient ascent to traverse and makes the actor prone to get\nstuck at local optima. To address this, we introduce a new actor architecture\nthat combines two simple insights: (i) use multiple actors and evaluate the\nQ-value maximizing action, and (ii) learn surrogates to the Q-function that are\nsimpler to optimize with gradient-based methods. We evaluate tasks such as\nrestricted locomotion, dexterous manipulation, and large discrete-action space\nrecommender systems and show that our actor finds optimal actions more\nfrequently and outperforms alternate actor architectures.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11833v1",
    "published_date": "2024-10-15 17:58:03 UTC",
    "updated_date": "2024-10-15 17:58:03 UTC"
  },
  {
    "arxiv_id": "2410.11825v3",
    "title": "Learning Smooth Humanoid Locomotion through Lipschitz-Constrained Policies",
    "authors": [
      "Zixuan Chen",
      "Xialin He",
      "Yen-Jen Wang",
      "Qiayuan Liao",
      "Yanjie Ze",
      "Zhongyu Li",
      "S. Shankar Sastry",
      "Jiajun Wu",
      "Koushil Sreenath",
      "Saurabh Gupta",
      "Xue Bin Peng"
    ],
    "abstract": "Reinforcement learning combined with sim-to-real transfer offers a general\nframework for developing locomotion controllers for legged robots. To\nfacilitate successful deployment in the real world, smoothing techniques, such\nas low-pass filters and smoothness rewards, are often employed to develop\npolicies with smooth behaviors. However, because these techniques are\nnon-differentiable and usually require tedious tuning of a large set of\nhyperparameters, they tend to require extensive manual tuning for each robotic\nplatform. To address this challenge and establish a general technique for\nenforcing smooth behaviors, we propose a simple and effective method that\nimposes a Lipschitz constraint on a learned policy, which we refer to as\nLipschitz-Constrained Policies (LCP). We show that the Lipschitz constraint can\nbe implemented in the form of a gradient penalty, which provides a\ndifferentiable objective that can be easily incorporated with automatic\ndifferentiation frameworks. We demonstrate that LCP effectively replaces the\nneed for smoothing rewards or low-pass filters and can be easily integrated\ninto training frameworks for many distinct humanoid robots. We extensively\nevaluate LCP in both simulation and real-world humanoid robots, producing\nsmooth and robust locomotion controllers. All simulation and deployment code,\nalong with complete checkpoints, is available on our project page:\nhttps://lipschitz-constrained-policy.github.io.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "8 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.11825v3",
    "published_date": "2024-10-15 17:52:20 UTC",
    "updated_date": "2024-10-28 09:46:19 UTC"
  },
  {
    "arxiv_id": "2410.11792v1",
    "title": "OKAMI: Teaching Humanoid Robots Manipulation Skills through Single Video Imitation",
    "authors": [
      "Jinhan Li",
      "Yifeng Zhu",
      "Yuqi Xie",
      "Zhenyu Jiang",
      "Mingyo Seo",
      "Georgios Pavlakos",
      "Yuke Zhu"
    ],
    "abstract": "We study the problem of teaching humanoid robots manipulation skills by\nimitating from single video demonstrations. We introduce OKAMI, a method that\ngenerates a manipulation plan from a single RGB-D video and derives a policy\nfor execution. At the heart of our approach is object-aware retargeting, which\nenables the humanoid robot to mimic the human motions in an RGB-D video while\nadjusting to different object locations during deployment. OKAMI uses\nopen-world vision models to identify task-relevant objects and retarget the\nbody motions and hand poses separately. Our experiments show that OKAMI\nachieves strong generalizations across varying visual and spatial conditions,\noutperforming the state-of-the-art baseline on open-world imitation from\nobservation. Furthermore, OKAMI rollout trajectories are leveraged to train\nclosed-loop visuomotor policies, which achieve an average success rate of 79.2%\nwithout the need for labor-intensive teleoperation. More videos can be found on\nour website https://ut-austin-rpl.github.io/OKAMI/.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted for oral presentation at 8th Annual Conference on Robot\n  Learning. Project website: https://ut-austin-rpl.github.io/OKAMI/",
    "pdf_url": "http://arxiv.org/pdf/2410.11792v1",
    "published_date": "2024-10-15 17:17:54 UTC",
    "updated_date": "2024-10-15 17:17:54 UTC"
  },
  {
    "arxiv_id": "2410.11933v2",
    "title": "Beyond Sequence: Impact of Geometric Context for RNA Property Prediction",
    "authors": [
      "Junjie Xu",
      "Artem Moskalev",
      "Tommaso Mansi",
      "Mangal Prakash",
      "Rui Liao"
    ],
    "abstract": "Accurate prediction of RNA properties, such as stability and interactions, is\ncrucial for advancing our understanding of biological processes and developing\nRNA-based therapeutics. RNA structures can be represented as 1D sequences, 2D\ntopological graphs, or 3D all-atom models, each offering different insights\ninto its function. Existing works predominantly focus on 1D sequence-based\nmodels, which overlook the geometric context provided by 2D and 3D geometries.\nThis study presents the first systematic evaluation of incorporating explicit\n2D and 3D geometric information into RNA property prediction, considering not\nonly performance but also real-world challenges such as limited data\navailability, partial labeling, sequencing noise, and computational efficiency.\nTo this end, we introduce a newly curated set of RNA datasets with enhanced 2D\nand 3D structural annotations, providing a resource for model evaluation on RNA\ndata. Our findings reveal that models with explicit geometry encoding generally\noutperform sequence-based models, with an average prediction RMSE reduction of\naround 12% across all various RNA tasks and excelling in low-data and partial\nlabeling regimes, underscoring the value of explicitly incorporating geometric\ncontext. On the other hand, geometry-unaware sequence-based models are more\nrobust under sequencing noise but often require around $2-5\\times$ training\ndata to match the performance of geometry-aware models. Our study offers\nfurther insights into the trade-offs between different RNA representations in\npractical applications and addresses a significant gap in evaluating deep\nlearning models for RNA tasks.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG",
      "q-bio.BM"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11933v2",
    "published_date": "2024-10-15 17:09:34 UTC",
    "updated_date": "2025-04-21 00:07:03 UTC"
  },
  {
    "arxiv_id": "2410.11786v2",
    "title": "Selection-p: Self-Supervised Task-Agnostic Prompt Compression for Faithfulness and Transferability",
    "authors": [
      "Tsz Ting Chung",
      "Leyang Cui",
      "Lemao Liu",
      "Xinting Huang",
      "Shuming Shi",
      "Dit-Yan Yeung"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated impressive capabilities in a\nwide range of natural language processing tasks when leveraging in-context\nlearning. To mitigate the additional computational and financial costs\nassociated with in-context learning, several prompt compression methods have\nbeen proposed to compress the in-context learning prompts. Despite their\nsuccess, these methods face challenges with transferability due to\nmodel-specific compression, or rely on external training data, such as GPT-4.\nIn this paper, we investigate the ability of LLMs to develop a unified\ncompression method that discretizes uninformative tokens, utilizing a\nself-supervised pre-training technique. By introducing a small number of\nparameters during the continual pre-training, the proposed Selection-p produces\na probability for each input token, indicating whether to preserve or discard\nit. Experiments show Selection-p achieves state-of-the-art performance across\nnumerous classification tasks, achieving compression rates of up to 10 times\nwhile experiencing only a marginal 0.8% decrease in performance. Moreover, it\nexhibits superior transferability to different models compared to prior work.\nAdditionally, we further analyze how Selection-p helps maintain performance on\nin-context learning with long contexts.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "14 pages, 5 figures, 10 tables, EMNLP 2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2410.11786v2",
    "published_date": "2024-10-15 17:05:25 UTC",
    "updated_date": "2024-10-21 13:11:44 UTC"
  },
  {
    "arxiv_id": "2410.11779v2",
    "title": "MLLM can see? Dynamic Correction Decoding for Hallucination Mitigation",
    "authors": [
      "Chenxi Wang",
      "Xiang Chen",
      "Ningyu Zhang",
      "Bozhong Tian",
      "Haoming Xu",
      "Shumin Deng",
      "Huajun Chen"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) frequently exhibit hallucination\nphenomena, but the underlying reasons remain poorly understood. In this paper,\nwe present an empirical analysis and find that, although MLLMs incorrectly\ngenerate the objects in the final output, they are actually able to recognize\nvisual objects in the preceding layers. We speculate that this may be due to\nthe strong knowledge priors of the language model suppressing the visual\ninformation, leading to hallucinations. Motivated by this, we propose a novel\ndynamic correction decoding method for MLLMs DeCo, which adaptively selects the\nappropriate preceding layers and proportionally integrates knowledge into the\nfinal layer to adjust the output logits. Note that DeCo is model agnostic and\ncan be seamlessly incorporated with various classic decoding strategies and\napplied to different MLLMs. We evaluate DeCo on widely-used benchmarks,\ndemonstrating that it can reduce hallucination rates by a large margin compared\nto baselines, highlighting its potential to mitigate hallucinations. Code is\navailable at https://github.com/zjunlp/DeCo.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CL",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.11779v2",
    "published_date": "2024-10-15 16:57:44 UTC",
    "updated_date": "2025-02-23 15:14:47 UTC"
  },
  {
    "arxiv_id": "2410.11776v1",
    "title": "Encoding architecture algebra",
    "authors": [
      "Stephane Bersier",
      "Xinyi Chen-Lin"
    ],
    "abstract": "Despite the wide variety of input types in machine learning, this diversity\nis often not fully reflected in their representations or model architectures,\nleading to inefficiencies throughout a model's lifecycle. This paper introduces\nan algebraic approach to constructing input-encoding architectures that\nproperly account for the data's structure, providing a step toward achieving\nmore typeful machine learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.PL",
      "cs.SE"
    ],
    "primary_category": "cs.LG",
    "comment": "25 pages, 6 figures. Keywords: typeful, algebraic data types,\n  tensors, structured data",
    "pdf_url": "http://arxiv.org/pdf/2410.11776v1",
    "published_date": "2024-10-15 16:56:34 UTC",
    "updated_date": "2024-10-15 16:56:34 UTC"
  },
  {
    "arxiv_id": "2410.11773v7",
    "title": "Time-Series Foundation AI Model for Value-at-Risk Forecasting",
    "authors": [
      "Anubha Goel",
      "Puneet Pasricha",
      "Juho Kanniainen"
    ],
    "abstract": "This study is the first to analyze the performance of a time-series\nfoundation AI model for Value-at-Risk (VaR), which essentially forecasts the\nleft-tail quantiles of returns. Foundation models, pre-trained on diverse\ndatasets, can be applied in a zero-shot setting with minimal data or further\nimproved through finetuning. We compare Google's TimesFM model to conventional\nparametric and non-parametric models, including GARCH and Generalized\nAutoregressive Score (GAS), using 19 years of daily returns from the SP 100\nindex and its constituents. Backtesting with over 8.5 years of out-of-sample\ndata shows that the fine-tuned foundation model consistently outperforms\ntraditional methods in actual-over-expected ratios. For the quantile score loss\nfunction, it performs comparably to the best econometric model, GAS. Overall,\nthe foundation model ranks as the best or among the top performers across the\n0.01, 0.025, 0.05, and 0.1 quantile forecasting. Fine-tuning significantly\nimproves accuracy, showing that zero-shot use is not optimal for VaR.",
    "categories": [
      "q-fin.RM",
      "cs.AI"
    ],
    "primary_category": "q-fin.RM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11773v7",
    "published_date": "2024-10-15 16:53:44 UTC",
    "updated_date": "2025-05-12 14:24:41 UTC"
  },
  {
    "arxiv_id": "2410.11769v2",
    "title": "Can Search-Based Testing with Pareto Optimization Effectively Cover Failure-Revealing Test Inputs?",
    "authors": [
      "Lev Sorokin",
      "Damir Safin",
      "Shiva Nejati"
    ],
    "abstract": "Search-based software testing (SBST) is a widely adopted technique for\ntesting complex systems with large input spaces, such as Deep Learning-enabled\n(DL-enabled) systems. Many SBST techniques focus on Pareto-based optimization,\nwhere multiple objectives are optimized in parallel to reveal failures.\nHowever, it is important to ensure that identified failures are spread\nthroughout the entire failure-inducing area of a search domain and not\nclustered in a sub-region. This ensures that identified failures are\nsemantically diverse and reveal a wide range of underlying causes. In this\npaper, we present a theoretical argument explaining why testing based on Pareto\noptimization is inadequate for covering failure-inducing areas within a search\ndomain. We support our argument with empirical results obtained by applying two\nwidely used types of Pareto-based optimization techniques, namely NSGA-II (an\nevolutionary algorithm) and OMOPSO (a swarm-based Pareto-optimization\nalgorithm), to two DL-enabled systems: an industrial Automated Valet Parking\n(AVP) system and a system for classifying handwritten digits. We measure the\ncoverage of failure-revealing test inputs in the input space using a metric\nthat we refer to as the Coverage Inverted Distance quality indicator. Our\nresults show that NSGA-II-based search and OMOPSO are not more effective than a\nna\\\"ive random search baseline in covering test inputs that reveal failures.\nThe replication package for this study is available in a GitHub repository.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted for publication by Empirical Software Engineering Journal\n  (EMSE) (in October 2024)",
    "pdf_url": "http://arxiv.org/pdf/2410.11769v2",
    "published_date": "2024-10-15 16:44:40 UTC",
    "updated_date": "2024-10-16 08:30:57 UTC"
  },
  {
    "arxiv_id": "2410.11766v2",
    "title": "DPD-NeuralEngine: A 22-nm 6.6-TOPS/W/mm$^2$ Recurrent Neural Network Accelerator for Wideband Power Amplifier Digital Pre-Distortion",
    "authors": [
      "Ang Li",
      "Haolin Wu",
      "Yizhuo Wu",
      "Qinyu Chen",
      "Leo C. N. de Vreede",
      "Chang Gao"
    ],
    "abstract": "The increasing adoption of Deep Neural Network (DNN)-based Digital\nPre-distortion (DPD) in modern communication systems necessitates efficient\nhardware implementations. This paper presents DPD-NeuralEngine, an ultra-fast,\ntiny-area, and power-efficient DPD accelerator based on a Gated Recurrent Unit\n(GRU) neural network (NN). Leveraging a co-designed software and hardware\napproach, our 22 nm CMOS implementation operates at 2 GHz, capable of\nprocessing I/Q signals up to 250 MSps. Experimental results demonstrate a\nthroughput of 256.5 GOPS and power efficiency of 1.32 TOPS/W with DPD\nlinearization performance measured in Adjacent Channel Power Ratio (ACPR) of\n-45.3 dBc and Error Vector Magnitude (EVM) of -39.8 dB. To our knowledge, this\nwork represents the first AI-based DPD application-specific integrated circuit\n(ASIC) accelerator, achieving a power-area efficiency (PAE) of 6.6\nTOPS/W/mm$^2$.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AR",
    "comment": "This paper has been accepted to be presented at the 2025\n  International Symposium on Circuits and Systems (ISCAS)",
    "pdf_url": "http://arxiv.org/pdf/2410.11766v2",
    "published_date": "2024-10-15 16:39:50 UTC",
    "updated_date": "2025-02-10 18:16:18 UTC"
  },
  {
    "arxiv_id": "2410.11761v3",
    "title": "SlideChat: A Large Vision-Language Assistant for Whole-Slide Pathology Image Understanding",
    "authors": [
      "Ying Chen",
      "Guoan Wang",
      "Yuanfeng Ji",
      "Yanjun Li",
      "Jin Ye",
      "Tianbin Li",
      "Ming Hu",
      "Rongshan Yu",
      "Yu Qiao",
      "Junjun He"
    ],
    "abstract": "Despite the progress made by multimodal large language models (MLLMs) in\ncomputational pathology, they remain limited by a predominant focus on\npatch-level analysis, missing essential contextual information at the\nwhole-slide level. The lack of large-scale instruction datasets and the\ngigapixel scale of whole slide images (WSIs) pose significant developmental\nchallenges. In this paper, we present SlideChat, the first vision-language\nassistant capable of understanding gigapixel whole-slide images, exhibiting\nexcellent multimodal conversational capability and response complex instruction\nacross diverse pathology scenarios. To support its development, we created\nSlideInstruction, the largest instruction-following dataset for WSIs consisting\nof 4.2K WSI captions and 176K VQA pairs with multiple categories. Furthermore,\nwe propose SlideBench, a multimodal benchmark that incorporates captioning and\nVQA tasks to assess SlideChat's capabilities in varied clinical settings such\nas microscopy, diagnosis. Compared to both general and specialized MLLMs,\nSlideChat exhibits exceptional capabilities achieving state-of-the-art\nperformance on 18 of 22 tasks. For example, it achieved an overall accuracy of\n81.17% on SlideBench-VQA (TCGA), and 54.15% on SlideBench-VQA (BCNB). Our code,\ndata, and model is publicly accessible at\nhttps://uni-medical.github.io/SlideChat.github.io.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by CVPR2025",
    "pdf_url": "http://arxiv.org/pdf/2410.11761v3",
    "published_date": "2024-10-15 16:33:33 UTC",
    "updated_date": "2025-03-19 17:56:39 UTC"
  },
  {
    "arxiv_id": "2410.11756v1",
    "title": "Evidence of Cognitive Deficits andDevelopmental Advances in Generative AI: A Clock Drawing Test Analysis",
    "authors": [
      "Isaac R. Galatzer-Levy",
      "Jed McGiffin",
      "David Munday",
      "Xin Liu",
      "Danny Karmon",
      "Ilia Labzovsky",
      "Rivka Moroshko",
      "Amir Zait",
      "Daniel McDuff"
    ],
    "abstract": "Generative AI's rapid advancement sparks interest in its cognitive abilities,\nespecially given its capacity for tasks like language understanding and code\ngeneration. This study explores how several recent GenAI models perform on the\nClock Drawing Test (CDT), a neuropsychological assessment of visuospatial\nplanning and organization. While models create clock-like drawings, they\nstruggle with accurate time representation, showing deficits similar to\nmild-severe cognitive impairment (Wechsler, 2009). Errors include numerical\nsequencing issues, incorrect clock times, and irrelevant additions, despite\naccurate rendering of clock features. Only GPT 4 Turbo and Gemini Pro 1.5\nproduced the correct time, scoring like healthy individuals (4/4). A follow-up\nclock-reading test revealed only Sonnet 3.5 succeeded, suggesting drawing\ndeficits stem from difficulty with numerical concepts. These findings may\nreflect weaknesses in visual-spatial understanding, working memory, or\ncalculation, highlighting strengths in learned knowledge but weaknesses in\nreasoning. Comparing human and machine performance is crucial for understanding\nAI's cognitive capabilities and guiding development toward human-like cognitive\nfunctions.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11756v1",
    "published_date": "2024-10-15 16:27:22 UTC",
    "updated_date": "2024-10-15 16:27:22 UTC"
  },
  {
    "arxiv_id": "2410.19789v1",
    "title": "Xeno-learning: knowledge transfer across species in deep learning-based spectral image analysis",
    "authors": [
      "Jan Sellner",
      "Alexander Studier-Fischer",
      "Ahmad Bin Qasim",
      "Silvia Seidlitz",
      "Nicholas Schreck",
      "Minu Tizabi",
      "Manuel Wiesenfarth",
      "Annette Kopp-Schneider",
      "Samuel Knödler",
      "Caelan Max Haney",
      "Gabriel Salg",
      "Berkin Özdemir",
      "Maximilian Dietrich",
      "Maurice Stephan Michel",
      "Felix Nickel",
      "Karl-Friedrich Kowalewski",
      "Lena Maier-Hein"
    ],
    "abstract": "Novel optical imaging techniques, such as hyperspectral imaging (HSI)\ncombined with machine learning-based (ML) analysis, have the potential to\nrevolutionize clinical surgical imaging. However, these novel modalities face a\nshortage of large-scale, representative clinical data for training ML\nalgorithms, while preclinical animal data is abundantly available through\nstandardized experiments and allows for controlled induction of pathological\ntissue states, which is not ethically possible in patients. To leverage this\nsituation, we propose a novel concept called \"xeno-learning\", a cross-species\nknowledge transfer paradigm inspired by xeno-transplantation, where organs from\na donor species are transplanted into a recipient species. Using a total of\n11,268 HSI images from humans as well as porcine and rat models, we show that\nalthough spectral signatures of organs differ across species, shared\npathophysiological mechanisms manifest as comparable relative spectral changes\nacross species. Such changes learnt in one species can thus be transferred to a\nnew species via a novel \"physiology-based data augmentation\" method, enabling\nthe large-scale secondary use of preclinical animal data for humans. The\nresulting ethical, monetary, and performance benefits of the proposed knowledge\ntransfer paradigm promise a high impact of the methodology on future\ndevelopments in the field.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Jan Sellner and Alexander Studier-Fischer contributed equally to this\n  work",
    "pdf_url": "http://arxiv.org/pdf/2410.19789v1",
    "published_date": "2024-10-15 16:25:16 UTC",
    "updated_date": "2024-10-15 16:25:16 UTC"
  },
  {
    "arxiv_id": "2410.22355v1",
    "title": "Learning Goal-oriented Bimanual Dough Rolling Using Dynamic Heterogeneous Graph Based on Human Demonstration",
    "authors": [
      "Junjia Liu",
      "Chenzui Li",
      "Shixiong Wang",
      "Zhipeng Dong",
      "Sylvain Calinon",
      "Miao Li",
      "Fei Chen"
    ],
    "abstract": "Soft object manipulation poses significant challenges for robots, requiring\neffective techniques for state representation and manipulation policy learning.\nState representation involves capturing the dynamic changes in the environment,\nwhile manipulation policy learning focuses on establishing the relationship\nbetween robot actions and state transformations to achieve specific goals. To\naddress these challenges, this research paper introduces a novel approach: a\ndynamic heterogeneous graph-based model for learning goal-oriented soft object\nmanipulation policies. The proposed model utilizes graphs as a unified\nrepresentation for both states and policy learning. By leveraging the dynamic\ngraph, we can extract crucial information regarding object dynamics and\nmanipulation policies. Furthermore, the model facilitates the integration of\ndemonstrations, enabling guided policy learning. To evaluate the efficacy of\nour approach, we designed a dough rolling task and conducted experiments using\nboth a differentiable simulator and a real-world humanoid robot. Additionally,\nseveral ablation studies were performed to analyze the effect of our method,\ndemonstrating its superiority in achieving human-like behavior.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "7 pages, 5 figures Accepted by IEEE ROBIO 2024 conference",
    "pdf_url": "http://arxiv.org/pdf/2410.22355v1",
    "published_date": "2024-10-15 16:12:00 UTC",
    "updated_date": "2024-10-15 16:12:00 UTC"
  },
  {
    "arxiv_id": "2410.11730v1",
    "title": "Patch-Based Diffusion Models Beat Whole-Image Models for Mismatched Distribution Inverse Problems",
    "authors": [
      "Jason Hu",
      "Bowen Song",
      "Jeffrey A. Fessler",
      "Liyue Shen"
    ],
    "abstract": "Diffusion models have achieved excellent success in solving inverse problems\ndue to their ability to learn strong image priors, but existing approaches\nrequire a large training dataset of images that should come from the same\ndistribution as the test dataset. When the training and test distributions are\nmismatched, artifacts and hallucinations can occur in reconstructed images due\nto the incorrect priors. In this work, we systematically study out of\ndistribution (OOD) problems where a known training distribution is first\nprovided. We first study the setting where only a single measurement obtained\nfrom the unknown test distribution is available. Next we study the setting\nwhere a very small sample of data belonging to the test distribution is\navailable, and our goal is still to reconstruct an image from a measurement\nthat came from the test distribution. In both settings, we use a patch-based\ndiffusion prior that learns the image distribution solely from patches.\nFurthermore, in the first setting, we include a self-supervised loss that helps\nthe network output maintain consistency with the measurement. Extensive\nexperiments show that in both settings, the patch-based method can obtain high\nquality image reconstructions that can outperform whole-image models and can\ncompete with methods that have access to large in-distribution training\ndatasets. Furthermore, we show how whole-image models are prone to memorization\nand overfitting, leading to artifacts in the reconstructions, while a\npatch-based model can resolve these issues.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11730v1",
    "published_date": "2024-10-15 16:02:08 UTC",
    "updated_date": "2024-10-15 16:02:08 UTC"
  },
  {
    "arxiv_id": "2410.11723v1",
    "title": "Generalizable Spacecraft Trajectory Generation via Multimodal Learning with Transformers",
    "authors": [
      "Davide Celestini",
      "Amirhossein Afsharrad",
      "Daniele Gammelli",
      "Tommaso Guffanti",
      "Gioele Zardini",
      "Sanjay Lall",
      "Elisa Capello",
      "Simone D'Amico",
      "Marco Pavone"
    ],
    "abstract": "Effective trajectory generation is essential for reliable on-board spacecraft\nautonomy. Among other approaches, learning-based warm-starting represents an\nappealing paradigm for solving the trajectory generation problem, effectively\ncombining the benefits of optimization- and data-driven methods. Current\napproaches for learning-based trajectory generation often focus on fixed,\nsingle-scenario environments, where key scene characteristics, such as obstacle\npositions or final-time requirements, remain constant across problem instances.\nHowever, practical trajectory generation requires the scenario to be frequently\nreconfigured, making the single-scenario approach a potentially impractical\nsolution. To address this challenge, we present a novel trajectory generation\nframework that generalizes across diverse problem configurations, by leveraging\nhigh-capacity transformer neural networks capable of learning from multimodal\ndata sources. Specifically, our approach integrates transformer-based neural\nnetwork models into the trajectory optimization process, encoding both\nscene-level information (e.g., obstacle locations, initial and goal states) and\ntrajectory-level constraints (e.g., time bounds, fuel consumption targets) via\nmultimodal representations. The transformer network then generates near-optimal\ninitial guesses for non-convex optimization problems, significantly enhancing\nconvergence speed and performance. The framework is validated through extensive\nsimulations and real-world experiments on a free-flyer platform, achieving up\nto 30% cost improvement and 80% reduction in infeasible cases with respect to\ntraditional approaches, and demonstrating robust generalization across diverse\nscenario variations.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.RO",
    "comment": "8 pages, 6 figures, submitted to 2025 American Control Conference\n  (ACC)",
    "pdf_url": "http://arxiv.org/pdf/2410.11723v1",
    "published_date": "2024-10-15 15:55:42 UTC",
    "updated_date": "2024-10-15 15:55:42 UTC"
  },
  {
    "arxiv_id": "2410.11722v2",
    "title": "RClicks: Realistic Click Simulation for Benchmarking Interactive Segmentation",
    "authors": [
      "Anton Antonov",
      "Andrey Moskalenko",
      "Denis Shepelev",
      "Alexander Krapukhin",
      "Konstantin Soshin",
      "Anton Konushin",
      "Vlad Shakhuro"
    ],
    "abstract": "The emergence of Segment Anything (SAM) sparked research interest in the\nfield of interactive segmentation, especially in the context of image editing\ntasks and speeding up data annotation. Unlike common semantic segmentation,\ninteractive segmentation methods allow users to directly influence their output\nthrough prompts (e.g. clicks). However, click patterns in real-world\ninteractive segmentation scenarios remain largely unexplored. Most methods rely\non the assumption that users would click in the center of the largest erroneous\narea. Nevertheless, recent studies show that this is not always the case. Thus,\nmethods may have poor performance in real-world deployment despite high metrics\nin a baseline benchmark. To accurately simulate real-user clicks, we conducted\na large crowdsourcing study of click patterns in an interactive segmentation\nscenario and collected 475K real-user clicks. Drawing on ideas from saliency\ntasks, we develop a clickability model that enables sampling clicks, which\nclosely resemble actual user inputs. Using our model and dataset, we propose\nRClicks benchmark for a comprehensive comparison of existing interactive\nsegmentation methods on realistic clicks. Specifically, we evaluate not only\nthe average quality of methods, but also the robustness w.r.t. click patterns.\nAccording to our benchmark, in real-world usage interactive segmentation models\nmay perform worse than it has been reported in the baseline benchmark, and most\nof the methods are not robust. We believe that RClicks is a significant step\ntowards creating interactive segmentation methods that provide the best user\nexperience in real-world cases.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC",
      "I.4.6"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.11722v2",
    "published_date": "2024-10-15 15:55:00 UTC",
    "updated_date": "2024-10-24 15:48:41 UTC"
  },
  {
    "arxiv_id": "2410.11701v2",
    "title": "Magnifier Prompt: Tackling Multimodal Hallucination via Extremely Simple Instructions",
    "authors": [
      "Yuhan Fu",
      "Ruobing Xie",
      "Jiazhen Liu",
      "Bangxiang Lan",
      "Xingwu Sun",
      "Zhanhui Kang",
      "Xirong Li"
    ],
    "abstract": "Hallucinations in multimodal large language models (MLLMs) hinder their\npractical applications. To address this, we propose a Magnifier Prompt\n(MagPrompt), a simple yet effective method to tackle hallucinations in MLLMs\nvia extremely simple instructions. MagPrompt is based on the following two key\nprinciples, which guide the design of various effective prompts, demonstrating\nrobustness: (1) MLLMs should focus more on the image. (2) When there are\nconflicts between the image and the model's inner knowledge, MLLMs should\nprioritize the image. MagPrompt is training-free and can be applied to\nopen-source and closed-source models, such as GPT-4o and Gemini-pro. It\nperforms well across many datasets and its effectiveness is comparable or even\nbetter than more complex methods like VCD. Furthermore, our prompt design\nprinciples and experimental analyses provide valuable insights into multimodal\nhallucination.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.MM"
    ],
    "primary_category": "cs.CL",
    "comment": "The proposed method does not work for up-to-date MLLMs.",
    "pdf_url": "http://arxiv.org/pdf/2410.11701v2",
    "published_date": "2024-10-15 15:39:37 UTC",
    "updated_date": "2025-02-21 09:48:58 UTC"
  },
  {
    "arxiv_id": "2410.13899v1",
    "title": "Security of and by Generative AI platforms",
    "authors": [
      "Hari Hayagreevan",
      "Souvik Khamaru"
    ],
    "abstract": "This whitepaper highlights the dual importance of securing generative AI\n(genAI) platforms and leveraging genAI for cybersecurity. As genAI technologies\nproliferate, their misuse poses significant risks, including data breaches,\nmodel tampering, and malicious content generation. Securing these platforms is\ncritical to protect sensitive data, ensure model integrity, and prevent\nadversarial attacks. Simultaneously, genAI presents opportunities for enhancing\nsecurity by automating threat detection, vulnerability analysis, and incident\nresponse. The whitepaper explores strategies for robust security frameworks\naround genAI systems, while also showcasing how genAI can empower organizations\nto anticipate, detect, and mitigate sophisticated cyber threats.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13899v1",
    "published_date": "2024-10-15 15:27:05 UTC",
    "updated_date": "2024-10-15 15:27:05 UTC"
  },
  {
    "arxiv_id": "2410.11689v2",
    "title": "BlendRL: A Framework for Merging Symbolic and Neural Policy Learning",
    "authors": [
      "Hikaru Shindo",
      "Quentin Delfosse",
      "Devendra Singh Dhami",
      "Kristian Kersting"
    ],
    "abstract": "Humans can leverage both symbolic reasoning and intuitive reactions. In\ncontrast, reinforcement learning policies are typically encoded in either\nopaque systems like neural networks or symbolic systems that rely on predefined\nsymbols and rules. This disjointed approach severely limits the agents'\ncapabilities, as they often lack either the flexible low-level reaction\ncharacteristic of neural agents or the interpretable reasoning of symbolic\nagents. To overcome this challenge, we introduce BlendRL, a neuro-symbolic RL\nframework that harmoniously integrates both paradigms within RL agents that use\nmixtures of both logic and neural policies. We empirically demonstrate that\nBlendRL agents outperform both neural and symbolic baselines in standard Atari\nenvironments, and showcase their robustness to environmental changes.\nAdditionally, we analyze the interaction between neural and symbolic policies,\nillustrating how their hybrid use helps agents overcome each other's\nlimitations.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2025 (Spotlight)",
    "pdf_url": "http://arxiv.org/pdf/2410.11689v2",
    "published_date": "2024-10-15 15:24:20 UTC",
    "updated_date": "2025-04-21 16:49:31 UTC"
  },
  {
    "arxiv_id": "2410.11687v2",
    "title": "State-space models can learn in-context by gradient descent",
    "authors": [
      "Neeraj Mohan Sushma",
      "Yudou Tian",
      "Harshvardhan Mestha",
      "Nicolo Colombo",
      "David Kappel",
      "Anand Subramoney"
    ],
    "abstract": "Deep state-space models (Deep SSMs) are becoming popular as effective\napproaches to model sequence data. They have also been shown to be capable of\nin-context learning, much like transformers. However, a complete picture of how\nSSMs might be able to do in-context learning has been missing. In this study,\nwe provide a direct and explicit construction to show that state-space models\ncan perform gradient-based learning and use it for in-context learning in much\nthe same way as transformers. Specifically, we prove that a single structured\nstate-space model layer, augmented with multiplicative input and output gating,\ncan reproduce the outputs of an implicit linear model with least squares loss\nafter one step of gradient descent. We then show a straightforward extension to\nmulti-step linear and non-linear regression tasks. We validate our construction\nby training randomly initialized augmented SSMs on linear and non-linear\nregression tasks. The empirically obtained parameters through optimization\nmatch the ones predicted analytically by the theoretical construction. Overall,\nwe elucidate the role of input- and output-gating in recurrent architectures as\nthe key inductive biases for enabling the expressive power typical of\nfoundation models. We also provide novel insights into the relationship between\nstate-space models and linear self-attention, and their ability to learn\nin-context.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "20 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.11687v2",
    "published_date": "2024-10-15 15:22:38 UTC",
    "updated_date": "2025-02-18 18:55:39 UTC"
  },
  {
    "arxiv_id": "2410.11684v1",
    "title": "Are UFOs Driving Innovation? The Illusion of Causality in Large Language Models",
    "authors": [
      "María Victoria Carro",
      "Francisca Gauna Selasco",
      "Denise Alejandra Mester",
      "Mario Alejandro Leiva"
    ],
    "abstract": "Illusions of causality occur when people develop the belief that there is a\ncausal connection between two variables with no supporting evidence. This\ncognitive bias has been proposed to underlie many societal problems including\nsocial prejudice, stereotype formation, misinformation and superstitious\nthinking. In this research we investigate whether large language models develop\nthe illusion of causality in real-world settings. We evaluated and compared\nnews headlines generated by GPT-4o-Mini, Claude-3.5-Sonnet, and Gemini-1.5-Pro\nto determine whether the models incorrectly framed correlations as causal\nrelationships. In order to also measure sycophantic behavior, which occurs when\na model aligns with a user's beliefs in order to look favorable even if it is\nnot objectively correct, we additionally incorporated the bias into the\nprompts, observing if this manipulation increases the likelihood of the models\nexhibiting the illusion of causality. We found that Claude-3.5-Sonnet is the\nmodel that presents the lowest degree of causal illusion aligned with\nexperiments on Correlation-to-Causation Exaggeration in human-written press\nreleases. On the other hand, our findings suggest that while mimicry sycophancy\nincreases the likelihood of causal illusions in these models, especially in\nGPT-4o-Mini, Claude-3.5-Sonnet remains the most robust against this cognitive\nbias.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11684v1",
    "published_date": "2024-10-15 15:20:49 UTC",
    "updated_date": "2024-10-15 15:20:49 UTC"
  },
  {
    "arxiv_id": "2410.11682v2",
    "title": "SurFhead: Affine Rig Blending for Geometrically Accurate 2D Gaussian Surfel Head Avatars",
    "authors": [
      "Jaeseong Lee",
      "Taewoong Kang",
      "Marcel C. Bühler",
      "Min-Jung Kim",
      "Sungwon Hwang",
      "Junha Hyung",
      "Hyojin Jang",
      "Jaegul Choo"
    ],
    "abstract": "Recent advancements in head avatar rendering using Gaussian primitives have\nachieved significantly high-fidelity results. Although precise head geometry is\ncrucial for applications like mesh reconstruction and relighting, current\nmethods struggle to capture intricate geometric details and render unseen poses\ndue to their reliance on similarity transformations, which cannot handle\nstretch and shear transforms essential for detailed deformations of geometry.\nTo address this, we propose SurFhead, a novel method that reconstructs riggable\nhead geometry from RGB videos using 2D Gaussian surfels, which offer\nwell-defined geometric properties, such as precise depth from fixed ray\nintersections and normals derived from their surface orientation, making them\nadvantageous over 3D counterparts. SurFhead ensures high-fidelity rendering of\nboth normals and images, even in extreme poses, by leveraging classical\nmesh-based deformation transfer and affine transformation interpolation.\nSurFhead introduces precise geometric deformation and blends surfels through\npolar decomposition of transformations, including those affecting normals. Our\nkey contribution lies in bridging classical graphics techniques, such as\nmesh-based deformation, with modern Gaussian primitives, achieving\nstate-of-the-art geometry reconstruction and rendering quality. Unlike previous\navatar rendering approaches, SurFhead enables efficient reconstruction driven\nby Gaussian primitives while preserving high-fidelity geometry.",
    "categories": [
      "cs.GR",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.GR",
    "comment": "ICLR 2025, Project page with videos:\n  https://summertight.github.io/SurFhead/",
    "pdf_url": "http://arxiv.org/pdf/2410.11682v2",
    "published_date": "2024-10-15 15:19:58 UTC",
    "updated_date": "2025-04-18 04:11:33 UTC"
  },
  {
    "arxiv_id": "2410.11677v2",
    "title": "Understanding Likelihood Over-optimisation in Direct Alignment Algorithms",
    "authors": [
      "Zhengyan Shi",
      "Sander Land",
      "Acyr Locatelli",
      "Matthieu Geist",
      "Max Bartolo"
    ],
    "abstract": "Direct Alignment Algorithms (DAAs), such as Direct Preference Optimisation\n(DPO) and Identity Preference Optimisation (IPO), have emerged as alternatives\nto online Reinforcement Learning from Human Feedback (RLHF) algorithms such as\nProximal Policy Optimisation (PPO) for aligning language models to human\npreferences, without the need for explicit reward modelling. These methods\ngenerally aim to increase the likelihood of generating better (preferred)\ncompletions while discouraging worse (non-preferred) ones, while staying close\nto the original model's behaviour. In this work, we explore the relationship\nbetween completion likelihood and model performance in state-of-the-art DAAs,\nand identify a critical issue of likelihood over-optimisation. Contrary to\nexpectations, we find that higher likelihood of better completions and larger\nmargins between better and worse completion likelihoods do not necessarily lead\nto better performance, and may even degrade it. Our analysis reveals that while\nhigher likelihood correlates with better memorisation of factual knowledge\npatterns, a slightly lower completion likelihood tends to improve output\ndiversity, thus leading to better generalisation to unseen scenarios. Moreover,\nwe identify two key indicators that signal when over-optimised output diversity\nbegins to harm performance: Decreasing Entropy over Top-k Tokens and\nDiminishing Top-k Probability Mass. Our experimental results validate that\nthese indicators are reliable signs of declining performance under different\nregularisations, helping prevent over-optimisation and improve alignment with\nhuman preferences.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Preprint Version",
    "pdf_url": "http://arxiv.org/pdf/2410.11677v2",
    "published_date": "2024-10-15 15:14:22 UTC",
    "updated_date": "2024-10-18 09:41:53 UTC"
  },
  {
    "arxiv_id": "2410.11672v1",
    "title": "Leaving the barn door open for Clever Hans: Simple features predict LLM benchmark answers",
    "authors": [
      "Lorenzo Pacchiardi",
      "Marko Tesic",
      "Lucy G. Cheke",
      "José Hernández-Orallo"
    ],
    "abstract": "The integrity of AI benchmarks is fundamental to accurately assess the\ncapabilities of AI systems. The internal validity of these benchmarks - i.e.,\nmaking sure they are free from confounding factors - is crucial for ensuring\nthat they are measuring what they are designed to measure. In this paper, we\nexplore a key issue related to internal validity: the possibility that AI\nsystems can solve benchmarks in unintended ways, bypassing the capability being\ntested. This phenomenon, widely known in human and animal experiments, is often\nreferred to as the 'Clever Hans' effect, where tasks are solved using spurious\ncues, often involving much simpler processes than those putatively assessed.\nPrevious research suggests that language models can exhibit this behaviour as\nwell. In several older Natural Language Processing (NLP) benchmarks, individual\n$n$-grams like \"not\" have been found to be highly predictive of the correct\nlabels, and supervised NLP models have been shown to exploit these patterns. In\nthis work, we investigate the extent to which simple $n$-grams extracted from\nbenchmark instances can be combined to predict labels in modern multiple-choice\nbenchmarks designed for LLMs, and whether LLMs might be using such $n$-gram\npatterns to solve these benchmarks. We show how simple classifiers trained on\nthese $n$-grams can achieve high scores on several benchmarks, despite lacking\nthe capabilities being tested. Additionally, we provide evidence that modern\nLLMs might be using these superficial patterns to solve benchmarks. This\nsuggests that the internal validity of these benchmarks may be compromised and\ncaution should be exercised when interpreting LLM performance results on them.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11672v1",
    "published_date": "2024-10-15 15:05:41 UTC",
    "updated_date": "2024-10-15 15:05:41 UTC"
  },
  {
    "arxiv_id": "2410.22353v3",
    "title": "RuleRAG: Rule-Guided Retrieval-Augmented Generation with Language Models for Question Answering",
    "authors": [
      "Zhongwu Chen",
      "Chengjin Xu",
      "Dingmin Wang",
      "Zhen Huang",
      "Yong Dou",
      "Xuhui Jiang",
      "Jian Guo"
    ],
    "abstract": "Retrieval-augmented generation (RAG) has shown promising potential in\nknowledge intensive question answering (QA). However, existing approaches only\nconsider the query itself, neither specifying the retrieval preferences for the\nretrievers nor informing the generators of how to refer to the retrieved\ndocuments for the answers, which poses a significant challenge to the QA\nperformance. To address these issues, we propose Rule-guided\nRetrieval-Augmented Generation with LMs, which explicitly introduces rules for\nin-context learning (RuleRAG-ICL) to guide retrievers to recall related\ndocuments in the directions of rules and uniformly guide generators to reason\nattributed by the same rules. Moreover, most existing RAG datasets were\nconstructed without considering rules and Knowledge Graphs (KGs) are recognized\nas providing high-quality rules. Therefore, we construct five rule-aware RAG\nbenchmarks for QA, RuleQA, based on KGs to stress the significance of retrieval\nand reasoning with rules. Experiments on RuleQA demonstrate RuleRAG-ICL\nimproves the retrieval quality of +89.2% in Recall@10 and answer accuracy of\n+103.1% in Exact Match, and RuleRAG-FT yields more enhancement. In addition,\nexperiments on four existing RAG datasets show RuleRAG is also effective by\noffering rules in RuleQA to them, further proving the generalization of rule\nguidance in RuleRAG.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.22353v3",
    "published_date": "2024-10-15 14:51:45 UTC",
    "updated_date": "2025-02-16 11:50:09 UTC"
  },
  {
    "arxiv_id": "2410.11665v1",
    "title": "VisualRWKV-HD and UHD: Advancing High-Resolution Processing for Visual Language Models",
    "authors": [
      "Zihang Li",
      "Haowen Hou"
    ],
    "abstract": "Accurately understanding complex visual information is crucial for visual\nlanguage models (VLMs). Enhancing image resolution can improve visual\nperception capabilities, not only reducing hallucinations but also boosting\nperformance in tasks that demand high resolution, such as text-rich or document\nanalysis. In this paper, we present VisualRWKV-HD and VisualRWKV-UHD, two\nadvancements in the VisualRWKV model family, specifically designed to process\nhigh-resolution visual inputs. For VisualRWKV-HD, we developed a lossless\ndownsampling method to effectively integrate a high-resolution vision encoder\nwith low-resolution encoders, without extending the input sequence length. For\nthe VisualRWKV-UHD model, we enhanced image representation by dividing the\nimage into four segments, which are then recombined with the original image.\nThis technique allows the model to incorporate both high-resolution and\nlow-resolution features, effectively balancing coarse and fine-grained\ninformation. As a result, the model supports resolutions up to 4096 x 4096\npixels, offering a more detailed and comprehensive visual processing\ncapability. Both VisualRWKV-HD and VisualRWKV-UHD not only achieve strong\nresults on VLM benchmarks but also show marked improvements in performance for\ntext-rich tasks.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11665v1",
    "published_date": "2024-10-15 14:49:19 UTC",
    "updated_date": "2024-10-15 14:49:19 UTC"
  },
  {
    "arxiv_id": "2410.11655v1",
    "title": "Retrieval Augmented Spelling Correction for E-Commerce Applications",
    "authors": [
      "Xuan Guo",
      "Rohit Patki",
      "Dante Everaert",
      "Christopher Potts"
    ],
    "abstract": "The rapid introduction of new brand names into everyday language poses a\nunique challenge for e-commerce spelling correction services, which must\ndistinguish genuine misspellings from novel brand names that use unconventional\nspelling. We seek to address this challenge via Retrieval Augmented Generation\n(RAG). On this approach, product names are retrieved from a catalog and\nincorporated into the context used by a large language model (LLM) that has\nbeen fine-tuned to do contextual spelling correction. Through quantitative\nevaluation and qualitative error analyses, we find improvements in spelling\ncorrection utilizing the RAG framework beyond a stand-alone LLM. We also\ndemonstrate the value of additional finetuning of the LLM to incorporate\nretrieved context.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11655v1",
    "published_date": "2024-10-15 14:42:18 UTC",
    "updated_date": "2024-10-15 14:42:18 UTC"
  },
  {
    "arxiv_id": "2410.11651v1",
    "title": "RS-MOCO: A deep learning-based topology-preserving image registration method for cardiac T1 mapping",
    "authors": [
      "Chiyi Huang",
      "Longwei Sun",
      "Dong Liang",
      "Haifeng Liang",
      "Hongwu Zeng",
      "Yanjie Zhu"
    ],
    "abstract": "Cardiac T1 mapping can evaluate various clinical symptoms of myocardial\ntissue. However, there is currently a lack of effective, robust, and efficient\nmethods for motion correction in cardiac T1 mapping. In this paper, we propose\na deep learning-based and topology-preserving image registration framework for\nmotion correction in cardiac T1 mapping. Notably, our proposed implicit\nconsistency constraint dubbed BLOC, to some extent preserves the image topology\nin registration by bidirectional consistency constraint and local anti-folding\nconstraint. To address the contrast variation issue, we introduce a weighted\nimage similarity metric for multimodal registration of cardiac T1-weighted\nimages. Besides, a semi-supervised myocardium segmentation network and a\ndual-domain attention module are integrated into the framework to further\nimprove the performance of the registration. Numerous comparative experiments,\nas well as ablation studies, demonstrated the effectiveness and high robustness\nof our method. The results also indicate that the proposed weighted image\nsimilarity metric, specifically crafted for our network, contributes a lot to\nthe enhancement of the motion correction efficacy, while the bidirectional\nconsistency constraint combined with the local anti-folding constraint ensures\na more desirable topology-preserving registration mapping.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11651v1",
    "published_date": "2024-10-15 14:38:35 UTC",
    "updated_date": "2024-10-15 14:38:35 UTC"
  },
  {
    "arxiv_id": "2410.11650v1",
    "title": "ED-ViT: Splitting Vision Transformer for Distributed Inference on Edge Devices",
    "authors": [
      "Xiang Liu",
      "Yijun Song",
      "Xia Li",
      "Yifei Sun",
      "Huiying Lan",
      "Zemin Liu",
      "Linshan Jiang",
      "Jialin Li"
    ],
    "abstract": "Deep learning models are increasingly deployed on resource-constrained edge\ndevices for real-time data analytics. In recent years, Vision Transformer\nmodels and their variants have demonstrated outstanding performance across\nvarious computer vision tasks. However, their high computational demands and\ninference latency pose significant challenges for model deployment on\nresource-constraint edge devices. To address this issue, we propose a novel\nVision Transformer splitting framework, ED-ViT, designed to execute complex\nmodels across multiple edge devices efficiently. Specifically, we partition\nVision Transformer models into several sub-models, where each sub-model is\ntailored to handle a specific subset of data classes. To further minimize\ncomputation overhead and inference latency, we introduce a class-wise pruning\ntechnique that reduces the size of each sub-model. We conduct extensive\nexperiments on five datasets with three model structures, demonstrating that\nour approach significantly reduces inference latency on edge devices and\nachieves a model size reduction of up to 28.9 times and 34.1 times,\nrespectively, while maintaining test accuracy comparable to the original Vision\nTransformer. Additionally, we compare ED-ViT with two state-of-the-art methods\nthat deploy CNN and SNN models on edge devices, evaluating accuracy, inference\ntime, and overall model size. Our comprehensive evaluation underscores the\neffectiveness of the proposed ED-ViT framework.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "14 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.11650v1",
    "published_date": "2024-10-15 14:38:14 UTC",
    "updated_date": "2024-10-15 14:38:14 UTC"
  },
  {
    "arxiv_id": "2410.11642v2",
    "title": "Improve Value Estimation of Q Function and Reshape Reward with Monte Carlo Tree Search",
    "authors": [
      "Jiamian Li"
    ],
    "abstract": "Reinforcement learning has achieved remarkable success in perfect information\ngames such as Go and Atari, enabling agents to compete at the highest levels\nagainst human players. However, research in reinforcement learning for\nimperfect information games has been relatively limited due to the more complex\ngame structures and randomness. Traditional methods face challenges in training\nand improving performance in imperfect information games due to issues like\ninaccurate Q value estimation and reward sparsity. In this paper, we focus on\nUno, an imperfect information game, and aim to address these problems by\nreducing Q value overestimation and reshaping reward function. We propose a\nnovel algorithm that utilizes Monte Carlo Tree Search to average the value\nestimations in Q function. Even though we choose Double Deep Q Learning as the\nfoundational framework in this paper, our method can be generalized and used in\nany algorithm which needs Q value estimation, such as the Actor-Critic.\nAdditionally, we employ Monte Carlo Tree Search to reshape the reward structure\nin the game environment. We compare our algorithm with several traditional\nmethods applied to games such as Double Deep Q Learning, Deep Monte Carlo and\nNeural Fictitious Self Play, and the experiments demonstrate that our algorithm\nconsistently outperforms these approaches, especially as the number of players\nin Uno increases, indicating a higher level of difficulty.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11642v2",
    "published_date": "2024-10-15 14:31:54 UTC",
    "updated_date": "2024-10-23 09:43:03 UTC"
  },
  {
    "arxiv_id": "2410.11623v1",
    "title": "VidEgoThink: Assessing Egocentric Video Understanding Capabilities for Embodied AI",
    "authors": [
      "Sijie Cheng",
      "Kechen Fang",
      "Yangyang Yu",
      "Sicheng Zhou",
      "Bohao Li",
      "Ye Tian",
      "Tingguang Li",
      "Lei Han",
      "Yang Liu"
    ],
    "abstract": "Recent advancements in Multi-modal Large Language Models (MLLMs) have opened\nnew avenues for applications in Embodied AI. Building on previous work,\nEgoThink, we introduce VidEgoThink, a comprehensive benchmark for evaluating\negocentric video understanding capabilities. To bridge the gap between MLLMs\nand low-level control in Embodied AI, we design four key interrelated tasks:\nvideo question-answering, hierarchy planning, visual grounding and reward\nmodeling. To minimize manual annotation costs, we develop an automatic data\ngeneration pipeline based on the Ego4D dataset, leveraging the prior knowledge\nand multimodal capabilities of GPT-4o. Three human annotators then filter the\ngenerated data to ensure diversity and quality, resulting in the VidEgoThink\nbenchmark. We conduct extensive experiments with three types of models:\nAPI-based MLLMs, open-source image-based MLLMs, and open-source video-based\nMLLMs. Experimental results indicate that all MLLMs, including GPT-4o, perform\npoorly across all tasks related to egocentric video understanding. These\nfindings suggest that foundation models still require significant advancements\nto be effectively applied to first-person scenarios in Embodied AI. In\nconclusion, VidEgoThink reflects a research trend towards employing MLLMs for\negocentric vision, akin to human capabilities, enabling active observation and\ninteraction in the complex real-world environments.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11623v1",
    "published_date": "2024-10-15 14:08:53 UTC",
    "updated_date": "2024-10-15 14:08:53 UTC"
  },
  {
    "arxiv_id": "2410.11594v1",
    "title": "Black-box Uncertainty Quantification Method for LLM-as-a-Judge",
    "authors": [
      "Nico Wagner",
      "Michael Desmond",
      "Rahul Nair",
      "Zahra Ashktorab",
      "Elizabeth M. Daly",
      "Qian Pan",
      "Martín Santillán Cooper",
      "James M. Johnson",
      "Werner Geyer"
    ],
    "abstract": "LLM-as-a-Judge is a widely used method for evaluating the performance of\nLarge Language Models (LLMs) across various tasks. We address the challenge of\nquantifying the uncertainty of LLM-as-a-Judge evaluations. While uncertainty\nquantification has been well-studied in other domains, applying it effectively\nto LLMs poses unique challenges due to their complex decision-making\ncapabilities and computational demands. In this paper, we introduce a novel\nmethod for quantifying uncertainty designed to enhance the trustworthiness of\nLLM-as-a-Judge evaluations. The method quantifies uncertainty by analyzing the\nrelationships between generated assessments and possible ratings. By\ncross-evaluating these relationships and constructing a confusion matrix based\non token probabilities, the method derives labels of high or low uncertainty.\nWe evaluate our method across multiple benchmarks, demonstrating a strong\ncorrelation between the accuracy of LLM evaluations and the derived uncertainty\nscores. Our findings suggest that this method can significantly improve the\nreliability and consistency of LLM-as-a-Judge evaluations.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11594v1",
    "published_date": "2024-10-15 13:29:22 UTC",
    "updated_date": "2024-10-15 13:29:22 UTC"
  },
  {
    "arxiv_id": "2410.17283v3",
    "title": "Advancements in Visual Language Models for Remote Sensing: Datasets, Capabilities, and Enhancement Techniques",
    "authors": [
      "Lijie Tao",
      "Haokui Zhang",
      "Haizhao Jing",
      "Yu Liu",
      "Dawei Yan",
      "Guoting Wei",
      "Xizhe Xue"
    ],
    "abstract": "Recently, the remarkable success of ChatGPT has sparked a renewed wave of\ninterest in artificial intelligence (AI), and the advancements in visual\nlanguage models (VLMs) have pushed this enthusiasm to new heights. Differring\nfrom previous AI approaches that generally formulated different tasks as\ndiscriminative models, VLMs frame tasks as generative models and align language\nwith visual information, enabling the handling of more challenging problems.\nThe remote sensing (RS) field, a highly practical domain, has also embraced\nthis new trend and introduced several VLM-based RS methods that have\ndemonstrated promising performance and enormous potential. In this paper, we\nfirst review the fundamental theories related to VLM, then summarize the\ndatasets constructed for VLMs in remote sensing and the various tasks they\naddressed. Finally, we categorize the improvement methods into three main parts\naccording to the core components of VLMs and provide a detailed introduction\nand comparison of these methods. A project associated with this review has been\ncreated at https://github.com/taolijie11111/VLMs-in-RS-review.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.17283v3",
    "published_date": "2024-10-15 13:28:55 UTC",
    "updated_date": "2025-01-02 04:13:40 UTC"
  },
  {
    "arxiv_id": "2410.11591v1",
    "title": "PaSTe: Improving the Efficiency of Visual Anomaly Detection at the Edge",
    "authors": [
      "Manuel Barusco",
      "Francesco Borsatti",
      "Davide Dalle Pezze",
      "Francesco Paissan",
      "Elisabetta Farella",
      "Gian Antonio Susto"
    ],
    "abstract": "Visual Anomaly Detection (VAD) has gained significant research attention for\nits ability to identify anomalous images and pinpoint the specific areas\nresponsible for the anomaly. A key advantage of VAD is its unsupervised nature,\nwhich eliminates the need for costly and time-consuming labeled data\ncollection. However, despite its potential for real-world applications, the\nliterature has given limited focus to resource-efficient VAD, particularly for\ndeployment on edge devices. This work addresses this gap by leveraging\nlightweight neural networks to reduce memory and computation requirements,\nenabling VAD deployment on resource-constrained edge devices. We benchmark the\nmajor VAD algorithms within this framework and demonstrate the feasibility of\nedge-based VAD using the well-known MVTec dataset. Furthermore, we introduce a\nnovel algorithm, Partially Shared Teacher-student (PaSTe), designed to address\nthe high resource demands of the existing Student Teacher Feature Pyramid\nMatching (STFPM) approach. Our results show that PaSTe decreases the inference\ntime by 25%, while reducing the training time by 33% and peak RAM usage during\ntraining by 76%. These improvements make the VAD process significantly more\nefficient, laying a solid foundation for real-world deployment on edge devices.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "13 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.11591v1",
    "published_date": "2024-10-15 13:25:43 UTC",
    "updated_date": "2024-10-15 13:25:43 UTC"
  },
  {
    "arxiv_id": "2410.11590v1",
    "title": "Towards a Healthy AI Tradition: Lessons from Biology and Biomedical Science",
    "authors": [
      "Simon Kasif"
    ],
    "abstract": "AI is a magnificent field that directly and profoundly touches on numerous\ndisciplines ranging from philosophy, computer science, engineering,\nmathematics, decision and data science and economics, to cognitive science,\nneuroscience and more. The number of applications and impact of AI is second to\nnone and the potential of AI to broadly impact future science developments is\nparticularly thrilling. While attempts to understand knowledge, reasoning,\ncognition and learning go back centuries, AI remains a relatively new field. In\npart due to the fact it has so many wide-ranging overlaps with other disparate\nfields it appears to have trouble developing a robust identity and culture.\nHere we suggest that contrasting the fast-moving AI culture to biological and\nbiomedical sciences is both insightful and useful way to inaugurate a healthy\ntradition needed to envision and manage our ascent to AGI and beyond\n(independent of the AI Platforms used). The co-evolution of AI and Biomedical\nScience offers many benefits to both fields. In a previous perspective, we\nsuggested that biomedical laboratories or centers can usefully embrace logistic\ntraditions in AI labs that will allow them to be highly collaborative, improve\nthe reproducibility of research, reduce risk aversion and produce faster\nmentorship pathways for PhDs and fellows. This perspective focuses on the\nbenefits to AI by adapting features of biomedical science at higher, primarily\ncultural levels.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11590v1",
    "published_date": "2024-10-15 13:25:02 UTC",
    "updated_date": "2024-10-15 13:25:02 UTC"
  },
  {
    "arxiv_id": "2410.11584v2",
    "title": "DeformPAM: Data-Efficient Learning for Long-horizon Deformable Object Manipulation via Preference-based Action Alignment",
    "authors": [
      "Wendi Chen",
      "Han Xue",
      "Fangyuan Zhou",
      "Yuan Fang",
      "Cewu Lu"
    ],
    "abstract": "In recent years, imitation learning has made progress in the field of robotic\nmanipulation. However, it still faces challenges when addressing complex\nlong-horizon tasks with deformable objects, such as high-dimensional state\nspaces, complex dynamics, and multimodal action distributions. Traditional\nimitation learning methods often require a large amount of data and encounter\ndistributional shifts and accumulative errors in these tasks. To address these\nissues, we propose a data-efficient general learning framework (DeformPAM)\nbased on preference learning and reward-guided action selection. DeformPAM\ndecomposes long-horizon tasks into multiple action primitives, utilizes 3D\npoint cloud inputs and diffusion models to model action distributions, and\ntrains an implicit reward model using human preference data. During the\ninference phase, the reward model scores multiple candidate actions, selecting\nthe optimal action for execution, thereby reducing the occurrence of anomalous\nactions and improving task completion quality. Experiments conducted on three\nchallenging real-world long-horizon deformable object manipulation tasks\ndemonstrate the effectiveness of this method. Results show that DeformPAM\nimproves both task completion quality and efficiency compared to baseline\nmethods even with limited data. Code and data will be available at\nhttps://deform-pam.robotflow.ai.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted to ICRA 2025. Project page: https://deform-pam.robotflow.ai",
    "pdf_url": "http://arxiv.org/pdf/2410.11584v2",
    "published_date": "2024-10-15 13:19:16 UTC",
    "updated_date": "2025-03-12 17:54:11 UTC"
  },
  {
    "arxiv_id": "2410.11582v1",
    "title": "On-the-fly Modulation for Balanced Multimodal Learning",
    "authors": [
      "Yake Wei",
      "Di Hu",
      "Henghui Du",
      "Ji-Rong Wen"
    ],
    "abstract": "Multimodal learning is expected to boost model performance by integrating\ninformation from different modalities. However, its potential is not fully\nexploited because the widely-used joint training strategy, which has a uniform\nobjective for all modalities, leads to imbalanced and under-optimized uni-modal\nrepresentations. Specifically, we point out that there often exists modality\nwith more discriminative information, e.g., vision of playing football and\nsound of blowing wind. They could dominate the joint training process,\nresulting in other modalities being significantly under-optimized. To alleviate\nthis problem, we first analyze the under-optimized phenomenon from both the\nfeed-forward and the back-propagation stages during optimization. Then,\nOn-the-fly Prediction Modulation (OPM) and On-the-fly Gradient Modulation (OGM)\nstrategies are proposed to modulate the optimization of each modality, by\nmonitoring the discriminative discrepancy between modalities during training.\nConcretely, OPM weakens the influence of the dominant modality by dropping its\nfeature with dynamical probability in the feed-forward stage, while OGM\nmitigates its gradient in the back-propagation stage. In experiments, our\nmethods demonstrate considerable improvement across a variety of multimodal\ntasks. These simple yet effective strategies not only enhance performance in\nvanilla and task-oriented multimodal models, but also in more complex\nmultimodal tasks, showcasing their effectiveness and flexibility. The source\ncode is available at \\url{https://github.com/GeWu-Lab/BML_TPAMI2024}.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by T-PAMI 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.11582v1",
    "published_date": "2024-10-15 13:15:50 UTC",
    "updated_date": "2024-10-15 13:15:50 UTC"
  },
  {
    "arxiv_id": "2410.11550v1",
    "title": "Y-Mol: A Multiscale Biomedical Knowledge-Guided Large Language Model for Drug Development",
    "authors": [
      "Tengfei Ma",
      "Xuan Lin",
      "Tianle Li",
      "Chaoyi Li",
      "Long Chen",
      "Peng Zhou",
      "Xibao Cai",
      "Xinyu Yang",
      "Daojian Zeng",
      "Dongsheng Cao",
      "Xiangxiang Zeng"
    ],
    "abstract": "Large Language Models (LLMs) have recently demonstrated remarkable\nperformance in general tasks across various fields. However, their\neffectiveness within specific domains such as drug development remains\nchallenges. To solve these challenges, we introduce \\textbf{Y-Mol}, forming a\nwell-established LLM paradigm for the flow of drug development. Y-Mol is a\nmultiscale biomedical knowledge-guided LLM designed to accomplish tasks across\nlead compound discovery, pre-clinic, and clinic prediction. By integrating\nmillions of multiscale biomedical knowledge and using LLaMA2 as the base LLM,\nY-Mol augments the reasoning capability in the biomedical domain by learning\nfrom a corpus of publications, knowledge graphs, and expert-designed synthetic\ndata. The capability is further enriched with three types of drug-oriented\ninstructions: description-based prompts from processed publications,\nsemantic-based prompts for extracting associations from knowledge graphs, and\ntemplate-based prompts for understanding expert knowledge from biomedical\ntools. Besides, Y-Mol offers a set of LLM paradigms that can autonomously\nexecute the downstream tasks across the entire process of drug development,\nincluding virtual screening, drug design, pharmacological properties\nprediction, and drug-related interaction prediction. Our extensive evaluations\nof various biomedical sources demonstrate that Y-Mol significantly outperforms\ngeneral-purpose LLMs in discovering lead compounds, predicting molecular\nproperties, and identifying drug interaction events.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "12 pages, Under Review",
    "pdf_url": "http://arxiv.org/pdf/2410.11550v1",
    "published_date": "2024-10-15 12:39:20 UTC",
    "updated_date": "2024-10-15 12:39:20 UTC"
  },
  {
    "arxiv_id": "2410.11533v2",
    "title": "Multi-round jailbreak attack on large language models",
    "authors": [
      "Yihua Zhou",
      "Xiaochuan Shi"
    ],
    "abstract": "Ensuring the safety and alignment of large language models (LLMs) with human\nvalues is crucial for generating responses that are beneficial to humanity.\nWhile LLMs have the capability to identify and avoid harmful queries, they\nremain vulnerable to \"jailbreak\" attacks, where carefully crafted prompts can\ninduce the generation of toxic content. Traditional single-round jailbreak\nattacks, such as GCG and AutoDAN, do not alter the sensitive words in the\ndangerous prompts. Although they can temporarily bypass the model's safeguards\nthrough prompt engineering, their success rate drops significantly as the LLM\nis further fine-tuned, and they cannot effectively circumvent static rule-based\nfilters that remove the hazardous vocabulary.\n  In this study, to better understand jailbreak attacks, we introduce a\nmulti-round jailbreak approach. This method can rewrite the dangerous prompts,\ndecomposing them into a series of less harmful sub-questions to bypass the\nLLM's safety checks. We first use the LLM to perform a decomposition task,\nbreaking down a set of natural language questions into a sequence of\nprogressive sub-questions, which are then used to fine-tune the Llama3-8B\nmodel, enabling it to decompose hazardous prompts. The fine-tuned model is then\nused to break down the problematic prompt, and the resulting sub-questions are\nsequentially asked to the victim model. If the victim model rejects a\nsub-question, a new decomposition is generated, and the process is repeated\nuntil the final objective is achieved. Our experimental results show a 94\\%\nsuccess rate on the llama2-7B and demonstrate the effectiveness of this\napproach in circumventing static rule-based filters.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "It is not fully completed",
    "pdf_url": "http://arxiv.org/pdf/2410.11533v2",
    "published_date": "2024-10-15 12:08:14 UTC",
    "updated_date": "2024-10-19 09:17:32 UTC"
  },
  {
    "arxiv_id": "2410.11531v1",
    "title": "AGENTiGraph: An Interactive Knowledge Graph Platform for LLM-based Chatbots Utilizing Private Data",
    "authors": [
      "Xinjie Zhao",
      "Moritz Blum",
      "Rui Yang",
      "Boming Yang",
      "Luis Márquez Carpintero",
      "Mónica Pina-Navarro",
      "Tony Wang",
      "Xin Li",
      "Huitao Li",
      "Yanran Fu",
      "Rongrong Wang",
      "Juntao Zhang",
      "Irene Li"
    ],
    "abstract": "Large Language Models~(LLMs) have demonstrated capabilities across various\napplications but face challenges such as hallucination, limited reasoning\nabilities, and factual inconsistencies, especially when tackling complex,\ndomain-specific tasks like question answering~(QA). While Knowledge\nGraphs~(KGs) have been shown to help mitigate these issues, research on the\nintegration of LLMs with background KGs remains limited. In particular, user\naccessibility and the flexibility of the underlying KG have not been thoroughly\nexplored. We introduce AGENTiGraph (Adaptive Generative ENgine for Task-based\nInteraction and Graphical Representation), a platform for knowledge management\nthrough natural language interaction. It integrates knowledge extraction,\nintegration, and real-time visualization. AGENTiGraph employs a multi-agent\narchitecture to dynamically interpret user intents, manage tasks, and integrate\nnew knowledge, ensuring adaptability to evolving user requirements and data\ncontexts. Our approach demonstrates superior performance in knowledge graph\ninteractions, particularly for complex domain-specific tasks. Experimental\nresults on a dataset of 3,500 test cases show AGENTiGraph significantly\noutperforms state-of-the-art zero-shot baselines, achieving 95.12\\% accuracy in\ntask classification and 90.45\\% success rate in task execution. User studies\ncorroborate its effectiveness in real-world scenarios. To showcase versatility,\nwe extended AGENTiGraph to legislation and healthcare domains, constructing\nspecialized KGs capable of answering complex queries in legal and medical\ncontexts.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "30 pages, 7 figures; Submitted to COLING 2025 System Demonstrations\n  Track",
    "pdf_url": "http://arxiv.org/pdf/2410.11531v1",
    "published_date": "2024-10-15 12:05:58 UTC",
    "updated_date": "2024-10-15 12:05:58 UTC"
  },
  {
    "arxiv_id": "2410.11507v4",
    "title": "TestAgent: A Framework for Domain-Adaptive Evaluation of LLMs via Dynamic Benchmark Construction and Exploratory Interaction",
    "authors": [
      "Wanying Wang",
      "Zeyu Ma",
      "Pengfei Liu",
      "Mingang Chen"
    ],
    "abstract": "As large language models (LLMs) are increasingly deployed to various vertical\ndomains, automatically evaluating their performance across different domains\nremains a critical challenge. Current evaluation methods often rely on static\nand resource-intensive datasets that are not aligned with real-world\nrequirements and lack cross-domain adaptability. To address these limitations,\nwe revisit the evaluation process and introduce two key concepts:\n\\textbf{Benchmark+}, which extends the traditional question-answer benchmark\ninto a more flexible ``strategy-criterion'' format; and \\textbf{Assessment+},\nwhich enhances the interaction process to facilitate deeper exploration and\ncomprehensive analysis from multiple perspectives. We propose\n\\textbf{\\textsc{TestAgent}}, an agent-based evaluation framework that\nimplements these concepts using retrieval-augmented generation and\nreinforcement learning. \\textsc{TestAgent} enables automatic dynamic benchmark\ngeneration and in-depth assessment across diverse vertical domains. Experiments\non tasks ranging from constructing multiple vertical domain evaluations to\ntransforming static benchmarks into dynamic forms demonstrate the effectiveness\nof \\textsc{TestAgent}. This work provides a novel perspective on automatic\nevaluation methods for domain-specific LLMs, offering a pathway for\ndomain-adaptive dynamic benchmark construction and exploratory assessment.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11507v4",
    "published_date": "2024-10-15 11:20:42 UTC",
    "updated_date": "2025-05-16 05:34:13 UTC"
  },
  {
    "arxiv_id": "2410.11502v3",
    "title": "Offline Model-Based Optimization by Learning to Rank",
    "authors": [
      "Rong-Xi Tan",
      "Ke Xue",
      "Shen-Huan Lyu",
      "Haopu Shang",
      "Yao Wang",
      "Yaoyuan Wang",
      "Sheng Fu",
      "Chao Qian"
    ],
    "abstract": "Offline model-based optimization (MBO) aims to identify a design that\nmaximizes a black-box function using only a fixed, pre-collected dataset of\ndesigns and their corresponding scores. A common approach in offline MBO is to\ntrain a regression-based surrogate model by minimizing mean squared error (MSE)\nand then find the best design within this surrogate model by different\noptimizers (e.g., gradient ascent). However, a critical challenge is the risk\nof out-of-distribution errors, i.e., the surrogate model may typically\noverestimate the scores and mislead the optimizers into suboptimal regions.\nPrior works have attempted to address this issue in various ways, such as using\nregularization techniques and ensemble learning to enhance the robustness of\nthe model, but it still remains. In this paper, we argue that regression models\ntrained with MSE are not well-aligned with the primary goal of offline MBO,\nwhich is to select promising designs rather than to predict their scores\nprecisely. Notably, if a surrogate model can maintain the order of candidate\ndesigns based on their relative score relationships, it can produce the best\ndesigns even without precise predictions. To validate it, we conduct\nexperiments to compare the relationship between the quality of the final\ndesigns and MSE, finding that the correlation is really very weak. In contrast,\na metric that measures order-maintaining quality shows a significantly stronger\ncorrelation. Based on this observation, we propose learning a ranking-based\nmodel that leverages learning to rank techniques to prioritize promising\ndesigns based on their relative scores. We show that the generalization error\non ranking loss can be well bounded. Empirical results across diverse tasks\ndemonstrate the superior performance of our proposed ranking-based models than\ntwenty existing methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.11502v3",
    "published_date": "2024-10-15 11:15:03 UTC",
    "updated_date": "2025-05-02 15:46:08 UTC"
  },
  {
    "arxiv_id": "2410.11499v1",
    "title": "BSM: Small but Powerful Biological Sequence Model for Genes and Proteins",
    "authors": [
      "Weixi Xiang",
      "Xueting Han",
      "Xiujuan Chai",
      "Jing Bai"
    ],
    "abstract": "Modeling biological sequences such as DNA, RNA, and proteins is crucial for\nunderstanding complex processes like gene regulation and protein synthesis.\nHowever, most current models either focus on a single type or treat multiple\ntypes of data separately, limiting their ability to capture cross-modal\nrelationships. We propose that by learning the relationships between these\nmodalities, the model can enhance its understanding of each type. To address\nthis, we introduce BSM, a small but powerful mixed-modal biological sequence\nfoundation model, trained on three types of data: RefSeq, Gene Related\nSequences, and interleaved biological sequences from the web. These datasets\ncapture the genetic flow, gene-protein relationships, and the natural\nco-occurrence of diverse biological data, respectively. By training on\nmixed-modal data, BSM significantly enhances learning efficiency and\ncross-modal representation, outperforming models trained solely on unimodal\ndata. With only 110M parameters, BSM achieves performance comparable to much\nlarger models across both single-modal and mixed-modal tasks, and uniquely\ndemonstrates in-context learning capability for mixed-modal tasks, which is\nabsent in existing models. Further scaling to 270M parameters demonstrates even\ngreater performance gains, highlighting the potential of BSM as a significant\nadvancement in multimodal biological sequence modeling.",
    "categories": [
      "q-bio.GN",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.GN",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11499v1",
    "published_date": "2024-10-15 11:12:28 UTC",
    "updated_date": "2024-10-15 11:12:28 UTC"
  },
  {
    "arxiv_id": "2410.11494v1",
    "title": "DynamicER: Resolving Emerging Mentions to Dynamic Entities for RAG",
    "authors": [
      "Jinyoung Kim",
      "Dayoon Ko",
      "Gunhee Kim"
    ],
    "abstract": "In the rapidly evolving landscape of language, resolving new linguistic\nexpressions in continuously updating knowledge bases remains a formidable\nchallenge. This challenge becomes critical in retrieval-augmented generation\n(RAG) with knowledge bases, as emerging expressions hinder the retrieval of\nrelevant documents, leading to generator hallucinations. To address this issue,\nwe introduce a novel task aimed at resolving emerging mentions to dynamic\nentities and present DynamicER benchmark. Our benchmark includes dynamic entity\nmention resolution and entity-centric knowledge-intensive QA task, evaluating\nentity linking and RAG model's adaptability to new expressions, respectively.\nWe discovered that current entity linking models struggle to link these new\nexpressions to entities. Therefore, we propose a temporal segmented clustering\nmethod with continual adaptation, effectively managing the temporal dynamics of\nevolving entities and emerging mentions. Extensive experiments demonstrate that\nour method outperforms existing baselines, enhancing RAG model performance on\nQA task with resolved mentions.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2024 Main",
    "pdf_url": "http://arxiv.org/pdf/2410.11494v1",
    "published_date": "2024-10-15 10:57:12 UTC",
    "updated_date": "2024-10-15 10:57:12 UTC"
  },
  {
    "arxiv_id": "2410.11493v2",
    "title": "Towards Fair Graph Representation Learning in Social Networks",
    "authors": [
      "Guixian Zhang",
      "Guan Yuan",
      "Debo Cheng",
      "Lin Liu",
      "Jiuyong Li",
      "Shichao Zhang"
    ],
    "abstract": "With the widespread use of Graph Neural Networks (GNNs) for representation\nlearning from network data, the fairness of GNN models has raised great\nattention lately. Fair GNNs aim to ensure that node representations can be\naccurately classified, but not easily associated with a specific group.\nExisting advanced approaches essentially enhance the generalisation of node\nrepresentation in combination with data augmentation strategy, and do not\ndirectly impose constraints on the fairness of GNNs. In this work, we identify\nthat a fundamental reason for the unfairness of GNNs in social network learning\nis the phenomenon of social homophily, i.e., users in the same group are more\ninclined to congregate. The message-passing mechanism of GNNs can cause users\nin the same group to have similar representations due to social homophily,\nleading model predictions to establish spurious correlations with sensitive\nattributes. Inspired by this reason, we propose a method called Equity-Aware\nGNN (EAGNN) towards fair graph representation learning. Specifically, to ensure\nthat model predictions are independent of sensitive attributes while\nmaintaining prediction performance, we introduce constraints for fair\nrepresentation learning based on three principles: sufficiency, independence,\nand separation. We theoretically demonstrate that our EAGNN method can\neffectively achieve group fairness. Extensive experiments on three datasets\nwith varying levels of social homophily illustrate that our EAGNN method\nachieves the state-of-the-art performance across two fairness metrics and\noffers competitive effectiveness.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11493v2",
    "published_date": "2024-10-15 10:57:02 UTC",
    "updated_date": "2024-10-22 02:31:19 UTC"
  },
  {
    "arxiv_id": "2410.11492v1",
    "title": "NavTopo: Leveraging Topological Maps For Autonomous Navigation Of a Mobile Robot",
    "authors": [
      "Kirill Muravyev",
      "Konstantin Yakovlev"
    ],
    "abstract": "Autonomous navigation of a mobile robot is a challenging task which requires\nability of mapping, localization, path planning and path following.\nConventional mapping methods build a dense metric map like an occupancy grid,\nwhich is affected by odometry error accumulation and consumes a lot of memory\nand computations in large environments. Another approach to mapping is the\nusage of topological properties, e.g. adjacency of locations in the\nenvironment. Topological maps are less prone to odometry error accumulation and\nhigh resources consumption, and also enable fast path planning because of the\ngraph sparsity. Based on this idea, we proposed NavTopo - a full navigation\npipeline based on topological map and two-level path planning. The pipeline\nlocalizes in the graph by matching neural network descriptors and 2D\nprojections of the input point clouds, which significantly reduces memory\nconsumption compared to metric and topological point cloud-based approaches. We\ntest our approach in a large indoor photo-relaistic simulated environment and\ncompare it to a metric map-based approach based on popular metric mapping\nmethod RTAB-MAP. The experimental results show that our topological approach\nsignificantly outperforms the metric one in terms of performance, keeping\nproper navigational efficiency.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "I.2.9; I.2.10"
    ],
    "primary_category": "cs.RO",
    "comment": "This paper is published in proceedings of the 9th International\n  Conference \"Interactive Collaborative Robotics\" (ICR 2024)",
    "pdf_url": "http://arxiv.org/pdf/2410.11492v1",
    "published_date": "2024-10-15 10:54:49 UTC",
    "updated_date": "2024-10-15 10:54:49 UTC"
  },
  {
    "arxiv_id": "2410.11464v1",
    "title": "CoActionGraphRec: Sequential Multi-Interest Recommendations Using Co-Action Graphs",
    "authors": [
      "Yi Sun",
      "Yuri M. Brovman"
    ],
    "abstract": "There are unique challenges to developing item recommender systems for\ne-commerce platforms like eBay due to sparse data and diverse user interests.\nWhile rich user-item interactions are important, eBay's data sparsity exceeds\nother e-commerce sites by an order of magnitude. To address this challenge, we\npropose CoActionGraphRec (CAGR), a text based two-tower deep learning model\n(Item Tower and User Tower) utilizing co-action graph layers. In order to\nenhance user and item representations, a graph-based solution tailored to\neBay's environment is utilized. For the Item Tower, we represent each item\nusing its co-action items to capture collaborative signals in a co-action graph\nthat is fully leveraged by the graph neural network component. For the User\nTower, we build a fully connected graph of each user's behavior sequence, with\nedges encoding pairwise relationships. Furthermore, an explicit interaction\nmodule learns representations capturing behavior interactions. Extensive\noffline and online A/B test experiments demonstrate the effectiveness of our\nproposed approach and results show improved performance over state-of-the-art\nmethods on key metrics.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11464v1",
    "published_date": "2024-10-15 10:11:18 UTC",
    "updated_date": "2024-10-15 10:11:18 UTC"
  },
  {
    "arxiv_id": "2410.11463v2",
    "title": "Advanced Persistent Threats (APT) Attribution Using Deep Reinforcement Learning",
    "authors": [
      "Animesh Singh Basnet",
      "Mohamed Chahine Ghanem",
      "Dipo Dunsin",
      "Wiktor Sowinski-Mydlarz"
    ],
    "abstract": "The development of the DRL model for malware attribution involved extensive\nresearch, iterative coding, and numerous adjustments based on the insights\ngathered from predecessor models and contemporary research papers. This\npreparatory work was essential to establish a robust foundation for the model,\nensuring it could adapt and respond effectively to the dynamic nature of\nmalware threats. Initially, the model struggled with low accuracy levels, but\nthrough persistent adjustments to its architecture and learning algorithms,\naccuracy improved dramatically from about 7 percent to over 73 percent in early\niterations. By the end of the training, the model consistently reached accuracy\nlevels near 98 percent, demonstrating its strong capability to accurately\nrecognise and attribute malware activities. This upward trajectory in training\naccuracy is graphically represented in the Figure, which vividly illustrates\nthe model maturation and increasing proficiency over time.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "21 Pages",
    "pdf_url": "http://arxiv.org/pdf/2410.11463v2",
    "published_date": "2024-10-15 10:10:33 UTC",
    "updated_date": "2025-01-07 15:48:15 UTC"
  },
  {
    "arxiv_id": "2410.22352v1",
    "title": "Neuromorphic Programming: Emerging Directions for Brain-Inspired Hardware",
    "authors": [
      "Steven Abreu",
      "Jens E. Pedersen"
    ],
    "abstract": "The value of brain-inspired neuromorphic computers critically depends on our\nability to program them for relevant tasks. Currently, neuromorphic hardware\noften relies on machine learning methods adapted from deep learning. However,\nneuromorphic computers have potential far beyond deep learning if we can only\nharness their energy efficiency and full computational power. Neuromorphic\nprogramming will necessarily be different from conventional programming,\nrequiring a paradigm shift in how we think about programming. This paper\npresents a conceptual analysis of programming within the context of\nneuromorphic computing, challenging conventional paradigms and proposing a\nframework that aligns more closely with the physical intricacies of these\nsystems. Our analysis revolves around five characteristics that are fundamental\nto neuromorphic programming and provides a basis for comparison to contemporary\nprogramming methods and languages. By studying past approaches, we contribute a\nframework that advocates for underutilized techniques and calls for richer\nabstractions to effectively instrument the new hardware class.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.DC",
      "cs.ET",
      "cs.PL"
    ],
    "primary_category": "cs.NE",
    "comment": "Accepted to International Conference on Neuromorphic Systems (ICONS)\n  2024. arXiv admin note: substantial text overlap with arXiv:2310.18260",
    "pdf_url": "http://arxiv.org/pdf/2410.22352v1",
    "published_date": "2024-10-15 10:08:15 UTC",
    "updated_date": "2024-10-15 10:08:15 UTC"
  },
  {
    "arxiv_id": "2410.11457v1",
    "title": "LR-SQL: A Supervised Fine-Tuning Method for Text2SQL Tasks under Low-Resource Scenarios",
    "authors": [
      "Wen Wuzhenghong",
      "Zhang Yongpan",
      "Pan Su",
      "Sun Yuwei",
      "Lu Pengwei",
      "Ding Cheng"
    ],
    "abstract": "Large language models revolutionize Text2SQL through supervised fine-tuning,\nyet a crucial limitation is overlooked: the complexity of databases leads to an\nincreased context length, consequently resulting in higher GPU memory demands\nfor model fine-tuning. To address this issue, we propose LR-SQL. LR-SQL\ncomprises two supervised fine-tuning models: the schema\\_link model and the\nSQL\\_generation model, with the schema\\_link model serving as the focal point\nfor streamlining the overall process. During the fine-tuning of the\nschema\\_link model, LR-SQL breaks down the complete database into flexible\ncombinations of tables with adjustable quantities, enabling the model to learn\nthe relationships within the entire database from these dispersed slices.\nFurthermore, to enhance the model's ability to perceive the relationships among\nvarious discrete slices during inference, LR-SQL trains the model's\nChain-of-Thought capability for this task. Experimental results demonstrate\nthat LR-SQL can reduce the total GPU memory usage by 40\\% compared to existing\nfine-tuning methods, while only losing 2\\% of table prediction accuracy in\nschema\\_link task. For the overall Text2SQL task, the Execution Accuracy\ndecrease by 0.6\\%.Our project is now available on\nhttps://github.com/hongWin/LR-SQL",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.DB",
    "comment": "12pages, 4 figures,submitting to a journal",
    "pdf_url": "http://arxiv.org/pdf/2410.11457v1",
    "published_date": "2024-10-15 10:02:55 UTC",
    "updated_date": "2024-10-15 10:02:55 UTC"
  },
  {
    "arxiv_id": "2410.11444v2",
    "title": "A Theoretical Survey on Foundation Models",
    "authors": [
      "Shi Fu",
      "Yuzhu Chen",
      "Yingjie Wang",
      "Dacheng Tao"
    ],
    "abstract": "Understanding the inner mechanisms of black-box foundation models (FMs) is\nessential yet challenging in artificial intelligence and its applications. Over\nthe last decade, the long-running focus has been on their explainability,\nleading to the development of post-hoc explainable methods to rationalize the\nspecific decisions already made by black-box FMs. However, these explainable\nmethods have certain limitations in terms of faithfulness and resource\nrequirement. Consequently, a new class of interpretable methods should be\nconsidered to unveil the underlying mechanisms of FMs in an accurate,\ncomprehensive, heuristic, and resource-light way. This survey aims to review\nthose interpretable methods that comply with the aforementioned principles and\nhave been successfully applied to FMs. These methods are deeply rooted in\nmachine learning theory, covering the analysis of generalization performance,\nexpressive capability, and dynamic behavior. They provide a thorough\ninterpretation of the entire workflow of FMs, ranging from the inference\ncapability and training dynamics to their ethical implications. Ultimately,\ndrawing upon these interpretations, this review identifies the next frontier\nresearch directions for FMs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "63 pages, 16 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.11444v2",
    "published_date": "2024-10-15 09:48:03 UTC",
    "updated_date": "2024-11-24 15:02:23 UTC"
  },
  {
    "arxiv_id": "2410.11437v1",
    "title": "Difficult Task Yes but Simple Task No: Unveiling the Laziness in Multimodal LLMs",
    "authors": [
      "Sihang Zhao",
      "Youliang Yuan",
      "Xiaoying Tang",
      "Pinjia He"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) demonstrate a strong understanding\nof the real world and can even handle complex tasks. However, they still fail\non some straightforward visual question-answering (VQA) problems. This paper\ndives deeper into this issue, revealing that models tend to err when answering\neasy questions (e.g. Yes/No questions) about an image, even though they can\ncorrectly describe it. We refer to this model behavior discrepancy between\ndifficult and simple questions as model laziness. To systematically investigate\nmodel laziness, we manually construct LazyBench, a benchmark that includes\nYes/No, multiple choice, short answer questions, and image description tasks\nthat are related to the same subjects in the images. Based on LazyBench, we\nobserve that laziness widely exists in current advanced MLLMs (e.g. GPT-4o,\nGemini-1.5-pro, Claude 3 and LLaVA-v1.5-13B), and it is more pronounced on\nstronger models. We also analyze the VQA v2 (LLaVA-v1.5-13B) benchmark and find\nthat about half of its failure cases are caused by model laziness, which\nfurther highlights the importance of ensuring that the model fully utilizes its\ncapability. To this end, we conduct preliminary exploration on how to mitigate\nlaziness and find that chain of thought (CoT) can effectively address this\nissue.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2410.11437v1",
    "published_date": "2024-10-15 09:40:50 UTC",
    "updated_date": "2024-10-15 09:40:50 UTC"
  },
  {
    "arxiv_id": "2410.11428v1",
    "title": "CTA-Net: A CNN-Transformer Aggregation Network for Improving Multi-Scale Feature Extraction",
    "authors": [
      "Chunlei Meng",
      "Jiacheng Yang",
      "Wei Lin",
      "Bowen Liu",
      "Hongda Zhang",
      "chun ouyang",
      "Zhongxue Gan"
    ],
    "abstract": "Convolutional neural networks (CNNs) and vision transformers (ViTs) have\nbecome essential in computer vision for local and global feature extraction.\nHowever, aggregating these architectures in existing methods often results in\ninefficiencies. To address this, the CNN-Transformer Aggregation Network\n(CTA-Net) was developed. CTA-Net combines CNNs and ViTs, with transformers\ncapturing long-range dependencies and CNNs extracting localized features. This\nintegration enables efficient processing of detailed local and broader\ncontextual information. CTA-Net introduces the Light Weight Multi-Scale Feature\nFusion Multi-Head Self-Attention (LMF-MHSA) module for effective multi-scale\nfeature integration with reduced parameters. Additionally, the Reverse\nReconstruction CNN-Variants (RRCV) module enhances the embedding of CNNs within\nthe transformer architecture. Extensive experiments on small-scale datasets\nwith fewer than 100,000 samples show that CTA-Net achieves superior performance\n(TOP-1 Acc 86.76\\%), fewer parameters (20.32M), and greater efficiency (FLOPs\n2.83B), making it a highly efficient and lightweight solution for visual tasks\non small-scale datasets (fewer than 100,000).",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "9 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.11428v1",
    "published_date": "2024-10-15 09:27:26 UTC",
    "updated_date": "2024-10-15 09:27:26 UTC"
  },
  {
    "arxiv_id": "2410.12878v1",
    "title": "Towards More Effective Table-to-Text Generation: Assessing In-Context Learning and Self-Evaluation with Open-Source Models",
    "authors": [
      "Sahar Iravani",
      "Tim . O . F Conrad"
    ],
    "abstract": "Table processing, a key task in natural language processing, has\nsignificantly benefited from recent advancements in language models (LMs).\nHowever, the capabilities of LMs in table-to-text generation, which transforms\nstructured data into coherent narrative text, require an in-depth\ninvestigation, especially with current open-source models. This study explores\nthe effectiveness of various in-context learning strategies in LMs across\nbenchmark datasets, focusing on the impact of providing examples to the model.\nMore importantly, we examine a real-world use case, offering valuable insights\ninto practical applications. To complement traditional evaluation metrics, we\nemploy a large language model (LLM) self-evaluation approach using\nchain-of-thought reasoning and assess its correlation with human-aligned\nmetrics like BERTScore. Our findings highlight the significant impact of\nexamples in improving table-to-text generation and suggest that, while LLM\nself-evaluation has potential, its current alignment with human judgment could\nbe enhanced. This points to the need for more reliable evaluation methods.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "15 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.12878v1",
    "published_date": "2024-10-15 09:19:42 UTC",
    "updated_date": "2024-10-15 09:19:42 UTC"
  },
  {
    "arxiv_id": "2410.11410v1",
    "title": "PMMT: Preference Alignment in Multilingual Machine Translation via LLM Distillation",
    "authors": [
      "Shuqiao Sun",
      "Yutong Yao",
      "Peiwen Wu",
      "Feijun Jiang",
      "Kaifu Zhang"
    ],
    "abstract": "Translation is important for cross-language communication, and many efforts\nhave been made to improve its accuracy. However, less investment is conducted\nin aligning translations with human preferences, such as translation tones or\nstyles. In this paper, a new method is proposed to effectively generate\nlarge-scale multilingual parallel corpora with specific translation preferences\nusing Large Language Models (LLMs). Meanwhile, an automatic pipeline is\ndesigned to distill human preferences into smaller Machine Translation (MT)\nmodels for efficiently and economically supporting large-scale calls in online\nservices. Experiments indicate that the proposed method takes the lead in\ntranslation tasks with aligned human preferences by a large margin. Meanwhile,\non popular public benchmarks like WMT and Flores, on which our models were not\ntrained, the proposed method also shows a competitive performance compared to\nSOTA works.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11410v1",
    "published_date": "2024-10-15 08:54:27 UTC",
    "updated_date": "2024-10-15 08:54:27 UTC"
  },
  {
    "arxiv_id": "2410.11407v1",
    "title": "A Case for AI Consciousness: Language Agents and Global Workspace Theory",
    "authors": [
      "Simon Goldstein",
      "Cameron Domenico Kirk-Giannini"
    ],
    "abstract": "It is generally assumed that existing artificial systems are not phenomenally\nconscious, and that the construction of phenomenally conscious artificial\nsystems would require significant technological progress if it is possible at\nall. We challenge this assumption by arguing that if Global Workspace Theory\n(GWT) - a leading scientific theory of phenomenal consciousness - is correct,\nthen instances of one widely implemented AI architecture, the artificial\nlanguage agent, might easily be made phenomenally conscious if they are not\nalready. Along the way, we articulate an explicit methodology for thinking\nabout how to apply scientific theories of consciousness to artificial systems\nand employ this methodology to arrive at a set of necessary and sufficient\nconditions for phenomenal consciousness according to GWT.",
    "categories": [
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11407v1",
    "published_date": "2024-10-15 08:50:45 UTC",
    "updated_date": "2024-10-15 08:50:45 UTC"
  },
  {
    "arxiv_id": "2410.11403v1",
    "title": "Enhancing Unimodal Latent Representations in Multimodal VAEs through Iterative Amortized Inference",
    "authors": [
      "Yuta Oshima",
      "Masahiro Suzuki",
      "Yutaka Matsuo"
    ],
    "abstract": "Multimodal variational autoencoders (VAEs) aim to capture shared latent\nrepresentations by integrating information from different data modalities. A\nsignificant challenge is accurately inferring representations from any subset\nof modalities without training an impractical number (2^M) of inference\nnetworks for all possible modality combinations. Mixture-based models simplify\nthis by requiring only as many inference models as there are modalities,\naggregating unimodal inferences. However, they suffer from information loss\nwhen modalities are missing. Alignment-based VAEs address this by aligning\nunimodal inference models with a multimodal model through minimizing the\nKullback-Leibler (KL) divergence but face issues due to amortization gaps,\nwhich compromise inference accuracy. To tackle these problems, we introduce\nmultimodal iterative amortized inference, an iterative refinement mechanism\nwithin the multimodal VAE framework. This method overcomes information loss\nfrom missing modalities and minimizes the amortization gap by iteratively\nrefining the multimodal inference using all available modalities. By aligning\nunimodal inference to this refined multimodal posterior, we achieve unimodal\ninferences that effectively incorporate multimodal information while requiring\nonly unimodal inputs during inference. Experiments on benchmark datasets show\nthat our approach improves inference performance, evidenced by higher linear\nclassification accuracy and competitive cosine similarity, and enhances\ncross-modal generation, indicated by lower FID scores. This demonstrates that\nour method enhances inferred representations from unimodal inputs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "22 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.11403v1",
    "published_date": "2024-10-15 08:49:38 UTC",
    "updated_date": "2024-10-15 08:49:38 UTC"
  },
  {
    "arxiv_id": "2410.11399v2",
    "title": "Convergence to the Truth",
    "authors": [
      "Hanti Lin"
    ],
    "abstract": "This article reviews and develops an epistemological tradition in the\nphilosophy of science, known as convergentism, which holds that inference\nmethods should be assessed based on their ability to converge to the truth\nacross a range of possible scenarios. Emphasis is placed on its historical\norigins in the work of C. S. Peirce and its recent developments in formal\nepistemology and data science (including statistics and machine learning).\nComparisons are made with three other traditions: (1) explanationism, which\nholds that theory choice should be guided by a theory's overall balance of\nexplanatory virtues, such as simplicity and fit with data; (2) instrumentalism,\nwhich maintains that scientific inference should be driven by the goal of\nobtaining useful models rather than true theories; and (3) Bayesianism, which\nshifts the focus from all-or-nothing beliefs to degrees of belief.",
    "categories": [
      "stat.OT",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.OT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11399v2",
    "published_date": "2024-10-15 08:44:14 UTC",
    "updated_date": "2025-02-25 01:42:32 UTC"
  },
  {
    "arxiv_id": "2410.11396v1",
    "title": "Implementing Derivations of Definite Logic Programs with Self-Attention Networks",
    "authors": [
      "Phan Thi Thanh Thuy",
      "Akihiro Yamamoto"
    ],
    "abstract": "In this paper we propose that a restricted version of logical inference can\nbe implemented with self-attention networks. We are aiming at showing that LLMs\n(Large Language Models) constructed with transformer networks can make logical\ninferences. We would reveal the potential of LLMs by analyzing self-attention\nnetworks, which are main components of transformer networks. Our approach is\nnot based on semantics of natural languages but operations of logical\ninference. %point of view. We show that hierarchical constructions of\nself-attention networks with feed forward networks (FFNs) can implement\ntop-down derivations for a class of logical formulae. We also show bottom-up\nderivations are also implemented for the same class. We believe that our\nresults show that LLMs implicitly have the power of logical inference.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Presented at NeLaMKRR@KR, 2024 (arXiv:2410.05339)",
    "pdf_url": "http://arxiv.org/pdf/2410.11396v1",
    "published_date": "2024-10-15 08:39:28 UTC",
    "updated_date": "2024-10-15 08:39:28 UTC"
  },
  {
    "arxiv_id": "2410.11395v1",
    "title": "Synthetic Interlocutors. Experiments with Generative AI to Prolong Ethnographic Encounters",
    "authors": [
      "Johan Irving Søltoft",
      "Laura Kocksch",
      "Anders Kristian Munk"
    ],
    "abstract": "This paper introduces \"Synthetic Interlocutors\" for ethnographic research.\nSynthetic Interlocutors are chatbots ingested with ethnographic textual\nmaterial (interviews and observations) by using Retrieval Augmented Generation\n(RAG). We integrated an open-source large language model with ethnographic data\nfrom three projects to explore two questions: Can RAG digest ethnographic\nmaterial and act as ethnographic interlocutor? And, if so, can Synthetic\nInterlocutors prolong encounters with the field and extend our analysis?\nThrough reflections on the process of building our Synthetic Interlocutors and\nan experimental collaborative workshop, we suggest that RAG can digest\nethnographic materials, and it might lead to prolonged, yet uneasy ethnographic\nencounters that allowed us to partially recreate and re-visit fieldwork\ninteractions while facilitating opportunities for novel analytic insights.\nSynthetic Interlocutors can produce collaborative, ambiguous and serendipitous\nmoments.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11395v1",
    "published_date": "2024-10-15 08:39:12 UTC",
    "updated_date": "2024-10-15 08:39:12 UTC"
  },
  {
    "arxiv_id": "2410.12877v2",
    "title": "Improving Instruction-Following in Language Models through Activation Steering",
    "authors": [
      "Alessandro Stolfo",
      "Vidhisha Balachandran",
      "Safoora Yousefi",
      "Eric Horvitz",
      "Besmira Nushi"
    ],
    "abstract": "The ability to follow instructions is crucial for numerous real-world\napplications of language models. In pursuit of deeper insights and more\npowerful capabilities, we derive instruction-specific vector representations\nfrom language models and use them to steer models accordingly. These vectors\nare computed as the difference in activations between inputs with and without\ninstructions, enabling a modular approach to activation steering. We\ndemonstrate how this method can enhance model adherence to constraints such as\noutput format, length, and word inclusion, providing inference-time control\nover instruction following. Our experiments across four models demonstrate how\nwe can use the activation vectors to guide models to follow constraints even\nwithout explicit instructions and to enhance performance when instructions are\npresent. Additionally, we explore the compositionality of activation steering,\nsuccessfully applying multiple instructions simultaneously. Finally, we\ndemonstrate that steering vectors computed on instruction-tuned models can\ntransfer to improve base models. Our findings demonstrate that activation\nsteering offers a practical and scalable approach for fine-grained control in\nlanguage generation. Our code and data are available at\nhttps://github.com/microsoft/llm-steer-instruct.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.12877v2",
    "published_date": "2024-10-15 08:38:20 UTC",
    "updated_date": "2025-04-14 09:04:45 UTC"
  },
  {
    "arxiv_id": "2410.11384v1",
    "title": "Role of Delay in Brain Dynamics",
    "authors": [
      "Yuval Meir",
      "Ofek Tevet",
      "Yarden Tzach",
      "Shiri Hodassman",
      "Ido Kanter"
    ],
    "abstract": "Significant variations of delays among connecting neurons cause an inevitable\ndisadvantage of asynchronous brain dynamics compared to synchronous deep\nlearning. However, this study demonstrates that this disadvantage can be\nconverted into a computational advantage using a network with a single output\nand M multiple delays between successive layers, thereby generating a\npolynomial time-series outputs with M. The proposed role of delay in brain\ndynamics (RoDiB) model, is capable of learning increasing number of classified\nlabels using a fixed architecture, and overcomes the inflexibility of the brain\nto update the learning architecture using additional neurons and connections.\nMoreover, the achievable accuracies of the RoDiB system are comparable with\nthose of its counterpart tunable single delay architectures with M outputs.\nFurther, the accuracies are significantly enhanced when the number of output\nlabels exceeds its fully connected input size. The results are mainly obtained\nusing simulations of VGG-6 on CIFAR datasets and also include multiple label\ninputs. However, currently only a small fraction of the abundant number of\nRoDiB outputs is utilized, thereby suggesting its potential for advanced\ncomputational power yet to be discovered.",
    "categories": [
      "physics.bio-ph",
      "cs.AI"
    ],
    "primary_category": "physics.bio-ph",
    "comment": "18 pages, 3 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.11384v1",
    "published_date": "2024-10-15 08:22:52 UTC",
    "updated_date": "2024-10-15 08:22:52 UTC"
  },
  {
    "arxiv_id": "2410.11381v1",
    "title": "Survey and Evaluation of Converging Architecture in LLMs based on Footsteps of Operations",
    "authors": [
      "Seongho Kim",
      "Jihyun Moon",
      "Juntaek Oh",
      "Insu Choi",
      "Joon-Sung Yang"
    ],
    "abstract": "The advent of the Attention mechanism and Transformer architecture enables\ncontextually natural text generation and compresses the burden of processing\nentire source information into singular vectors. Based on these two main ideas,\nmodel sizes gradually increases to accommodate more precise and comprehensive\ninformation, leading to the current state-of-the-art LLMs being very large,\nwith parameters around 70 billion. As the model sizes are growing, the demand\nfor substantial storage and computational capacity increases. This leads to the\ndevelopment of high-bandwidth memory and accelerators, as well as a variety of\nmodel architectures designed to meet these requirements. We note that LLM\narchitectures have increasingly converged. This paper analyzes how these\nconverged architectures perform in terms of layer configurations, operational\nmechanisms, and model sizes, considering various hyperparameter settings. In\nthis paper, we conduct a concise survey of the history of LLMs by tracing the\nevolution of their operational improvements. Furthermore, we summarize the\nperformance trends of LLMs under various hyperparameter settings using the RTX\n6000, which features the state-of-the-art Ada Lovelace architecture. We\nconclude that even the same model can exhibit different behaviors depending on\nthe hyperparameters or whether it is deployed in server or edge environments.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "68T50",
      "I.2.7"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages and 16 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.11381v1",
    "published_date": "2024-10-15 08:19:24 UTC",
    "updated_date": "2024-10-15 08:19:24 UTC"
  },
  {
    "arxiv_id": "2410.11378v1",
    "title": "WPFed: Web-based Personalized Federation for Decentralized Systems",
    "authors": [
      "Guanhua Ye",
      "Jifeng He",
      "Weiqing Wang",
      "Zhe Xue",
      "Feifei Kou",
      "Yawen Li"
    ],
    "abstract": "Decentralized learning has become crucial for collaborative model training in\nenvironments where data privacy and trust are paramount. In web-based\napplications, clients are liberated from traditional fixed network topologies,\nenabling the establishment of arbitrary peer-to-peer (P2P) connections. While\nthis flexibility is highly promising, it introduces a fundamental challenge:\nthe optimal selection of neighbors to ensure effective collaboration. To\naddress this, we introduce WPFed, a fully decentralized, web-based learning\nframework designed to enable globally optimal neighbor selection. WPFed employs\na dynamic communication graph and a weighted neighbor selection mechanism. By\nassessing inter-client similarity through Locality-Sensitive Hashing (LSH) and\nevaluating model quality based on peer rankings, WPFed enables clients to\nidentify personalized optimal neighbors on a global scale while preserving data\nprivacy. To enhance security and deter malicious behavior, WPFed integrates\nverification mechanisms for both LSH codes and performance rankings, leveraging\nblockchain-driven announcements to ensure transparency and verifiability.\nThrough extensive experiments on multiple real-world datasets, we demonstrate\nthat WPFed significantly improves learning outcomes and system robustness\ncompared to traditional federated learning methods. Our findings highlight\nWPFed's potential to facilitate effective and secure decentralized\ncollaborative learning across diverse and interconnected web environments.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11378v1",
    "published_date": "2024-10-15 08:17:42 UTC",
    "updated_date": "2024-10-15 08:17:42 UTC"
  },
  {
    "arxiv_id": "2410.11374v3",
    "title": "Preserve or Modify? Context-Aware Evaluation for Balancing Preservation and Modification in Text-Guided Image Editing",
    "authors": [
      "Yoonjeon Kim",
      "Soohyun Ryu",
      "Yeonsung Jung",
      "Hyunkoo Lee",
      "Joowon Kim",
      "June Yong Yang",
      "Jaeryong Hwang",
      "Eunho Yang"
    ],
    "abstract": "The development of vision-language and generative models has significantly\nadvanced text-guided image editing, which seeks the preservation of core\nelements in the source image while implementing modifications based on the\ntarget text. However, existing metrics have a context-blindness problem,\nindiscriminately applying the same evaluation criteria on completely different\npairs of source image and target text, biasing towards either modification or\npreservation. Directional CLIP similarity, the only metric that considers both\nsource image and target text, is also biased towards modification aspects and\nattends to irrelevant editing regions of the image. We propose AugCLIP, a\ncontext-aware metric that adaptively coordinates preservation and modification\naspects, depending on the specific context of a given source image and target\ntext. This is done by deriving the CLIP representation of an ideally edited\nimage, that preserves the source image with necessary modifications to align\nwith target text. More specifically, using a multi-modal large language model,\nAugCLIP augments the textual descriptions of the source and target, then\ncalculates a modification vector through a hyperplane that separates source and\ntarget attributes in CLIP space. Extensive experiments on five benchmark\ndatasets, encompassing a diverse range of editing scenarios, show that AugCLIP\naligns remarkably well with human evaluation standards, outperforming existing\nmetrics. The code is available at https://github.com/augclip/augclip_eval.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "accepted to CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.11374v3",
    "published_date": "2024-10-15 08:12:54 UTC",
    "updated_date": "2025-03-20 07:36:52 UTC"
  },
  {
    "arxiv_id": "2410.11355v1",
    "title": "Reducing Labeling Costs in Sentiment Analysis via Semi-Supervised Learning",
    "authors": [
      "Minoo Jafarlou",
      "Mario M. Kubek"
    ],
    "abstract": "Labeling datasets is a noteworthy challenge in machine learning, both in\nterms of cost and time. This research, however, leverages an efficient answer.\nBy exploring label propagation in semi-supervised learning, we can\nsignificantly reduce the number of labels required compared to traditional\nmethods. We employ a transductive label propagation method based on the\nmanifold assumption for text classification. Our approach utilizes a\ngraph-based method to generate pseudo-labels for unlabeled data for the text\nclassification task, which are then used to train deep neural networks. By\nextending labels based on cosine proximity within a nearest neighbor graph from\nnetwork embeddings, we combine unlabeled data into supervised learning, thereby\nreducing labeling costs. Based on previous successes in other domains, this\nstudy builds and evaluates this approach's effectiveness in sentiment analysis,\npresenting insights into semi-supervised learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.IR",
      "68T50, 68T07",
      "I.2.6; I.2.7; H.3.3"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, 7 figures, accepted at the 2024 8th International\n  Conference on Natural Language Processing and Information Retrieval (NLPIR\n  2024), Okayama, Japan, 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.11355v1",
    "published_date": "2024-10-15 07:25:33 UTC",
    "updated_date": "2024-10-15 07:25:33 UTC"
  },
  {
    "arxiv_id": "2410.11348v2",
    "title": "RATE: Causal Explainability of Reward Models with Imperfect Counterfactuals",
    "authors": [
      "David Reber",
      "Sean Richardson",
      "Todd Nief",
      "Cristina Garbacea",
      "Victor Veitch"
    ],
    "abstract": "Reward models are widely used as proxies for human preferences when aligning\nor evaluating LLMs. However, reward models are black boxes, and it is often\nunclear what, exactly, they are actually rewarding. In this paper we develop\nRewrite-based Attribute Treatment Estimator (RATE) as an effective method for\nmeasuring the sensitivity of a reward model to high-level attributes of\nresponses, such as sentiment, helpfulness, or complexity. Importantly, RATE\nmeasures the causal effect of an attribute on the reward. RATE uses LLMs to\nrewrite responses to produce imperfect counterfactual examples that can be used\nto measure causal effects. A key challenge is that these rewrites are imperfect\nin a manner that can induce substantial bias in the estimated sensitivity of\nthe reward model to the attribute. The core idea of RATE is to adjust for this\nimperfect-rewrite effect by rewriting twice. We establish the validity of the\nRATE procedure and show empirically that it is an effective estimator.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Code is available at https://github.com/toddnief/RATE",
    "pdf_url": "http://arxiv.org/pdf/2410.11348v2",
    "published_date": "2024-10-15 07:22:16 UTC",
    "updated_date": "2025-02-03 22:02:31 UTC"
  },
  {
    "arxiv_id": "2410.11338v1",
    "title": "DIAR: Diffusion-model-guided Implicit Q-learning with Adaptive Revaluation",
    "authors": [
      "Jaehyun Park",
      "Yunho Kim",
      "Sejin Kim",
      "Byung-Jun Lee",
      "Sundong Kim"
    ],
    "abstract": "We propose a novel offline reinforcement learning (offline RL) approach,\nintroducing the Diffusion-model-guided Implicit Q-learning with Adaptive\nRevaluation (DIAR) framework. We address two key challenges in offline RL:\nout-of-distribution samples and long-horizon problems. We leverage diffusion\nmodels to learn state-action sequence distributions and incorporate value\nfunctions for more balanced and adaptive decision-making. DIAR introduces an\nAdaptive Revaluation mechanism that dynamically adjusts decision lengths by\ncomparing current and future state values, enabling flexible long-term\ndecision-making. Furthermore, we address Q-value overestimation by combining\nQ-network learning with a value function guided by a diffusion model. The\ndiffusion model generates diverse latent trajectories, enhancing policy\nrobustness and generalization. As demonstrated in tasks like Maze2D, AntMaze,\nand Kitchen, DIAR consistently outperforms state-of-the-art algorithms in\nlong-horizon, sparse-reward environments.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "Preprint, under review. Comments welcome",
    "pdf_url": "http://arxiv.org/pdf/2410.11338v1",
    "published_date": "2024-10-15 07:09:56 UTC",
    "updated_date": "2024-10-15 07:09:56 UTC"
  },
  {
    "arxiv_id": "2410.11327v1",
    "title": "Sequential LLM Framework for Fashion Recommendation",
    "authors": [
      "Han Liu",
      "Xianfeng Tang",
      "Tianlang Chen",
      "Jiapeng Liu",
      "Indu Indu",
      "Henry Peng Zou",
      "Peng Dai",
      "Roberto Fernandez Galan",
      "Michael D Porter",
      "Dongmei Jia",
      "Ning Zhang",
      "Lian Xiong"
    ],
    "abstract": "The fashion industry is one of the leading domains in the global e-commerce\nsector, prompting major online retailers to employ recommendation systems for\nproduct suggestions and customer convenience. While recommendation systems have\nbeen widely studied, most are designed for general e-commerce problems and\nstruggle with the unique challenges of the fashion domain. To address these\nissues, we propose a sequential fashion recommendation framework that leverages\na pre-trained large language model (LLM) enhanced with recommendation-specific\nprompts. Our framework employs parameter-efficient fine-tuning with extensive\nfashion data and introduces a novel mix-up-based retrieval technique for\ntranslating text into relevant product suggestions. Extensive experiments show\nour proposed framework significantly enhances fashion recommendation\nperformance.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11327v1",
    "published_date": "2024-10-15 06:54:27 UTC",
    "updated_date": "2024-10-15 06:54:27 UTC"
  },
  {
    "arxiv_id": "2411.00003v4",
    "title": "Unsupervised Training of Diffusion Models for Feasible Solution Generation in Neural Combinatorial Optimization",
    "authors": [
      "Seong-Hyun Hong",
      "Hyun-Sung Kim",
      "Zian Jang",
      "Deunsol Yoon",
      "Hyungseok Song",
      "Byung-Jun Lee"
    ],
    "abstract": "Recent advancements in neural combinatorial optimization (NCO) methods have\nshown promising results in generating near-optimal solutions without the need\nfor expert-crafted heuristics. However, high performance of these approaches\noften rely on problem-specific human-expertise-based search after generating\ncandidate solutions, limiting their applicability to commonly solved CO\nproblems such as Traveling Salesman Problem (TSP). In this paper, we present\nIC/DC, an unsupervised CO framework that directly trains a diffusion model from\nscratch. We train our model in a self-supervised way to minimize the cost of\nthe solution while adhering to the problem-specific constraints. IC/DC is\nspecialized in addressing CO problems involving two distinct sets of items, and\nit does not need problem-specific search processes to generate valid solutions.\nIC/DC employs a novel architecture capable of capturing the intricate\nrelationships between items, and thereby enabling effective optimization in\nchallenging CO scenarios. IC/DC achieves state-of-the-art performance relative\nto existing NCO methods on the Parallel Machine Scheduling Problem (PMSP) and\nAsymmetric Traveling Salesman Problem (ATSP).",
    "categories": [
      "cs.AI",
      "cs.LG",
      "math.OC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00003v4",
    "published_date": "2024-10-15 06:53:30 UTC",
    "updated_date": "2025-02-12 11:47:03 UTC"
  },
  {
    "arxiv_id": "2410.11325v3",
    "title": "Speculative Knowledge Distillation: Bridging the Teacher-Student Gap Through Interleaved Sampling",
    "authors": [
      "Wenda Xu",
      "Rujun Han",
      "Zifeng Wang",
      "Long T. Le",
      "Dhruv Madeka",
      "Lei Li",
      "William Yang Wang",
      "Rishabh Agarwal",
      "Chen-Yu Lee",
      "Tomas Pfister"
    ],
    "abstract": "Recent advances in knowledge distillation (KD) have enabled smaller student\nmodels to approach the performance of larger teacher models. However, popular\nmethods such as supervised KD and on-policy KD, are adversely impacted by the\nknowledge gaps between teacher-student in practical scenarios. Supervised KD\nsuffers from a distribution mismatch between training with a static dataset and\ninference over final student-generated outputs. Conversely, on-policy KD, which\nuses student-generated samples for training, can suffer from low-quality\ntraining examples with which teacher models are not familiar, resulting in\ninaccurate teacher feedback. To address these limitations, we introduce\nSpeculative Knowledge Distillation (SKD), a novel approach that leverages\ncooperation between student and teacher models to generate high-quality\ntraining data on-the-fly while aligning with the student's inference-time\ndistribution. In SKD, the student proposes tokens, and the teacher replaces\npoorly ranked ones based on its own distribution, transferring high-quality\nknowledge adaptively. We evaluate SKD on various text generation tasks,\nincluding translation, summarization, math, and instruction following, and show\nthat SKD consistently outperforms existing KD methods across different domains,\ndata sizes, and model initialization strategies.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ICLR2025",
    "pdf_url": "http://arxiv.org/pdf/2410.11325v3",
    "published_date": "2024-10-15 06:51:25 UTC",
    "updated_date": "2025-04-27 23:18:29 UTC"
  },
  {
    "arxiv_id": "2410.11324v1",
    "title": "Diffusion-Based Offline RL for Improved Decision-Making in Augmented ARC Task",
    "authors": [
      "Yunho Kim",
      "Jaehyun Park",
      "Heejun Kim",
      "Sejin Kim",
      "Byung-Jun Lee",
      "Sundong Kim"
    ],
    "abstract": "Effective long-term strategies enable AI systems to navigate complex\nenvironments by making sequential decisions over extended horizons. Similarly,\nreinforcement learning (RL) agents optimize decisions across sequences to\nmaximize rewards, even without immediate feedback. To verify that Latent\nDiffusion-Constrained Q-learning (LDCQ), a prominent diffusion-based offline RL\nmethod, demonstrates strong reasoning abilities in multi-step decision-making,\nwe aimed to evaluate its performance on the Abstraction and Reasoning Corpus\n(ARC). However, applying offline RL methodologies to enhance strategic\nreasoning in AI for solving tasks in ARC is challenging due to the lack of\nsufficient experience data in the ARC training set. To address this limitation,\nwe introduce an augmented offline RL dataset for ARC, called Synthesized\nOffline Learning Data for Abstraction and Reasoning (SOLAR), along with the\nSOLAR-Generator, which generates diverse trajectory data based on predefined\nrules. SOLAR enables the application of offline RL methods by offering\nsufficient experience data. We synthesized SOLAR for a simple task and used it\nto train an agent with the LDCQ method. Our experiments demonstrate the\neffectiveness of the offline RL approach on a simple ARC task, showing the\nagent's ability to make multi-step sequential decisions and correctly identify\nanswer states. These results highlight the potential of the offline RL approach\nto enhance AI's strategic reasoning capabilities.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Preprint, Under review. Comments welcome",
    "pdf_url": "http://arxiv.org/pdf/2410.11324v1",
    "published_date": "2024-10-15 06:48:27 UTC",
    "updated_date": "2024-10-15 06:48:27 UTC"
  },
  {
    "arxiv_id": "2410.11312v1",
    "title": "Towards Differentiable Multilevel Optimization: A Gradient-Based Approach",
    "authors": [
      "Yuntian Gu",
      "Xuzheng Chen"
    ],
    "abstract": "Multilevel optimization has gained renewed interest in machine learning due\nto its promise in applications such as hyperparameter tuning and continual\nlearning. However, existing methods struggle with the inherent difficulty of\nefficiently handling the nested structure. This paper introduces a novel\ngradient-based approach for multilevel optimization that overcomes these\nlimitations by leveraging a hierarchically structured decomposition of the full\ngradient and employing advanced propagation techniques. Extending to n-level\nscenarios, our method significantly reduces computational complexity while\nimproving both solution accuracy and convergence speed. We demonstrate the\neffectiveness of our approach through numerical experiments, comparing it with\nexisting methods across several benchmarks. The results show a notable\nimprovement in solution accuracy. To the best of our knowledge, this is one of\nthe first algorithms to provide a general version of implicit differentiation\nwith both theoretical guarantees and superior empirical performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "18 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.11312v1",
    "published_date": "2024-10-15 06:17:59 UTC",
    "updated_date": "2024-10-15 06:17:59 UTC"
  },
  {
    "arxiv_id": "2410.11305v2",
    "title": "QSpec: Speculative Decoding with Complementary Quantization Schemes",
    "authors": [
      "Juntao Zhao",
      "Wenhao Lu",
      "Sheng Wang",
      "Lingpeng Kong",
      "Chuan Wu"
    ],
    "abstract": "Quantization has been substantially adopted to accelerate inference and\nreduce memory consumption of large language models (LLMs). While\nactivation-weight joint quantization speeds up the inference process through\nlow-precision kernels, we demonstrate that it suffers severe performance\ndegradation on multi-step reasoning tasks, rendering it ineffective. We propose\na novel quantization paradigm called QSPEC, which seamlessly integrates two\ncomplementary quantization schemes for speculative decoding. Leveraging nearly\ncost-free execution switching, QSPEC drafts tokens with low-precision, fast\nactivation-weight quantization, and verifies them with high-precision\nweight-only quantization, effectively combining the strengths of both\nquantization schemes. Compared to high-precision quantization methods, QSPEC\nempirically boosts token generation throughput by up to 1.64x without any\nquality compromise, distinguishing it from other low-precision quantization\napproaches. This enhancement is also consistent across various serving tasks,\nmodel sizes, quantization methods, and batch sizes. Compared to state-of-art\nspeculative decoding methods, our approach reuses weights and the KV cache,\navoiding extra memory overhead while achieving up to 1.55x speedup in batched\nserving with a high acceptance rate. Furthermore, QSPEC offers a plug-and-play\nadvantage without requiring any training. We believe that QSPEC demonstrates\nunique strengths for future deployment of high-fidelity quantization schemes,\nparticularly in memory-constrained scenarios (e.g., edge devices).",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11305v2",
    "published_date": "2024-10-15 05:57:51 UTC",
    "updated_date": "2025-02-01 04:24:16 UTC"
  },
  {
    "arxiv_id": "2410.11303v3",
    "title": "TSDS: Data Selection for Task-Specific Model Finetuning",
    "authors": [
      "Zifan Liu",
      "Amin Karbasi",
      "Theodoros Rekatsinas"
    ],
    "abstract": "Finetuning foundation models for specific tasks is an emerging paradigm in\nmodern machine learning. The efficacy of task-specific finetuning largely\ndepends on the selection of appropriate training data. We present TSDS\n(Task-Specific Data Selection), a framework to select data for task-specific\nmodel finetuning, guided by a small but representative set of examples from the\ntarget task. To do so, we formulate data selection for task-specific finetuning\nas an optimization problem with a distribution alignment loss based on optimal\ntransport to capture the discrepancy between the selected data and the target\ndistribution. In addition, we add a regularizer to encourage the diversity of\nthe selected data and incorporate kernel density estimation into the\nregularizer to reduce the negative effects of near-duplicates among the\ncandidate data. We connect our optimization problem to nearest neighbor search\nand design efficient algorithms to compute the optimal solution based on\napproximate nearest neighbor search techniques. We evaluate our method on data\nselection for both continued pretraining and instruction tuning of language\nmodels. We show that instruction tuning using data selected by our method with\na 1% selection ratio often outperforms using the full dataset and beats the\nbaseline selection methods by 1.5 points in F1 score on average.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "68T50, 68T01",
      "I.2.6; I.2.7"
    ],
    "primary_category": "cs.LG",
    "comment": "31 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2410.11303v3",
    "published_date": "2024-10-15 05:54:17 UTC",
    "updated_date": "2024-12-25 02:16:39 UTC"
  },
  {
    "arxiv_id": "2410.11302v1",
    "title": "Have the VLMs Lost Confidence? A Study of Sycophancy in VLMs",
    "authors": [
      "Shuo Li",
      "Tao Ji",
      "Xiaoran Fan",
      "Linsheng Lu",
      "Leyi Yang",
      "Yuming Yang",
      "Zhiheng Xi",
      "Rui Zheng",
      "Yuran Wang",
      "Xiaohui Zhao",
      "Tao Gui",
      "Qi Zhang",
      "Xuanjing Huang"
    ],
    "abstract": "In the study of LLMs, sycophancy represents a prevalent hallucination that\nposes significant challenges to these models. Specifically, LLMs often fail to\nadhere to original correct responses, instead blindly agreeing with users'\nopinions, even when those opinions are incorrect or malicious. However,\nresearch on sycophancy in visual language models (VLMs) has been scarce. In\nthis work, we extend the exploration of sycophancy from LLMs to VLMs,\nintroducing the MM-SY benchmark to evaluate this phenomenon. We present\nevaluation results from multiple representative models, addressing the gap in\nsycophancy research for VLMs. To mitigate sycophancy, we propose a synthetic\ndataset for training and employ methods based on prompts, supervised\nfine-tuning, and DPO. Our experiments demonstrate that these methods\neffectively alleviate sycophancy in VLMs. Additionally, we probe VLMs to assess\nthe semantic impact of sycophancy and analyze the attention distribution of\nvisual tokens. Our findings indicate that the ability to prevent sycophancy is\npredominantly observed in higher layers of the model. The lack of attention to\nimage knowledge in these higher layers may contribute to sycophancy, and\nenhancing image attention at high layers proves beneficial in mitigating this\nissue.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11302v1",
    "published_date": "2024-10-15 05:48:14 UTC",
    "updated_date": "2024-10-15 05:48:14 UTC"
  },
  {
    "arxiv_id": "2410.11298v2",
    "title": "Sorted Weight Sectioning for Energy-Efficient Unstructured Sparse DNNs on Compute-in-Memory Crossbars",
    "authors": [
      "Matheus Farias",
      "H. T. Kung"
    ],
    "abstract": "We introduce $\\textit{sorted weight sectioning}$ (SWS): a weight allocation\nalgorithm that places sorted deep neural network (DNN) weight sections on\nbit-sliced compute-in-memory (CIM) crossbars to reduce analog-to-digital\nconverter (ADC) energy consumption. Data conversions are the most\nenergy-intensive process in crossbar operation. SWS effectively reduces this\ncost leveraging (1) small weights and (2) zero weights (weight sparsity).\n  DNN weights follow bell-shaped distributions, with most weights near zero.\nUsing SWS, we only need low-order crossbar columns for sections with\nlow-magnitude weights. This reduces the quantity and resolution of ADCs used,\nexponentially decreasing ADC energy costs without significantly degrading DNN\naccuracy.\n  Unstructured sparsification further sharpens the weight distribution with\nsmall accuracy loss. However, it presents challenges in hardware tracking of\nzeros: we cannot switch zero rows to other layer weights in unsorted crossbars\nwithout index matching. SWS efficiently addresses unstructured sparse models\nusing offline remapping of zeros into earlier sections, which reveals full\nsparsity potential and maximizes energy efficiency.\n  Our method reduces ADC energy use by 89.5% on unstructured sparse BERT\nmodels. Overall, this paper introduces a novel algorithm to promote\nenergy-efficient CIM crossbars for unstructured sparse DNN workloads.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.ET",
      "cs.LG"
    ],
    "primary_category": "cs.AR",
    "comment": "5 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.11298v2",
    "published_date": "2024-10-15 05:37:16 UTC",
    "updated_date": "2024-10-29 04:39:50 UTC"
  },
  {
    "arxiv_id": "2410.11293v1",
    "title": "TraM : Enhancing User Sleep Prediction with Transformer-based Multivariate Time Series Modeling and Machine Learning Ensembles",
    "authors": [
      "Jinjae Kim",
      "Minjeong Ma",
      "Eunjee Choi",
      "Keunhee Cho",
      "Chanwoo Lee"
    ],
    "abstract": "This paper presents a novel approach that leverages Transformer-based\nmultivariate time series model and Machine Learning Ensembles to predict the\nquality of human sleep, emotional states, and stress levels. A formula to\ncalculate the labels was developed, and the various models were applied to user\ndata. Time Series Transformer was used for labels where time series\ncharacteristics are crucial, while Machine Learning Ensembles were employed for\nlabels requiring comprehensive daily activity statistics. Time Series\nTransformer excels in capturing the characteristics of time series through\npre-training, while Machine Learning Ensembles select machine learning models\nthat meet our categorization criteria. The proposed model, TraM, scored 6.10\nout of 10 in experiments, demonstrating superior performance compared to other\nmethodologies. The code and configuration for the TraM framework are available\nat: https://github.com/jin-jae/ETRI-Paper-Contest.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11293v1",
    "published_date": "2024-10-15 05:29:55 UTC",
    "updated_date": "2024-10-15 05:29:55 UTC"
  },
  {
    "arxiv_id": "2410.11911v2",
    "title": "Transfer Learning Adapts to Changing PSD in Gravitational Wave Data",
    "authors": [
      "Beka Modrekiladze"
    ],
    "abstract": "The detection of gravitational waves has opened unparalleled opportunities\nfor observing the universe, particularly through the study of black hole\ninspirals. These events serve as unique laboratories to explore the laws of\nphysics under conditions of extreme energies. However, significant noise in\ngravitational wave (GW) data from observatories such as Advanced LIGO and Virgo\nposes major challenges in signal identification. Traditional noise suppression\nmethods often fall short in fully addressing the non-Gaussian effects in the\ndata, including the fluctuations in noise power spectral density (PSD) over\nshort time intervals. These challenges have led to the exploration of an AI\napproach that, while overcoming previous obstacles, introduced its own\nchallenges, such as scalability, reliability issues, and the vanishing gradient\nproblem. Our approach addresses these issues through a simplified architecture.\nTo compensate for the potential limitations of a simpler model, we have\ndeveloped a novel training methodology that enables it to accurately detect\ngravitational waves amidst highly complex noise. Employing this strategy, our\nmodel achieves over 99% accuracy in non-white noise scenarios and shows\nremarkable adaptability to changing noise PSD conditions. By leveraging the\nprinciples of transfer learning, our model quickly adapts to new noise profiles\nwith just a few epochs of fine-tuning, facilitating real-time applications in\ndynamically changing noise environments.",
    "categories": [
      "gr-qc",
      "astro-ph.HE",
      "astro-ph.IM",
      "cs.AI"
    ],
    "primary_category": "gr-qc",
    "comment": "7 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.11911v2",
    "published_date": "2024-10-15 05:27:03 UTC",
    "updated_date": "2024-10-18 20:08:01 UTC"
  },
  {
    "arxiv_id": "2410.11291v2",
    "title": "Enhancing Assamese NLP Capabilities: Introducing a Centralized Dataset Repository",
    "authors": [
      "S. Tamang",
      "D. J. Bora"
    ],
    "abstract": "This paper introduces a centralized, open-source dataset repository designed\nto advance NLP and NMT for Assamese, a low-resource language. The repository,\navailable at GitHub, supports various tasks like sentiment analysis, named\nentity recognition, and machine translation by providing both pre-training and\nfine-tuning corpora. We review existing datasets, highlighting the need for\nstandardized resources in Assamese NLP, and discuss potential applications in\nAI-driven research, such as LLMs, OCR, and chatbots. While promising,\nchallenges like data scarcity and linguistic diversity remain. The repository\naims to foster collaboration and innovation, promoting Assamese language\nresearch in the digital age.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "6 pages, 1 table, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2410.11291v2",
    "published_date": "2024-10-15 05:26:57 UTC",
    "updated_date": "2024-10-16 06:25:57 UTC"
  },
  {
    "arxiv_id": "2410.11290v2",
    "title": "Backdoor Attack on Vertical Federated Graph Neural Network Learning",
    "authors": [
      "Jirui Yang",
      "Peng Chen",
      "Zhihui Lu",
      "Ruijun Deng",
      "Qiang Duan",
      "Jianping Zeng"
    ],
    "abstract": "Federated Graph Neural Network (FedGNN) integrate federated learning (FL)\nwith graph neural networks (GNNs) to enable privacy-preserving training on\ndistributed graph data. Vertical Federated Graph Neural Network (VFGNN), a key\nbranch of FedGNN, handles scenarios where data features and labels are\ndistributed among participants. Despite the robust privacy-preserving design of\nVFGNN, we have found that it still faces the risk of backdoor attacks, even in\nsituations where labels are inaccessible. This paper proposes BVG, a novel\nbackdoor attack method that leverages multi-hop triggers and backdoor\nretention, requiring only four target-class nodes to execute effective attacks.\nExperimental results demonstrate that BVG achieves nearly 100% attack success\nrates across three commonly used datasets and three GNN models, with minimal\nimpact on the main task accuracy. We also evaluated various defense methods,\nand the BVG method maintained high attack effectiveness even under existing\ndefenses. This finding highlights the need for advanced defense mechanisms to\ncounter sophisticated backdoor attacks in practical VFGNN applications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11290v2",
    "published_date": "2024-10-15 05:26:20 UTC",
    "updated_date": "2025-01-24 14:13:55 UTC"
  },
  {
    "arxiv_id": "2410.11287v2",
    "title": "Process Reward Model with Q-Value Rankings",
    "authors": [
      "Wendi Li",
      "Yixuan Li"
    ],
    "abstract": "Process Reward Modeling (PRM) is critical for complex reasoning and\ndecision-making tasks where the accuracy of intermediate steps significantly\ninfluences the overall outcome. Existing PRM approaches, primarily framed as\nclassification problems, employ cross-entropy loss to independently evaluate\neach step's correctness. This method can lead to suboptimal reward distribution\nand does not adequately address the interdependencies among steps. To address\nthese limitations, we introduce the Process Q-value Model (PQM), a novel\nframework that redefines PRM in the context of a Markov Decision Process. PQM\noptimizes Q-value rankings based on a novel comparative loss function,\nenhancing the model's ability to capture the intricate dynamics among\nsequential decisions. This approach provides a more granular and theoretically\ngrounded methodology for process rewards. Our extensive empirical evaluations\nacross various sampling policies, language model backbones, and multi-step\nreasoning benchmarks show that PQM outperforms classification-based PRMs. The\neffectiveness of the comparative loss function is highlighted in our\ncomprehensive ablation studies, confirming PQM's practical efficacy and\ntheoretical advantage.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11287v2",
    "published_date": "2024-10-15 05:10:34 UTC",
    "updated_date": "2025-02-11 05:41:41 UTC"
  },
  {
    "arxiv_id": "2410.11910v1",
    "title": "Explainable AI Methods for Multi-Omics Analysis: A Survey",
    "authors": [
      "Ahmad Hussein",
      "Mukesh Prasad",
      "Ali Braytee"
    ],
    "abstract": "Advancements in high-throughput technologies have led to a shift from\ntraditional hypothesis-driven methodologies to data-driven approaches.\nMulti-omics refers to the integrative analysis of data derived from multiple\n'omes', such as genomics, proteomics, transcriptomics, metabolomics, and\nmicrobiomics. This approach enables a comprehensive understanding of biological\nsystems by capturing different layers of biological information. Deep learning\nmethods are increasingly utilized to integrate multi-omics data, offering\ninsights into molecular interactions and enhancing research into complex\ndiseases. However, these models, with their numerous interconnected layers and\nnonlinear relationships, often function as black boxes, lacking transparency in\ndecision-making processes. To overcome this challenge, explainable artificial\nintelligence (xAI) methods are crucial for creating transparent models that\nallow clinicians to interpret and work with complex data more effectively. This\nreview explores how xAI can improve the interpretability of deep learning\nmodels in multi-omics research, highlighting its potential to provide\nclinicians with clear insights, thereby facilitating the effective application\nof such models in clinical settings.",
    "categories": [
      "q-bio.GN",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.GN",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11910v1",
    "published_date": "2024-10-15 05:01:17 UTC",
    "updated_date": "2024-10-15 05:01:17 UTC"
  },
  {
    "arxiv_id": "2410.11279v1",
    "title": "Advancing the Understanding of Fixed Point Iterations in Deep Neural Networks: A Detailed Analytical Study",
    "authors": [
      "Yekun Ke",
      "Xiaoyu Li",
      "Yingyu Liang",
      "Zhenmei Shi",
      "Zhao Song"
    ],
    "abstract": "Recent empirical studies have identified fixed point iteration phenomena in\ndeep neural networks, where the hidden state tends to stabilize after several\nlayers, showing minimal change in subsequent layers. This observation has\nspurred the development of practical methodologies, such as accelerating\ninference by bypassing certain layers once the hidden state stabilizes,\nselectively fine-tuning layers to modify the iteration process, and\nimplementing loops of specific layers to maintain fixed point iterations.\nDespite these advancements, the understanding of fixed point iterations remains\nsuperficial, particularly in high-dimensional spaces, due to the inadequacy of\ncurrent analytical tools. In this study, we conduct a detailed analysis of\nfixed point iterations in a vector-valued function modeled by neural networks.\nWe establish a sufficient condition for the existence of multiple fixed points\nof looped neural networks based on varying input regions. Additionally, we\nexpand our examination to include a robust version of fixed point iterations.\nTo demonstrate the effectiveness and insights provided by our approach, we\nprovide case studies that looped neural networks may exist $2^d$ number of\nrobust fixed points under exponentiation or polynomial activation functions,\nwhere $d$ is the feature dimension. Furthermore, our preliminary empirical\nresults support our theoretical findings. Our methodology enriches the toolkit\navailable for analyzing fixed point iterations of deep neural networks and may\nenhance our comprehension of neural network mechanisms.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "math.NA"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11279v1",
    "published_date": "2024-10-15 04:57:02 UTC",
    "updated_date": "2024-10-15 04:57:02 UTC"
  },
  {
    "arxiv_id": "2410.11276v1",
    "title": "ILAEDA: An Imitation Learning Based Approach for Automatic Exploratory Data Analysis",
    "authors": [
      "Abhijit Manatkar",
      "Devarsh Patel",
      "Hima Patel",
      "Naresh Manwani"
    ],
    "abstract": "Automating end-to-end Exploratory Data Analysis (AutoEDA) is a challenging\nopen problem, often tackled through Reinforcement Learning (RL) by learning to\npredict a sequence of analysis operations (FILTER, GROUP, etc). Defining\nrewards for each operation is a challenging task and existing methods rely on\nvarious \\emph{interestingness measures} to craft reward functions to capture\nthe importance of each operation. In this work, we argue that not all of the\nessential features of what makes an operation important can be accurately\ncaptured mathematically using rewards. We propose an AutoEDA model trained\nthrough imitation learning from expert EDA sessions, bypassing the need for\nmanually defined interestingness measures. Our method, based on generative\nadversarial imitation learning (GAIL), generalizes well across datasets, even\nwith limited expert data. We also introduce a novel approach for generating\nsynthetic EDA demonstrations for training. Our method outperforms the existing\nstate-of-the-art end-to-end EDA approach on benchmarks by upto 3x, showing\nstrong performance and generalization, while naturally capturing diverse\ninterestingness measures in generated EDA sessions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at AIMLSystems '24",
    "pdf_url": "http://arxiv.org/pdf/2410.11276v1",
    "published_date": "2024-10-15 04:56:13 UTC",
    "updated_date": "2024-10-15 04:56:13 UTC"
  },
  {
    "arxiv_id": "2410.11268v2",
    "title": "Bypassing the Exponential Dependency: Looped Transformers Efficiently Learn In-context by Multi-step Gradient Descent",
    "authors": [
      "Bo Chen",
      "Xiaoyu Li",
      "Yingyu Liang",
      "Zhenmei Shi",
      "Zhao Song"
    ],
    "abstract": "In-context learning has been recognized as a key factor in the success of\nLarge Language Models (LLMs). It refers to the model's ability to learn\npatterns on the fly from provided in-context examples in the prompt during\ninference. Previous studies have demonstrated that the Transformer architecture\nused in LLMs can implement a single-step gradient descent update by processing\nin-context examples in a single forward pass. Recent work has further shown\nthat, during in-context learning, a looped Transformer can implement multi-step\ngradient descent updates in forward passes. However, their theoretical results\nrequire an exponential number of in-context examples, $n = \\exp(\\Omega(T))$,\nwhere $T$ is the number of loops or passes, to achieve a reasonably low error.\nIn this paper, we study linear looped Transformers in-context learning on\nlinear vector generation tasks. We show that linear looped Transformers can\nimplement multi-step gradient descent efficiently for in-context learning. Our\nresults demonstrate that as long as the input data has a constant condition\nnumber, e.g., $n = O(d)$, the linear looped Transformers can achieve a small\nerror by multi-step gradient descent during in-context learning. Furthermore,\nour preliminary experiments validate our theoretical analysis. Our findings\nreveal that the Transformer architecture possesses a stronger in-context\nlearning capability than previously understood, offering new insights into the\nmechanisms behind LLMs and potentially guiding the better design of efficient\ninference algorithms for LLMs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "AIStats 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.11268v2",
    "published_date": "2024-10-15 04:44:23 UTC",
    "updated_date": "2025-02-28 22:12:33 UTC"
  },
  {
    "arxiv_id": "2410.11267v4",
    "title": "FedCCRL: Federated Domain Generalization with Cross-Client Representation Learning",
    "authors": [
      "Xinpeng Wang",
      "Yongxin Guo",
      "Xiaoying Tang"
    ],
    "abstract": "Domain Generalization (DG) aims to train models that can effectively\ngeneralize to unseen domains. However, in the context of Federated Learning\n(FL), where clients collaboratively train a model without directly sharing\ntheir data, most existing DG algorithms are not directly applicable to the FL\nsetting due to privacy constraints, as well as the limited data quantity and\ndomain diversity at each client. To tackle these challenges, we propose\nFedCCRL, a lightweight federated domain generalization method that\nsignificantly improves the model's generalization ability while preserving\nprivacy and ensuring computational and communication efficiency. Specifically,\nFedCCRL comprises two principal modules: the first is a cross-client feature\nextension module, which increases local domain diversity via cross-client\ndomain transfer and domain-invariant feature perturbation; the second is a\nrepresentation and prediction dual-stage alignment module, which enables the\nmodel to effectively capture domain-invariant features. Extensive experimental\nresults demonstrate that FedCCRL achieves the state-of-the-art performance on\nthe PACS, OfficeHome and miniDomainNet datasets across FL settings of varying\nnumbers of clients. Code is available at https://github.com/sanphouwang/fedccrl",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11267v4",
    "published_date": "2024-10-15 04:44:21 UTC",
    "updated_date": "2024-11-24 06:51:15 UTC"
  },
  {
    "arxiv_id": "2410.11265v1",
    "title": "In-Context Learning for Long-Context Sentiment Analysis on Infrastructure Project Opinions",
    "authors": [
      "Alireza Shamshiri",
      "Kyeong Rok Ryu",
      "June Young Park"
    ],
    "abstract": "Large language models (LLMs) have achieved impressive results across various\ntasks. However, they still struggle with long-context documents. This study\nevaluates the performance of three leading LLMs: GPT-4o, Claude 3.5 Sonnet, and\nGemini 1.5 Pro on lengthy, complex, and opinion-varying documents concerning\ninfrastructure projects, under both zero-shot and few-shot scenarios. Our\nresults indicate that GPT-4o excels in zero-shot scenarios for simpler, shorter\ndocuments, while Claude 3.5 Sonnet surpasses GPT-4o in handling more complex,\nsentiment-fluctuating opinions. In few-shot scenarios, Claude 3.5 Sonnet\noutperforms overall, while GPT-4o shows greater stability as the number of\ndemonstrations increases.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11265v1",
    "published_date": "2024-10-15 04:42:21 UTC",
    "updated_date": "2024-10-15 04:42:21 UTC"
  },
  {
    "arxiv_id": "2410.11262v1",
    "title": "Unveiling Options with Neural Decomposition",
    "authors": [
      "Mahdi Alikhasi",
      "Levi H. S. Lelis"
    ],
    "abstract": "In reinforcement learning, agents often learn policies for specific tasks\nwithout the ability to generalize this knowledge to related tasks. This paper\nintroduces an algorithm that attempts to address this limitation by decomposing\nneural networks encoding policies for Markov Decision Processes into reusable\nsub-policies, which are used to synthesize temporally extended actions, or\noptions. We consider neural networks with piecewise linear activation\nfunctions, so that they can be mapped to an equivalent tree that is similar to\noblique decision trees. Since each node in such a tree serves as a function of\nthe input of the tree, each sub-tree is a sub-policy of the main policy. We\nturn each of these sub-policies into options by wrapping it with while-loops of\nvaried number of iterations. Given the large number of options, we propose a\nselection mechanism based on minimizing the Levin loss for a uniform policy on\nthese options. Empirical results in two grid-world domains where exploration\ncan be difficult confirm that our method can identify useful options, thereby\naccelerating the learning process on similar but different tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Published as a conference paper at ICLR 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.11262v1",
    "published_date": "2024-10-15 04:36:44 UTC",
    "updated_date": "2024-10-15 04:36:44 UTC"
  },
  {
    "arxiv_id": "2410.11261v2",
    "title": "Beyond Linear Approximations: A Novel Pruning Approach for Attention Matrix",
    "authors": [
      "Yingyu Liang",
      "Jiangxuan Long",
      "Zhenmei Shi",
      "Zhao Song",
      "Yufa Zhou"
    ],
    "abstract": "Large Language Models (LLMs) have shown immense potential in enhancing\nvarious aspects of our daily lives, from conversational AI to search and AI\nassistants. However, their growing capabilities come at the cost of extremely\nlarge model sizes, making deployment on edge devices challenging due to memory\nand computational constraints. This paper introduces a novel approach to LLM\nweight pruning that directly optimizes for approximating the attention matrix,\na core component of transformer architectures. Unlike existing methods that\nfocus on linear approximations, our approach accounts for the non-linear nature\nof the Softmax attention mechanism. We provide theoretical guarantees for the\nconvergence of our Gradient Descent-based optimization method to a near-optimal\npruning mask solution. Our empirical results demonstrate the effectiveness of\nour non-linear pruning approach in maintaining model performance while\nsignificantly reducing computational costs, which is beyond the current\nstate-of-the-art methods, i.e., SparseGPT and Wanda, by a large margin. This\nwork establishes a new theoretical foundation for pruning algorithm design in\nLLMs, potentially paving the way for more efficient LLM inference on\nresource-constrained devices.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.11261v2",
    "published_date": "2024-10-15 04:35:56 UTC",
    "updated_date": "2025-02-26 18:44:29 UTC"
  },
  {
    "arxiv_id": "2410.11250v1",
    "title": "Learning Agents With Prioritization and Parameter Noise in Continuous State and Action Space",
    "authors": [
      "Rajesh Mangannavar",
      "Gopalakrishnan Srinivasaraghavan"
    ],
    "abstract": "Among the many variants of RL, an important class of problems is where the\nstate and action spaces are continuous -- autonomous robots, autonomous\nvehicles, optimal control are all examples of such problems that can lend\nthemselves naturally to reinforcement based algorithms, and have continuous\nstate and action spaces. In this paper, we introduce a prioritized form of a\ncombination of state-of-the-art approaches such as Deep Q-learning (DQN) and\nDeep Deterministic Policy Gradient (DDPG) to outperform the earlier results for\ncontinuous state and action space problems. Our experiments also involve the\nuse of parameter noise during training resulting in more robust deep RL models\noutperforming the earlier results significantly. We believe these results are a\nvaluable addition for continuous state and action space problems.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "I.2.6"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 3 figures. Published in Advances in Neural Networks - ISNN\n  2019",
    "pdf_url": "http://arxiv.org/pdf/2410.11250v1",
    "published_date": "2024-10-15 04:12:12 UTC",
    "updated_date": "2024-10-15 04:12:12 UTC"
  },
  {
    "arxiv_id": "2410.11242v1",
    "title": "Automatically Generating Visual Hallucination Test Cases for Multimodal Large Language Models",
    "authors": [
      "Zhongye Liu",
      "Hongbin Liu",
      "Yuepeng Hu",
      "Zedian Shao",
      "Neil Zhenqiang Gong"
    ],
    "abstract": "Visual hallucination (VH) occurs when a multimodal large language model\n(MLLM) generates responses with incorrect visual details for prompts. Existing\nmethods for generating VH test cases primarily rely on human annotations,\ntypically in the form of triples: (image, question, answer). In this paper, we\nintroduce VHExpansion, the first automated method for expanding VH test cases\nfor MLLMs. Given an initial VH test case, VHExpansion automatically expands it\nby perturbing the question and answer through negation as well as modifying the\nimage using both common and adversarial perturbations. Additionally, we propose\na new evaluation metric, symmetric accuracy, which measures the proportion of\ncorrectly answered VH test-case pairs. Each pair consists of a test case and\nits negated counterpart. Our theoretical analysis shows that symmetric accuracy\nis an unbiased evaluation metric that remains unaffected by the imbalance of VH\ntesting cases with varying answers when an MLLM is randomly guessing the\nanswers, whereas traditional accuracy is prone to such imbalance. We apply\nVHExpansion to expand three VH datasets annotated manually and use these\nexpanded datasets to benchmark seven MLLMs. Our evaluation shows that\nVHExpansion effectively identifies more VH test cases. Moreover, symmetric\naccuracy, being unbiased, leads to different conclusions about the\nvulnerability of MLLMs to VH compared to traditional accuracy metric. Finally,\nwe show that fine-tuning MLLMs on the expanded VH dataset generated by\nVHExpansion mitigates VH more effectively than fine-tuning on the original,\nmanually annotated dataset. Our code is available at:\nhttps://github.com/lycheeefish/VHExpansion.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11242v1",
    "published_date": "2024-10-15 03:56:16 UTC",
    "updated_date": "2024-10-15 03:56:16 UTC"
  },
  {
    "arxiv_id": "2410.11239v1",
    "title": "HR-Agent: A Task-Oriented Dialogue (TOD) LLM Agent Tailored for HR Applications",
    "authors": [
      "Weijie Xu",
      "Jay Desai",
      "Fanyou Wu",
      "Josef Valvoda",
      "Srinivasan H. Sengamedu"
    ],
    "abstract": "Recent LLM (Large Language Models) advancements benefit many fields such as\neducation and finance, but HR has hundreds of repetitive processes, such as\naccess requests, medical claim filing and time-off submissions, which are\nunaddressed. We relate these tasks to the LLM agent, which has addressed tasks\nsuch as writing assisting and customer support. We present HR-Agent, an\nefficient, confidential, and HR-specific LLM-based task-oriented dialogue\nsystem tailored for automating repetitive HR processes such as medical claims\nand access requests. Since conversation data is not sent to an LLM during\ninference, it preserves confidentiality required in HR-related tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T07",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11239v1",
    "published_date": "2024-10-15 03:51:08 UTC",
    "updated_date": "2024-10-15 03:51:08 UTC"
  },
  {
    "arxiv_id": "2410.11234v1",
    "title": "Bayes Adaptive Monte Carlo Tree Search for Offline Model-based Reinforcement Learning",
    "authors": [
      "Jiayu Chen",
      "Wentse Chen",
      "Jeff Schneider"
    ],
    "abstract": "Offline reinforcement learning (RL) is a powerful approach for data-driven\ndecision-making and control. Compared to model-free methods, offline\nmodel-based reinforcement learning (MBRL) explicitly learns world models from a\nstatic dataset and uses them as surrogate simulators, improving the data\nefficiency and enabling the learned policy to potentially generalize beyond the\ndataset support. However, there could be various MDPs that behave identically\non the offline dataset and so dealing with the uncertainty about the true MDP\ncan be challenging. In this paper, we propose modeling offline MBRL as a Bayes\nAdaptive Markov Decision Process (BAMDP), which is a principled framework for\naddressing model uncertainty. We further introduce a novel Bayes Adaptive\nMonte-Carlo planning algorithm capable of solving BAMDPs in continuous state\nand action spaces with stochastic transitions. This planning process is based\non Monte Carlo Tree Search and can be integrated into offline MBRL as a policy\nimprovement operator in policy iteration. Our ``RL + Search\" framework follows\nin the footsteps of superhuman AIs like AlphaZero, improving on current offline\nMBRL methods by incorporating more computation input. The proposed algorithm\nsignificantly outperforms state-of-the-art model-based and model-free offline\nRL methods on twelve D4RL MuJoCo benchmark tasks and three target tracking\ntasks in a challenging, stochastic tokamak control simulator.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11234v1",
    "published_date": "2024-10-15 03:36:43 UTC",
    "updated_date": "2024-10-15 03:36:43 UTC"
  },
  {
    "arxiv_id": "2410.11221v1",
    "title": "Multi-objective Reinforcement Learning: A Tool for Pluralistic Alignment",
    "authors": [
      "Peter Vamplew",
      "Conor F Hayes",
      "Cameron Foale",
      "Richard Dazeley",
      "Hadassah Harland"
    ],
    "abstract": "Reinforcement learning (RL) is a valuable tool for the creation of AI\nsystems. However it may be problematic to adequately align RL based on scalar\nrewards if there are multiple conflicting values or stakeholders to be\nconsidered. Over the last decade multi-objective reinforcement learning (MORL)\nusing vector rewards has emerged as an alternative to standard, scalar RL. This\npaper provides an overview of the role which MORL can play in creating\npluralistically-aligned AI.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted for the Pluralistic Alignment workshop at NeurIPS 2024.\n  https://pluralistic-alignment.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2410.11221v1",
    "published_date": "2024-10-15 03:06:13 UTC",
    "updated_date": "2024-10-15 03:06:13 UTC"
  },
  {
    "arxiv_id": "2410.11217v1",
    "title": "On the Capacity of Citation Generation by Large Language Models",
    "authors": [
      "Haosheng Qian",
      "Yixing Fan",
      "Ruqing Zhang",
      "Jiafeng Guo"
    ],
    "abstract": "Retrieval-augmented generation (RAG) appears as a promising method to\nalleviate the \"hallucination\" problem in large language models (LLMs), since it\ncan incorporate external traceable resources for response generation. The\nessence of RAG in combating the hallucination issue lies in accurately\nattributing claims in responses to the corresponding retrieved documents.\nHowever, most of existing works focus on improving the quality of generated\nresponses from the LLM, while largely overlooked its ability to attribute\nsources accurately. In this study, we conduct a systematic analysis about the\ncapabilities of LLMs in generating citations within response generation, and\nfurther introduce a novel method to enhance their citation generation\nabilities. Specifically, we evaluate both the correctness and citation quality\nfor seven widely-used LLMs on two benchmark datasets. Meanwhile, we introduce\nnew citation evaluation metrics to eliminate the over-penalization of\nunnecessary and excessive citations in existing metrics. Furthermore, we\npropose a Generate-then-Refine method that completes relevant citations and\nremoves irrelevant ones without altering the response text. The results on\nWebGLM-QA, ASQA and ELI5 datasets show that our method substantially improves\nthe quality of citations in responses generated by LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by CCIR 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.11217v1",
    "published_date": "2024-10-15 03:04:26 UTC",
    "updated_date": "2024-10-15 03:04:26 UTC"
  },
  {
    "arxiv_id": "2410.11908v1",
    "title": "ChatHouseDiffusion: Prompt-Guided Generation and Editing of Floor Plans",
    "authors": [
      "Sizhong Qin",
      "Chengyu He",
      "Qiaoyun Chen",
      "Sen Yang",
      "Wenjie Liao",
      "Yi Gu",
      "Xinzheng Lu"
    ],
    "abstract": "The generation and editing of floor plans are critical in architectural\nplanning, requiring a high degree of flexibility and efficiency. Existing\nmethods demand extensive input information and lack the capability for\ninteractive adaptation to user modifications. This paper introduces\nChatHouseDiffusion, which leverages large language models (LLMs) to interpret\nnatural language input, employs graphormer to encode topological relationships,\nand uses diffusion models to flexibly generate and edit floor plans. This\napproach allows iterative design adjustments based on user ideas, significantly\nenhancing design efficiency. Compared to existing models, ChatHouseDiffusion\nachieves higher Intersection over Union (IoU) scores, permitting precise,\nlocalized adjustments without the need for complete redesigns, thus offering\ngreater practicality. Experiments demonstrate that our model not only strictly\nadheres to user specifications but also facilitates a more intuitive design\nprocess through its interactive capabilities.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11908v1",
    "published_date": "2024-10-15 02:41:46 UTC",
    "updated_date": "2024-10-15 02:41:46 UTC"
  },
  {
    "arxiv_id": "2410.11201v2",
    "title": "Tree of Attributes Prompt Learning for Vision-Language Models",
    "authors": [
      "Tong Ding",
      "Wanhua Li",
      "Zhongqi Miao",
      "Hanspeter Pfister"
    ],
    "abstract": "Prompt learning has proven effective in adapting vision language models for\ndownstream tasks. However, existing methods usually append learnable prompt\ntokens solely with the category names to obtain textual features, which fails\nto fully leverage the rich context indicated in the category name. To address\nthis issue, we propose the Tree of Attributes Prompt learning (TAP), which\nfirst instructs LLMs to generate a tree of attributes with a \"concept -\nattribute - description\" structure for each category, and then learn the\nhierarchy with vision and text prompt tokens. Unlike existing methods that\nmerely augment category names with a set of unstructured descriptions, our\napproach essentially distills structured knowledge graphs associated with class\nnames from LLMs. Furthermore, our approach introduces text and vision prompts\ndesigned to explicitly learn the corresponding visual attributes, effectively\nserving as domain experts. Additionally, the general and diverse descriptions\ngenerated based on the class names may be wrong or absent in the specific given\nimages. To address this misalignment, we further introduce a vision-conditional\npooling module to extract instance-specific text features. Extensive\nexperimental results demonstrate that our approach outperforms state-of-the-art\nmethods on the zero-shot base-to-novel generalization, cross-dataset transfer,\nas well as few-shot classification across 11 diverse datasets. Code is\navailable at https://github.com/HHenryD/TAP.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11201v2",
    "published_date": "2024-10-15 02:37:39 UTC",
    "updated_date": "2025-04-21 15:37:50 UTC"
  },
  {
    "arxiv_id": "2410.11200v1",
    "title": "SplitSEE: A Splittable Self-supervised Framework for Single-Channel EEG Representation Learning",
    "authors": [
      "Rikuto Kotoge",
      "Zheng Chen",
      "Tasuku Kimura",
      "Yasuko Matsubara",
      "Takufumi Yanagisawa",
      "Haruhiko Kishima",
      "Yasushi Sakurai"
    ],
    "abstract": "While end-to-end multi-channel electroencephalography (EEG) learning\napproaches have shown significant promise, their applicability is often\nconstrained in neurological diagnostics, such as intracranial EEG resources.\nWhen provided with a single-channel EEG, how can we learn representations that\nare robust to multi-channels and scalable across varied tasks, such as seizure\nprediction? In this paper, we present SplitSEE, a structurally splittable\nframework designed for effective temporal-frequency representation learning in\nsingle-channel EEG. The key concept of SplitSEE is a self-supervised framework\nincorporating a deep clustering task. Given an EEG, we argue that the time and\nfrequency domains are two distinct perspectives, and hence, learned\nrepresentations should share the same cluster assignment. To this end, we first\npropose two domain-specific modules that independently learn domain-specific\nrepresentation and address the temporal-frequency tradeoff issue in\nconventional spectrogram-based methods. Then, we introduce a novel clustering\nloss to measure the information similarity. This encourages representations\nfrom both domains to coherently describe the same input by assigning them a\nconsistent cluster. SplitSEE leverages a pre-training-to-fine-tuning framework\nwithin a splittable architecture and has following properties: (a)\nEffectiveness: it learns representations solely from single-channel EEG but has\neven outperformed multi-channel baselines. (b) Robustness: it shows the\ncapacity to adapt across different channels with low performance variance.\nSuperior performance is also achieved with our collected clinical dataset. (c)\nScalability: With just one fine-tuning epoch, SplitSEE achieves high and stable\nperformance using partial model layers.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "This paper has been accepted by ICDM2024",
    "pdf_url": "http://arxiv.org/pdf/2410.11200v1",
    "published_date": "2024-10-15 02:34:33 UTC",
    "updated_date": "2024-10-15 02:34:33 UTC"
  },
  {
    "arxiv_id": "2410.11199v2",
    "title": "Isambard-AI: a leadership class supercomputer optimised specifically for Artificial Intelligence",
    "authors": [
      "Simon McIntosh-Smith",
      "Sadaf R Alam",
      "Christopher Woods"
    ],
    "abstract": "Isambard-AI is a new, leadership-class supercomputer, designed to support\nAI-related research. Based on the HPE Cray EX4000 system, and housed in a new,\nenergy efficient Modular Data Centre in Bristol, UK, Isambard-AI employs 5,448\nNVIDIA Grace-Hopper GPUs to deliver over 21 ExaFLOP/s of 8-bit floating point\nperformance for LLM training, and over 250 PetaFLOP/s of 64-bit performance,\nfor under 5MW. Isambard-AI integrates two, all-flash storage systems: a 20\nPiByte Cray ClusterStor and a 3.5 PiByte VAST solution. Combined these give\nIsambard-AI flexibility for training, inference and secure data accesses and\nsharing. But it is the software stack where Isambard-AI will be most different\nfrom traditional HPC systems. Isambard-AI is designed to support users who may\nhave been using GPUs in the cloud, and so access will more typically be via\nJupyter notebooks, MLOps, or other web-based, interactive interfaces, rather\nthan the approach used on traditional supercomputers of sshing into a system\nbefore submitting jobs to a batch scheduler. Its stack is designed to be\nquickly and regularly upgraded to keep pace with the rapid evolution of AI\nsoftware, with full support for containers. Phase 1 of Isambard-AI is due\nonline in May/June 2024, with the full system expected in production by the end\nof the year.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "11 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.11199v2",
    "published_date": "2024-10-15 02:34:26 UTC",
    "updated_date": "2024-11-04 12:47:31 UTC"
  },
  {
    "arxiv_id": "2410.11195v1",
    "title": "Athena: Retrieval-augmented Legal Judgment Prediction with Large Language Models",
    "authors": [
      "Xiao Peng",
      "Liang Chen"
    ],
    "abstract": "Recently, large language models (LLMs) like ChatGPT, LLaMA, and Claude have\nprevailed in countless domains, including legal scenarios. With LLMs' rapid\ntechnological progress, the development of prompt engineering (PE) as an\ninterface between the LLMs and real-world applications has drawn the attention\nof all developers. Various PE methods have been proposed to overcome real-world\nchallenges, such as few-shot prompting, chain-of-thought, and\nretrieval-augmented generation (RAG). However, RAG for legal judgment\nprediction (LJP) is still underexplored. To address this, we propose \"Athena\",\na novel framework cultivating RAG as a core preprocess component to enhance\nLLMs' performance on specialized tasks. Athena constructs a knowledge base for\naccusations, attached with a semantic retrieval mechanism through\nvectorization. Our experiments show that Athena's overall performance has\nimproved significantly, achieving state-of-the-art results on the CAIL2018\ndataset. Our ablation study on the in-context window size parameter further\nreproduces LLMs' \"lost-in-the-middle\" phenomenon with a relative positional\nvariation. And with moderate hyper-parameter-tuning, we can achieve at most 95%\nof accuracy accordingly. We also study the impact of query rewriting and data\ndistribution, providing possible directions for future research based on former\nanalyses.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "13 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.11195v1",
    "published_date": "2024-10-15 02:18:01 UTC",
    "updated_date": "2024-10-15 02:18:01 UTC"
  },
  {
    "arxiv_id": "2410.11906v1",
    "title": "Empowering Users in Digital Privacy Management through Interactive LLM-Based Agents",
    "authors": [
      "Bolun Sun",
      "Yifan Zhou",
      "Haiyun Jiang"
    ],
    "abstract": "This paper presents a novel application of large language models (LLMs) to\nenhance user comprehension of privacy policies through an interactive dialogue\nagent. We demonstrate that LLMs significantly outperform traditional models in\ntasks like Data Practice Identification, Choice Identification, Policy\nSummarization, and Privacy Question Answering, setting new benchmarks in\nprivacy policy analysis. Building on these findings, we introduce an innovative\nLLM-based agent that functions as an expert system for processing website\nprivacy policies, guiding users through complex legal language without\nrequiring them to pose specific questions. A user study with 100 participants\nshowed that users assisted by the agent had higher comprehension levels (mean\nscore of 2.6 out of 3 vs. 1.8 in the control group), reduced cognitive load\n(task difficulty ratings of 3.2 out of 10 vs. 7.8), increased confidence in\nmanaging privacy, and completed tasks in less time (5.5 minutes vs. 15.8\nminutes). This work highlights the potential of LLM-based agents to transform\nuser interaction with privacy policies, leading to more informed consent and\nempowering users in the digital services landscape.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11906v1",
    "published_date": "2024-10-15 02:16:59 UTC",
    "updated_date": "2024-10-15 02:16:59 UTC"
  },
  {
    "arxiv_id": "2410.11190v3",
    "title": "Mini-Omni2: Towards Open-source GPT-4o with Vision, Speech and Duplex Capabilities",
    "authors": [
      "Zhifei Xie",
      "Changqiao Wu"
    ],
    "abstract": "GPT-4o, an all-encompassing model, represents a milestone in the development\nof large multi-modal language models. It can understand visual, auditory, and\ntextual modalities, directly output audio, and support flexible duplex\ninteraction. Models from the open-source community often achieve some\nfunctionalities of GPT-4o, such as visual understanding and voice chat.\nNevertheless, training a unified model that incorporates all modalities is\nchallenging due to the complexities of multi-modal data, intricate model\narchitectures, and training processes. In this paper, we introduce Mini-Omni2,\na visual-audio assistant capable of providing real-time, end-to-end voice\nresponses to visoin and audio queries. By integrating pretrained visual and\nauditory encoders, Mini-Omni2 maintains performance in individual modalities.\nWe propose a three-stage training process to align modalities, allowing the\nlanguage model to handle multi-modal inputs and outputs after training on a\nlimited dataset. For interaction, we introduce a command-based interruption\nmechanism, enabling more flexible interaction with users. To the best of our\nknowledge, Mini-Omni2 is one of the closest reproductions of GPT-4o, which have\nsimilar form of functionality, and we hope it can offer valuable insights for\nsubsequent research.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "Technical report, work in progress. Demo and code:\n  https://github.com/gpt-omni/mini-omni2",
    "pdf_url": "http://arxiv.org/pdf/2410.11190v3",
    "published_date": "2024-10-15 02:10:45 UTC",
    "updated_date": "2024-11-05 02:27:57 UTC"
  },
  {
    "arxiv_id": "2410.11182v2",
    "title": "Position: On-Premises LLM Deployment Demands a Middle Path: Preserving Privacy Without Sacrificing Model Confidentiality",
    "authors": [
      "Hanbo Huang",
      "Yihan Li",
      "Bowen Jiang",
      "Lin Liu",
      "Bo Jiang",
      "Ruoyu Sun",
      "Zhuotao Liu",
      "Shiyu Liang"
    ],
    "abstract": "Current LLM customization typically relies on two deployment strategies:\nclosed-source APIs, which require users to upload private data to external\nservers, and open-weight models, which allow local fine-tuning but pose misuse\nrisks. In this position paper, we argue that (1) deploying closed-source LLMs\nwithin user-controlled infrastructure (\\textit{on-premises deployment})\nenhances data privacy and mitigates misuse risks, and (2) a well-designed\non-premises deployment must ensure model confidentiality -- by preventing model\ntheft -- and offer privacy-preserving customization. Prior research on small\nmodels has explored securing only the output layer within hardware-secured\ndevices to balance confidentiality and customization efficiency. However, we\nshow that this approach is insufficient for defending large-scale LLMs against\ndistillation attacks. We therefore introduce a {semi-open deployment framework}\nthat secures only a few, carefully chosen layers, achieving distillation\nresistance comparable to fully secured models while preserving fine-tuning\nflexibility. Through extensive experiments, we show that securing bottom layers\nsignificantly reduces functional extraction risks. Our findings demonstrate\nthat privacy and confidentiality can coexist, paving the way for secure\non-premises AI deployment that balances usability and protection.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages for main content of the paper",
    "pdf_url": "http://arxiv.org/pdf/2410.11182v2",
    "published_date": "2024-10-15 02:00:36 UTC",
    "updated_date": "2025-01-31 14:36:14 UTC"
  },
  {
    "arxiv_id": "2410.11181v2",
    "title": "DARNet: Dual Attention Refinement Network with Spatiotemporal Construction for Auditory Attention Detection",
    "authors": [
      "Sheng Yan",
      "Cunhang fan",
      "Hongyu Zhang",
      "Xiaoke Yang",
      "Jianhua Tao",
      "Zhao Lv"
    ],
    "abstract": "At a cocktail party, humans exhibit an impressive ability to direct their\nattention. The auditory attention detection (AAD) approach seeks to identify\nthe attended speaker by analyzing brain signals, such as EEG signals. However,\ncurrent AAD algorithms overlook the spatial distribution information within EEG\nsignals and lack the ability to capture long-range latent dependencies,\nlimiting the model's ability to decode brain activity. To address these issues,\nthis paper proposes a dual attention refinement network with spatiotemporal\nconstruction for AAD, named DARNet, which consists of the spatiotemporal\nconstruction module, dual attention refinement module, and feature fusion \\&\nclassifier module. Specifically, the spatiotemporal construction module aims to\nconstruct more expressive spatiotemporal feature representations, by capturing\nthe spatial distribution characteristics of EEG signals. The dual attention\nrefinement module aims to extract different levels of temporal patterns in EEG\nsignals and enhance the model's ability to capture long-range latent\ndependencies. The feature fusion \\& classifier module aims to aggregate\ntemporal patterns and dependencies from different levels and obtain the final\nclassification results. The experimental results indicate that compared to the\nstate-of-the-art models, DARNet achieves an average classification accuracy\nimprovement of 5.9\\% for 0.1s, 4.6\\% for 1s, and 3.9\\% for 2s on the DTU\ndataset. While maintaining excellent classification performance, DARNet\nsignificantly reduces the number of required parameters. Compared to the\nstate-of-the-art models, DARNet reduces the parameter count by 91\\%. Code is\navailable at: https://github.com/fchest/DARNet.git.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.LG",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11181v2",
    "published_date": "2024-10-15 01:51:29 UTC",
    "updated_date": "2024-11-18 16:25:53 UTC"
  },
  {
    "arxiv_id": "2410.11179v1",
    "title": "Interpretability as Compression: Reconsidering SAE Explanations of Neural Activations with MDL-SAEs",
    "authors": [
      "Kola Ayonrinde",
      "Michael T. Pearce",
      "Lee Sharkey"
    ],
    "abstract": "Sparse Autoencoders (SAEs) have emerged as a useful tool for interpreting the\ninternal representations of neural networks. However, naively optimising SAEs\nfor reconstruction loss and sparsity results in a preference for SAEs that are\nextremely wide and sparse. We present an information-theoretic framework for\ninterpreting SAEs as lossy compression algorithms for communicating\nexplanations of neural activations. We appeal to the Minimal Description Length\n(MDL) principle to motivate explanations of activations which are both accurate\nand concise. We further argue that interpretable SAEs require an additional\nproperty, \"independent additivity\": features should be able to be understood\nseparately. We demonstrate an example of applying our MDL-inspired framework by\ntraining SAEs on MNIST handwritten digits and find that SAE features\nrepresenting significant line segments are optimal, as opposed to SAEs with\nfeatures for memorised digits from the dataset or small digit fragments. We\nargue that using MDL rather than sparsity may avoid potential pitfalls with\nnaively maximising sparsity such as undesirable feature splitting and that this\nframework naturally suggests new hierarchical SAE architectures which provide\nmore concise explanations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.11179v1",
    "published_date": "2024-10-15 01:38:03 UTC",
    "updated_date": "2024-10-15 01:38:03 UTC"
  },
  {
    "arxiv_id": "2410.11176v1",
    "title": "Improving Bias in Facial Attribute Classification: A Combined Impact of KL Divergence induced Loss Function and Dual Attention",
    "authors": [
      "Shweta Patel",
      "Dakshina Ranjan Kisku"
    ],
    "abstract": "Ensuring that AI-based facial recognition systems produce fair predictions\nand work equally well across all demographic groups is crucial. Earlier systems\noften exhibited demographic bias, particularly in gender and racial\nclassification, with lower accuracy for women and individuals with darker skin\ntones. To tackle this issue and promote fairness in facial recognition,\nresearchers have introduced several bias-mitigation techniques for gender\nclassification and related algorithms. However, many challenges remain, such as\ndata diversity, balancing fairness with accuracy, disparity, and bias\nmeasurement. This paper presents a method using a dual attention mechanism with\na pre-trained Inception-ResNet V1 model, enhanced by KL-divergence\nregularization and a cross-entropy loss function. This approach reduces bias\nwhile improving accuracy and computational efficiency through transfer\nlearning. The experimental results show significant improvements in both\nfairness and classification accuracy, providing promising advances in\naddressing bias and enhancing the reliability of facial recognition systems.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "68T06",
      "I.2.10"
    ],
    "primary_category": "cs.CV",
    "comment": "15 pages, 9 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.11176v1",
    "published_date": "2024-10-15 01:29:09 UTC",
    "updated_date": "2024-10-15 01:29:09 UTC"
  },
  {
    "arxiv_id": "2410.11162v1",
    "title": "Towards General Deepfake Detection with Dynamic Curriculum",
    "authors": [
      "Wentang Song",
      "Yuzhen Lin",
      "Bin Li"
    ],
    "abstract": "Most previous deepfake detection methods bent their efforts to discriminate\nartifacts by end-to-end training. However, the learned networks often fail to\nmine the general face forgery information efficiently due to ignoring the data\nhardness. In this work, we propose to introduce the sample hardness into the\ntraining of deepfake detectors via the curriculum learning paradigm.\nSpecifically, we present a novel simple yet effective strategy, named Dynamic\nFacial Forensic Curriculum (DFFC), which makes the model gradually focus on\nhard samples during the training. Firstly, we propose Dynamic Forensic Hardness\n(DFH) which integrates the facial quality score and instantaneous instance loss\nto dynamically measure sample hardness during the training. Furthermore, we\npresent a pacing function to control the data subsets from easy to hard\nthroughout the training process based on DFH. Comprehensive experiments show\nthat DFFC can improve both within- and cross-dataset performance of various\nkinds of end-to-end deepfake detectors through a plug-and-play approach. It\nindicates that DFFC can help deepfake detectors learn general forgery\ndiscriminative features by effectively exploiting the information from hard\nsamples.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Received by ICASSP 2024 - 2024 IEEE International Conference on\n  Acoustics, Speech and Signal Processing (ICASSP)",
    "pdf_url": "http://arxiv.org/pdf/2410.11162v1",
    "published_date": "2024-10-15 00:58:09 UTC",
    "updated_date": "2024-10-15 00:58:09 UTC"
  },
  {
    "arxiv_id": "2410.22349v1",
    "title": "Search Engines in an AI Era: The False Promise of Factual and Verifiable Source-Cited Responses",
    "authors": [
      "Pranav Narayanan Venkit",
      "Philippe Laban",
      "Yilun Zhou",
      "Yixin Mao",
      "Chien-Sheng Wu"
    ],
    "abstract": "Large Language Model (LLM)-based applications are graduating from research\nprototypes to products serving millions of users, influencing how people write\nand consume information. A prominent example is the appearance of Answer\nEngines: LLM-based generative search engines supplanting traditional search\nengines. Answer engines not only retrieve relevant sources to a user query but\nsynthesize answer summaries that cite the sources. To understand these systems'\nlimitations, we first conducted a study with 21 participants, evaluating\ninteractions with answer vs. traditional search engines and identifying 16\nanswer engine limitations. From these insights, we propose 16 answer engine\ndesign recommendations, linked to 8 metrics. An automated evaluation\nimplementing our metrics on three popular engines (You.com, Perplexity.ai,\nBingChat) quantifies common limitations (e.g., frequent hallucination,\ninaccurate citation) and unique features (e.g., variation in answer\nconfidence), with results mirroring user study insights. We release our Answer\nEngine Evaluation benchmark (AEE) to facilitate transparent evaluation of\nLLM-based applications.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.22349v1",
    "published_date": "2024-10-15 00:50:31 UTC",
    "updated_date": "2024-10-15 00:50:31 UTC"
  },
  {
    "arxiv_id": "2410.11155v1",
    "title": "Latent-Predictive Empowerment: Measuring Empowerment without a Simulator",
    "authors": [
      "Andrew Levy",
      "Alessandro Allievi",
      "George Konidaris"
    ],
    "abstract": "Empowerment has the potential to help agents learn large skillsets, but is\nnot yet a scalable solution for training general-purpose agents. Recent\nempowerment methods learn diverse skillsets by maximizing the mutual\ninformation between skills and states; however, these approaches require a\nmodel of the transition dynamics, which can be challenging to learn in\nrealistic settings with high-dimensional and stochastic observations. We\npresent Latent-Predictive Empowerment (LPE), an algorithm that can compute\nempowerment in a more practical manner. LPE learns large skillsets by\nmaximizing an objective that is a principled replacement for the mutual\ninformation between skills and states and that only requires a simpler\nlatent-predictive model rather than a full simulator of the environment. We\nshow empirically in a variety of settings--including ones with high-dimensional\nobservations and highly stochastic transition dynamics--that our empowerment\nobjective (i) learns similar-sized skillsets as the leading empowerment\nalgorithm that assumes access to a model of the transition dynamics and (ii)\noutperforms other model-based approaches to empowerment.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11155v1",
    "published_date": "2024-10-15 00:41:18 UTC",
    "updated_date": "2024-10-15 00:41:18 UTC"
  },
  {
    "arxiv_id": "2410.11150v1",
    "title": "Optimizing Encoder-Only Transformers for Session-Based Recommendation Systems",
    "authors": [
      "Anis Redjdal",
      "Luis Pinto",
      "Michel Desmarais"
    ],
    "abstract": "Session-based recommendation is the task of predicting the next item a user\nwill interact with, often without access to historical user data. In this work,\nwe introduce Sequential Masked Modeling, a novel approach for encoder-only\ntransformer architectures to tackle the challenges of single-session\nrecommendation. Our method combines data augmentation through window sliding\nwith a unique penultimate token masking strategy to capture sequential\ndependencies more effectively. By enhancing how transformers handle session\ndata, Sequential Masked Modeling significantly improves next-item prediction\nperformance.\n  We evaluate our approach on three widely-used datasets, Yoochoose 1/64,\nDiginetica, and Tmall, comparing it to state-of-the-art single-session,\ncross-session, and multi-relation approaches. The results demonstrate that our\nTransformer-SMM models consistently outperform all models that rely on the same\namount of information, while even rivaling methods that have access to more\nextensive user history. This study highlights the potential of encoder-only\ntransformers in session-based recommendation and opens the door for further\nimprovements.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.11150v1",
    "published_date": "2024-10-15 00:23:18 UTC",
    "updated_date": "2024-10-15 00:23:18 UTC"
  }
]