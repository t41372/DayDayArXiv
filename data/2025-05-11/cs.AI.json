{
  "date": "2025-05-11",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-05-11 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 模型的优化、安全应用、机器人学习和医疗预测等领域，亮点包括 LLM 在跨领域任务中的创新应用（如机器人和医疗决策）、知名学者如 John E. Laird 的 AGI 架构探讨，以及多模态模型如 Seed1.5-VL 的技术报告，这些工作强调了 AI 的泛化性和实际部署潜力。令人印象深刻的是，X-Sim 和 Seed1.5-VL 等论文展示了 AI 在复杂环境中的高效学习和推理能力。\n\n下面，我挑选并简要讨论几篇关键论文，先从重要性和话题度高的入手，再快速掠过其他相关但不那么核心的文章。重点放在 AI 安全、机器人和医疗领域的创新，其他论文则简要概述以控制篇幅。\n\n### 重点论文讨论\n\n1. **X-Sim: Cross-Embodiment Learning via Real-to-Sim-to-Real (X-Sim: 通过实-仿-实跨实体学习)**  \n   这篇论文由 Prithwish Dan 等作者提出，聚焦机器人操作学习。核心贡献是提出 X-Sim 框架，利用物体运动作为密集信号，从 RGBD 视频重建仿真环境，并通过强化学习（RL）训练策略，然后用扩散模型微调以适应真实世界。发现显示，X-Sim 在 5 个操作任务中平均提升 30% 的任务进度，且无需机器人数据，支持跨视角泛化。该工作有话题度，因为它解决了机器人学习中的实体差异问题，作者团队包括知名学者如 Sanjiban Choudhury。\n\n2. **Seed1.5-VL Technical Report (Seed1.5-VL 技术报告)**  \n   作者团队庞大，包括 Dong Guo 等多位研究者。论文介绍了一个多模态视觉语言模型 Seed1.5-VL，包含 532M 参数的视觉编码器和 20B 参数的混合专家 LLM。主要发现是，该模型在 60 个基准中领先 38 个，并在代理任务（如 GUI 控制）中超越 OpenAI CUA 和 Claude 3.7。该报告强调模型设计、数据构建和训练阶段的优化，具有实际部署潜力，是 LLM 领域的重要进展。\n\n3. **Architectural Precedents for General Agents using Large Language Models (使用大型语言模型的通用代理架构先例)**  \n   由 Robert E. Wray 和 John E. Laird 等知名学者撰写。论文分析了认知架构模式在 LLM 中的应用，核心贡献是总结重复出现的认知设计模式（如推理和交互），并预测 LLM 代理系统的不足（如推理空白）。发现显示，这些模式可指导未来 AGI 研究。该工作有影响力，因为 Laird 等学者长期从事 AGI 相关工作。\n\n4. **RefPentester: A Knowledge-Informed Self-Reflective Penetration Testing Framework Based on Large Language Models (RefPentester: 基于大型语言模型的知识驱动自反渗透测试框架)**  \n   作者 Hanzheng Dai 等。论文提出 RefPentester 框架，解决 LLM 在渗透测试中的局限，如幻觉和短视规划。核心贡献是建模七状态机，支持自学习和阶段转换，实验显示其成功率比 GPT-4o 高 16.7%。该工作在 AI 安全领域有话题度，强调伦理和人类监督。\n\n接下来，快速聊聊相关论文，将 AI 和机器人主题归纳在一起：\n\n5. **Evaluating Reasoning LLMs for Suicide Screening with the Columbia-Suicide Severity Rating Scale (使用哥伦比亚自杀严重程度量表评估推理大型语言模型的自杀筛查能力)**  \n   作者 Avinash Patil 等。贡献在于评估 6 个 LLM（如 Claude 和 GPT）在自杀风险分类中的表现，发现 Claude 和 GPT 与人工标注最接近。该研究突出了 LLM 在公共健康中的潜力，但强调了伦理监督。\n\n6. **DialogueReason: Rule-Based RL Sparks Dialogue Reasoning in LLMs (DialogueReason: 基于规则的强化学习激发 LLM 的对话推理)**  \n   作者 Yubo Shu 等。论文引入对话式推理框架，使用 PPO 训练 LLM 处理复杂问题，实验显示在 MATH 和 AIME 数据集上优于单 monologue 模型。该工作提升了 LLM 的多样性和连贯性。\n\n7. **Can LLM-based Financial Investing Strategies Outperform the Market in Long Run? (基于 LLM 的财务投资策略能否长期超越市场？)**  \n   作者 Weixian Waylon Li 等。核心发现是 LLM 策略在熊市过度激进、在牛市过度保守，需加强趋势检测。该论文质疑 LLM 在金融中的泛化，提供了实际启示。\n\n对于机器人和医疗主题的剩余论文，简要掠过：\n\n- **Towards Scalable IoT Deployment for Visual Anomaly Detection via Efficient Compression (通过高效压缩实现可扩展 IoT 视觉异常检测部署)**：优化 IoT 边缘计算，实验显示减少 80% 推理时间，贡献在于平衡延迟和准确性。\n\n- **Predicting Diabetes Using Machine Learning: A Comparative Study of Classifiers (使用机器学习预测糖尿病：分类器的比较研究)**：提出 DNet 混合模型，准确率达 99.79%，但作为比较实验，影响较小。\n\n其他论文如量子计算、XAI 调查或特定领域优化（如 Efficient Fault Detection in WSN），虽有技术贡献（如 PCA 优化 DNN），但主题较窄或无明显话题度，故仅快速提及：这些工作探索了 AI 在 WSN 故障检测和 XAI 应用中的效率，但未有突破性发现。\n\n总之，今天的 arXiv 展示了 AI 向泛化智能的迈进，X-Sim 和 Seed1.5-VL 等论文值得关注。更多细节可查阅 arXiv。明天的快报见！",
  "papers": [
    {
      "arxiv_id": "2505.13480v1",
      "title": "Evaluating Reasoning LLMs for Suicide Screening with the Columbia-Suicide Severity Rating Scale",
      "title_zh": "翻译失败",
      "authors": [
        "Avinash Patil",
        "Siru Tao",
        "Amardeep Gedhu"
      ],
      "abstract": "Suicide prevention remains a critical public health challenge. While online\nplatforms such as Reddit's r/SuicideWatch have historically provided spaces for\nindividuals to express suicidal thoughts and seek community support, the advent\nof large language models (LLMs) introduces a new paradigm-where individuals may\nbegin disclosing ideation to AI systems instead of humans. This study evaluates\nthe capability of LLMs to perform automated suicide risk assessment using the\nColumbia-Suicide Severity Rating Scale (C-SSRS). We assess the zero-shot\nperformance of six models-including Claude, GPT, Mistral, and LLaMA-in\nclassifying posts across a 7-point severity scale (Levels 0-6). Results\nindicate that Claude and GPT closely align with human annotations, while\nMistral achieves the lowest ordinal prediction error. Most models exhibit\nordinal sensitivity, with misclassifications typically occurring between\nadjacent severity levels. We further analyze confusion patterns,\nmisclassification sources, and ethical considerations, underscoring the\nimportance of human oversight, transparency, and cautious deployment. Full code\nand supplementary materials are available at\nhttps://github.com/av9ash/llm_cssrs_code.",
      "tldr_zh": "本研究评估了大型语言模型（LLMs）在自杀风险筛查中的性能，使用 Columbia-Suicide Severity Rating Scale (C-SSRS) 对 Reddit 帖子进行 7 点严重度（Levels 0-6）分类。研究测试了六种模型（包括 Claude、GPT、Mistral 和 LLaMA）的零样本性能，结果显示 Claude 和 GPT 与人类标注最接近，而 Mistral 具有最低的顺序预测错误，大多数模型的误分类发生在相邻级别。作者进一步分析了混淆模式、错误来源以及伦理问题，如人类监督的必要性、透明度和谨慎部署，以确保 LLMs 在自杀预防中的安全应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "8 Pages, 6 Figures, 1 Table",
      "pdf_url": "http://arxiv.org/pdf/2505.13480v1",
      "published_date": "2025-05-11 23:55:27 UTC",
      "updated_date": "2025-05-11 23:55:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:40:36.156212"
    },
    {
      "arxiv_id": "2505.07119v2",
      "title": "Towards Scalable IoT Deployment for Visual Anomaly Detection via Efficient Compression",
      "title_zh": "翻译失败",
      "authors": [
        "Arianna Stropeni",
        "Francesco Borsatti",
        "Manuel Barusco",
        "Davide Dalle Pezze",
        "Marco Fabris",
        "Gian Antonio Susto"
      ],
      "abstract": "Visual Anomaly Detection (VAD) is a key task in industrial settings, where\nminimizing operational costs is essential. Deploying deep learning models\nwithin Internet of Things (IoT) environments introduces specific challenges due\nto limited computational power and bandwidth of edge devices. This study\ninvestigates how to perform VAD effectively under such constraints by\nleveraging compact, efficient processing strategies. We evaluate several data\ncompression techniques, examining the tradeoff between system latency and\ndetection accuracy. Experiments on the MVTec AD benchmark demonstrate that\nsignificant compression can be achieved with minimal loss in anomaly detection\nperformance compared to uncompressed data. Current results show up to 80%\nreduction in end-to-end inference time, including edge processing,\ntransmission, and server computation.",
      "tldr_zh": "这篇论文探讨了在IoT环境中部署视觉异常检测(VAD)的可扩展性，通过高效的数据压缩技术来应对边缘设备的计算能力和带宽限制。研究者评估了多种压缩方法，分析了系统延迟与检测准确性的权衡，并在MVTec AD基准上进行实验。结果显示，压缩策略实现了高达80%的端到端推理时间减少，包括边缘处理、传输和服务器计算，同时检测性能损失最小，为工业场景中的VAD应用提供了高效解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07119v2",
      "published_date": "2025-05-11 21:05:33 UTC",
      "updated_date": "2025-05-15 15:05:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:40:47.472343"
    },
    {
      "arxiv_id": "2505.07096v2",
      "title": "X-Sim: Cross-Embodiment Learning via Real-to-Sim-to-Real",
      "title_zh": "翻译失败",
      "authors": [
        "Prithwish Dan",
        "Kushal Kedia",
        "Angela Chao",
        "Edward Weiyi Duan",
        "Maximus Adrian Pace",
        "Wei-Chiu Ma",
        "Sanjiban Choudhury"
      ],
      "abstract": "Human videos offer a scalable way to train robot manipulation policies, but\nlack the action labels needed by standard imitation learning algorithms.\nExisting cross-embodiment approaches try to map human motion to robot actions,\nbut often fail when the embodiments differ significantly. We propose X-Sim, a\nreal-to-sim-to-real framework that uses object motion as a dense and\ntransferable signal for learning robot policies. X-Sim starts by reconstructing\na photorealistic simulation from an RGBD human video and tracking object\ntrajectories to define object-centric rewards. These rewards are used to train\na reinforcement learning (RL) policy in simulation. The learned policy is then\ndistilled into an image-conditioned diffusion policy using synthetic rollouts\nrendered with varied viewpoints and lighting. To transfer to the real world,\nX-Sim introduces an online domain adaptation technique that aligns real and\nsimulated observations during deployment. Importantly, X-Sim does not require\nany robot teleoperation data. We evaluate it across 5 manipulation tasks in 2\nenvironments and show that it: (1) improves task progress by 30% on average\nover hand-tracking and sim-to-real baselines, (2) matches behavior cloning with\n10x less data collection time, and (3) generalizes to new camera viewpoints and\ntest-time changes. Code and videos are available at\nhttps://portal-cornell.github.io/X-Sim/.",
      "tldr_zh": "该研究提出X-Sim框架，通过real-to-sim-to-real方法，利用人类视频中的物体运动作为密集可转移信号来训练机器人操作策略，而无需动作标签。框架首先从RGBD视频重建光实模拟环境，跟踪物体轨迹定义基于物体的奖励，并在模拟中训练reinforcement learning (RL)策略；随后，通过合成回放渲染蒸馏到image-conditioned diffusion policy，并采用在线domain adaptation技术实现真实世界转移。实验结果显示，X-Sim在5个操作任务中比手部跟踪和sim-to-real基线平均提升30%任务进度，且只需行为克隆的1/10数据收集时间，同时泛化到新相机视角和测试变化。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07096v2",
      "published_date": "2025-05-11 19:04:00 UTC",
      "updated_date": "2025-05-15 00:43:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:40:59.947033"
    },
    {
      "arxiv_id": "2505.07089v2",
      "title": "RefPentester: A Knowledge-Informed Self-Reflective Penetration Testing Framework Based on Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Hanzheng Dai",
        "Yuanliang Li",
        "Zhibo Zhang",
        "Jun Yan"
      ],
      "abstract": "Automated penetration testing (AutoPT) powered by large language models\n(LLMs) has gained attention for its ability to automate ethical hacking\nprocesses and identify vulnerabilities in target systems by leveraging the\nintrinsic knowledge of LLMs. However, existing LLM-based AutoPT frameworks\noften underperform compared to human experts in challenging tasks for several\nreasons: the imbalanced knowledge used in LLM training, short-sighted planning\nin the planning process, and hallucinations during command generation. In\naddition, the penetration testing (PT) process, with its trial-and-error\nnature, is limited by existing frameworks that lack mechanisms to learn from\nprevious failed operations, restricting adaptive improvement of PT strategies.\nTo address these limitations, we propose a knowledge-informed self-reflective\nPT framework powered by LLMs, called RefPentester, which is an AutoPT framework\ndesigned to assist human operators in identifying the current stage of the PT\nprocess, selecting appropriate tactic and technique for the stage, choosing\nsuggested action, providing step-by-step operational guidance, and learning\nfrom previous failed operations. We also modeled the PT process as a\nseven-state Stage Machine to integrate the proposed framework effectively. The\nevaluation shows that RefPentester can successfully reveal credentials on Hack\nThe Box's Sau machine, outperforming the baseline GPT-4o model by 16.7%. Across\nPT stages, RefPentester also demonstrates superior success rates on PT stage\ntransitions.",
      "tldr_zh": "该研究提出了RefPentester，一种基于大型语言模型(LLM)的知识驱动自反式渗透测试框架(AutoPT)，旨在解决现有框架在知识不平衡、短视规划和幻觉生成等方面的问题，并通过从失败操作中学习来提升策略适应性。框架将渗透测试过程建模为七状态阶段机，支持识别当前阶段、选择战术和技术、提供逐步指导以及自学习机制。实验结果显示，RefPentester在Hack The Box的Sau机器上成功揭示凭证，比基线GPT-4o模型高16.7%，并在PT阶段转换上表现出优越的成功率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07089v2",
      "published_date": "2025-05-11 18:38:00 UTC",
      "updated_date": "2025-05-14 00:44:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:41:11.813794"
    },
    {
      "arxiv_id": "2505.07087v1",
      "title": "Architectural Precedents for General Agents using Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Robert E. Wray",
        "James R. Kirk",
        "John E. Laird"
      ],
      "abstract": "One goal of AI (and AGI) is to identify and understand specific mechanisms\nand representations sufficient for general intelligence. Often, this work\nmanifests in research focused on architectures and many cognitive architectures\nhave been explored in AI/AGI. However, different research groups and even\ndifferent research traditions have somewhat independently identified\nsimilar/common patterns of processes and representations or cognitive design\npatterns that are manifest in existing architectures. Today, AI systems\nexploiting large language models (LLMs) offer a relatively new combination of\nmechanism and representation available for exploring the possibilities of\ngeneral intelligence. In this paper, we summarize a few recurring cognitive\ndesign patterns that have appeared in various pre-transformer AI architectures.\nWe then explore how these patterns are evident in systems using LLMs,\nespecially for reasoning and interactive (\"agentic\") use cases. By examining\nand applying these recurring patterns, we can also predict gaps or deficiencies\nin today's Agentic LLM Systems and identify likely subjects of future research\ntowards general intelligence using LLMs and other generative foundation models.",
      "tldr_zh": "该论文探讨了AI和AGI领域中，使用Large Language Models (LLMs)构建通用智能代理的架构先例，通过回顾历史认知架构中的常见认知设计patterns，总结了反复出现的处理和表示模式。作者分析了这些patterns在基于LLMs的系统中的体现，特别是应用于推理和交互式（agentic）任务，帮助识别当前Agentic LLM Systems的不足，如潜在的机制缺口。最终，论文预测了未来研究方向，以改进LLMs和其他生成基础模型，实现更全面的通用智能。",
      "categories": [
        "cs.AI",
        "I.2.11; I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 2 figures. Submitted to AGI25",
      "pdf_url": "http://arxiv.org/pdf/2505.07087v1",
      "published_date": "2025-05-11 18:29:54 UTC",
      "updated_date": "2025-05-11 18:29:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:41:23.469081"
    },
    {
      "arxiv_id": "2505.07079v1",
      "title": "Arbitrarily Applicable Same/Opposite Relational Responding with NARS",
      "title_zh": "翻译失败",
      "authors": [
        "Robert Johansson",
        "Patrick Hammer",
        "Tony Lofthouse"
      ],
      "abstract": "Same/opposite relational responding, a fundamental aspect of human symbolic\ncognition, allows the flexible generalization of stimulus relationships based\non minimal experience. In this study, we demonstrate the emergence of\n\\textit{arbitrarily applicable} same/opposite relational responding within the\nNon-Axiomatic Reasoning System (NARS), a computational cognitive architecture\ndesigned for adaptive reasoning under uncertainty. Specifically, we extend NARS\nwith an implementation of \\textit{acquired relations}, enabling the system to\nexplicitly derive both symmetric (mutual entailment) and novel relational\ncombinations (combinatorial entailment) from minimal explicit training in a\ncontextually controlled matching-to-sample (MTS) procedure. Experimental\nresults show that NARS rapidly internalizes explicitly trained relational rules\nand robustly demonstrates derived relational generalizations based on arbitrary\ncontextual cues. Importantly, derived relational responding in critical test\nphases inherently combines both mutual and combinatorial entailments, such as\nderiving same-relations from multiple explicitly trained opposite-relations.\nInternal confidence metrics illustrate strong internalization of these\nrelational principles, closely paralleling phenomena observed in human\nrelational learning experiments. Our findings underscore the potential for\nintegrating nuanced relational learning mechanisms inspired by learning\npsychology into artificial general intelligence frameworks, explicitly\nhighlighting the arbitrary and context-sensitive relational capabilities\nmodeled within NARS.",
      "tldr_zh": "本研究探讨了在Non-Axiomatic Reasoning System (NARS)中实现arbitrarily applicable same/opposite relational responding，这是一种人类符号认知的核心机制，能基于最小经验灵活泛化刺激关系。研究扩展了NARS的acquired relations功能，通过contextually controlled matching-to-sample (MTS)程序进行最小显式训练，允许系统推导出symmetric (mutual entailment)和novel relational combinations (combinatorial entailment)。实验结果显示，NARS快速内部化训练规则，并基于任意上下文线索展示稳健的派生关系泛化，例如从多个opposite-relations中推导出same-relations，同时内部信心指标反映出与人类关系学习相似的现象。该工作突出了将学习心理学启发的关系学习机制整合到人工通用智能(AGI)框架中的潜力，强调NARS的任意性和上下文敏感能力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07079v1",
      "published_date": "2025-05-11 18:03:37 UTC",
      "updated_date": "2025-05-11 18:03:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:41:36.600166"
    },
    {
      "arxiv_id": "2505.07078v2",
      "title": "Can LLM-based Financial Investing Strategies Outperform the Market in Long Run?",
      "title_zh": "基于 LLM 的金融投资策略能否在长期超越市场？",
      "authors": [
        "Weixian Waylon Li",
        "Hyeonjun Kim",
        "Mihai Cucuringu",
        "Tiejun Ma"
      ],
      "abstract": "Large Language Models (LLMs) have recently been leveraged for asset pricing\ntasks and stock trading applications, enabling AI agents to generate investment\ndecisions from unstructured financial data. However, most evaluations of LLM\ntiming-based investing strategies are conducted on narrow timeframes and\nlimited stock universes, overstating effectiveness due to survivorship and\ndata-snooping biases. We critically assess their generalizability and\nrobustness by proposing FINSABER, a backtesting framework evaluating\ntiming-based strategies across longer periods and a larger universe of symbols.\nSystematic backtests over two decades and 100+ symbols reveal that previously\nreported LLM advantages deteriorate significantly under broader cross-section\nand over a longer-term evaluation. Our market regime analysis further\ndemonstrates that LLM strategies are overly conservative in bull markets,\nunderperforming passive benchmarks, and overly aggressive in bear markets,\nincurring heavy losses. These findings highlight the need to develop LLM\nstrategies that are able to prioritise trend detection and regime-aware risk\ncontrols over mere scaling of framework complexity.",
      "tldr_zh": "本研究评估了大型语言模型 (LLMs) 在长期金融投资策略中的表现，提出 FINSABER 回测框架，以更长的时间跨度（20年）和更大股票范围（100+ 符号）来检验时序-based 策略的泛化性和稳健性。结果显示，LLMs 策略在更广泛的测试中优势显著下降，相比先前评估因存活偏差和数据窥探偏差而高估了其有效性。通过市场环境分析，发现 LLMs 策略在牛市过于保守，导致落后于被动基准，在熊市过于激进，造成重大损失。该研究强调，需要开发更注重趋势检测和市场环境风险控制的 LLM 策略，而不是单纯增加框架复杂度。",
      "categories": [
        "q-fin.TR",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "q-fin.TR",
      "comment": "14 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.07078v2",
      "published_date": "2025-05-11 18:02:21 UTC",
      "updated_date": "2025-05-20 14:51:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:41:48.022063"
    },
    {
      "arxiv_id": "2505.07064v1",
      "title": "ParaView-MCP: An Autonomous Visualization Agent with Direct Tool Use",
      "title_zh": "ParaView-MCP：一个具备直接工具使用的自治可视化代理",
      "authors": [
        "Shusen Liu",
        "Haichao Miao",
        "Peer-Timo Bremer"
      ],
      "abstract": "While powerful and well-established, tools like ParaView present a steep\nlearning curve that discourages many potential users. This work introduces\nParaView-MCP, an autonomous agent that integrates modern multimodal large\nlanguage models (MLLMs) with ParaView to not only lower the barrier to entry\nbut also augment ParaView with intelligent decision support. By leveraging the\nstate-of-the-art reasoning, command execution, and vision capabilities of\nMLLMs, ParaView-MCP enables users to interact with ParaView through natural\nlanguage and visual inputs. Specifically, our system adopted the Model Context\nProtocol (MCP) - a standardized interface for model-application communication -\nthat facilitates direct interaction between MLLMs with ParaView's Python API to\nallow seamless information exchange between the user, the language model, and\nthe visualization tool itself. Furthermore, by implementing a visual feedback\nmechanism that allows the agent to observe the viewport, we unlock a range of\nnew capabilities, including recreating visualizations from examples,\nclosed-loop visualization parameter updates based on user-defined goals, and\neven cross-application collaboration involving multiple tools. Broadly, we\nbelieve such an agent-driven visualization paradigm can profoundly change the\nway we interact with visualization tools. We expect a significant uptake in the\ndevelopment of such visualization tools, in both visualization research and\nindustry.",
      "tldr_zh": "本研究引入ParaView-MCP，一种自主可视化代理，将多模态大型语言模型(MLLMs)与ParaView整合，旨在降低ParaView的学习门槛并提供智能决策支持。系统采用Model Context Protocol (MCP)标准接口，实现MLLMs与ParaView的Python API直接交互，支持用户通过自然语言和视觉输入进行无缝沟通，并添加视觉反馈机制以启用新功能，如从示例重现可视化、基于用户目标的闭环参数更新，以及多工具跨应用协作。实验结果表明，这种代理驱动的可视化范式有望改变用户与可视化工具的互动方式，并在可视化研究和行业中推动广泛应用。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07064v1",
      "published_date": "2025-05-11 17:30:08 UTC",
      "updated_date": "2025-05-11 17:30:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:42:01.344725"
    },
    {
      "arxiv_id": "2505.07062v1",
      "title": "Seed1.5-VL Technical Report",
      "title_zh": "Seed1.5-VL 技术报告",
      "authors": [
        "Dong Guo",
        "Faming Wu",
        "Feida Zhu",
        "Fuxing Leng",
        "Guang Shi",
        "Haobin Chen",
        "Haoqi Fan",
        "Jian Wang",
        "Jianyu Jiang",
        "Jiawei Wang",
        "Jingji Chen",
        "Jingjia Huang",
        "Kang Lei",
        "Liping Yuan",
        "Lishu Luo",
        "Pengfei Liu",
        "Qinghao Ye",
        "Rui Qian",
        "Shen Yan",
        "Shixiong Zhao",
        "Shuai Peng",
        "Shuangye Li",
        "Sihang Yuan",
        "Sijin Wu",
        "Tianheng Cheng",
        "Weiwei Liu",
        "Wenqian Wang",
        "Xianhan Zeng",
        "Xiao Liu",
        "Xiaobo Qin",
        "Xiaohan Ding",
        "Xiaojun Xiao",
        "Xiaoying Zhang",
        "Xuanwei Zhang",
        "Xuehan Xiong",
        "Yanghua Peng",
        "Yangrui Chen",
        "Yanwei Li",
        "Yanxu Hu",
        "Yi Lin",
        "Yiyuan Hu",
        "Yiyuan Zhang",
        "Youbin Wu",
        "Yu Li",
        "Yudong Liu",
        "Yue Ling",
        "Yujia Qin",
        "Zanbo Wang",
        "Zhiwu He",
        "Aoxue Zhang",
        "Bairen Yi",
        "Bencheng Liao",
        "Can Huang",
        "Can Zhang",
        "Chaorui Deng",
        "Chaoyi Deng",
        "Cheng Lin",
        "Cheng Yuan",
        "Chenggang Li",
        "Chenhui Gou",
        "Chenwei Lou",
        "Chengzhi Wei",
        "Chundian Liu",
        "Chunyuan Li",
        "Deyao Zhu",
        "Donghong Zhong",
        "Feng Li",
        "Feng Zhang",
        "Gang Wu",
        "Guodong Li",
        "Guohong Xiao",
        "Haibin Lin",
        "Haihua Yang",
        "Haoming Wang",
        "Heng Ji",
        "Hongxiang Hao",
        "Hui Shen",
        "Huixia Li",
        "Jiahao Li",
        "Jialong Wu",
        "Jianhua Zhu",
        "Jianpeng Jiao",
        "Jiashi Feng",
        "Jiaze Chen",
        "Jianhui Duan",
        "Jihao Liu",
        "Jin Zeng",
        "Jingqun Tang",
        "Jingyu Sun",
        "Joya Chen",
        "Jun Long",
        "Junda Feng",
        "Junfeng Zhan",
        "Junjie Fang",
        "Junting Lu",
        "Kai Hua",
        "Kai Liu",
        "Kai Shen",
        "Kaiyuan Zhang",
        "Ke Shen",
        "Ke Wang",
        "Keyu Pan",
        "Kun Zhang",
        "Kunchang Li",
        "Lanxin Li",
        "Lei Li",
        "Lei Shi",
        "Li Han",
        "Liang Xiang",
        "Liangqiang Chen",
        "Lin Chen",
        "Lin Li",
        "Lin Yan",
        "Liying Chi",
        "Longxiang Liu",
        "Mengfei Du",
        "Mingxuan Wang",
        "Ningxin Pan",
        "Peibin Chen",
        "Pengfei Chen",
        "Pengfei Wu",
        "Qingqing Yuan",
        "Qingyao Shuai",
        "Qiuyan Tao",
        "Renjie Zheng",
        "Renrui Zhang",
        "Ru Zhang",
        "Rui Wang",
        "Rui Yang",
        "Rui Zhao",
        "Shaoqiang Xu",
        "Shihao Liang",
        "Shipeng Yan",
        "Shu Zhong",
        "Shuaishuai Cao",
        "Shuangzhi Wu",
        "Shufan Liu",
        "Shuhan Chang",
        "Songhua Cai",
        "Tenglong Ao",
        "Tianhao Yang",
        "Tingting Zhang",
        "Wanjun Zhong",
        "Wei Jia",
        "Wei Weng",
        "Weihao Yu",
        "Wenhao Huang",
        "Wenjia Zhu",
        "Wenli Yang",
        "Wenzhi Wang",
        "Xiang Long",
        "XiangRui Yin",
        "Xiao Li",
        "Xiaolei Zhu",
        "Xiaoying Jia",
        "Xijin Zhang",
        "Xin Liu",
        "Xinchen Zhang",
        "Xinyu Yang",
        "Xiongcai Luo",
        "Xiuli Chen",
        "Xuantong Zhong",
        "Xuefeng Xiao",
        "Xujing Li",
        "Yan Wu",
        "Yawei Wen",
        "Yifan Du",
        "Yihao Zhang",
        "Yining Ye",
        "Yonghui Wu",
        "Yu Liu",
        "Yu Yue",
        "Yufeng Zhou",
        "Yufeng Yuan",
        "Yuhang Xu",
        "Yuhong Yang",
        "Yun Zhang",
        "Yunhao Fang",
        "Yuntao Li",
        "Yurui Ren",
        "Yuwen Xiong",
        "Zehua Hong",
        "Zehua Wang",
        "Zewei Sun",
        "Zeyu Wang",
        "Zhao Cai",
        "Zhaoyue Zha",
        "Zhecheng An",
        "Zhehui Zhao",
        "Zhengzhuo Xu",
        "Zhipeng Chen",
        "Zhiyong Wu",
        "Zhuofan Zheng",
        "Zihao Wang",
        "Zilong Huang",
        "Ziyu Zhu",
        "Zuquan Song"
      ],
      "abstract": "We present Seed1.5-VL, a vision-language foundation model designed to advance\ngeneral-purpose multimodal understanding and reasoning. Seed1.5-VL is composed\nwith a 532M-parameter vision encoder and a Mixture-of-Experts (MoE) LLM of 20B\nactive parameters. Despite its relatively compact architecture, it delivers\nstrong performance across a wide spectrum of public VLM benchmarks and internal\nevaluation suites, achieving the state-of-the-art performance on 38 out of 60\npublic benchmarks. Moreover, in agent-centric tasks such as GUI control and\ngameplay, Seed1.5-VL outperforms leading multimodal systems, including OpenAI\nCUA and Claude 3.7. Beyond visual and video understanding, it also demonstrates\nstrong reasoning abilities, making it particularly effective for multimodal\nreasoning challenges such as visual puzzles. We believe these capabilities will\nempower broader applications across diverse tasks. In this report, we mainly\nprovide a comprehensive review of our experiences in building Seed1.5-VL across\nmodel design, data construction, and training at various stages, hoping that\nthis report can inspire further research. Seed1.5-VL is now accessible at\nhttps://www.volcengine.com/ (Volcano Engine Model ID:\ndoubao-1-5-thinking-vision-pro-250428)",
      "tldr_zh": "我们介绍了 Seed1.5-VL，这是一个视觉-语言基础模型，旨在提升通用的多模态理解和推理能力。模型由 532M 参数的视觉编码器和 20B 活跃参数的 Mixture-of-Experts (MoE) LLM 组成，尽管架构相对紧凑，却在 60 个公共 VLM 基准中领先 38 个，并在代理中心任务如 GUI 控制和游戏中超越 OpenAI CUA 和 Claude 3.7。Seed1.5-VL 展示了强大的推理能力，尤其在多模态推理挑战（如视觉谜题）上表现出色。该报告详细回顾了模型设计、数据构建和训练过程，以期启发进一步研究，并提供模型访问链接。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07062v1",
      "published_date": "2025-05-11 17:28:30 UTC",
      "updated_date": "2025-05-11 17:28:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:42:11.870732"
    },
    {
      "arxiv_id": "2505.07058v1",
      "title": "Explainable Artificial Intelligence Techniques for Software Development Lifecycle: A Phase-specific Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Lakshit Arora",
        "Sanjay Surendranath Girija",
        "Shashank Kapoor",
        "Aman Raj",
        "Dipen Pradhan",
        "Ankit Shetgaonkar"
      ],
      "abstract": "Artificial Intelligence (AI) is rapidly expanding and integrating more into\ndaily life to automate tasks, guide decision making, and enhance efficiency.\nHowever, complex AI models, which make decisions without providing clear\nexplanations (known as the \"black-box problem\"), currently restrict trust and\nwidespread adoption of AI. Explainable Artificial Intelligence (XAI) has\nemerged to address the black-box problem of making AI systems more\ninterpretable and transparent so stakeholders can trust, verify, and act upon\nAI-based outcomes. Researchers have developed various techniques to foster XAI\nin the Software Development Lifecycle. However, there are gaps in applying XAI\ntechniques in the Software Engineering phases. Literature review shows that 68%\nof XAI in Software Engineering research is focused on maintenance as opposed to\n8% on software management and requirements. In this paper, we present a\ncomprehensive survey of the applications of XAI methods such as concept-based\nexplanations, Local Interpretable Model-agnostic Explanations (LIME), SHapley\nAdditive exPlanations (SHAP), rule extraction, attention mechanisms,\ncounterfactual explanations, and example-based explanations to the different\nphases of the Software Development Life Cycle (SDLC), including requirements\nelicitation, design and development, testing and deployment, and evolution. To\nthe best of our knowledge, this paper presents the first comprehensive survey\nof XAI techniques for every phase of the Software Development Life Cycle\n(SDLC). This survey aims to promote explainable AI in Software Engineering and\nfacilitate the practical application of complex AI models in AI-driven software\ndevelopment.",
      "tldr_zh": "这篇论文对Explainable Artificial Intelligence (XAI)技术在软件开发生命周期（Software Development Lifecycle, SDLC）各阶段的应用进行了首个全面调查，旨在解决AI系统的黑箱问题并提升其可解释性和透明度。研究发现，现有XAI研究高度集中在软件维护阶段（占68%），而需求获取和软件管理阶段仅占8%，暴露了应用上的不均衡问题。论文详细探讨了多种XAI方法，包括concept-based explanations、Local Interpretable Model-agnostic Explanations (LIME)、SHapley Additive exPlanations (SHAP)、rule extraction、attention mechanisms、counterfactual explanations和example-based explanations，在SDLC的各个阶段如需求获取、设计开发、测试部署和演化中的实际应用。通过这一调查，论文旨在促进XAI在软件工程中的采用，并支持复杂AI模型在AI驱动软件开发中的实际部署。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted to IEEE COMPSAC 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.07058v1",
      "published_date": "2025-05-11 17:09:57 UTC",
      "updated_date": "2025-05-11 17:09:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:42:24.868775"
    },
    {
      "arxiv_id": "2505.07891v1",
      "title": "TrumorGPT: Graph-Based Retrieval-Augmented Large Language Model for Fact-Checking",
      "title_zh": "翻译失败",
      "authors": [
        "Ching Nam Hang",
        "Pei-Duo Yu",
        "Chee Wei Tan"
      ],
      "abstract": "In the age of social media, the rapid spread of misinformation and rumors has\nled to the emergence of infodemics, where false information poses a significant\nthreat to society. To combat this issue, we introduce TrumorGPT , a novel\ngenerative artificial intelligence solution designed for fact-checking in the\nhealth domain. TrumorGPT aims to distinguish \"trumors\", which are\nhealth-related rumors that turn out to be true, providing a crucial tool in\ndifferentiating between mere speculation and verified facts. This framework\nleverages a large language model (LLM) with few-shot learning for semantic\nhealth knowledge graph construction and semantic reasoning. TrumorGPT\nincorporates graph-based retrieval-augmented generation (GraphRAG) to address\nthe hallucination issue common in LLMs and the limitations of static training\ndata. GraphRAG involves accessing and utilizing information from regularly\nupdated semantic health knowledge graphs that consist of the latest medical\nnews and health information, ensuring that fact-checking by TrumorGPT is based\non the most recent data. Evaluating with extensive healthcare datasets,\nTrumorGPT demonstrates superior performance in fact-checking for public health\nclaims. Its ability to effectively conduct fact-checking across various\nplatforms marks a critical step forward in the fight against health-related\nmisinformation, enhancing trust and accuracy in the digital information age.",
      "tldr_zh": "该论文提出TrumorGPT，一种基于图的检索增强生成(GraphRAG)的大型语言模型(LLM)，旨在针对健康领域的“trumors”（最终证明为真的健康相关谣言）进行事实核查，以区分误信息和已验证事实。TrumorGPT利用少样本学习构建语义健康知识图，并通过GraphRAG访问定期更新的医疗新闻和健康信息，解决LLM的幻觉问题和数据时效性限制。在广泛的医疗数据集上评估，该框架在公共健康声明的事实核查中表现出色，推动了数字信息时代的信任和准确性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07891v1",
      "published_date": "2025-05-11 17:00:21 UTC",
      "updated_date": "2025-05-11 17:00:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:42:36.827896"
    },
    {
      "arxiv_id": "2505.07052v1",
      "title": "Unlocking Non-Block-Structured Decisions: Inductive Mining with Choice Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Humam Kourani",
        "Gyunam Park",
        "Wil M. P. van der Aalst"
      ],
      "abstract": "Process discovery aims to automatically derive process models from event\nlogs, enabling organizations to analyze and improve their operational\nprocesses. Inductive mining algorithms, while prioritizing soundness and\nefficiency through hierarchical modeling languages, often impose a strict\nblock-structured representation. This limits their ability to accurately\ncapture the complexities of real-world processes. While recent advancements\nlike the Partially Ordered Workflow Language (POWL) have addressed the\nblock-structure limitation for concurrency, a significant gap remains in\neffectively modeling non-block-structured decision points. In this paper, we\nbridge this gap by proposing an extension of POWL to handle\nnon-block-structured decisions through the introduction of choice graphs.\nChoice graphs offer a structured yet flexible approach to model complex\ndecision logic within the hierarchical framework of POWL. We present an\ninductive mining discovery algorithm that uses our extension and preserves the\nquality guarantees of the inductive mining framework. Our experimental\nevaluation demonstrates that the discovered models, enriched with choice\ngraphs, more precisely represent the complex decision-making behavior found in\nreal-world processes, without compromising the high scalability inherent in\ninductive mining techniques.",
      "tldr_zh": "本研究针对过程发现（Process discovery）中的挑战，指出 Inductive mining 算法虽强调健全性和效率，但其严格的块结构表示限制了捕捉真实世界过程的复杂性，特别是非块结构的决策点。作者提出扩展 Partially Ordered Workflow Language (POWL)，通过引入 Choice graphs 来灵活建模复杂的决策逻辑，同时保持分层框架。实验结果显示，该扩展的 Inductive mining 发现算法能更精确地表示真实过程的决策行为，并维持高可伸缩性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "The Version of Record of this contribution will be published in the\n  proceedings of the 23rd International Conference on Business Process\n  Management (BPM 2025). This preprint has not undergone peer review or any\n  post-submission improvements or corrections",
      "pdf_url": "http://arxiv.org/pdf/2505.07052v1",
      "published_date": "2025-05-11 16:50:25 UTC",
      "updated_date": "2025-05-11 16:50:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:42:48.655048"
    },
    {
      "arxiv_id": "2505.07049v1",
      "title": "DialogueReason: Rule-Based RL Sparks Dialogue Reasoning in LLMs",
      "title_zh": "DialogueReason：基于规则的强化学习激发大语言模型中的对话推理",
      "authors": [
        "Yubo Shu",
        "Zhewei Huang",
        "Xin Wu",
        "Chen Hu",
        "Shuchang Zhou",
        "Daxin Jiang"
      ],
      "abstract": "We propose DialogueReason, a reasoning paradigm that uncovers the lost roles\nin monologue-style reasoning models, aiming to boost diversity and coherency of\nthe reasoning process. Recent advances in RL-based large reasoning models have\nled to impressive long CoT capabilities and high performance on math and\nscience benchmarks. However, these reasoning models rely mainly on\nmonologue-style reasoning, which often limits reasoning diversity and\ncoherency, frequently recycling fixed strategies or exhibiting unnecessary\nshifts in attention. Our work consists of an analysis of monologue reasoning\npatterns and the development of a dialogue-based reasoning approach. We first\nintroduce the Compound-QA task, which concatenates multiple problems into a\nsingle prompt to assess both diversity and coherency of reasoning. Our analysis\nshows that Compound-QA exposes weaknesses in monologue reasoning, evidenced by\nboth quantitative metrics and qualitative reasoning traces. Building on the\nanalysis, we propose a dialogue-based reasoning, named DialogueReason,\nstructured around agents, environment, and interactions. Using PPO with\nrule-based rewards, we train open-source LLMs (Qwen-QWQ and Qwen-Base) to adopt\ndialogue reasoning. We evaluate trained models on MATH, AIME, and GPQA\ndatasets, showing that the dialogue reasoning model outperforms monologue\nmodels under more complex compound questions. Additionally, we discuss how\ndialogue-based reasoning helps enhance interpretability, facilitate more\nintuitive human interaction, and inspire advances in multi-agent system design.",
      "tldr_zh": "本研究提出DialogueReason，一种对话式推理范式，旨在解决现有单 monologue-style 推理模型在多样性和连贯性方面的局限性，通过引入Compound-QA任务来评估和暴露这些弱点。研究方法基于强化学习（RL），具体使用PPO算法和rule-based rewards训练开源LLMs（如Qwen-QWQ和Qwen-Base），构建代理、环境和交互的对话式推理结构。实验结果显示，DialogueReason在MATH、AIME和GPQA数据集上，尤其在复杂复合问题中，显著优于monologue模型；此外，该方法提升了推理的可解释性，便于人类交互，并启发了多代理系统设计。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07049v1",
      "published_date": "2025-05-11 16:39:58 UTC",
      "updated_date": "2025-05-11 16:39:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:43:00.185032"
    },
    {
      "arxiv_id": "2505.07045v1",
      "title": "Reinforcement Learning (RL) Meets Urban Climate Modeling: Investigating the Efficacy and Impacts of RL-Based HVAC Control",
      "title_zh": "翻译失败",
      "authors": [
        "Junjie Yu",
        "John S. Schreck",
        "David John Gagne",
        "Keith W. Oleson",
        "Jie Li",
        "Yongtu Liang",
        "Qi Liao",
        "Mingfei Sun",
        "David O. Topping",
        "Zhonghua Zheng"
      ],
      "abstract": "Reinforcement learning (RL)-based heating, ventilation, and air conditioning\n(HVAC) control has emerged as a promising technology for reducing building\nenergy consumption while maintaining indoor thermal comfort. However, the\nefficacy of such strategies is influenced by the background climate and their\nimplementation may potentially alter both the indoor climate and local urban\nclimate. This study proposes an integrated framework combining RL with an urban\nclimate model that incorporates a building energy model, aiming to evaluate the\nefficacy of RL-based HVAC control across different background climates, impacts\nof RL strategies on indoor climate and local urban climate, and the\ntransferability of RL strategies across cities. Our findings reveal that the\nreward (defined as a weighted combination of energy consumption and thermal\ncomfort) and the impacts of RL strategies on indoor climate and local urban\nclimate exhibit marked variability across cities with different background\nclimates. The sensitivity of reward weights and the transferability of RL\nstrategies are also strongly influenced by the background climate. Cities in\nhot climates tend to achieve higher rewards across most reward weight\nconfigurations that balance energy consumption and thermal comfort, and those\ncities with more varying atmospheric temperatures demonstrate greater RL\nstrategy transferability. These findings underscore the importance of\nthoroughly evaluating RL-based HVAC control strategies in diverse climatic\ncontexts. This study also provides a new insight that city-to-city learning\nwill potentially aid the deployment of RL-based HVAC control.",
      "tldr_zh": "这篇论文提出一个整合 Reinforcement Learning (RL) 与城市气候模型的框架，用于评估 RL-based HVAC 控制在不同气候下的效能，包括对室内和本地城市气候的影响以及策略的可转移性。研究发现，RL 策略的奖励（能源消耗和热舒适的加权组合）在不同城市表现出显著差异，热气候城市在大多数奖励权重配置下获得更高奖励，而温度变化大的城市显示出更好的策略转移性。这些发现强调了在多样气候背景下彻底评估 RL-HVAC 控制策略的必要性，并建议通过城市间学习来促进其部署。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.ao-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07045v1",
      "published_date": "2025-05-11 16:33:42 UTC",
      "updated_date": "2025-05-11 16:33:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:43:12.480490"
    },
    {
      "arxiv_id": "2505.07041v1",
      "title": "Empirical Analysis of Asynchronous Federated Learning on Heterogeneous Devices: Efficiency, Fairness, and Privacy Trade-offs",
      "title_zh": "对异构设备上异步联邦学习的实证分析：效率、公平性和隐私权衡",
      "authors": [
        "Samaneh Mohammadi",
        "Iraklis Symeonidis",
        "Ali Balador",
        "Francesco Flammini"
      ],
      "abstract": "Device heterogeneity poses major challenges in Federated Learning (FL), where\nresource-constrained clients slow down synchronous schemes that wait for all\nupdates before aggregation. Asynchronous FL addresses this by incorporating\nupdates as they arrive, substantially improving efficiency. While its\nefficiency gains are well recognized, its privacy costs remain largely\nunexplored, particularly for high-end devices that contribute updates more\nfrequently, increasing their cumulative privacy exposure. This paper presents\nthe first comprehensive analysis of the efficiency-fairness-privacy trade-off\nin synchronous vs. asynchronous FL under realistic device heterogeneity. We\nempirically compare FedAvg and staleness-aware FedAsync using a physical\ntestbed of five edge devices spanning diverse hardware tiers, integrating Local\nDifferential Privacy (LDP) and the Moments Accountant to quantify per-client\nprivacy loss. Using Speech Emotion Recognition (SER) as a privacy-critical\nbenchmark, we show that FedAsync achieves up to 10x faster convergence but\nexacerbates fairness and privacy disparities: high-end devices contribute 6-10x\nmore updates and incur up to 5x higher privacy loss, while low-end devices\nsuffer amplified accuracy degradation due to infrequent, stale, and\nnoise-perturbed updates. These findings motivate the need for adaptive FL\nprotocols that jointly optimize aggregation and privacy mechanisms based on\nclient capacity and participation dynamics, moving beyond static,\none-size-fits-all solutions.",
      "tldr_zh": "这篇论文通过实证分析比较了同步和异步联邦学习(Asynchronous FL)在设备异构环境下的效率、公平性和隐私权衡，重点探讨异步FL如何通过即时整合更新提升效率，但可能加剧隐私风险。研究使用FedAvg和FedAsync算法，在五种不同硬件设备的物理测试床上进行实验，并整合Local Differential Privacy (LDP)和Moments Accountant量化每客户端隐私损失；在语音情感识别(SER)基准测试中，FedAsync实现了高达10倍的收敛速度，但高端设备贡献更新6-10倍，导致隐私损失增加5倍，而低端设备因更新不频繁和噪声干扰而出现准确率下降。论文建议开发自适应FL协议，根据客户端能力和参与动态优化聚合和隐私机制，以克服静态方案的局限性。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "This paper was accepted to IJCNN 2025. This version is a preprint and\n  not the official published version",
      "pdf_url": "http://arxiv.org/pdf/2505.07041v1",
      "published_date": "2025-05-11 16:25:06 UTC",
      "updated_date": "2025-05-11 16:25:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:43:24.971105"
    },
    {
      "arxiv_id": "2505.07036v1",
      "title": "Predicting Diabetes Using Machine Learning: A Comparative Study of Classifiers",
      "title_zh": "使用机器学习预测糖尿病：分类器的比较研究",
      "authors": [
        "Mahade Hasan",
        "Farhana Yasmin"
      ],
      "abstract": "Diabetes remains a significant health challenge globally, contributing to\nsevere complications like kidney disease, vision loss, and heart issues. The\napplication of machine learning (ML) in healthcare enables efficient and\naccurate disease prediction, offering avenues for early intervention and\npatient support. Our study introduces an innovative diabetes prediction\nframework, leveraging both traditional ML techniques such as Logistic\nRegression, SVM, Na\\\"ive Bayes, and Random Forest and advanced ensemble methods\nlike AdaBoost, Gradient Boosting, Extra Trees, and XGBoost. Central to our\napproach is the development of a novel model, DNet, a hybrid architecture\ncombining Convolutional Neural Network (CNN) and Long Short-Term Memory (LSTM)\nlayers for effective feature extraction and sequential learning. The DNet model\ncomprises an initial convolutional block for capturing essential features,\nfollowed by a residual block with skip connections to facilitate efficient\ninformation flow. Batch Normalization and Dropout are employed for robust\nregularization, and an LSTM layer captures temporal dependencies within the\ndata. Using a Kaggle-sourced real-world diabetes dataset, our model evaluation\nspans cross-validation accuracy, precision, recall, F1 score, and ROC-AUC.\nAmong the models, DNet demonstrates the highest efficacy with an accuracy of\n99.79% and an AUC-ROC of 99.98%, establishing its potential for superior\ndiabetes prediction. This robust hybrid architecture showcases the value of\ncombining CNN and LSTM layers, emphasizing its applicability in medical\ndiagnostics and disease prediction tasks.",
      "tldr_zh": "这篇论文比较了多种机器学习分类器在糖尿病预测中的性能，包括传统方法如 Logistic Regression、SVM、Naïve Bayes 和 Random Forest，以及高级集成方法如 AdaBoost、Gradient Boosting、Extra Trees 和 XGBoost。研究创新性地提出 DNet 模型，这是一种结合 Convolutional Neural Network (CNN) 和 Long Short-Term Memory (LSTM) 的混合架构，用于高效特征提取和序列学习，并在数据集上通过残差块、批量归一化和 Dropout 实现鲁棒性。实验结果显示，DNet 在 Kaggle 真实糖尿病数据集上取得了 99.79% 的准确率和 99.98% 的 AUC-ROC，证明了其在医疗诊断和疾病预测中的显著优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07036v1",
      "published_date": "2025-05-11 16:14:31 UTC",
      "updated_date": "2025-05-11 16:14:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:43:37.604944"
    },
    {
      "arxiv_id": "2505.07030v1",
      "title": "Efficient Fault Detection in WSN Based on PCA-Optimized Deep Neural Network Slicing Trained with GOA",
      "title_zh": "翻译失败",
      "authors": [
        "Mahmood Mohassel Feghhi",
        "Raya Majid Alsharfa",
        "Majid Hameed Majeed"
      ],
      "abstract": "Fault detection in Wireless Sensor Networks (WSNs) is crucial for reliable\ndata transmission and network longevity. Traditional fault detection methods\noften struggle with optimizing deep neural networks (DNNs) for efficient\nperformance, especially in handling high-dimensional data and capturing\nnonlinear relationships. Additionally, these methods typically suffer from slow\nconvergence and difficulty in finding optimal network architectures using\ngradient-based optimization. This study proposes a novel hybrid method\ncombining Principal Component Analysis (PCA) with a DNN optimized by the\nGrasshopper Optimization Algorithm (GOA) to address these limitations. Our\napproach begins by computing eigenvalues from the original 12-dimensional\ndataset and sorting them in descending order. The cumulative sum of these\nvalues is calculated, retaining principal components until 99.5% variance is\nachieved, effectively reducing dimensionality to 4 features while preserving\ncritical information. This compressed representation trains a six-layer DNN\nwhere GOA optimizes the network architecture, overcoming backpropagation's\nlimitations in discovering nonlinear relationships. This hybrid PCA-GOA-DNN\nframework compresses the data and trains a six-layer DNN that is optimized by\nGOA, enhancing both training efficiency and fault detection accuracy. The\ndataset used in this study is a real-world WSNs dataset developed by the\nUniversity of North Carolina, which was used to evaluate the proposed method's\nperformance. Extensive simulations demonstrate that our approach achieves a\nremarkable 99.72% classification accuracy, with exceptional precision and\nrecall, outperforming conventional methods. The method is computationally\nefficient, making it suitable for large-scale WSN deployments, and represents a\nsignificant advancement in fault detection for resource-constrained WSNs.",
      "tldr_zh": "本文提出了一种高效的无线传感器网络（WSNs）故障检测方法，结合主成分分析（PCA）降维和Grasshopper Optimization Algorithm（GOA）优化深度神经网络（DNN），以解决传统方法在处理高维数据和非线性关系时的局限性。具体而言，该方法先通过PCA将12维数据集降维到4维，保留99.5%的方差，然后使用GOA优化六层DNN的架构，提升训练效率和准确性。实验在真实WSNs数据集上验证，该框架实现了99.72%的分类准确率，并在精度和召回率上优于传统方法，适合大规模资源受限环境的应用。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "eess.SP"
      ],
      "primary_category": "cs.AI",
      "comment": "22 pages, 18 figures, Accepted for publication in International\n  Journal of Intelligent Engineering and Systems, May 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.07030v1",
      "published_date": "2025-05-11 15:51:56 UTC",
      "updated_date": "2025-05-11 15:51:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:43:48.806094"
    },
    {
      "arxiv_id": "2505.07027v1",
      "title": "LLM-Augmented Chemical Synthesis and Design Decision Programs",
      "title_zh": "LLM 增强的化学合成和设计决策程序",
      "authors": [
        "Haorui Wang",
        "Jeff Guo",
        "Lingkai Kong",
        "Rampi Ramprasad",
        "Philippe Schwaller",
        "Yuanqi Du",
        "Chao Zhang"
      ],
      "abstract": "Retrosynthesis, the process of breaking down a target molecule into simpler\nprecursors through a series of valid reactions, stands at the core of organic\nchemistry and drug development. Although recent machine learning (ML) research\nhas advanced single-step retrosynthetic modeling and subsequent route searches,\nthese solutions remain restricted by the extensive combinatorial space of\npossible pathways. Concurrently, large language models (LLMs) have exhibited\nremarkable chemical knowledge, hinting at their potential to tackle complex\ndecision-making tasks in chemistry. In this work, we explore whether LLMs can\nsuccessfully navigate the highly constrained, multi-step retrosynthesis\nplanning problem. We introduce an efficient scheme for encoding reaction\npathways and present a new route-level search strategy, moving beyond the\nconventional step-by-step reactant prediction. Through comprehensive\nevaluations, we show that our LLM-augmented approach excels at retrosynthesis\nplanning and extends naturally to the broader challenge of synthesizable\nmolecular design.",
      "tldr_zh": "本研究探讨了大语言模型（LLMs）在逆合成分析（retrosynthesis）中的应用，以解决有机化学和药物开发中目标分子分解为简单前体的多步规划挑战。作者提出了一种高效的反应路径编码方案和新的路线级搜索策略，超越传统的步步反应物预测，利用LLMs的化学知识进行决策。实验结果显示，该LLM增强方法在逆合成规划上表现出色，并自然扩展到可合成分子设计的更广泛问题中。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.NE",
        "physics.chem-ph"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07027v1",
      "published_date": "2025-05-11 15:43:00 UTC",
      "updated_date": "2025-05-11 15:43:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:44:01.001330"
    },
    {
      "arxiv_id": "2505.09646v1",
      "title": "Temporal Interception and Present Reconstruction: A Cognitive-Signal Model for Human and AI Decision Making",
      "title_zh": "翻译失败",
      "authors": [
        "Carmel Mary Esther A"
      ],
      "abstract": "This paper proposes a novel theoretical model to explain how the human mind\nand artificial intelligence can approach real-time awareness by reducing\nperceptual delays. By investigating cosmic signal delay, neurological reaction\ntimes, and the ancient cognitive state of stillness, we explore how one may\nshift from reactive perception to a conscious interface with the near future.\nThis paper introduces both a physical and cognitive model for perceiving the\npresent not as a linear timestamp, but as an interference zone where\nearly-arriving cosmic signals and reactive human delays intersect. We propose\nexperimental approaches to test these ideas using human neural observation and\nneuro-receptive extensions. Finally, we propose a mathematical framework to\nguide the evolution of AI systems toward temporally efficient, ethically sound,\nand internally conscious decision-making processes",
      "tldr_zh": "这篇论文提出了一种新颖的认知-信号模型（Cognitive-Signal Model），旨在解释人类和AI如何通过减少感知延迟来实现实时意识，探讨了宇宙信号延迟、神经反应时间以及古老的认知静止状态。模型将“现在”视为一个非线性的干扰区，即早期宇宙信号与人类反应延迟的交汇点，从而从反应式感知转向与近未来的有意识界面。论文还建议实验方法，包括人类神经观察和神经接收扩展，并提供一个数学框架来指导AI系统向时间高效、道德健全且内部意识的决策过程演进。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "physics.hist-ph"
      ],
      "primary_category": "q-bio.NC",
      "comment": "8 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.09646v1",
      "published_date": "2025-05-11 15:38:27 UTC",
      "updated_date": "2025-05-11 15:38:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:44:12.982490"
    },
    {
      "arxiv_id": "2505.07023v1",
      "title": "Incremental Uncertainty-aware Performance Monitoring with Active Labeling Intervention",
      "title_zh": "增量不确定性感知性能监控，结合主动标记干预",
      "authors": [
        "Alexander Koebler",
        "Thomas Decker",
        "Ingo Thon",
        "Volker Tresp",
        "Florian Buettner"
      ],
      "abstract": "We study the problem of monitoring machine learning models under gradual\ndistribution shifts, where circumstances change slowly over time, often leading\nto unnoticed yet significant declines in accuracy. To address this, we propose\nIncremental Uncertainty-aware Performance Monitoring (IUPM), a novel label-free\nmethod that estimates performance changes by modeling gradual shifts using\noptimal transport. In addition, IUPM quantifies the uncertainty in the\nperformance prediction and introduces an active labeling procedure to restore a\nreliable estimate under a limited labeling budget. Our experiments show that\nIUPM outperforms existing performance estimation baselines in various gradual\nshift scenarios and that its uncertainty awareness guides label acquisition\nmore effectively compared to other strategies.",
      "tldr_zh": "本文研究了机器学习模型在逐渐分布偏移（gradual distribution shifts）下的性能监控问题，提出了一种新型无标签方法 Incremental Uncertainty-aware Performance Monitoring (IUPM)，它通过 optimal transport 建模偏移来估计性能变化，并量化预测不确定性，同时引入 active labeling procedure 在标签预算有限的情况下恢复可靠估计。IUPM 的实验结果显示，在各种 gradual shift 场景中，它优于现有基线方法，且不确定性意识能更有效地指导标签获取策略。该方法为动态环境下模型监控提供了实用解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07023v1",
      "published_date": "2025-05-11 15:35:55 UTC",
      "updated_date": "2025-05-11 15:35:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:44:24.427487"
    },
    {
      "arxiv_id": "2505.07020v1",
      "title": "R-CAGE: A Structural Model for Emotion Output Design in Human-AI Interaction",
      "title_zh": "R-CAGE：人-AI 交互中情感输出设计的结构模型",
      "authors": [
        "Suyeon Choi"
      ],
      "abstract": "This paper presents R-CAGE (Rhythmic Control Architecture for Guarding Ego),\na theoretical framework for restructuring emotional output in long-term\nhuman-AI interaction. While prior affective computing approaches emphasized\nexpressiveness, immersion, and responsiveness, they often neglected the\ncognitive and structural consequences of repeated emotional engagement. R-CAGE\ninstead conceptualizes emotional output not as reactive expression but as\nethical design structure requiring architectural intervention. The model is\ngrounded in experiential observations of subtle affective symptoms such as\nlocalized head tension, interpretive fixation, and emotional lag arising from\nprolonged interaction with affective AI systems. These indicate a mismatch\nbetween system-driven emotion and user interpretation that cannot be fully\nexplained by biometric data or observable behavior. R-CAGE adopts a\nuser-centered stance prioritizing psychological recovery, interpretive\nautonomy, and identity continuity. The framework consists of four control\nblocks: (1) Control of Rhythmic Expression regulates output pacing to reduce\nfatigue; (2) Architecture of Sensory Structuring adjusts intensity and timing\nof affective stimuli; (3) Guarding of Cognitive Framing reduces semantic\npressure to allow flexible interpretation; (4) Ego-Aligned Response Design\nsupports self-reference recovery during interpretive lag. By structurally\nregulating emotional rhythm, sensory intensity, and interpretive affordances,\nR-CAGE frames emotion not as performative output but as sustainable design\nunit. The goal is to protect users from oversaturation and cognitive overload\nwhile sustaining long-term interpretive agency in AI-mediated environments.",
      "tldr_zh": "本论文提出 R-CAGE（Rhythmic Control Architecture for Guarding Ego）框架，这是一个理论模型，用于重构人类-AI 长期互动中的情感输出设计，强调将情感视为道德架构干预而非简单反应性表达。框架基于对用户体验的观察，如头部紧张、解释固定和情感滞后等症状，构建了四个控制块：Control of Rhythmic Expression 调节输出节奏以减少疲劳、Architecture of Sensory Structuring 调整感官刺激强度和时机、Guarding of Cognitive Framing 降低语义压力以支持解释灵活性，以及 Ego-Aligned Response Design 促进自我参考恢复。R-CAGE 的目标是通过结构化调节情感节奏、感官强度和解释能力，保护用户免受认知超载和过度饱和，同时维持长期的心理恢复、解释自主性和身份连续性。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY",
        "H.5.2"
      ],
      "primary_category": "cs.HC",
      "comment": "theory-only preprint. Independent research",
      "pdf_url": "http://arxiv.org/pdf/2505.07020v1",
      "published_date": "2025-05-11 15:30:23 UTC",
      "updated_date": "2025-05-11 15:30:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:44:37.494974"
    },
    {
      "arxiv_id": "2505.07013v1",
      "title": "Efficient and Robust Multidimensional Attention in Remote Physiological Sensing through Target Signal Constrained Factorization",
      "title_zh": "通过目标信号约束因子分解实现的远程生理信号感知中的高效且鲁棒的多维注意机制",
      "authors": [
        "Jitesh Joshi",
        "Youngjun Cho"
      ],
      "abstract": "Remote physiological sensing using camera-based technologies offers\ntransformative potential for non-invasive vital sign monitoring across\nhealthcare and human-computer interaction domains. Although deep learning\napproaches have advanced the extraction of physiological signals from video\ndata, existing methods have not been sufficiently assessed for their robustness\nto domain shifts. These shifts in remote physiological sensing include\nvariations in ambient conditions, camera specifications, head movements, facial\nposes, and physiological states which often impact real-world performance\nsignificantly. Cross-dataset evaluation provides an objective measure to assess\ngeneralization capabilities across these domain shifts. We introduce Target\nSignal Constrained Factorization module (TSFM), a novel multidimensional\nattention mechanism that explicitly incorporates physiological signal\ncharacteristics as factorization constraints, allowing more precise feature\nextraction. Building on this innovation, we present MMRPhys, an efficient\ndual-branch 3D-CNN architecture designed for simultaneous multitask estimation\nof photoplethysmography (rPPG) and respiratory (rRSP) signals from multimodal\nRGB and thermal video inputs. Through comprehensive cross-dataset evaluation on\nfive benchmark datasets, we demonstrate that MMRPhys with TSFM significantly\noutperforms state-of-the-art methods in generalization across domain shifts for\nrPPG and rRSP estimation, while maintaining a minimal inference latency\nsuitable for real-time applications. Our approach establishes new benchmarks\nfor robust multitask and multimodal physiological sensing and offers a\ncomputationally efficient framework for practical deployment in unconstrained\nenvironments. The web browser-based application featuring on-device real-time\ninference of MMRPhys model is available at\nhttps://physiologicailab.github.io/mmrphys-live",
      "tldr_zh": "本研究针对远程生理信号监测中的领域偏移问题（如环境变化和头部运动），提出了一种高效且鲁棒的多维注意机制——Target Signal Constrained Factorization (TSFM)，通过生理信号特性作为约束来实现更精确的特征提取。基于此，作者开发了MMRPhys，一个双分支3D-CNN架构，能够从RGB和热成像视频中同时估计光电容积描记(rPPG)和呼吸(rRSP)信号。实验在五个基准数据集上的跨数据集评估中显示，MMRPhys结合TSFM在泛化性能上显著优于现有方法，同时保持低延迟，适用于实时应用，并为多任务多模态生理监测提供了高效的部署框架。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "25 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.07013v1",
      "published_date": "2025-05-11 15:20:45 UTC",
      "updated_date": "2025-05-11 15:20:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:44:48.699202"
    },
    {
      "arxiv_id": "2505.07012v1",
      "title": "Hand-Shadow Poser",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Xu",
        "Yinqiao Wang",
        "Niloy J. Mitra",
        "Shuaicheng Liu",
        "Pheng-Ann Heng",
        "Chi-Wing Fu"
      ],
      "abstract": "Hand shadow art is a captivating art form, creatively using hand shadows to\nreproduce expressive shapes on the wall. In this work, we study an inverse\nproblem: given a target shape, find the poses of left and right hands that\ntogether best produce a shadow resembling the input. This problem is\nnontrivial, since the design space of 3D hand poses is huge while being\nrestrictive due to anatomical constraints. Also, we need to attend to the\ninput's shape and crucial features, though the input is colorless and\ntextureless. To meet these challenges, we design Hand-Shadow Poser, a\nthree-stage pipeline, to decouple the anatomical constraints (by hand) and\nsemantic constraints (by shadow shape): (i) a generative hand assignment module\nto explore diverse but reasonable left/right-hand shape hypotheses; (ii) a\ngeneralized hand-shadow alignment module to infer coarse hand poses with a\nsimilarity-driven strategy for selecting hypotheses; and (iii) a\nshadow-feature-aware refinement module to optimize the hand poses for physical\nplausibility and shadow feature preservation. Further, we design our pipeline\nto be trainable on generic public hand data, thus avoiding the need for any\nspecialized training dataset. For method validation, we build a benchmark of\n210 diverse shadow shapes of varying complexity and a comprehensive set of\nmetrics, including a novel DINOv2-based evaluation metric. Through extensive\ncomparisons with multiple baselines and user studies, our approach is\ndemonstrated to effectively generate bimanual hand poses for a large variety of\nhand shapes for over 85% of the benchmark cases.",
      "tldr_zh": "本研究解决了手影艺术的反问题：给定一个目标形状，找到左右手姿势，使其投射出的影子最接近输入形状，同时处理手部解剖学约束和输入的无颜色纹理特征。研究提出Hand-Shadow Poser框架，一个三阶段管道，包括生成手分配模块探索合理手形假设、广义手影对齐模块推断粗糙姿势，以及影子特征感知精炼模块优化姿势以确保物理合理性和特征保留。该框架可在通用公共手部数据上训练，无需专门数据集，并构建了一个包含210个多样影子形状的基准数据集，使用DINOv2-based指标等进行评估。实验结果显示，该方法在85%以上的基准案例中成功生成双手手势，并优于多个基线模型。",
      "categories": [
        "cs.CG",
        "cs.AI"
      ],
      "primary_category": "cs.CG",
      "comment": "SIGGRAPH 2025 (ACM TOG)",
      "pdf_url": "http://arxiv.org/pdf/2505.07012v1",
      "published_date": "2025-05-11 15:15:35 UTC",
      "updated_date": "2025-05-11 15:15:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:45:00.544079"
    },
    {
      "arxiv_id": "2505.07005v1",
      "title": "Explainable AI the Latest Advancements and New Trends",
      "title_zh": "翻译失败",
      "authors": [
        "Bowen Long",
        "Enjie Liu",
        "Renxi Qiu",
        "Yanqing Duan"
      ],
      "abstract": "In recent years, Artificial Intelligence technology has excelled in various\napplications across all domains and fields. However, the various algorithms in\nneural networks make it difficult to understand the reasons behind decisions.\nFor this reason, trustworthy AI techniques have started gaining popularity. The\nconcept of trustworthiness is cross-disciplinary; it must meet societal\nstandards and principles, and technology is used to fulfill these requirements.\nIn this paper, we first surveyed developments from various countries and\nregions on the ethical elements that make AI algorithms trustworthy; and then\nfocused our survey on the state of the art research into the interpretability\nof AI. We have conducted an intensive survey on technologies and techniques\nused in making AI explainable. Finally, we identified new trends in achieving\nexplainable AI. In particular, we elaborate on the strong link between the\nexplainability of AI and the meta-reasoning of autonomous systems. The concept\nof meta-reasoning is 'reason the reasoning', which coincides with the intention\nand goal of explainable Al. The integration of the approaches could pave the\nway for future interpretable AI systems.",
      "tldr_zh": "这篇论文调查了 Explainable AI 的最新进展和新趋势，强调了 AI 算法的可信赖性及其在满足社会伦理标准中的重要性。作者首先审视了全球各国对 AI 信任伦理元素的政策和发展，然后对 AI 可解释性的技术进行了深入调研，包括各种使 AI 决策透明的方法。论文识别出 Explainable AI 与 meta-reasoning（对推理进行推理）的强联系，并提出整合这些方法以推进未来可解释自主系统的开发。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07005v1",
      "published_date": "2025-05-11 15:01:12 UTC",
      "updated_date": "2025-05-11 15:01:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:45:11.885561"
    },
    {
      "arxiv_id": "2505.06997v1",
      "title": "A Multi-Agent Reinforcement Learning Approach for Cooperative Air-Ground-Human Crowdsensing in Emergency Rescue",
      "title_zh": "翻译失败",
      "authors": [
        "Wenhao Lu",
        "Zhengqiu Zhu",
        "Yong Zhao",
        "Yonglin Tian",
        "Junjie Zeng",
        "Jun Zhang",
        "Zhong Liu",
        "Fei-Yue Wang"
      ],
      "abstract": "Mobile crowdsensing is evolving beyond traditional human-centric models by\nintegrating heterogeneous entities like unmanned aerial vehicles (UAVs) and\nunmanned ground vehicles (UGVs). Optimizing task allocation among these diverse\nagents is critical, particularly in challenging emergency rescue scenarios\ncharacterized by complex environments, limited communication, and partial\nobservability. This paper tackles the Heterogeneous-Entity\nCollaborative-Sensing Task Allocation (HECTA) problem specifically for\nemergency rescue, considering humans, UAVs, and UGVs. We introduce a novel\n``Hard-Cooperative'' policy where UGVs prioritize recharging low-battery UAVs,\nalongside performing their sensing tasks. The primary objective is maximizing\nthe task completion rate (TCR) under strict time constraints. We rigorously\nformulate this NP-hard problem as a decentralized partially observable Markov\ndecision process (Dec-POMDP) to effectively handle sequential decision-making\nunder uncertainty. To solve this, we propose HECTA4ER, a novel multi-agent\nreinforcement learning algorithm built upon a Centralized Training with\nDecentralized Execution architecture. HECTA4ER incorporates tailored designs,\nincluding specialized modules for complex feature extraction, utilization of\naction-observation history via hidden states, and a mixing network integrating\nglobal and local information, specifically addressing the challenges of partial\nobservability. Furthermore, theoretical analysis confirms the algorithm's\nconvergence properties. Extensive simulations demonstrate that HECTA4ER\nsignificantly outperforms baseline algorithms, achieving an average 18.42%\nincrease in TCR. Crucially, a real-world case study validates the algorithm's\neffectiveness and robustness in dynamic sensing scenarios, highlighting its\nstrong potential for practical application in emergency response.",
      "tldr_zh": "该论文提出了一种多智能体强化学习(Multi-Agent Reinforcement Learning)方法，用于紧急救援中的异构实体协作感知任务分配(HECTA)，涉及人类、UAVs(无人机)和UGVs(无人地面车辆)。作者引入“Hard-Cooperative”政策，让UGVs优先为低电量UAVs充电，同时优化任务分配，以最大化任务完成率(TCR)并处理部分可观察性和通信限制问题。问题被形式化为去中心化部分可观察Markov决策过程(Dec-POMDP)，并通过HECTA4ER算法解决，该算法采用集中训练与分散执行架构，结合复杂特征提取和混合网络设计。实验结果显示，HECTA4ER比基线算法平均提高18.42%的TCR，并在真实案例研究中证明了其在动态紧急响应场景中的有效性和鲁棒性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06997v1",
      "published_date": "2025-05-11 14:49:15 UTC",
      "updated_date": "2025-05-11 14:49:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:45:25.111384"
    },
    {
      "arxiv_id": "2505.06993v2",
      "title": "Technical Report: Quantifying and Analyzing the Generalization Power of a DNN",
      "title_zh": "技术报告：量化与分析 DNN 的泛化能力",
      "authors": [
        "Yuxuan He",
        "Junpeng Zhang",
        "Lei Cheng",
        "Hongyuan Zhang",
        "Quanshi Zhang"
      ],
      "abstract": "This paper proposes a new perspective for analyzing the generalization power\nof deep neural networks (DNNs), i.e., directly disentangling and analyzing the\ndynamics of generalizable and non-generalizable interaction encoded by a DNN\nthrough the training process. Specifically, this work builds upon the recent\ntheoretical achievement in explainble AI, which proves that the detailed\ninference logic of DNNs can be can be strictly rewritten as a small number of\nAND-OR interaction patterns. Based on this, we propose an efficient method to\nquantify the generalization power of each interaction, and we discover a\ndistinct three-phase dynamics of the generalization power of interactions\nduring training. In particular, the early phase of training typically removes\nnoisy and non-generalizable interactions and learns simple and generalizable\nones. The second and the third phases tend to capture increasingly complex\ninteractions that are harder to generalize. Experimental results verify that\nthe learning of non-generalizable interactions is the the direct cause for the\ngap between the training and testing losses.",
      "tldr_zh": "这篇论文提出了一种新视角，通过直接分离和分析深度神经网络 (DNNs) 中可泛化和不可泛化交互的动态，来量化其泛化能力。基于可解释 AI 的理论，该方法将 DNN 的推理逻辑重写为少量的 AND-OR interaction 模式，并发现训练过程存在三个阶段：早期移除噪声交互并学习简单可泛化交互，后续阶段则捕获更复杂且难以泛化的交互。实验验证显示，非泛化交互的学习是训练和测试损失差距的直接原因，为提升 DNN 泛化性能提供了新洞见。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06993v2",
      "published_date": "2025-05-11 14:37:30 UTC",
      "updated_date": "2025-05-20 15:25:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:45:35.952242"
    },
    {
      "arxiv_id": "2505.06987v1",
      "title": "Convert Language Model into a Value-based Strategic Planner",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoyu Wang",
        "Yue Zhao",
        "Qingqing Gu",
        "Zhonglin Jiang",
        "Xiaokai Chen",
        "Yong Chen",
        "Luo Ji"
      ],
      "abstract": "Emotional support conversation (ESC) aims to alleviate the emotional distress\nof individuals through effective conversations. Although large language models\n(LLMs) have obtained remarkable progress on ESC, most of these studies might\nnot define the diagram from the state model perspective, therefore providing a\nsuboptimal solution for long-term satisfaction. To address such an issue, we\nleverage the Q-learning on LLMs, and propose a framework called straQ*. Our\nframework allows a plug-and-play LLM to bootstrap the planning during ESC,\ndetermine the optimal strategy based on long-term returns, and finally guide\nthe LLM to response. Substantial experiments on ESC datasets suggest that\nstraQ* outperforms many baselines, including direct inference, self-refine,\nchain of thought, finetuning, and finite state machines.",
      "tldr_zh": "这篇论文提出了一种名为 straQ* 的框架，将大型语言模型 (LLMs) 转化为基于价值的战略规划器，以提升情感支持对话 (ESC) 的长期满意度。框架通过应用 Q-learning 技术，使 LLMs 能够进行规划、评估长期回报并选择最优策略，从而指导对话响应。实验结果显示，straQ* 在 ESC 数据集上优于多项基线，包括直接推理、链式思考、微调和有限状态机等。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages, 5 figures, Accepted by ACL 2025 Industry Track",
      "pdf_url": "http://arxiv.org/pdf/2505.06987v1",
      "published_date": "2025-05-11 14:13:58 UTC",
      "updated_date": "2025-05-11 14:13:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:45:48.218557"
    },
    {
      "arxiv_id": "2505.06977v2",
      "title": "CAT Merging: A Training-Free Approach for Resolving Conflicts in Model Merging",
      "title_zh": "翻译失败",
      "authors": [
        "Wenju Sun",
        "Qingyong Li",
        "Yangli-ao Geng",
        "Boyang Li"
      ],
      "abstract": "Multi-task model merging offers a promising paradigm for integrating multiple\nexpert models into a unified model without additional training. Existing\nstate-of-the-art techniques, such as Task Arithmetic and its variants, merge\nmodels by accumulating task vectors -- the parameter differences between\npretrained and finetuned models. However, task vector accumulation is often\nhindered by knowledge conflicts, leading to performance degradation. To address\nthis challenge, we propose Conflict-Aware Task Merging (CAT Merging), a novel\ntraining-free framework that selectively trims conflict-prone components from\nthe task vectors. CAT Merging introduces several parameter-specific strategies,\nincluding projection for linear weights and masking for scaling and shifting\nparameters in normalization layers. Extensive experiments on vision, language,\nand vision-language tasks demonstrate that CAT Merging effectively suppresses\nknowledge conflicts, achieving average accuracy improvements of up to 2.5%\n(ViT-B/32) and 2.0% (ViT-L/14) over state-of-the-art methods.",
      "tldr_zh": "本文提出 CAT Merging，一种无需训练的框架，用于解决多任务模型合并中的知识冲突问题。该方法通过选择性地修剪任务向量中的冲突-prone 组件，并采用参数特定策略，如投影(linear weights)和掩码(scaling and shifting parameters in normalization layers)，来优化合并过程。实验结果显示，在视觉、语言和视觉-语言任务上，CAT Merging 相较于 Task Arithmetic 等现有方法，平均准确率提升高达 2.5% (ViT-B/32) 和 2.0% (ViT-L/14)。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06977v2",
      "published_date": "2025-05-11 13:24:09 UTC",
      "updated_date": "2025-05-14 14:11:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:46:00.288965"
    },
    {
      "arxiv_id": "2505.06964v2",
      "title": "Bridging AI and Carbon Capture: A Dataset for LLMs in Ionic Liquids and CBE Research",
      "title_zh": "翻译失败",
      "authors": [
        "Gaurab Sarkar",
        "Sougata Saha"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated exceptional performance in\ngeneral knowledge and reasoning tasks across various domains. However, their\neffectiveness in specialized scientific fields like Chemical and Biological\nEngineering (CBE) remains underexplored. Addressing this gap requires robust\nevaluation benchmarks that assess both knowledge and reasoning capabilities in\nthese niche areas, which are currently lacking. To bridge this divide, we\npresent a comprehensive empirical analysis of LLM reasoning capabilities in\nCBE, with a focus on Ionic Liquids (ILs) for carbon sequestration - an emerging\nsolution for mitigating global warming. We develop and release an expert -\ncurated dataset of 5,920 examples designed to benchmark LLMs' reasoning in this\ndomain. The dataset incorporates varying levels of difficulty, balancing\nlinguistic complexity and domain-specific knowledge. Using this dataset, we\nevaluate three open-source LLMs with fewer than 10 billion parameters. Our\nfindings reveal that while smaller general-purpose LLMs exhibit basic knowledge\nof ILs, they lack the specialized reasoning skills necessary for advanced\napplications. Building on these results, we discuss strategies to enhance the\nutility of LLMs for carbon capture research, particularly using ILs. Given the\nsignificant carbon footprint of LLMs, aligning their development with IL\nresearch presents a unique opportunity to foster mutual progress in both fields\nand advance global efforts toward achieving carbon neutrality by 2050.",
      "tldr_zh": "这篇论文探讨了大型语言模型（LLMs）在化学和生物工程（CBE）领域的应用，特别针对离子液体（ILs）用于碳捕获的推理能力。研究者开发并发布了一个由专家策划的数据集，包含5,920个例子，以不同难度级别评估LLMs的知识和推理表现，并评估了三个参数少于10亿的开源LLMs。结果显示，这些模型具备基本ILs知识但缺乏高级推理技能，论文因此提出策略来提升LLMs在碳捕获研究中的效用，并强调将AI发展与ILs研究整合，以推动碳中和目标。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06964v2",
      "published_date": "2025-05-11 12:32:57 UTC",
      "updated_date": "2025-05-17 05:08:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:46:13.292978"
    },
    {
      "arxiv_id": "2505.06963v1",
      "title": "Reinforcement Learning-Based Monocular Vision Approach for Autonomous UAV Landing",
      "title_zh": "翻译失败",
      "authors": [
        "Tarik Houichime",
        "Younes EL Amrani"
      ],
      "abstract": "This paper introduces an innovative approach for the autonomous landing of\nUnmanned Aerial Vehicles (UAVs) using only a front-facing monocular camera,\ntherefore obviating the requirement for depth estimation cameras. Drawing on\nthe inherent human estimating process, the proposed method reframes the landing\ntask as an optimization problem. The UAV employs variations in the visual\ncharacteristics of a specially designed lenticular circle on the landing pad,\nwhere the perceived color and form provide critical information for estimating\nboth altitude and depth. Reinforcement learning algorithms are utilized to\napproximate the functions governing these estimations, enabling the UAV to\nascertain ideal landing settings via training. This method's efficacy is\nassessed by simulations and experiments, showcasing its potential for robust\nand accurate autonomous landing without dependence on complex sensor setups.\nThis research contributes to the advancement of cost-effective and efficient\nUAV landing solutions, paving the way for wider applicability across various\nfields.",
      "tldr_zh": "本研究提出了一种基于强化学习（Reinforcement Learning）的单目视觉方法，用于无人驾驶飞行器（UAV）的自主着陆，仅依赖前置单目摄像头，而无需深度估计传感器。通过借鉴人类估计过程，将着陆任务转化为优化问题，利用着陆垫上的特殊设计透镜圆（lenticular circle）的颜色和形状变化来估计高度和深度。强化学习算法通过训练近似这些估计函数，帮助UAV确定理想着陆设置。模拟和实验结果证明，该方法具有鲁棒性和高准确性，为成本效益高的UAV着陆解决方案提供了新途径，适用于多种领域。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06963v1",
      "published_date": "2025-05-11 12:23:37 UTC",
      "updated_date": "2025-05-11 12:23:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:46:23.971206"
    },
    {
      "arxiv_id": "2505.06949v1",
      "title": "Causal knowledge graph analysis identifies adverse drug effects",
      "title_zh": "翻译失败",
      "authors": [
        "Sumyyah Toonsi",
        "Paul Schofield",
        "Robert Hoehndorf"
      ],
      "abstract": "Knowledge graphs and structural causal models have each proven valuable for\norganizing biomedical knowledge and estimating causal effects, but remain\nlargely disconnected: knowledge graphs encode qualitative relationships\nfocusing on facts and deductive reasoning without formal probabilistic\nsemantics, while causal models lack integration with background knowledge in\nknowledge graphs and have no access to the deductive reasoning capabilities\nthat knowledge graphs provide. To bridge this gap, we introduce a novel\nformulation of Causal Knowledge Graphs (CKGs) which extend knowledge graphs\nwith formal causal semantics, preserving their deductive capabilities while\nenabling principled causal inference. CKGs support deconfounding via explicitly\nmarked causal edges and facilitate hypothesis formulation aligned with both\nencoded and entailed background knowledge. We constructed a Drug-Disease CKG\n(DD-CKG) integrating disease progression pathways, drug indications,\nside-effects, and hierarchical disease classification to enable automated\nlarge-scale mediation analysis. Applied to UK Biobank and MIMIC-IV cohorts, we\ntested whether drugs mediate effects between indications and downstream disease\nprogression, adjusting for confounders inferred from the DD-CKG. Our approach\nsuccessfully reproduced known adverse drug reactions with high precision while\nidentifying previously undocumented significant candidate adverse effects.\nFurther validation through side effect similarity analysis demonstrated that\ncombining our predicted drug effects with established databases significantly\nimproves the prediction of shared drug indications, supporting the clinical\nrelevance of our novel findings. These results demonstrate that our methodology\nprovides a generalizable, knowledge-driven framework for scalable causal\ninference.",
      "tldr_zh": "本研究引入了Causal Knowledge Graphs (CKGs)，一种扩展知识图谱的框架，赋予其正式的因果语义，同时保留演绎推理能力，从而桥接知识图谱和结构因果模型在生物医学领域的应用。研究构建了Drug-Disease CKG (DD-CKG)，整合疾病进展路径、药物适应症、副作用及分层疾病分类，用于自动化大规模mediation analysis，并通过显式因果边处理混杂因素。在UK Biobank和MIMIC-IV队列上应用该框架后，成功再现已知不良药物反应，并识别出新的候选不良效果，进一步通过副作用相似性分析验证其临床相关性。这些结果展示了CKGs作为一种可推广的、基于知识的框架，用于可扩展的因果推理的潜力。",
      "categories": [
        "cs.AI",
        "q-bio.BM"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06949v1",
      "published_date": "2025-05-11 11:35:43 UTC",
      "updated_date": "2025-05-11 11:35:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:46:38.202050"
    },
    {
      "arxiv_id": "2505.06936v1",
      "title": "AI-Powered Inverse Design of Ku-Band SIW Resonant Structures by Iterative Residual Correction Network",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammad Mashayekhi",
        "Kamran Salehian"
      ],
      "abstract": "Inverse electromagnetic modeling has emerged as a powerful approach for\ndesigning complex microwave structures with high accuracy and efficiency. In\nthis study, we propose an Iterative Residual Correction Network (IRC-Net) for\nthe inverse design of Ku-band Substrate Integrated Waveguide (SIW) components\nbased on multimode resonators. We use a multimode resonance structure to\ndemonstrate that it is possible to control the resonances of the structure.\nTherefore, these structures can be used for resonant components and smart\nfilter design. The proposed deep learning architecture leverages residual\nneural networks to overcome the limitations of traditional inverse design\ntechniques, such as the Feedforward Inverse Model (FIM), offering improved\ngeneralization and prediction accuracy. The approach begins with a FIM to\ngenerate initial design estimates, followed by an iterative correction strategy\ninspired by the Hybrid Inverse-Forward Residual Refinement Network\n(HiFR\\textsuperscript{2}-Net), which we call IRC-Net. Experiments demonstrate\nthat the IRC-Net achieves substantial improvements in prediction accuracy\ncompared to traditional single-stage networks, validated through statistical\nmetrics, full-wave electromagnetic simulations, and measurements. To validate\nthe proposed framework, we first design and fabricate a three-resonance SIW\nstructure. Next, we apply the trained IRC-Net model to predict the geometry of\na four-resonance structure based on its desired frequency response. Both\ndesigns are fabricated and tested, showing strong agreement between the\nsimulated, predicted, and measured results, confirming the effectiveness and\npracticality of the proposed method.",
      "tldr_zh": "本研究提出了一种基于人工智能的 Iterative Residual Correction Network (IRC-Net)，用于 Ku-band Substrate Integrated Waveguide (SIW) 谐振结构的反向设计，通过多模态谐振结构实现对谐振的精确控制，以应用于谐振组件和智能滤波器设计。IRC-Net 结合 Feedforward Inverse Model (FIM) 生成初始设计估计，并采用迭代修正策略，基于残差神经网络提升预测准确性和泛化能力。实验结果显示，该方法在统计指标、全波电磁模拟和实际测量中比传统单阶段网络提高了预测准确性；通过设计、制作并测试三谐振和四谐振 SIW 结构，模拟、预测与测量结果高度一致，验证了其有效性和实用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.06936v1",
      "published_date": "2025-05-11 10:51:43 UTC",
      "updated_date": "2025-05-11 10:51:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:46:48.649126"
    },
    {
      "arxiv_id": "2505.11526v1",
      "title": "Code Retrieval for MILP Instance Generation",
      "title_zh": "MILP 实例生成的代码检索",
      "authors": [
        "Tianxing Yang",
        "Huigen Ye",
        "Hua Xu"
      ],
      "abstract": "Mixed-Integer Linear Programming (MILP) is widely used in fields such as\nscheduling, logistics, and planning. Enhancing the performance of MILP solvers,\nparticularly learning-based solvers, requires substantial amounts of\nhigh-quality data. However, existing methods for MILP instance generation\ntypically necessitate training a separate model for each problem class and are\ncomputationally intensive when generating new instances. To address these\nlimitations, we reformulate the MILP Instance Generation task as MILP Code\nGeneration task, enabling efficient, flexible, and interpretable instance\ngeneration through code. Since MILP instances generated from code can vary\nsignificantly in scale, we introduce MILP-EmbedSim, a new similarity metric\nthat accurately measures the similarity between instances of varying sizes\nwithin the same problem class. Leveraging this metric, we propose\nMILP-Retrieval, a pipeline that retrieves generation code from library to\nproduce MILP instances highly similar to target instance. MILP-Retrieval\noutperforms baselines in both MILP Code Generation and Instance Generation\ntasks, provides a novel perspective on MILP instance generation and opens new\npossibilities for learning-based solvers.",
      "tldr_zh": "这篇论文针对 Mixed-Integer Linear Programming (MILP) 实例生成的效率问题，将其重新表述为 MILP 代码生成任务，从而实现高效、灵活且可解释的实例生成。论文引入了 MILP-EmbedSim，一种新颖的相似度度量，用于评估同一问题类别中不同规模实例的相似性。基于此，他们提出 MILP-Retrieval 管道，通过从库中检索代码来生成与目标实例高度相似的 MILP 实例，并在代码生成和实例生成任务中优于基线方法，为基于学习的 MILP 求解器提供了新视角和可能性。",
      "categories": [
        "math.OC",
        "cs.AI"
      ],
      "primary_category": "math.OC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11526v1",
      "published_date": "2025-05-11 10:41:44 UTC",
      "updated_date": "2025-05-11 10:41:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:47:00.847035"
    },
    {
      "arxiv_id": "2505.06913v1",
      "title": "RedTeamLLM: an Agentic AI framework for offensive security",
      "title_zh": "翻译失败",
      "authors": [
        "Brian Challita",
        "Pierre Parrend"
      ],
      "abstract": "From automated intrusion testing to discovery of zero-day attacks before\nsoftware launch, agentic AI calls for great promises in security engineering.\nThis strong capability is bound with a similar threat: the security and\nresearch community must build up its models before the approach is leveraged by\nmalicious actors for cybercrime. We therefore propose and evaluate RedTeamLLM,\nan integrated architecture with a comprehensive security model for\nautomatization of pentest tasks. RedTeamLLM follows three key steps:\nsummarizing, reasoning and act, which embed its operational capacity. This\nnovel framework addresses four open challenges: plan correction, memory\nmanagement, context window constraint, and generality vs. specialization.\nEvaluation is performed through the automated resolution of a range of\nentry-level, but not trivial, CTF challenges. The contribution of the reasoning\ncapability of our agentic AI framework is specifically evaluated.",
      "tldr_zh": "本论文提出 RedTeamLLM，这是一个 Agentic AI 框架，用于 offensive security 中的自动化渗透测试任务，以防范恶意 actor 利用 AI 进行网络犯罪。该框架基于三个关键步骤：summarizing（总结）、reasoning（推理）和 act（行动），有效解决了 plan correction、memory management、context window constraint 以及 generality vs. specialization 等开放挑战。通过在多种 entry-level CTF 挑战中的评估，RedTeamLLM 展示了其推理能力的显著贡献，为安全工程提供了可靠的自动化工具。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06913v1",
      "published_date": "2025-05-11 09:19:10 UTC",
      "updated_date": "2025-05-11 09:19:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:47:12.587398"
    },
    {
      "arxiv_id": "2505.06911v1",
      "title": "MMiC: Mitigating Modality Incompleteness in Clustered Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Lishan Yang",
        "Wei Zhang",
        "Quan Z. Sheng",
        "Weitong Chen",
        "Lina Yao",
        "Weitong Chen",
        "Ali Shakeri"
      ],
      "abstract": "In the era of big data, data mining has become indispensable for uncovering\nhidden patterns and insights from vast and complex datasets. The integration of\nmultimodal data sources further enhances its potential. Multimodal Federated\nLearning (MFL) is a distributed approach that enhances the efficiency and\nquality of multimodal learning, ensuring collaborative work and privacy\nprotection. However, missing modalities pose a significant challenge in MFL,\noften due to data quality issues or privacy policies across the clients. In\nthis work, we present MMiC, a framework for Mitigating Modality incompleteness\nin MFL within the Clusters. MMiC replaces partial parameters within client\nmodels inside clusters to mitigate the impact of missing modalities.\nFurthermore, it leverages the Banzhaf Power Index to optimize client selection\nunder these conditions. Finally, MMiC employs an innovative approach to\ndynamically control global aggregation by utilizing Markovitz Portfolio\nOptimization. Extensive experiments demonstrate that MMiC consistently\noutperforms existing federated learning architectures in both global and\npersonalized performance on multimodal datasets with missing modalities,\nconfirming the effectiveness of our proposed solution.",
      "tldr_zh": "该论文提出 MMiC 框架，用于缓解多模态联邦学习（MFL）中模态不完整性的问题，尤其针对集群环境中的缺失模态挑战。MMiC 通过替换集群内客户端模型的部分参数、利用 Banzhaf Power Index 优化客户端选择，以及采用 Markovitz Portfolio Optimization 动态控制全局聚合，来提升模型的鲁棒性和性能。实验结果表明，MMiC 在包含缺失模态的多模态数据集上，比现有联邦学习架构在全局和个性化性能上表现出色，验证了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.11; I.2.7"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 10 figures, it's KDD'2025 under reviewing",
      "pdf_url": "http://arxiv.org/pdf/2505.06911v1",
      "published_date": "2025-05-11 09:12:36 UTC",
      "updated_date": "2025-05-11 09:12:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:47:24.607523"
    },
    {
      "arxiv_id": "2505.06907v1",
      "title": "Towards Artificial General or Personalized Intelligence? A Survey on Foundation Models for Personalized Federated Intelligence",
      "title_zh": "通往人工通用智能还是个性化智能？ 关于用于个性化联邦智能的基础模型的调查",
      "authors": [
        "Yu Qiao",
        "Huy Q. Le",
        "Avi Deb Raha",
        "Phuong-Nam Tran",
        "Apurba Adhikary",
        "Mengchun Zhang",
        "Loc X. Nguyen",
        "Eui-Nam Huh",
        "Dusit Niyato",
        "Choong Seon Hong"
      ],
      "abstract": "The rise of large language models (LLMs), such as ChatGPT, DeepSeek, and\nGrok-3, has reshaped the artificial intelligence landscape. As prominent\nexamples of foundational models (FMs) built on LLMs, these models exhibit\nremarkable capabilities in generating human-like content, bringing us closer to\nachieving artificial general intelligence (AGI). However, their large-scale\nnature, sensitivity to privacy concerns, and substantial computational demands\npresent significant challenges to personalized customization for end users. To\nbridge this gap, this paper presents the vision of artificial personalized\nintelligence (API), focusing on adapting these powerful models to meet the\nspecific needs and preferences of users while maintaining privacy and\nefficiency. Specifically, this paper proposes personalized federated\nintelligence (PFI), which integrates the privacy-preserving advantages of\nfederated learning (FL) with the zero-shot generalization capabilities of FMs,\nenabling personalized, efficient, and privacy-protective deployment at the\nedge. We first review recent advances in both FL and FMs, and discuss the\npotential of leveraging FMs to enhance federated systems. We then present the\nkey motivations behind realizing PFI and explore promising opportunities in\nthis space, including efficient PFI, trustworthy PFI, and PFI empowered by\nretrieval-augmented generation (RAG). Finally, we outline key challenges and\nfuture research directions for deploying FM-powered FL systems at the edge with\nimproved personalization, computational efficiency, and privacy guarantees.\nOverall, this survey aims to lay the groundwork for the development of API as a\ncomplement to AGI, with a particular focus on PFI as a key enabling technique.",
      "tldr_zh": "这篇调查论文探讨了从人工通用智能(AGI)转向人工个性化智能(API)的愿景，强调了如何适应大型语言模型(FMs)如ChatGPT以满足用户特定需求，同时解决隐私和计算效率问题。主要贡献是提出个性化联邦智能(PFI)，它结合联邦学习(FL)的隐私保护优势与FMs的零样本泛化能力，实现高效的边缘部署。论文回顾了FL和FMs的最新进展，探讨了PFI的动机和机会（如高效PFI、可信PFI以及检索增强生成(RAG)的赋能），并概述了关键挑战和未来方向，以推动API作为AGI的补充发展。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "On going work",
      "pdf_url": "http://arxiv.org/pdf/2505.06907v1",
      "published_date": "2025-05-11 08:57:53 UTC",
      "updated_date": "2025-05-11 08:57:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:47:37.467915"
    },
    {
      "arxiv_id": "2505.06897v1",
      "title": "Embodied Intelligence: The Key to Unblocking Generalized Artificial Intelligence",
      "title_zh": "具身智能：解锁通用人工智能的关键",
      "authors": [
        "Jinhao Jiang",
        "Changlin Chen",
        "Shile Feng",
        "Wanru Geng",
        "Zesheng Zhou",
        "Ni Wang",
        "Shuai Li",
        "Feng-Qi Cui",
        "Erbao Dong"
      ],
      "abstract": "The ultimate goal of artificial intelligence (AI) is to achieve Artificial\nGeneral Intelligence (AGI). Embodied Artificial Intelligence (EAI), which\ninvolves intelligent systems with physical presence and real-time interaction\nwith the environment, has emerged as a key research direction in pursuit of\nAGI. While advancements in deep learning, reinforcement learning, large-scale\nlanguage models, and multimodal technologies have significantly contributed to\nthe progress of EAI, most existing reviews focus on specific technologies or\napplications. A systematic overview, particularly one that explores the direct\nconnection between EAI and AGI, remains scarce. This paper examines EAI as a\nfoundational approach to AGI, systematically analyzing its four core modules:\nperception, intelligent decision-making, action, and feedback. We provide a\ndetailed discussion of how each module contributes to the six core principles\nof AGI. Additionally, we discuss future trends, challenges, and research\ndirections in EAI, emphasizing its potential as a cornerstone for AGI\ndevelopment. Our findings suggest that EAI's integration of dynamic learning\nand real-world interaction is essential for bridging the gap between narrow AI\nand AGI.",
      "tldr_zh": "这篇论文探讨了Embodied Artificial Intelligence (EAI)作为实现Artificial General Intelligence (AGI)的关键途径，强调EAI通过物理存在和实时环境互动来弥补现有AI技术的局限。论文系统分析了EAI的四个核心模块——perception、intelligent decision-making、action和feedback，以及这些模块如何支持AGI的六个核心原则。研究发现，EAI的动态学习和真实世界互动能有效桥接narrow AI与AGI的差距，并指出了未来趋势、挑战和研究方向，为AGI发展奠定基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "19pages,7 figures,3 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.06897v1",
      "published_date": "2025-05-11 08:29:20 UTC",
      "updated_date": "2025-05-11 08:29:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:47:49.594712"
    },
    {
      "arxiv_id": "2505.06894v1",
      "title": "NeuGen: Amplifying the 'Neural' in Neural Radiance Fields for Domain Generalization",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmed Qazi",
        "Abdul Basit",
        "Asim Iqbal"
      ],
      "abstract": "Neural Radiance Fields (NeRF) have significantly advanced the field of novel\nview synthesis, yet their generalization across diverse scenes and conditions\nremains challenging. Addressing this, we propose the integration of a novel\nbrain-inspired normalization technique Neural Generalization (NeuGen) into\nleading NeRF architectures which include MVSNeRF and GeoNeRF. NeuGen extracts\nthe domain-invariant features, thereby enhancing the models' generalization\ncapabilities. It can be seamlessly integrated into NeRF architectures and\ncultivates a comprehensive feature set that significantly improves accuracy and\nrobustness in image rendering. Through this integration, NeuGen shows improved\nperformance on benchmarks on diverse datasets across state-of-the-art NeRF\narchitectures, enabling them to generalize better across varied scenes. Our\ncomprehensive evaluations, both quantitative and qualitative, confirm that our\napproach not only surpasses existing models in generalizability but also\nmarkedly improves rendering quality. Our work exemplifies the potential of\nmerging neuroscientific principles with deep learning frameworks, setting a new\nprecedent for enhanced generalizability and efficiency in novel view synthesis.\nA demo of our study is available at https://neugennerf.github.io.",
      "tldr_zh": "这项研究针对 Neural Radiance Fields (NeRF) 在不同场景和条件下的泛化挑战，提出了一种脑启发的归一化技术 NeuGen，并将其整合到 MVSNeRF 和 GeoNeRF 等领先架构中，以提取领域不变特征并提升模型的准确性和鲁棒性。NeuGen 通过无缝集成，显著改善了图像渲染性能，并在多样数据集的基准测试中超越现有模型。实验结果显示，该方法不仅在定量和定性评估中表现出更高的泛化能力，还展示了将神经科学原则与深度学习框架相结合的创新潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.06894v1",
      "published_date": "2025-05-11 08:17:33 UTC",
      "updated_date": "2025-05-11 08:17:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:48:00.852064"
    },
    {
      "arxiv_id": "2505.06889v1",
      "title": "IM-BERT: Enhancing Robustness of BERT through the Implicit Euler Method",
      "title_zh": "IM-BERT：通过隐式欧拉方法增强 BERT 的鲁棒性",
      "authors": [
        "Mihyeon Kim",
        "Juhyoung Park",
        "Youngbin Kim"
      ],
      "abstract": "Pre-trained Language Models (PLMs) have achieved remarkable performance on\ndiverse NLP tasks through pre-training and fine-tuning. However, fine-tuning\nthe model with a large number of parameters on limited downstream datasets\noften leads to vulnerability to adversarial attacks, causing overfitting of the\nmodel on standard datasets.\n  To address these issues, we propose IM-BERT from the perspective of a dynamic\nsystem by conceptualizing a layer of BERT as a solution of Ordinary\nDifferential Equations (ODEs). Under the situation of initial value\nperturbation, we analyze the numerical stability of two main numerical ODE\nsolvers: the explicit and implicit Euler approaches.\n  Based on these analyses, we introduce a numerically robust IM-connection\nincorporating BERT's layers. This strategy enhances the robustness of PLMs\nagainst adversarial attacks, even in low-resource scenarios, without\nintroducing additional parameters or adversarial training strategies.\n  Experimental results on the adversarial GLUE (AdvGLUE) dataset validate the\nrobustness of IM-BERT under various conditions. Compared to the original BERT,\nIM-BERT exhibits a performance improvement of approximately 8.3\\%p on the\nAdvGLUE dataset. Furthermore, in low-resource scenarios, IM-BERT outperforms\nBERT by achieving 5.9\\%p higher accuracy.",
      "tldr_zh": "本研究针对预训练语言模型(PLMs)如BERT在微调时易受对抗攻击和过拟合的问题，提出IM-BERT方法，将BERT层视为普通微分方程(ODEs)的解，并采用Implicit Euler Method分析数值稳定性。\nIM-BERT引入隐式连接(IM-connection)来增强模型鲁棒性，即使在低资源场景下，也无需额外参数或对抗训练。\n实验结果显示，在AdvGLUE数据集上，IM-BERT比原BERT提高了约8.3%的性能；在低资源场景下，准确率提升了5.9%。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EMNLP 2024 Main",
      "pdf_url": "http://arxiv.org/pdf/2505.06889v1",
      "published_date": "2025-05-11 07:54:33 UTC",
      "updated_date": "2025-05-11 07:54:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:48:12.359545"
    },
    {
      "arxiv_id": "2505.06886v1",
      "title": "Mice to Machines: Neural Representations from Visual Cortex for Domain Generalization",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmed Qazi",
        "Hamd Jalil",
        "Asim Iqbal"
      ],
      "abstract": "The mouse is one of the most studied animal models in the field of systems\nneuroscience. Understanding the generalized patterns and decoding the neural\nrepresentations that are evoked by the diverse range of natural scene stimuli\nin the mouse visual cortex is one of the key quests in computational vision. In\nrecent years, significant parallels have been drawn between the primate visual\ncortex and hierarchical deep neural networks. However, their generalized\nefficacy in understanding mouse vision has been limited. In this study, we\ninvestigate the functional alignment between the mouse visual cortex and deep\nlearning models for object classification tasks. We first introduce a\ngeneralized representational learning strategy that uncovers a striking\nresemblance between the functional mapping of the mouse visual cortex and\nhigh-performing deep learning models on both top-down (population-level) and\nbottom-up (single cell-level) scenarios. Next, this representational similarity\nacross the two systems is further enhanced by the addition of Neural Response\nNormalization (NeuRN) layer, inspired by the activation profile of excitatory\nand inhibitory neurons in the visual cortex. To test the performance effect of\nNeuRN on real-world tasks, we integrate it into deep learning models and\nobserve significant improvements in their robustness against data shifts in\ndomain generalization tasks. Our work proposes a novel framework for comparing\nthe functional architecture of the mouse visual cortex with deep learning\nmodels. Our findings carry broad implications for the development of advanced\nAI models that draw inspiration from the mouse visual cortex, suggesting that\nthese models serve as valuable tools for studying the neural representations of\nthe mouse visual cortex and, as a result, enhancing their performance on\nreal-world tasks.",
      "tldr_zh": "本研究探讨了小鼠视觉皮层(neural representations)的功能映射与深度学习模型的相似性，以提升领域泛化(domain generalization)任务的性能。研究者引入了一种泛化表示学习策略，在top-down (population-level)和bottom-up (single cell-level)层面揭示了小鼠视觉皮层与高性能深度学习模型的显著相似性。接着，他们开发了Neural Response Normalization (NeuRN)层，模拟视觉皮层中兴奋和抑制神经元的激活模式，并将其整合到深度学习模型中，导致模型在面对数据偏移时鲁棒性显著提升。该框架为比较小鼠视觉皮层与AI模型的功能架构提供了新途径，并暗示从神经生物学中汲取灵感可增强AI在实际任务中的表现。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 8 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2505.06886v1",
      "published_date": "2025-05-11 07:37:37 UTC",
      "updated_date": "2025-05-11 07:37:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:48:24.881833"
    },
    {
      "arxiv_id": "2505.06883v2",
      "title": "FACET: Force-Adaptive Control via Impedance Reference Tracking for Legged Robots",
      "title_zh": "翻译失败",
      "authors": [
        "Botian Xu",
        "Haoyang Weng",
        "Qingzhou Lu",
        "Yang Gao",
        "Huazhe Xu"
      ],
      "abstract": "Reinforcement learning (RL) has made significant strides in legged robot\ncontrol, enabling locomotion across diverse terrains and complex\nloco-manipulation capabilities. However, the commonly used position or velocity\ntracking-based objectives are agnostic to forces experienced by the robot,\nleading to stiff and potentially dangerous behaviors and poor control during\nforceful interactions. To address this limitation, we present\n\\emph{Force-Adaptive Control via Impedance Reference Tracking} (FACET).\nInspired by impedance control, we use RL to train a control policy to imitate a\nvirtual mass-spring-damper system, allowing fine-grained control under external\nforces by manipulating the virtual spring. In simulation, we demonstrate that\nour quadruped robot achieves improved robustness to large impulses (up to 200\nNs) and exhibits controllable compliance, achieving an 80% reduction in\ncollision impulse. The policy is deployed to a physical robot to showcase both\ncompliance and the ability to engage with large forces by kinesthetic control\nand pulling payloads up to 2/3 of its weight. Further extension to a legged\nloco-manipulator and a humanoid shows the applicability of our method to more\ncomplex settings to enable whole-body compliance control. Project Website:\nhttps://facet.pages.dev/",
      "tldr_zh": "该研究提出FACET（Force-Adaptive Control via Impedance Reference Tracking）方法，利用Reinforcement Learning (RL)训练控制策略来模仿虚拟的mass-spring-damper系统，从而实现腿部机器人对外部力的精细控制，解决传统基于位置或速度跟踪的目标导致的僵硬行为问题。在模拟实验中，四足机器人展示了增强的鲁棒性，能承受高达200 Ns的冲击并将碰撞冲量减少80%。实际部署证明了FACET的顺从性，例如通过动觉控制拉动相当于机器人体重2/3的负载，并扩展适用于腿部loco-manipulator和人形机器人，实现全身顺从控制。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06883v2",
      "published_date": "2025-05-11 07:23:26 UTC",
      "updated_date": "2025-05-19 11:28:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:48:36.642868"
    },
    {
      "arxiv_id": "2505.06881v1",
      "title": "NeuRN: Neuro-inspired Domain Generalization for Image Classification",
      "title_zh": "NeuRN：神经启发的图像分类领域泛化",
      "authors": [
        "Hamd Jalil",
        "Ahmed Qazi",
        "Asim Iqbal"
      ],
      "abstract": "Domain generalization in image classification is a crucial challenge, with\nmodels often failing to generalize well across unseen datasets. We address this\nissue by introducing a neuro-inspired Neural Response Normalization (NeuRN)\nlayer which draws inspiration from neurons in the mammalian visual cortex,\nwhich aims to enhance the performance of deep learning architectures on unseen\ntarget domains by training deep learning models on a source domain. The\nperformance of these models is considered as a baseline and then compared\nagainst models integrated with NeuRN on image classification tasks. We perform\nexperiments across a range of deep learning architectures, including ones\nderived from Neural Architecture Search and Vision Transformer. Additionally,\nin order to shortlist models for our experiment from amongst the vast range of\ndeep neural networks available which have shown promising results, we also\npropose a novel method that uses the Needleman-Wunsch algorithm to compute\nsimilarity between deep learning architectures. Our results demonstrate the\neffectiveness of NeuRN by showing improvement against baseline in cross-domain\nimage classification tasks. Our framework attempts to establish a foundation\nfor future neuro-inspired deep learning models.",
      "tldr_zh": "这篇论文针对图像分类中的 Domain Generalization 问题，提出了一种受神经元启发的 Neural Response Normalization (NeuRN) 层，灵感来源于哺乳动物视觉皮层，以提升模型在未见目标域上的泛化性能。研究方法包括将 NeuRN 集成到多种深度学习架构（如 Neural Architecture Search 和 Vision Transformer 衍生模型）中进行训练，并引入 Needleman-Wunsch 算法来计算架构相似性以筛选实验模型。结果显示，NeuRN 显著提高了基线模型在跨域图像分类任务中的性能，为未来神经启发深度学习框架奠定基础。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.CV",
      "comment": "14 pages, 7 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2505.06881v1",
      "published_date": "2025-05-11 07:20:11 UTC",
      "updated_date": "2025-05-11 07:20:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:48:48.081044"
    },
    {
      "arxiv_id": "2505.06874v1",
      "title": "Enhancing Time Series Forecasting via a Parallel Hybridization of ARIMA and Polynomial Classifiers",
      "title_zh": "通过 ARIMA 与多项式分类器的并行混合增强时间序列预测",
      "authors": [
        "Thanh Son Nguyen",
        "Van Thanh Nguyen",
        "Dang Minh Duc Nguyen"
      ],
      "abstract": "Time series forecasting has attracted significant attention, leading to the\nde-velopment of a wide range of approaches, from traditional statistical\nmeth-ods to advanced deep learning models. Among them, the Auto-Regressive\nIntegrated Moving Average (ARIMA) model remains a widely adopted linear\ntechnique due to its effectiveness in modeling temporal dependencies in\neconomic, industrial, and social data. On the other hand, polynomial\nclassifi-ers offer a robust framework for capturing non-linear relationships\nand have demonstrated competitive performance in domains such as stock price\npre-diction. In this study, we propose a hybrid forecasting approach that\ninte-grates the ARIMA model with a polynomial classifier to leverage the\ncom-plementary strengths of both models. The hybrid method is evaluated on\nmultiple real-world time series datasets spanning diverse domains. Perfor-mance\nis assessed based on forecasting accuracy and computational effi-ciency.\nExperimental results reveal that the proposed hybrid model consist-ently\noutperforms the individual models in terms of prediction accuracy, al-beit with\na modest increase in execution time.",
      "tldr_zh": "这篇论文提出了一种混合时间序列预测方法，通过将 ARIMA 模型与 polynomial classifiers 并行结合，充分利用 ARIMA 在线性建模方面的优势和 polynomial classifiers 在捕捉非线性关系方面的能力。研究在多个真实世界数据集上评估了该方法的预测准确性和计算效率，结果显示混合模型在准确性上 consistently outperforms 单个模型，尽管执行时间略有增加。该方法为经济、工业和社会数据的时间序列预测提供了更有效的框架。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06874v1",
      "published_date": "2025-05-11 06:53:19 UTC",
      "updated_date": "2025-05-11 06:53:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:48:59.671196"
    },
    {
      "arxiv_id": "2505.06861v1",
      "title": "Efficient Robotic Policy Learning via Latent Space Backward Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Dongxiu Liu",
        "Haoyi Niu",
        "Zhihao Wang",
        "Jinliang Zheng",
        "Yinan Zheng",
        "Zhonghong Ou",
        "Jianming Hu",
        "Jianxiong Li",
        "Xianyuan Zhan"
      ],
      "abstract": "Current robotic planning methods often rely on predicting multi-frame images\nwith full pixel details. While this fine-grained approach can serve as a\ngeneric world model, it introduces two significant challenges for downstream\npolicy learning: substantial computational costs that hinder real-time\ndeployment, and accumulated inaccuracies that can mislead action extraction.\nPlanning with coarse-grained subgoals partially alleviates efficiency issues.\nHowever, their forward planning schemes can still result in off-task\npredictions due to accumulation errors, leading to misalignment with long-term\ngoals. This raises a critical question: Can robotic planning be both efficient\nand accurate enough for real-time control in long-horizon, multi-stage tasks?\nTo address this, we propose a Latent Space Backward Planning scheme (LBP),\nwhich begins by grounding the task into final latent goals, followed by\nrecursively predicting intermediate subgoals closer to the current state. The\ngrounded final goal enables backward subgoal planning to always remain aware of\ntask completion, facilitating on-task prediction along the entire planning\nhorizon. The subgoal-conditioned policy incorporates a learnable token to\nsummarize the subgoal sequences and determines how each subgoal guides action\nextraction. Through extensive simulation and real-robot long-horizon\nexperiments, we show that LBP outperforms existing fine-grained and forward\nplanning methods, achieving SOTA performance. Project Page:\nhttps://lbp-authors.github.io",
      "tldr_zh": "该研究针对机器人规划中依赖全像素图像预测的问题，指出其导致的计算成本高和错误积累，进而提出Latent Space Backward Planning (LBP)方案，从最终潜在目标开始，向后递归预测中间子目标，以确保规划始终关注任务完成。\nLBP使用子目标条件策略，通过可学习的token总结子目标序列并指导动作提取，从而提高了效率和准确性。\n实验结果显示，在模拟和真实机器人长时序任务中，LBP超越了现有细粒度和前向规划方法，达到了SOTA性能。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted by ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.06861v1",
      "published_date": "2025-05-11 06:13:51 UTC",
      "updated_date": "2025-05-11 06:13:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:49:12.844222"
    },
    {
      "arxiv_id": "2505.06860v1",
      "title": "DP-TRAE: A Dual-Phase Merging Transferable Reversible Adversarial Example for Image Privacy Protection",
      "title_zh": "翻译失败",
      "authors": [
        "Xia Du",
        "Jiajie Zhu",
        "Jizhe Zhou",
        "Chi-man Pun",
        "Zheng Lin",
        "Cong Wu",
        "Zhe Chen",
        "Jun Luo"
      ],
      "abstract": "In the field of digital security, Reversible Adversarial Examples (RAE)\ncombine adversarial attacks with reversible data hiding techniques to\neffectively protect sensitive data and prevent unauthorized analysis by\nmalicious Deep Neural Networks (DNNs). However, existing RAE techniques\nprimarily focus on white-box attacks, lacking a comprehensive evaluation of\ntheir effectiveness in black-box scenarios. This limitation impedes their\nbroader deployment in complex, dynamic environments. Further more, traditional\nblack-box attacks are often characterized by poor transferability and high\nquery costs, significantly limiting their practical applicability. To address\nthese challenges, we propose the Dual-Phase Merging Transferable Reversible\nAttack method, which generates highly transferable initial adversarial\nperturbations in a white-box model and employs a memory augmented black-box\nstrategy to effectively mislead target mod els. Experimental results\ndemonstrate the superiority of our approach, achieving a 99.0% attack success\nrate and 100% recovery rate in black-box scenarios, highlighting its robustness\nin privacy protection. Moreover, we successfully implemented a black-box attack\non a commercial model, further substantiating the potential of this approach\nfor practical use.",
      "tldr_zh": "本研究针对 Reversible Adversarial Examples (RAE) 在 black-box 场景下的局限性，提出了 DP-TRAE 方法，该方法通过双阶段合并可转移可逆对抗攻击来提升图像隐私保护的鲁棒性。DP-TRAE 先在 white-box 模型中生成高度可转移的初始对抗扰动，然后采用 memory augmented black-box 策略来误导目标模型，确保敏感数据的有效隐藏和恢复。实验结果显示，该方法在 black-box 场景中实现了 99.0% 的攻击成功率和 100% 的恢复率，并在商业模型上成功应用，证明了其在实际隐私保护中的潜力。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "12 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.06860v1",
      "published_date": "2025-05-11 06:11:10 UTC",
      "updated_date": "2025-05-11 06:11:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:49:25.644314"
    },
    {
      "arxiv_id": "2505.06856v1",
      "title": "Beyond Patterns: Harnessing Causal Logic for Autonomous Driving Trajectory Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Bonan Wang",
        "Haicheng Liao",
        "Chengyue Wang",
        "Bin Rao",
        "Yanchen Guan",
        "Guyang Yu",
        "Jiaxun Zhang",
        "Songning Lai",
        "Chengzhong Xu",
        "Zhenning Li"
      ],
      "abstract": "Accurate trajectory prediction has long been a major challenge for autonomous\ndriving (AD). Traditional data-driven models predominantly rely on statistical\ncorrelations, often overlooking the causal relationships that govern traffic\nbehavior. In this paper, we introduce a novel trajectory prediction framework\nthat leverages causal inference to enhance predictive robustness,\ngeneralization, and accuracy. By decomposing the environment into spatial and\ntemporal components, our approach identifies and mitigates spurious\ncorrelations, uncovering genuine causal relationships. We also employ a\nprogressive fusion strategy to integrate multimodal information, simulating\nhuman-like reasoning processes and enabling real-time inference. Evaluations on\nfive real-world datasets--ApolloScape, nuScenes, NGSIM, HighD, and\nMoCAD--demonstrate our model's superiority over existing state-of-the-art\n(SOTA) methods, with improvements in key metrics such as RMSE and FDE. Our\nfindings highlight the potential of causal reasoning to transform trajectory\nprediction, paving the way for robust AD systems.",
      "tldr_zh": "这篇论文提出了一种新型轨迹预测框架，通过利用 causal inference 来超越传统数据驱动模型的统计相关性，提高自动驾驶（AD）的预测鲁棒性、泛化和准确性。框架将环境分解为空间和时间组件，识别并缓解 spurious correlations，以揭示真实的因果关系，并采用 progressive fusion 策略整合多模态信息，模拟人类推理并支持实时推理。在五个真实数据集（ApolloScape、nuScenes、NGSIM、HighD 和 MoCAD）上的评估显示，该方法在 RMSE 和 FDE 等关键指标上优于现有 SOTA 方法。总体而言，这为构建更可靠的自动驾驶系统提供了新途径。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06856v1",
      "published_date": "2025-05-11 05:56:07 UTC",
      "updated_date": "2025-05-11 05:56:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:49:36.713286"
    },
    {
      "arxiv_id": "2505.07888v1",
      "title": "Implementing Long Text Style Transfer with LLMs through Dual-Layered Sentence and Paragraph Structure Extraction and Mapping",
      "title_zh": "翻译失败",
      "authors": [
        "Yusen Wu",
        "Xiaotie Deng"
      ],
      "abstract": "This paper addresses the challenge in long-text style transfer using\nzero-shot learning of large language models (LLMs), proposing a hierarchical\nframework that combines sentence-level stylistic adaptation with\nparagraph-level structural coherence. We argue that in the process of effective\nparagraph-style transfer, to preserve the consistency of original syntactic and\nsemantic information, it is essential to perform style transfer not only at the\nsentence level but also to incorporate paragraph-level semantic considerations,\nwhile ensuring structural coherence across inter-sentential relationships. Our\nproposed framework, ZeroStylus, operates through two systematic phases:\nhierarchical template acquisition from reference texts and template-guided\ngeneration with multi-granular matching. The framework dynamically constructs\nsentence and paragraph template repositories, enabling context-aware\ntransformations while preserving inter-sentence logical relationships.\nExperimental evaluations demonstrate significant improvements over baseline\nmethods, with structured rewriting achieving 6.90 average score compared to\n6.70 for direct prompting approaches in tri-axial metrics assessing style\nconsistency, content preservation, and expression quality. Ablation studies\nvalidate the necessity of both template hierarchies during style transfer,\nshowing higher content preservation win rate against sentence-only approaches\nthrough paragraph-level structural encoding, as well as direct prompting method\nthrough sentence-level pattern extraction and matching. The results establish\nnew capabilities for coherent long-text style transfer without requiring\nparallel corpora or LLM fine-tuning.",
      "tldr_zh": "本论文提出一种分层框架 ZeroStylus，用于利用大型语言模型（LLMs）实现长文本风格转移的零样本学习（zero-shot learning），通过结合句子级风格适应和段落级结构一致性，解决内容保留和语义连贯性问题。该框架分为两个阶段：从参考文本动态获取分层模板（包括句子和段落模板库），以及基于模板的多粒度匹配进行上下文感知生成，确保句子间逻辑关系保持完整。实验结果显示，ZeroStylus 在风格一致性、内容保留和表达质量的评估中，比直接提示方法平均得分提高至6.90；消融研究进一步验证了模板层次的必要性，段落级结构编码显著提升了内容保留率。总体上，该方法无需平行语料或 LLM 微调，即实现了高效的连贯长文本风格转移。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07888v1",
      "published_date": "2025-05-11 05:53:33 UTC",
      "updated_date": "2025-05-11 05:53:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:49:48.800202"
    },
    {
      "arxiv_id": "2505.06841v1",
      "title": "Optimizing Recommendations using Fine-Tuned LLMs",
      "title_zh": "使用微调的大型语言模型优化推荐",
      "authors": [
        "Prabhdeep Cheema",
        "Erhan Guven"
      ],
      "abstract": "As digital media platforms strive to meet evolving user expectations,\ndelivering highly personalized and intuitive movies and media recommendations\nhas become essential for attracting and retaining audiences. Traditional\nsystems often rely on keyword-based search and recommendation techniques, which\nlimit users to specific keywords and a combination of keywords. This paper\nproposes an approach that generates synthetic datasets by modeling real-world\nuser interactions, creating complex chat-style data reflective of diverse\npreferences. This allows users to express more information with complex\npreferences, such as mood, plot details, and thematic elements, in addition to\nconventional criteria like genre, title, and actor-based searches. In today's\nsearch space, users cannot write queries like ``Looking for a fantasy movie\nfeaturing dire wolves, ideally set in a harsh frozen world with themes of\nloyalty and survival.''\n  Building on these contributions, we evaluate synthetic datasets for diversity\nand effectiveness in training and benchmarking models, particularly in areas\noften absent from traditional datasets. This approach enhances personalization\nand accuracy by enabling expressive and natural user queries. It establishes a\nfoundation for the next generation of conversational AI-driven search and\nrecommendation systems in digital entertainment.",
      "tldr_zh": "本研究针对数字媒体平台的推荐系统优化问题，提出了一种使用Fine-Tuned LLMs的方法，通过模拟真实用户互动生成合成数据集，以创建反映多样偏好的复杂聊天式数据。该方法允许用户以自然方式表达复杂偏好，如心情、情节细节和主题，而非仅限于传统关键词搜索，从而提升推荐的个性化与准确性。实验评估显示，这些数据集在训练和基准测试中表现出色，尤其在传统数据集缺失的领域，提供更有效的支持，为下一代对话式AI驱动的搜索和推荐系统奠定了基础。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted and presented at IEEE CAI 2025. This version includes minor\n  clarifications and formatting updates",
      "pdf_url": "http://arxiv.org/pdf/2505.06841v1",
      "published_date": "2025-05-11 04:53:34 UTC",
      "updated_date": "2025-05-11 04:53:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:49:59.869901"
    },
    {
      "arxiv_id": "2505.06839v1",
      "title": "The power of fine-grained experts: Granularity boosts expressivity in Mixture of Experts",
      "title_zh": "翻译失败",
      "authors": [
        "Enric Boix-Adsera",
        "Philippe Rigollet"
      ],
      "abstract": "Mixture-of-Experts (MoE) layers are increasingly central to frontier model\narchitectures. By selectively activating parameters, they reduce computational\ncost while scaling total parameter count. This paper investigates the impact of\nthe number of active experts, termed granularity, comparing architectures with\nmany (e.g., 8 per layer in DeepSeek) to those with fewer (e.g., 1 per layer in\nLlama-4 models). We prove an exponential separation in network expressivity\nbased on this design parameter, suggesting that models benefit from higher\ngranularity. Experimental results corroborate our theoretical findings and\nillustrate this separation.",
      "tldr_zh": "本研究探讨了Mixture-of-Experts (MoE)模型中活跃专家的数量（granularity）对网络表达性(expressivity)的影响，证明了更高的granularity（如每层8个专家）相较于更低的granularity（如每层1个专家）能显著提升模型的表达能力。论文通过理论证明展示了基于granularity设计参数的指数级分离，表明细粒度专家架构更有优势。实验结果进一步验证了这些发现，并在不同模型（如DeepSeek和Llama-4）上展示了这种性能差距。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06839v1",
      "published_date": "2025-05-11 04:35:40 UTC",
      "updated_date": "2025-05-11 04:35:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:50:11.444140"
    },
    {
      "arxiv_id": "2505.06827v1",
      "title": "Sandcastles in the Storm: Revisiting the (Im)possibility of Strong Watermarking",
      "title_zh": "风暴中的沙堡：重新审视强水印的(不)可能性",
      "authors": [
        "Fabrice Y Harel-Canada",
        "Boran Erol",
        "Connor Choi",
        "Jason Liu",
        "Gary Jiarui Song",
        "Nanyun Peng",
        "Amit Sahai"
      ],
      "abstract": "Watermarking AI-generated text is critical for combating misuse. Yet recent\ntheoretical work argues that any watermark can be erased via random walk\nattacks that perturb text while preserving quality. However, such attacks rely\non two key assumptions: (1) rapid mixing (watermarks dissolve quickly under\nperturbations) and (2) reliable quality preservation (automated quality oracles\nperfectly guide edits). Through large-scale experiments and human-validated\nassessments, we find mixing is slow: 100% of perturbed texts retain traces of\ntheir origin after hundreds of edits, defying rapid mixing. Oracles falter, as\nstate-of-the-art quality detectors misjudge edits (77% accuracy), compounding\nerrors during attacks. Ultimately, attacks underperform: automated walks remove\nwatermarks just 26% of the time -- dropping to 10% under human quality review.\nThese findings challenge the inevitability of watermark removal. Instead,\npractical barriers -- slow mixing and imperfect quality control -- reveal\nwatermarking to be far more robust than theoretical models suggest. The gap\nbetween idealized attacks and real-world feasibility underscores the need for\nstronger watermarking methods and more realistic attack models.",
      "tldr_zh": "这篇论文重新审视了强 watermarking 在 AI 生成文本中的可行性，挑战了理论观点，即 random walk attacks 可以轻松移除水印。研究通过大规模实验和人类验证发现，random walk attacks 的快速混合假设不成立——扰动数百次后，100%的文本仍保留水印痕迹，且状态-of-the-art 质量检测器准确率仅77%，导致攻击成功率仅26%（人类审查下降至10%）。这些实际障碍表明 watermarking 远比理论模型预测的更稳健，并呼吁开发更强大的 watermarking 方法和更现实的攻击模型。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "In Review @ ACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.06827v1",
      "published_date": "2025-05-11 03:41:13 UTC",
      "updated_date": "2025-05-11 03:41:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:50:24.538241"
    },
    {
      "arxiv_id": "2505.06821v1",
      "title": "ThreatLens: LLM-guided Threat Modeling and Test Plan Generation for Hardware Security Verification",
      "title_zh": "翻译失败",
      "authors": [
        "Dipayan Saha",
        "Hasan Al Shaikh",
        "Shams Tarek",
        "Farimah Farahmandi"
      ],
      "abstract": "Current hardware security verification processes predominantly rely on manual\nthreat modeling and test plan generation, which are labor-intensive,\nerror-prone, and struggle to scale with increasing design complexity and\nevolving attack methodologies. To address these challenges, we propose\nThreatLens, an LLM-driven multi-agent framework that automates security threat\nmodeling and test plan generation for hardware security verification.\nThreatLens integrates retrieval-augmented generation (RAG) to extract relevant\nsecurity knowledge, LLM-powered reasoning for threat assessment, and\ninteractive user feedback to ensure the generation of practical test plans. By\nautomating these processes, the framework reduces the manual verification\neffort, enhances coverage, and ensures a structured, adaptable approach to\nsecurity verification. We evaluated our framework on the NEORV32 SoC,\ndemonstrating its capability to automate security verification through\nstructured test plans and validating its effectiveness in real-world scenarios.",
      "tldr_zh": "该研究针对硬件安全验证中手动威胁建模和测试计划生成的劳动密集型问题，提出ThreatLens，一个基于LLM的多智能体框架，以实现自动化处理。ThreatLens整合了检索增强生成(RAG)来提取相关安全知识、LLM驱动的推理进行威胁评估，以及交互式用户反馈，确保测试计划的实用性和适应性。通过在NEORV32 SoC上的评估，该框架显著减少了手动努力，提高了安全覆盖范围，并验证了其在真实场景的有效性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.CR",
      "comment": "This paper has been presented at IEEE VLSI Test Symposium (VTS) 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.06821v1",
      "published_date": "2025-05-11 03:10:39 UTC",
      "updated_date": "2025-05-11 03:10:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:50:36.371971"
    },
    {
      "arxiv_id": "2505.06817v1",
      "title": "Control Plane as a Tool: A Scalable Design Pattern for Agentic AI Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Sivasathivel Kandasamy"
      ],
      "abstract": "Agentic AI systems represent a new frontier in artificial intelligence, where\nagents often based on large language models(LLMs) interact with tools,\nenvironments, and other agents to accomplish tasks with a degree of autonomy.\nThese systems show promise across a range of domains, but their architectural\nunderpinnings remain immature. This paper conducts a comprehensive review of\nthe types of agents, their modes of interaction with the environment, and the\ninfrastructural and architectural challenges that emerge. We identify a gap in\nhow these systems manage tool orchestration at scale and propose a reusable\ndesign abstraction: the \"Control Plane as a Tool\" pattern. This pattern allows\ndevelopers to expose a single tool interface to an agent while encapsulating\nmodular tool routing logic behind it. We position this pattern within the\nbroader context of agent design and argue that it addresses several key\nchallenges in scaling, safety, and extensibility.",
      "tldr_zh": "该论文审视了基于大型语言模型(LLMs)的 Agentic AI systems 的架构挑战，包括代理类型、环境互动以及基础设施问题。作者识别了工具编排在规模化方面的关键差距，并提出“Control Plane as a Tool”设计模式，该模式允许开发者向代理暴露单一工具接口，同时封装模块化的工具路由逻辑。最终，该模式提升了系统在规模化、安全性和扩展性方面的性能，为构建高效的代理系统提供了可重用抽象。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "2 Figures and 2 Tables",
      "pdf_url": "http://arxiv.org/pdf/2505.06817v1",
      "published_date": "2025-05-11 02:58:50 UTC",
      "updated_date": "2025-05-11 02:58:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:50:48.576561"
    },
    {
      "arxiv_id": "2505.06814v1",
      "title": "Overview of the NLPCC 2025 Shared Task 4: Multi-modal, Multilingual, and Multi-hop Medical Instructional Video Question Answering Challenge",
      "title_zh": "翻译失败",
      "authors": [
        "Bin Li",
        "Shenxi Liu",
        "Yixuan Weng",
        "Yue Du",
        "Yuhang Tian",
        "Shoujun Zhou"
      ],
      "abstract": "Following the successful hosts of the 1-st (NLPCC 2023 Foshan) CMIVQA and the\n2-rd (NLPCC 2024 Hangzhou) MMIVQA challenges, this year, a new task has been\nintroduced to further advance research in multi-modal, multilingual, and\nmulti-hop medical instructional question answering (M4IVQA) systems, with a\nspecific focus on medical instructional videos. The M4IVQA challenge focuses on\nevaluating models that integrate information from medical instructional videos,\nunderstand multiple languages, and answer multi-hop questions requiring\nreasoning over various modalities. This task consists of three tracks:\nmulti-modal, multilingual, and multi-hop Temporal Answer Grounding in Single\nVideo (M4TAGSV), multi-modal, multilingual, and multi-hop Video Corpus\nRetrieval (M4VCR) and multi-modal, multilingual, and multi-hop Temporal Answer\nGrounding in Video Corpus (M4TAGVC). Participants in M4IVQA are expected to\ndevelop algorithms capable of processing both video and text data,\nunderstanding multilingual queries, and providing relevant answers to multi-hop\nmedical questions. We believe the newly introduced M4IVQA challenge will drive\ninnovations in multimodal reasoning systems for healthcare scenarios,\nultimately contributing to smarter emergency response systems and more\neffective medical education platforms in multilingual communities. Our official\nwebsite is https://cmivqa.github.io/",
      "tldr_zh": "本论文概述了 NLPCC 2025 共享任务 4，即多模态 (Multi-modal)、多语言 (Multilingual) 和多跳跃 (Multi-hop) 医疗教学视频问答挑战 (M4IVQA)，旨在扩展之前 CMIVQA 和 MMIVQA 挑战的成果。任务聚焦于评估模型从医疗教学视频中整合信息、处理多语言查询并回答需要跨模态推理的多跳跃问题，包括三个轨道：M4TAGSV (单视频时间答案定位)、M4VCR (视频语料库检索) 和 M4TAGVC (视频语料库时间答案定位)。参与者需开发算法处理视频和文本数据，以实现更准确的医疗问答。整体挑战将推动多模态推理系统的创新，助力多语言社区的智能紧急响应和医疗教育平台。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 5 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.06814v1",
      "published_date": "2025-05-11 02:15:14 UTC",
      "updated_date": "2025-05-11 02:15:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:51:01.347178"
    },
    {
      "arxiv_id": "2505.07886v1",
      "title": "PLHF: Prompt Optimization with Few-Shot Human Feedback",
      "title_zh": "PLHF：基于少样本人类反馈的提示优化",
      "authors": [
        "Chun-Pai Yang",
        "Kan Zheng",
        "Shou-De Lin"
      ],
      "abstract": "Automatic prompt optimization frameworks are developed to obtain suitable\nprompts for large language models (LLMs) with respect to desired output quality\nmetrics. Although existing approaches can handle conventional tasks such as\nfixed-solution question answering, defining the metric becomes complicated when\nthe output quality cannot be easily assessed by comparisons with standard\ngolden samples. Consequently, optimizing the prompts effectively and\nefficiently without a clear metric becomes a critical challenge. To address the\nissue, we present PLHF (which stands for \"P\"rompt \"L\"earning with \"H\"uman\n\"F\"eedback), a few-shot prompt optimization framework inspired by the\nwell-known RLHF technique. Different from naive strategies, PLHF employs a\nspecific evaluator module acting as the metric to estimate the output quality.\nPLHF requires only a single round of human feedback to complete the entire\nprompt optimization process. Empirical results on both public and industrial\ndatasets show that PLHF outperforms prior output grading strategies for LLM\nprompt optimizations.",
      "tldr_zh": "该研究提出 PLHF 框架，用于优化大语言模型 (LLMs) 的提示词，以提升输出质量。不同于传统方法，PLHF 受 RLHF 启发，通过一个特定评估器模块作为指标，估算输出质量，并仅需少量 few-shot 人类反馈即可完成整个优化过程。在公共和工业数据集上的实验显示，PLHF 优于现有输出评估策略，证明其有效性和效率。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07886v1",
      "published_date": "2025-05-11 00:56:03 UTC",
      "updated_date": "2025-05-11 00:56:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:51:11.130379"
    },
    {
      "arxiv_id": "2505.06799v1",
      "title": "Quantum Observers: A NISQ Hardware Demonstration of Chaotic State Prediction Using Quantum Echo-state Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Erik L. Connerty",
        "Ethan N. Evans",
        "Gerasimos Angelatos",
        "Vignesh Narayanan"
      ],
      "abstract": "Recent advances in artificial intelligence have highlighted the remarkable\ncapabilities of neural network (NN)-powered systems on classical computers.\nHowever, these systems face significant computational challenges that limit\nscalability and efficiency. Quantum computers hold the potential to overcome\nthese limitations and increase processing power beyond classical systems.\nDespite this, integrating quantum computing with NNs remains largely unrealized\ndue to challenges posed by noise, decoherence, and high error rates in current\nquantum hardware. Here, we propose a novel quantum echo-state network (QESN)\ndesign and implementation algorithm that can operate within the presence of\nnoise on current IBM hardware. We apply classical control-theoretic response\nanalysis to characterize the QESN, emphasizing its rich nonlinear dynamics and\nmemory, as well as its ability to be fine-tuned with sparsity and re-uploading\nblocks. We validate our approach through a comprehensive demonstration of QESNs\nfunctioning as quantum observers, applied in both high-fidelity simulations and\nhardware experiments utilizing data from a prototypical chaotic Lorenz system.\nOur results show that the QESN can predict long time-series with persistent\nmemory, running over 100 times longer than the median T}1 and T2 of the IBM\nMarrakesh QPU, achieving state-of-the-art time-series performance on\nsuperconducting hardware.",
      "tldr_zh": "该研究提出了一种新型量子回声状态网络(QESN)，旨在克服经典神经网络的计算限制，并适应NISQ硬件的噪声和错误率问题，通过经典控制理论分析其非线性动态和记忆能力，并利用稀疏性和重新上传块进行微调。研究将QESN作为量子观察者应用于混沌Lorenz系统的状态预测，在高保真模拟和IBM Marrakesh QPU硬件实验中进行验证。结果显示，QESN能实现长时序预测，运行时间超过硬件中值T1和T2的100倍，达到了目前在超导硬件上的最先进时序性能。",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "14 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.06799v1",
      "published_date": "2025-05-11 00:40:44 UTC",
      "updated_date": "2025-05-11 00:40:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:51:24.330295"
    },
    {
      "arxiv_id": "2505.06795v3",
      "title": "Decoding Futures Price Dynamics: A Regularized Sparse Autoencoder for Interpretable Multi-Horizon Forecasting and Factor Discovery",
      "title_zh": "翻译失败",
      "authors": [
        "Abhijit Gupta"
      ],
      "abstract": "Commodity price volatility creates economic challenges, necessitating\naccurate multi-horizon forecasting. Predicting prices for commodities like\ncopper and crude oil is complicated by diverse interacting factors\n(macroeconomic, supply/demand, geopolitical, etc.). Current models often lack\ntransparency, limiting strategic use. This paper presents a Regularized Sparse\nAutoencoder (RSAE), a deep learning framework for simultaneous multi-horizon\ncommodity price prediction and discovery of interpretable latent market\ndrivers. The RSAE forecasts prices at multiple horizons (e.g., 1-day, 1-week,\n1-month) using multivariate time series. Crucially, L1 regularization\n($\\|\\mathbf{z}\\|_1$) on its latent vector $\\mathbf{z}$ enforces sparsity,\npromoting parsimonious explanations of market dynamics through learned factors\nrepresenting underlying drivers (e.g., demand, supply shocks). Drawing from\nenergy-based models and sparse coding, the RSAE optimizes predictive accuracy\nwhile learning sparse representations. Evaluated on historical Copper and Crude\nOil data with numerous indicators, our findings indicate the RSAE offers\ncompetitive multi-horizon forecasting accuracy and data-driven insights into\nprice dynamics via its interpretable latent space, a key advantage over\ntraditional black-box approaches.",
      "tldr_zh": "该论文针对商品价格波动（如铜和原油）带来的经济挑战，提出了一种 Regularized Sparse Autoencoder (RSAE) 模型，用于可解释的多时间 horizon 预测（如1天、1周、1个月）和潜在市场驱动因素的发现。RSAE 利用多元时间序列数据，通过 L1 正则化（\\|\\mathbf{z}\\|_1）在潜在向量 \\mathbf{z} 上强制稀疏性，从而优化预测准确性并提供简洁的市场动态解释，借鉴能量模型和稀疏编码技术。在历史铜和原油数据上的评估表明，RSAE 比传统黑箱模型提高了多 horizon 预测性能，并提供了宝贵的可解释洞察。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06795v3",
      "published_date": "2025-05-11 00:21:53 UTC",
      "updated_date": "2025-05-14 17:49:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T21:51:37.347885"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 56,
  "processed_papers_count": 56,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-24T21:51:55.072992"
}