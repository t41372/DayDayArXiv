{
  "date": "2024-07-22",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-07-22 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 模型优化、LLM 在推荐和强化学习中的应用、图像生成与处理，以及新数据集的开发等主题。重点包括 LLM 推理能力的提升、扩散模型的低成本训练，以及针对真实世界挑战的鲁棒性改进；令人印象深刻的文章有 Tuomas Sandholm 参与的博弈算法优化，以及 NeurIPS 相关的工作；这些论文展示了 AI 在实际应用中的潜力，如医疗和机器人领域。\n\n下面，我将挑选并简要讨论部分重要、相关或有话题度的论文，先从高影响力主题入手，如 LLM 和生成模型，然后快速掠过其他领域。每个条目列出论文标题（中文 + 英文），并突出主要贡献和发现。\n\n### LLM 和生成模型\n- **标题**：Leveraging LLM Reasoning Enhances Personalized Recommender Systems（利用 LLM 推理提升个性化推荐系统）  \n  这篇论文探索了 LLM 在推荐系统中的推理能力，通过 Chain-of-Thought 提示在零样本和微调设置下提升推荐任务的质量。主要贡献是提出 RecSAVER 框架，用于自动评估 LLM 推理响应的一致性和可靠性，发现 LLM 推理能显著改善个性化推荐的准确性和泛化。\n\n- **标题**：Stretching Each Dollar: Diffusion Training from Scratch on a Micro-Budget（最大化每分钱：基于微预算从零训练扩散模型）  \n  作者提出了一种低成本训练扩散模型的方法，通过随机掩码和混合专家层减少计算资源。主要发现是，使用仅 37M 图像和 1890 美元成本，训练出 1.16B 参数模型，在 ImageNet 上达到 12.7 FID，远超传统方法，展示了高效 AI 训练的潜力。\n\n- **标题**：Discrete Flow Matching（离散流匹配）  \n  这篇论文扩展了流匹配和扩散模型到离散数据领域，提出一种新算法处理序列生成。主要贡献是通过模拟退火和概率路径优化，实现了在文本生成任务中的高性能，并在 HumanEval 和 MBPP 基准上达到 6.7% Pass@1，提升了 LLM 在离散任务的鲁棒性。\n\n- **标题**：Latent Adversarial Training Improves Robustness to Persistent Harmful Behaviors in LLMs（潜在对抗训练提升 LLM 对持久有害行为的鲁棒性）  \n  作者开发了针对 LLM 的潜在对抗训练方法，针对性地减少有害输出。主要发现是，该方法能显著降低 jailbreaking 和后门攻击的影响，并在多个基准上提升模型的安全性，适用于 ChatGPT 等系统。\n\n### 图像处理和数据集\n- **标题**：HaloQuest: A Visual Hallucination Dataset for Advancing Multimodal Reasoning（HaloQuest：用于提升多模态推理的可视化幻觉数据集）  \n  这篇论文引入了一个新数据集 HaloQuest，用于评估和减轻视觉语言模型的幻觉问题。主要贡献是通过合成图像和零样本设置，显著提升模型在多模态任务的性能，并在实验中证明了 In-Context Learning 的有效性。\n\n- **标题**：SwinSF: Image Reconstruction from Spatial-Temporal Spike Streams（SwinSF：从空间-时间脉冲流重建图像）  \n  作者提出了一种基于 Swin Transformer 的图像重建方法，处理高动态范围视频数据。主要发现是，该模型在真实和合成数据集上达到 SOTA 性能，显著提升了运动模糊场景的重建质量。\n\n- **标题**：Norface: Improving Facial Expression Analysis by Identity Normalization（Norface：通过身份归一化提升面部表情分析）  \n  这篇论文开发了端到端面部表情分析框架，通过身份和姿势归一化减少噪声。主要贡献是结合微分模块和图像校正，提升了 AU 检测和表情识别的准确性，在公共基准上超越现有方法。\n\n### 强化学习和决策\n- **标题**：Faster Optimal Coalition Structure Generation via Offline Coalition Selection and Graph-Based Search（更快的博弈结构生成：通过离线联盟选择和基于图的搜索）  \n  作者（包括知名学者 Tuomas Sandholm）提出 SMART 算法，结合动态规划和分支定界优化多代理系统。主要发现是，该算法在常见值分布上比现有方法（如 ODP-IP）更快生成最优解，提升了 coalition formation 的效率。\n\n- **标题**：Exploring and Addressing Reward Confusion in Offline Preference Learning（探索和解决离线偏好学习中的奖励混淆）  \n  这篇 NeurIPS 相关论文分析了强化学习中的奖励混淆问题，并提出使用偏好传递和主动学习的方法。主要贡献是通过基准实验证明，该方法能显著减少虚假相关性，提高 RL 模型的鲁棒性。\n\n- **标题**：Robust personalized pricing under uncertainty of purchase probabilities（在购买概率不确定性下的鲁棒个性化定价）  \n  作者提出一个鲁棒优化模型，处理预测不确定性。主要发现是，通过混合整数线性规划和拉格朗日分解算法，提升了定价策略的可靠性，在实际场景中减少了收入损失。\n\n### 其他领域快速掠过\n- **标题**：Making LLMs Work for Enterprise Data Tasks（让 LLM 适用于企业数据任务）  \n  这篇论文讨论了 LLM 在企业数据库中的应用，焦点是文本到 SQL 和语义检测。主要发现是，LLM 在企业数据上表现较差，但通过延迟、成本和质量优化，可以有效集成。\n\n- **标题**：A Survey of Explainable Artificial Intelligence (XAI) in Financial Time Series Forecasting（AI 在金融时间序列预测中的可解释性调查）  \n  调研了 XAI 在金融领域的应用，强调了可解释性和鲁棒性的重要性。主要贡献是提供了一个分类框架，帮助理解 XAI 的局限和潜力。\n\n- **标题**：GFE-Mamba: Mamba-based AD Multi-modal Progression Assessment（GFE-Mamba：基于 Mamba 的 AD 多模态进展评估）  \n  这篇论文使用 Mamba 模型进行阿尔茨海默病进展预测，结合 MRI 和 PET 图像。主要发现是，该方法在多模态融合上提升了准确性，适用于医疗诊断。\n\n今天 arXiv 的论文数量众多，但核心亮点在于 LLM 的实用性和 AI 鲁棒性的提升。这些工作为 AI 应用提供了新思路，但也提醒我们关注模型的泛化和伦理问题。明天的快报将持续追踪最新进展！",
  "papers": [
    {
      "arxiv_id": "2407.16092v1",
      "title": "Faster Optimal Coalition Structure Generation via Offline Coalition Selection and Graph-Based Search",
      "title_zh": "翻译失败",
      "authors": [
        "Redha Taguelmimt",
        "Samir Aknine",
        "Djamila Boukredera",
        "Narayan Changder",
        "Tuomas Sandholm"
      ],
      "abstract": "Coalition formation is a key capability in multi-agent systems. An important\nproblem in coalition formation is coalition structure generation: partitioning\nagents into coalitions to optimize the social welfare. This is a challenging\nproblem that has been the subject of active research for the past three\ndecades. In this paper, we present a novel algorithm, SMART, for the problem\nbased on a hybridization of three innovative techniques. Two of these\ntechniques are based on dynamic programming, where we show a powerful\nconnection between the coalitions selected for evaluation and the performance\nof the algorithms. These algorithms use offline phases to optimize the choice\nof coalitions to evaluate. The third one uses branch-and-bound and integer\npartition graph search to explore the solution space. Our techniques bring a\nnew way of approaching the problem and a new level of precision to the field.\nIn experiments over several common value distributions, we show that the\nhybridization of these techniques in SMART is faster than the fastest prior\nalgorithms (ODP-IP, BOSS) in generating optimal solutions across all the value\ndistributions.",
      "tldr_zh": "该论文针对多智能体系统的联盟结构生成问题提出了一种新算法SMART，该问题涉及将代理分区为联盟以优化社会福利。SMART算法通过三种创新技术混合实现加速：基于动态规划的离线联盟选择、动态规划与算法性能的连接，以及分支定界和整数分区图搜索。实验结果显示，在多种常见价值分布上，SMART比现有最快算法（如ODP-IP和BOSS）更快地生成最优解。该方法为联盟结构生成领域提供了新视角和更高精确度。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.GT",
        "I.2; F.2"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.16092v1",
      "published_date": "2024-07-22 23:24:03 UTC",
      "updated_date": "2024-07-22 23:24:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:43:57.124415"
    },
    {
      "arxiv_id": "2407.16077v1",
      "title": "Modelling brain connectomes networks: Solv is a worthy competitor to hyperbolic geometry!",
      "title_zh": "翻译失败",
      "authors": [
        "Dorota Celińska-Kopczyńska",
        "Eryk Kopczyński"
      ],
      "abstract": "Finding suitable embeddings for connectomes (spatially embedded complex\nnetworks that map neural connections in the brain) is crucial for analyzing and\nunderstanding cognitive processes. Recent studies have found two-dimensional\nhyperbolic embeddings superior to Euclidean embeddings in modeling connectomes\nacross species, especially human connectomes. However, those studies had\nlimitations: geometries other than Euclidean, hyperbolic, or spherical were not\nconsidered. Following William Thurston's suggestion that the networks of\nneurons in the brain could be successfully represented in Solv geometry, we\nstudy the goodness-of-fit of the embeddings for 21 connectome networks (8\nspecies). To this end, we suggest an embedding algorithm based on Simulating\nAnnealing that allows us to embed connectomes to Euclidean, Spherical,\nHyperbolic, Solv, Nil, and product geometries. Our algorithm tends to find\nbetter embeddings than the state-of-the-art, even in the hyperbolic case. Our\nfindings suggest that while three-dimensional hyperbolic embeddings yield the\nbest results in many cases, Solv embeddings perform reasonably well.",
      "tldr_zh": "本研究探讨了脑连接网络（connectomes）的几何嵌入，以更好地分析认知过程。作者提出了一种基于 Simulating Annealing 的嵌入算法，支持将 connectomes 嵌入到 Euclidean、Spherical、Hyperbolic、Solv、Nil 和产品几何中，并发现该算法在多种几何下优于现有技术。实验结果显示，三维 Hyperbolic embeddings 在21个网络（8个物种）中往往表现最佳，但 Solv geometry 也表现出色，作为 Hyperbolic 的有力竞争者。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "math.MG"
      ],
      "primary_category": "q-bio.NC",
      "comment": "Full version of our paper accepted to ECAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.16077v1",
      "published_date": "2024-07-22 22:36:04 UTC",
      "updated_date": "2024-07-22 22:36:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:44:08.662253"
    },
    {
      "arxiv_id": "2407.16067v1",
      "title": "LCA-on-the-Line: Benchmarking Out-of-Distribution Generalization with Class Taxonomies",
      "title_zh": "翻译失败",
      "authors": [
        "Jia Shi",
        "Gautam Gare",
        "Jinjin Tian",
        "Siqi Chai",
        "Zhiqiu Lin",
        "Arun Vasudevan",
        "Di Feng",
        "Francesco Ferroni",
        "Shu Kong"
      ],
      "abstract": "We tackle the challenge of predicting models' Out-of-Distribution (OOD)\nperformance using in-distribution (ID) measurements without requiring OOD data.\nExisting evaluations with \"Effective Robustness\", which use ID accuracy as an\nindicator of OOD accuracy, encounter limitations when models are trained with\ndiverse supervision and distributions, such as class labels (Vision Models,\nVMs, on ImageNet) and textual descriptions (Visual-Language Models, VLMs, on\nLAION). VLMs often generalize better to OOD data than VMs despite having\nsimilar or lower ID performance. To improve the prediction of models' OOD\nperformance from ID measurements, we introduce the Lowest Common Ancestor\n(LCA)-on-the-Line framework. This approach revisits the established concept of\nLCA distance, which measures the hierarchical distance between labels and\npredictions within a predefined class hierarchy, such as WordNet. We assess 75\nmodels using ImageNet as the ID dataset and five significantly shifted OOD\nvariants, uncovering a strong linear correlation between ID LCA distance and\nOOD top-1 accuracy. Our method provides a compelling alternative for\nunderstanding why VLMs tend to generalize better. Additionally, we propose a\ntechnique to construct a taxonomic hierarchy on any dataset using K-means\nclustering, demonstrating that LCA distance is robust to the constructed\ntaxonomic hierarchy. Moreover, we demonstrate that aligning model predictions\nwith class taxonomies, through soft labels or prompt engineering, can enhance\nmodel generalization. Open source code in our Project Page:\nhttps://elvishelvis.github.io/papers/lca/.",
      "tldr_zh": "该论文提出LCA-on-the-Line框架，使用Lowest Common Ancestor (LCA)距离来评估模型的Out-of-Distribution (OOD)泛化性能，仅基于in-distribution (ID)测量，而无需OOD数据。研究发现，在ImageNet作为ID数据集和五个OOD变体上测试75个模型时，ID LCA距离与OOD top-1准确率存在强线性相关，这解释了Visual-Language Models (VLMs)尽管ID性能相似或更低，却比Vision Models (VMs)泛化更佳的原因。作者还引入K-means聚类构建类税onomies的方法，并证明通过软标签或提示工程对齐模型预测与税onomies能提升泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2024 Oral Presentation; Project Page:\n  https://elvishelvis.github.io/papers/lca/",
      "pdf_url": "http://arxiv.org/pdf/2407.16067v1",
      "published_date": "2024-07-22 21:54:19 UTC",
      "updated_date": "2024-07-22 21:54:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:44:21.982078"
    },
    {
      "arxiv_id": "2407.16062v1",
      "title": "Artificial Intelligence-based Decision Support Systems for Precision and Digital Health",
      "title_zh": "翻译失败",
      "authors": [
        "Nina Deliu",
        "Bibhas Chakraborty"
      ],
      "abstract": "Precision health, increasingly supported by digital technologies, is a domain\nof research that broadens the paradigm of precision medicine, advancing\neveryday healthcare. This vision goes hand in hand with the groundbreaking\nadvent of artificial intelligence (AI), which is reshaping the way we diagnose,\ntreat, and monitor both clinical subjects and the general population. AI tools\npowered by machine learning have shown considerable improvements in a variety\nof healthcare domains. In particular, reinforcement learning (RL) holds great\npromise for sequential and dynamic problems such as dynamic treatment regimes\nand just-in-time adaptive interventions in digital health. In this work, we\ndiscuss the opportunity offered by AI, more specifically RL, to current trends\nin healthcare, providing a methodological survey of RL methods in the context\nof precision and digital health. Focusing on the area of adaptive\ninterventions, we expand the methodological survey with illustrative case\nstudies that used RL in real practice.\n  This invited article has undergone anonymous review and is intended as a book\nchapter for the volume \"Frontiers of Statistics and Data Science\" edited by\nSubhashis Ghoshal and Anindya Roy for the International Indian Statistical\nAssociation Series on Statistics and Data Science, published by Springer. It\ncovers the material from a short course titled \"Artificial Intelligence in\nPrecision and Digital Health\" taught by the author Bibhas Chakraborty at the\nIISA 2022 Conference, December 26-30 2022, at the Indian Institute of Science,\nBengaluru.",
      "tldr_zh": "这篇论文探讨了人工智能（AI）在精确健康（precision health）和数字健康领域的应用，特别是通过AI驱动的决策支持系统来提升诊断、治疗和监测。论文强调强化学习（RL）在处理动态问题如动态治疗制度和即时适应性干预方面的潜力，并提供了一个RL方法的方法论调查。作者通过实际案例研究展示了RL在适应性干预中的实际应用，并基于其在IISA 2022会议上的短课程内容，旨在为医疗领域的发展提供指导。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "This contribution is a part of the volume \"Frontiers of Statistics\n  and Data Science\" edited by Subhashis Ghoshal and Anindya Roy for the\n  International Indian Statistical Association Series on Statistics and Data\n  Science, published by Springer. It covers the material from a short course\n  titled \"Artificial Intelligence in Precision and Digital Health\" (IISA 2022\n  Conference) and includes parts of arXiv:2203.02605",
      "pdf_url": "http://arxiv.org/pdf/2407.16062v1",
      "published_date": "2024-07-22 21:39:34 UTC",
      "updated_date": "2024-07-22 21:39:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:44:32.416825"
    },
    {
      "arxiv_id": "2407.20256v1",
      "title": "Making LLMs Work for Enterprise Data Tasks",
      "title_zh": "使 LLMs 适用于企业",
      "authors": [
        "Çağatay Demiralp",
        "Fabian Wenz",
        "Peter Baile Chen",
        "Moe Kayali",
        "Nesime Tatbul",
        "Michael Stonebraker"
      ],
      "abstract": "Large language models (LLMs) know little about enterprise database tables in\nthe private data ecosystem, which substantially differ from web text in\nstructure and content. As LLMs' performance is tied to their training data, a\ncrucial question is how useful they can be in improving enterprise database\nmanagement and analysis tasks. To address this, we contribute experimental\nresults on LLMs' performance for text-to-SQL and semantic column-type detection\ntasks on enterprise datasets. The performance of LLMs on enterprise data is\nsignificantly lower than on benchmark datasets commonly used. Informed by our\nfindings and feedback from industry practitioners, we identify three\nfundamental challenges -- latency, cost, and quality -- and propose potential\nsolutions to use LLMs in enterprise data workflows effectively.",
      "tldr_zh": "这篇论文探讨了大型语言模型（LLMs）在企业数据任务中的应用问题，因为LLMs 对企业数据库表的结构和内容了解有限，导致性能不佳。研究通过实验评估了LLMs 在文本到SQL（text-to-SQL）和语义列类型检测（semantic column-type detection）任务上的表现，发现其在企业数据集上的准确率远低于标准基准数据集。论文进一步识别了延迟（latency）、成本（cost）和质量（quality）三大挑战，并提出潜在解决方案，以更有效地将LLMs 整合到企业数据工作流中。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DB",
      "comment": "Poster at North East Database Day 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.20256v1",
      "published_date": "2024-07-22 21:16:59 UTC",
      "updated_date": "2024-07-22 21:16:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:44:44.241954"
    },
    {
      "arxiv_id": "2407.16047v1",
      "title": "Leveraging Large Language Models to Geolocate Linguistic Variations in Social Media Posts",
      "title_zh": "利用大语言模型对社交媒体帖子中的语言变体进行地理定位",
      "authors": [
        "Davide Savarro",
        "Davide Zago",
        "Stefano Zoia"
      ],
      "abstract": "Geolocalization of social media content is the task of determining the\ngeographical location of a user based on textual data, that may show linguistic\nvariations and informal language. In this project, we address the GeoLingIt\nchallenge of geolocalizing tweets written in Italian by leveraging large\nlanguage models (LLMs). GeoLingIt requires the prediction of both the region\nand the precise coordinates of the tweet. Our approach involves fine-tuning\npre-trained LLMs to simultaneously predict these geolocalization aspects. By\nintegrating innovative methodologies, we enhance the models' ability to\nunderstand the nuances of Italian social media text to improve the\nstate-of-the-art in this domain. This work is conducted as part of the Large\nLanguage Models course at the Bertinoro International Spring School 2024. We\nmake our code publicly available on GitHub\nhttps://github.com/dawoz/geolingit-biss2024.",
      "tldr_zh": "本研究利用大型语言模型(LLMs)来定位社交媒体帖子中的语言变体，特别针对GeoLingIt挑战，旨在基于意大利推文预测用户的区域和精确坐标。方法涉及微调预训练LLMs，同时整合创新技术以更好地理解意大利社交媒体文本的细微差别和非正式语言，从而提升该领域的状态-of-the-art水平。该工作作为Bertinoro International Spring School 2024大型语言模型课程的一部分，并已在GitHub上公开代码。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.16047v1",
      "published_date": "2024-07-22 20:54:35 UTC",
      "updated_date": "2024-07-22 20:54:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:44:58.110181"
    },
    {
      "arxiv_id": "2407.16040v2",
      "title": "Generalizing Teacher Networks for Effective Knowledge Distillation Across Student Architectures",
      "title_zh": "泛化教师网络用于跨学生架构的有效知识蒸馏",
      "authors": [
        "Kuluhan Binici",
        "Weiming Wu",
        "Tulika Mitra"
      ],
      "abstract": "Knowledge distillation (KD) is a model compression method that entails\ntraining a compact student model to emulate the performance of a more complex\nteacher model. However, the architectural capacity gap between the two models\nlimits the effectiveness of knowledge transfer. Addressing this issue, previous\nworks focused on customizing teacher-student pairs to improve compatibility, a\ncomputationally expensive process that needs to be repeated every time either\nmodel changes. Hence, these methods are impractical when a teacher model has to\nbe compressed into different student models for deployment on multiple hardware\ndevices with distinct resource constraints. In this work, we propose Generic\nTeacher Network (GTN), a one-off KD-aware training to create a generic teacher\ncapable of effectively transferring knowledge to any student model sampled from\na given finite pool of architectures. To this end, we represent the student\npool as a weight-sharing supernet and condition our generic teacher to align\nwith the capacities of various student architectures sampled from this\nsupernet. Experimental evaluation shows that our method both improves overall\nKD effectiveness and amortizes the minimal additional training cost of the\ngeneric teacher across students in the pool.",
      "tldr_zh": "本研究针对知识蒸馏 (KD) 中教师模型与学生模型架构差异导致的知识转移效率低下问题，提出了一种通用教师网络 (Generic Teacher Network, GTN)。GTN 通过一次性 KD 感知训练，使教师模型能够有效适应来自一个有限学生架构池的任意模型，该池以权重共享的超网 (supernet) 表示，从而避免了每次模型变化时的重复定制。实验结果显示，GTN 不仅提升了整体 KD 效果，还将通用教师的额外训练成本分摊到多个学生模型上，提高了部署灵活性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "British Machine Vision Conference (BMVC 24)",
      "pdf_url": "http://arxiv.org/pdf/2407.16040v2",
      "published_date": "2024-07-22 20:34:00 UTC",
      "updated_date": "2025-01-08 07:21:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:45:08.481213"
    },
    {
      "arxiv_id": "2407.18272v1",
      "title": "AICircuit: A Multi-Level Dataset and Benchmark for AI-Driven Analog Integrated Circuit Design",
      "title_zh": "翻译失败",
      "authors": [
        "Asal Mehradfar",
        "Xuzhe Zhao",
        "Yue Niu",
        "Sara Babakniya",
        "Mahdi Alesheikh",
        "Hamidreza Aghasi",
        "Salman Avestimehr"
      ],
      "abstract": "Analog and radio-frequency circuit design requires extensive exploration of\nboth circuit topology and parameters to meet specific design criteria like\npower consumption and bandwidth. Designers must review state-of-the-art\ntopology configurations in the literature and sweep various circuit parameters\nwithin each configuration. This design process is highly specialized and\ntime-intensive, particularly as the number of circuit parameters increases and\nthe circuit becomes more complex. Prior research has explored the potential of\nmachine learning to enhance circuit design procedures. However, these studies\nprimarily focus on simple circuits, overlooking the more practical and complex\nanalog and radio-frequency systems. A major obstacle for bearing the power of\nmachine learning in circuit design is the availability of a generic and diverse\ndataset, along with robust metrics, which are essential for thoroughly\nevaluating and improving machine learning algorithms in the analog and\nradio-frequency circuit domain. We present AICircuit, a comprehensive\nmulti-level dataset and benchmark for developing and evaluating ML algorithms\nin analog and radio-frequency circuit design. AICircuit comprises seven\ncommonly used basic circuits and two complex wireless transceiver systems\ncomposed of multiple circuit blocks, encompassing a wide array of design\nscenarios encountered in real-world applications. We extensively evaluate\nvarious ML algorithms on the dataset, revealing the potential of ML algorithms\nin learning the mapping from the design specifications to the desired circuit\nparameters.",
      "tldr_zh": "这篇论文针对模拟和射频电路设计的复杂性，提出了AICircuit，这是一个多级数据集和基准，用于AI驱动的电路设计研究。AICircuit涵盖七种常用基本电路和两个复杂的无线收发器系统，旨在解决现有ML（machine learning）算法在复杂场景中的局限性，并提供多样化的设计场景。实验评估显示，ML算法在学习从设计规范到电路参数的映射方面具有显著潜力，为提升电路设计效率提供了新途径。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.18272v1",
      "published_date": "2024-07-22 20:32:16 UTC",
      "updated_date": "2024-07-22 20:32:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:45:22.000927"
    },
    {
      "arxiv_id": "2408.00802v1",
      "title": "Leveraging LLM Reasoning Enhances Personalized Recommender Systems",
      "title_zh": "利用 LLM 推理提升个性化推荐系统",
      "authors": [
        "Alicia Y. Tsai",
        "Adam Kraft",
        "Long Jin",
        "Chenwei Cai",
        "Anahita Hosseini",
        "Taibai Xu",
        "Zemin Zhang",
        "Lichan Hong",
        "Ed H. Chi",
        "Xinyang Yi"
      ],
      "abstract": "Recent advancements have showcased the potential of Large Language Models\n(LLMs) in executing reasoning tasks, particularly facilitated by\nChain-of-Thought (CoT) prompting. While tasks like arithmetic reasoning involve\nclear, definitive answers and logical chains of thought, the application of LLM\nreasoning in recommendation systems (RecSys) presents a distinct challenge.\nRecSys tasks revolve around subjectivity and personalized preferences, an\nunder-explored domain in utilizing LLMs' reasoning capabilities. Our study\nexplores several aspects to better understand reasoning for RecSys and\ndemonstrate how task quality improves by utilizing LLM reasoning in both\nzero-shot and finetuning settings. Additionally, we propose RecSAVER\n(Recommender Systems Automatic Verification and Evaluation of Reasoning) to\nautomatically assess the quality of LLM reasoning responses without the\nrequirement of curated gold references or human raters. We show that our\nframework aligns with real human judgment on the coherence and faithfulness of\nreasoning responses. Overall, our work shows that incorporating reasoning into\nRecSys can improve personalized tasks, paving the way for further advancements\nin recommender system methodologies.",
      "tldr_zh": "本文探讨了如何利用大型语言模型 (LLMs) 的推理能力，特别是 Chain-of-Thought (CoT) 提示，来提升推荐系统 (RecSys) 的个性化任务性能，以应对其主观性和偏好挑战。研究在 zero-shot 和 finetuning 设置中评估了 LLM 推理的效果，并提出 RecSAVER（Recommender Systems Automatic Verification and Evaluation of Reasoning）框架，用于自动评估推理响应的质量，而无需金标准参考或人工评分。结果表明，RecSAVER 与人类判断在一致性和忠实度上高度一致，证明将推理整合到 RecSys 中能显著改善任务质量，并为推荐系统方法的发展开辟新路径。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "To be published at ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.00802v1",
      "published_date": "2024-07-22 20:18:50 UTC",
      "updated_date": "2024-07-22 20:18:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:45:33.914520"
    },
    {
      "arxiv_id": "2407.16030v1",
      "title": "Enhancing Temporal Understanding in LLMs for Semi-structured Tables",
      "title_zh": "翻译失败",
      "authors": [
        "Irwin Deng",
        "Kushagra Dixit",
        "Vivek Gupta",
        "Dan Roth"
      ],
      "abstract": "Temporal reasoning over tabular data presents substantial challenges for\nlarge language models (LLMs), as evidenced by recent research. In this study,\nwe conduct a comprehensive analysis of temporal datasets to pinpoint the\nspecific limitations of LLMs. Our investigation leads to enhancements in\nTempTabQA, a dataset specifically designed for tabular temporal question\nanswering. We provide critical insights for improving LLM performance in\ntemporal reasoning tasks with tabular data. Furthermore, we introduce a novel\napproach, C.L.E.A.R to strengthen LLM capabilities in this domain. Our findings\ndemonstrate that our method significantly improves evidence-based reasoning\nacross various models. Additionally, our experimental results reveal that\nindirect supervision with auxiliary data substantially boosts model performance\nin these tasks. This work contributes to a deeper understanding of LLMs'\ntemporal reasoning abilities over tabular data and promotes advancements in\ntheir application across diverse fields.",
      "tldr_zh": "这项研究探讨了大型语言模型 (LLMs) 在处理半结构化表格的时序推理 (temporal reasoning) 方面的挑战，通过全面分析时序数据集来识别其具体限制。研究者改进了 TempTabQA 数据集，并提供了提升 LLM 性能的关键见解。引入了新方法 C.L.E.A.R，以加强模型在该领域的证据-based 推理能力，并证明间接监督和辅助数据能显著提升性能。总体而言，此工作加深了对 LLMs 在表格数据上时序推理能力的理解，并推动其在多样领域的应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DB",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Total Pages 18, Total Tables 6, Total figures 7",
      "pdf_url": "http://arxiv.org/pdf/2407.16030v1",
      "published_date": "2024-07-22 20:13:10 UTC",
      "updated_date": "2024-07-22 20:13:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:45:44.525466"
    },
    {
      "arxiv_id": "2407.16026v1",
      "title": "KWT-Tiny: RISC-V Accelerated, Embedded Keyword Spotting Transformer",
      "title_zh": "翻译失败",
      "authors": [
        "Aness Al-Qawlaq",
        "Ajay Kumar M",
        "Deepu John"
      ],
      "abstract": "This paper explores the adaptation of Transformerbased models for edge\ndevices through the quantisation and hardware acceleration of the ARM Keyword\nTransformer (KWT) model on a RISC-V platform. The model was targeted to run on\n64kB RAM in bare-metal C using a custom-developed edge AI library. KWT-1 was\nretrained to be 369 times smaller, with only a 10% loss in accuracy through\nreducing output classes from 35 to 2. The retraining and quantisation reduced\nmodel size from 2.42 MB to 1.65 kB. The integration of custom RISC-V\ninstructions that accelerated GELU and SoftMax operations enabled a 5x speedup\nand thus ~5x power reduction in inference, with inference clock cycle counts\ndecreasing from 26 million to 5.5 million clock cycles while incurring a small\narea overhead of approximately 29%. The results demonstrate a viable method for\nporting and accelerating Transformer-based models in low-power IoT devices.",
      "tldr_zh": "本文提出 KWT-Tiny，一种针对 RISC-V 平台的嵌入式关键词检测 Transformer 模型，通过量化（quantisation）和硬件加速，将 ARM Keyword Transformer (KWT) 模型适应到边缘设备，目标运行在 64kB RAM 的裸金属 C 环境中。KWT-1 模型经重新训练和量化，将输出类别从 35 减少到 2，使模型大小从 2.42 MB 缩小到 1.65 kB，同时仅损失 10% 的准确率。自定义 RISC-V 指令加速了 GELU 和 SoftMax 操作，实现推理速度 5 倍提升和功耗约 5 倍减少，时钟周期从 26 百万降至 5.5 百万。结果展示了在低功耗 IoT 设备上移植和加速 Transformer 模型的可行方法。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.PF"
      ],
      "primary_category": "cs.AR",
      "comment": "6 pages, 7 figures, accepted to be published in the IEEE SOCC 2024\n  conference",
      "pdf_url": "http://arxiv.org/pdf/2407.16026v1",
      "published_date": "2024-07-22 20:07:21 UTC",
      "updated_date": "2024-07-22 20:07:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:45:58.989916"
    },
    {
      "arxiv_id": "2407.16025v2",
      "title": "Exploring and Addressing Reward Confusion in Offline Preference Learning",
      "title_zh": "探索并解决离线偏好学习中的奖励混淆",
      "authors": [
        "Xin Chen",
        "Sam Toyer",
        "Florian Shkurti"
      ],
      "abstract": "Spurious correlations in a reward model's training data can prevent\nReinforcement Learning from Human Feedback (RLHF) from identifying the desired\ngoal and induce unwanted behaviors. This paper shows that offline RLHF is\nsusceptible to reward confusion, especially in the presence of spurious\ncorrelations in offline data. We create a benchmark to study this problem and\npropose a method that can significantly reduce reward confusion by leveraging\ntransitivity of preferences while building a global preference chain with\nactive learning.",
      "tldr_zh": "该论文探讨了离线偏好学习中的奖励混淆（reward confusion）问题，特别是在训练数据中存在虚假相关性（spurious correlations）时，这会导致 Reinforcement Learning from Human Feedback (RLHF) 无法识别期望目标并引发不期望行为。研究者创建了一个基准（benchmark）来系统研究这一问题，并提出了一种新方法，通过利用偏好传递性（transitivity of preferences）和主动学习（active learning）构建全局偏好链，从而显著减少奖励混淆。该方法为提升 RLHF 的鲁棒性提供了有效途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS2024 Workshop on Bayesian Decision-making and Uncertainty",
      "pdf_url": "http://arxiv.org/pdf/2407.16025v2",
      "published_date": "2024-07-22 20:03:36 UTC",
      "updated_date": "2024-10-15 13:22:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:46:10.735756"
    },
    {
      "arxiv_id": "2407.16010v2",
      "title": "AIDE: Antithetical, Intent-based, and Diverse Example-Based Explanations",
      "title_zh": "翻译失败",
      "authors": [
        "Ikhtiyor Nematov",
        "Dimitris Sacharidis",
        "Tomer Sagi",
        "Katja Hose"
      ],
      "abstract": "For many use-cases, it is often important to explain the prediction of a\nblack-box model by identifying the most influential training data samples.\nExisting approaches lack customization for user intent and often provide a\nhomogeneous set of explanation samples, failing to reveal the model's reasoning\nfrom different angles.\n  In this paper, we propose AIDE, an approach for providing antithetical (i.e.,\ncontrastive), intent-based, diverse explanations for opaque and complex models.\nAIDE distinguishes three types of explainability intents: interpreting a\ncorrect, investigating a wrong, and clarifying an ambiguous prediction. For\neach intent, AIDE selects an appropriate set of influential training samples\nthat support or oppose the prediction either directly or by contrast. To\nprovide a succinct summary, AIDE uses diversity-aware sampling to avoid\nredundancy and increase coverage of the training data.\n  We demonstrate the effectiveness of AIDE on image and text classification\ntasks, in three ways: quantitatively, assessing correctness and continuity;\nqualitatively, comparing anecdotal evidence from AIDE and other example-based\napproaches; and via a user study, evaluating multiple aspects of AIDE. The\nresults show that AIDE addresses the limitations of existing methods and\nexhibits desirable traits for an explainability method.",
      "tldr_zh": "本文提出 AIDE，一种反向（antithetical）、基于意图的、多样化的基于示例的解释方法，用于解释黑盒模型的预测，解决现有方法缺乏用户意图定制和解释样本同质化的问题。AIDE 区分三种解释意图——解释正确的预测、调查错误的预测以及澄清模糊的预测，并通过多样性感知采样选择支持或反对预测的训练样本，以避免冗余并提升覆盖范围。在图像和文本分类任务的实验中，AIDE 通过定量评估、定性比较和用户研究证明了其有效性，展示了更全面和可信的解释性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.16010v2",
      "published_date": "2024-07-22 19:33:12 UTC",
      "updated_date": "2024-08-08 09:12:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:46:22.076187"
    },
    {
      "arxiv_id": "2407.15987v1",
      "title": "AI for Handball: predicting and explaining the 2024 Olympic Games tournament with Deep Learning and Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Florian Felice"
      ],
      "abstract": "Over summer 2024, the world will be looking at Paris to encourage their\nfavorite athletes win the Olympic gold medal. In handball, few nations will\nfight hard to win the precious metal with speculations predicting the victory\nfor France or Denmark for men and France or Norway for women. However, there is\nso far no scientific method proposed to predict the final results of the\ncompetition. In this work, we leverage a deep learning model to predict the\nresults of the handball tournament of the 2024 Olympic Games. This model,\ncoupled with explainable AI (xAI) techniques, allows us to extract insightful\ninformation about the main factors influencing the outcome of each match.\nNotably, xAI helps sports experts understand how factors like match information\nor individual athlete performance contribute to the predictions. Furthermore,\nwe integrate Large Language Models (LLMs) to generate human-friendly\nexplanations that highlight the most important factors impacting the match\nresults. By providing human-centric explanations, our approach offers a deeper\nunderstanding of the AI predictions, making them more actionable for coaches\nand analysts.",
      "tldr_zh": "本研究利用 Deep Learning 模型预测 2024 年奥运会手球比赛结果，填补了缺乏科学预测方法的空白。模型结合 explainable AI (xAI) 技术分析关键影响因素，如比赛信息和运动员表现，提供对预测的深入解释。同时，集成 Large Language Models (LLMs) 生成易懂的人类友好解释，帮助教练和分析师更好地理解并应用这些预测。整体方法提升了 AI 在体育领域的可解释性和实用性。",
      "categories": [
        "stat.AP",
        "cs.AI"
      ],
      "primary_category": "stat.AP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.15987v1",
      "published_date": "2024-07-22 18:54:06 UTC",
      "updated_date": "2024-07-22 18:54:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:46:33.502841"
    },
    {
      "arxiv_id": "2407.15849v1",
      "title": "WayEx: Waypoint Exploration using a Single Demonstration",
      "title_zh": "翻译失败",
      "authors": [
        "Mara Levy",
        "Nirat Saini",
        "Abhinav Shrivastava"
      ],
      "abstract": "We propose WayEx, a new method for learning complex goal-conditioned robotics\ntasks from a single demonstration. Our approach distinguishes itself from\nexisting imitation learning methods by demanding fewer expert examples and\neliminating the need for information about the actions taken during the\ndemonstration. This is accomplished by introducing a new reward function and\nemploying a knowledge expansion technique. We demonstrate the effectiveness of\nWayEx, our waypoint exploration strategy, across six diverse tasks, showcasing\nits applicability in various environments. Notably, our method significantly\nreduces training time by 50% as compared to traditional reinforcement learning\nmethods. WayEx obtains a higher reward than existing imitation learning methods\ngiven only a single demonstration. Furthermore, we demonstrate its success in\ntackling complex environments where standard approaches fall short. More\ninformation is available at: https://waypoint-ex.github.io.",
      "tldr_zh": "该研究提出 WayEx，一种仅需单个演示即可学习复杂目标条件机器人任务的方法，与现有 imitation learning 方法不同，它减少了专家示例需求并省去动作信息，通过引入新奖励函数和知识扩展技术来实现。在六个多样化任务中，WayEx 展示了其适用性，并将训练时间比传统 reinforcement learning 方法减少 50%。此外，该方法在复杂环境中表现出色，获得比现有 imitation learning 方法更高的奖励。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "ICRA 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.15849v1",
      "published_date": "2024-07-22 17:59:46 UTC",
      "updated_date": "2024-07-22 17:59:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:46:43.797378"
    },
    {
      "arxiv_id": "2407.15847v4",
      "title": "LLMmap: Fingerprinting For Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Dario Pasquini",
        "Evgenios M. Kornaropoulos",
        "Giuseppe Ateniese"
      ],
      "abstract": "We introduce LLMmap, a first-generation fingerprinting technique targeted at\nLLM-integrated applications. LLMmap employs an active fingerprinting approach,\nsending carefully crafted queries to the application and analyzing the\nresponses to identify the specific LLM version in use. Our query selection is\ninformed by domain expertise on how LLMs generate uniquely identifiable\nresponses to thematically varied prompts. With as few as 8 interactions, LLMmap\ncan accurately identify 42 different LLM versions with over 95% accuracy. More\nimportantly, LLMmap is designed to be robust across different application\nlayers, allowing it to identify LLM versions--whether open-source or\nproprietary--from various vendors, operating under various unknown system\nprompts, stochastic sampling hyperparameters, and even complex generation\nframeworks such as RAG or Chain-of-Thought. We discuss potential mitigations\nand demonstrate that, against resourceful adversaries, effective\ncountermeasures may be challenging or even unrealizable.",
      "tldr_zh": "这篇论文介绍了LLMmap，一种针对集成大型语言模型(LLM)的指纹识别(fingerprinting)技术，通过发送精心设计的查询并分析响应，来准确识别具体LLM版本。LLMmap基于对LLM生成独特响应的领域知识，仅需8次交互即可以超过95%的准确率识别42个不同LLM版本，并对各种应用场景保持鲁棒性，包括未知系统提示、随机采样参数以及复杂框架如RAG或Chain-of-Thought。论文讨论了潜在的缓解措施，但指出对资源丰富的对手，有效的countermeasures可能难以实现或不可行。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Appearing in the proceedings of the 34th USENIX Security Symposium",
      "pdf_url": "http://arxiv.org/pdf/2407.15847v4",
      "published_date": "2024-07-22 17:59:45 UTC",
      "updated_date": "2025-02-10 19:42:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:46:57.412745"
    },
    {
      "arxiv_id": "2407.15845v1",
      "title": "Reconstructing Training Data From Real World Models Trained with Transfer Learning",
      "title_zh": "从使用迁移学习训练的现实世界模型中重构训练数据",
      "authors": [
        "Yakir Oz",
        "Gilad Yehudai",
        "Gal Vardi",
        "Itai Antebi",
        "Michal Irani",
        "Niv Haim"
      ],
      "abstract": "Current methods for reconstructing training data from trained classifiers are\nrestricted to very small models, limited training set sizes, and low-resolution\nimages. Such restrictions hinder their applicability to real-world scenarios.\nIn this paper, we present a novel approach enabling data reconstruction in\nrealistic settings for models trained on high-resolution images. Our method\nadapts the reconstruction scheme of arXiv:2206.07758 to real-world scenarios --\nspecifically, targeting models trained via transfer learning over image\nembeddings of large pre-trained models like DINO-ViT and CLIP. Our work employs\ndata reconstruction in the embedding space rather than in the image space,\nshowcasing its applicability beyond visual data. Moreover, we introduce a novel\nclustering-based method to identify good reconstructions from thousands of\ncandidates. This significantly improves on previous works that relied on\nknowledge of the training set to identify good reconstructed images. Our\nfindings shed light on a potential privacy risk for data leakage from models\ntrained using transfer learning.",
      "tldr_zh": "这篇论文提出了一种新方法，用于从真实世界模型中重建训练数据，针对通过转移学习（如 DINO-ViT 和 CLIP）训练的高分辨率图像模型，克服了现有方法的限制。该方法在嵌入空间（embedding space）进行重建，而不是图像空间，并引入基于聚类的技术，从数千个候选中自动识别高质量重建结果，而无需依赖训练集知识。研究结果显示，这种方法显著提升了重建的适用性，并揭示了转移学习模型中潜在的数据泄漏隐私风险。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.15845v1",
      "published_date": "2024-07-22 17:59:10 UTC",
      "updated_date": "2024-07-22 17:59:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:47:19.416181"
    },
    {
      "arxiv_id": "2407.15843v1",
      "title": "CarFormer: Self-Driving with Learned Object-Centric Representations",
      "title_zh": "CarFormer：基于学习到的对象中心表示的自动驾驶",
      "authors": [
        "Shadi Hamdan",
        "Fatma Güney"
      ],
      "abstract": "The choice of representation plays a key role in self-driving. Bird's eye\nview (BEV) representations have shown remarkable performance in recent years.\nIn this paper, we propose to learn object-centric representations in BEV to\ndistill a complex scene into more actionable information for self-driving. We\nfirst learn to place objects into slots with a slot attention model on BEV\nsequences. Based on these object-centric representations, we then train a\ntransformer to learn to drive as well as reason about the future of other\nvehicles. We found that object-centric slot representations outperform both\nscene-level and object-level approaches that use the exact attributes of\nobjects. Slot representations naturally incorporate information about objects\nfrom their spatial and temporal context such as position, heading, and speed\nwithout explicitly providing it. Our model with slots achieves an increased\ncompletion rate of the provided routes and, consequently, a higher driving\nscore, with a lower variance across multiple runs, affirming slots as a\nreliable alternative in object-centric approaches. Additionally, we validate\nour model's performance as a world model through forecasting experiments,\ndemonstrating its capability to predict future slot representations accurately.\nThe code and the pre-trained models can be found at\nhttps://kuis-ai.github.io/CarFormer/.",
      "tldr_zh": "这篇论文介绍了 CarFormer，一种基于鸟瞰视角 (BEV) 的对象中心表示 (object-centric representations) 用于自动驾驶的框架，通过 slot attention 模型在 BEV 序列上学习将复杂场景分解为对象 slots。基于这些 slots，作者训练了一个 transformer 模型来实现驾驶决策并预测其他车辆的未来轨迹，从而自然地整合了对象的位置、航向和速度等信息，而无需显式提供。实验结果表明，CarFormer 优于场景级和对象级方法，提高了路线完成率和驾驶分数，同时降低了性能方差，并在预测任务中展示了准确的未来 slots 表示能力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to ECCV 2024, code and the pre-trained models can be found\n  at https://kuis-ai.github.io/CarFormer/",
      "pdf_url": "http://arxiv.org/pdf/2407.15843v1",
      "published_date": "2024-07-22 17:59:01 UTC",
      "updated_date": "2024-07-22 17:59:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:47:22.949768"
    },
    {
      "arxiv_id": "2407.15844v1",
      "title": "HandDGP: Camera-Space Hand Mesh Prediction with Differentiable Global Positioning",
      "title_zh": "HandDGP：相机空间手部网格预测与可微全局",
      "authors": [
        "Eugene Valassakis",
        "Guillermo Garcia-Hernando"
      ],
      "abstract": "Predicting camera-space hand meshes from single RGB images is crucial for\nenabling realistic hand interactions in 3D virtual and augmented worlds.\nPrevious work typically divided the task into two stages: given a cropped image\nof the hand, predict meshes in relative coordinates, followed by lifting these\npredictions into camera space in a separate and independent stage, often\nresulting in the loss of valuable contextual and scale information. To prevent\nthe loss of these cues, we propose unifying these two stages into an end-to-end\nsolution that addresses the 2D-3D correspondence problem. This solution enables\nback-propagation from camera space outputs to the rest of the network through a\nnew differentiable global positioning module. We also introduce an image\nrectification step that harmonizes both the training dataset and the input\nimage as if they were acquired with the same camera, helping to alleviate the\ninherent scale-depth ambiguity of the problem. We validate the effectiveness of\nour framework in evaluations against several baselines and state-of-the-art\napproaches across three public benchmarks.",
      "tldr_zh": "这项研究提出 HandDGP 框架，用于从单张 RGB 图像预测相机空间的手部网格，从而提升 3D 虚拟和增强现实中的手部交互真实性。传统方法将任务分为两阶段，导致上下文和规模信息丢失，而 HandDGP 统一为端到端解决方案，直接解决 2D-3D 对应问题。框架引入可微分全局定位 (Differentiable Global Positioning) 模块，支持从相机空间输出向网络其他部分的梯度反向传播，并通过图像矫正步骤使训练数据集和输入图像保持一致，缓解规模-深度模糊性。在三个公共基准上，HandDGP 与基线和最先进方法相比表现出色，验证了其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "To be presented at ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.15844v1",
      "published_date": "2024-07-22 17:59:01 UTC",
      "updated_date": "2024-07-22 17:59:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:47:34.097585"
    },
    {
      "arxiv_id": "2407.15839v2",
      "title": "Importance Sampling-Guided Meta-Training for Intelligent Agents in Highly Interactive Environments",
      "title_zh": "重要性采样指导的元训练，用于高度交互环境中的智能代理",
      "authors": [
        "Mansur Arief",
        "Mike Timmerman",
        "Jiachen Li",
        "David Isele",
        "Mykel J Kochenderfer"
      ],
      "abstract": "Training intelligent agents to navigate highly interactive environments\npresents significant challenges. While guided meta reinforcement learning (RL)\napproach that first trains a guiding policy to train the ego agent has proven\neffective in improving generalizability across scenarios with various levels of\ninteraction, the state-of-the-art method tends to be overly sensitive to\nextreme cases, impairing the agents' performance in the more common scenarios.\nThis study introduces a novel training framework that integrates guided meta RL\nwith importance sampling (IS) to optimize training distributions iteratively\nfor navigating highly interactive driving scenarios, such as T-intersections or\nroundabouts. Unlike traditional methods that may underrepresent critical\ninteractions or overemphasize extreme cases during training, our approach\nstrategically adjusts the training distribution towards more challenging\ndriving behaviors using IS proposal distributions and applies the importance\nratio to de-bias the result. By estimating a naturalistic distribution from\nreal-world datasets and employing a mixture model for iterative training\nrefinements, the framework ensures a balanced focus across common and extreme\ndriving scenarios. Experiments conducted with both synthetic and naturalistic\ndatasets demonstrate both accelerated training and performance improvements\nunder highly interactive driving tasks.",
      "tldr_zh": "这篇论文提出了一种结合 importance sampling (IS) 的 guided meta reinforcement learning (RL) 框架，用于训练智能代理在高度交互环境（如驾驶场景）中的表现，以解决现有方法对极端案例过度敏感的问题。该框架通过 IS 提案分布迭代优化训练分布，战略性地强调更具挑战性的行为，同时使用重要性比率消除偏差，并基于真实数据集估计自然分布和混合模型来实现常见与极端场景的平衡。实验在合成和自然数据集上证明，该方法显著加速了训练过程，并提升了代理在交互式任务（如 T 型路口或环岛）的性能。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.15839v2",
      "published_date": "2024-07-22 17:57:12 UTC",
      "updated_date": "2024-10-28 04:48:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:47:45.326905"
    },
    {
      "arxiv_id": "2407.15837v1",
      "title": "Towards Latent Masked Image Modeling for Self-Supervised Visual Representation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yibing Wei",
        "Abhinav Gupta",
        "Pedro Morgado"
      ],
      "abstract": "Masked Image Modeling (MIM) has emerged as a promising method for deriving\nvisual representations from unlabeled image data by predicting missing pixels\nfrom masked portions of images. It excels in region-aware learning and provides\nstrong initializations for various tasks, but struggles to capture high-level\nsemantics without further supervised fine-tuning, likely due to the low-level\nnature of its pixel reconstruction objective. A promising yet unrealized\nframework is learning representations through masked reconstruction in latent\nspace, combining the locality of MIM with the high-level targets. However, this\napproach poses significant training challenges as the reconstruction targets\nare learned in conjunction with the model, potentially leading to trivial or\nsuboptimal solutions.Our study is among the first to thoroughly analyze and\naddress the challenges of such framework, which we refer to as Latent MIM.\nThrough a series of carefully designed experiments and extensive analysis, we\nidentify the source of these challenges, including representation collapsing\nfor joint online/target optimization, learning objectives, the high region\ncorrelation in latent space and decoding conditioning. By sequentially\naddressing these issues, we demonstrate that Latent MIM can indeed learn\nhigh-level representations while retaining the benefits of MIM models.",
      "tldr_zh": "这篇论文探讨了在潜在空间（latent space）中进行掩盖图像建模（Latent Masked Image Modeling, Latent MIM），旨在提升自监督视觉表示学习（self-supervised visual representation learning）。传统 Masked Image Modeling (MIM) 虽擅长区域感知学习，但因其像素重建目标而难以捕获高层语义；为此，论文首次全面分析了 Latent MIM 的挑战，包括表示崩溃（representation collapsing）、学习目标和潜在空间中的高区域相关性。作者通过一系列实验设计和优化策略（如解码条件调整）成功解决了这些问题，证明 Latent MIM 可以学习高层表示，同时保留 MIM 的优势。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.15837v1",
      "published_date": "2024-07-22 17:54:41 UTC",
      "updated_date": "2024-07-22 17:54:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:47:59.008777"
    },
    {
      "arxiv_id": "2407.15835v2",
      "title": "dMel: Speech Tokenization made Simple",
      "title_zh": "dMel：语音标记化变得简单",
      "authors": [
        "He Bai",
        "Tatiana Likhomanenko",
        "Ruixiang Zhang",
        "Zijin Gu",
        "Zakaria Aldeneh",
        "Navdeep Jaitly"
      ],
      "abstract": "Large language models have revolutionized natural language processing by\nleveraging self-supervised pretraining on vast textual data. Inspired by this\nsuccess, researchers have investigated complicated speech tokenization methods\nto discretize continuous speech signals so that language modeling techniques\ncan be applied to speech data. However, existing approaches either model\nsemantic (content) tokens, potentially losing acoustic information, or model\nacoustic tokens, risking the loss of semantic (content) information. Having\nmultiple token types also complicates the architecture and requires additional\npretraining. Here we show that discretizing mel-filterbank channels into\ndiscrete intensity bins produces a simple representation (dMel), that performs\nbetter than other existing speech tokenization methods. Using an LM-style\ntransformer architecture for speech-text modeling, we comprehensively evaluate\ndifferent speech tokenization methods on speech recognition (ASR) and speech\nsynthesis (TTS). Our results demonstrate the effectiveness of dMel in achieving\nhigh performance on both tasks within a unified framework, paving the way for\nefficient and effective joint modeling of speech and text.",
      "tldr_zh": "该论文提出了一种简化的语音标记化方法 dMel，通过将 mel-filterbank 通道离散化为离散强度 bin，避免了现有方法在语义或声学信息丢失上的问题。相比其他复杂标记化技术，dMel 在使用 LM-style transformer 架构的统一框架中，实现了更好的语音识别 (ASR) 和语音合成 (TTS) 性能。实验结果表明，dMel 不仅提升了任务表现，还为高效的语音和文本联合建模铺平了道路。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "under review",
      "pdf_url": "http://arxiv.org/pdf/2407.15835v2",
      "published_date": "2024-07-22 17:51:53 UTC",
      "updated_date": "2024-10-02 20:38:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:48:09.747822"
    },
    {
      "arxiv_id": "2407.15831v2",
      "title": "NV-Retriever: Improving text embedding models with effective hard-negative mining",
      "title_zh": "NV-Retriever：通过有效的硬负样本挖掘改进文本嵌入模型",
      "authors": [
        "Gabriel de Souza P. Moreira",
        "Radek Osmulski",
        "Mengyao Xu",
        "Ronay Ak",
        "Benedikt Schifferer",
        "Even Oldridge"
      ],
      "abstract": "Text embedding models have been popular for information retrieval\napplications such as semantic search and Question-Answering systems based on\nRetrieval-Augmented Generation (RAG). Those models are typically Transformer\nmodels that are fine-tuned with contrastive learning objectives. One of the\nchallenging aspects of fine-tuning embedding models is the selection of high\nquality hard-negative passages for contrastive learning. In this paper we\nintroduce a family of positive-aware mining methods that use the positive\nrelevance score as an anchor for effective false negative removal, leading to\nfaster training and more accurate retrieval models. We provide an ablation\nstudy on hard-negative mining methods over their configurations, exploring\ndifferent teacher and base models. We further demonstrate the efficacy of our\nproposed mining methods at scale with the NV-Retriever-v1 model, which scores\n60.9 on MTEB Retrieval (BEIR) benchmark and placed 1st when it was published to\nthe MTEB Retrieval on July, 2024.",
      "tldr_zh": "这篇论文针对文本嵌入模型在信息检索应用（如语义搜索和基于 RAG 的问答系统）的微调问题，提出了一种 positive-aware mining 方法，使用 positive relevance score 作为锚点来有效移除 false negatives，从而加速训练并提升模型准确性。研究通过 ablation study 探索了不同 teacher 和 base 模型的 hard-negative mining 配置。最终，NV-Retriever-v1 模型在 MTEB Retrieval (BEIR) 基准上得分 60.9，并于 2024 年 7 月在该基准中排名第一。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.15831v2",
      "published_date": "2024-07-22 17:50:31 UTC",
      "updated_date": "2025-02-07 15:17:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:48:31.866300"
    },
    {
      "arxiv_id": "2407.15820v2",
      "title": "On shallow planning under partial observability",
      "title_zh": "翻译失败",
      "authors": [
        "Randy Lefebvre",
        "Audrey Durand"
      ],
      "abstract": "Formulating a real-world problem under the Reinforcement Learning framework\ninvolves non-trivial design choices, such as selecting a discount factor for\nthe learning objective (discounted cumulative rewards), which articulates the\nplanning horizon of the agent. This work investigates the impact of the\ndiscount factor on the bias-variance trade-off given structural parameters of\nthe underlying Markov Decision Process. Our results support the idea that a\nshorter planning horizon might be beneficial, especially under partial\nobservability.",
      "tldr_zh": "这篇论文探讨了在强化学习框架中，选择折扣因子（用于折扣累积奖励）对代理规划视野的影响，特别是如何影响偏差-方差权衡。研究通过分析Markov Decision Process的结构参数，评估了不同折扣因子设置下的性能。结果表明，在部分可观测性环境中，采用更短的规划视野可能更具优势，从而为强化学习问题设计提供重要指导。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2407.15820v2",
      "published_date": "2024-07-22 17:34:07 UTC",
      "updated_date": "2025-02-17 21:14:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:48:33.335832"
    },
    {
      "arxiv_id": "2407.15815v2",
      "title": "Learning to Manipulate Anywhere: A Visual Generalizable Framework For Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Zhecheng Yuan",
        "Tianming Wei",
        "Shuiqi Cheng",
        "Gu Zhang",
        "Yuanpei Chen",
        "Huazhe Xu"
      ],
      "abstract": "Can we endow visuomotor robots with generalization capabilities to operate in\ndiverse open-world scenarios? In this paper, we propose \\textbf{Maniwhere}, a\ngeneralizable framework tailored for visual reinforcement learning, enabling\nthe trained robot policies to generalize across a combination of multiple\nvisual disturbance types. Specifically, we introduce a multi-view\nrepresentation learning approach fused with Spatial Transformer Network (STN)\nmodule to capture shared semantic information and correspondences among\ndifferent viewpoints. In addition, we employ a curriculum-based randomization\nand augmentation approach to stabilize the RL training process and strengthen\nthe visual generalization ability. To exhibit the effectiveness of Maniwhere,\nwe meticulously design 8 tasks encompassing articulate objects, bi-manual, and\ndexterous hand manipulation tasks, demonstrating Maniwhere's strong visual\ngeneralization and sim2real transfer abilities across 3 hardware platforms. Our\nexperiments show that Maniwhere significantly outperforms existing\nstate-of-the-art methods. Videos are provided at\nhttps://gemcollector.github.io/maniwhere/.",
      "tldr_zh": "该研究提出了一种名为 Maniwhere 的视觉强化学习框架，旨在让机器人政策在多种视觉干扰下实现泛化操作。框架结合多视图表示学习与 Spatial Transformer Network (STN) 模块，捕捉不同视点间的共享语义信息和对应关系，并采用基于课程的随机化和增强方法来稳定训练过程并提升视觉泛化能力。在实验中，Maniwhere 在 8 个任务（包括 articulated 对象、双手动和灵巧手操作）上表现出色，并在 3 个硬件平台实现强视觉泛化和 sim2real 转移，显著优于现有最先进方法。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "Webpage: https://gemcollector.github.io/maniwhere/",
      "pdf_url": "http://arxiv.org/pdf/2407.15815v2",
      "published_date": "2024-07-22 17:29:02 UTC",
      "updated_date": "2024-10-23 05:32:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:48:45.156921"
    },
    {
      "arxiv_id": "2407.15814v2",
      "title": "Perceptions of Linguistic Uncertainty by Language Models and Humans",
      "title_zh": "语言模型和人类对语言不确定性的感知",
      "authors": [
        "Catarina G Belem",
        "Markelle Kelly",
        "Mark Steyvers",
        "Sameer Singh",
        "Padhraic Smyth"
      ],
      "abstract": "_Uncertainty expressions_ such as \"probably\" or \"highly unlikely\" are\npervasive in human language. While prior work has established that there is\npopulation-level agreement in terms of how humans quantitatively interpret\nthese expressions, there has been little inquiry into the abilities of language\nmodels in the same context. In this paper, we investigate how language models\nmap linguistic expressions of uncertainty to numerical responses. Our approach\nassesses whether language models can employ theory of mind in this setting:\nunderstanding the uncertainty of another agent about a particular statement,\nindependently of the model's own certainty about that statement. We find that 7\nout of 10 models are able to map uncertainty expressions to probabilistic\nresponses in a human-like manner. However, we observe systematically different\nbehavior depending on whether a statement is actually true or false. This\nsensitivity indicates that language models are substantially more susceptible\nto bias based on their prior knowledge (as compared to humans). These findings\nraise important questions and have broad implications for human-AI and AI-AI\ncommunication.",
      "tldr_zh": "这篇论文探讨了语言模型和人类对不确定性表达（如 \"uncertainty expressions\"）的感知差异，焦点在于这些表达如何被映射为数字概率响应。研究通过实验评估语言模型是否能运用理论思维（\"theory of mind\"），即理解其他代理的不确定性，而非受自身知识偏见影响。结果显示，10 个模型中有 7 个能以类似人类的方式处理这些表达，但模型对语句真实性的敏感度更高，导致更大的偏见问题。与人类相比，这种行为突显了语言模型在处理不确定性时的局限性。该发现对人类-AI 和 AI-AI 通信提出了重要启示。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at EMNLP 2024 (Main)",
      "pdf_url": "http://arxiv.org/pdf/2407.15814v2",
      "published_date": "2024-07-22 17:26:12 UTC",
      "updated_date": "2024-11-07 17:33:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:48:57.942704"
    },
    {
      "arxiv_id": "2407.15811v1",
      "title": "Stretching Each Dollar: Diffusion Training from Scratch on a Micro-Budget",
      "title_zh": "充分利用每一美元：从零开始的微预算扩散训练",
      "authors": [
        "Vikash Sehwag",
        "Xianghao Kong",
        "Jingtao Li",
        "Michael Spranger",
        "Lingjuan Lyu"
      ],
      "abstract": "As scaling laws in generative AI push performance, they also simultaneously\nconcentrate the development of these models among actors with large\ncomputational resources. With a focus on text-to-image (T2I) generative models,\nwe aim to address this bottleneck by demonstrating very low-cost training of\nlarge-scale T2I diffusion transformer models. As the computational cost of\ntransformers increases with the number of patches in each image, we propose to\nrandomly mask up to 75% of the image patches during training. We propose a\ndeferred masking strategy that preprocesses all patches using a patch-mixer\nbefore masking, thus significantly reducing the performance degradation with\nmasking, making it superior to model downscaling in reducing computational\ncost. We also incorporate the latest improvements in transformer architecture,\nsuch as the use of mixture-of-experts layers, to improve performance and\nfurther identify the critical benefit of using synthetic images in micro-budget\ntraining. Finally, using only 37M publicly available real and synthetic images,\nwe train a 1.16 billion parameter sparse transformer with only \\$1,890\neconomical cost and achieve a 12.7 FID in zero-shot generation on the COCO\ndataset. Notably, our model achieves competitive FID and high-quality\ngenerations while incurring 118$\\times$ lower cost than stable diffusion models\nand 14$\\times$ lower cost than the current state-of-the-art approach that costs\n\\$28,400. We aim to release our end-to-end training pipeline to further\ndemocratize the training of large-scale diffusion models on micro-budgets.",
      "tldr_zh": "这篇论文针对大规模文本到图像(T2I)生成模型的训练成本问题，提出了一种低预算方法，通过随机掩盖高达75%的图像补丁和deferred masking策略（如使用patch-mixer预处理）来显著减少计算开销，同时整合mixture-of-experts层和合成图像以提升性能。研究发现，使用仅37M真实和合成图像，训练一个11.6亿参数的稀疏transformer模型仅需1890美元，即可在COCO数据集上实现12.7的FID零样本生成性能，比Stable Diffusion低118倍成本，比当前最先进方法低14倍。最终，该方法旨在通过开源训练管道，促进大型扩散模型在微预算环境下的民主化训练。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "41 pages, 28 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2407.15811v1",
      "published_date": "2024-07-22 17:23:28 UTC",
      "updated_date": "2024-07-22 17:23:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:49:12.298911"
    },
    {
      "arxiv_id": "2407.15909v1",
      "title": "A Survey of Explainable Artificial Intelligence (XAI) in Financial Time Series Forecasting",
      "title_zh": "金融时间序列预测中可解释人工智能 (XAI) 的调查",
      "authors": [
        "Pierre-Daniel Arsenault",
        "Shengrui Wang",
        "Jean-Marc Patenande"
      ],
      "abstract": "Artificial Intelligence (AI) models have reached a very significant level of\naccuracy. While their superior performance offers considerable benefits, their\ninherent complexity often decreases human trust, which slows their application\nin high-risk decision-making domains, such as finance. The field of eXplainable\nAI (XAI) seeks to bridge this gap, aiming to make AI models more\nunderstandable. This survey, focusing on published work from the past five\nyears, categorizes XAI approaches that predict financial time series. In this\npaper, explainability and interpretability are distinguished, emphasizing the\nneed to treat these concepts separately as they are not applied the same way in\npractice. Through clear definitions, a rigorous taxonomy of XAI approaches, a\ncomplementary characterization, and examples of XAI's application in the\nfinance industry, this paper provides a comprehensive view of XAI's current\nrole in finance. It can also serve as a guide for selecting the most\nappropriate XAI approach for future applications.",
      "tldr_zh": "这篇论文调查了过去五年 Explainable AI (XAI) 在金融时间序列预测中的应用，旨在解决 AI 模型高准确性与低可信任性之间的矛盾，从而促进其在高风险领域如金融中的采用。论文区分了 explainability 和 interpretability 的概念，提供清晰定义、严格的 XAI 方法分类、补充特征描述以及实际行业应用示例。最终，它为未来选择合适的 XAI 策略提供了全面指导和参考框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "A.1; I.2; J.1"
      ],
      "primary_category": "cs.LG",
      "comment": "35 pages, This is the author's version of the work. It is posted here\n  for your personal use. Not for redistribution. The definitive Version of\n  Record will be published in a journal soon",
      "pdf_url": "http://arxiv.org/pdf/2407.15909v1",
      "published_date": "2024-07-22 17:06:19 UTC",
      "updated_date": "2024-07-22 17:06:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:49:22.103559"
    },
    {
      "arxiv_id": "2407.15793v4",
      "title": "CLIP with Generative Latent Replay: a Strong Baseline for Incremental Learning",
      "title_zh": "CLIP 结合生成式潜在重放：增量学习的强大基线",
      "authors": [
        "Emanuele Frascaroli",
        "Aniello Panariello",
        "Pietro Buzzega",
        "Lorenzo Bonicelli",
        "Angelo Porrello",
        "Simone Calderara"
      ],
      "abstract": "With the emergence of Transformers and Vision-Language Models (VLMs) such as\nCLIP, fine-tuning large pre-trained models has recently become a prevalent\nstrategy in Continual Learning. This has led to the development of numerous\nprompting strategies to adapt transformer-based models without incurring\ncatastrophic forgetting. However, these strategies often compromise the\noriginal zero-shot capabilities of the pre-trained CLIP model and struggle to\nadapt to domains that significantly deviate from the pre-training data. In this\nwork, we propose Continual Generative training for Incremental prompt-Learning,\na simple and novel approach to mitigate forgetting while adapting CLIP.\nBriefly, we employ Variational Autoencoders (VAEs) to learn class-conditioned\ndistributions within the embedding space of the visual encoder. We then exploit\nthese distributions to sample new synthetic visual embeddings and train the\ncorresponding class-specific textual prompts during subsequent tasks. Through\nextensive experiments on different domains, we show that such a generative\nreplay approach can adapt to new tasks while improving zero-shot capabilities,\nevaluated using a novel metric tailored for CL scenarios. Notably, further\nanalysis reveals that our approach can bridge the gap with joint prompt tuning.\nThe codebase is available at https://github.com/aimagelab/mammoth.",
      "tldr_zh": "本研究提出了一种名为“CLIP with Generative Latent Replay”的方法，作为持续学习(Continual Learning)中的强基线，旨在缓解微调预训练模型如 CLIP 时出现的灾难性遗忘问题，同时保留其零样本能力。方法利用 Variational Autoencoders (VAEs) 在视觉编码器的嵌入空间中学习类条件分布，并通过采样合成视觉嵌入来训练任务特定的文本提示，从而适应新任务。实验结果显示，该生成式重放方法在不同领域显著提升了模型的适应性和零样本性能，与联合提示调整相当，并提供开源代码以促进进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages, 1 figure. Accepted as ORAL at the The 35th British Machine\n  Vision Conference 2024 (BMVC 2024), Glasgow, UK",
      "pdf_url": "http://arxiv.org/pdf/2407.15793v4",
      "published_date": "2024-07-22 16:51:28 UTC",
      "updated_date": "2024-10-28 12:41:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:49:33.600569"
    },
    {
      "arxiv_id": "2408.03950v1",
      "title": "EcoFollower: An Environment-Friendly Car Following Model Considering Fuel Consumption",
      "title_zh": "EcoFollower：一种考虑燃油消耗的环境友好跟车模型",
      "authors": [
        "Hui Zhong",
        "Xianda Chen",
        "PakHin Tiu",
        "Hongliang Lu",
        "Meixin Zhu"
      ],
      "abstract": "To alleviate energy shortages and environmental impacts caused by\ntransportation, this study introduces EcoFollower, a novel eco-car-following\nmodel developed using reinforcement learning (RL) to optimize fuel consumption\nin car-following scenarios. Employing the NGSIM datasets, the performance of\nEcoFollower was assessed in comparison with the well-established Intelligent\nDriver Model (IDM). The findings demonstrate that EcoFollower excels in\nsimulating realistic driving behaviors, maintaining smooth vehicle operations,\nand closely matching the ground truth metrics of time-to-collision (TTC),\nheadway, and comfort. Notably, the model achieved a significant reduction in\nfuel consumption, lowering it by 10.42\\% compared to actual driving scenarios.\nThese results underscore the capability of RL-based models like EcoFollower to\nenhance autonomous vehicle algorithms, promoting safer and more\nenergy-efficient driving strategies.",
      "tldr_zh": "本研究引入了 EcoFollower，一种基于强化学习 (RL) 的环保跟车模型，旨在通过优化跟车场景中的驾驶行为来减少燃油消耗。模型使用 NGSIM 数据集与 Intelligent Driver Model (IDM) 进行比较，结果显示 EcoFollower 在模拟真实驾驶、保持平滑操作以及匹配时间到碰撞 (TTC)、跟车距离和舒适度指标方面表现出色。关键发现是，该模型将燃油消耗降低了 10.42%，从而证明了 RL 技术在提升自动驾驶算法的安全性和能源效率方面的潜力。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.03950v1",
      "published_date": "2024-07-22 16:48:37 UTC",
      "updated_date": "2024-07-22 16:48:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:49:46.681853"
    },
    {
      "arxiv_id": "2407.15786v2",
      "title": "LICORICE: Label-Efficient Concept-Based Interpretable Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuorui Ye",
        "Stephanie Milani",
        "Geoffrey J. Gordon",
        "Fei Fang"
      ],
      "abstract": "Recent advances in reinforcement learning (RL) have predominantly leveraged\nneural network policies for decision-making, yet these models often lack\ninterpretability, posing challenges for stakeholder comprehension and trust.\nConcept bottleneck models offer an interpretable alternative by integrating\nhuman-understandable concepts into policies. However, prior work assumes that\nconcept annotations are readily available during training. For RL, this\nrequirement poses a significant limitation: it necessitates continuous\nreal-time concept annotation, which either places an impractical burden on\nhuman annotators or incurs substantial costs in API queries and inference time\nwhen employing automated labeling methods. To overcome this limitation, we\nintroduce a novel training scheme that enables RL agents to efficiently learn a\nconcept-based policy by only querying annotators to label a small set of data.\nOur algorithm, LICORICE, involves three main contributions: interleaving\nconcept learning and RL training, using an ensemble to actively select\ninformative data points for labeling, and decorrelating the concept data. We\nshow how LICORICE reduces human labeling efforts to 500 or fewer concept labels\nin three environments, and 5000 or fewer in two more complex environments, all\nat no cost to performance. We also explore the use of VLMs as automated concept\nannotators, finding them effective in some cases but imperfect in others. Our\nwork significantly reduces the annotation burden for interpretable RL, making\nit more practical for real-world applications that necessitate transparency.",
      "tldr_zh": "该论文提出 LICORICE，一种标签高效的概念瓶颈模型（Concept bottleneck models），用于可解释强化学习（RL），以解决传统方法需要大量概念标注的局限性。该算法通过交错概念学习和 RL 训练、使用集合（ensemble）主动选择信息丰富的标注点，以及去相关概念数据，仅需 500 或更少的标签，即可在多个环境中实现高效政策学习，而不影响性能。此外，研究探讨了使用视觉语言模型（VLMs）作为自动标注器，其在某些情况下有效但不完美，从而降低了可解释 RL 在实际应用中的标注负担。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2407.15786v2",
      "published_date": "2024-07-22 16:46:33 UTC",
      "updated_date": "2025-03-20 07:50:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:50:00.220813"
    },
    {
      "arxiv_id": "2407.15784v1",
      "title": "Diffusion Model Based Resource Allocation Strategy in Ultra-Reliable Wireless Networked Control Systems",
      "title_zh": "基于扩散模型的资源分配策略在超可靠无线网络化控制系统中",
      "authors": [
        "Amirhassan Babazadeh Darabi",
        "Sinem Coleri"
      ],
      "abstract": "Diffusion models are vastly used in generative AI, leveraging their\ncapability to capture complex data distributions. However, their potential\nremains largely unexplored in the field of resource allocation in wireless\nnetworks. This paper introduces a novel diffusion model-based resource\nallocation strategy for Wireless Networked Control Systems (WNCSs) with the\nobjective of minimizing total power consumption through the optimization of the\nsampling period in the control system, and blocklength and packet error\nprobability in the finite blocklength regime of the communication system. The\nproblem is first reduced to the optimization of blocklength only based on the\nderivation of the optimality conditions. Then, the optimization theory solution\ncollects a dataset of channel gains and corresponding optimal blocklengths.\nFinally, the Denoising Diffusion Probabilistic Model (DDPM) uses this collected\ndataset to train the resource allocation algorithm that generates optimal\nblocklength values conditioned on the channel state information (CSI). Via\nextensive simulations, the proposed approach is shown to outperform previously\nproposed Deep Reinforcement Learning (DRL) based approaches with close to\noptimal performance regarding total power consumption. Moreover, an improvement\nof up to eighteen-fold in the reduction of critical constraint violations is\nobserved, further underscoring the accuracy of the solution.",
      "tldr_zh": "本研究提出了一种基于Diffusion Models的资源分配策略，用于超可靠无线网络控制系统(WNCSs)，旨在通过优化采样周期、块长(blocklength)和分组错误概率(packet error probability)来最小化总功耗。研究首先简化问题为仅优化块长，并利用优化理论收集信道增益和对应最佳块长的数据集，然后训练Denoising Diffusion Probabilistic Model (DDPM)来根据信道状态信息(CSI)生成最佳块长值。与现有的Deep Reinforcement Learning (DRL)方法相比，该策略在模拟实验中实现了更接近最优的功耗性能，并将关键约束违反减少了多达十八倍，展示了其准确性和有效性。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.IT",
        "cs.SY",
        "math.IT"
      ],
      "primary_category": "eess.SY",
      "comment": "5 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.15784v1",
      "published_date": "2024-07-22 16:44:57 UTC",
      "updated_date": "2024-07-22 16:44:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:50:10.995553"
    },
    {
      "arxiv_id": "2407.15780v1",
      "title": "Explaining Decisions in ML Models: a Parameterized Complexity Analysis",
      "title_zh": "机器学习模型中决策的解释：参数化复杂",
      "authors": [
        "Sebastian Ordyniak",
        "Giacomo Paesani",
        "Mateusz Rychlicki",
        "Stefan Szeider"
      ],
      "abstract": "This paper presents a comprehensive theoretical investigation into the\nparameterized complexity of explanation problems in various machine learning\n(ML) models. Contrary to the prevalent black-box perception, our study focuses\non models with transparent internal mechanisms. We address two principal types\nof explanation problems: abductive and contrastive, both in their local and\nglobal variants. Our analysis encompasses diverse ML models, including Decision\nTrees, Decision Sets, Decision Lists, Ordered Binary Decision Diagrams, Random\nForests, and Boolean Circuits, and ensembles thereof, each offering unique\nexplanatory challenges. This research fills a significant gap in explainable AI\n(XAI) by providing a foundational understanding of the complexities of\ngenerating explanations for these models. This work provides insights vital for\nfurther research in the domain of XAI, contributing to the broader discourse on\nthe necessity of transparency and accountability in AI systems.",
      "tldr_zh": "这篇论文对机器学习模型中解释问题的parameterized complexity进行了全面理论分析，聚焦于具有透明内部机制的模型，而不是黑箱系统。研究涵盖了abductive和contrastive解释的局部和全局变体，涉及多种模型如Decision Trees、Decision Sets、Decision Lists、Ordered Binary Decision Diagrams、Random Forests和Boolean Circuits及其集成。论文填补了可解释AI（XAI）领域的空白，通过揭示解释复杂性提供关键洞见，推动AI系统的透明度和责任性发展。",
      "categories": [
        "cs.AI",
        "cs.CC"
      ],
      "primary_category": "cs.AI",
      "comment": "A short version of the paper has been accepted at the 21st\n  International Conference on Principles of Knowledge Representation and\n  Reasoning (KR 2024)",
      "pdf_url": "http://arxiv.org/pdf/2407.15780v1",
      "published_date": "2024-07-22 16:37:48 UTC",
      "updated_date": "2024-07-22 16:37:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:50:23.484364"
    },
    {
      "arxiv_id": "2407.15771v1",
      "title": "Local Occupancy-Enhanced Object Grasping with Multiple Triplanar Projection",
      "title_zh": "局部占用增强对象抓取的多重三平面投影技术",
      "authors": [
        "Kangqi Ma",
        "Hao Dong",
        "Yadong Mu"
      ],
      "abstract": "This paper addresses the challenge of robotic grasping of general objects.\nSimilar to prior research, the task reads a single-view 3D observation (i.e.,\npoint clouds) captured by a depth camera as input. Crucially, the success of\nobject grasping highly demands a comprehensive understanding of the shape of\nobjects within the scene. However, single-view observations often suffer from\nocclusions (including both self and inter-object occlusions), which lead to\ngaps in the point clouds, especially in complex cluttered scenes. This renders\nincomplete perception of the object shape and frequently causes failures or\ninaccurate pose estimation during object grasping. In this paper, we tackle\nthis issue with an effective albeit simple solution, namely completing\ngrasping-related scene regions through local occupancy prediction. Following\nprior practice, the proposed model first runs by proposing a number of most\nlikely grasp points in the scene. Around each grasp point, a module is designed\nto infer any voxel in its neighborhood to be either void or occupied by some\nobject. Importantly, the occupancy map is inferred by fusing both local and\nglobal cues. We implement a multi-group tri-plane scheme for efficiently\naggregating long-distance contextual information. The model further estimates\n6-DoF grasp poses utilizing the local occupancy-enhanced object shape\ninformation and returns the top-ranked grasp proposal. Comprehensive\nexperiments on both the large-scale GraspNet-1Billion benchmark and real\nrobotic arm demonstrate that the proposed method can effectively complete the\nunobserved parts in cluttered and occluded scenes. Benefiting from the\noccupancy-enhanced feature, our model clearly outstrips other competing methods\nunder various performance metrics such as grasping average precision.",
      "tldr_zh": "本论文针对机器人抓取一般物体的挑战，提出一种基于局部占用预测的方法，以解决单视图点 clouds 中的遮挡（occlusions）问题，导致物体形状感知不完整。方法首先识别可能的抓取点，然后利用多组三平面投影（multiple triplanar projection）方案融合局部和全局线索，推断邻域体素的占用状态，从而增强物体形状信息。接着，模型基于增强后的特征估计6-DoF抓取姿势，并选择排名最高的抓取提案。实验结果显示，该方法在GraspNet-1Billion基准和真实机器人臂测试中有效完成未观察部分，并在grasping average precision等指标上显著优于其他方法。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.15771v1",
      "published_date": "2024-07-22 16:22:28 UTC",
      "updated_date": "2024-07-22 16:22:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:50:35.993888"
    },
    {
      "arxiv_id": "2407.15762v2",
      "title": "Conditional Language Policy: A General Framework for Steerable Multi-Objective Finetuning",
      "title_zh": "翻译失败",
      "authors": [
        "Kaiwen Wang",
        "Rahul Kidambi",
        "Ryan Sullivan",
        "Alekh Agarwal",
        "Christoph Dann",
        "Andrea Michi",
        "Marco Gelmi",
        "Yunxuan Li",
        "Raghav Gupta",
        "Avinava Dubey",
        "Alexandre Ramé",
        "Johan Ferret",
        "Geoffrey Cideron",
        "Le Hou",
        "Hongkun Yu",
        "Amr Ahmed",
        "Aranyak Mehta",
        "Léonard Hussenot",
        "Olivier Bachem",
        "Edouard Leurent"
      ],
      "abstract": "Reward-based finetuning is crucial for aligning language policies with\nintended behaviors (e.g., creativity and safety). A key challenge is to develop\nsteerable language models that trade-off multiple (conflicting) objectives in a\nflexible and efficient manner. This paper presents Conditional Language Policy\n(CLP), a general framework for finetuning language models on multiple\nobjectives. Building on techniques from multi-task training and\nparameter-efficient finetuning, CLP learn steerable models that effectively\ntrade-off conflicting objectives at inference time. Notably, this does not\nrequire training or maintaining multiple models to achieve different trade-offs\nbetween the objectives. Through extensive experiments and ablations on two\nsummarization datasets, we show that CLP learns steerable language models that\noutperform and Pareto-dominate the existing approaches for multi-objective\nfinetuning.",
      "tldr_zh": "该研究提出Conditional Language Policy (CLP)，一个通用框架，用于在多目标微调(multi-objective finetuning)中使语言模型实现灵活权衡（如创意与安全性等冲突目标）。CLP 基于多任务训练和参数高效微调(parameter-efficient finetuning)技术，允许模型在推理时有效调整目标取舍，而无需训练或维护多个模型。实验在两个总结数据集上表明，CLP 学习的可控语言模型优于现有方法，并在Pareto-dominate方面表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "40 pages. Findings of EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.15762v2",
      "published_date": "2024-07-22 16:13:38 UTC",
      "updated_date": "2024-10-23 17:42:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:50:47.638289"
    },
    {
      "arxiv_id": "2408.02379v1",
      "title": "The Contribution of XAI for the Safe Development and Certification of AI: An Expert-Based Analysis",
      "title_zh": "XAI 对 AI 安全开发和认证的贡献：基于专家的分析",
      "authors": [
        "Benjamin Fresz",
        "Vincent Philipp Göbels",
        "Safa Omri",
        "Danilo Brajovic",
        "Andreas Aichele",
        "Janika Kutz",
        "Jens Neuhüttler",
        "Marco F. Huber"
      ],
      "abstract": "Developing and certifying safe - or so-called trustworthy - AI has become an\nincreasingly salient issue, especially in light of upcoming regulation such as\nthe EU AI Act. In this context, the black-box nature of machine learning models\nlimits the use of conventional avenues of approach towards certifying complex\ntechnical systems. As a potential solution, methods to give insights into this\nblack-box - devised in the field of eXplainable AI (XAI) - could be used. In\nthis study, the potential and shortcomings of such methods for the purpose of\nsafe AI development and certification are discussed in 15 qualitative\ninterviews with experts out of the areas of (X)AI and certification. We find\nthat XAI methods can be a helpful asset for safe AI development, as they can\nshow biases and failures of ML-models, but since certification relies on\ncomprehensive and correct information about technical systems, their impact is\nexpected to be limited.",
      "tldr_zh": "本研究探讨了eXplainable AI (XAI) 在AI安全开发和认证中的作用，针对机器学习模型的黑箱问题及其与欧盟AI Act等法规的关联，通过15次定性专家访谈（来自(X)AI和认证领域）进行分析。结果表明，XAI方法有助于识别AI模型的偏差和故障，从而支持安全开发过程，但由于认证需要全面且准确的技术系统信息，其整体影响有限。该分析为未来AI监管和可解释性技术提供了宝贵见解。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.02379v1",
      "published_date": "2024-07-22 16:08:21 UTC",
      "updated_date": "2024-07-22 16:08:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:50:58.575126"
    },
    {
      "arxiv_id": "2407.15756v1",
      "title": "Model editing for distribution shifts in uranium oxide morphological analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Davis Brown",
        "Cody Nizinski",
        "Madelyn Shapiro",
        "Corey Fallon",
        "Tianzhixi Yin",
        "Henry Kvinge",
        "Jonathan H. Tu"
      ],
      "abstract": "Deep learning still struggles with certain kinds of scientific data. Notably,\npretraining data may not provide coverage of relevant distribution shifts\n(e.g., shifts induced via the use of different measurement instruments). We\nconsider deep learning models trained to classify the synthesis conditions of\nuranium ore concentrates (UOCs) and show that model editing is particularly\neffective for improving generalization to distribution shifts common in this\ndomain. In particular, model editing outperforms finetuning on two curated\ndatasets comprising of micrographs taken of U$_{3}$O$_{8}$ aged in humidity\nchambers and micrographs acquired with different scanning electron microscopes,\nrespectively.",
      "tldr_zh": "本研究探讨了深度学习在科学数据分析中的挑战，特别是预训练数据无法覆盖相关 distribution shifts（如不同测量仪器引起的偏移），并聚焦于铀氧化物形态分析。研究者训练了用于分类铀矿精矿（UOCs）合成条件的模型，并证明 model editing 比 finetuning 更有效地改善了对分布偏移的泛化能力。在两个数据集上的实验中，model editing 在 U₃O₈ 湿度老化显微照片和不同扫描电子显微镜获取的显微照片上表现出色，显著提升了模型性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Presented at CV4MS @ CVPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.15756v1",
      "published_date": "2024-07-22 16:06:51 UTC",
      "updated_date": "2024-07-22 16:06:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:51:11.520737"
    },
    {
      "arxiv_id": "2407.15748v1",
      "title": "MoRSE: Bridging the Gap in Cybersecurity Expertise with Retrieval Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Marco Simoni",
        "Andrea Saracino",
        "Vinod P.",
        "Mauro Conti"
      ],
      "abstract": "In this paper, we introduce MoRSE (Mixture of RAGs Security Experts), the\nfirst specialised AI chatbot for cybersecurity. MoRSE aims to provide\ncomprehensive and complete knowledge about cybersecurity. MoRSE uses two RAG\n(Retrieval Augmented Generation) systems designed to retrieve and organize\ninformation from multidimensional cybersecurity contexts. MoRSE differs from\ntraditional RAGs by using parallel retrievers that work together to retrieve\nsemantically related information in different formats and structures. Unlike\ntraditional Large Language Models (LLMs) that rely on Parametric Knowledge\nBases, MoRSE retrieves relevant documents from Non-Parametric Knowledge Bases\nin response to user queries. Subsequently, MoRSE uses this information to\ngenerate accurate answers. In addition, MoRSE benefits from real-time updates\nto its knowledge bases, enabling continuous knowledge enrichment without\nretraining. We have evaluated the effectiveness of MoRSE against other\nstate-of-the-art LLMs, evaluating the system on 600 cybersecurity specific\nquestions. The experimental evaluation has shown that the improvement in terms\nof relevance and correctness of the answer is more than 10\\% compared to known\nsolutions such as GPT-4 and Mixtral 7x8.",
      "tldr_zh": "本论文介绍了 MoRSE（Mixture of RAGs Security Experts），这是第一个专门针对网络安全的 AI 聊天机器人，旨在弥合网络安全专业知识的差距。MoRSE 采用两个 RAG（Retrieval Augmented Generation）系统，通过并行检索器从多维非参数知识库中检索语义相关信息，并生成准确的响应，与传统 LLMs（Large Language Models）的参数知识库方法不同，还支持实时更新知识库而无需重新训练。在针对 600 个网络安全问题的实验评估中，MoRSE 在相关性和正确性方面比 GPT-4 和 Mixtral 7x8 等模型提高了超过 10%，展示了其在网络安全领域的显著优势。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.15748v1",
      "published_date": "2024-07-22 15:53:27 UTC",
      "updated_date": "2024-07-22 15:53:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:51:22.623064"
    },
    {
      "arxiv_id": "2407.15739v1",
      "title": "Diffusion for Out-of-Distribution Detection on Road Scenes and Beyond",
      "title_zh": "翻译失败",
      "authors": [
        "Silvio Galesso",
        "Philipp Schröppel",
        "Hssan Driss",
        "Thomas Brox"
      ],
      "abstract": "In recent years, research on out-of-distribution (OoD) detection for semantic\nsegmentation has mainly focused on road scenes -- a domain with a constrained\namount of semantic diversity. In this work, we challenge this constraint and\nextend the domain of this task to general natural images. To this end, we\nintroduce: 1. the ADE-OoD benchmark, which is based on the ADE20k dataset and\nincludes images from diverse domains with a high semantic diversity, and 2. a\nnovel approach that uses Diffusion score matching for OoD detection (DOoD) and\nis robust to the increased semantic diversity. ADE-OoD features indoor and\noutdoor images, defines 150 semantic categories as in-distribution, and\ncontains a variety of OoD objects. For DOoD, we train a diffusion model with an\nMLP architecture on semantic in-distribution embeddings and build on the score\nmatching interpretation to compute pixel-wise OoD scores at inference time. On\ncommon road scene OoD benchmarks, DOoD performs on par or better than the state\nof the art, without using outliers for training or making assumptions about the\ndata domain. On ADE-OoD, DOoD outperforms previous approaches, but leaves much\nroom for future improvements.",
      "tldr_zh": "这项研究扩展了语义分割中 Out-of-Distribution (OoD) 检测的应用，从受限的道路场景到一般自然图像，引入了基于 ADE20k 的 ADE-OoD 基准数据集，以评估高语义多样性的图像。\n他们提出了一种新方法 DOoD，利用 Diffusion score matching 训练扩散模型在语义 in-distribution 嵌入上，生成像素级 OoD 分数，从而提高检测鲁棒性。\n在常见道路场景基准上，DOoD 的性能与最先进方法相当或更好，且不依赖异常值训练或数据域假设；在 ADE-OoD 测试中，它超过了现有方法，但仍有改进潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "ECCV 2024 - Benchmark page: https://ade-ood.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2407.15739v1",
      "published_date": "2024-07-22 15:41:37 UTC",
      "updated_date": "2024-07-22 15:41:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:51:35.668541"
    },
    {
      "arxiv_id": "2407.15738v3",
      "title": "Parallel Split Learning with Global Sampling",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammad Kohankhaki",
        "Ahmad Ayad",
        "Mahdi Barhoush",
        "Anke Schmeink"
      ],
      "abstract": "Distributed deep learning in resource-constrained environments faces\nscalability and generalization challenges due to large effective batch sizes\nand non-identically distributed client data. We introduce a server-driven\nsampling strategy that maintains a fixed global batch size by dynamically\nadjusting client-side batch sizes. This decouples the effective batch size from\nthe number of participating devices and ensures that global batches better\nreflect the overall data distribution. Using standard concentration bounds, we\nestablish tighter deviation guarantees compared to existing approaches.\nEmpirical results on a benchmark dataset confirm that the proposed method\nimproves model accuracy, training efficiency, and convergence stability,\noffering a scalable solution for learning at the network edge.",
      "tldr_zh": "本文提出了一种名为“Parallel Split Learning with Global Sampling”的方法，用于解决分布式深度学习在资源受限环境中的可扩展性和泛化挑战，该方法通过服务器驱动的采样策略动态调整客户端批量大小，以保持固定的全局批量大小，并确保全局批量更好地反映整体数据分布。相比现有方法，该策略利用标准concentration bounds建立了更紧的偏差保证。实验结果在基准数据集上表明，该方法显著提高了模型准确性、训练效率和收敛稳定性，为网络边缘学习提供了可扩展的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.15738v3",
      "published_date": "2024-07-22 15:41:23 UTC",
      "updated_date": "2025-05-03 18:37:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:51:47.768726"
    },
    {
      "arxiv_id": "2407.15734v1",
      "title": "TaskGen: A Task-Based, Memory-Infused Agentic Framework using StrictJSON",
      "title_zh": "翻译失败",
      "authors": [
        "John Chong Min Tan",
        "Prince Saroj",
        "Bharat Runwal",
        "Hardik Maheshwari",
        "Brian Lim Yi Sheng",
        "Richard Cottrill",
        "Alankrit Chona",
        "Ambuj Kumar",
        "Mehul Motani"
      ],
      "abstract": "TaskGen is an open-sourced agentic framework which uses an Agent to solve an\narbitrary task by breaking them down into subtasks. Each subtask is mapped to\nan Equipped Function or another Agent to execute. In order to reduce verbosity\n(and hence token usage), TaskGen uses StrictJSON that ensures JSON output from\nthe Large Language Model (LLM), along with additional features such as type\nchecking and iterative error correction. Key to the philosophy of TaskGen is\nthe management of information/memory on a need-to-know basis. We empirically\nevaluate TaskGen on various environments such as 40x40 dynamic maze navigation\nwith changing obstacle locations (100% solve rate), TextWorld escape room\nsolving with dense rewards and detailed goals (96% solve rate), web browsing\n(69% of actions successful), solving the MATH dataset (71% solve rate over 100\nLevel-5 problems), Retrieval Augmented Generation on NaturalQuestions dataset\n(F1 score of 47.03%)",
      "tldr_zh": "TaskGen 是一个开源的代理框架（Agentic Framework），它通过将任意任务分解成子任务来实现高效解决，每个子任务映射到 Equipped Function 或另一个 Agent 执行。框架采用 StrictJSON 来确保 LLM 输出为 JSON 格式，减少冗余并提供类型检查和迭代错误修正，同时强调按需管理信息/内存。实验评估显示，TaskGen 在多种环境中表现出色，包括 40x40 动态迷宫导航（100% 解决率）、TextWorld 逃脱室（96% 解决率）、网页浏览（69% 动作成功）、MATH 数据集（71% 解决率）和 NaturalQuestions 检索增强生成（F1 分数 47.03%）。这为任务分解和代理系统提供了可扩展的实用方法。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "53 pages",
      "pdf_url": "http://arxiv.org/pdf/2407.15734v1",
      "published_date": "2024-07-22 15:37:41 UTC",
      "updated_date": "2024-07-22 15:37:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:52:00.376843"
    },
    {
      "arxiv_id": "2407.15723v1",
      "title": "DStruct2Design: Data and Benchmarks for Data Structure Driven Generative Floor Plan Design",
      "title_zh": "DStruct2Design：数据和基准用于数据结构驱动的生成式楼层平面图设计",
      "authors": [
        "Zhi Hao Luo",
        "Luis Lara",
        "Ge Ya Luo",
        "Florian Golemo",
        "Christopher Beckham",
        "Christopher Pal"
      ],
      "abstract": "Text conditioned generative models for images have yielded impressive\nresults. Text conditioned floorplan generation as a special type of raster\nimage generation task also received particular attention. However there are\nmany use cases in floorpla generation where numerical properties of the\ngenerated result are more important than the aesthetics. For instance, one\nmight want to specify sizes for certain rooms in a floorplan and compare the\ngenerated floorplan with given specifications Current approaches, datasets and\ncommonly used evaluations do not support these kinds of constraints. As such,\nan attractive strategy is to generate an intermediate data structure that\ncontains numerical properties of a floorplan which can be used to generate the\nfinal floorplan image. To explore this setting we (1) construct a new dataset\nfor this data-structure to data-structure formulation of floorplan generation\nusing two popular image based floorplan datasets RPLAN and ProcTHOR-10k, and\nprovide the tools to convert further procedurally generated ProcTHOR floorplan\ndata into our format. (2) We explore the task of floorplan generation given a\npartial or complete set of constraints and we design a series of metrics and\nbenchmarks to enable evaluating how well samples generated from models respect\nthe constraints. (3) We create multiple baselines by finetuning a large\nlanguage model (LLM), Llama3, and demonstrate the feasibility of using\nfloorplan data structure conditioned LLMs for the problem of floorplan\ngeneration respecting numerical constraints. We hope that our new datasets and\nbenchmarks will encourage further research on different ways to improve the\nperformance of LLMs and other generative modelling techniques for generating\ndesigns where quantitative constraints are only partially specified, but must\nbe respected.",
      "tldr_zh": "该论文提出了 DStruct2Design，这是一个基于数据结构的数据集和基准，用于文本条件生成楼层平面图设计，重点解决数值属性（如房间大小）约束的问题，以弥补现有方法的不足。研究者构建了新数据集，通过转换 RPLAN 和 ProcTHOR-10k 等图像数据集，提供工具支持进一步数据格式化。论文探索了给定部分或完整约束的楼层平面图生成任务，并设计了系列指标和基准来评估生成样本对约束的遵守度。通过微调大型语言模型（LLM）Llama3，创建了多个基线模型，证明了使用数据结构条件LLM生成符合量化约束的设计是可行的，并呼吁更多研究来提升此类生成技术的性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.15723v1",
      "published_date": "2024-07-22 15:27:55 UTC",
      "updated_date": "2024-07-22 15:27:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:52:13.736890"
    },
    {
      "arxiv_id": "2407.15720v2",
      "title": "Do Large Language Models Have Compositional Ability? An Investigation into Limitations and Scalability",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuoyan Xu",
        "Zhenmei Shi",
        "Yingyu Liang"
      ],
      "abstract": "Large language models (LLMs) have emerged as powerful tools for many AI\nproblems and exhibit remarkable in-context learning (ICL) capabilities.\nCompositional ability, solving unseen complex tasks that combine two or more\nsimple tasks, is an essential reasoning ability for Artificial General\nIntelligence. Despite the tremendous success of LLMs, how they approach\ncomposite tasks, especially those not encountered during the pretraining phase,\nremains an open and largely underexplored question. In this study, we delve\ninto the ICL capabilities of LLMs on composite tasks, with only simple tasks as\nin-context examples. We develop a test suite of composite tasks including\nlinguistic and logical challenges and perform empirical studies across\ndifferent LLM families. We observe that models exhibit divergent behaviors: (1)\nFor simpler composite tasks that apply distinct mapping mechanisms to different\ninput segments, the models demonstrate decent compositional ability, while\nscaling up the model enhances this ability; (2) for more complex composite\ntasks involving reasoning multiple steps, where each step represents one task,\nmodels typically underperform, and scaling up generally provides no\nimprovements. We offer theoretical analysis in a simplified setting, explaining\nthat models exhibit compositional capability when the task handles different\ninput parts separately. We believe our work sheds new light on the capabilities\nof LLMs in solving composite tasks regarding the nature of the tasks and model\nscale. Our dataset and code are available at\n{\\url{https://github.com/OliverXUZY/LLM_Compose}}.",
      "tldr_zh": "本研究调查大型语言模型 (LLMs) 是否具备组合能力，即解决未见过的复杂任务，这些任务将两个或多个简单任务结合，这对实现通用人工智能 (AGI) 至关重要。研究者开发了一个测试套件，包括语言和逻辑挑战，通过 in-context learning (ICL) 仅使用简单任务作为上下文示例，对不同 LLMs 家族进行了实证分析。结果发现，对于较简单的组合任务（涉及不同输入段的独立映射），模型表现出良好的能力，且模型规模的扩大能进一步提升表现；然而，对于多步推理的复杂任务，模型通常表现不佳，扩大规模也无显著改善。该研究提供了理论分析，解释了模型在处理分离输入部分时显示组合能力的条件，并公开了数据集和代码。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.15720v2",
      "published_date": "2024-07-22 15:22:34 UTC",
      "updated_date": "2024-08-11 04:39:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:52:25.935693"
    },
    {
      "arxiv_id": "2407.15719v3",
      "title": "GFE-Mamba: Mamba-based AD Multi-modal Progression Assessment via Generative Feature Extraction from MCI",
      "title_zh": "翻译失败",
      "authors": [
        "Zhaojie Fang",
        "Shenghao Zhu",
        "Yifei Chen",
        "Binfeng Zou",
        "Fan Jia",
        "Chang Liu",
        "Xiang Feng",
        "Linwei Qiu",
        "Feiwei Qin",
        "Jin Fan",
        "Changbiao Chu",
        "Changmiao Wang"
      ],
      "abstract": "Alzheimer's Disease (AD) is a progressive, irreversible neurodegenerative\ndisorder that often originates from Mild Cognitive Impairment (MCI). This\nprogression results in significant memory loss and severely affects patients'\nquality of life. Clinical trials have consistently shown that early and\ntargeted interventions for individuals with MCI may slow or even prevent the\nadvancement of AD. Research indicates that accurate medical classification\nrequires diverse multimodal data, including detailed assessment scales and\nneuroimaging techniques like Magnetic Resonance Imaging (MRI) and Positron\nEmission Tomography (PET). However, simultaneously collecting the\naforementioned three modalities for training presents substantial challenges.\nTo tackle these difficulties, we propose GFE-Mamba, a multimodal classifier\nfounded on Generative Feature Extractor. The intermediate features provided by\nthis Extractor can compensate for the shortcomings of PET and achieve profound\nmultimodal fusion in the classifier. The Mamba block, as the backbone of the\nclassifier, enables it to efficiently extract information from long-sequence\nscale information. Pixel-level Bi-cross Attention supplements pixel-level\ninformation from MRI and PET. We provide our rationale for developing this\ncross-temporal progression prediction dataset and the pre-trained Extractor\nweights. Our experimental findings reveal that the GFE-Mamba model effectively\npredicts the progression from MCI to AD and surpasses several leading methods\nin the field. Our source code is available at\nhttps://github.com/Tinysqua/GFE-Mamba.",
      "tldr_zh": "这篇论文针对阿尔茨海默病（AD）从轻度认知障碍（MCI）进展的预测挑战，提出 GFE-Mamba 模型，该模型基于 Generative Feature Extractor 生成中间特征来补偿 PET 数据的缺失，并通过 Mamba block 高效提取长序列信息以及 Pixel-level Bi-cross Attention 融合 MRI 和 PET 的像素级细节。GFE-Mamba 实现了多模态数据的深度融合，解决了数据收集难题。实验结果表明，该模型在预测 MCI 到 AD 进展方面优于现有方法，并提供了开源代码和预训练权重。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.15719v3",
      "published_date": "2024-07-22 15:22:33 UTC",
      "updated_date": "2025-01-29 06:35:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:52:36.114958"
    },
    {
      "arxiv_id": "2407.15714v1",
      "title": "Mamba meets crack segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhili He",
        "Yu-Hsing Wang"
      ],
      "abstract": "Cracks pose safety risks to infrastructure and cannot be overlooked. The\nprevailing structures in existing crack segmentation networks predominantly\nconsist of CNNs or Transformers. However, CNNs exhibit a deficiency in global\nmodeling capability, hindering the representation to entire crack features.\nTransformers can capture long-range dependencies but suffer from high and\nquadratic complexity. Recently, Mamba has garnered extensive attention due to\nits linear spatial and computational complexity and its powerful global\nperception. This study explores the representation capabilities of Mamba to\ncrack features. Specifically, this paper uncovers the connection between Mamba\nand the attention mechanism, providing a profound insight, an attention\nperspective, into interpreting Mamba and devising a novel Mamba module\nfollowing the principles of attention blocks, namely CrackMamba. We compare\nCrackMamba with the most prominent visual Mamba modules, Vim and Vmamba, on two\ndatasets comprising asphalt pavement and concrete pavement cracks, and steel\ncracks, respectively. The quantitative results show that CrackMamba stands out\nas the sole Mamba block consistently enhancing the baseline model's performance\nacross all evaluation measures, while reducing its parameters and computational\ncosts. Moreover, this paper substantiates that Mamba can achieve global\nreceptive fields through both theoretical analysis and visual interpretability.\nThe discoveries of this study offer a dual contribution. First, as a\nplug-and-play and simple yet effective Mamba module, CrackMamba exhibits\nimmense potential for integration into various crack segmentation models.\nSecond, the proposed innovative Mamba design concept, integrating Mamba with\nthe attention mechanism, holds significant reference value for all Mamba-based\ncomputer vision models, not limited to crack segmentation networks, as\ninvestigated in this study.",
      "tldr_zh": "本研究探讨了Mamba模型在裂缝分割任务中的应用，以解决CNNs的全局建模不足和Transformers的高计算复杂度问题。论文揭示了Mamba与注意力机制的内在联系，并设计了CrackMamba模块，该模块遵循注意力块原理，增强裂缝特征表示。实验结果显示，CrackMamba在沥青路面、混凝土路面和钢材裂缝数据集上优于Vim和Vmamba模块，不仅提升了基线模型的性能，还降低了参数和计算成本。通过理论分析和可视化，证明Mamba能实现全局感受野，为裂缝分割及其他计算机视觉模型提供即插即用的创新设计概念。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "32 pages, 8 figures. Preprint submitted to Elsevier",
      "pdf_url": "http://arxiv.org/pdf/2407.15714v1",
      "published_date": "2024-07-22 15:21:35 UTC",
      "updated_date": "2024-07-22 15:21:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:52:48.462274"
    },
    {
      "arxiv_id": "2407.15708v2",
      "title": "SwinSF: Image Reconstruction from Spatial-Temporal Spike Streams",
      "title_zh": "SwinSF: 基于空间-时间尖峰流的图像重建",
      "authors": [
        "Liangyan Jiang",
        "Chuang Zhu",
        "Yanxu Chen"
      ],
      "abstract": "The spike camera, with its high temporal resolution, low latency, and high\ndynamic range, addresses high-speed imaging challenges like motion blur. It\ncaptures photons at each pixel independently, creating binary spike streams\nrich in temporal information but challenging for image reconstruction. Current\nalgorithms, both traditional and deep learning-based, still need to be improved\nin the utilization of the rich temporal detail and the restoration of the\ndetails of the reconstructed image. To overcome this, we introduce Swin\nSpikeformer (SwinSF), a novel model for dynamic scene reconstruction from spike\nstreams. SwinSF is composed of Spike Feature Extraction, Spatial-Temporal\nFeature Extraction, and Final Reconstruction Module. It combines shifted window\nself-attention and proposed temporal spike attention, ensuring a comprehensive\nfeature extraction that encapsulates both spatial and temporal dynamics,\nleading to a more robust and accurate reconstruction of spike streams.\nFurthermore, we build a new synthesized dataset for spike image reconstruction\nwhich matches the resolution of the latest spike camera, ensuring its relevance\nand applicability to the latest developments in spike camera imaging.\nExperimental results demonstrate that the proposed network SwinSF sets a new\nbenchmark, achieving state-of-the-art performance across a series of datasets,\nincluding both real-world and synthesized data across various resolutions. Our\ncodes and proposed dataset will be available soon.",
      "tldr_zh": "本研究针对 spike camera 的高时间分辨率、低延迟和高动态范围特性，提出 SwinSF 模型，用于从空间-时间 spike streams 重建动态场景图像，以解决现有算法在利用时间细节和图像细节恢复上的不足。SwinSF 包括 Spike Feature Extraction、Spatial-Temporal Feature Extraction 和 Final Reconstruction Module 模块，结合 shifted window self-attention 和 temporal spike attention，实现对空间和时间动态的全面特征提取，从而提升重建精度。该模型在构建的新合成数据集以及多种真实和合成数据集上实现了最先进性能，准确率显著提高，代码和数据集即将公开。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.15708v2",
      "published_date": "2024-07-22 15:17:39 UTC",
      "updated_date": "2024-07-24 16:55:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:52:59.877159"
    },
    {
      "arxiv_id": "2407.15707v1",
      "title": "Predicting the Best of N Visual Trackers",
      "title_zh": "翻译失败",
      "authors": [
        "Basit Alawode",
        "Sajid Javed",
        "Arif Mahmood",
        "Jiri Matas"
      ],
      "abstract": "We observe that the performance of SOTA visual trackers surprisingly strongly\nvaries across different video attributes and datasets. No single tracker\nremains the best performer across all tracking attributes and datasets. To\nbridge this gap, for a given video sequence, we predict the \"Best of the N\nTrackers\", called the BofN meta-tracker. At its core, a Tracking Performance\nPrediction Network (TP2N) selects a predicted best performing visual tracker\nfor the given video sequence using only a few initial frames. We also introduce\na frame-level BofN meta-tracker which keeps predicting best performer after\nregular temporal intervals. The TP2N is based on self-supervised learning\narchitectures MocoV2, SwAv, BT, and DINO; experiments show that the DINO with\nViT-S as a backbone performs the best. The video-level BofN meta-tracker\noutperforms, by a large margin, existing SOTA trackers on nine standard\nbenchmarks - LaSOT, TrackingNet, GOT-10K, VOT2019, VOT2021, VOT2022, UAV123,\nOTB100, and WebUAV-3M. Further improvement is achieved by the frame-level BofN\nmeta-tracker effectively handling variations in the tracking scenarios within\nlong sequences. For instance, on GOT-10k, BofN meta-tracker average overlap is\n88.7% and 91.1% with video and frame-level settings respectively. The best\nperforming tracker, RTS, achieves 85.20% AO. On VOT2022, BofN expected average\noverlap is 67.88% and 70.98% with video and frame level settings, compared to\nthe best performing ARTrack, 64.12%. This work also presents an extensive\nevaluation of competitive tracking methods on all commonly used benchmarks,\nfollowing their protocols. The code, the trained models, and the results will\nsoon be made publicly available on\nhttps://github.com/BasitAlawode/Best_of_N_Trackers.",
      "tldr_zh": "本研究观察到SOTA视觉追踪器在不同视频属性和数据集上的性能差异显著，没有单一追踪器能始终表现最佳。为此，提出BofN meta-tracker框架，通过Tracking Performance Prediction Network (TP2N)利用视频序列的初始帧预测最佳追踪器，TP2N基于自监督学习架构如DINO with ViT-S实现。实验结果显示，视频级BofN meta-tracker在九个标准基准（如LaSOT、TrackingNet和GOT-10k）上大幅优于现有SOTA追踪器，例如在GOT-10k上达到88.7%的平均重叠率，而最佳追踪器RTS仅为85.20%；帧级版本进一步提升性能，处理长序列中的变化更有效。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.15707v1",
      "published_date": "2024-07-22 15:17:09 UTC",
      "updated_date": "2024-07-22 15:17:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:53:13.522006"
    },
    {
      "arxiv_id": "2407.15700v1",
      "title": "A Life-long Learning Intrusion Detection System for 6G-Enabled IoV",
      "title_zh": "翻译失败",
      "authors": [
        "Abdelaziz Amara korba",
        "Souad Sebaa",
        "Malik Mabrouki",
        "Yacine Ghamri-Doudane",
        "Karima Benatchba"
      ],
      "abstract": "The introduction of 6G technology into the Internet of Vehicles (IoV)\npromises to revolutionize connectivity with ultra-high data rates and seamless\nnetwork coverage. However, this technological leap also brings significant\nchallenges, particularly for the dynamic and diverse IoV landscape, which must\nmeet the rigorous reliability and security requirements of 6G networks.\nFurthermore, integrating 6G will likely increase the IoV's susceptibility to a\nspectrum of emerging cyber threats. Therefore, it is crucial for security\nmechanisms to dynamically adapt and learn new attack patterns, keeping pace\nwith the rapid evolution and diversification of these threats - a capability\ncurrently lacking in existing systems. This paper presents a novel intrusion\ndetection system leveraging the paradigm of life-long (or continual) learning.\nOur methodology combines class-incremental learning with federated learning, an\napproach ideally suited to the distributed nature of the IoV. This strategy\neffectively harnesses the collective intelligence of Connected and Automated\nVehicles (CAVs) and edge computing capabilities to train the detection system.\nTo the best of our knowledge, this study is the first to synergize\nclass-incremental learning with federated learning specifically for cyber\nattack detection. Through comprehensive experiments on a recent network traffic\ndataset, our system has exhibited a robust adaptability in learning new cyber\nattack patterns, while effectively retaining knowledge of previously\nencountered ones. Additionally, it has proven to maintain high accuracy and a\nlow false positive rate.",
      "tldr_zh": "这篇论文针对 6G 技术在 Internet of Vehicles (IoV) 中的应用，提出了一种基于 life-long learning 的入侵检测系统，以动态适应新兴网络威胁。方法结合 class-incremental learning 和 federated learning，利用 Connected and Automated Vehicles (CAVs) 及 edge computing 的分布式能力进行集体训练，确保系统能高效学习新攻击模式。实验在最近的网络流量数据集上验证，该系统表现出色，能够保留旧知识、保持高准确率并降低假阳性率。该研究是首个将 class-incremental learning 与 federated learning 整合用于网络攻击检测的创新尝试。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.15700v1",
      "published_date": "2024-07-22 15:07:27 UTC",
      "updated_date": "2024-07-22 15:07:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:53:24.413563"
    },
    {
      "arxiv_id": "2407.15688v1",
      "title": "AI-Driven Fast and Early Detection of IoT Botnet Threats: A Comprehensive Network Traffic Analysis Approach",
      "title_zh": "AI驱动",
      "authors": [
        "Abdelaziz Amara korba",
        "Aleddine Diaf",
        "Yacine Ghamri-Doudane"
      ],
      "abstract": "In the rapidly evolving landscape of cyber threats targeting the Internet of\nThings (IoT) ecosystem, and in light of the surge in botnet-driven Distributed\nDenial of Service (DDoS) and brute force attacks, this study focuses on the\nearly detection of IoT bots. It specifically addresses the detection of stealth\nbot communication that precedes and orchestrates attacks. This study proposes a\ncomprehensive methodology for analyzing IoT network traffic, including\nconsiderations for both unidirectional and bidirectional flow, as well as\npacket formats. It explores a wide spectrum of network features critical for\nrepresenting network traffic and characterizing benign IoT traffic patterns\neffectively. Moreover, it delves into the modeling of traffic using various\nsemi-supervised learning techniques. Through extensive experimentation with the\nIoT-23 dataset - a comprehensive collection featuring diverse botnet types and\ntraffic scenarios - we have demonstrated the feasibility of detecting botnet\ntraffic corresponding to different operations and types of bots, specifically\nfocusing on stealth command and control (C2) communications. The results\nobtained have demonstrated the feasibility of identifying C2 communication with\na 100% success rate through packet-based methods and 94% via flow based\napproaches, with a false positive rate of 1.53%.",
      "tldr_zh": "这篇论文提出了一种AI驱动的全面网络流量分析方法，用于快速早期检测IoT机器人网络（botnet）威胁，特别是针对DDoS和暴力攻击前的隐蔽命令和控制（C2）通信。方法包括分析单向和双向流量、数据包格式，并提取关键网络特征来表征良性IoT流量模式，同时采用半监督学习技术进行流量建模。通过在IoT-23数据集上的广泛实验，论文证明了检测不同类型botnet的 feasibility，实现了100%的数据包基于检测成功率和94%的流量基于检测成功率，假阳性率仅为1.53%。这为IoT安全提供了高效、可信的威胁检测框架。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.15688v1",
      "published_date": "2024-07-22 14:54:40 UTC",
      "updated_date": "2024-07-22 14:54:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:53:37.612768"
    },
    {
      "arxiv_id": "2407.15680v1",
      "title": "HaloQuest: A Visual Hallucination Dataset for Advancing Multimodal Reasoning",
      "title_zh": "HaloQuest：用于推进多模态推理的视觉幻觉数据集",
      "authors": [
        "Zhecan Wang",
        "Garrett Bingham",
        "Adams Yu",
        "Quoc Le",
        "Thang Luong",
        "Golnaz Ghiasi"
      ],
      "abstract": "Hallucination has been a major problem for large language models and remains\na critical challenge when it comes to multimodality in which vision-language\nmodels (VLMs) have to deal with not just textual but also visual inputs.\nDespite rapid progress in VLMs, resources for evaluating and addressing\nmultimodal hallucination are limited and mostly focused on evaluation. This\nwork introduces HaloQuest, a novel visual question answering dataset that\ncaptures various aspects of multimodal hallucination such as false premises,\ninsufficient contexts, and visual challenges. A novel idea from HaloQuest is to\nleverage synthetic images, apart from real ones, to enable dataset creation at\nscale. With over 7.7K examples spanning across a wide variety of categories,\nHaloQuest was designed to be both a challenging benchmark for VLMs and a\nfine-tuning dataset for advancing multimodal reasoning. Our experiments reveal\nthat current models struggle with HaloQuest, with all open-source VLMs\nachieving below 36% accuracy. On the other hand, fine-tuning on HaloQuest\nsignificantly reduces hallucination rates while preserving performance on\nstandard reasoning tasks. Our results discover that benchmarking with generated\nimages is highly correlated (r=0.97) with real images. Last but not least, we\npropose a novel Auto-Eval mechanism that is highly correlated with human raters\n(r=0.99) for evaluating VLMs. In sum, this work makes concrete strides towards\nunderstanding, evaluating, and mitigating hallucination in VLMs, serving as an\nimportant step towards more reliable multimodal AI systems in the future.",
      "tldr_zh": "该研究引入了HaloQuest，这是一个新的视觉问答数据集，旨在评估和缓解视觉语言模型(VLMs)中的多模态幻觉问题，如虚假前提、不充分上下文和视觉挑战。HaloQuest利用合成图像（结合真实图像）实现了大规模创建，包含超过7.7K个例子，覆盖多种类别，可作为VLMs的基准测试和微调数据集。实验显示，当前开源VLMs在HaloQuest上的准确率低于36%，但通过在该数据集上微调，能显著降低幻觉率，同时保持标准推理任务的性能；此外，提出的Auto-Eval机制与人类评估高度相关(r=0.99)，为构建更可靠的多模态AI系统提供了重要工具。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted as a main conference paper at ECCV 2024\n  (https://github.com/google/haloquest)",
      "pdf_url": "http://arxiv.org/pdf/2407.15680v1",
      "published_date": "2024-07-22 14:49:51 UTC",
      "updated_date": "2024-07-22 14:49:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:53:48.525067"
    },
    {
      "arxiv_id": "2407.15906v3",
      "title": "An Ad-hoc graph node vector embedding algorithm for general knowledge graphs using Kinetica-Graph",
      "title_zh": "翻译失败",
      "authors": [
        "B. Kaan Karamete",
        "Eli Glaser"
      ],
      "abstract": "This paper discusses how to generate general graph node embeddings from\nknowledge graph representations. The embedded space is composed of a number of\nsub-features to mimic both local affinity and remote structural relevance.\nThese sub-feature dimensions are defined by several indicators that we\nspeculate to catch nodal similarities, such as hop-based topological patterns,\nthe number of overlapping labels, the transitional probabilities (markov-chain\nprobabilities), and the cluster indices computed by our recursive spectral\nbisection (RSB) algorithm. These measures are flattened over the one\ndimensional vector space into their respective sub-component ranges such that\nthe entire set of vector similarity functions could be used for finding similar\nnodes. The error is defined by the sum of pairwise square differences across a\nrandomly selected sample of graph nodes between the assumed embeddings and the\nground truth estimates as our novel loss function. The ground truth is\nestimated to be a combination of pairwise Jaccard similarity and the number of\noverlapping labels. Finally, we demonstrate a multi-variate stochastic gradient\ndescent (SGD) algorithm to compute the weighing factors among sub-vector spaces\nto minimize the average error using a random sampling logic.",
      "tldr_zh": "这篇论文提出了一种ad-hoc图节点向量嵌入算法，使用Kinetica-Graph生成一般知识图谱的节点嵌入，以捕捉局部亲和力和远程结构相关性。算法通过子特征维度模拟多种指标，包括hop-based topological patterns、重叠labels数、markov-chain probabilities和RSB算法计算的聚类指数，这些特征被平铺到一个一维向量空间中，以支持节点相似性计算。损失函数基于成对平方差与ground truth（Jaccard相似度和重叠labels）的比较，并采用多变量SGD算法优化权重因子，从而最小化平均嵌入错误。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 17 figures, 16 references",
      "pdf_url": "http://arxiv.org/pdf/2407.15906v3",
      "published_date": "2024-07-22 14:43:10 UTC",
      "updated_date": "2025-01-02 20:52:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:54:01.749284"
    },
    {
      "arxiv_id": "2407.15675v1",
      "title": "Flow-guided Motion Prediction with Semantics and Dynamic Occupancy Grid Maps",
      "title_zh": "翻译失败",
      "authors": [
        "Rabbia Asghar",
        "Wenqian Liu",
        "Lukas Rummelhard",
        "Anne Spalanzani",
        "Christian Laugier"
      ],
      "abstract": "Accurate prediction of driving scenes is essential for road safety and\nautonomous driving. Occupancy Grid Maps (OGMs) are commonly employed for scene\nprediction due to their structured spatial representation, flexibility across\nsensor modalities and integration of uncertainty. Recent studies have\nsuccessfully combined OGMs with deep learning methods to predict the evolution\nof scene and learn complex behaviours. These methods, however, do not consider\nprediction of flow or velocity vectors in the scene. In this work, we propose a\nnovel multi-task framework that leverages dynamic OGMs and semantic information\nto predict both future vehicle semantic grids and the future flow of the scene.\nThis incorporation of semantic flow not only offers intermediate scene features\nbut also enables the generation of warped semantic grids. Evaluation on the\nreal-world NuScenes dataset demonstrates improved prediction capabilities and\nenhanced ability of the model to retain dynamic vehicles within the scene.",
      "tldr_zh": "本文提出一个多任务框架，利用动态 Occupancy Grid Maps (OGMs) 和语义信息，预测驾驶场景的未来车辆语义网格和场景流，以弥补现有方法忽略流或速度向量预测的不足。框架通过整合语义流作为中间特征，实现扭曲语义网格的生成，从而提升场景预测的准确性和动态车辆保留能力。在 NuScenes 数据集上的评估显示，该方法比基线模型显著提高了预测性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted for publication at the 27th IEEE International Conference on\n  Intelligent Transportation Systems (ITSC) (ITSC 2024)",
      "pdf_url": "http://arxiv.org/pdf/2407.15675v1",
      "published_date": "2024-07-22 14:42:34 UTC",
      "updated_date": "2024-07-22 14:42:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:54:12.785854"
    },
    {
      "arxiv_id": "2407.15671v1",
      "title": "Problems in AI, their roots in philosophy, and implications for science and society",
      "title_zh": "AI 中的问题：其根源于哲学，以及对科学和社会的影响",
      "authors": [
        "Max Velthoven",
        "Eric Marcus"
      ],
      "abstract": "Artificial Intelligence (AI) is one of today's most relevant emergent\ntechnologies. In view thereof, this paper proposes that more attention should\nbe paid to the philosophical aspects of AI technology and its use. It is argued\nthat this deficit is generally combined with philosophical misconceptions about\nthe growth of knowledge. To identify these misconceptions, reference is made to\nthe ideas of the philosopher of science Karl Popper and the physicist David\nDeutsch. The works of both thinkers aim against mistaken theories of knowledge,\nsuch as inductivism, empiricism, and instrumentalism. This paper shows that\nthese theories bear similarities to how current AI technology operates. It also\nshows that these theories are very much alive in the (public) discourse on AI,\noften called Bayesianism. In line with Popper and Deutsch, it is proposed that\nall these theories are based on mistaken philosophies of knowledge. This\nincludes an analysis of the implications of these mistaken philosophies for the\nuse of AI in science and society, including some of the likely problem\nsituations that will arise. This paper finally provides a realistic outlook on\nArtificial General Intelligence (AGI) and three propositions on A(G)I and\nphilosophy (i.e., epistemology).",
      "tldr_zh": "这篇论文探讨了人工智能（AI）领域的问题及其哲学根源，强调应更多关注AI技术的哲学方面，以纠正对知识增长的误解。作者参考哲学家Karl Popper和物理学家David Deutsch的观点，批评归纳主义（inductivism）、经验主义（empiricism）和工具主义（instrumentalism）等错误知识理论，并指出这些理论类似于当前AI运作方式（如Bayesianism）。论文分析这些哲学误区对AI在科学和社会应用的影响，包括潜在问题，并对人工通用智能（AGI）的现实前景给出展望，同时提出三个关于A(G)I与认识论（epistemology）的命题。",
      "categories": [
        "cs.AI",
        "cs.ET",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.15671v1",
      "published_date": "2024-07-22 14:38:54 UTC",
      "updated_date": "2024-07-22 14:38:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:54:24.266058"
    },
    {
      "arxiv_id": "2407.15668v2",
      "title": "SLVideo: A Sign Language Video Moment Retrieval Framework",
      "title_zh": "SLVideo：手语视频时刻检索框架",
      "authors": [
        "Gonçalo Vinagre Martins",
        "João Magalhães",
        "Afonso Quinaz",
        "Carla Viegas",
        "Sofia Cavaco"
      ],
      "abstract": "SLVideo is a video moment retrieval system for Sign Language videos that\nincorporates facial expressions, addressing this gap in existing technology.\nThe system extracts embedding representations for the hand and face signs from\nvideo frames to capture the signs in their entirety, enabling users to search\nfor a specific sign language video segment with text queries. A collection of\neight hours of annotated Portuguese Sign Language videos is used as the\ndataset, and a CLIP model is used to generate the embeddings. The initial\nresults are promising in a zero-shot setting. In addition, SLVideo incorporates\na thesaurus that enables users to search for similar signs to those retrieved,\nusing the video segment embeddings, and also supports the edition and creation\nof video sign language annotations. Project web page:\nhttps://novasearch.github.io/SLVideo/",
      "tldr_zh": "该研究提出了 SLVideo 框架，这是一个针对手语视频的时刻检索系统，能够整合面部表情来填补现有技术的空白。系统通过从视频帧中提取手部和面部符号的嵌入表示（使用 CLIP 模型），允许用户通过文本查询搜索特定手语视频片段。研究使用了八小时标注的葡萄牙手语视频数据集，并在零样本设置下取得了有前景的初步结果。此外，SLVideo 还包含一个词库，支持搜索类似符号以及编辑和创建视频手语标注。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "4 pages, 1 figure, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2407.15668v2",
      "published_date": "2024-07-22 14:29:36 UTC",
      "updated_date": "2024-11-05 18:38:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:54:37.142752"
    },
    {
      "arxiv_id": "2407.15662v1",
      "title": "How to Shrink Confidence Sets for Many Equivalent Discrete Distributions?",
      "title_zh": "翻译失败",
      "authors": [
        "Odalric-Ambrym Maillard",
        "Mohammad Sadegh Talebi"
      ],
      "abstract": "We consider the situation when a learner faces a set of unknown discrete\ndistributions $(p_k)_{k\\in \\mathcal K}$ defined over a common alphabet\n$\\mathcal X$, and can build for each distribution $p_k$ an individual\nhigh-probability confidence set thanks to $n_k$ observations sampled from\n$p_k$. The set $(p_k)_{k\\in \\mathcal K}$ is structured: each distribution $p_k$\nis obtained from the same common, but unknown, distribution q via applying an\nunknown permutation to $\\mathcal X$. We call this\n\\emph{permutation-equivalence}. The goal is to build refined confidence sets\n\\emph{exploiting} this structural property. Like other popular notions of\nstructure (Lipschitz smoothness, Linearity, etc.) permutation-equivalence\nnaturally appears in machine learning problems, and to benefit from its\npotential gain calls for a specific approach. We present a strategy to\neffectively exploit permutation-equivalence, and provide a finite-time\nhigh-probability bound on the size of the refined confidence sets output by the\nstrategy. Since a refinement is not possible for too few observations in\ngeneral, under mild technical assumptions, our finite-time analysis establish\nwhen the number of observations $(n_k)_{k\\in \\mathcal K}$ are large enough so\nthat the output confidence sets improve over initial individual sets. We\ncarefully characterize this event and the corresponding improvement. Further,\nour result implies that the size of confidence sets shrink at asymptotic rates\nof $O(1/\\sqrt{\\sum_{k\\in \\mathcal K} n_k})$ and $O(1/\\max_{k\\in K} n_{k})$,\nrespectively for elements inside and outside the support of q, when the size of\neach individual confidence set shrinks at respective rates of $O(1/\\sqrt{n_k})$\nand $O(1/n_k)$. We illustrate the practical benefit of exploiting permutation\nequivalence on a reinforcement learning task.",
      "tldr_zh": "本研究探讨了如何利用permutation-equivalence结构来缩小多个等价离散分布的confidence sets。具体而言，当多个未知离散分布（p_k）通过未知置换从一个共同分布q衍生时，论文提出了一种策略，通过整合所有分布的观察样本（n_k），提供有限时间高概率边界来精炼confidence sets。结果表明，当样本数量足够大时，精炼后的confidence sets在支持内和外的尺寸分别以O(1/√∑n_k)和O(1/max n_k)的渐近率缩小，比原始的O(1/√n_k)和O(1/n_k)速率更高效；该方法在强化学习任务中展示了实际改进。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.15662v1",
      "published_date": "2024-07-22 14:19:19 UTC",
      "updated_date": "2024-07-22 14:19:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:54:48.326152"
    },
    {
      "arxiv_id": "2407.15656v1",
      "title": "Evaluation of Reinforcement Learning for Autonomous Penetration Testing using A3C, Q-learning and DQN",
      "title_zh": "翻译失败",
      "authors": [
        "Norman Becker",
        "Daniel Reti",
        "Evridiki V. Ntagiou",
        "Marcus Wallum",
        "Hans D. Schotten"
      ],
      "abstract": "Penetration testing is the process of searching for security weaknesses by\nsimulating an attack. It is usually performed by experienced professionals,\nwhere scanning and attack tools are applied. By automating the execution of\nsuch tools, the need for human interaction and decision-making could be\nreduced. In this work, a Network Attack Simulator (NASim) was used as an\nenvironment to train reinforcement learning agents to solve three predefined\nsecurity scenarios. These scenarios cover techniques of exploitation,\npost-exploitation and wiretapping. A large hyperparameter grid search was\nperformed to find the best hyperparameter combinations. The algorithms\nQ-learning, DQN and A3C were used, whereby A3C was able to solve all scenarios\nand achieve generalization. In addition, A3C could solve these scenarios with\nfewer actions than the baseline automated penetration testing. Although the\ntraining was performed on rather small scenarios and with small state and\naction spaces for the agents, the results show that a penetration test can\nsuccessfully be performed by the RL agent.",
      "tldr_zh": "本研究评估了强化学习(Reinforcement Learning)算法在自主渗透测试中的应用，使用Q-learning、DQN和A3C算法在Network Attack Simulator (NASim)环境中训练代理，以解决三个预定义的安全场景，包括漏洞利用、后利用和窃听。研究通过大规模超参数网格搜索优化算法参数，结果显示A3C算法能够成功解决所有场景，实现泛化，并比基线自动化渗透测试方法使用更少的动作。尽管训练场景规模较小，状态和动作空间有限，但实验证明强化学习代理能有效执行渗透测试任务。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.15656v1",
      "published_date": "2024-07-22 14:17:29 UTC",
      "updated_date": "2024-07-22 14:17:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:55:01.313842"
    },
    {
      "arxiv_id": "2407.15645v1",
      "title": "Psychometric Alignment: Capturing Human Knowledge Distributions via Language Models",
      "title_zh": "心理测量对齐：通过语言模型捕捉人类知识分布",
      "authors": [
        "Joy He-Yueya",
        "Wanjing Anya Ma",
        "Kanishk Gandhi",
        "Benjamin W. Domingue",
        "Emma Brunskill",
        "Noah D. Goodman"
      ],
      "abstract": "Language models (LMs) are increasingly used to simulate human-like responses\nin scenarios where accurately mimicking a population's behavior can guide\ndecision-making, such as in developing educational materials and designing\npublic policies. The objective of these simulations is for LMs to capture the\nvariations in human responses, rather than merely providing the expected\ncorrect answers. Prior work has shown that LMs often generate unrealistically\naccurate responses, but there are no established metrics to quantify how\nclosely the knowledge distribution of LMs aligns with that of humans. To\naddress this, we introduce \"psychometric alignment,\" a metric that measures the\nextent to which LMs reflect human knowledge distribution. Assessing this\nalignment involves collecting responses from both LMs and humans to the same\nset of test items and using Item Response Theory to analyze the differences in\nitem functioning between the groups. We demonstrate that our metric can capture\nimportant variations in populations that traditional metrics, like differences\nin accuracy, fail to capture. We apply this metric to assess existing LMs for\ntheir alignment with human knowledge distributions across three real-world\ndomains. We find significant misalignment between LMs and human populations,\nthough using persona-based prompts can improve alignment. Interestingly,\nsmaller LMs tend to achieve greater psychometric alignment than larger LMs.\nFurther, training LMs on human response data from the target distribution\nenhances their psychometric alignment on unseen test items, but the\neffectiveness of such training varies across domains.",
      "tldr_zh": "本研究探讨了语言模型（LMs）在模拟人类响应时的表现，旨在捕捉人类知识分布的变异而非仅提供正确答案，以指导决策如教育和公共政策。作者引入了“psychometric alignment”指标，通过收集 LMs 和人类对相同测试项目的响应，并应用 Item Response Theory (IRT) 分析组间差异，量化 LMs 与人类知识分布的匹配程度。结果显示，该指标能捕捉传统准确率指标忽略的变异；在三个真实领域评估中，现有 LMs 与人类分布存在显著不匹配，但使用 persona-based prompts 可改善对齐，且较小 LMs 比大型 LMs 表现更好；此外，针对人类响应数据训练 LMs 可提升 psychometric alignment，但效果因领域而异。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Code and data: https://github.com/joyheyueya/psychometric-alignment",
      "pdf_url": "http://arxiv.org/pdf/2407.15645v1",
      "published_date": "2024-07-22 14:02:59 UTC",
      "updated_date": "2024-07-22 14:02:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:55:16.403864"
    },
    {
      "arxiv_id": "2407.15621v2",
      "title": "RadioRAG: Factual large language models for enhanced diagnostics in radiology using online retrieval augmented generation",
      "title_zh": "翻译失败",
      "authors": [
        "Soroosh Tayebi Arasteh",
        "Mahshad Lotfinia",
        "Keno Bressem",
        "Robert Siepmann",
        "Lisa Adams",
        "Dyke Ferber",
        "Christiane Kuhl",
        "Jakob Nikolas Kather",
        "Sven Nebelung",
        "Daniel Truhn"
      ],
      "abstract": "Large language models (LLMs) often generate outdated or inaccurate\ninformation based on static training datasets. Retrieval augmented generation\n(RAG) mitigates this by integrating outside data sources. While previous RAG\nsystems used pre-assembled, fixed databases with limited flexibility, we have\ndeveloped Radiology RAG (RadioRAG), an end-to-end framework that retrieves data\nfrom authoritative radiologic online sources in real-time. We evaluate the\ndiagnostic accuracy of various LLMs when answering radiology-specific questions\nwith and without access to additional online information via RAG. Using 80\nquestions from the RSNA Case Collection across radiologic subspecialties and 24\nadditional expert-curated questions with reference standard answers, LLMs\n(GPT-3.5-turbo, GPT-4, Mistral-7B, Mixtral-8x7B, and Llama3 [8B and 70B]) were\nprompted with and without RadioRAG in a zero-shot inference scenario RadioRAG\nretrieved context-specific information from www.radiopaedia.org in real-time.\nAccuracy was investigated. Statistical analyses were performed using\nbootstrapping. The results were further compared with human performance.\nRadioRAG improved diagnostic accuracy across most LLMs, with relative accuracy\nincreases ranging up to 54% for different LLMs. It matched or exceeded non-RAG\nmodels and the human radiologist in question answering across radiologic\nsubspecialties, particularly in breast imaging and emergency radiology.\nHowever, the degree of improvement varied among models; GPT-3.5-turbo and\nMixtral-8x7B-instruct-v0.1 saw notable gains, while Mistral-7B-instruct-v0.2\nshowed no improvement, highlighting variability in RadioRAG's effectiveness.\nLLMs benefit when provided access to domain-specific data beyond their training\ndata. For radiology, RadioRAG establishes a robust framework that substantially\nimproves diagnostic accuracy and factuality in radiological question answering.",
      "tldr_zh": "这篇论文介绍了 RadioRAG，一个端到端框架，利用在线检索增强生成 (RAG) 技术，从权威放射学在线来源（如 radiopaedia.org）实时获取数据，以提升大型语言模型 (LLMs) 在放射学诊断中的准确性和事实性。研究评估了多种 LLMs（如 GPT-3.5-turbo、GPT-4 和 Llama3）在回答 80 个 RSNA 病例问题和 24 个专家策划问题时的表现，结果显示 RadioRAG 使大多数模型的诊断准确性相对提高了高达 54%，并在乳腺成像和急诊放射学等子领域匹配或超过了人类放射科医生的水平。然而，改善效果因模型而异，例如 Mistral-7B 没有显著提升，突显了框架的适用性差异。总的来说，RadioRAG 为放射学领域提供了稳健的工具，提高了 LLMs 的诊断可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.15621v2",
      "published_date": "2024-07-22 13:29:56 UTC",
      "updated_date": "2024-12-25 10:49:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:55:26.392814"
    },
    {
      "arxiv_id": "2407.15617v1",
      "title": "Norface: Improving Facial Expression Analysis by Identity Normalization",
      "title_zh": "Norface：通过身份归一化改进面部表情分析",
      "authors": [
        "Hanwei Liu",
        "Rudong An",
        "Zhimeng Zhang",
        "Bowen Ma",
        "Wei Zhang",
        "Yan Song",
        "Yujing Hu",
        "Wei Chen",
        "Yu Ding"
      ],
      "abstract": "Facial Expression Analysis remains a challenging task due to unexpected\ntask-irrelevant noise, such as identity, head pose, and background. To address\nthis issue, this paper proposes a novel framework, called Norface, that is\nunified for both Action Unit (AU) analysis and Facial Emotion Recognition (FER)\ntasks. Norface consists of a normalization network and a classification\nnetwork. First, the carefully designed normalization network struggles to\ndirectly remove the above task-irrelevant noise, by maintaining facial\nexpression consistency but normalizing all original images to a common identity\nwith consistent pose, and background. Then, these additional normalized images\nare fed into the classification network. Due to consistent identity and other\nfactors (e.g. head pose, background, etc.), the normalized images enable the\nclassification network to extract useful expression information more\neffectively. Additionally, the classification network incorporates a Mixture of\nExperts to refine the latent representation, including handling the input of\nfacial representations and the output of multiple (AU or emotion) labels.\nExtensive experiments validate the carefully designed framework with the\ninsight of identity normalization. The proposed method outperforms existing\nSOTA methods in multiple facial expression analysis tasks, including AU\ndetection, AU intensity estimation, and FER tasks, as well as their\ncross-dataset tasks. For the normalized datasets and code please visit\n{https://norface-fea.github.io/}.",
      "tldr_zh": "本研究针对面部表情分析中存在的任务无关噪声（如身份、头部姿势和背景）问题，提出了一种统一的Norface框架，用于Action Unit (AU)分析和Facial Emotion Recognition (FER)任务。Norface框架包括标准化网络和分类网络，其中标准化网络通过保持表情一致性，将原始图像标准化为共同身份、姿势和背景，从而去除噪声；分类网络则利用这些标准化图像并整合Mixture of Experts机制来精炼潜在表示，提升表情信息提取效率。实验结果显示，该方法在AU检测、AU强度估计和FER任务上超越现有SOTA方法，并在跨数据集任务中表现出色，为面部表情分析提供了新颖的身份归一化洞见。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ECCV2024",
      "pdf_url": "http://arxiv.org/pdf/2407.15617v1",
      "published_date": "2024-07-22 13:24:32 UTC",
      "updated_date": "2024-07-22 13:24:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:55:46.500799"
    },
    {
      "arxiv_id": "2407.15616v2",
      "title": "Sustainable broadcasting in Blockchain Networks with Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Danila Valko",
        "Daniel Kudenko"
      ],
      "abstract": "Recent estimates put the carbon footprint of Bitcoin and Ethereum at an\naverage of 64 and 26 million tonnes of CO2 per year, respectively. To address\nthis growing problem, several possible approaches have been proposed in the\nliterature: creating alternative blockchain consensus mechanisms, applying\nredundancy reduction techniques, utilizing renewable energy sources, and\nemploying energy-efficient devices, etc. In this paper, we follow the second\navenue and propose an efficient approach based on reinforcement learning that\nimproves the block broadcasting scheme in blockchain networks. The analysis and\nexperimental results confirmed that the proposed improvement of the block\npropagation scheme could cleverly handle network dynamics and achieve better\nresults than the default approach. Additionally, our technical integration of\nthe simulator and developed RL environment can be used as a complete solution\nfor further study of new schemes and protocols that use RL or other ML\ntechniques.",
      "tldr_zh": "本研究针对区块链网络（如比特币和以太坊）的高碳足迹问题（分别约每年6400万和2600万吨CO2），提出了一种基于Reinforcement Learning的块广播方案改进方法，以减少冗余并提升能源效率。该方法通过智能处理网络动态，实现比默认广播方案更好的性能，实验结果证实其有效性。分析显示，该改进方案能优化块传播过程，并提供了一个集成的模拟器和RL环境，作为进一步研究新协议或机器学习技术的完整解决方案。该框架为可持续区块链技术的发展提供了可行路径。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "7 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.15616v2",
      "published_date": "2024-07-22 13:24:08 UTC",
      "updated_date": "2025-04-02 20:17:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:55:48.340098"
    },
    {
      "arxiv_id": "2407.15612v3",
      "title": "Can GPT-4 learn to analyse moves in research article abstracts?",
      "title_zh": "翻译失败",
      "authors": [
        "Danni Yu",
        "Marina Bondi",
        "Ken Hyland"
      ],
      "abstract": "One of the most powerful and enduring ideas in written discourse analysis is\nthat genres can be described in terms of the moves which structure a writer's\npurpose. Considerable research has sought to identify these distinct\ncommunicative acts, but analyses have been beset by problems of subjectivity,\nreliability and the time-consuming need for multiple coders to confirm\nanalyses. In this paper we employ the affordances of GPT-4 to automate the\nannotation process by using natural language prompts. Focusing on abstracts\nfrom articles in four applied linguistics journals, we devise prompts which\nenable the model to identify moves effectively. The annotated outputs of these\nprompts were evaluated by two assessors with a third addressing disagreements.\nThe results show that an 8-shot prompt was more effective than one using two,\nconfirming that the inclusion of examples illustrating areas of variability can\nenhance GPT-4's ability to recognize multiple moves in a single sentence and\nreduce bias related to textual position. We suggest that GPT-4 offers\nconsiderable potential in automating this annotation process, when human actors\nwith domain specific linguistic expertise inform the prompting process.",
      "tldr_zh": "该论文探讨了是否能使用GPT-4自动化分析研究文章摘要中的moves（一种结构化写作目的的沟通行为）。研究方法涉及设计自然语言提示，对应用语言学期刊摘要进行标注，并比较2-shot和8-shot提示的效果，结果显示8-shot提示更有效，能更好地识别单句中的多个moves并减少文本位置偏差。通过人类专家指导，论文证明GPT-4在自动化此标注过程方面具有巨大潜力，从而解决传统分析的主观性和可靠性问题。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.15612v3",
      "published_date": "2024-07-22 13:14:27 UTC",
      "updated_date": "2024-11-04 13:25:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:56:11.445584"
    },
    {
      "arxiv_id": "2407.15600v1",
      "title": "A Pairwise Comparison Relation-assisted Multi-objective Evolutionary Neural Architecture Search Method with Multi-population Mechanism",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Xue",
        "Chenchen Zhu",
        "MengChu Zhou",
        "Mohamed Wahib",
        "Moncef Gabbouj"
      ],
      "abstract": "Neural architecture search (NAS) enables re-searchers to automatically\nexplore vast search spaces and find efficient neural networks. But NAS suffers\nfrom a key bottleneck, i.e., numerous architectures need to be evaluated during\nthe search process, which requires a lot of computing resources and time. In\norder to improve the efficiency of NAS, a series of methods have been proposed\nto reduce the evaluation time of neural architectures. However, they are not\nefficient enough and still only focus on the accuracy of architectures. In\naddition to the classification accuracy, more efficient and smaller network\narchitectures are required in real-world applications. To address the above\nproblems, we propose the SMEM-NAS, a pairwise com-parison relation-assisted\nmulti-objective evolutionary algorithm based on a multi-population mechanism.\nIn the SMEM-NAS, a surrogate model is constructed based on pairwise compari-son\nrelations to predict the accuracy ranking of architectures, rather than the\nabsolute accuracy. Moreover, two populations cooperate with each other in the\nsearch process, i.e., a main population guides the evolution, while a vice\npopulation expands the diversity. Our method aims to provide high-performance\nmodels that take into account multiple optimization objectives. We conduct a\nseries of experiments on the CIFAR-10, CIFAR-100 and ImageNet datasets to\nverify its effectiveness. With only a single GPU searching for 0.17 days,\ncompetitive architectures can be found by SMEM-NAS which achieves 78.91%\naccuracy with the MAdds of 570M on the ImageNet. This work makes a significant\nadvance in the important field of NAS.",
      "tldr_zh": "本研究针对神经架构搜索(NAS)中评估架构耗时长且仅关注分类准确率的问题，提出了一种基于成对比较关系(pairwise comparison relations)的多目标进化算法SMEM-NAS，并引入多群机制(multi-population mechanism)。该方法通过构建代理模型(surrogate model)预测架构的准确性排名，而非绝对值，主群(main population)引导进化，副群(vice population)增强多样性，从而优化准确率、网络效率和大小等多目标。实验在CIFAR-10、CIFAR-100和ImageNet数据集上验证，SMEM-NAS仅用单GPU搜索0.17天，即找到准确率78.91%、MAdds为570M的竞争性架构，为NAS领域提供了高效的搜索框架。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.15600v1",
      "published_date": "2024-07-22 12:46:22 UTC",
      "updated_date": "2024-07-22 12:46:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:56:13.712568"
    },
    {
      "arxiv_id": "2407.15595v2",
      "title": "Discrete Flow Matching",
      "title_zh": "翻译失败",
      "authors": [
        "Itai Gat",
        "Tal Remez",
        "Neta Shaul",
        "Felix Kreuk",
        "Ricky T. Q. Chen",
        "Gabriel Synnaeve",
        "Yossi Adi",
        "Yaron Lipman"
      ],
      "abstract": "Despite Flow Matching and diffusion models having emerged as powerful\ngenerative paradigms for continuous variables such as images and videos, their\napplication to high-dimensional discrete data, such as language, is still\nlimited. In this work, we present Discrete Flow Matching, a novel discrete flow\nparadigm designed specifically for generating discrete data. Discrete Flow\nMatching offers several key contributions:(i) it works with a general family of\nprobability paths interpolating between source and target distributions; (ii)\nit allows for a generic formula for sampling from these probability paths using\nlearned posteriors such as the probability denoiser ($x$-prediction) and\nnoise-prediction ($\\epsilon$-prediction); (iii) practically, focusing on\nspecific probability paths defined with different schedulers improves\ngenerative perplexity compared to previous discrete diffusion and flow models;\nand (iv) by scaling Discrete Flow Matching models up to 1.7B parameters, we\nreach 6.7% Pass@1 and 13.4% Pass@10 on HumanEval and 6.7% Pass@1 and 20.6%\nPass@10 on 1-shot MBPP coding benchmarks. Our approach is capable of generating\nhigh-quality discrete data in a non-autoregressive fashion, significantly\nclosing the gap between autoregressive models and discrete flow models.",
      "tldr_zh": "本研究提出了一种名为 Discrete Flow Matching 的新范式，用于生成高维离散数据，如语言，旨在解决 Flow Matching 和 diffusion models 在离散领域应用的局限性。主要贡献包括：它支持一族概率 paths 插值源和目标分布，并提供使用学习后验（如 x-prediction 和 ε-prediction）采样的通用公式；通过不同 schedulers 定义的特定概率 paths，提升了生成 perplexity，比之前的离散 diffusion 和 flow 模型更有效。实验结果显示，将模型扩展到 1.7B 参数后，在 HumanEval 上达到 6.7% Pass@1 和 13.4% Pass@10，在 1-shot MBPP 上达到 6.7% Pass@1 和 20.6% Pass@10；此外，该方法实现非自回归的高质量数据生成，显著缩小了 autoregressive 模型与离散 flow 模型的性能差距。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.15595v2",
      "published_date": "2024-07-22 12:33:27 UTC",
      "updated_date": "2024-11-05 10:02:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:56:26.144910"
    },
    {
      "arxiv_id": "2407.21045v1",
      "title": "Unlocking the Potential: Benchmarking Large Language Models in Water Engineering and Research",
      "title_zh": "翻译失败",
      "authors": [
        "Boyan Xu",
        "Liang Wen",
        "Zihao Li",
        "Yuxing Yang",
        "Guanlan Wu",
        "Xiongpeng Tang",
        "Yu Li",
        "Zihao Wu",
        "Qingxian Su",
        "Xueqing Shi",
        "Yue Yang",
        "Rui Tong",
        "How Yong Ng"
      ],
      "abstract": "Recent advancements in Large Language Models (LLMs) have sparked interest in\ntheir potential applications across various fields. This paper embarked on a\npivotal inquiry: Can existing LLMs effectively serve as \"water expert models\"\nfor water engineering and research tasks? This study was the first to evaluate\nLLMs' contributions across various water engineering and research tasks by\nestablishing a domain-specific benchmark suite, namely, WaterER. Herein, we\nprepared 983 tasks related to water engineering and research, categorized into\n\"wastewater treatment\", \"environmental restoration\", \"drinking water treatment\nand distribution\", \"sanitation\", \"anaerobic digestion\" and \"contaminants\nassessment\". We evaluated the performance of seven LLMs (i.e., GPT-4, GPT-3.5,\nGemini, GLM-4, ERNIE, QWEN and Llama3) on these tasks. We highlighted the\nstrengths of GPT-4 in handling diverse and complex tasks of water engineering\nand water research, the specialized capabilities of Gemini in academic\ncontexts, Llama3's strongest capacity to answer Chinese water engineering\nquestions and the competitive performance of Chinese-oriented models like\nGLM-4, ERNIE and QWEN in some water engineering tasks. More specifically,\ncurrent LLMs excelled particularly in generating precise research gaps for\npapers on \"contaminants and related water quality monitoring and assessment\".\nAdditionally, they were more adept at creating appropriate titles for research\npapers on \"treatment processes for wastewaters\", \"environmental restoration\",\nand \"drinking water treatment\". Overall, this study pioneered evaluating LLMs\nin water engineering and research by introducing the WaterER benchmark to\nassess the trustworthiness of their predictions. This standardized evaluation\nframework would also drive future advancements in LLM technology by using\ntargeting datasets, propelling these models towards becoming true \"water\nexpert\".",
      "tldr_zh": "这篇论文首次评估大型语言模型 (LLMs) 在水工程和研究领域的潜力，通过建立一个特定基准套件 WaterER，包含 983 个任务，涵盖废水处理、环境恢复等子领域。研究者测试了七个 LLMs（包括 GPT-4、GPT-3.5 和 Gemini），发现 GPT-4 在处理多样化复杂任务方面表现最强，Gemini 在学术上下文中表现出色，而 Llama3 和其他中文导向模型如 GLM-4 在相关任务中具有竞争力。总体结果显示，当前 LLMs 特别擅长生成研究空白和论文标题，推动了 LLMs 向可靠的“水专家”模型发展，并为未来技术进步提供了标准化评估框架。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.21045v1",
      "published_date": "2024-07-22 12:32:22 UTC",
      "updated_date": "2024-07-22 12:32:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:56:38.164474"
    },
    {
      "arxiv_id": "2407.15588v5",
      "title": "Unsupervised Robust Cross-Lingual Entity Alignment via Neighbor Triple Matching with Entity and Relation Texts",
      "title_zh": "翻译失败",
      "authors": [
        "Soojin Yoon",
        "Sungho Ko",
        "Tongyoung Kim",
        "SeongKu Kang",
        "Jinyoung Yeo",
        "Dongha Lee"
      ],
      "abstract": "Cross-lingual entity alignment (EA) enables the integration of multiple\nknowledge graphs (KGs) across different languages, providing users with\nseamless access to diverse and comprehensive knowledge. Existing methods,\nmostly supervised, face challenges in obtaining labeled entity pairs. To\naddress this, recent studies have shifted towards self-supervised and\nunsupervised frameworks. Despite their effectiveness, these approaches have\nlimitations: (1) Relation passing: mainly focusing on the entity while\nneglecting the semantic information of relations, (2) Isomorphic assumption:\nassuming isomorphism between source and target graphs, which leads to noise and\nreduced alignment accuracy, and (3) Noise vulnerability: susceptible to noise\nin the textual features, especially when encountering inconsistent translations\nor Out-of-Vocabulary (OOV) problems. In this paper, we propose ERAlign, an\nunsupervised and robust cross-lingual EA pipeline that jointly performs\nEntity-level and Relation-level Alignment by neighbor triple matching strategy\nusing semantic textual features of relations and entities. Its refinement step\niteratively enhances results by fusing entity-level and relation-level\nalignments based on neighbor triple matching. The additional verification step\nexamines the entities' neighbor triples as the linearized text. This\nAlign-then-Verify pipeline rigorously assesses alignment results, achieving\nnear-perfect alignment even in the presence of noisy textual features of\nentities. Our extensive experiments demonstrate that the robustness and general\napplicability of ERAlign improved the accuracy and effectiveness of EA tasks,\ncontributing significantly to knowledge-oriented applications.",
      "tldr_zh": "这篇论文提出 ERAlign，一种无监督且鲁棒的跨语言实体对齐（Cross-lingual Entity Alignment）方法，通过邻居三元组匹配策略联合处理实体级和关系级对齐，利用实体和关系的语义文本特征来缓解关系忽略、同构假设和噪声敏感等问题。ERAlign 的管道包括迭代精炼步骤（融合实体和关系对齐结果）和验证步骤（检查线性化邻居三元组文本），从而提升对齐准确性，即使面对噪声文本特征也能实现近乎完美的结果。实验证明，ERAlign 在知识图谱（KGs）整合任务中显著提高了准确性和有效性，为知识导向应用提供了更可靠的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "WSDM 2025",
      "pdf_url": "http://arxiv.org/pdf/2407.15588v5",
      "published_date": "2024-07-22 12:25:48 UTC",
      "updated_date": "2025-02-12 09:50:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:56:59.086853"
    },
    {
      "arxiv_id": "2408.00800v2",
      "title": "Chatbot-Based Ontology Interaction Using Large Language Models and Domain-Specific Standards",
      "title_zh": "翻译失败",
      "authors": [
        "Jonathan Reif",
        "Tom Jeleniewski",
        "Milapji Singh Gill",
        "Felix Gehlhoff",
        "Alexander Fay"
      ],
      "abstract": "The following contribution introduces a concept that employs Large Language\nModels (LLMs) and a chatbot interface to enhance SPARQL query generation for\nontologies, thereby facilitating intuitive access to formalized knowledge.\nUtilizing natural language inputs, the system converts user inquiries into\naccurate SPARQL queries that strictly query the factual content of the\nontology, effectively preventing misinformation or fabrication by the LLM. To\nenhance the quality and precision of outcomes, additional textual information\nfrom established domain-specific standards is integrated into the ontology for\nprecise descriptions of its concepts and relationships. An experimental study\nassesses the accuracy of generated SPARQL queries, revealing significant\nbenefits of using LLMs for querying ontologies and highlighting areas for\nfuture research.",
      "tldr_zh": "本研究提出了一种基于Large Language Models (LLMs)和聊天机器人接口的概念，用于增强本体查询的SPARQL生成，从而实现对正式化知识的直观访问。该系统将用户自然语言输入转换为准确的SPARQL查询，确保仅查询本体中的事实内容，以防止LLM生成错误信息或虚构内容；同时，通过整合领域特定标准的额外文本信息，精确描述本体概念和关系。实验评估显示，该方法显著提高了SPARQL查询的准确性，并指出了未来研究的潜在方向。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "\\c{opyright} 2024 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works",
      "pdf_url": "http://arxiv.org/pdf/2408.00800v2",
      "published_date": "2024-07-22 11:58:36 UTC",
      "updated_date": "2024-10-17 09:13:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:57:00.538746"
    },
    {
      "arxiv_id": "2407.15901v1",
      "title": "Enhancing Cognitive Workload Classification Using Integrated LSTM Layers and CNNs for fNIRS Data Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Mehshan Ahmed Khan",
        "Houshyar Asadi",
        "Mohammad Reza Chalak Qazani",
        "Adetokunbo Arogbonlo",
        "Siamak Pedrammehr",
        "Adnan Anwar",
        "Asim Bhatti",
        "Saeid Nahavandi",
        "Chee Peng Lim"
      ],
      "abstract": "Functional near-infrared spectroscopy (fNIRS) is employed as a non-invasive\nmethod to monitor functional brain activation by capturing changes in the\nconcentrations of oxygenated haemoglobin (HbO) and deoxygenated haemo-globin\n(HbR). Various machine learning classification techniques have been utilized to\ndistinguish cognitive states. However, conventional machine learning methods,\nalthough simpler to implement, undergo a complex pre-processing phase before\nnetwork training and demonstrate reduced accuracy due to inadequate data\npreprocessing. Additionally, previous research in cog-nitive load assessment\nusing fNIRS has predominantly focused on differ-sizeentiating between two\nlevels of mental workload. These studies mainly aim to classify low and high\nlevels of cognitive load or distinguish between easy and difficult tasks. To\naddress these limitations associated with conven-tional methods, this paper\nconducts a comprehensive exploration of the im-pact of Long Short-Term Memory\n(LSTM) layers on the effectiveness of Convolutional Neural Networks (CNNs)\nwithin deep learning models. This is to address the issues related to spatial\nfeatures overfitting and lack of tem-poral dependencies in CNN in the previous\nstudies. By integrating LSTM layers, the model can capture temporal\ndependencies in the fNIRS data, al-lowing for a more comprehensive\nunderstanding of cognitive states. The primary objective is to assess how\nincorporating LSTM layers enhances the performance of CNNs. The experimental\nresults presented in this paper demonstrate that the integration of LSTM layers\nwith Convolutional layers results in an increase in the accuracy of deep\nlearning models from 97.40% to 97.92%.",
      "tldr_zh": "本文研究了如何通过整合 LSTM 层和 CNNs 来提升 fNIRS 数据分析中的认知负荷分类准确率，针对传统机器学习方法的复杂预处理和低准确率问题，以及 CNNs 在处理空间特征过拟合和时间依赖性不足的局限性。研究方法包括在深度学习模型中添加 LSTM 层，以更好地捕获 fNIRS 数据的时间序列特征，从而更全面地理解认知状态。实验结果表明，这种整合显著提高了模型性能，将准确率从 97.40% 提升至 97.92%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "conference",
      "pdf_url": "http://arxiv.org/pdf/2407.15901v1",
      "published_date": "2024-07-22 11:28:34 UTC",
      "updated_date": "2024-07-22 11:28:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:57:12.922888"
    },
    {
      "arxiv_id": "2407.15549v2",
      "title": "Latent Adversarial Training Improves Robustness to Persistent Harmful Behaviors in LLMs",
      "title_zh": "潜在对抗训练提升了LLMs中对持久有害行为的鲁棒性",
      "authors": [
        "Abhay Sheshadri",
        "Aidan Ewart",
        "Phillip Guo",
        "Aengus Lynch",
        "Cindy Wu",
        "Vivek Hebbar",
        "Henry Sleight",
        "Asa Cooper Stickland",
        "Ethan Perez",
        "Dylan Hadfield-Menell",
        "Stephen Casper"
      ],
      "abstract": "Large language models (LLMs) can often be made to behave in undesirable ways\nthat they are explicitly fine-tuned not to. For example, the LLM red-teaming\nliterature has produced a wide variety of 'jailbreaking' techniques to elicit\nharmful text from models that were fine-tuned to be harmless. Recent work on\nred-teaming, model editing, and interpretability suggests that this challenge\nstems from how (adversarial) fine-tuning largely serves to suppress rather than\nremove undesirable capabilities from LLMs. Prior work has introduced latent\nadversarial training (LAT) as a way to improve robustness to broad classes of\nfailures. These prior works have considered untargeted latent space attacks\nwhere the adversary perturbs latent activations to maximize loss on examples of\ndesirable behavior. Untargeted LAT can provide a generic type of robustness but\ndoes not leverage information about specific failure modes. Here, we experiment\nwith targeted LAT where the adversary seeks to minimize loss on a specific\ncompeting task. We find that it can augment a wide variety of state-of-the-art\nmethods. First, we use targeted LAT to improve robustness to jailbreaks,\noutperforming a strong R2D2 baseline with orders of magnitude less compute.\nSecond, we use it to more effectively remove backdoors with no knowledge of the\ntrigger. Finally, we use it to more effectively unlearn knowledge for specific\nundesirable tasks in a way that is also more robust to re-learning. Overall,\nour results suggest that targeted LAT can be an effective tool for defending\nagainst harmful behaviors from LLMs.",
      "tldr_zh": "这篇论文探讨了如何通过Latent Adversarial Training (LAT)提升大型语言模型(LLMs)对持久有害行为的鲁棒性，针对问题如jailbreaking导致的模型输出有害文本。作者引入了针对性LAT方法，其中对手在潜在空间中扰动激活以最小化特定竞争任务的损失，从而比传统未针对性方法更有效地利用失败模式信息。实验结果显示，针对性LAT在抵抗jailbreaking、移除后门和取消有害任务学习方面显著优于R2D2基线，且计算量减少几个数量级。总体而言，该方法为防御LLMs中的有害行为提供了高效工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.15549v2",
      "published_date": "2024-07-22 11:19:14 UTC",
      "updated_date": "2024-08-21 23:22:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:57:25.393796"
    },
    {
      "arxiv_id": "2408.02378v1",
      "title": "Scaling CS1 Support with Compiler-Integrated Conversational AI",
      "title_zh": "翻译失败",
      "authors": [
        "Jake Renzella",
        "Alexandra Vassar",
        "Lorenzo Lee Solano",
        "Andrew Taylor"
      ],
      "abstract": "This paper introduces DCC Sidekick, a web-based conversational AI tool that\nenhances an existing LLM-powered C/C++ compiler by generating educational\nprogramming error explanations. The tool seamlessly combines code display,\ncompile- and run-time error messages, and stack frame read-outs alongside an AI\ninterface, leveraging compiler error context for improved explanations. We\nanalyse usage data from a large Australian CS1 course, where 959 students\nengaged in 11,222 DCC Sidekick sessions, resulting in 17,982 error explanations\nover seven weeks. Notably, over 50% of interactions occurred outside business\nhours, underscoring the tool's value as an always-available resource. Our\nfindings reveal strong adoption of AI-assisted debugging tools, demonstrating\ntheir scalability in supporting extensive CS1 courses. We provide\nimplementation insights and recommendations for educators seeking to\nincorporate AI tools with appropriate pedagogical safeguards.",
      "tldr_zh": "本研究引入了 DCC Sidekick，一种基于网络的对话 AI 工具，用于增强 LLM 驱动的 C/C++ 编译器，通过生成教育性的编程错误解释，并整合代码显示、编译和运行时错误消息以及堆栈帧读出，以利用编译器错误上下文改善解释。研究分析了在澳大利亚大型 CS1 课程中的使用数据，涉及 959 名学生、11,222 次会话和 17,982 个错误解释，七周内超过 50% 的互动发生在工作时间外，突显了工具作为随时可用资源的价值。结果显示，AI 辅助调试工具获得了广泛采用，提升了 CS1 课程支持的可扩展性。作者提供了实施见解和建议，帮助教育者以适当的教学保障整合此类工具。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CY",
      "comment": "Papers, funding sources, and Github Repositories at:\n  https://dcc.cse.unsw.edu.au/",
      "pdf_url": "http://arxiv.org/pdf/2408.02378v1",
      "published_date": "2024-07-22 10:53:55 UTC",
      "updated_date": "2024-07-22 10:53:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:57:37.154193"
    },
    {
      "arxiv_id": "2407.15532v2",
      "title": "Large-scale Time-Varying Portfolio Optimisation using Graph Attention Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Kamesh Korangi",
        "Christophe Mues",
        "Cristián Bravo"
      ],
      "abstract": "Apart from assessing individual asset performance, investors in financial\nmarkets also need to consider how a set of firms performs collectively as a\nportfolio. Whereas traditional Markowitz-based mean-variance portfolios are\nwidespread, network-based optimisation techniques offer a more flexible tool to\ncapture complex interdependencies between asset values. However, most of the\nexisting studies do not contain firms at risk of default and remove any firms\nthat drop off indices over a certain time. This is the first study to also\nincorporate such firms in portfolio optimisation on a large scale. We propose\nand empirically test a novel method that leverages Graph Attention networks\n(GATs), a subclass of Graph Neural Networks (GNNs). GNNs, as deep\nlearning-based models, can exploit network data to uncover nonlinear\nrelationships. Their ability to handle high-dimensional data and accommodate\ncustomised layers for specific purposes makes them appealing for large-scale\nproblems such as mid- and small-cap portfolio optimisation. This study utilises\n30 years of data on mid-cap firms, creating graphs of firms using distance\ncorrelation and the Triangulated Maximally Filtered Graph approach. These\ngraphs are the inputs to a GAT model incorporating weight and allocation\nconstraints and a loss function derived from the Sharpe ratio, thus focusing on\nmaximising portfolio risk-adjusted returns. This new model is benchmarked\nagainst a network characteristic-based portfolio, a mean variance-based\nportfolio, and an equal-weighted portfolio. The results show that the portfolio\nproduced by the GAT-based model outperforms all benchmarks and is consistently\nsuperior to other strategies over a long period, while also being informative\nof market dynamics.",
      "tldr_zh": "本研究针对投资组合优化问题，提出一种新方法，使用Graph Attention Networks (GATs)——Graph Neural Networks (GNNs)的子类——来处理大规模时间变化的资产组合，包括传统模型忽略的有违约风险公司。方法通过距离相关性和Triangulated Maximally Filtered Graph构建公司网络图，并将GATs模型结合权重分配约束和基于Sharpe ratio的损失函数，以最大化风险调整回报。实验结果显示，该模型生成的投资组合在30年数据中长期优于Markowitz-based mean-variance portfolios、网络特征组合和等权重组合，并在揭示市场动态方面表现出色。",
      "categories": [
        "q-fin.PM",
        "cs.AI",
        "cs.SI",
        "q-fin.RM",
        "stat.ML"
      ],
      "primary_category": "q-fin.PM",
      "comment": "39 pages, 10 figures, v2",
      "pdf_url": "http://arxiv.org/pdf/2407.15532v2",
      "published_date": "2024-07-22 10:50:47 UTC",
      "updated_date": "2025-02-03 22:04:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:57:48.490089"
    },
    {
      "arxiv_id": "2407.15527v2",
      "title": "Interpretable Concept-Based Memory Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "David Debot",
        "Pietro Barbiero",
        "Francesco Giannini",
        "Gabriele Ciravegna",
        "Michelangelo Diligenti",
        "Giuseppe Marra"
      ],
      "abstract": "The lack of transparency in the decision-making processes of deep learning\nsystems presents a significant challenge in modern artificial intelligence\n(AI), as it impairs users' ability to rely on and verify these systems. To\naddress this challenge, Concept Bottleneck Models (CBMs) have made significant\nprogress by incorporating human-interpretable concepts into deep learning\narchitectures. This approach allows predictions to be traced back to specific\nconcept patterns that users can understand and potentially intervene on.\nHowever, existing CBMs' task predictors are not fully interpretable, preventing\na thorough analysis and any form of formal verification of their\ndecision-making process prior to deployment, thereby raising significant\nreliability concerns. To bridge this gap, we introduce Concept-based Memory\nReasoner (CMR), a novel CBM designed to provide a human-understandable and\nprovably-verifiable task prediction process. Our approach is to model each task\nprediction as a neural selection mechanism over a memory of learnable logic\nrules, followed by a symbolic evaluation of the selected rule. The presence of\nan explicit memory and the symbolic evaluation allow domain experts to inspect\nand formally verify the validity of certain global properties of interest for\nthe task prediction process. Experimental results demonstrate that CMR achieves\nbetter accuracy-interpretability trade-offs to state-of-the-art CBMs, discovers\nlogic rules consistent with ground truths, allows for rule interventions, and\nallows pre-deployment verification.",
      "tldr_zh": "这项研究针对深度学习系统中决策过程缺乏透明度的挑战，提出了一种新型Concept Bottleneck Models (CBMs)变体——Concept-based Memory Reasoner (CMR)。CMR通过神经选择机制从记忆中的可学习逻辑规则中选取规则，并进行符号评估，实现任务预测的可解释性和可验证性，从而允许领域专家检查、干预规则并在部署前正式验证全局属性。实验结果表明，CMR在准确性与可解释性权衡上优于现有CBMs，能够发现与真实情况一致的逻辑规则。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.15527v2",
      "published_date": "2024-07-22 10:32:48 UTC",
      "updated_date": "2024-11-15 12:05:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:58:02.192031"
    },
    {
      "arxiv_id": "2407.15526v2",
      "title": "Synthetic Image Learning: Preserving Performance and Preventing Membership Inference Attacks",
      "title_zh": "合成图像",
      "authors": [
        "Eugenio Lomurno",
        "Matteo Matteucci"
      ],
      "abstract": "Generative artificial intelligence has transformed the generation of\nsynthetic data, providing innovative solutions to challenges like data scarcity\nand privacy, which are particularly critical in fields such as medicine.\nHowever, the effective use of this synthetic data to train high-performance\nmodels remains a significant challenge. This paper addresses this issue by\nintroducing Knowledge Recycling (KR), a pipeline designed to optimise the\ngeneration and use of synthetic data for training downstream classifiers. At\nthe heart of this pipeline is Generative Knowledge Distillation (GKD), the\nproposed technique that significantly improves the quality and usefulness of\nthe information provided to classifiers through a synthetic dataset\nregeneration and soft labelling mechanism. The KR pipeline has been tested on a\nvariety of datasets, with a focus on six highly heterogeneous medical image\ndatasets, ranging from retinal images to organ scans. The results show a\nsignificant reduction in the performance gap between models trained on real and\nsynthetic data, with models based on synthetic data outperforming those trained\non real data in some cases. Furthermore, the resulting models show almost\ncomplete immunity to Membership Inference Attacks, manifesting privacy\nproperties missing in models trained with conventional techniques.",
      "tldr_zh": "这篇论文提出了一种名为 Knowledge Recycling (KR) 的管道，用于优化合成图像数据的生成和应用，旨在解决数据稀缺和隐私挑战，尤其在医学领域。KR 的核心是 Generative Knowledge Distillation (GKD) 技术，通过合成数据集再生和软标签机制，提高了下游分类器的性能，使其在多种数据集（如六种异构医学图像数据集）上与真实数据训练的模型差距显著缩小，有时甚至优于后者。实验结果显示，该方法不仅提升了模型性能，还使模型几乎完全免疫 Membership Inference Attacks，从而增强了隐私保护。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.15526v2",
      "published_date": "2024-07-22 10:31:07 UTC",
      "updated_date": "2024-07-30 13:03:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:58:15.798843"
    },
    {
      "arxiv_id": "2408.03339v1",
      "title": "The Ontoverse: Democratising Access to Knowledge Graph-based Data Through a Cartographic Interface",
      "title_zh": "The Ontoverse：通过地图学界面实现基于知识图谱数据的民主化",
      "authors": [
        "Johannes Zimmermann",
        "Dariusz Wiktorek",
        "Thomas Meusburger",
        "Miquel Monge-Dalmau",
        "Antonio Fabregat",
        "Alexander Jarasch",
        "Günter Schmidt",
        "Jorge S. Reis-Filho",
        "T. Ian Simpson"
      ],
      "abstract": "As the number of scientific publications and preprints is growing\nexponentially, several attempts have been made to navigate this complex and\nincreasingly detailed landscape. These have almost exclusively taken\nunsupervised approaches that fail to incorporate domain knowledge and lack the\nstructural organisation required for intuitive interactive human exploration\nand discovery. Especially in highly interdisciplinary fields, a deep\nunderstanding of the connectedness of research works across topics is essential\nfor generating insights. We have developed a unique approach to data navigation\nthat leans on geographical visualisation and uses hierarchically structured\ndomain knowledge to enable end-users to explore knowledge spaces grounded in\ntheir desired domains of interest. This can take advantage of existing\nontologies, proprietary intelligence schemata, or be directly derived from the\nunderlying data through hierarchical topic modelling. Our approach uses natural\nlanguage processing techniques to extract named entities from the underlying\ndata and normalise them against relevant domain references and navigational\nstructures. The knowledge is integrated by first calculating similarities\nbetween entities based on their shared extracted feature space and then by\nalignment to the navigational structures. The result is a knowledge graph that\nallows for full text and semantic graph query and structured topic driven\nnavigation. This allows end-users to identify entities relevant to their needs\nand access extensive graph analytics. The user interface facilitates graphical\ninteraction with the underlying knowledge graph and mimics a cartographic map\nto maximise ease of use and widen adoption. We demonstrate an exemplar project\nusing our generalisable and scalable infrastructure for an academic biomedical\nliterature corpus that is grounded against hundreds of different named domain\nentities.",
      "tldr_zh": "本文提出 Ontoverse，一种创新方法，通过地图式(cartographic)界面和分层结构化领域知识，实现知识图谱(knowledge graph)数据的民主化访问，以解决科学出版物爆炸式增长带来的导航难题。方法利用自然语言处理(natural language processing)提取命名实体，并通过计算实体相似性和与导航结构的对齐，形成支持全文和语义查询的知识图谱。实验在生物医学文献语料库上展示了该系统的可扩展性和易用性，帮助用户在跨学科领域轻松探索研究关联和洞见。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.ET",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.03339v1",
      "published_date": "2024-07-22 10:29:25 UTC",
      "updated_date": "2024-07-22 10:29:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:58:26.188899"
    },
    {
      "arxiv_id": "2407.15899v3",
      "title": "Spatial-Temporal Cross-View Contrastive Pre-training for Check-in Sequence Representation Learning",
      "title_zh": "时空跨视图对比预训练用于签到序列",
      "authors": [
        "Letian Gong",
        "Huaiyu Wan",
        "Shengnan Guo",
        "Xiucheng Li",
        "Yan Lin",
        "Erwen Zheng",
        "Tianyi Wang",
        "Zeyu Zhou",
        "Youfang Lin"
      ],
      "abstract": "The rapid growth of location-based services (LBS) has yielded massive amounts\nof data on human mobility. Effectively extracting meaningful representations\nfor user-generated check-in sequences is pivotal for facilitating various\ndownstream services. However, the user-generated check-in data are\nsimultaneously influenced by the surrounding objective circumstances and the\nuser's subjective intention. Specifically, the temporal uncertainty and spatial\ndiversity exhibited in check-in data make it difficult to capture the\nmacroscopic spatial-temporal patterns of users and to understand the semantics\nof user mobility activities. Furthermore, the distinct characteristics of the\ntemporal and spatial information in check-in sequences call for an effective\nfusion method to incorporate these two types of information. In this paper, we\npropose a novel Spatial-Temporal Cross-view Contrastive Representation (STCCR)\nframework for check-in sequence representation learning. Specifically, STCCR\naddresses the above challenges by employing self-supervision from \"spatial\ntopic\" and \"temporal intention\" views, facilitating effective fusion of spatial\nand temporal information at the semantic level. Besides, STCCR leverages\ncontrastive clustering to uncover users' shared spatial topics from diverse\nmobility activities, while employing angular momentum contrast to mitigate the\nimpact of temporal uncertainty and noise. We extensively evaluate STCCR on\nthree real-world datasets and demonstrate its superior performance across three\ndownstream tasks.",
      "tldr_zh": "本文提出STCCR框架，用于基于位置服务(LBS)的签到序列表示学习，旨在解决时间不确定性和空间多样性带来的挑战，通过“spatial topic”和“temporal intention”视图的自监督方法实现空间和时间信息的语义级融合。STCCR采用contrastive clustering来挖掘用户共享的spatial topics，并利用angular momentum contrast减少时间不确定性和噪声，从而有效捕捉宏观空间-时间模式。实验在三个真实数据集上验证了STCCR的优越性能，在签到序列相关下游任务中显著超越基线模型。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper has been accepted as a regular paper at IEEE TKDE",
      "pdf_url": "http://arxiv.org/pdf/2407.15899v3",
      "published_date": "2024-07-22 10:20:34 UTC",
      "updated_date": "2024-07-25 07:18:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:58:37.545956"
    },
    {
      "arxiv_id": "2407.15523v1",
      "title": "TOM: A Development Platform For Wearable Intelligent Assistants",
      "title_zh": "翻译失败",
      "authors": [
        "Nuwan Janaka",
        "Shengdong Zhao",
        "David Hsu",
        "Sherisse Tan Jing Wen",
        "Koh Chun Keat"
      ],
      "abstract": "Advanced digital assistants can significantly enhance task performance,\nreduce user burden, and provide personalized guidance to improve users'\nabilities. However, the development of such intelligent digital assistants\npresents a formidable challenge. To address this, we introduce TOM, a\nconceptual architecture and software platform (https://github.com/TOM-Platform)\ndesigned to support the development of intelligent wearable assistants that are\ncontextually aware of both the user and the environment. This system was\ndeveloped collaboratively with AR/MR researchers, HCI researchers, AI/Robotic\nresearchers, and software developers, and it continues to evolve to meet the\ndiverse requirements of these stakeholders. TOM facilitates the creation of\nintelligent assistive AR applications for daily activities and supports the\nrecording and analysis of user interactions, integration of new devices, and\nthe provision of assistance for various activities. Additionally, we showcase\nseveral proof-of-concept assistive services and discuss the challenges involved\nin developing such services.",
      "tldr_zh": "该论文介绍了 TOM 平台，这是一个概念架构和软件系统（https://github.com/TOM-Platform），旨在支持开发智能可穿戴助手，帮助提升任务性能、减轻用户负担并提供个性化指导。TOM 通过与 AR/MR、HCI 和 AI/Robotic 研究者及软件开发者的合作，实现对用户和环境的上下文感知，支持创建智能辅助 AR 应用、记录分析用户交互、集成新设备以及提供日常活动协助。论文展示了几个概念验证服务，并讨论了开发此类服务的挑战，如系统复杂性和多领域协作需求。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "14 pages, 6 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2407.15523v1",
      "published_date": "2024-07-22 10:20:02 UTC",
      "updated_date": "2024-07-22 10:20:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:58:50.147853"
    },
    {
      "arxiv_id": "2407.15520v2",
      "title": "Future-Proofing Mobile Networks: A Digital Twin Approach to Multi-Signal Management",
      "title_zh": "翻译失败",
      "authors": [
        "Roberto Morabito",
        "Bivek Pandey",
        "Paulius Daubaris",
        "Yasith R Wanigarathna",
        "Sasu Tarkoma"
      ],
      "abstract": "Digital Twins (DTs) are set to become a key enabling technology in future\nwireless networks, with their use in network management increasing\nsignificantly. We developed a DT framework that leverages the heterogeneity of\nnetwork access technologies as a resource for enhanced network performance and\nmanagement, enabling smart data handling in the physical network. Tested in a\nCampus Area Network environment, our framework integrates diverse data sources\nto provide real-time, holistic insights into network performance and\nenvironmental sensing. We also envision that traditional analytics will evolve\nto rely on emerging AI models, such as Generative AI (GenAI), while leveraging\ncurrent analytics capabilities. This capacity can simplify analytics processes\nthrough advanced ML models, enabling descriptive, diagnostic, predictive, and\nprescriptive analytics in a unified fashion. Finally, we present specific\nresearch opportunities concerning interoperability aspects and envision\naligning advancements in DT technology with evolved AI integration.",
      "tldr_zh": "本研究提出了一种基于 Digital Twins (DTs) 的框架，用于未来无线网络的多信号管理，通过利用网络访问技术的异质性来提升网络性能和智能数据处理。框架在 Campus Area Network 环境中整合多样数据来源，提供实时洞察，并结合 Generative AI (GenAI) 等新兴 AI 模型，统一实现描述性、诊断性、预测性和处方性分析，从而简化分析流程。实验结果显示，该框架显著改善了网络管理和环境感知，为未来网络发展奠定基础。论文还指出了互操作性及 DT 与 AI 整合方面的研究机会。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "A shortened version of this paper is currently under review for\n  publication in an IEEE magazine. If accepted, the copyright will be\n  transferred to IEEE",
      "pdf_url": "http://arxiv.org/pdf/2407.15520v2",
      "published_date": "2024-07-22 10:13:46 UTC",
      "updated_date": "2024-08-06 07:25:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:59:01.889207"
    },
    {
      "arxiv_id": "2407.15512v2",
      "title": "Increasing the Robustness of Model Predictions to Missing Sensors in Earth Observation",
      "title_zh": "翻译失败",
      "authors": [
        "Francisco Mena",
        "Diego Arenas",
        "Andreas Dengel"
      ],
      "abstract": "Multi-sensor ML models for EO aim to enhance prediction accuracy by\nintegrating data from various sources. However, the presence of missing data\nposes a significant challenge, particularly in non-persistent sensors that can\nbe affected by external factors. Existing literature has explored strategies\nlike temporal dropout and sensor-invariant models to address the generalization\nto missing data issues. Inspired by these works, we study two novel methods\ntailored for multi-sensor scenarios, namely Input Sensor Dropout (ISensD) and\nEnsemble Sensor Invariant (ESensI). Through experimentation on three\nmulti-sensor temporal EO datasets, we demonstrate that these methods\neffectively increase the robustness of model predictions to missing sensors.\nParticularly, we focus on how the predictive performance of models drops when\nsensors are missing at different levels. We observe that ensemble multi-sensor\nmodels are the most robust to the lack of sensors. In addition, the sensor\ndropout component in ISensD shows promising robustness results.",
      "tldr_zh": "本研究针对多传感器地球观测（EO）机器学习模型在面对传感器缺失时预测准确性下降的问题，提出两种新方法：Input Sensor Dropout (ISensD) 和 Ensemble Sensor Invariant (ESensI)，以提升模型的鲁棒性。ISensD 通过模拟传感器缺失来训练模型，而 ESensI 则采用集成策略构建传感器不变模型。在三个多传感器时间序列 EO 数据集上的实验显示，这些方法显著提高了模型对不同级别传感器缺失的耐受性，特别是集成多传感器模型表现出最佳鲁棒性，且 ISensD 的传感器 dropout 组件在保持预测性能方面尤为有效。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at the MACLEAN workshop in the ECML/PKDD 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.15512v2",
      "published_date": "2024-07-22 09:58:29 UTC",
      "updated_date": "2024-09-04 11:01:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:59:12.623761"
    },
    {
      "arxiv_id": "2407.15510v1",
      "title": "Algebraic anti-unification",
      "title_zh": "翻译失败",
      "authors": [
        "Christian Antić"
      ],
      "abstract": "Abstraction is key to human and artificial intelligence as it allows one to\nsee common structure in otherwise distinct objects or situations and as such it\nis a key element for generality in AI. Anti-unification (or generalization) is\n\\textit{the} part of theoretical computer science and AI studying abstraction.\nIt has been successfully applied to various AI-related problems, most\nimportantly inductive logic programming. Up to this date, anti-unification is\nstudied only from a syntactic perspective in the literature. The purpose of\nthis paper is to initiate an algebraic (i.e. semantic) theory of\nanti-unification within general algebras. This is motivated by recent\napplications to similarity and analogical proportions.",
      "tldr_zh": "这篇论文探讨了anti-unification（反统一）的概念及其在人工智能中的核心作用，作为抽象的关键，用于识别不同对象或情境的共同结构，从而提升AI的泛化能力。现有研究主要从syntactic（句法）角度进行anti-unification，而本文首次启动了algebraic（代数）理论，即从semantic（语义）视角在general algebras（一般代数）中发展这一理论。论文的动机源于anti-unification在similarity（相似性）和analogical proportions（类比比例）方面的最新应用，这有助于解决AI相关问题，如归纳逻辑编程。总的来说，该工作为anti-unification的研究提供了新的语义框架。",
      "categories": [
        "cs.AI",
        "cs.DM",
        "cs.LO",
        "cs.SC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.15510v1",
      "published_date": "2024-07-22 09:49:46 UTC",
      "updated_date": "2024-07-22 09:49:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:59:27.239917"
    },
    {
      "arxiv_id": "2407.15508v3",
      "title": "Compensate Quantization Errors+: Quantized Models Are Inquisitive Learners",
      "title_zh": "翻译失败",
      "authors": [
        "Yifei Gao",
        "Jie Ou",
        "Lei Wang",
        "Jun Cheng",
        "Mengchu Zhou"
      ],
      "abstract": "The quantization of large language models (LLMs) has been a prominent\nresearch area aimed at enabling their lightweight deployment in practice.\nExisting research about LLM's quantization has mainly explored the interplay\nbetween weights and activations, or employing auxiliary components while\nneglecting the necessity of adjusting weights during quantization.\nConsequently, original weight distributions frequently fail to yield desired\nresults after round-to-nearest (RTN) quantization. Even though incorporating\ntechniques such as mixed precision and low-rank error approximation in LLM's\nquantization can yield improved results, they inevitably introduce additional\ncomputational overhead. On the other hand, traditional techniques for weight\nquantization, such as Generative Post-Training Quantization, rely on manually\ntweaking weight distributions to minimize local errors, but they fall short of\nachieving globally optimal outcomes. Although the recently proposed Learnable\nSingular-value Increment improves global weight quantization by modifying\nweight distributions, it disrupts the original distribution considerably. This\nintroduces pronounced bias toward the training data and can degrade downstream\ntask performance. In this paper, we introduce Singular-value Diagonal\nExpansion, a more nuanced approach to refining weight distributions to achieve\nbetter quantization alignment. Furthermore, we introduce Cross-layer Learning\nthat improves overall quantization outcomes by distributing errors more evenly\nacross layers. Our plug-and-play weight-quantization methods demonstrate\nsubstantial performance improvements over state-of-the-art approaches,\nincluding OmniQuant, DuQuant, and PrefixQuant.",
      "tldr_zh": "本研究针对大型语言模型(LLMs)的量化问题，指出现有方法忽略了量化过程中权重调整的必要性，导致原始权重分布在量化后（如RTN）性能不佳，并引入额外计算开销。作者提出了Singular-value Diagonal Expansion方法，通过细致精炼权重分布实现更好的量化对齐，以及Cross-layer Learning方法，通过在层间均匀分布错误来提升整体量化效果。这些即插即用方法避免了破坏原始分布的缺点，并在实验中比最先进方法如OmniQuant、DuQuant和PrefixQuant取得了显著性能提升，证明量化模型可以成为更高效的学习者。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "Effecient Quantization Methods for LLMs",
      "pdf_url": "http://arxiv.org/pdf/2407.15508v3",
      "published_date": "2024-07-22 09:45:16 UTC",
      "updated_date": "2025-05-15 05:34:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:59:39.292744"
    },
    {
      "arxiv_id": "2408.03948v1",
      "title": "A Survey of AI Reliance",
      "title_zh": "翻译失败",
      "authors": [
        "Sven Eckhardt",
        "Niklas Kühl",
        "Mateusz Dolata",
        "Gerhard Schwabe"
      ],
      "abstract": "Artificial intelligence (AI) systems have become an indispensable component\nof modern technology. However, research on human behavioral responses is\nlagging behind, i.e., the research into human reliance on AI advice (AI\nreliance). Current shortcomings in the literature include the unclear\ninfluences on AI reliance, lack of external validity, conflicting approaches to\nmeasuring reliance, and disregard for a change in reliance over time. Promising\navenues for future research include reliance on generative AI output and\nreliance in multi-user situations. In conclusion, we present a morphological\nbox that serves as a guide for research on AI reliance.",
      "tldr_zh": "这篇论文对人类对AI建议的依赖（AI reliance）进行了全面调查，指出当前研究存在不足，如影响因素不明、缺乏外部有效性、测量方法冲突以及忽略依赖随时间的变化。论文强调了未来研究方向，包括对生成式AI输出和多用户场景的依赖分析，并提供了一个morphological box作为研究指南。该调查为理解和改进AI reliance提供了关键框架。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.03948v1",
      "published_date": "2024-07-22 09:34:58 UTC",
      "updated_date": "2024-07-22 09:34:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T08:59:49.501771"
    },
    {
      "arxiv_id": "2407.15487v1",
      "title": "In-Context Learning Improves Compositional Understanding of Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Matteo Nulli",
        "Anesa Ibrahimi",
        "Avik Pal",
        "Hoshe Lee",
        "Ivona Najdenkoska"
      ],
      "abstract": "Vision-Language Models (VLMs) have shown remarkable capabilities in a large\nnumber of downstream tasks. Nonetheless, compositional image understanding\nremains a rather difficult task due to the object bias present in training\ndata. In this work, we investigate the reasons for such a lack of capability by\nperforming an extensive bench-marking of compositional understanding in VLMs.\nWe compare contrastive models with generative ones and analyze their\ndifferences in architecture, pre-training data, and training tasks and losses.\nFurthermore, we leverage In-Context Learning (ICL) as a way to improve the\nability of VLMs to perform more complex reasoning and understanding given an\nimage. Our extensive experiments demonstrate that our proposed approach\noutperforms baseline models across multiple compositional understanding\ndatasets.",
      "tldr_zh": "本研究探讨了Vision-Language Models (VLMs)在compositional image understanding方面的不足，主要由于训练数据中的object bias导致理解能力受限。通过基准测试比较contrastive models和generative models在架构、预训练数据和训练任务方面的差异，并引入In-Context Learning (ICL)来提升VLMs的复杂推理和图像理解能力。实验结果显示，该方法在多个compositional understanding数据集上超过了基线模型的表现。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.15487v1",
      "published_date": "2024-07-22 09:03:29 UTC",
      "updated_date": "2024-07-22 09:03:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T09:00:01.285386"
    },
    {
      "arxiv_id": "2407.15475v2",
      "title": "Autonomous Robotic Swarms: A Corroborative Approach for Verification and Validation",
      "title_zh": "翻译失败",
      "authors": [
        "Dhaminda B. Abeywickrama",
        "Suet Lee",
        "Chris Bennett",
        "Razanne Abu-Aisheh",
        "Tom Didiot-Cook",
        "Simon Jones",
        "Sabine Hauert",
        "Kerstin Eder"
      ],
      "abstract": "The emergent behaviour of autonomous robotic swarms poses a significant\nchallenge to their safety assurance. Assurance tasks encompass adherence to\nstandards, certification processes, and the execution of verification and\nvalidation (V&V) methods, such as model checking. In this study, we propose a\ncorroborative approach for formally verifying and validating autonomous robotic\nswarms, which are defined at the macroscopic formal modelling, low-fidelity\nsimulation, high-fidelity simulation, and real-robot levels. Our formal\nmacroscopic models, used for verification, are characterised by data derived\nfrom actual simulations to ensure both accuracy and traceability across\ndifferent swarm system models. Furthermore, our work combines formal\nverification with simulations and experimental validation using real robots. In\nthis way, our corroborative approach for V&V seeks to enhance confidence in the\nevidence, in contrast to employing these methods separately. We explore our\napproach through a case study focused on a swarm of robots operating within a\npublic cloakroom.",
      "tldr_zh": "本研究针对自主机器人群体的紧急行为对安全保障的挑战，提出了一种协作方法（corroborative approach），用于正式验证和验证（V&V），包括模型检查等任务。该方法整合了宏观正式建模、低保真模拟、高保真模拟以及真实机器人级别，确保模型的准确性和可追溯性。通过结合正式验证、模拟和实验验证，该方法增强了证据的信心，并通过一个机器人群在公共衣帽间操作的案例研究进行了探索。结果表明，这种综合方法比单独使用这些技术更有效。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "I.2.9; D.2; I.6"
      ],
      "primary_category": "cs.RO",
      "comment": "Updated Data Repository and Abstract. 15 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.15475v2",
      "published_date": "2024-07-22 08:40:05 UTC",
      "updated_date": "2025-02-28 20:59:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T09:00:14.330287"
    },
    {
      "arxiv_id": "2407.15431v1",
      "title": "Pre-Training and Prompting for Few-Shot Node Classification on Text-Attributed Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Huanjing Zhao",
        "Beining Yang",
        "Yukuo Cen",
        "Junyu Ren",
        "Chenhui Zhang",
        "Yuxiao Dong",
        "Evgeny Kharlamov",
        "Shu Zhao",
        "Jie Tang"
      ],
      "abstract": "The text-attributed graph (TAG) is one kind of important real-world\ngraph-structured data with each node associated with raw texts. For TAGs,\ntraditional few-shot node classification methods directly conduct training on\nthe pre-processed node features and do not consider the raw texts. The\nperformance is highly dependent on the choice of the feature pre-processing\nmethod. In this paper, we propose P2TAG, a framework designed for few-shot node\nclassification on TAGs with graph pre-training and prompting. P2TAG first\npre-trains the language model (LM) and graph neural network (GNN) on TAGs with\nself-supervised loss. To fully utilize the ability of language models, we adapt\nthe masked language modeling objective for our framework. The pre-trained model\nis then used for the few-shot node classification with a mixed prompt method,\nwhich simultaneously considers both text and graph information. We conduct\nexperiments on six real-world TAGs, including paper citation networks and\nproduct co-purchasing networks. Experimental results demonstrate that our\nproposed framework outperforms existing graph few-shot learning methods on\nthese datasets with +18.98% ~ +35.98% improvements.",
      "tldr_zh": "本论文针对文本属性图 (Text-Attributed Graphs, TAGs) 中的少样本节点分类问题，提出P2TAG框架，以解决传统方法依赖特征预处理导致的性能不稳定问题。P2TAG首先通过自监督损失在TAGs上预训练语言模型 (LM) 和图神经网络 (GNN)，并适应掩码语言建模 (Masked Language Modeling) 目标，以充分利用文本信息；随后，使用混合提示方法同时整合文本和图信息进行少样本节点分类。实验在六个真实世界数据集（如论文引用网络和产品共同购买网络）上验证了框架的有效性，与现有方法相比，准确率提升18.98%~35.98%。这为TAGs上的图少样本学习提供了新的基准。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SI",
      "comment": "Accepted to KDD'24",
      "pdf_url": "http://arxiv.org/pdf/2407.15431v1",
      "published_date": "2024-07-22 07:24:21 UTC",
      "updated_date": "2024-07-22 07:24:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T09:00:26.481009"
    },
    {
      "arxiv_id": "2408.03337v4",
      "title": "PsyDI: Towards a Personalized and Progressively In-depth Chatbot for Psychological Measurements",
      "title_zh": "翻译失败",
      "authors": [
        "Xueyan Li",
        "Xinyan Chen",
        "Yazhe Niu",
        "Shuai Hu",
        "Yu Liu"
      ],
      "abstract": "In the field of psychology, traditional assessment methods, such as\nstandardized scales, are frequently critiqued for their static nature, lack of\npersonalization, and reduced participant engagement, while comprehensive\ncounseling evaluations are often inaccessible. The complexity of quantifying\npsychological traits further limits these methods. Despite advances with large\nlanguage models (LLMs), many still depend on single-round Question-and-Answer\ninteractions. To bridge this gap, we introduce PsyDI, a personalized and\nprogressively in-depth chatbot designed for psychological measurements,\nexemplified by its application in the Myers-Briggs Type Indicator (MBTI)\nframework. PsyDI leverages user-related multi-modal information and engages in\ncustomized, multi-turn interactions to provide personalized, easily accessible\nmeasurements, while ensuring precise MBTI type determination. To address the\nchallenge of unquantifiable psychological traits, we introduce a novel training\nparadigm that involves learning the ranking of proxy variables associated with\nthese traits, culminating in a robust score model for MBTI measurements. The\nscore model enables PsyDI to conduct comprehensive and precise measurements\nthrough multi-turn interactions within a unified estimation context. Through\nvarious experiments, we validate the efficacy of both the score model and the\nPsyDI pipeline, demonstrating its potential to serve as a general framework for\npsychological measurements. Furthermore, the online deployment of PsyDI has\ngarnered substantial user engagement, with over 3,000 visits, resulting in the\ncollection of numerous multi-turn dialogues annotated with MBTI types, which\nfacilitates further research. The source code for the training and web service\ncomponents is publicly available as a part of OpenDILab at:\nhttps://github.com/opendilab/PsyDI",
      "tldr_zh": "该研究针对传统心理评估方法的静态性、缺乏个性化及参与度问题，提出PsyDI，一种个性化和逐步深入的聊天机器人，用于心理测量，以Myers-Briggs Type Indicator (MBTI)框架为例。PsyDI利用用户多模态信息进行定制的多轮互动，并引入一种新训练范式，通过学习心理特质相关代理变量的排名，构建一个精确的评分模型，实现统一的MBTI类型评估。实验结果验证了评分模型和PsyDI管道的有效性，其线上部署已吸引超过3,000次访问，收集了大量标注对话数据，并提供开源代码以支持进一步研究。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "29 pages, 15 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.03337v4",
      "published_date": "2024-07-22 07:19:12 UTC",
      "updated_date": "2025-01-16 07:40:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T09:00:38.584854"
    },
    {
      "arxiv_id": "2407.15428v1",
      "title": "Decoding BACnet Packets: A Large Language Model Approach for Packet Interpretation",
      "title_zh": "翻译失败",
      "authors": [
        "Rashi Sharma",
        "Hiroyuki Okada",
        "Tatsumi Oba",
        "Karthikk Subramanian",
        "Naoto Yanai",
        "Sugiri Pranata"
      ],
      "abstract": "The Industrial Control System (ICS) environment encompasses a wide range of\nintricate communication protocols, posing substantial challenges for Security\nOperations Center (SOC) analysts tasked with monitoring, interpreting, and\naddressing network activities and security incidents. Conventional monitoring\ntools and techniques often struggle to provide a clear understanding of the\nnature and intent of ICS-specific communications. To enhance comprehension, we\npropose a software solution powered by a Large Language Model (LLM). This\nsolution currently focused on BACnet protocol, processes a packet file data and\nextracts context by using a mapping database, and contemporary context\nretrieval methods for Retrieval Augmented Generation (RAG). The processed\npacket information, combined with the extracted context, serves as input to the\nLLM, which generates a concise packet file summary for the user. The software\ndelivers a clear, coherent, and easily understandable summary of network\nactivities, enabling SOC analysts to better assess the current state of the\ncontrol system.",
      "tldr_zh": "这篇论文针对工业控制系统 (ICS) 中复杂通信协议的监控难题，提出了一种基于 Large Language Model (LLM) 的软件解决方案，以提升 Security Operations Center (SOC) 分析师对网络活动的理解。方法包括处理 BACnet 协议的数据包文件，利用映射数据库和 Retrieval Augmented Generation (RAG) 技术提取上下文，并将这些信息输入 LLM 生成简洁摘要。该方案能提供清晰、可信的网络活动总结，帮助分析师更有效地评估控制系统状态。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "12 pages",
      "pdf_url": "http://arxiv.org/pdf/2407.15428v1",
      "published_date": "2024-07-22 07:15:49 UTC",
      "updated_date": "2024-07-22 07:15:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T09:00:50.017147"
    },
    {
      "arxiv_id": "2407.15427v1",
      "title": "YOLO-pdd: A Novel Multi-scale PCB Defect Detection Method Using Deep Representations with Sequential Images",
      "title_zh": "翻译失败",
      "authors": [
        "Bowen Liu",
        "Dongjie Chen",
        "Xiao Qi"
      ],
      "abstract": "With the rapid growth of the PCB manufacturing industry, there is an\nincreasing demand for computer vision inspection to detect defects during\nproduction. Improving the accuracy and generalization of PCB defect detection\nmodels remains a significant challenge. This paper proposes a high-precision,\nrobust, and real-time end-to-end method for PCB defect detection based on deep\nConvolutional Neural Networks (CNN). Traditional methods often suffer from low\naccuracy and limited applicability. We propose a novel approach combining\nYOLOv5 and multiscale modules for hierarchical residual-like connections. In\nPCB defect detection, noise can confuse the background and small targets. The\nYOLOv5 model provides a strong foundation with its real-time processing and\naccurate object detection capabilities. The multi-scale module extends\ntraditional approaches by incorporating hierarchical residual-like connections\nwithin a single block, enabling multiscale feature extraction. This\nplug-and-play module significantly enhances performance by extracting features\nat multiple scales and levels, which are useful for identifying defects of\nvarying sizes and complexities. Our multi-scale architecture integrates feature\nextraction, defect localization, and classification into a unified network.\nExperiments on a large-scale PCB dataset demonstrate significant improvements\nin precision, recall, and F1-score compared to existing methods. This work\nadvances computer vision inspection for PCB defect detection, providing a\nreliable solution for high-precision, robust, real-time, and domain-adaptive\ndefect detection in the PCB manufacturing industry.",
      "tldr_zh": "本论文提出了一种名为 YOLO-pdd 的新型多尺度 PCB 缺陷检测方法，基于深度卷积神经网络 (CNN) 结合 YOLOv5 和多尺度模块，以提高检测的精度、鲁棒性和实时性。该方法通过分层残差-like 连接的多尺度模块增强特征提取能力，能够有效处理噪声、背景干扰以及不同大小的缺陷。实验在大型 PCB 数据集上显示，与现有方法相比，YOLO-pdd 在精度、召回率和 F1-score 上实现了显著提升，为 PCB 制造行业的计算机视觉检测提供了可靠的端到端解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.15427v1",
      "published_date": "2024-07-22 07:08:22 UTC",
      "updated_date": "2024-07-22 07:08:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T09:01:01.650572"
    },
    {
      "arxiv_id": "2407.17524v1",
      "title": "StreamTinyNet: video streaming analysis with spatial-temporal TinyML",
      "title_zh": "翻译失败",
      "authors": [
        "Hazem Hesham Yousef Shalby",
        "Massimo Pavan",
        "Manuel Roveri"
      ],
      "abstract": "Tiny Machine Learning (TinyML) is a branch of Machine Learning (ML) that\nconstitutes a bridge between the ML world and the embedded system ecosystem\n(i.e., Internet of Things devices, embedded devices, and edge computing units),\nenabling the execution of ML algorithms on devices constrained in terms of\nmemory, computational capabilities, and power consumption. Video Streaming\nAnalysis (VSA), one of the most interesting tasks of TinyML, consists in\nscanning a sequence of frames in a streaming manner, with the goal of\nidentifying interesting patterns. Given the strict constraints of these tiny\ndevices, all the current solutions rely on performing a frame-by-frame\nanalysis, hence not exploiting the temporal component in the stream of data. In\nthis paper, we present StreamTinyNet, the first TinyML architecture to perform\nmultiple-frame VSA, enabling a variety of use cases that requires\nspatial-temporal analysis that were previously impossible to be carried out at\na TinyML level. Experimental results on public-available datasets show the\neffectiveness and efficiency of the proposed solution. Finally, StreamTinyNet\nhas been ported and tested on the Arduino Nicla Vision, showing the feasibility\nof what proposed.",
      "tldr_zh": "这篇论文介绍了StreamTinyNet，一种基于TinyML的视频流分析框架，能够进行spatial-temporal（空间-时间）分析，从而克服现有方法仅限于帧-by-帧处理的局限性。StreamTinyNet是第一个支持多帧VSA（Video Streaming Analysis）的TinyML架构，适用于内存和计算资源受限的嵌入式设备，如物联网设备。实验结果显示，该框架在公开数据集上表现出色，并已在Arduino Nicla Vision上成功移植和测试，证明了其实际可行性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "this paper has been accepted and presented at the WCCI24 conference",
      "pdf_url": "http://arxiv.org/pdf/2407.17524v1",
      "published_date": "2024-07-22 07:08:03 UTC",
      "updated_date": "2024-07-22 07:08:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T09:01:14.893874"
    },
    {
      "arxiv_id": "2407.15425v2",
      "title": "Empirical Capacity Model for Self-Attention Neural Networks",
      "title_zh": "自注意力神经网络的经验容量模型",
      "authors": [
        "Aki Härmä",
        "Marcin Pietrasik",
        "Anna Wilbik"
      ],
      "abstract": "Large pretrained self-attention neural networks, or transformers, have been\nvery successful in various tasks recently. The performance of a model on a\ngiven task depends on its ability to memorize and generalize the training data.\nLarge transformer models, which may have billions of parameters, in theory have\na huge capacity to memorize content. However, the current algorithms for the\noptimization fall short of the theoretical capacity, and the capacity is also\nhighly dependent on the content. In this paper, we focus on the memory capacity\nof these models obtained using common training algorithms and synthetic\ntraining data. Based on the results, we derive an empirical capacity model\n(ECM) for a generic transformer. The ECM can be used to design task-specific\ntransformer models with an optimal number of parameters in cases where the\ntarget memorization capability of the task can be defined.",
      "tldr_zh": "本研究探讨了自注意力神经网络（transformers）的记忆容量问题，发现这些模型的实际容量低于理论值，且高度依赖于内容和训练算法。作者通过使用常见训练算法和合成训练数据，进行实验分析并推导出一个经验容量模型（Empirical Capacity Model, ECM）。该模型可帮助设计针对特定任务的transformer模型，实现最优参数数量，从而提升模型的记忆和泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted to BNAIC'24, 14 pages + refs",
      "pdf_url": "http://arxiv.org/pdf/2407.15425v2",
      "published_date": "2024-07-22 07:02:15 UTC",
      "updated_date": "2024-07-31 10:27:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T09:01:26.449264"
    },
    {
      "arxiv_id": "2407.15423v2",
      "title": "Integrating IP Broadcasting with Audio Tags: Workflow and Challenges",
      "title_zh": "IP 广播与音频标签的整合：工作流和挑战",
      "authors": [
        "Rhys Burchett-Vass",
        "Arshdeep Singh",
        "Gabriel Bibbó",
        "Mark D. Plumbley"
      ],
      "abstract": "The broadcasting industry is increasingly adopting IP techniques,\nrevolutionising both live and pre-recorded content production, from news\ngathering to live music events. IP broadcasting allows for the transport of\naudio and video signals in an easily configurable way, aligning with modern\nnetworking techniques. This shift towards an IP workflow allows for much\ngreater flexibility, not only in routing signals but with the integration of\ntools using standard web development techniques. One possible tool could\ninclude the use of live audio tagging, which has a number of uses in the\nproduction of content. These include from automated closed captioning to\nidentifying unwanted sound events within a scene. In this paper, we describe\nthe process of containerising an audio tagging model into a microservice, a\nsmall segregated code module that can be integrated into a multitude of\ndifferent network setups. The goal is to develop a modular, accessible, and\nflexible tool capable of seamless deployment into broadcasting workflows of all\nsizes, from small productions to large corporations. Challenges surrounding\nlatency of the selected audio tagging model and its effect on the usefulness of\nthe end product are discussed.",
      "tldr_zh": "本论文探讨了将音频标记(audio tags)整合到IP广播工作流中的方法和挑战。研究者描述了将音频标记模型容器化为微服务，从而实现模块化部署，适用于从小型制作到大型企业的各种网络设置，这增强了广播内容的灵活性，如自动生成闭路字幕和识别不想要的声音事件。主要挑战包括音频标记模型的延迟问题，可能影响最终产品的实用性，但整体方法为IP广播提供了更高效的工具整合框架。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.MM",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "Submitted to DCASE 2024 Workshop",
      "pdf_url": "http://arxiv.org/pdf/2407.15423v2",
      "published_date": "2024-07-22 07:00:21 UTC",
      "updated_date": "2024-07-23 08:46:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T09:01:38.646496"
    },
    {
      "arxiv_id": "2407.15421v2",
      "title": "Planning in a recurrent neural network that plays Sokoban",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammad Taufeeque",
        "Philip Quirke",
        "Maximilian Li",
        "Chris Cundy",
        "Aaron David Tucker",
        "Adam Gleave",
        "Adrià Garriga-Alonso"
      ],
      "abstract": "How a neural network (NN) generalizes to novel situations depends on whether\nit has learned to select actions heuristically or via a planning process. \"An\ninvestigation of model-free planning\" (Guez et al. 2019) found that a recurrent\nNN (RNN) trained to play Sokoban appears to plan, with extra computation steps\nimproving the RNN's success rate. We replicate and expand on their behavioral\nanalysis, finding the RNN learns to give itself extra computation steps in\ncomplex situations by \"pacing\" in cycles. Moreover, we train linear probes that\npredict the future actions taken by the network and find that intervening on\nthe hidden state using these probes controls the agent's subsequent actions.\nLeveraging these insights, we perform model surgery, enabling the convolutional\nNN to generalize beyond its 10x10 architectural limit to arbitrarily sized\ninputs. The resulting model solves challenging, highly off-distribution levels.\nWe open-source our model and code, and believe the neural network's small size\n(1.29M parameters) makes it an excellent model organism to deepen our\nunderstanding of learned planning.",
      "tldr_zh": "这篇论文研究了循环神经网络(RNN)在玩 Sokoban 游戏时是否通过规划过程而非启发式选择来实现泛化，扩展了 Guez et al. (2019) 的分析，发现 RNN 在复杂场景下通过“循环踱步”(pacing in cycles)来增加计算步骤，从而提高成功率。作者训练了线性探针(linear probes)来预测网络的未来动作，并通过干预隐藏状态来控制代理的行为。最终，通过模型手术(model surgery)，RNN 成功泛化到超过其 10x10 架构限制的任意大小输入，并解决了高度离分布的挑战水平，同时开源了该小尺寸模型(1.29M 参数)以深化对学习规划的理解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Mechanistic Interpretability workshop, ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.15421v2",
      "published_date": "2024-07-22 06:57:34 UTC",
      "updated_date": "2024-10-24 18:06:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T09:01:51.585913"
    },
    {
      "arxiv_id": "2408.03946v1",
      "title": "Prompting for products: Investigating design space exploration strategies for text-to-image generative models",
      "title_zh": "产品提示：调查文本到图像生成模型的设计空间探索策略",
      "authors": [
        "Leah Chong",
        "I-Ping Lo",
        "Jude Rayan",
        "Steven Dow",
        "Faez Ahmed",
        "Ioanna Lykourentzou"
      ],
      "abstract": "Text-to-image models are enabling efficient design space exploration, rapidly\ngenerating images from text prompts. However, many generative AI tools are\nimperfect for product design applications as they are not built for the goals\nand requirements of product design. The unclear link between text input and\nimage output further complicates their application. This work empirically\ninvestigates design space exploration strategies that can successfully yield\nproduct images that are feasible, novel, and aesthetic, which are three common\ngoals in product design. Specifically, user actions within the global and local\nediting modes, including their time spent, prompt length, mono vs.\nmulti-criteria prompts, and goal orientation of prompts, are analyzed. Key\nfindings reveal the pivotal role of mono vs. multi-criteria and goal\norientation of prompts in achieving specific design goals over time and prompt\nlength. The study recommends prioritizing the use of multi-criteria prompts for\nfeasibility and novelty during global editing, while favoring mono-criteria\nprompts for aesthetics during local editing. Overall, this paper underscores\nthe nuanced relationship between the AI-driven text-to-image models and their\neffectiveness in product design, urging designers to carefully structure\nprompts during different editing modes to better meet the unique demands of\nproduct design.",
      "tldr_zh": "这篇论文探讨了文本到图像生成模型（text-to-image generative models）在产品设计中的应用问题，重点调查了设计空间探索（design space exploration）策略，以生成兼具可行性、新颖性和美学性的产品图像。研究通过实证分析用户在全局和本地编辑模式下的行为，包括提示长度、单标准 vs. 多标准提示以及目标导向，揭示了多标准提示和目标导向在实现特定设计目标中的关键作用。结果显示，在全局编辑中优先使用多标准提示可提升可行性和新颖性，而在本地编辑中采用单标准提示更利于美学优化；论文强调设计师需根据编辑模式精心构建提示，以最大化模型在产品设计中的有效性。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "I.2.1"
      ],
      "primary_category": "cs.HC",
      "comment": "12 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.03946v1",
      "published_date": "2024-07-22 06:42:04 UTC",
      "updated_date": "2024-07-22 06:42:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T09:02:05.205678"
    },
    {
      "arxiv_id": "2408.03945v1",
      "title": "Impacts of Anthropomorphizing Large Language Models in Learning Environments",
      "title_zh": "在学习环境中拟人化大语言模型的影响",
      "authors": [
        "Kristina Schaaff",
        "Marc-André Heidelmann"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly being used in learning\nenvironments to support teaching-be it as learning companions or as tutors.\nWith our contribution, we aim to discuss the implications of the\nanthropomorphization of LLMs in learning environments on educational theory to\nbuild a foundation for more effective learning outcomes and understand their\nemotional impact on learners. According to the media equation, people tend to\nrespond to media in the same way as they would respond to another person. A\nstudy conducted by the Georgia Institute of Technology showed that chatbots can\nbe successfully implemented in learning environments. In this study, learners\nin selected online courses were unable to distinguish the chatbot from a \"real\"\nteacher. As LLM-based chatbots such as OpenAI's GPT series are increasingly\nused in educational tools, it is important to understand how the attribution\nprocesses to LLM-based chatbots in terms of anthropomorphization affect\nlearners' emotions.",
      "tldr_zh": "这篇论文探讨了在学习环境中对大型语言模型 (LLMs) 进行拟人化 (anthropomorphization) 的影响，旨在为更有效的学习成果奠定基础，并分析其对学习者的情感冲击。论文基于媒体等式 (media equation) 理论，指出人们倾向于像对待真人一样回应媒体，如聊天机器人。引用佐治亚理工学院的研究，显示学习者难以区分 LLM-based 聊天机器人（如 GPT 系列）和真实老师，并强调理解 attribution processes 如何影响学习者情绪的重要性。最终，该研究为优化教育工具的设计提供了理论指导。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "Presented at Affective Computing Pre-Conference at ISRE 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.03945v1",
      "published_date": "2024-07-22 06:28:54 UTC",
      "updated_date": "2024-07-22 06:28:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T09:02:16.959091"
    },
    {
      "arxiv_id": "2407.15406v1",
      "title": "Automated Road Safety: Enhancing Sign and Surface Damage Detection with AI",
      "title_zh": "翻译失败",
      "authors": [
        "Davide Merolla",
        "Vittorio Latorre",
        "Antonio Salis",
        "Gianluca Boanelli"
      ],
      "abstract": "Public transportation plays a crucial role in our lives, and the road network\nis a vital component in the implementation of smart cities. Recent advancements\nin AI have enabled the development of advanced monitoring systems capable of\ndetecting anomalies in road surfaces and road signs, which, if unaddressed, can\nlead to serious road accidents. This paper presents an innovative approach to\nenhance road safety through the detection and classification of traffic signs\nand road surface damage using advanced deep learning techniques. This\nintegrated approach supports proactive maintenance strategies, improving road\nsafety and resource allocation for the Molise region and the city of\nCampobasso. The resulting system, developed as part of the Casa delle\nTecnologie Emergenti (House of Emergent Technologies) Molise (Molise CTE)\nresearch project funded by the Italian Minister of Economic Growth (MIMIT),\nleverages cutting-edge technologies such as Cloud Computing and High\nPerformance Computing with GPU utilization. It serves as a valuable tool for\nmunicipalities, enabling quick detection of anomalies and the prompt\norganization of maintenance operations",
      "tldr_zh": "本论文提出了一种创新的AI方法，用于检测和分类交通标志及路面损坏，以提升道路安全。该方法利用先进的深度 learning 技术、Cloud Computing 和 GPU 高性能计算，支持主动维护策略，并针对意大利Molise地区和Campobasso城市进行优化。实验结果表明，该系统能快速识别异常，促进维护操作的及时组织，从而改善道路安全和资源分配效率。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "16 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.15406v1",
      "published_date": "2024-07-22 06:22:36 UTC",
      "updated_date": "2024-07-22 06:22:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T09:02:28.391824"
    },
    {
      "arxiv_id": "2407.15017v4",
      "title": "Knowledge Mechanisms in Large Language Models: A Survey and Perspective",
      "title_zh": "大型语言模型中的知识机制：综述与视角",
      "authors": [
        "Mengru Wang",
        "Yunzhi Yao",
        "Ziwen Xu",
        "Shuofei Qiao",
        "Shumin Deng",
        "Peng Wang",
        "Xiang Chen",
        "Jia-Chen Gu",
        "Yong Jiang",
        "Pengjun Xie",
        "Fei Huang",
        "Huajun Chen",
        "Ningyu Zhang"
      ],
      "abstract": "Understanding knowledge mechanisms in Large Language Models (LLMs) is crucial\nfor advancing towards trustworthy AGI. This paper reviews knowledge mechanism\nanalysis from a novel taxonomy including knowledge utilization and evolution.\nKnowledge utilization delves into the mechanism of memorization, comprehension\nand application, and creation. Knowledge evolution focuses on the dynamic\nprogression of knowledge within individual and group LLMs. Moreover, we discuss\nwhat knowledge LLMs have learned, the reasons for the fragility of parametric\nknowledge, and the potential dark knowledge (hypothesis) that will be\nchallenging to address. We hope this work can help understand knowledge in LLMs\nand provide insights for future research.",
      "tldr_zh": "这篇论文对大型语言模型 (LLMs) 中的知识机制进行了全面调查和展望，强调理解这些机制对实现可信赖 AGI 的重要性。论文采用一个新颖的分类框架，包括知识利用（涵盖 memorization、comprehension、application 和 creation）和知识演化（聚焦于个体及群体 LLMs 中的动态知识进展）。此外，它讨论了 LLMs 学到的知识、参数知识的脆弱性以及潜在的 dark knowledge 假设，并为未来研究提供宝贵见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024 Findings; 39 pages (v4)",
      "pdf_url": "http://arxiv.org/pdf/2407.15017v4",
      "published_date": "2024-07-22 06:15:59 UTC",
      "updated_date": "2024-12-04 09:54:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T09:02:41.324933"
    },
    {
      "arxiv_id": "2407.15403v1",
      "title": "Offline Imitation Learning Through Graph Search and Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Zhao-Heng Yin",
        "Pieter Abbeel"
      ],
      "abstract": "Imitation learning is a powerful machine learning algorithm for a robot to\nacquire manipulation skills. Nevertheless, many real-world manipulation tasks\ninvolve precise and dexterous robot-object interactions, which make it\ndifficult for humans to collect high-quality expert demonstrations. As a\nresult, a robot has to learn skills from suboptimal demonstrations and\nunstructured interactions, which remains a key challenge. Existing works\ntypically use offline deep reinforcement learning (RL) to solve this challenge,\nbut in practice these algorithms are unstable and fragile due to the deadly\ntriad issue. To overcome this problem, we propose GSR, a simple yet effective\nalgorithm that learns from suboptimal demonstrations through Graph Search and\nRetrieval. We first use pretrained representation to organize the interaction\nexperience into a graph and perform a graph search to calculate the values of\ndifferent behaviors. Then, we apply a retrieval-based procedure to identify the\nbest behavior (actions) on each state and use behavior cloning to learn that\nbehavior. We evaluate our method in both simulation and real-world robotic\nmanipulation tasks with complex visual inputs, covering various precise and\ndexterous manipulation skills with objects of different physical properties.\nGSR can achieve a 10% to 30% higher success rate and over 30% higher\nproficiency compared to baselines. Our project page is at\nhttps://zhaohengyin.github.io/gsr.",
      "tldr_zh": "本论文针对机器人模仿学习（Imitation Learning）中从次优演示学习技能的挑战，提出了一种简单有效的算法GSR，通过Graph Search and Retrieval来处理复杂机器人-物体交互。GSR首先使用预训练表示将交互经验组织成图，进行图搜索计算行为值，然后通过检索机制识别最佳行为（actions）并应用行为克隆（behavior cloning）进行学习。与现有基于离线深度强化学习（offline deep reinforcement learning）的基线方法相比，GSR在模拟和真实世界机器人操作任务中，成功率提升10%至30%，熟练度提高超过30%。这项工作为精确灵活的机器人操控提供了更稳定可靠的解决方案。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Robotics: Science and Systems (RSS) 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.15403v1",
      "published_date": "2024-07-22 06:12:21 UTC",
      "updated_date": "2024-07-22 06:12:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T09:02:53.383856"
    },
    {
      "arxiv_id": "2407.15402v1",
      "title": "Tackling Selfish Clients in Federated Learning",
      "title_zh": "在联邦学习中应对自私客户端",
      "authors": [
        "Andrea Augello",
        "Ashish Gupta",
        "Giuseppe Lo Re",
        "Sajal K. Das"
      ],
      "abstract": "Federated Learning (FL) is a distributed machine learning paradigm\nfacilitating participants to collaboratively train a model without revealing\ntheir local data. However, when FL is deployed into the wild, some intelligent\nclients can deliberately deviate from the standard training process to make the\nglobal model inclined toward their local model, thereby prioritizing their\nlocal data distribution. We refer to this novel category of misbehaving clients\nas selfish. In this paper, we propose a Robust aggregation strategy for FL\nserver to mitigate the effect of Selfishness (in short RFL-Self). RFL-Self\nincorporates an innovative method to recover (or estimate) the true updates of\nselfish clients from the received ones, leveraging robust statistics (median of\nnorms) of the updates at every round. By including the recovered updates in\naggregation, our strategy offers strong robustness against selfishness. Our\nexperimental results, obtained on MNIST and CIFAR-10 datasets, demonstrate that\njust 2% of clients behaving selfishly can decrease the accuracy by up to 36%,\nand RFL-Self can mitigate that effect without degrading the global model\nperformance.",
      "tldr_zh": "本研究针对 Federated Learning (FL) 中 selfish clients 的问题，这些客户端故意偏离标准训练过程，以使全局模型偏向其本地数据分布。论文提出了一种鲁棒聚合策略 RFL-Self，利用 robust statistics（如 norms 的 median）来估计和恢复 selfish clients 的真实更新，并将其纳入聚合过程，以提升系统的鲁棒性。在 MNIST 和 CIFAR-10 数据集上的实验显示，仅 2% 的 selfish clients 即可导致准确率下降高达 36%，而 RFL-Self 能有效缓解这一影响，同时不降低全局模型性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 16 figures. European Conference on Artificial Intelligence\n  (ECAI) 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.15402v1",
      "published_date": "2024-07-22 06:08:13 UTC",
      "updated_date": "2024-07-22 06:08:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T09:03:03.526253"
    },
    {
      "arxiv_id": "2407.15399v1",
      "title": "Imposter.AI: Adversarial Attacks with Hidden Intentions towards Aligned Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Xiao Liu",
        "Liangzhi Li",
        "Tong Xiang",
        "Fuying Ye",
        "Lu Wei",
        "Wangyue Li",
        "Noa Garcia"
      ],
      "abstract": "With the development of large language models (LLMs) like ChatGPT, both their\nvast applications and potential vulnerabilities have come to the forefront.\nWhile developers have integrated multiple safety mechanisms to mitigate their\nmisuse, a risk remains, particularly when models encounter adversarial inputs.\nThis study unveils an attack mechanism that capitalizes on human conversation\nstrategies to extract harmful information from LLMs. We delineate three pivotal\nstrategies: (i) decomposing malicious questions into seemingly innocent\nsub-questions; (ii) rewriting overtly malicious questions into more covert,\nbenign-sounding ones; (iii) enhancing the harmfulness of responses by prompting\nmodels for illustrative examples. Unlike conventional methods that target\nexplicit malicious responses, our approach delves deeper into the nature of the\ninformation provided in responses. Through our experiments conducted on\nGPT-3.5-turbo, GPT-4, and Llama2, our method has demonstrated a marked efficacy\ncompared to conventional attack methods. In summary, this work introduces a\nnovel attack method that outperforms previous approaches, raising an important\nquestion: How to discern whether the ultimate intent in a dialogue is\nmalicious?",
      "tldr_zh": "这篇论文介绍了Imposter.AI，一种针对对齐的大型语言模型(LLMs)的新型对抗攻击方法，通过模拟人类对话策略来提取有害信息。方法包括三项关键策略：(i) 将恶意问题分解成看似无害的子问题；(ii) 将显性恶意问题改写成隐蔽的 benign-sounding 形式；(iii) 通过提示模型提供 illustrative examples 来增强响应有害性。与传统攻击不同，该方法更注重响应中信息的本质，在GPT-3.5-turbo、GPT-4和Llama2上的实验显示其有效性显著优于现有方法，并引发了如何识别对话中恶意意图的关键问题。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.15399v1",
      "published_date": "2024-07-22 06:04:29 UTC",
      "updated_date": "2024-07-22 06:04:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T09:03:16.922593"
    },
    {
      "arxiv_id": "2407.15396v2",
      "title": "Semantic Diversity-aware Prototype-based Learning for Unbiased Scene Graph Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Jaehyeong Jeon",
        "Kibum Kim",
        "Kanghoon Yoon",
        "Chanyoung Park"
      ],
      "abstract": "The scene graph generation (SGG) task involves detecting objects within an\nimage and predicting predicates that represent the relationships between the\nobjects. However, in SGG benchmark datasets, each subject-object pair is\nannotated with a single predicate even though a single predicate may exhibit\ndiverse semantics (i.e., semantic diversity), existing SGG models are trained\nto predict the one and only predicate for each pair. This in turn results in\nthe SGG models to overlook the semantic diversity that may exist in a\npredicate, thus leading to biased predictions. In this paper, we propose a\nnovel model-agnostic Semantic Diversity-aware Prototype-based Learning (DPL)\nframework that enables unbiased predictions based on the understanding of the\nsemantic diversity of predicates. Specifically, DPL learns the regions in the\nsemantic space covered by each predicate to distinguish among the various\ndifferent semantics that a single predicate can represent. Extensive\nexperiments demonstrate that our proposed model-agnostic DPL framework brings\nsignificant performance improvement on existing SGG models, and also\neffectively understands the semantic diversity of predicates.",
      "tldr_zh": "本文针对场景图生成(SGG)任务中谓词语义多样性(semantic diversity)被忽略导致的预测偏差问题，提出了一种模型无关的框架：Semantic Diversity-aware Prototype-based Learning (DPL)。DPL 通过学习每个谓词在语义空间中覆盖的区域，来区分一个谓词可能代表的多种语义，从而实现无偏预测。实验结果显示，该框架显著提高了现有 SGG 模型的性能，并有效理解了谓词的语义多样性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.15396v2",
      "published_date": "2024-07-22 05:53:46 UTC",
      "updated_date": "2024-07-25 12:54:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T09:03:27.681556"
    },
    {
      "arxiv_id": "2407.15390v1",
      "title": "ALLaM: Large Language Models for Arabic and English",
      "title_zh": "翻译失败",
      "authors": [
        "M Saiful Bari",
        "Yazeed Alnumay",
        "Norah A. Alzahrani",
        "Nouf M. Alotaibi",
        "Hisham A. Alyahya",
        "Sultan AlRashed",
        "Faisal A. Mirza",
        "Shaykhah Z. Alsubaie",
        "Hassan A. Alahmed",
        "Ghadah Alabduljabbar",
        "Raghad Alkhathran",
        "Yousef Almushayqih",
        "Raneem Alnajim",
        "Salman Alsubaihi",
        "Maryam Al Mansour",
        "Majed Alrubaian",
        "Ali Alammari",
        "Zaki Alawami",
        "Abdulmohsen Al-Thubaity",
        "Ahmed Abdelali",
        "Jeril Kuriakose",
        "Abdalghani Abujabal",
        "Nora Al-Twairesh",
        "Areeb Alowisheq",
        "Haidar Khan"
      ],
      "abstract": "We present ALLaM: Arabic Large Language Model, a series of large language\nmodels to support the ecosystem of Arabic Language Technologies (ALT). ALLaM is\ncarefully trained considering the values of language alignment and knowledge\ntransfer at scale. Our autoregressive decoder-only architecture models\ndemonstrate how second-language acquisition via vocabulary expansion and\npretraining on a mixture of Arabic and English text can steer a model towards a\nnew language (Arabic) without any catastrophic forgetting in the original\nlanguage (English). Furthermore, we highlight the effectiveness of using\nparallel/translated data to aid the process of knowledge alignment between\nlanguages. Finally, we show that extensive alignment with human preferences can\nsignificantly enhance the performance of a language model compared to models of\na larger scale with lower quality alignment. ALLaM achieves state-of-the-art\nperformance in various Arabic benchmarks, including MMLU Arabic, ACVA, and\nArabic Exams. Our aligned models improve both in Arabic and English from their\nbase aligned models.",
      "tldr_zh": "我们介绍了 ALLaM，一系列支持阿拉伯和英语的大型语言模型（Large Language Models），旨在提升阿拉伯语言技术生态。模型采用自回归解码器架构，通过词汇扩展和混合阿拉伯-英语文本预训练，实现从英语到阿拉伯语的知识转移，而避免了灾难性遗忘（catastrophic forgetting），并利用平行数据辅助语言间知识对齐。实验结果显示，ALLaM 在 MMLU Arabic、ACVA 和 Arabic Exams 等基准测试中达到最先进性能，且通过人类偏好对齐，显著提升了模型在双语任务上的表现。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.15390v1",
      "published_date": "2024-07-22 05:35:17 UTC",
      "updated_date": "2024-07-22 05:35:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T09:03:40.907688"
    },
    {
      "arxiv_id": "2407.15385v1",
      "title": "Towards Robust Vision Transformer via Masked Adaptive Ensemble",
      "title_zh": "翻译失败",
      "authors": [
        "Fudong Lin",
        "Jiadong Lou",
        "Xu Yuan",
        "Nian-Feng Tzeng"
      ],
      "abstract": "Adversarial training (AT) can help improve the robustness of Vision\nTransformers (ViT) against adversarial attacks by intentionally injecting\nadversarial examples into the training data. However, this way of adversarial\ninjection inevitably incurs standard accuracy degradation to some extent,\nthereby calling for a trade-off between standard accuracy and robustness.\nBesides, the prominent AT solutions are still vulnerable to adaptive attacks.\nTo tackle such shortcomings, this paper proposes a novel ViT architecture,\nincluding a detector and a classifier bridged by our newly developed adaptive\nensemble. Specifically, we empirically discover that detecting adversarial\nexamples can benefit from the Guided Backpropagation technique. Driven by this\ndiscovery, a novel Multi-head Self-Attention (MSA) mechanism is introduced to\nenhance our detector to sniff adversarial examples. Then, a classifier with two\nencoders is employed for extracting visual representations respectively from\nclean images and adversarial examples, with our adaptive ensemble to adaptively\nadjust the proportion of visual representations from the two encoders for\naccurate classification. This design enables our ViT architecture to achieve a\nbetter trade-off between standard accuracy and robustness. Besides, our\nadaptive ensemble technique allows us to mask off a random subset of image\npatches within input data, boosting our ViT's robustness against adaptive\nattacks, while maintaining high standard accuracy. Experimental results exhibit\nthat our ViT architecture, on CIFAR-10, achieves the best standard accuracy and\nadversarial robustness of 90.3% and 49.8%, respectively.",
      "tldr_zh": "本文提出了一种新型 Vision Transformer (ViT) 架构，通过 Masked Adaptive Ensemble 技术来提升模型对对抗攻击的鲁棒性，同时缓解 Adversarial Training (AT) 带来的标准准确率下降问题。该架构包括一个基于 Guided Backpropagation 和改进的 Multi-head Self-Attention (MSA) 机制的检测器，用于识别对抗样本，以及一个带有两个编码器的分类器，通过 Adaptive Ensemble 动态调整干净图像和对抗样本的视觉表示比例以实现精确分类。此外，该方法允许屏蔽输入图像的随机子集，进一步增强对自适应攻击的抵抗力；实验结果显示，在 CIFAR-10 数据集上，该 ViT 架构达到了 90.3% 的标准准确率和 49.8% 的对抗鲁棒性，优于现有基线模型。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages",
      "pdf_url": "http://arxiv.org/pdf/2407.15385v1",
      "published_date": "2024-07-22 05:28:29 UTC",
      "updated_date": "2024-07-22 05:28:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T09:03:54.242618"
    },
    {
      "arxiv_id": "2407.15366v1",
      "title": "Walking in Others' Shoes: How Perspective-Taking Guides Large Language Models in Reducing Toxicity and Bias",
      "title_zh": "翻译失败",
      "authors": [
        "Rongwu Xu",
        "Zi'an Zhou",
        "Tianwei Zhang",
        "Zehan Qi",
        "Su Yao",
        "Ke Xu",
        "Wei Xu",
        "Han Qiu"
      ],
      "abstract": "The common toxicity and societal bias in contents generated by large language\nmodels (LLMs) necessitate strategies to reduce harm. Present solutions often\ndemand white-box access to the model or substantial training, which is\nimpractical for cutting-edge commercial LLMs. Moreover, prevailing prompting\nmethods depend on external tool feedback and fail to simultaneously lessen\ntoxicity and bias. Motivated by social psychology principles, we propose a\nnovel strategy named \\textbf{perspective-taking prompting (\\textsc{PeT})} that\ninspires LLMs to integrate diverse human perspectives and self-regulate their\nresponses. This self-correction mechanism can significantly diminish toxicity\n(up to $89\\%$) and bias (up to $73\\%$) in LLMs' responses. Rigorous evaluations\nand ablation studies are conducted on two commercial LLMs (ChatGPT and GLM) and\nthree open-source LLMs, revealing \\textsc{PeT}'s superiority in producing less\nharmful responses, outperforming five strong baselines.",
      "tldr_zh": "这篇论文探讨了如何通过一种名为 perspective-taking prompting (PeT) 的新策略来减少大型语言模型 (LLMs) 中的毒性和社会偏见。PeT 基于社会心理学原理，引导 LLMs 整合多样人类视角并进行自我调节响应，从而避免依赖外部工具或大量训练。实验结果显示，该方法在 ChatGPT、GLM 和三个开源 LLMs 上显著降低毒性（高达89%）和偏见（高达73%），并优于五个强基线方法。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.15366v1",
      "published_date": "2024-07-22 04:25:01 UTC",
      "updated_date": "2024-07-22 04:25:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T09:04:06.530369"
    },
    {
      "arxiv_id": "2407.15362v3",
      "title": "A Multimodal Knowledge-enhanced Whole-slide Pathology Foundation Model",
      "title_zh": "多模态知识增强的全切片病理学基础模型",
      "authors": [
        "Yingxue Xu",
        "Yihui Wang",
        "Fengtao Zhou",
        "Jiabo Ma",
        "Cheng Jin",
        "Shu Yang",
        "Jinbang Li",
        "Zhengyu Zhang",
        "Chenglong Zhao",
        "Huajun Zhou",
        "Zhenhui Li",
        "Huangjing Lin",
        "Xin Wang",
        "Jiguang Wang",
        "Anjia Han",
        "Ronald Cheong Kin Chan",
        "Li Liang",
        "Xiuming Zhang",
        "Hao Chen"
      ],
      "abstract": "Remarkable strides in computational pathology have been made in the\ntask-agnostic foundation model that advances the performance of a wide array of\ndownstream clinical tasks. Despite the promising performance, there are still\nseveral challenges. First, prior works have resorted to either vision-only or\nimage-caption data, disregarding pathology reports with more clinically\nauthentic information from pathologists and gene expression profiles which\nrespectively offer distinct knowledge for versatile clinical applications.\nSecond, the current progress in pathology FMs predominantly concentrates on the\npatch level, where the restricted context of patch-level pretraining fails to\ncapture whole-slide patterns. Even recent slide-level FMs still struggle to\nprovide whole-slide context for patch representation. In this study, for the\nfirst time, we develop a pathology foundation model incorporating three levels\nof modalities: pathology slides, pathology reports, and gene expression data,\nwhich resulted in 26,169 slide-level modality pairs from 10,275 patients across\n32 cancer types, amounting to over 116 million pathological patch images. To\nleverage these data for CPath, we propose a novel whole-slide pretraining\nparadigm that injects the multimodal whole-slide context into the patch\nrepresentation, called Multimodal Self-TAught PRetraining (mSTAR). The proposed\nparadigm revolutionizes the pretraining workflow for CPath, enabling the\npathology FM to acquire the whole-slide context. To the best of our knowledge,\nthis is the first attempt to incorporate three modalities at the whole-slide\ncontext for enhancing pathology FMs. To systematically evaluate the\ncapabilities of mSTAR, we built the largest spectrum of oncological benchmark,\nspanning 7 categories of oncological applications in 15 types of 97 practical\noncological tasks.",
      "tldr_zh": "本文提出了一种多模态知识增强的 Whole-Slide Pathology Foundation Model，以解决现有病理基础模型（Foundation Models）在数据类型和上下文捕捉方面的局限性。该模型首次整合了三种模态——病理幻灯片、病理报告和基因表达数据——基于 10,275 名患者、32 种癌症类型的 26,169 个 Slide-level 模态对（超过 116 百万个病理 Patch 图像）进行训练。作者引入了新型预训练范式 Multimodal Self-TAught PRetraining (mSTAR)，通过注入多模态 Whole-Slide 上下文到 Patch 表示中，提升了模型对整体幻灯片模式的理解，并在 97 个实际肿瘤学任务上建立了最大的基准，展示了显著的性能改进。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "62 pages",
      "pdf_url": "http://arxiv.org/pdf/2407.15362v3",
      "published_date": "2024-07-22 04:09:27 UTC",
      "updated_date": "2025-03-25 08:49:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T09:04:21.889264"
    },
    {
      "arxiv_id": "2407.21043v2",
      "title": "CP-Prompt: Composition-Based Cross-modal Prompting for Domain-Incremental Continual Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Feng",
        "Zhen Tian",
        "Yifan Zhu",
        "Zongfu Han",
        "Haoran Luo",
        "Guangwei Zhang",
        "Meina Song"
      ],
      "abstract": "The key challenge of cross-modal domain-incremental learning (DIL) is to\nenable the learning model to continuously learn from novel data with different\nfeature distributions under the same task without forgetting old ones. However,\nexisting top-performing methods still cause high forgetting rates, by lacking\nintra-domain knowledge extraction and inter-domain common prompting strategy.\nIn this paper, we propose a simple yet effective framework, CP-Prompt, by\ntraining limited parameters to instruct a pre-trained model to learn new\ndomains and avoid forgetting existing feature distributions. CP-Prompt captures\nintra-domain knowledge by compositionally inserting personalized prompts on\nmulti-head self-attention layers and then learns the inter-domain knowledge\nwith a common prompting strategy. CP-Prompt shows superiority compared with\nstate-of-the-art baselines among three widely evaluated DIL tasks. The source\ncode is available at https://github.com/dannis97500/CP_Prompt.",
      "tldr_zh": "本研究针对跨模态领域增量学习 (DIL) 的关键挑战，即模型需持续学习新数据分布而不遗忘旧知识，提出了一种简单有效的框架 CP-Prompt。CP-Prompt 通过在多头自注意力 (multi-head self-attention) 层上组合插入个性化提示来捕获内部域知识，并采用共同提示策略 (common prompting strategy) 学习域间知识，从而指导预训练模型适应新域。实验结果表明，CP-Prompt 在三个广泛评估的 DIL 任务中优于最先进基线，提升了模型的持续学习性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by ACM MM 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.21043v2",
      "published_date": "2024-07-22 04:07:12 UTC",
      "updated_date": "2024-08-02 14:58:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T09:04:31.228997"
    },
    {
      "arxiv_id": "2407.15356v1",
      "title": "X-Recon: Learning-based Patient-specific High-Resolution CT Reconstruction from Orthogonal X-Ray Images",
      "title_zh": "翻译失败",
      "authors": [
        "Yunpeng Wang",
        "Kang Wang",
        "Yaoyao Zhuo",
        "Weiya Shi",
        "Fei Shan",
        "Lei Liu"
      ],
      "abstract": "Rapid and accurate diagnosis of pneumothorax, utilizing chest X-ray and\ncomputed tomography (CT), is crucial for assisted diagnosis. Chest X-ray is\ncommonly used for initial localization of pneumothorax, while CT ensures\naccurate quantification. However, CT scans involve high radiation doses and can\nbe costly. To achieve precise quantitative diagnosis while minimizing radiation\nexposure, we proposed X-Recon, a CT ultra-sparse reconstruction network based\non ortho-lateral chest X-ray images. X-Recon integrates generative adversarial\nnetworks (GANs), including a generator with a multi-scale fusion rendering\nmodule and a discriminator enhanced by 3D coordinate convolutional layers,\ndesigned to facilitate CT reconstruction. To improve precision, a projective\nspatial transformer is utilized to incorporate multi-angle projection loss.\nAdditionally, we proposed PTX-Seg, a zero-shot pneumothorax segmentation\nalgorithm, combining image processing techniques with deep-learning models for\nthe segmentation of air-accumulated regions and lung structures. Experiments on\na large-scale dataset demonstrate its superiority over existing approaches.\nX-Recon achieved a significantly higher reconstruction resolution with a higher\naverage spatial resolution and a lower average slice thickness. The\nreconstruction metrics achieved state-of-the-art performance in terms of\nseveral metrics including peak signal-to-noise ratio. The zero-shot\nsegmentation algorithm, PTX-Seg, also demonstrated high segmentation precision\nfor the air-accumulated region, the left lung, and the right lung. Moreover,\nthe consistency analysis for the pneumothorax chest occupancy ratio between\nreconstructed CT and original CT obtained a high correlation coefficient. Code\nwill be available at: https://github.com/wangyunpengbio/X-Recon",
      "tldr_zh": "本文提出 X-Recon，一种基于正侧胸部 X-Ray 图像的学习方法，用于重建高分辨率患者特异性 CT，从而实现精确量化气胸诊断的同时减少辐射暴露和成本。X-Recon 整合了 GANs，包括多尺度融合渲染模块和增强的 3D 坐标卷积层判别器，并通过投影空间变换器融入多角度投影损失来提升重建精度。此外，作者开发了 PTX-Seg，一种零样本气胸分割算法，结合图像处理技术和深度学习模型，对空气积累区域和肺结构进行高精度分割。在大型数据集上的实验表明，X-Recon 实现了更高的重建分辨率（如更高的平均空间分辨率和更低的平均切片厚度），并在峰值信噪比等指标上达到最先进性能，且重建 CT 与原始 CT 在气胸胸部占用率上显示出高相关系数。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.15356v1",
      "published_date": "2024-07-22 03:55:36 UTC",
      "updated_date": "2024-07-22 03:55:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T09:04:46.037088"
    },
    {
      "arxiv_id": "2407.15351v2",
      "title": "LLMExplainer: Large Language Model based Bayesian Inference for Graph Explanation Generation",
      "title_zh": "LLMExplainer：基于大型语言",
      "authors": [
        "Jiaxing Zhang",
        "Jiayi Liu",
        "Dongsheng Luo",
        "Jennifer Neville",
        "Hua Wei"
      ],
      "abstract": "Recent studies seek to provide Graph Neural Network (GNN) interpretability\nvia multiple unsupervised learning models. Due to the scarcity of datasets,\ncurrent methods easily suffer from learning bias. To solve this problem, we\nembed a Large Language Model (LLM) as knowledge into the GNN explanation\nnetwork to avoid the learning bias problem. We inject LLM as a Bayesian\nInference (BI) module to mitigate learning bias. The efficacy of the BI module\nhas been proven both theoretically and experimentally. We conduct experiments\non both synthetic and real-world datasets. The innovation of our work lies in\ntwo parts: 1. We provide a novel view of the possibility of an LLM functioning\nas a Bayesian inference to improve the performance of existing algorithms; 2.\nWe are the first to discuss the learning bias issues in the GNN explanation\nproblem.",
      "tldr_zh": "本研究提出LLMExplainer框架，利用Large Language Model (LLM)嵌入Graph Neural Network (GNN)解释网络中，作为Bayesian Inference (BI)模块，以缓解现有无监督GNN解释方法因数据集稀缺而导致的学习偏差问题。该方法通过LLM的知识注入和BI机制，理论上和实验上证明了其有效性，并在合成和真实数据集上进行了验证。创新点包括：首次探讨GNN解释中的学习偏差问题，以及提供LLM作为Bayesian Inference的新视角，以提升算法性能。整体框架为GNN的可解释性提供了更可靠的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint Paper with 13 pages",
      "pdf_url": "http://arxiv.org/pdf/2407.15351v2",
      "published_date": "2024-07-22 03:36:38 UTC",
      "updated_date": "2024-07-23 04:01:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T09:04:53.978864"
    },
    {
      "arxiv_id": "2407.15893v1",
      "title": "Cascaded two-stage feature clustering and selection via separability and consistency in fuzzy decision systems",
      "title_zh": "翻译失败",
      "authors": [
        "Yuepeng Chen",
        "Weiping Ding",
        "Hengrong Ju",
        "Jiashuang Huang",
        "Tao Yin"
      ],
      "abstract": "Feature selection is a vital technique in machine learning, as it can reduce\ncomputational complexity, improve model performance, and mitigate the risk of\noverfitting. However, the increasing complexity and dimensionality of datasets\npose significant challenges in the selection of features. Focusing on these\nchallenges, this paper proposes a cascaded two-stage feature clustering and\nselection algorithm for fuzzy decision systems. In the first stage, we reduce\nthe search space by clustering relevant features and addressing inter-feature\nredundancy. In the second stage, a clustering-based sequentially forward\nselection method that explores the global and local structure of data is\npresented. We propose a novel metric for assessing the significance of\nfeatures, which considers both global separability and local consistency.\nGlobal separability measures the degree of intra-class cohesion and inter-class\nseparation based on fuzzy membership, providing a comprehensive understanding\nof data separability. Meanwhile, local consistency leverages the fuzzy\nneighborhood rough set model to capture uncertainty and fuzziness in the data.\nThe effectiveness of our proposed algorithm is evaluated through experiments\nconducted on 18 public datasets and a real-world schizophrenia dataset. The\nexperiment results demonstrate our algorithm's superiority over benchmarking\nalgorithms in both classification accuracy and the number of selected features.",
      "tldr_zh": "这篇论文针对特征选择(feature selection)面临的挑战，提出了一种级联两阶段特征聚类和选择算法，适用于模糊决策系统(fuzzy decision systems)，以减少计算复杂度、提升模型性能并缓解过拟合。算法的第一阶段通过聚类相关特征并处理特征间冗余来缩小搜索空间；第二阶段则采用基于聚类的顺序向前选择方法，探索数据的全局和局部结构。论文引入了一种新指标，结合全局可分性(global separability)——基于模糊成员度衡量类内凝聚和类间分离——以及局部一致性(local consistency)——利用模糊邻域粗糙集模型捕获数据的不确定性。实验结果显示，该算法在18个公共数据集和一个真实世界精神分裂症数据集上，优于基准算法，在分类准确性和选定特征数量方面表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper has been accepted by IEEE Transactions on Fuzzy Systems\n  for publication. Permission from IEEE must be obtained for all other uses, in\n  any current or future media. The final version is available at\n  [10.1109/TFUZZ.2024.3420963]",
      "pdf_url": "http://arxiv.org/pdf/2407.15893v1",
      "published_date": "2024-07-22 02:44:32 UTC",
      "updated_date": "2024-07-22 02:44:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T09:05:08.101166"
    },
    {
      "arxiv_id": "2408.03943v1",
      "title": "Building Machines that Learn and Think with People",
      "title_zh": "翻译失败",
      "authors": [
        "Katherine M. Collins",
        "Ilia Sucholutsky",
        "Umang Bhatt",
        "Kartik Chandra",
        "Lionel Wong",
        "Mina Lee",
        "Cedegao E. Zhang",
        "Tan Zhi-Xuan",
        "Mark Ho",
        "Vikash Mansinghka",
        "Adrian Weller",
        "Joshua B. Tenenbaum",
        "Thomas L. Griffiths"
      ],
      "abstract": "What do we want from machine intelligence? We envision machines that are not\njust tools for thought, but partners in thought: reasonable, insightful,\nknowledgeable, reliable, and trustworthy systems that think with us. Current\nartificial intelligence (AI) systems satisfy some of these criteria, some of\nthe time. In this Perspective, we show how the science of collaborative\ncognition can be put to work to engineer systems that really can be called\n``thought partners,'' systems built to meet our expectations and complement our\nlimitations. We lay out several modes of collaborative thought in which humans\nand AI thought partners can engage and propose desiderata for human-compatible\nthought partnerships. Drawing on motifs from computational cognitive science,\nwe motivate an alternative scaling path for the design of thought partners and\necosystems around their use through a Bayesian lens, whereby the partners we\nconstruct actively build and reason over models of the human and world.",
      "tldr_zh": "这篇论文探讨了构建 AI 系统作为人类思考伙伴的可能性，这些系统应具备合理性、洞察力、知识渊博性以及可靠性，以弥补人类局限。作者基于协作认知科学，提出几种人类和 AI 共同参与的思考模式，并定义了人类兼容的思考伙伴期望标准。论文通过贝叶斯视角，建议一种替代的 AI 设计路径，让系统主动构建并推理人类和世界的模型，从而实现更有效的协作认知。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.03943v1",
      "published_date": "2024-07-22 02:42:45 UTC",
      "updated_date": "2024-07-22 02:42:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T09:05:18.629219"
    },
    {
      "arxiv_id": "2407.15332v1",
      "title": "Robust personalized pricing under uncertainty of purchase probabilities",
      "title_zh": "在购买概率不确定性下的稳健个性化定价",
      "authors": [
        "Shunnosuke Ikeda",
        "Naoki Nishimura",
        "Noriyoshi Sukegawa",
        "Yuichi Takano"
      ],
      "abstract": "This paper is concerned with personalized pricing models aimed at maximizing\nthe expected revenues or profits for a single item. While it is essential for\npersonalized pricing to predict the purchase probabilities for each consumer,\nthese predicted values are inherently subject to unavoidable errors that can\nnegatively impact the realized revenues and profits. To address this issue, we\nfocus on robust optimization techniques that yield reliable solutions to\noptimization problems under uncertainty. Specifically, we propose a robust\noptimization model for personalized pricing that accounts for the uncertainty\nof predicted purchase probabilities. This model can be formulated as a\nmixed-integer linear optimization problem, which can be solved exactly using\nmathematical optimization solvers. We also develop a Lagrangian decomposition\nalgorithm combined with line search to efficiently find high-quality solutions\nfor large-scale optimization problems. Experimental results demonstrate the\neffectiveness of our robust optimization model and highlight the utility of our\nLagrangian decomposition algorithm in terms of both computational efficiency\nand solution quality.",
      "tldr_zh": "本文研究了在购买概率不确定性下进行鲁棒个性化定价，以最大化预期收入或利润。作者提出一个鲁棒优化模型，通过考虑预测购买概率的误差，将问题表述为混合整数线性优化问题，并使用数学优化求解器求解。 additionally，他们开发了Lagrangian decomposition算法结合线搜索方法，以高效处理大规模问题；实验结果显示，该模型显著提高了解决方案的可靠性和计算效率。",
      "categories": [
        "math.OC",
        "cs.AI"
      ],
      "primary_category": "math.OC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.15332v1",
      "published_date": "2024-07-22 02:36:19 UTC",
      "updated_date": "2024-07-22 02:36:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T09:05:30.045130"
    },
    {
      "arxiv_id": "2407.15325v2",
      "title": "Odyssey: Empowering Minecraft Agents with Open-World Skills",
      "title_zh": "Odyssey: 赋予 Minecraft 代理以开放世界技能",
      "authors": [
        "Shunyu Liu",
        "Yaoru Li",
        "Kongcheng Zhang",
        "Zhenyu Cui",
        "Wenkai Fang",
        "Yuxuan Zheng",
        "Tongya Zheng",
        "Mingli Song"
      ],
      "abstract": "Recent studies have delved into constructing generalist agents for open-world\nenvironments like Minecraft. Despite the encouraging results, existing efforts\nmainly focus on solving basic programmatic tasks, e.g., material collection and\ntool-crafting following the Minecraft tech-tree, treating the ObtainDiamond\ntask as the ultimate goal. This limitation stems from the narrowly defined set\nof actions available to agents, requiring them to learn effective long-horizon\nstrategies from scratch. Consequently, discovering diverse gameplay\nopportunities in the open world becomes challenging. In this work, we introduce\nOdyssey, a new framework that empowers Large Language Model (LLM)-based agents\nwith open-world skills to explore the vast Minecraft world. Odyssey comprises\nthree key parts: (1) An interactive agent with an open-world skill library that\nconsists of 40 primitive skills and 183 compositional skills. (2) A fine-tuned\nLLaMA-3 model trained on a large question-answering dataset with 390k+\ninstruction entries derived from the Minecraft Wiki. (3) A new agent capability\nbenchmark includes the long-term planning task, the dynamic-immediate planning\ntask, and the autonomous exploration task. Extensive experiments demonstrate\nthat the proposed Odyssey framework can effectively evaluate different\ncapabilities of LLM-based agents. All datasets, model weights, and code are\npublicly available to motivate future research on more advanced autonomous\nagent solutions.",
      "tldr_zh": "该研究提出Odyssey框架，以增强Large Language Model (LLM)-based agents在Minecraft开放世界中的技能，解决现有代理仅限于基本任务（如材料收集和工具制作）的局限性。框架包括一个交互式代理的开放世界技能库（包含40个原始技能和183个组合技能）、一个在Minecraft Wiki数据上微调的LLaMA-3模型（基于39万+指令训练集），以及一个新的代理能力基准（涵盖长期规划、动态即时规划和自主探索任务）。实验结果显示，Odyssey能有效评估agents的多种能力，所有数据集、模型权重和代码已公开，以促进未来自主代理研究。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.15325v2",
      "published_date": "2024-07-22 02:06:59 UTC",
      "updated_date": "2024-10-07 09:40:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T09:05:53.187531"
    },
    {
      "arxiv_id": "2407.15312v1",
      "title": "FMDNN: A Fuzzy-guided Multi-granular Deep Neural Network for Histopathological Image Classification",
      "title_zh": "FMDNN：一种模糊引导的多粒度",
      "authors": [
        "Weiping Ding",
        "Tianyi Zhou",
        "Jiashuang Huang",
        "Shu Jiang",
        "Tao Hou",
        "Chin-Teng Lin"
      ],
      "abstract": "Histopathological image classification constitutes a pivotal task in\ncomputer-aided diagnostics. The precise identification and categorization of\nhistopathological images are of paramount significance for early disease\ndetection and treatment. In the diagnostic process of pathologists, a\nmulti-tiered approach is typically employed to assess abnormalities in cell\nregions at different magnifications. However, feature extraction is often\nperformed at a single granularity, overlooking the multi-granular\ncharacteristics of cells. To address this issue, we propose the Fuzzy-guided\nMulti-granularity Deep Neural Network (FMDNN). Inspired by the multi-granular\ndiagnostic approach of pathologists, we perform feature extraction on cell\nstructures at coarse, medium, and fine granularity, enabling the model to fully\nharness the information in histopathological images. We incorporate the theory\nof fuzzy logic to address the challenge of redundant key information arising\nduring multi-granular feature extraction. Cell features are described from\ndifferent perspectives using multiple fuzzy membership functions, which are\nfused to create universal fuzzy features. A fuzzy-guided cross-attention module\nguides universal fuzzy features toward multi-granular features. We propagate\nthese features through an encoder to all patch tokens, aiming to achieve\nenhanced classification accuracy and robustness. In experiments on multiple\npublic datasets, our model exhibits a significant improvement in accuracy over\ncommonly used classification methods for histopathological image classification\nand shows commendable interpretability.",
      "tldr_zh": "该研究针对病理图像分类中的单一粒度特征提取问题，提出了一种Fuzzy-guided Multi-granular Deep Neural Network (FMDNN)模型，受病理学家多层诊断启发，在粗、中、细粒度上提取细胞结构特征，以充分利用图像信息。模型融入模糊逻辑理论，通过多个模糊成员函数描述特征并融合成通用模糊特征，再利用模糊引导的交叉注意力模块将这些特征引导到多粒度特征中，并通过编码器传播以提升分类准确性和鲁棒性。在多个公共数据集上的实验显示，FMDNN 比传统方法显著提高了准确率，并展示了良好的可解释性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "This paper has been accepted by IEEE Transactions on Fuzzy Systems\n  for publication. Permission from IEEE must be obtained for all other uses, in\n  any current or future media. The final version is available at [doi:\n  10.1109/TFUZZ.2024.3410929]",
      "pdf_url": "http://arxiv.org/pdf/2407.15312v1",
      "published_date": "2024-07-22 00:46:15 UTC",
      "updated_date": "2024-07-22 00:46:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T09:07:54.460283"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 110,
  "processed_papers_count": 110,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-19T09:08:17.508644"
}