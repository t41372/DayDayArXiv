{
  "date": "2024-05-05",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-05-05 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于人工智能（AI）和机器学习领域，包括大型语言模型（LLM）的优化、强化学习（RL）的创新应用、医疗AI的进展，以及多模态生成技术，其中 RICE 的强化学习解释框架、Self-Reflection in LLM Agents 的自省机制，以及 Agent Hospital 的医疗模拟系统特别令人印象深刻，同时涉及知名会议如 ICML 2024 和 EMNLP 2024 的接受论文。\n\n下面，我将挑选并简要讨论部分关键论文，先优先聊那些创新性强、可能引发话题的文章（如涉及 LLM 和 RL 的），并将相关主题归类。其他较常规或小众论文（如某些优化算法或特定领域实验）将快速掠过，以控制篇幅。\n\n### AI 和 LLM 相关论文\n1. **Self-Reflection in LLM Agents: Effects on Problem-Solving Performance（LLM 代理的自省：对问题解决性能的影响）**  \n   作者：Matthew Renze, Erhan Guven。这篇论文探索了 LLM 通过自省机制（如反思错误并提供指导）来提升问题解决能力的实验，结果显示自省显著提高了性能（p < 0.001）。主要贡献：证明了 LLM 的自省能有效优化多选题回答，为 LLM 在实际应用中的鲁棒性提供新视角。\n\n2. **Agent Hospital: A Simulacrum of Hospital with Evolvable Medical Agents（代理医院：一个可演化的医疗代理模拟系统）**  \n   作者：Junkai Li 等。这篇论文构建了一个全 LLM 驱动的医院模拟环境，让医生代理通过处理数万患者案例演化。关键发现：演化后的代理在 MedQA 基准上超越了现有方法，准确率高达 88.52% 在 “What-if” 场景，展示了 LLM 在医疗 AI 中的潜力，为自动医疗决策提供新框架。\n\n3. **MedAdapter: Efficient Test-Time Adaptation of Large Language Models towards Medical Reasoning（MedAdapter：针对医疗推理的 LLM 高效测试时适应）**  \n   作者：Wenqi Shi 等（EMNLP 2024 接受）。论文提出 MedAdapter，通过微调小规模适配器提升 LLM 在生物医疗任务的性能。贡献：在不需大量资源下，提高了白盒和黑盒 LLM 的表现，平均提升 25.48%，为隐私保护的医疗 AI 应用提供了实用方案。\n\n4. **Exploring the Compositional Deficiency of Large Language Models in Mathematical Reasoning（探索大型语言模型在数学推理中的组合缺陷）**  \n   作者：Jun Zhao 等（EMNLP 2024 接受）。论文使用 MathTrap 数据集测试 LLM 在数学推理的组合能力，发现 LLM 虽有相关知识，但无法自发组合。贡献：通过提示和微调方法缓解缺陷，并测试了 OpenAI o1 模型，强调了 LLM 在复杂推理中的局限性。\n\n5. **Parameter-Efficient Fine-Tuning with Discrete Fourier Transform（基于离散傅立叶变换的参数高效微调）**  \n   作者：Ziqi Gao 等（ICML 2024 接受）。论文提出 FourierFT 方法，通过傅立叶变换压缩微调参数。发现：在 LLaMA2-7B 上，仅用 0.064M 参数就超越 LoRA 的 33.5M。贡献：为 LLM 微调提供高效策略，适用于自然语言和图像任务。\n\n其他 LLM 相关论文如 Sentiment Analysis Across Languages（跨语言情感分析）和 Revisiting a Pain in the Neck（语义短语处理基准）等，快速提一下：它们评估了 LLM 在多语言情感分析和短语理解上的性能，但未有突破性创新。\n\n### 强化学习和机器人相关论文\n6. **RICE: Breaking Through the Training Bottlenecks of Reinforcement Learning with Explanation（RICE：通过解释方法突破强化学习训练瓶颈）**  \n   作者：Zelei Cheng 等（ICML 2024 接受）。这篇令人印象深刻的论文提出 RICE 框架，使用解释方法构建混合初始状态分布。贡献：理论上保证了更紧的次优性边界，并在多种 RL 环境（如 Atari）中提升性能，是 RL 领域的重要进展。\n\n7. **ClothPPO: A Proximal Policy Optimization Enhancing Framework for Robotic Cloth Manipulation（ClothPPO：针对机器人布料操作的 PPO 增强框架）**  \n   作者：Libing Yang 等。论文将布料操作建模为部分可观测马尔科夫决策过程，使用 PPO 指导策略。发现：提升了软体操作任务的性能。贡献：为机器人操作提供新框架，结合监督预训练和 PPO。\n\n8. **CoverLib: Classifiers-equipped Experience Library by Iterative Problem Distribution Coverage Maximization for Domain-tuned Motion Planning（CoverLib：通过迭代问题分布覆盖最大化的分类器增强经验库，用于领域调整的运动规划）**  \n   作者：Hirokazu Ishida 等（IEEE Transactions on Robotics 接受）。论文构建了一个迭代经验库，用于运动规划。贡献：平衡了规划速度和成功率，适用于各种适应算法。\n\n其他 RL 论文如 Safe Reinforcement Learning（安全强化学习）和 Multi-Agent RL-Based Industrial AIGC Service Offloading（多代理 RL 在工业 AIGC 中的应用）等，快速掠过：它们优化了安全约束和任务卸载，但未超出预期。\n\n### 医疗和视觉相关论文\n9. **AC-MAMBASEG: An adaptive convolution and Mamba-based architecture for enhanced skin lesion segmentation（AC-MAMBASEG：基于自适应卷积和 Mamba 的皮肤病变分割架构）**  \n   作者：Viet-Thanh Nguyen 等。论文提出 AC-MAMBASEG 模型，结合 CNN 和 Mamba 框架提升皮肤病变分割。发现：在 ISIC-2018 数据集上表现优异。贡献：为计算机辅助诊断提供高效工具。\n\n10. **Region-specific Risk Quantification for Interpretable Prognosis of COVID-19（基于区域风险量化的可解释 COVID-19 预后预测）**  \n   作者：Zhusi Zhong 等。论文使用深度生存模型和 Grad-CAM 分析 COVID-19 X 射线图像。贡献：实现了区域级风险定位，提升了预后预测的准确性和可解释性（C-index 达 0.764）。\n\n其他医疗论文如 High Order Reasoning for Time Critical Recommendation（高阶推理在紧急医疗推荐中）和 RepAugment（呼吸音分类增强）等，快速提一下：它们改善了医疗决策和音频分类，但应用较为特定。\n\n### 其他快速掠过\n剩余论文如 On Probabilistic and Causal Reasoning（概率和因果推理）、Visual Grounding for Desktop GUIs（桌面 GUI 视觉 grounding）、和 Mozart's Touch（多模态音乐生成）等，涉及因果推理、GUI 识别和音乐 AI，但由于篇幅有限，仅提要：Mozart's Touch 通过 LLM 生成与视觉对齐的音乐，展示了多模态潜力；其他论文在各自领域有技术贡献，但未有广泛影响。\n\n总之，今天的 arXiv 论文突显了 AI 领域的活力，尤其在 LLM 和 RL 的交叉应用上。感兴趣的读者可关注上述关键论文，探索更多创新点！（本快报基于 38 篇论文精选，保持简洁以便快速阅读。）",
  "papers": [
    {
      "arxiv_id": "2405.03069v2",
      "title": "On Probabilistic and Causal Reasoning with Summation Operators",
      "title_zh": "翻译失败",
      "authors": [
        "Duligur Ibeling",
        "Thomas F. Icard",
        "Milan Mossé"
      ],
      "abstract": "Ibeling et al. (2023). axiomatize increasingly expressive languages of\ncausation and probability, and Mosse et al. (2024) show that reasoning\n(specifically the satisfiability problem) in each causal language is as\ndifficult, from a computational complexity perspective, as reasoning in its\nmerely probabilistic or \"correlational\" counterpart. Introducing a summation\noperator to capture common devices that appear in applications -- such as the\n$do$-calculus of Pearl (2009) for causal inference, which makes ample use of\nmarginalization -- van der Zander et al. (2023) partially extend these earlier\ncomplexity results to causal and probabilistic languages with marginalization.\nWe complete this extension, fully characterizing the complexity of\nprobabilistic and causal reasoning with summation, demonstrating that these\nagain remain equally difficult. Surprisingly, allowing free variables for\nrandom variable values results in a system that is undecidable, so long as the\nranges of these random variables are unrestricted. We finally axiomatize these\nlanguages featuring marginalization (or more generally summation), resolving\nopen questions posed by Ibeling et al. (2023).",
      "tldr_zh": "这篇论文探讨了带有 summation operators 的概率和因果推理的复杂性，扩展了 Ibeling et al. (2023) 和 Mosse et al. (2024) 的研究成果。作者全面表征了这些语言的 satisfiability problem，证明其推理难度与纯概率或相关性推理相当，同时引入 summation operator（如 do-calculus 中的 marginalization）来处理实际应用中的变量边缘化。令人惊讶的是，允许自由变量（free variables）用于随机变量值时，系统变得 undecidable，前提是变量范围不受限制；最终，论文对这些语言进行了公理化，解决了相关领域的开放问题。",
      "categories": [
        "math.LO",
        "cs.AI",
        "cs.CC",
        "cs.LO"
      ],
      "primary_category": "math.LO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.03069v2",
      "published_date": "2024-05-05 22:32:01 UTC",
      "updated_date": "2024-05-18 20:14:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:04:31.134020"
    },
    {
      "arxiv_id": "2405.03064v3",
      "title": "RICE: Breaking Through the Training Bottlenecks of Reinforcement Learning with Explanation",
      "title_zh": "RICE：通过解释突破强化学习训练瓶颈",
      "authors": [
        "Zelei Cheng",
        "Xian Wu",
        "Jiahao Yu",
        "Sabrina Yang",
        "Gang Wang",
        "Xinyu Xing"
      ],
      "abstract": "Deep reinforcement learning (DRL) is playing an increasingly important role\nin real-world applications. However, obtaining an optimally performing DRL\nagent for complex tasks, especially with sparse rewards, remains a significant\nchallenge. The training of a DRL agent can be often trapped in a bottleneck\nwithout further progress. In this paper, we propose RICE, an innovative\nrefining scheme for reinforcement learning that incorporates explanation\nmethods to break through the training bottlenecks. The high-level idea of RICE\nis to construct a new initial state distribution that combines both the default\ninitial states and critical states identified through explanation methods,\nthereby encouraging the agent to explore from the mixed initial states. Through\ncareful design, we can theoretically guarantee that our refining scheme has a\ntighter sub-optimality bound. We evaluate RICE in various popular RL\nenvironments and real-world applications. The results demonstrate that RICE\nsignificantly outperforms existing refining schemes in enhancing agent\nperformance.",
      "tldr_zh": "该论文针对深度强化学习（DRL）在复杂任务中的训练瓶颈问题，尤其是稀疏奖励场景，提出了一种创新方案RICE，该方案通过整合解释方法来识别关键状态，并构建一个结合默认初始状态和这些关键状态的混合初始状态分布，以鼓励代理从多样化起点探索。RICE的设计理论上保证了更紧的次优性边界，从而提升了训练效率。在各种流行RL环境和真实应用中，实验结果表明RICE显著超过了现有精炼方案，提高了代理的整体性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.03064v3",
      "published_date": "2024-05-05 22:06:42 UTC",
      "updated_date": "2024-06-06 00:36:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:04:42.055739"
    },
    {
      "arxiv_id": "2407.01558v2",
      "title": "Visual grounding for desktop graphical user interfaces",
      "title_zh": "桌面图形用户界面的视觉 grounding",
      "authors": [
        "Tassnim Dardouri",
        "Laura Minkova",
        "Jessica López Espejel",
        "Walid Dahhane",
        "El Hassane Ettifouri"
      ],
      "abstract": "Most instance perception and image understanding solutions focus mainly on\nnatural images. However, applications for synthetic images, and more\nspecifically, images of Graphical User Interfaces (GUI) remain limited. This\nhinders the development of autonomous computer-vision-powered Artificial\nIntelligence (AI) agents. In this work, we present Instruction Visual Grounding\nor IVG, a multi-modal solution for object identification in a GUI. More\nprecisely, given a natural language instruction and GUI screen, IVG locates the\ncoordinates of the element on the screen where the instruction would be\nexecuted. To this end, we develop two methods. The first method is a three-part\narchitecture that relies on a combination of a Large Language Model (LLM) and\nan object detection model. The second approach uses a multi-modal foundation\nmodel.",
      "tldr_zh": "本研究针对图形用户界面 (GUI) 的图像理解问题，提出了一种名为 Instruction Visual Grounding (IVG) 的多模态解决方案，用于根据自然语言指令在 GUI 屏幕上定位元素坐标，从而支持自主计算机视觉驱动的 AI 代理。\nIVG 包括两种方法：第一种采用三部分架构，结合 Large Language Model (LLM) 和对象检测模型；第二种基于多模态基础模型。\n这项创新有助于扩展图像理解技术从自然图像向合成图像领域的应用。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Preprint submitted to Computer Vision and Image Understanding journal",
      "pdf_url": "http://arxiv.org/pdf/2407.01558v2",
      "published_date": "2024-05-05 19:10:19 UTC",
      "updated_date": "2024-09-17 10:15:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:04:55.067970"
    },
    {
      "arxiv_id": "2405.06682v3",
      "title": "Self-Reflection in LLM Agents: Effects on Problem-Solving Performance",
      "title_zh": "LLM 代理中的自我反思：对问题解决性能的影响",
      "authors": [
        "Matthew Renze",
        "Erhan Guven"
      ],
      "abstract": "In this study, we investigated the effects of self-reflection in large\nlanguage models (LLMs) on problem-solving performance. We instructed nine\npopular LLMs to answer a series of multiple-choice questions to provide a\nperformance baseline. For each incorrectly answered question, we instructed\neight types of self-reflecting LLM agents to reflect on their mistakes and\nprovide themselves with guidance to improve problem-solving. Then, using this\nguidance, each self-reflecting agent attempted to re-answer the same questions.\nOur results indicate that LLM agents are able to significantly improve their\nproblem-solving performance through self-reflection ($p < 0.001$). In addition,\nwe compared the various types of self-reflection to determine their individual\ncontribution to performance. All code and data are available on GitHub at\nhttps://github.com/matthewrenze/self-reflection",
      "tldr_zh": "这篇论文研究了大型语言模型(LLMs)中的自反省(self-reflection)对问题解决性能的影响。研究者首先让九个流行LLMs回答多选题以建立基准，然后针对错误答案，让八种类型的自反省代理反思错误并提供改进指导，再使用这些指导重新回答问题。结果显示，通过自反省，LLMs的性能显著提升(p < 0.001)，并比较了不同自反省类型的贡献，所有代码和数据已在GitHub上公开。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.06682v3",
      "published_date": "2024-05-05 18:56:46 UTC",
      "updated_date": "2024-10-16 23:19:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:05:04.632178"
    },
    {
      "arxiv_id": "2405.04550v1",
      "title": "Exploring a Cognitive Architecture for Learning Arithmetic Equations",
      "title_zh": "探索算术方程学习的认知架构",
      "authors": [
        "Cole Gawin"
      ],
      "abstract": "The acquisition and performance of arithmetic skills and basic operations\nsuch as addition, subtraction, multiplication, and division are essential for\ndaily functioning, and reflect complex cognitive processes. This paper explores\nthe cognitive mechanisms powering arithmetic learning, presenting a\nneurobiologically plausible cognitive architecture that simulates the\nacquisition of these skills. I implement a number vectorization embedding\nnetwork and an associative memory model to investigate how an intelligent\nsystem can learn and recall arithmetic equations in a manner analogous to the\nhuman brain. I perform experiments that provide insights into the\ngeneralization capabilities of connectionist models, neurological causes of\ndyscalculia, and the influence of network architecture on cognitive\nperformance. Through this interdisciplinary investigation, I aim to contribute\nto ongoing research into the neural correlates of mathematical cognition in\nintelligent systems.",
      "tldr_zh": "本论文探讨了算术技能（如加、减、乘、除）的认知机制，并提出一个神经生物学上合理的cognitive architecture，以模拟人类大脑的学习过程。作者实现了number vectorization embedding network和associative memory model，允许智能系统类似于人类方式学习和回忆算术方程。实验结果揭示了连接主义模型的泛化能力、dyscalculia的神经原因，以及网络架构对认知表现的影响，为智能系统中数学认知的神经相关研究提供新见解。",
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ],
      "primary_category": "q-bio.NC",
      "comment": "16 pages, 6 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2405.04550v1",
      "published_date": "2024-05-05 18:42:00 UTC",
      "updated_date": "2024-05-05 18:42:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:05:17.112097"
    },
    {
      "arxiv_id": "2405.06681v1",
      "title": "Leveraging Lecture Content for Improved Feedback: Explorations with GPT-4 and Retrieval Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Sven Jacobs",
        "Steffen Jaschke"
      ],
      "abstract": "This paper presents the use of Retrieval Augmented Generation (RAG) to\nimprove the feedback generated by Large Language Models for programming tasks.\nFor this purpose, corresponding lecture recordings were transcribed and made\navailable to the Large Language Model GPT-4 as external knowledge source\ntogether with timestamps as metainformation by using RAG. The purpose of this\nis to prevent hallucinations and to enforce the use of the technical terms and\nphrases from the lecture. In an exercise platform developed to solve\nprogramming problems for an introductory programming lecture, students can\nrequest feedback on their solutions generated by GPT-4. For this task GPT-4\nreceives the students' code solution, the compiler output, the result of unit\ntests and the relevant passages from the lecture notes available through the\nuse of RAG as additional context. The feedback generated by GPT-4 should guide\nstudents to solve problems independently and link to the lecture content, using\nthe time stamps of the transcript as meta-information. In this way, the\ncorresponding lecture videos can be viewed immediately at the corresponding\npositions. For the evaluation, students worked with the tool in a workshop and\ndecided for each feedback whether it should be extended by RAG or not. First\nresults based on a questionnaire and the collected usage data show that the use\nof RAG can improve feedback generation and is preferred by students in some\nsituations. Due to the slower speed of feedback generation, the benefits are\nsituation dependent.",
      "tldr_zh": "本论文探讨了利用 Retrieval Augmented Generation (RAG) 提升 GPT-4 在编程任务反馈生成中的表现，通过将讲座录像转录（包括时间戳）作为外部知识源，以防止幻觉并强化讲座中的技术术语。在编程练习平台上，GPT-4 结合学生的代码、编译输出、单元测试结果和相关讲座内容，提供指导性反馈并链接到具体讲座视频位置。实验结果显示，学生在工作坊评估中偏好 RAG 增强的反馈，认为其在某些情境下提高了反馈质量，但由于生成速度较慢，实际益处取决于具体情况。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "accepted at CSEE&T 2024: 36th International Conference on Software\n  Engineering Education and Training, W\\\"urzburg, Germany",
      "pdf_url": "http://arxiv.org/pdf/2405.06681v1",
      "published_date": "2024-05-05 18:32:06 UTC",
      "updated_date": "2024-05-05 18:32:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:05:30.211104"
    },
    {
      "arxiv_id": "2405.03011v1",
      "title": "AC-MAMBASEG: An adaptive convolution and Mamba-based architecture for enhanced skin lesion segmentation",
      "title_zh": "AC-MAMBASEG：基于自适应卷积和 Mamba 的架构，用于增强皮肤病变分割",
      "authors": [
        "Viet-Thanh Nguyen",
        "Van-Truong Pham",
        "Thi-Thao Tran"
      ],
      "abstract": "Skin lesion segmentation is a critical task in computer-aided diagnosis\nsystems for dermatological diseases. Accurate segmentation of skin lesions from\nmedical images is essential for early detection, diagnosis, and treatment\nplanning. In this paper, we propose a new model for skin lesion segmentation\nnamely AC-MambaSeg, an enhanced model that has the hybrid CNN-Mamba backbone,\nand integrates advanced components such as Convolutional Block Attention Module\n(CBAM), Attention Gate, and Selective Kernel Bottleneck. AC-MambaSeg leverages\nthe Vision Mamba framework for efficient feature extraction, while CBAM and\nSelective Kernel Bottleneck enhance its ability to focus on informative regions\nand suppress background noise. We evaluate the performance of AC-MambaSeg on\ndiverse datasets of skin lesion images including ISIC-2018 and PH2; then\ncompare it against existing segmentation methods. Our model shows promising\npotential for improving computer-aided diagnosis systems and facilitating early\ndetection and treatment of dermatological diseases. Our source code will be\nmade available at: https://github.com/vietthanh2710/AC-MambaSeg.",
      "tldr_zh": "本研究提出了一种名为 AC-MambaSeg 的新模型，用于增强皮肤病变分割，以支持皮肤病诊断系统的早期检测和治疗规划。该模型采用混合 CNN-Mamba 骨干网络，并整合 Convolutional Block Attention Module (CBAM)、Attention Gate 和 Selective Kernel Bottleneck 等组件，利用 Vision Mamba 框架进行高效特征提取，同时提升对关键区域的关注并抑制背景噪声。在 ISIC-2018 和 PH2 数据集上的实验表明，AC-MambaSeg 比现有分割方法表现出色，具有改善计算机辅助诊断系统的潜力。模型源代码可公开获取于 GitHub。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages, 7 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2405.03011v1",
      "published_date": "2024-05-05 17:37:50 UTC",
      "updated_date": "2024-05-05 17:37:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:05:40.468599"
    },
    {
      "arxiv_id": "2405.03010v1",
      "title": "High Order Reasoning for Time Critical Recommendation in Evidence-based Medicine",
      "title_zh": "翻译失败",
      "authors": [
        "Manjiang Yu",
        "Xue Li"
      ],
      "abstract": "In time-critical decisions, human decision-makers can interact with\nAI-enabled situation-aware software to evaluate many imminent and possible\nscenarios, retrieve billions of facts, and estimate different outcomes based on\ntrillions of parameters in a fraction of a second. In high-order reasoning,\n\"what-if\" questions can be used to challenge the assumptions or pre-conditions\nof the reasoning, \"why-not\" questions can be used to challenge on the method\napplied in the reasoning, \"so-what\" questions can be used to challenge the\npurpose of the decision, and \"how-about\" questions can be used to challenge the\napplicability of the method. When above high-order reasoning questions are\napplied to assist human decision-making, it can help humans to make\ntime-critical decisions and avoid false-negative or false-positive types of\nerrors. In this paper, we present a model of high-order reasoning to offer\nrecommendations in evidence-based medicine in a time-critical fashion for the\napplications in ICU. The Large Language Model (LLM) is used in our system. The\nexperiments demonstrated the LLM exhibited optimal performance in the \"What-if\"\nscenario, achieving a similarity of 88.52% with the treatment plans of human\ndoctors. In the \"Why-not\" scenario, the best-performing model tended to opt for\nalternative treatment plans in 70% of cases for patients who died after being\ndischarged from the ICU. In the \"So-what\" scenario, the optimal model provided\na detailed analysis of the motivation and significance of treatment plans for\nICU patients, with its reasoning achieving a similarity of 55.6% with actual\ndiagnostic information. In the \"How-about\" scenario, the top-performing LLM\ndemonstrated a content similarity of 66.5% in designing treatment plans\ntransferring for similar diseases. Meanwhile, LLMs managed to predict the life\nstatus of patients after their discharge from the ICU with an accuracy of 70%.",
      "tldr_zh": "该论文提出了一种高阶推理模型，用于证据-based 医学中时间紧迫的推荐决策，通过 \"what-if\"、\"why-not\"、\"so-what\" 和 \"how-about\" 问题来挑战假设、方法、目的和适用性，从而辅助人类避免错误决策。模型利用 Large Language Model (LLM) 在 ICU 场景中进行高阶推理实验，结果显示 LLM 在 \"What-if\" 场景下与人类医生治疗方案相似度达 88.52%，在 \"Why-not\" 场景下有 70% 的病例选择替代方案，并在患者生命状态预测上达到 70% 准确率。在 \"So-what\" 和 \"How-about\" 场景中，LLM 分别实现了 55.6% 和 66.5% 的内容相似度，为时间紧迫医疗决策提供了可靠支持。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages, 15 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.03010v1",
      "published_date": "2024-05-05 17:36:22 UTC",
      "updated_date": "2024-05-05 17:36:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:05:53.564772"
    },
    {
      "arxiv_id": "2405.03009v1",
      "title": "Explainable Malware Detection with Tailored Logic Explained Networks",
      "title_zh": "可解释恶意软件检测：基于定制逻辑解释网络",
      "authors": [
        "Peter Anthony",
        "Francesco Giannini",
        "Michelangelo Diligenti",
        "Martin Homola",
        "Marco Gori",
        "Stefan Balogh",
        "Jan Mojzis"
      ],
      "abstract": "Malware detection is a constant challenge in cybersecurity due to the rapid\ndevelopment of new attack techniques. Traditional signature-based approaches\nstruggle to keep pace with the sheer volume of malware samples. Machine\nlearning offers a promising solution, but faces issues of generalization to\nunseen samples and a lack of explanation for the instances identified as\nmalware. However, human-understandable explanations are especially important in\nsecurity-critical fields, where understanding model decisions is crucial for\ntrust and legal compliance. While deep learning models excel at malware\ndetection, their black-box nature hinders explainability. Conversely,\ninterpretable models often fall short in performance. To bridge this gap in\nthis application domain, we propose the use of Logic Explained Networks (LENs),\nwhich are a recently proposed class of interpretable neural networks providing\nexplanations in the form of First-Order Logic (FOL) rules. This paper extends\nthe application of LENs to the complex domain of malware detection,\nspecifically using the large-scale EMBER dataset. In the experimental results\nwe show that LENs achieve robustness that exceeds traditional interpretable\nmethods and that are rivaling black-box models. Moreover, we introduce a\ntailored version of LENs that is shown to generate logic explanations with\nhigher fidelity with respect to the model's predictions.",
      "tldr_zh": "这篇论文针对恶意软件检测面临的挑战，如传统方法跟不上新攻击技巧和机器学习模型的泛化及解释性不足，提出使用 Logic Explained Networks (LENs) 作为可解释神经网络，提供 First-Order Logic (FOL) 规则的解释。作者扩展 LENs 到大规模 EMBER 数据集，实验结果显示其性能超越传统可解释方法，并与黑箱模型相媲美。进一步，他们引入定制版本的 LENs，提升了逻辑解释的保真度，从而提高模型决策的可信度和实际应用价值。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.03009v1",
      "published_date": "2024-05-05 17:36:02 UTC",
      "updated_date": "2024-05-05 17:36:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:06:05.275758"
    },
    {
      "arxiv_id": "2405.03007v1",
      "title": "On the performativity of SDG classifications in large bibliometric databases",
      "title_zh": "关于大型文献计量数据库中 SDG 分类的可执行性",
      "authors": [
        "Matteo Ottaviani",
        "Stephan Stahlschmidt"
      ],
      "abstract": "Large bibliometric databases, such as Web of Science, Scopus, and OpenAlex,\nfacilitate bibliometric analyses, but are performative, affecting the\nvisibility of scientific outputs and the impact measurement of participating\nentities. Recently, these databases have taken up the UN's Sustainable\nDevelopment Goals (SDGs) in their respective classifications, which have been\ncriticised for their diverging nature. This work proposes using the feature of\nlarge language models (LLMs) to learn about the \"data bias\" injected by diverse\nSDG classifications into bibliometric data by exploring five SDGs. We build a\nLLM that is fine-tuned in parallel by the diverse SDG classifications inscribed\ninto the databases' SDG classifications. Our results show high sensitivity in\nmodel architecture, classified publications, fine-tuning process, and natural\nlanguage generation. The wide arbitrariness at different levels raises concerns\nabout using LLM in research practice.",
      "tldr_zh": "该研究探讨了大型文献计量数据库（如Web of Science、Scopus和OpenAlex）中Sustainable Development Goals (SDGs)分类的“performativity”，即这些分类如何影响科学产出的可见性和影响测量。作者提出使用Large Language Models (LLMs)来分析由多样SDG分类注入的“data bias”，通过构建并并行微调LLM模型来探索五种SDGs。结果显示，模型在架构、分类出版物、微调过程和自然语言生成方面高度敏感，这种广泛的任意性引发了对LLMs在研究实践中的可靠性和应用价值的担忧。",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.DL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.03007v1",
      "published_date": "2024-05-05 17:28:54 UTC",
      "updated_date": "2024-05-05 17:28:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:06:16.616742"
    },
    {
      "arxiv_id": "2405.03005v1",
      "title": "Safe Reinforcement Learning with Learned Non-Markovian Safety Constraints",
      "title_zh": "安全强化学习中基于学习得到的非Markov安全约束",
      "authors": [
        "Siow Meng Low",
        "Akshat Kumar"
      ],
      "abstract": "In safe Reinforcement Learning (RL), safety cost is typically defined as a\nfunction dependent on the immediate state and actions. In practice, safety\nconstraints can often be non-Markovian due to the insufficient fidelity of\nstate representation, and safety cost may not be known. We therefore address a\ngeneral setting where safety labels (e.g., safe or unsafe) are associated with\nstate-action trajectories. Our key contributions are: first, we design a safety\nmodel that specifically performs credit assignment to assess contributions of\npartial state-action trajectories on safety. This safety model is trained using\na labeled safety dataset. Second, using RL-as-inference strategy we derive an\neffective algorithm for optimizing a safe policy using the learned safety\nmodel. Finally, we devise a method to dynamically adapt the tradeoff\ncoefficient between reward maximization and safety compliance. We rewrite the\nconstrained optimization problem into its dual problem and derive a\ngradient-based method to dynamically adjust the tradeoff coefficient during\ntraining. Our empirical results demonstrate that this approach is highly\nscalable and able to satisfy sophisticated non-Markovian safety constraints.",
      "tldr_zh": "该论文探讨了安全强化学习（Safe Reinforcement Learning），其中安全约束往往是非马尔可夫的（Non-Markovian）且未知，提出了一种基于轨迹安全标签的方法来处理这一问题。主要贡献包括设计一个安全模型，通过信用分配（credit assignment）评估部分状态-动作轨迹对安全的贡献，并使用标记数据集进行训练；其次，利用 RL-as-inference 策略优化安全策略；最后，开发了一种动态调整权衡系数的方法，将约束优化问题转化为对偶问题，并通过梯度方法在训练中适应奖励最大化和安全合规性的 tradeoff。实验结果表明，该方法具有高扩展性，并能有效满足复杂的非马尔可夫安全约束。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.03005v1",
      "published_date": "2024-05-05 17:27:22 UTC",
      "updated_date": "2024-05-05 17:27:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:06:29.519758"
    },
    {
      "arxiv_id": "2405.03003v1",
      "title": "Parameter-Efficient Fine-Tuning with Discrete Fourier Transform",
      "title_zh": "翻译失败",
      "authors": [
        "Ziqi Gao",
        "Qichao Wang",
        "Aochuan Chen",
        "Zijing Liu",
        "Bingzhe Wu",
        "Liang Chen",
        "Jia Li"
      ],
      "abstract": "Low-rank adaptation~(LoRA) has recently gained much interest in fine-tuning\nfoundation models. It effectively reduces the number of trainable parameters by\nincorporating low-rank matrices $A$ and $B$ to represent the weight change,\ni.e., $\\Delta W=BA$. Despite LoRA's progress, it faces storage challenges when\nhandling extensive customization adaptations or larger base models. In this\nwork, we aim to further compress trainable parameters by enjoying the powerful\nexpressiveness of the Fourier transform. Specifically, we introduce FourierFT,\nwhich treats $\\Delta W$ as a matrix in the spatial domain and learns only a\nsmall fraction of its spectral coefficients. With the trained spectral\ncoefficients, we implement the inverse discrete Fourier transform to recover\n$\\Delta W$. Empirically, our FourierFT method shows comparable or better\nperformance with fewer parameters than LoRA on various tasks, including natural\nlanguage understanding, natural language generation, instruction tuning, and\nimage classification. For example, when performing instruction tuning on the\nLLaMA2-7B model, FourierFT surpasses LoRA with only 0.064M trainable\nparameters, compared to LoRA's 33.5M. Our code is released at\n\\url{https://github.com/Chaos96/fourierft}.",
      "tldr_zh": "本文提出FourierFT方法，利用Discrete Fourier Transform来进一步压缩参数，解决LoRA（Low-rank adaptation）在存储和定制适应方面的挑战。具体而言，FourierFT将权重变化ΔW视为空间域矩阵，仅学习其光谱系数的一小部分，然后通过逆离散傅立叶变换恢复ΔW。实验结果显示，在自然语言理解、生成、指令微调和图像分类任务上，FourierFT与LoRA相比表现出色或相当，且参数显著减少，例如在LLaMA2-7B模型的指令微调中，仅需0.064M参数而非LoRA的33.5M。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.03003v1",
      "published_date": "2024-05-05 17:15:24 UTC",
      "updated_date": "2024-05-05 17:15:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:06:41.685366"
    },
    {
      "arxiv_id": "2405.03000v2",
      "title": "MedAdapter: Efficient Test-Time Adaptation of Large Language Models towards Medical Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Wenqi Shi",
        "Ran Xu",
        "Yuchen Zhuang",
        "Yue Yu",
        "Haotian Sun",
        "Hang Wu",
        "Carl Yang",
        "May D. Wang"
      ],
      "abstract": "Despite their improved capabilities in generation and reasoning, adapting\nlarge language models (LLMs) to the biomedical domain remains challenging due\nto their immense size and corporate privacy. In this work, we propose\nMedAdapter, a unified post-hoc adapter for test-time adaptation of LLMs towards\nbiomedical applications. Instead of fine-tuning the entire LLM, MedAdapter\neffectively adapts the original model by fine-tuning only a small BERT-sized\nadapter to rank candidate solutions generated by LLMs. Experiments demonstrate\nthat MedAdapter effectively adapts both white-box and black-box LLMs in\nbiomedical reasoning, achieving average performance improvements of 25.48% and\n11.31%, respectively, without requiring extensive computational resources or\nsharing data with third parties. MedAdapter also yields superior performance\nwhen combined with train-time adaptation, highlighting a flexible and\ncomplementary solution to existing adaptation methods. Faced with the\nchallenges of balancing model performance, computational resources, and data\nprivacy, MedAdapter provides an efficient, privacy-preserving, cost-effective,\nand transparent solution for adapting LLMs to the biomedical domain.",
      "tldr_zh": "本研究提出 MedAdapter，一种高效的测试时适应 (Test-Time Adaptation) 框架，用于将大型语言模型 (LLMs) 适应到生物医学推理领域，而无需处理模型的庞大尺寸和隐私问题。MedAdapter 通过仅微调一个小型 BERT-sized adapter 来对 LLMs 生成的候选解决方案进行排名，从而避免了全面微调的需求。实验结果显示，该框架在生物医学推理任务上，使白盒 LLMs 的平均性能提升 25.48%，黑盒 LLMs 提升 11.31%，且不需大量计算资源或数据共享。与训练时适应方法结合时，MedAdapter 表现出色，提供了一个灵活、隐私保护且成本有效的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted in EMNLP 2024 main conference",
      "pdf_url": "http://arxiv.org/pdf/2405.03000v2",
      "published_date": "2024-05-05 17:06:31 UTC",
      "updated_date": "2024-10-04 06:31:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:06:53.124823"
    },
    {
      "arxiv_id": "2405.02996v1",
      "title": "RepAugment: Input-Agnostic Representation-Level Augmentation for Respiratory Sound Classification",
      "title_zh": "翻译失败",
      "authors": [
        "June-Woo Kim",
        "Miika Toikkanen",
        "Sangmin Bae",
        "Minseok Kim",
        "Ho-Young Jung"
      ],
      "abstract": "Recent advancements in AI have democratized its deployment as a healthcare\nassistant. While pretrained models from large-scale visual and audio datasets\nhave demonstrably generalized to this task, surprisingly, no studies have\nexplored pretrained speech models, which, as human-originated sounds,\nintuitively would share closer resemblance to lung sounds. This paper explores\nthe efficacy of pretrained speech models for respiratory sound classification.\nWe find that there is a characterization gap between speech and lung sound\nsamples, and to bridge this gap, data augmentation is essential. However, the\nmost widely used augmentation technique for audio and speech, SpecAugment,\nrequires 2-dimensional spectrogram format and cannot be applied to models\npretrained on speech waveforms. To address this, we propose RepAugment, an\ninput-agnostic representation-level augmentation technique that outperforms\nSpecAugment, but is also suitable for respiratory sound classification with\nwaveform pretrained models. Experimental results show that our approach\noutperforms the SpecAugment, demonstrating a substantial improvement in the\naccuracy of minority disease classes, reaching up to 7.14%.",
      "tldr_zh": "这篇论文探讨了使用预训练语音模型进行呼吸音分类（respiratory sound classification）的有效性，发现语音和肺音样本之间存在特征差距，因此数据增强至关重要。作者提出RepAugment，一种输入无关的表示级别增强技术（representation-level augmentation），它能超越传统的SpecAugment，同时适用于基于波形预训练的模型。实验结果表明，RepAugment显著提升了分类准确率，尤其在少数疾病类别上提高了多达7.14%。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted EMBC 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.02996v1",
      "published_date": "2024-05-05 16:45:46 UTC",
      "updated_date": "2024-05-05 16:45:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:07:04.515025"
    },
    {
      "arxiv_id": "2405.03718v2",
      "title": "A Single Online Agent Can Efficiently Learn Mean Field Games",
      "title_zh": "一个单一的在线代理能够高效学习平均场游戏",
      "authors": [
        "Chenyu Zhang",
        "Xu Chen",
        "Xuan Di"
      ],
      "abstract": "Mean field games (MFGs) are a promising framework for modeling the behavior\nof large-population systems. However, solving MFGs can be challenging due to\nthe coupling of forward population evolution and backward agent dynamics.\nTypically, obtaining mean field Nash equilibria (MFNE) involves an iterative\napproach where the forward and backward processes are solved alternately, known\nas fixed-point iteration (FPI). This method requires fully observed population\npropagation and agent dynamics over the entire spatial domain, which could be\nimpractical in some real-world scenarios. To overcome this limitation, this\npaper introduces a novel online single-agent model-free learning scheme, which\nenables a single agent to learn MFNE using online samples, without prior\nknowledge of the state-action space, reward function, or transition dynamics.\nSpecifically, the agent updates its policy through the value function (Q),\nwhile simultaneously evaluating the mean field state (M), using the same batch\nof observations. We develop two variants of this learning scheme: off-policy\nand on-policy QM iteration. We prove that they efficiently approximate FPI, and\na sample complexity guarantee is provided. The efficacy of our methods is\nconfirmed by numerical experiments.",
      "tldr_zh": "本研究针对Mean Field Games (MFGs)中前向人群演化和后向代理动态耦合的挑战，提出了一种新型在线单代理无模型学习方案。该方案允许单个代理使用在线样本学习Mean Field Nash Equilibria (MFNE)，无需事先了解状态-动作空间、奖励函数或转移动态，而是通过价值函数 (Q) 更新策略，同时评估均值场状态 (M)。该方法开发了off-policy和on-policy QM迭代两种变体，并证明它们能高效逼近Fixed-Point Iteration (FPI)，同时提供了样本复杂度保证。通过数值实验验证，该方法在实际场景中显示出显著的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.GT",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "Published as a conference paper at ECAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.03718v2",
      "published_date": "2024-05-05 16:38:04 UTC",
      "updated_date": "2024-07-16 06:03:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:07:17.187649"
    },
    {
      "arxiv_id": "2405.06680v4",
      "title": "Exploring the Compositional Deficiency of Large Language Models in Mathematical Reasoning",
      "title_zh": "探索大语言模型在数学推理中的组合性缺陷",
      "authors": [
        "Jun Zhao",
        "Jingqi Tong",
        "Yurong Mou",
        "Ming Zhang",
        "Qi Zhang",
        "Xuanjing Huang"
      ],
      "abstract": "Human cognition exhibits systematic compositionality, the algebraic ability\nto generate infinite novel combinations from finite learned components, which\nis the key to understanding and reasoning about complex logic. In this work, we\ninvestigate the compositionality of large language models (LLMs) in\nmathematical reasoning. Specifically, we construct a new dataset\n\\textsc{MathTrap} by introducing carefully designed logical traps into the\nproblem descriptions of MATH and GSM8K. Since problems with logical flaws are\nquite rare in the real world, these represent \"unseen\" cases to LLMs. Solving\nthese requires the models to systematically compose (1) the mathematical\nknowledge involved in the original problems with (2) knowledge related to the\nintroduced traps. Our experiments show that while LLMs possess both components\nof requisite knowledge, they do not \\textbf{spontaneously} combine them to\nhandle these novel cases. We explore several methods to mitigate this\ndeficiency, such as natural language prompts, few-shot demonstrations, and\nfine-tuning. Additionally, we test the recently released OpenAI o1 model and\nfind that human-like `slow thinking' helps improve the compositionality of\nLLMs. Overall, systematic compositionality remains an open challenge for large\nlanguage models.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）在数学推理中的组合性缺陷，即模型未能系统地将有限知识组件组合以处理新颖问题。研究者构建了新数据集 MathTrap，通过在 MATH 和 GSM8K 问题中引入逻辑陷阱，测试 LLMs 是否能结合原始数学知识与陷阱相关知识。实验结果显示，尽管 LLMs 拥有所需知识，但它们不会自发组合这些元素来解决这些“未见”案例。作者尝试了自然语言提示、少样本演示和微调等方法，并发现 OpenAI o1 模型的人类式“慢思考”能部分改善组合性；总体上，系统组合性（systematic compositionality）仍是 LLMs 的开放挑战。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.06680v4",
      "published_date": "2024-05-05 16:35:30 UTC",
      "updated_date": "2024-10-10 14:38:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:07:29.972949"
    },
    {
      "arxiv_id": "2405.02985v1",
      "title": "Can Large Language Models Make the Grade? An Empirical Study Evaluating LLMs Ability to Mark Short Answer Questions in K-12 Education",
      "title_zh": "翻译失败",
      "authors": [
        "Owen Henkel",
        "Adam Boxer",
        "Libby Hills",
        "Bill Roberts"
      ],
      "abstract": "This paper presents reports on a series of experiments with a novel dataset\nevaluating how well Large Language Models (LLMs) can mark (i.e. grade) open\ntext responses to short answer questions, Specifically, we explore how well\ndifferent combinations of GPT version and prompt engineering strategies\nperformed at marking real student answers to short answer across different\ndomain areas (Science and History) and grade-levels (spanning ages 5-16) using\na new, never-used-before dataset from Carousel, a quizzing platform. We found\nthat GPT-4, with basic few-shot prompting performed well (Kappa, 0.70) and,\nimportantly, very close to human-level performance (0.75). This research builds\non prior findings that GPT-4 could reliably score short answer reading\ncomprehension questions at a performance-level very close to that of expert\nhuman raters. The proximity to human-level performance, across a variety of\nsubjects and grade levels suggests that LLMs could be a valuable tool for\nsupporting low-stakes formative assessment tasks in K-12 education and has\nimportant implications for real-world education delivery.",
      "tldr_zh": "本研究评估了大语言模型(LLMs)在 K-12 教育中评分短答题的能力，通过一个新数据集测试不同 GPT 版本和提示工程策略在科学和历史领域、5-16 岁年级的真实学生答案上表现。结果显示，GPT-4 使用基本 few-shot 提示的评分表现良好（Kappa 0.70），接近人类水平（0.75），并扩展了先前关于阅读理解题的发现。该研究表明，LLMs 可以作为支持低风险形成性评估的宝贵工具，为 K-12 教育的实际应用提供重要启示。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.02985v1",
      "published_date": "2024-05-05 16:11:06 UTC",
      "updated_date": "2024-05-05 16:11:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:07:42.340802"
    },
    {
      "arxiv_id": "2405.02972v1",
      "title": "Multi-Agent RL-Based Industrial AIGC Service Offloading over Wireless Edge Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Siyuan Li",
        "Xi Lin",
        "Hansong Xu",
        "Kun Hua",
        "Xiaomin Jin",
        "Gaolei Li",
        "Jianhua Li"
      ],
      "abstract": "Currently, the generative model has garnered considerable attention due to\nits application in addressing the challenge of scarcity of abnormal samples in\nthe industrial Internet of Things (IoT). However, challenges persist regarding\nthe edge deployment of generative models and the optimization of joint edge\nAI-generated content (AIGC) tasks. In this paper, we focus on the edge\noptimization of AIGC task execution and propose GMEL, a generative model-driven\nindustrial AIGC collaborative edge learning framework. This framework aims to\nfacilitate efficient few-shot learning by leveraging realistic sample synthesis\nand edge-based optimization capabilities. First, a multi-task AIGC\ncomputational offloading model is presented to ensure the efficient execution\nof heterogeneous AIGC tasks on edge servers. Then, we propose an\nattention-enhanced multi-agent reinforcement learning (AMARL) algorithm aimed\nat refining offloading policies within the IoT system, thereby supporting\ngenerative model-driven edge learning. Finally, our experimental results\ndemonstrate the effectiveness of the proposed algorithm in optimizing the total\nsystem latency of the edge-based AIGC task completion.",
      "tldr_zh": "该研究针对工业物联网(IoT)中生成模型的边缘部署和AIGC任务优化挑战，提出了一种名为GMEL的生成模型驱动的工业AIGC协作边缘学习框架，以实现高效的少样本学习和真实样本合成。框架首先构建了一个多任务AIGC计算卸载模型，确保异构AIGC任务在边缘服务器上高效执行。随后，引入了基于注意力机制的多智能体强化学习(AMARL)算法来优化IoT系统中的卸载策略，支持生成模型驱动的边缘学习。实验结果表明，该算法显著降低了边缘AIGC任务完成的总系统延迟，证明了其在无线边缘网络中的有效性。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.02972v1",
      "published_date": "2024-05-05 15:31:47 UTC",
      "updated_date": "2024-05-05 15:31:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:07:52.644289"
    },
    {
      "arxiv_id": "2405.02968v4",
      "title": "CoverLib: Classifiers-equipped Experience Library by Iterative Problem Distribution Coverage Maximization for Domain-tuned Motion Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Hirokazu Ishida",
        "Naoki Hiraoka",
        "Kei Okada",
        "Masayuki Inaba"
      ],
      "abstract": "Library-based methods are known to be very effective for fast motion planning\nby adapting an experience retrieved from a precomputed library. This article\npresents CoverLib, a principled approach for constructing and utilizing such a\nlibrary. CoverLib iteratively adds an experience-classifier-pair to the\nlibrary, where each classifier corresponds to an adaptable region of the\nexperience within the problem space. This iterative process is an active\nprocedure, as it selects the next experience based on its ability to\neffectively cover the uncovered region. During the query phase, these\nclassifiers are utilized to select an experience that is expected to be\nadaptable for a given problem. Experimental results demonstrate that CoverLib\neffectively mitigates the trade-off between plannability and speed observed in\nglobal (e.g. sampling-based) and local (e.g. optimization-based) methods. As a\nresult, it achieves both fast planning and high success rates over the problem\ndomain. Moreover, due to its adaptation-algorithm-agnostic nature, CoverLib\nseamlessly integrates with various adaptation methods, including nonlinear\nprogramming-based and sampling-based algorithms.",
      "tldr_zh": "本文提出 CoverLib，一种通过迭代问题分布覆盖最大化（Iterative Problem Distribution Coverage Maximization）构建经验库的方法，用于领域调整的运动规划（Domain-tuned Motion Planning）。CoverLib 主动添加经验-分类器对（experience-classifier-pair）到库中，每个分类器对应经验在问题空间中的可适应区域，并在查询阶段使用这些分类器选择适合的经验。实验结果显示，CoverLib 有效缓解了全局方法（如基于采样的）和局部方法（如基于优化的）在可规划性和速度之间的权衡，实现快速规划和高成功率，并能无缝整合各种适应算法，如基于非线性编程和基于采样的算法。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted for publication in IEEE Transactions on Robotics",
      "pdf_url": "http://arxiv.org/pdf/2405.02968v4",
      "published_date": "2024-05-05 15:27:05 UTC",
      "updated_date": "2025-02-21 06:23:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:08:05.916805"
    },
    {
      "arxiv_id": "2405.02965v2",
      "title": "Robust Collaborative Perception without External Localization and Clock Devices",
      "title_zh": "无需外部定位和时钟设备的鲁棒协作感知",
      "authors": [
        "Zixing Lei",
        "Zhenyang Ni",
        "Ruize Han",
        "Shuo Tang",
        "Dingju Wang",
        "Chen Feng",
        "Siheng Chen",
        "Yanfeng Wang"
      ],
      "abstract": "A consistent spatial-temporal coordination across multiple agents is\nfundamental for collaborative perception, which seeks to improve perception\nabilities through information exchange among agents. To achieve this\nspatial-temporal alignment, traditional methods depend on external devices to\nprovide localization and clock signals. However, hardware-generated signals\ncould be vulnerable to noise and potentially malicious attack, jeopardizing the\nprecision of spatial-temporal alignment. Rather than relying on external\nhardwares, this work proposes a novel approach: aligning by recognizing the\ninherent geometric patterns within the perceptual data of various agents.\nFollowing this spirit, we propose a robust collaborative perception system that\noperates independently of external localization and clock devices. The key\nmodule of our system,~\\emph{FreeAlign}, constructs a salient object graph for\neach agent based on its detected boxes and uses a graph neural network to\nidentify common subgraphs between agents, leading to accurate relative pose and\ntime. We validate \\emph{FreeAlign} on both real-world and simulated datasets.\nThe results show that, the ~\\emph{FreeAlign} empowered robust collaborative\nperception system perform comparably to systems relying on precise localization\nand clock devices.",
      "tldr_zh": "这篇论文提出了一种Robust Collaborative Perception系统，用于多代理协作感知，而无需依赖外部定位和时钟设备，而是通过识别代理感知数据的内在几何模式来实现空间-时间对齐。核心模块FreeAlign为每个代理构建显著对象图，并利用Graph Neural Network识别代理间的共同子图，从而计算准确的相对位姿和时间。实验结果显示，该系统在真实和模拟数据集上表现与依赖精确外部设备的系统相当，为鲁棒性更强的协作感知提供了新途径。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "6pages, accepted to ICRA 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.02965v2",
      "published_date": "2024-05-05 15:20:36 UTC",
      "updated_date": "2024-05-31 13:58:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:08:16.931953"
    },
    {
      "arxiv_id": "2405.02957v3",
      "title": "Agent Hospital: A Simulacrum of Hospital with Evolvable Medical Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Junkai Li",
        "Yunghwei Lai",
        "Weitao Li",
        "Jingyi Ren",
        "Meng Zhang",
        "Xinhui Kang",
        "Siyu Wang",
        "Peng Li",
        "Ya-Qin Zhang",
        "Weizhi Ma",
        "Yang Liu"
      ],
      "abstract": "The recent rapid development of large language models (LLMs) has sparked a\nnew wave of technological revolution in medical artificial intelligence (AI).\nWhile LLMs are designed to understand and generate text like a human,\nautonomous agents that utilize LLMs as their \"brain\" have exhibited\ncapabilities beyond text processing such as planning, reflection, and using\ntools by enabling their \"bodies\" to interact with the environment. We introduce\na simulacrum of hospital called Agent Hospital that simulates the entire\nprocess of treating illness, in which all patients, nurses, and doctors are\nLLM-powered autonomous agents. Within the simulacrum, doctor agents are able to\nevolve by treating a large number of patient agents without the need to label\ntraining data manually. After treating tens of thousands of patient agents in\nthe simulacrum (human doctors may take several years in the real world), the\nevolved doctor agents outperform state-of-the-art medical agent methods on the\nMedQA benchmark comprising US Medical Licensing Examination (USMLE) test\nquestions. Our methods of simulacrum construction and agent evolution have the\npotential in benefiting a broad range of applications beyond medical AI.",
      "tldr_zh": "本研究引入了Agent Hospital，这是一个模拟医院环境，其中所有患者、护士和医生都是基于大型语言模型(LLMs)的自治代理。该系统允许医生代理通过处理大量患者代理来实现进化，而无需手动标注训练数据；在模拟环境中处理数万个患者后，这些进化后的医生代理在MedQA基准测试（包括US Medical Licensing Examination (USMLE)问题）中超过了最先进的方法。Agent Hospital的模拟构建和代理进化方法具有广泛潜力，可应用于医疗AI以外的领域。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.02957v3",
      "published_date": "2024-05-05 14:53:51 UTC",
      "updated_date": "2025-01-17 11:59:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:08:29.455400"
    },
    {
      "arxiv_id": "2405.02936v2",
      "title": "On the Tractability of SHAP Explanations under Markovian Distributions",
      "title_zh": "翻译失败",
      "authors": [
        "Reda Marzouk",
        "Colin de La Higuera"
      ],
      "abstract": "Thanks to its solid theoretical foundation, the SHAP framework is arguably\none the most widely utilized frameworks for local explainability of ML models.\nDespite its popularity, its exact computation is known to be very challenging,\nproven to be NP-Hard in various configurations. Recent works have unveiled\npositive complexity results regarding the computation of the SHAP score for\nspecific model families, encompassing decision trees, random forests, and some\nclasses of boolean circuits. Yet, all these positive results hinge on the\nassumption of feature independence, often simplistic in real-world scenarios.\nIn this article, we investigate the computational complexity of the SHAP score\nby relaxing this assumption and introducing a Markovian perspective. We show\nthat, under the Markovian assumption, computing the SHAP score for the class of\nWeighted automata, Disjoint DNFs and Decision Trees can be performed in\npolynomial time, offering a first positive complexity result for the problem of\nSHAP score computation that transcends the limitations of the feature\nindependence assumption.",
      "tldr_zh": "这篇论文探讨了在 Markovian 分布下，SHAP 解释的可计算性问题，SHAP 作为一种流行的 ML 模型局部解释框架，其精确计算通常被证明是 NP-Hard。作者引入 Markovian 视角，放松了传统的特征独立性假设，并证明对于 Weighted automata、Disjoint DNFs 和 Decision Trees 等特定模型类，计算 SHAP 分数可以以多项式时间完成。这为超越特征独立性限制的 SHAP 计算提供了首个积极的复杂性结果，提升了实际场景中的解释可行性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.02936v2",
      "published_date": "2024-05-05 13:56:12 UTC",
      "updated_date": "2024-05-24 23:45:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:08:42.197731"
    },
    {
      "arxiv_id": "2405.02929v3",
      "title": "Unified Dynamic Scanpath Predictors Outperform Individually Trained Neural Models",
      "title_zh": "统一的动态扫描路径预测器优于单独训练的神经模型",
      "authors": [
        "Fares Abawi",
        "Di Fu",
        "Stefan Wermter"
      ],
      "abstract": "Previous research on scanpath prediction has mainly focused on group models,\ndisregarding the fact that the scanpaths and attentional behaviors of\nindividuals are diverse. The disregard of these differences is especially\ndetrimental to social human-robot interaction, whereby robots commonly emulate\nhuman gaze based on heuristics or predefined patterns. However, human gaze\npatterns are heterogeneous and varying behaviors can significantly affect the\noutcomes of such human-robot interactions. To fill this gap, we developed a\ndeep learning-based social cue integration model for saliency prediction to\ninstead predict scanpaths in videos. Our model learned scanpaths by recursively\nintegrating fixation history and social cues through a gating mechanism and\nsequential attention. We evaluated our approach on gaze datasets of dynamic\nsocial scenes, observed under the free-viewing condition. The introduction of\nfixation history into our models makes it possible to train a single unified\nmodel rather than the resource-intensive approach of training individual models\nfor each set of scanpaths. We observed that the late neural integration\napproach surpasses early fusion when training models on a large dataset, in\ncomparison to a smaller dataset with a similar distribution. Results also\nindicate that a single unified model, trained on all the observers' scanpaths,\nperforms on par or better than individually trained models. We hypothesize that\nthis outcome is a result of the group saliency representations instilling\nuniversal attention in the model, while the supervisory signal and fixation\nhistory guide it to learn personalized attentional behaviors, providing the\nunified model a benefit over individual models due to its implicit\nrepresentation of universal attention.",
      "tldr_zh": "本研究发现，传统的扫描路径(scanpath)预测模型主要关注群体行为，忽略了个体差异，这对人机交互（如机器人模仿人类注视）造成负面影响。论文提出了一种基于深度学习的社交线索整合模型，通过门控机制(gating mechanism)和顺序注意力(sequential attention)递归整合注视历史(fixation history)和社交线索，以预测动态社交场景中的扫描路径。实验结果显示，在大型数据集上，统一的单一模型（late neural integration 方式）性能优于早期融合方法，且与或优于 individually trained models，因为它融合了通用注意力和个性化行为，提供更高效的训练方式。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.02929v3",
      "published_date": "2024-05-05 13:15:11 UTC",
      "updated_date": "2025-04-20 12:41:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:08:53.898701"
    },
    {
      "arxiv_id": "2405.04549v1",
      "title": "ClothPPO: A Proximal Policy Optimization Enhancing Framework for Robotic Cloth Manipulation with Observation-Aligned Action Spaces",
      "title_zh": "翻译失败",
      "authors": [
        "Libing Yang",
        "Yang Li",
        "Long Chen"
      ],
      "abstract": "Vision-based robotic cloth unfolding has made great progress recently.\nHowever, prior works predominantly rely on value learning and have not fully\nexplored policy-based techniques. Recently, the success of reinforcement\nlearning on the large language model has shown that the policy gradient\nalgorithm can enhance policy with huge action space. In this paper, we\nintroduce ClothPPO, a framework that employs a policy gradient algorithm based\non actor-critic architecture to enhance a pre-trained model with huge 10^6\naction spaces aligned with observation in the task of unfolding clothes. To\nthis end, we redefine the cloth manipulation problem as a partially observable\nMarkov decision process. A supervised pre-training stage is employed to train a\nbaseline model of our policy. In the second stage, the Proximal Policy\nOptimization (PPO) is utilized to guide the supervised model within the\nobservation-aligned action space. By optimizing and updating the strategy, our\nproposed method increases the garment's surface area for cloth unfolding under\nthe soft-body manipulation task. Experimental results show that our proposed\nframework can further improve the unfolding performance of other\nstate-of-the-art methods.",
      "tldr_zh": "该论文提出ClothPPO框架，一种基于Proximal Policy Optimization (PPO)的增强方法，用于机器人布料操作任务，旨在处理巨大行动空间（10^6）与观察对齐的问题。通过将布料操作重新定义为部分可观察Markov决策过程(POMDP)，框架包括监督预训练阶段来建立基线模型，以及后续PPO优化阶段来指导策略，提高布料展开的效率。实验结果表明，ClothPPO显著增加了衣物表面面积，并在软体操作任务中超越了其他最先进方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.04549v1",
      "published_date": "2024-05-05 12:36:18 UTC",
      "updated_date": "2024-05-05 12:36:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:09:05.740907"
    },
    {
      "arxiv_id": "2405.02887v2",
      "title": "Sentiment Analysis Across Languages: Evaluation Before and After Machine Translation to English",
      "title_zh": "跨语言情感分析：机器翻译成英语前后评估",
      "authors": [
        "Aekansh Kathunia",
        "Mohammad Kaif",
        "Nalin Arora",
        "N Narotam"
      ],
      "abstract": "People communicate in more than 7,000 languages around the world, with around\n780 languages spoken in India alone. Despite this linguistic diversity,\nresearch on Sentiment Analysis has predominantly focused on English text data,\nresulting in a disproportionate availability of sentiment resources for\nEnglish. This paper examines the performance of transformer models in Sentiment\nAnalysis tasks across multilingual datasets and text that has undergone machine\ntranslation. By comparing the effectiveness of these models in different\nlinguistic contexts, we gain insights into their performance variations and\npotential implications for sentiment analysis across diverse languages. We also\ndiscuss the shortcomings and potential for future work towards the end.",
      "tldr_zh": "该论文探讨了情感分析(Sentiment Analysis)任务在多语言环境下的性能问题，强调现有研究主要聚焦于英语，导致其他语言资源不足。研究者评估了Transformer模型在多语言数据集上的表现，并比较了直接分析与机器翻译(Machine Translation)到英语后的效果，从而揭示了模型性能在不同语言背景下的差异及其潜在影响。最后，论文讨论了现有方法的缺点，并指出未来改进的方向，以推动跨语言情感分析的发展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages, 3 Figures",
      "pdf_url": "http://arxiv.org/pdf/2405.02887v2",
      "published_date": "2024-05-05 10:52:09 UTC",
      "updated_date": "2024-09-02 15:41:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:09:16.794924"
    },
    {
      "arxiv_id": "2405.02881v2",
      "title": "FedConPE: Efficient Federated Conversational Bandits with Heterogeneous Clients",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuohua Li",
        "Maoli Liu",
        "John C. S. Lui"
      ],
      "abstract": "Conversational recommender systems have emerged as a potent solution for\nefficiently eliciting user preferences. These systems interactively present\nqueries associated with \"key terms\" to users and leverage user feedback to\nestimate user preferences more efficiently. Nonetheless, most existing\nalgorithms adopt a centralized approach. In this paper, we introduce FedConPE,\na phase elimination-based federated conversational bandit algorithm, where $M$\nagents collaboratively solve a global contextual linear bandit problem with the\nhelp of a central server while ensuring secure data management. To effectively\ncoordinate all the clients and aggregate their collected data, FedConPE uses an\nadaptive approach to construct key terms that minimize uncertainty across all\ndimensions in the feature space. Furthermore, compared with existing federated\nlinear bandit algorithms, FedConPE offers improved computational and\ncommunication efficiency as well as enhanced privacy protections. Our\ntheoretical analysis shows that FedConPE is minimax near-optimal in terms of\ncumulative regret. We also establish upper bounds for communication costs and\nconversation frequency. Comprehensive evaluations demonstrate that FedConPE\noutperforms existing conversational bandit algorithms while using fewer\nconversations.",
      "tldr_zh": "该论文提出FedConPE，一种基于相位消除的联邦对话Bandit算法，旨在处理异构客户端的对话推荐系统问题，通过M个代理与中央服务器协作来高效估计用户偏好，同时确保数据安全。FedConPE采用自适应方法构建关键术语，以最小化特征空间中的不确定性，并提升计算、通信效率以及隐私保护。与现有算法相比，该算法在理论上实现累积遗憾的近似最优，并在实验中表现出色，使用更少的对话即获得更好的性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to the 33rd International Joint Conference on Artificial\n  Intelligence (IJCAI), 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.02881v2",
      "published_date": "2024-05-05 10:28:06 UTC",
      "updated_date": "2024-06-20 16:11:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:09:28.780868"
    },
    {
      "arxiv_id": "2405.03716v1",
      "title": "Predicting the usability of mobile applications using AI tools: the rise of large user interface models, opportunities, and challenges",
      "title_zh": "使用 AI 工具预测移动应用的可用性：大型用户界面模型的兴起、机会",
      "authors": [
        "Abdallah Namoun",
        "Ahmed Alrehaili",
        "Zaib Un Nisa",
        "Hani Almoamari",
        "Ali Tufail"
      ],
      "abstract": "This article proposes the so-called large user interface models (LUIMs) to\nenable the generation of user interfaces and prediction of usability using\nartificial intelligence in the context of mobile applications.",
      "tldr_zh": "这篇文章提出了large user interface models (LUIMs)，一种利用人工智能工具生成用户界面并预测移动应用可用性的模型。LUIMs旨在通过AI技术解决移动应用设计中的关键问题，包括界面生成和可用性评估。文章同时探讨了这种模型的兴起所带来的机会（如提升设计效率）和挑战（如潜在的准确性问题）。这为未来移动应用开发提供了新的研究方向和实践指导。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "12 pages, 3 figures, 4 tables, The 7th International Conference on\n  Emerging Data and Industry (EDI40)",
      "pdf_url": "http://arxiv.org/pdf/2405.03716v1",
      "published_date": "2024-05-05 09:24:48 UTC",
      "updated_date": "2024-05-05 09:24:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:09:42.491975"
    },
    {
      "arxiv_id": "2405.02861v1",
      "title": "Revisiting a Pain in the Neck: Semantic Phrase Processing Benchmark for Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Liu",
        "Melissa Xiaohui Qin",
        "Hongming Li",
        "Chao Huang"
      ],
      "abstract": "We introduce LexBench, a comprehensive evaluation suite enabled to test\nlanguage models (LMs) on ten semantic phrase processing tasks. Unlike prior\nstudies, it is the first work to propose a framework from the comparative\nperspective to model the general semantic phrase (i.e., lexical collocation)\nand three fine-grained semantic phrases, including idiomatic expression, noun\ncompound, and verbal construction. Thanks to \\ourbenchmark, we assess the\nperformance of 15 LMs across model architectures and parameter scales in\nclassification, extraction, and interpretation tasks. Through the experiments,\nwe first validate the scaling law and find that, as expected, large models\nexcel better than the smaller ones in most tasks. Second, we investigate\nfurther through the scaling semantic relation categorization and find that\nfew-shot LMs still lag behind vanilla fine-tuned models in the task. Third,\nthrough human evaluation, we find that the performance of strong models is\ncomparable to the human level regarding semantic phrase processing. Our\nbenchmarking findings can serve future research aiming to improve the generic\ncapability of LMs on semantic phrase comprehension. Our source code and data\nare available at https://github.com/jacklanda/LexBench",
      "tldr_zh": "本文提出 LexBench，一种全面的评估框架，用于测试语言模型 (LMs) 在十个语义短语处理任务上的性能，包括一般语义短语（如词汇搭配）和细粒度类型（如惯用表达、名词复合词和动词结构）。通过评估 15 个不同架构和参数规模的 LMs，在分类、提取和解释任务中，实验验证了规模定律，即大型模型在大多数任务上优于小型模型，且少样本 LMs 落后于完全微调模型。人类评估进一步显示，强模型的表现已接近人类水平，为未来提升 LMs 的语义短语理解能力提供宝贵基准，并公开了源代码和数据。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "68T50",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "24 pages, 17 figures, 10 tables",
      "pdf_url": "http://arxiv.org/pdf/2405.02861v1",
      "published_date": "2024-05-05 09:20:38 UTC",
      "updated_date": "2024-05-05 09:20:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:09:54.850811"
    },
    {
      "arxiv_id": "2405.02850v7",
      "title": "Halfway Escape Optimization: A Quantum-Inspired Solution for General Optimization Problems",
      "title_zh": "翻译失败",
      "authors": [
        "Jiawen Li",
        "Anwar PP Abdul Majeed",
        "Pascal Lefevre"
      ],
      "abstract": "This paper first proposes the Halfway Escape Optimization (HEO) algorithm, a\nquantum-inspired metaheuristic designed to address general optimization\nproblems. The HEO mimics the effects between quantum such as tunneling,\nentanglement. After the introduction to the HEO mechansims, the study presents\na comprehensive evaluation of HEO's performance against extensively-used\noptimization algorithms, including Particle Swarm Optimization (PSO), Genetic\nAlgorithm (GA), Artificial Fish Swarm Algorithm (AFSA), Grey Wolf Optimizer\n(GWO), and Quantum behaved Particle Swarm Optimization (QPSO). The primary\nanalysis encompasses 14 benchmark functions with dimension 30, demonstrating\nHEO's effectiveness and adaptability in navigating general optimization\nproblems. The test of HEO in Pressure Vessel Design and Tubular Column Design\nalso infers its feasibility and potential in real-time applications. Further\nvalidation of HEO in Osmancik-97 and Cammeo Rice Classification achieves a\nhigher accuracy record.",
      "tldr_zh": "本文提出了一种量子启发的 Halfway Escape Optimization (HEO) 算法，用于解决一般优化问题，该算法模仿量子效应如隧道效应和纠缠，以提升优化效率。研究通过与 Particle Swarm Optimization (PSO)、Genetic Algorithm (GA)、Artificial Fish Swarm Algorithm (AFSA)、Grey Wolf Optimizer (GWO) 和 Quantum behaved Particle Swarm Optimization (QPSO) 等算法在 14 个维度 30 的基准函数上进行比较，证明 HEO 在有效性和适应性方面表现出色。在实际应用中，如 Pressure Vessel Design 和 Tubular Column Design 的测试，以及 Osmancik-97 和 Cammeo Rice Classification 的验证中，HEO 展示了可行性和更高的准确率。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.02850v7",
      "published_date": "2024-05-05 08:43:07 UTC",
      "updated_date": "2024-09-24 12:11:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:10:06.128704"
    },
    {
      "arxiv_id": "2405.02849v1",
      "title": "Modelling Opaque Bilateral Market Dynamics in Financial Trading: Insights from a Multi-Agent Simulation Study",
      "title_zh": "金融交易中不透明双边市场动态的建模：来自多智能体模拟研究的洞见",
      "authors": [
        "Alicia Vidler",
        "Toby Walsh"
      ],
      "abstract": "Exploring complex adaptive financial trading environments through multi-agent\nbased simulation methods presents an innovative approach within the realm of\nquantitative finance. Despite the dominance of multi-agent reinforcement\nlearning approaches in financial markets with observable data, there exists a\nset of systematically significant financial markets that pose challenges due to\ntheir partial or obscured data availability. We, therefore, devise a\nmulti-agent simulation approach employing small-scale meta-heuristic methods.\nThis approach aims to represent the opaque bilateral market for Australian\ngovernment bond trading, capturing the bilateral nature of bank-to-bank\ntrading, also referred to as \"over-the-counter\" (OTC) trading, and commonly\noccurring between \"market makers\". The uniqueness of the bilateral market,\ncharacterized by negotiated transactions and a limited number of agents, yields\nvaluable insights for agent-based modelling and quantitative finance. The\ninherent rigidity of this market structure, which is at odds with the global\nproliferation of multilateral platforms and the decentralization of finance,\nunderscores the unique insights offered by our agent-based model. We explore\nthe implications of market rigidity on market structure and consider the\nelement of stability, in market design. This extends the ongoing discourse on\ncomplex financial trading environments, providing an enhanced understanding of\ntheir dynamics and implications.",
      "tldr_zh": "本研究通过多智能体模拟方法探讨了金融交易中不透明双边市场（bilateral market）的动态，针对数据不完整或模糊的市场环境提出了一种基于小规模元启发式方法（meta-heuristic methods）的模拟框架。重点模拟澳大利亚政府债券交易的银行间“场外”交易（over-the-counter, OTC）场景，强调市场制造者（market makers）的协商交易特性。结果显示，这种市场刚性与全球多边平台和去中心化金融趋势相悖，揭示了其对市场结构和稳定性的影响，为理解复杂金融交易环境提供了新洞见。",
      "categories": [
        "q-fin.CP",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "q-fin.CP",
      "comment": "13 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.02849v1",
      "published_date": "2024-05-05 08:42:20 UTC",
      "updated_date": "2024-05-05 08:42:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:10:17.753917"
    },
    {
      "arxiv_id": "2405.02846v1",
      "title": "Responsible AI: Portraits with Intelligent Bibliometrics",
      "title_zh": "翻译失败",
      "authors": [
        "Yi Zhang",
        "Mengjia Wu",
        "Guangquan Zhang",
        "Jie Lu"
      ],
      "abstract": "Shifting the focus from principles to practical implementation, responsible\nartificial intelligence (AI) has garnered considerable attention across\nacademia, industry, and society at large. Despite being in its nascent stages,\nthis emerging field grapples with nebulous concepts and intricate knowledge\nframeworks. By analyzing three prevailing concepts - explainable AI,\ntrustworthy AI, and ethical AI, this study defined responsible AI and\nidentified its core principles. Methodologically, this study successfully\ndemonstrated the implementation of leveraging AI's capabilities into\nbibliometrics for enhanced knowledge discovery and the cross-validation of\nexperimentally examined models with domain insights. Empirically, this study\ninvestigated 17,799 research articles contributed by the AI community since\n2015. This involves recognizing key technological players and their\nrelationships, unveiling the topical landscape and hierarchy of responsible AI,\ncharting its evolution, and elucidating the interplay between the\nresponsibility principles and primary AI techniques. An analysis of a core\ncohort comprising 380 articles from multiple disciplines captures the most\nrecent advancements in responsible AI. As one of the pioneering bibliometric\nstudies dedicated to exploring responsible AI, this study will provide\ncomprehensive macro-level insights, enhancing the understanding of responsible\nAI while furnishing valuable knowledge support for AI regulation and governance\ninitiatives.",
      "tldr_zh": "本研究将责任 AI（Responsible AI）的焦点从原则转向实际实施，通过分析可解释 AI（explainable AI）、可靠 AI（trustworthy AI）和伦理 AI（ethical AI）来定义其核心原则，并利用 AI 增强的文献计量学（bibliometrics）进行知识发现和模型交叉验证。研究方法包括对自 2015 年以来 17,799 篇 AI 相关文章的实证分析，识别关键技术参与者及其关系、揭示责任 AI 的主题景观和演变，以及探讨责任原则与主要 AI 技术的互动。最终，通过分析 380 篇核心文章，该研究提供了全面的宏观见解，支持 AI 监管和治理的推进。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.02846v1",
      "published_date": "2024-05-05 08:40:22 UTC",
      "updated_date": "2024-05-05 08:40:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:10:29.851931"
    },
    {
      "arxiv_id": "2405.02821v2",
      "title": "Sim2Real Transfer for Audio-Visual Navigation with Frequency-Adaptive Acoustic Field Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Changan Chen",
        "Jordi Ramos",
        "Anshul Tomar",
        "Kristen Grauman"
      ],
      "abstract": "Sim2real transfer has received increasing attention lately due to the success\nof learning robotic tasks in simulation end-to-end. While there has been a lot\nof progress in transferring vision-based navigation policies, the existing\nsim2real strategy for audio-visual navigation performs data augmentation\nempirically without measuring the acoustic gap. The sound differs from light in\nthat it spans across much wider frequencies and thus requires a different\nsolution for sim2real. We propose the first treatment of sim2real for\naudio-visual navigation by disentangling it into acoustic field prediction\n(AFP) and waypoint navigation. We first validate our design choice in the\nSoundSpaces simulator and show improvement on the Continuous AudioGoal\nnavigation benchmark. We then collect real-world data to measure the spectral\ndifference between the simulation and the real world by training AFP models\nthat only take a specific frequency subband as input. We further propose a\nfrequency-adaptive strategy that intelligently selects the best frequency band\nfor prediction based on both the measured spectral difference and the energy\ndistribution of the received audio, which improves the performance on the real\ndata. Lastly, we build a real robot platform and show that the transferred\npolicy can successfully navigate to sounding objects. This work demonstrates\nthe potential of building intelligent agents that can see, hear, and act\nentirely from simulation, and transferring them to the real world.",
      "tldr_zh": "本文提出了一种针对音频-视觉导航的Sim2Real转移方法，将任务分解为声学场预测(Acoustic Field Prediction, AFP)和路径点导航(Waypoint Navigation)，以解决模拟与真实世界声学差异问题。研究者通过在SoundSpaces模拟器中验证设计，并收集真实数据训练AFP模型，引入频率自适应策略(Frequency-Adaptive Strategy)来根据频谱差异和音频能量分布选择最佳频率带，从而显著提升导航性能。实验结果显示，该方法在Continuous AudioGoal基准上取得改进，并在真实机器人平台上成功导航到发声物体，展示了从模拟环境转移智能代理的潜力。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "cs.RO",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Camera ready version for IROS 2024. Project page:\n  https://vision.cs.utexas.edu/projects/sim2real/",
      "pdf_url": "http://arxiv.org/pdf/2405.02821v2",
      "published_date": "2024-05-05 06:01:31 UTC",
      "updated_date": "2024-09-10 23:43:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:10:43.864804"
    },
    {
      "arxiv_id": "2405.02815v1",
      "title": "Region-specific Risk Quantification for Interpretable Prognosis of COVID-19",
      "title_zh": "针对 COVID-19 的区域特定风险量化，用于可解释预后",
      "authors": [
        "Zhusi Zhong",
        "Jie Li",
        "Zhuoqi Ma",
        "Scott Collins",
        "Harrison Bai",
        "Paul Zhang",
        "Terrance Healey",
        "Xinbo Gao",
        "Michael K. Atalay",
        "Zhicheng Jiao"
      ],
      "abstract": "The COVID-19 pandemic has strained global public health, necessitating\naccurate diagnosis and intervention to control disease spread and reduce\nmortality rates. This paper introduces an interpretable deep survival\nprediction model designed specifically for improved understanding and trust in\nCOVID-19 prognosis using chest X-ray (CXR) images. By integrating a large-scale\npretrained image encoder, Risk-specific Grad-CAM, and anatomical region\ndetection techniques, our approach produces regional interpretable outcomes\nthat effectively capture essential disease features while focusing on rare but\ncritical abnormal regions. Our model's predictive results provide enhanced\nclarity and transparency through risk area localization, enabling clinicians to\nmake informed decisions regarding COVID-19 diagnosis with better understanding\nof prognostic insights. We evaluate the proposed method on a multi-center\nsurvival dataset and demonstrate its effectiveness via quantitative and\nqualitative assessments, achieving superior C-indexes (0.764 and 0.727) and\ntime-dependent AUCs (0.799 and 0.691). These results suggest that our\nexplainable deep survival prediction model surpasses traditional survival\nanalysis methods in risk prediction, improving interpretability for clinical\ndecision making and enhancing AI system trustworthiness.",
      "tldr_zh": "本研究提出了一种区域特定的风险量化方法，用于COVID-19的可解释预后预测，旨在通过胸部X-ray (CXR)图像提升诊断的准确性和可信度。该方法整合大型预训练图像编码器、Risk-specific Grad-CAM和解剖区域检测技术，生成区域可解释结果，重点捕捉关键疾病特征和罕见异常区域，从而帮助临床医生更好地理解风险并做出决策。在多中心生存数据集上评估，该模型取得了优越的C-index（0.764和0.727）和时间依赖AUC（0.799和0.691），超越传统生存分析方法，提高了AI系统的解释性和可信度。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.02815v1",
      "published_date": "2024-05-05 05:08:38 UTC",
      "updated_date": "2024-05-05 05:08:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:10:53.945847"
    },
    {
      "arxiv_id": "2405.02807v1",
      "title": "Kinematic analysis of structural mechanics based on convolutional neural network",
      "title_zh": "基于卷积神经网络的结构力学运动学分析",
      "authors": [
        "Leye Zhang",
        "Xiangxiang Tian",
        "Hongjun Zhang"
      ],
      "abstract": "Attempt to use convolutional neural network to achieve kinematic analysis of\nplane bar structure. Through 3dsMax animation software and OpenCV module,\nself-build image dataset of geometrically stable system and geometrically\nunstable system. we construct and train convolutional neural network model\nbased on the TensorFlow and Keras deep learning platform framework. The model\nachieves 100% accuracy on the training set, validation set, and test set. The\naccuracy on the additional test set is 93.7%, indicating that convolutional\nneural network can learn and master the relevant knowledge of kinematic\nanalysis of structural mechanics. In the future, the generalization ability of\nthe model can be improved through the diversity of dataset, which has the\npotential to surpass human experts for complex structures. Convolutional neural\nnetwork has certain practical value in the field of kinematic analysis of\nstructural mechanics. Using visualization technology, we reveal how\nconvolutional neural network learns and recognizes structural features. Using\npre-trained VGG16 model for feature extraction and fine-tuning, we found that\nthe generalization ability is inferior to the self-built model.",
      "tldr_zh": "该研究利用卷积神经网络 (CNN) 进行结构力学运动学分析，针对平面杆结构通过 3dsMax 和 OpenCV 构建了几何稳定与不稳定系统的图像数据集，并基于 TensorFlow 和 Keras 平台训练模型。结果显示，模型在训练集、验证集和测试集上达到 100% 准确率，在额外测试集上达 93.7%，证明 CNN 能有效学习和掌握相关知识。相比预训练的 VGG16 模型，自建模型的泛化能力更强，通过可视化技术揭示了 CNN 如何识别结构特征，并建议通过数据集多样性提升模型性能，以潜在超越人类专家。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 13 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.02807v1",
      "published_date": "2024-05-05 04:00:03 UTC",
      "updated_date": "2024-05-05 04:00:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:11:06.946567"
    },
    {
      "arxiv_id": "2405.02801v3",
      "title": "Mozart's Touch: A Lightweight Multi-modal Music Generation Framework Based on Pre-Trained Large Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jiajun Li",
        "Tianze Xu",
        "Xuesong Chen",
        "Xinrui Yao",
        "Shuchang Liu"
      ],
      "abstract": "In recent years, AI-Generated Content (AIGC) has witnessed rapid\nadvancements, facilitating the creation of music, images, and other artistic\nforms across a wide range of industries. However, current models for image- and\nvideo-to-music synthesis struggle to capture the nuanced emotions and\natmosphere conveyed by visual content. To fill this gap, we propose Mozart's\nTouch, a multi-modal music generation framework capable of generating music\naligned with cross-modal inputs such as images, videos, and text. The framework\nconsists of three key components: Multi-modal Captioning Module, Large Language\nModel (LLM) understanding \\& Bridging Module, and Music Generation Module.\nUnlike traditional end-to-end methods, Mozart's Touch uses LLMs to accurately\ninterpret visual elements without requiring the training or fine-tuning of\nmusic generation models, providing efficiency and transparency through clear,\ninterpretable prompts. We also introduce the \"LLM-Bridge\" method to resolve the\nheterogeneous representation challenges between descriptive texts from\ndifferent modalities. Through a series of objective and subjective evaluations,\nwe demonstrate that Mozart's Touch outperforms current state-of-the-art models.\nOur code and examples are available at\nhttps://github.com/TiffanyBlews/MozartsTouch.",
      "tldr_zh": "该研究提出Mozart's Touch，一种基于预训练大型模型的轻量级多模态音乐生成框架，旨在解决现有模型在图像和视频到音乐合成中捕捉情感和氛围的不足。该框架包括Multi-modal Captioning Module、Large Language Model (LLM) understanding & Bridging Module以及Music Generation Module，通过LLMs准确解释视觉元素而无需训练或微调音乐生成模型，从而提升效率和透明度。论文引入\"LLM-Bridge\"方法来处理不同模态描述文本的异构表示挑战。实验结果显示，Mozart's Touch在客观和主观评估中优于当前state-of-the-art模型。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "10 pages, 2 figures, submitted to AIGC 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.02801v3",
      "published_date": "2024-05-05 03:15:52 UTC",
      "updated_date": "2024-11-25 08:32:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:11:18.286095"
    },
    {
      "arxiv_id": "2405.02791v3",
      "title": "Efficient Text-driven Motion Generation via Latent Consistency Training",
      "title_zh": "翻译失败",
      "authors": [
        "Mengxian Hu",
        "Minghao Zhu",
        "Xun Zhou",
        "Qingqing Yan",
        "Shu Li",
        "Chengju Liu",
        "Qijun Chen"
      ],
      "abstract": "Text-driven human motion generation based on diffusion strategies establishes\na reliable foundation for multimodal applications in human-computer\ninteractions. However, existing advances face significant efficiency challenges\ndue to the substantial computational overhead of iteratively solving for\nnonlinear reverse diffusion trajectories during the inference phase. To this\nend, we propose the motion latent consistency training framework (MLCT), which\nprecomputes reverse diffusion trajectories from raw data in the training phase\nand enables few-step or single-step inference via self-consistency constraints\nin the inference phase. Specifically, a motion autoencoder with quantization\nconstraints is first proposed for constructing concise and bounded solution\ndistributions for motion diffusion processes. Subsequently, a classifier-free\nguidance format is constructed via an additional unconditional loss function to\naccomplish the precomputation of conditional diffusion trajectories in the\ntraining phase. Finally, a clustering guidance module based on the\nK-nearest-neighbor algorithm is developed for the chain-conduction optimization\nmechanism of self-consistency constraints, which provides additional references\nof solution distributions at a small query cost. By combining these\nenhancements, we achieve stable and consistency training in non-pixel modality\nand latent representation spaces. Benchmark experiments demonstrate that our\nmethod significantly outperforms traditional consistency distillation methods\nwith reduced training cost and enhances the consistency model to perform\ncomparably to state-of-the-art models with lower inference costs.",
      "tldr_zh": "该研究提出了一种高效的文本驱动动作生成框架——motion latent consistency training (MLCT)，通过在训练阶段预计算逆扩散轨迹，实现推理阶段的少步或单步生成，从而解决现有扩散策略方法的计算开销问题。框架的关键组件包括带量化约束的motion autoencoder，用于构建简洁的解决方案分布；classifier-free guidance格式，通过额外无条件损失函数预计算条件扩散轨迹；以及基于K-nearest-neighbor算法的clustering guidance module，提供自一致性约束的优化参考。实验结果表明，MLCT显著优于传统一致性蒸馏方法，减少了训练成本，并在较低推理开销下达到与最先进模型相当的性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.02791v3",
      "published_date": "2024-05-05 02:11:57 UTC",
      "updated_date": "2024-11-29 16:03:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:11:31.320594"
    },
    {
      "arxiv_id": "2405.06677v1",
      "title": "ATG: Benchmarking Automated Theorem Generation for Generative Language Models",
      "title_zh": "ATG：针对生成式语言模型的自动定理生成基准测试",
      "authors": [
        "Xiaohan Lin",
        "Qingxing Cao",
        "Yinya Huang",
        "Zhicheng Yang",
        "Zhengying Liu",
        "Zhenguo Li",
        "Xiaodan Liang"
      ],
      "abstract": "Humans can develop new theorems to explore broader and more complex\nmathematical results. While current generative language models (LMs) have\nachieved significant improvement in automatically proving theorems, their\nability to generate new or reusable theorems is still under-explored. Without\nthe new theorems, current LMs struggle to prove harder theorems that are\ndistant from the given hypotheses with the exponentially growing search space.\nTherefore, this paper proposes an Automated Theorem Generation (ATG) benchmark\nthat evaluates whether an agent can automatically generate valuable (and\npossibly brand new) theorems that are applicable for downstream theorem proving\nas reusable knowledge. Specifically, we construct the ATG benchmark by\nsplitting the Metamath library into three sets: axioms, library, and problem\nbased on their proving depth. We conduct extensive experiments to investigate\nwhether current LMs can generate theorems in the library and benefit the\nproblem theorems proving. The results demonstrate that high-quality ATG data\nfacilitates models' performances on downstream ATP. However, there is still\nroom for current LMs to develop better ATG and generate more advanced and\nhuman-like theorems. We hope the new ATG challenge can shed some light on\nadvanced complex theorem proving.",
      "tldr_zh": "该论文提出 Automated Theorem Generation (ATG) 基准，用于评估生成语言模型 (LMs) 自动生成新定理的能力，以解决 LMs 在证明复杂定理时因搜索空间指数增长而面临的挑战。研究者通过将 Metamath 库基于证明深度分成公理、库和问题三部分，进行广泛实验，检验 LMs 是否能生成可重用的定理并提升下游 Automated Theorem Proving (ATP) 性能。结果显示，高质量 ATG 数据显著提高了模型的证明效果，但当前 LMs 仍需改进以生成更高级的人类级定理，从而推动更复杂的定理证明研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.06677v1",
      "published_date": "2024-05-05 02:06:37 UTC",
      "updated_date": "2024-05-05 02:06:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:11:43.559784"
    },
    {
      "arxiv_id": "2405.02774v1",
      "title": "Get more for less: Principled Data Selection for Warming Up Fine-Tuning in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Feiyang Kang",
        "Hoang Anh Just",
        "Yifan Sun",
        "Himanshu Jahagirdar",
        "Yuanzhi Zhang",
        "Rongxing Du",
        "Anit Kumar Sahu",
        "Ruoxi Jia"
      ],
      "abstract": "This work focuses on leveraging and selecting from vast, unlabeled, open data\nto pre-fine-tune a pre-trained language model. The goal is to minimize the need\nfor costly domain-specific data for subsequent fine-tuning while achieving\ndesired performance levels. While many data selection algorithms have been\ndesigned for small-scale applications, rendering them unsuitable for our\ncontext, some emerging methods do cater to language data scales. However, they\noften prioritize data that aligns with the target distribution. While this\nstrategy may be effective when training a model from scratch, it can yield\nlimited results when the model has already been pre-trained on a different\ndistribution. Differing from prior work, our key idea is to select data that\nnudges the pre-training distribution closer to the target distribution. We show\nthe optimality of this approach for fine-tuning tasks under certain conditions.\nWe demonstrate the efficacy of our methodology across a diverse array of tasks\n(NLU, NLG, zero-shot) with models up to 2.7B, showing that it consistently\nsurpasses other selection methods. Moreover, our proposed method is\nsignificantly faster than existing techniques, scaling to millions of samples\nwithin a single GPU hour. Our code is open-sourced (Code repository:\nhttps://anonymous.4open.science/r/DV4LLM-D761/ ). While fine-tuning offers\nsignificant potential for enhancing performance across diverse tasks, its\nassociated costs often limit its widespread adoption; with this work, we hope\nto lay the groundwork for cost-effective fine-tuning, making its benefits more\naccessible.",
      "tldr_zh": "这项研究提出了一种原则性的数据选择方法，用于预微调大型语言模型（LLMs），旨在通过选择无标签开放数据来将预训练分布逐步推向目标分布，从而减少后续fine-tuning对昂贵领域特定数据的依赖。不同于现有方法，该方法优先优化分布差异，在NLU、NLG和zero-shot任务上测试后，证明其在模型规模达2.7B时 consistently 优于其他选择策略。实验结果显示，该方法不仅提升了性能，还显著更快，能在单GPU小时内处理数百万样本，并已开源代码以促进成本有效的fine-tuning应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Published as a conference paper at ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.02774v1",
      "published_date": "2024-05-05 00:08:00 UTC",
      "updated_date": "2024-05-05 00:08:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T06:11:53.988954"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 38,
  "processed_papers_count": 38,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-18T06:12:17.427001"
}