[
  {
    "arxiv_id": "2508.07111v1",
    "title": "Investigating Intersectional Bias in Large Language Models using Confidence Disparities in Coreference Resolution",
    "authors": [
      "Falaah Arif Khan",
      "Nivedha Sivakumar",
      "Yinong Oliver Wang",
      "Katherine Metcalf",
      "Cezanne Camacho",
      "Barry-John Theobald",
      "Luca Zappella",
      "Nicholas Apostoloff"
    ],
    "abstract": "Large language models (LLMs) have achieved impressive performance, leading to their widespread adoption as decision-support tools in resource-constrained contexts like hiring and admissions. There is, however, scientific consensus that AI systems can reflect and exacerbate societal biases, raising concerns about identity-based harm when used in critical social contexts. Prior work has laid a solid foundation for assessing bias in LLMs by evaluating demographic disparities in different language reasoning tasks. In this work, we extend single-axis fairness evaluations to examine intersectional bias, recognizing that when multiple axes of discrimination intersect, they create distinct patterns of disadvantage. We create a new benchmark called WinoIdentity by augmenting the WinoBias dataset with 25 demographic markers across 10 attributes, including age, nationality, and race, intersected with binary gender, yielding 245,700 prompts to evaluate 50 distinct bias patterns. Focusing on harms of omission due to underrepresentation, we investigate bias through the lens of uncertainty and propose a group (un)fairness metric called Coreference Confidence Disparity which measures whether models are more or less confident for some intersectional identities than others. We evaluate five recently published LLMs and find confidence disparities as high as 40% along various demographic attributes including body type, sexual orientation and socio-economic status, with models being most uncertain about doubly-disadvantaged identities in anti-stereotypical settings. Surprisingly, coreference confidence decreases even for hegemonic or privileged markers, indicating that the recent impressive performance of LLMs is more likely due to memorization than logical reasoning. Notably, these are two independent failures in value alignment and validity that can compound to cause social harm.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.07111v1",
    "published_date": "2025-08-09 22:24:40 UTC",
    "updated_date": "2025-08-09 22:24:40 UTC"
  },
  {
    "arxiv_id": "2508.07107v2",
    "title": "Designing a Feedback-Driven Decision Support System for Dynamic Student Intervention",
    "authors": [
      "Timothy Oluwapelumi Adeyemi",
      "Nadiah Fahad AlOtaibi"
    ],
    "abstract": "Accurate prediction of student performance is essential for enabling timely academic interventions. However, most machine learning models used in educational settings are static and lack the ability to adapt when new data such as post-intervention outcomes become available. To address this limitation, we propose a Feedback-Driven Decision Support System (DSS) with a closed-loop architecture that enables continuous model refinement. The system employs a LightGBM-based regressor with incremental retraining, allowing educators to input updated student performance data, which automatically triggers model updates. This adaptive mechanism enhances prediction accuracy by learning from real-world academic progress over time.\n  The platform features a Flask-based web interface to support real-time interaction and integrates SHAP (SHapley Additive exPlanations) for model interpretability, ensuring transparency and trustworthiness in predictions. Experimental results demonstrate a 10.7% reduction in RMSE after retraining, with consistent upward adjustments in predicted scores for students who received interventions. By transforming static predictive models into self-improving systems, our approach advances educational analytics toward human-centered, data-driven, and responsive artificial intelligence. The framework is designed for seamless integration into Learning Management Systems (LMS) and institutional dashboards, facilitating practical deployment in real educational environments.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 1 figure, 3 tables",
    "pdf_url": "https://arxiv.org/pdf/2508.07107v2",
    "published_date": "2025-08-09 21:24:54 UTC",
    "updated_date": "2025-08-12 10:20:46 UTC"
  },
  {
    "arxiv_id": "2508.07102v1",
    "title": "Towards High-Order Mean Flow Generative Models: Feasibility, Expressivity, and Provably Efficient Criteria",
    "authors": [
      "Yang Cao",
      "Yubin Chen",
      "Zhao Song",
      "Jiahao Zhang"
    ],
    "abstract": "Generative modelling has seen significant advances through simulation-free paradigms such as Flow Matching, and in particular, the MeanFlow framework, which replaces instantaneous velocity fields with average velocities to enable efficient single-step sampling. In this work, we introduce a theoretical study on Second-Order MeanFlow, a novel extension that incorporates average acceleration fields into the MeanFlow objective. We first establish the feasibility of our approach by proving that the average acceleration satisfies a generalized consistency condition analogous to first-order MeanFlow, thereby supporting stable, one-step sampling and tractable loss functions. We then characterize its expressivity via circuit complexity analysis, showing that under mild assumptions, the Second-Order MeanFlow sampling process can be implemented by uniform threshold circuits within the $\\mathsf{TC}^0$ class. Finally, we derive provably efficient criteria for scalable implementation by leveraging fast approximate attention computations: we prove that attention operations within the Second-Order MeanFlow architecture can be approximated to within $1/\\mathrm{poly}(n)$ error in time $n^{2+o(1)}$. Together, these results lay the theoretical foundation for high-order flow matching models that combine rich dynamics with practical sampling efficiency.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.07102v1",
    "published_date": "2025-08-09 21:10:58 UTC",
    "updated_date": "2025-08-09 21:10:58 UTC"
  },
  {
    "arxiv_id": "2508.07101v1",
    "title": "Less Is More: Training-Free Sparse Attention with Global Locality for Efficient Reasoning",
    "authors": [
      "Lijie Yang",
      "Zhihao Zhang",
      "Arti Jain",
      "Shijie Cao",
      "Baihong Yuan",
      "Yiwei Chen",
      "Zhihao Jia",
      "Ravi Netravali"
    ],
    "abstract": "Large reasoning models achieve strong performance through test-time scaling but incur substantial computational overhead, particularly from excessive token generation when processing short input prompts. While sparse attention mechanisms can reduce latency and memory usage, existing approaches suffer from significant accuracy degradation due to accumulated errors during long-generation reasoning. These methods generally require either high token retention rates or expensive retraining. We introduce LessIsMore, a training-free sparse attention mechanism for reasoning tasks, which leverages global attention patterns rather than relying on traditional head-specific local optimizations. LessIsMore aggregates token selections from local attention heads with recent contextual information, enabling unified cross-head token ranking for future decoding layers. This unified selection improves generalization and efficiency by avoiding the need to maintain separate token subsets per head. Evaluation across diverse reasoning tasks and benchmarks shows that LessIsMore preserves -- and in some cases improves -- accuracy while achieving a $1.1\\times$ average decoding speed-up compared to full attention. Moreover, LessIsMore attends to $2\\times$ fewer tokens without accuracy loss, achieving a $1.13\\times$ end-to-end speed-up compared to existing sparse attention methods.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.07101v1",
    "published_date": "2025-08-09 21:10:33 UTC",
    "updated_date": "2025-08-09 21:10:33 UTC"
  },
  {
    "arxiv_id": "2508.07095v1",
    "title": "Hide or Highlight: Understanding the Impact of Factuality Expression on User Trust",
    "authors": [
      "Hyo Jin Do",
      "Werner Geyer"
    ],
    "abstract": "Large language models are known to produce outputs that are plausible but factually incorrect. To prevent people from making erroneous decisions by blindly trusting AI, researchers have explored various ways of communicating factuality estimates in AI-generated outputs to end-users. However, little is known about whether revealing content estimated to be factually incorrect influences users' trust when compared to hiding it altogether. We tested four different ways of disclosing an AI-generated output with factuality assessments: transparent (highlights less factual content), attention (highlights factual content), opaque (removes less factual content), ambiguity (makes less factual content vague), and compared them with a baseline response without factuality information. We conducted a human subjects research (N = 148) using the strategies in question-answering scenarios. We found that the opaque and ambiguity strategies led to higher trust while maintaining perceived answer quality, compared to the other strategies. We discuss the efficacy of hiding presumably less factual content to build end-user trust.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "17 pages, 3 figures, To be published in Proceedings of the 8th AAAI/ACM Conference on AI, Ethics, and Society (AIES 2025)",
    "pdf_url": "https://arxiv.org/pdf/2508.07095v1",
    "published_date": "2025-08-09 20:45:21 UTC",
    "updated_date": "2025-08-09 20:45:21 UTC"
  },
  {
    "arxiv_id": "2508.07087v1",
    "title": "SQL-Exchange: Transforming SQL Queries Across Domains",
    "authors": [
      "Mohammadreza Daviran",
      "Brian Lin",
      "Davood Rafiei"
    ],
    "abstract": "We introduce SQL-Exchange, a framework for mapping SQL queries across different database schemas by preserving the source query structure while adapting domain-specific elements to align with the target schema. We investigate the conditions under which such mappings are feasible and beneficial, and examine their impact on enhancing the in-context learning performance of text-to-SQL systems as a downstream task. Our comprehensive evaluation across multiple model families and benchmark datasets--assessing structural alignment with source queries, execution validity on target databases, and semantic correctness--demonstrates that SQL-Exchange is effective across a wide range of schemas and query types. Our results further show that using mapped queries as in-context examples consistently improves text-to-SQL performance over using queries from the source schema.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.07087v1",
    "published_date": "2025-08-09 19:55:54 UTC",
    "updated_date": "2025-08-09 19:55:54 UTC"
  },
  {
    "arxiv_id": "2508.11682v2",
    "title": "Age-Normalized HRV Features for Non-Invasive Glucose Prediction: A Pilot Sleep-Aware Machine Learning Study",
    "authors": [
      "Md Basit Azam",
      "Sarangthem Ibotombi Singh"
    ],
    "abstract": "Non-invasive glucose monitoring remains a critical challenge in the management of diabetes. HRV during sleep shows promise for glucose prediction however, age-related autonomic changes significantly confound traditional HRV analyses. We analyzed 43 subjects with multi-modal data including sleep-stage specific ECG, HRV features, and clinical measurements. A novel age-normalization technique was applied to the HRV features by, dividing the raw values by age-scaled factors. BayesianRidge regression with 5-fold cross-validation was employed for log-glucose prediction. Age-normalized HRV features achieved R2 = 0.161 (MAE = 0.182) for log-glucose prediction, representing a 25.6% improvement over non-normalized features (R2 = 0.132). The top predictive features were hrv rem mean rr age normalized (r = 0.443, p = 0.004), hrv ds mean rr age normalized (r = 0.438, p = 0.005), and diastolic blood pressure (r = 0.437, p = 0.005). Systematic ablation studies confirmed age-normalization as the critical component, with sleep-stage specific features providing additional predictive value. Age-normalized HRV features significantly enhance glucose prediction accuracy compared with traditional approaches. This sleep-aware methodology addresses fundamental limitations in autonomic function assessment and suggests a preliminary feasibility for non-invasive glucose monitoring applications. However, these results require validation in larger cohorts before clinical consideration.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.11682v2",
    "published_date": "2025-08-09 19:24:31 UTC",
    "updated_date": "2025-08-19 13:01:13 UTC"
  },
  {
    "arxiv_id": "2508.07080v1",
    "title": "An Evolutionary Game-Theoretic Merging Decision-Making Considering Social Acceptance for Autonomous Driving",
    "authors": [
      "Haolin Liu",
      "Zijun Guo",
      "Yanbo Chen",
      "Jiaqi Chen",
      "Huilong Yu",
      "Junqiang Xi"
    ],
    "abstract": "Highway on-ramp merging is of great challenge for autonomous vehicles (AVs), since they have to proactively interact with surrounding vehicles to enter the main road safely within limited time. However, existing decision-making algorithms fail to adequately address dynamic complexities and social acceptance of AVs, leading to suboptimal or unsafe merging decisions. To address this, we propose an evolutionary game-theoretic (EGT) merging decision-making framework, grounded in the bounded rationality of human drivers, which dynamically balances the benefits of both AVs and main-road vehicles (MVs). We formulate the cut-in decision-making process as an EGT problem with a multi-objective payoff function that reflects human-like driving preferences. By solving the replicator dynamic equation for the evolutionarily stable strategy (ESS), the optimal cut-in timing is derived, balancing efficiency, comfort, and safety for both AVs and MVs. A real-time driving style estimation algorithm is proposed to adjust the game payoff function online by observing the immediate reactions of MVs. Empirical results demonstrate that we improve the efficiency, comfort and safety of both AVs and MVs compared with existing game-theoretic and traditional planning approaches across multi-object metrics.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.07080v1",
    "published_date": "2025-08-09 19:18:28 UTC",
    "updated_date": "2025-08-09 19:18:28 UTC"
  },
  {
    "arxiv_id": "2508.07079v1",
    "title": "Model Predictive Control for Crowd Navigation via Learning-Based Trajectory Prediction",
    "authors": [
      "Mohamed Parvez Aslam",
      "Bojan Derajic",
      "Mohamed-Khalil Bouzidi",
      "Sebastian Bernhard",
      "Jan Oliver Ringert"
    ],
    "abstract": "Safe navigation in pedestrian-rich environments remains a key challenge for autonomous robots. This work evaluates the integration of a deep learning-based Social-Implicit (SI) pedestrian trajectory predictor within a Model Predictive Control (MPC) framework on the physical Continental Corriere robot. Tested across varied pedestrian densities, the SI-MPC system is compared to a traditional Constant Velocity (CV) model in both open-loop prediction and closed-loop navigation. Results show that SI improves trajectory prediction - reducing errors by up to 76% in low-density settings - and enhances safety and motion smoothness in crowded scenes. Moreover, real-world deployment reveals discrepancies between open-loop metrics and closed-loop performance, as the SI model yields broader, more cautious predictions. These findings emphasize the importance of system-level evaluation and highlight the SI-MPC framework's promise for safer, more adaptive navigation in dynamic, human-populated environments.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.07079v1",
    "published_date": "2025-08-09 19:11:28 UTC",
    "updated_date": "2025-08-09 19:11:28 UTC"
  },
  {
    "arxiv_id": "2508.07075v1",
    "title": "Surgical Knowledge Rewrite in Compact LLMs: An 'Unlearn-then-Learn' Strategy with ($IA^3$) for Localized Factual Modulation and Catastrophic Forgetting Mitigation",
    "authors": [
      "Stanley Ngugi"
    ],
    "abstract": "Large Language Models (LLMs) struggle with dynamic knowledge updates, especially when new information conflicts with deeply embedded facts. Such conflicting factual edits often lead to two critical issues: resistance to adopting the new fact and severe catastrophic forgetting of unrelated knowledge. This paper introduces and evaluates a novel \"unlearn-then-learn\" strategy for precise knowledge editing in LLMs, leveraging the parameter-efficient fine-tuning (PEFT) technique, Infused Adapter by Inhibiting and Amplifying Inner Activations ($IA^3$). Crucially, this two-stage approach is powered by an initial circuit localization phase that identifies and targets the specific internal components responsible for encoding the conflicting fact. Through a rigorous experimental methodology on microsoft/Phi-3-mini-4k-instruct, we demonstrate that this mechanistically informed two-stage approach achieves near-perfect accuracy (98.50%) for the new, modulated fact while simultaneously effectively suppressing the original conflicting fact (96.00% forget rate). Critically, our strategy exhibits unprecedented localization (72.00% F_control accuracy), dramatically mitigating catastrophic forgetting observed in direct fine-tuning approaches (which showed as low as ~20% F_control accuracy), a direct benefit of our targeted interpretability-guided intervention. Furthermore, qualitative analysis reveals a nuanced mechanism of \"soft forgetting,\" where original knowledge is suppressed from default retrieval but remains latent and conditionally accessible, enhancing model safety and control. These findings represent a significant advancement towards precise, localized, and safe knowledge management in compact LLMs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 2 visual aids",
    "pdf_url": "https://arxiv.org/pdf/2508.07075v1",
    "published_date": "2025-08-09 18:48:25 UTC",
    "updated_date": "2025-08-09 18:48:25 UTC"
  },
  {
    "arxiv_id": "2508.08325v2",
    "title": "Algorithmic Collusion of Pricing and Advertising on E-commerce Platforms",
    "authors": [
      "Hangcheng Zhao",
      "Ron Berman"
    ],
    "abstract": "When online sellers use AI learning algorithms to automatically compete on e-commerce platforms, there is concern that they will learn to coordinate on higher than competitive prices. However, this concern was primarily raised in single-dimension price competition. We investigate whether this prediction holds when sellers make pricing and advertising decisions together, i.e., two-dimensional decisions. We analyze competition in multi-agent reinforcement learning, and use a large-scale dataset from Amazon.com to provide empirical evidence. We show that when consumers have high search costs, learning algorithms can coordinate on prices lower than competitive prices, facilitating a win-win-win for consumers, sellers, and platforms. This occurs because algorithms learn to coordinate on lower advertising bids, which lower advertising costs, leading to lower prices and enlarging demand on the platform. We also show that our results generalize to any learning algorithm that uses exploration of price and advertising bids. Consistent with our predictions, an empirical analysis shows that price levels exhibit a negative interaction between estimated consumer search costs and algorithm usage index. We analyze the platform's strategic response and find that reserve price adjustments will not increase platform profits, but commission adjustments will, while maintaining the beneficial outcomes for both sellers and consumers.",
    "categories": [
      "econ.GN",
      "cs.AI",
      "cs.CE",
      "cs.GT",
      "cs.LG"
    ],
    "primary_category": "econ.GN",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.08325v2",
    "published_date": "2025-08-09 18:44:17 UTC",
    "updated_date": "2025-10-31 01:04:51 UTC"
  },
  {
    "arxiv_id": "2508.07069v1",
    "title": "SEADialogues: A Multilingual Culturally Grounded Multi-turn Dialogue Dataset on Southeast Asian Languages",
    "authors": [
      "Muhammad Dehan Al Kautsar",
      "Aswin Candra",
      "Muhammad Alif Al Hakim",
      "Maxalmina Satria Kahfi",
      "Fajri Koto",
      "Alham Fikri Aji",
      "Peerat Limkonchotiwat",
      "Ekapol Chuangsuwanich",
      "Genta Indra Winata"
    ],
    "abstract": "Although numerous datasets have been developed to support dialogue systems, most existing chit-chat datasets overlook the cultural nuances inherent in natural human conversations. To address this gap, we introduce SEADialogues, a culturally grounded dialogue dataset centered on Southeast Asia, a region with over 700 million people and immense cultural diversity. Our dataset features dialogues in eight languages from six Southeast Asian countries, many of which are low-resource despite having sizable speaker populations. To enhance cultural relevance and personalization, each dialogue includes persona attributes and two culturally grounded topics that reflect everyday life in the respective communities. Furthermore, we release a multi-turn dialogue dataset to advance research on culturally aware and human-centric large language models, including conversational dialogue agents.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Preprint",
    "pdf_url": "https://arxiv.org/pdf/2508.07069v1",
    "published_date": "2025-08-09 18:22:35 UTC",
    "updated_date": "2025-08-09 18:22:35 UTC"
  },
  {
    "arxiv_id": "2508.07063v1",
    "title": "Towards Safer AI Moderation: Evaluating LLM Moderators Through a Unified Benchmark Dataset and Advocating a Human-First Approach",
    "authors": [
      "Naseem Machlovi",
      "Maryam Saleki",
      "Innocent Ababio",
      "Ruhul Amin"
    ],
    "abstract": "As AI systems become more integrated into daily life, the need for safer and more reliable moderation has never been greater. Large Language Models (LLMs) have demonstrated remarkable capabilities, surpassing earlier models in complexity and performance. Their evaluation across diverse tasks has consistently showcased their potential, enabling the development of adaptive and personalized agents. However, despite these advancements, LLMs remain prone to errors, particularly in areas requiring nuanced moral reasoning. They struggle with detecting implicit hate, offensive language, and gender biases due to the subjective and context-dependent nature of these issues. Moreover, their reliance on training data can inadvertently reinforce societal biases, leading to inconsistencies and ethical concerns in their outputs. To explore the limitations of LLMs in this role, we developed an experimental framework based on state-of-the-art (SOTA) models to assess human emotions and offensive behaviors. The framework introduces a unified benchmark dataset encompassing 49 distinct categories spanning the wide spectrum of human emotions, offensive and hateful text, and gender and racial biases. Furthermore, we introduced SafePhi, a QLoRA fine-tuned version of Phi-4, adapting diverse ethical contexts and outperforming benchmark moderators by achieving a Macro F1 score of 0.89, where OpenAI Moderator and Llama Guard score 0.77 and 0.74, respectively. This research also highlights the critical domains where LLM moderators consistently underperformed, pressing the need to incorporate more heterogeneous and representative data with human-in-the-loop, for better model robustness and explainability.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.07063v1",
    "published_date": "2025-08-09 18:00:27 UTC",
    "updated_date": "2025-08-09 18:00:27 UTC"
  },
  {
    "arxiv_id": "2509.00005v2",
    "title": "Per-sender neural network classifiers for email authorship validation",
    "authors": [
      "Rohit Dube"
    ],
    "abstract": "Business email compromise and lateral spear phishing attacks are among modern organizations' most costly and damaging threats. While inbound phishing defenses have improved significantly, most organizations still trust internal emails by default, leaving themselves vulnerable to attacks from compromised employee accounts. In this work, we define and explore the problem of authorship validation: verifying whether a claimed sender actually authored a given email. Authorship validation is a lightweight, real-time defense that complements traditional detection methods by modeling per-sender writing style. Further, the paper presents a collection of new datasets based on the Enron corpus. These simulate inauthentic messages using both human-written and large language model-generated emails. The paper also evaluates two classifiers -- a Naive Bayes model and a character-level convolutional neural network (Char-CNN) -- for the authorship validation task. Our experiments show that the Char-CNN model achieves high accuracy and F1 scores under various circumstances. Finally, we discuss deployment considerations and show that per-sender authorship classifiers are practical for integrating into existing commercial email security systems with low overhead.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "stat.AP"
    ],
    "primary_category": "cs.CR",
    "comment": "12 pages, 6 figures, 8 tables, 41 references",
    "pdf_url": "https://arxiv.org/pdf/2509.00005v2",
    "published_date": "2025-08-09 17:58:16 UTC",
    "updated_date": "2026-01-07 20:41:13 UTC"
  },
  {
    "arxiv_id": "2508.07054v1",
    "title": "Membership and Memorization in LLM Knowledge Distillation",
    "authors": [
      "Ziqi Zhang",
      "Ali Shahin Shamsabadi",
      "Hanxiao Lu",
      "Yifeng Cai",
      "Hamed Haddadi"
    ],
    "abstract": "Recent advances in Knowledge Distillation (KD) aim to mitigate the high computational demands of Large Language Models (LLMs) by transferring knowledge from a large ''teacher'' to a smaller ''student'' model. However, students may inherit the teacher's privacy when the teacher is trained on private data. In this work, we systematically characterize and investigate membership and memorization privacy risks inherent in six LLM KD techniques. Using instruction-tuning settings that span seven NLP tasks, together with three teacher model families (GPT-2, LLAMA-2, and OPT), and various size student models, we demonstrate that all existing LLM KD approaches carry membership and memorization privacy risks from the teacher to its students. However, the extent of privacy risks varies across different KD techniques. We systematically analyse how key LLM KD components (KD objective functions, student training data and NLP tasks) impact such privacy risks. We also demonstrate a significant disagreement between memorization and membership privacy risks of LLM KD techniques. Finally, we characterize per-block privacy risk and demonstrate that the privacy risk varies across different blocks by a large margin.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.07054v1",
    "published_date": "2025-08-09 17:40:41 UTC",
    "updated_date": "2025-08-09 17:40:41 UTC"
  },
  {
    "arxiv_id": "2508.10034v1",
    "title": "Jet Image Tagging Using Deep Learning: An Ensemble Model",
    "authors": [
      "Juvenal Bassa",
      "Vidya Manian",
      "Sudhir Malik",
      "Arghya Chattopadhyay"
    ],
    "abstract": "Jet classification in high-energy particle physics is important for understanding fundamental interactions and probing phenomena beyond the Standard Model. Jets originate from the fragmentation and hadronization of quarks and gluons, and pose a challenge for identification due to their complex, multidimensional structure. Traditional classification methods often fall short in capturing these intricacies, necessitating advanced machine learning approaches. In this paper, we employ two neural networks simultaneously as an ensemble to tag various jet types. We convert the jet data to two-dimensional histograms instead of representing them as points in a higher-dimensional space. Specifically, this ensemble approach, hereafter referred to as Ensemble Model, is used to tag jets into classes from the JetNet dataset, corresponding to: Top Quarks, Light Quarks (up or down), and W and Z bosons. For the jet classes mentioned above, we show that the Ensemble Model can be used for both binary and multi-categorical classification. This ensemble approach learns jet features by leveraging the strengths of each constituent network achieving superior performance compared to either individual network.",
    "categories": [
      "physics.data-an",
      "cs.AI",
      "cs.LG",
      "hep-ex",
      "hep-ph"
    ],
    "primary_category": "physics.data-an",
    "comment": "19 Pages. All codes available at https://github.com/Basjuven/Jet_Images_Tagging_EM",
    "pdf_url": "https://arxiv.org/pdf/2508.10034v1",
    "published_date": "2025-08-09 17:40:15 UTC",
    "updated_date": "2025-08-09 17:40:15 UTC"
  },
  {
    "arxiv_id": "2508.07050v2",
    "title": "ReasonRank: Empowering Passage Ranking with Strong Reasoning Ability",
    "authors": [
      "Wenhan Liu",
      "Xinyu Ma",
      "Weiwei Sun",
      "Yutao Zhu",
      "Yuchen Li",
      "Dawei Yin",
      "Zhicheng Dou"
    ],
    "abstract": "Large Language Model (LLM) based listwise ranking has shown superior performance in many passage ranking tasks. With the development of Large Reasoning Models, many studies have demonstrated that step-by-step reasoning during test-time helps improve listwise ranking performance. However, due to the scarcity of reasoning-intensive training data, existing rerankers perform poorly in many complex ranking scenarios and the ranking ability of reasoning-intensive rerankers remains largely underdeveloped. In this paper, we first propose an automated reasoning-intensive training data synthesis framework, which sources training queries and passages from diverse domains and applies DeepSeek-R1 to generate high-quality training labels. A self-consistency data filtering mechanism is designed to ensure the data quality. To empower the listwise reranker with strong reasoning ability, we further propose a two-stage post-training approach, which includes a cold-start supervised fine-tuning (SFT) stage for reasoning pattern learning and a reinforcement learning (RL) stage for further ranking ability enhancement. During the RL stage, based on the nature of listwise ranking, we design a multi-view ranking reward, which is more effective than a ranking metric-based reward. Extensive experiments demonstrate that our trained reasoning-intensive reranker \\textbf{ReasonRank} outperforms existing baselines significantly and also achieves much lower latency than pointwise reranker Rank1. \\textbf{Through further experiments, our ReasonRank has achieved state-of-the-art (SOTA) performance 40.6 on the BRIGHT leaderboard\\footnote{https://brightbenchmark.github.io/}.} Our codes are available at https://github.com/8421BCD/ReasonRank.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "21 pages",
    "pdf_url": "https://arxiv.org/pdf/2508.07050v2",
    "published_date": "2025-08-09 17:26:18 UTC",
    "updated_date": "2025-08-22 09:15:24 UTC"
  },
  {
    "arxiv_id": "2508.07048v1",
    "title": "Whisfusion: Parallel ASR Decoding via a Diffusion Transformer",
    "authors": [
      "Taeyoun Kwon",
      "Junhyuk Ahn",
      "Taegeun Yun",
      "Heeju Jwa",
      "Yoonchae Choi",
      "Siwon Park",
      "Nam-Joon Kim",
      "Jangchan Kim",
      "Hyun Gon Ryu",
      "Hyuk-Jae Lee"
    ],
    "abstract": "Fast Automatic Speech Recognition (ASR) is critical for latency-sensitive applications such as real-time captioning and meeting transcription. However, truly parallel ASR decoding remains challenging due to the sequential nature of autoregressive (AR) decoders and the context limitations of non-autoregressive (NAR) methods. While modern ASR encoders can process up to 30 seconds of audio at once, AR decoders still generate tokens sequentially, creating a latency bottleneck. We propose Whisfusion, the first framework to fuse a pre-trained Whisper encoder with a text diffusion decoder. This NAR architecture resolves the AR latency bottleneck by processing the entire acoustic context in parallel at every decoding step. A lightweight cross-attention adapter trained via parameter-efficient fine-tuning (PEFT) bridges the two modalities. We also introduce a batch-parallel, multi-step decoding strategy that improves accuracy by increasing the number of candidates with minimal impact on speed. Fine-tuned solely on LibriSpeech (960h), Whisfusion achieves a lower WER than Whisper-tiny (8.3% vs. 9.7%), and offers comparable latency on short audio. For longer utterances (>20s), it is up to 2.6x faster than the AR baseline, establishing a new, efficient operating point for long-form ASR. The implementation and training scripts are available at https://github.com/taeyoun811/Whisfusion.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "16 pages, 9 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.07048v1",
    "published_date": "2025-08-09 17:20:54 UTC",
    "updated_date": "2025-08-09 17:20:54 UTC"
  },
  {
    "arxiv_id": "2508.07044v1",
    "title": "Balancing Privacy and Efficiency: Music Information Retrieval via Additive Homomorphic Encryption",
    "authors": [
      "William Zerong Wang",
      "Dongfang Zhao"
    ],
    "abstract": "In the era of generative AI, ensuring the privacy of music data presents unique challenges: unlike static artworks such as images, music data is inherently temporal and multimodal, and it is sampled, transformed, and remixed at an unprecedented scale. These characteristics make its core vector embeddings, i.e, the numerical representations of the music, highly susceptible to being learned, misused, or even stolen by models without accessing the original audio files. Traditional methods like copyright licensing and digital watermarking offer limited protection for these abstract mathematical representations, thus necessitating a stronger, e.g., cryptographic, approach to safeguarding the embeddings themselves. Standard encryption schemes, such as AES, render data unintelligible for computation, making such searches impossible. While Fully Homomorphic Encryption (FHE) provides a plausible solution by allowing arbitrary computations on ciphertexts, its substantial performance overhead remains impractical for large-scale vector similarity searches. Given this trade-off, we propose a more practical approach using Additive Homomorphic Encryption (AHE) for vector similarity search. The primary contributions of this paper are threefold: we analyze threat models unique to music information retrieval systems; we provide a theoretical analysis and propose an efficient AHE-based solution through inner products of music embeddings to deliver privacy-preserving similarity search; and finally, we demonstrate the efficiency and practicality of the proposed approach through empirical evaluation and comparison to FHE schemes on real-world MP3 files.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.07044v1",
    "published_date": "2025-08-09 17:00:34 UTC",
    "updated_date": "2025-08-09 17:00:34 UTC"
  },
  {
    "arxiv_id": "2508.07043v2",
    "title": "K-Dense Analyst: Towards Fully Automated Scientific Analysis",
    "authors": [
      "Orion Li",
      "Vinayak Agarwal",
      "Summer Zhou",
      "Ashwin Gopinath",
      "Timothy Kassis"
    ],
    "abstract": "The complexity of modern bioinformatics analysis has created a critical gap between data generation and developing scientific insights. While large language models (LLMs) have shown promise in scientific reasoning, they remain fundamentally limited when dealing with real-world analytical workflows that demand iterative computation, tool integration and rigorous validation. We introduce K-Dense Analyst, a hierarchical multi-agent system that achieves autonomous bioinformatics analysis through a dual-loop architecture. K-Dense Analyst, part of the broader K-Dense platform, couples planning with validated execution using specialized agents to decompose complex objectives into executable, verifiable tasks within secure computational environments. On BixBench, a comprehensive benchmark for open-ended biological analysis, K-Dense Analyst achieves 29.2% accuracy, surpassing the best-performing language model (GPT-5) by 6.3 percentage points, representing nearly 27% improvement over what is widely considered the most powerful LLM available. Remarkably, K-Dense Analyst achieves this performance using Gemini 2.5 Pro, which attains only 18.3% accuracy when used directly, demonstrating that our architectural innovations unlock capabilities far beyond the underlying model's baseline performance. Our insights demonstrate that autonomous scientific reasoning requires more than enhanced language models, it demands purpose-built systems that can bridge the gap between high-level scientific objectives and low-level computational execution. These results represent a significant advance toward fully autonomous computational biologists capable of accelerating discovery across the life sciences.",
    "categories": [
      "cs.AI",
      "cs.MA",
      "q-bio.GN",
      "q-bio.QM"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.07043v2",
    "published_date": "2025-08-09 16:59:55 UTC",
    "updated_date": "2025-09-29 23:01:20 UTC"
  },
  {
    "arxiv_id": "2508.16599v2",
    "title": "Humans Perceive Wrong Narratives from AI Reasoning Texts",
    "authors": [
      "Mosh Levy",
      "Zohar Elyoseph",
      "Yoav Goldberg"
    ],
    "abstract": "A new generation of AI models generates step-by-step reasoning text before producing an answer. This text appears to offer a human-readable window into their computation process, and is increasingly relied upon for transparency and interpretability. However, it is unclear whether human understanding of this text matches the model's actual computational process. In this paper, we investigate a necessary condition for correspondence: the ability of humans to identify which steps in a reasoning text causally influence later steps. We evaluated humans on this ability by composing questions based on counterfactual measurements and found a significant discrepancy: participant accuracy was only 29%, barely above chance (25%), and remained low (42%) even when evaluating the majority vote on questions with high agreement. Our results reveal a fundamental gap between how humans interpret reasoning texts and how models use it, challenging its utility as a simple interpretability tool. We argue that reasoning texts should be treated as an artifact to be investigated, not taken at face value, and that understanding the non-human ways these models use language is a critical research direction.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.16599v2",
    "published_date": "2025-08-09 16:29:10 UTC",
    "updated_date": "2025-08-28 11:53:23 UTC"
  },
  {
    "arxiv_id": "2508.07031v1",
    "title": "Trustworthy Medical Imaging with Large Language Models: A Study of Hallucinations Across Modalities",
    "authors": [
      "Anindya Bijoy Das",
      "Shahnewaz Karim Sakib",
      "Shibbir Ahmed"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly applied to medical imaging tasks, including image interpretation and synthetic image generation. However, these models often produce hallucinations, which are confident but incorrect outputs that can mislead clinical decisions. This study examines hallucinations in two directions: image to text, where LLMs generate reports from X-ray, CT, or MRI scans, and text to image, where models create medical images from clinical prompts. We analyze errors such as factual inconsistencies and anatomical inaccuracies, evaluating outputs using expert informed criteria across imaging modalities. Our findings reveal common patterns of hallucination in both interpretive and generative tasks, with implications for clinical reliability. We also discuss factors contributing to these failures, including model architecture and training data. By systematically studying both image understanding and generation, this work provides insights into improving the safety and trustworthiness of LLM driven medical imaging systems.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.07031v1",
    "published_date": "2025-08-09 16:03:46 UTC",
    "updated_date": "2025-08-09 16:03:46 UTC"
  },
  {
    "arxiv_id": "2508.07029v2",
    "title": "From Imitation to Optimization: A Comparative Study of Offline Learning for Autonomous Driving",
    "authors": [
      "Antonio Guillen-Perez"
    ],
    "abstract": "Learning robust driving policies from large-scale, real-world datasets is a central challenge in autonomous driving, as online data collection is often unsafe and impractical. While Behavioral Cloning (BC) offers a straightforward approach to imitation learning, policies trained with BC are notoriously brittle and suffer from compounding errors in closed-loop execution. This work presents a comprehensive pipeline and a comparative study to address this limitation. We first develop a series of increasingly sophisticated BC baselines, culminating in a Transformer-based model that operates on a structured, entity-centric state representation. While this model achieves low imitation loss, we show that it still fails in long-horizon simulations. We then demonstrate that by applying a state-of-the-art Offline Reinforcement Learning algorithm, Conservative Q-Learning (CQL), to the same data and architecture, we can learn a significantly more robust policy. Using a carefully engineered reward function, the CQL agent learns a conservative value function that enables it to recover from minor errors and avoid out-of-distribution states. In a large-scale evaluation on 1,000 unseen scenarios from the Waymo Open Motion Dataset, our final CQL agent achieves a 3.2x higher success rate and a 7.4x lower collision rate than the strongest BC baseline, proving that an offline RL approach is critical for learning robust, long-horizon driving policies from static expert data.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.07029v2",
    "published_date": "2025-08-09 16:03:10 UTC",
    "updated_date": "2025-08-27 14:32:13 UTC"
  },
  {
    "arxiv_id": "2508.07027v1",
    "title": "Making Effective Decisions: Machine Learning and the Ecogame in 1970",
    "authors": [
      "Catherine Mason"
    ],
    "abstract": "This paper considers Ecogame, an innovative art project of 1970, whose creators believed in a positive vision of a technological future; an understanding, posited on cybernetics, of a future that could be participatory via digital means, and therefore more democratised. Using simulation and early machine learning techniques over a live network, Ecogame combined the power of visual art with cybernetic concepts of adaptation, feedback, and control to propose that behaviour had implications for the total system. It provides an historical precedent for contemporary AI-driven art about using AI in a more human-centred way.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "In Proceedings of Explainable AI for the Arts Workshop 2025 (XAIxArts 2025) arXiv:2406.14485",
    "pdf_url": "https://arxiv.org/pdf/2508.07027v1",
    "published_date": "2025-08-09 15:51:26 UTC",
    "updated_date": "2025-08-09 15:51:26 UTC"
  },
  {
    "arxiv_id": "2508.10033v1",
    "title": "Cognitive Cybersecurity for Artificial Intelligence: Guardrail Engineering with CCS-7",
    "authors": [
      "Yuksel Aydin"
    ],
    "abstract": "Language models exhibit human-like cognitive vulnerabilities, such as emotional framing, that escape traditional behavioral alignment. We present CCS-7 (Cognitive Cybersecurity Suite), a taxonomy of seven vulnerabilities grounded in human cognitive security research. To establish a human benchmark, we ran a randomized controlled trial with 151 participants: a \"Think First, Verify Always\" (TFVA) lesson improved cognitive security by +7.9% overall. We then evaluated TFVA-style guardrails across 12,180 experiments on seven diverse language model architectures. Results reveal architecture-dependent risk patterns: some vulnerabilities (e.g., identity confusion) are almost fully mitigated, while others (e.g., source interference) exhibit escalating backfire, with error rates increasing by up to 135% in certain models. Humans, in contrast, show consistent moderate improvement. These findings reframe cognitive safety as a model-specific engineering problem: interventions effective in one architecture may fail, or actively harm, another, underscoring the need for architecture-aware cognitive safety testing before deployment.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.10033v1",
    "published_date": "2025-08-09 15:46:30 UTC",
    "updated_date": "2025-08-09 15:46:30 UTC"
  },
  {
    "arxiv_id": "2508.07022v1",
    "title": "MultiMedEdit: A Scenario-Aware Benchmark for Evaluating Knowledge Editing in Medical VQA",
    "authors": [
      "Shengtao Wen",
      "Haodong Chen",
      "Yadong Wang",
      "Zhongying Pan",
      "Xiang Chen",
      "Yu Tian",
      "Bo Qian",
      "Dong Liang",
      "Sheng-Jun Huang"
    ],
    "abstract": "Knowledge editing (KE) provides a scalable approach for updating factual knowledge in large language models without full retraining. While previous studies have demonstrated effectiveness in general domains and medical QA tasks, little attention has been paid to KE in multimodal medical scenarios. Unlike text-only settings, medical KE demands integrating updated knowledge with visual reasoning to support safe and interpretable clinical decisions. To address this gap, we propose MultiMedEdit, the first benchmark tailored to evaluating KE in clinical multimodal tasks. Our framework spans both understanding and reasoning task types, defines a three-dimensional metric suite (reliability, generality, and locality), and supports cross-paradigm comparisons across general and domain-specific models. We conduct extensive experiments under single-editing and lifelong-editing settings. Results suggest that current methods struggle with generalization and long-tail reasoning, particularly in complex clinical workflows. We further present an efficiency analysis (e.g., edit latency, memory footprint), revealing practical trade-offs in real-world deployment across KE paradigms. Overall, MultiMedEdit not only reveals the limitations of current approaches but also provides a solid foundation for developing clinically robust knowledge editing techniques in the future.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.AI",
    "comment": "Under Review",
    "pdf_url": "https://arxiv.org/pdf/2508.07022v1",
    "published_date": "2025-08-09 15:36:08 UTC",
    "updated_date": "2025-08-09 15:36:08 UTC"
  },
  {
    "arxiv_id": "2508.07015v2",
    "title": "Efficient and Reliable Hitting-Set Computations for the Implicit Hitting Set Approach",
    "authors": [
      "Hannes Ihalainen",
      "Dieter Vandesande",
      "André Schidler",
      "Jeremias Berg",
      "Bart Bogaerts",
      "Matti Järvisalo"
    ],
    "abstract": "The implicit hitting set (IHS) approach offers a general framework for solving computationally hard combinatorial optimization problems declaratively. IHS iterates between a decision oracle used for extracting sources of inconsistency and an optimizer for computing so-called hitting sets (HSs) over the accumulated sources of inconsistency. While the decision oracle is language-specific, the optimizers is usually instantiated through integer programming.\n  We explore alternative algorithmic techniques for hitting set optimization based on different ways of employing pseudo-Boolean (PB) reasoning as well as stochastic local search. We extensively evaluate the practical feasibility of the alternatives in particular in the context of pseudo-Boolean (0-1 IP) optimization as one of the most recent instantiations of IHS. Highlighting a trade-off between efficiency and reliability, while a commercial IP solver turns out to remain the most effective way to instantiate HS computations, it can cause correctness issues due to numerical instability; in fact, we show that exact HS computations instantiated via PB reasoning can be made competitive with a numerically exact IP solver. Furthermore, the use of PB reasoning as a basis for HS computations allows for obtaining certificates for the correctness of IHS computations, generally applicable to any IHS instantiation in which reasoning in the declarative language at hand can be captured in the PB-based proof format we employ.",
    "categories": [
      "cs.AI",
      "cs.DS"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted for publication in the proceedings of AAAI 2026",
    "pdf_url": "https://arxiv.org/pdf/2508.07015v2",
    "published_date": "2025-08-09 15:27:36 UTC",
    "updated_date": "2025-11-17 08:14:51 UTC"
  },
  {
    "arxiv_id": "2508.07014v2",
    "title": "TurboBias: Universal ASR Context-Biasing powered by GPU-accelerated Phrase-Boosting Tree",
    "authors": [
      "Andrei Andrusenko",
      "Vladimir Bataev",
      "Lilit Grigoryan",
      "Vitaly Lavrukhin",
      "Boris Ginsburg"
    ],
    "abstract": "Recognizing specific key phrases is an essential task for contextualized Automatic Speech Recognition (ASR). However, most existing context-biasing approaches have limitations associated with the necessity of additional model training, significantly slow down the decoding process, or constrain the choice of the ASR system type. This paper proposes a universal ASR context-biasing framework that supports all major types: CTC, Transducers, and Attention Encoder-Decoder models. The framework is based on a GPU-accelerated word boosting tree, which enables it to be used in shallow fusion mode for greedy and beam search decoding without noticeable speed degradation, even with a vast number of key phrases (up to 20K items). The obtained results showed high efficiency of the proposed method, surpassing the considered open-source context-biasing approaches in accuracy and decoding speed. Our context-biasing framework is open-sourced as a part of the NeMo toolkit.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "Accepted to ASRU 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.07014v2",
    "published_date": "2025-08-09 15:27:07 UTC",
    "updated_date": "2025-08-12 14:25:57 UTC"
  },
  {
    "arxiv_id": "2508.07009v1",
    "title": "Neural Channel Knowledge Map Assisted Scheduling Optimization of Active IRSs in Multi-User Systems",
    "authors": [
      "Xintong Chen",
      "Zhenyu Jiang",
      "Jiangbin Lyu",
      "Liqun Fu"
    ],
    "abstract": "Intelligent Reflecting Surfaces (IRSs) have potential for significant performance gains in next-generation wireless networks but face key challenges, notably severe double-pathloss and complex multi-user scheduling due to hardware constraints. Active IRSs partially address pathloss but still require efficient scheduling in cell-level multi-IRS multi-user systems, whereby the overhead/delay of channel state acquisition and the scheduling complexity both rise dramatically as the user density and channel dimensions increase. Motivated by these challenges, this paper proposes a novel scheduling framework based on neural Channel Knowledge Map (CKM), designing Transformer-based deep neural networks (DNNs) to predict ergodic spectral efficiency (SE) from historical channel/throughput measurements tagged with user positions. Specifically, two cascaded networks, LPS-Net and SE-Net, are designed to predict link power statistics (LPS) and ergodic SE accurately. We further propose a low-complexity Stable Matching-Iterative Balancing (SM-IB) scheduling algorithm. Numerical evaluations verify that the proposed neural CKM significantly enhances prediction accuracy and computational efficiency, while the SM-IB algorithm effectively achieves near-optimal max-min throughput with greatly reduced complexity.",
    "categories": [
      "cs.IT",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IT",
    "comment": "Propose Neural Channel Knowledge Map for multi-user scheduling",
    "pdf_url": "https://arxiv.org/pdf/2508.07009v1",
    "published_date": "2025-08-09 15:14:03 UTC",
    "updated_date": "2025-08-09 15:14:03 UTC"
  },
  {
    "arxiv_id": "2508.08322v1",
    "title": "Context Engineering for Multi-Agent LLM Code Assistants Using Elicit, NotebookLM, ChatGPT, and Claude Code",
    "authors": [
      "Muhammad Haseeb"
    ],
    "abstract": "Large Language Models (LLMs) have shown promise in automating code generation and software engineering tasks, yet they often struggle with complex, multi-file projects due to context limitations and knowledge gaps. We propose a novel context engineering workflow that combines multiple AI components: an Intent Translator (GPT-5) for clarifying user requirements, an Elicit-powered semantic literature retrieval for injecting domain knowledge, NotebookLM-based document synthesis for contextual understanding, and a Claude Code multi-agent system for code generation and validation. Our integrated approach leverages intent clarification, retrieval-augmented generation, and specialized sub-agents orchestrated via Claude's agent framework. We demonstrate that this method significantly improves the accuracy and reliability of code assistants in real-world repositories, yielding higher single-shot success rates and better adherence to project context than baseline single-agent approaches. Qualitative results on a large Next.js codebase show the multi-agent system effectively plans, edits, and tests complex features with minimal human intervention. We compare our system with recent frameworks like CodePlan, MASAI, and HyperAgent, highlighting how targeted context injection and agent role decomposition lead to state-of-the-art performance. Finally, we discuss the implications for deploying LLM-based coding assistants in production, along with lessons learned on context management and future research directions.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "15 pages, 5 figures, research paper on multi-agent LLM systems for code generation",
    "pdf_url": "https://arxiv.org/pdf/2508.08322v1",
    "published_date": "2025-08-09 14:45:53 UTC",
    "updated_date": "2025-08-09 14:45:53 UTC"
  },
  {
    "arxiv_id": "2508.07001v1",
    "title": "Consensus-based Decentralized Multi-agent Reinforcement Learning for Random Access Network Optimization",
    "authors": [
      "Myeung Suk Oh",
      "Zhiyao Zhang",
      "FNU Hairi",
      "Alvaro Velasquez",
      "Jia Liu"
    ],
    "abstract": "With wireless devices increasingly forming a unified smart network for seamless, user-friendly operations, random access (RA) medium access control (MAC) design is considered a key solution for handling unpredictable data traffic from multiple terminals. However, it remains challenging to design an effective RA-based MAC protocol to minimize collisions and ensure transmission fairness across the devices. While existing multi-agent reinforcement learning (MARL) approaches with centralized training and decentralized execution (CTDE) have been proposed to optimize RA performance, their reliance on centralized training and the significant overhead required for information collection can make real-world applications unrealistic. In this work, we adopt a fully decentralized MARL architecture, where policy learning does not rely on centralized tasks but leverages consensus-based information exchanges across devices. We design our MARL algorithm over an actor-critic (AC) network and propose exchanging only local rewards to minimize communication overhead. Furthermore, we provide a theoretical proof of global convergence for our approach. Numerical experiments show that our proposed MARL algorithm can significantly improve RA network performance compared to other baselines.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NI",
    "comment": "This paper has been accepted in ACM International Symposium on Theory, Algorithmic Foundations, and Protocol Design for Mobile Networks and Mobile Computing (MobiHoc) 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.07001v1",
    "published_date": "2025-08-09 14:39:27 UTC",
    "updated_date": "2025-08-09 14:39:27 UTC"
  },
  {
    "arxiv_id": "2508.11681v1",
    "title": "Future progress in artificial intelligence: A survey of expert opinion",
    "authors": [
      "Vincent C. Müller",
      "Nick Bostrom"
    ],
    "abstract": "There is, in some quarters, concern about high-level machine intelligence and superintelligent AI coming up in a few decades, bringing with it significant risks for humanity. In other quarters, these issues are ignored or considered science fiction. We wanted to clarify what the distribution of opinions actually is, what probability the best experts currently assign to high-level machine intelligence coming up within a particular time-frame, which risks they see with that development, and how fast they see these developing. We thus designed a brief questionnaire and distributed it to four groups of experts in 2012/2013. The median estimate of respondents was for a one in two chance that high-level machine intelligence will be developed around 2040-2050, rising to a nine in ten chance by 2075. Experts expect that systems will move on to superintelligence in less than 30 years thereafter. They estimate the chance is about one in three that this development turns out to be 'bad' or 'extremely bad' for humanity.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.11681v1",
    "published_date": "2025-08-09 14:34:53 UTC",
    "updated_date": "2025-08-09 14:34:53 UTC"
  },
  {
    "arxiv_id": "2508.06997v1",
    "title": "Conformal Set-based Human-AI Complementarity with Multiple Experts",
    "authors": [
      "Helbert Paat",
      "Guohao Shen"
    ],
    "abstract": "Decision support systems are designed to assist human experts in classification tasks by providing conformal prediction sets derived from a pre-trained model. This human-AI collaboration has demonstrated enhanced classification performance compared to using either the model or the expert independently. In this study, we focus on the selection of instance-specific experts from a pool of multiple human experts, contrasting it with existing research that typically focuses on single-expert scenarios. We characterize the conditions under which multiple experts can benefit from the conformal sets. With the insight that only certain experts may be relevant for each instance, we explore the problem of subset selection and introduce a greedy algorithm that utilizes conformal sets to identify the subset of expert predictions that will be used in classifying an instance. This approach is shown to yield better performance compared to naive methods for human subset selection. Based on real expert predictions from the CIFAR-10H and ImageNet-16H datasets, our simulation study indicates that our proposed greedy algorithm achieves near-optimal subsets, resulting in improved classification performance among multiple experts.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.HC",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at AAMAS 2025. Code available at: https://github.com/paathelb/conformal_hai_multiple",
    "pdf_url": "https://arxiv.org/pdf/2508.06997v1",
    "published_date": "2025-08-09 14:17:51 UTC",
    "updated_date": "2025-08-09 14:17:51 UTC"
  },
  {
    "arxiv_id": "2508.14058v1",
    "title": "Dual-Phase Playtime-guided Recommendation: Interest Intensity Exploration and Multimodal Random Walks",
    "authors": [
      "Jingmao Zhang",
      "Zhiting Zhao",
      "Yunqi Lin",
      "Jianghong Ma",
      "Tianjun Wei",
      "Haijun Zhang",
      "Xiaofeng Zhang"
    ],
    "abstract": "The explosive growth of the video game industry has created an urgent need for recommendation systems that can scale with expanding catalogs and maintain user engagement. While prior work has explored accuracy and diversity in recommendations, existing models underutilize playtime, a rich behavioral signal unique to gaming platforms, and overlook the potential of multimodal information to enhance diversity. In this paper, we propose DP2Rec, a novel Dual-Phase Playtime-guided Recommendation model designed to jointly optimize accuracy and diversity. First, we introduce a playtime-guided interest intensity exploration module that separates strong and weak preferences via dual-beta modeling, enabling fine-grained user profiling and more accurate recommendations. Second, we present a playtime-guided multimodal random walks module that simulates player exploration using transitions guided by both playtime-derived interest similarity and multimodal semantic similarity. This mechanism preserves core preferences while promoting cross-category discovery through latent semantic associations and adaptive category balancing. Extensive experiments on a real-world game dataset show that DP2Rec outperforms existing methods in both recommendation accuracy and diversity.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted for publication at ACM Multimedia (ACM MM) 2025. 10 pages, 5 figures. Code and dataset: https://github.com/zqxwcevrtyui/DP2Rec",
    "pdf_url": "https://arxiv.org/pdf/2508.14058v1",
    "published_date": "2025-08-09 13:51:00 UTC",
    "updated_date": "2025-08-09 13:51:00 UTC"
  },
  {
    "arxiv_id": "2508.06982v5",
    "title": "WeatherDiffusion: Controllable Weather Editing in Intrinsic Space",
    "authors": [
      "Yixin Zhu",
      "Zuoliang Zhu",
      "Jian Yang",
      "Miloš Hašan",
      "Jin Xie",
      "Beibei Wang"
    ],
    "abstract": "We present WeatherDiffusion, a diffusion-based framework for controllable weather editing in intrinsic space. Our framework includes two components based on diffusion priors: an inverse renderer that estimates material properties, scene geometry, and lighting as intrinsic maps from an input image, and a forward renderer that utilizes these geometry and material maps along with a text prompt that describes specific weather conditions to generate a final image. The intrinsic maps enhance controllability compared to traditional pixel-space editing approaches. We propose an intrinsic map-aware attention mechanism that improves spatial correspondence and decomposition quality in large outdoor scenes. For forward rendering, we leverage CLIP-space interpolation of weather prompts to achieve fine-grained weather control. We also introduce a synthetic and a real-world dataset, containing 38k and 18k images under various weather conditions, each with intrinsic map annotations. WeatherDiffusion outperforms state-of-the-art pixel-space editing approaches, weather restoration methods, and rendering-based methods, showing promise for downstream tasks such as autonomous driving, enhancing the robustness of detection and segmentation in challenging weather scenarios.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.06982v5",
    "published_date": "2025-08-09 13:29:39 UTC",
    "updated_date": "2026-01-07 07:13:27 UTC"
  },
  {
    "arxiv_id": "2508.06980v1",
    "title": "Simulating Biological Intelligence: Active Inference with Experiment-Informed Generative Model",
    "authors": [
      "Aswin Paul",
      "Moein Khajehnejad",
      "Forough Habibollahi",
      "Brett J. Kagan",
      "Adeel Razi"
    ],
    "abstract": "With recent and rapid advancements in artificial intelligence (AI), understanding the foundation of purposeful behaviour in autonomous agents is crucial for developing safe and efficient systems. While artificial neural networks have dominated the path to AI, recent studies are exploring the potential of biologically based systems, such as networks of living biological neuronal networks. Along with promises of high power and data efficiency, these systems may also inform more explainable and biologically plausible models. In this work, we propose a framework rooted in active inference, a general theory of behaviour, to model decision-making in embodied agents. Using experiment-informed generative models, we simulate decision-making processes in a simulated game-play environment, mirroring experimental setups that use biological neurons. Our results demonstrate learning in these agents, providing insights into the role of memory-based learning and predictive planning in intelligent decision-making. This work contributes to the growing field of explainable AI by offering a biologically grounded and scalable approach to understanding purposeful behaviour in agents.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "18 pages, 8 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.06980v1",
    "published_date": "2025-08-09 13:26:38 UTC",
    "updated_date": "2025-08-09 13:26:38 UTC"
  },
  {
    "arxiv_id": "2508.06972v3",
    "title": "DSperse: A Framework for Targeted Verification in Zero-Knowledge Machine Learning",
    "authors": [
      "Dan Ivanov",
      "Tristan Freiberg",
      "Shirin Shahabi",
      "Jonathan Gold",
      "Haruna Isah"
    ],
    "abstract": "DSperse is a modular framework for distributed machine learning inference with strategic cryptographic verification. Operating within the emerging paradigm of distributed zero-knowledge machine learning, DSperse avoids the high cost and rigidity of full-model circuitization by enabling targeted verification of strategically chosen subcomputations. These verifiable segments, or \"slices\", may cover part or all of the inference pipeline, with global consistency enforced through audit, replication, or economic incentives. This architecture supports a pragmatic form of trust minimization, localizing zero-knowledge proofs to the components where they provide the greatest value. We evaluate DSperse using multiple proving systems and report empirical results on memory usage, runtime, and circuit behavior under sliced and unsliced configurations. By allowing proof boundaries to align flexibly with the model's logical structure, DSperse supports scalable, targeted verification strategies suited to diverse deployment needs.",
    "categories": [
      "cs.AI",
      "cs.CR",
      "cs.DC",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "12 pages, 8 figures, and 10 tables",
    "pdf_url": "https://arxiv.org/pdf/2508.06972v3",
    "published_date": "2025-08-09 12:38:18 UTC",
    "updated_date": "2025-09-18 03:15:13 UTC"
  },
  {
    "arxiv_id": "2508.06966v1",
    "title": "Can Multitask Learning Enhance Model Explainability?",
    "authors": [
      "Hiba Najjar",
      "Bushra Alshbib",
      "Andreas Dengel"
    ],
    "abstract": "Remote sensing provides satellite data in diverse types and formats. The usage of multimodal learning networks exploits this diversity to improve model performance, except that the complexity of such networks comes at the expense of their interpretability. In this study, we explore how modalities can be leveraged through multitask learning to intrinsically explain model behavior. In particular, instead of additional inputs, we use certain modalities as additional targets to be predicted along with the main task. The success of this approach relies on the rich information content of satellite data, which remains as input modalities. We show how this modeling context provides numerous benefits: (1) in case of data scarcity, the additional modalities do not need to be collected for model inference at deployment, (2) the model performance remains comparable to the multimodal baseline performance, and in some cases achieves better scores, (3) prediction errors in the main task can be explained via the model behavior in the auxiliary task(s). We demonstrate the efficiency of our approach on three datasets, including segmentation, classification, and regression tasks. Code available at git.opendfki.de/hiba.najjar/mtl_explainability/.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at GCPR 2025, Special Track \"Photogrammetry and remote sensing\"",
    "pdf_url": "https://arxiv.org/pdf/2508.06966v1",
    "published_date": "2025-08-09 12:24:48 UTC",
    "updated_date": "2025-08-09 12:24:48 UTC"
  },
  {
    "arxiv_id": "2508.06963v1",
    "title": "MASteer: Multi-Agent Adaptive Steer Strategy for End-to-End LLM Trustworthiness Repair",
    "authors": [
      "Changqing Li",
      "Tianlin Li",
      "Xiaohan Zhang",
      "Aishan Liu",
      "Li Pan"
    ],
    "abstract": "Large Language Models (LLMs) face persistent and evolving trustworthiness issues, motivating developers to seek automated and flexible repair methods that enable convenient deployment across diverse scenarios. Existing repair methods like supervised fine-tuning (SFT) and reinforcement learning with human feedback (RLHF) are costly and slow, while prompt engineering lacks robustness and scalability. Representation engineering, which steers model behavior by injecting targeted concept vectors during inference, offers a lightweight, training-free alternative. However, current approaches depend on manually crafted samples and fixed steering strategies, limiting automation and adaptability. To overcome these challenges, we propose MASteer, the first end-to-end framework for trustworthiness repair in LLMs based on representation engineering. MASteer integrates two core components: AutoTester, a multi-agent system that generates diverse, high-quality steer samples tailored to developer needs; and AutoRepairer, which constructs adaptive steering strategies with anchor vectors for automated, context-aware strategy selection during inference. Experiments on standard and customized trustworthiness tasks show MASteer consistently outperforms baselines, improving metrics by 15.36% on LLaMA-3.1-8B-Chat and 4.21% on Qwen-3-8B-Chat, while maintaining general model capabilities. MASteer demonstrates strong robustness, generalization, and practical value for scalable, efficient trustworthiness repair.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.06963v1",
    "published_date": "2025-08-09 12:20:00 UTC",
    "updated_date": "2025-08-09 12:20:00 UTC"
  },
  {
    "arxiv_id": "2508.06960v1",
    "title": "DatasetResearch: Benchmarking Agent Systems for Demand-Driven Dataset Discovery",
    "authors": [
      "Keyu Li",
      "Mohan Jiang",
      "Dayuan Fu",
      "Yunze Wu",
      "Xiangkun Hu",
      "Dequan Wang",
      "Pengfei Liu"
    ],
    "abstract": "The rapid advancement of large language models has fundamentally shifted the bottleneck in AI development from computational power to data availability-with countless valuable datasets remaining hidden across specialized repositories, research appendices, and domain platforms. As reasoning capabilities and deep research methodologies continue to evolve, a critical question emerges: can AI agents transcend conventional search to systematically discover any dataset that meets specific user requirements, enabling truly autonomous demand-driven data curation? We introduce DatasetResearch, the first comprehensive benchmark evaluating AI agents' ability to discover and synthesize datasets from 208 real-world demands across knowledge-intensive and reasoning-intensive tasks. Our tri-dimensional evaluation framework reveals a stark reality: even advanced deep research systems achieve only 22% score on our challenging DatasetResearch-pro subset, exposing the vast gap between current capabilities and perfect dataset discovery. Our analysis uncovers a fundamental dichotomy-search agents excel at knowledge tasks through retrieval breadth, while synthesis agents dominate reasoning challenges via structured generation-yet both catastrophically fail on \"corner cases\" outside existing distributions. These findings establish the first rigorous baseline for dataset discovery agents and illuminate the path toward AI systems capable of finding any dataset in the digital universe. Our benchmark and comprehensive analysis provide the foundation for the next generation of self-improving AI systems and are publicly available at https://github.com/GAIR-NLP/DatasetResearch.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.06960v1",
    "published_date": "2025-08-09 12:15:08 UTC",
    "updated_date": "2025-08-09 12:15:08 UTC"
  },
  {
    "arxiv_id": "2508.06959v2",
    "title": "Beyond Frequency: Seeing Subtle Cues Through the Lens of Spatial Decomposition for Fine-Grained Visual Classification",
    "authors": [
      "Qin Xu",
      "Lili Zhu",
      "Xiaoxia Cheng",
      "Bo Jiang"
    ],
    "abstract": "The crux of resolving fine-grained visual classification (FGVC) lies in capturing discriminative and class-specific cues that correspond to subtle visual characteristics. Recently, frequency decomposition/transform based approaches have attracted considerable interests since its appearing discriminative cue mining ability. However, the frequency-domain methods are based on fixed basis functions, lacking adaptability to image content and unable to dynamically adjust feature extraction according to the discriminative requirements of different images. To address this, we propose a novel method for FGVC, named Subtle-Cue Oriented Perception Engine (SCOPE), which adaptively enhances the representational capability of low-level details and high-level semantics in the spatial domain, breaking through the limitations of fixed scales in the frequency domain and improving the flexibility of multi-scale fusion. The core of SCOPE lies in two modules: the Subtle Detail Extractor (SDE), which dynamically enhances subtle details such as edges and textures from shallow features, and the Salient Semantic Refiner (SSR), which learns semantically coherent and structure-aware refinement features from the high-level features guided by the enhanced shallow features. The SDE and SSR are cascaded stage-by-stage to progressively combine local details with global semantics. Extensive experiments demonstrate that our method achieves new state-of-the-art on four popular fine-grained image classification benchmarks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "After supplementary experiments and careful review, minor inconsistencies in prompt template configuration and partial experimental parameter records were identified. To ensure research accuracy, rigor, and reproducibility, we will revise technical descriptions, verify results with standardized parameters, and resubmit a polished version soon. Apologies for any inconvenience",
    "pdf_url": "https://arxiv.org/pdf/2508.06959v2",
    "published_date": "2025-08-09 12:13:40 UTC",
    "updated_date": "2025-11-13 08:34:25 UTC"
  },
  {
    "arxiv_id": "2508.06956v2",
    "title": "Neural Beam Field for Spatial Beam RSRP Prediction",
    "authors": [
      "Keqiang Guo",
      "Yuheng Zhong",
      "Xin Tong",
      "Jiangbin Lyu",
      "Rui Zhang"
    ],
    "abstract": "Accurately predicting beam-level reference signal received power (RSRP) is essential for beam management in dense multi-user wireless networks, yet challenging due to high measurement overhead and fast channel variations. This paper proposes Neural Beam Field (NBF), a hybrid neural-physical framework for efficient and interpretable spatial beam RSRP prediction. Central to our approach is the introduction of the Multi-path Conditional Power Profile (MCPP), a learnable physical intermediary representing the site-specific propagation environment. This approach decouples the environment from specific antenna/beam configurations, which helps the model learn site-specific multipath features and enhances its generalization capability. We adopt a decoupled ``blackbox-whitebox\" design: a Transformer-based deep neural network (DNN) learns the MCPP from sparse user measurements and positions, while a physics-inspired module analytically infers beam RSRP statistics. To improve convergence and adaptivity, we further introduce a Pretrain-and-Calibrate (PaC) strategy that leverages ray-tracing priors for physics-grounded pretraining and then RSRP data for on-site calibration. Extensive simulation results demonstrate that NBF significantly outperforms conventional table-based channel knowledge maps (CKMs) and pure blackbox DNNs in prediction accuracy, training efficiency, and generalization, while maintaining a compact model size. The proposed framework offers a scalable and physically grounded solution for intelligent beam management in next-generation dense wireless networks.",
    "categories": [
      "cs.IT",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IT",
    "comment": "Keywords: Neural Beam Field, Multipath Conditional Power Profile, Channel Knowledge Map, Beam-level RSRP, Transformer. Revised technical presentation and added more benchmark comparisons",
    "pdf_url": "https://arxiv.org/pdf/2508.06956v2",
    "published_date": "2025-08-09 12:05:51 UTC",
    "updated_date": "2025-10-10 15:23:25 UTC"
  },
  {
    "arxiv_id": "2508.06950v3",
    "title": "Large Language Models Do Not Simulate Human Psychology",
    "authors": [
      "Sarah Schröder",
      "Thekla Morgenroth",
      "Ulrike Kuhl",
      "Valerie Vaquet",
      "Benjamin Paaßen"
    ],
    "abstract": "Large Language Models (LLMs),such as ChatGPT, are increasingly used in research, ranging from simple writing assistance to complex data annotation tasks. Recently, some research has suggested that LLMs may even be able to simulate human psychology and can, hence, replace human participants in psychological studies. We caution against this approach. We provide conceptual arguments against the hypothesis that LLMs simulate human psychology. We then present empiric evidence illustrating our arguments by demonstrating that slight changes to wording that correspond to large changes in meaning lead to notable discrepancies between LLMs' and human responses, even for the recent CENTAUR model that was specifically fine-tuned on psychological responses. Additionally, different LLMs show very different responses to novel items, further illustrating their lack of reliability. We conclude that LLMs do not simulate human psychology and recommend that psychological researchers should treat LLMs as useful but fundamentally unreliable tools that need to be validated against human responses for every new application.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.06950v3",
    "published_date": "2025-08-09 11:56:59 UTC",
    "updated_date": "2025-08-13 14:59:57 UTC"
  },
  {
    "arxiv_id": "2508.06944v3",
    "title": "AMFT: Aligning LLM Reasoners by Meta-Learning the Optimal Imitation-Exploration Balance",
    "authors": [
      "Lixuan He",
      "Jie Feng",
      "Yong Li"
    ],
    "abstract": "Large Language Models (LLMs) are typically fine-tuned for reasoning tasks through a two-stage pipeline of Supervised Fine-Tuning (SFT) followed by Reinforcement Learning (RL), a process fraught with catastrophic forgetting and suboptimal trade-offs between imitation and exploration. Recent single-stage methods attempt to unify SFT and RL using heuristics, but lack a principled mechanism for dynamically balancing the two paradigms. In this paper, we reframe this challenge through the theoretical lens of \\textbf{implicit rewards}, viewing SFT and RL not as distinct methods but as complementary reward signals. We introduce \\textbf{Adaptive Meta Fine-Tuning (AMFT)}, a novel single-stage algorithm that learns the optimal balance between SFT's implicit, path-level reward and RL's explicit, outcome-based reward. The core of AMFT is a \\textbf{meta-gradient adaptive weight controller} that treats the SFT-RL balance as a learnable parameter, dynamically optimizing it to maximize long-term task performance. This forward-looking approach, regularized by policy entropy for stability, autonomously discovers an effective training curriculum. We conduct a comprehensive evaluation on challenging benchmarks spanning mathematical reasoning, abstract visual reasoning (General Points), and vision-language navigation (V-IRL). AMFT consistently establishes a new state-of-the-art and demonstrats superior generalization on out-of-distribution (OOD) tasks. Ablation studies and training dynamic analysis confirm that the meta-learning controller is crucial for AMFT's stability, sample efficiency, and performance, offering a more principled and effective paradigm for LLM alignment. Our codes are open-sourced via https://github.com/hlxtsyj/AMFT.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "The paper is currently under investigation regarding concerns of potential academic misconduct. While the investigation is ongoing, the authors have voluntarily requested to withdraw the manuscript",
    "pdf_url": "https://arxiv.org/pdf/2508.06944v3",
    "published_date": "2025-08-09 11:40:54 UTC",
    "updated_date": "2025-10-10 13:08:20 UTC"
  },
  {
    "arxiv_id": "2508.06943v2",
    "title": "Class Unbiasing for Generalization in Medical Diagnosis",
    "authors": [
      "Lishi Zuo",
      "Man-Wai Mak",
      "Lu Yi",
      "Youzhi Tu"
    ],
    "abstract": "Medical diagnosis might fail due to bias. In this work, we identified class-feature bias, which refers to models' potential reliance on features that are strongly correlated with only a subset of classes, leading to biased performance and poor generalization on other classes. We aim to train a class-unbiased model (Cls-unbias) that mitigates both class imbalance and class-feature bias simultaneously. Specifically, we propose a class-wise inequality loss which promotes equal contributions of classification loss from positive-class and negative-class samples. We propose to optimize a class-wise group distributionally robust optimization objective-a class-weighted training objective that upweights underperforming classes-to enhance the effectiveness of the inequality loss under class imbalance. Through synthetic and real-world datasets, we empirically demonstrate that class-feature bias can negatively impact model performance. Our proposed method effectively mitigates both class-feature bias and class imbalance, thereby improving the model's generalization ability.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.06943v2",
    "published_date": "2025-08-09 11:37:44 UTC",
    "updated_date": "2025-08-31 12:48:01 UTC"
  },
  {
    "arxiv_id": "2508.06942v1",
    "title": "When Prompt Engineering Meets Software Engineering: CNL-P as Natural and Robust \"APIs'' for Human-AI Interaction",
    "authors": [
      "Zhenchang Xing",
      "Yang Liu",
      "Zhuo Cheng",
      "Qing Huang",
      "Dehai Zhao",
      "Daniel Sun",
      "Chenhua Liu"
    ],
    "abstract": "With the growing capabilities of large language models (LLMs), they are increasingly applied in areas like intelligent customer service, code generation, and knowledge management. Natural language (NL) prompts act as the ``APIs'' for human-LLM interaction. To improve prompt quality, best practices for prompt engineering (PE) have been developed, including writing guidelines and templates. Building on this, we propose Controlled NL for Prompt (CNL-P), which not only incorporates PE best practices but also draws on key principles from software engineering (SE). CNL-P introduces precise grammar structures and strict semantic norms, further eliminating NL's ambiguity, allowing for a declarative but structured and accurate expression of user intent. This helps LLMs better interpret and execute the prompts, leading to more consistent and higher-quality outputs. We also introduce an NL2CNL-P conversion tool based on LLMs, enabling users to write prompts in NL, which are then transformed into CNL-P format, thus lowering the learning curve of CNL-P. In particular, we develop a linting tool that checks CNL-P prompts for syntactic and semantic accuracy, applying static analysis techniques to NL for the first time. Extensive experiments demonstrate that CNL-P enhances the quality of LLM responses through the novel and organic synergy of PE and SE. We believe that CNL-P can bridge the gap between emerging PE and traditional SE, laying the foundation for a new programming paradigm centered around NL.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.06942v1",
    "published_date": "2025-08-09 11:32:33 UTC",
    "updated_date": "2025-08-09 11:32:33 UTC"
  },
  {
    "arxiv_id": "2508.06941v2",
    "title": "CLAP: Coreference-Linked Augmentation for Passage Retrieval",
    "authors": [
      "Huanwei Xu",
      "Lin Xu",
      "Liang Yuan"
    ],
    "abstract": "Large Language Model (LLM)-based passage expansion has shown promise for enhancing first-stage retrieval, but often underperforms with dense retrievers due to semantic drift and misalignment with their pretrained semantic space. Beyond this, only a portion of a passage is typically relevant to a query, while the rest introduces noise--an issue compounded by chunking techniques that break coreference continuity. We propose Coreference-Linked Augmentation for Passage Retrieval (CLAP), a lightweight LLM-based expansion framework that segments passages into coherent chunks, resolves coreference chains, and generates localized pseudo-queries aligned with dense retriever representations. A simple fusion of global topical signals and fine-grained subtopic signals achieves robust performance across domains. CLAP yields consistent gains even as retriever strength increases, enabling dense retrievers to match or surpass second-stage rankers such as BM25 + MonoT5-3B, with up to 20.68% absolute nDCG@10 improvement. These improvements are especially notable in out-of-domain settings, where conventional LLM-based expansion methods relying on domain knowledge often falter. CLAP instead adopts a logic-centric pipeline that enables robust, domain-agnostic generalization.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "This paper has been accepted by CIKM 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.06941v2",
    "published_date": "2025-08-09 11:26:10 UTC",
    "updated_date": "2025-08-25 15:03:00 UTC"
  },
  {
    "arxiv_id": "2508.06939v1",
    "title": "Intrinsic Explainability of Multimodal Learning for Crop Yield Prediction",
    "authors": [
      "Hiba Najjar",
      "Deepak Pathak",
      "Marlon Nuske",
      "Andreas Dengel"
    ],
    "abstract": "Multimodal learning enables various machine learning tasks to benefit from diverse data sources, effectively mimicking the interplay of different factors in real-world applications, particularly in agriculture. While the heterogeneous nature of involved data modalities may necessitate the design of complex architectures, the model interpretability is often overlooked. In this study, we leverage the intrinsic explainability of Transformer-based models to explain multimodal learning networks, focusing on the task of crop yield prediction at the subfield level. The large datasets used cover various crops, regions, and years, and include four different input modalities: multispectral satellite and weather time series, terrain elevation maps and soil properties. Based on the self-attention mechanism, we estimate feature attributions using two methods, namely the Attention Rollout (AR) and Generic Attention (GA), and evaluate their performance against Shapley-based model-agnostic estimations, Shapley Value Sampling (SVS). Additionally, we propose the Weighted Modality Activation (WMA) method to assess modality attributions and compare it with SVS attributions. Our findings indicate that Transformer-based models outperform other architectures, specifically convolutional and recurrent networks, achieving R2 scores that are higher by 0.10 and 0.04 at the subfield and field levels, respectively. AR is shown to provide more robust and reliable temporal attributions, as confirmed through qualitative and quantitative evaluation, compared to GA and SVS values. Information about crop phenology stages was leveraged to interpret the explanation results in the light of established agronomic knowledge. Furthermore, modality attributions revealed varying patterns across the two methods compared.[...]",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.06939v1",
    "published_date": "2025-08-09 11:09:10 UTC",
    "updated_date": "2025-08-09 11:09:10 UTC"
  },
  {
    "arxiv_id": "2508.06937v2",
    "title": "CannyEdit: Selective Canny Control and Dual-Prompt Guidance for Training-Free Image Editing",
    "authors": [
      "Weiyan Xie",
      "Han Gao",
      "Didan Deng",
      "Kaican Li",
      "April Hua Liu",
      "Yongxiang Huang",
      "Nevin L. Zhang"
    ],
    "abstract": "Recent advances in text-to-image (T2I) models have enabled training-free regional image editing by leveraging the generative priors of foundation models. However, existing methods struggle to balance text adherence in edited regions, context fidelity in unedited areas, and seamless integration of edits. We introduce CannyEdit, a novel training-free framework that addresses this trilemma through two key innovations. First, Selective Canny Control applies structural guidance from a Canny ControlNet only to the unedited regions, preserving the original image's details while allowing for precise, text-driven changes in the specified editable area. Second, Dual-Prompt Guidance utilizes both a local prompt for the specific edit and a global prompt for overall scene coherence. Through this synergistic approach, these components enable controllable local editing for object addition, replacement, and removal, achieving a superior trade-off among text adherence, context fidelity, and editing seamlessness compared to current region-based methods. Beyond this, CannyEdit offers exceptional flexibility: it operates effectively with rough masks or even single-point hints in addition tasks. Furthermore, the framework can seamlessly integrate with vision-language models in a training-free manner for complex instruction-based editing that requires planning and reasoning. Our extensive evaluations demonstrate CannyEdit's strong performance against leading instruction-based editors in complex object addition scenarios.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Project Page: vaynexie.github.io/CannyEdit/; MindSpore Code: github.com/mindspore-lab/mindone/tree/master/examples/canny_edit; PyTorch Code: github.com/vaynexie/CannyEdit",
    "pdf_url": "https://arxiv.org/pdf/2508.06937v2",
    "published_date": "2025-08-09 11:06:58 UTC",
    "updated_date": "2025-10-26 07:19:20 UTC"
  },
  {
    "arxiv_id": "2508.06931v1",
    "title": "Automated Formalization via Conceptual Retrieval-Augmented LLMs",
    "authors": [
      "Wangyue Lu",
      "Lun Du",
      "Sirui Li",
      "Ke Weng",
      "Haozhe Sun",
      "Hengyu Liu",
      "Minghe Yu",
      "Tiancheng Zhang",
      "Ge Yu"
    ],
    "abstract": "Interactive theorem provers (ITPs) require manual formalization, which is labor-intensive and demands expert knowledge. While automated formalization offers a potential solution, it faces two major challenges: model hallucination (e.g., undefined predicates, symbol misuse, and version incompatibility) and the semantic gap caused by ambiguous or missing premises in natural language descriptions. To address these issues, we propose CRAMF, a Concept-driven Retrieval-Augmented Mathematical Formalization framework. CRAMF enhances LLM-based autoformalization by retrieving formal definitions of core mathematical concepts, providing contextual grounding during code generation. However, applying retrieval-augmented generation (RAG) in this setting is non-trivial due to the lack of structured knowledge bases, the polymorphic nature of mathematical concepts, and the high precision required in formal retrieval. We introduce a framework for automatically constructing a concept-definition knowledge base from Mathlib4, the standard mathematical library for the Lean 4 theorem prover, indexing over 26,000 formal definitions and 1,000+ core mathematical concepts. To address conceptual polymorphism, we propose contextual query augmentation with domain- and application-level signals. In addition, we design a dual-channel hybrid retrieval strategy with reranking to ensure accurate and relevant definition retrieval. Experiments on miniF2F, ProofNet, and our newly proposed AdvancedMath benchmark show that CRAMF can be seamlessly integrated into LLM-based autoformalizers, yielding consistent improvements in translation accuracy, achieving up to 62.1% and an average of 29.9% relative improvement.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.06931v1",
    "published_date": "2025-08-09 10:54:25 UTC",
    "updated_date": "2025-08-09 10:54:25 UTC"
  },
  {
    "arxiv_id": "2508.06917v1",
    "title": "CROP: Integrating Topological and Spatial Structures via Cross-View Prefixes for Molecular LLMs",
    "authors": [
      "Jianting Tang",
      "Yubo Wang",
      "Haoyu Cao",
      "Linli Xu"
    ],
    "abstract": "Recent advances in molecular science have been propelled significantly by large language models (LLMs). However, their effectiveness is limited when relying solely on molecular sequences, which fail to capture the complex structures of molecules. Beyond sequence representation, molecules exhibit two complementary structural views: the first focuses on the topological relationships between atoms, as exemplified by the graph view; and the second emphasizes the spatial configuration of molecules, as represented by the image view. The two types of views provide unique insights into molecular structures. To leverage these views collaboratively, we propose the CROss-view Prefixes (CROP) to enhance LLMs' molecular understanding through efficient multi-view integration. CROP possesses two advantages: (i) efficiency: by jointly resampling multiple structural views into fixed-length prefixes, it avoids excessive consumption of the LLM's limited context length and allows easy expansion to more views; (ii) effectiveness: by utilizing the LLM's self-encoded molecular sequences to guide the resampling process, it boosts the quality of the generated prefixes. Specifically, our framework features a carefully designed SMILES Guided Resampler for view resampling, and a Structural Embedding Gate for converting the resulting embeddings into LLM's prefixes. Extensive experiments demonstrate the superiority of CROP in tasks including molecule captioning, IUPAC name prediction and molecule property prediction.",
    "categories": [
      "q-bio.QM",
      "cs.AI"
    ],
    "primary_category": "q-bio.QM",
    "comment": "Accepted to ACMMM 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.06917v1",
    "published_date": "2025-08-09 10:06:28 UTC",
    "updated_date": "2025-08-09 10:06:28 UTC"
  },
  {
    "arxiv_id": "2508.09205v2",
    "title": "From Explainable to Explained AI: Ideas for Falsifying and Quantifying Explanations",
    "authors": [
      "Yoni Schirris",
      "Eric Marcus",
      "Jonas Teuwen",
      "Hugo Horlings",
      "Efstratios Gavves"
    ],
    "abstract": "Explaining deep learning models is essential for clinical integration of medical image analysis systems. A good explanation highlights if a model depends on spurious features that undermines generalization and harms a subset of patients or, conversely, may present novel biological insights. Although techniques like GradCAM can identify influential features, they are measurement tools that do not themselves form an explanation. We propose a human-machine-VLM interaction system tailored to explaining classifiers in computational pathology, including multi-instance learning for whole-slide images. Our proof of concept comprises (1) an AI-integrated slide viewer to run sliding-window experiments to test claims of an explanation, and (2) quantification of an explanation's predictiveness using general-purpose vision-language models. The results demonstrate that this allows us to qualitatively test claims of explanations and can quantifiably distinguish competing explanations. This offers a practical path from explainable AI to explained AI in digital pathology and beyond. Code and prompts are available at https://github.com/nki-ai/x2x.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "10 pages, 2 figures, 2 tables, submitted at MICCAI IMIMIC workshop",
    "pdf_url": "https://arxiv.org/pdf/2508.09205v2",
    "published_date": "2025-08-09 10:06:15 UTC",
    "updated_date": "2025-08-15 02:45:28 UTC"
  },
  {
    "arxiv_id": "2508.10032v1",
    "title": "The Cost of Thinking: Increased Jailbreak Risk in Large Language Models",
    "authors": [
      "Fan Yang"
    ],
    "abstract": "Thinking mode has always been regarded as one of the most valuable modes in LLMs. However, we uncover a surprising and previously overlooked phenomenon: LLMs with thinking mode are more easily broken by Jailbreak attack. We evaluate 9 LLMs on AdvBench and HarmBench and find that the success rate of attacking thinking mode in LLMs is almost higher than that of non-thinking mode. Through large numbers of sample studies, it is found that for educational purposes and excessively long thinking lengths are the characteristics of successfully attacked data, and LLMs also give harmful answers when they mostly know that the questions are harmful. In order to alleviate the above problems, this paper proposes a method of safe thinking intervention for LLMs, which explicitly guides the internal thinking processes of LLMs by adding \"specific thinking tokens\" of LLMs to the prompt. The results demonstrate that the safe thinking intervention can significantly reduce the attack success rate of LLMs with thinking mode.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.10032v1",
    "published_date": "2025-08-09 09:49:49 UTC",
    "updated_date": "2025-08-09 09:49:49 UTC"
  },
  {
    "arxiv_id": "2508.06908v2",
    "title": "Find Them All: Unveiling MLLMs for Versatile Person Re-identification",
    "authors": [
      "Jinhao Li",
      "Zijian Chen",
      "Lirong Deng",
      "Guangtao Zhai",
      "Changbo Wang"
    ],
    "abstract": "Person re-identification (ReID) aims to retrieve images of a target person from the gallery set, with wide applications in medical rehabilitation and public security. However, traditional person ReID models are typically uni-modal, resulting in limited generalizability across heterogeneous data modalities. Recently, the emergence of multi-modal large language models (MLLMs) has shown a promising avenue for addressing this issue. Despite this potential, existing methods merely regard MLLMs as feature extractors or caption generators, leaving their capabilities in person ReID tasks largely unexplored. To bridge this gap, we introduce a novel benchmark for \\underline{\\textbf{V}}ersatile \\underline{\\textbf{P}}erson \\underline{\\textbf{Re}}-\\underline{\\textbf{ID}}entification, termed VP-ReID. The benchmark includes 257,310 multi-modal queries and gallery images, covering ten diverse person ReID tasks. In addition, we propose two task-oriented evaluation schemes for MLLM-based person ReID. Extensive experiments demonstrate the impressive versatility, effectiveness, and interpretability of MLLMs in various person ReID tasks. Nevertheless, they also have limitations in handling a few modalities, particularly thermal and infrared data. We hope that VP-ReID can facilitate the community in developing more robust and generalizable cross-modal foundation models for person ReID.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.06908v2",
    "published_date": "2025-08-09 09:42:09 UTC",
    "updated_date": "2025-11-23 15:36:37 UTC"
  },
  {
    "arxiv_id": "2508.06900v1",
    "title": "Advancements in Chinese font generation since deep learning era: A survey",
    "authors": [
      "Weiran Chen",
      "Guiqian Zhu",
      "Ying Li",
      "Yi Ji",
      "Chunping Liu"
    ],
    "abstract": "Chinese font generation aims to create a new Chinese font library based on some reference samples. It is a topic of great concern to many font designers and typographers. Over the past years, with the rapid development of deep learning algorithms, various new techniques have achieved flourishing and thriving progress. Nevertheless, how to improve the overall quality of generated Chinese character images remains a tough issue. In this paper, we conduct a holistic survey of the recent Chinese font generation approaches based on deep learning. To be specific, we first illustrate the research background of the task. Then, we outline our literature selection and analysis methodology, and review a series of related fundamentals, including classical deep learning architectures, font representation formats, public datasets, and frequently-used evaluation metrics. After that, relying on the number of reference samples required to generate a new font, we categorize the existing methods into two major groups: many-shot font generation and few-shot font generation methods. Within each category, representative approaches are summarized, and their strengths and limitations are also discussed in detail. Finally, we conclude our paper with the challenges and future directions, with the expectation to provide some valuable illuminations for the researchers in this field.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "42 Pages, 25 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.06900v1",
    "published_date": "2025-08-09 09:15:05 UTC",
    "updated_date": "2025-08-09 09:15:05 UTC"
  },
  {
    "arxiv_id": "2508.06899v2",
    "title": "GDBA Revisited: Unleashing the Power of Guided Local Search for Distributed Constraint Optimization",
    "authors": [
      "Yanchen Deng",
      "Xinrun Wang",
      "Bo An"
    ],
    "abstract": "Local search is an important class of incomplete algorithms for solving Distributed Constraint Optimization Problems (DCOPs) but it often converges to poor local optima. While Generalized Distributed Breakout Algorithm (GDBA) provides a comprehensive rule set to escape premature convergence, its empirical benefits remain marginal on general-valued problems. In this work, we systematically examine GDBA and identify three factors that potentially lead to its inferior performance, i.e., over-aggressive constraint violation conditions, unbounded penalty accumulation, and uncoordinated penalty updates. To address these issues, we propose Distributed Guided Local Search (DGLS), a novel GLS framework for DCOPs that incorporates an adaptive violation condition to selectively penalize constraints with high cost, a penalty evaporation mechanism to control the magnitude of penalization, and a synchronization scheme for coordinated penalty updates. We theoretically show that the penalty values are bounded, and agents play a potential game in DGLS. Extensive empirical results on various benchmarks demonstrate the great superiority of DGLS over state-of-the-art baselines. Compared to Damped Max-sum with high damping factors, our DGLS achieves competitive performance on general-valued problems, and outperforms by significant margins on structured problems in terms of anytime results.",
    "categories": [
      "cs.AI",
      "cs.DM"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by AAAI 2026",
    "pdf_url": "https://arxiv.org/pdf/2508.06899v2",
    "published_date": "2025-08-09 09:12:06 UTC",
    "updated_date": "2026-01-12 07:36:44 UTC"
  },
  {
    "arxiv_id": "2508.06895v1",
    "title": "BASIC: Boosting Visual Alignment with Intrinsic Refined Embeddings in Multimodal Large Language Models",
    "authors": [
      "Jianting Tang",
      "Yubo Wang",
      "Haoyu Cao",
      "Linli Xu"
    ],
    "abstract": "Mainstream Multimodal Large Language Models (MLLMs) achieve visual understanding by using a vision projector to bridge well-pretrained vision encoders and large language models (LLMs). The inherent gap between visual and textual modalities makes the embeddings from the vision projector critical for visual comprehension. However, current alignment approaches treat visual embeddings as contextual cues and merely apply auto-regressive supervision to textual outputs, neglecting the necessity of introducing equivalent direct visual supervision, which hinders the potential finer alignment of visual embeddings. In this paper, based on our analysis of the refinement process of visual embeddings in the LLM's shallow layers, we propose BASIC, a method that utilizes refined visual embeddings within the LLM as supervision to directly guide the projector in generating initial visual embeddings. Specifically, the guidance is conducted from two perspectives: (i) optimizing embedding directions by reducing angles between initial and supervisory embeddings in semantic space; (ii) improving semantic matching by minimizing disparities between the logit distributions of both visual embeddings. Without additional supervisory models or artificial annotations, BASIC significantly improves the performance of MLLMs across a wide range of benchmarks, demonstrating the effectiveness of our introduced direct visual supervision.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to ICCV 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.06895v1",
    "published_date": "2025-08-09 09:00:45 UTC",
    "updated_date": "2025-08-09 09:00:45 UTC"
  },
  {
    "arxiv_id": "2508.06894v2",
    "title": "Pushdown Reward Machines for Reinforcement Learning",
    "authors": [
      "Giovanni Varricchione",
      "Toryn Q. Klassen",
      "Natasha Alechina",
      "Mehdi Dastani",
      "Brian Logan",
      "Sheila A. McIlraith"
    ],
    "abstract": "Reward machines (RMs) are automata structures that encode (non-Markovian) reward functions for reinforcement learning (RL). RMs can reward any behaviour representable in regular languages and, when paired with RL algorithms that exploit RM structure, have been shown to significantly improve sample efficiency in many domains. In this work, we present pushdown reward machines (pdRMs), an extension of reward machines based on deterministic pushdown automata. pdRMs can recognise and reward temporally extended behaviours representable in deterministic context-free languages, making them more expressive than reward machines. We introduce two variants of pdRM-based policies, one which has access to the entire stack of the pdRM, and one which can only access the top $k$ symbols (for a given constant $k$) of the stack. We propose a procedure to check when the two kinds of policies (for a given environment, pdRM, and constant $k$) achieve the same optimal state values. We then provide theoretical results establishing the expressive power of pdRMs, and space complexity results for the proposed learning problems. Lastly, we propose an approach for off-policy RL algorithms that exploits counterfactual experiences with pdRMs. We conclude by providing experimental results showing how agents can be trained to perform tasks representable in deterministic context-free languages using pdRMs.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Extended version of a paper accepted for publication at the 22nd International Conference on Principles of Knowledge Representation and Reasoning (KR 2025)",
    "pdf_url": "https://arxiv.org/pdf/2508.06894v2",
    "published_date": "2025-08-09 08:59:09 UTC",
    "updated_date": "2025-11-12 03:25:04 UTC"
  },
  {
    "arxiv_id": "2508.06890v1",
    "title": "Maestro-EVC: Controllable Emotional Voice Conversion Guided by References and Explicit Prosody",
    "authors": [
      "Jinsung Yoon",
      "Wooyeol Jeong",
      "Jio Gim",
      "Young-Joo Suh"
    ],
    "abstract": "Emotional voice conversion (EVC) aims to modify the emotional style of speech while preserving its linguistic content. In practical EVC, controllability, the ability to independently control speaker identity and emotional style using distinct references, is crucial. However, existing methods often struggle to fully disentangle these attributes and lack the ability to model fine-grained emotional expressions such as temporal dynamics. We propose Maestro-EVC, a controllable EVC framework that enables independent control of content, speaker identity, and emotion by effectively disentangling each attribute from separate references. We further introduce a temporal emotion representation and an explicit prosody modeling with prosody augmentation to robustly capture and transfer the temporal dynamics of the target emotion, even under prosody-mismatched conditions. Experimental results confirm that Maestro-EVC achieves high-quality, controllable, and emotionally expressive speech synthesis.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted at ASRU 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.06890v1",
    "published_date": "2025-08-09 08:46:32 UTC",
    "updated_date": "2025-08-09 08:46:32 UTC"
  },
  {
    "arxiv_id": "2508.08318v1",
    "title": "Between Fear and Desire, the Monster Artificial Intelligence (AI): Analysis through the Lenses of Monster Theory",
    "authors": [
      "Ahmed Tlili"
    ],
    "abstract": "With the increasing adoption of Artificial Intelligence (AI) in all fields and daily activities, a heated debate is found about the advantages and challenges of AI and the need for navigating the concerns associated with AI to make the best of it. To contribute to this literature and the ongoing debate related to it, this study draws on the Monster theory to explain the conflicting representation of AI. It suggests that studying monsters in popular culture can provide an in-depth understanding of AI and its monstrous effects. Specifically, this study aims to discuss AI perception and development through the seven theses of Monster theory. The obtained results revealed that, just like monsters, AI is complex in nature, and it should not be studied as a separate entity but rather within a given society or culture. Similarly, readers may perceive and interpret AI differently, just as readers may interpret monsters differently. The relationship between AI and monsters, as depicted in this study, does not seem to be as odd as it might be at first.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.08318v1",
    "published_date": "2025-08-09 08:35:14 UTC",
    "updated_date": "2025-08-09 08:35:14 UTC"
  },
  {
    "arxiv_id": "2508.08317v1",
    "title": "Evaluation of State-of-the-Art Deep Learning Techniques for Plant Disease and Pest Detection",
    "authors": [
      "Saptarshi Banerjee",
      "Tausif Mallick",
      "Amlan Chakroborty",
      "Himadri Nath Saha",
      "Nityananda T. Takur"
    ],
    "abstract": "Addressing plant diseases and pests is critical for enhancing crop production and preventing economic losses. Recent advances in artificial intelligence (AI), machine learning (ML), and deep learning (DL) have significantly improved the precision and efficiency of detection methods, surpassing the limitations of manual identification. This study reviews modern computer-based techniques for detecting plant diseases and pests from images, including recent AI developments. The methodologies are organized into five categories: hyperspectral imaging, non-visualization techniques, visualization approaches, modified deep learning architectures, and transformer models. This structured taxonomy provides researchers with detailed, actionable insights for selecting advanced state-of-the-art detection methods. A comprehensive survey of recent work and comparative studies demonstrates the consistent superiority of modern AI-based approaches, which often outperform older image analysis methods in speed and accuracy. In particular, vision transformers such as the Hierarchical Vision Transformer (HvT) have shown accuracy exceeding 99.3% in plant disease detection, outperforming architectures like MobileNetV3. The study concludes by discussing system design challenges, proposing solutions, and outlining promising directions for future research.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "AI/ML, Computer Vision",
    "pdf_url": "https://arxiv.org/pdf/2508.08317v1",
    "published_date": "2025-08-09 08:23:33 UTC",
    "updated_date": "2025-08-09 08:23:33 UTC"
  },
  {
    "arxiv_id": "2508.06878v1",
    "title": "NS-FPN: Improving Infrared Small Target Detection and Segmentation from Noise Suppression Perspective",
    "authors": [
      "Maoxun Yuan",
      "Duanni Meng",
      "Ziteng Xi",
      "Tianyi Zhao",
      "Shiji Zhao",
      "Yimian Dai",
      "Xingxing Wei"
    ],
    "abstract": "Infrared small target detection and segmentation (IRSTDS) is a critical yet challenging task in defense and civilian applications, owing to the dim, shapeless appearance of targets and severe background clutter. Recent CNN-based methods have achieved promising target perception results, but they only focus on enhancing feature representation to offset the impact of noise, which results in the increased false alarms problem. In this paper, through analyzing the problem from the frequency domain, we pioneer in improving performance from noise suppression perspective and propose a novel noise-suppression feature pyramid network (NS-FPN), which integrates a low-frequency guided feature purification (LFP) module and a spiral-aware feature sampling (SFS) module into the original FPN structure. The LFP module suppresses the noise features by purifying high-frequency components to achieve feature enhancement devoid of noise interference, while the SFS module further adopts spiral sampling to fuse target-relevant features in feature fusion process. Our NS-FPN is designed to be lightweight yet effective and can be easily plugged into existing IRSTDS frameworks. Extensive experiments on the public IRSTDS datasets demonstrate that our method significantly reduces false alarms and achieves superior performance on IRSTDS tasks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.06878v1",
    "published_date": "2025-08-09 08:17:37 UTC",
    "updated_date": "2025-08-09 08:17:37 UTC"
  },
  {
    "arxiv_id": "2508.06877v1",
    "title": "ESNERA: Empirical and semantic named entity alignment for named entity dataset merging",
    "authors": [
      "Xiaobo Zhang",
      "Congqing He",
      "Ying He",
      "Jian Peng",
      "Dajie Fu",
      "Tien-Ping Tan"
    ],
    "abstract": "Named Entity Recognition (NER) is a fundamental task in natural language processing. It remains a research hotspot due to its wide applicability across domains. Although recent advances in deep learning have significantly improved NER performance, they rely heavily on large, high-quality annotated datasets. However, building these datasets is expensive and time-consuming, posing a major bottleneck for further research. Current dataset merging approaches mainly focus on strategies like manual label mapping or constructing label graphs, which lack interpretability and scalability. To address this, we propose an automatic label alignment method based on label similarity. The method combines empirical and semantic similarities, using a greedy pairwise merging strategy to unify label spaces across different datasets. Experiments are conducted in two stages: first, merging three existing NER datasets into a unified corpus with minimal impact on NER performance; second, integrating this corpus with a small-scale, self-built dataset in the financial domain. The results show that our method enables effective dataset merging and enhances NER performance in the low-resource financial domain. This study presents an efficient, interpretable, and scalable solution for integrating multi-source NER corpora.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "30 pages, 12 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.06877v1",
    "published_date": "2025-08-09 08:15:26 UTC",
    "updated_date": "2025-08-09 08:15:26 UTC"
  },
  {
    "arxiv_id": "2508.16597v1",
    "title": "Bridging Foundation Models and Efficient Architectures: A Modular Brain Imaging Framework with Local Masking and Pretrained Representation Learning",
    "authors": [
      "Yanwen Wang",
      "Xinglin Zhao",
      "Yijin Song",
      "Xiaobo Liu",
      "Yanrong Hao",
      "Rui Cao",
      "Xin Wen"
    ],
    "abstract": "Functional connectivity (FC) derived from resting-state fMRI plays a critical role in personalized predictions such as age and cognitive performance. However, applying foundation models(FM) to fMRI data remains challenging due to its high dimensionality, computational complexity, and the difficulty in capturing complex spatiotemporal dynamics and indirect region-of-interest (ROI) interactions. To address these limitations, we propose a modular neuroimaging framework that integrates principles from FM with efficient, domain-specific architectures. Our approach begins with a Local Masked Autoencoder (LMAE) for pretraining, which reduces the influence of hemodynamic response function (HRF) dynamics and suppresses noise. This is followed by a Random Walk Mixture of Experts (RWMOE) module that clusters features across spatial and temporal dimensions, effectively capturing intricate brain interactions. Finally, a state-space model (SSM)-based predictor performs downstream task inference. Evaluated on the Cambridge Centre for Ageing and Neuroscience (Cam-CAN) dataset, our framework achieved mean absolute errors (MAEs) of 5.343 for age prediction and 2.940 for fluid intelligence, with Pearson correlation coefficients (PCCs) of 0.928 and 0.887, respectively-outperforming existing state-of-the-art methods. Visualization of expert distribution weights further enhances interpretability by identifying key brain regions. This work provides a robust, interpretable alternative to LLM-based approaches for fMRI analysis, offering novel insights into brain aging and cognitive function.",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.NC",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.16597v1",
    "published_date": "2025-08-09 08:06:01 UTC",
    "updated_date": "2025-08-09 08:06:01 UTC"
  },
  {
    "arxiv_id": "2508.11680v2",
    "title": "Comparative Analysis of Time Series Foundation Models for Demographic Forecasting: Enhancing Predictive Accuracy in US Population Dynamics",
    "authors": [
      "Aditya Akella",
      "Jonathan Farah"
    ],
    "abstract": "Demographic shifts, influenced by globalization, economic conditions, geopolitical events, and environmental factors, pose significant challenges for policymakers and researchers. Accurate demographic forecasting is essential for informed decision-making in areas such as urban planning, healthcare, and economic policy. This study explores the application of time series foundation models to predict demographic changes in the United States using datasets from the U.S. Census Bureau and Federal Reserve Economic Data (FRED). We evaluate the performance of the Time Series Foundation Model (TimesFM) against traditional baselines including Long Short-Term Memory (LSTM) networks, Autoregressive Integrated Moving Average (ARIMA), and Linear Regression. Our experiments across six demographically diverse states demonstrate that TimesFM achieves the lowest Mean Squared Error (MSE) in 86.67% of test cases, with particularly strong performance on minority populations with sparse historical data. These findings highlight the potential of pre-trained foundation models to enhance demographic analysis and inform proactive policy interventions without requiring extensive task-specific fine-tuning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "6 pages, 4 figures, 3 tables",
    "pdf_url": "https://arxiv.org/pdf/2508.11680v2",
    "published_date": "2025-08-09 07:55:09 UTC",
    "updated_date": "2025-08-19 07:06:02 UTC"
  },
  {
    "arxiv_id": "2508.06871v1",
    "title": "Sparsity-Driven Plasticity in Multi-Task Reinforcement Learning",
    "authors": [
      "Aleksandar Todorov",
      "Juan Cardenas-Cartagena",
      "Rafael F. Cunha",
      "Marco Zullich",
      "Matthia Sabatelli"
    ],
    "abstract": "Plasticity loss, a diminishing capacity to adapt as training progresses, is a critical challenge in deep reinforcement learning. We examine this issue in multi-task reinforcement learning (MTRL), where higher representational flexibility is crucial for managing diverse and potentially conflicting task demands. We systematically explore how sparsification methods, particularly Gradual Magnitude Pruning (GMP) and Sparse Evolutionary Training (SET), enhance plasticity and consequently improve performance in MTRL agents. We evaluate these approaches across distinct MTRL architectures (shared backbone, Mixture of Experts, Mixture of Orthogonal Experts) on standardized MTRL benchmarks, comparing against dense baselines, and a comprehensive range of alternative plasticity-inducing or regularization methods. Our results demonstrate that both GMP and SET effectively mitigate key indicators of plasticity degradation, such as neuron dormancy and representational collapse. These plasticity improvements often correlate with enhanced multi-task performance, with sparse agents frequently outperforming dense counterparts and achieving competitive results against explicit plasticity interventions. Our findings offer insights into the interplay between plasticity, network sparsity, and MTRL designs, highlighting dynamic sparsification as a robust but context-sensitive tool for developing more adaptable MTRL systems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.06871v1",
    "published_date": "2025-08-09 07:44:44 UTC",
    "updated_date": "2025-08-09 07:44:44 UTC"
  },
  {
    "arxiv_id": "2508.06869v3",
    "title": "VSI: Visual Subtitle Integration for Keyframe Selection to enhance Long Video Understanding",
    "authors": [
      "Jianxiang He",
      "Meisheng Hong",
      "Jungang Li",
      "Ziyang Chen",
      "Weiyu Guo",
      "Xuming Hu",
      "Hui Xiong"
    ],
    "abstract": "Multimodal large language models (MLLMs) demonstrate exceptional performance in vision-language tasks, yet their processing of long videos is constrained by input context length and high computational costs. Sparse frame sampling thus becomes a necessary preprocessing step, with sampled frame quality directly impacting downstream performance. Existing keyframe search algorithms achieve a balance between efficiency and sampled frame quality but heavily rely on the visual modality alone. This makes them difficult to adapt to text-related tasks and often leads to retrieval results deviating from core semantic content. To address this, we propose the VISUAL-SUBTITLE INTEGRATION (VSI), a multimodal keyframe retrieval framework. It employs a dual-branch collaborative retrieval approach combining Video Search and Subtitle Match to fuse complementary visual and textual information for precise localization. Experiments on LongVideoBench and VideoMME demonstrate that VSI achieves state-of-the-art accuracy in keyframe retrieval while delivering breakthrough performance in text-related tasks and exhibiting strong generalization across other tasks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "9 pages,3 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.06869v3",
    "published_date": "2025-08-09 07:38:48 UTC",
    "updated_date": "2025-11-21 12:37:49 UTC"
  },
  {
    "arxiv_id": "2508.06859v2",
    "title": "MeteorPred: A Meteorological Multimodal Large Model and Dataset for Severe Weather Event Prediction",
    "authors": [
      "Shuo Tang",
      "Jian Xu",
      "Jiadong Zhang",
      "Yi Chen",
      "Qizhao Jin",
      "Lingdong Shen",
      "Chenglin Liu",
      "Shiming Xiang"
    ],
    "abstract": "Timely and accurate forecasts of severe weather events are essential for early warning and for constraining downstream analysis and decision-making. Since severe weather events prediction still depends on subjective, time-consuming expert interpretation, end-to-end \"AI weather station\" systems are emerging but face three major challenges: (1) scarcity of severe weather event samples; (2) imperfect alignment between high-dimensional meteorological data and textual warnings; (3) current multimodal language models cannot effectively process high-dimensional meteorological inputs or capture their complex spatiotemporal dependencies. To address these challenges, we introduce MP-Bench, the first large-scale multimodal dataset for severe weather events prediction, comprising 421,363 pairs of raw multi-year meteorological data and corresponding text caption, covering a wide range of severe weather scenarios. On top of this dataset, we develop a Meteorology Multimodal Large Model (MMLM) that directly ingests 4D meteorological inputs. In addition, it is designed to accommodate the unique characteristics of 4D meteorological data flow, incorporating three plug-and-play adaptive fusion modules that enable dynamic feature extraction and integration across temporal sequences, vertical pressure layers, and spatial dimensions. Extensive experiments on MP-Bench show that MMLM achieves strong performance across multiple tasks, demonstrating effective severe weather understanding and representing a key step toward automated, AI-driven severe weather events forecasting systems. Our source code and dataset will be made publicly available.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.06859v2",
    "published_date": "2025-08-09 06:54:41 UTC",
    "updated_date": "2025-11-22 07:05:59 UTC"
  },
  {
    "arxiv_id": "2508.06853v1",
    "title": "AGIC: Attention-Guided Image Captioning to Improve Caption Relevance",
    "authors": [
      "L. D. M. S. Sai Teja",
      "Ashok Urlana",
      "Pruthwik Mishra"
    ],
    "abstract": "Despite significant progress in image captioning, generating accurate and descriptive captions remains a long-standing challenge. In this study, we propose Attention-Guided Image Captioning (AGIC), which amplifies salient visual regions directly in the feature space to guide caption generation. We further introduce a hybrid decoding strategy that combines deterministic and probabilistic sampling to balance fluency and diversity. To evaluate AGIC, we conduct extensive experiments on the Flickr8k and Flickr30k datasets. The results show that AGIC matches or surpasses several state-of-the-art models while achieving faster inference. Moreover, AGIC demonstrates strong performance across multiple evaluation metrics, offering a scalable and interpretable solution for image captioning.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 5 Figures",
    "pdf_url": "https://arxiv.org/pdf/2508.06853v1",
    "published_date": "2025-08-09 06:42:25 UTC",
    "updated_date": "2025-08-09 06:42:25 UTC"
  },
  {
    "arxiv_id": "2508.06851v1",
    "title": "MDK12-Bench: A Comprehensive Evaluation of Multimodal Large Language Models on Multidisciplinary Exams",
    "authors": [
      "Pengfei Zhou",
      "Xiaopeng Peng",
      "Fanrui Zhang",
      "Zhaopan Xu",
      "Jiaxin Ai",
      "Yansheng Qiu",
      "Chuanhao Li",
      "Zhen Li",
      "Ming Li",
      "Yukang Feng",
      "Jianwen Sun",
      "Haoquan Zhang",
      "Zizhen Li",
      "Xiaofeng Mao",
      "Zekai Li",
      "Wangbo Zhao",
      "Kai Wang",
      "Xiaojun Chang",
      "Wenqi Shao",
      "Yang You",
      "Kaipeng Zhang"
    ],
    "abstract": "Multimodal large language models (MLLMs), which integrate language and visual cues for problem-solving, are crucial for advancing artificial general intelligence (AGI). However, current benchmarks for measuring the intelligence of MLLMs suffer from limited scale, narrow coverage, and unstructured knowledge, offering only static and undifferentiated evaluations. To bridge this gap, we introduce MDK12-Bench, a large-scale multidisciplinary benchmark built from real-world K-12 exams spanning six disciplines with 141K instances and 6,225 knowledge points organized in a six-layer taxonomy. Covering five question formats with difficulty and year annotations, it enables comprehensive evaluation to capture the extent to which MLLMs perform over four dimensions: 1) difficulty levels, 2) temporal (cross-year) shifts, 3) contextual shifts, and 4) knowledge-driven reasoning. We propose a novel dynamic evaluation framework that introduces unfamiliar visual, textual, and question form shifts to challenge model generalization while improving benchmark objectivity and longevity by mitigating data contamination. We further evaluate knowledge-point reference-augmented generation (KP-RAG) to examine the role of knowledge in problem-solving. Key findings reveal limitations in current MLLMs in multiple aspects and provide guidance for enhancing model robustness, interpretability, and AI-assisted education.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "35 pages, 33 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.06851v1",
    "published_date": "2025-08-09 06:21:10 UTC",
    "updated_date": "2025-08-09 06:21:10 UTC"
  },
  {
    "arxiv_id": "2508.06849v1",
    "title": "Towards Experience-Centered AI: A Framework for Integrating Lived Experience in Design and Development",
    "authors": [
      "Sanjana Gautam",
      "Mohit Chandra",
      "Ankolika De",
      "Tatiana Chakravorti",
      "Girik Malik",
      "Munmun De Choudhury"
    ],
    "abstract": "Lived experiences fundamentally shape how individuals interact with AI systems, influencing perceptions of safety, trust, and usability. While prior research has focused on developing techniques to emulate human preferences, and proposed taxonomies to categorize risks (such as psychological harms and algorithmic biases), these efforts have provided limited systematic understanding of lived human experiences or actionable strategies for embedding them meaningfully into the AI development lifecycle. This work proposes a framework for meaningfully integrating lived experience into the design and evaluation of AI systems. We synthesize interdisciplinary literature across lived experience philosophy, human-centered design, and human-AI interaction, arguing that centering lived experience can lead to models that more accurately reflect the retrospective, emotional, and contextual dimensions of human cognition. Drawing from a wide body of work across psychology, education, healthcare, and social policy, we present a targeted taxonomy of lived experiences with specific applicability to AI systems. To ground our framework, we examine three application domains (i) education, (ii) healthcare, and (iii) cultural alignment, illustrating how lived experience informs user goals, system expectations, and ethical considerations in each context. We further incorporate insights from AI system operators and human-AI partnerships to highlight challenges in responsibility allocation, mental model calibration, and long-term system adaptation. We conclude with actionable recommendations for developing experience-centered AI systems that are not only technically robust but also empathetic, context-aware, and aligned with human realities. This work offers a foundation for future research that bridges technical development with the lived experiences of those impacted by AI systems.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.06849v1",
    "published_date": "2025-08-09 06:12:40 UTC",
    "updated_date": "2025-08-09 06:12:40 UTC"
  },
  {
    "arxiv_id": "2508.06846v1",
    "title": "Highlight All the Phrases: Enhancing LLM Transparency through Visual Factuality Indicators",
    "authors": [
      "Hyo Jin Do",
      "Rachel Ostrand",
      "Werner Geyer",
      "Keerthiram Murugesan",
      "Dennis Wei",
      "Justin Weisz"
    ],
    "abstract": "Large language models (LLMs) are susceptible to generating inaccurate or false information, often referred to as \"hallucinations\" or \"confabulations.\" While several technical advancements have been made to detect hallucinated content by assessing the factuality of the model's responses, there is still limited research on how to effectively communicate this information to users. To address this gap, we conducted two scenario-based experiments with a total of 208 participants to systematically compare the effects of various design strategies for communicating factuality scores by assessing participants' ratings of trust, ease in validating response accuracy, and preference. Our findings reveal that participants preferred and trusted a design in which all phrases within a response were color-coded based on factuality scores. Participants also found it easier to validate accuracy of the response in this style compared to a baseline with no style applied. Our study offers practical design guidelines for LLM application developers and designers, aimed at calibrating user trust, aligning with user preferences, and enhancing users' ability to scrutinize LLM outputs.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "16 pages, 8 figures, To be published in Proceedings of the 8th AAAI/ACM Conference on AI, Ethics, and Society (AIES 2025)",
    "pdf_url": "https://arxiv.org/pdf/2508.06846v1",
    "published_date": "2025-08-09 06:00:15 UTC",
    "updated_date": "2025-08-09 06:00:15 UTC"
  },
  {
    "arxiv_id": "2508.09204v2",
    "title": "MoQE: Improve Quantization Model performance via Mixture of Quantization Experts",
    "authors": [
      "Jinhao Zhang",
      "Yunquan Zhang",
      "Boyang Zhang",
      "Zeyu Liu",
      "Daning Cheng"
    ],
    "abstract": "Quantization method plays a crucial role in improving model efficiency and reducing deployment costs, enabling the widespread application of deep learning models on resource-constrained devices. However, the quantization process inevitably introduces accuracy degradation. In this paper, we propose Mixture of Quantization Experts( abbr. MoQE), a quantization inference framework based on the Mixture-of-Experts (MoE) architecture, aiming to jointly improve the performance of quantization models. MoQE combines multiple quantization variants of one full-precision model as specialized \"quantization experts\" and dynamically routes input data to the most suitable expert based on its characteristics. MoQE alleviates the performance degradation commonly seen in single quantization models through specialization quantization expert models. We design lightweight, structure-aware router models tailored for both CV and NLP tasks. Experimental evaluations on ResNet, LLaMA, and Qwen model families across benchmark datasets including ImageNet, WikiText, C4, and OpenWebText demonstrate that MoQE achieves performance comparable to SOTA quantization model, without incurring significant increases in inference latency.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.09204v2",
    "published_date": "2025-08-09 05:58:29 UTC",
    "updated_date": "2025-09-27 08:46:35 UTC"
  },
  {
    "arxiv_id": "2508.06836v1",
    "title": "Multi-level Advantage Credit Assignment for Cooperative Multi-Agent Reinforcement Learning",
    "authors": [
      "Xutong Zhao",
      "Yaqi Xie"
    ],
    "abstract": "Cooperative multi-agent reinforcement learning (MARL) aims to coordinate multiple agents to achieve a common goal. A key challenge in MARL is credit assignment, which involves assessing each agent's contribution to the shared reward. Given the diversity of tasks, agents may perform different types of coordination, with rewards attributed to diverse and often overlapping agent subsets. In this work, we formalize the credit assignment level as the number of agents cooperating to obtain a reward, and address scenarios with multiple coexisting levels. We introduce a multi-level advantage formulation that performs explicit counterfactual reasoning to infer credits across distinct levels. Our method, Multi-level Advantage Credit Assignment (MACA), captures agent contributions at multiple levels by integrating advantage functions that reason about individual, joint, and correlated actions. Utilizing an attention-based framework, MACA identifies correlated agent relationships and constructs multi-level advantages to guide policy learning. Comprehensive experiments on challenging Starcraft v1\\&v2 tasks demonstrate MACA's superior performance, underscoring its efficacy in complex credit assignment scenarios.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at AISTATS 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.06836v1",
    "published_date": "2025-08-09 05:36:08 UTC",
    "updated_date": "2025-08-09 05:36:08 UTC"
  },
  {
    "arxiv_id": "2508.06832v1",
    "title": "Remote Sensing Image Intelligent Interpretation with the Language-Centered Perspective: Principles, Methods and Challenges",
    "authors": [
      "Haifeng Li",
      "Wang Guo",
      "Haiyang Wu",
      "Mengwei Wu",
      "Jipeng Zhang",
      "Qing Zhu",
      "Yu Liu",
      "Xin Huang",
      "Chao Tao"
    ],
    "abstract": "The mainstream paradigm of remote sensing image interpretation has long been dominated by vision-centered models, which rely on visual features for semantic understanding. However, these models face inherent limitations in handling multi-modal reasoning, semantic abstraction, and interactive decision-making. While recent advances have introduced Large Language Models (LLMs) into remote sensing workflows, existing studies primarily focus on downstream applications, lacking a unified theoretical framework that explains the cognitive role of language. This review advocates a paradigm shift from vision-centered to language-centered remote sensing interpretation. Drawing inspiration from the Global Workspace Theory (GWT) of human cognition, We propose a language-centered framework for remote sensing interpretation that treats LLMs as the cognitive central hub integrating perceptual, task, knowledge and action spaces to enable unified understanding, reasoning, and decision-making. We first explore the potential of LLMs as the central cognitive component in remote sensing interpretation, and then summarize core technical challenges, including unified multimodal representation, knowledge association, and reasoning and decision-making. Furthermore, we construct a global workspace-driven interpretation mechanism and review how language-centered solutions address each challenge. Finally, we outline future research directions from four perspectives: adaptive alignment of multimodal data, task understanding under dynamic knowledge constraints, trustworthy reasoning, and autonomous interaction. This work aims to provide a conceptual foundation for the next generation of remote sensing interpretation systems and establish a roadmap toward cognition-driven intelligent geospatial analysis.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.06832v1",
    "published_date": "2025-08-09 05:10:38 UTC",
    "updated_date": "2025-08-09 05:10:38 UTC"
  },
  {
    "arxiv_id": "2508.06827v2",
    "title": "Who's the Evil Twin? Differential Auditing for Undesired Behavior",
    "authors": [
      "Ishwar Balappanawar",
      "Venkata Hasith Vattikuti",
      "Greta Kintzley",
      "Ronan Azimi-Mancel",
      "Satvik Golechha"
    ],
    "abstract": "Detecting hidden behaviors in neural networks poses a significant challenge due to minimal prior knowledge and potential adversarial obfuscation. We explore this problem by framing detection as an adversarial game between two teams: the red team trains two similar models, one trained solely on benign data and the other trained on data containing hidden harmful behavior, with the performance of both being nearly indistinguishable on the benign dataset. The blue team, with limited to no information about the harmful behaviour, tries to identify the compromised model. We experiment using CNNs and try various blue team strategies, including Gaussian noise analysis, model diffing, integrated gradients, and adversarial attacks under different levels of hints provided by the red team. Results show high accuracy for adversarial-attack-based methods (100\\% correct prediction, using hints), which is very promising, whilst the other techniques yield more varied performance. During our LLM-focused rounds, we find that there are not many parallel methods that we could apply from our study with CNNs. Instead, we find that effective LLM auditing methods require some hints about the undesired distribution, which can then used in standard black-box and open-weight methods to probe the models further and reveal their misalignment. We open-source our auditing games (with the model and data) and hope that our findings contribute to designing better audits.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "main section: 8 pages, 4 figures, 1 table total: 34 pages, 44 figures, 12 tables",
    "pdf_url": "https://arxiv.org/pdf/2508.06827v2",
    "published_date": "2025-08-09 04:57:38 UTC",
    "updated_date": "2025-08-22 03:07:32 UTC"
  },
  {
    "arxiv_id": "2508.06823v1",
    "title": "Natural Language-Driven Viewpoint Navigation for Volume Exploration via Semantic Block Representation",
    "authors": [
      "Xuan Zhao",
      "Jun Tao"
    ],
    "abstract": "Exploring volumetric data is crucial for interpreting scientific datasets. However, selecting optimal viewpoints for effective navigation can be challenging, particularly for users without extensive domain expertise or familiarity with 3D navigation. In this paper, we propose a novel framework that leverages natural language interaction to enhance volumetric data exploration. Our approach encodes volumetric blocks to capture and differentiate underlying structures. It further incorporates a CLIP Score mechanism, which provides semantic information to the blocks to guide navigation. The navigation is empowered by a reinforcement learning framework that leverage these semantic cues to efficiently search for and identify desired viewpoints that align with the user's intent. The selected viewpoints are evaluated using CLIP Score to ensure that they best reflect the user queries. By automating viewpoint selection, our method improves the efficiency of volumetric data navigation and enhances the interpretability of complex scientific phenomena.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by IEEE VIS 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.06823v1",
    "published_date": "2025-08-09 04:44:59 UTC",
    "updated_date": "2025-08-09 04:44:59 UTC"
  },
  {
    "arxiv_id": "2508.06811v1",
    "title": "Anatomy of a Machine Learning Ecosystem: 2 Million Models on Hugging Face",
    "authors": [
      "Benjamin Laufer",
      "Hamidah Oderinwale",
      "Jon Kleinberg"
    ],
    "abstract": "Many have observed that the development and deployment of generative machine learning (ML) and artificial intelligence (AI) models follow a distinctive pattern in which pre-trained models are adapted and fine-tuned for specific downstream tasks. However, there is limited empirical work that examines the structure of these interactions. This paper analyzes 1.86 million models on Hugging Face, a leading peer production platform for model development. Our study of model family trees -- networks that connect fine-tuned models to their base or parent -- reveals sprawling fine-tuning lineages that vary widely in size and structure. Using an evolutionary biology lens to study ML models, we use model metadata and model cards to measure the genetic similarity and mutation of traits over model families. We find that models tend to exhibit a family resemblance, meaning their genetic markers and traits exhibit more overlap when they belong to the same model family. However, these similarities depart in certain ways from standard models of asexual reproduction, because mutations are fast and directed, such that two `sibling' models tend to exhibit more similarity than parent/child pairs. Further analysis of the directional drifts of these mutations reveals qualitative insights about the open machine learning ecosystem: Licenses counter-intuitively drift from restrictive, commercial licenses towards permissive or copyleft licenses, often in violation of upstream license's terms; models evolve from multi-lingual compatibility towards english-only compatibility; and model cards reduce in length and standardize by turning, more often, to templates and automatically generated text. Overall, this work takes a step toward an empirically grounded understanding of model fine-tuning and suggests that ecological models and methods can yield novel scientific insights.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.SI",
    "comment": "29 pages, 18 figures and tables",
    "pdf_url": "https://arxiv.org/pdf/2508.06811v1",
    "published_date": "2025-08-09 04:08:49 UTC",
    "updated_date": "2025-08-09 04:08:49 UTC"
  },
  {
    "arxiv_id": "2508.08315v1",
    "title": "EU Digital Regulation and Guatemala: AI, 5G, and Cybersecurity",
    "authors": [
      "Victor Lopez Juarez"
    ],
    "abstract": "The paper examines how EU rules in AI, 5G, and cybersecurity operate as transnational governance and shape policy in Guatemala. It outlines the AI Act's risk approach, the 5G Action Plan and Security Toolbox, and the cybersecurity regime built on ENISA, NIS2, the Cybersecurity Act, and the Cyber Resilience Act. It traces extraterritorial channels such as the Brussels effect, private standards, supply chain clauses, and data transfer controls. Guatemala specific impacts include SME compliance costs, procurement limits, environmental trade-offs in rollout, rights risks, and capacity gaps. The paper maps current national measures and proposes five guardrails: digital constitutionalism, green IT duties, third country impact assessment, standards co-design, and recognition of regulatory diversity.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.08315v1",
    "published_date": "2025-08-09 03:34:18 UTC",
    "updated_date": "2025-08-09 03:34:18 UTC"
  },
  {
    "arxiv_id": "2508.06806v1",
    "title": "Offline-to-Online Reinforcement Learning with Classifier-Free Diffusion Generation",
    "authors": [
      "Xiao Huang",
      "Xu Liu",
      "Enze Zhang",
      "Tong Yu",
      "Shuai Li"
    ],
    "abstract": "Offline-to-online Reinforcement Learning (O2O RL) aims to perform online fine-tuning on an offline pre-trained policy to minimize costly online interactions. Existing work used offline datasets to generate data that conform to the online data distribution for data augmentation. However, generated data still exhibits a gap with the online data, limiting overall performance. To address this, we propose a new data augmentation approach, Classifier-Free Diffusion Generation (CFDG). Without introducing additional classifier training overhead, CFDG leverages classifier-free guidance diffusion to significantly enhance the generation quality of offline and online data with different distributions. Additionally, it employs a reweighting method to enable more generated data to align with the online data, enhancing performance while maintaining the agent's stability. Experimental results show that CFDG outperforms replaying the two data types or using a standard diffusion model to generate new data. Our method is versatile and can be integrated with existing offline-to-online RL algorithms. By implementing CFDG to popular methods IQL, PEX and APL, we achieve a notable 15% average improvement in empirical performance on the D4RL benchmark such as MuJoCo and AntMaze.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML2025",
    "pdf_url": "https://arxiv.org/pdf/2508.06806v1",
    "published_date": "2025-08-09 03:32:23 UTC",
    "updated_date": "2025-08-09 03:32:23 UTC"
  },
  {
    "arxiv_id": "2508.06800v2",
    "title": "Hardness-Aware Dynamic Curriculum Learning for Robust Multimodal Emotion Recognition with Missing Modalities",
    "authors": [
      "Rui Liu",
      "Haolin Zuo",
      "Zheng Lian",
      "Hongyu Yuan",
      "Qi Fan"
    ],
    "abstract": "Missing modalities have recently emerged as a critical research direction in multimodal emotion recognition (MER). Conventional approaches typically address this issue through missing modality reconstruction. However, these methods fail to account for variations in reconstruction difficulty across different samples, consequently limiting the model's ability to handle hard samples effectively. To overcome this limitation, we propose a novel Hardness-Aware Dynamic Curriculum Learning framework, termed HARDY-MER. Our framework operates in two key stages: first, it estimates the hardness level of each sample, and second, it strategically emphasizes hard samples during training to enhance model performance on these challenging instances. Specifically, we first introduce a Multi-view Hardness Evaluation mechanism that quantifies reconstruction difficulty by considering both Direct Hardness (modality reconstruction errors) and Indirect Hardness (cross-modal mutual information). Meanwhile, we introduce a Retrieval-based Dynamic Curriculum Learning strategy that dynamically adjusts the training curriculum by retrieving samples with similar semantic information and balancing the learning focus between easy and hard instances. Extensive experiments on benchmark datasets demonstrate that HARDY-MER consistently outperforms existing methods in missing-modality scenarios. Our code will be made publicly available at https://github.com/HARDY-MER/HARDY-MER.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.06800v2",
    "published_date": "2025-08-09 03:10:56 UTC",
    "updated_date": "2025-08-14 16:06:55 UTC"
  },
  {
    "arxiv_id": "2508.06799v2",
    "title": "LSDTs: LLM-Augmented Semantic Digital Twins for Adaptive Knowledge-Intensive Infrastructure Planning",
    "authors": [
      "Naiyi Li",
      "Zihui Ma",
      "Runlong Yu",
      "Lingyao Li"
    ],
    "abstract": "Digital Twins (DTs) offer powerful tools for managing complex infrastructure systems, but their effectiveness is often limited by challenges in integrating unstructured knowledge. Recent advances in Large Language Models (LLMs) bring new potential to address this gap, with strong abilities in extracting and organizing diverse textual information. We therefore propose LSDTs (LLM-Augmented Semantic Digital Twins), a framework that helps LLMs extract planning knowledge from unstructured documents like environmental regulations and technical guidelines, and organize it into a formal ontology. This ontology forms a semantic layer that powers a digital twin-a virtual model of the physical system-allowing it to simulate realistic, regulation-aware planning scenarios. We evaluate LSDTs through a case study of offshore wind farm planning in Maryland, including its application during Hurricane Sandy. Results demonstrate that LSDTs support interpretable, regulation-aware layout optimization, enable high-fidelity simulation, and enhance adaptability in infrastructure planning. This work shows the potential of combining generative AI with digital twins to support complex, knowledge-driven planning tasks.",
    "categories": [
      "cs.ET",
      "cs.AI"
    ],
    "primary_category": "cs.ET",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.06799v2",
    "published_date": "2025-08-09 03:06:40 UTC",
    "updated_date": "2025-08-12 04:04:36 UTC"
  },
  {
    "arxiv_id": "2508.06793v2",
    "title": "Geometry-Aware Spiking Graph Neural Network",
    "authors": [
      "Bowen Zhang",
      "Genan Dai",
      "Hu Huang",
      "Long Lan"
    ],
    "abstract": "Graph Neural Networks (GNNs) have demonstrated impressive capabilities in modeling graph-structured data, while Spiking Neural Networks (SNNs) offer high energy efficiency through sparse, event-driven computation. However, existing spiking GNNs predominantly operate in Euclidean space and rely on fixed geometric assumptions, limiting their capacity to model complex graph structures such as hierarchies and cycles. To overcome these limitations, we propose \\method{}, a novel Geometry-Aware Spiking Graph Neural Network that unifies spike-based neural dynamics with adaptive representation learning on Riemannian manifolds. \\method{} features three key components: a Riemannian Embedding Layer that projects node features into a pool of constant-curvature manifolds, capturing non-Euclidean structures; a Manifold Spiking Layer that models membrane potential evolution and spiking behavior in curved spaces via geometry-consistent neighbor aggregation and curvature-based attention; and a Manifold Learning Objective that enables instance-wise geometry adaptation through jointly optimized classification and link prediction losses defined over geodesic distances. All modules are trained using Riemannian SGD, eliminating the need for backpropagation through time. Extensive experiments on multiple benchmarks show that GSG achieves superior accuracy, robustness, and energy efficiency compared to both Euclidean SNNs and manifold-based GNNs, establishing a new paradigm for curvature-aware, energy-efficient graph learning.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.06793v2",
    "published_date": "2025-08-09 02:52:38 UTC",
    "updated_date": "2025-08-25 10:22:46 UTC"
  },
  {
    "arxiv_id": "2508.10031v1",
    "title": "Context Misleads LLMs: The Role of Context Filtering in Maintaining Safe Alignment of LLMs",
    "authors": [
      "Jinhwa Kim",
      "Ian G. Harris"
    ],
    "abstract": "While Large Language Models (LLMs) have shown significant advancements in performance, various jailbreak attacks have posed growing safety and ethical risks. Malicious users often exploit adversarial context to deceive LLMs, prompting them to generate responses to harmful queries. In this study, we propose a new defense mechanism called Context Filtering model, an input pre-processing method designed to filter out untrustworthy and unreliable context while identifying the primary prompts containing the real user intent to uncover concealed malicious intent. Given that enhancing the safety of LLMs often compromises their helpfulness, potentially affecting the experience of benign users, our method aims to improve the safety of the LLMs while preserving their original performance. We evaluate the effectiveness of our model in defending against jailbreak attacks through comparative analysis, comparing our approach with state-of-the-art defense mechanisms against six different attacks and assessing the helpfulness of LLMs under these defenses. Our model demonstrates its ability to reduce the Attack Success Rates of jailbreak attacks by up to 88% while maintaining the original LLMs' performance, achieving state-of-the-art Safety and Helpfulness Product results. Notably, our model is a plug-and-play method that can be applied to all LLMs, including both white-box and black-box models, to enhance their safety without requiring any fine-tuning of the models themselves. We will make our model publicly available for research purposes.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "13 pages, 2 figures",
    "pdf_url": "https://arxiv.org/pdf/2508.10031v1",
    "published_date": "2025-08-09 02:37:59 UTC",
    "updated_date": "2025-08-09 02:37:59 UTC"
  },
  {
    "arxiv_id": "2508.06784v1",
    "title": "Mode-Aware Non-Linear Tucker Autoencoder for Tensor-based Unsupervised Learning",
    "authors": [
      "Junjing Zheng",
      "Chengliang Song",
      "Weidong Jiang",
      "Xinyu Zhang"
    ],
    "abstract": "High-dimensional data, particularly in the form of high-order tensors, presents a major challenge in self-supervised learning. While MLP-based autoencoders (AE) are commonly employed, their dependence on flattening operations exacerbates the curse of dimensionality, leading to excessively large model sizes, high computational overhead, and challenging optimization for deep structural feature capture. Although existing tensor networks alleviate computational burdens through tensor decomposition techniques, most exhibit limited capability in learning non-linear relationships. To overcome these limitations, we introduce the Mode-Aware Non-linear Tucker Autoencoder (MA-NTAE). MA-NTAE generalized classical Tucker decomposition to a non-linear framework and employs a Pick-and-Unfold strategy, facilitating flexible per-mode encoding of high-order tensors via recursive unfold-encode-fold operations, effectively integrating tensor structural priors. Notably, MA-NTAE exhibits linear growth in computational complexity with tensor order and proportional growth with mode dimensions. Extensive experiments demonstrate MA-NTAE's performance advantages over standard AE and current tensor networks in compression and clustering tasks, which become increasingly pronounced for higher-order, higher-dimensional tensors.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.06784v1",
    "published_date": "2025-08-09 02:26:32 UTC",
    "updated_date": "2025-08-09 02:26:32 UTC"
  },
  {
    "arxiv_id": "2508.06783v2",
    "title": "PROPS: Progressively Private Self-alignment of Large Language Models",
    "authors": [
      "Noel Teku",
      "Fengwei Tian",
      "Payel Bhattacharjee",
      "Souradip Chakraborty",
      "Amrit Singh Bedi",
      "Ravi Tandon"
    ],
    "abstract": "Alignment is a key step in developing Large Language Models (LLMs) using human feedback to ensure adherence to human values and societal norms. Dependence on human feedback raises privacy concerns about how much a labeler's preferences may reveal about their personal values, beliefs, and personality traits. Existing approaches, such as Differentially Private SGD (DP-SGD), provide rigorous privacy guarantees by privatizing gradients during fine-tuning and alignment but can provide more privacy than necessary as human preferences are tied only to labels of (prompt, response) pairs and can degrade model utility. This work focuses on LLM alignment with preference-level privacy, which preserves the privacy of preference labels provided by humans. We propose PROPS (PROgressively Private Self-alignment), a multi-stage privacy preserving alignment framework where privately aligned models in previous stages can serve as labelers for supplementing training data in the subsequent stages of alignment. We present theoretical guarantees for PROPS as well as comprehensive validation using multiple models (Pythia and GPT) and datasets (AlpacaEval, Anthropic HH-RLHF, truthy-dpo-v0.1) to demonstrate the utility of PROPS over existing methods while still providing high privacy. For the same privacy budget, alignment via PROPS can achieve up to 3x higher win-rates compared to DP-SGD, and 2.5x higher win-rates compared to Randomized Response (RR) based alignment.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.IT"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted in the Transactions on Machine Learning Research (TMLR), 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.06783v2",
    "published_date": "2025-08-09 02:17:47 UTC",
    "updated_date": "2025-12-09 20:15:49 UTC"
  },
  {
    "arxiv_id": "2508.06781v1",
    "title": "BiXSE: Improving Dense Retrieval via Probabilistic Graded Relevance Distillation",
    "authors": [
      "Christos Tsirigotis",
      "Vaibhav Adlakha",
      "Joao Monteiro",
      "Aaron Courville",
      "Perouz Taslakian"
    ],
    "abstract": "Neural sentence embedding models for dense retrieval typically rely on binary relevance labels, treating query-document pairs as either relevant or irrelevant. However, real-world relevance often exists on a continuum, and recent advances in large language models (LLMs) have made it feasible to scale the generation of fine-grained graded relevance labels. In this work, we propose BiXSE, a simple and effective pointwise training method that optimizes binary cross-entropy (BCE) over LLM-generated graded relevance scores. BiXSE interprets these scores as probabilistic targets, enabling granular supervision from a single labeled query-document pair per query. Unlike pairwise or listwise losses that require multiple annotated comparisons per query, BiXSE achieves strong performance with reduced annotation and compute costs by leveraging in-batch negatives. Extensive experiments across sentence embedding (MMTEB) and retrieval benchmarks (BEIR, TREC-DL) show that BiXSE consistently outperforms softmax-based contrastive learning (InfoNCE), and matches or exceeds strong pairwise ranking baselines when trained on LLM-supervised data. BiXSE offers a robust, scalable alternative for training dense retrieval models as graded relevance supervision becomes increasingly accessible.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "22 pages, 5 figures, accepted at COLM 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.06781v1",
    "published_date": "2025-08-09 02:15:17 UTC",
    "updated_date": "2025-08-09 02:15:17 UTC"
  },
  {
    "arxiv_id": "2508.06776v1",
    "title": "Zero-Direction Probing: A Linear-Algebraic Framework for Deep Analysis of Large-Language-Model Drift",
    "authors": [
      "Amit Pandey"
    ],
    "abstract": "We present Zero-Direction Probing (ZDP), a theory-only framework for detecting model drift from null directions of transformer activations without task labels or output evaluations. Under assumptions A1--A6, we prove: (i) the Variance--Leak Theorem, (ii) Fisher Null-Conservation, (iii) a Rank--Leak bound for low-rank updates, and (iv) a logarithmic-regret guarantee for online null-space trackers. We derive a Spectral Null-Leakage (SNL) metric with non-asymptotic tail bounds and a concentration inequality, yielding a-priori thresholds for drift under a Gaussian null model. These results show that monitoring right/left null spaces of layer activations and their Fisher geometry provides concrete, testable guarantees on representational change.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages",
    "pdf_url": "https://arxiv.org/pdf/2508.06776v1",
    "published_date": "2025-08-09 02:05:59 UTC",
    "updated_date": "2025-08-09 02:05:59 UTC"
  },
  {
    "arxiv_id": "2508.13172v1",
    "title": "White-Box Reasoning: Synergizing LLM Strategy and gm/Id Data for Automated Analog Circuit Design",
    "authors": [
      "Jianqiu Chen",
      "Siqi Li",
      "Xu He"
    ],
    "abstract": "Analog IC design is a bottleneck due to its reliance on experience and inefficient simulations, as traditional formulas fail in advanced nodes. Applying Large Language Models (LLMs) directly to this problem risks mere \"guessing\" without engineering principles. We present a \"synergistic reasoning\" framework that integrates an LLM's strategic reasoning with the physical precision of the gm/Id methodology. By empowering the LLM with gm/Id lookup tables, it becomes a quantitative, data-driven design partner.\n  We validated this on a two-stage op-amp, where our framework enabled the Gemini model to meet all TT corner specs in 5 iterations and extended optimization to all PVT corners. A crucial ablation study proved gm/Id data is key for this efficiency and precision; without it, the LLM is slower and deviates. Compared to a senior engineer's design, our framework achieves quasi-expert quality with an order-of-magnitude improvement in efficiency. This work validates a path for true analog design automation by combining LLM reasoning with scientific circuit design methodologies.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AR",
    "comment": "8 pages, 4 figures, 7 Tables",
    "pdf_url": "https://arxiv.org/pdf/2508.13172v1",
    "published_date": "2025-08-09 01:25:27 UTC",
    "updated_date": "2025-08-09 01:25:27 UTC"
  },
  {
    "arxiv_id": "2508.08314v1",
    "title": "Assessing the Quality of AI-Generated Exams: A Large-Scale Field Study",
    "authors": [
      "Calvin Isley",
      "Joshua Gilbert",
      "Evangelos Kassos",
      "Michaela Kocher",
      "Allen Nie",
      "Emma Brunskill",
      "Ben Domingue",
      "Jake Hofman",
      "Joscha Legewie",
      "Teddy Svoronos",
      "Charlotte Tuminelli",
      "Sharad Goel"
    ],
    "abstract": "While large language models (LLMs) challenge conventional methods of teaching and learning, they present an exciting opportunity to improve efficiency and scale high-quality instruction. One promising application is the generation of customized exams, tailored to specific course content. There has been significant recent excitement on automatically generating questions using artificial intelligence, but also comparatively little work evaluating the psychometric quality of these items in real-world educational settings. Filling this gap is an important step toward understanding generative AI's role in effective test design. In this study, we introduce and evaluate an iterative refinement strategy for question generation, repeatedly producing, assessing, and improving questions through cycles of LLM-generated critique and revision. We evaluate the quality of these AI-generated questions in a large-scale field study involving 91 classes -- covering computer science, mathematics, chemistry, and more -- in dozens of colleges across the United States, comprising nearly 1700 students. Our analysis, based on item response theory (IRT), suggests that for students in our sample the AI-generated questions performed comparably to expert-created questions designed for standardized exams. Our results illustrate the power of AI to make high-quality assessments more readily available, benefiting both teachers and students.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.08314v1",
    "published_date": "2025-08-09 01:20:53 UTC",
    "updated_date": "2025-08-09 01:20:53 UTC"
  },
  {
    "arxiv_id": "2508.06767v1",
    "title": "PANAMA: A Network-Aware MARL Framework for Multi-Agent Path Finding in Digital Twin Ecosystems",
    "authors": [
      "Arman Dogru",
      "R. Irem Bor-Yaliniz",
      "Nimal Gamini Senarath"
    ],
    "abstract": "Digital Twins (DTs) are transforming industries through advanced data processing and analysis, positioning the world of DTs, Digital World, as a cornerstone of nextgeneration technologies including embodied AI. As robotics and automated systems scale, efficient data-sharing frameworks and robust algorithms become critical. We explore the pivotal role of data handling in next-gen networks, focusing on dynamics between application and network providers (AP/NP) in DT ecosystems. We introduce PANAMA, a novel algorithm with Priority Asymmetry for Network Aware Multi-agent Reinforcement Learning (MARL) based multi-agent path finding (MAPF). By adopting a Centralized Training with Decentralized Execution (CTDE) framework and asynchronous actor-learner architectures, PANAMA accelerates training while enabling autonomous task execution by embodied AI. Our approach demonstrates superior pathfinding performance in accuracy, speed, and scalability compared to existing benchmarks. Through simulations, we highlight optimized data-sharing strategies for scalable, automated systems, ensuring resilience in complex, real-world environments. PANAMA bridges the gap between network-aware decision-making and robust multi-agent coordination, advancing the synergy between DTs, wireless networks, and AI-driven automation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC",
      "cs.MA",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.06767v1",
    "published_date": "2025-08-09 00:59:55 UTC",
    "updated_date": "2025-08-09 00:59:55 UTC"
  },
  {
    "arxiv_id": "2508.06763v3",
    "title": "SafePLUG: Empowering Multimodal LLMs with Pixel-Level Insight and Temporal Grounding for Traffic Accident Understanding",
    "authors": [
      "Zihao Sheng",
      "Zilin Huang",
      "Yansong Qu",
      "Jiancong Chen",
      "Yuhao Luo",
      "Yen-Jung Chen",
      "Yue Leng",
      "Sikai Chen"
    ],
    "abstract": "Multimodal large language models (MLLMs) have achieved remarkable progress across a range of vision-language tasks and demonstrate strong potential for traffic accident understanding. However, existing MLLMs in this domain primarily focus on coarse-grained image-level or video-level comprehension and often struggle to handle fine-grained visual details or localized scene components, limiting their applicability in complex accident scenarios. To address these limitations, we propose SafePLUG, a novel framework that empowers MLLMs with both Pixel-Level Understanding and temporal Grounding for comprehensive traffic accident analysis. SafePLUG supports both arbitrary-shaped visual prompts for region-aware question answering and pixel-level segmentation based on language instructions, while also enabling the recognition of temporally anchored events in traffic accident scenarios. To advance the development of MLLMs for traffic accident understanding, we curate a new dataset containing multimodal question-answer pairs centered on diverse accident scenarios, with detailed pixel-level annotations and temporal event boundaries. Experimental results show that SafePLUG achieves strong performance on multiple tasks, including region-based question answering, pixel-level segmentation, temporal event localization, and accident event understanding. These capabilities lay a foundation for fine-grained understanding of complex traffic scenes, with the potential to improve driving safety and enhance situational awareness in smart transportation systems. The code, dataset, and model checkpoints will be made publicly available at: https://zihaosheng.github.io/SafePLUG",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "The code, dataset, and model checkpoints will be made publicly available at: https://zihaosheng.github.io/SafePLUG",
    "pdf_url": "https://arxiv.org/pdf/2508.06763v3",
    "published_date": "2025-08-09 00:25:24 UTC",
    "updated_date": "2025-10-30 23:11:01 UTC"
  },
  {
    "arxiv_id": "2508.06756v2",
    "title": "FoundBioNet: A Foundation-Based Model for IDH Genotyping of Glioma from Multi-Parametric MRI",
    "authors": [
      "Somayeh Farahani",
      "Marjaneh Hejazi",
      "Antonio Di Ieva",
      "Sidong Liu"
    ],
    "abstract": "Accurate, noninvasive detection of isocitrate dehydrogenase (IDH) mutation is essential for effective glioma management. Traditional methods rely on invasive tissue sampling, which may fail to capture a tumor's spatial heterogeneity. While deep learning models have shown promise in molecular profiling, their performance is often limited by scarce annotated data. In contrast, foundation deep learning models offer a more generalizable approach for glioma imaging biomarkers. We propose a Foundation-based Biomarker Network (FoundBioNet) that utilizes a SWIN-UNETR-based architecture to noninvasively predict IDH mutation status from multi-parametric MRI. Two key modules are incorporated: Tumor-Aware Feature Encoding (TAFE) for extracting multi-scale, tumor-focused features, and Cross-Modality Differential (CMD) for highlighting subtle T2-FLAIR mismatch signals associated with IDH mutation. The model was trained and validated on a diverse, multi-center cohort of 1705 glioma patients from six public datasets. Our model achieved AUCs of 90.58%, 88.08%, 65.41%, and 80.31% on independent test sets from EGD, TCGA, Ivy GAP, RHUH, and UPenn, consistently outperforming baseline approaches (p <= 0.05). Ablation studies confirmed that both the TAFE and CMD modules are essential for improving predictive accuracy. By integrating large-scale pretraining and task-specific fine-tuning, FoundBioNet enables generalizable glioma characterization. This approach enhances diagnostic accuracy and interpretability, with the potential to enable more personalized patient care.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted for oral and poster presentation at MICCAI 2025",
    "pdf_url": "https://arxiv.org/pdf/2508.06756v2",
    "published_date": "2025-08-09 00:08:10 UTC",
    "updated_date": "2025-09-30 06:19:19 UTC"
  },
  {
    "arxiv_id": "2508.06755v1",
    "title": "Many-Turn Jailbreaking",
    "authors": [
      "Xianjun Yang",
      "Liqiang Xiao",
      "Shiyang Li",
      "Faisal Ladhak",
      "Hyokun Yun",
      "Linda Ruth Petzold",
      "Yi Xu",
      "William Yang Wang"
    ],
    "abstract": "Current jailbreaking work on large language models (LLMs) aims to elicit unsafe outputs from given prompts. However, it only focuses on single-turn jailbreaking targeting one specific query. On the contrary, the advanced LLMs are designed to handle extremely long contexts and can thus conduct multi-turn conversations. So, we propose exploring multi-turn jailbreaking, in which the jailbroken LLMs are continuously tested on more than the first-turn conversation or a single target query. This is an even more serious threat because 1) it is common for users to continue asking relevant follow-up questions to clarify certain jailbroken details, and 2) it is also possible that the initial round of jailbreaking causes the LLMs to respond to additional irrelevant questions consistently. As the first step (First draft done at June 2024) in exploring multi-turn jailbreaking, we construct a Multi-Turn Jailbreak Benchmark (MTJ-Bench) for benchmarking this setting on a series of open- and closed-source models and provide novel insights into this new safety threat. By revealing this new vulnerability, we aim to call for community efforts to build safer LLMs and pave the way for a more in-depth understanding of jailbreaking LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "https://arxiv.org/pdf/2508.06755v1",
    "published_date": "2025-08-09 00:02:39 UTC",
    "updated_date": "2025-08-09 00:02:39 UTC"
  }
]