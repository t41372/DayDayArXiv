[
  {
    "arxiv_id": "2407.02706v2",
    "title": "Pushing the Boundary: Specialising Deep Configuration Performance Learning",
    "authors": [
      "Jingzhi Gong"
    ],
    "abstract": "Software systems often have numerous configuration options that can be\nadjusted to meet different performance requirements. However, understanding the\ncombined impact of these options on performance is often challenging,\nespecially with limited real-world data. To tackle this issue, deep learning\ntechniques have gained popularity due to their ability to capture complex\nrelationships even with limited samples. This thesis begins with a systematic\nliterature review of deep learning techniques in configuration performance\nmodeling, analyzing 85 primary papers out of 948 searched papers. It identifies\nknowledge gaps and sets three objectives for the thesis. The first knowledge\ngap is the lack of understanding about which encoding scheme is better and in\nwhat circumstances. To address this, the thesis conducts an empirical study\ncomparing three popular encoding schemes. Actionable suggestions are provided\nto support more reliable decisions. Another knowledge gap is the sparsity\ninherited from the configuration landscape. To handle this, the thesis proposes\na model-agnostic and sparsity-robust framework called DaL, which uses a\n\"divide-and-learn\" approach. DaL outperforms state-of-the-art approaches in\naccuracy improvement across various real-world systems. The thesis also\naddresses the limitation of predicting under static environments by proposing a\nsequential meta-learning framework called SeMPL. Unlike traditional\nmeta-learning frameworks, SeMPL trains meta-environments in a specialized\norder, resulting in significantly improved prediction accuracy in\nmulti-environment scenarios. Overall, the thesis identifies and addresses\ncritical knowledge gaps in deep performance learning, significantly advancing\nthe accuracy of performance prediction.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "This PhD thesis was submitted in May 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.02706v2",
    "published_date": "2024-07-02 22:59:19 UTC",
    "updated_date": "2025-01-30 13:56:45 UTC"
  },
  {
    "arxiv_id": "2407.02694v2",
    "title": "LLM-Select: Feature Selection with Large Language Models",
    "authors": [
      "Daniel P. Jeong",
      "Zachary C. Lipton",
      "Pradeep Ravikumar"
    ],
    "abstract": "In this paper, we demonstrate a surprising capability of large language\nmodels (LLMs): given only input feature names and a description of a prediction\ntask, they are capable of selecting the most predictive features, with\nperformance rivaling the standard tools of data science. Remarkably, these\nmodels exhibit this capacity across various query mechanisms. For example, we\nzero-shot prompt an LLM to output a numerical importance score for a feature\n(e.g., \"blood pressure\") in predicting an outcome of interest (e.g., \"heart\nfailure\"), with no additional context. In particular, we find that the latest\nmodels, such as GPT-4, can consistently identify the most predictive features\nregardless of the query mechanism and across various prompting strategies. We\nillustrate these findings through extensive experiments on real-world data,\nwhere we show that LLM-based feature selection consistently achieves strong\nperformance competitive with data-driven methods such as the LASSO, despite\nnever having looked at the downstream training data. Our findings suggest that\nLLMs may be useful not only for selecting the best features for training but\nalso for deciding which features to collect in the first place. This could\nbenefit practitioners in domains like healthcare and the social sciences, where\ncollecting high-quality data comes at a high cost.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Published in Transactions on Machine Learning Research (TMLR), April\n  2025",
    "pdf_url": "http://arxiv.org/pdf/2407.02694v2",
    "published_date": "2024-07-02 22:23:40 UTC",
    "updated_date": "2025-04-17 21:50:37 UTC"
  },
  {
    "arxiv_id": "2407.02693v1",
    "title": "UAV-assisted Distributed Learning for Environmental Monitoring in Rural Environments",
    "authors": [
      "Vukan Ninkovic",
      "Dejan Vukobratovic",
      "Dragisa Miskovic"
    ],
    "abstract": "Distributed learning and inference algorithms have become indispensable for\nIoT systems, offering benefits such as workload alleviation, data privacy\npreservation, and reduced latency. This paper introduces an innovative approach\nthat utilizes unmanned aerial vehicles (UAVs) as a coverage extension relay for\nIoT environmental monitoring in rural areas. Our method integrates a split\nlearning (SL) strategy between edge devices, a UAV and a server to enhance\nadaptability and performance of inference mechanisms. By employing UAVs as a\nrelay and by incorporating SL, we address connectivity and resource constraints\nfor applications of learning in IoT in remote settings. Our system model\naccounts for diverse channel conditions to determine the most suitable\ntransmission strategy for optimal system behaviour. Through simulation\nanalysis, the proposed approach demonstrates its robustness and adaptability,\neven excelling under adverse channel conditions. Integrating UAV relaying and\nthe SL paradigm offers significant flexibility to the server, enabling adaptive\nstrategies that consider various trade-offs beyond simply minimizing overall\ninference quality.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02693v1",
    "published_date": "2024-07-02 22:21:03 UTC",
    "updated_date": "2024-07-02 22:21:03 UTC"
  },
  {
    "arxiv_id": "2407.02678v1",
    "title": "Reasoning in Large Language Models: A Geometric Perspective",
    "authors": [
      "Romain Cosentino",
      "Sarath Shekkizhar"
    ],
    "abstract": "The advancement of large language models (LLMs) for real-world applications\nhinges critically on enhancing their reasoning capabilities. In this work, we\nexplore the reasoning abilities of large language models (LLMs) through their\ngeometrical understanding. We establish a connection between the expressive\npower of LLMs and the density of their self-attention graphs. Our analysis\ndemonstrates that the density of these graphs defines the intrinsic dimension\nof the inputs to the MLP blocks. We demonstrate through theoretical analysis\nand toy examples that a higher intrinsic dimension implies a greater expressive\ncapacity of the LLM. We further provide empirical evidence linking this\ngeometric framework to recent advancements in methods aimed at enhancing the\nreasoning capabilities of LLMs.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02678v1",
    "published_date": "2024-07-02 21:39:53 UTC",
    "updated_date": "2024-07-02 21:39:53 UTC"
  },
  {
    "arxiv_id": "2407.02673v1",
    "title": "A Novel Approach to Image EEG Sleep Data for Improving Quality of Life in Patients Suffering From Brain Injuries Using DreamDiffusion",
    "authors": [
      "David Fahim",
      "Joshveer Grewal",
      "Ritvik Ellendula"
    ],
    "abstract": "Those experiencing strokes, traumatic brain injuries, and drug complications\ncan often end up hospitalized and diagnosed with coma or locked-in syndrome.\nSuch mental impediments can permanently alter the neurological pathways in work\nand significantly decrease the quality of life (QoL). It is critical to\ntranslate brain signals into images to gain a deeper understanding of the\nthoughts of a comatose patient. Traditionally, brain signals collected by an\nEEG could only be translated into text, but with the novel method of an\nopen-source model available on GitHub, DreamDiffusion can be used to convert\nbrain waves into images directly. DreamDiffusion works by extracting features\nfrom EEG signals and then using the features to create images through\nStableDiffusion. Upon this, we made further improvements that could make\nStableDiffusion the forerunner technology in waves to media translation. In our\nstudy, we begin by modifying the existing DreamDiffusion codebase so that it\ndoes not require any prior setup, avoiding any confusing steps needed to run\nthe model from GitHub. For many researchers, the incomplete setup process,\nerrors in the existing code, and a lack of directions made it nearly impossible\nto run, not even considering the model's performance. We brought the code into\nGoogle Colab so users could run and evaluate problems cell-by-cell, eliminating\nthe specific file and repository dependencies. We also provided the original\ntraining data file so users do not need to purchase the necessary computing\npower to train the model from the given dataset. The second change is utilizing\nthe mutability of the code and optimizing the model so it can be used to\ngenerate images from other given inputs, such as sleep data. Additionally, the\naffordability of EEG technology allows for global dissemination and creates the\nopportunity for those who want to work on the shared DreamDiffusion model.",
    "categories": [
      "q-bio.NC",
      "cs.AI"
    ],
    "primary_category": "q-bio.NC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02673v1",
    "published_date": "2024-07-02 21:26:28 UTC",
    "updated_date": "2024-07-02 21:26:28 UTC"
  },
  {
    "arxiv_id": "2407.02670v1",
    "title": "Adversarial Magnification to Deceive Deepfake Detection through Super Resolution",
    "authors": [
      "Davide Alessandro Coccomini",
      "Roberto Caldelli",
      "Giuseppe Amato",
      "Fabrizio Falchi",
      "Claudio Gennaro"
    ],
    "abstract": "Deepfake technology is rapidly advancing, posing significant challenges to\nthe detection of manipulated media content. Parallel to that, some adversarial\nattack techniques have been developed to fool the deepfake detectors and make\ndeepfakes even more difficult to be detected. This paper explores the\napplication of super resolution techniques as a possible adversarial attack in\ndeepfake detection. Through our experiments, we demonstrate that minimal\nchanges made by these methods in the visual appearance of images can have a\nprofound impact on the performance of deepfake detection systems. We propose a\nnovel attack using super resolution as a quick, black-box and effective method\nto camouflage fake images and/or generate false alarms on pristine images. Our\nresults indicate that the usage of super resolution can significantly impair\nthe accuracy of deepfake detectors, thereby highlighting the vulnerability of\nsuch systems to adversarial attacks. The code to reproduce our experiments is\navailable at:\nhttps://github.com/davide-coccomini/Adversarial-Magnification-to-Deceive-Deepfake-Detection-through-Super-Resolution",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02670v1",
    "published_date": "2024-07-02 21:17:36 UTC",
    "updated_date": "2024-07-02 21:17:36 UTC"
  },
  {
    "arxiv_id": "2407.17484v1",
    "title": "A Survey of Accessible Explainable Artificial Intelligence Research",
    "authors": [
      "Chukwunonso Henry Nwokoye",
      "Maria J. P. Peixoto",
      "Akriti Pandey",
      "Lauren Pardy",
      "Mahadeo Sukhai",
      "Peter R. Lewis"
    ],
    "abstract": "The increasing integration of Artificial Intelligence (AI) into everyday life\nmakes it essential to explain AI-based decision-making in a way that is\nunderstandable to all users, including those with disabilities. Accessible\nexplanations are crucial as accessibility in technology promotes digital\ninclusion and allows everyone, regardless of their physical, sensory, or\ncognitive abilities, to use these technologies effectively. This paper presents\na systematic literature review of the research on the accessibility of\nExplainable Artificial Intelligence (XAI), specifically considering persons\nwith sight loss. Our methodology includes searching several academic databases\nwith search terms to capture intersections between XAI and accessibility. The\nresults of this survey highlight the lack of research on Accessible XAI (AXAI)\nand stress the importance of including the disability community in XAI\ndevelopment to promote digital inclusion and accessibility and remove barriers.\nMost XAI techniques rely on visual explanations, such as heatmaps or graphs,\nwhich are not accessible to persons who are blind or have low vision.\nTherefore, it is necessary to develop explanation methods through non-visual\nmodalities, such as auditory and tactile feedback, visual modalities accessible\nto persons with low vision, and personalized solutions that meet the needs of\nindividuals, including those with multiple disabilities. We further emphasize\nthe importance of integrating universal design principles into AI development\npractices to ensure that AI technologies are usable by everyone.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "This work has been submitted to the IEEE for possible publication",
    "pdf_url": "http://arxiv.org/pdf/2407.17484v1",
    "published_date": "2024-07-02 21:09:46 UTC",
    "updated_date": "2024-07-02 21:09:46 UTC"
  },
  {
    "arxiv_id": "2407.02666v1",
    "title": "Commonsense Reasoning for Legged Robot Adaptation with Vision-Language Models",
    "authors": [
      "Annie S. Chen",
      "Alec M. Lessing",
      "Andy Tang",
      "Govind Chada",
      "Laura Smith",
      "Sergey Levine",
      "Chelsea Finn"
    ],
    "abstract": "Legged robots are physically capable of navigating a diverse variety of\nenvironments and overcoming a wide range of obstructions. For example, in a\nsearch and rescue mission, a legged robot could climb over debris, crawl\nthrough gaps, and navigate out of dead ends. However, the robot's controller\nneeds to respond intelligently to such varied obstacles, and this requires\nhandling unexpected and unusual scenarios successfully. This presents an open\nchallenge to current learning methods, which often struggle with generalization\nto the long tail of unexpected situations without heavy human supervision. To\naddress this issue, we investigate how to leverage the broad knowledge about\nthe structure of the world and commonsense reasoning capabilities of\nvision-language models (VLMs) to aid legged robots in handling difficult,\nambiguous situations. We propose a system, VLM-Predictive Control (VLM-PC),\ncombining two key components that we find to be crucial for eliciting\non-the-fly, adaptive behavior selection with VLMs: (1) in-context adaptation\nover previous robot interactions and (2) planning multiple skills into the\nfuture and replanning. We evaluate VLM-PC on several challenging real-world\nobstacle courses, involving dead ends and climbing and crawling, on a Go1\nquadruped robot. Our experiments show that by reasoning over the history of\ninteractions and future plans, VLMs enable the robot to autonomously perceive,\nnavigate, and act in a wide range of complex scenarios that would otherwise\nrequire environment-specific engineering or human guidance.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "27 pages",
    "pdf_url": "http://arxiv.org/pdf/2407.02666v1",
    "published_date": "2024-07-02 21:00:30 UTC",
    "updated_date": "2024-07-02 21:00:30 UTC"
  },
  {
    "arxiv_id": "2407.02651v2",
    "title": "Improving Steering and Verification in AI-Assisted Data Analysis with Interactive Task Decomposition",
    "authors": [
      "Majeed Kazemitabaar",
      "Jack Williams",
      "Ian Drosos",
      "Tovi Grossman",
      "Austin Henley",
      "Carina Negreanu",
      "Advait Sarkar"
    ],
    "abstract": "LLM-powered tools like ChatGPT Data Analysis, have the potential to help\nusers tackle the challenging task of data analysis programming, which requires\nexpertise in data processing, programming, and statistics. However, our\nformative study (n=15) uncovered serious challenges in verifying AI-generated\nresults and steering the AI (i.e., guiding the AI system to produce the desired\noutput). We developed two contrasting approaches to address these challenges.\nThe first (Stepwise) decomposes the problem into step-by-step subgoals with\npairs of editable assumptions and code until task completion, while the second\n(Phasewise) decomposes the entire problem into three editable, logical phases:\nstructured input/output assumptions, execution plan, and code. A controlled,\nwithin-subjects experiment (n=18) compared these systems against a\nconversational baseline. Users reported significantly greater control with the\nStepwise and Phasewise systems, and found intervention, correction, and\nverification easier, compared to the baseline. The results suggest design\nguidelines and trade-offs for AI-assisted data analysis tools.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Published at UIST 2024; 19 pages, 9 figures, and 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2407.02651v2",
    "published_date": "2024-07-02 20:33:50 UTC",
    "updated_date": "2024-08-01 15:56:00 UTC"
  },
  {
    "arxiv_id": "2407.03381v1",
    "title": "SeqMate: A Novel Large Language Model Pipeline for Automating RNA Sequencing",
    "authors": [
      "Devam Mondal",
      "Atharva Inamdar"
    ],
    "abstract": "RNA sequencing techniques, like bulk RNA-seq and Single Cell (sc) RNA-seq,\nare critical tools for the biologist looking to analyze the genetic\nactivity/transcriptome of a tissue or cell during an experimental procedure.\nPlatforms like Illumina's next-generation sequencing (NGS) are used to produce\nthe raw data for this experimental procedure. This raw FASTQ data must then be\nprepared via a complex series of data manipulations by bioinformaticians. This\nprocess currently takes place on an unwieldy textual user interface like a\nterminal/command line that requires the user to install and import multiple\nprogram packages, preventing the untrained biologist from initiating data\nanalysis. Open-source platforms like Galaxy have produced a more user-friendly\npipeline, yet the visual interface remains cluttered and highly technical,\nremaining uninviting for the natural scientist. To address this, SeqMate is a\nuser-friendly tool that allows for one-click analytics by utilizing the power\nof a large language model (LLM) to automate both data preparation and analysis\n(differential expression, trajectory analysis, etc). Furthermore, by utilizing\nthe power of generative AI, SeqMate is also capable of analyzing such findings\nand producing written reports of upregulated/downregulated/user-prompted genes\nwith sources cited from known repositories like PubMed, PDB, and Uniprot.",
    "categories": [
      "q-bio.GN",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.GN",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.03381v1",
    "published_date": "2024-07-02 20:28:30 UTC",
    "updated_date": "2024-07-02 20:28:30 UTC"
  },
  {
    "arxiv_id": "2407.02646v3",
    "title": "A Practical Review of Mechanistic Interpretability for Transformer-Based Language Models",
    "authors": [
      "Daking Rai",
      "Yilun Zhou",
      "Shi Feng",
      "Abulhair Saparov",
      "Ziyu Yao"
    ],
    "abstract": "Mechanistic interpretability (MI) is an emerging sub-field of\ninterpretability that seeks to understand a neural network model by\nreverse-engineering its internal computations. Recently, MI has garnered\nsignificant attention for interpreting transformer-based language models (LMs),\nresulting in many novel insights yet introducing new challenges. However, there\nhas not been work that comprehensively reviews these insights and challenges,\nparticularly as a guide for newcomers to this field. To fill this gap, we\nprovide a comprehensive survey from a task-centric perspective, organizing the\ntaxonomy of MI research around specific research questions or tasks. We outline\nthe fundamental objects of study in MI, along with the techniques, evaluation\nmethods, and key findings for each task in the taxonomy. In particular, we\npresent a task-centric taxonomy as a roadmap for beginners to navigate the\nfield by helping them quickly identify impactful problems in which they are\nmost interested and leverage MI for their benefit. Finally, we discuss the\ncurrent gaps in the field and suggest potential future directions for MI\nresearch.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "I.2.7"
    ],
    "primary_category": "cs.AI",
    "comment": "35 pages, 13 figures, Preprint",
    "pdf_url": "http://arxiv.org/pdf/2407.02646v3",
    "published_date": "2024-07-02 20:28:16 UTC",
    "updated_date": "2025-03-15 17:12:40 UTC"
  },
  {
    "arxiv_id": "2407.02641v1",
    "title": "Learning Graph Structures and Uncertainty for Accurate and Calibrated Time-series Forecasting",
    "authors": [
      "Harshavardhan Kamarthi",
      "Lingkai Kong",
      "Alexander Rodriguez",
      "Chao Zhang",
      "B Aditya Prakash"
    ],
    "abstract": "Multi-variate time series forecasting is an important problem with a wide\nrange of applications. Recent works model the relations between time-series as\ngraphs and have shown that propagating information over the relation graph can\nimprove time series forecasting. However, in many cases, relational information\nis not available or is noisy and reliable. Moreover, most works ignore the\nunderlying uncertainty of time-series both for structure learning and deriving\nthe forecasts resulting in the structure not capturing the uncertainty\nresulting in forecast distributions with poor uncertainty estimates. We tackle\nthis challenge and introduce STOIC, that leverages stochastic correlations\nbetween time-series to learn underlying structure between time-series and to\nprovide well-calibrated and accurate forecasts. Over a wide-range of benchmark\ndatasets STOIC provides around 16% more accurate and 14% better-calibrated\nforecasts.\n  STOIC also shows better adaptation to noise in data during inference and\ncaptures important and useful relational information in various benchmarks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02641v1",
    "published_date": "2024-07-02 20:14:32 UTC",
    "updated_date": "2024-07-02 20:14:32 UTC"
  },
  {
    "arxiv_id": "2407.03380v1",
    "title": "Multi-Peptide: Multimodality Leveraged Language-Graph Learning of Peptide Properties",
    "authors": [
      "Srivathsan Badrinarayanan",
      "Chakradhar Guntuboina",
      "Parisa Mollaei",
      "Amir Barati Farimani"
    ],
    "abstract": "Peptides are essential in biological processes and therapeutics. In this\nstudy, we introduce Multi-Peptide, an innovative approach that combines\ntransformer-based language models with Graph Neural Networks (GNNs) to predict\npeptide properties. We combine PeptideBERT, a transformer model tailored for\npeptide property prediction, with a GNN encoder to capture both sequence-based\nand structural features. By employing Contrastive Language-Image Pre-training\n(CLIP), Multi-Peptide aligns embeddings from both modalities into a shared\nlatent space, thereby enhancing the model's predictive accuracy. Evaluations on\nhemolysis and nonfouling datasets demonstrate Multi-Peptide's robustness,\nachieving state-of-the-art 86.185% accuracy in hemolysis prediction. This study\nhighlights the potential of multimodal learning in bioinformatics, paving the\nway for accurate and reliable predictions in peptide-based research and\napplications.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.03380v1",
    "published_date": "2024-07-02 20:13:47 UTC",
    "updated_date": "2024-07-02 20:13:47 UTC"
  },
  {
    "arxiv_id": "2407.02637v1",
    "title": "Change My Frame: Reframing in the Wild in r/ChangeMyView",
    "authors": [
      "Arturo Martínez Peguero",
      "Taro Watanabe"
    ],
    "abstract": "Recent work in reframing, within the scope of text style transfer, has so far\nmade use of out-of-context, task-prompted utterances in order to produce\nneutralizing or optimistic reframes. Our work aims to generalize reframing\nbased on the subreddit r/ChangeMyView (CMV). We build a dataset that leverages\nCMV's community's interactions and conventions to identify high-value,\ncommunity-recognized utterances that produce changes of perspective. With this\ndata, we widen the scope of the direction of reframing since the changes in\nperspective do not only occur in neutral or positive directions. We fine tune\ntransformer-based models, make use of a modern LLM to refine our dataset, and\nexplore challenges in the dataset creation and evaluation around this type of\nreframing.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "68T50",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "3 pages, NAACL 2024 workshop",
    "pdf_url": "http://arxiv.org/pdf/2407.02637v1",
    "published_date": "2024-07-02 20:09:11 UTC",
    "updated_date": "2024-07-02 20:09:11 UTC"
  },
  {
    "arxiv_id": "2407.02631v1",
    "title": "Nollywood: Let's Go to the Movies!",
    "authors": [
      "John E. Ortega",
      "Ibrahim Said Ahmad",
      "William Chen"
    ],
    "abstract": "Nollywood, based on the idea of Bollywood from India, is a series of\noutstanding movies that originate from Nigeria. Unfortunately, while the movies\nare in English, they are hard to understand for many native speakers due to the\ndialect of English that is spoken. In this article, we accomplish two goals:\n(1) create a phonetic sub-title model that is able to translate Nigerian\nEnglish speech to American English and (2) use the most advanced toxicity\ndetectors to discover how toxic the speech is. Our aim is to highlight the text\nin these videos which is often times ignored for lack of dialectal\nunderstanding due the fact that many people in Nigeria speak a native language\nlike Hausa at home.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages, 4 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2407.02631v1",
    "published_date": "2024-07-02 19:50:55 UTC",
    "updated_date": "2024-07-02 19:50:55 UTC"
  },
  {
    "arxiv_id": "2407.02623v3",
    "title": "Uplifting Lower-Income Data: Strategies for Socioeconomic Perspective Shifts in Large Multi-modal Models",
    "authors": [
      "Joan Nwatu",
      "Oana Ignat",
      "Rada Mihalcea"
    ],
    "abstract": "Recent work has demonstrated that the unequal representation of cultures and\nsocioeconomic groups in training data leads to biased Large Multi-modal (LMM)\nmodels. To improve LMM model performance on underrepresented data, we propose\nand evaluate several prompting strategies using non-English, geographic, and\nsocioeconomic attributes. We show that these geographic and socioeconomic\nintegrated prompts favor retrieving topic appearances commonly found in data\nfrom low-income households across different countries leading to improved LMM\nmodel performance on lower-income data. Our analyses identify and highlight\ncontexts where these strategies yield the most improvements.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "K.4; I.2.7; I.2.8"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02623v3",
    "published_date": "2024-07-02 19:27:00 UTC",
    "updated_date": "2024-10-14 14:11:42 UTC"
  },
  {
    "arxiv_id": "2407.02622v1",
    "title": "RISC-V R-Extension: Advancing Efficiency with Rented-Pipeline for Edge DNN Processing",
    "authors": [
      "Won Hyeok Kim",
      "Hyeong Jin Kim",
      "Tae Hee Han"
    ],
    "abstract": "The proliferation of edge devices necessitates efficient computational\narchitectures for lightweight tasks, particularly deep neural network (DNN)\ninference. Traditional NPUs, though effective for such operations, face\nchallenges in power, cost, and area when integrated into lightweight edge\ndevices. The RISC-V architecture, known for its modularity and open-source\nnature, offers a viable alternative. This paper introduces the RISC-V\nR-extension, a novel approach to enhancing DNN process efficiency on edge\ndevices. The extension features rented-pipeline stages and architectural\npipeline registers (APR), which optimize critical operation execution, thereby\nreducing latency and memory access frequency. Furthermore, this extension\nincludes new custom instructions to support these architectural improvements.\nThrough comprehensive analysis, this study demonstrates the boost of\nR-extension in edge device processing, setting the stage for more responsive\nand intelligent edge applications.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "6 pages, 6 figures, ICAIIC 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.02622v1",
    "published_date": "2024-07-02 19:25:05 UTC",
    "updated_date": "2024-07-02 19:25:05 UTC"
  },
  {
    "arxiv_id": "2407.02613v1",
    "title": "Wildfire Autonomous Response and Prediction Using Cellular Automata (WARP-CA)",
    "authors": [
      "Abdelrahman Ramadan"
    ],
    "abstract": "Wildfires pose a severe challenge to ecosystems and human settlements,\nexacerbated by climate change and environmental factors. Traditional wildfire\nmodeling, while useful, often fails to adapt to the rapid dynamics of such\nevents. This report introduces the (Wildfire Autonomous Response and Prediction\nUsing Cellular Automata) WARP-CA model, a novel approach that integrates\nterrain generation using Perlin noise with the dynamism of Cellular Automata\n(CA) to simulate wildfire spread. We explore the potential of Multi-Agent\nReinforcement Learning (MARL) to manage wildfires by simulating autonomous\nagents, such as UAVs and UGVs, within a collaborative framework. Our\nmethodology combines world simulation techniques and investigates emergent\nbehaviors in MARL, focusing on efficient wildfire suppression and considering\ncritical environmental factors like wind patterns and terrain features.",
    "categories": [
      "cs.AI",
      "cs.MA",
      "cs.NE",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02613v1",
    "published_date": "2024-07-02 19:01:59 UTC",
    "updated_date": "2024-07-02 19:01:59 UTC"
  },
  {
    "arxiv_id": "2407.02604v2",
    "title": "D-Rax: Domain-specific Radiologic assistant leveraging multi-modal data and eXpert model predictions",
    "authors": [
      "Hareem Nisar",
      "Syed Muhammad Anwar",
      "Zhifan Jiang",
      "Abhijeet Parida",
      "Ramon Sanchez-Jacob",
      "Vishwesh Nath",
      "Holger R. Roth",
      "Marius George Linguraru"
    ],
    "abstract": "Large vision language models (VLMs) have progressed incredibly from research\nto applicability for general-purpose use cases. LLaVA-Med, a pioneering large\nlanguage and vision assistant for biomedicine, can perform multi-modal\nbiomedical image and data analysis to provide a natural language interface for\nradiologists. While it is highly generalizable and works with multi-modal data,\nit is currently limited by well-known challenges that exist in the large\nlanguage model space. Hallucinations and imprecision in responses can lead to\nmisdiagnosis which currently hinder the clinical adaptability of VLMs. To\ncreate precise, user-friendly models in healthcare, we propose D-Rax -- a\ndomain-specific, conversational, radiologic assistance tool that can be used to\ngain insights about a particular radiologic image. In this study, we enhance\nthe conversational analysis of chest X-ray (CXR) images to support radiological\nreporting, offering comprehensive insights from medical imaging and aiding in\nthe formulation of accurate diagnosis. D-Rax is achieved by fine-tuning the\nLLaVA-Med architecture on our curated enhanced instruction-following data,\ncomprising of images, instructions, as well as disease diagnosis and\ndemographic predictions derived from MIMIC-CXR imaging data, CXR-related visual\nquestion answer (VQA) pairs, and predictive outcomes from multiple expert AI\nmodels. We observe statistically significant improvement in responses when\nevaluated for both open and close-ended conversations. Leveraging the power of\nstate-of-the-art diagnostic models combined with VLMs, D-Rax empowers\nclinicians to interact with medical images using natural language, which could\npotentially streamline their decision-making process, enhance diagnostic\naccuracy, and conserve their time.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "eess.IV"
    ],
    "primary_category": "cs.AI",
    "comment": "accepted to the MICCAI 2024 Second International Workshop on\n  Foundation Models for General Medical AI",
    "pdf_url": "http://arxiv.org/pdf/2407.02604v2",
    "published_date": "2024-07-02 18:43:10 UTC",
    "updated_date": "2024-08-02 13:45:53 UTC"
  },
  {
    "arxiv_id": "2407.02599v1",
    "title": "Meta 3D Gen",
    "authors": [
      "Raphael Bensadoun",
      "Tom Monnier",
      "Yanir Kleiman",
      "Filippos Kokkinos",
      "Yawar Siddiqui",
      "Mahendra Kariya",
      "Omri Harosh",
      "Roman Shapovalov",
      "Benjamin Graham",
      "Emilien Garreau",
      "Animesh Karnewar",
      "Ang Cao",
      "Idan Azuri",
      "Iurii Makarov",
      "Eric-Tuan Le",
      "Antoine Toisoul",
      "David Novotny",
      "Oran Gafni",
      "Natalia Neverova",
      "Andrea Vedaldi"
    ],
    "abstract": "We introduce Meta 3D Gen (3DGen), a new state-of-the-art, fast pipeline for\ntext-to-3D asset generation. 3DGen offers 3D asset creation with high prompt\nfidelity and high-quality 3D shapes and textures in under a minute. It supports\nphysically-based rendering (PBR), necessary for 3D asset relighting in\nreal-world applications. Additionally, 3DGen supports generative retexturing of\npreviously generated (or artist-created) 3D shapes using additional textual\ninputs provided by the user. 3DGen integrates key technical components, Meta 3D\nAssetGen and Meta 3D TextureGen, that we developed for text-to-3D and\ntext-to-texture generation, respectively. By combining their strengths, 3DGen\nrepresents 3D objects simultaneously in three ways: in view space, in\nvolumetric space, and in UV (or texture) space. The integration of these two\ntechniques achieves a win rate of 68% with respect to the single-stage model.\nWe compare 3DGen to numerous industry baselines, and show that it outperforms\nthem in terms of prompt fidelity and visual quality for complex textual\nprompts, while being significantly faster.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02599v1",
    "published_date": "2024-07-02 18:37:52 UTC",
    "updated_date": "2024-07-02 18:37:52 UTC"
  },
  {
    "arxiv_id": "2407.02598v2",
    "title": "AutoSplat: Constrained Gaussian Splatting for Autonomous Driving Scene Reconstruction",
    "authors": [
      "Mustafa Khan",
      "Hamidreza Fazlali",
      "Dhruv Sharma",
      "Tongtong Cao",
      "Dongfeng Bai",
      "Yuan Ren",
      "Bingbing Liu"
    ],
    "abstract": "Realistic scene reconstruction and view synthesis are essential for advancing\nautonomous driving systems by simulating safety-critical scenarios. 3D Gaussian\nSplatting excels in real-time rendering and static scene reconstructions but\nstruggles with modeling driving scenarios due to complex backgrounds, dynamic\nobjects, and sparse views. We propose AutoSplat, a framework employing Gaussian\nsplatting to achieve highly realistic reconstructions of autonomous driving\nscenes. By imposing geometric constraints on Gaussians representing the road\nand sky regions, our method enables multi-view consistent simulation of\nchallenging scenarios including lane changes. Leveraging 3D templates, we\nintroduce a reflected Gaussian consistency constraint to supervise both the\nvisible and unseen side of foreground objects. Moreover, to model the dynamic\nappearance of foreground objects, we estimate residual spherical harmonics for\neach foreground Gaussian. Extensive experiments on Pandaset and KITTI\ndemonstrate that AutoSplat outperforms state-of-the-art methods in scene\nreconstruction and novel view synthesis across diverse driving scenarios. Visit\nour project page at https://autosplat.github.io/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02598v2",
    "published_date": "2024-07-02 18:36:50 UTC",
    "updated_date": "2024-07-04 02:18:54 UTC"
  },
  {
    "arxiv_id": "2407.02489v1",
    "title": "Magic Insert: Style-Aware Drag-and-Drop",
    "authors": [
      "Nataniel Ruiz",
      "Yuanzhen Li",
      "Neal Wadhwa",
      "Yael Pritch",
      "Michael Rubinstein",
      "David E. Jacobs",
      "Shlomi Fruchter"
    ],
    "abstract": "We present Magic Insert, a method for dragging-and-dropping subjects from a\nuser-provided image into a target image of a different style in a physically\nplausible manner while matching the style of the target image. This work\nformalizes the problem of style-aware drag-and-drop and presents a method for\ntackling it by addressing two sub-problems: style-aware personalization and\nrealistic object insertion in stylized images. For style-aware personalization,\nour method first fine-tunes a pretrained text-to-image diffusion model using\nLoRA and learned text tokens on the subject image, and then infuses it with a\nCLIP representation of the target style. For object insertion, we use\nBootstrapped Domain Adaption to adapt a domain-specific photorealistic object\ninsertion model to the domain of diverse artistic styles. Overall, the method\nsignificantly outperforms traditional approaches such as inpainting. Finally,\nwe present a dataset, SubjectPlop, to facilitate evaluation and future progress\nin this area. Project page: https://magicinsert.github.io/",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page: https://magicinsert.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2407.02489v1",
    "published_date": "2024-07-02 17:59:50 UTC",
    "updated_date": "2024-07-02 17:59:50 UTC"
  },
  {
    "arxiv_id": "2407.02486v1",
    "title": "Neurocache: Efficient Vector Retrieval for Long-range Language Modeling",
    "authors": [
      "Ali Safaya",
      "Deniz Yuret"
    ],
    "abstract": "This paper introduces Neurocache, an approach to extend the effective context\nsize of large language models (LLMs) using an external vector cache to store\nits past states. Like recent vector retrieval approaches, Neurocache uses an\nefficient k-nearest-neighbor (kNN) algorithm to retrieve relevant past states\nand incorporate them into the attention process. Neurocache improves upon\nprevious methods by (1) storing compressed states, which reduces cache size;\n(2) performing a single retrieval operation per token which increases inference\nspeed; and (3) extending the retrieval window to neighboring states, which\nimproves both language modeling and downstream task accuracy. Our experiments\nshow the effectiveness of Neurocache both for models trained from scratch and\nfor pre-trained models such as Llama2-7B and Mistral-7B when enhanced with the\ncache mechanism. We also compare Neurocache with text retrieval methods and\nshow improvements in single-document question-answering and few-shot learning\ntasks. We made the source code available under:\nhttps://github.com/alisafaya/neurocache",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Long paper, published at the main conference NAACL'24",
    "pdf_url": "http://arxiv.org/pdf/2407.02486v1",
    "published_date": "2024-07-02 17:59:29 UTC",
    "updated_date": "2024-07-02 17:59:29 UTC"
  },
  {
    "arxiv_id": "2407.02485v1",
    "title": "RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs",
    "authors": [
      "Yue Yu",
      "Wei Ping",
      "Zihan Liu",
      "Boxin Wang",
      "Jiaxuan You",
      "Chao Zhang",
      "Mohammad Shoeybi",
      "Bryan Catanzaro"
    ],
    "abstract": "Large language models (LLMs) typically utilize the top-k contexts from a\nretriever in retrieval-augmented generation (RAG). In this work, we propose a\nnovel instruction fine-tuning framework RankRAG, which instruction-tunes a\nsingle LLM for the dual purpose of context ranking and answer generation in\nRAG. In particular, the instruction-tuned LLMs work surprisingly well by adding\na small fraction of ranking data into the training blend, and outperform\nexisting expert ranking models, including the same LLM exclusively fine-tuned\non a large amount of ranking data. For generation, we compare our model with\nmany strong baselines, including GPT-4-0613, GPT-4-turbo-2024-0409, and\nChatQA-1.5, an open-sourced model with the state-of-the-art performance on RAG\nbenchmarks. Specifically, our Llama3-RankRAG significantly outperforms\nLlama3-ChatQA-1.5 and GPT-4 models on nine knowledge-intensive benchmarks. In\naddition, it also performs comparably to GPT-4 on five RAG benchmarks in the\nbiomedical domain without instruction fine-tuning on biomedical data,\ndemonstrating its superb capability for generalization to new domains.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02485v1",
    "published_date": "2024-07-02 17:59:17 UTC",
    "updated_date": "2024-07-02 17:59:17 UTC"
  },
  {
    "arxiv_id": "2407.02483v2",
    "title": "MMedAgent: Learning to Use Medical Tools with Multi-modal Agent",
    "authors": [
      "Binxu Li",
      "Tiankai Yan",
      "Yuanting Pan",
      "Jie Luo",
      "Ruiyang Ji",
      "Jiayuan Ding",
      "Zhe Xu",
      "Shilong Liu",
      "Haoyu Dong",
      "Zihao Lin",
      "Yixin Wang"
    ],
    "abstract": "Multi-Modal Large Language Models (MLLMs), despite being successful, exhibit\nlimited generality and often fall short when compared to specialized models.\nRecently, LLM-based agents have been developed to address these challenges by\nselecting appropriate specialized models as tools based on user inputs.\nHowever, such advancements have not been extensively explored within the\nmedical domain. To bridge this gap, this paper introduces the first agent\nexplicitly designed for the medical field, named \\textbf{M}ulti-modal\n\\textbf{Med}ical \\textbf{Agent} (MMedAgent). We curate an instruction-tuning\ndataset comprising six medical tools solving seven tasks across five\nmodalities, enabling the agent to choose the most suitable tools for a given\ntask. Comprehensive experiments demonstrate that MMedAgent achieves superior\nperformance across a variety of medical tasks compared to state-of-the-art\nopen-source methods and even the closed-source model, GPT-4o. Furthermore,\nMMedAgent exhibits efficiency in updating and integrating new medical tools.\nCodes and models are all available.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.02483v2",
    "published_date": "2024-07-02 17:58:23 UTC",
    "updated_date": "2024-10-05 06:36:33 UTC"
  },
  {
    "arxiv_id": "2407.02474v1",
    "title": "Free Energy in a Circumplex Model of Emotion",
    "authors": [
      "Candice Pattisapu",
      "Tim Verbelen",
      "Riddhi J. Pitliya",
      "Alex B. Kiefer",
      "Mahault Albarracin"
    ],
    "abstract": "Previous active inference accounts of emotion translate fluctuations in free\nenergy to a sense of emotion, mainly focusing on valence. However, in affective\nscience, emotions are often represented as multi-dimensional. In this paper, we\npropose to adopt a Circumplex Model of emotion by mapping emotions into a\ntwo-dimensional spectrum of valence and arousal. We show how one can derive a\nvalence and arousal signal from an agent's expected free energy, relating\narousal to the entropy of posterior beliefs and valence to utility less\nexpected utility. Under this formulation, we simulate artificial agents engaged\nin a search task. We show that the manipulation of priors and object presence\nresults in commonsense variability in emotional states.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02474v1",
    "published_date": "2024-07-02 17:52:25 UTC",
    "updated_date": "2024-07-02 17:52:25 UTC"
  },
  {
    "arxiv_id": "2407.02466v3",
    "title": "PWM: Policy Learning with Multi-Task World Models",
    "authors": [
      "Ignat Georgiev",
      "Varun Giridhar",
      "Nicklas Hansen",
      "Animesh Garg"
    ],
    "abstract": "Reinforcement Learning (RL) has made significant strides in complex tasks but\nstruggles in multi-task settings with different embodiments. World model\nmethods offer scalability by learning a simulation of the environment but often\nrely on inefficient gradient-free optimization methods for policy extraction.\nIn contrast, gradient-based methods exhibit lower variance but fail to handle\ndiscontinuities. Our work reveals that well-regularized world models can\ngenerate smoother optimization landscapes than the actual dynamics,\nfacilitating more effective first-order optimization. We introduce Policy\nlearning with multi-task World Models (PWM), a novel model-based RL algorithm\nfor continuous control. Initially, the world model is pre-trained on offline\ndata, and then policies are extracted from it using first-order optimization in\nless than 10 minutes per task. PWM effectively solves tasks with up to 152\naction dimensions and outperforms methods that use ground-truth dynamics.\nAdditionally, PWM scales to an 80-task setting, achieving up to 27% higher\nrewards than existing baselines without relying on costly online planning.\nVisualizations and code are available at https://www.imgeorgiev.com/pwm/.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "Visualizations and code available at https://www.imgeorgiev.com/pwm",
    "pdf_url": "http://arxiv.org/pdf/2407.02466v3",
    "published_date": "2024-07-02 17:47:03 UTC",
    "updated_date": "2025-02-24 06:56:00 UTC"
  },
  {
    "arxiv_id": "2407.02465v1",
    "title": "Belief sharing: a blessing or a curse",
    "authors": [
      "Ozan Catal",
      "Toon Van de Maele",
      "Riddhi J. Pitliya",
      "Mahault Albarracin",
      "Candice Pattisapu",
      "Tim Verbelen"
    ],
    "abstract": "When collaborating with multiple parties, communicating relevant information\nis of utmost importance to efficiently completing the tasks at hand. Under\nactive inference, communication can be cast as sharing beliefs between\nfree-energy minimizing agents, where one agent's beliefs get transformed into\nan observation modality for the other. However, the best approach for\ntransforming beliefs into observations remains an open question. In this paper,\nwe demonstrate that naively sharing posterior beliefs can give rise to the\nnegative social dynamics of echo chambers and self-doubt. We propose an\nalternate belief sharing strategy which mitigates these issues.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02465v1",
    "published_date": "2024-07-02 17:46:42 UTC",
    "updated_date": "2024-07-02 17:46:42 UTC"
  },
  {
    "arxiv_id": "2407.02552v1",
    "title": "RLHF Can Speak Many Languages: Unlocking Multilingual Preference Optimization for LLMs",
    "authors": [
      "John Dang",
      "Arash Ahmadian",
      "Kelly Marchisio",
      "Julia Kreutzer",
      "Ahmet Üstün",
      "Sara Hooker"
    ],
    "abstract": "Preference optimization techniques have become a standard final stage for\ntraining state-of-art large language models (LLMs). However, despite widespread\nadoption, the vast majority of work to-date has focused on first-class citizen\nlanguages like English and Chinese. This captures a small fraction of the\nlanguages in the world, but also makes it unclear which aspects of current\nstate-of-the-art research transfer to a multilingual setting. In this work, we\nperform an exhaustive study to achieve a new state-of-the-art in aligning\nmultilingual LLMs. We introduce a novel, scalable method for generating\nhigh-quality multilingual feedback data to balance data coverage. We establish\nthe benefits of cross-lingual transfer and increased dataset size in preference\ntraining. Our preference-trained model achieves a 54.4% win-rate against Aya 23\n8B, the current state-of-the-art multilingual LLM in its parameter class, and a\n69.5% win-rate or higher against widely used models like Gemma-1.1-7B-it,\nLlama-3-8B-Instruct, Mistral-7B-Instruct-v0.3. As a result of our study, we\nexpand the frontier of alignment techniques to 23 languages covering half of\nthe world's population.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02552v1",
    "published_date": "2024-07-02 17:42:30 UTC",
    "updated_date": "2024-07-02 17:42:30 UTC"
  },
  {
    "arxiv_id": "2407.02448v1",
    "title": "Ensemble of pre-trained language models and data augmentation for hate speech detection from Arabic tweets",
    "authors": [
      "Kheir Eddine Daouadi",
      "Yaakoub Boualleg",
      "Kheir Eddine Haouaouchi"
    ],
    "abstract": "Today, hate speech classification from Arabic tweets has drawn the attention\nof several researchers. Many systems and techniques have been developed to\nresolve this classification task. Nevertheless, two of the major challenges\nfaced in this context are the limited performance and the problem of imbalanced\ndata. In this study, we propose a novel approach that leverages ensemble\nlearning and semi-supervised learning based on previously manually labeled. We\nconducted experiments on a benchmark dataset by classifying Arabic tweets into\n5 distinct classes: non-hate, general hate, racial, religious, or sexism.\nExperimental results show that: (1) ensemble learning based on pre-trained\nlanguage models outperforms existing related works; (2) Our proposed data\naugmentation improves the accuracy results of hate speech detection from Arabic\ntweets and outperforms existing related works. Our main contribution is the\nachievement of encouraging results in Arabic hate speech detection.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02448v1",
    "published_date": "2024-07-02 17:26:26 UTC",
    "updated_date": "2024-07-02 17:26:26 UTC"
  },
  {
    "arxiv_id": "2407.02446v1",
    "title": "Predicting vs. Acting: A Trade-off Between World Modeling & Agent Modeling",
    "authors": [
      "Margaret Li",
      "Weijia Shi",
      "Artidoro Pagnoni",
      "Peter West",
      "Ari Holtzman"
    ],
    "abstract": "RLHF-aligned LMs have shown unprecedented ability on both benchmarks and\nlong-form text generation, yet they struggle with one foundational task:\nnext-token prediction. As RLHF models become agent models aimed at interacting\nwith humans, they seem to lose their world modeling -- the ability to predict\nwhat comes next in arbitrary documents, which is the foundational training\nobjective of the Base LMs that RLHF adapts.\n  Besides empirically demonstrating this trade-off, we propose a potential\nexplanation: to perform coherent long-form generation, RLHF models restrict\nrandomness via implicit blueprints. In particular, RLHF models concentrate\nprobability on sets of anchor spans that co-occur across multiple generations\nfor the same prompt, serving as textual scaffolding but also limiting a model's\nability to generate documents that do not include these spans. We study this\ntrade-off on the most effective current agent models, those aligned with RLHF,\nwhile exploring why this may remain a fundamental trade-off between models that\nact and those that predict, even as alignment techniques improve.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02446v1",
    "published_date": "2024-07-02 17:22:54 UTC",
    "updated_date": "2024-07-02 17:22:54 UTC"
  },
  {
    "arxiv_id": "2407.02445v1",
    "title": "Meta 3D AssetGen: Text-to-Mesh Generation with High-Quality Geometry, Texture, and PBR Materials",
    "authors": [
      "Yawar Siddiqui",
      "Tom Monnier",
      "Filippos Kokkinos",
      "Mahendra Kariya",
      "Yanir Kleiman",
      "Emilien Garreau",
      "Oran Gafni",
      "Natalia Neverova",
      "Andrea Vedaldi",
      "Roman Shapovalov",
      "David Novotny"
    ],
    "abstract": "We present Meta 3D AssetGen (AssetGen), a significant advancement in\ntext-to-3D generation which produces faithful, high-quality meshes with texture\nand material control. Compared to works that bake shading in the 3D object's\nappearance, AssetGen outputs physically-based rendering (PBR) materials,\nsupporting realistic relighting. AssetGen generates first several views of the\nobject with factored shaded and albedo appearance channels, and then\nreconstructs colours, metalness and roughness in 3D, using a deferred shading\nloss for efficient supervision. It also uses a sign-distance function to\nrepresent 3D shape more reliably and introduces a corresponding loss for direct\nshape supervision. This is implemented using fused kernels for high memory\nefficiency. After mesh extraction, a texture refinement transformer operating\nin UV space significantly improves sharpness and details. AssetGen achieves 17%\nimprovement in Chamfer Distance and 40% in LPIPS over the best concurrent work\nfor few-view reconstruction, and a human preference of 72% over the best\nindustry competitors of comparable speed, including those that support PBR.\nProject page with generated assets: https://assetgen.github.io",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "Project Page: https://assetgen.github.io",
    "pdf_url": "http://arxiv.org/pdf/2407.02445v1",
    "published_date": "2024-07-02 17:21:47 UTC",
    "updated_date": "2024-07-02 17:21:47 UTC"
  },
  {
    "arxiv_id": "2407.02430v1",
    "title": "Meta 3D TextureGen: Fast and Consistent Texture Generation for 3D Objects",
    "authors": [
      "Raphael Bensadoun",
      "Yanir Kleiman",
      "Idan Azuri",
      "Omri Harosh",
      "Andrea Vedaldi",
      "Natalia Neverova",
      "Oran Gafni"
    ],
    "abstract": "The recent availability and adaptability of text-to-image models has sparked\na new era in many related domains that benefit from the learned text priors as\nwell as high-quality and fast generation capabilities, one of which is texture\ngeneration for 3D objects. Although recent texture generation methods achieve\nimpressive results by using text-to-image networks, the combination of global\nconsistency, quality, and speed, which is crucial for advancing texture\ngeneration to real-world applications, remains elusive. To that end, we\nintroduce Meta 3D TextureGen: a new feedforward method comprised of two\nsequential networks aimed at generating high-quality and globally consistent\ntextures for arbitrary geometries of any complexity degree in less than 20\nseconds. Our method achieves state-of-the-art results in quality and speed by\nconditioning a text-to-image model on 3D semantics in 2D space and fusing them\ninto a complete and high-resolution UV texture map, as demonstrated by\nextensive qualitative and quantitative evaluations. In addition, we introduce a\ntexture enhancement network that is capable of up-scaling any texture by an\narbitrary ratio, producing 4k pixel resolution textures.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02430v1",
    "published_date": "2024-07-02 17:04:34 UTC",
    "updated_date": "2024-07-02 17:04:34 UTC"
  },
  {
    "arxiv_id": "2407.02425v1",
    "title": "Reinforcement Learning and Machine ethics:a systematic review",
    "authors": [
      "Ajay Vishwanath",
      "Louise A. Dennis",
      "Marija Slavkovik"
    ],
    "abstract": "Machine ethics is the field that studies how ethical behaviour can be\naccomplished by autonomous systems. While there exist some systematic reviews\naiming to consolidate the state of the art in machine ethics prior to 2020,\nthese tend to not include work that uses reinforcement learning agents as\nentities whose ethical behaviour is to be achieved. The reason for this is that\nonly in the last years we have witnessed an increase in machine ethics studies\nwithin reinforcement learning. We present here a systematic review of\nreinforcement learning for machine ethics and machine ethics within\nreinforcement learning. Additionally, we highlight trends in terms of ethics\nspecifications, components and frameworks of reinforcement learning, and\nenvironments used to result in ethical behaviour. Our systematic review aims to\nconsolidate the work in machine ethics and reinforcement learning thus\ncompleting the gap in the state of the art machine ethics landscape",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02425v1",
    "published_date": "2024-07-02 16:54:00 UTC",
    "updated_date": "2024-07-02 16:54:00 UTC"
  },
  {
    "arxiv_id": "2407.02403v2",
    "title": "Face Reconstruction Transfer Attack as Out-of-Distribution Generalization",
    "authors": [
      "Yoon Gyo Jung",
      "Jaewoo Park",
      "Xingbo Dong",
      "Hojin Park",
      "Andrew Beng Jin Teoh",
      "Octavia Camps"
    ],
    "abstract": "Understanding the vulnerability of face recognition systems to malicious\nattacks is of critical importance. Previous works have focused on\nreconstructing face images that can penetrate a targeted verification system.\nEven in the white-box scenario, however, naively reconstructed images\nmisrepresent the identity information, hence the attacks are easily neutralized\nonce the face system is updated or changed. In this paper, we aim to\nreconstruct face images which are capable of transferring face attacks on\nunseen encoders. We term this problem as Face Reconstruction Transfer Attack\n(FRTA) and show that it can be formulated as an out-of-distribution (OOD)\ngeneralization problem. Inspired by its OOD nature, we propose to solve FRTA by\nAveraged Latent Search and Unsupervised Validation with pseudo target (ALSUV).\nTo strengthen the reconstruction attack on OOD unseen encoders, ALSUV\nreconstructs the face by searching the latent of amortized generator StyleGAN2\nthrough multiple latent optimization, latent optimization trajectory averaging,\nand unsupervised validation with a pseudo target. We demonstrate the efficacy\nand generalization of our method on widely used face datasets, accompanying it\nwith extensive ablation studies and visually, qualitatively, and quantitatively\nanalyses. The source code will be released.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to ECCV2024",
    "pdf_url": "http://arxiv.org/pdf/2407.02403v2",
    "published_date": "2024-07-02 16:21:44 UTC",
    "updated_date": "2024-09-12 17:57:52 UTC"
  },
  {
    "arxiv_id": "2407.02402v1",
    "title": "Assessing the Code Clone Detection Capability of Large Language Models",
    "authors": [
      "Zixian Zhang",
      "Takfarinas Saber"
    ],
    "abstract": "This study aims to assess the performance of two advanced Large Language\nModels (LLMs), GPT-3.5 and GPT-4, in the task of code clone detection. The\nevaluation involves testing the models on a variety of code pairs of different\nclone types and levels of similarity, sourced from two datasets: BigCloneBench\n(human-made) and GPTCloneBench (LLM-generated). Findings from the study\nindicate that GPT-4 consistently surpasses GPT-3.5 across all clone types. A\ncorrelation was observed between the GPTs' accuracy at identifying code clones\nand code similarity, with both GPT models exhibiting low effectiveness in\ndetecting the most complex Type-4 code clones. Additionally, GPT models\ndemonstrate a higher performance identifying code clones in LLM-generated code\ncompared to humans-generated code. However, they do not reach impressive\naccuracy. These results emphasize the imperative for ongoing enhancements in\nLLM capabilities, particularly in the recognition of code clones and in\nmitigating their predisposition towards self-generated code clones--which is\nlikely to become an issue as software engineers are more numerous to leverage\nLLM-enabled code generation and code refactoring tools.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02402v1",
    "published_date": "2024-07-02 16:20:44 UTC",
    "updated_date": "2024-07-02 16:20:44 UTC"
  },
  {
    "arxiv_id": "2407.02551v2",
    "title": "Breach By A Thousand Leaks: Unsafe Information Leakage in `Safe' AI Responses",
    "authors": [
      "David Glukhov",
      "Ziwen Han",
      "Ilia Shumailov",
      "Vardan Papyan",
      "Nicolas Papernot"
    ],
    "abstract": "Vulnerability of Frontier language models to misuse and jailbreaks has\nprompted the development of safety measures like filters and alignment training\nin an effort to ensure safety through robustness to adversarially crafted\nprompts. We assert that robustness is fundamentally insufficient for ensuring\nsafety goals, and current defenses and evaluation methods fail to account for\nrisks of dual-intent queries and their composition for malicious goals. To\nquantify these risks, we introduce a new safety evaluation framework based on\nimpermissible information leakage of model outputs and demonstrate how our\nproposed question-decomposition attack can extract dangerous knowledge from a\ncensored LLM more effectively than traditional jailbreaking. Underlying our\nproposed evaluation method is a novel information-theoretic threat model of\ninferential adversaries, distinguished from security adversaries, such as\njailbreaks, in that success is measured by inferring impermissible knowledge\nfrom victim outputs as opposed to forcing explicitly impermissible outputs from\nthe victim. Through our information-theoretic framework, we show that to ensure\nsafety against inferential adversaries, defense mechanisms must ensure\ninformation censorship, bounding the leakage of impermissible information.\nHowever, we prove that such defenses inevitably incur a safety-utility\ntrade-off.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02551v2",
    "published_date": "2024-07-02 16:19:25 UTC",
    "updated_date": "2024-10-30 17:16:44 UTC"
  },
  {
    "arxiv_id": "2407.02389v1",
    "title": "SafaRi:Adaptive Sequence Transformer for Weakly Supervised Referring Expression Segmentation",
    "authors": [
      "Sayan Nag",
      "Koustava Goswami",
      "Srikrishna Karanam"
    ],
    "abstract": "Referring Expression Segmentation (RES) aims to provide a segmentation mask\nof the target object in an image referred to by the text (i.e., referring\nexpression). Existing methods require large-scale mask annotations. Moreover,\nsuch approaches do not generalize well to unseen/zero-shot scenarios. To\naddress the aforementioned issues, we propose a weakly-supervised bootstrapping\narchitecture for RES with several new algorithmic innovations. To the best of\nour knowledge, ours is the first approach that considers only a fraction of\nboth mask and box annotations (shown in Figure 1 and Table 1) for training. To\nenable principled training of models in such low-annotation settings, improve\nimage-text region-level alignment, and further enhance spatial localization of\nthe target object in the image, we propose Cross-modal Fusion with Attention\nConsistency module. For automatic pseudo-labeling of unlabeled samples, we\nintroduce a novel Mask Validity Filtering routine based on a spatially aware\nzero-shot proposal scoring approach. Extensive experiments show that with just\n30% annotations, our model SafaRi achieves 59.31 and 48.26 mIoUs as compared to\n58.93 and 48.19 mIoUs obtained by the fully-supervised SOTA method SeqTR\nrespectively on RefCOCO+@testA and RefCOCO+testB datasets. SafaRi also\noutperforms SeqTR by 11.7% (on RefCOCO+testA) and 19.6% (on RefCOCO+testB) in a\nfully-supervised setting and demonstrates strong generalization capabilities in\nunseen/zero-shot tasks.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at ECCV 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.02389v1",
    "published_date": "2024-07-02 16:02:25 UTC",
    "updated_date": "2024-07-02 16:02:25 UTC"
  },
  {
    "arxiv_id": "2407.02362v2",
    "title": "Fast, Scalable, Energy-Efficient Non-element-wise Matrix Multiplication on FPGA",
    "authors": [
      "Xuqi Zhu",
      "Huaizhi Zhang",
      "JunKyu Lee",
      "Jiacheng Zhu",
      "Chandrajit Pal",
      "Sangeet Saha",
      "Klaus D. McDonald-Maier",
      "Xiaojun Zhai"
    ],
    "abstract": "Modern Neural Network (NN) architectures heavily rely on vast numbers of\nmultiply-accumulate arithmetic operations, constituting the predominant\ncomputational cost. Therefore, this paper proposes a high-throughput, scalable\nand energy efficient non-element-wise matrix multiplication unit on FPGAs as a\nbasic component of the NNs. We firstly streamline inter-layer and intra-layer\nredundancies of MADDNESS algorithm, a LUT-based approximate matrix\nmultiplication, to design a fast, efficient scalable approximate matrix\nmultiplication module termed \"Approximate Multiplication Unit (AMU)\". The AMU\noptimizes LUT-based matrix multiplications further through dedicated memory\nmanagement and access design, decoupling computational overhead from input\nresolution and boosting FPGA-based NN accelerator efficiency significantly. The\nexperimental results show that using our AMU achieves up to 9x higher\nthroughput and 112x higher energy efficiency over the state-of-the-art\nsolutions for the FPGA-based Quantised Neural Network (QNN) accelerators.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02362v2",
    "published_date": "2024-07-02 15:28:10 UTC",
    "updated_date": "2024-07-07 17:20:51 UTC"
  },
  {
    "arxiv_id": "2407.02354v1",
    "title": "Talking to Machines: do you read me?",
    "authors": [
      "Lina M. Rojas-Barahona"
    ],
    "abstract": "In this dissertation I would like to guide the reader to the research on\ndialogue but more precisely the research I have conducted during my career\nsince my PhD thesis. Starting from modular architectures with machine\nlearning/deep learning and reinforcement learning to end-to-end deep neural\nnetworks. Besides my work as research associate, I also present the work I have\nsupervised in the last years.\n  I review briefly the state of the art and highlight the open research\nproblems on conversational agents. Afterwards, I present my contribution to\nTask-Oriented Dialogues (TOD), both as research associate and as the industrial\nsupervisor of CIFRE theses. I discuss conversational QA. Particularly, I\npresent the work of two PhD candidates Thibault Cordier and Sebastien Montella;\nas well as the work of the young researcher Quentin Brabant. Finally, I present\nthe scientific project, where I discuss about Large Language Models (LLMs) for\nTask-Oriented Dialogue and Multimodal Task-Oriented Dialogue.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "French Doctoral Habilitation HDR manuscript:\n  https://hal.science/tel-04620199",
    "pdf_url": "http://arxiv.org/pdf/2407.02354v1",
    "published_date": "2024-07-02 15:19:46 UTC",
    "updated_date": "2024-07-02 15:19:46 UTC"
  },
  {
    "arxiv_id": "2407.02340v1",
    "title": "RVISA: Reasoning and Verification for Implicit Sentiment Analysis",
    "authors": [
      "Wenna Lai",
      "Haoran Xie",
      "Guandong Xu",
      "Qing Li"
    ],
    "abstract": "With an increasing social demand for fine-grained sentiment analysis (SA),\nimplicit sentiment analysis (ISA) poses a significant challenge with the\nabsence of salient cue words in expressions. It necessitates reliable reasoning\nto understand how the sentiment is aroused and thus determine implicit\nsentiments. In the era of Large Language Models (LLMs), Encoder-Decoder (ED)\nLLMs have gained popularity to serve as backbone models for SA applications,\nconsidering impressive text comprehension and reasoning ability among diverse\ntasks. On the other hand, Decoder-only (DO) LLMs exhibit superior natural\nlanguage generation and in-context learning capabilities. However, their\nresponses may contain misleading or inaccurate information. To identify\nimplicit sentiment with reliable reasoning, this study proposes RVISA, a\ntwo-stage reasoning framework that harnesses the generation ability of DO LLMs\nand the reasoning ability of ED LLMs to train an enhanced reasoner.\nSpecifically, we adopt three-hop reasoning prompting to explicitly furnish\nsentiment elements as cues. The generated rationales are utilized to fine-tune\nan ED LLM into a skilled reasoner. Additionally, we develop a straightforward\nyet effective verification mechanism to ensure the reliability of the reasoning\nlearning. We evaluated the proposed method on two benchmark datasets and\nachieved state-of-the-art results in ISA performance.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "11 pages, 6 figures, and 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2407.02340v1",
    "published_date": "2024-07-02 15:07:54 UTC",
    "updated_date": "2024-07-02 15:07:54 UTC"
  },
  {
    "arxiv_id": "2407.02335v1",
    "title": "CALICO: Confident Active Learning with Integrated Calibration",
    "authors": [
      "Lorenzo S. Querol",
      "Hajime Nagahara",
      "Hideaki Hayashi"
    ],
    "abstract": "The growing use of deep learning in safety-critical applications, such as\nmedical imaging, has raised concerns about limited labeled data, where this\ndemand is amplified as model complexity increases, posing hurdles for domain\nexperts to annotate data. In response to this, active learning (AL) is used to\nefficiently train models with limited annotation costs. In the context of deep\nneural networks (DNNs), AL often uses confidence or probability outputs as a\nscore for selecting the most informative samples. However, modern DNNs exhibit\nunreliable confidence outputs, making calibration essential. We propose an AL\nframework that self-calibrates the confidence used for sample selection during\nthe training process, referred to as Confident Active Learning with Integrated\nCalibratiOn (CALICO). CALICO incorporates the joint training of a classifier\nand an energy-based model, instead of the standard softmax-based classifier.\nThis approach allows for simultaneous estimation of the input data distribution\nand the class probabilities during training, improving calibration without\nneeding an additional labeled dataset. Experimental results showcase improved\nclassification performance compared to a softmax-based classifier with fewer\nlabeled samples. Furthermore, the calibration stability of the model is\nobserved to depend on the prior class distribution of the data.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to ICANN2024",
    "pdf_url": "http://arxiv.org/pdf/2407.02335v1",
    "published_date": "2024-07-02 15:05:19 UTC",
    "updated_date": "2024-07-02 15:05:19 UTC"
  },
  {
    "arxiv_id": "2407.02320v1",
    "title": "Exploring the Role of Transliteration in In-Context Learning for Low-resource Languages Written in Non-Latin Scripts",
    "authors": [
      "Chunlan Ma",
      "Yihong Liu",
      "Haotian Ye",
      "Hinrich Schütze"
    ],
    "abstract": "Decoder-only large language models (LLMs) excel in high-resource languages\nacross various tasks through few-shot or even zero-shot in-context learning\n(ICL). However, their performance often does not transfer well to low-resource\nlanguages, especially those written in non-Latin scripts. Inspired by recent\nwork that leverages transliteration in encoder-only models, we investigate\nwhether transliteration is also effective in improving LLMs' performance for\nlow-resource languages written in non-Latin scripts. To this end, we propose\nthree prompt templates, where the target-language text is represented in (1)\nits original script, (2) Latin script, or (3) both. We apply these methods to\nseveral representative LLMs of different sizes on various tasks including text\nclassification and sequential labeling. Our findings show that the\neffectiveness of transliteration varies by task type and model size. For\ninstance, all models benefit from transliterations for sequential labeling\n(with increases of up to 25%).",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02320v1",
    "published_date": "2024-07-02 14:51:20 UTC",
    "updated_date": "2024-07-02 14:51:20 UTC"
  },
  {
    "arxiv_id": "2407.02315v2",
    "title": "VFIMamba: Video Frame Interpolation with State Space Models",
    "authors": [
      "Guozhen Zhang",
      "Chunxu Liu",
      "Yutao Cui",
      "Xiaotong Zhao",
      "Kai Ma",
      "Limin Wang"
    ],
    "abstract": "Inter-frame modeling is pivotal in generating intermediate frames for video\nframe interpolation (VFI). Current approaches predominantly rely on convolution\nor attention-based models, which often either lack sufficient receptive fields\nor entail significant computational overheads. Recently, Selective State Space\nModels (S6) have emerged, tailored specifically for long sequence modeling,\noffering both linear complexity and data-dependent modeling capabilities. In\nthis paper, we propose VFIMamba, a novel frame interpolation method for\nefficient and dynamic inter-frame modeling by harnessing the S6 model. Our\napproach introduces the Mixed-SSM Block (MSB), which initially rearranges\ntokens from adjacent frames in an interleaved fashion and subsequently applies\nmulti-directional S6 modeling. This design facilitates the efficient\ntransmission of information across frames while upholding linear complexity.\nFurthermore, we introduce a novel curriculum learning strategy that\nprogressively cultivates proficiency in modeling inter-frame dynamics across\nvarying motion magnitudes, fully unleashing the potential of the S6 model.\nExperimental findings showcase that our method attains state-of-the-art\nperformance across diverse benchmarks, particularly excelling in\nhigh-resolution scenarios. In particular, on the X-TEST dataset, VFIMamba\ndemonstrates a noteworthy improvement of 0.80 dB for 4K frames and 0.96 dB for\n2K frames.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02315v2",
    "published_date": "2024-07-02 14:48:18 UTC",
    "updated_date": "2024-10-10 03:15:55 UTC"
  },
  {
    "arxiv_id": "2407.02309v1",
    "title": "Semantically Guided Representation Learning For Action Anticipation",
    "authors": [
      "Anxhelo Diko",
      "Danilo Avola",
      "Bardh Prenkaj",
      "Federico Fontana",
      "Luigi Cinque"
    ],
    "abstract": "Action anticipation is the task of forecasting future activity from a\npartially observed sequence of events. However, this task is exposed to\nintrinsic future uncertainty and the difficulty of reasoning upon\ninterconnected actions. Unlike previous works that focus on extrapolating\nbetter visual and temporal information, we concentrate on learning action\nrepresentations that are aware of their semantic interconnectivity based on\nprototypical action patterns and contextual co-occurrences. To this end, we\npropose the novel Semantically Guided Representation Learning (S-GEAR)\nframework. S-GEAR learns visual action prototypes and leverages language models\nto structure their relationship, inducing semanticity. To gather insights on\nS-GEAR's effectiveness, we test it on four action anticipation benchmarks,\nobtaining improved results compared to previous works: +3.5, +2.7, and +3.5\nabsolute points on Top-1 Accuracy on Epic-Kitchen 55, EGTEA Gaze+ and 50\nSalads, respectively, and +0.8 on Top-5 Recall on Epic-Kitchens 100. We further\nobserve that S-GEAR effectively transfers the geometric associations between\nactions from language to visual prototypes. Finally, S-GEAR opens new research\nfrontiers in anticipation tasks by demonstrating the intricate impact of action\nsemantic interconnectivity.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted as a full paper at ECCV'24 with Paper ID #4140",
    "pdf_url": "http://arxiv.org/pdf/2407.02309v1",
    "published_date": "2024-07-02 14:44:01 UTC",
    "updated_date": "2024-07-02 14:44:01 UTC"
  },
  {
    "arxiv_id": "2407.12828v2",
    "title": "Why Does New Knowledge Create Messy Ripple Effects in LLMs?",
    "authors": [
      "Jiaxin Qin",
      "Zixuan Zhang",
      "Chi Han",
      "Manling Li",
      "Pengfei Yu",
      "Heng Ji"
    ],
    "abstract": "Extensive previous research has focused on post-training knowledge editing\n(KE) for language models (LMs) to ensure that knowledge remains accurate and\nup-to-date. One desired property and open question in KE is to let edited LMs\ncorrectly handle ripple effects, where LM is expected to answer its logically\nrelated knowledge accurately. In this paper, we answer the question of why most\nKE methods still create messy ripple effects. We conduct extensive analysis and\nidentify a salient indicator, GradSim, that effectively reveals when and why\nupdated knowledge ripples in LMs. GradSim is computed by the cosine similarity\nbetween gradients of the original fact and its related knowledge. We observe a\nstrong positive correlation between ripple effect performance and GradSim\nacross different LMs, KE methods, and evaluation metrics. Further\ninvestigations into three counter-intuitive failure cases (Negation,\nOver-Ripple, Multi-Lingual) of ripple effects demonstrate that these failures\nare often associated with very low GradSim. This finding validates that GradSim\nis an effective indicator of when knowledge ripples in LMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.12828v2",
    "published_date": "2024-07-02 14:33:44 UTC",
    "updated_date": "2024-07-19 01:33:56 UTC"
  },
  {
    "arxiv_id": "2407.02292v2",
    "title": "Strategic Demand-Planning in Wireless Networks: Can Generative-AI Save Spectrum and Energy?",
    "authors": [
      "Berk Çiloğlu",
      "Görkem Berkay Koç",
      "Afsoon Alidadi Shamsabadi",
      "Metin Ozturk",
      "Halim Yanikomeroglu"
    ],
    "abstract": "Generative-AI (GenAI), a novel technology capable of producing various types\nof outputs, including text, images, and videos, offers significant potential\nfor wireless communications. This article introduces the concept of strategic\ndemand-planning through demand-labeling, demand-shaping, and\ndemand-rescheduling. Accordingly, GenAI is proposed as a powerful tool to\nfacilitate demand-shaping in wireless networks. More specifically, GenAI is\nused to compress and convert the content of various types (e.g., from a higher\nbandwidth mode to a lower one, such as from a video to text), which\nsubsequently enhances performance of wireless networks in various usage\nscenarios, such as cell-switching, user association and load balancing,\ninterference management, as well as disasters and unusual gatherings.\nTherefore, GenAI can serve a function in saving energy and spectrum in wireless\nnetworks. With recent advancements in AI, including sophisticated algorithms\nlike large language models and the development of more powerful hardware built\nexclusively for AI tasks, such as AI accelerators, the concept of\ndemand-planning, particularly demand-shaping through GenAI, becomes\nincreasingly relevant. Furthermore, recent efforts to make GenAI accessible on\ndevices, such as user terminals, make the implementation of this concept even\nmore straightforward and feasible.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02292v2",
    "published_date": "2024-07-02 14:27:06 UTC",
    "updated_date": "2024-12-01 11:31:18 UTC"
  },
  {
    "arxiv_id": "2407.02286v4",
    "title": "Rethinking Data Augmentation for Robust LiDAR Semantic Segmentation in Adverse Weather",
    "authors": [
      "Junsung Park",
      "Kyungmin Kim",
      "Hyunjung Shim"
    ],
    "abstract": "Existing LiDAR semantic segmentation methods often struggle with performance\ndeclines in adverse weather conditions. Previous work has addressed this issue\nby simulating adverse weather or employing universal data augmentation during\ntraining. However, these methods lack a detailed analysis and understanding of\nhow adverse weather negatively affects LiDAR semantic segmentation performance.\nMotivated by this issue, we identified key factors of adverse weather and\nconducted a toy experiment to pinpoint the main causes of performance\ndegradation: (1) Geometric perturbation due to refraction caused by fog or\ndroplets in the air and (2) Point drop due to energy absorption and occlusions.\nBased on these findings, we propose new strategic data augmentation techniques.\nFirst, we introduced a Selective Jittering (SJ) that jitters points in the\nrandom range of depth (or angle) to mimic geometric perturbation. Additionally,\nwe developed a Learnable Point Drop (LPD) to learn vulnerable erase patterns\nwith a Deep Q-Learning Network to approximate the point drop phenomenon from\nadverse weather conditions. Without precise weather simulation, these\ntechniques strengthen the LiDAR semantic segmentation model by exposing it to\nvulnerable conditions identified by our data-centric analysis. Experimental\nresults confirmed the suitability of the proposed data augmentation methods for\nenhancing robustness against adverse weather conditions. Our method achieves a\nnotable 39.5 mIoU on the SemanticKITTI-to-SemanticSTF benchmark, improving the\nbaseline by 8.1\\%p and establishing a new state-of-the-art. Our code will be\nreleased at \\url{https://github.com/engineerJPark/LiDARWeather}.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "29 pages, 11 figures, accpeted in ECCV 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.02286v4",
    "published_date": "2024-07-02 14:19:51 UTC",
    "updated_date": "2024-07-17 10:50:27 UTC"
  },
  {
    "arxiv_id": "2407.02283v2",
    "title": "A Refreshed Similarity-based Upsampler for Direct High-Ratio Feature Upsampling",
    "authors": [
      "Minghao Zhou",
      "Hong Wang",
      "Yefeng Zheng",
      "Deyu Meng"
    ],
    "abstract": "Feature upsampling is a fundamental and indispensable ingredient of almost\nall current network structures for dense prediction tasks. Recently, a popular\nsimilarity-based feature upsampling pipeline has been proposed, which utilizes\na high-resolution feature as guidance to help upsample the low-resolution deep\nfeature based on their local similarity. Albeit achieving promising\nperformance, this pipeline has specific limitations: 1) HR query and LR key\nfeatures are not well aligned; 2) the similarity between query-key features is\ncomputed based on the fixed inner product form; 3) neighbor selection is\ncoarsely operated on LR features, resulting in mosaic artifacts. These\nshortcomings make the existing methods along this pipeline primarily applicable\nto hierarchical network architectures with iterative features as guidance and\nthey are not readily extended to a broader range of structures, especially for\na direct high-ratio upsampling. Against the issues, we meticulously optimize\nevery methodological design. Specifically, we firstly propose an explicitly\ncontrollable query-key feature alignment from both semantic-aware and\ndetail-aware perspectives, and then construct a parameterized paired central\ndifference convolution block for flexibly calculating the similarity between\nthe well-aligned query-key features. Besides, we develop a fine-grained\nneighbor selection strategy on HR features, which is simple yet effective for\nalleviating mosaic artifacts. Based on these careful designs, we systematically\nconstruct a refreshed similarity-based feature upsampling framework named\nReSFU. Extensive experiments substantiate that our proposed ReSFU is finely\napplicable to various types of architectures in a direct high-ratio upsampling\nmanner, and consistently achieves satisfactory performance on different dense\nprediction applications, showing superior generality and ease of deployment.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Codes are available at https://github.com/zmhhmz/ReSFU",
    "pdf_url": "http://arxiv.org/pdf/2407.02283v2",
    "published_date": "2024-07-02 14:12:21 UTC",
    "updated_date": "2025-02-08 02:30:27 UTC"
  },
  {
    "arxiv_id": "2407.02280v2",
    "title": "FedIA: Federated Medical Image Segmentation with Heterogeneous Annotation Completeness",
    "authors": [
      "Yangyang Xiang",
      "Nannan Wu",
      "Li Yu",
      "Xin Yang",
      "Kwang-Ting Cheng",
      "Zengqiang Yan"
    ],
    "abstract": "Federated learning has emerged as a compelling paradigm for medical image\nsegmentation, particularly in light of increasing privacy concerns. However,\nmost of the existing research relies on relatively stringent assumptions\nregarding the uniformity and completeness of annotations across clients.\nContrary to this, this paper highlights a prevalent challenge in medical\npractice: incomplete annotations. Such annotations can introduce incorrectly\nlabeled pixels, potentially undermining the performance of neural networks in\nsupervised learning. To tackle this issue, we introduce a novel solution, named\nFedIA. Our insight is to conceptualize incomplete annotations as noisy data\n(i.e., low-quality data), with a focus on mitigating their adverse effects. We\nbegin by evaluating the completeness of annotations at the client level using a\ndesigned indicator. Subsequently, we enhance the influence of clients with more\ncomprehensive annotations and implement corrections for incomplete ones,\nthereby ensuring that models are trained on accurate data. Our method's\neffectiveness is validated through its superior performance on two extensively\nused medical image segmentation datasets, outperforming existing solutions. The\ncode is available at https://github.com/HUSTxyy/FedIA.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Early accepted by MICCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.02280v2",
    "published_date": "2024-07-02 14:08:55 UTC",
    "updated_date": "2024-07-03 07:12:34 UTC"
  },
  {
    "arxiv_id": "2407.02275v1",
    "title": "Learning Paradigms and Modelling Methodologies for Digital Twins in Process Industry",
    "authors": [
      "Michael Mayr",
      "Georgios C. Chasparis",
      "Josef Küng"
    ],
    "abstract": "Central to the digital transformation of the process industry are Digital\nTwins (DTs), virtual replicas of physical manufacturing systems that combine\nsensor data with sophisticated data-based or physics-based models, or a\ncombination thereof, to tackle a variety of industrial-relevant tasks like\nprocess monitoring, predictive control or decision support. The backbone of a\nDT, i.e. the concrete modelling methodologies and architectural frameworks\nsupporting these models, are complex, diverse and evolve fast, necessitating a\nthorough understanding of the latest state-of-the-art methods and trends to\nstay on top of a highly competitive market. From a research perspective,\ndespite the high research interest in reviewing various aspects of DTs,\nstructured literature reports specifically focusing on unravelling the utilized\nlearning paradigms (e.g. self-supervised learning) for DT-creation in the\nprocess industry are a novel contribution in this field. This study aims to\naddress these gaps by (1) systematically analyzing the modelling methodologies\n(e.g. Convolutional Neural Network, Encoder-Decoder, Hidden Markov Model) and\nparadigms (e.g. data-driven, physics-based, hybrid) used for DT-creation; (2)\nassessing the utilized learning strategies (e.g. supervised, unsupervised,\nself-supervised); (3) analyzing the type of modelling task (e.g. regression,\nclassification, clustering); and (4) identifying the challenges and research\ngaps, as well as, discuss potential resolutions provided.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02275v1",
    "published_date": "2024-07-02 14:05:10 UTC",
    "updated_date": "2024-07-02 14:05:10 UTC"
  },
  {
    "arxiv_id": "2407.02269v1",
    "title": "IFTT-PIN: A Self-Calibrating PIN-Entry Method",
    "authors": [
      "Kathryn McConkey",
      "Talha Enes Ayranci",
      "Mohamed Khamis",
      "Jonathan Grizou"
    ],
    "abstract": "Personalising an interface to the needs and preferences of a user often\nincurs additional interaction steps. In this paper, we demonstrate a novel\nmethod that enables the personalising of an interface without the need for\nexplicit calibration procedures, via a process we call self-calibration. A\nsecond-order effect of self-calibration is that an outside observer cannot\neasily infer what a user is trying to achieve because they cannot interpret the\nuser's actions. To explore this security angle, we developed IFTT-PIN (If This\nThen PIN) as the first self-calibrating PIN-entry method. When using IFTT-PIN,\nusers are free to choose any button for any meaning without ever explicitly\ncommunicating their choice to the machine. IFTT-PIN infers both the user's PIN\nand their preferred button mapping at the same time. This paper presents the\nconcept, implementation, and interactive demonstrations of IFTT-PIN, as well as\nan evaluation against shoulder surfing attacks. Our study (N=24) shows that by\nadding self-calibration to an existing PIN entry method, IFTT-PIN statistically\nsignificantly decreased PIN attack decoding rate by ca. 8.5 times (p=1.1e-9),\nwhile only decreasing the PIN entry encoding rate by ca. 1.4 times (p=0.02),\nleading to a positive security-usability trade-off. IFTT-PIN's entry rate\nsignificantly improved 21 days after first exposure (p=3.6e-6) to the method,\nsuggesting self-calibrating interfaces are memorable despite using an initially\nundefined user interface. Self-calibration methods might lead to novel\nopportunities for interaction that are more inclusive and versatile, a\npotentially interesting challenge for the community. A short introductory video\nis available at https://youtu.be/pP5sfniNRns.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "arXiv admin note: text overlap with arXiv:2205.09534",
    "pdf_url": "http://arxiv.org/pdf/2407.02269v1",
    "published_date": "2024-07-02 13:58:28 UTC",
    "updated_date": "2024-07-02 13:58:28 UTC"
  },
  {
    "arxiv_id": "2407.02268v2",
    "title": "Footprints of Data in a Classifier: Understanding the Privacy Risks and Solution Strategies",
    "authors": [
      "Payel Sadhukhan",
      "Tanujit Chakraborty"
    ],
    "abstract": "The widespread deployment of Artificial Intelligence (AI) across government\nand private industries brings both advancements and heightened privacy and\nsecurity concerns. Article 17 of the General Data Protection Regulation (GDPR)\nmandates the Right to Erasure, requiring data to be permanently removed from a\nsystem to prevent potential compromise. While existing research primarily\nfocuses on erasing sensitive data attributes, several passive data compromise\nmechanisms remain underexplored and unaddressed. One such issue arises from the\nresidual footprints of training data embedded within predictive models.\nPerformance disparities between test and training data can inadvertently reveal\nwhich data points were part of the training set, posing a privacy risk. This\nstudy examines how two fundamental aspects of classifier systems - training\ndata quality and classifier training methodology - contribute to privacy\nvulnerabilities. Our theoretical analysis demonstrates that classifiers exhibit\nuniversal vulnerability under conditions of data imbalance and distributional\nshifts. Empirical findings reinforce our theoretical results, highlighting the\nsignificant role of training data quality in classifier susceptibility.\nAdditionally, our study reveals that a classifier's operational mechanism and\narchitectural design impact its vulnerability. We further investigate\nmitigation strategies through data obfuscation techniques and analyze their\nimpact on both privacy and classification performance. To aid practitioners, we\nintroduce a privacy-performance trade-off index, providing a structured\napproach to balancing privacy protection with model effectiveness. The findings\noffer valuable insights for selecting classifiers and curating training data in\ndiverse real-world applications.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02268v2",
    "published_date": "2024-07-02 13:56:37 UTC",
    "updated_date": "2025-04-12 08:36:16 UTC"
  },
  {
    "arxiv_id": "2407.02258v1",
    "title": "SiamTST: A Novel Representation Learning Framework for Enhanced Multivariate Time Series Forecasting applied to Telco Networks",
    "authors": [
      "Simen Kristoffersen",
      "Peter Skaar Nordby",
      "Sara Malacarne",
      "Massimiliano Ruocco",
      "Pablo Ortiz"
    ],
    "abstract": "We introduce SiamTST, a novel representation learning framework for\nmultivariate time series. SiamTST integrates a Siamese network with attention,\nchannel-independent patching, and normalization techniques to achieve superior\nperformance. Evaluated on a real-world industrial telecommunication dataset,\nSiamTST demonstrates significant improvements in forecasting accuracy over\nexisting methods. Notably, a simple linear network also shows competitive\nperformance, achieving the second-best results, just behind SiamTST. The code\nis available at https://github.com/simenkristoff/SiamTST.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, 3 figures, public codebase",
    "pdf_url": "http://arxiv.org/pdf/2407.02258v1",
    "published_date": "2024-07-02 13:26:16 UTC",
    "updated_date": "2024-07-02 13:26:16 UTC"
  },
  {
    "arxiv_id": "2407.14269v1",
    "title": "Predictive Simultaneous Interpretation: Harnessing Large Language Models for Democratizing Real-Time Multilingual Communication",
    "authors": [
      "Kurando Iida",
      "Kenjiro Mimura",
      "Nobuo Ito"
    ],
    "abstract": "This study introduces a groundbreaking approach to simultaneous\ninterpretation by directly leveraging the predictive capabilities of Large\nLanguage Models (LLMs). We present a novel algorithm that generates real-time\ntranslations by predicting speaker utterances and expanding multiple\npossibilities in a tree-like structure. This method demonstrates unprecedented\nflexibility and adaptability, potentially overcoming the structural differences\nbetween languages more effectively than existing systems. Our theoretical\nanalysis, supported by illustrative examples, suggests that this approach could\nlead to more natural and fluent translations with minimal latency. The primary\npurpose of this paper is to share this innovative concept with the academic\ncommunity, stimulating further research and development in this field. We\ndiscuss the theoretical foundations, potential advantages, and implementation\nchallenges of this technique, positioning it as a significant step towards\ndemocratizing multilingual communication.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7; I.7.0"
    ],
    "primary_category": "cs.CL",
    "comment": "7 pages",
    "pdf_url": "http://arxiv.org/pdf/2407.14269v1",
    "published_date": "2024-07-02 13:18:28 UTC",
    "updated_date": "2024-07-02 13:18:28 UTC"
  },
  {
    "arxiv_id": "2407.12826v1",
    "title": "Assessing the Effectiveness of GPT-4o in Climate Change Evidence Synthesis and Systematic Assessments: Preliminary Insights",
    "authors": [
      "Elphin Tom Joe",
      "Sai Dileep Koneru",
      "Christine J Kirchhoff"
    ],
    "abstract": "In this research short, we examine the potential of using GPT-4o, a\nstate-of-the-art large language model (LLM) to undertake evidence synthesis and\nsystematic assessment tasks. Traditional workflows for such tasks involve large\ngroups of domain experts who manually review and synthesize vast amounts of\nliterature. The exponential growth of scientific literature and recent advances\nin LLMs provide an opportunity to complementing these traditional workflows\nwith new age tools. We assess the efficacy of GPT-4o to do these tasks on a\nsample from the dataset created by the Global Adaptation Mapping Initiative\n(GAMI) where we check the accuracy of climate change adaptation related feature\nextraction from the scientific literature across three levels of expertise. Our\nresults indicate that while GPT-4o can achieve high accuracy in low-expertise\ntasks like geographic location identification, their performance in\nintermediate and high-expertise tasks, such as stakeholder identification and\nassessment of depth of the adaptation response, is less reliable. The findings\nmotivate the need for designing assessment workflows that utilize the strengths\nof models like GPT-4o while also providing refinements to improve their\nperformance on these tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.12826v1",
    "published_date": "2024-07-02 13:14:57 UTC",
    "updated_date": "2024-07-02 13:14:57 UTC"
  },
  {
    "arxiv_id": "2407.02547v1",
    "title": "Domain Generalizable Knowledge Tracing via Concept Aggregation and Relation-Based Attention",
    "authors": [
      "Yuquan Xie",
      "Wanqi Yang",
      "Jinyu Wei",
      "Ming Yang",
      "Yang Gao"
    ],
    "abstract": "Knowledge Tracing (KT) is a critical task in online education systems, aiming\nto monitor students' knowledge states throughout a learning period. Common KT\napproaches involve predicting the probability of a student correctly answering\nthe next question based on their exercise history. However, these methods often\nsuffer from performance degradation when faced with the scarcity of student\ninteractions in new education systems. To address this, we leverage student\ninteractions from existing education systems to mitigate performance\ndegradation caused by limited training data. Nevertheless, these interactions\nexhibit significant differences since they are derived from different education\nsystems. To address this issue, we propose a domain generalization approach for\nknowledge tracing, where existing education systems are considered source\ndomains, and new education systems with limited data are considered target\ndomains. Additionally, we design a domain-generalizable knowledge tracing\nframework (DGKT) that can be applied to any KT model. Specifically, we present\na concept aggregation approach designed to reduce conceptual disparities within\nsequences of student interactions from diverse domains. To further mitigate\ndomain discrepancies, we introduce a novel normalization module called Sequence\nInstance Normalization (SeqIN). Moreover, to fully leverage exercise\ninformation, we propose a new knowledge tracing model tailored for the domain\ngeneralization KT task, named Domain-Generalizable Relation-based Knowledge\nTracing (DGRKT). Extensive experiments across five benchmark datasets\ndemonstrate that the proposed method performs well despite limited training\ndata.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02547v1",
    "published_date": "2024-07-02 13:13:44 UTC",
    "updated_date": "2024-07-02 13:13:44 UTC"
  },
  {
    "arxiv_id": "2407.12825v1",
    "title": "A Depression Detection Method Based on Multi-Modal Feature Fusion Using Cross-Attention",
    "authors": [
      "Shengjie Li",
      "Yinhao Xiao"
    ],
    "abstract": "Depression, a prevalent and serious mental health issue, affects\napproximately 3.8\\% of the global population. Despite the existence of\neffective treatments, over 75\\% of individuals in low- and middle-income\ncountries remain untreated, partly due to the challenge in accurately\ndiagnosing depression in its early stages. This paper introduces a novel method\nfor detecting depression based on multi-modal feature fusion utilizing\ncross-attention. By employing MacBERT as a pre-training model to extract\nlexical features from text and incorporating an additional Transformer module\nto refine task-specific contextual understanding, the model's adaptability to\nthe targeted task is enhanced. Diverging from previous practices of simply\nconcatenating multimodal features, this approach leverages cross-attention for\nfeature integration, significantly improving the accuracy in depression\ndetection and enabling a more comprehensive and precise analysis of user\nemotions and behaviors. Furthermore, a Multi-Modal Feature Fusion Network based\non Cross-Attention (MFFNC) is constructed, demonstrating exceptional\nperformance in the task of depression identification. The experimental results\nindicate that our method achieves an accuracy of 0.9495 on the test dataset,\nmarking a substantial improvement over existing approaches. Moreover, it\noutlines a promising methodology for other social media platforms and tasks\ninvolving multi-modal processing. Timely identification and intervention for\nindividuals with depression are crucial for saving lives, highlighting the\nimmense potential of technology in facilitating early intervention for mental\nhealth issues.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.12825v1",
    "published_date": "2024-07-02 13:13:35 UTC",
    "updated_date": "2024-07-02 13:13:35 UTC"
  },
  {
    "arxiv_id": "2407.02245v1",
    "title": "Safe CoR: A Dual-Expert Approach to Integrating Imitation Learning and Safe Reinforcement Learning Using Constraint Rewards",
    "authors": [
      "Hyeokjin Kwon",
      "Gunmin Lee",
      "Junseo Lee",
      "Songhwai Oh"
    ],
    "abstract": "In the realm of autonomous agents, ensuring safety and reliability in complex\nand dynamic environments remains a paramount challenge. Safe reinforcement\nlearning addresses these concerns by introducing safety constraints, but still\nfaces challenges in navigating intricate environments such as complex driving\nsituations. To overcome these challenges, we present the safe constraint reward\n(Safe CoR) framework, a novel method that utilizes two types of expert\ndemonstrations$\\unicode{x2013}$reward expert demonstrations focusing on\nperformance optimization and safe expert demonstrations prioritizing safety. By\nexploiting a constraint reward (CoR), our framework guides the agent to balance\nperformance goals of reward sum with safety constraints. We test the proposed\nframework in diverse environments, including the safety gym, metadrive, and the\nreal$\\unicode{x2013}$world Jackal platform. Our proposed framework enhances the\nperformance of algorithms by $39\\%$ and reduces constraint violations by $88\\%$\non the real-world Jackal platform, demonstrating the framework's efficacy.\nThrough this innovative approach, we expect significant advancements in\nreal-world performance, leading to transformative effects in the realm of safe\nand reliable autonomous agents.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted to the Proc. of the IEEE/RSJ International Conference on\n  Intelligent Robots and Systems (IROS), 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.02245v1",
    "published_date": "2024-07-02 13:05:16 UTC",
    "updated_date": "2024-07-02 13:05:16 UTC"
  },
  {
    "arxiv_id": "2407.02236v1",
    "title": "Indian Stock Market Prediction using Augmented Financial Intelligence ML",
    "authors": [
      "Anishka Chauhan",
      "Pratham Mayur",
      "Yeshwanth Sai Gokarakonda",
      "Pooriya Jamie",
      "Naman Mehrotra"
    ],
    "abstract": "This paper presents price prediction models using Machine Learning algorithms\naugmented with Superforecasters predictions, aimed at enhancing investment\ndecisions. Five Machine Learning models are built, including Bidirectional\nLSTM, ARIMA, a combination of CNN and LSTM, GRU, and a model built using LSTM\nand GRU algorithms. The models are evaluated using the Mean Absolute Error to\ndetermine their predictive accuracy. Additionally, the paper suggests\nincorporating human intelligence by identifying Superforecasters and tracking\ntheir predictions to anticipate unpredictable shifts or changes in stock prices\n. The predictions made by these users can further enhance the accuracy of stock\nprice predictions when combined with Machine Learning and Natural Language\nProcessing techniques. Predicting the price of any commodity can be a\nsignificant task but predicting the price of a stock in the stock market deals\nwith much more uncertainty. Recognising the limited knowledge and exposure to\nstocks among certain investors, this paper proposes price prediction models\nusing Machine Learning algorithms. In this work, five Machine learning models\nare built using Bidirectional LSTM, ARIMA, a combination of CNN and LSTM, GRU\nand the last one is built using LSTM and GRU algorithms. Later these models are\nassessed using MAE scores to find which model is predicting with the highest\naccuracy. In addition to this, this paper also suggests the use of human\nintelligence to closely predict the shift in price patterns in the stock market\nThe main goal is to identify Superforecasters and track their predictions to\nanticipate unpredictable shifts or changes in stock prices. By leveraging the\ncombined power of Machine Learning and the Human Intelligence, predictive\naccuracy can be significantly increased.",
    "categories": [
      "q-fin.TR",
      "cs.AI",
      "cs.CE",
      "stat.ML"
    ],
    "primary_category": "q-fin.TR",
    "comment": "Keywords: Machine Learning, Artificial Intelligence, LSTM, GRU, ARMA,\n  CNN, NLP, ANN, SVM, BSE, NIFTY, MAE, MSE, BiLSTM . Published in SSRN Journal",
    "pdf_url": "http://arxiv.org/pdf/2407.02236v1",
    "published_date": "2024-07-02 12:58:50 UTC",
    "updated_date": "2024-07-02 12:58:50 UTC"
  },
  {
    "arxiv_id": "2407.02233v2",
    "title": "Synthetic Multimodal Question Generation",
    "authors": [
      "Ian Wu",
      "Sravan Jayanthi",
      "Vijay Viswanathan",
      "Simon Rosenberg",
      "Sina Pakazad",
      "Tongshuang Wu",
      "Graham Neubig"
    ],
    "abstract": "Multimodal Retrieval Augmented Generation (MMRAG) is a powerful approach to\nquestion-answering over multimodal documents. A key challenge with evaluating\nMMRAG is the paucity of high-quality datasets matching the question styles and\nmodalities of interest. In light of this, we propose SMMQG, a synthetic data\ngeneration framework. SMMQG leverages interplay between a retriever, large\nlanguage model (LLM) and large multimodal model (LMM) to generate question and\nanswer pairs directly from multimodal documents, with the questions conforming\nto specified styles and modalities. We use SMMQG to generate an MMRAG dataset\nof 1024 questions over Wikipedia documents and evaluate state-of-the-art models\nusing it, revealing insights into model performance that are attainable only\nthrough style- and modality-specific evaluation data. Next, we measure the\nquality of data produced by SMMQG via a human study. We find that the quality\nof SMMQG-generated synthetic data is on par with the quality of the\ncrowdsourced benchmark MMQA and that downstream evaluation results using both\ndatasets strongly concur.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to EMNLP 2024 Findings; Camera Ready",
    "pdf_url": "http://arxiv.org/pdf/2407.02233v2",
    "published_date": "2024-07-02 12:57:42 UTC",
    "updated_date": "2024-10-03 19:08:37 UTC"
  },
  {
    "arxiv_id": "2407.02228v2",
    "title": "MTMamba: Enhancing Multi-Task Dense Scene Understanding by Mamba-Based Decoders",
    "authors": [
      "Baijiong Lin",
      "Weisen Jiang",
      "Pengguang Chen",
      "Yu Zhang",
      "Shu Liu",
      "Ying-Cong Chen"
    ],
    "abstract": "Multi-task dense scene understanding, which learns a model for multiple dense\nprediction tasks, has a wide range of application scenarios. Modeling\nlong-range dependency and enhancing cross-task interactions are crucial to\nmulti-task dense prediction. In this paper, we propose MTMamba, a novel\nMamba-based architecture for multi-task scene understanding. It contains two\ntypes of core blocks: self-task Mamba (STM) block and cross-task Mamba (CTM)\nblock. STM handles long-range dependency by leveraging Mamba, while CTM\nexplicitly models task interactions to facilitate information exchange across\ntasks. Experiments on NYUDv2 and PASCAL-Context datasets demonstrate the\nsuperior performance of MTMamba over Transformer-based and CNN-based methods.\nNotably, on the PASCAL-Context dataset, MTMamba achieves improvements of +2.08,\n+5.01, and +4.90 over the previous best methods in the tasks of semantic\nsegmentation, human parsing, and object boundary detection, respectively. The\ncode is available at https://github.com/EnVision-Research/MTMamba.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "ECCV 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.02228v2",
    "published_date": "2024-07-02 12:52:18 UTC",
    "updated_date": "2024-07-14 07:50:04 UTC"
  },
  {
    "arxiv_id": "2407.12824v1",
    "title": "Whispering Experts: Neural Interventions for Toxicity Mitigation in Language Models",
    "authors": [
      "Xavier Suau",
      "Pieter Delobelle",
      "Katherine Metcalf",
      "Armand Joulin",
      "Nicholas Apostoloff",
      "Luca Zappella",
      "Pau Rodríguez"
    ],
    "abstract": "An important issue with Large Language Models (LLMs) is their undesired\nability to generate toxic language. In this work, we show that the neurons\nresponsible for toxicity can be determined by their power to discriminate toxic\nsentences, and that toxic language can be mitigated by reducing their\nactivation levels proportionally to this power. We propose AUROC adaptation\n(AurA), an intervention that can be applied to any pre-trained LLM to mitigate\ntoxicity. As the intervention is proportional to the ability of each neuron to\ndiscriminate toxic content, it is free of any model-dependent hyperparameters.\nWe show that AurA can achieve up to $2.2 \\times$ reduction in toxicity with\nonly a $0.72$ perplexity increase. We also show that AurA is effective with\nmodels of different scale (from 1.5B to 40B parameters), and its effectiveness\nin mitigating toxic language, while preserving common-sense zero-shot\nabilities, holds across all scales. AurA can be combined with pre-prompting\nstrategies, boosting its average mitigation potential from $1.28\\times$ to\n$2.35\\times$. Moreover, AurA can counteract adversarial pre-prompts that\nmaliciously elicit toxic content, making it an effective method for deploying\nsafer and less toxic models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ICML 2024, 8 pages + appendix",
    "pdf_url": "http://arxiv.org/pdf/2407.12824v1",
    "published_date": "2024-07-02 12:48:29 UTC",
    "updated_date": "2024-07-02 12:48:29 UTC"
  },
  {
    "arxiv_id": "2407.02220v2",
    "title": "Embodied AI in Mobile Robots: Coverage Path Planning with Large Language Models",
    "authors": [
      "Xiangrui Kong",
      "Wenxiao Zhang",
      "Jin Hong",
      "Thomas Braunl"
    ],
    "abstract": "In recent years, Large Language Models (LLMs) have demonstrated remarkable\ncapabilities in understanding and solving mathematical problems, leading to\nadvancements in various fields. We propose an LLM-embodied path planning\nframework for mobile agents, focusing on solving high-level coverage path\nplanning issues and low-level control. Our proposed multi-layer architecture\nuses prompted LLMs in the path planning phase and integrates them with the\nmobile agents' low-level actuators. To evaluate the performance of various\nLLMs, we propose a coverage-weighted path planning metric to assess the\nperformance of the embodied models. Our experiments show that the proposed\nframework improves LLMs' spatial inference abilities. We demonstrate that the\nproposed multi-layer framework significantly enhances the efficiency and\naccuracy of these tasks by leveraging the natural language understanding and\ngenerative capabilities of LLMs. Our experiments show that this framework can\nimprove LLMs' 2D plane reasoning abilities and complete coverage path planning\ntasks. We also tested three LLM kernels: gpt-4o, gemini-1.5-flash, and\nclaude-3.5-sonnet. The experimental results show that claude-3.5 can complete\nthe coverage planning task in different scenarios, and its indicators are\nbetter than those of the other models.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "7 pages, 2 figures, conference",
    "pdf_url": "http://arxiv.org/pdf/2407.02220v2",
    "published_date": "2024-07-02 12:38:46 UTC",
    "updated_date": "2024-07-04 01:42:58 UTC"
  },
  {
    "arxiv_id": "2407.02217v1",
    "title": "Physics-Informed Model and Hybrid Planning for Efficient Dyna-Style Reinforcement Learning",
    "authors": [
      "Zakariae El Asri",
      "Olivier Sigaud",
      "Nicolas Thome"
    ],
    "abstract": "Applying reinforcement learning (RL) to real-world applications requires\naddressing a trade-off between asymptotic performance, sample efficiency, and\ninference time. In this work, we demonstrate how to address this triple\nchallenge by leveraging partial physical knowledge about the system dynamics.\nOur approach involves learning a physics-informed model to boost sample\nefficiency and generating imaginary trajectories from this model to learn a\nmodel-free policy and Q-function. Furthermore, we propose a hybrid planning\nstrategy, combining the learned policy and Q-function with the learned model to\nenhance time efficiency in planning. Through practical demonstrations, we\nillustrate that our method improves the compromise between sample efficiency,\ntime efficiency, and performance over state-of-the-art methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02217v1",
    "published_date": "2024-07-02 12:32:57 UTC",
    "updated_date": "2024-07-02 12:32:57 UTC"
  },
  {
    "arxiv_id": "2407.02211v2",
    "title": "PromptIntern: Saving Inference Costs by Internalizing Recurrent Prompt during Large Language Model Fine-tuning",
    "authors": [
      "Jiaru Zou",
      "Mengyu Zhou",
      "Tao Li",
      "Shi Han",
      "Dongmei Zhang"
    ],
    "abstract": "Recent advances in fine-tuning large language models (LLMs) have greatly\nenhanced their usage in domain-specific tasks. Despite the success, fine-tuning\ncontinues to rely on repeated and lengthy prompts, which escalate computational\nexpenses, require more resources, and lead to slower inference. In this paper,\nwe present a novel approach, PromptIntern, which internalizes prompt knowledge\nduring model fine-tuning to achieve efficient inference and save costs. Instead\nof compressing the prompts for a vanilla model, PromptIntern aims to embed the\nrecurrent prompt directly into the model parameters. We design a fine-tuning\npipeline that includes instruction template compression, few-shot example\nabsorption, and a progressive internalization strategy, effectively diminishing\nthe need for intricate prompts during inference. Comprehensive experiments on\nchallenging NL2Code tasks demonstrate that our method reduces input tokens by\nmore than 90%, accelerates inference by 4.2 times, and reduces monetary\ninference costs by 88.3%.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "This paper has been accepted by EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.02211v2",
    "published_date": "2024-07-02 12:21:14 UTC",
    "updated_date": "2024-10-15 22:23:41 UTC"
  },
  {
    "arxiv_id": "2407.02209v1",
    "title": "Generative Monoculture in Large Language Models",
    "authors": [
      "Fan Wu",
      "Emily Black",
      "Varun Chandrasekaran"
    ],
    "abstract": "We introduce {\\em generative monoculture}, a behavior observed in large\nlanguage models (LLMs) characterized by a significant narrowing of model output\ndiversity relative to available training data for a given task: for example,\ngenerating only positive book reviews for books with a mixed reception. While\nin some cases, generative monoculture enhances performance (e.g., LLMs more\noften produce efficient code), the dangers are exacerbated in others (e.g.,\nLLMs refuse to share diverse opinions). As LLMs are increasingly used in\nhigh-impact settings such as education and web search, careful maintenance of\nLLM output diversity is essential to ensure a variety of facts and perspectives\nare preserved over time. We experimentally demonstrate the prevalence of\ngenerative monoculture through analysis of book review and code generation\ntasks, and find that simple countermeasures such as altering sampling or\nprompting strategies are insufficient to mitigate the behavior. Moreover, our\nresults suggest that the root causes of generative monoculture are likely\nembedded within the LLM's alignment processes, suggesting a need for developing\nfine-tuning paradigms that preserve or promote diversity.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02209v1",
    "published_date": "2024-07-02 12:17:07 UTC",
    "updated_date": "2024-07-02 12:17:07 UTC"
  },
  {
    "arxiv_id": "2407.02208v2",
    "title": "How to Learn in a Noisy World? Self-Correcting the Real-World Data Noise in Machine Translation",
    "authors": [
      "Yan Meng",
      "Di Wu",
      "Christof Monz"
    ],
    "abstract": "The massive amounts of web-mined parallel data contain large amounts of\nnoise. Semantic misalignment, as the primary source of the noise, poses a\nchallenge for training machine translation systems. In this paper, we first\nintroduce a process for simulating misalignment controlled by semantic\nsimilarity, which closely resembles misaligned sentences in real-world\nweb-crawled corpora. Under our simulated misalignment noise settings, we\nquantitatively analyze its impact on machine translation and demonstrate the\nlimited effectiveness of widely used pre-filters for noise detection. This\nunderscores the necessity of more fine-grained ways to handle hard-to-detect\nmisalignment noise. With an observation of the increasing reliability of the\nmodel's self-knowledge for distinguishing misaligned and clean data at the\ntoken level, we propose self-correction, an approach that gradually increases\ntrust in the model's self-knowledge to correct the training supervision.\nComprehensive experiments show that our method significantly improves\ntranslation performance both in the presence of simulated misalignment noise\nand when applied to real-world, noisy web-mined datasets, across a range of\ntranslation tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02208v2",
    "published_date": "2024-07-02 12:15:15 UTC",
    "updated_date": "2025-02-07 15:03:38 UTC"
  },
  {
    "arxiv_id": "2407.12823v1",
    "title": "WTU-EVAL: A Whether-or-Not Tool Usage Evaluation Benchmark for Large Language Models",
    "authors": [
      "Kangyun Ning",
      "Yisong Su",
      "Xueqiang Lv",
      "Yuanzhe Zhang",
      "Jian Liu",
      "Kang Liu",
      "Jinan Xu"
    ],
    "abstract": "Although Large Language Models (LLMs) excel in NLP tasks, they still need\nexternal tools to extend their ability. Current research on tool learning with\nLLMs often assumes mandatory tool use, which does not always align with\nreal-world situations, where the necessity for tools is uncertain, and\nincorrect or unnecessary use of tools can damage the general abilities of LLMs.\nTherefore, we propose to explore whether LLMs can discern their ability\nboundaries and use tools flexibly. We then introduce the Whether-or-not tool\nusage Evaluation benchmark (WTU-Eval) to assess LLMs with eleven datasets,\nwhere six of them are tool-usage datasets, and five are general datasets. LLMs\nare prompted to use tools according to their needs. The results of eight LLMs\non WTU-Eval reveal that LLMs frequently struggle to determine tool use in\ngeneral datasets, and LLMs' performance in tool-usage datasets improves when\ntheir ability is similar to ChatGPT. In both datasets, incorrect tool usage\nsignificantly impairs LLMs' performance. To mitigate this, we also develop the\nfinetuning dataset to enhance tool decision-making. Fine-tuning Llama2-7B\nresults in a 14\\% average performance improvement and a 16.8\\% decrease in\nincorrect tool usage. We will release the WTU-Eval benchmark.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.12823v1",
    "published_date": "2024-07-02 12:07:38 UTC",
    "updated_date": "2024-07-02 12:07:38 UTC"
  },
  {
    "arxiv_id": "2407.02203v1",
    "title": "Automatic Adaptation Rule Optimization via Large Language Models",
    "authors": [
      "Yusei Ishimizu",
      "Jialong Li",
      "Jinglue Xu",
      "Jinyu Cai",
      "Hitoshi Iba",
      "Kenji Tei"
    ],
    "abstract": "Rule-based adaptation is a foundational approach to self-adaptation,\ncharacterized by its human readability and rapid response. However, building\nhigh-performance and robust adaptation rules is often a challenge because it\nessentially involves searching the optimal design in a complex (variables)\nspace. In response, this paper attempt to employ large language models (LLMs)\nas a optimizer to construct and optimize adaptation rules, leveraging the\ncommon sense and reasoning capabilities inherent in LLMs. Preliminary\nexperiments conducted in SWIM have validated the effectiveness and limitation\nof our method.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02203v1",
    "published_date": "2024-07-02 12:06:40 UTC",
    "updated_date": "2024-07-02 12:06:40 UTC"
  },
  {
    "arxiv_id": "2407.02197v1",
    "title": "Research on Reliable and Safe Occupancy Grid Prediction in Underground Parking Lots",
    "authors": [
      "JiaQi Luo"
    ],
    "abstract": "Against the backdrop of advancing science and technology, autonomous vehicle\ntechnology has emerged as a focal point of intense scrutiny within the academic\ncommunity. Nevertheless, the challenge persists in guaranteeing the safety and\nreliability of this technology when navigating intricate scenarios. While a\nsubstantial portion of autonomous driving research is dedicated to testing in\nopen-air environments, such as urban roads and highways, where the myriad\nvariables at play are meticulously examined, enclosed indoor spaces like\nunderground parking lots have, to a significant extent, been overlooked in the\nscholarly discourse. This discrepancy highlights a gap in derstanding the\nunique challenges these confined settings pose for autonomous navigation\nsystems.\n  This study tackles indoor autonomous driving, particularly in overlooked\nspaces like underground parking lots. Using CARLA's simulation platform, a\nrealistic parking model is created for data gathering. An occupancy grid\nnetwork then processes this data to predict vehicle paths and obstacles,\nenhancing the system's perception in complex indoor environments. Ultimately,\nthis strategy improves safety in autonomous parking operations. The paper\nmeticulously evaluates the model's predictive capabilities, validating its\nefficacy in the context of underground parking. Our findings confirm that the\nproposed strategy successfully enhances autonomous vehicle performance in these\ncomplex indoor settings. It equips autonomous systems with improved adaptation\nto underground lots, reinforcing safety measures and dependability. This work\npaves the way for future advancements and applications by addressing the\nresearch shortfall concerning indoor parking environments, serving as a pivotal\nreference point.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "15 pages, 19 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.02197v1",
    "published_date": "2024-07-02 11:56:14 UTC",
    "updated_date": "2024-07-02 11:56:14 UTC"
  },
  {
    "arxiv_id": "2407.02191v2",
    "title": "Attack-Aware Noise Calibration for Differential Privacy",
    "authors": [
      "Bogdan Kulynych",
      "Juan Felipe Gomez",
      "Georgios Kaissis",
      "Flavio du Pin Calmon",
      "Carmela Troncoso"
    ],
    "abstract": "Differential privacy (DP) is a widely used approach for mitigating privacy\nrisks when training machine learning models on sensitive data. DP mechanisms\nadd noise during training to limit the risk of information leakage. The scale\nof the added noise is critical, as it determines the trade-off between privacy\nand utility. The standard practice is to select the noise scale to satisfy a\ngiven privacy budget $\\varepsilon$. This privacy budget is in turn interpreted\nin terms of operational attack risks, such as accuracy, sensitivity, and\nspecificity of inference attacks aimed to recover information about the\ntraining data records. We show that first calibrating the noise scale to a\nprivacy budget $\\varepsilon$, and then translating {\\epsilon} to attack risk\nleads to overly conservative risk assessments and unnecessarily low utility.\nInstead, we propose methods to directly calibrate the noise scale to a desired\nattack risk level, bypassing the step of choosing $\\varepsilon$. For a given\nnotion of attack risk, our approach significantly decreases noise scale,\nleading to increased utility at the same level of privacy. We empirically\ndemonstrate that calibrating noise to attack sensitivity/specificity, rather\nthan $\\varepsilon$, when training privacy-preserving ML models substantially\nimproves model accuracy for the same risk level. Our work provides a principled\nand practical way to improve the utility of privacy-preserving ML without\ncompromising on privacy. The code is available at\nhttps://github.com/Felipe-Gomez/riskcal",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "math.ST",
      "stat.ML",
      "stat.TH"
    ],
    "primary_category": "cs.LG",
    "comment": "Appears in NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.02191v2",
    "published_date": "2024-07-02 11:49:59 UTC",
    "updated_date": "2024-11-07 21:51:49 UTC"
  },
  {
    "arxiv_id": "2407.02156v1",
    "title": "Towards Training Music Taggers on Synthetic Data",
    "authors": [
      "Nadine Kroher",
      "Steven Manangu",
      "Aggelos Pikrakis"
    ],
    "abstract": "Most contemporary music tagging systems rely on large volumes of annotated\ndata. As an alternative, we investigate the extent to which synthetically\ngenerated music excerpts can improve tagging systems when only small annotated\ncollections are available. To this end, we release GTZAN-synth, a synthetic\ndataset that follows the taxonomy of the well-known GTZAN dataset while being\nten times larger in data volume. We first observe that simply adding this\nsynthetic dataset to the training split of GTZAN does not result into\nperformance improvements. We then proceed to investigating domain adaptation,\ntransfer learning and fine-tuning strategies for the task at hand and draw the\nconclusion that the last two options yield an increase in accuracy. Overall,\nthe proposed approach can be considered as a first guide in a promising field\nfor future research.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.IR",
      "cs.LG",
      "eess.AS",
      "I.2"
    ],
    "primary_category": "cs.SD",
    "comment": "6 pages, 3 figures, accepted to 21st International Conference on\n  Content-based Multimedia Indexing (CBMI) 2024, code available\n  https://github.com/NadineKroher/music-tagging-synthetic-data-cbmi-2024",
    "pdf_url": "http://arxiv.org/pdf/2407.02156v1",
    "published_date": "2024-07-02 10:54:23 UTC",
    "updated_date": "2024-07-02 10:54:23 UTC"
  },
  {
    "arxiv_id": "2407.02147v2",
    "title": "GemmAr: Enhancing LLMs Through Arabic Instruction-Tuning",
    "authors": [
      "Hasna Chouikhi",
      "Manel Aloui",
      "Cyrine Ben Hammou",
      "Ghaith Chaabane",
      "Haithem Kchaou",
      "Chehir Dhaouadi"
    ],
    "abstract": "Large language models (LLMs) have greatly impacted the natural language\nprocessing (NLP) field, particularly for the English language. These models\nhave demonstrated capabilities in understanding and generating human-like text.\nThe success of language models largely depends on the availability of\nhigh-quality instruction datasets, which consist of detailed task descriptions\nand corresponding responses that are essential for training the models to\naddress a variety of prompts accurately. However, the availability and quality\nof these resources vary by language. While models perform well in English, they\noften need help with languages like Arabic, due to the lack of datasets for\nfine-tuning Arabic-specific tasks. To address this issue, we introduce\nInstAr-500k, a new Arabic instruction dataset created by generating and\ncollecting content that covers several domains and instruction types. We assess\nthis dataset by fine-tuning an open-source Gemma-7B model on several downstream\ntasks to improve its functionality. Based on multiple evaluations, our\nfine-tuned model achieves excellent performance on several Arabic NLP\nbenchmarks. These outcomes emphasize the effectiveness of our dataset in\nelevating the capabilities of language models for Arabic. Our instruction\ndataset bridges the performance gap between English and Arabic language models\nby providing resources that amplify Arabic NLP development. Building on this\nfoundation, we developed a model, GemmAr-7B-V1, specifically tuned to excel at\na wide range of Arabic NLP tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02147v2",
    "published_date": "2024-07-02 10:43:49 UTC",
    "updated_date": "2024-07-09 15:36:11 UTC"
  },
  {
    "arxiv_id": "2407.02138v2",
    "title": "Efficient Nearest Neighbor based Uncertainty Estimation for Natural Language Processing Tasks",
    "authors": [
      "Wataru Hashimoto",
      "Hidetaka Kamigaito",
      "Taro Watanabe"
    ],
    "abstract": "Trustworthiness in model predictions is crucial for safety-critical\napplications in the real world. However, deep neural networks often suffer from\nthe issues of uncertainty estimation, such as miscalibration. In this study, we\npropose $k$-Nearest Neighbor Uncertainty Estimation ($k$NN-UE), which is a new\nuncertainty estimation method that uses not only the distances from the\nneighbors, but also the ratio of labels in the neighbors. Experiments on\nsentiment analysis, natural language inference, and named entity recognition\nshow that our proposed method outperforms the baselines and recent\ndensity-based methods in several calibration and uncertainty metrics. Moreover,\nour analyses indicate that approximate nearest neighbor search techniques\nreduce the inference overhead without significantly degrading the uncertainty\nestimation performance when they are appropriately combined.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at Findings of NAACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2407.02138v2",
    "published_date": "2024-07-02 10:33:31 UTC",
    "updated_date": "2025-02-06 17:32:04 UTC"
  },
  {
    "arxiv_id": "2407.02119v2",
    "title": "Cost-Effective Proxy Reward Model Construction with On-Policy and Active Learning",
    "authors": [
      "Yifang Chen",
      "Shuohang Wang",
      "Ziyi Yang",
      "Hiteshi Sharma",
      "Nikos Karampatziakis",
      "Donghan Yu",
      "Kevin Jamieson",
      "Simon Shaolei Du",
      "Yelong Shen"
    ],
    "abstract": "Reinforcement learning with human feedback (RLHF), as a widely adopted\napproach in current large language model pipelines, is \\textit{bottlenecked by\nthe size of human preference data}. While traditional methods rely on offline\npreference dataset constructions, recent approaches have shifted towards online\nsettings, where a learner uses a small amount of labeled seed data and a large\npool of unlabeled prompts to iteratively construct new preference data through\nself-generated responses and high-quality reward/preference feedback. However,\nmost current online algorithms still focus on preference labeling during policy\nmodel updating with given feedback oracles, which incurs significant expert\nquery costs. \\textit{We are the first to explore cost-effective proxy reward\noracles construction strategies for further labeling preferences or rewards\nwith extremely limited labeled data and expert query budgets}. Our approach\nintroduces two key innovations: (1) on-policy query to avoid OOD and imbalance\nissues in seed data, and (2) active learning to select the most informative\ndata for preference queries. Using these methods, we train a evaluation model\nwith minimal expert-labeled data, which then effectively labels nine times more\npreference pairs for further RLHF training. For instance, our model using\nDirect Preference Optimization (DPO) gains around over 1% average improvement\non AlpacaEval2, MMLU-5shot and MMLU-0shot, with only 1.7K query cost. Our\nmethodology is orthogonal to other direct expert query-based strategies and\ntherefore might be integrated with them to further reduce query costs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02119v2",
    "published_date": "2024-07-02 10:09:19 UTC",
    "updated_date": "2024-07-09 08:24:06 UTC"
  },
  {
    "arxiv_id": "2407.02112v3",
    "title": "A Data-Centric Perspective on Evaluating Machine Learning Models for Tabular Data",
    "authors": [
      "Andrej Tschalzev",
      "Sascha Marton",
      "Stefan Lüdtke",
      "Christian Bartelt",
      "Heiner Stuckenschmidt"
    ],
    "abstract": "Tabular data is prevalent in real-world machine learning applications, and\nnew models for supervised learning of tabular data are frequently proposed.\nComparative studies assessing the performance of models typically consist of\nmodel-centric evaluation setups with overly standardized data preprocessing.\nThis paper demonstrates that such model-centric evaluations are biased, as\nreal-world modeling pipelines often require dataset-specific preprocessing and\nfeature engineering. Therefore, we propose a data-centric evaluation framework.\nWe select 10 relevant datasets from Kaggle competitions and implement\nexpert-level preprocessing pipelines for each dataset. We conduct experiments\nwith different preprocessing pipelines and hyperparameter optimization (HPO)\nregimes to quantify the impact of model selection, HPO, feature engineering,\nand test-time adaptation. Our main findings are: 1. After dataset-specific\nfeature engineering, model rankings change considerably, performance\ndifferences decrease, and the importance of model selection reduces. 2. Recent\nmodels, despite their measurable progress, still significantly benefit from\nmanual feature engineering. This holds true for both tree-based models and\nneural networks. 3. While tabular data is typically considered static, samples\nare often collected over time, and adapting to distribution shifts can be\nimportant even in supposedly static data. These insights suggest that research\nefforts should be directed toward a data-centric perspective, acknowledging\nthat tabular data requires feature engineering and often exhibits temporal\ncharacteristics. Our framework is available under:\nhttps://github.com/atschalz/dc_tabeval.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02112v3",
    "published_date": "2024-07-02 09:54:39 UTC",
    "updated_date": "2024-12-18 16:07:04 UTC"
  },
  {
    "arxiv_id": "2407.02109v2",
    "title": "HRSAM: Efficient Interactive Segmentation in High-Resolution Images",
    "authors": [
      "You Huang",
      "Wenbin Lai",
      "Jiayi Ji",
      "Liujuan Cao",
      "Shengchuan Zhang",
      "Rongrong Ji"
    ],
    "abstract": "The Segment Anything Model (SAM) has advanced interactive segmentation but is\nlimited by the high computational cost on high-resolution images. This requires\ndownsampling to meet GPU constraints, sacrificing the fine-grained details\nneeded for high-precision interactive segmentation. To address SAM's\nlimitations, we focus on visual length extrapolation and propose a lightweight\nmodel named HRSAM. The extrapolation enables HRSAM trained on low resolutions\nto generalize to high resolutions. We begin by finding the link between the\nextrapolation and attention scores, which leads us to base HRSAM on Swin\nattention. We then introduce the Flexible Local Attention (FLA) framework,\nusing CUDA-optimized Efficient Memory Attention to accelerate HRSAM. Within\nFLA, we implement Flash Swin attention, achieving over a 35% speedup compared\nto traditional Swin attention, and propose a KV-only padding mechanism to\nenhance extrapolation. We also develop the Cycle-scan module that uses State\nSpace models to efficiently expand HRSAM's receptive field. We further develop\nthe HRSAM++ within FLA by adding an anchor map, providing multi-scale data\naugmentation for the extrapolation and a larger receptive field at slight\ncomputational cost. Experiments show that, under standard training, HRSAMs\nsurpass the previous SOTA with only 38% of the latency. With SAM-distillation,\nthe extrapolation enables HRSAMs to outperform the teacher model at lower\nlatency. Further finetuning achieves performance significantly exceeding the\nprevious SOTA.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02109v2",
    "published_date": "2024-07-02 09:51:56 UTC",
    "updated_date": "2024-11-23 01:44:00 UTC"
  },
  {
    "arxiv_id": "2407.02106v1",
    "title": "Automated Knowledge Graph Learning in Industrial Processes",
    "authors": [
      "Lolitta Ammann",
      "Jorge Martinez-Gil",
      "Michael Mayr",
      "Georgios C. Chasparis"
    ],
    "abstract": "Industrial processes generate vast amounts of time series data, yet\nextracting meaningful relationships and insights remains challenging. This\npaper introduces a framework for automated knowledge graph learning from time\nseries data, specifically tailored for industrial applications. Our framework\naddresses the complexities inherent in industrial datasets, transforming them\ninto knowledge graphs that improve decision-making, process optimization, and\nknowledge discovery. Additionally, it employs Granger causality to identify key\nattributes that can inform the design of predictive models. To illustrate the\npractical utility of our approach, we also present a motivating use case\ndemonstrating the benefits of our framework in a real-world industrial\nscenario. Further, we demonstrate how the automated conversion of time series\ndata into knowledge graphs can identify causal influences or dependencies\nbetween important process parameters.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02106v1",
    "published_date": "2024-07-02 09:47:56 UTC",
    "updated_date": "2024-07-02 09:47:56 UTC"
  },
  {
    "arxiv_id": "2407.02078v1",
    "title": "MARLIN: A Cloud Integrated Robotic Solution to Support Intralogistics in Retail",
    "authors": [
      "Dennis Mronga",
      "Andreas Bresser",
      "Fabian Maas",
      "Adrian Danzglock",
      "Simon Stelter",
      "Alina Hawkin",
      "Hoang Giang Nguyen",
      "Michael Beetz",
      "Frank Kirchner"
    ],
    "abstract": "In this paper, we present the service robot MARLIN and its integration with\nthe K4R platform, a cloud system for complex AI applications in retail. At its\ncore, this platform contains so-called semantic digital twins, a semantically\nannotated representation of the retail store. MARLIN continuously exchanges\ndata with the K4R platform, improving the robot's capabilities in perception,\nautonomous navigation, and task planning. We exploit these capabilities in a\nretail intralogistics scenario, specifically by assisting store employees in\nstocking shelves. We demonstrate that MARLIN is able to update the digital\nrepresentation of the retail store by detecting and classifying obstacles,\nautonomously planning and executing replenishment missions, adapting to\nunforeseen changes in the environment, and interacting with store employees.\nExperiments are conducted in simulation, in a laboratory environment, and in a\nreal store. We also describe and evaluate a novel algorithm for autonomous\nnavigation of articulated tractor-trailer systems. The algorithm outperforms\nthe manufacturer's proprietary navigation approach and improves MARLIN's\nnavigation capabilities in confined spaces.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02078v1",
    "published_date": "2024-07-02 09:12:54 UTC",
    "updated_date": "2024-07-02 09:12:54 UTC"
  },
  {
    "arxiv_id": "2407.02070v2",
    "title": "Latent Diffusion Model for Generating Ensembles of Climate Simulations",
    "authors": [
      "Johannes Meuer",
      "Maximilian Witte",
      "Tobias Sebastian Finn",
      "Claudia Timmreck",
      "Thomas Ludwig",
      "Christopher Kadow"
    ],
    "abstract": "Obtaining accurate estimates of uncertainty in climate scenarios often\nrequires generating large ensembles of high-resolution climate simulations, a\ncomputationally expensive and memory intensive process. To address this\nchallenge, we train a novel generative deep learning approach on extensive sets\nof climate simulations. The model consists of two components: a variational\nautoencoder for dimensionality reduction and a denoising diffusion\nprobabilistic model that generates multiple ensemble members. We validate our\nmodel on the Max Planck Institute Grand Ensemble and show that it achieves good\nagreement with the original ensemble in terms of variability. By leveraging the\nlatent space representation, our model can rapidly generate large ensembles\non-the-fly with minimal memory requirements, which can significantly improve\nthe efficiency of uncertainty quantification in climate simulations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.ao-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 7 figures, Accepted at the ICML 2024 Machine Learning for\n  Earth System Modeling workshop",
    "pdf_url": "http://arxiv.org/pdf/2407.02070v2",
    "published_date": "2024-07-02 08:59:24 UTC",
    "updated_date": "2024-07-04 12:43:52 UTC"
  },
  {
    "arxiv_id": "2407.02062v2",
    "title": "Are Data Augmentation Methods in Named Entity Recognition Applicable for Uncertainty Estimation?",
    "authors": [
      "Wataru Hashimoto",
      "Hidetaka Kamigaito",
      "Taro Watanabe"
    ],
    "abstract": "This work investigates the impact of data augmentation on confidence\ncalibration and uncertainty estimation in Named Entity Recognition (NER) tasks.\nFor the future advance of NER in safety-critical fields like healthcare and\nfinance, it is essential to achieve accurate predictions with calibrated\nconfidence when applying Deep Neural Networks (DNNs), including Pre-trained\nLanguage Models (PLMs), as a real-world application. However, DNNs are prone to\nmiscalibration, which limits their applicability. Moreover, existing methods\nfor calibration and uncertainty estimation are computational expensive. Our\ninvestigation in NER found that data augmentation improves calibration and\nuncertainty in cross-genre and cross-lingual setting, especially in-domain\nsetting. Furthermore, we showed that the calibration for NER tends to be more\neffective when the perplexity of the sentences generated by data augmentation\nis lower, and that increasing the size of the augmentation further improves\ncalibration and uncertainty.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to EMNLP 2024 main conference",
    "pdf_url": "http://arxiv.org/pdf/2407.02062v2",
    "published_date": "2024-07-02 08:49:43 UTC",
    "updated_date": "2024-10-25 10:07:18 UTC"
  },
  {
    "arxiv_id": "2407.02060v1",
    "title": "Terminating Differentiable Tree Experts",
    "authors": [
      "Jonathan Thomm",
      "Michael Hersche",
      "Giacomo Camposampiero",
      "Aleksandar Terzić",
      "Bernhard Schölkopf",
      "Abbas Rahimi"
    ],
    "abstract": "We advance the recently proposed neuro-symbolic Differentiable Tree Machine,\nwhich learns tree operations using a combination of transformers and Tensor\nProduct Representations. We investigate the architecture and propose two key\ncomponents. We first remove a series of different transformer layers that are\nused in every step by introducing a mixture of experts. This results in a\nDifferentiable Tree Experts model with a constant number of parameters for any\narbitrary number of steps in the computation, compared to the previous method\nin the Differentiable Tree Machine with a linear growth. Given this flexibility\nin the number of steps, we additionally propose a new termination algorithm to\nprovide the model the power to choose how many steps to make automatically. The\nresulting Terminating Differentiable Tree Experts model sluggishly learns to\npredict the number of steps without an oracle. It can do so while maintaining\nthe learning capabilities of the model, converging to the optimal amount of\nsteps.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SC"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at the 18th International Conference on Neural-Symbolic\n  Learning and Reasoning (NeSy) 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.02060v1",
    "published_date": "2024-07-02 08:45:38 UTC",
    "updated_date": "2024-07-02 08:45:38 UTC"
  },
  {
    "arxiv_id": "2407.02056v1",
    "title": "Integrate the Essence and Eliminate the Dross: Fine-Grained Self-Consistency for Free-Form Language Generation",
    "authors": [
      "Xinglin Wang",
      "Yiwei Li",
      "Shaoxiong Feng",
      "Peiwen Yuan",
      "Boyuan Pan",
      "Heda Wang",
      "Yao Hu",
      "Kan Li"
    ],
    "abstract": "Self-consistency (SC), leveraging multiple samples from LLMs, shows\nsignificant gains on various reasoning tasks but struggles with free-form\ngeneration due to the difficulty of aggregating answers. Its variants, UCS and\nUSC, rely on sample selection or voting mechanisms to improve output quality.\nThese methods, however, face limitations due to their inability to fully\nutilize the nuanced consensus knowledge present within multiple candidate\nsamples, often resulting in suboptimal outputs. We propose Fine-Grained\nSelf-Consistency (FSC) to addresses these limitations by extracting and\nintegrating segment-level commonalities from candidate samples, enhancing the\nperformance of LLMs both in open-ended and reasoning tasks. Based on this, we\npresent two additional strategies: candidate filtering, which enhances overall\nquality by identifying highly similar candidate sets, and merging, which\nreduces input token requirements by combining similar samples. The\neffectiveness of FSC is demonstrated through extensive experiments on various\ntasks, including summarization, code generation, and mathematical reasoning,\nusing GPT-3.5-turbo and GPT-4. The results indicate significant improvements\nover baseline methods, showcasing the potential of FSC to optimize output\nquality by effectively synthesizing fine-grained consensus knowledge from\nmultiple samples.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ACL2024 Main Conference",
    "pdf_url": "http://arxiv.org/pdf/2407.02056v1",
    "published_date": "2024-07-02 08:38:31 UTC",
    "updated_date": "2024-07-02 08:38:31 UTC"
  },
  {
    "arxiv_id": "2407.02055v1",
    "title": "Abstract Dialectical Frameworks are Boolean Networks (full version)",
    "authors": [
      "Jesse Heyninck",
      "Matthias Knorr",
      "João Leite"
    ],
    "abstract": "Dialectical frameworks are a unifying model of formal argumentation, where\nargumentative relations between arguments are represented by assigning\nacceptance conditions to atomic arguments. Their generality allow them to cover\na number of different approaches with varying forms of representing the\nargumentation structure. Boolean regulatory networks are used to model the\ndynamics of complex biological processes, taking into account the interactions\nof biological compounds, such as proteins or genes. These models have proven\nhighly useful for comprehending such biological processes, allowing to\nreproduce known behaviour and testing new hypotheses and predictions in silico,\nfor example in the context of new medical treatments. While both these\napproaches stem from entirely different communities, it turns out that there\nare striking similarities in their appearence. In this paper, we study the\nrelation between these two formalisms revealing their communalities as well as\ntheir differences, and introducing a correspondence that allows to establish\nnovel results for the individual formalisms.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02055v1",
    "published_date": "2024-07-02 08:37:05 UTC",
    "updated_date": "2024-07-02 08:37:05 UTC"
  },
  {
    "arxiv_id": "2407.02048v1",
    "title": "Revolutionising Role-Playing Games with ChatGPT",
    "authors": [
      "Rita Stampfl",
      "Barbara Geyer",
      "Marie Deissl-O'Meara",
      "Igor Ivkić"
    ],
    "abstract": "Digitalisation in education and its influence on teaching methods is the\nfocus of this study, which examines the use of ChatGPT in a role-playing game\nused in the Cloud Computing Engineering Master's programme at the University of\nApplied Sciences Burgenland. The aim of the study was to analyse the impact of\nAI-based simulations on students' learning experience. Based on Vygotsky's\nsociocultural theory, ChatGPT was used to give students a deeper understanding\nof strategic decision-making processes in simulated business scenarios. The\nmethodological approach included role-playing and qualitative content analysis\nof 20 student reflections. The findings suggest that ChatGPT enhances students'\nengagement, critical thinking, and communication skills, in addition to\ncontributing to the effective application of theoretical knowledge.\nFurthermore, simulations can contribute to the effective application of\ntheoretical knowledge. The results underscore the significance of adaptive\nteaching approaches in promoting digital literacy and equipping learners for\nthe digital workplace. The integration of AI into curricula and the need for\nongoing innovation in higher education are also emphasised as a means of\nguaranteeing excellent, future-focused instruction. The findings highlight the\npotential of AI and ChatGPT in particular, as an innovative cutting-edge\neducational tool that can both enhance the learning experience and help achieve\nthe Sustainable Development Goals (SDGs) through education.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "Received 23-02-2024; Accepted 20-05-2024; Published 27-05-2024",
    "pdf_url": "http://arxiv.org/pdf/2407.02048v1",
    "published_date": "2024-07-02 08:21:40 UTC",
    "updated_date": "2024-07-02 08:21:40 UTC"
  },
  {
    "arxiv_id": "2407.02042v1",
    "title": "Fake News Detection and Manipulation Reasoning via Large Vision-Language Models",
    "authors": [
      "Ruihan Jin",
      "Ruibo Fu",
      "Zhengqi Wen",
      "Shuai Zhang",
      "Yukun Liu",
      "Jianhua Tao"
    ],
    "abstract": "Fake news becomes a growing threat to information security and public opinion\nwith the rapid sprawl of media manipulation. Therefore, fake news detection\nattracts widespread attention from academic community. Traditional fake news\ndetection models demonstrate remarkable performance on authenticity binary\nclassification but their ability to reason detailed faked traces based on the\nnews content remains under-explored. Furthermore, due to the lack of external\nknowledge, the performance of existing methods on fact-related news is\nquestionable, leaving their practical implementation unclear. In this paper, we\npropose a new multi-media research topic, namely manipulation reasoning.\nManipulation reasoning aims to reason manipulations based on news content. To\nsupport the research, we introduce a benchmark for fake news detection and\nmanipulation reasoning, referred to as Human-centric and Fact-related Fake News\n(HFFN). The benchmark highlights the centrality of human and the high factual\nrelevance, with detailed manual annotations. HFFN encompasses four realistic\ndomains with fake news samples generated through three manipulation approaches.\nMoreover, a Multi-modal news Detection and Reasoning langUage Model (M-DRUM) is\npresented not only to judge on the authenticity of multi-modal news, but also\nraise analytical reasoning about potential manipulations. On the feature\nextraction level, a cross-attention mechanism is employed to extract\nfine-grained fusion features from multi-modal inputs. On the reasoning level, a\nlarge vision-language model (LVLM) serves as the backbone to facilitate\nfact-related reasoning. A two-stage training framework is deployed to better\nactivate the capacity of identification and reasoning. Comprehensive\nexperiments demonstrate that our model outperforms state-of-the-art (SOTA) fake\nnews detection models and powerful LVLMs like GPT-4 and LLaVA.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02042v1",
    "published_date": "2024-07-02 08:16:43 UTC",
    "updated_date": "2024-07-02 08:16:43 UTC"
  },
  {
    "arxiv_id": "2407.02040v1",
    "title": "ScaleDreamer: Scalable Text-to-3D Synthesis with Asynchronous Score Distillation",
    "authors": [
      "Zhiyuan Ma",
      "Yuxiang Wei",
      "Yabin Zhang",
      "Xiangyu Zhu",
      "Zhen Lei",
      "Lei Zhang"
    ],
    "abstract": "By leveraging the text-to-image diffusion priors, score distillation can\nsynthesize 3D contents without paired text-3D training data. Instead of\nspending hours of online optimization per text prompt, recent studies have been\nfocused on learning a text-to-3D generative network for amortizing multiple\ntext-3D relations, which can synthesize 3D contents in seconds. However,\nexisting score distillation methods are hard to scale up to a large amount of\ntext prompts due to the difficulties in aligning pretrained diffusion prior\nwith the distribution of rendered images from various text prompts. Current\nstate-of-the-arts such as Variational Score Distillation finetune the\npretrained diffusion model to minimize the noise prediction error so as to\nalign the distributions, which are however unstable to train and will impair\nthe model's comprehension capability to numerous text prompts. Based on the\nobservation that the diffusion models tend to have lower noise prediction\nerrors at earlier timesteps, we propose Asynchronous Score Distillation (ASD),\nwhich minimizes the noise prediction error by shifting the diffusion timestep\nto earlier ones. ASD is stable to train and can scale up to 100k prompts. It\nreduces the noise prediction error without changing the weights of pre-trained\ndiffusion model, thus keeping its strong comprehension capability to prompts.\nWe conduct extensive experiments across different 2D diffusion models,\nincluding Stable Diffusion and MVDream, and text-to-3D generators, including\nHyper-iNGP, 3DConv-Net and Triplane-Transformer. The results demonstrate ASD's\neffectiveness in stable 3D generator training, high-quality 3D content\nsynthesis, and its superior prompt-consistency, especially under large prompt\ncorpus.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ECCV 2024. Code available at\n  https://github.com/theEricMa/ScaleDreamer",
    "pdf_url": "http://arxiv.org/pdf/2407.02040v1",
    "published_date": "2024-07-02 08:12:14 UTC",
    "updated_date": "2024-07-02 08:12:14 UTC"
  },
  {
    "arxiv_id": "2407.17482v2",
    "title": "Reinforcement Learning from Human Feedback: Whose Culture, Whose Values, Whose Perspectives?",
    "authors": [
      "Kristian González Barman",
      "Simon Lohse",
      "Henk de Regt"
    ],
    "abstract": "We argue for the epistemic and ethical advantages of pluralism in\nReinforcement Learning from Human Feedback (RLHF) in the context of Large\nLanguage Models (LLM). Drawing on social epistemology and pluralist philosophy\nof science, we suggest ways in which RHLF can be made more responsive to human\nneeds and how we can address challenges along the way. The paper concludes with\nan agenda for change, i.e. concrete, actionable steps to improve LLM\ndevelopment.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.17482v2",
    "published_date": "2024-07-02 08:07:27 UTC",
    "updated_date": "2025-01-17 09:17:30 UTC"
  },
  {
    "arxiv_id": "2407.02031v2",
    "title": "SwiftDiffusion: Efficient Diffusion Model Serving with Add-on Modules",
    "authors": [
      "Suyi Li",
      "Lingyun Yang",
      "Xiaoxiao Jiang",
      "Hanfeng Lu",
      "Dakai An",
      "Zhipeng Di",
      "Weiyi Lu",
      "Jiawei Chen",
      "Kan Liu",
      "Yinghao Yu",
      "Tao Lan",
      "Guodong Yang",
      "Lin Qu",
      "Liping Zhang",
      "Wei Wang"
    ],
    "abstract": "Text-to-image (T2I) generation using diffusion models has become a\nblockbuster service in today's AI cloud. A production T2I service typically\ninvolves a serving workflow where a base diffusion model is augmented with\nvarious \"add-on\" modules, notably ControlNet and LoRA, to enhance image\ngeneration control. Compared to serving the base model alone, these add-on\nmodules introduce significant loading and computational overhead, resulting in\nincreased latency. In this paper, we present SwiftDiffusion, a system that\nefficiently serves a T2I workflow through a holistic approach. SwiftDiffusion\ndecouples ControNet from the base model and deploys it as a separate,\nindependently scaled service on dedicated GPUs, enabling ControlNet caching,\nparallelization, and sharing. To mitigate the high loading overhead of LoRA\nserving, SwiftDiffusion employs a bounded asynchronous LoRA loading (BAL)\ntechnique, allowing LoRA loading to overlap with the initial base model\nexecution by up to k steps without compromising image quality. Furthermore,\nSwiftDiffusion optimizes base model execution with a novel latent parallelism\ntechnique. Collectively, these designs enable SwiftDiffusion to outperform the\nstate-of-the-art T2I serving systems, achieving up to 7.8x latency reduction\nand 1.6x throughput improvement in serving SDXL models on H800 GPUs, without\nsacrificing image quality.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02031v2",
    "published_date": "2024-07-02 07:59:08 UTC",
    "updated_date": "2024-12-06 11:47:06 UTC"
  },
  {
    "arxiv_id": "2407.02028v1",
    "title": "Why does in-context learning fail sometimes? Evaluating in-context learning on open and closed questions",
    "authors": [
      "Xiang Li",
      "Haoran Tang",
      "Siyu Chen",
      "Ziwei Wang",
      "Ryan Chen",
      "Marcin Abram"
    ],
    "abstract": "We measure the performance of in-context learning as a function of task\nnovelty and difficulty for open and closed questions. For that purpose, we\ncreated a novel benchmark consisting of hard scientific questions, each paired\nwith a context of various relevancy. We show that counter-intuitively, a\ncontext that is more aligned with the topic does not always help more than a\nless relevant context. This effect is especially visible for open questions and\nquestions of high difficulty or novelty. This result reveals a fundamental\ndifference between the treatment of close-form and open-form questions by\nlarge-language models and shows a need for a more robust evaluation of\nin-context learning on the variety of different types of questions. It also\nposes a new question of how to optimally select a context for large language\nmodels, especially in the context of Retrieval Augmented Generation (RAG)\nsystems. Our results suggest that the answer to this question can be highly\napplication-dependent and might be contingent on factors including the format\nof the question, the perceived difficulty level of the questions, and the\nnovelty or popularity of the information we seek.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages plus references, 4 main figures, 6 pages of supplementary\n  material",
    "pdf_url": "http://arxiv.org/pdf/2407.02028v1",
    "published_date": "2024-07-02 07:52:30 UTC",
    "updated_date": "2024-07-02 07:52:30 UTC"
  },
  {
    "arxiv_id": "2407.02025v4",
    "title": "On the Expressive Power of Sparse Geometric MPNNs",
    "authors": [
      "Yonatan Sverdlov",
      "Nadav Dym"
    ],
    "abstract": "Motivated by applications in chemistry and other sciences, we study the\nexpressive power of message-passing neural networks for geometric graphs, whose\nnode features correspond to 3-dimensional positions. Recent work has shown that\nsuch models can separate generic pairs of non-isomorphic geometric graphs,\nthough they may fail to separate some rare and complicated instances. However,\nthese results assume a fully connected graph, where each node possesses\ncomplete knowledge of all other nodes. In contrast, often, in application,\nevery node only possesses knowledge of a small number of nearest neighbors.\n  This paper shows that generic pairs of non-isomorphic geometric graphs can be\nseparated by message-passing networks with rotation equivariant features as\nlong as the underlying graph is connected. When only invariant intermediate\nfeatures are allowed, generic separation is guaranteed for generically globally\nrigid graphs. We introduce a simple architecture, EGENNET, which achieves our\ntheoretical guarantees and compares favorably with alternative architecture on\nsynthetic and chemical benchmarks. Our code is available at\nhttps://github.com/yonatansverdlov/E-GenNet.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02025v4",
    "published_date": "2024-07-02 07:48:22 UTC",
    "updated_date": "2025-02-17 16:36:37 UTC"
  },
  {
    "arxiv_id": "2407.02004v2",
    "title": "SAVE: Segment Audio-Visual Easy way using Segment Anything Model",
    "authors": [
      "Khanh-Binh Nguyen",
      "Chae Jung Park"
    ],
    "abstract": "The primary aim of Audio-Visual Segmentation (AVS) is to precisely identify\nand locate auditory elements within visual scenes by accurately predicting\nsegmentation masks at the pixel level. Achieving this involves comprehensively\nconsidering data and model aspects to address this task effectively. This study\npresents a lightweight approach, SAVE, which efficiently adapts the pre-trained\nsegment anything model (SAM) to the AVS task. By incorporating an image encoder\nadapter into the transformer blocks to better capture the distinct dataset\ninformation and proposing a residual audio encoder adapter to encode the audio\nfeatures as a sparse prompt, our proposed model achieves effective audio-visual\nfusion and interaction during the encoding stage. Our proposed method\naccelerates the training and inference speed by reducing the input resolution\nfrom 1024 to 256 pixels while achieving higher performance compared with the\nprevious SOTA. Extensive experimentation validates our approach, demonstrating\nthat our proposed model outperforms other SOTA methods significantly. Moreover,\nleveraging the pre-trained model on synthetic data enhances performance on real\nAVSBench data, achieving 84.59 mIoU on the S4 (V1S) subset and 70.28 mIoU on\nthe MS3 (V1M) set with only 256 pixels for input images. This increases up to\n86.16 mIoU on the S4 (V1S) and 70.83 mIoU on the MS3 (V1M) with inputs of 1024\npixels.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02004v2",
    "published_date": "2024-07-02 07:22:28 UTC",
    "updated_date": "2024-07-03 23:49:36 UTC"
  },
  {
    "arxiv_id": "2407.02543v1",
    "title": "Towards the Next Frontier in Speech Representation Learning Using Disentanglement",
    "authors": [
      "Varun Krishna",
      "Sriram Ganapathy"
    ],
    "abstract": "The popular frameworks for self-supervised learning of speech representations\nhave largely focused on frame-level masked prediction of speech regions. While\nthis has shown promising downstream task performance for speech recognition and\nrelated tasks, this has largely ignored factors of speech that are encoded at\ncoarser level, like characteristics of the speaker or channel that remain\nconsistent through-out a speech utterance. In this work, we propose a framework\nfor Learning Disentangled Self Supervised (termed as Learn2Diss)\nrepresentations of speech, which consists of frame-level and an utterance-level\nencoder modules. The two encoders are initially learned independently, where\nthe frame-level model is largely inspired by existing self supervision\ntechniques, thereby learning pseudo-phonemic representations, while the\nutterance-level encoder is inspired by constrastive learning of pooled\nembeddings, thereby learning pseudo-speaker representations. The joint learning\nof these two modules consists of disentangling the two encoders using a mutual\ninformation based criterion. With several downstream evaluation experiments, we\nshow that the proposed Learn2Diss achieves state-of-the-art results on a\nvariety of tasks, with the frame-level encoder representations improving\nsemantic tasks, while the utterance-level representations improve non-semantic\ntasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02543v1",
    "published_date": "2024-07-02 07:13:35 UTC",
    "updated_date": "2024-07-02 07:13:35 UTC"
  },
  {
    "arxiv_id": "2407.12043v2",
    "title": "The Art of Saying No: Contextual Noncompliance in Language Models",
    "authors": [
      "Faeze Brahman",
      "Sachin Kumar",
      "Vidhisha Balachandran",
      "Pradeep Dasigi",
      "Valentina Pyatkin",
      "Abhilasha Ravichander",
      "Sarah Wiegreffe",
      "Nouha Dziri",
      "Khyathi Chandu",
      "Jack Hessel",
      "Yulia Tsvetkov",
      "Noah A. Smith",
      "Yejin Choi",
      "Hannaneh Hajishirzi"
    ],
    "abstract": "Chat-based language models are designed to be helpful, yet they should not\ncomply with every user request. While most existing work primarily focuses on\nrefusal of \"unsafe\" queries, we posit that the scope of noncompliance should be\nbroadened. We introduce a comprehensive taxonomy of contextual noncompliance\ndescribing when and how models should not comply with user requests. Our\ntaxonomy spans a wide range of categories including incomplete, unsupported,\nindeterminate, and humanizing requests (in addition to unsafe requests). To\ntest noncompliance capabilities of language models, we use this taxonomy to\ndevelop a new evaluation suite of 1000 noncompliance prompts. We find that most\nexisting models show significantly high compliance rates in certain previously\nunderstudied categories with models like GPT-4 incorrectly complying with as\nmany as 30% of requests. To address these gaps, we explore different training\nstrategies using a synthetically-generated training set of requests and\nexpected noncompliant responses. Our experiments demonstrate that while direct\nfinetuning of instruction-tuned models can lead to both over-refusal and a\ndecline in general capabilities, using parameter efficient methods like low\nrank adapters helps to strike a good balance between appropriate noncompliance\nand other capabilities.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "The first two authors are co-first authors; Accepted at NeurIPS 2024\n  Track on Datasets and Benchmarks",
    "pdf_url": "http://arxiv.org/pdf/2407.12043v2",
    "published_date": "2024-07-02 07:12:51 UTC",
    "updated_date": "2024-11-22 17:48:57 UTC"
  },
  {
    "arxiv_id": "2407.01994v1",
    "title": "Simple Augmentations of Logical Rules for Neuro-Symbolic Knowledge Graph Completion",
    "authors": [
      "Ananjan Nandi",
      "Navdeep Kaur",
      "Parag Singla",
      "Mausam"
    ],
    "abstract": "High-quality and high-coverage rule sets are imperative to the success of\nNeuro-Symbolic Knowledge Graph Completion (NS-KGC) models, because they form\nthe basis of all symbolic inferences. Recent literature builds neural models\nfor generating rule sets, however, preliminary experiments show that they\nstruggle with maintaining high coverage. In this work, we suggest three simple\naugmentations to existing rule sets: (1) transforming rules to their abductive\nforms, (2) generating equivalent rules that use inverse forms of constituent\nrelations and (3) random walks that propose new rules. Finally, we prune\npotentially low quality rules. Experiments over four datasets and five\nruleset-baseline settings suggest that these simple augmentations consistently\nimprove results, and obtain up to 7.1 pt MRR and 8.5 pt Hits@1 gains over using\nrules without augmentations.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "comment": "12 pages, 15 tables Published in ACL 2023",
    "pdf_url": "http://arxiv.org/pdf/2407.01994v1",
    "published_date": "2024-07-02 07:07:59 UTC",
    "updated_date": "2024-07-02 07:07:59 UTC"
  },
  {
    "arxiv_id": "2407.01991v3",
    "title": "Generation of Geodesics with Actor-Critic Reinforcement Learning to Predict Midpoints",
    "authors": [
      "Kazumi Kasaura"
    ],
    "abstract": "To find the shortest paths for all pairs on manifolds with infinitesimally\ndefined metrics, we introduce a framework to generate them by predicting\nmidpoints recursively. To learn midpoint prediction, we propose an actor-critic\napproach. We prove the soundness of our approach and show experimentally that\nthe proposed method outperforms existing methods on several planning tasks,\nincluding path planning for agents with complex kinematics and motion planning\nfor multi-degree-of-freedom robot arms.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "17 pages with 8 pages of appendices and references, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.01991v3",
    "published_date": "2024-07-02 07:06:49 UTC",
    "updated_date": "2025-03-21 14:44:42 UTC"
  },
  {
    "arxiv_id": "2407.02542v1",
    "title": "ECAT: A Entire space Continual and Adaptive Transfer Learning Framework for Cross-Domain Recommendation",
    "authors": [
      "Chaoqun Hou",
      "Yuanhang Zhou",
      "Yi Cao",
      "Tong Liu"
    ],
    "abstract": "In industrial recommendation systems, there are several mini-apps designed to\nmeet the diverse interests and needs of users. The sample space of them is\nmerely a small subset of the entire space, making it challenging to train an\nefficient model. In recent years, there have been many excellent studies\nrelated to cross-domain recommendation aimed at mitigating the problem of data\nsparsity. However, few of them have simultaneously considered the adaptability\nof both sample and representation continual transfer setting to the target\ntask. To overcome the above issue, we propose a Entire space Continual and\nAdaptive Transfer learning framework called ECAT which includes two core\ncomponents: First, as for sample transfer, we propose a two-stage method that\nrealizes a coarse-to-fine process. Specifically, we perform an initial\nselection through a graph-guided method, followed by a fine-grained selection\nusing domain adaptation method. Second, we propose an adaptive knowledge\ndistillation method for continually transferring the representations from a\nmodel that is well-trained on the entire space dataset. ECAT enables full\nutilization of the entire space samples and representations under the\nsupervision of the target task, while avoiding negative migration.\nComprehensive experiments on real-world industrial datasets from Taobao show\nthat ECAT advances state-of-the-art performance on offline metrics, and brings\n+13.6% CVR and +8.6% orders for Baiyibutie, a famous mini-app of Taobao.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02542v1",
    "published_date": "2024-07-02 07:02:39 UTC",
    "updated_date": "2024-07-02 07:02:39 UTC"
  },
  {
    "arxiv_id": "2407.01979v1",
    "title": "Unveiling Global Interactive Patterns across Graphs: Towards Interpretable Graph Neural Networks",
    "authors": [
      "Yuwen Wang",
      "Shunyu Liu",
      "Tongya Zheng",
      "Kaixuan Chen",
      "Mingli Song"
    ],
    "abstract": "Graph Neural Networks (GNNs) have emerged as a prominent framework for graph\nmining, leading to significant advances across various domains. Stemmed from\nthe node-wise representations of GNNs, existing explanation studies have\nembraced the subgraph-specific viewpoint that attributes the decision results\nto the salient features and local structures of nodes. However, graph-level\ntasks necessitate long-range dependencies and global interactions for advanced\nGNNs, deviating significantly from subgraph-specific explanations. To bridge\nthis gap, this paper proposes a novel intrinsically interpretable scheme for\ngraph classification, termed as Global Interactive Pattern (GIP) learning,\nwhich introduces learnable global interactive patterns to explicitly interpret\ndecisions. GIP first tackles the complexity of interpretation by clustering\nnumerous nodes using a constrained graph clustering module. Then, it matches\nthe coarsened global interactive instance with a batch of self-interpretable\ngraph prototypes, thereby facilitating a transparent graph-level reasoning\nprocess. Extensive experiments conducted on both synthetic and real-world\nbenchmarks demonstrate that the proposed GIP yields significantly superior\ninterpretability and competitive performance to~the state-of-the-art\ncounterparts. Our code will be made publicly available.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted in KDD2024",
    "pdf_url": "http://arxiv.org/pdf/2407.01979v1",
    "published_date": "2024-07-02 06:31:13 UTC",
    "updated_date": "2024-07-02 06:31:13 UTC"
  },
  {
    "arxiv_id": "2407.01976v2",
    "title": "A Bounding Box is Worth One Token: Interleaving Layout and Text in a Large Language Model for Document Understanding",
    "authors": [
      "Jinghui Lu",
      "Haiyang Yu",
      "Yanjie Wang",
      "Yongjie Ye",
      "Jingqun Tang",
      "Ziwei Yang",
      "Binghong Wu",
      "Qi Liu",
      "Hao Feng",
      "Han Wang",
      "Hao Liu",
      "Can Huang"
    ],
    "abstract": "Recently, many studies have demonstrated that exclusively incorporating\nOCR-derived text and spatial layouts with large language models (LLMs) can be\nhighly effective for document understanding tasks. However, existing methods\nthat integrate spatial layouts with text have limitations, such as producing\noverly long text sequences or failing to fully leverage the autoregressive\ntraits of LLMs. In this work, we introduce Interleaving Layout and Text in a\nLarge Language Model (LayTextLLM)} for document understanding. In particular,\nLayTextLLM projects each bounding box to a single embedding and interleaves it\nwith text, efficiently avoiding long sequence issues while leveraging\nautoregressive traits of LLMs. LayTextLLM not only streamlines the interaction\nof layout and textual data but also shows enhanced performance in Key\nInformation Extraction (KIE) and Visual Question Answering (VQA). Comprehensive\nbenchmark evaluations reveal significant improvements, with a 27.2% increase on\nKIE tasks and 12.0% on VQA tasks compared to previous state-of-the-art document\nunderstanding MLLMs, as well as a 15.1% improvement over other SOTA OCR-based\nLLMs on KIE tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.01976v2",
    "published_date": "2024-07-02 06:29:05 UTC",
    "updated_date": "2024-07-24 11:45:48 UTC"
  },
  {
    "arxiv_id": "2407.04737v2",
    "title": "Hierarchical Decoupling Capacitor Optimization for Power Distribution Network of 2.5D ICs with Co-Analysis of Frequency and Time Domains Based on Deep Reinforcement Learning",
    "authors": [
      "Yuanyuan Duan",
      "Haiyang Feng",
      "Zhiping Yu",
      "Hanming Wu",
      "Leilai Shao",
      "Xiaolei Zhu"
    ],
    "abstract": "With the growing need for higher memory bandwidth and computation density,\n2.5D design, which involves integrating multiple chiplets onto an interposer,\nemerges as a promising solution. However, this integration introduces\nsignificant challenges due to increasing data rates and a large number of I/Os,\nnecessitating advanced optimization of the power distribution networks (PDNs)\nboth on-chip and on-interposer to mitigate the small signal noise and\nsimultaneous switching noise (SSN). Traditional PDN optimization strategies in\n2.5D systems primarily focus on reducing impedance by integrating decoupling\ncapacitors (decaps) to lessen small signal noises. Unfortunately, relying\nsolely on frequency-domain analysis has been proven inadequate for addressing\ncoupled SSN, as indicated by our experimental results. In this work, we\nintroduce a novel two-phase optimization flow using deep reinforcement learning\nto tackle both the on-chip small signal noise and SSN. Initially, we optimize\nthe impedance in the frequency domain to maintain the small signal noise within\nacceptable limits while avoiding over-design. Subsequently, in the time domain,\nwe refine the PDN to minimize the voltage violation integral (VVI), a more\naccurate measure of SSN severity. To the best of our knowledge, this is the\nfirst dual-domain optimization strategy that simultaneously addresses both the\nsmall signal noise and SSN propagation through strategic decap placement in\non-chip and on-interposer PDNs, offering a significant step forward in the\ndesign of robust PDNs for 2.5D integrated systems.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "The data needs to be experimentally revalidated, and the experimental\n  details require further optimization",
    "pdf_url": "http://arxiv.org/pdf/2407.04737v2",
    "published_date": "2024-07-02 06:12:55 UTC",
    "updated_date": "2024-09-27 03:22:07 UTC"
  },
  {
    "arxiv_id": "2407.01972v1",
    "title": "MeMemo: On-device Retrieval Augmentation for Private and Personalized Text Generation",
    "authors": [
      "Zijie J. Wang",
      "Duen Horng Chau"
    ],
    "abstract": "Retrieval-augmented text generation (RAG) addresses the common limitations of\nlarge language models (LLMs), such as hallucination, by retrieving information\nfrom an updatable external knowledge base. However, existing approaches often\nrequire dedicated backend servers for data storage and retrieval, thereby\nlimiting their applicability in use cases that require strict data privacy,\nsuch as personal finance, education, and medicine. To address the pressing need\nfor client-side dense retrieval, we introduce MeMemo, the first open-source\nJavaScript toolkit that adapts the state-of-the-art approximate nearest\nneighbor search technique HNSW to browser environments. Developed with modern\nand native Web technologies, such as IndexedDB and Web Workers, our toolkit\nleverages client-side hardware capabilities to enable researchers and\ndevelopers to efficiently search through millions of high-dimensional vectors\nin the browser. MeMemo enables exciting new design and research opportunities,\nsuch as private and personalized content creation and interactive prototyping,\nas demonstrated in our example application RAG Playground. Reflecting on our\nwork, we discuss the opportunities and challenges for on-device dense\nretrieval. MeMemo is available at https://github.com/poloclub/mememo.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted to SIGIR 2024. 6 pages, 2 figures. For a live demo, visit\n  https://poloclub.github.io/mememo/. Code is open-source at\n  https://github.com/poloclub/mememo",
    "pdf_url": "http://arxiv.org/pdf/2407.01972v1",
    "published_date": "2024-07-02 06:08:55 UTC",
    "updated_date": "2024-07-02 06:08:55 UTC"
  },
  {
    "arxiv_id": "2407.17480v4",
    "title": "Dynamic Universal Approximation Theory: The Basic Theory for Deep Learning-Based Computer Vision Models",
    "authors": [
      "Wei Wang",
      "Qing Li"
    ],
    "abstract": "Computer vision (CV) is one of the most crucial fields in artificial\nintelligence. In recent years, a variety of deep learning models based on\nconvolutional neural networks (CNNs) and Transformers have been designed to\ntackle diverse problems in CV. These algorithms have found practical\napplications in areas such as robotics and facial recognition. Despite the\nincreasing power of current CV models, several fundamental questions remain\nunresolved: Why do CNNs require deep layers? What ensures the generalization\nability of CNNs? Why do residual-based networks outperform fully convolutional\nnetworks like VGG? What is the fundamental difference between residual-based\nCNNs and Transformer-based networks? Why can CNNs utilize LoRA and pruning\ntechniques? The root cause of these questions lies in the lack of a robust\ntheoretical foundation for deep learning models in CV. To address these\ncritical issues and techniques, we employ the Universal Approximation Theorem\n(UAT) to provide a theoretical basis for convolution- and Transformer-based\nmodels in CV. By doing so, we aim to elucidate these questions from a\ntheoretical perspective.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "arXiv admin note: text overlap with arXiv:2407.00958",
    "pdf_url": "http://arxiv.org/pdf/2407.17480v4",
    "published_date": "2024-07-02 06:08:30 UTC",
    "updated_date": "2024-11-29 06:15:05 UTC"
  },
  {
    "arxiv_id": "2407.01953v1",
    "title": "CatMemo at the FinLLM Challenge Task: Fine-Tuning Large Language Models using Data Fusion in Financial Applications",
    "authors": [
      "Yupeng Cao",
      "Zhiyuan Yao",
      "Zhi Chen",
      "Zhiyang Deng"
    ],
    "abstract": "The integration of Large Language Models (LLMs) into financial analysis has\ngarnered significant attention in the NLP community. This paper presents our\nsolution to IJCAI-2024 FinLLM challenge, investigating the capabilities of LLMs\nwithin three critical areas of financial tasks: financial classification,\nfinancial text summarization, and single stock trading. We adopted Llama3-8B\nand Mistral-7B as base models, fine-tuning them through Parameter Efficient\nFine-Tuning (PEFT) and Low-Rank Adaptation (LoRA) approaches. To enhance model\nperformance, we combine datasets from task 1 and task 2 for data fusion. Our\napproach aims to tackle these diverse tasks in a comprehensive and integrated\nmanner, showcasing LLMs' capacity to address diverse and complex financial\ntasks with improved accuracy and decision-making capabilities.",
    "categories": [
      "cs.CE",
      "cs.AI",
      "cs.LG",
      "q-fin.CP"
    ],
    "primary_category": "cs.CE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.01953v1",
    "published_date": "2024-07-02 05:04:13 UTC",
    "updated_date": "2024-07-02 05:04:13 UTC"
  },
  {
    "arxiv_id": "2407.01950v1",
    "title": "LDP: A Local Diffusion Planner for Efficient Robot Navigation and Collision Avoidance",
    "authors": [
      "Wenhao Yu",
      "Jie Peng",
      "Huanyu Yang",
      "Junrui Zhang",
      "Yifan Duan",
      "Jianmin Ji",
      "Yanyong Zhang"
    ],
    "abstract": "The conditional diffusion model has been demonstrated as an efficient tool\nfor learning robot policies, owing to its advancement to accurately model the\nconditional distribution of policies. The intricate nature of real-world\nscenarios, characterized by dynamic obstacles and maze-like structures,\nunderscores the complexity of robot local navigation decision-making as a\nconditional distribution problem. Nevertheless, leveraging the diffusion model\nfor robot local navigation is not trivial and encounters several under-explored\nchallenges: (1) Data Urgency. The complex conditional distribution in local\nnavigation needs training data to include diverse policy in diverse real-world\nscenarios; (2) Myopic Observation. Due to the diversity of the perception\nscenarios, diffusion decisions based on the local perspective of robots may\nprove suboptimal for completing the entire task, as they often lack foresight.\nIn certain scenarios requiring detours, the robot may become trapped. To\naddress these issues, our approach begins with an exploration of a diverse data\ngeneration mechanism that encompasses multiple agents exhibiting distinct\npreferences through target selection informed by integrated global-local\ninsights. Then, based on this diverse training data, a diffusion agent is\nobtained, capable of excellent collision avoidance in diverse scenarios.\nSubsequently, we augment our Local Diffusion Planner, also known as LDP by\nincorporating global observations in a lightweight manner. This enhancement\nbroadens the observational scope of LDP, effectively mitigating the risk of\nbecoming ensnared in local optima and promoting more robust navigational\ndecisions.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "8 pages, 6 figures, accepted by IROS 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.01950v1",
    "published_date": "2024-07-02 04:53:35 UTC",
    "updated_date": "2024-07-02 04:53:35 UTC"
  },
  {
    "arxiv_id": "2407.01948v1",
    "title": "Extracting and Encoding: Leveraging Large Language Models and Medical Knowledge to Enhance Radiological Text Representation",
    "authors": [
      "Pablo Messina",
      "René Vidal",
      "Denis Parra",
      "Álvaro Soto",
      "Vladimir Araujo"
    ],
    "abstract": "Advancing representation learning in specialized fields like medicine remains\nchallenging due to the scarcity of expert annotations for text and images. To\ntackle this issue, we present a novel two-stage framework designed to extract\nhigh-quality factual statements from free-text radiology reports in order to\nimprove the representations of text encoders and, consequently, their\nperformance on various downstream tasks. In the first stage, we propose a\n\\textit{Fact Extractor} that leverages large language models (LLMs) to identify\nfactual statements from well-curated domain-specific datasets. In the second\nstage, we introduce a \\textit{Fact Encoder} (CXRFE) based on a BERT model\nfine-tuned with objective functions designed to improve its representations\nusing the extracted factual data. Our framework also includes a new\nembedding-based metric (CXRFEScore) for evaluating chest X-ray text generation\nsystems, leveraging both stages of our approach. Extensive evaluations show\nthat our fact extractor and encoder outperform current state-of-the-art methods\nin tasks such as sentence ranking, natural language inference, and label\nextraction from radiology reports. Additionally, our metric proves to be more\nrobust and effective than existing metrics commonly used in the radiology\nreport generation literature. The code of this project is available at\n\\url{https://github.com/PabloMessina/CXR-Fact-Encoder}.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ACL 2024 (Findings)",
    "pdf_url": "http://arxiv.org/pdf/2407.01948v1",
    "published_date": "2024-07-02 04:39:19 UTC",
    "updated_date": "2024-07-02 04:39:19 UTC"
  },
  {
    "arxiv_id": "2407.01942v1",
    "title": "Certainly Uncertain: A Benchmark and Metric for Multimodal Epistemic and Aleatoric Awareness",
    "authors": [
      "Khyathi Raghavi Chandu",
      "Linjie Li",
      "Anas Awadalla",
      "Ximing Lu",
      "Jae Sung Park",
      "Jack Hessel",
      "Lijuan Wang",
      "Yejin Choi"
    ],
    "abstract": "The ability to acknowledge the inevitable uncertainty in their knowledge and\nreasoning is a prerequisite for AI systems to be truly truthful and reliable.\nIn this paper, we present a taxonomy of uncertainty specific to vision-language\nAI systems, distinguishing between epistemic uncertainty (arising from a lack\nof information) and aleatoric uncertainty (due to inherent unpredictability),\nand further explore finer categories within. Based on this taxonomy, we\nsynthesize a benchmark dataset, CertainlyUncertain, featuring 178K visual\nquestion answering (VQA) samples as contrastive pairs. This is achieved by 1)\ninpainting images to make previously answerable questions into unanswerable\nones; and 2) using image captions to prompt large language models for both\nanswerable and unanswerable questions. Additionally, we introduce a new metric\nconfidence-weighted accuracy, that is well correlated with both accuracy and\ncalibration error, to address the shortcomings of existing metrics.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "26 pages",
    "pdf_url": "http://arxiv.org/pdf/2407.01942v1",
    "published_date": "2024-07-02 04:23:54 UTC",
    "updated_date": "2024-07-02 04:23:54 UTC"
  },
  {
    "arxiv_id": "2407.11024v5",
    "title": "A mathematical framework of intelligence and consciousness based on Riemannian Geometry",
    "authors": [
      "Meng Lu"
    ],
    "abstract": "Understanding intelligence is a central pursuit in neuroscience, cognitive\nscience, and artificial intelligence. Intelligence encompasses learning,\nproblem-solving, creativity, and even consciousness. Recent advancements in\ngeometric analysis have revealed new insights into high-dimensional information\nrepresentation and organisation, exposing intrinsic data structures and dynamic\nprocesses within neural and artificial systems. However, a comprehensive\nframework that unifies the static and dynamic aspects of intelligence is still\nlacking. This manuscript proposes a mathematical framework based on Riemannian\ngeometry to describe the structure and dynamics of intelligence and\nconsciousness. Intelligence elements are conceptualised as tokens embedded in a\nhigh-dimensional space. The learned token embeddings capture the\ninterconnections of tokens across various scenarios and tasks, forming\nmanifolds in the intelligence space. Thought flow is depicted as the sequential\nactivation of tokens along geodesics within these manifolds. During the\nnavigation of geodesics, consciousness, as a self-referential process,\nperceives the thought flow, evaluates it against predictions, and provides\nfeedback through prediction errors, adjusting the geodesic: non-zero prediction\nerrors, such as learning, lead to the restructuring of the curved manifolds,\nthus changing the geodesic of thought flow. This dynamic interaction integrates\nnew information, evolves the geometry and facilitates learning. The geometry of\nintelligence guides consciousness, and consciousness structures the geometry of\nintelligence. By integrating geometric concepts, this proposed theory offers a\nunified, mathematically framework for describing the structure and dynamics of\nintelligence and consciousness. Applicable to biological and artificial\nintelligence, this framework may pave the way for future research and empirical\nvalidation.",
    "categories": [
      "cs.AI",
      "math.DG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.11024v5",
    "published_date": "2024-07-02 04:17:56 UTC",
    "updated_date": "2024-11-10 08:46:40 UTC"
  },
  {
    "arxiv_id": "2407.01929v3",
    "title": "What We Talk About When We Talk About LMs: Implicit Paradigm Shifts and the Ship of Language Models",
    "authors": [
      "Shengqi Zhu",
      "Jeffrey M. Rzeszotarski"
    ],
    "abstract": "The term Language Models (LMs) as a time-specific collection of models of\ninterest is constantly reinvented, with its referents updated much like the\n$\\textit{Ship of Theseus}$ replaces its parts but remains the same ship in\nessence. In this paper, we investigate this $\\textit{Ship of Language Models}$\nproblem, wherein scientific evolution takes the form of continuous, implicit\nretrofits of key existing terms. We seek to initiate a novel perspective of\nscientific progress, in addition to the more well-studied emergence of new\nterms. To this end, we construct the data infrastructure based on recent NLP\npublications. Then, we perform a series of text-based analyses toward a\ndetailed, quantitative understanding of the use of Language Models as a term of\nart. Our work highlights how systems and theories influence each other in\nscientific discourse, and we call for attention to the transformation of this\nShip that we all are contributing to.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "NAACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2407.01929v3",
    "published_date": "2024-07-02 03:45:55 UTC",
    "updated_date": "2025-02-09 06:15:33 UTC"
  },
  {
    "arxiv_id": "2407.01920v2",
    "title": "To Forget or Not? Towards Practical Knowledge Unlearning for Large Language Models",
    "authors": [
      "Bozhong Tian",
      "Xiaozhuan Liang",
      "Siyuan Cheng",
      "Qingbin Liu",
      "Mengru Wang",
      "Dianbo Sui",
      "Xi Chen",
      "Huajun Chen",
      "Ningyu Zhang"
    ],
    "abstract": "Large Language Models (LLMs) trained on extensive corpora inevitably retain\nsensitive data, such as personal privacy information and copyrighted material.\nRecent advancements in knowledge unlearning involve updating LLM parameters to\nerase specific knowledge. However, current unlearning paradigms are mired in\nvague forgetting boundaries, often erasing knowledge indiscriminately. In this\nwork, we introduce KnowUnDo, a benchmark containing copyrighted content and\nuser privacy domains to evaluate if the unlearning process inadvertently erases\nessential knowledge. Our findings indicate that existing unlearning methods\noften suffer from excessive unlearning. To address this, we propose a simple\nyet effective method, MemFlex, which utilizes gradient information to precisely\ntarget and unlearn sensitive parameters. Experimental results show that MemFlex\nis superior to existing methods in both precise knowledge unlearning and\ngeneral knowledge retaining of LLMs. Code and dataset are released at\nhttps://github.com/zjunlp/KnowUnDo.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2024 Findings; Code and dataset are released at\n  https://github.com/zjunlp/KnowUnDo",
    "pdf_url": "http://arxiv.org/pdf/2407.01920v2",
    "published_date": "2024-07-02 03:34:16 UTC",
    "updated_date": "2024-10-06 15:49:20 UTC"
  },
  {
    "arxiv_id": "2407.01919v1",
    "title": "A Method to Facilitate Membership Inference Attacks in Deep Learning Models",
    "authors": [
      "Zitao Chen",
      "Karthik Pattabiraman"
    ],
    "abstract": "Modern machine learning (ML) ecosystems offer a surging number of ML\nframeworks and code repositories that can greatly facilitate the development of\nML models. Today, even ordinary data holders who are not ML experts can apply\noff-the-shelf codebase to build high-performance ML models on their data, many\nof which are sensitive in nature (e.g., clinical records).\n  In this work, we consider a malicious ML provider who supplies model-training\ncode to the data holders, does not have access to the training process, and has\nonly black-box query access to the resulting model. In this setting, we\ndemonstrate a new form of membership inference attack that is strictly more\npowerful than prior art. Our attack empowers the adversary to reliably\nde-identify all the training samples (average >99% attack TPR@0.1% FPR), and\nthe compromised models still maintain competitive performance as their\nuncorrupted counterparts (average <1% accuracy drop). Moreover, we show that\nthe poisoned models can effectively disguise the amplified membership leakage\nunder common membership privacy auditing, which can only be revealed by a set\nof secret samples known by the adversary.\n  Overall, our study not only points to the worst-case membership privacy\nleakage, but also unveils a common pitfall underlying existing privacy auditing\nmethods, which calls for future efforts to rethink the current practice of\nauditing membership privacy in machine learning models.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CR",
    "comment": "NDSS'25 (a shorter version of this paper will appear in the\n  conference proceeding)",
    "pdf_url": "http://arxiv.org/pdf/2407.01919v1",
    "published_date": "2024-07-02 03:33:42 UTC",
    "updated_date": "2024-07-02 03:33:42 UTC"
  },
  {
    "arxiv_id": "2407.12822v1",
    "title": "Lightweight Large Language Model for Medication Enquiry: Med-Pal",
    "authors": [
      "Kabilan Elangovan",
      "Jasmine Chiat Ling Ong",
      "Liyuan Jin",
      "Benjamin Jun Jie Seng",
      "Yu Heng Kwan",
      "Lit Soo Tan",
      "Ryan Jian Zhong",
      "Justina Koi Li Ma",
      "YuHe Ke",
      "Nan Liu",
      "Kathleen M Giacomini",
      "Daniel Shu Wei Ting"
    ],
    "abstract": "Large Language Models (LLMs) have emerged as a potential solution to assist\ndigital health development with patient education, commonly medication-related\nenquires. We trained and validated Med-Pal, a medication domain-specific\nLLM-chatbot fine-tuned with a fine-grained and expert curated dataset from a\nselection of five light-weighted open-source LLMs of smaller parameter size (7\nbillion or less) regarding computational constraints and prioritizing\noperational efficiency. A multi-disciplinary team performed a clinical\nevaluation of LLMs responses using the SCORE criteria, focusing on safety,\naccuracy, bias, reproducibility, and ease of understanding. Best performing\nlight-weighted LLM was chosen as Med-Pal for further engineering with\nguard-railing using adversarial prompting. Med-Pal and existing light-weighted\nLLMs, including pretrained Biomistral and finetuned Meerkat, were validated on\nan independent dataset on a broad range of medication-related questions (231 in\ntotal), 12 different question types across 14 different medication classes.\nMistral-7b emerged as the top performer among selected lightweight LLMs,\nachieving the highest median score of 14 and 71.9% high-quality responses in\naccuracy and safety domains, hence chosen as the backbone LLM for Med-Pal. When\ncompared against Biomistral, Med-pal outperformed in generating responses\nappropriate for patient communication, with significant reductions bias and\nerrors typical of general LLMs. Comparable performance was observed when\ncomparing Med-Pal with Meerkat. Med-Pal showcases the feasibility of developing\nand employing fine-tuned light-weighted LLMs to enhance digital health\ncommunications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.12822v1",
    "published_date": "2024-07-02 03:32:39 UTC",
    "updated_date": "2024-07-02 03:32:39 UTC"
  },
  {
    "arxiv_id": "2407.01916v1",
    "title": "Sequential Manipulation Against Rank Aggregation: Theory and Algorithm",
    "authors": [
      "Ke Ma",
      "Qianqian Xu",
      "Jinshan Zeng",
      "Wei Liu",
      "Xiaochun Cao",
      "Yingfei Sun",
      "Qingming Huang"
    ],
    "abstract": "Rank aggregation with pairwise comparisons is widely encountered in\nsociology, politics, economics, psychology, sports, etc . Given the enormous\nsocial impact and the consequent incentives, the potential adversary has a\nstrong motivation to manipulate the ranking list. However, the ideal attack\nopportunity and the excessive adversarial capability cause the existing methods\nto be impractical. To fully explore the potential risks, we leverage an online\nattack on the vulnerable data collection process. Since it is independent of\nrank aggregation and lacks effective protection mechanisms, we disrupt the data\ncollection process by fabricating pairwise comparisons without knowledge of the\nfuture data or the true distribution. From the game-theoretic perspective, the\nconfrontation scenario between the online manipulator and the ranker who takes\ncontrol of the original data source is formulated as a distributionally robust\ngame that deals with the uncertainty of knowledge. Then we demonstrate that the\nequilibrium in the above game is potentially favorable to the adversary by\nanalyzing the vulnerability of the sampling algorithms such as Bernoulli and\nreservoir methods. According to the above theoretical analysis, different\nsequential manipulation policies are proposed under a Bayesian decision\nframework and a large class of parametric pairwise comparison models. For\nattackers with complete knowledge, we establish the asymptotic optimality of\nthe proposed policies. To increase the success rate of the sequential\nmanipulation with incomplete knowledge, a distributionally robust estimator,\nwhich replaces the maximum likelihood estimation in a saddle point problem,\nprovides a conservative data generation solution. Finally, the corroborating\nempirical evidence shows that the proposed method manipulates the results of\nrank aggregation methods in a sequential manner.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by IEEE TPAMI URL:\n  https://ieeexplore.ieee.org/document/10564181",
    "pdf_url": "http://arxiv.org/pdf/2407.01916v1",
    "published_date": "2024-07-02 03:31:21 UTC",
    "updated_date": "2024-07-02 03:31:21 UTC"
  },
  {
    "arxiv_id": "2407.01910v2",
    "title": "MG-Verilog: Multi-grained Dataset Towards Enhanced LLM-assisted Verilog Generation",
    "authors": [
      "Yongan Zhang",
      "Zhongzhi Yu",
      "Yonggan Fu",
      "Cheng Wan",
      "Yingyan Celine Lin"
    ],
    "abstract": "Large Language Models (LLMs) have recently shown promise in streamlining\nhardware design processes by encapsulating vast amounts of domain-specific\ndata. In addition, they allow users to interact with the design processes\nthrough natural language instructions, thus making hardware design more\naccessible to developers. However, effectively leveraging LLMs in hardware\ndesign necessitates providing domain-specific data during inference (e.g.,\nthrough in-context learning), fine-tuning, or pre-training. Unfortunately,\nexisting publicly available hardware datasets are often limited in size,\ncomplexity, or detail, which hinders the effectiveness of LLMs in hardware\ndesign tasks. To address this issue, we first propose a set of criteria for\ncreating high-quality hardware datasets that can effectively enhance\nLLM-assisted hardware design. Based on these criteria, we propose a\nMulti-Grained-Verilog (MG-Verilog) dataset, which encompasses descriptions at\nvarious levels of detail and corresponding code samples. To benefit the broader\nhardware design community, we have developed an open-source infrastructure that\nfacilitates easy access, integration, and extension of the dataset to meet\nspecific project needs. Furthermore, to fully exploit the potential of the\nMG-Verilog dataset, which varies in complexity and detail, we introduce a\nbalanced fine-tuning scheme. This scheme serves as a unique use case to\nleverage the diverse levels of detail provided by the dataset. Extensive\nexperiments demonstrate that the proposed dataset and fine-tuning scheme\nconsistently improve the performance of LLMs in hardware design tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted in ISLAD 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.01910v2",
    "published_date": "2024-07-02 03:21:24 UTC",
    "updated_date": "2024-07-03 15:15:20 UTC"
  },
  {
    "arxiv_id": "2407.01906v2",
    "title": "Let the Expert Stick to His Last: Expert-Specialized Fine-Tuning for Sparse Architectural Large Language Models",
    "authors": [
      "Zihan Wang",
      "Deli Chen",
      "Damai Dai",
      "Runxin Xu",
      "Zhuoshu Li",
      "Y. Wu"
    ],
    "abstract": "Parameter-efficient fine-tuning (PEFT) is crucial for customizing Large\nLanguage Models (LLMs) with constrained resources. Although there have been\nvarious PEFT methods for dense-architecture LLMs, PEFT for sparse-architecture\nLLMs is still underexplored. In this work, we study the PEFT method for LLMs\nwith the Mixture-of-Experts (MoE) architecture and the contents of this work\nare mainly threefold: (1) We investigate the dispersion degree of the activated\nexperts in customized tasks, and found that the routing distribution for a\nspecific task tends to be highly concentrated, while the distribution of\nactivated experts varies significantly across different tasks. (2) We propose\nExpert-Specialized Fine-Tuning, or ESFT, which tunes the experts most relevant\nto downstream tasks while freezing the other experts and modules; experimental\nresults demonstrate that our method not only improves the tuning efficiency,\nbut also matches or even surpasses the performance of full-parameter\nfine-tuning. (3) We further analyze the impact of the MoE architecture on\nexpert-specialized fine-tuning. We find that MoE models with finer-grained\nexperts are more advantageous in selecting the combination of experts that are\nmost relevant to downstream tasks, thereby enhancing both the training\nefficiency and effectiveness. Our code is available at\nhttps://github.com/deepseek-ai/ESFT.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.01906v2",
    "published_date": "2024-07-02 03:11:13 UTC",
    "updated_date": "2024-07-05 03:23:59 UTC"
  },
  {
    "arxiv_id": "2407.01903v2",
    "title": "Text-Aware Diffusion for Policy Learning",
    "authors": [
      "Calvin Luo",
      "Mandy He",
      "Zilai Zeng",
      "Chen Sun"
    ],
    "abstract": "Training an agent to achieve particular goals or perform desired behaviors is\noften accomplished through reinforcement learning, especially in the absence of\nexpert demonstrations. However, supporting novel goals or behaviors through\nreinforcement learning requires the ad-hoc design of appropriate reward\nfunctions, which quickly becomes intractable. To address this challenge, we\npropose Text-Aware Diffusion for Policy Learning (TADPoLe), which uses a\npretrained, frozen text-conditioned diffusion model to compute dense zero-shot\nreward signals for text-aligned policy learning. We hypothesize that\nlarge-scale pretrained generative models encode rich priors that can supervise\na policy to behave not only in a text-aligned manner, but also in alignment\nwith a notion of naturalness summarized from internet-scale training data. In\nour experiments, we demonstrate that TADPoLe is able to learn policies for\nnovel goal-achievement and continuous locomotion behaviors specified by natural\nlanguage, in both Humanoid and Dog environments. The behaviors are learned\nzero-shot without ground-truth rewards or expert demonstrations, and are\nqualitatively more natural according to human evaluation. We further show that\nTADPoLe performs competitively when applied to robotic manipulation tasks in\nthe Meta-World environment, without having access to any in-domain\ndemonstrations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.01903v2",
    "published_date": "2024-07-02 03:08:20 UTC",
    "updated_date": "2024-10-31 16:49:26 UTC"
  },
  {
    "arxiv_id": "2407.01902v2",
    "title": "SeqAR: Jailbreak LLMs with Sequential Auto-Generated Characters",
    "authors": [
      "Yan Yang",
      "Zeguan Xiao",
      "Xin Lu",
      "Hongru Wang",
      "Xuetao Wei",
      "Hailiang Huang",
      "Guanhua Chen",
      "Yun Chen"
    ],
    "abstract": "The widespread applications of large language models (LLMs) have brought\nabout concerns regarding their potential misuse. Although aligned with human\npreference data before release, LLMs remain vulnerable to various malicious\nattacks. In this paper, we adopt a red-teaming strategy to enhance LLM safety\nand introduce SeqAR, a simple yet effective framework to design jailbreak\nprompts automatically. The SeqAR framework generates and optimizes multiple\njailbreak characters and then applies sequential jailbreak characters in a\nsingle query to bypass the guardrails of the target LLM. Different from\nprevious work which relies on proprietary LLMs or seed jailbreak templates\ncrafted by human expertise, SeqAR can generate and optimize the jailbreak\nprompt in a cold-start scenario using open-sourced LLMs without any seed\njailbreak templates. Experimental results show that SeqAR achieves attack\nsuccess rates of 88% and 60% in bypassing the safety alignment of GPT-3.5-1106\nand GPT-4, respectively. Furthermore, we extensively evaluate the\ntransferability of the generated templates across different LLMs and held-out\nmalicious requests, while also exploring defense strategies against the\njailbreak attack designed by SeqAR.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted by NAACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2407.01902v2",
    "published_date": "2024-07-02 02:58:29 UTC",
    "updated_date": "2025-03-02 06:28:59 UTC"
  },
  {
    "arxiv_id": "2407.01892v2",
    "title": "GRASP: A Grid-Based Benchmark for Evaluating Commonsense Spatial Reasoning",
    "authors": [
      "Zhisheng Tang",
      "Mayank Kejriwal"
    ],
    "abstract": "Spatial reasoning, an important faculty of human cognition with many\npractical applications, is one of the core commonsense skills that is not\npurely language-based and, for satisfying (as opposed to optimal) solutions,\nrequires some minimum degree of planning. Existing benchmarks of Commonsense\nSpatial Reasoning (CSR) tend to evaluate how Large Language Models (LLMs)\ninterpret text-based spatial $\\textit{descriptions}$ rather than directly\nevaluate a plan produced by the LLM in response to a $\\textit{specific}$\nspatial reasoning problem. In this paper, we construct a large-scale benchmark\ncalled GRASP, which consists of 16,000 grid-based environments where the agent\nis tasked with an energy collection problem. These environments include 100\ngrid instances instantiated using each of the 160 different grid settings,\ninvolving five different energy distributions, two modes of agent starting\nposition, and two distinct obstacle configurations, as well as three kinds of\nagent constraints. Using GRASP, we compare classic baseline approaches, such as\nrandom walk and greedy search methods, with advanced LLMs like GPT-3.5-Turbo,\nGPT-4o, and GPT-o1-mini. The experimental results indicate that even these\nadvanced LLMs struggle to consistently achieve satisfactory solutions.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.01892v2",
    "published_date": "2024-07-02 02:27:46 UTC",
    "updated_date": "2025-01-17 04:29:47 UTC"
  },
  {
    "arxiv_id": "2407.01887v3",
    "title": "Beyond Numeric Awards: In-Context Dueling Bandits with LLM Agents",
    "authors": [
      "Fanzeng Xia",
      "Hao Liu",
      "Yisong Yue",
      "Tongxin Li"
    ],
    "abstract": "In-context reinforcement learning (ICRL) is a frontier paradigm for solving\nreinforcement learning problems in the foundation model era. While ICRL\ncapabilities have been demonstrated in transformers through task-specific\ntraining, the potential of Large Language Models (LLMs) out-of-the-box remains\nlargely unexplored. Recent findings highlight that LLMs often face challenges\nwhen dealing with numerical contexts, and limited attention has been paid to\nevaluating their performance through preference feedback generated by the\nenvironment. This paper is the first to investigate LLMs as in-context\ndecision-makers under the problem of Dueling Bandits (DB), a stateless\npreference-based reinforcement learning setting that extends the classic\nMulti-Armed Bandit (MAB) model by querying for preference feedback. We compare\nGPT-3.5 Turbo, GPT-4, GPT-4 Turbo, Llama 3.1, and o1-Preview against nine\nwell-established DB algorithms. Our results reveal that our top-performing LLM,\nGPT-4 Turbo, has the zero-shot relative decision-making ability to achieve\nsurprisingly low weak regret across all the DB environment instances by quickly\nincluding the best arm in duels. However, an optimality gap exists between LLMs\nand classic DB algorithms in terms of strong regret. LLMs struggle to converge\nand consistently exploit even when explicitly prompted to do so, and are\nsensitive to prompt variations. To bridge this gap, we propose an agentic flow\nframework: LLM with Enhanced Algorithmic Dueling (LEAD), which integrates\noff-the-shelf DB algorithms with LLM agents through fine-grained adaptive\ninterplay. We show that LEAD has theoretical guarantees inherited from classic\nDB algorithms on both weak and strong regret. We validate its efficacy and\nrobustness even with noisy and adversarial prompts. The design of our framework\nsheds light on how to enhance the trustworthiness of LLMs used for in-context\ndecision-making.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.01887v3",
    "published_date": "2024-07-02 02:18:14 UTC",
    "updated_date": "2025-01-02 13:49:59 UTC"
  },
  {
    "arxiv_id": "2407.01886v1",
    "title": "Core Knowledge Learning Framework for Graph Adaptation and Scalability Learning",
    "authors": [
      "Bowen Zhang",
      "Zhichao Huang",
      "Genan Dai",
      "Guangning Xu",
      "Xiaomao Fan",
      "Hu Huang"
    ],
    "abstract": "Graph classification is a pivotal challenge in machine learning, especially\nwithin the realm of graph-based data, given its importance in numerous\nreal-world applications such as social network analysis, recommendation\nsystems, and bioinformatics. Despite its significance, graph classification\nfaces several hurdles, including adapting to diverse prediction tasks, training\nacross multiple target domains, and handling small-sample prediction scenarios.\nCurrent methods often tackle these challenges individually, leading to\nfragmented solutions that lack a holistic approach to the overarching problem.\nIn this paper, we propose an algorithm aimed at addressing the aforementioned\nchallenges. By incorporating insights from various types of tasks, our method\naims to enhance adaptability, scalability, and generalizability in graph\nclassification. Motivated by the recognition that the underlying subgraph plays\na crucial role in GNN prediction, while the remainder is task-irrelevant, we\nintroduce the Core Knowledge Learning (\\method{}) framework for graph\nadaptation and scalability learning. \\method{} comprises several key modules,\nincluding the core subgraph knowledge submodule, graph domain adaptation\nmodule, and few-shot learning module for downstream tasks. Each module is\ntailored to tackle specific challenges in graph classification, such as domain\nshift, label inconsistencies, and data scarcity. By learning the core subgraph\nof the entire graph, we focus on the most pertinent features for task\nrelevance. Consequently, our method offers benefits such as improved model\nperformance, increased domain adaptability, and enhanced robustness to domain\nvariations. Experimental results demonstrate significant performance\nenhancements achieved by our method compared to state-of-the-art approaches.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.01886v1",
    "published_date": "2024-07-02 02:16:43 UTC",
    "updated_date": "2024-07-02 02:16:43 UTC"
  },
  {
    "arxiv_id": "2407.01885v1",
    "title": "Survey on Knowledge Distillation for Large Language Models: Methods, Evaluation, and Application",
    "authors": [
      "Chuanpeng Yang",
      "Wang Lu",
      "Yao Zhu",
      "Yidong Wang",
      "Qian Chen",
      "Chenlong Gao",
      "Bingjie Yan",
      "Yiqiang Chen"
    ],
    "abstract": "Large Language Models (LLMs) have showcased exceptional capabilities in\nvarious domains, attracting significant interest from both academia and\nindustry. Despite their impressive performance, the substantial size and\ncomputational demands of LLMs pose considerable challenges for practical\ndeployment, particularly in environments with limited resources. The endeavor\nto compress language models while maintaining their accuracy has become a focal\npoint of research. Among the various methods, knowledge distillation has\nemerged as an effective technique to enhance inference speed without greatly\ncompromising performance. This paper presents a thorough survey from three\naspects: method, evaluation, and application, exploring knowledge distillation\ntechniques tailored specifically for LLMs. Specifically, we divide the methods\ninto white-box KD and black-box KD to better illustrate their differences.\nFurthermore, we also explored the evaluation tasks and distillation effects\nbetween different distillation methods, and proposed directions for future\nresearch. Through in-depth understanding of the latest advancements and\npractical applications, this survey provides valuable resources for\nresearchers, paving the way for sustained progress in this field.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "28 pages",
    "pdf_url": "http://arxiv.org/pdf/2407.01885v1",
    "published_date": "2024-07-02 02:14:42 UTC",
    "updated_date": "2024-07-02 02:14:42 UTC"
  },
  {
    "arxiv_id": "2407.02540v1",
    "title": "Analytical Solution of a Three-layer Network with a Matrix Exponential Activation Function",
    "authors": [
      "Kuo Gai",
      "Shihua Zhang"
    ],
    "abstract": "In practice, deeper networks tend to be more powerful than shallow ones, but\nthis has not been understood theoretically. In this paper, we find the\nanalytical solution of a three-layer network with a matrix exponential\nactivation function, i.e., $$ f(X)=W_3\\exp(W_2\\exp(W_1X)), X\\in\n\\mathbb{C}^{d\\times d} $$ have analytical solutions for the equations $$\n  Y_1=f(X_1),Y_2=f(X_2) $$ for $X_1,X_2,Y_1,Y_2$ with only invertible\nassumptions. Our proof shows the power of depth and the use of a non-linear\nactivation function, since one layer network can only solve one\nequation,i.e.,$Y=WX$.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "8 pages,1 figure",
    "pdf_url": "http://arxiv.org/pdf/2407.02540v1",
    "published_date": "2024-07-02 01:59:34 UTC",
    "updated_date": "2024-07-02 01:59:34 UTC"
  },
  {
    "arxiv_id": "2407.01875v1",
    "title": "Spatio-Temporal Graphical Counterfactuals: An Overview",
    "authors": [
      "Mingyu Kang",
      "Duxin Chen",
      "Ziyuan Pu",
      "Jianxi Gao",
      "Wenwu Yu"
    ],
    "abstract": "Counterfactual thinking is a critical yet challenging topic for artificial\nintelligence to learn knowledge from data and ultimately improve their\nperformances for new scenarios. Many research works, including Potential\nOutcome Model and Structural Causal Model, have been proposed to realize it.\nHowever, their modelings, theoretical foundations and application approaches\nare usually different. Moreover, there is a lack of graphical approach to infer\nspatio-temporal counterfactuals, that considers spatial and temporal\ninteractions between multiple units. Thus, in this work, our aim is to\ninvestigate a survey to compare and discuss different counterfactual models,\ntheories and approaches, and further build a unified graphical causal\nframeworks to infer the spatio-temporal counterfactuals.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.01875v1",
    "published_date": "2024-07-02 01:34:13 UTC",
    "updated_date": "2024-07-02 01:34:13 UTC"
  },
  {
    "arxiv_id": "2407.01873v1",
    "title": "Automated Text Scoring in the Age of Generative AI for the GPU-poor",
    "authors": [
      "Christopher Michael Ormerod",
      "Alexander Kwako"
    ],
    "abstract": "Current research on generative language models (GLMs) for automated text\nscoring (ATS) has focused almost exclusively on querying proprietary models via\nApplication Programming Interfaces (APIs). Yet such practices raise issues\naround transparency and security, and these methods offer little in the way of\nefficiency or customizability. With the recent proliferation of smaller,\nopen-source models, there is the option to explore GLMs with computers equipped\nwith modest, consumer-grade hardware, that is, for the \"GPU poor.\" In this\nstudy, we analyze the performance and efficiency of open-source, small-scale\nGLMs for ATS. Results show that GLMs can be fine-tuned to achieve adequate,\nthough not state-of-the-art, performance. In addition to ATS, we take small\nsteps towards analyzing models' capacity for generating feedback by prompting\nGLMs to explain their scores. Model-generated feedback shows promise, but\nrequires more rigorous evaluation focused on targeted use cases.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "21 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2407.01873v1",
    "published_date": "2024-07-02 01:17:01 UTC",
    "updated_date": "2024-07-02 01:17:01 UTC"
  },
  {
    "arxiv_id": "2407.02539v3",
    "title": "Research on Autonomous Robots Navigation based on Reinforcement Learning",
    "authors": [
      "Zixiang Wang",
      "Hao Yan",
      "Yining Wang",
      "Zhengjia Xu",
      "Zhuoyue Wang",
      "Zhizhong Wu"
    ],
    "abstract": "Reinforcement learning continuously optimizes decision-making based on\nreal-time feedback reward signals through continuous interaction with the\nenvironment, demonstrating strong adaptive and self-learning capabilities. In\nrecent years, it has become one of the key methods to achieve autonomous\nnavigation of robots. In this work, an autonomous robot navigation method based\non reinforcement learning is introduced. We use the Deep Q Network (DQN) and\nProximal Policy Optimization (PPO) models to optimize the path planning and\ndecision-making process through the continuous interaction between the robot\nand the environment, and the reward signals with real-time feedback. By\ncombining the Q-value function with the deep neural network, deep Q network can\nhandle high-dimensional state space, so as to realize path planning in complex\nenvironments. Proximal policy optimization is a strategy gradient-based method,\nwhich enables robots to explore and utilize environmental information more\nefficiently by optimizing policy functions. These methods not only improve the\nrobot's navigation ability in the unknown environment, but also enhance its\nadaptive and self-learning capabilities. Through multiple training and\nsimulation experiments, we have verified the effectiveness and robustness of\nthese models in various complex scenarios.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.02539v3",
    "published_date": "2024-07-02 00:44:06 UTC",
    "updated_date": "2024-08-14 04:49:22 UTC"
  },
  {
    "arxiv_id": "2407.01864v2",
    "title": "Research on target detection method of distracted driving behavior based on improved YOLOv8",
    "authors": [
      "Shiquan Shen",
      "Zhizhong Wu",
      "Pan Zhang"
    ],
    "abstract": "With the development of deep learning technology, the detection and\nclassification of distracted driving behaviour requires higher accuracy.\nExisting deep learning-based methods are computationally intensive and\nparameter redundant, limiting the efficiency and accuracy in practical\napplications. To solve this problem, this study proposes an improved YOLOv8\ndetection method based on the original YOLOv8 model by integrating the BoTNet\nmodule, GAM attention mechanism and EIoU loss function. By optimising the\nfeature extraction and multi-scale feature fusion strategies, the training and\ninference processes are simplified, and the detection accuracy and efficiency\nare significantly improved. Experimental results show that the improved model\nperforms well in both detection speed and accuracy, with an accuracy rate of\n99.4%, and the model is smaller and easy to deploy, which is able to identify\nand classify distracted driving behaviours in real time, provide timely\nwarnings, and enhance driving safety.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Major revision on content, no replacement available soon",
    "pdf_url": "http://arxiv.org/pdf/2407.01864v2",
    "published_date": "2024-07-02 00:43:41 UTC",
    "updated_date": "2024-07-05 17:17:48 UTC"
  }
]