{
  "date": "2025-05-06",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-05-06 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文更新主要聚焦于 AI 模型优化、多模态理解和应用，尤其是大型语言模型（LLMs）在医疗、机器人决策和生成任务中的创新进展，亮点包括高效 GPU 共享系统（如 Prism）和多模态对话 AI（如 AMIE），以及著名学者如 Ion Stoica 和 Xue Bin Peng 的贡献，这些工作突显了 AI 在实际场景中的潜力。\n\n### 重点论文讨论\n我们挑选了最具话题度和影响力的论文优先讨论，并将相关主题归类。以下聚焦于 LLM 优化、视觉多模态和机器人领域，其他较基础的论文（如某些算法优化或小数据集实验）将快速掠过。\n\n**LLM 和生成模型优化**  \n- **Prism: Unleashing GPU Sharing for Cost-Efficient Multi-LLM Serving（Prism: 释放 GPU 共享以实现多 LLM 服务的成本高效）**  \n  作者包括 Ion Stoica，这篇论文提出 Prism 系统，通过动态内存协调和两级调度策略，实现多 LLM 服务的成本节约（超过 2 倍）和延迟目标达成（3.3 倍提升），核心贡献在于解决 GPU 共享的实时适应性问题。\n  \n- **SLOT: Structuring the Output of Large Language Models（SLOT: 结构化大型语言模型的输出）**  \n  这篇工作引入 SLOT 方法，使用轻量级模型后处理 LLM 输出，实现高达 99.5% 的模式准确性和 94.0% 的内容相似度，显著优于现有技术，适用于信息提取等关键应用。\n\n- **X-Reasoner: Towards Generalizable Reasoning Across Modalities and Domains（X-Reasoner: 实现跨模态和领域的泛化推理）**  \n  作者包括 Hoifung Poon，该论文通过文本后训练提升模型在多模态和医疗领域的推理能力，X-Reasoner 在各种基准上超越同类模型，核心在于两阶段训练策略的泛化优势。\n\n- **RAVU: Retrieval Augmented Video Understanding with Compositional Reasoning over Graph（RAVU: 通过图上的组合推理增强检索辅助视频理解）**  \n  这篇论文提出 RAVU 框架，使用图表示和检索机制处理长视频查询，实现高效的多跳推理，显著提升视频问答任务的准确性。\n\n**视觉和多模态应用**  \n- **Advancing Conversational Diagnostic AI with Multimodal Reasoning（使用多模态推理推进对话式诊断 AI）**  \n  作者包括 Pushmeet Kohli 和 Vivek Natarajan，这篇工作扩展 AMIE 系统，支持多模态数据处理，在随机测试中优于人类医生，核心发现是多模态历史采集提升诊断准确性和沟通能力。\n\n- **Tri-MTL: A Triple Multitask Learning Approach for Respiratory Disease Diagnosis（Tri-MTL: 呼吸系统疾病诊断的三任务学习方法）**  \n  这篇论文开发 Tri-MTL 框架，结合元数据和多任务学习，提高呼吸声分类和诊断性能，F1 分数显著提升，适用于医疗音频分析。\n\n- **DocSpiral: A Platform for Integrated Assistive Document Annotation through Human-in-the-Spiral（DocSpiral: 通过人类参与的螺旋式平台集成辅助文档标注）**  \n  该工作提出 DocSpiral 系统，使用迭代标注和 AI 模型减少文档处理时间（至少 41%），核心在于人类-AI 协作的实用框架。\n\n**机器人和强化学习**  \n- **PARC: Physics-based Augmentation with Reinforcement Learning for Character Controllers（PARC: 使用强化学习的物理增强用于角色控制器）**  \n  作者包括 Xue Bin Peng，这篇论文引入 PARC 框架，通过迭代数据增强和物理模拟扩展控制器能力，显著提升复杂地形遍历的敏捷性。\n\n- **StableMotion: Training Motion Cleanup Models with Unpaired Corrupted Data（StableMotion: 使用非配对损坏数据训练运动清理模型）**  \n  这篇工作提出 StableMotion 方法，使用质量指标训练生成模型，减少足球 mocap 数据中的运动伪影（68% 和 81% 的减少），核心在于无监督修复的鲁棒性。\n\n其他论文，如一些基础算法优化（例如 GRAML 或 Diffusion Models）或特定领域应用（例如 Terahertz 通道建模），虽有贡献但不具突破性，故快速掠过：它们主要改进特定任务的效率或准确性，但未引入重大创新。\n\n总之，今天的更新强调 AI 模型的实用性和鲁棒性，相关工作为医疗和机器人领域提供了高效工具，建议关注 LLM 优化和多模态推理方向。更多细节可查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2505.04021v2",
      "title": "Prism: Unleashing GPU Sharing for Cost-Efficient Multi-LLM Serving",
      "title_zh": "翻译失败",
      "authors": [
        "Shan Yu",
        "Jiarong Xing",
        "Yifan Qiao",
        "Mingyuan Ma",
        "Yangmin Li",
        "Yang Wang",
        "Shuo Yang",
        "Zhiqiang Xie",
        "Shiyi Cao",
        "Ke Bao",
        "Ion Stoica",
        "Harry Xu",
        "Ying Sheng"
      ],
      "abstract": "Serving large language models (LLMs) is expensive, especially for providers\nhosting many models, making cost reduction essential. The unique workload\npatterns of serving multiple LLMs (i.e., multi-LLM serving) create new\nopportunities and challenges for this task. The long-tail popularity of models\nand their long idle periods present opportunities to improve utilization\nthrough GPU sharing. However, existing GPU sharing systems lack the ability to\nadjust their resource allocation and sharing policies at runtime, making them\nineffective at meeting latency service-level objectives (SLOs) under rapidly\nfluctuating workloads.\n  This paper presents Prism, a multi-LLM serving system that unleashes the full\npotential of GPU sharing to achieve both cost efficiency and SLO attainment. At\nits core, Prism tackles a key limitation of existing\nsystems$\\unicode{x2014}$the lack of $\\textit{cross-model memory coordination}$,\nwhich is essential for flexibly sharing GPU memory across models under dynamic\nworkloads. Prism achieves this with two key designs. First, it supports\non-demand memory allocation by dynamically mapping physical to virtual memory\npages, allowing flexible memory redistribution among models that space- and\ntime-share a GPU. Second, it improves memory efficiency through a two-level\nscheduling policy that dynamically adjusts sharing strategies based on models'\nruntime demands. Evaluations on real-world traces show that Prism achieves more\nthan $2\\times$ cost savings and $3.3\\times$ SLO attainment compared to\nstate-of-the-art systems.",
      "tldr_zh": "该论文提出Prism，一种针对多大型语言模型(LLMs)服务的系统，通过优化GPU sharing实现成本效率和延迟服务水平目标(SLOs)的平衡。Prism的核心创新包括跨模型内存协调机制，支持按需内存分配（动态映射物理到虚拟内存页面）和两级调度策略，根据模型的运行时需求调整共享策略，以应对动态工作负载。实验结果显示，在真实追踪数据上，Prism相较于现有系统节省超过2倍成本，并提升3.3倍的SLO达成率。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG",
        "cs.PF"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04021v2",
      "published_date": "2025-05-06 23:38:33 UTC",
      "updated_date": "2025-05-12 18:19:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:01:29.612961"
    },
    {
      "arxiv_id": "2505.04019v1",
      "title": "Extending Decision Predicate Graphs for Comprehensive Explanation of Isolation Forest",
      "title_zh": "扩展决策谓词图以全面解释隔离森林",
      "authors": [
        "Matteo Ceschin",
        "Leonardo Arrighi",
        "Luca Longo",
        "Sylvio Barbon Junior"
      ],
      "abstract": "The need to explain predictive models is well-established in modern machine\nlearning. However, beyond model interpretability, understanding pre-processing\nmethods is equally essential. Understanding how data modifications impact model\nperformance improvements and potential biases and promoting a reliable pipeline\nis mandatory for developing robust machine learning solutions. Isolation Forest\n(iForest) is a widely used technique for outlier detection that performs well.\nIts effectiveness increases with the number of tree-based learners. However,\nthis also complicates the explanation of outlier selection and the decision\nboundaries for inliers. This research introduces a novel Explainable AI (XAI)\nmethod, tackling the problem of global explainability. In detail, it aims to\noffer a global explanation for outlier detection to address its opaque nature.\nOur approach is based on the Decision Predicate Graph (DPG), which clarifies\nthe logic of ensemble methods and provides both insights and a graph-based\nmetric to explain how samples are identified as outliers using the proposed\nInlier-Outlier Propagation Score (IOP-Score). Our proposal enhances iForest's\nexplainability and provides a comprehensive view of the decision-making\nprocess, detailing which features contribute to outlier identification and how\nthe model utilizes them. This method advances the state-of-the-art by providing\ninsights into decision boundaries and a comprehensive view of holistic feature\nusage in outlier identification. -- thus promoting a fully explainable machine\nlearning pipeline.",
      "tldr_zh": "这篇论文扩展了 Decision Predicate Graph (DPG) 来全面解释 Isolation Forest (iForest)，针对其在异常检测中的决策过程不透明问题，提供全局可解释性。研究提出了一种新型 Explainable AI (XAI) 方法，通过 DPG 澄清集成方法的逻辑，并引入 Inlier-Outlier Propagation Score (IOP-Score) 来量化样本如何被识别为异常，以及哪些特征在决策中发挥作用。最终，这提升了 iForest 的解释能力，提供对决策边界和整体特征使用的全面洞见，从而促进可靠的机器学习管道开发。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04019v1",
      "published_date": "2025-05-06 23:32:16 UTC",
      "updated_date": "2025-05-06 23:32:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:01:42.682740"
    },
    {
      "arxiv_id": "2505.04016v1",
      "title": "SLOT: Structuring the Output of Large Language Models",
      "title_zh": "SLOT: 结构化大型语言模型的输出",
      "authors": [
        "Darren Yow-Bang Wang",
        "Zhengyuan Shen",
        "Soumya Smruti Mishra",
        "Zhichao Xu",
        "Yifei Teng",
        "Haibo Ding"
      ],
      "abstract": "Structured outputs are essential for large language models (LLMs) in critical\napplications like agents and information extraction. Despite their\ncapabilities, LLMs often generate outputs that deviate from predefined schemas,\nsignificantly hampering reliable application development. We present SLOT\n(Structured LLM Output Transformer), a model-agnostic approach that transforms\nunstructured LLM outputs into precise structured formats. While existing\nsolutions predominantly rely on constrained decoding techniques or are tightly\ncoupled with specific models, SLOT employs a fine-tuned lightweight language\nmodel as a post-processing layer, achieving flexibility across various LLMs and\nschema specifications. We introduce a systematic pipeline for data curation and\nsynthesis alongside a formal evaluation methodology that quantifies both schema\naccuracy and content fidelity. Our results demonstrate that fine-tuned\nMistral-7B model with constrained decoding achieves near perfect schema\naccuracy (99.5%) and content similarity (94.0%), outperforming\nClaude-3.5-Sonnet by substantial margins (+25 and +20 percentage points,\nrespectively). Notably, even compact models like Llama-3.2-1B can match or\nexceed the structured output capabilities of much larger proprietary models\nwhen equipped with SLOT, enabling reliable structured generation in\nresource-constrained environments.",
      "tldr_zh": "这篇论文介绍了SLOT（Structured LLM Output Transformer），一种模型无关的方法，用于将大型语言模型(LLM)的非结构化输出转化为精确的结构化格式，解决LLM在关键应用（如代理和信息提取）中偏离预定义模式的难题。SLOT采用微调的轻量级语言模型作为后处理层，并结合系统化的数据整理管道和正式评估方法，来量化模式准确性和内容保真度。实验结果显示，微调的Mistral-7B模型实现了99.5%的模式准确性和94.0%的内容相似性，比Claude-3.5-Sonnet高出25和20个百分点；此外，即使是小型模型如Llama-3.2-1B，使用SLOT后也能匹敌大型专有模型，在资源受限环境中实现可靠的结构化生成。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04016v1",
      "published_date": "2025-05-06 23:29:43 UTC",
      "updated_date": "2025-05-06 23:29:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:01:54.482685"
    },
    {
      "arxiv_id": "2505.04015v1",
      "title": "MergeGuard: Efficient Thwarting of Trojan Attacks in Machine Learning Models",
      "title_zh": "翻译失败",
      "authors": [
        "Soheil Zibakhsh Shabgahi",
        "Yaman Jandali",
        "Farinaz Koushanfar"
      ],
      "abstract": "This paper proposes MergeGuard, a novel methodology for mitigation of AI\nTrojan attacks. Trojan attacks on AI models cause inputs embedded with triggers\nto be misclassified to an adversary's target class, posing a significant threat\nto model usability trained by an untrusted third party. The core of MergeGuard\nis a new post-training methodology for linearizing and merging fully connected\nlayers which we show simultaneously improves model generalizability and\nperformance. Our Proof of Concept evaluation on Transformer models demonstrates\nthat MergeGuard maintains model accuracy while decreasing trojan attack success\nrate, outperforming commonly used (post-training) Trojan mitigation by\nfine-tuning methodologies.",
      "tldr_zh": "这篇论文提出了MergeGuard，一种高效的方法，用于缓解AI模型中的Trojan Attacks。MergeGuard的核心是新的后训练方法，通过线性化和合并全连接层，同时提升模型的泛化性和性能。实验结果显示，在Transformer Models上的评估中，该方法保持了模型准确性，同时显著降低了Trojan Attacks的成功率，并优于传统的后训练微调方法。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04015v1",
      "published_date": "2025-05-06 23:26:25 UTC",
      "updated_date": "2025-05-06 23:26:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:02:04.269532"
    },
    {
      "arxiv_id": "2505.04002v1",
      "title": "PARC: Physics-based Augmentation with Reinforcement Learning for Character Controllers",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Xu",
        "Yi Shi",
        "KangKang Yin",
        "Xue Bin Peng"
      ],
      "abstract": "Humans excel in navigating diverse, complex environments with agile motor\nskills, exemplified by parkour practitioners performing dynamic maneuvers, such\nas climbing up walls and jumping across gaps. Reproducing these agile movements\nwith simulated characters remains challenging, in part due to the scarcity of\nmotion capture data for agile terrain traversal behaviors and the high cost of\nacquiring such data. In this work, we introduce PARC (Physics-based\nAugmentation with Reinforcement Learning for Character Controllers), a\nframework that leverages machine learning and physics-based simulation to\niteratively augment motion datasets and expand the capabilities of terrain\ntraversal controllers. PARC begins by training a motion generator on a small\ndataset consisting of core terrain traversal skills. The motion generator is\nthen used to produce synthetic data for traversing new terrains. However, these\ngenerated motions often exhibit artifacts, such as incorrect contacts or\ndiscontinuities. To correct these artifacts, we train a physics-based tracking\ncontroller to imitate the motions in simulation. The corrected motions are then\nadded to the dataset, which is used to continue training the motion generator\nin the next iteration. PARC's iterative process jointly expands the\ncapabilities of the motion generator and tracker, creating agile and versatile\nmodels for interacting with complex environments. PARC provides an effective\napproach to develop controllers for agile terrain traversal, which bridges the\ngap between the scarcity of motion data and the need for versatile character\ncontrollers.",
      "tldr_zh": "该研究提出PARC框架，利用强化学习(Reinforcement Learning)和物理模拟，针对模拟字符在复杂地形中的敏捷运动问题进行数据增强。\nPARC从小型数据集训练运动生成器，生成合成数据后，通过物理跟踪控制器修正如接触错误或不连续性的问题，并迭代更新数据集以提升生成器和控制器的能力。\n结果显示，该框架有效扩展了字符控制器的功能，桥接了运动数据稀缺的挑战，为开发敏捷地形穿越模型提供了实用方法。",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.GR",
      "comment": "SIGGRAPH Conference Papers 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.04002v1",
      "published_date": "2025-05-06 22:29:07 UTC",
      "updated_date": "2025-05-06 22:29:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:02:17.444133"
    },
    {
      "arxiv_id": "2505.03989v2",
      "title": "An alignment safety case sketch based on debate",
      "title_zh": "基于辩论的对齐安全案例草图",
      "authors": [
        "Marie Davidsen Buhl",
        "Jacob Pfau",
        "Benjamin Hilton",
        "Geoffrey Irving"
      ],
      "abstract": "If AI systems match or exceed human capabilities on a wide range of tasks, it\nmay become difficult for humans to efficiently judge their actions -- making it\nhard to use human feedback to steer them towards desirable traits. One proposed\nsolution is to leverage another superhuman system to point out flaws in the\nsystem's outputs via a debate. This paper outlines the value of debate for AI\nsafety, as well as the assumptions and further research required to make debate\nwork. It does so by sketching an ``alignment safety case'' -- an argument that\nan AI system will not autonomously take actions which could lead to egregious\nharm, despite being able to do so. The sketch focuses on the risk of an AI R\\&D\nagent inside an AI company sabotaging research, for example by producing false\nresults. To prevent this, the agent is trained via debate, subject to\nexploration guarantees, to teach the system to be honest. Honesty is maintained\nthroughout deployment via online training. The safety case rests on four key\nclaims: (1) the agent has become good at the debate game, (2) good performance\nin the debate game implies that the system is mostly honest, (3) the system\nwill not become significantly less honest during deployment, and (4) the\ndeployment context is tolerant of some errors. We identify open research\nproblems that, if solved, could render this a compelling argument that an AI\nsystem is safe.",
      "tldr_zh": "这篇论文提出了一个基于辩论(debate)的“alignment safety case”框架，以确保超人类能力的AI系统不会自主采取导致严重危害的行动。该框架针对AI R&D代理（如在AI公司中破坏研究）的风险，通过辩论游戏训练代理来培养其诚实(honesty)，并结合exploration guarantees和在线训练来维持这一特性。安全案例依赖于四个关键声明：代理在辩论游戏中表现良好、良好表现意味着系统mostly honest、系统在部署中不会显著降低诚实度，以及部署环境能容忍一些错误。最后，论文指出了需要解决的开放研究问题，以使这一安全论证更具说服力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03989v2",
      "published_date": "2025-05-06 21:53:44 UTC",
      "updated_date": "2025-05-08 16:52:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:02:29.943251"
    },
    {
      "arxiv_id": "2505.03988v1",
      "title": "Can Large Language Models Predict Parallel Code Performance?",
      "title_zh": "大语言模型能够预测并行代码的性能吗？",
      "authors": [
        "Gregory Bolet",
        "Giorgis Georgakoudis",
        "Harshitha Menon",
        "Konstantinos Parasyris",
        "Niranjan Hasabnis",
        "Hayden Estes",
        "Kirk W. Cameron",
        "Gal Oren"
      ],
      "abstract": "Accurate determination of the performance of parallel GPU code typically\nrequires execution-time profiling on target hardware -- an increasingly\nprohibitive step due to limited access to high-end GPUs. This paper explores\nwhether Large Language Models (LLMs) can offer an alternative approach for GPU\nperformance prediction without relying on hardware. We frame the problem as a\nroofline classification task: given the source code of a GPU kernel and the\nhardware specifications of a target GPU, can an LLM predict whether the GPU\nkernel is compute-bound or bandwidth-bound?\n  For this study, we build a balanced dataset of 340 GPU kernels, obtained from\nHeCBench benchmark and written in CUDA and OpenMP, along with their\nground-truth labels obtained via empirical GPU profiling. We evaluate LLMs\nacross four scenarios: (1) with access to profiling data of the kernel source,\n(2) zero-shot with source code only, (3) few-shot with code and label pairs,\nand (4) fine-tuned on a small custom dataset.\n  Our results show that state-of-the-art LLMs have a strong understanding of\nthe Roofline model, achieving 100% classification accuracy when provided with\nexplicit profiling data. We also find that reasoning-capable LLMs significantly\noutperform standard LLMs in zero- and few-shot settings, achieving up to 64%\naccuracy on GPU source codes, without profiling information. Lastly, we find\nthat LLM fine-tuning will require much more data than what we currently have\navailable.\n  This work is among the first to use LLMs for source-level roofline\nperformance prediction via classification, and illustrates their potential to\nguide optimization efforts when runtime profiling is infeasible. Our findings\nsuggest that with better datasets and prompt strategies, LLMs could become\npractical tools for HPC performance analysis and performance portability.",
      "tldr_zh": "本研究探讨了Large Language Models (LLMs)是否能预测并行GPU代码性能，而无需实际硬件执行，从而解决高性能GPU访问受限的问题。研究将任务框架为roofline分类，构建了一个包含340个CUDA和OpenMP GPU内核的平衡数据集，并评估LLMs在四种场景下的表现：提供分析数据、zero-shot仅用源代码、few-shot用代码和标签对，以及在小自定义数据集上fine-tuned。结果显示，LLMs在有显式分析数据时达到100%分类准确率，在zero-shot和few-shot设置中，具备推理能力的模型最高可达64%准确率，但fine-tuning需要更多数据。该工作首次证明LLMs在源代码级roofline性能预测中的潜力，有望成为HPC性能分析的实用工具。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.PF"
      ],
      "primary_category": "cs.DC",
      "comment": "5 pages, 4 figures, accepted to AI4Sys Workshop at HPDC 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.03988v1",
      "published_date": "2025-05-06 21:41:20 UTC",
      "updated_date": "2025-05-06 21:41:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:02:42.831536"
    },
    {
      "arxiv_id": "2505.09640v1",
      "title": "Feature Relevancy, Necessity and Usefulness: Complexity and Algorithms",
      "title_zh": "翻译失败",
      "authors": [
        "Tomás Capdevielle",
        "Santiago Cifuentes"
      ],
      "abstract": "Given a classification model and a prediction for some input, there are\nheuristic strategies for ranking features according to their importance in\nregard to the prediction. One common approach to this task is rooted in\npropositional logic and the notion of \\textit{sufficient reason}. Through this\nconcept, the categories of relevant and necessary features were proposed in\norder to identify the crucial aspects of the input. This paper improves the\nexisting techniques and algorithms for deciding which are the relevant and/or\nnecessary features, showing in particular that necessity can be detected\nefficiently in complex models such as neural networks. We also generalize the\nnotion of relevancy and study associated problems. Moreover, we present a new\nglobal notion (i.e. that intends to explain whether a feature is important for\nthe behavior of the model in general, not depending on a particular input) of\n\\textit{usefulness} and prove that it is related to relevancy and necessity.\nFurthermore, we develop efficient algorithms for detecting it in decision trees\nand other more complex models, and experiment on three datasets to analyze its\npractical utility.",
      "tldr_zh": "这篇论文基于命题逻辑的 sufficient reason 概念，改进了检测分类模型中特征的 relevant features 和 necessary features 的算法，并展示了这些算法在神经网络等复杂模型中可高效实现。论文进一步泛化了 relevancy 的定义，引入了新的全局概念 usefulness，以评估特征在模型整体行为中的重要性，并证明了它与 relevancy 和 necessity 的关系。作者开发了针对 decision trees 和其他复杂模型的检测算法，并在三个数据集上进行实验，验证了 usefulness 的实用性。",
      "categories": [
        "cs.AI",
        "68T01",
        "I.2.0"
      ],
      "primary_category": "cs.AI",
      "comment": "22 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.09640v1",
      "published_date": "2025-05-06 21:41:07 UTC",
      "updated_date": "2025-05-06 21:41:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:02:54.224665"
    },
    {
      "arxiv_id": "2505.03985v1",
      "title": "LogiDebrief: A Signal-Temporal Logic based Automated Debriefing Approach with Large Language Models Integration",
      "title_zh": "翻译失败",
      "authors": [
        "Zirong Chen",
        "Ziyan An",
        "Jennifer Reynolds",
        "Kristin Mullen",
        "Stephen Martini",
        "Meiyi Ma"
      ],
      "abstract": "Emergency response services are critical to public safety, with 9-1-1\ncall-takers playing a key role in ensuring timely and effective emergency\noperations. To ensure call-taking performance consistency, quality assurance is\nimplemented to evaluate and refine call-takers' skillsets. However, traditional\nhuman-led evaluations struggle with high call volumes, leading to low coverage\nand delayed assessments. We introduce LogiDebrief, an AI-driven framework that\nautomates traditional 9-1-1 call debriefing by integrating Signal-Temporal\nLogic (STL) with Large Language Models (LLMs) for fully-covered rigorous\nperformance evaluation. LogiDebrief formalizes call-taking requirements as\nlogical specifications, enabling systematic assessment of 9-1-1 calls against\nprocedural guidelines. It employs a three-step verification process: (1)\ncontextual understanding to identify responder types, incident classifications,\nand critical conditions; (2) STL-based runtime checking with LLM integration to\nensure compliance; and (3) automated aggregation of results into quality\nassurance reports. Beyond its technical contributions, LogiDebrief has\ndemonstrated real-world impact. Successfully deployed at Metro Nashville\nDepartment of Emergency Communications, it has assisted in debriefing 1,701\nreal-world calls, saving 311.85 hours of active engagement. Empirical\nevaluation with real-world data confirms its accuracy, while a case study and\nextensive user study highlight its effectiveness in enhancing call-taking\nperformance.",
      "tldr_zh": "该论文提出 LogiDebrief，一种基于 Signal-Temporal Logic (STL) 和 Large Language Models (LLMs) 的 AI 驱动框架，用于自动化 9-1-1 紧急通话评估，解决传统人工评估面临的高通话量、低覆盖和延迟问题。框架采用三步验证过程：包括上下文理解以识别响应者类型和关键条件、STL 结合 LLM 的运行时检查确保遵守程序指南，以及自动生成质量保证报告。实证结果显示，该系统在 Metro Nashville 的实际部署中处理了 1,701 个真实通话，节省了 311.85 小时，并通过用户研究证实了其准确性和对通话性能的提升。",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at IJCAI-2025",
      "pdf_url": "http://arxiv.org/pdf/2505.03985v1",
      "published_date": "2025-05-06 21:27:07 UTC",
      "updated_date": "2025-05-06 21:27:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:03:08.295187"
    },
    {
      "arxiv_id": "2505.03983v1",
      "title": "Diffusion Models are Secretly Exchangeable: Parallelizing DDPMs via Autospeculation",
      "title_zh": "翻译失败",
      "authors": [
        "Hengyuan Hu",
        "Aniket Das",
        "Dorsa Sadigh",
        "Nima Anari"
      ],
      "abstract": "Denoising Diffusion Probabilistic Models (DDPMs) have emerged as powerful\ntools for generative modeling. However, their sequential computation\nrequirements lead to significant inference-time bottlenecks. In this work, we\nutilize the connection between DDPMs and Stochastic Localization to prove that,\nunder an appropriate reparametrization, the increments of DDPM satisfy an\nexchangeability property. This general insight enables near-black-box\nadaptation of various performance optimization techniques from autoregressive\nmodels to the diffusion setting. To demonstrate this, we introduce\n\\emph{Autospeculative Decoding} (ASD), an extension of the widely used\nspeculative decoding algorithm to DDPMs that does not require any auxiliary\ndraft models. Our theoretical analysis shows that ASD achieves a $\\tilde{O}\n(K^{\\frac{1}{3}})$ parallel runtime speedup over the $K$ step sequential DDPM.\nWe also demonstrate that a practical implementation of autospeculative decoding\naccelerates DDPM inference significantly in various domains.",
      "tldr_zh": "该研究揭示了去噪扩散概率模型(DDPMs)在其增量满足可交换性(exchangeability)属性时，可以通过适当的重新参数化来并行化，从而缓解其顺序计算的推断瓶颈。论文引入了Autospeculative Decoding (ASD)，这是一种无需辅助模型的speculative decoding扩展，将自回归模型的优化技术应用于扩散模型。理论分析显示，ASD 实现了约O(K^{1/3})的并行运行时加速，而实际实现已在各种领域显著提升 DDPMs 的推断效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03983v1",
      "published_date": "2025-05-06 21:10:37 UTC",
      "updated_date": "2025-05-06 21:10:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:03:17.015362"
    },
    {
      "arxiv_id": "2505.03981v1",
      "title": "X-Reasoner: Towards Generalizable Reasoning Across Modalities and Domains",
      "title_zh": "X-Reasoner：面向跨模态和跨领域泛化推理",
      "authors": [
        "Qianchu Liu",
        "Sheng Zhang",
        "Guanghui Qin",
        "Timothy Ossowski",
        "Yu Gu",
        "Ying Jin",
        "Sid Kiblawi",
        "Sam Preston",
        "Mu Wei",
        "Paul Vozila",
        "Tristan Naumann",
        "Hoifung Poon"
      ],
      "abstract": "Recent proprietary models (e.g., o3) have begun to demonstrate strong\nmultimodal reasoning capabilities. Yet, most existing open-source research\nconcentrates on training text-only reasoning models, with evaluations limited\nto mainly mathematical and general-domain tasks. Therefore, it remains unclear\nhow to effectively extend reasoning capabilities beyond text input and general\ndomains. This paper explores a fundamental research question: Is reasoning\ngeneralizable across modalities and domains? Our findings support an\naffirmative answer: General-domain text-based post-training can enable such\nstrong generalizable reasoning. Leveraging this finding, we introduce\nX-Reasoner, a vision-language model post-trained solely on general-domain text\nfor generalizable reasoning, using a two-stage approach: an initial supervised\nfine-tuning phase with distilled long chain-of-thoughts, followed by\nreinforcement learning with verifiable rewards. Experiments show that\nX-Reasoner successfully transfers reasoning capabilities to both multimodal and\nout-of-domain settings, outperforming existing state-of-the-art models trained\nwith in-domain and multimodal data across various general and medical\nbenchmarks (Figure 1). Additionally, we find that X-Reasoner's performance in\nspecialized domains can be further enhanced through continued training on\ndomain-specific text-only data. Building upon this, we introduce\nX-Reasoner-Med, a medical-specialized variant that achieves new state of the\nart on numerous text-only and multimodal medical benchmarks.",
      "tldr_zh": "该论文探讨了推理能力是否能跨模态和领域泛化，并通过实验证实，基于通用领域文本的后训练可以实现这一目标。研究引入了X-Reasoner，一种视觉-语言模型，仅通过两阶段方法进行后训练：首先是监督微调阶段，使用蒸馏的长chain-of-thought推理；其次是reinforcement learning阶段，以可验证奖励优化模型。实验结果显示，X-Reasoner在多模态和领域外场景中超越现有state-of-the-art模型，在各种通用和医疗基准上表现出色，即使这些模型使用了领域内和多模态数据。进一步，通过在领域特定文本-only数据上继续训练，X-Reasoner-Med变体在众多医疗基准上达到了新的state of the art。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03981v1",
      "published_date": "2025-05-06 21:08:27 UTC",
      "updated_date": "2025-05-06 21:08:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:03:31.622137"
    },
    {
      "arxiv_id": "2505.03974v1",
      "title": "Deep Learning Framework for Infrastructure Maintenance: Crack Detection and High-Resolution Imaging of Infrastructure Surfaces",
      "title_zh": "基础设施维护的深度学习框架：裂缝检测和基础设施表面的高分辨率成像",
      "authors": [
        "Nikhil M. Pawar",
        "Jorge A. Prozzi",
        "Feng Hong",
        "Surya Sarat Chandra Congress"
      ],
      "abstract": "Recently, there has been an impetus for the application of cutting-edge data\ncollection platforms such as drones mounted with camera sensors for\ninfrastructure asset management. However, the sensor characteristics, proximity\nto the structure, hard-to-reach access, and environmental conditions often\nlimit the resolution of the datasets. A few studies used super-resolution\ntechniques to address the problem of low-resolution images. Nevertheless, these\ntechniques were observed to increase computational cost and false alarms of\ndistress detection due to the consideration of all the infrastructure images\ni.e., positive and negative distress classes. In order to address the\npre-processing of false alarm and achieve efficient super-resolution, this\nstudy developed a framework consisting of convolutional neural network (CNN)\nand efficient sub-pixel convolutional neural network (ESPCNN). CNN accurately\nclassified both the classes. ESPCNN, which is the lightweight super-resolution\ntechnique, generated high-resolution infrastructure image of positive distress\nobtained from CNN. The ESPCNN outperformed bicubic interpolation in all the\nevaluation metrics for super-resolution. Based on the performance metrics, the\ncombination of CNN and ESPCNN was observed to be effective in preprocessing the\ninfrastructure images with negative distress, reducing the computational cost\nand false alarms in the next step of super-resolution. The visual inspection\nshowed that EPSCNN is able to capture crack propagation, complex geometry of\neven minor cracks. The proposed framework is expected to help the highway\nagencies in accurately performing distress detection and assist in efficient\nasset management practices.",
      "tldr_zh": "这篇论文提出了一种深度学习框架，用于基础设施维护，专注于裂缝检测和高分辨率成像，以解决无人机采集图像的分辨率低、计算成本高和误报等问题。框架结合了CNN进行准确分类正负裂缝类图像，以及ESPCNN作为轻量级超分辨率技术，仅对正裂缝图像进行处理。结果显示，ESPCNN在所有评估指标上优于bicubic interpolation，能够有效捕获裂缝传播和复杂几何细节。该框架通过减少计算成本和误报，帮助公路机构提高裂缝检测准确性和资产管理效率。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "Presented :Transportation Research Board 104th Annual Meeting,\n  Washington, D.C",
      "pdf_url": "http://arxiv.org/pdf/2505.03974v1",
      "published_date": "2025-05-06 20:52:58 UTC",
      "updated_date": "2025-05-06 20:52:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:03:41.105467"
    },
    {
      "arxiv_id": "2505.04653v1",
      "title": "Advancing Conversational Diagnostic AI with Multimodal Reasoning",
      "title_zh": "通过多模态推理推进对话式诊断AI",
      "authors": [
        "Khaled Saab",
        "Jan Freyberg",
        "Chunjong Park",
        "Tim Strother",
        "Yong Cheng",
        "Wei-Hung Weng",
        "David G. T. Barrett",
        "David Stutz",
        "Nenad Tomasev",
        "Anil Palepu",
        "Valentin Liévin",
        "Yash Sharma",
        "Roma Ruparel",
        "Abdullah Ahmed",
        "Elahe Vedadi",
        "Kimberly Kanada",
        "Cian Hughes",
        "Yun Liu",
        "Geoff Brown",
        "Yang Gao",
        "Sean Li",
        "S. Sara Mahdavi",
        "James Manyika",
        "Katherine Chou",
        "Yossi Matias",
        "Avinatan Hassidim",
        "Dale R. Webster",
        "Pushmeet Kohli",
        "S. M. Ali Eslami",
        "Joëlle Barral",
        "Adam Rodman",
        "Vivek Natarajan",
        "Mike Schaekermann",
        "Tao Tu",
        "Alan Karthikesalingam",
        "Ryutaro Tanno"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated great potential for conducting\ndiagnostic conversations but evaluation has been largely limited to\nlanguage-only interactions, deviating from the real-world requirements of\nremote care delivery. Instant messaging platforms permit clinicians and\npatients to upload and discuss multimodal medical artifacts seamlessly in\nmedical consultation, but the ability of LLMs to reason over such data while\npreserving other attributes of competent diagnostic conversation remains\nunknown. Here we advance the conversational diagnosis and management\nperformance of the Articulate Medical Intelligence Explorer (AMIE) through a\nnew capability to gather and interpret multimodal data, and reason about this\nprecisely during consultations. Leveraging Gemini 2.0 Flash, our system\nimplements a state-aware dialogue framework, where conversation flow is\ndynamically controlled by intermediate model outputs reflecting patient states\nand evolving diagnoses. Follow-up questions are strategically directed by\nuncertainty in such patient states, leading to a more structured multimodal\nhistory-taking process that emulates experienced clinicians. We compared AMIE\nto primary care physicians (PCPs) in a randomized, blinded, OSCE-style study of\nchat-based consultations with patient actors. We constructed 105 evaluation\nscenarios using artifacts like smartphone skin photos, ECGs, and PDFs of\nclinical documents across diverse conditions and demographics. Our rubric\nassessed multimodal capabilities and other clinically meaningful axes like\nhistory-taking, diagnostic accuracy, management reasoning, communication, and\nempathy. Specialist evaluation showed AMIE to be superior to PCPs on 7/9\nmultimodal and 29/32 non-multimodal axes (including diagnostic accuracy). The\nresults show clear progress in multimodal conversational diagnostic AI, but\nreal-world translation needs further research.",
      "tldr_zh": "本研究提升了对话式诊断 AI（AMIE）的性能，通过整合多模态数据（如图像、ECG 和 PDF），以处理远程医疗咨询中的实际需求。利用 Gemini 2.0 Flash，该系统构建了一个状态感知对话框架，能够动态根据患者状态和诊断不确定性引导后续问题，实现结构化的多模态历史采集。实验采用随机盲法 OSCE-style 研究，在 105 个场景中比较 AMIE 与初级护理医师（PCPs），结果显示 AMIE 在 7/9 多模态轴和 29/32 非多模态轴上优越，包括诊断准确性、管理推理和沟通能力。该进展突显了多模态对话诊断 AI 的潜力，但实际应用仍需进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04653v1",
      "published_date": "2025-05-06 20:52:01 UTC",
      "updated_date": "2025-05-06 20:52:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:03:55.313118"
    },
    {
      "arxiv_id": "2505.03961v2",
      "title": "The Power of Stories: Narrative Priming Shapes How LLM Agents Collaborate and Compete",
      "title_zh": "翻译失败",
      "authors": [
        "Gerrit Großmann",
        "Larisa Ivanova",
        "Sai Leela Poduru",
        "Mohaddeseh Tabrizian",
        "Islam Mesabah",
        "David A. Selby",
        "Sebastian J. Vollmer"
      ],
      "abstract": "According to Yuval Noah Harari, large-scale human cooperation is driven by\nshared narratives that encode common beliefs and values. This study explores\nwhether such narratives can similarly nudge LLM agents toward collaboration. We\nuse a finitely repeated public goods game in which LLM agents choose either\ncooperative or egoistic spending strategies. We prime agents with stories\nhighlighting teamwork to different degrees and test how this influences\nnegotiation outcomes. Our experiments explore four questions:(1) How do\nnarratives influence negotiation behavior? (2) What differs when agents share\nthe same story versus different ones? (3) What happens when the agent numbers\ngrow? (4) Are agents resilient against self-serving negotiators? We find that\nstory-based priming significantly affects negotiation strategies and success\nrates. Common stories improve collaboration, benefiting each agent. By\ncontrast, priming agents with different stories reverses this effect, and those\nagents primed toward self-interest prevail. We hypothesize that these results\ncarry implications for multi-agent system design and AI alignment.",
      "tldr_zh": "本研究探讨了叙事 priming 如何影响 LLM agents 的合作与竞争行为，基于 Yuval Noah Harari 的观点，测试共享叙事是否能促进大型人类合作在 AI 代理中的应用。研究采用有限重复的 public goods game 实验，让 LLM agents 在故事 priming（不同程度强调团队合作）下选择合作或自私策略，并分析四个关键问题，包括叙事对行为的影响、共享 vs. 不同故事的差异、代理数量变化以及对自私谈判者的抵抗力。结果显示，故事 priming 显著提升谈判策略和成功率，共享相同故事促进合作并惠及所有代理，而不同故事则导致自私行为占优势；这些发现为 multi-agent system 设计和 AI alignment 提供了重要启示。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.MA",
        "I.2.11; I.2.7; I.6; J.4"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages, 8 figures. Code available at\n  https://github.com/storyagents25/story-agents",
      "pdf_url": "http://arxiv.org/pdf/2505.03961v2",
      "published_date": "2025-05-06 20:23:25 UTC",
      "updated_date": "2025-05-08 08:29:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:04:05.395121"
    },
    {
      "arxiv_id": "2505.03947v1",
      "title": "Frog Soup: Zero-Shot, In-Context, and Sample-Efficient Frogger Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Xiang Li",
        "Yiyang Hao",
        "Doug Fulop"
      ],
      "abstract": "One of the primary aspirations in reinforcement learning research is\ndeveloping general-purpose agents capable of rapidly adapting to and mastering\nnovel tasks. While RL gaming agents have mastered many Atari games, they remain\nslow and costly to train for each game. In this work, we demonstrate that\nlatest reasoning LLMs with out-of-domain RL post-training can play a\nchallenging Atari game called Frogger under a zero-shot setting. We then\ninvestigate the effect of in-context learning and the amount of reasoning\neffort on LLM performance. Lastly, we demonstrate a way to bootstrap\ntraditional RL method with LLM demonstrations, which significantly improves\ntheir performance and sample efficiency. Our implementation is open sourced at\nhttps://github.com/AlienKevin/frogger.",
      "tldr_zh": "本文提出Frog Soup框架，利用最新的大型语言模型（LLMs）在zero-shot设置下玩Atari游戏Frogger，实现强化学习（RL）代理的快速适应。研究探讨了in-context learning和推理努力对LLMs性能的影响，发现这些因素能显著提升代理在复杂任务中的表现。最后，通过LLMs演示引导传统RL方法，显著提高了其性能和sample efficiency，并提供了开源实现。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03947v1",
      "published_date": "2025-05-06 19:51:41 UTC",
      "updated_date": "2025-05-06 19:51:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:04:17.523256"
    },
    {
      "arxiv_id": "2505.03946v1",
      "title": "Decentralized Distributed Proximal Policy Optimization (DD-PPO) for High Performance Computing Scheduling on Multi-User Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Matthew Sgambati",
        "Aleksandar Vakanski",
        "Matthew Anderson"
      ],
      "abstract": "Resource allocation in High Performance Computing (HPC) environments presents\na complex and multifaceted challenge for job scheduling algorithms. Beyond the\nefficient allocation of system resources, schedulers must account for and\noptimize multiple performance metrics, including job wait time and system\nutilization. While traditional rule-based scheduling algorithms dominate the\ncurrent deployments of HPC systems, the increasing heterogeneity and scale of\nthose systems is expected to challenge the efficiency and flexibility of those\nalgorithms in minimizing job wait time and maximizing utilization. Recent\nresearch efforts have focused on leveraging advancements in Reinforcement\nLearning (RL) to develop more adaptable and intelligent scheduling strategies.\nRecent RL-based scheduling approaches have explored a range of algorithms, from\nDeep Q-Networks (DQN) to Proximal Policy Optimization (PPO), and more recently,\nhybrid methods that integrate Graph Neural Networks with RL techniques.\nHowever, a common limitation across these methods is their reliance on\nrelatively small datasets, and these methods face scalability issues when using\nlarge datasets. This study introduces a novel RL-based scheduler utilizing the\nDecentralized Distributed Proximal Policy Optimization (DD-PPO) algorithm,\nwhich supports large-scale distributed training across multiple workers without\nrequiring parameter synchronization at every step. By eliminating reliance on\ncentralized updates to a shared policy, the DD-PPO scheduler enhances\nscalability, training efficiency, and sample utilization. The validation\ndataset leveraged over 11.5 million real HPC job traces for comparing DD-PPO\nperformance between traditional and advanced scheduling approaches, and the\nexperimental results demonstrate improved scheduling performance in comparison\nto both rule-based schedulers and existing RL-based scheduling algorithms.",
      "tldr_zh": "本文针对高性能计算 (HPC) 系统中的作业调度挑战，提出了一种新型强化学习 (RL) 算法——Decentralized Distributed Proximal Policy Optimization (DD-PPO)，它支持大规模分布式训练，无需每步参数同步，从而提升了可扩展性、训练效率和样本利用。DD-PPO 通过整合真实作业数据，解决了传统规则-based 调度和现有 RL 方法（如 DQN 和 PPO）在处理异构大规模系统时的局限性。实验基于超过 1150 万真实 HPC 作业痕迹进行验证，结果显示 DD-PPO 在优化作业等待时间和系统利用率方面，显著优于基线方法。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03946v1",
      "published_date": "2025-05-06 19:50:37 UTC",
      "updated_date": "2025-05-06 19:50:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:04:30.052560"
    },
    {
      "arxiv_id": "2505.03945v1",
      "title": "AI-Driven Security in Cloud Computing: Enhancing Threat Detection, Automated Response, and Cyber Resilience",
      "title_zh": "AI 驱动的云计算安全：增强威胁检测、自动化响应和网络弹性",
      "authors": [
        "Shamnad Mohamed Shaffi",
        "Sunish Vengathattil",
        "Jezeena Nikarthil Sidhick",
        "Resmi Vijayan"
      ],
      "abstract": "Cloud security concerns have been greatly realized in recent years due to the\nincrease of complicated threats in the computing world. Many traditional\nsolutions do not work well in real-time to detect or prevent more complex\nthreats. Artificial intelligence is today regarded as a revolution in\ndetermining a protection plan for cloud data architecture through machine\nlearning, statistical visualization of computing infrastructure, and detection\nof security breaches followed by counteraction. These AI-enabled systems make\nwork easier as more network activities are scrutinized, and any anomalous\nbehavior that might be a precursor to a more serious breach is prevented. This\npaper examines ways AI can enhance cloud security by applying predictive\nanalytics, behavior-based security threat detection, and AI-stirring\nencryption. It also outlines the problems of the previous security models and\nhow AI overcomes them. For a similar reason, issues like data privacy, biases\nin the AI model, and regulatory compliance are also covered. So, AI improves\nthe protection of cloud computing contexts; however, more efforts are needed in\nthe subsequent phases to extend the technology's reliability, modularity, and\nethical aspects. This means that AI can be blended with other new computing\ntechnologies, including blockchain, to improve security frameworks further. The\npaper discusses the current trends in securing cloud data architecture using AI\nand presents further research and application directions.",
      "tldr_zh": "这篇论文探讨了AI在云计算安全中的应用，旨在通过预测分析、行为-based 威胁检测和AI-driven 加密来提升威胁检测、自动响应和网络弹性，从而解决传统安全模型的实时不足。论文分析了AI如何克服现有问题的同时，强调了数据隐私、AI模型偏差和监管合规等挑战，并指出尽管AI显著改善了云安全，但需进一步努力提升其可靠性和道德方面。未来方向包括将AI与区块链等技术整合，以推动云数据架构的安全创新。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03945v1",
      "published_date": "2025-05-06 19:45:13 UTC",
      "updated_date": "2025-05-06 19:45:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:04:41.555318"
    },
    {
      "arxiv_id": "2505.06277v1",
      "title": "Terahertz Spatial Wireless Channel Modeling with Radio Radiance Field",
      "title_zh": "翻译失败",
      "authors": [
        "John Song",
        "Lihao Zhang",
        "Feng Ye",
        "Haijian Sun"
      ],
      "abstract": "Terahertz (THz) communication is a key enabler for 6G systems, offering\nultra-wide bandwidth and unprecedented data rates. However, THz signal\npropagation differs significantly from lower-frequency bands due to severe free\nspace path loss, minimal diffraction and specular reflection, and prominent\nscattering, making conventional channel modeling and pilot-based estimation\napproaches inefficient. In this work, we investigate the feasibility of\napplying radio radiance field (RRF) framework to the THz band. This method\nreconstructs a continuous RRF using visual-based geometry and sparse THz RF\nmeasurements, enabling efficient spatial channel state information\n(Spatial-CSI) modeling without dense sampling. We first build a fine simulated\nTHz scenario, then we reconstruct the RRF and evaluate the performance in terms\nof both reconstruction quality and effectiveness in THz communication, showing\nthat the reconstructed RRF captures key propagation paths with sparse training\nsamples. Our findings demonstrate that RRF modeling remains effective in the\nTHz regime and provides a promising direction for scalable, low-cost spatial\nchannel reconstruction in future 6G networks.",
      "tldr_zh": "本文探讨了 Terahertz (THz) 通信在 6G 系统中的挑战，包括严重的自由空间路径损耗和传播特性差异，导致传统通道建模方法低效。作者提出使用 Radio Radiance Field (RRF) 框架，通过视觉几何和稀疏 THz 测量重建连续 RRF，实现高效的 Spatial-CSI 建模，而无需密集采样。在模拟场景实验中，重建的 RRF 成功捕获关键传播路径，提升了 THz 通信性能。研究结果表明，这一方法为 6G 网络提供了一个可扩展、低成本的空间通道重建方案。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.CV",
        "cs.NI"
      ],
      "primary_category": "eess.SP",
      "comment": "submitted to IEEE conferences",
      "pdf_url": "http://arxiv.org/pdf/2505.06277v1",
      "published_date": "2025-05-06 19:38:33 UTC",
      "updated_date": "2025-05-06 19:38:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:04:54.954009"
    },
    {
      "arxiv_id": "2505.03941v2",
      "title": "GRAML: Goal Recognition As Metric Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Matan Shamir",
        "Reuth Mirsky"
      ],
      "abstract": "Goal Recognition (GR) is the problem of recognizing an agent's objectives\nbased on observed actions. Recent data-driven approaches for GR alleviate the\nneed for costly, manually crafted domain models. However, these approaches can\nonly reason about a pre-defined set of goals, and time-consuming training is\nneeded for new emerging goals. To keep this model-learning automated while\nenabling quick adaptation to new goals, this paper introduces GRAML: Goal\nRecognition As Metric Learning. GRAML uses a Siamese network to treat GR as a\ndeep metric learning task, employing an RNN that learns a metric over an\nembedding space, where the embeddings for observation traces leading to\ndifferent goals are distant, and embeddings of traces leading to the same goals\nare close. This metric is especially useful when adapting to new goals, even if\ngiven just one example observation trace per goal. Evaluated on a versatile set\nof environments, GRAML shows speed, flexibility, and runtime improvements over\nthe state-of-the-art GR while maintaining accurate recognition.",
      "tldr_zh": "本研究将目标识别（Goal Recognition, GR）问题转化为深度度量学习任务，提出 GRAML 方法，以解决现有数据驱动方法仅限于预定义目标且适应新目标时需耗时训练的问题。GRAML 使用 Siamese 网络和 RNN 学习一个嵌入空间的度量，使得导致不同目标的观察轨迹嵌入距离远，而导致相同目标的嵌入距离近，从而实现快速适应新目标，即使仅提供每个目标的一个示例观察轨迹。实验结果显示，GRAML 在多种环境中表现出色，比现有最先进方法具有更高的速度、灵活性和运行时效率，同时保持准确的识别性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted for publication in International Joint Conference on\n  Artificial Intelligence (IJCAI) 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.03941v2",
      "published_date": "2025-05-06 19:38:07 UTC",
      "updated_date": "2025-05-20 14:21:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:05:06.234964"
    },
    {
      "arxiv_id": "2505.05501v1",
      "title": "Preliminary Explorations with GPT-4o(mni) Native Image Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Pu Cao",
        "Feng Zhou",
        "Junyi Ji",
        "Qingye Kong",
        "Zhixiang Lv",
        "Mingjian Zhang",
        "Xuekun Zhao",
        "Siqi Wu",
        "Yinghui Lin",
        "Qing Song",
        "Lu Yang"
      ],
      "abstract": "Recently, the visual generation ability by GPT-4o(mni) has been unlocked by\nOpenAI. It demonstrates a very remarkable generation capability with excellent\nmultimodal condition understanding and varied task instructions. In this paper,\nwe aim to explore the capabilities of GPT-4o across various tasks. Inspired by\nprevious study, we constructed a task taxonomy along with a carefully curated\nset of test samples to conduct a comprehensive qualitative test. Benefiting\nfrom GPT-4o's powerful multimodal comprehension, its image-generation process\ndemonstrates abilities surpassing those of traditional image-generation tasks.\nThus, regarding the dimensions of model capabilities, we evaluate its\nperformance across six task categories: traditional image generation tasks,\ndiscriminative tasks, knowledge-based generation, commonsense-based generation,\nspatially-aware image generation, and temporally-aware image generation. These\ntasks not only assess the quality and conditional alignment of the model's\noutputs but also probe deeper into GPT-4o's understanding of real-world\nconcepts. Our results reveal that GPT-4o performs impressively well in\ngeneral-purpose synthesis tasks, showing strong capabilities in text-to-image\ngeneration, visual stylization, and low-level image processing. However,\nsignificant limitations remain in its ability to perform precise spatial\nreasoning, instruction-grounded generation, and consistent temporal prediction.\nFurthermore, when faced with knowledge-intensive or domain-specific scenarios,\nsuch as scientific illustrations or mathematical plots, the model often\nexhibits hallucinations, factual errors, or structural inconsistencies. These\nfindings suggest that while GPT-4o marks a substantial advancement in unified\nmultimodal generation, there is still a long way to go before it can be\nreliably applied to professional or safety-critical domains.",
      "tldr_zh": "本研究探索了GPT-4o的原生图像生成能力，通过构建任务分类和精心策划的测试样本，进行全面定性评估。论文评估了六个任务类别，包括传统图像生成任务、鉴别任务、基于知识的生成、基于常识的生成、空间感知图像生成和时间感知图像生成。结果显示，GPT-4o在一般合成任务如文本到图像生成、视觉风格化和低级图像处理方面表现出色，展现了强大的多模态理解能力。然而，该模型在精确空间推理、指令引导生成和一致时间预测上存在显著局限，尤其在知识密集型或领域特定场景中，可能出现幻觉、事实错误或结构不一致。这些发现表明，GPT-4o在统一多模态生成方面取得了进展，但仍需改进才能适用于专业或安全关键领域。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05501v1",
      "published_date": "2025-05-06 19:35:29 UTC",
      "updated_date": "2025-05-06 19:35:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:05:18.341477"
    },
    {
      "arxiv_id": "2505.09639v1",
      "title": "Study and improvement of search algorithms in two-players perfect information games",
      "title_zh": "在两人完全信息游戏中搜索算法的研究与改进",
      "authors": [
        "Quentin Cohen-Solal"
      ],
      "abstract": "Games, in their mathematical sense, are everywhere (game industries,\neconomics, defense, education, chemistry, biology, ...).Search algorithms in\ngames are artificial intelligence methods for playing such games.\nUnfortunately, there is no study on these algorithms that evaluates the\ngenerality of their performance. We propose to address this gap in the case of\ntwo-player zero-sum games with perfect information. Furthermore, we propose a\nnew search algorithm and we show that, for a short search time, it outperforms\nall studied algorithms on all games in this large experiment and that, for a\nmedium search time, it outperforms all studied algorithms on 17 of the 22\nstudied games.",
      "tldr_zh": "这篇论文研究了搜索算法在两玩家零和完美信息游戏中的性能普遍性问题，填补了现有研究的空白，并提出了一种新搜索算法。通过大规模实验，该新算法在短搜索时间内优于所有研究算法，在中等搜索时间内则在22个游戏中优于17个。研究结果为AI在游戏领域的应用提供了重要改进。",
      "categories": [
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09639v1",
      "published_date": "2025-05-06 19:29:59 UTC",
      "updated_date": "2025-05-06 19:29:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:05:28.935219"
    },
    {
      "arxiv_id": "2505.04650v1",
      "title": "Multimodal Benchmarking and Recommendation of Text-to-Image Generation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Kapil Wanaskar",
        "Gaytri Jena",
        "Magdalini Eirinaki"
      ],
      "abstract": "This work presents an open-source unified benchmarking and evaluation\nframework for text-to-image generation models, with a particular focus on the\nimpact of metadata augmented prompts. Leveraging the DeepFashion-MultiModal\ndataset, we assess generated outputs through a comprehensive set of\nquantitative metrics, including Weighted Score, CLIP (Contrastive Language\nImage Pre-training)-based similarity, LPIPS (Learned Perceptual Image Patch\nSimilarity), FID (Frechet Inception Distance), and retrieval-based measures, as\nwell as qualitative analysis. Our results demonstrate that structured metadata\nenrichments greatly enhance visual realism, semantic fidelity, and model\nrobustness across diverse text-to-image architectures. While not a traditional\nrecommender system, our framework enables task-specific recommendations for\nmodel selection and prompt design based on evaluation metrics.",
      "tldr_zh": "这篇论文提出一个开源的统一基准测试框架，用于评估文本到图像生成模型，特别是元数据增强提示的影响。框架利用 DeepFashion-MultiModal 数据集，通过 Weighted Score、CLIP-based similarity、LPIPS、FID 和检索-based measures 等定量指标，以及定性分析，全面评估生成图像的质量。结果显示，结构化的元数据增强显著提高了视觉真实性、语义 fidelity 和模型 robustness。该框架还支持基于评估指标的任务特定推荐，帮助优化模型选择和提示设计。",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.GR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04650v1",
      "published_date": "2025-05-06 18:53:34 UTC",
      "updated_date": "2025-05-06 18:53:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:05:43.057066"
    },
    {
      "arxiv_id": "2505.03917v1",
      "title": "Improving Failure Prediction in Aircraft Fastener Assembly Using Synthetic Data in Imbalanced Datasets",
      "title_zh": "利用合成数据改进不平衡数据集中的飞机紧固件组装故障预测",
      "authors": [
        "Gustavo J. G. Lahr",
        "Ricardo V. Godoy",
        "Thiago H. Segreto",
        "Jose O. Savazzi",
        "Arash Ajoudani",
        "Thiago Boaventura",
        "Glauco A. P. Caurin"
      ],
      "abstract": "Automating aircraft manufacturing still relies heavily on human labor due to\nthe complexity of the assembly processes and customization requirements. One\nkey challenge is achieving precise positioning, especially for large aircraft\nstructures, where errors can lead to substantial maintenance costs or part\nrejection. Existing solutions often require costly hardware or lack\nflexibility. Used in aircraft by the thousands, threaded fasteners, e.g.,\nscrews, bolts, and collars, are traditionally executed by fixed-base robots and\nusually have problems in being deployed in the mentioned manufacturing sites.\nThis paper emphasizes the importance of error detection and classification for\nefficient and safe assembly of threaded fasteners, especially aeronautical\ncollars. Safe assembly of threaded fasteners is paramount since acquiring\nsufficient data for training deep learning models poses challenges due to the\nrarity of failure cases and imbalanced datasets. The paper addresses this by\nproposing techniques like class weighting and data augmentation, specifically\ntailored for temporal series data, to improve classification performance.\nFurthermore, the paper introduces a novel problem-modeling approach,\nemphasizing metrics relevant to collar assembly rather than solely focusing on\naccuracy. This tailored approach enhances the models' capability to handle the\nchallenges of threaded fastener assembly effectively.",
      "tldr_zh": "本论文针对飞机紧固件装配中的故障预测问题，强调了在不平衡数据集环境下数据稀缺的挑战，特别是失败案例的稀少。研究提出使用类权重(class weighting)和数据增强(data augmentation)技术，专门针对时间序列数据，以提升错误检测和分类的性能。同时，引入一种新颖的问题建模方法，关注与领圈装配相关的关键指标而非仅准确率，从而显著提高了模型在处理螺纹紧固件装配挑战方面的有效性。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03917v1",
      "published_date": "2025-05-06 18:45:50 UTC",
      "updated_date": "2025-05-06 18:45:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:05:54.577124"
    },
    {
      "arxiv_id": "2505.03899v1",
      "title": "A Graphical Global Optimization Framework for Parameter Estimation of Statistical Models with Nonconvex Regularization Functions",
      "title_zh": "翻译失败",
      "authors": [
        "Danial Davarnia",
        "Mohammadreza Kiaghadi"
      ],
      "abstract": "Optimization problems with norm-bounding constraints arise in a variety of\napplications, including portfolio optimization, machine learning, and feature\nselection. A common approach to these problems involves relaxing the norm\nconstraint via Lagrangian relaxation, transforming it into a regularization\nterm in the objective function. A particularly challenging class includes the\nzero-norm function, which promotes sparsity in statistical parameter\nestimation. Most existing exact methods for solving these problems introduce\nbinary variables and artificial bounds to reformulate them as\nhigher-dimensional mixed-integer programs, solvable by standard solvers. Other\nexact approaches exploit specific structural properties of the objective,\nmaking them difficult to generalize across different problem types. Alternative\nmethods employ nonconvex penalties with favorable statistical characteristics,\nbut these are typically addressed using heuristic or local optimization\ntechniques due to their structural complexity. In this paper, we propose a\nnovel graph-based method to globally solve optimization problems involving\ngeneralized norm-bounding constraints. Our approach encompasses standard\n$\\ell_p$-norms for $p \\in [0, \\infty)$ and nonconvex penalties such as SCAD and\nMCP. We leverage decision diagrams to construct strong convex relaxations\ndirectly in the original variable space, eliminating the need for auxiliary\nvariables or artificial bounds. Integrated into a spatial branch-and-cut\nframework, our method guarantees convergence to the global optimum. We\ndemonstrate its effectiveness through preliminary computational experiments on\nbenchmark sparse linear regression problems involving complex nonconvex\npenalties, which are not tractable using existing global optimization\ntechniques.",
      "tldr_zh": "本文提出了一种基于图形的全局优化框架，用于统计模型参数估计中涉及非凸正则化函数的优化问题，如范数约束（norm-bounding constraints）和零范数（zero-norm）等。该框架利用决策图（decision diagrams）在原始变量空间构建强凸松弛，并将其整合到空间分支和切割（spatial branch-and-cut）框架中，保证收敛到全局最优，无需辅助变量或人工边界。实验结果显示，该方法在基准稀疏线性回归问题上表现出色，尤其适用于SCAD和MCP等非凸惩罚函数，比现有全局优化技术更具可行性。",
      "categories": [
        "math.OC",
        "cs.AI",
        "math.ST",
        "stat.TH"
      ],
      "primary_category": "math.OC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03899v1",
      "published_date": "2025-05-06 18:09:54 UTC",
      "updated_date": "2025-05-06 18:09:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:06:06.541359"
    },
    {
      "arxiv_id": "2505.03896v1",
      "title": "Novel Extraction of Discriminative Fine-Grained Feature to Improve Retinal Vessel Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Shuang Zeng",
        "Chee Hong Lee",
        "Micky C Nnamdi",
        "Wenqi Shi",
        "J Ben Tamo",
        "Lei Zhu",
        "Hangzhou He",
        "Xinliang Zhang",
        "Qian Chen",
        "May D. Wang",
        "Yanye Lu",
        "Qiushi Ren"
      ],
      "abstract": "Retinal vessel segmentation is a vital early detection method for several\nsevere ocular diseases. Despite significant progress in retinal vessel\nsegmentation with the advancement of Neural Networks, there are still\nchallenges to overcome. Specifically, retinal vessel segmentation aims to\npredict the class label for every pixel within a fundus image, with a primary\nfocus on intra-image discrimination, making it vital for models to extract more\ndiscriminative features. Nevertheless, existing methods primarily focus on\nminimizing the difference between the output from the decoder and the label,\nbut ignore fully using feature-level fine-grained representations from the\nencoder. To address these issues, we propose a novel Attention U-shaped\nKolmogorov-Arnold Network named AttUKAN along with a novel Label-guided\nPixel-wise Contrastive Loss for retinal vessel segmentation. Specifically, we\nimplement Attention Gates into Kolmogorov-Arnold Networks to enhance model\nsensitivity by suppressing irrelevant feature activations and model\ninterpretability by non-linear modeling of KAN blocks. Additionally, we also\ndesign a novel Label-guided Pixel-wise Contrastive Loss to supervise our\nproposed AttUKAN to extract more discriminative features by distinguishing\nbetween foreground vessel-pixel pairs and background pairs. Experiments are\nconducted across four public datasets including DRIVE, STARE, CHASE_DB1, HRF\nand our private dataset. AttUKAN achieves F1 scores of 82.50%, 81.14%, 81.34%,\n80.21% and 80.09%, along with MIoU scores of 70.24%, 68.64%, 68.59%, 67.21% and\n66.94% in the above datasets, which are the highest compared to 11 networks for\nretinal vessel segmentation. Quantitative and qualitative results show that our\nAttUKAN achieves state-of-the-art performance and outperforms existing retinal\nvessel segmentation methods. Our code will be available at\nhttps://github.com/stevezs315/AttUKAN.",
      "tldr_zh": "这篇论文针对视网膜血管分割(Retinal vessel segmentation)中的挑战，提出了一种新型Attention U-shaped Kolmogorov-Arnold Network (AttUKAN)，通过整合Attention Gates来抑制无关特征激活并提升模型敏感性和可解释性，同时设计了Label-guided Pixel-wise Contrastive Loss来监督模型提取更具区分性的细粒度特征，从而改善像素级预测准确性。在DRIVE、STARE、CHASE_DB1、HRF和一个私有数据集上的实验中，AttUKAN 取得了最高的F1 scores（高达82.50%）和MIoU scores（高达70.24%），优于11个基准网络，实现了state-of-the-art性能。总体而言，该方法为早期眼部疾病检测提供了更可靠的工具。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03896v1",
      "published_date": "2025-05-06 18:03:41 UTC",
      "updated_date": "2025-05-06 18:03:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:06:20.226329"
    },
    {
      "arxiv_id": "2505.03739v1",
      "title": "VITA-Audio: Fast Interleaved Cross-Modal Token Generation for Efficient Large Speech-Language Model",
      "title_zh": "VITA-A",
      "authors": [
        "Zuwei Long",
        "Yunhang Shen",
        "Chaoyou Fu",
        "Heting Gao",
        "Lijiang Li",
        "Peixian Chen",
        "Mengdan Zhang",
        "Hang Shao",
        "Jian Li",
        "Jinlong Peng",
        "Haoyu Cao",
        "Ke Li",
        "Rongrong Ji",
        "Xing Sun"
      ],
      "abstract": "With the growing requirement for natural human-computer interaction,\nspeech-based systems receive increasing attention as speech is one of the most\ncommon forms of daily communication. However, the existing speech models still\nexperience high latency when generating the first audio token during streaming,\nwhich poses a significant bottleneck for deployment. To address this issue, we\npropose VITA-Audio, an end-to-end large speech model with fast audio-text token\ngeneration. Specifically, we introduce a lightweight Multiple Cross-modal Token\nPrediction (MCTP) module that efficiently generates multiple audio tokens\nwithin a single model forward pass, which not only accelerates the inference\nbut also significantly reduces the latency for generating the first audio in\nstreaming scenarios. In addition, a four-stage progressive training strategy is\nexplored to achieve model acceleration with minimal loss of speech quality. To\nour knowledge, VITA-Audio is the first multi-modal large language model capable\nof generating audio output during the first forward pass, enabling real-time\nconversational capabilities with minimal latency. VITA-Audio is fully\nreproducible and is trained on open-source data only. Experimental results\ndemonstrate that our model achieves an inference speedup of 3~5x at the 7B\nparameter scale, but also significantly outperforms open-source models of\nsimilar model size on multiple benchmarks for automatic speech recognition\n(ASR), text-to-speech (TTS), and spoken question answering (SQA) tasks.",
      "tldr_zh": "本文提出 VITA-Audio，一种端到端的语音大语言模型，旨在解决现有语音模型在生成第一个音频令牌时的延迟问题，从而提升实时人机交互效率。核心方法包括引入轻量级 Multiple Cross-modal Token Prediction (MCTP) 模块，能在单次模型前向传递中生成多个音频令牌，显著加速推理并减少流式场景的延迟。此外，该模型采用四阶段渐进训练策略，以最小化语音质量损失。实验结果显示，VITA-Audio 在 7B 参数规模下实现 3~5 倍的推理加速，并在 Automatic Speech Recognition (ASR)、Text-to-Speech (TTS) 和 Spoken Question Answering (SQA) 任务上优于同规模开源模型。总的来说，这是一个完全可复现的开源模型，首次实现了在首次前向传递中生成音频输出，支持实时对话。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Training and Inference Codes: https://github.com/VITA-MLLM/VITA-Audio",
      "pdf_url": "http://arxiv.org/pdf/2505.03739v1",
      "published_date": "2025-05-06 17:59:53 UTC",
      "updated_date": "2025-05-06 17:59:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:06:32.233978"
    },
    {
      "arxiv_id": "2505.03738v1",
      "title": "AMO: Adaptive Motion Optimization for Hyper-Dexterous Humanoid Whole-Body Control",
      "title_zh": "AMO：自适应运动优化用于超灵巧人形机器人全身控制",
      "authors": [
        "Jialong Li",
        "Xuxin Cheng",
        "Tianshu Huang",
        "Shiqi Yang",
        "Ri-Zhao Qiu",
        "Xiaolong Wang"
      ],
      "abstract": "Humanoid robots derive much of their dexterity from hyper-dexterous\nwhole-body movements, enabling tasks that require a large operational\nworkspace: such as picking objects off the ground. However, achieving these\ncapabilities on real humanoids remains challenging due to their high degrees of\nfreedom (DoF) and nonlinear dynamics. We propose Adaptive Motion Optimization\n(AMO), a framework that integrates sim-to-real reinforcement learning (RL) with\ntrajectory optimization for real-time, adaptive whole-body control. To mitigate\ndistribution bias in motion imitation RL, we construct a hybrid AMO dataset and\ntrain a network capable of robust, on-demand adaptation to potentially O.O.D.\ncommands. We validate AMO in simulation and on a 29-DoF Unitree G1 humanoid\nrobot, demonstrating superior stability and an expanded workspace compared to\nstrong baselines. Finally, we show that AMO's consistent performance supports\nautonomous task execution via imitation learning, underscoring the system's\nversatility and robustness.",
      "tldr_zh": "该论文提出 Adaptive Motion Optimization (AMO) 框架，用于实现人形机器人的超灵巧全身控制，解决高自由度 (DoF) 和非线性动态带来的挑战。AMO 通过整合 sim-to-real reinforcement learning (RL) 和轨迹优化，构建混合数据集并训练网络，以实现实时适应潜在 O.O.D. (Out-of-Distribution) 命令。实验在模拟环境中和 29-DoF Unitree G1 机器人上验证，显示 AMO 比基线模型具有更高的稳定性和更大的工作空间，并支持通过模仿学习进行自主任务执行。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "website: https://amo-humanoid.github.io",
      "pdf_url": "http://arxiv.org/pdf/2505.03738v1",
      "published_date": "2025-05-06 17:59:51 UTC",
      "updated_date": "2025-05-06 17:59:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:06:43.164437"
    },
    {
      "arxiv_id": "2505.03730v1",
      "title": "FlexiAct: Towards Flexible Action Control in Heterogeneous Scenarios",
      "title_zh": "FlexiAct：迈向异构场景中的灵活动作控制",
      "authors": [
        "Shiyi Zhang",
        "Junhao Zhuang",
        "Zhaoyang Zhang",
        "Ying Shan",
        "Yansong Tang"
      ],
      "abstract": "Action customization involves generating videos where the subject performs\nactions dictated by input control signals. Current methods use pose-guided or\nglobal motion customization but are limited by strict constraints on spatial\nstructure, such as layout, skeleton, and viewpoint consistency, reducing\nadaptability across diverse subjects and scenarios. To overcome these\nlimitations, we propose FlexiAct, which transfers actions from a reference\nvideo to an arbitrary target image. Unlike existing methods, FlexiAct allows\nfor variations in layout, viewpoint, and skeletal structure between the subject\nof the reference video and the target image, while maintaining identity\nconsistency. Achieving this requires precise action control, spatial structure\nadaptation, and consistency preservation. To this end, we introduce RefAdapter,\na lightweight image-conditioned adapter that excels in spatial adaptation and\nconsistency preservation, surpassing existing methods in balancing appearance\nconsistency and structural flexibility. Additionally, based on our\nobservations, the denoising process exhibits varying levels of attention to\nmotion (low frequency) and appearance details (high frequency) at different\ntimesteps. So we propose FAE (Frequency-aware Action Extraction), which, unlike\nexisting methods that rely on separate spatial-temporal architectures, directly\nachieves action extraction during the denoising process. Experiments\ndemonstrate that our method effectively transfers actions to subjects with\ndiverse layouts, skeletons, and viewpoints. We release our code and model\nweights to support further research at\nhttps://shiyi-zh0408.github.io/projectpages/FlexiAct/",
      "tldr_zh": "本文提出 FlexiAct，一种灵活的动作控制框架，用于从参考视频向任意目标图像转移动作，允许布局、视角和骨骼结构的变异，同时保持身份一致性，以克服现有方法的空间约束限制。关键组件包括 RefAdapter，一个轻量级的图像条件适配器，用于实现空间适应和外观一致性，以及 FAE (Frequency-aware Action Extraction)，通过在去噪过程中关注不同频率（低频动作和高频细节）来直接提取动作。实验结果显示，FlexiAct 有效处理多样化主体的动作转移，并在 https://shiyi-zh0408.github.io/projectpages/FlexiAct/ 发布了代码和模型权重，以支持进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by Siggraph2025, Project Page:\n  https://shiyi-zh0408.github.io/projectpages/FlexiAct/",
      "pdf_url": "http://arxiv.org/pdf/2505.03730v1",
      "published_date": "2025-05-06 17:58:02 UTC",
      "updated_date": "2025-05-06 17:58:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:06:54.374734"
    },
    {
      "arxiv_id": "2505.03710v1",
      "title": "Actor-Critics Can Achieve Optimal Sample Efficiency",
      "title_zh": "Actor-Critic 可以实现最优样本效率",
      "authors": [
        "Kevin Tan",
        "Wei Fan",
        "Yuting Wei"
      ],
      "abstract": "Actor-critic algorithms have become a cornerstone in reinforcement learning\n(RL), leveraging the strengths of both policy-based and value-based methods.\nDespite recent progress in understanding their statistical efficiency, no\nexisting work has successfully learned an $\\epsilon$-optimal policy with a\nsample complexity of $O(1/\\epsilon^2)$ trajectories with general function\napproximation when strategic exploration is necessary.\n  We address this open problem by introducing a novel actor-critic algorithm\nthat attains a sample-complexity of $O(dH^5 \\log|\\mathcal{A}|/\\epsilon^2 + d\nH^4 \\log|\\mathcal{F}|/ \\epsilon^2)$ trajectories, and accompanying $\\sqrt{T}$\nregret when the Bellman eluder dimension $d$ does not increase with $T$ at more\nthan a $\\log T$ rate.\n  Here, $\\mathcal{F}$ is the critic function class, $\\mathcal{A}$ is the action\nspace, and $H$ is the horizon in the finite horizon MDP setting. Our algorithm\nintegrates optimism, off-policy critic estimation targeting the optimal\nQ-function, and rare-switching policy resets.\n  We extend this to the setting of Hybrid RL, showing that initializing the\ncritic with offline data yields sample efficiency gains compared to purely\noffline or online RL. Further, utilizing access to offline data, we provide a\n\\textit{non-optimistic} provably efficient actor-critic algorithm that only\nadditionally requires $N_{\\text{off}} \\geq c_{\\text{off}}^*dH^4/\\epsilon^2$ in\nexchange for omitting optimism, where $c_{\\text{off}}^*$ is the single-policy\nconcentrability coefficient and $N_{\\text{off}}$ is the number of offline\nsamples. This addresses another open problem in the literature. We further\nprovide numerical experiments to support our theoretical findings.",
      "tldr_zh": "本论文证明了actor-critic算法在强化学习中可以实现最优样本效率，解决了现有方法在需要战略探索的场景下无法达到O(1/ε²)轨迹复杂度的开放问题。作者引入了一种新算法，结合optimism、off-policy critic估计以及rare-switching policy resets，在有限地平线MDP设置中实现了O(dH^5 log|𝒜|/ε² + dH^4 log|ℱ|/ε²)轨迹的样本复杂度，并展示了伴随的√T regret。扩展到Hybrid RL，该算法利用离线数据初始化critic，提升样本效率，并提供了一个非乐观版本，仅需N_off ≥ c_off^* dH^4/ε²的离线样本即可高效；数值实验进一步验证了这些理论发现。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "Accepted to ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.03710v1",
      "published_date": "2025-05-06 17:32:39 UTC",
      "updated_date": "2025-05-06 17:32:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:07:06.451164"
    },
    {
      "arxiv_id": "2505.03867v1",
      "title": "Scratch Copilot: Supporting Youth Creative Coding with AI",
      "title_zh": "Scratch Copilot：使用 AI 支持青年创造性编码",
      "authors": [
        "Stefania Druga",
        "Amy J. Ko"
      ],
      "abstract": "Creative coding platforms like Scratch have democratized programming for\nchildren, yet translating imaginative ideas into functional code remains a\nsignificant hurdle for many young learners. While AI copilots assist adult\nprogrammers, few tools target children in block-based environments. Building on\nprior research \\cite{druga_how_2021,druga2023ai, druga2023scratch}, we present\nCognimates Scratch Copilot: an AI-powered assistant integrated into a\nScratch-like environment, providing real-time support for ideation, code\ngeneration, debugging, and asset creation. This paper details the system\narchitecture and findings from an exploratory qualitative evaluation with 18\ninternational children (ages 7--12). Our analysis reveals how the AI Copilot\nsupported key creative coding processes, particularly aiding ideation and\ndebugging. Crucially, it also highlights how children actively negotiated the\nuse of AI, demonstrating strong agency by adapting or rejecting suggestions to\nmaintain creative control. Interactions surfaced design tensions between\nproviding helpful scaffolding and fostering independent problem-solving, as\nwell as learning opportunities arising from navigating AI limitations and\nerrors. Findings indicate Cognimates Scratch Copilot's potential to enhance\ncreative self-efficacy and engagement. Based on these insights, we propose\ninitial design guidelines for AI coding assistants that prioritize youth agency\nand critical interaction alongside supportive scaffolding.",
      "tldr_zh": "本研究针对儿童在Scratch等创意编码平台上将想法转化为代码的挑战，开发了Cognimates Scratch Copilot——一个AI辅助工具，集成于Scratch-like环境，提供实时支持包括构思、代码生成、调试和资产创建。研究通过对18名7-12岁国际儿童的定性评估，揭示AI Copilot显著提升了构思和调试过程，同时儿童展现出强烈主动性，通过适应或拒绝AI建议来保持创意控制。结果突显了设计张力，如在提供支持性支架与培养独立问题解决之间，并基于此提出AI编码助手的初步设计指南，强调优先青少年主动性和批判性互动，以增强创造性自我效能和参与度。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "5 figures, 14 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.03867v1",
      "published_date": "2025-05-06 17:13:29 UTC",
      "updated_date": "2025-05-06 17:13:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:07:19.014475"
    },
    {
      "arxiv_id": "2505.07842v1",
      "title": "RAN Cortex: Memory-Augmented Intelligence for Context-Aware Decision-Making in AI-Native Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Sebastian Barros"
      ],
      "abstract": "As Radio Access Networks (RAN) evolve toward AI-native architectures,\nintelligent modules such as xApps and rApps are expected to make increasingly\nautonomous decisions across scheduling, mobility, and resource management\ndomains. However, these agents remain fundamentally stateless, treating each\ndecision as isolated, lacking any persistent memory of prior events or\noutcomes. This reactive behavior constrains optimization, especially in\nenvironments where network dynamics exhibit episodic or recurring patterns. In\nthis work, we propose RAN Cortex, a memory-augmented architecture that enables\ncontextual recall in AI-based RAN decision systems. RAN Cortex introduces a\nmodular layer composed of four elements: a context encoder that transforms\nnetwork state into high-dimensional embeddings, a vector-based memory store of\npast network episodes, a recall engine to retrieve semantically similar\nsituations, and a policy interface that supplies historical context to AI\nagents in real time or near-real time. We formalize the retrieval-augmented\ndecision problem in the RAN, present a system architecture compatible with\nO-RAN interfaces, and analyze feasible deployments within the Non-RT and\nNear-RT RIC domains. Through illustrative use cases such as stadium traffic\nmitigation and mobility management in drone corridors, we demonstrate how\ncontextual memory improves adaptability, continuity, and overall RAN\nintelligence. This work introduces memory as a missing primitive in AI-native\nRAN designs and provides a framework to enable \"learning agents\" without the\nneed for retraining or centralized inference",
      "tldr_zh": "该研究针对AI-native无线接入网络(RAN)中，智能模块如xApps和rApps的决策缺乏记忆机制的问题，提出RAN Cortex——一个记忆增强架构，以实现上下文感知决策。RAN Cortex包括四个模块：context encoder将网络状态转化为高维嵌入、vector-based memory store存储过去事件、recall engine检索相似情境，以及policy interface实时提供历史上下文。该框架形式化了RAN中的检索增强决策问题，并与O-RAN接口兼容，可部署在Non-RT和Near-RT RIC领域。通过体育场流量缓解和无人机走廊移动管理的用例，证明了RAN Cortex提升了网络的适应性、连续性和整体智能，无需重新训练即可实现“学习”代理。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "28 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.07842v1",
      "published_date": "2025-05-06 17:01:05 UTC",
      "updated_date": "2025-05-06 17:01:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:07:30.544808"
    },
    {
      "arxiv_id": "2505.03694v2",
      "title": "Demonstrating ViSafe: Vision-enabled Safety for High-speed Detect and Avoid",
      "title_zh": "翻译失败",
      "authors": [
        "Parv Kapoor",
        "Ian Higgins",
        "Nikhil Keetha",
        "Jay Patrikar",
        "Brady Moon",
        "Zelin Ye",
        "Yao He",
        "Ivan Cisneros",
        "Yaoyu Hu",
        "Changliu Liu",
        "Eunsuk Kang",
        "Sebastian Scherer"
      ],
      "abstract": "Assured safe-separation is essential for achieving seamless high-density\noperation of airborne vehicles in a shared airspace. To equip\nresource-constrained aerial systems with this safety-critical capability, we\npresent ViSafe, a high-speed vision-only airborne collision avoidance system.\nViSafe offers a full-stack solution to the Detect and Avoid (DAA) problem by\ntightly integrating a learning-based edge-AI framework with a custom\nmulti-camera hardware prototype designed under SWaP-C constraints. By\nleveraging perceptual input-focused control barrier functions (CBF) to design,\nencode, and enforce safety thresholds, ViSafe can provide provably safe runtime\nguarantees for self-separation in high-speed aerial operations. We evaluate\nViSafe's performance through an extensive test campaign involving both\nsimulated digital twins and real-world flight scenarios. By independently\nvarying agent types, closure rates, interaction geometries, and environmental\nconditions (e.g., weather and lighting), we demonstrate that ViSafe\nconsistently ensures self-separation across diverse scenarios. In\nfirst-of-its-kind real-world high-speed collision avoidance tests with closure\nrates reaching 144 km/h, ViSafe sets a new benchmark for vision-only autonomous\ncollision avoidance, establishing a new standard for safety in high-speed\naerial navigation.",
      "tldr_zh": "该论文介绍了ViSafe，一种基于视觉的空中碰撞避免系统，旨在为资源受限的航空系统提供高速Detect and Avoid (DAA)安全保障。ViSafe通过整合学习-based边缘AI框架、自定义的多相机硬件原型（符合SWaP-C约束）和感知输入聚焦的控制屏障函数(CBF)，来设计、编码并执行安全阈值，确保高速度空中操作中的自分离。实验结果显示，在模拟和真实飞行测试中，ViSafe在各种代理类型、关闭速率（高达144 km/h）、交互几何和环境条件下均能保持一致的安全性能，树立了视觉-only自主碰撞避免的新基准。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "13 pages, RSS 2025 Demo track, https://theairlab.org/visafe/",
      "pdf_url": "http://arxiv.org/pdf/2505.03694v2",
      "published_date": "2025-05-06 16:59:54 UTC",
      "updated_date": "2025-05-08 14:12:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:07:42.025145"
    },
    {
      "arxiv_id": "2505.03864v1",
      "title": "From Glue-Code to Protocols: A Critical Analysis of A2A and MCP Integration for Scalable Agent Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Qiaomu Li",
        "Ying Xie"
      ],
      "abstract": "Artificial intelligence is rapidly evolving towards multi-agent systems where\nnumerous AI agents collaborate and interact with external tools. Two key open\nstandards, Google's Agent to Agent (A2A) protocol for inter-agent communication\nand Anthropic's Model Context Protocol (MCP) for standardized tool access,\npromise to overcome the limitations of fragmented, custom integration\napproaches. While their potential synergy is significant, this paper argues\nthat effectively integrating A2A and MCP presents unique, emergent challenges\nat their intersection, particularly concerning semantic interoperability\nbetween agent tasks and tool capabilities, the compounded security risks\narising from combined discovery and execution, and the practical governance\nrequired for the envisioned \"Agent Economy\". This work provides a critical\nanalysis, moving beyond a survey to evaluate the practical implications and\ninherent difficulties of combining these horizontal and vertical integration\nstandards. We examine the benefits (e.g., specialization, scalability) while\ncritically assessing their dependencies and trade-offs in an integrated\ncontext. We identify key challenges increased by the integration, including\nnovel security vulnerabilities, privacy complexities, debugging difficulties\nacross protocols, and the need for robust semantic negotiation mechanisms. In\nsummary, A2A+MCP offers a vital architectural foundation, but fully realizing\nits potential requires substantial advancements to manage the complexities of\ntheir combined operation.",
      "tldr_zh": "这篇论文对 Google 的 Agent to Agent (A2A) 协议和 Anthropic 的 Model Context Protocol (MCP) 在可扩展多智能体系统中的整合进行批判性分析，旨在超越碎片化的自定义集成方法。研究评估了整合的益处，包括智能体专业化和系统可扩展性，同时强调了潜在挑战，如语义互操作性问题、复合安全风险（如漏洞和隐私复杂性）、跨协议调试困难，以及对语义协商机制的需求。总体上，虽然 A2A+MCP 提供了关键的架构基础，但论文指出，实现其潜力需要进一步的改进来管理整合复杂性。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03864v1",
      "published_date": "2025-05-06 16:40:39 UTC",
      "updated_date": "2025-05-06 16:40:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:07:54.759324"
    },
    {
      "arxiv_id": "2505.03863v1",
      "title": "Data-Driven Falsification of Cyber-Physical Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Atanu Kundu",
        "Sauvik Gon",
        "Rajarshi Ray"
      ],
      "abstract": "Cyber-Physical Systems (CPS) are abundant in safety-critical domains such as\nhealthcare, avionics, and autonomous vehicles. Formal verification of their\noperational safety is, therefore, of utmost importance. In this paper, we\naddress the falsification problem, where the focus is on searching for an\nunsafe execution in the system instead of proving their absence. The\ncontribution of this paper is a framework that (a) connects the falsification\nof CPS with the falsification of deep neural networks (DNNs) and (b) leverages\nthe inherent interpretability of Decision Trees for faster falsification of\nCPS. This is achieved by: (1) building a surrogate model of the CPS under test,\neither as a DNN model or a Decision Tree, (2) application of various DNN\nfalsification tools to falsify CPS, and (3) a novel falsification algorithm\nguided by the explanations of safety violations of the CPS model extracted from\nits Decision Tree surrogate. The proposed framework has the potential to\nexploit a repertoire of \\emph{adversarial attack} algorithms designed to\nfalsify robustness properties of DNNs, as well as state-of-the-art\nfalsification algorithms for DNNs. Although the presented methodology is\napplicable to systems that can be executed/simulated in general, we demonstrate\nits effectiveness, particularly in CPS. We show that our framework, implemented\nas a tool \\textsc{FlexiFal}, can detect hard-to-find counterexamples in CPS\nthat have linear and non-linear dynamics. Decision tree-guided falsification\nshows promising results in efficiently finding multiple counterexamples in the\nARCH-COMP 2024 falsification benchmarks~\\cite{khandait2024arch}.",
      "tldr_zh": "这篇论文提出一个数据驱动框架，用于证伪 Cyber-Physical Systems (CPS)，通过将 CPS 的证伪与 deep neural networks (DNNs) 的证伪相结合，并利用 Decision Trees 的内在解释性来加速发现不安全执行。框架的关键步骤包括构建 CPS 的代理模型（如 DNN 或 Decision Trees）、应用 DNN 证伪工具，以及一个新型算法，利用决策树提取的安全违规解释进行指导。该方法在 ARCH-COMP 2024 基准测试中表现出色，能够高效检测线性与非线性动态 CPS 中的多个难找反例，从而提升 CPS 安全验证的效率。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03863v1",
      "published_date": "2025-05-06 16:33:06 UTC",
      "updated_date": "2025-05-06 16:33:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:08:07.119356"
    },
    {
      "arxiv_id": "2505.03678v1",
      "title": "Graph Drawing for LLMs: An Empirical Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Walter Didimo",
        "Fabrizio Montecchiani",
        "Tommaso Piselli"
      ],
      "abstract": "Our work contributes to the fast-growing literature on the use of Large\nLanguage Models (LLMs) to perform graph-related tasks. In particular, we focus\non usage scenarios that rely on the visual modality, feeding the model with a\ndrawing of the graph under analysis. We investigate how the model's performance\nis affected by the chosen layout paradigm, the aesthetics of the drawing, and\nthe prompting technique used for the queries. We formulate three corresponding\nresearch questions and present the results of a thorough experimental analysis.\nOur findings reveal that choosing the right layout paradigm and optimizing the\nreadability of the input drawing from a human perspective can significantly\nimprove the performance of the model on the given task. Moreover, selecting the\nmost effective prompting technique is a challenging yet crucial task for\nachieving optimal performance.",
      "tldr_zh": "本研究通过实证评估探讨了Large Language Models (LLMs)在处理图相关任务时的表现，特别关注视觉模态下图绘图的输入方式。研究者实验分析了布局范式(layout paradigm)、绘图美学和prompting technique等因素对模型性能的影响。结果表明，选择合适的layout paradigm并优化绘图的可读性（从人类视角）能显著提升任务准确性，而选择有效的prompting technique是实现最佳性能的关键。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03678v1",
      "published_date": "2025-05-06 16:23:42 UTC",
      "updated_date": "2025-05-06 16:23:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:08:18.708416"
    },
    {
      "arxiv_id": "2505.06275v1",
      "title": "Attonsecond Streaking Phase Retrieval Via Deep Learning Methods",
      "title_zh": "翻译失败",
      "authors": [
        "Yuzhou Zhu",
        "Zheng Zhang",
        "Ruyi Zhang",
        "Liang Zhou"
      ],
      "abstract": "Attosecond streaking phase retrieval is essential for resolving electron\ndynamics on sub-femtosecond time scales yet traditional algorithms rely on\niterative minimization and central momentum approximations that degrade\naccuracy for broadband pulses. In this work phase retrieval is reformulated as\na supervised computer-vision problem and four neural architectures are\nsystematically compared. A convolutional network demonstrates strong\nsensitivity to local streak edges but lacks global context; a vision\ntransformer captures long-range delay-energy correlations at the expense of\nlocal inductive bias; a hybrid CNN-ViT model unites local feature extraction\nand full-graph attention; and a capsule network further enforces spatial pose\nagreement through dynamic routing. A theoretical analysis introduces local,\nglobal and positional sensitivity measures and derives surrogate error bounds\nthat predict the strict ordering $CNN<ViT<Hybrid<Capsule$. Controlled\nexperiments on synthetic streaking spectrograms confirm this hierarchy, with\nthe capsule network achieving the highest retrieval fidelity. Looking forward,\nembedding the strong-field integral into physics-informed neural networks and\nexploring photonic hardware implementations promise pathways toward real-time\nattosecond pulse characterization under demanding experimental conditions.",
      "tldr_zh": "本文将attosecond streaking phase retrieval重新表述为监督计算机视觉问题，通过比较四种神经网络架构（CNN、ViT、Hybrid模型和Capsule Network）来提升相位检索准确性。CNN对局部条纹边缘敏感但缺少全局上下文，ViT捕捉长程延迟-能量相关却牺牲局部归纳偏差，Hybrid模型结合局部特征提取和全局注意力，而Capsule Network通过动态路由强化空间姿势一致性。理论分析引入局部、全局和位置敏感性度量，预测并实验验证了性能顺序为CNN < ViT < Hybrid < Capsule，其中Capsule Network在合成谱图上表现出最高检索保真度。展望未来，嵌入强场积分到physics-informed neural networks并探索光子硬件实现，有望实现实时attosecond脉冲表征。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "physics.optics"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06275v1",
      "published_date": "2025-05-06 16:16:42 UTC",
      "updated_date": "2025-05-06 16:16:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:08:33.072460"
    },
    {
      "arxiv_id": "2505.03674v1",
      "title": "Gap the (Theory of) Mind: Sharing Beliefs About Teammates' Goals Boosts Collaboration Perception, Not Performance",
      "title_zh": "翻译失败",
      "authors": [
        "Yotam Amitai",
        "Reuth Mirsky",
        "Ofra Amir"
      ],
      "abstract": "In human-agent teams, openly sharing goals is often assumed to enhance\nplanning, collaboration, and effectiveness. However, direct communication of\nthese goals is not always feasible, requiring teammates to infer their\npartner's intentions through actions. Building on this, we investigate whether\nan AI agent's ability to share its inferred understanding of a human teammate's\ngoals can improve task performance and perceived collaboration. Through an\nexperiment comparing three conditions-no recognition (NR), viable goals (VG),\nand viable goals on-demand (VGod) - we find that while goal-sharing information\ndid not yield significant improvements in task performance or overall\nsatisfaction scores, thematic analysis suggests that it supported strategic\nadaptations and subjective perceptions of collaboration. Cognitive load\nassessments revealed no additional burden across conditions, highlighting the\nchallenge of balancing informativeness and simplicity in human-agent\ninteractions. These findings highlight the nuanced trade-off of goal-sharing:\nwhile it fosters trust and enhances perceived collaboration, it can\noccasionally hinder objective performance gains.",
      "tldr_zh": "本研究探讨了在人类-代理团队中，AI 代理分享对其队友目标推断的能力是否能提升任务表现和感知协作。研究者通过实验比较了三种条件——无识别 (NR)、可行目标 (VG) 和按需可行目标 (VGod)，发现目标分享信息并未显著改善任务表现或整体满意度。主题分析显示，这种分享支持了战略适应和主观协作感知，同时认知负荷评估表明各条件未增加额外负担。这些发现突出了目标分享的权衡：它增强了信任和 Theory of Mind 的感知协作，但可能无法带来客观性能提升，并强调了在人类-代理互动中平衡信息性和简单性的挑战。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03674v1",
      "published_date": "2025-05-06 16:15:24 UTC",
      "updated_date": "2025-05-06 16:15:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:08:42.928515"
    },
    {
      "arxiv_id": "2505.03668v1",
      "title": "Learning Symbolic Persistent Macro-Actions for POMDP Solving Over Time",
      "title_zh": "翻译失败",
      "authors": [
        "Celeste Veronese",
        "Daniele Meli",
        "Alessandro Farinelli"
      ],
      "abstract": "This paper proposes an integration of temporal logical reasoning and\nPartially Observable Markov Decision Processes (POMDPs) to achieve\ninterpretable decision-making under uncertainty with macro-actions. Our method\nleverages a fragment of Linear Temporal Logic (LTL) based on Event Calculus\n(EC) to generate \\emph{persistent} (i.e., constant) macro-actions, which guide\nMonte Carlo Tree Search (MCTS)-based POMDP solvers over a time horizon,\nsignificantly reducing inference time while ensuring robust performance. Such\nmacro-actions are learnt via Inductive Logic Programming (ILP) from a few\ntraces of execution (belief-action pairs), thus eliminating the need for\nmanually designed heuristics and requiring only the specification of the POMDP\ntransition model. In the Pocman and Rocksample benchmark scenarios, our learned\nmacro-actions demonstrate increased expressiveness and generality when compared\nto time-independent heuristics, indeed offering substantial computational\nefficiency improvements.",
      "tldr_zh": "该论文提出了一种将时间逻辑推理与部分可观测马尔可夫决策过程 (POMDPs) 整合的方法，用于在不确定性下实现可解释的决策，通过生成持久 (persistent) 宏动作来指导决策过程。方法利用 Linear Temporal Logic (LTL) 的 Event Calculus (EC) 片段来创建这些宏动作，并结合 Monte Carlo Tree Search (MCTS)-based POMDP 求解器，显著减少推理时间并提升鲁棒性。宏动作通过 Inductive Logic Programming (ILP) 从少量执行轨迹 (belief-action pairs) 中学习，仅需 POMDP 转换模型，而无需手动设计启发式规则。在 Pocman 和 Rocksample 基准场景中，该方法展示了更高的表达性和泛化性，比时间无关的启发式方法提供了实质性的计算效率改进。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at 9th Conference on Neurosymbolic Learning and Reasoning",
      "pdf_url": "http://arxiv.org/pdf/2505.03668v1",
      "published_date": "2025-05-06 16:08:55 UTC",
      "updated_date": "2025-05-06 16:08:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:08:54.728486"
    },
    {
      "arxiv_id": "2505.03662v1",
      "title": "Revolutionizing Brain Tumor Imaging: Generating Synthetic 3D FA Maps from T1-Weighted MRI using CycleGAN Models",
      "title_zh": "翻译失败",
      "authors": [
        "Xin Du",
        "Francesca M. Cozzi",
        "Rajesh Jena"
      ],
      "abstract": "Fractional anisotropy (FA) and directionally encoded colour (DEC) maps are\nessential for evaluating white matter integrity and structural connectivity in\nneuroimaging. However, the spatial misalignment between FA maps and\ntractography atlases hinders their effective integration into predictive\nmodels. To address this issue, we propose a CycleGAN based approach for\ngenerating FA maps directly from T1-weighted MRI scans, representing the first\napplication of this technique to both healthy and tumour-affected tissues. Our\nmodel, trained on unpaired data, produces high fidelity maps, which have been\nrigorously evaluated using Structural Similarity Index (SSIM) and Peak\nSignal-to-Noise Ratio (PSNR), demonstrating particularly robust performance in\ntumour regions. Radiological assessments further underscore the model's\npotential to enhance clinical workflows by providing an AI-driven alternative\nthat reduces the necessity for additional scans.",
      "tldr_zh": "本文提出一种基于 CycleGAN 模型的方法，从 T1-weighted MRI 扫描生成合成 3D FA 地图，以解决 FA 地图与轨迹图集的空间不对齐问题，这是首次应用于健康和肿瘤受影响组织。模型在未配对数据上训练，通过 Structural Similarity Index (SSIM) 和 Peak Signal-to-Noise Ratio (PSNR) 评估显示出高保真度，尤其在肿瘤区域表现强劲。放射学评估表明，此方法可提升临床工作流程，提供 AI 驱动的替代方案，减少额外扫描的必要性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "68U10"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.03662v1",
      "published_date": "2025-05-06 16:05:22 UTC",
      "updated_date": "2025-05-06 16:05:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:09:07.073518"
    },
    {
      "arxiv_id": "2505.03655v1",
      "title": "Counterfactual Inference for Eliminating Sentiment Bias in Recommender Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Le Pan",
        "Yuanjiang Cao",
        "Chengkai Huang",
        "Wenjie Zhang",
        "Lina Yao"
      ],
      "abstract": "Recommender Systems (RSs) aim to provide personalized recommendations for\nusers. A newly discovered bias, known as sentiment bias, uncovers a common\nphenomenon within Review-based RSs (RRSs): the recommendation accuracy of users\nor items with negative reviews deteriorates compared with users or items with\npositive reviews. Critical users and niche items are disadvantaged by such\nunfair recommendations. We study this problem from the perspective of\ncounterfactual inference with two stages. At the model training stage, we build\na causal graph and model how sentiment influences the final rating score.\nDuring the inference stage, we decouple the direct and indirect effects to\nmitigate the impact of sentiment bias and remove the indirect effect using\ncounterfactual inference. We have conducted extensive experiments, and the\nresults validate that our model can achieve comparable performance on rating\nprediction for better recommendations and effective mitigation of sentiment\nbias. To the best of our knowledge, this is the first work to employ\ncounterfactual inference on sentiment bias mitigation in RSs.",
      "tldr_zh": "该论文探讨了推荐系统（RSs）中的情感偏差（sentiment bias），即基于评论的推荐系统（RRSs）中，负面评论的用户或物品的推荐准确率较低，导致关键用户和利基物品受损。作者采用反事实推理（counterfactual inference）的双阶段方法：在模型训练阶段构建因果图（causal graph）来分析情感对评分的间接影响，在推理阶段解耦直接和间接效应以消除偏差。实验结果表明，该方法在评分预测上性能与基准相当，并有效缓解了情感偏差，这是RSs领域首次应用此技术。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03655v1",
      "published_date": "2025-05-06 16:00:41 UTC",
      "updated_date": "2025-05-06 16:00:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:09:18.951444"
    },
    {
      "arxiv_id": "2505.03654v2",
      "title": "ReGraP-LLaVA: Reasoning enabled Graph-based Personalized Large Language and Vision Assistant",
      "title_zh": "翻译失败",
      "authors": [
        "Yifan Xiang",
        "Zhenxi Zhang",
        "Bin Li",
        "Yixuan Weng",
        "Shoujun Zhou",
        "Yangfan He",
        "Keqin Li"
      ],
      "abstract": "Recent advances in personalized MLLMs enable effective capture of\nuser-specific concepts, supporting both recognition of personalized concepts\nand contextual captioning. However, humans typically explore and reason over\nrelations among objects and individuals, transcending surface-level information\nto achieve more personalized and contextual understanding. To this end,\nexisting methods may face three main limitations: Their training data lacks\nmulti-object sets in which relations among objects are learnable. Building on\nthe limited training data, their models overlook the relations between\ndifferent personalized concepts and fail to reason over them. Their experiments\nmainly focus on a single personalized concept, where evaluations are limited to\nrecognition and captioning tasks. To address the limitations, we present a new\ndataset named ReGraP, consisting of 120 sets of personalized knowledge. Each\nset includes images, KGs, and CoT QA pairs derived from the KGs, enabling more\nstructured and sophisticated reasoning pathways. We propose ReGraP-LLaVA, an\nMLLM trained with the corresponding KGs and CoT QA pairs, where soft and hard\ngraph prompting methods are designed to align KGs within the model's semantic\nspace. We establish the ReGraP Benchmark, which contains diverse task types:\nmultiple-choice, fill-in-the-blank, True/False, and descriptive questions in\nboth open- and closed-ended settings. The proposed benchmark is designed to\nevaluate the relational reasoning and knowledge-connection capability of\npersonalized MLLMs. We conduct experiments on the proposed ReGraP-LLaVA and\nother competitive MLLMs. Results show that the proposed model not only learns\npersonalized knowledge but also performs relational reasoning in responses,\nachieving the SoTA performance compared with the competitive methods. All the\ncodes and datasets are released at: https://github.com/xyfyyds/ReGraP.",
      "tldr_zh": "本论文针对现有个性化多模态大型语言模型（MLLMs）的局限性，即无法有效处理对象间关系、训练数据不足和实验单一问题，提出了新数据集 ReGraP 和模型 ReGraP-LLaVA。ReGraP 包含 120 组个性化知识，每组包括图像、知识图谱（KGs）和基于 Chain-of-Thought（CoT）的 QA 对，以支持更结构化的关系推理训练。ReGraP-LLaVA 通过软和硬图提示方法整合 KGs 和 CoT QA 对，实现对个性化概念的识别、关系推理和知识连接，并建立了 ReGraP Benchmark 来评估多种任务类型，如多选和描述性问题。实验结果显示，该模型在关系推理任务上超越了竞争方法，达到了 state-of-the-art（SoTA）性能，并已开源相关代码和数据集。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2505.03654v2",
      "published_date": "2025-05-06 16:00:13 UTC",
      "updated_date": "2025-05-19 08:25:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:09:31.371334"
    },
    {
      "arxiv_id": "2505.03648v1",
      "title": "Binding threshold units with artificial oscillatory neurons",
      "title_zh": "翻译失败",
      "authors": [
        "Vladimir Fanaskov",
        "Ivan Oseledets"
      ],
      "abstract": "Artificial Kuramoto oscillatory neurons were recently introduced as an\nalternative to threshold units. Empirical evidence suggests that oscillatory\nunits outperform threshold units in several tasks including unsupervised object\ndiscovery and certain reasoning problems. The proposed coupling mechanism for\nthese oscillatory neurons is heterogeneous, combining a generalized Kuramoto\nequation with standard coupling methods used for threshold units. In this\nresearch note, we present a theoretical framework that clearly distinguishes\noscillatory neurons from threshold units and establishes a coupling mechanism\nbetween them. We argue that, from a biological standpoint, oscillatory and\nthreshold units realise distinct aspects of neural coding: roughly, threshold\nunits model intensity of neuron firing, while oscillatory units facilitate\ninformation exchange by frequency modulation. To derive interaction between\nthese two types of units, we constrain their dynamics by focusing on dynamical\nsystems that admit Lyapunov functions. For threshold units, this leads to\nHopfield associative memory model, and for oscillatory units it yields a\nspecific form of generalized Kuramoto model. The resulting dynamical systems\ncan be naturally coupled to form a Hopfield-Kuramoto associative memory model,\nwhich also admits a Lyapunov function. Various forms of coupling are possible.\nNotably, oscillatory neurons can be employed to implement a low-rank correction\nto the weight matrix of a Hopfield network. This correction can be viewed\neither as a form of Hebbian learning or as a popular LoRA method used for\nfine-tuning of large language models. We demonstrate the practical realization\nof this particular coupling through illustrative toy experiments.",
      "tldr_zh": "这篇论文提出了一种理论框架，将人工Kuramoto振荡神经元与阈值单元区分开来，并建立它们之间的耦合机制，从生物角度来看，阈值单元模型神经元放电强度，而振荡单元通过频率调制促进信息交换。通过关注具有Lyapunov functions的动态系统，论文推导出Hopfield联想记忆模型与特定泛化Kuramoto模型的交互，形成Hopfield-Kuramoto联想记忆模型。实验结果显示，这种耦合允许各种形式，包括使用振荡神经元实现Hopfield网络权重矩阵的低秩修正（如Hebbian learning或LoRA方法），并通过玩具实验验证了其实际可行性。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03648v1",
      "published_date": "2025-05-06 15:54:52 UTC",
      "updated_date": "2025-05-06 15:54:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:09:43.750375"
    },
    {
      "arxiv_id": "2505.03646v1",
      "title": "ALMA: Aggregated Lipschitz Maximization Attack on Auto-encoders",
      "title_zh": "ALMA：针对自动编码器的聚合 Lipschitz 最大化攻击",
      "authors": [
        "Chethan Krishnamurthy Ramanaik",
        "Arjun Roy",
        "Eirini Ntoutsi"
      ],
      "abstract": "Despite the extensive use of deep autoencoders (AEs) in critical\napplications, their adversarial robustness remains relatively underexplored\ncompared to classification models. AE robustness is characterized by the\nLipschitz bounds of its components. Existing robustness evaluation frameworks\nbased on white-box attacks do not fully exploit the vulnerabilities of\nintermediate ill-conditioned layers in AEs. In the context of optimizing\nimperceptible norm-bounded additive perturbations to maximize output damage,\nexisting methods struggle to effectively propagate adversarial loss gradients\nthroughout the network, often converging to less effective perturbations. To\naddress this, we propose a novel layer-conditioning-based adversarial\noptimization objective that effectively guides the adversarial map toward\nregions of local Lipschitz bounds by enhancing loss gradient information\npropagation during attack optimization. We demonstrate through extensive\nexperiments on state-of-the-art AEs that our adversarial objective results in\nstronger attacks, outperforming existing methods in both universal and\nsample-specific scenarios. As a defense method against this attack, we\nintroduce an inference-time adversarially trained defense plugin that mitigates\nthe effects of adversarial examples.",
      "tldr_zh": "本文提出 ALMA，一种针对深度自编码器(AEs)的聚合 Lipschitz 最大化攻击，旨在解决现有白盒攻击方法在梯度传播和利用中间层脆弱性方面的不足。ALMA 通过基于层条件化的优化目标，增强损失梯度信息传播，从而更有效地生成不可察觉的范数边界扰动，以最大化输出损害。实验结果显示，该攻击在最先进 AEs 上显著优于现有方法，在通用和样本特定场景中提升攻击强度。作为防御措施，作者引入了一种推理时的对抗训练插件，用于缓解对抗样本的影响。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03646v1",
      "published_date": "2025-05-06 15:52:14 UTC",
      "updated_date": "2025-05-06 15:52:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:09:55.472920"
    },
    {
      "arxiv_id": "2505.03643v1",
      "title": "BURNS: Backward Underapproximate Reachability for Neural-Feedback-Loop Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Chelsea Sidrane",
        "Jana Tumova"
      ],
      "abstract": "Learning-enabled planning and control algorithms are increasingly popular,\nbut they often lack rigorous guarantees of performance or safety. We introduce\nan algorithm for computing underapproximate backward reachable sets of\nnonlinear discrete time neural feedback loops. We then use the backward\nreachable sets to check goal-reaching properties. Our algorithm is based on\noverapproximating the system dynamics function to enable computation of\nunderapproximate backward reachable sets through solutions of mixed-integer\nlinear programs. We rigorously analyze the soundness of our algorithm and\ndemonstrate it on a numerical example. Our work expands the class of properties\nthat can be verified for learning-enabled systems.",
      "tldr_zh": "该研究提出了一种名为 BURNS 的算法，用于计算非线性离散时间神经反馈环路（neural feedback loops）的 underapproximate backward reachable sets，以验证学习启用规划和控制系统的性能与安全。算法通过 overapproximating 系统动态函数，并利用 mixed-integer linear programs 的解决方案，来精确计算 backward reachable sets，从而检查目标到达属性。研究分析了算法的 soundness，并通过数值例子进行了演示，扩展了可验证的学习启用系统的属性类别。",
      "categories": [
        "cs.AI",
        "cs.LO",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03643v1",
      "published_date": "2025-05-06 15:50:43 UTC",
      "updated_date": "2025-05-06 15:50:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:10:06.299565"
    },
    {
      "arxiv_id": "2505.03641v1",
      "title": "Synthesizing Images on Perceptual Boundaries of ANNs for Uncovering and Manipulating Human Perceptual Variability",
      "title_zh": "翻译失败",
      "authors": [
        "Chen Wei",
        "Chi Zhang",
        "Jiachen Zou",
        "Haotian Deng",
        "Dietmar Heinke",
        "Quanying Liu"
      ],
      "abstract": "Human decision-making in cognitive tasks and daily life exhibits considerable\nvariability, shaped by factors such as task difficulty, individual preferences,\nand personal experiences. Understanding this variability across individuals is\nessential for uncovering the perceptual and decision-making mechanisms that\nhumans rely on when faced with uncertainty and ambiguity. We present a\ncomputational framework BAM (Boundary Alignment & Manipulation framework) that\ncombines perceptual boundary sampling in ANNs and human behavioral experiments\nto systematically investigate this phenomenon. Our perceptual boundary sampling\nalgorithm generates stimuli along ANN decision boundaries that intrinsically\ninduce significant perceptual variability. The efficacy of these stimuli is\nempirically validated through large-scale behavioral experiments involving 246\nparticipants across 116,715 trials, culminating in the variMNIST dataset\ncontaining 19,943 systematically annotated images. Through personalized model\nalignment and adversarial generation, we establish a reliable method for\nsimultaneously predicting and manipulating the divergent perceptual decisions\nof pairs of participants. This work bridges the gap between computational\nmodels and human individual difference research, providing new tools for\npersonalized perception analysis.",
      "tldr_zh": "本研究探讨了人类感知决策的变异性（受任务难度、偏好和经历影响），并提出 BAM（Boundary Alignment & Manipulation framework）框架，通过 ANN（人工神经网络）的感知边界采样算法和人类行为实验系统地调查这一现象。该算法生成沿 ANN 决策边界的刺激，以诱发显著感知变异，并通过大规模实验（涉及246名参与者和116,715次试验）验证其有效性，创建了包含19,943张标注图像的 variMNIST 数据集。通过个性化模型对齐和对抗生成技术，该框架实现了对参与者之间不同感知决策的预测和操纵，为桥接计算模型与人类个体差异研究提供了新工具。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "accepted at ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.03641v1",
      "published_date": "2025-05-06 15:44:42 UTC",
      "updated_date": "2025-05-06 15:44:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:10:19.050460"
    },
    {
      "arxiv_id": "2505.06274v1",
      "title": "PARM: Multi-Objective Test-Time Alignment via Preference-Aware Autoregressive Reward Model",
      "title_zh": "翻译失败",
      "authors": [
        "Baijiong Lin",
        "Weisen Jiang",
        "Yuancheng Xu",
        "Hao Chen",
        "Ying-Cong Chen"
      ],
      "abstract": "Multi-objective test-time alignment aims to adapt large language models\n(LLMs) to diverse multi-dimensional user preferences during inference while\nkeeping LLMs frozen. Recently, GenARM (Xu et al., 2025) first independently\ntrains Autoregressive Reward Models (ARMs) for each preference dimension\nwithout awareness of each other, then combines their outputs based on\nuser-specific preference vectors during inference to achieve multi-objective\ntest-time alignment, leading to two key limitations: the need for\n\\textit{multiple} ARMs increases the inference cost, and the separate training\nof ARMs causes the misalignment between the guided generation and the user\npreferences. To address these issues, we propose Preference-aware ARM (PARM), a\nsingle unified ARM trained across all preference dimensions. PARM uses our\nproposed Preference-Aware Bilinear Low-Rank Adaptation (PBLoRA), which employs\na bilinear form to condition the ARM on preference vectors, enabling it to\nachieve precise control over preference trade-offs during inference.\nExperiments demonstrate that PARM reduces inference costs and achieves better\nalignment with preference vectors compared with existing methods. Additionally,\nPARM enables weak-to-strong guidance, allowing a smaller PARM to guide a larger\nfrozen LLM without expensive training, making multi-objective alignment\naccessible with limited computing resources. The code is available at\nhttps://github.com/Baijiong-Lin/PARM.",
      "tldr_zh": "该论文提出 PARM，一种基于 Preference-Aware Autoregressive Reward Model 的方法，用于实现 Multi-Objective Test-Time Alignment，帮助大型语言模型 (LLMs) 在推理阶段适应多维用户偏好，同时保持模型冻结。PARM 通过单一统一的 Autoregressive Reward Models (ARMs) 和我们提出的 Preference-Aware Bilinear Low-Rank Adaptation (PBLoRA) 技术，使用双线性形式根据偏好向量调节模型，从而精确控制偏好权衡并解决现有方法的推理成本高和训练不协调问题。实验结果表明，PARM 比基线方法降低了推理成本、提升了偏好对齐效果，并支持 weak-to-strong guidance，允许较小的 PARM 指导更大的冻结 LLM，在有限计算资源下实现高效的多目标对齐。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.06274v1",
      "published_date": "2025-05-06 15:42:31 UTC",
      "updated_date": "2025-05-06 15:42:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:10:31.782521"
    },
    {
      "arxiv_id": "2505.06273v2",
      "title": "Policy-labeled Preference Learning: Is Preference Enough for RLHF?",
      "title_zh": "翻译失败",
      "authors": [
        "Taehyun Cho",
        "Seokhun Ju",
        "Seungyub Han",
        "Dohyeong Kim",
        "Kyungjae Lee",
        "Jungwoo Lee"
      ],
      "abstract": "To design rewards that align with human goals, Reinforcement Learning from\nHuman Feedback (RLHF) has emerged as a prominent technique for learning reward\nfunctions from human preferences and optimizing policies via reinforcement\nlearning algorithms. However, existing RLHF methods often misinterpret\ntrajectories as being generated by an optimal policy, causing inaccurate\nlikelihood estimation and suboptimal learning. Inspired by Direct Preference\nOptimization framework which directly learns optimal policy without explicit\nreward, we propose policy-labeled preference learning (PPL), to resolve\nlikelihood mismatch issues by modeling human preferences with regret, which\nreflects behavior policy information. We also provide a contrastive KL\nregularization, derived from regret-based principles, to enhance RLHF in\nsequential decision making. Experiments in high-dimensional continuous control\ntasks demonstrate PPL's significant improvements in offline RLHF performance\nand its effectiveness in online settings.",
      "tldr_zh": "该研究质疑了基于人类反馈的强化学习（RLHF）是否足够有效，指出现有方法因误将轨迹视为最优策略生成而导致似然估计不准确和学习次优。作者提出 policy-labeled preference learning (PPL) 方法，受 Direct Preference Optimization 启发，通过使用 regret 来建模人类偏好，从而融入行为策略信息并解决似然不匹配问题；同时，引入基于 regret 的对比 KL regularization 以提升 RLHF 在顺序决策中的性能。在高维连续控制任务的实验中，PPL 显著提高了离线 RLHF 的表现，并在在线环境中表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06273v2",
      "published_date": "2025-05-06 15:09:55 UTC",
      "updated_date": "2025-05-13 04:50:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:10:41.848337"
    },
    {
      "arxiv_id": "2505.03859v1",
      "title": "Deepfakes on Demand: the rise of accessible non-consensual deepfake image generators",
      "title_zh": "翻译失败",
      "authors": [
        "Will Hawkins",
        "Chris Russell",
        "Brent Mittelstadt"
      ],
      "abstract": "Advances in multimodal machine learning have made text-to-image (T2I) models\nincreasingly accessible and popular. However, T2I models introduce risks such\nas the generation of non-consensual depictions of identifiable individuals,\notherwise known as deepfakes. This paper presents an empirical study exploring\nthe accessibility of deepfake model variants online. Through a metadata\nanalysis of thousands of publicly downloadable model variants on two popular\nrepositories, Hugging Face and Civitai, we demonstrate a huge rise in easily\naccessible deepfake models. Almost 35,000 examples of publicly downloadable\ndeepfake model variants are identified, primarily hosted on Civitai. These\ndeepfake models have been downloaded almost 15 million times since November\n2022, with the models targeting a range of individuals from global celebrities\nto Instagram users with under 10,000 followers. Both Stable Diffusion and Flux\nmodels are used for the creation of deepfake models, with 96% of these\ntargeting women and many signalling intent to generate non-consensual intimate\nimagery (NCII). Deepfake model variants are often created via the\nparameter-efficient fine-tuning technique known as low rank adaptation (LoRA),\nrequiring as few as 20 images, 24GB VRAM, and 15 minutes of time, making this\nprocess widely accessible via consumer-grade computers. Despite these models\nviolating the Terms of Service of hosting platforms, and regulation seeking to\nprevent dissemination, these results emphasise the pressing need for greater\naction to be taken against the creation of deepfakes and NCII.",
      "tldr_zh": "这项研究通过对Hugging Face和Civitai两个仓库的元数据分析，探讨了文本到图像(T2I)模型的普及如何导致非共识性deepfake图像生成器的激增，揭示了近35,000个可公开下载的deepfake模型变体，主要托管在Civitai，并已被下载约1,500万次。  \n这些模型多针对女性（占96%），涉及从全球名人到小影响者（如Instagram用户），并经常使用低秩适配(LoRA)技术，仅需20张图像、24GB VRAM和15分钟即可在消费级计算机上创建。  \n尽管这些模型违反了平台的服务条款和相关法规，该研究强调了迫切需要采取更强有力的措施来防止deepfakes和非共识性亲密图像(NCII)的生成与传播。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CV",
        "68T01"
      ],
      "primary_category": "cs.CY",
      "comment": "13 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.03859v1",
      "published_date": "2025-05-06 15:00:59 UTC",
      "updated_date": "2025-05-06 15:00:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:10:56.363364"
    },
    {
      "arxiv_id": "2505.03586v3",
      "title": "Rainbow Delay Compensation: A Multi-Agent Reinforcement Learning Framework for Mitigating Delayed Observation",
      "title_zh": "Rainbow Delay Compensation：多智能体强化学习框架，用于缓解延迟观察",
      "authors": [
        "Songchen Fu",
        "Siang Chen",
        "Shaojing Zhao",
        "Letian Bai",
        "Ta Li",
        "Yonghong Yan"
      ],
      "abstract": "In real-world multi-agent systems (MASs), observation delays are ubiquitous,\npreventing agents from making decisions based on the environment's true state.\nAn individual agent's local observation often consists of multiple components\nfrom other agents or dynamic entities in the environment. These discrete\nobservation components with varying delay characteristics pose significant\nchallenges for multi-agent reinforcement learning (MARL). In this paper, we\nfirst formulate the decentralized stochastic individual delay partially\nobservable Markov decision process (DSID-POMDP) by extending the standard\nDec-POMDP. We then propose the Rainbow Delay Compensation (RDC), a MARL\ntraining framework for addressing stochastic individual delays, along with\nrecommended implementations for its constituent modules. We implement the\nDSID-POMDP's observation generation pattern using standard MARL benchmarks,\nincluding MPE and SMAC. Experiments demonstrate that baseline MARL methods\nsuffer severe performance degradation under fixed and unfixed delays. The\nRDC-enhanced approach mitigates this issue, remarkably achieving ideal\ndelay-free performance in certain delay scenarios while maintaining\ngeneralizability. Our work provides a novel perspective on multi-agent delayed\nobservation problems and offers an effective solution framework. The source\ncode is available at https://anonymous.4open.science/r/RDC-pymarl-4512/.",
      "tldr_zh": "该论文针对多智能体系统(MASs)中普遍存在的观察延迟问题，扩展了标准 Dec-POMDP 模型，制定了去中心化随机个体延迟部分可观察 Markov 决策过程(DSID-POMDP)，以更好地处理代理本地观察的延迟特性。作者提出了 Rainbow Delay Compensation (RDC) 框架，这是一种 MARL 训练框架，结合推荐模块实现来缓解随机个体延迟的影响。实验在 MPE 和 SMAC 基准上表明，基线 MARL 方法在固定和非固定延迟下性能严重下降，而 RDC 增强方法显著改善了这一问题，在某些场景下实现了理想的无延迟性能，并保持了泛化性。该工作为多智能体延迟观察问题提供了新视角和有效的解决方案框架。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "68T07 (Primary), 68T20, 68T42 (Secondary)",
        "I.2"
      ],
      "primary_category": "cs.MA",
      "comment": "The code will be open-sourced in the RDC-pymarl project under\n  https://github.com/linkjoker1006",
      "pdf_url": "http://arxiv.org/pdf/2505.03586v3",
      "published_date": "2025-05-06 14:47:56 UTC",
      "updated_date": "2025-05-12 09:11:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:11:07.869194"
    },
    {
      "arxiv_id": "2505.03584v1",
      "title": "BCause: Human-AI collaboration to improve hybrid mapping and ideation in argumentation-grounded deliberation",
      "title_zh": "翻译失败",
      "authors": [
        "Lucas Anastasiou",
        "Anna De Liddo"
      ],
      "abstract": "Public deliberation, as in open discussion of issues of public concern, often\nsuffers from scattered and shallow discourse, poor sensemaking, and a\ndisconnect from actionable policy outcomes. This paper introduces BCause, a\ndiscussion system leveraging generative AI and human-machine collaboration to\ntransform unstructured dialogue around public issues (such as urban living,\npolicy changes, and current socio-economic transformations) into structured,\nactionable democratic processes. We present three innovations: (i) importing\nand transforming unstructured transcripts into argumentative discussions, (ii)\ngeo-deliberated problem-sensing via a Telegram bot for local issue reporting,\nand (iii) smart reporting with customizable widgets (e.g., summaries, topic\nmodelling, policy recommendations, clustered arguments). The system's human-AI\npartnership preserves critical human participation to ensure ethical oversight,\ncontextual relevance, and creative synthesis.",
      "tldr_zh": "这篇论文介绍了 BCause 系统，它通过 Human-AI collaboration 提升 argumentation-grounded deliberation 中的混合映射和构思，旨在解决公共审议（如城市生活和政策变化讨论）中散乱、浅薄和与行动脱节的问题。系统创新包括：(i) 将非结构化对话转变成结构化论证讨论，(ii) 使用 Telegram 机器人进行基于地理位置的本地问题感知，以及 (iii) 提供可定制的智能报告小部件，如摘要、主题建模、政策推荐和聚类论证。BCause 强调人类参与以确保伦理监督、上下文相关性和创意合成，从而将公共讨论转化为可行动的民主过程。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY",
        "I.2"
      ],
      "primary_category": "cs.HC",
      "comment": "5 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.03584v1",
      "published_date": "2025-05-06 14:43:49 UTC",
      "updated_date": "2025-05-06 14:43:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:11:20.034375"
    },
    {
      "arxiv_id": "2505.03574v1",
      "title": "LlamaFirewall: An open source guardrail system for building secure AI agents",
      "title_zh": "LlamaFirewall：一个开源的安全防护系统，用于构建安全的 AI 代理",
      "authors": [
        "Sahana Chennabasappa",
        "Cyrus Nikolaidis",
        "Daniel Song",
        "David Molnar",
        "Stephanie Ding",
        "Shengye Wan",
        "Spencer Whitman",
        "Lauren Deason",
        "Nicholas Doucette",
        "Abraham Montilla",
        "Alekhya Gampa",
        "Beto de Paola",
        "Dominik Gabi",
        "James Crnkovich",
        "Jean-Christophe Testud",
        "Kat He",
        "Rashnil Chaturvedi",
        "Wu Zhou",
        "Joshua Saxe"
      ],
      "abstract": "Large language models (LLMs) have evolved from simple chatbots into\nautonomous agents capable of performing complex tasks such as editing\nproduction code, orchestrating workflows, and taking higher-stakes actions\nbased on untrusted inputs like webpages and emails. These capabilities\nintroduce new security risks that existing security measures, such as model\nfine-tuning or chatbot-focused guardrails, do not fully address. Given the\nhigher stakes and the absence of deterministic solutions to mitigate these\nrisks, there is a critical need for a real-time guardrail monitor to serve as a\nfinal layer of defense, and support system level, use case specific safety\npolicy definition and enforcement. We introduce LlamaFirewall, an open-source\nsecurity focused guardrail framework designed to serve as a final layer of\ndefense against security risks associated with AI Agents. Our framework\nmitigates risks such as prompt injection, agent misalignment, and insecure code\nrisks through three powerful guardrails: PromptGuard 2, a universal jailbreak\ndetector that demonstrates clear state of the art performance; Agent Alignment\nChecks, a chain-of-thought auditor that inspects agent reasoning for prompt\ninjection and goal misalignment, which, while still experimental, shows\nstronger efficacy at preventing indirect injections in general scenarios than\npreviously proposed approaches; and CodeShield, an online static analysis\nengine that is both fast and extensible, aimed at preventing the generation of\ninsecure or dangerous code by coding agents. Additionally, we include\neasy-to-use customizable scanners that make it possible for any developer who\ncan write a regular expression or an LLM prompt to quickly update an agent's\nsecurity guardrails.",
      "tldr_zh": "该研究介绍了 LlamaFirewall，一个开源的安全守卫框架，旨在为 LLMs 驱动的 AI 代理提供最终防御层，解决如提示注入、代理错位和不安全代码等风险，这些风险源于代理处理复杂任务的能力。框架包括三个关键组件：PromptGuard 2，一种先进的通用越狱检测器，展示了领先性能；Agent Alignment Checks，一种基于链式思维的审计器，用于检测代理推理中的注入和目标错位；以及 CodeShield，一个快速可扩展的在线静态分析引擎，防止生成危险代码。此外，LlamaFirewall 提供易于自定义的扫描器，允许开发者通过正则表达式或 LLM 提示快速增强代理的安全性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03574v1",
      "published_date": "2025-05-06 14:34:21 UTC",
      "updated_date": "2025-05-06 14:34:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:11:33.878797"
    },
    {
      "arxiv_id": "2505.03570v1",
      "title": "OSUniverse: Benchmark for Multimodal GUI-navigation AI Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Mariya Davydova",
        "Daniel Jeffries",
        "Patrick Barker",
        "Arturo Márquez Flores",
        "Sinéad Ryan"
      ],
      "abstract": "In this paper, we introduce OSUniverse: a benchmark of complex, multimodal\ndesktop-oriented tasks for advanced GUI-navigation AI agents that focuses on\nease of use, extensibility, comprehensive coverage of test cases, and automated\nvalidation. We divide the tasks in increasing levels of complexity, from basic\nprecision clicking to multistep, multiapplication tests requiring dexterity,\nprecision, and clear thinking from the agent. In version one of the benchmark,\npresented here, we have calibrated the complexity of the benchmark test cases\nto ensure that the SOTA (State of the Art) agents (at the time of publication)\ndo not achieve results higher than 50%, while the average white collar worker\ncan perform all these tasks with perfect accuracy. The benchmark can be scored\nmanually, but we also introduce an automated validation mechanism that has an\naverage error rate less than 2%. Therefore, this benchmark presents solid\nground for fully automated measuring of progress, capabilities and the\neffectiveness of GUI-navigation AI agents over the short and medium-term\nhorizon. The source code of the benchmark is available at\nhttps://github.com/agentsea/osuniverse.",
      "tldr_zh": "本文提出OSUniverse基准，用于评估多模态GUI-navigation AI代理在复杂桌面任务中的性能。该基准设计了从基本精确点击到多步多应用测试的递增复杂度任务，强调易用性、可扩展性和全面覆盖，确保SOTA代理的成绩不超过50%，而普通白领工人可完美完成。OSUniverse引入自动验证机制，平均错误率小于2%，支持手动和自动化评分，便于长期跟踪AI代理的进步和有效性。源代码可在GitHub上获取。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03570v1",
      "published_date": "2025-05-06 14:29:47 UTC",
      "updated_date": "2025-05-06 14:29:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:11:43.094929"
    },
    {
      "arxiv_id": "2505.03562v1",
      "title": "Real-Time Person Image Synthesis Using a Flow Matching Model",
      "title_zh": "基于流匹配模型的实时人物图像合成",
      "authors": [
        "Jiwoo Jeong",
        "Kirok Kim",
        "Wooju Kim",
        "Nam-Joon Kim"
      ],
      "abstract": "Pose-Guided Person Image Synthesis (PGPIS) generates realistic person images\nconditioned on a target pose and a source image. This task plays a key role in\nvarious real-world applications, such as sign language video generation, AR/VR,\ngaming, and live streaming. In these scenarios, real-time PGPIS is critical for\nproviding immediate visual feedback and maintaining user immersion.However,\nachieving real-time performance remains a significant challenge due to the\ncomplexity of synthesizing high-fidelity images from diverse and dynamic human\nposes. Recent diffusion-based methods have shown impressive image quality in\nPGPIS, but their slow sampling speeds hinder deployment in time-sensitive\napplications. This latency is particularly problematic in tasks like generating\nsign language videos during live broadcasts, where rapid image updates are\nrequired. Therefore, developing a fast and reliable PGPIS model is a crucial\nstep toward enabling real-time interactive systems. To address this challenge,\nwe propose a generative model based on flow matching (FM). Our approach enables\nfaster, more stable, and more efficient training and sampling. Furthermore, the\nproposed model supports conditional generation and can operate in latent space,\nmaking it especially suitable for real-time PGPIS applications where both speed\nand quality are critical. We evaluate our proposed method, Real-Time Person\nImage Synthesis Using a Flow Matching Model (RPFM), on the widely used\nDeepFashion dataset for PGPIS tasks. Our results show that RPFM achieves\nnear-real-time sampling speeds while maintaining performance comparable to the\nstate-of-the-art models. Our methodology trades off a slight, acceptable\ndecrease in generated-image accuracy for over a twofold increase in generation\nspeed, thereby ensuring real-time performance.",
      "tldr_zh": "本论文针对姿势引导的个人图像合成（PGPIS）任务，提出了一种基于流匹配（Flow Matching）模型的实时生成方法，以解决现有扩散模型在实时应用（如手语视频生成、AR/VR 和直播）中的速度瓶颈问题。该方法通过更快的训练和采样过程，支持条件生成并在潜在空间操作，实现高效且稳定的图像合成。实验在 DeepFashion 数据集上评估显示，提出的 RPFM 模型在保持与最先进模型相当性能的同时，采样速度提高两倍以上，仅以微小准确性损失为代价，从而满足实时交互系统的需求。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03562v1",
      "published_date": "2025-05-06 14:13:44 UTC",
      "updated_date": "2025-05-06 14:13:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:11:55.932967"
    },
    {
      "arxiv_id": "2505.03561v1",
      "title": "Ergodic Generative Flows",
      "title_zh": "遍历生成流",
      "authors": [
        "Leo Maxime Brunswic",
        "Mateo Clemente",
        "Rui Heng Yang",
        "Adam Sigal",
        "Amir Rasouli",
        "Yinchuan Li"
      ],
      "abstract": "Generative Flow Networks (GFNs) were initially introduced on directed acyclic\ngraphs to sample from an unnormalized distribution density. Recent works have\nextended the theoretical framework for generative methods allowing more\nflexibility and enhancing application range. However, many challenges remain in\ntraining GFNs in continuous settings and for imitation learning (IL), including\nintractability of flow-matching loss, limited tests of non-acyclic training,\nand the need for a separate reward model in imitation learning. The present\nwork proposes a family of generative flows called Ergodic Generative Flows\n(EGFs) which are used to address the aforementioned issues. First, we leverage\nergodicity to build simple generative flows with finitely many globally defined\ntransformations (diffeomorphisms) with universality guarantees and tractable\nflow-matching loss (FM loss). Second, we introduce a new loss involving\ncross-entropy coupled to weak flow-matching control, coined KL-weakFM loss. It\nis designed for IL training without a separate reward model. We evaluate\nIL-EGFs on toy 2D tasks and real-world datasets from NASA on the sphere, using\nthe KL-weakFM loss. Additionally, we conduct toy 2D reinforcement learning\nexperiments with a target reward, using the FM loss.",
      "tldr_zh": "本研究提出了一种新的生成流框架Ergodic Generative Flows (EGFs)，旨在解决Generative Flow Networks (GFNs)在连续设置和imitation learning (IL)中的挑战，包括流匹配损失(flow-matching loss)的不可计算性、非环训练的局限性，以及IL中对单独奖励模型的需求。EGFs利用ergodicity构建简单生成流，通过有限的全局定义变换(diffeomorphisms)实现通用性和可计算的FM loss。作者引入了KL-weakFM损失函数，该函数结合交叉熵和弱流匹配控制，用于IL训练，而无需额外奖励模型。在实验中，IL-EGFs在2D玩具任务和NASA真实世界数据集上表现良好，使用FM loss在2D强化学习任务中也取得了积极结果。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.DG",
        "math.DS",
        "37A25, 68T07, 68W20, 68Q87, 68T99"
      ],
      "primary_category": "cs.LG",
      "comment": "20 pages, 5 figures, 1 table, accepted at ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.03561v1",
      "published_date": "2025-05-06 14:13:21 UTC",
      "updated_date": "2025-05-06 14:13:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:12:09.016112"
    },
    {
      "arxiv_id": "2505.03560v1",
      "title": "Rapid AI-based generation of coverage paths for dispensing applications",
      "title_zh": "快速基于AI的覆盖",
      "authors": [
        "Simon Baeuerle",
        "Ian F. Mendonca",
        "Kristof Van Laerhoven",
        "Ralf Mikut",
        "Andreas Steimer"
      ],
      "abstract": "Coverage Path Planning of Thermal Interface Materials (TIM) plays a crucial\nrole in the design of power electronics and electronic control units. Up to\nnow, this is done manually by experts or by using optimization approaches with\na high computational effort. We propose a novel AI-based approach to generate\ndispense paths for TIM and similar dispensing applications. It is a drop-in\nreplacement for optimization-based approaches. An Artificial Neural Network\n(ANN) receives the target cooling area as input and directly outputs the\ndispense path. Our proposed setup does not require labels and we show its\nfeasibility on multiple target areas. The resulting dispense paths can be\ndirectly transferred to automated manufacturing equipment and do not exhibit\nair entrapments. The approach of using an ANN to predict process parameters for\na desired target state in real-time could potentially be transferred to other\nmanufacturing processes.",
      "tldr_zh": "论文提出了一种基于人工智能的快速方法，用于生成Thermal Interface Materials (TIM) 的覆盖路径，旨在取代手动或计算密集的优化方法，以提升电力电子和电子控制单元的设计效率。方法利用Artificial Neural Network (ANN) 直接从目标冷却区域输入输出分配路径，无需标签，并在多个目标区域上验证了其可行性。生成的路径可直接应用于自动化制造设备，避免空气夹带，并展示了ANN 在实时预测过程参数方面的潜力，可扩展到其他制造过程。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03560v1",
      "published_date": "2025-05-06 14:13:20 UTC",
      "updated_date": "2025-05-06 14:13:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:12:19.262689"
    },
    {
      "arxiv_id": "2505.03557v1",
      "title": "Generating Synthetic Data via Augmentations for Improved Facial Resemblance in DreamBooth and InstantID",
      "title_zh": "通过增强生成合成数据，以改善 DreamBooth 和 InstantID 中的面部相似度",
      "authors": [
        "Koray Ulusan",
        "Benjamin Kiefer"
      ],
      "abstract": "The personalization of Stable Diffusion for generating professional portraits\nfrom amateur photographs is a burgeoning area, with applications in various\ndownstream contexts. This paper investigates the impact of augmentations on\nimproving facial resemblance when using two prominent personalization\ntechniques: DreamBooth and InstantID. Through a series of experiments with\ndiverse subject datasets, we assessed the effectiveness of various augmentation\nstrategies on the generated headshots' fidelity to the original subject. We\nintroduce FaceDistance, a wrapper around FaceNet, to rank the generations based\non facial similarity, which aided in our assessment. Ultimately, this research\nprovides insights into the role of augmentations in enhancing facial\nresemblance in SDXL-generated portraits, informing strategies for their\neffective deployment in downstream applications.",
      "tldr_zh": "这篇论文探讨了通过增强技术（augmentations）生成合成数据，以提升 DreamBooth 和 InstantID 在 Stable Diffusion 中的面部相似度，针对从业余照片生成专业肖像的应用场景。研究者通过一系列实验评估了不同增强策略对生成头像保真度的影响，并引入了 FaceDistance（基于 FaceNet 的评估工具）来量化面部相似度排名。结果表明，这些策略显著提高了 SDXL 生成肖像的精确性，并为下游应用提供了有效的部署指导。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to CVPR 2025 Workshop \"Synthetic Data for Computer Vision\n  Workshop\", https://syndata4cv.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2505.03557v1",
      "published_date": "2025-05-06 14:11:02 UTC",
      "updated_date": "2025-05-06 14:11:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:12:31.061043"
    },
    {
      "arxiv_id": "2505.03553v1",
      "title": "A Hashgraph-Inspired Consensus Mechanism for Reliable Multi-Model Reasoning",
      "title_zh": "一种受 Hashgraph 启发的共识机制，用于可靠的多模型推理",
      "authors": [
        "Kolawole E. Ogunsina",
        "Morayo A. Ogunsina"
      ],
      "abstract": "Inconsistent outputs and hallucinations from large language models (LLMs) are\nmajor obstacles to reliable AI systems. When different proprietary reasoning\nmodels (RMs), such as those by OpenAI, Google, Anthropic, DeepSeek, and xAI,\nare given the same complex request, they often produce divergent results due to\nvariations in training and inference. This paper proposes a novel consensus\nmechanism, inspired by distributed ledger technology, to validate and converge\nthese outputs, treating each RM as a black-box peer. Building on the Hashgraph\nconsensus algorithm, our approach employs gossip-about-gossip communication and\nvirtual voting to achieve agreement among an ensemble of RMs. We present an\narchitectural design for a prototype system in which RMs iteratively exchange\nand update their answers, using information from each round to improve accuracy\nand confidence in subsequent rounds. This approach goes beyond simple majority\nvoting by incorporating the knowledge and cross-verification content of every\nmodel. We justify the feasibility of this Hashgraph-inspired consensus for AI\nensembles and outline its advantages over traditional ensembling techniques in\nreducing nonfactual outputs. Preliminary considerations for implementation,\nevaluation criteria for convergence and accuracy, and potential challenges are\ndiscussed. The proposed mechanism demonstrates a promising direction for\nmulti-agent AI systems to self-validate and deliver high-fidelity responses in\ncomplex tasks.",
      "tldr_zh": "这篇论文针对大型语言模型(LLMs)的不一致输出和幻觉问题，提出了一种受 Hashgraph 启发的共识机制，用于多模型推理的可靠验证。\n该机制将不同推理模型(RMs)，如 OpenAI 和 Google 的模型，视为黑盒对等体，通过 gossip-about-gossip 通信和虚拟投票，实现模型间的迭代交流和答案更新，从而提高准确性和置信度。\n与传统集成技术相比，这种方法超越简单多数投票，利用知识交叉验证减少非事实输出，并为多代理 AI 系统提供自验证的高保真响应方向。",
      "categories": [
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.AI",
      "comment": "15 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.03553v1",
      "published_date": "2025-05-06 14:05:12 UTC",
      "updated_date": "2025-05-06 14:05:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:12:44.530779"
    },
    {
      "arxiv_id": "2505.03547v1",
      "title": "STORY2GAME: Generating (Almost) Everything in an Interactive Fiction Game",
      "title_zh": "STORY2GAME：生成互动小说游戏中的（几乎）所有内容",
      "authors": [
        "Eric Zhou",
        "Shreyas Basavatia",
        "Moontashir Siam",
        "Zexin Chen",
        "Mark O. Riedl"
      ],
      "abstract": "We introduce STORY2GAME, a novel approach to using Large Language Models to\ngenerate text-based interactive fiction games that starts by generating a\nstory, populates the world, and builds the code for actions in a game engine\nthat enables the story to play out interactively. Whereas a given set of\nhard-coded actions can artificially constrain story generation, the ability to\ngenerate actions means the story generation process can be more open-ended but\nstill allow for experiences that are grounded in a game state. The key to\nsuccessful action generation is to use LLM-generated preconditions and effects\nof actions in the stories as guides for what aspects of the game state must be\ntracked and changed by the game engine when a player performs an action. We\nalso introduce a technique for dynamically generating new actions to\naccommodate the player's desire to perform actions that they think of that are\nnot part of the story. Dynamic action generation may require on-the-fly updates\nto the game engine's state representation and revision of previously generated\nactions. We evaluate the success rate of action code generation with respect to\nwhether a player can interactively play through the entire generated story.",
      "tldr_zh": "该研究提出 STORY2GAME，一种利用 Large Language Models (LLMs) 生成基于文本的互动小说游戏的方法，该过程从生成故事开始，然后填充游戏世界并构建游戏引擎代码以支持互动动作。核心创新在于使用 LLM 生成的动作前置条件和效果来指导游戏状态的跟踪和变化，确保故事生成更具开放性同时保持与游戏状态的 groundedness。论文还引入动态生成新动作的技术，能够实时更新游戏引擎的状态和修改现有动作，以适应玩家未预设的想法。最后，通过评估玩家是否能完整互动玩完生成的故事，证明了动作代码生成的成功率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03547v1",
      "published_date": "2025-05-06 14:00:41 UTC",
      "updated_date": "2025-05-06 14:00:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:12:57.365214"
    },
    {
      "arxiv_id": "2505.03522v1",
      "title": "Optimization of Module Transferability in Single Image Super-Resolution: Universality Assessment and Cycle Residual Blocks",
      "title_zh": "翻译失败",
      "authors": [
        "Haotong Cheng",
        "Zhiqi Zhang",
        "Hao Li",
        "Xinshang Zhang"
      ],
      "abstract": "Deep learning has substantially advanced the Single Image Super-Resolution\n(SISR). However, existing researches have predominantly focused on raw\nperformance gains, with little attention paid to quantifying the\ntransferability of architectural components. In this paper, we introduce the\nconcept of \"Universality\" and its associated definitions which extend the\ntraditional notion of \"Generalization\" to encompass the modules' ease of\ntransferability, thus revealing the relationships between module universality\nand model generalizability. Then we propose the Universality Assessment\nEquation (UAE), a metric for quantifying how readily a given module could be\ntransplanted across models. Guided by the UAE results of standard residual\nblocks and other plug-and-play modules, we further design two optimized\nmodules, Cycle Residual Block (CRB) and Depth-Wise Cycle Residual Block (DCRB).\nThrough comprehensive experiments on natural-scene benchmarks, remote-sensing\ndatasets, extreme-industrial imagery and on-device deployments, we demonstrate\nthat networks embedded with the proposed plug-and-play modules outperform\nseveral state-of-the-arts, reaching a PSNR enhancement of up to 0.83dB or\nenabling a 71.3% reduction in parameters with negligible loss in reconstruction\nfidelity.",
      "tldr_zh": "本研究聚焦于单图像超分辨率(Single Image Super-Resolution, SISR)中模块的可转移性优化，引入了“Universality”概念来扩展传统“Generalization”，强调模块在模型间的易转移性。作者提出了 Universality Assessment Equation (UAE) 指标，用于量化模块的转移潜力，并据此设计了两种优化模块：Cycle Residual Block (CRB) 和 Depth-Wise Cycle Residual Block (DCRB)。通过在自然场景、遥感数据、工业图像和设备部署上的全面实验，嵌入这些模块的网络比现有方法提升 PSNR 最高达 0.83 dB，或实现参数减少 71.3% 而几乎不影响重建质量。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03522v1",
      "published_date": "2025-05-06 13:35:59 UTC",
      "updated_date": "2025-05-06 13:35:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:13:08.622174"
    },
    {
      "arxiv_id": "2505.06272v1",
      "title": "A Sensitivity-Driven Expert Allocation Method in LoRA-MoE for Efficient Fine-Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Junzhou Xu",
        "Boyu Diao"
      ],
      "abstract": "As deep learning models expand, the pre-training-fine-tuning paradigm has\nbecome the standard approach for handling various downstream tasks. However,\nshared parameters can lead to diminished performance when dealing with complex\ndatasets involving multiple tasks. While introducing Mixture-of-Experts (MoE)\nmethods has alleviated this issue to some extent, it also significantly\nincreases the number of parameters required for fine-tuning and training time,\nintroducing greater parameter redundancy. To address these challenges, we\npropose a method for allocating expert numbers based on parameter sensitivity\nLoRA-SMoE (A Sensitivity-Driven Expert Allocation Method in LoRA-MoE for\nEfficient Fine-Tuning). This method rapidly assesses the sensitivity of\ndifferent tasks to parameters by sampling a small amount of data and using\ngradient information. It then adaptively allocates expert numbers within a\ngiven budget. The process maintains comparable memory consumption to LoRA\n(Low-Rank Adaptation) while ensuring an efficient and resource-friendly\nfine-tuning procedure. Experimental results demonstrate that compared to SOTA\nfine-tuning methods, our LoRA-SMoE approach can enhance model performance while\nreducing the number of trainable parameters. This significantly improves model\nperformance in resource-constrained environments. Additionally, due to its\nefficient parameter sensitivity evaluation mechanism, LoRA-SMoE requires\nminimal computational overhead to optimize expert allocation, making it\nparticularly suitable for scenarios with limited computational resources. All\nthe code in this study will be made publicly available following the acceptance\nof the paper for publication. Source code is at\nhttps://github.com/EMLS-ICTCAS/LoRA-SMoE",
      "tldr_zh": "该研究针对深度学习模型在多任务微调中的参数共享问题和Mixture-of-Experts (MoE) 方法带来的参数冗余问题，提出了一种基于参数敏感性的专家分配方法，即LoRA-SMoE (A Sensitivity-Driven Expert Allocation Method in LoRA-MoE for Efficient Fine-Tuning)。该方法通过采样少量数据并利用梯度信息快速评估任务对参数的敏感性，从而在给定预算下自适应分配专家数量，同时保持与LoRA (Low-Rank Adaptation) 相似的内存消耗。实验结果显示，LoRA-SMoE 相较于现有SOTA 微调方法，能提升模型性能并减少可训练参数，在资源受限环境中表现出色，且其高效的参数敏感性评估机制使优化过程计算开销最小。代码已在GitHub上公开（https://github.com/EMLS-ICTCAS/LoRA-SMoE）。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06272v1",
      "published_date": "2025-05-06 13:22:46 UTC",
      "updated_date": "2025-05-06 13:22:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:13:21.047489"
    },
    {
      "arxiv_id": "2505.03510v1",
      "title": "From Neurons to Computation: Biological Reservoir Computing for Pattern Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Ludovico Iannello",
        "Luca Ciampi",
        "Gabriele Lagani",
        "Fabrizio Tonelli",
        "Eleonora Crocco",
        "Lucio Maria Calcagnile",
        "Angelo Di Garbo",
        "Federico Cremisi",
        "Giuseppe Amato"
      ],
      "abstract": "In this paper, we introduce a novel paradigm for reservoir computing (RC)\nthat leverages a pool of cultured biological neurons as the reservoir\nsubstrate, creating a biological reservoir computing (BRC). This system\noperates similarly to an echo state network (ESN), with the key distinction\nthat the neural activity is generated by a network of cultured neurons, rather\nthan being modeled by traditional artificial computational units. The neuronal\nactivity is recorded using a multi-electrode array (MEA), which enables\nhigh-throughput recording of neural signals. In our approach, inputs are\nintroduced into the network through a subset of the MEA electrodes, while the\nremaining electrodes capture the resulting neural activity. This generates a\nnonlinear mapping of the input data to a high-dimensional biological feature\nspace, where distinguishing between data becomes more efficient and\nstraightforward, allowing a simple linear classifier to perform pattern\nrecognition tasks effectively. To evaluate the performance of our proposed\nsystem, we present an experimental study that includes various input patterns,\nsuch as positional codes, bars with different orientations, and a digit\nrecognition task. The results demonstrate the feasibility of using biological\nneural networks to perform tasks traditionally handled by artificial neural\nnetworks, paving the way for further exploration of biologically-inspired\ncomputing systems, with potential applications in neuromorphic engineering and\nbio-hybrid computing.",
      "tldr_zh": "本研究提出了一种新型的Biological Reservoir Computing (BRC)范式，使用培养的生物神经元作为reservoir substrate，取代传统的人工计算单位，以模拟Echo State Network (ESN)。通过Multi-Electrode Array (MEA)记录神经活动，输入数据经部分电极引入后，在高维生物特征空间中实现非线性映射，从而提升模式识别效率。实验验证了BRC在位置码、条形方向和数字识别任务中的有效性，与传统人工神经网络相比表现出色，为神经形态工程和生物混合计算系统的发展提供了新路径。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03510v1",
      "published_date": "2025-05-06 13:20:04 UTC",
      "updated_date": "2025-05-06 13:20:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:13:34.216222"
    },
    {
      "arxiv_id": "2505.03492v1",
      "title": "Augmenting Human Cognition through Everyday AR",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoan Liu"
      ],
      "abstract": "As spatial computing and multimodal LLMs mature, AR is tending to become an\nintuitive \"thinking tool,\" embedding semantic and context-aware intelligence\ndirectly into everyday environments. This paper explores how always-on AR can\nseamlessly bridge digital cognition and physical affordances, enabling\nproactive, context-sensitive interactions that enhance human task performance\nand understanding.",
      "tldr_zh": "这篇论文探讨了随着空间计算和multimodal LLMs的成熟，AR（Augmented Reality）正发展为一种直观的“thinking tool”，将语义和上下文感知智能嵌入日常生活环境中。论文重点研究了始终开启的AR如何无缝桥接数字认知与物理affordances，实现主动且上下文敏感的交互。结果表明，这种方法能显著提升人类任务绩效和理解，为AR在日常增强认知方面提供了新途径。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "3 pages, 4 figures. Position paper accepted to CHI'25 Workshop\n  'Everyday AR through AI-in-the-Loop'",
      "pdf_url": "http://arxiv.org/pdf/2505.03492v1",
      "published_date": "2025-05-06 12:48:38 UTC",
      "updated_date": "2025-05-06 12:48:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:13:45.137364"
    },
    {
      "arxiv_id": "2505.03490v1",
      "title": "A new membership inference attack that spots memorization in generative and predictive models: Loss-Based with Reference Model algorithm (LBRM)",
      "title_zh": "翻译失败",
      "authors": [
        "Faiz Taleb",
        "Ivan Gazeau",
        "Maryline Laurent"
      ],
      "abstract": "Generative models can unintentionally memorize training data, posing\nsignificant privacy risks. This paper addresses the memorization phenomenon in\ntime series imputation models, introducing the Loss-Based with Reference Model\n(LBRM) algorithm. The LBRM method leverages a reference model to enhance the\naccuracy of membership inference attacks, distinguishing between training and\ntest data. Our contributions are twofold: first, we propose an innovative\nmethod to effectively extract and identify memorized training data,\nsignificantly improving detection accuracy. On average, without fine-tuning,\nthe AUROC improved by approximately 40\\%. With fine-tuning, the AUROC increased\nby approximately 60\\%. Second, we validate our approach through membership\ninference attacks on two types of architectures designed for time series\nimputation, demonstrating the robustness and versatility of the LBRM approach\nin different contexts. These results highlight the significant enhancement in\ndetection accuracy provided by the LBRM approach, addressing privacy risks in\ntime series imputation models.",
      "tldr_zh": "该论文提出了一种新的成员推理攻击算法——Loss-Based with Reference Model (LBRM)，旨在检测生成和预测模型中对训练数据的无意记忆，从而缓解隐私风险。LBRM 通过利用参考模型来增强攻击的准确性，有效区分训练数据和测试数据，并在时间序列插值模型上实现了显著改进。实验结果显示，该方法在不进行微调的情况下，AUROC 平均提高了约 40%，而微调后提高了约 60%；此外，在两种不同架构上验证了其鲁棒性和通用性，为处理时间序列模型的隐私风险提供了重要工具。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03490v1",
      "published_date": "2025-05-06 12:47:24 UTC",
      "updated_date": "2025-05-06 12:47:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:13:57.773253"
    },
    {
      "arxiv_id": "2505.03475v1",
      "title": "am-ELO: A Stable Framework for Arena-based LLM Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Zirui Liu",
        "Jiatong Li",
        "Yan Zhuang",
        "Qi Liu",
        "Shuanghong Shen",
        "Jie Ouyang",
        "Mingyue Cheng",
        "Shijin Wang"
      ],
      "abstract": "Arena-based evaluation is a fundamental yet significant evaluation paradigm\nfor modern AI models, especially large language models (LLMs). Existing\nframework based on ELO rating system suffers from the inevitable instability\nproblem due to ranking inconsistency and the lack of attention to the varying\nabilities of annotators. In this paper, we introduce a novel stable arena\nframework to address these issues by enhancing the ELO Rating System.\nSpecifically, we replace the iterative update method with a Maximum Likelihood\nEstimation (MLE) approach, m-ELO, and provide theoretical proof of the\nconsistency and stability of the MLE approach for model ranking. Additionally,\nwe proposed the am-ELO, which modify the Elo Rating's probability function to\nincorporate annotator abilities, enabling the simultaneous estimation of model\nscores and annotator reliability. Experiments demonstrate that this method\nensures stability, proving that this framework offers a more robust, accurate,\nand stable evaluation method for LLMs.",
      "tldr_zh": "本文提出 am-ELO 框架，以解决现有基于 ELO 评级系统的 Arena 评估方法在大型语言模型(LLM)评估中的不稳定性问题，如排名不一致和忽略标注者能力。具体而言，该框架引入 m-ELO，通过 Maximum Likelihood Estimation (MLE) 替换迭代更新方法，并证明其在模型排名的一致性和稳定性。am-ELO 进一步修改 ELO 的概率函数，以整合标注者能力，实现模型分数和标注者可靠性的同时估计。实验结果显示，该框架显著提升了评估的稳健性、准确性和稳定性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "ICML2025 Accepted",
      "pdf_url": "http://arxiv.org/pdf/2505.03475v1",
      "published_date": "2025-05-06 12:28:50 UTC",
      "updated_date": "2025-05-06 12:28:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:14:09.782081"
    },
    {
      "arxiv_id": "2505.03470v1",
      "title": "Blending 3D Geometry and Machine Learning for Multi-View Stereopsis",
      "title_zh": "翻译失败",
      "authors": [
        "Vibhas Vats",
        "Md. Alimoor Reza",
        "David Crandall",
        "Soon-heung Jung"
      ],
      "abstract": "Traditional multi-view stereo (MVS) methods primarily depend on photometric\nand geometric consistency constraints. In contrast, modern learning-based\nalgorithms often rely on the plane sweep algorithm to infer 3D geometry,\napplying explicit geometric consistency (GC) checks only as a post-processing\nstep, with no impact on the learning process itself. In this work, we introduce\nGC MVSNet plus plus, a novel approach that actively enforces geometric\nconsistency of reference view depth maps across multiple source views (multi\nview) and at various scales (multi scale) during the learning phase (see Fig.\n1). This integrated GC check significantly accelerates the learning process by\ndirectly penalizing geometrically inconsistent pixels, effectively halving the\nnumber of training iterations compared to other MVS methods. Furthermore, we\nintroduce a densely connected cost regularization network with two distinct\nblock designs simple and feature dense optimized to harness dense feature\nconnections for enhanced regularization. Extensive experiments demonstrate that\nour approach achieves a new state of the art on the DTU and BlendedMVS datasets\nand secures second place on the Tanks and Temples benchmark. To our knowledge,\nGC MVSNet plus plus is the first method to enforce multi-view, multi-scale\nsupervised geometric consistency during learning. Our code is available.",
      "tldr_zh": "这篇论文提出 GC MVSNet++，一种将 3D 几何和机器学习相结合的方法，用于提升多视图立体（Multi-View Stereopsis）性能。该方法在学习阶段主动强制执行多视图（multi-view）和多尺度（multi-scale）的几何一致性检查，直接惩罚不一致像素，从而将训练迭代次数减半，并引入密集连接的成本正则化网络以增强特征处理。实验结果显示，该方法在 DTU 和 BlendedMVS 数据集上达到新状态艺术，在 Tanks and Temples 基准上排名第二，首次实现了学习过程中的监督几何一致性强制。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CG",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "A pre-print -- paper under-review. arXiv admin note: substantial text\n  overlap with arXiv:2310.19583",
      "pdf_url": "http://arxiv.org/pdf/2505.03470v1",
      "published_date": "2025-05-06 12:22:45 UTC",
      "updated_date": "2025-05-06 12:22:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:14:23.036956"
    },
    {
      "arxiv_id": "2505.03452v1",
      "title": "An Analysis of Hyper-Parameter Optimization Methods for Retrieval Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Matan Orbach",
        "Ohad Eytan",
        "Benjamin Sznajder",
        "Ariel Gera",
        "Odellia Boni",
        "Yoav Kantor",
        "Gal Bloch",
        "Omri Levy",
        "Hadas Abraham",
        "Nitzan Barzilay",
        "Eyal Shnarch",
        "Michael E. Factor",
        "Shila Ofek-Koifman",
        "Paula Ta-Shma",
        "Assaf Toledo"
      ],
      "abstract": "Finding the optimal Retrieval-Augmented Generation (RAG) configuration for a\ngiven use case can be complex and expensive. Motivated by this challenge,\nframeworks for RAG hyper-parameter optimization (HPO) have recently emerged,\nyet their effectiveness has not been rigorously benchmarked. To address this\ngap, we present a comprehensive study involving 5 HPO algorithms over 5\ndatasets from diverse domains, including a new one collected for this work on\nreal-world product documentation. Our study explores the largest HPO search\nspace considered to date, with two optimized evaluation metrics. Analysis of\nthe results shows that RAG HPO can be done efficiently, either greedily or with\niterative random search, and that it significantly boosts RAG performance for\nall datasets. For greedy HPO approaches, we show that optimizing models first\nis preferable to the prevalent practice of optimizing sequentially according to\nthe RAG pipeline order.",
      "tldr_zh": "该研究分析了针对 Retrieval-Augmented Generation (RAG) 的 Hyper-Parameter Optimization (HPO) 方法，旨在解决优化配置的复杂性和高成本问题。通过测试 5 种 HPO 算法在 5 个不同领域数据集（包括一个新收集的真实世界产品文档数据集）上，探索了迄今为止最大的搜索空间和两个优化评估指标。结果显示，HPO 可以高效实现，使用贪婪方法或迭代随机搜索显著提升 RAG 性能，且优先优化模型比按 RAG 管道顺序优化更有效。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03452v1",
      "published_date": "2025-05-06 11:47:52 UTC",
      "updated_date": "2025-05-06 11:47:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:14:35.208840"
    },
    {
      "arxiv_id": "2505.03451v1",
      "title": "Detecting Quishing Attacks with Machine Learning Techniques Through QR Code Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Fouad Trad",
        "Ali Chehab"
      ],
      "abstract": "The rise of QR code based phishing (\"Quishing\") poses a growing cybersecurity\nthreat, as attackers increasingly exploit QR codes to bypass traditional\nphishing defenses. Existing detection methods predominantly focus on URL\nanalysis, which requires the extraction of the QR code payload, and may\ninadvertently expose users to malicious content. Moreover, QR codes can encode\nvarious types of data beyond URLs, such as Wi-Fi credentials and payment\ninformation, making URL-based detection insufficient for broader security\nconcerns. To address these gaps, we propose the first framework for quishing\ndetection that directly analyzes QR code structure and pixel patterns without\nextracting the embedded content. We generated a dataset of phishing and benign\nQR codes and we used it to train and evaluate multiple machine learning models,\nincluding Logistic Regression, Decision Trees, Random Forest, Naive Bayes,\nLightGBM, and XGBoost. Our best-performing model (XGBoost) achieves an AUC of\n0.9106, demonstrating the feasibility of QR-centric detection. Through feature\nimportance analysis, we identify key visual indicators of malicious intent and\nrefine our feature set by removing non-informative pixels, improving\nperformance to an AUC of 0.9133 with a reduced feature space. Our findings\nreveal that the structural features of QR code correlate strongly with phishing\nrisk. This work establishes a foundation for quishing mitigation and highlights\nthe potential of direct QR analysis as a critical layer in modern phishing\ndefenses.",
      "tldr_zh": "本论文提出了一种新型框架，用于检测基于 QR code 的钓鱼攻击（Quishing），通过直接分析 QR code 的结构和像素模式，而非提取嵌入内容，从而避免暴露用户给恶意风险。该框架利用机器学习模型（如 Logistic Regression、Decision Trees、Random Forest、Naive Bayes、LightGBM 和 XGBoost）训练于一个新生成的数据集上，最佳模型 XGBoost 达到了 AUC 0.9106，并通过特征重要性分析优化特征集，进一步提升至 AUC 0.9133。研究发现，QR code 的结构特征与钓鱼风险高度相关，为 Quishing 攻击的缓解提供了基础，并强调了直接 QR 分析在现代网络安全防御中的关键作用。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted in 8th International Conference on Optimization and Learning\n  (OLA2025)",
      "pdf_url": "http://arxiv.org/pdf/2505.03451v1",
      "published_date": "2025-05-06 11:47:13 UTC",
      "updated_date": "2025-05-06 11:47:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:14:46.393296"
    },
    {
      "arxiv_id": "2505.03443v1",
      "title": "Elevating Semantic Exploration: A Novel Approach Utilizing Distributed Repositories",
      "title_zh": "提升语义探索",
      "authors": [
        "Valerio Bellandi"
      ],
      "abstract": "Centralized and distributed systems are two main approaches to organizing ICT\ninfrastructure, each with its pros and cons. Centralized systems concentrate\nresources in one location, making management easier but creating single points\nof failure. Distributed systems, on the other hand, spread resources across\nmultiple nodes, offering better scalability and fault tolerance, but requiring\nmore complex management. The choice between them depends on factors like\napplication needs, scalability, and data sensitivity. Centralized systems suit\napplications with limited scalability and centralized control, while\ndistributed systems excel in large-scale environments requiring high\navailability and performance. This paper explores a distributed document\nrepository system developed for the Italian Ministry of Justice, using edge\nrepositories to analyze textual data and metadata, enhancing semantic\nexploration capabilities.",
      "tldr_zh": "该论文比较了集中式和分布式系统的优缺点，指出分布式系统在可扩展性和容错方面更具优势，尤其适合大规模环境。该研究提出了一种新型分布式文档仓库系统，应用于意大利司法部，通过 edge repositories 分析文本数据和元数据，以提升 semantic exploration 的能力。这种方法为语义探索提供了更高效的框架，适用于需要高可用性的应用场景。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.DC",
      "comment": "This paper has been accepted at the 6th International Conference on\n  Recent Trends and Applications in Computer Science. It will appear in the\n  proceedings",
      "pdf_url": "http://arxiv.org/pdf/2505.03443v1",
      "published_date": "2025-05-06 11:30:16 UTC",
      "updated_date": "2025-05-06 11:30:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:14:56.404035"
    },
    {
      "arxiv_id": "2505.03439v1",
      "title": "The Steganographic Potentials of Language Models",
      "title_zh": "语言模型的隐写潜力",
      "authors": [
        "Artem Karpov",
        "Tinuade Adeleke",
        "Seong Hah Cho",
        "Natalia Perez-Campanero"
      ],
      "abstract": "The potential for large language models (LLMs) to hide messages within plain\ntext (steganography) poses a challenge to detection and thwarting of unaligned\nAI agents, and undermines faithfulness of LLMs reasoning. We explore the\nsteganographic capabilities of LLMs fine-tuned via reinforcement learning (RL)\nto: (1) develop covert encoding schemes, (2) engage in steganography when\nprompted, and (3) utilize steganography in realistic scenarios where hidden\nreasoning is likely, but not prompted. In these scenarios, we detect the\nintention of LLMs to hide their reasoning as well as their steganography\nperformance. Our findings in the fine-tuning experiments as well as in\nbehavioral non fine-tuning evaluations reveal that while current models exhibit\nrudimentary steganographic abilities in terms of security and capacity,\nexplicit algorithmic guidance markedly enhances their capacity for information\nconcealment.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）在隐写术（steganography）中的潜力，强调其隐藏消息的能力可能挑战不友好AI代理的检测并影响LLMs推理的忠实性。研究通过强化学习（RL）微调LLMs，开发隐蔽编码方案，并在提示下或现实场景中测试模型进行隐写术的行为，包括检测隐藏推理的意图和性能。结果显示，当前模型在安全性和容量方面仅具备基本隐写能力，但添加显式算法指导显著提升了其信息隐藏效能。",
      "categories": [
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Published at Building Trust Workshop at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.03439v1",
      "published_date": "2025-05-06 11:25:52 UTC",
      "updated_date": "2025-05-06 11:25:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:15:09.237183"
    },
    {
      "arxiv_id": "2505.03434v1",
      "title": "Procedural Memory Is Not All You Need: Bridging Cognitive Gaps in LLM-Based Agents",
      "title_zh": "程序记忆并非全部所需：桥接基于 LLM 的代理中的认知鸿沟",
      "authors": [
        "Schaun Wheeler",
        "Olivier Jeunen"
      ],
      "abstract": "Large Language Models (LLMs) represent a landmark achievement in Artificial\nIntelligence (AI), demonstrating unprecedented proficiency in procedural tasks\nsuch as text generation, code completion, and conversational coherence. These\ncapabilities stem from their architecture, which mirrors human procedural\nmemory -- the brain's ability to automate repetitive, pattern-driven tasks\nthrough practice. However, as LLMs are increasingly deployed in real-world\napplications, it becomes impossible to ignore their limitations operating in\ncomplex, unpredictable environments. This paper argues that LLMs, while\ntransformative, are fundamentally constrained by their reliance on procedural\nmemory. To create agents capable of navigating ``wicked'' learning environments\n-- where rules shift, feedback is ambiguous, and novelty is the norm -- we must\naugment LLMs with semantic memory and associative learning systems. By adopting\na modular architecture that decouples these cognitive functions, we can bridge\nthe gap between narrow procedural expertise and the adaptive intelligence\nrequired for real-world problem-solving.",
      "tldr_zh": "大型语言模型 (LLMs) 在程序性任务如文本生成和代码完成上表现出色，但其依赖程序性记忆 (procedural memory) 导致在复杂、多变的“wicked”学习环境中表现有限。论文指出，LLMs 需要通过整合语义记忆 (semantic memory) 和联想学习系统 (associative learning systems) 来弥补这些认知差距。作者提出采用模块化架构 (modular architecture) 来分离这些认知功能，从而实现程序性专长与适应性智能的桥接。该方法有望提升基于 LLMs 的代理在真实世界问题解决中的效能。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to the workshop on Hybrid AI for Human-Centric\n  Personalization (HyPer), co-located with ACM UMAP '25",
      "pdf_url": "http://arxiv.org/pdf/2505.03434v1",
      "published_date": "2025-05-06 11:18:34 UTC",
      "updated_date": "2025-05-06 11:18:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:15:23.872112"
    },
    {
      "arxiv_id": "2505.05498v2",
      "title": "An Overview of the Prospects and Challenges of Using Artificial Intelligence for Energy Management Systems in Microgrids",
      "title_zh": "人工智能在微电网能源管理系统中的前景与挑战概述",
      "authors": [
        "Noor ul Misbah Khanum",
        "Hayssam Dahrouj",
        "Ramesh C. Bansal",
        "Hissam Mouayad Tawfik"
      ],
      "abstract": "Microgrids have emerged as a pivotal solution in the quest for a sustainable\nand energy-efficient future. While microgrids offer numerous advantages, they\nare also prone to issues related to reliably forecasting renewable energy\ndemand and production, protecting against cyberattacks, controlling operational\ncosts, optimizing power flow, and regulating the performance of energy\nmanagement systems (EMS). Tackling these energy management challenges is\nessential to facilitate microgrid applications and seamlessly incorporate\nrenewable energy resources. Artificial intelligence (AI) has recently\ndemonstrated immense potential for optimizing energy management in microgrids,\nproviding efficient and reliable solutions. This paper highlights the combined\nbenefits of enabling AI-based methodologies in the energy management systems of\nmicrogrids by examining the applicability and efficiency of AI-based EMS in\nachieving specific technical and economic objectives. The paper also points out\nseveral future research directions that promise to spearhead AI-driven EMS,\nnamely the development of self-healing microgrids, integration with blockchain\ntechnology, use of Internet of things (IoT), and addressing interpretability,\ndata privacy, scalability, and the prospects to generative AI in the context of\nfuture AI-based EMS.",
      "tldr_zh": "这篇论文概述了在微电网（microgrids）能源管理系统（EMS）中应用人工智能（AI）的潜力与挑战，重点讨论了AI如何解决可再生能源预测、网络攻击防护、成本控制和功率优化等问题，以提升微电网的可靠性和效率。论文审视了AI-based方法在实现技术与经济目标方面的适用性和益处，并通过案例分析证明了其在优化能源管理中的重要作用。未来研究方向包括开发自愈微电网（self-healing microgrids）、整合区块链和物联网（IoT）技术，以及解决AI的可解释性、数据隐私和可扩展性问题，以推动AI-driven EMS的创新发展。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "62 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.05498v2",
      "published_date": "2025-05-06 11:08:36 UTC",
      "updated_date": "2025-05-13 06:44:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:15:36.604226"
    },
    {
      "arxiv_id": "2505.03427v1",
      "title": "MedArabiQ: Benchmarking Large Language Models on Arabic Medical Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Mouath Abu Daoud",
        "Chaimae Abouzahir",
        "Leen Kharouf",
        "Walid Al-Eisawi",
        "Nizar Habash",
        "Farah E. Shamout"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated significant promise for\nvarious applications in healthcare. However, their efficacy in the Arabic\nmedical domain remains unexplored due to the lack of high-quality\ndomain-specific datasets and benchmarks. This study introduces MedArabiQ, a\nnovel benchmark dataset consisting of seven Arabic medical tasks, covering\nmultiple specialties and including multiple choice questions,\nfill-in-the-blank, and patient-doctor question answering. We first constructed\nthe dataset using past medical exams and publicly available datasets. We then\nintroduced different modifications to evaluate various LLM capabilities,\nincluding bias mitigation. We conducted an extensive evaluation with five\nstate-of-the-art open-source and proprietary LLMs, including GPT-4o, Claude\n3.5-Sonnet, and Gemini 1.5. Our findings highlight the need for the creation of\nnew high-quality benchmarks that span different languages to ensure fair\ndeployment and scalability of LLMs in healthcare. By establishing this\nbenchmark and releasing the dataset, we provide a foundation for future\nresearch aimed at evaluating and enhancing the multilingual capabilities of\nLLMs for the equitable use of generative AI in healthcare.",
      "tldr_zh": "本研究引入了MedArabiQ，这是一个针对阿拉伯语医疗任务的新型基准数据集，涵盖七个任务如多项选择、填空和患者-医生问答，以评估Large Language Models (LLMs)在该领域的性能。数据集基于过去的医疗考试和公开可用资源构建，并通过各种修改（如偏见缓解）来测试LLMs的不同能力，包括对GPT-4o、Claude 3.5-Sonnet和Gemini 1.5等五种先进模型的广泛评估。结果显示，LLMs在阿拉伯语医疗任务上存在不足，强调了创建高质量多语言基准的必要性，并为未来提升LLMs的多语言能力和在医疗领域的公平应用提供基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "21 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.03427v1",
      "published_date": "2025-05-06 11:07:26 UTC",
      "updated_date": "2025-05-06 11:07:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:15:48.393366"
    },
    {
      "arxiv_id": "2505.03426v1",
      "title": "Phenotype-Guided Generative Model for High-Fidelity Cardiac MRI Synthesis: Advancing Pretraining and Clinical Applications",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyu Li",
        "Yujian Hu",
        "Zhengyao Ding",
        "Yiheng Mao",
        "Haitao Li",
        "Fan Yi",
        "Hongkun Zhang",
        "Zhengxing Huang"
      ],
      "abstract": "Cardiac Magnetic Resonance (CMR) imaging is a vital non-invasive tool for\ndiagnosing heart diseases and evaluating cardiac health. However, the limited\navailability of large-scale, high-quality CMR datasets poses a major challenge\nto the effective application of artificial intelligence (AI) in this domain.\nEven the amount of unlabeled data and the health status it covers are difficult\nto meet the needs of model pretraining, which hinders the performance of AI\nmodels on downstream tasks. In this study, we present Cardiac Phenotype-Guided\nCMR Generation (CPGG), a novel approach for generating diverse CMR data that\ncovers a wide spectrum of cardiac health status. The CPGG framework consists of\ntwo stages: in the first stage, a generative model is trained using cardiac\nphenotypes derived from CMR data; in the second stage, a masked autoregressive\ndiffusion model, conditioned on these phenotypes, generates high-fidelity CMR\ncine sequences that capture both structural and functional features of the\nheart in a fine-grained manner. We synthesized a massive amount of CMR to\nexpand the pretraining data. Experimental results show that CPGG generates\nhigh-quality synthetic CMR data, significantly improving performance on various\ndownstream tasks, including diagnosis and cardiac phenotypes prediction. These\ngains are demonstrated across both public and private datasets, highlighting\nthe effectiveness of our approach. Code is availabel at\nhttps://anonymous.4open.science/r/CPGG.",
      "tldr_zh": "本研究针对心脏磁共振 (CMR) 数据稀缺问题，提出了一种新型框架 Cardiac Phenotype-Guided CMR Generation (CPGG)，用于生成高保真合成 CMR 数据。该框架分为两阶段：首先利用 CMR 派生的心脏表型训练生成模型，其次采用 masked autoregressive diffusion 模型，以这些表型为条件，生成捕捉心脏结构和功能细节的多样化 CMR 序列。实验结果显示，CPGG 显著扩展了预训练数据，提升了下游任务（如诊断和心脏表型预测）的性能，在公共和私有数据集上均表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03426v1",
      "published_date": "2025-05-06 11:06:41 UTC",
      "updated_date": "2025-05-06 11:06:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:16:00.676134"
    },
    {
      "arxiv_id": "2505.03424v1",
      "title": "Framework GNN-AID: Graph Neural Network Analysis Interpretation and Defense",
      "title_zh": "GNN-AID 框架：图神经网络分析、解释和防御",
      "authors": [
        "Kirill Lukyanov",
        "Mikhail Drobyshevskiy",
        "Georgii Sazonov",
        "Mikhail Soloviov",
        "Ilya Makarov"
      ],
      "abstract": "The growing need for Trusted AI (TAI) highlights the importance of\ninterpretability and robustness in machine learning models. However, many\nexisting tools overlook graph data and rarely combine these two aspects into a\nsingle solution. Graph Neural Networks (GNNs) have become a popular approach,\nachieving top results across various tasks. We introduce GNN-AID (Graph Neural\nNetwork Analysis, Interpretation, and Defense), an open-source framework\ndesigned for graph data to address this gap. Built as a Python library, GNN-AID\nsupports advanced trust methods and architectural layers, allowing users to\nanalyze graph datasets and GNN behavior using attacks, defenses, and\ninterpretability methods.\n  GNN-AID is built on PyTorch-Geometric, offering preloaded datasets, models,\nand support for any GNNs through customizable interfaces. It also includes a\nweb interface with tools for graph visualization and no-code features like an\ninteractive model builder, simplifying the exploration and analysis of GNNs.\nThe framework also supports MLOps techniques, ensuring reproducibility and\nresult versioning to track and revisit analyses efficiently.\n  GNN-AID is a flexible tool for developers and researchers. It helps\ndevelopers create, analyze, and customize graph models, while also providing\naccess to prebuilt datasets and models for quick experimentation. Researchers\ncan use the framework to explore advanced topics on the relationship between\ninterpretability and robustness, test defense strategies, and combine methods\nto protect against different types of attacks.\n  We also show how defenses against evasion and poisoning attacks can conflict\nwhen applied to graph data, highlighting the complex connections between\ndefense strategies.\n  GNN-AID is available at\n\\href{https://github.com/ispras/GNN-AID}{github.com/ispras/GNN-AID}",
      "tldr_zh": "该研究引入了GNN-AID（Graph Neural Network Analysis, Interpretation, and Defense），一个开源Python框架，旨在提升Trusted AI在图数据上的可解释性和鲁棒性。框架构建于PyTorch-Geometric之上，提供预加载数据集、模型支持以及攻击、防御和解释方法，同时集成网络接口、图形可视化和无代码工具（如交互式模型构建器），并支持MLOps技术以确保分析的可复现性。GNN-AID帮助开发者和研究者快速实验和定制GNN模型，并揭示了防御策略在图数据中可能存在的冲突，例如针对逃避和投毒攻击的权衡，推进了对解释性与鲁棒性关系的探索。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03424v1",
      "published_date": "2025-05-06 11:03:19 UTC",
      "updated_date": "2025-05-06 11:03:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:16:12.060604"
    },
    {
      "arxiv_id": "2505.03406v1",
      "title": "Lightweight Clinical Decision Support System using QLoRA-Fine-Tuned LLMs and Retrieval-Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammad Shoaib Ansari",
        "Mohd Sohail Ali Khan",
        "Shubham Revankar",
        "Aditya Varma",
        "Anil S. Mokhade"
      ],
      "abstract": "This research paper investigates the application of Large Language Models\n(LLMs) in healthcare, specifically focusing on enhancing medical decision\nsupport through Retrieval-Augmented Generation (RAG) integrated with\nhospital-specific data and fine-tuning using Quantized Low-Rank Adaptation\n(QLoRA). The system utilizes Llama 3.2-3B-Instruct as its foundation model. By\nembedding and retrieving context-relevant healthcare information, the system\nsignificantly improves response accuracy. QLoRA facilitates notable parameter\nefficiency and memory optimization, preserving the integrity of medical\ninformation through specialized quantization techniques. Our research also\nshows that our model performs relatively well on various medical benchmarks,\nindicating that it can be used to make basic medical suggestions. This paper\ndetails the system's technical components, including its architecture,\nquantization methods, and key healthcare applications such as enhanced disease\nprediction from patient symptoms and medical history, treatment suggestions,\nand efficient summarization of complex medical reports. We touch on the ethical\nconsiderations-patient privacy, data security, and the need for rigorous\nclinical validation-as well as the practical challenges of integrating such\nsystems into real-world healthcare workflows. Furthermore, the lightweight\nquantized weights ensure scalability and ease of deployment even in\nlow-resource hospital environments. Finally, the paper concludes with an\nanalysis of the broader impact of LLMs on healthcare and outlines future\ndirections for LLMs in medical settings.",
      "tldr_zh": "这篇论文提出了一种轻量级临床决策支持系统，通过使用 Quantized Low-Rank Adaptation (QLoRA) 微调的 LLMs（如 Llama 3.2-3B-Instruct）和 Retrieval-Augmented Generation (RAG) 技术，整合医院特定数据以提升医疗决策的准确性和效率。系统通过嵌入和检索相关医疗信息，实现参数优化和内存节省，同时在各种医疗基准上表现出色，可用于疾病预测、治疗建议以及复杂报告的总结。研究强调了伦理考虑，如患者隐私和数据安全，并探讨了在低资源环境中的可扩展性及未来 LLMs 在医疗领域的应用前景。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "12 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.03406v1",
      "published_date": "2025-05-06 10:31:54 UTC",
      "updated_date": "2025-05-06 10:31:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:16:25.342325"
    },
    {
      "arxiv_id": "2505.03401v1",
      "title": "DDaTR: Dynamic Difference-aware Temporal Residual Network for Longitudinal Radiology Report Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Shanshan Song",
        "Hui Tang",
        "Honglong Yang",
        "Xiaomeng Li"
      ],
      "abstract": "Radiology Report Generation (RRG) automates the creation of radiology reports\nfrom medical imaging, enhancing the efficiency of the reporting process.\nLongitudinal Radiology Report Generation (LRRG) extends RRG by incorporating\nthe ability to compare current and prior exams, facilitating the tracking of\ntemporal changes in clinical findings. Existing LRRG approaches only extract\nfeatures from prior and current images using a visual pre-trained encoder,\nwhich are then concatenated to generate the final report. However, these\nmethods struggle to effectively capture both spatial and temporal correlations\nduring the feature extraction process. Consequently, the extracted features\ninadequately capture the information of difference across exams and thus\nunderrepresent the expected progressions, leading to sub-optimal performance in\nLRRG. To address this, we develop a novel dynamic difference-aware temporal\nresidual network (DDaTR). In DDaTR, we introduce two modules at each stage of\nthe visual encoder to capture multi-level spatial correlations. The Dynamic\nFeature Alignment Module (DFAM) is designed to align prior features across\nmodalities for the integrity of prior clinical information. Prompted by the\nenriched prior features, the dynamic difference-aware module (DDAM) captures\nfavorable difference information by identifying relationships across exams.\nFurthermore, our DDaTR employs the dynamic residual network to unidirectionally\ntransmit longitudinal information, effectively modelling temporal correlations.\nExtensive experiments demonstrated superior performance over existing methods\non three benchmarks, proving its efficacy in both RRG and LRRG tasks.",
      "tldr_zh": "本文针对纵向放射学报告生成（LRRG）中现有方法无法有效捕获空间和时间相关性的问题，提出了一种新型动态差分感知时间残差网络（DDaTR）。DDaTR 在视觉编码器的每个阶段引入动态特征对齐模块（DFAM）来对齐先前特征，确保临床信息完整性，以及动态差分感知模块（DDAM）来捕获检查间的差分信息，并通过动态残差网络单向传输纵向信息以建模时间相关性。实验结果显示，DDaTR 在三个基准上显著优于现有方法，提升了放射学报告生成（RRG）和 LRRG 任务的性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03401v1",
      "published_date": "2025-05-06 10:29:23 UTC",
      "updated_date": "2025-05-06 10:29:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:16:38.619210"
    },
    {
      "arxiv_id": "2505.03392v1",
      "title": "Automatic Calibration for Membership Inference Attack on Large Language Models",
      "title_zh": "针对大型语言模型的成员推断攻击自动校准",
      "authors": [
        "Saleh Zare Zade",
        "Yao Qiang",
        "Xiangyu Zhou",
        "Hui Zhu",
        "Mohammad Amin Roshani",
        "Prashant Khanduri",
        "Dongxiao Zhu"
      ],
      "abstract": "Membership Inference Attacks (MIAs) have recently been employed to determine\nwhether a specific text was part of the pre-training data of Large Language\nModels (LLMs). However, existing methods often misinfer non-members as members,\nleading to a high false positive rate, or depend on additional reference models\nfor probability calibration, which limits their practicality. To overcome these\nchallenges, we introduce a novel framework called Automatic Calibration\nMembership Inference Attack (ACMIA), which utilizes a tunable temperature to\ncalibrate output probabilities effectively. This approach is inspired by our\ntheoretical insights into maximum likelihood estimation during the pre-training\nof LLMs. We introduce ACMIA in three configurations designed to accommodate\ndifferent levels of model access and increase the probability gap between\nmembers and non-members, improving the reliability and robustness of membership\ninference. Extensive experiments on various open-source LLMs demonstrate that\nour proposed attack is highly effective, robust, and generalizable, surpassing\nstate-of-the-art baselines across three widely used benchmarks. Our code is\navailable at:\n\\href{https://github.com/Salehzz/ACMIA}{\\textcolor{blue}{Github}}.",
      "tldr_zh": "这篇论文针对 Large Language Models (LLMs) 的 Membership Inference Attacks (MIAs) 问题，提出了一种新型框架 Automatic Calibration Membership Inference Attack (ACMIA)，通过可调节温度（tunable temperature）校准输出概率，减少假阳性率并减少对额外参考模型的依赖。ACMIA 的设计基于对 LLMs 预训练中最大似然估计的理论洞见，并提供三种配置以适应不同模型访问级别，提高成员和非成员的概率差距。实验在多种开源 LLMs 上验证，ACMIA 超越了最先进基线，在三个常用基准上表现出更高的有效性、鲁棒性和泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03392v1",
      "published_date": "2025-05-06 10:15:05 UTC",
      "updated_date": "2025-05-06 10:15:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:16:50.073901"
    },
    {
      "arxiv_id": "2505.03380v1",
      "title": "Reinforced Correlation Between Vision and Language for Precise Medical AI Assistant",
      "title_zh": "强化视觉与语言相关性用于精确医疗AI助手",
      "authors": [
        "Haonan Wang",
        "Jiaji Mao",
        "Lehan Wang",
        "Qixiang Zhang",
        "Marawan Elbatel",
        "Yi Qin",
        "Huijun Hu",
        "Baoxun Li",
        "Wenhui Deng",
        "Weifeng Qin",
        "Hongrui Li",
        "Jialin Liang",
        "Jun Shen",
        "Xiaomeng Li"
      ],
      "abstract": "Medical AI assistants support doctors in disease diagnosis, medical image\nanalysis, and report generation. However, they still face significant\nchallenges in clinical use, including limited accuracy with multimodal content\nand insufficient validation in real-world settings. We propose RCMed, a\nfull-stack AI assistant that improves multimodal alignment in both input and\noutput, enabling precise anatomical delineation, accurate localization, and\nreliable diagnosis through hierarchical vision-language grounding. A\nself-reinforcing correlation mechanism allows visual features to inform\nlanguage context, while language semantics guide pixel-wise attention, forming\na closed loop that refines both modalities. This correlation is enhanced by a\ncolor region description strategy, translating anatomical structures into\nsemantically rich text to learn shape-location-text relationships across\nscales. Trained on 20 million image-mask-description triplets, RCMed achieves\nstate-of-the-art precision in contextualizing irregular lesions and subtle\nanatomical boundaries, excelling in 165 clinical tasks across 9 modalities. It\nachieved a 23.5% relative improvement in cell segmentation from microscopy\nimages over prior methods. RCMed's strong vision-language alignment enables\nexceptional generalization, with state-of-the-art performance in external\nvalidation across 20 clinically significant cancer types, including novel\ntasks. This work demonstrates how integrated multimodal models capture\nfine-grained patterns, enabling human-level interpretation in complex scenarios\nand advancing human-centric AI healthcare.",
      "tldr_zh": "本研究提出 RCMed，一种全栈医疗 AI 助手，通过强化视觉和语言之间的相关性，提升多模态输入和输出的对齐精度，从而实现精确的解剖描绘、定位和诊断。核心机制包括自强化相关方法，让视觉特征指导语言上下文，同时语言语义优化像素级注意力，并结合颜色区域描述策略来学习跨尺度的形状-位置-文本关系。训练于20百万图像-掩码-描述三元组的数据集上，RCMed 在165个临床任务和9个模态中达到 state-of-the-art 性能，显微镜图像细胞分割较前方法提升23.5%，并在20种癌症类型的外部分析中展现出色的泛化能力，促进了人类水平的 AI 医疗解释。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03380v1",
      "published_date": "2025-05-06 10:00:08 UTC",
      "updated_date": "2025-05-06 10:00:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:17:01.452286"
    },
    {
      "arxiv_id": "2505.03373v1",
      "title": "SPAP: Structured Pruning via Alternating Optimization and Penalty Methods",
      "title_zh": "翻译失败",
      "authors": [
        "Hanyu Hu",
        "Xiaoming Yuan"
      ],
      "abstract": "The deployment of large language models (LLMs) is often constrained by their\nsubstantial computational and memory demands. While structured pruning presents\na viable approach by eliminating entire network components, existing methods\nsuffer from performance degradation, reliance on heuristic metrics, or\nexpensive finetuning. To address these challenges, we propose SPAP (Structured\nPruning via Alternating Optimization and Penalty Methods), a novel and\nefficient structured pruning framework for LLMs grounded in optimization\ntheory. SPAP formulates the pruning problem through a mixed-integer\noptimization model, employs a penalty method that effectively makes pruning\ndecisions to minimize pruning errors, and introduces an alternating\nminimization algorithm tailored to the splittable problem structure for\nefficient weight updates and performance recovery. Extensive experiments on\nOPT, LLaMA-3/3.1/3.2, and Qwen2.5 models demonstrate SPAP's superiority over\nstate-of-the-art methods, delivering linear inference speedups (1.29$\\times$ at\n30% sparsity) and proportional memory reductions. Our work offers a practical,\noptimization-driven solution for pruning LLMs while preserving model\nperformance.",
      "tldr_zh": "本论文提出SPAP（Structured Pruning via Alternating Optimization and Penalty Methods），一种基于优化理论的创新框架，用于解决大型语言模型（LLMs）的计算和内存需求问题。SPAP通过混合整数优化模型制定剪枝问题，并结合惩罚方法最小化剪枝错误，以及交替最小化算法实现高效权重更新和性能恢复，从而避免了现有方法的性能下降和依赖启发式指标的缺点。在OPT、LLaMA-3/3.1/3.2和Qwen2.5模型上的实验显示，SPAP在30%稀疏度下实现了1.29倍的线性推理加速和相应的内存减少，优于现有最先进方法，提供了一个实用且优化的LLMs剪枝解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03373v1",
      "published_date": "2025-05-06 09:47:53 UTC",
      "updated_date": "2025-05-06 09:47:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:17:11.820304"
    },
    {
      "arxiv_id": "2505.03369v1",
      "title": "Validating the Effectiveness of a Large Language Model-based Approach for Identifying Children's Development across Various Free Play Settings in Kindergarten",
      "title_zh": "验证基于大型语言模型的方法在幼儿园各种自由游戏环境中识别儿童发展的有效",
      "authors": [
        "Yuanyuan Yang",
        "Yuan Shen",
        "Tianchen Sun",
        "Yangbin Xie"
      ],
      "abstract": "Free play is a fundamental aspect of early childhood education, supporting\nchildren's cognitive, social, emotional, and motor development. However,\nassessing children's development during free play poses significant challenges\ndue to the unstructured and spontaneous nature of the activity. Traditional\nassessment methods often rely on direct observations by teachers, parents, or\nresearchers, which may fail to capture comprehensive insights from free play\nand provide timely feedback to educators. This study proposes an innovative\napproach combining Large Language Models (LLMs) with learning analytics to\nanalyze children's self-narratives of their play experiences. The LLM\nidentifies developmental abilities, while performance scores across different\nplay settings are calculated using learning analytics techniques. We collected\n2,224 play narratives from 29 children in a kindergarten, covering four\ndistinct play areas over one semester. According to the evaluation results from\neight professionals, the LLM-based approach achieved high accuracy in\nidentifying cognitive, motor, and social abilities, with accuracy exceeding 90%\nin most domains. Moreover, significant differences in developmental outcomes\nwere observed across play settings, highlighting each area's unique\ncontributions to specific abilities. These findings confirm that the proposed\napproach is effective in identifying children's development across various free\nplay settings. This study demonstrates the potential of integrating LLMs and\nlearning analytics to provide child-centered insights into developmental\ntrajectories, offering educators valuable data to support personalized learning\nand enhance early childhood education practices.",
      "tldr_zh": "这篇论文提出了一种基于Large Language Models (LLMs) 和学习分析的方法，来评估幼儿园儿童在不同自由玩耍环境中的认知、社会和运动发展，通过分析儿童的自述玩耍经历来识别关键能力。研究收集了29名儿童的2224个玩耍叙述，覆盖四个玩耍区域，并由八位专业人士评估，结果显示LLMs在大多数领域准确率超过90%。此外，研究发现不同玩耍环境对发展结果有显著差异，这为教育者提供个性化学习数据，支持早期教育实践的优化。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "15 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.03369v1",
      "published_date": "2025-05-06 09:40:47 UTC",
      "updated_date": "2025-05-06 09:40:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:17:24.197988"
    },
    {
      "arxiv_id": "2505.03359v1",
      "title": "Domain Adversarial Training for Mitigating Gender Bias in Speech-based Mental Health Detection",
      "title_zh": "翻译失败",
      "authors": [
        "June-Woo Kim",
        "Haram Yoon",
        "Wonkyo Oh",
        "Dawoon Jung",
        "Sung-Hoon Yoon",
        "Dae-Jin Kim",
        "Dong-Ho Lee",
        "Sang-Yeol Lee",
        "Chan-Mo Yang"
      ],
      "abstract": "Speech-based AI models are emerging as powerful tools for detecting\ndepression and the presence of Post-traumatic stress disorder (PTSD), offering\na non-invasive and cost-effective way to assess mental health. However, these\nmodels often struggle with gender bias, which can lead to unfair and inaccurate\npredictions. In this study, our study addresses this issue by introducing a\ndomain adversarial training approach that explicitly considers gender\ndifferences in speech-based depression and PTSD detection. Specifically, we\ntreat different genders as distinct domains and integrate this information into\na pretrained speech foundation model. We then validate its effectiveness on the\nE-DAIC dataset to assess its impact on performance. Experimental results show\nthat our method notably improves detection performance, increasing the F1-score\nby up to 13.29 percentage points compared to the baseline. This highlights the\nimportance of addressing demographic disparities in AI-driven mental health\nassessment.",
      "tldr_zh": "本研究针对语音-based AI模型在检测抑郁和Post-traumatic stress disorder (PTSD)时的性别偏差问题，提出了一种Domain Adversarial Training方法，将不同性别视为独立domains，并将其整合到预训练的语音基础模型中。该方法通过显式处理性别差异，提高了模型的公平性和准确性。在E-DAIC数据集上的实验显示，与基线模型相比，F1-score提升了高达13.29个百分点。该创新方法突出了在AI驱动的心理健康评估中解决人口统计差异的重要性，从而促进更公正的临床应用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to EMBC 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.03359v1",
      "published_date": "2025-05-06 09:29:14 UTC",
      "updated_date": "2025-05-06 09:29:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:17:36.295683"
    },
    {
      "arxiv_id": "2505.03856v1",
      "title": "An Active Inference Model of Covert and Overt Visual Attention",
      "title_zh": "隐蔽与显性视觉注意的主动推理模型",
      "authors": [
        "Tin Mišić",
        "Karlo Koledić",
        "Fabio Bonsignorio",
        "Ivan Petrović",
        "Ivan Marković"
      ],
      "abstract": "The ability to selectively attend to relevant stimuli while filtering out\ndistractions is essential for agents that process complex, high-dimensional\nsensory input. This paper introduces a model of covert and overt visual\nattention through the framework of active inference, utilizing dynamic\noptimization of sensory precisions to minimize free-energy. The model\ndetermines visual sensory precisions based on both current environmental\nbeliefs and sensory input, influencing attentional allocation in both covert\nand overt modalities. To test the effectiveness of the model, we analyze its\nbehavior in the Posner cueing task and a simple target focus task using\ntwo-dimensional(2D) visual data. Reaction times are measured to investigate the\ninterplay between exogenous and endogenous attention, as well as valid and\ninvalid cueing. The results show that exogenous and valid cues generally lead\nto faster reaction times compared to endogenous and invalid cues. Furthermore,\nthe model exhibits behavior similar to inhibition of return, where previously\nattended locations become suppressed after a specific cue-target onset\nasynchrony interval. Lastly, we investigate different aspects of overt\nattention and show that involuntary, reflexive saccades occur faster than\nintentional ones, but at the expense of adaptability.",
      "tldr_zh": "这篇论文提出了一种基于 active inference 的模型，用于模拟 covert 和 overt 视觉注意力，通过动态优化 sensory precisions 来最小化 free-energy，从而根据环境信念和感官输入分配注意力。模型在 Posner cueing 任务和简单目标聚焦任务中使用 2D 视觉数据进行测试，结果显示 exogenous 和 valid cues 导致更快的反应时间，同时模型表现出类似于 inhibition of return 的行为，即先前关注的区域在特定间隔后被抑制。最后，研究发现非自愿的 reflexive saccades 比 intentional ones 更快，但会降低适应性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "q-bio.NC",
        "I.2.6; I.2.10"
      ],
      "primary_category": "cs.CV",
      "comment": "7 pages, 7 figures. Code available at\n  https://github.com/unizgfer-lamor/ainf-visual-attention",
      "pdf_url": "http://arxiv.org/pdf/2505.03856v1",
      "published_date": "2025-05-06 09:26:00 UTC",
      "updated_date": "2025-05-06 09:26:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:17:49.507939"
    },
    {
      "arxiv_id": "2505.06271v1",
      "title": "Tri-MTL: A Triple Multitask Learning Approach for Respiratory Disease Diagnosis",
      "title_zh": "Tri-MTL：一种三",
      "authors": [
        "June-Woo Kim",
        "Sanghoon Lee",
        "Miika Toikkanen",
        "Daehwan Hwang",
        "Kyunghoon Kim"
      ],
      "abstract": "Auscultation remains a cornerstone of clinical practice, essential for both\ninitial evaluation and continuous monitoring. Clinicians listen to the lung\nsounds and make a diagnosis by combining the patient's medical history and test\nresults. Given this strong association, multitask learning (MTL) can offer a\ncompelling framework to simultaneously model these relationships, integrating\nrespiratory sound patterns with disease manifestations. While MTL has shown\nconsiderable promise in medical applications, a significant research gap\nremains in understanding the complex interplay between respiratory sounds,\ndisease manifestations, and patient metadata attributes. This study\ninvestigates how integrating MTL with cutting-edge deep learning architectures\ncan enhance both respiratory sound classification and disease diagnosis.\nSpecifically, we extend recent findings regarding the beneficial impact of\nmetadata on respiratory sound classification by evaluating its effectiveness\nwithin an MTL framework. Our comprehensive experiments reveal significant\nimprovements in both lung sound classification and diagnostic performance when\nthe stethoscope information is incorporated into the MTL architecture.",
      "tldr_zh": "本研究提出Tri-MTL，一种三重多任务学习(Multitask Learning)方法，旨在整合呼吸音模式、疾病表现和患者元数据，以提升呼吸疾病诊断的准确性。通过结合先进深度学习架构，该方法扩展了元数据在呼吸音分类中的作用，并在MTL框架内进行评估。实验结果显示，融入听诊信息后，肺音分类和诊断性能均显著改善，为临床实践提供更有效的诊断工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to EMBC 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.06271v1",
      "published_date": "2025-05-06 09:25:15 UTC",
      "updated_date": "2025-05-06 09:25:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:18:00.013320"
    },
    {
      "arxiv_id": "2505.03338v1",
      "title": "Safer Prompts: Reducing IP Risk in Visual Generative AI",
      "title_zh": "翻译失败",
      "authors": [
        "Lena Reissinger",
        "Yuanyuan Li",
        "Anna-Carolina Haensch",
        "Neeraj Sarna"
      ],
      "abstract": "Visual Generative AI models have demonstrated remarkable capability in\ngenerating high-quality images from simple inputs like text prompts. However,\nbecause these models are trained on images from diverse sources, they risk\nmemorizing and reproducing specific content, raising concerns about\nintellectual property (IP) infringement. Recent advances in prompt engineering\noffer a cost-effective way to enhance generative AI performance. In this paper,\nwe evaluate the effectiveness of prompt engineering techniques in mitigating IP\ninfringement risks in image generation. Our findings show that Chain of Thought\nPrompting and Task Instruction Prompting significantly reduce the similarity\nbetween generated images and the training data of diffusion models, thereby\nlowering the risk of IP infringement.",
      "tldr_zh": "本论文探讨了视觉生成 AI（Visual Generative AI）模型在生成图像时可能因记忆训练数据而引发知识产权（IP）侵权风险的问题。研究评估了提示工程技术，包括 Chain of Thought Prompting 和 Task Instruction Prompting，作为一种成本有效的解决方案。这些技术通过减少生成图像与训练数据的相似度，显著降低了 IP 侵权风险，为更安全的图像生成提供了实用方法。",
      "categories": [
        "math.NA",
        "cs.AI",
        "cs.NA"
      ],
      "primary_category": "math.NA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03338v1",
      "published_date": "2025-05-06 09:10:12 UTC",
      "updated_date": "2025-05-06 09:10:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:18:12.256052"
    },
    {
      "arxiv_id": "2505.03336v1",
      "title": "Avoid Recommending Out-of-Domain Items: Constrained Generative Recommendation with LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Liao",
        "Wensheng Lu",
        "Jianxun Lian",
        "Mingqi Wu",
        "Shuo Wang",
        "Yong Zhang",
        "Yitian Huang",
        "Mingyang Zhou",
        "Xing Xie"
      ],
      "abstract": "Large Language Models (LLMs) have shown promise for generative recommender\nsystems due to their transformative capabilities in user interaction. However,\nensuring they do not recommend out-of-domain (OOD) items remains a challenge.\nWe study two distinct methods to address this issue: RecLM-ret, a\nretrieval-based method, and RecLM-cgen, a constrained generation method. Both\nmethods integrate seamlessly with existing LLMs to ensure in-domain\nrecommendations. Comprehensive experiments on three recommendation datasets\ndemonstrate that RecLM-cgen consistently outperforms RecLM-ret and existing\nLLM-based recommender models in accuracy while eliminating OOD recommendations,\nmaking it the preferred method for adoption. Additionally, RecLM-cgen maintains\nstrong generalist capabilities and is a lightweight plug-and-play module for\neasy integration into LLMs, offering valuable practical benefits for the\ncommunity. Source code is available at https://github.com/microsoft/RecAI",
      "tldr_zh": "本文研究了如何使用 Large Language Models (LLMs) 进行生成式推荐系统，同时避免推荐 Out-of-Domain (OOD) 物品的问题，提出了两种方法：基于检索的 RecLM-ret 和基于约束生成的 RecLM-cgen。RecLM-cgen 通过无缝集成到现有 LLMs 中，确保推荐的准确性和领域内性，在三个推荐数据集上的实验中，表现优于 RecLM-ret 和其他模型，同时完全消除了 OOD 推荐。RecLM-cgen 还保持了 LLMs 的强大通用能力，作为一个轻量级的即插即用模块，便于社区应用和集成。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "13 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.03336v1",
      "published_date": "2025-05-06 09:08:36 UTC",
      "updated_date": "2025-05-06 09:08:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:18:25.104412"
    },
    {
      "arxiv_id": "2505.03335v2",
      "title": "Absolute Zero: Reinforced Self-play Reasoning with Zero Data",
      "title_zh": "翻译失败",
      "authors": [
        "Andrew Zhao",
        "Yiran Wu",
        "Yang Yue",
        "Tong Wu",
        "Quentin Xu",
        "Yang Yue",
        "Matthieu Lin",
        "Shenzhi Wang",
        "Qingyun Wu",
        "Zilong Zheng",
        "Gao Huang"
      ],
      "abstract": "Reinforcement learning with verifiable rewards (RLVR) has shown promise in\nenhancing the reasoning capabilities of large language models by learning\ndirectly from outcome-based rewards. Recent RLVR works that operate under the\nzero setting avoid supervision in labeling the reasoning process, but still\ndepend on manually curated collections of questions and answers for training.\nThe scarcity of high-quality, human-produced examples raises concerns about the\nlong-term scalability of relying on human supervision, a challenge already\nevident in the domain of language model pretraining. Furthermore, in a\nhypothetical future where AI surpasses human intelligence, tasks provided by\nhumans may offer limited learning potential for a superintelligent system. To\naddress these concerns, we propose a new RLVR paradigm called Absolute Zero, in\nwhich a single model learns to propose tasks that maximize its own learning\nprogress and improves reasoning by solving them, without relying on any\nexternal data. Under this paradigm, we introduce the Absolute Zero Reasoner\n(AZR), a system that self-evolves its training curriculum and reasoning ability\nby using a code executor to both validate proposed code reasoning tasks and\nverify answers, serving as an unified source of verifiable reward to guide\nopen-ended yet grounded learning. Despite being trained entirely without\nexternal data, AZR achieves overall SOTA performance on coding and mathematical\nreasoning tasks, outperforming existing zero-setting models that rely on tens\nof thousands of in-domain human-curated examples. Furthermore, we demonstrate\nthat AZR can be effectively applied across different model scales and is\ncompatible with various model classes.",
      "tldr_zh": "本研究提出Absolute Zero范式，一种无需外部数据的强化学习框架（RLVR），让模型通过自我生成任务并解决它们来最大化学习进步，从而解决现有方法依赖人类监督的局限性。Absolute Zero Reasoner (AZR)系统使用代码执行器验证提出的代码推理任务和答案，作为统一的验证奖励来源，实现开放式却可靠的学习。实验结果显示，AZR在零数据设置下，在编码和数学推理任务上达到SOTA性能，优于依赖数万个人类示例的基线模型，且适用于不同模型规模和类型。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03335v2",
      "published_date": "2025-05-06 09:08:00 UTC",
      "updated_date": "2025-05-07 13:01:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:18:36.182183"
    },
    {
      "arxiv_id": "2505.03332v3",
      "title": "AI-Driven Scholarly Peer Review via Persistent Workflow Prompting, Meta-Prompting, and Meta-Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Evgeny Markhasin"
      ],
      "abstract": "Critical peer review of scientific manuscripts presents a significant\nchallenge for Large Language Models (LLMs), partly due to data limitations and\nthe complexity of expert reasoning. This report introduces Persistent Workflow\nPrompting (PWP), a potentially broadly applicable prompt engineering\nmethodology designed to bridge this gap using standard LLM chat interfaces\n(zero-code, no APIs). We present a proof-of-concept PWP prompt for the critical\nanalysis of experimental chemistry manuscripts, featuring a hierarchical,\nmodular architecture (structured via Markdown) that defines detailed analysis\nworkflows. We develop this PWP prompt through iterative application of\nmeta-prompting techniques and meta-reasoning aimed at systematically codifying\nexpert review workflows, including tacit knowledge. Submitted once at the start\nof a session, this PWP prompt equips the LLM with persistent workflows\ntriggered by subsequent queries, guiding modern reasoning LLMs through\nsystematic, multimodal evaluations. Demonstrations show the PWP-guided LLM\nidentifying major methodological flaws in a test case while mitigating LLM\ninput bias and performing complex tasks, including distinguishing claims from\nevidence, integrating text/photo/figure analysis to infer parameters, executing\nquantitative feasibility checks, comparing estimates against claims, and\nassessing a priori plausibility. To ensure transparency and facilitate\nreplication, we provide full prompts, detailed demonstration analyses, and logs\nof interactive chats as supplementary resources. Beyond the specific\napplication, this work offers insights into the meta-development process\nitself, highlighting the potential of PWP, informed by detailed workflow\nformalization, to enable sophisticated analysis using readily available LLMs\nfor complex scientific tasks.",
      "tldr_zh": "这篇论文提出了一种AI驱动的学术同行评审方法，名为Persistent Workflow Prompting (PWP)，通过meta-prompting和meta-reasoning技术来构建分层模块化提示架构，帮助Large Language Models (LLMs)系统化分析科学手稿。PWP方法无需代码或API，仅使用标准聊天接口，即可编码专家评审流程，包括隐性知识，并在实验化学手稿上进行多模态评估，如区分声明与证据、整合文本/照片/图分析以及执行定量可行性检查。实验演示显示，PWP引导的LLM能有效识别方法论缺陷、减轻输入偏差，并提升整体评审准确性，为使用现成LLMs处理复杂科学任务提供了可复制的见解和框架。",
      "categories": [
        "cs.AI",
        "physics.chem-ph"
      ],
      "primary_category": "cs.AI",
      "comment": "23 pages, 37 pages (references and appendixes)",
      "pdf_url": "http://arxiv.org/pdf/2505.03332v3",
      "published_date": "2025-05-06 09:06:18 UTC",
      "updated_date": "2025-05-18 06:53:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:18:50.365023"
    },
    {
      "arxiv_id": "2505.03327v1",
      "title": "Very High-Resolution Forest Mapping with TanDEM-X InSAR Data and Self-Supervised Learning",
      "title_zh": "翻译失败",
      "authors": [
        "José-Luis Bueso-Bello",
        "Benjamin Chauvel",
        "Daniel Carcereri",
        "Philipp Posovszky",
        "Pietro Milillo",
        "Jennifer Ruiz",
        "Juan-Carlos Fernández-Diaz",
        "Carolina González",
        "Michele Martone",
        "Ronny Hänsch",
        "Paola Rizzoli"
      ],
      "abstract": "Deep learning models have shown encouraging capabilities for mapping\naccurately forests at medium resolution with TanDEM-X interferometric SAR data.\nSuch models, as most of current state-of-the-art deep learning techniques in\nremote sensing, are trained in a fully-supervised way, which requires a large\namount of labeled data for training and validation. In this work, our aim is to\nexploit the high-resolution capabilities of the TanDEM-X mission to map forests\nat 6 m. The goal is to overcome the intrinsic limitations posed by\nmidresolution products, which affect, e.g., the detection of narrow roads\nwithin vegetated areas and the precise delineation of forested regions\ncontours. To cope with the lack of extended reliable reference datasets at such\na high resolution, we investigate self-supervised learning techniques for\nextracting highly informative representations from the input features, followed\nby a supervised training step with a significantly smaller number of reliable\nlabels. A 1 m resolution forest/non-forest reference map over Pennsylvania,\nUSA, allows for comparing different training approaches for the development of\nan effective forest mapping framework with limited labeled samples. We select\nthe best-performing approach over this test region and apply it in a real-case\nforest mapping scenario over the Amazon rainforest, where only very few labeled\ndata at high resolution are available. In this challenging scenario, the\nproposed self-supervised framework significantly enhances the classification\naccuracy with respect to fully-supervised methods, trained using the same\namount of labeled data, representing an extremely promising starting point for\nlarge-scale, very high-resolution forest mapping with TanDEM-X data.",
      "tldr_zh": "本研究利用 TanDEM-X InSAR 数据和自监督学习方法，实现 6 m 高分辨率森林映射，以克服中分辨率产品的局限性，如难以检测窄路和精确界定森林轮廓。研究者通过自监督学习从输入特征中提取信息，然后结合少量可靠标注数据进行监督训练，从而减少了对大规模标注数据集的依赖。在宾夕法尼亚的测试中，比较了不同训练方法，并在亚马逊雨林的真实场景中应用，结果显示，该框架显著提升了分类准确率，为大规模高分辨率森林映射提供了高效的起点。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "Preprint submitted to Remote Sensing of Environment",
      "pdf_url": "http://arxiv.org/pdf/2505.03327v1",
      "published_date": "2025-05-06 08:54:28 UTC",
      "updated_date": "2025-05-06 08:54:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:19:00.728024"
    },
    {
      "arxiv_id": "2505.03319v1",
      "title": "SD-VSum: A Method and Dataset for Script-Driven Video Summarization",
      "title_zh": "翻译失败",
      "authors": [
        "Manolis Mylonas",
        "Evlampios Apostolidis",
        "Vasileios Mezaris"
      ],
      "abstract": "In this work, we introduce the task of script-driven video summarization,\nwhich aims to produce a summary of the full-length video by selecting the parts\nthat are most relevant to a user-provided script outlining the visual content\nof the desired summary. Following, we extend a recently-introduced large-scale\ndataset for generic video summarization (VideoXum) by producing natural\nlanguage descriptions of the different human-annotated summaries that are\navailable per video. In this way we make it compatible with the introduced\ntask, since the available triplets of ``video, summary and summary\ndescription'' can be used for training a method that is able to produce\ndifferent summaries for a given video, driven by the provided script about the\ncontent of each summary. Finally, we develop a new network architecture for\nscript-driven video summarization (SD-VSum), that relies on the use of a\ncross-modal attention mechanism for aligning and fusing information from the\nvisual and text modalities. Our experimental evaluations demonstrate the\nadvanced performance of SD-VSum against state-of-the-art approaches for\nquery-driven and generic (unimodal and multimodal) summarization from the\nliterature, and document its capacity to produce video summaries that are\nadapted to each user's needs about their content.",
      "tldr_zh": "本文引入了 script-driven video summarization 任务，该任务通过用户提供的脚本选择视频中最相关部分生成摘要，并扩展了 VideoXum 数据集以包含视频、摘要和自然语言描述的三元组，支持不同摘要的训练。作者开发了 SD-VSum 网络架构，利用 cross-modal attention 机制对齐和融合视觉与文本信息。实验证明，SD-VSum 比现有查询驱动和通用总结方法性能更优，能根据用户需求产生适应性视频摘要。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2505.03319v1",
      "published_date": "2025-05-06 08:47:14 UTC",
      "updated_date": "2025-05-06 08:47:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:19:12.132977"
    },
    {
      "arxiv_id": "2505.03315v1",
      "title": "Artificial Behavior Intelligence: Technology, Challenges, and Future Directions",
      "title_zh": "人工行为智能：技术、挑战和未来方向",
      "authors": [
        "Kanghyun Jo",
        "Jehwan Choi",
        "Kwanho Kim",
        "Seongmin Kim",
        "Duy-Linh Nguyen",
        "Xuan-Thuy Vo",
        "Adri Priadana",
        "Tien-Dat Tran"
      ],
      "abstract": "Understanding and predicting human behavior has emerged as a core capability\nin various AI application domains such as autonomous driving, smart healthcare,\nsurveillance systems, and social robotics. This paper defines the technical\nframework of Artificial Behavior Intelligence (ABI), which comprehensively\nanalyzes and interprets human posture, facial expressions, emotions, behavioral\nsequences, and contextual cues. It details the essential components of ABI,\nincluding pose estimation, face and emotion recognition, sequential behavior\nanalysis, and context-aware modeling. Furthermore, we highlight the\ntransformative potential of recent advances in large-scale pretrained models,\nsuch as large language models (LLMs), vision foundation models, and multimodal\nintegration models, in significantly improving the accuracy and\ninterpretability of behavior recognition. Our research team has a strong\ninterest in the ABI domain and is actively conducting research, particularly\nfocusing on the development of intelligent lightweight models capable of\nefficiently inferring complex human behaviors. This paper identifies several\ntechnical challenges that must be addressed to deploy ABI in real-world\napplications including learning behavioral intelligence from limited data,\nquantifying uncertainty in complex behavior prediction, and optimizing model\nstructures for low-power, real-time inference. To tackle these challenges, our\nteam is exploring various optimization strategies including lightweight\ntransformers, graph-based recognition architectures, energy-aware loss\nfunctions, and multimodal knowledge distillation, while validating their\napplicability in real-time environments.",
      "tldr_zh": "这篇论文定义了 Artificial Behavior Intelligence (ABI) 的技术框架，用于全面分析和解释人类姿势、面部表情、情绪、行为序列以及上下文线索，包括关键组件如姿势估计、面部和情绪识别、顺序行为分析以及上下文感知建模。论文强调了大型预训练模型（如 LLMs、vision foundation models 和多模态集成模型）的最新进展，能够显著提升行为识别的准确性和可解释性。作者团队专注于开发智能轻量级模型来推断复杂人类行为，并指出了部署 ABI 的主要挑战，包括从有限数据学习行为智能、量化复杂行为预测的不确定性，以及优化模型结构以实现低功耗实时推理。为应对这些挑战，他们正在探索优化策略，如轻量级 Transformers、基于图形的识别架构、能量感知损失函数和多模态知识蒸馏，并在实时环境中进行验证。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 6 figures, Pre-print for IWIS2025",
      "pdf_url": "http://arxiv.org/pdf/2505.03315v1",
      "published_date": "2025-05-06 08:45:44 UTC",
      "updated_date": "2025-05-06 08:45:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:19:26.357098"
    },
    {
      "arxiv_id": "2505.03314v1",
      "title": "Mamba-Diffusion Model with Learnable Wavelet for Controllable Symbolic Music Generation",
      "title_zh": "Mamba-Diffusion 模型结合可学习小波用于可控符号音乐生成",
      "authors": [
        "Jincheng Zhang",
        "György Fazekas",
        "Charalampos Saitis"
      ],
      "abstract": "The recent surge in the popularity of diffusion models for image synthesis\nhas attracted new attention to their potential for generation tasks in other\ndomains. However, their applications to symbolic music generation remain\nlargely under-explored because symbolic music is typically represented as\nsequences of discrete events and standard diffusion models are not well-suited\nfor discrete data. We represent symbolic music as image-like pianorolls,\nfacilitating the use of diffusion models for the generation of symbolic music.\nMoreover, this study introduces a novel diffusion model that incorporates our\nproposed Transformer-Mamba block and learnable wavelet transform.\nClassifier-free guidance is utilised to generate symbolic music with target\nchords. Our evaluation shows that our method achieves compelling results in\nterms of music quality and controllability, outperforming the strong baseline\nin pianoroll generation. Our code is available at\nhttps://github.com/jinchengzhanggg/proffusion.",
      "tldr_zh": "该论文探讨了将扩散模型应用于符号音乐生成的问题，通过将符号音乐表示为图像般的 pianorolls 来克服标准扩散模型对离散数据的局限性。作者引入了一种新颖的扩散模型，结合 Transformer-Mamba block 和 learnable wavelet transform，以提升生成效率和质量。同时，利用 classifier-free guidance 实现对目标和弦的控制生成。实验结果表明，该方法在音乐质量和可控性方面优于基线模型。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03314v1",
      "published_date": "2025-05-06 08:44:52 UTC",
      "updated_date": "2025-05-06 08:44:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:19:40.004294"
    },
    {
      "arxiv_id": "2505.03303v1",
      "title": "Comparative Analysis of Lightweight Deep Learning Models for Memory-Constrained Devices",
      "title_zh": "轻量级深度学习模型在内存受限设备上的比较分析",
      "authors": [
        "Tasnim Shahriar"
      ],
      "abstract": "This paper presents a comprehensive evaluation of lightweight deep learning\nmodels for image classification, emphasizing their suitability for deployment\nin resource-constrained environments such as low-memory devices. Five\nstate-of-the-art architectures - MobileNetV3 Small, ResNet18, SqueezeNet,\nEfficientNetV2-S, and ShuffleNetV2 - are benchmarked across three diverse\ndatasets: CIFAR-10, CIFAR-100, and Tiny ImageNet. The models are assessed using\nfour key performance metrics: classification accuracy, inference time,\nfloating-point operations (FLOPs), and model size. Additionally, we investigate\nthe impact of hyperparameter tuning, data augmentation, and training paradigms\nby comparing pretrained models with scratch-trained counterparts, focusing on\nMobileNetV3 Small. Our findings reveal that transfer learning significantly\nenhances model accuracy and computational efficiency, particularly for complex\ndatasets like Tiny ImageNet. EfficientNetV2 consistently achieves the highest\naccuracy, while MobileNetV3 offers the best balance between accuracy and\nefficiency, and SqueezeNet excels in inference speed and compactness. This\nstudy highlights critical trade-offs between accuracy and efficiency, offering\nactionable insights for deploying lightweight models in real-world applications\nwhere computational resources are limited. By addressing these challenges, this\nresearch contributes to optimizing deep learning systems for edge computing and\nmobile platforms.",
      "tldr_zh": "这篇论文对五种轻量级深度学习模型（MobileNetV3 Small、ResNet18、SqueezeNet、EfficientNetV2-S 和 ShuffleNetV2）进行了全面比较评估，针对图像分类任务在内存受限设备上的适用性。模型在 CIFAR-10、CIFAR-100 和 Tiny ImageNet 数据集上进行了基准测试，评估指标包括分类准确率、推理时间、FLOPs 和模型大小，同时探讨了超参数调整、数据增强以及迁移学习（如预训练 vs. 从零训练 MobileNetV3 Small）的影响。研究发现，迁移学习显著提升了模型的准确率和计算效率，尤其在复杂数据集上；EfficientNetV2-S 表现出最高准确率，MobileNetV3 Small 则在准确率与效率间实现了最佳平衡，而 SqueezeNet 在推理速度和模型紧凑性方面最突出。该研究揭示了准确率与资源效率的权衡，提供优化深度学习模型在边缘计算和移动平台部署的关键见解。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "68-XX (Primary) 68Txx, 68T07 (Secondary)"
      ],
      "primary_category": "cs.CV",
      "comment": "22 pages, 10 figures, 4 tables, submitted to Springer - Pattern\n  Recognition and Image Analysis",
      "pdf_url": "http://arxiv.org/pdf/2505.03303v1",
      "published_date": "2025-05-06 08:36:01 UTC",
      "updated_date": "2025-05-06 08:36:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:19:53.725983"
    },
    {
      "arxiv_id": "2505.03299v1",
      "title": "Towards Efficient Benchmarking of Foundation Models in Remote Sensing: A Capabilities Encoding Approach",
      "title_zh": "迈向遥感领域基础模型的高效基准测试：一种能力编码方法",
      "authors": [
        "Pierre Adorni",
        "Minh-Tan Pham",
        "Stéphane May",
        "Sébastien Lefèvre"
      ],
      "abstract": "Foundation models constitute a significant advancement in computer vision:\nafter a single, albeit costly, training phase, they can address a wide array of\ntasks. In the field of Earth observation, over 75 remote sensing vision\nfoundation models have been developed in the past four years. However, none has\nconsistently outperformed the others across all available downstream tasks. To\nfacilitate their comparison, we propose a cost-effective method for predicting\na model's performance on multiple downstream tasks without the need for\nfine-tuning on each one. This method is based on what we call \"capabilities\nencoding.\" The utility of this novel approach is twofold: we demonstrate its\npotential to simplify the selection of a foundation model for a given new task,\nand we employ it to offer a fresh perspective on the existing literature,\nsuggesting avenues for future research. Codes are available at\nhttps://github.com/pierreadorni/capabilities-encoding.",
      "tldr_zh": "该论文针对远程感知领域的 Foundation Models 提出了一种高效基准测试方法，即 Capabilities Encoding Approach，以简化模型性能评估。方法基于模型能力的编码预测其在多个下游任务上的表现，而无需对每个任务进行微调，从而显著降低计算成本。研究结果表明，此方法不仅有助于为新任务快速选择合适的基础模型，还提供了对现有文献的新视角，并建议了未来研究方向。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at the MORSE workshop of CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.03299v1",
      "published_date": "2025-05-06 08:29:18 UTC",
      "updated_date": "2025-05-06 08:29:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:20:02.191464"
    },
    {
      "arxiv_id": "2505.03296v1",
      "title": "The Unreasonable Effectiveness of Discrete-Time Gaussian Process Mixtures for Robot Policy Learning",
      "title_zh": "离散时间高斯过程混合体在机器人策略学习中的不可思",
      "authors": [
        "Jan Ole von Hartz",
        "Adrian Röfer",
        "Joschka Boedecker",
        "Abhinav Valada"
      ],
      "abstract": "We present Mixture of Discrete-time Gaussian Processes (MiDiGap), a novel\napproach for flexible policy representation and imitation learning in robot\nmanipulation. MiDiGap enables learning from as few as five demonstrations using\nonly camera observations and generalizes across a wide range of challenging\ntasks. It excels at long-horizon behaviors such as making coffee, highly\nconstrained motions such as opening doors, dynamic actions such as scooping\nwith a spatula, and multimodal tasks such as hanging a mug. MiDiGap learns\nthese tasks on a CPU in less than a minute and scales linearly to large\ndatasets. We also develop a rich suite of tools for inference-time steering\nusing evidence such as collision signals and robot kinematic constraints. This\nsteering enables novel generalization capabilities, including obstacle\navoidance and cross-embodiment policy transfer. MiDiGap achieves\nstate-of-the-art performance on diverse few-shot manipulation benchmarks. On\nconstrained RLBench tasks, it improves policy success by 76 percentage points\nand reduces trajectory cost by 67%. On multimodal tasks, it improves policy\nsuccess by 48 percentage points and increases sample efficiency by a factor of\n20. In cross-embodiment transfer, it more than doubles policy success. We make\nthe code publicly available at https://midigap.cs.uni-freiburg.de.",
      "tldr_zh": "本研究提出了 MiDiGap（Mixture of Discrete-time Gaussian Processes），一种用于机器人操作的灵活策略表示和模仿学习方法，仅需少至 5 个相机观察演示即可实现高效学习。MiDiGap 适用于多种挑战性任务，包括长时序行为（如制作咖啡）、受限动作（如开门）、动态操作（如用铲子舀东西）和多模态任务（如挂杯子），并能在 CPU 上不到一分钟内学习，且线性扩展到大型数据集。该方法还提供了推理时转向工具，利用碰撞信号和机器人运动学约束，实现障碍物避免和跨设备策略转移。在基准测试中，MiDiGap 在 RLBench 任务上提升策略成功率 76 百分点并减少轨迹成本 67%，在多模态任务上提高成功率 48 百分点并提升样本效率 20 倍，在跨设备转移中使成功率增加一倍以上。研究代码已公开可用。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Submitted for publication to IEEE Transaction on Robotics",
      "pdf_url": "http://arxiv.org/pdf/2505.03296v1",
      "published_date": "2025-05-06 08:27:23 UTC",
      "updated_date": "2025-05-06 08:27:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:20:15.731381"
    },
    {
      "arxiv_id": "2505.03295v1",
      "title": "Capability-Driven Skill Generation with LLMs: A RAG-Based Approach for Reusing Existing Libraries and Interfaces",
      "title_zh": "翻译失败",
      "authors": [
        "Luis Miguel Vieira da Silva",
        "Aljosha Köcher",
        "Nicolas König",
        "Felix Gehlhoff",
        "Alexander Fay"
      ],
      "abstract": "Modern automation systems increasingly rely on modular architectures, with\ncapabilities and skills as one solution approach. Capabilities define the\nfunctions of resources in a machine-readable form and skills provide the\nconcrete implementations that realize those capabilities. However, the\ndevelopment of a skill implementation conforming to a corresponding capability\nremains a time-consuming and challenging task. In this paper, we present a\nmethod that treats capabilities as contracts for skill implementations and\nleverages large language models to generate executable code based on natural\nlanguage user input. A key feature of our approach is the integration of\nexisting software libraries and interface technologies, enabling the generation\nof skill implementations across different target languages. We introduce a\nframework that allows users to incorporate their own libraries and resource\ninterfaces into the code generation process through a retrieval-augmented\ngeneration architecture. The proposed method is evaluated using an autonomous\nmobile robot controlled via Python and ROS 2, demonstrating the feasibility and\nflexibility of the approach.",
      "tldr_zh": "这篇论文提出了一种基于大型语言模型（LLMs）的技能生成方法，将 capabilities 视为技能实现的合同，通过检索增强生成（RAG）架构根据自然语言输入自动生成可执行代码，从而重用现有软件库和接口技术。关键特征包括支持不同目标语言的技能实现，并允许用户整合自定义库和资源接口，以提高开发效率。该方法在 Python 和 ROS 2 控制的自主移动机器人上进行了评估，证明了其可行性和灵活性。",
      "categories": [
        "cs.AI",
        "cs.RO",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03295v1",
      "published_date": "2025-05-06 08:27:04 UTC",
      "updated_date": "2025-05-06 08:27:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:20:27.353102"
    },
    {
      "arxiv_id": "2505.03281v1",
      "title": "Physics-inspired Energy Transition Neural Network for Sequence Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Zhou Wu",
        "Junyi An",
        "Baile Xu",
        "Furao Shen",
        "Jian Zhao"
      ],
      "abstract": "Recently, the superior performance of Transformers has made them a more\nrobust and scalable solution for sequence modeling than traditional recurrent\nneural networks (RNNs). However, the effectiveness of Transformer in capturing\nlong-term dependencies is primarily attributed to their comprehensive\npair-modeling process rather than inherent inductive biases toward sequence\nsemantics. In this study, we explore the capabilities of pure RNNs and reassess\ntheir long-term learning mechanisms. Inspired by the physics energy transition\nmodels that track energy changes over time, we propose a effective recurrent\nstructure called the``Physics-inspired Energy Transition Neural Network\"\n(PETNN). We demonstrate that PETNN's memory mechanism effectively stores\ninformation over long-term dependencies. Experimental results indicate that\nPETNN outperforms transformer-based methods across various sequence tasks.\nFurthermore, owing to its recurrent nature, PETNN exhibits significantly lower\ncomplexity. Our study presents an optimal foundational recurrent architecture\nand highlights the potential for developing effective recurrent neural networks\nin fields currently dominated by Transformer.",
      "tldr_zh": "本文重新评估了RNN在序列建模中的长期学习机制，并提出了一种受物理能量转移模型启发的RNN结构，名为PETNN（Physics-inspired Energy Transition Neural Network）。PETNN通过有效的记忆机制增强了对长期依赖的存储能力，在实验中表现出色，优于Transformer-based方法，并显著降低了计算复杂度。该研究为RNN提供了一个优化基础架构，展示了其在Transformer主导领域的潜在应用前景。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03281v1",
      "published_date": "2025-05-06 08:07:15 UTC",
      "updated_date": "2025-05-06 08:07:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:20:38.504819"
    },
    {
      "arxiv_id": "2505.03275v1",
      "title": "RAG-MCP: Mitigating Prompt Bloat in LLM Tool Selection via Retrieval-Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Tiantian Gan",
        "Qiyao Sun"
      ],
      "abstract": "Large language models (LLMs) struggle to effectively utilize a growing number\nof external tools, such as those defined by the Model Context Protocol\n(MCP)\\cite{IntroducingMCP}, due to prompt bloat and selection complexity. We\nintroduce RAG-MCP, a Retrieval-Augmented Generation framework that overcomes\nthis challenge by offloading tool discovery. RAG-MCP uses semantic retrieval to\nidentify the most relevant MCP(s) for a given query from an external index\nbefore engaging the LLM. Only the selected tool descriptions are passed to the\nmodel, drastically reducing prompt size and simplifying decision-making.\nExperiments, including an MCP stress test, demonstrate RAG-MCP significantly\ncuts prompt tokens (e.g., by over 50%) and more than triples tool selection\naccuracy (43.13% vs 13.62% baseline) on benchmark tasks. RAG-MCP enables\nscalable and accurate tool integration for LLMs.",
      "tldr_zh": "大语言模型(LLMs)在处理越来越多的外部工具时，面临提示膨胀(prompt bloat)和选择复杂的问题。论文提出RAG-MCP框架，通过Retrieval-Augmented Generation利用语义检索从外部索引中识别最相关的MCP工具描述，仅将这些描述传递给模型，从而显著减少提示大小并简化决策。实验结果显示，RAG-MCP将提示tokens减少超过50%，并将工具选择准确率提高三倍以上（从13.62%到43.13%），从而实现LLMs工具集成的可扩展性和准确性。",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03275v1",
      "published_date": "2025-05-06 08:05:35 UTC",
      "updated_date": "2025-05-06 08:05:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:20:52.190026"
    },
    {
      "arxiv_id": "2505.03265v1",
      "title": "Synthline: A Product Line Approach for Synthetic Requirements Engineering Data Generation using Large Language Models",
      "title_zh": "Synthline：一种基于大型语言模型的产品线方法，用于合成需求",
      "authors": [
        "Abdelkarim El-Hajjami",
        "Camille Salinesi"
      ],
      "abstract": "While modern Requirements Engineering (RE) heavily relies on natural language\nprocessing and Machine Learning (ML) techniques, their effectiveness is limited\nby the scarcity of high-quality datasets. This paper introduces Synthline, a\nProduct Line (PL) approach that leverages Large Language Models to\nsystematically generate synthetic RE data for classification-based use cases.\nThrough an empirical evaluation conducted in the context of using ML for the\nidentification of requirements specification defects, we investigated both the\ndiversity of the generated data and its utility for training downstream models.\nOur analysis reveals that while synthetic datasets exhibit less diversity than\nreal data, they are good enough to serve as viable training resources.\nMoreover, our evaluation shows that combining synthetic and real data leads to\nsubstantial performance improvements. Specifically, hybrid approaches achieve\nup to 85% improvement in precision and a 2x increase in recall compared to\nmodels trained exclusively on real data. These findings demonstrate the\npotential of PL-based synthetic data generation to address data scarcity in RE.\nWe make both our implementation and generated datasets publicly available to\nsupport reproducibility and advancement in the field.",
      "tldr_zh": "本文提出Synthline，一种基于Product Line (PL)的方法，利用Large Language Models (LLMs)系统生成合成Requirements Engineering (RE)数据，以解决RE领域高质量数据集稀缺的问题。通过实证评估，研究发现合成数据虽多样性不如真实数据，但可作为有效训练资源，且将合成数据与真实数据结合，能使Machine Learning (ML)模型的精确度提高高达85%并将召回率提高2倍。这些发现展示了PL-based合成数据生成的潜力，并通过公开实现和数据集支持进一步研究。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03265v1",
      "published_date": "2025-05-06 07:57:16 UTC",
      "updated_date": "2025-05-06 07:57:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:21:04.491188"
    },
    {
      "arxiv_id": "2505.03242v1",
      "title": "Seeing the Abstract: Translating the Abstract Language for Vision Language Models",
      "title_zh": "洞察抽象：为视觉语言模型翻译抽象语言",
      "authors": [
        "Davide Talon",
        "Federico Girella",
        "Ziyue Liu",
        "Marco Cristani",
        "Yiming Wang"
      ],
      "abstract": "Natural language goes beyond dryly describing visual content. It contains\nrich abstract concepts to express feeling, creativity and properties that\ncannot be directly perceived. Yet, current research in Vision Language Models\n(VLMs) has not shed light on abstract-oriented language. Our research breaks\nnew ground by uncovering its wide presence and under-estimated value, with\nextensive analysis. Particularly, we focus our investigation on the fashion\ndomain, a highly-representative field with abstract expressions. By analyzing\nrecent large-scale multimodal fashion datasets, we find that abstract terms\nhave a dominant presence, rivaling the concrete ones, providing novel\ninformation, and being useful in the retrieval task. However, a critical\nchallenge emerges: current general-purpose or fashion-specific VLMs are\npre-trained with databases that lack sufficient abstract words in their text\ncorpora, thus hindering their ability to effectively represent\nabstract-oriented language. We propose a training-free and model-agnostic\nmethod, Abstract-to-Concrete Translator (ACT), to shift abstract\nrepresentations towards well-represented concrete ones in the VLM latent space,\nusing pre-trained models and existing multimodal databases. On the\ntext-to-image retrieval task, despite being training-free, ACT outperforms the\nfine-tuned VLMs in both same- and cross-dataset settings, exhibiting its\neffectiveness with a strong generalization capability. Moreover, the\nimprovement introduced by ACT is consistent with various VLMs, making it a\nplug-and-play solution.",
      "tldr_zh": "该研究揭示了 Vision Language Models (VLMs) 在处理抽象语言（如情感和创意概念）方面的不足，通过对时尚领域的多模态数据集分析，发现抽象术语在表达和检索任务中占有主导地位且价值被低估。针对 VLMs 因训练数据缺乏抽象词汇而导致的表示问题，论文提出了一种无训练、模型无关的方法 Abstract-to-Concrete Translator (ACT)，利用预训练模型和现有数据库将抽象表示转化为具体表示。实验结果表明，ACT 在文本到图像检索任务中超越了微调的 VLMs，并在同域和跨域设置中展现出强大的泛化能力，使其成为一种即插即用的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to CVPR25. Project page:\n  https://davidetalon.github.io/fashionact-page/",
      "pdf_url": "http://arxiv.org/pdf/2505.03242v1",
      "published_date": "2025-05-06 07:14:10 UTC",
      "updated_date": "2025-05-06 07:14:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:21:15.935446"
    },
    {
      "arxiv_id": "2505.03217v1",
      "title": "Accelerating Evolution: Integrating PSO Principles into Real-Coded Genetic Algorithm Crossover",
      "title_zh": "加速进化：将 PSO 原理整合到实数编码遗传算法交叉操作中",
      "authors": [
        "Xiaobo Jin",
        "JiaShu Tu"
      ],
      "abstract": "This study introduces an innovative crossover operator named Particle Swarm\nOptimization-inspired Crossover (PSOX), which is specifically developed for\nreal-coded genetic algorithms. Departing from conventional crossover approaches\nthat only exchange information between individuals within the same generation,\nPSOX uniquely incorporates guidance from both the current global best solution\nand historical optimal solutions across multiple generations. This novel\nmechanism enables the algorithm to maintain population diversity while\nsimultaneously accelerating convergence toward promising regions of the search\nspace. The effectiveness of PSOX is rigorously evaluated through comprehensive\nexperiments on 15 benchmark test functions with diverse characteristics,\nincluding unimodal, multimodal, and highly complex landscapes. Comparative\nanalysis against five state-of-the-art crossover operators reveals that PSOX\nconsistently delivers superior performance in terms of solution accuracy,\nalgorithmic stability, and convergence speed, especially when combined with an\nappropriate mutation strategy. Furthermore, the study provides an in-depth\ninvestigation of how different mutation rates influence PSOX's performance,\nyielding practical guidelines for parameter tuning when addressing optimization\nproblems with varying landscape properties.",
      "tldr_zh": "本文提出了一种名为 PSOX 的创新交叉操作符，用于实数编码遗传算法中，该操作符整合了 PSO (Particle Swarm Optimization) 原则，通过利用当前全局最优解和历史最优解，同时保持种群多样性并加速向搜索空间的有前景区域收敛。实验在 15 个基准测试函数上进行，包括单峰、多峰和复杂景观，与五种最先进交叉操作符相比，PSOX 在解决方案准确性、算法稳定性及收敛速度方面表现出显著优势，尤其当结合适当的变异策略时。研究还深入分析了不同变异率对 PSOX 性能的影响，并提供了针对不同优化问题景观的实用参数调整指南。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "I.2.8; G.1.6"
      ],
      "primary_category": "cs.NE",
      "comment": "14 pages,2 figures,4 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.03217v1",
      "published_date": "2025-05-06 06:17:57 UTC",
      "updated_date": "2025-05-06 06:17:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:21:27.566282"
    },
    {
      "arxiv_id": "2505.03214v1",
      "title": "DocSpiral: A Platform for Integrated Assistive Document Annotation through Human-in-the-Spiral",
      "title_zh": "翻译失败",
      "authors": [
        "Qiang Sun",
        "Sirui Li",
        "Tingting Bi",
        "Du Huynh",
        "Mark Reynolds",
        "Yuanyi Luo",
        "Wei Liu"
      ],
      "abstract": "Acquiring structured data from domain-specific, image-based documents such as\nscanned reports is crucial for many downstream tasks but remains challenging\ndue to document variability. Many of these documents exist as images rather\nthan as machine-readable text, which requires human annotation to train\nautomated extraction systems. We present DocSpiral, the first\nHuman-in-the-Spiral assistive document annotation platform, designed to address\nthe challenge of extracting structured information from domain-specific,\nimage-based document collections. Our spiral design establishes an iterative\ncycle in which human annotations train models that progressively require less\nmanual intervention. DocSpiral integrates document format normalization,\ncomprehensive annotation interfaces, evaluation metrics dashboard, and API\nendpoints for the development of AI / ML models into a unified workflow.\nExperiments demonstrate that our framework reduces annotation time by at least\n41\\% while showing consistent performance gains across three iterations during\nmodel training. By making this annotation platform freely accessible, we aim to\nlower barriers to AI/ML models development in document processing, facilitating\nthe adoption of large language models in image-based, document-intensive fields\nsuch as geoscience and healthcare. The system is freely available at:\nhttps://app.ai4wa.com. The demonstration video is available:\nhttps://app.ai4wa.com/docs/docspiral/demo.",
      "tldr_zh": "该论文提出 DocSpiral，一种集成辅助文档注释平台，通过 Human-in-the-Spiral 的迭代循环设计，帮助从领域特定图像-based 文档（如扫描报告）中提取结构化数据，从而减少手动干预。平台整合了文档格式规范化、全面注释界面、评估指标仪表板和 API 端点，支持 AI/ML 模型的开发和训练。实验结果显示，DocSpiral 减少了至少 41% 的注释时间，并在三个迭代的模型训练中实现一致性能提升。该平台免费开放，旨在降低 AI/ML 在图像-based 文档处理领域的采用门槛，如地质科学和医疗领域。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03214v1",
      "published_date": "2025-05-06 06:02:42 UTC",
      "updated_date": "2025-05-06 06:02:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:21:42.572265"
    },
    {
      "arxiv_id": "2505.03204v2",
      "title": "DCS-ST for Classification of Breast Cancer Histopathology Images with Limited Annotations",
      "title_zh": "翻译失败",
      "authors": [
        "Liu Suxing",
        "Byungwon Min"
      ],
      "abstract": "Deep learning methods have shown promise in classifying breast cancer\nhistopathology images, but their performance often declines with limited\nannotated data, a critical challenge in medical imaging due to the high cost\nand expertise required for annotations.",
      "tldr_zh": "本研究针对乳腺癌组织病理图像分类问题，探讨了深度学习方法的潜力，但指出在标注数据有限时，其性能会显著下降，这是医疗成像领域的主要挑战，因为标注过程需要高成本和专业知识。论文提出了DCS-ST方法，该方法旨在通过优化模型设计来处理数据标注稀缺的情况。实验结果表明，DCS-ST在有限标注条件下提升了分类准确性，为实际医疗应用提供了更高效的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03204v2",
      "published_date": "2025-05-06 05:38:17 UTC",
      "updated_date": "2025-05-07 04:09:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:21:53.292925"
    },
    {
      "arxiv_id": "2505.03196v1",
      "title": "A Trustworthy Multi-LLM Network: Challenges,Solutions, and A Use Case",
      "title_zh": "翻译失败",
      "authors": [
        "Haoxiang Luo",
        "Gang Sun",
        "Yinqiu Liu",
        "Dusit Niyato",
        "Hongfang Yu",
        "Mohammed Atiquzzaman",
        "Schahram Dustdar"
      ],
      "abstract": "Large Language Models (LLMs) demonstrate strong potential across a variety of\ntasks in communications and networking due to their advanced reasoning\ncapabilities. However, because different LLMs have different model structures\nand are trained using distinct corpora and methods, they may offer varying\noptimization strategies for the same network issues. Moreover, the limitations\nof an individual LLM's training data, aggravated by the potential maliciousness\nof its hosting device, can result in responses with low confidence or even\nbias. To address these challenges, we propose a blockchain-enabled\ncollaborative framework that connects multiple LLMs into a Trustworthy\nMulti-LLM Network (MultiLLMN). This architecture enables the cooperative\nevaluation and selection of the most reliable and high-quality responses to\ncomplex network optimization problems. Specifically, we begin by reviewing\nrelated work and highlighting the limitations of existing LLMs in collaboration\nand trust, emphasizing the need for trustworthiness in LLM-based systems. We\nthen introduce the workflow and design of the proposed Trustworthy MultiLLMN\nframework. Given the severity of False Base Station (FBS) attacks in B5G and 6G\ncommunication systems and the difficulty of addressing such threats through\ntraditional modeling techniques, we present FBS defense as a case study to\nempirically validate the effectiveness of our approach. Finally, we outline\npromising future research directions in this emerging area.",
      "tldr_zh": "该论文探讨了大型语言模型（LLMs）在通信和网络任务中的潜力及其挑战，包括不同LLMs的结构差异和训练局限性可能导致响应低自信度或偏见的问题。为解决这些问题，作者提出一个区块链启用的协作框架，构建可信的多LLM网络（Trustworthy MultiLLMN），通过合作评估和选择最可靠的响应来优化网络问题。论文以False Base Station (FBS) 攻击防御作为案例研究，验证了框架的有效性，并概述了未来研究方向，如增强LLM协作和信任机制。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03196v1",
      "published_date": "2025-05-06 05:32:46 UTC",
      "updated_date": "2025-05-06 05:32:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:22:05.729115"
    },
    {
      "arxiv_id": "2505.03193v1",
      "title": "A study on audio synchronous steganography detection and distributed guide inference model based on sliding spectral features and intelligent inference drive",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Meng"
      ],
      "abstract": "With the rise of short video platforms in global communication, embedding\nsteganographic data in audio synchronization streams has emerged as a new\ncovert communication method. To address the limitations of traditional\ntechniques in detecting synchronized steganography, this paper proposes a\ndetection and distributed guidance reconstruction model based on short video\n\"Yupan\" samples released by China's South Sea Fleet on TikTok. The method\nintegrates sliding spectrum feature extraction and intelligent inference\nmechanisms. A 25 ms sliding window with short-time Fourier transform (STFT) is\nused to extract the main frequency trajectory and construct the synchronization\nframe detection model (M1), identifying a frame flag \"FFFFFFFFFFFFFFFFFF80\".\nThe subsequent 32-byte payload is decoded by a structured model (M2) to infer\ndistributed guidance commands. Analysis reveals a low-entropy, repetitive byte\nsequence in the 36 to 45 second audio segment with highly concentrated spectral\nenergy, confirming the presence of synchronization frames. Although plaintext\nsemantics are not restored, the consistency in command field layout suggests\nfeatures of military communication protocols. The multi-segment splicing model\nfurther shows cross-video embedding and centralized decoding capabilities. The\nproposed framework validates the effectiveness of sliding spectral features for\nsynchronized steganography detection and builds an extensible inference model\nfor covert communication analysis and tactical guidance simulation on open\nplatforms.",
      "tldr_zh": "该论文研究了音频同步隐写术（steganography）的检测问题，针对传统方法的局限性，提出了一种基于滑动谱特征和智能推理驱动的检测及分布式引导重建模型，使用短时傅里叶变换（STFT）和25 ms滑动窗口提取主频率轨迹。模型包括同步帧检测模型（M1）识别特定帧标志，以及结构化模型（M2）解码负载以推断分布式引导命令；在分析中国南海舰队短视频样本时，发现音频段有低熵重复序列和高度集中谱能量，揭示了可能的军事通信协议特征。实验结果验证了该框架在同步隐写术检测的有效性，并为隐秘通信分析和战术引导模拟提供了可扩展的推理模型。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CR",
        "eess.AS",
        "94A12 (Primary), 68T07, 42A38 (Secondary)",
        "H.3.3; I.5.4; I.2.6"
      ],
      "primary_category": "cs.SD",
      "comment": "This paper proposes a novel framework for detecting steganographic\n  content in short video audio streams using sliding spectral features and\n  distributed inference models, combining STFT analysis, entropy-based\n  synchronization, and deep learning-driven decoding strategies",
      "pdf_url": "http://arxiv.org/pdf/2505.03193v1",
      "published_date": "2025-05-06 05:24:11 UTC",
      "updated_date": "2025-05-06 05:24:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:22:20.082229"
    },
    {
      "arxiv_id": "2505.03189v1",
      "title": "Patterns and Mechanisms of Contrastive Activation Engineering",
      "title_zh": "对比激活工程的模式和机制",
      "authors": [
        "Yixiong Hao",
        "Ayush Panda",
        "Stepan Shabalin",
        "Sheikh Abdur Raheem Ali"
      ],
      "abstract": "Controlling the behavior of Large Language Models (LLMs) remains a\nsignificant challenge due to their inherent complexity and opacity. While\ntechniques like fine-tuning can modify model behavior, they typically require\nextensive computational resources. Recent work has introduced a class of\ncontrastive activation engineering (CAE) techniques as promising approaches for\nsteering LLM outputs through targeted modifications to their internal\nrepresentations. Applied at inference-time with zero cost, CAE has the\npotential to introduce a new paradigm of flexible, task-specific LLM behavior\ntuning. We analyze the performance of CAE in in-distribution,\nout-of-distribution settings, evaluate drawbacks, and begin to develop\ncomprehensive guidelines for its effective deployment. We find that 1. CAE is\nonly reliably effective when applied to in-distribution contexts. 2. Increasing\nthe number of samples used to generate steering vectors has diminishing returns\nat around 80 samples. 3. Steering vectors are susceptible to adversarial inputs\nthat reverses the behavior that is steered for. 4. Steering vectors harm the\noverall model perplexity. 5. Larger models are more resistant to\nsteering-induced degradation.",
      "tldr_zh": "本论文探讨了控制大型语言模型(LLMs)行为的挑战，并引入对比激活工程(CAE)技术作为一种在推理时无需额外计算资源的引导方法。研究发现，CAE在分布内场景中可靠有效，但对分布外输入表现不佳，且使用约80个样本生成转向向量后收益递减；此外，转向向量易受对抗输入逆转，并会降低模型的整体困惑度。总体而言，较大模型对CAE引发的性能退化更具抵抗力，该研究为CAE的有效部署提供了初步指导。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "Published at the ICLR 2025 Bi-Align, HAIC, and Building Trust\n  workshops",
      "pdf_url": "http://arxiv.org/pdf/2505.03189v1",
      "published_date": "2025-05-06 05:15:12 UTC",
      "updated_date": "2025-05-06 05:15:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:22:29.140154"
    },
    {
      "arxiv_id": "2505.03176v2",
      "title": "seq-JEPA: Autoregressive Predictive Learning of Invariant-Equivariant World Models",
      "title_zh": "seq",
      "authors": [
        "Hafez Ghaemi",
        "Eilif Muller",
        "Shahab Bakhtiari"
      ],
      "abstract": "Current self-supervised algorithms commonly rely on transformations such as\ndata augmentation and masking to learn visual representations. This is achieved\nby enforcing invariance or equivariance with respect to these transformations\nafter encoding two views of an image. This dominant two-view paradigm often\nlimits the flexibility of learned representations for downstream adaptation by\ncreating performance trade-offs between high-level invariance-demanding tasks\nsuch as image classification and more fine-grained equivariance-related tasks.\nIn this work, we proposes \\emph{seq-JEPA}, a world modeling framework that\nintroduces architectural inductive biases into joint-embedding predictive\narchitectures to resolve this trade-off. Without relying on dual equivariance\npredictors or loss terms, seq-JEPA simultaneously learns two architecturally\nsegregated representations: one equivariant to specified transformations and\nanother invariant to them. To do so, our model processes short sequences of\ndifferent views (observations) of inputs. Each encoded view is concatenated\nwith an embedding of the relative transformation (action) that produces the\nnext observation in the sequence. These view-action pairs are passed through a\ntransformer encoder that outputs an aggregate representation. A predictor head\nthen conditions this aggregate representation on the upcoming action to predict\nthe representation of the next observation. Empirically, seq-JEPA demonstrates\nstrong performance on both equivariant and invariant benchmarks without\nsacrificing one for the other. Furthermore, it excels at tasks that inherently\nrequire aggregating a sequence of observations, such as path integration across\nactions and predictive learning across eye movements.",
      "tldr_zh": "本文提出 seq-JEPA 框架，一种自回归预测学习方法，用于构建同时学习不变性(invariant)和等变性(equivariant)世界模型，解决传统自监督算法在图像分类等高层次任务与细粒度任务之间性能权衡的问题。该框架通过架构诱导偏差处理输入序列的不同视图，将每个编码视图与相对变换(行动)嵌入串联，经 transformer 编码器聚合表示，并使用预测头基于即将到来的行动预测下一个观察的表示。实验结果表明，seq-JEPA 在等变性和不变性基准上均表现出强性能，且在路径整合和预测学习等需要序列聚合的任务中表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03176v2",
      "published_date": "2025-05-06 04:39:11 UTC",
      "updated_date": "2025-05-22 06:37:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:22:40.785964"
    },
    {
      "arxiv_id": "2505.03173v1",
      "title": "RAVU: Retrieval Augmented Video Understanding with Compositional Reasoning over Graph",
      "title_zh": "翻译失败",
      "authors": [
        "Sameer Malik",
        "Moyuru Yamada",
        "Ayush Singh",
        "Dishank Aggarwal"
      ],
      "abstract": "Comprehending long videos remains a significant challenge for Large\nMulti-modal Models (LMMs). Current LMMs struggle to process even minutes to\nhours videos due to their lack of explicit memory and retrieval mechanisms. To\naddress this limitation, we propose RAVU (Retrieval Augmented Video\nUnderstanding), a novel framework for video understanding enhanced by retrieval\nwith compositional reasoning over a spatio-temporal graph. We construct a graph\nrepresentation of the video, capturing both spatial and temporal relationships\nbetween entities. This graph serves as a long-term memory, allowing us to track\nobjects and their actions across time. To answer complex queries, we decompose\nthe queries into a sequence of reasoning steps and execute these steps on the\ngraph, retrieving relevant key information. Our approach enables more accurate\nunderstanding of long videos, particularly for queries that require multi-hop\nreasoning and tracking objects across frames. Our approach demonstrate superior\nperformances with limited retrieved frames (5-10) compared with other SOTA\nmethods and baselines on two major video QA datasets, NExT-QA and EgoSchema.",
      "tldr_zh": "本研究提出 RAVU（Retrieval Augmented Video Understanding）框架，以解决大型多模态模型（LMMs）在处理长视频时缺乏显式记忆和检索机制的问题。RAVU 通过构建时空图（spatio-temporal graph）来捕捉视频中实体之间的空间和时间关系，作为长期记忆跟踪对象和动作；同时，将复杂查询分解为序列推理步骤，并在图上执行这些步骤以检索关键信息。该方法特别适用于需要多跳推理（multi-hop reasoning）和跨帧对象跟踪的查询，并在 NExT-QA 和 EgoSchema 等视频问答数据集上，使用有限的检索帧（5-10）时，表现出优于现有 SOTA 方法的性能。总体上，RAVU 提升了长视频理解的准确性和效率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03173v1",
      "published_date": "2025-05-06 04:38:09 UTC",
      "updated_date": "2025-05-06 04:38:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:22:52.806250"
    },
    {
      "arxiv_id": "2505.03172v1",
      "title": "Null Counterfactual Factor Interactions for Goal-Conditioned Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Caleb Chuck",
        "Fan Feng",
        "Carl Qi",
        "Chang Shi",
        "Siddhant Agarwal",
        "Amy Zhang",
        "Scott Niekum"
      ],
      "abstract": "Hindsight relabeling is a powerful tool for overcoming sparsity in\ngoal-conditioned reinforcement learning (GCRL), especially in certain domains\nsuch as navigation and locomotion. However, hindsight relabeling can struggle\nin object-centric domains. For example, suppose that the goal space consists of\na robotic arm pushing a particular target block to a goal location. In this\ncase, hindsight relabeling will give high rewards to any trajectory that does\nnot interact with the block. However, these behaviors are only useful when the\nobject is already at the goal -- an extremely rare case in practice. A dataset\ndominated by these kinds of trajectories can complicate learning and lead to\nfailures. In object-centric domains, one key intuition is that meaningful\ntrajectories are often characterized by object-object interactions such as\npushing the block with the gripper. To leverage this intuition, we introduce\nHindsight Relabeling using Interactions (HInt), which combines interactions\nwith hindsight relabeling to improve the sample efficiency of downstream RL.\nHowever because interactions do not have a consensus statistical definition\ntractable for downstream GCRL, we propose a definition of interactions based on\nthe concept of null counterfactual: a cause object is interacting with a target\nobject if, in a world where the cause object did not exist, the target object\nwould have different transition dynamics. We leverage this definition to infer\ninteractions in Null Counterfactual Interaction Inference (NCII), which uses a\n\"nulling'' operation with a learned model to infer interactions. NCII is able\nto achieve significantly improved interaction inference accuracy in both simple\nlinear dynamics domains and dynamic robotic domains in Robosuite, Robot Air\nHockey, and Franka Kitchen and HInt improves sample efficiency by up to 4x.",
      "tldr_zh": "这篇论文针对目标条件强化学习(GCRL)中的稀疏奖励问题，指出传统Hindsight Relabeling在物体中心域（如机器人臂任务）中效率低下，因为它会奖励不涉及物体交互的轨迹。作者提出Hindsight Relabeling using Interactions (HInt)方法，通过结合物体交互来提升样本效率。交互定义基于Null Counterfactual概念，即如果某个物体不存在，目标物体的动态会改变，则视为交互。实验结果显示，Null Counterfactual Interaction Inference (NCII)算法在Robosuite等环境中显著提高了交互推断准确性，并使HInt将样本效率提升高达4倍。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.03172v1",
      "published_date": "2025-05-06 04:32:47 UTC",
      "updated_date": "2025-05-06 04:32:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:23:04.377975"
    },
    {
      "arxiv_id": "2505.03171v1",
      "title": "CombiBench: Benchmarking LLM Capability for Combinatorial Mathematics",
      "title_zh": "翻译失败",
      "authors": [
        "Junqi Liu",
        "Xiaohan Lin",
        "Jonas Bayer",
        "Yael Dillies",
        "Weijie Jiang",
        "Xiaodan Liang",
        "Roman Soletskyi",
        "Haiming Wang",
        "Yunzhou Xie",
        "Beibei Xiong",
        "Zhengfeng Yang",
        "Jujian Zhang",
        "Lihong Zhi",
        "Jia Li",
        "Zhengying Liu"
      ],
      "abstract": "Neurosymbolic approaches integrating large language models with formal\nreasoning have recently achieved human-level performance on mathematics\ncompetition problems in algebra, geometry and number theory. In comparison,\ncombinatorics remains a challenging domain, characterized by a lack of\nappropriate benchmarks and theorem libraries. To address this gap, we introduce\nCombiBench, a comprehensive benchmark comprising 100 combinatorial problems,\neach formalized in Lean~4 and paired with its corresponding informal statement.\nThe problem set covers a wide spectrum of difficulty levels, ranging from\nmiddle school to IMO and university level, and span over ten combinatorial\ntopics. CombiBench is suitable for testing IMO solving capabilities since it\nincludes all IMO combinatorial problems since 2000 (except IMO 2004 P3 as its\nstatement contain an images). Furthermore, we provide a comprehensive and\nstandardized evaluation framework, dubbed Fine-Eval (for\n$\\textbf{F}$ill-in-the-blank $\\textbf{in}$ L$\\textbf{e}$an Evaluation), for\nformal mathematics. It accommodates not only proof-based problems but also, for\nthe first time, the evaluation of fill-in-the-blank questions. Using Fine-Eval\nas the evaluation method and Kimina Lean Server as the backend, we benchmark\nseveral LLMs on CombiBench and observe that their capabilities for formally\nsolving combinatorial problems remain limited. Among all models tested (none of\nwhich has been trained for this particular task), Kimina-Prover attains the\nbest results, solving 7 problems (out of 100) under both ``with solution'' and\n``without solution'' scenarios. We open source the benchmark dataset alongside\nwith the code of the proposed evaluation method at\nhttps://github.com/MoonshotAI/CombiBench/.",
      "tldr_zh": "这篇论文引入了 CombiBench，一个包含 100 个形式化组合数学问题的基准，用于评估大型语言模型 (LLMs) 在该领域的能力，问题覆盖从中学到国际数学奥林匹克 (IMO) 和大学水平的十多个主题，并包括 2000 年以来的大部分 IMO 组合问题。CombiBench 每道问题均在 Lean 4 中形式化，并配有非正式陈述，同时提供了 Fine-Eval 评估框架，该框架支持证明问题和填空题的标准化评估。实验结果显示，现有 LLMs 在形式化解决组合问题方面能力有限，其中 Kimina-Prover 表现最佳，在“有解决方案”和“无解决方案”场景下各解决了 7 个问题。作者开源了数据集和代码，以促进进一步研究。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03171v1",
      "published_date": "2025-05-06 04:32:17 UTC",
      "updated_date": "2025-05-06 04:32:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:23:17.315456"
    },
    {
      "arxiv_id": "2505.06270v1",
      "title": "Importance Analysis for Dynamic Control of Balancing Parameter in a Simple Knowledge Distillation Setting",
      "title_zh": "翻译失败",
      "authors": [
        "Seongmin Kim",
        "Kwanho Kim",
        "Minseung Kim",
        "Kanghyun Jo"
      ],
      "abstract": "Although deep learning models owe their remarkable success to deep and\ncomplex architectures, this very complexity typically comes at the expense of\nreal-time performance. To address this issue, a variety of model compression\ntechniques have been proposed, among which knowledge distillation (KD) stands\nout for its strong empirical performance. The KD contains two concurrent\nprocesses: (i) matching the outputs of a large, pre-trained teacher network and\na lightweight student network, and (ii) training the student to solve its\ndesignated downstream task. The associated loss functions are termed the\ndistillation loss and the downsteam-task loss, respectively. Numerous prior\nstudies report that KD is most effective when the influence of the distillation\nloss outweighs that of the downstream-task loss. The influence(or importance)\nis typically regulated by a balancing parameter. This paper provides a\nmathematical rationale showing that in a simple KD setting when the loss is\ndecreasing, the balancing parameter should be dynamically adjusted",
      "tldr_zh": "本论文分析了在简单知识蒸馏（KD）设置中，平衡参数的动态控制，以优化模型压缩效果。KD 涉及匹配预训练教师网络的输出与轻量级学生网络的输出，同时训练学生网络处理下游任务；当蒸馏损失的影响大于下游任务损失时，KD 的性能最佳。论文通过数学依据证明，在损失函数减少时，应动态调整平衡参数，以提升整体训练效率和模型表现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "3 pages, 2 figures, conference preprint for IWIS2025",
      "pdf_url": "http://arxiv.org/pdf/2505.06270v1",
      "published_date": "2025-05-06 04:04:30 UTC",
      "updated_date": "2025-05-06 04:04:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:23:28.821045"
    },
    {
      "arxiv_id": "2505.03156v1",
      "title": "Soft Best-of-n Sampling for Model Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Claudio Mayrink Verdun",
        "Alex Oesterling",
        "Himabindu Lakkaraju",
        "Flavio P. Calmon"
      ],
      "abstract": "Best-of-$n$ (BoN) sampling is a practical approach for aligning language\nmodel outputs with human preferences without expensive fine-tuning. BoN\nsampling is performed by generating $n$ responses to a prompt and then\nselecting the sample that maximizes a reward function. BoN yields high reward\nvalues in practice at a distortion cost, as measured by the KL-divergence\nbetween the sampled and original distribution. This distortion is coarsely\ncontrolled by varying the number of samples: larger $n$ yields a higher reward\nat a higher distortion cost. We introduce Soft Best-of-$n$ sampling, a\ngeneralization of BoN that allows for smooth interpolation between the original\ndistribution and reward-maximizing distribution through a temperature parameter\n$\\lambda$. We establish theoretical guarantees showing that Soft Best-of-$n$\nsampling converges sharply to the optimal tilted distribution at a rate of\n$O(1/n)$ in KL and the expected (relative) reward. For sequences of discrete\noutputs, we analyze an additive reward model that reveals the fundamental\nlimitations of blockwise sampling.",
      "tldr_zh": "这篇论文提出了 Soft Best-of-n 采样方法，作为 Best-of-n (BoN) 采样的推广，用于在不进行昂贵微调的情况下使语言模型输出与人类偏好对齐。BoN 通过生成 n 个响应并选择奖励函数最大化的样本，但会增加 KL-divergence 衡量的扭曲成本，而 Soft Best-of-n 通过温度参数 λ 实现原分布与奖励最大化分布的平滑插值。理论分析显示，该方法在 KL 散度和预期奖励上以 O(1/n) 的收敛率逼近最优倾斜分布。对于离散序列输出，论文还分析了加法奖励模型，揭示了块式采样的基本限制。总的来说，此方法为模型对齐提供了更灵活且高效的框架。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "math.IT"
      ],
      "primary_category": "cs.IT",
      "comment": "Accepted for presentation at the 2025 IEEE International Symposium on\n  Information Theory (ISIT 2025)",
      "pdf_url": "http://arxiv.org/pdf/2505.03156v1",
      "published_date": "2025-05-06 04:03:11 UTC",
      "updated_date": "2025-05-06 04:03:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:23:42.179239"
    },
    {
      "arxiv_id": "2505.03154v1",
      "title": "StableMotion: Training Motion Cleanup Models with Unpaired Corrupted Data",
      "title_zh": "Stable",
      "authors": [
        "Yuxuan Mu",
        "Hung Yu Ling",
        "Yi Shi",
        "Ismael Baira Ojeda",
        "Pengcheng Xi",
        "Chang Shu",
        "Fabio Zinno",
        "Xue Bin Peng"
      ],
      "abstract": "Motion capture (mocap) data often exhibits visually jarring artifacts due to\ninaccurate sensors and post-processing. Cleaning this corrupted data can\nrequire substantial manual effort from human experts, which can be a costly and\ntime-consuming process. Previous data-driven motion cleanup methods offer the\npromise of automating this cleanup process, but often require in-domain paired\ncorrupted-to-clean training data. Constructing such paired datasets requires\naccess to high-quality, relatively artifact-free motion clips, which often\nnecessitates laborious manual cleanup. In this work, we present StableMotion, a\nsimple yet effective method for training motion cleanup models directly from\nunpaired corrupted datasets that need cleanup. The core component of our method\nis the introduction of motion quality indicators, which can be easily annotated\nthrough manual labeling or heuristic algorithms and enable training of\nquality-aware motion generation models on raw motion data with mixed quality.\nAt test time, the model can be prompted to generate high-quality motions using\nthe quality indicators. Our method can be implemented through a simple\ndiffusion-based framework, leading to a unified motion generate-discriminate\nmodel, which can be used to both identify and fix corrupted frames. We\ndemonstrate that our proposed method is effective for training motion cleanup\nmodels on raw mocap data in production scenarios by applying StableMotion to\nSoccerMocap, a 245-hour soccer mocap dataset containing real-world motion\nartifacts. The trained model effectively corrects a wide range of motion\nartifacts, reducing motion pops and frozen frames by 68% and 81%, respectively.\nSee https://youtu.be/3Y7MMAH02B4 for more results.",
      "tldr_zh": "该论文提出StableMotion方法，用于训练运动清理模型，仅需使用unpaired corrupted数据，而非传统paired数据集，从而避免了手动清理的高成本。核心创新在于引入motion quality indicators，通过手动标注或启发式算法训练quality-aware motion generation模型，该模型基于diffusion-based framework，能够统一生成和鉴别运动数据。实验结果显示，在SoccerMocap数据集（245小时真实mocap数据）上，StableMotion有效减少了motion artifacts，包括motion pops减少68%和frozen frames减少81%。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "17 pages, 13 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.03154v1",
      "published_date": "2025-05-06 04:02:47 UTC",
      "updated_date": "2025-05-06 04:02:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:23:53.349919"
    },
    {
      "arxiv_id": "2505.03149v2",
      "title": "Motion-compensated cardiac MRI using low-rank diffeomorphic flow (DMoCo)",
      "title_zh": "翻译失败",
      "authors": [
        "Joseph Kettelkamp",
        "Ludovica Romanin",
        "Sarv Priya",
        "Mathews Jacob"
      ],
      "abstract": "We introduce an unsupervised motion-compensated image reconstruction\nalgorithm for free-breathing and ungated 3D cardiac magnetic resonance imaging\n(MRI). We express the image volume corresponding to each specific motion phase\nas the deformation of a single static image template. The main contribution of\nthe work is the low-rank model for the compact joint representation of the\nfamily of diffeomorphisms, parameterized by the motion phases. The\ndiffeomorphism at a specific motion phase is obtained by integrating a\nparametric velocity field along a path connecting the reference template phase\nto the motion phase. The velocity field at different phases is represented\nusing a low-rank model. The static template and the low-rank motion model\nparameters are learned directly from the k-space data in an unsupervised\nfashion. The more constrained motion model is observed to offer improved\nrecovery compared to current motion-resolved and motion-compensated algorithms\nfor free-breathing 3D cine MRI.",
      "tldr_zh": "我们提出了一种无监督的运动补偿图像重建算法DMoCo，用于自由呼吸和无门控的3D心脏MRI，将每个运动阶段的图像体积表示为一个静态模板的变形。核心贡献是使用low-rank模型来紧凑地联合表示微分同胚(diffeomorphisms)的家族，通过整合参数化的速度场从参考阶段到目标阶段实现。静态模板和low-rank运动模型参数直接从k-space数据中无监督学习，与现有运动解析和运动补偿算法相比，该方法在自由呼吸3D cine MRI中实现了更好的图像恢复。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03149v2",
      "published_date": "2025-05-06 03:52:17 UTC",
      "updated_date": "2025-05-07 21:20:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:24:06.174194"
    },
    {
      "arxiv_id": "2505.03853v1",
      "title": "GRAPE: Heterogeneous Graph Representation Learning for Genetic Perturbation with Coding and Non-Coding Biotype",
      "title_zh": "翻译失败",
      "authors": [
        "Changxi Chi",
        "Jun Xia",
        "Jingbo Zhou",
        "Jiabei Cheng",
        "Chang Yu",
        "Stan Z. Li"
      ],
      "abstract": "Predicting genetic perturbations enables the identification of potentially\ncrucial genes prior to wet-lab experiments, significantly improving overall\nexperimental efficiency. Since genes are the foundation of cellular life,\nbuilding gene regulatory networks (GRN) is essential to understand and predict\nthe effects of genetic perturbations. However, current methods fail to fully\nleverage gene-related information, and solely rely on simple evaluation metrics\nto construct coarse-grained GRN. More importantly, they ignore functional\ndifferences between biotypes, limiting the ability to capture potential gene\ninteractions. In this work, we leverage pre-trained large language model and\nDNA sequence model to extract features from gene descriptions and DNA sequence\ndata, respectively, which serve as the initialization for gene representations.\nAdditionally, we introduce gene biotype information for the first time in\ngenetic perturbation, simulating the distinct roles of genes with different\nbiotypes in regulating cellular processes, while capturing implicit gene\nrelationships through graph structure learning (GSL). We propose GRAPE, a\nheterogeneous graph neural network (HGNN) that leverages gene representations\ninitialized with features from descriptions and sequences, models the distinct\nroles of genes with different biotypes, and dynamically refines the GRN through\nGSL. The results on publicly available datasets show that our method achieves\nstate-of-the-art performance.",
      "tldr_zh": "该研究针对遗传扰动（Genetic Perturbation）预测问题，提出了一种名为 GRAPE 的异构图表示学习框架，以解决现有基因调控网络（GRN）构建方法未充分利用基因信息和忽略不同生物类型（Coding and Non-Coding Biotype）功能差异的局限性。GRAPE 通过预训练的大型语言模型和 DNA 序列模型，从基因描述和序列数据中提取初始特征，并首次引入生物类型信息来模拟基因的独特作用，同时利用图结构学习（GSL）捕获隐含关系。实验结果显示，该框架在公开数据集上实现了最先进性能，提高了关键基因识别的准确性和效率。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG",
        "q-bio.GN"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03853v1",
      "published_date": "2025-05-06 03:35:24 UTC",
      "updated_date": "2025-05-06 03:35:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:24:17.955249"
    },
    {
      "arxiv_id": "2505.03135v1",
      "title": "Holmes: Automated Fact Check with Large Language Models",
      "title_zh": "Holmes：基于大型语言模型的自动化事实检查",
      "authors": [
        "Haoran Ou",
        "Gelei Deng",
        "Xingshuo Han",
        "Jie Zhang",
        "Xinlei He",
        "Han Qiu",
        "Shangwei Guo",
        "Tianwei Zhang"
      ],
      "abstract": "The rise of Internet connectivity has accelerated the spread of\ndisinformation, threatening societal trust, decision-making, and national\nsecurity. Disinformation has evolved from simple text to complex multimodal\nforms combining images and text, challenging existing detection methods.\nTraditional deep learning models struggle to capture the complexity of\nmultimodal disinformation. Inspired by advances in AI, this study explores\nusing Large Language Models (LLMs) for automated disinformation detection. The\nempirical study shows that (1) LLMs alone cannot reliably assess the\ntruthfulness of claims; (2) providing relevant evidence significantly improves\ntheir performance; (3) however, LLMs cannot autonomously search for accurate\nevidence. To address this, we propose Holmes, an end-to-end framework featuring\na novel evidence retrieval method that assists LLMs in collecting high-quality\nevidence. Our approach uses (1) LLM-powered summarization to extract key\ninformation from open sources and (2) a new algorithm and metrics to evaluate\nevidence quality. Holmes enables LLMs to verify claims and generate\njustifications effectively. Experiments show Holmes achieves 88.3% accuracy on\ntwo open-source datasets and 90.2% in real-time verification tasks. Notably,\nour improved evidence retrieval boosts fact-checking accuracy by 30.8% over\nexisting methods",
      "tldr_zh": "本研究针对多模态虚假信息（结合图像和文本）的传播问题，探索使用 Large Language Models (LLMs) 进行自动事实检查，但发现 LLMs 单独无法可靠评估声明真实性，需要高质量证据支持。论文提出 Holmes 框架，这是一个端到端系统，包括 LLM 驱动的证据总结从开放来源提取关键信息，以及新算法和指标来评估证据质量，从而帮助 LLMs 验证声明并生成理由。实验结果显示，Holmes 在两个开源数据集上达到88.3%的准确率，在实时验证任务中达90.2%，其改进证据检索方法比现有方法提升30.8%的准确率。总的来说，该框架为高效、可信的事实检查提供了新途径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03135v1",
      "published_date": "2025-05-06 03:19:51 UTC",
      "updated_date": "2025-05-06 03:19:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:24:31.939714"
    },
    {
      "arxiv_id": "2505.03132v1",
      "title": "VISLIX: An XAI Framework for Validating Vision Models with Slice Discovery and Analysis",
      "title_zh": "VISLIX：一个 X",
      "authors": [
        "Xinyuan Yan",
        "Xiwei Xuan",
        "Jorge Piazentin Ono",
        "Jiajing Guo",
        "Vikram Mohanty",
        "Shekar Arvind Kumar",
        "Liang Gou",
        "Bei Wang",
        "Liu Ren"
      ],
      "abstract": "Real-world machine learning models require rigorous evaluation before\ndeployment, especially in safety-critical domains like autonomous driving and\nsurveillance. The evaluation of machine learning models often focuses on data\nslices, which are subsets of the data that share a set of characteristics. Data\nslice finding automatically identifies conditions or data subgroups where\nmodels underperform, aiding developers in mitigating performance issues.\nDespite its popularity and effectiveness, data slicing for vision model\nvalidation faces several challenges. First, data slicing often needs additional\nimage metadata or visual concepts, and falls short in certain computer vision\ntasks, such as object detection. Second, understanding data slices is a\nlabor-intensive and mentally demanding process that heavily relies on the\nexpert's domain knowledge. Third, data slicing lacks a human-in-the-loop\nsolution that allows experts to form hypothesis and test them interactively. To\novercome these limitations and better support the machine learning operations\nlifecycle, we introduce VISLIX, a novel visual analytics framework that employs\nstate-of-the-art foundation models to help domain experts analyze slices in\ncomputer vision models. Our approach does not require image metadata or visual\nconcepts, automatically generates natural language insights, and allows users\nto test data slice hypothesis interactively. We evaluate VISLIX with an expert\nstudy and three use cases, that demonstrate the effectiveness of our tool in\nproviding comprehensive insights for validating object detection models.",
      "tldr_zh": "这篇论文介绍了 VISLIX，一种 XAI 框架，旨在通过数据切片（data slices）发现和分析来验证视觉模型，尤其适用于安全关键领域如自动驾驶和监控。VISLIX 利用 state-of-the-art foundation models 自动生成自然语言洞见，支持用户交互式测试假设，且无需额外图像元数据或视觉概念，从而解决传统数据切片方法的局限性。实验通过专家研究和三个用例证明了该框架在对象检测模型验证中的有效性，提供全面洞见以提升模型性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03132v1",
      "published_date": "2025-05-06 03:09:15 UTC",
      "updated_date": "2025-05-06 03:09:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:24:41.206561"
    },
    {
      "arxiv_id": "2505.06268v1",
      "title": "Cluster-Aware Multi-Round Update for Wireless Federated Learning in Heterogeneous Environments",
      "title_zh": "异构环境下的无线联邦学习集群感知多轮更新",
      "authors": [
        "Pengcheng Sun",
        "Erwu Liu",
        "Wei Ni",
        "Kanglei Yu",
        "Rui Wang",
        "Abbas Jamalipour"
      ],
      "abstract": "The aggregation efficiency and accuracy of wireless Federated Learning (FL)\nare significantly affected by resource constraints, especially in heterogeneous\nenvironments where devices exhibit distinct data distributions and\ncommunication capabilities. This paper proposes a clustering strategy that\nleverages prior knowledge similarity to group devices with similar data and\ncommunication characteristics, mitigating performance degradation from\nheterogeneity. On this basis, a novel Cluster- Aware Multi-round Update (CAMU)\nstrategy is proposed, which treats clusters as the basic units and adjusts the\nlocal update frequency based on the clustered contribution threshold,\neffectively reducing update bias and enhancing aggregation accuracy. The\ntheoretical convergence of the CAMU strategy is rigorously validated.\nMeanwhile, based on the convergence upper bound, the local update frequency and\ntransmission power of each cluster are jointly optimized to achieve an optimal\nbalance between computation and communication resources under constrained\nconditions, significantly improving the convergence efficiency of FL.\nExperimental results demonstrate that the proposed method effectively improves\nthe model performance of FL in heterogeneous environments and achieves a better\nbalance between communication cost and computational load under limited\nresources.",
      "tldr_zh": "本文针对无线联邦学习(FL)在异构环境中的资源约束问题，提出了一种聚类策略，利用设备数据和通信特性的相似性进行分组，以缓解性能下降。基于此，引入Cluster-Aware Multi-Round Update (CAMU)策略，将集群作为基本单位，根据贡献阈值调整本地更新频率，减少更新偏差并提升聚合准确性。研究还理论验证了CAMU的收敛性，并通过优化每个集群的本地更新频率和传输功率，在资源限制下实现了计算与通信资源的平衡。实验结果表明，该方法显著提高了FL在异构环境下的模型性能，同时优化了通信成本和计算负载。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.06268v1",
      "published_date": "2025-05-06 02:48:48 UTC",
      "updated_date": "2025-05-06 02:48:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:24:54.618822"
    },
    {
      "arxiv_id": "2505.03108v1",
      "title": "Is AI currently capable of identifying wild oysters? A comparison of human annotators against the AI model, ODYSSEE",
      "title_zh": "翻译失败",
      "authors": [
        "Brendan Campbell",
        "Alan Williams",
        "Kleio Baxevani",
        "Alyssa Campbell",
        "Rushabh Dhoke",
        "Rileigh E. Hudock",
        "Xiaomin Lin",
        "Vivek Mange",
        "Bernhard Neuberger",
        "Arjun Suresh",
        "Alhim Vera",
        "Arthur Trembanis",
        "Herbert G. Tanner",
        "Edward Hale"
      ],
      "abstract": "Oysters are ecologically and commercially important species that require\nfrequent monitoring to track population demographics (e.g. abundance, growth,\nmortality). Current methods of monitoring oyster reefs often require\ndestructive sampling methods and extensive manual effort. Therefore, they are\nsuboptimal for small-scale or sensitive environments. A recent alternative, the\nODYSSEE model, was developed to use deep learning techniques to identify live\noysters using video or images taken in the field of oyster reefs to assess\nabundance. The validity of this model in identifying live oysters on a reef was\ncompared to expert and non-expert annotators. In addition, we identified\npotential sources of prediction error. Although the model can make inferences\nsignificantly faster than expert and non-expert annotators (39.6 s, $2.34 \\pm\n0.61$ h, $4.50 \\pm 1.46$ h, respectively), the model overpredicted the number\nof live oysters, achieving lower accuracy (63\\%) in identifying live oysters\ncompared to experts (74\\%) and non-experts (75\\%) alike. Image quality was an\nimportant factor in determining the accuracy of the model and the annotators.\nBetter quality images improved human accuracy and worsened model accuracy.\nAlthough ODYSSEE was not sufficiently accurate, we anticipate that future\ntraining on higher-quality images, utilizing additional live imagery, and\nincorporating additional annotation training classes will greatly improve the\nmodel's predictive power based on the results of this analysis. Future research\nshould address methods that improve the detection of living vs. dead oysters.",
      "tldr_zh": "这篇论文评估了AI模型ODYSSEE在识别野外牡蛎方面的能力，通过比较其与专家和非专家注释者的表现。研究发现，虽然ODYSSEE在处理视频或图像时速度更快（仅需39.6秒），但其准确率仅为63%，低于专家（74%）和非专家（75%），且模型倾向于过预测活牡蛎数量。图像质量是关键影响因素，高质量图像提高了人类准确率但降低了模型表现；作者建议通过使用更多高质量图像和额外训练类别来改进ODYSSEE的预测能力，以更好地支持牡蛎种群监测。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03108v1",
      "published_date": "2025-05-06 02:01:27 UTC",
      "updated_date": "2025-05-06 02:01:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:25:06.159009"
    },
    {
      "arxiv_id": "2505.03105v1",
      "title": "Cognitio Emergens: Agency, Dimensions, and Dynamics in Human-AI Knowledge Co-Creation",
      "title_zh": "翻译失败",
      "authors": [
        "Xule Lin"
      ],
      "abstract": "Scientific knowledge creation is fundamentally transforming as humans and AI\nsystems evolve beyond tool-user relationships into co-evolutionary epistemic\npartnerships. When AlphaFold revolutionized protein structure prediction,\nresearchers described engaging with an epistemic partner that reshaped how they\nconceptualized fundamental relationships. This article introduces Cognitio\nEmergens (CE), a framework addressing critical limitations in existing models\nthat focus on static roles or narrow metrics while failing to capture how\nscientific understanding emerges through recursive human-AI interaction over\ntime. CE integrates three components addressing these limitations: Agency\nConfigurations describing how authority distributes between humans and AI\n(Directed, Contributory, Partnership), with partnerships dynamically\noscillating between configurations rather than following linear progression;\nEpistemic Dimensions capturing six specific capabilities emerging through\ncollaboration across Discovery, Integration, and Projection axes, creating\ndistinctive \"capability signatures\" that guide development; and Partnership\nDynamics identifying forces shaping how these relationships evolve,\nparticularly the risk of epistemic alienation where researchers lose\ninterpretive control over knowledge they formally endorse. Drawing from\nautopoiesis theory, social systems theory, and organizational modularity, CE\nreveals how knowledge co-creation emerges through continuous negotiation of\nroles, values, and organizational structures. By reconceptualizing human-AI\nscientific collaboration as fundamentally co-evolutionary, CE offers a balanced\nperspective that neither uncritically celebrates nor unnecessarily fears AI's\nevolving role, instead providing conceptual tools for cultivating partnerships\nthat maintain meaningful human participation while enabling transformative\nscientific breakthroughs.",
      "tldr_zh": "该论文引入 Cognitio Emergens (CE) 框架，以解决现有模型在人类-AI 知识共同创造中的局限性，如静态角色和狭隘指标。CE 整合三个核心组件：Agency Configurations（描述人类和 AI 之间权力的动态分配，包括 Directed、Contributory 和 Partnership 类型）、Epistemic Dimensions（捕捉通过 Discovery、Integration 和 Projection 轴的六种合作能力，形成独特的能力签名），以及 Partnership Dynamics（识别关系演变的力量，特别是 epistemic alienation 的风险）。基于 autopoiesis theory、社会系统理论和组织模块化，CE 重新定义人类-AI 合作为共同演化过程，提供平衡视角，促进有意义的伙伴关系和科学创新。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY",
        "H.5.3; I.2.11; K.4.3; H.1.2; I.2.4"
      ],
      "primary_category": "cs.HC",
      "comment": "62 pages (31 appendix pages for guidance), 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.03105v1",
      "published_date": "2025-05-06 01:49:44 UTC",
      "updated_date": "2025-05-06 01:49:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:25:18.677282"
    },
    {
      "arxiv_id": "2505.03096v1",
      "title": "Assessing and Enhancing the Robustness of LLM-based Multi-Agent Systems Through Chaos Engineering",
      "title_zh": "通过混沌工程评估和增强基于 LLM 的",
      "authors": [
        "Joshua Owotogbe"
      ],
      "abstract": "This study explores the application of chaos engineering to enhance the\nrobustness of Large Language Model-Based Multi-Agent Systems (LLM-MAS) in\nproduction-like environments under real-world conditions. LLM-MAS can\npotentially improve a wide range of tasks, from answering questions and\ngenerating content to automating customer support and improving decision-making\nprocesses. However, LLM-MAS in production or preproduction environments can be\nvulnerable to emergent errors or disruptions, such as hallucinations, agent\nfailures, and agent communication failures. This study proposes a chaos\nengineering framework to proactively identify such vulnerabilities in LLM-MAS,\nassess and build resilience against them, and ensure reliable performance in\ncritical applications.",
      "tldr_zh": "这篇论文探讨了使用混沌工程（chaos engineering）来评估和提升基于大型语言模型的多智能体系统（LLM-MAS）的鲁棒性，以应对真实世界生产环境中的潜在问题，如幻觉（hallucinations）、代理失败和通信失败。研究提出一个混沌工程框架，用于主动识别LLM-MAS的漏洞，并通过模拟干扰来增强其抗逆性。最终，该框架旨在确保LLM-MAS在关键应用中实现可靠性能，从而支持任务如回答问题、内容生成和决策自动化。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03096v1",
      "published_date": "2025-05-06 01:13:14 UTC",
      "updated_date": "2025-05-06 01:13:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:25:30.726056"
    },
    {
      "arxiv_id": "2505.03084v1",
      "title": "Adversarial Attacks in Multimodal Systems: A Practitioner's Survey",
      "title_zh": "多模态系统中的对抗攻击：实践者综述",
      "authors": [
        "Shashank Kapoor",
        "Sanjay Surendranath Girija",
        "Lakshit Arora",
        "Dipen Pradhan",
        "Ankit Shetgaonkar",
        "Aman Raj"
      ],
      "abstract": "The introduction of multimodal models is a huge step forward in Artificial\nIntelligence. A single model is trained to understand multiple modalities:\ntext, image, video, and audio. Open-source multimodal models have made these\nbreakthroughs more accessible. However, considering the vast landscape of\nadversarial attacks across these modalities, these models also inherit\nvulnerabilities of all the modalities, and ultimately, the adversarial threat\namplifies. While broad research is available on possible attacks within or\nacross these modalities, a practitioner-focused view that outlines attack types\nremains absent in the multimodal world. As more Machine Learning Practitioners\nadopt, fine-tune, and deploy open-source models in real-world applications,\nit's crucial that they can view the threat landscape and take the preventive\nactions necessary. This paper addresses the gap by surveying adversarial\nattacks targeting all four modalities: text, image, video, and audio. This\nsurvey provides a view of the adversarial attack landscape and presents how\nmultimodal adversarial threats have evolved. To the best of our knowledge, this\nsurvey is the first comprehensive summarization of the threat landscape in the\nmultimodal world.",
      "tldr_zh": "这篇论文针对多模态系统中的对抗攻击(Adversarial Attacks)进行了一个从业者导向的调查，强调多模态模型（处理文本、图像、视频和音频等模态）继承了各模态的漏洞，导致威胁放大。论文系统总结了针对这四种模态的攻击类型，并分析了这些威胁如何演变，成为首个全面概述多模态威胁景观的综述。研究填补了现有文献的空白，帮助机器学习从业者在实际应用中识别风险并采取预防措施。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted in IEEE COMPSAC 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.03084v1",
      "published_date": "2025-05-06 00:41:16 UTC",
      "updated_date": "2025-05-06 00:41:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:25:42.856973"
    },
    {
      "arxiv_id": "2505.03077v1",
      "title": "Latent Adaptive Planner for Dynamic Manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Donghun Noh",
        "Deqian Kong",
        "Minglu Zhao",
        "Andrew Lizarraga",
        "Jianwen Xie",
        "Ying Nian Wu",
        "Dennis Hong"
      ],
      "abstract": "This paper presents Latent Adaptive Planner (LAP), a novel approach for\ndynamic nonprehensile manipulation tasks that formulates planning as latent\nspace inference, effectively learned from human demonstration videos. Our\nmethod addresses key challenges in visuomotor policy learning through a\nprincipled variational replanning framework that maintains temporal consistency\nwhile efficiently adapting to environmental changes. LAP employs Bayesian\nupdating in latent space to incrementally refine plans as new observations\nbecome available, striking an optimal balance between computational efficiency\nand real-time adaptability. We bridge the embodiment gap between humans and\nrobots through model-based proportional mapping that regenerates accurate\nkinematic-dynamic joint states and object positions from human demonstrations.\nExperimental evaluations across multiple complex manipulation benchmarks\ndemonstrate that LAP achieves state-of-the-art performance, outperforming\nexisting approaches in success rate, trajectory smoothness, and energy\nefficiency, particularly in dynamic adaptation scenarios. Our approach enables\nrobots to perform complex interactions with human-like adaptability while\nproviding an expandable framework applicable to diverse robotic platforms using\nthe same human demonstration videos.",
      "tldr_zh": "本研究提出Latent Adaptive Planner (LAP)，一种新型方法，用于动态非抓取操作任务，通过将规划表述为潜在空间推理，从人类演示视频中有效学习。LAP 采用基于变分再规划的框架和Bayesian updating，在潜在空间中逐步完善计划，确保时间一致性、计算效率和对环境变化的实时适应，同时通过模型-based 比例映射桥接人类与机器人的实施差距。实验结果显示，LAP 在多个复杂操作基准上实现了最先进性能，在成功率、轨迹平滑性和能量效率方面优于现有方法，尤其在动态适应场景中，并提供了一个可扩展框架，适用于不同机器人平台使用相同的演示视频。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03077v1",
      "published_date": "2025-05-06 00:09:09 UTC",
      "updated_date": "2025-05-06 00:09:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T20:25:54.962516"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 122,
  "processed_papers_count": 122,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-24T20:26:15.299837"
}