[
  {
    "arxiv_id": "2404.08690v1",
    "title": "Towards Building a Robust Toxicity Predictor",
    "authors": [
      "Dmitriy Bespalov",
      "Sourav Bhabesh",
      "Yi Xiang",
      "Liutong Zhou",
      "Yanjun Qi"
    ],
    "abstract": "Recent NLP literature pays little attention to the robustness of toxicity\nlanguage predictors, while these systems are most likely to be used in\nadversarial contexts. This paper presents a novel adversarial attack,\n\\texttt{ToxicTrap}, introducing small word-level perturbations to fool SOTA\ntext classifiers to predict toxic text samples as benign. ToxicTrap exploits\ngreedy based search strategies to enable fast and effective generation of toxic\nadversarial examples. Two novel goal function designs allow ToxicTrap to\nidentify weaknesses in both multiclass and multilabel toxic language detectors.\nOur empirical results show that SOTA toxicity text classifiers are indeed\nvulnerable to the proposed attacks, attaining over 98\\% attack success rates in\nmultilabel cases. We also show how a vanilla adversarial training and its\nimproved version can help increase robustness of a toxicity detector even\nagainst unseen attacks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL 2023 /",
    "pdf_url": "http://arxiv.org/pdf/2404.08690v1",
    "published_date": "2024-04-09 22:56:05 UTC",
    "updated_date": "2024-04-09 22:56:05 UTC"
  },
  {
    "arxiv_id": "2404.06647v2",
    "title": "From Protoscience to Epistemic Monoculture: How Benchmarking Set the Stage for the Deep Learning Revolution",
    "authors": [
      "Bernard J. Koch",
      "David Peterson"
    ],
    "abstract": "Over the past decade, AI research has focused heavily on building ever-larger\ndeep learning models. This approach has simultaneously unlocked incredible\nachievements in science and technology, and hindered AI from overcoming\nlong-standing limitations with respect to explainability, ethical harms, and\nenvironmental efficiency. Drawing on qualitative interviews and computational\nanalyses, our three-part history of AI research traces the creation of this\n\"epistemic monoculture\" back to a radical reconceptualization of scientific\nprogress that began in the late 1980s. In the first era of AI research\n(1950s-late 1980s), researchers and patrons approached AI as a \"basic\" science\nthat would advance through autonomous exploration and organic assessments of\nprogress (e.g., peer-review, theoretical consensus). The failure of this\napproach led to a retrenchment of funding in the 1980s. Amid this \"AI Winter,\"\nan intervention by the U.S. government reoriented the field towards measurable\nprogress on tasks of military and commercial interest. A new evaluation system\ncalled \"benchmarking\" provided an objective way to quantify progress on tasks\nby focusing exclusively on increasing predictive accuracy on example datasets.\nDistilling science down to verifiable metrics clarified the roles of\nscientists, allowed the field to rapidly integrate talent, and provided clear\nsignals of significance and progress. But history has also revealed a tradeoff\nto this streamlined approach to science: the consolidation around external\ninterests and inherent conservatism of benchmarking has disincentivized\nexploration beyond scaling monoculture. In the discussion, we explain how AI's\nmonoculture offers a compelling challenge to the belief that basic,\nexploration-driven research is needed for scientific progress. Implications for\nthe spread of AI monoculture to other sciences in the era of generative AI are\nalso discussed.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.06647v2",
    "published_date": "2024-04-09 22:55:06 UTC",
    "updated_date": "2024-04-11 02:09:23 UTC"
  },
  {
    "arxiv_id": "2404.06645v1",
    "title": "GenCHiP: Generating Robot Policy Code for High-Precision and Contact-Rich Manipulation Tasks",
    "authors": [
      "Kaylee Burns",
      "Ajinkya Jain",
      "Keegan Go",
      "Fei Xia",
      "Michael Stark",
      "Stefan Schaal",
      "Karol Hausman"
    ],
    "abstract": "Large Language Models (LLMs) have been successful at generating robot policy\ncode, but so far these results have been limited to high-level tasks that do\nnot require precise movement. It is an open question how well such approaches\nwork for tasks that require reasoning over contact forces and working within\ntight success tolerances. We find that, with the right action space, LLMs are\ncapable of successfully generating policies for a variety of contact-rich and\nhigh-precision manipulation tasks, even under noisy conditions, such as\nperceptual errors or grasping inaccuracies. Specifically, we reparameterize the\naction space to include compliance with constraints on the interaction forces\nand stiffnesses involved in reaching a target pose. We validate this approach\non subtasks derived from the Functional Manipulation Benchmark (FMB) and NIST\nTask Board Benchmarks. Exposing this action space alongside methods for\nestimating object poses improves policy generation with an LLM by greater than\n3x and 4x when compared to non-compliant action spaces",
    "categories": [
      "cs.RO",
      "cs.AI",
      "I.2.9"
    ],
    "primary_category": "cs.RO",
    "comment": "14 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.06645v1",
    "published_date": "2024-04-09 22:47:25 UTC",
    "updated_date": "2024-04-09 22:47:25 UTC"
  },
  {
    "arxiv_id": "2404.06644v1",
    "title": "Khayyam Challenge (PersianMMLU): Is Your LLM Truly Wise to The Persian Language?",
    "authors": [
      "Omid Ghahroodi",
      "Marzia Nouri",
      "Mohammad Vali Sanian",
      "Alireza Sahebi",
      "Doratossadat Dastgheib",
      "Ehsaneddin Asgari",
      "Mahdieh Soleymani Baghshah",
      "Mohammad Hossein Rohban"
    ],
    "abstract": "Evaluating Large Language Models (LLMs) is challenging due to their\ngenerative nature, necessitating precise evaluation methodologies.\nAdditionally, non-English LLM evaluation lags behind English, resulting in the\nabsence or weakness of LLMs for many languages. In response to this necessity,\nwe introduce Khayyam Challenge (also known as PersianMMLU), a meticulously\ncurated collection comprising 20,192 four-choice questions sourced from 38\ndiverse tasks extracted from Persian examinations, spanning a wide spectrum of\nsubjects, complexities, and ages. The primary objective of the Khayyam\nChallenge is to facilitate the rigorous evaluation of LLMs that support the\nPersian language. Distinctive features of the Khayyam Challenge are (i) its\ncomprehensive coverage of various topics, including literary comprehension,\nmathematics, sciences, logic, intelligence testing, etc., aimed at assessing\ndifferent facets of LLMs such as language comprehension, reasoning, and\ninformation retrieval across various educational stages, from lower primary\nschool to upper secondary school (ii) its inclusion of rich metadata such as\nhuman response rates, difficulty levels, and descriptive answers (iii) its\nutilization of new data to avoid data contamination issues prevalent in\nexisting frameworks (iv) its use of original, non-translated data tailored for\nPersian speakers, ensuring the framework is free from translation challenges\nand errors while encompassing cultural nuances (v) its inherent scalability for\nfuture data updates and evaluations without requiring special human effort.\nPrevious works lacked an evaluation framework that combined all of these\nfeatures into a single comprehensive benchmark. Furthermore, we evaluate a wide\nrange of existing LLMs that support the Persian language, with statistical\nanalyses and interpretations of their outputs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.06644v1",
    "published_date": "2024-04-09 22:38:13 UTC",
    "updated_date": "2024-04-09 22:38:13 UTC"
  },
  {
    "arxiv_id": "2404.06641v1",
    "title": "Federated learning model for predicting major postoperative complications",
    "authors": [
      "Yonggi Park",
      "Yuanfang Ren",
      "Benjamin Shickel",
      "Ziyuan Guan",
      "Ayush Patela",
      "Yingbo Ma",
      "Zhenhong Hu",
      "Tyler J. Loftus",
      "Parisa Rashidi",
      "Tezcan Ozrazgat-Baslanti",
      "Azra Bihorac"
    ],
    "abstract": "Background: The accurate prediction of postoperative complication risk using\nElectronic Health Records (EHR) and artificial intelligence shows great\npotential. Training a robust artificial intelligence model typically requires\nlarge-scale and diverse datasets. In reality, collecting medical data often\nencounters challenges surrounding privacy protection. Methods: This\nretrospective cohort study includes adult patients who were admitted to UFH\nGainesville (GNV) (n = 79,850) and Jacksonville (JAX) (n = 28,636) for any type\nof inpatient surgical procedure. Using perioperative and intraoperative\nfeatures, we developed federated learning models to predict nine major\npostoperative complications (i.e., prolonged intensive care unit stay and\nmechanical ventilation). We compared federated learning models with local\nlearning models trained on a single site and central learning models trained on\npooled dataset from two centers. Results: Our federated learning models\nachieved the area under the receiver operating characteristics curve (AUROC)\nvalues ranged from 0.81 for wound complications to 0.92 for prolonged ICU stay\nat UFH GNV center. At UFH JAX center, these values ranged from 0.73-0.74 for\nwound complications to 0.92-0.93 for hospital mortality. Federated learning\nmodels achieved comparable AUROC performance to central learning models, except\nfor prolonged ICU stay, where the performance of federated learning models was\nslightly higher than central learning models at UFH GNV center, but slightly\nlower at UFH JAX center. In addition, our federated learning model obtained\ncomparable performance to the best local learning model at each center,\ndemonstrating strong generalizability. Conclusion: Federated learning is shown\nto be a useful tool to train robust and generalizable models from large scale\ndata across multiple institutions where data protection barriers are high.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "57 pages. 2 figures, 3 tables, 2 supplemental figures, 8 supplemental\n  tables",
    "pdf_url": "http://arxiv.org/pdf/2404.06641v1",
    "published_date": "2024-04-09 22:31:10 UTC",
    "updated_date": "2024-04-09 22:31:10 UTC"
  },
  {
    "arxiv_id": "2404.06633v1",
    "title": "Evolving Loss Functions for Specific Image Augmentation Techniques",
    "authors": [
      "Brandon Morgan",
      "Dean Hougen"
    ],
    "abstract": "Previous work in Neural Loss Function Search (NLFS) has shown a lack of\ncorrelation between smaller surrogate functions and large convolutional neural\nnetworks with massive regularization. We expand upon this research by revealing\nanother disparity that exists, correlation between different types of image\naugmentation techniques. We show that different loss functions can perform well\non certain image augmentation techniques, while performing poorly on others. We\nexploit this disparity by performing an evolutionary search on five types of\nimage augmentation techniques in the hopes of finding image augmentation\nspecific loss functions. The best loss functions from each evolution were then\ntaken and transferred to WideResNet-28-10 on CIFAR-10 and CIFAR-100 across each\nof the five image augmentation techniques. The best from that were then taken\nand evaluated by fine-tuning EfficientNetV2Small on the CARS, Oxford-Flowers,\nand Caltech datasets across each of the five image augmentation techniques.\nMultiple loss functions were found that outperformed cross-entropy across\nmultiple experiments. In the end, we found a single loss function, which we\ncalled the inverse bessel logarithm loss, that was able to outperform\ncross-entropy across the majority of experiments.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.06633v1",
    "published_date": "2024-04-09 21:53:53 UTC",
    "updated_date": "2024-04-09 21:53:53 UTC"
  },
  {
    "arxiv_id": "2404.06631v1",
    "title": "Counting Objects in a Robotic Hand",
    "authors": [
      "Francis Tsow",
      "Tianze Chen",
      "Yu Sun"
    ],
    "abstract": "A robot performing multi-object grasping needs to sense the number of objects\nin the hand after grasping. The count plays an important role in determining\nthe robot's next move and the outcome and efficiency of the whole pick-place\nprocess. This paper presents a data-driven contrastive learning-based counting\nclassifier with a modified loss function as a simple and effective approach for\nobject counting despite significant occlusion challenges caused by robotic\nfingers and objects. The model was validated against other models with three\ndifferent common shapes (spheres, cylinders, and cubes) in simulation and in a\nreal setup. The proposed contrastive learning-based counting approach achieved\nabove 96\\% accuracy for all three objects in the real setup.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.06631v1",
    "published_date": "2024-04-09 21:46:14 UTC",
    "updated_date": "2024-04-09 21:46:14 UTC"
  },
  {
    "arxiv_id": "2404.06609v1",
    "title": "GOAT-Bench: A Benchmark for Multi-Modal Lifelong Navigation",
    "authors": [
      "Mukul Khanna",
      "Ram Ramrakhya",
      "Gunjan Chhablani",
      "Sriram Yenamandra",
      "Theophile Gervet",
      "Matthew Chang",
      "Zsolt Kira",
      "Devendra Singh Chaplot",
      "Dhruv Batra",
      "Roozbeh Mottaghi"
    ],
    "abstract": "The Embodied AI community has made significant strides in visual navigation\ntasks, exploring targets from 3D coordinates, objects, language descriptions,\nand images. However, these navigation models often handle only a single input\nmodality as the target. With the progress achieved so far, it is time to move\ntowards universal navigation models capable of handling various goal types,\nenabling more effective user interaction with robots. To facilitate this goal,\nwe propose GOAT-Bench, a benchmark for the universal navigation task referred\nto as GO to AnyThing (GOAT). In this task, the agent is directed to navigate to\na sequence of targets specified by the category name, language description, or\nimage in an open-vocabulary fashion. We benchmark monolithic RL and modular\nmethods on the GOAT task, analyzing their performance across modalities, the\nrole of explicit and implicit scene memories, their robustness to noise in goal\nspecifications, and the impact of memory in lifelong scenarios.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.06609v1",
    "published_date": "2024-04-09 20:40:00 UTC",
    "updated_date": "2024-04-09 20:40:00 UTC"
  },
  {
    "arxiv_id": "2404.06599v3",
    "title": "Collaborative Multi-source Domain Adaptation Through Optimal Transport",
    "authors": [
      "Omar Ghannou",
      "Younès Bennani"
    ],
    "abstract": "Multi-source Domain Adaptation (MDA) seeks to adapt models trained on data\nfrom multiple labeled source domains to perform effectively on an unlabeled\ntarget domain data, assuming access to sources data. To address the challenges\nof model adaptation and data privacy, we introduce Collaborative MDA Through\nOptimal Transport (CMDA-OT), a novel framework consisting of two key phases. In\nthe first phase, each source domain is independently adapted to the target\ndomain using optimal transport methods. In the second phase, a centralized\ncollaborative learning architecture is employed, which aggregates the N models\nfrom the N sources without accessing their data, thereby safeguarding privacy.\nDuring this process, the server leverages a small set of pseudo-labeled samples\nfrom the target domain, known as the target validation subset, to refine and\nguide the adaptation. This dual-phase approach not only improves model\nperformance on the target domain but also addresses vital privacy challenges\ninherent in domain adaptation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.06599v3",
    "published_date": "2024-04-09 20:06:25 UTC",
    "updated_date": "2024-08-19 14:24:40 UTC"
  },
  {
    "arxiv_id": "2404.06593v1",
    "title": "Spatially Optimized Compact Deep Metric Learning Model for Similarity Search",
    "authors": [
      "Md. Farhadul Islam",
      "Md. Tanzim Reza",
      "Meem Arafat Manab",
      "Mohammad Rakibul Hasan Mahin",
      "Sarah Zabeen",
      "Jannatun Noor"
    ],
    "abstract": "Spatial optimization is often overlooked in many computer vision tasks.\nFilters should be able to recognize the features of an object regardless of\nwhere it is in the image. Similarity search is a crucial task where spatial\nfeatures decide an important output. The capacity of convolution to capture\nvisual patterns across various locations is limited. In contrast to\nconvolution, the involution kernel is dynamically created at each pixel based\non the pixel value and parameters that have been learned. This study\ndemonstrates that utilizing a single layer of involution feature extractor\nalongside a compact convolution model significantly enhances the performance of\nsimilarity search. Additionally, we improve predictions by using the GELU\nactivation function rather than the ReLU. The negligible amount of weight\nparameters in involution with a compact model with better performance makes the\nmodel very useful in real-world implementations. Our proposed model is below 1\nmegabyte in size. We have experimented with our proposed methodology and other\nmodels on CIFAR-10, FashionMNIST, and MNIST datasets. Our proposed method\noutperforms across all three datasets.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "68",
      "I.4.7; I.2.6; I.2.10"
    ],
    "primary_category": "cs.CV",
    "comment": "5 pages, 3 figures,",
    "pdf_url": "http://arxiv.org/pdf/2404.06593v1",
    "published_date": "2024-04-09 19:49:01 UTC",
    "updated_date": "2024-04-09 19:49:01 UTC"
  },
  {
    "arxiv_id": "2404.06579v1",
    "title": "Less is More for Improving Automatic Evaluation of Factual Consistency",
    "authors": [
      "Tong Wang",
      "Ninad Kulkarni",
      "Yanjun Qi"
    ],
    "abstract": "Assessing the factual consistency of automatically generated texts in\nrelation to source context is crucial for developing reliable natural language\ngeneration applications. Recent literature proposes AlignScore which uses a\nunified alignment model to evaluate factual consistency and substantially\noutperforms previous methods across many benchmark tasks. In this paper, we\ntake a closer look of datasets used in AlignScore and uncover an unexpected\nfinding: utilizing a smaller number of data points can actually improve\nperformance. We process the original AlignScore training dataset to remove\nnoise, augment with robustness-enhanced samples, and utilize a subset\ncomprising 10\\% of the data to train an improved factual consistency evaluation\nmodel, we call LIM-RA (Less Is More for Robust AlignScore). LIM-RA demonstrates\nsuperior performance, consistently outperforming AlignScore and other strong\nbaselines like ChatGPT across four benchmarks (two utilizing traditional\nnatural language generation datasets and two focused on large language model\noutputs). Our experiments show that LIM-RA achieves the highest score on 24 of\nthe 33 test datasets, while staying competitive on the rest, establishing the\nnew state-of-the-art benchmarks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted in NAACL24 Industry; 7 pages",
    "pdf_url": "http://arxiv.org/pdf/2404.06579v1",
    "published_date": "2024-04-09 19:02:12 UTC",
    "updated_date": "2024-04-09 19:02:12 UTC"
  },
  {
    "arxiv_id": "2404.06571v1",
    "title": "Building A Knowledge Graph to Enrich ChatGPT Responses in Manufacturing Service Discovery",
    "authors": [
      "Yunqing Li",
      "Binil Starly"
    ],
    "abstract": "Sourcing and identification of new manufacturing partners is crucial for\nmanufacturing system integrators to enhance agility and reduce risk through\nsupply chain diversification in the global economy. The advent of advanced\nlarge language models has captured significant interest, due to their ability\nto generate comprehensive and articulate responses across a wide range of\nknowledge domains. However, the system often falls short in accuracy and\ncompleteness when responding to domain-specific inquiries, particularly in\nareas like manufacturing service discovery. This research explores the\npotential of leveraging Knowledge Graphs in conjunction with ChatGPT to\nstreamline the process for prospective clients in identifying small\nmanufacturing enterprises. In this study, we propose a method that integrates\nbottom-up ontology with advanced machine learning models to develop a\nManufacturing Service Knowledge Graph from an array of structured and\nunstructured data sources, including the digital footprints of small-scale\nmanufacturers throughout North America. The Knowledge Graph and the learned\ngraph embedding vectors are leveraged to tackle intricate queries within the\ndigital supply chain network, responding with enhanced reliability and greater\ninterpretability. The approach highlighted is scalable to millions of entities\nthat can be distributed to form a global Manufacturing Service Knowledge\nNetwork Graph that can potentially interconnect multiple types of Knowledge\nGraphs that span industry sectors, geopolitical boundaries, and business\ndomains. The dataset developed for this study, now publicly accessible,\nencompasses more than 13,000 manufacturers' weblinks, manufacturing services,\ncertifications, and location entity types.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.06571v1",
    "published_date": "2024-04-09 18:46:46 UTC",
    "updated_date": "2024-04-09 18:46:46 UTC"
  },
  {
    "arxiv_id": "2404.07242v1",
    "title": "Sandwich attack: Multi-language Mixture Adaptive Attack on LLMs",
    "authors": [
      "Bibek Upadhayay",
      "Vahid Behzadan"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly being developed and applied,\nbut their widespread use faces challenges. These include aligning LLMs'\nresponses with human values to prevent harmful outputs, which is addressed\nthrough safety training methods. Even so, bad actors and malicious users have\nsucceeded in attempts to manipulate the LLMs to generate misaligned responses\nfor harmful questions such as methods to create a bomb in school labs, recipes\nfor harmful drugs, and ways to evade privacy rights. Another challenge is the\nmultilingual capabilities of LLMs, which enable the model to understand and\nrespond in multiple languages. Consequently, attackers exploit the unbalanced\npre-training datasets of LLMs in different languages and the comparatively\nlower model performance in low-resource languages than high-resource ones. As a\nresult, attackers use a low-resource languages to intentionally manipulate the\nmodel to create harmful responses. Many of the similar attack vectors have been\npatched by model providers, making the LLMs more robust against language-based\nmanipulation. In this paper, we introduce a new black-box attack vector called\nthe \\emph{Sandwich attack}: a multi-language mixture attack, which manipulates\nstate-of-the-art LLMs into generating harmful and misaligned responses. Our\nexperiments with five different models, namely Google's Bard, Gemini Pro,\nLLaMA-2-70-B-Chat, GPT-3.5-Turbo, GPT-4, and Claude-3-OPUS, show that this\nattack vector can be used by adversaries to generate harmful responses and\nelicit misaligned responses from these models. By detailing both the mechanism\nand impact of the Sandwich attack, this paper aims to guide future research and\ndevelopment towards more secure and resilient LLMs, ensuring they serve the\npublic good while minimizing potential for misuse.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.07242v1",
    "published_date": "2024-04-09 18:29:42 UTC",
    "updated_date": "2024-04-09 18:29:42 UTC"
  },
  {
    "arxiv_id": "2404.06561v1",
    "title": "Learning Strategies For Successful Crowd Navigation",
    "authors": [
      "Rajshree Daulatabad",
      "Serena Nath"
    ],
    "abstract": "Teaching autonomous mobile robots to successfully navigate human crowds is a\nchallenging task. Not only does it require planning, but it requires\nmaintaining social norms which may differ from one context to another. Here we\nfocus on crowd navigation, using a neural network to learn specific strategies\nin-situ with a robot. This allows us to take into account human behavior and\nreactions toward a real robot as well as learn strategies that are specific to\nvarious scenarios in that context. A CNN takes a top-down image of the scene as\ninput and outputs the next action for the robot to take in terms of speed and\nangle. Here we present the method, experimental results, and quantitatively\nevaluate our approach.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "8 pages",
    "pdf_url": "http://arxiv.org/pdf/2404.06561v1",
    "published_date": "2024-04-09 18:25:21 UTC",
    "updated_date": "2024-04-09 18:25:21 UTC"
  },
  {
    "arxiv_id": "2404.06511v2",
    "title": "MoReVQA: Exploring Modular Reasoning Models for Video Question Answering",
    "authors": [
      "Juhong Min",
      "Shyamal Buch",
      "Arsha Nagrani",
      "Minsu Cho",
      "Cordelia Schmid"
    ],
    "abstract": "This paper addresses the task of video question answering (videoQA) via a\ndecomposed multi-stage, modular reasoning framework. Previous modular methods\nhave shown promise with a single planning stage ungrounded in visual content.\nHowever, through a simple and effective baseline, we find that such systems can\nlead to brittle behavior in practice for challenging videoQA settings. Thus,\nunlike traditional single-stage planning methods, we propose a multi-stage\nsystem consisting of an event parser, a grounding stage, and a final reasoning\nstage in conjunction with an external memory. All stages are training-free, and\nperformed using few-shot prompting of large models, creating interpretable\nintermediate outputs at each stage. By decomposing the underlying planning and\ntask complexity, our method, MoReVQA, improves over prior work on standard\nvideoQA benchmarks (NExT-QA, iVQA, EgoSchema, ActivityNet-QA) with\nstate-of-the-art results, and extensions to related tasks (grounded videoQA,\nparagraph captioning).",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2024; updated NExT-GQA results in Appendix",
    "pdf_url": "http://arxiv.org/pdf/2404.06511v2",
    "published_date": "2024-04-09 17:59:31 UTC",
    "updated_date": "2025-03-27 05:18:09 UTC"
  },
  {
    "arxiv_id": "2404.06492v2",
    "title": "Graph Reinforcement Learning for Combinatorial Optimization: A Survey and Unifying Perspective",
    "authors": [
      "Victor-Alexandru Darvariu",
      "Stephen Hailes",
      "Mirco Musolesi"
    ],
    "abstract": "Graphs are a natural representation for systems based on relations between\nconnected entities. Combinatorial optimization problems, which arise when\nconsidering an objective function related to a process of interest on discrete\nstructures, are often challenging due to the rapid growth of the solution\nspace. The trial-and-error paradigm of Reinforcement Learning has recently\nemerged as a promising alternative to traditional methods, such as exact\nalgorithms and (meta)heuristics, for discovering better decision-making\nstrategies in a variety of disciplines including chemistry, computer science,\nand statistics. Despite the fact that they arose in markedly different fields,\nthese techniques share significant commonalities. Therefore, we set out to\nsynthesize this work in a unifying perspective that we term Graph Reinforcement\nLearning, interpreting it as a constructive decision-making method for graph\nproblems. After covering the relevant technical background, we review works\nalong the dividing line of whether the goal is to optimize graph structure\ngiven a process of interest, or to optimize the outcome of the process itself\nunder fixed graph structure. Finally, we discuss the common challenges facing\nthe field and open research questions. In contrast with other surveys, the\npresent work focuses on non-canonical graph problems for which performant\nalgorithms are typically not known and Reinforcement Learning is able to\nprovide efficient and effective solutions.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "To appear in Transactions on Machine Learning Research (TMLR)",
    "pdf_url": "http://arxiv.org/pdf/2404.06492v2",
    "published_date": "2024-04-09 17:45:25 UTC",
    "updated_date": "2024-08-20 11:21:32 UTC"
  },
  {
    "arxiv_id": "2404.06488v1",
    "title": "Pitfalls of Conversational LLMs on News Debiasing",
    "authors": [
      "Ipek Baris Schlicht",
      "Defne Altiok",
      "Maryanne Taouk",
      "Lucie Flek"
    ],
    "abstract": "This paper addresses debiasing in news editing and evaluates the\neffectiveness of conversational Large Language Models in this task. We designed\nan evaluation checklist tailored to news editors' perspectives, obtained\ngenerated texts from three popular conversational models using a subset of a\npublicly available dataset in media bias, and evaluated the texts according to\nthe designed checklist. Furthermore, we examined the models as evaluator for\nchecking the quality of debiased model outputs. Our findings indicate that none\nof the LLMs are perfect in debiasing. Notably, some models, including ChatGPT,\nintroduced unnecessary changes that may impact the author's style and create\nmisinformation. Lastly, we show that the models do not perform as proficiently\nas domain experts in evaluating the quality of debiased outputs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "The paper is accepted at the DELITE workshop which is co-located at\n  COLING/LREC",
    "pdf_url": "http://arxiv.org/pdf/2404.06488v1",
    "published_date": "2024-04-09 17:42:59 UTC",
    "updated_date": "2024-04-09 17:42:59 UTC"
  },
  {
    "arxiv_id": "2404.06484v5",
    "title": "Public-private funding models in open source software development: A case study on scikit-learn",
    "authors": [
      "Cailean Osborne"
    ],
    "abstract": "Governments are increasingly funding open source software (OSS) development\nto support software security, digital sovereignty, and national competitiveness\nin science and innovation, amongst others. However, little is known about how\nOSS developers evaluate the relative benefits and drawbacks of governmental\nfunding for OSS. This study explores this question through a case study on\nscikit-learn, a Python library for machine learning, funded by public research\ngrants, commercial sponsorship, micro-donations, and a 32 euro million grant\nannounced in France's artificial intelligence strategy. Through 25 interviews\nwith scikit-learn's maintainers and funders, this study makes two key\ncontributions. First, it contributes empirical findings about the benefits and\ndrawbacks of public and private funding in an impactful OSS project, and the\ngovernance protocols employed by the maintainers to balance the diverse\ninterests of their community and funders. Second, it offers practical lessons\non funding for OSS developers, governments, and companies based on the\nexperience of scikit-learn. The paper concludes with key recommendations for\npractitioners and future research directions.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CY",
      "cs.LG",
      "K.4.1"
    ],
    "primary_category": "cs.SE",
    "comment": "15 pages",
    "pdf_url": "http://arxiv.org/pdf/2404.06484v5",
    "published_date": "2024-04-09 17:35:11 UTC",
    "updated_date": "2024-05-03 15:57:04 UTC"
  },
  {
    "arxiv_id": "2404.06480v2",
    "title": "Ada-LEval: Evaluating long-context LLMs with length-adaptable benchmarks",
    "authors": [
      "Chonghua Wang",
      "Haodong Duan",
      "Songyang Zhang",
      "Dahua Lin",
      "Kai Chen"
    ],
    "abstract": "Recently, the large language model (LLM) community has shown increasing\ninterest in enhancing LLMs' capability to handle extremely long documents. As\nvarious long-text techniques and model architectures emerge, the precise and\ndetailed evaluation of models' long-text capabilities has become increasingly\nimportant. Existing long-text evaluation benchmarks, such as L-Eval and\nLongBench, construct long-text test sets based on open-source datasets,\nfocusing mainly on QA and summarization tasks. These datasets include test\nsamples of varying lengths (from 2k to 32k+) entangled together, making it\nchallenging to assess model capabilities across different length ranges.\nMoreover, they do not cover the ultralong settings (100k+ tokens) that the\nlatest LLMs claim to achieve. In this paper, we introduce Ada-LEval, a\nlength-adaptable benchmark for evaluating the long-context understanding of\nLLMs. Ada-LEval includes two challenging subsets, TSort and BestAnswer, which\nenable a more reliable evaluation of LLMs' long context capabilities. These\nbenchmarks support intricate manipulation of the length of test cases, and can\neasily produce text samples up to 128k tokens. We evaluate 4 state-of-the-art\nclosed-source API models and 6 open-source models with Ada-LEval. The\nevaluation results demonstrate the limitations of current LLMs, especially in\nultra-long-context settings. Our code is available at\nhttps://github.com/open-compass/Ada-LEval.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "NAACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.06480v2",
    "published_date": "2024-04-09 17:30:48 UTC",
    "updated_date": "2024-04-10 07:40:56 UTC"
  },
  {
    "arxiv_id": "2404.06479v4",
    "title": "Visually Descriptive Language Model for Vector Graphics Reasoning",
    "authors": [
      "Zhenhailong Wang",
      "Joy Hsu",
      "Xingyao Wang",
      "Kuan-Hao Huang",
      "Manling Li",
      "Jiajun Wu",
      "Heng Ji"
    ],
    "abstract": "Despite significant advancements, large multimodal models (LMMs) still\nstruggle to bridge the gap between low-level visual perception -- focusing on\nshapes, sizes, and layouts -- and high-level language reasoning, such as\nsemantics and logic. This limitation is evident in tasks that require precise\nvisual perception, like comparing geometric properties or solving visual\nreasoning problems. To study this failure mode, we focus on vector graphics --\nimages composed of 2D objects and shapes, prevalent in LMM-based tasks in web,\ndesign, and OS environments. We identify two key research questions: how can we\nenable precise visual perception, and how can we facilitate high-level\nreasoning based on such low-level perceptions? To capture fine visual details,\nwe use Scalable Vector Graphics (SVG) for accurate encoding of visual scenes.\nHowever, SVGs are not readily interpretable by LMMs in a zero-shot manner. To\ntackle this, we propose the Visually Descriptive Language Model (VDLM), which\nintroduces a Primal Visual Description (PVD) as an intermediate textual\nrepresentation. PVD translates SVGs into a text-based abstraction consisting of\nprimitive attributes (e.g., shape, position, measurement) and their\ncorresponding values. PVD can be learned using task-agnostic synthesized data\nand represents visual primitives that are universal across vector graphics.\nThis abstraction is more structured, allowing for direct interpretation by\nfoundation models for zero-shot generalization. Without human-annotated data,\nempirical results show that VDLM significantly improves state-of-the-art LMMs\nlike GPT-4o on various multimodal perception and reasoning tasks. Extensive\nanalyses of VDLM show improved interpretability due to its disentangled\nperception and reasoning. We also demonstrate a positive correlation between\nPVD quality and task performance. Project page:\nhttps://mikewangwzhl.github.io/VDLM/",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "Project page: https://mikewangwzhl.github.io/VDLM/",
    "pdf_url": "http://arxiv.org/pdf/2404.06479v4",
    "published_date": "2024-04-09 17:30:18 UTC",
    "updated_date": "2024-10-03 21:59:32 UTC"
  },
  {
    "arxiv_id": "2404.06474v3",
    "title": "Autonomous Evaluation and Refinement of Digital Agents",
    "authors": [
      "Jiayi Pan",
      "Yichi Zhang",
      "Nicholas Tomlin",
      "Yifei Zhou",
      "Sergey Levine",
      "Alane Suhr"
    ],
    "abstract": "We show that domain-general automatic evaluators can significantly improve\nthe performance of agents for web navigation and device control. We experiment\nwith multiple evaluation models that trade off between inference cost,\nmodularity of design, and accuracy. We validate the performance of these models\nin several popular benchmarks for digital agents, finding between 74.4 and\n92.9% agreement with oracle evaluation metrics. Finally, we use these\nevaluators to improve the performance of existing agents via fine-tuning and\ninference-time guidance. Without any additional supervision, we improve\nstate-of-the-art performance by 29% on the popular benchmark WebArena, and\nachieve around 75% relative improvement in device control settings.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Published at COLM 2024. Code at\n  https://github.com/Berkeley-NLP/Agent-Eval-Refine",
    "pdf_url": "http://arxiv.org/pdf/2404.06474v3",
    "published_date": "2024-04-09 17:25:47 UTC",
    "updated_date": "2024-10-07 14:19:37 UTC"
  },
  {
    "arxiv_id": "2404.06529v1",
    "title": "Emergent Braitenberg-style Behaviours for Navigating the ViZDoom `My Way Home' Labyrinth",
    "authors": [
      "Caleidgh Bayer",
      "Robert J. Smith",
      "Malcolm I. Heywood"
    ],
    "abstract": "The navigation of complex labyrinths with tens of rooms under visual\npartially observable state is typically addressed using recurrent deep\nreinforcement learning architectures. In this work, we show that navigation can\nbe achieved through the emergent evolution of a simple Braitentberg-style\nheuristic that structures the interaction between agent and labyrinth, i.e.\ncomplex behaviour from simple heuristics. To do so, the approach of tangled\nprogram graphs is assumed in which programs cooperatively coevolve to develop a\nmodular indexing scheme that only employs 0.8\\% of the state space. We\nattribute this simplicity to several biases implicit in the representation,\nsuch as the use of pixel indexing as opposed to deploying a convolutional\nkernel or image processing operators.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.06529v1",
    "published_date": "2024-04-09 17:12:16 UTC",
    "updated_date": "2024-04-09 17:12:16 UTC"
  },
  {
    "arxiv_id": "2404.06453v1",
    "title": "PURE: Turning Polysemantic Neurons Into Pure Features by Identifying Relevant Circuits",
    "authors": [
      "Maximilian Dreyer",
      "Erblina Purelku",
      "Johanna Vielhaben",
      "Wojciech Samek",
      "Sebastian Lapuschkin"
    ],
    "abstract": "The field of mechanistic interpretability aims to study the role of\nindividual neurons in Deep Neural Networks. Single neurons, however, have the\ncapability to act polysemantically and encode for multiple (unrelated)\nfeatures, which renders their interpretation difficult. We present a method for\ndisentangling polysemanticity of any Deep Neural Network by decomposing a\npolysemantic neuron into multiple monosemantic \"virtual\" neurons. This is\nachieved by identifying the relevant sub-graph (\"circuit\") for each \"pure\"\nfeature. We demonstrate how our approach allows us to find and disentangle\nvarious polysemantic units of ResNet models trained on ImageNet. While\nevaluating feature visualizations using CLIP, our method effectively\ndisentangles representations, improving upon methods based on neuron\nactivations. Our code is available at https://github.com/maxdreyer/PURE.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "14 pages (4 pages manuscript, 2 pages references, 8 pages appendix)",
    "pdf_url": "http://arxiv.org/pdf/2404.06453v1",
    "published_date": "2024-04-09 16:54:19 UTC",
    "updated_date": "2024-04-09 16:54:19 UTC"
  },
  {
    "arxiv_id": "2404.06448v2",
    "title": "Automated Federated Pipeline for Parameter-Efficient Fine-Tuning of Large Language Models",
    "authors": [
      "Zihan Fang",
      "Zheng Lin",
      "Zhe Chen",
      "Xianhao Chen",
      "Yue Gao",
      "Yuguang Fang"
    ],
    "abstract": "Recently, there has been a surge in the development of advanced intelligent\ngenerative content (AIGC), especially large language models (LLMs). However,\nfor many downstream tasks, it is necessary to fine-tune LLMs using private\ndata. While federated learning offers a promising privacy-preserving solution\nto LLM fine-tuning, the substantial size of an LLM, combined with high\ncomputational and communication demands, makes it hard to apply to downstream\ntasks. More importantly, private edge servers often possess varying computing\nand network resources in real-world scenarios, introducing additional\ncomplexities to LLM fine-tuning. To tackle these problems, we design and\nimplement an automated federated pipeline, named FedPipe, to fine-tune LLMs\nwith minimal training cost but without adding any inference latency. FedPipe\nfirstly identifies the weights to be fine-tuned based on their contributions to\nthe LLM training. It then configures a low-rank adapter for each selected\nweight to train local low-rank adapters on an edge server, and aggregate local\nadapters of all edge servers to fine-tune the whole LLM. Finally, it\nappropriately quantizes the parameters of LLM to reduce memory space according\nto the requirements of edge servers. Extensive experiments demonstrate that\nFedPipe expedites the model training and achieves higher accuracy than\nstate-of-the-art benchmarks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages, 16 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.06448v2",
    "published_date": "2024-04-09 16:50:30 UTC",
    "updated_date": "2024-12-06 07:10:30 UTC"
  },
  {
    "arxiv_id": "2404.06430v2",
    "title": "pfl-research: simulation framework for accelerating research in Private Federated Learning",
    "authors": [
      "Filip Granqvist",
      "Congzheng Song",
      "Áine Cahill",
      "Rogier van Dalen",
      "Martin Pelikan",
      "Yi Sheng Chan",
      "Xiaojun Feng",
      "Natarajan Krishnaswami",
      "Vojta Jina",
      "Mona Chitnis"
    ],
    "abstract": "Federated learning (FL) is an emerging machine learning (ML) training\nparadigm where clients own their data and collaborate to train a global model,\nwithout revealing any data to the server and other participants. Researchers\ncommonly perform experiments in a simulation environment to quickly iterate on\nideas. However, existing open-source tools do not offer the efficiency required\nto simulate FL on larger and more realistic FL datasets. We introduce\npfl-research, a fast, modular, and easy-to-use Python framework for simulating\nFL. It supports TensorFlow, PyTorch, and non-neural network models, and is\ntightly integrated with state-of-the-art privacy algorithms. We study the speed\nof open-source FL frameworks and show that pfl-research is 7-72$\\times$ faster\nthan alternative open-source frameworks on common cross-device setups. Such\nspeedup will significantly boost the productivity of the FL research community\nand enable testing hypotheses on realistic FL datasets that were previously too\nresource intensive. We release a suite of benchmarks that evaluates an\nalgorithm's overall performance on a diverse set of realistic scenarios. The\ncode is available on GitHub at https://github.com/apple/pfl-research.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.06430v2",
    "published_date": "2024-04-09 16:23:01 UTC",
    "updated_date": "2024-12-10 11:21:26 UTC"
  },
  {
    "arxiv_id": "2404.06429v3",
    "title": "Magic-Boost: Boost 3D Generation with Multi-View Conditioned Diffusion",
    "authors": [
      "Fan Yang",
      "Jianfeng Zhang",
      "Yichun Shi",
      "Bowen Chen",
      "Chenxu Zhang",
      "Huichao Zhang",
      "Xiaofeng Yang",
      "Xiu Li",
      "Jiashi Feng",
      "Guosheng Lin"
    ],
    "abstract": "Benefiting from the rapid development of 2D diffusion models, 3D content\ngeneration has witnessed significant progress. One promising solution is to\nfinetune the pre-trained 2D diffusion models to produce multi-view images and\nthen reconstruct them into 3D assets via feed-forward sparse-view\nreconstruction models. However, limited by the 3D inconsistency in the\ngenerated multi-view images and the low reconstruction resolution of the\nfeed-forward reconstruction models, the generated 3d assets are still limited\nto incorrect geometries and blurry textures. To address this problem, we\npresent a multi-view based refine method, named Magic-Boost, to further refine\nthe generation results. In detail, we first propose a novel multi-view\nconditioned diffusion model which extracts 3d prior from the synthesized\nmulti-view images to synthesize high-fidelity novel view images and then\nintroduce a novel iterative-update strategy to adopt it to provide precise\nguidance to refine the coarse generated results through a fast optimization\nprocess. Conditioned on the strong 3d priors extracted from the synthesized\nmulti-view images, Magic-Boost is capable of providing precise optimization\nguidance that well aligns with the coarse generated 3D assets, enriching the\nlocal detail in both geometry and texture within a short time ($\\sim15$min).\nExtensive experiments show Magic-Boost greatly enhances the coarse generated\ninputs, generates high-quality 3D assets with rich geometric and textural\ndetails. (Project Page: https://magic-research.github.io/magic-boost/)",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.06429v3",
    "published_date": "2024-04-09 16:20:03 UTC",
    "updated_date": "2025-01-09 02:34:25 UTC"
  },
  {
    "arxiv_id": "2404.06423v3",
    "title": "Deep Reinforcement Learning-Based Approach for a Single Vehicle Persistent Surveillance Problem with Fuel Constraints",
    "authors": [
      "Manav Mishra",
      "Hritik Bana",
      "Saswata Sarkar",
      "Sujeevraja Sanjeevi",
      "PB Sujit",
      "Kaarthik Sundar"
    ],
    "abstract": "This article presents a deep reinforcement learning-based approach to tackle\na persistent surveillance mission requiring a single unmanned aerial vehicle\ninitially stationed at a depot with fuel or time-of-flight constraints to\nrepeatedly visit a set of targets with equal priority. Owing to the vehicle's\nfuel or time-of-flight constraints, the vehicle must be regularly refueled, or\nits battery must be recharged at the depot. The objective of the problem is to\ndetermine an optimal sequence of visits to the targets that minimizes the\nmaximum time elapsed between successive visits to any target while ensuring\nthat the vehicle never runs out of fuel or charge. We present a deep\nreinforcement learning algorithm to solve this problem and present the results\nof numerical experiments that corroborate the effectiveness of this approach in\ncomparison with common-sense greedy heuristics.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "6 pages",
    "pdf_url": "http://arxiv.org/pdf/2404.06423v3",
    "published_date": "2024-04-09 16:14:03 UTC",
    "updated_date": "2024-05-03 02:05:20 UTC"
  },
  {
    "arxiv_id": "2404.06418v1",
    "title": "Studying the Impact of Latent Representations in Implicit Neural Networks for Scientific Continuous Field Reconstruction",
    "authors": [
      "Wei Xu",
      "Derek Freeman DeSantis",
      "Xihaier Luo",
      "Avish Parmar",
      "Klaus Tan",
      "Balu Nadiga",
      "Yihui Ren",
      "Shinjae Yoo"
    ],
    "abstract": "Learning a continuous and reliable representation of physical fields from\nsparse sampling is challenging and it affects diverse scientific disciplines.\nIn a recent work, we present a novel model called MMGN (Multiplicative and\nModulated Gabor Network) with implicit neural networks. In this work, we design\nadditional studies leveraging explainability methods to complement the previous\nexperiments and further enhance the understanding of latent representations\ngenerated by the model. The adopted methods are general enough to be leveraged\nfor any latent space inspection. Preliminary results demonstrate the contextual\ninformation incorporated in the latent representations and their impact on the\nmodel performance. As a work in progress, we will continue to verify our\nfindings and develop novel explainability approaches.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.06418v1",
    "published_date": "2024-04-09 16:07:35 UTC",
    "updated_date": "2024-04-09 16:07:35 UTC"
  },
  {
    "arxiv_id": "2404.06411v1",
    "title": "AgentQuest: A Modular Benchmark Framework to Measure Progress and Improve LLM Agents",
    "authors": [
      "Luca Gioacchini",
      "Giuseppe Siracusano",
      "Davide Sanvito",
      "Kiril Gashteovski",
      "David Friede",
      "Roberto Bifulco",
      "Carolin Lawrence"
    ],
    "abstract": "The advances made by Large Language Models (LLMs) have led to the pursuit of\nLLM agents that can solve intricate, multi-step reasoning tasks. As with any\nresearch pursuit, benchmarking and evaluation are key corner stones to\nefficient and reliable progress. However, existing benchmarks are often narrow\nand simply compute overall task success. To face these issues, we propose\nAgentQuest -- a framework where (i) both benchmarks and metrics are modular and\neasily extensible through well documented and easy-to-use APIs; (ii) we offer\ntwo new evaluation metrics that can reliably track LLM agent progress while\nsolving a task. We exemplify the utility of the metrics on two use cases\nwherein we identify common failure points and refine the agent architecture to\nobtain a significant performance increase. Together with the research\ncommunity, we hope to extend AgentQuest further and therefore we make it\navailable under https://github.com/nec-research/agentquest.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at the 2024 Conference of the North American Chapter of the\n  Association for Computational Linguistics: Human Language Technologies\n  (NAACL-HLT 2024)",
    "pdf_url": "http://arxiv.org/pdf/2404.06411v1",
    "published_date": "2024-04-09 16:01:24 UTC",
    "updated_date": "2024-04-09 16:01:24 UTC"
  },
  {
    "arxiv_id": "2404.06407v3",
    "title": "Rethinking How to Evaluate Language Model Jailbreak",
    "authors": [
      "Hongyu Cai",
      "Arjun Arunasalam",
      "Leo Y. Lin",
      "Antonio Bianchi",
      "Z. Berkay Celik"
    ],
    "abstract": "Large language models (LLMs) have become increasingly integrated with various\napplications. To ensure that LLMs do not generate unsafe responses, they are\naligned with safeguards that specify what content is restricted. However, such\nalignment can be bypassed to produce prohibited content using a technique\ncommonly referred to as jailbreak. Different systems have been proposed to\nperform the jailbreak automatically. These systems rely on evaluation methods\nto determine whether a jailbreak attempt is successful. However, our analysis\nreveals that current jailbreak evaluation methods have two limitations. (1)\nTheir objectives lack clarity and do not align with the goal of identifying\nunsafe responses. (2) They oversimplify the jailbreak result as a binary\noutcome, successful or not. In this paper, we propose three metrics, safeguard\nviolation, informativeness, and relative truthfulness, to evaluate language\nmodel jailbreak. Additionally, we demonstrate how these metrics correlate with\nthe goal of different malicious actors. To compute these metrics, we introduce\na multifaceted approach that extends the natural language generation evaluation\nmethod after preprocessing the response. We evaluate our metrics on a benchmark\ndataset produced from three malicious intent datasets and three jailbreak\nsystems. The benchmark dataset is labeled by three annotators. We compare our\nmultifaceted approach with three existing jailbreak evaluation methods.\nExperiments demonstrate that our multifaceted evaluation outperforms existing\nmethods, with F1 scores improving on average by 17% compared to existing\nbaselines. Our findings motivate the need to move away from the binary view of\nthe jailbreak problem and incorporate a more comprehensive evaluation to ensure\nthe safety of the language model.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.06407v3",
    "published_date": "2024-04-09 15:54:16 UTC",
    "updated_date": "2024-05-07 14:06:23 UTC"
  },
  {
    "arxiv_id": "2404.06405v2",
    "title": "Wu's Method can Boost Symbolic AI to Rival Silver Medalists and AlphaGeometry to Outperform Gold Medalists at IMO Geometry",
    "authors": [
      "Shiven Sinha",
      "Ameya Prabhu",
      "Ponnurangam Kumaraguru",
      "Siddharth Bhat",
      "Matthias Bethge"
    ],
    "abstract": "Proving geometric theorems constitutes a hallmark of visual reasoning\ncombining both intuitive and logical skills. Therefore, automated theorem\nproving of Olympiad-level geometry problems is considered a notable milestone\nin human-level automated reasoning. The introduction of AlphaGeometry, a\nneuro-symbolic model trained with 100 million synthetic samples, marked a major\nbreakthrough. It solved 25 of 30 International Mathematical Olympiad (IMO)\nproblems whereas the reported baseline based on Wu's method solved only ten. In\nthis note, we revisit the IMO-AG-30 Challenge introduced with AlphaGeometry,\nand find that Wu's method is surprisingly strong. Wu's method alone can solve\n15 problems, and some of them are not solved by any of the other methods. This\nleads to two key findings: (i) Combining Wu's method with the classic synthetic\nmethods of deductive databases and angle, ratio, and distance chasing solves 21\nout of 30 methods by just using a CPU-only laptop with a time limit of 5\nminutes per problem. Essentially, this classic method solves just 4 problems\nless than AlphaGeometry and establishes the first fully symbolic baseline\nstrong enough to rival the performance of an IMO silver medalist. (ii) Wu's\nmethod even solves 2 of the 5 problems that AlphaGeometry failed to solve.\nThus, by combining AlphaGeometry with Wu's method we set a new state-of-the-art\nfor automated theorem proving on IMO-AG-30, solving 27 out of 30 problems, the\nfirst AI method which outperforms an IMO gold medalist.",
    "categories": [
      "cs.AI",
      "cs.CG",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Work in Progress. Released for wider feedback",
    "pdf_url": "http://arxiv.org/pdf/2404.06405v2",
    "published_date": "2024-04-09 15:54:00 UTC",
    "updated_date": "2024-04-11 14:37:29 UTC"
  },
  {
    "arxiv_id": "2404.06404v1",
    "title": "Apprentices to Research Assistants: Advancing Research with Large Language Models",
    "authors": [
      "M. Namvarpour",
      "A. Razi"
    ],
    "abstract": "Large Language Models (LLMs) have emerged as powerful tools in various\nresearch domains. This article examines their potential through a literature\nreview and firsthand experimentation. While LLMs offer benefits like\ncost-effectiveness and efficiency, challenges such as prompt tuning, biases,\nand subjectivity must be addressed. The study presents insights from\nexperiments utilizing LLMs for qualitative analysis, highlighting successes and\nlimitations. Additionally, it discusses strategies for mitigating challenges,\nsuch as prompt optimization techniques and leveraging human expertise. This\nstudy aligns with the 'LLMs as Research Tools' workshop's focus on integrating\nLLMs into HCI data work critically and ethically. By addressing both\nopportunities and challenges, our work contributes to the ongoing dialogue on\ntheir responsible application in research.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG",
      "I.2; H.5; H.3; K.4; I.7"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.06404v1",
    "published_date": "2024-04-09 15:53:06 UTC",
    "updated_date": "2024-04-09 15:53:06 UTC"
  },
  {
    "arxiv_id": "2404.06393v4",
    "title": "MuPT: A Generative Symbolic Music Pretrained Transformer",
    "authors": [
      "Xingwei Qu",
      "Yuelin Bai",
      "Yinghao Ma",
      "Ziya Zhou",
      "Ka Man Lo",
      "Jiaheng Liu",
      "Ruibin Yuan",
      "Lejun Min",
      "Xueling Liu",
      "Tianyu Zhang",
      "Xinrun Du",
      "Shuyue Guo",
      "Yiming Liang",
      "Yizhi Li",
      "Shangda Wu",
      "Junting Zhou",
      "Tianyu Zheng",
      "Ziyang Ma",
      "Fengze Han",
      "Wei Xue",
      "Gus Xia",
      "Emmanouil Benetos",
      "Xiang Yue",
      "Chenghua Lin",
      "Xu Tan",
      "Stephen W. Huang",
      "Jie Fu",
      "Ge Zhang"
    ],
    "abstract": "In this paper, we explore the application of Large Language Models (LLMs) to\nthe pre-training of music. While the prevalent use of MIDI in music modeling is\nwell-established, our findings suggest that LLMs are inherently more compatible\nwith ABC Notation, which aligns more closely with their design and strengths,\nthereby enhancing the model's performance in musical composition. To address\nthe challenges associated with misaligned measures from different tracks during\ngeneration, we propose the development of a Synchronized Multi-Track ABC\nNotation (SMT-ABC Notation), which aims to preserve coherence across multiple\nmusical tracks. Our contributions include a series of models capable of\nhandling up to 8192 tokens, covering 90% of the symbolic music data in our\ntraining set. Furthermore, we explore the implications of the Symbolic Music\nScaling Law (SMS Law) on model performance. The results indicate a promising\ndirection for future research in music generation, offering extensive resources\nfor community-led research through our open-source contributions.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.06393v4",
    "published_date": "2024-04-09 15:35:52 UTC",
    "updated_date": "2024-11-05 15:40:25 UTC"
  },
  {
    "arxiv_id": "2404.06392v1",
    "title": "Event Extraction in Basque: Typologically motivated Cross-Lingual Transfer-Learning Analysis",
    "authors": [
      "Mikel Zubillaga",
      "Oscar Sainz",
      "Ainara Estarrona",
      "Oier Lopez de Lacalle",
      "Eneko Agirre"
    ],
    "abstract": "Cross-lingual transfer-learning is widely used in Event Extraction for\nlow-resource languages and involves a Multilingual Language Model that is\ntrained in a source language and applied to the target language. This paper\nstudies whether the typological similarity between source and target languages\nimpacts the performance of cross-lingual transfer, an under-explored topic. We\nfirst focus on Basque as the target language, which is an ideal target language\nbecause it is typologically different from surrounding languages. Our\nexperiments on three Event Extraction tasks show that the shared linguistic\ncharacteristic between source and target languages does have an impact on\ntransfer quality. Further analysis of 72 language pairs reveals that for tasks\nthat involve token classification such as entity and event trigger\nidentification, common writing script and morphological features produce higher\nquality cross-lingual transfer. In contrast, for tasks involving structural\nprediction like argument extraction, common word order is the most relevant\nfeature. In addition, we show that when increasing the training size, not all\nthe languages scale in the same way in the cross-lingual setting. To perform\nthe experiments we introduce EusIE, an event extraction dataset for Basque,\nwhich follows the Multilingual Event Extraction dataset (MEE). The dataset and\ncode are publicly available.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at LREC-Coling 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.06392v1",
    "published_date": "2024-04-09 15:35:41 UTC",
    "updated_date": "2024-04-09 15:35:41 UTC"
  },
  {
    "arxiv_id": "2404.06370v1",
    "title": "Enhancing Decision Analysis with a Large Language Model: pyDecision a Comprehensive Library of MCDA Methods in Python",
    "authors": [
      "Valdecy Pereira",
      "Marcio Pereira Basilio",
      "Carlos Henrique Tarjano SantosCarlos Henrique Tarjano Santos"
    ],
    "abstract": "Purpose: Multicriteria decision analysis (MCDA) has become increasingly\nessential for decision-making in complex environments. In response to this\nneed, the pyDecision library, implemented in Python and available at\nhttps://bit.ly/3tLFGtH, has been developed to provide a comprehensive and\naccessible collection of MCDA methods. Methods: The pyDecision offers 70 MCDA\nmethods, including AHP, TOPSIS, and the PROMETHEE and ELECTRE families. Beyond\noffering a vast range of techniques, the library provides visualization tools\nfor more intuitive results interpretation. In addition to these features,\npyDecision has integrated ChatGPT, an advanced Large Language Model, where\ndecision-makers can use ChatGPT to discuss and compare the outcomes of\ndifferent methods, providing a more interactive and intuitive understanding of\nthe solutions. Findings: Large Language Models are undeniably potent but can\nsometimes be a double-edged sword. Its answers may be misleading without\nrigorous verification of its outputs, especially for researchers lacking deep\ndomain expertise. It's imperative to approach its insights with a discerning\neye and a solid foundation in the relevant field. Originality: With the\nintegration of MCDA methods and ChatGPT, pyDecision is a significant\ncontribution to the scientific community, as it is an invaluable resource for\nresearchers, practitioners, and decision-makers navigating complex\ndecision-making problems and seeking the most appropriate solutions based on\nMCDA methods.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "23 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.06370v1",
    "published_date": "2024-04-09 15:06:25 UTC",
    "updated_date": "2024-04-09 15:06:25 UTC"
  },
  {
    "arxiv_id": "2404.06369v2",
    "title": "WebCode2M: A Real-World Dataset for Code Generation from Webpage Designs",
    "authors": [
      "Yi Gui",
      "Zhen Li",
      "Yao Wan",
      "Yemin Shi",
      "Hongyu Zhang",
      "Yi Su",
      "Bohua Chen",
      "Dongping Chen",
      "Siyuan Wu",
      "Xing Zhou",
      "Wenbin Jiang",
      "Hai Jin",
      "Xiangliang Zhang"
    ],
    "abstract": "Automatically generating webpage code from webpage designs can significantly\nreduce the workload of front-end developers, and recent Multimodal Large\nLanguage Models (MLLMs) have shown promising potential in this area. However,\nour investigation reveals that most existing MLLMs are constrained by the\nabsence of high-quality, large-scale, real-world datasets, resulting in\ninadequate performance in automated webpage code generation. To fill this gap,\nthis paper introduces WebCode2M, a new dataset comprising 2.56 million\ninstances, each containing a design image along with the corresponding webpage\ncode and layout details. Sourced from real-world web resources, WebCode2M\noffers a rich and valuable dataset for webpage code generation across a variety\nof applications. The dataset quality is ensured by a scoring model that filters\nout instances with aesthetic deficiencies or other incomplete elements. To\nvalidate the effectiveness of WebCode2M, we introduce a baseline model based on\nthe Vision Transformer (ViT), named WebCoder, and establish a benchmark for\nfair comparison. Additionally, we introduce a new metric, TreeBLEU, to measure\nthe structural hierarchy recall. The benchmarking results demonstrate that our\ndataset significantly improves the ability of MLLMs to generate code from\nwebpage designs, confirming its effectiveness and usability for future\napplications in front-end design tools. Finally, we highlight several practical\nchallenges introduced by our dataset, calling for further research. The code\nand dataset are publicly available at our project homepage:\nhttps://webcode2m.github.io.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CV",
    "comment": "WWW'25",
    "pdf_url": "http://arxiv.org/pdf/2404.06369v2",
    "published_date": "2024-04-09 15:05:48 UTC",
    "updated_date": "2025-02-22 05:15:18 UTC"
  },
  {
    "arxiv_id": "2404.06362v2",
    "title": "Test-Time Adaptation with SaLIP: A Cascade of SAM and CLIP for Zero shot Medical Image Segmentation",
    "authors": [
      "Sidra Aleem",
      "Fangyijie Wang",
      "Mayug Maniparambil",
      "Eric Arazo",
      "Julia Dietlmeier",
      "Guenole Silvestre",
      "Kathleen Curran",
      "Noel E. O'Connor",
      "Suzanne Little"
    ],
    "abstract": "The Segment Anything Model (SAM) and CLIP are remarkable vision foundation\nmodels (VFMs). SAM, a prompt driven segmentation model, excels in segmentation\ntasks across diverse domains, while CLIP is renowned for its zero shot\nrecognition capabilities. However, their unified potential has not yet been\nexplored in medical image segmentation. To adapt SAM to medical imaging,\nexisting methods primarily rely on tuning strategies that require extensive\ndata or prior prompts tailored to the specific task, making it particularly\nchallenging when only a limited number of data samples are available. This work\npresents an in depth exploration of integrating SAM and CLIP into a unified\nframework for medical image segmentation. Specifically, we propose a simple\nunified framework, SaLIP, for organ segmentation. Initially, SAM is used for\npart based segmentation within the image, followed by CLIP to retrieve the mask\ncorresponding to the region of interest (ROI) from the pool of SAM generated\nmasks. Finally, SAM is prompted by the retrieved ROI to segment a specific\norgan. Thus, SaLIP is training and fine tuning free and does not rely on domain\nexpertise or labeled data for prompt engineering. Our method shows substantial\nenhancements in zero shot segmentation, showcasing notable improvements in DICE\nscores across diverse segmentation tasks like brain (63.46%), lung (50.11%),\nand fetal head (30.82%), when compared to un prompted SAM. Code and text\nprompts are available at: https://github.com/aleemsidra/SaLIP.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.06362v2",
    "published_date": "2024-04-09 14:56:34 UTC",
    "updated_date": "2024-04-30 15:58:32 UTC"
  },
  {
    "arxiv_id": "2404.06356v1",
    "title": "Policy-Guided Diffusion",
    "authors": [
      "Matthew Thomas Jackson",
      "Michael Tryfan Matthews",
      "Cong Lu",
      "Benjamin Ellis",
      "Shimon Whiteson",
      "Jakob Foerster"
    ],
    "abstract": "In many real-world settings, agents must learn from an offline dataset\ngathered by some prior behavior policy. Such a setting naturally leads to\ndistribution shift between the behavior policy and the target policy being\ntrained - requiring policy conservatism to avoid instability and overestimation\nbias. Autoregressive world models offer a different solution to this by\ngenerating synthetic, on-policy experience. However, in practice, model\nrollouts must be severely truncated to avoid compounding error. As an\nalternative, we propose policy-guided diffusion. Our method uses diffusion\nmodels to generate entire trajectories under the behavior distribution,\napplying guidance from the target policy to move synthetic experience further\non-policy. We show that policy-guided diffusion models a regularized form of\nthe target distribution that balances action likelihood under both the target\nand behavior policies, leading to plausible trajectories with high target\npolicy probability, while retaining a lower dynamics error than an offline\nworld model baseline. Using synthetic experience from policy-guided diffusion\nas a drop-in substitute for real data, we demonstrate significant improvements\nin performance across a range of standard offline reinforcement learning\nalgorithms and environments. Our approach provides an effective alternative to\nautoregressive offline world models, opening the door to the controllable\ngeneration of synthetic training data.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "Previously at the NeurIPS 2023 Workshop on Robot Learning",
    "pdf_url": "http://arxiv.org/pdf/2404.06356v1",
    "published_date": "2024-04-09 14:46:48 UTC",
    "updated_date": "2024-04-09 14:46:48 UTC"
  },
  {
    "arxiv_id": "2404.06353v1",
    "title": "High Noise Scheduling is a Must",
    "authors": [
      "Mahmut S. Gokmen",
      "Cody Bumgardner",
      "Jie Zhang",
      "Ge Wang",
      "Jin Chen"
    ],
    "abstract": "Consistency models possess high capabilities for image generation, advancing\nsampling steps to a single step through their advanced techniques. Current\nadvancements move one step forward consistency training techniques and\neliminates the limitation of distillation training. Even though the proposed\ncurriculum and noise scheduling in improved training techniques yield better\nresults than basic consistency models, it lacks well balanced noise\ndistribution and its consistency between curriculum. In this study, it is\ninvestigated the balance between high and low noise levels in noise\ndistribution and offered polynomial noise distribution to maintain the\nstability. This proposed polynomial noise distribution is also supported with a\npredefined Karras noises to prevent unique noise levels arises with Karras\nnoise generation algorithm. Furthermore, by elimination of learned noisy steps\nwith a curriculum based on sinusoidal function increase the performance of the\nmodel in denoising. To make a fair comparison with the latest released\nconsistency model training techniques, experiments are conducted with same\nhyper-parameters except curriculum and noise distribution. The models utilized\nduring experiments are determined with low depth to prove the robustness of our\nproposed technique. The results show that the polynomial noise distribution\noutperforms the model trained with log-normal noise distribution, yielding a\n33.54 FID score after 100,000 training steps with constant discretization\nsteps. Additionally, the implementation of a sinusoidal-based curriculum\nenhances denoising performance, resulting in a FID score of 30.48.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.06353v1",
    "published_date": "2024-04-09 14:44:12 UTC",
    "updated_date": "2024-04-09 14:44:12 UTC"
  },
  {
    "arxiv_id": "2404.06345v2",
    "title": "AgentsCoDriver: Large Language Model Empowered Collaborative Driving with Lifelong Learning",
    "authors": [
      "Senkang Hu",
      "Zhengru Fang",
      "Zihan Fang",
      "Yiqin Deng",
      "Xianhao Chen",
      "Yuguang Fang"
    ],
    "abstract": "Connected and autonomous driving is developing rapidly in recent years.\nHowever, current autonomous driving systems, which are primarily based on\ndata-driven approaches, exhibit deficiencies in interpretability,\ngeneralization, and continuing learning capabilities. In addition, the\nsingle-vehicle autonomous driving systems lack of the ability of collaboration\nand negotiation with other vehicles, which is crucial for the safety and\nefficiency of autonomous driving systems. In order to address these issues, we\nleverage large language models (LLMs) to develop a novel framework,\nAgentsCoDriver, to enable multiple vehicles to conduct collaborative driving.\nAgentsCoDriver consists of five modules: observation module, reasoning engine,\ncognitive memory module, reinforcement reflection module, and communication\nmodule. It can accumulate knowledge, lessons, and experiences over time by\ncontinuously interacting with the environment, thereby making itself capable of\nlifelong learning. In addition, by leveraging the communication module,\ndifferent agents can exchange information and realize negotiation and\ncollaboration in complex traffic environments. Extensive experiments are\nconducted and show the superiority of AgentsCoDriver.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.06345v2",
    "published_date": "2024-04-09 14:33:16 UTC",
    "updated_date": "2024-04-21 09:12:19 UTC"
  },
  {
    "arxiv_id": "2404.06330v1",
    "title": "Generative Pre-Trained Transformer for Symbolic Regression Base In-Context Reinforcement Learning",
    "authors": [
      "Yanjie Li",
      "Weijun Li",
      "Lina Yu",
      "Min Wu",
      "Jingyi Liu",
      "Wenqiang Li",
      "Meilan Hao",
      "Shu Wei",
      "Yusong Deng"
    ],
    "abstract": "The mathematical formula is the human language to describe nature and is the\nessence of scientific research. Finding mathematical formulas from\nobservational data is a major demand of scientific research and a major\nchallenge of artificial intelligence. This area is called symbolic regression.\nOriginally symbolic regression was often formulated as a combinatorial\noptimization problem and solved using GP or reinforcement learning algorithms.\nThese two kinds of algorithms have strong noise robustness ability and good\nVersatility. However, inference time usually takes a long time, so the search\nefficiency is relatively low. Later, based on large-scale pre-training data\nproposed, such methods use a large number of synthetic data points and\nexpression pairs to train a Generative Pre-Trained Transformer(GPT). Then this\nGPT can only need to perform one forward propagation to obtain the results, the\nadvantage is that the inference speed is very fast. However, its performance is\nvery dependent on the training data and performs poorly on data outside the\ntraining set, which leads to poor noise robustness and Versatility of such\nmethods. So, can we combine the advantages of the above two categories of SR\nalgorithms? In this paper, we propose \\textbf{FormulaGPT}, which trains a GPT\nusing massive sparse reward learning histories of reinforcement learning-based\nSR algorithms as training data. After training, the SR algorithm based on\nreinforcement learning is distilled into a Transformer. When new test data\ncomes, FormulaGPT can directly generate a \"reinforcement learning process\" and\nautomatically update the learning policy in context. Tested on more than ten\ndatasets including SRBench, formulaGPT achieves the state-of-the-art\nperformance in fitting ability compared with four baselines. In addition, it\nachieves satisfactory results in noise robustness, versatility, and inference\nefficiency.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "21 pages",
    "pdf_url": "http://arxiv.org/pdf/2404.06330v1",
    "published_date": "2024-04-09 14:08:47 UTC",
    "updated_date": "2024-04-09 14:08:47 UTC"
  },
  {
    "arxiv_id": "2404.06326v1",
    "title": "What is the $\\textit{intrinsic}$ dimension of your binary data? -- and how to compute it quickly",
    "authors": [
      "Tom Hanika",
      "Tobias Hille"
    ],
    "abstract": "Dimensionality is an important aspect for analyzing and understanding\n(high-dimensional) data. In their 2006 ICDM paper Tatti et al. answered the\nquestion for a (interpretable) dimension of binary data tables by introducing a\nnormalized correlation dimension. In the present work we revisit their results\nand contrast them with a concept based notion of intrinsic dimension (ID)\nrecently introduced for geometric data sets. To do this, we present a novel\napproximation for this ID that is based on computing concepts only up to a\ncertain support value. We demonstrate and evaluate our approximation using all\navailable datasets from Tatti et al., which have between 469 and 41271\nextrinsic dimensions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "68T05 06-08 68T01 68T09"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.06326v1",
    "published_date": "2024-04-09 14:04:26 UTC",
    "updated_date": "2024-04-09 14:04:26 UTC"
  },
  {
    "arxiv_id": "2404.06325v1",
    "title": "Automatically Learning HTN Methods from Landmarks",
    "authors": [
      "Ruoxi Li",
      "Dana Nau",
      "Mark Roberts",
      "Morgan Fine-Morris"
    ],
    "abstract": "Hierarchical Task Network (HTN) planning usually requires a domain engineer\nto provide manual input about how to decompose a planning problem. Even\nHTN-MAKER, a well-known method-learning algorithm, requires a domain engineer\nto annotate the tasks with information about what to learn. We introduce\nCURRICULAMA, an HTN method learning algorithm that completely automates the\nlearning process. It uses landmark analysis to compose annotated tasks and\nleverages curriculum learning to order the learning of methods from simpler to\nmore complex. This eliminates the need for manual input, resolving a core issue\nwith HTN-MAKER. We prove CURRICULAMA's soundness, and show experimentally that\nit has a substantially similar convergence rate in learning a complete set of\nmethods to HTN-MAKER.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "This work has been submitted to FLAIRS-24",
    "pdf_url": "http://arxiv.org/pdf/2404.06325v1",
    "published_date": "2024-04-09 14:03:38 UTC",
    "updated_date": "2024-04-09 14:03:38 UTC"
  },
  {
    "arxiv_id": "2404.06324v1",
    "title": "Dynamic D2D-Assisted Federated Learning over O-RAN: Performance Analysis, MAC Scheduler, and Asymmetric User Selection",
    "authors": [
      "Payam Abdisarabshali",
      "Kwang Taik Kim",
      "Michael Langberg",
      "Weifeng Su",
      "Seyyedali Hosseinalipour"
    ],
    "abstract": "Existing studies on federated learning (FL) are mostly focused on system\norchestration for static snapshots of the network and making static control\ndecisions (e.g., spectrum allocation). However, real-world wireless networks\nare susceptible to temporal variations of wireless channel capacity and users'\ndatasets. In this paper, we incorporate multi-granular system dynamics (MSDs)\ninto FL, including (M1) dynamic wireless channel capacity, captured by a set of\ndiscrete-time events, called $\\mathscr{D}$-Events, and (M2) dynamic datasets of\nusers. The latter is characterized by (M2-a) modeling the dynamics of user's\ndataset size via an ordinary differential equation and (M2-b) introducing\ndynamic model drift}, formulated via a partial differential inequality} drawing\nconcrete analytical connections between the dynamics of users' datasets and FL\naccuracy. We then conduct FL orchestration under MSDs by introducing dynamic\ncooperative FL with dedicated MAC schedulers (DCLM), exploiting the unique\nfeatures of open radio access network (O-RAN). DCLM proposes (i) a hierarchical\ndevice-to-device (D2D)-assisted model training, (ii) dynamic control decisions\nthrough dedicated O-RAN MAC schedulers, and (iii) asymmetric user selection. We\nprovide extensive theoretical analysis to study the convergence of DCLM. We\nthen optimize the degrees of freedom (e.g., user selection and spectrum\nallocation) in DCLM through a highly non-convex optimization problem. We\ndevelop a systematic approach to obtain the solution for this problem, opening\nthe door to solving a broad variety of network-aware FL optimization problems.\nWe show the efficiency of DCLM via numerical simulations and provide a series\nof future directions.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NI",
    "comment": "120 pages, 13 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.06324v1",
    "published_date": "2024-04-09 14:03:04 UTC",
    "updated_date": "2024-04-09 14:03:04 UTC"
  },
  {
    "arxiv_id": "2404.06279v3",
    "title": "NoiseNCA: Noisy Seed Improves Spatio-Temporal Continuity of Neural Cellular Automata",
    "authors": [
      "Ehsan Pajouheshgar",
      "Yitao Xu",
      "Sabine Süsstrunk"
    ],
    "abstract": "Neural Cellular Automata (NCA) is a class of Cellular Automata where the\nupdate rule is parameterized by a neural network that can be trained using\ngradient descent. In this paper, we focus on NCA models used for texture\nsynthesis, where the update rule is inspired by partial differential equations\n(PDEs) describing reaction-diffusion systems. To train the NCA model, the\nspatio-temporal domain is discretized, and Euler integration is used to\nnumerically simulate the PDE. However, whether a trained NCA truly learns the\ncontinuous dynamic described by the corresponding PDE or merely overfits the\ndiscretization used in training remains an open question. We study NCA models\nat the limit where space-time discretization approaches continuity. We find\nthat existing NCA models tend to overfit the training discretization,\nespecially in the proximity of the initial condition, also called \"seed\". To\naddress this, we propose a solution that utilizes uniform noise as the initial\ncondition. We demonstrate the effectiveness of our approach in preserving the\nconsistency of NCA dynamics across a wide range of spatio-temporal\ngranularities. Our improved NCA model enables two new test-time interactions by\nallowing continuous control over the speed of pattern formation and the scale\nof the synthesized patterns. We demonstrate this new NCA feature in our\ninteractive online demo. Our work reveals that NCA models can learn continuous\ndynamics and opens new venues for NCA research from a dynamical system's\nperspective.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.MA"
    ],
    "primary_category": "cs.CV",
    "comment": "9 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.06279v3",
    "published_date": "2024-04-09 13:02:33 UTC",
    "updated_date": "2024-06-14 11:48:51 UTC"
  },
  {
    "arxiv_id": "2404.06278v1",
    "title": "Dimensionality Reduction in Sentence Transformer Vector Databases with Fast Fourier Transform",
    "authors": [
      "Vitaly Bulgakov",
      "Alec Segal"
    ],
    "abstract": "Dimensionality reduction in vector databases is pivotal for streamlining AI\ndata management, enabling efficient storage, faster computation, and improved\nmodel performance. This paper explores the benefits of reducing vector database\ndimensions, with a focus on computational efficiency and overcoming the curse\nof dimensionality. We introduce a novel application of Fast Fourier Transform\n(FFT) to dimensionality reduction, a method previously underexploited in this\ncontext. By demonstrating its utility across various AI domains, including\nRetrieval-Augmented Generation (RAG) models and image processing, this\nFFT-based approach promises to improve data retrieval processes and enhance the\nefficiency and scalability of AI solutions. The incorporation of FFT may not\nonly optimize operations in real-time processing and recommendation systems but\nalso extend to advanced image processing techniques, where dimensionality\nreduction can significantly improve performance and analysis efficiency. This\npaper advocates for the broader adoption of FFT in vector database management,\nmarking a significant stride towards addressing the challenges of data volume\nand complexity in AI research and applications. Unlike many existing\napproaches, we directly handle the embedding vectors produced by the model\nafter processing a test input.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.DB",
    "comment": "13 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.06278v1",
    "published_date": "2024-04-09 13:02:22 UTC",
    "updated_date": "2024-04-09 13:02:22 UTC"
  },
  {
    "arxiv_id": "2404.06267v1",
    "title": "PGTNet: A Process Graph Transformer Network for Remaining Time Prediction of Business Process Instances",
    "authors": [
      "Keyvan Amiri Elyasi",
      "Han van der Aa",
      "Heiner Stuckenschmidt"
    ],
    "abstract": "We present PGTNet, an approach that transforms event logs into graph datasets\nand leverages graph-oriented data for training Process Graph Transformer\nNetworks to predict the remaining time of business process instances. PGTNet\nconsistently outperforms state-of-the-art deep learning approaches across a\ndiverse range of 20 publicly available real-world event logs. Notably, our\napproach is most promising for highly complex processes, where existing deep\nlearning approaches encounter difficulties stemming from their limited ability\nto learn control-flow relationships among process activities and capture\nlong-range dependencies. PGTNet addresses these challenges, while also being\nable to consider multiple process perspectives during the learning process.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "16 pages, 4 figures, To be published in: Advanced Information Systems\n  Engineering - 36th International Conference, CAiSE 2024, Limassol, Cyprus,\n  June 03-07, 2024, Proceedings",
    "pdf_url": "http://arxiv.org/pdf/2404.06267v1",
    "published_date": "2024-04-09 12:45:17 UTC",
    "updated_date": "2024-04-09 12:45:17 UTC"
  },
  {
    "arxiv_id": "2404.06261v1",
    "title": "Playing to Vision Foundation Model's Strengths in Stereo Matching",
    "authors": [
      "Chuang-Wei Liu",
      "Qijun Chen",
      "Rui Fan"
    ],
    "abstract": "Stereo matching has become a key technique for 3D environment perception in\nintelligent vehicles. For a considerable time, convolutional neural networks\n(CNNs) have remained the mainstream choice for feature extraction in this\ndomain. Nonetheless, there is a growing consensus that the existing paradigm\nshould evolve towards vision foundation models (VFM), particularly those\ndeveloped based on vision Transformers (ViTs) and pre-trained through\nself-supervision on extensive, unlabeled datasets. While VFMs are adept at\nextracting informative, general-purpose visual features, specifically for dense\nprediction tasks, their performance often lacks in geometric vision tasks. This\nstudy serves as the first exploration of a viable approach for adapting VFMs to\nstereo matching. Our ViT adapter, referred to as ViTAS, is constructed upon\nthree types of modules: spatial differentiation, patch attention fusion, and\ncross-attention. The first module initializes feature pyramids, while the\nlatter two aggregate stereo and multi-scale contextual information into\nfine-grained features, respectively. ViTAStereo, which combines ViTAS with cost\nvolume-based stereo matching back-end processes, achieves the top rank on the\nKITTI Stereo 2012 dataset and outperforms the second-best network StereoBase by\napproximately 7.9% in terms of the percentage of error pixels, with a tolerance\nof 3 pixels. Additional experiments across diverse scenarios further\ndemonstrate its superior generalizability compared to all other\nstate-of-the-art approaches. We believe this new paradigm will pave the way for\nthe next generation of stereo matching networks.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.06261v1",
    "published_date": "2024-04-09 12:34:28 UTC",
    "updated_date": "2024-04-09 12:34:28 UTC"
  },
  {
    "arxiv_id": "2404.06246v1",
    "title": "GHNeRF: Learning Generalizable Human Features with Efficient Neural Radiance Fields",
    "authors": [
      "Arnab Dey",
      "Di Yang",
      "Rohith Agaram",
      "Antitza Dantcheva",
      "Andrew I. Comport",
      "Srinath Sridhar",
      "Jean Martinet"
    ],
    "abstract": "Recent advances in Neural Radiance Fields (NeRF) have demonstrated promising\nresults in 3D scene representations, including 3D human representations.\nHowever, these representations often lack crucial information on the underlying\nhuman pose and structure, which is crucial for AR/VR applications and games. In\nthis paper, we introduce a novel approach, termed GHNeRF, designed to address\nthese limitations by learning 2D/3D joint locations of human subjects with NeRF\nrepresentation. GHNeRF uses a pre-trained 2D encoder streamlined to extract\nessential human features from 2D images, which are then incorporated into the\nNeRF framework in order to encode human biomechanic features. This allows our\nnetwork to simultaneously learn biomechanic features, such as joint locations,\nalong with human geometry and texture. To assess the effectiveness of our\nmethod, we conduct a comprehensive comparison with state-of-the-art human NeRF\ntechniques and joint estimation algorithms. Our results show that GHNeRF can\nachieve state-of-the-art results in near real-time.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.06246v1",
    "published_date": "2024-04-09 12:11:25 UTC",
    "updated_date": "2024-04-09 12:11:25 UTC"
  },
  {
    "arxiv_id": "2404.06243v1",
    "title": "ActNetFormer: Transformer-ResNet Hybrid Method for Semi-Supervised Action Recognition in Videos",
    "authors": [
      "Sharana Dharshikgan Suresh Dass",
      "Hrishav Bakul Barua",
      "Ganesh Krishnasamy",
      "Raveendran Paramesran",
      "Raphael C. -W. Phan"
    ],
    "abstract": "Human action or activity recognition in videos is a fundamental task in\ncomputer vision with applications in surveillance and monitoring, self-driving\ncars, sports analytics, human-robot interaction and many more. Traditional\nsupervised methods require large annotated datasets for training, which are\nexpensive and time-consuming to acquire. This work proposes a novel approach\nusing Cross-Architecture Pseudo-Labeling with contrastive learning for\nsemi-supervised action recognition. Our framework leverages both labeled and\nunlabelled data to robustly learn action representations in videos, combining\npseudo-labeling with contrastive learning for effective learning from both\ntypes of samples. We introduce a novel cross-architecture approach where 3D\nConvolutional Neural Networks (3D CNNs) and video transformers (VIT) are\nutilised to capture different aspects of action representations; hence we call\nit ActNetFormer. The 3D CNNs excel at capturing spatial features and local\ndependencies in the temporal domain, while VIT excels at capturing long-range\ndependencies across frames. By integrating these complementary architectures\nwithin the ActNetFormer framework, our approach can effectively capture both\nlocal and global contextual information of an action. This comprehensive\nrepresentation learning enables the model to achieve better performance in\nsemi-supervised action recognition tasks by leveraging the strengths of each of\nthese architectures. Experimental results on standard action recognition\ndatasets demonstrate that our approach performs better than the existing\nmethods, achieving state-of-the-art performance with only a fraction of labeled\ndata. The official website of this work is available at:\nhttps://github.com/rana2149/ActNetFormer.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC",
      "cs.LG",
      "cs.MM",
      "Artificial intelligence, Computer vision, Machine learning, Deep\n  learning, Human-computer Interaction",
      "I.2; I.2.9; I.2.10; I.3.3; I.4.5"
    ],
    "primary_category": "cs.CV",
    "comment": "Submitted for peer review",
    "pdf_url": "http://arxiv.org/pdf/2404.06243v1",
    "published_date": "2024-04-09 12:09:56 UTC",
    "updated_date": "2024-04-09 12:09:56 UTC"
  },
  {
    "arxiv_id": "2404.16048v2",
    "title": "GUIDE: Graphical User Interface Data for Execution",
    "authors": [
      "Rajat Chawla",
      "Adarsh Jha",
      "Muskaan Kumar",
      "Mukunda NS",
      "Ishaan Bhola"
    ],
    "abstract": "In this paper, we introduce GUIDE, a novel dataset tailored for the\nadvancement of Multimodal Large Language Model (MLLM) applications,\nparticularly focusing on Robotic Process Automation (RPA) use cases. Our\ndataset encompasses diverse data from various websites including\nApollo(62.67\\%), Gmail(3.43\\%), Calendar(10.98\\%) and Canva(22.92\\%). Each data\nentry includes an image, a task description, the last action taken, CoT and the\nnext action to be performed along with grounding information of where the\naction needs to be executed. The data is collected using our in-house advanced\nannotation tool NEXTAG (Next Action Grounding and Annotation Tool). The data is\nadapted for multiple OS, browsers and display types. It is collected by\nmultiple annotators to capture the variation of design and the way person uses\na website.\n  Through this dataset, we aim to facilitate research and development in the\nrealm of LLMs for graphical user interfaces, particularly in tasks related to\nRPA. The dataset's multi-platform nature and coverage of diverse websites\nenable the exploration of cross-interface capabilities in automation tasks. We\nbelieve that our dataset will serve as a valuable resource for advancing the\ncapabilities of multi-platform LLMs in practical applications, fostering\ninnovation in the field of automation and natural language understanding. Using\nGUIDE, we build V-Zen, the first RPA model to automate multiple websites using\nour in-House Automation tool AUTONODE",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "11 pages, 8 figures, 3 Tables and 1 Algorithm",
    "pdf_url": "http://arxiv.org/pdf/2404.16048v2",
    "published_date": "2024-04-09 11:59:41 UTC",
    "updated_date": "2024-10-27 05:54:50 UTC"
  },
  {
    "arxiv_id": "2404.08006v1",
    "title": "Learning Efficient and Fair Policies for Uncertainty-Aware Collaborative Human-Robot Order Picking",
    "authors": [
      "Igor G. Smit",
      "Zaharah Bukhsh",
      "Mykola Pechenizkiy",
      "Kostas Alogariastos",
      "Kasper Hendriks",
      "Yingqian Zhang"
    ],
    "abstract": "In collaborative human-robot order picking systems, human pickers and\nAutonomous Mobile Robots (AMRs) travel independently through a warehouse and\nmeet at pick locations where pickers load items onto the AMRs. In this paper,\nwe consider an optimization problem in such systems where we allocate pickers\nto AMRs in a stochastic environment. We propose a novel multi-objective Deep\nReinforcement Learning (DRL) approach to learn effective allocation policies to\nmaximize pick efficiency while also aiming to improve workload fairness amongst\nhuman pickers. In our approach, we model the warehouse states using a graph,\nand define a neural network architecture that captures regional information and\neffectively extracts representations related to efficiency and workload. We\ndevelop a discrete-event simulation model, which we use to train and evaluate\nthe proposed DRL approach. In the experiments, we demonstrate that our approach\ncan find non-dominated policy sets that outline good trade-offs between\nfairness and efficiency objectives. The trained policies outperform the\nbenchmarks in terms of both efficiency and fairness. Moreover, they show good\ntransferability properties when tested on scenarios with different warehouse\nsizes. The implementation of the simulation model, proposed approach, and\nexperiments are published.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "math.OC"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.08006v1",
    "published_date": "2024-04-09 11:45:16 UTC",
    "updated_date": "2024-04-09 11:45:16 UTC"
  },
  {
    "arxiv_id": "2404.06229v2",
    "title": "Autonomous Driving Small-Scale Cars: A Survey of Recent Development",
    "authors": [
      "Dianzhao Li",
      "Paul Auerbach",
      "Ostap Okhrin"
    ],
    "abstract": "While engaging with the unfolding revolution in autonomous driving, a\nchallenge presents itself, how can we effectively raise awareness within\nsociety about this transformative trend? While full-scale autonomous driving\nvehicles often come with a hefty price tag, the emergence of small-scale car\nplatforms offers a compelling alternative. These platforms not only serve as\nvaluable educational tools for the broader public and young generations but\nalso function as robust research platforms, contributing significantly to the\nongoing advancements in autonomous driving technology. This survey outlines\nvarious small-scale car platforms, categorizing them and detailing the research\nadvancements accomplished through their usage. The conclusion provides\nproposals for promising future directions in the field.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.06229v2",
    "published_date": "2024-04-09 11:40:37 UTC",
    "updated_date": "2024-12-20 16:10:32 UTC"
  },
  {
    "arxiv_id": "2404.06224v1",
    "title": "Low-Cost Generation and Evaluation of Dictionary Example Sentences",
    "authors": [
      "Bill Cai",
      "Clarence Boon Liang Ng",
      "Daniel Tan",
      "Shelvia Hotama"
    ],
    "abstract": "Dictionary example sentences play an important role in illustrating word\ndefinitions and usage, but manually creating quality sentences is challenging.\nPrior works have demonstrated that language models can be trained to generate\nexample sentences. However, they relied on costly customized models and word\nsense datasets for generation and evaluation of their work. Rapid advancements\nin foundational models present the opportunity to create low-cost, zero-shot\nmethods for the generation and evaluation of dictionary example sentences. We\nintroduce a new automatic evaluation metric called OxfordEval that measures the\nwin-rate of generated sentences against existing Oxford Dictionary sentences.\nOxfordEval shows high alignment with human judgments, enabling large-scale\nautomated quality evaluation. We experiment with various LLMs and\nconfigurations to generate dictionary sentences across word classes. We\ncomplement this with a novel approach of using masked language models to\nidentify and select sentences that best exemplify word meaning. The eventual\nmodel, FM-MLM, achieves over 85.1% win rate against Oxford baseline sentences\naccording to OxfordEval, compared to 39.8% win rate for prior model-generated\nsentences.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.06224v1",
    "published_date": "2024-04-09 11:26:59 UTC",
    "updated_date": "2024-04-09 11:26:59 UTC"
  },
  {
    "arxiv_id": "2404.07239v1",
    "title": "Advancements in Radiomics and Artificial Intelligence for Thyroid Cancer Diagnosis",
    "authors": [
      "Milad Yousefi",
      "Shadi Farabi Maleki",
      "Ali Jafarizadeh",
      "Mahya Ahmadpour Youshanlui",
      "Aida Jafari",
      "Siamak Pedrammehr",
      "Roohallah Alizadehsani",
      "Ryszard Tadeusiewicz",
      "Pawel Plawiak"
    ],
    "abstract": "Thyroid cancer is an increasing global health concern that requires advanced\ndiagnostic methods. The application of AI and radiomics to thyroid cancer\ndiagnosis is examined in this review. A review of multiple databases was\nconducted in compliance with PRISMA guidelines until October 2023. A\ncombination of keywords led to the discovery of an English academic publication\non thyroid cancer and related subjects. 267 papers were returned from the\noriginal search after 109 duplicates were removed. Relevant studies were\nselected according to predetermined criteria after 124 articles were eliminated\nbased on an examination of their abstract and title. After the comprehensive\nanalysis, an additional six studies were excluded. Among the 28 included\nstudies, radiomics analysis, which incorporates ultrasound (US) images,\ndemonstrated its effectiveness in diagnosing thyroid cancer. Various results\nwere noted, some of the studies presenting new strategies that outperformed the\nstatus quo. The literature has emphasized various challenges faced by AI\nmodels, including interpretability issues, dataset constraints, and operator\ndependence. The synthesized findings of the 28 included studies mentioned the\nneed for standardization efforts and prospective multicenter studies to address\nthese concerns. Furthermore, approaches to overcome these obstacles were\nidentified, such as advances in explainable AI technology and personalized\nmedicine techniques. The review focuses on how AI and radiomics could transform\nthe diagnosis and treatment of thyroid cancer. Despite challenges, future\nresearch on multidisciplinary cooperation, clinical applicability validation,\nand algorithm improvement holds the potential to improve patient outcomes and\ndiagnostic precision in the treatment of thyroid cancer.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "eess.IV",
      "J.3.2; J.3.3"
    ],
    "primary_category": "q-bio.QM",
    "comment": "50 pages, 8 figures, 1 table, 119 references",
    "pdf_url": "http://arxiv.org/pdf/2404.07239v1",
    "published_date": "2024-04-09 11:05:20 UTC",
    "updated_date": "2024-04-09 11:05:20 UTC"
  },
  {
    "arxiv_id": "2404.06212v1",
    "title": "OmniFusion Technical Report",
    "authors": [
      "Elizaveta Goncharova",
      "Anton Razzhigaev",
      "Matvey Mikhalchuk",
      "Maxim Kurkin",
      "Irina Abdullaeva",
      "Matvey Skripkin",
      "Ivan Oseledets",
      "Denis Dimitrov",
      "Andrey Kuznetsov"
    ],
    "abstract": "Last year, multimodal architectures served up a revolution in AI-based\napproaches and solutions, extending the capabilities of large language models\n(LLM). We propose an \\textit{OmniFusion} model based on a pretrained LLM and\nadapters for visual modality. We evaluated and compared several architecture\ndesign principles for better text and visual data coupling: MLP and transformer\nadapters, various CLIP ViT-based encoders (SigLIP, InternVIT, etc.), and their\nfusing approach, image encoding method (whole image or tiles encoding) and two\n7B LLMs (the proprietary one and open-source Mistral). Experiments on 8\nvisual-language benchmarks show the top score for the best OmniFusion setup in\nterms of different VQA tasks in comparison with open-source LLaVA-like\nsolutions: VizWiz, Pope, MM-Vet, ScienceQA, MMBench, TextVQA, VQAv2, MMMU. We\nalso propose a variety of situations, where OmniFusion provides highly-detailed\nanswers in different domains: housekeeping, sightseeing, culture, medicine,\nhandwritten and scanned equations recognition, etc. Mistral-based OmniFusion\nmodel is an open-source solution with weights, training and inference scripts\navailable at https://github.com/AIRI-Institute/OmniFusion.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "6804, 68T50 (Primary)",
      "I.2.7; I.2.10; I.4.9"
    ],
    "primary_category": "cs.CV",
    "comment": "17 pages, 4 figures, 9 tables, 2 appendices",
    "pdf_url": "http://arxiv.org/pdf/2404.06212v1",
    "published_date": "2024-04-09 11:00:19 UTC",
    "updated_date": "2024-04-09 11:00:19 UTC"
  },
  {
    "arxiv_id": "2404.06209v3",
    "title": "Elephants Never Forget: Memorization and Learning of Tabular Data in Large Language Models",
    "authors": [
      "Sebastian Bordt",
      "Harsha Nori",
      "Vanessa Rodrigues",
      "Besmira Nushi",
      "Rich Caruana"
    ],
    "abstract": "While many have shown how Large Language Models (LLMs) can be applied to a\ndiverse set of tasks, the critical issues of data contamination and\nmemorization are often glossed over. In this work, we address this concern for\ntabular data. Specifically, we introduce a variety of different techniques to\nassess whether a language model has seen a tabular dataset during training.\nThis investigation reveals that LLMs have memorized many popular tabular\ndatasets verbatim. We then compare the few-shot learning performance of LLMs on\ndatasets that were seen during training to the performance on datasets released\nafter training. We find that LLMs perform better on datasets seen during\ntraining, indicating that memorization leads to overfitting. At the same time,\nLLMs show non-trivial performance on novel datasets and are surprisingly robust\nto data transformations. We then investigate the in-context statistical\nlearning abilities of LLMs. While LLMs are significantly better than random at\nsolving statistical classification problems, the sample efficiency of few-shot\nlearning lags behind traditional statistical learning algorithms, especially as\nthe dimension of the problem increases. This suggests that much of the observed\nfew-shot performance on novel real-world datasets is due to the LLM's world\nknowledge. Overall, our results highlight the importance of testing whether an\nLLM has seen an evaluation dataset during pre-training. We release the\nhttps://github.com/interpretml/LLM-Tabular-Memorization-Checker Python package\nto test LLMs for memorization of tabular datasets.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "COLM camera ready, fix typo",
    "pdf_url": "http://arxiv.org/pdf/2404.06209v3",
    "published_date": "2024-04-09 10:58:21 UTC",
    "updated_date": "2024-12-04 10:33:18 UTC"
  },
  {
    "arxiv_id": "2404.15189v1",
    "title": "Text2Grasp: Grasp synthesis by text prompts of object grasping parts",
    "authors": [
      "Xiaoyun Chang",
      "Yi Sun"
    ],
    "abstract": "The hand plays a pivotal role in human ability to grasp and manipulate\nobjects and controllable grasp synthesis is the key for successfully performing\ndownstream tasks. Existing methods that use human intention or task-level\nlanguage as control signals for grasping inherently face ambiguity. To address\nthis challenge, we propose a grasp synthesis method guided by text prompts of\nobject grasping parts, Text2Grasp, which provides more precise control.\nSpecifically, we present a two-stage method that includes a text-guided\ndiffusion model TextGraspDiff to first generate a coarse grasp pose, then apply\na hand-object contact optimization process to ensure both plausibility and\ndiversity. Furthermore, by leveraging Large Language Model, our method\nfacilitates grasp synthesis guided by task-level and personalized text\ndescriptions without additional manual annotations. Extensive experiments\ndemonstrate that our method achieves not only accurate part-level grasp control\nbut also comparable performance in grasp quality.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.15189v1",
    "published_date": "2024-04-09 10:57:27 UTC",
    "updated_date": "2024-04-09 10:57:27 UTC"
  },
  {
    "arxiv_id": "2404.06201v1",
    "title": "Open-Source AI-based SE Tools: Opportunities and Challenges of Collaborative Software Learning",
    "authors": [
      "Zhihao Lin",
      "Wei Ma",
      "Tao Lin",
      "Yaowen Zheng",
      "Jingquan Ge",
      "Jun Wang",
      "Jacques Klein",
      "Tegawende Bissyande",
      "Yang Liu",
      "Li Li"
    ],
    "abstract": "Large Language Models (LLMs) have become instrumental in advancing software\nengineering (SE) tasks, showcasing their efficacy in code understanding and\nbeyond. Like traditional SE tools, open-source collaboration is key in\nrealising the excellent products. However, with AI models, the essential need\nis in data. The collaboration of these AI-based SE models hinges on maximising\nthe sources of high-quality data. However, data especially of high quality,\noften holds commercial or sensitive value, making it less accessible for\nopen-source AI-based SE projects. This reality presents a significant barrier\nto the development and enhancement of AI-based SE tools within the software\nengineering community. Therefore, researchers need to find solutions for\nenabling open-source AI-based SE models to tap into resources by different\norganisations. Addressing this challenge, our position paper investigates one\nsolution to facilitate access to diverse organizational resources for\nopen-source AI models, ensuring privacy and commercial sensitivities are\nrespected. We introduce a governance framework centered on federated learning\n(FL), designed to foster the joint development and maintenance of open-source\nAI code models while safeguarding data privacy and security. Additionally, we\npresent guidelines for developers on AI-based SE tool collaboration, covering\ndata requirements, model architecture, updating strategies, and version\ncontrol. Given the significant influence of data characteristics on FL, our\nresearch examines the effect of code data heterogeneity on FL performance.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.06201v1",
    "published_date": "2024-04-09 10:47:02 UTC",
    "updated_date": "2024-04-09 10:47:02 UTC"
  },
  {
    "arxiv_id": "2404.06188v1",
    "title": "Diverse Randomized Value Functions: A Provably Pessimistic Approach for Offline Reinforcement Learning",
    "authors": [
      "Xudong Yu",
      "Chenjia Bai",
      "Hongyi Guo",
      "Changhong Wang",
      "Zhen Wang"
    ],
    "abstract": "Offline Reinforcement Learning (RL) faces distributional shift and unreliable\nvalue estimation, especially for out-of-distribution (OOD) actions. To address\nthis, existing uncertainty-based methods penalize the value function with\nuncertainty quantification and demand numerous ensemble networks, posing\ncomputational challenges and suboptimal outcomes. In this paper, we introduce a\nnovel strategy employing diverse randomized value functions to estimate the\nposterior distribution of $Q$-values. It provides robust uncertainty\nquantification and estimates lower confidence bounds (LCB) of $Q$-values. By\napplying moderate value penalties for OOD actions, our method fosters a\nprovably pessimistic approach. We also emphasize on diversity within randomized\nvalue functions and enhance efficiency by introducing a diversity\nregularization method, reducing the requisite number of networks. These modules\nlead to reliable value estimation and efficient policy learning from offline\ndata. Theoretical analysis shows that our method recovers the provably\nefficient LCB-penalty under linear MDP assumptions. Extensive empirical results\nalso demonstrate that our proposed method significantly outperforms baseline\nmethods in terms of performance and parametric efficiency.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.06188v1",
    "published_date": "2024-04-09 10:15:18 UTC",
    "updated_date": "2024-04-09 10:15:18 UTC"
  },
  {
    "arxiv_id": "2404.06186v1",
    "title": "Clue-Instruct: Text-Based Clue Generation for Educational Crossword Puzzles",
    "authors": [
      "Andrea Zugarini",
      "Kamyar Zeinalipour",
      "Surya Sai Kadali",
      "Marco Maggini",
      "Marco Gori",
      "Leonardo Rigutini"
    ],
    "abstract": "Crossword puzzles are popular linguistic games often used as tools to engage\nstudents in learning. Educational crosswords are characterized by less cryptic\nand more factual clues that distinguish them from traditional crossword\npuzzles. Despite there exist several publicly available clue-answer pair\ndatabases for traditional crosswords, educational clue-answer pairs datasets\nare missing. In this article, we propose a methodology to build educational\nclue generation datasets that can be used to instruct Large Language Models\n(LLMs). By gathering from Wikipedia pages informative content associated with\nrelevant keywords, we use Large Language Models to automatically generate\npedagogical clues related to the given input keyword and its context. With such\nan approach, we created clue-instruct, a dataset containing 44,075 unique\nexamples with text-keyword pairs associated with three distinct crossword\nclues. We used clue-instruct to instruct different LLMs to generate educational\nclues from a given input content and keyword. Both human and automatic\nevaluations confirmed the quality of the generated clues, thus validating the\neffectiveness of our approach.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.06186v1",
    "published_date": "2024-04-09 10:12:34 UTC",
    "updated_date": "2024-04-09 10:12:34 UTC"
  },
  {
    "arxiv_id": "2404.06181v1",
    "title": "EPL: Evidential Prototype Learning for Semi-supervised Medical Image Segmentation",
    "authors": [
      "Yuanpeng He"
    ],
    "abstract": "Although current semi-supervised medical segmentation methods can achieve\ndecent performance, they are still affected by the uncertainty in unlabeled\ndata and model predictions, and there is currently a lack of effective\nstrategies that can explore the uncertain aspects of both simultaneously. To\naddress the aforementioned issues, we propose Evidential Prototype Learning\n(EPL), which utilizes an extended probabilistic framework to effectively fuse\nvoxel probability predictions from different sources and achieves prototype\nfusion utilization of labeled and unlabeled data under a generalized evidential\nframework, leveraging voxel-level dual uncertainty masking. The uncertainty not\nonly enables the model to self-correct predictions but also improves the guided\nlearning process with pseudo-labels and is able to feed back into the\nconstruction of hidden features. The method proposed in this paper has been\nexperimented on LA, Pancreas-CT and TBAD datasets, achieving the\nstate-of-the-art performance in three different labeled ratios, which strongly\ndemonstrates the effectiveness of our strategy.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.06181v1",
    "published_date": "2024-04-09 10:04:06 UTC",
    "updated_date": "2024-04-09 10:04:06 UTC"
  },
  {
    "arxiv_id": "2404.06177v2",
    "title": "Uncertainty-aware Evidential Fusion-based Learning for Semi-supervised Medical Image Segmentation",
    "authors": [
      "Yuanpeng He",
      "Lijian Li"
    ],
    "abstract": "Although the existing uncertainty-based semi-supervised medical segmentation\nmethods have achieved excellent performance, they usually only consider a\nsingle uncertainty evaluation, which often fails to solve the problem related\nto credibility completely. Therefore, based on the framework of evidential deep\nlearning, this paper integrates the evidential predictive results in the\ncross-region of mixed and original samples to reallocate the confidence degree\nand uncertainty measure of each voxel, which is realized by emphasizing\nuncertain information of probability assignments fusion rule of traditional\nevidence theory. Furthermore, we design a voxel-level asymptotic learning\nstrategy by introducing information entropy to combine with the fused\nuncertainty measure to estimate voxel prediction more precisely. The model will\ngradually pay attention to the prediction results with high uncertainty in the\nlearning process, to learn the features that are difficult to master. The\nexperimental results on LA, Pancreas-CT, ACDC and TBAD datasets demonstrate the\nsuperior performance of our proposed method in comparison with the existing\nstate of the arts.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.06177v2",
    "published_date": "2024-04-09 09:58:10 UTC",
    "updated_date": "2024-04-11 15:57:52 UTC"
  },
  {
    "arxiv_id": "2404.06170v1",
    "title": "CLIP-Embed-KD: Computationally Efficient Knowledge Distillation Using Embeddings as Teachers",
    "authors": [
      "Lakshmi Nair"
    ],
    "abstract": "Contrastive Language-Image Pre-training (CLIP) has been shown to improve\nzero-shot generalization capabilities of language and vision models. In this\npaper, we extend CLIP for efficient knowledge distillation, by utilizing\nembeddings as teachers. Typical knowledge distillation frameworks require\nrunning forward passes through a teacher model, which is often prohibitive in\nthe case of billion or trillion parameter teachers. In these cases, using only\nthe embeddings of the teacher models to guide the distillation can yield\nsignificant computational savings. Our preliminary findings show that\nCLIP-based knowledge distillation with embeddings can outperform full scale\nknowledge distillation using $9\\times$ less memory and $8\\times$ less training\ntime. Code available at: https://github.com/lnairGT/CLIP-Distillation/",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Short paper - 5 pages; 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.06170v1",
    "published_date": "2024-04-09 09:49:57 UTC",
    "updated_date": "2024-04-09 09:49:57 UTC"
  },
  {
    "arxiv_id": "2404.06167v1",
    "title": "scCDCG: Efficient Deep Structural Clustering for single-cell RNA-seq via Deep Cut-informed Graph Embedding",
    "authors": [
      "Ping Xu",
      "Zhiyuan Ning",
      "Meng Xiao",
      "Guihai Feng",
      "Xin Li",
      "Yuanchun Zhou",
      "Pengfei Wang"
    ],
    "abstract": "Single-cell RNA sequencing (scRNA-seq) is essential for unraveling cellular\nheterogeneity and diversity, offering invaluable insights for bioinformatics\nadvancements. Despite its potential, traditional clustering methods in\nscRNA-seq data analysis often neglect the structural information embedded in\ngene expression profiles, crucial for understanding cellular correlations and\ndependencies. Existing strategies, including graph neural networks, face\nchallenges in handling the inefficiency due to scRNA-seq data's intrinsic\nhigh-dimension and high-sparsity. Addressing these limitations, we introduce\nscCDCG (single-cell RNA-seq Clustering via Deep Cut-informed Graph), a novel\nframework designed for efficient and accurate clustering of scRNA-seq data that\nsimultaneously utilizes intercellular high-order structural information. scCDCG\ncomprises three main components: (i) A graph embedding module utilizing deep\ncut-informed techniques, which effectively captures intercellular high-order\nstructural information, overcoming the over-smoothing and inefficiency issues\nprevalent in prior graph neural network methods. (ii) A self-supervised\nlearning module guided by optimal transport, tailored to accommodate the unique\ncomplexities of scRNA-seq data, specifically its high-dimension and\nhigh-sparsity. (iii) An autoencoder-based feature learning module that\nsimplifies model complexity through effective dimension reduction and feature\nextraction. Our extensive experiments on 6 datasets demonstrate scCDCG's\nsuperior performance and efficiency compared to 7 established models,\nunderscoring scCDCG's potential as a transformative tool in scRNA-seq data\nanalysis. Our code is available at: https://github.com/XPgogogo/scCDCG.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.GN"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted as a long paper for the research track at DASFAA 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.06167v1",
    "published_date": "2024-04-09 09:46:17 UTC",
    "updated_date": "2024-04-09 09:46:17 UTC"
  },
  {
    "arxiv_id": "2404.06162v3",
    "title": "Characterizing Multimodal Long-form Summarization: A Case Study on Financial Reports",
    "authors": [
      "Tianyu Cao",
      "Natraj Raman",
      "Danial Dervovic",
      "Chenhao Tan"
    ],
    "abstract": "As large language models (LLMs) expand the power of natural language\nprocessing to handle long inputs, rigorous and systematic analyses are\nnecessary to understand their abilities and behavior. A salient application is\nsummarization, due to its ubiquity and controversy (e.g., researchers have\ndeclared the death of summarization). In this paper, we use financial report\nsummarization as a case study because financial reports are not only long but\nalso use numbers and tables extensively. We propose a computational framework\nfor characterizing multimodal long-form summarization and investigate the\nbehavior of Claude 2.0/2.1, GPT-4/3.5, and Cohere. We find that GPT-3.5 and\nCohere fail to perform this summarization task meaningfully. For Claude 2 and\nGPT-4, we analyze the extractiveness of the summary and identify a position\nbias in LLMs. This position bias disappears after shuffling the input for\nClaude, which suggests that Claude seems to recognize important information. We\nalso conduct a comprehensive investigation on the use of numeric data in\nLLM-generated summaries and offer a taxonomy of numeric hallucination. We\nemploy prompt engineering to improve GPT-4's use of numbers with limited\nsuccess. Overall, our analyses highlight the strong capability of Claude 2 in\nhandling long multimodal inputs compared to GPT-4. The generated summaries and\nevaluation code are available at\nhttps://github.com/ChicagoHAI/characterizing-multimodal-long-form-summarization.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.06162v3",
    "published_date": "2024-04-09 09:34:25 UTC",
    "updated_date": "2024-08-15 13:59:08 UTC"
  },
  {
    "arxiv_id": "2404.06152v1",
    "title": "HFNeRF: Learning Human Biomechanic Features with Neural Radiance Fields",
    "authors": [
      "Arnab Dey",
      "Di Yang",
      "Antitza Dantcheva",
      "Jean Martinet"
    ],
    "abstract": "In recent advancements in novel view synthesis, generalizable Neural Radiance\nFields (NeRF) based methods applied to human subjects have shown remarkable\nresults in generating novel views from few images. However, this generalization\nability cannot capture the underlying structural features of the skeleton\nshared across all instances. Building upon this, we introduce HFNeRF: a novel\ngeneralizable human feature NeRF aimed at generating human biomechanic features\nusing a pre-trained image encoder. While previous human NeRF methods have shown\npromising results in the generation of photorealistic virtual avatars, such\nmethods lack underlying human structure or biomechanic features such as\nskeleton or joint information that are crucial for downstream applications\nincluding Augmented Reality (AR)/Virtual Reality (VR). HFNeRF leverages 2D\npre-trained foundation models toward learning human features in 3D using neural\nrendering, and then volume rendering towards generating 2D feature maps. We\nevaluate HFNeRF in the skeleton estimation task by predicting heatmaps as\nfeatures. The proposed method is fully differentiable, allowing to successfully\nlearn color, geometry, and human skeleton in a simultaneous manner. This paper\npresents preliminary results of HFNeRF, illustrating its potential in\ngenerating realistic virtual avatars with biomechanic features using NeRF.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.06152v1",
    "published_date": "2024-04-09 09:23:04 UTC",
    "updated_date": "2024-04-09 09:23:04 UTC"
  },
  {
    "arxiv_id": "2404.06144v1",
    "title": "Differential Privacy for Anomaly Detection: Analyzing the Trade-off Between Privacy and Explainability",
    "authors": [
      "Fatima Ezzeddine",
      "Mirna Saad",
      "Omran Ayoub",
      "Davide Andreoletti",
      "Martin Gjoreski",
      "Ihab Sbeity",
      "Marc Langheinrich",
      "Silvia Giordano"
    ],
    "abstract": "Anomaly detection (AD), also referred to as outlier detection, is a\nstatistical process aimed at identifying observations within a dataset that\nsignificantly deviate from the expected pattern of the majority of the data.\nSuch a process finds wide application in various fields, such as finance and\nhealthcare. While the primary objective of AD is to yield high detection\naccuracy, the requirements of explainability and privacy are also paramount.\nThe first ensures the transparency of the AD process, while the second\nguarantees that no sensitive information is leaked to untrusted parties. In\nthis work, we exploit the trade-off of applying Explainable AI (XAI) through\nSHapley Additive exPlanations (SHAP) and differential privacy (DP). We perform\nAD with different models and on various datasets, and we thoroughly evaluate\nthe cost of privacy in terms of decreased accuracy and explainability. Our\nresults show that the enforcement of privacy through DP has a significant\nimpact on detection accuracy and explainability, which depends on both the\ndataset and the considered AD model. We further show that the visual\ninterpretation of explanations is also influenced by the choice of the AD\nalgorithm.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.06144v1",
    "published_date": "2024-04-09 09:09:36 UTC",
    "updated_date": "2024-04-09 09:09:36 UTC"
  },
  {
    "arxiv_id": "2404.06137v1",
    "title": "SmurfCat at SemEval-2024 Task 6: Leveraging Synthetic Data for Hallucination Detection",
    "authors": [
      "Elisei Rykov",
      "Yana Shishkina",
      "Kseniia Petrushina",
      "Kseniia Titova",
      "Sergey Petrakov",
      "Alexander Panchenko"
    ],
    "abstract": "In this paper, we present our novel systems developed for the SemEval-2024\nhallucination detection task. Our investigation spans a range of strategies to\ncompare model predictions with reference standards, encompassing diverse\nbaselines, the refinement of pre-trained encoders through supervised learning,\nand an ensemble approaches utilizing several high-performing models. Through\nthese explorations, we introduce three distinct methods that exhibit strong\nperformance metrics. To amplify our training data, we generate additional\ntraining samples from unlabelled training subset. Furthermore, we provide a\ndetailed comparative analysis of our approaches. Notably, our premier method\nachieved a commendable 9th place in the competition's model-agnostic track and\n17th place in model-aware track, highlighting its effectiveness and potential.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "12 pages, 10 tables, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.06137v1",
    "published_date": "2024-04-09 09:03:44 UTC",
    "updated_date": "2024-04-09 09:03:44 UTC"
  },
  {
    "arxiv_id": "2404.06127v1",
    "title": "FLEX: FLEXible Federated Learning Framework",
    "authors": [
      "Francisco Herrera",
      "Daniel Jiménez-López",
      "Alberto Argente-Garrido",
      "Nuria Rodríguez-Barroso",
      "Cristina Zuheros",
      "Ignacio Aguilera-Martos",
      "Beatriz Bello",
      "Mario García-Márquez",
      "M. Victoria Luzón"
    ],
    "abstract": "In the realm of Artificial Intelligence (AI), the need for privacy and\nsecurity in data processing has become paramount. As AI applications continue\nto expand, the collection and handling of sensitive data raise concerns about\nindividual privacy protection. Federated Learning (FL) emerges as a promising\nsolution to address these challenges by enabling decentralized model training\non local devices, thus preserving data privacy. This paper introduces FLEX: a\nFLEXible Federated Learning Framework designed to provide maximum flexibility\nin FL research experiments. By offering customizable features for data\ndistribution, privacy parameters, and communication strategies, FLEX empowers\nresearchers to innovate and develop novel FL techniques. The framework also\nincludes libraries for specific FL implementations including: (1) anomalies,\n(2) blockchain, (3) adversarial attacks and defences, (4) natural language\nprocessing and (5) decision trees, enhancing its versatility and applicability\nin various domains. Overall, FLEX represents a significant advancement in FL\nresearch, facilitating the development of robust and efficient FL applications.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Submitted to Information Fusion",
    "pdf_url": "http://arxiv.org/pdf/2404.06127v1",
    "published_date": "2024-04-09 08:51:05 UTC",
    "updated_date": "2024-04-09 08:51:05 UTC"
  },
  {
    "arxiv_id": "2404.06124v3",
    "title": "Hierarchical Insights: Exploiting Structural Similarities for Reliable 3D Semantic Segmentation",
    "authors": [
      "Mariella Dreissig",
      "Simon Ruehle",
      "Florian Piewak",
      "Joschka Boedecker"
    ],
    "abstract": "Safety-critical applications such as autonomous driving require robust 3D\nenvironment perception algorithms capable of handling diverse and ambiguous\nsurroundings. The predictive performance of classification models is heavily\ninfluenced by the dataset and the prior knowledge provided by the annotated\nlabels. While labels guide the learning process, they often fail to capture the\ninherent relationships between classes that are naturally understood by humans.\nWe propose a training strategy for a 3D LiDAR semantic segmentation model that\nlearns structural relationships between classes through abstraction. This is\nachieved by implicitly modeling these relationships using a learning rule for\nhierarchical multi-label classification (HMC). Our detailed analysis\ndemonstrates that this training strategy not only improves the model's\nconfidence calibration but also retains additional information useful for\ndownstream tasks such as fusion, prediction, and planning.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.06124v3",
    "published_date": "2024-04-09 08:49:01 UTC",
    "updated_date": "2024-07-31 07:32:55 UTC"
  },
  {
    "arxiv_id": "2404.06114v1",
    "title": "Communication-Efficient Large-Scale Distributed Deep Learning: A Comprehensive Survey",
    "authors": [
      "Feng Liang",
      "Zhen Zhang",
      "Haifeng Lu",
      "Victor C. M. Leung",
      "Yanyi Guo",
      "Xiping Hu"
    ],
    "abstract": "With the rapid growth in the volume of data sets, models, and devices in the\ndomain of deep learning, there is increasing attention on large-scale\ndistributed deep learning. In contrast to traditional distributed deep\nlearning, the large-scale scenario poses new challenges that include fault\ntolerance, scalability of algorithms and infrastructures, and heterogeneity in\ndata sets, models, and resources. Due to intensive synchronization of models\nand sharing of data across GPUs and computing nodes during distributed training\nand inference processes, communication efficiency becomes the bottleneck for\nachieving high performance at a large scale. This article surveys the\nliterature over the period of 2018-2023 on algorithms and technologies aimed at\nachieving efficient communication in large-scale distributed deep learning at\nvarious levels, including algorithms, frameworks, and infrastructures.\nSpecifically, we first introduce efficient algorithms for model synchronization\nand communication data compression in the context of large-scale distributed\ntraining. Next, we introduce efficient strategies related to resource\nallocation and task scheduling for use in distributed training and inference.\nAfter that, we present the latest technologies pertaining to modern\ncommunication infrastructures used in distributed deep learning with a focus on\nexamining the impact of the communication overhead in a large-scale and\nheterogeneous setting. Finally, we conduct a case study on the distributed\ntraining of large language models at a large scale to illustrate how to apply\nthese technologies in real cases. This article aims to offer researchers a\ncomprehensive understanding of the current landscape of large-scale distributed\ndeep learning and to reveal promising future research directions toward\ncommunication-efficient solutions in this scope.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.06114v1",
    "published_date": "2024-04-09 08:35:04 UTC",
    "updated_date": "2024-04-09 08:35:04 UTC"
  },
  {
    "arxiv_id": "2404.08687v1",
    "title": "A Survey of Reasoning for Substitution Relationships: Definitions, Methods, and Directions",
    "authors": [
      "Anxin Yang",
      "Zhijuan Du",
      "Tao Sun"
    ],
    "abstract": "Substitute relationships are fundamental to people's daily lives across\nvarious domains. This study aims to comprehend and predict substitute\nrelationships among products in diverse fields, extensively analyzing the\napplication of machine learning algorithms, natural language processing, and\nother technologies. By comparing model methodologies across different domains,\nsuch as defining substitutes, representing and learning substitute\nrelationships, and substitute reasoning, this study offers a methodological\nfoundation for delving deeper into substitute relationships. Through ongoing\nresearch and innovation, we can further refine the personalization and accuracy\nof substitute recommendation systems, thus advancing the development and\napplication of this field.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.08687v1",
    "published_date": "2024-04-09 08:33:43 UTC",
    "updated_date": "2024-04-09 08:33:43 UTC"
  },
  {
    "arxiv_id": "2404.06090v1",
    "title": "Fair Graph Neural Network with Supervised Contrastive Regularization",
    "authors": [
      "Mahdi Tavassoli Kejani",
      "Fadi Dornaika",
      "Jean-Michel Loubes"
    ],
    "abstract": "In recent years, Graph Neural Networks (GNNs) have made significant\nadvancements, particularly in tasks such as node classification, link\nprediction, and graph representation. However, challenges arise from biases\nthat can be hidden not only in the node attributes but also in the connections\nbetween entities. Therefore, ensuring fairness in graph neural network learning\nhas become a critical problem. To address this issue, we propose a novel model\nfor training fairness-aware GNN, which enhances the Counterfactual Augmented\nFair Graph Neural Network Framework (CAF). Our approach integrates Supervised\nContrastive Loss and Environmental Loss to enhance both accuracy and fairness.\nExperimental validation on three real datasets demonstrates the superiority of\nour proposed model over CAF and several other existing graph-based learning\nmethods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.06090v1",
    "published_date": "2024-04-09 07:49:05 UTC",
    "updated_date": "2024-04-09 07:49:05 UTC"
  },
  {
    "arxiv_id": "2404.06079v2",
    "title": "The X-LANCE Technical Report for Interspeech 2024 Speech Processing Using Discrete Speech Unit Challenge",
    "authors": [
      "Yiwei Guo",
      "Chenrun Wang",
      "Yifan Yang",
      "Hankun Wang",
      "Ziyang Ma",
      "Chenpeng Du",
      "Shuai Wang",
      "Hanzheng Li",
      "Shuai Fan",
      "Hui Zhang",
      "Xie Chen",
      "Kai Yu"
    ],
    "abstract": "Discrete speech tokens have been more and more popular in multiple speech\nprocessing fields, including automatic speech recognition (ASR), text-to-speech\n(TTS) and singing voice synthesis (SVS). In this paper, we describe the systems\ndeveloped by the SJTU X-LANCE group for the TTS (acoustic + vocoder), SVS, and\nASR tracks in the Interspeech 2024 Speech Processing Using Discrete Speech Unit\nChallenge. Notably, we achieved 1st rank on the leaderboard in the TTS track\nboth with the whole training set and only 1h training data, with the highest\nUTMOS score and lowest bitrate among all submissions.",
    "categories": [
      "eess.AS",
      "cs.AI"
    ],
    "primary_category": "eess.AS",
    "comment": "5 pages, 3 figures. Report of a challenge",
    "pdf_url": "http://arxiv.org/pdf/2404.06079v2",
    "published_date": "2024-04-09 07:37:41 UTC",
    "updated_date": "2024-04-10 00:33:25 UTC"
  },
  {
    "arxiv_id": "2404.06077v1",
    "title": "Is Your AI Truly Yours? Leveraging Blockchain for Copyrights, Provenance, and Lineage",
    "authors": [
      "Yilin Sai",
      "Qin Wang",
      "Guangsheng Yu",
      "H. M. N. Dilum Bandara",
      "Shiping Chen"
    ],
    "abstract": "As Artificial Intelligence (AI) integrates into diverse areas, particularly\nin content generation, ensuring rightful ownership and ethical use becomes\nparamount. AI service providers are expected to prioritize responsibly sourcing\ntraining data and obtaining licenses from data owners. However, existing\nstudies primarily center on safeguarding static copyrights, which simply treats\nmetadata/datasets as non-fungible items with transferable/trading capabilities,\nneglecting the dynamic nature of training procedures that can shape an ongoing\ntrajectory.\n  In this paper, we present \\textsc{IBis}, a blockchain-based framework\ntailored for AI model training workflows. \\textsc{IBis} integrates on-chain\nregistries for datasets, licenses and models, alongside off-chain signing\nservices to facilitate collaboration among multiple participants. Our framework\naddresses concerns regarding data and model provenance and copyright\ncompliance. \\textsc{IBis} enables iterative model retraining and fine-tuning,\nand offers flexible license checks and renewals. Further, \\textsc{IBis}\nprovides APIs designed for seamless integration with existing contract\nmanagement software, minimizing disruptions to established model training\nprocesses. We implement \\textsc{IBis} using Daml on the Canton blockchain.\nEvaluation results showcase the feasibility and scalability of \\textsc{IBis}\nacross varying numbers of users, datasets, models, and licenses.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.06077v1",
    "published_date": "2024-04-09 07:32:30 UTC",
    "updated_date": "2024-04-09 07:32:30 UTC"
  },
  {
    "arxiv_id": "2404.06063v2",
    "title": "Heuristic-enhanced Candidates Selection strategy for GPTs tackle Few-Shot Aspect-Based Sentiment Analysis",
    "authors": [
      "Baoxing Jiang",
      "Yujie Wan",
      "Shenggen Ju"
    ],
    "abstract": "Few-Shot Aspect-Based Sentiment Analysis (FSABSA) is an indispensable and\nhighly challenging task in natural language processing. However, methods based\non Pre-trained Language Models (PLMs) struggle to accommodate multiple\nsub-tasks, and methods based on Generative Pre-trained Transformers (GPTs)\nperform poorly. To address the above issues, the paper designs a\nHeuristic-enhanced Candidates Selection (HCS) strategy and further proposes All\nin One (AiO) model based on it. The model works in a two-stage, which\nsimultaneously accommodates the accuracy of PLMs and the generalization\ncapability of GPTs. Specifically, in the first stage, a backbone model based on\nPLMs generates rough heuristic candidates for the input sentence. In the second\nstage, AiO leverages LLMs' contextual learning capabilities to generate precise\npredictions. The study conducted comprehensive comparative and ablation\nexperiments on five benchmark datasets. The experimental results demonstrate\nthat the proposed model can better adapt to multiple sub-tasks, and also\noutperforms the methods that directly utilize GPTs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2404.06063v2",
    "published_date": "2024-04-09 07:02:14 UTC",
    "updated_date": "2024-08-19 07:50:54 UTC"
  },
  {
    "arxiv_id": "2404.06059v1",
    "title": "Efficient Quantum Circuits for Machine Learning Activation Functions including Constant T-depth ReLU",
    "authors": [
      "Wei Zi",
      "Siyi Wang",
      "Hyunji Kim",
      "Xiaoming Sun",
      "Anupam Chattopadhyay",
      "Patrick Rebentrost"
    ],
    "abstract": "In recent years, Quantum Machine Learning (QML) has increasingly captured the\ninterest of researchers. Among the components in this domain, activation\nfunctions hold a fundamental and indispensable role. Our research focuses on\nthe development of activation functions quantum circuits for integration into\nfault-tolerant quantum computing architectures, with an emphasis on minimizing\n$T$-depth. Specifically, we present novel implementations of ReLU and leaky\nReLU activation functions, achieving constant $T$-depths of 4 and 8,\nrespectively. Leveraging quantum lookup tables, we extend our exploration to\nother activation functions such as the sigmoid. This approach enables us to\ncustomize precision and $T$-depth by adjusting the number of qubits, making our\nresults more adaptable to various application scenarios. This study represents\na significant advancement towards enhancing the practicality and application of\nquantum machine learning.",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "primary_category": "quant-ph",
    "comment": "13 pages",
    "pdf_url": "http://arxiv.org/pdf/2404.06059v1",
    "published_date": "2024-04-09 06:53:12 UTC",
    "updated_date": "2024-04-09 06:53:12 UTC"
  },
  {
    "arxiv_id": "2404.06025v2",
    "title": "Greedy-DiM: Greedy Algorithms for Unreasonably Effective Face Morphs",
    "authors": [
      "Zander W. Blasingame",
      "Chen Liu"
    ],
    "abstract": "Morphing attacks are an emerging threat to state-of-the-art Face Recognition\n(FR) systems, which aim to create a single image that contains the biometric\ninformation of multiple identities. Diffusion Morphs (DiM) are a recently\nproposed morphing attack that has achieved state-of-the-art performance for\nrepresentation-based morphing attacks. However, none of the existing research\non DiMs have leveraged the iterative nature of DiMs and left the DiM model as a\nblack box, treating it no differently than one would a Generative Adversarial\nNetwork (GAN) or Varational AutoEncoder (VAE). We propose a greedy strategy on\nthe iterative sampling process of DiM models which searches for an optimal step\nguided by an identity-based heuristic function. We compare our proposed\nalgorithm against ten other state-of-the-art morphing algorithms using the\nopen-source SYN-MAD 2022 competition dataset. We find that our proposed\nalgorithm is unreasonably effective, fooling all of the tested FR systems with\nan MMPMR of 100%, outperforming all other morphing algorithms compared.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted as a conference paper at IJCB 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.06025v2",
    "published_date": "2024-04-09 05:21:32 UTC",
    "updated_date": "2024-07-02 15:48:49 UTC"
  },
  {
    "arxiv_id": "2404.06022v2",
    "title": "Band-Attention Modulated RetNet for Face Forgery Detection",
    "authors": [
      "Zhida Zhang",
      "Jie Cao",
      "Wenkui Yang",
      "Qihang Fan",
      "Kai Zhou",
      "Ran He"
    ],
    "abstract": "The transformer networks are extensively utilized in face forgery detection\ndue to their scalability across large datasets.Despite their success,\ntransformers face challenges in balancing the capture of global context, which\nis crucial for unveiling forgery clues, with computational complexity.To\nmitigate this issue, we introduce Band-Attention modulated RetNet (BAR-Net), a\nlightweight network designed to efficiently process extensive visual contexts\nwhile avoiding catastrophic forgetting.Our approach empowers the target token\nto perceive global information by assigning differential attention levels to\ntokens at varying distances. We implement self-attention along both spatial\naxes, thereby maintaining spatial priors and easing the computational\nburden.Moreover, we present the adaptive frequency Band-Attention Modulation\nmechanism, which treats the entire Discrete Cosine Transform spectrogram as a\nseries of frequency bands with learnable weights.Together, BAR-Net achieves\nfavorable performance on several face forgery datasets, outperforming current\nstate-of-the-art methods.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "The essay is poorly expressed in writing and will be re-optimised",
    "pdf_url": "http://arxiv.org/pdf/2404.06022v2",
    "published_date": "2024-04-09 05:11:28 UTC",
    "updated_date": "2024-07-02 01:19:01 UTC"
  },
  {
    "arxiv_id": "2404.06014v1",
    "title": "Using 3-Objective Evolutionary Algorithms for the Dynamic Chance Constrained Knapsack Problem",
    "authors": [
      "Ishara Hewa Pathiranage",
      "Frank Neumann",
      "Denis Antipov",
      "Aneta Neumann"
    ],
    "abstract": "Real-world optimization problems often involve stochastic and dynamic\ncomponents. Evolutionary algorithms are particularly effective in these\nscenarios, as they can easily adapt to uncertain and changing environments but\noften uncertainty and dynamic changes are studied in isolation. In this paper,\nwe explore the use of 3-objective evolutionary algorithms for the chance\nconstrained knapsack problem with dynamic constraints. In our setting, the\nweights of the items are stochastic and the knapsack's capacity changes over\ntime. We introduce a 3-objective formulation that is able to deal with the\nstochastic and dynamic components at the same time and is independent of the\nconfidence level required for the constraint. This new approach is then\ncompared to the 2-objective formulation which is limited to a single confidence\nlevel. We evaluate the approach using two different multi-objective\nevolutionary algorithms (MOEAs), namely the global simple evolutionary\nmulti-objective optimizer (GSEMO) and the multi-objective evolutionary\nalgorithm based on decomposition (MOEA/D), across various benchmark scenarios.\nOur analysis highlights the advantages of the 3-objective formulation over the\n2-objective formulation in addressing the dynamic chance constrained knapsack\nproblem.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.06014v1",
    "published_date": "2024-04-09 04:47:01 UTC",
    "updated_date": "2024-04-09 04:47:01 UTC"
  },
  {
    "arxiv_id": "2404.06007v1",
    "title": "Collaborative Edge AI Inference over Cloud-RAN",
    "authors": [
      "Pengfei Zhang",
      "Dingzhu Wen",
      "Guangxu Zhu",
      "Qimei Chen",
      "Kaifeng Han",
      "Yuanming Shi"
    ],
    "abstract": "In this paper, a cloud radio access network (Cloud-RAN) based collaborative\nedge AI inference architecture is proposed. Specifically, geographically\ndistributed devices capture real-time noise-corrupted sensory data samples and\nextract the noisy local feature vectors, which are then aggregated at each\nremote radio head (RRH) to suppress sensing noise. To realize efficient uplink\nfeature aggregation, we allow each RRH receives local feature vectors from all\ndevices over the same resource blocks simultaneously by leveraging an\nover-the-air computation (AirComp) technique. Thereafter, these aggregated\nfeature vectors are quantized and transmitted to a central processor (CP) for\nfurther aggregation and downstream inference tasks. Our aim in this work is to\nmaximize the inference accuracy via a surrogate accuracy metric called\ndiscriminant gain, which measures the discernibility of different classes in\nthe feature space. The key challenges lie on simultaneously suppressing the\ncoupled sensing noise, AirComp distortion caused by hostile wireless channels,\nand the quantization error resulting from the limited capacity of fronthaul\nlinks. To address these challenges, this work proposes a joint transmit\nprecoding, receive beamforming, and quantization error control scheme to\nenhance the inference accuracy. Extensive numerical experiments demonstrate the\neffectiveness and superiority of our proposed optimization algorithm compared\nto various baselines.",
    "categories": [
      "cs.IT",
      "cs.AI",
      "cs.LG",
      "eess.SP",
      "math.IT"
    ],
    "primary_category": "cs.IT",
    "comment": "This paper is accepted by IEEE Transactions on Communications on\n  08-Apr-2024",
    "pdf_url": "http://arxiv.org/pdf/2404.06007v1",
    "published_date": "2024-04-09 04:26:16 UTC",
    "updated_date": "2024-04-09 04:26:16 UTC"
  },
  {
    "arxiv_id": "2404.06003v1",
    "title": "FreeEval: A Modular Framework for Trustworthy and Efficient Evaluation of Large Language Models",
    "authors": [
      "Zhuohao Yu",
      "Chang Gao",
      "Wenjin Yao",
      "Yidong Wang",
      "Zhengran Zeng",
      "Wei Ye",
      "Jindong Wang",
      "Yue Zhang",
      "Shikun Zhang"
    ],
    "abstract": "The rapid development of large language model (LLM) evaluation methodologies\nand datasets has led to a profound challenge: integrating state-of-the-art\nevaluation techniques cost-effectively while ensuring reliability,\nreproducibility, and efficiency. Currently, there is a notable absence of a\nunified and adaptable framework that seamlessly integrates various evaluation\napproaches. Moreover, the reliability of evaluation findings is often\nquestionable due to potential data contamination, with the evaluation\nefficiency commonly overlooked when facing the substantial costs associated\nwith LLM inference. In response to these challenges, we introduce FreeEval, a\nmodular and scalable framework crafted to enable trustworthy and efficient\nautomatic evaluations of LLMs. Firstly, FreeEval's unified abstractions\nsimplify the integration and improve the transparency of diverse evaluation\nmethodologies, encompassing dynamic evaluation that demand sophisticated LLM\ninteractions. Secondly, the framework integrates meta-evaluation techniques\nlike human evaluation and data contamination detection, which, along with\ndynamic evaluation modules in the platform, enhance the fairness of the\nevaluation outcomes. Lastly, FreeEval is designed with a high-performance\ninfrastructure, including distributed computation and caching strategies,\nenabling extensive evaluations across multi-node, multi-GPU clusters for\nopen-source and proprietary LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "We open-source all our code at:\n  https://github.com/WisdomShell/FreeEval",
    "pdf_url": "http://arxiv.org/pdf/2404.06003v1",
    "published_date": "2024-04-09 04:17:51 UTC",
    "updated_date": "2024-04-09 04:17:51 UTC"
  },
  {
    "arxiv_id": "2404.05990v1",
    "title": "Automatic Authorities: Power and AI",
    "authors": [
      "Seth Lazar"
    ],
    "abstract": "As rapid advances in Artificial Intelligence and the rise of some of\nhistory's most potent corporations meet the diminished neoliberal state, people\nare increasingly subject to power exercised by means of automated systems.\nMachine learning and related computational technologies now underpin vital\ngovernment services. They connect consumers and producers in new algorithmic\nmarkets. They determine how we find out about everything from how to vote to\nwhere to get vaccinated, and whose speech is amplified, reduced, or restricted.\nAnd a new wave of products based on Large Language Models (LLMs) will further\ntransform our economic and political lives. Automatic Authorities are automated\ncomputational systems used to exercise power over us by determining what we may\nknow, what we may have, and what our options will be. In response to their\nrise, scholars working on the societal impacts of AI and related technologies\nhave advocated shifting attention from how to make AI systems beneficial or\nfair towards a critical analysis of these new power relations. But power is\neverywhere, and is not necessarily bad. On what basis should we object to new\nor intensified power relations, and what can be done to justify them? This\npaper introduces the philosophical materials with which to formulate these\nquestions, and offers preliminary answers. It starts by pinning down the\nconcept of power, focusing on the ability that some agents have to shape\nothers' lives. It then explores how AI enables and intensifies the exercise of\npower so understood, and sketches three problems with power and three ways to\nsolve those problems. It emphasises, in particular, that justifying power\nrequires more than satisfying substantive justificatory criteria; standards of\nproper authority and procedural legitimacy must also be met. We need to know\nnot only what power may be used for, but how it may be used, and by whom.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.05990v1",
    "published_date": "2024-04-09 03:48:42 UTC",
    "updated_date": "2024-04-09 03:48:42 UTC"
  },
  {
    "arxiv_id": "2404.06524v1",
    "title": "An Enhanced Grey Wolf Optimizer with Elite Inheritance and Balance Search Mechanisms",
    "authors": [
      "Jianhua Jiang",
      "Ziying Zhao",
      "Weihua Li",
      "Keqin Li"
    ],
    "abstract": "The Grey Wolf Optimizer (GWO) is recognized as a novel meta-heuristic\nalgorithm inspired by the social leadership hierarchy and hunting mechanism of\ngrey wolves. It is well-known for its simple parameter setting, fast\nconvergence speed, and strong optimization capability. In the original GWO,\nthere are two significant design flaws in its fundamental optimization\nmechanisms. Problem (1): the algorithm fails to inherit from elite positions\nfrom the last iteration when generating the next positions of the wolf\npopulation, potentially leading to suboptimal solutions. Problem (2): the\npositions of the population are updated based on the central position of the\nthree leading wolves (alpha, beta, delta), without a balanced mechanism between\nlocal and global search. To tackle these problems, an enhanced Grey Wolf\nOptimizer with Elite Inheritance Mechanism and Balance Search Mechanism, named\nas EBGWO, is proposed to improve the effectiveness of the position updating and\nthe quality of the convergence solutions. The IEEE CEC 2014 benchmark functions\nsuite and a series of simulation tests are employed to evaluate the performance\nof the proposed algorithm. The simulation tests involve a comparative study\nbetween EBGWO, three GWO variants, GWO and two well-known meta-heuristic\nalgorithms. The experimental results demonstrate that the proposed EBGWO\nalgorithm outperforms other meta-heuristic algorithms in both accuracy and\nconvergence speed. Three engineering optimization problems are adopted to prove\nits capability in processing real-world problems. The results indicate that the\nproposed EBGWO outperforms several popular algorithms.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "51 pages, 21 tables, 16 figures, journal",
    "pdf_url": "http://arxiv.org/pdf/2404.06524v1",
    "published_date": "2024-04-09 03:28:00 UTC",
    "updated_date": "2024-04-09 03:28:00 UTC"
  },
  {
    "arxiv_id": "2404.05980v5",
    "title": "Tackling Structural Hallucination in Image Translation with Local Diffusion",
    "authors": [
      "Seunghoi Kim",
      "Chen Jin",
      "Tom Diethe",
      "Matteo Figini",
      "Henry F. J. Tregidgo",
      "Asher Mullokandov",
      "Philip Teare",
      "Daniel C. Alexander"
    ],
    "abstract": "Recent developments in diffusion models have advanced conditioned image\ngeneration, yet they struggle with reconstructing out-of-distribution (OOD)\nimages, such as unseen tumors in medical images, causing \"image hallucination\"\nand risking misdiagnosis. We hypothesize such hallucinations result from local\nOOD regions in the conditional images. We verify that partitioning the OOD\nregion and conducting separate image generations alleviates hallucinations in\nseveral applications. From this, we propose a training-free diffusion framework\nthat reduces hallucination with multiple Local Diffusion processes. Our\napproach involves OOD estimation followed by two modules: a \"branching\" module\ngenerates locally both within and outside OOD regions, and a \"fusion\" module\nintegrates these predictions into one. Our evaluation shows our method\nmitigates hallucination over baseline models quantitatively and qualitatively,\nreducing misdiagnosis by 40% and 25% in the real-world medical and natural\nimage datasets, respectively. It also demonstrates compatibility with various\npre-trained diffusion models.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.05980v5",
    "published_date": "2024-04-09 03:24:10 UTC",
    "updated_date": "2024-07-17 06:07:48 UTC"
  },
  {
    "arxiv_id": "2404.05971v1",
    "title": "Does Transformer Interpretability Transfer to RNNs?",
    "authors": [
      "Gonçalo Paulo",
      "Thomas Marshall",
      "Nora Belrose"
    ],
    "abstract": "Recent advances in recurrent neural network architectures, such as Mamba and\nRWKV, have enabled RNNs to match or exceed the performance of equal-size\ntransformers in terms of language modeling perplexity and downstream\nevaluations, suggesting that future systems may be built on completely new\narchitectures. In this paper, we examine if selected interpretability methods\noriginally designed for transformer language models will transfer to these\nup-and-coming recurrent architectures. Specifically, we focus on steering model\noutputs via contrastive activation addition, on eliciting latent predictions\nvia the tuned lens, and eliciting latent knowledge from models fine-tuned to\nproduce false outputs under certain conditions. Our results show that most of\nthese techniques are effective when applied to RNNs, and we show that it is\npossible to improve some of them by taking advantage of RNNs' compressed state.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.05971v1",
    "published_date": "2024-04-09 02:59:17 UTC",
    "updated_date": "2024-04-09 02:59:17 UTC"
  },
  {
    "arxiv_id": "2404.05967v1",
    "title": "JSTR: Judgment Improves Scene Text Recognition",
    "authors": [
      "Masato Fujitake"
    ],
    "abstract": "In this paper, we present a method for enhancing the accuracy of scene text\nrecognition tasks by judging whether the image and text match each other. While\nprevious studies focused on generating the recognition results from input\nimages, our approach also considers the model's misrecognition results to\nunderstand its error tendencies, thus improving the text recognition pipeline.\nThis method boosts text recognition accuracy by providing explicit feedback on\nthe data that the model is likely to misrecognize by predicting correct or\nincorrect between the image and text. The experimental results on publicly\navailable datasets demonstrate that our proposed method outperforms the\nbaseline and state-of-the-art methods in scene text recognition.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "IntelliSys 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.05967v1",
    "published_date": "2024-04-09 02:55:12 UTC",
    "updated_date": "2024-04-09 02:55:12 UTC"
  },
  {
    "arxiv_id": "2404.05966v2",
    "title": "THOUGHTSCULPT: Reasoning with Intermediate Revision and Search",
    "authors": [
      "Yizhou Chi",
      "Kevin Yang",
      "Dan Klein"
    ],
    "abstract": "We present THOUGHTSCULPT, a general reasoning and search method for tasks\nwith outputs that can be decomposed into components. THOUGHTSCULPT explores a\nsearch tree of potential solutions using Monte Carlo Tree Search (MCTS),\nbuilding solutions one action at a time and evaluating according to any\ndomain-specific heuristic, which in practice is often simply an LLM evaluator.\nCritically, our action space includes revision actions: THOUGHTSCULPT may\nchoose to revise part of its previous output rather than continuing to build\nthe rest of its output. Empirically, THOUGHTSCULPT outperforms state-of-the-art\nreasoning methods across three challenging tasks: Story Outline Improvement (up\nto +30% interestingness), Mini-Crosswords Solving (up to +16% word success\nrate), and Constrained Generation (up to +10% concept coverage).",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to NAACL 2025 Findings. Code and data available at\n  https://github.com/cyzus/thoughtsculpt",
    "pdf_url": "http://arxiv.org/pdf/2404.05966v2",
    "published_date": "2024-04-09 02:53:14 UTC",
    "updated_date": "2025-02-15 03:57:43 UTC"
  },
  {
    "arxiv_id": "2404.05961v2",
    "title": "LLM2Vec: Large Language Models Are Secretly Powerful Text Encoders",
    "authors": [
      "Parishad BehnamGhader",
      "Vaibhav Adlakha",
      "Marius Mosbach",
      "Dzmitry Bahdanau",
      "Nicolas Chapados",
      "Siva Reddy"
    ],
    "abstract": "Large decoder-only language models (LLMs) are the state-of-the-art models on\nmost of today's NLP tasks and benchmarks. Yet, the community is only slowly\nadopting these models for text embedding tasks, which require rich\ncontextualized representations. In this work, we introduce LLM2Vec, a simple\nunsupervised approach that can transform any decoder-only LLM into a strong\ntext encoder. LLM2Vec consists of three simple steps: 1) enabling bidirectional\nattention, 2) masked next token prediction, and 3) unsupervised contrastive\nlearning. We demonstrate the effectiveness of LLM2Vec by applying it to 4\npopular LLMs ranging from 1.3B to 8B parameters and evaluate the transformed\nmodels on English word- and sequence-level tasks. We outperform encoder-only\nmodels by a large margin on word-level tasks and reach a new unsupervised\nstate-of-the-art performance on the Massive Text Embeddings Benchmark (MTEB).\nMoreover, when combining LLM2Vec with supervised contrastive learning, we\nachieve state-of-the-art performance on MTEB among models that train only on\npublicly available data (as of May 24, 2024). Our strong empirical results and\nextensive analysis demonstrate that LLMs can be effectively transformed into\nuniversal text encoders in a parameter-efficient manner without the need for\nexpensive adaptation or synthetic GPT-4 generated data.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to COLM 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.05961v2",
    "published_date": "2024-04-09 02:51:05 UTC",
    "updated_date": "2024-08-21 22:46:05 UTC"
  },
  {
    "arxiv_id": "2404.05959v2",
    "title": "Map Optical Properties to Subwavelength Structures Directly via a Diffusion Model",
    "authors": [
      "Shijie Rao",
      "Kaiyu Cui",
      "Yidong Huang",
      "Jiawei Yang",
      "Yali Li",
      "Shengjin Wang",
      "Xue Feng",
      "Fang Liu",
      "Wei Zhang"
    ],
    "abstract": "Subwavelength photonic structures and metamaterials provide revolutionary\napproaches for controlling light. The inverse design methods proposed for these\nsubwavelength structures are vital to the development of new photonic devices.\nHowever, most of the existing inverse design methods cannot realize direct\nmapping from optical properties to photonic structures but instead rely on\nforward simulation methods to perform iterative optimization. In this work, we\nexploit the powerful generative abilities of artificial intelligence (AI) and\npropose a practical inverse design method based on latent diffusion models. Our\nmethod maps directly the optical properties to structures without the\nrequirement of forward simulation and iterative optimization. Here, the given\noptical properties can work as \"prompts\" and guide the constructed model to\ncorrectly \"draw\" the required photonic structures. Experiments show that our\ndirect mapping-based inverse design method can generate subwavelength photonic\nstructures at high fidelity while following the given optical properties. This\nmay change the method used for optical design and greatly accelerate the\nresearch on new photonic devices.",
    "categories": [
      "physics.optics",
      "cs.AI"
    ],
    "primary_category": "physics.optics",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.05959v2",
    "published_date": "2024-04-09 02:45:39 UTC",
    "updated_date": "2024-12-11 01:17:34 UTC"
  },
  {
    "arxiv_id": "2404.05955v1",
    "title": "VisualWebBench: How Far Have Multimodal LLMs Evolved in Web Page Understanding and Grounding?",
    "authors": [
      "Junpeng Liu",
      "Yifan Song",
      "Bill Yuchen Lin",
      "Wai Lam",
      "Graham Neubig",
      "Yuanzhi Li",
      "Xiang Yue"
    ],
    "abstract": "Multimodal Large Language models (MLLMs) have shown promise in web-related\ntasks, but evaluating their performance in the web domain remains a challenge\ndue to the lack of comprehensive benchmarks. Existing benchmarks are either\ndesigned for general multimodal tasks, failing to capture the unique\ncharacteristics of web pages, or focus on end-to-end web agent tasks, unable to\nmeasure fine-grained abilities such as OCR, understanding, and grounding. In\nthis paper, we introduce \\bench{}, a multimodal benchmark designed to assess\nthe capabilities of MLLMs across a variety of web tasks. \\bench{} consists of\nseven tasks, and comprises 1.5K human-curated instances from 139 real websites,\ncovering 87 sub-domains. We evaluate 14 open-source MLLMs, Gemini Pro, Claude-3\nseries, and GPT-4V(ision) on \\bench{}, revealing significant challenges and\nperformance gaps. Further analysis highlights the limitations of current MLLMs,\nincluding inadequate grounding in text-rich environments and subpar performance\nwith low-resolution image inputs. We believe \\bench{} will serve as a valuable\nresource for the research community and contribute to the creation of more\npowerful and versatile MLLMs for web-related applications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.05955v1",
    "published_date": "2024-04-09 02:29:39 UTC",
    "updated_date": "2024-04-09 02:29:39 UTC"
  },
  {
    "arxiv_id": "2404.05950v1",
    "title": "Efficient Multi-Task Reinforcement Learning via Task-Specific Action Correction",
    "authors": [
      "Jinyuan Feng",
      "Min Chen",
      "Zhiqiang Pu",
      "Tenghai Qiu",
      "Jianqiang Yi"
    ],
    "abstract": "Multi-task reinforcement learning (MTRL) demonstrate potential for enhancing\nthe generalization of a robot, enabling it to perform multiple tasks\nconcurrently. However, the performance of MTRL may still be susceptible to\nconflicts between tasks and negative interference. To facilitate efficient\nMTRL, we propose Task-Specific Action Correction (TSAC), a general and\ncomplementary approach designed for simultaneous learning of multiple tasks.\nTSAC decomposes policy learning into two separate policies: a shared policy\n(SP) and an action correction policy (ACP). To alleviate conflicts resulting\nfrom excessive focus on specific tasks' details in SP, ACP incorporates\ngoal-oriented sparse rewards, enabling an agent to adopt a long-term\nperspective and achieve generalization across tasks. Additional rewards\ntransform the original problem into a multi-objective MTRL problem.\nFurthermore, to convert the multi-objective MTRL into a single-objective\nformulation, TSAC assigns a virtual expected budget to the sparse rewards and\nemploys Lagrangian method to transform a constrained single-objective\noptimization into an unconstrained one. Experimental evaluations conducted on\nMeta-World's MT10 and MT50 benchmarks demonstrate that TSAC outperforms\nexisting state-of-the-art methods, achieving significant improvements in both\nsample efficiency and effective action execution.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.05950v1",
    "published_date": "2024-04-09 02:11:35 UTC",
    "updated_date": "2024-04-09 02:11:35 UTC"
  },
  {
    "arxiv_id": "2404.05943v1",
    "title": "Interplay of Machine Translation, Diacritics, and Diacritization",
    "authors": [
      "Wei-Rui Chen",
      "Ife Adebara",
      "Muhammad Abdul-Mageed"
    ],
    "abstract": "We investigate two research questions: (1) how do machine translation (MT)\nand diacritization influence the performance of each other in a multi-task\nlearning setting (2) the effect of keeping (vs. removing) diacritics on MT\nperformance. We examine these two questions in both high-resource (HR) and\nlow-resource (LR) settings across 55 different languages (36 African languages\nand 19 European languages). For (1), results show that diacritization\nsignificantly benefits MT in the LR scenario, doubling or even tripling\nperformance for some languages, but harms MT in the HR scenario. We find that\nMT harms diacritization in LR but benefits significantly in HR for some\nlanguages. For (2), MT performance is similar regardless of diacritics being\nkept or removed. In addition, we propose two classes of metrics to measure the\ncomplexity of a diacritical system, finding these metrics to correlate\npositively with the performance of our diacritization models. Overall, our work\nprovides insights for developing MT and diacritization systems under different\ndata size conditions and may have implications that generalize beyond the 55\nlanguages we investigate.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to NAACL 2024 Main Conference",
    "pdf_url": "http://arxiv.org/pdf/2404.05943v1",
    "published_date": "2024-04-09 01:55:05 UTC",
    "updated_date": "2024-04-09 01:55:05 UTC"
  },
  {
    "arxiv_id": "2404.05920v1",
    "title": "Inclusive Practices for Child-Centered AI Design and Testing",
    "authors": [
      "Emani Dotch",
      "Vitica Arnold"
    ],
    "abstract": "We explore ideas and inclusive practices for designing and testing\nchild-centered artificially intelligent technologies for neurodivergent\nchildren. AI is promising for supporting social communication, self-regulation,\nand sensory processing challenges common for neurodivergent children. The\nauthors, both neurodivergent individuals and related to neurodivergent people,\ndraw from their professional and personal experiences to offer insights on\ncreating AI technologies that are accessible and include input from\nneurodivergent children. We offer ideas for designing AI technologies for\nneurodivergent children and considerations for including them in the design\nprocess while accounting for their sensory sensitivities. We conclude by\nemphasizing the importance of adaptable and supportive AI technologies and\ndesign processes and call for further conversation to refine child-centered AI\ndesign and testing methods.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "CHI 2024 Workshop on Child-centred AI Design, May 11, 2024, Honolulu,\n  HI, USA",
    "pdf_url": "http://arxiv.org/pdf/2404.05920v1",
    "published_date": "2024-04-09 00:51:24 UTC",
    "updated_date": "2024-04-09 00:51:24 UTC"
  },
  {
    "arxiv_id": "2404.05913v1",
    "title": "Deep Reinforcement Learning for Personalized Diagnostic Decision Pathways Using Electronic Health Records: A Comparative Study on Anemia and Systemic Lupus Erythematosus",
    "authors": [
      "Lillian Muyama",
      "Antoine Neuraz",
      "Adrien Coulet"
    ],
    "abstract": "Background: Clinical diagnosis is typically reached by following a series of\nsteps recommended by guidelines authored by colleges of experts. Accordingly,\nguidelines play a crucial role in rationalizing clinical decisions but suffer\nfrom limitations as they are built to cover the majority of the population and\nfail at covering patients with uncommon conditions. Moreover, their updates are\nlong and expensive, making them unsuitable for emerging diseases and practices.\n  Methods: Inspired by guidelines, we formulate the task of diagnosis as a\nsequential decision-making problem and study the use of Deep Reinforcement\nLearning (DRL) algorithms to learn the optimal sequence of actions to perform\nin order to obtain a correct diagnosis from Electronic Health Records (EHRs).\nWe apply DRL on synthetic, but realistic EHRs and develop two clinical use\ncases: Anemia diagnosis, where the decision pathways follow the schema of a\ndecision tree; and Systemic Lupus Erythematosus (SLE) diagnosis, which follows\na weighted criteria score. We particularly evaluate the robustness of our\napproaches to noisy and missing data since these frequently occur in EHRs.\n  Results: In both use cases, and in the presence of imperfect data, our best\nDRL algorithms exhibit competitive performance when compared to the traditional\nclassifiers, with the added advantage that they enable the progressive\ngeneration of a pathway to the suggested diagnosis which can both guide and\nexplain the decision-making process.\n  Conclusion: DRL offers the opportunity to learn personalized decision\npathways to diagnosis. We illustrate with our two use cases their advantages:\nthey generate step-by-step pathways that are self-explanatory; and their\ncorrectness is competitive when compared to state-of-the-art approaches.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "arXiv admin note: substantial text overlap with arXiv:2305.06295",
    "pdf_url": "http://arxiv.org/pdf/2404.05913v1",
    "published_date": "2024-04-09 00:07:16 UTC",
    "updated_date": "2024-04-09 00:07:16 UTC"
  }
]