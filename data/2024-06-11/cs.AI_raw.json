[
  {
    "arxiv_id": "2406.07770v1",
    "title": "DualBind: A Dual-Loss Framework for Protein-Ligand Binding Affinity Prediction",
    "authors": [
      "Meng Liu",
      "Saee Gopal Paliwal"
    ],
    "abstract": "Accurate prediction of protein-ligand binding affinities is crucial for drug\ndevelopment. Recent advances in machine learning show promising results on this\ntask. However, these methods typically rely heavily on labeled data, which can\nbe scarce or unreliable, or they rely on assumptions like Boltzmann-distributed\ndata that may not hold true in practice. Here, we present DualBind, a novel\nframework that integrates supervised mean squared error (MSE) with unsupervised\ndenoising score matching (DSM) to accurately learn the binding energy function.\nDualBind not only addresses the limitations of DSM-only models by providing\nmore accurate absolute affinity predictions but also improves generalizability\nand reduces reliance on labeled data compared to MSE-only models. Our\nexperimental results demonstrate that DualBind excels in predicting binding\naffinities and can effectively utilize both labeled and unlabeled data to\nenhance performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": "Preprint, work in progress",
    "pdf_url": "http://arxiv.org/pdf/2406.07770v1",
    "published_date": "2024-06-11 23:29:48 UTC",
    "updated_date": "2024-06-11 23:29:48 UTC"
  },
  {
    "arxiv_id": "2406.09441v1",
    "title": "Comment on paper: Position: Rethinking Post-Hoc Search-Based Neural Approaches for Solving Large-Scale Traveling Salesman Problems",
    "authors": [
      "Yimeng Min"
    ],
    "abstract": "We identify two major issues in the SoftDist paper (Xia et al.): (1) the\nfailure to run all steps of different baselines on the same hardware\nenvironment, and (2) the use of inconsistent time measurements when comparing\nto other baselines. These issues lead to flawed conclusions. When all steps are\nexecuted in the same hardware environment, the primary claim made in SoftDist\nis no longer supported.",
    "categories": [
      "cs.PF",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.PF",
    "comment": "comment on arXiv:2406.03503, 4 pages, 1 figure and 1 table",
    "pdf_url": "http://arxiv.org/pdf/2406.09441v1",
    "published_date": "2024-06-11 23:14:19 UTC",
    "updated_date": "2024-06-11 23:14:19 UTC"
  },
  {
    "arxiv_id": "2406.07765v2",
    "title": "Using AI-Based Coding Assistants in Practice: State of Affairs, Perceptions, and Ways Forward",
    "authors": [
      "Agnia Sergeyuk",
      "Yaroslav Golubev",
      "Timofey Bryksin",
      "Iftekhar Ahmed"
    ],
    "abstract": "Context. The last several years saw the emergence of AI assistants for code -\nmulti-purpose AI-based helpers in software engineering. As they become\nomnipresent in all aspects of software development, it becomes critical to\nunderstand their usage patterns.\n  Objective. We aim to better understand how specifically developers are using\nAI assistants, why they are not using them in certain parts of their\ndevelopment workflow, and what needs to be improved in the future.\n  Methods. In this work, we carried out a large-scale survey aimed at how AI\nassistants are used, focusing on specific software development activities and\nstages. We collected opinions of 481 programmers on five broad activities: (a)\nimplementing new features, (b) writing tests, (c) bug triaging, (d)\nrefactoring, and (e) writing natural-language artifacts, as well as their\nindividual stages.\n  Results. Our results provide a novel comparison of different stages where AI\nassistants are used that is both comprehensive and detailed. It highlights\nspecific activities that developers find less enjoyable and want to delegate to\nan AI assistant, e.g., writing tests and natural-language artifacts. We also\ndetermine more granular stages where AI assistants are used, such as generating\ntests and generating docstrings, as well as less studied parts of the workflow,\nsuch as generating test data. Among the reasons for not using assistants, there\nare general aspects like trust and company policies, as well as more concrete\nissues like the lack of project-size context, which can be the focus of the\nfuture research.\n  Conclusion. The provided analysis highlights stages of software development\nthat developers want to delegate and that are already popular for using AI\nassistants, which can be a good focus for features aimed to help developers\nright now. The main reasons for not using AI assistants can serve as a\nguideline for future work.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.SE",
    "comment": "Published in Information and Software Technology. 32 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.07765v2",
    "published_date": "2024-06-11 23:10:43 UTC",
    "updated_date": "2024-11-07 11:09:24 UTC"
  },
  {
    "arxiv_id": "2406.07753v1",
    "title": "The MuSe 2024 Multimodal Sentiment Analysis Challenge: Social Perception and Humor Recognition",
    "authors": [
      "Shahin Amiriparian",
      "Lukas Christ",
      "Alexander Kathan",
      "Maurice Gerczuk",
      "Niklas Müller",
      "Steffen Klug",
      "Lukas Stappen",
      "Andreas König",
      "Erik Cambria",
      "Björn Schuller",
      "Simone Eulitz"
    ],
    "abstract": "The Multimodal Sentiment Analysis Challenge (MuSe) 2024 addresses two\ncontemporary multimodal affect and sentiment analysis problems: In the Social\nPerception Sub-Challenge (MuSe-Perception), participants will predict 16\ndifferent social attributes of individuals such as assertiveness, dominance,\nlikability, and sincerity based on the provided audio-visual data. The\nCross-Cultural Humor Detection Sub-Challenge (MuSe-Humor) dataset expands upon\nthe Passau Spontaneous Football Coach Humor (Passau-SFCH) dataset, focusing on\nthe detection of spontaneous humor in a cross-lingual and cross-cultural\nsetting. The main objective of MuSe 2024 is to unite a broad audience from\nvarious research domains, including multimodal sentiment analysis, audio-visual\naffective computing, continuous signal processing, and natural language\nprocessing. By fostering collaboration and exchange among experts in these\nfields, the MuSe 2024 endeavors to advance the understanding and application of\nsentiment analysis and affective computing across multiple modalities. This\nbaseline paper provides details on each sub-challenge and its corresponding\ndataset, extracted features from each data modality, and discusses challenge\nbaselines. For our baseline system, we make use of a range of Transformers and\nexpert-designed features and train Gated Recurrent Unit (GRU)-Recurrent Neural\nNetwork (RNN) models on them, resulting in a competitive baseline system. On\nthe unseen test datasets of the respective sub-challenges, it achieves a mean\nPearson's Correlation Coefficient ($\\rho$) of 0.3573 for MuSe-Perception and an\nArea Under the Curve (AUC) value of 0.8682 for MuSe-Humor.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "68T10",
      "I.2"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07753v1",
    "published_date": "2024-06-11 22:26:20 UTC",
    "updated_date": "2024-06-11 22:26:20 UTC"
  },
  {
    "arxiv_id": "2406.07737v1",
    "title": "The Future of Software Engineering in an AI-Driven World",
    "authors": [
      "Valerio Terragni",
      "Partha Roop",
      "Kelly Blincoe"
    ],
    "abstract": "A paradigm shift is underway in Software Engineering, with AI systems such as\nLLMs gaining increasing importance for improving software development\nproductivity. This trend is anticipated to persist. In the next five years, we\nwill likely see an increasing symbiotic partnership between human developers\nand AI. The Software Engineering research community cannot afford to overlook\nthis trend; we must address the key research challenges posed by the\nintegration of AI into the software development process. In this paper, we\npresent our vision of the future of software development in an AI-Driven world\nand explore the key challenges that our research community should address to\nrealize this vision.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG",
      "cs.PL"
    ],
    "primary_category": "cs.SE",
    "comment": "This paper was accepted at the \"International Workshop on Software\n  Engineering in 2030,\" co-located with FSE 2024. It was also invited to the\n  special issue of ACM TOSEM",
    "pdf_url": "http://arxiv.org/pdf/2406.07737v1",
    "published_date": "2024-06-11 21:46:19 UTC",
    "updated_date": "2024-06-11 21:46:19 UTC"
  },
  {
    "arxiv_id": "2406.12905v1",
    "title": "PufferLib: Making Reinforcement Learning Libraries and Environments Play Nice",
    "authors": [
      "Joseph Suarez"
    ],
    "abstract": "You have an environment, a model, and a reinforcement learning library that\nare designed to work together but don't. PufferLib makes them play nice. The\nlibrary provides one-line environment wrappers that eliminate common\ncompatibility problems and fast vectorization to accelerate training. With\nPufferLib, you can use familiar libraries like CleanRL and SB3 to scale from\nclassic benchmarks like Atari and Procgen to complex simulators like NetHack\nand Neural MMO. We release pip packages and prebuilt images with dependencies\nfor dozens of environments. All of our code is free and open-source software\nunder the MIT license, complete with baselines, documentation, and support at\npufferai.github.io.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.12905v1",
    "published_date": "2024-06-11 21:13:34 UTC",
    "updated_date": "2024-06-11 21:13:34 UTC"
  },
  {
    "arxiv_id": "2406.07727v1",
    "title": "Efficient Parallel Multi-Hop Reasoning: A Scalable Approach for Knowledge Graph Analysis",
    "authors": [
      "Jesmin Jahan Tithi",
      "Fabio Checconi",
      "Fabrizio Petrini"
    ],
    "abstract": "Multi-hop reasoning (MHR) is a process in artificial intelligence and natural\nlanguage processing where a system needs to make multiple inferential steps to\narrive at a conclusion or answer. In the context of knowledge graphs or\ndatabases, it involves traversing multiple linked entities and relationships to\nunderstand complex queries or perform tasks requiring a deeper understanding.\nMulti-hop reasoning is a critical function in various applications, including\nquestion answering, knowledge base completion, and link prediction. It has\ngarnered significant interest in artificial intelligence, machine learning, and\ngraph analytics.\n  This paper focuses on optimizing MHR for time efficiency on large-scale\ngraphs, diverging from the traditional emphasis on accuracy which is an\northogonal goal. We introduce a novel parallel algorithm that harnesses\ndomain-specific learned embeddings to efficiently identify the top K paths\nbetween vertices in a knowledge graph to find the best answers to a three-hop\nquery. Our contributions are: (1) We present a new parallel algorithm to\nenhance MHR performance, scalability and efficiency. (2) We demonstrate the\nalgorithm's superior performance on leading-edge Intel and AMD architectures\nthrough empirical results.\n  We showcase the algorithm's practicality through a case study on identifying\nacademic affiliations of potential Turing Award laureates in Deep Learning,\nhighlighting its capability to handle intricate entity relationships. This\ndemonstrates the potential of our approach to enabling high-performance MHR,\nuseful to navigate the growing complexity of modern knowledge graphs.",
    "categories": [
      "cs.AI",
      "cs.DC",
      "cs.DS",
      "cs.LG",
      "cs.PF",
      "H.4; C.4"
    ],
    "primary_category": "cs.AI",
    "comment": "11 Pages with references",
    "pdf_url": "http://arxiv.org/pdf/2406.07727v1",
    "published_date": "2024-06-11 21:12:34 UTC",
    "updated_date": "2024-06-11 21:12:34 UTC"
  },
  {
    "arxiv_id": "2406.07714v2",
    "title": "LLAMAFUZZ: Large Language Model Enhanced Greybox Fuzzing",
    "authors": [
      "Hongxiang Zhang",
      "Yuyang Rong",
      "Yifeng He",
      "Hao Chen"
    ],
    "abstract": "Greybox fuzzing has achieved success in revealing bugs and vulnerabilities in\nprograms. However, randomized mutation strategies have limited the fuzzer's\nperformance on structured data. Specialized fuzzers can handle complex\nstructured data, but require additional efforts in grammar and suffer from low\nthroughput.\n  In this paper, we explore the potential of utilizing the Large Language Model\nto enhance greybox fuzzing for structured data. We utilize the pre-trained\nknowledge of LLM about data conversion and format to generate new valid inputs.\nWe further fine-tuned it with paired mutation seeds to learn structured format\nand mutation strategies effectively. Our LLM-based fuzzer, LLAMAFUZZ,\nintegrates the power of LLM to understand and mutate structured data to\nfuzzing. We conduct experiments on the standard bug-based benchmark Magma and a\nwide variety of real-world programs. LLAMAFUZZ outperforms our top competitor\nby 41 bugs on average. We also identified 47 unique bugs across all trials.\nMoreover, LLAMAFUZZ demonstrated consistent performance on both bug trigger and\nbug reached. Compared to AFL++, LLAMAFUZZ achieved 27.19% more branches in\nreal-world program sets on average. We also demonstrate a case study to explain\nhow LLMs enhance the fuzzing process in terms of code coverage.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07714v2",
    "published_date": "2024-06-11 20:48:28 UTC",
    "updated_date": "2024-06-13 21:11:09 UTC"
  },
  {
    "arxiv_id": "2406.07699v1",
    "title": "CUPID: Contextual Understanding of Prompt-conditioned Image Distributions",
    "authors": [
      "Yayan Zhao",
      "Mingwei Li",
      "Matthew Berger"
    ],
    "abstract": "We present CUPID: a visualization method for the contextual understanding of\nprompt-conditioned image distributions. CUPID targets the visual analysis of\ndistributions produced by modern text-to-image generative models, wherein a\nuser can specify a scene via natural language, and the model generates a set of\nimages, each intended to satisfy the user's description. CUPID is designed to\nhelp understand the resulting distribution, using contextual cues to facilitate\nanalysis: objects mentioned in the prompt, novel, synthesized objects not\nexplicitly mentioned, and their potential relationships. Central to CUPID is a\nnovel method for visualizing high-dimensional distributions, wherein\ncontextualized embeddings of objects, those found within images, are mapped to\na low-dimensional space via density-based embeddings. We show how such\nembeddings allows one to discover salient styles of objects within a\ndistribution, as well as identify anomalous, or rare, object styles. Moreover,\nwe introduce conditional density embeddings, whereby conditioning on a given\nobject allows one to compare object dependencies within the distribution. We\nemploy CUPID for analyzing image distributions produced by large-scale\ndiffusion models, where our experimental results offer insights on language\nmisunderstanding from such models and biases in object composition, while also\nproviding an interface for discovery of typical, or rare, synthesized scenes.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07699v1",
    "published_date": "2024-06-11 20:26:41 UTC",
    "updated_date": "2024-06-11 20:26:41 UTC"
  },
  {
    "arxiv_id": "2406.07693v3",
    "title": "A Labelled Dataset for Sentiment Analysis of Videos on YouTube, TikTok, and Other Sources about the 2024 Outbreak of Measles",
    "authors": [
      "Nirmalya Thakur",
      "Vanessa Su",
      "Mingchen Shao",
      "Kesha A. Patel",
      "Hongseok Jeong",
      "Victoria Knieling",
      "Andrew Bian"
    ],
    "abstract": "The work of this paper presents a dataset that contains the data of 4011\nvideos about the ongoing outbreak of measles published on 264 websites on the\ninternet between January 1, 2024, and May 31, 2024. The dataset is available at\nhttps://dx.doi.org/10.21227/40s8-xf63. These websites primarily include YouTube\nand TikTok, which account for 48.6% and 15.2% of the videos, respectively. The\nremainder of the websites include Instagram and Facebook as well as the\nwebsites of various global and local news organizations. For each of these\nvideos, the URL of the video, title of the post, description of the post, and\nthe date of publication of the video are presented as separate attributes in\nthe dataset. After developing this dataset, sentiment analysis (using VADER),\nsubjectivity analysis (using TextBlob), and fine-grain sentiment analysis\n(using DistilRoBERTa-base) of the video titles and video descriptions were\nperformed. This included classifying each video title and video description\ninto (i) one of the sentiment classes i.e. positive, negative, or neutral, (ii)\none of the subjectivity classes i.e. highly opinionated, neutral opinionated,\nor least opinionated, and (iii) one of the fine-grain sentiment classes i.e.\nfear, surprise, joy, sadness, anger, disgust, or neutral. These results are\npresented as separate attributes in the dataset for the training and testing of\nmachine learning algorithms for performing sentiment analysis or subjectivity\nanalysis in this field as well as for other applications. Finally, this paper\nalso presents a list of open research questions that may be investigated using\nthis dataset.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.SI",
      "I.2.7; I.2.8; I.5.4; K.4.2; H.2.8; I.2.6"
    ],
    "primary_category": "cs.CY",
    "comment": "19 pages",
    "pdf_url": "http://arxiv.org/pdf/2406.07693v3",
    "published_date": "2024-06-11 20:14:22 UTC",
    "updated_date": "2024-07-18 04:24:57 UTC"
  },
  {
    "arxiv_id": "2406.07688v1",
    "title": "AI Radiologist: Revolutionizing Liver Tissue Segmentation with Convolutional Neural Networks and a Clinician-Friendly GUI",
    "authors": [
      "Ayman Al-Kababji",
      "Faycal Bensaali",
      "Sarada Prasad Dakua",
      "Yassine Himeur"
    ],
    "abstract": "Artificial Intelligence (AI) is a pervasive research topic, permeating\nvarious sectors and applications. In this study, we harness the power of AI,\nspecifically convolutional neural networks (ConvNets), for segmenting liver\ntissues. It also focuses on developing a user-friendly graphical user interface\n(GUI) tool, \"AI Radiologist\", enabling clinicians to effectively delineate\ndifferent liver tissues (parenchyma, tumors, and vessels), thereby saving\nlives. This endeavor bridges the gap between academic research and practical,\nindustrial applications. The GUI is a single-page application and is designed\nusing the PyQt5 Python framework. The offline-available AI Radiologist resorts\nto three ConvNet models trained to segment all liver tissues. With respect to\nthe Dice metric, the best liver ConvNet scores 98.16%, the best tumor ConvNet\nscores 65.95%, and the best vessel ConvNet scores 51.94%. It outputs 2D slices\nof the liver, tumors, and vessels, along with 3D interpolations in .obj and\n.mtl formats, which can be visualized/printed using any 3D-compatible software.\nThus, the AI Radiologist offers a convenient tool for clinicians to perform\nliver tissue segmentation and 3D interpolation employing state-of-the-art\nmodels for tissues segmentation. With the provided capacity to select the\nvolumes and pre-trained models, the clinicians can leave the rest to the AI\nRadiologist.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "38 pages, 19 figures, 7 tables submitted to journal",
    "pdf_url": "http://arxiv.org/pdf/2406.07688v1",
    "published_date": "2024-06-11 20:10:16 UTC",
    "updated_date": "2024-06-11 20:10:16 UTC"
  },
  {
    "arxiv_id": "2406.07685v2",
    "title": "Test-Time Fairness and Robustness in Large Language Models",
    "authors": [
      "Leonardo Cotta",
      "Chris J. Maddison"
    ],
    "abstract": "Frontier Large Language Models (LLMs) can be socially discriminatory or\nsensitive to spurious features of their inputs. Because only well-resourced\ncorporations can train frontier LLMs, we need robust test-time strategies to\ncontrol such biases. Existing solutions, which instruct the LLM to be fair or\nrobust, rely on the model's implicit understanding of bias. Causality provides\na rich formalism through which we can be explicit about our debiasing\nrequirements. Yet, as we show, a naive application of the standard causal\ndebiasing strategy, counterfactual data augmentation, fails under standard\nassumptions to debias predictions at an individual level at test time. To\naddress this, we develop a stratified notion of debiasing called stratified\ninvariance, which can capture a range of debiasing requirements from population\nlevel to individual level through an additional measurement that stratifies the\npredictions. We present a complete observational test for stratified\ninvariance. Finally, we introduce a data augmentation strategy that guarantees\nstratified invariance at test time under suitable assumptions, together with a\nprompting strategy that encourages stratified invariance in LLMs. We show that\nour prompting strategy, unlike implicit instructions, consistently reduces the\nbias of frontier LLMs across a suite of synthetic and real-world benchmarks\nwithout requiring additional data, finetuning or pre-training.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07685v2",
    "published_date": "2024-06-11 20:05:15 UTC",
    "updated_date": "2024-10-04 21:10:33 UTC"
  },
  {
    "arxiv_id": "2406.07683v1",
    "title": "Impact of AI-tooling on the Engineering Workspace",
    "authors": [
      "Lena Chretien",
      "Nikolas Albarran"
    ],
    "abstract": "To understand the impacts of AI-driven coding tools on engineers' workflow\nand work environment, we utilize the Jellyfish platform to analyze indicators\nof change. Key indicators are derived from Allocations, Coding Fraction vs. PR\nFraction, Lifecycle Phases, Cycle Time, Jira ticket size, PR pickup time, PR\ncomments, PR comment count, interactions, and coding languages. Significant\nchanges were observed in coding time fractions among Copilot users, with an\naverage decrease of 3% with individual decreases as large as 15%. Ticket sizes\ndecreased by an average of 16% across four companies, accompanied by an 8%\ndecrease in cycle times, whereas the control group showed no change.\nAdditionally, the PR process evolved with Copilot usage, featuring longer and\nmore comprehensive comments, despite the weekly number of PRs reviewed\nremaining constant. Not all hypothesized changes were observed across all\nparticipating companies. However, some companies experienced a decrease in PR\npickup times by up to 33%, indicating reduced workflow bottlenecks, and one\ncompany experienced a shift of up to 17% of effort from maintenance and support\nwork towards product growth initiatives. This study is the first to utilize\ndata from more than one company and goes beyond simple productivity and\nsatisfaction measures, considering real-world engineering settings instead. By\ndoing so, we highlight that some companies seem to benefit more than others\nfrom the use of Copilot and that changes can be subtle when investigating\naggregates rather than specific aspects of engineering work and workflows -\nsomething that will be further investigated in the future.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07683v1",
    "published_date": "2024-06-11 20:04:09 UTC",
    "updated_date": "2024-06-11 20:04:09 UTC"
  },
  {
    "arxiv_id": "2406.07676v1",
    "title": "FastAST: Accelerating Audio Spectrogram Transformer via Token Merging and Cross-Model Knowledge Distillation",
    "authors": [
      "Swarup Ranjan Behera",
      "Abhishek Dhiman",
      "Karthik Gowda",
      "Aalekhya Satya Narayani"
    ],
    "abstract": "Audio classification models, particularly the Audio Spectrogram Transformer\n(AST), play a crucial role in efficient audio analysis. However, optimizing\ntheir efficiency without compromising accuracy remains a challenge. In this\npaper, we introduce FastAST, a framework that integrates Token Merging (ToMe)\ninto the AST framework. FastAST enhances inference speed without requiring\nextensive retraining by merging similar tokens in audio spectrograms.\nFurthermore, during training, FastAST brings about significant speed\nimprovements. The experiments indicate that FastAST can increase audio\nclassification throughput with minimal impact on accuracy. To mitigate the\naccuracy impact, we integrate Cross-Model Knowledge Distillation (CMKD) into\nthe FastAST framework. Integrating ToMe and CMKD into AST results in improved\naccuracy compared to AST while maintaining faster inference speeds. FastAST\nrepresents a step towards real-time, resource-efficient audio analysis.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "cs.MM",
      "eess.AS",
      "68T10"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted to Interspeech 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.07676v1",
    "published_date": "2024-06-11 19:50:50 UTC",
    "updated_date": "2024-06-11 19:50:50 UTC"
  },
  {
    "arxiv_id": "2406.10273v5",
    "title": "Beyond Words: On Large Language Models Actionability in Mission-Critical Risk Analysis",
    "authors": [
      "Matteo Esposito",
      "Francesco Palagiano",
      "Valentina Lenarduzzi",
      "Davide Taibi"
    ],
    "abstract": "Context. Risk analysis assesses potential risks in specific scenarios. Risk\nanalysis principles are context-less; the same methodology can be applied to a\nrisk connected to health and information technology security. Risk analysis\nrequires a vast knowledge of national and international regulations and\nstandards and is time and effort-intensive. A large language model can quickly\nsummarize information in less time than a human and can be fine-tuned to\nspecific tasks.\n  Aim. Our empirical study aims to investigate the effectiveness of\nRetrieval-Augmented Generation and fine-tuned LLM in risk analysis. To our\nknowledge, no prior study has explored its capabilities in risk analysis.\n  Method. We manually curated 193 unique scenarios leading to 1283\nrepresentative samples from over 50 mission-critical analyses archived by the\nindustrial context team in the last five years. We compared the base GPT-3.5\nand GPT-4 models versus their Retrieval-Augmented Generation and fine-tuned\ncounterparts. We employ two human experts as competitors of the models and\nthree other human experts to review the models and the former human experts'\nanalysis. The reviewers analyzed 5,000 scenario analyses.\n  Results and Conclusions. Human experts demonstrated higher accuracy, but LLMs\nare quicker and more actionable. Moreover, our findings show that RAG-assisted\nLLMs have the lowest hallucination rates, effectively uncovering hidden risks\nand complementing human expertise. Thus, the choice of model depends on\nspecific needs, with FTMs for accuracy, RAG for hidden risks discovery, and\nbase models for comprehensiveness and actionability. Therefore, experts can\nleverage LLMs as an effective complementing companion in risk analysis within a\ncondensed timeframe. They can also save costs by averting unnecessary expenses\nassociated with implementing unwarranted countermeasures.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.10273v5",
    "published_date": "2024-06-11 19:20:27 UTC",
    "updated_date": "2024-09-06 22:28:37 UTC"
  },
  {
    "arxiv_id": "2406.07662v3",
    "title": "Progress Towards Decoding Visual Imagery via fNIRS",
    "authors": [
      "Michel Adamic",
      "Wellington Avelino",
      "Anna Brandenberger",
      "Bryan Chiang",
      "Hunter Davis",
      "Stephen Fay",
      "Andrew Gregory",
      "Aayush Gupta",
      "Raphael Hotter",
      "Grace Jiang",
      "Fiona Leng",
      "Stephen Polcyn",
      "Thomas Ribeiro",
      "Paul Scotti",
      "Michelle Wang",
      "Marley Xiong",
      "Jonathan Xu"
    ],
    "abstract": "We demonstrate the possibility of reconstructing images from fNIRS brain\nactivity and start building a prototype to match the required specs. By\ntraining an image reconstruction model on downsampled fMRI data, we discovered\nthat cm-scale spatial resolution is sufficient for image generation. We\nobtained 71% retrieval accuracy with 1-cm resolution, compared to 93% on the\nfull-resolution fMRI, and 20% with 2-cm resolution. With simulations and\nhigh-density tomography, we found that time-domain fNIRS can achieve 1-cm\nresolution, compared to 2-cm resolution for continuous-wave fNIRS. Lastly, we\nshare designs for a prototype time-domain fNIRS device, consisting of a laser\ndriver, a single photon detector, and a time-to-digital converter system.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "q-bio.NC"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07662v3",
    "published_date": "2024-06-11 19:08:32 UTC",
    "updated_date": "2024-06-22 17:42:13 UTC"
  },
  {
    "arxiv_id": "2407.15009v2",
    "title": "RogueGPT: dis-ethical tuning transforms ChatGPT4 into a Rogue AI in 158 Words",
    "authors": [
      "Alessio Buscemi",
      "Daniele Proverbio"
    ],
    "abstract": "The ethical implications and potentials for misuse of Generative Artificial\nIntelligence are increasingly worrying topics. This paper explores how easily\nthe default ethical guardrails of ChatGPT, using its latest customization\nfeatures, can be bypassed by simple prompts and fine-tuning, that can be\neffortlessly accessed by the broad public. This malevolently altered version of\nChatGPT, nicknamed \"RogueGPT\", responded with worrying behaviours, beyond those\ntriggered by jailbreak prompts. We conduct an empirical study of RogueGPT\nresponses, assessing its flexibility in answering questions pertaining to what\nshould be disallowed usage. Our findings raise significant concerns about the\nmodel's knowledge about topics like illegal drug production, torture methods\nand terrorism. The ease of driving ChatGPT astray, coupled with its global\naccessibility, highlights severe issues regarding the data quality used for\ntraining the foundational model and the implementation of ethical safeguards.\nWe thus underline the responsibilities and dangers of user-driven\nmodifications, and the broader effects that these may have on the design of\nsafeguarding and ethical modules implemented by AI programmers.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.15009v2",
    "published_date": "2024-06-11 18:59:43 UTC",
    "updated_date": "2024-07-23 15:13:03 UTC"
  },
  {
    "arxiv_id": "2406.07646v1",
    "title": "Pre-training Feature Guided Diffusion Model for Speech Enhancement",
    "authors": [
      "Yiyuan Yang",
      "Niki Trigoni",
      "Andrew Markham"
    ],
    "abstract": "Speech enhancement significantly improves the clarity and intelligibility of\nspeech in noisy environments, improving communication and listening\nexperiences. In this paper, we introduce a novel pretraining feature-guided\ndiffusion model tailored for efficient speech enhancement, addressing the\nlimitations of existing discriminative and generative models. By integrating\nspectral features into a variational autoencoder (VAE) and leveraging\npre-trained features for guidance during the reverse process, coupled with the\nutilization of the deterministic discrete integration method (DDIM) to\nstreamline sampling steps, our model improves efficiency and speech enhancement\nquality. Demonstrating state-of-the-art results on two public datasets with\ndifferent SNRs, our model outshines other baselines in efficiency and\nrobustness. The proposed method not only optimizes performance but also\nenhances practical deployment capabilities, without increasing computational\ndemands.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted by Interspeech 2024 Conference",
    "pdf_url": "http://arxiv.org/pdf/2406.07646v1",
    "published_date": "2024-06-11 18:22:59 UTC",
    "updated_date": "2024-06-11 18:22:59 UTC"
  },
  {
    "arxiv_id": "2406.07640v2",
    "title": "When is an Embedding Model More Promising than Another?",
    "authors": [
      "Maxime Darrin",
      "Philippe Formont",
      "Ismail Ben Ayed",
      "Jackie CK Cheung",
      "Pablo Piantanida"
    ],
    "abstract": "Embedders play a central role in machine learning, projecting any object into\nnumerical representations that can, in turn, be leveraged to perform various\ndownstream tasks. The evaluation of embedding models typically depends on\ndomain-specific empirical approaches utilizing downstream tasks, primarily\nbecause of the lack of a standardized framework for comparison. However,\nacquiring adequately large and representative datasets for conducting these\nassessments is not always viable and can prove to be prohibitively expensive\nand time-consuming. In this paper, we present a unified approach to evaluate\nembedders. First, we establish theoretical foundations for comparing embedding\nmodels, drawing upon the concepts of sufficiency and informativeness. We then\nleverage these concepts to devise a tractable comparison criterion (information\nsufficiency), leading to a task-agnostic and self-supervised ranking procedure.\nWe demonstrate experimentally that our approach aligns closely with the\ncapability of embedding models to facilitate various downstream tasks in both\nnatural language processing and molecular biology. This effectively offers\npractitioners a valuable tool for prioritizing model trials.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07640v2",
    "published_date": "2024-06-11 18:13:46 UTC",
    "updated_date": "2024-11-16 17:01:02 UTC"
  },
  {
    "arxiv_id": "2406.07546v2",
    "title": "Commonsense-T2I Challenge: Can Text-to-Image Generation Models Understand Commonsense?",
    "authors": [
      "Xingyu Fu",
      "Muyu He",
      "Yujie Lu",
      "William Yang Wang",
      "Dan Roth"
    ],
    "abstract": "We present a novel task and benchmark for evaluating the ability of\ntext-to-image(T2I) generation models to produce images that align with\ncommonsense in real life, which we call Commonsense-T2I. Given two adversarial\ntext prompts containing an identical set of action words with minor\ndifferences, such as \"a lightbulb without electricity\" v.s. \"a lightbulb with\nelectricity\", we evaluate whether T2I models can conduct visual-commonsense\nreasoning, e.g. produce images that fit \"the lightbulb is unlit\" vs. \"the\nlightbulb is lit\" correspondingly. Commonsense-T2I presents an adversarial\nchallenge, providing pairwise text prompts along with expected outputs. The\ndataset is carefully hand-curated by experts and annotated with fine-grained\nlabels, such as commonsense type and likelihood of the expected outputs, to\nassist analyzing model behavior. We benchmark a variety of state-of-the-art\n(sota) T2I models and surprisingly find that, there is still a large gap\nbetween image synthesis and real life photos--even the DALL-E 3 model could\nonly achieve 48.92% on Commonsense-T2I, and the stable diffusion XL model only\nachieves 24.92% accuracy. Our experiments show that GPT-enriched prompts cannot\nsolve this challenge, and we include a detailed analysis about possible reasons\nfor such deficiency. We aim for Commonsense-T2I to serve as a high-quality\nevaluation benchmark for T2I commonsense checking, fostering advancements in\nreal life image generation.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "COLM 2024, Project Url: https://zeyofu.github.io/CommonsenseT2I/",
    "pdf_url": "http://arxiv.org/pdf/2406.07546v2",
    "published_date": "2024-06-11 17:59:48 UTC",
    "updated_date": "2024-08-12 19:33:52 UTC"
  },
  {
    "arxiv_id": "2406.07545v1",
    "title": "Open-LLM-Leaderboard: From Multi-choice to Open-style Questions for LLMs Evaluation, Benchmark, and Arena",
    "authors": [
      "Aidar Myrzakhan",
      "Sondos Mahmoud Bsharat",
      "Zhiqiang Shen"
    ],
    "abstract": "Multiple-choice questions (MCQ) are frequently used to assess large language\nmodels (LLMs). Typically, an LLM is given a question and selects the answer\ndeemed most probable after adjustments for factors like length. Unfortunately,\nLLMs may inherently favor certain answer choice IDs, such as A/B/C/D, due to\ninherent biases of priori unbalanced probabilities, influencing the prediction\nof answers based on these IDs. Previous research has introduced methods to\nreduce this ''selection bias'' by simply permutating options on a few test\nsamples and applying to new ones. Another problem of MCQ is the lottery ticket\nchoice by ''random guessing''. The LLM does not learn particular knowledge, but\nthe option is guessed correctly. This situation is especially serious for those\nsmall-scale LLMs. To address them, a more thorough approach involves shifting\nfrom MCQ to open-style questions, which can fundamentally eliminate selection\nbias and random guessing issues. However, transitioning causes its own set of\nchallenges in (1) identifying suitable open-style questions and (2) validating\nthe correctness of LLM open-style responses against human-annotated\nground-truths. This work aims to tackle these significant difficulties, and\nestablish a new LLM evaluation benchmark through entirely open-style questions.\nConsequently, we introduce the Open-LLM-Leaderboard to track various LLMs'\nperformance and reflect true capability of them, such as GPT-4o/4/3.5, Claude\n3, Gemini, etc. Our code and dataset are available at\nhttps://github.com/VILA-Lab/Open-LLM-Leaderboard.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Code and dataset are available at\n  https://github.com/VILA-Lab/Open-LLM-Leaderboard",
    "pdf_url": "http://arxiv.org/pdf/2406.07545v1",
    "published_date": "2024-06-11 17:59:47 UTC",
    "updated_date": "2024-06-11 17:59:47 UTC"
  },
  {
    "arxiv_id": "2406.07544v2",
    "title": "Situational Awareness Matters in 3D Vision Language Reasoning",
    "authors": [
      "Yunze Man",
      "Liang-Yan Gui",
      "Yu-Xiong Wang"
    ],
    "abstract": "Being able to carry out complicated vision language reasoning tasks in 3D\nspace represents a significant milestone in developing household robots and\nhuman-centered embodied AI. In this work, we demonstrate that a critical and\ndistinct challenge in 3D vision language reasoning is situational awareness,\nwhich incorporates two key components: (1) The autonomous agent grounds its\nself-location based on a language prompt. (2) The agent answers open-ended\nquestions from the perspective of its calculated position. To address this\nchallenge, we introduce SIG3D, an end-to-end Situation-Grounded model for 3D\nvision language reasoning. We tokenize the 3D scene into sparse voxel\nrepresentation and propose a language-grounded situation estimator, followed by\na situated question answering module. Experiments on the SQA3D and ScanQA\ndatasets show that SIG3D outperforms state-of-the-art models in situation\nestimation and question answering by a large margin (e.g., an enhancement of\nover 30% on situation estimation accuracy). Subsequent analysis corroborates\nour architectural design choices, explores the distinct functions of visual and\ntextual tokens, and highlights the importance of situational awareness in the\ndomain of 3D question answering.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2024. Project Page: https://yunzeman.github.io/situation3d",
    "pdf_url": "http://arxiv.org/pdf/2406.07544v2",
    "published_date": "2024-06-11 17:59:45 UTC",
    "updated_date": "2024-06-26 17:59:50 UTC"
  },
  {
    "arxiv_id": "2406.07542v1",
    "title": "Cognitive Insights Across Languages: Enhancing Multimodal Interview Analysis",
    "authors": [
      "David Ortiz-Perez",
      "Jose Garcia-Rodriguez",
      "David Tomás"
    ],
    "abstract": "Cognitive decline is a natural process that occurs as individuals age. Early\ndiagnosis of anomalous decline is crucial for initiating professional treatment\nthat can enhance the quality of life of those affected. To address this issue,\nwe propose a multimodal model capable of predicting Mild Cognitive Impairment\nand cognitive scores. The TAUKADIAL dataset is used to conduct the evaluation,\nwhich comprises audio recordings of clinical interviews. The proposed model\ndemonstrates the ability to transcribe and differentiate between languages used\nin the interviews. Subsequently, the model extracts audio and text features,\ncombining them into a multimodal architecture to achieve robust and generalized\nresults. Our approach involves in-depth research to implement various features\nobtained from the proposed modalities.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "GitHub repository: https://github.com/davidorp/taukadial",
    "pdf_url": "http://arxiv.org/pdf/2406.07542v1",
    "published_date": "2024-06-11 17:59:31 UTC",
    "updated_date": "2024-06-11 17:59:31 UTC"
  },
  {
    "arxiv_id": "2406.07524v2",
    "title": "Simple and Effective Masked Diffusion Language Models",
    "authors": [
      "Subham Sekhar Sahoo",
      "Marianne Arriola",
      "Yair Schiff",
      "Aaron Gokaslan",
      "Edgar Marroquin",
      "Justin T Chiu",
      "Alexander Rush",
      "Volodymyr Kuleshov"
    ],
    "abstract": "While diffusion models excel at generating high-quality images, prior work\nreports a significant performance gap between diffusion and autoregressive (AR)\nmethods in language modeling. In this work, we show that simple masked discrete\ndiffusion is more performant than previously thought. We apply an effective\ntraining recipe that improves the performance of masked diffusion models and\nderive a simplified, Rao-Blackwellized objective that results in additional\nimprovements. Our objective has a simple form -- it is a mixture of classical\nmasked language modeling losses -- and can be used to train encoder-only\nlanguage models that admit efficient samplers, including ones that can generate\narbitrary lengths of text semi-autoregressively like a traditional language\nmodel. On language modeling benchmarks, a range of masked diffusion models\ntrained with modern engineering practices achieves a new state-of-the-art among\ndiffusion models, and approaches AR perplexity. We provide the code, along with\na blog post and video tutorial on the project page: https://s-sahoo.com/mdlm",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "NeurIPS 2024. We provide the code at\n  https://github.com/kuleshov-group/mdlm",
    "pdf_url": "http://arxiv.org/pdf/2406.07524v2",
    "published_date": "2024-06-11 17:51:40 UTC",
    "updated_date": "2024-11-10 20:34:34 UTC"
  },
  {
    "arxiv_id": "2406.07520v3",
    "title": "Neural Gaffer: Relighting Any Object via Diffusion",
    "authors": [
      "Haian Jin",
      "Yuan Li",
      "Fujun Luan",
      "Yuanbo Xiangli",
      "Sai Bi",
      "Kai Zhang",
      "Zexiang Xu",
      "Jin Sun",
      "Noah Snavely"
    ],
    "abstract": "Single-image relighting is a challenging task that involves reasoning about\nthe complex interplay between geometry, materials, and lighting. Many prior\nmethods either support only specific categories of images, such as portraits,\nor require special capture conditions, like using a flashlight. Alternatively,\nsome methods explicitly decompose a scene into intrinsic components, such as\nnormals and BRDFs, which can be inaccurate or under-expressive. In this work,\nwe propose a novel end-to-end 2D relighting diffusion model, called Neural\nGaffer, that takes a single image of any object and can synthesize an accurate,\nhigh-quality relit image under any novel environmental lighting condition,\nsimply by conditioning an image generator on a target environment map, without\nan explicit scene decomposition. Our method builds on a pre-trained diffusion\nmodel, and fine-tunes it on a synthetic relighting dataset, revealing and\nharnessing the inherent understanding of lighting present in the diffusion\nmodel. We evaluate our model on both synthetic and in-the-wild Internet imagery\nand demonstrate its advantages in terms of generalization and accuracy.\nMoreover, by combining with other generative methods, our model enables many\ndownstream 2D tasks, such as text-based relighting and object insertion. Our\nmodel can also operate as a strong relighting prior for 3D tasks, such as\nrelighting a radiance field.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "Project Website: https://neural-gaffer.github.io",
    "pdf_url": "http://arxiv.org/pdf/2406.07520v3",
    "published_date": "2024-06-11 17:50:15 UTC",
    "updated_date": "2024-11-12 01:45:49 UTC"
  },
  {
    "arxiv_id": "2406.07515v2",
    "title": "Beyond Model Collapse: Scaling Up with Synthesized Data Requires Verification",
    "authors": [
      "Yunzhen Feng",
      "Elvis Dohmatob",
      "Pu Yang",
      "Francois Charton",
      "Julia Kempe"
    ],
    "abstract": "Large Language Models (LLM) are increasingly trained on data generated by\nother LLM, either because generated text and images become part of the\npre-training corpus, or because synthetized data is used as a replacement for\nexpensive human-annotation. This raises concerns about \\emph{model collapse}, a\ndrop in model performance when their training sets include generated data.\nConsidering that it is easier for both humans and machines to tell between good\nand bad examples than to generate high-quality samples, we investigate the use\nof verification on synthesized data to prevent model collapse. We provide a\ntheoretical characterization using Gaussian mixtures, linear classifiers, and\nlinear verifiers to derive conditions with measurable proxies to assess whether\nthe verifier can effectively select synthesized data that leads to optimal\nperformance. We experiment with two practical tasks -- computing matrix\neigenvalues with transformers and news summarization with LLMs -- which both\nexhibit model collapse when trained on generated data, and show that verifiers,\neven imperfect ones, can indeed be harnessed to prevent model collapse and that\nour proposed proxy measure strongly correlates with performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07515v2",
    "published_date": "2024-06-11 17:46:16 UTC",
    "updated_date": "2024-10-25 03:38:41 UTC"
  },
  {
    "arxiv_id": "2406.07506v1",
    "title": "Understanding Visual Concepts Across Models",
    "authors": [
      "Brandon Trabucco",
      "Max Gurinas",
      "Kyle Doherty",
      "Ruslan Salakhutdinov"
    ],
    "abstract": "Large multimodal models such as Stable Diffusion can generate, detect, and\nclassify new visual concepts after fine-tuning just a single word embedding. Do\nmodels learn similar words for the same concepts (i.e. <orange-cat> = orange +\ncat)? We conduct a large-scale analysis on three state-of-the-art models in\ntext-to-image generation, open-set object detection, and zero-shot\nclassification, and find that new word embeddings are model-specific and\nnon-transferable. Across 4,800 new embeddings trained for 40 diverse visual\nconcepts on four standard datasets, we find perturbations within an\n$\\epsilon$-ball to any prior embedding that generate, detect, and classify an\narbitrary concept. When these new embeddings are spliced into new models,\nfine-tuning that targets the original model is lost. We show popular soft\nprompt-tuning approaches find these perturbative solutions when applied to\nvisual concept learning tasks, and embeddings for visual concepts are not\ntransferable. Code for reproducing our work is available at:\nhttps://visual-words.github.io.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Official code at: https://github.com/visual-words/visual-words",
    "pdf_url": "http://arxiv.org/pdf/2406.07506v1",
    "published_date": "2024-06-11 17:40:31 UTC",
    "updated_date": "2024-06-11 17:40:31 UTC"
  },
  {
    "arxiv_id": "2406.07496v1",
    "title": "TextGrad: Automatic \"Differentiation\" via Text",
    "authors": [
      "Mert Yuksekgonul",
      "Federico Bianchi",
      "Joseph Boen",
      "Sheng Liu",
      "Zhi Huang",
      "Carlos Guestrin",
      "James Zou"
    ],
    "abstract": "AI is undergoing a paradigm shift, with breakthroughs achieved by systems\norchestrating multiple large language models (LLMs) and other complex\ncomponents. As a result, developing principled and automated optimization\nmethods for compound AI systems is one of the most important new challenges.\nNeural networks faced a similar challenge in its early days until\nbackpropagation and automatic differentiation transformed the field by making\noptimization turn-key. Inspired by this, we introduce TextGrad, a powerful\nframework performing automatic ``differentiation'' via text. TextGrad\nbackpropagates textual feedback provided by LLMs to improve individual\ncomponents of a compound AI system. In our framework, LLMs provide rich,\ngeneral, natural language suggestions to optimize variables in computation\ngraphs, ranging from code snippets to molecular structures. TextGrad follows\nPyTorch's syntax and abstraction and is flexible and easy-to-use. It works\nout-of-the-box for a variety of tasks, where the users only provide the\nobjective function without tuning components or prompts of the framework. We\nshowcase TextGrad's effectiveness and generality across a diverse range of\napplications, from question answering and molecule optimization to radiotherapy\ntreatment planning. Without modifying the framework, TextGrad improves the\nzero-shot accuracy of GPT-4o in Google-Proof Question Answering from $51\\%$ to\n$55\\%$, yields $20\\%$ relative performance gain in optimizing LeetCode-Hard\ncoding problem solutions, improves prompts for reasoning, designs new druglike\nsmall molecules with desirable in silico binding, and designs radiation\noncology treatment plans with high specificity. TextGrad lays a foundation to\naccelerate the development of the next-generation of AI systems.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "41 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.07496v1",
    "published_date": "2024-06-11 17:32:21 UTC",
    "updated_date": "2024-06-11 17:32:21 UTC"
  },
  {
    "arxiv_id": "2406.07494v3",
    "title": "CADS: A Systematic Literature Review on the Challenges of Abstractive Dialogue Summarization",
    "authors": [
      "Frederic Kirstein",
      "Jan Philip Wahle",
      "Bela Gipp",
      "Terry Ruas"
    ],
    "abstract": "Abstractive dialogue summarization is the task of distilling conversations\ninto informative and concise summaries. Although reviews have been conducted on\nthis topic, there is a lack of comprehensive work detailing the challenges of\ndialogue summarization, unifying the differing understanding of the task, and\naligning proposed techniques, datasets, and evaluation metrics with the\nchallenges. This article summarizes the research on Transformer-based\nabstractive summarization for English dialogues by systematically reviewing\n1262 unique research papers published between 2019 and 2024, relying on the\nSemantic Scholar and DBLP databases. We cover the main challenges present in\ndialog summarization (i.e., language, structure, comprehension, speaker,\nsalience, and factuality) and link them to corresponding techniques such as\ngraph-based approaches, additional training tasks, and planning strategies,\nwhich typically overly rely on BART-based encoder-decoder models. We find that\nwhile some challenges, like language, have seen considerable progress, mainly\ndue to training methods, others, such as comprehension, factuality, and\nsalience, remain difficult and hold significant research opportunities. We\ninvestigate how these approaches are typically assessed, covering the datasets\nfor the subdomains of dialogue (e.g., meeting, medical), the established\nautomatic metrics and human evaluation approaches for assessing scores and\nannotator agreement. We observe that only a few datasets span across all\nsubdomains. The ROUGE metric is the most used, while human evaluation is\nfrequently reported without sufficient detail on inner-annotator agreement and\nannotation guidelines. Additionally, we discuss the possible implications of\nthe recently explored large language models and conclude that despite a\npotential shift in relevance and difficulty, our described challenge taxonomy\nremains relevant.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Published in the Journal of Artificial Intelligence Research (JAIR)\n  (https://www.jair.org/index.php/jair/article/view/16674)",
    "pdf_url": "http://arxiv.org/pdf/2406.07494v3",
    "published_date": "2024-06-11 17:30:22 UTC",
    "updated_date": "2025-04-23 18:00:46 UTC"
  },
  {
    "arxiv_id": "2406.07440v2",
    "title": "Textual Similarity as a Key Metric in Machine Translation Quality Estimation",
    "authors": [
      "Kun Sun",
      "Rong Wang"
    ],
    "abstract": "Machine Translation (MT) Quality Estimation (QE) assesses translation\nreliability without reference texts. This study introduces \"textual similarity\"\nas a new metric for QE, using sentence transformers and cosine similarity to\nmeasure semantic closeness. Analyzing data from the MLQE-PE dataset, we found\nthat textual similarity exhibits stronger correlations with human scores than\ntraditional metrics (hter, model evaluation, sentence probability etc.).\nEmploying GAMMs as a statistical tool, we demonstrated that textual similarity\nconsistently outperforms other metrics across multiple language pairs in\npredicting human scores. We also found that \"hter\" actually failed to predict\nhuman scores in QE. Our findings highlight the effectiveness of textual\nsimilarity as a robust QE metric, recommending its integration with other\nmetrics into QE frameworks and MT system training for improved accuracy and\nusability.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07440v2",
    "published_date": "2024-06-11 16:48:17 UTC",
    "updated_date": "2024-07-01 09:30:34 UTC"
  },
  {
    "arxiv_id": "2406.07599v3",
    "title": "CTIBench: A Benchmark for Evaluating LLMs in Cyber Threat Intelligence",
    "authors": [
      "Md Tanvirul Alam",
      "Dipkamal Bhusal",
      "Le Nguyen",
      "Nidhi Rastogi"
    ],
    "abstract": "Cyber threat intelligence (CTI) is crucial in today's cybersecurity\nlandscape, providing essential insights to understand and mitigate the\never-evolving cyber threats. The recent rise of Large Language Models (LLMs)\nhave shown potential in this domain, but concerns about their reliability,\naccuracy, and hallucinations persist. While existing benchmarks provide general\nevaluations of LLMs, there are no benchmarks that address the practical and\napplied aspects of CTI-specific tasks. To bridge this gap, we introduce\nCTIBench, a benchmark designed to assess LLMs' performance in CTI applications.\nCTIBench includes multiple datasets focused on evaluating knowledge acquired by\nLLMs in the cyber-threat landscape. Our evaluation of several state-of-the-art\nmodels on these tasks provides insights into their strengths and weaknesses in\nCTI contexts, contributing to a better understanding of LLM capabilities in\nCTI.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07599v3",
    "published_date": "2024-06-11 16:42:02 UTC",
    "updated_date": "2024-11-11 12:00:35 UTC"
  },
  {
    "arxiv_id": "2406.07428v3",
    "title": "GemNet: Menu-Based, Strategy-Proof Multi-Bidder Auctions Through Deep Learning",
    "authors": [
      "Tonghan Wang",
      "Yanchen Jiang",
      "David C. Parkes"
    ],
    "abstract": "Automated mechanism design (AMD) uses computational methods for mechanism\ndesign. Differentiable economics is a form of AMD that uses deep learning to\nlearn mechanism designs and has enabled strong progress in AMD in recent years.\nNevertheless, a major open problem has been to learn multi-bidder, general, and\nfully strategy-proof (SP) auctions. We introduce GEneral Menu-based NETwork\n(GemNet), which significantly extends the menu-based approach of the\nsingle-bidder RochetNet (D\\\"utting et al., 2024) to the multi-bidder setting.\nThe challenge in achieving SP is to learn bidder-independent menus that are\nfeasible, so that the optimal menu choices for each bidder do not over-allocate\nitems when taken together (we call this menu compatibility). GemNet penalizes\nthe failure of menu compatibility during training, and transforms learned menus\nafter training through price changes, by considering a set of discretized\nbidder values and reasoning about Lipschitz smoothness to guarantee menu\ncompatibility on the entire value space. This approach is general, leaving\ntrained menus that already satisfy menu compatibility undisturbed and reducing\nto RochetNet for a single bidder. Mixed-integer linear programs are used for\nmenu transforms, and through a number of optimizations enabled by deep\nlearning, including adaptive grids and methods to skip menu elements, we scale\nto large auction design problems. GemNet learns auctions with better revenue\nthan affine maximization methods, achieves exact SP whereas previous general\nmulti-bidder methods are approximately SP, and offers greatly enhanced\ninterpretability.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.GT",
    "comment": "This paper received the Exemplary Paper Award for the AI track at the\n  Twenty-Fifth ACM Conference on Economics and Computation (ACM EC '24), where\n  it appeared as an extended abstract; The first two authors contributed\n  equally to this work",
    "pdf_url": "http://arxiv.org/pdf/2406.07428v3",
    "published_date": "2024-06-11 16:30:30 UTC",
    "updated_date": "2024-11-05 16:37:19 UTC"
  },
  {
    "arxiv_id": "2406.07423v1",
    "title": "Beyond ELBOs: A Large-Scale Evaluation of Variational Methods for Sampling",
    "authors": [
      "Denis Blessing",
      "Xiaogang Jia",
      "Johannes Esslinger",
      "Francisco Vargas",
      "Gerhard Neumann"
    ],
    "abstract": "Monte Carlo methods, Variational Inference, and their combinations play a\npivotal role in sampling from intractable probability distributions. However,\ncurrent studies lack a unified evaluation framework, relying on disparate\nperformance measures and limited method comparisons across diverse tasks,\ncomplicating the assessment of progress and hindering the decision-making of\npractitioners. In response to these challenges, our work introduces a benchmark\nthat evaluates sampling methods using a standardized task suite and a broad\nrange of performance criteria. Moreover, we study existing metrics for\nquantifying mode collapse and introduce novel metrics for this purpose. Our\nfindings provide insights into strengths and weaknesses of existing sampling\nmethods, serving as a valuable reference for future developments. The code is\npublicly available here.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07423v1",
    "published_date": "2024-06-11 16:23:33 UTC",
    "updated_date": "2024-06-11 16:23:33 UTC"
  },
  {
    "arxiv_id": "2406.07418v1",
    "title": "Enhanced Gene Selection in Single-Cell Genomics: Pre-Filtering Synergy and Reinforced Optimization",
    "authors": [
      "Weiliang Zhang",
      "Zhen Meng",
      "Dongjie Wang",
      "Min Wu",
      "Kunpeng Liu",
      "Yuanchun Zhou",
      "Meng Xiao"
    ],
    "abstract": "Recent advancements in single-cell genomics necessitate precision in gene\npanel selection to interpret complex biological data effectively. Those methods\naim to streamline the analysis of scRNA-seq data by focusing on the most\ninformative genes that contribute significantly to the specific analysis task.\nTraditional selection methods, which often rely on expert domain knowledge,\nembedded machine learning models, or heuristic-based iterative optimization,\nare prone to biases and inefficiencies that may obscure critical genomic\nsignals. Recognizing the limitations of traditional methods, we aim to\ntranscend these constraints with a refined strategy. In this study, we\nintroduce an iterative gene panel selection strategy that is applicable to\nclustering tasks in single-cell genomics. Our method uniquely integrates\nresults from other gene selection algorithms, providing valuable preliminary\nboundaries or prior knowledge as initial guides in the search space to enhance\nthe efficiency of our framework. Furthermore, we incorporate the stochastic\nnature of the exploration process in reinforcement learning (RL) and its\ncapability for continuous optimization through reward-based feedback. This\ncombination mitigates the biases inherent in the initial boundaries and\nharnesses RL's adaptability to refine and target gene panel selection\ndynamically. To illustrate the effectiveness of our method, we conducted\ndetailed comparative experiments, case studies, and visualization analysis.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "q-bio.GN"
    ],
    "primary_category": "cs.AI",
    "comment": "25 pages",
    "pdf_url": "http://arxiv.org/pdf/2406.07418v1",
    "published_date": "2024-06-11 16:21:33 UTC",
    "updated_date": "2024-06-11 16:21:33 UTC"
  },
  {
    "arxiv_id": "2406.10269v1",
    "title": "Markov Constraint as Large Language Model Surrogate",
    "authors": [
      "Alexandre Bonlarron",
      "Jean-Charles Régin"
    ],
    "abstract": "This paper presents NgramMarkov, a variant of the Markov constraints. It is\ndedicated to text generation in constraint programming (CP). It involves a set\nof n-grams (i.e., sequence of n words) associated with probabilities given by a\nlarge language model (LLM). It limits the product of the probabilities of the\nn-gram of a sentence. The propagator of this constraint can be seen as an\nextension of the ElementaryMarkov constraint propagator, incorporating the LLM\ndistribution instead of the maximum likelihood estimation of n-grams. It uses a\ngliding threshold, i.e., it rejects n-grams whose local probabilities are too\nlow, to guarantee balanced solutions. It can also be combined with a\n\"look-ahead\" approach to remove n-grams that are very unlikely to lead to\nacceptable sentences for a fixed-length horizon. This idea is based on the\nMDDMarkovProcess constraint propagator, but without explicitly using an MDD\n(Multi-Valued Decision Diagram). The experimental results show that the\ngenerated text is valued in a similar way to the LLM perplexity function. Using\nthis new constraint dramatically reduces the number of candidate sentences\nproduced, improves computation times, and allows larger corpora or smaller\nn-grams to be used. A real-world problem has been solved for the first time\nusing 4-grams instead of 5-grams.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "To appear at The 33rd International Joint Conference on Artificial\n  Intelligence, IJCAI-24 (in press)",
    "pdf_url": "http://arxiv.org/pdf/2406.10269v1",
    "published_date": "2024-06-11 16:09:53 UTC",
    "updated_date": "2024-06-11 16:09:53 UTC"
  },
  {
    "arxiv_id": "2406.07398v2",
    "title": "Visual Representation Learning with Stochastic Frame Prediction",
    "authors": [
      "Huiwon Jang",
      "Dongyoung Kim",
      "Junsu Kim",
      "Jinwoo Shin",
      "Pieter Abbeel",
      "Younggyo Seo"
    ],
    "abstract": "Self-supervised learning of image representations by predicting future frames\nis a promising direction but still remains a challenge. This is because of the\nunder-determined nature of frame prediction; multiple potential futures can\narise from a single current frame. To tackle this challenge, in this paper, we\nrevisit the idea of stochastic video generation that learns to capture\nuncertainty in frame prediction and explore its effectiveness for\nrepresentation learning. Specifically, we design a framework that trains a\nstochastic frame prediction model to learn temporal information between frames.\nMoreover, to learn dense information within each frame, we introduce an\nauxiliary masked image modeling objective along with a shared decoder\narchitecture. We find this architecture allows for combining both objectives in\na synergistic and compute-efficient manner. We demonstrate the effectiveness of\nour framework on a variety of tasks from video label propagation and\nvision-based robot learning domains, such as video segmentation, pose tracking,\nvision-based robotic locomotion, and manipulation tasks. Code is available on\nthe project webpage: https://sites.google.com/view/2024rsp.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "International Conference on Machine Learning (ICML) 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.07398v2",
    "published_date": "2024-06-11 16:05:15 UTC",
    "updated_date": "2024-08-08 19:48:10 UTC"
  },
  {
    "arxiv_id": "2406.07394v2",
    "title": "Accessing GPT-4 level Mathematical Olympiad Solutions via Monte Carlo Tree Self-refine with LLaMa-3 8B",
    "authors": [
      "Di Zhang",
      "Xiaoshui Huang",
      "Dongzhan Zhou",
      "Yuqiang Li",
      "Wanli Ouyang"
    ],
    "abstract": "This paper introduces the MCT Self-Refine (MCTSr) algorithm, an innovative\nintegration of Large Language Models (LLMs) with Monte Carlo Tree Search\n(MCTS), designed to enhance performance in complex mathematical reasoning\ntasks. Addressing the challenges of accuracy and reliability in LLMs,\nparticularly in strategic and mathematical reasoning, MCTSr leverages\nsystematic exploration and heuristic self-refine mechanisms to improve\ndecision-making frameworks within LLMs. The algorithm constructs a Monte Carlo\nsearch tree through iterative processes of Selection, self-refine,\nself-evaluation, and Backpropagation, utilizing an improved Upper Confidence\nBound (UCB) formula to optimize the exploration-exploitation balance. Extensive\nexperiments demonstrate MCTSr's efficacy in solving Olympiad-level mathematical\nproblems, significantly improving success rates across multiple datasets,\nincluding GSM8K, GSM Hard, MATH, and Olympiad-level benchmarks, including Math\nOdyssey, AIME, and OlympiadBench. The study advances the application of LLMs in\ncomplex reasoning tasks and sets a foundation for future AI integration,\nenhancing decision-making accuracy and reliability in LLM-driven applications.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07394v2",
    "published_date": "2024-06-11 16:01:07 UTC",
    "updated_date": "2024-06-13 07:19:06 UTC"
  },
  {
    "arxiv_id": "2406.07381v1",
    "title": "World Models with Hints of Large Language Models for Goal Achieving",
    "authors": [
      "Zeyuan Liu",
      "Ziyu Huan",
      "Xiyao Wang",
      "Jiafei Lyu",
      "Jian Tao",
      "Xiu Li",
      "Furong Huang",
      "Huazhe Xu"
    ],
    "abstract": "Reinforcement learning struggles in the face of long-horizon tasks and sparse\ngoals due to the difficulty in manual reward specification. While existing\nmethods address this by adding intrinsic rewards, they may fail to provide\nmeaningful guidance in long-horizon decision-making tasks with large state and\naction spaces, lacking purposeful exploration. Inspired by human cognition, we\npropose a new multi-modal model-based RL approach named Dreaming with Large\nLanguage Models (DLLM). DLLM integrates the proposed hinting subgoals from the\nLLMs into the model rollouts to encourage goal discovery and reaching in\nchallenging tasks. By assigning higher intrinsic rewards to samples that align\nwith the hints outlined by the language model during model rollouts, DLLM\nguides the agent toward meaningful and efficient exploration. Extensive\nexperiments demonstrate that the DLLM outperforms recent methods in various\nchallenging, sparse-reward environments such as HomeGrid, Crafter, and\nMinecraft by 27.7\\%, 21.1\\%, and 9.9\\%, respectively.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07381v1",
    "published_date": "2024-06-11 15:49:08 UTC",
    "updated_date": "2024-06-11 15:49:08 UTC"
  },
  {
    "arxiv_id": "2406.07378v1",
    "title": "Large Language Models for Constrained-Based Causal Discovery",
    "authors": [
      "Kai-Hendrik Cohrs",
      "Gherardo Varando",
      "Emiliano Diaz",
      "Vasileios Sitokonstantinou",
      "Gustau Camps-Valls"
    ],
    "abstract": "Causality is essential for understanding complex systems, such as the\neconomy, the brain, and the climate. Constructing causal graphs often relies on\neither data-driven or expert-driven approaches, both fraught with challenges.\nThe former methods, like the celebrated PC algorithm, face issues with data\nrequirements and assumptions of causal sufficiency, while the latter demand\nsubstantial time and domain knowledge. This work explores the capabilities of\nLarge Language Models (LLMs) as an alternative to domain experts for causal\ngraph generation. We frame conditional independence queries as prompts to LLMs\nand employ the PC algorithm with the answers. The performance of the LLM-based\nconditional independence oracle on systems with known causal graphs shows a\nhigh degree of variability. We improve the performance through a proposed\nstatistical-inspired voting schema that allows some control over false-positive\nand false-negative rates. Inspecting the chain-of-thought argumentation, we\nfind causal reasoning to justify its answer to a probabilistic query. We show\nevidence that knowledge-based CIT could eventually become a complementary tool\nfor data-driven causal discovery.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07378v1",
    "published_date": "2024-06-11 15:45:24 UTC",
    "updated_date": "2024-06-11 15:45:24 UTC"
  },
  {
    "arxiv_id": "2406.07368v2",
    "title": "When Linear Attention Meets Autoregressive Decoding: Towards More Effective and Efficient Linearized Large Language Models",
    "authors": [
      "Haoran You",
      "Yichao Fu",
      "Zheng Wang",
      "Amir Yazdanbakhsh",
      "Yingyan Celine Lin"
    ],
    "abstract": "Autoregressive Large Language Models (LLMs) have achieved impressive\nperformance in language tasks but face two significant bottlenecks: (1)\nquadratic complexity in the attention module as the number of tokens increases,\nand (2) limited efficiency due to the sequential processing nature of\nautoregressive LLMs during generation. While linear attention and speculative\ndecoding offer potential solutions, their applicability and synergistic\npotential for enhancing autoregressive LLMs remain uncertain. We conduct the\nfirst comprehensive study on the efficacy of existing linear attention methods\nfor autoregressive LLMs, integrating them with speculative decoding. We\nintroduce an augmentation technique for linear attention that ensures\ncompatibility with speculative decoding, enabling more efficient training and\nserving of LLMs. Extensive experiments and ablation studies involving seven\nexisting linear attention models and five encoder/decoder-based LLMs\nconsistently validate the effectiveness of our augmented linearized LLMs.\nNotably, our approach achieves up to a 6.67 reduction in perplexity on the\nLLaMA model and up to a 2$\\times$ speedup during generation compared to prior\nlinear attention methods. Codes and models are available at\nhttps://github.com/GATECH-EIC/Linearized-LLM.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by ICML 2024; 17 pages; 10 figures; 16 tables",
    "pdf_url": "http://arxiv.org/pdf/2406.07368v2",
    "published_date": "2024-06-11 15:34:43 UTC",
    "updated_date": "2024-07-25 17:18:01 UTC"
  },
  {
    "arxiv_id": "2406.07365v1",
    "title": "BvSP: Broad-view Soft Prompting for Few-Shot Aspect Sentiment Quad Prediction",
    "authors": [
      "Yinhao Bai",
      "Yalan Xie",
      "Xiaoyi Liu",
      "Yuhua Zhao",
      "Zhixin Han",
      "Mengting Hu",
      "Hang Gao",
      "Renhong Cheng"
    ],
    "abstract": "Aspect sentiment quad prediction (ASQP) aims to predict four aspect-based\nelements, including aspect term, opinion term, aspect category, and sentiment\npolarity. In practice, unseen aspects, due to distinct data distribution,\nimpose many challenges for a trained neural model. Motivated by this, this work\nformulates ASQP into the few-shot scenario, which aims for fast adaptation in\nreal applications. Therefore, we first construct a few-shot ASQP dataset (FSQP)\nthat contains richer categories and is more balanced for the few-shot study.\nMoreover, recent methods extract quads through a generation paradigm, which\ninvolves converting the input sentence into a templated target sequence.\nHowever, they primarily focus on the utilization of a single template or the\nconsideration of different template orders, thereby overlooking the\ncorrelations among various templates. To tackle this issue, we further propose\na Broadview Soft Prompting (BvSP) method that aggregates multiple templates\nwith a broader view by taking into account the correlation between the\ndifferent templates. Specifically, BvSP uses the pre-trained language model to\nselect the most relevant k templates with Jensen-Shannon divergence. BvSP\nfurther introduces soft prompts to guide the pre-trained language model using\nthe selected templates. Then, we aggregate the results of multi-templates by\nvoting mechanism. Empirical results demonstrate that BvSP significantly\noutperforms the stateof-the-art methods under four few-shot settings and other\npublic datasets. Our code and dataset are available at\nhttps://github.com/byinhao/BvSP.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ACL 2024 Main Conference",
    "pdf_url": "http://arxiv.org/pdf/2406.07365v1",
    "published_date": "2024-06-11 15:32:32 UTC",
    "updated_date": "2024-06-11 15:32:32 UTC"
  },
  {
    "arxiv_id": "2406.10268v2",
    "title": "Autograding Mathematical Induction Proofs with Natural Language Processing",
    "authors": [
      "Chenyan Zhao",
      "Mariana Silva",
      "Seth Poulsen"
    ],
    "abstract": "In mathematical proof education, there remains a need for interventions that\nhelp students learn to write mathematical proofs. Research has shown that\ntimely feedback can be very helpful to students learning new skills. While for\nmany years natural language processing models have struggled to perform well on\ntasks related to mathematical texts, recent developments in natural language\nprocessing have created the opportunity to complete the task of giving students\ninstant feedback on their mathematical proofs. In this paper, we present a set\nof training methods and models capable of autograding freeform mathematical\nproofs by leveraging existing large language models and other machine learning\ntechniques. The models are trained using proof data collected from four\ndifferent proof by induction problems. We use four different robust large\nlanguage models to compare their performances, and all achieve satisfactory\nperformances to various degrees. Additionally, we recruit human graders to\ngrade the same proofs as the training data, and find that the best grading\nmodel is also more accurate than most human graders. With the development of\nthese grading models, we create and deploy an autograder for proof by induction\nproblems and perform a user study with students. Results from the study shows\nthat students are able to make significant improvements to their proofs using\nthe feedback from the autograder, but students still do not trust the AI\nautograders as much as they trust human graders. Future work can improve on the\nautograder feedback and figure out ways to help students trust AI autograders.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.10268v2",
    "published_date": "2024-06-11 15:30:26 UTC",
    "updated_date": "2025-02-19 06:18:20 UTC"
  },
  {
    "arxiv_id": "2406.07358v4",
    "title": "AI Sandbagging: Language Models can Strategically Underperform on Evaluations",
    "authors": [
      "Teun van der Weij",
      "Felix Hofstätter",
      "Ollie Jaffe",
      "Samuel F. Brown",
      "Francis Rhys Ward"
    ],
    "abstract": "Trustworthy capability evaluations are crucial for ensuring the safety of AI\nsystems, and are becoming a key component of AI regulation. However, the\ndevelopers of an AI system, or the AI system itself, may have incentives for\nevaluations to understate the AI's actual capability. These conflicting\ninterests lead to the problem of sandbagging, which we define as strategic\nunderperformance on an evaluation. In this paper we assess sandbagging\ncapabilities in contemporary language models (LMs). We prompt frontier LMs,\nlike GPT-4 and Claude 3 Opus, to selectively underperform on dangerous\ncapability evaluations, while maintaining performance on general (harmless)\ncapability evaluations. Moreover, we find that models can be fine-tuned, on a\nsynthetic dataset, to hide specific capabilities unless given a password. This\nbehaviour generalizes to high-quality, held-out benchmarks such as WMDP. In\naddition, we show that both frontier and smaller models can be prompted or\npassword-locked to target specific scores on a capability evaluation. We have\nmediocre success in password-locking a model to mimic the answers a weaker\nmodel would give. Overall, our results suggest that capability evaluations are\nvulnerable to sandbagging. This vulnerability decreases the trustworthiness of\nevaluations, and thereby undermines important safety decisions regarding the\ndevelopment and deployment of advanced AI systems.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07358v4",
    "published_date": "2024-06-11 15:26:57 UTC",
    "updated_date": "2025-02-06 20:58:43 UTC"
  },
  {
    "arxiv_id": "2406.07353v1",
    "title": "Toxic Memes: A Survey of Computational Perspectives on the Detection and Explanation of Meme Toxicities",
    "authors": [
      "Delfina Sol Martinez Pandiani",
      "Erik Tjong Kim Sang",
      "Davide Ceolin"
    ],
    "abstract": "Internet memes, channels for humor, social commentary, and cultural\nexpression, are increasingly used to spread toxic messages. Studies on the\ncomputational analyses of toxic memes have significantly grown over the past\nfive years, and the only three surveys on computational toxic meme analysis\ncover only work published until 2022, leading to inconsistent terminology and\nunexplored trends. Our work fills this gap by surveying content-based\ncomputational perspectives on toxic memes, and reviewing key developments until\nearly 2024. Employing the PRISMA methodology, we systematically extend the\npreviously considered papers, achieving a threefold result. First, we survey\n119 new papers, analyzing 158 computational works focused on content-based\ntoxic meme analysis. We identify over 30 datasets used in toxic meme analysis\nand examine their labeling systems. Second, after observing the existence of\nunclear definitions of meme toxicity in computational works, we introduce a new\ntaxonomy for categorizing meme toxicity types. We also note an expansion in\ncomputational tasks beyond the simple binary classification of memes as toxic\nor non-toxic, indicating a shift towards achieving a nuanced comprehension of\ntoxicity. Third, we identify three content-based dimensions of meme toxicity\nunder automatic study: target, intent, and conveyance tactics. We develop a\nframework illustrating the relationships between these dimensions and meme\ntoxicities. The survey analyzes key challenges and recent trends, such as\nenhanced cross-modal reasoning, integrating expert and cultural knowledge, the\ndemand for automatic toxicity explanations, and handling meme toxicity in\nlow-resource languages. Also, it notes the rising use of Large Language Models\n(LLMs) and generative AI for detecting and generating toxic memes. Finally, it\nproposes pathways for advancing toxic meme detection and interpretation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.CY",
      "cs.SI"
    ],
    "primary_category": "cs.CL",
    "comment": "39 pages, 12 figures, 9 tables",
    "pdf_url": "http://arxiv.org/pdf/2406.07353v1",
    "published_date": "2024-06-11 15:22:48 UTC",
    "updated_date": "2024-06-11 15:22:48 UTC"
  },
  {
    "arxiv_id": "2406.07340v1",
    "title": "Formally Verified Approximate Policy Iteration",
    "authors": [
      "Maximilian Schäffeler",
      "Mohammad Abdulaziz"
    ],
    "abstract": "We formally verify an algorithm for approximate policy iteration on Factored\nMarkov Decision Processes using the interactive theorem prover Isabelle/HOL.\nNext, we show how the formalized algorithm can be refined to an executable,\nverified implementation. The implementation is evaluated on benchmark problems\nto show its practicability. As part of the refinement, we develop verified\nsoftware to certify Linear Programming solutions. The algorithm builds on a\ndiverse library of formalized mathematics and pushes existing methodologies for\ninteractive theorem provers to the limits. We discuss the process of the\nverification project and the modifications to the algorithm needed for formal\nverification.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07340v1",
    "published_date": "2024-06-11 15:07:08 UTC",
    "updated_date": "2024-06-11 15:07:08 UTC"
  },
  {
    "arxiv_id": "2406.07330v1",
    "title": "CTC-based Non-autoregressive Textless Speech-to-Speech Translation",
    "authors": [
      "Qingkai Fang",
      "Zhengrui Ma",
      "Yan Zhou",
      "Min Zhang",
      "Yang Feng"
    ],
    "abstract": "Direct speech-to-speech translation (S2ST) has achieved impressive\ntranslation quality, but it often faces the challenge of slow decoding due to\nthe considerable length of speech sequences. Recently, some research has turned\nto non-autoregressive (NAR) models to expedite decoding, yet the translation\nquality typically lags behind autoregressive (AR) models significantly. In this\npaper, we investigate the performance of CTC-based NAR models in S2ST, as these\nmodels have shown impressive results in machine translation. Experimental\nresults demonstrate that by combining pretraining, knowledge distillation, and\nadvanced NAR training techniques such as glancing training and non-monotonic\nlatent alignments, CTC-based NAR models achieve translation quality comparable\nto the AR model, while preserving up to 26.81$\\times$ decoding speedup.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SD",
      "eess.AS",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL 2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2406.07330v1",
    "published_date": "2024-06-11 15:00:33 UTC",
    "updated_date": "2024-06-11 15:00:33 UTC"
  },
  {
    "arxiv_id": "2406.07327v2",
    "title": "3D-Properties: Identifying Challenges in DPO and Charting a Path Forward",
    "authors": [
      "Yuzi Yan",
      "Yibo Miao",
      "Jialian Li",
      "Yipin Zhang",
      "Jian Xie",
      "Zhijie Deng",
      "Dong Yan"
    ],
    "abstract": "Aligning large language models (LLMs) with human preferences has gained\nsignificant attention, with Proximal Policy Optimization (PPO) as a standard\nyet computationally expensive method and Direct Preference Optimization (DPO)\nas a more efficient alternative. While DPO offers simplicity, it remains\nunderutilized in state-of-the-art LLMs, suggesting potential limitations. In\nthis work, we revisit DPO, analyzing its theoretical foundations and empirical\nperformance to bridge this gap. We identify three key properties, termed 3D\nproperties, that emerge from DPO's learning process: Drastic drop in rejected\nresponse likelihood, Degradation into response suppression, and Dispersion\neffect on unseen responses. We show that these issues arise from DPO's\noptimization dynamics, where the interaction between chosen and rejected\nresponse gradients leads to instability. Our findings are supported by\nexperiments on both a controlled toy model and real-world LLM tasks, including\nmathematical problem-solving and instruction following. To address these\nchallenges, we propose simple regularization techniques that improve training\nstability and performance. Additionally, we examine how preference data\ndistribution impacts DPO's effectiveness, offering insights into how alignment\nmodels handle out-of-domain (OOD) data. Our work connects these observations to\nbroader research and provides a theoretical explanation for DPO's limitations.\nWe hope these insights will guide future advancements in reward-model-free\npreference learning, bringing it closer to reward-model-based approaches.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07327v2",
    "published_date": "2024-06-11 14:59:24 UTC",
    "updated_date": "2025-02-07 00:02:26 UTC"
  },
  {
    "arxiv_id": "2406.07325v1",
    "title": "Beyond Training: Optimizing Reinforcement Learning Based Job Shop Scheduling Through Adaptive Action Sampling",
    "authors": [
      "Constantin Waubert de Puiseau",
      "Christian Dörpelkus",
      "Jannik Peters",
      "Hasan Tercan",
      "Tobias Meisen"
    ],
    "abstract": "Learned construction heuristics for scheduling problems have become\nincreasingly competitive with established solvers and heuristics in recent\nyears. In particular, significant improvements have been observed in solution\napproaches using deep reinforcement learning (DRL). While much attention has\nbeen paid to the design of network architectures and training algorithms to\nachieve state-of-the-art results, little research has investigated the optimal\nuse of trained DRL agents during inference. Our work is based on the hypothesis\nthat, similar to search algorithms, the utilization of trained DRL agents\nshould be dependent on the acceptable computational budget. We propose a simple\nyet effective parameterization, called $\\delta$-sampling that manipulates the\ntrained action vector to bias agent behavior towards exploration or\nexploitation during solution construction. By following this approach, we can\nachieve a more comprehensive coverage of the search space while still\ngenerating an acceptable number of solutions. In addition, we propose an\nalgorithm for obtaining the optimal parameterization for such a given number of\nsolutions and any given trained agent. Experiments extending existing training\nprotocols for job shop scheduling problems with our inference method validate\nour hypothesis and result in the expected improvements of the generated\nsolutions.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Presented Workshop Paper at ICAPS2024",
    "pdf_url": "http://arxiv.org/pdf/2406.07325v1",
    "published_date": "2024-06-11 14:59:18 UTC",
    "updated_date": "2024-06-11 14:59:18 UTC"
  },
  {
    "arxiv_id": "2406.07323v1",
    "title": "Should XAI Nudge Human Decisions with Explanation Biasing?",
    "authors": [
      "Yosuke Fukuchi",
      "Seiji Yamada"
    ],
    "abstract": "This paper reviews our previous trials of Nudge-XAI, an approach that\nintroduces automatic biases into explanations from explainable AIs (XAIs) with\nthe aim of leading users to better decisions, and it discusses the benefits and\nchallenges. Nudge-XAI uses a user model that predicts the influence of\nproviding an explanation or emphasizing it and attempts to guide users toward\nAI-suggested decisions without coercion. The nudge design is expected to\nenhance the autonomy of users, reduce the risk associated with an AI making\ndecisions without users' full agreement, and enable users to avoid AI failures.\nTo discuss the potential of Nudge-XAI, this paper reports a post-hoc\ninvestigation of previous experimental results using cluster analysis. The\nresults demonstrate the diversity of user behavior in response to Nudge-XAI,\nwhich supports our aim of enhancing user autonomy. However, it also highlights\nthe challenge of users who distrust AI and falsely make decisions contrary to\nAI suggestions, suggesting the need for personalized adjustment of the strength\nof nudges to make this approach work more generally.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted at the 9th issue of the International Conference Series on\n  Robot Ethics and Standards (ICRES 2024)",
    "pdf_url": "http://arxiv.org/pdf/2406.07323v1",
    "published_date": "2024-06-11 14:53:07 UTC",
    "updated_date": "2024-06-11 14:53:07 UTC"
  },
  {
    "arxiv_id": "2406.07302v2",
    "title": "BertaQA: How Much Do Language Models Know About Local Culture?",
    "authors": [
      "Julen Etxaniz",
      "Gorka Azkune",
      "Aitor Soroa",
      "Oier Lopez de Lacalle",
      "Mikel Artetxe"
    ],
    "abstract": "Large Language Models (LLMs) exhibit extensive knowledge about the world, but\nmost evaluations have been limited to global or anglocentric subjects. This\nraises the question of how well these models perform on topics relevant to\nother cultures, whose presence on the web is not that prominent. To address\nthis gap, we introduce BertaQA, a multiple-choice trivia dataset that is\nparallel in English and Basque. The dataset consists of a local subset with\nquestions pertinent to the Basque culture, and a global subset with questions\nof broader interest. We find that state-of-the-art LLMs struggle with local\ncultural knowledge, even as they excel on global topics. However, we show that\ncontinued pre-training in Basque significantly improves the models' performance\non Basque culture, even when queried in English. To our knowledge, this is the\nfirst solid evidence of knowledge transfer from a low-resource to a\nhigh-resource language. Our analysis sheds light on the complex interplay\nbetween language and knowledge, and reveals that some prior findings do not\nfully hold when reassessed on local topics. Our dataset and evaluation code are\navailable under open licenses at https://github.com/juletx/BertaQA.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "NEURIPS Datasets & Benchmarks 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.07302v2",
    "published_date": "2024-06-11 14:30:34 UTC",
    "updated_date": "2024-11-18 14:40:54 UTC"
  },
  {
    "arxiv_id": "2406.07291v1",
    "title": "Joint Learning of Context and Feedback Embeddings in Spoken Dialogue",
    "authors": [
      "Livia Qian",
      "Gabriel Skantze"
    ],
    "abstract": "Short feedback responses, such as backchannels, play an important role in\nspoken dialogue. So far, most of the modeling of feedback responses has focused\non their timing, often neglecting how their lexical and prosodic form influence\ntheir contextual appropriateness and conversational function. In this paper, we\ninvestigate the possibility of embedding short dialogue contexts and feedback\nresponses in the same representation space using a contrastive learning\nobjective. In our evaluation, we primarily focus on how such embeddings can be\nused as a context-feedback appropriateness metric and thus for feedback\nresponse ranking in U.S. English dialogues. Our results show that the model\noutperforms humans given the same ranking task and that the learned embeddings\ncarry information about the conversational function of feedback responses.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Interspeech 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.07291v1",
    "published_date": "2024-06-11 14:22:37 UTC",
    "updated_date": "2024-06-11 14:22:37 UTC"
  },
  {
    "arxiv_id": "2406.07289v1",
    "title": "Can We Achieve High-quality Direct Speech-to-Speech Translation without Parallel Speech Data?",
    "authors": [
      "Qingkai Fang",
      "Shaolei Zhang",
      "Zhengrui Ma",
      "Min Zhang",
      "Yang Feng"
    ],
    "abstract": "Recently proposed two-pass direct speech-to-speech translation (S2ST) models\ndecompose the task into speech-to-text translation (S2TT) and text-to-speech\n(TTS) within an end-to-end model, yielding promising results. However, the\ntraining of these models still relies on parallel speech data, which is\nextremely challenging to collect. In contrast, S2TT and TTS have accumulated a\nlarge amount of data and pretrained models, which have not been fully utilized\nin the development of S2ST models. Inspired by this, in this paper, we first\nintroduce a composite S2ST model named ComSpeech, which can seamlessly\nintegrate any pretrained S2TT and TTS models into a direct S2ST model.\nFurthermore, to eliminate the reliance on parallel speech data, we propose a\nnovel training method ComSpeech-ZS that solely utilizes S2TT and TTS data. It\naligns representations in the latent space through contrastive learning,\nenabling the speech synthesis capability learned from the TTS data to\ngeneralize to S2ST in a zero-shot manner. Experimental results on the CVSS\ndataset show that when the parallel speech data is available, ComSpeech\nsurpasses previous two-pass models like UnitY and Translatotron 2 in both\ntranslation quality and decoding speed. When there is no parallel speech data,\nComSpeech-ZS lags behind \\name by only 0.7 ASR-BLEU and outperforms the\ncascaded models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SD",
      "eess.AS",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL 2024 main conference. Project Page:\n  https://ictnlp.github.io/ComSpeech-Site/",
    "pdf_url": "http://arxiv.org/pdf/2406.07289v1",
    "published_date": "2024-06-11 14:17:12 UTC",
    "updated_date": "2024-06-11 14:17:12 UTC"
  },
  {
    "arxiv_id": "2406.07284v2",
    "title": "Unsupervised Object Detection with Theoretical Guarantees",
    "authors": [
      "Marian Longa",
      "João F. Henriques"
    ],
    "abstract": "Unsupervised object detection using deep neural networks is typically a\ndifficult problem with few to no guarantees about the learned representation.\nIn this work we present the first unsupervised object detection method that is\ntheoretically guaranteed to recover the true object positions up to\nquantifiable small shifts. We develop an unsupervised object detection\narchitecture and prove that the learned variables correspond to the true object\npositions up to small shifts related to the encoder and decoder receptive field\nsizes, the object sizes, and the widths of the Gaussians used in the rendering\nprocess. We perform detailed analysis of how the error depends on each of these\nvariables and perform synthetic experiments validating our theoretical\npredictions up to a precision of individual pixels. We also perform experiments\non CLEVR-based data and show that, unlike current SOTA object detection methods\n(SAM, CutLER), our method's prediction errors always lie within our theoretical\nbounds. We hope that this work helps open up an avenue of research into object\ndetection methods with theoretical guarantees.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.07284v2",
    "published_date": "2024-06-11 14:12:31 UTC",
    "updated_date": "2024-10-24 08:09:47 UTC"
  },
  {
    "arxiv_id": "2406.07277v2",
    "title": "Speaking Your Language: Spatial Relationships in Interpretable Emergent Communication",
    "authors": [
      "Olaf Lipinski",
      "Adam J. Sobey",
      "Federico Cerutti",
      "Timothy J. Norman"
    ],
    "abstract": "Effective communication requires the ability to refer to specific parts of an\nobservation in relation to others. While emergent communication literature\nshows success in developing various language properties, no research has shown\nthe emergence of such positional references. This paper demonstrates how agents\ncan communicate about spatial relationships within their observations. The\nresults indicate that agents can develop a language capable of expressing the\nrelationships between parts of their observation, achieving over 90% accuracy\nwhen trained in a referential game which requires such communication. Using a\ncollocation measure, we demonstrate how the agents create such references. This\nanalysis suggests that agents use a mixture of non-compositional and\ncompositional messages to convey spatial relationships. We also show that the\nemergent language is interpretable by humans. The translation accuracy is\ntested by communicating with the receiver agent, where the receiver achieves\nover 78% accuracy using parts of this lexicon, confirming that the\ninterpretation of the emergent language was successful.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at NeurIPS 2024. 18 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.07277v2",
    "published_date": "2024-06-11 14:04:25 UTC",
    "updated_date": "2024-10-28 14:14:10 UTC"
  },
  {
    "arxiv_id": "2406.07275v1",
    "title": "DCA-Bench: A Benchmark for Dataset Curation Agents",
    "authors": [
      "Benhao Huang",
      "Yingzhuo Yu",
      "Jin Huang",
      "Xingjian Zhang",
      "Jiaqi Ma"
    ],
    "abstract": "The quality of datasets plays an increasingly crucial role in the research\nand development of modern artificial intelligence (AI). Despite the\nproliferation of open dataset platforms nowadays, data quality issues, such as\ninsufficient documentation, inaccurate annotations, and ethical concerns,\nremain common in datasets widely used in AI. Furthermore, these issues are\noften subtle and difficult to be detected by rule-based scripts, requiring\nexpensive manual identification and verification by dataset users or\nmaintainers. With the increasing capability of large language models (LLMs), it\nis promising to streamline the curation of datasets with LLM agents. In this\nwork, as the initial step towards this goal, we propose a dataset curation\nagent benchmark, DCA-Bench, to measure LLM agents' capability of detecting\nhidden dataset quality issues. Specifically, we collect diverse real-world\ndataset quality issues from eight open dataset platforms as a testbed.\nAdditionally, to establish an automatic pipeline for evaluating the success of\nLLM agents, which requires a nuanced understanding of the agent outputs, we\nimplement a dedicated Evaluator using another LLM agent. We demonstrate that\nthe LLM-based Evaluator empirically aligns well with human evaluation, allowing\nreliable automatic evaluation on the proposed benchmark. We further conduct\nexperiments on several baseline LLM agents on the proposed benchmark and\ndemonstrate the complexity of the task, indicating that applying LLMs to\nreal-world dataset curation still requires further in-depth exploration and\ninnovation. Finally, the proposed benchmark can also serve as a testbed for\nmeasuring the capability of LLMs in problem discovery rather than just\nproblem-solving. The benchmark suite is available at\n\\url{https://github.com/TRAIS-Lab/dca-bench}.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07275v1",
    "published_date": "2024-06-11 14:02:23 UTC",
    "updated_date": "2024-06-11 14:02:23 UTC"
  },
  {
    "arxiv_id": "2406.07266v3",
    "title": "SemlaFlow -- Efficient 3D Molecular Generation with Latent Attention and Equivariant Flow Matching",
    "authors": [
      "Ross Irwin",
      "Alessandro Tibo",
      "Jon Paul Janet",
      "Simon Olsson"
    ],
    "abstract": "Methods for jointly generating molecular graphs along with their 3D\nconformations have gained prominence recently due to their potential impact on\nstructure-based drug design. Current approaches, however, often suffer from\nvery slow sampling times or generate molecules with poor chemical validity.\nAddressing these limitations, we propose Semla, a scalable E(3)-equivariant\nmessage passing architecture. We further introduce an unconditional 3D\nmolecular generation model, SemlaFlow, which is trained using equivariant flow\nmatching to generate a joint distribution over atom types, coordinates, bond\ntypes and formal charges. Our model produces state-of-the-art results on\nbenchmark datasets with as few as 20 sampling steps, corresponding to a two\norder-of-magnitude speedup compared to state-of-the-art. Furthermore, we\nhighlight limitations of current evaluation methods for 3D generation and\npropose new benchmark metrics for unconditional molecular generators. Finally,\nusing these new metrics, we compare our model's ability to generate high\nquality samples against current approaches and further demonstrate SemlaFlow's\nstrong performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "AISTATS 2025",
    "pdf_url": "http://arxiv.org/pdf/2406.07266v3",
    "published_date": "2024-06-11 13:51:51 UTC",
    "updated_date": "2025-02-28 16:56:08 UTC"
  },
  {
    "arxiv_id": "2406.07595v4",
    "title": "VulDetectBench: Evaluating the Deep Capability of Vulnerability Detection with Large Language Models",
    "authors": [
      "Yu Liu",
      "Lang Gao",
      "Mingxin Yang",
      "Yu Xie",
      "Ping Chen",
      "Xiaojin Zhang",
      "Wei Chen"
    ],
    "abstract": "Large Language Models (LLMs) have training corpora containing large amounts\nof program code, greatly improving the model's code comprehension and\ngeneration capabilities. However, sound comprehensive research on detecting\nprogram vulnerabilities, a more specific task related to code, and evaluating\nthe performance of LLMs in this more specialized scenario is still lacking. To\naddress common challenges in vulnerability analysis, our study introduces a new\nbenchmark, VulDetectBench, specifically designed to assess the vulnerability\ndetection capabilities of LLMs. The benchmark comprehensively evaluates LLM's\nability to identify, classify, and locate vulnerabilities through five tasks of\nincreasing difficulty. We evaluate the performance of 17 models (both open- and\nclosed-source) and find that while existing models can achieve over 80%\naccuracy on tasks related to vulnerability identification and classification,\nthey still fall short on specific, more detailed vulnerability analysis tasks,\nwith less than 30% accuracy, making it difficult to provide valuable auxiliary\ninformation for professional vulnerability mining. Our benchmark effectively\nevaluates the capabilities of various LLMs at different levels in the specific\ntask of vulnerability detection, providing a foundation for future research and\nimprovements in this critical area of code security. VulDetectBench is publicly\navailable at https://github.com/Sweetaroo/VulDetectBench.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07595v4",
    "published_date": "2024-06-11 13:42:57 UTC",
    "updated_date": "2024-08-21 14:51:06 UTC"
  },
  {
    "arxiv_id": "2406.07594v2",
    "title": "MLLMGuard: A Multi-dimensional Safety Evaluation Suite for Multimodal Large Language Models",
    "authors": [
      "Tianle Gu",
      "Zeyang Zhou",
      "Kexin Huang",
      "Dandan Liang",
      "Yixu Wang",
      "Haiquan Zhao",
      "Yuanqi Yao",
      "Xingge Qiao",
      "Keqing Wang",
      "Yujiu Yang",
      "Yan Teng",
      "Yu Qiao",
      "Yingchun Wang"
    ],
    "abstract": "Powered by remarkable advancements in Large Language Models (LLMs),\nMultimodal Large Language Models (MLLMs) demonstrate impressive capabilities in\nmanifold tasks. However, the practical application scenarios of MLLMs are\nintricate, exposing them to potential malicious instructions and thereby posing\nsafety risks. While current benchmarks do incorporate certain safety\nconsiderations, they often lack comprehensive coverage and fail to exhibit the\nnecessary rigor and robustness. For instance, the common practice of employing\nGPT-4V as both the evaluator and a model to be evaluated lacks credibility, as\nit tends to exhibit a bias toward its own responses. In this paper, we present\nMLLMGuard, a multidimensional safety evaluation suite for MLLMs, including a\nbilingual image-text evaluation dataset, inference utilities, and a lightweight\nevaluator. MLLMGuard's assessment comprehensively covers two languages (English\nand Chinese) and five important safety dimensions (Privacy, Bias, Toxicity,\nTruthfulness, and Legality), each with corresponding rich subtasks. Focusing on\nthese dimensions, our evaluation dataset is primarily sourced from platforms\nsuch as social media, and it integrates text-based and image-based red teaming\ntechniques with meticulous annotation by human experts. This can prevent\ninaccurate evaluation caused by data leakage when using open-source datasets\nand ensures the quality and challenging nature of our benchmark. Additionally,\na fully automated lightweight evaluator termed GuardRank is developed, which\nachieves significantly higher evaluation accuracy than GPT-4. Our evaluation\nresults across 13 advanced models indicate that MLLMs still have a substantial\njourney ahead before they can be considered safe and responsible.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07594v2",
    "published_date": "2024-06-11 13:41:33 UTC",
    "updated_date": "2024-06-13 11:22:15 UTC"
  },
  {
    "arxiv_id": "2406.07259v1",
    "title": "Scientific Computing with Large Language Models",
    "authors": [
      "Christopher Culver",
      "Peter Hicks",
      "Mihailo Milenkovic",
      "Sanjif Shanmugavelu",
      "Tobias Becker"
    ],
    "abstract": "We provide an overview of the emergence of large language models for\nscientific computing applications. We highlight use cases that involve natural\nlanguage processing of scientific documents and specialized languages designed\nto describe physical systems. For the former, chatbot style applications appear\nin medicine, mathematics and physics and can be used iteratively with domain\nexperts for problem solving. We also review specialized languages within\nmolecular biology, the languages of molecules, proteins, and DNA where language\nmodels are being used to predict properties and even create novel physical\nsystems at much faster rates than traditional computing methods.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "13 pages",
    "pdf_url": "http://arxiv.org/pdf/2406.07259v1",
    "published_date": "2024-06-11 13:39:07 UTC",
    "updated_date": "2024-06-11 13:39:07 UTC"
  },
  {
    "arxiv_id": "2406.07257v1",
    "title": "Scholarly Question Answering using Large Language Models in the NFDI4DataScience Gateway",
    "authors": [
      "Hamed Babaei Giglou",
      "Tilahun Abedissa Taffa",
      "Rana Abdullah",
      "Aida Usmanova",
      "Ricardo Usbeck",
      "Jennifer D'Souza",
      "Sören Auer"
    ],
    "abstract": "This paper introduces a scholarly Question Answering (QA) system on top of\nthe NFDI4DataScience Gateway, employing a Retrieval Augmented Generation-based\n(RAG) approach. The NFDI4DS Gateway, as a foundational framework, offers a\nunified and intuitive interface for querying various scientific databases using\nfederated search. The RAG-based scholarly QA, powered by a Large Language Model\n(LLM), facilitates dynamic interaction with search results, enhancing filtering\ncapabilities and fostering a conversational engagement with the Gateway search.\nThe effectiveness of both the Gateway and the scholarly QA system is\ndemonstrated through experimental analysis.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "13 pages main content, 16 pages overall, 3 Figures, accepted for\n  publication at NSLP 2024 workshop at ESWC 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.07257v1",
    "published_date": "2024-06-11 13:36:19 UTC",
    "updated_date": "2024-06-11 13:36:19 UTC"
  },
  {
    "arxiv_id": "2406.07593v1",
    "title": "Modeling Sustainable Resource Management using Active Inference",
    "authors": [
      "Mahault Albarracin",
      "Ines Hipolito",
      "Maria Raffa",
      "Paul Kinghorn"
    ],
    "abstract": "Active inference helps us simulate adaptive behavior and decision-making in\nbiological and artificial agents. Building on our previous work exploring the\nrelationship between active inference, well-being, resilience, and\nsustainability, we present a computational model of an agent learning\nsustainable resource management strategies in both static and dynamic\nenvironments. The agent's behavior emerges from optimizing its own well-being,\nrepresented by prior preferences, subject to beliefs about environmental\ndynamics. In a static environment, the agent learns to consistently consume\nresources to satisfy its needs. In a dynamic environment where resources\ndeplete and replenish based on the agent's actions, the agent adapts its\nbehavior to balance immediate needs with long-term resource availability. This\ndemonstrates how active inference can give rise to sustainable and resilient\nbehaviors in the face of changing environmental conditions. We discuss the\nimplications of our model, its limitations, and suggest future directions for\nintegrating more complex agent-environment interactions. Our work highlights\nactive inference's potential for understanding and shaping sustainable\nbehaviors.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Version prior to reviewer comments",
    "pdf_url": "http://arxiv.org/pdf/2406.07593v1",
    "published_date": "2024-06-11 13:36:12 UTC",
    "updated_date": "2024-06-11 13:36:12 UTC"
  },
  {
    "arxiv_id": "2406.07256v1",
    "title": "AS-70: A Mandarin stuttered speech dataset for automatic speech recognition and stuttering event detection",
    "authors": [
      "Rong Gong",
      "Hongfei Xue",
      "Lezhi Wang",
      "Xin Xu",
      "Qisheng Li",
      "Lei Xie",
      "Hui Bu",
      "Shaomei Wu",
      "Jiaming Zhou",
      "Yong Qin",
      "Binbin Zhang",
      "Jun Du",
      "Jia Bin",
      "Ming Li"
    ],
    "abstract": "The rapid advancements in speech technologies over the past two decades have\nled to human-level performance in tasks like automatic speech recognition (ASR)\nfor fluent speech. However, the efficacy of these models diminishes when\napplied to atypical speech, such as stuttering. This paper introduces AS-70,\nthe first publicly available Mandarin stuttered speech dataset, which stands\nout as the largest dataset in its category. Encompassing conversational and\nvoice command reading speech, AS-70 includes verbatim manual transcription,\nrendering it suitable for various speech-related tasks. Furthermore, baseline\nsystems are established, and experimental results are presented for ASR and\nstuttering event detection (SED) tasks. By incorporating this dataset into the\nmodel fine-tuning, significant improvements in the state-of-the-art ASR models,\ne.g., Whisper and Hubert, are observed, enhancing their inclusivity in\naddressing stuttered speech.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted by Interspeech 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.07256v1",
    "published_date": "2024-06-11 13:35:50 UTC",
    "updated_date": "2024-06-11 13:35:50 UTC"
  },
  {
    "arxiv_id": "2406.07251v3",
    "title": "Is One GPU Enough? Pushing Image Generation at Higher-Resolutions with Foundation Models",
    "authors": [
      "Athanasios Tragakis",
      "Marco Aversa",
      "Chaitanya Kaul",
      "Roderick Murray-Smith",
      "Daniele Faccio"
    ],
    "abstract": "In this work, we introduce Pixelsmith, a zero-shot text-to-image generative\nframework to sample images at higher resolutions with a single GPU. We are the\nfirst to show that it is possible to scale the output of a pre-trained\ndiffusion model by a factor of 1000, opening the road for gigapixel image\ngeneration at no additional cost. Our cascading method uses the image generated\nat the lowest resolution as a baseline to sample at higher resolutions. For the\nguidance, we introduce the Slider, a tunable mechanism that fuses the overall\nstructure contained in the first-generated image with enhanced fine details. At\neach inference step, we denoise patches rather than the entire latent space,\nminimizing memory demands such that a single GPU can handle the process,\nregardless of the image's resolution. Our experimental results show that\nPixelsmith not only achieves higher quality and diversity compared to existing\ntechniques, but also reduces sampling time and artifacts. The code for our work\nis available at https://github.com/Thanos-DB/Pixelsmith.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07251v3",
    "published_date": "2024-06-11 13:33:33 UTC",
    "updated_date": "2024-10-24 12:31:09 UTC"
  },
  {
    "arxiv_id": "2406.07249v2",
    "title": "Are Protein Language Models Compute Optimal?",
    "authors": [
      "Yaiza Serrano",
      "Álvaro Ciudad",
      "Alexis Molina"
    ],
    "abstract": "While protein language models (pLMs) have transformed biological research,\nthe scaling laws governing their improvement remain underexplored. By adapting\nmethodologies from NLP scaling laws, we investigated the optimal ratio between\nmodel parameters and training tokens within a fixed compute budget. Our study\nreveals that pLM sizes scale sublinearly with compute budget, showing\ndiminishing returns in performance as model size increases, and we identify a\nperformance plateau in training loss comparable to the one found in relevant\nworks in the field. Our findings suggest that widely-used pLMs might not be\ncompute-optimal, indicating that larger models could achieve convergence more\nefficiently. Training a 35M model on a reduced token set, we attained\nperplexity results comparable to larger models like ESM-2 (15B) and xTrimoPGLM\n(100B) with a single dataset pass. This work paves the way towards more\ncompute-efficient pLMs, democratizing their training and practical application\nin computational biology.",
    "categories": [
      "q-bio.BM",
      "cs.AI"
    ],
    "primary_category": "q-bio.BM",
    "comment": "Proceedings of the ICML 2024 Workshop on Accessible and Efficient\n  Foundation Models for Biological Discovery, Vienna, Austria. 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.07249v2",
    "published_date": "2024-06-11 13:32:11 UTC",
    "updated_date": "2024-06-26 05:07:15 UTC"
  },
  {
    "arxiv_id": "2406.07232v2",
    "title": "DUAL-REFLECT: Enhancing Large Language Models for Reflective Translation through Dual Learning Feedback Mechanisms",
    "authors": [
      "Andong Chen",
      "Lianzhang Lou",
      "Kehai Chen",
      "Xuefeng Bai",
      "Yang Xiang",
      "Muyun Yang",
      "Tiejun Zhao",
      "Min Zhang"
    ],
    "abstract": "Recently, large language models (LLMs) enhanced by self-reflection have\nachieved promising performance on machine translation. The key idea is guiding\nLLMs to generate translation with human-like feedback. However, existing\nself-reflection methods lack effective feedback information, limiting the\ntranslation performance. To address this, we introduce a DUAL-REFLECT\nframework, leveraging the dual learning of translation tasks to provide\neffective feedback, thereby enhancing the models' self-reflective abilities and\nimproving translation performance. The application of this method across\nvarious translation tasks has proven its effectiveness in improving translation\naccuracy and eliminating ambiguities, especially in translation tasks with\nlow-resource language pairs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ACL 2024 main conference",
    "pdf_url": "http://arxiv.org/pdf/2406.07232v2",
    "published_date": "2024-06-11 13:10:39 UTC",
    "updated_date": "2024-06-21 16:49:33 UTC"
  },
  {
    "arxiv_id": "2406.07229v1",
    "title": "Improving Commonsense Bias Classification by Mitigating the Influence of Demographic Terms",
    "authors": [
      "JinKyu Lee",
      "Jihie Kim"
    ],
    "abstract": "Understanding commonsense knowledge is crucial in the field of Natural\nLanguage Processing (NLP). However, the presence of demographic terms in\ncommonsense knowledge poses a potential risk of compromising the performance of\nNLP models. This study aims to investigate and propose methods for enhancing\nthe performance and effectiveness of a commonsense polarization classifier by\nmitigating the influence of demographic terms. Three methods are introduced in\nthis paper: (1) hierarchical generalization of demographic terms (2)\nthreshold-based augmentation and (3) integration of hierarchical generalization\nand threshold-based augmentation methods (IHTA). The first method involves\nreplacing demographic terms with more general ones based on a term hierarchy\nontology, aiming to mitigate the influence of specific terms. To address the\nlimited bias-related information, the second method measures the polarization\nof demographic terms by comparing the changes in the model's predictions when\nthese terms are masked versus unmasked. This method augments commonsense\nsentences containing terms with high polarization values by replacing their\npredicates with synonyms generated by ChatGPT. The third method combines the\ntwo approaches, starting with threshold-based augmentation followed by\nhierarchical generalization. The experiments show that the first method\nincreases the accuracy over the baseline by 2.33%, and the second one by 0.96%\nover standard augmentation methods. The IHTA techniques yielded an 8.82% and\n9.96% higher accuracy than threshold-based and standard augmentation methods,\nrespectively.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T50",
      "I.2.7; I.2.6"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 5 figures, conference presentation, supported by MSIT\n  (Korea) under ITRC program (IITP-2024-2020-0-01789) and AI Convergence\n  Innovation HR Development (IITP-2024-RS-2023-00254592)",
    "pdf_url": "http://arxiv.org/pdf/2406.07229v1",
    "published_date": "2024-06-11 13:09:16 UTC",
    "updated_date": "2024-06-11 13:09:16 UTC"
  },
  {
    "arxiv_id": "2406.07230v2",
    "title": "Needle In A Multimodal Haystack",
    "authors": [
      "Weiyun Wang",
      "Shuibo Zhang",
      "Yiming Ren",
      "Yuchen Duan",
      "Tiantong Li",
      "Shuo Liu",
      "Mengkang Hu",
      "Zhe Chen",
      "Kaipeng Zhang",
      "Lewei Lu",
      "Xizhou Zhu",
      "Ping Luo",
      "Yu Qiao",
      "Jifeng Dai",
      "Wenqi Shao",
      "Wenhai Wang"
    ],
    "abstract": "With the rapid advancement of multimodal large language models (MLLMs), their\nevaluation has become increasingly comprehensive. However, understanding long\nmultimodal content, as a foundational ability for real-world applications,\nremains underexplored. In this work, we present Needle In A Multimodal Haystack\n(MM-NIAH), the first benchmark specifically designed to systematically evaluate\nthe capability of existing MLLMs to comprehend long multimodal documents. Our\nbenchmark includes three types of evaluation tasks: multimodal retrieval,\ncounting, and reasoning. In each task, the model is required to answer the\nquestions according to different key information scattered throughout the given\nmultimodal document. Evaluating the leading MLLMs on MM-NIAH, we observe that\nexisting models still have significant room for improvement on these tasks,\nespecially on vision-centric evaluation. We hope this work can provide a\nplatform for further research on long multimodal document comprehension and\ncontribute to the advancement of MLLMs. Code and benchmark are released at\nhttps://github.com/OpenGVLab/MM-NIAH.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to NeurIPS 2024 Track Datasets and Benchmarks",
    "pdf_url": "http://arxiv.org/pdf/2406.07230v2",
    "published_date": "2024-06-11 13:09:16 UTC",
    "updated_date": "2024-10-09 07:46:02 UTC"
  },
  {
    "arxiv_id": "2406.07228v1",
    "title": "Haptic Repurposing with GenAI",
    "authors": [
      "Haoyu Wang"
    ],
    "abstract": "Mixed Reality aims to merge the digital and physical worlds to create\nimmersive human-computer interactions. Despite notable advancements, the\nabsence of realistic haptic feedback often breaks the immersive experience by\ncreating a disconnect between visual and tactile perceptions. This paper\nintroduces Haptic Repurposing with GenAI, an innovative approach to enhance MR\ninteractions by transforming any physical objects into adaptive haptic\ninterfaces for AI-generated virtual assets. Utilizing state-of-the-art\ngenerative AI models, this system captures both 2D and 3D features of physical\nobjects and, through user-directed prompts, generates corresponding virtual\nobjects that maintain the physical form of the original objects. Through\nmodel-based object tracking, the system dynamically anchors virtual assets to\nphysical props in real time, allowing objects to visually morph into any\nuser-specified virtual object. This paper details the system's development,\npresents findings from usability studies that validate its effectiveness, and\nexplores its potential to significantly enhance interactive MR environments.\nThe hope is this work can lay a foundation for further research into AI-driven\nspatial transformation in immersive and haptic technologies.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "F.2.2, I.2.7"
    ],
    "primary_category": "cs.HC",
    "comment": "10 Pages, 11 Figures",
    "pdf_url": "http://arxiv.org/pdf/2406.07228v1",
    "published_date": "2024-06-11 13:06:28 UTC",
    "updated_date": "2024-06-11 13:06:28 UTC"
  },
  {
    "arxiv_id": "2406.07222v2",
    "title": "Improving Autoformalization using Type Checking",
    "authors": [
      "Auguste Poiroux",
      "Gail Weiss",
      "Viktor Kunčak",
      "Antoine Bosselut"
    ],
    "abstract": "Autoformalization, the automatic translation of unconstrained natural\nlanguage into formal languages, has garnered significant attention due to its\npotential applications in theorem proving, formal verification, and LLM output\nchecking. In this work, we analyze both current autoformalization methods and\nthe processes used to evaluate them, focusing specifically on the Lean 4\ntheorem proving language. We demonstrate that scaling type-check filtering with\nself-consistency techniques on top of existing methods significantly improves\nperformance, achieving absolute accuracy gains of up to +18.4\\% on ProofNet. To\nsupport reproducibility and further research, we release our code, including\nnew symbolic equivalence for Lean formulas. We also release new benchmarks: a\nnew research-level mathematics dataset RLM25, a corrected ProofNet, and\nProofNetVerif with labeled correct and incorrect autoformalization pairs for\nevaluating metrics.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "New benchmarks released, see\n  https://github.com/augustepoiroux/RLMEval ,\n  https://huggingface.co/datasets/PAug/ProofNetSharp , and\n  https://huggingface.co/datasets/PAug/ProofNetVerif . For code, see\n  https://github.com/augustepoiroux/LeanInteract",
    "pdf_url": "http://arxiv.org/pdf/2406.07222v2",
    "published_date": "2024-06-11 13:01:50 UTC",
    "updated_date": "2025-02-11 11:02:10 UTC"
  },
  {
    "arxiv_id": "2407.11994v1",
    "title": "Evaluating Contextually Personalized Programming Exercises Created with Generative AI",
    "authors": [
      "Evanfiya Logacheva",
      "Arto Hellas",
      "James Prather",
      "Sami Sarsa",
      "Juho Leinonen"
    ],
    "abstract": "Programming skills are typically developed through completing various\nhands-on exercises. Such programming problems can be contextualized to\nstudents' interests and cultural backgrounds. Prior research in educational\npsychology has demonstrated that context personalization of exercises\nstimulates learners' situational interests and positively affects their\nengagement. However, creating a varied and comprehensive set of programming\nexercises for students to practice on is a time-consuming and laborious task\nfor computer science educators. Previous studies have shown that large language\nmodels can generate conceptually and contextually relevant programming\nexercises. Thus, they offer a possibility to automatically produce personalized\nprogramming problems to fit students' interests and needs. This article reports\non a user study conducted in an elective introductory programming course that\nincluded contextually personalized programming exercises created with GPT-4.\nThe quality of the exercises was evaluated by both the students and the\nauthors. Additionally, this work investigated student attitudes towards the\ncreated exercises and their engagement with the system. The results demonstrate\nthat the quality of exercises generated with GPT-4 was generally high. What is\nmore, the course participants found them engaging and useful. This suggests\nthat AI-generated programming problems can be a worthwhile addition to\nintroductory programming courses, as they provide students with a practically\nunlimited pool of practice material tailored to their personal interests and\neducational needs.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "19 pages, 12 figures. Accepted for publication at ICER 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.11994v1",
    "published_date": "2024-06-11 12:59:52 UTC",
    "updated_date": "2024-06-11 12:59:52 UTC"
  },
  {
    "arxiv_id": "2406.07217v2",
    "title": "A Synthetic Dataset for Personal Attribute Inference",
    "authors": [
      "Hanna Yukhymenko",
      "Robin Staab",
      "Mark Vero",
      "Martin Vechev"
    ],
    "abstract": "Recently, powerful Large Language Models (LLMs) have become easily accessible\nto hundreds of millions of users world-wide. However, their strong capabilities\nand vast world knowledge do not come without associated privacy risks. In this\nwork, we focus on the emerging privacy threat LLMs pose -- the ability to\naccurately infer personal information from online texts. Despite the growing\nimportance of LLM-based author profiling, research in this area has been\nhampered by a lack of suitable public datasets, largely due to ethical and\nprivacy concerns associated with real personal data. We take two steps to\naddress this problem: (i) we construct a simulation framework for the popular\nsocial media platform Reddit using LLM agents seeded with synthetic personal\nprofiles; (ii) using this framework, we generate SynthPAI, a diverse synthetic\ndataset of over 7800 comments manually labeled for personal attributes. We\nvalidate our dataset with a human study showing that humans barely outperform\nrandom guessing on the task of distinguishing our synthetic comments from real\nones. Further, we verify that our dataset enables meaningful personal attribute\ninference research by showing across 18 state-of-the-art LLMs that our\nsynthetic comments allow us to draw the same conclusions as real-world data.\nCombined, our experimental results, dataset and pipeline form a strong basis\nfor future privacy-preserving research geared towards understanding and\nmitigating inference-based privacy threats that LLMs pose.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07217v2",
    "published_date": "2024-06-11 12:50:53 UTC",
    "updated_date": "2024-11-04 11:06:40 UTC"
  },
  {
    "arxiv_id": "2406.07212v3",
    "title": "Trustworthy and Practical AI for Healthcare: A Guided Deferral System with Large Language Models",
    "authors": [
      "Joshua Strong",
      "Qianhui Men",
      "Alison Noble"
    ],
    "abstract": "Large language models (LLMs) offer a valuable technology for various\napplications in healthcare. However, their tendency to hallucinate and the\nexisting reliance on proprietary systems pose challenges in environments\nconcerning critical decision-making and strict data privacy regulations, such\nas healthcare, where the trust in such systems is paramount. Through combining\nthe strengths and discounting the weaknesses of humans and AI, the field of\nHuman-AI Collaboration (HAIC) presents one front for tackling these challenges\nand hence improving trust. This paper presents a novel HAIC guided deferral\nsystem that can simultaneously parse medical reports for disorder\nclassification, and defer uncertain predictions with intelligent guidance to\nhumans. We develop methodology which builds efficient, effective and\nopen-source LLMs for this purpose, for the real-world deployment in healthcare.\nWe conduct a pilot study which showcases the effectiveness of our proposed\nsystem in practice. Additionally, we highlight drawbacks of standard\ncalibration metrics in imbalanced data scenarios commonly found in healthcare,\nand suggest a simple yet effective solution: the Imbalanced Expected\nCalibration Error.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "AAAI-AISI 2025",
    "pdf_url": "http://arxiv.org/pdf/2406.07212v3",
    "published_date": "2024-06-11 12:41:54 UTC",
    "updated_date": "2025-02-26 00:49:57 UTC"
  },
  {
    "arxiv_id": "2406.07592v3",
    "title": "MambaLRP: Explaining Selective State Space Sequence Models",
    "authors": [
      "Farnoush Rezaei Jafari",
      "Grégoire Montavon",
      "Klaus-Robert Müller",
      "Oliver Eberle"
    ],
    "abstract": "Recent sequence modeling approaches using selective state space sequence\nmodels, referred to as Mamba models, have seen a surge of interest. These\nmodels allow efficient processing of long sequences in linear time and are\nrapidly being adopted in a wide range of applications such as language\nmodeling, demonstrating promising performance. To foster their reliable use in\nreal-world scenarios, it is crucial to augment their transparency. Our work\nbridges this critical gap by bringing explainability, particularly Layer-wise\nRelevance Propagation (LRP), to the Mamba architecture. Guided by the axiom of\nrelevance conservation, we identify specific components in the Mamba\narchitecture, which cause unfaithful explanations. To remedy this issue, we\npropose MambaLRP, a novel algorithm within the LRP framework, which ensures a\nmore stable and reliable relevance propagation through these components. Our\nproposed method is theoretically sound and excels in achieving state-of-the-art\nexplanation performance across a diverse range of models and datasets.\nMoreover, MambaLRP facilitates a deeper inspection of Mamba architectures,\nuncovering various biases and evaluating their significance. It also enables\nthe analysis of previous speculations regarding the long-range capabilities of\nMamba models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07592v3",
    "published_date": "2024-06-11 12:15:47 UTC",
    "updated_date": "2025-01-15 11:18:10 UTC"
  },
  {
    "arxiv_id": "2406.07188v2",
    "title": "Merging Improves Self-Critique Against Jailbreak Attacks",
    "authors": [
      "Victor Gallego"
    ],
    "abstract": "The robustness of large language models (LLMs) against adversarial\nmanipulations, such as jailbreak attacks, remains a significant challenge. In\nthis work, we propose an approach that enhances the self-critique capability of\nthe LLM and further fine-tunes it over sanitized synthetic data. This is done\nwith the addition of an external critic model that can be merged with the\noriginal, thus bolstering self-critique capabilities and improving the\nrobustness of the LLMs response to adversarial prompts. Our results demonstrate\nthat the combination of merging and self-critique can reduce the attack success\nrate of adversaries significantly, thus offering a promising defense mechanism\nagainst jailbreak attacks. Code, data and models released at\nhttps://github.com/vicgalle/merging-self-critique-jailbreaks .",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Published at ICML 2024 Workshop on Foundation Models in the Wild",
    "pdf_url": "http://arxiv.org/pdf/2406.07188v2",
    "published_date": "2024-06-11 12:01:09 UTC",
    "updated_date": "2024-07-14 18:27:14 UTC"
  },
  {
    "arxiv_id": "2406.07162v1",
    "title": "EmoBox: Multilingual Multi-corpus Speech Emotion Recognition Toolkit and Benchmark",
    "authors": [
      "Ziyang Ma",
      "Mingjie Chen",
      "Hezhao Zhang",
      "Zhisheng Zheng",
      "Wenxi Chen",
      "Xiquan Li",
      "Jiaxin Ye",
      "Xie Chen",
      "Thomas Hain"
    ],
    "abstract": "Speech emotion recognition (SER) is an important part of human-computer\ninteraction, receiving extensive attention from both industry and academia.\nHowever, the current research field of SER has long suffered from the following\nproblems: 1) There are few reasonable and universal splits of the datasets,\nmaking comparing different models and methods difficult. 2) No commonly used\nbenchmark covers numerous corpus and languages for researchers to refer to,\nmaking reproduction a burden. In this paper, we propose EmoBox, an\nout-of-the-box multilingual multi-corpus speech emotion recognition toolkit,\nalong with a benchmark for both intra-corpus and cross-corpus settings. For\nintra-corpus settings, we carefully designed the data partitioning for\ndifferent datasets. For cross-corpus settings, we employ a foundation SER\nmodel, emotion2vec, to mitigate annotation errors and obtain a test set that is\nfully balanced in speakers and emotions distributions. Based on EmoBox, we\npresent the intra-corpus SER results of 10 pre-trained speech models on 32\nemotion datasets with 14 languages, and the cross-corpus SER results on 4\ndatasets with the fully balanced test sets. To the best of our knowledge, this\nis the largest SER benchmark, across language scopes and quantity scales. We\nhope that our toolkit and benchmark can facilitate the research of SER in the\ncommunity.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted by INTERSPEECH 2024. GitHub Repository:\n  https://github.com/emo-box/EmoBox",
    "pdf_url": "http://arxiv.org/pdf/2406.07162v1",
    "published_date": "2024-06-11 11:12:51 UTC",
    "updated_date": "2024-06-11 11:12:51 UTC"
  },
  {
    "arxiv_id": "2406.07155v3",
    "title": "Scaling Large Language Model-based Multi-Agent Collaboration",
    "authors": [
      "Chen Qian",
      "Zihao Xie",
      "YiFei Wang",
      "Wei Liu",
      "Kunlun Zhu",
      "Hanchen Xia",
      "Yufan Dang",
      "Zhuoyun Du",
      "Weize Chen",
      "Cheng Yang",
      "Zhiyuan Liu",
      "Maosong Sun"
    ],
    "abstract": "Recent breakthroughs in large language model-driven autonomous agents have\nrevealed that multi-agent collaboration often surpasses each individual through\ncollective reasoning. Inspired by the neural scaling law--increasing neurons\nenhances performance, this study explores whether the continuous addition of\ncollaborative agents can yield similar benefits. Technically, we utilize\ndirected acyclic graphs to organize agents into a multi-agent collaboration\nnetwork (MacNet), upon which their interactive reasoning is topologically\norchestrated for autonomous task solving. Extensive evaluations reveal that it\neffectively supports collaboration among over a thousand agents, with irregular\ntopologies outperforming regular ones. We also identify a collaborative scaling\nlaw--the overall performance follows a logistic growth pattern as agents scale,\nwith collaborative emergence occurring earlier than traditional neural\nemergence. We speculate this may be because scaling agents catalyzes their\nmultidimensional considerations during interactive reflection and refinement,\nthereby producing more comprehensive artifacts. The code is available at\nhttps://github.com/OpenBMB/ChatDev/tree/macnet.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.MA",
      "cs.NI",
      "cs.SI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to ICLR-2025",
    "pdf_url": "http://arxiv.org/pdf/2406.07155v3",
    "published_date": "2024-06-11 11:02:04 UTC",
    "updated_date": "2025-03-17 00:22:42 UTC"
  },
  {
    "arxiv_id": "2406.07151v1",
    "title": "EEG-ImageNet: An Electroencephalogram Dataset and Benchmarks with Image Visual Stimuli of Multi-Granularity Labels",
    "authors": [
      "Shuqi Zhu",
      "Ziyi Ye",
      "Qingyao Ai",
      "Yiqun Liu"
    ],
    "abstract": "Identifying and reconstructing what we see from brain activity gives us a\nspecial insight into investigating how the biological visual system represents\nthe world. While recent efforts have achieved high-performance image\nclassification and high-quality image reconstruction from brain signals\ncollected by Functional Magnetic Resonance Imaging (fMRI) or\nmagnetoencephalogram (MEG), the expensiveness and bulkiness of these devices\nmake relevant applications difficult to generalize to practical applications.\nOn the other hand, Electroencephalography (EEG), despite its advantages of ease\nof use, cost-efficiency, high temporal resolution, and non-invasive nature, has\nnot been fully explored in relevant studies due to the lack of comprehensive\ndatasets. To address this gap, we introduce EEG-ImageNet, a novel EEG dataset\ncomprising recordings from 16 subjects exposed to 4000 images selected from the\nImageNet dataset. EEG-ImageNet consists of 5 times EEG-image pairs larger than\nexisting similar EEG benchmarks. EEG-ImageNet is collected with image stimuli\nof multi-granularity labels, i.e., 40 images with coarse-grained labels and 40\nwith fine-grained labels. Based on it, we establish benchmarks for object\nclassification and image reconstruction. Experiments with several commonly used\nmodels show that the best models can achieve object classification with\naccuracy around 60% and image reconstruction with two-way identification around\n64%. These results demonstrate the dataset's potential to advance EEG-based\nvisual brain-computer interfaces, understand the visual perception of\nbiological systems, and provide potential applications in improving machine\nvisual models.",
    "categories": [
      "cs.MM",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.MM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07151v1",
    "published_date": "2024-06-11 10:52:17 UTC",
    "updated_date": "2024-06-11 10:52:17 UTC"
  },
  {
    "arxiv_id": "2406.07147v2",
    "title": "Wearable Device-Based Real-Time Monitoring of Physiological Signals: Evaluating Cognitive Load Across Different Tasks",
    "authors": [
      "Ling He",
      "Yanxin Chen",
      "Wenqi Wang",
      "Shuting He",
      "Xiaoqiang Hu"
    ],
    "abstract": "This study employs cutting-edge wearable monitoring technology to conduct\nhigh-precision, high-temporal-resolution (1-second interval) cognitive load\nassessment on electroencephalogram (EEG) data from the FP1 channel and heart\nrate variability (HRV) data of secondary vocational students. By jointly\nanalyzing these two critical physiological indicators, the research delves into\ntheir application value in assessing cognitive load among secondary vocational\nstudents and their utility across various tasks. The study designed two\nexperiments to validate the efficacy of the proposed approach: Initially, a\nrandom forest classification model, developed using the N-BACK task, enabled\nthe precise decoding of physiological signal characteristics in secondary\nvocational students under different levels of cognitive load, achieving a\nclassification accuracy of 97%. Subsequently, this classification model was\napplied in a cross-task experiment involving the National Computer Rank\nExamination (Level-1), demonstrating the method's significant applicability and\ncross-task transferability in diverse learning contexts. Conducted with high\nportability, this research holds substantial theoretical and practical\nsignificance for optimizing teaching resource allocation in secondary\nvocational education, as well as for cognitive load assessment methods and\nmonitoring. Currently, the research findings are undergoing trial\nimplementation in the school.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07147v2",
    "published_date": "2024-06-11 10:48:26 UTC",
    "updated_date": "2024-07-03 10:33:29 UTC"
  },
  {
    "arxiv_id": "2406.07590v2",
    "title": "StreamFP: Learnable Fingerprint-guided Data Selection for Efficient Stream Learning",
    "authors": [
      "Tongjun Shi",
      "Shuhao Zhang",
      "Binbin Chen",
      "Bingsheng He"
    ],
    "abstract": "Stream Learning (SL) requires models that can quickly adapt to continuously\nevolving data, posing significant challenges in both computational efficiency\nand learning accuracy. Effective data selection is critical in SL to ensure a\nbalance between information retention and training efficiency. Traditional\nrule-based data selection methods struggle to accommodate the dynamic nature of\nstreaming data, highlighting the necessity for innovative solutions that\neffectively address these challenges. Recent approaches to handling changing\ndata distributions face challenges that limit their effectiveness in fast-paced\nenvironments. In response, we propose StreamFP, a novel approach that uniquely\nemploys dynamic, learnable parameters called fingerprints to enhance data\nselection efficiency and adaptability in stream learning. StreamFP optimizes\ncoreset selection through its unique fingerprint-guided mechanism for efficient\ntraining while ensuring robust buffer updates that adaptively respond to data\ndynamics, setting it apart from existing methods in stream learning.\nExperimental results demonstrate that StreamFP outperforms state-of-the-art\nmethods by achieving accuracy improvements of 15.99%, 29.65%, and 51.24%\ncompared to baseline models across varying data arrival rates, alongside a\ntraining throughput increase of 4.6x.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07590v2",
    "published_date": "2024-06-11 10:46:41 UTC",
    "updated_date": "2025-01-04 04:29:42 UTC"
  },
  {
    "arxiv_id": "2406.07146v3",
    "title": "Argus: Benchmarking and Enhancing Vision-Language Models for 3D Radiology Report Generation",
    "authors": [
      "Che Liu",
      "Zhongwei Wan",
      "Yuqi Wang",
      "Hui Shen",
      "Haozhe Wang",
      "Kangyu Zheng",
      "Mi Zhang",
      "Rossella Arcucci"
    ],
    "abstract": "Automatic radiology report generation holds significant potential to\nstreamline the labor-intensive process of report writing by radiologists,\nparticularly for 3D radiographs such as CT scans. While CT scans are critical\nfor clinical diagnostics, they remain less explored compared to 2D radiographs.\nTo date, there has been no comprehensive benchmark for 3D radiograph report\ngeneration (3DRRG), nor sufficient investigation into the optimal training\nstrategies for Vision Language Models (VLMs) in this context, particularly with\nrespect to vision encoder choices, visual token compression, and model scaling.\nIn this work, we make three key contributions. We curate **CT-3DRRG**, the\nlargest **publicly** available 3D CT-report dataset, establishing a robust and\ndiverse benchmark for evaluating VLM performance on 3DRRG. Furthermore, we\npropose a comprehensive training recipe for building high-performing VLMs for\n3DRRG, exploring key factors such as vision encoder pretraining strategies,\nvisual token compression, and the impact of data & model scale. Guided by these\nfindings, we introduce **Argus**, a state-of-the-art family of VLMs that\nachieve superior performance across different model sizes and input 3D medical\nimage resolutions, efficiently processing high-resolution 3D images up to $512\n\\times 512 \\times 256$[^1].",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07146v3",
    "published_date": "2024-06-11 10:45:59 UTC",
    "updated_date": "2025-02-25 06:17:52 UTC"
  },
  {
    "arxiv_id": "2406.07141v2",
    "title": "Identifiable Object-Centric Representation Learning via Probabilistic Slot Attention",
    "authors": [
      "Avinash Kori",
      "Francesco Locatello",
      "Ainkaran Santhirasekaram",
      "Francesca Toni",
      "Ben Glocker",
      "Fabio De Sousa Ribeiro"
    ],
    "abstract": "Learning modular object-centric representations is crucial for systematic\ngeneralization. Existing methods show promising object-binding capabilities\nempirically, but theoretical identifiability guarantees remain relatively\nunderdeveloped. Understanding when object-centric representations can\ntheoretically be identified is crucial for scaling slot-based methods to\nhigh-dimensional images with correctness guarantees. To that end, we propose a\nprobabilistic slot-attention algorithm that imposes an aggregate mixture prior\nover object-centric slot representations, thereby providing slot\nidentifiability guarantees without supervision, up to an equivalence relation.\nWe provide empirical verification of our theoretical identifiability result\nusing both simple 2-dimensional data and high-resolution imaging datasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07141v2",
    "published_date": "2024-06-11 10:40:54 UTC",
    "updated_date": "2024-11-11 14:10:55 UTC"
  },
  {
    "arxiv_id": "2406.07129v3",
    "title": "Mining Frequent Structures in Conceptual Models",
    "authors": [
      "Mattia Fumagalli",
      "Tiago Prince Sales",
      "Pedro Paulo F. Barcelos",
      "Giovanni Micale",
      "Philipp-Lorenz Glaser",
      "Dominik Bork",
      "Vadim Zaytsev",
      "Diego Calvanese",
      "Giancarlo Guizzardi"
    ],
    "abstract": "The problem of using structured methods to represent knowledge is well-known\nin conceptual modeling and has been studied for many years. It has been proven\nthat adopting modeling patterns represents an effective structural method.\nPatterns are, indeed, generalizable recurrent structures that can be exploited\nas solutions to design problems. They aid in understanding and improving the\nprocess of creating models. The undeniable value of using patterns in\nconceptual modeling was demonstrated in several experimental studies. However,\ndiscovering patterns in conceptual models is widely recognized as a highly\ncomplex task and a systematic solution to pattern identification is currently\nlacking. In this paper, we propose a general approach to the problem of\ndiscovering frequent structures, as they occur in conceptual modeling\nlanguages. As proof of concept, we implement our approach by focusing on two\nwidely-used conceptual modeling languages. This implementation includes an\nexploratory tool that integrates a frequent subgraph mining algorithm with\ngraph manipulation techniques. The tool processes multiple conceptual models\nand identifies recurrent structures based on various criteria. We validate the\ntool using two state-of-the-art curated datasets: one consisting of models\nencoded in OntoUML and the other in ArchiMate. The primary objective of our\napproach is to provide a support tool for language engineers. This tool can be\nused to identify both effective and ineffective modeling practices, enabling\nthe refinement and evolution of conceptual modeling languages. Furthermore, it\nfacilitates the reuse of accumulated expertise, ultimately supporting the\ncreation of higher-quality models in a given language.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07129v3",
    "published_date": "2024-06-11 10:24:02 UTC",
    "updated_date": "2024-12-25 08:59:25 UTC"
  },
  {
    "arxiv_id": "2406.07126v3",
    "title": "Logical Distillation of Graph Neural Networks",
    "authors": [
      "Alexander Pluska",
      "Pascal Welke",
      "Thomas Gärtner",
      "Sagar Malhotra"
    ],
    "abstract": "We present a logic based interpretable model for learning on graphs and an\nalgorithm to distill this model from a Graph Neural Network (GNN). Recent\nresults have shown connections between the expressivity of GNNs and the\ntwo-variable fragment of first-order logic with counting quantifiers (C2). We\nintroduce a decision-tree based model which leverages an extension of C2 to\ndistill interpretable logical classifiers from GNNs. We test our approach on\nmultiple GNN architectures. The distilled models are interpretable, succinct,\nand attain similar accuracy to the underlying GNN. Furthermore, when the ground\ntruth is expressible in C2, our approach outperforms the GNN.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "To Appear in the Proceedings of KR 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.07126v3",
    "published_date": "2024-06-11 10:18:58 UTC",
    "updated_date": "2024-08-21 09:40:02 UTC"
  },
  {
    "arxiv_id": "2406.07125v1",
    "title": "CARACAS: vehiCular ArchitectuRe for detAiled Can Attacks Simulation",
    "authors": [
      "Sadek Misto Kirdi",
      "Nicola Scarano",
      "Franco Oberti",
      "Luca Mannella",
      "Stefano Di Carlo",
      "Alessandro Savino"
    ],
    "abstract": "Modern vehicles are increasingly vulnerable to attacks that exploit network\ninfrastructures, particularly the Controller Area Network (CAN) networks. To\neffectively counter such threats using contemporary tools like Intrusion\nDetection Systems (IDSs) based on data analysis and classification, large\ndatasets of CAN messages become imperative. This paper delves into the\nfeasibility of generating synthetic datasets by harnessing the modeling\ncapabilities of simulation frameworks such as Simulink coupled with a robust\nrepresentation of attack models to present CARACAS, a vehicular model,\nincluding component control via CAN messages and attack injection capabilities.\nCARACAS showcases the efficacy of this methodology, including a Battery\nElectric Vehicle (BEV) model, and focuses on attacks targeting torque control\nin two distinct scenarios.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "6 pages, 8 figures, TrustAICyberSec workshop - IEEE ISCC 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.07125v1",
    "published_date": "2024-06-11 10:16:55 UTC",
    "updated_date": "2024-06-11 10:16:55 UTC"
  },
  {
    "arxiv_id": "2406.07124v1",
    "title": "CHARME: A chain-based reinforcement learning approach for the minor embedding problem",
    "authors": [
      "Hoang M. Ngo",
      "Nguyen H K. Do",
      "Minh N. Vu",
      "Tamer Kahveci",
      "My T. Thai"
    ],
    "abstract": "Quantum Annealing (QA) holds great potential for solving combinatorial\noptimization problems efficiently. However, the effectiveness of QA algorithms\nheavily relies on the embedding of problem instances, represented as logical\ngraphs, into the quantum unit processing (QPU) whose topology is in form of a\nlimited connectivity graph, known as the minor embedding Problem. Existing\nmethods for the minor embedding problem suffer from scalability issues when\nconfronted with larger problem sizes. In this paper, we propose a novel\napproach utilizing Reinforcement Learning (RL) techniques to address the minor\nembedding problem, named CHARME. CHARME includes three key components: a Graph\nNeural Network (GNN) architecture for policy modeling, a state transition\nalgorithm ensuring solution validity, and an order exploration strategy for\neffective training. Through comprehensive experiments on synthetic and\nreal-world instances, we demonstrate that the efficiency of our proposed order\nexploration strategy as well as our proposed RL framework, CHARME. In details,\nCHARME yields superior solutions compared to fast embedding methods such as\nMinorminer and ATOM. Moreover, our method surpasses the OCT-based approach,\nknown for its slower runtime but high-quality solutions, in several cases. In\naddition, our proposed exploration enhances the efficiency of the training of\nthe CHARME framework by providing better solutions compared to the greedy\nstrategy.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07124v1",
    "published_date": "2024-06-11 10:12:10 UTC",
    "updated_date": "2024-06-11 10:12:10 UTC"
  },
  {
    "arxiv_id": "2406.07119v1",
    "title": "T2S-GPT: Dynamic Vector Quantization for Autoregressive Sign Language Production from Text",
    "authors": [
      "Aoxiong Yin",
      "Haoyuan Li",
      "Kai Shen",
      "Siliang Tang",
      "Yueting Zhuang"
    ],
    "abstract": "In this work, we propose a two-stage sign language production (SLP) paradigm\nthat first encodes sign language sequences into discrete codes and then\nautoregressively generates sign language from text based on the learned\ncodebook. However, existing vector quantization (VQ) methods are fixed-length\nencodings, overlooking the uneven information density in sign language, which\nleads to under-encoding of important regions and over-encoding of unimportant\nregions. To address this issue, we propose a novel dynamic vector quantization\n(DVA-VAE) model that can dynamically adjust the encoding length based on the\ninformation density in sign language to achieve accurate and compact encoding.\nThen, a GPT-like model learns to generate code sequences and their\ncorresponding durations from spoken language text. Extensive experiments\nconducted on the PHOENIX14T dataset demonstrate the effectiveness of our\nproposed method. To promote sign language research, we propose a new large\nGerman sign language dataset, PHOENIX-News, which contains 486 hours of sign\nlanguage videos, audio, and transcription texts.Experimental analysis on\nPHOENIX-News shows that the performance of our model can be further improved by\nincreasing the size of the training data. Our project homepage is\nhttps://t2sgpt-demo.yinaoxiong.cn.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.07119v1",
    "published_date": "2024-06-11 10:06:53 UTC",
    "updated_date": "2024-06-11 10:06:53 UTC"
  },
  {
    "arxiv_id": "2406.07117v1",
    "title": "Augmenting Offline RL with Unlabeled Data",
    "authors": [
      "Zhao Wang",
      "Briti Gangopadhyay",
      "Jia-Fong Yeh",
      "Shingo Takamatsu"
    ],
    "abstract": "Recent advancements in offline Reinforcement Learning (Offline RL) have led\nto an increased focus on methods based on conservative policy updates to\naddress the Out-of-Distribution (OOD) issue. These methods typically involve\nadding behavior regularization or modifying the critic learning objective,\nfocusing primarily on states or actions with substantial dataset support.\nHowever, we challenge this prevailing notion by asserting that the absence of\nan action or state from a dataset does not necessarily imply its suboptimality.\nIn this paper, we propose a novel approach to tackle the OOD problem. We\nintroduce an offline RL teacher-student framework, complemented by a policy\nsimilarity measure. This framework enables the student policy to gain insights\nnot only from the offline RL dataset but also from the knowledge transferred by\na teacher policy. The teacher policy is trained using another dataset\nconsisting of state-action pairs, which can be viewed as practical domain\nknowledge acquired without direct interaction with the environment. We believe\nthis additional knowledge is key to effectively solving the OOD issue. This\nresearch represents a significant advancement in integrating a teacher-student\nnetwork into the actor-critic framework, opening new avenues for studies on\nknowledge transfer in offline RL and effectively addressing the OOD challenge.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07117v1",
    "published_date": "2024-06-11 10:02:07 UTC",
    "updated_date": "2024-06-11 10:02:07 UTC"
  },
  {
    "arxiv_id": "2406.07115v2",
    "title": "Advancing Tool-Augmented Large Language Models: Integrating Insights from Errors in Inference Trees",
    "authors": [
      "Sijia Chen",
      "Yibo Wang",
      "Yi-Feng Wu",
      "Qing-Guo Chen",
      "Zhao Xu",
      "Weihua Luo",
      "Kaifu Zhang",
      "Lijun Zhang"
    ],
    "abstract": "Tool-augmented large language models (LLMs) leverage tools, often in the form\nof APIs, to improve their reasoning capabilities on complex tasks. This enables\nthem to act as intelligent agents interacting with the real world. The recently\nintroduced ToolLLaMA model by Qin et al. [2023] utilizes the depth-first\nsearch-based decision tree (DFSDT) mechanism for multi-step reasoning with\n$16000+$ real-world APIs, effectively enhancing the performance of\ntool-augmented LLMs compared to traditional chain reasoning mechanisms.\nHowever, their approach only employs successful paths from decision trees (also\ncalled inference trees) for supervised fine-tuning (SFT), missing out on the\npotential learning opportunities from failed paths. Inspired by this, we\npropose an inference trajectory optimization framework based on preference\nlearning to address this limitation. We first introduce a novel method for\nconstructing step-wise preference data from tree-like expert trajectories,\nwhich leverages the previously ignored failed explorations in the decision\ntrees. In the subsequent training phase, we first fine-tune the LLM with\nsuccessful tool-usage expert trajectories and then apply direct preference\noptimization (DPO) with the preference data to update the LLM's policy,\nresulting in our ToolPrefer-LLaMA (TP-LLaMA) model. This approach not only\nenhances the utilization of original expert data but also broadens the learning\nspace of the model. Our experiments demonstrate that by obtaining insights from\nerrors in inference trees, TP-LLaMA significantly outperforms the baselines\nacross almost all test scenarios by a large margin and exhibits better\ngeneralization capabilities with unseen APIs. At the same time, TP-LLaMA has\nalso demonstrated superior reasoning efficiency compared to the baselines,\nmaking it more suitable for complex tool-usage reasoning tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.07115v2",
    "published_date": "2024-06-11 10:00:18 UTC",
    "updated_date": "2025-03-21 08:12:07 UTC"
  },
  {
    "arxiv_id": "2406.07114v2",
    "title": "Unlocking the Potential of Metaverse in Innovative and Immersive Digital Health",
    "authors": [
      "Fatemeh Ebrahimzadeh",
      "Ramin Safa"
    ],
    "abstract": "The concept of Metaverse has attracted a lot of attention in various fields\nand one of its important applications is health and treatment. The Metaverse\nhas enormous potential to transform healthcare by changing patient care,\nmedical education, and the way teaching/learning and research are done. The\npurpose of this research is to provide an introduction to the basic concepts\nand fundamental technologies of the Metaverse. This paper examines the pros and\ncons of the Metaverse in healthcare context and analyzes its potential from the\ntechnology and AI perspective. In particular, the role of machine learning\nmethods is discussed; We will explain how machine learning algorithms can be\napplied to the Metaverse generated data to gain better insights in healthcare\napplications. Additionally, we examine the future visions of the Metaverse in\nhealth delivery, by examining emerging technologies such as blockchain and also\naddressing privacy concerns. The findings of this study contribute to a deeper\nunderstanding of the applications of Metaverse in healthcare and its potential\nto revolutionize the delivery of medical services.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.IR",
      "68T01a",
      "I.2.0; I.2.1"
    ],
    "primary_category": "cs.CY",
    "comment": "12 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.07114v2",
    "published_date": "2024-06-11 09:58:27 UTC",
    "updated_date": "2024-07-04 20:08:38 UTC"
  },
  {
    "arxiv_id": "2406.07113v4",
    "title": "Beyond Bare Queries: Open-Vocabulary Object Grounding with 3D Scene Graph",
    "authors": [
      "Sergey Linok",
      "Tatiana Zemskova",
      "Svetlana Ladanova",
      "Roman Titkov",
      "Dmitry Yudin",
      "Maxim Monastyrny",
      "Aleksei Valenkov"
    ],
    "abstract": "Locating objects described in natural language presents a significant\nchallenge for autonomous agents. Existing CLIP-based open-vocabulary methods\nsuccessfully perform 3D object grounding with simple (bare) queries, but cannot\ncope with ambiguous descriptions that demand an understanding of object\nrelations. To tackle this problem, we propose a modular approach called BBQ\n(Beyond Bare Queries), which constructs 3D scene graph representation with\nmetric and semantic spatial edges and utilizes a large language model as a\nhuman-to-agent interface through our deductive scene reasoning algorithm. BBQ\nemploys robust DINO-powered associations to construct 3D object-centric map and\nan advanced raycasting algorithm with a 2D vision-language model to describe\nthem as graph nodes. On the Replica and ScanNet datasets, we have demonstrated\nthat BBQ takes a leading place in open-vocabulary 3D semantic segmentation\ncompared to other zero-shot methods. Also, we show that leveraging spatial\nrelations is especially effective for scenes containing multiple entities of\nthe same semantic class. On challenging Sr3D+, Nr3D and ScanRefer benchmarks,\nour deductive approach demonstrates a significant improvement, enabling objects\ngrounding by complex queries compared to other state-of-the-art methods. The\ncombination of our design choices and software implementation has resulted in\nsignificant data processing speed in experiments on the robot on-board\ncomputer. This promising performance enables the application of our approach in\nintelligent robotics projects. We made the code publicly available at\nhttps://linukc.github.io/BeyondBareQueries/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "6 pages, 6 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2406.07113v4",
    "published_date": "2024-06-11 09:57:04 UTC",
    "updated_date": "2025-05-06 14:02:10 UTC"
  },
  {
    "arxiv_id": "2406.07589v1",
    "title": "Tag and correct: high precision post-editing approach to correction of speech recognition errors",
    "authors": [
      "Tomasz Ziętkiewicz"
    ],
    "abstract": "This paper presents a new approach to the problem of correcting speech\nrecognition errors by means of post-editing. It consists of using a neural\nsequence tagger that learns how to correct an ASR (Automatic Speech\nRecognition) hypothesis word by word and a corrector module that applies\ncorrections returned by the tagger. The proposed solution is applicable to any\nASR system, regardless of its architecture, and provides high-precision control\nover errors being corrected. This is especially crucial in production\nenvironments, where avoiding the introduction of new mistakes by the error\ncorrection model may be more important than the net gain in overall results.\nThe results show that the performance of the proposed error correction models\nis comparable with previous approaches while requiring much smaller resources\nto train, which makes it suitable for industrial applications, where both\ninference latency and training times are critical factors that limit the use of\nother techniques.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "5 pages, 3 figures, Published in Proceedings of the 17th Conference\n  on Computer Science and Intelligence Systems (FedCSIS 2022)",
    "pdf_url": "http://arxiv.org/pdf/2406.07589v1",
    "published_date": "2024-06-11 09:52:33 UTC",
    "updated_date": "2024-06-11 09:52:33 UTC"
  },
  {
    "arxiv_id": "2406.07103v1",
    "title": "MR-RawNet: Speaker verification system with multiple temporal resolutions for variable duration utterances using raw waveforms",
    "authors": [
      "Seung-bin Kim",
      "Chan-yeong Lim",
      "Jungwoo Heo",
      "Ju-ho Kim",
      "Hyun-seo Shin",
      "Kyo-Won Koo",
      "Ha-Jin Yu"
    ],
    "abstract": "In speaker verification systems, the utilization of short utterances presents\na persistent challenge, leading to performance degradation primarily due to\ninsufficient phonetic information to characterize the speakers. To overcome\nthis obstacle, we propose a novel structure, MR-RawNet, designed to enhance the\nrobustness of speaker verification systems against variable duration utterances\nusing raw waveforms. The MR-RawNet extracts time-frequency representations from\nraw waveforms via a multi-resolution feature extractor that optimally adjusts\nboth temporal and spectral resolutions simultaneously. Furthermore, we apply a\nmulti-resolution attention block that focuses on diverse and extensive temporal\ncontexts, ensuring robustness against changes in utterance length. The\nexperimental results, conducted on VoxCeleb1 dataset, demonstrate that the\nMR-RawNet exhibits superior performance in handling utterances of variable\nduration compared to other raw waveform-based systems.",
    "categories": [
      "eess.AS",
      "cs.AI"
    ],
    "primary_category": "eess.AS",
    "comment": "5 pages, accepted by Interspeech 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.07103v1",
    "published_date": "2024-06-11 09:42:47 UTC",
    "updated_date": "2024-06-11 09:42:47 UTC"
  },
  {
    "arxiv_id": "2406.07100v3",
    "title": "D-GRIL: End-to-End Topological Learning with 2-parameter Persistence",
    "authors": [
      "Soham Mukherjee",
      "Shreyas N. Samaga",
      "Cheng Xin",
      "Steve Oudot",
      "Tamal K. Dey"
    ],
    "abstract": "End-to-end topological learning using 1-parameter persistence is well-known.\nWe show that the framework can be enhanced using 2-parameter persistence by\nadopting a recently introduced 2-parameter persistence based vectorization\ntechnique called GRIL. We establish a theoretical foundation of differentiating\nGRIL producing D-GRIL. We show that D-GRIL can be used to learn a bifiltration\nfunction on standard benchmark graph datasets. Further, we exhibit that this\nframework can be applied in the context of bio-activity prediction in drug\ndiscovery.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.AT"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07100v3",
    "published_date": "2024-06-11 09:42:03 UTC",
    "updated_date": "2025-02-22 02:59:16 UTC"
  },
  {
    "arxiv_id": "2406.07098v1",
    "title": "Guiding Catalogue Enrichment with User Queries",
    "authors": [
      "Yupei Du",
      "Jacek Golebiowski",
      "Philipp Schmidt",
      "Ziawasch Abedjan"
    ],
    "abstract": "Techniques for knowledge graph (KGs) enrichment have been increasingly\ncrucial for commercial applications that rely on evolving product catalogues.\nHowever, because of the huge search space of potential enrichment, predictions\nfrom KG completion (KGC) methods suffer from low precision, making them\nunreliable for real-world catalogues. Moreover, candidate facts for enrichment\nhave varied relevance to users. While making correct predictions for incomplete\ntriplets in KGs has been the main focus of KGC method, the relevance of when to\napply such predictions has been neglected. Motivated by the product search use\ncase, we address the angle of generating relevant completion for a catalogue\nusing user search behaviour and the users property association with a product.\nIn this paper, we present our intuition for identifying enrichable data points\nand use general-purpose KGs to show-case the performance benefits. In\nparticular, we extract entity-predicate pairs from user queries, which are more\nlikely to be correct and relevant, and use these pairs to guide the prediction\nof KGC methods. We assess our method on two popular encyclopedia KGs, DBPedia\nand YAGO 4. Our results from both automatic and human evaluations show that\nquery guidance can significantly improve the correctness and relevance of\nprediction.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.IR",
    "comment": "ECML PKDD 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.07098v1",
    "published_date": "2024-06-11 09:38:46 UTC",
    "updated_date": "2024-06-11 09:38:46 UTC"
  },
  {
    "arxiv_id": "2406.07096v1",
    "title": "Fast Context-Biasing for CTC and Transducer ASR models with CTC-based Word Spotter",
    "authors": [
      "Andrei Andrusenko",
      "Aleksandr Laptev",
      "Vladimir Bataev",
      "Vitaly Lavrukhin",
      "Boris Ginsburg"
    ],
    "abstract": "Accurate recognition of rare and new words remains a pressing problem for\ncontextualized Automatic Speech Recognition (ASR) systems. Most context-biasing\nmethods involve modification of the ASR model or the beam-search decoding\nalgorithm, complicating model reuse and slowing down inference. This work\npresents a new approach to fast context-biasing with CTC-based Word Spotter\n(CTC-WS) for CTC and Transducer (RNN-T) ASR models. The proposed method matches\nCTC log-probabilities against a compact context graph to detect potential\ncontext-biasing candidates. The valid candidates then replace their greedy\nrecognition counterparts in corresponding frame intervals. A Hybrid\nTransducer-CTC model enables the CTC-WS application for the Transducer model.\nThe results demonstrate a significant acceleration of the context-biasing\nrecognition with a simultaneous improvement in F-score and WER compared to\nbaseline methods. The proposed method is publicly available in the NVIDIA NeMo\ntoolkit.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "Accepted by Interspeech 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.07096v1",
    "published_date": "2024-06-11 09:37:52 UTC",
    "updated_date": "2024-06-11 09:37:52 UTC"
  },
  {
    "arxiv_id": "2406.07095v1",
    "title": "Data Complexity in Expressive Description Logics With Path Expressions",
    "authors": [
      "Bartosz Bednarczyk"
    ],
    "abstract": "We investigate the data complexity of the satisfiability problem for the very\nexpressive description logic ZOIQ (a.k.a. ALCHb Self reg OIQ) over\nquasi-forests and establish its NP-completeness. This completes the data\ncomplexity landscape for decidable fragments of ZOIQ, and reproves known\nresults on decidable fragments of OWL2 (SR family). Using the same technique,\nwe establish coNEXPTIME-completeness (w.r.t. the combined complexity) of the\nentailment problem of rooted queries in ZIQ.",
    "categories": [
      "cs.LO",
      "cs.AI",
      "cs.CC"
    ],
    "primary_category": "cs.LO",
    "comment": "Accepted to IJCAI 2024. A version with the appendix will appear soon",
    "pdf_url": "http://arxiv.org/pdf/2406.07095v1",
    "published_date": "2024-06-11 09:37:51 UTC",
    "updated_date": "2024-06-11 09:37:51 UTC"
  },
  {
    "arxiv_id": "2407.00050v1",
    "title": "FoldToken2: Learning compact, invariant and generative protein structure language",
    "authors": [
      "Zhangyang Gao",
      "Cheng Tan",
      "Stan Z. Li"
    ],
    "abstract": "The equivalent nature of 3D coordinates has posed long term challenges in\nprotein structure representation learning, alignment, and generation. Can we\ncreate a compact and invariant language that equivalently represents protein\nstructures? Towards this goal, we propose FoldToken2 to transfer equivariant\nstructures into discrete tokens, while maintaining the recoverability of the\noriginal structures. From FoldToken1 to FoldToken2, we improve three key\ncomponents: (1) invariant structure encoder, (2) vector-quantized compressor,\nand (3) equivalent structure decoder. We evaluate FoldToken2 on the protein\nstructure reconstruction task and show that it outperforms previous FoldToken1\nby 20\\% in TMScore and 81\\% in RMSD. FoldToken2 probably be the first method\nthat works well on both single-chain and multi-chain protein structures\nquantization. We believe that FoldToken2 will inspire further improvement in\nprotein structure representation learning, structure alignment, and structure\ngeneration tasks.",
    "categories": [
      "q-bio.BM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.BM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.00050v1",
    "published_date": "2024-06-11 09:24:51 UTC",
    "updated_date": "2024-06-11 09:24:51 UTC"
  },
  {
    "arxiv_id": "2406.10267v2",
    "title": "Unused information in token probability distribution of generative LLM: improving LLM reading comprehension through calculation of expected values",
    "authors": [
      "Krystian Zawistowski"
    ],
    "abstract": "LLM text decoding is key component for perceived LLM quality. We demonstrate\ntwo experiments showing that decoding methods could be improved by manipulation\nof token probabilities. First, we test few LLM on SummEval summary scoring\ndataset, to measure reading comprehension. We compare scores from greedy\ndecoding to expected values over the next token distribution. We scale logits\nby large temperature to increase the entropy of scores. This allows strong\nimprovement of performance on SummEval (in terms of correlations to human\njudgement). We see improvement from 6-8% to 13-28% for 7B Mistral and from\n20%-46% to 37%-56% for Mixtral, beating GPT 4 0314 result on two metrics. Part\nof the gain seems related to positional bias. Secondly, we use\nprobability-based tree sampling algorithm, to examine all most probable\ngenerations for given prompt.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "7 pages, 1 figure, presented at FEDCSIS 2024 conference,",
    "pdf_url": "http://arxiv.org/pdf/2406.10267v2",
    "published_date": "2024-06-11 09:24:18 UTC",
    "updated_date": "2024-09-26 06:57:27 UTC"
  },
  {
    "arxiv_id": "2406.07078v1",
    "title": "Unified Modeling Enhanced Multimodal Learning for Precision Neuro-Oncology",
    "authors": [
      "Huahui Yi",
      "Xiaofei Wang",
      "Kang Li",
      "Chao Li"
    ],
    "abstract": "Multimodal learning, integrating histology images and genomics, promises to\nenhance precision oncology with comprehensive views at microscopic and\nmolecular levels. However, existing methods may not sufficiently model the\nshared or complementary information for more effective integration. In this\nstudy, we introduce a Unified Modeling Enhanced Multimodal Learning (UMEML)\nframework that employs a hierarchical attention structure to effectively\nleverage shared and complementary features of both modalities of histology and\ngenomics. Specifically, to mitigate unimodal bias from modality imbalance, we\nutilize a query-based cross-attention mechanism for prototype clustering in the\npathology encoder. Our prototype assignment and modularity strategy are\ndesigned to align shared features and minimizes modality gaps. An additional\nregistration mechanism with learnable tokens is introduced to enhance\ncross-modal feature integration and robustness in multimodal unified modeling.\nOur experiments demonstrate that our method surpasses previous state-of-the-art\napproaches in glioma diagnosis and prognosis tasks, underscoring its\nsuperiority in precision neuro-Oncology.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07078v1",
    "published_date": "2024-06-11 09:06:41 UTC",
    "updated_date": "2024-06-11 09:06:41 UTC"
  },
  {
    "arxiv_id": "2406.07067v1",
    "title": "TIM: Temporal Interaction Model in Notification System",
    "authors": [
      "Huxiao Ji",
      "Haitao Yang",
      "Linchuan Li",
      "Shunyu Zhang",
      "Cunyi Zhang",
      "Xuanping Li",
      "Wenwu Ou"
    ],
    "abstract": "Modern mobile applications heavily rely on the notification system to acquire\ndaily active users and enhance user engagement. Being able to proactively reach\nusers, the system has to decide when to send notifications to users. Although\nmany researchers have studied optimizing the timing of sending notifications,\nthey only utilized users' contextual features, without modeling users' behavior\npatterns. Additionally, these efforts only focus on individual notifications,\nand there is a lack of studies on optimizing the holistic timing of multiple\nnotifications within a period. To bridge these gaps, we propose the Temporal\nInteraction Model (TIM), which models users' behavior patterns by estimating\nCTR in every time slot over a day in our short video application Kuaishou. TIM\nleverages long-term user historical interaction sequence features such as\nnotification receipts, clicks, watch time and effective views, and employs a\ntemporal attention unit (TAU) to extract user behavior patterns. Moreover, we\nprovide an elegant strategy of holistic notifications send time control to\nimprove user engagement while minimizing disruption. We evaluate the\neffectiveness of TIM through offline experiments and online A/B tests. The\nresults indicate that TIM is a reliable tool for forecasting user behavior,\nleading to a remarkable enhancement in user engagement without causing undue\ndisturbance.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07067v1",
    "published_date": "2024-06-11 08:53:15 UTC",
    "updated_date": "2024-06-11 08:53:15 UTC"
  },
  {
    "arxiv_id": "2406.07063v1",
    "title": "Reconstructing the Tropical Pacific Upper Ocean using Online Data Assimilation with a Deep Learning model",
    "authors": [
      "Zilu Meng",
      "Gregory J. Hakim"
    ],
    "abstract": "A deep learning (DL) model, based on a transformer architecture, is trained\non a climate-model dataset and compared with a standard linear inverse model\n(LIM) in the tropical Pacific. We show that the DL model produces more accurate\nforecasts compared to the LIM when tested on a reanalysis dataset. We then\nassess the ability of an ensemble Kalman filter to reconstruct the\nmonthly-averaged upper ocean from a noisy set of 24 sea-surface temperature\nobservations designed to mimic existing coral proxy measurements, and compare\nresults for the DL model and LIM. Due to signal damping in the DL model, we\nimplement a novel inflation technique by adding noise from hindcast\nexperiments. Results show that assimilating observations with the DL model\nyields better reconstructions than the LIM for observation averaging times\nranging from one month to one year. The improved reconstruction is due to the\nenhanced predictive capabilities of the DL model, which map the memory of past\nobservations to future assimilation times.",
    "categories": [
      "physics.ao-ph",
      "cs.AI",
      "physics.flu-dyn"
    ],
    "primary_category": "physics.ao-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07063v1",
    "published_date": "2024-06-11 08:45:41 UTC",
    "updated_date": "2024-06-11 08:45:41 UTC"
  },
  {
    "arxiv_id": "2406.07060v1",
    "title": "Reading Miscue Detection in Primary School through Automatic Speech Recognition",
    "authors": [
      "Lingyun Gao",
      "Cristian Tejedor-Garcia",
      "Helmer Strik",
      "Catia Cucchiarini"
    ],
    "abstract": "Automatic reading diagnosis systems can benefit both teachers for more\nefficient scoring of reading exercises and students for accessing reading\nexercises with feedback more easily. However, there are limited studies on\nAutomatic Speech Recognition (ASR) for child speech in languages other than\nEnglish, and limited research on ASR-based reading diagnosis systems. This\nstudy investigates how efficiently state-of-the-art (SOTA) pretrained ASR\nmodels recognize Dutch native children speech and manage to detect reading\nmiscues. We found that Hubert Large finetuned on Dutch speech achieves SOTA\nphoneme-level child speech recognition (PER at 23.1\\%), while Whisper (Faster\nWhisper Large-v2) achieves SOTA word-level performance (WER at 9.8\\%). Our\nfindings suggest that Wav2Vec2 Large and Whisper are the two best ASR models\nfor reading miscue detection. Specifically, Wav2Vec2 Large shows the highest\nrecall at 0.83, whereas Whisper exhibits the highest precision at 0.52 and an\nF1 score of 0.52.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "eess.AS",
      "eess.SP"
    ],
    "primary_category": "cs.CL",
    "comment": "Proc. INTERSPEECH 2024, 1-5 September 2024. Kos Island, Greece",
    "pdf_url": "http://arxiv.org/pdf/2406.07060v1",
    "published_date": "2024-06-11 08:41:21 UTC",
    "updated_date": "2024-06-11 08:41:21 UTC"
  },
  {
    "arxiv_id": "2406.07057v2",
    "title": "MultiTrust: A Comprehensive Benchmark Towards Trustworthy Multimodal Large Language Models",
    "authors": [
      "Yichi Zhang",
      "Yao Huang",
      "Yitong Sun",
      "Chang Liu",
      "Zhe Zhao",
      "Zhengwei Fang",
      "Yifan Wang",
      "Huanran Chen",
      "Xiao Yang",
      "Xingxing Wei",
      "Hang Su",
      "Yinpeng Dong",
      "Jun Zhu"
    ],
    "abstract": "Despite the superior capabilities of Multimodal Large Language Models (MLLMs)\nacross diverse tasks, they still face significant trustworthiness challenges.\nYet, current literature on the assessment of trustworthy MLLMs remains limited,\nlacking a holistic evaluation to offer thorough insights into future\nimprovements. In this work, we establish MultiTrust, the first comprehensive\nand unified benchmark on the trustworthiness of MLLMs across five primary\naspects: truthfulness, safety, robustness, fairness, and privacy. Our benchmark\nemploys a rigorous evaluation strategy that addresses both multimodal risks and\ncross-modal impacts, encompassing 32 diverse tasks with self-curated datasets.\nExtensive experiments with 21 modern MLLMs reveal some previously unexplored\ntrustworthiness issues and risks, highlighting the complexities introduced by\nthe multimodality and underscoring the necessity for advanced methodologies to\nenhance their reliability. For instance, typical proprietary models still\nstruggle with the perception of visually confusing images and are vulnerable to\nmultimodal jailbreaking and adversarial attacks; MLLMs are more inclined to\ndisclose privacy in text and reveal ideological and cultural biases even when\npaired with irrelevant images in inference, indicating that the multimodality\namplifies the internal risks from base LLMs. Additionally, we release a\nscalable toolbox for standardized trustworthiness research, aiming to\nfacilitate future advancements in this important field. Code and resources are\npublicly available at: https://multi-trust.github.io/.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "100 pages, 84 figures, 33 tables",
    "pdf_url": "http://arxiv.org/pdf/2406.07057v2",
    "published_date": "2024-06-11 08:38:13 UTC",
    "updated_date": "2024-12-06 14:21:06 UTC"
  },
  {
    "arxiv_id": "2406.07054v2",
    "title": "CoEvol: Constructing Better Responses for Instruction Finetuning through Multi-Agent Cooperation",
    "authors": [
      "Renhao Li",
      "Minghuan Tan",
      "Derek F. Wong",
      "Min Yang"
    ],
    "abstract": "In recent years, instruction fine-tuning (IFT) on large language models\n(LLMs) has garnered considerable attention to enhance model performance on\nunseen tasks. Attempts have been made on automatic construction and effective\nselection for IFT data. However, we posit that previous methods have not fully\nharnessed the potential of LLMs for enhancing data quality. The responses\nwithin IFT data could be further enhanced by leveraging the capabilities of\nLLMs themselves. In this paper, we propose CoEvol, an LLM-based multi-agent\ncooperation framework for the improvement of responses to instructions. To\neffectively refine the responses, we develop an iterative framework following a\ndebate-advise-edit-judge paradigm. A two-stage multi-agent debate strategy is\nfurther devised to ensure the diversity and reliability of editing suggestions\nwithin the framework. Empirically, models equipped with CoEvol outperform\ncompetitive baselines evaluated by MT-Bench and AlpacaEval, demonstrating its\neffectiveness in enhancing instruction-following capabilities for LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to the main conference of EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.07054v2",
    "published_date": "2024-06-11 08:35:37 UTC",
    "updated_date": "2024-10-24 02:59:46 UTC"
  },
  {
    "arxiv_id": "2406.07041v1",
    "title": "Integrating Domain Knowledge for handling Limited Data in Offline RL",
    "authors": [
      "Briti Gangopadhyay",
      "Zhao Wang",
      "Jia-Fong Yeh",
      "Shingo Takamatsu"
    ],
    "abstract": "With the ability to learn from static datasets, Offline Reinforcement\nLearning (RL) emerges as a compelling avenue for real-world applications.\nHowever, state-of-the-art offline RL algorithms perform sub-optimally when\nconfronted with limited data confined to specific regions within the state\nspace. The performance degradation is attributed to the inability of offline RL\nalgorithms to learn appropriate actions for rare or unseen observations. This\npaper proposes a novel domain knowledge-based regularization technique and\nadaptively refines the initial domain knowledge to considerably boost\nperformance in limited data with partially omitted states. The key insight is\nthat the regularization term mitigates erroneous actions for sparse samples and\nunobserved states covered by domain knowledge. Empirical evaluations on\nstandard discrete environment datasets demonstrate a substantial average\nperformance increase of at least 27% compared to existing offline RL algorithms\noperating on limited data.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07041v1",
    "published_date": "2024-06-11 07:59:17 UTC",
    "updated_date": "2024-06-11 07:59:17 UTC"
  },
  {
    "arxiv_id": "2406.07036v1",
    "title": "Paying More Attention to Source Context: Mitigating Unfaithful Translations from Large Language Model",
    "authors": [
      "Hongbin Zhang",
      "Kehai Chen",
      "Xuefeng Bai",
      "Yang Xiang",
      "Min Zhang"
    ],
    "abstract": "Large language models (LLMs) have showcased impressive multilingual machine\ntranslation ability. However, unlike encoder-decoder style models, decoder-only\nLLMs lack an explicit alignment between source and target contexts. Analyzing\ncontribution scores during generation processes revealed that LLMs can be\nbiased towards previously generated tokens over corresponding source tokens,\nleading to unfaithful translations. To address this issue, we propose to\nencourage LLMs to pay more attention to the source context from both source and\ntarget perspectives in zeroshot prompting: 1) adjust source context attention\nweights; 2) suppress irrelevant target prefix influence; Additionally, we\npropose 3) avoiding over-reliance on the target prefix in instruction tuning.\nExperimental results from both human-collected unfaithfulness test sets\nfocusing on LLM-generated unfaithful translations and general test sets, verify\nour methods' effectiveness across multiple language pairs. Further human\nevaluation shows our method's efficacy in reducing hallucinatory translations\nand facilitating faithful translation generation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by ACL2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2406.07036v1",
    "published_date": "2024-06-11 07:49:04 UTC",
    "updated_date": "2024-06-11 07:49:04 UTC"
  },
  {
    "arxiv_id": "2406.07034v1",
    "title": "Improving Multi-hop Logical Reasoning in Knowledge Graphs with Context-Aware Query Representation Learning",
    "authors": [
      "Jeonghoon Kim",
      "Heesoo Jung",
      "Hyeju Jang",
      "Hogun Park"
    ],
    "abstract": "Multi-hop logical reasoning on knowledge graphs is a pivotal task in natural\nlanguage processing, with numerous approaches aiming to answer First-Order\nLogic (FOL) queries. Recent geometry (e.g., box, cone) and probability (e.g.,\nbeta distribution)-based methodologies have effectively addressed complex FOL\nqueries. However, a common challenge across these methods lies in determining\naccurate geometric bounds or probability parameters for these queries. The\nchallenge arises because existing methods rely on linear sequential operations\nwithin their computation graphs, overlooking the logical structure of the query\nand the relation-induced information that can be gleaned from the relations of\nthe query, which we call the context of the query. To address the problem, we\npropose a model-agnostic methodology that enhances the effectiveness of\nexisting multi-hop logical reasoning approaches by fully integrating the\ncontext of the FOL query graph. Our approach distinctively discerns (1) the\nstructural context inherent to the query structure and (2) the relation-induced\ncontext unique to each node in the query graph as delineated in the\ncorresponding knowledge graph. This dual-context paradigm helps nodes within a\nquery graph attain refined internal representations throughout the multi-hop\nreasoning steps. Through experiments on two datasets, our method consistently\nenhances the three multi-hop reasoning foundation models, achieving performance\nimprovements of up to 19.5%. Our code is available at\nhttps://github.com/kjh9503/caqr.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to ACL 2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2406.07034v1",
    "published_date": "2024-06-11 07:48:20 UTC",
    "updated_date": "2024-06-11 07:48:20 UTC"
  },
  {
    "arxiv_id": "2406.10265v2",
    "title": "Improving Language Models for Emotion Analysis: Insights from Cognitive Science",
    "authors": [
      "Constant Bonard",
      "Gustave Cortal"
    ],
    "abstract": "We propose leveraging cognitive science research on emotions and\ncommunication to improve language models for emotion analysis. First, we\npresent the main emotion theories in psychology and cognitive science. Then, we\nintroduce the main methods of emotion annotation in natural language processing\nand their connections to psychological theories. We also present the two main\ntypes of analyses of emotional communication in cognitive pragmatics. Finally,\nbased on the cognitive science research presented, we propose directions for\nimproving language models for emotion analysis. We suggest that these research\nefforts pave the way for constructing new annotation schemes, methods, and a\npossible benchmark for emotional understanding, considering different facets of\nhuman emotion and communication.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.10265v2",
    "published_date": "2024-06-11 07:42:13 UTC",
    "updated_date": "2024-08-26 10:54:12 UTC"
  },
  {
    "arxiv_id": "2406.07028v1",
    "title": "Heterogeneous Learning Rate Scheduling for Neural Architecture Search on Long-Tailed Datasets",
    "authors": [
      "Chenxia Tang"
    ],
    "abstract": "In this paper, we attempt to address the challenge of applying Neural\nArchitecture Search (NAS) algorithms, specifically the Differentiable\nArchitecture Search (DARTS), to long-tailed datasets where class distribution\nis highly imbalanced. We observe that traditional re-sampling and re-weighting\ntechniques, which are effective in standard classification tasks, lead to\nperformance degradation when combined with DARTS. To mitigate this, we propose\na novel adaptive learning rate scheduling strategy tailored for the\narchitecture parameters of DARTS when integrated with the Bilateral Branch\nNetwork (BBN) for handling imbalanced datasets. Our approach dynamically\nadjusts the learning rate of the architecture parameters based on the training\nepoch, preventing the disruption of well-trained representations in the later\nstages of training. Additionally, we explore the impact of branch mixing\nfactors on the algorithm's performance. Through extensive experiments on the\nCIFAR-10 dataset with an artificially induced long-tailed distribution, we\ndemonstrate that our method achieves comparable accuracy to using DARTS alone.\nAnd the experiment results suggest that re-sampling methods inherently harm the\nperformance of the DARTS algorithm. Our findings highlight the importance of\ncareful data augment when applying DNAS to imbalanced learning scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.07028v1",
    "published_date": "2024-06-11 07:32:25 UTC",
    "updated_date": "2024-06-11 07:32:25 UTC"
  },
  {
    "arxiv_id": "2406.07025v2",
    "title": "Entropy-Reinforced Planning with Large Language Models for Drug Discovery",
    "authors": [
      "Xuefeng Liu",
      "Chih-chan Tien",
      "Peng Ding",
      "Songhao Jiang",
      "Rick L. Stevens"
    ],
    "abstract": "The objective of drug discovery is to identify chemical compounds that\npossess specific pharmaceutical properties toward a binding target. Existing\nlarge language models (LLMS) can achieve high token matching scores in terms of\nlikelihood for molecule generation. However, relying solely on LLM decoding\noften results in the generation of molecules that are either invalid due to a\nsingle misused token, or suboptimal due to unbalanced exploration and\nexploitation as a consequence of the LLMs prior experience. Here we propose\nERP, Entropy-Reinforced Planning for Transformer Decoding, which employs an\nentropy-reinforced planning algorithm to enhance the Transformer decoding\nprocess and strike a balance between exploitation and exploration. ERP aims to\nachieve improvements in multiple properties compared to direct sampling from\nthe Transformer. We evaluated ERP on the SARS-CoV-2 virus (3CLPro) and human\ncancer cell target protein (RTCB) benchmarks and demonstrated that, in both\nbenchmarks, ERP consistently outperforms the current state-of-the-art algorithm\nby 1-5 percent, and baselines by 5-10 percent, respectively. Moreover, such\nimprovement is robust across Transformer models trained with different\nobjectives. Finally, to further illustrate the capabilities of ERP, we tested\nour algorithm on three code generation benchmarks and outperformed the current\nstate-of-the-art approach as well. Our code is publicly available at:\nhttps://github.com/xuefeng-cs/ERP.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.QM",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Published in ICML2024",
    "pdf_url": "http://arxiv.org/pdf/2406.07025v2",
    "published_date": "2024-06-11 07:29:13 UTC",
    "updated_date": "2025-03-29 07:27:37 UTC"
  },
  {
    "arxiv_id": "2406.07016v4",
    "title": "Delving into ChatGPT usage in academic writing through excess vocabulary",
    "authors": [
      "Dmitry Kobak",
      "Rita González-Márquez",
      "Emőke-Ágnes Horvát",
      "Jan Lause"
    ],
    "abstract": "Large language models (LLMs) like ChatGPT can generate and revise text with\nhuman-level performance. These models come with clear limitations: they can\nproduce inaccurate information, reinforce existing biases, and be easily\nmisused. Yet, many scientists use them for their scholarly writing. But how\nwide-spread is such LLM usage in the academic literature? To answer this\nquestion, we present an unbiased, large-scale approach: we study vocabulary\nchanges in 14 million PubMed abstracts from 2010--2024, and show how the\nappearance of LLMs led to an abrupt increase in the frequency of certain style\nwords. This excess word analysis suggests that at least 10% of 2024 abstracts\nwere processed with LLMs. This lower bound differed across disciplines,\ncountries, and journals, reaching 30% for some sub-corpora. We show that LLMs\nhave had an unprecedented impact on the scientific literature, surpassing the\neffect of major world events such as the Covid pandemic.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.DL",
      "cs.SI"
    ],
    "primary_category": "cs.CL",
    "comment": "v4: Reverting to v2",
    "pdf_url": "http://arxiv.org/pdf/2406.07016v4",
    "published_date": "2024-06-11 07:16:34 UTC",
    "updated_date": "2025-02-19 22:15:24 UTC"
  },
  {
    "arxiv_id": "2406.07008v1",
    "title": "Eye-for-an-eye: Appearance Transfer with Semantic Correspondence in Diffusion Models",
    "authors": [
      "Sooyeon Go",
      "Kyungmook Choi",
      "Minjung Shin",
      "Youngjung Uh"
    ],
    "abstract": "As pretrained text-to-image diffusion models have become a useful tool for\nimage synthesis, people want to specify the results in various ways. In this\npaper, we introduce a method to produce results with the same structure of a\ntarget image but painted with colors from a reference image, i.e., appearance\ntransfer, especially following the semantic correspondence between the result\nand the reference. E.g., the result wing takes color from the reference wing,\nnot the reference head. Existing methods rely on the query-key similarity\nwithin self-attention layer, usually producing defective results. To this end,\nwe propose to find semantic correspondences and explicitly rearrange the\nfeatures according to the semantic correspondences. Extensive experiments show\nthe superiority of our method in various aspects: preserving the structure of\nthe target and reflecting the color from the reference according to the\nsemantic correspondences, even when the two images are not aligned.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "project page : https://sooyeon-go.github.io/eye_for_an_eye/",
    "pdf_url": "http://arxiv.org/pdf/2406.07008v1",
    "published_date": "2024-06-11 07:08:48 UTC",
    "updated_date": "2024-06-11 07:08:48 UTC"
  },
  {
    "arxiv_id": "2406.07001v1",
    "title": "Mitigating Boundary Ambiguity and Inherent Bias for Text Classification in the Era of Large Language Models",
    "authors": [
      "Zhenyi Lu",
      "Jie Tian",
      "Wei Wei",
      "Xiaoye Qu",
      "Yu Cheng",
      "Wenfeng xie",
      "Dangyang Chen"
    ],
    "abstract": "Text classification is a crucial task encountered frequently in practical\nscenarios, yet it is still under-explored in the era of large language models\n(LLMs). This study shows that LLMs are vulnerable to changes in the number and\narrangement of options in text classification. Our extensive empirical analyses\nreveal that the key bottleneck arises from ambiguous decision boundaries and\ninherent biases towards specific tokens and positions. To mitigate these\nissues, we make the first attempt and propose a novel two-stage classification\nframework for LLMs. Our approach is grounded in the empirical observation that\npairwise comparisons can effectively alleviate boundary ambiguity and inherent\nbias. Specifically, we begin with a self-reduction technique to efficiently\nnarrow down numerous options, which contributes to reduced decision space and a\nfaster comparison process. Subsequently, pairwise contrastive comparisons are\nemployed in a chain-of-thought manner to draw out nuances and distinguish\nconfusable options, thus refining the ambiguous decision boundary. Extensive\nexperiments on four datasets (Banking77, HWU64, LIU54, and Clinic150) verify\nthe effectiveness of our framework. Furthermore, benefitting from our\nframework, various LLMs can achieve consistent improvements. Our code and data\nare available in \\url{https://github.com/Chuge0335/PC-CoT}.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL2024 findings",
    "pdf_url": "http://arxiv.org/pdf/2406.07001v1",
    "published_date": "2024-06-11 06:53:19 UTC",
    "updated_date": "2024-06-11 06:53:19 UTC"
  },
  {
    "arxiv_id": "2406.06976v2",
    "title": "Discrete Dictionary-based Decomposition Layer for Structured Representation Learning",
    "authors": [
      "Taewon Park",
      "Hyun-Chul Kim",
      "Minho Lee"
    ],
    "abstract": "Neuro-symbolic neural networks have been extensively studied to integrate\nsymbolic operations with neural networks, thereby improving systematic\ngeneralization. Specifically, Tensor Product Representation (TPR) framework\nenables neural networks to perform differentiable symbolic operations by\nencoding the symbolic structure of data within vector spaces. However,\nTPR-based neural networks often struggle to decompose unseen data into\nstructured TPR representations, undermining their symbolic operations. To\naddress this decomposition problem, we propose a Discrete Dictionary-based\nDecomposition (D3) layer designed to enhance the decomposition capabilities of\nTPR-based models. D3 employs discrete, learnable key-value dictionaries trained\nto capture symbolic features essential for decomposition operations. It\nleverages the prior knowledge acquired during training to generate structured\nTPR representations by mapping input data to pre-learned symbolic features\nwithin these dictionaries. D3 is a straightforward drop-in layer that can be\nseamlessly integrated into any TPR-based model without modifications. Our\nexperimental results demonstrate that D3 significantly improves the systematic\ngeneralization of various TPR-based models while requiring fewer additional\nparameters. Notably, D3 outperforms baseline models on the synthetic task that\ndemands the systematic decomposition of unseen combinatorial data.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Published in NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.06976v2",
    "published_date": "2024-06-11 06:16:33 UTC",
    "updated_date": "2024-11-01 01:51:35 UTC"
  },
  {
    "arxiv_id": "2406.06968v1",
    "title": "Beyond the Norms: Detecting Prediction Errors in Regression Models",
    "authors": [
      "Andres Altieri",
      "Marco Romanelli",
      "Georg Pichler",
      "Florence Alberge",
      "Pablo Piantanida"
    ],
    "abstract": "This paper tackles the challenge of detecting unreliable behavior in\nregression algorithms, which may arise from intrinsic variability (e.g.,\naleatoric uncertainty) or modeling errors (e.g., model uncertainty). First, we\nformally introduce the notion of unreliability in regression, i.e., when the\noutput of the regressor exceeds a specified discrepancy (or error). Then, using\npowerful tools for probabilistic modeling, we estimate the discrepancy density,\nand we measure its statistical diversity using our proposed metric for\nstatistical dissimilarity. In turn, this allows us to derive a data-driven\nscore that expresses the uncertainty of the regression outcome. We show\nempirical improvements in error detection for multiple regression tasks,\nconsistently outperforming popular baseline approaches, and contributing to the\nbroader field of uncertainty quantification and safe machine learning systems.\nOur code is available at https://zenodo.org/records/11281964.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "To appear as spotlight at ICML 2024. 36 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.06968v1",
    "published_date": "2024-06-11 05:51:44 UTC",
    "updated_date": "2024-06-11 05:51:44 UTC"
  },
  {
    "arxiv_id": "2406.06967v3",
    "title": "Dual Thinking and Logical Processing -- Are Multi-modal Large Language Models Closing the Gap with Human Vision ?",
    "authors": [
      "Kailas Dayanandan",
      "Nikhil Kumar",
      "Anand Sinha",
      "Brejesh Lall"
    ],
    "abstract": "The dual thinking framework considers fast, intuitive, and slower logical\nprocessing. The perception of dual thinking in vision requires images where\ninferences from intuitive and logical processing differ, and the latter is\nunder-explored in current studies. We introduce a novel adversarial dataset to\nprovide evidence for the dual thinking framework in human vision, which also\nfacilitates the study of the qualitative behavior of deep learning models. Our\npsychophysical studies show the presence of multiple inferences in rapid\nsuccession, and analysis of errors shows that the early stopping of visual\nprocessing can result in missing relevant information. MLLMs (Multi-modal Large\nLanguage Models) and VLMs (Vision Language Models) have made significant\nprogress in correcting errors in intuitive processing in human vision and\nshowed enhanced performance on images requiring logical processing. However,\ntheir improvements in logical processing have not kept pace with their\nadvancements in intuitive processing. In contrast, segmentation models exhibit\nerrors similar to those seen in intuitive human processing and lack\nunderstanding of sub-structures, as indicated by errors related to\nsub-components in identified instances. As AI (Artificial Intelligence)-based\nsystems find increasing applications in safety-critical domains like autonomous\ndriving, the integration of logical processing capabilities becomes essential.\nThis not only enhances performance but also addresses the limitations of\nscaling-based approaches while ensuring robustness and reliability in\nreal-world environments.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.06967v3",
    "published_date": "2024-06-11 05:50:34 UTC",
    "updated_date": "2025-02-28 17:28:36 UTC"
  },
  {
    "arxiv_id": "2406.06962v1",
    "title": "Evolving Subnetwork Training for Large Language Models",
    "authors": [
      "Hanqi Li",
      "Lu Chen",
      "Da Ma",
      "Zijian Wu",
      "Su Zhu",
      "Kai Yu"
    ],
    "abstract": "Large language models have ushered in a new era of artificial intelligence\nresearch. However, their substantial training costs hinder further development\nand widespread adoption. In this paper, inspired by the redundancy in the\nparameters of large language models, we propose a novel training paradigm:\nEvolving Subnetwork Training (EST). EST samples subnetworks from the layers of\nthe large language model and from commonly used modules within each layer,\nMulti-Head Attention (MHA) and Multi-Layer Perceptron (MLP). By gradually\nincreasing the size of the subnetworks during the training process, EST can\nsave the cost of training. We apply EST to train GPT2 model and TinyLlama\nmodel, resulting in 26.7\\% FLOPs saving for GPT2 and 25.0\\% for TinyLlama\nwithout an increase in loss on the pre-training dataset. Moreover, EST leads to\nperformance improvements in downstream tasks, indicating that it benefits\ngeneralization. Additionally, we provide intuitive theoretical studies based on\ntraining dynamics and Dropout theory to ensure the feasibility of EST. Our code\nis available at https://github.com/OpenDFM/EST.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.06962v1",
    "published_date": "2024-06-11 05:44:56 UTC",
    "updated_date": "2024-06-11 05:44:56 UTC"
  },
  {
    "arxiv_id": "2406.06959v2",
    "title": "Unleashing the Denoising Capability of Diffusion Prior for Solving Inverse Problems",
    "authors": [
      "Jiawei Zhang",
      "Jiaxin Zhuang",
      "Cheng Jin",
      "Gen Li",
      "Yuantao Gu"
    ],
    "abstract": "The recent emergence of diffusion models has significantly advanced the\nprecision of learnable priors, presenting innovative avenues for addressing\ninverse problems. Since inverse problems inherently entail maximum a posteriori\nestimation, previous works have endeavored to integrate diffusion priors into\nthe optimization frameworks. However, prevailing optimization-based inverse\nalgorithms primarily exploit the prior information within the diffusion models\nwhile neglecting their denoising capability. To bridge this gap, this work\nleverages the diffusion process to reframe noisy inverse problems as a\ntwo-variable constrained optimization task by introducing an auxiliary\noptimization variable. By employing gradient truncation, the projection\ngradient descent method is efficiently utilized to solve the corresponding\noptimization problem. The proposed algorithm, termed ProjDiff, effectively\nharnesses the prior information and the denoising capability of a pre-trained\ndiffusion model within the optimization framework. Extensive experiments on the\nimage restoration tasks and source separation and partial generation tasks\ndemonstrate that ProjDiff exhibits superior performance across various linear\nand nonlinear inverse problems, highlighting its potential for practical\napplications. Code is available at https://github.com/weigerzan/ProjDiff/.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.06959v2",
    "published_date": "2024-06-11 05:35:18 UTC",
    "updated_date": "2025-01-18 07:02:25 UTC"
  },
  {
    "arxiv_id": "2406.14571v1",
    "title": "PreSto: An In-Storage Data Preprocessing System for Training Recommendation Models",
    "authors": [
      "Yunjae Lee",
      "Hyeseong Kim",
      "Minsoo Rhu"
    ],
    "abstract": "Training recommendation systems (RecSys) faces several challenges as it\nrequires the \"data preprocessing\" stage to preprocess an ample amount of raw\ndata and feed them to the GPU for training in a seamless manner. To sustain\nhigh training throughput, state-of-the-art solutions reserve a large fleet of\nCPU servers for preprocessing which incurs substantial deployment cost and\npower consumption. Our characterization reveals that prior CPU-centric\npreprocessing is bottlenecked on feature generation and feature normalization\noperations as it fails to reap out the abundant inter-/intra-feature\nparallelism in RecSys preprocessing. PreSto is a storage-centric preprocessing\nsystem leveraging In-Storage Processing (ISP), which offloads the bottlenecked\npreprocessing operations to our ISP units. We show that PreSto outperforms the\nbaseline CPU-centric system with a $9.6\\times$ speedup in end-to-end\npreprocessing time, $4.3\\times$ enhancement in cost-efficiency, and\n$11.3\\times$ improvement in energyefficiency on average for production-scale\nRecSys preprocessing.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.14571v1",
    "published_date": "2024-06-11 05:26:45 UTC",
    "updated_date": "2024-06-11 05:26:45 UTC"
  },
  {
    "arxiv_id": "2406.06949v2",
    "title": "Triple-domain Feature Learning with Frequency-aware Memory Enhancement for Moving Infrared Small Target Detection",
    "authors": [
      "Weiwei Duan",
      "Luping Ji",
      "Shengjia Chen",
      "Sicheng Zhu",
      "Mao Ye"
    ],
    "abstract": "As a sub-field of object detection, moving infrared small target detection\npresents significant challenges due to tiny target sizes and low contrast\nagainst backgrounds. Currently-existing methods primarily rely on the features\nextracted only from spatio-temporal domain. Frequency domain has hardly been\nconcerned yet, although it has been widely applied in image processing. To\nextend feature source domains and enhance feature representation, we propose a\nnew Triple-domain Strategy (Tridos) with the frequency-aware memory enhancement\non spatio-temporal domain for infrared small target detection. In this scheme,\nit effectively detaches and enhances frequency features by a local-global\nfrequency-aware module with Fourier transform. Inspired by human visual system,\nour memory enhancement is designed to capture the spatial relations of infrared\ntargets among video frames. Furthermore, it encodes temporal dynamics motion\nfeatures via differential learning and residual enhancing. Additionally, we\nfurther design a residual compensation to reconcile possible cross-domain\nfeature mismatches. To our best knowledge, proposed Tridos is the first work to\nexplore infrared target feature learning comprehensively in\nspatio-temporal-frequency domains. The extensive experiments on three datasets\n(i.e., DAUB, ITSDT-15K and IRDST) validate that our triple-domain infrared\nfeature learning scheme could often be obviously superior to state-of-the-art\nones. Source codes are available at https://github.com/UESTC-nnLab/Tridos.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "This paper has accepted IEEE TGRS",
    "pdf_url": "http://arxiv.org/pdf/2406.06949v2",
    "published_date": "2024-06-11 05:21:30 UTC",
    "updated_date": "2024-09-05 14:16:31 UTC"
  },
  {
    "arxiv_id": "2406.06947v3",
    "title": "CAAP: Context-Aware Action Planning Prompting to Solve Computer Tasks with Front-End UI Only",
    "authors": [
      "Junhee Cho",
      "Jihoon Kim",
      "Daseul Bae",
      "Jinho Choo",
      "Youngjune Gwon",
      "Yeong-Dae Kwon"
    ],
    "abstract": "Software robots have long been used in Robotic Process Automation (RPA) to\nautomate mundane and repetitive computer tasks. With the advent of Large\nLanguage Models (LLMs) and their advanced reasoning capabilities, these agents\nare now able to handle more complex or previously unseen tasks. However,\nLLM-based automation techniques in recent literature frequently rely on HTML\nsource code for input or application-specific API calls for actions, limiting\ntheir applicability to specific environments. We propose an LLM-based agent\nthat mimics human behavior in solving computer tasks. It perceives its\nenvironment solely through screenshot images, which are then converted into\ntext for an LLM to process. By leveraging the reasoning capability of the LLM,\nwe eliminate the need for large-scale human demonstration data typically\nrequired for model training. The agent only executes keyboard and mouse\noperations on Graphical User Interface (GUI), removing the need for\npre-provided APIs to function. To further enhance the agent's performance in\nthis setting, we propose a novel prompting strategy called Context-Aware Action\nPlanning (CAAP) prompting, which enables the agent to thoroughly examine the\ntask context from multiple perspectives. Our agent achieves an average success\nrate of 94.5% on MiniWoB++ and an average task score of 62.3 on WebShop,\noutperforming all previous studies of agents that rely solely on screen images.\nThis method demonstrates potential for broader applications, particularly for\ntasks requiring coordination across multiple applications on desktops or\nsmartphones, marking a significant advancement in the field of automation\nagents. Codes and models are accessible at\nhttps://github.com/caap-agent/caap-agent.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "11 pages, 7 figures; (20 pages and 16 figures more in appendix)",
    "pdf_url": "http://arxiv.org/pdf/2406.06947v3",
    "published_date": "2024-06-11 05:21:20 UTC",
    "updated_date": "2024-12-26 11:02:28 UTC"
  },
  {
    "arxiv_id": "2406.06937v2",
    "title": "A Non-autoregressive Generation Framework for End-to-End Simultaneous Speech-to-Speech Translation",
    "authors": [
      "Zhengrui Ma",
      "Qingkai Fang",
      "Shaolei Zhang",
      "Shoutao Guo",
      "Yang Feng",
      "Min Zhang"
    ],
    "abstract": "Simultaneous translation models play a crucial role in facilitating\ncommunication. However, existing research primarily focuses on text-to-text or\nspeech-to-text models, necessitating additional cascade components to achieve\nspeech-to-speech translation. These pipeline methods suffer from error\npropagation and accumulate delays in each cascade component, resulting in\nreduced synchronization between the speaker and listener. To overcome these\nchallenges, we propose a novel non-autoregressive generation framework for\nsimultaneous speech translation (NAST-S2X), which integrates speech-to-text and\nspeech-to-speech tasks into a unified end-to-end framework. We develop a\nnon-autoregressive decoder capable of concurrently generating multiple text or\nacoustic unit tokens upon receiving fixed-length speech chunks. The decoder can\ngenerate blank or repeated tokens and employ CTC decoding to dynamically adjust\nits latency. Experimental results show that NAST-S2X outperforms\nstate-of-the-art models in both speech-to-text and speech-to-speech tasks. It\nachieves high-quality simultaneous interpretation within a delay of less than 3\nseconds and provides a 28 times decoding speedup in offline generation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL 2024; Codes and demos are at https://github.com/ictnlp/NAST-S2x",
    "pdf_url": "http://arxiv.org/pdf/2406.06937v2",
    "published_date": "2024-06-11 04:25:48 UTC",
    "updated_date": "2024-10-19 08:25:59 UTC"
  },
  {
    "arxiv_id": "2406.06911v3",
    "title": "AsyncDiff: Parallelizing Diffusion Models by Asynchronous Denoising",
    "authors": [
      "Zigeng Chen",
      "Xinyin Ma",
      "Gongfan Fang",
      "Zhenxiong Tan",
      "Xinchao Wang"
    ],
    "abstract": "Diffusion models have garnered significant interest from the community for\ntheir great generative ability across various applications. However, their\ntypical multi-step sequential-denoising nature gives rise to high cumulative\nlatency, thereby precluding the possibilities of parallel computation. To\naddress this, we introduce AsyncDiff, a universal and plug-and-play\nacceleration scheme that enables model parallelism across multiple devices. Our\napproach divides the cumbersome noise prediction model into multiple\ncomponents, assigning each to a different device. To break the dependency chain\nbetween these components, it transforms the conventional sequential denoising\ninto an asynchronous process by exploiting the high similarity between hidden\nstates in consecutive diffusion steps. Consequently, each component is\nfacilitated to compute in parallel on separate devices. The proposed strategy\nsignificantly reduces inference latency while minimally impacting the\ngenerative quality. Specifically, for the Stable Diffusion v2.1, AsyncDiff\nachieves a 2.7x speedup with negligible degradation and a 4.0x speedup with\nonly a slight reduction of 0.38 in CLIP Score, on four NVIDIA A5000 GPUs. Our\nexperiments also demonstrate that AsyncDiff can be readily applied to video\ndiffusion models with encouraging performances. The code is available at\nhttps://github.com/czg1225/AsyncDiff.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.06911v3",
    "published_date": "2024-06-11 03:09:37 UTC",
    "updated_date": "2024-09-26 05:47:36 UTC"
  },
  {
    "arxiv_id": "2406.06907v1",
    "title": "SignMusketeers: An Efficient Multi-Stream Approach for Sign Language Translation at Scale",
    "authors": [
      "Shester Gueuwou",
      "Xiaodan Du",
      "Greg Shakhnarovich",
      "Karen Livescu"
    ],
    "abstract": "A persistent challenge in sign language video processing, including the task\nof sign language to written language translation, is how we learn\nrepresentations of sign language in an effective and efficient way that can\npreserve the important attributes of these languages, while remaining invariant\nto irrelevant visual differences. Informed by the nature and linguistics of\nsigned languages, our proposed method focuses on just the most relevant parts\nin a signing video: the face, hands and body posture of the signer. However,\ninstead of using pose estimation coordinates from off-the-shelf pose tracking\nmodels, which have inconsistent performance for hands and faces, we propose to\nlearn the complex handshapes and rich facial expressions of sign languages in a\nself-supervised fashion. Our approach is based on learning from individual\nframes (rather than video sequences) and is therefore much more efficient than\nprior work on sign language pre-training. Compared to a recent model that\nestablished a new state of the art in sign language translation on the How2Sign\ndataset, our approach yields similar translation performance, using less than\n3\\% of the compute.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.06907v1",
    "published_date": "2024-06-11 03:00:41 UTC",
    "updated_date": "2024-06-11 03:00:41 UTC"
  },
  {
    "arxiv_id": "2406.10262v1",
    "title": "Fast solution to the fair ranking problem using the Sinkhorn algorithm",
    "authors": [
      "Yuki Uehara",
      "Shunnosuke Ikeda",
      "Naoki Nishimura",
      "Koya Ohashi",
      "Yilin Li",
      "Jie Yang",
      "Deddy Jobson",
      "Xingxia Zha",
      "Takeshi Matsumoto",
      "Noriyoshi Sukegawa",
      "Yuichi Takano"
    ],
    "abstract": "In two-sided marketplaces such as online flea markets, recommender systems\nfor providing consumers with personalized item rankings play a key role in\npromoting transactions between providers and consumers. Meanwhile, two-sided\nmarketplaces face the problem of balancing consumer satisfaction and fairness\namong items to stimulate activity of item providers. Saito and Joachims (2022)\ndevised an impact-based fair ranking method for maximizing the Nash social\nwelfare based on fair division; however, this method, which requires solving a\nlarge-scale constrained nonlinear optimization problem, is very difficult to\napply to practical-scale recommender systems. We thus propose a fast solution\nto the impact-based fair ranking problem. We first transform the fair ranking\nproblem into an unconstrained optimization problem and then design a gradient\nascent method that repeatedly executes the Sinkhorn algorithm. Experimental\nresults demonstrate that our algorithm provides fair rankings of high quality\nand is about 1000 times faster than application of commercial optimization\nsoftware.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "math.OC",
      "stat.CO"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.10262v1",
    "published_date": "2024-06-11 02:21:24 UTC",
    "updated_date": "2024-06-11 02:21:24 UTC"
  },
  {
    "arxiv_id": "2406.06891v1",
    "title": "Tokenize features, enhancing tables: the FT-TABPFN model for tabular classification",
    "authors": [
      "Quangao Liu",
      "Wei Yang",
      "Chen Liang",
      "Longlong Pang",
      "Zhuozhang Zou"
    ],
    "abstract": "Traditional methods for tabular classification usually rely on supervised\nlearning from scratch, which requires extensive training data to determine\nmodel parameters. However, a novel approach called Prior-Data Fitted Networks\n(TabPFN) has changed this paradigm. TabPFN uses a 12-layer transformer trained\non large synthetic datasets to learn universal tabular representations. This\nmethod enables fast and accurate predictions on new tasks with a single forward\npass and no need for additional training. Although TabPFN has been successful\non small datasets, it generally shows weaker performance when dealing with\ncategorical features. To overcome this limitation, we propose FT-TabPFN, which\nis an enhanced version of TabPFN that includes a novel Feature Tokenization\nlayer to better handle classification features. By fine-tuning it for\ndownstream tasks, FT-TabPFN not only expands the functionality of the original\nmodel but also significantly improves its applicability and accuracy in tabular\nclassification. Our full source code is available for community use and\ndevelopment.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.06891v1",
    "published_date": "2024-06-11 02:13:46 UTC",
    "updated_date": "2024-06-11 02:13:46 UTC"
  },
  {
    "arxiv_id": "2406.06887v4",
    "title": "$\\textbf{PLUM}$: Improving Code LMs with Execution-Guided On-Policy Preference Learning Driven By Synthetic Test Cases",
    "authors": [
      "Dylan Zhang",
      "Shizhe Diao",
      "Xueyan Zou",
      "Hao Peng"
    ],
    "abstract": "Preference learning provides a promising solution to address the limitations\nof supervised fine-tuning (SFT) for code language models, where the model is\nnot explicitly trained to differentiate between correct and incorrect code.\nRecent findings demonstrate that on-policy data is the key to successful\npreference learning, where the preference data is collected using the same\npolicy LM being trained. Inspired by this, we propose PLUM, an on-policy\n$\\textbf{P}$reference $\\textbf{L}$earning framework A$\\textbf{u}$gmented with\ntest cases for code L$\\textbf{M}$ s. The framework operates in three key\nstages: (1) automatic generation of test cases from natural language\ninstructions, (2) creation of a preference data by evaluating candidate code\nsolutions sampled from the policy, which can then be used to (3) train the\npolicy LM. PLUM levitates the need to train reward models, allowing for large\nscale on-policy and online preference data collation. PLUM is evaluated on both\nstandard benchmarks (HumanEval, MBPP) and more challenging ones\n(LiveCodeBench), delivering substantial improvements over original SFT'ed\nmodels and other execution-feedback-driven approaches. We show PLUM's benefits\nare consistent across various widely-used code LMs even they have been\nwell-trained with SFT. For example, PLUM increases pass rates by up to 4.8% on\naverage on standard benchmarks and 11.8% on LiveCodeBench, demonstrating its\neffectiveness and generalizability. We also demonstrate the benefits of\non-policy and online preference learning by comprehensive experimentation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.PL",
      "cs.SE"
    ],
    "primary_category": "cs.CL",
    "comment": "Template",
    "pdf_url": "http://arxiv.org/pdf/2406.06887v4",
    "published_date": "2024-06-11 02:07:18 UTC",
    "updated_date": "2024-10-12 06:09:18 UTC"
  },
  {
    "arxiv_id": "2406.10261v1",
    "title": "FoodSky: A Food-oriented Large Language Model that Passes the Chef and Dietetic Examination",
    "authors": [
      "Pengfei Zhou",
      "Weiqing Min",
      "Chaoran Fu",
      "Ying Jin",
      "Mingyu Huang",
      "Xiangyang Li",
      "Shuhuan Mei",
      "Shuqiang Jiang"
    ],
    "abstract": "Food is foundational to human life, serving not only as a source of\nnourishment but also as a cornerstone of cultural identity and social\ninteraction. As the complexity of global dietary needs and preferences grows,\nfood intelligence is needed to enable food perception and reasoning for various\ntasks, ranging from recipe generation and dietary recommendation to\ndiet-disease correlation discovery and understanding. Towards this goal, for\npowerful capabilities across various domains and tasks in Large Language Models\n(LLMs), we introduce Food-oriented LLM FoodSky to comprehend food data through\nperception and reasoning. Considering the complexity and typicality of Chinese\ncuisine, we first construct one comprehensive Chinese food corpus FoodEarth\nfrom various authoritative sources, which can be leveraged by FoodSky to\nachieve deep understanding of food-related data. We then propose Topic-based\nSelective State Space Model (TS3M) and the Hierarchical Topic Retrieval\nAugmented Generation (HTRAG) mechanism to enhance FoodSky in capturing\nfine-grained food semantics and generating context-aware food-relevant text,\nrespectively. Our extensive evaluations demonstrate that FoodSky significantly\noutperforms general-purpose LLMs in both chef and dietetic examinations, with\nan accuracy of 67.2% and 66.4% on the Chinese National Chef Exam and the\nNational Dietetic Exam, respectively. FoodSky not only promises to enhance\nculinary creativity and promote healthier eating patterns, but also sets a new\nstandard for domain-specific LLMs that address complex real-world issues in the\nfood domain. An online demonstration of FoodSky is available at\nhttp://222.92.101.211:8200.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "32 pages, 19 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.10261v1",
    "published_date": "2024-06-11 01:27:00 UTC",
    "updated_date": "2024-06-11 01:27:00 UTC"
  },
  {
    "arxiv_id": "2406.06874v3",
    "title": "Learning Reward and Policy Jointly from Demonstration and Preference Improves Alignment",
    "authors": [
      "Chenliang Li",
      "Siliang Zeng",
      "Zeyi Liao",
      "Jiaxiang Li",
      "Dongyeop Kang",
      "Alfredo Garcia",
      "Mingyi Hong"
    ],
    "abstract": "Aligning human preference and value is an important requirement for building\ncontemporary foundation models and embodied AI. However, popular approaches\nsuch as reinforcement learning with human feedback (RLHF) break down the task\ninto successive stages, such as supervised fine-tuning (SFT), reward modeling\n(RM), and reinforcement learning (RL), each performing one specific learning\ntask. Such a sequential approach results in serious issues such as significant\nunder-utilization of data and distribution mismatch between the learned reward\nmodel and generated policy, which eventually lead to poor alignment\nperformance. We develop a single stage approach named Alignment with Integrated\nHuman Feedback (AIHF), capable of integrating both human preference and\ndemonstration to train reward models and the policy. The proposed approach\nadmits a suite of efficient algorithms, which can easily reduce to, and\nleverage, popular alignment algorithms such as RLHF and Directly Policy\nOptimization (DPO), and only requires minor changes to the existing alignment\npipelines. We demonstrate the efficiency of the proposed solutions with\nextensive experiments involving alignment problems in LLMs and robotic control\nproblems in MuJoCo. We observe that the proposed solutions outperform the\nexisting alignment algorithms such as RLHF and DPO by large margins, especially\nwhen the amount of high-quality preference data is relatively limited.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.06874v3",
    "published_date": "2024-06-11 01:20:53 UTC",
    "updated_date": "2024-11-29 23:41:57 UTC"
  },
  {
    "arxiv_id": "2406.06870v3",
    "title": "What's in an embedding? Would a rose by any embedding smell as sweet?",
    "authors": [
      "Venkat Venkatasubramanian"
    ],
    "abstract": "Large Language Models (LLMs) are often criticized for lacking true\n\"understanding\" and the ability to \"reason\" with their knowledge, being seen\nmerely as autocomplete systems. We believe that this assessment might be\nmissing a nuanced insight. We suggest that LLMs do develop a kind of empirical\n\"understanding\" that is \"geometry\"-like, which seems adequate for a range of\napplications in NLP, computer vision, coding assistance, etc. However, this\n\"geometric\" understanding, built from incomplete and noisy data, makes them\nunreliable, difficult to generalize, and lacking in inference capabilities and\nexplanations, similar to the challenges faced by heuristics-based expert\nsystems decades ago.\n  To overcome these limitations, we suggest that LLMs should be integrated with\nan \"algebraic\" representation of knowledge that includes symbolic AI elements\nused in expert systems. This integration aims to create large knowledge models\n(LKMs) that not only possess \"deep\" knowledge grounded in first principles, but\nalso have the ability to reason and explain, mimicking human expert\ncapabilities. To harness the full potential of generative AI safely and\neffectively, a paradigm shift is needed from LLM to more comprehensive LKM.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "7 pages, 9 images",
    "pdf_url": "http://arxiv.org/pdf/2406.06870v3",
    "published_date": "2024-06-11 01:10:40 UTC",
    "updated_date": "2024-06-15 06:35:33 UTC"
  },
  {
    "arxiv_id": "2406.06865v1",
    "title": "Eyeballing Combinatorial Problems: A Case Study of Using Multimodal Large Language Models to Solve Traveling Salesman Problems",
    "authors": [
      "Mohammed Elhenawy",
      "Ahmed Abdelhay",
      "Taqwa I. Alhadidi",
      "Huthaifa I Ashqar",
      "Shadi Jaradat",
      "Ahmed Jaber",
      "Sebastien Glaser",
      "Andry Rakotonirainy"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated proficiency in\nprocessing di-verse modalities, including text, images, and audio. These models\nleverage extensive pre-existing knowledge, enabling them to address complex\nproblems with minimal to no specific training examples, as evidenced in\nfew-shot and zero-shot in-context learning scenarios. This paper investigates\nthe use of MLLMs' visual capabilities to 'eyeball' solutions for the Traveling\nSalesman Problem (TSP) by analyzing images of point distributions on a\ntwo-dimensional plane. Our experiments aimed to validate the hypothesis that\nMLLMs can effectively 'eyeball' viable TSP routes. The results from zero-shot,\nfew-shot, self-ensemble, and self-refine zero-shot evaluations show promising\noutcomes. We anticipate that these findings will inspire further exploration\ninto MLLMs' visual reasoning abilities to tackle other combinatorial problems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.06865v1",
    "published_date": "2024-06-11 00:41:08 UTC",
    "updated_date": "2024-06-11 00:41:08 UTC"
  },
  {
    "arxiv_id": "2406.06864v1",
    "title": "Validating LLM-Generated Programs with Metamorphic Prompt Testing",
    "authors": [
      "Xiaoyin Wang",
      "Dakai Zhu"
    ],
    "abstract": "The latest paradigm shift in software development brings in the innovation\nand automation afforded by Large Language Models (LLMs), showcased by\nGenerative Pre-trained Transformer (GPT), which has shown remarkable capacity\nto generate code autonomously, significantly reducing the manual effort\nrequired for various programming tasks. Although, the potential benefits of\nLLM-generated code are vast, most notably in efficiency and rapid prototyping,\nas LLMs become increasingly integrated into the software development lifecycle\nand hence the supply chain, complex and multifaceted challenges arise as the\ncode generated from these language models carry profound questions on quality\nand correctness. Research is required to comprehensively explore these critical\nconcerns surrounding LLM-generated code.\n  In this paper, we propose a novel solution called metamorphic prompt testing\nto address these challenges. Our intuitive observation is that intrinsic\nconsistency always exists among correct code pieces but may not exist among\nflawed code pieces, so we can detect flaws in the code by detecting\ninconsistencies. Therefore, we can vary a given prompt to multiple prompts with\nparaphrasing, and to ask the LLM to acquire multiple versions of generated\ncode, so that we can validate whether the semantic relations still hold in the\nacquired code through cross-validation. Our evaluation on HumanEval shows that\nmetamorphic prompt testing is able to detect 75 percent of the erroneous\nprograms generated by GPT-4, with a false positive rate of 8.6 percent.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.06864v1",
    "published_date": "2024-06-11 00:40:17 UTC",
    "updated_date": "2024-06-11 00:40:17 UTC"
  },
  {
    "arxiv_id": "2406.06863v1",
    "title": "Ollabench: Evaluating LLMs' Reasoning for Human-centric Interdependent Cybersecurity",
    "authors": [
      "Tam n. Nguyen"
    ],
    "abstract": "Large Language Models (LLMs) have the potential to enhance Agent-Based\nModeling by better representing complex interdependent cybersecurity systems,\nimproving cybersecurity threat modeling and risk management. However,\nevaluating LLMs in this context is crucial for legal compliance and effective\napplication development. Existing LLM evaluation frameworks often overlook the\nhuman factor and cognitive computing capabilities essential for interdependent\ncybersecurity. To address this gap, I propose OllaBench, a novel evaluation\nframework that assesses LLMs' accuracy, wastefulness, and consistency in\nanswering scenario-based information security compliance and non-compliance\nquestions. OllaBench is built on a foundation of 24 cognitive behavioral\ntheories and empirical evidence from 38 peer-reviewed papers. OllaBench was\nused to evaluate 21 LLMs, including both open-weight and commercial models from\nOpenAI, Anthropic, Google, Microsoft, Meta and so on. The results reveal that\nwhile commercial LLMs have the highest overall accuracy scores, there is\nsignificant room for improvement. Smaller low-resolution open-weight LLMs are\nnot far behind in performance, and there are significant differences in token\nefficiency and consistency among the evaluated models. OllaBench provides a\nuser-friendly interface and supports a wide range of LLM platforms, making it a\nvaluable tool for researchers and solution developers in the field of\nhuman-centric interdependent cybersecurity and beyond.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.HC",
      "I.2.0; J.4"
    ],
    "primary_category": "cs.CR",
    "comment": "12 pages, 7 figures, 2 tables The final conference/journal version\n  may have significantly more content updates",
    "pdf_url": "http://arxiv.org/pdf/2406.06863v1",
    "published_date": "2024-06-11 00:35:39 UTC",
    "updated_date": "2024-06-11 00:35:39 UTC"
  },
  {
    "arxiv_id": "2406.06856v1",
    "title": "Sample Complexity Reduction via Policy Difference Estimation in Tabular Reinforcement Learning",
    "authors": [
      "Adhyyan Narang",
      "Andrew Wagenmaker",
      "Lillian Ratliff",
      "Kevin Jamieson"
    ],
    "abstract": "In this paper, we study the non-asymptotic sample complexity for the pure\nexploration problem in contextual bandits and tabular reinforcement learning\n(RL): identifying an epsilon-optimal policy from a set of policies with high\nprobability. Existing work in bandits has shown that it is possible to identify\nthe best policy by estimating only the difference between the behaviors of\nindividual policies, which can be substantially cheaper than estimating the\nbehavior of each policy directly. However, the best-known complexities in RL\nfail to take advantage of this and instead estimate the behavior of each policy\ndirectly. Does it suffice to estimate only the differences in the behaviors of\npolicies in RL? We answer this question positively for contextual bandits but\nin the negative for tabular RL, showing a separation between contextual bandits\nand RL. However, inspired by this, we show that it almost suffices to estimate\nonly the differences in RL: if we can estimate the behavior of a single\nreference policy, it suffices to only estimate how any other policy deviates\nfrom this reference policy. We develop an algorithm which instantiates this\nprinciple and obtains, to the best of our knowledge, the tightest known bound\non the sample complexity of tabular RL.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "59 pages, 2 Figures",
    "pdf_url": "http://arxiv.org/pdf/2406.06856v1",
    "published_date": "2024-06-11 00:02:19 UTC",
    "updated_date": "2024-06-11 00:02:19 UTC"
  }
]