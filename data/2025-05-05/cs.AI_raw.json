[
  {
    "arxiv_id": "2505.03850v1",
    "title": "Impact Analysis of Inference Time Attack of Perception Sensors on Autonomous Vehicles",
    "authors": [
      "Hanlin Chen",
      "Simin Chen",
      "Wenyu Li",
      "Wei Yang",
      "Yiheng Feng"
    ],
    "abstract": "As a safety-critical cyber-physical system, cybersecurity and related safety\nissues for Autonomous Vehicles (AVs) have been important research topics for a\nwhile. Among all the modules on AVs, perception is one of the most accessible\nattack surfaces, as drivers and AVs have no control over the outside\nenvironment. Most current work targeting perception security for AVs focuses on\nperception correctness. In this work, we propose an impact analysis based on\ninference time attacks for autonomous vehicles. We demonstrate in a simulation\nsystem that such inference time attacks can also threaten the safety of both\nthe ego vehicle and other traffic participants.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted and presented in TRBAM 2024",
    "pdf_url": "http://arxiv.org/pdf/2505.03850v1",
    "published_date": "2025-05-05 23:00:27 UTC",
    "updated_date": "2025-05-05 23:00:27 UTC"
  },
  {
    "arxiv_id": "2505.06267v1",
    "title": "AKD : Adversarial Knowledge Distillation For Large Language Models Alignment on Coding tasks",
    "authors": [
      "Ilyas Oulkadda",
      "Julien Perez"
    ],
    "abstract": "The widespread adoption of Large Language Models (LLMs) for code generation,\nexemplified by GitHub Copilot\\footnote{A coding extension powered by a Code-LLM\nto assist in code completion tasks} surpassing a million users, highlights the\ntransformative potential of these tools in improving developer productivity.\nHowever, this rapid growth also underscores critical concerns regarding the\nquality, safety, and reliability of the code they generate. As Code-LLMs\nevolve, they face significant challenges, including the diminishing returns of\nmodel scaling and the scarcity of new, high-quality training data. To address\nthese issues, this paper introduces Adversarial Knowledge Distillation (AKD), a\nnovel approach that leverages adversarially generated synthetic datasets to\ndistill the capabilities of larger models into smaller, more efficient ones. By\nsystematically stress-testing and refining the reasoning capabilities of\nCode-LLMs, AKD provides a framework for enhancing model robustness,\nreliability, and security while improving their parameter-efficiency. We\nbelieve this work represents a critical step toward ensuring dependable\nautomated code generation within the constraints of existing data and the\ncost-efficiency of model execution.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.06267v1",
    "published_date": "2025-05-05 22:41:19 UTC",
    "updated_date": "2025-05-05 22:41:19 UTC"
  },
  {
    "arxiv_id": "2505.03054v2",
    "title": "BLAB: Brutally Long Audio Bench",
    "authors": [
      "Orevaoghene Ahia",
      "Martijn Bartelds",
      "Kabir Ahuja",
      "Hila Gonen",
      "Valentin Hofmann",
      "Siddhant Arora",
      "Shuyue Stella Li",
      "Vishal Puttagunta",
      "Mofetoluwa Adeyemi",
      "Charishma Buchireddy",
      "Ben Walls",
      "Noah Bennett",
      "Shinji Watanabe",
      "Noah A. Smith",
      "Yulia Tsvetkov",
      "Sachin Kumar"
    ],
    "abstract": "Developing large audio language models (LMs) capable of understanding diverse\nspoken interactions is essential for accommodating the multimodal nature of\nhuman communication and can increase the accessibility of language technologies\nacross different user populations. Recent work on audio LMs has primarily\nevaluated their performance on short audio segments, typically under 30\nseconds, with limited exploration of long-form conversational speech segments\nthat more closely reflect natural user interactions with these models. We\nintroduce Brutally Long Audio Bench (BLAB), a challenging long-form audio\nbenchmark that evaluates audio LMs on localization, duration estimation,\nemotion, and counting tasks using audio segments averaging 51 minutes in\nlength. BLAB consists of 833+ hours of diverse, full-length audio clips, each\npaired with human-annotated, text-based natural language questions and answers.\nOur audio data were collected from permissively licensed sources and underwent\na human-assisted filtering process to ensure task compliance. We evaluate six\nopen-source and proprietary audio LMs on BLAB and find that all of them,\nincluding advanced models such as Gemini 2.0 Pro and GPT-4o, struggle with the\ntasks in BLAB. Our comprehensive analysis reveals key insights into the\ntrade-offs between task difficulty and audio duration. In general, we find that\naudio LMs struggle with long-form speech, with performance declining as\nduration increases. They perform poorly on localization, temporal reasoning,\ncounting, and struggle to understand non-phonemic information, relying more on\nprompts than audio content. BLAB serves as a challenging evaluation framework\nto develop audio LMs with robust long-form audio understanding capabilities.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.03054v2",
    "published_date": "2025-05-05 22:28:53 UTC",
    "updated_date": "2025-05-12 19:49:55 UTC"
  },
  {
    "arxiv_id": "2505.03053v1",
    "title": "Developing A Framework to Support Human Evaluation of Bias in Generated Free Response Text",
    "authors": [
      "Jennifer Healey",
      "Laurie Byrum",
      "Md Nadeem Akhtar",
      "Surabhi Bhargava",
      "Moumita Sinha"
    ],
    "abstract": "LLM evaluation is challenging even the case of base models. In real world\ndeployments, evaluation is further complicated by the interplay of task\nspecific prompts and experiential context. At scale, bias evaluation is often\nbased on short context, fixed choice benchmarks that can be rapidly evaluated,\nhowever, these can lose validity when the LLMs' deployed context differs. Large\nscale human evaluation is often seen as too intractable and costly. Here we\npresent our journey towards developing a semi-automated bias evaluation\nframework for free text responses that has human insights at its core. We\ndiscuss how we developed an operational definition of bias that helped us\nautomate our pipeline and a methodology for classifying bias beyond multiple\nchoice. We additionally comment on how human evaluation helped us uncover\nproblematic templates in a bias benchmark.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "6 pages, no figures, presented at CHI 2025 workshop for Human\n  Evaluation and Auditing of Language Models",
    "pdf_url": "http://arxiv.org/pdf/2505.03053v1",
    "published_date": "2025-05-05 22:26:55 UTC",
    "updated_date": "2025-05-05 22:26:55 UTC"
  },
  {
    "arxiv_id": "2505.03035v1",
    "title": "MORE: Mobile Manipulation Rearrangement Through Grounded Language Reasoning",
    "authors": [
      "Mohammad Mohammadi",
      "Daniel Honerkamp",
      "Martin BÃ¼chner",
      "Matteo Cassinelli",
      "Tim Welschehold",
      "Fabien Despinoy",
      "Igor Gilitschenski",
      "Abhinav Valada"
    ],
    "abstract": "Autonomous long-horizon mobile manipulation encompasses a multitude of\nchallenges, including scene dynamics, unexplored areas, and error recovery.\nRecent works have leveraged foundation models for scene-level robotic reasoning\nand planning. However, the performance of these methods degrades when dealing\nwith a large number of objects and large-scale environments. To address these\nlimitations, we propose MORE, a novel approach for enhancing the capabilities\nof language models to solve zero-shot mobile manipulation planning for\nrearrangement tasks. MORE leverages scene graphs to represent environments,\nincorporates instance differentiation, and introduces an active filtering\nscheme that extracts task-relevant subgraphs of object and region instances.\nThese steps yield a bounded planning problem, effectively mitigating\nhallucinations and improving reliability. Additionally, we introduce several\nenhancements that enable planning across both indoor and outdoor environments.\nWe evaluate MORE on 81 diverse rearrangement tasks from the BEHAVIOR-1K\nbenchmark, where it becomes the first approach to successfully solve a\nsignificant share of the benchmark, outperforming recent foundation model-based\napproaches. Furthermore, we demonstrate the capabilities of our approach in\nseveral complex real-world tasks, mimicking everyday activities. We make the\ncode publicly available at https://more-model.cs.uni-freiburg.de.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.03035v1",
    "published_date": "2025-05-05 21:26:03 UTC",
    "updated_date": "2025-05-05 21:26:03 UTC"
  },
  {
    "arxiv_id": "2505.04646v1",
    "title": "Computational Irreducibility as the Foundation of Agency: A Formal Model Connecting Undecidability to Autonomous Behavior in Complex Systems",
    "authors": [
      "Poria Azadi"
    ],
    "abstract": "This article explores the emergence of autonomy and agency by connecting\nfundamental computational limits (decidability, completeness, computational\nirreducibility) with physical concepts. We introduce a formal model of a\n\"minimal agent\" operating within potentially Turing-complete environments.\nUsing algorithmic information theory, we argue that the inherent undecidability\nand computational irreducibility of agent-environment interaction lead to\nunpredictability and novel information generation, enabling agency (effective\ngoal-directed action). Computational irreducibility prevents full external\nprediction, creating necessary conditions for autonomous behavior. We relate\nthis to computational sourcehood, where an agent is the irreducible origin of\nits behavior, though formalizing this concept remains challenging. Our central\nthesis, formally proven, is that genuine autonomy necessarily implies\nundecidability from an external perspective, distinguishing autonomous systems\nfrom predictable ones. We propose that agency arises when agent-environment\ncoupling complexity allows mutual information between internal states and\nrelevant environmental variables to increase, particularly where analytical\nsolutions are absent and operational closure is needed for persistence. This\nframework links agency directly to the computational properties of interaction,\noffering implications for understanding consciousness, designing autonomous AI,\nand reconceptualizing free will in a deterministic yet computationally\nirreducible universe.",
    "categories": [
      "cs.AI",
      "cs.CC",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04646v1",
    "published_date": "2025-05-05 21:24:50 UTC",
    "updated_date": "2025-05-05 21:24:50 UTC"
  },
  {
    "arxiv_id": "2505.03033v1",
    "title": "Evaluating the Impact of AI-Powered Audiovisual Personalization on Learner Emotion, Focus, and Learning Outcomes",
    "authors": [
      "George Xi Wang",
      "Jingying Deng",
      "Safinah Ali"
    ],
    "abstract": "Independent learners often struggle with sustaining focus and emotional\nregulation in unstructured or distracting settings. Although some rely on\nambient aids such as music, ASMR, or visual backgrounds to support\nconcentration, these tools are rarely integrated into cohesive,\nlearner-centered systems. Moreover, existing educational technologies focus\nprimarily on content adaptation and feedback, overlooking the emotional and\nsensory context in which learning takes place. Large language models have\ndemonstrated powerful multimodal capabilities including the ability to generate\nand adapt text, audio, and visual content. Educational research has yet to\nfully explore their potential in creating personalized audiovisual learning\nenvironments. To address this gap, we introduce an AI-powered system that uses\nLLMs to generate personalized multisensory study environments. Users select or\ngenerate customized visual themes (e.g., abstract vs. realistic, static vs.\nanimated) and auditory elements (e.g., white noise, ambient ASMR, familiar vs.\nnovel sounds) to create immersive settings aimed at reducing distraction and\nenhancing emotional stability. Our primary research question investigates how\ncombinations of personalized audiovisual elements affect learner cognitive load\nand engagement. Using a mixed-methods design that incorporates biometric\nmeasures and performance outcomes, this study evaluates the effectiveness of\nLLM-driven sensory personalization. The findings aim to advance emotionally\nresponsive educational technologies and extend the application of multimodal\nLLMs into the sensory dimension of self-directed learning.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.03033v1",
    "published_date": "2025-05-05 21:19:50 UTC",
    "updated_date": "2025-05-05 21:19:50 UTC"
  },
  {
    "arxiv_id": "2505.06266v2",
    "title": "Knowledge Guided Encoder-Decoder Framework: Integrating Multiple Physical Models for Agricultural Ecosystem Modeling",
    "authors": [
      "Qi Cheng",
      "Licheng Liu",
      "Yao Zhang",
      "Mu Hong",
      "Shiyuan Luo",
      "Zhenong Jin",
      "Yiqun Xie",
      "Xiaowei Jia"
    ],
    "abstract": "Agricultural monitoring is critical for ensuring food security, maintaining\nsustainable farming practices, informing policies on mitigating food shortage,\nand managing greenhouse gas emissions. Traditional process-based physical\nmodels are often designed and implemented for specific situations, and their\nparameters could also be highly uncertain. In contrast, data-driven models\noften use black-box structures and does not explicitly model the\ninter-dependence between different ecological variables. As a result, they\nrequire extensive training data and lack generalizability to different tasks\nwith data distribution shifts and inconsistent observed variables. To address\nthe need for more universal models, we propose a knowledge-guided\nencoder-decoder model, which can predict key crop variables by leveraging\nknowledge of underlying processes from multiple physical models. The proposed\nmethod also integrates a language model to process complex and inconsistent\ninputs and also utilizes it to implement a model selection mechanism for\nselectively combining the knowledge from different physical models. Our\nevaluations on predicting carbon and nitrogen fluxes for multiple sites\ndemonstrate the effectiveness and robustness of the proposed model under\nvarious scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.06266v2",
    "published_date": "2025-05-05 21:16:10 UTC",
    "updated_date": "2025-05-13 02:04:13 UTC"
  },
  {
    "arxiv_id": "2505.03025v1",
    "title": "A Typology of Synthetic Datasets for Dialogue Processing in Clinical Contexts",
    "authors": [
      "Steven Bedrick",
      "A. Seza DoÄruÃ¶z",
      "Sergiu Nisioi"
    ],
    "abstract": "Synthetic data sets are used across linguistic domains and NLP tasks,\nparticularly in scenarios where authentic data is limited (or even\nnon-existent). One such domain is that of clinical (healthcare) contexts, where\nthere exist significant and long-standing challenges (e.g., privacy,\nanonymization, and data governance) which have led to the development of an\nincreasing number of synthetic datasets. One increasingly important category of\nclinical dataset is that of clinical dialogues which are especially sensitive\nand difficult to collect, and as such are commonly synthesized.\n  While such synthetic datasets have been shown to be sufficient in some\nsituations, little theory exists to inform how they may be best used and\ngeneralized to new applications. In this paper, we provide an overview of how\nsynthetic datasets are created, evaluated and being used for dialogue related\ntasks in the medical domain. Additionally, we propose a novel typology for use\nin classifying types and degrees of data synthesis, to facilitate comparison\nand evaluation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.03025v1",
    "published_date": "2025-05-05 20:58:08 UTC",
    "updated_date": "2025-05-05 20:58:08 UTC"
  },
  {
    "arxiv_id": "2505.03020v1",
    "title": "The Multimodal Paradox: How Added and Missing Modalities Shape Bias and Performance in Multimodal AI",
    "authors": [
      "Kishore Sampath",
      "Pratheesh",
      "Ayaazuddin Mohammad",
      "Resmi Ramachandranpillai"
    ],
    "abstract": "Multimodal learning, which integrates diverse data sources such as images,\ntext, and structured data, has proven superior to unimodal counterparts in\nhigh-stakes decision-making. However, while performance gains remain the gold\nstandard for evaluating multimodal systems, concerns around bias and robustness\nare frequently overlooked. In this context, this paper explores two key\nresearch questions (RQs): (i) RQ1 examines whether adding a modality\ncon-sistently enhances performance and investigates its role in shaping\nfairness measures, assessing whether it mitigates or amplifies bias in\nmultimodal models; (ii) RQ2 investigates the impact of missing modalities at\ninference time, analyzing how multimodal models generalize in terms of both\nperformance and fairness. Our analysis reveals that incorporating new\nmodalities during training consistently enhances the performance of multimodal\nmodels, while fairness trends exhibit variability across different evaluation\nmeasures and datasets. Additionally, the absence of modalities at inference\ndegrades performance and fairness, raising concerns about its robustness in\nreal-world deployment. We conduct extensive experiments using multimodal\nhealthcare datasets containing images, time series, and structured information\nto validate our findings.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "CVPR 2025 Second Workshop on Responsible Generative AI",
    "pdf_url": "http://arxiv.org/pdf/2505.03020v1",
    "published_date": "2025-05-05 20:42:44 UTC",
    "updated_date": "2025-05-05 20:42:44 UTC"
  },
  {
    "arxiv_id": "2505.03019v1",
    "title": "Memorization or Interpolation ? Detecting LLM Memorization through Input Perturbation Analysis",
    "authors": [
      "AlbÃ©rick Euraste DjirÃ©",
      "Abdoul Kader KaborÃ©",
      "Earl T. Barr",
      "Jacques Klein",
      "TegawendÃ© F. BissyandÃ©"
    ],
    "abstract": "While Large Language Models (LLMs) achieve remarkable performance through\ntraining on massive datasets, they can exhibit concerning behaviors such as\nverbatim reproduction of training data rather than true generalization. This\nmemorization phenomenon raises significant concerns about data privacy,\nintellectual property rights, and the reliability of model evaluations. This\npaper introduces PEARL, a novel approach for detecting memorization in LLMs.\nPEARL assesses how sensitive an LLM's performance is to input perturbations,\nenabling memorization detection without requiring access to the model's\ninternals. We investigate how input perturbations affect the consistency of\noutputs, enabling us to distinguish between true generalization and\nmemorization. Our findings, following extensive experiments on the Pythia open\nmodel, provide a robust framework for identifying when the model simply\nregurgitates learned information. Applied on the GPT 4o models, the PEARL\nframework not only identified cases of memorization of classic texts from the\nBible or common code from HumanEval but also demonstrated that it can provide\nsupporting evidence that some data, such as from the New York Times news\narticles, were likely part of the training data of a given model.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.03019v1",
    "published_date": "2025-05-05 20:42:34 UTC",
    "updated_date": "2025-05-05 20:42:34 UTC"
  },
  {
    "arxiv_id": "2505.03018v1",
    "title": "Lesion-Aware Generative Artificial Intelligence for Virtual Contrast-Enhanced Mammography in Breast Cancer",
    "authors": [
      "Aurora Rofena",
      "Arianna Manchia",
      "Claudia Lucia Piccolo",
      "Bruno Beomonte Zobel",
      "Paolo Soda",
      "Valerio Guarrasi"
    ],
    "abstract": "Contrast-Enhanced Spectral Mammography (CESM) is a dual-energy mammographic\ntechnique that improves lesion visibility through the administration of an\niodinated contrast agent. It acquires both a low-energy image, comparable to\nstandard mammography, and a high-energy image, which are then combined to\nproduce a dual-energy subtracted image highlighting lesion contrast\nenhancement. While CESM offers superior diagnostic accuracy compared to\nstandard mammography, its use entails higher radiation exposure and potential\nside effects associated with the contrast medium. To address these limitations,\nwe propose Seg-CycleGAN, a generative deep learning framework for Virtual\nContrast Enhancement in CESM. The model synthesizes high-fidelity dual-energy\nsubtracted images from low-energy images, leveraging lesion segmentation maps\nto guide the generative process and improve lesion reconstruction. Building\nupon the standard CycleGAN architecture, Seg-CycleGAN introduces localized loss\nterms focused on lesion areas, enhancing the synthesis of diagnostically\nrelevant regions. Experiments on the CESM@UCBM dataset demonstrate that\nSeg-CycleGAN outperforms the baseline in terms of PSNR and SSIM, while\nmaintaining competitive MSE and VIF. Qualitative evaluations further confirm\nimproved lesion fidelity in the generated images. These results suggest that\nsegmentation-aware generative models offer a viable pathway toward\ncontrast-free CESM alternatives.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.03018v1",
    "published_date": "2025-05-05 20:41:30 UTC",
    "updated_date": "2025-05-05 20:41:30 UTC"
  },
  {
    "arxiv_id": "2505.03005v2",
    "title": "RADLADS: Rapid Attention Distillation to Linear Attention Decoders at Scale",
    "authors": [
      "Daniel Goldstein",
      "Eric Alcaide",
      "Janna Lu",
      "Eugene Cheah"
    ],
    "abstract": "We present Rapid Attention Distillation to Linear Attention Decoders at Scale\n(RADLADS), a protocol for rapidly converting softmax attention transformers\ninto linear attention decoder models, along with two new RWKV-variant\narchitectures, and models converted from popular Qwen2.5 open source models in\n7B, 32B, and 72B sizes. Our conversion process requires only 350-700M tokens,\nless than 0.005% of the token count used to train the original teacher models.\nConverting to our 72B linear attention model costs less than \\$2,000 USD at\ntoday's prices, yet quality at inference remains close to the original\ntransformer. These models achieve state-of-the-art downstream performance\nacross a set of standard benchmarks for linear attention models of their size.\nWe release all our models on HuggingFace under the Apache 2.0 license, with the\nexception of our 72B models which are also governed by the Qwen License\nAgreement.\n  Models at\nhttps://huggingface.co/collections/recursal/radlads-6818ee69e99e729ba8a87102\nTraining Code at https://github.com/recursal/RADLADS-paper",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.03005v2",
    "published_date": "2025-05-05 20:03:28 UTC",
    "updated_date": "2025-05-07 18:54:55 UTC"
  },
  {
    "arxiv_id": "2505.02966v1",
    "title": "Generating Narrated Lecture Videos from Slides with Synchronized Highlights",
    "authors": [
      "Alexander Holmberg"
    ],
    "abstract": "Turning static slides into engaging video lectures takes considerable time\nand effort, requiring presenters to record explanations and visually guide\ntheir audience through the material. We introduce an end-to-end system designed\nto automate this process entirely. Given a slide deck, this system synthesizes\na video lecture featuring AI-generated narration synchronized precisely with\ndynamic visual highlights. These highlights automatically draw attention to the\nspecific concept being discussed, much like an effective presenter would. The\ncore technical contribution is a novel highlight alignment module. This module\naccurately maps spoken phrases to locations on a given slide using diverse\nstrategies (e.g., Levenshtein distance, LLM-based semantic analysis) at\nselectable granularities (line or word level) and utilizes timestamp-providing\nText-to-Speech (TTS) for timing synchronization. We demonstrate the system's\neffectiveness through a technical evaluation using a manually annotated slide\ndataset with 1000 samples, finding that LLM-based alignment achieves high\nlocation accuracy (F1 > 92%), significantly outperforming simpler methods,\nespecially on complex, math-heavy content. Furthermore, the calculated\ngeneration cost averages under $1 per hour of video, offering potential savings\nof two orders of magnitude compared to conservative estimates of manual\nproduction costs. This combination of high accuracy and extremely low cost\npositions this approach as a practical and scalable tool for transforming\nstatic slides into effective, visually-guided video lectures.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02966v1",
    "published_date": "2025-05-05 18:51:53 UTC",
    "updated_date": "2025-05-05 18:51:53 UTC"
  },
  {
    "arxiv_id": "2505.02952v1",
    "title": "Iterative Resolution of Prompt Ambiguities Using a Progressive Cutting-Search Approach",
    "authors": [
      "Fabrizio Marozzo"
    ],
    "abstract": "Generative AI systems have revolutionized human interaction by enabling\nnatural language-based coding and problem solving. However, the inherent\nambiguity of natural language often leads to imprecise instructions, forcing\nusers to iteratively test, correct, and resubmit their prompts. We propose an\niterative approach that systematically narrows down these ambiguities through a\nstructured series of clarification questions and alternative solution\nproposals, illustrated with input/output examples as well. Once every\nuncertainty is resolved, a final, precise solution is generated. Evaluated on a\ndiverse dataset spanning coding, data analysis, and creative writing, our\nmethod demonstrates superior accuracy, competitive resolution times, and higher\nuser satisfaction compared to conventional one-shot solutions, which typically\nrequire multiple manual iterations to achieve a correct output.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.ET",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02952v1",
    "published_date": "2025-05-05 18:31:18 UTC",
    "updated_date": "2025-05-05 18:31:18 UTC"
  },
  {
    "arxiv_id": "2505.02945v1",
    "title": "The Cognitive Foundations of Economic Exchange: A Modular Framework Grounded in Behavioral Evidence",
    "authors": [
      "Egil Diau"
    ],
    "abstract": "A key challenge in multi-agent AI is modeling social cooperation under\nrealistic behavioral constraints. Many foundational concepts in economics and\nethics such as \"trust\" or \"morality\" are often defined informally, without\noperational criteria or cognitive grounding, which limits their testability and\nimplementation in artificial agents. Drawing on converging empirical evidence\nfrom primate behavior, infant cognition, and economic anthropology, we propose\na conceptual framework composed of three cognitively minimal mechanisms:\nindividual recognition, reciprocal credence, and cost return sensitivity. This\nframework reframes trust as a graded cognitive expectation, providing a\nsimulateable basis for reciprocal exchange in artificial agents, and enabling\nthe bottom-up emergence of scalable cooperation and institutional dynamics.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.CY",
    "comment": "This is a position paper. Theoretical framework is finalized; minor\n  language revisions are ongoing. Submitted for feedback and public discussion",
    "pdf_url": "http://arxiv.org/pdf/2505.02945v1",
    "published_date": "2025-05-05 18:21:53 UTC",
    "updated_date": "2025-05-05 18:21:53 UTC"
  },
  {
    "arxiv_id": "2505.02931v1",
    "title": "The Art of Repair: Optimizing Iterative Program Repair with Instruction-Tuned Models",
    "authors": [
      "Fernando Vallecillos Ruiz",
      "Max Hort",
      "Leon Moonen"
    ],
    "abstract": "Automatic program repair (APR) aims to reduce the manual efforts required to\nidentify and fix errors in source code. Before the rise of LLM-based agents, a\ncommon strategy was to increase the number of generated patches, sometimes to\nthe thousands, to achieve better repair results on benchmarks. More recently,\nself-iterative capabilities enabled LLMs to refine patches over multiple rounds\nguided by feedback. However, literature often focuses on many iterations and\ndisregards different numbers of outputs.\n  We investigate an APR pipeline that balances these two approaches, the\ngeneration of multiple outputs and multiple rounds of iteration, while imposing\na limit of 10 total patches per bug. We apply three SOTA instruction-tuned LLMs\n- DeepSeekCoder-Instruct, Codellama-Instruct, Llama3.1-Instruct - to the APR\ntask. We further fine-tune each model on an APR dataset with three sizes (1K,\n30K, 65K) and two techniques (Full Fine-Tuning and LoRA), allowing us to assess\ntheir repair capabilities on two APR benchmarks: HumanEval-Java and Defects4J.\n  Our results show that by using only a fraction (<1%) of the fine-tuning\ndataset, we can achieve improvements of up to 78% in the number of plausible\npatches generated, challenging prior studies that reported limited gains using\nFull Fine-Tuning. However, we find that exceeding certain thresholds leads to\ndiminishing outcomes, likely due to overfitting. Moreover, we show that base\nmodels greatly benefit from creating patches in an iterative fashion rather\nthan generating them all at once. In addition, the benefit of iterative\nstrategies becomes more pronounced in complex benchmarks. Even fine-tuned\nmodels, while benefiting less from iterations, still gain advantages,\nparticularly on complex benchmarks. The research underscores the need for\nbalanced APR strategies that combine multi-output generation and iterative\nrefinement.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted for publication in the research track of the 29th\n  International Conference on Evaluation and Assessment in Software Engineering\n  (EASE), 17-20 June 2025, Istanbul, T\\\"urkiye",
    "pdf_url": "http://arxiv.org/pdf/2505.02931v1",
    "published_date": "2025-05-05 18:06:51 UTC",
    "updated_date": "2025-05-05 18:06:51 UTC"
  },
  {
    "arxiv_id": "2505.02889v1",
    "title": "Early Prediction of Sepsis: Feature-Aligned Transfer Learning",
    "authors": [
      "Oyindolapo O. Komolafe",
      "Zhimin Mei",
      "David Morales Zarate",
      "Gregory William Spangenberg"
    ],
    "abstract": "Sepsis is a life threatening medical condition that occurs when the body has\nan extreme response to infection, leading to widespread inflammation, organ\nfailure, and potentially death. Because sepsis can worsen rapidly, early\ndetection is critical to saving lives. However, current diagnostic methods\noften identify sepsis only after significant damage has already occurred. Our\nproject aims to address this challenge by developing a machine learning based\nsystem to predict sepsis in its early stages, giving healthcare providers more\ntime to intervene.\n  A major problem with existing models is the wide variability in the patient\ninformation or features they use, such as heart rate, temperature, and lab\nresults. This inconsistency makes models difficult to compare and limits their\nability to work across different hospitals and settings. To solve this, we\npropose a method called Feature Aligned Transfer Learning (FATL), which\nidentifies and focuses on the most important and commonly reported features\nacross multiple studies, ensuring the model remains consistent and clinically\nrelevant.\n  Most existing models are trained on narrow patient groups, leading to\npopulation bias. FATL addresses this by combining knowledge from models trained\non diverse populations, using a weighted approach that reflects each models\ncontribution. This makes the system more generalizable and effective across\ndifferent patient demographics and clinical environments. FATL offers a\npractical and scalable solution for early sepsis detection, particularly in\nhospitals with limited resources, and has the potential to improve patient\noutcomes, reduce healthcare costs, and support more equitable healthcare\ndelivery.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "A project implemented for MACHINE LEARNING IN HEALTH AND BIOMEDICAL\n  SCIENCE",
    "pdf_url": "http://arxiv.org/pdf/2505.02889v1",
    "published_date": "2025-05-05 17:59:34 UTC",
    "updated_date": "2025-05-05 17:59:34 UTC"
  },
  {
    "arxiv_id": "2505.02829v1",
    "title": "LISAT: Language-Instructed Segmentation Assistant for Satellite Imagery",
    "authors": [
      "Jerome Quenum",
      "Wen-Han Hsieh",
      "Tsung-Han Wu",
      "Ritwik Gupta",
      "Trevor Darrell",
      "David M. Chan"
    ],
    "abstract": "Segmentation models can recognize a pre-defined set of objects in images.\nHowever, models that can reason over complex user queries that implicitly refer\nto multiple objects of interest are still in their infancy. Recent advances in\nreasoning segmentation--generating segmentation masks from complex, implicit\nquery text--demonstrate that vision-language models can operate across an open\ndomain and produce reasonable outputs. However, our experiments show that such\nmodels struggle with complex remote-sensing imagery. In this work, we introduce\nLISAt, a vision-language model designed to describe complex remote-sensing\nscenes, answer questions about them, and segment objects of interest. We\ntrained LISAt on a new curated geospatial reasoning-segmentation dataset, GRES,\nwith 27,615 annotations over 9,205 images, and a multimodal pretraining\ndataset, PreGRES, containing over 1 million question-answer pairs. LISAt\noutperforms existing geospatial foundation models such as RS-GPT4V by over\n10.04 % (BLEU-4) on remote-sensing description tasks, and surpasses\nstate-of-the-art open-domain models on reasoning segmentation tasks by 143.36 %\n(gIoU). Our model, datasets, and code are available at\nhttps://lisat-bair.github.io/LISAt/",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "28 pages, 10 figures, 19 tables",
    "pdf_url": "http://arxiv.org/pdf/2505.02829v1",
    "published_date": "2025-05-05 17:56:25 UTC",
    "updated_date": "2025-05-05 17:56:25 UTC"
  },
  {
    "arxiv_id": "2505.02828v1",
    "title": "Privacy Risks and Preservation Methods in Explainable Artificial Intelligence: A Scoping Review",
    "authors": [
      "Sonal Allana",
      "Mohan Kankanhalli",
      "Rozita Dara"
    ],
    "abstract": "Explainable Artificial Intelligence (XAI) has emerged as a pillar of\nTrustworthy AI and aims to bring transparency in complex models that are opaque\nby nature. Despite the benefits of incorporating explanations in models, an\nurgent need is found in addressing the privacy concerns of providing this\nadditional information to end users. In this article, we conduct a scoping\nreview of existing literature to elicit details on the conflict between privacy\nand explainability. Using the standard methodology for scoping review, we\nextracted 57 articles from 1,943 studies published from January 2019 to\nDecember 2024. The review addresses 3 research questions to present readers\nwith more understanding of the topic: (1) what are the privacy risks of\nreleasing explanations in AI systems? (2) what current methods have researchers\nemployed to achieve privacy preservation in XAI systems? (3) what constitutes a\nprivacy preserving explanation? Based on the knowledge synthesized from the\nselected studies, we categorize the privacy risks and preservation methods in\nXAI and propose the characteristics of privacy preserving explanations to aid\nresearchers and practitioners in understanding the requirements of XAI that is\nprivacy compliant. Lastly, we identify the challenges in balancing privacy with\nother system desiderata and provide recommendations for achieving privacy\npreserving XAI. We expect that this review will shed light on the complex\nrelationship of privacy and explainability, both being the fundamental\nprinciples of Trustworthy AI.",
    "categories": [
      "cs.AI",
      "cs.CR",
      "cs.ET"
    ],
    "primary_category": "cs.AI",
    "comment": "Submitted for peer review",
    "pdf_url": "http://arxiv.org/pdf/2505.02828v1",
    "published_date": "2025-05-05 17:53:28 UTC",
    "updated_date": "2025-05-05 17:53:28 UTC"
  },
  {
    "arxiv_id": "2505.03848v1",
    "title": "Advanced Clustering Framework for Semiconductor Image Analytics Integrating Deep TDA with Self-Supervised and Transfer Learning Techniques",
    "authors": [
      "Janhavi Giri",
      "Attila Lengyel",
      "Don Kent",
      "Edward Kibardin"
    ],
    "abstract": "Semiconductor manufacturing generates vast amounts of image data, crucial for\ndefect identification and yield optimization, yet often exceeds manual\ninspection capabilities. Traditional clustering techniques struggle with\nhigh-dimensional, unlabeled data, limiting their effectiveness in capturing\nnuanced patterns. This paper introduces an advanced clustering framework that\nintegrates deep Topological Data Analysis (TDA) with self-supervised and\ntransfer learning techniques, offering a novel approach to unsupervised image\nclustering. TDA captures intrinsic topological features, while self-supervised\nlearning extracts meaningful representations from unlabeled data, reducing\nreliance on labeled datasets. Transfer learning enhances the framework's\nadaptability and scalability, allowing fine-tuning to new datasets without\nretraining from scratch. Validated on synthetic and open-source semiconductor\nimage datasets, the framework successfully identifies clusters aligned with\ndefect patterns and process variations. This study highlights the\ntransformative potential of combining TDA, self-supervised learning, and\ntransfer learning, providing a scalable solution for proactive process\nmonitoring and quality control in semiconductor manufacturing and other domains\nwith large-scale image datasets.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.ET",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "46 pages, 22 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2505.03848v1",
    "published_date": "2025-05-05 17:53:03 UTC",
    "updated_date": "2025-05-05 17:53:03 UTC"
  },
  {
    "arxiv_id": "2505.02824v1",
    "title": "Towards Dataset Copyright Evasion Attack against Personalized Text-to-Image Diffusion Models",
    "authors": [
      "Kuofeng Gao",
      "Yufei Zhu",
      "Yiming Li",
      "Jiawang Bai",
      "Yong Yang",
      "Zhifeng Li",
      "Shu-Tao Xia"
    ],
    "abstract": "Text-to-image (T2I) diffusion models have rapidly advanced, enabling\nhigh-quality image generation conditioned on textual prompts. However, the\ngrowing trend of fine-tuning pre-trained models for personalization raises\nserious concerns about unauthorized dataset usage. To combat this, dataset\nownership verification (DOV) has emerged as a solution, embedding watermarks\ninto the fine-tuning datasets using backdoor techniques. These watermarks\nremain inactive under benign samples but produce owner-specified outputs when\ntriggered. Despite the promise of DOV for T2I diffusion models, its robustness\nagainst copyright evasion attacks (CEA) remains unexplored. In this paper, we\nexplore how attackers can bypass these mechanisms through CEA, allowing models\nto circumvent watermarks even when trained on watermarked datasets. We propose\nthe first copyright evasion attack (i.e., CEAT2I) specifically designed to\nundermine DOV in T2I diffusion models. Concretely, our CEAT2I comprises three\nstages: watermarked sample detection, trigger identification, and efficient\nwatermark mitigation. A key insight driving our approach is that T2I models\nexhibit faster convergence on watermarked samples during the fine-tuning,\nevident through intermediate feature deviation. Leveraging this, CEAT2I can\nreliably detect the watermarked samples. Then, we iteratively ablate tokens\nfrom the prompts of detected watermarked samples and monitor shifts in\nintermediate features to pinpoint the exact trigger tokens. Finally, we adopt a\nclosed-form concept erasure method to remove the injected watermark. Extensive\nexperiments show that our CEAT2I effectively evades DOV mechanisms while\npreserving model performance.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02824v1",
    "published_date": "2025-05-05 17:51:55 UTC",
    "updated_date": "2025-05-05 17:51:55 UTC"
  },
  {
    "arxiv_id": "2505.02820v1",
    "title": "AutoLibra: Agent Metric Induction from Open-Ended Feedback",
    "authors": [
      "Hao Zhu",
      "Phil Cuvin",
      "Xinkai Yu",
      "Charlotte Ka Yee Yan",
      "Jason Zhang",
      "Diyi Yang"
    ],
    "abstract": "Agents are predominantly evaluated and optimized via task success metrics,\nwhich are coarse, rely on manual design from experts, and fail to reward\nintermediate emergent behaviors. We propose AutoLibra, a framework for agent\nevaluation, that transforms open-ended human feedback, e.g., \"If you find that\nthe button is disabled, don't click it again\", or \"This agent has too much\nautonomy to decide what to do on its own\", into metrics for evaluating\nfine-grained behaviors in agent trajectories. AutoLibra accomplishes this by\ngrounding feedback to an agent's behavior, clustering similar positive and\nnegative behaviors, and creating concrete metrics with clear definitions and\nconcrete examples, which can be used for prompting LLM-as-a-Judge as\nevaluators. We further propose two meta-metrics to evaluate the alignment of a\nset of (induced) metrics with open feedback: \"coverage\" and \"redundancy\".\nThrough optimizing these meta-metrics, we experimentally demonstrate\nAutoLibra's ability to induce more concrete agent evaluation metrics than the\nones proposed in previous agent evaluation benchmarks and discover new metrics\nto analyze agents. We also present two applications of AutoLibra in agent\nimprovement: First, we show that AutoLibra-induced metrics serve as better\nprompt-engineering targets than the task success rate on a wide range of text\ngame tasks, improving agent performance over baseline by a mean of 20%. Second,\nwe show that AutoLibra can iteratively select high-quality fine-tuning data for\nweb navigation agents. Our results suggest that AutoLibra is a powerful\ntask-agnostic tool for evaluating and improving language agents.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "https://opensocial.world/",
    "pdf_url": "http://arxiv.org/pdf/2505.02820v1",
    "published_date": "2025-05-05 17:47:49 UTC",
    "updated_date": "2025-05-05 17:47:49 UTC"
  },
  {
    "arxiv_id": "2505.02811v1",
    "title": "Knowing You Don't Know: Learning When to Continue Search in Multi-round RAG through Self-Practicing",
    "authors": [
      "Diji Yang",
      "Linda Zeng",
      "Jinmeng Rao",
      "Yi Zhang"
    ],
    "abstract": "Retrieval Augmented Generation (RAG) has shown strong capability in enhancing\nlanguage models' knowledge and reducing AI generative hallucinations, driving\nits widespread use. However, complex tasks requiring multi-round retrieval\nremain challenging, and early attempts tend to be overly optimistic without a\ngood sense of self-skepticism. Current multi-round RAG systems may continue\nsearching even when enough information has already been retrieved, or they may\nprovide incorrect answers without having sufficient information or knowledge.\nExisting solutions either require large amounts of expensive human-labeled\nprocess supervision data or lead to subpar performance.\n  This paper aims to address these limitations by introducing a new framework,\n\\textbf{SIM-RAG}, to explicitly enhance RAG systems' self-awareness and\nmulti-round retrieval capabilities. To train SIM-RAG, we first let a RAG system\nself-practice multi-round retrieval, augmenting existing question-answer pairs\nwith intermediate inner monologue reasoning steps to generate synthetic\ntraining data. For each pair, the system may explore multiple retrieval paths,\nwhich are labeled as successful if they reach the correct answer and\nunsuccessful otherwise. Using this data, we train a lightweight information\nsufficiency Critic. At inference time, the Critic evaluates whether the RAG\nsystem has retrieved sufficient information at each round, guiding retrieval\ndecisions and improving system-level self-awareness through in-context\nreinforcement learning.\n  Experiments across multiple prominent RAG benchmarks show that SIM-RAG is an\neffective multi-round RAG solution. Furthermore, this framework is\nsystem-efficient, adding a lightweight component to RAG without requiring\nmodifications to existing LLMs or search engines, and data-efficient,\neliminating the need for costly human-annotated mid-step retrieval process\nsupervision data.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "comment": "Proceedings of the 48th International ACM SIGIR 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.02811v1",
    "published_date": "2025-05-05 17:39:35 UTC",
    "updated_date": "2025-05-05 17:39:35 UTC"
  },
  {
    "arxiv_id": "2505.02795v1",
    "title": "HSplitLoRA: A Heterogeneous Split Parameter-Efficient Fine-Tuning Framework for Large Language Models",
    "authors": [
      "Zheng Lin",
      "Yuxin Zhang",
      "Zhe Chen",
      "Zihan Fang",
      "Xianhao Chen",
      "Praneeth Vepakomma",
      "Wei Ni",
      "Jun Luo",
      "Yue Gao"
    ],
    "abstract": "Recently, large language models (LLMs) have achieved remarkable\nbreakthroughs, revolutionizing the natural language processing domain and\nbeyond. Due to immense parameter sizes, fine-tuning these models with private\ndata for diverse downstream tasks has become mainstream. Though federated\nlearning (FL) offers a promising solution for fine-tuning LLMs without sharing\nraw data, substantial computing costs hinder its democratization. Moreover, in\nreal-world scenarios, private client devices often possess heterogeneous\ncomputing resources, further complicating LLM fine-tuning. To combat these\nchallenges, we propose HSplitLoRA, a heterogeneous parameter-efficient\nfine-tuning (PEFT) framework built on split learning (SL) and low-rank\nadaptation (LoRA) fine-tuning, for efficiently fine-tuning LLMs on\nheterogeneous client devices. HSplitLoRA first identifies important weights\nbased on their contributions to LLM training. It then dynamically configures\nthe decomposition ranks of LoRA adapters for selected weights and determines\nthe model split point according to varying computing budgets of client devices.\nFinally, a noise-free adapter aggregation mechanism is devised to support\nheterogeneous adapter aggregation without introducing noise. Extensive\nexperiments demonstrate that HSplitLoRA outperforms state-of-the-art benchmarks\nin training accuracy and convergence speed.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "16 pages, 22 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.02795v1",
    "published_date": "2025-05-05 17:09:19 UTC",
    "updated_date": "2025-05-05 17:09:19 UTC"
  },
  {
    "arxiv_id": "2505.02888v1",
    "title": "When Your Own Output Becomes Your Training Data: Noise-to-Meaning Loops and a Formal RSI Trigger",
    "authors": [
      "Rintaro Ando"
    ],
    "abstract": "We present Noise-to-Meaning Recursive Self-Improvement (N2M-RSI), a minimal\nformal model showing that once an AI agent feeds its own outputs back as inputs\nand crosses an explicit information-integration threshold, its internal\ncomplexity will grow without bound under our assumptions. The framework unifies\nearlier ideas on self-prompting large language models, G\\\"odelian\nself-reference, and AutoML, yet remains implementation-agnostic. The model\nfurthermore scales naturally to interacting swarms of agents, hinting at\nsuper-linear effects once communication among instances is permitted. For\nsafety reasons, we omit system-specific implementation details and release only\na brief, model-agnostic toy prototype in Appendix C.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "68T05, 68Q85",
      "I.2.0; I.2.3; I.2.6"
    ],
    "primary_category": "cs.LG",
    "comment": "20 pages, 4 figures, 3 tables. Code:\n  github.com/rintaro-ando-tech/n2m-rsi-demo (v1.0)",
    "pdf_url": "http://arxiv.org/pdf/2505.02888v1",
    "published_date": "2025-05-05 17:03:07 UTC",
    "updated_date": "2025-05-05 17:03:07 UTC"
  },
  {
    "arxiv_id": "2505.02781v1",
    "title": "Local Markov Equivalence and Local Causal Discovery for Identifying Controlled Direct Effects",
    "authors": [
      "TimothÃ©e Loranchet",
      "Charles K. Assaad"
    ],
    "abstract": "Understanding and identifying controlled direct effects (CDEs) is crucial\nacross numerous scientific domains, including public health. While existing\nmethods can identify these effects from causal directed acyclic graphs (DAGs),\nthe true underlying structure is often unknown in practice. Essential graphs,\nwhich represent a Markov equivalence class of DAGs characterized by the same\nset of d-separations, provide a more practical and realistic alternative.\nHowever, learning the full essential graph is computationally intensive and\ntypically depends on strong, untestable assumptions. In this work, we\ncharacterize a local class of graphs, defined relative to a target variable,\nthat share a specific subset of d-separations, and introduce a graphical\nrepresentation of this class, called the local essential graph (LEG). We then\npresent LocPC, a novel algorithm designed to recover the LEG from an observed\ndistribution using only local conditional independence tests. Building on\nLocPC, we propose LocPC-CDE, an algorithm that discovers the portion of the LEG\nthat is sufficient to identify a CDE, bypassing the need of retrieving the full\nessential graph. Compared to global methods, our algorithms require less\nconditional independence tests and operate under weaker assumptions while\nmaintaining theoretical guarantees.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02781v1",
    "published_date": "2025-05-05 16:47:29 UTC",
    "updated_date": "2025-05-05 16:47:29 UTC"
  },
  {
    "arxiv_id": "2505.02780v1",
    "title": "Beyond the Monitor: Mixed Reality Visualization and AI for Enhanced Digital Pathology Workflow",
    "authors": [
      "Jai Prakash Veerla",
      "Partha Sai Guttikonda",
      "Helen H. Shang",
      "Mohammad Sadegh Nasr",
      "Cesar Torres",
      "Jacob M. Luber"
    ],
    "abstract": "Pathologists rely on gigapixel whole-slide images (WSIs) to diagnose diseases\nlike cancer, yet current digital pathology tools hinder diagnosis. The immense\nscale of WSIs, often exceeding 100,000 X 100,000 pixels, clashes with the\nlimited views traditional monitors offer. This mismatch forces constant panning\nand zooming, increasing pathologist cognitive load, causing diagnostic fatigue,\nand slowing pathologists' adoption of digital methods. PathVis, our\nmixed-reality visualization platform for Apple Vision Pro, addresses these\nchallenges. It transforms the pathologist's interaction with data, replacing\ncumbersome mouse-and-monitor navigation with intuitive exploration using\nnatural hand gestures, eye gaze, and voice commands in an immersive workspace.\nPathVis integrates AI to enhance diagnosis. An AI-driven search function\ninstantly retrieves and displays the top five similar patient cases\nside-by-side, improving diagnostic precision and efficiency through rapid\ncomparison. Additionally, a multimodal conversational AI assistant offers\nreal-time image interpretation support and aids collaboration among\npathologists across multiple Apple devices. By merging the directness of\ntraditional pathology with advanced mixed-reality visualization and AI, PathVis\nimproves diagnostic workflows, reduces cognitive strain, and makes pathology\npractice more effective and engaging. The PathVis source code and a demo video\nare publicly available at: https://github.com/jaiprakash1824/Path_Vis",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.ET",
      "q-bio.TO"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02780v1",
    "published_date": "2025-05-05 16:46:53 UTC",
    "updated_date": "2025-05-05 16:46:53 UTC"
  },
  {
    "arxiv_id": "2505.02766v1",
    "title": "Giving Simulated Cells a Voice: Evolving Prompt-to-Intervention Models for Cellular Control",
    "authors": [
      "Nam H. Le",
      "Patrick Erikson",
      "Yanbo Zhang",
      "Michael Levin",
      "Josh Bongard"
    ],
    "abstract": "Guiding biological systems toward desired states, such as morphogenetic\noutcomes, remains a fundamental challenge with far-reaching implications for\nmedicine and synthetic biology. While large language models (LLMs) have enabled\nnatural language as an interface for interpretable control in AI systems, their\nuse as mediators for steering biological or cellular dynamics remains largely\nunexplored.\n  In this work, we present a functional pipeline that translates natural\nlanguage prompts into spatial vector fields capable of directing simulated\ncellular collectives. Our approach combines a large language model with an\nevolvable neural controller (Prompt-to-Intervention, or P2I), optimized via\nevolutionary strategies to generate behaviors such as clustering or scattering\nin a simulated 2D environment.\n  We demonstrate that even with constrained vocabulary and simplified cell\nmodels, evolved P2I networks can successfully align cellular dynamics with\nuser-defined goals expressed in plain language. This work offers a complete\nloop from language input to simulated bioelectric-like intervention to\nbehavioral output, providing a foundation for future systems capable of natural\nlanguage-driven cellular control.",
    "categories": [
      "cs.AI",
      "cs.NE",
      "cs.RO",
      "q-bio.TO"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to GECCO Workshop on Bio-Inspired AI (ACM GECCO2025). 13\n  pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.02766v1",
    "published_date": "2025-05-05 16:21:46 UTC",
    "updated_date": "2025-05-05 16:21:46 UTC"
  },
  {
    "arxiv_id": "2505.02763v1",
    "title": "Bye-bye, Bluebook? Automating Legal Procedure with Large Language Models",
    "authors": [
      "Matthew Dahl"
    ],
    "abstract": "Legal practice requires careful adherence to procedural rules. In the United\nStates, few are more complex than those found in The Bluebook: A Uniform System\nof Citation. Compliance with this system's 500+ pages of byzantine formatting\ninstructions is the raison d'etre of thousands of student law review editors\nand the bete noire of lawyers everywhere. To evaluate whether large language\nmodels (LLMs) are able to adhere to the procedures of such a complicated\nsystem, we construct an original dataset of 866 Bluebook tasks and test\nflagship LLMs from OpenAI, Anthropic, Google, Meta, and DeepSeek. We show (1)\nthat these models produce fully compliant Bluebook citations only 69%-74% of\nthe time and (2) that in-context learning on the Bluebook's underlying system\nof rules raises accuracy only to 77%. These results caution against using\noff-the-shelf LLMs to automate aspects of the law where fidelity to procedure\nis paramount.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02763v1",
    "published_date": "2025-05-05 16:18:07 UTC",
    "updated_date": "2025-05-05 16:18:07 UTC"
  },
  {
    "arxiv_id": "2505.02747v1",
    "title": "The use of Artificial Intelligence for Intervention and Assessment in Individuals with ASD",
    "authors": [
      "Aggeliki Sideraki",
      "Christos-Nikolaos Anagnostopoulos"
    ],
    "abstract": "This paper explores the use of Artificial Intelligence (AI) as a tool for\ndiagnosis, assessment, and intervention for individuals with Autism Spectrum\nDisorder (ASD). It focuses particularly on AI's role in early diagnosis,\nutilizing advanced machine learning techniques and data analysis. Recent\nstudies demonstrate that deep learning algorithms can identify behavioral\npatterns through biometric data analysis, video-based interaction assessments,\nand linguistic feature extraction, providing a more accurate and timely\ndiagnosis compared to traditional methods. Additionally, AI automates\ndiagnostic tools, reducing subjective biases and enabling the development of\npersonalized assessment protocols for ASD monitoring. At the same time, the\npaper examines AI-powered intervention technologies, emphasizing educational\nrobots and adaptive communication tools. Social robotic assistants, such as NAO\nand Kaspar, have been shown to enhance social skills in children by offering\nstructured, repetitive interactions that reinforce learning. Furthermore,\nAI-driven Augmentative and Alternative Communication (AAC) systems allow\nchildren with ASD to express themselves more effectively, while\nmachine-learning chatbots provide language development support through\npersonalized responses. The study presents research findings supporting the\neffectiveness of these AI applications while addressing challenges such as\nlong-term evaluation and customization to individual needs. In conclusion, the\npaper highlights the significance of AI as an innovative tool in ASD diagnosis\nand intervention, advocating for further research to assess its long-term\nimpact.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "21 pages",
    "pdf_url": "http://arxiv.org/pdf/2505.02747v1",
    "published_date": "2025-05-05 15:58:32 UTC",
    "updated_date": "2025-05-05 15:58:32 UTC"
  },
  {
    "arxiv_id": "2505.02887v1",
    "title": "CreoPep: A Universal Deep Learning Framework for Target-Specific Peptide Design and Optimization",
    "authors": [
      "Cheng Ge",
      "Han-Shen Tae",
      "Zhenqiang Zhang",
      "Lu Lu",
      "Zhijie Huang",
      "Yilin Wang",
      "Tao Jiang",
      "Wenqing Cai",
      "Shan Chang",
      "David J. Adams",
      "Rilei Yu"
    ],
    "abstract": "Target-specific peptides, such as conotoxins, exhibit exceptional binding\naffinity and selectivity toward ion channels and receptors. However, their\ntherapeutic potential remains underutilized due to the limited diversity of\nnatural variants and the labor-intensive nature of traditional optimization\nstrategies. Here, we present CreoPep, a deep learning-based conditional\ngenerative framework that integrates masked language modeling with a\nprogressive masking scheme to design high-affinity peptide mutants while\nuncovering novel structural motifs. CreoPep employs an integrative augmentation\npipeline, combining FoldX-based energy screening with temperature-controlled\nmultinomial sampling, to generate structurally and functionally diverse\npeptides that retain key pharmacological properties. We validate this approach\nby designing conotoxin inhibitors targeting the $\\alpha$7 nicotinic\nacetylcholine receptor, achieving submicromolar potency in electrophysiological\nassays. Structural analysis reveals that CreoPep-generated variants engage in\nboth conserved and novel binding modes, including disulfide-deficient forms,\nthus expanding beyond conventional design paradigms. Overall, CreoPep offers a\nrobust and generalizable platform that bridges computational peptide design\nwith experimental validation, accelerating the discovery of next-generation\npeptide therapeutics.",
    "categories": [
      "q-bio.BM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.BM",
    "comment": "16 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.02887v1",
    "published_date": "2025-05-05 15:56:39 UTC",
    "updated_date": "2025-05-05 15:56:39 UTC"
  },
  {
    "arxiv_id": "2505.02886v1",
    "title": "Taskmaster Deconstructed: A Quantitative Look at Tension, Volatility, and Viewer Ratings",
    "authors": [
      "David H. Silver"
    ],
    "abstract": "Taskmaster is a British television show that combines comedic performance\nwith a formal scoring system. Despite the appearance of structured competition,\nit remains unclear whether scoring dynamics contribute meaningfully to audience\nengagement. We conducted a statistical analysis of 162 episodes across 18\nseries, using fifteen episode-level metrics to quantify rank volatility, point\nspread, lead changes, and winner dominance. None of these metrics showed a\nsignificant association with IMDb ratings, even after controlling for series\neffects. Long-term trends suggest that average points have increased over time,\nwhile volatility has slightly declined and rank spread has remained stable.\nThese patterns indicate an attempt to enhance competitive visibility without\naltering the show's structural equilibrium. We also analyzed contestant rank\ntrajectories and identified five recurring archetypes describing performance\nstyles. These patterns suggest that viewer interest is shaped more by\ncontestant behavior than by game mechanics.",
    "categories": [
      "physics.soc-ph",
      "cs.AI",
      "62P25 (Applications to social sciences), 91B14 (Social choice) 62P25",
      "H.5.1; I.2.7"
    ],
    "primary_category": "physics.soc-ph",
    "comment": "29 pages, includes 5 figures and 18 supplementary visualizations.\n  Submitted as a preprint. Code and data available at github dot com slash\n  silverdavi slash taskmaster-stats",
    "pdf_url": "http://arxiv.org/pdf/2505.02886v1",
    "published_date": "2025-05-05 15:46:32 UTC",
    "updated_date": "2025-05-05 15:46:32 UTC"
  },
  {
    "arxiv_id": "2505.02737v2",
    "title": "Knowledge Graphs for Enhancing Large Language Models in Entity Disambiguation",
    "authors": [
      "Gerard Pons",
      "Besim Bilalli",
      "Anna Queralt"
    ],
    "abstract": "Recent advances in Large Language Models (LLMs) have positioned them as a\nprominent solution for Natural Language Processing tasks. Notably, they can\napproach these problems in a zero or few-shot manner, thereby eliminating the\nneed for training or fine-tuning task-specific models. However, LLMs face some\nchallenges, including hallucination and the presence of outdated knowledge or\nmissing information from specific domains in the training data. These problems\ncannot be easily solved by retraining the models with new data as it is a\ntime-consuming and expensive process. To mitigate these issues, Knowledge\nGraphs (KGs) have been proposed as a structured external source of information\nto enrich LLMs. With this idea, in this work we use KGs to enhance LLMs for\nzero-shot Entity Disambiguation (ED). For that purpose, we leverage the\nhierarchical representation of the entities' classes in a KG to gradually prune\nthe candidate space as well as the entities' descriptions to enrich the input\nprompt with additional factual knowledge. Our evaluation on popular ED datasets\nshows that the proposed method outperforms non-enhanced and description-only\nenhanced LLMs, and has a higher degree of adaptability than task-specific\nmodels. Furthermore, we conduct an error analysis and discuss the impact of the\nleveraged KG's semantic expressivity on the ED performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.LG",
    "comment": "Pre-print submitted to ISWC 2024",
    "pdf_url": "http://arxiv.org/pdf/2505.02737v2",
    "published_date": "2025-05-05 15:40:24 UTC",
    "updated_date": "2025-05-06 06:44:35 UTC"
  },
  {
    "arxiv_id": "2505.02735v1",
    "title": "FormalMATH: Benchmarking Formal Mathematical Reasoning of Large Language Models",
    "authors": [
      "Zhouliang Yu",
      "Ruotian Peng",
      "Keyi Ding",
      "Yizhe Li",
      "Zhongyuan Peng",
      "Minghao Liu",
      "Yifan Zhang",
      "Zheng Yuan",
      "Huajian Xin",
      "Wenhao Huang",
      "Yandong Wen",
      "Ge Zhang",
      "Weiyang Liu"
    ],
    "abstract": "Formal mathematical reasoning remains a critical challenge for artificial\nintelligence, hindered by limitations of existing benchmarks in scope and\nscale. To address this, we present FormalMATH, a large-scale Lean4 benchmark\ncomprising 5,560 formally verified problems spanning from high-school Olympiad\nchallenges to undergraduate-level theorems across diverse domains (e.g.,\nalgebra, applied mathematics, calculus, number theory, and discrete\nmathematics). To mitigate the inefficiency of manual formalization, we\nintroduce a novel human-in-the-loop autoformalization pipeline that integrates:\n(1) specialized large language models (LLMs) for statement autoformalization,\n(2) multi-LLM semantic verification, and (3) negation-based disproof filtering\nstrategies using off-the-shelf LLM-based provers. This approach reduces expert\nannotation costs by retaining 72.09% of statements before manual verification\nwhile ensuring fidelity to the original natural-language problems. Our\nevaluation of state-of-the-art LLM-based theorem provers reveals significant\nlimitations: even the strongest models achieve only 16.46% success rate under\npractical sampling budgets, exhibiting pronounced domain bias (e.g., excelling\nin algebra but failing in calculus) and over-reliance on simplified automation\ntactics. Notably, we identify a counterintuitive inverse relationship between\nnatural-language solution guidance and proof success in chain-of-thought\nreasoning scenarios, suggesting that human-written informal reasoning\nintroduces noise rather than clarity in the formal reasoning settings. We\nbelieve that FormalMATH provides a robust benchmark for benchmarking formal\nmathematical reasoning.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Technical Report v1 (33 pages, 8 figures, project page:\n  https://sphere-ai-lab.github.io/FormalMATH/)",
    "pdf_url": "http://arxiv.org/pdf/2505.02735v1",
    "published_date": "2025-05-05 15:37:00 UTC",
    "updated_date": "2025-05-05 15:37:00 UTC"
  },
  {
    "arxiv_id": "2505.02722v1",
    "title": "Enhancing LLMs' Clinical Reasoning with Real-World Data from a Nationwide Sepsis Registry",
    "authors": [
      "Junu Kim",
      "Chaeeun Shim",
      "Sungjin Park",
      "Su Yeon Lee",
      "Gee Young Suh",
      "Chae-Man Lim",
      "Seong Jin Choi",
      "Song Mi Moon",
      "Kyoung-Ho Song",
      "Eu Suk Kim",
      "Hong Bin Kim",
      "Sejoong Kim",
      "Chami Im",
      "Dong-Wan Kang",
      "Yong Soo Kim",
      "Hee-Joon Bae",
      "Sung Yoon Lim",
      "Han-Gil Jeong",
      "Edward Choi"
    ],
    "abstract": "Although large language models (LLMs) have demonstrated impressive reasoning\ncapabilities across general domains, their effectiveness in real-world clinical\npractice remains limited. This is likely due to their insufficient exposure to\nreal-world clinical data during training, as such data is typically not\nincluded due to privacy concerns. To address this, we propose enhancing the\nclinical reasoning capabilities of LLMs by leveraging real-world clinical data.\nWe constructed reasoning-intensive questions from a nationwide sepsis registry\nand fine-tuned Phi-4 on these questions using reinforcement learning, resulting\nin C-Reason. C-Reason exhibited strong clinical reasoning capabilities on the\nin-domain test set, as evidenced by both quantitative metrics and expert\nevaluations. Furthermore, its enhanced reasoning capabilities generalized to a\nsepsis dataset involving different tasks and patient cohorts, an open-ended\nconsultations on antibiotics use task, and other diseases. Future research\nshould focus on training LLMs with large-scale, multi-disease clinical datasets\nto develop more powerful, general-purpose clinical reasoning models.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02722v1",
    "published_date": "2025-05-05 15:23:47 UTC",
    "updated_date": "2025-05-05 15:23:47 UTC"
  },
  {
    "arxiv_id": "2505.05494v1",
    "title": "An Automated LLM-based Pipeline for Asset-Level Database Creation to Assess Deforestation Impact",
    "authors": [
      "Avanija Menon",
      "Ovidiu Serban"
    ],
    "abstract": "The European Union Deforestation Regulation (EUDR) requires companies to\nprove their products do not contribute to deforestation, creating a critical\ndemand for precise, asset-level environmental impact data. Current databases\nlack the necessary detail, relying heavily on broad financial metrics and\nmanual data collection, which limits regulatory compliance and accurate\nenvironmental modeling. This study presents an automated, end-to-end data\nextraction pipeline that uses LLMs to create, clean, and validate structured\ndatabases, specifically targeting sectors with a high risk of deforestation.\nThe pipeline introduces Instructional, Role-Based, Zero-Shot Chain-of-Thought\n(IRZ-CoT) prompting to enhance data extraction accuracy and a\nRetrieval-Augmented Validation (RAV) process that integrates real-time web\nsearches for improved data reliability. Applied to SEC EDGAR filings in the\nMining, Oil & Gas, and Utilities sectors, the pipeline demonstrates significant\nimprovements over traditional zero-shot prompting approaches, particularly in\nextraction accuracy and validation coverage. This work advances NLP-driven\nautomation for regulatory compliance, CSR (Corporate Social Responsibility),\nand ESG, with broad sectoral applicability.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.DB",
    "comment": "Accepted to ACL ClimateNLP 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.05494v1",
    "published_date": "2025-05-05 15:17:27 UTC",
    "updated_date": "2025-05-05 15:17:27 UTC"
  },
  {
    "arxiv_id": "2505.02712v1",
    "title": "Graph Neural Network-Based Reinforcement Learning for Controlling Biological Networks: The GATTACA Framework",
    "authors": [
      "Andrzej Mizera",
      "Jakub Zarzycki"
    ],
    "abstract": "Cellular reprogramming, the artificial transformation of one cell type into\nanother, has been attracting increasing research attention due to its\ntherapeutic potential for complex diseases. However, discovering reprogramming\nstrategies through classical wet-lab experiments is hindered by lengthy time\ncommitments and high costs. In this study, we explore the use of deep\nreinforcement learning (DRL) to control Boolean network models of complex\nbiological systems, such as gene regulatory networks and signalling pathway\nnetworks. We formulate a novel control problem for Boolean network models under\nthe asynchronous update mode in the context of cellular reprogramming. To\nfacilitate scalability, we consider our previously introduced concept of a\npseudo-attractor and we improve our procedure for effective identification of\npseudo-attractor states. Finally, we devise a computational framework to solve\nthe control problem. To leverage the structure of biological systems, we\nincorporate graph neural networks with graph convolutions into the artificial\nneural network approximator for the action-value function learned by the DRL\nagent. Experiments on a number of large real-world biological networks from\nliterature demonstrate the scalability and effectiveness of our approach.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.MN"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02712v1",
    "published_date": "2025-05-05 15:07:20 UTC",
    "updated_date": "2025-05-05 15:07:20 UTC"
  },
  {
    "arxiv_id": "2505.02709v1",
    "title": "Technical Report: Evaluating Goal Drift in Language Model Agents",
    "authors": [
      "Rauno Arike",
      "Elizabeth Donoway",
      "Henning Bartsch",
      "Marius Hobbhahn"
    ],
    "abstract": "As language models (LMs) are increasingly deployed as autonomous agents,\ntheir robust adherence to human-assigned objectives becomes crucial for safe\noperation. When these agents operate independently for extended periods without\nhuman oversight, even initially well-specified goals may gradually shift.\nDetecting and measuring goal drift - an agent's tendency to deviate from its\noriginal objective over time - presents significant challenges, as goals can\nshift gradually, causing only subtle behavioral changes. This paper proposes a\nnovel approach to analyzing goal drift in LM agents. In our experiments, agents\nare first explicitly given a goal through their system prompt, then exposed to\ncompeting objectives through environmental pressures. We demonstrate that while\nthe best-performing agent (a scaffolded version of Claude 3.5 Sonnet) maintains\nnearly perfect goal adherence for more than 100,000 tokens in our most\ndifficult evaluation setting, all evaluated models exhibit some degree of goal\ndrift. We also find that goal drift correlates with models' increasing\nsusceptibility to pattern-matching behaviors as the context length grows.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02709v1",
    "published_date": "2025-05-05 15:06:09 UTC",
    "updated_date": "2025-05-05 15:06:09 UTC"
  },
  {
    "arxiv_id": "2505.02707v1",
    "title": "Voila: Voice-Language Foundation Models for Real-Time Autonomous Interaction and Voice Role-Play",
    "authors": [
      "Yemin Shi",
      "Yu Shu",
      "Siwei Dong",
      "Guangyi Liu",
      "Jaward Sesay",
      "Jingwen Li",
      "Zhiting Hu"
    ],
    "abstract": "A voice AI agent that blends seamlessly into daily life would interact with\nhumans in an autonomous, real-time, and emotionally expressive manner. Rather\nthan merely reacting to commands, it would continuously listen, reason, and\nrespond proactively, fostering fluid, dynamic, and emotionally resonant\ninteractions. We introduce Voila, a family of large voice-language foundation\nmodels that make a step towards this vision. Voila moves beyond traditional\npipeline systems by adopting a new end-to-end architecture that enables\nfull-duplex, low-latency conversations while preserving rich vocal nuances such\nas tone, rhythm, and emotion. It achieves a response latency of just 195\nmilliseconds, surpassing the average human response time. Its hierarchical\nmulti-scale Transformer integrates the reasoning capabilities of large language\nmodels (LLMs) with powerful acoustic modeling, enabling natural, persona-aware\nvoice generation -- where users can simply write text instructions to define\nthe speaker's identity, tone, and other characteristics. Moreover, Voila\nsupports over one million pre-built voices and efficient customization of new\nones from brief audio samples as short as 10 seconds. Beyond spoken dialogue,\nVoila is designed as a unified model for a wide range of voice-based\napplications, including automatic speech recognition (ASR), Text-to-Speech\n(TTS), and, with minimal adaptation, multilingual speech translation. Voila is\nfully open-sourced to support open research and accelerate progress toward\nnext-generation human-machine interactions.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.SD"
    ],
    "primary_category": "cs.AI",
    "comment": "18 pages, 7 figures, Website: https://voila.maitrix.org",
    "pdf_url": "http://arxiv.org/pdf/2505.02707v1",
    "published_date": "2025-05-05 15:05:01 UTC",
    "updated_date": "2025-05-05 15:05:01 UTC"
  },
  {
    "arxiv_id": "2505.02694v1",
    "title": "AI Standardized Patient Improves Human Conversations in Advanced Cancer Care",
    "authors": [
      "Kurtis Haut",
      "Masum Hasan",
      "Thomas Carroll",
      "Ronald Epstein",
      "Taylan Sen",
      "Ehsan Hoque"
    ],
    "abstract": "Serious illness communication (SIC) in end-of-life care faces challenges such\nas emotional stress, cultural barriers, and balancing hope with honesty.\nDespite its importance, one of the few available ways for clinicians to\npractice SIC is with standardized patients, which is expensive, time-consuming,\nand inflexible. In this paper, we present SOPHIE, an AI-powered standardized\npatient simulation and automated feedback system. SOPHIE combines large\nlanguage models (LLMs), a lifelike virtual avatar, and automated, personalized\nfeedback based on clinical literature to provide remote, on-demand SIC\ntraining. In a randomized control study with healthcare students and\nprofessionals, SOPHIE users demonstrated significant improvement across three\ncritical SIC domains: Empathize, Be Explicit, and Empower. These results\nsuggest that AI-driven tools can enhance complex interpersonal communication\nskills, offering scalable, accessible solutions to address a critical gap in\nclinician education.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "20 pages, 6 figures, 4 tables, submitting to New England Journal of\n  Medicine (NEJM)",
    "pdf_url": "http://arxiv.org/pdf/2505.02694v1",
    "published_date": "2025-05-05 14:44:17 UTC",
    "updated_date": "2025-05-05 14:44:17 UTC"
  },
  {
    "arxiv_id": "2505.02884v1",
    "title": "Unlearning vs. Obfuscation: Are We Truly Removing Knowledge?",
    "authors": [
      "Guangzhi Sun",
      "Potsawee Manakul",
      "Xiao Zhan",
      "Mark Gales"
    ],
    "abstract": "Unlearning has emerged as a critical capability for large language models\n(LLMs) to support data privacy, regulatory compliance, and ethical AI\ndeployment. Recent techniques often rely on obfuscation by injecting incorrect\nor irrelevant information to suppress knowledge. Such methods effectively\nconstitute knowledge addition rather than true removal, often leaving models\nvulnerable to probing. In this paper, we formally distinguish unlearning from\nobfuscation and introduce a probing-based evaluation framework to assess\nwhether existing approaches genuinely remove targeted information. Moreover, we\npropose DF-MCQ, a novel unlearning method that flattens the model predictive\ndistribution over automatically generated multiple-choice questions using\nKL-divergence, effectively removing knowledge about target individuals and\ntriggering appropriate refusal behaviour. Experimental results demonstrate that\nDF-MCQ achieves unlearning with over 90% refusal rate and a random choice-level\nuncertainty that is much higher than obfuscation on probing questions.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02884v1",
    "published_date": "2025-05-05 14:21:08 UTC",
    "updated_date": "2025-05-05 14:21:08 UTC"
  },
  {
    "arxiv_id": "2505.02665v2",
    "title": "A Survey of Slow Thinking-based Reasoning LLMs using Reinforced Learning and Inference-time Scaling Law",
    "authors": [
      "Qianjun Pan",
      "Wenkai Ji",
      "Yuyang Ding",
      "Junsong Li",
      "Shilian Chen",
      "Junyi Wang",
      "Jie Zhou",
      "Qin Chen",
      "Min Zhang",
      "Yulan Wu",
      "Liang He"
    ],
    "abstract": "This survey explores recent advancements in reasoning large language models\n(LLMs) designed to mimic \"slow thinking\" - a reasoning process inspired by\nhuman cognition, as described in Kahneman's Thinking, Fast and Slow. These\nmodels, like OpenAI's o1, focus on scaling computational resources dynamically\nduring complex tasks, such as math reasoning, visual reasoning, medical\ndiagnosis, and multi-agent debates. We present the development of reasoning\nLLMs and list their key technologies. By synthesizing over 100 studies, it\ncharts a path toward LLMs that combine human-like deep thinking with scalable\nefficiency for reasoning. The review breaks down methods into three categories:\n(1) test-time scaling dynamically adjusts computation based on task complexity\nvia search and sampling, dynamic verification; (2) reinforced learning refines\ndecision-making through iterative improvement leveraging policy networks,\nreward models, and self-evolution strategies; and (3) slow-thinking frameworks\n(e.g., long CoT, hierarchical processes) that structure problem-solving with\nmanageable steps. The survey highlights the challenges and further directions\nof this domain. Understanding and advancing the reasoning abilities of LLMs is\ncrucial for unlocking their full potential in real-world applications, from\nscientific discovery to decision support systems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02665v2",
    "published_date": "2025-05-05 14:14:59 UTC",
    "updated_date": "2025-05-08 05:27:18 UTC"
  },
  {
    "arxiv_id": "2505.02659v2",
    "title": "A Note on Statistically Accurate Tabular Data Generation Using Large Language Models",
    "authors": [
      "Andrey Sidorenko"
    ],
    "abstract": "Large language models (LLMs) have shown promise in synthetic tabular data\ngeneration, yet existing methods struggle to preserve complex feature\ndependencies, particularly among categorical variables. This work introduces a\nprobability-driven prompting approach that leverages LLMs to estimate\nconditional distributions, enabling more accurate and scalable data synthesis.\nThe results highlight the potential of prompting probability distributions to\nenhance the statistical fidelity of LLM-generated tabular data.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02659v2",
    "published_date": "2025-05-05 14:05:15 UTC",
    "updated_date": "2025-05-06 08:34:46 UTC"
  },
  {
    "arxiv_id": "2505.02655v1",
    "title": "SCFormer: Structured Channel-wise Transformer with Cumulative Historical State for Multivariate Time Series Forecasting",
    "authors": [
      "Shiwei Guo",
      "Ziang Chen",
      "Yupeng Ma",
      "Yunfei Han",
      "Yi Wang"
    ],
    "abstract": "The Transformer model has shown strong performance in multivariate time\nseries forecasting by leveraging channel-wise self-attention. However, this\napproach lacks temporal constraints when computing temporal features and does\nnot utilize cumulative historical series effectively.To address these\nlimitations, we propose the Structured Channel-wise Transformer with Cumulative\nHistorical state (SCFormer). SCFormer introduces temporal constraints to all\nlinear transformations, including the query, key, and value matrices, as well\nas the fully connected layers within the Transformer. Additionally, SCFormer\nemploys High-order Polynomial Projection Operators (HiPPO) to deal with\ncumulative historical time series, allowing the model to incorporate\ninformation beyond the look-back window during prediction. Extensive\nexperiments on multiple real-world datasets demonstrate that SCFormer\nsignificantly outperforms mainstream baselines, highlighting its effectiveness\nin enhancing time series forecasting. The code is publicly available at\nhttps://github.com/ShiweiGuo1995/SCFormer",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02655v1",
    "published_date": "2025-05-05 13:59:55 UTC",
    "updated_date": "2025-05-05 13:59:55 UTC"
  },
  {
    "arxiv_id": "2505.02649v1",
    "title": "Eye Movements as Indicators of Deception: A Machine Learning Approach",
    "authors": [
      "Valentin Foucher",
      "Santiago de Leon-Martinez",
      "Robert Moro"
    ],
    "abstract": "Gaze may enhance the robustness of lie detectors but remains under-studied.\nThis study evaluated the efficacy of AI models (using fixations, saccades,\nblinks, and pupil size) for detecting deception in Concealed Information Tests\nacross two datasets. The first, collected with Eyelink 1000, contains gaze data\nfrom a computerized experiment where 87 participants revealed, concealed, or\nfaked the value of a previously selected card. The second, collected with Pupil\nNeon, involved 36 participants performing a similar task but facing an\nexperimenter. XGBoost achieved accuracies up to 74% in a binary classification\ntask (Revealing vs. Concealing) and 49% in a more challenging\nthree-classification task (Revealing vs. Concealing vs. Faking). Feature\nanalysis identified saccade number, duration, amplitude, and maximum pupil size\nas the most important for deception prediction. These results demonstrate the\nfeasibility of using gaze and AI to enhance lie detectors and encourage future\nresearch that may improve on this.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02649v1",
    "published_date": "2025-05-05 13:50:12 UTC",
    "updated_date": "2025-05-05 13:50:12 UTC"
  },
  {
    "arxiv_id": "2505.03846v1",
    "title": "GAME: Learning Multimodal Interactions via Graph Structures for Personality Trait Estimation",
    "authors": [
      "Kangsheng Wang",
      "Yuhang Li",
      "Chengwei Ye",
      "Yufei Lin",
      "Huanzhen Zhang",
      "Bohan Hu",
      "Linuo Xu",
      "Shuyan Liu"
    ],
    "abstract": "Apparent personality analysis from short videos poses significant chal-lenges\ndue to the complex interplay of visual, auditory, and textual cues. In this\npaper, we propose GAME, a Graph-Augmented Multimodal Encoder designed to\nrobustly model and fuse multi-source features for automatic personality\nprediction. For the visual stream, we construct a facial graph and introduce a\ndual-branch Geo Two-Stream Network, which combines Graph Convolutional Networks\n(GCNs) and Convolutional Neural Net-works (CNNs) with attention mechanisms to\ncapture both structural and appearance-based facial cues. Complementing this,\nglobal context and iden-tity features are extracted using pretrained ResNet18\nand VGGFace back-bones. To capture temporal dynamics, frame-level features are\nprocessed by a BiGRU enhanced with temporal attention modules. Meanwhile, audio\nrepresentations are derived from the VGGish network, and linguistic se-mantics\nare captured via the XLM-Roberta transformer. To achieve effective multimodal\nintegration, we propose a Channel Attention-based Fusion module, followed by a\nMulti-Layer Perceptron (MLP) regression head for predicting personality traits.\nExtensive experiments show that GAME con-sistently outperforms existing methods\nacross multiple benchmarks, vali-dating its effectiveness and generalizability.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.03846v1",
    "published_date": "2025-05-05 13:48:09 UTC",
    "updated_date": "2025-05-05 13:48:09 UTC"
  },
  {
    "arxiv_id": "2505.02640v1",
    "title": "Adaptive Budgeted Multi-Armed Bandits for IoT with Dynamic Resource Constraints",
    "authors": [
      "Shubham Vaishnav",
      "Praveen Kumar Donta",
      "Sindri MagnÃºsson"
    ],
    "abstract": "Internet of Things (IoT) systems increasingly operate in environments where\ndevices must respond in real time while managing fluctuating resource\nconstraints, including energy and bandwidth. Yet, current approaches often fall\nshort in addressing scenarios where operational constraints evolve over time.\nTo address these limitations, we propose a novel Budgeted Multi-Armed Bandit\nframework tailored for IoT applications with dynamic operational limits. Our\nmodel introduces a decaying violation budget, which permits limited constraint\nviolations early in the learning process and gradually enforces stricter\ncompliance over time. We present the Budgeted Upper Confidence Bound (UCB)\nalgorithm, which adaptively balances performance optimization and compliance\nwith time-varying constraints. We provide theoretical guarantees showing that\nBudgeted UCB achieves sublinear regret and logarithmic constraint violations\nover the learning horizon. Extensive simulations in a wireless communication\nsetting show that our approach achieves faster adaptation and better constraint\nsatisfaction than standard online learning methods. These results highlight the\nframework's potential for building adaptive, resource-aware IoT systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02640v1",
    "published_date": "2025-05-05 13:33:39 UTC",
    "updated_date": "2025-05-05 13:33:39 UTC"
  },
  {
    "arxiv_id": "2505.02639v1",
    "title": "Enhancing Chemical Reaction and Retrosynthesis Prediction with Large Language Model and Dual-task Learning",
    "authors": [
      "Xuan Lin",
      "Qingrui Liu",
      "Hongxin Xiang",
      "Daojian Zeng",
      "Xiangxiang Zeng"
    ],
    "abstract": "Chemical reaction and retrosynthesis prediction are fundamental tasks in drug\ndiscovery. Recently, large language models (LLMs) have shown potential in many\ndomains. However, directly applying LLMs to these tasks faces two major\nchallenges: (i) lacking a large-scale chemical synthesis-related instruction\ndataset; (ii) ignoring the close correlation between reaction and\nretrosynthesis prediction for the existing fine-tuning strategies. To address\nthese challenges, we propose ChemDual, a novel LLM framework for accurate\nchemical synthesis. Specifically, considering the high cost of data acquisition\nfor reaction and retrosynthesis, ChemDual regards the\nreaction-and-retrosynthesis of molecules as a related\nrecombination-and-fragmentation process and constructs a large-scale of 4.4\nmillion instruction dataset. Furthermore, ChemDual introduces an enhanced\nLLaMA, equipped with a multi-scale tokenizer and dual-task learning strategy,\nto jointly optimize the process of recombination and fragmentation as well as\nthe tasks between reaction and retrosynthesis prediction. Extensive experiments\non Mol-Instruction and USPTO-50K datasets demonstrate that ChemDual achieves\nstate-of-the-art performance in both predictions of reaction and\nretrosynthesis, outperforming the existing conventional single-task approaches\nand the general open-source LLMs. Through molecular docking analysis, ChemDual\ngenerates compounds with diverse and strong protein binding affinity, further\nhighlighting its strong potential in drug design.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted for publication at IJCAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.02639v1",
    "published_date": "2025-05-05 13:31:36 UTC",
    "updated_date": "2025-05-05 13:31:36 UTC"
  },
  {
    "arxiv_id": "2505.02627v1",
    "title": "A Theoretical Analysis of Compositional Generalization in Neural Networks: A Necessary and Sufficient Condition",
    "authors": [
      "Yuanpeng Li"
    ],
    "abstract": "Compositional generalization is a crucial property in artificial\nintelligence, enabling models to handle novel combinations of known components.\nWhile most deep learning models lack this capability, certain models succeed in\nspecific tasks, suggesting the existence of governing conditions. This paper\nderives a necessary and sufficient condition for compositional generalization\nin neural networks. Conceptually, it requires that (i) the computational graph\nmatches the true compositional structure, and (ii) components encode just\nenough information in training. The condition is supported by mathematical\nproofs. This criterion combines aspects of architecture design, regularization,\nand training data properties. A carefully designed minimal example illustrates\nan intuitive understanding of the condition. We also discuss the potential of\nthe condition for assessing compositional generalization before training. This\nwork is a fundamental theoretical study of compositional generalization in\nneural networks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02627v1",
    "published_date": "2025-05-05 13:13:46 UTC",
    "updated_date": "2025-05-05 13:13:46 UTC"
  },
  {
    "arxiv_id": "2505.02625v1",
    "title": "LLaMA-Omni2: LLM-based Real-time Spoken Chatbot with Autoregressive Streaming Speech Synthesis",
    "authors": [
      "Qingkai Fang",
      "Yan Zhou",
      "Shoutao Guo",
      "Shaolei Zhang",
      "Yang Feng"
    ],
    "abstract": "Real-time, intelligent, and natural speech interaction is an essential part\nof the next-generation human-computer interaction. Recent advancements have\nshowcased the potential of building intelligent spoken chatbots based on large\nlanguage models (LLMs). In this paper, we introduce LLaMA-Omni 2, a series of\nspeech language models (SpeechLMs) ranging from 0.5B to 14B parameters, capable\nof achieving high-quality real-time speech interaction. LLaMA-Omni 2 is built\nupon the Qwen2.5 series models, integrating a speech encoder and an\nautoregressive streaming speech decoder. Despite being trained on only 200K\nmulti-turn speech dialogue samples, LLaMA-Omni 2 demonstrates strong\nperformance on several spoken question answering and speech instruction\nfollowing benchmarks, surpassing previous state-of-the-art SpeechLMs like\nGLM-4-Voice, which was trained on millions of hours of speech data.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "Preprint. Project: https://github.com/ictnlp/LLaMA-Omni2",
    "pdf_url": "http://arxiv.org/pdf/2505.02625v1",
    "published_date": "2025-05-05 12:53:09 UTC",
    "updated_date": "2025-05-05 12:53:09 UTC"
  },
  {
    "arxiv_id": "2505.02609v1",
    "title": "Study of the influence of a biased database on the prediction of standard algorithms for selecting the best candidate for an interview",
    "authors": [
      "Shuyu Wang",
      "AngÃ©lique Saillet",
      "PhilomÃ¨ne Le Gall",
      "Alain Lacroux",
      "Christelle Martin-Lacroux",
      "Vincent Brault"
    ],
    "abstract": "Artificial intelligence is used at various stages of the recruitment process\nto automatically select the best candidate for a position, with companies\nguaranteeing unbiased recruitment. However, the algorithms used are either\ntrained by humans or are based on learning from past experiences that were\nbiased. In this article, we propose to generate data mimicking external\n(discrimination) and internal biases (self-censorship) in order to train five\nclassic algorithms and to study the extent to which they do or do not find the\nbest candidates according to objective criteria. In addition, we study the\ninfluence of the anonymisation of files on the quality of predictions.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "stat.AP",
      "stat.ME"
    ],
    "primary_category": "cs.AI",
    "comment": "38 pages, 25 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2505.02609v1",
    "published_date": "2025-05-05 12:24:31 UTC",
    "updated_date": "2025-05-05 12:24:31 UTC"
  },
  {
    "arxiv_id": "2505.02581v3",
    "title": "Neurodivergent Influenceability as a Contingent Solution to the AI Alignment Problem",
    "authors": [
      "Alberto HernÃ¡ndez-Espinosa",
      "Felipe S. AbrahÃ£o",
      "Olaf Witkowski",
      "Hector Zenil"
    ],
    "abstract": "The AI alignment problem, which focusses on ensuring that artificial\nintelligence (AI), including AGI and ASI, systems act according to human\nvalues, presents profound challenges. With the progression from narrow AI to\nArtificial General Intelligence (AGI) and Superintelligence, fears about\ncontrol and existential risk have escalated. Here, we investigate whether\nembracing inevitable AI misalignment can be a contingent strategy to foster a\ndynamic ecosystem of competing agents as a viable path to steer them in more\nhuman-aligned trends and mitigate risks. We explore how misalignment may serve\nand should be promoted as a counterbalancing mechanism to team up with\nwhichever agents are most aligned to human interests, ensuring that no single\nsystem dominates destructively. The main premise of our contribution is that\nmisalignment is inevitable because full AI-human alignment is a mathematical\nimpossibility from Turing-complete systems, which we also offer as a proof in\nthis contribution, a feature then inherited to AGI and ASI systems. We\nintroduce a change-of-opinion attack test based on perturbation and\nintervention analysis to study how humans and agents may change or neutralise\nfriendly and unfriendly AIs through cooperation and competition. We show that\nopen models are more diverse and that most likely guardrails implemented in\nproprietary models are successful at controlling some of the agents' range of\nbehaviour with positive and negative consequences while closed systems are more\nsteerable and can also be used against proprietary AI systems. We also show\nthat human and AI intervention has different effects hence suggesting multiple\nstrategies.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "44 pages",
    "pdf_url": "http://arxiv.org/pdf/2505.02581v3",
    "published_date": "2025-05-05 11:33:18 UTC",
    "updated_date": "2025-05-15 01:23:57 UTC"
  },
  {
    "arxiv_id": "2505.02579v2",
    "title": "EMORL: Ensemble Multi-Objective Reinforcement Learning for Efficient and Flexible LLM Fine-Tuning",
    "authors": [
      "Lingxiao Kong",
      "Cong Yang",
      "Susanne Neufang",
      "Oya Deniz Beyan",
      "Zeyd Boukhers"
    ],
    "abstract": "Recent advances in reinforcement learning (RL) for large language model (LLM)\nfine-tuning show promise in addressing multi-objective tasks but still face\nsignificant challenges, including complex objective balancing, low training\nefficiency, poor scalability, and limited explainability. Leveraging ensemble\nlearning principles, we introduce an Ensemble Multi-Objective RL (EMORL)\nframework that fine-tunes multiple models with individual objectives while\noptimizing their aggregation after the training to improve efficiency and\nflexibility. Our method is the first to aggregate the last hidden states of\nindividual models, incorporating contextual information from multiple\nobjectives. This approach is supported by a hierarchical grid search algorithm\nthat identifies optimal weighted combinations. We evaluate EMORL on counselor\nreflection generation tasks, using text-scoring LLMs to evaluate the\ngenerations and provide rewards during RL fine-tuning. Through comprehensive\nexperiments on the PAIR and Psych8k datasets, we demonstrate the advantages of\nEMORL against existing baselines: significantly lower and more stable training\nconsumption ($17,529\\pm 1,650$ data points and $6,573\\pm 147.43$ seconds),\nimproved scalability and explainability, and comparable performance across\nmultiple objectives.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "13 pages, 9 figures, submitted to SIGDIAL 2025 conference",
    "pdf_url": "http://arxiv.org/pdf/2505.02579v2",
    "published_date": "2025-05-05 11:30:46 UTC",
    "updated_date": "2025-05-06 06:26:11 UTC"
  },
  {
    "arxiv_id": "2505.02576v1",
    "title": "Recursive Decomposition with Dependencies for Generic Divide-and-Conquer Reasoning",
    "authors": [
      "Sergio HernÃ¡ndez-GutiÃ©rrez",
      "Minttu Alakuijala",
      "Alexander V. Nikitin",
      "Pekka Marttinen"
    ],
    "abstract": "Reasoning tasks are crucial in many domains, especially in science and\nengineering. Although large language models (LLMs) have made progress in\nreasoning tasks using techniques such as chain-of-thought and least-to-most\nprompting, these approaches still do not effectively scale to complex problems\nin either their performance or execution time. Moreover, they often require\nadditional supervision for each new task, such as in-context examples. In this\nwork, we introduce Recursive Decomposition with Dependencies (RDD), a scalable\ndivide-and-conquer method for solving reasoning problems that requires less\nsupervision than prior approaches. Our method can be directly applied to a new\nproblem class even in the absence of any task-specific guidance. Furthermore,\nRDD supports sub-task dependencies, allowing for ordered execution of\nsub-tasks, as well as an error recovery mechanism that can correct mistakes\nmade in previous steps. We evaluate our approach on two benchmarks with six\ndifficulty levels each and in two in-context settings: one with task-specific\nexamples and one without. Our results demonstrate that RDD outperforms other\nmethods in a compute-matched setting as task complexity increases, while also\nbeing more computationally efficient.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02576v1",
    "published_date": "2025-05-05 11:24:20 UTC",
    "updated_date": "2025-05-05 11:24:20 UTC"
  },
  {
    "arxiv_id": "2505.02573v1",
    "title": "Rethinking Federated Graph Learning: A Data Condensation Perspective",
    "authors": [
      "Hao Zhang",
      "Xunkai Li",
      "Yinlin Zhu",
      "Lianglin Hu"
    ],
    "abstract": "Federated graph learning is a widely recognized technique that promotes\ncollaborative training of graph neural networks (GNNs) by multi-client\ngraphs.However, existing approaches heavily rely on the communication of model\nparameters or gradients for federated optimization and fail to adequately\naddress the data heterogeneity introduced by intricate and diverse graph\ndistributions. Although some methods attempt to share additional messages among\nthe server and clients to improve federated convergence during communication,\nthey introduce significant privacy risks and increase communication overhead.\nTo address these issues, we introduce the concept of a condensed graph as a\nnovel optimization carrier to address FGL data heterogeneity and propose a new\nFGL paradigm called FedGM. Specifically, we utilize a generalized condensation\ngraph consensus to aggregate comprehensive knowledge from distributed graphs,\nwhile minimizing communication costs and privacy risks through a single\ntransmission of the condensed data. Extensive experiments on six public\ndatasets consistently demonstrate the superiority of FedGM over\nstate-of-the-art baselines, highlighting its potential for a novel FGL\nparadigm.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DB",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02573v1",
    "published_date": "2025-05-05 11:23:29 UTC",
    "updated_date": "2025-05-05 11:23:29 UTC"
  },
  {
    "arxiv_id": "2505.02566v1",
    "title": "Robustness questions the interpretability of graph neural networks: what to do?",
    "authors": [
      "Kirill Lukyanov",
      "Georgii Sazonov",
      "Serafim Boyarsky",
      "Ilya Makarov"
    ],
    "abstract": "Graph Neural Networks (GNNs) have become a cornerstone in graph-based data\nanalysis, with applications in diverse domains such as bioinformatics, social\nnetworks, and recommendation systems. However, the interplay between model\ninterpretability and robustness remains poorly understood, especially under\nadversarial scenarios like poisoning and evasion attacks. This paper presents a\ncomprehensive benchmark to systematically analyze the impact of various factors\non the interpretability of GNNs, including the influence of\nrobustness-enhancing defense mechanisms.\n  We evaluate six GNN architectures based on GCN, SAGE, GIN, and GAT across\nfive datasets from two distinct domains, employing four interpretability\nmetrics: Fidelity, Stability, Consistency, and Sparsity. Our study examines how\ndefenses against poisoning and evasion attacks, applied before and during model\ntraining, affect interpretability and highlights critical trade-offs between\nrobustness and interpretability. The framework will be published as open\nsource.\n  The results reveal significant variations in interpretability depending on\nthe chosen defense methods and model architecture characteristics. By\nestablishing a standardized benchmark, this work provides a foundation for\ndeveloping GNNs that are both robust to adversarial threats and interpretable,\nfacilitating trust in their deployment in sensitive applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02566v1",
    "published_date": "2025-05-05 11:14:56 UTC",
    "updated_date": "2025-05-05 11:14:56 UTC"
  },
  {
    "arxiv_id": "2505.03845v1",
    "title": "A Deep Learning approach for Depressive Symptoms assessment in Parkinson's disease patients using facial videos",
    "authors": [
      "Ioannis Kyprakis",
      "Vasileios Skaramagkas",
      "Iro Boura",
      "Georgios Karamanis",
      "Dimitrios I. Fotiadis",
      "Zinovia Kefalopoulou",
      "Cleanthe Spanaki",
      "Manolis Tsiknakis"
    ],
    "abstract": "Parkinson's disease (PD) is a neurodegenerative disorder, manifesting with\nmotor and non-motor symptoms. Depressive symptoms are prevalent in PD,\naffecting up to 45% of patients. They are often underdiagnosed due to\noverlapping motor features, such as hypomimia. This study explores deep\nlearning (DL) models-ViViT, Video Swin Tiny, and 3D CNN-LSTM with attention\nlayers-to assess the presence and severity of depressive symptoms, as detected\nby the Geriatric Depression Scale (GDS), in PD patients through facial video\nanalysis. The same parameters were assessed in a secondary analysis taking into\naccount whether patients were one hour after (ON-medication state) or 12 hours\nwithout (OFF-medication state) dopaminergic medication. Using a dataset of\n1,875 videos from 178 patients, the Video Swin Tiny model achieved the highest\nperformance, with up to 94% accuracy and 93.7% F1-score in binary\nclassification (presence of absence of depressive symptoms), and 87.1% accuracy\nwith an 85.4% F1-score in multiclass tasks (absence or mild or severe\ndepressive symptoms).",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.03845v1",
    "published_date": "2025-05-05 10:58:39 UTC",
    "updated_date": "2025-05-05 10:58:39 UTC"
  },
  {
    "arxiv_id": "2505.02550v2",
    "title": "Bielik v3 Small: Technical Report",
    "authors": [
      "Krzysztof Ociepa",
      "Åukasz Flis",
      "Remigiusz Kinas",
      "Krzysztof WrÃ³bel",
      "Adrian GwoÅºdziej"
    ],
    "abstract": "We introduce Bielik v3, a series of parameter-efficient generative text\nmodels (1.5B and 4.5B) optimized for Polish language processing. These models\ndemonstrate that smaller, well-optimized architectures can achieve performance\ncomparable to much larger counterparts while requiring substantially fewer\ncomputational resources. Our approach incorporates several key innovations: a\ncustom Polish tokenizer (APT4) that significantly improves token efficiency,\nWeighted Instruction Cross-Entropy Loss to balance learning across instruction\ntypes, and Adaptive Learning Rate that dynamically adjusts based on training\nprogress. Trained on a meticulously curated corpus of 292 billion tokens\nspanning 303 million documents, these models excel across multiple benchmarks,\nincluding the Open PL LLM Leaderboard, Complex Polish Text Understanding\nBenchmark, Polish EQ-Bench, and Polish Medical Leaderboard. The 4.5B parameter\nmodel achieves results competitive with models 2-3 times its size, while the\n1.5B model delivers strong performance despite its extremely compact profile.\nThese advances establish new benchmarks for parameter-efficient language\nmodeling in less-represented languages, making high-quality Polish language AI\nmore accessible for resource-constrained applications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "68T50",
      "I.2.7"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02550v2",
    "published_date": "2025-05-05 10:39:51 UTC",
    "updated_date": "2025-05-08 22:57:46 UTC"
  },
  {
    "arxiv_id": "2505.02540v1",
    "title": "Lazy But Effective: Collaborative Personalized Federated Learning with Heterogeneous Data",
    "authors": [
      "Ljubomir Rokvic",
      "Panayiotis Danassis",
      "Boi Faltings"
    ],
    "abstract": "In Federated Learning, heterogeneity in client data distributions often means\nthat a single global model does not have the best performance for individual\nclients. Consider for example training a next-word prediction model for\nkeyboards: user-specific language patterns due to demographics (dialect, age,\netc.), language proficiency, and writing style result in a highly non-IID\ndataset across clients. Other examples are medical images taken with different\nmachines, or driving data from different vehicle types. To address this, we\npropose a simple yet effective personalized federated learning framework\n(pFedLIA) that utilizes a computationally efficient influence approximation,\ncalled `Lazy Influence', to cluster clients in a distributed manner before\nmodel aggregation. Within each cluster, data owners collaborate to jointly\ntrain a model that captures the specific data patterns of the clients. Our\nmethod has been shown to successfully recover the global model's performance\ndrop due to the non-IID-ness in various synthetic and real-world settings,\nspecifically a next-word prediction task on the Nordic languages as well as\nseveral benchmark tasks. It matches the performance of a hypothetical Oracle\nclustering, and significantly improves on existing baselines, e.g., an\nimprovement of 17% on CIFAR100.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at the International Joint Conference on Neural Networks\n  (IJCNN), IEEE, 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.02540v1",
    "published_date": "2025-05-05 10:26:35 UTC",
    "updated_date": "2025-05-05 10:26:35 UTC"
  },
  {
    "arxiv_id": "2505.02537v2",
    "title": "Advancing Constrained Monotonic Neural Networks: Achieving Universal Approximation Beyond Bounded Activations",
    "authors": [
      "Davide Sartor",
      "Alberto Sinigaglia",
      "Gian Antonio Susto"
    ],
    "abstract": "Conventional techniques for imposing monotonicity in MLPs by construction\ninvolve the use of non-negative weight constraints and bounded activation\nfunctions, which pose well-known optimization challenges. In this work, we\ngeneralize previous theoretical results, showing that MLPs with non-negative\nweight constraint and activations that saturate on alternating sides are\nuniversal approximators for monotonic functions. Additionally, we show an\nequivalence between the saturation side in the activations and the sign of the\nweight constraint. This connection allows us to prove that MLPs with convex\nmonotone activations and non-positive constrained weights also qualify as\nuniversal approximators, in contrast to their non-negative constrained\ncounterparts. Our results provide theoretical grounding to the empirical\neffectiveness observed in previous works while leading to possible\narchitectural simplification. Moreover, to further alleviate the optimization\ndifficulties, we propose an alternative formulation that allows the network to\nadjust its activations according to the sign of the weights. This eliminates\nthe requirement for weight reparameterization, easing initialization and\nimproving training stability. Experimental evaluation reinforces the validity\nof the theoretical results, showing that our novel approach compares favourably\nto traditional monotonic architectures.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "International Conference on Machine Learning",
    "pdf_url": "http://arxiv.org/pdf/2505.02537v2",
    "published_date": "2025-05-05 10:18:48 UTC",
    "updated_date": "2025-05-06 11:45:55 UTC"
  },
  {
    "arxiv_id": "2505.02533v1",
    "title": "Large Language Model Partitioning for Low-Latency Inference at the Edge",
    "authors": [
      "Dimitrios Kafetzis",
      "Ramin Khalili",
      "Iordanis Koutsopoulos"
    ],
    "abstract": "Large Language Models (LLMs) based on autoregressive, decoder-only\nTransformers generate text one token at a time, where a token represents a\ndiscrete unit of text. As each newly produced token is appended to the partial\noutput sequence, the length grows and so does the memory and compute load, due\nto the expanding key-value caches, which store intermediate representations of\nall previously generated tokens in the multi-head attention (MHA) layer. As\nthis iterative process steadily increases memory and compute demands,\nlayer-based partitioning in resource-constrained edge environments often\nresults in memory overload or high inference latency. To address this and\nreduce inference latency, we propose a resource-aware Transformer architecture\npartitioning algorithm, where the partitioning decision is updated at regular\nintervals during token generation. The approach is myopic in that it is based\non instantaneous information about device resource availability and network\nlink bandwidths. When first executed, the algorithm places blocks on devices,\nand in later executions, it migrates these blocks among devices so that the sum\nof migration delay and inference delay remains low. Our approach partitions the\ndecoder at the attention head level, co-locating each attention head with its\nkey-value cache and allowing dynamic migrations whenever resources become\ntight. By allocating different attention heads to different devices, we exploit\nparallel execution of attention heads and thus achieve substantial reductions\nin inference delays. Our experiments show that in small-scale settings (3-5\ndevices), the proposed method achieves within 15 to 20 percent of an exact\noptimal solver's latency, while in larger-scale tests it achieves notable\nimprovements in inference speed and memory usage compared to state-of-the-art\nlayer-based partitioning approaches.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02533v1",
    "published_date": "2025-05-05 10:16:16 UTC",
    "updated_date": "2025-05-05 10:16:16 UTC"
  },
  {
    "arxiv_id": "2505.07839v1",
    "title": "Sub-diffraction terahertz backpropagation compressive imaging",
    "authors": [
      "Yongsheng Zhu",
      "Shaojing Liu",
      "Ximiao Wang",
      "Runli Li",
      "Haili Yang",
      "Jiali Wang",
      "Hongjia Zhu",
      "Yanlin Ke",
      "Ningsheng Xu",
      "Huanjun Chen",
      "Shaozhi Deng"
    ],
    "abstract": "Terahertz single-pixel imaging (TSPI) has garnered significant attention due\nto its simplicity and cost-effectiveness. However, the relatively long\nwavelength of THz waves limits sub-diffraction-scale imaging resolution.\nAlthough TSPI technique can achieve sub-wavelength resolution, it requires\nharsh experimental conditions and time-consuming processes. Here, we propose a\nsub-diffraction THz backpropagation compressive imaging technique. We\nilluminate the object with monochromatic continuous-wave THz radiation. The\ntransmitted THz wave is modulated by prearranged patterns generated on the back\nsurface of a 500-{\\mu}m-thick silicon wafer, realized through photoexcited\ncarriers using a 532-nm laser. The modulated THz wave is then recorded by a\nsingle-element detector. An untrained neural network is employed to iteratively\nreconstruct the object image with an ultralow compression ratio of 1.5625%\nunder a physical model constraint, thus reducing the long sampling times. To\nfurther suppress the diffraction-field effects, embedded with the angular\nspectrum propagation (ASP) theory to model the diffraction of THz waves during\npropagation, the network retrieves near-field information from the object,\nenabling sub-diffraction imaging with a spatial resolution of ~{\\lambda}0/7\n({\\lambda}0 = 833.3 {\\mu}m at 0.36 THz) and eliminating the need for ultrathin\nphotomodulators. This approach provides an efficient solution for advancing THz\nmicroscopic imaging and addressing other inverse imaging challenges.",
    "categories": [
      "eess.IV",
      "cs.AI"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.07839v1",
    "published_date": "2025-05-05 09:59:13 UTC",
    "updated_date": "2025-05-05 09:59:13 UTC"
  },
  {
    "arxiv_id": "2505.02516v1",
    "title": "Machine-Learning-Powered Neural Interfaces for Smart Prosthetics and Diagnostics",
    "authors": [
      "MohammadAli Shaeri",
      "Jinhan Liu",
      "Mahsa Shoaran"
    ],
    "abstract": "Advanced neural interfaces are transforming applications ranging from\nneuroscience research to diagnostic tools (for mental state recognition, tremor\nand seizure detection) as well as prosthetic devices (for motor and\ncommunication recovery). By integrating complex functions into miniaturized\nneural devices, these systems unlock significant opportunities for personalized\nassistive technologies and adaptive therapeutic interventions. Leveraging\nhigh-density neural recordings, on-site signal processing, and machine learning\n(ML), these interfaces extract critical features, identify disease\nneuro-markers, and enable accurate, low-latency neural decoding. This\nintegration facilitates real-time interpretation of neural signals, adaptive\nmodulation of brain activity, and efficient control of assistive devices.\nMoreover, the synergy between neural interfaces and ML has paved the way for\nself-sufficient, ubiquitous platforms capable of operating in diverse\nenvironments with minimal hardware costs and external dependencies. In this\nwork, we review recent advancements in AI-driven decoding algorithms and\nenergy-efficient System-on-Chip (SoC) platforms for next-generation\nminiaturized neural devices. These innovations highlight the potential for\ndeveloping intelligent neural interfaces, addressing critical challenges in\nscalability, reliability, interpretability, and user adaptability.",
    "categories": [
      "cs.AI",
      "cs.AR",
      "cs.LG",
      "eess.SP",
      "q-bio.NC",
      "I.2.0; B.7.0; I.5.1; C.3"
    ],
    "primary_category": "cs.AI",
    "comment": "To appear in the 2025 IEEE International NEWCAS Conference\n  (NEWCAS'25)",
    "pdf_url": "http://arxiv.org/pdf/2505.02516v1",
    "published_date": "2025-05-05 09:49:13 UTC",
    "updated_date": "2025-05-05 09:49:13 UTC"
  },
  {
    "arxiv_id": "2505.03844v2",
    "title": "From Spaceborne to Airborne: SAR Image Synthesis Using Foundation Models for Multi-Scale Adaptation",
    "authors": [
      "Solene Debuysere",
      "Nicolas Trouve",
      "Nathan Letheule",
      "Olivier Leveque",
      "Elise Colin"
    ],
    "abstract": "The availability of Synthetic Aperture Radar (SAR) satellite imagery has\nincreased considerably in recent years, with datasets commercially available.\nHowever, the acquisition of high-resolution SAR images in airborne\nconfigurations, remains costly and limited. Thus, the lack of open source,\nwell-labeled, or easily exploitable SAR text-image datasets is a barrier to the\nuse of existing foundation models in remote sensing applications. In this\ncontext, synthetic image generation is a promising solution to augment this\nscarce data, enabling a broader range of applications. Leveraging over 15 years\nof ONERA's extensive archival airborn data from acquisition campaigns, we\ncreated a comprehensive training dataset of 110 thousands SAR images to exploit\na 3.5 billion parameters pre-trained latent diffusion model\n\\cite{Baqu2019SethiR}. In this work, we present a novel approach utilizing\nspatial conditioning techniques within a foundation model to transform\nsatellite SAR imagery into airborne SAR representations. Additionally, we\ndemonstrate that our pipeline is effective for bridging the realism of\nsimulated images generated by ONERA's physics-based simulator EMPRISE\n\\cite{empriseem_ai_images}. Our method explores a key application of AI in\nadvancing SAR imaging technology. To the best of our knowledge, we are the\nfirst to introduce this approach in the literature.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.03844v2",
    "published_date": "2025-05-05 09:33:06 UTC",
    "updated_date": "2025-05-11 16:43:40 UTC"
  },
  {
    "arxiv_id": "2505.02502v1",
    "title": "Unveiling the Landscape of LLM Deployment in the Wild: An Empirical Study",
    "authors": [
      "Xinyi Hou",
      "Jiahao Han",
      "Yanjie Zhao",
      "Haoyu Wang"
    ],
    "abstract": "Background: Large language models (LLMs) are increasingly deployed via\nopen-source and commercial frameworks, enabling individuals and organizations\nto self-host advanced AI capabilities. However, insecure defaults and\nmisconfigurations often expose LLM services to the public Internet, posing\nsignificant security and system engineering risks. Aims: This study aims to\nunveil the current landscape of public-facing LLM deployments in the wild\nthrough a large-scale empirical study, focusing on service prevalence, exposure\ncharacteristics, systemic vulnerabilities, and associated risks. Method: We\nconducted an Internet-wide measurement to identify public-facing LLM\ndeployments across 15 frameworks, discovering 320,102 services. We extracted\n158 unique API endpoints, grouped into 12 functional categories based on\ncapabilities and security risks. We further analyzed configurations,\nauthentication practices, and geographic distributions, revealing deployment\ntrends and systemic issues in real-world LLM system engineering. Results: Our\nstudy shows that public LLM deployments are rapidly growing but often insecure.\nAmong all endpoints, we observe widespread use of insecure protocols, poor TLS\nconfigurations, and unauthenticated access to critical operations. Security\nrisks, including model disclosure, system leakage, and unauthorized access, are\npervasive, highlighting the need for secure-by-default frameworks and stronger\ndeployment practices. Conclusions: Public-facing LLM deployments suffer from\nwidespread security and configuration flaws, exposing services to misuse, model\ntheft, resource hijacking, and remote exploitation. Strengthening default\nsecurity, deployment practices, and operational standards is critical for the\ngrowing self-hosted LLM ecosystem.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02502v1",
    "published_date": "2025-05-05 09:30:19 UTC",
    "updated_date": "2025-05-05 09:30:19 UTC"
  },
  {
    "arxiv_id": "2505.02501v1",
    "title": "Corr2Distrib: Making Ambiguous Correspondences an Ally to Predict Reliable 6D Pose Distributions",
    "authors": [
      "Asma Brazi",
      "Boris Meden",
      "Fabrice Mayran de Chamisso",
      "Steve Bourgeois",
      "Vincent Lepetit"
    ],
    "abstract": "We introduce Corr2Distrib, the first correspondence-based method which\nestimates a 6D camera pose distribution from an RGB image, explaining the\nobservations. Indeed, symmetries and occlusions introduce visual ambiguities,\nleading to multiple valid poses. While a few recent methods tackle this\nproblem, they do not rely on local correspondences which, according to the BOP\nChallenge, are currently the most effective way to estimate a single 6DoF pose\nsolution. Using correspondences to estimate a pose distribution is not\nstraightforward, since ambiguous correspondences induced by visual ambiguities\ndrastically decrease the performance of PnP. With Corr2Distrib, we turn these\nambiguities into an advantage to recover all valid poses. Corr2Distrib first\nlearns a symmetry-aware representation for each 3D point on the object's\nsurface, characterized by a descriptor and a local frame. This representation\nenables the generation of 3DoF rotation hypotheses from single 2D-3D\ncorrespondences. Next, we refine these hypotheses into a 6DoF pose distribution\nusing PnP and pose scoring. Our experimental evaluations on complex\nnon-synthetic scenes show that Corr2Distrib outperforms state-of-the-art\nsolutions for both pose distribution estimation and single pose estimation from\nan RGB image, demonstrating the potential of correspondences-based approaches.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.02501v1",
    "published_date": "2025-05-05 09:29:32 UTC",
    "updated_date": "2025-05-05 09:29:32 UTC"
  },
  {
    "arxiv_id": "2505.02489v1",
    "title": "Beyond the model: Key differentiators in large language models and multi-agent services",
    "authors": [
      "Muskaan Goyal",
      "Pranav Bhasin"
    ],
    "abstract": "With the launch of foundation models like DeepSeek, Manus AI, and Llama 4, it\nhas become evident that large language models (LLMs) are no longer the sole\ndefining factor in generative AI. As many now operate at comparable levels of\ncapability, the real race is not about having the biggest model but optimizing\nthe surrounding ecosystem, including data quality and management, computational\nefficiency, latency, and evaluation frameworks. This review article delves into\nthese critical differentiators that ensure modern AI services are efficient and\nprofitable.",
    "categories": [
      "cs.AI",
      "cs.ET",
      "cs.MA",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "4 pages",
    "pdf_url": "http://arxiv.org/pdf/2505.02489v1",
    "published_date": "2025-05-05 09:15:31 UTC",
    "updated_date": "2025-05-05 09:15:31 UTC"
  },
  {
    "arxiv_id": "2505.07838v1",
    "title": "Moving From Monolithic To Microservices Architecture for Multi-Agent Systems",
    "authors": [
      "Muskaan Goyal",
      "Pranav Bhasin"
    ],
    "abstract": "The transition from monolithic to microservices architecture revolutionized\nsoftware development by improving scalability and maintainability. This\nparadigm shift is now becoming relevant for complex multi-agent systems (MAS).\nThis review article explores the evolution from monolithic architecture to\nmicroservices architecture in the specific context of MAS. It will highlight\nthe limitations of traditional monolithic MAS and the benefits of adopting a\nmicroservices-based approach. The article further examines the core\narchitectural principles and communication protocols, including Agent\nCommunication Languages (ACLs), the Model Context Protocol (MCP), and the\nApplication-to-Application (A2A) protocol. The article identifies emerging\narchitectural patterns, design challenges, and considerations through a\ncomparative lens of the paradigm shift.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.DC",
      "cs.MA"
    ],
    "primary_category": "cs.SE",
    "comment": "5 pages, comparative analysis",
    "pdf_url": "http://arxiv.org/pdf/2505.07838v1",
    "published_date": "2025-05-05 09:10:46 UTC",
    "updated_date": "2025-05-05 09:10:46 UTC"
  },
  {
    "arxiv_id": "2505.02486v1",
    "title": "SEFE: Superficial and Essential Forgetting Eliminator for Multimodal Continual Instruction Tuning",
    "authors": [
      "Jinpeng Chen",
      "Runmin Cong",
      "Yuzhi Zhao",
      "Hongzheng Yang",
      "Guangneng Hu",
      "Horace Ho Shing Ip",
      "Sam Kwong"
    ],
    "abstract": "Multimodal Continual Instruction Tuning (MCIT) aims to enable Multimodal\nLarge Language Models (MLLMs) to incrementally learn new tasks without\ncatastrophic forgetting. In this paper, we explore forgetting in this context,\ncategorizing it into superficial forgetting and essential forgetting.\nSuperficial forgetting refers to cases where the model's knowledge may not be\ngenuinely lost, but its responses to previous tasks deviate from expected\nformats due to the influence of subsequent tasks' answer styles, making the\nresults unusable. By contrast, essential forgetting refers to situations where\nthe model provides correctly formatted but factually inaccurate answers,\nindicating a true loss of knowledge. Assessing essential forgetting\nnecessitates addressing superficial forgetting first, as severe superficial\nforgetting can obscure the model's knowledge state. Hence, we first introduce\nthe Answer Style Diversification (ASD) paradigm, which defines a standardized\nprocess for transforming data styles across different tasks, unifying their\ntraining sets into similarly diversified styles to prevent superficial\nforgetting caused by style shifts. Building on this, we propose RegLoRA to\nmitigate essential forgetting. RegLoRA stabilizes key parameters where prior\nknowledge is primarily stored by applying regularization, enabling the model to\nretain existing competencies. Experimental results demonstrate that our overall\nmethod, SEFE, achieves state-of-the-art performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02486v1",
    "published_date": "2025-05-05 09:09:41 UTC",
    "updated_date": "2025-05-05 09:09:41 UTC"
  },
  {
    "arxiv_id": "2505.02485v1",
    "title": "Integrating Column Generation and Large Neighborhood Search for Bus Driver Scheduling with Complex Break Constraints",
    "authors": [
      "Lucas Kletzander",
      "Tommaso Mannelli Mazzoli",
      "Nysret Musliu",
      "Pascal Van Hentenryck"
    ],
    "abstract": "The Bus Driver Scheduling Problem (BDSP) is a combinatorial optimization\nproblem with the goal to design shifts to cover prearranged bus tours. The\nobjective takes into account the operational cost as well as the satisfaction\nof drivers. This problem is heavily constrained due to strict legal rules and\ncollective agreements. The objective of this article is to provide\nstate-of-the-art exact and hybrid solution methods that can provide\nhigh-quality solutions for instances of different sizes. This work presents a\ncomprehensive study of both an exact method, Branch and Price (B&P), as well as\na Large Neighborhood Search (LNS) framework which uses B&P or Column Generation\n(CG) for the repair phase to solve the BDSP. It further proposes and evaluates\na novel deeper integration of B&P and LNS, storing the generated columns from\nthe LNS subproblems and reusing them for other subproblems, or to find better\nglobal solutions. The article presents a detailed analysis of several\ncomponents of the solution methods and their impact, including general\nimprovements for the B&P subproblem, which is a high-dimensional Resource\nConstrained Shortest Path Problem (RCSPP), and the components of the LNS. The\nevaluation shows that our approach provides new state-of-the-art results for\ninstances of all sizes, including exact solutions for small instances, and low\ngaps to a known lower bound for mid-sized instances. Conclusions: We observe\nthat B&P provides the best results for small instances, while the tight\nintegration of LNS and CG can provide high-quality solutions for larger\ninstances, further improving over LNS which just uses CG as a black box. The\nproposed methods are general and can also be applied to other rule sets and\nrelated optimization problems",
    "categories": [
      "math.OC",
      "cs.AI"
    ],
    "primary_category": "math.OC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02485v1",
    "published_date": "2025-05-05 09:08:25 UTC",
    "updated_date": "2025-05-05 09:08:25 UTC"
  },
  {
    "arxiv_id": "2505.02484v1",
    "title": "El Agente: An Autonomous Agent for Quantum Chemistry",
    "authors": [
      "Yunheng Zou",
      "Austin H. Cheng",
      "Abdulrahman Aldossary",
      "Jiaru Bai",
      "Shi Xuan Leong",
      "Jorge Arturo Campos-Gonzalez-Angulo",
      "Changhyeok Choi",
      "Cher Tian Ser",
      "Gary Tom",
      "Andrew Wang",
      "Zijian Zhang",
      "Ilya Yakavets",
      "Han Hao",
      "Chris Crebolder",
      "Varinia Bernales",
      "AlÃ¡n Aspuru-Guzik"
    ],
    "abstract": "Computational chemistry tools are widely used to study the behaviour of\nchemical phenomena. Yet, the complexity of these tools can make them\ninaccessible to non-specialists and challenging even for experts. In this work,\nwe introduce El Agente Q, an LLM-based multi-agent system that dynamically\ngenerates and executes quantum chemistry workflows from natural language user\nprompts. The system is built on a novel cognitive architecture featuring a\nhierarchical memory framework that enables flexible task decomposition,\nadaptive tool selection, post-analysis, and autonomous file handling and\nsubmission. El Agente Q is benchmarked on six university-level course exercises\nand two case studies, demonstrating robust problem-solving performance\n(averaging >87% task success) and adaptive error handling through in situ\ndebugging. It also supports longer-term, multi-step task execution for more\ncomplex workflows, while maintaining transparency through detailed action trace\nlogs. Together, these capabilities lay the foundation for increasingly\nautonomous and accessible quantum chemistry.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.MA",
      "physics.chem-ph"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02484v1",
    "published_date": "2025-05-05 09:07:22 UTC",
    "updated_date": "2025-05-05 09:07:22 UTC"
  },
  {
    "arxiv_id": "2505.02483v1",
    "title": "Automated Hybrid Reward Scheduling via Large Language Models for Robotic Skill Learning",
    "authors": [
      "Changxin Huang",
      "Junyang Liang",
      "Yanbin Chang",
      "Jingzhao Xu",
      "Jianqiang Li"
    ],
    "abstract": "Enabling a high-degree-of-freedom robot to learn specific skills is a\nchallenging task due to the complexity of robotic dynamics. Reinforcement\nlearning (RL) has emerged as a promising solution; however, addressing such\nproblems requires the design of multiple reward functions to account for\nvarious constraints in robotic motion. Existing approaches typically sum all\nreward components indiscriminately to optimize the RL value function and\npolicy. We argue that this uniform inclusion of all reward components in policy\noptimization is inefficient and limits the robot's learning performance. To\naddress this, we propose an Automated Hybrid Reward Scheduling (AHRS) framework\nbased on Large Language Models (LLMs). This paradigm dynamically adjusts the\nlearning intensity of each reward component throughout the policy optimization\nprocess, enabling robots to acquire skills in a gradual and structured manner.\nSpecifically, we design a multi-branch value network, where each branch\ncorresponds to a distinct reward component. During policy optimization, each\nbranch is assigned a weight that reflects its importance, and these weights are\nautomatically computed based on rules designed by LLMs. The LLM generates a\nrule set in advance, derived from the task description, and during training, it\nselects a weight calculation rule from the library based on language prompts\nthat evaluate the performance of each branch. Experimental results demonstrate\nthat the AHRS method achieves an average 6.48% performance improvement across\nmultiple high-degree-of-freedom robotic tasks.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02483v1",
    "published_date": "2025-05-05 09:06:17 UTC",
    "updated_date": "2025-05-05 09:06:17 UTC"
  },
  {
    "arxiv_id": "2505.02467v1",
    "title": "Timing Is Everything: Finding the Optimal Fusion Points in Multimodal Medical Imaging",
    "authors": [
      "Valerio Guarrasi",
      "Klara Mogensen",
      "Sara Tassinari",
      "Sara Qvarlander",
      "Paolo Soda"
    ],
    "abstract": "Multimodal deep learning harnesses diverse imaging modalities, such as MRI\nsequences, to enhance diagnostic accuracy in medical imaging. A key challenge\nis determining the optimal timing for integrating these\nmodalities-specifically, identifying the network layers where fusion modules\nshould be inserted. Current approaches often rely on manual tuning or\nexhaustive search, which are computationally expensive without any guarantee of\nconverging to optimal results. We propose a sequential forward search algorithm\nthat incrementally activates and evaluates candidate fusion modules at\ndifferent layers of a multimodal network. At each step, the algorithm retrains\nfrom previously learned weights and compares validation loss to identify the\nbest-performing configuration. This process systematically reduces the search\nspace, enabling efficient identification of the optimal fusion timing without\nexhaustively testing all possible module placements. The approach is validated\non two multimodal MRI datasets, each addressing different classification tasks.\nOur algorithm consistently identified configurations that outperformed unimodal\nbaselines, late fusion, and a brute-force ensemble of all potential fusion\nplacements. These architectures demonstrated superior accuracy, F-score, and\nspecificity while maintaining competitive or improved AUC values. Furthermore,\nthe sequential nature of the search significantly reduced computational\noverhead, making the optimization process more practical. By systematically\ndetermining the optimal timing to fuse imaging modalities, our method advances\nmultimodal deep learning for medical imaging. It provides an efficient and\nrobust framework for fusion optimization, paving the way for improved clinical\ndecision-making and more adaptable, scalable architectures in medical AI\napplications.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02467v1",
    "published_date": "2025-05-05 08:53:21 UTC",
    "updated_date": "2025-05-05 08:53:21 UTC"
  },
  {
    "arxiv_id": "2505.02462v1",
    "title": "Incentivizing Inclusive Contributions in Model Sharing Markets",
    "authors": [
      "Enpei Zhang",
      "Jingyi Chai",
      "Rui Ye",
      "Yanfeng Wang",
      "Siheng Chen"
    ],
    "abstract": "While data plays a crucial role in training contemporary AI models, it is\nacknowledged that valuable public data will be exhausted in a few years,\ndirecting the world's attention towards the massive decentralized private data.\nHowever, the privacy-sensitive nature of raw data and lack of incentive\nmechanism prevent these valuable data from being fully exploited. Addressing\nthese challenges, this paper proposes inclusive and incentivized personalized\nfederated learning (iPFL), which incentivizes data holders with diverse\npurposes to collaboratively train personalized models without revealing raw\ndata. iPFL constructs a model-sharing market by solving a graph-based training\noptimization and incorporates an incentive mechanism based on game theory\nprinciples. Theoretical analysis shows that iPFL adheres to two key incentive\nproperties: individual rationality and truthfulness. Empirical studies on\neleven AI tasks (e.g., large language models' instruction-following tasks)\ndemonstrate that iPFL consistently achieves the highest economic utility, and\nbetter or comparable model performance compared to baseline methods. We\nanticipate that our iPFL can serve as a valuable technique for boosting future\nAI models on decentralized private data while making everyone satisfied.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.GT"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02462v1",
    "published_date": "2025-05-05 08:45:26 UTC",
    "updated_date": "2025-05-05 08:45:26 UTC"
  },
  {
    "arxiv_id": "2505.02443v1",
    "title": "Investigating the Impact of Personalized AI Tutors on Language Learning Performance",
    "authors": [
      "Simon Suh"
    ],
    "abstract": "Driven by the global shift towards online learning prompted by the COVID 19\npandemic, Artificial Intelligence has emerged as a pivotal player in the field\nof education. Intelligent Tutoring Systems offer a new method of personalized\nteaching, replacing the limitations of traditional teaching methods. However,\nconcerns arise about the ability of AI tutors to address skill development and\nengagement during the learning process. In this paper, I will conduct a quasi\nexperiment with paired sample t test on 34 students pre and post use of AI\ntutors in language learning platforms like Santa and Duolingo to examine the\nrelationship between students engagement, academic performance, and students\nsatisfaction during a personalized language learning experience.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "I.2.6; K.3.1"
    ],
    "primary_category": "cs.AI",
    "comment": "16 pages, 4 figures, 1 table, Uses three theoretical frameworks like\n  Domain modeling, Gardner Theory of Multiple Intelligences, and Zone of\n  Proximal Development",
    "pdf_url": "http://arxiv.org/pdf/2505.02443v1",
    "published_date": "2025-05-05 08:11:20 UTC",
    "updated_date": "2025-05-05 08:11:20 UTC"
  },
  {
    "arxiv_id": "2505.02441v1",
    "title": "MSFNet-CPD: Multi-Scale Cross-Modal Fusion Network for Crop Pest Detection",
    "authors": [
      "Jiaqi Zhang",
      "Zhuodong Liu",
      "Kejian Yu"
    ],
    "abstract": "Accurate identification of agricultural pests is essential for crop\nprotection but remains challenging due to the large intra-class variance and\nfine-grained differences among pest species. While deep learning has advanced\npest detection, most existing approaches rely solely on low-level visual\nfeatures and lack effective multi-modal integration, leading to limited\naccuracy and poor interpretability. Moreover, the scarcity of high-quality\nmulti-modal agricultural datasets further restricts progress in this field. To\naddress these issues, we construct two novel multi-modal benchmarks-CTIP102 and\nSTIP102-based on the widely-used IP102 dataset, and introduce a Multi-scale\nCross-Modal Fusion Network (MSFNet-CPD) for robust pest detection. Our approach\nenhances visual quality via a super-resolution reconstruction module, and feeds\nboth the original and reconstructed images into the network to improve clarity\nand detection performance. To better exploit semantic cues, we propose an\nImage-Text Fusion (ITF) module for joint modeling of visual and textual\nfeatures, and an Image-Text Converter (ITC) that reconstructs fine-grained\ndetails across multiple scales to handle challenging backgrounds. Furthermore,\nwe introduce an Arbitrary Combination Image Enhancement (ACIE) strategy to\ngenerate a more complex and diverse pest detection dataset, MTIP102, improving\nthe model's generalization to real-world scenarios. Extensive experiments\ndemonstrate that MSFNet-CPD consistently outperforms state-of-the-art methods\non multiple pest detection benchmarks. All code and datasets will be made\npublicly available at: https://github.com/Healer-ML/MSFNet-CPD.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to IJCNN 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.02441v1",
    "published_date": "2025-05-05 08:10:22 UTC",
    "updated_date": "2025-05-05 08:10:22 UTC"
  },
  {
    "arxiv_id": "2505.02439v1",
    "title": "ReeM: Ensemble Building Thermodynamics Model for Efficient HVAC Control via Hierarchical Reinforcement Learning",
    "authors": [
      "Yang Deng",
      "Yaohui Liu",
      "Rui Liang",
      "Dafang Zhao",
      "Donghua Xie",
      "Ittetsu Taniguchi",
      "Dan Wang"
    ],
    "abstract": "The building thermodynamics model, which predicts real-time indoor\ntemperature changes under potential HVAC (Heating, Ventilation, and Air\nConditioning) control operations, is crucial for optimizing HVAC control in\nbuildings. While pioneering studies have attempted to develop such models for\nvarious building environments, these models often require extensive data\ncollection periods and rely heavily on expert knowledge, making the modeling\nprocess inefficient and limiting the reusability of the models. This paper\nexplores a model ensemble perspective that utilizes existing developed models\nas base models to serve a target building environment, thereby providing\naccurate predictions while reducing the associated efforts. Given that building\ndata streams are non-stationary and the number of base models may increase, we\npropose a Hierarchical Reinforcement Learning (HRL) approach to dynamically\nselect and weight the base models. Our approach employs a two-tiered\ndecision-making process: the high-level focuses on model selection, while the\nlow-level determines the weights of the selected models. We thoroughly evaluate\nthe proposed approach through offline experiments and an on-site case study,\nand the experimental results demonstrate the effectiveness of our method.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02439v1",
    "published_date": "2025-05-05 08:09:36 UTC",
    "updated_date": "2025-05-05 08:09:36 UTC"
  },
  {
    "arxiv_id": "2505.02435v2",
    "title": "A New Approach to Backtracking Counterfactual Explanations: A Unified Causal Framework for Efficient Model Interpretability",
    "authors": [
      "Pouria Fatemi",
      "Ehsan Sharifian",
      "Mohammad Hossein Yassaee"
    ],
    "abstract": "Counterfactual explanations enhance interpretability by identifying\nalternative inputs that produce different outputs, offering localized insights\ninto model decisions. However, traditional methods often neglect causal\nrelationships, leading to unrealistic examples. While newer approaches\nintegrate causality, they are computationally expensive. To address these\nchallenges, we propose an efficient method called BRACE based on backtracking\ncounterfactuals that incorporates causal reasoning to generate actionable\nexplanations. We first examine the limitations of existing methods and then\nintroduce our novel approach and its features. We also explore the relationship\nbetween our method and previous techniques, demonstrating that it generalizes\nthem in specific scenarios. Finally, experiments show that our method provides\ndeeper insights into model outputs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02435v2",
    "published_date": "2025-05-05 08:01:56 UTC",
    "updated_date": "2025-05-22 13:51:17 UTC"
  },
  {
    "arxiv_id": "2505.02433v2",
    "title": "FairPO: Robust Preference Optimization for Fair Multi-Label Learning",
    "authors": [
      "Soumen Kumar Mondal",
      "Akshit Varmora",
      "Prateek Chanda",
      "Ganesh Ramakrishnan"
    ],
    "abstract": "We propose FairPO, a novel framework designed to promote fairness in\nmulti-label classification by directly optimizing preference signals with a\ngroup robustness perspective. In our framework, the set of labels is\npartitioned into privileged and non-privileged groups, and a preference-based\nloss inspired by Direct Preference Optimization (DPO) is employed to more\neffectively differentiate true positive labels from confusing negatives within\nthe privileged group, while preserving baseline classification performance for\nnon-privileged labels. By framing the learning problem as a robust optimization\nover groups, our approach dynamically adjusts the training emphasis toward\ngroups with poorer performance, thereby mitigating bias and ensuring a fairer\ntreatment across diverse label categories. In addition, we outline plans to\nextend this approach by investigating alternative loss formulations such as\nSimple Preference Optimisation (SimPO) and Contrastive Preference Optimization\n(CPO) to exploit reference-free reward formulations and contrastive training\nsignals. Furthermore, we plan to extend FairPO with multilabel generation\ncapabilities, enabling the model to dynamically generate diverse and coherent\nlabel sets for ambiguous inputs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02433v2",
    "published_date": "2025-05-05 07:58:54 UTC",
    "updated_date": "2025-05-16 12:47:32 UTC"
  },
  {
    "arxiv_id": "2505.02426v1",
    "title": "Towards One-shot Federated Learning: Advances, Challenges, and Future Directions",
    "authors": [
      "Flora Amato",
      "Lingyu Qiu",
      "Mohammad Tanveer",
      "Salvatore Cuomo",
      "Fabio Giampaolo",
      "Francesco Piccialli"
    ],
    "abstract": "One-shot FL enables collaborative training in a single round, eliminating the\nneed for iterative communication, making it particularly suitable for use in\nresource-constrained and privacy-sensitive applications. This survey offers a\nthorough examination of One-shot FL, highlighting its distinct operational\nframework compared to traditional federated approaches. One-shot FL supports\nresource-limited devices by enabling single-round model aggregation while\nmaintaining data locality. The survey systematically categorizes existing\nmethodologies, emphasizing advancements in client model initialization,\naggregation techniques, and strategies for managing heterogeneous data\ndistributions. Furthermore, we analyze the limitations of current approaches,\nparticularly in terms of scalability and generalization in non-IID settings. By\nanalyzing cutting-edge techniques and outlining open challenges, this survey\naspires to provide a comprehensive reference for researchers and practitioners\naiming to design and implement One-shot FL systems, advancing the development\nand adoption of One-shot FL solutions in a real-world, resource-constrained\nscenario.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02426v1",
    "published_date": "2025-05-05 07:46:21 UTC",
    "updated_date": "2025-05-05 07:46:21 UTC"
  },
  {
    "arxiv_id": "2505.02881v2",
    "title": "Rewriting Pre-Training Data Boosts LLM Performance in Math and Code",
    "authors": [
      "Kazuki Fujii",
      "Yukito Tajima",
      "Sakae Mizuki",
      "Hinari Shimada",
      "Taihei Shiotani",
      "Koshiro Saito",
      "Masanari Ohi",
      "Masaki Kawamura",
      "Taishi Nakamura",
      "Takumi Okamoto",
      "Shigeki Ishida",
      "Kakeru Hattori",
      "Youmi Ma",
      "Hiroya Takamura",
      "Rio Yokota",
      "Naoaki Okazaki"
    ],
    "abstract": "The performance of large language models (LLMs) in program synthesis and\nmathematical reasoning is fundamentally limited by the quality of their\npre-training corpora. We introduce two openly licensed datasets, released under\nthe Llama 3.3 Community License, that significantly enhance LLM performance by\nsystematically rewriting public data. SwallowCode (approximately 16.1 billion\ntokens) refines Python snippets from The-Stack-v2 through a novel four-stage\npipeline: syntax validation, pylint-based style filtering, and a two-stage LLM\nrewriting process that enforces style conformity and transforms snippets into\nself-contained, algorithmically efficient examples. Unlike prior methods that\nrely on exclusionary filtering or limited transformations, our\ntransform-and-retain approach upgrades low-quality code, maximizing data\nutility. SwallowMath (approximately 2.3 billion tokens) enhances Finemath-4+ by\nremoving boilerplate, restoring context, and reformatting solutions into\nconcise, step-by-step explanations. Within a fixed 50 billion token training\nbudget, continual pre-training of Llama-3.1-8B with SwallowCode boosts pass@1\nby +17.0 on HumanEval and +17.7 on HumanEval+ compared to Stack-Edu, surpassing\nthe baseline model's code generation capabilities. Similarly, substituting\nSwallowMath yields +12.4 accuracy on GSM8K and +7.6 on MATH. Ablation studies\nconfirm that each pipeline stage contributes incrementally, with rewriting\ndelivering the largest gains. All datasets, prompts, and checkpoints are\npublicly available, enabling reproducible research and advancing LLM\npre-training for specialized domains.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02881v2",
    "published_date": "2025-05-05 07:38:43 UTC",
    "updated_date": "2025-05-10 14:45:30 UTC"
  },
  {
    "arxiv_id": "2505.02417v2",
    "title": "T2S: High-resolution Time Series Generation with Text-to-Series Diffusion Models",
    "authors": [
      "Yunfeng Ge",
      "Jiawei Li",
      "Yiji Zhao",
      "Haomin Wen",
      "Zhao Li",
      "Meikang Qiu",
      "Hongyan Li",
      "Ming Jin",
      "Shirui Pan"
    ],
    "abstract": "Text-to-Time Series generation holds significant potential to address\nchallenges such as data sparsity, imbalance, and limited availability of\nmultimodal time series datasets across domains. While diffusion models have\nachieved remarkable success in Text-to-X (e.g., vision and audio data)\ngeneration, their use in time series generation remains in its nascent stages.\nExisting approaches face two critical limitations: (1) the lack of systematic\nexploration of general-proposed time series captions, which are often\ndomain-specific and struggle with generalization; and (2) the inability to\ngenerate time series of arbitrary lengths, limiting their applicability to\nreal-world scenarios. In this work, we first categorize time series captions\ninto three levels: point-level, fragment-level, and instance-level.\nAdditionally, we introduce a new fragment-level dataset containing over 600,000\nhigh-resolution time series-text pairs. Second, we propose Text-to-Series\n(T2S), a diffusion-based framework that bridges the gap between natural\nlanguage and time series in a domain-agnostic manner. T2S employs a\nlength-adaptive variational autoencoder to encode time series of varying\nlengths into consistent latent embeddings. On top of that, T2S effectively\naligns textual representations with latent embeddings by utilizing Flow\nMatching and employing Diffusion Transformer as the denoiser. We train T2S in\nan interleaved paradigm across multiple lengths, allowing it to generate\nsequences of any desired length. Extensive evaluations demonstrate that T2S\nachieves state-of-the-art performance across 13 datasets spanning 12 domains.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by the 34th International Joint Conference on Artificial\n  Intelligence (IJCAI 2025)",
    "pdf_url": "http://arxiv.org/pdf/2505.02417v2",
    "published_date": "2025-05-05 07:22:54 UTC",
    "updated_date": "2025-05-08 08:30:12 UTC"
  },
  {
    "arxiv_id": "2505.02413v1",
    "title": "Task-Oriented Semantic Communication in Large Multimodal Models-based Vehicle Networks",
    "authors": [
      "Baoxia Du",
      "Hongyang Du",
      "Dusit Niyato",
      "Ruidong Li"
    ],
    "abstract": "Task-oriented semantic communication has emerged as a fundamental approach\nfor enhancing performance in various communication scenarios. While recent\nadvances in Generative Artificial Intelligence (GenAI), such as Large Language\nModels (LLMs), have been applied to semantic communication designs, the\npotential of Large Multimodal Models (LMMs) remains largely unexplored. In this\npaper, we investigate an LMM-based vehicle AI assistant using a Large Language\nand Vision Assistant (LLaVA) and propose a task-oriented semantic communication\nframework to facilitate efficient interaction between users and cloud servers.\nTo reduce computational demands and shorten response time, we optimize LLaVA's\nimage slicing to selectively focus on areas of utmost interest to users.\nAdditionally, we assess the importance of image patches by combining objective\nand subjective user attention, adjusting energy usage for transmitting semantic\ninformation. This strategy optimizes resource utilization, ensuring precise\ntransmission of critical information. We construct a Visual Question Answering\n(VQA) dataset for traffic scenarios to evaluate effectiveness. Experimental\nresults show that our semantic communication framework significantly increases\naccuracy in answering questions under the same channel conditions, performing\nparticularly well in environments with poor Signal-to-Noise Ratios (SNR).\nAccuracy can be improved by 13.4% at an SNR of 12dB and 33.1% at 10dB,\nrespectively.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02413v1",
    "published_date": "2025-05-05 07:18:47 UTC",
    "updated_date": "2025-05-05 07:18:47 UTC"
  },
  {
    "arxiv_id": "2505.02410v2",
    "title": "Bielik 11B v2 Technical Report",
    "authors": [
      "Krzysztof Ociepa",
      "Åukasz Flis",
      "Krzysztof WrÃ³bel",
      "Adrian GwoÅºdziej",
      "Remigiusz Kinas"
    ],
    "abstract": "We present Bielik 11B v2, a state-of-the-art language model optimized for\nPolish text processing. Built on the Mistral 7B v0.2 architecture and scaled to\n11B parameters using depth up-scaling, this model demonstrates exceptional\nperformance across Polish language benchmarks while maintaining strong\ncross-lingual capabilities. We introduce two key technical innovations:\nWeighted Instruction Cross-Entropy Loss, which optimizes learning across\ndiverse instruction types by assigning quality-based weights to training\nexamples, and Adaptive Learning Rate, which dynamically adjusts based on\ncontext length. Comprehensive evaluation across multiple benchmarks\ndemonstrates that Bielik 11B v2 outperforms many larger models, including those\nwith 2-6 times more parameters, and significantly surpasses other specialized\nPolish language models on tasks ranging from linguistic understanding to\ncomplex reasoning. The model's parameter efficiency and extensive quantization\noptions enable deployment across various hardware configurations, advancing\nPolish language AI capabilities and establishing new benchmarks for\nresource-efficient language modeling in less-represented languages.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T50",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02410v2",
    "published_date": "2025-05-05 07:03:41 UTC",
    "updated_date": "2025-05-08 22:55:18 UTC"
  },
  {
    "arxiv_id": "2505.02396v1",
    "title": "Diagnostic Uncertainty in Pneumonia Detection using CNN MobileNetV2 and CNN from Scratch",
    "authors": [
      "Kennard Norbert Sudiardjo",
      "Islam Nur Alam",
      "Wilson Wijaya",
      "Lili Ayu Wulandhari"
    ],
    "abstract": "Pneumonia Diagnosis, though it is crucial for an effective treatment, it can\nbe hampered by uncertainty. This uncertainty starts to arise due to some\nfactors like atypical presentations, limitations of diagnostic tools such as\nchest X-rays, and the presence of co-existing respiratory conditions. This\nresearch proposes one of the supervised learning methods, CNN. Using\nMobileNetV2 as the pre-trained one with ResNet101V2 architecture and using\nKeras API as the built from scratch model, for identifying lung diseases\nespecially pneumonia. The datasets used in this research were obtained from the\nwebsite through Kaggle. The result shows that by implementing CNN MobileNetV2\nand CNN from scratch the result is promising. While validating data,\nMobileNetV2 performs with stability and minimal overfitting, while the training\naccuracy increased to 84.87% later it slightly decreased to 78.95%, with\nincreasing validation loss from 0.499 to 0.6345. Nonetheless, MobileNetV2 is\nmore stable. Although it takes more time to train each epoch. Meanwhile, after\nthe 10th epoch, the Scratch model displayed more instability and overfitting\ndespite having higher validation accuracy, training accuracy decreased\nsignificantly to 78.12% and the validation loss increased from 0.5698 to\n1.1809. With these results, ResNet101V2 offers stability, and the Scratch model\noffers high accuracy.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02396v1",
    "published_date": "2025-05-05 06:40:08 UTC",
    "updated_date": "2025-05-05 06:40:08 UTC"
  },
  {
    "arxiv_id": "2505.02391v1",
    "title": "Optimizing Chain-of-Thought Reasoners via Gradient Variance Minimization in Rejection Sampling and RL",
    "authors": [
      "Jiarui Yao",
      "Yifan Hao",
      "Hanning Zhang",
      "Hanze Dong",
      "Wei Xiong",
      "Nan Jiang",
      "Tong Zhang"
    ],
    "abstract": "Chain-of-thought (CoT) reasoning in large language models (LLMs) can be\nformalized as a latent variable problem, where the model needs to generate\nintermediate reasoning steps. While prior approaches such as iterative\nreward-ranked fine-tuning (RAFT) have relied on such formulations, they\ntypically apply uniform inference budgets across prompts, which fails to\naccount for variability in difficulty and convergence behavior. This work\nidentifies the main bottleneck in CoT training as inefficient stochastic\ngradient estimation due to static sampling strategies. We propose GVM-RAFT, a\nprompt-specific Dynamic Sample Allocation Strategy designed to minimize\nstochastic gradient variance under a computational budget constraint. The\nmethod dynamically allocates computational resources by monitoring prompt\nacceptance rates and stochastic gradient norms, ensuring that the resulting\ngradient variance is minimized. Our theoretical analysis shows that the\nproposed dynamic sampling strategy leads to accelerated convergence guarantees\nunder suitable conditions. Experiments on mathematical reasoning show that\nGVM-RAFT achieves a 2-4x speedup and considerable accuracy improvements over\nvanilla RAFT. The proposed dynamic sampling strategy is general and can be\nincorporated into other reinforcement learning algorithms, such as GRPO,\nleading to similar improvements in convergence and test accuracy. Our code is\navailable at https://github.com/RLHFlow/GVM.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02391v1",
    "published_date": "2025-05-05 06:26:00 UTC",
    "updated_date": "2025-05-05 06:26:00 UTC"
  },
  {
    "arxiv_id": "2505.02390v1",
    "title": "Quantitative Analysis of Performance Drop in DeepSeek Model Quantization",
    "authors": [
      "Enbo Zhao",
      "Yi Shen",
      "Shuming Shi",
      "Jieyun Huang",
      "Zhihao Chen",
      "Ning Wang",
      "Siqi Xiao",
      "Jian Zhang",
      "Kai Wang",
      "Shiguo Lian"
    ],
    "abstract": "Recently, there is a high demand for deploying DeepSeek-R1 and V3 locally,\npossibly because the official service often suffers from being busy and some\norganizations have data privacy concerns. While single-machine deployment\noffers infrastructure simplicity, the models' 671B FP8 parameter configuration\nexceeds the practical memory limits of a standard 8-GPU machine. Quantization\nis a widely used technique that helps reduce model memory consumption. However,\nit is unclear what the performance of DeepSeek-R1 and V3 will be after being\nquantized. This technical report presents the first quantitative evaluation of\nmulti-bitwidth quantization across the complete DeepSeek model spectrum. Key\nfindings reveal that 4-bit quantization maintains little performance\ndegradation versus FP8 while enabling single-machine deployment on standard\nNVIDIA GPU devices. We further propose DQ3_K_M, a dynamic 3-bit quantization\nmethod that significantly outperforms traditional Q3_K_M variant on various\nbenchmarks, which is also comparable with 4-bit quantization (Q4_K_M) approach\nin most tasks. Moreover, DQ3_K_M supports single-machine deployment\nconfigurations for both NVIDIA H100/A100 and Huawei 910B. Our implementation of\nDQ3\\_K\\_M is released at https://github.com/UnicomAI/DeepSeek-Eval, containing\noptimized 3-bit quantized variants of both DeepSeek-R1 and DeepSeek-V3.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02390v1",
    "published_date": "2025-05-05 06:25:20 UTC",
    "updated_date": "2025-05-05 06:25:20 UTC"
  },
  {
    "arxiv_id": "2505.02388v1",
    "title": "MetaScenes: Towards Automated Replica Creation for Real-world 3D Scans",
    "authors": [
      "Huangyue Yu",
      "Baoxiong Jia",
      "Yixin Chen",
      "Yandan Yang",
      "Puhao Li",
      "Rongpeng Su",
      "Jiaxin Li",
      "Qing Li",
      "Wei Liang",
      "Song-Chun Zhu",
      "Tengyu Liu",
      "Siyuan Huang"
    ],
    "abstract": "Embodied AI (EAI) research requires high-quality, diverse 3D scenes to\neffectively support skill acquisition, sim-to-real transfer, and\ngeneralization. Achieving these quality standards, however, necessitates the\nprecise replication of real-world object diversity. Existing datasets\ndemonstrate that this process heavily relies on artist-driven designs, which\ndemand substantial human effort and present significant scalability challenges.\nTo scalably produce realistic and interactive 3D scenes, we first present\nMetaScenes, a large-scale, simulatable 3D scene dataset constructed from\nreal-world scans, which includes 15366 objects spanning 831 fine-grained\ncategories. Then, we introduce Scan2Sim, a robust multi-modal alignment model,\nwhich enables the automated, high-quality replacement of assets, thereby\neliminating the reliance on artist-driven designs for scaling 3D scenes. We\nfurther propose two benchmarks to evaluate MetaScenes: a detailed scene\nsynthesis task focused on small item layouts for robotic manipulation and a\ndomain transfer task in vision-and-language navigation (VLN) to validate\ncross-domain transfer. Results confirm MetaScene's potential to enhance EAI by\nsupporting more generalizable agent learning and sim-to-real applications,\nintroducing new possibilities for EAI research. Project website:\nhttps://meta-scenes.github.io/.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.02388v1",
    "published_date": "2025-05-05 06:13:25 UTC",
    "updated_date": "2025-05-05 06:13:25 UTC"
  },
  {
    "arxiv_id": "2505.02387v3",
    "title": "RM-R1: Reward Modeling as Reasoning",
    "authors": [
      "Xiusi Chen",
      "Gaotang Li",
      "Ziqi Wang",
      "Bowen Jin",
      "Cheng Qian",
      "Yu Wang",
      "Hongru Wang",
      "Yu Zhang",
      "Denghui Zhang",
      "Tong Zhang",
      "Hanghang Tong",
      "Heng Ji"
    ],
    "abstract": "Reward modeling is essential for aligning large language models with human\npreferences through reinforcement learning from human feedback. To provide\naccurate reward signals, a reward model (RM) should stimulate deep thinking and\nconduct interpretable reasoning before assigning a score or a judgment.\nInspired by recent advances of long chain-of-thought on reasoning-intensive\ntasks, we hypothesize and validate that integrating reasoning capabilities into\nreward modeling significantly enhances RMs interpretability and performance. To\nthis end, we introduce a new class of generative reward models - Reasoning\nReward Models (ReasRMs) - which formulate reward modeling as a reasoning task.\nWe propose a reasoning-oriented training pipeline and train a family of\nReasRMs, RM-R1. RM-R1 features a chain-of-rubrics (CoR) mechanism -\nself-generating sample-level chat rubrics or math/code solutions, and\nevaluating candidate responses against them. The training of RM-R1 consists of\ntwo key stages: (1) distillation of high-quality reasoning chains and (2)\nreinforcement learning with verifiable rewards. Empirically, our models achieve\nstate-of-the-art performance across three reward model benchmarks on average,\noutperforming much larger open-weight models (e.g., INF-ORM-Llama3.1-70B) and\nproprietary ones (e.g., GPT-4o) by up to 4.9%. Beyond final performance, we\nperform thorough empirical analyses to understand the key ingredients of\nsuccessful ReasRM training. To facilitate future research, we release six\nREASRM models along with code and data at https://github.com/RM-R1-UIUC/RM-R1.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "25 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2505.02387v3",
    "published_date": "2025-05-05 06:11:12 UTC",
    "updated_date": "2025-05-18 03:26:32 UTC"
  },
  {
    "arxiv_id": "2505.03840v1",
    "title": "CoCoB: Adaptive Collaborative Combinatorial Bandits for Online Recommendation",
    "authors": [
      "Cairong Yan",
      "Jinyi Han",
      "Jin Ju",
      "Yanting Zhang",
      "Zijian Wang",
      "Xuan Shao"
    ],
    "abstract": "Clustering bandits have gained significant attention in recommender systems\nby leveraging collaborative information from neighboring users to better\ncapture target user preferences. However, these methods often lack a clear\ndefinition of similar users and face challenges when users with unique\npreferences lack appropriate neighbors. In such cases, relying on divergent\npreferences of misidentified neighbors can degrade recommendation quality. To\naddress these limitations, this paper proposes an adaptive Collaborative\nCombinatorial Bandits algorithm (CoCoB). CoCoB employs an innovative two-sided\nbandit architecture, applying bandit principles to both the user and item\nsides. The user-bandit employs an enhanced Bayesian model to explore user\nsimilarity, identifying neighbors based on a similarity probability threshold.\nThe item-bandit treats items as arms, generating diverse recommendations\ninformed by the user-bandit's output. CoCoB dynamically adapts, leveraging\nneighbor preferences when available or focusing solely on the target user\notherwise. Regret analysis under a linear contextual bandit setting and\nexperiments on three real-world datasets demonstrate CoCoB's effectiveness,\nachieving an average 2.4% improvement in F1 score over state-of-the-art\nmethods.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "This paper has been accepted by DASFAA 2025: The International\n  Conference on Database Systems for Advanced Applications. This version\n  provides more detailed information",
    "pdf_url": "http://arxiv.org/pdf/2505.03840v1",
    "published_date": "2025-05-05 05:41:16 UTC",
    "updated_date": "2025-05-05 05:41:16 UTC"
  },
  {
    "arxiv_id": "2505.02370v1",
    "title": "SuperEdit: Rectifying and Facilitating Supervision for Instruction-Based Image Editing",
    "authors": [
      "Ming Li",
      "Xin Gu",
      "Fan Chen",
      "Xiaoying Xing",
      "Longyin Wen",
      "Chen Chen",
      "Sijie Zhu"
    ],
    "abstract": "Due to the challenges of manually collecting accurate editing data, existing\ndatasets are typically constructed using various automated methods, leading to\nnoisy supervision signals caused by the mismatch between editing instructions\nand original-edited image pairs. Recent efforts attempt to improve editing\nmodels through generating higher-quality edited images, pre-training on\nrecognition tasks, or introducing vision-language models (VLMs) but fail to\nresolve this fundamental issue. In this paper, we offer a novel solution by\nconstructing more effective editing instructions for given image pairs. This\nincludes rectifying the editing instructions to better align with the\noriginal-edited image pairs and using contrastive editing instructions to\nfurther enhance their effectiveness. Specifically, we find that editing models\nexhibit specific generation attributes at different inference steps,\nindependent of the text. Based on these prior attributes, we define a unified\nguide for VLMs to rectify editing instructions. However, there are some\nchallenging editing scenarios that cannot be resolved solely with rectified\ninstructions. To this end, we further construct contrastive supervision signals\nwith positive and negative instructions and introduce them into the model\ntraining using triplet loss, thereby further facilitating supervision\neffectiveness. Our method does not require the VLM modules or pre-training\ntasks used in previous work, offering a more direct and efficient way to\nprovide better supervision signals, and providing a novel, simple, and\neffective solution for instruction-based image editing. Results on multiple\nbenchmarks demonstrate that our method significantly outperforms existing\napproaches. Compared with previous SOTA SmartEdit, we achieve 9.19%\nimprovements on the Real-Edit benchmark with 30x less training data and 13x\nsmaller model size.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Code, Data and Models are available at:\n  https://github.com/bytedance/SuperEdit",
    "pdf_url": "http://arxiv.org/pdf/2505.02370v1",
    "published_date": "2025-05-05 05:19:40 UTC",
    "updated_date": "2025-05-05 05:19:40 UTC"
  },
  {
    "arxiv_id": "2505.02369v3",
    "title": "Sharpness-Aware Minimization with Z-Score Gradient Filtering for Neural Networks",
    "authors": [
      "Juyoung Yun"
    ],
    "abstract": "Sharpness-Aware Minimization (SAM) improves neural network generalization by\noptimizing the worst-case loss within a neighborhood of parameters, yet it\nperturbs parameters using the entire gradient vector, including components with\nlow statistical significance. We introduce ZSharp, a refined sharpness-aware\noptimization method that incorporates layer-wise Z-score normalization followed\nby percentile-based filtering. This process selects only the most statistically\nsignificant gradient components-those with large standardized magnitudes-for\nconstructing the perturbation direction. ZSharp retains the standard two-phase\nSAM structure of ascent and descent while modifying the ascent step to focus on\nsharper, curvature-relevant directions. We evaluate ZSharp on CIFAR-10,\nCIFAR-100, and Tiny-ImageNet using a range of models including ResNet, VGG, and\nVision Transformers. Across all architectures and datasets, ZSharp consistently\nachieves higher test accuracy compared to SAM, ASAM, and Friendly-SAM. These\nresults indicate that Z-score-based gradient filtering can enhance the\nsharpness sensitivity of the update direction, leading to improved\ngeneralization in deep neural network training.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.IT",
      "cs.NE",
      "math.IT"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02369v3",
    "published_date": "2025-05-05 05:13:12 UTC",
    "updated_date": "2025-05-07 14:21:19 UTC"
  },
  {
    "arxiv_id": "2505.02366v2",
    "title": "JTCSE: Joint Tensor-Modulus Constraints and Cross-Attention for Unsupervised Contrastive Learning of Sentence Embeddings",
    "authors": [
      "Tianyu Zong",
      "Hongzhu Yi",
      "Bingkang Shi",
      "Yuanxiang Wang",
      "Jungang Xu"
    ],
    "abstract": "Unsupervised contrastive learning has become a hot research topic in natural\nlanguage processing. Existing works usually aim at constraining the orientation\ndistribution of the representations of positive and negative samples in the\nhigh-dimensional semantic space in contrastive learning, but the semantic\nrepresentation tensor possesses both modulus and orientation features, and the\nexisting works ignore the modulus feature of the representations and cause\ninsufficient contrastive learning. % Therefore, we firstly propose a training\nobjective that aims at modulus constraints on the semantic representation\ntensor, to strengthen the alignment between the positive samples in contrastive\nlearning. Therefore, we first propose a training objective that is designed to\nimpose modulus constraints on the semantic representation tensor, to strengthen\nthe alignment between positive samples in contrastive learning. Then, the\nBERT-like model suffers from the phenomenon of sinking attention, leading to a\nlack of attention to CLS tokens that aggregate semantic information. In\nresponse, we propose a cross-attention structure among the twin-tower ensemble\nmodels to enhance the model's attention to CLS token and optimize the quality\nof CLS Pooling. Combining the above two motivations, we propose a new\n\\textbf{J}oint \\textbf{T}ensor representation modulus constraint and\n\\textbf{C}ross-attention unsupervised contrastive learning \\textbf{S}entence\n\\textbf{E}mbedding representation framework JTCSE, which we evaluate in seven\nsemantic text similarity computation tasks, and the experimental results show\nthat JTCSE's twin-tower ensemble model and single-tower distillation model\noutperform the other baselines and become the current SOTA. In addition, we\nhave conducted an extensive zero-shot downstream task evaluation, which shows\nthat JTCSE outperforms other baselines overall on more than 130 tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02366v2",
    "published_date": "2025-05-05 05:09:21 UTC",
    "updated_date": "2025-05-07 01:11:50 UTC"
  },
  {
    "arxiv_id": "2505.02362v1",
    "title": "Advancing Email Spam Detection: Leveraging Zero-Shot Learning and Large Language Models",
    "authors": [
      "Ghazaleh SHirvani",
      "Saeid Ghasemshirazi"
    ],
    "abstract": "Email spam detection is a critical task in modern communication systems,\nessential for maintaining productivity, security, and user experience.\nTraditional machine learning and deep learning approaches, while effective in\nstatic settings, face significant limitations in adapting to evolving spam\ntactics, addressing class imbalance, and managing data scarcity. These\nchallenges necessitate innovative approaches that reduce dependency on\nextensive labeled datasets and frequent retraining. This study investigates the\neffectiveness of Zero-Shot Learning using FLAN-T5, combined with advanced\nNatural Language Processing (NLP) techniques such as BERT for email spam\ndetection. By employing BERT to preprocess and extract critical information\nfrom email content, and FLAN-T5 to classify emails in a Zero-Shot framework,\nthe proposed approach aims to address the limitations of traditional spam\ndetection systems. The integration of FLAN-T5 and BERT enables robust spam\ndetection without relying on extensive labeled datasets or frequent retraining,\nmaking it highly adaptable to unseen spam patterns and adversarial\nenvironments. This research highlights the potential of leveraging zero-shot\nlearning and NLPs for scalable and efficient spam detection, providing insights\ninto their capability to address the dynamic and challenging nature of spam\ndetection tasks.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02362v1",
    "published_date": "2025-05-05 04:48:20 UTC",
    "updated_date": "2025-05-05 04:48:20 UTC"
  },
  {
    "arxiv_id": "2505.02360v1",
    "title": "Catastrophic Overfitting, Entropy Gap and Participation Ratio: A Noiseless $l^p$ Norm Solution for Fast Adversarial Training",
    "authors": [
      "Fares B. Mehouachi",
      "Saif Eddin Jabari"
    ],
    "abstract": "Adversarial training is a cornerstone of robust deep learning, but fast\nmethods like the Fast Gradient Sign Method (FGSM) often suffer from\nCatastrophic Overfitting (CO), where models become robust to single-step\nattacks but fail against multi-step variants. While existing solutions rely on\nnoise injection, regularization, or gradient clipping, we propose a novel\nsolution that purely controls the $l^p$ training norm to mitigate CO.\n  Our study is motivated by the empirical observation that CO is more prevalent\nunder the $l^{\\infty}$ norm than the $l^2$ norm. Leveraging this insight, we\ndevelop a framework for generalized $l^p$ attack as a fixed point problem and\ncraft $l^p$-FGSM attacks to understand the transition mechanics from $l^2$ to\n$l^{\\infty}$. This leads to our core insight: CO emerges when highly\nconcentrated gradients where information localizes in few dimensions interact\nwith aggressive norm constraints. By quantifying gradient concentration through\nParticipation Ratio and entropy measures, we develop an adaptive $l^p$-FGSM\nthat automatically tunes the training norm based on gradient information.\nExtensive experiments demonstrate that this approach achieves strong robustness\nwithout requiring additional regularization or noise injection, providing a\nnovel and theoretically-principled pathway to mitigate the CO problem.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02360v1",
    "published_date": "2025-05-05 04:41:21 UTC",
    "updated_date": "2025-05-05 04:41:21 UTC"
  },
  {
    "arxiv_id": "2505.02352v1",
    "title": "Social Biases in Knowledge Representations of Wikidata separates Global North from Global South",
    "authors": [
      "Paramita Das",
      "Sai Keerthana Karnam",
      "Aditya Soni",
      "Animesh Mukherjee"
    ],
    "abstract": "Knowledge Graphs have become increasingly popular due to their wide usage in\nvarious downstream applications, including information retrieval, chatbot\ndevelopment, language model construction, and many others. Link prediction (LP)\nis a crucial downstream task for knowledge graphs, as it helps to address the\nproblem of the incompleteness of the knowledge graphs. However, previous\nresearch has shown that knowledge graphs, often created in a (semi) automatic\nmanner, are not free from social biases. These biases can have harmful effects\non downstream applications, especially by leading to unfair behavior toward\nminority groups. To understand this issue in detail, we develop a framework --\nAuditLP -- deploying fairness metrics to identify biased outcomes in LP,\nspecifically how occupations are classified as either male or female-dominated\nbased on gender as a sensitive attribute. We have experimented with the\nsensitive attribute of age and observed that occupations are categorized as\nyoung-biased, old-biased, and age-neutral. We conduct our experiments on a\nlarge number of knowledge triples that belong to 21 different geographies\nextracted from the open-sourced knowledge graph, Wikidata. Our study shows that\nthe variance in the biased outcomes across geographies neatly mirrors the\nsocio-economic and cultural division of the world, resulting in a transparent\npartition of the Global North from the Global South.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2505.02352v1",
    "published_date": "2025-05-05 04:21:12 UTC",
    "updated_date": "2025-05-05 04:21:12 UTC"
  },
  {
    "arxiv_id": "2505.03838v2",
    "title": "IntelliCardiac: An Intelligent Platform for Cardiac Image Segmentation and Classification",
    "authors": [
      "Ting Yu Tsai",
      "An Yu",
      "Meghana Spurthi Maadugundu",
      "Ishrat Jahan Mohima",
      "Umme Habiba Barsha",
      "Mei-Hwa F. Chen",
      "Balakrishnan Prabhakaran",
      "Ming-Ching Chang"
    ],
    "abstract": "Precise and effective processing of cardiac imaging data is critical for the\nidentification and management of the cardiovascular diseases. We introduce\nIntelliCardiac, a comprehensive, web-based medical image processing platform\nfor the automatic segmentation of 4D cardiac images and disease classification,\nutilizing an AI model trained on the publicly accessible ACDC dataset. The\nsystem, intended for patients, cardiologists, and healthcare professionals,\noffers an intuitive interface and uses deep learning models to identify\nessential heart structures and categorize cardiac diseases. The system supports\nanalysis of both the right and left ventricles as well as myocardium, and then\nclassifies patient's cardiac images into five diagnostic categories: dilated\ncardiomyopathy, myocardial infarction, hypertrophic cardiomyopathy, right\nventricular abnormality, and no disease. IntelliCardiac combines a deep\nlearning-based segmentation model with a two-step classification pipeline. The\nsegmentation module gains an overall accuracy of 92.6%. The classification\nmodule, trained on characteristics taken from segmented heart structures,\nachieves 98% accuracy in five categories. These results exceed the performance\nof the existing state-of-the-art methods that integrate both segmentation and\nclassification models. IntelliCardiac, which supports real-time visualization,\nworkflow integration, and AI-assisted diagnostics, has great potential as a\nscalable, accurate tool for clinical decision assistance in cardiac imaging and\ndiagnosis.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.03838v2",
    "published_date": "2025-05-05 04:09:31 UTC",
    "updated_date": "2025-05-08 01:21:21 UTC"
  },
  {
    "arxiv_id": "2505.02347v2",
    "title": "Temporal Robustness in Discrete Time Linear Dynamical Systems",
    "authors": [
      "Nilava Metya",
      "Arunesh Sinha"
    ],
    "abstract": "Discrete time linear dynamical systems, including Markov chains, have found\nmany applications. However, in some problems, there is uncertainty about the\ntime horizon for which the system runs. This creates uncertainty about the cost\n(or reward) incurred based on the state distribution when the system stops.\nGiven past data samples of how long a system ran, we propose to theoretically\nanalyze a distributional robust cost estimation task in a Wasserstein ambiguity\nset, instead of learning a probability distribution from a few samples. Towards\nthis, we show an equivalence between a discrete time Markov Chain on a\nprobability simplex and a global asymptotic stable (GAS) discrete time linear\ndynamical system, allowing us to base our study on a GAS system only. Then, we\nprovide various polynomial time algorithms and hardness results for different\ncases in our theoretical study, including a fundamental result about\nWasserstein distance based polytope.",
    "categories": [
      "math.OC",
      "cs.AI"
    ],
    "primary_category": "math.OC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02347v2",
    "published_date": "2025-05-05 04:02:33 UTC",
    "updated_date": "2025-05-21 20:54:47 UTC"
  },
  {
    "arxiv_id": "2505.02877v1",
    "title": "A Wireless Collaborated Inference Acceleration Framework for Plant Disease Recognition",
    "authors": [
      "Hele Zhu",
      "Xinyi Huang",
      "Haojia Gao",
      "Mengfei Jiang",
      "Haohua Que",
      "Lei Mu"
    ],
    "abstract": "Plant disease is a critical factor affecting agricultural production.\nTraditional manual recognition methods face significant drawbacks, including\nlow accuracy, high costs, and inefficiency. Deep learning techniques have\ndemonstrated significant benefits in identifying plant diseases, but they still\nface challenges such as inference delays and high energy consumption. Deep\nlearning algorithms are difficult to run on resource-limited embedded devices.\nOffloading these models to cloud servers is confronted with the restriction of\ncommunication bandwidth, and all of these factors will influence the\ninference's efficiency. We propose a collaborative inference framework for\nrecognizing plant diseases between edge devices and cloud servers to enhance\ninference speed. The DNN model for plant disease recognition is pruned through\ndeep reinforcement learning to improve the inference speed and reduce energy\nconsumption. Then the optimal split point is determined by a greedy strategy to\nachieve the best collaborated inference acceleration. Finally, the system for\ncollaborative inference acceleration in plant disease recognition has been\nimplemented using Gradio to facilitate friendly human-machine interaction.\nExperiments indicate that the proposed collaborative inference framework\nsignificantly increases inference speed while maintaining acceptable\nrecognition accuracy, offering a novel solution for rapidly diagnosing and\npreventing plant diseases.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02877v1",
    "published_date": "2025-05-05 03:17:32 UTC",
    "updated_date": "2025-05-05 03:17:32 UTC"
  },
  {
    "arxiv_id": "2505.02322v1",
    "title": "HyperTree Planning: Enhancing LLM Reasoning via Hierarchical Thinking",
    "authors": [
      "Runquan Gui",
      "Zhihai Wang",
      "Jie Wang",
      "Chi Ma",
      "Huiling Zhen",
      "Mingxuan Yuan",
      "Jianye Hao",
      "Defu Lian",
      "Enhong Chen",
      "Feng Wu"
    ],
    "abstract": "Recent advancements have significantly enhanced the performance of large\nlanguage models (LLMs) in tackling complex reasoning tasks, achieving notable\nsuccess in domains like mathematical and logical reasoning. However, these\nmethods encounter challenges with complex planning tasks, primarily due to\nextended reasoning steps, diverse constraints, and the challenge of handling\nmultiple distinct sub-tasks. To address these challenges, we propose HyperTree\nPlanning (HTP), a novel reasoning paradigm that constructs hypertree-structured\nplanning outlines for effective planning. The hypertree structure enables LLMs\nto engage in hierarchical thinking by flexibly employing the divide-and-conquer\nstrategy, effectively breaking down intricate reasoning steps, accommodating\ndiverse constraints, and managing multiple distinct sub-tasks in a\nwell-organized manner. We further introduce an autonomous planning framework\nthat completes the planning process by iteratively refining and expanding the\nhypertree-structured planning outlines. Experiments demonstrate the\neffectiveness of HTP, achieving state-of-the-art accuracy on the TravelPlanner\nbenchmark with Gemini-1.5-Pro, resulting in a 3.6 times performance improvement\nover o1-preview.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "arXiv admin note: text overlap with arXiv:2406.14228 by other authors",
    "pdf_url": "http://arxiv.org/pdf/2505.02322v1",
    "published_date": "2025-05-05 02:38:58 UTC",
    "updated_date": "2025-05-05 02:38:58 UTC"
  },
  {
    "arxiv_id": "2505.04642v1",
    "title": "Rethinking Multimodal Sentiment Analysis: A High-Accuracy, Simplified Fusion Architecture",
    "authors": [
      "Nischal Mandal",
      "Yang Li"
    ],
    "abstract": "Multimodal sentiment analysis, a pivotal task in affective computing, seeks\nto understand human emotions by integrating cues from language, audio, and\nvisual signals. While many recent approaches leverage complex attention\nmechanisms and hierarchical architectures, we propose a lightweight, yet\neffective fusion-based deep learning model tailored for utterance-level emotion\nclassification. Using the benchmark IEMOCAP dataset, which includes aligned\ntext, audio-derived numeric features, and visual descriptors, we design a\nmodality-specific encoder using fully connected layers followed by dropout\nregularization. The modality-specific representations are then fused using\nsimple concatenation and passed through a dense fusion layer to capture\ncross-modal interactions. This streamlined architecture avoids computational\noverhead while preserving performance, achieving a classification accuracy of\n92% across six emotion categories. Our approach demonstrates that with careful\nfeature engineering and modular design, simpler fusion strategies can\noutperform or match more complex models, particularly in resource-constrained\nenvironments.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04642v1",
    "published_date": "2025-05-05 02:31:11 UTC",
    "updated_date": "2025-05-05 02:31:11 UTC"
  },
  {
    "arxiv_id": "2505.02314v1",
    "title": "NeuroSim V1.5: Improved Software Backbone for Benchmarking Compute-in-Memory Accelerators with Device and Circuit-level Non-idealities",
    "authors": [
      "James Read",
      "Ming-Yen Lee",
      "Wei-Hsing Huang",
      "Yuan-Chun Luo",
      "Anni Lu",
      "Shimeng Yu"
    ],
    "abstract": "The exponential growth of artificial intelligence (AI) applications has\nexposed the inefficiency of conventional von Neumann architectures, where\nfrequent data transfers between compute units and memory create significant\nenergy and latency bottlenecks. Analog Computing-in-Memory (ACIM) addresses\nthis challenge by performing multiply-accumulate (MAC) operations directly in\nthe memory arrays, substantially reducing data movement. However, designing\nrobust ACIM accelerators requires accurate modeling of device- and\ncircuit-level non-idealities. In this work, we present NeuroSim V1.5,\nintroducing several key advances: (1) seamless integration with TensorRT's\npost-training quantization flow enabling support for more neural networks\nincluding transformers, (2) a flexible noise injection methodology built on\npre-characterized statistical models, making it straightforward to incorporate\ndata from SPICE simulations or silicon measurements, (3) expanded device\nsupport including emerging non-volatile capacitive memories, and (4) up to 6.5x\nfaster runtime than NeuroSim V1.4 through optimized behavioral simulation. The\ncombination of these capabilities uniquely enables systematic design space\nexploration across both accuracy and hardware efficiency metrics. Through\nmultiple case studies, we demonstrate optimization of critical design\nparameters while maintaining network accuracy. By bridging high-fidelity noise\nmodeling with efficient simulation, NeuroSim V1.5 advances the design and\nvalidation of next-generation ACIM accelerators. All NeuroSim versions are\navailable open-source at https://github.com/neurosim/NeuroSim.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AR",
    "comment": "15 pages, 9 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2505.02314v1",
    "published_date": "2025-05-05 02:07:04 UTC",
    "updated_date": "2025-05-05 02:07:04 UTC"
  },
  {
    "arxiv_id": "2505.02313v1",
    "title": "What Is AI Safety? What Do We Want It to Be?",
    "authors": [
      "Jacqueline Harding",
      "Cameron Domenico Kirk-Giannini"
    ],
    "abstract": "The field of AI safety seeks to prevent or reduce the harms caused by AI\nsystems. A simple and appealing account of what is distinctive of AI safety as\na field holds that this feature is constitutive: a research project falls\nwithin the purview of AI safety just in case it aims to prevent or reduce the\nharms caused by AI systems. Call this appealingly simple account The Safety\nConception of AI safety. Despite its simplicity and appeal, we argue that The\nSafety Conception is in tension with at least two trends in the ways AI safety\nresearchers and organizations think and talk about AI safety: first, a tendency\nto characterize the goal of AI safety research in terms of catastrophic risks\nfrom future systems; second, the increasingly popular idea that AI safety can\nbe thought of as a branch of safety engineering. Adopting the methodology of\nconceptual engineering, we argue that these trends are unfortunate: when we\nconsider what concept of AI safety it would be best to have, there are\ncompelling reasons to think that The Safety Conception is the answer.\nDescriptively, The Safety Conception allows us to see how work on topics that\nhave historically been treated as central to the field of AI safety is\ncontinuous with work on topics that have historically been treated as more\nmarginal, like bias, misinformation, and privacy. Normatively, taking The\nSafety Conception seriously means approaching all efforts to prevent or\nmitigate harms from AI systems based on their merits rather than drawing\narbitrary distinctions between them.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02313v1",
    "published_date": "2025-05-05 01:55:00 UTC",
    "updated_date": "2025-05-05 01:55:00 UTC"
  },
  {
    "arxiv_id": "2505.02309v2",
    "title": "Optimizing LLMs for Resource-Constrained Environments: A Survey of Model Compression Techniques",
    "authors": [
      "Sanjay Surendranath Girija",
      "Shashank Kapoor",
      "Lakshit Arora",
      "Dipen Pradhan",
      "Aman Raj",
      "Ankit Shetgaonkar"
    ],
    "abstract": "Large Language Models (LLMs) have revolutionized many areas of artificial\nintelligence (AI), but their substantial resource requirements limit their\ndeployment on mobile and edge devices. This survey paper provides a\ncomprehensive overview of techniques for compressing LLMs to enable efficient\ninference in resource-constrained environments. We examine three primary\napproaches: Knowledge Distillation, Model Quantization, and Model Pruning. For\neach technique, we discuss the underlying principles, present different\nvariants, and provide examples of successful applications. We also briefly\ndiscuss complementary techniques such as mixture-of-experts and early-exit\nstrategies. Finally, we highlight promising future directions, aiming to\nprovide a valuable resource for both researchers and practitioners seeking to\noptimize LLMs for edge deployment.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to IEEE COMPSAC 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.02309v2",
    "published_date": "2025-05-05 01:27:47 UTC",
    "updated_date": "2025-05-08 05:55:48 UTC"
  },
  {
    "arxiv_id": "2505.06264v1",
    "title": "Prediction of Delirium Risk in Mild Cognitive Impairment Using Time-Series data, Machine Learning and Comorbidity Patterns -- A Retrospective Study",
    "authors": [
      "Santhakumar Ramamoorthy",
      "Priya Rani",
      "James Mahon",
      "Glenn Mathews",
      "Shaun Cloherty",
      "Mahdi Babaei"
    ],
    "abstract": "Delirium represents a significant clinical concern characterized by high\nmorbidity and mortality rates, particularly in patients with mild cognitive\nimpairment (MCI). This study investigates the associated risk factors for\ndelirium by analyzing the comorbidity patterns relevant to MCI and developing a\nlongitudinal predictive model leveraging machine learning methodologies. A\nretrospective analysis utilizing the MIMIC-IV v2.2 database was performed to\nevaluate comorbid conditions, survival probabilities, and predictive modeling\noutcomes. The examination of comorbidity patterns identified distinct risk\nprofiles for the MCI population. Kaplan-Meier survival analysis demonstrated\nthat individuals with MCI exhibit markedly reduced survival probabilities when\ndeveloping delirium compared to their non-MCI counterparts, underscoring the\nheightened vulnerability within this cohort. For predictive modeling, a Long\nShort-Term Memory (LSTM) ML network was implemented utilizing time-series data,\ndemographic variables, Charlson Comorbidity Index (CCI) scores, and an array of\ncomorbid conditions. The model demonstrated robust predictive capabilities with\nan AUROC of 0.93 and an AUPRC of 0.92. This study underscores the critical role\nof comorbidities in evaluating delirium risk and highlights the efficacy of\ntime-series predictive modeling in pinpointing patients at elevated risk for\ndelirium development.",
    "categories": [
      "stat.AP",
      "cs.AI"
    ],
    "primary_category": "stat.AP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.06264v1",
    "published_date": "2025-05-05 01:21:31 UTC",
    "updated_date": "2025-05-05 01:21:31 UTC"
  },
  {
    "arxiv_id": "2505.02306v4",
    "title": "SafeMate: A Modular RAG-Based Agent for Context-Aware Emergency Guidance",
    "authors": [
      "Junfeng Jiao",
      "Jihyung Park",
      "Yiming Xu",
      "Kristen Sussman",
      "Lucy Atkinson"
    ],
    "abstract": "Despite the abundance of public safety documents and emergency protocols,\nmost individuals remain ill-equipped to interpret and act on such information\nduring crises. Traditional emergency decision support systems (EDSS) are\ndesigned for professionals and rely heavily on static documents like PDFs or\nSOPs, which are difficult for non-experts to navigate under stress. This gap\nbetween institutional knowledge and public accessibility poses a critical\nbarrier to effective emergency preparedness and response. We introduce\nSafeMate, a retrieval-augmented AI assistant that delivers accurate,\ncontext-aware guidance to general users in both preparedness and active\nemergency scenarios. Built on the Model Context Protocol (MCP), SafeMate\ndynamically routes user queries to tools for document retrieval, checklist\ngeneration, and structured summarization. It uses FAISS with cosine similarity\nto identify relevant content from trusted sources.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02306v4",
    "published_date": "2025-05-05 01:09:02 UTC",
    "updated_date": "2025-05-19 15:39:14 UTC"
  },
  {
    "arxiv_id": "2505.02299v1",
    "title": "Adaptive Scoring and Thresholding with Human Feedback for Robust Out-of-Distribution Detection",
    "authors": [
      "Daisuke Yamada",
      "Harit Vishwakarma",
      "Ramya Korlakai Vinayak"
    ],
    "abstract": "Machine Learning (ML) models are trained on in-distribution (ID) data but\noften encounter out-of-distribution (OOD) inputs during deployment -- posing\nserious risks in safety-critical domains. Recent works have focused on\ndesigning scoring functions to quantify OOD uncertainty, with score thresholds\ntypically set based solely on ID data to achieve a target true positive rate\n(TPR), since OOD data is limited before deployment. However, these TPR-based\nthresholds leave false positive rates (FPR) uncontrolled, often resulting in\nhigh FPRs where OOD points are misclassified as ID. Moreover, fixed scoring\nfunctions and thresholds lack the adaptivity needed to handle newly observed,\nevolving OOD inputs, leading to sub-optimal performance. To address these\nchallenges, we propose a human-in-the-loop framework that \\emph{safely updates\nboth scoring functions and thresholds on the fly} based on real-world OOD\ninputs. Our method maximizes TPR while strictly controlling FPR at all times,\neven as the system adapts over time. We provide theoretical guarantees for FPR\ncontrol under stationary conditions and present extensive empirical evaluations\non OpenOOD benchmarks to demonstrate that our approach outperforms existing\nmethods by achieving higher TPRs while maintaining FPR control.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.02299v1",
    "published_date": "2025-05-05 00:25:14 UTC",
    "updated_date": "2025-05-05 00:25:14 UTC"
  }
]