[
  {
    "arxiv_id": "2409.07656v1",
    "title": "Passed the Turing Test: Living in Turing Futures",
    "authors": [
      "Bernardo Gon√ßalves"
    ],
    "abstract": "The world has seen the emergence of machines based on pretrained models,\ntransformers, also known as generative artificial intelligences for their\nability to produce various types of content, including text, images, audio, and\nsynthetic data. Without resorting to preprogramming or special tricks, their\nintelligence grows as they learn from experience, and to ordinary people, they\ncan appear human-like in conversation. This means that they can pass the Turing\ntest, and that we are now living in one of many possible Turing futures where\nmachines can pass for what they are not. However, the learning machines that\nTuring imagined would pass his imitation tests were machines inspired by the\nnatural development of the low-energy human cortex. They would be raised like\nhuman children and naturally learn the ability to deceive an observer. These\n``child machines,'' Turing hoped, would be powerful enough to have an impact on\nsociety and nature.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "Author's version. Forthcoming in Intelligent Computing, a Science\n  Partner Journal published in affiliation with Zhejiang Lab\n  (https://spj.science.org/journal/icomputing). First submitted 19 Feb 2024.\n  Revised 16 Jul 2024. Accepted 15 Aug 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.07656v1",
    "published_date": "2024-09-11 22:56:30 UTC",
    "updated_date": "2024-09-11 22:56:30 UTC"
  },
  {
    "arxiv_id": "2409.07645v1",
    "title": "Feature Importance in Pedestrian Intention Prediction: A Context-Aware Review",
    "authors": [
      "Mohsen Azarmi",
      "Mahdi Rezaei",
      "He Wang",
      "Ali Arabian"
    ],
    "abstract": "Recent advancements in predicting pedestrian crossing intentions for\nAutonomous Vehicles using Computer Vision and Deep Neural Networks are\npromising. However, the black-box nature of DNNs poses challenges in\nunderstanding how the model works and how input features contribute to final\npredictions. This lack of interpretability delimits the trust in model\nperformance and hinders informed decisions on feature selection,\nrepresentation, and model optimisation; thereby affecting the efficacy of\nfuture research in the field. To address this, we introduce Context-aware\nPermutation Feature Importance (CAPFI), a novel approach tailored for\npedestrian intention prediction. CAPFI enables more interpretability and\nreliable assessments of feature importance by leveraging subdivided scenario\ncontexts, mitigating the randomness of feature values through targeted\nshuffling. This aims to reduce variance and prevent biased estimations in\nimportance scores during permutations. We divide the Pedestrian Intention\nEstimation (PIE) dataset into 16 comparable context sets, measure the baseline\nperformance of five distinct neural network architectures for intention\nprediction in each context, and assess input feature importance using CAPFI. We\nobserved nuanced differences among models across various contextual\ncharacteristics. The research reveals the critical role of pedestrian bounding\nboxes and ego-vehicle speed in predicting pedestrian intentions, and potential\nprediction biases due to the speed feature through cross-context permutation\nevaluation. We propose an alternative feature representation by considering\nproximity change rate for rendering dynamic pedestrian-vehicle locomotion,\nthereby enhancing the contributions of input features to intention prediction.\nThese findings underscore the importance of contextual features and their\ndiversity to develop accurate and robust intent-predictive models.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.RO",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.07645v1",
    "published_date": "2024-09-11 22:13:01 UTC",
    "updated_date": "2024-09-11 22:13:01 UTC"
  },
  {
    "arxiv_id": "2409.07638v2",
    "title": "Can We Count on LLMs? The Fixed-Effect Fallacy and Claims of GPT-4 Capabilities",
    "authors": [
      "Thomas Ball",
      "Shuo Chen",
      "Cormac Herley"
    ],
    "abstract": "In this paper we explore evaluation of LLM capabilities. We present\nmeasurements of GPT-4 performance on several deterministic tasks; each task\ninvolves a basic calculation and takes as input parameter some element drawn\nfrom a large well-defined population (e.g., count elements in a list, multiply\ntwo k-digit numbers, etc). We examine several conditions per-task and perform\nenough trials so that statistically significant differences can be detected.\nThis allows us to investigate the sensitivity of task-accuracy both to query\nphrasing and input parameter population. We find that seemingly trivial\nmodifications in the task-prompt or input population can yield differences far\nlarger than can be explained by sampling effects. For example, performance on a\nsimple list-counting task varies with query-phrasing and list-length, but also\nwith list composition (i.e., the thing-to-be-counted) and object frequency\n(e.g., success when an element accounts for $\\approx$ 50\\% of a list is\ndifferent from when it accounts for $\\approx$ 70\\% etc).\n  We conclude that efforts to quantify LLM capabilities easily succumb to the\nlanguage-as-fixed-effect fallacy, where experimental observations are\nimproperly generalized beyond what the data supports. A consequence appears to\nbe that intuitions that have been formed based on interactions with humans form\na very unreliable guide as to which input modifications should ``make no\ndifference'' to LLM performance.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.07638v2",
    "published_date": "2024-09-11 21:48:33 UTC",
    "updated_date": "2024-09-24 17:34:07 UTC"
  },
  {
    "arxiv_id": "2409.07637v1",
    "title": "Weather-Informed Probabilistic Forecasting and Scenario Generation in Power Systems",
    "authors": [
      "Hanyu Zhang",
      "Reza Zandehshahvar",
      "Mathieu Tanneau",
      "Pascal Van Hentenryck"
    ],
    "abstract": "The integration of renewable energy sources (RES) into power grids presents\nsignificant challenges due to their intrinsic stochasticity and uncertainty,\nnecessitating the development of new techniques for reliable and efficient\nforecasting. This paper proposes a method combining probabilistic forecasting\nand Gaussian copula for day-ahead prediction and scenario generation of load,\nwind, and solar power in high-dimensional contexts. By incorporating weather\ncovariates and restoring spatio-temporal correlations, the proposed method\nenhances the reliability of probabilistic forecasts in RES. Extensive numerical\nexperiments compare the effectiveness of different time series models, with\nperformance evaluated using comprehensive metrics on a real-world and\nhigh-dimensional dataset from Midcontinent Independent System Operator (MISO).\nThe results highlight the importance of weather information and demonstrate the\nefficacy of the Gaussian copula in generating realistic scenarios, with the\nproposed weather-informed Temporal Fusion Transformer (WI-TFT) model showing\nsuperior performance.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "stat.AP"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.07637v1",
    "published_date": "2024-09-11 21:44:59 UTC",
    "updated_date": "2024-09-11 21:44:59 UTC"
  },
  {
    "arxiv_id": "2409.13746v2",
    "title": "Mapping Biomedical Ontology Terms to IDs: Effect of Domain Prevalence on Prediction Accuracy",
    "authors": [
      "Thanh Son Do",
      "Daniel B. Hier",
      "Tayo Obafemi-Ajayi"
    ],
    "abstract": "This study evaluates the ability of large language models (LLMs) to map\nbiomedical ontology terms to their corresponding ontology IDs across the Human\nPhenotype Ontology (HPO), Gene Ontology (GO), and UniProtKB terminologies.\nUsing counts of ontology IDs in the PubMed Central (PMC) dataset as a surrogate\nfor their prevalence in the biomedical literature, we examined the relationship\nbetween ontology ID prevalence and mapping accuracy. Results indicate that\nontology ID prevalence strongly predicts accurate mapping of HPO terms to HPO\nIDs, GO terms to GO IDs, and protein names to UniProtKB accession numbers.\nHigher prevalence of ontology IDs in the biomedical literature correlated with\nhigher mapping accuracy. Predictive models based on receiver operating\ncharacteristic (ROC) curves confirmed this relationship.\n  In contrast, this pattern did not apply to mapping protein names to Human\nGenome Organisation's (HUGO) gene symbols. GPT-4 achieved a high baseline\nperformance (95%) in mapping protein names to HUGO gene symbols, with mapping\naccuracy unaffected by prevalence. We propose that the high prevalence of HUGO\ngene symbols in the literature has caused these symbols to become lexicalized,\nenabling GPT-4 to map protein names to HUGO gene symbols with high accuracy.\nThese findings highlight the limitations of LLMs in mapping ontology terms to\nlow-prevalence ontology IDs and underscore the importance of incorporating\nontology ID prevalence into the training and evaluation of LLMs for biomedical\napplications.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2"
    ],
    "primary_category": "cs.CL",
    "comment": "Presented at 2025 IEEE Conference on Artificial Intelligence (CAI).\n  Santa Clara, CA. May 5, 2025",
    "pdf_url": "http://arxiv.org/pdf/2409.13746v2",
    "published_date": "2024-09-11 21:34:46 UTC",
    "updated_date": "2025-05-12 15:43:37 UTC"
  },
  {
    "arxiv_id": "2409.07629v3",
    "title": "Dividable Configuration Performance Learning",
    "authors": [
      "Jingzhi Gong",
      "Tao Chen",
      "Rami Bahsoon"
    ],
    "abstract": "Machine/deep learning models have been widely adopted for predicting the\nconfiguration performance of software systems. However, a crucial yet\nunaddressed challenge is how to cater for the sparsity inherited from the\nconfiguration landscape: the influence of configuration options (features) and\nthe distribution of data samples are highly sparse. In this paper, we propose a\nmodel-agnostic and sparsity-robust framework for predicting configuration\nperformance, dubbed DaL, based on the new paradigm of dividable learning that\nbuilds a model via \"divide-and-learn\". To handle sample sparsity, the samples\nfrom the configuration landscape are divided into distant divisions, for each\nof which we build a sparse local model, e.g., regularized Hierarchical\nInteraction Neural Network, to deal with the feature sparsity. A newly given\nconfiguration would then be assigned to the right model of division for the\nfinal prediction. Further, DaL adaptively determines the optimal number of\ndivisions required for a system and sample size without any extra training or\nprofiling. Experiment results from 12 real-world systems and five sets of\ntraining data reveal that, compared with the state-of-the-art approaches, DaL\nperforms no worse than the best counterpart on 44 out of 60 cases with up to\n1.61x improvement on accuracy; requires fewer samples to reach the same/better\naccuracy; and producing acceptable training overhead. In particular, the\nmechanism that adapted the parameter d can reach the optimal value for 76.43%\nof the individual runs. The result also confirms that the paradigm of dividable\nlearning is more suitable than other similar paradigms such as ensemble\nlearning for predicting configuration performance. Practically, DaL\nconsiderably improves different global models when using them as the underlying\nlocal models, which further strengthens its flexibility.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted by TSE in October 2024. arXiv admin note: substantial text\n  overlap with arXiv:2407.02706, arXiv:2306.06651",
    "pdf_url": "http://arxiv.org/pdf/2409.07629v3",
    "published_date": "2024-09-11 21:23:23 UTC",
    "updated_date": "2024-11-20 12:40:11 UTC"
  },
  {
    "arxiv_id": "2409.07619v1",
    "title": "Ensemble Methods for Sequence Classification with Hidden Markov Models",
    "authors": [
      "Maxime Kawawa-Beaudan",
      "Srijan Sood",
      "Soham Palande",
      "Ganapathy Mani",
      "Tucker Balch",
      "Manuela Veloso"
    ],
    "abstract": "We present a lightweight approach to sequence classification using Ensemble\nMethods for Hidden Markov Models (HMMs). HMMs offer significant advantages in\nscenarios with imbalanced or smaller datasets due to their simplicity,\ninterpretability, and efficiency. These models are particularly effective in\ndomains such as finance and biology, where traditional methods struggle with\nhigh feature dimensionality and varied sequence lengths. Our ensemble-based\nscoring method enables the comparison of sequences of any length and improves\nperformance on imbalanced datasets.\n  This study focuses on the binary classification problem, particularly in\nscenarios with data imbalance, where the negative class is the majority (e.g.,\nnormal data) and the positive class is the minority (e.g., anomalous data),\noften with extreme distribution skews. We propose a novel training approach for\nHMM Ensembles that generalizes to multi-class problems and supports\nclassification and anomaly detection. Our method fits class-specific groups of\ndiverse models using random data subsets, and compares likelihoods across\nclasses to produce composite scores, achieving high average precisions and\nAUCs.\n  In addition, we compare our approach with neural network-based methods such\nas Convolutional Neural Networks (CNNs) and Long Short-Term Memory networks\n(LSTMs), highlighting the efficiency and robustness of HMMs in data-scarce\nenvironments. Motivated by real-world use cases, our method demonstrates robust\nperformance across various benchmarks, offering a flexible framework for\ndiverse applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.07619v1",
    "published_date": "2024-09-11 20:59:32 UTC",
    "updated_date": "2024-09-11 20:59:32 UTC"
  },
  {
    "arxiv_id": "2409.07618v1",
    "title": "Understanding Foundation Models: Are We Back in 1924?",
    "authors": [
      "Alan F. Smeaton"
    ],
    "abstract": "This position paper explores the rapid development of Foundation Models (FMs)\nin AI and their implications for intelligence and reasoning. It examines the\ncharacteristics of FMs, including their training on vast datasets and use of\nembedding spaces to capture semantic relationships. The paper discusses recent\nadvancements in FMs' reasoning abilities which we argue cannot be attributed to\nincreased model size but to novel training techniques which yield learning\nphenomena like grokking. It also addresses the challenges in benchmarking FMs\nand compares their structure to the human brain. We argue that while FMs show\npromising developments in reasoning and knowledge representation, understanding\ntheir inner workings remains a significant challenge, similar to ongoing\nefforts in neuroscience to comprehend human brain function. Despite having some\nsimilarities, fundamental differences between FMs and the structure of human\nbrain warn us against making direct comparisons or expecting neuroscience to\nprovide immediate insights into FM function.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "7 pages, 4 Figures, to appear in Proceedings of the 2nd International\n  Conference on Foundation and Large Language Models (FLLM2024) 26-29 November,\n  2024, Dubai, UAE",
    "pdf_url": "http://arxiv.org/pdf/2409.07618v1",
    "published_date": "2024-09-11 20:59:27 UTC",
    "updated_date": "2024-09-11 20:59:27 UTC"
  },
  {
    "arxiv_id": "2409.12170v1",
    "title": "The Unreliability of Acoustic Systems in Alzheimer's Speech Datasets with Heterogeneous Recording Conditions",
    "authors": [
      "Lara Gauder",
      "Pablo Riera",
      "Andrea Slachevsky",
      "Gonzalo Forno",
      "Adolfo M. Garcia",
      "Luciana Ferrer"
    ],
    "abstract": "Automated speech analysis is a thriving approach to detect early markers of\nAlzheimer's disease (AD). Yet, recording conditions in most AD datasets are\nheterogeneous, with patients and controls often evaluated in different acoustic\nsettings. While this is not a problem for analyses based on speech\ntranscription or features obtained from manual alignment, it does cast serious\ndoubts on the validity of acoustic features, which are strongly influenced by\nacquisition conditions. We examined this issue in the ADreSSo dataset, derived\nfrom the widely used Pitt corpus. We show that systems based on two acoustic\nfeatures, MFCCs and Wav2vec 2.0 embeddings, can discriminate AD patients from\ncontrols with above-chance performance when using only the non-speech part of\nthe audio signals. We replicated this finding in a separate dataset of Spanish\nspeakers. Thus, in these datasets, the class can be partly predicted by\nrecording conditions. Our results are a warning against the use of acoustic\nsystems for identifying patients based on non-standardized recordings. We\npropose that acoustically heterogeneous datasets for dementia studies should be\neither (a) analyzed using only transcripts or other features derived from\nmanual annotations, or (b) replaced by datasets collected with strictly\ncontrolled acoustic conditions.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "5 pages, 1 figure, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2409.12170v1",
    "published_date": "2024-09-11 20:50:45 UTC",
    "updated_date": "2024-09-11 20:50:45 UTC"
  },
  {
    "arxiv_id": "2409.07606v3",
    "title": "The Role of Deep Learning Regularizations on Actors in Offline RL",
    "authors": [
      "Denis Tarasov",
      "Anja Surina",
      "Caglar Gulcehre"
    ],
    "abstract": "Deep learning regularization techniques, such as dropout, layer\nnormalization, or weight decay, are widely adopted in the construction of\nmodern artificial neural networks, often resulting in more robust training\nprocesses and improved generalization capabilities. However, in the domain of\nReinforcement Learning (RL), the application of these techniques has been\nlimited, usually applied to value function estimators (Hiraoka et al., 2021;\nSmith et al., 2022), and may result in detrimental effects. This issue is even\nmore pronounced in offline RL settings, which bear greater similarity to\nsupervised learning but have received less attention. Recent work in continuous\noffline RL (Park et al., 2024) has demonstrated that while we can build\nsufficiently powerful critic networks, the generalization of actor networks\nremains a bottleneck. In this study, we empirically show that applying standard\nregularization techniques to actor networks in offline RL actor-critic\nalgorithms yields improvements of 6% on average across two algorithms and three\ndifferent continuous D4RL domains.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "https://github.com/DT6A/ActoReg",
    "pdf_url": "http://arxiv.org/pdf/2409.07606v3",
    "published_date": "2024-09-11 20:35:29 UTC",
    "updated_date": "2024-11-21 14:35:28 UTC"
  },
  {
    "arxiv_id": "2409.07585v1",
    "title": "Efficient Localized Adaptation of Neural Weather Forecasting: A Case Study in the MENA Region",
    "authors": [
      "Muhammad Akhtar Munir",
      "Fahad Shahbaz Khan",
      "Salman Khan"
    ],
    "abstract": "Accurate weather and climate modeling is critical for both scientific\nadvancement and safeguarding communities against environmental risks.\nTraditional approaches rely heavily on Numerical Weather Prediction (NWP)\nmodels, which simulate energy and matter flow across Earth's systems. However,\nheavy computational requirements and low efficiency restrict the suitability of\nNWP, leading to a pressing need for enhanced modeling techniques. Neural\nnetwork-based models have emerged as promising alternatives, leveraging\ndata-driven approaches to forecast atmospheric variables. In this work, we\nfocus on limited-area modeling and train our model specifically for localized\nregion-level downstream tasks. As a case study, we consider the MENA region due\nto its unique climatic challenges, where accurate localized weather forecasting\nis crucial for managing water resources, agriculture and mitigating the impacts\nof extreme weather events. This targeted approach allows us to tailor the\nmodel's capabilities to the unique conditions of the region of interest. Our\nstudy aims to validate the effectiveness of integrating parameter-efficient\nfine-tuning (PEFT) methodologies, specifically Low-Rank Adaptation (LoRA) and\nits variants, to enhance forecast accuracy, as well as training speed,\ncomputational resource utilization, and memory efficiency in weather and\nclimate modeling for specific regions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.ao-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "Our codebase and pre-trained models can be accessed at: [this\n  url](https://github.com/akhtarvision/weather-regional)",
    "pdf_url": "http://arxiv.org/pdf/2409.07585v1",
    "published_date": "2024-09-11 19:31:56 UTC",
    "updated_date": "2024-09-11 19:31:56 UTC"
  },
  {
    "arxiv_id": "2409.07584v1",
    "title": "DS-ViT: Dual-Stream Vision Transformer for Cross-Task Distillation in Alzheimer's Early Diagnosis",
    "authors": [
      "Ke Chen",
      "Yifeng Wang",
      "Yufei Zhou",
      "Haohan Wang"
    ],
    "abstract": "In the field of Alzheimer's disease diagnosis, segmentation and\nclassification tasks are inherently interconnected. Sharing knowledge between\nmodels for these tasks can significantly improve training efficiency,\nparticularly when training data is scarce. However, traditional knowledge\ndistillation techniques often struggle to bridge the gap between segmentation\nand classification due to the distinct nature of tasks and different model\narchitectures. To address this challenge, we propose a dual-stream pipeline\nthat facilitates cross-task and cross-architecture knowledge sharing. Our\napproach introduces a dual-stream embedding module that unifies feature\nrepresentations from segmentation and classification models, enabling\ndimensional integration of these features to guide the classification model. We\nvalidated our method on multiple 3D datasets for Alzheimer's disease diagnosis,\ndemonstrating significant improvements in classification performance,\nespecially on small datasets. Furthermore, we extended our pipeline with a\nresidual temporal attention mechanism for early diagnosis, utilizing images\ntaken before the atrophy of patients' brain mass. This advancement shows\npromise in enabling diagnosis approximately six months earlier in mild and\nasymptomatic stages, offering critical time for intervention.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "68T07, 92C55 (Primary) 93C85 (Secondary)"
    ],
    "primary_category": "eess.IV",
    "comment": "8 pages, 3 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2409.07584v1",
    "published_date": "2024-09-11 19:31:01 UTC",
    "updated_date": "2024-09-11 19:31:01 UTC"
  },
  {
    "arxiv_id": "2409.07581v1",
    "title": "Violence detection in videos using deep recurrent and convolutional neural networks",
    "authors": [
      "Abdarahmane Traor√©",
      "Moulay A. Akhloufi"
    ],
    "abstract": "Violence and abnormal behavior detection research have known an increase of\ninterest in recent years, due mainly to a rise in crimes in large cities\nworldwide. In this work, we propose a deep learning architecture for violence\ndetection which combines both recurrent neural networks (RNNs) and\n2-dimensional convolutional neural networks (2D CNN). In addition to video\nframes, we use optical flow computed using the captured sequences. CNN extracts\nspatial characteristics in each frame, while RNN extracts temporal\ncharacteristics. The use of optical flow allows to encode the movements in the\nscenes. The proposed approaches reach the same level as the state-of-the-art\ntechniques and sometime surpass them. It was validated on 3 databases achieving\ngood results.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages, 7 figures, 2020 IEEE International Conference on Systems,\n  Man, and Cybernetics (SMC)",
    "pdf_url": "http://arxiv.org/pdf/2409.07581v1",
    "published_date": "2024-09-11 19:21:51 UTC",
    "updated_date": "2024-09-11 19:21:51 UTC"
  },
  {
    "arxiv_id": "2409.07578v3",
    "title": "A Novel Mathematical Framework for Objective Characterization of Ideas",
    "authors": [
      "B. Sankar",
      "Dibakar Sen"
    ],
    "abstract": "The demand for innovation in product design necessitates a prolific ideation\nphase. Conversational AI (CAI) systems that use Large Language Models (LLMs)\nsuch as GPT (Generative Pre-trained Transformer) have been shown to be fruitful\nin augmenting human creativity, providing numerous novel and diverse ideas.\nDespite the success in ideation quantity, the qualitative assessment of these\nideas remains challenging and traditionally reliant on expert human evaluation.\nThis method suffers from limitations such as human judgment errors, bias, and\noversight. Addressing this gap, our study introduces a comprehensive\nmathematical framework for automated analysis to objectively evaluate the\nplethora of ideas generated by CAI systems and/or humans. This framework is\nparticularly advantageous for novice designers who lack experience in selecting\npromising ideas. By converting the ideas into higher dimensional vectors and\nquantitatively measuring the diversity between them using tools such as UMAP,\nDBSCAN and PCA, the proposed method provides a reliable and objective way of\nselecting the most promising ideas, thereby enhancing the efficiency of the\nideation phase.",
    "categories": [
      "cs.AI",
      "53A45",
      "I.2.7; G.3"
    ],
    "primary_category": "cs.AI",
    "comment": "35 pages, 18 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2409.07578v3",
    "published_date": "2024-09-11 19:10:29 UTC",
    "updated_date": "2025-05-15 18:53:26 UTC"
  },
  {
    "arxiv_id": "2409.07569v3",
    "title": "A Comprehensive Survey on Inverse Constrained Reinforcement Learning: Definitions, Progress and Challenges",
    "authors": [
      "Guiliang Liu",
      "Sheng Xu",
      "Shicheng Liu",
      "Ashish Gaurav",
      "Sriram Ganapathi Subramanian",
      "Pascal Poupart"
    ],
    "abstract": "Inverse Constrained Reinforcement Learning (ICRL) is the task of inferring\nthe implicit constraints that expert agents adhere to, based on their\ndemonstration data. As an emerging research topic, ICRL has received\nconsiderable attention in recent years. This article presents a categorical\nsurvey of the latest advances in ICRL. It serves as a comprehensive reference\nfor machine learning researchers and practitioners, as well as starters seeking\nto comprehend the definitions, advancements, and important challenges in ICRL.\nWe begin by formally defining the problem and outlining the algorithmic\nframework that facilitates constraint inference across various scenarios. These\ninclude deterministic or stochastic environments, environments with limited\ndemonstrations, and multiple agents. For each context, we illustrate the\ncritical challenges and introduce a series of fundamental methods to tackle\nthese issues. This survey encompasses discrete, virtual, and realistic\nenvironments for evaluating ICRL agents. We also delve into the most pertinent\napplications of ICRL, such as autonomous driving, robot control, and sports\nanalytics. To stimulate continuing research, we conclude the survey with a\ndiscussion of key unresolved questions in ICRL that can effectively foster a\nbridge between theoretical understanding and practical industrial applications.\nThe papers referenced in this survey can be found at\nhttps://github.com/Jasonxu1225/Awesome-Constraint-Inference-in-RL.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "36 pages",
    "pdf_url": "http://arxiv.org/pdf/2409.07569v3",
    "published_date": "2024-09-11 18:49:03 UTC",
    "updated_date": "2025-02-01 03:57:57 UTC"
  },
  {
    "arxiv_id": "2409.07547v1",
    "title": "Machine Learning and Constraint Programming for Efficient Healthcare Scheduling",
    "authors": [
      "Aymen Ben Said",
      "Malek Mouhoub"
    ],
    "abstract": "Solving combinatorial optimization problems involve satisfying a set of hard\nconstraints while optimizing some objectives. In this context, exact or\napproximate methods can be used. While exact methods guarantee the optimal\nsolution, they often come with an exponential running time as opposed to\napproximate methods that trade the solutions quality for a better running time.\nIn this context, we tackle the Nurse Scheduling Problem (NSP). The NSP consist\nin assigning nurses to daily shifts within a planning horizon such that\nworkload constraints are satisfied while hospitals costs and nurses preferences\nare optimized. To solve the NSP, we propose implicit and explicit approaches.\nIn the implicit solving approach, we rely on Machine Learning methods using\nhistorical data to learn and generate new solutions through the constraints and\nobjectives that may be embedded in the learned patterns. To quantify the\nquality of using our implicit approach in capturing the embedded constraints\nand objectives, we rely on the Frobenius Norm, a quality measure used to\ncompute the average error between the generated solutions and historical data.\nTo compensate for the uncertainty related to the implicit approach given that\nthe constraints and objectives may not be concretely visible in the produced\nsolutions, we propose an alternative explicit approach where we first model the\nNSP using the Constraint Satisfaction Problem (CSP) framework. Then we develop\nStochastic Local Search methods and a new Branch and Bound algorithm enhanced\nwith constraint propagation techniques and variables/values ordering\nheuristics. Since our implicit approach may not guarantee the feasibility or\noptimality of the generated solution, we propose a data-driven approach to\npassively learn the NSP as a constraint network. The learned constraint\nnetwork, formulated as a CSP, will then be solved using the methods we listed\nearlier.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.07547v1",
    "published_date": "2024-09-11 18:09:25 UTC",
    "updated_date": "2024-09-11 18:09:25 UTC"
  },
  {
    "arxiv_id": "2409.07453v1",
    "title": "\"My Grade is Wrong!\": A Contestable AI Framework for Interactive Feedback in Evaluating Student Essays",
    "authors": [
      "Shengxin Hong",
      "Chang Cai",
      "Sixuan Du",
      "Haiyue Feng",
      "Siyuan Liu",
      "Xiuyi Fan"
    ],
    "abstract": "Interactive feedback, where feedback flows in both directions between teacher\nand student, is more effective than traditional one-way feedback. However, it\nis often too time-consuming for widespread use in educational practice. While\nLarge Language Models (LLMs) have potential for automating feedback, they\nstruggle with reasoning and interaction in an interactive setting. This paper\nintroduces CAELF, a Contestable AI Empowered LLM Framework for automating\ninteractive feedback. CAELF allows students to query, challenge, and clarify\ntheir feedback by integrating a multi-agent system with computational\nargumentation. Essays are first assessed by multiple Teaching-Assistant Agents\n(TA Agents), and then a Teacher Agent aggregates the evaluations through formal\nreasoning to generate feedback and grades. Students can further engage with the\nfeedback to refine their understanding. A case study on 500 critical thinking\nessays with user studies demonstrates that CAELF significantly improves\ninteractive feedback, enhancing the reasoning and interaction capabilities of\nLLMs. This approach offers a promising solution to overcoming the time and\nresource barriers that have limited the adoption of interactive feedback in\neducational settings.",
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.07453v1",
    "published_date": "2024-09-11 17:59:01 UTC",
    "updated_date": "2024-09-11 17:59:01 UTC"
  },
  {
    "arxiv_id": "2409.07510v5",
    "title": "Still More Shades of Null: An Evaluation Suite for Responsible Missing Value Imputation",
    "authors": [
      "Falaah Arif Khan",
      "Denys Herasymuk",
      "Nazar Protsiv",
      "Julia Stoyanovich"
    ],
    "abstract": "Data missingness is a practical challenge of sustained interest to the\nscientific community. In this paper, we present Shades-of-Null, an evaluation\nsuite for responsible missing value imputation. Our work is novel in two ways\n(i) we model realistic and socially-salient missingness scenarios that go\nbeyond Rubin's classic Missing Completely at Random (MCAR), Missing At Random\n(MAR) and Missing Not At Random (MNAR) settings, to include multi-mechanism\nmissingness (when different missingness patterns co-exist in the data) and\nmissingness shift (when the missingness mechanism changes between training and\ntest) (ii) we evaluate imputers holistically, based on imputation quality and\nimputation fairness, as well as on the predictive performance, fairness and\nstability of the models that are trained and tested on the data\npost-imputation.\n  We use Shades-of-Null to conduct a large-scale empirical study involving\n29,736 experimental pipelines, and find that while there is no single\nbest-performing imputation approach for all missingness types, interesting\ntrade-offs arise between predictive performance, fairness and stability, based\non the combination of missingness scenario, imputer choice, and the\narchitecture of the predictive model. We make Shades-of-Null publicly\navailable, to enable researchers to rigorously evaluate missing value\nimputation methods on a wide range of metrics in plausible and socially\nmeaningful scenarios.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.07510v5",
    "published_date": "2024-09-11 17:58:39 UTC",
    "updated_date": "2025-03-18 17:46:41 UTC"
  },
  {
    "arxiv_id": "2409.07448v3",
    "title": "Introducing Perturb-ability Score (PS) to Enhance Robustness Against Problem-Space Evasion Adversarial Attacks on Flow-based ML-NIDS",
    "authors": [
      "Mohamed elShehaby",
      "Ashraf Matrawy"
    ],
    "abstract": "As network security threats continue to evolve, safeguarding Machine Learning\n(ML)-based Network Intrusion Detection Systems (NIDS) from adversarial attacks\nis crucial. This paper introduces the notion of feature perturb-ability and\npresents a novel Perturb-ability Score (PS) metric that identifies NIDS\nfeatures susceptible to manipulation in the problem-space by an attacker. By\nquantifying a feature's susceptibility to perturbations within the\nproblem-space, the PS facilitates the selection of features that are inherently\nmore robust against evasion adversarial attacks on ML-NIDS during the feature\nselection phase. These features exhibit natural resilience to perturbations, as\nthey are heavily constrained by the problem-space limitations and correlations\nof the NIDS domain. Furthermore, manipulating these features may either disrupt\nthe malicious function of evasion adversarial attacks on NIDS or render the\nnetwork traffic invalid for processing (or both). This proposed novel approach\nemploys a fresh angle by leveraging network domain constraints as a defense\nmechanism against problem-space evasion adversarial attacks targeting ML-NIDS.\nWe demonstrate the effectiveness of our PS-guided feature selection defense in\nenhancing NIDS robustness. Experimental results across various ML-based NIDS\nmodels and public datasets show that selecting only robust features (low-PS\nfeatures) can maintain solid detection performance while significantly reducing\nvulnerability to evasion adversarial attacks. Additionally, our findings verify\nthat the PS effectively identifies NIDS features highly vulnerable to\nproblem-space perturbations.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.07448v3",
    "published_date": "2024-09-11 17:52:37 UTC",
    "updated_date": "2025-01-22 18:10:50 UTC"
  },
  {
    "arxiv_id": "2409.07440v1",
    "title": "SUPER: Evaluating Agents on Setting Up and Executing Tasks from Research Repositories",
    "authors": [
      "Ben Bogin",
      "Kejuan Yang",
      "Shashank Gupta",
      "Kyle Richardson",
      "Erin Bransom",
      "Peter Clark",
      "Ashish Sabharwal",
      "Tushar Khot"
    ],
    "abstract": "Given that Large Language Models (LLMs) have made significant progress in\nwriting code, can they now be used to autonomously reproduce results from\nresearch repositories? Such a capability would be a boon to the research\ncommunity, helping researchers validate, understand, and extend prior work. To\nadvance towards this goal, we introduce SUPER, the first benchmark designed to\nevaluate the capability of LLMs in setting up and executing tasks from research\nrepositories. SUPERaims to capture the realistic challenges faced by\nresearchers working with Machine Learning (ML) and Natural Language Processing\n(NLP) research repositories. Our benchmark comprises three distinct problem\nsets: 45 end-to-end problems with annotated expert solutions, 152 sub problems\nderived from the expert set that focus on specific challenges (e.g.,\nconfiguring a trainer), and 602 automatically generated problems for\nlarger-scale development. We introduce various evaluation measures to assess\nboth task success and progress, utilizing gold solutions when available or\napproximations otherwise. We show that state-of-the-art approaches struggle to\nsolve these problems with the best model (GPT-4o) solving only 16.3% of the\nend-to-end set, and 46.1% of the scenarios. This illustrates the challenge of\nthis task, and suggests that SUPER can serve as a valuable resource for the\ncommunity to make and measure progress.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.07440v1",
    "published_date": "2024-09-11 17:37:48 UTC",
    "updated_date": "2024-09-11 17:37:48 UTC"
  },
  {
    "arxiv_id": "2409.07431v2",
    "title": "Synthetic continued pretraining",
    "authors": [
      "Zitong Yang",
      "Neil Band",
      "Shuangping Li",
      "Emmanuel Cand√®s",
      "Tatsunori Hashimoto"
    ],
    "abstract": "Pretraining on large-scale, unstructured internet text enables language\nmodels to acquire a significant amount of world knowledge. However, this\nknowledge acquisition is data-inefficient--to learn a given fact, models must\nbe trained on hundreds to thousands of diverse representations of it. This\nposes a challenge when adapting a pretrained model to a small corpus of\ndomain-specific documents, where each fact may appear rarely or only once. We\npropose to bridge this gap with synthetic continued pretraining: using the\nsmall domain-specific corpus to synthesize a large corpus more amenable to\nlearning, and then performing continued pretraining on the synthesized corpus.\nWe instantiate this proposal with EntiGraph, a synthetic data augmentation\nalgorithm that extracts salient entities from the source documents and then\ngenerates diverse text by drawing connections between the sampled entities.\nSynthetic continued pretraining with EntiGraph enables a language model to\nanswer questions and follow generic instructions related to the source\ndocuments without access to them. If, instead, the source documents are\navailable at inference time, we show that the knowledge acquired through our\napproach compounds with retrieval-augmented generation. To better understand\nthese results, we build a simple mathematical model of EntiGraph, and show how\nsynthetic data augmentation can \"rearrange\" knowledge to enable more\ndata-efficient learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Updated organization of experimental results and methods\n  introduction. Released the dataset and model weights artifact",
    "pdf_url": "http://arxiv.org/pdf/2409.07431v2",
    "published_date": "2024-09-11 17:21:59 UTC",
    "updated_date": "2024-10-03 13:07:25 UTC"
  },
  {
    "arxiv_id": "2409.07416v1",
    "title": "Hierarchical Reinforcement Learning for Temporal Abstraction of Listwise Recommendation",
    "authors": [
      "Luo Ji",
      "Gao Liu",
      "Mingyang Yin",
      "Hongxia Yang",
      "Jingren Zhou"
    ],
    "abstract": "Modern listwise recommendation systems need to consider both long-term user\nperceptions and short-term interest shifts. Reinforcement learning can be\napplied on recommendation to study such a problem but is also subject to large\nsearch space, sparse user feedback and long interactive latency. Motivated by\nrecent progress in hierarchical reinforcement learning, we propose a novel\nframework called mccHRL to provide different levels of temporal abstraction on\nlistwise recommendation. Within the hierarchical framework, the high-level\nagent studies the evolution of user perception, while the low-level agent\nproduces the item selection policy by modeling the process as a sequential\ndecision-making problem. We argue that such framework has a well-defined\ndecomposition of the outra-session context and the intra-session context, which\nare encoded by the high-level and low-level agents, respectively. To verify\nthis argument, we implement both a simulator-based environment and an\nindustrial dataset-based experiment. Results observe significant performance\nimprovement by our method, compared with several well-known baselines. Data and\ncodes have been made public.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "18 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.07416v1",
    "published_date": "2024-09-11 17:01:06 UTC",
    "updated_date": "2024-09-11 17:01:06 UTC"
  },
  {
    "arxiv_id": "2409.07415v2",
    "title": "SoK: Security and Privacy Risks of Healthcare AI",
    "authors": [
      "Yuanhaur Chang",
      "Han Liu",
      "Chenyang Lu",
      "Ning Zhang"
    ],
    "abstract": "The integration of artificial intelligence (AI) and machine learning (ML)\ninto healthcare systems holds great promise for enhancing patient care and care\ndelivery efficiency; however, it also exposes sensitive data and system\nintegrity to potential cyberattacks. Current security and privacy (S&P)\nresearch on healthcare AI is highly unbalanced in terms of healthcare\ndeployment scenarios and threat models, and has a disconnected focus with the\nbiomedical research community. This hinders a comprehensive understanding of\nthe risks that healthcare AI entails. To address this gap, this paper takes a\nthorough examination of existing healthcare AI S&P research, providing a\nunified framework that allows the identification of under-explored areas. Our\nsurvey presents a systematic overview of healthcare AI attacks and defenses,\nand points out challenges and research opportunities for each AI-driven\nhealthcare application domain. Through our experimental analysis of different\nthreat models and feasibility studies on under-explored adversarial attacks, we\nprovide compelling insights into the pressing need for cybersecurity research\nin the rapidly evolving field of healthcare AI.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.07415v2",
    "published_date": "2024-09-11 16:59:58 UTC",
    "updated_date": "2025-04-30 22:27:30 UTC"
  },
  {
    "arxiv_id": "2409.07409v2",
    "title": "Robust Robot Walker: Learning Agile Locomotion over Tiny Traps",
    "authors": [
      "Shaoting Zhu",
      "Runhan Huang",
      "Linzhan Mou",
      "Hang Zhao"
    ],
    "abstract": "Quadruped robots must exhibit robust walking capabilities in practical\napplications. In this work, we propose a novel approach that enables quadruped\nrobots to pass various small obstacles, or \"tiny traps\". Existing methods often\nrely on exteroceptive sensors, which can be unreliable for detecting such tiny\ntraps. To overcome this limitation, our approach focuses solely on\nproprioceptive inputs. We introduce a two-stage training framework\nincorporating a contact encoder and a classification head to learn implicit\nrepresentations of different traps. Additionally, we design a set of tailored\nreward functions to improve both the stability of training and the ease of\ndeployment for goal-tracking tasks. To benefit further research, we design a\nnew benchmark for tiny trap task. Extensive experiments in both simulation and\nreal-world settings demonstrate the effectiveness and robustness of our method.\nProject Page: https://robust-robot-walker.github.io/",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "10 pages, 17 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.07409v2",
    "published_date": "2024-09-11 16:50:29 UTC",
    "updated_date": "2024-09-12 15:35:49 UTC"
  },
  {
    "arxiv_id": "2409.07407v1",
    "title": "CLNX: Bridging Code and Natural Language for C/C++ Vulnerability-Contributing Commits Identification",
    "authors": [
      "Zeqing Qin",
      "Yiwei Wu",
      "Lansheng Han"
    ],
    "abstract": "Large Language Models (LLMs) have shown great promise in vulnerability\nidentification. As C/C++ comprises half of the Open-Source Software (OSS)\nvulnerabilities over the past decade and updates in OSS mainly occur through\ncommits, enhancing LLMs' ability to identify C/C++ Vulnerability-Contributing\nCommits (VCCs) is essential. However, current studies primarily focus on\nfurther pre-training LLMs on massive code datasets, which is resource-intensive\nand poses efficiency challenges. In this paper, we enhance the ability of\nBERT-based LLMs to identify C/C++ VCCs in a lightweight manner. We propose\nCodeLinguaNexus (CLNX) as a bridge facilitating communication between C/C++\nprograms and LLMs. Based on commits, CLNX efficiently converts the source code\ninto a more natural representation while preserving key details. Specifically,\nCLNX first applies structure-level naturalization to decompose complex\nprograms, followed by token-level naturalization to interpret complex symbols.\nWe evaluate CLNX on public datasets of 25,872 C/C++ functions with their\ncommits. The results show that CLNX significantly enhances the performance of\nLLMs on identifying C/C++ VCCs. Moreover, CLNX-equipped CodeBERT achieves new\nstate-of-the-art and identifies 38 OSS vulnerabilities in the real world.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "68M25"
    ],
    "primary_category": "cs.CR",
    "comment": "8 pages, 2 figures, conference",
    "pdf_url": "http://arxiv.org/pdf/2409.07407v1",
    "published_date": "2024-09-11 16:49:46 UTC",
    "updated_date": "2024-09-11 16:49:46 UTC"
  },
  {
    "arxiv_id": "2409.07402v2",
    "title": "What to align in multimodal contrastive learning?",
    "authors": [
      "Benoit Dufumier",
      "Javiera Castillo-Navarro",
      "Devis Tuia",
      "Jean-Philippe Thiran"
    ],
    "abstract": "Humans perceive the world through multisensory integration, blending the\ninformation of different modalities to adapt their behavior. Contrastive\nlearning offers an appealing solution for multimodal self-supervised learning.\nIndeed, by considering each modality as a different view of the same entity, it\nlearns to align features of different modalities in a shared representation\nspace. However, this approach is intrinsically limited as it only learns shared\nor redundant information between modalities, while multimodal interactions can\narise in other ways. In this work, we introduce CoMM, a Contrastive MultiModal\nlearning strategy that enables the communication between modalities in a single\nmultimodal space. Instead of imposing cross- or intra- modality constraints, we\npropose to align multimodal representations by maximizing the mutual\ninformation between augmented versions of these multimodal features. Our\ntheoretical analysis shows that shared, synergistic and unique terms of\ninformation naturally emerge from this formulation, allowing us to estimate\nmultimodal interactions beyond redundancy. We test CoMM both in a controlled\nand in a series of real-world settings: in the former, we demonstrate that CoMM\neffectively captures redundant, unique and synergistic information between\nmodalities. In the latter, CoMM learns complex multimodal interactions and\nachieves state-of-the-art results on the seven multimodal benchmarks. Code is\navailable at https://github.com/Duplums/CoMM",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2025, 25 pages",
    "pdf_url": "http://arxiv.org/pdf/2409.07402v2",
    "published_date": "2024-09-11 16:42:22 UTC",
    "updated_date": "2025-03-05 16:48:23 UTC"
  },
  {
    "arxiv_id": "2409.07372v1",
    "title": "Awaking the Slides: A Tuning-free and Knowledge-regulated AI Tutoring System via Language Model Coordination",
    "authors": [
      "Daniel Zhang-Li",
      "Zheyuan Zhang",
      "Jifan Yu",
      "Joy Lim Jia Yin",
      "Shangqing Tu",
      "Linlu Gong",
      "Haohua Wang",
      "Zhiyuan Liu",
      "Huiqin Liu",
      "Lei Hou",
      "Juanzi Li"
    ],
    "abstract": "The vast pre-existing slides serve as rich and important materials to carry\nlecture knowledge. However, effectively leveraging lecture slides to serve\nstudents is difficult due to the multi-modal nature of slide content and the\nheterogeneous teaching actions. We study the problem of discovering effective\ndesigns that convert a slide into an interactive lecture. We develop\nSlide2Lecture, a tuning-free and knowledge-regulated intelligent tutoring\nsystem that can (1) effectively convert an input lecture slide into a\nstructured teaching agenda consisting of a set of heterogeneous teaching\nactions; (2) create and manage an interactive lecture that generates responsive\ninteractions catering to student learning demands while regulating the\ninteractions to follow teaching actions. Slide2Lecture contains a complete\npipeline for learners to obtain an interactive classroom experience to learn\nthe slide. For teachers and developers, Slide2Lecture enables customization to\ncater to personalized demands. The evaluation rated by annotators and students\nshows that Slide2Lecture is effective in outperforming the remaining\nimplementation. Slide2Lecture's online deployment has made more than 200K\ninteraction with students in the 3K lecture sessions. We open source\nSlide2Lecture's implementation in\nhttps://anonymous.4open.science/r/slide2lecture-4210/.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.07372v1",
    "published_date": "2024-09-11 16:03:09 UTC",
    "updated_date": "2024-09-11 16:03:09 UTC"
  },
  {
    "arxiv_id": "2409.07368v3",
    "title": "Demo: SGCode: A Flexible Prompt-Optimizing System for Secure Generation of Code",
    "authors": [
      "Khiem Ton",
      "Nhi Nguyen",
      "Mahmoud Nazzal",
      "Abdallah Khreishah",
      "Cristian Borcea",
      "NhatHai Phan",
      "Ruoming Jin",
      "Issa Khalil",
      "Yelong Shen"
    ],
    "abstract": "This paper introduces SGCode, a flexible prompt-optimizing system to generate\nsecure code with large language models (LLMs). SGCode integrates recent\nprompt-optimization approaches with LLMs in a unified system accessible through\nfront-end and back-end APIs, enabling users to 1) generate secure code, which\nis free of vulnerabilities, 2) review and share security analysis, and 3)\neasily switch from one prompt optimization approach to another, while providing\ninsights on model and system performance. We populated SGCode on an AWS server\nwith PromSec, an approach that optimizes prompts by combining an LLM and\nsecurity tools with a lightweight generative adversarial graph neural network\nto detect and fix security vulnerabilities in the generated code. Extensive\nexperiments show that SGCode is practical as a public tool to gain insights\ninto the trade-offs between model utility, secure code generation, and system\ncost. SGCode has only a marginal cost compared with prompting LLMs. SGCode is\navailable at: https://sgcode.codes/.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.07368v3",
    "published_date": "2024-09-11 15:56:15 UTC",
    "updated_date": "2024-09-25 15:17:27 UTC"
  },
  {
    "arxiv_id": "2409.07353v1",
    "title": "Securing Vision-Language Models with a Robust Encoder Against Jailbreak and Adversarial Attacks",
    "authors": [
      "Md Zarif Hossain",
      "Ahmed Imteaj"
    ],
    "abstract": "Large Vision-Language Models (LVLMs), trained on multimodal big datasets,\nhave significantly advanced AI by excelling in vision-language tasks. However,\nthese models remain vulnerable to adversarial attacks, particularly jailbreak\nattacks, which bypass safety protocols and cause the model to generate\nmisleading or harmful responses. This vulnerability stems from both the\ninherent susceptibilities of LLMs and the expanded attack surface introduced by\nthe visual modality. We propose Sim-CLIP+, a novel defense mechanism that\nadversarially fine-tunes the CLIP vision encoder by leveraging a Siamese\narchitecture. This approach maximizes cosine similarity between perturbed and\nclean samples, facilitating resilience against adversarial manipulations.\nSim-CLIP+ offers a plug-and-play solution, allowing seamless integration into\nexisting LVLM architectures as a robust vision encoder. Unlike previous\ndefenses, our method requires no structural modifications to the LVLM and\nincurs minimal computational overhead. Sim-CLIP+ demonstrates effectiveness\nagainst both gradient-based adversarial attacks and various jailbreak\ntechniques. We evaluate Sim-CLIP+ against three distinct jailbreak attack\nstrategies and perform clean evaluations using standard downstream datasets,\nincluding COCO for image captioning and OKVQA for visual question answering.\nExtensive experiments demonstrate that Sim-CLIP+ maintains high clean accuracy\nwhile substantially improving robustness against both gradient-based\nadversarial attacks and jailbreak techniques. Our code and robust vision\nencoders are available at\nhttps://github.com/speedlab-git/Robust-Encoder-against-Jailbreak-attack.git.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.07353v1",
    "published_date": "2024-09-11 15:39:42 UTC",
    "updated_date": "2024-09-11 15:39:42 UTC"
  },
  {
    "arxiv_id": "2409.07351v2",
    "title": "Federated Impression for Learning with Distributed Heterogeneous Data",
    "authors": [
      "Atrin Arya",
      "Sana Ayromlou",
      "Armin Saadat",
      "Purang Abolmaesumi",
      "Xiaoxiao Li"
    ],
    "abstract": "Standard deep learning-based classification approaches may not always be\npractical in real-world clinical applications, as they require a centralized\ncollection of all samples. Federated learning (FL) provides a paradigm that can\nlearn from distributed datasets across clients without requiring them to share\ndata, which can help mitigate privacy and data ownership issues. In FL,\nsub-optimal convergence caused by data heterogeneity is common among data from\ndifferent health centers due to the variety in data collection protocols and\npatient demographics across centers. Through experimentation in this study, we\nshow that data heterogeneity leads to the phenomenon of catastrophic forgetting\nduring local training. We propose FedImpres which alleviates catastrophic\nforgetting by restoring synthetic data that represents the global information\nas federated impression. To achieve this, we distill the global model resulting\nfrom each communication round. Subsequently, we use the synthetic data\nalongside the local data to enhance the generalization of local training.\nExtensive experiments show that the proposed method achieves state-of-the-art\nperformance on both the BloodMNIST and Retina datasets, which contain label\nimbalance and domain shift, with an improvement in classification accuracy of\nup to 20%.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.07351v2",
    "published_date": "2024-09-11 15:37:52 UTC",
    "updated_date": "2024-10-09 13:55:01 UTC"
  },
  {
    "arxiv_id": "2409.07341v1",
    "title": "Online Decision MetaMorphFormer: A Casual Transformer-Based Reinforcement Learning Framework of Universal Embodied Intelligence",
    "authors": [
      "Luo Ji",
      "Runji Lin"
    ],
    "abstract": "Interactive artificial intelligence in the motion control field is an\ninteresting topic, especially when universal knowledge is adaptive to multiple\ntasks and universal environments. Despite there being increasing efforts in the\nfield of Reinforcement Learning (RL) with the aid of transformers, most of them\nmight be limited by the offline training pipeline, which prohibits exploration\nand generalization abilities. To address this limitation, we propose the\nframework of Online Decision MetaMorphFormer (ODM) which aims to achieve\nself-awareness, environment recognition, and action planning through a unified\nmodel architecture. Motivated by cognitive and behavioral psychology, an ODM\nagent is able to learn from others, recognize the world, and practice itself\nbased on its own experience. ODM can also be applied to any arbitrary agent\nwith a multi-joint body, located in different environments, and trained with\ndifferent types of tasks using large-scale pre-trained datasets. Through the\nuse of pre-trained datasets, ODM can quickly warm up and learn the necessary\nknowledge to perform the desired task, while the target environment continues\nto reinforce the universal policy. Extensive online experiments as well as\nfew-shot and zero-shot environmental tests are used to verify ODM's performance\nand generalization ability. The results of our study contribute to the study of\ngeneral artificial intelligence in embodied and cognitive fields. Code,\nresults, and video examples can be found on the website\n\\url{https://rlodm.github.io/odm/}.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.07341v1",
    "published_date": "2024-09-11 15:22:43 UTC",
    "updated_date": "2024-09-11 15:22:43 UTC"
  },
  {
    "arxiv_id": "2409.07340v1",
    "title": "A Framework for Predicting the Impact of Game Balance Changes through Meta Discovery",
    "authors": [
      "Akash Saravanan",
      "Matthew Guzdial"
    ],
    "abstract": "A metagame is a collection of knowledge that goes beyond the rules of a game.\nIn competitive, team-based games like Pok\\'emon or League of Legends, it refers\nto the set of current dominant characters and/or strategies within the player\nbase. Developer changes to the balance of the game can have drastic and\nunforeseen consequences on these sets of meta characters. A framework for\npredicting the impact of balance changes could aid developers in making more\ninformed balance decisions. In this paper we present such a Meta Discovery\nframework, leveraging Reinforcement Learning for automated testing of balance\nchanges. Our results demonstrate the ability to predict the outcome of balance\nchanges in Pok\\'emon Showdown, a collection of competitive Pok\\'emon tiers,\nwith high accuracy.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "11 pages, 1 figure, IEEE Transactions on Games",
    "pdf_url": "http://arxiv.org/pdf/2409.07340v1",
    "published_date": "2024-09-11 15:20:43 UTC",
    "updated_date": "2024-09-11 15:20:43 UTC"
  },
  {
    "arxiv_id": "2409.07335v1",
    "title": "Explanation, Debate, Align: A Weak-to-Strong Framework for Language Model Generalization",
    "authors": [
      "Mehrdad Zakershahrak",
      "Samira Ghodratnama"
    ],
    "abstract": "The rapid advancement of artificial intelligence systems has brought the\nchallenge of AI alignment to the forefront of research, particularly in complex\ndecision-making and task execution. As these systems surpass human-level\nperformance in sophisticated problems, ensuring their alignment with human\nvalues, intentions, and ethical guidelines becomes crucial. Building on\nprevious work in explanation generation for human-agent alignment, we address\nthe more complex dynamics of multi-agent systems and human-AI teams. This paper\nintroduces a novel approach to model alignment through weak-to-strong\ngeneralization in the context of language models. We present a framework where\na strong model facilitates the improvement of a weaker model, bridging the gap\nbetween explanation generation and model alignment. Our method, formalized as a\nfacilitation function, allows for the transfer of capabilities from advanced\nmodels to less capable ones without direct access to extensive training data.\nOur results suggest that this facilitation-based approach not only enhances\nmodel performance but also provides insights into the nature of model alignment\nand the potential for scalable oversight of AI systems.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.07335v1",
    "published_date": "2024-09-11 15:16:25 UTC",
    "updated_date": "2024-09-11 15:16:25 UTC"
  },
  {
    "arxiv_id": "2409.07321v1",
    "title": "Module-wise Adaptive Adversarial Training for End-to-end Autonomous Driving",
    "authors": [
      "Tianyuan Zhang",
      "Lu Wang",
      "Jiaqi Kang",
      "Xinwei Zhang",
      "Siyuan Liang",
      "Yuwei Chen",
      "Aishan Liu",
      "Xianglong Liu"
    ],
    "abstract": "Recent advances in deep learning have markedly improved autonomous driving\n(AD) models, particularly end-to-end systems that integrate perception,\nprediction, and planning stages, achieving state-of-the-art performance.\nHowever, these models remain vulnerable to adversarial attacks, where\nhuman-imperceptible perturbations can disrupt decision-making processes. While\nadversarial training is an effective method for enhancing model robustness\nagainst such attacks, no prior studies have focused on its application to\nend-to-end AD models. In this paper, we take the first step in adversarial\ntraining for end-to-end AD models and present a novel Module-wise Adaptive\nAdversarial Training (MA2T). However, extending conventional adversarial\ntraining to this context is highly non-trivial, as different stages within the\nmodel have distinct objectives and are strongly interconnected. To address\nthese challenges, MA2T first introduces Module-wise Noise Injection, which\ninjects noise before the input of different modules, targeting training models\nwith the guidance of overall objectives rather than each independent module\nloss. Additionally, we introduce Dynamic Weight Accumulation Adaptation, which\nincorporates accumulated weight changes to adaptively learn and adjust the loss\nweights of each module based on their contributions (accumulated reduction\nrates) for better balance and robust training. To demonstrate the efficacy of\nour defense, we conduct extensive experiments on the widely-used nuScenes\ndataset across several end-to-end AD models under both white-box and black-box\nattacks, where our method outperforms other baselines by large margins\n(+5-10%). Moreover, we validate the robustness of our defense through\nclosed-loop evaluation in the CARLA simulation environment, showing improved\nresilience even against natural corruption.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "14 pages",
    "pdf_url": "http://arxiv.org/pdf/2409.07321v1",
    "published_date": "2024-09-11 15:00:18 UTC",
    "updated_date": "2024-09-11 15:00:18 UTC"
  },
  {
    "arxiv_id": "2409.18969v2",
    "title": "Integrating SPARQL and LLMs for Question Answering over Scholarly Data Sources",
    "authors": [
      "Fomubad Borista Fondi",
      "Azanzi Jiomekong Fidel",
      "Gaoussou Camara"
    ],
    "abstract": "The Scholarly Hybrid Question Answering over Linked Data (QALD) Challenge at\nthe International Semantic Web Conference (ISWC) 2024 focuses on Question\nAnswering (QA) over diverse scholarly sources: DBLP, SemOpenAlex, and\nWikipedia-based texts. This paper describes a methodology that combines SPARQL\nqueries, divide and conquer algorithms, and a pre-trained extractive question\nanswering model. It starts with SPARQL queries to gather data, then applies\ndivide and conquer to manage various question types and sources, and uses the\nmodel to handle personal author questions. The approach, evaluated with Exact\nMatch and F-score metrics, shows promise for improving QA accuracy and\nefficiency in scholarly contexts.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "Scholarly Hybrid Question answering challenge from the International\n  Semantic Web Conference of 2024(ISWC), 7 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.18969v2",
    "published_date": "2024-09-11 14:50:28 UTC",
    "updated_date": "2024-11-28 20:29:44 UTC"
  },
  {
    "arxiv_id": "2409.07314v1",
    "title": "MEDIC: Towards a Comprehensive Framework for Evaluating LLMs in Clinical Applications",
    "authors": [
      "Praveen K Kanithi",
      "Cl√©ment Christophe",
      "Marco AF Pimentel",
      "Tathagata Raha",
      "Nada Saadi",
      "Hamza Javed",
      "Svetlana Maslenkova",
      "Nasir Hayat",
      "Ronnie Rajan",
      "Shadab Khan"
    ],
    "abstract": "The rapid development of Large Language Models (LLMs) for healthcare\napplications has spurred calls for holistic evaluation beyond frequently-cited\nbenchmarks like USMLE, to better reflect real-world performance. While\nreal-world assessments are valuable indicators of utility, they often lag\nbehind the pace of LLM evolution, likely rendering findings obsolete upon\ndeployment. This temporal disconnect necessitates a comprehensive upfront\nevaluation that can guide model selection for specific clinical applications.\nWe introduce MEDIC, a framework assessing LLMs across five critical dimensions\nof clinical competence: medical reasoning, ethics and bias, data and language\nunderstanding, in-context learning, and clinical safety. MEDIC features a novel\ncross-examination framework quantifying LLM performance across areas like\ncoverage and hallucination detection, without requiring reference outputs. We\napply MEDIC to evaluate LLMs on medical question-answering, safety,\nsummarization, note generation, and other tasks. Our results show performance\ndisparities across model sizes, baseline vs medically finetuned models, and\nhave implications on model selection for applications requiring specific model\nstrengths, such as low hallucination or lower cost of inference. MEDIC's\nmultifaceted evaluation reveals these performance trade-offs, bridging the gap\nbetween theoretical capabilities and practical implementation in healthcare\nsettings, ensuring that the most promising models are identified and adapted\nfor diverse healthcare applications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Technical report",
    "pdf_url": "http://arxiv.org/pdf/2409.07314v1",
    "published_date": "2024-09-11 14:44:51 UTC",
    "updated_date": "2024-09-11 14:44:51 UTC"
  },
  {
    "arxiv_id": "2409.10561v3",
    "title": "DrLLM: Prompt-Enhanced Distributed Denial-of-Service Resistance Method with Large Language Models",
    "authors": [
      "Zhenyu Yin",
      "Shang Liu",
      "Guangyuan Xu"
    ],
    "abstract": "The increasing number of Distributed Denial of Service (DDoS) attacks poses a\nmajor threat to the Internet, highlighting the importance of DDoS mitigation.\nMost existing approaches require complex training methods to learn data\nfeatures, which increases the complexity and generality of the application. In\nthis paper, we propose DrLLM, which aims to mine anomalous traffic information\nin zero-shot scenarios through Large Language Models (LLMs). To bridge the gap\nbetween DrLLM and existing approaches, we embed the global and local\ninformation of the traffic data into the reasoning paradigm and design three\nmodules, namely Knowledge Embedding, Token Embedding, and Progressive Role\nReasoning, for data representation and reasoning. In addition we explore the\ngeneralization of prompt engineering in the cybersecurity domain to improve the\nclassification capability of DrLLM. Our ablation experiments demonstrate the\napplicability of DrLLM in zero-shot scenarios and further demonstrate the\npotential of LLMs in the network domains. DrLLM implementation code has been\nopen-sourced at https://github.com/liuup/DrLLM.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted by ICASSP2025",
    "pdf_url": "http://arxiv.org/pdf/2409.10561v3",
    "published_date": "2024-09-11 14:41:44 UTC",
    "updated_date": "2025-01-13 13:12:09 UTC"
  },
  {
    "arxiv_id": "2409.07291v1",
    "title": "Exploring User-level Gradient Inversion with a Diffusion Prior",
    "authors": [
      "Zhuohang Li",
      "Andrew Lowy",
      "Jing Liu",
      "Toshiaki Koike-Akino",
      "Bradley Malin",
      "Kieran Parsons",
      "Ye Wang"
    ],
    "abstract": "We explore user-level gradient inversion as a new attack surface in\ndistributed learning. We first investigate existing attacks on their ability to\nmake inferences about private information beyond training data reconstruction.\nMotivated by the low reconstruction quality of existing methods, we propose a\nnovel gradient inversion attack that applies a denoising diffusion model as a\nstrong image prior in order to enhance recovery in the large batch setting.\nUnlike traditional attacks, which aim to reconstruct individual samples and\nsuffer at large batch and image sizes, our approach instead aims to recover a\nrepresentative image that captures the sensitive shared semantic information\ncorresponding to the underlying user. Our experiments with face images\ndemonstrate the ability of our methods to recover realistic facial images along\nwith private user attributes.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.CV",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Presented at the International Workshop on Federated Learning in the\n  Age of Foundation Models in conjunction with NeurIPS 2023",
    "pdf_url": "http://arxiv.org/pdf/2409.07291v1",
    "published_date": "2024-09-11 14:20:47 UTC",
    "updated_date": "2024-09-11 14:20:47 UTC"
  },
  {
    "arxiv_id": "2409.07286v1",
    "title": "Using Generative Agents to Create Tip Sheets for Investigative Data Reporting",
    "authors": [
      "Joris Veerbeek",
      "Nicholas Diakopoulos"
    ],
    "abstract": "This paper introduces a system using generative AI agents to create tip\nsheets for investigative data reporting. Our system employs three specialized\nagents--an analyst, a reporter, and an editor--to collaboratively generate and\nrefine tips from datasets. We validate this approach using real-world\ninvestigative stories, demonstrating that our agent-based system generally\ngenerates more newsworthy and accurate insights compared to a baseline model\nwithout agents, although some variability was noted between different stories.\nOur findings highlight the potential of generative AI to provide leads for\ninvestigative data reporting.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Short paper to be presented at Computation + Journalism 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.07286v1",
    "published_date": "2024-09-11 14:14:15 UTC",
    "updated_date": "2024-09-11 14:14:15 UTC"
  },
  {
    "arxiv_id": "2409.18968v2",
    "title": "Safety challenges of AI in medicine in the era of large language models",
    "authors": [
      "Xiaoye Wang",
      "Nicole Xi Zhang",
      "Hongyu He",
      "Trang Nguyen",
      "Kun-Hsing Yu",
      "Hao Deng",
      "Cynthia Brandt",
      "Danielle S. Bitterman",
      "Ling Pan",
      "Ching-Yu Cheng",
      "James Zou",
      "Dianbo Liu"
    ],
    "abstract": "Recent advancements in artificial intelligence (AI), particularly in large\nlanguage models (LLMs), have unlocked significant potential to enhance the\nquality and efficiency of medical care. By introducing a novel way to interact\nwith AI and data through natural language, LLMs offer new opportunities for\nmedical practitioners, patients, and researchers. However, as AI and LLMs\nbecome more powerful and especially achieve superhuman performance in some\nmedical tasks, public concerns over their safety have intensified. These\nconcerns about AI safety have emerged as the most significant obstacles to the\nadoption of AI in medicine. In response, this review examines emerging risks in\nAI utilization during the LLM era. First, we explore LLM-specific safety\nchallenges from functional and communication perspectives, addressing issues\nacross data collection, model training, and real-world application. We then\nconsider inherent safety problems shared by all AI systems, along with\nadditional complications introduced by LLMs. Last, we discussed how safety\nissues of using AI in clinical practice and healthcare system operation would\nundermine trust among patient, clinicians and the public, and how to build\nconfidence in these systems. By emphasizing the development of safe AI, we\nbelieve these technologies can be more rapidly and reliably integrated into\neveryday medical practice to benefit both patients and clinicians.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.18968v2",
    "published_date": "2024-09-11 13:47:47 UTC",
    "updated_date": "2025-01-30 08:55:23 UTC"
  },
  {
    "arxiv_id": "2409.12171v1",
    "title": "Semantic Interoperability on Blockchain by Generating Smart Contracts Based on Knowledge Graphs",
    "authors": [
      "William Van Woensel",
      "Oshani Seneviratne"
    ],
    "abstract": "Background: Health 3.0 allows decision making to be based on longitudinal\ndata from multiple institutions, from across the patient's healthcare journey.\nIn such a distributed setting, blockchain smart contracts can act as neutral\nintermediaries to implement trustworthy decision making.\n  Objective: In a distributed setting, transmitted data will be structured\nusing standards (such as HL7 FHIR) for semantic interoperability. In turn, the\nsmart contract will require interoperability with this standard, implement a\ncomplex communication setup (e.g., using oracles), and be developed using\nblockchain languages (e.g., Solidity). We propose the encoding of smart\ncontract logic using a high-level semantic Knowledge Graph, using concepts from\nthe domain standard. We then deploy this semantic KG on blockchain.\n  Methods: Off-chain, a code generation pipeline compiles the KG into a\nconcrete smart contract, which is then deployed on-chain. Our pipeline targets\nan intermediary bridge representation, which can be transpiled into a specific\nblockchain language. Our choice avoids on-chain rule engines, with\nunpredictable and likely higher computational cost; it is thus in line with the\neconomic rules of blockchain.\n  Results: We applied our code generation approach to generate smart contracts\nfor 3 health insurance cases from Medicare. We discuss the suitability of our\napproach - the need for a neutral intermediary - for a number of healthcare use\ncases. Our evaluation finds that the generated contracts perform well in terms\nof correctness and execution cost (\"gas\") on blockchain.\n  Conclusions: We showed that it is feasible to automatically generate smart\ncontract code based on a semantic KG, in a way that respects the economic rules\nof blockchain. Future work includes studying the use of Large Language Models\n(LLM) in our approach, and evaluations on other blockchains.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.12171v1",
    "published_date": "2024-09-11 13:46:24 UTC",
    "updated_date": "2024-09-11 13:46:24 UTC"
  },
  {
    "arxiv_id": "2409.07246v2",
    "title": "Propaganda to Hate: A Multimodal Analysis of Arabic Memes with Multi-Agent LLMs",
    "authors": [
      "Firoj Alam",
      "Md. Rafiul Biswas",
      "Uzair Shah",
      "Wajdi Zaghouani",
      "Georgios Mikros"
    ],
    "abstract": "In the past decade, social media platforms have been used for information\ndissemination and consumption. While a major portion of the content is posted\nto promote citizen journalism and public awareness, some content is posted to\nmislead users. Among different content types such as text, images, and videos,\nmemes (text overlaid on images) are particularly prevalent and can serve as\npowerful vehicles for propaganda, hate, and humor. In the current literature,\nthere have been efforts to individually detect such content in memes. However,\nthe study of their intersection is very limited. In this study, we explore the\nintersection between propaganda and hate in memes using a multi-agent LLM-based\napproach. We extend the propagandistic meme dataset with coarse and\nfine-grained hate labels. Our finding suggests that there is an association\nbetween propaganda and hate in memes. We provide detailed experimental results\nthat can serve as a baseline for future studies. We will make the experimental\nresources publicly available to the community\n(https://github.com/firojalam/propaganda-and-hateful-memes).",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T50",
      "F.2.2; I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "propaganda, hate-speech, disinformation, misinformation, fake news,\n  LLMs, GPT-4, multimodality, multimodal LLMs",
    "pdf_url": "http://arxiv.org/pdf/2409.07246v2",
    "published_date": "2024-09-11 13:04:34 UTC",
    "updated_date": "2024-10-06 08:30:48 UTC"
  },
  {
    "arxiv_id": "2409.09086v1",
    "title": "Inf-MLLM: Efficient Streaming Inference of Multimodal Large Language Models on a Single GPU",
    "authors": [
      "Zhenyu Ning",
      "Jieru Zhao",
      "Qihao Jin",
      "Wenchao Ding",
      "Minyi Guo"
    ],
    "abstract": "Multimodal Large Language Models (MLLMs) are distinguished by their\nmultimodal comprehensive ability and widely used in many real-world\napplications including GPT-4o, autonomous driving and robotics. Despite their\nimpressive performance, the multimodal inputs always incur long context. The\ninference under long context requires caching massive Key and Value states (KV\ncache) of previous tokens, which introduces high latency and excessive memory\nconsumption. Due to this reason, it is challenging to deploy streaming\ninference of MLLMs on edge devices, which largely constrains the power and\nusage of MLLMs in real-world applications. In this paper, we introduce\nInf-MLLM, an efficient inference framework for MLLMs, which enable streaming\ninference of MLLM on a single GPU with infinite context. Inf-MLLM is based on\nour key observation of the attention pattern in both LLMs and MLLMs called\n\"attention saddles\". Thanks to the newly discovered attention pattern, Inf-MLLM\nmaintains a size-constrained KV cache by dynamically caching recent tokens and\nrelevant tokens. Furthermore, Inf-MLLM proposes attention bias, a novel\napproach to enable MLLMs to capture long-term dependency. We show that Inf-MLLM\nenables multiple LLMs and MLLMs to achieve stable performance over 4M-token\nlong texts and multi-round conversations with 1-hour-long videos on a single\nGPU. In addition, Inf-MLLM exhibits superior streaming reasoning quality than\nexisting methods such as StreamingLLM and 2x speedup than H2O.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.DC",
      "cs.PF"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.09086v1",
    "published_date": "2024-09-11 12:44:12 UTC",
    "updated_date": "2024-09-11 12:44:12 UTC"
  },
  {
    "arxiv_id": "2409.07507v1",
    "title": "Traceable LLM-based validation of statements in knowledge graphs",
    "authors": [
      "Daniel Adam",
      "Tom√°≈° Kliegr"
    ],
    "abstract": "This article presents a method for verifying RDF triples using LLMs, with an\nemphasis on providing traceable arguments. Because the LLMs cannot currently\nreliably identify the origin of the information used to construct the response\nto the user query, our approach is to avoid using internal LLM factual\nknowledge altogether. Instead, verified RDF statements are compared to chunks\nof external documents retrieved through a web search or Wikipedia. To assess\nthe possible application of this workflow on biosciences content, we evaluated\n1,719 positive statements from the BioRED dataset and the same number of newly\ngenerated negative statements. The resulting precision is 88%, and recall is\n44%. This indicates that the method requires human oversight. We demonstrate\nthe method on Wikidata, where a SPARQL query is used to automatically retrieve\nstatements needing verification. Overall, the results suggest that LLMs could\nbe used for large-scale verification of statements in KGs, a task previously\nunfeasible due to human annotation costs.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.07507v1",
    "published_date": "2024-09-11 12:27:41 UTC",
    "updated_date": "2024-09-11 12:27:41 UTC"
  },
  {
    "arxiv_id": "2409.07218v1",
    "title": "Behavioral Cloning Models Reality Check for Autonomous Driving",
    "authors": [
      "Mustafa Yildirim",
      "Barkin Dagda",
      "Vinal Asodia",
      "Saber Fallah"
    ],
    "abstract": "How effective are recent advancements in autonomous vehicle perception\nsystems when applied to real-world autonomous vehicle control? While numerous\nvision-based autonomous vehicle systems have been trained and evaluated in\nsimulated environments, there is a notable lack of real-world validation for\nthese systems. This paper addresses this gap by presenting the real-world\nvalidation of state-of-the-art perception systems that utilize Behavior Cloning\n(BC) for lateral control, processing raw image data to predict steering\ncommands. The dataset was collected using a scaled research vehicle and tested\non various track setups. Experimental results demonstrate that these methods\npredict steering angles with low error margins in real-time, indicating\npromising potential for real-world applications.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.07218v1",
    "published_date": "2024-09-11 12:19:38 UTC",
    "updated_date": "2024-09-11 12:19:38 UTC"
  },
  {
    "arxiv_id": "2409.07202v1",
    "title": "Heterogeneity-Aware Coordination for Federated Learning via Stitching Pre-trained blocks",
    "authors": [
      "Shichen Zhan",
      "Yebo Wu",
      "Chunlin Tian",
      "Yan Zhao",
      "Li Li"
    ],
    "abstract": "Federated learning (FL) coordinates multiple devices to collaboratively train\na shared model while preserving data privacy. However, large memory footprint\nand high energy consumption during the training process excludes the low-end\ndevices from contributing to the global model with their own data, which\nseverely deteriorates the model performance in real-world scenarios. In this\npaper, we propose FedStitch, a hierarchical coordination framework for\nheterogeneous federated learning with pre-trained blocks. Unlike the\ntraditional approaches that train the global model from scratch, for a new\ntask, FedStitch composes the global model via stitching pre-trained blocks.\nSpecifically, each participating client selects the most suitable block based\non their local data from the candidate pool composed of blocks from pre-trained\nmodels. The server then aggregates the optimal block for stitching. This\nprocess iterates until a new stitched network is generated. Except for the new\ntraining paradigm, FedStitch consists of the following three core components:\n1) an RL-weighted aggregator, 2) a search space optimizer deployed on the\nserver side, and 3) a local energy optimizer deployed on each participating\nclient. The RL-weighted aggregator helps to select the right block in the\nnon-IID scenario, while the search space optimizer continuously reduces the\nsize of the candidate block pool during stitching. Meanwhile, the local energy\noptimizer is designed to minimize energy consumption of each client while\nguaranteeing the overall training progress. The results demonstrate that\ncompared to existing approaches, FedStitch improves the model accuracy up to\n20.93%. At the same time, it achieves up to 8.12% speedup, reduces the memory\nfootprint up to 79.5%, and achieves 89.41% energy saving at most during the\nlearning procedure.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.07202v1",
    "published_date": "2024-09-11 11:47:50 UTC",
    "updated_date": "2024-09-11 11:47:50 UTC"
  },
  {
    "arxiv_id": "2409.07200v2",
    "title": "ThermalGaussian: Thermal 3D Gaussian Splatting",
    "authors": [
      "Rongfeng Lu",
      "Hangyu Chen",
      "Zunjie Zhu",
      "Yuhang Qin",
      "Ming Lu",
      "Le Zhang",
      "Chenggang Yan",
      "Anke Xue"
    ],
    "abstract": "Thermography is especially valuable for the military and other users of\nsurveillance cameras. Some recent methods based on Neural Radiance Fields\n(NeRF) are proposed to reconstruct the thermal scenes in 3D from a set of\nthermal and RGB images. However, unlike NeRF, 3D Gaussian splatting (3DGS)\nprevails due to its rapid training and real-time rendering. In this work, we\npropose ThermalGaussian, the first thermal 3DGS approach capable of rendering\nhigh-quality images in RGB and thermal modalities. We first calibrate the RGB\ncamera and the thermal camera to ensure that both modalities are accurately\naligned. Subsequently, we use the registered images to learn the multimodal 3D\nGaussians. To prevent the overfitting of any single modality, we introduce\nseveral multimodal regularization constraints. We also develop smoothing\nconstraints tailored to the physical characteristics of the thermal modality.\nBesides, we contribute a real-world dataset named RGBT-Scenes, captured by a\nhand-hold thermal-infrared camera, facilitating future research on thermal\nscene reconstruction. We conduct comprehensive experiments to show that\nThermalGaussian achieves photorealistic rendering of thermal images and\nimproves the rendering quality of RGB images. With the proposed multimodal\nregularization constraints, we also reduced the model's storage cost by 90%.\nOur project page is at https://thermalgaussian.github.io/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.07200v2",
    "published_date": "2024-09-11 11:45:57 UTC",
    "updated_date": "2025-04-22 07:28:59 UTC"
  },
  {
    "arxiv_id": "2409.07505v1",
    "title": "A Survey of Anomaly Detection in In-Vehicle Networks",
    "authors": [
      "√ñvg√º √ñzdemir",
      "M. Tuƒüberk ƒ∞≈üyapar",
      "Pƒ±nar Karag√∂z",
      "Klaus Werner Schmidt",
      "Demet Demir",
      "N. Alpay Karag√∂z"
    ],
    "abstract": "Modern vehicles are equipped with Electronic Control Units (ECU) that are\nused for controlling important vehicle functions including safety-critical\noperations. ECUs exchange information via in-vehicle communication buses, of\nwhich the Controller Area Network (CAN bus) is by far the most widespread\nrepresentative. Problems that may occur in the vehicle's physical parts or\nmalicious attacks may cause anomalies in the CAN traffic, impairing the correct\nvehicle operation. Therefore, the detection of such anomalies is vital for\nvehicle safety. This paper reviews the research on anomaly detection for\nin-vehicle networks, more specifically for the CAN bus. Our main focus is the\nevaluation of methods used for CAN bus anomaly detection together with the\ndatasets used in such analysis. To provide the reader with a more comprehensive\nunderstanding of the subject, we first give a brief review of related studies\non time series-based anomaly detection. Then, we conduct an extensive survey of\nrecent deep learning-based techniques as well as conventional techniques for\nCAN bus anomaly detection. Our comprehensive analysis delves into anomaly\ndetection algorithms employed in in-vehicle networks, specifically focusing on\ntheir learning paradigms, inherent strengths, and weaknesses, as well as their\nefficacy when applied to CAN bus datasets. Lastly, we highlight challenges and\nopen research problems in CAN bus anomaly detection.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.07505v1",
    "published_date": "2024-09-11 11:45:18 UTC",
    "updated_date": "2024-09-11 11:45:18 UTC"
  },
  {
    "arxiv_id": "2409.07194v1",
    "title": "Cyber Deception: State of the art, Trends and Open challenges",
    "authors": [
      "Pedro Beltr√°n L√≥pez",
      "Manuel Gil P√©rez",
      "Pantaleone Nespoli"
    ],
    "abstract": "The growing interest in cybersecurity has significantly increased articles\ndesigning and implementing various Cyber Deception (CYDEC) mechanisms. This\ntrend reflects the urgent need for new strategies to address cyber threats\neffectively. Since its emergence, CYDEC has established itself as an innovative\ndefense against attackers, thanks to its proactive and reactive capabilities,\nfinding applications in numerous real-life scenarios. Despite the considerable\nwork devoted to CYDEC, the literature still presents significant gaps. In\nparticular, there has not been (i) a comprehensive analysis of the main\ncomponents characterizing CYDEC, (ii) a generic classification covering all\ntypes of solutions, nor (iii) a survey of the current state of the literature\nin various contexts. This article aims to fill these gaps through a detailed\nreview of the main features that comprise CYDEC, developing a comprehensive\nclassification taxonomy. In addition, the different frameworks used to generate\nCYDEC are reviewed, presenting a more comprehensive one. Existing solutions in\nthe literature using CYDEC, both without Artificial Intelligence (AI) and with\nAI, are studied and compared. Finally, the most salient trends of the current\nstate of the art are discussed, offering a list of pending challenges for\nfuture research.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.CR",
    "comment": "38 pages",
    "pdf_url": "http://arxiv.org/pdf/2409.07194v1",
    "published_date": "2024-09-11 11:31:34 UTC",
    "updated_date": "2024-09-11 11:31:34 UTC"
  },
  {
    "arxiv_id": "2409.07192v1",
    "title": "How Mature is Requirements Engineering for AI-based Systems? A Systematic Mapping Study on Practices, Challenges, and Future Research Directions",
    "authors": [
      "Umm-e- Habiba",
      "Markus Haug",
      "Justus Bogner",
      "Stefan Wagner"
    ],
    "abstract": "Artificial intelligence (AI) permeates all fields of life, which resulted in\nnew challenges in requirements engineering for artificial intelligence (RE4AI),\ne.g., the difficulty in specifying and validating requirements for AI or\nconsidering new quality requirements due to emerging ethical implications. It\nis currently unclear if existing RE methods are sufficient or if new ones are\nneeded to address these challenges. Therefore, our goal is to provide a\ncomprehensive overview of RE4AI to researchers and practitioners. What has been\nachieved so far, i.e., what practices are available, and what research gaps and\nchallenges still need to be addressed? To achieve this, we conducted a\nsystematic mapping study combining query string search and extensive\nsnowballing. The extracted data was aggregated, and results were synthesized\nusing thematic analysis. Our selection process led to the inclusion of 126\nprimary studies. Existing RE4AI research focuses mainly on requirements\nanalysis and elicitation, with most practices applied in these areas.\nFurthermore, we identified requirements specification, explainability, and the\ngap between machine learning engineers and end-users as the most prevalent\nchallenges, along with a few others. Additionally, we proposed seven potential\nresearch directions to address these challenges. Practitioners can use our\nresults to identify and select suitable RE methods for working on their\nAI-based systems, while researchers can build on the identified gaps and\nresearch directions to push the field forward.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted in Requirements Engineering Journal, 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.07192v1",
    "published_date": "2024-09-11 11:28:16 UTC",
    "updated_date": "2024-09-11 11:28:16 UTC"
  },
  {
    "arxiv_id": "2409.07189v1",
    "title": "A Perspective on AI-Guided Molecular Simulations in VR: Exploring Strategies for Imitation Learning in Hyperdimensional Molecular Systems",
    "authors": [
      "Mohamed Dhouioui",
      "Jonathan Barnoud",
      "Rhoslyn Roebuck Williams",
      "Harry J. Stroud",
      "Phil Bates",
      "David R. Glowacki"
    ],
    "abstract": "Molecular dynamics simulations are a crucial computational tool for\nresearchers to understand and engineer molecular structure and function in\nareas such as drug discovery, protein engineering, and material design. Despite\ntheir utility, MD simulations are expensive, owing to the high dimensionality\nof molecular systems. Interactive molecular dynamics in virtual reality\n(iMD-VR) has recently been developed as a 'human-in-the-loop' strategy, which\nleverages high-performance computing to accelerate the researcher's ability to\nsolve the hyperdimensional sampling problem. By providing an immersive 3D\nenvironment that enables visualization and manipulation of real-time molecular\nmotion, iMD-VR enables researchers and students to efficiently and intuitively\nexplore and navigate these complex, high-dimensional systems. iMD-VR platforms\noffer a unique opportunity to quickly generate rich datasets that capture human\nexperts' spatial insight regarding molecular structure and function. This paper\nexplores the possibility of employing user-generated iMD-VR datasets to train\nAI agents via imitation learning (IL). IL is an important technique in robotics\nthat enables agents to mimic complex behaviors from expert demonstrations, thus\ncircumventing the need for explicit programming or intricate reward design. We\nreview the utilization of IL for manipulation tasks in robotics and discuss how\niMD-VR recordings could be used to train IL models for solving specific\nmolecular 'tasks'. We then investigate how such approaches could be applied to\nthe data captured from iMD-VR recordings. Finally, we outline the future\nresearch directions and potential challenges of using AI agents to augment\nhuman expertise to efficiently navigate conformational spaces, highlighting how\nthis approach could provide valuable insight across domains such as materials\nscience, protein engineering, and computer-aided drug design.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.HC",
      "q-bio.BM"
    ],
    "primary_category": "cs.LG",
    "comment": "(Accepted for presentation at the First Workshop on \"eXtended Reality\n  \\& Intelligent Agents\" (XRIA24) @ ECAI24, Santiago De Compostela (Spain), 20\n  October 2024)",
    "pdf_url": "http://arxiv.org/pdf/2409.07189v1",
    "published_date": "2024-09-11 11:21:02 UTC",
    "updated_date": "2024-09-11 11:21:02 UTC"
  },
  {
    "arxiv_id": "2409.07186v2",
    "title": "Enhancing Angular Resolution via Directionality Encoding and Geometric Constraints in Brain Diffusion Tensor Imaging",
    "authors": [
      "Sheng Chen",
      "Zihao Tang",
      "Mariano Cabezas",
      "Xinyi Wang",
      "Arkiev D'Souza",
      "Michael Barnett",
      "Fernando Calamante",
      "Weidong Cai",
      "Chenyu Wang"
    ],
    "abstract": "Diffusion-weighted imaging (DWI) is a type of Magnetic Resonance Imaging\n(MRI) technique sensitised to the diffusivity of water molecules, offering the\ncapability to inspect tissue microstructures and is the only in-vivo method to\nreconstruct white matter fiber tracts non-invasively. The DWI signal can be\nanalysed with the diffusion tensor imaging (DTI) model to estimate the\ndirectionality of water diffusion within voxels. Several scalar metrics,\nincluding axial diffusivity (AD), mean diffusivity (MD), radial diffusivity\n(RD), and fractional anisotropy (FA), can be further derived from DTI to\nquantitatively summarise the microstructural integrity of brain tissue. These\nscalar metrics have played an important role in understanding the organisation\nand health of brain tissue at a microscopic level in clinical studies. However,\nreliable DTI metrics rely on DWI acquisitions with high gradient directions,\nwhich often go beyond the commonly used clinical protocols. To enhance the\nutility of clinically acquired DWI and save scanning time for robust DTI\nanalysis, this work proposes DirGeo-DTI, a deep learning-based method to\nestimate reliable DTI metrics even from a set of DWIs acquired with the minimum\ntheoretical number (6) of gradient directions. DirGeo-DTI leverages directional\nencoding and geometric constraints to facilitate the training process. Two\npublic DWI datasets were used for evaluation, demonstrating the effectiveness\nof the proposed method. Extensive experimental results show that the proposed\nmethod achieves the best performance compared to existing DTI enhancement\nmethods and potentially reveals further clinical insights with routine clinical\nDWI scans.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to ICONIP2024, Diffusion Weighted Imaging, Diffusion Tensor\n  Imaging, Angular Resolution Enhancement, Fractional Anisotropy",
    "pdf_url": "http://arxiv.org/pdf/2409.07186v2",
    "published_date": "2024-09-11 11:12:26 UTC",
    "updated_date": "2024-09-14 13:30:34 UTC"
  },
  {
    "arxiv_id": "2409.07165v1",
    "title": "Linear Time Complexity Conformers with SummaryMixing for Streaming Speech Recognition",
    "authors": [
      "Titouan Parcollet",
      "Rogier van Dalen",
      "Shucong Zhang",
      "Sourav Batthacharya"
    ],
    "abstract": "Automatic speech recognition (ASR) with an encoder equipped with\nself-attention, whether streaming or non-streaming, takes quadratic time in the\nlength of the speech utterance. This slows down training and decoding, increase\ntheir cost, and limit the deployment of the ASR in constrained devices.\nSummaryMixing is a promising linear-time complexity alternative to\nself-attention for non-streaming speech recognition that, for the first time,\npreserves or outperforms the accuracy of self-attention models. Unfortunately,\nthe original definition of SummaryMixing is not suited to streaming speech\nrecognition. Hence, this work extends SummaryMixing to a Conformer Transducer\nthat works in both a streaming and an offline mode. It shows that this new\nlinear-time complexity speech encoder outperforms self-attention in both\nscenarios while requiring less compute and memory during training and decoding.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.07165v1",
    "published_date": "2024-09-11 10:24:43 UTC",
    "updated_date": "2024-09-11 10:24:43 UTC"
  },
  {
    "arxiv_id": "2409.07154v2",
    "title": "Recurrent Aggregators in Neural Algorithmic Reasoning",
    "authors": [
      "Kaijia Xu",
      "Petar Veliƒçkoviƒá"
    ],
    "abstract": "Neural algorithmic reasoning (NAR) is an emerging field that seeks to design\nneural networks that mimic classical algorithmic computations. Today, graph\nneural networks (GNNs) are widely used in neural algorithmic reasoners due to\ntheir message passing framework and permutation equivariance. In this extended\nabstract, we challenge this design choice, and replace the equivariant\naggregation function with a recurrent neural network. While seemingly\ncounter-intuitive, this approach has appropriate grounding when nodes have a\nnatural ordering -- and this is the case frequently in established reasoning\nbenchmarks like CLRS-30. Indeed, our recurrent NAR (RNAR) model performs very\nstrongly on such tasks, while handling many others gracefully. A notable\nachievement of RNAR is its decisive state-of-the-art result on the Heapsort and\nQuickselect tasks, both deemed as a significant challenge for contemporary\nneural algorithmic reasoners -- especially the latter, where RNAR achieves a\nmean micro-F1 score of 87%.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Presented at the Third Learning on Graphs Conference (LoG 2024). 10\n  pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2409.07154v2",
    "published_date": "2024-09-11 09:59:56 UTC",
    "updated_date": "2024-12-01 15:07:43 UTC"
  },
  {
    "arxiv_id": "2409.07151v1",
    "title": "Zero-Shot Text-to-Speech as Golden Speech Generator: A Systematic Framework and its Applicability in Automatic Pronunciation Assessment",
    "authors": [
      "Tien-Hong Lo",
      "Meng-Ting Tsai",
      "Berlin Chen"
    ],
    "abstract": "Second language (L2) learners can improve their pronunciation by imitating\ngolden speech, especially when the speech that aligns with their respective\nspeech characteristics. This study explores the hypothesis that\nlearner-specific golden speech generated with zero-shot text-to-speech (ZS-TTS)\ntechniques can be harnessed as an effective metric for measuring the\npronunciation proficiency of L2 learners. Building on this exploration, the\ncontributions of this study are at least two-fold: 1) design and development of\na systematic framework for assessing the ability of a synthesis model to\ngenerate golden speech, and 2) in-depth investigations of the effectiveness of\nusing golden speech in automatic pronunciation assessment (APA). Comprehensive\nexperiments conducted on the L2-ARCTIC and Speechocean762 benchmark datasets\nsuggest that our proposed modeling can yield significant performance\nimprovements with respect to various assessment metrics in relation to some\nprior arts. To our knowledge, this study is the first to explore the role of\ngolden speech in both ZS-TTS and APA, offering a promising regime for\ncomputer-assisted pronunciation training (CAPT).",
    "categories": [
      "eess.AS",
      "cs.AI"
    ],
    "primary_category": "eess.AS",
    "comment": "11 pages, 4 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2409.07151v1",
    "published_date": "2024-09-11 09:55:57 UTC",
    "updated_date": "2024-09-11 09:55:57 UTC"
  },
  {
    "arxiv_id": "2409.07136v1",
    "title": "Leveraging Unstructured Text Data for Federated Instruction Tuning of Large Language Models",
    "authors": [
      "Rui Ye",
      "Rui Ge",
      "Yuchi Fengting",
      "Jingyi Chai",
      "Yanfeng Wang",
      "Siheng Chen"
    ],
    "abstract": "Federated instruction tuning enables multiple clients to collaboratively\nfine-tune a shared large language model (LLM) that can follow humans'\ninstructions without directly sharing raw data. However, existing literature\nimpractically requires that all the clients readily hold instruction-tuning\ndata (i.e., structured instruction-response pairs), which necessitates massive\nhuman annotations since clients' data is usually unstructured text instead.\nAddressing this, we propose a novel and flexible framework FedIT-U2S, which can\nautomatically transform unstructured corpus into structured data for federated\ninstruction tuning. FedIT-U2S consists two key steps: (1) few-shot\ninstruction-tuning data generation, where each unstructured data piece together\nwith several examples is combined to prompt an LLM in generating an\ninstruction-response pair. To further enhance the flexibility, a\nretrieval-based example selection technique is proposed, where the examples are\nautomatically selected based on the relatedness between the client's data piece\nand example pool, bypassing the need of determining examples in advance. (2) A\ntypical federated instruction tuning process based on the generated data.\nOverall, FedIT-U2S can be applied to diverse scenarios as long as the client\nholds valuable text corpus, broadening the application scope of federated\ninstruction tuning. We conduct a series of experiments on three domains\n(medicine, knowledge, and math), showing that our proposed FedIT-U2S can\nconsistently and significantly brings improvement over the base LLM.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.CL",
    "comment": "11 pages, work in progress",
    "pdf_url": "http://arxiv.org/pdf/2409.07136v1",
    "published_date": "2024-09-11 09:31:44 UTC",
    "updated_date": "2024-09-11 09:31:44 UTC"
  },
  {
    "arxiv_id": "2409.07128v1",
    "title": "Deep Learning Techniques for Hand Vein Biometrics: A Comprehensive Review",
    "authors": [
      "Mustapha Hemis",
      "Hamza Kheddar",
      "Sami Bourouis",
      "Nasir Saleem"
    ],
    "abstract": "Biometric authentication has garnered significant attention as a secure and\nefficient method of identity verification. Among the various modalities, hand\nvein biometrics, including finger vein, palm vein, and dorsal hand vein\nrecognition, offer unique advantages due to their high accuracy, low\nsusceptibility to forgery, and non-intrusiveness. The vein patterns within the\nhand are highly complex and distinct for each individual, making them an ideal\nbiometric identifier. Additionally, hand vein recognition is contactless,\nenhancing user convenience and hygiene compared to other modalities such as\nfingerprint or iris recognition. Furthermore, the veins are internally located,\nrendering them less susceptible to damage or alteration, thus enhancing the\nsecurity and reliability of the biometric system. The combination of these\nfactors makes hand vein biometrics a highly effective and secure method for\nidentity verification. This review paper delves into the latest advancements in\ndeep learning techniques applied to finger vein, palm vein, and dorsal hand\nvein recognition. It encompasses all essential fundamentals of hand vein\nbiometrics, summarizes publicly available datasets, and discusses\nstate-of-the-art metrics used for evaluating the three modes. Moreover, it\nprovides a comprehensive overview of suggested approaches for finger, palm,\ndorsal, and multimodal vein techniques, offering insights into the best\nperformance achieved, data augmentation techniques, and effective transfer\nlearning methods, along with associated pretrained deep learning models.\nAdditionally, the review addresses research challenges faced and outlines\nfuture directions and perspectives, encouraging researchers to enhance existing\nmethods and propose innovative techniques.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CR",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.07128v1",
    "published_date": "2024-09-11 09:25:05 UTC",
    "updated_date": "2024-09-11 09:25:05 UTC"
  },
  {
    "arxiv_id": "2409.07127v2",
    "title": "DCMAC: Demand-aware Customized Multi-Agent Communication via Upper Bound Training",
    "authors": [
      "Dongkun Huo",
      "Huateng Zhang",
      "Yixue Hao",
      "Yuanlin Ye",
      "Long Hu",
      "Rui Wang",
      "Min Chen"
    ],
    "abstract": "Efficient communication can enhance the overall performance of collaborative\nmulti-agent reinforcement learning. A common approach is to share observations\nthrough full communication, leading to significant communication overhead.\nExisting work attempts to perceive the global state by conducting teammate\nmodel based on local information. However, they ignore that the uncertainty\ngenerated by prediction may lead to difficult training. To address this\nproblem, we propose a Demand-aware Customized Multi-Agent Communication (DCMAC)\nprotocol, which use an upper bound training to obtain the ideal policy. By\nutilizing the demand parsing module, agent can interpret the gain of sending\nlocal message on teammate, and generate customized messages via compute the\ncorrelation between demands and local observation using cross-attention\nmechanism. Moreover, our method can adapt to the communication resources of\nagents and accelerate the training progress by appropriating the ideal policy\nwhich is trained with joint observation. Experimental results reveal that DCMAC\nsignificantly outperforms the baseline algorithms in both unconstrained and\ncommunication constrained scenarios.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "Paper has errors and needs to be revised and submitted",
    "pdf_url": "http://arxiv.org/pdf/2409.07127v2",
    "published_date": "2024-09-11 09:23:27 UTC",
    "updated_date": "2024-12-10 02:25:18 UTC"
  },
  {
    "arxiv_id": "2409.07119v1",
    "title": "Credibility-Limited Revision for Epistemic Spaces",
    "authors": [
      "Kai Sauerwald"
    ],
    "abstract": "We consider credibility-limited revision in the framework of belief change\nfor epistemic spaces, permitting inconsistent belief sets and inconsistent\nbeliefs. In this unrestricted setting, the class of credibility-limited\nrevision operators does not include any AGM revision operators. We extend the\nclass of credibility-limited revision operators in a way that all AGM revision\noperators are included while keeping the original spirit of credibility-limited\nrevision. Extended credibility-limited revision operators are defined\naxiomatically. A semantic characterization of extended credibility-limited\nrevision operators that employ total preorders on possible worlds is presented.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.07119v1",
    "published_date": "2024-09-11 09:15:43 UTC",
    "updated_date": "2024-09-11 09:15:43 UTC"
  },
  {
    "arxiv_id": "2409.07115v1",
    "title": "Attention Down-Sampling Transformer, Relative Ranking and Self-Consistency for Blind Image Quality Assessment",
    "authors": [
      "Mohammed Alsaafin",
      "Musab Alsheikh",
      "Saeed Anwar",
      "Muhammad Usman"
    ],
    "abstract": "The no-reference image quality assessment is a challenging domain that\naddresses estimating image quality without the original reference. We introduce\nan improved mechanism to extract local and non-local information from images\nvia different transformer encoders and CNNs. The utilization of Transformer\nencoders aims to mitigate locality bias and generate a non-local representation\nby sequentially processing CNN features, which inherently capture local visual\nstructures. Establishing a stronger connection between subjective and objective\nassessments is achieved through sorting within batches of images based on\nrelative distance information. A self-consistency approach to self-supervision\nis presented, explicitly addressing the degradation of no-reference image\nquality assessment (NR-IQA) models under equivariant transformations. Our\napproach ensures model robustness by maintaining consistency between an image\nand its horizontally flipped equivalent. Through empirical evaluation of five\npopular image quality assessment datasets, the proposed model outperforms\nalternative algorithms in the context of no-reference image quality assessment\ndatasets, especially on smaller datasets. Codes are available at\n\\href{https://github.com/mas94/ADTRS}{https://github.com/mas94/ADTRS}",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "Accepted in International Conference on Image Processing (ICIP)",
    "pdf_url": "http://arxiv.org/pdf/2409.07115v1",
    "published_date": "2024-09-11 09:08:43 UTC",
    "updated_date": "2024-09-11 09:08:43 UTC"
  },
  {
    "arxiv_id": "2409.07114v1",
    "title": "A Continual and Incremental Learning Approach for TinyML On-device Training Using Dataset Distillation and Model Size Adaption",
    "authors": [
      "Marcus R√ºb",
      "Philipp Tuchel",
      "Axel Sikora",
      "Daniel Mueller-Gritschneder"
    ],
    "abstract": "A new algorithm for incremental learning in the context of Tiny Machine\nlearning (TinyML) is presented, which is optimized for low-performance and\nenergy efficient embedded devices. TinyML is an emerging field that deploys\nmachine learning models on resource-constrained devices such as\nmicrocontrollers, enabling intelligent applications like voice recognition,\nanomaly detection, predictive maintenance, and sensor data processing in\nenvironments where traditional machine learning models are not feasible. The\nalgorithm solve the challenge of catastrophic forgetting through the use of\nknowledge distillation to create a small, distilled dataset. The novelty of the\nmethod is that the size of the model can be adjusted dynamically, so that the\ncomplexity of the model can be adapted to the requirements of the task. This\noffers a solution for incremental learning in resource-constrained\nenvironments, where both model size and computational efficiency are critical\nfactors. Results show that the proposed algorithm offers a promising approach\nfor TinyML incremental learning on embedded devices. The algorithm was tested\non five datasets including: CIFAR10, MNIST, CORE50, HAR, Speech Commands. The\nfindings indicated that, despite using only 43% of Floating Point Operations\n(FLOPs) compared to a larger fixed model, the algorithm experienced a\nnegligible accuracy loss of just 1%. In addition, the presented method is\nmemory efficient. While state-of-the-art incremental learning is usually very\nmemory intensive, the method requires only 1% of the original data set.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.07114v1",
    "published_date": "2024-09-11 09:02:33 UTC",
    "updated_date": "2024-09-11 09:02:33 UTC"
  },
  {
    "arxiv_id": "2409.07109v1",
    "title": "Advancing On-Device Neural Network Training with TinyPropv2: Dynamic, Sparse, and Efficient Backpropagation",
    "authors": [
      "Marcus R√ºb",
      "Axel Sikora",
      "Daniel Mueller-Gritschneder"
    ],
    "abstract": "This study introduces TinyPropv2, an innovative algorithm optimized for\non-device learning in deep neural networks, specifically designed for low-power\nmicrocontroller units. TinyPropv2 refines sparse backpropagation by dynamically\nadjusting the level of sparsity, including the ability to selectively skip\ntraining steps. This feature significantly lowers computational effort without\nsubstantially compromising accuracy. Our comprehensive evaluation across\ndiverse datasets CIFAR 10, CIFAR100, Flower, Food, Speech Command, MNIST, HAR,\nand DCASE2020 reveals that TinyPropv2 achieves near-parity with full training\nmethods, with an average accuracy drop of only around 1 percent in most cases.\nFor instance, against full training, TinyPropv2's accuracy drop is minimal, for\nexample, only 0.82 percent on CIFAR 10 and 1.07 percent on CIFAR100. In terms\nof computational effort, TinyPropv2 shows a marked reduction, requiring as\nlittle as 10 percent of the computational effort needed for full training in\nsome scenarios, and consistently outperforms other sparse training\nmethodologies. These findings underscore TinyPropv2's capacity to efficiently\nmanage computational resources while maintaining high accuracy, positioning it\nas an advantageous solution for advanced embedded device applications in the\nIoT ecosystem.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "2024 International Joint Conference on Neural Networks (IJCNN)",
    "pdf_url": "http://arxiv.org/pdf/2409.07109v1",
    "published_date": "2024-09-11 08:56:13 UTC",
    "updated_date": "2024-09-11 08:56:13 UTC"
  },
  {
    "arxiv_id": "2409.07098v1",
    "title": "Redundancy-Aware Camera Selection for Indoor Scene Neural Rendering",
    "authors": [
      "Zehao Wang",
      "Han Zhou",
      "Matthew B. Blaschko",
      "Tinne Tuytelaars",
      "Minye Wu"
    ],
    "abstract": "Novel view synthesis of indoor scenes can be achieved by capturing a\nmonocular video sequence of the environment. However, redundant information\ncaused by artificial movements in the input video data reduces the efficiency\nof scene modeling. In this work, we tackle this challenge from the perspective\nof camera selection. We begin by constructing a similarity matrix that\nincorporates both the spatial diversity of the cameras and the semantic\nvariation of the images. Based on this matrix, we use the Intra-List Diversity\n(ILD) metric to assess camera redundancy, formulating the camera selection task\nas an optimization problem. Then we apply a diversity-based sampling algorithm\nto optimize the camera selection. We also develop a new dataset, IndoorTraj,\nwhich includes long and complex camera movements captured by humans in virtual\nindoor environments, closely mimicking real-world scenarios. Experimental\nresults demonstrate that our strategy outperforms other approaches under time\nand memory constraints. Remarkably, our method achieves performance comparable\nto models trained on the full dataset, while using only an average of 15% of\nthe frames and 75% of the allotted time.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.07098v1",
    "published_date": "2024-09-11 08:36:49 UTC",
    "updated_date": "2024-09-11 08:36:49 UTC"
  },
  {
    "arxiv_id": "2409.07092v1",
    "title": "CWT-Net: Super-resolution of Histopathology Images Using a Cross-scale Wavelet-based Transformer",
    "authors": [
      "Feiyang Jia",
      "Zhineng Chen",
      "Ziying Song",
      "Lin Liu",
      "Caiyan Jia"
    ],
    "abstract": "Super-resolution (SR) aims to enhance the quality of low-resolution images\nand has been widely applied in medical imaging. We found that the design\nprinciples of most existing methods are influenced by SR tasks based on\nreal-world images and do not take into account the significance of the\nmulti-level structure in pathological images, even if they can achieve\nrespectable objective metric evaluations. In this work, we delve into two\nsuper-resolution working paradigms and propose a novel network called CWT-Net,\nwhich leverages cross-scale image wavelet transform and Transformer\narchitecture. Our network consists of two branches: one dedicated to learning\nsuper-resolution and the other to high-frequency wavelet features. To generate\nhigh-resolution histopathology images, the Transformer module shares and fuses\nfeatures from both branches at various stages. Notably, we have designed a\nspecialized wavelet reconstruction module to effectively enhance the wavelet\ndomain features and enable the network to operate in different modes, allowing\nfor the introduction of additional relevant information from cross-scale\nimages. Our experimental results demonstrate that our model significantly\noutperforms state-of-the-art methods in both performance and visualization\nevaluations and can substantially boost the accuracy of image diagnostic\nnetworks.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.07092v1",
    "published_date": "2024-09-11 08:26:28 UTC",
    "updated_date": "2024-09-11 08:26:28 UTC"
  },
  {
    "arxiv_id": "2409.07088v1",
    "title": "Ontology-Free General-Domain Knowledge Graph-to-Text Generation Dataset Synthesis using Large Language Model",
    "authors": [
      "Daehee Kim",
      "Deokhyung Kang",
      "Sangwon Ryu",
      "Gary Geunbae Lee"
    ],
    "abstract": "Knowledge Graph-to-Text (G2T) generation involves verbalizing structured\nknowledge graphs into natural language text. Recent advancements in Pretrained\nLanguage Models (PLMs) have improved G2T performance, but their effectiveness\ndepends on datasets with precise graph-text alignment. However, the scarcity of\nhigh-quality, general-domain G2T generation datasets restricts progress in the\ngeneral-domain G2T generation research. To address this issue, we introduce\nWikipedia Ontology-Free Graph-text dataset (WikiOFGraph), a new large-scale G2T\ndataset generated using a novel method that leverages Large Language Model\n(LLM) and Data-QuestEval. Our new dataset, which contains 5.85M general-domain\ngraph-text pairs, offers high graph-text consistency without relying on\nexternal ontologies. Experimental results demonstrate that PLM fine-tuned on\nWikiOFGraph outperforms those trained on other datasets across various\nevaluation metrics. Our method proves to be a scalable and effective solution\nfor generating high-quality G2T data, significantly advancing the field of G2T\ngeneration.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2409.07088v1",
    "published_date": "2024-09-11 08:16:20 UTC",
    "updated_date": "2024-09-11 08:16:20 UTC"
  },
  {
    "arxiv_id": "2409.07078v1",
    "title": "Multimodal Emotion Recognition with Vision-language Prompting and Modality Dropout",
    "authors": [
      "Anbin QI",
      "Zhongliang Liu",
      "Xinyong Zhou",
      "Jinba Xiao",
      "Fengrun Zhang",
      "Qi Gan",
      "Ming Tao",
      "Gaozheng Zhang",
      "Lu Zhang"
    ],
    "abstract": "In this paper, we present our solution for the Second Multimodal Emotion\nRecognition Challenge Track 1(MER2024-SEMI). To enhance the accuracy and\ngeneralization performance of emotion recognition, we propose several methods\nfor Multimodal Emotion Recognition. Firstly, we introduce EmoVCLIP, a model\nfine-tuned based on CLIP using vision-language prompt learning, designed for\nvideo-based emotion recognition tasks. By leveraging prompt learning on CLIP,\nEmoVCLIP improves the performance of pre-trained CLIP on emotional videos.\nAdditionally, to address the issue of modality dependence in multimodal fusion,\nwe employ modality dropout for robust information fusion. Furthermore, to aid\nBaichuan in better extracting emotional information, we suggest using GPT-4 as\nthe prompt for Baichuan. Lastly, we utilize a self-training strategy to\nleverage unlabeled videos. In this process, we use unlabeled videos with\nhigh-confidence pseudo-labels generated by our model and incorporate them into\nthe training set. Experimental results demonstrate that our model ranks 1st in\nthe MER2024-SEMI track, achieving an accuracy of 90.15% on the test set.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.07078v1",
    "published_date": "2024-09-11 08:06:47 UTC",
    "updated_date": "2024-09-11 08:06:47 UTC"
  },
  {
    "arxiv_id": "2409.07055v2",
    "title": "Legal Fact Prediction: The Missing Piece in Legal Judgment Prediction",
    "authors": [
      "Junkai Liu",
      "Yujie Tong",
      "Hui Huang",
      "Bowen Zheng",
      "Yiran Hu",
      "Peicheng Wu",
      "Chuan Xiao",
      "Makoto Onizuka",
      "Muyun Yang",
      "Shuyuan Zheng"
    ],
    "abstract": "Legal judgment prediction (LJP), which enables litigants and their lawyers to\nforecast judgment outcomes and refine litigation strategies, has emerged as a\ncrucial legal NLP task. Existing studies typically utilize legal facts, i.e.,\nfacts that have been established by evidence and determined by the judge, to\npredict the judgment. However, legal facts are often difficult to obtain in the\nearly stages of litigation, significantly limiting the practical applicability\nof fact-based LJP. To address this limitation, we propose a novel legal NLP\ntask: \\textit{legal fact prediction} (LFP), which takes the evidence submitted\nby litigants for trial as input to predict legal facts, thereby empowering\nfact-based LJP technologies to perform prediction in the absence of\nground-truth legal facts. We also propose the first benchmark dataset,\nLFPBench, for evaluating the LFP task. Our extensive experiments on LFPBench\ndemonstrate the effectiveness of LFP-empowered LJP and highlight promising\nresearch directions for LFP. Our code and data are available at\nhttps://github.com/HPRCEST/LFPBench.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.07055v2",
    "published_date": "2024-09-11 07:01:08 UTC",
    "updated_date": "2025-03-06 05:48:54 UTC"
  },
  {
    "arxiv_id": "2409.07054v2",
    "title": "Native vs Non-Native Language Prompting: A Comparative Analysis",
    "authors": [
      "Mohamed Bayan Kmainasi",
      "Rakif Khan",
      "Ali Ezzat Shahroor",
      "Boushra Bendou",
      "Maram Hasanain",
      "Firoj Alam"
    ],
    "abstract": "Large language models (LLMs) have shown remarkable abilities in different\nfields, including standard Natural Language Processing (NLP) tasks. To elicit\nknowledge from LLMs, prompts play a key role, consisting of natural language\ninstructions. Most open and closed source LLMs are trained on available labeled\nand unlabeled resources--digital content such as text, images, audio, and\nvideos. Hence, these models have better knowledge for high-resourced languages\nbut struggle with low-resourced languages. Since prompts play a crucial role in\nunderstanding their capabilities, the language used for prompts remains an\nimportant research question. Although there has been significant research in\nthis area, it is still limited, and less has been explored for medium to\nlow-resourced languages. In this study, we investigate different prompting\nstrategies (native vs. non-native) on 11 different NLP tasks associated with 12\ndifferent Arabic datasets (9.7K data points). In total, we conducted 197\nexperiments involving 3 LLMs, 12 datasets, and 3 prompting strategies. Our\nfindings suggest that, on average, the non-native prompt performs the best,\nfollowed by mixed and native prompts.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T50",
      "F.2.2; I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "Foundation Models, Large Language Models, Arabic NLP, LLMs, Native,\n  Contextual Understanding, Arabic LLM",
    "pdf_url": "http://arxiv.org/pdf/2409.07054v2",
    "published_date": "2024-09-11 06:59:37 UTC",
    "updated_date": "2024-10-06 10:16:27 UTC"
  },
  {
    "arxiv_id": "2409.07045v1",
    "title": "Beyond IID: Optimizing Instruction Learning from the Perspective of Instruction Interaction and Dependency",
    "authors": [
      "Hanyu Zhao",
      "Li Du",
      "Yiming Ju",
      "Chengwei Wu",
      "Tengfei Pan"
    ],
    "abstract": "With the availability of various instruction datasets, a pivotal challenge is\nhow to effectively select and integrate these instructions to fine-tune large\nlanguage models (LLMs). Previous research mainly focuses on selecting\nindividual high-quality instructions. However, these works overlooked the joint\ninteractions and dependencies between different categories of instructions,\nleading to suboptimal selection strategies. Moreover, the nature of these\ninteraction patterns remains largely unexplored, let alone optimize the\ninstruction set with regard to them. To fill these gaps, in this paper, we: (1)\nsystemically investigate interaction and dependency patterns between different\ncategories of instructions, (2) manage to optimize the instruction set\nconcerning the interaction patterns using a linear programming-based method,\nand optimize the learning schema of SFT using an instruction dependency\ntaxonomy guided curriculum learning. Experimental results across different LLMs\ndemonstrate improved performance over strong baselines on widely adopted\nbenchmarks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.07045v1",
    "published_date": "2024-09-11 06:27:50 UTC",
    "updated_date": "2024-09-11 06:27:50 UTC"
  },
  {
    "arxiv_id": "2409.07033v1",
    "title": "E-commerce Webpage Recommendation Scheme Base on Semantic Mining and Neural Networks",
    "authors": [
      "Wenchao Zhao",
      "Xiaoyi Liu",
      "Ruilin Xu",
      "Lingxi Xiao",
      "Muqing Li"
    ],
    "abstract": "In e-commerce websites, web mining web page recommendation technology has\nbeen widely used. However, recommendation solutions often cannot meet the\nactual application needs of online shopping users. To address this problem,\nthis paper proposes an e-commerce web page recommendation solution that\ncombines semantic web mining and BP neural networks. First, the web logs of\nuser searches are processed, and 5 features are extracted: content priority,\ntime consumption priority, online shopping users' explicit/implicit feedback on\nthe website, recommendation semantics and input deviation amount. Then, these\nfeatures are used as input features of the BP neural network to classify and\nidentify the priority of the final output web page. Finally, the web pages are\nsorted according to priority and recommended to users. This project uses book\nsales webpages as samples for experiments. The results show that this solution\ncan quickly and accurately identify the webpages required by users.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "arXiv admin note: text overlap with arXiv:2409.01137",
    "pdf_url": "http://arxiv.org/pdf/2409.07033v1",
    "published_date": "2024-09-11 06:03:02 UTC",
    "updated_date": "2024-09-11 06:03:02 UTC"
  },
  {
    "arxiv_id": "2409.07016v1",
    "title": "Improving Anomalous Sound Detection via Low-Rank Adaptation Fine-Tuning of Pre-Trained Audio Models",
    "authors": [
      "Xinhu Zheng",
      "Anbai Jiang",
      "Bing Han",
      "Yanmin Qian",
      "Pingyi Fan",
      "Jia Liu",
      "Wei-Qiang Zhang"
    ],
    "abstract": "Anomalous Sound Detection (ASD) has gained significant interest through the\napplication of various Artificial Intelligence (AI) technologies in industrial\nsettings. Though possessing great potential, ASD systems can hardly be readily\ndeployed in real production sites due to the generalization problem, which is\nprimarily caused by the difficulty of data collection and the complexity of\nenvironmental factors. This paper introduces a robust ASD model that leverages\naudio pre-trained models. Specifically, we fine-tune these models using machine\noperation data, employing SpecAug as a data augmentation strategy.\nAdditionally, we investigate the impact of utilizing Low-Rank Adaptation (LoRA)\ntuning instead of full fine-tuning to address the problem of limited data for\nfine-tuning. Our experiments on the DCASE2023 Task 2 dataset establish a new\nbenchmark of 77.75% on the evaluation set, with a significant improvement of\n6.48% compared with previous state-of-the-art (SOTA) models, including top-tier\ntraditional convolutional networks and speech pre-trained models, which\ndemonstrates the effectiveness of audio pre-trained models with LoRA tuning.\nAblation studies are also conducted to showcase the efficacy of the proposed\nscheme.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.07016v1",
    "published_date": "2024-09-11 05:19:38 UTC",
    "updated_date": "2024-09-11 05:19:38 UTC"
  },
  {
    "arxiv_id": "2409.07012v2",
    "title": "Towards Predicting Temporal Changes in a Patient's Chest X-ray Images based on Electronic Health Records",
    "authors": [
      "Daeun Kyung",
      "Junu Kim",
      "Tackeun Kim",
      "Edward Choi"
    ],
    "abstract": "Chest X-ray (CXR) is an important diagnostic tool widely used in hospitals to\nassess patient conditions and monitor changes over time. Recently, generative\nmodels, specifically diffusion-based models, have shown promise in generating\nrealistic synthetic CXRs. However, these models mainly focus on conditional\ngeneration using single-time-point data, i.e., generating CXRs conditioned on\ntheir corresponding reports from a specific time. This limits their clinical\nutility, particularly for capturing temporal changes. To address this\nlimitation, we propose a novel framework, EHRXDiff, which predicts future CXR\nimages by integrating previous CXRs with subsequent medical events, e.g.,\nprescriptions, lab measures, etc. Our framework dynamically tracks and predicts\ndisease progression based on a latent diffusion model, conditioned on the\nprevious CXR image and a history of medical events. We comprehensively evaluate\nthe performance of our framework across three key aspects, including clinical\nconsistency, demographic consistency, and visual realism. Results show that our\nframework generates high-quality, realistic future images that effectively\ncapture potential temporal changes. This suggests that our framework could be\nfurther developed to support clinical decision-making and provide valuable\ninsights for patient monitoring and treatment planning in the medical field.\nThe code is available at https://github.com/dek924/EHRXDiff.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "Accepted at Proc. of Conference on Health, Inference, and Learning\n  (CHIL) 2025 (10 pages for main text, 3 pages for references, 8 pages for\n  supplementary materials)",
    "pdf_url": "http://arxiv.org/pdf/2409.07012v2",
    "published_date": "2024-09-11 04:49:44 UTC",
    "updated_date": "2025-05-06 00:52:51 UTC"
  },
  {
    "arxiv_id": "2409.06997v1",
    "title": "What is the Right Notion of Distance between Predict-then-Optimize Tasks?",
    "authors": [
      "Paula Rodriguez-Diaz",
      "Lingkai Kong",
      "Kai Wang",
      "David Alvarez-Melis",
      "Milind Tambe"
    ],
    "abstract": "Comparing datasets is a fundamental task in machine learning, essential for\nvarious learning paradigms; from evaluating train and test datasets for model\ngeneralization to using dataset similarity for detecting data drift. While\ntraditional notions of dataset distances offer principled measures of\nsimilarity, their utility has largely been assessed through prediction error\nminimization. However, in Predict-then-Optimize (PtO) frameworks, where\npredictions serve as inputs for downstream optimization tasks, model\nperformance is measured through decision regret minimization rather than\nprediction error minimization. In this work, we (i) show that traditional\ndataset distances, which rely solely on feature and label dimensions, lack\ninformativeness in the PtO context, and (ii) propose a new dataset distance\nthat incorporates the impacts of downstream decisions. Our results show that\nthis decision-aware dataset distance effectively captures adaptation success in\nPtO contexts, providing a PtO adaptation bound in terms of dataset distance.\nEmpirically, we show that our proposed distance measure accurately predicts\ntransferability across three different PtO tasks from the literature.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.06997v1",
    "published_date": "2024-09-11 04:13:17 UTC",
    "updated_date": "2024-09-11 04:13:17 UTC"
  },
  {
    "arxiv_id": "2409.06978v1",
    "title": "Large Language Models and the Extended Church-Turing Thesis",
    "authors": [
      "Ji≈ô√≠ Wiedermann",
      "Jan van Leeuwen"
    ],
    "abstract": "The Extended Church-Turing Thesis (ECTT) posits that all effective\ninformation processing, including unbounded and non-uniform interactive\ncomputations, can be described in terms of interactive Turing machines with\nadvice. Does this assertion also apply to the abilities of contemporary large\nlanguage models (LLMs)? From a broader perspective, this question calls for an\ninvestigation of the computational power of LLMs by the classical means of\ncomputability and computational complexity theory, especially the theory of\nautomata. Along these lines, we establish a number of fundamental results.\nFirstly, we argue that any fixed (non-adaptive) LLM is computationally\nequivalent to a, possibly very large, deterministic finite-state transducer.\nThis characterizes the base level of LLMs. We extend this to a key result\nconcerning the simulation of space-bounded Turing machines by LLMs. Secondly,\nwe show that lineages of evolving LLMs are computationally equivalent to\ninteractive Turing machines with advice. The latter finding confirms the\nvalidity of the ECTT for lineages of LLMs. From a computability viewpoint, it\nalso suggests that lineages of LLMs possess super-Turing computational power.\nConsequently, in our computational model knowledge generation is in general a\nnon-algorithmic process realized by lineages of LLMs. Finally, we discuss the\nmerits of our findings in the broader context of several related disciplines\nand philosophies.",
    "categories": [
      "cs.FL",
      "cs.AI"
    ],
    "primary_category": "cs.FL",
    "comment": "In Proceedings NCMA 2024, arXiv:2409.06120",
    "pdf_url": "http://arxiv.org/pdf/2409.06978v1",
    "published_date": "2024-09-11 03:09:55 UTC",
    "updated_date": "2024-09-11 03:09:55 UTC"
  },
  {
    "arxiv_id": "2409.06957v2",
    "title": "Policy Filtration in RLHF to Fine-Tune LLM for Code Generation",
    "authors": [
      "Wei Shen",
      "Chuheng Zhang"
    ],
    "abstract": "Reinforcement learning from human feedback (RLHF) is one of the key\ntechniques that helps large language models (LLMs) to follow instructions and\nprovide helpful and harmless responses. While direct policy optimization\nmethods exist, state-of-the-art LLMs adopt RL-based methods (usually PPO) in\nRLHF to train the policy to generate good responses guided by a reward model\nlearned from preference data. The main challenge of these methods is the\ninaccuracy of the intermediate reward model, especially in code generation\ntasks that require long and complex reasoning to score a response. We find that\nthe reliability of the reward model varies across responses assigned with\ndifferent rewards. This motivates us to filter the samples whose rewards may be\nunreliable to improve signal-to-noise ratio during policy learning, resulting\nin Policy Filtration for Proximal Policy Optimization (PF-PPO). To choose a\nproper policy filtration strategy for a given reward model, the coefficient of\ndetermination ($R^2$) between rewards and actual scores on filtered samples\nserves as a good metrics and helps us find several promising strategies. We\nprovide extensive experiments to validate the effectiveness of PF-PPO in code\ngeneration tasks, and find that some variants of PF-PPO are highly effective\nand achieve new state-of-the-art performance across 7-billion-parameter models\non HumanEval, MBPP, and a new and more challenging LeetCode Contest benchmark.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.06957v2",
    "published_date": "2024-09-11 02:40:38 UTC",
    "updated_date": "2024-12-10 06:21:47 UTC"
  },
  {
    "arxiv_id": "2409.06953v4",
    "title": "Neural Algorithmic Reasoning with Multiple Correct Solutions",
    "authors": [
      "Zeno Kujawa",
      "John Poole",
      "Dobrik Georgiev",
      "Danilo Numeroso",
      "Henry Fleischmann",
      "Pietro Li√≤"
    ],
    "abstract": "Neural Algorithmic Reasoning (NAR) extends classical algorithms to higher\ndimensional data. However, canonical implementations of NAR train neural\nnetworks to return only a single solution, even when there are multiple correct\nsolutions to a problem, such as single-source shortest paths. For some\napplications, it is desirable to recover more than one correct solution. To\nthat end, we give the first method for NAR with multiple solutions. We\ndemonstrate our method on two classical algorithms: Bellman-Ford (BF) and\nDepth-First Search (DFS), favouring deeper insight into two algorithms over a\nbroader survey of algorithms. This method involves generating appropriate\ntraining data as well as sampling and validating solutions from model output.\nEach step of our method, which can serve as a framework for neural algorithmic\nreasoning beyond the tasks presented in this paper, might be of independent\ninterest to the field and our results represent the first attempt at this task\nin the NAR literature.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.06953v4",
    "published_date": "2024-09-11 02:29:53 UTC",
    "updated_date": "2025-05-11 07:01:18 UTC"
  },
  {
    "arxiv_id": "2409.06949v1",
    "title": "You Have Thirteen Hours in Which to Solve the Labyrinth: Enhancing AI Game Masters with Function Calling",
    "authors": [
      "Jaewoo Song",
      "Andrew Zhu",
      "Chris Callison-Burch"
    ],
    "abstract": "Developing a consistent and reliable AI game master for text-based games is a\nchallenging task due to the limitations of large language models (LLMs) and the\ncomplexity of the game master's role. This paper presents a novel approach to\nenhance AI game masters by leveraging function calling in the context of the\ntable-top role-playing game \"Jim Henson's Labyrinth: The Adventure Game.\" Our\nmethodology involves integrating game-specific controls through functions,\nwhich we show improves the narrative quality and state update consistency of\nthe AI game master. The experimental results, based on human evaluations and\nunit tests, demonstrate the effectiveness of our approach in enhancing gameplay\nexperience and maintaining coherence with the game state. This work contributes\nto the advancement of game AI and interactive storytelling, offering insights\ninto the design of more engaging and consistent AI-driven game masters.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Wordplay Workshop @ ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2409.06949v1",
    "published_date": "2024-09-11 02:03:51 UTC",
    "updated_date": "2024-09-11 02:03:51 UTC"
  },
  {
    "arxiv_id": "2409.13745v1",
    "title": "Context-Aware Membership Inference Attacks against Pre-trained Large Language Models",
    "authors": [
      "Hongyan Chang",
      "Ali Shahin Shamsabadi",
      "Kleomenis Katevas",
      "Hamed Haddadi",
      "Reza Shokri"
    ],
    "abstract": "Prior Membership Inference Attacks (MIAs) on pre-trained Large Language\nModels (LLMs), adapted from classification model attacks, fail due to ignoring\nthe generative process of LLMs across token sequences. In this paper, we\npresent a novel attack that adapts MIA statistical tests to the perplexity\ndynamics of subsequences within a data point. Our method significantly\noutperforms prior loss-based approaches, revealing context-dependent\nmemorization patterns in pre-trained LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.13745v1",
    "published_date": "2024-09-11 01:56:35 UTC",
    "updated_date": "2024-09-11 01:56:35 UTC"
  },
  {
    "arxiv_id": "2409.06945v1",
    "title": "FSMDet: Vision-guided feature diffusion for fully sparse 3D detector",
    "authors": [
      "Tianran Liu",
      "Morteza Mousa Pasandi",
      "Robert Laganiere"
    ],
    "abstract": "Fully sparse 3D detection has attracted an increasing interest in the recent\nyears. However, the sparsity of the features in these frameworks challenges the\ngeneration of proposals because of the limited diffusion process. In addition,\nthe quest for efficiency has led to only few work on vision-assisted fully\nsparse models. In this paper, we propose FSMDet (Fully Sparse Multi-modal\nDetection), which use visual information to guide the LiDAR feature diffusion\nprocess while still maintaining the efficiency of the pipeline. Specifically,\nmost of fully sparse works focus on complex customized center fusion\ndiffusion/regression operators. However, we observed that if the adequate\nobject completion is performed, even the simplest interpolation operator leads\nto satisfactory results. Inspired by this observation, we split the\nvision-guided diffusion process into two modules: a Shape Recover Layer\n(SRLayer) and a Self Diffusion Layer (SDLayer). The former uses RGB information\nto recover the shape of the visible part of an object, and the latter uses a\nvisual prior to further spread the features to the center region. Experiments\ndemonstrate that our approach successfully improves the performance of previous\nfully sparse models that use LiDAR only and reaches SOTA performance in\nmultimodal models. At the same time, thanks to the sparse architecture, our\nmethod can be up to 5 times more efficient than previous SOTA methods in the\ninference process.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by European Conference on Computer Vision (ECCV) 2024\n  workshop on VCAD",
    "pdf_url": "http://arxiv.org/pdf/2409.06945v1",
    "published_date": "2024-09-11 01:55:45 UTC",
    "updated_date": "2024-09-11 01:55:45 UTC"
  },
  {
    "arxiv_id": "2409.06941v2",
    "title": "FreeRide: Harvesting Bubbles in Pipeline Parallelism",
    "authors": [
      "Jiashu Zhang",
      "Zihan Pan",
      "Molly",
      "Xu",
      "Khuzaima Daudjee",
      "Sihang Liu"
    ],
    "abstract": "The occurrence of bubbles in pipeline parallelism is an inherent limitation\nthat can account for more than 40% of the large language model (LLM) training\ntime and is one of the main reasons for the underutilization of GPU resources\nin LLM training. Harvesting these bubbles for GPU side tasks can increase\nresource utilization and reduce training costs but comes with challenges.\nFirst, because bubbles are discontinuous with various shapes, programming side\ntasks becomes difficult while requiring excessive engineering effort. Second, a\nside task can compete with pipeline training for GPU resources and incur\nsignificant overhead. To address these challenges, we propose FreeRide, a\nsystem designed to harvest bubbles in pipeline parallelism for side tasks.\nFreeRide provides programmers with interfaces to implement side tasks easily,\nmanages bubbles and side tasks during pipeline training, and controls access to\nGPU resources by side tasks to reduce overhead. We demonstrate that FreeRide\nachieves 7.8% average cost savings with a negligible overhead of about 1% in\ntraining LLMs while serving model training, graph analytics, and image\nprocessing side tasks.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.06941v2",
    "published_date": "2024-09-11 01:46:49 UTC",
    "updated_date": "2025-04-27 05:25:56 UTC"
  },
  {
    "arxiv_id": "2409.06928v1",
    "title": "Intrapartum Ultrasound Image Segmentation of Pubic Symphysis and Fetal Head Using Dual Student-Teacher Framework with CNN-ViT Collaborative Learning",
    "authors": [
      "Jianmei Jiang",
      "Huijin Wang",
      "Jieyun Bai",
      "Shun Long",
      "Shuangping Chen",
      "Victor M. Campello",
      "Karim Lekadir"
    ],
    "abstract": "The segmentation of the pubic symphysis and fetal head (PSFH) constitutes a\npivotal step in monitoring labor progression and identifying potential delivery\ncomplications. Despite the advances in deep learning, the lack of annotated\nmedical images hinders the training of segmentation. Traditional\nsemi-supervised learning approaches primarily utilize a unified network model\nbased on Convolutional Neural Networks (CNNs) and apply consistency\nregularization to mitigate the reliance on extensive annotated data. However,\nthese methods often fall short in capturing the discriminative features of\nunlabeled data and in delineating the long-range dependencies inherent in the\nambiguous boundaries of PSFH within ultrasound images. To address these\nlimitations, we introduce a novel framework, the Dual-Student and Teacher\nCombining CNN and Transformer (DSTCT), which synergistically integrates the\ncapabilities of CNNs and Transformers. Our framework comprises a Vision\nTransformer (ViT) as the teacher and two student mod ls one ViT and one CNN.\nThis dual-student setup enables mutual supervision through the generation of\nboth hard and soft pseudo-labels, with the consistency in their predictions\nbeing refined by minimizing the classifier determinacy discrepancy. The teacher\nmodel further reinforces learning within this architecture through the\nimposition of consistency regularization constraints. To augment the\ngeneralization abilities of our approach, we employ a blend of data and model\nperturbation techniques. Comprehensive evaluations on the benchmark dataset of\nthe PSFH Segmentation Grand Challenge at MICCAI 2023 demonstrate our DSTCT\nframework outperformed ten contemporary semi-supervised segmentation methods.\nCode available at https://github.com/jjm1589/DSTCT.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.06928v1",
    "published_date": "2024-09-11 00:57:31 UTC",
    "updated_date": "2024-09-11 00:57:31 UTC"
  },
  {
    "arxiv_id": "2409.13744v2",
    "title": "A Simplified Retriever to Improve Accuracy of Phenotype Normalizations by Large Language Models",
    "authors": [
      "Daniel B. Hier",
      "Thanh Son Do",
      "Tayo Obafemi-Ajayi"
    ],
    "abstract": "Large language models (LLMs) have shown improved accuracy in phenotype term\nnormalization tasks when augmented with retrievers that suggest candidate\nnormalizations based on term definitions. In this work, we introduce a\nsimplified retriever that enhances LLM accuracy by searching the Human\nPhenotype Ontology (HPO) for candidate matches using contextual word embeddings\nfrom BioBERT without the need for explicit term definitions. Testing this\nmethod on terms derived from the clinical synopses of Online Mendelian\nInheritance in Man (OMIM), we demonstrate that the normalization accuracy of a\nstate-of-the-art LLM increases from a baseline of 62.3% without augmentation to\n90.3% with retriever augmentation. This approach is potentially generalizable\nto other biomedical term normalization tasks and offers an efficient\nalternative to more complex retrieval methods.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "68",
      "I.2"
    ],
    "primary_category": "cs.CL",
    "comment": "Published by Frontiers in Digital Health",
    "pdf_url": "http://arxiv.org/pdf/2409.13744v2",
    "published_date": "2024-09-11 00:16:17 UTC",
    "updated_date": "2025-03-04 19:15:49 UTC"
  },
  {
    "arxiv_id": "2409.07503v1",
    "title": "AdaPPA: Adaptive Position Pre-Fill Jailbreak Attack Approach Targeting LLMs",
    "authors": [
      "Lijia Lv",
      "Weigang Zhang",
      "Xuehai Tang",
      "Jie Wen",
      "Feng Liu",
      "Jizhong Han",
      "Songlin Hu"
    ],
    "abstract": "Jailbreak vulnerabilities in Large Language Models (LLMs) refer to methods\nthat extract malicious content from the model by carefully crafting prompts or\nsuffixes, which has garnered significant attention from the research community.\nHowever, traditional attack methods, which primarily focus on the semantic\nlevel, are easily detected by the model. These methods overlook the difference\nin the model's alignment protection capabilities at different output stages. To\naddress this issue, we propose an adaptive position pre-fill jailbreak attack\napproach for executing jailbreak attacks on LLMs. Our method leverages the\nmodel's instruction-following capabilities to first output pre-filled safe\ncontent, then exploits its narrative-shifting abilities to generate harmful\ncontent. Extensive black-box experiments demonstrate our method can improve the\nattack success rate by 47% on the widely recognized secure model (Llama2)\ncompared to existing approaches. Our code can be found at:\nhttps://github.com/Yummy416/AdaPPA.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.07503v1",
    "published_date": "2024-09-11 00:00:58 UTC",
    "updated_date": "2024-09-11 00:00:58 UTC"
  }
]