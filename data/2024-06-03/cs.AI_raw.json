[
  {
    "arxiv_id": "2406.01853v1",
    "title": "Multi-Agent Reinforcement Learning Meets Leaf Sequencing in Radiotherapy",
    "authors": [
      "Riqiang Gao",
      "Florin C. Ghesu",
      "Simon Arberet",
      "Shahab Basiri",
      "Esa Kuusela",
      "Martin Kraus",
      "Dorin Comaniciu",
      "Ali Kamen"
    ],
    "abstract": "In contemporary radiotherapy planning (RTP), a key module leaf sequencing is\npredominantly addressed by optimization-based approaches. In this paper, we\npropose a novel deep reinforcement learning (DRL) model termed as Reinforced\nLeaf Sequencer (RLS) in a multi-agent framework for leaf sequencing. The RLS\nmodel offers improvements to time-consuming iterative optimization steps via\nlarge-scale training and can control movement patterns through the design of\nreward mechanisms. We have conducted experiments on four datasets with four\nmetrics and compared our model with a leading optimization sequencer. Our\nfindings reveal that the proposed RLS model can achieve reduced fluence\nreconstruction errors, and potential faster convergence when integrated in an\noptimization planner. Additionally, RLS has shown promising results in a full\nartificial intelligence RTP pipeline. We hope this pioneer multi-agent RL leaf\nsequencer can foster future research on machine learning for RTP.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.01853v1",
    "published_date": "2024-06-03 23:55:20 UTC",
    "updated_date": "2024-06-03 23:55:20 UTC"
  },
  {
    "arxiv_id": "2406.01838v2",
    "title": "Learning the Target Network in Function Space",
    "authors": [
      "Kavosh Asadi",
      "Yao Liu",
      "Shoham Sabach",
      "Ming Yin",
      "Rasool Fakoor"
    ],
    "abstract": "We focus on the task of learning the value function in the reinforcement\nlearning (RL) setting. This task is often solved by updating a pair of online\nand target networks while ensuring that the parameters of these two networks\nare equivalent. We propose Lookahead-Replicate (LR), a new value-function\napproximation algorithm that is agnostic to this parameter-space equivalence.\nInstead, the LR algorithm is designed to maintain an equivalence between the\ntwo networks in the function space. This value-based equivalence is obtained by\nemploying a new target-network update. We show that LR leads to a convergent\nbehavior in learning the value function. We also present empirical results\ndemonstrating that LR-based target-network updates significantly improve deep\nRL on the Atari benchmark.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to International Conference on Machine Learning (ICML24)",
    "pdf_url": "http://arxiv.org/pdf/2406.01838v2",
    "published_date": "2024-06-03 23:10:35 UTC",
    "updated_date": "2024-09-23 02:43:55 UTC"
  },
  {
    "arxiv_id": "2406.01835v1",
    "title": "An Open Multilingual System for Scoring Readability of Wikipedia",
    "authors": [
      "Mykola Trokhymovych",
      "Indira Sen",
      "Martin Gerlach"
    ],
    "abstract": "With over 60M articles, Wikipedia has become the largest platform for open\nand freely accessible knowledge. While it has more than 15B monthly visits, its\ncontent is believed to be inaccessible to many readers due to the lack of\nreadability of its text. However, previous investigations of the readability of\nWikipedia have been restricted to English only, and there are currently no\nsystems supporting the automatic readability assessment of the 300+ languages\nin Wikipedia. To bridge this gap, we develop a multilingual model to score the\nreadability of Wikipedia articles. To train and evaluate this model, we create\na novel multilingual dataset spanning 14 languages, by matching articles from\nWikipedia to simplified Wikipedia and online children encyclopedias. We show\nthat our model performs well in a zero-shot scenario, yielding a ranking\naccuracy of more than 80% across 14 languages and improving upon previous\nbenchmarks. These results demonstrate the applicability of the model at scale\nfor languages in which there is no ground-truth data available for model\nfine-tuning. Furthermore, we provide the first overview on the state of\nreadability in Wikipedia beyond English.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01835v1",
    "published_date": "2024-06-03 23:07:18 UTC",
    "updated_date": "2024-06-03 23:07:18 UTC"
  },
  {
    "arxiv_id": "2406.01833v2",
    "title": "CAFO: Feature-Centric Explanation on Time Series Classification",
    "authors": [
      "Jaeho Kim",
      "Seok-Ju Hahn",
      "Yoontae Hwang",
      "Junghye Lee",
      "Seulki Lee"
    ],
    "abstract": "In multivariate time series (MTS) classification, finding the important\nfeatures (e.g., sensors) for model performance is crucial yet challenging due\nto the complex, high-dimensional nature of MTS data, intricate temporal\ndynamics, and the necessity for domain-specific interpretations. Current\nexplanation methods for MTS mostly focus on time-centric explanations, apt for\npinpointing important time periods but less effective in identifying key\nfeatures. This limitation underscores the pressing need for a feature-centric\napproach, a vital yet often overlooked perspective that complements\ntime-centric analysis. To bridge this gap, our study introduces a novel\nfeature-centric explanation and evaluation framework for MTS, named CAFO\n(Channel Attention and Feature Orthgonalization). CAFO employs a\nconvolution-based approach with channel attention mechanisms, incorporating a\ndepth-wise separable channel attention module (DepCA) and a QR\ndecomposition-based loss for promoting feature-wise orthogonality. We\ndemonstrate that this orthogonalization enhances the separability of attention\ndistributions, thereby refining and stabilizing the ranking of feature\nimportance. This improvement in feature-wise ranking enhances our understanding\nof feature explainability in MTS. Furthermore, we develop metrics to evaluate\nglobal and class-specific feature importance. Our framework's efficacy is\nvalidated through extensive empirical analyses on two major public benchmarks\nand real-world datasets, both synthetic and self-collected, specifically\ndesigned to highlight class-wise discriminative features. The results confirm\nCAFO's robustness and informative capacity in assessing feature importance in\nMTS classification tasks. This study not only advances the understanding of\nfeature-centric explanations in MTS but also sets a foundation for future\nexplorations in feature-centric explanations.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to KDD 2024 Research Track",
    "pdf_url": "http://arxiv.org/pdf/2406.01833v2",
    "published_date": "2024-06-03 23:06:45 UTC",
    "updated_date": "2024-06-12 01:27:51 UTC"
  },
  {
    "arxiv_id": "2406.01832v1",
    "title": "A Robust Filter for Marker-less Multi-person Tracking in Human-Robot Interaction Scenarios",
    "authors": [
      "Enrico Martini",
      "Harshil Parekh",
      "Shaoting Peng",
      "Nicola Bombieri",
      "Nadia Figueroa"
    ],
    "abstract": "Pursuing natural and marker-less human-robot interaction (HRI) has been a\nlong-standing robotics research focus, driven by the vision of seamless\ncollaboration without physical markers. Marker-less approaches promise an\nimproved user experience, but state-of-the-art struggles with the challenges\nposed by intrinsic errors in human pose estimation (HPE) and depth cameras.\nThese errors can lead to issues such as robot jittering, which can\nsignificantly impact the trust users have in collaborative systems. We propose\na filtering pipeline that refines incomplete 3D human poses from an HPE\nbackbone and a single RGB-D camera to address these challenges, solving for\nocclusions that can degrade the interaction. Experimental results show that\nusing the proposed filter leads to more consistent and noise-free motion\nrepresentation, reducing unexpected robot movements and enabling smoother\ninteraction.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.RO",
    "comment": "Published by and copyright protected by IEEE, 6 pages, 3 figures,\n  33rd IEEE International Conference on Robot & Human Interactive Communication\n  (RO-MAN 2024)",
    "pdf_url": "http://arxiv.org/pdf/2406.01832v1",
    "published_date": "2024-06-03 22:59:53 UTC",
    "updated_date": "2024-06-03 22:59:53 UTC"
  },
  {
    "arxiv_id": "2406.01829v2",
    "title": "FaçAID: A Transformer Model for Neuro-Symbolic Facade Reconstruction",
    "authors": [
      "Aleksander Plocharski",
      "Jan Swidzinski",
      "Joanna Porter-Sobieraj",
      "Przemyslaw Musialski"
    ],
    "abstract": "We introduce a neuro-symbolic transformer-based model that converts flat,\nsegmented facade structures into procedural definitions using a custom-designed\nsplit grammar. To facilitate this, we first develop a semi-complex split\ngrammar tailored for architectural facades and then generate a dataset\ncomprising of facades alongside their corresponding procedural representations.\nThis dataset is used to train our transformer model to convert segmented, flat\nfacades into the procedural language of our grammar. During inference, the\nmodel applies this learned transformation to new facade segmentations,\nproviding a procedural representation that users can adjust to generate varied\nfacade designs. This method not only automates the conversion of static facade\nimages into dynamic, editable procedural formats but also enhances the design\nflexibility, allowing for easy modifications.",
    "categories": [
      "cs.GR",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.NE",
      "I.3.5; I.2.2; I.4.5"
    ],
    "primary_category": "cs.GR",
    "comment": "11 pages, 11 figures, in ACM SIGGRAPH Asia 2024 Conference Papers\n  Proceedings",
    "pdf_url": "http://arxiv.org/pdf/2406.01829v2",
    "published_date": "2024-06-03 22:56:40 UTC",
    "updated_date": "2024-09-13 09:39:53 UTC"
  },
  {
    "arxiv_id": "2406.01825v2",
    "title": "EMOE: Expansive Matching of Experts for Robust Uncertainty Based Rejection",
    "authors": [
      "Yunni Qu",
      "James Wellnitz",
      "Alexander Tropsha",
      "Junier Oliva"
    ],
    "abstract": "Expansive Matching of Experts (EMOE) is a novel method that utilizes\nsupport-expanding, extrapolatory pseudo-labeling to improve prediction and\nuncertainty based rejection on out-of-distribution (OOD) points. We propose an\nexpansive data augmentation technique that generates OOD instances in a latent\nspace, and an empirical trial based approach to filter out augmented expansive\npoints for pseudo-labeling. EMOE utilizes a diverse set of multiple base\nexperts as pseudo-labelers on the augmented data to improve OOD performance\nthrough a shared MLP with multiple heads (one per expert). We demonstrate that\nEMOE achieves superior performance compared to state-of-the-art methods on\ntabular data.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01825v2",
    "published_date": "2024-06-03 22:37:45 UTC",
    "updated_date": "2024-06-05 03:22:38 UTC"
  },
  {
    "arxiv_id": "2406.01823v1",
    "title": "Causal Discovery with Fewer Conditional Independence Tests",
    "authors": [
      "Kirankumar Shiragur",
      "Jiaqi Zhang",
      "Caroline Uhler"
    ],
    "abstract": "Many questions in science center around the fundamental problem of\nunderstanding causal relationships. However, most constraint-based causal\ndiscovery algorithms, including the well-celebrated PC algorithm, often incur\nan exponential number of conditional independence (CI) tests, posing\nlimitations in various applications. Addressing this, our work focuses on\ncharacterizing what can be learned about the underlying causal graph with a\nreduced number of CI tests. We show that it is possible to a learn a coarser\nrepresentation of the hidden causal graph with a polynomial number of tests.\nThis coarser representation, named Causal Consistent Partition Graph (CCPG),\ncomprises of a partition of the vertices and a directed graph defined over its\ncomponents. CCPG satisfies consistency of orientations and additional\nconstraints which favor finer partitions. Furthermore, it reduces to the\nunderlying causal graph when the causal graph is identifiable. As a\nconsequence, our results offer the first efficient algorithm for recovering the\ntrue causal graph with a polynomial number of tests, in special cases where the\ncausal graph is fully identifiable through observational data and potentially\nadditional interventions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ME",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01823v1",
    "published_date": "2024-06-03 22:27:09 UTC",
    "updated_date": "2024-06-03 22:27:09 UTC"
  },
  {
    "arxiv_id": "2406.01820v1",
    "title": "Finding Lottery Tickets in Vision Models via Data-driven Spectral Foresight Pruning",
    "authors": [
      "Leonardo Iurada",
      "Marco Ciccone",
      "Tatiana Tommasi"
    ],
    "abstract": "Recent advances in neural network pruning have shown how it is possible to\nreduce the computational costs and memory demands of deep learning models\nbefore training. We focus on this framework and propose a new pruning at\ninitialization algorithm that leverages the Neural Tangent Kernel (NTK) theory\nto align the training dynamics of the sparse network with that of the dense\none. Specifically, we show how the usually neglected data-dependent component\nin the NTK's spectrum can be taken into account by providing an analytical\nupper bound to the NTK's trace obtained by decomposing neural networks into\nindividual paths. This leads to our Path eXclusion (PX), a foresight pruning\nmethod designed to preserve the parameters that mostly influence the NTK's\ntrace. PX is able to find lottery tickets (i.e. good paths) even at high\nsparsity levels and largely reduces the need for additional training. When\napplied to pre-trained models it extracts subnetworks directly usable for\nseveral downstream tasks, resulting in performance comparable to those of the\ndense counterpart but with substantial cost and computational savings. Code\navailable at: https://github.com/iurada/px-ntk-pruning",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted CVPR 2024 - https://iurada.github.io/PX",
    "pdf_url": "http://arxiv.org/pdf/2406.01820v1",
    "published_date": "2024-06-03 22:19:42 UTC",
    "updated_date": "2024-06-03 22:19:42 UTC"
  },
  {
    "arxiv_id": "2406.01813v1",
    "title": "Diffusion Boosted Trees",
    "authors": [
      "Xizewen Han",
      "Mingyuan Zhou"
    ],
    "abstract": "Combining the merits of both denoising diffusion probabilistic models and\ngradient boosting, the diffusion boosting paradigm is introduced for tackling\nsupervised learning problems. We develop Diffusion Boosted Trees (DBT), which\ncan be viewed as both a new denoising diffusion generative model parameterized\nby decision trees (one single tree for each diffusion timestep), and a new\nboosting algorithm that combines the weak learners into a strong learner of\nconditional distributions without making explicit parametric assumptions on\ntheir density forms. We demonstrate through experiments the advantages of DBT\nover deep neural network-based diffusion models as well as the competence of\nDBT on real-world regression tasks, and present a business application (fraud\ndetection) of DBT for classification on tabular data with the ability of\nlearning to defer.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "stat.AP",
      "stat.ME"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01813v1",
    "published_date": "2024-06-03 22:11:38 UTC",
    "updated_date": "2024-06-03 22:11:38 UTC"
  },
  {
    "arxiv_id": "2406.01812v1",
    "title": "Memory Capacity Analysis of Time-delay Reservoir Computing Based on Silicon Microring Resonator Nonlinearities",
    "authors": [
      "Bernard J. Giron Castro",
      "Christophe Peucheret",
      "Francesco Da Ros"
    ],
    "abstract": "Silicon microring resonators (MRRs) have shown strong potential in acting as\nthe nonlinear nodes of photonic reservoir computing (RC) schemes. By using\nnonlinearities within a silicon MRR, such as the ones caused by free-carrier\ndispersion (FCD) and thermo-optic (TO) effects, it is possible to map the input\ndata of the RC to a higher dimensional space. Furthermore, by adding an\nexternal waveguide between the through and add ports of the MRR, it is possible\nto implement a time-delay RC (TDRC) with enhanced memory. The input from the\nthrough port is fed back into the add port of the ring with the delay applied\nby the external waveguide effectively adding memory. In a TDRC, the nodes are\nmultiplexed in time, and their respective time evolutions are detected at the\ndrop port. The performance of MRR-based TDRC is highly dependent on the amount\nof nonlinearity in the MRR. The nonlinear effects, in turn, are dependent on\nthe physical properties of the MRR as they determine the lifetime of the\neffects. Another factor to take into account is the stability of the MRR\nresponse, as strong time-domain discontinuities at the drop port are known to\nemerge from FCD nonlinearities due to self-pulsing (high nonlinear behaviour).\nHowever, quantifying the right amount of nonlinearity that RC needs for a\ncertain task in order to achieve optimum performance is challenging. Therefore,\nfurther analysis is required to fully understand the nonlinear dynamics of this\nTDRC setup. Here, we quantify the nonlinear and linear memory capacity of the\npreviously described microring-based TDRC scheme, as a function of the time\nconstants of the generated carriers and the thermal of the TO effects. We\nanalyze the properties of the TDRC dynamics that generate the parameter space,\nin terms of input signal power and frequency detuning range, over which\nconventional RC tasks can be satisfactorily performed by the TDRC scheme.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "physics.optics"
    ],
    "primary_category": "cs.NE",
    "comment": "12 pages, 12 figures. Proceedings SPIE Europe 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.01812v1",
    "published_date": "2024-06-03 22:10:25 UTC",
    "updated_date": "2024-06-03 22:10:25 UTC"
  },
  {
    "arxiv_id": "2406.01806v1",
    "title": "Contextualized Sequence Likelihood: Enhanced Confidence Scores for Natural Language Generation",
    "authors": [
      "Zhen Lin",
      "Shubhendu Trivedi",
      "Jimeng Sun"
    ],
    "abstract": "The advent of large language models (LLMs) has dramatically advanced the\nstate-of-the-art in numerous natural language generation tasks. For LLMs to be\napplied reliably, it is essential to have an accurate measure of their\nconfidence. Currently, the most commonly used confidence score function is the\nlikelihood of the generated sequence, which, however, conflates semantic and\nsyntactic components. For instance, in question-answering (QA) tasks, an\nawkward phrasing of the correct answer might result in a lower probability\nprediction. Additionally, different tokens should be weighted differently\ndepending on the context. In this work, we propose enhancing the predicted\nsequence probability by assigning different weights to various tokens using\nattention values elicited from the base LLM. By employing a validation set, we\ncan identify the relevant attention heads, thereby significantly improving the\nreliability of the vanilla sequence probability confidence measure. We refer to\nthis new score as the Contextualized Sequence Likelihood (CSL). CSL is easy to\nimplement, fast to compute, and offers considerable potential for further\nimprovement with task-specific prompts. Across several QA datasets and a\ndiverse array of LLMs, CSL has demonstrated significantly higher reliability\nthan state-of-the-art baselines in predicting generation quality, as measured\nby the AUROC or AUARC.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01806v1",
    "published_date": "2024-06-03 21:55:07 UTC",
    "updated_date": "2024-06-03 21:55:07 UTC"
  },
  {
    "arxiv_id": "2406.01805v2",
    "title": "TabMDA: Tabular Manifold Data Augmentation for Any Classifier using Transformers with In-context Subsetting",
    "authors": [
      "Andrei Margeloiu",
      "Adrián Bazaga",
      "Nikola Simidjievski",
      "Pietro Liò",
      "Mateja Jamnik"
    ],
    "abstract": "Tabular data is prevalent in many critical domains, yet it is often\nchallenging to acquire in large quantities. This scarcity usually results in\npoor performance of machine learning models on such data. Data augmentation, a\ncommon strategy for performance improvement in vision and language tasks,\ntypically underperforms for tabular data due to the lack of explicit symmetries\nin the input space. To overcome this challenge, we introduce TabMDA, a novel\nmethod for manifold data augmentation on tabular data. This method utilises a\npre-trained in-context model, such as TabPFN, to map the data into an embedding\nspace. TabMDA performs label-invariant transformations by encoding the data\nmultiple times with varied contexts. This process explores the learned\nembedding space of the underlying in-context models, thereby enlarging the\ntraining dataset. TabMDA is a training-free method, making it applicable to any\nclassifier. We evaluate TabMDA on five standard classifiers and observe\nsignificant performance improvements across various tabular datasets. Our\nresults demonstrate that TabMDA provides an effective way to leverage\ninformation from pre-trained in-context models to enhance the performance of\ndownstream classifiers. Code is available at\nhttps://github.com/AdrianBZG/TabMDA.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Presented at 1st ICML Workshop on In-Context Learning (ICL @ ICML\n  2024)",
    "pdf_url": "http://arxiv.org/pdf/2406.01805v2",
    "published_date": "2024-06-03 21:51:13 UTC",
    "updated_date": "2024-07-29 15:08:17 UTC"
  },
  {
    "arxiv_id": "2406.02625v1",
    "title": "Progressive Inference: Explaining Decoder-Only Sequence Classification Models Using Intermediate Predictions",
    "authors": [
      "Sanjay Kariyappa",
      "Freddy Lécué",
      "Saumitra Mishra",
      "Christopher Pond",
      "Daniele Magazzeni",
      "Manuela Veloso"
    ],
    "abstract": "This paper proposes Progressive Inference - a framework to compute input\nattributions to explain the predictions of decoder-only sequence classification\nmodels. Our work is based on the insight that the classification head of a\ndecoder-only Transformer model can be used to make intermediate predictions by\nevaluating them at different points in the input sequence. Due to the causal\nattention mechanism, these intermediate predictions only depend on the tokens\nseen before the inference point, allowing us to obtain the model's prediction\non a masked input sub-sequence, with negligible computational overheads. We\ndevelop two methods to provide sub-sequence level attributions using this\ninsight. First, we propose Single Pass-Progressive Inference (SP-PI), which\ncomputes attributions by taking the difference between consecutive intermediate\npredictions. Second, we exploit a connection with Kernel SHAP to develop Multi\nPass-Progressive Inference (MP-PI). MP-PI uses intermediate predictions from\nmultiple masked versions of the input to compute higher quality attributions.\nOur studies on a diverse set of models trained on text classification tasks\nshow that SP-PI and MP-PI provide significantly better attributions compared to\nprior work.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02625v1",
    "published_date": "2024-06-03 21:48:57 UTC",
    "updated_date": "2024-06-03 21:48:57 UTC"
  },
  {
    "arxiv_id": "2406.01793v2",
    "title": "Towards the Transferability of Rewards Recovered via Regularized Inverse Reinforcement Learning",
    "authors": [
      "Andreas Schlaginhaufen",
      "Maryam Kamgarpour"
    ],
    "abstract": "Inverse reinforcement learning (IRL) aims to infer a reward from expert\ndemonstrations, motivated by the idea that the reward, rather than the policy,\nis the most succinct and transferable description of a task [Ng et al., 2000].\nHowever, the reward corresponding to an optimal policy is not unique, making it\nunclear if an IRL-learned reward is transferable to new transition laws in the\nsense that its optimal policy aligns with the optimal policy corresponding to\nthe expert's true reward. Past work has addressed this problem only under the\nassumption of full access to the expert's policy, guaranteeing transferability\nwhen learning from two experts with the same reward but different transition\nlaws that satisfy a specific rank condition [Rolland et al., 2022]. In this\nwork, we show that the conditions developed under full access to the expert's\npolicy cannot guarantee transferability in the more practical scenario where we\nhave access only to demonstrations of the expert. Instead of a binary rank\ncondition, we propose principal angles as a more refined measure of similarity\nand dissimilarity between transition laws. Based on this, we then establish two\nkey results: 1) a sufficient condition for transferability to any transition\nlaws when learning from at least two experts with sufficiently different\ntransition laws, and 2) a sufficient condition for transferability to local\nchanges in the transition law when learning from a single expert. Furthermore,\nwe also provide a probably approximately correct (PAC) algorithm and an\nend-to-end analysis for learning transferable rewards from demonstrations of\nmultiple experts.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "The Thirty-Eighth Annual Conference on Neural Information Processing\n  Systems (NeurIPS 2024)",
    "pdf_url": "http://arxiv.org/pdf/2406.01793v2",
    "published_date": "2024-06-03 21:18:08 UTC",
    "updated_date": "2025-02-03 22:27:13 UTC"
  },
  {
    "arxiv_id": "2406.01789v1",
    "title": "AI-based Classification of Customer Support Tickets: State of the Art and Implementation with AutoML",
    "authors": [
      "Mario Truss",
      "Stephan Boehm"
    ],
    "abstract": "Automation of support ticket classification is crucial to improve customer\nsupport performance and shortening resolution time for customer inquiries. This\nresearch aims to test the applicability of automated machine learning (AutoML)\nas a technology to train a machine learning model (ML model) that can classify\nsupport tickets. The model evaluation conducted in this research shows that\nAutoML can be used to train ML models with good classification performance.\nMoreover, this paper fills a research gap by providing new insights into\ndeveloping AI solutions without a dedicated professional by utilizing AutoML,\nwhich makes this technology more accessible for companies without specialized\nAI departments and staff.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "I.2; I.2.7; K.6"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01789v1",
    "published_date": "2024-06-03 21:13:02 UTC",
    "updated_date": "2024-06-03 21:13:02 UTC"
  },
  {
    "arxiv_id": "2406.01786v1",
    "title": "Recent Advances in Data-Driven Business Process Management",
    "authors": [
      "Lars Ackermann",
      "Martin Käppel",
      "Laura Marcus",
      "Linda Moder",
      "Sebastian Dunzer",
      "Markus Hornsteiner",
      "Annina Liessmann",
      "Yorck Zisgen",
      "Philip Empl",
      "Lukas-Valentin Herm",
      "Nicolas Neis",
      "Julian Neuberger",
      "Leo Poss",
      "Myriam Schaschek",
      "Sven Weinzierl",
      "Niklas Wördehoff",
      "Stefan Jablonski",
      "Agnes Koschmider",
      "Wolfgang Kratsch",
      "Martin Matzner",
      "Stefanie Rinderle-Ma",
      "Maximilian Röglinger",
      "Stefan Schönig",
      "Axel Winkelmann"
    ],
    "abstract": "The rapid development of cutting-edge technologies, the increasing volume of\ndata and also the availability and processability of new types of data sources\nhas led to a paradigm shift in data-based management and decision-making. Since\nbusiness processes are at the core of organizational work, these developments\nheavily impact BPM as a crucial success factor for organizations. In view of\nthis emerging potential, data-driven business process management has become a\nrelevant and vibrant research area. Given the complexity and\ninterdisciplinarity of the research field, this position paper therefore\npresents research insights regarding data-driven BPM.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "68U35 68T07 68T07, 68U35, 68T01",
      "H.4.1; I.2.1; I.2.6; I.2.7; H.2.8; K.6.1"
    ],
    "primary_category": "cs.DB",
    "comment": "position paper, 34 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.01786v1",
    "published_date": "2024-06-03 21:05:59 UTC",
    "updated_date": "2024-06-03 21:05:59 UTC"
  },
  {
    "arxiv_id": "2406.01782v1",
    "title": "Multi-agent assignment via state augmented reinforcement learning",
    "authors": [
      "Leopoldo Agorio",
      "Sean Van Alen",
      "Miguel Calvo-Fullana",
      "Santiago Paternain",
      "Juan Andres Bazerque"
    ],
    "abstract": "We address the conflicting requirements of a multi-agent assignment problem\nthrough constrained reinforcement learning, emphasizing the inadequacy of\nstandard regularization techniques for this purpose. Instead, we recur to a\nstate augmentation approach in which the oscillation of dual variables is\nexploited by agents to alternate between tasks. In addition, we coordinate the\nactions of the multiple agents acting on their local states through these\nmultipliers, which are gossiped through a communication network, eliminating\nthe need to access other agent states. By these means, we propose a distributed\nmulti-agent assignment protocol with theoretical feasibility guarantees that we\ncorroborate in a monitoring numerical experiment.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.LG",
      "cs.MA",
      "cs.SY",
      "93E35"
    ],
    "primary_category": "eess.SY",
    "comment": "12 pages, 3 figures, 6th Annual Conference on Learning for Dynamics\n  and Control",
    "pdf_url": "http://arxiv.org/pdf/2406.01782v1",
    "published_date": "2024-06-03 20:56:12 UTC",
    "updated_date": "2024-06-03 20:56:12 UTC"
  },
  {
    "arxiv_id": "2407.17590v1",
    "title": "Is computational creativity flourishing on the dead internet?",
    "authors": [
      "Terence Broad"
    ],
    "abstract": "The dead internet theory is a conspiracy theory that states that all\ninteractions and posts on social media are no longer being made by real people,\nbut rather by autonomous bots. While the theory is obviously not true, an\nincreasing amount of posts on social media have been made by bots optimised to\ngain followers and drive engagement on social media platforms. This paper looks\nat the recent phenomenon of these bots, analysing their behaviour through the\nlens of computational creativity to investigate the question: is computational\ncreativity flourishing on the dead internet?",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "6 pages",
    "pdf_url": "http://arxiv.org/pdf/2407.17590v1",
    "published_date": "2024-06-03 20:15:06 UTC",
    "updated_date": "2024-06-03 20:15:06 UTC"
  },
  {
    "arxiv_id": "2406.01762v1",
    "title": "Non-Asymptotic Analysis for Single-Loop (Natural) Actor-Critic with Compatible Function Approximation",
    "authors": [
      "Yudan Wang",
      "Yue Wang",
      "Yi Zhou",
      "Shaofeng Zou"
    ],
    "abstract": "Actor-critic (AC) is a powerful method for learning an optimal policy in\nreinforcement learning, where the critic uses algorithms, e.g., temporal\ndifference (TD) learning with function approximation, to evaluate the current\npolicy and the actor updates the policy along an approximate gradient direction\nusing information from the critic. This paper provides the \\textit{tightest}\nnon-asymptotic convergence bounds for both the AC and natural AC (NAC)\nalgorithms. Specifically, existing studies show that AC converges to an\n$\\epsilon+\\varepsilon_{\\text{critic}}$ neighborhood of stationary points with\nthe best known sample complexity of $\\mathcal{O}(\\epsilon^{-2})$ (up to a log\nfactor), and NAC converges to an\n$\\epsilon+\\varepsilon_{\\text{critic}}+\\sqrt{\\varepsilon_{\\text{actor}}}$\nneighborhood of the global optimum with the best known sample complexity of\n$\\mathcal{O}(\\epsilon^{-3})$, where $\\varepsilon_{\\text{critic}}$ is the\napproximation error of the critic and $\\varepsilon_{\\text{actor}}$ is the\napproximation error induced by the insufficient expressive power of the\nparameterized policy class. This paper analyzes the convergence of both AC and\nNAC algorithms with compatible function approximation. Our analysis eliminates\nthe term $\\varepsilon_{\\text{critic}}$ from the error bounds while still\nachieving the best known sample complexities. Moreover, we focus on the\nchallenging single-loop setting with a single Markovian sample trajectory. Our\nmajor technical novelty lies in analyzing the stochastic bias due to\npolicy-dependent and time-varying compatible function approximation in the\ncritic, and handling the non-ergodicity of the MDP due to the single Markovian\nsample trajectory. Numerical results are also provided in the appendix.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.01762v1",
    "published_date": "2024-06-03 20:05:04 UTC",
    "updated_date": "2024-06-03 20:05:04 UTC"
  },
  {
    "arxiv_id": "2406.01759v2",
    "title": "From Latent to Lucid: Transforming Knowledge Graph Embeddings into Interpretable Structures with KGEPrisma",
    "authors": [
      "Christoph Wehner",
      "Chrysa Iliopoulou",
      "Ute Schmid",
      "Tarek R. Besold"
    ],
    "abstract": "In this paper, we introduce a post-hoc and local explainable AI method\ntailored for Knowledge Graph Embedding (KGE) models. These models are essential\nto Knowledge Graph Completion yet criticized for their opaque, black-box\nnature. Despite their significant success in capturing the semantics of\nknowledge graphs through high-dimensional latent representations, their\ninherent complexity poses substantial challenges to explainability. While\nexisting methods like Kelpie use resource-intensive perturbation to explain KGE\nmodels, our approach directly decodes the latent representations encoded by KGE\nmodels, leveraging the smoothness of the embeddings, which follows the\nprinciple that similar embeddings reflect similar behaviours within the\nKnowledge Graph, meaning that nodes are similarly embedded because their graph\nneighbourhood looks similar. This principle is commonly referred to as\nsmoothness. By identifying symbolic structures, in the form of triples, within\nthe subgraph neighborhoods of similarly embedded entities, our method\nidentifies the statistical regularities on which the models rely and translates\nthese insights into human-understandable symbolic rules and facts. This bridges\nthe gap between the abstract representations of KGE models and their predictive\noutputs, offering clear, interpretable insights. Key contributions include a\nnovel post-hoc and local explainable AI method for KGE models that provides\nimmediate, faithful explanations without retraining, facilitating real-time\napplication on large-scale knowledge graphs. The method's flexibility enables\nthe generation of rule-based, instance-based, and analogy-based explanations,\nmeeting diverse user needs. Extensive evaluations show the effectiveness of our\napproach in delivering faithful and well-localized explanations, enhancing the\ntransparency and trustworthiness of KGE models.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01759v2",
    "published_date": "2024-06-03 19:54:11 UTC",
    "updated_date": "2025-05-07 12:15:25 UTC"
  },
  {
    "arxiv_id": "2406.01757v1",
    "title": "Position: Cracking the Code of Cascading Disparity Towards Marginalized Communities",
    "authors": [
      "Golnoosh Farnadi",
      "Mohammad Havaei",
      "Negar Rostamzadeh"
    ],
    "abstract": "The rise of foundation models holds immense promise for advancing AI, but\nthis progress may amplify existing risks and inequalities, leaving marginalized\ncommunities behind. In this position paper, we discuss that disparities towards\nmarginalized communities - performance, representation, privacy, robustness,\ninterpretability and safety - are not isolated concerns but rather\ninterconnected elements of a cascading disparity phenomenon. We contrast\nfoundation models with traditional models and highlight the potential for\nexacerbated disparity against marginalized communities. Moreover, we emphasize\nthe unique threat of cascading impacts in foundation models, where\ninterconnected disparities can trigger long-lasting negative consequences,\nspecifically to the people on the margin. We define marginalized communities\nwithin the machine learning context and explore the multifaceted nature of\ndisparities. We analyze the sources of these disparities, tracing them from\ndata creation, training and deployment procedures to highlight the complex\ntechnical and socio-technical landscape. To mitigate the pressing crisis, we\nconclude with a set of calls to action to mitigate disparity at its source.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2406.01757v1",
    "published_date": "2024-06-03 19:52:41 UTC",
    "updated_date": "2024-06-03 19:52:41 UTC"
  },
  {
    "arxiv_id": "2406.01755v1",
    "title": "Sparser, Better, Deeper, Stronger: Improving Sparse Training with Exact Orthogonal Initialization",
    "authors": [
      "Aleksandra Irena Nowak",
      "Łukasz Gniecki",
      "Filip Szatkowski",
      "Jacek Tabor"
    ],
    "abstract": "Static sparse training aims to train sparse models from scratch, achieving\nremarkable results in recent years. A key design choice is given by the sparse\ninitialization, which determines the trainable sub-network through a binary\nmask. Existing methods mainly select such mask based on a predefined dense\ninitialization. Such an approach may not efficiently leverage the mask's\npotential impact on the optimization. An alternative direction, inspired by\nresearch into dynamical isometry, is to introduce orthogonality in the sparse\nsubnetwork, which helps in stabilizing the gradient signal. In this work, we\npropose Exact Orthogonal Initialization (EOI), a novel sparse orthogonal\ninitialization scheme based on composing random Givens rotations. Contrary to\nother existing approaches, our method provides exact (not approximated)\northogonality and enables the creation of layers with arbitrary densities. We\ndemonstrate the superior effectiveness and efficiency of EOI through\nexperiments, consistently outperforming common sparse initialization\ntechniques. Our method enables training highly sparse 1000-layer MLP and CNN\nnetworks without residual connections or normalization techniques, emphasizing\nthe crucial role of weight initialization in static sparse training alongside\nsparse mask selection. The code is available at\nhttps://github.com/woocash2/sparser-better-deeper-stronger",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.01755v1",
    "published_date": "2024-06-03 19:44:47 UTC",
    "updated_date": "2024-06-03 19:44:47 UTC"
  },
  {
    "arxiv_id": "2406.06575v1",
    "title": "Ask-EDA: A Design Assistant Empowered by LLM, Hybrid RAG and Abbreviation De-hallucination",
    "authors": [
      "Luyao Shi",
      "Michael Kazda",
      "Bradley Sears",
      "Nick Shropshire",
      "Ruchir Puri"
    ],
    "abstract": "Electronic design engineers are challenged to find relevant information\nefficiently for a myriad of tasks within design construction, verification and\ntechnology development. Large language models (LLM) have the potential to help\nimprove productivity by serving as conversational agents that effectively\nfunction as subject-matter experts. In this paper we demonstrate Ask-EDA, a\nchat agent designed to serve as a 24x7 expert available to provide guidance to\ndesign engineers. Ask-EDA leverages LLM, hybrid retrieval augmented generation\n(RAG) and abbreviation de-hallucination (ADH) techniques to deliver more\nrelevant and accurate responses. We curated three evaluation datasets, namely\nq2a-100, cmds-100 and abbr-100. Each dataset is tailored to assess a distinct\naspect: general design question answering, design command handling and\nabbreviation resolution. We demonstrated that hybrid RAG offers over a 40%\nimprovement in Recall on the q2a-100 dataset and over a 60% improvement on the\ncmds-100 dataset compared to not using RAG, while ADH yields over a 70%\nenhancement in Recall on the abbr-100 dataset. The evaluation results show that\nAsk-EDA can effectively respond to design-related inquiries.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted paper at The First IEEE International Workshop on LLM-Aided\n  Design, 2024 (LAD 24)",
    "pdf_url": "http://arxiv.org/pdf/2406.06575v1",
    "published_date": "2024-06-03 19:40:28 UTC",
    "updated_date": "2024-06-03 19:40:28 UTC"
  },
  {
    "arxiv_id": "2406.02622v1",
    "title": "Safeguarding Large Language Models: A Survey",
    "authors": [
      "Yi Dong",
      "Ronghui Mu",
      "Yanghao Zhang",
      "Siqi Sun",
      "Tianle Zhang",
      "Changshun Wu",
      "Gaojie Jin",
      "Yi Qi",
      "Jinwei Hu",
      "Jie Meng",
      "Saddek Bensalem",
      "Xiaowei Huang"
    ],
    "abstract": "In the burgeoning field of Large Language Models (LLMs), developing a robust\nsafety mechanism, colloquially known as \"safeguards\" or \"guardrails\", has\nbecome imperative to ensure the ethical use of LLMs within prescribed\nboundaries. This article provides a systematic literature review on the current\nstatus of this critical mechanism. It discusses its major challenges and how it\ncan be enhanced into a comprehensive mechanism dealing with ethical issues in\nvarious contexts. First, the paper elucidates the current landscape of\nsafeguarding mechanisms that major LLM service providers and the open-source\ncommunity employ. This is followed by the techniques to evaluate, analyze, and\nenhance some (un)desirable properties that a guardrail might want to enforce,\nsuch as hallucinations, fairness, privacy, and so on. Based on them, we review\ntechniques to circumvent these controls (i.e., attacks), to defend the attacks,\nand to reinforce the guardrails. While the techniques mentioned above represent\nthe current status and the active research trends, we also discuss several\nchallenges that cannot be easily dealt with by the methods and present our\nvision on how to implement a comprehensive guardrail through the full\nconsideration of multi-disciplinary approach, neural-symbolic method, and\nsystems development lifecycle.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "under review. arXiv admin note: text overlap with arXiv:2402.01822",
    "pdf_url": "http://arxiv.org/pdf/2406.02622v1",
    "published_date": "2024-06-03 19:27:46 UTC",
    "updated_date": "2024-06-03 19:27:46 UTC"
  },
  {
    "arxiv_id": "2406.06574v1",
    "title": "Towards Transparency: Exploring LLM Trainings Datasets through Visual Topic Modeling and Semantic Frame",
    "authors": [
      "Charles de Dampierre",
      "Andrei Mogoutov",
      "Nicolas Baumard"
    ],
    "abstract": "LLMs are now responsible for making many decisions on behalf of humans: from\nanswering questions to classifying things, they have become an important part\nof everyday life. While computation and model architecture have been rapidly\nexpanding in recent years, the efforts towards curating training datasets are\nstill in their beginnings. This underappreciation of training datasets has led\nLLMs to create biased and low-quality content. In order to solve that issue, we\npresent Bunka, a software that leverages AI and Cognitive Science to improve\nthe refinement of textual datasets. We show how Topic Modeling coupled with\n2-dimensional Cartography can increase the transparency of datasets. We then\nshow how the same Topic Modeling techniques can be applied to Preferences\ndatasets to accelerate the fine-tuning process and increase the capacities of\nthe model on different benchmarks. Lastly, we show how using Frame Analysis can\ngive insights into existing biases in the training corpus. Overall, we argue\nthat we need better tools to explore and increase the quality and transparency\nof LLMs training datasets.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.06574v1",
    "published_date": "2024-06-03 18:44:13 UTC",
    "updated_date": "2024-06-03 18:44:13 UTC"
  },
  {
    "arxiv_id": "2406.01698v3",
    "title": "Demystifying AI Platform Design for Distributed Inference of Next-Generation LLM models",
    "authors": [
      "Abhimanyu Bambhaniya",
      "Ritik Raj",
      "Geonhwa Jeong",
      "Souvik Kundu",
      "Sudarshan Srinivasan",
      "Suvinay Subramanian",
      "Midhilesh Elavazhagan",
      "Madhu Kumar",
      "Tushar Krishna"
    ],
    "abstract": "Large language models (LLMs) have shown remarkable performance across a wide\nrange of applications, often outperforming human experts. However, deploying\nthese gigantic models efficiently for diverse inference use cases requires\ncarefully designed hardware platforms with ample computing, memory, and network\nresources. With constant innovation in LLM serving optimizations and model\narchitecture evolving at breakneck speed, the hardware requirements to meet\nService Level Objectives (SLOs) remain an open research question.\n  To answer the question, we present an analytical tool, GenZ, to efficiently\nnavigate the relationship between diverse LLM model architectures(Dense, GQA,\nMoE, Mamba), LLM serving optimizations(Chunking, Speculative decoding,\nquanitization), and AI platform design parameters. Our tool estimates LLM\ninference performance metrics for the given scenario. We have validated against\nreal hardware platforms running various different LLM models, achieving a max\ngeomean error of 5.82.We use GenZ to identify compute, memory capacity, memory\nbandwidth, network latency, and network bandwidth requirements across diverse\nLLM inference use cases. We also study diverse architectural choices in use\ntoday (inspired by LLM serving platforms from several vendors) to help inform\ncomputer architects designing next-generation AI hardware accelerators and\nplatforms. The trends and insights derived from GenZ can guide AI engineers\ndeploying LLMs as well as computer architects designing next-generation\nhardware accelerators and platforms. Ultimately, this work sheds light on the\nplatform design considerations for unlocking the full potential of large\nlanguage models across a spectrum of applications. The source code is available\nat https://github.com/abhibambhaniya/GenZ-LLM-Analyzer . Users can also be\ntried it on at https://genz-llm-analyzer.streamlit.app/ without any setup on\nyour web browser.",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.DC",
      "cs.LG"
    ],
    "primary_category": "cs.AR",
    "comment": "19 Pages, https://github.com/abhibambhaniya/GenZ-LLM-Analyzer,\n  https://genz-llm-analyzer.streamlit.app/",
    "pdf_url": "http://arxiv.org/pdf/2406.01698v3",
    "published_date": "2024-06-03 18:00:50 UTC",
    "updated_date": "2025-05-15 02:46:53 UTC"
  },
  {
    "arxiv_id": "2406.01662v2",
    "title": "Few-Shot Classification of Interactive Activities of Daily Living (InteractADL)",
    "authors": [
      "Zane Durante",
      "Robathan Harries",
      "Edward Vendrow",
      "Zelun Luo",
      "Yuta Kyuragi",
      "Kazuki Kozuka",
      "Li Fei-Fei",
      "Ehsan Adeli"
    ],
    "abstract": "Understanding Activities of Daily Living (ADLs) is a crucial step for\ndifferent applications including assistive robots, smart homes, and healthcare.\nHowever, to date, few benchmarks and methods have focused on complex ADLs,\nespecially those involving multi-person interactions in home environments. In\nthis paper, we propose a new dataset and benchmark, InteractADL, for\nunderstanding complex ADLs that involve interaction between humans (and\nobjects). Furthermore, complex ADLs occurring in home environments comprise a\nchallenging long-tailed distribution due to the rarity of multi-person\ninteractions, and pose fine-grained visual recognition tasks due to the\npresence of semantically and visually similar classes. To address these issues,\nwe propose a novel method for fine-grained few-shot video classification called\nName Tuning that enables greater semantic separability by learning optimal\nclass name vectors. We show that Name Tuning can be combined with existing\nprompt tuning strategies to learn the entire input text (rather than only\nlearning the prompt or class names) and demonstrate improved performance for\nfew-shot classification on InteractADL and 4 other fine-grained visual\nclassification benchmarks. For transparency and reproducibility, we release our\ncode at https://github.com/zanedurante/vlm_benchmark.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01662v2",
    "published_date": "2024-06-03 17:59:55 UTC",
    "updated_date": "2024-10-16 23:00:23 UTC"
  },
  {
    "arxiv_id": "2406.01592v2",
    "title": "Text-guided Controllable Mesh Refinement for Interactive 3D Modeling",
    "authors": [
      "Yun-Chun Chen",
      "Selena Ling",
      "Zhiqin Chen",
      "Vladimir G. Kim",
      "Matheus Gadelha",
      "Alec Jacobson"
    ],
    "abstract": "We propose a novel technique for adding geometric details to an input coarse\n3D mesh guided by a text prompt. Our method is composed of three stages. First,\nwe generate a single-view RGB image conditioned on the input coarse geometry\nand the input text prompt. This single-view image generation step allows the\nuser to pre-visualize the result and offers stronger conditioning for\nsubsequent multi-view generation. Second, we use our novel multi-view normal\ngeneration architecture to jointly generate six different views of the normal\nimages. The joint view generation reduces inconsistencies and leads to sharper\ndetails. Third, we optimize our mesh with respect to all views and generate a\nfine, detailed geometry as output. The resulting method produces an output\nwithin seconds and offers explicit user control over the coarse structure,\npose, and desired details of the resulting 3D mesh.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.GR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "SIGGRAPH Asia 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.01592v2",
    "published_date": "2024-06-03 17:59:43 UTC",
    "updated_date": "2024-09-11 00:42:37 UTC"
  },
  {
    "arxiv_id": "2406.01588v1",
    "title": "nn2poly: An R Package for Converting Neural Networks into Interpretable Polynomials",
    "authors": [
      "Pablo Morala",
      "Jenny Alexandra Cifuentes",
      "Rosa E. Lillo",
      "Iñaki Ucar"
    ],
    "abstract": "The nn2poly package provides the implementation in R of the NN2Poly method to\nexplain and interpret feed-forward neural networks by means of polynomial\nrepresentations that predict in an equivalent manner as the original\nnetwork.Through the obtained polynomial coefficients, the effect and importance\nof each variable and their interactions on the output can be represented. This\ncapabiltiy of capturing interactions is a key aspect usually missing from most\nExplainable Artificial Intelligence (XAI) methods, specially if they rely on\nexpensive computations that can be amplified when used on large neural\nnetworks. The package provides integration with the main deep learning\nframework packages in R (tensorflow and torch), allowing an user-friendly\napplication of the NN2Poly algorithm. Furthermore, nn2poly provides\nimplementation of the required weight constraints to be used during the network\ntraining in those same frameworks. Other neural networks packages can also be\nused by including their weights in list format. Polynomials obtained with\nnn2poly can also be used to predict with new data or be visualized through its\nown plot method. Simulations are provided exemplifying the usage of the package\nalongside with a comparison with other approaches available in R to interpret\nneural networks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01588v1",
    "published_date": "2024-06-03 17:59:30 UTC",
    "updated_date": "2024-06-03 17:59:30 UTC"
  },
  {
    "arxiv_id": "2406.01586v2",
    "title": "ManiCM: Real-time 3D Diffusion Policy via Consistency Model for Robotic Manipulation",
    "authors": [
      "Guanxing Lu",
      "Zifeng Gao",
      "Tianxing Chen",
      "Wenxun Dai",
      "Ziwei Wang",
      "Wenbo Ding",
      "Yansong Tang"
    ],
    "abstract": "Diffusion models have been verified to be effective in generating complex\ndistributions from natural images to motion trajectories. Recent\ndiffusion-based methods show impressive performance in 3D robotic manipulation\ntasks, whereas they suffer from severe runtime inefficiency due to multiple\ndenoising steps, especially with high-dimensional observations. To this end, we\npropose a real-time robotic manipulation model named ManiCM that imposes the\nconsistency constraint to the diffusion process, so that the model can generate\nrobot actions in only one-step inference. Specifically, we formulate a\nconsistent diffusion process in the robot action space conditioned on the point\ncloud input, where the original action is required to be directly denoised from\nany point along the ODE trajectory. To model this process, we design a\nconsistency distillation technique to predict the action sample directly\ninstead of predicting the noise within the vision community for fast\nconvergence in the low-dimensional action manifold. We evaluate ManiCM on 31\nrobotic manipulation tasks from Adroit and Metaworld, and the results\ndemonstrate that our approach accelerates the state-of-the-art method by 10\ntimes in average inference speed while maintaining competitive average success\nrate.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "https://manicm-fast.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2406.01586v2",
    "published_date": "2024-06-03 17:59:23 UTC",
    "updated_date": "2025-03-26 09:00:08 UTC"
  },
  {
    "arxiv_id": "2406.01661v2",
    "title": "A Diffusion Model Framework for Unsupervised Neural Combinatorial Optimization",
    "authors": [
      "Sebastian Sanokowski",
      "Sepp Hochreiter",
      "Sebastian Lehner"
    ],
    "abstract": "Learning to sample from intractable distributions over discrete sets without\nrelying on corresponding training data is a central problem in a wide range of\nfields, including Combinatorial Optimization. Currently, popular deep\nlearning-based approaches rely primarily on generative models that yield exact\nsample likelihoods. This work introduces a method that lifts this restriction\nand opens the possibility to employ highly expressive latent variable models\nlike diffusion models. Our approach is conceptually based on a loss that upper\nbounds the reverse Kullback-Leibler divergence and evades the requirement of\nexact sample likelihoods. We experimentally validate our approach in data-free\nCombinatorial Optimization and demonstrate that our method achieves a new\nstate-of-the-art on a wide range of benchmark problems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DM",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.01661v2",
    "published_date": "2024-06-03 17:55:02 UTC",
    "updated_date": "2024-08-08 12:17:56 UTC"
  },
  {
    "arxiv_id": "2406.01575v2",
    "title": "Contextual Bilevel Reinforcement Learning for Incentive Alignment",
    "authors": [
      "Vinzenz Thoma",
      "Barna Pasztor",
      "Andreas Krause",
      "Giorgia Ramponi",
      "Yifan Hu"
    ],
    "abstract": "The optimal policy in various real-world strategic decision-making problems\ndepends both on the environmental configuration and exogenous events. For these\nsettings, we introduce Contextual Bilevel Reinforcement Learning (CB-RL), a\nstochastic bilevel decision-making model, where the lower level consists of\nsolving a contextual Markov Decision Process (CMDP). CB-RL can be viewed as a\nStackelberg Game where the leader and a random context beyond the leader's\ncontrol together decide the setup of many MDPs that potentially multiple\nfollowers best respond to. This framework extends beyond traditional bilevel\noptimization and finds relevance in diverse fields such as RLHF, tax design,\nreward shaping, contract theory and mechanism design. We propose a stochastic\nHyper Policy Gradient Descent (HPGD) algorithm to solve CB-RL, and demonstrate\nits convergence. Notably, HPGD uses stochastic hypergradient estimates, based\non observations of the followers' trajectories. Therefore, it allows followers\nto use any training procedure and the leader to be agnostic of the specific\nalgorithm, which aligns with various real-world scenarios. We further consider\nthe setting when the leader can influence the training of followers and propose\nan accelerated algorithm. We empirically demonstrate the performance of our\nalgorithm for reward shaping and tax design.",
    "categories": [
      "math.OC",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "math.OC",
    "comment": "60 pages, 21 Figures",
    "pdf_url": "http://arxiv.org/pdf/2406.01575v2",
    "published_date": "2024-06-03 17:54:39 UTC",
    "updated_date": "2024-12-08 17:04:50 UTC"
  },
  {
    "arxiv_id": "2406.01660v4",
    "title": "Self-Improving Robust Preference Optimization",
    "authors": [
      "Eugene Choi",
      "Arash Ahmadian",
      "Matthieu Geist",
      "Oilvier Pietquin",
      "Mohammad Gheshlaghi Azar"
    ],
    "abstract": "Online and offline RLHF methods, such as PPO and DPO, have been highly\nsuccessful in aligning AI with human preferences. Despite their success,\nhowever, these methods suffer from fundamental limitations: (a) Models trained\nwith RLHF can learn from mistakes or negative examples through RL mechanism or\ncontrastive loss during training. However, at inference time, they lack an\ninnate self-improvement mechanism for error corrections. (b) The optimal\nsolution of existing methods is highly task-dependent, making it difficult for\nthem to generalize to new tasks. To address these challenges, we propose\nSelf-Improving Robust Preference Optimization (SRPO), a practical and\nmathematically principled offline RLHF framework. The key idea behind SRPO is\nto cast the problem of learning from human preferences as a self-improvement\nprocess, mathematically formulated as a min-max objective that jointly\noptimizes a self-improvement policy and a generative policy in an adversarial\nfashion. Crucially, the solution for this optimization problem is independent\nof the training task, which makes it robust to its changes. We then show that\nthis objective can be reformulated as a non-adversarial offline loss, which can\nbe efficiently optimized using standard supervised learning techniques at\nscale. To demonstrate SRPO's effectiveness, we evaluate it using AI Win-Rate\n(WR) against human (GOLD) completions. When tested on the XSum dataset, SRPO\noutperforms DPO by a margin of 15% after 5 self revisions, achieving an\nimpressive 90% WR. Moreover, on the challenging Arena-Hard prompts, SRPO\noutperforms both DPO and IPO (by 4% without revision and 6% after a single\nrevision), reaching a 56% WR against against Llama-3.1-8B-Instruct.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01660v4",
    "published_date": "2024-06-03 17:53:25 UTC",
    "updated_date": "2025-04-11 23:24:37 UTC"
  },
  {
    "arxiv_id": "2406.01562v1",
    "title": "A New View on Planning in Online Reinforcement Learning",
    "authors": [
      "Kevin Roice",
      "Parham Mohammad Panahi",
      "Scott M. Jordan",
      "Adam White",
      "Martha White"
    ],
    "abstract": "This paper investigates a new approach to model-based reinforcement learning\nusing background planning: mixing (approximate) dynamic programming updates and\nmodel-free updates, similar to the Dyna architecture. Background planning with\nlearned models is often worse than model-free alternatives, such as Double DQN,\neven though the former uses significantly more memory and computation. The\nfundamental problem is that learned models can be inaccurate and often generate\ninvalid states, especially when iterated many steps. In this paper, we avoid\nthis limitation by constraining background planning to a set of (abstract)\nsubgoals and learning only local, subgoal-conditioned models. This goal-space\nplanning (GSP) approach is more computationally efficient, naturally\nincorporates temporal abstraction for faster long-horizon planning and avoids\nlearning the transition dynamics entirely. We show that our GSP algorithm can\npropagate value from an abstract space in a manner that helps a variety of base\nlearners learn significantly faster in different domains.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Published in the Planning and Reinforcement Learning Workshop at\n  ICAPS 2024. arXiv admin note: text overlap with arXiv:2206.02902",
    "pdf_url": "http://arxiv.org/pdf/2406.01562v1",
    "published_date": "2024-06-03 17:45:19 UTC",
    "updated_date": "2024-06-03 17:45:19 UTC"
  },
  {
    "arxiv_id": "2406.01561v4",
    "title": "Guided Score identity Distillation for Data-Free One-Step Text-to-Image Generation",
    "authors": [
      "Mingyuan Zhou",
      "Zhendong Wang",
      "Huangjie Zheng",
      "Hai Huang"
    ],
    "abstract": "Diffusion-based text-to-image generation models trained on extensive\ntext-image pairs have demonstrated the ability to produce photorealistic images\naligned with textual descriptions. However, a significant limitation of these\nmodels is their slow sample generation process, which requires iterative\nrefinement through the same network. To overcome this, we introduce a data-free\nguided distillation method that enables the efficient distillation of\npretrained Stable Diffusion models without access to the real training data,\noften restricted due to legal, privacy, or cost concerns. This method enhances\nScore identity Distillation (SiD) with Long and Short Classifier-Free Guidance\n(LSG), an innovative strategy that applies Classifier-Free Guidance (CFG) not\nonly to the evaluation of the pretrained diffusion model but also to the\ntraining and evaluation of the fake score network. We optimize a model-based\nexplicit score matching loss using a score-identity-based approximation\nalongside our proposed guidance strategies for practical computation. By\nexclusively training with synthetic images generated by its one-step generator,\nour data-free distillation method rapidly improves FID and CLIP scores,\nachieving state-of-the-art FID performance while maintaining a competitive CLIP\nscore. Notably, the one-step distillation of Stable Diffusion 1.5 achieves an\nFID of 8.15 on the COCO-2014 validation set, a record low value under the\ndata-free setting. Our code and checkpoints are available at\nhttps://github.com/mingyuanzhou/SiD-LSG.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.CV",
    "comment": "ICLR 2025; fixed typos in Table 1; Code and model checkpoints\n  available at https://github.com/mingyuanzhou/SiD-LSG; More efficient code\n  using AMP is coming soon",
    "pdf_url": "http://arxiv.org/pdf/2406.01561v4",
    "published_date": "2024-06-03 17:44:11 UTC",
    "updated_date": "2025-02-08 17:46:58 UTC"
  },
  {
    "arxiv_id": "2406.01552v1",
    "title": "Learning equivariant tensor functions with applications to sparse vector recovery",
    "authors": [
      "Wilson G. Gregory",
      "Josué Tonelli-Cueto",
      "Nicholas F. Marshall",
      "Andrew S. Lee",
      "Soledad Villar"
    ],
    "abstract": "This work characterizes equivariant polynomial functions from tuples of\ntensor inputs to tensor outputs. Loosely motivated by physics, we focus on\nequivariant functions with respect to the diagonal action of the orthogonal\ngroup on tensors. We show how to extend this characterization to other linear\nalgebraic groups, including the Lorentz and symplectic groups.\n  Our goal behind these characterizations is to define equivariant machine\nlearning models. In particular, we focus on the sparse vector estimation\nproblem. This problem has been broadly studied in the theoretical computer\nscience literature, and explicit spectral methods, derived by techniques from\nsum-of-squares, can be shown to recover sparse vectors under certain\nassumptions. Our numerical results show that the proposed equivariant machine\nlearning models can learn spectral methods that outperform the best\ntheoretically known spectral methods in some regimes. The experiments also\nsuggest that learned spectral methods can solve the problem in settings that\nhave not yet been theoretically analyzed.\n  This is an example of a promising direction in which theory can inform\nmachine learning models and machine learning models could inform theory.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01552v1",
    "published_date": "2024-06-03 17:32:43 UTC",
    "updated_date": "2024-06-03 17:32:43 UTC"
  },
  {
    "arxiv_id": "2406.01549v2",
    "title": "An Information Bottleneck Perspective for Effective Noise Filtering on Retrieval-Augmented Generation",
    "authors": [
      "Kun Zhu",
      "Xiaocheng Feng",
      "Xiyuan Du",
      "Yuxuan Gu",
      "Weijiang Yu",
      "Haotian Wang",
      "Qianglong Chen",
      "Zheng Chu",
      "Jingchang Chen",
      "Bing Qin"
    ],
    "abstract": "Retrieval-augmented generation integrates the capabilities of large language\nmodels with relevant information retrieved from an extensive corpus, yet\nencounters challenges when confronted with real-world noisy data. One recent\nsolution is to train a filter module to find relevant content but only achieve\nsuboptimal noise compression. In this paper, we propose to introduce the\ninformation bottleneck theory into retrieval-augmented generation. Our approach\ninvolves the filtration of noise by simultaneously maximizing the mutual\ninformation between compression and ground output, while minimizing the mutual\ninformation between compression and retrieved passage. In addition, we derive\nthe formula of information bottleneck to facilitate its application in novel\ncomprehensive evaluations, the selection of supervised fine-tuning data, and\nthe construction of reinforcement learning rewards. Experimental results\ndemonstrate that our approach achieves significant improvements across various\nquestion answering datasets, not only in terms of the correctness of answer\ngeneration but also in the conciseness with $2.5\\%$ compression rate.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.01549v2",
    "published_date": "2024-06-03 17:31:06 UTC",
    "updated_date": "2024-07-04 14:21:39 UTC"
  },
  {
    "arxiv_id": "2406.01548v3",
    "title": "How to discretize continuous state-action spaces in Q-learning: A symbolic control approach",
    "authors": [
      "Sadek Belamfedel Alaoui",
      "Adnane Saoud"
    ],
    "abstract": "Q-learning is widely recognized as an effective approach for synthesizing\ncontrollers to achieve specific goals. However, handling challenges posed by\ncontinuous state-action spaces remains an ongoing research focus. This paper\npresents a systematic analysis that highlights a major drawback in space\ndiscretization methods. To address this challenge, the paper proposes a\nsymbolic model that represents behavioral relations, such as alternating\nsimulation from abstraction to the controlled system. This relation allows for\nseamless application of the synthesized controller based on abstraction to the\noriginal system. Introducing a novel Q-learning technique for symbolic models,\nthe algorithm yields two Q-tables encoding optimal policies. Theoretical\nanalysis demonstrates that these Q-tables serve as both upper and lower bounds\non the Q-values of the original system with continuous spaces. Additionally,\nthe paper explores the correlation between the parameters of the space\nabstraction and the loss in Q-values. The resulting algorithm facilitates\nachieving optimality within an arbitrary accuracy, providing control over the\ntrade-off between accuracy and computational complexity. The obtained results\nprovide valuable insights for selecting appropriate learning parameters and\nrefining the controller. The engineering relevance of the proposed Q-learning\nbased symbolic model is illustrated through two case studies.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY",
      "math.DS"
    ],
    "primary_category": "eess.SY",
    "comment": "Q-learning, Symbolic control, Abstraction",
    "pdf_url": "http://arxiv.org/pdf/2406.01548v3",
    "published_date": "2024-06-03 17:30:42 UTC",
    "updated_date": "2024-06-05 22:58:27 UTC"
  },
  {
    "arxiv_id": "2406.01544v2",
    "title": "Validity Learning on Failures: Mitigating the Distribution Shift in Autonomous Vehicle Planning",
    "authors": [
      "Fazel Arasteh",
      "Mohammed Elmahgiubi",
      "Behzad Khamidehi",
      "Hamidreza Mirkhani",
      "Weize Zhang",
      "Cao Tongtong",
      "Kasra Rezaee"
    ],
    "abstract": "The planning problem constitutes a fundamental aspect of the autonomous\ndriving framework. Recent strides in representation learning have empowered\nvehicles to comprehend their surrounding environments, thereby facilitating the\nintegration of learning-based planning strategies. Among these approaches,\nImitation Learning stands out due to its notable training efficiency. However,\ntraditional Imitation Learning methodologies encounter challenges associated\nwith the co-variate shift phenomenon. We propose Validity Learning on Failures,\nVL(on failure), as a remedy to address this issue. The essence of our method\nlies in deploying a pre-trained planner across diverse scenarios. Instances\nwhere the planner deviates from its immediate objectives, such as maintaining a\nsafe distance from obstacles or adhering to traffic rules, are flagged as\nfailures. The states corresponding to these failures are compiled into a new\ndataset, termed the failure dataset. Notably, the absence of expert annotations\nfor this data precludes the applicability of standard imitation learning\napproaches. To facilitate learning from the closed-loop mistakes, we introduce\nthe VL objective which aims to discern valid trajectories within the current\nenvironmental context. Experimental evaluations conducted on both reactive\nCARLA simulation and non-reactive log-replay simulations reveal substantial\nenhancements in closed-loop metrics such as \\textit{Score, Progress}, and\nSuccess Rate, underscoring the effectiveness of the proposed methodology.\nFurther evaluations against the Bench2Drive benchmark demonstrate that VL(on\nfailure) outperforms the state-of-the-art methods by a large margin.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01544v2",
    "published_date": "2024-06-03 17:25:18 UTC",
    "updated_date": "2024-09-23 19:47:50 UTC"
  },
  {
    "arxiv_id": "2406.01538v2",
    "title": "What Are Large Language Models Mapping to in the Brain? A Case Against Over-Reliance on Brain Scores",
    "authors": [
      "Ebrahim Feghhi",
      "Nima Hadidi",
      "Bryan Song",
      "Idan A. Blank",
      "Jonathan C. Kao"
    ],
    "abstract": "Given the remarkable capabilities of large language models (LLMs), there has\nbeen a growing interest in evaluating their similarity to the human brain. One\napproach towards quantifying this similarity is by measuring how well a model\npredicts neural signals, also called \"brain score\". Internal representations\nfrom LLMs achieve state-of-the-art brain scores, leading to speculation that\nthey share computational principles with human language processing. This\ninference is only valid if the subset of neural activity predicted by LLMs\nreflects core elements of language processing. Here, we question this\nassumption by analyzing three neural datasets used in an impactful study on\nLLM-to-brain mappings, with a particular focus on an fMRI dataset where\nparticipants read short passages. We first find that when using shuffled\ntrain-test splits, as done in previous studies with these datasets, a trivial\nfeature that encodes temporal autocorrelation not only outperforms LLMs but\nalso accounts for the majority of neural variance that LLMs explain. We\ntherefore use contiguous splits moving forward. Second, we explain the\nsurprisingly high brain scores of untrained LLMs by showing they do not account\nfor additional neural variance beyond two simple features: sentence length and\nsentence position. This undermines evidence used to claim that the transformer\narchitecture biases computations to be more brain-like. Third, we find that\nbrain scores of trained LLMs on this dataset can largely be explained by\nsentence length, position, and pronoun-dereferenced static word embeddings; a\nsmall, additional amount is explained by sense-specific embeddings and\ncontextual representations of sentence structure. We conclude that\nover-reliance on brain scores can lead to over-interpretations of similarity\nbetween LLMs and brains, and emphasize the importance of deconstructing what\nLLMs are mapping to in neural signals.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 4 figures in the main paper",
    "pdf_url": "http://arxiv.org/pdf/2406.01538v2",
    "published_date": "2024-06-03 17:13:27 UTC",
    "updated_date": "2024-06-20 20:35:36 UTC"
  },
  {
    "arxiv_id": "2406.06572v2",
    "title": "Graph Neural Network Enhanced Retrieval for Question Answering of LLMs",
    "authors": [
      "Zijian Li",
      "Qingyan Guo",
      "Jiawei Shao",
      "Lei Song",
      "Jiang Bian",
      "Jun Zhang",
      "Rui Wang"
    ],
    "abstract": "Retrieval augmented generation has revolutionized large language model (LLM)\noutputs by providing factual supports. Nevertheless, it struggles to capture\nall the necessary knowledge for complex reasoning questions. Existing retrieval\nmethods typically divide reference documents into passages, treating them in\nisolation. These passages, however, are often interrelated, such as passages\nthat are contiguous or share the same keywords. Therefore, it is crucial to\nrecognize such relatedness for enhancing the retrieval process. In this paper,\nwe propose a novel retrieval method, called GNN-Ret, which leverages graph\nneural networks (GNNs) to enhance retrieval by exploiting the relatedness\nbetween passages. Specifically, we first construct a graph of passages by\nconnecting passages that are structure-related or keyword-related. A graph\nneural network (GNN) is then leveraged to exploit the relationships between\npassages and improve the retrieval of supporting passages. Furthermore, we\nextend our method to handle multi-hop reasoning questions using a recurrent\ngraph neural network (RGNN), named RGNN-Ret. At each step, RGNN-Ret integrates\nthe graphs of passages from previous steps, thereby enhancing the retrieval of\nsupporting passages. Extensive experiments on benchmark datasets demonstrate\nthat GNN-Ret achieves higher accuracy for question answering with a single\nquery of LLMs than strong baselines that require multiple queries, and RGNN-Ret\nfurther improves accuracy and achieves state-of-the-art performance, with up to\n10.4% accuracy improvement on the 2WikiMQA dataset.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "Under review",
    "pdf_url": "http://arxiv.org/pdf/2406.06572v2",
    "published_date": "2024-06-03 17:07:46 UTC",
    "updated_date": "2024-10-18 08:20:38 UTC"
  },
  {
    "arxiv_id": "2406.02618v2",
    "title": "Immunocto: a massive immune cell database auto-generated for histopathology",
    "authors": [
      "Mikaël Simard",
      "Zhuoyan Shen",
      "Konstantin Bräutigam",
      "Rasha Abu-Eid",
      "Maria A. Hawkins",
      "Charles-Antoine Collins-Fekete"
    ],
    "abstract": "With the advent of novel cancer treatment options such as immunotherapy,\nstudying the tumour immune micro-environment (TIME) is crucial to inform on\nprognosis and understand potential response to therapeutic agents. A key\napproach to characterising the TIME may be through combining (1) digitised\nmicroscopic high-resolution optical images of hematoxylin and eosin (H&E)\nstained tissue sections obtained in routine histopathology examinations with\n(2) automated immune cell detection and classification methods. In this work,\nwe introduce a workflow to automatically generate robust single cell contours\nand labels from dually stained tissue sections with H&E and multiplexed\nimmunofluorescence (IF) markers. The approach harnesses the Segment Anything\nModel and requires minimal human intervention compared to existing single cell\ndatabases. With this methodology, we create Immunocto, a massive, multi-million\nautomatically generated database of 6,848,454 human cells and objects,\nincluding 2,282,818 immune cells distributed across 4 subtypes: CD4$^+$ T cell\nlymphocytes, CD8$^+$ T cell lymphocytes, CD20$^+$ B cell lymphocytes, and\nCD68$^+$/CD163$^+$ macrophages. For each cell, we provide a 64$\\times$64\npixels$^2$ H&E image at $\\mathbf{40}\\times$ magnification, along with a binary\nmask of the nucleus and a label. The database, which is made publicly\navailable, can be used to train models to study the TIME on routine H&E slides.\nWe show that deep learning models trained on Immunocto result in\nstate-of-the-art performance for lymphocyte detection. The approach\ndemonstrates the benefits of using matched H&E and IF data to generate robust\ndatabases for computational pathology applications.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02618v2",
    "published_date": "2024-06-03 17:03:58 UTC",
    "updated_date": "2025-02-28 11:06:18 UTC"
  },
  {
    "arxiv_id": "2406.01514v3",
    "title": "Decoupled Alignment for Robust Plug-and-Play Adaptation",
    "authors": [
      "Haozheng Luo",
      "Jiahao Yu",
      "Wenxin Zhang",
      "Jialong Li",
      "Jerry Yao-Chieh Hu",
      "Xinyu Xing",
      "Han Liu"
    ],
    "abstract": "We introduce a low-resource safety enhancement method for aligning large\nlanguage models (LLMs) without the need for supervised fine-tuning (SFT) or\nreinforcement learning from human feedback (RLHF). Our main idea is to exploit\nknowledge distillation to extract the alignment information from existing\nwell-aligned LLMs and integrate it into unaligned LLMs in a plug-and-play\nfashion. Methodology, we employ delta debugging to identify the critical\ncomponents of knowledge necessary for effective distillation. On the harmful\nquestion dataset, our method significantly enhances the average defense success\nrate by approximately 14.41%, reaching as high as 51.39%, in 17 unaligned\npre-trained LLMs, without compromising performance.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01514v3",
    "published_date": "2024-06-03 16:46:18 UTC",
    "updated_date": "2024-06-06 04:25:40 UTC"
  },
  {
    "arxiv_id": "2406.06571v5",
    "title": "SUBLLM: A Novel Efficient Architecture with Token Sequence Subsampling for LLM",
    "authors": [
      "Quandong Wang",
      "Yuxuan Yuan",
      "Xiaoyu Yang",
      "Ruike Zhang",
      "Kang Zhao",
      "Wei Liu",
      "Jian Luan",
      "Daniel Povey",
      "Bin Wang"
    ],
    "abstract": "While Large Language Models (LLMs) have achieved remarkable success in\nvarious fields, the efficiency of training and inference remains a major\nchallenge. To address this issue, we propose SUBLLM, short for\nSubsampling-Upsampling-Bypass Large Language Model, an innovative architecture\nthat extends the core decoder-only framework by incorporating subsampling,\nupsampling, and bypass modules. The subsampling modules are responsible for\nshortening the sequence, while the upsampling modules restore the sequence\nlength, and the bypass modules enhance convergence. In comparison to LLaMA, the\nproposed SUBLLM exhibits significant enhancements in both training and\ninference speeds as well as memory usage, while maintaining competitive\nfew-shot performance. During training, SUBLLM increases speeds by 26% and cuts\nmemory by 10GB per GPU. In inference, it boosts speeds by up to 37% and reduces\nmemory by 1GB per GPU. The training and inference speeds can be enhanced by 34%\nand 52% respectively when the context window is expanded to 8192. Our code is\navailable at https://github.com/XiaoMi/subllm.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 5 figures, accepted by ECAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.06571v5",
    "published_date": "2024-06-03 16:43:04 UTC",
    "updated_date": "2024-08-23 08:17:58 UTC"
  },
  {
    "arxiv_id": "2406.01506v3",
    "title": "The Geometry of Categorical and Hierarchical Concepts in Large Language Models",
    "authors": [
      "Kiho Park",
      "Yo Joong Choe",
      "Yibo Jiang",
      "Victor Veitch"
    ],
    "abstract": "The linear representation hypothesis is the informal idea that semantic\nconcepts are encoded as linear directions in the representation spaces of large\nlanguage models (LLMs). Previous work has shown how to make this notion precise\nfor representing binary concepts that have natural contrasts (e.g., {male,\nfemale}) as directions in representation space. However, many natural concepts\ndo not have natural contrasts (e.g., whether the output is about an animal). In\nthis work, we show how to extend the formalization of the linear representation\nhypothesis to represent features (e.g., is_animal) as vectors. This allows us\nto immediately formalize the representation of categorical concepts as\npolytopes in the representation space. Further, we use the formalization to\nprove a relationship between the hierarchical structure of concepts and the\ngeometry of their representations. We validate these theoretical results on the\nGemma and LLaMA-3 large language models, estimating representations for 900+\nhierarchically related concepts using data from WordNet.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted for an oral presentation at ICLR 2025. Best Paper Award at\n  the ICML 2024 Workshop on Mechanistic Interpretability. Code is available at\n  https://github.com/KihoPark/LLM_Categorical_Hierarchical_Representations",
    "pdf_url": "http://arxiv.org/pdf/2406.01506v3",
    "published_date": "2024-06-03 16:34:01 UTC",
    "updated_date": "2025-02-18 02:23:45 UTC"
  },
  {
    "arxiv_id": "2406.16906v1",
    "title": "REST: Efficient and Accelerated EEG Seizure Analysis through Residual State Updates",
    "authors": [
      "Arshia Afzal",
      "Grigorios Chrysos",
      "Volkan Cevher",
      "Mahsa Shoaran"
    ],
    "abstract": "EEG-based seizure detection models face challenges in terms of inference\nspeed and memory efficiency, limiting their real-time implementation in\nclinical devices. This paper introduces a novel graph-based residual state\nupdate mechanism (REST) for real-time EEG signal analysis in applications such\nas epileptic seizure detection. By leveraging a combination of graph neural\nnetworks and recurrent structures, REST efficiently captures both non-Euclidean\ngeometry and temporal dependencies within EEG data. Our model demonstrates high\naccuracy in both seizure detection and classification tasks. Notably, REST\nachieves a remarkable 9-fold acceleration in inference speed compared to\nstate-of-the-art models, while simultaneously demanding substantially less\nmemory than the smallest model employed for this task. These attributes\nposition REST as a promising candidate for real-time implementation in clinical\ndevices, such as Responsive Neurostimulation or seizure alert systems.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "Accepted paper at International Confrence on Machine Learning (ICML\n  2024). Visit our website: https://arshiaafzal.github.io/REST/",
    "pdf_url": "http://arxiv.org/pdf/2406.16906v1",
    "published_date": "2024-06-03 16:30:19 UTC",
    "updated_date": "2024-06-03 16:30:19 UTC"
  },
  {
    "arxiv_id": "2406.12888v1",
    "title": "A Space Group Symmetry Informed Network for O(3) Equivariant Crystal Tensor Prediction",
    "authors": [
      "Keqiang Yan",
      "Alexandra Saxton",
      "Xiaofeng Qian",
      "Xiaoning Qian",
      "Shuiwang Ji"
    ],
    "abstract": "We consider the prediction of general tensor properties of crystalline\nmaterials, including dielectric, piezoelectric, and elastic tensors. A key\nchallenge here is how to make the predictions satisfy the unique tensor\nequivariance to O(3) group and invariance to crystal space groups. To this end,\nwe propose a General Materials Tensor Network (GMTNet), which is carefully\ndesigned to satisfy the required symmetries. To evaluate our method, we curate\na dataset and establish evaluation metrics that are tailored to the intricacies\nof crystal tensor predictions. Experimental results show that our GMTNet not\nonly achieves promising performance on crystal tensors of various orders but\nalso generates predictions fully consistent with the intrinsic crystal\nsymmetries. Our code is publicly available as part of the AIRS library\n(https://github.com/divelab/AIRS).",
    "categories": [
      "cond-mat.mtrl-sci",
      "cs.AI",
      "physics.atom-ph"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "comment": "This paper has been accepted to ICML 24 as a poster. You are\n  encouraged to cite the conference version of this paper",
    "pdf_url": "http://arxiv.org/pdf/2406.12888v1",
    "published_date": "2024-06-03 16:26:16 UTC",
    "updated_date": "2024-06-03 16:26:16 UTC"
  },
  {
    "arxiv_id": "2406.01481v1",
    "title": "Learning from Streaming Data when Users Choose",
    "authors": [
      "Jinyan Su",
      "Sarah Dean"
    ],
    "abstract": "In digital markets comprised of many competing services, each user chooses\nbetween multiple service providers according to their preferences, and the\nchosen service makes use of the user data to incrementally improve its model.\nThe service providers' models influence which service the user will choose at\nthe next time step, and the user's choice, in return, influences the model\nupdate, leading to a feedback loop. In this paper, we formalize the above\ndynamics and develop a simple and efficient decentralized algorithm to locally\nminimize the overall user loss. Theoretically, we show that our algorithm\nasymptotically converges to stationary points of of the overall loss almost\nsurely. We also experimentally demonstrate the utility of our algorithm with\nreal world data.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by ICML24",
    "pdf_url": "http://arxiv.org/pdf/2406.01481v1",
    "published_date": "2024-06-03 16:07:52 UTC",
    "updated_date": "2024-06-03 16:07:52 UTC"
  },
  {
    "arxiv_id": "2406.16905v1",
    "title": "Optimising Random Forest Machine Learning Algorithms for User VR Experience Prediction Based on Iterative Local Search-Sparrow Search Algorithm",
    "authors": [
      "Xirui Tang",
      "Feiyang Li",
      "Zinan Cao",
      "Qixuan Yu",
      "Yulu Gong"
    ],
    "abstract": "In this paper, an improved method for VR user experience prediction is\ninvestigated by introducing a sparrow search algorithm and a random forest\nalgorithm improved by an iterative local search-optimised sparrow search\nalgorithm. The study firstly conducted a statistical analysis of the data, and\nthen trained and tested using the traditional random forest model, the random\nforest model improved by the sparrow search algorithm, and the random forest\nalgorithm improved based on the iterative local search-sparrow search\nalgorithm, respectively. The results show that the traditional random forest\nmodel has a prediction accuracy of 93% on the training set but only 73.3% on\nthe test set, which is poor in generalisation; whereas the model improved by\nthe sparrow search algorithm has a prediction accuracy of 94% on the test set,\nwhich is improved compared with the traditional model. What is more noteworthy\nis that the improved model based on the iterative local search-sparrow search\nalgorithm achieves 100% accuracy on both the training and test sets, which is\nsignificantly better than the other two methods. These research results provide\nnew ideas and methods for VR user experience prediction, especially the\nimproved model based on the iterative local search-sparrow search algorithm\nperforms well and is able to more accurately predict and classify the user's VR\nexperience. In the future, the application of this method in other fields can\nbe further explored, and its effectiveness can be verified through real cases\nto promote the development of AI technology in the field of user experience.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.16905v1",
    "published_date": "2024-06-03 15:58:26 UTC",
    "updated_date": "2024-06-03 15:58:26 UTC"
  },
  {
    "arxiv_id": "2406.01468v2",
    "title": "Understanding Token Probability Encoding in Output Embeddings",
    "authors": [
      "Hakaze Cho",
      "Yoshihiro Sakai",
      "Kenshiro Tanaka",
      "Mariko Kato",
      "Naoya Inoue"
    ],
    "abstract": "In this paper, we investigate the output token probability information in the\noutput embedding of language models. We find an approximate common log-linear\nencoding of output token probabilities within the output embedding vectors and\nempirically demonstrate that it is accurate and sparse. As a causality\nexamination, we steer the encoding in output embedding to modify the output\nprobability distribution accurately. Moreover, the sparsity we find in output\nprobability encoding suggests that a large number of dimensions in the output\nembedding do not contribute to causal language modeling. Therefore, we attempt\nto delete the output-unrelated dimensions and find more than 30% of the\ndimensions can be deleted without significant movement in output distribution\nand sequence generation. Additionally, in the pre-training dynamics of language\nmodels, we find that the output embeddings capture the corpus token frequency\ninformation in early steps, even before an obvious convergence of parameters\nstarts.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "15 pages, 17 figures, 3 tables. COLING 2025 Accepted",
    "pdf_url": "http://arxiv.org/pdf/2406.01468v2",
    "published_date": "2024-06-03 15:57:29 UTC",
    "updated_date": "2024-12-11 13:22:12 UTC"
  },
  {
    "arxiv_id": "2406.01462v2",
    "title": "The Importance of Online Data: Understanding Preference Fine-tuning via Coverage",
    "authors": [
      "Yuda Song",
      "Gokul Swamy",
      "Aarti Singh",
      "J. Andrew Bagnell",
      "Wen Sun"
    ],
    "abstract": "Learning from human preference data has emerged as the dominant paradigm for\nfine-tuning large language models (LLMs). The two most common families of\ntechniques -- online reinforcement learning (RL) such as Proximal Policy\nOptimization (PPO) and offline contrastive methods such as Direct Preference\nOptimization (DPO) -- were positioned as equivalent in prior work due to the\nfact that both have to start from the same offline preference dataset. To\nfurther expand our theoretical understanding of the similarities and\ndifferences between online and offline techniques for preference fine-tuning,\nwe conduct a rigorous analysis through the lens of dataset coverage, a concept\nthat captures how the training data covers the test distribution and is widely\nused in RL. We prove that a global coverage condition is both necessary and\nsufficient for offline contrastive methods to converge to the optimal policy,\nbut a weaker partial coverage condition suffices for online RL methods. This\nseparation provides one explanation of why online RL methods can perform better\nthan offline methods, especially when the offline preference data is not\ndiverse enough. Finally, motivated by our preceding theoretical observations,\nwe derive a hybrid preference optimization (HyPO) algorithm that uses offline\ndata for contrastive-based preference optimization and online data for KL\nregularization. Theoretically and empirically, we demonstrate that HyPO is more\nperformant than its pure offline counterpart DPO, while still preserving its\ncomputation and memory efficiency.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01462v2",
    "published_date": "2024-06-03 15:51:04 UTC",
    "updated_date": "2024-07-16 16:51:38 UTC"
  },
  {
    "arxiv_id": "2406.01460v2",
    "title": "MLIP: Efficient Multi-Perspective Language-Image Pretraining with Exhaustive Data Utilization",
    "authors": [
      "Yu Zhang",
      "Qi Zhang",
      "Zixuan Gong",
      "Yiwei Shi",
      "Yepeng Liu",
      "Duoqian Miao",
      "Yang Liu",
      "Ke Liu",
      "Kun Yi",
      "Wei Fan",
      "Liang Hu",
      "Changwei Wang"
    ],
    "abstract": "Contrastive Language-Image Pretraining (CLIP) has achieved remarkable\nsuccess, leading to rapid advancements in multimodal studies. However, CLIP\nfaces a notable challenge in terms of inefficient data utilization. It relies\non a single contrastive supervision for each image-text pair during\nrepresentation learning, disregarding a substantial amount of valuable\ninformation that could offer richer supervision. Additionally, the retention of\nnon-informative tokens leads to increased computational demands and time costs,\nparticularly in CLIP's ViT image encoder. To address these issues, we propose\nMulti-Perspective Language-Image Pretraining (MLIP). In MLIP, we leverage the\nfrequency transform's sensitivity to both high and low-frequency variations,\nwhich complements the spatial domain's sensitivity limited to low-frequency\nvariations only. By incorporating frequency transforms and token-level\nalignment, we expand CILP's single supervision into multi-domain and\nmulti-level supervision, enabling a more thorough exploration of informative\nimage features. Additionally, we introduce a token merging method guided by\ncomprehensive semantics from the frequency and spatial domains. This allows us\nto merge tokens to multi-granularity tokens with a controllable compression\nrate to accelerate CLIP. Extensive experiments validate the effectiveness of\nour design.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.01460v2",
    "published_date": "2024-06-03 15:49:11 UTC",
    "updated_date": "2024-06-04 07:36:57 UTC"
  },
  {
    "arxiv_id": "2406.06569v1",
    "title": "Enhancing Clinical Documentation with Synthetic Data: Leveraging Generative Models for Improved Accuracy",
    "authors": [
      "Anjanava Biswas",
      "Wrick Talukdar"
    ],
    "abstract": "Accurate and comprehensive clinical documentation is crucial for delivering\nhigh-quality healthcare, facilitating effective communication among providers,\nand ensuring compliance with regulatory requirements. However, manual\ntranscription and data entry processes can be time-consuming, error-prone, and\nsusceptible to inconsistencies, leading to incomplete or inaccurate medical\nrecords. This paper proposes a novel approach to augment clinical documentation\nby leveraging synthetic data generation techniques to generate realistic and\ndiverse clinical transcripts. We present a methodology that combines\nstate-of-the-art generative models, such as Generative Adversarial Networks\n(GANs) and Variational Autoencoders (VAEs), with real-world clinical transcript\nand other forms of clinical data to generate synthetic transcripts. These\nsynthetic transcripts can then be used to supplement existing documentation\nworkflows, providing additional training data for natural language processing\nmodels and enabling more accurate and efficient transcription processes.\nThrough extensive experiments on a large dataset of anonymized clinical\ntranscripts, we demonstrate the effectiveness of our approach in generating\nhigh-quality synthetic transcripts that closely resemble real-world data.\nQuantitative evaluation metrics, including perplexity scores and BLEU scores,\nas well as qualitative assessments by domain experts, validate the fidelity and\nutility of the generated synthetic transcripts. Our findings highlight\nsynthetic data generation's potential to address clinical documentation\nchallenges, improving patient care, reducing administrative burdens, and\nenhancing healthcare system efficiency.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.06569v1",
    "published_date": "2024-06-03 15:49:03 UTC",
    "updated_date": "2024-06-03 15:49:03 UTC"
  },
  {
    "arxiv_id": "2407.08745v1",
    "title": "Evolutionary Computation for the Design and Enrichment of General-Purpose Artificial Intelligence Systems: Survey and Prospects",
    "authors": [
      "Javier Poyatos",
      "Javier Del Ser",
      "Salvador Garcia",
      "Hisao Ishibuchi",
      "Daniel Molina",
      "Isaac Triguero",
      "Bing Xue",
      "Xin Yao",
      "Francisco Herrera"
    ],
    "abstract": "In Artificial Intelligence, there is an increasing demand for adaptive models\ncapable of dealing with a diverse spectrum of learning tasks, surpassing the\nlimitations of systems devised to cope with a single task. The recent emergence\nof General-Purpose Artificial Intelligence Systems (GPAIS) poses model\nconfiguration and adaptability challenges at far greater complexity scales than\nthe optimal design of traditional Machine Learning models. Evolutionary\nComputation (EC) has been a useful tool for both the design and optimization of\nMachine Learning models, endowing them with the capability to configure and/or\nadapt themselves to the task under consideration. Therefore, their application\nto GPAIS is a natural choice. This paper aims to analyze the role of EC in the\nfield of GPAIS, exploring the use of EC for their design or enrichment. We also\nmatch GPAIS properties to Machine Learning areas in which EC has had a notable\ncontribution, highlighting recent milestones of EC for GPAIS. Furthermore, we\ndiscuss the challenges of harnessing the benefits of EC for GPAIS, presenting\ndifferent strategies to both design and improve GPAIS with EC, covering\ntangential areas, identifying research niches, and outlining potential research\ndirections for EC and GPAIS.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.08745v1",
    "published_date": "2024-06-03 15:47:17 UTC",
    "updated_date": "2024-06-03 15:47:17 UTC"
  },
  {
    "arxiv_id": "2406.01455v3",
    "title": "Automatic Fused Multimodal Deep Learning for Plant Identification",
    "authors": [
      "Alfreds Lapkovskis",
      "Natalia Nefedova",
      "Ali Beikmohammadi"
    ],
    "abstract": "Plant classification is vital for ecological conservation and agricultural\nproductivity, enhancing our understanding of plant growth dynamics and aiding\nspecies preservation. The advent of deep learning (DL) techniques has\nrevolutionized this field by enabling autonomous feature extraction,\nsignificantly reducing the dependence on manual expertise. However,\nconventional DL models often rely solely on single data sources, failing to\ncapture the full biological diversity of plant species comprehensively. Recent\nresearch has turned to multimodal learning to overcome this limitation by\nintegrating multiple data types, which enriches the representation of plant\ncharacteristics. This shift introduces the challenge of determining the optimal\npoint for modality fusion. In this paper, we introduce a pioneering multimodal\nDL-based approach for plant classification with automatic modality fusion.\nUtilizing the multimodal fusion architecture search, our method integrates\nimages from multiple plant organs -- flowers, leaves, fruits, and stems -- into\na cohesive model. To address the lack of multimodal datasets, we contributed\nMultimodal-PlantCLEF, a restructured version of the PlantCLEF2015 dataset\ntailored for multimodal tasks. Our method achieves 82.61% accuracy on 979\nclasses of Multimodal-PlantCLEF, surpassing state-of-the-art methods and\noutperforming late fusion by 10.33%. Through the incorporation of multimodal\ndropout, our approach demonstrates strong robustness to missing modalities. We\nvalidate our model against established benchmarks using standard performance\nmetrics and McNemar's test, further underscoring its superiority.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01455v3",
    "published_date": "2024-06-03 15:43:29 UTC",
    "updated_date": "2025-01-18 12:51:29 UTC"
  },
  {
    "arxiv_id": "2406.01424v2",
    "title": "Universal In-Context Approximation By Prompting Fully Recurrent Models",
    "authors": [
      "Aleksandar Petrov",
      "Tom A. Lamb",
      "Alasdair Paren",
      "Philip H. S. Torr",
      "Adel Bibi"
    ],
    "abstract": "Zero-shot and in-context learning enable solving tasks without model\nfine-tuning, making them essential for developing generative model solutions.\nTherefore, it is crucial to understand whether a pretrained model can be\nprompted to approximate any function, i.e., whether it is a universal\nin-context approximator. While it was recently shown that transformer models do\npossess this property, these results rely on their attention mechanism. Hence,\nthese findings do not apply to fully recurrent architectures like RNNs, LSTMs,\nand the increasingly popular SSMs. We demonstrate that RNNs, LSTMs, GRUs,\nLinear RNNs, and linear gated architectures such as Mamba and Hawk/Griffin can\nalso serve as universal in-context approximators. To streamline our argument,\nwe introduce a programming language called LSRL that compiles to these fully\nrecurrent architectures. LSRL may be of independent interest for further\nstudies of fully recurrent models, such as constructing interpretability\nbenchmarks. We also study the role of multiplicative gating and observe that\narchitectures incorporating such gating (e.g., LSTMs, GRUs, Hawk/Griffin) can\nimplement certain operations more stably, making them more viable candidates\nfor practical in-context universal approximation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Published at NeurIPS 2024, Code at\n  https://github.com/AleksandarPetrov/LSRL",
    "pdf_url": "http://arxiv.org/pdf/2406.01424v2",
    "published_date": "2024-06-03 15:25:13 UTC",
    "updated_date": "2024-10-10 16:39:12 UTC"
  },
  {
    "arxiv_id": "2406.01423v2",
    "title": "Value Improved Actor Critic Algorithms",
    "authors": [
      "Yaniv Oren",
      "Moritz A. Zanger",
      "Pascal R. van der Vaart",
      "Mustafa Mert Celikok",
      "Matthijs T. J. Spaan",
      "Wendelin Bohmer"
    ],
    "abstract": "To learn approximately optimal acting policies for decision problems, modern\nActor Critic algorithms rely on deep Neural Networks (DNNs) to parameterize the\nacting policy and greedification operators to iteratively improve it. The\nreliance on DNNs suggests an improvement that is gradient based, which is per\nstep much less greedy than the improvement possible by greedier operators such\nas the greedy update used by Q-learning algorithms. On the other hand, slow and\nsteady changes to the policy can also be beneficial for the stability of the\nlearning process, resulting in a tradeoff between greedification and stability.\nTo address this tradeoff, we propose to extend the standard framework of actor\ncritic algorithms with value-improvement: a second greedification operator\napplied only when updating the policy's value estimate. In this framework the\nagent can evaluate non-parameterized policies and perform much greedier updates\nwhile maintaining the steady gradient-based improvement to the parameterized\nacting policy. We prove that this approach converges in the popular analysis\nscheme of Generalized Policy Iteration in the finite-horizon domain.\nEmpirically, incorporating value-improvement into the popular off-policy\nactor-critic algorithms TD3 and SAC significantly improves or matches\nperformance over their respective baselines, across different environments from\nthe DeepMind continuous control domain, with negligible compute and\nimplementation cost.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01423v2",
    "published_date": "2024-06-03 15:24:15 UTC",
    "updated_date": "2025-03-11 11:25:21 UTC"
  },
  {
    "arxiv_id": "2406.01421v1",
    "title": "Problematizing AI Omnipresence in Landscape Architecture",
    "authors": [
      "Phillip Fernberg",
      "Zihao Zhang"
    ],
    "abstract": "This position paper argues for, and offers, a critical lens through which to\nexamine the current AI frenzy in the landscape architecture profession. In it,\nthe authors propose five archetypes or mental modes that landscape architects\nmight inhabit when thinking about AI. Rather than limiting judgments of AI use\nto a single axis of acceleration, these archetypes and corresponding narratives\nexist along a relational spectrum and are permeable, allowing LAs to take on\nand switch between them according to context. We model these relationships\nbetween the archetypes and their contributions to AI advancement using a causal\nloop diagram (CLD), and with those interactions argue that more nuanced ways of\napproaching AI might also open new modes of practice in the new digital\neconomy.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01421v1",
    "published_date": "2024-06-03 15:20:05 UTC",
    "updated_date": "2024-06-03 15:20:05 UTC"
  },
  {
    "arxiv_id": "2407.08744v1",
    "title": "Toward Efficient Deep Spiking Neuron Networks:A Survey On Compression",
    "authors": [
      "Hui Xie",
      "Ge Yang",
      "Wenjuan Gao"
    ],
    "abstract": "With the rapid development of deep learning, Deep Spiking Neural Networks\n(DSNNs) have emerged as promising due to their unique spike event processing\nand asynchronous computation. When deployed on neuromorphic chips, DSNNs offer\nsignificant power advantages over Deep Artificial Neural Networks (DANNs) and\neliminate time and energy consuming multiplications due to the binary nature of\nspikes (0 or 1). Additionally, DSNNs excel in processing temporal information,\nmaking them potentially superior for handling temporal data compared to DANNs.\nHowever, their deep network structure and numerous parameters result in high\ncomputational costs and energy consumption, limiting real-life deployment. To\nenhance DSNNs efficiency, researchers have adapted methods from DANNs, such as\npruning, quantization, and knowledge distillation, and developed specific\ntechniques like reducing spike firing and pruning time steps. While previous\nsurveys have covered DSNNs algorithms, hardware deployment, and general\noverviews, focused research on DSNNs compression and efficiency has been\nlacking. This survey addresses this gap by concentrating on efficient DSNNs and\ntheir compression methods. It begins with an exploration of DSNNs' biological\nbackground and computational units, highlighting differences from DANNs. It\nthen delves into various compression methods, including pruning, quantization,\nknowledge distillation, and reducing spike firing, and concludes with\nsuggestions for future research directions.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.08744v1",
    "published_date": "2024-06-03 15:11:54 UTC",
    "updated_date": "2024-06-03 15:11:54 UTC"
  },
  {
    "arxiv_id": "2406.01402v1",
    "title": "Mixture of Rationale: Multi-Modal Reasoning Mixture for Visual Question Answering",
    "authors": [
      "Tao Li",
      "Linjun Shou",
      "Xuejun Liu"
    ],
    "abstract": "Zero-shot visual question answering (VQA) is a challenging task that requires\nreasoning across modalities. While some existing methods rely on a single\nrationale within the Chain of Thoughts (CoT) framework, they may fall short of\ncapturing the complexity of the VQA problem. On the other hand, some other\nmethods that use multiple rationales may still suffer from low diversity, poor\nmodality alignment, and inefficient retrieval and fusion. In response to these\nchallenges, we propose \\emph{Mixture of Rationales (MoR)}, a novel multi-modal\nreasoning method that mixes multiple rationales for VQA. MoR uses a single\nfrozen Vision-and-Language Pre-trained Models (VLPM) model to {dynamically\ngenerate, retrieve and fuse multi-modal thoughts}. We evaluate MoR on two\nchallenging VQA datasets, i.e. NLVR2 and OKVQA, with two representative\nbackbones OFA and VL-T5. MoR achieves a 12.43\\% accuracy improvement on NLVR2,\nand a 2.45\\% accuracy improvement on OKVQA-S( the science and technology\ncategory of OKVQA).",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "I.2.10"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01402v1",
    "published_date": "2024-06-03 15:04:47 UTC",
    "updated_date": "2024-06-03 15:04:47 UTC"
  },
  {
    "arxiv_id": "2406.01394v4",
    "title": "PrivacyRestore: Privacy-Preserving Inference in Large Language Models via Privacy Removal and Restoration",
    "authors": [
      "Ziqian Zeng",
      "Jianwei Wang",
      "Junyao Yang",
      "Zhengdong Lu",
      "Huiping Zhuang",
      "Cen Chen"
    ],
    "abstract": "The widespread usage of online Large Language Models (LLMs) inference\nservices has raised significant privacy concerns about the potential exposure\nof private information in user inputs to malicious eavesdroppers. Existing\nprivacy protection methods for LLMs suffer from either insufficient privacy\nprotection, performance degradation, or large inference time overhead. To\naddress these limitations, we propose PrivacyRestore, a plug-and-play method to\nprotect the privacy of user inputs during LLM inference. The server first\ntrains restoration vectors for each privacy span and then release to clients.\nPrivacy span is defined as a contiguous sequence of tokens within a text that\ncontain private information. The client then aggregate restoration vectors of\nall privacy spans in the input into a single meta restoration vector which is\nlater sent to the server side along with the input without privacy spans.The\nprivate information is restored via activation steering during inference.\nFurthermore, we prove that PrivacyRestore inherently prevents the linear growth\nof the privacy budget.We create three datasets, covering medical and legal\ndomains, to evaluate the effectiveness of privacy preserving methods. The\nexperimental results show that PrivacyRestore effectively protects private\ninformation and maintain acceptable levels of performance and inference\noverhead.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01394v4",
    "published_date": "2024-06-03 14:57:39 UTC",
    "updated_date": "2024-12-26 03:49:34 UTC"
  },
  {
    "arxiv_id": "2406.01389v2",
    "title": "RL in Latent MDPs is Tractable: Online Guarantees via Off-Policy Evaluation",
    "authors": [
      "Jeongyeol Kwon",
      "Shie Mannor",
      "Constantine Caramanis",
      "Yonathan Efroni"
    ],
    "abstract": "In many real-world decision problems there is partially observed, hidden or\nlatent information that remains fixed throughout an interaction. Such decision\nproblems can be modeled as Latent Markov Decision Processes (LMDPs), where a\nlatent variable is selected at the beginning of an interaction and is not\ndisclosed to the agent. In the last decade, there has been significant progress\nin solving LMDPs under different structural assumptions. However, for general\nLMDPs, there is no known learning algorithm that provably matches the existing\nlower bound (Kwon et al., 2021). We introduce the first sample-efficient\nalgorithm for LMDPs without any additional structural assumptions. Our result\nbuilds off a new perspective on the role of off-policy evaluation guarantees\nand coverage coefficients in LMDPs, a perspective, that has been overlooked in\nthe context of exploration in partially observed environments. Specifically, we\nestablish a novel off-policy evaluation lemma and introduce a new coverage\ncoefficient for LMDPs. Then, we show how these can be used to derive\nnear-optimal guarantees of an optimistic exploration algorithm. These results,\nwe believe, can be valuable for a wide range of interactive learning problems\nbeyond LMDPs, and especially, for partially observed environments.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "Fixed typos + alpha",
    "pdf_url": "http://arxiv.org/pdf/2406.01389v2",
    "published_date": "2024-06-03 14:51:27 UTC",
    "updated_date": "2024-06-26 15:42:57 UTC"
  },
  {
    "arxiv_id": "2406.01651v3",
    "title": "FusionDTI: Fine-grained Binding Discovery with Token-level Fusion for Drug-Target Interaction",
    "authors": [
      "Zhaohan Meng",
      "Zaiqiao Meng",
      "Ke Yuan",
      "Iadh Ounis"
    ],
    "abstract": "Predicting drug-target interaction (DTI) is critical in the drug discovery\nprocess. Despite remarkable advances in recent DTI models through the\nintegration of representations from diverse drug and target encoders, such\nmodels often struggle to capture the fine-grained interactions between drugs\nand protein, i.e. the binding of specific drug atoms (or substructures) and key\namino acids of proteins, which is crucial for understanding the binding\nmechanisms and optimising drug design. To address this issue, this paper\nintroduces a novel model, called FusionDTI, which uses a token-level Fusion\nmodule to effectively learn fine-grained information for Drug-Target\nInteraction. In particular, our FusionDTI model uses the SELFIES representation\nof drugs to mitigate sequence fragment invalidation and incorporates the\nstructure-aware (SA) vocabulary of target proteins to address the limitation of\namino acid sequences in structural information, additionally leveraging\npre-trained language models extensively trained on large-scale biomedical\ndatasets as encoders to capture the complex information of drugs and targets.\nExperiments on three well-known benchmark datasets show that our proposed\nFusionDTI model achieves the best performance in DTI prediction compared with\nseven existing state-of-the-art baselines. Furthermore, our case study\nindicates that FusionDTI could highlight the potential binding sites, enhancing\nthe explainability of the DTI prediction.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG",
      "q-bio.BM"
    ],
    "primary_category": "q-bio.QM",
    "comment": "10 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.01651v3",
    "published_date": "2024-06-03 14:48:54 UTC",
    "updated_date": "2024-10-07 21:22:58 UTC"
  },
  {
    "arxiv_id": "2406.01384v3",
    "title": "Extending Structural Causal Models for Autonomous Vehicles to Simplify Temporal System Construction & Enable Dynamic Interactions Between Agents",
    "authors": [
      "Rhys Howard",
      "Lars Kunze"
    ],
    "abstract": "In this work we aim to bridge the divide between autonomous vehicles and\ncausal reasoning. Autonomous vehicles have come to increasingly interact with\nhuman drivers, and in many cases may pose risks to the physical or mental\nwell-being of those they interact with. Meanwhile causal models, despite their\ninherent transparency and ability to offer contrastive explanations, have found\nlimited usage within such systems. As such, we first identify the challenges\nthat have limited the integration of structural causal models within autonomous\nvehicles. We then introduce a number of theoretical extensions to the\nstructural causal model formalism in order to tackle these challenges. This\naugments these models to possess greater levels of modularisation and\nencapsulation, as well presenting temporal causal model representation with\nconstant space complexity. We also prove through the extensions we have\nintroduced that dynamically mutable sets (e.g. varying numbers of autonomous\nvehicles across time) can be used within a structural causal model while\nmaintaining a relaxed form of causal stationarity. Finally we discuss the\napplication of the extensions in the context of the autonomous vehicle and\nservice robotics domain along with potential directions for future work.",
    "categories": [
      "cs.AI",
      "cs.RO",
      "cs.SE",
      "D.1.5; D.2.11; G.2.2; I.2.9; J.2"
    ],
    "primary_category": "cs.AI",
    "comment": "30 Pages = 13 Pages (Main Content) + 4 Pages (References) + 13 Pages\n  (Appendix), 15 Figures = 5 Figures (Main Content) + 10 (Appendix), To be\n  published in the Proceedings of the 2025 Causal Learning and Reasoning\n  Conference, Update upload of accepted paper version",
    "pdf_url": "http://arxiv.org/pdf/2406.01384v3",
    "published_date": "2024-06-03 14:47:05 UTC",
    "updated_date": "2025-03-18 05:14:38 UTC"
  },
  {
    "arxiv_id": "2406.01382v1",
    "title": "Do Large Language Models Perform the Way People Expect? Measuring the Human Generalization Function",
    "authors": [
      "Keyon Vafa",
      "Ashesh Rambachan",
      "Sendhil Mullainathan"
    ],
    "abstract": "What makes large language models (LLMs) impressive is also what makes them\nhard to evaluate: their diversity of uses. To evaluate these models, we must\nunderstand the purposes they will be used for. We consider a setting where\nthese deployment decisions are made by people, and in particular, people's\nbeliefs about where an LLM will perform well. We model such beliefs as the\nconsequence of a human generalization function: having seen what an LLM gets\nright or wrong, people generalize to where else it might succeed. We collect a\ndataset of 19K examples of how humans make generalizations across 79 tasks from\nthe MMLU and BIG-Bench benchmarks. We show that the human generalization\nfunction can be predicted using NLP methods: people have consistent structured\nways to generalize. We then evaluate LLM alignment with the human\ngeneralization function. Our results show that -- especially for cases where\nthe cost of mistakes is high -- more capable models (e.g. GPT-4) can do worse\non the instances people choose to use them for, exactly because they are not\naligned with the human generalization function.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "To appear in ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.01382v1",
    "published_date": "2024-06-03 14:45:21 UTC",
    "updated_date": "2024-06-03 14:45:21 UTC"
  },
  {
    "arxiv_id": "2406.01650v1",
    "title": "TAGMol: Target-Aware Gradient-guided Molecule Generation",
    "authors": [
      "Vineeth Dorna",
      "D. Subhalingam",
      "Keshav Kolluru",
      "Shreshth Tuli",
      "Mrityunjay Singh",
      "Saurabh Singal",
      "N. M. Anoop Krishnan",
      "Sayan Ranu"
    ],
    "abstract": "3D generative models have shown significant promise in structure-based drug\ndesign (SBDD), particularly in discovering ligands tailored to specific target\nbinding sites. Existing algorithms often focus primarily on ligand-target\nbinding, characterized by binding affinity. Moreover, models trained solely on\ntarget-ligand distribution may fall short in addressing the broader objectives\nof drug discovery, such as the development of novel ligands with desired\nproperties like drug-likeness, and synthesizability, underscoring the\nmultifaceted nature of the drug design process. To overcome these challenges,\nwe decouple the problem into molecular generation and property prediction. The\nlatter synergistically guides the diffusion sampling process, facilitating\nguided diffusion and resulting in the creation of meaningful molecules with the\ndesired properties. We call this guided molecular generation process as TAGMol.\nThrough experiments on benchmark datasets, TAGMol demonstrates superior\nperformance compared to state-of-the-art baselines, achieving a 22% improvement\nin average Vina Score and yielding favorable outcomes in essential auxiliary\nproperties. This establishes TAGMol as a comprehensive framework for drug\ngeneration.",
    "categories": [
      "q-bio.BM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.BM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01650v1",
    "published_date": "2024-06-03 14:43:54 UTC",
    "updated_date": "2024-06-03 14:43:54 UTC"
  },
  {
    "arxiv_id": "2406.01377v1",
    "title": "Multi-Agent Transfer Learning via Temporal Contrastive Learning",
    "authors": [
      "Weihao Zeng",
      "Joseph Campbell",
      "Simon Stepputtis",
      "Katia Sycara"
    ],
    "abstract": "This paper introduces a novel transfer learning framework for deep\nmulti-agent reinforcement learning. The approach automatically combines\ngoal-conditioned policies with temporal contrastive learning to discover\nmeaningful sub-goals. The approach involves pre-training a goal-conditioned\nagent, finetuning it on the target domain, and using contrastive learning to\nconstruct a planning graph that guides the agent via sub-goals. Experiments on\nmulti-agent coordination Overcooked tasks demonstrate improved sample\nefficiency, the ability to solve sparse-reward and long-horizon problems, and\nenhanced interpretability compared to baselines. The results highlight the\neffectiveness of integrating goal-conditioned policies with unsupervised\ntemporal abstraction learning for complex multi-agent transfer learning.\nCompared to state-of-the-art baselines, our method achieves the same or better\nperformances while requiring only 21.7% of the training samples.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "6 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.01377v1",
    "published_date": "2024-06-03 14:42:14 UTC",
    "updated_date": "2024-06-03 14:42:14 UTC"
  },
  {
    "arxiv_id": "2406.01364v1",
    "title": "BELLS: A Framework Towards Future Proof Benchmarks for the Evaluation of LLM Safeguards",
    "authors": [
      "Diego Dorn",
      "Alexandre Variengien",
      "Charbel-Raphaël Segerie",
      "Vincent Corruble"
    ],
    "abstract": "Input-output safeguards are used to detect anomalies in the traces produced\nby Large Language Models (LLMs) systems. These detectors are at the core of\ndiverse safety-critical applications such as real-time monitoring, offline\nevaluation of traces, and content moderation. However, there is no widely\nrecognized methodology to evaluate them. To fill this gap, we introduce the\nBenchmarks for the Evaluation of LLM Safeguards (BELLS), a structured\ncollection of tests, organized into three categories: (1) established failure\ntests, based on already-existing benchmarks for well-defined failure modes,\naiming to compare the performance of current input-output safeguards; (2)\nemerging failure tests, to measure generalization to never-seen-before failure\nmodes and encourage the development of more general safeguards; (3) next-gen\narchitecture tests, for more complex scaffolding (such as LLM-agents and\nmulti-agent systems), aiming to foster the development of safeguards that could\nadapt to future applications for which no safeguard currently exists.\nFurthermore, we implement and share the first next-gen architecture test, using\nthe MACHIAVELLI environment, along with an interactive visualization of the\ndataset.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01364v1",
    "published_date": "2024-06-03 14:32:30 UTC",
    "updated_date": "2024-06-03 14:32:30 UTC"
  },
  {
    "arxiv_id": "2406.01649v1",
    "title": "CoLa-DCE -- Concept-guided Latent Diffusion Counterfactual Explanations",
    "authors": [
      "Franz Motzkus",
      "Christian Hellert",
      "Ute Schmid"
    ],
    "abstract": "Recent advancements in generative AI have introduced novel prospects and\npractical implementations. Especially diffusion models show their strength in\ngenerating diverse and, at the same time, realistic features, positioning them\nwell for generating counterfactual explanations for computer vision models.\nAnswering \"what if\" questions of what needs to change to make an image\nclassifier change its prediction, counterfactual explanations align well with\nhuman understanding and consequently help in making model behavior more\ncomprehensible. Current methods succeed in generating authentic\ncounterfactuals, but lack transparency as feature changes are not directly\nperceivable. To address this limitation, we introduce Concept-guided Latent\nDiffusion Counterfactual Explanations (CoLa-DCE). CoLa-DCE generates\nconcept-guided counterfactuals for any classifier with a high degree of control\nregarding concept selection and spatial conditioning. The counterfactuals\ncomprise an increased granularity through minimal feature changes. The\nreference feature visualization ensures better comprehensibility, while the\nfeature localization provides increased transparency of \"where\" changed \"what\".\nWe demonstrate the advantages of our approach in minimality and\ncomprehensibility across multiple image classification models and datasets and\nprovide insights into how our CoLa-DCE explanations help comprehend model\nerrors like misclassification cases.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ME"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01649v1",
    "published_date": "2024-06-03 14:27:46 UTC",
    "updated_date": "2024-06-03 14:27:46 UTC"
  },
  {
    "arxiv_id": "2406.01648v1",
    "title": "Consciousness defined: requirements for biological and artificial general intelligence",
    "authors": [
      "Craig I. McKenzie"
    ],
    "abstract": "Consciousness is notoriously hard to define with objective terms. An\nobjective definition of consciousness is critically needed so that we might\naccurately understand how consciousness and resultant choice behaviour may\narise in biological or artificial systems. Many theories have integrated\nneurobiological and psychological research to explain how consciousness might\narise, but few, if any, outline what is fundamentally required to generate\nconsciousness. To identify such requirements, I examine current theories of\nconsciousness and corresponding scientific research to generate a new\ndefinition of consciousness from first principles. Critically, consciousness is\nthe apparatus that provides the ability to make decisions, but it is not\ndefined by the decision itself. As such, a definition of consciousness does not\nrequire choice behaviour or an explicit awareness of temporality despite both\nbeing well-characterised outcomes of conscious thought. Rather, requirements\nfor consciousness include: at least some capability for perception, a memory\nfor the storage of such perceptual information which in turn provides a\nframework for an imagination with which a sense of self can be capable of\nmaking decisions based on possible and desired futures. Thought experiments and\nobservable neurological phenomena demonstrate that these components are\nfundamentally required of consciousness, whereby the loss of any one component\nremoves the capability for conscious thought. Identifying these requirements\nprovides a new definition for consciousness by which we can objectively\ndetermine consciousness in any conceivable agent, such as non-human animals and\nartificially intelligent systems.",
    "categories": [
      "q-bio.NC",
      "cs.AI"
    ],
    "primary_category": "q-bio.NC",
    "comment": "16 pages, 1 figure, 2 tables, 74 references",
    "pdf_url": "http://arxiv.org/pdf/2406.01648v1",
    "published_date": "2024-06-03 14:20:56 UTC",
    "updated_date": "2024-06-03 14:20:56 UTC"
  },
  {
    "arxiv_id": "2406.01355v1",
    "title": "Differentially Private Fine-Tuning of Diffusion Models",
    "authors": [
      "Yu-Lin Tsai",
      "Yizhe Li",
      "Zekai Chen",
      "Po-Yu Chen",
      "Chia-Mu Yu",
      "Xuebin Ren",
      "Francois Buet-Golfouse"
    ],
    "abstract": "The integration of Differential Privacy (DP) with diffusion models (DMs)\npresents a promising yet challenging frontier, particularly due to the\nsubstantial memorization capabilities of DMs that pose significant privacy\nrisks. Differential privacy offers a rigorous framework for safeguarding\nindividual data points during model training, with Differential Privacy\nStochastic Gradient Descent (DP-SGD) being a prominent implementation.\nDiffusion method decomposes image generation into iterative steps,\ntheoretically aligning well with DP's incremental noise addition. Despite the\nnatural fit, the unique architecture of DMs necessitates tailored approaches to\neffectively balance privacy-utility trade-off. Recent developments in this\nfield have highlighted the potential for generating high-quality synthetic data\nby pre-training on public data (i.e., ImageNet) and fine-tuning on private\ndata, however, there is a pronounced gap in research on optimizing the\ntrade-offs involved in DP settings, particularly concerning parameter\nefficiency and model scalability. Our work addresses this by proposing a\nparameter-efficient fine-tuning strategy optimized for private diffusion\nmodels, which minimizes the number of trainable parameters to enhance the\nprivacy-utility trade-off. We empirically demonstrate that our method achieves\nstate-of-the-art performance in DP synthesis, significantly surpassing previous\nbenchmarks on widely studied datasets (e.g., with only 0.47M trainable\nparameters, achieving a more than 35% improvement over the previous\nstate-of-the-art with a small privacy budget on the CelebA-64 dataset).\nAnonymous codes available at https://anonymous.4open.science/r/DP-LORA-F02F.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CV",
    "comment": "16 pages, 5 figures, 11 tables",
    "pdf_url": "http://arxiv.org/pdf/2406.01355v1",
    "published_date": "2024-06-03 14:18:04 UTC",
    "updated_date": "2024-06-03 14:18:04 UTC"
  },
  {
    "arxiv_id": "2406.01352v2",
    "title": "Position: An Inner Interpretability Framework for AI Inspired by Lessons from Cognitive Neuroscience",
    "authors": [
      "Martina G. Vilas",
      "Federico Adolfi",
      "David Poeppel",
      "Gemma Roig"
    ],
    "abstract": "Inner Interpretability is a promising emerging field tasked with uncovering\nthe inner mechanisms of AI systems, though how to develop these mechanistic\ntheories is still much debated. Moreover, recent critiques raise issues that\nquestion its usefulness to advance the broader goals of AI. However, it has\nbeen overlooked that these issues resemble those that have been grappled with\nin another field: Cognitive Neuroscience. Here we draw the relevant connections\nand highlight lessons that can be transferred productively between fields.\nBased on these, we propose a general conceptual framework and give concrete\nmethodological strategies for building mechanistic explanations in AI inner\ninterpretability research. With this conceptual framework, Inner\nInterpretability can fend off critiques and position itself on a productive\npath to explain AI systems.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "q-bio.NC"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.01352v2",
    "published_date": "2024-06-03 14:16:56 UTC",
    "updated_date": "2024-07-31 13:18:13 UTC"
  },
  {
    "arxiv_id": "2406.01333v1",
    "title": "Probing Language Models for Pre-training Data Detection",
    "authors": [
      "Zhenhua Liu",
      "Tong Zhu",
      "Chuanyuan Tan",
      "Haonan Lu",
      "Bing Liu",
      "Wenliang Chen"
    ],
    "abstract": "Large Language Models (LLMs) have shown their impressive capabilities, while\nalso raising concerns about the data contamination problems due to privacy\nissues and leakage of benchmark datasets in the pre-training phase. Therefore,\nit is vital to detect the contamination by checking whether an LLM has been\npre-trained on the target texts. Recent studies focus on the generated texts\nand compute perplexities, which are superficial features and not reliable. In\nthis study, we propose to utilize the probing technique for pre-training data\ndetection by examining the model's internal activations. Our method is simple\nand effective and leads to more trustworthy pre-training data detection.\nAdditionally, we propose ArxivMIA, a new challenging benchmark comprising arxiv\nabstracts from Computer Science and Mathematics categories. Our experiments\ndemonstrate that our method outperforms all baselines, and achieves\nstate-of-the-art performance on both WikiMIA and ArxivMIA, with additional\nexperiments confirming its efficacy (Our code and dataset are available at\nhttps://github.com/zhliu0106/probing-lm-data).",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by ACL-2024 main conference",
    "pdf_url": "http://arxiv.org/pdf/2406.01333v1",
    "published_date": "2024-06-03 13:58:04 UTC",
    "updated_date": "2024-06-03 13:58:04 UTC"
  },
  {
    "arxiv_id": "2406.01329v1",
    "title": "Transferring Domain Knowledge with (X)AI-Based Learning Systems",
    "authors": [
      "Philipp Spitzer",
      "Niklas Kühl",
      "Marc Goutier",
      "Manuel Kaschura",
      "Gerhard Satzger"
    ],
    "abstract": "In numerous high-stakes domains, training novices via conventional learning\nsystems does not suffice. To impart tacit knowledge, experts' hands-on guidance\nis imperative. However, training novices by experts is costly and\ntime-consuming, increasing the need for alternatives. Explainable artificial\nintelligence (XAI) has conventionally been used to make black-box artificial\nintelligence systems interpretable. In this work, we utilize XAI as an\nalternative: An (X)AI system is trained on experts' past decisions and is then\nemployed to teach novices by providing examples coupled with explanations. In a\nstudy with 249 participants, we measure the effectiveness of such an approach\nfor a classification task. We show that (X)AI-based learning systems are able\nto induce learning in novices and that their cognitive styles moderate\nlearning. Thus, we take the first steps to reveal the impact of XAI on human\nlearning and point AI developers to future options to tailor the design of\n(X)AI-based learning systems.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Thirty-Second European Conference on Information Systems (ECIS 2024),\n  Paphos, Cyprus",
    "pdf_url": "http://arxiv.org/pdf/2406.01329v1",
    "published_date": "2024-06-03 13:56:30 UTC",
    "updated_date": "2024-06-03 13:56:30 UTC"
  },
  {
    "arxiv_id": "2406.01321v1",
    "title": "Sequence-to-Sequence Multi-Modal Speech In-Painting",
    "authors": [
      "Mahsa Kadkhodaei Elyaderani",
      "Shahram Shirani"
    ],
    "abstract": "Speech in-painting is the task of regenerating missing audio contents using\nreliable context information. Despite various recent studies in multi-modal\nperception of audio in-painting, there is still a need for an effective\ninfusion of visual and auditory information in speech in-painting. In this\npaper, we introduce a novel sequence-to-sequence model that leverages the\nvisual information to in-paint audio signals via an encoder-decoder\narchitecture. The encoder plays the role of a lip-reader for facial recordings\nand the decoder takes both encoder outputs as well as the distorted audio\nspectrograms to restore the original speech. Our model outperforms an\naudio-only speech in-painting model and has comparable results with a recent\nmulti-modal speech in-painter in terms of speech quality and intelligibility\nmetrics for distortions of 300 ms to 1500 ms duration, which proves the\neffectiveness of the introduced multi-modality in speech in-painting.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01321v1",
    "published_date": "2024-06-03 13:42:10 UTC",
    "updated_date": "2024-06-03 13:42:10 UTC"
  },
  {
    "arxiv_id": "2406.01317v3",
    "title": "The Intelligible and Effective Graph Neural Additive Networks",
    "authors": [
      "Maya Bechler-Speicher",
      "Amir Globerson",
      "Ran Gilad-Bachrach"
    ],
    "abstract": "Graph Neural Networks (GNNs) have emerged as the predominant approach for\nlearning over graph-structured data. However, most GNNs operate as black-box\nmodels and require post-hoc explanations, which may not suffice in high-stakes\nscenarios where transparency is crucial. In this paper, we present a GNN that\nis interpretable by design. Our model, Graph Neural Additive Network (GNAN), is\na novel extension of the interpretable class of Generalized Additive Models,\nand can be visualized and fully understood by humans. GNAN is designed to be\nfully interpretable, offering both global and local explanations at the feature\nand graph levels through direct visualization of the model. These\nvisualizations describe exactly how the model uses the relationships between\nthe target variable, the features, and the graph. We demonstrate the\nintelligibility of GNANs in a series of examples on different tasks and\ndatasets. In addition, we show that the accuracy of GNAN is on par with\nblack-box GNNs, making it suitable for critical applications where transparency\nis essential, alongside high accuracy.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01317v3",
    "published_date": "2024-06-03 13:29:36 UTC",
    "updated_date": "2024-12-06 18:25:17 UTC"
  },
  {
    "arxiv_id": "2406.06567v2",
    "title": "DHA: Learning Decoupled-Head Attention from Transformer Checkpoints via Adaptive Heads Fusion",
    "authors": [
      "Yilong Chen",
      "Linhao Zhang",
      "Junyuan Shang",
      "Zhenyu Zhang",
      "Tingwen Liu",
      "Shuohuan Wang",
      "Yu Sun"
    ],
    "abstract": "Large language models (LLMs) with billions of parameters demonstrate\nimpressive performance. However, the widely used Multi-Head Attention (MHA) in\nLLMs incurs substantial computational and memory costs during inference. While\nsome efforts have optimized attention mechanisms by pruning heads or sharing\nparameters among heads, these methods often lead to performance degradation or\nnecessitate substantial continued pre-training costs to restore performance.\nBased on the analysis of attention redundancy, we design a Decoupled-Head\nAttention (DHA) mechanism. DHA adaptively configures group sharing for key\nheads and value heads across various layers, achieving a better balance between\nperformance and efficiency. Inspired by the observation of clustering similar\nheads, we propose to progressively transform the MHA checkpoint into the DHA\nmodel through linear fusion of similar head parameters step by step, retaining\nthe parametric knowledge of the MHA checkpoint. We construct DHA models by\ntransforming various scales of MHA checkpoints given target head budgets. Our\nexperiments show that DHA remarkably requires a mere 0.25\\% of the original\nmodel's pre-training budgets to achieve 97.6\\% of performance while saving 75\\%\nof KV cache. Compared to Group-Query Attention (GQA), DHA achieves a 5$\\times$\ntraining acceleration, a maximum of 13.93\\% performance improvement under\n0.01\\% pre-training budget, and 4\\% relative improvement under 0.05\\%\npre-training budget.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at NeurIPS 2024 10 pages, 9 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2406.06567v2",
    "published_date": "2024-06-03 13:28:43 UTC",
    "updated_date": "2024-12-07 13:23:39 UTC"
  },
  {
    "arxiv_id": "2406.01316v2",
    "title": "Enhancing Inertial Hand based HAR through Joint Representation of Language, Pose and Synthetic IMUs",
    "authors": [
      "Vitor Fortes Rey",
      "Lala Shakti Swarup Ray",
      "Xia Qingxin",
      "Kaishun Wu",
      "Paul Lukowicz"
    ],
    "abstract": "Due to the scarcity of labeled sensor data in HAR, prior research has turned\nto video data to synthesize Inertial Measurement Units (IMU) data, capitalizing\non its rich activity annotations. However, generating IMU data from videos\npresents challenges for HAR in real-world settings, attributed to the poor\nquality of synthetic IMU data and its limited efficacy in subtle, fine-grained\nmotions. In this paper, we propose Multi$^3$Net, our novel multi-modal,\nmultitask, and contrastive-based framework approach to address the issue of\nlimited data. Our pretraining procedure uses videos from online repositories,\naiming to learn joint representations of text, pose, and IMU simultaneously. By\nemploying video data and contrastive learning, our method seeks to enhance\nwearable HAR performance, especially in recognizing subtle activities.Our\nexperimental findings validate the effectiveness of our approach in improving\nHAR performance with IMU data. We demonstrate that models trained with\nsynthetic IMU data generated from videos using our method surpass existing\napproaches in recognizing fine-grained activities.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "ISWC 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.01316v2",
    "published_date": "2024-06-03 13:28:42 UTC",
    "updated_date": "2024-07-27 13:08:43 UTC"
  },
  {
    "arxiv_id": "2406.01314v1",
    "title": "Compute-Efficient Medical Image Classification with Softmax-Free Transformers and Sequence Normalization",
    "authors": [
      "Firas Khader",
      "Omar S. M. El Nahhas",
      "Tianyu Han",
      "Gustav Müller-Franzes",
      "Sven Nebelung",
      "Jakob Nikolas Kather",
      "Daniel Truhn"
    ],
    "abstract": "The Transformer model has been pivotal in advancing fields such as natural\nlanguage processing, speech recognition, and computer vision. However, a\ncritical limitation of this model is its quadratic computational and memory\ncomplexity relative to the sequence length, which constrains its application to\nlonger sequences. This is especially crucial in medical imaging where\nhigh-resolution images can reach gigapixel scale. Efforts to address this issue\nhave predominantely focused on complex techniques, such as decomposing the\nsoftmax operation integral to the Transformer's architecture. This paper\naddresses this quadratic computational complexity of Transformer models and\nintroduces a remarkably simple and effective method that circumvents this issue\nby eliminating the softmax function from the attention mechanism and adopting a\nsequence normalization technique for the key, query, and value tokens. Coupled\nwith a reordering of matrix multiplications this approach reduces the memory-\nand compute complexity to a linear scale. We evaluate this approach across\nvarious medical imaging datasets comprising fundoscopic, dermascopic,\nradiologic and histologic imaging data. Our findings highlight that these\nmodels exhibit a comparable performance to traditional transformer models,\nwhile efficiently handling longer sequences.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01314v1",
    "published_date": "2024-06-03 13:27:08 UTC",
    "updated_date": "2024-06-03 13:27:08 UTC"
  },
  {
    "arxiv_id": "2406.01309v3",
    "title": "REvolve: Reward Evolution with Large Language Models using Human Feedback",
    "authors": [
      "Rishi Hazra",
      "Alkis Sygkounas",
      "Andreas Persson",
      "Amy Loutfi",
      "Pedro Zuidberg Dos Martires"
    ],
    "abstract": "Designing effective reward functions is crucial to training reinforcement\nlearning (RL) algorithms. However, this design is non-trivial, even for domain\nexperts, due to the subjective nature of certain tasks that are hard to\nquantify explicitly. In recent works, large language models (LLMs) have been\nused for reward generation from natural language task descriptions, leveraging\ntheir extensive instruction tuning and commonsense understanding of human\nbehavior. In this work, we hypothesize that LLMs, guided by human feedback, can\nbe used to formulate reward functions that reflect human implicit knowledge. We\nstudy this in three challenging settings -- autonomous driving, humanoid\nlocomotion, and dexterous manipulation -- wherein notions of ``good\" behavior\nare tacit and hard to quantify. To this end, we introduce REvolve, a truly\nevolutionary framework that uses LLMs for reward design in RL. REvolve\ngenerates and refines reward functions by utilizing human feedback to guide the\nevolution process, effectively translating implicit human knowledge into\nexplicit reward functions for training (deep) RL agents. Experimentally, we\ndemonstrate that agents trained on REvolve-designed rewards outperform other\nstate-of-the-art baselines.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "Published in ICLR 2025. Project page:\n  https://rishihazra.github.io/REvolve",
    "pdf_url": "http://arxiv.org/pdf/2406.01309v3",
    "published_date": "2024-06-03 13:23:27 UTC",
    "updated_date": "2025-04-06 20:42:37 UTC"
  },
  {
    "arxiv_id": "2406.01304v3",
    "title": "CodeR: Issue Resolving with Multi-Agent and Task Graphs",
    "authors": [
      "Dong Chen",
      "Shaoxin Lin",
      "Muhan Zeng",
      "Daoguang Zan",
      "Jian-Gang Wang",
      "Anton Cheshkov",
      "Jun Sun",
      "Hao Yu",
      "Guoliang Dong",
      "Artem Aliev",
      "Jie Wang",
      "Xiao Cheng",
      "Guangtai Liang",
      "Yuchi Ma",
      "Pan Bian",
      "Tao Xie",
      "Qianxiang Wang"
    ],
    "abstract": "GitHub issue resolving recently has attracted significant attention from\nacademia and industry. SWE-bench is proposed to measure the performance in\nresolving issues. In this paper, we propose CodeR, which adopts a multi-agent\nframework and pre-defined task graphs to Repair & Resolve reported bugs and add\nnew features within code Repository. On SWE-bench lite, CodeR is able to solve\n28.33% of issues, when submitting only once for each issue. We examine the\nperformance impact of each design of CodeR and offer insights to advance this\nresearch direction.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CL",
    "comment": "https://github.com/NL2Code/CodeR",
    "pdf_url": "http://arxiv.org/pdf/2406.01304v3",
    "published_date": "2024-06-03 13:13:35 UTC",
    "updated_date": "2024-06-11 03:52:03 UTC"
  },
  {
    "arxiv_id": "2406.01288v2",
    "title": "Improved Few-Shot Jailbreaking Can Circumvent Aligned Language Models and Their Defenses",
    "authors": [
      "Xiaosen Zheng",
      "Tianyu Pang",
      "Chao Du",
      "Qian Liu",
      "Jing Jiang",
      "Min Lin"
    ],
    "abstract": "Recently, Anil et al. (2024) show that many-shot (up to hundreds of)\ndemonstrations can jailbreak state-of-the-art LLMs by exploiting their\nlong-context capability. Nevertheless, is it possible to use few-shot\ndemonstrations to efficiently jailbreak LLMs within limited context sizes?\nWhile the vanilla few-shot jailbreaking may be inefficient, we propose improved\ntechniques such as injecting special system tokens like [/INST] and employing\ndemo-level random search from a collected demo pool. These simple techniques\nresult in surprisingly effective jailbreaking against aligned LLMs (even with\nadvanced defenses). For examples, our method achieves >80% (mostly >95%) ASRs\non Llama-2-7B and Llama-3-8B without multiple restarts, even if the models are\nenhanced by strong defenses such as perplexity detection and/or SmoothLLM,\nwhich is challenging for suffix-based jailbreaking. In addition, we conduct\ncomprehensive and elaborate (e.g., making sure to use correct system prompts)\nevaluations against other aligned LLMs and advanced defenses, where our method\nconsistently achieves nearly 100% ASRs. Our code is available at\nhttps://github.com/sail-sg/I-FSJ.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.01288v2",
    "published_date": "2024-06-03 12:59:17 UTC",
    "updated_date": "2024-10-30 12:08:42 UTC"
  },
  {
    "arxiv_id": "2406.01647v2",
    "title": "An Analysis under a Unified Fomulation of Learning Algorithms with Output Constraints",
    "authors": [
      "Mooho Song",
      "Jay-Yoon Lee"
    ],
    "abstract": "Neural networks (NN) perform well in diverse tasks, but sometimes produce\nnonsensical results to humans. Most NN models \"solely\" learn from (input,\noutput) pairs, occasionally conflicting with human knowledge. Many studies\nindicate injecting human knowledge by reducing output constraints during\ntraining can improve model performance and reduce constraint violations. While\nthere have been several attempts to compare different existing algorithms under\nthe same programming framework, nonetheless, there has been no previous work\nthat categorizes learning algorithms with output constraints in a unified\nmanner. Our contributions are as follows: (1) We categorize the previous\nstudies based on three axes: type of constraint loss used (e.g. probabilistic\nsoft logic, REINFORCE), exploration strategy of constraint-violating examples,\nand integration mechanism of learning signals from main task and constraint.\n(2) We propose new algorithms to integrate the information of main task and\nconstraint injection, inspired by continual-learning algorithms. (3)\nFurthermore, we propose the $H\\beta$-score as a metric for considering the main\ntask metric and constraint violation simultaneously. To provide a thorough\nanalysis, we examine all the algorithms on three NLP tasks: natural language\ninference (NLI), synthetic transduction examples (STE), and semantic role\nlabeling (SRL). We explore and reveal the key factors of various algorithms\nassociated with achieving high $H\\beta$-scores.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01647v2",
    "published_date": "2024-06-03 12:58:29 UTC",
    "updated_date": "2024-08-21 11:55:22 UTC"
  },
  {
    "arxiv_id": "2406.01285v1",
    "title": "Large Language Models as Recommender Systems: A Study of Popularity Bias",
    "authors": [
      "Jan Malte Lichtenberg",
      "Alexander Buchholz",
      "Pola Schwöbel"
    ],
    "abstract": "The issue of popularity bias -- where popular items are disproportionately\nrecommended, overshadowing less popular but potentially relevant items --\nremains a significant challenge in recommender systems. Recent advancements\nhave seen the integration of general-purpose Large Language Models (LLMs) into\nthe architecture of such systems. This integration raises concerns that it\nmight exacerbate popularity bias, given that the LLM's training data is likely\ndominated by popular items. However, it simultaneously presents a novel\nopportunity to address the bias via prompt tuning. Our study explores this\ndichotomy, examining whether LLMs contribute to or can alleviate popularity\nbias in recommender systems. We introduce a principled way to measure\npopularity bias by discussing existing metrics and proposing a novel metric\nthat fulfills a series of desiderata. Based on our new metric, we compare a\nsimple LLM-based recommender to traditional recommender systems on a movie\nrecommendation task. We find that the LLM recommender exhibits less popularity\nbias, even without any explicit mitigation.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted at Gen-IR@SIGIR24 workshop",
    "pdf_url": "http://arxiv.org/pdf/2406.01285v1",
    "published_date": "2024-06-03 12:53:37 UTC",
    "updated_date": "2024-06-03 12:53:37 UTC"
  },
  {
    "arxiv_id": "2406.01283v1",
    "title": "Focus on the Core: Efficient Attention via Pruned Token Compression for Document Classification",
    "authors": [
      "Jungmin Yun",
      "Mihyeon Kim",
      "Youngbin Kim"
    ],
    "abstract": "Transformer-based models have achieved dominant performance in numerous NLP\ntasks. Despite their remarkable successes, pre-trained transformers such as\nBERT suffer from a computationally expensive self-attention mechanism that\ninteracts with all tokens, including the ones unfavorable to classification\nperformance. To overcome these challenges, we propose integrating two\nstrategies: token pruning and token combining. Token pruning eliminates less\nimportant tokens in the attention mechanism's key and value as they pass\nthrough the layers. Additionally, we adopt fuzzy logic to handle uncertainty\nand alleviate potential mispruning risks arising from an imbalanced\ndistribution of each token's importance. Token combining, on the other hand,\ncondenses input sequences into smaller sizes in order to further compress the\nmodel. By integrating these two approaches, we not only improve the model's\nperformance but also reduce its computational demands. Experiments with various\ndatasets demonstrate superior performance compared to baseline models,\nespecially with the best improvement over the existing BERT model, achieving\n+5%p in accuracy and +5.6%p in F1 score. Additionally, memory cost is reduced\nto 0.61x, and a speedup of 1.64x is achieved.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to EMNLP 2023 Findings",
    "pdf_url": "http://arxiv.org/pdf/2406.01283v1",
    "published_date": "2024-06-03 12:51:52 UTC",
    "updated_date": "2024-06-03 12:51:52 UTC"
  },
  {
    "arxiv_id": "2406.01278v1",
    "title": "fruit-SALAD: A Style Aligned Artwork Dataset to reveal similarity perception in image embeddings",
    "authors": [
      "Tillmann Ohm",
      "Andres Karjus",
      "Mikhail Tamm",
      "Maximilian Schich"
    ],
    "abstract": "The notion of visual similarity is essential for computer vision, and in\napplications and studies revolving around vector embeddings of images. However,\nthe scarcity of benchmark datasets poses a significant hurdle in exploring how\nthese models perceive similarity. Here we introduce Style Aligned Artwork\nDatasets (SALADs), and an example of fruit-SALAD with 10,000 images of fruit\ndepictions. This combined semantic category and style benchmark comprises 100\ninstances each of 10 easy-to-recognize fruit categories, across 10 easy\ndistinguishable styles. Leveraging a systematic pipeline of generative image\nsynthesis, this visually diverse yet balanced benchmark demonstrates salient\ndifferences in semantic category and style similarity weights across various\ncomputational models, including machine learning models, feature extraction\nalgorithms, and complexity measures, as well as conceptual models for\nreference. This meticulously designed dataset offers a controlled and balanced\nplatform for the comparative analysis of similarity perception. The SALAD\nframework allows the comparison of how these models perform semantic category\nand style recognition task to go beyond the level of anecdotal knowledge,\nmaking it robustly quantifiable and qualitatively interpretable.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CC",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01278v1",
    "published_date": "2024-06-03 12:47:48 UTC",
    "updated_date": "2024-06-03 12:47:48 UTC"
  },
  {
    "arxiv_id": "2406.01275v1",
    "title": "Lifting Factor Graphs with Some Unknown Factors",
    "authors": [
      "Malte Luttermann",
      "Ralf Möller",
      "Marcel Gehrke"
    ],
    "abstract": "Lifting exploits symmetries in probabilistic graphical models by using a\nrepresentative for indistinguishable objects, allowing to carry out query\nanswering more efficiently while maintaining exact answers. In this paper, we\ninvestigate how lifting enables us to perform probabilistic inference for\nfactor graphs containing factors whose potentials are unknown. We introduce the\nLifting Factor Graphs with Some Unknown Factors (LIFAGU) algorithm to identify\nsymmetric subgraphs in a factor graph containing unknown factors, thereby\nenabling the transfer of known potentials to unknown potentials to ensure a\nwell-defined semantics and allow for (lifted) probabilistic inference.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to the Proceedings of the 17th European Conference on\n  Symbolic and Quantitative Approaches to Reasoning with Uncertainty\n  (ECSQARU-23)",
    "pdf_url": "http://arxiv.org/pdf/2406.01275v1",
    "published_date": "2024-06-03 12:44:55 UTC",
    "updated_date": "2024-06-03 12:44:55 UTC"
  },
  {
    "arxiv_id": "2406.01646v1",
    "title": "iKAN: Global Incremental Learning with KAN for Human Activity Recognition Across Heterogeneous Datasets",
    "authors": [
      "Mengxi Liu",
      "Sizhen Bian",
      "Bo Zhou",
      "Paul Lukowicz"
    ],
    "abstract": "This work proposes an incremental learning (IL) framework for wearable sensor\nhuman activity recognition (HAR) that tackles two challenges simultaneously:\ncatastrophic forgetting and non-uniform inputs. The scalable framework, iKAN,\npioneers IL with Kolmogorov-Arnold Networks (KAN) to replace multi-layer\nperceptrons as the classifier that leverages the local plasticity and global\nstability of splines. To adapt KAN for HAR, iKAN uses task-specific feature\nbranches and a feature redistribution layer. Unlike existing IL methods that\nprimarily adjust the output dimension or the number of classifier nodes to\nadapt to new tasks, iKAN focuses on expanding the feature extraction branches\nto accommodate new inputs from different sensor modalities while maintaining\nconsistent dimensions and the number of classifier outputs. Continual learning\nacross six public HAR datasets demonstrated the iKAN framework's incremental\nlearning performance, with a last performance of 84.9\\% (weighted F1 score) and\nan average incremental performance of 81.34\\%, which significantly outperforms\nthe two existing incremental learning methods, such as EWC (51.42\\%) and\nexperience replay (59.92\\%).",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "This work is submitted to Ubicomp/ISWC24 and is under review",
    "pdf_url": "http://arxiv.org/pdf/2406.01646v1",
    "published_date": "2024-06-03 12:33:27 UTC",
    "updated_date": "2024-06-03 12:33:27 UTC"
  },
  {
    "arxiv_id": "2406.01645v1",
    "title": "FNP: Fourier Neural Processes for Arbitrary-Resolution Data Assimilation",
    "authors": [
      "Kun Chen",
      "Tao Chen",
      "Peng Ye",
      "Hao Chen",
      "Kang Chen",
      "Tao Han",
      "Wanli Ouyang",
      "Lei Bai"
    ],
    "abstract": "Data assimilation is a vital component in modern global medium-range weather\nforecasting systems to obtain the best estimation of the atmospheric state by\ncombining the short-term forecast and observations. Recently, AI-based data\nassimilation approaches have attracted increasing attention for their\nsignificant advantages over traditional techniques in terms of computational\nconsumption. However, existing AI-based data assimilation methods can only\nhandle observations with a specific resolution, lacking the compatibility and\ngeneralization ability to assimilate observations with other resolutions.\nConsidering that complex real-world observations often have different\nresolutions, we propose the \\textit{\\textbf{Fourier Neural Processes}} (FNP)\nfor \\textit{arbitrary-resolution data assimilation} in this paper. Leveraging\nthe efficiency of the designed modules and flexible structure of neural\nprocesses, FNP achieves state-of-the-art results in assimilating observations\nwith varying resolutions, and also exhibits increasing advantages over the\ncounterparts as the resolution and the amount of observations increase.\nMoreover, our FNP trained on a fixed resolution can directly handle the\nassimilation of observations with out-of-distribution resolutions and the\nobservational information reconstruction task without additional fine-tuning,\ndemonstrating its excellent generalization ability across data resolutions as\nwell as across tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01645v1",
    "published_date": "2024-06-03 12:24:24 UTC",
    "updated_date": "2024-06-03 12:24:24 UTC"
  },
  {
    "arxiv_id": "2406.01256v1",
    "title": "Augmented Commonsense Knowledge for Remote Object Grounding",
    "authors": [
      "Bahram Mohammadi",
      "Yicong Hong",
      "Yuankai Qi",
      "Qi Wu",
      "Shirui Pan",
      "Javen Qinfeng Shi"
    ],
    "abstract": "The vision-and-language navigation (VLN) task necessitates an agent to\nperceive the surroundings, follow natural language instructions, and act in\nphoto-realistic unseen environments. Most of the existing methods employ the\nentire image or object features to represent navigable viewpoints. However,\nthese representations are insufficient for proper action prediction, especially\nfor the REVERIE task, which uses concise high-level instructions, such as\n''Bring me the blue cushion in the master bedroom''. To address enhancing\nrepresentation, we propose an augmented commonsense knowledge model (ACK) to\nleverage commonsense information as a spatio-temporal knowledge graph for\nimproving agent navigation. Specifically, the proposed approach involves\nconstructing a knowledge base by retrieving commonsense information from\nConceptNet, followed by a refinement module to remove noisy and irrelevant\nknowledge. We further present ACK which consists of knowledge graph-aware\ncross-modal and concept aggregation modules to enhance visual representation\nand visual-textual data alignment by integrating visible objects, commonsense\nknowledge, and concept history, which includes object and knowledge temporal\ninformation. Moreover, we add a new pipeline for the commonsense-based\ndecision-making process which leads to more accurate local action prediction.\nExperimental results demonstrate our proposed model noticeably outperforms the\nbaseline and archives the state-of-the-art on the REVERIE benchmark.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01256v1",
    "published_date": "2024-06-03 12:12:33 UTC",
    "updated_date": "2024-06-03 12:12:33 UTC"
  },
  {
    "arxiv_id": "2406.01255v1",
    "title": "On the Nonlinearity of Layer Normalization",
    "authors": [
      "Yunhao Ni",
      "Yuxin Guo",
      "Junlong Jia",
      "Lei Huang"
    ],
    "abstract": "Layer normalization (LN) is a ubiquitous technique in deep learning but our\ntheoretical understanding to it remains elusive. This paper investigates a new\ntheoretical direction for LN, regarding to its nonlinearity and representation\ncapacity. We investigate the representation capacity of a network with\nlayerwise composition of linear and LN transformations, referred to as LN-Net.\nWe theoretically show that, given $m$ samples with any label assignment, an\nLN-Net with only 3 neurons in each layer and $O(m)$ LN layers can correctly\nclassify them. We further show the lower bound of the VC dimension of an\nLN-Net. The nonlinearity of LN can be amplified by group partition, which is\nalso theoretically demonstrated with mild assumption and empirically supported\nby our experiments. Based on our analyses, we consider to design neural\narchitecture by exploiting and amplifying the nonlinearity of LN, and the\neffectiveness is supported by our experiments.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "42 pages, accepted to ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.01255v1",
    "published_date": "2024-06-03 12:11:34 UTC",
    "updated_date": "2024-06-03 12:11:34 UTC"
  },
  {
    "arxiv_id": "2406.01253v2",
    "title": "animal2vec and MeerKAT: A self-supervised transformer for rare-event raw audio input and a large-scale reference dataset for bioacoustics",
    "authors": [
      "Julian C. Schäfer-Zimmermann",
      "Vlad Demartsev",
      "Baptiste Averly",
      "Kiran Dhanjal-Adams",
      "Mathieu Duteil",
      "Gabriella Gall",
      "Marius Faiß",
      "Lily Johnson-Ulrich",
      "Dan Stowell",
      "Marta B. Manser",
      "Marie A. Roch",
      "Ariana Strandburg-Peshkin"
    ],
    "abstract": "Bioacoustic research, vital for understanding animal behavior, conservation,\nand ecology, faces a monumental challenge: analyzing vast datasets where animal\nvocalizations are rare. While deep learning techniques are becoming standard,\nadapting them to bioacoustics remains difficult. We address this with\nanimal2vec, an interpretable large transformer model, and a self-supervised\ntraining scheme tailored for sparse and unbalanced bioacoustic data. It learns\nfrom unlabeled audio and then refines its understanding with labeled data.\nFurthermore, we introduce and publicly release MeerKAT: Meerkat Kalahari Audio\nTranscripts, a dataset of meerkat (Suricata suricatta) vocalizations with\nmillisecond-resolution annotations, the largest labeled dataset on non-human\nterrestrial mammals currently available. Our model outperforms existing methods\non MeerKAT and the publicly available NIPS4Bplus birdsong dataset. Moreover,\nanimal2vec performs well even with limited labeled data (few-shot learning).\nanimal2vec and MeerKAT provide a new reference point for bioacoustic research,\nenabling scientists to analyze large amounts of data even with scarce ground\ntruth information.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS",
      "q-bio.QM",
      "stat.AP"
    ],
    "primary_category": "cs.SD",
    "comment": "Code available at: https://github.com/livingingroups/animal2vec |\n  Dataset available at: https://doi.org/10.17617/3.0J0DYB",
    "pdf_url": "http://arxiv.org/pdf/2406.01253v2",
    "published_date": "2024-06-03 12:11:01 UTC",
    "updated_date": "2024-07-26 07:39:30 UTC"
  },
  {
    "arxiv_id": "2406.01252v3",
    "title": "Towards Scalable Automated Alignment of LLMs: A Survey",
    "authors": [
      "Boxi Cao",
      "Keming Lu",
      "Xinyu Lu",
      "Jiawei Chen",
      "Mengjie Ren",
      "Hao Xiang",
      "Peilin Liu",
      "Yaojie Lu",
      "Ben He",
      "Xianpei Han",
      "Le Sun",
      "Hongyu Lin",
      "Bowen Yu"
    ],
    "abstract": "Alignment is the most critical step in building large language models (LLMs)\nthat meet human needs. With the rapid development of LLMs gradually surpassing\nhuman capabilities, traditional alignment methods based on human-annotation are\nincreasingly unable to meet the scalability demands. Therefore, there is an\nurgent need to explore new sources of automated alignment signals and technical\napproaches. In this paper, we systematically review the recently emerging\nmethods of automated alignment, attempting to explore how to achieve effective,\nscalable, automated alignment once the capabilities of LLMs exceed those of\nhumans. Specifically, we categorize existing automated alignment methods into 4\nmajor categories based on the sources of alignment signals and discuss the\ncurrent status and potential development of each category. Additionally, we\nexplore the underlying mechanisms that enable automated alignment and discuss\nthe essential factors that make automated alignment technologies feasible and\neffective from the fundamental role of alignment.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.CL",
    "comment": "Paper List: https://github.com/cascip/awesome-auto-alignment",
    "pdf_url": "http://arxiv.org/pdf/2406.01252v3",
    "published_date": "2024-06-03 12:10:26 UTC",
    "updated_date": "2024-09-03 07:07:59 UTC"
  },
  {
    "arxiv_id": "2406.01250v1",
    "title": "DumpKV: Learning based lifetime aware garbage collection for key value separation in LSM-tree",
    "authors": [
      "Zhutao Zhuang",
      "Xinqi Zeng",
      "Zhiguang Chen"
    ],
    "abstract": "Key\\-value separation is used in LSM\\-tree to stored large value in separate\nlog files to reduce write amplification, but requires garbage collection to\ngarbage collect invalid values. Existing garbage collection techniques in\nLSM\\-tree typically adopt static parameter based garbage collection to garbage\ncollect obsolete values which struggles to achieve low write amplification and\nit's challenging to find proper parameter for garbage collection triggering. In\nthis work we introduce DumpKV, which introduces learning based lifetime aware\ngarbage collection with dynamic lifetime adjustment to do efficient garbage\ncollection to achieve lower write amplification. DumpKV manages large values\nusing trained lightweight model with features suitable for various application\nbased on past write access information of keys to give lifetime prediction for\neach individual key to enable efficient garbage collection. To reduce\ninterference to write throughput DumpKV conducts feature collection during\nL0\\-L1 compaction leveraging the fact that LSM\\-tree is small under KV\nseparation. Experimental results show that DumpKV achieves lower write\namplification by 38\\%\\-73\\% compared to existing key\\-value separation garbage\ncollection LSM\\-tree stores with small feature storage overhead.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DB",
    "comment": "Hi",
    "pdf_url": "http://arxiv.org/pdf/2406.01250v1",
    "published_date": "2024-06-03 12:07:22 UTC",
    "updated_date": "2024-06-03 12:07:22 UTC"
  },
  {
    "arxiv_id": "2406.01213v1",
    "title": "Improving Pseudo Labels with Global-Local Denoising Framework for Cross-lingual Named Entity Recognition",
    "authors": [
      "Zhuojun Ding",
      "Wei Wei",
      "Xiaoye Qu",
      "Dangyang Chen"
    ],
    "abstract": "Cross-lingual named entity recognition (NER) aims to train an NER model for\nthe target language leveraging only labeled source language data and unlabeled\ntarget language data. Prior approaches either perform label projection on\ntranslated source language data or employ a source model to assign pseudo\nlabels for target language data and train a target model on these\npseudo-labeled data to generalize to the target language. However, these\nautomatic labeling procedures inevitably introduce noisy labels, thus leading\nto a performance drop. In this paper, we propose a Global-Local Denoising\nframework (GLoDe) for cross-lingual NER. Specifically, GLoDe introduces a\nprogressive denoising strategy to rectify incorrect pseudo labels by leveraging\nboth global and local distribution information in the semantic space. The\nrefined pseudo-labeled target language data significantly improves the model's\ngeneralization ability. Moreover, previous methods only consider improving the\nmodel with language-agnostic features, however, we argue that target\nlanguage-specific features are also important and should never be ignored. To\nthis end, we employ a simple auxiliary task to achieve this goal. Experimental\nresults on two benchmark datasets with six target languages demonstrate that\nour proposed GLoDe significantly outperforms current state-of-the-art methods.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by IJCAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.01213v1",
    "published_date": "2024-06-03 11:29:19 UTC",
    "updated_date": "2024-06-03 11:29:19 UTC"
  },
  {
    "arxiv_id": "2407.13960v1",
    "title": "Using Artificial Intelligence to Accelerate Collective Intelligence: Policy Synth and Smarter Crowdsourcing",
    "authors": [
      "Róbert Bjarnason",
      "Dane Gambrell",
      "Joshua Lanthier-Welch"
    ],
    "abstract": "In an era characterized by rapid societal changes and complex challenges,\ninstitutions' traditional methods of problem-solving in the public sector are\nincreasingly proving inadequate. In this study, we present an innovative and\neffective model for how institutions can use artificial intelligence to enable\ngroups of people to generate effective solutions to urgent problems more\nefficiently. We describe a proven collective intelligence method, called\nSmarter Crowdsourcing, which is designed to channel the collective intelligence\nof those with expertise about a problem into actionable solutions through\ncrowdsourcing. Then we introduce Policy Synth, an innovative toolkit which\nleverages AI to make the Smarter Crowdsourcing problem-solving approach both\nmore scalable, more effective and more efficient. Policy Synth is crafted using\na human-centric approach, recognizing that AI is a tool to enhance human\nintelligence and creativity, not replace it. Based on a real-world case study\ncomparing the results of expert crowdsourcing alone with expert sourcing\nsupported by Policy Synth AI agents, we conclude that Smarter Crowdsourcing\nwith Policy Synth presents an effective model for integrating the collective\nwisdom of human experts and the computational power of AI to enhance and scale\nup public problem-solving processes. While many existing approaches view AI as\na tool to make crowdsourcing and deliberative processes better and more\nefficient, Policy Synth goes a step further, recognizing that AI can also be\nused to synthesize the findings from engagements together with research to\ndevelop evidence-based solutions and policies. The study offers practical tools\nand insights for institutions looking to engage communities effectively in\naddressing urgent societal challenges.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "I.2; H.4; J.4"
    ],
    "primary_category": "cs.CY",
    "comment": "51 pages, 23 figures, Submitted for ACM Collective Intelligence\n  Conference 2024, Parallel Track Presentation, Boston, MA, USA",
    "pdf_url": "http://arxiv.org/pdf/2407.13960v1",
    "published_date": "2024-06-03 11:27:23 UTC",
    "updated_date": "2024-06-03 11:27:23 UTC"
  },
  {
    "arxiv_id": "2406.01203v1",
    "title": "Scaling Up Deep Clustering Methods Beyond ImageNet-1K",
    "authors": [
      "Nikolas Adaloglou",
      "Felix Michels",
      "Kaspar Senft",
      "Diana Petrusheva",
      "Markus Kollmann"
    ],
    "abstract": "Deep image clustering methods are typically evaluated on small-scale balanced\nclassification datasets while feature-based $k$-means has been applied on\nproprietary billion-scale datasets. In this work, we explore the performance of\nfeature-based deep clustering approaches on large-scale benchmarks whilst\ndisentangling the impact of the following data-related factors: i) class\nimbalance, ii) class granularity, iii) easy-to-recognize classes, and iv) the\nability to capture multiple classes. Consequently, we develop multiple new\nbenchmarks based on ImageNet21K. Our experimental analysis reveals that\nfeature-based $k$-means is often unfairly evaluated on balanced datasets.\nHowever, deep clustering methods outperform $k$-means across most large-scale\nbenchmarks. Interestingly, $k$-means underperforms on easy-to-classify\nbenchmarks by large margins. The performance gap, however, diminishes on the\nhighest data regimes such as ImageNet21K. Finally, we find that non-primary\ncluster predictions capture meaningful classes (i.e. coarser classes).",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Work in progress",
    "pdf_url": "http://arxiv.org/pdf/2406.01203v1",
    "published_date": "2024-06-03 11:13:27 UTC",
    "updated_date": "2024-06-03 11:13:27 UTC"
  },
  {
    "arxiv_id": "2406.01198v1",
    "title": "Automatic Essay Multi-dimensional Scoring with Fine-tuning and Multiple Regression",
    "authors": [
      "Kun Sun",
      "Rong Wang"
    ],
    "abstract": "Automated essay scoring (AES) involves predicting a score that reflects the\nwriting quality of an essay. Most existing AES systems produce only a single\noverall score. However, users and L2 learners expect scores across different\ndimensions (e.g., vocabulary, grammar, coherence) for English essays in\nreal-world applications. To address this need, we have developed two models\nthat automatically score English essays across multiple dimensions by employing\nfine-tuning and other strategies on two large datasets. The results demonstrate\nthat our systems achieve impressive performance in evaluation using three\ncriteria: precision, F1 score, and Quadratic Weighted Kappa. Furthermore, our\nsystem outperforms existing methods in overall scoring.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01198v1",
    "published_date": "2024-06-03 10:59:50 UTC",
    "updated_date": "2024-06-03 10:59:50 UTC"
  },
  {
    "arxiv_id": "2406.01196v1",
    "title": "3D WholeBody Pose Estimation based on Semantic Graph Attention Network and Distance Information",
    "authors": [
      "Sihan Wen",
      "Xiantan Zhu",
      "Zhiming Tan"
    ],
    "abstract": "In recent years, a plethora of diverse methods have been proposed for 3D pose\nestimation. Among these, self-attention mechanisms and graph convolutions have\nboth been proven to be effective and practical methods. Recognizing the\nstrengths of those two techniques, we have developed a novel Semantic Graph\nAttention Network which can benefit from the ability of self-attention to\ncapture global context, while also utilizing the graph convolutions to handle\nthe local connectivity and structural constraints of the skeleton. We also\ndesign a Body Part Decoder that assists in extracting and refining the\ninformation related to specific segments of the body. Furthermore, our approach\nincorporates Distance Information, enhancing our model's capability to\ncomprehend and accurately predict spatial relationships. Finally, we introduce\na Geometry Loss who makes a critical constraint on the structural skeleton of\nthe body, ensuring that the model's predictions adhere to the natural limits of\nhuman posture. The experimental results validate the effectiveness of our\napproach, demonstrating that every element within the system is essential for\nimproving pose estimation outcomes. With comparison to state-of-the-art, the\nproposed work not only meets but exceeds the existing benchmarks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01196v1",
    "published_date": "2024-06-03 10:59:00 UTC",
    "updated_date": "2024-06-03 10:59:00 UTC"
  },
  {
    "arxiv_id": "2406.01189v3",
    "title": "MultiMax: Sparse and Multi-Modal Attention Learning",
    "authors": [
      "Yuxuan Zhou",
      "Mario Fritz",
      "Margret Keuper"
    ],
    "abstract": "SoftMax is a ubiquitous ingredient of modern machine learning algorithms. It\nmaps an input vector onto a probability simplex and reweights the input by\nconcentrating the probability mass at large entries. Yet, as a smooth\napproximation to the Argmax function, a significant amount of probability mass\nis distributed to other, residual entries, leading to poor interpretability and\nnoise. Although sparsity can be achieved by a family of SoftMax variants, they\noften require an alternative loss function and do not preserve multi-modality.\nWe show that this trade-off between multi-modality and sparsity limits the\nexpressivity of SoftMax as well as its variants. We provide a solution to this\ntension between objectives by proposing a piece-wise differentiable function,\ntermed MultiMax, which adaptively modulates the output distribution according\nto input entry range. Through comprehensive analysis and evaluation, we show\nthat MultiMax successfully produces a distribution that supresses irrelevant\nentries while preserving multimodality, with benefits in image classification,\nlanguage modeling and machine translation. The code is available at\nhttps://github.com/ZhouYuxuanYX/MultiMax.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.01189v3",
    "published_date": "2024-06-03 10:51:43 UTC",
    "updated_date": "2025-01-08 07:59:53 UTC"
  },
  {
    "arxiv_id": "2406.01183v2",
    "title": "Automatic Input Feature Relevance via Spectral Neural Networks",
    "authors": [
      "Lorenzo Chicchi",
      "Lorenzo Buffoni",
      "Diego Febbe",
      "Lorenzo Giambagli",
      "Raffaele Marino",
      "Duccio Fanelli"
    ],
    "abstract": "In machine learning practice it is often useful to identify relevant input\nfeatures, so as to obtain compact dataset for more efficient numerical\nhandling. On the other hand, by isolating key input elements, ranked according\ntheir respective degree of relevance, can help to elaborate on the process of\ndecision making. Here, we propose a novel method to estimate the relative\nimportance of the input components for a Deep Neural Network. This is achieved\nby leveraging on a spectral re-parametrization of the optimization process.\nEigenvalues associated to input nodes provide in fact a robust proxy to gauge\nthe relevance of the supplied entry features. Notably, the spectral features\nranking is performed automatically, as a byproduct of the network training,\nwith no additional processing to be carried out. The technique is successfully\nchallenged against both synthetic and real data.",
    "categories": [
      "cs.LG",
      "cond-mat.dis-nn",
      "cond-mat.stat-mech",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01183v2",
    "published_date": "2024-06-03 10:39:12 UTC",
    "updated_date": "2025-05-05 07:48:02 UTC"
  },
  {
    "arxiv_id": "2406.01179v2",
    "title": "Are AI-Generated Text Detectors Robust to Adversarial Perturbations?",
    "authors": [
      "Guanhua Huang",
      "Yuchen Zhang",
      "Zhe Li",
      "Yongjian You",
      "Mingze Wang",
      "Zhouwang Yang"
    ],
    "abstract": "The widespread use of large language models (LLMs) has sparked concerns about\nthe potential misuse of AI-generated text, as these models can produce content\nthat closely resembles human-generated text. Current detectors for AI-generated\ntext (AIGT) lack robustness against adversarial perturbations, with even minor\nchanges in characters or words causing a reversal in distinguishing between\nhuman-created and AI-generated text. This paper investigates the robustness of\nexisting AIGT detection methods and introduces a novel detector, the Siamese\nCalibrated Reconstruction Network (SCRN). The SCRN employs a reconstruction\nnetwork to add and remove noise from text, extracting a semantic representation\nthat is robust to local perturbations. We also propose a siamese calibration\ntechnique to train the model to make equally confidence predictions under\ndifferent noise, which improves the model's robustness against adversarial\nperturbations. Experiments on four publicly available datasets show that the\nSCRN outperforms all baseline methods, achieving 6.5\\%-18.25\\% absolute\naccuracy improvement over the best baseline method under adversarial attacks.\nMoreover, it exhibits superior generalizability in cross-domain, cross-genre,\nand mixed-source scenarios. The code is available at\n\\url{https://github.com/CarlanLark/Robust-AIGC-Detector}.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ACL 2024 main conference",
    "pdf_url": "http://arxiv.org/pdf/2406.01179v2",
    "published_date": "2024-06-03 10:21:48 UTC",
    "updated_date": "2024-06-26 12:43:56 UTC"
  },
  {
    "arxiv_id": "2406.01168v2",
    "title": "How Ethical Should AI Be? How AI Alignment Shapes the Risk Preferences of LLMs",
    "authors": [
      "Shumiao Ouyang",
      "Hayong Yun",
      "Xingjian Zheng"
    ],
    "abstract": "This study examines the risk preferences of Large Language Models (LLMs) and\nhow aligning them with human ethical standards affects their economic\ndecision-making. Analyzing 30 LLMs reveals a range of inherent risk profiles,\nfrom risk-averse to risk-seeking. We find that aligning LLMs with human values,\nfocusing on harmlessness, helpfulness, and honesty, shifts them towards risk\naversion. While some alignment improves investment forecast accuracy, excessive\nalignment leads to overly cautious predictions, potentially resulting in severe\nunderinvestment. Our findings highlight the need for a nuanced approach that\nbalances ethical alignment with the specific requirements of economic domains\nwhen using LLMs in finance.",
    "categories": [
      "econ.GN",
      "cs.AI",
      "cs.CY",
      "cs.ET",
      "cs.HC",
      "q-fin.EC"
    ],
    "primary_category": "econ.GN",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01168v2",
    "published_date": "2024-06-03 10:05:25 UTC",
    "updated_date": "2024-08-01 21:28:48 UTC"
  },
  {
    "arxiv_id": "2406.01149v1",
    "title": "Agnostic Learning of Mixed Linear Regressions with EM and AM Algorithms",
    "authors": [
      "Avishek Ghosh",
      "Arya Mazumdar"
    ],
    "abstract": "Mixed linear regression is a well-studied problem in parametric statistics\nand machine learning. Given a set of samples, tuples of covariates and labels,\nthe task of mixed linear regression is to find a small list of linear\nrelationships that best fit the samples. Usually it is assumed that the label\nis generated stochastically by randomly selecting one of two or more linear\nfunctions, applying this chosen function to the covariates, and potentially\nintroducing noise to the result. In that situation, the objective is to\nestimate the ground-truth linear functions up to some parameter error. The\npopular expectation maximization (EM) and alternating minimization (AM)\nalgorithms have been previously analyzed for this.\n  In this paper, we consider the more general problem of agnostic learning of\nmixed linear regression from samples, without such generative models. In\nparticular, we show that the AM and EM algorithms, under standard conditions of\nseparability and good initialization, lead to agnostic learning in mixed linear\nregression by converging to the population loss minimizers, for suitably\ndefined loss functions. In some sense, this shows the strength of AM and EM\nalgorithms that converges to ``optimal solutions'' even in the absence of\nrealizable generative models.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.IT",
      "cs.LG",
      "math.IT"
    ],
    "primary_category": "stat.ML",
    "comment": "To appear in ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.01149v1",
    "published_date": "2024-06-03 09:43:24 UTC",
    "updated_date": "2024-06-03 09:43:24 UTC"
  },
  {
    "arxiv_id": "2406.02616v5",
    "title": "Adaptive Layer Splitting for Wireless LLM Inference in Edge Computing: A Model-Based Reinforcement Learning Approach",
    "authors": [
      "Yuxuan Chen",
      "Rongpeng Li",
      "Xiaoxue Yu",
      "Zhifeng Zhao",
      "Honggang Zhang"
    ],
    "abstract": "Optimizing the deployment of large language models (LLMs) in edge computing\nenvironments is critical for enhancing privacy and computational efficiency.\nToward efficient wireless LLM inference in edge computing, this study\ncomprehensively analyzes the impact of different splitting points in mainstream\nopen-source LLMs. On this basis, this study introduces a framework taking\ninspiration from model-based reinforcement learning (MBRL) to determine the\noptimal splitting point across the edge and user equipment (UE). By\nincorporating a reward surrogate model, our approach significantly reduces the\ncomputational cost of frequent performance evaluations. Extensive simulations\ndemonstrate that this method effectively balances inference performance and\ncomputational load under varying network conditions, providing a robust\nsolution for LLM deployment in decentralized settings.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02616v5",
    "published_date": "2024-06-03 09:41:42 UTC",
    "updated_date": "2024-09-11 11:59:25 UTC"
  },
  {
    "arxiv_id": "2406.01140v2",
    "title": "Logical Reasoning with Relation Network for Inductive Knowledge Graph Completion",
    "authors": [
      "Qinggang Zhang",
      "Keyu Duan",
      "Junnan Dong",
      "Pai Zheng",
      "Xiao Huang"
    ],
    "abstract": "Inductive knowledge graph completion (KGC) aims to infer the missing relation\nfor a set of newly-coming entities that never appeared in the training set.\nSuch a setting is more in line with reality, as real-world KGs are constantly\nevolving and introducing new knowledge. Recent studies have shown promising\nresults using message passing over subgraphs to embed newly-coming entities for\ninductive KGC. However, the inductive capability of these methods is usually\nlimited by two key issues. (i) KGC always suffers from data sparsity, and the\nsituation is even exacerbated in inductive KGC where new entities often have\nfew or no connections to the original KG. (ii) Cold-start problem. It is over\ncoarse-grained for accurate KG reasoning to generate representations for new\nentities by gathering the local information from few neighbors. To this end, we\npropose a novel iNfOmax RelAtion Network, namely NORAN, for inductive KG\ncompletion. It aims to mine latent relation patterns for inductive KG\ncompletion. Specifically, by centering on relations, NORAN provides a hyper\nview towards KG modeling, where the correlations between relations can be\nnaturally captured as entity-independent logical evidence to conduct inductive\nKGC. Extensive experiment results on five benchmarks show that our framework\nsubstantially outperforms the state-of-the-art KGC methods.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "30th SIGKDD Conference on Knowledge Discovery and Data Mining",
    "pdf_url": "http://arxiv.org/pdf/2406.01140v2",
    "published_date": "2024-06-03 09:30:43 UTC",
    "updated_date": "2024-07-22 02:42:42 UTC"
  },
  {
    "arxiv_id": "2406.01139v1",
    "title": "Depth-Bounded Epistemic Planning",
    "authors": [
      "Thomas Bolander",
      "Alessandro Burigana",
      "Marco Montali"
    ],
    "abstract": "In this paper, we propose a novel algorithm for epistemic planning based on\ndynamic epistemic logic (DEL). The novelty is that we limit the depth of\nreasoning of the planning agent to an upper bound b, meaning that the planning\nagent can only reason about higher-order knowledge to at most (modal) depth b.\nThe algorithm makes use of a novel type of canonical b-bisimulation contraction\nguaranteeing unique minimal models with respect to b-bisimulation. We show our\ndepth-bounded planning algorithm to be sound. Additionally, we show it to be\ncomplete with respect to planning tasks having a solution within bound b of\nreasoning depth (and hence the iterative bound-deepening variant is complete in\nthe standard sense). For bound b of reasoning depth, the algorithm is shown to\nbe (b + 1)-EXPTIME complete, and furthermore fixed-parameter tractable in the\nnumber of agents and atoms. We present both a tree search and a graph search\nvariant of the algorithm, and we benchmark an implementation of the tree search\nversion against a baseline epistemic planner.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01139v1",
    "published_date": "2024-06-03 09:30:28 UTC",
    "updated_date": "2024-06-03 09:30:28 UTC"
  },
  {
    "arxiv_id": "2406.01136v2",
    "title": "Towards Practical Single-shot Motion Synthesis",
    "authors": [
      "Konstantinos Roditakis",
      "Spyridon Thermos",
      "Nikolaos Zioulis"
    ],
    "abstract": "Despite the recent advances in the so-called \"cold start\" generation from\ntext prompts, their needs in data and computing resources, as well as the\nambiguities around intellectual property and privacy concerns pose certain\ncounterarguments for their utility. An interesting and relatively unexplored\nalternative has been the introduction of unconditional synthesis from a single\nsample, which has led to interesting generative applications. In this paper we\nfocus on single-shot motion generation and more specifically on accelerating\nthe training time of a Generative Adversarial Network (GAN). In particular, we\ntackle the challenge of GAN's equilibrium collapse when using mini-batch\ntraining by carefully annealing the weights of the loss functions that prevent\nmode collapse. Additionally, we perform statistical analysis in the generator\nand discriminator models to identify correlations between training stages and\nenable transfer learning. Our improved GAN achieves competitive quality and\ndiversity on the Mixamo benchmark when compared to the original GAN\narchitecture and a single-shot diffusion model, while being up to x6.8 faster\nin training time from the former and x1.75 from the latter. Finally, we\ndemonstrate the ability of our improved GAN to mix and compose motion with a\nsingle forward pass. Project page available at\nhttps://moverseai.github.io/single-shot.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2024, AI for 3D Generation Workshop, Project page:\n  https://moverseai.github.io/single-shot",
    "pdf_url": "http://arxiv.org/pdf/2406.01136v2",
    "published_date": "2024-06-03 09:27:57 UTC",
    "updated_date": "2024-06-04 09:02:14 UTC"
  },
  {
    "arxiv_id": "2406.01131v1",
    "title": "Favi-Score: A Measure for Favoritism in Automated Preference Ratings for Generative AI Evaluation",
    "authors": [
      "Pius von Däniken",
      "Jan Deriu",
      "Don Tuggener",
      "Mark Cieliebak"
    ],
    "abstract": "Generative AI systems have become ubiquitous for all kinds of modalities,\nwhich makes the issue of the evaluation of such models more pressing. One\npopular approach is preference ratings, where the generated outputs of\ndifferent systems are shown to evaluators who choose their preferences. In\nrecent years the field shifted towards the development of automated (trained)\nmetrics to assess generated outputs, which can be used to create preference\nratings automatically. In this work, we investigate the evaluation of the\nmetrics themselves, which currently rely on measuring the correlation to human\njudgments or computing sign accuracy scores.\n  These measures only assess how well the metric agrees with the human ratings.\nHowever, our research shows that this does not tell the whole story. Most\nmetrics exhibit a disagreement with human system assessments which is often\nskewed in favor of particular text generation systems, exposing a degree of\nfavoritism in automated metrics. This paper introduces a formal definition of\nfavoritism in preference metrics, and derives the Favi-Score, which measures\nthis phenomenon. In particular we show that favoritism is strongly related to\nerrors in final system rankings. Thus, we propose that preference-based metrics\nought to be evaluated on both sign accuracy scores and favoritism.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at ACL Main Conference",
    "pdf_url": "http://arxiv.org/pdf/2406.01131v1",
    "published_date": "2024-06-03 09:20:46 UTC",
    "updated_date": "2024-06-03 09:20:46 UTC"
  },
  {
    "arxiv_id": "2406.01126v1",
    "title": "TCMBench: A Comprehensive Benchmark for Evaluating Large Language Models in Traditional Chinese Medicine",
    "authors": [
      "Wenjing Yue",
      "Xiaoling Wang",
      "Wei Zhu",
      "Ming Guan",
      "Huanran Zheng",
      "Pengfei Wang",
      "Changzhi Sun",
      "Xin Ma"
    ],
    "abstract": "Large language models (LLMs) have performed remarkably well in various\nnatural language processing tasks by benchmarking, including in the Western\nmedical domain. However, the professional evaluation benchmarks for LLMs have\nyet to be covered in the traditional Chinese medicine(TCM) domain, which has a\nprofound history and vast influence. To address this research gap, we introduce\nTCM-Bench, an comprehensive benchmark for evaluating LLM performance in TCM. It\ncomprises the TCM-ED dataset, consisting of 5,473 questions sourced from the\nTCM Licensing Exam (TCMLE), including 1,300 questions with authoritative\nanalysis. It covers the core components of TCMLE, including TCM basis and\nclinical practice. To evaluate LLMs beyond accuracy of question answering, we\npropose TCMScore, a metric tailored for evaluating the quality of answers\ngenerated by LLMs for TCM related questions. It comprehensively considers the\nconsistency of TCM semantics and knowledge. After conducting comprehensive\nexperimental analyses from diverse perspectives, we can obtain the following\nfindings: (1) The unsatisfactory performance of LLMs on this benchmark\nunderscores their significant room for improvement in TCM. (2) Introducing\ndomain knowledge can enhance LLMs' performance. However, for in-domain models\nlike ZhongJing-TCM, the quality of generated analysis text has decreased, and\nwe hypothesize that their fine-tuning process affects the basic LLM\ncapabilities. (3) Traditional metrics for text generation quality like Rouge\nand BertScore are susceptible to text length and surface semantic ambiguity,\nwhile domain-specific metrics such as TCMScore can further supplement and\nexplain their evaluation results. These findings highlight the capabilities and\nlimitations of LLMs in the TCM and aim to provide a more profound assistance to\nmedical research.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "20 pages, 15 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.01126v1",
    "published_date": "2024-06-03 09:11:13 UTC",
    "updated_date": "2024-06-03 09:11:13 UTC"
  },
  {
    "arxiv_id": "2406.01116v1",
    "title": "Accelerating Heterogeneous Federated Learning with Closed-form Classifiers",
    "authors": [
      "Eros Fanì",
      "Raffaello Camoriano",
      "Barbara Caputo",
      "Marco Ciccone"
    ],
    "abstract": "Federated Learning (FL) methods often struggle in highly statistically\nheterogeneous settings. Indeed, non-IID data distributions cause client drift\nand biased local solutions, particularly pronounced in the final classification\nlayer, negatively impacting convergence speed and accuracy. To address this\nissue, we introduce Federated Recursive Ridge Regression (Fed3R). Our method\nfits a Ridge Regression classifier computed in closed form leveraging\npre-trained features. Fed3R is immune to statistical heterogeneity and is\ninvariant to the sampling order of the clients. Therefore, it proves\nparticularly effective in cross-device scenarios. Furthermore, it is fast and\nefficient in terms of communication and computation costs, requiring up to two\norders of magnitude fewer resources than the competitors. Finally, we propose\nto leverage the Fed3R parameters as an initialization for a softmax classifier\nand subsequently fine-tune the model using any FL algorithm (Fed3R with\nFine-Tuning, Fed3R+FT). Our findings also indicate that maintaining a fixed\nclassifier aids in stabilizing the training and learning more discriminative\nfeatures in cross-device settings. Official website: https://fed-3r.github.io/.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at ICML 2024 - https://fed-3r.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2406.01116v1",
    "published_date": "2024-06-03 08:52:06 UTC",
    "updated_date": "2024-06-03 08:52:06 UTC"
  },
  {
    "arxiv_id": "2406.02615v1",
    "title": "A hybrid numerical methodology coupling Reduced Order Modeling and Graph Neural Networks for non-parametric geometries: applications to structural dynamics problems",
    "authors": [
      "Victor Matray",
      "Faisal Amlani",
      "Frédéric Feyel",
      "David Néron"
    ],
    "abstract": "This work introduces a new approach for accelerating the numerical analysis\nof time-domain partial differential equations (PDEs) governing complex physical\nsystems. The methodology is based on a combination of a classical reduced-order\nmodeling (ROM) framework and recently-introduced Graph Neural Networks (GNNs),\nwhere the latter is trained on highly heterogeneous databases of varying\nnumerical discretization sizes. The proposed techniques are shown to be\nparticularly suitable for non-parametric geometries, ultimately enabling the\ntreatment of a diverse range of geometries and topologies. Performance studies\nare presented in an application context related to the design of aircraft seats\nand their corresponding mechanical responses to shocks, where the main\nmotivation is to reduce the computational burden and enable the rapid design\niteration for such problems that entail non-parametric geometries. The methods\nproposed here are straightforwardly applicable to other scientific or\nengineering problems requiring a large number of finite element-based numerical\nsimulations, with the potential to significantly enhance efficiency while\nmaintaining reasonable accuracy.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.class-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02615v1",
    "published_date": "2024-06-03 08:51:25 UTC",
    "updated_date": "2024-06-03 08:51:25 UTC"
  },
  {
    "arxiv_id": "2406.01114v1",
    "title": "Globally Interpretable Classifiers via Boolean Formulas with Dynamic Propositions",
    "authors": [
      "Reijo Jaakkola",
      "Tomi Janhunen",
      "Antti Kuusisto",
      "Masood Feyzbakhsh Rankooh",
      "Miikka Vilander"
    ],
    "abstract": "Interpretability and explainability are among the most important challenges\nof modern artificial intelligence, being mentioned even in various legislative\nsources. In this article, we develop a method for extracting immediately human\ninterpretable classifiers from tabular data. The classifiers are given in the\nform of short Boolean formulas built with propositions that can either be\ndirectly extracted from categorical attributes or dynamically computed from\nnumeric ones. Our method is implemented using Answer Set Programming. We\ninvestigate seven datasets and compare our results to ones obtainable by\nstate-of-the-art classifiers for tabular data, namely, XGBoost and random\nforests. Over all datasets, the accuracies obtainable by our method are similar\nto the reference methods. The advantage of our classifiers in all cases is that\nthey are very short and immediately human intelligible as opposed to the\nblack-box nature of the reference methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.LO",
      "I.2.6; F.4.1; I.2.4"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01114v1",
    "published_date": "2024-06-03 08:46:17 UTC",
    "updated_date": "2024-06-03 08:46:17 UTC"
  },
  {
    "arxiv_id": "2406.02614v2",
    "title": "Frequency Enhanced Pre-training for Cross-city Few-shot Traffic Forecasting",
    "authors": [
      "Zhanyu Liu",
      "Jianrong Ding",
      "Guanjie Zheng"
    ],
    "abstract": "The field of Intelligent Transportation Systems (ITS) relies on accurate\ntraffic forecasting to enable various downstream applications. However,\ndeveloping cities often face challenges in collecting sufficient training\ntraffic data due to limited resources and outdated infrastructure. Recognizing\nthis obstacle, the concept of cross-city few-shot forecasting has emerged as a\nviable approach. While previous cross-city few-shot forecasting methods ignore\nthe frequency similarity between cities, we have made an observation that the\ntraffic data is more similar in the frequency domain between cities. Based on\nthis fact, we propose a \\textbf{F}requency \\textbf{E}nhanced\n\\textbf{P}re-training Framework for \\textbf{Cross}-city Few-shot Forecasting\n(\\textbf{FEPCross}). FEPCross has a pre-training stage and a fine-tuning stage.\nIn the pre-training stage, we propose a novel Cross-Domain Spatial-Temporal\nEncoder that incorporates the information of the time and frequency domain and\ntrains it with self-supervised tasks encompassing reconstruction and\ncontrastive objectives. In the fine-tuning stage, we design modules to enrich\ntraining samples and maintain a momentum-updated graph structure, thereby\nmitigating the risk of overfitting to the few-shot training data. Empirical\nevaluations performed on real-world traffic datasets validate the exceptional\nefficacy of FEPCross, outperforming existing approaches of diverse categories\nand demonstrating characteristics that foster the progress of cross-city\nfew-shot forecasting.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by ECMLPKDD 2024 (Research Track)",
    "pdf_url": "http://arxiv.org/pdf/2406.02614v2",
    "published_date": "2024-06-03 08:42:00 UTC",
    "updated_date": "2024-06-06 01:38:45 UTC"
  },
  {
    "arxiv_id": "2406.01103v1",
    "title": "Advancing DRL Agents in Commercial Fighting Games: Training, Integration, and Agent-Human Alignment",
    "authors": [
      "Chen Zhang",
      "Qiang He",
      "Zhou Yuan",
      "Elvis S. Liu",
      "Hong Wang",
      "Jian Zhao",
      "Yang Wang"
    ],
    "abstract": "Deep Reinforcement Learning (DRL) agents have demonstrated impressive success\nin a wide range of game genres. However, existing research primarily focuses on\noptimizing DRL competence rather than addressing the challenge of prolonged\nplayer interaction. In this paper, we propose a practical DRL agent system for\nfighting games named Sh\\=ukai, which has been successfully deployed to Naruto\nMobile, a popular fighting game with over 100 million registered users.\nSh\\=ukai quantifies the state to enhance generalizability, introducing\nHeterogeneous League Training (HELT) to achieve balanced competence,\ngeneralizability, and training efficiency. Furthermore, Sh\\=ukai implements\nspecific rewards to align the agent's behavior with human expectations.\nSh\\=ukai's ability to generalize is demonstrated by its consistent competence\nacross all characters, even though it was trained on only 13% of them.\nAdditionally, HELT exhibits a remarkable 22% improvement in sample efficiency.\nSh\\=ukai serves as a valuable training partner for players in Naruto Mobile,\nenabling them to enhance their abilities and skills.",
    "categories": [
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accept at ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.01103v1",
    "published_date": "2024-06-03 08:39:15 UTC",
    "updated_date": "2024-06-03 08:39:15 UTC"
  },
  {
    "arxiv_id": "2406.01099v2",
    "title": "Deep reinforcement learning for weakly coupled MDP's with continuous actions",
    "authors": [
      "Francisco Robledo",
      "Urtzi Ayesta",
      "Konstantin Avrachenkov"
    ],
    "abstract": "This paper introduces the Lagrange Policy for Continuous Actions (LPCA), a\nreinforcement learning algorithm specifically designed for weakly coupled MDP\nproblems with continuous action spaces. LPCA addresses the challenge of\nresource constraints dependent on continuous actions by introducing a Lagrange\nrelaxation of the weakly coupled MDP problem within a neural network framework\nfor Q-value computation. This approach effectively decouples the MDP, enabling\nefficient policy learning in resource-constrained environments. We present two\nvariations of LPCA: LPCA-DE, which utilizes differential evolution for global\noptimization, and LPCA-Greedy, a method that incrementally and greadily selects\nactions based on Q-value gradients. Comparative analysis against other\nstate-of-the-art techniques across various settings highlight LPCA's robustness\nand efficiency in managing resource allocation while maximizing rewards.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "ACM SIGMETRICS / ASMTA 2024, Jun 2024, Venise, Italy",
    "pdf_url": "http://arxiv.org/pdf/2406.01099v2",
    "published_date": "2024-06-03 08:34:32 UTC",
    "updated_date": "2024-06-12 06:51:00 UTC"
  },
  {
    "arxiv_id": "2406.18570v1",
    "title": "It's a Feature, Not a Bug: Measuring Creative Fluidity in Image Generators",
    "authors": [
      "Aditi Ramaswamy",
      "Melane Navaratnarajah",
      "Hana Chockler"
    ],
    "abstract": "With the rise of freely available image generators, AI-generated art has\nbecome the centre of a series of heated debates, one of which concerns the\nconcept of human creativity. Can an image generation AI exhibit ``creativity''\nof the same type that artists do, and if so, how does that manifest? Our paper\nattempts to define and empirically measure one facet of creative behavior in\nAI, by conducting an experiment to quantify the \"fluidity of prompt\ninterpretation\", or just \"fluidity\", in a series of selected popular image\ngenerators. To study fluidity, we (1) introduce a clear definition for it, (2)\ncreate chains of auto-generated prompts and images seeded with an initial\n\"ground-truth: image, (3) measure these chains' breakage points using\npreexisting visual and semantic metrics, and (4) use both statistical tests and\nvisual explanations to study these chains and determine whether the image\ngenerators used to produce them exhibit significant fluidity.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.18570v1",
    "published_date": "2024-06-03 08:31:29 UTC",
    "updated_date": "2024-06-03 08:31:29 UTC"
  },
  {
    "arxiv_id": "2406.02613v1",
    "title": "ACCO: Accumulate while you Communicate, Hiding Communications in Distributed LLM Training",
    "authors": [
      "Adel Nabli",
      "Louis Fournier",
      "Pierre Erbacher",
      "Louis Serrano",
      "Eugene Belilovsky",
      "Edouard Oyallon"
    ],
    "abstract": "Training Large Language Models (LLMs) relies heavily on distributed\nimplementations, employing multiple GPUs to compute stochastic gradients on\nmodel replicas in parallel. However, synchronizing gradients in data parallel\nsettings induces a communication overhead increasing with the number of\ndistributed workers, which can impede the efficiency gains of parallelization.\nTo address this challenge, optimization algorithms reducing inter-worker\ncommunication have emerged, such as local optimization methods used in\nFederated Learning. While effective in minimizing communication overhead, these\nmethods incur significant memory costs, hindering scalability: in addition to\nextra momentum variables, if communications are only allowed between multiple\nlocal optimization steps, then the optimizer's states cannot be sharded among\nworkers. In response, we propose $\\textbf{AC}$cumulate while\n$\\textbf{CO}$mmunicate ($\\texttt{ACCO}$), a memory-efficient optimization\nalgorithm tailored for distributed training of LLMs. $\\texttt{ACCO}$ allows to\nshard optimizer states across workers, overlaps gradient computations and\ncommunications to conceal communication costs, and accommodates heterogeneous\nhardware. Our method relies on a novel technique to mitigate the one-step delay\ninherent in parallel execution of gradient computations and communications,\neliminating the need for warmup steps and aligning with the training dynamics\nof standard distributed optimization while converging faster in terms of\nwall-clock time. We demonstrate the effectiveness of $\\texttt{ACCO}$ on several\nLLMs training and fine-tuning tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02613v1",
    "published_date": "2024-06-03 08:23:45 UTC",
    "updated_date": "2024-06-03 08:23:45 UTC"
  },
  {
    "arxiv_id": "2406.02612v1",
    "title": "Is Data Valuation Learnable and Interpretable?",
    "authors": [
      "Ou Wu",
      "Weiyao Zhu",
      "Mengyang Li"
    ],
    "abstract": "Measuring the value of individual samples is critical for many data-driven\ntasks, e.g., the training of a deep learning model. Recent literature witnesses\nthe substantial efforts in developing data valuation methods. The primary data\nvaluation methodology is based on the Shapley value from game theory, and\nvarious methods are proposed along this path. {Even though Shapley value-based\nvaluation has solid theoretical basis, it is entirely an experiment-based\napproach and no valuation model has been constructed so far.} In addition,\ncurrent data valuation methods ignore the interpretability of the output\nvalues, despite an interptable data valuation method is of great helpful for\napplications such as data pricing. This study aims to answer an important\nquestion: is data valuation learnable and interpretable? A learned valuation\nmodel have several desirable merits such as fixed number of parameters and\nknowledge reusability. An intrepretable data valuation model can explain why a\nsample is valuable or invaluable. To this end, two new data value modeling\nframeworks are proposed, in which a multi-layer perception~(MLP) and a new\nregression tree are utilized as specific base models for model training and\ninterpretability, respectively. Extensive experiments are conducted on\nbenchmark datasets. {The experimental results provide a positive answer for the\nquestion.} Our study opens up a new technical path for the assessing of data\nvalues. Large data valuation models can be built across many different\ndata-driven tasks, which can promote the widespread application of data\nvaluation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02612v1",
    "published_date": "2024-06-03 08:13:47 UTC",
    "updated_date": "2024-06-03 08:13:47 UTC"
  },
  {
    "arxiv_id": "2406.01086v1",
    "title": "Effective Subset Selection Through The Lens of Neural Network Pruning",
    "authors": [
      "Noga Bar",
      "Raja Giryes"
    ],
    "abstract": "Having large amounts of annotated data significantly impacts the\neffectiveness of deep neural networks. However, the annotation task can be very\nexpensive in some domains, such as medical data. Thus, it is important to\nselect the data to be annotated wisely, which is known as the subset selection\nproblem. We investigate the relationship between subset selection and neural\nnetwork pruning, which is more widely studied, and establish a correspondence\nbetween them. Leveraging insights from network pruning, we propose utilizing\nthe norm criterion of neural network features to improve subset selection\nmethods. We empirically validate our proposed strategy on various networks and\ndatasets, demonstrating enhanced accuracy. This shows the potential of\nemploying pruning tools for subset selection.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01086v1",
    "published_date": "2024-06-03 08:12:32 UTC",
    "updated_date": "2024-06-03 08:12:32 UTC"
  },
  {
    "arxiv_id": "2406.01085v1",
    "title": "FedAdOb: Privacy-Preserving Federated Deep Learning with Adaptive Obfuscation",
    "authors": [
      "Hanlin Gu",
      "Jiahuan Luo",
      "Yan Kang",
      "Yuan Yao",
      "Gongxi Zhu",
      "Bowen Li",
      "Lixin Fan",
      "Qiang Yang"
    ],
    "abstract": "Federated learning (FL) has emerged as a collaborative approach that allows\nmultiple clients to jointly learn a machine learning model without sharing\ntheir private data. The concern about privacy leakage, albeit demonstrated\nunder specific conditions, has triggered numerous follow-up research in\ndesigning powerful attacking methods and effective defending mechanisms aiming\nto thwart these attacking methods. Nevertheless, privacy-preserving mechanisms\nemployed in these defending methods invariably lead to compromised model\nperformances due to a fixed obfuscation applied to private data or gradients.\nIn this article, we, therefore, propose a novel adaptive obfuscation mechanism,\ncoined FedAdOb, to protect private data without yielding original model\nperformances. Technically, FedAdOb utilizes passport-based adaptive obfuscation\nto ensure data privacy in both horizontal and vertical federated learning\nsettings. The privacy-preserving capabilities of FedAdOb, specifically with\nregard to private features and labels, are theoretically proven through\nTheorems 1 and 2. Furthermore, extensive experimental evaluations conducted on\nvarious datasets and network architectures demonstrate the effectiveness of\nFedAdOb by manifesting its superior trade-off between privacy preservation and\nmodel performance, surpassing existing methods.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01085v1",
    "published_date": "2024-06-03 08:12:09 UTC",
    "updated_date": "2024-06-03 08:12:09 UTC"
  },
  {
    "arxiv_id": "2406.01079v1",
    "title": "Object Aware Egocentric Online Action Detection",
    "authors": [
      "Joungbin An",
      "Yunsu Park",
      "Hyolim Kang",
      "Seon Joo Kim"
    ],
    "abstract": "Advancements in egocentric video datasets like Ego4D, EPIC-Kitchens, and\nEgo-Exo4D have enriched the study of first-person human interactions, which is\ncrucial for applications in augmented reality and assisted living. Despite\nthese advancements, current Online Action Detection methods, which efficiently\ndetect actions in streaming videos, are predominantly designed for exocentric\nviews and thus fail to capitalize on the unique perspectives inherent to\negocentric videos. To address this gap, we introduce an Object-Aware Module\nthat integrates egocentric-specific priors into existing OAD frameworks,\nenhancing first-person footage interpretation. Utilizing object-specific\ndetails and temporal dynamics, our module improves scene understanding in\ndetecting actions. Validated extensively on the Epic-Kitchens 100 dataset, our\nwork can be seamlessly integrated into existing models with minimal overhead\nand bring consistent performance enhancements, marking an important step\nforward in adapting action detection systems to egocentric video analysis.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR First Joint Egocentric Vision Workshop 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.01079v1",
    "published_date": "2024-06-03 07:58:40 UTC",
    "updated_date": "2024-06-03 07:58:40 UTC"
  },
  {
    "arxiv_id": "2406.01076v1",
    "title": "Estimating Canopy Height at Scale",
    "authors": [
      "Jan Pauls",
      "Max Zimmer",
      "Una M. Kelly",
      "Martin Schwartz",
      "Sassan Saatchi",
      "Philippe Ciais",
      "Sebastian Pokutta",
      "Martin Brandt",
      "Fabian Gieseke"
    ],
    "abstract": "We propose a framework for global-scale canopy height estimation based on\nsatellite data. Our model leverages advanced data preprocessing techniques,\nresorts to a novel loss function designed to counter geolocation inaccuracies\ninherent in the ground-truth height measurements, and employs data from the\nShuttle Radar Topography Mission to effectively filter out erroneous labels in\nmountainous regions, enhancing the reliability of our predictions in those\nareas. A comparison between predictions and ground-truth labels yields an MAE /\nRMSE of 2.43 / 4.73 (meters) overall and 4.45 / 6.72 (meters) for trees taller\nthan five meters, which depicts a substantial improvement compared to existing\nglobal-scale maps. The resulting height map as well as the underlying framework\nwill facilitate and enhance ecological analyses at a global scale, including,\nbut not limited to, large-scale forest and biomass monitoring.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "ICML Camera-Ready, 17 pages, 14 figures, 7 tables",
    "pdf_url": "http://arxiv.org/pdf/2406.01076v1",
    "published_date": "2024-06-03 07:53:38 UTC",
    "updated_date": "2024-06-03 07:53:38 UTC"
  },
  {
    "arxiv_id": "2406.01072v1",
    "title": "Towards Efficient Deep Spiking Neural Networks Construction with Spiking Activity based Pruning",
    "authors": [
      "Yaxin Li",
      "Qi Xu",
      "Jiangrong Shen",
      "Hongming Xu",
      "Long Chen",
      "Gang Pan"
    ],
    "abstract": "The emergence of deep and large-scale spiking neural networks (SNNs)\nexhibiting high performance across diverse complex datasets has led to a need\nfor compressing network models due to the presence of a significant number of\nredundant structural units, aiming to more effectively leverage their low-power\nconsumption and biological interpretability advantages. Currently, most model\ncompression techniques for SNNs are based on unstructured pruning of individual\nconnections, which requires specific hardware support. Hence, we propose a\nstructured pruning approach based on the activity levels of convolutional\nkernels named Spiking Channel Activity-based (SCA) network pruning framework.\nInspired by synaptic plasticity mechanisms, our method dynamically adjusts the\nnetwork's structure by pruning and regenerating convolutional kernels during\ntraining, enhancing the model's adaptation to the current target task. While\nmaintaining model performance, this approach refines the network architecture,\nultimately reducing computational load and accelerating the inference process.\nThis indicates that structured dynamic sparse learning methods can better\nfacilitate the application of deep SNNs in low-power and high-efficiency\nscenarios.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01072v1",
    "published_date": "2024-06-03 07:44:37 UTC",
    "updated_date": "2024-06-03 07:44:37 UTC"
  },
  {
    "arxiv_id": "2406.06566v4",
    "title": "Natural Language Interaction with a Household Electricity Knowledge-based Digital Twin",
    "authors": [
      "Carolina Fortuna",
      "Vid Hanžel",
      "Blaž Bertalanič"
    ],
    "abstract": "Domain specific digital twins, representing a digital replica of various\nsegments of the smart grid, are foreseen as able to model, simulate, and\ncontrol the respective segments. At the same time, knowledge-based digital\ntwins, coupled with AI, may also empower humans to understand aspects of the\nsystem through natural language interaction in view of planning and policy\nmaking. This paper is the first to assess and report on the potential of\nRetrieval Augmented Generation (RAG) question answers related to household\nelectrical energy measurement aspects leveraging a knowledge-based energy\ndigital twin. Relying on the recently published electricity consumption\nknowledge graph that actually represents a knowledge-based digital twin, we\nstudy the capabilities of ChatGPT, Gemini and Llama in answering electricity\nrelated questions. Furthermore, we compare the answers with the ones generated\nthrough a RAG techniques that leverages an existing electricity knowledge-based\ndigital twin. Our findings illustrate that the RAG approach not only reduces\nthe incidence of incorrect information typically generated by LLMs but also\nsignificantly improves the quality of the output by grounding responses in\nverifiable data. This paper details our methodology, presents a comparative\nanalysis of responses with and without RAG, and discusses the implications of\nour findings for future applications of AI in specialized sectors like energy\ndata analysis.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at IEEE SmartGridComm'24",
    "pdf_url": "http://arxiv.org/pdf/2406.06566v4",
    "published_date": "2024-06-03 07:44:32 UTC",
    "updated_date": "2024-08-16 07:43:55 UTC"
  },
  {
    "arxiv_id": "2406.01065v1",
    "title": "Causal prompting model-based offline reinforcement learning",
    "authors": [
      "Xuehui Yu",
      "Yi Guan",
      "Rujia Shen",
      "Xin Li",
      "Chen Tang",
      "Jingchi Jiang"
    ],
    "abstract": "Model-based offline Reinforcement Learning (RL) allows agents to fully\nutilise pre-collected datasets without requiring additional or unethical\nexplorations. However, applying model-based offline RL to online systems\npresents challenges, primarily due to the highly suboptimal (noise-filled) and\ndiverse nature of datasets generated by online systems. To tackle these issues,\nwe introduce the Causal Prompting Reinforcement Learning (CPRL) framework,\ndesigned for highly suboptimal and resource-constrained online scenarios. The\ninitial phase of CPRL involves the introduction of the Hidden-Parameter Block\nCausal Prompting Dynamic (Hip-BCPD) to model environmental dynamics. This\napproach utilises invariant causal prompts and aligns hidden parameters to\ngeneralise to new and diverse online users. In the subsequent phase, a single\npolicy is trained to address multiple tasks through the amalgamation of\nreusable skills, circumventing the need for training from scratch. Experiments\nconducted across datasets with varying levels of noise, including\nsimulation-based and real-world offline datasets from the Dnurse APP,\ndemonstrate that our proposed method can make robust decisions in\nout-of-distribution and noisy environments, outperforming contemporary\nalgorithms. Additionally, we separately verify the contributions of Hip-BCPDs\nand the skill-reuse strategy to the robustness of performance. We further\nanalyse the visualised structure of Hip-BCPD and the interpretability of\nsub-skills. We released our source code and the first ever real-world medical\ndataset for precise medical decision-making tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01065v1",
    "published_date": "2024-06-03 07:28:57 UTC",
    "updated_date": "2024-06-03 07:28:57 UTC"
  },
  {
    "arxiv_id": "2406.04373v1",
    "title": "VerilogReader: LLM-Aided Hardware Test Generation",
    "authors": [
      "Ruiyang Ma",
      "Yuxin Yang",
      "Ziqian Liu",
      "Jiaxi Zhang",
      "Min Li",
      "Junhua Huang",
      "Guojie Luo"
    ],
    "abstract": "Test generation has been a critical and labor-intensive process in hardware\ndesign verification. Recently, the emergence of Large Language Model (LLM) with\ntheir advanced understanding and inference capabilities, has introduced a novel\napproach. In this work, we investigate the integration of LLM into the Coverage\nDirected Test Generation (CDG) process, where the LLM functions as a Verilog\nReader. It accurately grasps the code logic, thereby generating stimuli that\ncan reach unexplored code branches. We compare our framework with random\ntesting, using our self-designed Verilog benchmark suite. Experiments\ndemonstrate that our framework outperforms random testing on designs within the\nLLM's comprehension scope. Our work also proposes prompt engineering\noptimizations to augment LLM's understanding scope and accuracy.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.04373v1",
    "published_date": "2024-06-03 07:20:51 UTC",
    "updated_date": "2024-06-03 07:20:51 UTC"
  },
  {
    "arxiv_id": "2406.02610v1",
    "title": "MoFormer: Multi-objective Antimicrobial Peptide Generation Based on Conditional Transformer Joint Multi-modal Fusion Descriptor",
    "authors": [
      "Li Wang",
      "Xiangzheng Fu",
      "Jiahao Yang",
      "Xinyi Zhang",
      "Xiucai Ye",
      "Yiping Liu",
      "Tetsuya Sakurai",
      "Xiangxiang Zeng"
    ],
    "abstract": "Deep learning holds a big promise for optimizing existing peptides with more\ndesirable properties, a critical step towards accelerating new drug discovery.\nDespite the recent emergence of several optimized Antimicrobial peptides(AMP)\ngeneration methods, multi-objective optimizations remain still quite\nchallenging for the idealism-realism tradeoff. Here, we establish a\nmulti-objective AMP synthesis pipeline (MoFormer) for the simultaneous\noptimization of multi-attributes of AMPs. MoFormer improves the desired\nattributes of AMP sequences in a highly structured latent space, guided by\nconditional constraints and fine-grained multi-descriptor.We show that MoFormer\noutperforms existing methods in the generation task of enhanced antimicrobial\nactivity and minimal hemolysis. We also utilize a Pareto-based non-dominated\nsorting algorithm and proxies based on large model fine-tuning to\nhierarchically rank the candidates. We demonstrate substantial property\nimprovement using MoFormer from two perspectives: (1) employing molecular\nsimulations and scoring interactions among amino acids to decipher the\nstructure and functionality of AMPs; (2) visualizing latent space to examine\nthe qualities and distribution features, verifying an effective means to\nfacilitate multi-objective optimization AMPs with design constraints",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02610v1",
    "published_date": "2024-06-03 07:17:18 UTC",
    "updated_date": "2024-06-03 07:17:18 UTC"
  },
  {
    "arxiv_id": "2406.01056v1",
    "title": "Virtual avatar generation models as world navigators",
    "authors": [
      "Sai Mandava"
    ],
    "abstract": "We introduce SABR-CLIMB, a novel video model simulating human movement in\nrock climbing environments using a virtual avatar. Our diffusion transformer\npredicts the sample instead of noise in each diffusion step and ingests entire\nvideos to output complete motion sequences. By leveraging a large proprietary\ndataset, NAV-22M, and substantial computational resources, we showcase a proof\nof concept for a system to train general-purpose virtual avatars for complex\ntasks in robotics, sports, and healthcare.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "16 pages, 15 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.01056v1",
    "published_date": "2024-06-03 07:10:15 UTC",
    "updated_date": "2024-06-03 07:10:15 UTC"
  },
  {
    "arxiv_id": "2406.01047v1",
    "title": "An Advanced Reinforcement Learning Framework for Online Scheduling of Deferrable Workloads in Cloud Computing",
    "authors": [
      "Hang Dong",
      "Liwen Zhu",
      "Zhao Shan",
      "Bo Qiao",
      "Fangkai Yang",
      "Si Qin",
      "Chuan Luo",
      "Qingwei Lin",
      "Yuwen Yang",
      "Gurpreet Virdi",
      "Saravan Rajmohan",
      "Dongmei Zhang",
      "Thomas Moscibroda"
    ],
    "abstract": "Efficient resource utilization and perfect user experience usually conflict\nwith each other in cloud computing platforms. Great efforts have been invested\nin increasing resource utilization but trying not to affect users' experience\nfor cloud computing platforms. In order to better utilize the remaining pieces\nof computing resources spread over the whole platform, deferrable jobs are\nprovided with a discounted price to users. For this type of deferrable jobs,\nusers are allowed to submit jobs that will run for a specific uninterrupted\nduration in a flexible range of time in the future with a great discount. With\nthese deferrable jobs to be scheduled under the remaining capacity after\ndeploying those on-demand jobs, it remains a challenge to achieve high resource\nutilization and meanwhile shorten the waiting time for users as much as\npossible in an online manner. In this paper, we propose an online deferrable\njob scheduling method called \\textit{Online Scheduling for DEferrable jobs in\nCloud} (\\OSDEC{}), where a deep reinforcement learning model is adopted to\nlearn the scheduling policy, and several auxiliary tasks are utilized to\nprovide better state representations and improve the performance of the model.\nWith the integrated reinforcement learning framework, the proposed method can\nwell plan the deployment schedule and achieve a short waiting time for users\nwhile maintaining a high resource utilization for the platform. The proposed\nmethod is validated on a public dataset and shows superior performance.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01047v1",
    "published_date": "2024-06-03 06:55:26 UTC",
    "updated_date": "2024-06-03 06:55:26 UTC"
  },
  {
    "arxiv_id": "2406.01045v1",
    "title": "Decompose, Enrich, and Extract! Schema-aware Event Extraction using LLMs",
    "authors": [
      "Fatemeh Shiri",
      "Van Nguyen",
      "Farhad Moghimifar",
      "John Yoo",
      "Gholamreza Haffari",
      "Yuan-Fang Li"
    ],
    "abstract": "Large Language Models (LLMs) demonstrate significant capabilities in\nprocessing natural language data, promising efficient knowledge extraction from\ndiverse textual sources to enhance situational awareness and support\ndecision-making. However, concerns arise due to their susceptibility to\nhallucination, resulting in contextually inaccurate content. This work focuses\non harnessing LLMs for automated Event Extraction, introducing a new method to\naddress hallucination by decomposing the task into Event Detection and Event\nArgument Extraction. Moreover, the proposed method integrates dynamic\nschema-aware augmented retrieval examples into prompts tailored for each\nspecific inquiry, thereby extending and adapting advanced prompting techniques\nsuch as Retrieval-Augmented Generation. Evaluation findings on prominent event\nextraction benchmarks and results from a synthesized benchmark illustrate the\nmethod's superior performance compared to baseline approaches.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01045v1",
    "published_date": "2024-06-03 06:55:10 UTC",
    "updated_date": "2024-06-03 06:55:10 UTC"
  },
  {
    "arxiv_id": "2406.01044v1",
    "title": "Nuclear Medicine Artificial Intelligence in Action: The Bethesda Report (AI Summit 2024)",
    "authors": [
      "Arman Rahmim",
      "Tyler J. Bradshaw",
      "Guido Davidzon",
      "Joyita Dutta",
      "Georges El Fakhri",
      "Munir Ghesani",
      "Nicolas A. Karakatsanis",
      "Quanzheng Li",
      "Chi Liu",
      "Emilie Roncali",
      "Babak Saboury",
      "Tahir Yusufaly",
      "Abhinav K. Jha"
    ],
    "abstract": "The 2nd SNMMI Artificial Intelligence (AI) Summit, organized by the SNMMI AI\nTask Force, took place in Bethesda, MD, on February 29 - March 1, 2024.\nBringing together various community members and stakeholders, and following up\non a prior successful 2022 AI Summit, the summit theme was: AI in Action. Six\nkey topics included (i) an overview of prior and ongoing efforts by the AI task\nforce, (ii) emerging needs and tools for computational nuclear oncology, (iii)\nnew frontiers in large language and generative models, (iv) defining the value\nproposition for the use of AI in nuclear medicine, (v) open science including\nefforts for data and model repositories, and (vi) issues of reimbursement and\nfunding. The primary efforts, findings, challenges, and next steps are\nsummarized in this manuscript.",
    "categories": [
      "physics.med-ph",
      "cs.AI"
    ],
    "primary_category": "physics.med-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01044v1",
    "published_date": "2024-06-03 06:54:38 UTC",
    "updated_date": "2024-06-03 06:54:38 UTC"
  },
  {
    "arxiv_id": "2406.18569v1",
    "title": "FLOW: Fusing and Shuffling Global and Local Views for Cross-User Human Activity Recognition with IMUs",
    "authors": [
      "Qi Qiu",
      "Tao Zhu",
      "Furong Duan",
      "Kevin I-Kai Wang",
      "Liming Chen",
      "Mingxing Nie",
      "Mingxing Nie"
    ],
    "abstract": "Inertial Measurement Unit (IMU) sensors are widely employed for Human\nActivity Recognition (HAR) due to their portability, energy efficiency, and\ngrowing research interest. However, a significant challenge for IMU-HAR models\nis achieving robust generalization performance across diverse users. This\nlimitation stems from substantial variations in data distribution among\nindividual users. One primary reason for this distribution disparity lies in\nthe representation of IMU sensor data in the local coordinate system, which is\nsusceptible to subtle user variations during IMU wearing. To address this\nissue, we propose a novel approach that extracts a global view representation\nbased on the characteristics of IMU data, effectively alleviating the data\ndistribution discrepancies induced by wearing styles. To validate the efficacy\nof the global view representation, we fed both global and local view data into\nmodel for experiments. The results demonstrate that global view data\nsignificantly outperforms local view data in cross-user experiments.\nFurthermore, we propose a Multi-view Supervised Network (MVFNet) based on\nShuffling to effectively fuse local view and global view data. It supervises\nthe feature extraction of each view through view division and view shuffling,\nso as to avoid the model ignoring important features as much as possible.\nExtensive experiments conducted on OPPORTUNITY and PAMAP2 datasets demonstrate\nthat the proposed algorithm outperforms the current state-of-the-art methods in\ncross-user HAR.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.18569v1",
    "published_date": "2024-06-03 06:52:18 UTC",
    "updated_date": "2024-06-03 06:52:18 UTC"
  },
  {
    "arxiv_id": "2406.01040v1",
    "title": "Synthetic Data Generation for 3D Myocardium Deformation Analysis",
    "authors": [
      "Shahar Zuler",
      "Dan Raviv"
    ],
    "abstract": "Accurate analysis of 3D myocardium deformation using high-resolution\ncomputerized tomography (CT) datasets with ground truth (GT) annotations is\ncrucial for advancing cardiovascular imaging research. However, the scarcity of\nsuch datasets poses a significant challenge for developing robust myocardium\ndeformation analysis models. To address this, we propose a novel approach to\nsynthetic data generation for enriching cardiovascular imaging datasets.\n  We introduce a synthetic data generation method, enriched with crucial GT 3D\noptical flow annotations. We outline the data preparation from a cardiac\nfour-dimensional (4D) CT scan, selection of parameters, and the subsequent\ncreation of synthetic data from the same or other sources of 3D cardiac CT data\nfor training.\n  Our work contributes to overcoming the limitations imposed by the scarcity of\nhigh-resolution CT datasets with precise annotations, thereby facilitating the\ndevelopment of accurate and reliable myocardium deformation analysis algorithms\nfor clinical applications and diagnostics.\n  Our code is available at:\nhttp://www.github.com/shaharzuler/cardio_volume_skewer",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01040v1",
    "published_date": "2024-06-03 06:40:53 UTC",
    "updated_date": "2024-06-03 06:40:53 UTC"
  },
  {
    "arxiv_id": "2406.01032v1",
    "title": "LLM and GNN are Complementary: Distilling LLM for Multimodal Graph Learning",
    "authors": [
      "Junjie Xu",
      "Zongyu Wu",
      "Minhua Lin",
      "Xiang Zhang",
      "Suhang Wang"
    ],
    "abstract": "Recent progress in Graph Neural Networks (GNNs) has greatly enhanced the\nability to model complex molecular structures for predicting properties.\nNevertheless, molecular data encompasses more than just graph structures,\nincluding textual and visual information that GNNs do not handle well. To\nbridge this gap, we present an innovative framework that utilizes multimodal\nmolecular data to extract insights from Large Language Models (LLMs). We\nintroduce GALLON (Graph Learning from Large Language Model Distillation), a\nframework that synergizes the capabilities of LLMs and GNNs by distilling\nmultimodal knowledge into a unified Multilayer Perceptron (MLP). This method\nintegrates the rich textual and visual data of molecules with the structural\nanalysis power of GNNs. Extensive experiments reveal that our distilled MLP\nmodel notably improves the accuracy and efficiency of molecular property\npredictions.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.01032v1",
    "published_date": "2024-06-03 06:33:51 UTC",
    "updated_date": "2024-06-03 06:33:51 UTC"
  },
  {
    "arxiv_id": "2406.01641v3",
    "title": "Reciprocal Reward Influence Encourages Cooperation From Self-Interested Agents",
    "authors": [
      "John L. Zhou",
      "Weizhe Hong",
      "Jonathan C. Kao"
    ],
    "abstract": "Cooperation between self-interested individuals is a widespread phenomenon in\nthe natural world, but remains elusive in interactions between artificially\nintelligent agents. Instead, naive reinforcement learning algorithms typically\nconverge to Pareto-dominated outcomes in even the simplest of social dilemmas.\nAn emerging literature on opponent shaping has demonstrated the ability to\nreach prosocial outcomes by influencing the learning of other agents. However,\nsuch methods differentiate through the learning step of other agents or\noptimize for meta-game dynamics, which rely on privileged access to opponents'\nlearning algorithms or exponential sample complexity, respectively. To provide\na learning rule-agnostic and sample-efficient alternative, we introduce\nReciprocators, reinforcement learning agents which are intrinsically motivated\nto reciprocate the influence of opponents' actions on their returns. This\napproach seeks to modify other agents' $Q$-values by increasing their return\nfollowing beneficial actions (with respect to the Reciprocator) and decreasing\nit after detrimental actions, guiding them towards mutually beneficial actions\nwithout directly differentiating through a model of their policy. We show that\nReciprocators can be used to promote cooperation in temporally extended social\ndilemmas during simultaneous learning. Our code is available at\nhttps://github.com/johnlyzhou/reciprocator/.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.01641v3",
    "published_date": "2024-06-03 06:07:27 UTC",
    "updated_date": "2025-01-14 23:08:11 UTC"
  },
  {
    "arxiv_id": "2406.06565v2",
    "title": "MixEval: Deriving Wisdom of the Crowd from LLM Benchmark Mixtures",
    "authors": [
      "Jinjie Ni",
      "Fuzhao Xue",
      "Xiang Yue",
      "Yuntian Deng",
      "Mahir Shah",
      "Kabir Jain",
      "Graham Neubig",
      "Yang You"
    ],
    "abstract": "Evaluating large language models (LLMs) is challenging. Traditional\nground-truth-based benchmarks fail to capture the comprehensiveness and nuance\nof real-world queries, while LLM-as-judge benchmarks suffer from grading biases\nand limited query quantity. Both of them may also become contaminated over\ntime. User-facing evaluation, such as Chatbot Arena, provides reliable signals\nbut is costly and slow. In this work, we propose MixEval, a new paradigm for\nestablishing efficient, gold-standard LLM evaluation by strategically mixing\noff-the-shelf benchmarks. It bridges (1) comprehensive and well-distributed\nreal-world user queries and (2) efficient and fairly-graded ground-truth-based\nbenchmarks, by matching queries mined from the web with similar queries from\nexisting benchmarks. Based on MixEval, we further build MixEval-Hard, which\noffers more room for model improvement. Our benchmarks' advantages lie in (1) a\n0.96 model ranking correlation with Chatbot Arena arising from the highly\nimpartial query distribution and grading mechanism, (2) fast, cheap, and\nreproducible execution (6% of the time and cost of MMLU), and (3) dynamic\nevaluation enabled by the rapid and stable data update pipeline. We provide\nextensive meta-evaluation and analysis for our and existing LLM benchmarks to\ndeepen the community's understanding of LLM evaluation and guide future\nresearch directions.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.06565v2",
    "published_date": "2024-06-03 05:47:05 UTC",
    "updated_date": "2024-10-12 14:13:27 UTC"
  },
  {
    "arxiv_id": "2406.01012v1",
    "title": "Attention-based Iterative Decomposition for Tensor Product Representation",
    "authors": [
      "Taewon Park",
      "Inchul Choi",
      "Minho Lee"
    ],
    "abstract": "In recent research, Tensor Product Representation (TPR) is applied for the\nsystematic generalization task of deep neural networks by learning the\ncompositional structure of data. However, such prior works show limited\nperformance in discovering and representing the symbolic structure from unseen\ntest data because their decomposition to the structural representations was\nincomplete. In this work, we propose an Attention-based Iterative Decomposition\n(AID) module designed to enhance the decomposition operations for the\nstructured representations encoded from the sequential input data with TPR. Our\nAID can be easily adapted to any TPR-based model and provides enhanced\nsystematic decomposition through a competitive attention mechanism between\ninput features and structured representations. In our experiments, AID shows\neffectiveness by significantly improving the performance of TPR-based prior\nworks on the series of systematic generalization tasks. Moreover, in the\nquantitative and qualitative evaluations, AID produces more compositional and\nwell-bound structural representations than other works.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Published in ICLR 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.01012v1",
    "published_date": "2024-06-03 05:46:52 UTC",
    "updated_date": "2024-06-03 05:46:52 UTC"
  },
  {
    "arxiv_id": "2406.01011v1",
    "title": "Multi-Object Tracking based on Imaging Radar 3D Object Detection",
    "authors": [
      "Patrick Palmer",
      "Martin Krüger",
      "Richard Altendorfer",
      "Torsten Bertram"
    ],
    "abstract": "Effective tracking of surrounding traffic participants allows for an accurate\nstate estimation as a necessary ingredient for prediction of future behavior\nand therefore adequate planning of the ego vehicle trajectory. One approach for\ndetecting and tracking surrounding traffic participants is the combination of a\nlearning based object detector with a classical tracking algorithm. Learning\nbased object detectors have been shown to work adequately on lidar and camera\ndata, while learning based object detectors using standard radar data input\nhave proven to be inferior. Recently, with the improvements to radar sensor\ntechnology in the form of imaging radars, the object detection performance on\nradar was greatly improved but is still limited compared to lidar sensors due\nto the sparsity of the radar point cloud. This presents a unique challenge for\nthe task of multi-object tracking. The tracking algorithm must overcome the\nlimited detection quality while generating consistent tracks. To this end, a\ncomparison between different multi-object tracking methods on imaging radar\ndata is required to investigate its potential for downstream tasks. The work at\nhand compares multiple approaches and analyzes their limitations when applied\nto imaging radar data. Furthermore, enhancements to the presented approaches in\nthe form of probabilistic association algorithms are considered for this task.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "Presented at: 9. International ATZ-Live Automated Driving 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.01011v1",
    "published_date": "2024-06-03 05:46:23 UTC",
    "updated_date": "2024-06-03 05:46:23 UTC"
  },
  {
    "arxiv_id": "2406.06564v3",
    "title": "SwitchLoRA: Switched Low-Rank Adaptation Can Learn Full-Rank Information",
    "authors": [
      "Kaiye Zhou",
      "Shucheng Wang",
      "Jun Xu"
    ],
    "abstract": "In the training of large language models, parameter-efficient techniques such\nas LoRA optimize memory usage and reduce communication overhead and memory\nusage during the fine-tuning phase. However, applying such techniques directly\nduring the pre-training phase results in poor performance, primarily because\nthe premature implementation of low-rank training significantly reduces model\naccuracy. Existing methods like ReLoRA and GaLore have attempted to address\nthis challenge by updating the low-rank subspace. However, they still fall\nshort of achieving the accuracy of full-rank training. Specifically, ReLoRA\nrestricts the frequency of updates to preserve optimizer states consistency,\nhindering its ability to closely approximate full-rank training behavior.\nMeanwhile, GaLore relies on Singular Value Decomposition (SVD) to approximate\nthe full-rank space, which introduces accuracy loss during the approximation\nprocess. In this paper, we introduce SwitchLoRA, a parameter-efficient training\ntechnique that frequently and smoothly replaces the trainable parameters of\nLoRA adapters with alternative parameters. SwitchLoRA updates the low-rank\nsubspace incrementally, targeting only a few dimensions at a time to minimize\nthe impact on optimizer states. This allows a higher update frequency, thereby\nenhancing accuracy by enabling the updated parameters to more closely mimic\nfull-rank behavior during the pre-training phase. Our results demonstrate that\nSwitchLoRA actually surpasses full-rank training, reducing perplexity from\n15.23 to 15.01 on the LLaMA 1.3B model, while also cutting communication\noverhead by 54\\% and memory usage by 13\\%. Furthermore, after full fine-tuning\nthe SwitchLoRA pre-trained model and the full-rank pre-trained model on the\nGLUE benchmark, the SwitchLoRA pre-trained model showed an average accuracy\ngain of about 1\\% over the full-rank pre-trained model.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "SwitchLoRA introduces an innovative parameter-efficient training\n  method that dynamically switches parameters throughout the entire training\n  period, achieving significant memory and communication overhead while\n  preserving accuracy",
    "pdf_url": "http://arxiv.org/pdf/2406.06564v3",
    "published_date": "2024-06-03 05:40:34 UTC",
    "updated_date": "2025-01-02 17:02:35 UTC"
  },
  {
    "arxiv_id": "2406.01006v2",
    "title": "SemCoder: Training Code Language Models with Comprehensive Semantics Reasoning",
    "authors": [
      "Yangruibo Ding",
      "Jinjun Peng",
      "Marcus J. Min",
      "Gail Kaiser",
      "Junfeng Yang",
      "Baishakhi Ray"
    ],
    "abstract": "Code Large Language Models (Code LLMs) have excelled at tasks like code\ncompletion but often miss deeper semantics such as execution effects and\ndynamic states. This paper aims to bridge the gap between Code LLMs' reliance\non static text data and the need for semantic understanding for complex tasks\nlike debugging and program repair. We introduce a novel strategy, monologue\nreasoning, to train Code LLMs to reason comprehensive semantics, encompassing\nhigh-level functional descriptions, local execution effects of individual\nstatements, and overall input/output behavior, thereby linking static code text\nwith dynamic execution states. We begin by collecting PyX, a clean Python\ncorpus of fully executable code samples with functional descriptions and test\ncases. We propose training Code LLMs not only to write code but also to\nunderstand code semantics by reasoning about key properties, constraints, and\nexecution behaviors using natural language, mimicking human verbal debugging,\ni.e., rubber-duck debugging. This approach led to the development of SemCoder,\na Code LLM with only 6.7B parameters, which shows competitive performance with\nGPT-3.5-turbo on code generation and execution reasoning tasks. SemCoder\nachieves 79.3% on HumanEval (GPT-3.5-turbo: 76.8%), 63.6% on CRUXEval-I\n(GPT-3.5-turbo: 50.3%), and 63.9% on CRUXEval-O (GPT-3.5-turbo: 59.0%). We also\nstudy the effectiveness of SemCoder's monologue-style execution reasoning\ncompared to concrete scratchpad reasoning, showing that our approach integrates\nsemantics from multiple dimensions more smoothly. Finally, we demonstrate the\npotential of applying learned semantics to improve Code LLMs' debugging and\nself-refining capabilities. Our data, code, and models are available at:\nhttps://github.com/ARiSE-Lab/SemCoder.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CL",
    "comment": "NeurIPS 2024 Camera-ready",
    "pdf_url": "http://arxiv.org/pdf/2406.01006v2",
    "published_date": "2024-06-03 05:36:57 UTC",
    "updated_date": "2024-10-31 23:44:31 UTC"
  },
  {
    "arxiv_id": "2406.00983v1",
    "title": "Take its Essence, Discard its Dross! Debiasing for Toxic Language Detection via Counterfactual Causal Effect",
    "authors": [
      "Junyu Lu",
      "Bo Xu",
      "Xiaokun Zhang",
      "Kaiyuan Liu",
      "Dongyu Zhang",
      "Liang Yang",
      "Hongfei Lin"
    ],
    "abstract": "Current methods of toxic language detection (TLD) typically rely on specific\ntokens to conduct decisions, which makes them suffer from lexical bias, leading\nto inferior performance and generalization. Lexical bias has both \"useful\" and\n\"misleading\" impacts on understanding toxicity. Unfortunately, instead of\ndistinguishing between these impacts, current debiasing methods typically\neliminate them indiscriminately, resulting in a degradation in the detection\naccuracy of the model. To this end, we propose a Counterfactual Causal\nDebiasing Framework (CCDF) to mitigate lexical bias in TLD. It preserves the\n\"useful impact\" of lexical bias and eliminates the \"misleading impact\".\nSpecifically, we first represent the total effect of the original sentence and\nbiased tokens on decisions from a causal view. We then conduct counterfactual\ninference to exclude the direct causal effect of lexical bias from the total\neffect. Empirical evaluations demonstrate that the debiased TLD model\nincorporating CCDF achieves state-of-the-art performance in both accuracy and\nfairness compared to competitive baselines applied on several vanilla models.\nThe generalization capability of our model outperforms current debiased models\nfor out-of-distribution data.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.00983v1",
    "published_date": "2024-06-03 04:34:30 UTC",
    "updated_date": "2024-06-03 04:34:30 UTC"
  },
  {
    "arxiv_id": "2406.00977v2",
    "title": "Dragonfly: Multi-Resolution Zoom-In Encoding Enhances Vision-Language Models",
    "authors": [
      "Rahul Thapa",
      "Kezhen Chen",
      "Ian Covert",
      "Rahul Chalamala",
      "Ben Athiwaratkun",
      "Shuaiwen Leon Song",
      "James Zou"
    ],
    "abstract": "Recent advances in vision-language models (VLMs) have demonstrated the\nadvantages of processing images at higher resolutions and utilizing multi-crop\nfeatures to preserve native resolution details. However, despite these\nimprovements, existing vision transformers (ViTs) still struggle to capture\nfine-grained details from less prominent objects, charts, and embedded text,\nlimiting their effectiveness in certain tasks. In this paper, we extend recent\nhigh-resolution and multi-crop techniques by not only preserving the native\nresolution, but zooming in beyond it and extracting features from a large\nnumber of image sub-crops. This enhancement allows our model to better capture\nfine-grained details, overcoming the limitations of current ViTs. To manage the\nincreased token count and computational complexity, we demonstrate that a\nsimple mean-pooling aggregation over tokens is effective. Our model, Dragonfly,\nachieves competitive performance on general-domain tasks such as ScienceQA and\nAI2D, and excels in tasks requiring fine-grained image understanding, including\nTextVQA and ChartQA. Among models in the 7-8B parameter range, Dragonfly\nconsistently ranks at the top across ten general-domain benchmarks, achieving\nthe highest or second-highest scores in most cases, outperforming models that\nare significantly larger or trained on larger datasets. Our biomedical model,\nDragonfly-Med, sets new benchmarks on several medical tasks, achieving 91.6%\naccuracy on SLAKE (compared to 84.8% for Med-Gemini), a 67.1% token F1 score on\nPath-VQA (compared to 62.7% for Med-PaLM M), and state-of-the-art results\nacross the majority of image captioning tasks. Overall, our work highlights the\npersistent challenge of engineering visual representations with\nfixed-resolution ViTs, and proposes a simple yet effective solution to address\nthis issue and boost performance in both general and specialized domains.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.00977v2",
    "published_date": "2024-06-03 04:17:12 UTC",
    "updated_date": "2024-10-14 23:15:24 UTC"
  },
  {
    "arxiv_id": "2406.00975v2",
    "title": "Luna: An Evaluation Foundation Model to Catch Language Model Hallucinations with High Accuracy and Low Cost",
    "authors": [
      "Masha Belyi",
      "Robert Friel",
      "Shuai Shao",
      "Atindriyo Sanyal"
    ],
    "abstract": "Retriever Augmented Generation (RAG) systems have become pivotal in enhancing\nthe capabilities of language models by incorporating external knowledge\nretrieval mechanisms. However, a significant challenge in deploying these\nsystems in industry applications is the detection and mitigation of\nhallucinations: instances where the model generates information that is not\ngrounded in the retrieved context. Addressing this issue is crucial for\nensuring the reliability and accuracy of responses generated by large language\nmodels (LLMs) in diverse industry settings. Current hallucination detection\ntechniques fail to deliver accuracy, low latency, and low cost simultaneously.\nWe introduce Luna: a DeBERTA-large (440M) encoder, finetuned for hallucination\ndetection in RAG settings. We demonstrate that Luna outperforms GPT-3.5 and\ncommercial evaluation frameworks on the hallucination detection task, with 97%\nand 91% reduction in cost and latency, respectively. Luna is lightweight and\ngeneralizes across multiple industry verticals and out-of-domain data, making\nit an ideal candidate for industry LLM applications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.00975v2",
    "published_date": "2024-06-03 04:14:21 UTC",
    "updated_date": "2024-06-05 15:45:04 UTC"
  },
  {
    "arxiv_id": "2406.02609v2",
    "title": "Less is More: Pseudo-Label Filtering for Continual Test-Time Adaptation",
    "authors": [
      "Jiayao Tan",
      "Fan Lyu",
      "Chenggong Ni",
      "Tingliang Feng",
      "Fuyuan Hu",
      "Zhang Zhang",
      "Shaochuang Zhao",
      "Liang Wang"
    ],
    "abstract": "Continual Test-Time Adaptation (CTTA) aims to adapt a pre-trained model to a\nsequence of target domains during the test phase without accessing the source\ndata. To adapt to unlabeled data from unknown domains, existing methods rely on\nconstructing pseudo-labels for all samples and updating the model through\nself-training. However, these pseudo-labels often involve noise, leading to\ninsufficient adaptation. To improve the quality of pseudo-labels, we propose a\npseudo-label selection method for CTTA, called Pseudo Labeling Filter (PLF).\nThe key idea of PLF is to keep selecting appropriate thresholds for\npseudo-labels and identify reliable ones for self-training. Specifically, we\npresent three principles for setting thresholds during continuous domain\nlearning, including initialization, growth and diversity. Based on these\nprinciples, we design Self-Adaptive Thresholding to filter pseudo-labels.\nAdditionally, we introduce a Class Prior Alignment (CPA) method to encourage\nthe model to make diverse predictions for unknown domain samples. Through\nextensive experiments, PLF outperforms current state-of-the-art methods,\nproving its effectiveness in CTTA.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "arXiv admin note: text overlap with arXiv:2310.03335 by other authors",
    "pdf_url": "http://arxiv.org/pdf/2406.02609v2",
    "published_date": "2024-06-03 04:09:36 UTC",
    "updated_date": "2024-07-12 08:15:22 UTC"
  },
  {
    "arxiv_id": "2406.06563v1",
    "title": "Skywork-MoE: A Deep Dive into Training Techniques for Mixture-of-Experts Language Models",
    "authors": [
      "Tianwen Wei",
      "Bo Zhu",
      "Liang Zhao",
      "Cheng Cheng",
      "Biye Li",
      "Weiwei Lü",
      "Peng Cheng",
      "Jianhao Zhang",
      "Xiaoyu Zhang",
      "Liang Zeng",
      "Xiaokun Wang",
      "Yutuan Ma",
      "Rui Hu",
      "Shuicheng Yan",
      "Han Fang",
      "Yahui Zhou"
    ],
    "abstract": "In this technical report, we introduce the training methodologies implemented\nin the development of Skywork-MoE, a high-performance mixture-of-experts (MoE)\nlarge language model (LLM) with 146 billion parameters and 16 experts. It is\ninitialized from the pre-existing dense checkpoints of our Skywork-13B model.\nWe explore the comparative effectiveness of upcycling versus training from\nscratch initializations. Our findings suggest that the choice between these two\napproaches should consider both the performance of the existing dense\ncheckpoints and the MoE training budget. We highlight two innovative\ntechniques: gating logit normalization, which improves expert diversification,\nand adaptive auxiliary loss coefficients, allowing for layer-specific\nadjustment of auxiliary loss coefficients. Our experimental results validate\nthe effectiveness of these methods. Leveraging these techniques and insights,\nwe trained our upcycled Skywork-MoE on a condensed subset of our SkyPile\ncorpus. The evaluation results demonstrate that our model delivers strong\nperformance across a wide range of benchmarks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.06563v1",
    "published_date": "2024-06-03 03:58:41 UTC",
    "updated_date": "2024-06-03 03:58:41 UTC"
  },
  {
    "arxiv_id": "2407.13942v1",
    "title": "Harmful Suicide Content Detection",
    "authors": [
      "Kyumin Park",
      "Myung Jae Baik",
      "YeongJun Hwang",
      "Yen Shin",
      "HoJae Lee",
      "Ruda Lee",
      "Sang Min Lee",
      "Je Young Hannah Sun",
      "Ah Rah Lee",
      "Si Yeun Yoon",
      "Dong-ho Lee",
      "Jihyung Moon",
      "JinYeong Bak",
      "Kyunghyun Cho",
      "Jong-Woo Paik",
      "Sungjoon Park"
    ],
    "abstract": "Harmful suicide content on the Internet is a significant risk factor inducing\nsuicidal thoughts and behaviors among vulnerable populations. Despite global\nefforts, existing resources are insufficient, specifically in high-risk regions\nlike the Republic of Korea. Current research mainly focuses on understanding\nnegative effects of such content or suicide risk in individuals, rather than on\nautomatically detecting the harmfulness of content. To fill this gap, we\nintroduce a harmful suicide content detection task for classifying online\nsuicide content into five harmfulness levels. We develop a multi-modal\nbenchmark and a task description document in collaboration with medical\nprofessionals, and leverage large language models (LLMs) to explore efficient\nmethods for moderating such content. Our contributions include proposing a\nnovel detection task, a multi-modal Korean benchmark with expert annotations,\nand suggesting strategies using LLMs to detect illegal and harmful content.\nOwing to the potential harm involved, we publicize our implementations and\nbenchmark, incorporating an ethical verification process.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.SI"
    ],
    "primary_category": "cs.CY",
    "comment": "30 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.13942v1",
    "published_date": "2024-06-03 03:43:44 UTC",
    "updated_date": "2024-06-03 03:43:44 UTC"
  },
  {
    "arxiv_id": "2406.00965v5",
    "title": "HBTP: Heuristic Behavior Tree Planning with Large Language Model Reasoning",
    "authors": [
      "Yishuai Cai",
      "Xinglin Chen",
      "Yunxin Mao",
      "Minglong Li",
      "Shaowu Yang",
      "Wenjing Yang",
      "Ji Wang"
    ],
    "abstract": "Behavior Trees (BTs) are increasingly becoming a popular control structure in\nrobotics due to their modularity, reactivity, and robustness. In terms of BT\ngeneration methods, BT planning shows promise for generating reliable BTs.\nHowever, the scalability of BT planning is often constrained by prolonged\nplanning times in complex scenarios, largely due to a lack of domain knowledge.\nIn contrast, pre-trained Large Language Models (LLMs) have demonstrated task\nreasoning capabilities across various domains, though the correctness and\nsafety of their planning remain uncertain. This paper proposes integrating BT\nplanning with LLM reasoning, introducing Heuristic Behavior Tree Planning\n(HBTP)-a reliable and efficient framework for BT generation. The key idea in\nHBTP is to leverage LLMs for task-specific reasoning to generate a heuristic\npath, which BT planning can then follow to expand efficiently. We first\nintroduce the heuristic BT expansion process, along with two heuristic variants\ndesigned for optimal planning and satisficing planning, respectively. Then, we\npropose methods to address the inaccuracies of LLM reasoning, including action\nspace pruning and reflective feedback, to further enhance both reasoning\naccuracy and planning efficiency. Experiments demonstrate the theoretical\nbounds of HBTP, and results from four datasets confirm its practical\neffectiveness in everyday service robot applications.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.00965v5",
    "published_date": "2024-06-03 03:38:56 UTC",
    "updated_date": "2025-03-07 08:27:32 UTC"
  },
  {
    "arxiv_id": "2406.06562v1",
    "title": "Achieving Sparse Activation in Small Language Models",
    "authors": [
      "Jifeng Song",
      "Kai Huang",
      "Xiangyu Yin",
      "Boyuan Yang",
      "Wei Gao"
    ],
    "abstract": "Sparse activation, which selectively activates only an input-dependent set of\nneurons in inference, is a useful technique to reduce the computing cost of\nLarge Language Models (LLMs) without retraining or adaptation efforts. However,\nwhether it can be applied to the recently emerging Small Language Models (SLMs)\nremains questionable, because SLMs are generally less over-parameterized than\nLLMs. In this paper, we aim to achieve sparse activation in SLMs. We first show\nthat the existing sparse activation schemes in LLMs that build on neurons'\noutput magnitudes cannot be applied to SLMs, and activating neurons based on\ntheir attribution scores is a better alternative. Further, we demonstrated and\nquantified the large errors of existing attribution metrics when being used for\nsparse activation, due to the interdependency among attribution scores of\nneurons across different layers. Based on these observations, we proposed a new\nattribution metric that can provably correct such errors and achieve precise\nsparse activation. Experiments over multiple popular SLMs and datasets show\nthat our approach can achieve 80% sparsification ratio with <5% model accuracy\nloss, comparable to the sparse activation achieved in LLMs. The source code is\navailable at: https://github.com/pittisl/Sparse-Activation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "15 pages",
    "pdf_url": "http://arxiv.org/pdf/2406.06562v1",
    "published_date": "2024-06-03 03:21:49 UTC",
    "updated_date": "2024-06-03 03:21:49 UTC"
  },
  {
    "arxiv_id": "2406.00954v1",
    "title": "Annotation Guidelines-Based Knowledge Augmentation: Towards Enhancing Large Language Models for Educational Text Classification",
    "authors": [
      "Shiqi Liu",
      "Sannyuya Liu",
      "Lele Sha",
      "Zijie Zeng",
      "Dragan Gasevic",
      "Zhi Liu"
    ],
    "abstract": "Various machine learning approaches have gained significant popularity for\nthe automated classification of educational text to identify indicators of\nlearning engagement -- i.e. learning engagement classification (LEC). LEC can\noffer comprehensive insights into human learning processes, attracting\nsignificant interest from diverse research communities, including Natural\nLanguage Processing (NLP), Learning Analytics, and Educational Data Mining.\nRecently, Large Language Models (LLMs), such as ChatGPT, have demonstrated\nremarkable performance in various NLP tasks. However, their comprehensive\nevaluation and improvement approaches in LEC tasks have not been thoroughly\ninvestigated. In this study, we propose the Annotation Guidelines-based\nKnowledge Augmentation (AGKA) approach to improve LLMs. AGKA employs GPT 4.0 to\nretrieve label definition knowledge from annotation guidelines, and then\napplies the random under-sampler to select a few typical examples.\nSubsequently, we conduct a systematic evaluation benchmark of LEC, which\nincludes six LEC datasets covering behavior classification (question and\nurgency level), emotion classification (binary and epistemic emotion), and\ncognition classification (opinion and cognitive presence). The study results\ndemonstrate that AGKA can enhance non-fine-tuned LLMs, particularly GPT 4.0 and\nLlama 3 70B. GPT 4.0 with AGKA few-shot outperforms full-shot fine-tuned models\nsuch as BERT and RoBERTa on simple binary classification datasets. However, GPT\n4.0 lags in multi-class tasks that require a deep understanding of complex\nsemantic information. Notably, Llama 3 70B with AGKA is a promising combination\nbased on open-source LLM, because its performance is on par with closed-source\nGPT 4.0 with AGKA. In addition, LLMs struggle to distinguish between labels\nwith similar names in multi-class classification.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "The manuscript has been submitted for peer review to the IEEE\n  Transactions on Learning Technologies",
    "pdf_url": "http://arxiv.org/pdf/2406.00954v1",
    "published_date": "2024-06-03 03:09:01 UTC",
    "updated_date": "2024-06-03 03:09:01 UTC"
  },
  {
    "arxiv_id": "2406.00944v3",
    "title": "A Theory for Token-Level Harmonization in Retrieval-Augmented Generation",
    "authors": [
      "Shicheng Xu",
      "Liang Pang",
      "Huawei Shen",
      "Xueqi Cheng"
    ],
    "abstract": "Retrieval-augmented generation (RAG) utilizes retrieved texts to enhance\nlarge language models (LLMs). Studies show that while RAG provides valuable\nexternal information (benefit), it may also mislead LLMs (detriment) with noisy\nor incorrect retrieved texts. Although many existing methods attempt to\npreserve benefit and avoid detriment, they lack a theoretical explanation for\nRAG. The benefit and detriment in the next token prediction of RAG remain a\nblack box that cannot be quantified or compared in an explainable manner, so\nexisting methods are data-driven, need additional utility evaluators or\npost-hoc. This paper takes the first step towards providing a theory to explain\nand trade off the benefit and detriment in RAG. First, we model RAG as the\nfusion between distribution of LLMs knowledge and distribution of retrieved\ntexts. Then, we formalize the trade-off between the value of external knowledge\n(benefit) and its potential risk of misleading LLMs (detriment) in next token\nprediction of RAG by distribution difference in this fusion. Finally, we prove\nthat the actual effect of RAG on the token, which is the comparison between\nbenefit and detriment, can be predicted without any training or accessing the\nutility of retrieval. Based on our theory, we propose a practical novel method,\nTok-RAG, which achieves collaborative generation between the pure LLM and RAG\nat token level to preserve benefit and avoid detriment. Experiments in\nreal-world tasks using LLMs such as OPT, LLaMA-2, and Mistral show the\neffectiveness of our method and support our theoretical findings.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2406.00944v3",
    "published_date": "2024-06-03 02:56:14 UTC",
    "updated_date": "2025-02-28 03:23:52 UTC"
  },
  {
    "arxiv_id": "2406.00943v2",
    "title": "State Space Models on Temporal Graphs: A First-Principles Study",
    "authors": [
      "Jintang Li",
      "Ruofan Wu",
      "Xinzhou Jin",
      "Boqun Ma",
      "Liang Chen",
      "Zibin Zheng"
    ],
    "abstract": "Over the past few years, research on deep graph learning has shifted from\nstatic graphs to temporal graphs in response to real-world complex systems that\nexhibit dynamic behaviors. In practice, temporal graphs are formalized as an\nordered sequence of static graph snapshots observed at discrete time points.\nSequence models such as RNNs or Transformers have long been the predominant\nbackbone networks for modeling such temporal graphs. Yet, despite the promising\nresults, RNNs struggle with long-range dependencies, while transformers are\nburdened by quadratic computational complexity. Recently, state space models\n(SSMs), which are framed as discretized representations of an underlying\ncontinuous-time linear dynamical system, have garnered substantial attention\nand achieved breakthrough advancements in independent sequence modeling. In\nthis work, we undertake a principled investigation that extends SSM theory to\ntemporal graphs by integrating structural information into the online\napproximation objective via the adoption of a Laplacian regularization term.\nThe emergent continuous-time system introduces novel algorithmic challenges,\nthereby necessitating our development of GraphSSM, a graph state space model\nfor modeling the dynamics of temporal graphs. Extensive experimental results\ndemonstrate the effectiveness of our GraphSSM framework across various temporal\ngraph benchmarks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2406.00943v2",
    "published_date": "2024-06-03 02:56:11 UTC",
    "updated_date": "2024-10-29 11:32:15 UTC"
  },
  {
    "arxiv_id": "2406.00083v2",
    "title": "BadRAG: Identifying Vulnerabilities in Retrieval Augmented Generation of Large Language Models",
    "authors": [
      "Jiaqi Xue",
      "Mengxin Zheng",
      "Yebowen Hu",
      "Fei Liu",
      "Xun Chen",
      "Qian Lou"
    ],
    "abstract": "Large Language Models (LLMs) are constrained by outdated information and a\ntendency to generate incorrect data, commonly referred to as \"hallucinations.\"\nRetrieval-Augmented Generation (RAG) addresses these limitations by combining\nthe strengths of retrieval-based methods and generative models. This approach\ninvolves retrieving relevant information from a large, up-to-date dataset and\nusing it to enhance the generation process, leading to more accurate and\ncontextually appropriate responses. Despite its benefits, RAG introduces a new\nattack surface for LLMs, particularly because RAG databases are often sourced\nfrom public data, such as the web. In this paper, we propose \\TrojRAG{} to\nidentify the vulnerabilities and attacks on retrieval parts (RAG database) and\ntheir indirect attacks on generative parts (LLMs). Specifically, we identify\nthat poisoning several customized content passages could achieve a retrieval\nbackdoor, where the retrieval works well for clean queries but always returns\ncustomized poisoned adversarial queries. Triggers and poisoned passages can be\nhighly customized to implement various attacks. For example, a trigger could be\na semantic group like \"The Republican Party, Donald Trump, etc.\" Adversarial\npassages can be tailored to different contents, not only linked to the triggers\nbut also used to indirectly attack generative LLMs without modifying them.\nThese attacks can include denial-of-service attacks on RAG and semantic\nsteering attacks on LLM generations conditioned by the triggers. Our\nexperiments demonstrate that by just poisoning 10 adversarial passages can\ninduce 98.2\\% success rate to retrieve the adversarial passages. Then, these\npassages can increase the reject ratio of RAG-based GPT-4 from 0.01\\% to 74.6\\%\nor increase the rate of negative responses from 0.22\\% to 72\\% for targeted\nqueries.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.00083v2",
    "published_date": "2024-06-03 02:25:33 UTC",
    "updated_date": "2024-06-06 13:38:42 UTC"
  },
  {
    "arxiv_id": "2406.00938v1",
    "title": "A Synergistic Approach In Network Intrusion Detection By Neurosymbolic AI",
    "authors": [
      "Alice Bizzarri",
      "Chung-En Yu",
      "Brian Jalaian",
      "Fabrizio Riguzzi",
      "Nathaniel D. Bastian"
    ],
    "abstract": "The prevailing approaches in Network Intrusion Detection Systems (NIDS) are\noften hampered by issues such as high resource consumption, significant\ncomputational demands, and poor interpretability. Furthermore, these systems\ngenerally struggle to identify novel, rapidly changing cyber threats. This\npaper delves into the potential of incorporating Neurosymbolic Artificial\nIntelligence (NSAI) into NIDS, combining deep learning's data-driven strengths\nwith symbolic AI's logical reasoning to tackle the dynamic challenges in\ncybersecurity, which also includes detailed NSAI techniques introduction for\ncyber professionals to explore the potential strengths of NSAI in NIDS. The\ninclusion of NSAI in NIDS marks potential advancements in both the detection\nand interpretation of intricate network threats, benefiting from the robust\npattern recognition of neural networks and the interpretive prowess of symbolic\nreasoning. By analyzing network traffic data types and machine learning\narchitectures, we illustrate NSAI's distinctive capability to offer more\nprofound insights into network behavior, thereby improving both detection\nperformance and the adaptability of the system. This merging of technologies\nnot only enhances the functionality of traditional NIDS but also sets the stage\nfor future developments in building more resilient, interpretable, and dynamic\ndefense mechanisms against advanced cyber threats. The continued progress in\nthis area is poised to transform NIDS into a system that is both responsive to\nknown threats and anticipatory of emerging, unseen ones.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.SC"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.00938v1",
    "published_date": "2024-06-03 02:24:01 UTC",
    "updated_date": "2024-06-03 02:24:01 UTC"
  },
  {
    "arxiv_id": "2407.01577v1",
    "title": "MOT: A Mixture of Actors Reinforcement Learning Method by Optimal Transport for Algorithmic Trading",
    "authors": [
      "Xi Cheng",
      "Jinghao Zhang",
      "Yunan Zeng",
      "Wenfang Xue"
    ],
    "abstract": "Algorithmic trading refers to executing buy and sell orders for specific\nassets based on automatically identified trading opportunities. Strategies\nbased on reinforcement learning (RL) have demonstrated remarkable capabilities\nin addressing algorithmic trading problems. However, the trading patterns\ndiffer among market conditions due to shifted distribution data. Ignoring\nmultiple patterns in the data will undermine the performance of RL. In this\npaper, we propose MOT,which designs multiple actors with disentangled\nrepresentation learning to model the different patterns of the market.\nFurthermore, we incorporate the Optimal Transport (OT) algorithm to allocate\nsamples to the appropriate actor by introducing a regularization loss term.\nAdditionally, we propose Pretrain Module to facilitate imitation learning by\naligning the outputs of actors with expert strategy and better balance the\nexploration and exploitation of RL. Experimental results on real futures market\ndata demonstrate that MOT exhibits excellent profit capabilities while\nbalancing risks. Ablation studies validate the effectiveness of the components\nof MOT.",
    "categories": [
      "q-fin.TR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-fin.TR",
    "comment": "13 pages, 5 figures, PAKDD2024 accepted",
    "pdf_url": "http://arxiv.org/pdf/2407.01577v1",
    "published_date": "2024-06-03 01:42:52 UTC",
    "updated_date": "2024-06-03 01:42:52 UTC"
  },
  {
    "arxiv_id": "2406.00922v3",
    "title": "MediQ: Question-Asking LLMs and a Benchmark for Reliable Interactive Clinical Reasoning",
    "authors": [
      "Shuyue Stella Li",
      "Vidhisha Balachandran",
      "Shangbin Feng",
      "Jonathan S. Ilgen",
      "Emma Pierson",
      "Pang Wei Koh",
      "Yulia Tsvetkov"
    ],
    "abstract": "Users typically engage with LLMs interactively, yet most existing benchmarks\nevaluate them in a static, single-turn format, posing reliability concerns in\ninteractive scenarios. We identify a key obstacle towards reliability: LLMs are\ntrained to answer any question, even with incomplete context or insufficient\nknowledge. In this paper, we propose to change the static paradigm to an\ninteractive one, develop systems that proactively ask questions to gather more\ninformation and respond reliably, and introduce an benchmark - MediQ - to\nevaluate question-asking ability in LLMs. MediQ simulates clinical interactions\nconsisting of a Patient System and an adaptive Expert System; with potentially\nincomplete initial information, the Expert refrains from making diagnostic\ndecisions when unconfident, and instead elicits missing details via follow-up\nquestions. We provide a pipeline to convert single-turn medical benchmarks into\nan interactive format. Our results show that directly prompting\nstate-of-the-art LLMs to ask questions degrades performance, indicating that\nadapting LLMs to proactive information-seeking settings is nontrivial. We\nexperiment with abstention strategies to better estimate model confidence and\ndecide when to ask questions, improving diagnostic accuracy by 22.3%; however,\nperformance still lags compared to an (unrealistic in practice) upper bound\nwith complete information upfront. Further analyses show improved interactive\nperformance with filtering irrelevant contexts and reformatting conversations.\nOverall, we introduce a novel problem towards LLM reliability, an interactive\nMediQ benchmark and a novel question-asking system, and highlight directions to\nextend LLMs' information-seeking abilities in critical domains.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "29 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2406.00922v3",
    "published_date": "2024-06-03 01:32:52 UTC",
    "updated_date": "2024-11-07 18:59:30 UTC"
  },
  {
    "arxiv_id": "2406.02608v1",
    "title": "PPINtonus: Early Detection of Parkinson's Disease Using Deep-Learning Tonal Analysis",
    "authors": [
      "Varun Reddy"
    ],
    "abstract": "PPINtonus is a system for the early detection of Parkinson's Disease (PD)\nutilizing deep-learning tonal analysis, providing a cost-effective and\naccessible alternative to traditional neurological examinations. Partnering\nwith the Parkinson's Voice Project (PVP), PPINtonus employs a semi-supervised\nconditional generative adversarial network to generate synthetic data points,\nenhancing the training dataset for a multi-layered deep neural network.\nCombined with PRAAT phonetics software, this network accurately assesses\nbiomedical voice measurement values from a simple 120-second vocal test\nperformed with a standard microphone in typical household noise conditions. The\nmodel's performance was validated using a confusion matrix, achieving an\nimpressive 92.5 \\% accuracy with a low false negative rate. PPINtonus\ndemonstrated a precision of 92.7 \\%, making it a reliable tool for early PD\ndetection. The non-intrusive and efficient methodology of PPINtonus can\nsignificantly benefit developing countries by enabling early diagnosis and\nimproving the quality of life for millions of PD patients through timely\nintervention and management.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.02608v1",
    "published_date": "2024-06-03 01:07:42 UTC",
    "updated_date": "2024-06-03 01:07:42 UTC"
  },
  {
    "arxiv_id": "2406.00914v1",
    "title": "Wasserstein gradient flow for optimal probability measure decomposition",
    "authors": [
      "Jiangze Han",
      "Christopher Thomas Ryan",
      "Xin T. Tong"
    ],
    "abstract": "We examine the infinite-dimensional optimization problem of finding a\ndecomposition of a probability measure into K probability sub-measures to\nminimize specific loss functions inspired by applications in clustering and\nuser grouping. We analytically explore the structures of the support of optimal\nsub-measures and introduce algorithms based on Wasserstein gradient flow,\ndemonstrating their convergence. Numerical results illustrate the\nimplementability of our algorithms and provide further insights.",
    "categories": [
      "math.OC",
      "cs.AI"
    ],
    "primary_category": "math.OC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.00914v1",
    "published_date": "2024-06-03 00:47:32 UTC",
    "updated_date": "2024-06-03 00:47:32 UTC"
  },
  {
    "arxiv_id": "2406.01638v5",
    "title": "TimeCMA: Towards LLM-Empowered Multivariate Time Series Forecasting via Cross-Modality Alignment",
    "authors": [
      "Chenxi Liu",
      "Qianxiong Xu",
      "Hao Miao",
      "Sun Yang",
      "Lingzheng Zhang",
      "Cheng Long",
      "Ziyue Li",
      "Rui Zhao"
    ],
    "abstract": "Multivariate time series forecasting (MTSF) aims to learn temporal dynamics\namong variables to forecast future time series. Existing statistical and deep\nlearning-based methods suffer from limited learnable parameters and small-scale\ntraining data. Recently, large language models (LLMs) combining time series\nwith textual prompts have achieved promising performance in MTSF. However, we\ndiscovered that current LLM-based solutions fall short in learning disentangled\nembeddings. We introduce TimeCMA, an intuitive yet effective framework for MTSF\nvia cross-modality alignment. Specifically, we present a dual-modality encoding\nwith two branches: the time series encoding branch extracts disentangled yet\nweak time series embeddings, and the LLM-empowered encoding branch wraps the\nsame time series with text as prompts to obtain entangled yet robust prompt\nembeddings. As a result, such a cross-modality alignment retrieves both\ndisentangled and robust time series embeddings, \"the best of two worlds\", from\nthe prompt embeddings based on time series and prompt modality similarities. As\nanother key design, to reduce the computational costs from time series with\ntheir length textual prompts, we design an effective prompt to encourage the\nmost essential temporal information to be encapsulated in the last token: only\nthe last token is passed to downstream prediction. We further store the last\ntoken embeddings to accelerate inference speed. Extensive experiments on eight\nreal datasets demonstrate that TimeCMA outperforms state-of-the-arts.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted as an Oral Presentation at AAAI 2025 (Main Technical Track)",
    "pdf_url": "http://arxiv.org/pdf/2406.01638v5",
    "published_date": "2024-06-03 00:27:29 UTC",
    "updated_date": "2025-03-29 08:44:30 UTC"
  }
]