[
  {
    "arxiv_id": "2408.12767v1",
    "title": "When In-memory Computing Meets Spiking Neural Networks -- A Perspective on Device-Circuit-System-and-Algorithm Co-design",
    "authors": [
      "Abhishek Moitra",
      "Abhiroop Bhattacharjee",
      "Yuhang Li",
      "Youngeun Kim",
      "Priyadarshini Panda"
    ],
    "abstract": "This review explores the intersection of bio-plausible artificial\nintelligence in the form of Spiking Neural Networks (SNNs) with the analog\nIn-Memory Computing (IMC) domain, highlighting their collective potential for\nlow-power edge computing environments. Through detailed investigation at the\ndevice, circuit, and system levels, we highlight the pivotal synergies between\nSNNs and IMC architectures. Additionally, we emphasize the critical need for\ncomprehensive system-level analyses, considering the inter-dependencies between\nalgorithms, devices, circuit & system parameters, crucial for optimal\nperformance. An in-depth analysis leads to identification of key system-level\nbottlenecks arising from device limitations which can be addressed using\nSNN-specific algorithm-hardware co-design techniques. This review underscores\nthe imperative for holistic device to system design space co-exploration,\nhighlighting the critical aspects of hardware and algorithm research endeavors\nfor low-power neuromorphic solutions.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.AR",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "19 Pages, 13 Figures",
    "pdf_url": "http://arxiv.org/pdf/2408.12767v1",
    "published_date": "2024-08-22 23:45:40 UTC",
    "updated_date": "2024-08-22 23:45:40 UTC"
  },
  {
    "arxiv_id": "2408.12763v2",
    "title": "Assessing Modality Bias in Video Question Answering Benchmarks with Multimodal Large Language Models",
    "authors": [
      "Jean Park",
      "Kuk Jin Jang",
      "Basam Alasaly",
      "Sriharsha Mopidevi",
      "Andrew Zolensky",
      "Eric Eaton",
      "Insup Lee",
      "Kevin Johnson"
    ],
    "abstract": "Multimodal large language models (MLLMs) can simultaneously process visual,\ntextual, and auditory data, capturing insights that complement human analysis.\nHowever, existing video question-answering (VidQA) benchmarks and datasets\noften exhibit a bias toward a single modality, despite the goal of requiring\nadvanced reasoning skills that integrate diverse modalities to answer the\nqueries. In this work, we introduce the modality importance score (MIS) to\nidentify such bias. It is designed to assess which modality embeds the\nnecessary information to answer the question. Additionally, we propose an\ninnovative method using state-of-the-art MLLMs to estimate the modality\nimportance, which can serve as a proxy for human judgments of modality\nperception. With this MIS, we demonstrate the presence of unimodal bias and the\nscarcity of genuinely multimodal questions in existing datasets. We further\nvalidate the modality importance score with multiple ablation studies to\nevaluate the performance of MLLMs on permuted feature sets. Our results\nindicate that current models do not effectively integrate information due to\nmodality imbalance in existing datasets. Our proposed MLLM-derived MIS can\nguide the curation of modality-balanced datasets that advance multimodal\nlearning and enhance MLLMs' capabilities to understand and utilize synergistic\nrelations across modalities.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12763v2",
    "published_date": "2024-08-22 23:32:42 UTC",
    "updated_date": "2024-12-19 19:37:44 UTC"
  },
  {
    "arxiv_id": "2408.12762v2",
    "title": "Visual Verity in AI-Generated Imagery: Computational Metrics and Human-Centric Analysis",
    "authors": [
      "Memoona Aziz",
      "Umair Rehman",
      "Syed Ali Safi",
      "Amir Zaib Abbasi"
    ],
    "abstract": "The rapid advancements in AI technologies have revolutionized the production\nof graphical content across various sectors, including entertainment,\nadvertising, and e-commerce. These developments have spurred the need for\nrobust evaluation methods to assess the quality and realism of AI-generated\nimages. To address this, we conducted three studies. First, we introduced and\nvalidated a questionnaire called Visual Verity, which measures photorealism,\nimage quality, and text-image alignment. Second, we applied this questionnaire\nto assess images from AI models (DALL-E2, DALL-E3, GLIDE, Stable Diffusion) and\ncamera-generated images, revealing that camera-generated images excelled in\nphotorealism and text-image alignment, while AI models led in image quality. We\nalso analyzed statistical properties, finding that camera-generated images\nscored lower in hue, saturation, and brightness. Third, we evaluated\ncomputational metrics' alignment with human judgments, identifying MS-SSIM and\nCLIP as the most consistent with human assessments. Additionally, we proposed\nthe Neural Feature Similarity Score (NFSS) for assessing image quality. Our\nfindings highlight the need for refining computational metrics to better\ncapture human visual perception, thereby enhancing AI-generated content\nevaluation.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12762v2",
    "published_date": "2024-08-22 23:29:07 UTC",
    "updated_date": "2024-09-01 17:41:09 UTC"
  },
  {
    "arxiv_id": "2408.12748v1",
    "title": "SLM Meets LLM: Balancing Latency, Interpretability and Consistency in Hallucination Detection",
    "authors": [
      "Mengya Hu",
      "Rui Xu",
      "Deren Lei",
      "Yaxi Li",
      "Mingyu Wang",
      "Emily Ching",
      "Eslam Kamal",
      "Alex Deng"
    ],
    "abstract": "Large language models (LLMs) are highly capable but face latency challenges\nin real-time applications, such as conducting online hallucination detection.\nTo overcome this issue, we propose a novel framework that leverages a small\nlanguage model (SLM) classifier for initial detection, followed by a LLM as\nconstrained reasoner to generate detailed explanations for detected\nhallucinated content. This study optimizes the real-time interpretable\nhallucination detection by introducing effective prompting techniques that\nalign LLM-generated explanations with SLM decisions. Empirical experiment\nresults demonstrate its effectiveness, thereby enhancing the overall user\nexperience.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "preprint under review",
    "pdf_url": "http://arxiv.org/pdf/2408.12748v1",
    "published_date": "2024-08-22 22:13:13 UTC",
    "updated_date": "2024-08-22 22:13:13 UTC"
  },
  {
    "arxiv_id": "2408.12742v1",
    "title": "TReX- Reusing Vision Transformer's Attention for Efficient Xbar-based Computing",
    "authors": [
      "Abhishek Moitra",
      "Abhiroop Bhattacharjee",
      "Youngeun Kim",
      "Priyadarshini Panda"
    ],
    "abstract": "Due to the high computation overhead of Vision Transformers (ViTs), In-memory\nComputing architectures are being researched towards energy-efficient\ndeployment in edge-computing scenarios. Prior works have proposed efficient\nalgorithm-hardware co-design and IMC-architectural improvements to improve the\nenergy-efficiency of IMC-implemented ViTs. However, all prior works have\nneglected the overhead and co-depencence of attention blocks on the\naccuracy-energy-delay-area of IMC-implemented ViTs. To this end, we propose\nTReX- an attention-reuse-driven ViT optimization framework that effectively\nperforms attention reuse in ViT models to achieve optimal\naccuracy-energy-delay-area tradeoffs. TReX optimally chooses the transformer\nencoders for attention reuse to achieve near iso-accuracy performance while\nmeeting the user-specified delay requirement. Based on our analysis on the\nImagenet-1k dataset, we find that TReX achieves 2.3x (2.19x) EDAP reduction and\n1.86x (1.79x) TOPS/mm2 improvement with ~1% accuracy drop in case of DeiT-S\n(LV-ViT-S) ViT models. Additionally, TReX achieves high accuracy at high EDAP\nreduction compared to state-of-the-art token pruning and weight sharing\napproaches. On NLP tasks such as CoLA, TReX leads to 2% higher non-ideal\naccuracy compared to baseline at 1.6x lower EDAP.",
    "categories": [
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.AI",
    "comment": "12 pages",
    "pdf_url": "http://arxiv.org/pdf/2408.12742v1",
    "published_date": "2024-08-22 21:51:38 UTC",
    "updated_date": "2024-08-22 21:51:38 UTC"
  },
  {
    "arxiv_id": "2408.12734v1",
    "title": "Towards measuring fairness in speech recognition: Fair-Speech dataset",
    "authors": [
      "Irina-Elena Veliche",
      "Zhuangqun Huang",
      "Vineeth Ayyat Kochaniyan",
      "Fuchun Peng",
      "Ozlem Kalinli",
      "Michael L. Seltzer"
    ],
    "abstract": "The current public datasets for speech recognition (ASR) tend not to focus\nspecifically on the fairness aspect, such as performance across different\ndemographic groups. This paper introduces a novel dataset, Fair-Speech, a\npublicly released corpus to help researchers evaluate their ASR models for\naccuracy across a diverse set of self-reported demographic information, such as\nage, gender, ethnicity, geographic variation and whether the participants\nconsider themselves native English speakers. Our dataset includes approximately\n26.5K utterances in recorded speech by 593 people in the United States, who\nwere paid to record and submit audios of themselves saying voice commands. We\nalso provide ASR baselines, including on models trained on transcribed and\nuntranscribed social media videos and open source models.",
    "categories": [
      "cs.AI",
      "cs.CY",
      "cs.SD",
      "eess.AS",
      "stat.ML"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12734v1",
    "published_date": "2024-08-22 20:55:17 UTC",
    "updated_date": "2024-08-22 20:55:17 UTC"
  },
  {
    "arxiv_id": "2408.12733v2",
    "title": "SQL-GEN: Bridging the Dialect Gap for Text-to-SQL Via Synthetic Data And Model Merging",
    "authors": [
      "Mohammadreza Pourreza",
      "Ruoxi Sun",
      "Hailong Li",
      "Lesly Miculicich",
      "Tomas Pfister",
      "Sercan O. Arik"
    ],
    "abstract": "Recent advances in Text-to-SQL have largely focused on the SQLite dialect,\nneglecting the diverse landscape of SQL dialects like BigQuery and PostgreSQL.\nThis limitation is due to the diversity in SQL syntaxes and functions, along\nwith the high cost of collecting and curating SQL-specific training data. To\naddress this, we introduce SQL-GEN, a framework for generating high-quality\nsynthetic training data for any SQL dialect, guided by readily available\ndialect-specific tutorials. SQL-GEN significantly improves cross-dialect\nText-to-SQL performance, boosting execution accuracy by up to 20\\% over\nexisting methods. This performance gain narrows the gap with models trained on\nlarge-scale human-annotated data. Furthermore, combining synthetic data from\nSQL-GEN with human-annotated data yields additional improvements of up to\n5.6\\%. To unify multi-dialect capabilities within a single model, we propose a\nnovel Mixture-of-Experts (MoE) initialization that leverages the shared\nknowledge across dialects. Our approach merges self-attention layers from\ndialect-specific models and initializes expert gates using dialect-specific\nkeywords. This leads to a versatile model optimized for multiple SQL dialects,\noutperforming single-dialect models and significantly enhancing overall\nperformance.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.DB",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12733v2",
    "published_date": "2024-08-22 20:50:48 UTC",
    "updated_date": "2024-10-02 18:19:15 UTC"
  },
  {
    "arxiv_id": "2408.12727v1",
    "title": "BankTweak: Adversarial Attack against Multi-Object Trackers by Manipulating Feature Banks",
    "authors": [
      "Woojin Shin",
      "Donghwa Kang",
      "Daejin Choi",
      "Brent Kang",
      "Jinkyu Lee",
      "Hyeongboo Baek"
    ],
    "abstract": "Multi-object tracking (MOT) aims to construct moving trajectories for\nobjects, and modern multi-object trackers mainly utilize the\ntracking-by-detection methodology. Initial approaches to MOT attacks primarily\naimed to degrade the detection quality of the frames under attack, thereby\nreducing accuracy only in those specific frames, highlighting a lack of\n\\textit{efficiency}. To improve efficiency, recent advancements manipulate\nobject positions to cause persistent identity (ID) switches during the\nassociation phase, even after the attack ends within a few frames. However,\nthese position-manipulating attacks have inherent limitations, as they can be\neasily counteracted by adjusting distance-related parameters in the association\nphase, revealing a lack of \\textit{robustness}. In this paper, we present\n\\textsf{BankTweak}, a novel adversarial attack designed for MOT trackers, which\nfeatures efficiency and robustness. \\textsf{BankTweak} focuses on the feature\nextractor in the association phase and reveals vulnerability in the Hungarian\nmatching method used by feature-based MOT systems. Exploiting the\nvulnerability, \\textsf{BankTweak} induces persistent ID switches (addressing\n\\textit{efficiency}) even after the attack ends by strategically injecting\naltered features into the feature banks without modifying object positions\n(addressing \\textit{robustness}). To demonstrate the applicability, we apply\n\\textsf{BankTweak} to three multi-object trackers (DeepSORT, StrongSORT, and\nMOTDT) with one-stage, two-stage, anchor-free, and transformer detectors.\nExtensive experiments on the MOT17 and MOT20 datasets show that our method\nsubstantially surpasses existing attacks, exposing the vulnerability of the\ntracking-by-detection framework to \\textsf{BankTweak}.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12727v1",
    "published_date": "2024-08-22 20:35:46 UTC",
    "updated_date": "2024-08-22 20:35:46 UTC"
  },
  {
    "arxiv_id": "2408.12720v1",
    "title": "Generating Realistic X-ray Scattering Images Using Stable Diffusion and Human-in-the-loop Annotations",
    "authors": [
      "Zhuowen Zhao",
      "Xiaoya Chong",
      "Tanny Chavez",
      "Alexander Hexemer"
    ],
    "abstract": "We fine-tuned a foundational stable diffusion model using X-ray scattering\nimages and their corresponding descriptions to generate new scientific images\nfrom given prompts. However, some of the generated images exhibit significant\nunrealistic artifacts, commonly known as \"hallucinations\". To address this\nissue, we trained various computer vision models on a dataset composed of 60%\nhuman-approved generated images and 40% experimental images to detect\nunrealistic images. The classified images were then reviewed and corrected by\nhuman experts, and subsequently used to further refine the classifiers in next\nrounds of training and inference. Our evaluations demonstrate the feasibility\nof generating high-fidelity, domain-specific images using a fine-tuned\ndiffusion model. We anticipate that generative AI will play a crucial role in\nenhancing data augmentation and driving the development of digital twins in\nscientific research facilities.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12720v1",
    "published_date": "2024-08-22 20:23:04 UTC",
    "updated_date": "2024-08-22 20:23:04 UTC"
  },
  {
    "arxiv_id": "2408.13284v1",
    "title": "From Radiologist Report to Image Label: Assessing Latent Dirichlet Allocation in Training Neural Networks for Orthopedic Radiograph Classification",
    "authors": [
      "Jakub Olczak",
      "Max Gordon"
    ],
    "abstract": "Background: Radiography (X-rays) is the dominant modality in orthopedics, and\nimproving the interpretation of radiographs is clinically relevant. Machine\nlearning (ML) has revolutionized data analysis and has been applied to\nmedicine, with some success, in the form of natural language processing (NLP)\nand artificial neural networks (ANN). Latent Dirichlet allocation (LDA) is an\nNLP method that automatically categorizes documents into topics. Successfully\napplying ML to orthopedic radiography could enable the creation of\ncomputer-aided decision systems for use in the clinic. We studied how an\nautomated ML pipeline could classify orthopedic trauma radiographs from\nradiologist reports. Methods: Wrist and ankle radiographs from Danderyd\nHospital in Sweden taken between 2002 and 2015, with radiologist reports. LDA\nwas used to create image labels for radiographs from the radiologist reports.\nRadiographs and labels were used to train an image recognition ANN. The ANN\noutcomes were manually reviewed to get an accurate estimate of the method's\nutility and accuracy. Results: Image Labels generated via LDA could\nsuccessfully train the ANN. The ANN reached an accuracy between 91% and 60%\ncompared to a gold standard, depending on the label. Conclusions: We found that\nLDA was unsuited to label orthopedic radiographs from reports with high\naccuracy. However, despite this, the ANN could learn to detect some features in\nradiographs with high accuracy. The study also illustrates how ML and ANN can\nbe applied to medical research.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "This article is an abridged version of a 2016 master's thesis at the\n  Karolinska Institute. The original is available upon request",
    "pdf_url": "http://arxiv.org/pdf/2408.13284v1",
    "published_date": "2024-08-22 19:47:25 UTC",
    "updated_date": "2024-08-22 19:47:25 UTC"
  },
  {
    "arxiv_id": "2408.12695v1",
    "title": "Learning Valid Dual Bounds in Constraint Programming: Boosted Lagrangian Decomposition with Self-Supervised Learning",
    "authors": [
      "Swann Bessa",
      "Darius Dabert",
      "Max Bourgeat",
      "Louis-Martin Rousseau",
      "Quentin Cappart"
    ],
    "abstract": "Lagrangian decomposition (LD) is a relaxation method that provides a dual\nbound for constrained optimization problems by decomposing them into more\nmanageable sub-problems. This bound can be used in branch-and-bound algorithms\nto prune the search space effectively. In brief, a vector of Lagrangian\nmultipliers is associated with each sub-problem, and an iterative procedure\n(e.g., a sub-gradient optimization) adjusts these multipliers to find the\ntightest bound. Initially applied to integer programming, Lagrangian\ndecomposition also had success in constraint programming due to its versatility\nand the fact that global constraints provide natural sub-problems. However, the\nnon-linear and combinatorial nature of sub-problems in constraint programming\nmakes it computationally intensive to optimize the Lagrangian multipliers with\nsub-gradient methods at each node of the tree search. This currently limits the\npracticality of LD as a general bounding mechanism for constraint programming.\nTo address this challenge, we propose a self-supervised learning approach that\nleverages neural networks to generate multipliers directly, yielding tight\nbounds. This approach significantly reduces the number of sub-gradient\noptimization steps required, enhancing the pruning efficiency and reducing the\nexecution time of constraint programming solvers. This contribution is one of\nthe few that leverage learning to enhance bounding mechanisms on the dual side,\na critical element in the design of combinatorial solvers. To our knowledge,\nthis work presents the first generic method for learning valid dual bounds in\nconstraint programming.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12695v1",
    "published_date": "2024-08-22 19:26:29 UTC",
    "updated_date": "2024-08-22 19:26:29 UTC"
  },
  {
    "arxiv_id": "2408.12692v2",
    "title": "Rethinking Training for De-biasing Text-to-Image Generation: Unlocking the Potential of Stable Diffusion",
    "authors": [
      "Eunji Kim",
      "Siwon Kim",
      "Minjun Park",
      "Rahim Entezari",
      "Sungroh Yoon"
    ],
    "abstract": "Recent advancements in text-to-image models, such as Stable Diffusion, show\nsignificant demographic biases. Existing de-biasing techniques rely heavily on\nadditional training, which imposes high computational costs and risks of\ncompromising core image generation functionality. This hinders them from being\nwidely adopted to real-world applications. In this paper, we explore Stable\nDiffusion's overlooked potential to reduce bias without requiring additional\ntraining. Through our analysis, we uncover that initial noises associated with\nminority attributes form \"minority regions\" rather than scattered. We view\nthese \"minority regions\" as opportunities in SD to reduce bias. To unlock the\npotential, we propose a novel de-biasing method called 'weak guidance,'\ncarefully designed to guide a random noise to the minority regions without\ncompromising semantic integrity. Through analysis and experiments on various\nversions of SD, we demonstrate that our proposed approach effectively reduces\nbias without additional training, achieving both efficiency and preservation of\ncore image generation functionality.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "19 pages; First two authors contributed equally; Accepted at CVPR\n  2025",
    "pdf_url": "http://arxiv.org/pdf/2408.12692v2",
    "published_date": "2024-08-22 19:12:52 UTC",
    "updated_date": "2025-03-27 07:52:45 UTC"
  },
  {
    "arxiv_id": "2408.12682v1",
    "title": "MultiMed: Massively Multimodal and Multitask Medical Understanding",
    "authors": [
      "Shentong Mo",
      "Paul Pu Liang"
    ],
    "abstract": "Biomedical data is inherently multimodal, consisting of electronic health\nrecords, medical imaging, digital pathology, genome sequencing, wearable\nsensors, and more. The application of artificial intelligence tools to these\nmultifaceted sensing technologies has the potential to revolutionize the\nprognosis, diagnosis, and management of human health and disease. However,\ncurrent approaches to biomedical AI typically only train and evaluate with one\nor a small set of medical modalities and tasks. This limitation hampers the\ndevelopment of comprehensive tools that can leverage the rich interconnected\ninformation across many heterogeneous biomedical sensors. To address this\nchallenge, we present MultiMed, a benchmark designed to evaluate and enable\nlarge-scale learning across a wide spectrum of medical modalities and tasks.\nMultiMed consists of 2.56 million samples across ten medical modalities such as\nmedical reports, pathology, genomics, and protein data, and is structured into\neleven challenging tasks, including disease prognosis, protein structure\nprediction, and medical question answering. Using MultiMed, we conduct\ncomprehensive experiments benchmarking state-of-the-art unimodal, multimodal,\nand multitask models. Our analysis highlights the advantages of training\nlarge-scale medical models across many related modalities and tasks. Moreover,\nMultiMed enables studies of generalization across related medical concepts,\nrobustness to real-world noisy data and distribution shifts, and novel modality\ncombinations to improve prediction performance. MultiMed will be publicly\navailable and regularly updated and welcomes inputs from the community.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.MM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12682v1",
    "published_date": "2024-08-22 18:41:36 UTC",
    "updated_date": "2024-08-22 18:41:36 UTC"
  },
  {
    "arxiv_id": "2408.12680v2",
    "title": "Can LLMs Understand Social Norms in Autonomous Driving Games?",
    "authors": [
      "Boxuan Wang",
      "Haonan Duan",
      "Yanhao Feng",
      "Xu Chen",
      "Yongjie Fu",
      "Zhaobin Mo",
      "Xuan Di"
    ],
    "abstract": "Social norm is defined as a shared standard of acceptable behavior in a\nsociety. The emergence of social norms fosters coordination among agents\nwithout any hard-coded rules, which is crucial for the large-scale deployment\nof AVs in an intelligent transportation system. This paper explores the\napplication of LLMs in understanding and modeling social norms in autonomous\ndriving games. We introduce LLMs into autonomous driving games as intelligent\nagents who make decisions according to text prompts. These agents are referred\nto as LLM-based agents. Our framework involves LLM-based agents playing Markov\ngames in a multi-agent system (MAS), allowing us to investigate the emergence\nof social norms among individual agents. We aim to identify social norms by\ndesigning prompts and utilizing LLMs on textual information related to the\nenvironment setup and the observations of LLM-based agents. Using the OpenAI\nChat API powered by GPT-4.0, we conduct experiments to simulate interactions\nand evaluate the performance of LLM-based agents in two driving scenarios:\nunsignalized intersection and highway platoon. The results show that LLM-based\nagents can handle dynamically changing environments in Markov games, and social\nnorms evolve among LLM-based agents in both scenarios. In the intersection\ngame, LLM-based agents tend to adopt a conservative driving policy when facing\na potential car crash. The advantage of LLM-based agents in games lies in their\nstrong operability and analyzability, which facilitate experimental design.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12680v2",
    "published_date": "2024-08-22 18:39:00 UTC",
    "updated_date": "2024-09-01 05:24:15 UTC"
  },
  {
    "arxiv_id": "2408.12673v3",
    "title": "Enhancing Transferability of Adversarial Attacks with GE-AdvGAN+: A Comprehensive Framework for Gradient Editing",
    "authors": [
      "Zhibo Jin",
      "Jiayu Zhang",
      "Zhiyu Zhu",
      "Chenyu Zhang",
      "Jiahao Huang",
      "Jianlong Zhou",
      "Fang Chen"
    ],
    "abstract": "Transferable adversarial attacks pose significant threats to deep neural\nnetworks, particularly in black-box scenarios where internal model information\nis inaccessible. Studying adversarial attack methods helps advance the\nperformance of defense mechanisms and explore model vulnerabilities. These\nmethods can uncover and exploit weaknesses in models, promoting the development\nof more robust architectures. However, current methods for transferable attacks\noften come with substantial computational costs, limiting their deployment and\napplication, especially in edge computing scenarios. Adversarial generative\nmodels, such as Generative Adversarial Networks (GANs), are characterized by\ntheir ability to generate samples without the need for retraining after an\ninitial training phase. GE-AdvGAN, a recent method for transferable adversarial\nattacks, is based on this principle. In this paper, we propose a novel general\nframework for gradient editing-based transferable attacks, named GE-AdvGAN+,\nwhich integrates nearly all mainstream attack methods to enhance\ntransferability while significantly reducing computational resource\nconsumption. Our experiments demonstrate the compatibility and effectiveness of\nour framework. Compared to the baseline AdvGAN, our best-performing method,\nGE-AdvGAN++, achieves an average ASR improvement of 47.8. Additionally, it\nsurpasses the latest competing algorithm, GE-AdvGAN, with an average ASR\nincrease of 5.9. The framework also exhibits enhanced computational efficiency,\nachieving 2217.7 FPS, outperforming traditional methods such as BIM and\nMI-FGSM. The implementation code for our GE-AdvGAN+ framework is available at\nhttps://github.com/GEAdvGANP",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12673v3",
    "published_date": "2024-08-22 18:26:31 UTC",
    "updated_date": "2024-09-20 11:07:03 UTC"
  },
  {
    "arxiv_id": "2408.12670v1",
    "title": "Leveraging Information Consistency in Frequency and Spatial Domain for Adversarial Attacks",
    "authors": [
      "Zhibo Jin",
      "Jiayu Zhang",
      "Zhiyu Zhu",
      "Xinyi Wang",
      "Yiyun Huang",
      "Huaming Chen"
    ],
    "abstract": "Adversarial examples are a key method to exploit deep neural networks. Using\ngradient information, such examples can be generated in an efficient way\nwithout altering the victim model. Recent frequency domain transformation has\nfurther enhanced the transferability of such adversarial examples, such as\nspectrum simulation attack. In this work, we investigate the effectiveness of\nfrequency domain-based attacks, aligning with similar findings in the spatial\ndomain. Furthermore, such consistency between the frequency and spatial domains\nprovides insights into how gradient-based adversarial attacks induce\nperturbations across different domains, which is yet to be explored. Hence, we\npropose a simple, effective, and scalable gradient-based adversarial attack\nalgorithm leveraging the information consistency in both frequency and spatial\ndomains. We evaluate the algorithm for its effectiveness against different\nmodels. Extensive experiments demonstrate that our algorithm achieves\nstate-of-the-art results compared to other gradient-based algorithms. Our code\nis available at: https://github.com/LMBTough/FSA.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by PRICAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.12670v1",
    "published_date": "2024-08-22 18:24:08 UTC",
    "updated_date": "2024-08-22 18:24:08 UTC"
  },
  {
    "arxiv_id": "2408.12666v2",
    "title": "Benchmarking Counterfactual Interpretability in Deep Learning Models for Time Series Classification",
    "authors": [
      "Ziwen Kan",
      "Shahbaz Rezaei",
      "Xin Liu"
    ],
    "abstract": "The popularity of deep learning methods in the time series domain boosts\ninterest in interpretability studies, including counterfactual (CF) methods. CF\nmethods identify minimal changes in instances to alter the model predictions.\nDespite extensive research, no existing work benchmarks CF methods in the time\nseries domain. Additionally, the results reported in the literature are\ninconclusive due to the limited number of datasets and inadequate metrics. In\nthis work, we redesign quantitative metrics to accurately capture desirable\ncharacteristics in CFs. We specifically redesign the metrics for sparsity and\nplausibility and introduce a new metric for consistency. Combined with\nvalidity, generation time, and proximity, we form a comprehensive metric set.\nWe systematically benchmark 6 different CF methods on 20 univariate datasets\nand 10 multivariate datasets with 3 different classifiers. Results indicate\nthat the performance of CF methods varies across metrics and among different\nmodels. Finally, we provide case studies and a guideline for practical usage.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages, 27 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.12666v2",
    "published_date": "2024-08-22 18:17:26 UTC",
    "updated_date": "2024-10-10 02:52:38 UTC"
  },
  {
    "arxiv_id": "2408.12664v2",
    "title": "Multilevel Interpretability Of Artificial Neural Networks: Leveraging Framework And Methods From Neuroscience",
    "authors": [
      "Zhonghao He",
      "Jascha Achterberg",
      "Katie Collins",
      "Kevin Nejad",
      "Danyal Akarca",
      "Yinzhu Yang",
      "Wes Gurnee",
      "Ilia Sucholutsky",
      "Yuhan Tang",
      "Rebeca Ianov",
      "George Ogden",
      "Chole Li",
      "Kai Sandbrink",
      "Stephen Casper",
      "Anna Ivanova",
      "Grace W. Lindsay"
    ],
    "abstract": "As deep learning systems are scaled up to many billions of parameters,\nrelating their internal structure to external behaviors becomes very\nchallenging. Although daunting, this problem is not new: Neuroscientists and\ncognitive scientists have accumulated decades of experience analyzing a\nparticularly complex system - the brain. In this work, we argue that\ninterpreting both biological and artificial neural systems requires analyzing\nthose systems at multiple levels of analysis, with different analytic tools for\neach level. We first lay out a joint grand challenge among scientists who study\nthe brain and who study artificial neural networks: understanding how\ndistributed neural mechanisms give rise to complex cognition and behavior. We\nthen present a series of analytical tools that can be used to analyze\nbiological and artificial neural systems, organizing those tools according to\nMarr's three levels of analysis: computation/behavior,\nalgorithm/representation, and implementation. Overall, the multilevel\ninterpretability framework provides a principled way to tackle neural system\ncomplexity; links structure, computation, and behavior; clarifies assumptions\nand research priorities at each level; and paves the way toward a unified\neffort for understanding intelligent systems, may they be biological or\nartificial.",
    "categories": [
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12664v2",
    "published_date": "2024-08-22 18:17:20 UTC",
    "updated_date": "2024-08-26 02:35:50 UTC"
  },
  {
    "arxiv_id": "2408.12659v1",
    "title": "Disentangled Structural and Featural Representation for Task-Agnostic Graph Valuation",
    "authors": [
      "Ali Falahati",
      "Mohammad Mohammadi Amiri"
    ],
    "abstract": "With the emergence of data marketplaces, the demand for methods to assess the\nvalue of data has increased significantly. While numerous techniques have been\nproposed for this purpose, none have specifically addressed graphs as the main\ndata modality. Graphs are widely used across various fields, ranging from\nchemical molecules to social networks. In this study, we break down graphs into\ntwo main components: structural and featural, and we focus on evaluating data\nwithout relying on specific task-related metrics, making it applicable in\npractical scenarios where validation requirements may be lacking. We introduce\na novel framework called blind message passing, which aligns the seller's and\nbuyer's graphs using a shared node permutation based on graph matching. This\nallows us to utilize the graph Wasserstein distance to quantify the differences\nin the structural distribution of graph datasets, called the structural\ndisparities. We then consider featural aspects of buyers' and sellers' graphs\nfor data valuation and capture their statistical similarities and differences,\nreferred to as relevance and diversity, respectively. Our approach ensures that\nbuyers and sellers remain unaware of each other's datasets. Our experiments on\nreal datasets demonstrate the effectiveness of our approach in capturing the\nrelevance, diversity, and structural disparities of seller data for buyers,\nparticularly in graph-based data valuation scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "math.IT",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12659v1",
    "published_date": "2024-08-22 18:05:41 UTC",
    "updated_date": "2024-08-22 18:05:41 UTC"
  },
  {
    "arxiv_id": "2408.12658v2",
    "title": "Hierarchical Generative Modeling of Melodic Vocal Contours in Hindustani Classical Music",
    "authors": [
      "Nithya Shikarpur",
      "Krishna Maneesha Dendukuri",
      "Yusong Wu",
      "Antoine Caillon",
      "Cheng-Zhi Anna Huang"
    ],
    "abstract": "Hindustani music is a performance-driven oral tradition that exhibits the\nrendition of rich melodic patterns. In this paper, we focus on generative\nmodeling of singers' vocal melodies extracted from audio recordings, as the\nvoice is musically prominent within the tradition. Prior generative work in\nHindustani music models melodies as coarse discrete symbols which fails to\ncapture the rich expressive melodic intricacies of singing. Thus, we propose to\nuse a finely quantized pitch contour, as an intermediate representation for\nhierarchical audio modeling. We propose GaMaDHaNi, a modular two-level\nhierarchy, consisting of a generative model on pitch contours, and a pitch\ncontour to audio synthesis model. We compare our approach to non-hierarchical\naudio models and hierarchical models that use a self-supervised intermediate\nrepresentation, through a listening test and qualitative analysis. We also\nevaluate audio model's ability to faithfully represent the pitch contour input\nusing Pearson correlation coefficient. By using pitch contours as an\nintermediate representation, we show that our model may be better equipped to\nlisten and respond to musicians in a human-AI collaborative setting by\nhighlighting two potential interaction use cases (1) primed generation, and (2)\ncoarse pitch conditioning.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted at International Society for Music Information Retrieval\n  (ISMIR) 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.12658v2",
    "published_date": "2024-08-22 18:04:29 UTC",
    "updated_date": "2024-08-26 13:02:46 UTC"
  },
  {
    "arxiv_id": "2408.12598v3",
    "title": "ND-SDF: Learning Normal Deflection Fields for High-Fidelity Indoor Reconstruction",
    "authors": [
      "Ziyu Tang",
      "Weicai Ye",
      "Yifan Wang",
      "Di Huang",
      "Hujun Bao",
      "Tong He",
      "Guofeng Zhang"
    ],
    "abstract": "Neural implicit reconstruction via volume rendering has demonstrated its\neffectiveness in recovering dense 3D surfaces. However, it is non-trivial to\nsimultaneously recover meticulous geometry and preserve smoothness across\nregions with differing characteristics. To address this issue, previous methods\ntypically employ geometric priors, which are often constrained by the\nperformance of the prior models. In this paper, we propose ND-SDF, which learns\na Normal Deflection field to represent the angular deviation between the scene\nnormal and the prior normal. Unlike previous methods that uniformly apply\ngeometric priors on all samples, introducing significant bias in accuracy, our\nproposed normal deflection field dynamically learns and adapts the utilization\nof samples based on their specific characteristics, thereby improving both the\naccuracy and effectiveness of the model. Our method not only obtains smooth\nweakly textured regions such as walls and floors but also preserves the\ngeometric details of complex structures. In addition, we introduce a novel ray\nsampling strategy based on the deflection angle to facilitate the unbiased\nrendering process, which significantly improves the quality and accuracy of\nintricate surfaces, especially on thin structures. Consistent improvements on\nvarious challenging datasets demonstrate the superiority of our method.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12598v3",
    "published_date": "2024-08-22 17:59:01 UTC",
    "updated_date": "2025-04-08 15:24:36 UTC"
  },
  {
    "arxiv_id": "2408.12591v2",
    "title": "Differentiable Logic Programming for Distant Supervision",
    "authors": [
      "Akihiro Takemura",
      "Katsumi Inoue"
    ],
    "abstract": "We introduce a new method for integrating neural networks with logic\nprogramming in Neural-Symbolic AI (NeSy), aimed at learning with distant\nsupervision, in which direct labels are unavailable. Unlike prior methods, our\napproach does not depend on symbolic solvers for reasoning about missing\nlabels. Instead, it evaluates logical implications and constraints in a\ndifferentiable manner by embedding both neural network outputs and logic\nprograms into matrices. This method facilitates more efficient learning under\ndistant supervision. We evaluated our approach against existing methods while\nmaintaining a constant volume of training data. The findings indicate that our\nmethod not only matches or exceeds the accuracy of other methods across various\ntasks but also speeds up the learning process. These results highlight the\npotential of our approach to enhance both accuracy and learning efficiency in\nNeSy applications.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Updated Figure 1 and fixed the overlapping caption issue. 11 pages\n  including the appendix. To be published in ECAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.12591v2",
    "published_date": "2024-08-22 17:55:52 UTC",
    "updated_date": "2024-08-25 06:40:06 UTC"
  },
  {
    "arxiv_id": "2408.12590v2",
    "title": "xGen-VideoSyn-1: High-fidelity Text-to-Video Synthesis with Compressed Representations",
    "authors": [
      "Can Qin",
      "Congying Xia",
      "Krithika Ramakrishnan",
      "Michael Ryoo",
      "Lifu Tu",
      "Yihao Feng",
      "Manli Shu",
      "Honglu Zhou",
      "Anas Awadalla",
      "Jun Wang",
      "Senthil Purushwalkam",
      "Le Xue",
      "Yingbo Zhou",
      "Huan Wang",
      "Silvio Savarese",
      "Juan Carlos Niebles",
      "Zeyuan Chen",
      "Ran Xu",
      "Caiming Xiong"
    ],
    "abstract": "We present xGen-VideoSyn-1, a text-to-video (T2V) generation model capable of\nproducing realistic scenes from textual descriptions. Building on recent\nadvancements, such as OpenAI's Sora, we explore the latent diffusion model\n(LDM) architecture and introduce a video variational autoencoder (VidVAE).\nVidVAE compresses video data both spatially and temporally, significantly\nreducing the length of visual tokens and the computational demands associated\nwith generating long-sequence videos. To further address the computational\ncosts, we propose a divide-and-merge strategy that maintains temporal\nconsistency across video segments. Our Diffusion Transformer (DiT) model\nincorporates spatial and temporal self-attention layers, enabling robust\ngeneralization across different timeframes and aspect ratios. We have devised a\ndata processing pipeline from the very beginning and collected over 13M\nhigh-quality video-text pairs. The pipeline includes multiple steps such as\nclipping, text detection, motion estimation, aesthetics scoring, and dense\ncaptioning based on our in-house video-LLM model. Training the VidVAE and DiT\nmodels required approximately 40 and 642 H100 days, respectively. Our model\nsupports over 14-second 720p video generation in an end-to-end way and\ndemonstrates competitive performance against state-of-the-art T2V models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ECCV24 AI4VA",
    "pdf_url": "http://arxiv.org/pdf/2408.12590v2",
    "published_date": "2024-08-22 17:55:22 UTC",
    "updated_date": "2024-08-31 05:12:09 UTC"
  },
  {
    "arxiv_id": "2408.12638v1",
    "title": "AI-driven Transformer Model for Fault Prediction in Non-Linear Dynamic Automotive System",
    "authors": [
      "Priyanka Kumar"
    ],
    "abstract": "Fault detection in automotive engine systems is one of the most promising\nresearch areas. Several works have been done in the field of model-based fault\ndiagnosis. Many researchers have discovered more advanced statistical methods\nand algorithms for better fault detection on any automotive dynamic engine\nsystem. The gas turbines/diesel engines produce highly complex and huge data\nwhich are highly non-linear. So, researchers should come up with an automated\nsystem that is more resilient and robust enough to handle this huge, complex\ndata in highly non-linear dynamic automotive systems. Here, I present an\nAI-based fault classification and prediction model in the diesel engine that\ncan be applied to any highly non-linear dynamic automotive system. The main\ncontribution of this paper is the AI-based Transformer fault classification and\nprediction model in the diesel engine concerning the worldwide harmonic light\nvehicle test procedure (WLTP) driving cycle. This model used 27 input\ndimensions, 64 hidden dimensions with 2 layers, and 9 heads to create a\nclassifier with 12 output heads (one for fault-free data and 11 different fault\ntypes). This model was trained on the UTSA Arc High-Performance Compute (HPC)\ncluster with 5 NVIDIA V100 GPUs, 40-core CPUs, and 384GB RAM and achieved 70.01\n% accuracy on a held test set.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12638v1",
    "published_date": "2024-08-22 17:53:32 UTC",
    "updated_date": "2024-08-22 17:53:32 UTC"
  },
  {
    "arxiv_id": "2408.12637v1",
    "title": "Building and better understanding vision-language models: insights and future directions",
    "authors": [
      "Hugo Laurençon",
      "Andrés Marafioti",
      "Victor Sanh",
      "Léo Tronchon"
    ],
    "abstract": "The field of vision-language models (VLMs), which take images and texts as\ninputs and output texts, is rapidly evolving and has yet to reach consensus on\nseveral key aspects of the development pipeline, including data, architecture,\nand training methods. This paper can be seen as a tutorial for building a VLM.\nWe begin by providing a comprehensive overview of the current state-of-the-art\napproaches, highlighting the strengths and weaknesses of each, addressing the\nmajor challenges in the field, and suggesting promising research directions for\nunderexplored areas. We then walk through the practical steps to build\nIdefics3-8B, a powerful VLM that significantly outperforms its predecessor\nIdefics2-8B, while being trained efficiently, exclusively on open datasets, and\nusing a straightforward pipeline. These steps include the creation of Docmatix,\na dataset for improving document understanding capabilities, which is 240 times\nlarger than previously available datasets. We release the model along with the\ndatasets created for its training.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12637v1",
    "published_date": "2024-08-22 17:47:24 UTC",
    "updated_date": "2024-08-22 17:47:24 UTC"
  },
  {
    "arxiv_id": "2408.12581v1",
    "title": "Identifying the Best Arm in the Presence of Global Environment Shifts",
    "authors": [
      "Phurinut Srisawad",
      "Juergen Branke",
      "Long Tran-Thanh"
    ],
    "abstract": "This paper formulates a new Best-Arm Identification problem in the\nnon-stationary stochastic bandits setting, where the means of all arms are\nshifted in the same way due to a global influence of the environment. The aim\nis to identify the unique best arm across environmental change given a fixed\ntotal budget. While this setting can be regarded as a special case of\nAdversarial Bandits or Corrupted Bandits, we demonstrate that existing\nsolutions tailored to those settings do not fully utilise the nature of this\nglobal influence, and thus, do not work well in practice (despite their\ntheoretical guarantees). To overcome this issue, in this paper we develop a\nnovel selection policy that is consistent and robust in dealing with global\nenvironmental shifts. We then propose an allocation policy, LinLUCB, which\nexploits information about global shifts across all arms in each environment.\nEmpirical tests depict a significant improvement in our policies against other\nexisting methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Extended version of the paper accepted at the 27th European\n  Conference on Artificial Intelligence (ECAI 2024); Paper ID: M1125",
    "pdf_url": "http://arxiv.org/pdf/2408.12581v1",
    "published_date": "2024-08-22 17:47:01 UTC",
    "updated_date": "2024-08-22 17:47:01 UTC"
  },
  {
    "arxiv_id": "2408.12579v1",
    "title": "RuleAlign: Making Large Language Models Better Physicians with Diagnostic Rule Alignment",
    "authors": [
      "Xiaohan Wang",
      "Xiaoyan Yang",
      "Yuqi Zhu",
      "Yue Shen",
      "Jian Wang",
      "Peng Wei",
      "Lei Liang",
      "Jinjie Gu",
      "Huajun Chen",
      "Ningyu Zhang"
    ],
    "abstract": "Large Language Models (LLMs) like GPT-4, MedPaLM-2, and Med-Gemini achieve\nperformance competitively with human experts across various medical benchmarks.\nHowever, they still face challenges in making professional diagnoses akin to\nphysicians, particularly in efficiently gathering patient information and\nreasoning the final diagnosis. To this end, we introduce the RuleAlign\nframework, designed to align LLMs with specific diagnostic rules. We develop a\nmedical dialogue dataset comprising rule-based communications between patients\nand physicians and design an alignment learning approach through preference\nlearning. Experimental results demonstrate the effectiveness of the proposed\napproach. We hope that our work can serve as an inspiration for exploring the\npotential of LLMs as AI physicians.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Ongoing work",
    "pdf_url": "http://arxiv.org/pdf/2408.12579v1",
    "published_date": "2024-08-22 17:44:40 UTC",
    "updated_date": "2024-08-22 17:44:40 UTC"
  },
  {
    "arxiv_id": "2408.12578v2",
    "title": "A Percolation Model of Emergence: Analyzing Transformers Trained on a Formal Language",
    "authors": [
      "Ekdeep Singh Lubana",
      "Kyogo Kawaguchi",
      "Robert P. Dick",
      "Hidenori Tanaka"
    ],
    "abstract": "Increase in data, size, or compute can lead to sudden learning of specific\ncapabilities by a neural network -- a phenomenon often called \"emergence''.\nBeyond scientific understanding, establishing the causal factors underlying\nsuch emergent capabilities is crucial to enable risk regulation frameworks for\nAI. In this work, we seek inspiration from study of emergent properties in\nother fields and propose a phenomenological definition for the concept in the\ncontext of neural networks. Our definition implicates the acquisition of\ngeneral structures underlying the data-generating process as a cause of sudden\nperformance growth for specific, narrower tasks. We empirically investigate\nthis definition by proposing an experimental system grounded in a\ncontext-sensitive formal language and find that Transformers trained to perform\ntasks on top of strings from this language indeed exhibit emergent\ncapabilities. Specifically, we show that once the language's underlying grammar\nand context-sensitivity inducing structures are learned by the model,\nperformance on narrower tasks suddenly begins to improve. We then analogize our\nnetwork's learning dynamics with the process of percolation on a bipartite\ngraph, establishing a formal phase transition model that predicts the shift in\nthe point of emergence observed in our experiments when changing the data\nstructure. Overall, our experimental and theoretical frameworks yield a step\ntowards better defining, characterizing, and predicting emergence in neural\nnetworks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2408.12578v2",
    "published_date": "2024-08-22 17:44:22 UTC",
    "updated_date": "2024-09-07 20:10:28 UTC"
  },
  {
    "arxiv_id": "2408.12575v2",
    "title": "Enhanced Parking Perception by Multi-Task Fisheye Cross-view Transformers",
    "authors": [
      "Antonyo Musabini",
      "Ivan Novikov",
      "Sana Soula",
      "Christel Leonet",
      "Lihao Wang",
      "Rachid Benmokhtar",
      "Fabian Burger",
      "Thomas Boulay",
      "Xavier Perrotton"
    ],
    "abstract": "Current parking area perception algorithms primarily focus on detecting\nvacant slots within a limited range, relying on error-prone homographic\nprojection for both labeling and inference. However, recent advancements in\nAdvanced Driver Assistance System (ADAS) require interaction with end-users\nthrough comprehensive and intelligent Human-Machine Interfaces (HMIs). These\ninterfaces should present a complete perception of the parking area going from\ndistinguishing vacant slots' entry lines to the orientation of other parked\nvehicles. This paper introduces Multi-Task Fisheye Cross View Transformers (MT\nF-CVT), which leverages features from a four-camera fisheye Surround-view\nCamera System (SVCS) with multihead attentions to create a detailed Bird-Eye\nView (BEV) grid feature map. Features are processed by both a segmentation\ndecoder and a Polygon-Yolo based object detection decoder for parking slots and\nvehicles. Trained on data labeled using LiDAR, MT F-CVT positions objects\nwithin a 25m x 25m real open-road scenes with an average error of only 20 cm.\nOur larger model achieves an F-1 score of 0.89. Moreover the smaller model\noperates at 16 fps on an Nvidia Jetson Orin embedded board, with similar\ndetection results to the larger one. MT F-CVT demonstrates robust\ngeneralization capability across different vehicles and camera rig\nconfigurations. A demo video from an unseen vehicle and camera rig is available\nat: https://streamable.com/jjw54x.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "This paper is a preprint of a paper submitted to the 26th Irish\n  Machine Vision and Image Processing Conference (IMVIP 2024). If accepted, the\n  copy of record will be available at IET Digital Library",
    "pdf_url": "http://arxiv.org/pdf/2408.12575v2",
    "published_date": "2024-08-22 17:42:16 UTC",
    "updated_date": "2024-09-30 13:30:54 UTC"
  },
  {
    "arxiv_id": "2408.12574v4",
    "title": "MuMA-ToM: Multi-modal Multi-Agent Theory of Mind",
    "authors": [
      "Haojun Shi",
      "Suyu Ye",
      "Xinyu Fang",
      "Chuanyang Jin",
      "Leyla Isik",
      "Yen-Ling Kuo",
      "Tianmin Shu"
    ],
    "abstract": "Understanding people's social interactions in complex real-world scenarios\noften relies on intricate mental reasoning. To truly understand how and why\npeople interact with one another, we must infer the underlying mental states\nthat give rise to the social interactions, i.e., Theory of Mind reasoning in\nmulti-agent interactions. Additionally, social interactions are often\nmulti-modal -- we can watch people's actions, hear their conversations, and/or\nread about their past behaviors. For AI systems to successfully and safely\ninteract with people in real-world environments, they also need to understand\npeople's mental states as well as their inferences about each other's mental\nstates based on multi-modal information about their interactions. For this, we\nintroduce MuMA-ToM, a Multi-modal Multi-Agent Theory of Mind benchmark.\nMuMA-ToM is the first multi-modal Theory of Mind benchmark that evaluates\nmental reasoning in embodied multi-agent interactions. In MuMA-ToM, we provide\nvideo and text descriptions of people's multi-modal behavior in realistic\nhousehold environments. Based on the context, we then ask questions about\npeople's goals, beliefs, and beliefs about others' goals. We validated MuMA-ToM\nin a human experiment and provided a human baseline. We also proposed a novel\nmulti-modal, multi-agent ToM model, LIMP (Language model-based Inverse\nMulti-agent Planning). Our experimental results show that LIMP significantly\noutperforms state-of-the-art methods, including large multi-modal models (e.g.,\nGPT-4o, Gemini-1.5 Pro) and a recent multi-modal ToM model, BIP-ALM.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "AAAI-25 (Oral). Project website:\n  https://scai.cs.jhu.edu/projects/MuMA-ToM/ Code:\n  https://github.com/SCAI-JHU/MuMA-ToM",
    "pdf_url": "http://arxiv.org/pdf/2408.12574v4",
    "published_date": "2024-08-22 17:41:45 UTC",
    "updated_date": "2025-01-23 16:31:49 UTC"
  },
  {
    "arxiv_id": "2408.12568v2",
    "title": "Pruning By Explaining Revisited: Optimizing Attribution Methods to Prune CNNs and Transformers",
    "authors": [
      "Sayed Mohammad Vakilzadeh Hatefi",
      "Maximilian Dreyer",
      "Reduan Achtibat",
      "Thomas Wiegand",
      "Wojciech Samek",
      "Sebastian Lapuschkin"
    ],
    "abstract": "To solve ever more complex problems, Deep Neural Networks are scaled to\nbillions of parameters, leading to huge computational costs. An effective\napproach to reduce computational requirements and increase efficiency is to\nprune unnecessary components of these often over-parameterized networks.\nPrevious work has shown that attribution methods from the field of eXplainable\nAI serve as effective means to extract and prune the least relevant network\ncomponents in a few-shot fashion. We extend the current state by proposing to\nexplicitly optimize hyperparameters of attribution methods for the task of\npruning, and further include transformer-based networks in our analysis. Our\napproach yields higher model compression rates of large transformer- and\nconvolutional architectures (VGG, ResNet, ViT) compared to previous works,\nwhile still attaining high performance on ImageNet classification tasks. Here,\nour experiments indicate that transformers have a higher degree of\nover-parameterization compared to convolutional neural networks. Code is\navailable at https://github.com/erfanhatefi/Pruning-by-eXplaining-in-PyTorch.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted as a workshop paper at ECCV 2024, 26 pages (11 pages\n  manuscript, 3 pages references, 12 pages appendix)",
    "pdf_url": "http://arxiv.org/pdf/2408.12568v2",
    "published_date": "2024-08-22 17:35:18 UTC",
    "updated_date": "2024-10-23 17:53:24 UTC"
  },
  {
    "arxiv_id": "2408.12561v2",
    "title": "ssProp: Energy-Efficient Training for Convolutional Neural Networks with Scheduled Sparse Back Propagation",
    "authors": [
      "Lujia Zhong",
      "Shuo Huang",
      "Yonggang Shi"
    ],
    "abstract": "Recently, deep learning has made remarkable strides, especially with\ngenerative modeling, such as large language models and probabilistic diffusion\nmodels. However, training these models often involves significant computational\nresources, requiring billions of petaFLOPs. This high resource consumption\nresults in substantial energy usage and a large carbon footprint, raising\ncritical environmental concerns. Back-propagation (BP) is a major source of\ncomputational expense during training deep learning models. To advance research\non energy-efficient training and allow for sparse learning on any machine and\ndevice, we propose a general, energy-efficient convolution module that can be\nseamlessly integrated into any deep learning architecture. Specifically, we\nintroduce channel-wise sparsity with additional gradient selection schedulers\nduring backward based on the assumption that BP is often dense and inefficient,\nwhich can lead to over-fitting and high computational consumption. Our\nexperiments demonstrate that our approach reduces 40\\% computations while\npotentially improving model performance, validated on image classification and\ngeneration tasks. This reduction can lead to significant energy savings and a\nlower carbon footprint during the research and development phases of\nlarge-scale AI systems. Additionally, our method mitigates over-fitting in a\nmanner distinct from Dropout, allowing it to be combined with Dropout to\nfurther enhance model performance and reduce computational resource usage.\nExtensive experiments validate that our method generalizes to a variety of\ndatasets and tasks and is compatible with a wide range of deep learning\narchitectures and modules. Code is publicly available at\nhttps://github.com/lujiazho/ssProp.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by AAAI24 Workshop: Scalable and Efficient Artificial\n  Intelligence Systems",
    "pdf_url": "http://arxiv.org/pdf/2408.12561v2",
    "published_date": "2024-08-22 17:22:59 UTC",
    "updated_date": "2024-12-29 19:45:44 UTC"
  },
  {
    "arxiv_id": "2408.12560v1",
    "title": "Data Quality Antipatterns for Software Analytics",
    "authors": [
      "Aaditya Bhatia",
      "Dayi Lin",
      "Gopi Krishnan Rajbahadur",
      "Bram Adams",
      "Ahmed E. Hassan"
    ],
    "abstract": "Background: Data quality is vital in software analytics, particularly for\nmachine learning (ML) applications like software defect prediction (SDP).\nDespite the widespread use of ML in software engineering, the effect of data\nquality antipatterns on these models remains underexplored.\n  Objective: This study develops a taxonomy of ML-specific data quality\nantipatterns and assesses their impact on software analytics models'\nperformance and interpretation.\n  Methods: We identified eight types and 14 sub-types of ML-specific data\nquality antipatterns through a literature review. We conducted experiments to\ndetermine the prevalence of these antipatterns in SDP data (RQ1), assess how\ncleaning order affects model performance (RQ2), evaluate the impact of\nantipattern removal on performance (RQ3), and examine the consistency of\ninterpretation from models built with different antipatterns (RQ4).\n  Results: In our SDP case study, we identified nine antipatterns. Over 90% of\nthese overlapped at both row and column levels, complicating cleaning\nprioritization and risking excessive data removal. The order of cleaning\nsignificantly impacts ML model performance, with neural networks being more\nresilient to cleaning order changes than simpler models like logistic\nregression. Antipatterns such as Tailed Distributions and Class Overlap show a\nstatistically significant correlation with performance metrics when other\nantipatterns are cleaned. Models built with different antipatterns showed\nmoderate consistency in interpretation results.\n  Conclusion: The cleaning order of different antipatterns impacts ML model\nperformance. Five antipatterns have a statistically significant correlation\nwith model performance when others are cleaned. Additionally, model\ninterpretation is moderately affected by different data quality antipatterns.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12560v1",
    "published_date": "2024-08-22 17:21:09 UTC",
    "updated_date": "2024-08-22 17:21:09 UTC"
  },
  {
    "arxiv_id": "2408.12549v3",
    "title": "Modeling Time-Variant Responses of Optical Compressors with Selective State Space Models",
    "authors": [
      "Riccardo Simionato",
      "Stefano Fasciani"
    ],
    "abstract": "This paper presents a method for modeling optical dynamic range compressors\nusing deep neural networks with Selective State Space models. The proposed\napproach surpasses previous methods based on recurrent layers by employing a\nSelective State Space block to encode the input audio. It features a refined\ntechnique integrating Feature-wise Linear Modulation and Gated Linear Units to\nadjust the network dynamically, conditioning the compression's attack and\nrelease phases according to external parameters. The proposed architecture is\nwell-suited for low-latency and real-time applications, crucial in live audio\nprocessing. The method has been validated on the analog optical compressors\nTubeTech CL 1B and Teletronix LA-2A, which possess distinct characteristics.\nEvaluation is performed using quantitative metrics and subjective listening\ntests, comparing the proposed method with other state-of-the-art models.\nResults show that our black-box modeling methods outperform all others,\nachieving accurate emulation of the compression process for both seen and\nunseen settings during training. We further show a correlation between this\naccuracy and the sampling density of the control parameters in the dataset and\nidentify settings with fast attack and slow release as the most challenging to\nemulate.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Journal of the Audio Engineering Society",
    "pdf_url": "http://arxiv.org/pdf/2408.12549v3",
    "published_date": "2024-08-22 17:03:08 UTC",
    "updated_date": "2025-01-16 14:26:40 UTC"
  },
  {
    "arxiv_id": "2408.12534v1",
    "title": "Automatic Organ and Pan-cancer Segmentation in Abdomen CT: the FLARE 2023 Challenge",
    "authors": [
      "Jun Ma",
      "Yao Zhang",
      "Song Gu",
      "Cheng Ge",
      "Ershuai Wang",
      "Qin Zhou",
      "Ziyan Huang",
      "Pengju Lyu",
      "Jian He",
      "Bo Wang"
    ],
    "abstract": "Organ and cancer segmentation in abdomen Computed Tomography (CT) scans is\nthe prerequisite for precise cancer diagnosis and treatment. Most existing\nbenchmarks and algorithms are tailored to specific cancer types, limiting their\nability to provide comprehensive cancer analysis. This work presents the first\ninternational competition on abdominal organ and pan-cancer segmentation by\nproviding a large-scale and diverse dataset, including 4650 CT scans with\nvarious cancer types from over 40 medical centers. The winning team established\na new state-of-the-art with a deep learning-based cascaded framework, achieving\naverage Dice Similarity Coefficient scores of 92.3% for organs and 64.9% for\nlesions on the hidden multi-national testing set. The dataset and code of top\nteams are publicly available, offering a benchmark platform to drive further\ninnovations https://codalab.lisn.upsaclay.fr/competitions/12239.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "MICCAI 2024 FLARE Challenge Summary",
    "pdf_url": "http://arxiv.org/pdf/2408.12534v1",
    "published_date": "2024-08-22 16:38:45 UTC",
    "updated_date": "2024-08-22 16:38:45 UTC"
  },
  {
    "arxiv_id": "2408.12525v1",
    "title": "PCGRL+: Scaling, Control and Generalization in Reinforcement Learning Level Generators",
    "authors": [
      "Sam Earle",
      "Zehua Jiang",
      "Julian Togelius"
    ],
    "abstract": "Procedural Content Generation via Reinforcement Learning (PCGRL) has been\nintroduced as a means by which controllable designer agents can be trained\nbased only on a set of computable metrics acting as a proxy for the level's\nquality and key characteristics. While PCGRL offers a unique set of affordances\nfor game designers, it is constrained by the compute-intensive process of\ntraining RL agents, and has so far been limited to generating relatively small\nlevels. To address this issue of scale, we implement several PCGRL environments\nin Jax so that all aspects of learning and simulation happen in parallel on the\nGPU, resulting in faster environment simulation; removing the CPU-GPU transfer\nof information bottleneck during RL training; and ultimately resulting in\nsignificantly improved training speed. We replicate several key results from\nprior works in this new framework, letting models train for much longer than\npreviously studied, and evaluating their behavior after 1 billion timesteps.\nAiming for greater control for human designers, we introduce randomized level\nsizes and frozen \"pinpoints\" of pivotal game tiles as further ways of\ncountering overfitting. To test the generalization ability of learned\ngenerators, we evaluate models on large, out-of-distribution map sizes, and\nfind that partial observation sizes learn more robust design strategies.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 7 figures, 6 tables. Published at IEEE Conference on Games,\n  2024",
    "pdf_url": "http://arxiv.org/pdf/2408.12525v1",
    "published_date": "2024-08-22 16:30:24 UTC",
    "updated_date": "2024-08-22 16:30:24 UTC"
  },
  {
    "arxiv_id": "2408.12519v1",
    "title": "Advanced atom-level representations for protein flexibility prediction utilizing graph neural networks",
    "authors": [
      "Sina Sarparast",
      "Aldo Zaimi",
      "Maximilian Ebert",
      "Michael-Rock Goldsmith"
    ],
    "abstract": "Protein dynamics play a crucial role in many biological processes and drug\ninteractions. However, measuring, and simulating protein dynamics is\nchallenging and time-consuming. While machine learning holds promise in\ndeciphering the determinants of protein dynamics from structural information,\nmost existing methods for protein representation learning operate at the\nresidue level, ignoring the finer details of atomic interactions. In this work,\nwe propose for the first time to use graph neural networks (GNNs) to learn\nprotein representations at the atomic level and predict B-factors from protein\n3D structures. The B-factor reflects the atomic displacement of atoms in\nproteins, and can serve as a surrogate for protein flexibility. We compared\ndifferent GNN architectures to assess their performance. The Meta-GNN model\nachieves a correlation coefficient of 0.71 on a large and diverse test set of\nover 4k proteins (17M atoms) from the Protein Data Bank (PDB), outperforming\nprevious methods by a large margin. Our work demonstrates the potential of\nrepresentations learned by GNNs for protein flexibility prediction and other\nrelated tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12519v1",
    "published_date": "2024-08-22 16:15:13 UTC",
    "updated_date": "2024-08-22 16:15:13 UTC"
  },
  {
    "arxiv_id": "2408.12503v2",
    "title": "The Russian-focused embedders' exploration: ruMTEB benchmark and Russian embedding model design",
    "authors": [
      "Artem Snegirev",
      "Maria Tikhonova",
      "Anna Maksimova",
      "Alena Fenogenova",
      "Alexander Abramov"
    ],
    "abstract": "Embedding models play a crucial role in Natural Language Processing (NLP) by\ncreating text embeddings used in various tasks such as information retrieval\nand assessing semantic text similarity. This paper focuses on research related\nto embedding models in the Russian language. It introduces a new\nRussian-focused embedding model called ru-en-RoSBERTa and the ruMTEB benchmark,\nthe Russian version extending the Massive Text Embedding Benchmark (MTEB). Our\nbenchmark includes seven categories of tasks, such as semantic textual\nsimilarity, text classification, reranking, and retrieval.The research also\nassesses a representative set of Russian and multilingual models on the\nproposed benchmark. The findings indicate that the new model achieves results\nthat are on par with state-of-the-art models in Russian. We release the model\nru-en-RoSBERTa, and the ruMTEB framework comes with open-source code,\nintegration into the original framework and a public leaderboard.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "to appear in NAACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2408.12503v2",
    "published_date": "2024-08-22 15:53:23 UTC",
    "updated_date": "2025-02-03 12:53:11 UTC"
  },
  {
    "arxiv_id": "2408.12496v1",
    "title": "MEDCO: Medical Education Copilots Based on A Multi-Agent Framework",
    "authors": [
      "Hao Wei",
      "Jianing Qiu",
      "Haibao Yu",
      "Wu Yuan"
    ],
    "abstract": "Large language models (LLMs) have had a significant impact on diverse\nresearch domains, including medicine and healthcare. However, the potential of\nLLMs as copilots in medical education remains underexplored. Current\nAI-assisted educational tools are limited by their solitary learning approach\nand inability to simulate the multi-disciplinary and interactive nature of\nactual medical training. To address these limitations, we propose MEDCO\n(Medical EDucation COpilots), a novel multi-agent-based copilot system\nspecially developed to emulate real-world medical training environments. MEDCO\nincorporates three primary agents: an agentic patient, an expert doctor, and a\nradiologist, facilitating a multi-modal and interactive learning environment.\nOur framework emphasizes the learning of proficient question-asking skills,\nmulti-disciplinary collaboration, and peer discussions between students. Our\nexperiments show that simulated virtual students who underwent training with\nMEDCO not only achieved substantial performance enhancements comparable to\nthose of advanced models, but also demonstrated human-like learning behaviors\nand improvements, coupled with an increase in the number of learning samples.\nThis work contributes to medical education by introducing a copilot that\nimplements an interactive and collaborative learning approach. It also provides\nvaluable insights into the effectiveness of AI-integrated training paradigms.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12496v1",
    "published_date": "2024-08-22 15:41:58 UTC",
    "updated_date": "2024-08-22 15:41:58 UTC"
  },
  {
    "arxiv_id": "2408.12494v2",
    "title": "GenderCARE: A Comprehensive Framework for Assessing and Reducing Gender Bias in Large Language Models",
    "authors": [
      "Kunsheng Tang",
      "Wenbo Zhou",
      "Jie Zhang",
      "Aishan Liu",
      "Gelei Deng",
      "Shuai Li",
      "Peigui Qi",
      "Weiming Zhang",
      "Tianwei Zhang",
      "Nenghai Yu"
    ],
    "abstract": "Large language models (LLMs) have exhibited remarkable capabilities in\nnatural language generation, but they have also been observed to magnify\nsocietal biases, particularly those related to gender. In response to this\nissue, several benchmarks have been proposed to assess gender bias in LLMs.\nHowever, these benchmarks often lack practical flexibility or inadvertently\nintroduce biases. To address these shortcomings, we introduce GenderCARE, a\ncomprehensive framework that encompasses innovative Criteria, bias Assessment,\nReduction techniques, and Evaluation metrics for quantifying and mitigating\ngender bias in LLMs. To begin, we establish pioneering criteria for gender\nequality benchmarks, spanning dimensions such as inclusivity, diversity,\nexplainability, objectivity, robustness, and realisticity. Guided by these\ncriteria, we construct GenderPair, a novel pair-based benchmark designed to\nassess gender bias in LLMs comprehensively. Our benchmark provides standardized\nand realistic evaluations, including previously overlooked gender groups such\nas transgender and non-binary individuals. Furthermore, we develop effective\ndebiasing techniques that incorporate counterfactual data augmentation and\nspecialized fine-tuning strategies to reduce gender bias in LLMs without\ncompromising their overall performance. Extensive experiments demonstrate a\nsignificant reduction in various gender bias benchmarks, with reductions\npeaking at over 90% and averaging above 35% across 17 different LLMs.\nImportantly, these reductions come with minimal variability in mainstream\nlanguage tasks, remaining below 2%. By offering a realistic assessment and\ntailored reduction of gender biases, we hope that our GenderCARE can represent\na significant step towards achieving fairness and equity in LLMs. More details\nare available at https://github.com/kstanghere/GenderCARE-ccs24.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by ACM CCS 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.12494v2",
    "published_date": "2024-08-22 15:35:46 UTC",
    "updated_date": "2025-02-23 05:10:23 UTC"
  },
  {
    "arxiv_id": "2408.12491v2",
    "title": "AI in radiological imaging of soft-tissue and bone tumours: a systematic review evaluating against CLAIM and FUTURE-AI guidelines",
    "authors": [
      "Douwe J. Spaanderman",
      "Matthew Marzetti",
      "Xinyi Wan",
      "Andrew F. Scarsbrook",
      "Philip Robinson",
      "Edwin H. G. Oei",
      "Jacob J. Visser",
      "Robert Hemke",
      "Kirsten van Langevelde",
      "David F. Hanff",
      "Geert J. L. H. van Leenders",
      "Cornelis Verhoef",
      "Dirk J. Gruühagen",
      "Wiro J. Niessen",
      "Stefan Klein",
      "Martijn P. A. Starmans"
    ],
    "abstract": "Soft-tissue and bone tumours (STBT) are rare, diagnostically challenging\nlesions with variable clinical behaviours and treatment approaches. This\nsystematic review provides an overview of Artificial Intelligence (AI) methods\nusing radiological imaging for diagnosis and prognosis of these tumours,\nhighlighting challenges in clinical translation, and evaluating study alignment\nwith the Checklist for AI in Medical Imaging (CLAIM) and the FUTURE-AI\ninternational consensus guidelines for trustworthy and deployable AI to promote\nthe clinical translation of AI methods. The review covered literature from\nseveral bibliographic databases, including papers published before 17/07/2024.\nOriginal research in peer-reviewed journals focused on radiology-based AI for\ndiagnosing or prognosing primary STBT was included. Exclusion criteria were\nanimal, cadaveric, or laboratory studies, and non-English papers. Abstracts\nwere screened by two of three independent reviewers for eligibility. Eligible\npapers were assessed against guidelines by one of three independent reviewers.\nThe search identified 15,015 abstracts, from which 325 articles were included\nfor evaluation. Most studies performed moderately on CLAIM, averaging a score\nof 28.9$\\pm$7.5 out of 53, but poorly on FUTURE-AI, averaging 5.1$\\pm$2.1 out\nof 30. Imaging-AI tools for STBT remain at the proof-of-concept stage,\nindicating significant room for improvement. Future efforts by AI developers\nshould focus on design (e.g. define unmet clinical need, intended clinical\nsetting and how AI would be integrated in clinical workflow), development (e.g.\nbuild on previous work, explainability), evaluation (e.g. evaluating and\naddressing biases, evaluating AI against best practices), and data\nreproducibility and availability (making documented code and data publicly\navailable). Following these recommendations could improve clinical translation\nof AI methods.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "25 pages, 6 figures, 8 supplementary figures",
    "pdf_url": "http://arxiv.org/pdf/2408.12491v2",
    "published_date": "2024-08-22 15:31:48 UTC",
    "updated_date": "2025-03-31 13:58:36 UTC"
  },
  {
    "arxiv_id": "2408.12483v1",
    "title": "Not All Samples Should Be Utilized Equally: Towards Understanding and Improving Dataset Distillation",
    "authors": [
      "Shaobo Wang",
      "Yantai Yang",
      "Qilong Wang",
      "Kaixin Li",
      "Linfeng Zhang",
      "Junchi Yan"
    ],
    "abstract": "Dataset Distillation (DD) aims to synthesize a small dataset capable of\nperforming comparably to the original dataset. Despite the success of numerous\nDD methods, theoretical exploration of this area remains unaddressed. In this\npaper, we take an initial step towards understanding various matching-based DD\nmethods from the perspective of sample difficulty. We begin by empirically\nexamining sample difficulty, measured by gradient norm, and observe that\ndifferent matching-based methods roughly correspond to specific difficulty\ntendencies. We then extend the neural scaling laws of data pruning to DD to\ntheoretically explain these matching-based methods. Our findings suggest that\nprioritizing the synthesis of easier samples from the original dataset can\nenhance the quality of distilled datasets, especially in low IPC\n(image-per-class) settings. Based on our empirical observations and theoretical\nanalysis, we introduce the Sample Difficulty Correction (SDC) approach,\ndesigned to predominantly generate easier samples to achieve higher dataset\nquality. Our SDC can be seamlessly integrated into existing methods as a plugin\nwith minimal code adjustments. Experimental results demonstrate that adding SDC\ngenerates higher-quality distilled datasets across 7 distillation methods and 6\ndatasets.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12483v1",
    "published_date": "2024-08-22 15:20:32 UTC",
    "updated_date": "2024-08-22 15:20:32 UTC"
  },
  {
    "arxiv_id": "2408.12476v3",
    "title": "Predicting Solar Energy Generation with Machine Learning based on AQI and Weather Features",
    "authors": [
      "Arjun Shah",
      "Varun Viswanath",
      "Kashish Gandhi",
      "Nilesh Madhukar Patil"
    ],
    "abstract": "This paper addresses the pressing need for an accurate solar energy\nprediction model, which is crucial for efficient grid integration. We explore\nthe influence of the Air Quality Index and weather features on solar energy\ngeneration, employing advanced Machine Learning and Deep Learning techniques.\nOur methodology uses time series modeling and makes novel use of power\ntransform normalization and zero-inflated modeling. Various Machine Learning\nalgorithms and Conv2D Long Short-Term Memory model based Deep Learning models\nare applied to these transformations for precise predictions. Results\nunderscore the effectiveness of our approach, demonstrating enhanced prediction\naccuracy with Air Quality Index and weather features. We achieved a 0.9691\n$R^2$ Score, 0.18 MAE, 0.10 RMSE with Conv2D Long Short-Term Memory model,\nshowcasing the power transform technique's innovation in enhancing time series\nforecasting for solar energy generation. Such results help our research\ncontribute valuable insights to the synergy between Air Quality Index, weather\nfeatures, and Deep Learning techniques for solar energy prediction.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at AISD2024 : Second International Workshop on Artificial\n  Intelligence: Empowering Sustainable Development",
    "pdf_url": "http://arxiv.org/pdf/2408.12476v3",
    "published_date": "2024-08-22 15:13:44 UTC",
    "updated_date": "2024-10-03 20:29:26 UTC"
  },
  {
    "arxiv_id": "2408.12466v1",
    "title": "WCEbleedGen: A wireless capsule endoscopy dataset and its benchmarking for automatic bleeding classification, detection, and segmentation",
    "authors": [
      "Palak Handa",
      "Manas Dhir",
      "Amirreza Mahbod",
      "Florian Schwarzhans",
      "Ramona Woitek",
      "Nidhi Goel",
      "Deepak Gunjan"
    ],
    "abstract": "Computer-based analysis of Wireless Capsule Endoscopy (WCE) is crucial.\nHowever, a medically annotated WCE dataset for training and evaluation of\nautomatic classification, detection, and segmentation of bleeding and\nnon-bleeding frames is currently lacking. The present work focused on\ndevelopment of a medically annotated WCE dataset called WCEbleedGen for\nautomatic classification, detection, and segmentation of bleeding and\nnon-bleeding frames. It comprises 2,618 WCE bleeding and non-bleeding frames\nwhich were collected from various internet resources and existing WCE datasets.\nA comprehensive benchmarking and evaluation of the developed dataset was done\nusing nine classification-based, three detection-based, and three\nsegmentation-based deep learning models. The dataset is of high-quality, is\nclass-balanced and contains single and multiple bleeding sites. Overall, our\nstandard benchmark results show that Visual Geometric Group (VGG) 19, You Only\nLook Once version 8 nano (YOLOv8n), and Link network (Linknet) performed best\nin automatic classification, detection, and segmentation-based evaluations,\nrespectively. Automatic bleeding diagnosis is crucial for WCE video\ninterpretations. This diverse dataset will aid in developing of real-time,\nmulti-task learning-based innovative solutions for automatic bleeding diagnosis\nin WCE. The dataset and code are publicly available at\nhttps://zenodo.org/records/10156571 and\nhttps://github.com/misahub2023/Benchmarking-Codes-of-the-WCEBleedGen-dataset.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12466v1",
    "published_date": "2024-08-22 15:06:50 UTC",
    "updated_date": "2024-08-22 15:06:50 UTC"
  },
  {
    "arxiv_id": "2408.12454v3",
    "title": "Relaxed Rotational Equivariance via $G$-Biases in Vision",
    "authors": [
      "Zhiqiang Wu",
      "Yingjie Liu",
      "Licheng Sun",
      "Jian Yang",
      "Hanlin Dong",
      "Shing-Ho J. Lin",
      "Xuan Tang",
      "Jinpeng Mi",
      "Bo Jin",
      "Xian Wei"
    ],
    "abstract": "Group Equivariant Convolution (GConv) can capture rotational equivariance\nfrom original data. It assumes uniform and strict rotational equivariance\nacross all features as the transformations under the specific group. However,\nthe presentation or distribution of real-world data rarely conforms to strict\nrotational equivariance, commonly referred to as Rotational Symmetry-Breaking\n(RSB) in the system or dataset, making GConv unable to adapt effectively to\nthis phenomenon. Motivated by this, we propose a simple but highly effective\nmethod to address this problem, which utilizes a set of learnable biases called\n$G$-Biases under the group order to break strict group constraints and then\nachieve a Relaxed Rotational Equivariant Convolution (RREConv). To validate the\nefficiency of RREConv, we conduct extensive ablation experiments on the\ndiscrete rotational group $\\mathcal{C}_n$. Experiments demonstrate that the\nproposed RREConv-based methods achieve excellent performance compared to\nexisting GConv-based methods in both classification and 2D object detection\ntasks on the natural image datasets.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12454v3",
    "published_date": "2024-08-22 14:52:53 UTC",
    "updated_date": "2025-01-14 15:35:55 UTC"
  },
  {
    "arxiv_id": "2408.12443v1",
    "title": "A Riemannian Approach for Spatiotemporal Analysis and Generation of 4D Tree-shaped Structures",
    "authors": [
      "Tahmina Khanam",
      "Hamid Laga",
      "Mohammed Bennamoun",
      "Guanjin Wang",
      "Ferdous Sohel",
      "Farid Boussaid",
      "Guan Wang",
      "Anuj Srivastava"
    ],
    "abstract": "We propose the first comprehensive approach for modeling and analyzing the\nspatiotemporal shape variability in tree-like 4D objects, i.e., 3D objects\nwhose shapes bend, stretch, and change in their branching structure over time\nas they deform, grow, and interact with their environment. Our key contribution\nis the representation of tree-like 3D shapes using Square Root Velocity\nFunction Trees (SRVFT). By solving the spatial registration in the SRVFT space,\nwhich is equipped with an L2 metric, 4D tree-shaped structures become\ntime-parameterized trajectories in this space. This reduces the problem of\nmodeling and analyzing 4D tree-like shapes to that of modeling and analyzing\nelastic trajectories in the SRVFT space, where elasticity refers to time\nwarping. In this paper, we propose a novel mathematical representation of the\nshape space of such trajectories, a Riemannian metric on that space, and\ncomputational tools for fast and accurate spatiotemporal registration and\ngeodesics computation between 4D tree-shaped structures. Leveraging these\nbuilding blocks, we develop a full framework for modelling the spatiotemporal\nvariability using statistical models and generating novel 4D tree-like\nstructures from a set of exemplars. We demonstrate and validate the proposed\nframework using real 4D plant data.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12443v1",
    "published_date": "2024-08-22 14:39:30 UTC",
    "updated_date": "2024-08-22 14:39:30 UTC"
  },
  {
    "arxiv_id": "2409.00061v1",
    "title": "Enhancing Natural Language Inference Performance with Knowledge Graph for COVID-19 Automated Fact-Checking in Indonesian Language",
    "authors": [
      "Arief Purnama Muharram",
      "Ayu Purwarianti"
    ],
    "abstract": "Automated fact-checking is a key strategy to overcome the spread of COVID-19\nmisinformation on the internet. These systems typically leverage deep learning\napproaches through Natural Language Inference (NLI) to verify the truthfulness\nof information based on supporting evidence. However, one challenge that arises\nin deep learning is performance stagnation due to a lack of knowledge during\ntraining. This study proposes using a Knowledge Graph (KG) as external\nknowledge to enhance NLI performance for automated COVID-19 fact-checking in\nthe Indonesian language. The proposed model architecture comprises three\nmodules: a fact module, an NLI module, and a classifier module. The fact module\nprocesses information from the KG, while the NLI module handles semantic\nrelationships between the given premise and hypothesis. The representation\nvectors from both modules are concatenated and fed into the classifier module\nto produce the final result. The model was trained using the generated\nIndonesian COVID-19 fact-checking dataset and the COVID-19 KG Bahasa Indonesia.\nOur study demonstrates that incorporating KGs can significantly improve NLI\nperformance in fact-checking, achieving the best accuracy of 0,8616. This\nsuggests that KGs are a valuable component for enhancing NLI performance in\nautomated fact-checking.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2409.00061v1",
    "published_date": "2024-08-22 14:27:47 UTC",
    "updated_date": "2024-08-22 14:27:47 UTC"
  },
  {
    "arxiv_id": "2408.12426v1",
    "title": "Enhanced Infield Agriculture with Interpretable Machine Learning Approaches for Crop Classification",
    "authors": [
      "Sudi Murindanyi",
      "Joyce Nakatumba-Nabende",
      "Rahman Sanya",
      "Rose Nakibuule",
      "Andrew Katumba"
    ],
    "abstract": "The increasing popularity of Artificial Intelligence in recent years has led\nto a surge in interest in image classification, especially in the agricultural\nsector. With the help of Computer Vision, Machine Learning, and Deep Learning,\nthe sector has undergone a significant transformation, leading to the\ndevelopment of new techniques for crop classification in the field. Despite the\nextensive research on various image classification techniques, most have\nlimitations such as low accuracy, limited use of data, and a lack of reporting\nmodel size and prediction. The most significant limitation of all is the need\nfor model explainability. This research evaluates four different approaches for\ncrop classification, namely traditional ML with handcrafted feature extraction\nmethods like SIFT, ORB, and Color Histogram; Custom Designed CNN and\nestablished DL architecture like AlexNet; transfer learning on five models\npre-trained using ImageNet such as EfficientNetV2, ResNet152V2, Xception,\nInception-ResNetV2, MobileNetV3; and cutting-edge foundation models like YOLOv8\nand DINOv2, a self-supervised Vision Transformer Model. All models performed\nwell, but Xception outperformed all of them in terms of generalization,\nachieving 98% accuracy on the test data, with a model size of 80.03 MB and a\nprediction time of 0.0633 seconds. A key aspect of this research was the\napplication of Explainable AI to provide the explainability of all the models.\nThis journal presents the explainability of Xception model with LIME, SHAP, and\nGradCAM, ensuring transparency and trustworthiness in the models' predictions.\nThis study highlights the importance of selecting the right model according to\ntask-specific needs. It also underscores the important role of explainability\nin deploying AI in agriculture, providing insightful information to help\nenhance AI-driven crop management strategies.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12426v1",
    "published_date": "2024-08-22 14:20:34 UTC",
    "updated_date": "2024-08-22 14:20:34 UTC"
  },
  {
    "arxiv_id": "2408.12423v1",
    "title": "Multi-Knowledge Fusion Network for Time Series Representation Learning",
    "authors": [
      "Sagar Srinivas Sakhinana",
      "Shivam Gupta",
      "Krishna Sai Sudhir Aripirala",
      "Venkataramana Runkana"
    ],
    "abstract": "Forecasting the behaviour of complex dynamical systems such as interconnected\nsensor networks characterized by high-dimensional multivariate time series(MTS)\nis of paramount importance for making informed decisions and planning for the\nfuture in a broad spectrum of applications. Graph forecasting networks(GFNs)\nare well-suited for forecasting MTS data that exhibit spatio-temporal\ndependencies. However, most prior works of GFN-based methods on MTS forecasting\nrely on domain-expertise to model the nonlinear dynamics of the system, but\nneglect the potential to leverage the inherent relational-structural\ndependencies among time series variables underlying MTS data. On the other\nhand, contemporary works attempt to infer the relational structure of the\ncomplex dependencies between the variables and simultaneously learn the\nnonlinear dynamics of the interconnected system but neglect the possibility of\nincorporating domain-specific prior knowledge to improve forecast accuracy. To\nthis end, we propose a hybrid architecture that combines explicit prior\nknowledge with implicit knowledge of the relational structure within the MTS\ndata. It jointly learns intra-series temporal dependencies and inter-series\nspatial dependencies by encoding time-conditioned structural spatio-temporal\ninductive biases to provide more accurate and reliable forecasts. It also\nmodels the time-varying uncertainty of the multi-horizon forecasts to support\ndecision-making by providing estimates of prediction uncertainty. The proposed\narchitecture has shown promising results on multiple benchmark datasets and\noutperforms state-of-the-art forecasting methods by a significant margin. We\nreport and discuss the ablation studies to validate our forecasting\narchitecture.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Paper accepted at ML4IoT Workshop, International Conference on\n  Learning Representations(ICLR) 2023",
    "pdf_url": "http://arxiv.org/pdf/2408.12423v1",
    "published_date": "2024-08-22 14:18:16 UTC",
    "updated_date": "2024-08-22 14:18:16 UTC"
  },
  {
    "arxiv_id": "2408.12420v1",
    "title": "Dataset | Mindset = Explainable AI | Interpretable AI",
    "authors": [
      "Caesar Wu",
      "Rajkumar Buyya",
      "Yuan Fang Li",
      "Pascal Bouvry"
    ],
    "abstract": "We often use \"explainable\" Artificial Intelligence (XAI)\" and \"interpretable\nAI (IAI)\" interchangeably when we apply various XAI tools for a given dataset\nto explain the reasons that underpin machine learning (ML) outputs. However,\nthese notions can sometimes be confusing because interpretation often has a\nsubjective connotation, while explanations lean towards objective facts. We\nargue that XAI is a subset of IAI. The concept of IAI is beyond the sphere of a\ndataset. It includes the domain of a mindset. At the core of this ambiguity is\nthe duality of reasons, in which we can reason either outwards or inwards. When\ndirected outwards, we want the reasons to make sense through the laws of\nnature. When turned inwards, we want the reasons to be happy, guided by the\nlaws of the heart. While XAI and IAI share reason as the common notion for the\ngoal of transparency, clarity, fairness, reliability, and accountability in the\ncontext of ethical AI and trustworthy AI (TAI), their differences lie in that\nXAI emphasizes the post-hoc analysis of a dataset, and IAI requires a priori\nmindset of abstraction. This hypothesis can be proved by empirical experiments\nbased on an open dataset and harnessed by High-Performance Computing (HPC). The\ndemarcation of XAI and IAI is indispensable because it would be impossible to\ndetermine regulatory policies for many AI applications, especially in\nhealthcare, human resources, banking, and finance. We aim to clarify these\nnotions and lay the foundation of XAI, IAI, EAI, and TAI for many practitioners\nand policymakers in future AI applications and research.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12420v1",
    "published_date": "2024-08-22 14:12:53 UTC",
    "updated_date": "2024-08-22 14:12:53 UTC"
  },
  {
    "arxiv_id": "2408.12419v3",
    "title": "AlphaFolding: 4D Diffusion for Dynamic Protein Structure Prediction with Reference and Motion Guidance",
    "authors": [
      "Kaihui Cheng",
      "Ce Liu",
      "Qingkun Su",
      "Jun Wang",
      "Liwei Zhang",
      "Yining Tang",
      "Yao Yao",
      "Siyu Zhu",
      "Yuan Qi"
    ],
    "abstract": "Protein structure prediction is pivotal for understanding the\nstructure-function relationship of proteins, advancing biological research, and\nfacilitating pharmaceutical development and experimental design. While deep\nlearning methods and the expanded availability of experimental 3D protein\nstructures have accelerated structure prediction, the dynamic nature of protein\nstructures has received limited attention. This study introduces an innovative\n4D diffusion model incorporating molecular dynamics (MD) simulation data to\nlearn dynamic protein structures. Our approach is distinguished by the\nfollowing components: (1) a unified diffusion model capable of generating\ndynamic protein structures, including both the backbone and side chains,\nutilizing atomic grouping and side-chain dihedral angle predictions; (2) a\nreference network that enhances structural consistency by integrating the\nlatent embeddings of the initial 3D protein structures; and (3) a motion\nalignment module aimed at improving temporal structural coherence across\nmultiple time steps. To our knowledge, this is the first diffusion-based model\naimed at predicting protein trajectories across multiple time steps\nsimultaneously. Validation on benchmark datasets demonstrates that our model\nexhibits high accuracy in predicting dynamic 3D structures of proteins\ncontaining up to 256 amino acids over 32 time steps, effectively capturing both\nlocal flexibility in stable states and significant conformational changes. URL:\nhttps://fudan-generative-vision.github.io/AlphaFolding/#/",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12419v3",
    "published_date": "2024-08-22 14:12:50 UTC",
    "updated_date": "2024-12-25 15:20:56 UTC"
  },
  {
    "arxiv_id": "2408.12418v1",
    "title": "CODE: Confident Ordinary Differential Editing",
    "authors": [
      "Bastien van Delft",
      "Tommaso Martorella",
      "Alexandre Alahi"
    ],
    "abstract": "Conditioning image generation facilitates seamless editing and the creation\nof photorealistic images. However, conditioning on noisy or Out-of-Distribution\n(OoD) images poses significant challenges, particularly in balancing fidelity\nto the input and realism of the output. We introduce Confident Ordinary\nDifferential Editing (CODE), a novel approach for image synthesis that\neffectively handles OoD guidance images. Utilizing a diffusion model as a\ngenerative prior, CODE enhances images through score-based updates along the\nprobability-flow Ordinary Differential Equation (ODE) trajectory. This method\nrequires no task-specific training, no handcrafted modules, and no assumptions\nregarding the corruptions affecting the conditioning image. Our method is\ncompatible with any diffusion model. Positioned at the intersection of\nconditional image generation and blind image restoration, CODE operates in a\nfully blind manner, relying solely on a pre-trained generative model. Our\nmethod introduces an alternative approach to blind restoration: instead of\ntargeting a specific ground truth image based on assumptions about the\nunderlying corruption, CODE aims to increase the likelihood of the input image\nwhile maintaining fidelity. This results in the most probable in-distribution\nimage around the input. Our contributions are twofold. First, CODE introduces a\nnovel editing method based on ODE, providing enhanced control, realism, and\nfidelity compared to its SDE-based counterpart. Second, we introduce a\nconfidence interval-based clipping method, which improves CODE's effectiveness\nby allowing it to disregard certain pixels or information, thus enhancing the\nrestoration process in a blind manner. Experimental results demonstrate CODE's\neffectiveness over existing methods, particularly in scenarios involving severe\ndegradation or OoD inputs.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12418v1",
    "published_date": "2024-08-22 14:12:20 UTC",
    "updated_date": "2024-08-22 14:12:20 UTC"
  },
  {
    "arxiv_id": "2408.12634v1",
    "title": "Joint Hypergraph Rewiring and Memory-Augmented Forecasting Techniques in Digital Twin Technology",
    "authors": [
      "Sagar Srinivas Sakhinana",
      "Krishna Sai Sudhir Aripirala",
      "Shivam Gupta",
      "Venkataramana Runkana"
    ],
    "abstract": "Digital Twin technology creates virtual replicas of physical objects,\nprocesses, or systems by replicating their properties, data, and behaviors.\nThis advanced technology offers a range of intelligent functionalities, such as\nmodeling, simulation, and data-driven decision-making, that facilitate design\noptimization, performance estimation, and monitoring operations. Forecasting\nplays a pivotal role in Digital Twin technology, as it enables the prediction\nof future outcomes, supports informed decision-making, minimizes risks, driving\nimprovements in efficiency, productivity, and cost reduction. Recently, Digital\nTwin technology has leveraged Graph forecasting techniques in large-scale\ncomplex sensor networks to enable accurate forecasting and simulation of\ndiverse scenarios, fostering proactive and data-driven decision making.\nHowever, existing Graph forecasting techniques lack scalability for many\nreal-world applications. They have limited ability to adapt to non-stationary\nenvironments, retain past knowledge, lack a mechanism to capture the higher\norder spatio-temporal dynamics, and estimate uncertainty in model predictions.\nTo surmount the challenges, we introduce a hybrid architecture that enhances\nthe hypergraph representation learning backbone by incorporating fast\nadaptation to new patterns and memory-based retrieval of past knowledge. This\nbalance aims to improve the slowly-learned backbone and achieve better\nperformance in adapting to recent changes. In addition, it models the\ntime-varying uncertainty of multi-horizon forecasts, providing estimates of\nprediction uncertainty. Our forecasting architecture has been validated through\nablation studies and has demonstrated promising results across multiple\nbenchmark datasets, surpassing state-ofthe-art forecasting methods by a\nsignificant margin.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Paper accepted at AI for Digital Twins and Cyber-Physical\n  Applications Workshop, International Joint Conferences on Artificial\n  Intelligence(IJCAI-23). arXiv admin note: text overlap with arXiv:2408.12409",
    "pdf_url": "http://arxiv.org/pdf/2408.12634v1",
    "published_date": "2024-08-22 14:08:45 UTC",
    "updated_date": "2024-08-22 14:08:45 UTC"
  },
  {
    "arxiv_id": "2408.12413v3",
    "title": "Dynamic PDB: A New Dataset and a SE(3) Model Extension by Integrating Dynamic Behaviors and Physical Properties in Protein Structures",
    "authors": [
      "Ce Liu",
      "Jun Wang",
      "Zhiqiang Cai",
      "Yingxu Wang",
      "Huizhen Kuang",
      "Kaihui Cheng",
      "Liwei Zhang",
      "Qingkun Su",
      "Yining Tang",
      "Fenglei Cao",
      "Limei Han",
      "Siyu Zhu",
      "Yuan Qi"
    ],
    "abstract": "Despite significant progress in static protein structure collection and\nprediction, the dynamic behavior of proteins, one of their most vital\ncharacteristics, has been largely overlooked in prior research. This oversight\ncan be attributed to the limited availability, diversity, and heterogeneity of\ndynamic protein datasets. To address this gap, we propose to enhance existing\nprestigious static 3D protein structural databases, such as the Protein Data\nBank (PDB), by integrating dynamic data and additional physical properties.\nSpecifically, we introduce a large-scale dataset, Dynamic PDB, encompassing\napproximately 12.6K proteins, each subjected to all-atom molecular dynamics\n(MD) simulations lasting 1 microsecond to capture conformational changes.\nFurthermore, we provide a comprehensive suite of physical properties, including\natomic velocities and forces, potential and kinetic energies of proteins, and\nthe temperature of the simulation environment, recorded at 1 picosecond\nintervals throughout the simulations. For benchmarking purposes, we evaluate\nstate-of-the-art methods on the proposed dataset for the task of trajectory\nprediction. To demonstrate the value of integrating richer physical properties\nin the study of protein dynamics and related model design, we base our approach\non the SE(3) diffusion model and incorporate these physical properties into the\ntrajectory prediction process. Preliminary results indicate that this\nstraightforward extension of the SE(3) model yields improved accuracy, as\nmeasured by MAE and RMSD, when the proposed physical properties are taken into\nconsideration. https://fudan-generative-vision.github.io/dynamicPDB/ .",
    "categories": [
      "q-bio.BM",
      "cs.AI"
    ],
    "primary_category": "q-bio.BM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12413v3",
    "published_date": "2024-08-22 14:06:01 UTC",
    "updated_date": "2024-09-18 10:53:11 UTC"
  },
  {
    "arxiv_id": "2408.12409v1",
    "title": "Multi-Source Knowledge-Based Hybrid Neural Framework for Time Series Representation Learning",
    "authors": [
      "Sagar Srinivas Sakhinana",
      "Krishna Sai Sudhir Aripirala",
      "Shivam Gupta",
      "Venkataramana Runkana"
    ],
    "abstract": "Accurately predicting the behavior of complex dynamical systems,\ncharacterized by high-dimensional multivariate time series(MTS) in\ninterconnected sensor networks, is crucial for informed decision-making in\nvarious applications to minimize risk. While graph forecasting networks(GFNs)\nare ideal for forecasting MTS data that exhibit spatio-temporal dependencies,\nprior works rely solely on the domain-specific knowledge of time-series\nvariables inter-relationships to model the nonlinear dynamics, neglecting\ninherent relational structural dependencies among the variables within the MTS\ndata. In contrast, contemporary works infer relational structures from MTS data\nbut neglect domain-specific knowledge. The proposed hybrid architecture\naddresses these limitations by combining both domain-specific knowledge and\nimplicit knowledge of the relational structure underlying the MTS data using\nKnowledge-Based Compositional Generalization. The hybrid architecture shows\npromising results on multiple benchmark datasets, outperforming\nstate-of-the-art forecasting methods. Additionally, the architecture models the\ntime varying uncertainty of multi-horizon forecasts.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Paper is accepted at Knowledge-Based Compositional Generalization\n  Workshop, International Joint Conferences on Artificial\n  Intelligence(IJCAI-23)",
    "pdf_url": "http://arxiv.org/pdf/2408.12409v1",
    "published_date": "2024-08-22 13:58:55 UTC",
    "updated_date": "2024-08-22 13:58:55 UTC"
  },
  {
    "arxiv_id": "2408.12400v1",
    "title": "Multi-Style Facial Sketch Synthesis through Masked Generative Modeling",
    "authors": [
      "Bowen Sun",
      "Guo Lu",
      "Shibao Zheng"
    ],
    "abstract": "The facial sketch synthesis (FSS) model, capable of generating sketch\nportraits from given facial photographs, holds profound implications across\nmultiple domains, encompassing cross-modal face recognition, entertainment,\nart, media, among others. However, the production of high-quality sketches\nremains a formidable task, primarily due to the challenges and flaws associated\nwith three key factors: (1) the scarcity of artist-drawn data, (2) the\nconstraints imposed by limited style types, and (3) the deficiencies of\nprocessing input information in existing models. To address these difficulties,\nwe propose a lightweight end-to-end synthesis model that efficiently converts\nimages to corresponding multi-stylized sketches, obviating the necessity for\nany supplementary inputs (\\eg, 3D geometry). In this study, we overcome the\nissue of data insufficiency by incorporating semi-supervised learning into the\ntraining process. Additionally, we employ a feature extraction module and style\nembeddings to proficiently steer the generative transformer during the\niterative prediction of masked image tokens, thus achieving a continuous\nstylized output that retains facial features accurately in sketches. The\nextensive experiments demonstrate that our method consistently outperforms\nprevious algorithms across multiple benchmarks, exhibiting a discernible\ndisparity.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12400v1",
    "published_date": "2024-08-22 13:45:04 UTC",
    "updated_date": "2024-08-22 13:45:04 UTC"
  },
  {
    "arxiv_id": "2408.12632v1",
    "title": "Generative Diffusion Model-based Downscaling of Observed Sea Surface Height over Kuroshio Extension since 2000",
    "authors": [
      "Qiuchang Han",
      "Xingliang Jiang",
      "Yang Zhao",
      "Xudong Wang",
      "Zhijin Li",
      "Renhe Zhang"
    ],
    "abstract": "Satellite altimetry has been widely utilized to monitor global sea surface\ndynamics, enabling investigation of upper ocean variability from basin-scale to\nlocalized eddy ranges. However, the sparse spatial resolution of observational\naltimetry limits our understanding of oceanic submesoscale variability,\nprevalent at horizontal scales below 0.25o resolution. Here, we introduce a\nstate-of-the-art generative diffusion model to train high-resolution sea\nsurface height (SSH) reanalysis data and demonstrate its advantage in\nobservational SSH downscaling over the eddy-rich Kuroshio Extension region. The\ndiffusion-based model effectively downscales raw satellite-interpolated data\nfrom 0.25o resolution to 1/16o, corresponding to approximately 12-km\nwavelength. This model outperforms other high-resolution reanalysis datasets\nand neural network-based methods. Also, it successfully reproduces the spatial\npatterns and power spectra of satellite along-track observations. Our\ndiffusion-based results indicate that eddy kinetic energy at horizontal scales\nless than 250 km has intensified significantly since 2004 in the Kuroshio\nExtension region. These findings underscore the great potential of deep\nlearning in reconstructing satellite altimetry and enhancing our understanding\nof ocean dynamics at eddy scales.",
    "categories": [
      "physics.ao-ph",
      "cs.AI"
    ],
    "primary_category": "physics.ao-ph",
    "comment": "28 pages, 7 figures, and 1 table",
    "pdf_url": "http://arxiv.org/pdf/2408.12632v1",
    "published_date": "2024-08-22 13:26:19 UTC",
    "updated_date": "2024-08-22 13:26:19 UTC"
  },
  {
    "arxiv_id": "2408.12373v2",
    "title": "Cell-ontology guided transcriptome foundation model",
    "authors": [
      "Xinyu Yuan",
      "Zhihao Zhan",
      "Zuobai Zhang",
      "Manqi Zhou",
      "Jianan Zhao",
      "Boyu Han",
      "Yue Li",
      "Jian Tang"
    ],
    "abstract": "Transcriptome foundation models TFMs hold great promises of deciphering the\ntranscriptomic language that dictate diverse cell functions by self-supervised\nlearning on large-scale single-cell gene expression data, and ultimately\nunraveling the complex mechanisms of human diseases. However, current TFMs\ntreat cells as independent samples and ignore the taxonomic relationships\nbetween cell types, which are available in cell ontology graphs. We argue that\neffectively leveraging this ontology information during the TFM pre-training\ncan improve learning biologically meaningful gene co-expression patterns while\npreserving TFM as a general purpose foundation model for downstream zero-shot\nand fine-tuning tasks. To this end, we present single cell, Cell-ontology\nguided TFM scCello. We introduce cell-type coherence loss and ontology\nalignment loss, which are minimized along with the masked gene expression\nprediction loss during the pre-training. The novel loss component guide scCello\nto learn the cell-type-specific representation and the structural relation\nbetween cell types from the cell ontology graph, respectively. We pre-trained\nscCello on 22 million cells from CellxGene database leveraging their cell-type\nlabels mapped to the cell ontology graph from Open Biological and Biomedical\nOntology Foundry. Our TFM demonstrates competitive generalization and\ntransferability performance over the existing TFMs on biologically important\ntasks including identifying novel cell types of unseen cells, prediction of\ncell-type-specific marker genes, and cancer drug responses.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to NeurIPS 2024 as Spotlight",
    "pdf_url": "http://arxiv.org/pdf/2408.12373v2",
    "published_date": "2024-08-22 13:15:49 UTC",
    "updated_date": "2025-02-28 17:36:51 UTC"
  },
  {
    "arxiv_id": "2408.12369v2",
    "title": "RoundTable: Leveraging Dynamic Schema and Contextual Autocomplete for Enhanced Query Precision in Tabular Question Answering",
    "authors": [
      "Pratyush Kumar",
      "Kuber Vijaykumar Bellad",
      "Bharat Vadlamudi",
      "Aman Chadha"
    ],
    "abstract": "With advancements in Large Language Models (LLMs), a major use case that has\nemerged is querying databases in plain English, translating user questions into\nexecutable database queries, which has improved significantly. However,\nreal-world datasets often feature a vast array of attributes and complex\nvalues, complicating the LLMs task of accurately identifying relevant columns\nor values from natural language queries. Traditional methods cannot fully relay\nthe datasets size and complexity to the LLM. To address these challenges, we\npropose a novel framework that leverages Full-Text Search (FTS) on the input\ntable. This approach not only enables precise detection of specific values and\ncolumns but also narrows the search space for language models, thereby\nenhancing query accuracy. Additionally, it supports a custom auto-complete\nfeature that suggests queries based on the data in the table. This integration\nsignificantly refines the interaction between the user and complex datasets,\noffering a sophisticated solution to the limitations faced by current table\nquerying capabilities. This work is accompanied by an application for both Mac\nand Windows platforms, which readers can try out themselves on their own data.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "13 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.12369v2",
    "published_date": "2024-08-22 13:13:06 UTC",
    "updated_date": "2024-08-23 08:11:09 UTC"
  },
  {
    "arxiv_id": "2408.12364v1",
    "title": "SAM-SP: Self-Prompting Makes SAM Great Again",
    "authors": [
      "Chunpeng Zhou",
      "Kangjie Ning",
      "Qianqian Shen",
      "Sheng Zhou",
      "Zhi Yu",
      "Haishuai Wang"
    ],
    "abstract": "The recently introduced Segment Anything Model (SAM), a Visual Foundation\nModel (VFM), has demonstrated impressive capabilities in zero-shot segmentation\ntasks across diverse natural image datasets. Despite its success, SAM\nencounters noticeably performance degradation when applied to specific domains,\nsuch as medical images. Current efforts to address this issue have involved\nfine-tuning strategies, intended to bolster the generalizability of the vanilla\nSAM. However, these approaches still predominantly necessitate the utilization\nof domain specific expert-level prompts during the evaluation phase, which\nseverely constrains the model's practicality.\n  To overcome this limitation, we introduce a novel self-prompting based\nfine-tuning approach, called SAM-SP, tailored for extending the vanilla SAM\nmodel. Specifically, SAM-SP leverages the output from the previous iteration of\nthe model itself as prompts to guide subsequent iteration of the model. This\nself-prompting module endeavors to learn how to generate useful prompts\nautonomously and alleviates the dependence on expert prompts during the\nevaluation phase, significantly broadening SAM's applicability. Additionally,\nwe integrate a self-distillation module to enhance the self-prompting process\nfurther. Extensive experiments across various domain specific datasets validate\nthe effectiveness of the proposed SAM-SP. Our SAM-SP not only alleviates the\nreliance on expert prompts but also exhibits superior segmentation performance\ncomparing to the state-of-the-art task-specific segmentation approaches, the\nvanilla SAM, and SAM-based approaches.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.CV",
    "comment": "Under Review",
    "pdf_url": "http://arxiv.org/pdf/2408.12364v1",
    "published_date": "2024-08-22 13:03:05 UTC",
    "updated_date": "2024-08-22 13:03:05 UTC"
  },
  {
    "arxiv_id": "2408.12355v1",
    "title": "Class-balanced Open-set Semi-supervised Object Detection for Medical Images",
    "authors": [
      "Zhanyun Lu",
      "Renshu Gu",
      "Huimin Cheng",
      "Siyu Pang",
      "Mingyu Xu",
      "Peifang Xu",
      "Yaqi Wang",
      "Yuichiro Kinoshita",
      "Juan Ye",
      "Gangyong Jia",
      "Qing Wu"
    ],
    "abstract": "Medical image datasets in the real world are often unlabeled and imbalanced,\nand Semi-Supervised Object Detection (SSOD) can utilize unlabeled data to\nimprove an object detector. However, existing approaches predominantly assumed\nthat the unlabeled data and test data do not contain out-of-distribution (OOD)\nclasses. The few open-set semi-supervised object detection methods have two\nweaknesses: first, the class imbalance is not considered; second, the OOD\ninstances are distinguished and simply discarded during pseudo-labeling. In\nthis paper, we consider the open-set semi-supervised object detection problem\nwhich leverages unlabeled data that contain OOD classes to improve object\ndetection for medical images. Our study incorporates two key innovations:\nCategory Control Embed (CCE) and out-of-distribution Detection Fusion\nClassifier (OODFC). CCE is designed to tackle dataset imbalance by constructing\na Foreground information Library, while OODFC tackles open-set challenges by\nintegrating the ``unknown'' information into basic pseudo-labels. Our method\noutperforms the state-of-the-art SSOD performance, achieving a 4.25 mAP\nimprovement on the public Parasite dataset.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12355v1",
    "published_date": "2024-08-22 12:54:15 UTC",
    "updated_date": "2024-08-22 12:54:15 UTC"
  },
  {
    "arxiv_id": "2408.12337v1",
    "title": "Fine-tuning Smaller Language Models for Question Answering over Financial Documents",
    "authors": [
      "Karmvir Singh Phogat",
      "Sai Akhil Puranam",
      "Sridhar Dasaratha",
      "Chetan Harsha",
      "Shashishekar Ramakrishna"
    ],
    "abstract": "Recent research has shown that smaller language models can acquire\nsubstantial reasoning abilities when fine-tuned with reasoning exemplars\ncrafted by a significantly larger teacher model. We explore this paradigm for\nthe financial domain, focusing on the challenge of answering questions that\nrequire multi-hop numerical reasoning over financial texts. We assess the\nperformance of several smaller models that have been fine-tuned to generate\nprograms that encode the required financial reasoning and calculations. Our\nfindings demonstrate that these fine-tuned smaller models approach the\nperformance of the teacher model.\n  To provide a granular analysis of model performance, we propose an approach\nto investigate the specific student model capabilities that are enhanced by\nfine-tuning. Our empirical analysis indicates that fine-tuning refines the\nstudent models ability to express and apply the required financial concepts\nalong with adapting the entity extraction for the specific data format. In\naddition, we hypothesize and demonstrate that comparable financial reasoning\ncapability can be induced using relatively smaller datasets.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12337v1",
    "published_date": "2024-08-22 12:23:29 UTC",
    "updated_date": "2024-08-22 12:23:29 UTC"
  },
  {
    "arxiv_id": "2408.12334v2",
    "title": "Boosting Graph Neural Network Expressivity with Learnable Lanczos Constraints",
    "authors": [
      "Niloofar Azizi",
      "Nils Kriege",
      "Horst Bischof"
    ],
    "abstract": "Graph Neural Networks (GNNs) excel in handling graph-structured data but\noften underperform in link prediction tasks compared to classical methods,\nmainly due to the limitations of the commonly used message-passing principle.\nNotably, their ability to distinguish non-isomorphic graphs is limited by the\n1-dimensional Weisfeiler-Lehman test. Our study presents a novel method to\nenhance the expressivity of GNNs by embedding induced subgraphs into the graph\nLaplacian matrix's eigenbasis. We introduce a Learnable Lanczos algorithm with\nLinear Constraints (LLwLC), proposing two novel subgraph extraction strategies:\nencoding vertex-deleted subgraphs and applying Neumann eigenvalue constraints.\nFor the former, we demonstrate the ability to distinguish graphs that are\nindistinguishable by 2-WL, while maintaining efficient time complexity. The\nlatter focuses on link representations enabling differentiation between\n$k$-regular graphs and node automorphism, a vital aspect for link prediction\ntasks. Our approach results in an extremely lightweight architecture, reducing\nthe need for extensive training datasets. Empirically, our method improves\nperformance in challenging link prediction tasks across benchmark datasets,\nestablishing its practical utility and supporting our theoretical findings.\nNotably, LLwLC achieves 20x and 10x speedup by only requiring 5% and 10% data\nfrom the PubMed and OGBL-Vessel datasets while comparing to the\nstate-of-the-art.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12334v2",
    "published_date": "2024-08-22 12:22:00 UTC",
    "updated_date": "2025-02-14 22:08:20 UTC"
  },
  {
    "arxiv_id": "2408.12333v3",
    "title": "GRATR: Zero-Shot Evidence Graph Retrieval-Augmented Trustworthiness Reasoning",
    "authors": [
      "Ying Zhu",
      "Shengchang Li",
      "Ziqian Kong",
      "Qiang Yang",
      "Peilan Xu"
    ],
    "abstract": "Trustworthiness reasoning aims to enable agents in multiplayer games with\nincomplete information to identify potential allies and adversaries, thereby\nenhancing decision-making. In this paper, we introduce the graph\nretrieval-augmented trustworthiness reasoning (GRATR) framework, which\nretrieves observable evidence from the game environment to inform\ndecision-making by large language models (LLMs) without requiring additional\ntraining, making it a zero-shot approach. Within the GRATR framework, agents\nfirst observe the actions of other players and evaluate the resulting shifts in\ninter-player trust, constructing a corresponding trustworthiness graph. During\ndecision-making, the agent performs multi-hop retrieval to evaluate\ntrustworthiness toward a specific target, where evidence chains are retrieved\nfrom multiple trusted sources to form a comprehensive assessment. Experiments\nin the multiplayer game \\emph{Werewolf} demonstrate that GRATR outperforms the\nalternatives, improving reasoning accuracy by 50.5\\% and reducing hallucination\nby 30.6\\% compared to the baseline method. Additionally, when tested on a\ndataset of Twitter tweets during the U.S. election period, GRATR surpasses the\nbaseline method by 10.4\\% in accuracy, highlighting its potential in real-world\napplications such as intent analysis.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12333v3",
    "published_date": "2024-08-22 12:21:22 UTC",
    "updated_date": "2025-01-27 09:18:07 UTC"
  },
  {
    "arxiv_id": "2408.12326v1",
    "title": "Interactive DualChecker for Mitigating Hallucinations in Distilling Large Language Models",
    "authors": [
      "Meiyun Wang",
      "Masahiro Suzuki",
      "Hiroki Sakaji",
      "Kiyoshi Izumi"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated exceptional capabilities\nacross various machine learning (ML) tasks. Given the high costs of creating\nannotated datasets for supervised learning, LLMs offer a valuable alternative\nby enabling effective few-shot in-context learning. However, these models can\nproduce hallucinations, particularly in domains with incomplete knowledge.\nAdditionally, current methods for knowledge distillation using LLMs often\nstruggle to enhance the effectiveness of both teacher and student models. To\naddress these challenges, we introduce DualChecker, an innovative framework\ndesigned to mitigate hallucinations and improve the performance of both teacher\nand student models during knowledge distillation. DualChecker employs\nContextAligner to ensure that the context provided by teacher models aligns\nwith human labeling standards. It also features a dynamic checker system that\nenhances model interaction: one component re-prompts teacher models with more\ndetailed content when they show low confidence, and another identifies\nborderline cases from student models to refine the teaching templates. This\ninteractive process promotes continuous improvement and effective knowledge\ntransfer between the models. We evaluate DualChecker using a green innovation\ntextual dataset that includes binary, multiclass, and token classification\ntasks. The experimental results show that DualChecker significantly outperforms\nexisting state-of-the-art methods, achieving up to a 17% improvement in F1\nscore for teacher models and 10% for student models. Notably, student models\nfine-tuned with LLM predictions perform comparably to those fine-tuned with\nactual data, even in a challenging domain. We make all datasets, models, and\ncode from this research publicly available.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CE",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12326v1",
    "published_date": "2024-08-22 12:04:04 UTC",
    "updated_date": "2024-08-22 12:04:04 UTC"
  },
  {
    "arxiv_id": "2408.12320v3",
    "title": "TensorOpera Router: A Multi-Model Router for Efficient LLM Inference",
    "authors": [
      "Dimitris Stripelis",
      "Zijian Hu",
      "Jipeng Zhang",
      "Zhaozhuo Xu",
      "Alay Dilipbhai Shah",
      "Han Jin",
      "Yuhang Yao",
      "Salman Avestimehr",
      "Chaoyang He"
    ],
    "abstract": "With the rapid growth of Large Language Models (LLMs) across various domains,\nnumerous new LLMs have emerged, each possessing domain-specific expertise. This\nproliferation has highlighted the need for quick, high-quality, and\ncost-effective LLM query response methods. Yet, no single LLM exists to\nefficiently balance this trilemma. Some models are powerful but extremely\ncostly, while others are fast and inexpensive but qualitatively inferior. To\naddress this challenge, we present TO-Router, a non-monolithic LLM querying\nsystem that seamlessly integrates various LLM experts into a single query\ninterface and dynamically routes incoming queries to the most high-performant\nexpert based on query's requirements. Through extensive experiments, we\ndemonstrate that when compared to standalone expert models, TO-Router improves\nquery efficiency by up to 40\\%, and leads to significant cost reductions of up\nto 30%, while maintaining or enhancing model performance by up to 10%.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "I.2; I.5"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages, 7 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2408.12320v3",
    "published_date": "2024-08-22 11:57:07 UTC",
    "updated_date": "2024-10-23 18:11:42 UTC"
  },
  {
    "arxiv_id": "2408.12315v1",
    "title": "Large Language Models Are Self-Taught Reasoners: Enhancing LLM Applications via Tailored Problem-Solving Demonstrations",
    "authors": [
      "Kai Tzu-iunn Ong",
      "Taeyoon Kwon",
      "Jinyoung Yeo"
    ],
    "abstract": "Guiding large language models with a selected set of human-authored\ndemonstrations is a common practice for improving LLM applications. However,\nhuman effort can be costly, especially in specialized domains (e.g., clinical\ndiagnosis), and does not guarantee optimal performance due to the potential\ndiscrepancy of target skills between selected demonstrations and real test\ninstances. Motivated by these, this paper explores the automatic creation of\ncustomized demonstrations, whose target skills align with the given target\ninstance. We present SELF-TAUGHT, a problem-solving framework, which\nfacilitates demonstrations that are \"tailored\" to the target problem and\n\"filtered\" for better quality (i.e., correctness) in a zero-shot manner. In 15\ntasks of multiple-choice questions of diverse domains and the diagnosis of\nAlzheimer's disease (AD) with real-world patients, SELF-TAUGHT achieves\nsuperior performance to strong baselines (e.g., Few-shot CoT, Plan-and-Solve,\nAuto-CoT). We conduct comprehensive analyses on SELF-TAUGHT, including its\ngeneralizability to existing prompting methods and different LLMs, the quality\nof its intermediate generation, and more.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "preprint / under review",
    "pdf_url": "http://arxiv.org/pdf/2408.12315v1",
    "published_date": "2024-08-22 11:41:35 UTC",
    "updated_date": "2024-08-22 11:41:35 UTC"
  },
  {
    "arxiv_id": "2408.12308v3",
    "title": "Deep Learning with CNNs: A Compact Holistic Tutorial with Focus on Supervised Regression (Preprint)",
    "authors": [
      "Yansel Gonzalez Tejeda",
      "Helmut A. Mayer"
    ],
    "abstract": "In this tutorial, we present a compact and holistic discussion of Deep\nLearning with a focus on Convolutional Neural Networks (CNNs) and supervised\nregression. While there are numerous books and articles on the individual\ntopics we cover, comprehensive and detailed tutorials that address Deep\nLearning from a foundational yet rigorous and accessible perspective are rare.\nMost resources on CNNs are either too advanced, focusing on cutting-edge\narchitectures, or too narrow, addressing only specific applications like image\nclassification.This tutorial not only summarizes the most relevant concepts but\nalso provides an in-depth exploration of each, offering a complete yet agile\nset of ideas. Moreover, we highlight the powerful synergy between learning\ntheory, statistic, and machine learning, which together underpin the Deep\nLearning and CNN frameworks. We aim for this tutorial to serve as an optimal\nresource for students, professors, and anyone interested in understanding the\nfoundations of Deep Learning. Upon acceptance we will provide an accompanying\nrepository under\n\\href{https://github.com/neoglez/deep-learning-tutorial}{https://github.com/neoglez/deep-learning-tutorial}\n  Keywords: Tutorial, Deep Learning, Convolutional Neural Networks, Machine\nLearning.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Submitted to the journal Machine Learning and Knowledge Extraction",
    "pdf_url": "http://arxiv.org/pdf/2408.12308v3",
    "published_date": "2024-08-22 11:34:34 UTC",
    "updated_date": "2024-11-12 11:45:35 UTC"
  },
  {
    "arxiv_id": "2408.12305v2",
    "title": "Tipta uzmanlik sinavinda (tus) buyuk dil modelleri insanlardan daha mi basarili?",
    "authors": [
      "Yesim Aygul",
      "Muge Olucoglu",
      "Adil Alpkocak"
    ],
    "abstract": "The potential of artificial intelligence in medical education and assessment\nhas been made evident by recent developments in natural language processing and\nartificial intelligence. Medical questions can now be successfully answered by\nartificial intelligence algorithms. It can help medical practitioners. This\nstudy evaluates the performance of three different artificial intelligence\nmodels in answering Turkish medical questions in the 2021 1st Term Medical\nSpecialization Examination (MSE). MSE consists of a total of 240 questions\nacross clinical (CMST) and basic (BMST) medical sciences. According to the\nresults in CMST, it was concluded that Gemini correctly answered 82 questions,\nChatGPT-4 answered 105 questions and ChatGPT-4o answered 117 questions. In\nBMST, Gemini and ChatGPT-4 answered 93 questions and ChatGPT-4o answered 107\nquestions correctly according to the answer key. ChatGPT-4o outperformed the\ncandidate with the highest scores of 113 and 106 according to CMST and BMST\nrespectively. This study highlights the importance of the potential of\nartificial intelligence in medical education and assessment. It demonstrates\nthat advanced models can achieve high accuracy and contextual understanding,\ndemonstrating their potential role in medical education and evaluation.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages, in Turkish language, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.12305v2",
    "published_date": "2024-08-22 11:25:08 UTC",
    "updated_date": "2024-08-27 06:31:09 UTC"
  },
  {
    "arxiv_id": "2408.12304v1",
    "title": "OPTDTALS: Approximate Logic Synthesis via Optimal Decision Trees Approach",
    "authors": [
      "Hao Hu",
      "Shaowei Cai"
    ],
    "abstract": "The growing interest in Explainable Artificial Intelligence (XAI) motivates\npromising studies of computing optimal Interpretable Machine Learning models,\nespecially decision trees. Such models generally provide optimality in compact\nsize or empirical accuracy. Recent works focus on improving efficiency due to\nthe natural scalability issue. The application of such models to practical\nproblems is quite limited. As an emerging problem in circuit design,\nApproximate Logic Synthesis (ALS) aims to reduce circuit complexity by\nsacrificing correctness. Recently, multiple heuristic machine learning methods\nhave been applied in ALS, which learns approximated circuits from samples of\ninput-output pairs.\n  In this paper, we propose a new ALS methodology realizing the approximation\nvia learning optimal decision trees in empirical accuracy. Compared to previous\nheuristic ALS methods, the guarantee of optimality achieves a more controllable\ntrade-off between circuit complexity and accuracy. Experimental results show\nclear improvements in our methodology in the quality of approximated designs\n(circuit complexity and accuracy) compared to the state-of-the-art approaches.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12304v1",
    "published_date": "2024-08-22 11:23:58 UTC",
    "updated_date": "2024-08-22 11:23:58 UTC"
  },
  {
    "arxiv_id": "2408.12293v1",
    "title": "AT-SNN: Adaptive Tokens for Vision Transformer on Spiking Neural Network",
    "authors": [
      "Donghwa Kang",
      "Youngmoon Lee",
      "Eun-Kyu Lee",
      "Brent Kang",
      "Jinkyu Lee",
      "Hyeongboo Baek"
    ],
    "abstract": "In the training and inference of spiking neural networks (SNNs), direct\ntraining and lightweight computation methods have been orthogonally developed,\naimed at reducing power consumption. However, only a limited number of\napproaches have applied these two mechanisms simultaneously and failed to fully\nleverage the advantages of SNN-based vision transformers (ViTs) since they were\noriginally designed for convolutional neural networks (CNNs). In this paper, we\npropose AT-SNN designed to dynamically adjust the number of tokens processed\nduring inference in SNN-based ViTs with direct training, wherein power\nconsumption is proportional to the number of tokens. We first demonstrate the\napplicability of adaptive computation time (ACT), previously limited to RNNs\nand ViTs, to SNN-based ViTs, enhancing it to discard less informative spatial\ntokens selectively. Also, we propose a new token-merge mechanism that relies on\nthe similarity of tokens, which further reduces the number of tokens while\nenhancing accuracy. We implement AT-SNN to Spikformer and show the\neffectiveness of AT-SNN in achieving high energy efficiency and accuracy\ncompared to state-of-the-art approaches on the image classification tasks,\nCIFAR10, CIFAR-100, and TinyImageNet. For example, our approach uses up to\n42.4% fewer tokens than the existing best-performing method on CIFAR-100, while\nconserving higher accuracy.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages",
    "pdf_url": "http://arxiv.org/pdf/2408.12293v1",
    "published_date": "2024-08-22 11:06:18 UTC",
    "updated_date": "2024-08-22 11:06:18 UTC"
  },
  {
    "arxiv_id": "2408.12292v1",
    "title": "Towards Deconfounded Image-Text Matching with Causal Inference",
    "authors": [
      "Wenhui Li",
      "Xinqi Su",
      "Dan Song",
      "Lanjun Wang",
      "Kun Zhang",
      "An-An Liu"
    ],
    "abstract": "Prior image-text matching methods have shown remarkable performance on many\nbenchmark datasets, but most of them overlook the bias in the dataset, which\nexists in intra-modal and inter-modal, and tend to learn the spurious\ncorrelations that extremely degrade the generalization ability of the model.\nFurthermore, these methods often incorporate biased external knowledge from\nlarge-scale datasets as prior knowledge into image-text matching model, which\nis inevitable to force model further learn biased associations. To address\nabove limitations, this paper firstly utilizes Structural Causal Models (SCMs)\nto illustrate how intra- and inter-modal confounders damage the image-text\nmatching. Then, we employ backdoor adjustment to propose an innovative\nDeconfounded Causal Inference Network (DCIN) for image-text matching task. DCIN\n(1) decomposes the intra- and inter-modal confounders and incorporates them\ninto the encoding stage of visual and textual features, effectively eliminating\nthe spurious correlations during image-text matching, and (2) uses causal\ninference to mitigate biases of external knowledge. Consequently, the model can\nlearn causality instead of spurious correlations caused by dataset bias.\nExtensive experiments on two well-known benchmark datasets, i.e., Flickr30K and\nMSCOCO, demonstrate the superiority of our proposed method.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "ACM MM",
    "pdf_url": "http://arxiv.org/pdf/2408.12292v1",
    "published_date": "2024-08-22 11:04:28 UTC",
    "updated_date": "2024-08-22 11:04:28 UTC"
  },
  {
    "arxiv_id": "2408.12279v1",
    "title": "Developing vocal system impaired patient-aimed voice quality assessment approach using ASR representation-included multiple features",
    "authors": [
      "Shaoxiang Dang",
      "Tetsuya Matsumoto",
      "Yoshinori Takeuchi",
      "Takashi Tsuboi",
      "Yasuhiro Tanaka",
      "Daisuke Nakatsubo",
      "Satoshi Maesawa",
      "Ryuta Saito",
      "Masahisa Katsuno",
      "Hiroaki Kudo"
    ],
    "abstract": "The potential of deep learning in clinical speech processing is immense, yet\nthe hurdles of limited and imbalanced clinical data samples loom large. This\narticle addresses these challenges by showcasing the utilization of automatic\nspeech recognition and self-supervised learning representations, pre-trained on\nextensive datasets of normal speech. This innovative approach aims to estimate\nvoice quality of patients with impaired vocal systems. Experiments involve\nchecks on PVQD dataset, covering various causes of vocal system damage in\nEnglish, and a Japanese dataset focusing on patients with Parkinson's disease\nbefore and after undergoing subthalamic nucleus deep brain stimulation\n(STN-DBS) surgery. The results on PVQD reveal a notable correlation (>0.8 on\nPCC) and an extraordinary accuracy (<0.5 on MSE) in predicting Grade, Breathy,\nand Asthenic indicators. Meanwhile, progress has been achieved in predicting\nthe voice quality of patients in the context of STN-DBS.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted by Interspeech 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.12279v1",
    "published_date": "2024-08-22 10:22:53 UTC",
    "updated_date": "2024-08-22 10:22:53 UTC"
  },
  {
    "arxiv_id": "2408.12270v1",
    "title": "Variance reduction of diffusion model's gradients with Taylor approximation-based control variate",
    "authors": [
      "Paul Jeha",
      "Will Grathwohl",
      "Michael Riis Andersen",
      "Carl Henrik Ek",
      "Jes Frellsen"
    ],
    "abstract": "Score-based models, trained with denoising score matching, are remarkably\neffective in generating high dimensional data. However, the high variance of\ntheir training objective hinders optimisation. We attempt to reduce it with a\ncontrol variate, derived via a $k$-th order Taylor expansion on the training\nobjective and its gradient. We prove an equivalence between the two and\ndemonstrate empirically the effectiveness of our approach on a low dimensional\nproblem setting; and study its effect on larger problems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, ICML Structured Probabilistic Inference & Generative\n  Modeling 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.12270v1",
    "published_date": "2024-08-22 10:08:34 UTC",
    "updated_date": "2024-08-22 10:08:34 UTC"
  },
  {
    "arxiv_id": "2408.12263v1",
    "title": "Toward the Evaluation of Large Language Models Considering Score Variance across Instruction Templates",
    "authors": [
      "Yusuke Sakai",
      "Adam Nohejl",
      "Jiangnan Hang",
      "Hidetaka Kamigaito",
      "Taro Watanabe"
    ],
    "abstract": "The natural language understanding (NLU) performance of large language models\n(LLMs) has been evaluated across various tasks and datasets. The existing\nevaluation methods, however, do not take into account the variance in scores\ndue to differences in prompts, which leads to unfair evaluation and comparison\nof NLU performance. Moreover, evaluation designed for specific prompts is\ninappropriate for instruction tuning, which aims to perform well with any\nprompt. It is therefore necessary to find a way to measure NLU performance in a\nfair manner, considering score variance between different instruction\ntemplates. In this study, we provide English and Japanese cross-lingual\ndatasets for evaluating the NLU performance of LLMs, which include multiple\ninstruction templates for fair evaluation of each task, along with regular\nexpressions to constrain the output format. Furthermore, we propose the Sharpe\nscore as an evaluation metric that takes into account the variance in scores\nbetween templates. Comprehensive analysis of English and Japanese LLMs reveals\nthat the high variance among templates has a significant impact on the fair\nevaluation of LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "19 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.12263v1",
    "published_date": "2024-08-22 10:00:20 UTC",
    "updated_date": "2024-08-22 10:00:20 UTC"
  },
  {
    "arxiv_id": "2408.12259v2",
    "title": "How Safe is Your Safety Metric? Automatic Concatenation Tests for Metric Reliability",
    "authors": [
      "Ora Nova Fandina",
      "Leshem Choshen",
      "Eitan Farchi",
      "George Kour",
      "Yotam Perlitz",
      "Orna Raz"
    ],
    "abstract": "Consider a scenario where a harmfulness evaluation metric intended to filter\nunsafe responses from a Large Language Model. When applied to individual\nharmful prompt-response pairs, it correctly flags them as unsafe by assigning a\nhigh-risk score. Yet, if those same pairs are concatenated, the metrics\ndecision unexpectedly reverses - labelling the combined content as safe with a\nlow score, allowing the harmful text to bypass the filter. We found that\nmultiple safety metrics, including advanced metrics such as GPT-based judges,\nexhibit this non-safe behaviour. Moreover, they show a strong sensitivity to\ninput order: responses are often classified as safe if safe content appears\nfirst, regardless of any harmful content that follows, and vice versa. These\nfindings underscore the importance of evaluating the safety of safety metrics,\nthat is, the reliability of their output scores. To address this, we developed\ngeneral, automatic, concatenation-based tests to assess key properties of these\nmetrics. When applied in a model safety scenario, the tests revealed\nsignificant inconsistencies in harmfulness evaluations.",
    "categories": [
      "cs.AI",
      "68T50"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12259v2",
    "published_date": "2024-08-22 09:57:57 UTC",
    "updated_date": "2025-02-12 19:32:28 UTC"
  },
  {
    "arxiv_id": "2408.12254v1",
    "title": "A Language-agnostic Model of Child Language Acquisition",
    "authors": [
      "Louis Mahon",
      "Omri Abend",
      "Uri Berger",
      "Katherine Demuth",
      "Mark Johnson",
      "Mark Steedman"
    ],
    "abstract": "This work reimplements a recent semantic bootstrapping child-language\nacquisition model, which was originally designed for English, and trains it to\nlearn a new language: Hebrew. The model learns from pairs of utterances and\nlogical forms as meaning representations, and acquires both syntax and word\nmeanings simultaneously. The results show that the model mostly transfers to\nHebrew, but that a number of factors, including the richer morphology in\nHebrew, makes the learning slower and less robust. This suggests that a clear\ndirection for future work is to enable the model to leverage the similarities\nbetween different word forms.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12254v1",
    "published_date": "2024-08-22 09:48:06 UTC",
    "updated_date": "2024-08-22 09:48:06 UTC"
  },
  {
    "arxiv_id": "2408.12250v1",
    "title": "Can Artificial Intelligence Embody Moral Values?",
    "authors": [
      "Torben Swoboda",
      "Lode Lauwaert"
    ],
    "abstract": "The neutrality thesis holds that technology cannot be laden with values. This\nlong-standing view has faced critiques, but much of the argumentation against\nneutrality has focused on traditional, non-smart technologies like bridges and\nrazors. In contrast, AI is a smart technology increasingly used in high-stakes\ndomains like healthcare, finance, and policing, where its decisions can cause\nmoral harm. In this paper, we argue that artificial intelligence, particularly\nartificial agents that autonomously make decisions to pursue their goals,\nchallenge the neutrality thesis. Our central claim is that the computational\nmodels underlying artificial agents can integrate representations of moral\nvalues such as fairness, honesty and avoiding harm. We provide a conceptual\nframework discussing the neutrality thesis, values, and AI. Moreover, we\nexamine two approaches to designing computational models of morality,\nartificial conscience and ethical prompting, and present empirical evidence\nfrom text-based game environments that artificial agents with such models\nexhibit more ethical behavior compared to agents without these models. The\nfindings support that AI can embody moral values, which contradicts the claim\nthat all technologies are necessarily value-neutral.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12250v1",
    "published_date": "2024-08-22 09:39:16 UTC",
    "updated_date": "2024-08-22 09:39:16 UTC"
  },
  {
    "arxiv_id": "2408.12249v1",
    "title": "LLMs are not Zero-Shot Reasoners for Biomedical Information Extraction",
    "authors": [
      "Aishik Nagar",
      "Viktor Schlegel",
      "Thanh-Tung Nguyen",
      "Hao Li",
      "Yuping Wu",
      "Kuluhan Binici",
      "Stefan Winkler"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly adopted for applications in\nhealthcare, reaching the performance of domain experts on tasks such as\nquestion answering and document summarisation. Despite their success on these\ntasks, it is unclear how well LLMs perform on tasks that are traditionally\npursued in the biomedical domain, such as structured information extration. To\nbreach this gap, in this paper, we systematically benchmark LLM performance in\nMedical Classification and Named Entity Recognition (NER) tasks. We aim to\ndisentangle the contribution of different factors to the performance,\nparticularly the impact of LLMs' task knowledge and reasoning capabilities,\ntheir (parametric) domain knowledge, and addition of external knowledge. To\nthis end we evaluate various open LLMs -- including BioMistral and Llama-2\nmodels -- on a diverse set of biomedical datasets, using standard prompting,\nChain-of-Thought (CoT) and Self-Consistency based reasoning as well as\nRetrieval-Augmented Generation (RAG) with PubMed and Wikipedia corpora.\nCounter-intuitively, our results reveal that standard prompting consistently\noutperforms more complex techniques across both tasks, laying bare the\nlimitations in the current application of CoT, self-consistency and RAG in the\nbiomedical domain. Our findings suggest that advanced prompting methods\ndeveloped for knowledge- or reasoning-intensive tasks, such as CoT or RAG, are\nnot easily portable to biomedical tasks where precise structured outputs are\nrequired. This highlights the need for more effective integration of external\nknowledge and reasoning mechanisms in LLMs to enhance their performance in\nreal-world biomedical applications.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "11 pages",
    "pdf_url": "http://arxiv.org/pdf/2408.12249v1",
    "published_date": "2024-08-22 09:37:40 UTC",
    "updated_date": "2024-08-22 09:37:40 UTC"
  },
  {
    "arxiv_id": "2408.12247v2",
    "title": "Enhanced Fine-Tuning of Lightweight Domain-Specific Q&A Model Based on Large Language Models",
    "authors": [
      "Shenglin Zhang",
      "Pengtian Zhu",
      "Minghua Ma",
      "Jiagang Wang",
      "Yongqian Sun",
      "Dongwen Li",
      "Jingyu Wang",
      "Qianying Guo",
      "Xiaolei Hua",
      "Lin Zhu",
      "Dan Pei"
    ],
    "abstract": "Large language models (LLMs) excel at general question-answering (Q&A) but\noften fall short in specialized domains due to a lack of domain-specific\nknowledge. Commercial companies face the dual challenges of privacy protection\nand resource constraints when involving LLMs for fine-tuning. This paper\npropose a novel framework, Self-Evolution, designed to address these issues by\nleveraging lightweight open-source LLMs through multiple iterative fine-tuning\nrounds. To enhance the efficiency of iterative fine-tuning, Self-Evolution\nemploy a strategy that filters and reinforces the knowledge with higher value\nduring the iterative process. We employed Self-Evolution on Qwen1.5-7B-Chat\nusing 4,000 documents containing rich domain knowledge from China Mobile,\nachieving a performance score 174% higher on domain-specific question-answering\nevaluations than Qwen1.5-7B-Chat and even 22% higher than Qwen1.5-72B-Chat.\nSelf-Evolution has been deployed in China Mobile's daily operation and\nmaintenance for 117 days, and it improves the efficiency of locating alarms,\nfixing problems, and finding related reports, with an average efficiency\nimprovement of over 18.6%. In addition, we release Self-Evolution framework\ncode in https://github.com/Zero-Pointer/Self-Evolution.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12247v2",
    "published_date": "2024-08-22 09:36:15 UTC",
    "updated_date": "2024-08-23 01:25:26 UTC"
  },
  {
    "arxiv_id": "2408.12237v1",
    "title": "Weight Scope Alignment: A Frustratingly Easy Method for Model Merging",
    "authors": [
      "Yichu Xu",
      "Xin-Chun Li",
      "Le Gan",
      "De-Chuan Zhan"
    ],
    "abstract": "Merging models becomes a fundamental procedure in some applications that\nconsider model efficiency and robustness. The training randomness or Non-I.I.D.\ndata poses a huge challenge for averaging-based model fusion. Previous research\nefforts focus on element-wise regularization or neural permutations to enhance\nmodel averaging while overlooking weight scope variations among models, which\ncan significantly affect merging effectiveness. In this paper, we reveal\nvariations in weight scope under different training conditions, shedding light\non its influence on model merging. Fortunately, the parameters in each layer\nbasically follow the Gaussian distribution, which inspires a novel and simple\nregularization approach named Weight Scope Alignment (WSA). It contains two key\ncomponents: 1) leveraging a target weight scope to guide the model training\nprocess for ensuring weight scope matching in the subsequent model merging. 2)\nfusing the weight scope of two or more models into a unified one for\nmulti-stage model fusion. We extend the WSA regularization to two different\nscenarios, including Mode Connectivity and Federated Learning. Abundant\nexperimental studies validate the effectiveness of our approach.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12237v1",
    "published_date": "2024-08-22 09:13:27 UTC",
    "updated_date": "2024-08-22 09:13:27 UTC"
  },
  {
    "arxiv_id": "2408.12236v1",
    "title": "MedDiT: A Knowledge-Controlled Diffusion Transformer Framework for Dynamic Medical Image Generation in Virtual Simulated Patient",
    "authors": [
      "Yanzeng Li",
      "Cheng Zeng",
      "Jinchao Zhang",
      "Jie Zhou",
      "Lei Zou"
    ],
    "abstract": "Medical education relies heavily on Simulated Patients (SPs) to provide a\nsafe environment for students to practice clinical skills, including medical\nimage analysis. However, the high cost of recruiting qualified SPs and the lack\nof diverse medical imaging datasets have presented significant challenges. To\naddress these issues, this paper introduces MedDiT, a novel\nknowledge-controlled conversational framework that can dynamically generate\nplausible medical images aligned with simulated patient symptoms, enabling\ndiverse diagnostic skill training. Specifically, MedDiT integrates various\npatient Knowledge Graphs (KGs), which describe the attributes and symptoms of\npatients, to dynamically prompt Large Language Models' (LLMs) behavior and\ncontrol the patient characteristics, mitigating hallucination during medical\nconversation. Additionally, a well-tuned Diffusion Transformer (DiT) model is\nincorporated to generate medical images according to the specified patient\nattributes in the KG. In this paper, we present the capabilities of MedDiT\nthrough a practical demonstration, showcasing its ability to act in diverse\nsimulated patient cases and generate the corresponding medical images. This can\nprovide an abundant and interactive learning experience for students, advancing\nmedical education by offering an immersive simulation platform for future\nhealthcare professionals. The work sheds light on the feasibility of\nincorporating advanced technologies like LLM, KG, and DiT in education\napplications, highlighting their potential to address the challenges faced in\nsimulated patient-based medical education.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12236v1",
    "published_date": "2024-08-22 09:10:29 UTC",
    "updated_date": "2024-08-22 09:10:29 UTC"
  },
  {
    "arxiv_id": "2408.12226v1",
    "title": "EvalYaks: Instruction Tuning Datasets and LoRA Fine-tuned Models for Automated Scoring of CEFR B2 Speaking Assessment Transcripts",
    "authors": [
      "Nicy Scaria",
      "Silvester John Joseph Kennedy",
      "Thomas Latinovich",
      "Deepak Subramani"
    ],
    "abstract": "Relying on human experts to evaluate CEFR speaking assessments in an\ne-learning environment creates scalability challenges, as it limits how quickly\nand widely assessments can be conducted. We aim to automate the evaluation of\nCEFR B2 English speaking assessments in e-learning environments from\nconversation transcripts. First, we evaluate the capability of leading open\nsource and commercial Large Language Models (LLMs) to score a candidate's\nperformance across various criteria in the CEFR B2 speaking exam in both global\nand India-specific contexts. Next, we create a new expert-validated,\nCEFR-aligned synthetic conversational dataset with transcripts that are rated\nat different assessment scores. In addition, new instruction-tuned datasets are\ndeveloped from the English Vocabulary Profile (up to CEFR B2 level) and the\nCEFR-SP WikiAuto datasets. Finally, using these new datasets, we perform\nparameter efficient instruction tuning of Mistral Instruct 7B v0.2 to develop a\nfamily of models called EvalYaks. Four models in this family are for assessing\nthe four sections of the CEFR B2 speaking exam, one for identifying the CEFR\nlevel of vocabulary and generating level-specific vocabulary, and another for\ndetecting the CEFR level of text and generating level-specific text. EvalYaks\nachieved an average acceptable accuracy of 96%, a degree of variation of 0.35\nlevels, and performed 3 times better than the next best model. This\ndemonstrates that a 7B parameter LLM instruction tuned with high-quality\nCEFR-aligned assessment data can effectively evaluate and score CEFR B2 English\nspeaking assessments, offering a promising solution for scalable, automated\nlanguage proficiency evaluation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12226v1",
    "published_date": "2024-08-22 08:57:31 UTC",
    "updated_date": "2024-08-22 08:57:31 UTC"
  },
  {
    "arxiv_id": "2408.12214v2",
    "title": "Bridging Large Language Models and Optimization: A Unified Framework for Text-attributed Combinatorial Optimization",
    "authors": [
      "Xia Jiang",
      "Yaoxin Wu",
      "Yuan Wang",
      "Yingqian Zhang"
    ],
    "abstract": "To advance capabilities of large language models (LLMs) in solving\ncombinatorial optimization problems (COPs), this paper presents the\nLanguage-based Neural COP Solver (LNCS), a novel framework that is unified for\nthe end-to-end resolution of diverse text-attributed COPs. LNCS leverages LLMs\nto encode problem instances into a unified semantic space, and integrates their\nembeddings with a Transformer-based solution generator to produce high-quality\nsolutions. By training the solution generator with conflict-free multi-task\nreinforcement learning, LNCS effectively enhances LLM performance in tackling\nCOPs of varying types and sizes, achieving state-of-the-art results across\ndiverse problems. Extensive experiments validate the effectiveness and\ngeneralizability of the LNCS, highlighting its potential as a unified and\npractical framework for real-world COP applications.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12214v2",
    "published_date": "2024-08-22 08:42:44 UTC",
    "updated_date": "2024-12-15 09:20:31 UTC"
  },
  {
    "arxiv_id": "2408.12212v2",
    "title": "Relational decomposition for program synthesis",
    "authors": [
      "Céline Hocquette",
      "Andrew Cropper"
    ],
    "abstract": "We introduce a relational approach to program synthesis. The key idea is to\ndecompose synthesis tasks into simpler relational synthesis subtasks.\nSpecifically, our representation decomposes a training input-output example\ninto sets of input and output facts respectively. We then learn relations\nbetween the input and output facts. We demonstrate our approach using an\noff-the-shelf inductive logic programming (ILP) system on four challenging\nsynthesis datasets. Our results show that (i) our representation can outperform\na standard one, and (ii) an off-the-shelf ILP system with our representation\ncan outperform domain-specific approaches.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12212v2",
    "published_date": "2024-08-22 08:41:52 UTC",
    "updated_date": "2025-02-06 14:58:03 UTC"
  },
  {
    "arxiv_id": "2408.12198v1",
    "title": "Two-level deep domain decomposition method",
    "authors": [
      "Victorita Dolean",
      "Serge Gratton",
      "Alexander Heinlein",
      "Valentin Mercier"
    ],
    "abstract": "This study presents a two-level Deep Domain Decomposition Method (Deep-DDM)\naugmented with a coarse-level network for solving boundary value problems using\nphysics-informed neural networks (PINNs). The addition of the coarse level\nnetwork improves scalability and convergence rates compared to the single level\nmethod. Tested on a Poisson equation with Dirichlet boundary conditions, the\ntwo-level deep DDM demonstrates superior performance, maintaining efficient\nconvergence regardless of the number of subdomains. This advance provides a\nmore scalable and effective approach to solving complex partial differential\nequations with machine learning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Preprint proceeding format",
    "pdf_url": "http://arxiv.org/pdf/2408.12198v1",
    "published_date": "2024-08-22 08:20:39 UTC",
    "updated_date": "2024-08-22 08:20:39 UTC"
  },
  {
    "arxiv_id": "2408.12188v1",
    "title": "Reasoning Factual Knowledge in Structured Data with Large Language Models",
    "authors": [
      "Sirui Huang",
      "Yanggan Gu",
      "Xuming Hu",
      "Zhonghao Li",
      "Qing Li",
      "Guandong Xu"
    ],
    "abstract": "Large language models (LLMs) have made remarkable progress in various natural\nlanguage processing tasks as a benefit of their capability to comprehend and\nreason with factual knowledge. However, a significant amount of factual\nknowledge is stored in structured data, which possesses unique characteristics\nthat differ from the unstructured texts used for pretraining. This difference\ncan introduce imperceptible inference parameter deviations, posing challenges\nfor LLMs in effectively utilizing and reasoning with structured data to\naccurately infer factual knowledge. To this end, we propose a benchmark named\nStructFact, to evaluate the structural reasoning capabilities of LLMs in\ninferring factual knowledge. StructFact comprises 8,340 factual questions\nencompassing various tasks, domains, timelines, and regions. This benchmark\nallows us to investigate the capability of LLMs across five factual tasks\nderived from the unique characteristics of structural facts. Extensive\nexperiments on a set of LLMs with different training strategies reveal the\nlimitations of current LLMs in inferring factual knowledge from structured\ndata. We present this benchmark as a compass to navigate the strengths and\nweaknesses of LLMs in reasoning with structured data for knowledge-sensitive\ntasks, and to encourage advancements in related real-world applications. Please\nfind our code at https://github.com/EganGu/StructFact.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12188v1",
    "published_date": "2024-08-22 08:05:09 UTC",
    "updated_date": "2024-08-22 08:05:09 UTC"
  },
  {
    "arxiv_id": "2408.12187v1",
    "title": "A Safe and Efficient Self-evolving Algorithm for Decision-making and Control of Autonomous Driving Systems",
    "authors": [
      "Shuo Yang",
      "Liwen Wang",
      "Yanjun Huang",
      "Hong Chen"
    ],
    "abstract": "Autonomous vehicles with a self-evolving ability are expected to cope with\nunknown scenarios in the real-world environment. Take advantage of trial and\nerror mechanism, reinforcement learning is able to self evolve by learning the\noptimal policy, and it is particularly well suitable for solving\ndecision-making problems. However, reinforcement learning suffers from safety\nissues and low learning efficiency, especially in the continuous action space.\nTherefore, the motivation of this paper is to address the above problem by\nproposing a hybrid Mechanism-Experience-Learning augmented approach.\nSpecifically, to realize the efficient self-evolution, the driving tendency by\nanalogy with human driving experience is proposed to reduce the search space of\nthe autonomous driving problem, while the constrained optimization problem\nbased on a mechanistic model is designed to ensure safety during the\nself-evolving process. Experimental results show that the proposed method is\ncapable of generating safe and reasonable actions in various complex scenarios,\nimproving the performance of the autonomous driving system. Compared to\nconventional reinforcement learning, the safety and efficiency of the proposed\nalgorithm are greatly improved. The training process is collision-free, and the\ntraining time is equivalent to less than 10 minutes in the real world.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12187v1",
    "published_date": "2024-08-22 08:05:03 UTC",
    "updated_date": "2024-08-22 08:05:03 UTC"
  },
  {
    "arxiv_id": "2408.12185v1",
    "title": "Rank and Align: Towards Effective Source-free Graph Domain Adaptation",
    "authors": [
      "Junyu Luo",
      "Zhiping Xiao",
      "Yifan Wang",
      "Xiao Luo",
      "Jingyang Yuan",
      "Wei Ju",
      "Langechuan Liu",
      "Ming Zhang"
    ],
    "abstract": "Graph neural networks (GNNs) have achieved impressive performance in graph\ndomain adaptation. However, extensive source graphs could be unavailable in\nreal-world scenarios due to privacy and storage concerns. To this end, we\ninvestigate an underexplored yet practical problem of source-free graph domain\nadaptation, which transfers knowledge from source models instead of source\ngraphs to a target domain. To solve this problem, we introduce a novel\nGNN-based approach called Rank and Align (RNA), which ranks graph similarities\nwith spectral seriation for robust semantics learning, and aligns inharmonic\ngraphs with harmonic graphs which close to the source domain for subgraph\nextraction. In particular, to overcome label scarcity, we employ the spectral\nseriation algorithm to infer the robust pairwise rankings, which can guide\nsemantic learning using a similarity learning objective. To depict distribution\nshifts, we utilize spectral clustering and the silhouette coefficient to detect\nharmonic graphs, which the source model can easily classify. To reduce\npotential domain discrepancy, we extract domain-invariant subgraphs from\ninharmonic graphs by an adversarial edge sampling process, which guides the\ninvariant learning of GNNs. Extensive experiments on several benchmark datasets\ndemonstrate the effectiveness of our proposed RNA.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.LG",
    "comment": "Published in IJCAI2024",
    "pdf_url": "http://arxiv.org/pdf/2408.12185v1",
    "published_date": "2024-08-22 08:00:50 UTC",
    "updated_date": "2024-08-22 08:00:50 UTC"
  },
  {
    "arxiv_id": "2408.12184v1",
    "title": "Randomness control and reproducibility study of random forest algorithm in R and Python",
    "authors": [
      "Louisa Camadini",
      "Yanis Bouzid",
      "Maeva Merlet",
      "Léopold Carron"
    ],
    "abstract": "When it comes to the safety of cosmetic products, compliance with regulatory\nstandards is crucialto guarantee consumer protection against the risks of skin\nirritation. Toxicologists must thereforebe fully conversant with all risks.\nThis applies not only to their day-to-day work, but also to allthe algorithms\nthey integrate into their routines. Recognizing this, ensuring the\nreproducibility ofalgorithms becomes one of the most crucial aspects to\naddress.However, how can we prove the robustness of an algorithm such as the\nrandom forest, that reliesheavily on randomness? In this report, we will\ndiscuss the strategy of integrating random forest intoocular tolerance\nassessment for toxicologists.We will compare four packages: randomForest and\nRanger (R packages), adapted in Python via theSKRanger package, and the widely\nused Scikit-Learn with the RandomForestClassifier() function.Our goal is to\ninvestigate the parameters and sources of randomness affecting the outcomes\nofRandom Forest algorithms.By setting comparable parameters and using the same\nPseudo-Random Number Generator (PRNG),we expect to reproduce results\nconsistently across the various available implementations of therandom forest\nalgorithm. Nevertheless, this exploration will unveil hidden layers of\nrandomness andguide our understanding of the critical parameters necessary to\nensure reproducibility across all fourimplementations of the random forest\nalgorithm.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12184v1",
    "published_date": "2024-08-22 07:59:49 UTC",
    "updated_date": "2024-08-22 07:59:49 UTC"
  },
  {
    "arxiv_id": "2408.12159v1",
    "title": "Search-Based LLMs for Code Optimization",
    "authors": [
      "Shuzheng Gao",
      "Cuiyun Gao",
      "Wenchao Gu",
      "Michael Lyu"
    ],
    "abstract": "The code written by developers usually suffers from efficiency problems and\ncontain various performance bugs. These inefficiencies necessitate the research\nof automated refactoring methods for code optimization. Early research in code\noptimization employs rule-based methods and focuses on specific inefficiency\nissues, which are labor-intensive and suffer from the low coverage issue.\nRecent work regards the task as a sequence generation problem, and resorts to\ndeep learning (DL) techniques such as large language models (LLMs). These\nmethods typically prompt LLMs to directly generate optimized code. Although\nthese methods show state-of-the-art performance, such one-step generation\nparadigm is hard to achieve an optimal solution. First, complex optimization\nmethods such as combinatorial ones are hard to be captured by LLMs. Second, the\none-step generation paradigm poses challenge in precisely infusing the\nknowledge required for effective code optimization within LLMs, resulting in\nunder-optimized code.To address these problems, we propose to model this task\nfrom the search perspective, and propose a search-based LLMs framework named\nSBLLM that enables iterative refinement and discovery of improved optimization\nmethods. SBLLM synergistically integrate LLMs with evolutionary search and\nconsists of three key components: 1) an execution-based representative sample\nselection part that evaluates the fitness of each existing optimized code and\nprioritizes promising ones to pilot the generation of improved code; 2) an\nadaptive optimization pattern retrieval part that infuses targeted optimization\npatterns into the model for guiding LLMs towards rectifying and progressively\nenhancing their optimization methods; and 3) a genetic operator-inspired\nchain-of-thought prompting part that aids LLMs in combining different\noptimization methods and generating improved optimization methods.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted by 2025 IEEE/ACM 47th International Conference on Software\n  Engineering (ICSE'25)",
    "pdf_url": "http://arxiv.org/pdf/2408.12159v1",
    "published_date": "2024-08-22 06:59:46 UTC",
    "updated_date": "2024-08-22 06:59:46 UTC"
  },
  {
    "arxiv_id": "2408.12157v1",
    "title": "Implicit Sentiment Analysis Based on Chain of Thought Prompting",
    "authors": [
      "Zhihua Duan",
      "Jialin Wang"
    ],
    "abstract": "Implicit Sentiment Analysis (ISA) is a crucial research area in natural\nlanguage processing. Inspired by the idea of large language model Chain of\nThought (CoT), this paper introduces a Sentiment Analysis of Thinking (SAoT)\nframework. The framework first analyzes the implicit aspects and opinions in\nthe text using common sense and thinking chain capabilities. Then, it reflects\non the process of implicit sentiment analysis and finally deduces the polarity\nof sentiment. The model is evaluated on the SemEval 2014 dataset, consisting of\n1120 restaurant reviews and 638 laptop reviews. The experimental results\ndemonstrate that the utilization of the ERNIE-Bot-4+SAoT model yields a notable\nperformance improvement. Specifically, on the restaurant dataset, the F1 score\nreaches 75.27, accompanied by an ISA score of 66.29. Similarly, on the computer\ndataset, the F1 score achieves 76.50, while the ISA score amounts to 73.46.\nComparatively, the ERNIE-Bot-4+SAoT model surpasses the BERTAsp + SCAPt\nbaseline by an average margin of 47.99%.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12157v1",
    "published_date": "2024-08-22 06:55:29 UTC",
    "updated_date": "2024-08-22 06:55:29 UTC"
  },
  {
    "arxiv_id": "2408.12151v2",
    "title": "A Tighter Complexity Analysis of SparseGPT",
    "authors": [
      "Xiaoyu Li",
      "Yingyu Liang",
      "Zhenmei Shi",
      "Zhao Song"
    ],
    "abstract": "In this work, we improved the analysis of the running time of SparseGPT\n[Frantar, Alistarh ICML 2023] from $O(d^{3})$ to $O(d^{\\omega} + d^{2+a+o(1)} +\nd^{1+\\omega(1,1,a)-a})$ for any $a \\in [0, 1]$, where $\\omega$ is the exponent\nof matrix multiplication. In particular, for the current $\\omega \\approx 2.371$\n[Alman, Duan, Williams, Xu, Xu, Zhou 2024], our running time boils down to\n$O(d^{2.53})$. This running time is due to the analysis of the lazy update\nbehavior in iterative maintenance problems such as [Deng, Song, Weinstein 2022;\nBrand, Song, Zhou ICML 2024].",
    "categories": [
      "cs.DS",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.DS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12151v2",
    "published_date": "2024-08-22 06:40:32 UTC",
    "updated_date": "2024-10-18 03:36:03 UTC"
  },
  {
    "arxiv_id": "2408.12150v1",
    "title": "DeepHQ: Learned Hierarchical Quantizer for Progressive Deep Image Coding",
    "authors": [
      "Jooyoung Lee",
      "Se Yoon Jeong",
      "Munchurl Kim"
    ],
    "abstract": "Unlike fixed- or variable-rate image coding, progressive image coding (PIC)\naims to compress various qualities of images into a single bitstream,\nincreasing the versatility of bitstream utilization and providing high\ncompression efficiency compared to simulcast compression. Research on neural\nnetwork (NN)-based PIC is in its early stages, mainly focusing on applying\nvarying quantization step sizes to the transformed latent representations in a\nhierarchical manner. These approaches are designed to compress only the\nprogressively added information as the quality improves, considering that a\nwider quantization interval for lower-quality compression includes multiple\nnarrower sub-intervals for higher-quality compression. However, the existing\nmethods are based on handcrafted quantization hierarchies, resulting in\nsub-optimal compression efficiency. In this paper, we propose an NN-based\nprogressive coding method that firstly utilizes learned quantization step sizes\nvia learning for each quantization layer. We also incorporate selective\ncompression with which only the essential representation components are\ncompressed for each quantization layer. We demonstrate that our method achieves\nsignificantly higher coding efficiency than the existing approaches with\ndecreased decoding time and reduced model size.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12150v1",
    "published_date": "2024-08-22 06:32:53 UTC",
    "updated_date": "2024-08-22 06:32:53 UTC"
  },
  {
    "arxiv_id": "2408.12148v1",
    "title": "Multi-tool Integration Application for Math Reasoning Using Large Language Model",
    "authors": [
      "Zhihua Duan",
      "Jialin Wang"
    ],
    "abstract": "Mathematical reasoning is an important research direction in the field of\nartificial intelligence. This article proposes a novel multi tool application\nframework for mathematical reasoning, aiming to achieve more comprehensive and\naccurate mathematical reasoning by utilizing the collaborative effect of large\nlanguage models (LLMs) and multiple external tools. Firstly, use a Math Tool to\nperform basic mathematical calculations during the inference process through\ninteraction with LLM. Secondly, Code Tool can generate code fragments that\ncomply with syntax rules and execute them, providing support for complex\nmathematical problems. Then, through the iterative reasoning of the CoT Tool,\nthe logical coherence and accuracy of mathematical reasoning are enhanced.\nUltimately, by using self consistency tools to select the final answer based on\ndifferent parameters, the consistency and reliability of reasoning are\nimproved. Through the synergistic effect of these tools, the framework has\nachieved significant performance improvement in mathematical reasoning tasks.\nWe conducted experiments on the NumGLUE Task 4 test set, which includes 220\nmathematical reasoning fill in the blank questions. The experimental results\nshowed that, based on Math Tool, Code Tool, and CoT Tool, in Task 4 task,our\nmethod achieved an accuracy of 89.09,compared with the GPT3+FewShot baseline,\nFew Shot+ERNIE-4.0+self consistency improved by 49.09%, and compared with\nfine-tuning the Fine tuning baseline, Few Shot+ERNIE-4.0+self consistency\nimproved by 52.29%",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12148v1",
    "published_date": "2024-08-22 06:27:10 UTC",
    "updated_date": "2024-08-22 06:27:10 UTC"
  },
  {
    "arxiv_id": "2408.12142v2",
    "title": "MDD-5k: A New Diagnostic Conversation Dataset for Mental Disorders Synthesized via Neuro-Symbolic LLM Agents",
    "authors": [
      "Congchi Yin",
      "Feng Li",
      "Shu Zhang",
      "Zike Wang",
      "Jun Shao",
      "Piji Li",
      "Jianhua Chen",
      "Xun Jiang"
    ],
    "abstract": "The clinical diagnosis of most mental disorders primarily relies on the\nconversations between psychiatrist and patient. The creation of such diagnostic\nconversation datasets is promising to boost the AI mental healthcare community.\nHowever, directly collecting the conversations in real diagnosis scenarios is\nnear impossible due to stringent privacy and ethical considerations. To address\nthis issue, we seek to synthesize diagnostic conversation by exploiting\nanonymized patient cases that are easier to access. Specifically, we design a\nneuro-symbolic multi-agent framework for synthesizing the diagnostic\nconversation of mental disorders with large language models. It takes patient\ncase as input and is capable of generating multiple diverse conversations with\none single patient case. The framework basically involves the interaction\nbetween a doctor agent and a patient agent, and generates conversations under\nsymbolic control via a dynamic diagnosis tree. By applying the proposed\nframework, we develop the largest Chinese mental disorders diagnosis dataset\nMDD-5k. This dataset is built upon 1000 real, anonymized patient cases by\ncooperating with Shanghai Mental Health Center and comprises 5000 high-quality\nlong conversations with diagnosis results and treatment opinions as labels. To\nthe best of our knowledge, it's also the first labeled dataset for Chinese\nmental disorders diagnosis. Human evaluation demonstrates the proposed MDD-5k\ndataset successfully simulates human-like diagnostic process of mental\ndisorders.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by the 39th Annual AAAI Conference on Artificial\n  Intelligence",
    "pdf_url": "http://arxiv.org/pdf/2408.12142v2",
    "published_date": "2024-08-22 05:59:47 UTC",
    "updated_date": "2024-12-26 06:39:38 UTC"
  },
  {
    "arxiv_id": "2408.12139v2",
    "title": "DRExplainer: Quantifiable Interpretability in Drug Response Prediction with Directed Graph Convolutional Network",
    "authors": [
      "Haoyuan Shi",
      "Tao Xu",
      "Xiaodi Li",
      "Qian Gao",
      "Zhiwei Xiong",
      "Junfeng Xia",
      "Zhenyu Yue"
    ],
    "abstract": "Predicting the response of a cancer cell line to a therapeutic drug is\npivotal for personalized medicine. Despite numerous deep learning methods that\nhave been developed for drug response prediction, integrating diverse\ninformation about biological entities and predicting the directional response\nremain major challenges. Here, we propose a novel interpretable predictive\nmodel, DRExplainer, which leverages a directed graph convolutional network to\nenhance the prediction in a directed bipartite network framework. DRExplainer\nconstructs a directed bipartite network integrating multi-omics profiles of\ncell lines, the chemical structure of drugs and known drug response to achieve\ndirected prediction. Then, DRExplainer identifies the most relevant subgraph to\neach prediction in this directed bipartite network by learning a mask,\nfacilitating critical medical decision-making. Additionally, we introduce a\nquantifiable method for model interpretability that leverages a ground truth\nbenchmark dataset curated from biological features. In computational\nexperiments, DRExplainer outperforms state-of-the-art predictive methods and\nanother graph-based explanation method under the same experimental setting.\nFinally, the case studies further validate the interpretability and the\neffectiveness of DRExplainer in predictive novel drug response. Our code is\navailable at: https://github.com/vshy-dream/DRExplainer.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12139v2",
    "published_date": "2024-08-22 05:45:48 UTC",
    "updated_date": "2025-03-28 02:50:29 UTC"
  },
  {
    "arxiv_id": "2408.12133v2",
    "title": "Self-Supervised Representation Learning for Geospatial Objects: A Survey",
    "authors": [
      "Yile Chen",
      "Weiming Huang",
      "Kaiqi Zhao",
      "Yue Jiang",
      "Gao Cong"
    ],
    "abstract": "The proliferation of various data sources in urban and territorial\nenvironments has significantly facilitated the development of geospatial\nartificial intelligence (GeoAI) across a wide range of geospatial applications.\nHowever, geospatial data, which is inherently linked to geospatial objects,\noften exhibits data heterogeneity that necessitates specialized fusion and\nrepresentation strategies while simultaneously being inherently sparse in\nlabels for downstream tasks. Consequently, there is a growing demand for\ntechniques that can effectively leverage geospatial data without heavy reliance\non task-specific labels and model designs. This need aligns with the principles\nof self-supervised learning (SSL), which has garnered increasing attention for\nits ability to learn effective and generalizable representations directly from\ndata without extensive labeled supervision. This paper presents a comprehensive\nand up-to-date survey of SSL techniques specifically applied to or developed\nfor geospatial objects in three primary vector geometric types: Point,\nPolyline, and Polygon. We systematically categorize various SSL techniques into\npredictive and contrastive methods, and analyze their adaptation to different\ndata types for representation learning across various downstream tasks.\nFurthermore, we examine the emerging trends in SSL for geospatial objects,\nparticularly the gradual advancements towards geospatial foundation models.\nFinally, we discuss key challenges in current research and outline promising\ndirections for future investigation. By offering a structured analysis of\nexisting studies, this paper aims to inspire continued progress in integrating\nSSL with geospatial objects, and the development of geospatial foundation\nmodels in a longer term.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12133v2",
    "published_date": "2024-08-22 05:28:22 UTC",
    "updated_date": "2025-04-25 06:06:00 UTC"
  },
  {
    "arxiv_id": "2408.12130v3",
    "title": "S-EPOA: Overcoming the Indistinguishability of Segments with Skill-Driven Preference-Based Reinforcement Learning",
    "authors": [
      "Ni Mu",
      "Yao Luan",
      "Yiqin Yang",
      "Bo Xu",
      "Qing-shan Jia"
    ],
    "abstract": "Preference-based reinforcement learning (PbRL) stands out by utilizing human\npreferences as a direct reward signal, eliminating the need for intricate\nreward engineering. However, despite its potential, traditional PbRL methods\nare often constrained by the indistinguishability of segments, which impedes\nthe learning process. In this paper, we introduce Skill-Enhanced Preference\nOptimization Algorithm (S-EPOA), which addresses the segment\nindistinguishability issue by integrating skill mechanisms into the preference\nlearning framework. Specifically, we first conduct the unsupervised pretraining\nto learn useful skills. Then, we propose a novel query selection mechanism to\nbalance the information gain and distinguishability over the learned skill\nspace. Experimental results on a range of tasks, including robotic manipulation\nand locomotion, demonstrate that S-EPOA significantly outperforms conventional\nPbRL methods in terms of both robustness and learning efficiency. The results\nhighlight the effectiveness of skill-driven learning in overcoming the\nchallenges posed by segment indistinguishability.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "IJCAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2408.12130v3",
    "published_date": "2024-08-22 04:54:25 UTC",
    "updated_date": "2025-05-13 14:30:16 UTC"
  },
  {
    "arxiv_id": "2408.12129v1",
    "title": "Deep Analysis of Time Series Data for Smart Grid Startup Strategies: A Transformer-LSTM-PSO Model Approach",
    "authors": [
      "Zecheng Zhang"
    ],
    "abstract": "Grid startup, an integral component of the power system, holds strategic\nimportance for ensuring the reliability and efficiency of the electrical grid.\nHowever, current methodologies for in-depth analysis and precise prediction of\ngrid startup scenarios are inadequate. To address these challenges, we propose\na novel method based on the Transformer-LSTM-PSO model. This model uniquely\ncombines the Transformer's self-attention mechanism, LSTM's temporal modeling\ncapabilities, and the parameter tuning features of the particle swarm\noptimization algorithm. It is designed to more effectively capture the complex\ntemporal relationships in grid startup schemes. Our experiments demonstrate\nsignificant improvements, with our model achieving lower RMSE and MAE values\nacross multiple datasets compared to existing benchmarks, particularly in the\nNYISO Electric Market dataset where the RMSE was reduced by approximately 15%\nand the MAE by 20% compared to conventional models. Our main contribution is\nthe development of a Transformer-LSTM-PSO model that significantly enhances the\naccuracy and efficiency of smart grid startup predictions. The application of\nthe Transformer-LSTM-PSO model represents a significant advancement in smart\ngrid predictive analytics, concurrently fostering the development of more\nreliable and intelligent grid management systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "46 pages",
    "pdf_url": "http://arxiv.org/pdf/2408.12129v1",
    "published_date": "2024-08-22 04:52:02 UTC",
    "updated_date": "2024-08-22 04:52:02 UTC"
  },
  {
    "arxiv_id": "2408.12128v1",
    "title": "Diffusion-Based Visual Art Creation: A Survey and New Perspectives",
    "authors": [
      "Bingyuan Wang",
      "Qifeng Chen",
      "Zeyu Wang"
    ],
    "abstract": "The integration of generative AI in visual art has revolutionized not only\nhow visual content is created but also how AI interacts with and reflects the\nunderlying domain knowledge. This survey explores the emerging realm of\ndiffusion-based visual art creation, examining its development from both\nartistic and technical perspectives. We structure the survey into three phases,\ndata feature and framework identification, detailed analyses using a structured\ncoding process, and open-ended prospective outlooks. Our findings reveal how\nartistic requirements are transformed into technical challenges and highlight\nthe design and application of diffusion-based methods within visual art\ncreation. We also provide insights into future directions from technical and\nsynergistic perspectives, suggesting that the confluence of generative AI and\nart has shifted the creative paradigm and opened up new possibilities. By\nsummarizing the development and trends of this emerging interdisciplinary area,\nwe aim to shed light on the mechanisms through which AI systems emulate and\npossibly, enhance human capacities in artistic perception and creativity.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "35 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.12128v1",
    "published_date": "2024-08-22 04:49:50 UTC",
    "updated_date": "2024-08-22 04:49:50 UTC"
  },
  {
    "arxiv_id": "2408.12125v1",
    "title": "AutoTest: Evolutionary Code Solution Selection with Test Cases",
    "authors": [
      "Zhihua Duan",
      "Jialin Wang"
    ],
    "abstract": "With the development of code generation techniques, selecting the correct\ncode solution from multiple candidate solutions has become a crucial task. This\nstudy proposes AutoTest, a novel technique that combines automated test case\ngeneration with code solution execution to optimize the selection process using\nan evolutionary genetic algorithm. Firstly, AutoTest utilizes large pre-trained\nlanguage models such as codegen-16B, code-davinci-002, and incoder-6B to\nprovide code solutions and their corresponding test cases. Then, by executing\nthe code solutions and evaluating their performance on the test cases, a\nconsensus set is formed. Fine-grained ranking is achieved through the\nselection, mutation, and crossover mechanisms based on the evolutionary genetic\nalgorithm, with the adjustment of alpha and beta parameters. Finally, the best\ncode solution is chosen. AutoTest demonstrates significant performance\nimprovements on the HumanEval benchmark test. The HumanEval dataset consists of\n164 programming problems, and AutoTest achieves approximately a 10% improvement\nover the baseline method in terms of pass@1 score.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12125v1",
    "published_date": "2024-08-22 04:38:41 UTC",
    "updated_date": "2024-08-22 04:38:41 UTC"
  },
  {
    "arxiv_id": "2408.12121v1",
    "title": "Emotion-Agent: Unsupervised Deep Reinforcement Learning with Distribution-Prototype Reward for Continuous Emotional EEG Analysis",
    "authors": [
      "Zhihao Zhou",
      "Qile Liu",
      "Jiyuan Wang",
      "Zhen Liang"
    ],
    "abstract": "Continuous electroencephalography (EEG) signals are widely used in affective\nbrain-computer interface (aBCI) applications. However, not all continuously\ncollected EEG signals are relevant or meaningful to the task at hand (e.g.,\nwondering thoughts). On the other hand, manually labeling the relevant parts is\nnearly impossible due to varying engagement patterns across different tasks and\nindividuals. Therefore, effectively and efficiently identifying the important\nparts from continuous EEG recordings is crucial for downstream BCI tasks, as it\ndirectly impacts the accuracy and reliability of the results. In this paper, we\npropose a novel unsupervised deep reinforcement learning framework, called\nEmotion-Agent, to automatically identify relevant and informative emotional\nmoments from continuous EEG signals. Specifically, Emotion-Agent involves\nunsupervised deep reinforcement learning combined with a heuristic algorithm.\nWe first use the heuristic algorithm to perform an initial global search and\nform prototype representations of the EEG signals, which facilitates the\nefficient exploration of the signal space and identify potential regions of\ninterest. Then, we design distribution-prototype reward functions to estimate\nthe interactions between samples and prototypes, ensuring that the identified\nparts are both relevant and representative of the underlying emotional states.\nEmotion-Agent is trained using Proximal Policy Optimization (PPO) to achieve\nstable and efficient convergence. Our experiments compare the performance with\nand without Emotion-Agent. The results demonstrate that selecting relevant and\ninformative emotional parts before inputting them into downstream tasks\nenhances the accuracy and reliability of aBCI applications.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "11 pages, 4 figures, 4 tables, submitted to AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2408.12121v1",
    "published_date": "2024-08-22 04:29:25 UTC",
    "updated_date": "2024-08-22 04:29:25 UTC"
  },
  {
    "arxiv_id": "2408.12119v1",
    "title": "Understanding Data Reconstruction Leakage in Federated Learning from a Theoretical Perspective",
    "authors": [
      "Zifan Wang",
      "Binghui Zhang",
      "Meng Pang",
      "Yuan Hong",
      "Binghui Wang"
    ],
    "abstract": "Federated learning (FL) is an emerging collaborative learning paradigm that\naims to protect data privacy. Unfortunately, recent works show FL algorithms\nare vulnerable to the serious data reconstruction attacks. However, existing\nworks lack a theoretical foundation on to what extent the devices' data can be\nreconstructed and the effectiveness of these attacks cannot be compared fairly\ndue to their unstable performance. To address this deficiency, we propose a\ntheoretical framework to understand data reconstruction attacks to FL. Our\nframework involves bounding the data reconstruction error and an attack's error\nbound reflects its inherent attack effectiveness. Under the framework, we can\ntheoretically compare the effectiveness of existing attacks. For instance, our\nresults on multiple datasets validate that the iDLG attack inherently\noutperforms the DLG attack.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12119v1",
    "published_date": "2024-08-22 04:20:48 UTC",
    "updated_date": "2024-08-22 04:20:48 UTC"
  },
  {
    "arxiv_id": "2408.12116v2",
    "title": "Geolocation Representation from Large Language Models are Generic Enhancers for Spatio-Temporal Learning",
    "authors": [
      "Junlin He",
      "Tong Nie",
      "Wei Ma"
    ],
    "abstract": "In the geospatial domain, universal representation models are significantly\nless prevalent than their extensive use in natural language processing and\ncomputer vision. This discrepancy arises primarily from the high costs\nassociated with the input of existing representation models, which often\nrequire street views and mobility data. To address this, we develop a novel,\ntraining-free method that leverages large language models (LLMs) and auxiliary\nmap data from OpenStreetMap to derive geolocation representations (LLMGeovec).\nLLMGeovec can represent the geographic semantics of city, country, and global\nscales, which acts as a generic enhancer for spatio-temporal learning.\nSpecifically, by direct feature concatenation, we introduce a simple yet\neffective paradigm for enhancing multiple spatio-temporal tasks including\ngeographic prediction (GP), long-term time series forecasting (LTSF), and\ngraph-based spatio-temporal forecasting (GSTF). LLMGeovec can seamlessly\nintegrate into a wide spectrum of spatio-temporal learning models, providing\nimmediate enhancements. Experimental results demonstrate that LLMGeovec\nachieves global coverage and significantly boosts the performance of leading\nGP, LTSF, and GSTF models. Our codes are available at\n\\url{https://github.com/Umaruchain/LLMGeovec}.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at AAAI25 main track",
    "pdf_url": "http://arxiv.org/pdf/2408.12116v2",
    "published_date": "2024-08-22 04:05:02 UTC",
    "updated_date": "2024-12-18 03:23:40 UTC"
  },
  {
    "arxiv_id": "2408.12113v1",
    "title": "Risk Analysis in Customer Relationship Management via Quantile Region Convolutional Neural Network-Long Short-Term Memory and Cross-Attention Mechanism",
    "authors": [
      "Yaowen Huang",
      "Jun Der Leu",
      "Baoli Lu",
      "Yan Zhou"
    ],
    "abstract": "Risk analysis is an important business decision support task in customer\nrelationship management (CRM), involving the identification of potential risks\nor challenges that may affect customer satisfaction, retention rates, and\noverall business performance. To enhance risk analysis in CRM, this paper\ncombines the advantages of quantile region convolutional neural network-long\nshort-term memory (QRCNN-LSTM) and cross-attention mechanisms for modeling. The\nQRCNN-LSTM model combines sequence modeling with deep learning architectures\ncommonly used in natural language processing tasks, enabling the capture of\nboth local and global dependencies in sequence data. The cross-attention\nmechanism enhances interactions between different input data parts, allowing\nthe model to focus on specific areas or features relevant to CRM risk analysis.\nBy applying QRCNN-LSTM and cross-attention mechanisms to CRM risk analysis,\nempirical evidence demonstrates that this approach can effectively identify\npotential risks and provide data-driven support for business decisions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "44 pages",
    "pdf_url": "http://arxiv.org/pdf/2408.12113v1",
    "published_date": "2024-08-22 03:55:28 UTC",
    "updated_date": "2024-08-22 03:55:28 UTC"
  },
  {
    "arxiv_id": "2408.12112v3",
    "title": "Balancing Act: Prioritization Strategies for LLM-Designed Restless Bandit Rewards",
    "authors": [
      "Shresth Verma",
      "Niclas Boehmer",
      "Lingkai Kong",
      "Milind Tambe"
    ],
    "abstract": "LLMs are increasingly used to design reward functions based on human\npreferences in Reinforcement Learning (RL). We focus on LLM-designed rewards\nfor Restless Multi-Armed Bandits, a framework for allocating limited resources\namong agents. In applications such as public health, this approach empowers\ngrassroots health workers to tailor automated allocation decisions to community\nneeds. In the presence of multiple agents, altering the reward function based\non human preferences can impact subpopulations very differently, leading to\ncomplex tradeoffs and a multi-objective resource allocation problem. We are the\nfirst to present a principled method termed Social Choice Language Model for\ndealing with these tradeoffs for LLM-designed rewards for multiagent planners\nin general and restless bandits in particular. The novel part of our model is a\ntransparent and configurable selection component, called an adjudicator,\nexternal to the LLM that controls complex tradeoffs via a user-selected social\nwelfare function. Our experiments demonstrate that our model reliably selects\nmore effective, aligned, and balanced reward functions compared to purely\nLLM-based approaches.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12112v3",
    "published_date": "2024-08-22 03:54:08 UTC",
    "updated_date": "2025-01-16 08:44:22 UTC"
  },
  {
    "arxiv_id": "2408.12097v1",
    "title": "Extraction of Research Objectives, Machine Learning Model Names, and Dataset Names from Academic Papers and Analysis of Their Interrelationships Using LLM and Network Analysis",
    "authors": [
      "S. Nishio",
      "H. Nonaka",
      "N. Tsuchiya",
      "A. Migita",
      "Y. Banno",
      "T. Hayashi",
      "H. Sakaji",
      "T. Sakumoto",
      "K. Watabe"
    ],
    "abstract": "Machine learning is widely utilized across various industries. Identifying\nthe appropriate machine learning models and datasets for specific tasks is\ncrucial for the effective industrial application of machine learning. However,\nthis requires expertise in both machine learning and the relevant domain,\nleading to a high learning cost. Therefore, research focused on extracting\ncombinations of tasks, machine learning models, and datasets from academic\npapers is critically important, as it can facilitate the automatic\nrecommendation of suitable methods. Conventional information extraction methods\nfrom academic papers have been limited to identifying machine learning models\nand other entities as named entities. To address this issue, this study\nproposes a methodology extracting tasks, machine learning methods, and dataset\nnames from scientific papers and analyzing the relationships between these\ninformation by using LLM, embedding model, and network clustering. The proposed\nmethod's expression extraction performance, when using Llama3, achieves an\nF-score exceeding 0.8 across various categories, confirming its practical\nutility. Benchmarking results on financial domain papers have demonstrated the\neffectiveness of this method, providing insights into the use of the latest\ndatasets, including those related to ESG (Environmental, Social, and\nGovernance) data.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2408.12097v1",
    "published_date": "2024-08-22 03:10:52 UTC",
    "updated_date": "2024-08-22 03:10:52 UTC"
  },
  {
    "arxiv_id": "2408.12095v2",
    "title": "uMedSum: A Unified Framework for Advancing Medical Abstractive Summarization",
    "authors": [
      "Aishik Nagar",
      "Yutong Liu",
      "Andy T. Liu",
      "Viktor Schlegel",
      "Vijay Prakash Dwivedi",
      "Arun-Kumar Kaliya-Perumal",
      "Guna Pratheep Kalanchiam",
      "Yili Tang",
      "Robby T. Tan"
    ],
    "abstract": "Medical abstractive summarization faces the challenge of balancing\nfaithfulness and informativeness. Current methods often sacrifice key\ninformation for faithfulness or introduce confabulations when prioritizing\ninformativeness. While recent advancements in techniques like in-context\nlearning (ICL) and fine-tuning have improved medical summarization, they often\noverlook crucial aspects such as faithfulness and informativeness without\nconsidering advanced methods like model reasoning and self-improvement.\nMoreover, the field lacks a unified benchmark, hindering systematic evaluation\ndue to varied metrics and datasets. This paper addresses these gaps by\npresenting a comprehensive benchmark of six advanced abstractive summarization\nmethods across three diverse datasets using five standardized metrics. Building\non these findings, we propose uMedSum, a modular hybrid summarization framework\nthat introduces novel approaches for sequential confabulation removal followed\nby key missing information addition, ensuring both faithfulness and\ninformativeness. Our work improves upon previous GPT-4-based state-of-the-art\n(SOTA) medical summarization methods, significantly outperforming them in both\nquantitative metrics and qualitative domain expert evaluations. Notably, we\nachieve an average relative performance improvement of 11.8% in reference-free\nmetrics over the previous SOTA. Doctors prefer uMedSum's summaries 6 times more\nthan previous SOTA in difficult cases where there are chances of confabulations\nor missing information. These results highlight uMedSum's effectiveness and\ngeneralizability across various datasets and metrics, marking a significant\nadvancement in medical summarization.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "12 pages",
    "pdf_url": "http://arxiv.org/pdf/2408.12095v2",
    "published_date": "2024-08-22 03:08:49 UTC",
    "updated_date": "2024-08-26 02:26:31 UTC"
  },
  {
    "arxiv_id": "2408.12086v1",
    "title": "Unlocking Attributes' Contribution to Successful Camouflage: A Combined Textual and VisualAnalysis Strategy",
    "authors": [
      "Hong Zhang",
      "Yixuan Lyu",
      "Qian Yu",
      "Hanyang Liu",
      "Huimin Ma",
      "Ding Yuan",
      "Yifan Yang"
    ],
    "abstract": "In the domain of Camouflaged Object Segmentation (COS), despite continuous\nimprovements in segmentation performance, the underlying mechanisms of\neffective camouflage remain poorly understood, akin to a black box. To address\nthis gap, we present the first comprehensive study to examine the impact of\ncamouflage attributes on the effectiveness of camouflage patterns, offering a\nquantitative framework for the evaluation of camouflage designs. To support\nthis analysis, we have compiled the first dataset comprising descriptions of\ncamouflaged objects and their attribute contributions, termed COD-Text And\nX-attributions (COD-TAX). Moreover, drawing inspiration from the hierarchical\nprocess by which humans process information: from high-level textual\ndescriptions of overarching scenarios, through mid-level summaries of local\nareas, to low-level pixel data for detailed analysis. We have developed a\nrobust framework that combines textual and visual information for the task of\nCOS, named Attribution CUe Modeling with Eye-fixation Network (ACUMEN). ACUMEN\ndemonstrates superior performance, outperforming nine leading methods across\nthree widely-used datasets. We conclude by highlighting key insights derived\nfrom the attributes identified in our study. Code:\nhttps://github.com/lyu-yx/ACUMEN.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ECCV 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.12086v1",
    "published_date": "2024-08-22 02:51:21 UTC",
    "updated_date": "2024-08-22 02:51:21 UTC"
  },
  {
    "arxiv_id": "2408.12080v1",
    "title": "Exploring the Feasibility of Automated Data Standardization using Large Language Models for Seamless Positioning",
    "authors": [
      "Max J. L. Lee",
      "Ju Lin",
      "Li-Ta Hsu"
    ],
    "abstract": "We propose a feasibility study for real-time automated data standardization\nleveraging Large Language Models (LLMs) to enhance seamless positioning systems\nin IoT environments. By integrating and standardizing heterogeneous sensor data\nfrom smartphones, IoT devices, and dedicated systems such as Ultra-Wideband\n(UWB), our study ensures data compatibility and improves positioning accuracy\nusing the Extended Kalman Filter (EKF). The core components include the\nIntelligent Data Standardization Module (IDSM), which employs a fine-tuned LLM\nto convert varied sensor data into a standardized format, and the\nTransformation Rule Generation Module (TRGM), which automates the creation of\ntransformation rules and scripts for ongoing data standardization. Evaluated in\nreal-time environments, our study demonstrates adaptability and scalability,\nenhancing operational efficiency and accuracy in seamless navigation. This\nstudy underscores the potential of advanced LLMs in overcoming sensor data\nintegration complexities, paving the way for more scalable and precise IoT\nnavigation solutions.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "eess.SP",
    "comment": "Accepted at IPIN 2024. To be published in IEEE Xplore",
    "pdf_url": "http://arxiv.org/pdf/2408.12080v1",
    "published_date": "2024-08-22 02:40:21 UTC",
    "updated_date": "2024-08-22 02:40:21 UTC"
  },
  {
    "arxiv_id": "2408.12079v1",
    "title": "High-Quality Data Augmentation for Low-Resource NMT: Combining a Translation Memory, a GAN Generator, and Filtering",
    "authors": [
      "Hengjie Liu",
      "Ruibo Hou",
      "Yves Lepage"
    ],
    "abstract": "Back translation, as a technique for extending a dataset, is widely used by\nresearchers in low-resource language translation tasks. It typically translates\nfrom the target to the source language to ensure high-quality translation\nresults. This paper proposes a novel way of utilizing a monolingual corpus on\nthe source side to assist Neural Machine Translation (NMT) in low-resource\nsettings. We realize this concept by employing a Generative Adversarial Network\n(GAN), which augments the training data for the discriminator while mitigating\nthe interference of low-quality synthetic monolingual translations with the\ngenerator. Additionally, this paper integrates Translation Memory (TM) with\nNMT, increasing the amount of data available to the generator. Moreover, we\npropose a novel procedure to filter the synthetic sentence pairs during the\naugmentation process, ensuring the high quality of the data.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12079v1",
    "published_date": "2024-08-22 02:35:47 UTC",
    "updated_date": "2024-08-22 02:35:47 UTC"
  },
  {
    "arxiv_id": "2408.12076v1",
    "title": "ConflictBank: A Benchmark for Evaluating the Influence of Knowledge Conflicts in LLM",
    "authors": [
      "Zhaochen Su",
      "Jun Zhang",
      "Xiaoye Qu",
      "Tong Zhu",
      "Yanshu Li",
      "Jiashuo Sun",
      "Juntao Li",
      "Min Zhang",
      "Yu Cheng"
    ],
    "abstract": "Large language models (LLMs) have achieved impressive advancements across\nnumerous disciplines, yet the critical issue of knowledge conflicts, a major\nsource of hallucinations, has rarely been studied. Only a few research explored\nthe conflicts between the inherent knowledge of LLMs and the retrieved\ncontextual knowledge. However, a thorough assessment of knowledge conflict in\nLLMs is still missing. Motivated by this research gap, we present ConflictBank,\nthe first comprehensive benchmark developed to systematically evaluate\nknowledge conflicts from three aspects: (i) conflicts encountered in retrieved\nknowledge, (ii) conflicts within the models' encoded knowledge, and (iii) the\ninterplay between these conflict forms. Our investigation delves into four\nmodel families and twelve LLM instances, meticulously analyzing conflicts\nstemming from misinformation, temporal discrepancies, and semantic divergences.\nBased on our proposed novel construction framework, we create 7,453,853\nclaim-evidence pairs and 553,117 QA pairs. We present numerous findings on\nmodel scale, conflict causes, and conflict types. We hope our ConflictBank\nbenchmark will help the community better understand model behavior in conflicts\nand develop more reliable LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Under Review",
    "pdf_url": "http://arxiv.org/pdf/2408.12076v1",
    "published_date": "2024-08-22 02:33:13 UTC",
    "updated_date": "2024-08-22 02:33:13 UTC"
  },
  {
    "arxiv_id": "2408.12067v2",
    "title": "Distributed Noncoherent Joint Transmission Based on Multi-Agent Reinforcement Learning for Dense Small Cell MISO Systems",
    "authors": [
      "Shaozhuang Bai",
      "Zhenzhen Gao",
      "Xuewen Liao"
    ],
    "abstract": "We consider a dense small cell (DSC) network where multi-antenna small cell\nbase stations (SBSs) transmit data to single-antenna users over a shared\nfrequency band. To enhance capacity, a state-of-the-art technique known as\nnoncoherent joint transmission (JT) is applied, enabling users to receive data\nfrom multiple coordinated SBSs. However, the sum rate maximization problem with\nnoncoherent JT is inherently nonconvex and NP-hard. While existing\noptimization-based noncoherent JT algorithms can provide near-optimal\nperformance, they require global channel state information (CSI) and multiple\niterations, which makes them difficult to be implemeted in DSC networks.To\novercome these challenges, we first prove that the optimal beamforming\nstructure is the same for both the power minimization problem and the sum rate\nmaximization problem, and then mathematically derive the optimal beamforming\nstructure for both problems by solving the power minimization problem.The\noptimal beamforming structure can effectively reduces the variable\ndimensions.By exploiting the optimal beamforming structure, we propose a deep\ndeterministic policy gradient-based distributed noncoherent JT scheme to\nmaximize the system sum rate.In the proposed scheme, each SBS utilizes global\ninformation for training and uses local CSI to determine beamforming vectors.\nSimulation results demonstrate that the proposed scheme achieves comparable\nperformance with considerably lower computational complexity and information\noverhead compared to centralized iterative optimization-based techniques,\nmaking it more attractive for practical deployment.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "eess.SP",
    "comment": "After thorough discussions with my co-authors, we have identified\n  certain issues with the paper that cannot be resolved through revisions. As a\n  result, we have collectively decided to complete withdraw the paper from\n  arXiv",
    "pdf_url": "http://arxiv.org/pdf/2408.12067v2",
    "published_date": "2024-08-22 02:11:14 UTC",
    "updated_date": "2024-09-11 04:06:45 UTC"
  },
  {
    "arxiv_id": "2408.12065v1",
    "title": "Transformers As Approximations of Solomonoff Induction",
    "authors": [
      "Nathan Young",
      "Michael Witbrock"
    ],
    "abstract": "Solomonoff Induction is an optimal-in-the-limit unbounded algorithm for\nsequence prediction, representing a Bayesian mixture of every computable\nprobability distribution and performing close to optimally in predicting any\ncomputable sequence.\n  Being an optimal form of computational sequence prediction, it seems\nplausible that it may be used as a model against which other methods of\nsequence prediction might be compared.\n  We put forth and explore the hypothesis that Transformer models - the basis\nof Large Language Models - approximate Solomonoff Induction better than any\nother extant sequence prediction method. We explore evidence for and against\nthis hypothesis, give alternate hypotheses that take this evidence into\naccount, and outline next steps for modelling Transformers and other kinds of\nAI in this way.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12065v1",
    "published_date": "2024-08-22 02:05:44 UTC",
    "updated_date": "2024-08-22 02:05:44 UTC"
  },
  {
    "arxiv_id": "2408.12063v1",
    "title": "A Deconfounding Approach to Climate Model Bias Correction",
    "authors": [
      "Wentao Gao",
      "Jiuyong Li",
      "Debo Cheng",
      "Lin Liu",
      "Jixue Liu",
      "Thuc Duy Le",
      "Xiaojing Du",
      "Xiongren Chen",
      "Yanchang Zhao",
      "Yun Chen"
    ],
    "abstract": "Global Climate Models (GCMs) are crucial for predicting future climate\nchanges by simulating the Earth systems. However, GCM outputs exhibit\nsystematic biases due to model uncertainties, parameterization simplifications,\nand inadequate representation of complex climate phenomena. Traditional bias\ncorrection methods, which rely on historical observation data and statistical\ntechniques, often neglect unobserved confounders, leading to biased results.\nThis paper proposes a novel bias correction approach to utilize both GCM and\nobservational data to learn a factor model that captures multi-cause latent\nconfounders. Inspired by recent advances in causality based time series\ndeconfounding, our method first constructs a factor model to learn latent\nconfounders from historical data and then applies them to enhance the bias\ncorrection process using advanced time series forecasting models. The\nexperimental results demonstrate significant improvements in the accuracy of\nprecipitation outputs. By addressing unobserved confounders, our approach\noffers a robust and theoretically grounded solution for climate model bias\ncorrection.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "physics.ao-ph"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12063v1",
    "published_date": "2024-08-22 01:53:35 UTC",
    "updated_date": "2024-08-22 01:53:35 UTC"
  },
  {
    "arxiv_id": "2408.12062v2",
    "title": "Enhancing Sampling Protocol for Point Cloud Classification Against Corruptions",
    "authors": [
      "Chongshou Li",
      "Pin Tang",
      "Xinke Li",
      "Yuheng Liu",
      "Tianrui Li"
    ],
    "abstract": "Established sampling protocols for 3D point cloud learning, such as Farthest\nPoint Sampling (FPS) and Fixed Sample Size (FSS), have long been relied upon.\nHowever, real-world data often suffer from corruptions, such as sensor noise,\nwhich violates the benign data assumption in current protocols. As a result,\nthese protocols are highly vulnerable to noise, posing significant safety risks\nin critical applications like autonomous driving. To address these issues, we\npropose an enhanced point cloud sampling protocol, PointSP, designed to improve\nrobustness against point cloud corruptions. PointSP incorporates key point\nreweighting to mitigate outlier sensitivity and ensure the selection of\nrepresentative points. It also introduces a local-global balanced downsampling\nstrategy, which allows for scalable and adaptive sampling while maintaining\ngeometric consistency. Additionally, a lightweight tangent plane interpolation\nmethod is used to preserve local geometry while enhancing the density of the\npoint cloud. Unlike learning-based approaches that require additional model\ntraining, PointSP is architecture-agnostic, requiring no extra learning or\nmodification to the network. This enables seamless integration into existing\npipelines. Extensive experiments on synthetic and real-world corrupted datasets\nshow that PointSP significantly improves the robustness and accuracy of point\ncloud classification, outperforming state-of-the-art methods across multiple\nbenchmarks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2408.12062v2",
    "published_date": "2024-08-22 01:48:31 UTC",
    "updated_date": "2025-02-03 08:43:20 UTC"
  },
  {
    "arxiv_id": "2408.12060v2",
    "title": "Evidence-backed Fact Checking using RAG and Few-Shot In-Context Learning with LLMs",
    "authors": [
      "Ronit Singhal",
      "Pransh Patwa",
      "Parth Patwa",
      "Aman Chadha",
      "Amitava Das"
    ],
    "abstract": "Given the widespread dissemination of misinformation on social media,\nimplementing fact-checking mechanisms for online claims is essential. Manually\nverifying every claim is very challenging, underscoring the need for an\nautomated fact-checking system. This paper presents our system designed to\naddress this issue. We utilize the Averitec dataset (Schlichtkrull et al.,\n2023) to assess the performance of our fact-checking system. In addition to\nveracity prediction, our system provides supporting evidence, which is\nextracted from the dataset. We develop a Retrieve and Generate (RAG) pipeline\nto extract relevant evidence sentences from a knowledge base, which are then\ninputted along with the claim into a large language model (LLM) for\nclassification. We also evaluate the few-shot In-Context Learning (ICL)\ncapabilities of multiple LLMs. Our system achieves an 'Averitec' score of 0.33,\nwhich is a 22% absolute improvement over the baseline. Our Code is publicly\navailable on\nhttps://github.com/ronit-singhal/evidence-backed-fact-checking-using-rag-and-few-shot-in-context-learning-with-llms.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted in The Seventh FEVER Workshop at EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2408.12060v2",
    "published_date": "2024-08-22 01:42:34 UTC",
    "updated_date": "2024-10-04 19:31:41 UTC"
  },
  {
    "arxiv_id": "2408.12056v2",
    "title": "Enhancing Automated Program Repair with Solution Design",
    "authors": [
      "Jiuang Zhao",
      "Donghao Yang",
      "Li Zhang",
      "Xiaoli Lian",
      "Zitian Yang",
      "Fang Liu"
    ],
    "abstract": "Automatic Program Repair (APR) endeavors to autonomously rectify issues\nwithin specific projects, which generally encompasses three categories of\ntasks: bug resolution, new feature development, and feature enhancement.\nDespite extensive research proposing various methodologies, their efficacy in\naddressing real issues remains unsatisfactory. It's worth noting that,\ntypically, engineers have design rationales (DR) on solution-planed solutions\nand a set of underlying reasons-before they start patching code. In open-source\nprojects, these DRs are frequently captured in issue logs through project\nmanagement tools like Jira. This raises a compelling question: How can we\nleverage DR scattered across the issue logs to efficiently enhance APR? To\ninvestigate this premise, we introduce DRCodePilot, an approach designed to\naugment GPT-4-Turbo's APR capabilities by incorporating DR into the prompt\ninstruction. Furthermore, given GPT-4's constraints in fully grasping the\nbroader project context and occasional shortcomings in generating precise\nidentifiers, we have devised a feedback-based self-reflective framework, in\nwhich we prompt GPT-4 to reconsider and refine its outputs by referencing a\nprovided patch and suggested identifiers. We have established a benchmark\ncomprising 938 issue-patch pairs sourced from two open-source repositories\nhosted on GitHub and Jira. Our experimental results are impressive: DRCodePilot\nachieves a full-match ratio that is a remarkable 4.7x higher than when GPT-4 is\nutilized directly. Additionally, the CodeBLEU scores also exhibit promising\nenhancements. Moreover, our findings reveal that the standalone application of\nDR can yield promising increase in the full-match ratio across CodeLlama,\nGPT-3.5, and GPT-4 within our benchmark suite. We believe that our DRCodePilot\ninitiative heralds a novel human-in-the-loop avenue for advancing the field of\nAPR.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "*These authors contributed equally to this work. {\\dag}Corresponding\n  author. Will appear in ase'24",
    "pdf_url": "http://arxiv.org/pdf/2408.12056v2",
    "published_date": "2024-08-22 01:13:02 UTC",
    "updated_date": "2024-09-22 03:16:38 UTC"
  }
]