[
  {
    "arxiv_id": "2502.04573v1",
    "title": "Zero-shot Meta-learning for Tabular Prediction Tasks with Adversarially Pre-trained Transformer",
    "authors": [
      "Yulun Wu",
      "Doron L. Bergman"
    ],
    "abstract": "We present an Adversarially Pre-trained Transformer (APT) that is able to\nperform zero-shot meta-learning on tabular prediction tasks without\npre-training on any real-world dataset, extending on the recent development of\nPrior-Data Fitted Networks (PFNs) and TabPFN. Specifically, APT is pre-trained\nwith adversarial synthetic data agents, who continue to shift their underlying\ndata generating distribution and deliberately challenge the model with\ndifferent synthetic datasets. In addition, we propose a mixture block\narchitecture that is able to handle classification tasks with arbitrary number\nof classes, addressing the class size limitation -- a crucial weakness of prior\ndeep tabular zero-shot learners. In experiments, we show that our framework\nmatches state-of-the-art performance on small classification tasks without\nfiltering on dataset characteristics such as number of classes and number of\nmissing values, while maintaining an average runtime under one second. On\ncommon benchmark dataset suites in both classification and regression, we show\nthat adversarial pre-training was able to enhance TabPFN's performance. In our\nanalysis, we demonstrate that the adversarial synthetic data agents were able\nto generate a more diverse collection of data compared to the ordinary random\ngenerator in TabPFN. In addition, we demonstrate that our mixture block neural\ndesign has improved generalizability and greatly accelerated pre-training.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04573v1",
    "published_date": "2025-02-06 23:58:11 UTC",
    "updated_date": "2025-02-06 23:58:11 UTC"
  },
  {
    "arxiv_id": "2502.04567v1",
    "title": "Preference Optimization via Contrastive Divergence: Your Reward Model is Secretly an NLL Estimator",
    "authors": [
      "Zhuotong Chen",
      "Fang Liu",
      "Xuan Zhu",
      "Yanjun Qi",
      "Mohammad Ghavamzadeh"
    ],
    "abstract": "Existing studies on preference optimization (PO) have centered on\nconstructing pairwise preference data following simple heuristics, such as\nmaximizing the margin between preferred and dispreferred completions based on\nhuman (or AI) ranked scores. However, none of these heuristics has a full\ntheoretical justification. In this work, we develop a novel PO framework that\nprovides theoretical guidance to effectively sample dispreferred completions.\nTo achieve this, we formulate PO as minimizing the negative log-likelihood\n(NLL) of a probability model and propose to estimate its normalization constant\nvia a sampling strategy. As we will demonstrate, these estimative samples can\nact as dispreferred completions in PO. We then select contrastive divergence\n(CD) as the sampling strategy, and propose a novel MC-PO algorithm that applies\nthe Monte Carlo (MC) kernel from CD to sample hard negatives w.r.t. the\nparameterized reward model. Finally, we propose the OnMC-PO algorithm, an\nextension of MC-PO to the online setting. On popular alignment benchmarks,\nMC-PO outperforms existing SOTA baselines, and OnMC-PO leads to further\nimprovement.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04567v1",
    "published_date": "2025-02-06 23:45:08 UTC",
    "updated_date": "2025-02-06 23:45:08 UTC"
  },
  {
    "arxiv_id": "2502.04563v2",
    "title": "WaferLLM: A Wafer-Scale LLM Inference System",
    "authors": [
      "Congjie He",
      "Yeqi Huang",
      "Pei Mu",
      "Ziming Miao",
      "Jilong Xue",
      "Lingxiao Ma",
      "Fan Yang",
      "Luo Mai"
    ],
    "abstract": "Emerging AI accelerators increasingly adopt wafer-scale manufacturing\ntechnologies, integrating hundreds of thousands of AI cores in a mesh-based\narchitecture with large distributed on-chip memory (tens of GB in total) and\nultra-high on-chip memory bandwidth (tens of PB/s). However, current LLM\ninference systems, optimized for shared memory architectures like GPUs, fail to\nfully exploit these accelerators.\n  We introduce WaferLLM, the first wafer-scale LLM inference system. WaferLLM\nis guided by a novel PLMR model (pronounced as \"Plummer\") that captures the\nunique hardware characteristics of wafer-scale architectures. Leveraging this\nmodel, WaferLLM pioneers wafer-scale LLM parallelism, optimizing the\nutilization of hundreds of thousands of on-chip cores. It also introduces\nMeshGEMM and MeshGEMV, the first GEMM and GEMV implementations designed to\nscale effectively on wafer-scale accelerators.\n  Evaluations show that WaferLLM achieves 200$\\times$ better wafer-scale\naccelerator utilization than state-of-the-art systems. On a commodity\nwafer-scale accelerator, WaferLLM delivers 606$\\times$ faster and 22$\\times$\nmore energy-efficient GEMV compared to an advanced GPU. For LLMs, based on\n16-bit data type, WaferLLM achieves 2700 toks/sec/req decode speed on Llama3-8B\nmodel and 840 toks/sec/req decode speed on Qwen2-72B model, which enables\n39$\\times$ faster decoding with 1.7$\\times$ better energy efficiency. We\nanticipate these numbers will grow significantly as wafer-scale AI models,\nsoftware, and hardware continue to mature.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.AR",
      "cs.DC",
      "cs.ET"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04563v2",
    "published_date": "2025-02-06 23:32:19 UTC",
    "updated_date": "2025-02-18 12:16:48 UTC"
  },
  {
    "arxiv_id": "2502.04558v1",
    "title": "Probing a Vision-Language-Action Model for Symbolic States and Integration into a Cognitive Architecture",
    "authors": [
      "Hong Lu",
      "Hengxu Li",
      "Prithviraj Singh Shahani",
      "Stephanie Herbers",
      "Matthias Scheutz"
    ],
    "abstract": "Vision-language-action (VLA) models hold promise as generalist robotics\nsolutions by translating visual and linguistic inputs into robot actions, yet\nthey lack reliability due to their black-box nature and sensitivity to\nenvironmental changes. In contrast, cognitive architectures (CA) excel in\nsymbolic reasoning and state monitoring but are constrained by rigid predefined\nexecution. This work bridges these approaches by probing OpenVLA's hidden\nlayers to uncover symbolic representations of object properties, relations, and\naction states, enabling integration with a CA for enhanced interpretability and\nrobustness. Through experiments on LIBERO-spatial pick-and-place tasks, we\nanalyze the encoding of symbolic states across different layers of OpenVLA's\nLlama backbone. Our probing results show consistently high accuracies (> 0.90)\nfor both object and action states across most layers, though contrary to our\nhypotheses, we did not observe the expected pattern of object states being\nencoded earlier than action states. We demonstrate an integrated DIARC-OpenVLA\nsystem that leverages these symbolic representations for real-time state\nmonitoring, laying the foundation for more interpretable and reliable robotic\nmanipulation.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "8 Pages, 4 Figures",
    "pdf_url": "http://arxiv.org/pdf/2502.04558v1",
    "published_date": "2025-02-06 23:11:11 UTC",
    "updated_date": "2025-02-06 23:11:11 UTC"
  },
  {
    "arxiv_id": "2502.04556v1",
    "title": "TruthFlow: Truthful LLM Generation via Representation Flow Correction",
    "authors": [
      "Hanyu Wang",
      "Bochuan Cao",
      "Yuanpu Cao",
      "Jinghui Chen"
    ],
    "abstract": "Large language models (LLMs) are known to struggle with consistently\ngenerating truthful responses. While various representation intervention\ntechniques have been proposed, these methods typically apply a universal\nrepresentation correction vector to all input queries, limiting their\neffectiveness against diverse queries in practice. In this study, we introduce\nTruthFlow, a novel method that leverages the Flow Matching technique for\nquery-specific truthful representation correction. Specifically, TruthFlow\nfirst uses a flow model to learn query-specific correction vectors that\ntransition representations from hallucinated to truthful states. Then, during\ninference, the trained flow model generates these correction vectors to enhance\nthe truthfulness of LLM outputs. Experimental results demonstrate that\nTruthFlow significantly improves performance on open-ended generation tasks\nacross various advanced LLMs evaluated on TruthfulQA. Moreover, the trained\nTruthFlow model exhibits strong transferability, performing effectively on\nother unseen hallucination benchmarks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04556v1",
    "published_date": "2025-02-06 23:10:14 UTC",
    "updated_date": "2025-02-06 23:10:14 UTC"
  },
  {
    "arxiv_id": "2502.04554v1",
    "title": "Unifying and Optimizing Data Values for Selection via Sequential-Decision-Making",
    "authors": [
      "Hongliang Chi",
      "Qiong Wu",
      "Zhengyi Zhou",
      "Jonathan Light",
      "Emily Dodwell",
      "Yao Ma"
    ],
    "abstract": "Data selection has emerged as a crucial downstream application of data\nvaluation. While existing data valuation methods have shown promise in\nselection tasks, the theoretical foundations and full potential of using data\nvalues for selection remain largely unexplored. In this work, we first\ndemonstrate that data values applied for selection can be naturally\nreformulated as a sequential-decision-making problem, where the optimal data\nvalue can be derived through dynamic programming. We show this framework\nunifies and reinterprets existing methods like Data Shapley through the lens of\napproximate dynamic programming, specifically as myopic reward function\napproximations to this sequential problem. Furthermore, we analyze how\nsequential data selection optimality is affected when the ground-truth utility\nfunction exhibits monotonic submodularity with curvature. To address the\ncomputational challenges in obtaining optimal data values, we propose an\nefficient approximation scheme using learned bipartite graphs as surrogate\nutility models, ensuring greedy selection is still optimal when the surrogate\nutility is correctly specified and learned. Extensive experiments demonstrate\nthe effectiveness of our approach across diverse datasets.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04554v1",
    "published_date": "2025-02-06 23:03:10 UTC",
    "updated_date": "2025-02-06 23:03:10 UTC"
  },
  {
    "arxiv_id": "2502.05232v1",
    "title": "Aligner-Encoders: Self-Attention Transformers Can Be Self-Transducers",
    "authors": [
      "Adam Stooke",
      "Rohit Prabhavalkar",
      "Khe Chai Sim",
      "Pedro Moreno Mengibar"
    ],
    "abstract": "Modern systems for automatic speech recognition, including the RNN-Transducer\nand Attention-based Encoder-Decoder (AED), are designed so that the encoder is\nnot required to alter the time-position of information from the audio sequence\ninto the embedding; alignment to the final text output is processed during\ndecoding. We discover that the transformer-based encoder adopted in recent\nyears is actually capable of performing the alignment internally during the\nforward pass, prior to decoding. This new phenomenon enables a simpler and more\nefficient model, the \"Aligner-Encoder\". To train it, we discard the dynamic\nprogramming of RNN-T in favor of the frame-wise cross-entropy loss of AED,\nwhile the decoder employs the lighter text-only recurrence of RNN-T without\nlearned cross-attention -- it simply scans embedding frames in order from the\nbeginning, producing one token each until predicting the end-of-message. We\nconduct experiments demonstrating performance remarkably close to the state of\nthe art, including a special inference configuration enabling long-form\nrecognition. In a representative comparison, we measure the total inference\ntime for our model to be 2x faster than RNN-T and 16x faster than AED. Lastly,\nwe find that the audio-text alignment is clearly visible in the self-attention\nweights of a certain layer, which could be said to perform \"self-transduction\".",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05232v1",
    "published_date": "2025-02-06 22:09:52 UTC",
    "updated_date": "2025-02-06 22:09:52 UTC"
  },
  {
    "arxiv_id": "2502.04531v1",
    "title": "AnyPlace: Learning Generalized Object Placement for Robot Manipulation",
    "authors": [
      "Yuchi Zhao",
      "Miroslav Bogdanovic",
      "Chengyuan Luo",
      "Steven Tohme",
      "Kourosh Darvish",
      "Alán Aspuru-Guzik",
      "Florian Shkurti",
      "Animesh Garg"
    ],
    "abstract": "Object placement in robotic tasks is inherently challenging due to the\ndiversity of object geometries and placement configurations. To address this,\nwe propose AnyPlace, a two-stage method trained entirely on synthetic data,\ncapable of predicting a wide range of feasible placement poses for real-world\ntasks. Our key insight is that by leveraging a Vision-Language Model (VLM) to\nidentify rough placement locations, we focus only on the relevant regions for\nlocal placement, which enables us to train the low-level\nplacement-pose-prediction model to capture diverse placements efficiently. For\ntraining, we generate a fully synthetic dataset of randomly generated objects\nin different placement configurations (insertion, stacking, hanging) and train\nlocal placement-prediction models. We conduct extensive evaluations in\nsimulation, demonstrating that our method outperforms baselines in terms of\nsuccess rate, coverage of possible placement modes, and precision. In\nreal-world experiments, we show how our approach directly transfers models\ntrained purely on synthetic data to the real world, where it successfully\nperforms placements in scenarios where other models struggle -- such as with\nvarying object geometries, diverse placement modes, and achieving high\nprecision for fine placement. More at: https://any-place.github.io.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04531v1",
    "published_date": "2025-02-06 22:04:13 UTC",
    "updated_date": "2025-02-06 22:04:13 UTC"
  },
  {
    "arxiv_id": "2502.04530v1",
    "title": "Robust Probabilistic Model Checking with Continuous Reward Domains",
    "authors": [
      "Xiaotong Ji",
      "Hanchun Wang",
      "Antonio Filieri",
      "Ilenia Epifani"
    ],
    "abstract": "Probabilistic model checking traditionally verifies properties on the\nexpected value of a measure of interest. This restriction may fail to capture\nthe quality of service of a significant proportion of a system's runs,\nespecially when the probability distribution of the measure of interest is\npoorly represented by its expected value due to heavy-tail behaviors or\nmultiple modalities. Recent works inspired by distributional reinforcement\nlearning use discrete histograms to approximate integer reward distribution,\nbut they struggle with continuous reward space and present challenges in\nbalancing accuracy and scalability. We propose a novel method for handling both\ncontinuous and discrete reward distributions in Discrete Time Markov Chains\nusing moment matching with Erlang mixtures. By analytically deriving\nhigher-order moments through Moment Generating Functions, our method\napproximates the reward distribution with theoretically bounded error while\npreserving the statistical properties of the true distribution. This detailed\ndistributional insight enables the formulation and robust model checking of\nquality properties based on the entire reward distribution function, rather\nthan restricting to its expected value. We include a theoretical foundation\nensuring bounded approximation errors, along with an experimental evaluation\ndemonstrating our method's accuracy and scalability in practical model-checking\nproblems.",
    "categories": [
      "cs.AI",
      "cs.FL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by the 20th International Conference on Software Engineering\n  for Adaptive and Self-Managing Systems 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.04530v1",
    "published_date": "2025-02-06 22:03:18 UTC",
    "updated_date": "2025-02-06 22:03:18 UTC"
  },
  {
    "arxiv_id": "2502.04522v4",
    "title": "ImprovNet -- Generating Controllable Musical Improvisations with Iterative Corruption Refinement",
    "authors": [
      "Keshav Bhandari",
      "Sungkyun Chang",
      "Tongyu Lu",
      "Fareza R. Enus",
      "Louis B. Bradshaw",
      "Dorien Herremans",
      "Simon Colton"
    ],
    "abstract": "Despite deep learning's remarkable advances in style transfer across various\ndomains, generating controllable performance-level musical style transfer for\ncomplete symbolically represented musical works remains a challenging area of\nresearch. Much of this is owed to limited datasets, especially for genres such\nas jazz, and the lack of unified models that can handle multiple music\ngeneration tasks. This paper presents ImprovNet, a transformer-based\narchitecture that generates expressive and controllable musical improvisations\nthrough a self-supervised corruption-refinement training strategy. The\nimprovisational style transfer is aimed at making meaningful modifications to\none or more musical elements - melody, harmony or rhythm of the original\ncomposition with respect to the target genre. ImprovNet unifies multiple\ncapabilities within a single model: it can perform cross-genre and intra-genre\nimprovisations, harmonize melodies with genre-specific styles, and execute\nshort prompt continuation and infilling tasks. The model's iterative generation\nframework allows users to control the degree of style transfer and structural\nsimilarity to the original composition. Objective and subjective evaluations\ndemonstrate ImprovNet's effectiveness in generating musically coherent\nimprovisations while maintaining structural relationships with the original\npieces. The model outperforms Anticipatory Music Transformer in short\ncontinuation and infilling tasks and successfully achieves recognizable genre\nconversion, with 79\\% of participants correctly identifying jazz-style\nimprovisations of classical pieces. Our code and demo page can be found at\nhttps://github.com/keshavbhandari/improvnet.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "10 pages, 6 figures, IJCNN 2025 conference",
    "pdf_url": "http://arxiv.org/pdf/2502.04522v4",
    "published_date": "2025-02-06 21:45:38 UTC",
    "updated_date": "2025-05-16 14:56:53 UTC"
  },
  {
    "arxiv_id": "2502.04515v1",
    "title": "MedGNN: Towards Multi-resolution Spatiotemporal Graph Learning for Medical Time Series Classification",
    "authors": [
      "Wei Fan",
      "Jingru Fei",
      "Dingyu Guo",
      "Kun Yi",
      "Xiaozhuang Song",
      "Haolong Xiang",
      "Hangting Ye",
      "Min Li"
    ],
    "abstract": "Medical time series has been playing a vital role in real-world healthcare\nsystems as valuable information in monitoring health conditions of patients.\nAccurate classification for medical time series, e.g., Electrocardiography\n(ECG) signals, can help for early detection and diagnosis. Traditional methods\ntowards medical time series classification rely on handcrafted feature\nextraction and statistical methods; with the recent advancement of artificial\nintelligence, the machine learning and deep learning methods have become more\npopular. However, existing methods often fail to fully model the complex\nspatial dynamics under different scales, which ignore the dynamic\nmulti-resolution spatial and temporal joint inter-dependencies. Moreover, they\nare less likely to consider the special baseline wander problem as well as the\nmulti-view characteristics of medical time series, which largely hinders their\nprediction performance. To address these limitations, we propose a\nMulti-resolution Spatiotemporal Graph Learning framework, MedGNN, for medical\ntime series classification. Specifically, we first propose to construct\nmulti-resolution adaptive graph structures to learn dynamic multi-scale\nembeddings. Then, to address the baseline wander problem, we propose Difference\nAttention Networks to operate self-attention mechanisms on the finite\ndifference for temporal modeling. Moreover, to learn the multi-view\ncharacteristics, we utilize the Frequency Convolution Networks to capture\ncomplementary information of medical time series from the frequency domain. In\naddition, we introduce the Multi-resolution Graph Transformer architecture to\nmodel the dynamic dependencies and fuse the information from different\nresolutions. Finally, we have conducted extensive experiments on multiple\nmedical real-world datasets that demonstrate the superior performance of our\nmethod. Our Code is available.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by WWW 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.04515v1",
    "published_date": "2025-02-06 21:34:54 UTC",
    "updated_date": "2025-02-06 21:34:54 UTC"
  },
  {
    "arxiv_id": "2502.04512v2",
    "title": "Safety is Essential for Responsible Open-Ended Systems",
    "authors": [
      "Ivaxi Sheth",
      "Jan Wehner",
      "Sahar Abdelnabi",
      "Ruta Binkyte",
      "Mario Fritz"
    ],
    "abstract": "AI advancements have been significantly driven by a combination of foundation\nmodels and curiosity-driven learning aimed at increasing capability and\nadaptability. A growing area of interest within this field is Open-Endedness -\nthe ability of AI systems to continuously and autonomously generate novel and\ndiverse artifacts or solutions. This has become relevant for accelerating\nscientific discovery and enabling continual adaptation in AI agents. This\nposition paper argues that the inherently dynamic and self-propagating nature\nof Open-Ended AI introduces significant, underexplored risks, including\nchallenges in maintaining alignment, predictability, and control. This paper\nsystematically examines these challenges, proposes mitigation strategies, and\ncalls for action for different stakeholders to support the safe, responsible\nand successful development of Open-Ended AI.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "12 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.04512v2",
    "published_date": "2025-02-06 21:32:07 UTC",
    "updated_date": "2025-02-10 19:27:12 UTC"
  },
  {
    "arxiv_id": "2502.05231v1",
    "title": "Thin ring wing as a means of flow improvement upstream of a propeller",
    "authors": [
      "Vladimir Sluchak"
    ],
    "abstract": "There are numerous devices currently known with the purpose of reducing the\nirregularity of the flow upstream of the propeller and to decrease by that\nmeans the propeller-induced vibration and noise. Many of these devices are\nwing-shaped vortex-generators that affect the flow with their induced (i.e.\npassive) longitudinal vortices. The paper's subject is the use of a ring-shaped\nwing as a highly effective passive vortex-generator which allows to control the\nflow closer to the most charged sections of propeller blades. The problem of a\nthin ring-shaped wing with irregular (asymmetric) geometry in the irregular\nsteady flow has been solved in a linear approach and the intensity of the\ninduced longitudinal vortices as a function of the irregularity of the flow and\nthe geometry of the ring wing has been estimated using that solution.\nExperiments in the towing tank showing good concordance with the theoretical\nmodel confirmed the effectiveness of such a device. Some additional advantages\nof a ring-shaped wing incorporated into the construction of stabilizers are\nconsidered.",
    "categories": [
      "physics.flu-dyn",
      "cs.AI"
    ],
    "primary_category": "physics.flu-dyn",
    "comment": "7 pages, 7 figures, Propellers/Shafting 97 Symposium",
    "pdf_url": "http://arxiv.org/pdf/2502.05231v1",
    "published_date": "2025-02-06 21:30:08 UTC",
    "updated_date": "2025-02-06 21:30:08 UTC"
  },
  {
    "arxiv_id": "2502.06845v1",
    "title": "DiffNMR3: Advancing NMR Resolution Beyond Instrumental Limits",
    "authors": [
      "Sen Yan",
      "Etienne Goffinet",
      "Fabrizio Gabellieri",
      "Ryan Young",
      "Lydia Gkoura",
      "Laurence Jennings",
      "Filippo Castiglione",
      "Thomas Launey"
    ],
    "abstract": "Nuclear Magnetic Resonance (NMR) spectroscopy is a crucial analytical\ntechnique used for molecular structure elucidation, with applications spanning\nchemistry, biology, materials science, and medicine. However, the frequency\nresolution of NMR spectra is limited by the \"field strength\" of the instrument.\nHigh-field NMR instruments provide high-resolution spectra but are\nprohibitively expensive, whereas lower-field instruments offer more accessible,\nbut lower-resolution, results. This paper introduces an AI-driven approach that\nnot only enhances the frequency resolution of NMR spectra through\nsuper-resolution techniques but also provides multi-scale functionality. By\nleveraging a diffusion model, our method can reconstruct high-field spectra\nfrom low-field NMR data, offering flexibility in generating spectra at varying\nmagnetic field strengths. These reconstructions are comparable to those\nobtained from high-field instruments, enabling finer spectral details and\nimproving molecular characterization. To date, our approach is one of the first\nto overcome the limitations of instrument field strength, achieving NMR\nsuper-resolution through AI. This cost-effective solution makes high-resolution\nanalysis accessible to more researchers and industries, without the need for\nmultimillion-dollar equipment.",
    "categories": [
      "physics.ins-det",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "physics.ins-det",
    "comment": "13 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.06845v1",
    "published_date": "2025-02-06 21:00:35 UTC",
    "updated_date": "2025-02-06 21:00:35 UTC"
  },
  {
    "arxiv_id": "2502.06844v1",
    "title": "Exploring Model Invariance with Discrete Search for Ultra-Low-Bit Quantization",
    "authors": [
      "Yuqiao Wen",
      "Yanshuai Cao",
      "Lili Mou"
    ],
    "abstract": "Large language models have been increasing in size due to their success in a\nwide range of applications. This calls for a pressing need to reduce memory\nusage to make them more accessible. Post-training quantization is a popular\ntechnique which uses fewer bits (e.g., 4--8 bits) to represent the model\nwithout retraining it. However, it remains a challenging task to perform\nquantization in an ultra-low-bit setup (e.g., 2 bits). In this paper, we\npropose InvarExplore, a unified framework that systematically explores\ndifferent model invariance at the same time, allowing us to take advantage of\nthe synergy between each type of invariance. Importantly, InvarExplore features\na discrete search algorithm that enables us to explore permutation invariance,\nwhich is under-studied as it cannot be optimized with gradient-based methods.\nResults show that InvarExplore is compatible with existing state-of-the-art\nmethods, achieving an add-on performance improvement over strong competing\nmethods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "I.2.7; I.2.6; I.2.m; I.5.1; I.7.m"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.06844v1",
    "published_date": "2025-02-06 21:00:13 UTC",
    "updated_date": "2025-02-06 21:00:13 UTC"
  },
  {
    "arxiv_id": "2502.04499v1",
    "title": "Revisiting Intermediate-Layer Matching in Knowledge Distillation: Layer-Selection Strategy Doesn't Matter (Much)",
    "authors": [
      "Zony Yu",
      "Yuqiao Wen",
      "Lili Mou"
    ],
    "abstract": "Knowledge distillation (KD) is a popular method of transferring knowledge\nfrom a large \"teacher\" model to a small \"student\" model. KD can be divided into\ntwo categories: prediction matching and intermediate-layer matching. We explore\nan intriguing phenomenon: layer-selection strategy does not matter (much) in\nintermediate-layer matching. In this paper, we show that seemingly nonsensical\nmatching strategies such as matching the teacher's layers in reverse still\nresult in surprisingly good student performance. We provide an interpretation\nfor this phenomenon by examining the angles between teacher layers viewed from\nthe student's perspective.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "I.2.7; I.2.6"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04499v1",
    "published_date": "2025-02-06 21:00:01 UTC",
    "updated_date": "2025-02-06 21:00:01 UTC"
  },
  {
    "arxiv_id": "2502.04489v1",
    "title": "CNN Autoencoders for Hierarchical Feature Extraction and Fusion in Multi-sensor Human Activity Recognition",
    "authors": [
      "Saeed Arabzadeh",
      "Farshad Almasganj",
      "Mohammad Mahdi Ahmadi"
    ],
    "abstract": "Deep learning methods have been widely used for Human Activity Recognition\n(HAR) using recorded signals from Iner-tial Measurement Units (IMUs) sensors\nthat are installed on various parts of the human body. For this type of HAR,\nsev-eral challenges exist, the most significant of which is the analysis of\nmultivarious IMU sensors data. Here, we introduce a Hierarchically Unsupervised\nFusion (HUF) model designed to extract, and fuse features from IMU sensors data\nvia a hybrid structure of Convolutional Neural Networks (CNN)s and Autoencoders\n(AE)s. First, we design a stack CNN-AE to embed short-time signals into sets of\nhigh dimensional features. Second, we develop another CNN-AE network to locally\nfuse the extracted features from each sensor unit. Finally, we unify all the\nsensor features through a third CNN-AE architecture as globally feature fusion\nto create a unique feature set. Additionally, we analyze the effects of varying\nthe model hyperparameters. The best results are achieved with eight\nconvolutional layers in each AE. Furthermore, it is determined that an\novercomplete AE with 256 kernels in the code layer is suitable for feature\nextraction in the first block of the proposed HUF model; this number reduces to\n64 in the last block of the model to customize the size of the applied features\nto the classifier. The tuned model is applied to the UCI-HAR, DaLiAc, and\nParkinson's disease gait da-tasets, achieving the classification accuracies of\n97%, 97%, and 88%, respectively, which are nearly 3% better com-pared to the\nstate-of-the-art supervised methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.04489v1",
    "published_date": "2025-02-06 20:36:41 UTC",
    "updated_date": "2025-02-06 20:36:41 UTC"
  },
  {
    "arxiv_id": "2502.04488v1",
    "title": "Building A Unified AI-centric Language System: analysis, framework and future work",
    "authors": [
      "Edward Hong Wang",
      "Cynthia Xin Wen"
    ],
    "abstract": "Recent advancements in large language models have demonstrated that extended\ninference through techniques can markedly improve performance, yet these gains\ncome with increased computational costs and the propagation of inherent biases\nfound in natural languages. This paper explores the design of a unified\nAI-centric language system that addresses these challenges by offering a more\nconcise, unambiguous, and computationally efficient alternative to traditional\nhuman languages. We analyze the limitations of natural language such as gender\nbias, morphological irregularities, and contextual ambiguities and examine how\nthese issues are exacerbated within current Transformer architectures, where\nredundant attention heads and token inefficiencies prevail. Drawing on insights\nfrom emergent artificial communication systems and constructed languages like\nEsperanto and Lojban, we propose a framework that translates diverse natural\nlanguage inputs into a streamlined AI-friendly language, enabling more\nefficient model training and inference while reducing memory footprints.\nFinally, we outline a pathway for empirical validation through controlled\nexperiments, paving the way for a universal interchange format that could\nrevolutionize AI-to-AI and human-to-AI interactions by enhancing clarity,\nfairness, and overall performance.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04488v1",
    "published_date": "2025-02-06 20:32:57 UTC",
    "updated_date": "2025-02-06 20:32:57 UTC"
  },
  {
    "arxiv_id": "2502.04485v1",
    "title": "Active Task Disambiguation with LLMs",
    "authors": [
      "Katarzyna Kobalczyk",
      "Nicolas Astorga",
      "Tennison Liu",
      "Mihaela van der Schaar"
    ],
    "abstract": "Despite the impressive performance of large language models (LLMs) across\nvarious benchmarks, their ability to address ambiguously specified\nproblems--frequent in real-world interactions--remains underexplored. To\naddress this gap, we introduce a formal definition of task ambiguity and frame\nthe problem of task disambiguation through the lens of Bayesian Experimental\nDesign. By posing clarifying questions, LLM agents can acquire additional task\nspecifications, progressively narrowing the space of viable solutions and\nreducing the risk of generating unsatisfactory outputs. Yet, generating\neffective clarifying questions requires LLM agents to engage in a form of\nmeta-cognitive reasoning, an ability LLMs may presently lack. Our proposed\napproach of active task disambiguation enables LLM agents to generate targeted\nquestions maximizing the information gain. Effectively, this approach shifts\nthe load from implicit to explicit reasoning about the space of viable\nsolutions. Empirical results demonstrate that this form of question selection\nleads to more effective task disambiguation in comparison to approaches relying\non reasoning solely within the space of questions.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04485v1",
    "published_date": "2025-02-06 20:20:22 UTC",
    "updated_date": "2025-02-06 20:20:22 UTC"
  },
  {
    "arxiv_id": "2502.05230v1",
    "title": "DiffNMR2: NMR Guided Sampling Acquisition Through Diffusion Model Uncertainty",
    "authors": [
      "Etienne Goffinet",
      "Sen Yan",
      "Fabrizio Gabellieri",
      "Laurence Jennings",
      "Lydia Gkoura",
      "Filippo Castiglione",
      "Ryan Young",
      "Idir Malki",
      "Ankita Singh",
      "Thomas Launey"
    ],
    "abstract": "Nuclear Magnetic Resonance (NMR) spectrometry uses electro-frequency pulses\nto probe the resonance of a compound's nucleus, which is then analyzed to\ndetermine its structure. The acquisition time of high-resolution NMR spectra\nremains a significant bottleneck, especially for complex biological samples\nsuch as proteins. In this study, we propose a novel and efficient sub-sampling\nstrategy based on a diffusion model trained on protein NMR data. Our method\niteratively reconstructs under-sampled spectra while using model uncertainty to\nguide subsequent sampling, significantly reducing acquisition time. Compared to\nstate-of-the-art strategies, our approach improves reconstruction accuracy by\n52.9\\%, reduces hallucinated peaks by 55.6%, and requires 60% less time in\ncomplex NMR experiments. This advancement holds promise for many applications,\nfrom drug discovery to materials science, where rapid and high-resolution\nspectral analysis is critical.",
    "categories": [
      "q-bio.QM",
      "cs.AI"
    ],
    "primary_category": "q-bio.QM",
    "comment": "11 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.05230v1",
    "published_date": "2025-02-06 20:10:28 UTC",
    "updated_date": "2025-02-06 20:10:28 UTC"
  },
  {
    "arxiv_id": "2502.04476v1",
    "title": "ADIFF: Explaining audio difference using natural language",
    "authors": [
      "Soham Deshmukh",
      "Shuo Han",
      "Rita Singh",
      "Bhiksha Raj"
    ],
    "abstract": "Understanding and explaining differences between audio recordings is crucial\nfor fields like audio forensics, quality assessment, and audio generation. This\ninvolves identifying and describing audio events, acoustic scenes, signal\ncharacteristics, and their emotional impact on listeners. This paper stands out\nas the first work to comprehensively study the task of explaining audio\ndifferences and then propose benchmark, baselines for the task. First, we\npresent two new datasets for audio difference explanation derived from the\nAudioCaps and Clotho audio captioning datasets. Using Large Language Models\n(LLMs), we generate three levels of difference explanations: (1) concise\ndescriptions of audio events and objects, (2) brief sentences about audio\nevents, acoustic scenes, and signal properties, and (3) comprehensive\nexplanations that include semantics and listener emotions. For the baseline, we\nuse prefix tuning where audio embeddings from two audio files are used to\nprompt a frozen language model. Our empirical analysis and ablation studies\nreveal that the naive baseline struggles to distinguish perceptually similar\nsounds and generate detailed tier 3 explanations. To address these limitations,\nwe propose ADIFF, which introduces a cross-projection module, position\ncaptioning, and a three-step training process to enhance the model's ability to\nproduce detailed explanations. We evaluate our model using objective metrics\nand human evaluation and show our model enhancements lead to significant\nimprovements in performance over naive baseline and SoTA Audio-Language Model\n(ALM) Qwen Audio. Lastly, we conduct multiple ablation studies to study the\neffects of cross-projection, language model parameters, position captioning,\nthird stage fine-tuning, and present our findings. Our benchmarks, findings,\nand strong baseline pave the way for nuanced and human-like explanations of\naudio differences.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted at ICLR 2025. Dataset and checkpoints are available at:\n  https://github.com/soham97/ADIFF",
    "pdf_url": "http://arxiv.org/pdf/2502.04476v1",
    "published_date": "2025-02-06 20:00:43 UTC",
    "updated_date": "2025-02-06 20:00:43 UTC"
  },
  {
    "arxiv_id": "2502.04475v1",
    "title": "Augmented Conditioning Is Enough For Effective Training Image Generation",
    "authors": [
      "Jiahui Chen",
      "Amy Zhang",
      "Adriana Romero-Soriano"
    ],
    "abstract": "Image generation abilities of text-to-image diffusion models have\nsignificantly advanced, yielding highly photo-realistic images from descriptive\ntext and increasing the viability of leveraging synthetic images to train\ncomputer vision models. To serve as effective training data, generated images\nmust be highly realistic while also sufficiently diverse within the support of\nthe target data distribution. Yet, state-of-the-art conditional image\ngeneration models have been primarily optimized for creative applications,\nprioritizing image realism and prompt adherence over conditional diversity. In\nthis paper, we investigate how to improve the diversity of generated images\nwith the goal of increasing their effectiveness to train downstream image\nclassification models, without fine-tuning the image generation model. We find\nthat conditioning the generation process on an augmented real image and text\nprompt produces generations that serve as effective synthetic datasets for\ndownstream training. Conditioning on real training images contextualizes the\ngeneration process to produce images that are in-domain with the real image\ndistribution, while data augmentations introduce visual diversity that improves\nthe performance of the downstream classifier. We validate\naugmentation-conditioning on a total of five established long-tail and few-shot\nimage classification benchmarks and show that leveraging augmentations to\ncondition the generation process results in consistent improvements over the\nstate-of-the-art on the long-tailed benchmark and remarkable gains in extreme\nfew-shot regimes of the remaining four benchmarks. These results constitute an\nimportant step towards effectively leveraging synthetic data for downstream\ntraining.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04475v1",
    "published_date": "2025-02-06 19:57:33 UTC",
    "updated_date": "2025-02-06 19:57:33 UTC"
  },
  {
    "arxiv_id": "2502.04470v1",
    "title": "Color in Visual-Language Models: CLIP deficiencies",
    "authors": [
      "Guillem Arias",
      "Ramon Baldrich",
      "Maria Vanrell"
    ],
    "abstract": "This work explores how color is encoded in CLIP (Contrastive Language-Image\nPre-training) which is currently the most influential VML (Visual Language\nmodel) in Artificial Intelligence. After performing different experiments on\nsynthetic datasets created for this task, we conclude that CLIP is able to\nattribute correct color labels to colored visual stimulus, but, we come across\ntwo main deficiencies: (a) a clear bias on achromatic stimuli that are poorly\nrelated to the color concept, thus white, gray and black are rarely assigned as\ncolor labels; and (b) the tendency to prioritize text over other visual\ninformation. Here we prove it is highly significant in color labelling through\nan exhaustive Stroop-effect test. With the aim to find the causes of these\ncolor deficiencies, we analyse the internal representation at the neuron level.\nWe conclude that CLIP presents an important amount of neurons selective to\ntext, specially in deepest layers of the network, and a smaller amount of\nmulti-modal color neurons which could be the key of understanding the concept\nof color properly. Our investigation underscores the necessity of refining\ncolor representation mechanisms in neural networks to foster a more\ncomprehensive comprehension of colors as humans understand them, thereby\nadvancing the efficacy and versatility of multimodal models like CLIP in\nreal-world scenarios.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "6 pages, 10 figures, conference, Artificial Intelligence",
    "pdf_url": "http://arxiv.org/pdf/2502.04470v1",
    "published_date": "2025-02-06 19:38:12 UTC",
    "updated_date": "2025-02-06 19:38:12 UTC"
  },
  {
    "arxiv_id": "2502.04469v1",
    "title": "No Images, No Problem: Retaining Knowledge in Continual VQA with Questions-Only Memory",
    "authors": [
      "Imad Eddine Marouf",
      "Enzo Tartaglione",
      "Stephane Lathuiliere",
      "Joost van de Weijer"
    ],
    "abstract": "Continual Learning in Visual Question Answering (VQACL) requires models to\nlearn new visual-linguistic tasks (plasticity) while retaining knowledge from\nprevious tasks (stability). The multimodal nature of VQACL presents unique\nchallenges, requiring models to balance stability across visual and textual\ndomains while maintaining plasticity to adapt to novel objects and reasoning\ntasks. Existing methods, predominantly designed for unimodal tasks, often\nstruggle to balance these demands effectively. In this work, we introduce\nQUestion-only replay with Attention Distillation (QUAD), a novel approach for\nVQACL that leverages only past task questions for regularisation, eliminating\nthe need to store visual data and addressing both memory and privacy concerns.\nQUAD achieves stability by introducing a question-only replay mechanism that\nselectively uses questions from previous tasks to prevent overfitting to the\ncurrent task's answer space, thereby mitigating the out-of-answer-set problem.\nComplementing this, we propose attention consistency distillation, which\nuniquely enforces both intra-modal and inter-modal attention consistency across\ntasks, preserving essential visual-linguistic associations. Extensive\nexperiments on VQAv2 and NExT-QA demonstrate that QUAD significantly\noutperforms state-of-the-art methods, achieving robust performance in continual\nVQA.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, in-review",
    "pdf_url": "http://arxiv.org/pdf/2502.04469v1",
    "published_date": "2025-02-06 19:37:43 UTC",
    "updated_date": "2025-02-06 19:37:43 UTC"
  },
  {
    "arxiv_id": "2502.04465v1",
    "title": "FocalCodec: Low-Bitrate Speech Coding via Focal Modulation Networks",
    "authors": [
      "Luca Della Libera",
      "Francesco Paissan",
      "Cem Subakan",
      "Mirco Ravanelli"
    ],
    "abstract": "Large language models have revolutionized natural language processing through\nself-supervised pretraining on massive datasets. Inspired by this success,\nresearchers have explored adapting these methods to speech by discretizing\ncontinuous audio into tokens using neural audio codecs. However, existing\napproaches face limitations, including high bitrates, the loss of either\nsemantic or acoustic information, and the reliance on multi-codebook designs\nwhen trying to capture both, which increases architectural complexity for\ndownstream tasks. To address these challenges, we introduce FocalCodec, an\nefficient low-bitrate codec based on focal modulation that utilizes a single\nbinary codebook to compress speech between 0.16 and 0.65 kbps. FocalCodec\ndelivers competitive performance in speech resynthesis and voice conversion at\nlower bitrates than the current state-of-the-art, while effectively handling\nmultilingual speech and noisy environments. Evaluation on downstream tasks\nshows that FocalCodec successfully preserves sufficient semantic and acoustic\ninformation, while also being well-suited for generative modeling. Demo\nsamples, code and checkpoints are available at\nhttps://lucadellalib.github.io/focalcodec-web/.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.LG",
    "comment": "18 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.04465v1",
    "published_date": "2025-02-06 19:24:50 UTC",
    "updated_date": "2025-02-06 19:24:50 UTC"
  },
  {
    "arxiv_id": "2502.06843v1",
    "title": "Vision-Integrated LLMs for Autonomous Driving Assistance : Human Performance Comparison and Trust Evaluation",
    "authors": [
      "Namhee Kim",
      "Woojin Park"
    ],
    "abstract": "Traditional autonomous driving systems often struggle with reasoning in\ncomplex, unexpected scenarios due to limited comprehension of spatial\nrelationships. In response, this study introduces a Large Language Model\n(LLM)-based Autonomous Driving (AD) assistance system that integrates a vision\nadapter and an LLM reasoning module to enhance visual understanding and\ndecision-making. The vision adapter, combining YOLOv4 and Vision Transformer\n(ViT), extracts comprehensive visual features, while GPT-4 enables human-like\nspatial reasoning and response generation. Experimental evaluations with 45\nexperienced drivers revealed that the system closely mirrors human performance\nin describing situations and moderately aligns with human decisions in\ngenerating appropriate responses.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.06843v1",
    "published_date": "2025-02-06 19:19:28 UTC",
    "updated_date": "2025-02-06 19:19:28 UTC"
  },
  {
    "arxiv_id": "2502.06842v1",
    "title": "Integrating Generative Artificial Intelligence in ADRD: A Framework for Streamlining Diagnosis and Care in Neurodegenerative Diseases",
    "authors": [
      "Andrew G. Breithaupt",
      "Alice Tang",
      "Bruce L. Miller",
      "Pedro Pinheiro-Chagas"
    ],
    "abstract": "Healthcare systems are struggling to meet the growing demand for neurological\ncare, with challenges particularly acute in Alzheimer's disease and related\ndementias (ADRD). While artificial intelligence research has often focused on\nidentifying patterns beyond human perception, implementing such predictive\ncapabilities remains challenging as clinicians cannot readily verify insights\nthey cannot themselves detect. We propose that large language models (LLMs)\noffer more immediately practical applications by enhancing clinicians'\ncapabilities in three critical areas: comprehensive data collection,\ninterpretation of complex clinical information, and timely application of\nrelevant medical knowledge. These challenges stem from limited time for proper\ndiagnosis, growing data complexity, and an overwhelming volume of medical\nliterature that exceeds any clinician's capacity to fully master. We present a\nframework for responsible AI integration that leverages LLMs' ability to\ncommunicate effectively with both patients and providers while maintaining\nhuman oversight. This approach prioritizes standardized, high-quality data\ncollection to enable a system that learns from every patient encounter while\nincorporating the latest clinical evidence, continuously improving care\ndelivery. We begin to address implementation challenges and initiate important\ndiscussions around ethical considerations and governance needs. While developed\nfor ADRD, this roadmap provides principles for responsible AI integration\nacross neurology and other medical specialties, with potential to improve\ndiagnostic accuracy, reduce care disparities, and advance clinical knowledge\nthrough a learning healthcare system.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "I.2.1"
    ],
    "primary_category": "cs.CY",
    "comment": "20 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2502.06842v1",
    "published_date": "2025-02-06 19:09:11 UTC",
    "updated_date": "2025-02-06 19:09:11 UTC"
  },
  {
    "arxiv_id": "2502.04326v1",
    "title": "WorldSense: Evaluating Real-world Omnimodal Understanding for Multimodal LLMs",
    "authors": [
      "Jack Hong",
      "Shilin Yan",
      "Jiayin Cai",
      "Xiaolong Jiang",
      "Yao Hu",
      "Weidi Xie"
    ],
    "abstract": "In this paper, we introduce WorldSense, the first benchmark to assess the\nmulti-modal video understanding, that simultaneously encompasses visual, audio,\nand text inputs. In contrast to existing benchmarks, our WorldSense has several\nfeatures: (i) collaboration of omni-modality, we design the evaluation tasks to\nfeature a strong coupling of audio and video, requiring models to effectively\nutilize the synergistic perception of omni-modality; (ii) diversity of videos\nand tasks, WorldSense encompasses a diverse collection of 1,662 audio-visual\nsynchronised videos, systematically categorized into 8 primary domains and 67\nfine-grained subcategories to cover the broad scenarios, and 3,172 multi-choice\nQA pairs across 26 distinct tasks to enable the comprehensive evaluation; (iii)\nhigh-quality annotations, all the QA pairs are manually labeled by 80 expert\nannotators with multiple rounds of correction to ensure quality. Based on our\nWorldSense, we extensively evaluate various state-of-the-art models. The\nexperimental results indicate that existing models face significant challenges\nin understanding real-world scenarios (48.0% best accuracy). We hope our\nWorldSense can provide a platform for evaluating the ability in constructing\nand understanding coherent contexts from omni-modality.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04326v1",
    "published_date": "2025-02-06 18:59:40 UTC",
    "updated_date": "2025-02-06 18:59:40 UTC"
  },
  {
    "arxiv_id": "2502.04428v1",
    "title": "Confident or Seek Stronger: Exploring Uncertainty-Based On-device LLM Routing From Benchmarking to Generalization",
    "authors": [
      "Yu-Neng Chuang",
      "Leisheng Yu",
      "Guanchu Wang",
      "Lizhe Zhang",
      "Zirui Liu",
      "Xuanting Cai",
      "Yang Sui",
      "Vladimir Braverman",
      "Xia Hu"
    ],
    "abstract": "Large language models (LLMs) are increasingly deployed and democratized on\nedge devices. To improve the efficiency of on-device deployment, small language\nmodels (SLMs) are often adopted due to their efficient decoding latency and\nreduced energy consumption. However, these SLMs often generate inaccurate\nresponses when handling complex queries. One promising solution is\nuncertainty-based SLM routing, offloading high-stakes queries to stronger LLMs\nwhen resulting in low-confidence responses on SLM. This follows the principle\nof \"If you lack confidence, seek stronger support\" to enhance reliability.\nRelying on more powerful LLMs is yet effective but increases invocation costs.\nTherefore, striking a routing balance between efficiency and efficacy remains a\ncritical challenge. Additionally, efficiently generalizing the routing strategy\nto new datasets remains under-explored. In this paper, we conduct a\ncomprehensive investigation into benchmarking and generalization of\nuncertainty-driven routing strategies from SLMs to LLMs over 1500+ settings.\nOur findings highlight: First, uncertainty-correctness alignment in different\nuncertainty quantification (UQ) methods significantly impacts routing\nperformance. Second, uncertainty distributions depend more on both the specific\nSLM and the chosen UQ method, rather than downstream data. Building on the\ninsight, we propose a calibration data construction instruction pipeline and\nopen-source a constructed hold-out set to enhance routing generalization on new\ndownstream scenarios. The experimental results indicate calibration data\neffectively bootstraps routing performance without any new data.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04428v1",
    "published_date": "2025-02-06 18:59:11 UTC",
    "updated_date": "2025-02-06 18:59:11 UTC"
  },
  {
    "arxiv_id": "2502.04322v1",
    "title": "Speak Easy: Eliciting Harmful Jailbreaks from LLMs with Simple Interactions",
    "authors": [
      "Yik Siu Chan",
      "Narutatsu Ri",
      "Yuxin Xiao",
      "Marzyeh Ghassemi"
    ],
    "abstract": "Despite extensive safety alignment efforts, large language models (LLMs)\nremain vulnerable to jailbreak attacks that elicit harmful behavior. While\nexisting studies predominantly focus on attack methods that require technical\nexpertise, two critical questions remain underexplored: (1) Are jailbroken\nresponses truly useful in enabling average users to carry out harmful actions?\n(2) Do safety vulnerabilities exist in more common, simple human-LLM\ninteractions? In this paper, we demonstrate that LLM responses most effectively\nfacilitate harmful actions when they are both actionable and informative--two\nattributes easily elicited in multi-step, multilingual interactions. Using this\ninsight, we propose HarmScore, a jailbreak metric that measures how effectively\nan LLM response enables harmful actions, and Speak Easy, a simple multi-step,\nmultilingual attack framework. Notably, by incorporating Speak Easy into direct\nrequest and jailbreak baselines, we see an average absolute increase of 0.319\nin Attack Success Rate and 0.426 in HarmScore in both open-source and\nproprietary LLMs across four safety benchmarks. Our work reveals a critical yet\noften overlooked vulnerability: Malicious users can easily exploit common\ninteraction patterns for harmful intentions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04322v1",
    "published_date": "2025-02-06 18:59:02 UTC",
    "updated_date": "2025-02-06 18:59:02 UTC"
  },
  {
    "arxiv_id": "2502.04315v3",
    "title": "ChameleonLLM: Batch-Aware Dynamic Low-Rank Adaptation via Inference-Time Clusters",
    "authors": [
      "Kamer Ali Yuksel",
      "Hassan Sawaf"
    ],
    "abstract": "Recent advances in large language models (LLMs) have shown remarkable\nperformance across diverse tasks. However, these models are typically deployed\nwith fixed weights, which limits their ability to adapt dynamically to the\nvariability inherent in real-world data during inference. This paper introduces\nChameleonLLM, a novel framework that enables inference-time adaptation of LLMs\nby leveraging batch-aware clustering and on-the-fly generation of low-rank\nupdates. Unlike traditional fine-tuning approaches such as Low-Rank Adaptation\n(LoRA) or methods that rely on a fixed set of pre-learned uniforms (changeable\nmasks), our method dynamically generates adaptive modifications to the decoder\nweights based on the aggregated statistics of clustered batches. By\nintelligently grouping similar inputs and computing context-aware low-rank\nupdates via a hyper-network, ChameleonLLM achieves significant performance\ngains, outperforming conventional LoRA methods while eliminating the overhead\nof maintaining multiple expert models. Our experiments highlight the potential\nof our approach to serve as a versatile and highly adaptive solution for\nlanguage model inference. ChameleonLLM is open-sourced to ensure the\nreproducibility of our experiments:\nhttps://anonymous.4open.science/r/ChamaleonLLM/",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04315v3",
    "published_date": "2025-02-06 18:57:06 UTC",
    "updated_date": "2025-02-11 14:01:39 UTC"
  },
  {
    "arxiv_id": "2502.04313v1",
    "title": "Great Models Think Alike and this Undermines AI Oversight",
    "authors": [
      "Shashwat Goel",
      "Joschka Struber",
      "Ilze Amanda Auzina",
      "Karuna K Chandra",
      "Ponnurangam Kumaraguru",
      "Douwe Kiela",
      "Ameya Prabhu",
      "Matthias Bethge",
      "Jonas Geiping"
    ],
    "abstract": "As Language Model (LM) capabilities advance, evaluating and supervising them\nat scale is getting harder for humans. There is hope that other language models\ncan automate both these tasks, which we refer to as \"AI Oversight\". We study\nhow model similarity affects both aspects of AI oversight by proposing a\nprobabilistic metric for LM similarity based on overlap in model mistakes.\nUsing this metric, we first show that LLM-as-a-judge scores favor models\nsimilar to the judge, generalizing recent self-preference results. Then, we\nstudy training on LM annotations, and find complementary knowledge between the\nweak supervisor and strong student model plays a crucial role in gains from\n\"weak-to-strong generalization\". As model capabilities increase, it becomes\nharder to find their mistakes, and we might defer more to AI oversight.\nHowever, we observe a concerning trend -- model mistakes are becoming more\nsimilar with increasing capabilities, pointing to risks from correlated\nfailures. Our work underscores the importance of reporting and correcting for\nmodel similarity, especially in the emerging paradigm of AI oversight.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "60 pages, 20 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.04313v1",
    "published_date": "2025-02-06 18:56:01 UTC",
    "updated_date": "2025-02-06 18:56:01 UTC"
  },
  {
    "arxiv_id": "2502.04426v1",
    "title": "Decoding AI Judgment: How LLMs Assess News Credibility and Bias",
    "authors": [
      "Edoardo Loru",
      "Jacopo Nudo",
      "Niccolò Di Marco",
      "Matteo Cinelli",
      "Walter Quattrociocchi"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly used to assess news\ncredibility, yet little is known about how they make these judgments. While\nprior research has examined political bias in LLM outputs or their potential\nfor automated fact-checking, their internal evaluation processes remain largely\nunexamined. Understanding how LLMs assess credibility provides insights into AI\nbehavior and how credibility is structured and applied in large-scale language\nmodels. This study benchmarks the reliability and political classifications of\nstate-of-the-art LLMs - Gemini 1.5 Flash (Google), GPT-4o mini (OpenAI), and\nLLaMA 3.1 (Meta) - against structured, expert-driven rating systems such as\nNewsGuard and Media Bias Fact Check. Beyond assessing classification\nperformance, we analyze the linguistic markers that shape LLM decisions,\nidentifying which words and concepts drive their evaluations. We uncover\npatterns in how LLMs associate credibility with specific linguistic features by\nexamining keyword frequency, contextual determinants, and rank distributions.\nBeyond static classification, we introduce a framework in which LLMs refine\ntheir credibility assessments by retrieving external information, querying\nother models, and adapting their responses. This allows us to investigate\nwhether their assessments reflect structured reasoning or rely primarily on\nprior learned associations.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04426v1",
    "published_date": "2025-02-06 18:52:10 UTC",
    "updated_date": "2025-02-06 18:52:10 UTC"
  },
  {
    "arxiv_id": "2502.04308v1",
    "title": "HOG-Diff: Higher-Order Guided Diffusion for Graph Generation",
    "authors": [
      "Yiming Huang",
      "Tolga Birdal"
    ],
    "abstract": "Graph generation is a critical yet challenging task as empirical analyses\nrequire a deep understanding of complex, non-Euclidean structures. Although\ndiffusion models have recently made significant achievements in graph\ngeneration, these models typically adapt from the frameworks designed for image\ngeneration, making them ill-suited for capturing the topological properties of\ngraphs. In this work, we propose a novel Higher-order Guided Diffusion\n(HOG-Diff) model that follows a coarse-to-fine generation curriculum and is\nguided by higher-order information, enabling the progressive generation of\nplausible graphs with inherent topological structures. We further prove that\nour model exhibits a stronger theoretical guarantee than classical diffusion\nframeworks. Extensive experiments on both molecular and generic graph\ngeneration tasks demonstrate that our method consistently outperforms or\nremains competitive with state-of-the-art baselines. Our code is available at\nhttps://github.com/Yiminghh/HOG-Diff.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI",
      "physics.soc-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04308v1",
    "published_date": "2025-02-06 18:51:14 UTC",
    "updated_date": "2025-02-06 18:51:14 UTC"
  },
  {
    "arxiv_id": "2502.04307v1",
    "title": "DexterityGen: Foundation Controller for Unprecedented Dexterity",
    "authors": [
      "Zhao-Heng Yin",
      "Changhao Wang",
      "Luis Pineda",
      "Francois Hogan",
      "Krishna Bodduluri",
      "Akash Sharma",
      "Patrick Lancaster",
      "Ishita Prasad",
      "Mrinal Kalakrishnan",
      "Jitendra Malik",
      "Mike Lambeta",
      "Tingfan Wu",
      "Pieter Abbeel",
      "Mustafa Mukadam"
    ],
    "abstract": "Teaching robots dexterous manipulation skills, such as tool use, presents a\nsignificant challenge. Current approaches can be broadly categorized into two\nstrategies: human teleoperation (for imitation learning) and sim-to-real\nreinforcement learning. The first approach is difficult as it is hard for\nhumans to produce safe and dexterous motions on a different embodiment without\ntouch feedback. The second RL-based approach struggles with the domain gap and\ninvolves highly task-specific reward engineering on complex tasks. Our key\ninsight is that RL is effective at learning low-level motion primitives, while\nhumans excel at providing coarse motion commands for complex, long-horizon\ntasks. Therefore, the optimal solution might be a combination of both\napproaches. In this paper, we introduce DexterityGen (DexGen), which uses RL to\npretrain large-scale dexterous motion primitives, such as in-hand rotation or\ntranslation. We then leverage this learned dataset to train a dexterous\nfoundational controller. In the real world, we use human teleoperation as a\nprompt to the controller to produce highly dexterous behavior. We evaluate the\neffectiveness of DexGen in both simulation and real world, demonstrating that\nit is a general-purpose controller that can realize input dexterous\nmanipulation commands and significantly improves stability by 10-100x measured\nas duration of holding objects across diverse tasks. Notably, with DexGen we\ndemonstrate unprecedented dexterous skills including diverse object\nreorientation and dexterous tool use such as pen, syringe, and screwdriver for\nthe first time.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "Project: https://zhaohengyin.github.io/dexteritygen",
    "pdf_url": "http://arxiv.org/pdf/2502.04307v1",
    "published_date": "2025-02-06 18:49:35 UTC",
    "updated_date": "2025-02-06 18:49:35 UTC"
  },
  {
    "arxiv_id": "2502.04302v1",
    "title": "Strong Equivalence in Answer Set Programming with Constraints",
    "authors": [
      "Pedro Cabalar",
      "Jorge Fandinno",
      "Torsten Schaub",
      "Philipp Wanko"
    ],
    "abstract": "We investigate the concept of strong equivalence within the extended\nframework of Answer Set Programming with constraints. Two groups of rules are\nconsidered strongly equivalent if, informally speaking, they have the same\nmeaning in any context. We demonstrate that, under certain assumptions, strong\nequivalence between rule sets in this extended setting can be precisely\ncharacterized by their equivalence in the logic of Here-and-There with\nconstraints. Furthermore, we present a translation from the language of several\nclingo-based answer set solvers that handle constraints into the language of\nHere-and-There with constraints. This translation enables us to leverage the\nlogic of Here-and-There to reason about strong equivalence within the context\nof these solvers. We also explore the computational complexity of determining\nstrong equivalence in this context.",
    "categories": [
      "cs.AI",
      "cs.LO",
      "I.2.4; I.2.8"
    ],
    "primary_category": "cs.AI",
    "comment": "30 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.04302v1",
    "published_date": "2025-02-06 18:43:59 UTC",
    "updated_date": "2025-02-06 18:43:59 UTC"
  },
  {
    "arxiv_id": "2502.04290v1",
    "title": "Every Call is Precious: Global Optimization of Black-Box Functions with Unknown Lipschitz Constants",
    "authors": [
      "Fares Fourati",
      "Salma Kharrat",
      "Vaneet Aggarwal",
      "Mohamed-Slim Alouini"
    ],
    "abstract": "Optimizing expensive, non-convex, black-box Lipschitz continuous functions\npresents significant challenges, particularly when the Lipschitz constant of\nthe underlying function is unknown. Such problems often demand numerous\nfunction evaluations to approximate the global optimum, which can be\nprohibitive in terms of time, energy, or resources. In this work, we introduce\nEvery Call is Precious (ECP), a novel global optimization algorithm that\nminimizes unpromising evaluations by strategically focusing on potentially\noptimal regions. Unlike previous approaches, ECP eliminates the need to\nestimate the Lipschitz constant, thereby avoiding additional function\nevaluations. ECP guarantees no-regret performance for infinite evaluation\nbudgets and achieves minimax-optimal regret bounds within finite budgets.\nExtensive ablation studies validate the algorithm's robustness, while empirical\nevaluations show that ECP outperforms 10 benchmark algorithms including\nLipschitz, Bayesian, bandits, and evolutionary methods across 30\nmulti-dimensional non-convex synthetic and real-world optimization problems,\nwhich positions ECP as a competitive approach for global optimization.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at AISTATS 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.04290v1",
    "published_date": "2025-02-06 18:34:40 UTC",
    "updated_date": "2025-02-06 18:34:40 UTC"
  },
  {
    "arxiv_id": "2502.04424v1",
    "title": "EmoBench-M: Benchmarking Emotional Intelligence for Multimodal Large Language Models",
    "authors": [
      "He Hu",
      "Yucheng Zhou",
      "Lianzhong You",
      "Hongbo Xu",
      "Qianning Wang",
      "Zheng Lian",
      "Fei Richard Yu",
      "Fei Ma",
      "Laizhong Cui"
    ],
    "abstract": "With the integration of Multimodal large language models (MLLMs) into robotic\nsystems and various AI applications, embedding emotional intelligence (EI)\ncapabilities into these models is essential for enabling robots to effectively\naddress human emotional needs and interact seamlessly in real-world scenarios.\nExisting static, text-based, or text-image benchmarks overlook the multimodal\ncomplexities of real-world interactions and fail to capture the dynamic,\nmultimodal nature of emotional expressions, making them inadequate for\nevaluating MLLMs' EI. Based on established psychological theories of EI, we\nbuild EmoBench-M, a novel benchmark designed to evaluate the EI capability of\nMLLMs across 13 valuation scenarios from three key dimensions: foundational\nemotion recognition, conversational emotion understanding, and socially complex\nemotion analysis. Evaluations of both open-source and closed-source MLLMs on\nEmoBench-M reveal a significant performance gap between them and humans,\nhighlighting the need to further advance their EI capabilities. All benchmark\nresources, including code and datasets, are publicly available at\nhttps://emo-gml.github.io/.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04424v1",
    "published_date": "2025-02-06 18:13:35 UTC",
    "updated_date": "2025-02-06 18:13:35 UTC"
  },
  {
    "arxiv_id": "2502.04269v1",
    "title": "How does a Multilingual LM Handle Multiple Languages?",
    "authors": [
      "Santhosh Kakarla",
      "Gautama Shastry Bulusu Venkata",
      "Aishwarya Gaddam"
    ],
    "abstract": "Multilingual language models have significantly advanced due to rapid\nprogress in natural language processing. Models like BLOOM 1.7B, trained on\ndiverse multilingual datasets, aim to bridge linguistic gaps. However, their\neffectiveness in capturing linguistic knowledge, particularly for low-resource\nlanguages, remains an open question. This study critically examines MLMs\ncapabilities in multilingual understanding, semantic representation, and\ncross-lingual knowledge transfer. While these models perform well for\nhigh-resource languages, they struggle with less-represented ones.\nAdditionally, traditional evaluation methods often overlook their internal\nsyntactic and semantic encoding.\n  This research addresses key limitations through three objectives. First, it\nassesses semantic similarity by analyzing multilingual word embeddings for\nconsistency using cosine similarity. Second, it examines BLOOM-1.7B and Qwen2\nthrough Named Entity Recognition and sentence similarity tasks to understand\ntheir linguistic structures. Third, it explores cross-lingual knowledge\ntransfer by evaluating generalization from high-resource to low-resource\nlanguages in sentiment analysis and text classification.\n  By leveraging linguistic probing, performance metrics, and visualizations,\nthis study provides insights into the strengths and limitations of MLMs. The\nfindings aim to enhance multilingual NLP models, ensuring better support for\nboth high- and low-resource languages, thereby promoting inclusivity in\nlanguage technologies.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.04269v1",
    "published_date": "2025-02-06 18:08:14 UTC",
    "updated_date": "2025-02-06 18:08:14 UTC"
  },
  {
    "arxiv_id": "2502.04268v2",
    "title": "Point2RBox-v2: Rethinking Point-supervised Oriented Object Detection with Spatial Layout Among Instances",
    "authors": [
      "Yi Yu",
      "Botao Ren",
      "Peiyuan Zhang",
      "Mingxin Liu",
      "Junwei Luo",
      "Shaofeng Zhang",
      "Feipeng Da",
      "Junchi Yan",
      "Xue Yang"
    ],
    "abstract": "With the rapidly increasing demand for oriented object detection (OOD),\nrecent research involving weakly-supervised detectors for learning OOD from\npoint annotations has gained great attention. In this paper, we rethink this\nchallenging task setting with the layout among instances and present\nPoint2RBox-v2. At the core are three principles: 1) Gaussian overlap loss. It\nlearns an upper bound for each instance by treating objects as 2D Gaussian\ndistributions and minimizing their overlap. 2) Voronoi watershed loss. It\nlearns a lower bound for each instance through watershed on Voronoi\ntessellation. 3) Consistency loss. It learns the size/rotation variation\nbetween two output sets with respect to an input image and its augmented view.\nSupplemented by a few devised techniques, e.g. edge loss and copy-paste, the\ndetector is further enhanced. To our best knowledge, Point2RBox-v2 is the first\napproach to explore the spatial layout among instances for learning\npoint-supervised OOD. Our solution is elegant and lightweight, yet it is\nexpected to give a competitive performance especially in densely packed scenes:\n62.61%/86.15%/34.71% on DOTA/HRSC/FAIR1M. Code is available at\nhttps://github.com/VisionXLab/point2rbox-v2.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages, 5 figures, 10 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.04268v2",
    "published_date": "2025-02-06 18:07:25 UTC",
    "updated_date": "2025-02-07 02:23:19 UTC"
  },
  {
    "arxiv_id": "2502.04263v1",
    "title": "Cross the Gap: Exposing the Intra-modal Misalignment in CLIP via Modality Inversion",
    "authors": [
      "Marco Mistretta",
      "Alberto Baldrati",
      "Lorenzo Agnolucci",
      "Marco Bertini",
      "Andrew D. Bagdanov"
    ],
    "abstract": "Pre-trained multi-modal Vision-Language Models like CLIP are widely used\noff-the-shelf for a variety of applications. In this paper, we show that the\ncommon practice of individually exploiting the text or image encoders of these\npowerful multi-modal models is highly suboptimal for intra-modal tasks like\nimage-to-image retrieval. We argue that this is inherently due to the\nCLIP-style inter-modal contrastive loss that does not enforce any intra-modal\nconstraints, leading to what we call intra-modal misalignment. To demonstrate\nthis, we leverage two optimization-based modality inversion techniques that map\nrepresentations from their input modality to the complementary one without any\nneed for auxiliary data or additional trained adapters. We empirically show\nthat, in the intra-modal tasks of image-to-image and text-to-text retrieval,\napproaching these tasks inter-modally significantly improves performance with\nrespect to intra-modal baselines on more than fifteen datasets. Additionally,\nwe demonstrate that approaching a native inter-modal task (e.g. zero-shot image\nclassification) intra-modally decreases performance, further validating our\nfindings. Finally, we show that incorporating an intra-modal term in the\npre-training objective or narrowing the modality gap between the text and image\nfeature embedding spaces helps reduce the intra-modal misalignment. The code is\npublicly available at: https://github.com/miccunifi/Cross-the-Gap.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted for publication at ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.04263v1",
    "published_date": "2025-02-06 17:58:59 UTC",
    "updated_date": "2025-02-06 17:58:59 UTC"
  },
  {
    "arxiv_id": "2502.04249v1",
    "title": "Free Energy Risk Metrics for Systemically Safe AI: Gatekeeping Multi-Agent Study",
    "authors": [
      "Michael Walters",
      "Rafael Kaufmann",
      "Justice Sefas",
      "Thomas Kopinski"
    ],
    "abstract": "We investigate the Free Energy Principle as a foundation for measuring risk\nin agentic and multi-agent systems. From these principles we introduce a\nCumulative Risk Exposure metric that is flexible to differing contexts and\nneeds. We contrast this to other popular theories for safe AI that hinge on\nmassive amounts of data or describing arbitrarily complex world models. In our\nframework, stakeholders need only specify their preferences over system\noutcomes, providing straightforward and transparent decision rules for risk\ngovernance and mitigation. This framework naturally accounts for uncertainty in\nboth world model and preference model, allowing for decision-making that is\nepistemically and axiologically humble, parsimonious, and future-proof. We\ndemonstrate this novel approach in a simplified autonomous vehicle environment\nwith multi-agent vehicles whose driving policies are mediated by gatekeepers\nthat evaluate, in an online fashion, the risk to the collective safety in their\nneighborhood, and intervene through each vehicle's policy when appropriate. We\nshow that the introduction of gatekeepers in an AV fleet, even at low\npenetration, can generate significant positive externalities in terms of\nincreased system safety.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.MA",
      "physics.data-an",
      "stat.ML"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2502.04249v1",
    "published_date": "2025-02-06 17:38:45 UTC",
    "updated_date": "2025-02-06 17:38:45 UTC"
  },
  {
    "arxiv_id": "2502.04245v1",
    "title": "TriNER: A Series of Named Entity Recognition Models For Hindi, Bengali & Marathi",
    "authors": [
      "Mohammed Amaan Dhamaskar",
      "Rasika Ransing"
    ],
    "abstract": "India's rich cultural and linguistic diversity poses various challenges in\nthe domain of Natural Language Processing (NLP), particularly in Named Entity\nRecognition (NER). NER is a NLP task that aims to identify and classify tokens\ninto different entity groups like Person, Location, Organization, Number, etc.\nThis makes NER very useful for downstream tasks like context-aware\nanonymization. This paper details our work to build a multilingual NER model\nfor the three most spoken languages in India - Hindi, Bengali & Marathi. We\ntrain a custom transformer model and fine tune a few pretrained models,\nachieving an F1 Score of 92.11 for a total of 6 entity groups. Through this\npaper, we aim to introduce a single model to perform NER and significantly\nreduce the inconsistencies in entity groups and tag names, across the three\nlanguages.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04245v1",
    "published_date": "2025-02-06 17:37:36 UTC",
    "updated_date": "2025-02-06 17:37:36 UTC"
  },
  {
    "arxiv_id": "2502.04242v2",
    "title": "A Theoretical Framework for Data Efficient Multi-Source Transfer Learning Based on Cramér-Rao Bound",
    "authors": [
      "Qingyue Zhang",
      "Haohao Fu",
      "Guanbo Huang",
      "Yaoyuan Liang",
      "Chang Chu",
      "Tianren Peng",
      "Yanru Wu",
      "Qi Li",
      "Yang Li",
      "Shao-Lun Huang"
    ],
    "abstract": "Multi-source transfer learning provides an effective solution to data\nscarcity in real-world supervised learning scenarios by leveraging multiple\nsource tasks. In this field, existing works typically use all available samples\nfrom sources in training, which constrains their training efficiency and may\nlead to suboptimal results. To address this, we propose a theoretical framework\nthat answers the question: what is the optimal quantity of source samples\nneeded from each source task to jointly train the target model? Specifically,\nwe introduce a generalization error measure that aligns with cross-entropy\nloss, and minimize it based on the Cram\\'er-Rao Bound to determine the optimal\ntransfer quantity for each source task. Additionally, we develop an\narchitecture-agnostic and data-efficient algorithm OTQMS to implement our\ntheoretical results for training deep multi-source transfer learning models.\nExperimental studies on diverse architectures and two real-world benchmark\ndatasets show that our proposed algorithm significantly outperforms\nstate-of-the-art approaches in both accuracy and data efficiency. The code and\nsupplementary materials are available in\nhttps://anonymous.4open.science/r/Materials.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04242v2",
    "published_date": "2025-02-06 17:32:49 UTC",
    "updated_date": "2025-02-25 14:33:16 UTC"
  },
  {
    "arxiv_id": "2502.15737v1",
    "title": "A Performance Analysis of You Only Look Once Models for Deployment on Constrained Computational Edge Devices in Drone Applications",
    "authors": [
      "Lucas Rey",
      "Ana M. Bernardos",
      "Andrzej D. Dobrzycki",
      "David Carramiñana",
      "Luca Bergesio",
      "Juan A. Besada",
      "José Ramón Casar"
    ],
    "abstract": "Advancements in embedded systems and Artificial Intelligence (AI) have\nenhanced the capabilities of Unmanned Aircraft Vehicles (UAVs) in computer\nvision. However, the integration of AI techniques o-nboard drones is\nconstrained by their processing capabilities. In this sense, this study\nevaluates the deployment of object detection models (YOLOv8n and YOLOv8s) on\nboth resource-constrained edge devices and cloud environments. The objective is\nto carry out a comparative performance analysis using a representative\nreal-time UAV image processing pipeline. Specifically, the NVIDIA Jetson Orin\nNano, Orin NX, and Raspberry Pi 5 (RPI5) devices have been tested to measure\ntheir detection accuracy, inference speed, and energy consumption, and the\neffects of post-training quantization (PTQ). The results show that YOLOv8n\nsurpasses YOLOv8s in its inference speed, achieving 52 FPS on the Jetson Orin\nNX and 65 fps with INT8 quantization. Conversely, the RPI5 failed to satisfy\nthe real-time processing needs in spite of its suitability for low-energy\nconsumption applications. An analysis of both the cloud-based and edge-based\nend-to-end processing times showed that increased communication latencies\nhindered real-time applications, revealing trade-offs between edge (low\nlatency) and cloud processing (quick processing). Overall, these findings\ncontribute to providing recommendations and optimization strategies for the\ndeployment of AI models on UAVs.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.CV",
      "I.2.10; C.3; C.1.3"
    ],
    "primary_category": "cs.DC",
    "comment": "This manuscript consists of 24 pages, 7 figures, and 7 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.15737v1",
    "published_date": "2025-02-06 17:22:01 UTC",
    "updated_date": "2025-02-06 17:22:01 UTC"
  },
  {
    "arxiv_id": "2502.04423v1",
    "title": "Primary Care Diagnoses as a Reliable Predictor for Orthopedic Surgical Interventions",
    "authors": [
      "Khushboo Verma",
      "Alan Michels",
      "Ergi Gumusaneli",
      "Shilpa Chitnis",
      "Smita Sinha Kumar",
      "Christopher Thompson",
      "Lena Esmail",
      "Guruprasath Srinivasan",
      "Chandini Panchada",
      "Sushovan Guha",
      "Satwant Kumar"
    ],
    "abstract": "Referral workflow inefficiencies, including misaligned referrals and delays,\ncontribute to suboptimal patient outcomes and higher healthcare costs. In this\nstudy, we investigated the possibility of predicting procedural needs based on\nprimary care diagnostic entries, thereby improving referral accuracy,\nstreamlining workflows, and providing better care to patients. A de-identified\ndataset of 2,086 orthopedic referrals from the University of Texas Health at\nTyler was analyzed using machine learning models built on Base General\nEmbeddings (BGE) for semantic extraction. To ensure real-world applicability,\nnoise tolerance experiments were conducted, and oversampling techniques were\nemployed to mitigate class imbalance. The selected optimum and parsimonious\nembedding model demonstrated high predictive accuracy (ROC-AUC: 0.874, Matthews\nCorrelation Coefficient (MCC): 0.540), effectively distinguishing patients\nrequiring surgical intervention. Dimensionality reduction techniques confirmed\nthe model's ability to capture meaningful clinical relationships. A threshold\nsensitivity analysis identified an optimal decision threshold (0.30) to balance\nprecision and recall, maximizing referral efficiency. In the predictive\nmodeling analysis, the procedure rate increased from 11.27% to an optimal\n60.1%, representing a 433% improvement with significant implications for\noperational efficiency and healthcare revenue.\n  The results of our study demonstrate that referral optimization can enhance\nprimary and surgical care integration. Through this approach, precise and\ntimely predictions of procedural requirements can be made, thereby minimizing\ndelays, improving surgical planning, and reducing administrative burdens. In\naddition, the findings highlight the potential of clinical decision support as\na scalable solution for improving patient outcomes and the efficiency of the\nhealthcare system.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "I.2.6; I.2.7; J.3; H.2.8"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04423v1",
    "published_date": "2025-02-06 17:15:12 UTC",
    "updated_date": "2025-02-06 17:15:12 UTC"
  },
  {
    "arxiv_id": "2502.04230v2",
    "title": "XAttnMark: Learning Robust Audio Watermarking with Cross-Attention",
    "authors": [
      "Yixin Liu",
      "Lie Lu",
      "Jihui Jin",
      "Lichao Sun",
      "Andrea Fanelli"
    ],
    "abstract": "The rapid proliferation of generative audio synthesis and editing\ntechnologies has raised significant concerns about copyright infringement, data\nprovenance, and the spread of misinformation through deepfake audio.\nWatermarking offers a proactive solution by embedding imperceptible,\nidentifiable, and traceable marks into audio content. While recent neural\nnetwork-based watermarking methods like WavMark and AudioSeal have improved\nrobustness and quality, they struggle to achieve both robust detection and\naccurate attribution simultaneously. This paper introduces Cross-Attention\nRobust Audio Watermark (XAttnMark), which bridges this gap by leveraging\npartial parameter sharing between the generator and the detector, a\ncross-attention mechanism for efficient message retrieval, and a temporal\nconditioning module for improved message distribution. Additionally, we propose\na psychoacoustic-aligned temporal-frequency masking loss that captures\nfine-grained auditory masking effects, enhancing watermark imperceptibility.\nOur approach achieves state-of-the-art performance in both detection and\nattribution, demonstrating superior robustness against a wide range of audio\ntransformations, including challenging generative editing with strong editing\nstrength. The project webpage is available at\nhttps://liuyixin-louis.github.io/xattnmark/.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CR",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "24 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.04230v2",
    "published_date": "2025-02-06 17:15:08 UTC",
    "updated_date": "2025-02-07 20:11:12 UTC"
  },
  {
    "arxiv_id": "2502.04229v1",
    "title": "Dark Distillation: Backdooring Distilled Datasets without Accessing Raw Data",
    "authors": [
      "Ziyuan Yang",
      "Ming Yan",
      "Yi Zhang",
      "Joey Tianyi Zhou"
    ],
    "abstract": "Dataset distillation (DD) enhances training efficiency and reduces bandwidth\nby condensing large datasets into smaller synthetic ones. It enables models to\nachieve performance comparable to those trained on the raw full dataset and has\nbecome a widely adopted method for data sharing. However, security concerns in\nDD remain underexplored. Existing studies typically assume that malicious\nbehavior originates from dataset owners during the initial distillation\nprocess, where backdoors are injected into raw datasets. In contrast, this work\nis the first to address a more realistic and concerning threat: attackers may\nintercept the dataset distribution process, inject backdoors into the distilled\ndatasets, and redistribute them to users. While distilled datasets were\npreviously considered resistant to backdoor attacks, we demonstrate that they\nremain vulnerable to such attacks. Furthermore, we show that attackers do not\neven require access to any raw data to inject the backdoors successfully.\nSpecifically, our approach reconstructs conceptual archetypes for each class\nfrom the model trained on the distilled dataset. Backdoors are then injected\ninto these archetypes to update the distilled dataset. Moreover, we ensure the\nupdated dataset not only retains the backdoor but also preserves the original\noptimization trajectory, thus maintaining the knowledge of the raw dataset. To\nachieve this, a hybrid loss is designed to integrate backdoor information along\nthe benign optimization trajectory, ensuring that previously learned\ninformation is not forgotten. Extensive experiments demonstrate that distilled\ndatasets are highly vulnerable to backdoor attacks, with risks pervasive across\nvarious raw datasets, distillation methods, and downstream training strategies.\nMoreover, our attack method is efficient, capable of synthesizing a malicious\ndistilled dataset in under one minute in certain cases.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04229v1",
    "published_date": "2025-02-06 17:14:17 UTC",
    "updated_date": "2025-02-06 17:14:17 UTC"
  },
  {
    "arxiv_id": "2502.04219v1",
    "title": "NLP-Based .NET CLR Event Logs Analyzer",
    "authors": [
      "Maxim Stavtsev",
      "Sergey Shershakov"
    ],
    "abstract": "In this paper, we present a tool for analyzing .NET CLR event logs based on a\nnovel method inspired by Natural Language Processing (NLP) approach. Our\nresearch addresses the growing need for effective monitoring and optimization\nof software systems through detailed event log analysis. We utilize a\nBERT-based architecture with an enhanced tokenization process customized to\nevent logs. The tool, developed using Python, its libraries, and an SQLite\ndatabase, allows both conducting experiments for academic purposes and\nefficiently solving industry-emerging tasks. Our experiments demonstrate the\nefficacy of our approach in compressing event sequences, detecting recurring\npatterns, and identifying anomalies. The trained model shows promising results,\nwith a high accuracy rate in anomaly detection, which demonstrates the\npotential of NLP methods to improve the reliability and stability of software\nsystems.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04219v1",
    "published_date": "2025-02-06 17:01:38 UTC",
    "updated_date": "2025-02-06 17:01:38 UTC"
  },
  {
    "arxiv_id": "2502.04210v3",
    "title": "Algorithmic causal structure emerging through compression",
    "authors": [
      "Liang Wendong",
      "Simon Buchholz",
      "Bernhard Schölkopf"
    ],
    "abstract": "We explore the relationship between causality, symmetry, and compression. We\nbuild on and generalize the known connection between learning and compression\nto a setting where causal models are not identifiable. We propose a framework\nwhere causality emerges as a consequence of compressing data across multiple\nenvironments. We define algorithmic causality as an alternative definition of\ncausality when traditional assumptions for causal identifiability do not hold.\nWe demonstrate how algorithmic causal and symmetric structures can emerge from\nminimizing upper bounds on Kolmogorov complexity, without knowledge of\nintervention targets. We hypothesize that these insights may also provide a\nnovel perspective on the emergence of causality in machine learning models,\nsuch as large language models, where causal relationships may not be explicitly\nidentifiable.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CC",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.LG",
    "comment": "Extended version of the camera-ready paper accepted at CLeaR 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.04210v3",
    "published_date": "2025-02-06 16:50:57 UTC",
    "updated_date": "2025-03-21 14:54:04 UTC"
  },
  {
    "arxiv_id": "2502.04194v2",
    "title": "The Best Instruction-Tuning Data are Those That Fit",
    "authors": [
      "Dylan Zhang",
      "Qirun Dai",
      "Hao Peng"
    ],
    "abstract": "High-quality supervised fine-tuning (SFT) data are crucial for eliciting\nstrong capabilities from pretrained large language models (LLMs). Typically,\ninstructions are paired with multiple responses sampled from other LLMs, which\nare often out of the distribution of the target model to be fine-tuned. This,\nat scale, can lead to diminishing returns and even hurt the models' performance\nand robustness. We propose **GRAPE**, a novel SFT framework that accounts for\nthe unique characteristics of the target model. For each instruction, it\ngathers responses from various LLMs and selects the one with the highest\nprobability measured by the target model, indicating that it aligns most\nclosely with the target model's pretrained distribution; it then proceeds with\nstandard SFT training.\n  We first evaluate GRAPE with a controlled experiment, where we sample various\nsolutions for each question in UltraInteract from multiple models and fine-tune\ncommonly used LMs like LLaMA3.1-8B, Mistral-7B, and Qwen2.5-7B on\nGRAPE-selected data. GRAPE significantly outperforms strong baselines,\nincluding distilling from the strongest model with an absolute gain of up to\n13.8%, averaged across benchmarks, and training on 3x more data with a maximum\nperformance improvement of 17.3%. GRAPE's strong performance generalizes to\nrealistic settings. We experiment with the post-training data used for Tulu3\nand Olmo-2. GRAPE outperforms strong baselines trained on 4.5 times more data\nby 6.1% and a state-of-the-art data selection approach by 3% on average\nperformance. Remarkably, using 1/3 of the data and half the number of epochs,\nGRAPE enables LLaMA3.1-8B to surpass the performance of Tulu3-SFT by 3.5%.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04194v2",
    "published_date": "2025-02-06 16:31:21 UTC",
    "updated_date": "2025-02-07 02:20:28 UTC"
  },
  {
    "arxiv_id": "2502.04172v1",
    "title": "Archetypal Analysis for Binary Data",
    "authors": [
      "A. Emilie J. Wedenborg",
      "Morten Mørup"
    ],
    "abstract": "Archetypal analysis (AA) is a matrix decomposition method that identifies\ndistinct patterns using convex combinations of the data points denoted\narchetypes with each data point in turn reconstructed as convex combinations of\nthe archetypes. AA thereby forms a polytope representing trade-offs of the\ndistinct aspects in the data. Most existing methods for AA are designed for\ncontinuous data and do not exploit the structure of the data distribution. In\nthis paper, we propose two new optimization frameworks for archetypal analysis\nfor binary data. i) A second order approximation of the AA likelihood based on\nthe Bernoulli distribution with efficient closed-form updates using an active\nset procedure for learning the convex combinations defining the archetypes, and\na sequential minimal optimization strategy for learning the observation\nspecific reconstructions. ii) A Bernoulli likelihood based version of the\nprincipal convex hull analysis (PCHA) algorithm originally developed for least\nsquares optimization. We compare these approaches with the only existing binary\nAA procedure relying on multiplicative updates and demonstrate their\nsuperiority on both synthetic and real binary data. Notably, the proposed\noptimization frameworks for AA can easily be extended to other data\ndistributions providing generic efficient optimization frameworks for AA based\non tailored likelihood functions reflecting the underlying data distribution.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "5 pages, Accepted at ICASSP 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.04172v1",
    "published_date": "2025-02-06 16:05:15 UTC",
    "updated_date": "2025-02-06 16:05:15 UTC"
  },
  {
    "arxiv_id": "2502.04421v1",
    "title": "Assessing and Prioritizing Ransomware Risk Based on Historical Victim Data",
    "authors": [
      "Spencer Massengale",
      "Philip Huff"
    ],
    "abstract": "We present an approach to identifying which ransomware adversaries are most\nlikely to target specific entities, thereby assisting these entities in\nformulating better protection strategies. Ransomware poses a formidable\ncybersecurity threat characterized by profit-driven motives, a complex\nunderlying economy supporting criminal syndicates, and the overt nature of its\nattacks. This type of malware has consistently ranked among the most prevalent,\nwith a rapid escalation in activity observed. Recent estimates indicate that\napproximately two-thirds of organizations experienced ransomware attacks in\n2023 \\cite{Sophos2023Ransomware}. A central tactic in ransomware campaigns is\npublicizing attacks to coerce victims into paying ransoms. Our study utilizes\npublic disclosures from ransomware victims to predict the likelihood of an\nentity being targeted by a specific ransomware variant. We employ a Large\nLanguage Model (LLM) architecture that uses a unique chain-of-thought,\nmulti-shot prompt methodology to define adversary SKRAM (Skills, Knowledge,\nResources, Authorities, and Motivation) profiles from ransomware bulletins,\nthreat reports, and news items. This analysis is enriched with publicly\navailable victim data and is further enhanced by a heuristic for generating\nsynthetic data that reflects victim profiles. Our work culminates in the\ndevelopment of a machine learning model that assists organizations in\nprioritizing ransomware threats and formulating defenses based on the tactics,\ntechniques, and procedures (TTP) of the most likely attackers.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04421v1",
    "published_date": "2025-02-06 15:57:56 UTC",
    "updated_date": "2025-02-06 15:57:56 UTC"
  },
  {
    "arxiv_id": "2502.04153v1",
    "title": "UltraIF: Advancing Instruction Following from the Wild",
    "authors": [
      "Kaikai An",
      "Li Sheng",
      "Ganqu Cui",
      "Shuzheng Si",
      "Ning Ding",
      "Yu Cheng",
      "Baobao Chang"
    ],
    "abstract": "Instruction-following made modern large language models (LLMs) helpful\nassistants. However, the key to taming LLMs on complex instructions remains\nmysterious, for that there are huge gaps between models trained by open-source\ncommunity and those trained by leading companies. To bridge the gap, we propose\na simple and scalable approach UltraIF for building LLMs that can follow\ncomplex instructions with open-source data. UltraIF first decomposes real-world\nuser prompts into simpler queries, constraints, and corresponding evaluation\nquestions for the constraints. Then, we train an UltraComposer to compose\nconstraint-associated prompts with evaluation questions. This prompt composer\nallows us to synthesize complicated instructions as well as filter responses\nwith evaluation questions. In our experiment, for the first time, we\nsuccessfully align LLaMA-3.1-8B-Base to catch up with its instruct version on 5\ninstruction-following benchmarks without any benchmark information, using only\n8B model as response generator and evaluator. The aligned model also achieved\ncompetitive scores on other benchmarks. Moreover, we also show that UltraIF\ncould further improve LLaMA-3.1-8B-Instruct through self-alignment, motivating\nbroader use cases for the method. Our code will be available at\nhttps://github.com/kkk-an/UltraIF.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04153v1",
    "published_date": "2025-02-06 15:39:16 UTC",
    "updated_date": "2025-02-06 15:39:16 UTC"
  },
  {
    "arxiv_id": "2502.04420v3",
    "title": "KVTuner: Sensitivity-Aware Layer-wise Mixed Precision KV Cache Quantization for Efficient and Nearly Lossless LLM Inference",
    "authors": [
      "Xing Li",
      "Zeyu Xing",
      "Yiming Li",
      "Linping Qu",
      "Hui-Ling Zhen",
      "Wulong Liu",
      "Yiwu Yao",
      "Sinno Jialin Pan",
      "Mingxuan Yuan"
    ],
    "abstract": "KV cache quantization can improve Large Language Models (LLMs) inference\nthroughput and latency in long contexts and large batch-size scenarios while\npreserving LLMs effectiveness. However, current methods have three unsolved\nissues: overlooking layer-wise sensitivity to KV cache quantization, high\noverhead of online fine-grained decision-making, and low flexibility to\ndifferent LLMs and constraints. Therefore, we thoroughly analyze the inherent\ncorrelation of layer-wise transformer attention patterns to KV cache\nquantization errors and study why key cache is more important than value cache\nfor quantization error reduction. We further propose a simple yet effective\nframework KVTuner to adaptively search for the optimal hardware-friendly\nlayer-wise KV quantization precision pairs for coarse-grained KV cache with\nmulti-objective optimization and directly utilize the offline searched\nconfigurations during online inference. To reduce the computational cost of\noffline calibration, we utilize the intra-layer KV precision pair pruning and\ninter-layer clustering to reduce the search space. Experimental results show\nthat we can achieve nearly lossless 3.25-bit mixed precision KV cache\nquantization for LLMs like Llama-3.1-8B-Instruct and 4.0-bit for sensitive\nmodels like Qwen2.5-7B-Instruct on mathematical reasoning tasks. The maximum\ninference throughput can be improved by 38.3% compared with KV8 quantization\nover various context lengths. Our code and searched configurations are\navailable at https://github.com/cmd2001/KVTuner.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "36 pages. Code: https://github.com/cmd2001/KVTuner",
    "pdf_url": "http://arxiv.org/pdf/2502.04420v3",
    "published_date": "2025-02-06 15:26:26 UTC",
    "updated_date": "2025-02-25 03:42:15 UTC"
  },
  {
    "arxiv_id": "2502.04419v2",
    "title": "Understanding and Mitigating the Bias Inheritance in LLM-based Data Augmentation on Downstream Tasks",
    "authors": [
      "Miaomiao Li",
      "Hao Chen",
      "Yang Wang",
      "Tingyuan Zhu",
      "Weijia Zhang",
      "Kaijie Zhu",
      "Kam-Fai Wong",
      "Jindong Wang"
    ],
    "abstract": "Generating synthetic datasets via large language models (LLMs) themselves has\nemerged as a promising approach to improve LLM performance. However, LLMs\ninherently reflect biases present in their training data, leading to a critical\nchallenge: when these models generate synthetic data for training, they may\npropagate and amplify their inherent biases that can significantly impact model\nfairness and robustness on downstream tasks--a phenomenon we term bias\ninheritance. This work presents the first systematic investigation in\nunderstanding, analyzing, and mitigating bias inheritance. We study this\nproblem by fine-tuning LLMs with a combined dataset consisting of original and\nLLM-augmented data, where bias ratio represents the proportion of augmented\ndata. Through systematic experiments across 10 classification and generation\ntasks, we analyze how 6 different types of biases manifest at varying bias\nratios. Our results reveal that bias inheritance has nuanced effects on\ndownstream tasks, influencing both classification tasks and generation tasks\ndifferently. Then, our analysis identifies three key misalignment factors:\nmisalignment of values, group data, and data distributions. Based on these\ninsights, we propose three mitigation strategies: token-based, mask-based, and\nloss-based approaches. Experiments demonstrate that these strategies also work\ndifferently on various tasks and bias, indicating the substantial challenges to\nfully mitigate bias inheritance. We hope this work can provide valuable\ninsights to the research of LLM data augmentation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Technical report; 31 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.04419v2",
    "published_date": "2025-02-06 15:20:58 UTC",
    "updated_date": "2025-02-10 16:34:03 UTC"
  },
  {
    "arxiv_id": "2502.04140v1",
    "title": "Synthetic Datasets for Machine Learning on Spatio-Temporal Graphs using PDEs",
    "authors": [
      "Jost Arndt",
      "Utku Isil",
      "Michael Detzel",
      "Wojciech Samek",
      "Jackie Ma"
    ],
    "abstract": "Many physical processes can be expressed through partial differential\nequations (PDEs). Real-world measurements of such processes are often collected\nat irregularly distributed points in space, which can be effectively\nrepresented as graphs; however, there are currently only a few existing\ndatasets. Our work aims to make advancements in the field of PDE-modeling\naccessible to the temporal graph machine learning community, while addressing\nthe data scarcity problem, by creating and utilizing datasets based on PDEs. In\nthis work, we create and use synthetic datasets based on PDEs to support\nspatio-temporal graph modeling in machine learning for different applications.\nMore precisely, we showcase three equations to model different types of\ndisasters and hazards in the fields of epidemiology, atmospheric particles, and\ntsunami waves. Further, we show how such created datasets can be used by\nbenchmarking several machine learning models on the epidemiological dataset.\nAdditionally, we show how pre-training on this dataset can improve model\nperformance on real-world epidemiological data. The presented methods enable\nothers to create datasets and benchmarks customized to individual requirements.\nThe source code for our methodology and the three created datasets can be found\non https://github.com/github-usr-ano/Temporal_Graph_Data_PDEs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Currently under review",
    "pdf_url": "http://arxiv.org/pdf/2502.04140v1",
    "published_date": "2025-02-06 15:20:32 UTC",
    "updated_date": "2025-02-06 15:20:32 UTC"
  },
  {
    "arxiv_id": "2502.04128v2",
    "title": "Llasa: Scaling Train-Time and Inference-Time Compute for Llama-based Speech Synthesis",
    "authors": [
      "Zhen Ye",
      "Xinfa Zhu",
      "Chi-Min Chan",
      "Xinsheng Wang",
      "Xu Tan",
      "Jiahe Lei",
      "Yi Peng",
      "Haohe Liu",
      "Yizhu Jin",
      "Zheqi Dai",
      "Hongzhan Lin",
      "Jianyi Chen",
      "Xingjian Du",
      "Liumeng Xue",
      "Yunlin Chen",
      "Zhifei Li",
      "Lei Xie",
      "Qiuqiang Kong",
      "Yike Guo",
      "Wei Xue"
    ],
    "abstract": "Recent advances in text-based large language models (LLMs), particularly in\nthe GPT series and the o1 model, have demonstrated the effectiveness of scaling\nboth training-time and inference-time compute. However, current\nstate-of-the-art TTS systems leveraging LLMs are often multi-stage, requiring\nseparate models (e.g., diffusion models after LLM), complicating the decision\nof whether to scale a particular model during training or testing. This work\nmakes the following contributions: First, we explore the scaling of train-time\nand inference-time compute for speech synthesis. Second, we propose a simple\nframework Llasa for speech synthesis that employs a single-layer vector\nquantizer (VQ) codec and a single Transformer architecture to fully align with\nstandard LLMs such as Llama. Our experiments reveal that scaling train-time\ncompute for Llasa consistently improves the naturalness of synthesized speech\nand enables the generation of more complex and accurate prosody patterns.\nFurthermore, from the perspective of scaling inference-time compute, we employ\nspeech understanding models as verifiers during the search, finding that\nscaling inference-time compute shifts the sampling modes toward the preferences\nof specific verifiers, thereby improving emotional expressiveness, timbre\nconsistency, and content accuracy. In addition, we released the checkpoint and\ntraining code for our TTS model (1B, 3B, 8B) and codec model publicly\navailable.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL",
      "cs.MM",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04128v2",
    "published_date": "2025-02-06 15:04:00 UTC",
    "updated_date": "2025-02-22 11:32:13 UTC"
  },
  {
    "arxiv_id": "2502.04418v1",
    "title": "Autotelic Reinforcement Learning: Exploring Intrinsic Motivations for Skill Acquisition in Open-Ended Environments",
    "authors": [
      "Prakhar Srivastava",
      "Jasmeet Singh"
    ],
    "abstract": "This paper presents a comprehensive overview of autotelic Reinforcement\nLearning (RL), emphasizing the role of intrinsic motivations in the open-ended\nformation of skill repertoires. We delineate the distinctions between\nknowledge-based and competence-based intrinsic motivations, illustrating how\nthese concepts inform the development of autonomous agents capable of\ngenerating and pursuing self-defined goals. The typology of Intrinsically\nMotivated Goal Exploration Processes (IMGEPs) is explored, with a focus on the\nimplications for multi-goal RL and developmental robotics. The autotelic\nlearning problem is framed within a reward-free Markov Decision Process (MDP),\nWHERE agents must autonomously represent, generate, and master their own goals.\nWe address the unique challenges in evaluating such agents, proposing various\nmetrics for measuring exploration, generalization, and robustness in complex\nenvironments. This work aims to advance the understanding of autotelic RL\nagents and their potential for enhancing skill acquisition in a diverse and\ndynamic setting.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.04418v1",
    "published_date": "2025-02-06 14:37:46 UTC",
    "updated_date": "2025-02-06 14:37:46 UTC"
  },
  {
    "arxiv_id": "2502.04110v1",
    "title": "Ancient Greek Technology: An Immersive Learning Use Case Described Using a Co-Intelligent Custom ChatGPT Assistant",
    "authors": [
      "Vlasis Kasapakis",
      "Leonel Morgado"
    ],
    "abstract": "Achieving consistency in immersive learning case descriptions is essential\nbut challenging due to variations in research focus, methodology, and\nresearchers' background. We address these challenges by leveraging the\nImmersive Learning Case Sheet (ILCS), a methodological instrument to\nstandardize case descriptions, that we applied to an immersive learning case on\nancient Greek technology in VRChat. Research team members had differing levels\nof familiarity with the ILCS and the case content, so we developed a custom\nChatGPT assistant to facilitate consistent terminology and process alignment\nacross the team. This paper constitutes an example of how structured case\nreports can be a novel contribution to immersive learning literature. Our\nfindings demonstrate how the ILCS supports structured reflection and\ninterpretation of the case. Further we report that the use of a ChatGPT\nassistant significantly sup-ports the coherence and quality of the team members\ndevelopment of the final ILCS. This exposes the potential of employing\nAI-driven tools to enhance collaboration and standardization of research\npractices in qualitative educational research. However, we also discuss the\nlimitations and challenges, including reliance on AI for interpretive tasks and\nmanaging varied levels of expertise within the team. This study thus provides\ninsights into the practical application of AI in standardizing immersive\nlearning research processes.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "H.5.1; I.2.1"
    ],
    "primary_category": "cs.HC",
    "comment": "5 pages, presented at the 2024 IEEE 3rd International Conference on\n  Intelligent Reality (ICIR 2024), 6th of December, 2024",
    "pdf_url": "http://arxiv.org/pdf/2502.04110v1",
    "published_date": "2025-02-06 14:35:42 UTC",
    "updated_date": "2025-02-06 14:35:42 UTC"
  },
  {
    "arxiv_id": "2502.04103v2",
    "title": "VTutor: An Open-Source SDK for Generative AI-Powered Animated Pedagogical Agents with Multi-Media Output",
    "authors": [
      "Eason Chen",
      "Chenyu Lin",
      "Xinyi Tang",
      "Aprille Xi",
      "Canwen Wang",
      "Jionghao Lin",
      "Kenneth R Koedinger"
    ],
    "abstract": "The rapid evolution of large language models (LLMs) has transformed\nhuman-computer interaction (HCI), but the interaction with LLMs is currently\nmainly focused on text-based interactions, while other multi-model approaches\nremain under-explored. This paper introduces VTutor, an open-source Software\nDevelopment Kit (SDK) that combines generative AI with advanced animation\ntechnologies to create engaging, adaptable, and realistic APAs for human-AI\nmulti-media interactions. VTutor leverages LLMs for real-time personalized\nfeedback, advanced lip synchronization for natural speech alignment, and WebGL\nrendering for seamless web integration. Supporting various 2D and 3D character\nmodels, VTutor enables researchers and developers to design emotionally\nresonant, contextually adaptive learning agents. This toolkit enhances learner\nengagement, feedback receptivity, and human-AI interaction while promoting\ntrustworthy AI principles in education. VTutor sets a new standard for\nnext-generation APAs, offering an accessible, scalable solution for fostering\nmeaningful and immersive human-AI interaction experiences. The VTutor project\nis open-sourced and welcomes community-driven contributions and showcases.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04103v2",
    "published_date": "2025-02-06 14:27:54 UTC",
    "updated_date": "2025-02-13 17:57:44 UTC"
  },
  {
    "arxiv_id": "2502.04417v1",
    "title": "NeuralMOVES: A lightweight and microscopic vehicle emission estimation model based on reverse engineering and surrogate learning",
    "authors": [
      "Edgar Ramirez-Sanchez",
      "Catherine Tang",
      "Yaosheng Xu",
      "Nrithya Renganathan",
      "Vindula Jayawardana",
      "Zhengbing He",
      "Cathy Wu"
    ],
    "abstract": "The transportation sector significantly contributes to greenhouse gas\nemissions, necessitating accurate emission models to guide mitigation\nstrategies. Despite its field validation and certification, the\nindustry-standard Motor Vehicle Emission Simulator (MOVES) faces challenges\nrelated to complexity in usage, high computational demands, and its\nunsuitability for microscopic real-time applications. To address these\nlimitations, we present NeuralMOVES, a comprehensive suite of high-performance,\nlightweight surrogate models for vehicle CO2 emissions. Developed based on\nreverse engineering and Neural Networks, NeuralMOVES achieves a remarkable\n6.013% Mean Average Percentage Error relative to MOVES across extensive tests\nspanning over two million scenarios with diverse trajectories and the factors\nregarding environments and vehicles. NeuralMOVES is only 2.4 MB, largely\ncondensing the original MOVES and the reverse engineered MOVES into a compact\nrepresentation, while maintaining high accuracy. Therefore, NeuralMOVES\nsignificantly enhances accessibility while maintaining the accuracy of MOVES,\nsimplifying CO2 evaluation for transportation analyses and enabling real-time,\nmicroscopic applications across diverse scenarios without reliance on complex\nsoftware or extensive computational resources. Moreover, this paper provides,\nfor the first time, a framework for reverse engineering industrial-grade\nsoftware tailored specifically to transportation scenarios, going beyond MOVES.\nThe surrogate models are available at https://github.com/edgar-rs/neuralMOVES.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04417v1",
    "published_date": "2025-02-06 14:26:26 UTC",
    "updated_date": "2025-02-06 14:26:26 UTC"
  },
  {
    "arxiv_id": "2502.04098v2",
    "title": "Efficient Few-Shot Continual Learning in Vision-Language Models",
    "authors": [
      "Aristeidis Panos",
      "Rahaf Aljundi",
      "Daniel Olmeda Reino",
      "Richard E. Turner"
    ],
    "abstract": "Vision-language models (VLMs) excel in tasks such as visual question\nanswering and image captioning. However, VLMs are often limited by their use of\npretrained image encoders, like CLIP, leading to image understanding errors\nthat hinder overall performance. On top of that, real-world applications often\nrequire the model to be continuously adapted as new and often limited data\ncontinuously arrive. To address this, we propose LoRSU (Low-Rank Adaptation\nwith Structured Updates), a robust and computationally efficient method for\nselectively updating image encoders within VLMs. LoRSU introduces structured\nand localized parameter updates, effectively correcting performance on\npreviously error-prone data while preserving the model's general robustness.\nOur approach leverages theoretical insights to identify and update only the\nmost critical parameters, achieving significant resource efficiency.\nSpecifically, we demonstrate that LoRSU reduces computational overhead by over\n25x compared to full VLM updates, without sacrificing performance. Experimental\nresults on VQA tasks in the few-shot continual learning setting, validate\nLoRSU's scalability, efficiency, and effectiveness, making it a compelling\nsolution for image encoder adaptation in resource-constrained environments.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04098v2",
    "published_date": "2025-02-06 14:20:55 UTC",
    "updated_date": "2025-02-07 13:35:01 UTC"
  },
  {
    "arxiv_id": "2502.04095v1",
    "title": "LLMs to Support a Domain Specific Knowledge Assistant",
    "authors": [
      "Maria-Flavia Lovin"
    ],
    "abstract": "This work presents a custom approach to developing a domain specific\nknowledge assistant for sustainability reporting using the International\nFinancial Reporting Standards (IFRS). In this domain, there is no publicly\navailable question-answer dataset, which has impeded the development of a\nhigh-quality chatbot to support companies with IFRS reporting. The two key\ncontributions of this project therefore are:\n  (1) A high-quality synthetic question-answer (QA) dataset based on IFRS\nsustainability standards, created using a novel generation and evaluation\npipeline leveraging Large Language Models (LLMs). This comprises 1,063 diverse\nQA pairs that address a wide spectrum of potential user queries in\nsustainability reporting. Various LLM-based techniques are employed to create\nthe dataset, including chain-of-thought reasoning and few-shot prompting. A\ncustom evaluation framework is developed to assess question and answer quality\nacross multiple dimensions, including faithfulness, relevance, and domain\nspecificity. The dataset averages a score range of 8.16 out of 10 on these\nmetrics.\n  (2) Two architectures for question-answering in the sustainability reporting\ndomain - a RAG pipeline and a fully LLM-based pipeline. The architectures are\ndeveloped by experimenting, fine-tuning, and training on the QA dataset. The\nfinal pipelines feature an LLM fine-tuned on domain specific data and an\nindustry classification component to improve the handling of complex queries.\nThe RAG architecture achieves an accuracy of 85.32% on single-industry and\n72.15% on cross-industry multiple-choice questions, outperforming the baseline\napproach by 4.67 and 19.21 percentage points, respectively. The LLM-based\npipeline achieves an accuracy of 93.45% on single-industry and 80.30% on\ncross-industry multiple-choice questions, an improvement of 12.80 and 27.36\npercentage points over the baseline, respectively.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04095v1",
    "published_date": "2025-02-06 14:12:41 UTC",
    "updated_date": "2025-02-06 14:12:41 UTC"
  },
  {
    "arxiv_id": "2502.04416v1",
    "title": "CMoE: Fast Carving of Mixture-of-Experts for Efficient LLM Inference",
    "authors": [
      "Zehua Pei",
      "Lancheng Zou",
      "Hui-Ling Zhen",
      "Xianzhi Yu",
      "Wulong Liu",
      "Sinno Jialin Pan",
      "Mingxuan Yuan",
      "Bei Yu"
    ],
    "abstract": "Large language models (LLMs) achieve impressive performance by scaling model\nparameters, but this comes with significant inference overhead. Feed-forward\nnetworks (FFNs), which dominate LLM parameters, exhibit high activation\nsparsity in hidden neurons. To exploit this, researchers have proposed using a\nmixture-of-experts (MoE) architecture, where only a subset of parameters is\nactivated. However, existing approaches often require extensive training data\nand resources, limiting their practicality. We propose CMoE (Carved MoE), a\nnovel framework to efficiently carve MoE models from dense models. CMoE\nachieves remarkable performance through efficient expert grouping and\nlightweight adaptation. First, neurons are grouped into shared and routed\nexperts based on activation rates. Next, we construct a routing mechanism\nwithout training from scratch, incorporating a differentiable routing process\nand load balancing. Using modest data, CMoE produces a well-designed, usable\nMoE from a 7B dense model within five minutes. With lightweight fine-tuning, it\nachieves high-performance recovery in under an hour. We make our code publicly\navailable at https://github.com/JarvisPei/CMoE.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04416v1",
    "published_date": "2025-02-06 14:05:30 UTC",
    "updated_date": "2025-02-06 14:05:30 UTC"
  },
  {
    "arxiv_id": "2502.04083v1",
    "title": "Automatic quantification of breast cancer biomarkers from multiple 18F-FDG PET image segmentation",
    "authors": [
      "Tewele W. Tareke",
      "Neree Payan",
      "Alexandre Cochet",
      "Laurent Arnould",
      "Benoit Presles",
      "Jean-Marc Vrigneaud",
      "Fabrice Meriaudeau",
      "Alain Lalande"
    ],
    "abstract": "Neoadjuvant chemotherapy (NAC) has become a standard clinical practice for\ntumor downsizing in breast cancer with 18F-FDG Positron Emission Tomography\n(PET). Our work aims to leverage PET imaging for the segmentation of breast\nlesions. The focus is on developing an automated system that accurately\nsegments primary tumor regions and extracts key biomarkers from these areas to\nprovide insights into the evolution of breast cancer following the first course\nof NAC. 243 baseline 18F-FDG PET scans (PET_Bl) and 180 follow-up 18F-FDG PET\nscans (PET_Fu) were acquired before and after the first course of NAC,\nrespectively. Firstly, a deep learning-based breast tumor segmentation method\nwas developed. The optimal baseline model (model trained on baseline exams) was\nfine-tuned on 15 follow-up exams and adapted using active learning to segment\ntumor areas in PET_Fu. The pipeline computes biomarkers such as maximum\nstandardized uptake value (SUVmax), metabolic tumor volume (MTV), and total\nlesion glycolysis (TLG) to evaluate tumor evolution between PET_Fu and PET_Bl.\nQuality control measures were employed to exclude aberrant outliers. The nnUNet\ndeep learning model outperformed in tumor segmentation on PET_Bl, achieved a\nDice similarity coefficient (DSC) of 0.89 and a Hausdorff distance (HD) of 3.52\nmm. After fine-tuning, the model demonstrated a DSC of 0.78 and a HD of 4.95 mm\non PET_Fu exams. Biomarkers analysis revealed very strong correlations whatever\nthe biomarker between manually segmented and automatically predicted regions.\nThe significant average decrease of SUVmax, MTV and TLG were 5.22, 11.79 cm3\nand 19.23 cm3, respectively. The presented approach demonstrates an automated\nsystem for breast tumor segmentation from 18F-FDG PET. Thanks to the extracted\nbiomarkers, our method enables the automatic assessment of cancer progression.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Submit soon to EJNMMI Research",
    "pdf_url": "http://arxiv.org/pdf/2502.04083v1",
    "published_date": "2025-02-06 13:51:28 UTC",
    "updated_date": "2025-02-06 13:51:28 UTC"
  },
  {
    "arxiv_id": "2502.04415v1",
    "title": "TerraQ: Spatiotemporal Question-Answering on Satellite Image Archives",
    "authors": [
      "Sergios-Anestis Kefalidis",
      "Konstantinos Plas",
      "Manolis Koubarakis"
    ],
    "abstract": "TerraQ is a spatiotemporal question-answering engine for satellite image\narchives. It is a natural language processing system that is built to process\nrequests for satellite images satisfying certain criteria. The requests can\nrefer to image metadata and entities from a specialized knowledge base (e.g.,\nthe Emilia-Romagna region). With it, users can make requests like \"Give me a\nhundred images of rivers near ports in France, with less than 20% snow coverage\nand more than 10% cloud coverage\", thus making Earth Observation data more\neasily accessible, in-line with the current landscape of digital assistants.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04415v1",
    "published_date": "2025-02-06 13:43:17 UTC",
    "updated_date": "2025-02-06 13:43:17 UTC"
  },
  {
    "arxiv_id": "2502.04066v2",
    "title": "SMI: An Information-Theoretic Metric for Predicting Model Knowledge Solely from Pre-Training Signals",
    "authors": [
      "Changhao Jiang",
      "Ming Zhang",
      "Junjie Ye",
      "Xiaoran Fan",
      "Yifei Cao",
      "Jiajun Sun",
      "Zhiheng Xi",
      "Shihan Dou",
      "Yi Dong",
      "Yujiong Shen",
      "Jingqi Tong",
      "Zhen Wang",
      "Tao Liang",
      "Zhihui Fei",
      "Mingyang Wan",
      "Guojun Ma",
      "Qi Zhang",
      "Tao Gui",
      "Xuanjing Huang"
    ],
    "abstract": "The GPT-4 technical report highlights the possibility of predicting model\nperformance on downstream tasks using only pre-training signals, though\ndetailed methodologies are absent. Such predictive capabilities are essential\nfor resource-efficient pre-training and the construction of task-aligned\ndatasets. In this paper, we aim to predict performance in closed-book question\nanswering (QA), a vital downstream task indicative of a model's internal\nknowledge. We address three primary challenges: (1) limited access to and\nunderstanding of pre-training corpora, (2) limitations of current evaluation\nmethods for pre-trained models, and (3) limitations of frequency-based metrics\nin predicting model performance. In response to these challenges, we conduct\nlarge-scale retrieval and semantic analysis across the pre-training corpora of\n21 publicly available and 3 custom-trained large language models. Subsequently,\nwe develop a multi-template QA evaluation framework incorporating paraphrased\nquestion variants. Building on these foundations, we propose Size-dependent\nMutual Information (SMI), an information-theoretic metric that linearly\ncorrelates pre-training data characteristics, model size, and QA accuracy,\nwithout requiring any additional training. The experimental results demonstrate\nthat SMI outperforms co-occurrence-based baselines, achieving $R^2$ > 0.75 on\nmodels with over one billion parameters. Theoretical analysis further reveals\nthe marginal benefits of scaling model size and optimizing data, indicating\nthat the upper limit of specific QA task accuracy is approximately 80%. Our\nproject is available at https://github.com/yuhui1038/SMI.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04066v2",
    "published_date": "2025-02-06 13:23:53 UTC",
    "updated_date": "2025-05-13 14:19:37 UTC"
  },
  {
    "arxiv_id": "2502.04058v1",
    "title": "Strategic Learning with Local Explanations as Feedback",
    "authors": [
      "Kiet Q. H. Vo",
      "Siu Lun Chau",
      "Masahiro Kato",
      "Yixin Wang",
      "Krikamol Muandet"
    ],
    "abstract": "We investigate algorithmic decision problems where agents can respond\nstrategically to the decision maker's (DM) models. The demand for clear and\nactionable explanations from DMs to (potentially strategic) agents continues to\nrise. While prior work often treats explanations as full model disclosures,\nexplanations in practice might convey only partial information, which can lead\nto misinterpretations and harmful responses. When full disclosure of the\npredictive model is neither feasible nor desirable, a key open question is how\nDMs can use explanations to maximise their utility without compromising agent\nwelfare. In this work, we explore well-known local and global explanation\nmethods, and establish a necessary condition to prevent explanations from\nmisleading agents into self-harming actions. Moreover, with conditional\nhomogeneity, we establish that action recommendation (AR)-based explanations\nare sufficient for non-harmful responses, akin to the revelation principle in\ninformation design. To operationalise AR-based explanations, we propose a\nsimple algorithm to jointly optimise the predictive model and AR policy to\nbalance DM outcomes with agent welfare. Our empirical results demonstrate the\nbenefits of this approach as a more refined strategy for safe and effective\npartial model disclosure in algorithmic decision-making.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04058v1",
    "published_date": "2025-02-06 13:17:24 UTC",
    "updated_date": "2025-02-06 13:17:24 UTC"
  },
  {
    "arxiv_id": "2502.04043v1",
    "title": "Probe-Free Low-Rank Activation Intervention",
    "authors": [
      "Chonghe Jiang",
      "Bao Nguyen",
      "Anthony Man-Cho So",
      "Viet Anh Nguyen"
    ],
    "abstract": "Language models (LMs) can produce texts that appear accurate and coherent but\ncontain untruthful or toxic content. Inference-time interventions that edit the\nhidden activations have shown promising results in steering the LMs towards\ndesirable generations. Existing activation intervention methods often comprise\nan activation probe to detect undesirable generation, triggering the activation\nmodification to steer subsequent generation. This paper proposes a probe-free\nintervention method FLORAIN for all attention heads in a specific activation\nlayer. It eliminates the need to train classifiers for probing purposes. The\nintervention function is parametrized by a sample-wise nonlinear low-rank\nmapping, which is trained by minimizing the distance between the modified\nactivations and their projection onto the manifold of desirable content. Under\nspecific constructions of the manifold and projection distance, we show that\nthe intervention strategy can be computed efficiently by solving a smooth\noptimization problem. The empirical results, benchmarked on multiple base\nmodels, demonstrate that FLORAIN consistently outperforms several baseline\nmethods in enhancing model truthfulness and quality across generation and\nmultiple-choice tasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by NAACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.04043v1",
    "published_date": "2025-02-06 13:03:05 UTC",
    "updated_date": "2025-02-06 13:03:05 UTC"
  },
  {
    "arxiv_id": "2502.04040v1",
    "title": "Leveraging Reasoning with Guidelines to Elicit and Utilize Knowledge for Enhancing Safety Alignment",
    "authors": [
      "Haoyu Wang",
      "Zeyu Qin",
      "Li Shen",
      "Xueqian Wang",
      "Minhao Cheng",
      "Dacheng Tao"
    ],
    "abstract": "Training safe LLMs is one of the most critical research challenge. However,\nthe commonly used method, Refusal Training (RT), struggles to generalize\nagainst various OOD jailbreaking attacks. Many safety training methods have\nbeen proposed to address this issue. While they offer valuable insights, we aim\nto complement this line of research by investigating whether OOD attacks truly\nexceed the capability of RT model. Conducting evaluation with BoN, we observe\nsignificant improvements on generalization as N increases. This underscores\nthat the model possesses sufficient safety-related latent knowledge, but RT\nfails to consistently elicit this knowledge when addressing OOD attacks.\nFurther analysis based on domain adaptation reveals that training with direct\nrefusal causes model to rely on superficial shortcuts, resulting in learning of\nnon-robust representation mappings. Based on our findings, we propose training\nmodel to perform safety reasoning for each query. Reasoning supervision\nencourages model to perform more computations, explicitly eliciting and using\nlatent knowledge through reasoning. To achieve this, we synthesize reasoning\nsupervision based on pre-guidelines, training the model to reason in alignment\nwith them, thereby effectively eliciting and utilizing latent knowledge from\ndiverse perspectives. Extensive experiments show that our method significantly\nimproves generalization performance against OOD attacks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "The first two authors contributed equally",
    "pdf_url": "http://arxiv.org/pdf/2502.04040v1",
    "published_date": "2025-02-06 13:01:44 UTC",
    "updated_date": "2025-02-06 13:01:44 UTC"
  },
  {
    "arxiv_id": "2502.04034v1",
    "title": "Generalize Drug Response Prediction by Latent Independent Projection for Asymmetric Constrained Domain Generalization",
    "authors": [
      "Ran Song",
      "Yinpu Bai",
      "Hui Liu"
    ],
    "abstract": "The accurate prediction of drug responses remains a formidable challenge,\nparticularly at the single-cell level and in clinical treatment contexts. Some\nstudies employ transfer learning techniques to predict drug responses in\nindividual cells and patients, but they require access to target-domain data\nduring training, which is often unavailable or only obtainable in future. In\nthis study, we propose a novel domain generalization framework, termed\npanCancerDR, to address this challenge. We conceptualize each cancer type as a\ndistinct source domain, with its cell lines serving as domain-specific samples.\nOur primary objective is to extract domain-invariant features from the\nexpression profiles of cell lines across diverse cancer types, thereby\ngeneralize the predictive capacity to out-of-distribution samples. To enhance\nrobustness, we introduce a latent independence projection (LIP) module that\nencourages the encoder to extract informative yet non-redundant features. Also,\nwe propose an asymmetric adaptive clustering constraint, which clusters\ndrug-sensitive samples into a compact group while drives resistant samples\ndispersed across separate clusters in the latent space. Our empirical\nexperiments demonstrate that panCancerDR effectively learns task-relevant\nfeatures from diverse source domains, and achieves accurate predictions of drug\nresponse for unseen cancer type during training. Furthermore, when evaluated on\nsingle-cell and patient-level prediction tasks, our model-trained solely on in\nvitro cell line data without access to target-domain information-consistently\noutperforms and matched current state-of-the-art methods. These findings\nhighlights the potential of our method for real-world clinical applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04034v1",
    "published_date": "2025-02-06 12:53:45 UTC",
    "updated_date": "2025-02-06 12:53:45 UTC"
  },
  {
    "arxiv_id": "2502.04030v1",
    "title": "Fine, I'll Merge It Myself: A Multi-Fidelity Framework for Automated Model Merging",
    "authors": [
      "Guinan Su",
      "Jonas Geiping"
    ],
    "abstract": "Reasoning capabilities represent a critical frontier for large language\nmodels (LLMs), but developing them requires extensive proprietary datasets and\ncomputational resources. One way to efficiently supplement capabilities with is\nby model merging, which offers a promising alternative by combining multiple\nmodels without retraining. However, current merging approaches rely on\nmanually-designed strategies for merging hyperparameters, limiting the\nexploration of potential model combinations and requiring significant human\neffort. We propose an Automated Model Merging Framework that enables\nfine-grained exploration of merging strategies while reducing costs through\nmulti-fidelity approximations. We support both single and multi-objective\noptimization and introduce two novel search spaces: layerwise fusion (LFS) and\ndepth-wise integration (DIS). Evaluating across a number of benchmarks, we find\nthat the search autonomously finds 1) Merges that further boost\nsingle-objective performance, even on tasks the model has already been\nfinetuned on, and 2) Merges that optimize multi-objective frontiers across\ntasks. Effective merges are found with limited compute, e.g. within less than\n500 search steps.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04030v1",
    "published_date": "2025-02-06 12:47:25 UTC",
    "updated_date": "2025-02-06 12:47:25 UTC"
  },
  {
    "arxiv_id": "2502.04413v1",
    "title": "MedRAG: Enhancing Retrieval-augmented Generation with Knowledge Graph-Elicited Reasoning for Healthcare Copilot",
    "authors": [
      "Xuejiao Zhao",
      "Siyan Liu",
      "Su-Yin Yang",
      "Chunyan Miao"
    ],
    "abstract": "Retrieval-augmented generation (RAG) is a well-suited technique for\nretrieving privacy-sensitive Electronic Health Records (EHR). It can serve as a\nkey module of the healthcare copilot, helping reduce misdiagnosis for\nhealthcare practitioners and patients. However, the diagnostic accuracy and\nspecificity of existing heuristic-based RAG models used in the medical domain\nare inadequate, particularly for diseases with similar manifestations. This\npaper proposes MedRAG, a RAG model enhanced by knowledge graph (KG)-elicited\nreasoning for the medical domain that retrieves diagnosis and treatment\nrecommendations based on manifestations. MedRAG systematically constructs a\ncomprehensive four-tier hierarchical diagnostic KG encompassing critical\ndiagnostic differences of various diseases. These differences are dynamically\nintegrated with similar EHRs retrieved from an EHR database, and reasoned\nwithin a large language model. This process enables more accurate and specific\ndecision support, while also proactively providing follow-up questions to\nenhance personalized medical decision-making. MedRAG is evaluated on both a\npublic dataset DDXPlus and a private chronic pain diagnostic dataset (CPDD)\ncollected from Tan Tock Seng Hospital, and its performance is compared against\nvarious existing RAG methods. Experimental results show that, leveraging the\ninformation integration and relational abilities of the KG, our MedRAG provides\nmore specific diagnostic insights and outperforms state-of-the-art models in\nreducing misdiagnosis rates. Our code will be available at\nhttps://github.com/SNOWTEAM2023/MedRAG",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04413v1",
    "published_date": "2025-02-06 12:27:35 UTC",
    "updated_date": "2025-02-06 12:27:35 UTC"
  },
  {
    "arxiv_id": "2502.04412v1",
    "title": "Decoder-Only LLMs are Better Controllers for Diffusion Models",
    "authors": [
      "Ziyi Dong",
      "Yao Xiao",
      "Pengxu Wei",
      "Liang Lin"
    ],
    "abstract": "Groundbreaking advancements in text-to-image generation have recently been\nachieved with the emergence of diffusion models. These models exhibit a\nremarkable ability to generate highly artistic and intricately detailed images\nbased on textual prompts. However, obtaining desired generation outcomes often\nnecessitates repetitive trials of manipulating text prompts just like casting\nspells on a magic mirror, and the reason behind that is the limited capability\nof semantic understanding inherent in current image generation models.\nSpecifically, existing diffusion models encode the text prompt input with a\npre-trained encoder structure, which is usually trained on a limited number of\nimage-caption pairs. The state-of-the-art large language models (LLMs) based on\nthe decoder-only structure have shown a powerful semantic understanding\ncapability as their architectures are more suitable for training on very\nlarge-scale unlabeled data. In this work, we propose to enhance text-to-image\ndiffusion models by borrowing the strength of semantic understanding from large\nlanguage models, and devise a simple yet effective adapter to allow the\ndiffusion models to be compatible with the decoder-only structure. Meanwhile,\nwe also provide a supporting theoretical analysis with various architectures\n(e.g., encoder-only, encoder-decoder, and decoder-only), and conduct extensive\nempirical evaluations to verify its effectiveness. The experimental results\nshow that the enhanced models with our adapter module are superior to the\nstat-of-the-art models in terms of text-to-image generation quality and\nreliability.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04412v1",
    "published_date": "2025-02-06 12:17:35 UTC",
    "updated_date": "2025-02-06 12:17:35 UTC"
  },
  {
    "arxiv_id": "2502.04008v1",
    "title": "Automating a Complete Software Test Process Using LLMs: An Automotive Case Study",
    "authors": [
      "Shuai Wang",
      "Yinan Yu",
      "Robert Feldt",
      "Dhasarathy Parthasarathy"
    ],
    "abstract": "Vehicle API testing verifies whether the interactions between a vehicle's\ninternal systems and external applications meet expectations, ensuring that\nusers can access and control various vehicle functions and data. However, this\ntask is inherently complex, requiring the alignment and coordination of API\nsystems, communication protocols, and even vehicle simulation systems to\ndevelop valid test cases. In practical industrial scenarios, inconsistencies,\nambiguities, and interdependencies across various documents and system\nspecifications pose significant challenges. This paper presents a system\ndesigned for the automated testing of in-vehicle APIs. By clearly defining and\nsegmenting the testing process, we enable Large Language Models (LLMs) to focus\non specific tasks, ensuring a stable and controlled testing workflow.\nExperiments conducted on over 100 APIs demonstrate that our system effectively\nautomates vehicle API testing. The results also confirm that LLMs can\nefficiently handle mundane tasks requiring human judgment, making them suitable\nfor complete automation in similar industrial contexts.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted by International Conference on Software Engineering (ICSE)\n  2025",
    "pdf_url": "http://arxiv.org/pdf/2502.04008v1",
    "published_date": "2025-02-06 12:10:01 UTC",
    "updated_date": "2025-02-06 12:10:01 UTC"
  },
  {
    "arxiv_id": "2502.03998v1",
    "title": "Online Learning of Counter Categories and Ratings in PvP Games",
    "authors": [
      "Chiu-Chou Lin",
      "I-Chen Wu"
    ],
    "abstract": "In competitive games, strength ratings like Elo are widely used to quantify\nplayer skill and support matchmaking by accounting for skill disparities better\nthan simple win rate statistics. However, scalar ratings cannot handle complex\nintransitive relationships, such as counter strategies seen in\nRock-Paper-Scissors. To address this, recent work introduced Neural Rating\nTable and Neural Counter Table, which combine scalar ratings with discrete\ncounter categories to model intransitivity. While effective, these methods rely\non neural network training and cannot perform real-time updates. In this paper,\nwe propose an online update algorithm that extends Elo principles to\nincorporate real-time learning of counter categories. Our method dynamically\nadjusts both ratings and counter relationships after each match, preserving the\nexplainability of scalar ratings while addressing intransitivity. Experiments\non zero-sum competitive games demonstrate its practicality, particularly in\nscenarios without complex team compositions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GT",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03998v1",
    "published_date": "2025-02-06 11:57:18 UTC",
    "updated_date": "2025-02-06 11:57:18 UTC"
  },
  {
    "arxiv_id": "2502.03992v1",
    "title": "Ontology-Guided, Hybrid Prompt Learning for Generalization in Knowledge Graph Question Answering",
    "authors": [
      "Longquan Jiang",
      "Junbo Huang",
      "Cedric Möller",
      "Ricardo Usbeck"
    ],
    "abstract": "Most existing Knowledge Graph Question Answering (KGQA) approaches are\ndesigned for a specific KG, such as Wikidata, DBpedia or Freebase. Due to the\nheterogeneity of the underlying graph schema, topology and assertions, most\nKGQA systems cannot be transferred to unseen Knowledge Graphs (KGs) without\nresource-intensive training data. We present OntoSCPrompt, a novel Large\nLanguage Model (LLM)-based KGQA approach with a two-stage architecture that\nseparates semantic parsing from KG-dependent interactions. OntoSCPrompt first\ngenerates a SPARQL query structure (including SPARQL keywords such as SELECT,\nASK, WHERE and placeholders for missing tokens) and then fills them with\nKG-specific information. To enhance the understanding of the underlying KG, we\npresent an ontology-guided, hybrid prompt learning strategy that integrates KG\nontology into the learning process of hybrid prompts (e.g., discrete and\ncontinuous vectors). We also present several task-specific decoding strategies\nto ensure the correctness and executability of generated SPARQL queries in both\nstages. Experimental results demonstrate that OntoSCPrompt performs as well as\nSOTA approaches without retraining on a number of KGQA datasets such as CWQ,\nWebQSP and LC-QuAD 1.0 in a resource-efficient manner and can generalize well\nto unseen domain-specific KGs like DBLP-QuAD and CoyPu KG Code:\n\\href{https://github.com/LongquanJiang/OntoSCPrompt}{https://github.com/LongquanJiang/OntoSCPrompt}",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted By ICSC 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.03992v1",
    "published_date": "2025-02-06 11:47:58 UTC",
    "updated_date": "2025-02-06 11:47:58 UTC"
  },
  {
    "arxiv_id": "2502.03984v1",
    "title": "PGB: One-Shot Pruning for BERT via Weight Grouping and Permutation",
    "authors": [
      "Hyemin Lim",
      "Jaeyeon Lee",
      "Dong-Wan Choi"
    ],
    "abstract": "Large pretrained language models such as BERT suffer from slow inference and\nhigh memory usage, due to their huge size. Recent approaches to compressing\nBERT rely on iterative pruning and knowledge distillation, which, however, are\noften too complicated and computationally intensive. This paper proposes a\nnovel semi-structured one-shot pruning method for BERT, called\n$\\textit{Permutation and Grouping for BERT}$ (PGB), which achieves high\ncompression efficiency and sparsity while preserving accuracy. To this end, PGB\nidentifies important groups of individual weights by permutation and prunes all\nother weights as a structure in both multi-head attention and feed-forward\nlayers. Furthermore, if no important group is formed in a particular layer, PGB\ndrops the entire layer to produce an even more compact model. Our experimental\nresults on BERT$_{\\text{BASE}}$ demonstrate that PGB outperforms the\nstate-of-the-art structured pruning methods in terms of computational cost and\naccuracy preservation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03984v1",
    "published_date": "2025-02-06 11:34:41 UTC",
    "updated_date": "2025-02-06 11:34:41 UTC"
  },
  {
    "arxiv_id": "2502.04411v2",
    "title": "Mediator: Memory-efficient LLM Merging with Less Parameter Conflicts and Uncertainty Based Routing",
    "authors": [
      "Kunfeng Lai",
      "Zhenheng Tang",
      "Xinglin Pan",
      "Peijie Dong",
      "Xiang Liu",
      "Haolan Chen",
      "Li Shen",
      "Bo Li",
      "Xiaowen Chu"
    ],
    "abstract": "Model merging aggregates Large Language Models (LLMs) finetuned on different\ntasks into a stronger one. However, parameter conflicts between models leads to\nperformance degradation in averaging. While model routing addresses this issue\nby selecting individual models during inference, it imposes excessive storage\nand compute costs, and fails to leverage the common knowledge from different\nmodels. In this work, we observe that different layers exhibit varying levels\nof parameter conflicts. Building on this insight, we average layers with\nminimal parameter conflicts and use a novel task-level expert routing for\nlayers with significant conflicts. To further reduce storage costs, inspired by\ntask arithmetic sparsity, we decouple multiple fine-tuned experts into a dense\nexpert and several sparse experts. Considering the out-of-distribution samples,\nwe select and merge appropriate experts based on the task uncertainty of the\ninput data. We conduct extensive experiments on both LLaMA and Qwen with\nvarying parameter scales, and evaluate on real-world reasoning tasks. Results\ndemonstrate that our method consistently achieves significant performance\nimprovements while requiring less system cost compared to existing methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "68T50"
    ],
    "primary_category": "cs.LG",
    "comment": "work in progress. arXiv admin note: text overlap with\n  arXiv:2405.09673 by other authors",
    "pdf_url": "http://arxiv.org/pdf/2502.04411v2",
    "published_date": "2025-02-06 11:26:30 UTC",
    "updated_date": "2025-02-11 12:09:51 UTC"
  },
  {
    "arxiv_id": "2502.03979v2",
    "title": "Towards Unified Music Emotion Recognition across Dimensional and Categorical Models",
    "authors": [
      "Jaeyong Kang",
      "Dorien Herremans"
    ],
    "abstract": "One of the most significant challenges in Music Emotion Recognition (MER)\ncomes from the fact that emotion labels can be heterogeneous across datasets\nwith regard to the emotion representation, including categorical (e.g., happy,\nsad) versus dimensional labels (e.g., valence-arousal). In this paper, we\npresent a unified multitask learning framework that combines these two types of\nlabels and is thus able to be trained on multiple datasets. This framework uses\nan effective input representation that combines musical features (i.e., key and\nchords) and MERT embeddings. Moreover, knowledge distillation is employed to\ntransfer the knowledge of teacher models trained on individual datasets to a\nstudent model, enhancing its ability to generalize across multiple tasks. To\nvalidate our proposed framework, we conducted extensive experiments on a\nvariety of datasets, including MTG-Jamendo, DEAM, PMEmo, and EmoMusic.\nAccording to our experimental results, the inclusion of musical features,\nmultitask learning, and knowledge distillation significantly enhances\nperformance. In particular, our model outperforms the state-of-the-art models,\nincluding the best-performing model from the MediaEval 2021 competition on the\nMTG-Jamendo dataset. Our work makes a significant contribution to MER by\nallowing the combination of categorical and dimensional emotion labels in one\nunified framework, thus enabling training across datasets.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03979v2",
    "published_date": "2025-02-06 11:20:22 UTC",
    "updated_date": "2025-04-11 12:58:23 UTC"
  },
  {
    "arxiv_id": "2503.05702v1",
    "title": "A Comprehensive Survey of Fuzzy Implication Functions",
    "authors": [
      "Raquel Fernandez-Peralta"
    ],
    "abstract": "Fuzzy implication functions are a key area of study in fuzzy logic, extending\nthe classical logical conditional to handle truth degrees in the interval\n$[0,1]$. While existing literature often focuses on a limited number of\nfamilies, in the last ten years many new families have been introduced, each\ndefined by specific construction methods and having different key properties.\nThis survey aims to provide a comprehensive and structured overview of the\ndiverse families of fuzzy implication functions, emphasizing their motivations,\nproperties, and potential applications. By organizing the information\nschematically, this document serves as a valuable resource for both theoretical\nresearchers seeking to avoid redundancy and practitioners looking to select\nappropriate operators for specific applications.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.05702v1",
    "published_date": "2025-02-06 11:09:24 UTC",
    "updated_date": "2025-02-06 11:09:24 UTC"
  },
  {
    "arxiv_id": "2502.03966v3",
    "title": "MultiFloodSynth: Multi-Annotated Flood Synthetic Dataset Generation",
    "authors": [
      "YoonJe Kang",
      "Yonghoon Jung",
      "Wonseop Shin",
      "Bumsoo Kim",
      "Sanghyun Seo"
    ],
    "abstract": "In this paper, we present synthetic data generation framework for flood\nhazard detection system. For high fidelity and quality, we characterize several\nreal-world properties into virtual world and simulate the flood situation by\ncontrolling them. For the sake of efficiency, recent generative models in\nimage-to-3D and urban city synthesis are leveraged to easily composite flood\nenvironments so that we avoid data bias due to the hand-crafted manner. Based\non our framework, we build the flood synthetic dataset with 5 levels, dubbed\nMultiFloodSynth which contains rich annotation types like normal map,\nsegmentation, 3D bounding box for a variety of downstream task. In experiments,\nour dataset demonstrate the enhanced performance of flood hazard detection with\non-par realism compared with real dataset.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "6 pages, 6 figures. Accepted as Oral Presentation to AAAI 2025\n  Workshop on Good-Data",
    "pdf_url": "http://arxiv.org/pdf/2502.03966v3",
    "published_date": "2025-02-06 10:59:44 UTC",
    "updated_date": "2025-02-13 08:54:42 UTC"
  },
  {
    "arxiv_id": "2502.07806v1",
    "title": "Quantum Powered Credit Risk Assessment: A Novel Approach using hybrid Quantum-Classical Deep Neural Network for Row-Type Dependent Predictive Analysis",
    "authors": [
      "Rath Minati",
      "Date Hema"
    ],
    "abstract": "The integration of Quantum Deep Learning (QDL) techniques into the landscape\nof financial risk analysis presents a promising avenue for innovation. This\nstudy introduces a framework for credit risk assessment in the banking sector,\ncombining quantum deep learning techniques with adaptive modeling for Row-Type\nDependent Predictive Analysis (RTDPA). By leveraging RTDPA, the proposed\napproach tailors predictive models to different loan categories, aiming to\nenhance the accuracy and efficiency of credit risk evaluation. While this work\nexplores the potential of integrating quantum methods with classical deep\nlearning for risk assessment, it focuses on the feasibility and performance of\nthis hybrid framework rather than claiming transformative industry-wide\nimpacts. The findings offer insights into how quantum techniques can complement\ntraditional financial analysis, paving the way for further advancements in\npredictive modeling for credit risk.",
    "categories": [
      "q-fin.CP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-fin.CP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07806v1",
    "published_date": "2025-02-06 10:57:18 UTC",
    "updated_date": "2025-02-06 10:57:18 UTC"
  },
  {
    "arxiv_id": "2502.03962v2",
    "title": "Quantum Circuit Design using a Progressive Widening Enhanced Monte Carlo Tree Search",
    "authors": [
      "Vincenzo Lipardi",
      "Domenica Dibenedetto",
      "Georgios Stamoulis",
      "Mark H. M. Winands"
    ],
    "abstract": "The performance of Variational Quantum Algorithms (VQAs) strongly depends on\nthe choice of the parameterized quantum circuit to optimize. One of the biggest\nchallenges in VQAs is designing quantum circuits tailored to the particular\nproblem. This article proposes a gradient-free Monte Carlo Tree Search (MCTS)\ntechnique to automate the process of quantum circuit design. Our proposed\ntechnique introduces a novel formulation of the action space based on a\nsampling scheme and a progressive widening technique to explore the space\ndynamically. When testing our MCTS approach on the domain of random quantum\ncircuits, MCTS approximates unstructured circuits under different values of\nstabilizer R\\'enyi entropy. It turns out that MCTS manages to approximate the\nbenchmark quantum states independently from their degree of nonstabilizerness.\nNext, our technique exhibits robustness across various application domains,\nincluding quantum chemistry and systems of linear equations. Compared to\nprevious MCTS research, our technique reduces the number of quantum circuit\nevaluations by a factor of 10 up to 100 while achieving equal or better\nresults. In addition, the resulting quantum circuits exhibit up to three times\nfewer CNOT gates, which is important for implementation on noisy quantum\nhardware.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "quant-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03962v2",
    "published_date": "2025-02-06 10:52:11 UTC",
    "updated_date": "2025-04-28 12:38:48 UTC"
  },
  {
    "arxiv_id": "2502.03957v1",
    "title": "Improving the Perturbation-Based Explanation of Deepfake Detectors Through the Use of Adversarially-Generated Samples",
    "authors": [
      "Konstantinos Tsigos",
      "Evlampios Apostolidis",
      "Vasileios Mezaris"
    ],
    "abstract": "In this paper, we introduce the idea of using adversarially-generated samples\nof the input images that were classified as deepfakes by a detector, to form\nperturbation masks for inferring the importance of different input features and\nproduce visual explanations. We generate these samples based on Natural\nEvolution Strategies, aiming to flip the original deepfake detector's decision\nand classify these samples as real. We apply this idea to four\nperturbation-based explanation methods (LIME, SHAP, SOBOL and RISE) and\nevaluate the performance of the resulting modified methods using a SOTA\ndeepfake detection model, a benchmarking dataset (FaceForensics++) and a\ncorresponding explanation evaluation framework. Our quantitative assessments\ndocument the mostly positive contribution of the proposed perturbation approach\nin the performance of explanation methods. Our qualitative analysis shows the\ncapacity of the modified explanation methods to demarcate the manipulated image\nregions more accurately, and thus to provide more useful explanations.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted for publication, AI4MFDD Workshop @ IEEE/CVF Winter\n  Conference on Applications of Computer Vision (WACV 2025), Tucson, AZ, USA,\n  Feb. 2025. This is the authors' \"accepted version\"",
    "pdf_url": "http://arxiv.org/pdf/2502.03957v1",
    "published_date": "2025-02-06 10:47:34 UTC",
    "updated_date": "2025-02-06 10:47:34 UTC"
  },
  {
    "arxiv_id": "2502.03954v1",
    "title": "MAQInstruct: Instruction-based Unified Event Relation Extraction",
    "authors": [
      "Jun Xu",
      "Mengshu Sun",
      "Zhiqiang Zhang",
      "Jun Zhou"
    ],
    "abstract": "Extracting event relations that deviate from known schemas has proven\nchallenging for previous methods based on multi-class classification, MASK\nprediction, or prototype matching. Recent advancements in large language models\nhave shown impressive performance through instruction tuning. Nevertheless, in\nthe task of event relation extraction, instruction-based methods face several\nchallenges: there are a vast number of inference samples, and the relations\nbetween events are non-sequential. To tackle these challenges, we present an\nimproved instruction-based event relation extraction framework named\nMAQInstruct. Firstly, we transform the task from extracting event relations\nusing given event-event instructions to selecting events using given\nevent-relation instructions, which reduces the number of samples required for\ninference. Then, by incorporating a bipartite matching loss, we reduce the\ndependency of the instruction-based method on the generation sequence. Our\nexperimental results demonstrate that MAQInstruct significantly improves the\nperformance of event relation extraction across multiple LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by WWW 2025 short",
    "pdf_url": "http://arxiv.org/pdf/2502.03954v1",
    "published_date": "2025-02-06 10:46:19 UTC",
    "updated_date": "2025-02-06 10:46:19 UTC"
  },
  {
    "arxiv_id": "2502.03948v1",
    "title": "Enhancing Online Learning Efficiency Through Heterogeneous Resource Integration with a Multi-Agent RAG System",
    "authors": [
      "Devansh Srivastav",
      "Hasan Md Tusfiqur Alam",
      "Afsaneh Asaei",
      "Mahmoud Fazeli",
      "Tanisha Sharma",
      "Daniel Sonntag"
    ],
    "abstract": "Efficient online learning requires seamless access to diverse resources such\nas videos, code repositories, documentation, and general web content. This\nposter paper introduces early-stage work on a Multi-Agent Retrieval-Augmented\nGeneration (RAG) System designed to enhance learning efficiency by integrating\nthese heterogeneous resources. Using specialized agents tailored for specific\nresource types (e.g., YouTube tutorials, GitHub repositories, documentation\nwebsites, and search engines), the system automates the retrieval and synthesis\nof relevant information. By streamlining the process of finding and combining\nknowledge, this approach reduces manual effort and enhances the learning\nexperience. A preliminary user study confirmed the system's strong usability\nand moderate-high utility, demonstrating its potential to improve the\nefficiency of knowledge acquisition.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03948v1",
    "published_date": "2025-02-06 10:36:17 UTC",
    "updated_date": "2025-02-06 10:36:17 UTC"
  },
  {
    "arxiv_id": "2502.03930v2",
    "title": "DiTAR: Diffusion Transformer Autoregressive Modeling for Speech Generation",
    "authors": [
      "Dongya Jia",
      "Zhuo Chen",
      "Jiawei Chen",
      "Chenpeng Du",
      "Jian Wu",
      "Jian Cong",
      "Xiaobin Zhuang",
      "Chumin Li",
      "Zhen Wei",
      "Yuping Wang",
      "Yuxuan Wang"
    ],
    "abstract": "Several recent studies have attempted to autoregressively generate continuous\nspeech representations without discrete speech tokens by combining diffusion\nand autoregressive models, yet they often face challenges with excessive\ncomputational loads or suboptimal outcomes. In this work, we propose Diffusion\nTransformer Autoregressive Modeling (DiTAR), a patch-based autoregressive\nframework combining a language model with a diffusion transformer. This\napproach significantly enhances the efficacy of autoregressive models for\ncontinuous tokens and reduces computational demands. DiTAR utilizes a\ndivide-and-conquer strategy for patch generation, where the language model\nprocesses aggregated patch embeddings and the diffusion transformer\nsubsequently generates the next patch based on the output of the language\nmodel. For inference, we propose defining temperature as the time point of\nintroducing noise during the reverse diffusion ODE to balance diversity and\ndeterminism. We also show in the extensive scaling analysis that DiTAR has\nsuperb scalability. In zero-shot speech generation, DiTAR achieves\nstate-of-the-art performance in robustness, speaker similarity, and\nnaturalness.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "16 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.03930v2",
    "published_date": "2025-02-06 10:09:49 UTC",
    "updated_date": "2025-02-14 09:49:57 UTC"
  },
  {
    "arxiv_id": "2502.04408v1",
    "title": "Transforming Multimodal Models into Action Models for Radiotherapy",
    "authors": [
      "Matteo Ferrante",
      "Alessandra Carosi",
      "Rolando Maria D Angelillo",
      "Nicola Toschi"
    ],
    "abstract": "Radiotherapy is a crucial cancer treatment that demands precise planning to\nbalance tumor eradication and preservation of healthy tissue. Traditional\ntreatment planning (TP) is iterative, time-consuming, and reliant on human\nexpertise, which can potentially introduce variability and inefficiency. We\npropose a novel framework to transform a large multimodal foundation model\n(MLM) into an action model for TP using a few-shot reinforcement learning (RL)\napproach. Our method leverages the MLM's extensive pre-existing knowledge of\nphysics, radiation, and anatomy, enhancing it through a few-shot learning\nprocess. This allows the model to iteratively improve treatment plans using a\nMonte Carlo simulator. Our results demonstrate that this method outperforms\nconventional RL-based approaches in both quality and efficiency, achieving\nhigher reward scores and more optimal dose distributions in simulations on\nprostate cancer data. This proof-of-concept suggests a promising direction for\nintegrating advanced AI models into clinical workflows, potentially enhancing\nthe speed, quality, and standardization of radiotherapy treatment planning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04408v1",
    "published_date": "2025-02-06 09:51:28 UTC",
    "updated_date": "2025-02-06 09:51:28 UTC"
  },
  {
    "arxiv_id": "2502.03918v1",
    "title": "Adaptation of Task Goal States from Prior Knowledge",
    "authors": [
      "Andrei Costinescu",
      "Darius Burschka"
    ],
    "abstract": "This paper presents a framework to define a task with freedom and variability\nin its goal state. A robot could use this to observe the execution of a task\nand target a different goal from the observed one; a goal that is still\ncompatible with the task description but would be easier for the robot to\nexecute. We define the model of an environment state and an environment\nvariation, and present experiments on how to interactively create the variation\nfrom a single task demonstration and how to use this variation to create an\nexecution plan for bringing any environment into the goal state.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03918v1",
    "published_date": "2025-02-06 09:51:04 UTC",
    "updated_date": "2025-02-06 09:51:04 UTC"
  },
  {
    "arxiv_id": "2502.03916v1",
    "title": "Experiments with Large Language Models on Retrieval-Augmented Generation for Closed-Source Simulation Software",
    "authors": [
      "Andreas Baumann",
      "Peter Eberhard"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly helpful in text generation,\neven writing code in programming languages based on user prompts written in\nnatural language. They are even applied to generate simulation models for\nmultibody systems from natural language. Research results suggest that LLMs\nsurpass the mere replication of existing code examples, where some LLMs have\nbeen trained on an open-source multibody simulation code. However, for\nclosed-source simulation software, such results are not to be expected as their\nideas and concepts might differ from other publicly available ones. LLMs can\nhallucinate for knowledge-intensive tasks, such as model creation, which can\nlead to wrong responses. This is especially the case for the LLM unknown\nclosed-source simulation software. The same applies to other internal knowledge\nkept private to protect intellectual property or data privacy. The\nRetrieval-Augmented Generation (RAG) approach might yield a solution for these\nknowledge-intensive tasks. This paper explores the application of RAG to\nclosed-source simulation software and presents first experiments. After a brief\nintroduction to LLMs, the RAG approach, and the simulation method applied by\nthe close-source simulation software, several examples are provided to test\nLLMs' knowledge of the simulation software and the creation of simulation\nmodels using two RAG systems. The examples show promising results indicating\nthe benefits of applying RAG systems to closed-source simulation software,\nhelping to access their knowledge. Nevertheless, they also reveal gaps in the\napplied information and open questions for further research.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "11 pages, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.03916v1",
    "published_date": "2025-02-06 09:48:04 UTC",
    "updated_date": "2025-02-06 09:48:04 UTC"
  },
  {
    "arxiv_id": "2502.04407v1",
    "title": "Illuminating Spaces: Deep Reinforcement Learning and Laser-Wall Partitioning for Architectural Layout Generation",
    "authors": [
      "Reza Kakooee",
      "Benjamin Dillenburger"
    ],
    "abstract": "Space layout design (SLD), occurring in the early stages of the design\nprocess, nonetheless influences both the functionality and aesthetics of the\nultimate architectural outcome. The complexity of SLD necessitates innovative\napproaches to efficiently explore vast solution spaces. While image-based\ngenerative AI has emerged as a potential solution, they often rely on\npixel-based space composition methods that lack intuitive representation of\narchitectural processes. This paper leverages deep Reinforcement Learning (RL),\nas it offers a procedural approach that intuitively mimics the process of human\ndesigners. Effectively using RL for SLD requires an explorative space composing\nmethod to generate desirable design solutions. We introduce \"laser-wall\", a\nnovel space partitioning method that conceptualizes walls as emitters of\nimaginary light beams to partition spaces. This approach bridges vector-based\nand pixel-based partitioning methods, offering both flexibility and exploratory\npower in generating diverse layouts. We present two planning strategies:\none-shot planning, which generates entire layouts in a single pass, and dynamic\nplanning, which allows for adaptive refinement by continuously transforming\nlaser-walls. Additionally, we introduce on-light and off-light wall\ntransformations for smooth and fast layout refinement, as well as identity-less\nand identity-full walls for versatile room assignment. We developed\nSpaceLayoutGym, an open-source OpenAI Gym compatible simulator for generating\nand evaluating space layouts. The RL agent processes the input design scenarios\nand generates solutions following a reward function that balances geometrical\nand topological requirements. Our results demonstrate that the RL-based\nlaser-wall approach can generate diverse and functional space layouts that\nsatisfy both geometric constraints and topological requirements and is\narchitecturally intuitive.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04407v1",
    "published_date": "2025-02-06 09:35:24 UTC",
    "updated_date": "2025-02-06 09:35:24 UTC"
  },
  {
    "arxiv_id": "2502.04406v1",
    "title": "Calibrated Physics-Informed Uncertainty Quantification",
    "authors": [
      "Vignesh Gopakumar",
      "Ander Gray",
      "Lorenzo Zanisi",
      "Timothy Nunn",
      "Stanislas Pamela",
      "Daniel Giles",
      "Matt J. Kusner",
      "Marc Peter Deisenroth"
    ],
    "abstract": "Neural PDEs offer efficient alternatives to computationally expensive\nnumerical PDE solvers for simulating complex physical systems. However, their\nlack of robust uncertainty quantification (UQ) limits deployment in critical\napplications. We introduce a model-agnostic, physics-informed conformal\nprediction (CP) framework that provides guaranteed uncertainty estimates\nwithout requiring labelled data. By utilising a physics-based approach, we are\nable to quantify and calibrate the model's inconsistencies with the PDE rather\nthan the uncertainty arising from the data. Our approach uses convolutional\nlayers as finite-difference stencils and leverages physics residual errors as\nnonconformity scores, enabling data-free UQ with marginal and joint coverage\nguarantees across prediction domains for a range of complex PDEs. We further\nvalidate the efficacy of our method on neural PDE models for plasma modelling\nand shot design in fusion reactors.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.comp-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04406v1",
    "published_date": "2025-02-06 09:23:06 UTC",
    "updated_date": "2025-02-06 09:23:06 UTC"
  },
  {
    "arxiv_id": "2502.06839v1",
    "title": "A Hybrid Model for Weakly-Supervised Speech Dereverberation",
    "authors": [
      "Louis Bahrman",
      "Mathieu Fontaine",
      "Gael Richard"
    ],
    "abstract": "This paper introduces a new training strategy to improve speech\ndereverberation systems using minimal acoustic information and reverberant\n(wet) speech. Most existing algorithms rely on paired dry/wet data, which is\ndifficult to obtain, or on target metrics that may not adequately capture\nreverberation characteristics and can lead to poor results on non-target\nmetrics. Our approach uses limited acoustic information, like the reverberation\ntime (RT60), to train a dereverberation system. The system's output is\nresynthesized using a generated room impulse response and compared with the\noriginal reverberant speech, providing a novel reverberation matching loss\nreplacing the standard target metrics. During inference, only the trained\ndereverberation model is used. Experimental results demonstrate that our method\nachieves more consistent performance across various objective metrics used in\nspeech dereverberation than the state-of-the-art.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.SD",
      "eess.SP"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.06839v1",
    "published_date": "2025-02-06 09:21:22 UTC",
    "updated_date": "2025-02-06 09:21:22 UTC"
  },
  {
    "arxiv_id": "2502.03897v4",
    "title": "UniForm: A Unified Multi-Task Diffusion Transformer for Audio-Video Generation",
    "authors": [
      "Lei Zhao",
      "Linfeng Feng",
      "Dongxu Ge",
      "Rujin Chen",
      "Fangqiu Yi",
      "Chi Zhang",
      "Xiao-Lei Zhang",
      "Xuelong Li"
    ],
    "abstract": "With the rise of diffusion models, audio-video generation has been\nrevolutionized. However, most existing methods rely on separate modules for\neach modality, with limited exploration of unified generative architectures. In\naddition, many are confined to a single task and small-scale datasets. To\naddress these limitations, we first propose UniForm, a unified multi-task\ndiffusion transformer that jointly generates audio and visual modalities in a\nshared latent space. A single diffusion process models both audio and video,\ncapturing the inherent correlations between sound and vision. Second, we\nintroduce task-specific noise schemes and task tokens, enabling a single model\nto support multiple tasks, including text-to-audio-video, audio-to-video, and\nvideo-to-audio generation. Furthermore, by leveraging large language models and\na large-scale text-audio-video combined dataset, UniForm achieves greater\ngenerative diversity than prior approaches. Extensive experiments show that\nUniForm achieves the state-of-the-art performance across audio-video generation\ntasks, producing content that is both well-aligned and close to real-world data\ndistributions. Our demos are available at https://uniform-t2av.github.io/.",
    "categories": [
      "cs.MM",
      "cs.AI",
      "cs.CV",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.MM",
    "comment": "Our demos are available at https://uniform-t2av.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2502.03897v4",
    "published_date": "2025-02-06 09:18:30 UTC",
    "updated_date": "2025-04-15 06:53:12 UTC"
  },
  {
    "arxiv_id": "2502.15735v1",
    "title": "DistrEE: Distributed Early Exit of Deep Neural Network Inference on Edge Devices",
    "authors": [
      "Xian Peng",
      "Xin Wu",
      "Lianming Xu",
      "Li Wang",
      "Aiguo Fei"
    ],
    "abstract": "Distributed DNN inference is becoming increasingly important as the demand\nfor intelligent services at the network edge grows. By leveraging the power of\ndistributed computing, edge devices can perform complicated and resource-hungry\ninference tasks previously only possible on powerful servers, enabling new\napplications in areas such as autonomous vehicles, industrial automation, and\nsmart homes. However, it is challenging to achieve accurate and efficient\ndistributed edge inference due to the fluctuating nature of the actual\nresources of the devices and the processing difficulty of the input data. In\nthis work, we propose DistrEE, a distributed DNN inference framework that can\nexit model inference early to meet specific quality of service requirements. In\nparticular, the framework firstly integrates model early exit and distributed\ninference for multi-node collaborative inferencing scenarios. Furthermore, it\ndesigns an early exit policy to control when the model inference terminates.\nExtensive simulation results demonstrate that DistrEE can efficiently realize\nefficient collaborative inference, achieving an effective trade-off between\ninference latency and accuracy.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15735v1",
    "published_date": "2025-02-06 09:16:54 UTC",
    "updated_date": "2025-02-06 09:16:54 UTC"
  },
  {
    "arxiv_id": "2502.04405v2",
    "title": "FAS: Fast ANN-SNN Conversion for Spiking Large Language Models",
    "authors": [
      "Long Chen",
      "Xiaotian Song",
      "Andy Song",
      "BaDong Chen",
      "Jiancheng Lv",
      "Yanan Sun"
    ],
    "abstract": "Spiking Large Language Models have been shown as a good alternative to LLMs\nin various scenarios. Existing methods for creating Spiking LLMs, i.e., direct\ntraining and ANN-SNN conversion, often suffer from performance degradation and\nrelatively high computational costs. To address these issues, we propose a\nnovel Fast ANN-SNN conversion strategy (FAS) that transforms LLMs into spiking\nLLMs in two stages. The first stage employs a full-parameter fine-tuning of\npre-trained models, so it does not need any direct training from scratch. The\nsecond stage introduces a coarse-to-fine calibration method to reduce\nconversion errors and improve accuracy. Experiments on both language and\nvision-language tasks across four different scales of LLMs demonstrate that FAS\ncan achieve state-of-the-art performance yet with significantly reduced\ninference latency and computational costs. Notably, FAS only takes eight\ntimesteps to achieve an accuracy of 3\\% higher than that of the OPT-7B model,\nwhile reducing energy consumption by 96.63\\%. The source code is available at\nhttps://github.com/lc783/FAS",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04405v2",
    "published_date": "2025-02-06 09:08:12 UTC",
    "updated_date": "2025-05-14 05:23:45 UTC"
  },
  {
    "arxiv_id": "2502.03884v1",
    "title": "Rank Also Matters: Hierarchical Configuration for Mixture of Adapter Experts in LLM Fine-Tuning",
    "authors": [
      "Peizhuang Cong",
      "Wenpu Liu",
      "Wenhan Yu",
      "Haochen Zhao",
      "Tong Yang"
    ],
    "abstract": "Large language models (LLMs) have demonstrated remarkable success across\nvarious tasks, accompanied by a continuous increase in their parameter size.\nParameter-efficient fine-tuning (PEFT) methods, such as Low-Rank Adaptation\n(LoRA), address the challenges of fine-tuning LLMs by significantly reducing\nthe number of trainable parameters. Recent studies have integrated LoRA with\nMixture of Experts (MoE) architectures, leveraging multiple adapter experts and\ngating mechanisms to further improve fine-tuning performance. However, existing\napproaches primarily focus on adjusting the allocations of adapter experts per\nlayer to optimize the introduced trainable parameter size, while neglecting a\ncritical factor of adapters' rank. To this end, we propose a hierarchical\nscheme for expert allocation and rank configuration, HILO, which dynamically\nadjusts the number and rank of adapter experts across layers, matching the\nvarying representational complexity of model layers in adapter-granularity.\nExtensive experiments on multiple benchmark tasks demonstrate that HILO\noutperforms existing methods in accuracy while introducing fewer trainable\nparameters, providing an efficient and practical solution for fine-tuning LLMs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03884v1",
    "published_date": "2025-02-06 08:58:03 UTC",
    "updated_date": "2025-02-06 08:58:03 UTC"
  },
  {
    "arxiv_id": "2502.04404v1",
    "title": "Step Back to Leap Forward: Self-Backtracking for Boosting Reasoning of Language Models",
    "authors": [
      "Xiao-Wen Yang",
      "Xuan-Yi Zhu",
      "Wen-Da Wei",
      "Ding-Chu Zhang",
      "Jie-Jing Shao",
      "Zhi Zhou",
      "Lan-Zhe Guo",
      "Yu-Feng Li"
    ],
    "abstract": "The integration of slow-thinking mechanisms into large language models (LLMs)\noffers a promising way toward achieving Level 2 AGI Reasoners, as exemplified\nby systems like OpenAI's o1. However, several significant challenges remain,\nincluding inefficient overthinking and an overreliance on auxiliary reward\nmodels. We point out that these limitations stem from LLMs' inability to\ninternalize the search process, a key component of effective reasoning. A\ncritical step toward addressing this issue is enabling LLMs to autonomously\ndetermine when and where to backtrack, a fundamental operation in traditional\nsearch algorithms. To this end, we propose a self-backtracking mechanism that\nequips LLMs with the ability to backtrack during both training and inference.\nThis mechanism not only enhances reasoning ability but also efficiency by\ntransforming slow-thinking processes into fast-thinking through\nself-improvement. Empirical evaluations demonstrate that our proposal\nsignificantly enhances the reasoning capabilities of LLMs, achieving a\nperformance gain of over 40 percent compared to the optimal-path supervised\nfine-tuning method. We believe this study introduces a novel and promising\npathway for developing more advanced and robust Reasoners.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "This is a preprint under review, 15 pages, 13 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.04404v1",
    "published_date": "2025-02-06 08:52:43 UTC",
    "updated_date": "2025-02-06 08:52:43 UTC"
  },
  {
    "arxiv_id": "2502.05228v1",
    "title": "Multi-Objective Mobile Damped Wave Algorithm (MOMDWA): A Novel Approach For Quantum System Control",
    "authors": [
      "Juntao Yu",
      "Jiaquan Yu",
      "Dedai Wei",
      "Xinye Sha",
      "Shengwei Fu",
      "Miuyu Qiu",
      "Yurun Jin",
      "Kaichen Ouyang"
    ],
    "abstract": "In this paper, we introduce a novel multi-objective optimization algorithm,\nthe Multi-Objective Mobile Damped Wave Algorithm (MOMDWA), specifically\ndesigned to address complex quantum control problems. Our approach extends the\ncapabilities of the original Mobile Damped Wave Algorithm (MDWA) by\nincorporating multiple objectives, enabling a more comprehensive optimization\nprocess. We applied MOMDWA to three quantum control scenarios, focusing on\noptimizing the balance between control fidelity, energy consumption, and\ncontrol smoothness. The results demonstrate that MOMDWA significantly enhances\nquantum control efficiency and robustness, achieving high fidelity while\nminimizing energy use and ensuring smooth control pulses. This advancement\noffers a valuable tool for quantum computing and other domains requiring\nprecise, multi-objective control.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.SY"
    ],
    "primary_category": "quant-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05228v1",
    "published_date": "2025-02-06 08:43:21 UTC",
    "updated_date": "2025-02-06 08:43:21 UTC"
  },
  {
    "arxiv_id": "2502.04403v1",
    "title": "Agency Is Frame-Dependent",
    "authors": [
      "David Abel",
      "André Barreto",
      "Michael Bowling",
      "Will Dabney",
      "Shi Dong",
      "Steven Hansen",
      "Anna Harutyunyan",
      "Khimya Khetarpal",
      "Clare Lyle",
      "Razvan Pascanu",
      "Georgios Piliouras",
      "Doina Precup",
      "Jonathan Richens",
      "Mark Rowland",
      "Tom Schaul",
      "Satinder Singh"
    ],
    "abstract": "Agency is a system's capacity to steer outcomes toward a goal, and is a\ncentral topic of study across biology, philosophy, cognitive science, and\nartificial intelligence. Determining if a system exhibits agency is a\nnotoriously difficult question: Dennett (1989), for instance, highlights the\npuzzle of determining which principles can decide whether a rock, a thermostat,\nor a robot each possess agency. We here address this puzzle from the viewpoint\nof reinforcement learning by arguing that agency is fundamentally\nframe-dependent: Any measurement of a system's agency must be made relative to\na reference frame. We support this claim by presenting a philosophical argument\nthat each of the essential properties of agency proposed by Barandiaran et al.\n(2009) and Moreno (2018) are themselves frame-dependent. We conclude that any\nbasic science of agency requires frame-dependence, and discuss the implications\nof this claim for reinforcement learning.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04403v1",
    "published_date": "2025-02-06 08:34:57 UTC",
    "updated_date": "2025-02-06 08:34:57 UTC"
  },
  {
    "arxiv_id": "2502.03852v1",
    "title": "Pursuing Better Decision Boundaries for Long-Tailed Object Detection via Category Information Amount",
    "authors": [
      "Yanbiao Ma",
      "Wei Dai",
      "Jiayi Chen"
    ],
    "abstract": "In object detection, the instance count is typically used to define whether a\ndataset exhibits a long-tail distribution, implicitly assuming that models will\nunderperform on categories with fewer instances. This assumption has led to\nextensive research on category bias in datasets with imbalanced instance\ncounts. However, models still exhibit category bias even in datasets where\ninstance counts are relatively balanced, clearly indicating that instance count\nalone cannot explain this phenomenon. In this work, we first introduce the\nconcept and measurement of category information amount. We observe a\nsignificant negative correlation between category information amount and\naccuracy, suggesting that category information amount more accurately reflects\nthe learning difficulty of a category. Based on this observation, we propose\nInformation Amount-Guided Angular Margin (IGAM) Loss. The core idea of IGAM is\nto dynamically adjust the decision space of each category based on its\ninformation amount, thereby reducing category bias in long-tail datasets. IGAM\nLoss not only performs well on long-tailed benchmark datasets such as LVIS v1.0\nand COCO-LT but also shows significant improvement for underrepresented\ncategories in the non-long-tailed dataset Pascal VOC. Comprehensive experiments\ndemonstrate the potential of category information amount as a tool and the\ngenerality of our proposed method.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Published as a conference paper at ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.03852v1",
    "published_date": "2025-02-06 08:08:18 UTC",
    "updated_date": "2025-02-06 08:08:18 UTC"
  },
  {
    "arxiv_id": "2502.04402v1",
    "title": "Beyond Interpolation: Extrapolative Reasoning with Reinforcement Learning and Graph Neural Networks",
    "authors": [
      "Niccolò Grillo",
      "Andrea Toccaceli",
      "Joël Mathys",
      "Benjamin Estermann",
      "Stefania Fresca",
      "Roger Wattenhofer"
    ],
    "abstract": "Despite incredible progress, many neural architectures fail to properly\ngeneralize beyond their training distribution. As such, learning to reason in a\ncorrect and generalizable way is one of the current fundamental challenges in\nmachine learning. In this respect, logic puzzles provide a great testbed, as we\ncan fully understand and control the learning environment. Thus, they allow to\nevaluate performance on previously unseen, larger and more difficult puzzles\nthat follow the same underlying rules. Since traditional approaches often\nstruggle to represent such scalable logical structures, we propose to model\nthese puzzles using a graph-based approach. Then, we investigate the key\nfactors enabling the proposed models to learn generalizable solutions in a\nreinforcement learning setting. Our study focuses on the impact of the\ninductive bias of the architecture, different reward systems and the role of\nrecurrent modeling in enabling sequential reasoning. Through extensive\nexperiments, we demonstrate how these elements contribute to successful\nextrapolation on increasingly complex puzzles.These insights and frameworks\noffer a systematic way to design learning-based systems capable of\ngeneralizable reasoning beyond interpolation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "The first two authors contributed equally to this work. Accepted as\n  workshop paper at NEURMAD@AAAI25",
    "pdf_url": "http://arxiv.org/pdf/2502.04402v1",
    "published_date": "2025-02-06 08:07:35 UTC",
    "updated_date": "2025-02-06 08:07:35 UTC"
  },
  {
    "arxiv_id": "2502.03843v1",
    "title": "Improving Natural Language Understanding for LLMs via Large-Scale Instruction Synthesis",
    "authors": [
      "Lin Yuan",
      "Jun Xu",
      "Honghao Gui",
      "Mengshu Sun",
      "Zhiqiang Zhang",
      "Lei Liang",
      "Jun Zhou"
    ],
    "abstract": "High-quality, large-scale instructions are crucial for aligning large\nlanguage models (LLMs), however, there is a severe shortage of instruction in\nthe field of natural language understanding (NLU). Previous works on\nconstructing NLU instructions mainly focus on information extraction (IE),\nneglecting tasks such as machine reading comprehension, question answering, and\ntext classification. Furthermore, the lack of diversity in the data has led to\na decreased generalization ability of trained LLMs in other NLU tasks and a\nnoticeable decline in the fundamental model's general capabilities. To address\nthis issue, we propose Hum, a large-scale, high-quality synthetic instruction\ncorpus for NLU tasks, designed to enhance the NLU capabilities of LLMs.\nSpecifically, Hum includes IE (either close IE or open IE), machine reading\ncomprehension, text classification, and instruction generalist tasks, thereby\nenriching task diversity. Additionally, we introduce a human-LLMs collaborative\nmechanism to synthesize instructions, which enriches instruction diversity by\nincorporating guidelines, preference rules, and format variants. We conduct\nextensive experiments on 5 NLU tasks and 28 general capability evaluation\ndatasets for LLMs. Experimental results show that Hum enhances the NLU\ncapabilities of six LLMs by an average of 3.1\\%, with no significant decline\nobserved in other general capabilities.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.03843v1",
    "published_date": "2025-02-06 07:53:40 UTC",
    "updated_date": "2025-02-06 07:53:40 UTC"
  },
  {
    "arxiv_id": "2502.04400v1",
    "title": "Adaptive Prototype Knowledge Transfer for Federated Learning with Mixed Modalities and Heterogeneous Tasks",
    "authors": [
      "Keke Gai",
      "Mohan Wang",
      "Jing Yu",
      "Dongjue Wang",
      "Qi Wu"
    ],
    "abstract": "Multimodal Federated Learning (MFL) enables multiple clients to\ncollaboratively train models on multimodal data while ensuring clients'\nprivacy. However, modality and task heterogeneity hinder clients from learning\na unified representation, weakening local model generalization, especially in\nMFL with mixed modalities where only some clients have multimodal data. In this\nwork, we propose an Adaptive prototype-based Multimodal Federated Learning\n(AproMFL) framework for mixed modalities and heterogeneous tasks to address the\naforementioned issues. Our AproMFL transfers knowledge through\nadaptively-constructed prototypes without a prior public dataset. Clients\nadaptively select prototype construction methods in line with tasks; server\nconverts client prototypes into unified multimodal prototypes and aggregates\nthem to form global prototypes, avoid clients keeping unified labels. We divide\nthe model into various modules and only aggregate mapping modules to reduce\ncommunication and computation overhead. To address aggregation issues in\nheterogeneity, we develop a client relationship graph-based scheme to\ndynamically adjust aggregation weights. Extensive experiments on representative\ndatasets evidence effectiveness of AproMFL.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.MM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04400v1",
    "published_date": "2025-02-06 07:28:05 UTC",
    "updated_date": "2025-02-06 07:28:05 UTC"
  },
  {
    "arxiv_id": "2502.03827v1",
    "title": "A comprehensive survey of contemporary Arabic sentiment analysis: Methods, Challenges, and Future Directions",
    "authors": [
      "Zhiqiang Shi",
      "Ruchit Agrawal"
    ],
    "abstract": "Sentiment Analysis, a popular subtask of Natural Language Processing, employs\ncomputational methods to extract sentiment, opinions, and other subjective\naspects from linguistic data. Given its crucial role in understanding human\nsentiment, research in sentiment analysis has witnessed significant growth in\nthe recent years. However, the majority of approaches are aimed at the English\nlanguage, and research towards Arabic sentiment analysis remains relatively\nunexplored. This paper presents a comprehensive and contemporary survey of\nArabic Sentiment Analysis, identifies the challenges and limitations of\nexisting literature in this field and presents avenues for future research. We\npresent a systematic review of Arabic sentiment analysis methods, focusing\nspecifically on research utilizing deep learning. We then situate Arabic\nSentiment Analysis within the broader context, highlighting research gaps in\nArabic sentiment analysis as compared to general sentiment analysis. Finally,\nwe outline the main challenges and promising future directions for research in\nArabic sentiment analysis.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Paper accepted to NAACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.03827v1",
    "published_date": "2025-02-06 07:23:51 UTC",
    "updated_date": "2025-02-06 07:23:51 UTC"
  },
  {
    "arxiv_id": "2502.04399v1",
    "title": "Online Location Planning for AI-Defined Vehicles: Optimizing Joint Tasks of Order Serving and Spatio-Temporal Heterogeneous Model Fine-Tuning",
    "authors": [
      "Bokeng Zheng",
      "Bo Rao",
      "Tianxiang Zhu",
      "Chee Wei Tan",
      "Jingpu Duan",
      "Zhi Zhou",
      "Xu Chen",
      "Xiaoxi Zhang"
    ],
    "abstract": "Advances in artificial intelligence (AI) including foundation models (FMs),\nare increasingly transforming human society, with smart city driving the\nevolution of urban living.Meanwhile, vehicle crowdsensing (VCS) has emerged as\na key enabler, leveraging vehicles' mobility and sensor-equipped capabilities.\nIn particular, ride-hailing vehicles can effectively facilitate flexible data\ncollection and contribute towards urban intelligence, despite resource\nlimitations. Therefore, this work explores a promising scenario, where\nedge-assisted vehicles perform joint tasks of order serving and the emerging\nfoundation model fine-tuning using various urban data. However, integrating the\nVCS AI task with the conventional order serving task is challenging, due to\ntheir inconsistent spatio-temporal characteristics: (i) The distributions of\nride orders and data point-of-interests (PoIs) may not coincide in geography,\nboth following a priori unknown patterns; (ii) they have distinct forms of\ntemporal effects, i.e., prolonged waiting makes orders become instantly invalid\nwhile data with increased staleness gradually reduces its utility for model\nfine-tuning.To overcome these obstacles, we propose an online framework based\non multi-agent reinforcement learning (MARL) with careful augmentation. A new\nquality-of-service (QoS) metric is designed to characterize and balance the\nutility of the two joint tasks, under the effects of varying data volumes and\nstaleness. We also integrate graph neural networks (GNNs) with MARL to enhance\nstate representations, capturing graph-structured, time-varying dependencies\namong vehicles and across locations. Extensive experiments on our testbed\nsimulator, utilizing various real-world foundation model fine-tuning tasks and\nthe New York City Taxi ride order dataset, demonstrate the advantage of our\nproposed method.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04399v1",
    "published_date": "2025-02-06 07:23:40 UTC",
    "updated_date": "2025-02-06 07:23:40 UTC"
  },
  {
    "arxiv_id": "2502.03824v3",
    "title": "Syntriever: How to Train Your Retriever with Synthetic Data from LLMs",
    "authors": [
      "Minsang Kim",
      "Seungjun Baek"
    ],
    "abstract": "LLMs have boosted progress in many AI applications. Recently, there were\nattempts to distill the vast knowledge of LLMs into information retrieval\nsystems. Those distillation methods mostly use output probabilities of LLMs\nwhich are unavailable in the latest black-box LLMs. We propose Syntriever, a\ntraining framework for retrievers using synthetic data from black-box LLMs.\nSyntriever consists of two stages. Firstly in the distillation stage, we\nsynthesize relevant and plausibly irrelevant passages and augmented queries\nusing chain-of-thoughts for the given queries. LLM is asked to self-verify the\nsynthetic data for possible hallucinations, after which retrievers are trained\nwith a loss designed to cluster the embeddings of relevant passages. Secondly\nin the alignment stage, we align the retriever with the preferences of LLMs. We\npropose a preference modeling called partial Plackett-Luce ranking to learn LLM\npreferences with regularization which prevents the model from deviating\nexcessively from that trained in the distillation stage. Experiments show that\nSyntriever achieves state-of-the-art performances on benchmark datasets from\nvarious domains in nDCG@$K$. The code is available at\n\\href{https://github.com/kmswin1/Syntriever}{https://github.com/kmswin1/Syntriever}.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "the Nations of the Americas Chapter of the Association for\n  Computational Linguistics (NAACL), Findings, Accepted",
    "pdf_url": "http://arxiv.org/pdf/2502.03824v3",
    "published_date": "2025-02-06 07:19:59 UTC",
    "updated_date": "2025-02-14 01:05:29 UTC"
  },
  {
    "arxiv_id": "2502.04397v2",
    "title": "Multimodal Medical Code Tokenizer",
    "authors": [
      "Xiaorui Su",
      "Shvat Messica",
      "Yepeng Huang",
      "Ruth Johnson",
      "Lukas Fesser",
      "Shanghua Gao",
      "Faryad Sahneh",
      "Marinka Zitnik"
    ],
    "abstract": "Foundation models trained on patient electronic health records (EHRs) require\ntokenizing medical data into sequences of discrete vocabulary items. Existing\ntokenizers treat medical codes from EHRs as isolated textual tokens. However,\neach medical code is defined by its textual description, its position in\nontological hierarchies, and its relationships to other codes, such as disease\nco-occurrences and drug-treatment associations. Medical vocabularies contain\nmore than 600,000 codes with critical information for clinical reasoning. We\nintroduce MedTok, a multimodal medical code tokenizer that uses the text\ndescriptions and relational context of codes. MedTok processes text using a\nlanguage model encoder and encodes the relational structure with a graph\nencoder. It then quantizes both modalities into a unified token space,\npreserving modality-specific and cross-modality information. We integrate\nMedTok into five EHR models and evaluate it on operational and clinical tasks\nacross in-patient and out-patient datasets, including outcome prediction,\ndiagnosis classification, drug recommendation, and risk stratification.\nSwapping standard EHR tokenizers with MedTok improves AUPRC across all EHR\nmodels, by 4.10% on MIMIC-III, 4.78% on MIMIC-IV, and 11.30% on EHRShot, with\nthe largest gains in drug recommendation. Beyond EHR modeling, we demonstrate\nusing MedTok tokenizer with medical QA systems. Our results demonstrate the\npotential of MedTok as a unified tokenizer for medical codes, improving\ntokenization for medical foundation models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "conference",
    "pdf_url": "http://arxiv.org/pdf/2502.04397v2",
    "published_date": "2025-02-06 06:58:09 UTC",
    "updated_date": "2025-02-12 22:26:50 UTC"
  },
  {
    "arxiv_id": "2502.03814v3",
    "title": "Large Language Models for Multi-Robot Systems: A Survey",
    "authors": [
      "Peihan Li",
      "Zijian An",
      "Shams Abrar",
      "Lifeng Zhou"
    ],
    "abstract": "The rapid advancement of Large Language Models (LLMs) has opened new\npossibilities in Multi-Robot Systems (MRS), enabling enhanced communication,\ntask planning, and human-robot interaction. Unlike traditional single-robot and\nmulti-agent systems, MRS poses unique challenges, including coordination,\nscalability, and real-world adaptability. This survey provides the first\ncomprehensive exploration of LLM integration into MRS. It systematically\ncategorizes their applications across high-level task allocation, mid-level\nmotion planning, low-level action generation, and human intervention. We\nhighlight key applications in diverse domains, such as household robotics,\nconstruction, formation control, target tracking, and robot games, showcasing\nthe versatility and transformative potential of LLMs in MRS. Furthermore, we\nexamine the challenges that limit adapting LLMs in MRS, including mathematical\nreasoning limitations, hallucination, latency issues, and the need for robust\nbenchmarking systems. Finally, we outline opportunities for future research,\nemphasizing advancements in fine-tuning, reasoning techniques, and\ntask-specific models. This survey aims to guide researchers in the intelligence\nand real-world deployment of MRS powered by LLMs. Based on the fast-evolving\nnature of research in the field, we keep updating the papers in the open-source\nGithub repository.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03814v3",
    "published_date": "2025-02-06 06:52:14 UTC",
    "updated_date": "2025-02-12 23:25:18 UTC"
  },
  {
    "arxiv_id": "2502.03804v2",
    "title": "Understanding and Supporting Formal Email Exchange by Answering AI-Generated Questions",
    "authors": [
      "Yusuke Miura",
      "Chi-Lan Yang",
      "Masaki Kuribayashi",
      "Keigo Matsumoto",
      "Hideaki Kuzuoka",
      "Shigeo Morishima"
    ],
    "abstract": "Replying to formal emails is time-consuming and cognitively demanding, as it\nrequires crafting polite phrasing and providing an adequate response to the\nsender's demands. Although systems with Large Language Models (LLMs) were\ndesigned to simplify the email replying process, users still need to provide\ndetailed prompts to obtain the expected output. Therefore, we proposed and\nevaluated an LLM-powered question-and-answer (QA)-based approach for users to\nreply to emails by answering a set of simple and short questions generated from\nthe incoming email. We developed a prototype system, ResQ, and conducted\ncontrolled and field experiments with 12 and 8 participants. Our results\ndemonstrated that the QA-based approach improves the efficiency of replying to\nemails and reduces workload while maintaining email quality, compared to a\nconventional prompt-based approach that requires users to craft appropriate\nprompts to obtain email drafts. We discuss how the QA-based approach influences\nthe email reply process and interpersonal relationship dynamics, as well as the\nopportunities and challenges associated with using a QA-based approach in\nAI-mediated communication.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03804v2",
    "published_date": "2025-02-06 06:27:09 UTC",
    "updated_date": "2025-02-07 02:45:17 UTC"
  },
  {
    "arxiv_id": "2502.18480v1",
    "title": "QExplorer: Large Language Model Based Query Extraction for Toxic Content Exploration",
    "authors": [
      "Shaola Ren",
      "Li Ke",
      "Longtao Huang",
      "Dehong Gao",
      "Hui Xue"
    ],
    "abstract": "Automatically extracting effective queries is challenging in information\nretrieval, especially in toxic content exploration, as such content is likely\nto be disguised. With the recent achievements in generative Large Language\nModel (LLM), we are able to leverage the capabilities of LLMs to extract\neffective queries for similar content exploration directly. This study proposes\nQExplorer, an approach of large language model based Query Extraction for toxic\ncontent Exploration. The QExplorer approach involves a 2-stage training\nprocess: instruction Supervised FineTuning (SFT) and preference alignment using\nDirect Preference Optimization (DPO), as well as the datasets construction with\nfeedback of search system. To verify the effectiveness of QExplorer, a series\nof offline and online experiments are conducted on our real-world system. The\noffline empirical results demonstrate that the performance of our automatic\nquery extraction outperforms that of several LLMs and humans. The online\ndeployment shows a significant increase in the detection of toxic items.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.18480v1",
    "published_date": "2025-02-06 06:11:58 UTC",
    "updated_date": "2025-02-06 06:11:58 UTC"
  },
  {
    "arxiv_id": "2502.03801v1",
    "title": "SoK: Benchmarking Poisoning Attacks and Defenses in Federated Learning",
    "authors": [
      "Heyi Zhang",
      "Yule Liu",
      "Xinlei He",
      "Jun Wu",
      "Tianshuo Cong",
      "Xinyi Huang"
    ],
    "abstract": "Federated learning (FL) enables collaborative model training while preserving\ndata privacy, but its decentralized nature exposes it to client-side data\npoisoning attacks (DPAs) and model poisoning attacks (MPAs) that degrade global\nmodel performance. While numerous proposed defenses claim substantial\neffectiveness, their evaluation is typically done in isolation with limited\nattack strategies, raising concerns about their validity. Additionally,\nexisting studies overlook the mutual effectiveness of defenses against both\nDPAs and MPAs, causing fragmentation in this field. This paper aims to provide\na unified benchmark and analysis of defenses against DPAs and MPAs, clarifying\nthe distinction between these two similar but slightly distinct domains. We\npresent a systematic taxonomy of poisoning attacks and defense strategies,\noutlining their design, strengths, and limitations. Then, a unified comparative\nevaluation across FL algorithms and data heterogeneity is conducted to validate\ntheir individual and mutual effectiveness and derive key insights for design\nprinciples and future research. Along with the analysis, we frame our work to a\nunified benchmark, FLPoison, with high modularity and scalability to evaluate\n15 representative poisoning attacks and 17 defense strategies, facilitating\nfuture research in this domain. Code is available at\nhttps://github.com/vio1etus/FLPoison.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03801v1",
    "published_date": "2025-02-06 06:05:00 UTC",
    "updated_date": "2025-02-06 06:05:00 UTC"
  },
  {
    "arxiv_id": "2502.05227v1",
    "title": "Robotouille: An Asynchronous Planning Benchmark for LLM Agents",
    "authors": [
      "Gonzalo Gonzalez-Pumariega",
      "Leong Su Yean",
      "Neha Sunkara",
      "Sanjiban Choudhury"
    ],
    "abstract": "Effective asynchronous planning, or the ability to efficiently reason and\nplan over states and actions that must happen in parallel or sequentially, is\nessential for agents that must account for time delays, reason over diverse\nlong-horizon tasks, and collaborate with other agents. While large language\nmodel (LLM) agents show promise in high-level task planning, current benchmarks\nfocus primarily on short-horizon tasks and do not evaluate such asynchronous\nplanning capabilities. We introduce Robotouille, a challenging benchmark\nenvironment designed to test LLM agents' ability to handle long-horizon\nasynchronous scenarios. Our synchronous and asynchronous datasets capture\nincreasingly complex planning challenges that go beyond existing benchmarks,\nrequiring agents to manage overlapping tasks and interruptions. Our results\nshow that ReAct (gpt4-o) achieves 47% on synchronous tasks but only 11% on\nasynchronous tasks, highlighting significant room for improvement. We further\nanalyze failure modes, demonstrating the need for LLM agents to better\nincorporate long-horizon feedback and self-audit their reasoning during task\nexecution. Code is available at https://github.com/portal-cornell/robotouille.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.RO",
    "comment": "11 pages (not including references or appendix); 41 figures (7 main\n  paper, 34 appendix); (v1) preprint",
    "pdf_url": "http://arxiv.org/pdf/2502.05227v1",
    "published_date": "2025-02-06 05:50:37 UTC",
    "updated_date": "2025-02-06 05:50:37 UTC"
  },
  {
    "arxiv_id": "2502.03793v2",
    "title": "It's All in The [MASK]: Simple Instruction-Tuning Enables BERT-like Masked Language Models As Generative Classifiers",
    "authors": [
      "Benjamin Clavié",
      "Nathan Cooper",
      "Benjamin Warner"
    ],
    "abstract": "While encoder-only models such as BERT and ModernBERT are ubiquitous in\nreal-world NLP applications, their conventional reliance on task-specific\nclassification heads can limit their applicability compared to decoder-based\nlarge language models (LLMs). In this work, we introduce\nModernBERT-Large-Instruct, a 0.4B-parameter encoder model that leverages its\nmasked language modelling (MLM) head for generative classification. Our\napproach employs an intentionally simple training loop and inference mechanism\nthat requires no heavy pre-processing, heavily engineered prompting, or\narchitectural modifications. ModernBERT-Large-Instruct exhibits strong\nzero-shot performance on both classification and knowledge-based tasks,\noutperforming similarly sized LLMs on MMLU and achieving 93% of Llama3-1B's\nMMLU performance with 60% less parameters. We also demonstrate that, when\nfine-tuned, the generative approach using the MLM head matches or even\nsurpasses traditional classification-head methods across diverse NLU tasks.This\ncapability emerges specifically in models trained on contemporary, diverse data\nmixes, with models trained on lower volume, less-diverse data yielding\nconsiderably weaker performance. Although preliminary, these results\ndemonstrate the potential of using the original generative masked language\nmodelling head over traditional task-specific heads for downstream tasks. Our\nwork suggests that further exploration into this area is warranted,\nhighlighting many avenues for future improvements.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03793v2",
    "published_date": "2025-02-06 05:47:37 UTC",
    "updated_date": "2025-02-10 14:08:19 UTC"
  },
  {
    "arxiv_id": "2502.08474v1",
    "title": "Training-Free Restoration of Pruned Neural Networks",
    "authors": [
      "Keonho Lee",
      "Minsoo Kim",
      "Dong-Wan Choi"
    ],
    "abstract": "Although network pruning has been highly popularized to compress deep neural\nnetworks, its resulting accuracy heavily depends on a fine-tuning process that\nis often computationally expensive and requires the original data. However,\nthis may not be the case in real-world scenarios, and hence a few recent works\nattempt to restore pruned networks without any expensive retraining process.\nTheir strong assumption is that every neuron being pruned can be replaced with\nanother one quite similar to it, but unfortunately this does not hold in many\nneural networks, where the similarity between neurons is extremely low in some\nlayers. In this article, we propose a more rigorous and robust method of\nrestoring pruned networks in a fine-tuning free and data-free manner, called\nLBYL (Leave Before You Leave). LBYL significantly relaxes the aforementioned\nassumption in a way that each pruned neuron leaves its pieces of information to\nas many preserved neurons as possible and thereby multiple neurons together\nobtain a more robust approximation to the original output of the neuron who\njust left. Our method is based on a theoretical analysis on how to formulate\nthe reconstruction error between the original network and its approximation,\nwhich nicely leads to a closed form solution for our derived loss function.\nThrough the extensive experiments, LBYL is confirmed to be indeed more\neffective to approximate the original network and consequently able to achieve\nhigher accuracy for restored networks, compared to the recent approaches\nexploiting the similarity between two neurons. The very first version of this\nwork, which contains major technical and theoretical components, was submitted\nto NeurIPS 2021 and ICML 2022.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Under Review in TNNLS since May 2022",
    "pdf_url": "http://arxiv.org/pdf/2502.08474v1",
    "published_date": "2025-02-06 05:30:48 UTC",
    "updated_date": "2025-02-06 05:30:48 UTC"
  },
  {
    "arxiv_id": "2502.05225v1",
    "title": "BitAbuse: A Dataset of Visually Perturbed Texts for Defending Phishing Attacks",
    "authors": [
      "Hanyong Lee",
      "Chaelyn Lee",
      "Yongjae Lee",
      "Jaesung Lee"
    ],
    "abstract": "Phishing often targets victims through visually perturbed texts to bypass\nsecurity systems. The noise contained in these texts functions as an\nadversarial attack, designed to deceive language models and hinder their\nability to accurately interpret the content. However, since it is difficult to\nobtain sufficient phishing cases, previous studies have used synthetic datasets\nthat do not contain real-world cases. In this study, we propose the BitAbuse\ndataset, which includes real-world phishing cases, to address the limitations\nof previous research. Our dataset comprises a total of 325,580 visually\nperturbed texts. The dataset inputs are drawn from the raw corpus, consisting\nof visually perturbed sentences and sentences generated through an artificial\nperturbation process. Each input sentence is labeled with its corresponding\nground truth, representing the restored, non-perturbed version. Language models\ntrained on our proposed dataset demonstrated significantly better performance\ncompared to previous methods, achieving an accuracy of approximately 96%. Our\nanalysis revealed a significant gap between real-world and synthetic examples,\nunderscoring the value of our dataset for building reliable pre-trained models\nfor restoration tasks. We release the BitAbuse dataset, which includes\nreal-world phishing cases annotated with visual perturbations, to support\nfuture research in adversarial attack defense.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "18 pages, To appear in the Annual Conference of the Nations of the\n  Americas Chapter of the Association for Computational Linguistics 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.05225v1",
    "published_date": "2025-02-06 05:04:04 UTC",
    "updated_date": "2025-02-06 05:04:04 UTC"
  },
  {
    "arxiv_id": "2502.05224v1",
    "title": "A Survey on Backdoor Threats in Large Language Models (LLMs): Attacks, Defenses, and Evaluations",
    "authors": [
      "Yihe Zhou",
      "Tao Ni",
      "Wei-Bin Lee",
      "Qingchuan Zhao"
    ],
    "abstract": "Large Language Models (LLMs) have achieved significantly advanced\ncapabilities in understanding and generating human language text, which have\ngained increasing popularity over recent years. Apart from their\nstate-of-the-art natural language processing (NLP) performance, considering\ntheir widespread usage in many industries, including medicine, finance,\neducation, etc., security concerns over their usage grow simultaneously. In\nrecent years, the evolution of backdoor attacks has progressed with the\nadvancement of defense mechanisms against them and more well-developed features\nin the LLMs. In this paper, we adapt the general taxonomy for classifying\nmachine learning attacks on one of the subdivisions - training-time white-box\nbackdoor attacks. Besides systematically classifying attack methods, we also\nconsider the corresponding defense methods against backdoor attacks. By\nproviding an extensive summary of existing works, we hope this survey can serve\nas a guideline for inspiring future research that further extends the attack\nscenarios and creates a stronger defense against them for more robust LLMs.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05224v1",
    "published_date": "2025-02-06 04:43:05 UTC",
    "updated_date": "2025-02-06 04:43:05 UTC"
  },
  {
    "arxiv_id": "2503.04747v1",
    "title": "E-LENS: User Requirements-Oriented AI Ethics Assurance",
    "authors": [
      "Jianlong Zhou",
      "Fang Chen"
    ],
    "abstract": "Despite the much proliferation of AI ethical principles in recent years,\nthere is a challenge of assuring AI ethics with current AI ethics frameworks in\nreal-world applications. While system safety has emerged as a distinct\ndiscipline for a long time, originated from safety concerns in early aircraft\nmanufacturing. The safety assurance is now an indispensable component in safety\ncritical domains. Motivated by the assurance approaches for safety-critical\nsystems such as aviation, this paper introduces the concept of AI ethics\nassurance cases into the AI ethics assurance. Three pillars of user\nrequirements, evidence, and validation are proposed as key components and\nintegrated into AI ethics assurance cases for a new approach of user\nrequirements-oriented AI ethics assurance. The user requirements-oriented AI\nethics assurance case is set up based on three pillars and hazard analysis\nmethods used in the safety assurance of safety-critical systems. This paper\nalso proposes a platform named Ethical-Lens (E-LENS) to implement the user\nrequirements-oriented AI ethics assurance approach. The proposed user\nrequirements-based E-LENS platform is then applied to assure AI ethics of an\nAI-driven human resource shortlisting system as a case study to show the\neffectiveness of the proposed approach.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "29 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.04747v1",
    "published_date": "2025-02-06 04:37:55 UTC",
    "updated_date": "2025-02-06 04:37:55 UTC"
  },
  {
    "arxiv_id": "2502.03773v1",
    "title": "ExpProof : Operationalizing Explanations for Confidential Models with ZKPs",
    "authors": [
      "Chhavi Yadav",
      "Evan Monroe Laufer",
      "Dan Boneh",
      "Kamalika Chaudhuri"
    ],
    "abstract": "In principle, explanations are intended as a way to increase trust in machine\nlearning models and are often obligated by regulations. However, many\ncircumstances where these are demanded are adversarial in nature, meaning the\ninvolved parties have misaligned interests and are incentivized to manipulate\nexplanations for their purpose. As a result, explainability methods fail to be\noperational in such settings despite the demand \\cite{bordt2022post}. In this\npaper, we take a step towards operationalizing explanations in adversarial\nscenarios with Zero-Knowledge Proofs (ZKPs), a cryptographic primitive.\nSpecifically we explore ZKP-amenable versions of the popular explainability\nalgorithm LIME and evaluate their performance on Neural Networks and Random\nForests.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03773v1",
    "published_date": "2025-02-06 04:24:29 UTC",
    "updated_date": "2025-02-06 04:24:29 UTC"
  },
  {
    "arxiv_id": "2502.03772v2",
    "title": "A Retrospective Systematic Study on Hierarchical Sparse Query Transformer-assisted Ultrasound Screening for Early Hepatocellular Carcinoma",
    "authors": [
      "Chaoyin She",
      "Ruifang Lu",
      "Danni He",
      "Jiayi Lv",
      "Yadan Lin",
      "Meiqing Cheng",
      "Hui Huang",
      "Fengyu Ye",
      "Lida Chen",
      "Wei Wang",
      "Qinghua Huang"
    ],
    "abstract": "Hepatocellular carcinoma (HCC), ranking as the third leading cause of\ncancer-related mortality worldwide, demands urgent improvements in early\ndetection to enhance patient survival. While ultrasound remains the preferred\nscreening modality due to its cost-effectiveness and real-time capabilities,\nits sensitivity (59%-78%) heavily relies on radiologists' expertise, leading to\ninconsistent diagnostic outcomes and operational inefficiencies. Recent\nadvancements in AI technology offer promising solutions to bridge this gap.\nThis study introduces the Hierarchical Sparse Query Transformer (HSQformer), a\nnovel hybrid architecture that synergizes CNNs' local feature extraction with\nVision Transformers' global contextual awareness through latent space\nrepresentation and sparse learning. By dynamically activating task-specific\nexperts via a Mixture-of-Experts (MoE) framework, HSQformer achieves\nhierarchical feature integration without structural redundancy. Evaluated\nacross three clinical scenarios: single-center, multi-center, and high-risk\npatient cohorts, HSQformer outperforms state-of-the-art models (e.g., 95.38%\nAUC in multi-center testing) and matches senior radiologists' diagnostic\naccuracy while significantly surpassing junior counterparts. These results\nhighlight the potential of AI-assisted tools to standardize HCC screening,\nreduce dependency on human expertise, and improve early diagnosis rates. The\nfull code is available at https://github.com/Asunatan/HSQformer.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03772v2",
    "published_date": "2025-02-06 04:17:02 UTC",
    "updated_date": "2025-03-20 06:38:41 UTC"
  },
  {
    "arxiv_id": "2502.04394v1",
    "title": "DECT: Harnessing LLM-assisted Fine-Grained Linguistic Knowledge and Label-Switched and Label-Preserved Data Generation for Diagnosis of Alzheimer's Disease",
    "authors": [
      "Tingyu Mo",
      "Jacqueline C. K. Lam",
      "Victor O. K. Li",
      "Lawrence Y. L. Cheung"
    ],
    "abstract": "Alzheimer's Disease (AD) is an irreversible neurodegenerative disease\naffecting 50 million people worldwide. Low-cost, accurate identification of key\nmarkers of AD is crucial for timely diagnosis and intervention. Language\nimpairment is one of the earliest signs of cognitive decline, which can be used\nto discriminate AD patients from normal control individuals.\nPatient-interviewer dialogues may be used to detect such impairments, but they\nare often mixed with ambiguous, noisy, and irrelevant information, making the\nAD detection task difficult. Moreover, the limited availability of AD speech\nsamples and variability in their speech styles pose significant challenges in\ndeveloping robust speech-based AD detection models. To address these\nchallenges, we propose DECT, a novel speech-based domain-specific approach\nleveraging large language models (LLMs) for fine-grained linguistic analysis\nand label-switched label-preserved data generation. Our study presents four\nnovelties: We harness the summarizing capabilities of LLMs to identify and\ndistill key Cognitive-Linguistic information from noisy speech transcripts,\neffectively filtering irrelevant information. We leverage the inherent\nlinguistic knowledge of LLMs to extract linguistic markers from unstructured\nand heterogeneous audio transcripts. We exploit the compositional ability of\nLLMs to generate AD speech transcripts consisting of diverse linguistic\npatterns to overcome the speech data scarcity challenge and enhance the\nrobustness of AD detection models. We use the augmented AD textual speech\ntranscript dataset and a more fine-grained representation of AD textual speech\ntranscript data to fine-tune the AD detection model. The results have shown\nthat DECT demonstrates superior model performance with an 11% improvement in AD\ndetection accuracy on the datasets from DementiaBank compared to the baselines.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04394v1",
    "published_date": "2025-02-06 04:00:25 UTC",
    "updated_date": "2025-02-06 04:00:25 UTC"
  },
  {
    "arxiv_id": "2502.03752v2",
    "title": "PRISM: A Robust Framework for Skill-based Meta-Reinforcement Learning with Noisy Demonstrations",
    "authors": [
      "Sanghyeon Lee",
      "Sangjun Bae",
      "Yisak Park",
      "Seungyul Han"
    ],
    "abstract": "Meta-reinforcement learning (Meta-RL) facilitates rapid adaptation to unseen\ntasks but faces challenges in long-horizon environments. Skill-based approaches\ntackle this by decomposing state-action sequences into reusable skills and\nemploying hierarchical decision-making. However, these methods are highly\nsusceptible to noisy offline demonstrations, resulting in unstable skill\nlearning and degraded performance. To overcome this, we propose Prioritized\nRefinement for Skill-Based Meta-RL (PRISM), a robust framework that integrates\nexploration near noisy data to generate online trajectories and combines them\nwith offline data. Through prioritization, PRISM extracts high-quality data to\nlearn task-relevant skills effectively. By addressing the impact of noise, our\nmethod ensures stable skill learning and achieves superior performance in\nlong-horizon tasks, even with noisy and sub-optimal data.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages main, 19 pages appendix with reference. Submitted to ICML\n  2025",
    "pdf_url": "http://arxiv.org/pdf/2502.03752v2",
    "published_date": "2025-02-06 03:28:45 UTC",
    "updated_date": "2025-02-14 11:02:01 UTC"
  },
  {
    "arxiv_id": "2502.03750v1",
    "title": "Principal Curvatures Estimation with Applications to Single Cell Data",
    "authors": [
      "Yanlei Zhang",
      "Lydia Mezrag",
      "Xingzhi Sun",
      "Charles Xu",
      "Kincaid Macdonald",
      "Dhananjay Bhaskar",
      "Smita Krishnaswamy",
      "Guy Wolf",
      "Bastian Rieck"
    ],
    "abstract": "The rapidly growing field of single-cell transcriptomic sequencing (scRNAseq)\npresents challenges for data analysis due to its massive datasets. A common\nmethod in manifold learning consists in hypothesizing that datasets lie on a\nlower dimensional manifold. This allows to study the geometry of point clouds\nby extracting meaningful descriptors like curvature. In this work, we will\npresent Adaptive Local PCA (AdaL-PCA), a data-driven method for accurately\nestimating various notions of intrinsic curvature on data manifolds, in\nparticular principal curvatures for surfaces. The model relies on local PCA to\nestimate the tangent spaces. The evaluation of AdaL-PCA on sampled surfaces\nshows state-of-the-art results. Combined with a PHATE embedding, the model\napplied to single-cell RNA sequencing data allows us to identify key variations\nin the cellular differentiation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "To be published in ICASSP 2025-2025 IEEE International Conference on\n  Acoustics, Speech and Signal Processing (ICASSP)",
    "pdf_url": "http://arxiv.org/pdf/2502.03750v1",
    "published_date": "2025-02-06 03:23:31 UTC",
    "updated_date": "2025-02-06 03:23:31 UTC"
  },
  {
    "arxiv_id": "2502.03740v1",
    "title": "Multiple Invertible and Partial-Equivariant Function for Latent Vector Transformation to Enhance Disentanglement in VAEs",
    "authors": [
      "Hee-Jun Jung",
      "Jaehyoung Jeong",
      "Kangil Kim"
    ],
    "abstract": "Disentanglement learning is a core issue for understanding and re-using\ntrained information in Variational AutoEncoder (VAE), and effective inductive\nbias has been reported as a key factor. However, the actual implementation of\nsuch bias is still vague. In this paper, we propose a novel method, called\nMultiple Invertible and partial-equivariant transformation\n(MIPE-transformation), to inject inductive bias by 1) guaranteeing the\ninvertibility of latent-to-latent vector transformation while preserving a\ncertain portion of equivariance of input-to-latent vector transformation,\ncalled Invertible and partial-equivariant transformation (IPE-transformation),\n2) extending the form of prior and posterior in VAE frameworks to an\nunrestricted form through a learnable conversion to an approximated exponential\nfamily, called Exponential Family conversion (EF-conversion), and 3)\nintegrating multiple units of IPE-transformation and EF-conversion, and their\ntraining. In experiments on 3D Cars, 3D Shapes, and dSprites datasets,\nMIPE-transformation improves the disentanglement performance of\nstate-of-the-art VAEs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "24 pages, 21 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.03740v1",
    "published_date": "2025-02-06 03:08:12 UTC",
    "updated_date": "2025-02-06 03:08:12 UTC"
  },
  {
    "arxiv_id": "2502.03729v2",
    "title": "Action-Free Reasoning for Policy Generalization",
    "authors": [
      "Jaden Clark",
      "Suvir Mirchandani",
      "Dorsa Sadigh",
      "Suneel Belkhale"
    ],
    "abstract": "End-to-end imitation learning offers a promising approach for training robot\npolicies. However, generalizing to new settings remains a significant\nchallenge. Although large-scale robot demonstration datasets have shown\npotential for inducing generalization, they are resource-intensive to scale. In\ncontrast, human video data is abundant and diverse, presenting an attractive\nalternative. Yet, these human-video datasets lack action labels, complicating\ntheir use in imitation learning. Existing methods attempt to extract grounded\naction representations (e.g., hand poses), but resulting policies struggle to\nbridge the embodiment gap between human and robot actions. We propose an\nalternative approach: leveraging language-based reasoning from human\nvideos-essential for guiding robot actions-to train generalizable robot\npolicies. Building on recent advances in reasoning-based policy architectures,\nwe introduce Reasoning through Action-free Data (RAD). RAD learns from both\nrobot demonstration data (with reasoning and action labels) and action-free\nhuman video data (with only reasoning labels). The robot data teaches the model\nto map reasoning to low-level actions, while the action-free data enhances\nreasoning capabilities. Additionally, we will release a new dataset of 3,377\nhuman-hand demonstrations with reasoning annotations compatible with the Bridge\nV2 benchmark and aimed at facilitating future research on reasoning-driven\nrobot learning. Our experiments show that RAD enables effective transfer across\nthe embodiment gap, allowing robots to perform tasks seen only in action-free\ndata. Furthermore, scaling up action-free reasoning data significantly improves\npolicy performance and generalization to novel tasks. These results highlight\nthe promise of reasoning-driven learning from action-free datasets for\nadvancing generalizable robot control. Project page:\nhttps://rad-generalization.github.io",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "13 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.03729v2",
    "published_date": "2025-02-06 02:43:23 UTC",
    "updated_date": "2025-02-11 04:51:45 UTC"
  },
  {
    "arxiv_id": "2502.04392v1",
    "title": "Division-of-Thoughts: Harnessing Hybrid Language Model Synergy for Efficient On-Device Agents",
    "authors": [
      "Chenyang Shao",
      "Xinyuan Hu",
      "Yutang Lin",
      "Fengli Xu"
    ],
    "abstract": "The rapid expansion of web content has made on-device AI assistants\nindispensable for helping users manage the increasing complexity of online\ntasks. The emergent reasoning ability in large language models offer a\npromising path for next-generation on-device AI agents. However, deploying\nfull-scale Large Language Models (LLMs) on resource-limited local devices is\nchallenging. In this paper, we propose Division-of-Thoughts (DoT), a\ncollaborative reasoning framework leveraging the synergy between locally\ndeployed Smaller-scale Language Models (SLMs) and cloud-based LLMs. DoT\nleverages a Task Decomposer to elicit the inherent planning abilities in\nlanguage models to decompose user queries into smaller sub-tasks, which allows\nhybrid language models to fully exploit their respective strengths. Besides,\nDoT employs a Task Scheduler to analyze the pair-wise dependency of sub-tasks\nand create a dependency graph, facilitating parallel reasoning of sub-tasks and\nthe identification of key steps. To allocate the appropriate model based on the\ndifficulty of sub-tasks, DoT leverages a Plug-and-Play Adapter, which is an\nadditional task head attached to the SLM that does not alter the SLM's\nparameters. To boost adapter's task allocation capability, we propose a\nself-reinforced training method that relies solely on task execution feedback.\nExtensive experiments on various benchmarks demonstrate that our DoT\nsignificantly reduces LLM costs while maintaining competitive reasoning\naccuracy. Specifically, DoT reduces the average reasoning time and API costs by\n66.12% and 83.57%, while achieving comparable reasoning accuracy with the best\nbaseline methods.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04392v1",
    "published_date": "2025-02-06 02:40:25 UTC",
    "updated_date": "2025-02-06 02:40:25 UTC"
  },
  {
    "arxiv_id": "2502.06836v1",
    "title": "CAST: Cross Attention based multimodal fusion of Structure and Text for materials property prediction",
    "authors": [
      "Jaewan Lee",
      "Changyoung Park",
      "Hongjun Yang",
      "Sungbin Lim",
      "Sehui Han"
    ],
    "abstract": "Recent advancements in AI have revolutionized property prediction in\nmaterials science and accelerating material discovery. Graph neural networks\n(GNNs) stand out due to their ability to represent crystal structures as\ngraphs, effectively capturing local interactions and delivering superior\npredictions. However, these methods often lose critical global information,\nsuch as crystal systems and repetitive unit connectivity. To address this, we\npropose CAST, a cross-attention-based multimodal fusion model that integrates\ngraph and text modalities to preserve essential material information. CAST\ncombines node- and token-level features using cross-attention mechanisms,\nsurpassing previous approaches reliant on material-level embeddings like graph\nmean-pooling or [CLS] tokens. A masked node prediction pretraining strategy\nfurther enhances atomic-level information integration. Our method achieved up\nto 22.9\\% improvement in property prediction across four crystal properties\nincluding band gap compared to methods like CrysMMNet and MultiMat. Pretraining\nwas key to aligning node and text embeddings, with attention maps confirming\nits effectiveness in capturing relationships between nodes and tokens. This\nstudy highlights the potential of multimodal learning in materials science,\npaving the way for more robust predictive models that incorporate both local\nand global information.",
    "categories": [
      "cs.LG",
      "cond-mat.mtrl-sci",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.06836v1",
    "published_date": "2025-02-06 02:29:39 UTC",
    "updated_date": "2025-02-06 02:29:39 UTC"
  },
  {
    "arxiv_id": "2502.03724v1",
    "title": "MD-BERT: Action Recognition in Dark Videos via Dynamic Multi-Stream Fusion and Temporal Modeling",
    "authors": [
      "Sharana Dharshikgan Suresh Dass",
      "Hrishav Bakul Barua",
      "Ganesh Krishnasamy",
      "Raveendran Paramesran",
      "Raphael C. -W. Phan"
    ],
    "abstract": "Action recognition in dark, low-light (under-exposed) or noisy videos is a\nchallenging task due to visibility degradation, which can hinder critical\nspatiotemporal details. This paper proposes MD-BERT, a novel multi-stream\napproach that integrates complementary pre-processing techniques such as gamma\ncorrection and histogram equalization alongside raw dark frames to address\nthese challenges. We introduce the Dynamic Feature Fusion (DFF) module,\nextending existing attentional fusion methods to a three-stream setting,\nthereby capturing fine-grained and global contextual information across\ndifferent brightness and contrast enhancements. The fused spatiotemporal\nfeatures are then processed by a BERT-based temporal model, which leverages its\nbidirectional self-attention to effectively capture long-range dependencies and\ncontextual relationships across frames. Extensive experiments on the ARID V1.0\nand ARID V1.5 dark video datasets show that MD-BERT outperforms existing\nmethods, establishing a new state-of-the-art performance. Ablation studies\nfurther highlight the individual contributions of each input stream and the\neffectiveness of the proposed DFF and BERT modules. The official website of\nthis work is available at: https://github.com/HrishavBakulBarua/DarkBERT",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC",
      "cs.LG",
      "cs.MM",
      "Artificial intelligence, Computer vision, Machine learning, Deep\n  learning, Human-computer Interaction",
      "I.2; I.2.9; I.2.10; I.3.3; I.4.5"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03724v1",
    "published_date": "2025-02-06 02:26:47 UTC",
    "updated_date": "2025-02-06 02:26:47 UTC"
  },
  {
    "arxiv_id": "2502.10425v2",
    "title": "Neuron Platonic Intrinsic Representation From Dynamics Using Contrastive Learning",
    "authors": [
      "Wei Wu",
      "Can Liao",
      "Zizhen Deng",
      "Zhengrui Guo",
      "Jinzhuo Wang"
    ],
    "abstract": "The Platonic Representation Hypothesis suggests a universal,\nmodality-independent reality representation behind different data modalities.\nInspired by this, we view each neuron as a system and detect its multi-segment\nactivity data under various peripheral conditions. We assume there's a\ntime-invariant representation for the same neuron, reflecting its intrinsic\nproperties like molecular profiles, location, and morphology. The goal of\nobtaining these intrinsic neuronal representations has two criteria: (I)\nsegments from the same neuron should have more similar representations than\nthose from different neurons; (II) the representations must generalize well to\nout-of-domain data. To meet these, we propose the NeurPIR (Neuron Platonic\nIntrinsic Representation) framework. It uses contrastive learning, with\nsegments from the same neuron as positive pairs and those from different\nneurons as negative pairs. In implementation, we use VICReg, which focuses on\npositive pairs and separates dissimilar samples via regularization. We tested\nour method on Izhikevich model-simulated neuronal population dynamics data. The\nresults accurately identified neuron types based on preset hyperparameters. We\nalso applied it to two real-world neuron dynamics datasets with neuron type\nannotations from spatial transcriptomics and neuron locations. Our model's\nlearned representations accurately predicted neuron types and locations and\nwere robust on out-of-domain data (from unseen animals). This shows the\npotential of our approach for understanding neuronal systems and future\nneuroscience research.",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "q-bio.NC",
    "comment": "Accepted by ICLR'2025",
    "pdf_url": "http://arxiv.org/pdf/2502.10425v2",
    "published_date": "2025-02-06 02:22:23 UTC",
    "updated_date": "2025-02-18 11:07:58 UTC"
  },
  {
    "arxiv_id": "2502.03717v2",
    "title": "Efficiently Generating Expressive Quadruped Behaviors via Language-Guided Preference Learning",
    "authors": [
      "Jaden Clark",
      "Joey Hejna",
      "Dorsa Sadigh"
    ],
    "abstract": "Expressive robotic behavior is essential for the widespread acceptance of\nrobots in social environments. Recent advancements in learned legged locomotion\ncontrollers have enabled more dynamic and versatile robot behaviors. However,\ndetermining the optimal behavior for interactions with different users across\nvaried scenarios remains a challenge. Current methods either rely on natural\nlanguage input, which is efficient but low-resolution, or learn from human\npreferences, which, although high-resolution, is sample inefficient. This paper\nintroduces a novel approach that leverages priors generated by pre-trained LLMs\nalongside the precision of preference learning. Our method, termed\nLanguage-Guided Preference Learning (LGPL), uses LLMs to generate initial\nbehavior samples, which are then refined through preference-based feedback to\nlearn behaviors that closely align with human expectations. Our core insight is\nthat LLMs can guide the sampling process for preference learning, leading to a\nsubstantial improvement in sample efficiency. We demonstrate that LGPL can\nquickly learn accurate and expressive behaviors with as few as four queries,\noutperforming both purely language-parameterized models and traditional\npreference learning approaches. Website with videos:\nhttps://lgpl-gaits.github.io/",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "8 pages 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.03717v2",
    "published_date": "2025-02-06 02:07:18 UTC",
    "updated_date": "2025-03-31 23:24:02 UTC"
  },
  {
    "arxiv_id": "2502.03715v1",
    "title": "Boosting Knowledge Graph-based Recommendations through Confidence-Aware Augmentation with Large Language Models",
    "authors": [
      "Rui Cai",
      "Chao Wang",
      "Qianyi Cai",
      "Dazhong Shen",
      "Hui Xiong"
    ],
    "abstract": "Knowledge Graph-based recommendations have gained significant attention due\nto their ability to leverage rich semantic relationships. However, constructing\nand maintaining Knowledge Graphs (KGs) is resource-intensive, and the accuracy\nof KGs can suffer from noisy, outdated, or irrelevant triplets. Recent\nadvancements in Large Language Models (LLMs) offer a promising way to improve\nthe quality and relevance of KGs for recommendation tasks. Despite this,\nintegrating LLMs into KG-based systems presents challenges, such as efficiently\naugmenting KGs, addressing hallucinations, and developing effective joint\nlearning methods. In this paper, we propose the Confidence-aware KG-based\nRecommendation Framework with LLM Augmentation (CKG-LLMA), a novel framework\nthat combines KGs and LLMs for recommendation task. The framework includes: (1)\nan LLM-based subgraph augmenter for enriching KGs with high-quality\ninformation, (2) a confidence-aware message propagation mechanism to filter\nnoisy triplets, and (3) a dual-view contrastive learning method to integrate\nuser-item interactions and KG data. Additionally, we employ a confidence-aware\nexplanation generation process to guide LLMs in producing realistic\nexplanations for recommendations. Finally, extensive experiments demonstrate\nthe effectiveness of CKG-LLMA across multiple public datasets.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03715v1",
    "published_date": "2025-02-06 02:06:48 UTC",
    "updated_date": "2025-02-06 02:06:48 UTC"
  },
  {
    "arxiv_id": "2502.03711v1",
    "title": "MultiQ&A: An Analysis in Measuring Robustness via Automated Crowdsourcing of Question Perturbations and Answers",
    "authors": [
      "Nicole Cho",
      "William Watson"
    ],
    "abstract": "One critical challenge in the institutional adoption journey of Large\nLanguage Models (LLMs) stems from their propensity to hallucinate in generated\nresponses. To address this, we propose MultiQ&A, a systematic approach for\nevaluating the robustness and consistency of LLM-generated answers. We\ndemonstrate MultiQ&A's ability to crowdsource question perturbations and their\nrespective answers through independent LLM agents at scale. Our experiments\nculminated in the examination of 1.9 million question perturbations and 2.3\nmillion answers. Furthermore, MultiQ&A shows that ensembled LLMs, such as\ngpt-3.5-turbo, remain relatively robust and consistent under perturbations.\nMultiQ&A provides clarity in the response generation space, offering an\neffective method for inspecting disagreements and variability. Therefore, our\nsystem offers a potential framework for institutional LLM adoption with the\nability to measure confidence, consistency, and the quantification of\nhallucinations.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "AAAI 2025 Workshop on Preventing and Detecting LLM Misinformation\n  (PDLM) (Oral)",
    "pdf_url": "http://arxiv.org/pdf/2502.03711v1",
    "published_date": "2025-02-06 01:58:48 UTC",
    "updated_date": "2025-02-06 01:58:48 UTC"
  },
  {
    "arxiv_id": "2502.03708v1",
    "title": "Aggregate and conquer: detecting and steering LLM concepts by combining nonlinear predictors over multiple layers",
    "authors": [
      "Daniel Beaglehole",
      "Adityanarayanan Radhakrishnan",
      "Enric Boix-Adserà",
      "Mikhail Belkin"
    ],
    "abstract": "A trained Large Language Model (LLM) contains much of human knowledge. Yet,\nit is difficult to gauge the extent or accuracy of that knowledge, as LLMs do\nnot always ``know what they know'' and may even be actively misleading. In this\nwork, we give a general method for detecting semantic concepts in the internal\nactivations of LLMs. Furthermore, we show that our methodology can be easily\nadapted to steer LLMs toward desirable outputs. Our innovations are the\nfollowing: (1) we use a nonlinear feature learning method to identify important\nlinear directions for predicting concepts from each layer; (2) we aggregate\nfeatures across layers to build powerful concept detectors and steering\nmechanisms. We showcase the power of our approach by attaining state-of-the-art\nresults for detecting hallucinations, harmfulness, toxicity, and untruthful\ncontent on seven benchmarks. We highlight the generality of our approach by\nsteering LLMs towards new concepts that, to the best of our knowledge, have not\nbeen previously considered in the literature, including: semantic\ndisambiguation, human languages, programming languages, hallucinated responses,\nscience subjects, poetic/Shakespearean English, and even multiple concepts\nsimultaneously. Moreover, our method can steer concepts with numerical\nattributes such as product reviews. We provide our code (including a simple API\nfor our methods) at https://github.com/dmbeaglehole/neural_controllers .",
    "categories": [
      "cs.CL",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03708v1",
    "published_date": "2025-02-06 01:41:48 UTC",
    "updated_date": "2025-02-06 01:41:48 UTC"
  },
  {
    "arxiv_id": "2502.03699v1",
    "title": "LLM Alignment as Retriever Optimization: An Information Retrieval Perspective",
    "authors": [
      "Bowen Jin",
      "Jinsung Yoon",
      "Zhen Qin",
      "Ziqi Wang",
      "Wei Xiong",
      "Yu Meng",
      "Jiawei Han",
      "Sercan O. Arik"
    ],
    "abstract": "Large Language Models (LLMs) have revolutionized artificial intelligence with\ncapabilities in reasoning, coding, and communication, driving innovation across\nindustries. Their true potential depends on effective alignment to ensure\ncorrect, trustworthy and ethical behavior, addressing challenges like\nmisinformation, hallucinations, bias and misuse. While existing Reinforcement\nLearning (RL)-based alignment methods are notoriously complex, direct\noptimization approaches offer a simpler alternative. In this work, we introduce\na novel direct optimization approach for LLM alignment by drawing on\nestablished Information Retrieval (IR) principles. We present a systematic\nframework that bridges LLM alignment and IR methodologies, mapping LLM\ngeneration and reward models to IR's retriever-reranker paradigm. Building on\nthis foundation, we propose LLM Alignment as Retriever Preference Optimization\n(LarPO), a new alignment method that enhances overall alignment quality.\nExtensive experiments validate LarPO's effectiveness with 38.9 % and 13.7 %\naveraged improvement on AlpacaEval2 and MixEval-Hard respectively. Our work\nopens new avenues for advancing LLM alignment by integrating IR foundations,\noffering a promising direction for future research.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "26 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.03699v1",
    "published_date": "2025-02-06 01:22:06 UTC",
    "updated_date": "2025-02-06 01:22:06 UTC"
  },
  {
    "arxiv_id": "2502.04391v1",
    "title": "Towards Fair and Robust Face Parsing for Generative AI: A Multi-Objective Approach",
    "authors": [
      "Sophia J. Abraham",
      "Jonathan D. Hauenstein",
      "Walter J. Scheirer"
    ],
    "abstract": "Face parsing is a fundamental task in computer vision, enabling applications\nsuch as identity verification, facial editing, and controllable image\nsynthesis. However, existing face parsing models often lack fairness and\nrobustness, leading to biased segmentation across demographic groups and errors\nunder occlusions, noise, and domain shifts. These limitations affect downstream\nface synthesis, where segmentation biases can degrade generative model outputs.\nWe propose a multi-objective learning framework that optimizes accuracy,\nfairness, and robustness in face parsing. Our approach introduces a\nhomotopy-based loss function that dynamically adjusts the importance of these\nobjectives during training. To evaluate its impact, we compare multi-objective\nand single-objective U-Net models in a GAN-based face synthesis pipeline\n(Pix2PixHD). Our results show that fairness-aware and robust segmentation\nimproves photorealism and consistency in face generation. Additionally, we\nconduct preliminary experiments using ControlNet, a structured conditioning\nmodel for diffusion-based synthesis, to explore how segmentation quality\ninfluences guided image generation. Our findings demonstrate that\nmulti-objective face parsing improves demographic consistency and robustness,\nleading to higher-quality GAN-based synthesis.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04391v1",
    "published_date": "2025-02-06 00:41:35 UTC",
    "updated_date": "2025-02-06 00:41:35 UTC"
  },
  {
    "arxiv_id": "2502.03688v2",
    "title": "A Comparison of DeepSeek and Other LLMs",
    "authors": [
      "Tianchen Gao",
      "Jiashun Jin",
      "Zheng Tracy Ke",
      "Gabriel Moryoussef"
    ],
    "abstract": "Recently, DeepSeek has been the focus of attention in and beyond the AI\ncommunity. An interesting problem is how DeepSeek compares to other large\nlanguage models (LLMs). There are many tasks an LLM can do, and in this paper,\nwe use the task of predicting an outcome using a short text for comparison. We\nconsider two settings, an authorship classification setting and a citation\nclassification setting. In the first one, the goal is to determine whether a\nshort text is written by human or AI. In the second one, the goal is to\nclassify a citation to one of four types using the textual content. For each\nexperiment, we compare DeepSeek with $4$ popular LLMs: Claude, Gemini, GPT, and\nLlama.\n  We find that, in terms of classification accuracy, DeepSeek outperforms\nGemini, GPT, and Llama in most cases, but underperforms Claude. We also find\nthat DeepSeek is comparably slower than others but with a low cost to use,\nwhile Claude is much more expensive than all the others. Finally, we find that\nin terms of similarity, the output of DeepSeek is most similar to those of\nGemini and Claude (and among all $5$ LLMs, Claude and Gemini have the most\nsimilar outputs).\n  In this paper, we also present a fully-labeled dataset collected by\nourselves, and propose a recipe where we can use the LLMs and a recent data\nset, MADStat, to generate new data sets. The datasets in our paper can be used\nas benchmarks for future study on LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "21 pages, 5 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.03688v2",
    "published_date": "2025-02-06 00:38:25 UTC",
    "updated_date": "2025-02-26 01:49:17 UTC"
  },
  {
    "arxiv_id": "2502.03686v1",
    "title": "Variational Control for Guidance in Diffusion Models",
    "authors": [
      "Kushagra Pandey",
      "Farrin Marouf Sofian",
      "Felix Draxler",
      "Theofanis Karaletsos",
      "Stephan Mandt"
    ],
    "abstract": "Diffusion models exhibit excellent sample quality, but existing guidance\nmethods often require additional model training or are limited to specific\ntasks. We revisit guidance in diffusion models from the perspective of\nvariational inference and control, introducing Diffusion Trajectory Matching\n(DTM) that enables guiding pretrained diffusion trajectories to satisfy a\nterminal cost. DTM unifies a broad class of guidance methods and enables novel\ninstantiations. We introduce a new method within this framework that achieves\nstate-of-the-art results on several linear and (blind) non-linear inverse\nproblems without requiring additional model training or modifications. For\ninstance, in ImageNet non-linear deblurring, our model achieves an FID score of\n34.31, significantly improving over the best pretrained-method baseline (FID\n78.07). We will make the code available in a future update.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages in main text. Total of 20 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.03686v1",
    "published_date": "2025-02-06 00:24:39 UTC",
    "updated_date": "2025-02-06 00:24:39 UTC"
  }
]