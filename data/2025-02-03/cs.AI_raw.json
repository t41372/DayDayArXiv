[
  {
    "arxiv_id": "2502.01889v2",
    "title": "Displacement-Sparse Neural Optimal Transport",
    "authors": [
      "Peter Chen",
      "Yue Xie",
      "Qingpeng Zhang"
    ],
    "abstract": "Optimal transport (OT) aims to find a map $T$ that transports mass from one\nprobability measure to another while minimizing a cost function. Recently,\nneural OT solvers have gained popularity in high dimensional biological\napplications such as drug perturbation, due to their superior computational and\nmemory efficiency compared to traditional exact Sinkhorn solvers. However, the\noverly complex high dimensional maps learned by neural OT solvers often suffer\nfrom poor interpretability. Prior work addressed this issue in the context of\nexact OT solvers by introducing \\emph{displacement-sparse maps} via designed\nelastic cost, but such method failed to be applied to neural OT settings. In\nthis work, we propose an intuitive and theoretically grounded approach to\nlearning \\emph{displacement-sparse maps} within neural OT solvers. Building on\nour new formulation, we introduce a novel smoothed $\\ell_0$ regularizer that\noutperforms the $\\ell_1$ based alternative from prior work. Leveraging Input\nConvex Neural Network's flexibility, we further develop a heuristic framework\nfor adaptively controlling sparsity intensity, an approach uniquely enabled by\nthe neural OT paradigm. We demonstrate the necessity of this adaptive framework\nin large-scale, high-dimensional training, showing not only improved accuracy\nbut also practical ease of use for downstream applications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "23 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.01889v2",
    "published_date": "2025-02-03 23:44:17 UTC",
    "updated_date": "2025-05-17 03:07:45 UTC"
  },
  {
    "arxiv_id": "2502.01885v1",
    "title": "A Privacy-Preserving Domain Adversarial Federated learning for multi-site brain functional connectivity analysis",
    "authors": [
      "Yipu Zhang",
      "Likai Wang",
      "Kuan-Jui Su",
      "Aiying Zhang",
      "Hao Zhu",
      "Xiaowen Liu",
      "Hui Shen",
      "Vince D. Calhoun",
      "Yuping Wang",
      "Hongwen Deng"
    ],
    "abstract": "Resting-state functional magnetic resonance imaging (rs-fMRI) and its derived\nfunctional connectivity networks (FCNs) have become critical for understanding\nneurological disorders. However, collaborative analyses and the\ngeneralizability of models still face significant challenges due to privacy\nregulations and the non-IID (non-independent and identically distributed)\nproperty of multiple data sources. To mitigate these difficulties, we propose\nDomain Adversarial Federated Learning (DAFed), a novel federated deep learning\nframework specifically designed for non-IID fMRI data analysis in multi-site\nsettings. DAFed addresses these challenges through feature disentanglement,\ndecomposing the latent feature space into domain-invariant and domain-specific\ncomponents, to ensure robust global learning while preserving local data\nspecificity. Furthermore, adversarial training facilitates effective knowledge\ntransfer between labeled and unlabeled datasets, while a contrastive learning\nmodule enhances the global representation of domain-invariant features. We\nevaluated DAFed on the diagnosis of ASD and further validated its\ngeneralizability in the classification of AD, demonstrating its superior\nclassification accuracy compared to state-of-the-art methods. Additionally, an\nenhanced Score-CAM module identifies key brain regions and functional\nconnectivity significantly associated with ASD and MCI, respectively,\nuncovering shared neurobiological patterns across sites. These findings\nhighlight the potential of DAFed to advance multi-site collaborative research\nin neuroimaging while protecting data confidentiality.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.LG",
    "comment": "34pages, 13 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.01885v1",
    "published_date": "2025-02-03 23:26:07 UTC",
    "updated_date": "2025-02-03 23:26:07 UTC"
  },
  {
    "arxiv_id": "2502.05211v1",
    "title": "Decoding FL Defenses: Systemization, Pitfalls, and Remedies",
    "authors": [
      "Momin Ahmad Khan",
      "Virat Shejwalkar",
      "Yasra Chandio",
      "Amir Houmansadr",
      "Fatima Muhammad Anwar"
    ],
    "abstract": "While the community has designed various defenses to counter the threat of\npoisoning attacks in Federated Learning (FL), there are no guidelines for\nevaluating these defenses. These defenses are prone to subtle pitfalls in their\nexperimental setups that lead to a false sense of security, rendering them\nunsuitable for practical deployment. In this paper, we systematically\nunderstand, identify, and provide a better approach to address these\nchallenges. First, we design a comprehensive systemization of FL defenses along\nthree dimensions: i) how client updates are processed, ii) what the server\nknows, and iii) at what stage the defense is applied. Next, we thoroughly\nsurvey 50 top-tier defense papers and identify the commonly used components in\ntheir evaluation setups. Based on this survey, we uncover six distinct pitfalls\nand study their prevalence. For example, we discover that around 30% of these\nworks solely use the intrinsically robust MNIST dataset, and 40% employ\nsimplistic attacks, which may inadvertently portray their defense as robust.\nUsing three representative defenses as case studies, we perform a critical\nreevaluation to study the impact of the identified pitfalls and show how they\nlead to incorrect conclusions about robustness. We provide actionable\nrecommendations to help researchers overcome each pitfall.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05211v1",
    "published_date": "2025-02-03 23:14:02 UTC",
    "updated_date": "2025-02-03 23:14:02 UTC"
  },
  {
    "arxiv_id": "2502.15731v1",
    "title": "Modular and Integrated AI Control Framework across Fiber and Wireless Networks for 6G",
    "authors": [
      "Merim Dzaferagic",
      "Marco Ruffini",
      "Daniel Kilper"
    ],
    "abstract": "The rapid evolution of communication networks towards 6G increasingly\nincorporates advanced AI-driven controls across various network segments to\nachieve intelligent, zero-touch operation. This paper proposes a comprehensive\nand modular framework for AI controllers, designed to be highly flexible and\nadaptable for use across both fiber optical and radio networks. Building on the\nprinciples established by the O-RAN Alliance for near-Real-Time RAN Intelligent\nControllers (near-RT RICs), our framework extends this AI-driven control into\nthe optical domain. Our approach addresses the critical need for a unified AI\ncontrol framework across diverse network transport technologies and domains,\nenabling the development of intelligent, automated, and scalable 6G networks.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15731v1",
    "published_date": "2025-02-03 23:12:44 UTC",
    "updated_date": "2025-02-03 23:12:44 UTC"
  },
  {
    "arxiv_id": "2502.06807v2",
    "title": "Competitive Programming with Large Reasoning Models",
    "authors": [
      "OpenAI",
      ":",
      "Ahmed El-Kishky",
      "Alexander Wei",
      "Andre Saraiva",
      "Borys Minaiev",
      "Daniel Selsam",
      "David Dohan",
      "Francis Song",
      "Hunter Lightman",
      "Ignasi Clavera",
      "Jakub Pachocki",
      "Jerry Tworek",
      "Lorenz Kuhn",
      "Lukasz Kaiser",
      "Mark Chen",
      "Max Schwarzer",
      "Mostafa Rohaninejad",
      "Nat McAleese",
      "o3 contributors",
      "Oleg Mürk",
      "Rhythm Garg",
      "Rui Shu",
      "Szymon Sidor",
      "Vineet Kosaraju",
      "Wenda Zhou"
    ],
    "abstract": "We show that reinforcement learning applied to large language models (LLMs)\nsignificantly boosts performance on complex coding and reasoning tasks.\nAdditionally, we compare two general-purpose reasoning models - OpenAI o1 and\nan early checkpoint of o3 - with a domain-specific system, o1-ioi, which uses\nhand-engineered inference strategies designed for competing in the 2024\nInternational Olympiad in Informatics (IOI). We competed live at IOI 2024 with\no1-ioi and, using hand-crafted test-time strategies, placed in the 49th\npercentile. Under relaxed competition constraints, o1-ioi achieved a gold\nmedal. However, when evaluating later models such as o3, we find that o3\nachieves gold without hand-crafted domain-specific strategies or relaxed\nconstraints. Our findings show that although specialized pipelines such as\no1-ioi yield solid improvements, the scaled-up, general-purpose o3 model\nsurpasses those results without relying on hand-crafted inference heuristics.\nNotably, o3 achieves a gold medal at the 2024 IOI and obtains a Codeforces\nrating on par with elite human competitors. Overall, these results indicate\nthat scaling general-purpose reinforcement learning, rather than relying on\ndomain-specific techniques, offers a robust path toward state-of-the-art AI in\nreasoning domains, such as competitive programming.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.06807v2",
    "published_date": "2025-02-03 23:00:15 UTC",
    "updated_date": "2025-02-18 22:21:40 UTC"
  },
  {
    "arxiv_id": "2502.01866v1",
    "title": "Online Curvature-Aware Replay: Leveraging $\\mathbf{2^{nd}}$ Order Information for Online Continual Learning",
    "authors": [
      "Edoardo Urettini",
      "Antonio Carta"
    ],
    "abstract": "Online Continual Learning (OCL) models continuously adapt to nonstationary\ndata streams, usually without task information. These settings are complex and\nmany traditional CL methods fail, while online methods (mainly replay-based)\nsuffer from instabilities after the task shift. To address this issue, we\nformalize replay-based OCL as a second-order online joint optimization with\nexplicit KL-divergence constraints on replay data. We propose Online\nCurvature-Aware Replay (OCAR) to solve the problem: a method that leverages\nsecond-order information of the loss using a K-FAC approximation of the Fisher\nInformation Matrix (FIM) to precondition the gradient. The FIM acts as a\nstabilizer to prevent forgetting while also accelerating the optimization in\nnon-interfering directions. We show how to adapt the estimation of the FIM to a\ncontinual setting stabilizing second-order optimization for non-iid data,\nuncovering the role of the Tikhonov regularization in the stability-plasticity\ntradeoff. Empirical results show that OCAR outperforms state-of-the-art methods\nin continual metrics achieving higher average accuracy throughout the training\nprocess in three different benchmarks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01866v1",
    "published_date": "2025-02-03 22:31:36 UTC",
    "updated_date": "2025-02-03 22:31:36 UTC"
  },
  {
    "arxiv_id": "2502.06806v2",
    "title": "Logits are All We Need to Adapt Closed Models",
    "authors": [
      "Gaurush Hiranandani",
      "Haolun Wu",
      "Subhojyoti Mukherjee",
      "Sanmi Koyejo"
    ],
    "abstract": "Many commercial Large Language Models (LLMs) are often closed-source,\nlimiting developers to prompt tuning for aligning content generation with\nspecific applications. While these models currently do not provide access to\ntoken logits, we argue that if such access were available, it would enable more\npowerful adaptation techniques beyond prompt engineering. In this paper, we\npropose a token-level probability reweighting framework that, given access to\nlogits and a small amount of task-specific data, can effectively steer\nblack-box LLMs toward application-specific content generation. Our approach\nviews next-token prediction through the lens of supervised classification. We\nshow that aligning black-box LLMs with task-specific data can be formulated as\na label noise correction problem, leading to \\emph{Plugin} model -- an\nautoregressive probability reweighting model that operates solely on logits. We\nprovide theoretical justification for why reweighting logits alone is\nsufficient for task adaptation. Extensive experiments with multiple datasets,\nLLMs, and reweighting models demonstrate the effectiveness of our method,\nadvocating for broader access to token logits in closed-source models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "33 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.06806v2",
    "published_date": "2025-02-03 22:24:22 UTC",
    "updated_date": "2025-02-23 07:20:51 UTC"
  },
  {
    "arxiv_id": "2503.04737v1",
    "title": "Carelessness Detection using Performance Factor Analysis: A New Operationalization with Unexpectedly Different Relationship to Learning",
    "authors": [
      "Jiayi Zhang",
      "Ryan S. Baker",
      "Namrata Srivastava",
      "Jaclyn Ocumpaugh",
      "Caitlin Mills",
      "Bruce M. McLaren"
    ],
    "abstract": "Detection of carelessness in digital learning platforms has relied on the\ncontextual slip model, which leverages conditional probability and Bayesian\nKnowledge Tracing (BKT) to identify careless errors, where students make\nmistakes despite having the knowledge. However, this model cannot effectively\nassess carelessness in questions tagged with multiple skills due to the use of\nconditional probability. This limitation narrows the scope within which the\nmodel can be applied. Thus, we propose a novel model, the Beyond Knowledge\nFeature Carelessness (BKFC) model. The model detects careless errors using\nperformance factor analysis (PFA) and behavioral features distilled from log\ndata, controlling for knowledge when detecting carelessness. We applied the\nBKFC to detect carelessness in data from middle school students playing a\nlearning game on decimal numbers and operations. We conducted analyses\ncomparing the careless errors detected using contextual slip to the BKFC model.\nUnexpectedly, careless errors identified by these two approaches did not align.\nWe found students' post-test performance was (corresponding to past results)\npositively associated with the carelessness detected using the contextual slip\nmodel, while negatively associated with the carelessness detected using the\nBKFC model. These results highlight the complexity of carelessness and\nunderline a broader challenge in operationalizing carelessness and careless\nerrors.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04737v1",
    "published_date": "2025-02-03 22:14:02 UTC",
    "updated_date": "2025-02-03 22:14:02 UTC"
  },
  {
    "arxiv_id": "2503.15525v1",
    "title": "The Use of Artificial Intelligence Tools in Assessing Content Validity: A Comparative Study with Human Experts",
    "authors": [
      "Hatice Gurdil",
      "Hatice Ozlem Anadol",
      "Yesim Beril Soguksu"
    ],
    "abstract": "In this study, it was investigated whether AI evaluators assess the content\nvalidity of B1-level English reading comprehension test items in a manner\nsimilar to human evaluators. A 25-item multiple-choice test was developed, and\nthese test items were evaluated by four human and four AI evaluators. No\nstatistically significant difference was found between the scores given by\nhuman and AI evaluators, with similar evaluation trends observed. The Content\nValidity Ratio (CVR) and the Item Content Validity Index (I-CVI) were\ncalculated and analyzed using the Wilcoxon Signed-Rank Test, with no\nstatistically significant difference. The findings revealed that in some cases,\nAI evaluators could replace human evaluators. However, differences in specific\nitems were thought to arise from varying interpretations of the evaluation\ncriteria. Ensuring linguistic clarity and clearly defining criteria could\ncontribute to more consistent evaluations. In this regard, the development of\nhybrid evaluation systems, in which AI technologies are used alongside human\nexperts, is recommended.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.15525v1",
    "published_date": "2025-02-03 22:09:01 UTC",
    "updated_date": "2025-02-03 22:09:01 UTC"
  },
  {
    "arxiv_id": "2502.01857v1",
    "title": "Learning Human Perception Dynamics for Informative Robot Communication",
    "authors": [
      "Shenghui Chen",
      "Ruihan Zhao",
      "Sandeep Chinchali",
      "Ufuk Topcu"
    ],
    "abstract": "Human-robot cooperative navigation is challenging in environments with\nincomplete information. We introduce CoNav-Maze, a simulated robotics\nenvironment where a robot navigates using local perception while a human\noperator provides guidance based on an inaccurate map. The robot can share its\ncamera views to improve the operator's understanding of the environment. To\nenable efficient human-robot cooperation, we propose Information Gain Monte\nCarlo Tree Search (IG-MCTS), an online planning algorithm that balances\nautonomous movement and informative communication. Central to IG-MCTS is a\nneural human perception dynamics model that estimates how humans distill\ninformation from robot communications. We collect a dataset through a\ncrowdsourced mapping task in CoNav-Maze and train this model using a fully\nconvolutional architecture with data augmentation. User studies show that\nIG-MCTS outperforms teleoperation and instruction-following baselines,\nachieving comparable task performance with significantly less communication and\nlower human cognitive load, as evidenced by eye-tracking metrics.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01857v1",
    "published_date": "2025-02-03 22:08:04 UTC",
    "updated_date": "2025-02-03 22:08:04 UTC"
  },
  {
    "arxiv_id": "2502.01842v2",
    "title": "Texture Image Synthesis Using Spatial GAN Based on Vision Transformers",
    "authors": [
      "Elahe Salari",
      "Zohreh Azimifar"
    ],
    "abstract": "Texture synthesis is a fundamental task in computer vision, whose goal is to\ngenerate visually realistic and structurally coherent textures for a wide range\nof applications, from graphics to scientific simulations. While traditional\nmethods like tiling and patch-based techniques often struggle with complex\ntextures, recent advancements in deep learning have transformed this field. In\nthis paper, we propose ViT-SGAN, a new hybrid model that fuses Vision\nTransformers (ViTs) with a Spatial Generative Adversarial Network (SGAN) to\naddress the limitations of previous methods. By incorporating specialized\ntexture descriptors such as mean-variance (mu, sigma) and textons into the\nself-attention mechanism of ViTs, our model achieves superior texture\nsynthesis. This approach enhances the model's capacity to capture complex\nspatial dependencies, leading to improved texture quality that is superior to\nstate-of-the-art models, especially for regular and irregular textures.\nComparison experiments with metrics such as FID, IS, SSIM, and LPIPS\ndemonstrate the substantial improvement of ViT-SGAN, which underlines its\nefficiency in generating diverse realistic textures.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2502.01842v2",
    "published_date": "2025-02-03 21:39:30 UTC",
    "updated_date": "2025-05-07 21:11:00 UTC"
  },
  {
    "arxiv_id": "2502.01839v2",
    "title": "Sample, Scrutinize and Scale: Effective Inference-Time Search by Scaling Verification",
    "authors": [
      "Eric Zhao",
      "Pranjal Awasthi",
      "Sreenivas Gollapudi"
    ],
    "abstract": "Sampling-based search, a simple paradigm for utilizing test-time compute,\ninvolves generating multiple candidate responses and selecting the best one --\ntypically by having models self-verify each response for correctness. In this\npaper, we study the scaling trends governing sampling-based search. Among our\nfindings is that simply scaling up a minimalist implementation of\nsampling-based search, using only random sampling and direct self-verification,\nprovides a practical inference method that, for example, elevates the reasoning\ncapabilities of Gemini v1.5 Pro above that of o1-Preview on popular benchmarks.\nWe partially attribute the scalability of sampling-based search to a phenomenon\nof implicit scaling, where sampling a larger pool of responses in turn improves\nself-verification accuracy. We further identify two useful principles for\nimproving self-verification capabilities with test-time compute: (1) comparing\nacross responses provides helpful signals about the locations of errors and\nhallucinations, and (2) different model output styles are useful for different\ncontexts -- chains of thought are useful for reasoning but harder to verify. We\nalso find that, though accurate verification can be elicited, frontier models\ndemonstrate remarkably weak out-of-box verification capabilities and introduce\na benchmark to measure progress on these deficiencies.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01839v2",
    "published_date": "2025-02-03 21:31:07 UTC",
    "updated_date": "2025-02-20 18:52:18 UTC"
  },
  {
    "arxiv_id": "2502.01837v1",
    "title": "TESS: A Scalable Temporally and Spatially Local Learning Rule for Spiking Neural Networks",
    "authors": [
      "Marco Paul E. Apolinario",
      "Kaushik Roy",
      "Charlotte Frenkel"
    ],
    "abstract": "The demand for low-power inference and training of deep neural networks\n(DNNs) on edge devices has intensified the need for algorithms that are both\nscalable and energy-efficient. While spiking neural networks (SNNs) allow for\nefficient inference by processing complex spatio-temporal dynamics in an\nevent-driven fashion, training them on resource-constrained devices remains\nchallenging due to the high computational and memory demands of conventional\nerror backpropagation (BP)-based approaches. In this work, we draw inspiration\nfrom biological mechanisms such as eligibility traces, spike-timing-dependent\nplasticity, and neural activity synchronization to introduce TESS, a temporally\nand spatially local learning rule for training SNNs. Our approach addresses\nboth temporal and spatial credit assignments by relying solely on locally\navailable signals within each neuron, thereby allowing computational and memory\noverheads to scale linearly with the number of neurons, independently of the\nnumber of time steps. Despite relying on local mechanisms, we demonstrate\nperformance comparable to the backpropagation through time (BPTT) algorithm,\nwithin $\\sim1.4$ accuracy points on challenging computer vision scenarios\nrelevant at the edge, such as the IBM DVS Gesture dataset, CIFAR10-DVS, and\ntemporal versions of CIFAR10, and CIFAR100. Being able to produce comparable\nperformance to BPTT while keeping low time and memory complexity, TESS enables\nefficient and scalable on-device learning at the edge.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "9 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.01837v1",
    "published_date": "2025-02-03 21:23:15 UTC",
    "updated_date": "2025-02-03 21:23:15 UTC"
  },
  {
    "arxiv_id": "2502.01834v1",
    "title": "Building a Cognitive Twin Using a Distributed Cognitive System and an Evolution Strategy",
    "authors": [
      "Wandemberg Gibaut",
      "Ricardo Gudwin"
    ],
    "abstract": "This work presents a technique to build interaction-based Cognitive Twins (a\ncomputational version of an external agent) using input-output training and an\nEvolution Strategy on top of a framework for distributed Cognitive\nArchitectures. Here, we show that it's possible to orchestrate many simple\nphysical and virtual devices to achieve good approximations of a person's\ninteraction behavior by training the system in an end-to-end fashion and\npresent performance metrics. The generated Cognitive Twin may later be used to\nautomate tasks, generate more realistic human-like artificial agents or further\ninvestigate its behaviors.",
    "categories": [
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.AI",
    "comment": "first submitted on 09/22/2022, published on 01/20/2025",
    "pdf_url": "http://arxiv.org/pdf/2502.01834v1",
    "published_date": "2025-02-03 21:19:13 UTC",
    "updated_date": "2025-02-03 21:19:13 UTC"
  },
  {
    "arxiv_id": "2502.01825v1",
    "title": "Assessing Data Augmentation-Induced Bias in Training and Testing of Machine Learning Models",
    "authors": [
      "Riddhi More",
      "Jeremy S. Bradbury"
    ],
    "abstract": "Data augmentation has become a standard practice in software engineering to\naddress limited or imbalanced data sets, particularly in specialized domains\nlike test classification and bug detection where data can be scarce. Although\ntechniques such as SMOTE and mutation-based augmentation are widely used in\nsoftware testing and debugging applications, a rigorous understanding of how\naugmented training data impacts model bias is lacking. It is especially\ncritical to consider bias in scenarios where augmented data sets are used not\njust in training but also in testing models. Through a comprehensive case study\nof flaky test classification, we demonstrate how to test for bias and\nunderstand the impact that the inclusion of augmented samples in testing sets\ncan have on model evaluation.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "D.2.5; I.2.7"
    ],
    "primary_category": "cs.SE",
    "comment": "4 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.01825v1",
    "published_date": "2025-02-03 21:06:35 UTC",
    "updated_date": "2025-02-03 21:06:35 UTC"
  },
  {
    "arxiv_id": "2502.01821v2",
    "title": "Agentic Bug Reproduction for Effective Automated Program Repair at Google",
    "authors": [
      "Runxiang Cheng",
      "Michele Tufano",
      "Jürgen Cito",
      "José Cambronero",
      "Pat Rondon",
      "Renyao Wei",
      "Aaron Sun",
      "Satish Chandra"
    ],
    "abstract": "Bug reports often lack sufficient detail for developers to reproduce and fix\nthe underlying defects. Bug Reproduction Tests (BRTs), tests that fail when the\nbug is present and pass when it has been resolved, are crucial for debugging,\nbut they are rarely included in bug reports, both in open-source and in\nindustrial settings. Thus, automatically generating BRTs from bug reports has\nthe potential to accelerate the debugging process and lower time to repair.\nThis paper investigates automated BRT generation within an industry setting,\nspecifically at Google, focusing on the challenges of a large-scale,\nproprietary codebase and considering real-world industry bugs extracted from\nGoogle's internal issue tracker. We adapt and evaluate a state-of-the-art BRT\ngeneration technique, LIBRO, and present our agent-based approach, BRT Agent,\nwhich makes use of a fine-tuned Large Language Model (LLM) for code editing.\nOur BRT Agent significantly outperforms LIBRO, achieving a 28% plausible BRT\ngeneration rate, compared to 10% by LIBRO, on 80 human-reported bugs from\nGoogle's internal issue tracker. We further investigate the practical value of\ngenerated BRTs by integrating them with an Automated Program Repair (APR)\nsystem at Google. Our results show that providing BRTs to the APR system\nresults in 30% more bugs with plausible fixes. Additionally, we introduce\nEnsemble Pass Rate (EPR), a metric which leverages the generated BRTs to select\nthe most promising fixes from all fixes generated by APR system. Our evaluation\non EPR for Top-K and threshold-based fix selections demonstrates promising\nresults and trade-offs. For example, EPR correctly selects a plausible fix from\na pool of 20 candidates in 70% of cases, based on its top-1 ranking.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01821v2",
    "published_date": "2025-02-03 20:57:17 UTC",
    "updated_date": "2025-03-11 02:30:46 UTC"
  },
  {
    "arxiv_id": "2502.01819v2",
    "title": "Score as Action: Fine-Tuning Diffusion Generative Models by Continuous-time Reinforcement Learning",
    "authors": [
      "Hanyang Zhao",
      "Haoxian Chen",
      "Ji Zhang",
      "David D. Yao",
      "Wenpin Tang"
    ],
    "abstract": "Reinforcement learning from human feedback (RLHF), which aligns a diffusion\nmodel with input prompt, has become a crucial step in building reliable\ngenerative AI models. Most works in this area use a discrete-time formulation,\nwhich is prone to induced errors, and often not applicable to models with\nhigher-order/black-box solvers. The objective of this study is to develop a\ndisciplined approach to fine-tune diffusion models using continuous-time RL,\nformulated as a stochastic control problem with a reward function that aligns\nthe end result (terminal state) with input prompt. The key idea is to treat\nscore matching as controls or actions, and thereby making connections to policy\noptimization and regularization in continuous-time RL. To carry out this idea,\nwe lay out a new policy optimization framework for continuous-time RL, and\nillustrate its potential in enhancing the value networks design space via\nleveraging the structural property of diffusion models. We validate the\nadvantages of our method by experiments in downstream tasks of fine-tuning\nlarge-scale Text2Image models of Stable Diffusion v1.5.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "primary_category": "cs.LG",
    "comment": "arXiv admin note: text overlap with arXiv:2409.08400",
    "pdf_url": "http://arxiv.org/pdf/2502.01819v2",
    "published_date": "2025-02-03 20:50:05 UTC",
    "updated_date": "2025-04-16 15:36:36 UTC"
  },
  {
    "arxiv_id": "2502.01806v1",
    "title": "Toward Neurosymbolic Program Comprehension",
    "authors": [
      "Alejandro Velasco",
      "Aya Garryyeva",
      "David N. Palacio",
      "Antonio Mastropaolo",
      "Denys Poshyvanyk"
    ],
    "abstract": "Recent advancements in Large Language Models (LLMs) have paved the way for\nLarge Code Models (LCMs), enabling automation in complex software engineering\ntasks, such as code generation, software testing, and program comprehension,\namong others. Tools like GitHub Copilot and ChatGPT have shown substantial\nbenefits in supporting developers across various practices. However, the\nambition to scale these models to trillion-parameter sizes, exemplified by\nGPT-4, poses significant challenges that limit the usage of Artificial\nIntelligence (AI)-based systems powered by large Deep Learning (DL) models.\nThese include rising computational demands for training and deployment and\nissues related to trustworthiness, bias, and interpretability. Such factors can\nmake managing these models impractical for many organizations, while their\n\"black-box'' nature undermines key aspects, including transparency and\naccountability. In this paper, we question the prevailing assumption that\nincreasing model parameters is always the optimal path forward, provided there\nis sufficient new data to learn additional patterns. In particular, we advocate\nfor a Neurosymbolic research direction that combines the strengths of existing\nDL techniques (e.g., LLMs) with traditional symbolic methods--renowned for\ntheir reliability, speed, and determinism. To this end, we outline the core\nfeatures and present preliminary results for our envisioned approach, aimed at\nestablishing the first Neurosymbolic Program Comprehension (NsPC) framework to\naid in identifying defective code components.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01806v1",
    "published_date": "2025-02-03 20:38:58 UTC",
    "updated_date": "2025-02-03 20:38:58 UTC"
  },
  {
    "arxiv_id": "2502.01803v1",
    "title": "Discovering Chunks in Neural Embeddings for Interpretability",
    "authors": [
      "Shuchen Wu",
      "Stephan Alaniz",
      "Eric Schulz",
      "Zeynep Akata"
    ],
    "abstract": "Understanding neural networks is challenging due to their high-dimensional,\ninteracting components. Inspired by human cognition, which processes complex\nsensory data by chunking it into recurring entities, we propose leveraging this\nprinciple to interpret artificial neural population activities. Biological and\nartificial intelligence share the challenge of learning from structured,\nnaturalistic data, and we hypothesize that the cognitive mechanism of chunking\ncan provide insights into artificial systems. We first demonstrate this concept\nin recurrent neural networks (RNNs) trained on artificial sequences with\nimposed regularities, observing that their hidden states reflect these\npatterns, which can be extracted as a dictionary of chunks that influence\nnetwork responses. Extending this to large language models (LLMs) like LLaMA,\nwe identify similar recurring embedding states corresponding to concepts in the\ninput, with perturbations to these states activating or inhibiting the\nassociated concepts. By exploring methods to extract dictionaries of\nidentifiable chunks across neural embeddings of varying complexity, our\nfindings introduce a new framework for interpreting neural networks, framing\ntheir population activity as structured reflections of the data they process.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01803v1",
    "published_date": "2025-02-03 20:30:46 UTC",
    "updated_date": "2025-02-03 20:30:46 UTC"
  },
  {
    "arxiv_id": "2502.01800v2",
    "title": "Flow-based Domain Randomization for Learning and Sequencing Robotic Skills",
    "authors": [
      "Aidan Curtis",
      "Eric Li",
      "Michael Noseworthy",
      "Nishad Gothoskar",
      "Sachin Chitta",
      "Hui Li",
      "Leslie Pack Kaelbling",
      "Nicole Carey"
    ],
    "abstract": "Domain randomization in reinforcement learning is an established technique\nfor increasing the robustness of control policies trained in simulation. By\nrandomizing environment properties during training, the learned policy can\nbecome robust to uncertainties along the randomized dimensions. While the\nenvironment distribution is typically specified by hand, in this paper we\ninvestigate automatically discovering a sampling distribution via\nentropy-regularized reward maximization of a normalizing-flow-based neural\nsampling distribution. We show that this architecture is more flexible and\nprovides greater robustness than existing approaches that learn simpler,\nparameterized sampling distributions, as demonstrated in six simulated and one\nreal-world robotics domain. Lastly, we explore how these learned sampling\ndistributions, combined with a privileged value function, can be used for\nout-of-distribution detection in an uncertainty-aware multi-step manipulation\nplanner.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01800v2",
    "published_date": "2025-02-03 20:25:50 UTC",
    "updated_date": "2025-05-05 19:40:42 UTC"
  },
  {
    "arxiv_id": "2502.01789v1",
    "title": "An Agentic AI Workflow for Detecting Cognitive Concerns in Real-world Data",
    "authors": [
      "Jiazi Tian",
      "Liqin Wang",
      "Pedram Fard",
      "Valdery Moura Junior",
      "Deborah Blacker",
      "Jennifer S. Haas",
      "Chirag Patel",
      "Shawn N. Murphy",
      "Lidia M. V. R. Moura",
      "Hossein Estiri"
    ],
    "abstract": "Early identification of cognitive concerns is critical but often hindered by\nsubtle symptom presentation. This study developed and validated a fully\nautomated, multi-agent AI workflow using LLaMA 3 8B to identify cognitive\nconcerns in 3,338 clinical notes from Mass General Brigham. The agentic\nworkflow, leveraging task-specific agents that dynamically collaborate to\nextract meaningful insights from clinical notes, was compared to an\nexpert-driven benchmark. Both workflows achieved high classification\nperformance, with F1-scores of 0.90 and 0.91, respectively. The agentic\nworkflow demonstrated improved specificity (1.00) and achieved prompt\nrefinement in fewer iterations. Although both workflows showed reduced\nperformance on validation data, the agentic workflow maintained perfect\nspecificity. These findings highlight the potential of fully automated\nmulti-agent AI workflows to achieve expert-level accuracy with greater\nefficiency, offering a scalable and cost-effective solution for detecting\ncognitive concerns in clinical settings.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01789v1",
    "published_date": "2025-02-03 20:08:33 UTC",
    "updated_date": "2025-02-03 20:08:33 UTC"
  },
  {
    "arxiv_id": "2502.01785v1",
    "title": "AquaticCLIP: A Vision-Language Foundation Model for Underwater Scene Analysis",
    "authors": [
      "Basit Alawode",
      "Iyyakutti Iyappan Ganapathi",
      "Sajid Javed",
      "Naoufel Werghi",
      "Mohammed Bennamoun",
      "Arif Mahmood"
    ],
    "abstract": "The preservation of aquatic biodiversity is critical in mitigating the\neffects of climate change. Aquatic scene understanding plays a pivotal role in\naiding marine scientists in their decision-making processes. In this paper, we\nintroduce AquaticCLIP, a novel contrastive language-image pre-training model\ntailored for aquatic scene understanding. AquaticCLIP presents a new\nunsupervised learning framework that aligns images and texts in aquatic\nenvironments, enabling tasks such as segmentation, classification, detection,\nand object counting. By leveraging our large-scale underwater image-text paired\ndataset without the need for ground-truth annotations, our model enriches\nexisting vision-language models in the aquatic domain. For this purpose, we\nconstruct a 2 million underwater image-text paired dataset using heterogeneous\nresources, including YouTube, Netflix, NatGeo, etc. To fine-tune AquaticCLIP,\nwe propose a prompt-guided vision encoder that progressively aggregates patch\nfeatures via learnable prompts, while a vision-guided mechanism enhances the\nlanguage encoder by incorporating visual context. The model is optimized\nthrough a contrastive pretraining loss to align visual and textual modalities.\nAquaticCLIP achieves notable performance improvements in zero-shot settings\nacross multiple underwater computer vision tasks, outperforming existing\nmethods in both robustness and interpretability. Our model sets a new benchmark\nfor vision-language applications in underwater environments. The code and\ndataset for AquaticCLIP are publicly available on GitHub at xxx.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01785v1",
    "published_date": "2025-02-03 19:56:16 UTC",
    "updated_date": "2025-02-03 19:56:16 UTC"
  },
  {
    "arxiv_id": "2503.15524v1",
    "title": "KHAIT: K-9 Handler Artificial Intelligence Teaming for Collaborative Sensemaking",
    "authors": [
      "Matthew Wilchek",
      "Linhan Wang",
      "Sally Dickinson",
      "Erica Feuerbacher",
      "Kurt Luther",
      "Feras A. Batarseh"
    ],
    "abstract": "In urban search and rescue (USAR) operations, communication between handlers\nand specially trained canines is crucial but often complicated by challenging\nenvironments and the specific behaviors canines are trained to exhibit when\ndetecting a person. Since a USAR canine often works out of sight of the\nhandler, the handler lacks awareness of the canine's location and situation,\nknown as the 'sensemaking gap.' In this paper, we propose KHAIT, a novel\napproach to close the sensemaking gap and enhance USAR effectiveness by\nintegrating object detection-based Artificial Intelligence (AI) and Augmented\nReality (AR). Equipped with AI-powered cameras, edge computing, and AR\nheadsets, KHAIT enables precise and rapid object detection from a canine's\nperspective, improving survivor localization. We evaluate this approach in a\nreal-world USAR environment, demonstrating an average survival allocation time\ndecrease of 22%, enhancing the speed and accuracy of operations.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CV",
      "cs.ET",
      "cs.MA",
      "I.2.11; I.4.8; H.5.2; H.5.3; J.7"
    ],
    "primary_category": "cs.HC",
    "comment": "13 pages, 7 figures, ACM 30th International Conference on Intelligent\n  User Interfaces (IUI 25)",
    "pdf_url": "http://arxiv.org/pdf/2503.15524v1",
    "published_date": "2025-02-03 19:30:56 UTC",
    "updated_date": "2025-02-03 19:30:56 UTC"
  },
  {
    "arxiv_id": "2502.01774v1",
    "title": "Grokking Explained: A Statistical Phenomenon",
    "authors": [
      "Breno W. Carvalho",
      "Artur S. d'Avila Garcez",
      "Luís C. Lamb",
      "Emílio Vital Brazil"
    ],
    "abstract": "Grokking, or delayed generalization, is an intriguing learning phenomenon\nwhere test set loss decreases sharply only after a model's training set loss\nhas converged. This challenges conventional understanding of the training\ndynamics in deep learning networks. In this paper, we formalize and investigate\ngrokking, highlighting that a key factor in its emergence is a distribution\nshift between training and test data. We introduce two synthetic datasets\nspecifically designed to analyze grokking. One dataset examines the impact of\nlimited sampling, and the other investigates transfer learning's role in\ngrokking. By inducing distribution shifts through controlled imbalanced\nsampling of sub-categories, we systematically reproduce the phenomenon,\ndemonstrating that while small-sampling is strongly associated with grokking,\nit is not its cause. Instead, small-sampling serves as a convenient mechanism\nfor achieving the necessary distribution shift. We also show that when classes\nform an equivariant map, grokking can be explained by the model's ability to\nlearn from similar classes or sub-categories. Unlike earlier work suggesting\nthat grokking primarily arises from high regularization and sparse data, we\ndemonstrate that it can also occur with dense data and minimal hyper-parameter\ntuning. Our findings deepen the understanding of grokking and pave the way for\ndeveloping better stopping criteria in future training processes.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01774v1",
    "published_date": "2025-02-03 19:28:11 UTC",
    "updated_date": "2025-02-03 19:28:11 UTC"
  },
  {
    "arxiv_id": "2502.01772v1",
    "title": "On Bob Dylan: A Computational Perspective",
    "authors": [
      "Prashant Garg"
    ],
    "abstract": "Cass Sunstein's essay 'On Bob Dylan' describes Dylan's 'dishabituating' style\n-- a constant refusal to conform to expectation and a penchant for reinventing\nhis musical and lyrical identity. In this paper, I extend Sunstein's\nobservations through a large-scale computational analysis of Dylan's lyrics\nfrom 1962 to 2012. Using o3-mini-high (a large language model), I extract\nconcept-to-concept relationships from the lyrics and construct directed\nknowledge graphs that capture Dylan's thematic structure. I then quantify\nshifts in sentiment, metaphorical expression, thematic diversity, and network\ncomplexity over time. The results indicate that Dylan's lyrics increasingly\nrely on metaphor, display an evolving sentiment profile, and exhibit heightened\ndishabituation -- measured here as a growing variance in the network centrality\nof key concepts. I also find that references to movement, protest, and mythic\nimagery fluctuate in ways that align with well-known phases of Dylan's career,\nreflecting the dynamic and unpredictable quality of his art. These findings not\nonly deepen our empirical understanding of Sunstein's thesis but also introduce\na novel computational method for analyzing an artist's evolution-offering\nbroader applicability to the study of cultural and creative change.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.SI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01772v1",
    "published_date": "2025-02-03 19:25:08 UTC",
    "updated_date": "2025-02-03 19:25:08 UTC"
  },
  {
    "arxiv_id": "2502.01770v1",
    "title": "Hamming Attention Distillation: Binarizing Keys and Queries for Efficient Long-Context Transformers",
    "authors": [
      "Mark Horton",
      "Tergel Molom-Ochir",
      "Peter Liu",
      "Bhavna Gopal",
      "Chiyue Wei",
      "Cong Guo",
      "Brady Taylor",
      "Deliang Fan",
      "Shan X. Wang",
      "Hai Li",
      "Yiran Chen"
    ],
    "abstract": "Pre-trained transformer models with extended context windows are notoriously\nexpensive to run at scale, often limiting real-world deployment due to their\nhigh computational and memory requirements. In this paper, we introduce Hamming\nAttention Distillation (HAD), a novel framework that binarizes keys and queries\nin the attention mechanism to achieve significant efficiency gains. By\nconverting keys and queries into {-1, +1} vectors and replacing dot-product\noperations with efficient Hamming distance computations, our method drastically\nreduces computational overhead. Additionally, we incorporate attention matrix\nsparsification to prune low-impact activations, which further reduces the cost\nof processing long-context sequences. \\par Despite these aggressive compression\nstrategies, our distilled approach preserves a high degree of representational\npower, leading to substantially improved accuracy compared to prior transformer\nbinarization methods. We evaluate HAD on a range of tasks and models, including\nthe GLUE benchmark, ImageNet, and QuALITY, demonstrating state-of-the-art\nperformance among binarized Transformers while drastically reducing the\ncomputational costs of long-context inference. \\par We implement HAD in custom\nhardware simulations, demonstrating superior performance characteristics\ncompared to a custom hardware implementation of standard attention. HAD\nachieves just $\\mathbf{1.78}\\%$ performance losses on GLUE compared to $9.08\\%$\nin state-of-the-art binarization work, and $\\mathbf{2.5}\\%$ performance losses\non ImageNet compared to $12.14\\%$, all while targeting custom hardware with a\n$\\mathbf{79}\\%$ area reduction and $\\mathbf{87}\\%$ power reduction compared to\nits standard attention counterpart.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01770v1",
    "published_date": "2025-02-03 19:24:01 UTC",
    "updated_date": "2025-02-03 19:24:01 UTC"
  },
  {
    "arxiv_id": "2502.01755v2",
    "title": "Robust Federated Finetuning of LLMs via Alternating Optimization of LoRA",
    "authors": [
      "Shuangyi Chen",
      "Yuanxin Guo",
      "Yue Ju",
      "Harik Dalal",
      "Ashish Khisti"
    ],
    "abstract": "Parameter-Efficient Fine-Tuning (PEFT) methods like Low-Rank Adaptation\n(LoRA) optimize federated training by reducing computational and communication\ncosts. We propose RoLoRA, a federated framework using alternating optimization\nto fine-tune LoRA adapters. Our approach emphasizes the importance of learning\nup and down projection matrices to enhance expressiveness and robustness. We\nuse both theoretical analysis and extensive experiments to demonstrate the\nadvantages of RoLoRA over prior approaches that either generate imperfect model\nupdates or limit expressiveness of the model. We present theoretical analysis\non a simplified linear model to demonstrate the importance of learning both\ndown-projection and up-projection matrices in LoRA. We provide extensive\nexperimental evaluations on a toy neural network on MNIST as well as large\nlanguage models including RoBERTa-Large, Llama-2-7B on diverse tasks to\ndemonstrate the advantages of RoLoRA over other methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "A preliminary version was in ICML24 workshop, arXiv:2409.02346",
    "pdf_url": "http://arxiv.org/pdf/2502.01755v2",
    "published_date": "2025-02-03 19:02:00 UTC",
    "updated_date": "2025-02-13 03:42:24 UTC"
  },
  {
    "arxiv_id": "2502.01754v1",
    "title": "Evaluation of Large Language Models via Coupled Token Generation",
    "authors": [
      "Nina Corvelo Benz",
      "Stratis Tsirtsis",
      "Eleni Straitouri",
      "Ivi Chatzi",
      "Ander Artola Velasco",
      "Suhas Thejaswi",
      "Manuel Gomez-Rodriguez"
    ],
    "abstract": "State of the art large language models rely on randomization to respond to a\nprompt. As an immediate consequence, a model may respond differently to the\nsame prompt if asked multiple times. In this work, we argue that the evaluation\nand ranking of large language models should control for the randomization\nunderpinning their functioning. Our starting point is the development of a\ncausal model for coupled autoregressive generation, which allows different\nlarge language models to sample responses with the same source of randomness.\nBuilding upon our causal model, we first show that, on evaluations based on\nbenchmark datasets, coupled autoregressive generation leads to the same\nconclusions as vanilla autoregressive generation but using provably fewer\nsamples. However, we further show that, on evaluations based on (human)\npairwise comparisons, coupled and vanilla autoregressive generation can\nsurprisingly lead to different rankings when comparing more than two models,\neven with an infinite amount of samples. This suggests that the apparent\nadvantage of a model over others in existing evaluation protocols may not be\ngenuine but rather confounded by the randomness inherent to the generation\nprocess. To illustrate and complement our theoretical results, we conduct\nexperiments with several large language models from the Llama family. We find\nthat, across multiple knowledge areas from the popular MMLU benchmark dataset,\ncoupled autoregressive generation requires up to 40% fewer samples to reach the\nsame conclusions as vanilla autoregressive generation. Further, using data from\nthe LMSYS Chatbot Arena platform, we find that the win-rates derived from\npairwise comparisons by a strong large language model to prompts differ under\ncoupled and vanilla autoregressive generation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01754v1",
    "published_date": "2025-02-03 19:01:17 UTC",
    "updated_date": "2025-02-03 19:01:17 UTC"
  },
  {
    "arxiv_id": "2502.01739v1",
    "title": "Grokking vs. Learning: Same Features, Different Encodings",
    "authors": [
      "Dmitry Manning-Coe",
      "Jacopo Gliozzi",
      "Alexander G. Stapleton",
      "Edward Hirst",
      "Giuseppe De Tomasi",
      "Barry Bradlyn",
      "David S. Berman"
    ],
    "abstract": "Grokking typically achieves similar loss to ordinary, \"steady\", learning. We\nask whether these different learning paths - grokking versus ordinary training\n- lead to fundamental differences in the learned models. To do so we compare\nthe features, compressibility, and learning dynamics of models trained via each\npath in two tasks. We find that grokked and steadily trained models learn the\nsame features, but there can be large differences in the efficiency with which\nthese features are encoded. In particular, we find a novel \"compressive regime\"\nof steady training in which there emerges a linear trade-off between model loss\nand compressibility, and which is absent in grokking. In this regime, we can\nachieve compression factors 25x times the base model, and 5x times the\ncompression achieved in grokking. We then track how model features and\ncompressibility develop through training. We show that model development in\ngrokking is task-dependent, and that peak compressibility is achieved\nimmediately after the grokking plateau. Finally, novel information-geometric\nmeasures are introduced which demonstrate that models undergoing grokking\nfollow a straight path in information space.",
    "categories": [
      "cs.LG",
      "cond-mat.dis-nn",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Code available at:\n  https://github.com/xand-stapleton/grokking_vs_learning",
    "pdf_url": "http://arxiv.org/pdf/2502.01739v1",
    "published_date": "2025-02-03 19:00:02 UTC",
    "updated_date": "2025-02-03 19:00:02 UTC"
  },
  {
    "arxiv_id": "2502.03482v1",
    "title": "Can Domain Experts Rely on AI Appropriately? A Case Study on AI-Assisted Prostate Cancer MRI Diagnosis",
    "authors": [
      "Chacha Chen",
      "Han Liu",
      "Jiamin Yang",
      "Benjamin M. Mervak",
      "Bora Kalaycioglu",
      "Grace Lee",
      "Emre Cakmakli",
      "Matteo Bonatti",
      "Sridhar Pudu",
      "Osman Kahraman",
      "Gul Gizem Pamuk",
      "Aytekin Oto",
      "Aritrick Chatterjee",
      "Chenhao Tan"
    ],
    "abstract": "Despite the growing interest in human-AI decision making, experimental\nstudies with domain experts remain rare, largely due to the complexity of\nworking with domain experts and the challenges in setting up realistic\nexperiments. In this work, we conduct an in-depth collaboration with\nradiologists in prostate cancer diagnosis based on MRI images. Building on\nexisting tools for teaching prostate cancer diagnosis, we develop an interface\nand conduct two experiments to study how AI assistance and performance feedback\nshape the decision making of domain experts. In Study 1, clinicians were asked\nto provide an initial diagnosis (human), then view the AI's prediction, and\nsubsequently finalize their decision (human-AI team). In Study 2 (after a\nmemory wash-out period), the same participants first received aggregated\nperformance statistics from Study 1, specifically their own performance, the\nAI's performance, and their human-AI team performance, and then directly viewed\nthe AI's prediction before making their diagnosis (i.e., no independent initial\ndiagnosis). These two workflows represent realistic ways that clinical AI tools\nmight be used in practice, where the second study simulates a scenario where\ndoctors can adjust their reliance and trust on AI based on prior performance\nfeedback. Our findings show that, while human-AI teams consistently outperform\nhumans alone, they still underperform the AI due to under-reliance, similar to\nprior studies with crowdworkers. Providing clinicians with performance feedback\ndid not significantly improve the performance of human-AI teams, although\nshowing AI decisions in advance nudges people to follow AI more. Meanwhile, we\nobserve that the ensemble of human-AI teams can outperform AI alone, suggesting\npromising directions for human-AI collaboration.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.CY",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.03482v1",
    "published_date": "2025-02-03 18:59:38 UTC",
    "updated_date": "2025-02-03 18:59:38 UTC"
  },
  {
    "arxiv_id": "2502.05209v2",
    "title": "Model Tampering Attacks Enable More Rigorous Evaluations of LLM Capabilities",
    "authors": [
      "Zora Che",
      "Stephen Casper",
      "Robert Kirk",
      "Anirudh Satheesh",
      "Stewart Slocum",
      "Lev E McKinney",
      "Rohit Gandikota",
      "Aidan Ewart",
      "Domenic Rosati",
      "Zichu Wu",
      "Zikui Cai",
      "Bilal Chughtai",
      "Yarin Gal",
      "Furong Huang",
      "Dylan Hadfield-Menell"
    ],
    "abstract": "Evaluations of large language model (LLM) risks and capabilities are\nincreasingly being incorporated into AI risk management and governance\nframeworks. Currently, most risk evaluations are conducted by designing inputs\nthat elicit harmful behaviors from the system. However, this approach suffers\nfrom two limitations. First, input-output evaluations cannot evaluate realistic\nrisks from open-weight models. Second, the behaviors identified during any\nparticular input-output evaluation can only lower-bound the model's\nworst-possible-case input-output behavior. As a complementary method for\neliciting harmful behaviors, we propose evaluating LLMs with model tampering\nattacks which allow for modifications to latent activations or weights. We pit\nstate-of-the-art techniques for removing harmful LLM capabilities against a\nsuite of 5 input-space and 6 model tampering attacks. In addition to\nbenchmarking these methods against each other, we show that (1) model\nresilience to capability elicitation attacks lies on a low-dimensional\nrobustness subspace; (2) the attack success rate of model tampering attacks can\nempirically predict and offer conservative estimates for the success of\nheld-out input-space attacks; and (3) state-of-the-art unlearning methods can\neasily be undone within 16 steps of fine-tuning. Together these results\nhighlight the difficulty of suppressing harmful LLM capabilities and show that\nmodel tampering attacks enable substantially more rigorous evaluations than\ninput-space attacks alone.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05209v2",
    "published_date": "2025-02-03 18:59:16 UTC",
    "updated_date": "2025-04-12 22:03:08 UTC"
  },
  {
    "arxiv_id": "2502.01636v2",
    "title": "Lifelong Knowledge Editing requires Better Regularization",
    "authors": [
      "Akshat Gupta",
      "Phudish Prateepamornkul",
      "Maochuan Lu",
      "Ahmed Alaa",
      "Thomas Hartvigsen",
      "Gopala Anumanchipalli"
    ],
    "abstract": "Knowledge editing is a promising way to improve factuality in large language\nmodels, but recent studies have shown significant model degradation during\nsequential editing. In this paper, we formalize the popular locate-then-edit\nmethods as a two-step fine-tuning process, allowing us to precisely identify\nthe root cause of this degradation. We show that model degradation occurs due\nto (1) over-optimization of internal activations and (2) continuous norm-growth\nof edited matrices. To mitigate these issues, we introduce two regularization\ntechniques: (1) Most-Probable Early Stopping (MPES) and (2) explicit Frobenius\nnorm-constraint. We demonstrate that applying these simple yet effective\nregularization techniques at key points in the editing process can\nsubstantially mitigate model degradation. Combining these regularization\nmethods enables scaling locate-then-edit methods to 10,000 edits while reducing\nediting time by 42-61%. These results show that targeted regularization is\nessential for lifelong knowledge editing.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01636v2",
    "published_date": "2025-02-03 18:59:14 UTC",
    "updated_date": "2025-05-21 17:58:23 UTC"
  },
  {
    "arxiv_id": "2502.01635v1",
    "title": "The AI Agent Index",
    "authors": [
      "Stephen Casper",
      "Luke Bailey",
      "Rosco Hunter",
      "Carson Ezell",
      "Emma Cabalé",
      "Michael Gerovitch",
      "Stewart Slocum",
      "Kevin Wei",
      "Nikola Jurkovic",
      "Ariba Khan",
      "Phillip J. K. Christoffersen",
      "A. Pinar Ozisik",
      "Rakshit Trivedi",
      "Dylan Hadfield-Menell",
      "Noam Kolt"
    ],
    "abstract": "Leading AI developers and startups are increasingly deploying agentic AI\nsystems that can plan and execute complex tasks with limited human involvement.\nHowever, there is currently no structured framework for documenting the\ntechnical components, intended uses, and safety features of agentic systems. To\nfill this gap, we introduce the AI Agent Index, the first public database to\ndocument information about currently deployed agentic AI systems. For each\nsystem that meets the criteria for inclusion in the index, we document the\nsystem's components (e.g., base model, reasoning implementation, tool use),\napplication domains (e.g., computer use, software engineering), and risk\nmanagement practices (e.g., evaluation results, guardrails), based on publicly\navailable information and correspondence with developers. We find that while\ndevelopers generally provide ample information regarding the capabilities and\napplications of agentic systems, they currently provide limited information\nregarding safety and risk management practices. The AI Agent Index is available\nonline at https://aiagentindex.mit.edu/",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Accompanying website: https://aiagentindex.mit.edu/",
    "pdf_url": "http://arxiv.org/pdf/2502.01635v1",
    "published_date": "2025-02-03 18:59:13 UTC",
    "updated_date": "2025-02-03 18:59:13 UTC"
  },
  {
    "arxiv_id": "2502.01634v1",
    "title": "Online Gradient Boosting Decision Tree: In-Place Updates for Efficient Adding/Deleting Data",
    "authors": [
      "Huawei Lin",
      "Jun Woo Chung",
      "Yingjie Lao",
      "Weijie Zhao"
    ],
    "abstract": "Gradient Boosting Decision Tree (GBDT) is one of the most popular machine\nlearning models in various applications. However, in the traditional settings,\nall data should be simultaneously accessed in the training procedure: it does\nnot allow to add or delete any data instances after training. In this paper, we\npropose an efficient online learning framework for GBDT supporting both\nincremental and decremental learning. To the best of our knowledge, this is the\nfirst work that considers an in-place unified incremental and decremental\nlearning on GBDT. To reduce the learning cost, we present a collection of\noptimizations for our framework, so that it can add or delete a small fraction\nof data on the fly. We theoretically show the relationship between the\nhyper-parameters of the proposed optimizations, which enables trading off\naccuracy and cost on incremental and decremental learning. The backdoor attack\nresults show that our framework can successfully inject and remove backdoor in\na well-trained model using incremental and decremental learning, and the\nempirical results on public datasets confirm the effectiveness and efficiency\nof our proposed online learning framework and optimizations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "25 pages, 11 figures, 16 tables. Keywords: Decremental Learning,\n  Incremental Learning, Machine Unlearning, Online Learning, Gradient Boosting\n  Decision Trees, GBDTs",
    "pdf_url": "http://arxiv.org/pdf/2502.01634v1",
    "published_date": "2025-02-03 18:59:04 UTC",
    "updated_date": "2025-02-03 18:59:04 UTC"
  },
  {
    "arxiv_id": "2502.01633v1",
    "title": "Adversarial Reasoning at Jailbreaking Time",
    "authors": [
      "Mahdi Sabbaghi",
      "Paul Kassianik",
      "George Pappas",
      "Yaron Singer",
      "Amin Karbasi",
      "Hamed Hassani"
    ],
    "abstract": "As large language models (LLMs) are becoming more capable and widespread, the\nstudy of their failure cases is becoming increasingly important. Recent\nadvances in standardizing, measuring, and scaling test-time compute suggest new\nmethodologies for optimizing models to achieve high performance on hard tasks.\nIn this paper, we apply these advances to the task of model jailbreaking:\neliciting harmful responses from aligned LLMs. We develop an adversarial\nreasoning approach to automatic jailbreaking via test-time computation that\nachieves SOTA attack success rates (ASR) against many aligned LLMs, even the\nones that aim to trade inference-time compute for adversarial robustness. Our\napproach introduces a new paradigm in understanding LLM vulnerabilities, laying\nthe foundation for the development of more robust and trustworthy AI systems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01633v1",
    "published_date": "2025-02-03 18:59:01 UTC",
    "updated_date": "2025-02-03 18:59:01 UTC"
  },
  {
    "arxiv_id": "2502.01630v1",
    "title": "TReMu: Towards Neuro-Symbolic Temporal Reasoning for LLM-Agents with Memory in Multi-Session Dialogues",
    "authors": [
      "Yubin Ge",
      "Salvatore Romeo",
      "Jason Cai",
      "Raphael Shu",
      "Monica Sunkara",
      "Yassine Benajiba",
      "Yi Zhang"
    ],
    "abstract": "Temporal reasoning in multi-session dialogues presents a significant\nchallenge which has been under-studied in previous temporal reasoning\nbenchmarks. To bridge this gap, we propose a new evaluation task for temporal\nreasoning in multi-session dialogues and introduce an approach to construct a\nnew benchmark by augmenting dialogues from LoCoMo and creating multi-choice\nQAs. Furthermore, we present TReMu, a new framework aimed at enhancing the\ntemporal reasoning capabilities of LLM-agents in this context. Specifically,\nthe framework employs \\textit{time-aware memorization} through timeline\nsummarization, generating retrievable memory by summarizing events in each\ndialogue session with their inferred dates. Additionally, we integrate\n\\textit{neuro-symbolic temporal reasoning}, where LLMs generate Python code to\nperform temporal calculations and select answers. Experimental evaluations on\npopular LLMs demonstrate that our benchmark is challenging, and the proposed\nframework significantly improves temporal reasoning performance compared to\nbaseline methods, raising from 29.83 on GPT-4o via standard prompting to 77.67\nvia our approach and highlighting its effectiveness in addressing temporal\nreasoning in multi-session dialogues.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01630v1",
    "published_date": "2025-02-03 18:58:19 UTC",
    "updated_date": "2025-02-03 18:58:19 UTC"
  },
  {
    "arxiv_id": "2502.01619v2",
    "title": "Learning to Generate Unit Tests for Automated Debugging",
    "authors": [
      "Archiki Prasad",
      "Elias Stengel-Eskin",
      "Justin Chih-Yao Chen",
      "Zaid Khan",
      "Mohit Bansal"
    ],
    "abstract": "Unit tests (UTs) play an instrumental role in assessing code correctness as\nwell as providing feedback to large language models (LLMs), motivating\nautomated test generation. However, we uncover a trade-off between generating\nunit test inputs that reveal errors when given a faulty code and correctly\npredicting the unit test output without access to the gold solution. To address\nthis trade-off, we propose UTGen, which teaches LLMs to generate unit test\ninputs that reveal errors along with their correct expected outputs based on\ntask descriptions. Since model-generated tests can provide noisy signals (e.g.,\nfrom incorrectly predicted outputs), we propose UTDebug that (i) scales UTGen\nvia test-time compute to improve UT output prediction, and (ii) validates and\nbacktracks edits based on multiple generated UTs to avoid overfitting, and\nhelps LLMs debug effectively. We show that UTGen outperforms other LLM-based\nbaselines by 7.59% based on a metric measuring the presence of both\nerror-revealing UT inputs and correct UT outputs. When used with UTDebug, we\nfind that feedback from UTGen's unit tests improves pass@1 accuracy of Qwen2.5\n32B on HumanEvalFix and our own harder debugging split of MBPP+ by over 3.17%\nand 12.35% (respectively) over other LLM-based UT generation baselines. Lastly,\nwe demonstrate that UTGen is a better judge for code correctness, outperforming\na state-of-the-art trained 8B reward model by 4.43% on HumanEval+ with\nbest-of-10 sampling using Qwen2.5 7B.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "First two authors contributed equally. Dataset and Code:\n  https://github.com/archiki/UTGenDebug",
    "pdf_url": "http://arxiv.org/pdf/2502.01619v2",
    "published_date": "2025-02-03 18:51:43 UTC",
    "updated_date": "2025-02-26 18:03:54 UTC"
  },
  {
    "arxiv_id": "2502.01618v3",
    "title": "A Probabilistic Inference Approach to Inference-Time Scaling of LLMs using Particle-Based Monte Carlo Methods",
    "authors": [
      "Isha Puri",
      "Shivchander Sudalairaj",
      "Guangxuan Xu",
      "Kai Xu",
      "Akash Srivastava"
    ],
    "abstract": "Large language models (LLMs) have achieved significant performance gains via\nscaling up model sizes and/or data. However, recent evidence suggests\ndiminishing returns from such approaches, motivating scaling the computation\nspent at inference time. Existing inference-time scaling methods, usually with\nreward models, cast the task as a search problem, which tends to be vulnerable\nto reward hacking as a consequence of approximation errors in reward models. In\nthis paper, we instead cast inference-time scaling as a probabilistic inference\ntask and leverage sampling-based techniques to explore the typical set of the\nstate distribution of a state-space model with an approximate likelihood,\nrather than optimize for its mode directly. We propose a novel inference-time\nscaling approach by adapting particle-based Monte Carlo methods to this task.\nOur empirical evaluation demonstrates that our methods have a 4-16x better\nscaling rate over our deterministic search counterparts on various challenging\nmathematical reasoning tasks. Using our approach, we show that\nQwen2.5-Math-1.5B-Instruct can surpass GPT-4o accuracy in only 4 rollouts,\nwhile Qwen2.5-Math-7B-Instruct scales to o1 level accuracy in only 32 rollouts.\nOur work not only presents an effective method to inference-time scaling, but\nalso connects the rich literature in probabilistic inference with\ninference-time scaling of LLMs to develop more robust algorithms in future\nwork. Code, videos, and further information available at\nhttps://probabilistic-inference-scaling.github.io.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01618v3",
    "published_date": "2025-02-03 18:50:50 UTC",
    "updated_date": "2025-02-11 23:52:26 UTC"
  },
  {
    "arxiv_id": "2502.01718v3",
    "title": "ACECODER: Acing Coder RL via Automated Test-Case Synthesis",
    "authors": [
      "Huaye Zeng",
      "Dongfu Jiang",
      "Haozhe Wang",
      "Ping Nie",
      "Xiaotong Chen",
      "Wenhu Chen"
    ],
    "abstract": "Most progress in recent coder models has been driven by supervised\nfine-tuning (SFT), while the potential of reinforcement learning (RL) remains\nlargely unexplored, primarily due to the lack of reliable reward data/model in\nthe code domain. In this paper, we address this challenge by leveraging\nautomated large-scale test-case synthesis to enhance code model training.\nSpecifically, we design a pipeline that generates extensive (question,\ntest-cases) pairs from existing code data. Using these test cases, we construct\npreference pairs based on pass rates over sampled programs to train reward\nmodels with Bradley-Terry loss. It shows an average of 10-point improvement for\nLlama-3.1-8B-Ins and 5-point improvement for Qwen2.5-Coder-7B-Ins through\nbest-of-32 sampling, making the 7B model on par with 236B DeepSeek-V2.5.\nFurthermore, we conduct reinforcement learning with both reward models and\ntest-case pass rewards, leading to consistent improvements across HumanEval,\nMBPP, BigCodeBench, and LiveCodeBench (V4). Notably, we follow the R1-style\ntraining to start from Qwen2.5-Coder-base directly and show that our RL\ntraining can improve model on HumanEval-plus by over 25\\% and MBPP-plus by 6\\%\nfor merely 80 optimization steps. We believe our results highlight the huge\npotential of reinforcement learning in coder models.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "9 pages, 1 figure, 8 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.01718v3",
    "published_date": "2025-02-03 18:46:04 UTC",
    "updated_date": "2025-02-10 18:40:00 UTC"
  },
  {
    "arxiv_id": "2502.01612v2",
    "title": "Self-Improving Transformers Overcome Easy-to-Hard and Length Generalization Challenges",
    "authors": [
      "Nayoung Lee",
      "Ziyang Cai",
      "Avi Schwarzschild",
      "Kangwook Lee",
      "Dimitris Papailiopoulos"
    ],
    "abstract": "Large language models often struggle with length generalization and solving\ncomplex problem instances beyond their training distribution. We present a\nself-improvement approach where models iteratively generate and learn from\ntheir own solutions, progressively tackling harder problems while maintaining a\nstandard transformer architecture. Across diverse tasks including arithmetic,\nstring manipulation, and maze solving, self-improving enables models to solve\nproblems far beyond their initial training distribution-for instance,\ngeneralizing from 10-digit to 100-digit addition without apparent saturation.\nWe observe that in some cases filtering for correct self-generated examples\nleads to exponential improvements in out-of-distribution performance across\ntraining rounds. Additionally, starting from pretrained models significantly\naccelerates this self-improvement process for several tasks. Our results\ndemonstrate how controlled weak-to-strong curricula can systematically teach a\nmodel logical extrapolation without any changes to the positional embeddings,\nor the model architecture.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Added references",
    "pdf_url": "http://arxiv.org/pdf/2502.01612v2",
    "published_date": "2025-02-03 18:45:22 UTC",
    "updated_date": "2025-02-13 05:32:54 UTC"
  },
  {
    "arxiv_id": "2502.01600v3",
    "title": "Reinforcement Learning for Long-Horizon Interactive LLM Agents",
    "authors": [
      "Kevin Chen",
      "Marco Cusumano-Towner",
      "Brody Huval",
      "Aleksei Petrenko",
      "Jackson Hamburger",
      "Vladlen Koltun",
      "Philipp Krähenbühl"
    ],
    "abstract": "Interactive digital agents (IDAs) leverage APIs of stateful digital\nenvironments to perform tasks in response to user requests. While IDAs powered\nby instruction-tuned large language models (LLMs) can react to feedback from\ninterface invocations in multi-step exchanges, they have not been trained in\ntheir respective digital environments. Prior methods accomplish less than half\nof tasks in sophisticated benchmarks such as AppWorld. We present a\nreinforcement learning (RL) approach that trains IDAs directly in their target\nenvironments. We formalize this training as a partially observable Markov\ndecision process and derive LOOP, a data- and memory-efficient variant of\nproximal policy optimization. LOOP uses no value network and maintains exactly\none copy of the underlying LLM in memory, making its implementation\nstraightforward and as memory-efficient as fine-tuning a single LLM. A\n32-billion-parameter agent trained with LOOP in the AppWorld environment\noutperforms the much larger OpenAI o1 agent by 9 percentage points (15%\nrelative). To our knowledge, this is the first reported application of RL to\nIDAs that interact with a stateful, multi-domain, multi-app environment via\ndirect API calls. Our analysis sheds light on the effectiveness of RL in this\narea, showing that the agent learns to consult the API documentation, avoid\nunwarranted assumptions, minimize confabulation, and recover from setbacks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01600v3",
    "published_date": "2025-02-03 18:35:42 UTC",
    "updated_date": "2025-03-08 05:23:57 UTC"
  },
  {
    "arxiv_id": "2502.01591v1",
    "title": "Improving Transformer World Models for Data-Efficient RL",
    "authors": [
      "Antoine Dedieu",
      "Joseph Ortiz",
      "Xinghua Lou",
      "Carter Wendelken",
      "Wolfgang Lehrach",
      "J Swaroop Guntupalli",
      "Miguel Lazaro-Gredilla",
      "Kevin Patrick Murphy"
    ],
    "abstract": "We present an approach to model-based RL that achieves a new state of the art\nperformance on the challenging Craftax-classic benchmark, an open-world 2D\nsurvival game that requires agents to exhibit a wide range of general abilities\n-- such as strong generalization, deep exploration, and long-term reasoning.\nWith a series of careful design choices aimed at improving sample efficiency,\nour MBRL algorithm achieves a reward of 67.4% after only 1M environment steps,\nsignificantly outperforming DreamerV3, which achieves 53.2%, and, for the first\ntime, exceeds human performance of 65.0%. Our method starts by constructing a\nSOTA model-free baseline, using a novel policy architecture that combines CNNs\nand RNNs. We then add three improvements to the standard MBRL setup: (a) \"Dyna\nwith warmup\", which trains the policy on real and imaginary data, (b) \"nearest\nneighbor tokenizer\" on image patches, which improves the scheme to create the\ntransformer world model (TWM) inputs, and (c) \"block teacher forcing\", which\nallows the TWM to reason jointly about the future tokens of the next timestep.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01591v1",
    "published_date": "2025-02-03 18:25:17 UTC",
    "updated_date": "2025-02-03 18:25:17 UTC"
  },
  {
    "arxiv_id": "2502.01587v1",
    "title": "Verbalized Bayesian Persuasion",
    "authors": [
      "Wenhao Li",
      "Yue Lin",
      "Xiangfeng Wang",
      "Bo Jin",
      "Hongyuan Zha",
      "Baoxiang Wang"
    ],
    "abstract": "Information design (ID) explores how a sender influence the optimal behavior\nof receivers to achieve specific objectives. While ID originates from everyday\nhuman communication, existing game-theoretic and machine learning methods often\nmodel information structures as numbers, which limits many applications to toy\ngames. This work leverages LLMs and proposes a verbalized framework in Bayesian\npersuasion (BP), which extends classic BP to real-world games involving human\ndialogues for the first time. Specifically, we map the BP to a verbalized\nmediator-augmented extensive-form game, where LLMs instantiate the sender and\nreceiver. To efficiently solve the verbalized game, we propose a generalized\nequilibrium-finding algorithm combining LLM and game solver. The algorithm is\nreinforced with techniques including verbalized commitment assumptions,\nverbalized obedience constraints, and information obfuscation. Numerical\nexperiments in dialogue scenarios, such as recommendation letters, courtroom\ninteractions, and law enforcement, validate that our framework can both\nreproduce theoretical results in classic BP and discover effective persuasion\nstrategies in more complex natural language and multi-stage scenarios.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.GT",
    "comment": "63 pages, 21 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.01587v1",
    "published_date": "2025-02-03 18:20:10 UTC",
    "updated_date": "2025-02-03 18:20:10 UTC"
  },
  {
    "arxiv_id": "2502.01584v3",
    "title": "PhD Knowledge Not Required: A Reasoning Challenge for Large Language Models",
    "authors": [
      "Zixuan Wu",
      "Francesca Lucchetti",
      "Aleksander Boruch-Gruszecki",
      "Jingmiao Zhao",
      "Carolyn Jane Anderson",
      "Joydeep Biswas",
      "Federico Cassano",
      "Molly Q Feldman",
      "Arjun Guha"
    ],
    "abstract": "Existing benchmarks for frontier models often test specialized, \"PhD-level\"\nknowledge that is difficult for non-experts to grasp. In contrast, we present a\nbenchmark with 594 problems based on the NPR Sunday Puzzle Challenge that\nrequires only general knowledge. Our benchmark is challenging for both humans\nand models; however correct solutions are easy to verify, and models' mistakes\nare easy to spot. As LLMs are more widely deployed in society, we believe it is\nuseful to develop benchmarks for frontier models that humans can understand\nwithout the need for deep domain expertise.\n  Our work reveals capability gaps that are not evident in existing benchmarks:\nOpenAI o1 significantly outperforms other reasoning models on our benchmark,\ndespite being on par with other models when tested on benchmarks that test\nspecialized knowledge. Furthermore, our analysis of reasoning outputs uncovers\nnew kinds of failures. DeepSeek R1, for instance, often concedes with \"I give\nup\" before providing an answer that it knows is wrong. R1 can also be\nremarkably \"uncertain\" in its output and in rare cases, it does not \"finish\nthinking,\" which suggests the need for techniques to \"wrap up\" before the\ncontext window limit is reached. We also quantify the effectiveness of\nreasoning longer to identify the point beyond which more reasoning is unlikely\nto improve accuracy on our benchmark.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01584v3",
    "published_date": "2025-02-03 18:10:38 UTC",
    "updated_date": "2025-03-31 14:21:49 UTC"
  },
  {
    "arxiv_id": "2502.01573v1",
    "title": "Next Steps in LLM-Supported Java Verification",
    "authors": [
      "Samuel Teuber",
      "Bernhard Beckert"
    ],
    "abstract": "Recent work has shown that Large Language Models (LLMs) are not only a\nsuitable tool for code generation but also capable of generating\nannotation-based code specifications. Scaling these methodologies may allow us\nto deduce provable correctness guarantees for large-scale software systems. In\ncomparison to other LLM tasks, the application field of deductive verification\nhas the notable advantage of providing a rigorous toolset to check\nLLM-generated solutions. This short paper provides early results on how this\nrigorous toolset can be used to reliably elicit correct specification\nannotations from an unreliable LLM oracle.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG",
      "cs.LO"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted to NSE 2025, 1st International Workshop on Neuro-Symbolic\n  Software Engineering (ICSE Workshop), 6 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.01573v1",
    "published_date": "2025-02-03 17:55:50 UTC",
    "updated_date": "2025-02-03 17:55:50 UTC"
  },
  {
    "arxiv_id": "2502.01568v5",
    "title": "Visual Theory of Mind Enables the Invention of Proto-Writing",
    "authors": [
      "Benjamin A. Spiegel",
      "Lucas Gelfond",
      "George Konidaris"
    ],
    "abstract": "Symbolic writing systems are graphical semiotic codes that are ubiquitous in\nmodern society but are otherwise absent in the animal kingdom. Anthropological\nevidence suggests that the earliest forms of some writing systems originally\nconsisted of iconic pictographs, which signify their referent via visual\nresemblance. While previous studies have examined the emergence and,\nseparately, the evolution of pictographic systems through a computational lens,\nmost employ non-naturalistic methodologies that make it difficult to draw clear\nanalogies to human and animal cognition. We develop a multi-agent reinforcement\nlearning testbed for emergent communication called a Signification Game, and\nformulate a model of inferential communication that enables agents to leverage\nvisual theory of mind to communicate actions using pictographs. Our model,\nwhich is situated within a broader formalism for animal communication, sheds\nlight on the cognitive and cultural processes underlying the emergence of\nproto-writing.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted for oral presentation at CogSci 2025, published here with\n  permission from organizers",
    "pdf_url": "http://arxiv.org/pdf/2502.01568v5",
    "published_date": "2025-02-03 17:50:37 UTC",
    "updated_date": "2025-05-10 19:24:55 UTC"
  },
  {
    "arxiv_id": "2502.01564v1",
    "title": "MeetMap: Real-Time Collaborative Dialogue Mapping with LLMs in Online Meetings",
    "authors": [
      "Xinyue Chen",
      "Nathan Yap",
      "Xinyi Lu",
      "Aylin Gunal",
      "Xu Wang"
    ],
    "abstract": "Video meeting platforms display conversations linearly through transcripts or\nsummaries. However, ideas during a meeting do not emerge linearly. We leverage\nLLMs to create dialogue maps in real time to help people visually structure and\nconnect ideas. Balancing the need to reduce the cognitive load on users during\nthe conversation while giving them sufficient control when using AI, we explore\ntwo system variants that encompass different levels of AI assistance. In\nHuman-Map, AI generates summaries of conversations as nodes, and users create\ndialogue maps with the nodes. In AI-Map, AI produces dialogue maps where users\ncan make edits. We ran a within-subject experiment with ten pairs of users,\ncomparing the two MeetMap variants and a baseline. Users preferred MeetMap over\ntraditional methods for taking notes, which aligned better with their mental\nmodels of conversations. Users liked the ease of use for AI-Map due to the low\neffort demands and appreciated the hands-on opportunity in Human-Map for\nsense-making.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "CSCW2025 Accepted",
    "pdf_url": "http://arxiv.org/pdf/2502.01564v1",
    "published_date": "2025-02-03 17:47:15 UTC",
    "updated_date": "2025-02-03 17:47:15 UTC"
  },
  {
    "arxiv_id": "2502.01558v1",
    "title": "Search-Based Adversarial Estimates for Improving Sample Efficiency in Off-Policy Reinforcement Learning",
    "authors": [
      "Federico Malato",
      "Ville Hautamaki"
    ],
    "abstract": "Sample inefficiency is a long-lasting challenge in deep reinforcement\nlearning (DRL). Despite dramatic improvements have been made, the problem is\nfar from being solved and is especially challenging in environments with sparse\nor delayed rewards. In our work, we propose to use Adversarial Estimates as a\nnew, simple and efficient approach to mitigate this problem for a class of\nfeedback-based DRL algorithms. Our approach leverages latent similarity search\nfrom a small set of human-collected trajectories to boost learning, using only\nfive minutes of human-recorded experience. The results of our study show\nalgorithms trained with Adversarial Estimates converge faster than their\noriginal version. Moreover, we discuss how our approach could enable learning\nin feedback-based algorithms in extreme scenarios with very sparse rewards.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Submitted to International Conference on Machine Learning 2025.\n  Currently under peer-review",
    "pdf_url": "http://arxiv.org/pdf/2502.01558v1",
    "published_date": "2025-02-03 17:41:02 UTC",
    "updated_date": "2025-02-03 17:41:02 UTC"
  },
  {
    "arxiv_id": "2502.01555v1",
    "title": "Query Brand Entity Linking in E-Commerce Search",
    "authors": [
      "Dong Liu",
      "Sreyashi Nag"
    ],
    "abstract": "In this work, we address the brand entity linking problem for e-commerce\nsearch queries. The entity linking task is done by either i)a two-stage process\nconsisting of entity mention detection followed by entity disambiguation or ii)\nan end-to-end linking approaches that directly fetch the target entity given\nthe input text. The task presents unique challenges: queries are extremely\nshort (averaging 2.4 words), lack natural language structure, and must handle a\nmassive space of unique brands. We present a two-stage approach combining\nnamed-entity recognition with matching, and a novel end-to-end solution using\nextreme multi-class classification. We validate our solutions by both offline\nbenchmarks and the impact of online A/B test.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01555v1",
    "published_date": "2025-02-03 17:37:37 UTC",
    "updated_date": "2025-02-03 17:37:37 UTC"
  },
  {
    "arxiv_id": "2502.01550v1",
    "title": "FireCastNet: Earth-as-a-Graph for Seasonal Fire Prediction",
    "authors": [
      "Dimitrios Michail",
      "Charalampos Davalas",
      "Lefki-Ioanna Panagiotou",
      "Ioannis Prapas",
      "Spyros Kondylatos",
      "Nikolaos Ioannis Bountos",
      "Ioannis Papoutsis"
    ],
    "abstract": "With climate change expected to exacerbate fire weather conditions, the\naccurate and timely anticipation of wildfires becomes increasingly crucial for\ndisaster mitigation. In this study, we utilize SeasFire, a comprehensive global\nwildfire dataset with climate, vegetation, oceanic indices, and human-related\nvariables, to enable seasonal wildfire forecasting with machine learning. For\nthe predictive analysis, we present FireCastNet, a novel architecture which\ncombines a 3D convolutional encoder with GraphCast, originally developed for\nglobal short-term weather forecasting using graph neural networks. FireCastNet\nis trained to capture the context leading to wildfires, at different spatial\nand temporal scales. Our investigation focuses on assessing the effectiveness\nof our model in predicting the presence of burned areas at varying forecasting\ntime horizons globally, extending up to six months into the future, and on how\ndifferent spatial or/and temporal context affects the performance. Our findings\ndemonstrate the potential of deep learning models in seasonal fire forecasting;\nlonger input time-series leads to more robust predictions, while integrating\nspatial information to capture wildfire spatio-temporal dynamics boosts\nperformance. Finally, our results hint that in order to enhance performance at\nlonger forecasting horizons, a larger receptive field spatially needs to be\nconsidered.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01550v1",
    "published_date": "2025-02-03 17:30:45 UTC",
    "updated_date": "2025-02-03 17:30:45 UTC"
  },
  {
    "arxiv_id": "2502.05208v1",
    "title": "Mitigation of Camouflaged Adversarial Attacks in Autonomous Vehicles--A Case Study Using CARLA Simulator",
    "authors": [
      "Yago Romano Martinez",
      "Brady Carter",
      "Abhijeet Solanki",
      "Wesam Al Amiri",
      "Syed Rafay Hasan",
      "Terry N. Guo"
    ],
    "abstract": "Autonomous vehicles (AVs) rely heavily on cameras and artificial intelligence\n(AI) to make safe and accurate driving decisions. However, since AI is the core\nenabling technology, this raises serious cyber threats that hinder the\nlarge-scale adoption of AVs. Therefore, it becomes crucial to analyze the\nresilience of AV security systems against sophisticated attacks that manipulate\ncamera inputs, deceiving AI models. In this paper, we develop\ncamera-camouflaged adversarial attacks targeting traffic sign recognition (TSR)\nin AVs. Specifically, if the attack is initiated by modifying the texture of a\nstop sign to fool the AV's object detection system, thereby affecting the AV\nactuators. The attack's effectiveness is tested using the CARLA AV simulator\nand the results show that such an attack can delay the auto-braking response to\nthe stop sign, resulting in potential safety issues. We conduct extensive\nexperiments under various conditions, confirming that our new attack is\neffective and robust. Additionally, we address the attack by presenting\nmitigation strategies. The proposed attack and defense methods are applicable\nto other end-to-end trained autonomous cyber-physical systems.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.05208v1",
    "published_date": "2025-02-03 17:30:43 UTC",
    "updated_date": "2025-02-03 17:30:43 UTC"
  },
  {
    "arxiv_id": "2502.01549v1",
    "title": "VideoRAG: Retrieval-Augmented Generation with Extreme Long-Context Videos",
    "authors": [
      "Xubin Ren",
      "Lingrui Xu",
      "Long Xia",
      "Shuaiqiang Wang",
      "Dawei Yin",
      "Chao Huang"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) has demonstrated remarkable success in\nenhancing Large Language Models (LLMs) through external knowledge integration,\nyet its application has primarily focused on textual content, leaving the rich\ndomain of multi-modal video knowledge predominantly unexplored. This paper\nintroduces VideoRAG, the first retrieval-augmented generation framework\nspecifically designed for processing and understanding extremely long-context\nvideos. Our core innovation lies in its dual-channel architecture that\nseamlessly integrates (i) graph-based textual knowledge grounding for capturing\ncross-video semantic relationships, and (ii) multi-modal context encoding for\nefficiently preserving visual features. This novel design empowers VideoRAG to\nprocess unlimited-length videos by constructing precise knowledge graphs that\nspan multiple videos while maintaining semantic dependencies through\nspecialized multi-modal retrieval paradigms. Through comprehensive empirical\nevaluation on our proposed LongerVideos benchmark-comprising over 160 videos\ntotaling 134+ hours across lecture, documentary, and entertainment\ncategories-VideoRAG demonstrates substantial performance compared to existing\nRAG alternatives and long video understanding methods. The source code of\nVideoRAG implementation and the benchmark dataset are openly available at:\nhttps://github.com/HKUDS/VideoRAG.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01549v1",
    "published_date": "2025-02-03 17:30:19 UTC",
    "updated_date": "2025-02-03 17:30:19 UTC"
  },
  {
    "arxiv_id": "2502.01540v1",
    "title": "What is a Number, That a Large Language Model May Know It?",
    "authors": [
      "Raja Marjieh",
      "Veniamin Veselovsky",
      "Thomas L. Griffiths",
      "Ilia Sucholutsky"
    ],
    "abstract": "Numbers are a basic part of how humans represent and describe the world\naround them. As a consequence, learning effective representations of numbers is\ncritical for the success of large language models as they become more\nintegrated into everyday decisions. However, these models face a challenge:\ndepending on context, the same sequence of digit tokens, e.g., 911, can be\ntreated as a number or as a string. What kind of representations arise from\nthis duality, and what are its downstream implications? Using a\nsimilarity-based prompting technique from cognitive science, we show that LLMs\nlearn representational spaces that blend string-like and numerical\nrepresentations. In particular, we show that elicited similarity judgments from\nthese models over integer pairs can be captured by a combination of Levenshtein\nedit distance and numerical Log-Linear distance, suggesting an entangled\nrepresentation. In a series of experiments we show how this entanglement is\nreflected in the latent embeddings, how it can be reduced but not entirely\neliminated by context, and how it can propagate into a realistic decision\nscenario. These results shed light on a representational tension in transformer\nmodels that must learn what a number is from text input.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "16 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.01540v1",
    "published_date": "2025-02-03 17:17:26 UTC",
    "updated_date": "2025-02-03 17:17:26 UTC"
  },
  {
    "arxiv_id": "2502.01534v1",
    "title": "Preference Leakage: A Contamination Problem in LLM-as-a-judge",
    "authors": [
      "Dawei Li",
      "Renliang Sun",
      "Yue Huang",
      "Ming Zhong",
      "Bohan Jiang",
      "Jiawei Han",
      "Xiangliang Zhang",
      "Wei Wang",
      "Huan Liu"
    ],
    "abstract": "Large Language Models (LLMs) as judges and LLM-based data synthesis have\nemerged as two fundamental LLM-driven data annotation methods in model\ndevelopment. While their combination significantly enhances the efficiency of\nmodel training and evaluation, little attention has been given to the potential\ncontamination brought by this new model development paradigm. In this work, we\nexpose preference leakage, a contamination problem in LLM-as-a-judge caused by\nthe relatedness between the synthetic data generators and LLM-based evaluators.\nTo study this issue, we first define three common relatednesses between data\ngenerator LLM and judge LLM: being the same model, having an inheritance\nrelationship, and belonging to the same model family. Through extensive\nexperiments, we empirically confirm the bias of judges towards their related\nstudent models caused by preference leakage across multiple LLM baselines and\nbenchmarks. Further analysis suggests that preference leakage is a pervasive\nissue that is harder to detect compared to previously identified biases in\nLLM-as-a-judge scenarios. All of these findings imply that preference leakage\nis a widespread and challenging problem in the area of LLM-as-a-judge. We\nrelease all codes and data at:\nhttps://github.com/David-Li0406/Preference-Leakage.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "17 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.01534v1",
    "published_date": "2025-02-03 17:13:03 UTC",
    "updated_date": "2025-02-03 17:13:03 UTC"
  },
  {
    "arxiv_id": "2502.01533v1",
    "title": "Transformers trained on proteins can learn to attend to Euclidean distance",
    "authors": [
      "Isaac Ellmen",
      "Constantin Schneider",
      "Matthew I. J. Raybould",
      "Charlotte M. Deane"
    ],
    "abstract": "While conventional Transformers generally operate on sequence data, they can\nbe used in conjunction with structure models, typically SE(3)-invariant or\nequivariant graph neural networks (GNNs), for 3D applications such as protein\nstructure modelling. These hybrids typically involve either (1)\npreprocessing/tokenizing structural features as input for Transformers or (2)\ntaking Transformer embeddings and processing them within a structural\nrepresentation. However, there is evidence that Transformers can learn to\nprocess structural information on their own, such as the AlphaFold3 structural\ndiffusion model. In this work we show that Transformers can function\nindependently as structure models when passed linear embeddings of coordinates.\nWe first provide a theoretical explanation for how Transformers can learn to\nfilter attention as a 3D Gaussian with learned variance. We then validate this\ntheory using both simulated 3D points and in the context of masked token\nprediction for proteins. Finally, we show that pre-training protein Transformer\nencoders with structure improves performance on a downstream task, yielding\nbetter performance than custom structural models. Together, this work provides\na basis for using standard Transformers as hybrid structure-language models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.BM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01533v1",
    "published_date": "2025-02-03 17:12:44 UTC",
    "updated_date": "2025-02-03 17:12:44 UTC"
  },
  {
    "arxiv_id": "2502.01524v1",
    "title": "Efficiently Integrate Large Language Models with Visual Perception: A Survey from the Training Paradigm Perspective",
    "authors": [
      "Xiaorui Ma",
      "Haoran Xie",
      "S. Joe Qin"
    ],
    "abstract": "The integration of vision-language modalities has been a significant focus in\nmultimodal learning, traditionally relying on Vision-Language Pretrained\nModels. However, with the advent of Large Language Models (LLMs), there has\nbeen a notable shift towards incorporating LLMs with vision modalities.\nFollowing this, the training paradigms for incorporating vision modalities into\nLLMs have evolved. Initially, the approach was to integrate the modalities\nthrough pretraining the modality integrator, named Single-stage Tuning. It has\nsince branched out into methods focusing on performance enhancement, denoted as\nTwo-stage Tuning, and those prioritizing parameter efficiency, referred to as\nDirect Adaptation. However, existing surveys primarily address the latest\nVision Large Language Models (VLLMs) with Two-stage Tuning, leaving a gap in\nunderstanding the evolution of training paradigms and their unique\nparameter-efficient considerations. This paper categorizes and reviews 34 VLLMs\nfrom top conferences, journals, and highly cited Arxiv papers, focusing on\nparameter efficiency during adaptation from the training paradigm perspective.\nWe first introduce the architecture of LLMs and parameter-efficient learning\nmethods, followed by a discussion on vision encoders and a comprehensive\ntaxonomy of modality integrators. We then review three training paradigms and\ntheir efficiency considerations, summarizing benchmarks in the VLLM field. To\ngain deeper insights into their effectiveness in parameter efficiency, we\ncompare and discuss the experimental results of representative models, among\nwhich the experiment of the Direct Adaptation paradigm is replicated. Providing\ninsights into recent developments and practical uses, this survey is a vital\nguide for researchers and practitioners navigating the efficient integration of\nvision modalities into LLMs.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "28 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.01524v1",
    "published_date": "2025-02-03 17:01:59 UTC",
    "updated_date": "2025-02-03 17:01:59 UTC"
  },
  {
    "arxiv_id": "2502.01521v2",
    "title": "Toward Task Generalization via Memory Augmentation in Meta-Reinforcement Learning",
    "authors": [
      "Kaixi Bao",
      "Chenhao Li",
      "Yarden As",
      "Andreas Krause",
      "Marco Hutter"
    ],
    "abstract": "Agents trained via reinforcement learning (RL) often struggle to perform well\non tasks that differ from those encountered during training. This limitation\npresents a challenge to the broader deployment of RL in diverse and dynamic\ntask settings. In this work, we introduce memory augmentation, a memory-based\nRL approach to improve task generalization. Our approach leverages\ntask-structured augmentations to simulate plausible out-of-distribution\nscenarios and incorporates memory mechanisms to enable context-aware policy\nadaptation. Trained on a predefined set of tasks, our policy demonstrates the\nability to generalize to unseen tasks through memory augmentation without\nrequiring additional interactions with the environment. Through extensive\nsimulation experiments and real-world hardware evaluations on legged locomotion\ntasks, we demonstrate that our approach achieves zero-shot generalization to\nunseen tasks while maintaining robust in-distribution performance and high\nsample efficiency.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01521v2",
    "published_date": "2025-02-03 17:00:19 UTC",
    "updated_date": "2025-05-07 18:57:25 UTC"
  },
  {
    "arxiv_id": "2503.04736v1",
    "title": "Standardizing Intelligence: Aligning Generative AI for Regulatory and Operational Compliance",
    "authors": [
      "Joseph Marvin Imperial",
      "Matthew D. Jones",
      "Harish Tayyar Madabushi"
    ],
    "abstract": "Technical standards, or simply standards, are established documented\nguidelines and rules that facilitate the interoperability, quality, and\naccuracy of systems and processes. In recent years, we have witnessed an\nemerging paradigm shift where the adoption of generative AI (GenAI) models has\nincreased tremendously, spreading implementation interests across\nstandard-driven industries, including engineering, legal, healthcare, and\neducation. In this paper, we assess the criticality levels of different\nstandards across domains and sectors and complement them by grading the current\ncompliance capabilities of state-of-the-art GenAI models. To support the\ndiscussion, we outline possible challenges and opportunities with integrating\nGenAI for standard compliance tasks while also providing actionable\nrecommendations for entities involved with developing and using standards.\nOverall, we argue that aligning GenAI with standards through computational\nmethods can help strengthen regulatory and operational compliance. We\nanticipate this area of research will play a central role in the management,\noversight, and trustworthiness of larger, more powerful GenAI-based systems in\nthe near future.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04736v1",
    "published_date": "2025-02-03 16:55:01 UTC",
    "updated_date": "2025-02-03 16:55:01 UTC"
  },
  {
    "arxiv_id": "2502.01517v1",
    "title": "Regularized interpolation in 4D neural fields enables optimization of 3D printed geometries",
    "authors": [
      "Christos Margadji",
      "Andi Kuswoyo",
      "Sebastian W. Pattinson"
    ],
    "abstract": "The ability to accurately produce geometries with specified properties is\nperhaps the most important characteristic of a manufacturing process. 3D\nprinting is marked by exceptional design freedom and complexity but is also\nprone to geometric and other defects that must be resolved for it to reach its\nfull potential. Ultimately, this will require both astute design decisions and\ntimely parameter adjustments to maintain stability that is challenging even\nwith expert human operators. While machine learning is widely investigated in\n3D printing, existing methods typically overlook spatial features that vary\nacross prints and thus find it difficult to produce desired geometries. Here,\nwe encode volumetric representations of printed parts into neural fields and\napply a new regularization strategy, based on minimizing the partial derivative\nof the field's output with respect to a single, non-learnable parameter. By\nthus encouraging small input changes to yield only small output variations, we\nencourage smooth interpolation between observed volumes and hence realistic\ngeometry predictions. This framework therefore allows the extraction of\n'imagined' 3D shapes, revealing how a part would look if manufactured under\npreviously unseen parameters. The resulting continuous field is used for\ndata-driven optimization to maximize geometric fidelity between expected and\nproduced geometries, reducing post-processing, material waste, and production\ncosts. By optimizing process parameters dynamically, our approach enables\nadvanced planning strategies, potentially allowing manufacturers to better\nrealize complex and feature-rich designs.",
    "categories": [
      "cs.GR",
      "cs.AI"
    ],
    "primary_category": "cs.GR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01517v1",
    "published_date": "2025-02-03 16:50:57 UTC",
    "updated_date": "2025-02-03 16:50:57 UTC"
  },
  {
    "arxiv_id": "2502.01503v2",
    "title": "Sea-cret Agents: Maritime Abduction for Region Generation to Expose Dark Vessel Trajectories",
    "authors": [
      "Divyagna Bavikadi",
      "Nathaniel Lee",
      "Paulo Shakarian",
      "Chad Parvis"
    ],
    "abstract": "Bad actors in the maritime industry engage in illegal behaviors after\ndisabling their vessel's automatic identification system (AIS) - which makes\nfinding such vessels difficult for analysts. Machine learning approaches only\nsucceed in identifying the locations of these ``dark vessels'' in the immediate\nfuture. This work leverages ideas from the literature on abductive inference\napplied to locating adversarial agents to solve the problem. Specifically, we\ncombine concepts from abduction, logic programming, and rule learning to create\nan efficient method that approaches full recall of dark vessels while requiring\nless search area than machine learning methods. We provide a logic-based\nparadigm for reasoning about maritime vessels, an abductive inference query\nmethod, an automatically extracted rule-based behavior model methodology, and a\nthorough suite of experiments.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.LO",
      "cs.SC"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to 24th International Conference on Autonomous Agents and\n  Multiagent Systems (AAMAS 2025)",
    "pdf_url": "http://arxiv.org/pdf/2502.01503v2",
    "published_date": "2025-02-03 16:36:26 UTC",
    "updated_date": "2025-02-06 23:01:55 UTC"
  },
  {
    "arxiv_id": "2502.01492v1",
    "title": "Develop AI Agents for System Engineering in Factorio",
    "authors": [
      "Neel Kant"
    ],
    "abstract": "Continuing advances in frontier model research are paving the way for\nwidespread deployment of AI agents. Meanwhile, global interest in building\nlarge, complex systems in software, manufacturing, energy and logistics has\nnever been greater. Although AI driven system engineering holds tremendous\npromise, the static benchmarks dominating agent evaluations today fail to\ncapture the crucial skills required for implementing dynamic systems, such as\nmanaging uncertain trade-offs and ensuring proactive adaptability. This\nposition paper advocates for training and evaluating AI agents' system\nengineering abilities through automation-oriented sandbox games-particularly\nFactorio. By directing research efforts in this direction, we can equip AI\nagents with the specialized reasoning and long-horizon planning necessary to\ndesign, maintain, and optimize tomorrow's most demanding engineering projects.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01492v1",
    "published_date": "2025-02-03 16:26:17 UTC",
    "updated_date": "2025-02-03 16:26:17 UTC"
  },
  {
    "arxiv_id": "2502.01490v1",
    "title": "MoireDB: Formula-generated Interference-fringe Image Dataset",
    "authors": [
      "Yuto Matsuo",
      "Ryo Hayamizu",
      "Hirokatsu Kataoka",
      "Akio Nakamura"
    ],
    "abstract": "Image recognition models have struggled to treat recognition robustness to\nreal-world degradations. In this context, data augmentation methods like PixMix\nimprove robustness but rely on generative arts and feature visualizations\n(FVis), which have copyright, drawing cost, and scalability issues. We propose\nMoireDB, a formula-generated interference-fringe image dataset for image\naugmentation enhancing robustness. MoireDB eliminates copyright concerns,\nreduces dataset assembly costs, and enhances robustness by leveraging illusory\npatterns. Experiments show that MoireDB augmented images outperforms\ntraditional Fractal arts and FVis-based augmentations, making it a scalable and\neffective solution for improving model robustness against real-world\ndegradations.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01490v1",
    "published_date": "2025-02-03 16:24:58 UTC",
    "updated_date": "2025-02-03 16:24:58 UTC"
  },
  {
    "arxiv_id": "2502.01715v1",
    "title": "Process-Supervised Reinforcement Learning for Code Generation",
    "authors": [
      "Yufan Ye",
      "Ting Zhang",
      "Wenbin Jiang",
      "Hua Huang"
    ],
    "abstract": "Existing reinforcement learning strategies based on outcome supervision have\nproven effective in enhancing the performance of large language models(LLMs)\nfor code generation. While reinforcement learning based on process supervision\nhas shown great promise in handling multi-step reasoning tasks, its\neffectiveness in code generation remains largely underexplored and\nunderjustified. The primary obstacle stems from the resource-intensive nature\nof constructing high-quality process-supervised data, which demands substantial\nhuman expertise and computational resources. In response to this challenge, we\npropose a \"statement mutation/refactoring-compile and execution verification\"\nstrategy: mutating and refactoring code line-by-line through a teacher model,\nand utilizing compiler execution results to automatically label each line,\nresulting in line-by-line process-supervised data, which is pivotal for\ntraining a process-supervised reward model. The trained reward model is then\nintegrated into the PRLCoder framework, followed by experimental validation on\nseveral benchmarks. Experimental results demonstrate that process-supervised\nreinforcement learning significantly surpasses methods relying solely on\noutcome supervision. Notably, in tackling complex code generation tasks,\nprocess-supervised reinforcement learning shows a clear advantage, ensuring\nboth the integrity of the code generation process and the correctness of the\ngeneration results.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01715v1",
    "published_date": "2025-02-03 16:22:06 UTC",
    "updated_date": "2025-02-03 16:22:06 UTC"
  },
  {
    "arxiv_id": "2502.01477v1",
    "title": "Position: Empowering Time Series Reasoning with Multimodal LLMs",
    "authors": [
      "Yaxuan Kong",
      "Yiyuan Yang",
      "Shiyu Wang",
      "Chenghao Liu",
      "Yuxuan Liang",
      "Ming Jin",
      "Stefan Zohren",
      "Dan Pei",
      "Yan Liu",
      "Qingsong Wen"
    ],
    "abstract": "Understanding time series data is crucial for multiple real-world\napplications. While large language models (LLMs) show promise in time series\ntasks, current approaches often rely on numerical data alone, overlooking the\nmultimodal nature of time-dependent information, such as textual descriptions,\nvisual data, and audio signals. Moreover, these methods underutilize LLMs'\nreasoning capabilities, limiting the analysis to surface-level interpretations\ninstead of deeper temporal and multimodal reasoning. In this position paper, we\nargue that multimodal LLMs (MLLMs) can enable more powerful and flexible\nreasoning for time series analysis, enhancing decision-making and real-world\napplications. We call on researchers and practitioners to leverage this\npotential by developing strategies that prioritize trust, interpretability, and\nrobust reasoning in MLLMs. Lastly, we highlight key research directions,\nincluding novel reasoning paradigms, architectural innovations, and\ndomain-specific applications, to advance time series reasoning with MLLMs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01477v1",
    "published_date": "2025-02-03 16:10:48 UTC",
    "updated_date": "2025-02-03 16:10:48 UTC"
  },
  {
    "arxiv_id": "2502.01472v1",
    "title": "FALCON: Fine-grained Activation Manipulation by Contrastive Orthogonal Unalignment for Large Language Model",
    "authors": [
      "Jinwei Hu",
      "Zhenglin Huang",
      "Xiangyu Yin",
      "Wenjie Ruan",
      "Guangliang Cheng",
      "Yi Dong",
      "Xiaowei Huang"
    ],
    "abstract": "Large language models have been widely applied, but can inadvertently encode\nsensitive or harmful information, raising significant safety concerns. Machine\nunlearning has emerged to alleviate this concern; however, existing\ntraining-time unlearning approaches, relying on coarse-grained loss\ncombinations, have limitations in precisely separating knowledge and balancing\nremoval effectiveness with model utility. In contrast, we propose Fine-grained\nActivation manipuLation by Contrastive Orthogonal uNalignment (FALCON), a novel\nrepresentation-guided unlearning approach that leverages information-theoretic\nguidance for efficient parameter selection, employs contrastive mechanisms to\nenhance representation separation, and projects conflict gradients onto\northogonal subspaces to resolve conflicts between forgetting and retention\nobjectives. Extensive experiments demonstrate that FALCON achieves superior\nunlearning effectiveness while maintaining model utility, exhibiting robust\nresistance against knowledge recovery attempts.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Under Review",
    "pdf_url": "http://arxiv.org/pdf/2502.01472v1",
    "published_date": "2025-02-03 16:05:15 UTC",
    "updated_date": "2025-02-03 16:05:15 UTC"
  },
  {
    "arxiv_id": "2502.01714v1",
    "title": "Position: Towards a Responsible LLM-empowered Multi-Agent Systems",
    "authors": [
      "Jinwei Hu",
      "Yi Dong",
      "Shuang Ao",
      "Zhuoyun Li",
      "Boxuan Wang",
      "Lokesh Singh",
      "Guangliang Cheng",
      "Sarvapali D. Ramchurn",
      "Xiaowei Huang"
    ],
    "abstract": "The rise of Agent AI and Large Language Model-powered Multi-Agent Systems\n(LLM-MAS) has underscored the need for responsible and dependable system\noperation. Tools like LangChain and Retrieval-Augmented Generation have\nexpanded LLM capabilities, enabling deeper integration into MAS through\nenhanced knowledge retrieval and reasoning. However, these advancements\nintroduce critical challenges: LLM agents exhibit inherent unpredictability,\nand uncertainties in their outputs can compound across interactions,\nthreatening system stability. To address these risks, a human-centered design\napproach with active dynamic moderation is essential. Such an approach enhances\ntraditional passive oversight by facilitating coherent inter-agent\ncommunication and effective system governance, allowing MAS to achieve desired\noutcomes more efficiently.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "Under Review",
    "pdf_url": "http://arxiv.org/pdf/2502.01714v1",
    "published_date": "2025-02-03 16:04:30 UTC",
    "updated_date": "2025-02-03 16:04:30 UTC"
  },
  {
    "arxiv_id": "2502.01456v1",
    "title": "Process Reinforcement through Implicit Rewards",
    "authors": [
      "Ganqu Cui",
      "Lifan Yuan",
      "Zefan Wang",
      "Hanbin Wang",
      "Wendi Li",
      "Bingxiang He",
      "Yuchen Fan",
      "Tianyu Yu",
      "Qixin Xu",
      "Weize Chen",
      "Jiarui Yuan",
      "Huayu Chen",
      "Kaiyan Zhang",
      "Xingtai Lv",
      "Shuo Wang",
      "Yuan Yao",
      "Xu Han",
      "Hao Peng",
      "Yu Cheng",
      "Zhiyuan Liu",
      "Maosong Sun",
      "Bowen Zhou",
      "Ning Ding"
    ],
    "abstract": "Dense process rewards have proven a more effective alternative to the sparse\noutcome-level rewards in the inference-time scaling of large language models\n(LLMs), particularly in tasks requiring complex multi-step reasoning. While\ndense rewards also offer an appealing choice for the reinforcement learning\n(RL) of LLMs since their fine-grained rewards have the potential to address\nsome inherent issues of outcome rewards, such as training efficiency and credit\nassignment, this potential remains largely unrealized. This can be primarily\nattributed to the challenges of training process reward models (PRMs) online,\nwhere collecting high-quality process labels is prohibitively expensive, making\nthem particularly vulnerable to reward hacking. To address these challenges, we\npropose PRIME (Process Reinforcement through IMplicit rEwards), which enables\nonline PRM updates using only policy rollouts and outcome labels through\nimplict process rewards. PRIME combines well with various advantage functions\nand forgoes the dedicated reward model training phrase that existing approaches\nrequire, substantially reducing the development overhead. We demonstrate\nPRIME's effectiveness on competitional math and coding. Starting from\nQwen2.5-Math-7B-Base, PRIME achieves a 15.1% average improvement across several\nkey reasoning benchmarks over the SFT model. Notably, our resulting model,\nEurus-2-7B-PRIME, surpasses Qwen2.5-Math-7B-Instruct on seven reasoning\nbenchmarks with 10% of its training data.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "20 pages. Model&Code&Data available at\n  https://github.com/PRIME-RL/PRIME",
    "pdf_url": "http://arxiv.org/pdf/2502.01456v1",
    "published_date": "2025-02-03 15:43:48 UTC",
    "updated_date": "2025-02-03 15:43:48 UTC"
  },
  {
    "arxiv_id": "2502.01455v1",
    "title": "Temporal-consistent CAMs for Weakly Supervised Video Segmentation in Waste Sorting",
    "authors": [
      "Andrea Marelli",
      "Luca Magri",
      "Federica Arrigoni",
      "Giacomo Boracchi"
    ],
    "abstract": "In industrial settings, weakly supervised (WS) methods are usually preferred\nover their fully supervised (FS) counterparts as they do not require costly\nmanual annotations. Unfortunately, the segmentation masks obtained in the WS\nregime are typically poor in terms of accuracy. In this work, we present a WS\nmethod capable of producing accurate masks for semantic segmentation in the\ncase of video streams. More specifically, we build saliency maps that exploit\nthe temporal coherence between consecutive frames in a video, promoting\nconsistency when objects appear in different frames. We apply our method in a\nwaste-sorting scenario, where we perform weakly supervised video segmentation\n(WSVS) by training an auxiliary classifier that distinguishes between videos\nrecorded before and after a human operator, who manually removes specific\nwastes from a conveyor belt. The saliency maps of this classifier identify\nmaterials to be removed, and we modify the classifier training to minimize\ndifferences between the saliency map of a central frame and those in adjacent\nframes, after having compensated object displacement. Experiments on a\nreal-world dataset demonstrate the benefits of integrating temporal coherence\ndirectly during the training phase of the classifier. Code and dataset are\navailable upon request.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "14 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.01455v1",
    "published_date": "2025-02-03 15:43:33 UTC",
    "updated_date": "2025-02-03 15:43:33 UTC"
  },
  {
    "arxiv_id": "2502.01450v1",
    "title": "Simulating Rumor Spreading in Social Networks using LLM Agents",
    "authors": [
      "Tianrui Hu",
      "Dimitrios Liakopoulos",
      "Xiwen Wei",
      "Radu Marculescu",
      "Neeraja J. Yadwadkar"
    ],
    "abstract": "With the rise of social media, misinformation has become increasingly\nprevalent, fueled largely by the spread of rumors. This study explores the use\nof Large Language Model (LLM) agents within a novel framework to simulate and\nanalyze the dynamics of rumor propagation across social networks. To this end,\nwe design a variety of LLM-based agent types and construct four distinct\nnetwork structures to conduct these simulations. Our framework assesses the\neffectiveness of different network constructions and agent behaviors in\ninfluencing the spread of rumors. Our results demonstrate that the framework\ncan simulate rumor spreading across more than one hundred agents in various\nnetworks with thousands of edges. The evaluations indicate that network\nstructure, personas, and spreading schemes can significantly influence rumor\ndissemination, ranging from no spread to affecting 83\\% of agents in\niterations, thereby offering a realistic simulation of rumor spread in social\nnetworks.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI",
    "comment": "7 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.01450v1",
    "published_date": "2025-02-03 15:39:56 UTC",
    "updated_date": "2025-02-03 15:39:56 UTC"
  },
  {
    "arxiv_id": "2502.01445v2",
    "title": "SPFFNet: Strip Perception and Feature Fusion Spatial Pyramid Pooling for Fabric Defect Detection",
    "authors": [
      "Peizhe Zhao"
    ],
    "abstract": "Defect detection in fabrics is critical for quality control, yet existing\nmethods often struggle with complex backgrounds and shape-specific defects. In\nthis paper, we propose an improved fabric defect detection model based on\nYOLOv11. To enhance the detection of strip defects, we introduce a Strip\nPerception Module (SPM) that improves feature capture through multi-scale\nconvolution. We further enhance the spatial pyramid pooling fast (SPPF) by\nintegrating a squeeze-and-excitation mechanism, resulting in the SE-SPPF\nmodule, which better integrates spatial and channel information for more\neffective defect feature extraction. Additionally, we propose a novel focal\nenhanced complete intersection over union (FECIoU) metric with adaptive\nweights, addressing scale differences and class imbalance by adjusting the\nweights of hard-to-detect instances through focal loss. Experimental results\ndemonstrate that our model achieves a 0.8-8.1% improvement in mean average\nprecision (mAP) on the Tianchi dataset and a 1.6-13.2% improvement on our\ncustom dataset, outperforming other state-of-the-art methods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, 4 figures, conference",
    "pdf_url": "http://arxiv.org/pdf/2502.01445v2",
    "published_date": "2025-02-03 15:33:11 UTC",
    "updated_date": "2025-02-04 03:25:51 UTC"
  },
  {
    "arxiv_id": "2502.01436v2",
    "title": "Towards Safer Chatbots: A Framework for Policy Compliance Evaluation of Custom GPTs",
    "authors": [
      "David Rodriguez",
      "William Seymour",
      "Jose M. Del Alamo",
      "Jose Such"
    ],
    "abstract": "Large Language Models (LLMs) have gained unprecedented prominence, achieving\nwidespread adoption across diverse domains and integrating deeply into society.\nThe capability to fine-tune general-purpose LLMs, such as Generative\nPre-trained Transformers (GPT), for specific tasks has facilitated the\nemergence of numerous Custom GPTs. These tailored models are increasingly made\navailable through dedicated marketplaces, such as OpenAI's GPT Store. However,\ntheir black-box nature introduces significant safety and compliance risks. In\nthis work, we present a scalable framework for the automated evaluation of\nCustom GPTs against OpenAI's usage policies, which define the permissible\nbehaviors of these systems. Our framework integrates three core components: (1)\nautomated discovery and data collection of models from the GPT store, (2) a\nred-teaming prompt generator tailored to specific policy categories and the\ncharacteristics of each target GPT, and (3) an LLM-as-a-judge technique to\nanalyze each prompt-response pair for potential policy violations. We validate\nour framework with a manually annotated ground truth, and evaluate it through a\nlarge-scale study with 782 Custom GPTs across three categories: Romantic,\nCybersecurity, and Academic GPTs. Our manual annotation process achieved an F1\nscore of 0.975 in identifying policy violations, confirming the reliability of\nthe framework's assessments. The results reveal that 58.7% of the analyzed\nmodels exhibit indications of non-compliance, exposing weaknesses in the GPT\nstore's review and approval processes. Furthermore, our findings indicate that\na model's popularity does not correlate with compliance, and non-compliance\nissues largely stem from behaviors inherited from base models rather than\nuser-driven customizations. We believe this approach is extendable to other\nchatbot platforms and policy domains, improving LLM-based systems safety.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.1; I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01436v2",
    "published_date": "2025-02-03 15:19:28 UTC",
    "updated_date": "2025-04-14 16:58:48 UTC"
  },
  {
    "arxiv_id": "2502.01427v1",
    "title": "Structural features of the fly olfactory circuit mitigate the stability-plasticity dilemma in continual learning",
    "authors": [
      "Heming Zou",
      "Yunliang Zang",
      "Xiangyang Ji"
    ],
    "abstract": "Artificial neural networks face the stability-plasticity dilemma in continual\nlearning, while the brain can maintain memories and remain adaptable. However,\nthe biological strategies for continual learning and their potential to inspire\nlearning algorithms in neural networks are poorly understood. This study\npresents a minimal model of the fly olfactory circuit to investigate the\nbiological strategies that support continual odor learning. We introduce the\nfly olfactory circuit as a plug-and-play component, termed the Fly Model, which\ncan integrate with modern machine learning methods to address this dilemma. Our\nfindings demonstrate that the Fly Model enhances both memory stability and\nlearning plasticity, overcoming the limitations of current continual learning\nstrategies. We validated its effectiveness across various challenging continual\nlearning scenarios using commonly used datasets. The fly olfactory system\nserves as an elegant biological circuit for lifelong learning, offering a\nmodule that enhances continual learning with minimal additional computational\ncost for machine learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "q-bio.NC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01427v1",
    "published_date": "2025-02-03 15:06:11 UTC",
    "updated_date": "2025-02-03 15:06:11 UTC"
  },
  {
    "arxiv_id": "2502.01419v1",
    "title": "Visual Attention Never Fades: Selective Progressive Attention ReCalibration for Detailed Image Captioning in Multimodal Large Language Models",
    "authors": [
      "Mingi Jung",
      "Saehuyng Lee",
      "Eunji Kim",
      "Sungroh Yoon"
    ],
    "abstract": "Detailed image captioning is essential for tasks like data generation and\naiding visually impaired individuals. High-quality captions require a balance\nbetween precision and recall, which remains challenging for current multimodal\nlarge language models (MLLMs). In this work, we hypothesize that this\nlimitation stems from weakening and increasingly noisy visual attention as\nresponses lengthen. To address this issue, we propose SPARC (Selective\nProgressive Attention ReCalibration), a training-free method that enhances the\ncontribution of visual tokens during decoding. SPARC is founded on three key\nobservations: (1) increasing the influence of all visual tokens reduces recall;\nthus, SPARC selectively amplifies visual tokens; (2) as captions lengthen,\nvisual attention becomes noisier, so SPARC identifies critical visual tokens by\nleveraging attention differences across time steps; (3) as visual attention\ngradually weakens, SPARC reinforces it to preserve its influence. Our\nexperiments, incorporating both automated and human evaluations, demonstrate\nthat existing methods improve the precision of MLLMs at the cost of recall. In\ncontrast, our proposed method enhances both precision and recall with minimal\ncomputational overhead.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01419v1",
    "published_date": "2025-02-03 14:58:11 UTC",
    "updated_date": "2025-02-03 14:58:11 UTC"
  },
  {
    "arxiv_id": "2502.01708v1",
    "title": "Aspects of Artificial Intelligence: Transforming Machine Learning Systems Naturally",
    "authors": [
      "Xiuzhan Guo"
    ],
    "abstract": "In this paper, we study the machine learning elements which we are interested\nin together as a machine learning system, consisting of a collection of machine\nlearning elements and a collection of relations between the elements. The\nrelations we concern are algebraic operations, binary relations, and binary\nrelations with composition that can be reasoned categorically. A machine\nlearning system transformation between two systems is a map between the\nsystems, which preserves the relations we concern. The system transformations\ngiven by quotient or clustering, representable functor, and Yoneda embedding\nare highlighted and discussed by machine learning examples. An adjunction\nbetween machine learning systems, a special machine learning system\ntransformation loop, provides the optimal way of solving problems. Machine\nlearning system transformations are linked and compared by their maps at\n2-cell, natural transformations. New insights and structures can be obtained\nfrom universal properties and algebraic structures given by monads, which are\ngenerated from adjunctions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DB",
      "cs.DM"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01708v1",
    "published_date": "2025-02-03 14:45:02 UTC",
    "updated_date": "2025-02-03 14:45:02 UTC"
  },
  {
    "arxiv_id": "2502.01406v1",
    "title": "GRADIEND: Monosemantic Feature Learning within Neural Networks Applied to Gender Debiasing of Transformer Models",
    "authors": [
      "Jonathan Drechsel",
      "Steffen Herbold"
    ],
    "abstract": "AI systems frequently exhibit and amplify social biases, including gender\nbias, leading to harmful consequences in critical areas. This study introduces\na novel encoder-decoder approach that leverages model gradients to learn a\nsingle monosemantic feature neuron encoding gender information. We show that\nour method can be used to debias transformer-based language models, while\nmaintaining other capabilities. We demonstrate the effectiveness of our\napproach across multiple encoder-only based models and highlight its potential\nfor broader applications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01406v1",
    "published_date": "2025-02-03 14:38:27 UTC",
    "updated_date": "2025-02-03 14:38:27 UTC"
  },
  {
    "arxiv_id": "2502.01403v3",
    "title": "AdaSVD: Adaptive Singular Value Decomposition for Large Language Models",
    "authors": [
      "Zhiteng Li",
      "Mingyuan Xia",
      "Jingyuan Zhang",
      "Zheng Hui",
      "Linghe Kong",
      "Yulun Zhang",
      "Xiaokang Yang"
    ],
    "abstract": "Large language models (LLMs) have achieved remarkable success in natural\nlanguage processing (NLP) tasks, yet their substantial memory requirements\npresent significant challenges for deployment on resource-constrained devices.\nSingular Value Decomposition (SVD) has emerged as a promising compression\ntechnique for LLMs, offering considerable reductions in memory overhead.\nHowever, existing SVD-based methods often struggle to effectively mitigate the\nerrors introduced by SVD truncation, leading to a noticeable performance gap\nwhen compared to the original models. Furthermore, applying a uniform\ncompression ratio across all transformer layers fails to account for the\nvarying importance of different layers. To address these challenges, we propose\nAdaSVD, an adaptive SVD-based LLM compression approach. Specifically, AdaSVD\nintroduces adaComp, which adaptively compensates for SVD truncation errors by\nalternately updating the singular matrices $\\mathcal{U}$ and\n$\\mathcal{V}^\\top$. Additionally, AdaSVD introduces adaCR, which adaptively\nassigns layer-specific compression ratios based on the relative importance of\neach layer. Extensive experiments across multiple LLM/VLM families and\nevaluation metrics demonstrate that AdaSVD consistently outperforms\nstate-of-the-art (SOTA) SVD-based methods, achieving superior performance with\nsignificantly reduced memory requirements. Code and models of AdaSVD will be\navailable at https://github.com/ZHITENGLI/AdaSVD.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "The code and models will be available at\n  https://github.com/ZHITENGLI/AdaSVD",
    "pdf_url": "http://arxiv.org/pdf/2502.01403v3",
    "published_date": "2025-02-03 14:34:37 UTC",
    "updated_date": "2025-03-09 09:04:18 UTC"
  },
  {
    "arxiv_id": "2502.01397v1",
    "title": "Can message-passing GNN approximate triangular factorizations of sparse matrices?",
    "authors": [
      "Vladislav Trifonov",
      "Ekaterina Muravleva",
      "Ivan Oseledets"
    ],
    "abstract": "We study fundamental limitations of Graph Neural Networks (GNNs) for learning\nsparse matrix preconditioners. While recent works have shown promising results\nusing GNNs to predict incomplete factorizations, we demonstrate that the local\nnature of message passing creates inherent barriers for capturing non-local\ndependencies required for optimal preconditioning. We introduce a new benchmark\ndataset of matrices where good sparse preconditioners exist but require\nnon-local computations, constructed using both synthetic examples and\nreal-world matrices. Our experimental results show that current GNN\narchitectures struggle to approximate these preconditioners, suggesting the\nneed for new architectural approaches beyond traditional message passing\nnetworks. We provide theoretical analysis and empirical evidence to explain\nthese limitations, with implications for the broader use of GNNs in numerical\nlinear algebra.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "math.NA"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01397v1",
    "published_date": "2025-02-03 14:28:20 UTC",
    "updated_date": "2025-02-03 14:28:20 UTC"
  },
  {
    "arxiv_id": "2502.01391v2",
    "title": "Learning Traffic Anomalies from Generative Models on Real-Time Observations",
    "authors": [
      "Fotis I. Giasemis",
      "Alexandros Sopasakis"
    ],
    "abstract": "Accurate detection of traffic anomalies is crucial for effective urban\ntraffic management and congestion mitigation. We use the Spatiotemporal\nGenerative Adversarial Network (STGAN) framework combining Graph Neural\nNetworks and Long Short-Term Memory networks to capture complex spatial and\ntemporal dependencies in traffic data. We apply STGAN to real-time,\nminute-by-minute observations from 42 traffic cameras across Gothenburg,\nSweden, collected over several months in 2020. The images are processed to\ncompute a flow metric representing vehicle density, which serves as input for\nthe model. Training is conducted on data from April to November 2020, and\nvalidation is performed on a separate dataset from November 14 to 23, 2020. Our\nresults demonstrate that the model effectively detects traffic anomalies with\nhigh precision and low false positive rates. The detected anomalies include\ncamera signal interruptions, visual artifacts, and extreme weather conditions\naffecting traffic flow.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01391v2",
    "published_date": "2025-02-03 14:23:23 UTC",
    "updated_date": "2025-05-14 09:00:33 UTC"
  },
  {
    "arxiv_id": "2502.01387v3",
    "title": "TeLL-Drive: Enhancing Autonomous Driving with Teacher LLM-Guided Deep Reinforcement Learning",
    "authors": [
      "Chengkai Xu",
      "Jiaqi Liu",
      "Shiyu Fang",
      "Yiming Cui",
      "Dong Chen",
      "Peng Hang",
      "Jian Sun"
    ],
    "abstract": "Although Deep Reinforcement Learning (DRL) and Large Language Models (LLMs)\neach show promise in addressing decision-making challenges in autonomous\ndriving, DRL often suffers from high sample complexity, while LLMs have\ndifficulty ensuring real-time decision making. To address these limitations, we\npropose TeLL-Drive, a hybrid framework that integrates a Teacher LLM to guide\nan attention-based Student DRL policy. By incorporating risk metrics,\nhistorical scenario retrieval, and domain heuristics into context-rich prompts,\nthe LLM produces high-level driving strategies through chain-of-thought\nreasoning. A self-attention mechanism then fuses these strategies with the DRL\nagent's exploration, accelerating policy convergence and boosting robustness\nacross diverse driving conditions. The experimental results, evaluated across\nmultiple traffic scenarios, show that TeLL-Drive outperforms existing baseline\nmethods, including other LLM-based approaches, in terms of success rates,\naverage returns, and real-time feasibility. Ablation studies underscore the\nimportance of each model component, especially the synergy between the\nattention mechanism and LLM-driven guidance. Finally, we build a virtual-real\nfusion experimental platform to verify the real-time performance, robustness,\nand reliability of the algorithm running on real vehicles through\nvehicle-in-loop experiments.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01387v3",
    "published_date": "2025-02-03 14:22:03 UTC",
    "updated_date": "2025-02-20 14:09:01 UTC"
  },
  {
    "arxiv_id": "2502.01384v2",
    "title": "Fine-Tuning Discrete Diffusion Models with Policy Gradient Methods",
    "authors": [
      "Oussama Zekri",
      "Nicolas Boullé"
    ],
    "abstract": "Discrete diffusion models have recently gained significant attention due to\ntheir ability to process complex discrete structures for language modeling.\nHowever, fine-tuning these models with policy gradient methods, as is commonly\ndone in Reinforcement Learning from Human Feedback (RLHF), remains a\nchallenging task. We propose an efficient, broadly applicable, and\ntheoretically justified policy gradient algorithm, called Score Entropy Policy\nOptimization (SEPO), for fine-tuning discrete diffusion models over\nnon-differentiable rewards. Our numerical experiments across several discrete\ngenerative tasks demonstrate the scalability and efficiency of our method. Our\ncode is available at https://github.com/ozekri/SEPO.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "30 pages, 8 figures, 8 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.01384v2",
    "published_date": "2025-02-03 14:20:19 UTC",
    "updated_date": "2025-05-16 05:22:08 UTC"
  },
  {
    "arxiv_id": "2502.01377v1",
    "title": "Data-Efficient Model for Psychological Resilience Prediction based on Neurological Data",
    "authors": [
      "Zhi Zhang",
      "Yan Liu",
      "Mengxia Gao",
      "Yu Yang",
      "Jiannong Cao",
      "Wai Kai Hou",
      "Shirley Li",
      "Sonata Yau",
      "Yun Kwok Wing",
      "Tatia M. C. Lee"
    ],
    "abstract": "Psychological resilience, defined as the ability to rebound from adversity,\nis crucial for mental health. Compared with traditional resilience assessments\nthrough self-reported questionnaires, resilience assessments based on\nneurological data offer more objective results with biological markers, hence\nsignificantly enhancing credibility. This paper proposes a novel data-efficient\nmodel to address the scarcity of neurological data. We employ Neuro\nKolmogorov-Arnold Networks as the structure of the prediction model. In the\ntraining stage, a new trait-informed multimodal representation algorithm with a\nsmart chunk technique is proposed to learn the shared latent space with limited\ndata. In the test stage, a new noise-informed inference algorithm is proposed\nto address the low signal-to-noise ratio of the neurological data. The proposed\nmodel not only shows impressive performance on both public datasets and\nself-constructed datasets but also provides some valuable psychological\nhypotheses for future research.",
    "categories": [
      "cs.CE",
      "cs.AI"
    ],
    "primary_category": "cs.CE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01377v1",
    "published_date": "2025-02-03 14:15:15 UTC",
    "updated_date": "2025-02-03 14:15:15 UTC"
  },
  {
    "arxiv_id": "2502.01375v1",
    "title": "Compact Rule-Based Classifier Learning via Gradient Descent",
    "authors": [
      "Javier Fumanal-Idocin",
      "Raquel Fernandez-Peralta",
      "Javier Andreu-Perez"
    ],
    "abstract": "Rule-based models play a crucial role in scenarios that require transparency\nand accountable decision-making. However, they primarily consist of discrete\nparameters and structures, which presents challenges for scalability and\noptimization. In this work, we introduce a new rule-based classifier trained\nusing gradient descent, in which the user can control the maximum number and\nlength of the rules. For numerical partitions, the user can also control the\npartitions used with fuzzy sets, which also helps keep the number of partitions\nsmall. We perform a series of exhaustive experiments on $40$ datasets to show\nhow this classifier performs in terms of accuracy and rule base size. Then, we\ncompare our results with a genetic search that fits an equivalent classifier\nand with other explainable and non-explainable state-of-the-art classifiers.\nOur results show how our method can obtain compact rule bases that use\nsignificantly fewer patterns than other rule-based methods and perform better\nthan other explainable classifiers.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01375v1",
    "published_date": "2025-02-03 14:13:39 UTC",
    "updated_date": "2025-02-03 14:13:39 UTC"
  },
  {
    "arxiv_id": "2502.01707v1",
    "title": "CLIP-DQA: Blindly Evaluating Dehazed Images from Global and Local Perspectives Using CLIP",
    "authors": [
      "Yirui Zeng",
      "Jun Fu",
      "Hadi Amirpour",
      "Huasheng Wang",
      "Guanghui Yue",
      "Hantao Liu",
      "Ying Chen",
      "Wei Zhou"
    ],
    "abstract": "Blind dehazed image quality assessment (BDQA), which aims to accurately\npredict the visual quality of dehazed images without any reference information,\nis essential for the evaluation, comparison, and optimization of image dehazing\nalgorithms. Existing learning-based BDQA methods have achieved remarkable\nsuccess, while the small scale of DQA datasets limits their performance. To\naddress this issue, in this paper, we propose to adapt Contrastive\nLanguage-Image Pre-Training (CLIP), pre-trained on large-scale image-text\npairs, to the BDQA task. Specifically, inspired by the fact that the human\nvisual system understands images based on hierarchical features, we take global\nand local information of the dehazed image as the input of CLIP. To accurately\nmap the input hierarchical information of dehazed images into the quality\nscore, we tune both the vision branch and language branch of CLIP with prompt\nlearning. Experimental results on two authentic DQA datasets demonstrate that\nour proposed approach, named CLIP-DQA, achieves more accurate quality\npredictions over existing BDQA methods. The code is available at\nhttps://github.com/JunFu1995/CLIP-DQA.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ISCAS 2025 (Oral)",
    "pdf_url": "http://arxiv.org/pdf/2502.01707v1",
    "published_date": "2025-02-03 14:12:25 UTC",
    "updated_date": "2025-02-03 14:12:25 UTC"
  },
  {
    "arxiv_id": "2502.01364v1",
    "title": "Meursault as a Data Point",
    "authors": [
      "Abhinav Pratap",
      "Amit Pathak"
    ],
    "abstract": "In an era dominated by datafication, the reduction of human experiences to\nquantifiable metrics raises profound philosophical and ethical questions. This\npaper explores these issues through the lens of Meursault, the protagonist of\nAlbert Camus' The Stranger, whose emotionally detached existence epitomizes the\nexistential concept of absurdity. Using natural language processing (NLP)\ntechniques including emotion detection (BERT), sentiment analysis (VADER), and\nnamed entity recognition (spaCy)-this study quantifies key events and behaviors\nin Meursault's life. Our analysis reveals the inherent limitations of applying\nalgorithmic models to complex human experiences, particularly those rooted in\nexistential alienation and moral ambiguity. By examining how modern AI tools\nmisinterpret Meursault's actions and emotions, this research underscores the\nbroader ethical dilemmas of reducing nuanced human narratives to data points,\nchallenging the foundational assumptions of our data-driven society. The\nfindings presented in this paper serve as a critique of the increasing reliance\non data-driven narratives and advocate for incorporating humanistic values in\nartificial intelligence.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.DL",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "7 pages, 9 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.01364v1",
    "published_date": "2025-02-03 13:56:48 UTC",
    "updated_date": "2025-02-03 13:56:48 UTC"
  },
  {
    "arxiv_id": "2502.01344v1",
    "title": "PSSD: Making Large Language Models Self-denial via Human Psyche Structure",
    "authors": [
      "Jinzhi Liao",
      "Zenghua Liao",
      "Xiang Zhao"
    ],
    "abstract": "The enhance of accuracy in reasoning results of LLMs arouses the community's\ninterests, wherein pioneering studies investigate post-hoc strategies to\nrectify potential mistakes. Despite extensive efforts, they are all stuck in a\nstate of resource competition demanding significant time and computing\nexpenses. The cause of the situation lies in the failure of identifying the\nfundamental feature of the solutions in this line, coined as the self-denial of\nLLMs. In other words, LLMs should confidently determine the potential existence\nof mistakes and carefully execute the targeted correction. As the whole\nprocedure conducts within LLMs, supporting and persuasive references are hard\nto acquire, while the absence of specific steps towards refining hidden\nmistakes persists even when errors are acknowledged. In response to the\nchallenges, we present PSSD, which refers to and implements the human psyche\nstructure such that three distinct and interconnected roles contribute to human\nreasoning. Specifically, PSSD leverages the recent multi-agent paradigm, and is\nfurther enhanced with three innovatively conceived roles: (1) the\nintuition-based id role that provides initial attempts based on benign LLMs;\n(2) the rule-driven superego role that summarizes rules to regulate the above\nattempts, and returns specific key points as guidance; and (3) the\nscript-centric ego role that absorbs all procedural information to generate\nexecutable script for the final answer prediction. Extensive experiments\ndemonstrate that the proposed design not only better enhance reasoning\ncapabilities, but also seamlessly integrate with current models, leading to\nsuperior performance.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "comment": "WWW '25",
    "pdf_url": "http://arxiv.org/pdf/2502.01344v1",
    "published_date": "2025-02-03 13:37:21 UTC",
    "updated_date": "2025-02-03 13:37:21 UTC"
  },
  {
    "arxiv_id": "2502.01342v1",
    "title": "Activation by Interval-wise Dropout: A Simple Way to Prevent Neural Networks from Plasticity Loss",
    "authors": [
      "Sangyeon Park",
      "Isaac Han",
      "Seungwon Oh",
      "Kyung-Joong Kim"
    ],
    "abstract": "Plasticity loss, a critical challenge in neural network training, limits a\nmodel's ability to adapt to new tasks or shifts in data distribution. This\npaper introduces AID (Activation by Interval-wise Dropout), a novel method\ninspired by Dropout, designed to address plasticity loss. Unlike Dropout, AID\ngenerates subnetworks by applying Dropout with different probabilities on each\npreactivation interval. Theoretical analysis reveals that AID regularizes the\nnetwork, promoting behavior analogous to that of deep linear networks, which do\nnot suffer from plasticity loss. We validate the effectiveness of AID in\nmaintaining plasticity across various benchmarks, including continual learning\ntasks on standard image classification datasets such as CIFAR10, CIFAR100, and\nTinyImageNet. Furthermore, we show that AID enhances reinforcement learning\nperformance in the Arcade Learning Environment benchmark.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01342v1",
    "published_date": "2025-02-03 13:34:53 UTC",
    "updated_date": "2025-02-03 13:34:53 UTC"
  },
  {
    "arxiv_id": "2502.01706v2",
    "title": "Comply: Learning Sentences with Complex Weights inspired by Fruit Fly Olfaction",
    "authors": [
      "Alexei Figueroa",
      "Justus Westerhoff",
      "Golzar Atefi",
      "Dennis Fast",
      "Benjamin Winter",
      "Felix Alexader Gers",
      "Alexander Löser",
      "Wolfang Nejdl"
    ],
    "abstract": "Biologically inspired neural networks offer alternative avenues to model data\ndistributions. FlyVec is a recent example that draws inspiration from the fruit\nfly's olfactory circuit to tackle the task of learning word embeddings.\nSurprisingly, this model performs competitively even against deep learning\napproaches specifically designed to encode text, and it does so with the\nhighest degree of computational efficiency. We pose the question of whether\nthis performance can be improved further. For this, we introduce Comply. By\nincorporating positional information through complex weights, we enable a\nsingle-layer neural network to learn sequence representations. Our experiments\nshow that Comply not only supersedes FlyVec but also performs on par with\nsignificantly larger state-of-the-art models. We achieve this without\nadditional parameters. Comply yields sparse contextual representations of\nsentences that can be interpreted explicitly from the neuron weights.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at NICE2025",
    "pdf_url": "http://arxiv.org/pdf/2502.01706v2",
    "published_date": "2025-02-03 13:30:44 UTC",
    "updated_date": "2025-02-05 14:17:37 UTC"
  },
  {
    "arxiv_id": "2502.01316v2",
    "title": "Learning Fused State Representations for Control from Multi-View Observations",
    "authors": [
      "Zeyu Wang",
      "Yao-Hui Li",
      "Xin Li",
      "Hongyu Zang",
      "Romain Laroche",
      "Riashat Islam"
    ],
    "abstract": "Multi-View Reinforcement Learning (MVRL) seeks to provide agents with\nmulti-view observations, enabling them to perceive environment with greater\neffectiveness and precision. Recent advancements in MVRL focus on extracting\nlatent representations from multiview observations and leveraging them in\ncontrol tasks. However, it is not straightforward to learn compact and\ntask-relevant representations, particularly in the presence of redundancy,\ndistracting information, or missing views. In this paper, we propose Multi-view\nFusion State for Control (MFSC), firstly incorporating bisimulation metric\nlearning into MVRL to learn task-relevant representations. Furthermore, we\npropose a multiview-based mask and latent reconstruction auxiliary task that\nexploits shared information across views and improves MFSC's robustness in\nmissing views by introducing a mask token. Extensive experimental results\ndemonstrate that our method outperforms existing approaches in MVRL tasks. Even\nin more realistic scenarios with interference or missing views, MFSC\nconsistently maintains high performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01316v2",
    "published_date": "2025-02-03 12:46:02 UTC",
    "updated_date": "2025-05-21 12:42:25 UTC"
  },
  {
    "arxiv_id": "2502.01311v1",
    "title": "TFBS-Finder: Deep Learning-based Model with DNABERT and Convolutional Networks to Predict Transcription Factor Binding Sites",
    "authors": [
      "Nimisha Ghosh",
      "Pratik Dutta",
      "Daniele Santoni"
    ],
    "abstract": "Transcription factors are proteins that regulate the expression of genes by\nbinding to specific genomic regions known as Transcription Factor Binding Sites\n(TFBSs), typically located in the promoter regions of those genes. Accurate\nprediction of these binding sites is essential for understanding the complex\ngene regulatory networks underlying various cellular functions. In this regard,\nmany deep learning models have been developed for such prediction, but there is\nstill scope of improvement. In this work, we have developed a deep learning\nmodel which uses pre-trained DNABERT, a Convolutional Neural Network (CNN)\nmodule, a Modified Convolutional Block Attention Module (MCBAM), a Multi-Scale\nConvolutions with Attention (MSCA) module and an output module. The pre-trained\nDNABERT is used for sequence embedding, thereby capturing the long-term\ndependencies in the DNA sequences while the CNN, MCBAM and MSCA modules are\nuseful in extracting higher-order local features. TFBS-Finder is trained and\ntested on 165 ENCODE ChIP-seq datasets. We have also performed ablation studies\nas well as cross-cell line validations and comparisons with other models. The\nexperimental results show the superiority of the proposed method in predicting\nTFBSs compared to the existing methodologies. The codes and the relevant\ndatasets are publicly available at\nhttps://github.com/NimishaGhosh/TFBS-Finder/.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.GN"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01311v1",
    "published_date": "2025-02-03 12:41:11 UTC",
    "updated_date": "2025-02-03 12:41:11 UTC"
  },
  {
    "arxiv_id": "2502.01310v1",
    "title": "A Statistical Learning Perspective on Semi-dual Adversarial Neural Optimal Transport Solvers",
    "authors": [
      "Roman Tarasov",
      "Petr Mokrov",
      "Milena Gazdieva",
      "Evgeny Burnaev",
      "Alexander Korotin"
    ],
    "abstract": "Neural network based Optimal Transport (OT) is a recent and fruitful\ndirection in the generative modeling community. It finds its applications in\nvarious fields such as domain translation, image super-resolution,\ncomputational biology and others. Among the existing approaches to OT, of\nconsiderable interest are adversarial minimax solvers based on semi-dual\nformulations of OT problems. While promising, these methods lack theoretical\ninvestigation from a statistical learning perspective. Our work fills this gap\nby establishing upper bounds on the generalization error of an approximate OT\nmap recovered by the minimax quadratic OT solver. Importantly, the bounds we\nderive depend solely on some standard statistical and mathematical properties\nof the considered functional classes (neural networks). While our analysis\nfocuses on the quadratic OT, we believe that similar bounds could be derived\nfor more general OT formulations, paving the promising direction for future\nresearch.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01310v1",
    "published_date": "2025-02-03 12:37:20 UTC",
    "updated_date": "2025-02-03 12:37:20 UTC"
  },
  {
    "arxiv_id": "2502.01303v1",
    "title": "Partial Channel Network: Compute Fewer, Perform Better",
    "authors": [
      "Haiduo Huang",
      "Tian Xia",
      "Wenzhe zhao",
      "Pengju Ren"
    ],
    "abstract": "Designing a module or mechanism that enables a network to maintain low\nparameters and FLOPs without sacrificing accuracy and throughput remains a\nchallenge. To address this challenge and exploit the redundancy within feature\nmap channels, we propose a new solution: partial channel mechanism (PCM).\nSpecifically, through the split operation, the feature map channels are divided\ninto different parts, with each part corresponding to different operations,\nsuch as convolution, attention, pooling, and identity mapping. Based on this\nassumption, we introduce a novel partial attention convolution (PATConv) that\ncan efficiently combine convolution with visual attention. Our exploration\nindicates that the PATConv can completely replace both the regular convolution\nand the regular visual attention while reducing model parameters and FLOPs.\nMoreover, PATConv can derive three new types of blocks: Partial\nChannel-Attention block (PAT_ch), Partial Spatial-Attention block (PAT_sp), and\nPartial Self-Attention block (PAT_sf). In addition, we propose a novel dynamic\npartial convolution (DPConv) that can adaptively learn the proportion of split\nchannels in different layers to achieve better trade-offs. Building on PATConv\nand DPConv, we propose a new hybrid network family, named PartialNet, which\nachieves superior top-1 accuracy and inference speed compared to some SOTA\nmodels on ImageNet-1K classification and excels in both detection and\nsegmentation on the COCO dataset. Our code is available at\nhttps://github.com/haiduo/PartialNet.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01303v1",
    "published_date": "2025-02-03 12:26:55 UTC",
    "updated_date": "2025-02-03 12:26:55 UTC"
  },
  {
    "arxiv_id": "2502.01295v1",
    "title": "Common Foundations for SHACL, ShEx, and PG-Schema",
    "authors": [
      "S. Ahmetaj",
      "I. Boneva",
      "J. Hidders",
      "K. Hose",
      "M. Jakubowski",
      "J. E. Labra-Gayo",
      "W. Martens",
      "F. Mogavero",
      "F. Murlak",
      "C. Okulmus",
      "A. Polleres",
      "O. Savkovic",
      "M. Simkus",
      "D. Tomaszuk"
    ],
    "abstract": "Graphs have emerged as an important foundation for a variety of applications,\nincluding capturing and reasoning over factual knowledge, semantic data\nintegration, social networks, and providing factual knowledge for machine\nlearning algorithms. To formalise certain properties of the data and to ensure\ndata quality, there is a need to describe the schema of such graphs. Because of\nthe breadth of applications and availability of different data models, such as\nRDF and property graphs, both the Semantic Web and the database community have\nindependently developed graph schema languages: SHACL, ShEx, and PG-Schema.\nEach language has its unique approach to defining constraints and validating\ngraph data, leaving potential users in the dark about their commonalities and\ndifferences. In this paper, we provide formal, concise definitions of the core\ncomponents of each of these schema languages. We employ a uniform framework to\nfacilitate a comprehensive comparison between the languages and identify a\ncommon set of functionalities, shedding light on both overlapping and\ndistinctive features of the three languages.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "I.2.4"
    ],
    "primary_category": "cs.DB",
    "comment": "To be published at WWW 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.01295v1",
    "published_date": "2025-02-03 12:17:25 UTC",
    "updated_date": "2025-02-03 12:17:25 UTC"
  },
  {
    "arxiv_id": "2502.01282v1",
    "title": "Rational Gaussian wavelets and corresponding model driven neural networks",
    "authors": [
      "Attila Miklós Ámon",
      "Kristian Fenech",
      "Péter Kovács",
      "Tamás Dózsa"
    ],
    "abstract": "In this paper we consider the continuous wavelet transform using Gaussian\nwavelets multiplied by an appropriate rational term. The zeros and poles of\nthis rational modifier act as free parameters and their choice highly\ninfluences the shape of the mother wavelet. This allows the proposed\nconstruction to approximate signals with complex morphology using only a few\nwavelet coefficients. We show that the proposed rational Gaussian wavelets are\nadmissible and provide numerical approximations of the wavelet coefficients\nusing variable projection operators. In addition, we show how the proposed\nvariable projection based rational Gaussian wavelet transform can be used in\nneural networks to obtain a highly interpretable feature learning layer. We\ndemonstrate the effectiveness of the proposed scheme through a biomedical\napplication, namely, the detection of ventricular ectopic beats (VEBs) in real\nECG measurements.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "65D15",
      "G.1.2"
    ],
    "primary_category": "stat.ML",
    "comment": "Submitted to IEEE Transactions on Signal Processing, 2024 (under\n  review)",
    "pdf_url": "http://arxiv.org/pdf/2502.01282v1",
    "published_date": "2025-02-03 11:53:11 UTC",
    "updated_date": "2025-02-03 11:53:11 UTC"
  },
  {
    "arxiv_id": "2502.01276v1",
    "title": "HyperSHAP: Shapley Values and Interactions for Hyperparameter Importance",
    "authors": [
      "Marcel Wever",
      "Maximilian Muschalik",
      "Fabian Fumagalli",
      "Marius Lindauer"
    ],
    "abstract": "Hyperparameter optimization (HPO) is a crucial step in achieving strong\npredictive performance. However, the impact of individual hyperparameters on\nmodel generalization is highly context-dependent, prohibiting a\none-size-fits-all solution and requiring opaque automated machine learning\n(AutoML) systems to find optimal configurations. The black-box nature of most\nAutoML systems undermines user trust and discourages adoption. To address this,\nwe propose a game-theoretic explainability framework for HPO that is based on\nShapley values and interactions. Our approach provides an additive\ndecomposition of a performance measure across hyperparameters, enabling local\nand global explanations of hyperparameter importance and interactions. The\nframework, named HyperSHAP, offers insights into ablations, the tunability of\nlearning algorithms, and optimizer behavior across different hyperparameter\nspaces. We evaluate HyperSHAP on various HPO benchmarks by analyzing the\ninteraction structure of the HPO problem. Our results show that while\nhigher-order interactions exist, most performance improvements can be explained\nby focusing on lower-order representations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01276v1",
    "published_date": "2025-02-03 11:47:52 UTC",
    "updated_date": "2025-02-03 11:47:52 UTC"
  },
  {
    "arxiv_id": "2502.01273v1",
    "title": "Analysis of Student-LLM Interaction in a Software Engineering Project",
    "authors": [
      "Agrawal Naman",
      "Ridwan Shariffdeen",
      "Guanlin Wang",
      "Sanka Rasnayaka",
      "Ganesh Neelakanta Iyer"
    ],
    "abstract": "Large Language Models (LLMs) are becoming increasingly competent across\nvarious domains, educators are showing a growing interest in integrating these\nLLMs into the learning process. Especially in software engineering, LLMs have\ndemonstrated qualitatively better capabilities in code summarization, code\ngeneration, and debugging. Despite various research on LLMs for software\nengineering tasks in practice, limited research captures the benefits of LLMs\nfor pedagogical advancements and their impact on the student learning process.\nTo this extent, we analyze 126 undergraduate students' interaction with an AI\nassistant during a 13-week semester to understand the benefits of AI for\nsoftware engineering learning. We analyze the conversations, code generated,\ncode utilized, and the human intervention levels to integrate the code into the\ncode base.\n  Our findings suggest that students prefer ChatGPT over CoPilot. Our analysis\nalso finds that ChatGPT generates responses with lower computational complexity\ncompared to CoPilot. Furthermore, conversational-based interaction helps\nimprove the quality of the code generated compared to auto-generated code.\nEarly adoption of LLMs in software engineering is crucial to remain competitive\nin the rapidly developing landscape. Hence, the next generation of software\nengineers must acquire the necessary skills to interact with AI to improve\nproductivity.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "D.2.3"
    ],
    "primary_category": "cs.SE",
    "comment": "8 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.01273v1",
    "published_date": "2025-02-03 11:44:00 UTC",
    "updated_date": "2025-02-03 11:44:00 UTC"
  },
  {
    "arxiv_id": "2502.01268v1",
    "title": "Resilient UAV Trajectory Planning via Few-Shot Meta-Offline Reinforcement Learning",
    "authors": [
      "Eslam Eldeeb",
      "Hirley Alves"
    ],
    "abstract": "Reinforcement learning (RL) has been a promising essence in future 5G-beyond\nand 6G systems. Its main advantage lies in its robust model-free\ndecision-making in complex and large-dimension wireless environments. However,\nmost existing RL frameworks rely on online interaction with the environment,\nwhich might not be feasible due to safety and cost concerns. Another problem\nwith online RL is the lack of scalability of the designed algorithm with\ndynamic or new environments. This work proposes a novel, resilient, few-shot\nmeta-offline RL algorithm combining offline RL using conservative Q-learning\n(CQL) and meta-learning using model-agnostic meta-learning (MAML). The proposed\nalgorithm can train RL models using static offline datasets without any online\ninteraction with the environments. In addition, with the aid of MAML, the\nproposed model can be scaled up to new unseen environments. We showcase the\nproposed algorithm for optimizing an unmanned aerial vehicle (UAV) 's\ntrajectory and scheduling policy to minimize the age-of-information (AoI) and\ntransmission power of limited-power devices. Numerical results show that the\nproposed few-shot meta-offline RL algorithm converges faster than baseline\nschemes, such as deep Q-networks and CQL. In addition, it is the only algorithm\nthat can achieve optimal joint AoI and transmission power using an offline\ndataset with few shots of data points and is resilient to network failures due\nto unprecedented environmental changes.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01268v1",
    "published_date": "2025-02-03 11:39:12 UTC",
    "updated_date": "2025-02-03 11:39:12 UTC"
  },
  {
    "arxiv_id": "2502.01253v1",
    "title": "Explainability-Driven Quality Assessment for Rule-Based Systems",
    "authors": [
      "Oshani Seneviratne",
      "Brendan Capuzzo",
      "William Van Woensel"
    ],
    "abstract": "This paper introduces an explanation framework designed to enhance the\nquality of rules in knowledge-based reasoning systems based on dataset-driven\ninsights. The traditional method for rule induction from data typically\nrequires labor-intensive labeling and data-driven learning. This framework\nprovides an alternative and instead allows for the data-driven refinement of\nexisting rules: it generates explanations of rule inferences and leverages\nhuman interpretation to refine rules. It leverages four complementary\nexplanation types: trace-based, contextual, contrastive, and counterfactual,\nproviding diverse perspectives for debugging, validating, and ultimately\nrefining rules. By embedding explainability into the reasoning architecture,\nthe framework enables knowledge engineers to address inconsistencies, optimize\nthresholds, and ensure fairness, transparency, and interpretability in\ndecision-making processes. Its practicality is demonstrated through a use case\nin finance.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01253v1",
    "published_date": "2025-02-03 11:26:09 UTC",
    "updated_date": "2025-02-03 11:26:09 UTC"
  },
  {
    "arxiv_id": "2502.01247v1",
    "title": "Learnable polynomial, trigonometric, and tropical activations",
    "authors": [
      "Ismail Khalfaoui-Hassani",
      "Stefan Kesselheim"
    ],
    "abstract": "This paper investigates scalable neural networks with learnable activation\nfunctions based on orthogonal function bases and tropical polynomials,\ntargeting ImageNet-1K classification and next token prediction on OpenWebText.\nTraditional activations, such as ReLU, are static. In contrast, learnable\nactivations enable the network to adapt dynamically during training. However,\nstability issues, such as vanishing or exploding gradients, arise with improper\nvariance management in deeper networks. To remedy this, we propose an\ninitialization scheme that single-handedly preserves unitary variance in\ntransformers and convolutional networks, ensuring stable gradient flow even in\ndeep architectures. Extensive experiments demonstrate that networks with\nHermite, Fourier, and Tropical-based learnable activations significantly\nimprove over GPT-2 and ConvNeXt networks in terms of accuracy and perplexity in\ntrain and test, highlighting the viability of learnable activations in\nlarge-scale tasks. The activation functions developed here are the subject of a\nlibrary coded entirely in pure PyTorch: torchortho, available at\nhttps://github.com/K-H-Ismail/torchortho.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "math.AG"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01247v1",
    "published_date": "2025-02-03 11:13:58 UTC",
    "updated_date": "2025-02-03 11:13:58 UTC"
  },
  {
    "arxiv_id": "2502.01243v1",
    "title": "OphthBench: A Comprehensive Benchmark for Evaluating Large Language Models in Chinese Ophthalmology",
    "authors": [
      "Chengfeng Zhou",
      "Ji Wang",
      "Juanjuan Qin",
      "Yining Wang",
      "Ling Sun",
      "Weiwei Dai"
    ],
    "abstract": "Large language models (LLMs) have shown significant promise across various\nmedical applications, with ophthalmology being a notable area of focus. Many\nophthalmic tasks have shown substantial improvement through the integration of\nLLMs. However, before these models can be widely adopted in clinical practice,\nevaluating their capabilities and identifying their limitations is crucial. To\naddress this research gap and support the real-world application of LLMs, we\nintroduce the OphthBench, a specialized benchmark designed to assess LLM\nperformance within the context of Chinese ophthalmic practices. This benchmark\nsystematically divides a typical ophthalmic clinical workflow into five key\nscenarios: Education, Triage, Diagnosis, Treatment, and Prognosis. For each\nscenario, we developed multiple tasks featuring diverse question types,\nresulting in a comprehensive benchmark comprising 9 tasks and 591 questions.\nThis comprehensive framework allows for a thorough assessment of LLMs'\ncapabilities and provides insights into their practical application in Chinese\nophthalmology. Using this benchmark, we conducted extensive experiments and\nanalyzed the results from 39 popular LLMs. Our evaluation highlights the\ncurrent gap between LLM development and its practical utility in clinical\nsettings, providing a clear direction for future advancements. By bridging this\ngap, we aim to unlock the potential of LLMs and advance their development in\nophthalmology.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01243v1",
    "published_date": "2025-02-03 11:04:51 UTC",
    "updated_date": "2025-02-03 11:04:51 UTC"
  },
  {
    "arxiv_id": "2502.01236v1",
    "title": "Eliciting Language Model Behaviors with Investigator Agents",
    "authors": [
      "Xiang Lisa Li",
      "Neil Chowdhury",
      "Daniel D. Johnson",
      "Tatsunori Hashimoto",
      "Percy Liang",
      "Sarah Schwettmann",
      "Jacob Steinhardt"
    ],
    "abstract": "Language models exhibit complex, diverse behaviors when prompted with\nfree-form text, making it difficult to characterize the space of possible\noutputs. We study the problem of behavior elicitation, where the goal is to\nsearch for prompts that induce specific target behaviors (e.g., hallucinations\nor harmful responses) from a target language model. To navigate the\nexponentially large space of possible prompts, we train investigator models to\nmap randomly-chosen target behaviors to a diverse distribution of outputs that\nelicit them, similar to amortized Bayesian inference. We do this through\nsupervised fine-tuning, reinforcement learning via DPO, and a novel Frank-Wolfe\ntraining objective to iteratively discover diverse prompting strategies. Our\ninvestigator models surface a variety of effective and human-interpretable\nprompts leading to jailbreaks, hallucinations, and open-ended aberrant\nbehaviors, obtaining a 100% attack success rate on a subset of AdvBench\n(Harmful Behaviors) and an 85% hallucination rate.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "20 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.01236v1",
    "published_date": "2025-02-03 10:52:44 UTC",
    "updated_date": "2025-02-03 10:52:44 UTC"
  },
  {
    "arxiv_id": "2502.01703v1",
    "title": "QLESS: A Quantized Approach for Data Valuation and Selection in Large Language Model Fine-Tuning",
    "authors": [
      "Moses Ananta",
      "Muhammad Farid Adilazuarda",
      "Zayd Muhammad Kawakibi Zuhri",
      "Ayu Purwarianti",
      "Alham Fikri Aji"
    ],
    "abstract": "Fine-tuning large language models (LLMs) is often constrained by the\ncomputational costs of processing massive datasets. We propose \\textbf{QLESS}\n(Quantized Low-rank Gradient Similarity Search), which integrates gradient\nquantization with the LESS framework to enable memory-efficient data valuation\nand selection. QLESS employs a two-step compression process: first, it obtains\nlow-dimensional gradient representations through LoRA-based random projection;\nthen, it quantizes these gradients to low-bitwidth representations. Experiments\non multiple LLM architectures (LLaMA, Mistral, Qwen) and benchmarks (MMLU, BBH,\nTyDiQA) show that QLESS achieves comparable data selection performance to LESS\nwhile reducing memory usage by up to 16x. Even 1-bit gradient quantization\npreserves data valuation quality. These findings underscore QLESS as a\npractical, scalable approach to identifying informative examples within strict\nmemory constraints.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01703v1",
    "published_date": "2025-02-03 10:52:32 UTC",
    "updated_date": "2025-02-03 10:52:32 UTC"
  },
  {
    "arxiv_id": "2502.01235v1",
    "title": "One-step full gradient suffices for low-rank fine-tuning, provably and efficiently",
    "authors": [
      "Yuanhe Zhang",
      "Fanghui Liu",
      "Yudong Chen"
    ],
    "abstract": "This paper studies how to improve the performance of Low-Rank Adaption (LoRA)\nas guided by our theoretical analysis. Our first set of theoretical results\nshow that for random initialization and linear models, \\textit{i)} LoRA will\nalign to the certain singular subspace of one-step gradient of full\nfine-tuning; \\textit{ii)} preconditioners improve convergence in the high-rank\ncase. These insights motivate us to focus on preconditioned LoRA using a\nspecific spectral initialization strategy for aligning with certain subspaces.\nFor both linear and nonlinear models, we prove that alignment and\ngeneralization guarantees can be directly achieved at initialization, and the\nsubsequent linear convergence can be also built. Our analysis leads to the\n\\emph{LoRA-One} algorithm (using \\emph{One}-step gradient and preconditioning),\na theoretically grounded algorithm that achieves significant empirical\nimprovement over vanilla LoRA and its variants on several benchmarks. Our\ntheoretical analysis, based on decoupling the learning dynamics and\ncharacterizing how spectral initialization contributes to feature learning, may\nbe of independent interest for understanding matrix sensing and deep learning\ntheory. The source code can be found in the\nhttps://github.com/YuanheZ/LoRA-One.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "86 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.01235v1",
    "published_date": "2025-02-03 10:50:03 UTC",
    "updated_date": "2025-02-03 10:50:03 UTC"
  },
  {
    "arxiv_id": "2502.01232v1",
    "title": "Efficient rule induction by ignoring pointless rules",
    "authors": [
      "Andrew Cropper",
      "David M. Cerna"
    ],
    "abstract": "The goal of inductive logic programming (ILP) is to find a set of logical\nrules that generalises training examples and background knowledge. We introduce\nan ILP approach that identifies pointless rules. A rule is pointless if it\ncontains a redundant literal or cannot discriminate against negative examples.\nWe show that ignoring pointless rules allows an ILP system to soundly prune the\nhypothesis space. Our experiments on multiple domains, including visual\nreasoning and game playing, show that our approach can reduce learning times by\n99% whilst maintaining predictive accuracies.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Under review for a conference",
    "pdf_url": "http://arxiv.org/pdf/2502.01232v1",
    "published_date": "2025-02-03 10:46:18 UTC",
    "updated_date": "2025-02-03 10:46:18 UTC"
  },
  {
    "arxiv_id": "2502.01225v1",
    "title": "The dark deep side of DeepSeek: Fine-tuning attacks against the safety alignment of CoT-enabled models",
    "authors": [
      "Zhiyuan Xu",
      "Joseph Gardiner",
      "Sana Belguith"
    ],
    "abstract": "Large language models are typically trained on vast amounts of data during\nthe pre-training phase, which may include some potentially harmful information.\nFine-tuning attacks can exploit this by prompting the model to reveal such\nbehaviours, leading to the generation of harmful content. In this paper, we\nfocus on investigating the performance of the Chain of Thought based reasoning\nmodel, DeepSeek, when subjected to fine-tuning attacks. Specifically, we\nexplore how fine-tuning manipulates the model's output, exacerbating the\nharmfulness of its responses while examining the interaction between the Chain\nof Thought reasoning and adversarial inputs. Through this study, we aim to shed\nlight on the vulnerability of Chain of Thought enabled models to fine-tuning\nattacks and the implications for their safety and ethical deployment.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "12 Pages",
    "pdf_url": "http://arxiv.org/pdf/2502.01225v1",
    "published_date": "2025-02-03 10:28:26 UTC",
    "updated_date": "2025-02-03 10:28:26 UTC"
  },
  {
    "arxiv_id": "2502.01218v1",
    "title": "Provable Ordering and Continuity in Vision-Language Pretraining for Generalizable Embodied Agents",
    "authors": [
      "Zhizhen Zhang",
      "Lei Zhu",
      "Zhen Fang",
      "Zi Huang",
      "Yadan Luo"
    ],
    "abstract": "Pre-training vision-language representations on human action videos has\nemerged as a promising approach to reduce reliance on large-scale expert\ndemonstrations for training embodied agents. However, prior methods often\nemploy time contrastive learning based on goal-reaching heuristics,\nprogressively aligning language instructions from the initial to the final\nframe. This overemphasis on future frames can result in erroneous\nvision-language associations, as actions may terminate early or include\nirrelevant moments in the end. To address this issue, we propose Action\nTemporal Coherence Learning (AcTOL) to learn ordered and continuous\nvision-language representations without rigid goal-based constraint. AcTOL\ntreats a video as a continuous trajectory where it (1) contrasts semantic\ndifferences between frames to reflect their natural ordering, and (2) imposes a\nlocal Brownian bridge constraint to ensure smooth transitions across\nintermediate frames. Extensive imitation learning experiments across varying\nnumbers of demonstrations show that the pretrained features significantly\nenhance downstream manipulation tasks by up to 49% with high robustness to\ndifferent linguistic styles of instructions, offering a viable pathway toward\ngeneralized embodied agents. The source code is included in the supplementary\nmaterial for reference.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01218v1",
    "published_date": "2025-02-03 10:16:49 UTC",
    "updated_date": "2025-02-03 10:16:49 UTC"
  },
  {
    "arxiv_id": "2503.15521v1",
    "title": "From Divergence to Consensus: Evaluating the Role of Large Language Models in Facilitating Agreement through Adaptive Strategies",
    "authors": [
      "Loukas Triantafyllopoulos",
      "Dimitris Kalles"
    ],
    "abstract": "Achieving consensus in group decision-making often involves overcoming\nsignificant challenges, particularly in reconciling diverse perspectives and\nmitigating biases that hinder agreement. Traditional methods relying on human\nfacilitators are often constrained by scalability and efficiency, especially in\nlarge-scale, fast-paced discussions. To address these challenges, this study\nproposes a novel framework employing large language models (LLMs) as automated\nfacilitators within a custom-built multi-user chat system. Leveraging cosine\nsimilarity as a core metric, this approach evaluates the ability of three\nstate-of-the-art LLMs- ChatGPT 4.0, Mistral Large 2, and AI21 Jamba Instruct-\nto synthesize consensus proposals that align with participants' viewpoints.\nUnlike conventional techniques, the system integrates adaptive facilitation\nstrategies, including clarifying misunderstandings, summarizing discussions,\nand proposing compromises, enabling the LLMs to iteratively refine consensus\nproposals based on user feedback. Experimental results demonstrate the\nsuperiority of ChatGPT 4.0, which achieves higher alignment with participant\nopinions, requiring fewer iterations to reach consensus compared to its\ncounterparts. Moreover, analysis reveals the nuanced performance of the models\nacross various sustainability-focused discussion topics, such as climate\naction, quality education, good health and well-being, and access to clean\nwater and sanitation. These findings highlight the transformative potential of\nLLM-driven facilitation for improving collective decision-making processes and\nunderscore the importance of advancing evaluation metrics and cross-cultural\nadaptability in future research.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "32 pages, 5 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2503.15521v1",
    "published_date": "2025-02-03 09:59:55 UTC",
    "updated_date": "2025-02-03 09:59:55 UTC"
  },
  {
    "arxiv_id": "2502.01199v1",
    "title": "Nearly Lossless Adaptive Bit Switching",
    "authors": [
      "Haiduo Huang",
      "Zhenhua Liu",
      "Tian Xia",
      "Wenzhe zhao",
      "Pengju Ren"
    ],
    "abstract": "Model quantization is widely applied for compressing and accelerating deep\nneural networks (DNNs). However, conventional Quantization-Aware Training (QAT)\nfocuses on training DNNs with uniform bit-width. The bit-width settings vary\nacross different hardware and transmission demands, which induces considerable\ntraining and storage costs. Hence, the scheme of one-shot joint training\nmultiple precisions is proposed to address this issue. Previous works either\nstore a larger FP32 model to switch between different precision models for\nhigher accuracy or store a smaller INT8 model but compromise accuracy due to\nusing shared quantization parameters. In this paper, we introduce the Double\nRounding quantization method, which fully utilizes the quantized representation\nrange to accomplish nearly lossless bit-switching while reducing storage by\nusing the highest integer precision instead of full precision. Furthermore, we\nobserve a competitive interference among different precisions during one-shot\njoint training, primarily due to inconsistent gradients of quantization scales\nduring backward propagation. To tackle this problem, we propose an Adaptive\nLearning Rate Scaling (ALRS) technique that dynamically adapts learning rates\nfor various precisions to optimize the training process. Additionally, we\nextend our Double Rounding to one-shot mixed precision training and develop a\nHessian-Aware Stochastic Bit-switching (HASB) strategy. Experimental results on\nthe ImageNet-1K classification demonstrate that our methods have enough\nadvantages to state-of-the-art one-shot joint QAT in both multi-precision and\nmixed-precision. We also validate the feasibility of our method on detection\nand segmentation tasks, as well as on LLMs task. Our codes are available at\nhttps://github.com/haiduo/Double-Rounding.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01199v1",
    "published_date": "2025-02-03 09:46:26 UTC",
    "updated_date": "2025-02-03 09:46:26 UTC"
  },
  {
    "arxiv_id": "2502.01190v1",
    "title": "Dance recalibration for dance coherency with recurrent convolution block",
    "authors": [
      "Seungho Eum",
      "Ihjoon Cho",
      "Junghyeon Kim"
    ],
    "abstract": "With the recent advancements in generative AI such as GAN, Diffusion, and\nVAE, the use of generative AI for dance generation has seen significant\nprogress and received considerable interest. In this study, We propose R-Lodge,\nan enhanced version of Lodge. R-Lodge incorporates Recurrent Sequential\nRepresentation Learning named Dance Recalibration to original coarse-to-fine\nlong dance generation model. R-Lodge utilizes Dance Recalibration method using\n$N$ Dance Recalibration Block to address the lack of consistency in the coarse\ndance representation of the Lodge model. By utilizing this method, each\ngenerated dance motion incorporates a bit of information from the previous\ndance motions. We evaluate R-Lodge on FineDance dataset and the results show\nthat R-Lodge enhances the consistency of the whole generated dance motions.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01190v1",
    "published_date": "2025-02-03 09:29:02 UTC",
    "updated_date": "2025-02-03 09:29:02 UTC"
  },
  {
    "arxiv_id": "2502.01189v3",
    "title": "Compressed Image Generation with Denoising Diffusion Codebook Models",
    "authors": [
      "Guy Ohayon",
      "Hila Manor",
      "Tomer Michaeli",
      "Michael Elad"
    ],
    "abstract": "We present a novel generative approach based on Denoising Diffusion Models\n(DDMs), which produces high-quality image samples along with their losslessly\ncompressed bit-stream representations. This is obtained by replacing the\nstandard Gaussian noise sampling in the reverse diffusion with a selection of\nnoise samples from pre-defined codebooks of fixed iid Gaussian vectors.\nSurprisingly, we find that our method, termed Denoising Diffusion Codebook\nModel (DDCM), retains sample quality and diversity of standard DDMs, even for\nextremely small codebooks. We leverage DDCM and pick the noises from the\ncodebooks that best match a given image, converting our generative model into a\nhighly effective lossy image codec achieving state-of-the-art perceptual image\ncompression results. More generally, by setting other noise selections rules,\nwe extend our compression method to any conditional image generation task\n(e.g., image restoration), where the generated images are produced jointly with\ntheir condensed bit-stream representations. Our work is accompanied by a\nmathematical interpretation of the proposed compressed conditional generation\nschemes, establishing a connection with score-based approximations of posterior\nsamplers for the tasks considered.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.IT",
      "eess.SP",
      "math.IT"
    ],
    "primary_category": "eess.IV",
    "comment": "Code and demo are available at https://ddcm-2025.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2502.01189v3",
    "published_date": "2025-02-03 09:25:57 UTC",
    "updated_date": "2025-02-10 13:11:20 UTC"
  },
  {
    "arxiv_id": "2502.01187v1",
    "title": "Skewed Memorization in Large Language Models: Quantification and Decomposition",
    "authors": [
      "Hao Li",
      "Di Huang",
      "Ziyu Wang",
      "Amir M. Rahmani"
    ],
    "abstract": "Memorization in Large Language Models (LLMs) poses privacy and security\nrisks, as models may unintentionally reproduce sensitive or copyrighted data.\nExisting analyses focus on average-case scenarios, often neglecting the highly\nskewed distribution of memorization. This paper examines memorization in LLM\nsupervised fine-tuning (SFT), exploring its relationships with training\nduration, dataset size, and inter-sample similarity. By analyzing memorization\nprobabilities over sequence lengths, we link this skewness to the token\ngeneration process, offering insights for estimating memorization and comparing\nit to established metrics. Through theoretical analysis and empirical\nevaluation, we provide a comprehensive understanding of memorization behaviors\nand propose strategies to detect and mitigate risks, contributing to more\nprivacy-preserving LLMs.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01187v1",
    "published_date": "2025-02-03 09:23:53 UTC",
    "updated_date": "2025-02-03 09:23:53 UTC"
  },
  {
    "arxiv_id": "2502.01185v1",
    "title": "Deep Active Speech Cancellation with Multi-Band Mamba Network",
    "authors": [
      "Yehuda Mishaly",
      "Lior Wolf",
      "Eliya Nachmani"
    ],
    "abstract": "We present a novel deep learning network for Active Speech Cancellation\n(ASC), advancing beyond Active Noise Cancellation (ANC) methods by effectively\ncanceling both noise and speech signals. The proposed Multi-Band Mamba\narchitecture segments input audio into distinct frequency bands, enabling\nprecise anti-signal generation and improved phase alignment across frequencies.\nAdditionally, we introduce an optimization-driven loss function that provides\nnear-optimal supervisory signals for anti-signal generation. Experimental\nresults demonstrate substantial performance gains, achieving up to 7.2dB\nimprovement in ANC scenarios and 6.2dB in ASC, significantly outperforming\nexisting methods. Audio samples are available at\nhttps://mishalydev.github.io/DeepASC-Demo",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS",
      "eess.SP"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01185v1",
    "published_date": "2025-02-03 09:22:26 UTC",
    "updated_date": "2025-02-03 09:22:26 UTC"
  },
  {
    "arxiv_id": "2502.01184v1",
    "title": "FragmentNet: Adaptive Graph Fragmentation for Graph-to-Sequence Molecular Representation Learning",
    "authors": [
      "Ankur Samanta",
      "Rohan Gupta",
      "Aditi Misra",
      "Christian McIntosh Clarke",
      "Jayakumar Rajadas"
    ],
    "abstract": "Molecular property prediction uses molecular structure to infer chemical\nproperties. Chemically interpretable representations that capture meaningful\nintramolecular interactions enhance the usability and effectiveness of these\npredictions. However, existing methods often rely on atom-based or rule-based\nfragment tokenization, which can be chemically suboptimal and lack scalability.\nWe introduce FragmentNet, a graph-to-sequence foundation model with an\nadaptive, learned tokenizer that decomposes molecular graphs into chemically\nvalid fragments while preserving structural connectivity. FragmentNet\nintegrates VQVAE-GCN for hierarchical fragment embeddings, spatial positional\nencodings for graph serialization, global molecular descriptors, and a\ntransformer. Pre-trained with Masked Fragment Modeling and fine-tuned on\nMoleculeNet tasks, FragmentNet outperforms models with similarly scaled\narchitectures and datasets while rivaling larger state-of-the-art models\nrequiring significantly more resources. This novel framework enables adaptive\ndecomposition, serialization, and reconstruction of molecular graphs,\nfacilitating fragment-based editing and visualization of property trends in\nlearned embeddings - a powerful tool for molecular design and optimization.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.chem-ph",
      "q-bio.QM"
    ],
    "primary_category": "cs.LG",
    "comment": "22 pages, 13 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.01184v1",
    "published_date": "2025-02-03 09:21:49 UTC",
    "updated_date": "2025-02-03 09:21:49 UTC"
  },
  {
    "arxiv_id": "2502.01182v1",
    "title": "A Single Model Ensemble Framework for Neural Machine Translation using Pivot Translation",
    "authors": [
      "Seokjin Oh",
      "Keonwoong Noh",
      "Woohwan Jung"
    ],
    "abstract": "Despite the significant advances in neural machine translation, performance\nremains subpar for low-resource language pairs. Ensembling multiple systems is\na widely adopted technique to enhance performance, often accomplished by\ncombining probability distributions. However, the previous approaches face the\nchallenge of high computational costs for training multiple models.\nFurthermore, for black-box models, averaging token-level probabilities at each\ndecoding step is not feasible. To address the problems of multi-model ensemble\nmethods, we present a pivot-based single model ensemble. The proposed strategy\nconsists of two steps: pivot-based candidate generation and post-hoc\naggregation. In the first step, we generate candidates through pivot\ntranslation. This can be achieved with only a single model and facilitates\nknowledge transfer from high-resource pivot languages, resulting in candidates\nthat are not only diverse but also more accurate. Next, in the aggregation\nstep, we select k high-quality candidates from the generated candidates and\nmerge them to generate a final translation that outperforms the existing\ncandidates. Our experimental results show that our method produces translations\nof superior quality by leveraging candidates from pivot translation to capture\nthe subtle nuances of the source sentence.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01182v1",
    "published_date": "2025-02-03 09:17:45 UTC",
    "updated_date": "2025-02-03 09:17:45 UTC"
  },
  {
    "arxiv_id": "2502.01701v2",
    "title": "Learning with Differentially Private (Sliced) Wasserstein Gradients",
    "authors": [
      "David Rodríguez-Vítores",
      "Clément Lalanne",
      "Jean-Michel Loubes"
    ],
    "abstract": "In this work, we introduce a novel framework for privately optimizing\nobjectives that rely on Wasserstein distances between data-dependent empirical\nmeasures. Our main theoretical contribution is, based on an explicit\nformulation of the Wasserstein gradient in a fully discrete setting, a control\non the sensitivity of this gradient to individual data points, allowing strong\nprivacy guarantees at minimal utility cost. Building on these insights, we\ndevelop a deep learning approach that incorporates gradient and activations\nclipping, originally designed for DP training of problems with a finite-sum\nstructure. We further demonstrate that privacy accounting methods extend to\nWasserstein-based objectives, facilitating large-scale private training.\nEmpirical results confirm that our framework effectively balances accuracy and\nprivacy, offering a theoretically sound solution for privacy-preserving machine\nlearning tasks relying on optimal transport distances such as Wasserstein\ndistance or sliced-Wasserstein distance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01701v2",
    "published_date": "2025-02-03 09:14:26 UTC",
    "updated_date": "2025-05-21 14:01:30 UTC"
  },
  {
    "arxiv_id": "2502.01179v3",
    "title": "Joint Localization and Activation Editing for Low-Resource Fine-Tuning",
    "authors": [
      "Wen Lai",
      "Alexander Fraser",
      "Ivan Titov"
    ],
    "abstract": "Parameter-efficient fine-tuning (PEFT) methods, such as LoRA, are commonly\nused to adapt LLMs. However, the effectiveness of standard PEFT methods is\nlimited in low-resource scenarios with only a few hundred examples. Recent\nadvances in interpretability research have inspired the emergence of activation\nediting (or steering) techniques, which modify the activations of specific\nmodel components. These methods, due to their extremely small parameter counts,\nshow promise for small datasets. However, their performance is highly dependent\non identifying the correct modules to edit and often lacks stability across\ndifferent datasets. In this paper, we propose Joint Localization and Activation\nEditing (JoLA), a method that jointly learns (1) which heads in the Transformer\nto edit (2) whether the intervention should be additive, multiplicative, or\nboth and (3) the intervention parameters themselves - the vectors applied as\nadditive offsets or multiplicative scalings to the head output. Through\nevaluations on three benchmarks spanning commonsense reasoning, natural\nlanguage understanding, and natural language generation, we demonstrate that\nJoLA consistently outperforms existing methods. The code for the method is\nreleased at https://github.com/wenlai-lavine/jola.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by ICML 2025. The code is released at\n  https://github.com/wenlai-lavine/jola",
    "pdf_url": "http://arxiv.org/pdf/2502.01179v3",
    "published_date": "2025-02-03 09:13:09 UTC",
    "updated_date": "2025-05-19 11:36:10 UTC"
  },
  {
    "arxiv_id": "2502.01160v1",
    "title": "Scalable Precise Computation of Shannon Entropy",
    "authors": [
      "Yong Lai",
      "Haolong Tong",
      "Zhenghang Xu",
      "Minghao Yin"
    ],
    "abstract": "Quantitative information flow analyses (QIF) are a class of techniques for\nmeasuring the amount of confidential information leaked by a program to its\npublic outputs.\n  Shannon entropy is an important method to quantify the amount of leakage in\nQIF.\n  This paper focuses on the programs modeled in Boolean constraints and\noptimizes the two stages of the Shannon entropy computation to implement a\nscalable precise tool PSE.\n  In the first stage, we design a knowledge compilation language called \\ADDAND\nthat combines Algebraic Decision Diagrams and conjunctive decomposition.\n  \\ADDAND avoids enumerating possible outputs of a program and supports\ntractable entropy computation.\n  In the second stage, we optimize the model counting queries that are used to\ncompute the probabilities of outputs.\n  We compare PSE with the state-of-the-art probably approximately correct tool\nEntropyEstimation, which was shown to significantly outperform the existing\nprecise tools.\n  The experimental results demonstrate that PSE solved 55 more benchmarks\ncompared to EntropyEstimation in a total of 441. For 98% of the benchmarks that\nboth PSE and EntropyEstimation solved, PSE is at least $10\\times$ as efficient\nas EntropyEstimation.",
    "categories": [
      "cs.AI",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.01160v1",
    "published_date": "2025-02-03 08:51:03 UTC",
    "updated_date": "2025-02-03 08:51:03 UTC"
  },
  {
    "arxiv_id": "2502.01159v1",
    "title": "AtmosSci-Bench: Evaluating the Recent Advance of Large Language Model for Atmospheric Science",
    "authors": [
      "Chenyue Li",
      "Wen Deng",
      "Mengqian Lu",
      "Binhang Yuan"
    ],
    "abstract": "The rapid advancements in large language models (LLMs), particularly in their\nreasoning capabilities, hold transformative potential for addressing complex\nchallenges in atmospheric science. However, leveraging LLMs effectively in this\ndomain requires a robust and comprehensive evaluation benchmark. To address\nthis need, we present AtmosSci-Bench, a novel benchmark designed to\nsystematically assess LLM performance across five core categories of\natmospheric science problems: hydrology, atmospheric dynamics, atmospheric\nphysics, geophysics, and physical oceanography. We employ a template-based\nquestion generation framework, enabling scalable and diverse multiple-choice\nquestions curated from graduate-level atmospheric science problems. We conduct\na comprehensive evaluation of representative LLMs, categorized into four\ngroups: instruction-tuned models, advanced reasoning models, math-augmented\nmodels, and domain-specific climate models. Our analysis provides some\ninteresting insights into the reasoning and problem-solving capabilities of\nLLMs in atmospheric science. We believe AtmosSci-Bench can serve as a critical\nstep toward advancing LLM applications in climate service by offering a\nstandard and rigorous evaluation framework. Our source codes are currently\navailable at https://github.com/Relaxed-System-Lab/AtmosSci-Bench.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "16 pages, 3 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2502.01159v1",
    "published_date": "2025-02-03 08:50:46 UTC",
    "updated_date": "2025-02-03 08:50:46 UTC"
  },
  {
    "arxiv_id": "2502.01158v1",
    "title": "MIND: Modality-Informed Knowledge Distillation Framework for Multimodal Clinical Prediction Tasks",
    "authors": [
      "Alejandro Guerra-Manzanares",
      "Farah E. Shamout"
    ],
    "abstract": "Multimodal fusion leverages information across modalities to learn better\nfeature representations with the goal of improving performance in fusion-based\ntasks. However, multimodal datasets, especially in medical settings, are\ntypically smaller than their unimodal counterparts, which can impede the\nperformance of multimodal models. Additionally, the increase in the number of\nmodalities is often associated with an overall increase in the size of the\nmultimodal network, which may be undesirable in medical use cases. Utilizing\nsmaller unimodal encoders may lead to sub-optimal performance, particularly\nwhen dealing with high-dimensional clinical data. In this paper, we propose the\nModality-INformed knowledge Distillation (MIND) framework, a multimodal model\ncompression approach based on knowledge distillation that transfers knowledge\nfrom ensembles of pre-trained deep neural networks of varying sizes into a\nsmaller multimodal student. The teacher models consist of unimodal networks,\nallowing the student to learn from diverse representations. MIND employs\nmulti-head joint fusion models, as opposed to single-head models, enabling the\nuse of unimodal encoders in the case of unimodal samples without requiring\nimputation or masking of absent modalities. As a result, MIND generates an\noptimized multimodal model, enhancing both multimodal and unimodal\nrepresentations. It can also be leveraged to balance multimodal learning during\ntraining. We evaluate MIND on binary and multilabel clinical prediction tasks\nusing time series data and chest X-ray images. Additionally, we assess the\ngeneralizability of the MIND framework on three non-medical multimodal\nmulticlass datasets. Experimental results demonstrate that MIND enhances the\nperformance of the smaller multimodal network across all five tasks, as well as\nvarious fusion methods and multimodal architectures, compared to\nstate-of-the-art baselines.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Published in Transactions on Machine Learning Research (01/2025),\n  https://openreview.net/forum?id=BhOJreYmur&noteId=ymnAhncuez",
    "pdf_url": "http://arxiv.org/pdf/2502.01158v1",
    "published_date": "2025-02-03 08:50:00 UTC",
    "updated_date": "2025-02-03 08:50:00 UTC"
  },
  {
    "arxiv_id": "2502.01154v1",
    "title": "Jailbreaking with Universal Multi-Prompts",
    "authors": [
      "Yu-Ling Hsu",
      "Hsuan Su",
      "Shang-Tse Chen"
    ],
    "abstract": "Large language models (LLMs) have seen rapid development in recent years,\nrevolutionizing various applications and significantly enhancing convenience\nand productivity. However, alongside their impressive capabilities, ethical\nconcerns and new types of attacks, such as jailbreaking, have emerged. While\nmost prompting techniques focus on optimizing adversarial inputs for individual\ncases, resulting in higher computational costs when dealing with large\ndatasets. Less research has addressed the more general setting of training a\nuniversal attacker that can transfer to unseen tasks. In this paper, we\nintroduce JUMP, a prompt-based method designed to jailbreak LLMs using\nuniversal multi-prompts. We also adapt our approach for defense, which we term\nDUMP. Experimental results demonstrate that our method for optimizing universal\nmulti-prompts outperforms existing techniques.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by NAACL Findings 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.01154v1",
    "published_date": "2025-02-03 08:44:24 UTC",
    "updated_date": "2025-02-03 08:44:24 UTC"
  },
  {
    "arxiv_id": "2502.01146v1",
    "title": "Quantum Machine Learning: A Hands-on Tutorial for Machine Learning Practitioners and Researchers",
    "authors": [
      "Yuxuan Du",
      "Xinbiao Wang",
      "Naixu Guo",
      "Zhan Yu",
      "Yang Qian",
      "Kaining Zhang",
      "Min-Hsiu Hsieh",
      "Patrick Rebentrost",
      "Dacheng Tao"
    ],
    "abstract": "This tutorial intends to introduce readers with a background in AI to quantum\nmachine learning (QML) -- a rapidly evolving field that seeks to leverage the\npower of quantum computers to reshape the landscape of machine learning. For\nself-consistency, this tutorial covers foundational principles, representative\nQML algorithms, their potential applications, and critical aspects such as\ntrainability, generalization, and computational complexity. In addition,\npractical code demonstrations are provided in https://qml-tutorial.github.io/\nto illustrate real-world implementations and facilitate hands-on learning.\nTogether, these elements offer readers a comprehensive overview of the latest\nadvancements in QML. By bridging the gap between classical machine learning and\nquantum computing, this tutorial serves as a valuable resource for those\nlooking to engage with QML and explore the forefront of AI in the quantum era.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "quant-ph",
    "comment": "260 pages; Comments are welcome",
    "pdf_url": "http://arxiv.org/pdf/2502.01146v1",
    "published_date": "2025-02-03 08:33:44 UTC",
    "updated_date": "2025-02-03 08:33:44 UTC"
  },
  {
    "arxiv_id": "2502.01143v3",
    "title": "ASAP: Aligning Simulation and Real-World Physics for Learning Agile Humanoid Whole-Body Skills",
    "authors": [
      "Tairan He",
      "Jiawei Gao",
      "Wenli Xiao",
      "Yuanhang Zhang",
      "Zi Wang",
      "Jiashun Wang",
      "Zhengyi Luo",
      "Guanqi He",
      "Nikhil Sobanbab",
      "Chaoyi Pan",
      "Zeji Yi",
      "Guannan Qu",
      "Kris Kitani",
      "Jessica Hodgins",
      "Linxi \"Jim\" Fan",
      "Yuke Zhu",
      "Changliu Liu",
      "Guanya Shi"
    ],
    "abstract": "Humanoid robots hold the potential for unparalleled versatility in performing\nhuman-like, whole-body skills. However, achieving agile and coordinated\nwhole-body motions remains a significant challenge due to the dynamics mismatch\nbetween simulation and the real world. Existing approaches, such as system\nidentification (SysID) and domain randomization (DR) methods, often rely on\nlabor-intensive parameter tuning or result in overly conservative policies that\nsacrifice agility. In this paper, we present ASAP (Aligning Simulation and\nReal-World Physics), a two-stage framework designed to tackle the dynamics\nmismatch and enable agile humanoid whole-body skills. In the first stage, we\npre-train motion tracking policies in simulation using retargeted human motion\ndata. In the second stage, we deploy the policies in the real world and collect\nreal-world data to train a delta (residual) action model that compensates for\nthe dynamics mismatch. Then, ASAP fine-tunes pre-trained policies with the\ndelta action model integrated into the simulator to align effectively with\nreal-world dynamics. We evaluate ASAP across three transfer scenarios: IsaacGym\nto IsaacSim, IsaacGym to Genesis, and IsaacGym to the real-world Unitree G1\nhumanoid robot. Our approach significantly improves agility and whole-body\ncoordination across various dynamic motions, reducing tracking error compared\nto SysID, DR, and delta dynamics learning baselines. ASAP enables highly agile\nmotions that were previously difficult to achieve, demonstrating the potential\nof delta action learning in bridging simulation and real-world dynamics. These\nresults suggest a promising sim-to-real direction for developing more\nexpressive and agile humanoids.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "RSS 2025. Project website: https://agile.human2humanoid.com/",
    "pdf_url": "http://arxiv.org/pdf/2502.01143v3",
    "published_date": "2025-02-03 08:22:46 UTC",
    "updated_date": "2025-04-26 03:22:14 UTC"
  },
  {
    "arxiv_id": "2502.01142v1",
    "title": "DeepRAG: Thinking to Retrieval Step by Step for Large Language Models",
    "authors": [
      "Xinyan Guan",
      "Jiali Zeng",
      "Fandong Meng",
      "Chunlei Xin",
      "Yaojie Lu",
      "Hongyu Lin",
      "Xianpei Han",
      "Le Sun",
      "Jie Zhou"
    ],
    "abstract": "Large Language Models (LLMs) have shown remarkable potential in reasoning\nwhile they still suffer from severe factual hallucinations due to timeliness,\naccuracy, and coverage of parametric knowledge. Meanwhile, integrating\nreasoning with retrieval-augmented generation (RAG) remains challenging due to\nineffective task decomposition and redundant retrieval, which can introduce\nnoise and degrade response quality. In this paper, we propose DeepRAG, a\nframework that models retrieval-augmented reasoning as a Markov Decision\nProcess (MDP), enabling strategic and adaptive retrieval. By iteratively\ndecomposing queries, DeepRAG dynamically determines whether to retrieve\nexternal knowledge or rely on parametric reasoning at each step. Experiments\nshow that DeepRAG improves retrieval efficiency while improving answer accuracy\nby 21.99%, demonstrating its effectiveness in optimizing retrieval-augmented\nreasoning.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01142v1",
    "published_date": "2025-02-03 08:22:45 UTC",
    "updated_date": "2025-02-03 08:22:45 UTC"
  },
  {
    "arxiv_id": "2502.01141v1",
    "title": "Beyond Yes or No: Predictive Compliance Monitoring Approaches for Quantifying the Magnitude of Compliance Violations",
    "authors": [
      "Qian Chen",
      "Stefanie Rinderle-Ma",
      "Lijie Wen"
    ],
    "abstract": "Most existing process compliance monitoring approaches detect compliance\nviolations in an ex post manner. Only predicate prediction focuses on\npredicting them. However, predicate prediction provides a binary yes/no notion\nof compliance, lacking the ability to measure to which extent an ongoing\nprocess instance deviates from the desired state as specified in constraints.\nHere, being able to quantify the magnitude of violation would provide\norganizations with deeper insights into their operational performance, enabling\ninformed decision making to reduce or mitigate the risk of non-compliance.\nThus, we propose two predictive compliance monitoring approaches to close this\nresearch gap. The first approach reformulates the binary classification problem\nas a hybrid task that considers both classification and regression, while the\nsecond employs a multi-task learning method to explicitly predict the\ncompliance status and the magnitude of violation for deviant cases\nsimultaneously. In this work, we focus on temporal constraints as they are\nsignificant in almost any application domain, e.g., health care. The evaluation\non synthetic and real-world event logs demonstrates that our approaches are\ncapable of quantifying the magnitude of violations while maintaining comparable\nperformance for compliance predictions achieved by state-of-the-art approaches.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01141v1",
    "published_date": "2025-02-03 08:18:33 UTC",
    "updated_date": "2025-02-03 08:18:33 UTC"
  },
  {
    "arxiv_id": "2502.01137v1",
    "title": "Self-Organizing Interaction Spaces: A Framework for Engineering Pervasive Applications in Mobile and Distributed Environments",
    "authors": [
      "Shubham Malhotra"
    ],
    "abstract": "The rapid adoption of pervasive and mobile computing has led to an\nunprecedented rate of data production and consumption by mobile applications at\nthe network edge. These applications often require interactions such as data\nexchange, behavior coordination, and collaboration, which are typically\nmediated by cloud servers. While cloud computing has been effective for\ndistributed systems, challenges like latency, cost, and intermittent\nconnectivity persist. With the advent of 5G technology, features like\nlocation-awareness and device-to-device (D2D) communication enable a more\ndistributed and adaptive architecture. This paper introduces Self-Organizing\nInteraction Spaces (SOIS), a novel framework for engineering pervasive\napplications. SOIS leverages the dynamic and heterogeneous nature of mobile\nnodes, allowing them to form adaptive organizational structures based on their\nindividual and social contexts. The framework provides two key abstractions for\nmodeling and programming pervasive applications using an organizational mindset\nand mechanisms for adapting dynamic organizational structures. Case examples\nand performance evaluations of a simulated mobile crowd-sensing application\ndemonstrate the feasibility and benefits of SOIS. Results highlight its\npotential to enhance efficiency and reduce reliance on traditional cloud\nmodels, paving the way for innovative solutions in mobile and distributed\nenvironments.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG",
      "cs.SE"
    ],
    "primary_category": "cs.DC",
    "comment": "9 pages, 3 listings",
    "pdf_url": "http://arxiv.org/pdf/2502.01137v1",
    "published_date": "2025-02-03 08:11:30 UTC",
    "updated_date": "2025-02-03 08:11:30 UTC"
  },
  {
    "arxiv_id": "2502.01129v3",
    "title": "Deep Reinforcement Learning for Dynamic Resource Allocation in Wireless Networks",
    "authors": [
      "Shubham Malhotra",
      "Fnu Yashu",
      "Muhammad Saqib",
      "Dipkumar Mehta",
      "Jagdish Jangid",
      "Sachin Dixit"
    ],
    "abstract": "This report investigates the application of deep reinforcement learning (DRL)\nalgorithms for dynamic resource allocation in wireless communication systems.\nAn environment that includes a base station, multiple antennas, and user\nequipment is created. Using the RLlib library, various DRL algorithms such as\nDeep Q-Network (DQN) and Proximal Policy Optimization (PPO) are then applied.\nThese algorithms are compared based on their ability to optimize resource\nallocation, focusing on the impact of different learning rates and scheduling\npolicies. The findings demonstrate that the choice of algorithm and learning\nrate significantly influences system performance, with DRL providing more\nefficient resource allocation compared to traditional methods.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.ET",
      "cs.LG"
    ],
    "primary_category": "cs.DC",
    "comment": "Upon further review, we found inconsistencies in our analysis and\n  decided to conduct additional research before resubmitting a revised version",
    "pdf_url": "http://arxiv.org/pdf/2502.01129v3",
    "published_date": "2025-02-03 07:49:00 UTC",
    "updated_date": "2025-03-13 13:17:05 UTC"
  },
  {
    "arxiv_id": "2502.01127v3",
    "title": "The Battling Influencers Game: Nash Equilibria Structure of a Potential Game and Implications to Value Alignment",
    "authors": [
      "Young Wu",
      "Yancheng Zhu",
      "Jin-Yi Cai",
      "Xiaojin Zhu"
    ],
    "abstract": "When multiple influencers attempt to compete for a receiver's attention,\ntheir influencing strategies must account for the presence of one another. We\nintroduce the Battling Influencers Game (BIG), a multi-player simultaneous-move\ngeneral-sum game, to provide a game-theoretic characterization of this social\nphenomenon. We prove that BIG is a potential game, that it has either one or an\ninfinite number of pure Nash equilibria (NEs), and these pure NEs can be found\nby convex optimization. Interestingly, we also prove that at any pure NE, all\n(except at most one) influencers must exaggerate their actions to the maximum\nextent. In other words, it is rational for the influencers to be non-truthful\nand extreme because they anticipate other influencers to cancel out part of\ntheir influence. We discuss the implications of BIG to value alignment.",
    "categories": [
      "cs.GT",
      "cs.AI"
    ],
    "primary_category": "cs.GT",
    "comment": "9 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.01127v3",
    "published_date": "2025-02-03 07:45:41 UTC",
    "updated_date": "2025-02-07 08:10:54 UTC"
  },
  {
    "arxiv_id": "2502.01118v1",
    "title": "Large Language Model-Enhanced Multi-Armed Bandits",
    "authors": [
      "Jiahang Sun",
      "Zhiyong Wang",
      "Runhan Yang",
      "Chenjun Xiao",
      "John C. S. Lui",
      "Zhongxiang Dai"
    ],
    "abstract": "Large language models (LLMs) have been adopted to solve sequential\ndecision-making tasks such as multi-armed bandits (MAB), in which an LLM is\ndirectly instructed to select the arms to pull in every iteration. However,\nthis paradigm of direct arm selection using LLMs has been shown to be\nsuboptimal in many MAB tasks. Therefore, we propose an alternative approach\nwhich combines the strengths of classical MAB and LLMs. Specifically, we adopt\na classical MAB algorithm as the high-level framework and leverage the strong\nin-context learning capability of LLMs to perform the sub-task of reward\nprediction. Firstly, we incorporate the LLM-based reward predictor into the\nclassical Thompson sampling (TS) algorithm and adopt a decaying schedule for\nthe LLM temperature to ensure a transition from exploration to exploitation.\nNext, we incorporate the LLM-based reward predictor (with a temperature of 0)\ninto a regression oracle-based MAB algorithm equipped with an explicit\nexploration mechanism. We also extend our TS-based algorithm to dueling bandits\nwhere only the preference feedback between pairs of arms is available, which\nrequires non-trivial algorithmic modifications. We conduct empirical\nevaluations using both synthetic MAB tasks and experiments designed using\nreal-world text datasets, in which the results show that our algorithms\nconsistently outperform previous baseline methods based on direct arm\nselection. Interestingly, we also demonstrate that in challenging tasks where\nthe arms lack semantic meanings that can be exploited by the LLM, our approach\nachieves considerably better performance than LLM-based direct arm selection.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2502.01118v1",
    "published_date": "2025-02-03 07:19:05 UTC",
    "updated_date": "2025-02-03 07:19:05 UTC"
  },
  {
    "arxiv_id": "2503.11655v1",
    "title": "Explainable Sentiment Analysis with DeepSeek-R1: Performance, Efficiency, and Few-Shot Learning",
    "authors": [
      "Donghao Huang",
      "Zhaoxia Wang"
    ],
    "abstract": "Recent advancements in large language models (LLMs) have significantly\nenhanced sentiment analysis capabilities. However, the trade-offs between model\nperformance, efficiency, and explainability of some latest models remain\nunderexplored. This study presents the first comprehensive evaluation of the\nDeepSeek-R1 series of models, reasoning open-source LLMs, for sentiment\nanalysis, comparing them against OpenAI's GPT-4 and GPT-4-mini. We\nsystematically analyze their performance under few-shot prompting conditions,\nscaling up to 50-shot configurations to assess in-context learning\neffectiveness. Our experiments reveal that DeepSeek-R1 demonstrates competitive\naccuracy, particularly in multi-class sentiment tasks, while offering enhanced\ninterpretability through its detailed reasoning process. Additionally, we\nhighlight the impact of increasing few-shot examples on model performance and\ndiscuss key trade-offs between explainability and computational efficiency.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages, 3 figures, 4 tables, submitted to an IEEE journal",
    "pdf_url": "http://arxiv.org/pdf/2503.11655v1",
    "published_date": "2025-02-03 07:17:46 UTC",
    "updated_date": "2025-02-03 07:17:46 UTC"
  },
  {
    "arxiv_id": "2502.01117v3",
    "title": "Learning to Learn Weight Generation via Local Consistency Diffusion",
    "authors": [
      "Yunchuan Guan",
      "Yu Liu",
      "Ke Zhou",
      "Zhiqi Shen",
      "Jenq-Neng Hwang",
      "Lei Li"
    ],
    "abstract": "Diffusion-based algorithms have emerged as promising techniques for weight\ngeneration. However, existing solutions are limited by two challenges:\ngeneralizability and local target assignment. The former arises from the\ninherent lack of cross-task transferability in existing single-level\noptimization methods, limiting the model's performance on new tasks. The latter\nlies in existing research modeling only global optimal weights, neglecting the\nsupervision signals in local target weights. Moreover, naively assigning local\ntarget weights causes local-global inconsistency. To address these issues, we\npropose Mc-Di, which integrates the diffusion algorithm with meta-learning for\nbetter generalizability. Furthermore, we extend the vanilla diffusion into a\nlocal consistency diffusion algorithm. Our theory and experiments demonstrate\nthat it can learn from local targets while maintaining consistency with the\nglobal optima. We validate Mc-Di's superior accuracy and inference efficiency\nin tasks that require frequent weight updates, including transfer learning,\nfew-shot learning, domain generalization, and large language model adaptation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01117v3",
    "published_date": "2025-02-03 07:13:59 UTC",
    "updated_date": "2025-05-19 05:44:58 UTC"
  },
  {
    "arxiv_id": "2502.01116v1",
    "title": "Picky LLMs and Unreliable RMs: An Empirical Study on Safety Alignment after Instruction Tuning",
    "authors": [
      "Guanlin Li",
      "Kangjie Chen",
      "Shangwei Guo",
      "Jie Zhang",
      "Han Qiu",
      "Chao Zhang",
      "Guoyin Wang",
      "Tianwei Zhang",
      "Jiwei Li"
    ],
    "abstract": "Large language models (LLMs) have emerged as powerful tools for addressing a\nwide range of general inquiries and tasks. Despite this, fine-tuning aligned\nLLMs on smaller, domain-specific datasets, critical to adapting them to\nspecialized tasks, can inadvertently degrade their safety alignment, even when\nthe datasets are benign. This phenomenon makes models more susceptible to\nproviding inappropriate responses. In this study, we systematically examine the\nfactors contributing to safety alignment degradation in benign fine-tuning\nscenarios. Our analysis identifies three critical factors affecting aligned\nLLMs: answer structure, identity calibration, and role-play. Additionally, we\nevaluate the reliability of state-of-the-art reward models (RMs), which are\noften used to guide alignment processes. Our findings reveal that these RMs\nfrequently fail to accurately reflect human preferences regarding safety,\nunderscoring their limitations in practical applications. By uncovering these\nchallenges, our work highlights the complexities of maintaining safety\nalignment during fine-tuning and offers guidance to help developers balance\nutility and safety in LLMs. Datasets and fine-tuning code used in our\nexperiments can be found in\nhttps://github.com/GuanlinLee/llm_instruction_tuning.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01116v1",
    "published_date": "2025-02-03 07:09:09 UTC",
    "updated_date": "2025-02-03 07:09:09 UTC"
  },
  {
    "arxiv_id": "2502.01113v1",
    "title": "GFM-RAG: Graph Foundation Model for Retrieval Augmented Generation",
    "authors": [
      "Linhao Luo",
      "Zicheng Zhao",
      "Gholamreza Haffari",
      "Dinh Phung",
      "Chen Gong",
      "Shirui Pan"
    ],
    "abstract": "Retrieval-augmented generation (RAG) has proven effective in integrating\nknowledge into large language models (LLMs). However, conventional RAGs\nstruggle to capture complex relationships between pieces of knowledge, limiting\ntheir performance in intricate reasoning that requires integrating knowledge\nfrom multiple sources. Recently, graph-enhanced retrieval augmented generation\n(GraphRAG) builds graph structure to explicitly model these relationships,\nenabling more effective and efficient retrievers. Nevertheless, its performance\nis still hindered by the noise and incompleteness within the graph structure.\nTo address this, we introduce GFM-RAG, a novel graph foundation model (GFM) for\nretrieval augmented generation. GFM-RAG is powered by an innovative graph\nneural network that reasons over graph structure to capture complex\nquery-knowledge relationships. The GFM with 8M parameters undergoes a two-stage\ntraining process on large-scale datasets, comprising 60 knowledge graphs with\nover 14M triples and 700k documents. This results in impressive performance and\ngeneralizability for GFM-RAG, making it the first graph foundation model\napplicable to unseen datasets for retrieval without any fine-tuning required.\nExtensive experiments on three multi-hop QA datasets and seven domain-specific\nRAG datasets demonstrate that GFM-RAG achieves state-of-the-art performance\nwhile maintaining efficiency and alignment with neural scaling laws,\nhighlighting its potential for further improvement.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "19 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.01113v1",
    "published_date": "2025-02-03 07:04:29 UTC",
    "updated_date": "2025-02-03 07:04:29 UTC"
  },
  {
    "arxiv_id": "2502.01111v1",
    "title": "A generative foundation model for an all-in-one seismic processing framework",
    "authors": [
      "Shijun Cheng",
      "Randy Harsuko",
      "Tariq Alkhalifah"
    ],
    "abstract": "Seismic data often face challenges in their utilization due to noise\ncontamination, incomplete acquisition, and limited low-frequency information,\nwhich hinder accurate subsurface imaging and interpretation. Traditional\nprocessing methods rely heavily on task-specific designs to address these\nchallenges and fail to account for the variability of data. To address these\nlimitations, we present a generative seismic foundation model (GSFM), a unified\nframework based on generative diffusion models (GDMs), designed to tackle\nmulti-task seismic processing challenges, including denoising, backscattered\nnoise attenuation, interpolation, and low-frequency extrapolation. GSFM\nleverages a pre-training stage on synthetic data to capture the features of\nclean, complete, and broadband seismic data distributions and applies an\niterative fine-tuning strategy to adapt the model to field data. By adopting a\ntarget-oriented diffusion process prediction, GSFM improves computational\nefficiency without compromising accuracy. Synthetic data tests demonstrate GSFM\nsurpasses benchmarks with equivalent architectures in all tasks and achieves\nperformance comparable to traditional pre-training strategies, even after their\nfine-tuning. Also, field data tests suggest that our iterative fine-tuning\napproach addresses the generalization limitations of conventional pre-training\nand fine-tuning paradigms, delivering significantly enhanced performance across\ndiverse tasks. Furthermore, GSFM's inherent probabilistic nature enables\neffective uncertainty quantification, offering valuable insights into the\nreliability of processing results.",
    "categories": [
      "physics.geo-ph",
      "cs.AI"
    ],
    "primary_category": "physics.geo-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01111v1",
    "published_date": "2025-02-03 07:01:36 UTC",
    "updated_date": "2025-02-03 07:01:36 UTC"
  },
  {
    "arxiv_id": "2502.01108v1",
    "title": "Pulse-PPG: An Open-Source Field-Trained PPG Foundation Model for Wearable Applications Across Lab and Field Settings",
    "authors": [
      "Mithun Saha",
      "Maxwell A. Xu",
      "Wanting Mao",
      "Sameer Neupane",
      "James M. Rehg",
      "Santosh Kumar"
    ],
    "abstract": "Photoplethysmography (PPG)-based foundation models are gaining traction due\nto the widespread use of PPG in biosignal monitoring and their potential to\ngeneralize across diverse health applications. In this paper, we introduce\nPulse-PPG, the first open-source PPG foundation model trained exclusively on\nraw PPG data collected over a 100-day field study with 120 participants.\nExisting PPG foundation models are either open-source but trained on clinical\ndata or closed-source, limiting their applicability in real-world settings. We\nevaluate Pulse-PPG across multiple datasets and downstream tasks, comparing its\nperformance against a state-of-the-art foundation model trained on clinical\ndata. Our results demonstrate that Pulse-PPG, trained on uncurated field data,\nexhibits superior generalization across clinical and mobile health applications\nin both lab and field settings. This suggests that exposure to real-world\nvariability enables the model to learn fine-grained representations, making it\nmore adaptable across tasks. Furthermore, pre-training on field data\nsurprisingly outperforms its pre-training on clinical data in many tasks,\nreinforcing the importance of training on real-world, diverse datasets. To\nencourage further advancements in robust foundation models leveraging field\ndata, we plan to release Pulse-PPG, providing researchers with a powerful\nresource for developing more generalizable PPG-based models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "The first two listed authors contributed equally to this research",
    "pdf_url": "http://arxiv.org/pdf/2502.01108v1",
    "published_date": "2025-02-03 06:56:40 UTC",
    "updated_date": "2025-02-03 06:56:40 UTC"
  },
  {
    "arxiv_id": "2502.01101v2",
    "title": "VidSketch: Hand-drawn Sketch-Driven Video Generation with Diffusion Control",
    "authors": [
      "Lifan Jiang",
      "Shuang Chen",
      "Boxi Wu",
      "Xiaotong Guan",
      "Jiahui Zhang"
    ],
    "abstract": "With the advancement of generative artificial intelligence, previous studies\nhave achieved the task of generating aesthetic images from hand-drawn sketches,\nfulfilling the public's needs for drawing. However, these methods are limited\nto static images and lack the ability to control video animation generation\nusing hand-drawn sketches. To address this gap, we propose VidSketch, the first\nmethod capable of generating high-quality video animations directly from any\nnumber of hand-drawn sketches and simple text prompts, bridging the divide\nbetween ordinary users and professional artists. Specifically, our method\nintroduces a Level-Based Sketch Control Strategy to automatically adjust the\nguidance strength of sketches during the generation process, accommodating\nusers with varying drawing skills. Furthermore, a TempSpatial Attention\nmechanism is designed to enhance the spatiotemporal consistency of generated\nvideo animations, significantly improving the coherence across frames. You can\nfind more detailed cases on our official website.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "17pages, 15 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.01101v2",
    "published_date": "2025-02-03 06:45:00 UTC",
    "updated_date": "2025-02-17 05:49:03 UTC"
  },
  {
    "arxiv_id": "2502.01100v1",
    "title": "ZebraLogic: On the Scaling Limits of LLMs for Logical Reasoning",
    "authors": [
      "Bill Yuchen Lin",
      "Ronan Le Bras",
      "Kyle Richardson",
      "Ashish Sabharwal",
      "Radha Poovendran",
      "Peter Clark",
      "Yejin Choi"
    ],
    "abstract": "We investigate the logical reasoning capabilities of large language models\n(LLMs) and their scalability in complex non-monotonic reasoning. To this end,\nwe introduce ZebraLogic, a comprehensive evaluation framework for assessing LLM\nreasoning performance on logic grid puzzles derived from constraint\nsatisfaction problems (CSPs). ZebraLogic enables the generation of puzzles with\ncontrollable and quantifiable complexity, facilitating a systematic study of\nthe scaling limits of models such as Llama, o1 models, and DeepSeek-R1. By\nencompassing a broad range of search space complexities and diverse logical\nconstraints, ZebraLogic provides a structured environment to evaluate reasoning\nunder increasing difficulty.\n  Our results reveal a significant decline in accuracy as problem complexity\ngrows -- a phenomenon we term the curse of complexity. This limitation persists\neven with larger models and increased inference-time computation, suggesting\ninherent constraints in current LLM reasoning capabilities. Additionally, we\nexplore strategies to enhance logical reasoning, including Best-of-N sampling,\nbacktracking mechanisms, and self-verification prompts. Our findings offer\ncritical insights into the scalability of LLM reasoning, highlight fundamental\nlimitations, and outline potential directions for improvement.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Website: https://huggingface.co/spaces/WildEval/ZebraLogic",
    "pdf_url": "http://arxiv.org/pdf/2502.01100v1",
    "published_date": "2025-02-03 06:44:49 UTC",
    "updated_date": "2025-02-03 06:44:49 UTC"
  },
  {
    "arxiv_id": "2502.04342v2",
    "title": "Tutorial on Using Machine Learning and Deep Learning Models for Mental Illness Detection",
    "authors": [
      "Yeyubei Zhang",
      "Zhongyan Wang",
      "Zhanyi Ding",
      "Yexin Tian",
      "Jianglai Dai",
      "Xiaorui Shen",
      "Yunchong Liu",
      "Yuchen Cao"
    ],
    "abstract": "Social media has become an important source for understanding mental health,\nproviding researchers with a way to detect conditions like depression from\nuser-generated posts. This tutorial provides practical guidance to address\ncommon challenges in applying machine learning and deep learning methods for\nmental health detection on these platforms. It focuses on strategies for\nworking with diverse datasets, improving text preprocessing, and addressing\nissues such as imbalanced data and model evaluation. Real-world examples and\nstep-by-step instructions demonstrate how to apply these techniques\neffectively, with an emphasis on transparency, reproducibility, and ethical\nconsiderations. By sharing these approaches, this tutorial aims to help\nresearchers build more reliable and widely applicable models for mental health\nresearch, contributing to better tools for early detection and intervention.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.04342v2",
    "published_date": "2025-02-03 06:43:12 UTC",
    "updated_date": "2025-03-04 05:13:07 UTC"
  },
  {
    "arxiv_id": "2502.01091v1",
    "title": "Enhancing Aspect-based Sentiment Analysis with ParsBERT in Persian Language",
    "authors": [
      "Farid Ariai",
      "Maryam Tayefeh Mahmoudi",
      "Ali Moeini"
    ],
    "abstract": "In the era of pervasive internet use and the dominance of social networks,\nresearchers face significant challenges in Persian text mining including the\nscarcity of adequate datasets in Persian and the inefficiency of existing\nlanguage models. This paper specifically tackles these challenges, aiming to\namplify the efficiency of language models tailored to the Persian language.\nFocusing on enhancing the effectiveness of sentiment analysis, our approach\nemploys an aspect-based methodology utilizing the ParsBERT model, augmented\nwith a relevant lexicon. The study centers on sentiment analysis of user\nopinions extracted from the Persian website 'Digikala.' The experimental\nresults not only highlight the proposed method's superior semantic capabilities\nbut also showcase its efficiency gains with an accuracy of 88.2% and an F1\nscore of 61.7. The importance of enhancing language models in this context lies\nin their pivotal role in extracting nuanced sentiments from user-generated\ncontent, ultimately advancing the field of sentiment analysis in Persian text\nmining by increasing efficiency and accuracy.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01091v1",
    "published_date": "2025-02-03 06:25:06 UTC",
    "updated_date": "2025-02-03 06:25:06 UTC"
  },
  {
    "arxiv_id": "2502.01090v1",
    "title": "Classic4Children: Adapting Chinese Literary Classics for Children with Large Language Model",
    "authors": [
      "Jiali Chen",
      "Xusen Hei",
      "Yuqi Xue",
      "Zihan Wu",
      "Jiayuan Xie",
      "Yi Cai"
    ],
    "abstract": "Chinese literary classics hold significant cultural and educational value,\noffering deep insights into morality, history, and human nature. These works\noften include classical Chinese and complex narratives, making them difficult\nfor children to read. To bridge this gap, we introduce a child-friendly\nliterary adaptation (CLA) task to adapt the Chinese literary classic into\nengaging and accessible text for children. However, recent large language\nmodels (LLMs) overlook children's reading preferences (\\ie, vivid character\nportrayals, concise narrative structures, and appropriate readability), which\nposes challenges in CLA. In this paper, we propose a method called\nInstructChild, which augments the LLM with these preferences for adaptation.\nSpecifically, we first obtain the characters' personalities and narrative\nstructure as additional information for fine-grained instruction tuning. Then,\nwe devise a readability metric as the reward to align the LLM with the\nchildren's reading level. Finally, a lookahead decoding strategy is applied to\nimprove the readability of the generated text during inference. To support the\nevaluation of CLA task, we construct the Classic4Children dataset, which\ncomprises both the original and child-friendly versions of the Four Great\nClassical Novels of Chinese literature. Experimental results show that our\nInstructChild significantly improves automatic and human evaluation\nperformance.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at NAACL 2025 Findings",
    "pdf_url": "http://arxiv.org/pdf/2502.01090v1",
    "published_date": "2025-02-03 06:23:35 UTC",
    "updated_date": "2025-02-03 06:23:35 UTC"
  },
  {
    "arxiv_id": "2502.01089v2",
    "title": "Advanced Architectures Integrated with Agentic AI for Next-Generation Wireless Networks",
    "authors": [
      "Kapal Dev",
      "Sunder Ali Khowaja",
      "Keshav Singh",
      "Engin Zeydan",
      "Merouane Debbah"
    ],
    "abstract": "This paper investigates a range of cutting-edge technologies and\narchitectural innovations aimed at simplifying network operations, reducing\noperational expenditure (OpEx), and enabling the deployment of new service\nmodels. The focus is on (i) Proposing novel, more efficient 6G architectures,\nwith both Control and User planes enabling the seamless expansion of services,\nwhile addressing long-term 6G network evolution. (ii) Exploring advanced\ntechniques for constrained artificial intelligence (AI) operations,\nparticularly the design of AI agents for real-time learning, optimizing energy\nconsumption, and the allocation of computational resources. (iii) Identifying\ntechnologies and architectures that support the orchestration of backend\nservices using serverless computing models across multiple domains,\nparticularly for vertical industries. (iv) Introducing optically-based,\nultra-high-speed, low-latency network architectures, with fast optical\nswitching and real-time control, replacing conventional electronic switching to\nreduce power consumption by an order of magnitude.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "6 Pages",
    "pdf_url": "http://arxiv.org/pdf/2502.01089v2",
    "published_date": "2025-02-03 06:18:29 UTC",
    "updated_date": "2025-04-15 15:24:26 UTC"
  },
  {
    "arxiv_id": "2502.01083v1",
    "title": "Tool Unlearning for Tool-Augmented LLMs",
    "authors": [
      "Jiali Cheng",
      "Hadi Amiri"
    ],
    "abstract": "Tool-augmented large language models (LLMs) are often trained on datasets of\nquery-response pairs, which embed the ability to use tools or APIs directly\ninto the parametric knowledge of LLMs. Tool-augmented LLMs need the ability to\nforget learned tools due to security vulnerabilities, privacy regulations, or\ntool deprecations. However, ``tool unlearning'' has not been investigated in\nunlearning literature. We introduce this novel task, which requires addressing\ndistinct challenges compared to traditional unlearning: knowledge removal\nrather than forgetting individual samples, the high cost of optimizing LLMs,\nand the need for principled evaluation metrics. To bridge these gaps, we\npropose ToolDelete, the first approach for unlearning tools from tool-augmented\nLLMs. It implements three key properties to address the above challenges for\neffective tool unlearning and introduces a new membership inference attack\n(MIA) model for effective evaluation. Extensive experiments on multiple tool\nlearning datasets and tool-augmented LLMs show that ToolDelete effectively\nunlearns randomly selected tools, while preserving the LLM's knowledge on\nnon-deleted tools and maintaining performance on general tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "https://clu-uml.github.io/MU-Bench-Project-Page/",
    "pdf_url": "http://arxiv.org/pdf/2502.01083v1",
    "published_date": "2025-02-03 05:50:55 UTC",
    "updated_date": "2025-02-03 05:50:55 UTC"
  },
  {
    "arxiv_id": "2502.01081v2",
    "title": "The Jumping Reasoning Curve? Tracking the Evolution of Reasoning Performance in GPT-[n] and o-[n] Models on Multimodal Puzzles",
    "authors": [
      "Vernon Y. H. Toh",
      "Yew Ken Chia",
      "Deepanway Ghosal",
      "Soujanya Poria"
    ],
    "abstract": "The releases of OpenAI's o-[n] series, such as o1, o3, and o4-mini, mark a\nsignificant paradigm shift in Large Language Models towards advanced reasoning\ncapabilities. Notably, models like o3 have demonstrated strong performance on\nbenchmarks like the Abstraction and Reasoning Corpus for Artificial General\nIntelligence (ARC-AGI). However, this benchmark is limited to symbolic\npatterns, whereas humans often perceive and reason about multimodal scenarios\ninvolving both vision and language data. Thus, there is an urgent need to\ninvestigate advanced reasoning capabilities in multimodal tasks. To this end,\nwe track the evolution of the GPT-[n] and o-[n] series models (including o1,\no3, and o4-mini) on challenging multimodal puzzles from PuzzleVQA and\nAlgoPuzzleVQA, which demand fine-grained visual perception. Our results reveal\nthat o-[n] series, particularly later iterations like o3 and o4-mini,\nsignificantly outperform the GPT-[n] series and show strong scalability in\nmultimodal reasoning. Nonetheless, despite these substantial advancements and\nthe superior capabilities demonstrated by the o-[n] series, our findings\nhighlight that even these leading models face persistent challenges.\nDifficulties are particularly evident in tasks requiring precise visual\nperception, robust compositional reasoning across multiple visual attributes,\nand solving complex algorithmic or highly combinatorial puzzles, indicating\ncritical areas for future AGI development. We plan to continuously track new\nmodels in the series and update our results in this paper accordingly. All\nresources used in this evaluation are openly available at\nhttps://github.com/declare-lab/LLM-PuzzleTest.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01081v2",
    "published_date": "2025-02-03 05:47:04 UTC",
    "updated_date": "2025-05-21 07:57:40 UTC"
  },
  {
    "arxiv_id": "2502.01060v1",
    "title": "Learning Nonlinearity of Boolean Functions: An Experimentation with Neural Networks",
    "authors": [
      "Sriram Ranga",
      "Nandish Chattopadhyay",
      "Anupam Chattopadhyay"
    ],
    "abstract": "This paper investigates the learnability of the nonlinearity property of\nBoolean functions using neural networks. We train encoder style deep neural\nnetworks to learn to predict the nonlinearity of Boolean functions from\nexamples of functions in the form of a truth table and their corresponding\nnonlinearity values. We report empirical results to show that deep neural\nnetworks are able to learn to predict the property for functions in 4 and 5\nvariables with an accuracy above 95%. While these results are positive and a\ndisciplined analysis is being presented for the first time in this regard, we\nshould also underline the statutory warning that it seems quite challenging to\nextend the idea to higher number of variables, and it is also not clear whether\none can get advantage in terms of time and space complexity over the existing\ncombinatorial algorithms.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "To be published in International conference on Artificial\n  Intelligence and Sustainable Computing, AISC 2024",
    "pdf_url": "http://arxiv.org/pdf/2502.01060v1",
    "published_date": "2025-02-03 05:10:25 UTC",
    "updated_date": "2025-02-03 05:10:25 UTC"
  },
  {
    "arxiv_id": "2502.01059v1",
    "title": "Knowledge Synthesis of Photosynthesis Research Using a Large Language Model",
    "authors": [
      "Seungri Yoon",
      "Woosang Jeon",
      "Sanghyeok Choi",
      "Taehyeong Kim",
      "Tae In Ahn"
    ],
    "abstract": "The development of biological data analysis tools and large language models\n(LLMs) has opened up new possibilities for utilizing AI in plant science\nresearch, with the potential to contribute significantly to knowledge\nintegration and research gap identification. Nonetheless, current LLMs struggle\nto handle complex biological data and theoretical models in photosynthesis\nresearch and often fail to provide accurate scientific contexts. Therefore,\nthis study proposed a photosynthesis research assistant (PRAG) based on\nOpenAI's GPT-4o with retrieval-augmented generation (RAG) techniques and prompt\noptimization. Vector databases and an automated feedback loop were used in the\nprompt optimization process to enhance the accuracy and relevance of the\nresponses to photosynthesis-related queries. PRAG showed an average improvement\nof 8.7% across five metrics related to scientific writing, with a 25.4%\nincrease in source transparency. Additionally, its scientific depth and domain\ncoverage were comparable to those of photosynthesis research papers. A\nknowledge graph was used to structure PRAG's responses with papers within and\noutside the database, which allowed PRAG to match key entities with 63% and\n39.5% of the database and test papers, respectively. PRAG can be applied for\nphotosynthesis research and broader plant science domains, paving the way for\nmore in-depth data analysis and predictive capabilities.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "17 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.01059v1",
    "published_date": "2025-02-03 05:10:19 UTC",
    "updated_date": "2025-02-03 05:10:19 UTC"
  },
  {
    "arxiv_id": "2502.01057v3",
    "title": "FetDTIAlign: A Deep Learning Framework for Affine and Deformable Registration of Fetal Brain dMRI",
    "authors": [
      "Bo Li",
      "Qi Zeng",
      "Simon K. Warfield",
      "Davood Karimi"
    ],
    "abstract": "Diffusion MRI (dMRI) provides unique insights into fetal brain microstructure\nin utero. Longitudinal and cross-sectional fetal dMRI studies can reveal\ncrucial neurodevelopmental changes but require precise spatial alignment across\nscans and subjects. This is challenging due to low data quality, rapid brain\ndevelopment, and limited anatomical landmarks. Existing registration methods,\ndesigned for high-quality adult data, struggle with these complexities. To\naddress this, we introduce FetDTIAlign, a deep learning approach for fetal\nbrain dMRI registration, enabling accurate affine and deformable alignment.\nFetDTIAlign features a dual-encoder architecture and iterative feature-based\ninference, reducing the impact of noise and low resolution. It optimizes\nnetwork configurations and domain-specific features at each registration stage,\nenhancing both robustness and accuracy. We validated FetDTIAlign on data from\n23 to 36 weeks gestation, covering 60 white matter tracts. It consistently\noutperformed two classical optimization-based methods and a deep learning\npipeline, achieving superior anatomical correspondence. Further validation on\nexternal data from the Developing Human Connectome Project confirmed its\ngeneralizability across acquisition protocols. Our results demonstrate the\nfeasibility of deep learning for fetal brain dMRI registration, providing a\nmore accurate and reliable alternative to classical techniques. By enabling\nprecise cross-subject and tract-specific analyses, FetDTIAlign supports new\ndiscoveries in early brain development.",
    "categories": [
      "eess.IV",
      "cs.AI"
    ],
    "primary_category": "eess.IV",
    "comment": "Under review. NeuroImage, 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.01057v3",
    "published_date": "2025-02-03 05:10:00 UTC",
    "updated_date": "2025-02-24 17:55:45 UTC"
  },
  {
    "arxiv_id": "2502.01048v1",
    "title": "Sparks of Explainability: Recent Advancements in Explaining Large Vision Models",
    "authors": [
      "Thomas Fel"
    ],
    "abstract": "This thesis explores advanced approaches to improve explainability in\ncomputer vision by analyzing and modeling the features exploited by deep neural\nnetworks. Initially, it evaluates attribution methods, notably saliency maps,\nby introducing a metric based on algorithmic stability and an approach\nutilizing Sobol indices, which, through quasi-Monte Carlo sequences, allows a\nsignificant reduction in computation time. In addition, the EVA method offers a\nfirst formulation of attribution with formal guarantees via verified\nperturbation analysis.\n  Experimental results indicate that in complex scenarios these methods do not\nprovide sufficient understanding, particularly because they identify only\n\"where\" the model focuses without clarifying \"what\" it perceives. Two\nhypotheses are therefore examined: aligning models with human reasoning --\nthrough the introduction of a training routine that integrates the imitation of\nhuman explanations and optimization within the space of 1-Lipschitz functions\n-- and adopting a conceptual explainability approach.\n  The CRAFT method is proposed to automate the extraction of the concepts used\nby the model and to assess their importance, complemented by MACO, which\nenables their visualization. These works converge towards a unified framework,\nillustrated by an interactive demonstration applied to the 1000 ImageNet\nclasses in a ResNet model.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Doctoral thesis",
    "pdf_url": "http://arxiv.org/pdf/2502.01048v1",
    "published_date": "2025-02-03 04:49:32 UTC",
    "updated_date": "2025-02-03 04:49:32 UTC"
  },
  {
    "arxiv_id": "2502.01036v1",
    "title": "eagle: early approximated gradient based learning rate estimator",
    "authors": [
      "Takumi Fujimoto",
      "Hiroaki Nishi"
    ],
    "abstract": "We propose EAGLE update rule, a novel optimization method that accelerates\nloss convergence during the early stages of training by leveraging both current\nand previous step parameter and gradient values. The update algorithm estimates\noptimal parameters by computing the changes in parameters and gradients between\nconsecutive training steps and leveraging the local curvature of the loss\nlandscape derived from these changes. However, this update rule has potential\ninstability, and to address that, we introduce an adaptive switching mechanism\nthat dynamically selects between Adam and EAGLE update rules to enhance\ntraining stability. Experiments on standard benchmark datasets demonstrate that\nEAGLE optimizer, which combines this novel update rule with the switching\nmechanism achieves rapid training loss convergence with fewer epochs, compared\nto conventional optimization methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "43pages, 24figures",
    "pdf_url": "http://arxiv.org/pdf/2502.01036v1",
    "published_date": "2025-02-03 04:15:34 UTC",
    "updated_date": "2025-02-03 04:15:34 UTC"
  },
  {
    "arxiv_id": "2502.01029v1",
    "title": "Comprehensive Modeling Approaches for Forecasting Bitcoin Transaction Fees: A Comparative Study",
    "authors": [
      "Jiangqin Ma",
      "Erfan Mahmoudinia"
    ],
    "abstract": "Transaction fee prediction in Bitcoin's ecosystem represents a crucial\nchallenge affecting both user costs and miner revenue optimization. This study\npresents a systematic evaluation of six predictive models for forecasting\nBitcoin transaction fees across a 24-hour horizon (144 blocks): SARIMAX,\nProphet, Time2Vec, Time2Vec with Attention, a Hybrid model combining SARIMAX\nwith Gradient Boosting, and the Temporal Fusion Transformer (TFT). Our approach\nintegrates comprehensive feature engineering spanning mempool metrics, network\nparameters, and historical fee patterns to capture the multifaceted dynamics of\nfee behavior.\n  Through rigorous 5-fold cross-validation and independent testing, our\nanalysis reveals that traditional statistical approaches outperform more\ncomplex deep learning architectures. The SARIMAX model achieves superior\naccuracy on the independent test set, while Prophet demonstrates strong\nperformance during cross-validation. Notably, sophisticated deep learning\nmodels like Time2Vec and TFT show comparatively lower predictive power despite\ntheir architectural complexity. This performance disparity likely stems from\nthe relatively constrained training dataset of 91 days, suggesting that deep\nlearning models may achieve enhanced results with extended historical data.\n  These findings offer significant practical implications for cryptocurrency\nstakeholders, providing empirically-validated guidance for fee-sensitive\ndecision making while illuminating critical considerations in model selection\nbased on data constraints. The study establishes a foundation for advanced fee\nprediction while highlighting the current advantages of traditional statistical\nmethods in this domain.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01029v1",
    "published_date": "2025-02-03 03:52:07 UTC",
    "updated_date": "2025-02-03 03:52:07 UTC"
  },
  {
    "arxiv_id": "2502.01014v1",
    "title": "Refining Adaptive Zeroth-Order Optimization at Ease",
    "authors": [
      "Yao Shu",
      "Qixin Zhang",
      "Kun He",
      "Zhongxiang Dai"
    ],
    "abstract": "Recently, zeroth-order (ZO) optimization plays an essential role in scenarios\nwhere gradient information is inaccessible or unaffordable, such as black-box\nsystems and resource-constrained environments. While existing adaptive methods\nsuch as ZO-AdaMM have shown promise, they are fundamentally limited by their\nunderutilization of moment information during optimization, usually resulting\nin underperforming convergence. To overcome these limitations, this paper\nintroduces Refined Adaptive Zeroth-Order Optimization (R-AdaZO). Specifically,\nwe first show the untapped variance reduction effect of first moment estimate\non ZO gradient estimation, which improves the accuracy and stability of ZO\nupdates. We then refine the second moment estimate based on these\nvariance-reduced gradient estimates to better capture the geometry of the\noptimization landscape, enabling a more effective scaling of ZO updates. We\npresent rigorous theoretical analysis to show (I) the first analysis to the\nvariance reduction of first moment estimate in ZO optimization, (II) the\nimproved second moment estimates with a more accurate approximation of its\nvariance-free ideal, (III) the first variance-aware convergence framework for\nadaptive ZO methods, which may be of independent interest, and (IV) the faster\nconvergence of R-AdaZO than existing baselines like ZO-AdaMM. Our extensive\nexperiments, including synthetic problems, black-box adversarial attack, and\nmemory-efficient fine-tuning of large language models (LLMs), further verify\nthe superior convergence of R-AdaZO, indicating that R-AdaZO offers an improved\nsolution for real-world ZO optimization challenges.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01014v1",
    "published_date": "2025-02-03 03:10:44 UTC",
    "updated_date": "2025-02-03 03:10:44 UTC"
  },
  {
    "arxiv_id": "2502.01013v1",
    "title": "Encrypted Large Model Inference: The Equivariant Encryption Paradigm",
    "authors": [
      "James Buban",
      "Hongyang Zhang",
      "Claudio Angione",
      "Harry Yang",
      "Ahmad Farhan",
      "Seyfal Sultanov",
      "Michael Du",
      "Xuran Ma",
      "Zihao Wang",
      "Yue Zhao",
      "Arria Owlia",
      "Fielding Johnston",
      "Patrick Colangelo"
    ],
    "abstract": "Large scale deep learning model, such as modern language models and diffusion\narchitectures, have revolutionized applications ranging from natural language\nprocessing to computer vision. However, their deployment in distributed or\ndecentralized environments raises significant privacy concerns, as sensitive\ndata may be exposed during inference. Traditional techniques like secure\nmulti-party computation, homomorphic encryption, and differential privacy offer\npartial remedies but often incur substantial computational overhead, latency\npenalties, or limited compatibility with non-linear network operations. In this\nwork, we introduce Equivariant Encryption (EE), a novel paradigm designed to\nenable secure, \"blind\" inference on encrypted data with near zero performance\noverhead. Unlike fully homomorphic approaches that encrypt the entire\ncomputational graph, EE selectively obfuscates critical internal\nrepresentations within neural network layers while preserving the exact\nfunctionality of both linear and a prescribed set of non-linear operations.\nThis targeted encryption ensures that raw inputs, intermediate activations, and\noutputs remain confidential, even when processed on untrusted infrastructure.\nWe detail the theoretical foundations of EE, compare its performance and\nintegration complexity against conventional privacy preserving techniques, and\ndemonstrate its applicability across a range of architectures, from\nconvolutional networks to large language models. Furthermore, our work provides\na comprehensive threat analysis, outlining potential attack vectors and\nbaseline strategies, and benchmarks EE against standard inference pipelines in\ndecentralized settings. The results confirm that EE maintains high fidelity and\nthroughput, effectively bridging the gap between robust data confidentiality\nand the stringent efficiency requirements of modern, large scale model\ninference.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01013v1",
    "published_date": "2025-02-03 03:05:20 UTC",
    "updated_date": "2025-02-03 03:05:20 UTC"
  },
  {
    "arxiv_id": "2502.00997v3",
    "title": "MergeME: Model Merging Techniques for Homogeneous and Heterogeneous MoEs",
    "authors": [
      "Yuhang Zhou",
      "Giannis Karamanolakis",
      "Victor Soto",
      "Anna Rumshisky",
      "Mayank Kulkarni",
      "Furong Huang",
      "Wei Ai",
      "Jianhua Lu"
    ],
    "abstract": "The recent success of specialized Large Language Models (LLMs) in domains\nsuch as mathematical reasoning and coding has led to growing interest in\nmethods for merging these expert LLMs into a unified Mixture-of-Experts (MoE)\nmodel, with the goal of enhancing performance in each domain while retaining\neffectiveness on general tasks. However, the effective merging of expert models\nremains an open challenge, especially for models with highly divergent weight\nparameters or different architectures. State-of-the-art MoE merging methods\nonly work with homogeneous model architectures and rely on simple unweighted\naveraging to merge expert layers, which does not address parameter interference\nand requires extensive fine-tuning of the merged MoE to restore performance. To\naddress these limitations, this paper introduces new MoE merging techniques,\nincluding strategies to mitigate parameter interference, routing heuristics to\nreduce the need for MoE fine-tuning, and a novel method for merging experts\nwith different architectures. Extensive experiments across multiple domains\ndemonstrate the effectiveness of our proposed methods, reducing fine-tuning\ncosts, improving performance over state-of-the-art methods, and expanding the\napplicability of MoE merging.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by NAACL 2025 Main",
    "pdf_url": "http://arxiv.org/pdf/2502.00997v3",
    "published_date": "2025-02-03 02:34:46 UTC",
    "updated_date": "2025-02-17 16:51:23 UTC"
  },
  {
    "arxiv_id": "2502.17447v1",
    "title": "AirTag, You're It: Reverse Logistics and Last Mile Dynamics",
    "authors": [
      "David Noever",
      "Forrest McKee"
    ],
    "abstract": "This study addresses challenges in reverse logistics, a frequently overlooked\nbut essential component of last-mile delivery, particularly in disaster relief\nscenarios where infrastructure disruptions demand adaptive solutions. While\nhub-and-spoke logistics networks excel at long-distance scalability, they often\nfail to optimize closely spaced spokes reliant on distant hubs, introducing\ninefficiencies in transit times and resource allocation. Using 20 Apple AirTags\nembedded in packages, this research provides empirical insights into logistical\nflows, capturing granular spatial and temporal data through Bluetooth LE (BLE)\n5 trackers integrated with the Apple Find My network. These trackers\ndemonstrated their value in monitoring dynamic cargo movements, enabling\nreal-time adjustments in mobile hub placement and route optimization,\nparticularly in disaster relief contexts like Hurricane Helene. A novel\napplication of discrete event simulation (DES) further explored the saddle\npoint in hub-spoke configurations, where excessive hub reliance clashes with\ndiminishing spoke interaction demand. By coupling simulation results with\nempirical AirTag tracking, the study highlights the potential of BLE technology\nto refine reverse logistics, reduce delays, and improve operational flexibility\nin both routine and crisis-driven delivery networks.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.17447v1",
    "published_date": "2025-02-03 02:21:23 UTC",
    "updated_date": "2025-02-03 02:21:23 UTC"
  },
  {
    "arxiv_id": "2502.00989v1",
    "title": "ChartCitor: Multi-Agent Framework for Fine-Grained Chart Visual Attribution",
    "authors": [
      "Kanika Goswami",
      "Puneet Mathur",
      "Ryan Rossi",
      "Franck Dernoncourt"
    ],
    "abstract": "Large Language Models (LLMs) can perform chart question-answering tasks but\noften generate unverified hallucinated responses. Existing answer attribution\nmethods struggle to ground responses in source charts due to limited\nvisual-semantic context, complex visual-text alignment requirements, and\ndifficulties in bounding box prediction across complex layouts. We present\nChartCitor, a multi-agent framework that provides fine-grained bounding box\ncitations by identifying supporting evidence within chart images. The system\norchestrates LLM agents to perform chart-to-table extraction, answer\nreformulation, table augmentation, evidence retrieval through pre-filtering and\nre-ranking, and table-to-chart mapping. ChartCitor outperforms existing\nbaselines across different chart types. Qualitative user studies show that\nChartCitor helps increase user trust in Generative AI by providing enhanced\nexplainability for LLM-assisted chart QA and enables professionals to be more\nproductive.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.00989v1",
    "published_date": "2025-02-03 02:00:51 UTC",
    "updated_date": "2025-02-03 02:00:51 UTC"
  },
  {
    "arxiv_id": "2502.00988v1",
    "title": "PlotGen: Multi-Agent LLM-based Scientific Data Visualization via Multimodal Feedback",
    "authors": [
      "Kanika Goswami",
      "Puneet Mathur",
      "Ryan Rossi",
      "Franck Dernoncourt"
    ],
    "abstract": "Scientific data visualization is pivotal for transforming raw data into\ncomprehensible visual representations, enabling pattern recognition,\nforecasting, and the presentation of data-driven insights. However, novice\nusers often face difficulties due to the complexity of selecting appropriate\ntools and mastering visualization techniques. Large Language Models (LLMs) have\nrecently demonstrated potential in assisting code generation, though they\nstruggle with accuracy and require iterative debugging. In this paper, we\npropose PlotGen, a novel multi-agent framework aimed at automating the creation\nof precise scientific visualizations. PlotGen orchestrates multiple LLM-based\nagents, including a Query Planning Agent that breaks down complex user requests\ninto executable steps, a Code Generation Agent that converts pseudocode into\nexecutable Python code, and three retrieval feedback agents - a Numeric\nFeedback Agent, a Lexical Feedback Agent, and a Visual Feedback Agent - that\nleverage multimodal LLMs to iteratively refine the data accuracy, textual\nlabels, and visual correctness of generated plots via self-reflection.\nExtensive experiments show that PlotGen outperforms strong baselines, achieving\na 4-6 percent improvement on the MatPlotBench dataset, leading to enhanced user\ntrust in LLM-generated visualizations and improved novice productivity due to a\nreduction in debugging time needed for plot errors.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.00988v1",
    "published_date": "2025-02-03 02:00:29 UTC",
    "updated_date": "2025-02-03 02:00:29 UTC"
  },
  {
    "arxiv_id": "2502.00987v2",
    "title": "RandLoRA: Full-rank parameter-efficient fine-tuning of large models",
    "authors": [
      "Paul Albert",
      "Frederic Z. Zhang",
      "Hemanth Saratchandran",
      "Cristian Rodriguez-Opazo",
      "Anton van den Hengel",
      "Ehsan Abbasnejad"
    ],
    "abstract": "Low-Rank Adaptation (LoRA) and its variants have shown impressive results in\nreducing the number of trainable parameters and memory requirements of large\ntransformer networks while maintaining fine-tuning performance. The low-rank\nnature of the weight update inherently limits the representation power of\nfine-tuned models, however, thus potentially compromising performance on\ncomplex tasks. This raises a critical question: when a performance gap between\nLoRA and standard fine-tuning is observed, is it due to the reduced number of\ntrainable parameters or the rank deficiency? This paper aims to answer this\nquestion by introducing RandLoRA, a parameter-efficient method that performs\nfull-rank updates using a learned linear combinations of low-rank,\nnon-trainable random matrices. Our method limits the number of trainable\nparameters by restricting optimization to diagonal scaling matrices applied to\nthe fixed random matrices. This allows us to effectively overcome the low-rank\nlimitations while maintaining parameter and memory efficiency during training.\nThrough extensive experimentation across vision, language, and vision-language\nbenchmarks, we systematically evaluate the limitations of LoRA and existing\nrandom basis methods. Our findings reveal that full-rank updates are beneficial\nacross vision and language tasks individually, and even more so for\nvision-language tasks, where RandLoRA significantly reduces -- and sometimes\neliminates -- the performance gap between standard fine-tuning and LoRA,\ndemonstrating its efficacy.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CL",
    "comment": "To appear at the International Conference on Learning Representations\n  (ICLR) 2025",
    "pdf_url": "http://arxiv.org/pdf/2502.00987v2",
    "published_date": "2025-02-03 01:59:45 UTC",
    "updated_date": "2025-03-12 00:43:45 UTC"
  },
  {
    "arxiv_id": "2502.02610v1",
    "title": "Secure & Personalized Music-to-Video Generation via CHARCHA",
    "authors": [
      "Mehul Agarwal",
      "Gauri Agarwal",
      "Santiago Benoit",
      "Andrew Lippman",
      "Jean Oh"
    ],
    "abstract": "Music is a deeply personal experience and our aim is to enhance this with a\nfully-automated pipeline for personalized music video generation. Our work\nallows listeners to not just be consumers but co-creators in the music video\ngeneration process by creating personalized, consistent and context-driven\nvisuals based on lyrics, rhythm and emotion in the music. The pipeline combines\nmultimodal translation and generation techniques and utilizes low-rank\nadaptation on listeners' images to create immersive music videos that reflect\nboth the music and the individual. To ensure the ethical use of users'\nidentity, we also introduce CHARCHA (patent pending), a facial identity\nverification protocol that protects people against unauthorized use of their\nface while at the same time collecting authorized images from users for\npersonalizing their videos. This paper thus provides a secure and innovative\nframework for creating deeply personalized music videos.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.HC",
      "cs.MM"
    ],
    "primary_category": "cs.AI",
    "comment": "NeurIPS 2024 Creative AI Track",
    "pdf_url": "http://arxiv.org/pdf/2502.02610v1",
    "published_date": "2025-02-03 01:25:47 UTC",
    "updated_date": "2025-02-03 01:25:47 UTC"
  },
  {
    "arxiv_id": "2502.00980v1",
    "title": "Forecasting VIX using interpretable Kolmogorov-Arnold networks",
    "authors": [
      "So-Yoon Cho",
      "Sungchul Lee",
      "Hyun-Gyoon Kim"
    ],
    "abstract": "This paper presents the use of Kolmogorov-Arnold Networks (KANs) for\nforecasting the CBOE Volatility Index (VIX). Unlike traditional MLP-based\nneural networks that are often criticized for their black-box nature, KAN\noffers an interpretable approach via learnable spline-based activation\nfunctions and symbolification. Based on a parsimonious architecture with\nsymbolic functions, KAN expresses a forecast of the VIX as a closed-form in\nterms of explanatory variables, and provide interpretable insights into key\ncharacteristics of the VIX, including mean reversion and the leverage effect.\nThrough in-depth empirical analysis across multiple datasets and periods, we\nshow that KANs achieve competitive forecasting performance while requiring\nsignificantly fewer parameters compared to MLP-based neural network models. Our\nfindings demonstrate the capacity and potential of KAN as an interpretable\nfinancial time-series forecasting method.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.00980v1",
    "published_date": "2025-02-03 01:24:02 UTC",
    "updated_date": "2025-02-03 01:24:02 UTC"
  },
  {
    "arxiv_id": "2502.01697v3",
    "title": "BARE: Leveraging Base Language Models for Few-Shot Synthetic Data Generation",
    "authors": [
      "Alan Zhu",
      "Parth Asawa",
      "Jared Quincy Davis",
      "Lingjiao Chen",
      "Boris Hanin",
      "Ion Stoica",
      "Joseph E. Gonzalez",
      "Matei Zaharia"
    ],
    "abstract": "As the demand for high-quality data in model training grows, researchers and\ndevelopers are increasingly generating synthetic data to tune and train LLMs.\nHowever, current data generation methods rely on seed sets containing tens of\nthousands of examples to prompt instruction-tuned models. This reliance can be\nespecially problematic when the curation of high-quality examples is expensive\nor difficult. In this paper we explore the novel few-shot synthetic data\ngeneration setting -- generating a high-quality dataset from a few examples. We\nshow that when working with only a few seed examples, instruction-tuned models\nused in current synthetic data methods produce insufficient diversity for\ndownstream tasks. In contrast, we show that base models without post-training,\nlargely untapped for synthetic data generation, offer substantially greater\noutput diversity, albeit with lower instruction following abilities. Leveraging\nthis insight, we propose Base-Refine (BARE), a novel two-stage method that\ncombines the diversity of base models with the quality assurance of\ninstruction-tuned models. BARE excels in few-shot synthetic data generation:\nusing only 3 seed examples it generates diverse, high-quality datasets that\nsignificantly improve downstream task performance. We show that fine-tuning\nLlama 3.1 8B with 1,000 BARE-generated samples achieves performance comparable\nto state-of-the-art similarly sized models on LiveCodeBench tasks. Furthermore,\ndata generated with BARE enables a 101% improvement for a fine-tuned Llama 3.2\n1B on GSM8K over data generated by only instruction-models, and an 18.4%\nimprovement for a fine-tuned Llama 3.1 8B over the state-of-the-art RAFT method\nfor RAG data generation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.01697v3",
    "published_date": "2025-02-03 00:12:40 UTC",
    "updated_date": "2025-05-21 17:50:43 UTC"
  },
  {
    "arxiv_id": "2502.14874v2",
    "title": "Is Mathematics Obsolete?",
    "authors": [
      "Jeremy Avigad"
    ],
    "abstract": "This is an essay about the value of mathematical and symbolic reasoning in\nthe age of AI.",
    "categories": [
      "math.HO",
      "cs.AI"
    ],
    "primary_category": "math.HO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.14874v2",
    "published_date": "2025-02-03 00:10:44 UTC",
    "updated_date": "2025-02-27 02:23:11 UTC"
  },
  {
    "arxiv_id": "2502.00964v3",
    "title": "ML-Dev-Bench: Comparative Analysis of AI Agents on ML development workflows",
    "authors": [
      "Harshith Padigela",
      "Chintan Shah",
      "Dinkar Juyal"
    ],
    "abstract": "In this report, we present ML-Dev-Bench, a benchmark aimed at testing agentic\ncapabilities on applied Machine Learning development tasks. While existing\nbenchmarks focus on isolated coding tasks or Kaggle-style competitions,\nML-Dev-Bench tests agents' ability to handle the full complexity of ML\ndevelopment workflows. The benchmark assesses performance across critical\naspects including dataset handling, model training, improving existing models,\ndebugging, and API integration with popular ML tools. We evaluate three agents\n- ReAct, Openhands, and AIDE - on a diverse set of 30 tasks, providing insights\ninto their strengths and limitations in handling practical ML development\nchallenges. We open source the benchmark for the benefit of the community at\n\\href{https://github.com/ml-dev-bench/ml-dev-bench}{https://github.com/ml-dev-bench/ml-dev-bench}.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.00964v3",
    "published_date": "2025-02-03 00:04:49 UTC",
    "updated_date": "2025-02-19 05:09:01 UTC"
  }
]