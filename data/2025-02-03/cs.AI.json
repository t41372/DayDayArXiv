{
  "date": "2025-02-03",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-02-03 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 159 篇论文，主要聚焦于 AI 代理、LLM 优化、强化学习和视觉生成等领域，亮点包括 OpenAI 等知名学者在推理模型上的创新，以及 LLM 在医疗和安全方面的应用，强调了高效计算和鲁棒性的改进。\n\n今天的论文覆盖了机器学习、AI 安全和应用创新等主题。其中最令人印象深刻的是 OpenAI 团队的论文，展示了大规模推理模型在编程和数学任务上的突破；此外，LLM 安全和医疗应用的论文（如脑功能分析和药物预测）也值得关注，因为它们解决了实际问题，如隐私保护和鲁棒性。以下我挑选了 10 篇关键论文进行详细讨论，先从高影响力主题入手（如 LLM 推理和安全），再快速掠过其他相关或次要论文。\n\n### 关键论文讨论\n\n1. **Competitive Programming with Large Reasoning Models**（竞争编程中的大型推理模型）  \n   作者包括 OpenAI 团队（如 Jakub Pachocki 和 Lukasz Kaiser）。这篇论文的主要贡献是展示强化学习应用于 LLM，能显著提升复杂编码和推理任务的性能。作者比较了通用模型（如 o3）和特定模型（如 o1-ioi），发现 o3 在无需手动策略的情况下即可达到顶级性能（如在 IOI 竞赛中获金牌），这为 AI 在编程领域的扩展提供了新见解。\n\n2. **Self-Improving Transformers Overcome Easy-to-Hard and Length Generalization Challenges**（自提升 Transformer 克服简单到复杂和长度泛化挑战）  \n   作者如 Nayoung Lee 和 Dimitris Papailiopoulos。论文提出自提升框架，让 Transformer 通过迭代生成和学习数据，处理超出训练分布的复杂任务。关键发现是模型能零样本泛化到更难问题（如 100 位加法），并在实验中超越传统方法，强调了持续学习的潜力。\n\n3. **Learning Fused State Representations for Control from Multi-View Observations**（从多视图观察学习融合状态表示用于控制）  \n   作者包括 Zi Wang 和 Yuke Zhu。论文创新性地使用多视图强化学习，融合视觉数据生成任务相关表示。主要发现是新方法在机器人控制任务中提升了鲁棒性，即使在干扰或缺失视图下也能保持高性能，适用于复杂环境决策。\n\n4. **A Privacy-Preserving Domain Adversarial Federated Learning for Multi-Site Brain Functional Connectivity Analysis**（隐私保护的域对抗联邦学习用于多站点脑功能连接分析）  \n   作者如 Vince D. Calhoun 和 Hongwen Deng。论文提出 DAFed 框架，用于处理非独立同分布的 fMRI 数据，通过特征分离和对比学习实现隐私保护。主要贡献是提升了多站点神经影像诊断准确性（如 ASD 分类），并发现关键脑区模式，适用于医疗 AI。\n\n5. **Displacement-Sparse Neural Optimal Transport**（位移稀疏神经最优传输）  \n   作者如 Peter Chen 和 Yue Xie。论文引入稀疏映射方法优化神经 OT 求解器，显著提高了高维生物应用（如药物扰动）的解释性和效率。关键发现是新正则化器和自适应框架提升了准确性，适用于复杂数据传输问题。\n\n6. **Modular and Integrated AI Control Framework Across Fiber and Wireless Networks for 6G**（模块化和集成 AI 控制框架用于 6G 光纤和无线网络）  \n   作者如 Marco Ruffini 和 Daniel Kilper。论文设计了灵活的 AI 控制框架，扩展 O-RAN 原理到光网络，实现智能自动化。主要发现是统一框架提升了 6G 网络的可扩展性，强调了 AI 在通信领域的实际应用。\n\n7. **Decoding FL Defenses: Systemization, Pitfalls, and Remedies**（解码联邦学习防御：系统化、陷阱和补救）  \n   作者如 Amir Houmansadr。论文系统分析了联邦学习防御的缺陷，如实验设置问题，并提供改进建议。贡献在于识别 30% 防御依赖简单数据集，提出可操作指南，提升了 FL 的鲁棒性。\n\n8. **VidSketch: Hand-drawn Sketch-Driven Video Generation with Diffusion Control**（手绘草图驱动的视频生成使用扩散控制）  \n   作者如 Lifan Jiang。论文首次实现从手绘草图生成高质量视频，引入层级控制策略和注意力机制。主要发现是生成视频更一致且高效，适用于创意设计。\n\n9. **Agentic Bug Reproduction for Effective Automated Program Repair at Google**（代理式错误重现用于谷歌的自动化程序修复）  \n   作者如 Satish Chandra。论文开发 BRT Agent，使用 LLM 生成可重现测试，提高程序修复效率。关键发现是结合测试生成提升修复率 30%，适用于工业级代码维护。\n\n10. **Towards Safer Chatbots: A Framework for Policy Compliance Evaluation of Custom GPTs**（面向更安全的聊天机器人：自定义 GPT 的政策合规评估框架）  \n   作者如 Jose Such。论文提出框架评估自定义 GPT 的政策合规性，通过红队测试和 LLM 判断。主要贡献是检测 58.7% 模型违规，提供可扩展方法，提升 AI 安全性。\n\n其他论文中，有一些次要但相关的工作，如强化学习优化（如 Online Curvature-Aware Replay）和图像生成（如 Texture Image Synthesis），它们提供了方法改进但影响力较小，我这里快速掠过：例如，**Online Curvature-Aware Replay**（在线曲率感知重放）使用二阶信息提升连续学习稳定性；**Texture Image Synthesis Using Spatial GAN Based on Vision Transformers**（基于视觉 Transformer 的纹理图像合成）改进了 GAN 生成质量。这些论文的核心在于算法效率，但未见重大突破，故不展开。\n\n总之，今天的 arXiv 更新突显了 AI 在推理、安全和应用领域的进展，OpenAI 等团队的贡献尤其值得关注。如果你对 LLM 优化或医疗 AI 感兴趣，这些论文是绝佳起点！（约 1200 字）",
  "papers": [
    {
      "arxiv_id": "2502.01889v2",
      "title": "Displacement-Sparse Neural Optimal Transport",
      "title_zh": "位移稀疏神经最优传输",
      "authors": [
        "Peter Chen",
        "Yue Xie",
        "Qingpeng Zhang"
      ],
      "abstract": "Optimal transport (OT) aims to find a map $T$ that transports mass from one\nprobability measure to another while minimizing a cost function. Recently,\nneural OT solvers have gained popularity in high dimensional biological\napplications such as drug perturbation, due to their superior computational and\nmemory efficiency compared to traditional exact Sinkhorn solvers. However, the\noverly complex high dimensional maps learned by neural OT solvers often suffer\nfrom poor interpretability. Prior work addressed this issue in the context of\nexact OT solvers by introducing \\emph{displacement-sparse maps} via designed\nelastic cost, but such method failed to be applied to neural OT settings. In\nthis work, we propose an intuitive and theoretically grounded approach to\nlearning \\emph{displacement-sparse maps} within neural OT solvers. Building on\nour new formulation, we introduce a novel smoothed $\\ell_0$ regularizer that\noutperforms the $\\ell_1$ based alternative from prior work. Leveraging Input\nConvex Neural Network's flexibility, we further develop a heuristic framework\nfor adaptively controlling sparsity intensity, an approach uniquely enabled by\nthe neural OT paradigm. We demonstrate the necessity of this adaptive framework\nin large-scale, high-dimensional training, showing not only improved accuracy\nbut also practical ease of use for downstream applications.",
      "tldr_zh": "本研究针对Optimal Transport (OT) 的神经求解器在高维生物应用（如药物扰动）中计算效率高但解释性差的问题，提出了一种学习displacement-sparse maps 的新方法。该方法基于新的理论框架，引入smoothed $\\ell_0$ regularizer 以替代传统的$\\ell_1$ based 方法，并利用Input Convex Neural Network (ICNN) 的灵活性开发自适应稀疏控制框架，以动态调整稀疏度。实验结果显示，该方法在大规模高维训练中显著提升准确性，并简化了下游应用的实用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "23 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.01889v2",
      "published_date": "2025-02-03 23:44:17 UTC",
      "updated_date": "2025-05-17 03:07:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:05:13.509607"
    },
    {
      "arxiv_id": "2502.01885v1",
      "title": "A Privacy-Preserving Domain Adversarial Federated learning for multi-site brain functional connectivity analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Yipu Zhang",
        "Likai Wang",
        "Kuan-Jui Su",
        "Aiying Zhang",
        "Hao Zhu",
        "Xiaowen Liu",
        "Hui Shen",
        "Vince D. Calhoun",
        "Yuping Wang",
        "Hongwen Deng"
      ],
      "abstract": "Resting-state functional magnetic resonance imaging (rs-fMRI) and its derived\nfunctional connectivity networks (FCNs) have become critical for understanding\nneurological disorders. However, collaborative analyses and the\ngeneralizability of models still face significant challenges due to privacy\nregulations and the non-IID (non-independent and identically distributed)\nproperty of multiple data sources. To mitigate these difficulties, we propose\nDomain Adversarial Federated Learning (DAFed), a novel federated deep learning\nframework specifically designed for non-IID fMRI data analysis in multi-site\nsettings. DAFed addresses these challenges through feature disentanglement,\ndecomposing the latent feature space into domain-invariant and domain-specific\ncomponents, to ensure robust global learning while preserving local data\nspecificity. Furthermore, adversarial training facilitates effective knowledge\ntransfer between labeled and unlabeled datasets, while a contrastive learning\nmodule enhances the global representation of domain-invariant features. We\nevaluated DAFed on the diagnosis of ASD and further validated its\ngeneralizability in the classification of AD, demonstrating its superior\nclassification accuracy compared to state-of-the-art methods. Additionally, an\nenhanced Score-CAM module identifies key brain regions and functional\nconnectivity significantly associated with ASD and MCI, respectively,\nuncovering shared neurobiological patterns across sites. These findings\nhighlight the potential of DAFed to advance multi-site collaborative research\nin neuroimaging while protecting data confidentiality.",
      "tldr_zh": "本研究提出了一种隐私保护的领域对抗联邦学习框架（DAFed），旨在解决多站点非-IID（non-IID）fMRI数据分析中的隐私法规和数据异质性挑战。该框架通过特征分离将潜在特征空间分解为领域无关和领域特定组件，并结合对抗训练和对比学习模块，实现高效的知识转移和全局表示增强。在ASD诊断和AD分类任务上，DAFed比现有最先进方法表现出更高的分类准确率，并利用增强的Score-CAM模块识别与ASD和MCI相关的关键脑区和功能连接。该方法为保护数据隐私的同时推进多站点神经影像协作研究提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.LG",
      "comment": "34pages, 13 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.01885v1",
      "published_date": "2025-02-03 23:26:07 UTC",
      "updated_date": "2025-02-03 23:26:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:05:25.344674"
    },
    {
      "arxiv_id": "2502.05211v1",
      "title": "Decoding FL Defenses: Systemization, Pitfalls, and Remedies",
      "title_zh": "翻译失败",
      "authors": [
        "Momin Ahmad Khan",
        "Virat Shejwalkar",
        "Yasra Chandio",
        "Amir Houmansadr",
        "Fatima Muhammad Anwar"
      ],
      "abstract": "While the community has designed various defenses to counter the threat of\npoisoning attacks in Federated Learning (FL), there are no guidelines for\nevaluating these defenses. These defenses are prone to subtle pitfalls in their\nexperimental setups that lead to a false sense of security, rendering them\nunsuitable for practical deployment. In this paper, we systematically\nunderstand, identify, and provide a better approach to address these\nchallenges. First, we design a comprehensive systemization of FL defenses along\nthree dimensions: i) how client updates are processed, ii) what the server\nknows, and iii) at what stage the defense is applied. Next, we thoroughly\nsurvey 50 top-tier defense papers and identify the commonly used components in\ntheir evaluation setups. Based on this survey, we uncover six distinct pitfalls\nand study their prevalence. For example, we discover that around 30% of these\nworks solely use the intrinsically robust MNIST dataset, and 40% employ\nsimplistic attacks, which may inadvertently portray their defense as robust.\nUsing three representative defenses as case studies, we perform a critical\nreevaluation to study the impact of the identified pitfalls and show how they\nlead to incorrect conclusions about robustness. We provide actionable\nrecommendations to help researchers overcome each pitfall.",
      "tldr_zh": "该论文系统化分析了Federated Learning (FL)防御机制，揭示了现有防御在评估中存在的细微缺陷，可能导致虚假的安全感和实际部署问题。通过设计一个基于三个维度的框架（客户端更新处理方式、服务器知识和防御应用阶段），并调查50篇顶级防御论文，作者识别出六个常见pitfalls，例如30%的论文仅使用内在鲁棒的MNIST数据集，以及40%采用简单攻击，从而夸大防御效果。针对三个代表性防御进行案例研究，论文展示了这些pitfalls如何导致关于鲁棒性的错误结论，并提供了可操作的推荐，帮助研究人员避免这些陷阱。总的来说，该工作为FL防御的可靠评估提供了重要指导。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05211v1",
      "published_date": "2025-02-03 23:14:02 UTC",
      "updated_date": "2025-02-03 23:14:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:05:36.751711"
    },
    {
      "arxiv_id": "2502.15731v1",
      "title": "Modular and Integrated AI Control Framework across Fiber and Wireless Networks for 6G",
      "title_zh": "模块化和",
      "authors": [
        "Merim Dzaferagic",
        "Marco Ruffini",
        "Daniel Kilper"
      ],
      "abstract": "The rapid evolution of communication networks towards 6G increasingly\nincorporates advanced AI-driven controls across various network segments to\nachieve intelligent, zero-touch operation. This paper proposes a comprehensive\nand modular framework for AI controllers, designed to be highly flexible and\nadaptable for use across both fiber optical and radio networks. Building on the\nprinciples established by the O-RAN Alliance for near-Real-Time RAN Intelligent\nControllers (near-RT RICs), our framework extends this AI-driven control into\nthe optical domain. Our approach addresses the critical need for a unified AI\ncontrol framework across diverse network transport technologies and domains,\nenabling the development of intelligent, automated, and scalable 6G networks.",
      "tldr_zh": "本论文提出一个模块化且集成的AI控制框架，旨在应用于光纤（fiber optical）和无线（radio）网络，以实现6G网络的智能、零触点操作。该框架基于O-RAN Alliance的near-RT RICs原则，并扩展到光域，提供高度灵活性和适应性，统一AI驱动控制跨不同网络传输技术。研究强调此框架能促进6G网络的自动化和可扩展性，解决多域网络集成挑战。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.15731v1",
      "published_date": "2025-02-03 23:12:44 UTC",
      "updated_date": "2025-02-03 23:12:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:05:47.014515"
    },
    {
      "arxiv_id": "2502.06807v2",
      "title": "Competitive Programming with Large Reasoning Models",
      "title_zh": "翻译失败",
      "authors": [
        "OpenAI",
        ":",
        "Ahmed El-Kishky",
        "Alexander Wei",
        "Andre Saraiva",
        "Borys Minaiev",
        "Daniel Selsam",
        "David Dohan",
        "Francis Song",
        "Hunter Lightman",
        "Ignasi Clavera",
        "Jakub Pachocki",
        "Jerry Tworek",
        "Lorenz Kuhn",
        "Lukasz Kaiser",
        "Mark Chen",
        "Max Schwarzer",
        "Mostafa Rohaninejad",
        "Nat McAleese",
        "o3 contributors",
        "Oleg Mürk",
        "Rhythm Garg",
        "Rui Shu",
        "Szymon Sidor",
        "Vineet Kosaraju",
        "Wenda Zhou"
      ],
      "abstract": "We show that reinforcement learning applied to large language models (LLMs)\nsignificantly boosts performance on complex coding and reasoning tasks.\nAdditionally, we compare two general-purpose reasoning models - OpenAI o1 and\nan early checkpoint of o3 - with a domain-specific system, o1-ioi, which uses\nhand-engineered inference strategies designed for competing in the 2024\nInternational Olympiad in Informatics (IOI). We competed live at IOI 2024 with\no1-ioi and, using hand-crafted test-time strategies, placed in the 49th\npercentile. Under relaxed competition constraints, o1-ioi achieved a gold\nmedal. However, when evaluating later models such as o3, we find that o3\nachieves gold without hand-crafted domain-specific strategies or relaxed\nconstraints. Our findings show that although specialized pipelines such as\no1-ioi yield solid improvements, the scaled-up, general-purpose o3 model\nsurpasses those results without relying on hand-crafted inference heuristics.\nNotably, o3 achieves a gold medal at the 2024 IOI and obtains a Codeforces\nrating on par with elite human competitors. Overall, these results indicate\nthat scaling general-purpose reinforcement learning, rather than relying on\ndomain-specific techniques, offers a robust path toward state-of-the-art AI in\nreasoning domains, such as competitive programming.",
      "tldr_zh": "本研究展示了通过强化学习（reinforcement learning）应用于大型语言模型（LLMs），显著提升了在复杂编码和推理任务上的性能。研究比较了通用推理模型如 OpenAI o1 和 o3，与特定领域模型 o1-ioi，后者在 2024 年国际信息学奥林匹克（IOI）中使用手工设计的推理策略，取得了 49th percentile 的排名，并在放松约束下获得金牌。相比之下，o3 模型无需任何手工策略或放松约束，即可独立获得 IOI 金牌，并达到与精英人类竞争者相当的 Codeforces 评分。这些结果表明，扩展通用强化学习比依赖领域特定技术更可靠，为实现人工智能在推理领域的先进水平提供了稳健路径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.06807v2",
      "published_date": "2025-02-03 23:00:15 UTC",
      "updated_date": "2025-02-18 22:21:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:06:00.086378"
    },
    {
      "arxiv_id": "2502.01866v1",
      "title": "Online Curvature-Aware Replay: Leveraging $\\mathbf{2^{nd}}$ Order Information for Online Continual Learning",
      "title_zh": "在线曲率感知重放：利用第二",
      "authors": [
        "Edoardo Urettini",
        "Antonio Carta"
      ],
      "abstract": "Online Continual Learning (OCL) models continuously adapt to nonstationary\ndata streams, usually without task information. These settings are complex and\nmany traditional CL methods fail, while online methods (mainly replay-based)\nsuffer from instabilities after the task shift. To address this issue, we\nformalize replay-based OCL as a second-order online joint optimization with\nexplicit KL-divergence constraints on replay data. We propose Online\nCurvature-Aware Replay (OCAR) to solve the problem: a method that leverages\nsecond-order information of the loss using a K-FAC approximation of the Fisher\nInformation Matrix (FIM) to precondition the gradient. The FIM acts as a\nstabilizer to prevent forgetting while also accelerating the optimization in\nnon-interfering directions. We show how to adapt the estimation of the FIM to a\ncontinual setting stabilizing second-order optimization for non-iid data,\nuncovering the role of the Tikhonov regularization in the stability-plasticity\ntradeoff. Empirical results show that OCAR outperforms state-of-the-art methods\nin continual metrics achieving higher average accuracy throughout the training\nprocess in three different benchmarks.",
      "tldr_zh": "本文针对Online Continual Learning (OCL)中任务切换导致的不稳定性问题，提出Online Curvature-Aware Replay (OCAR)方法，将基于重放的OCL形式化为二阶在线联合优化，并使用K-FAC近似Fisher Information Matrix (FIM)来预处理梯度，从而稳定训练过程、防止遗忘并加速非干扰方向的优化。OCAR还适应FIM的估计以处理非独立同分布数据，并揭示Tikhonov正则化在稳定-可塑性权衡中的关键作用。实验结果显示，该方法在三个基准上超越最先进方法，在持续指标中实现了更高的平均准确率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01866v1",
      "published_date": "2025-02-03 22:31:36 UTC",
      "updated_date": "2025-02-03 22:31:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:06:12.706718"
    },
    {
      "arxiv_id": "2502.06806v2",
      "title": "Logits are All We Need to Adapt Closed Models",
      "title_zh": "翻译失败",
      "authors": [
        "Gaurush Hiranandani",
        "Haolun Wu",
        "Subhojyoti Mukherjee",
        "Sanmi Koyejo"
      ],
      "abstract": "Many commercial Large Language Models (LLMs) are often closed-source,\nlimiting developers to prompt tuning for aligning content generation with\nspecific applications. While these models currently do not provide access to\ntoken logits, we argue that if such access were available, it would enable more\npowerful adaptation techniques beyond prompt engineering. In this paper, we\npropose a token-level probability reweighting framework that, given access to\nlogits and a small amount of task-specific data, can effectively steer\nblack-box LLMs toward application-specific content generation. Our approach\nviews next-token prediction through the lens of supervised classification. We\nshow that aligning black-box LLMs with task-specific data can be formulated as\na label noise correction problem, leading to \\emph{Plugin} model -- an\nautoregressive probability reweighting model that operates solely on logits. We\nprovide theoretical justification for why reweighting logits alone is\nsufficient for task adaptation. Extensive experiments with multiple datasets,\nLLMs, and reweighting models demonstrate the effectiveness of our method,\nadvocating for broader access to token logits in closed-source models.",
      "tldr_zh": "本文探讨了闭源大型语言模型(LLMs)的适应挑战，提出通过访问token logits即可实现更有效的任务调整，而无需依赖提示工程。作者引入了一个token-level probability reweighting框架，将next-token预测视为监督分类问题，并通过Plugin模型——一个仅在logits上操作的自回归概率再加权模型——来纠正label noise并引导模型生成任务特定内容。实验在多个数据集和LLMs上验证了该方法的有效性，并提供了理论证明，主张为闭源模型提供更广泛的token logits访问以提升适应能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "33 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.06806v2",
      "published_date": "2025-02-03 22:24:22 UTC",
      "updated_date": "2025-02-23 07:20:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:06:24.523401"
    },
    {
      "arxiv_id": "2503.04737v1",
      "title": "Carelessness Detection using Performance Factor Analysis: A New Operationalization with Unexpectedly Different Relationship to Learning",
      "title_zh": "使用性能因素分析的粗心检测：一种新的操作化方法，与学习具有意外不同的",
      "authors": [
        "Jiayi Zhang",
        "Ryan S. Baker",
        "Namrata Srivastava",
        "Jaclyn Ocumpaugh",
        "Caitlin Mills",
        "Bruce M. McLaren"
      ],
      "abstract": "Detection of carelessness in digital learning platforms has relied on the\ncontextual slip model, which leverages conditional probability and Bayesian\nKnowledge Tracing (BKT) to identify careless errors, where students make\nmistakes despite having the knowledge. However, this model cannot effectively\nassess carelessness in questions tagged with multiple skills due to the use of\nconditional probability. This limitation narrows the scope within which the\nmodel can be applied. Thus, we propose a novel model, the Beyond Knowledge\nFeature Carelessness (BKFC) model. The model detects careless errors using\nperformance factor analysis (PFA) and behavioral features distilled from log\ndata, controlling for knowledge when detecting carelessness. We applied the\nBKFC to detect carelessness in data from middle school students playing a\nlearning game on decimal numbers and operations. We conducted analyses\ncomparing the careless errors detected using contextual slip to the BKFC model.\nUnexpectedly, careless errors identified by these two approaches did not align.\nWe found students' post-test performance was (corresponding to past results)\npositively associated with the carelessness detected using the contextual slip\nmodel, while negatively associated with the carelessness detected using the\nBKFC model. These results highlight the complexity of carelessness and\nunderline a broader challenge in operationalizing carelessness and careless\nerrors.",
      "tldr_zh": "本研究针对现有 contextual slip model 在检测 careless errors 的局限性（如无法有效处理多技能标签问题），提出了一种新模型 Beyond Knowledge Feature Carelessness (BKFC)，利用 Performance Factor Analysis (PFA) 和从日志数据中提取的行为特征来检测粗心错误，同时控制知识因素。研究将 BKFC 应用于中学生玩的学习游戏数据中，并与 contextual slip 模型进行比较，结果显示两种方法检测的 careless errors 不一致：contextual slip 模型检测的粗心错误与学生的后续学习表现正相关，而 BKFC 模型检测的则负相关。这些发现揭示了 carelessness 的复杂性，并强调了在操作化 careless errors 时存在的挑战。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04737v1",
      "published_date": "2025-02-03 22:14:02 UTC",
      "updated_date": "2025-02-03 22:14:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:06:37.144017"
    },
    {
      "arxiv_id": "2503.15525v1",
      "title": "The Use of Artificial Intelligence Tools in Assessing Content Validity: A Comparative Study with Human Experts",
      "title_zh": "人工智能工具在评估内容效度中的使用：与人类专家的比较研究",
      "authors": [
        "Hatice Gurdil",
        "Hatice Ozlem Anadol",
        "Yesim Beril Soguksu"
      ],
      "abstract": "In this study, it was investigated whether AI evaluators assess the content\nvalidity of B1-level English reading comprehension test items in a manner\nsimilar to human evaluators. A 25-item multiple-choice test was developed, and\nthese test items were evaluated by four human and four AI evaluators. No\nstatistically significant difference was found between the scores given by\nhuman and AI evaluators, with similar evaluation trends observed. The Content\nValidity Ratio (CVR) and the Item Content Validity Index (I-CVI) were\ncalculated and analyzed using the Wilcoxon Signed-Rank Test, with no\nstatistically significant difference. The findings revealed that in some cases,\nAI evaluators could replace human evaluators. However, differences in specific\nitems were thought to arise from varying interpretations of the evaluation\ncriteria. Ensuring linguistic clarity and clearly defining criteria could\ncontribute to more consistent evaluations. In this regard, the development of\nhybrid evaluation systems, in which AI technologies are used alongside human\nexperts, is recommended.",
      "tldr_zh": "本研究比较了AI评估器与人类评估器在评估B1级英语阅读理解测试项目内容有效性的表现，使用了一个25项多项选择测试，由四名人类和四名AI评估器进行评估。结果显示，AI和人类评估分数无统计学显著差异，Content Validity Ratio (CVR) 和 Item Content Validity Index (I-CVI) 通过 Wilcoxon Signed-Rank Test 分析也未显示显著差异。研究发现，AI在某些情况下可取代人类评估器，但差异可能源于对评估标准的不同解释，因此推荐开发AI与人类专家的混合评估系统，以确保语言清晰和标准一致。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15525v1",
      "published_date": "2025-02-03 22:09:01 UTC",
      "updated_date": "2025-02-03 22:09:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:06:48.388769"
    },
    {
      "arxiv_id": "2502.01857v1",
      "title": "Learning Human Perception Dynamics for Informative Robot Communication",
      "title_zh": "学习人类感知动态以实现信息丰富的机器人通信",
      "authors": [
        "Shenghui Chen",
        "Ruihan Zhao",
        "Sandeep Chinchali",
        "Ufuk Topcu"
      ],
      "abstract": "Human-robot cooperative navigation is challenging in environments with\nincomplete information. We introduce CoNav-Maze, a simulated robotics\nenvironment where a robot navigates using local perception while a human\noperator provides guidance based on an inaccurate map. The robot can share its\ncamera views to improve the operator's understanding of the environment. To\nenable efficient human-robot cooperation, we propose Information Gain Monte\nCarlo Tree Search (IG-MCTS), an online planning algorithm that balances\nautonomous movement and informative communication. Central to IG-MCTS is a\nneural human perception dynamics model that estimates how humans distill\ninformation from robot communications. We collect a dataset through a\ncrowdsourced mapping task in CoNav-Maze and train this model using a fully\nconvolutional architecture with data augmentation. User studies show that\nIG-MCTS outperforms teleoperation and instruction-following baselines,\nachieving comparable task performance with significantly less communication and\nlower human cognitive load, as evidenced by eye-tracking metrics.",
      "tldr_zh": "该研究针对人类-机器人合作导航在信息不完整环境中的挑战，引入了 CoNav-Maze 模拟环境，其中机器人使用本地感知导航，并通过分享相机视图增强人类操作员的理解。论文提出 Information Gain Monte Carlo Tree Search (IG-MCTS) 算法，该算法结合在线规划和一个神经人类感知动态模型，来平衡机器人自主运动与信息通信，并基于众包数据集进行训练。用户研究结果显示，IG-MCTS 相较于遥操作和指令跟随基线，在任务性能相当的情况下，显著减少通信量并降低人类认知负荷，如眼动追踪指标所证。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01857v1",
      "published_date": "2025-02-03 22:08:04 UTC",
      "updated_date": "2025-02-03 22:08:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:07:00.114093"
    },
    {
      "arxiv_id": "2502.01842v2",
      "title": "Texture Image Synthesis Using Spatial GAN Based on Vision Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Elahe Salari",
        "Zohreh Azimifar"
      ],
      "abstract": "Texture synthesis is a fundamental task in computer vision, whose goal is to\ngenerate visually realistic and structurally coherent textures for a wide range\nof applications, from graphics to scientific simulations. While traditional\nmethods like tiling and patch-based techniques often struggle with complex\ntextures, recent advancements in deep learning have transformed this field. In\nthis paper, we propose ViT-SGAN, a new hybrid model that fuses Vision\nTransformers (ViTs) with a Spatial Generative Adversarial Network (SGAN) to\naddress the limitations of previous methods. By incorporating specialized\ntexture descriptors such as mean-variance (mu, sigma) and textons into the\nself-attention mechanism of ViTs, our model achieves superior texture\nsynthesis. This approach enhances the model's capacity to capture complex\nspatial dependencies, leading to improved texture quality that is superior to\nstate-of-the-art models, especially for regular and irregular textures.\nComparison experiments with metrics such as FID, IS, SSIM, and LPIPS\ndemonstrate the substantial improvement of ViT-SGAN, which underlines its\nefficiency in generating diverse realistic textures.",
      "tldr_zh": "本论文提出ViT-SGAN模型，将Vision Transformers (ViTs)与Spatial GAN (SGAN)结合，用于纹理图像合成，以克服传统方法在复杂纹理上的局限性。通过将均值-方差 (mu, sigma) 和 textons 等纹理描述符融入ViTs的自注意力机制，该模型提升了对复杂空间依赖性的捕捉能力，从而生成更高质量的纹理。实验结果显示，ViT-SGAN在FID、IS、SSIM和LPIPS等指标上比现有模型显著改进，尤其适用于规则和不规则纹理的合成。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2502.01842v2",
      "published_date": "2025-02-03 21:39:30 UTC",
      "updated_date": "2025-05-07 21:11:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:07:12.468852"
    },
    {
      "arxiv_id": "2502.01839v2",
      "title": "Sample, Scrutinize and Scale: Effective Inference-Time Search by Scaling Verification",
      "title_zh": "采样、审查和扩展：通过扩展验证的有效推理时搜索",
      "authors": [
        "Eric Zhao",
        "Pranjal Awasthi",
        "Sreenivas Gollapudi"
      ],
      "abstract": "Sampling-based search, a simple paradigm for utilizing test-time compute,\ninvolves generating multiple candidate responses and selecting the best one --\ntypically by having models self-verify each response for correctness. In this\npaper, we study the scaling trends governing sampling-based search. Among our\nfindings is that simply scaling up a minimalist implementation of\nsampling-based search, using only random sampling and direct self-verification,\nprovides a practical inference method that, for example, elevates the reasoning\ncapabilities of Gemini v1.5 Pro above that of o1-Preview on popular benchmarks.\nWe partially attribute the scalability of sampling-based search to a phenomenon\nof implicit scaling, where sampling a larger pool of responses in turn improves\nself-verification accuracy. We further identify two useful principles for\nimproving self-verification capabilities with test-time compute: (1) comparing\nacross responses provides helpful signals about the locations of errors and\nhallucinations, and (2) different model output styles are useful for different\ncontexts -- chains of thought are useful for reasoning but harder to verify. We\nalso find that, though accurate verification can be elicited, frontier models\ndemonstrate remarkably weak out-of-box verification capabilities and introduce\na benchmark to measure progress on these deficiencies.",
      "tldr_zh": "这篇论文探讨了基于采样的搜索方法（sampling-based search），通过生成多个候选响应并利用自我验证（self-verification）来选择最佳响应，从而提升推理任务的性能。研究发现，简单扩展这种方法（如增加采样规模）能显著改善模型能力，例如使 Gemini v1.5 Pro 在流行基准测试中超过 o1-Preview，这部分归因于隐式缩放（implicit scaling）现象，即更大的响应池提升了验证准确性。作者提出了两个改进原则：（1）比较不同响应有助于识别错误和幻觉的位置；（2）不同输出风格（如思维链）适用于不同上下文，但思维链更适合推理却更难验证。最后，论文引入了一个基准来衡量前沿模型的弱验证能力，促进相关领域的进步。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01839v2",
      "published_date": "2025-02-03 21:31:07 UTC",
      "updated_date": "2025-02-20 18:52:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:07:25.336109"
    },
    {
      "arxiv_id": "2502.01837v1",
      "title": "TESS: A Scalable Temporally and Spatially Local Learning Rule for Spiking Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Marco Paul E. Apolinario",
        "Kaushik Roy",
        "Charlotte Frenkel"
      ],
      "abstract": "The demand for low-power inference and training of deep neural networks\n(DNNs) on edge devices has intensified the need for algorithms that are both\nscalable and energy-efficient. While spiking neural networks (SNNs) allow for\nefficient inference by processing complex spatio-temporal dynamics in an\nevent-driven fashion, training them on resource-constrained devices remains\nchallenging due to the high computational and memory demands of conventional\nerror backpropagation (BP)-based approaches. In this work, we draw inspiration\nfrom biological mechanisms such as eligibility traces, spike-timing-dependent\nplasticity, and neural activity synchronization to introduce TESS, a temporally\nand spatially local learning rule for training SNNs. Our approach addresses\nboth temporal and spatial credit assignments by relying solely on locally\navailable signals within each neuron, thereby allowing computational and memory\noverheads to scale linearly with the number of neurons, independently of the\nnumber of time steps. Despite relying on local mechanisms, we demonstrate\nperformance comparable to the backpropagation through time (BPTT) algorithm,\nwithin $\\sim1.4$ accuracy points on challenging computer vision scenarios\nrelevant at the edge, such as the IBM DVS Gesture dataset, CIFAR10-DVS, and\ntemporal versions of CIFAR10, and CIFAR100. Being able to produce comparable\nperformance to BPTT while keeping low time and memory complexity, TESS enables\nefficient and scalable on-device learning at the edge.",
      "tldr_zh": "这篇论文引入了 TESS，一种可扩展的时空局部学习规则，用于 Spiking Neural Networks (SNNs)，旨在解决边缘设备上 DNNs 训练的低功耗需求。TESS 受 eligibility traces、spike-timing-dependent plasticity 和 neural activity synchronization 等生物机制启发，仅依赖每个神经元的局部信号，实现时间和空间信用分配，使计算和内存开销线性增长。实验结果显示，TESS 在 IBM DVS Gesture、CIFAR10-DVS 以及 CIFAR10 和 CIFAR100 的时间版本数据集上，性能与 Backpropagation Through Time (BPTT) 相当，仅差约 1.4% 准确率。该方法支持高效、可扩展的边缘设备学习，提供了一种低复杂度的 SNNs 训练替代方案。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "9 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.01837v1",
      "published_date": "2025-02-03 21:23:15 UTC",
      "updated_date": "2025-02-03 21:23:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:07:36.756676"
    },
    {
      "arxiv_id": "2502.01834v1",
      "title": "Building a Cognitive Twin Using a Distributed Cognitive System and an Evolution Strategy",
      "title_zh": "翻译失败",
      "authors": [
        "Wandemberg Gibaut",
        "Ricardo Gudwin"
      ],
      "abstract": "This work presents a technique to build interaction-based Cognitive Twins (a\ncomputational version of an external agent) using input-output training and an\nEvolution Strategy on top of a framework for distributed Cognitive\nArchitectures. Here, we show that it's possible to orchestrate many simple\nphysical and virtual devices to achieve good approximations of a person's\ninteraction behavior by training the system in an end-to-end fashion and\npresent performance metrics. The generated Cognitive Twin may later be used to\nautomate tasks, generate more realistic human-like artificial agents or further\ninvestigate its behaviors.",
      "tldr_zh": "本研究提出了一种使用分布式认知系统（Distributed Cognitive System）和进化策略（Evolution Strategy）构建基于交互的认知双胞胎（Cognitive Twins）的方法，通过输入-输出训练在分布式认知架构框架上实现端到端训练。研究展示了如何协调多个简单的物理和虚拟设备，以良好逼近个人的交互行为，并提供了相关的性能指标。生成的认知双胞胎可应用于自动化任务、创建更真实的人类-like 人工代理，或进一步探索其行为特性。",
      "categories": [
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "first submitted on 09/22/2022, published on 01/20/2025",
      "pdf_url": "http://arxiv.org/pdf/2502.01834v1",
      "published_date": "2025-02-03 21:19:13 UTC",
      "updated_date": "2025-02-03 21:19:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:07:48.792943"
    },
    {
      "arxiv_id": "2502.01825v1",
      "title": "Assessing Data Augmentation-Induced Bias in Training and Testing of Machine Learning Models",
      "title_zh": "评估数据增强引发的偏差在机器学习模型训练和测试中的影响",
      "authors": [
        "Riddhi More",
        "Jeremy S. Bradbury"
      ],
      "abstract": "Data augmentation has become a standard practice in software engineering to\naddress limited or imbalanced data sets, particularly in specialized domains\nlike test classification and bug detection where data can be scarce. Although\ntechniques such as SMOTE and mutation-based augmentation are widely used in\nsoftware testing and debugging applications, a rigorous understanding of how\naugmented training data impacts model bias is lacking. It is especially\ncritical to consider bias in scenarios where augmented data sets are used not\njust in training but also in testing models. Through a comprehensive case study\nof flaky test classification, we demonstrate how to test for bias and\nunderstand the impact that the inclusion of augmented samples in testing sets\ncan have on model evaluation.",
      "tldr_zh": "数据增强（Data augmentation）在软件工程中广泛用于处理数据不足或不平衡问题，尤其在测试分类和错误检测领域，但其对机器学习模型偏差的影响尚未得到充分研究。论文通过一个易变测试分类（flaky test classification）的案例研究，评估了增强技术（如 SMOTE 和基于变异的增强）在训练和测试阶段引入的偏差。研究发现，将增强样本纳入测试集会显著影响模型评估结果，从而为测试和减轻这种偏差提供了重要指导。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "D.2.5; I.2.7"
      ],
      "primary_category": "cs.SE",
      "comment": "4 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.01825v1",
      "published_date": "2025-02-03 21:06:35 UTC",
      "updated_date": "2025-02-03 21:06:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:08:00.101976"
    },
    {
      "arxiv_id": "2502.01821v2",
      "title": "Agentic Bug Reproduction for Effective Automated Program Repair at Google",
      "title_zh": "翻译失败",
      "authors": [
        "Runxiang Cheng",
        "Michele Tufano",
        "Jürgen Cito",
        "José Cambronero",
        "Pat Rondon",
        "Renyao Wei",
        "Aaron Sun",
        "Satish Chandra"
      ],
      "abstract": "Bug reports often lack sufficient detail for developers to reproduce and fix\nthe underlying defects. Bug Reproduction Tests (BRTs), tests that fail when the\nbug is present and pass when it has been resolved, are crucial for debugging,\nbut they are rarely included in bug reports, both in open-source and in\nindustrial settings. Thus, automatically generating BRTs from bug reports has\nthe potential to accelerate the debugging process and lower time to repair.\nThis paper investigates automated BRT generation within an industry setting,\nspecifically at Google, focusing on the challenges of a large-scale,\nproprietary codebase and considering real-world industry bugs extracted from\nGoogle's internal issue tracker. We adapt and evaluate a state-of-the-art BRT\ngeneration technique, LIBRO, and present our agent-based approach, BRT Agent,\nwhich makes use of a fine-tuned Large Language Model (LLM) for code editing.\nOur BRT Agent significantly outperforms LIBRO, achieving a 28% plausible BRT\ngeneration rate, compared to 10% by LIBRO, on 80 human-reported bugs from\nGoogle's internal issue tracker. We further investigate the practical value of\ngenerated BRTs by integrating them with an Automated Program Repair (APR)\nsystem at Google. Our results show that providing BRTs to the APR system\nresults in 30% more bugs with plausible fixes. Additionally, we introduce\nEnsemble Pass Rate (EPR), a metric which leverages the generated BRTs to select\nthe most promising fixes from all fixes generated by APR system. Our evaluation\non EPR for Top-K and threshold-based fix selections demonstrates promising\nresults and trade-offs. For example, EPR correctly selects a plausible fix from\na pool of 20 candidates in 70% of cases, based on its top-1 ranking.",
      "tldr_zh": "这篇论文针对 bug 报告细节不足的问题，提出了一种基于代理（Agentic）的 BRT Agent 方法，使用 fine-tuned Large Language Model (LLM) 来自动生成 Bug Reproduction Tests (BRTs)，以加速调试过程。相比现有技术 LIBRO，BRT Agent 在 Google 的内部 bug 上将可信 BRT 生成率从 10% 提高到 28%。此外，将生成的 BRTs 集成到 Automated Program Repair (APR) 系统后，可使 30% 更多 bug 获得可信修复，并引入 Ensemble Pass Rate (EPR) 指标来优化修复选择，例如在 20 个候选中，EPR 的 top-1 排名正确率达 70%。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01821v2",
      "published_date": "2025-02-03 20:57:17 UTC",
      "updated_date": "2025-03-11 02:30:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:08:12.968547"
    },
    {
      "arxiv_id": "2502.01819v2",
      "title": "Score as Action: Fine-Tuning Diffusion Generative Models by Continuous-time Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Hanyang Zhao",
        "Haoxian Chen",
        "Ji Zhang",
        "David D. Yao",
        "Wenpin Tang"
      ],
      "abstract": "Reinforcement learning from human feedback (RLHF), which aligns a diffusion\nmodel with input prompt, has become a crucial step in building reliable\ngenerative AI models. Most works in this area use a discrete-time formulation,\nwhich is prone to induced errors, and often not applicable to models with\nhigher-order/black-box solvers. The objective of this study is to develop a\ndisciplined approach to fine-tune diffusion models using continuous-time RL,\nformulated as a stochastic control problem with a reward function that aligns\nthe end result (terminal state) with input prompt. The key idea is to treat\nscore matching as controls or actions, and thereby making connections to policy\noptimization and regularization in continuous-time RL. To carry out this idea,\nwe lay out a new policy optimization framework for continuous-time RL, and\nillustrate its potential in enhancing the value networks design space via\nleveraging the structural property of diffusion models. We validate the\nadvantages of our method by experiments in downstream tasks of fine-tuning\nlarge-scale Text2Image models of Stable Diffusion v1.5.",
      "tldr_zh": "本文提出了一种基于连续时间强化学习（Continuous-Time Reinforcement Learning）的微调方法，用于对齐扩散生成模型（Diffusion Generative Models）与输入提示，从而解决现有离散时间RLHF方法的误差易发和适用性问题。关键创新是将分数匹配（Score Matching）视为控制或动作，构建一个新的策略优化框架，并利用扩散模型的结构属性增强价值网络的设计空间。通过在Stable Diffusion v1.5的Text2Image任务上的实验，该方法展示了显著优势，验证了其在微调大型生成模型中的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "arXiv admin note: text overlap with arXiv:2409.08400",
      "pdf_url": "http://arxiv.org/pdf/2502.01819v2",
      "published_date": "2025-02-03 20:50:05 UTC",
      "updated_date": "2025-04-16 15:36:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:08:24.462537"
    },
    {
      "arxiv_id": "2502.01806v1",
      "title": "Toward Neurosymbolic Program Comprehension",
      "title_zh": "翻译失败",
      "authors": [
        "Alejandro Velasco",
        "Aya Garryyeva",
        "David N. Palacio",
        "Antonio Mastropaolo",
        "Denys Poshyvanyk"
      ],
      "abstract": "Recent advancements in Large Language Models (LLMs) have paved the way for\nLarge Code Models (LCMs), enabling automation in complex software engineering\ntasks, such as code generation, software testing, and program comprehension,\namong others. Tools like GitHub Copilot and ChatGPT have shown substantial\nbenefits in supporting developers across various practices. However, the\nambition to scale these models to trillion-parameter sizes, exemplified by\nGPT-4, poses significant challenges that limit the usage of Artificial\nIntelligence (AI)-based systems powered by large Deep Learning (DL) models.\nThese include rising computational demands for training and deployment and\nissues related to trustworthiness, bias, and interpretability. Such factors can\nmake managing these models impractical for many organizations, while their\n\"black-box'' nature undermines key aspects, including transparency and\naccountability. In this paper, we question the prevailing assumption that\nincreasing model parameters is always the optimal path forward, provided there\nis sufficient new data to learn additional patterns. In particular, we advocate\nfor a Neurosymbolic research direction that combines the strengths of existing\nDL techniques (e.g., LLMs) with traditional symbolic methods--renowned for\ntheir reliability, speed, and determinism. To this end, we outline the core\nfeatures and present preliminary results for our envisioned approach, aimed at\nestablishing the first Neurosymbolic Program Comprehension (NsPC) framework to\naid in identifying defective code components.",
      "tldr_zh": "这篇论文质疑了单纯通过增加模型参数（如GPT-4）来提升Large Language Models (LLMs)和Large Code Models (LCMs)在软件工程任务中的效能，并强调了其带来的计算需求、信任性、偏差和可解释性问题。作者提倡采用Neurosymbolic方法，将Deep Learning (DL)技术（如LLMs）与传统的符号方法结合，以利用后者的可靠性和确定性。论文概述了Neurosymbolic Program Comprehension (NsPC)框架的核心特征和初步结果，该框架旨在辅助识别有缺陷的代码组件，从而为更可信的程序理解提供新途径。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01806v1",
      "published_date": "2025-02-03 20:38:58 UTC",
      "updated_date": "2025-02-03 20:38:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:08:36.162148"
    },
    {
      "arxiv_id": "2502.01803v1",
      "title": "Discovering Chunks in Neural Embeddings for Interpretability",
      "title_zh": "翻译失败",
      "authors": [
        "Shuchen Wu",
        "Stephan Alaniz",
        "Eric Schulz",
        "Zeynep Akata"
      ],
      "abstract": "Understanding neural networks is challenging due to their high-dimensional,\ninteracting components. Inspired by human cognition, which processes complex\nsensory data by chunking it into recurring entities, we propose leveraging this\nprinciple to interpret artificial neural population activities. Biological and\nartificial intelligence share the challenge of learning from structured,\nnaturalistic data, and we hypothesize that the cognitive mechanism of chunking\ncan provide insights into artificial systems. We first demonstrate this concept\nin recurrent neural networks (RNNs) trained on artificial sequences with\nimposed regularities, observing that their hidden states reflect these\npatterns, which can be extracted as a dictionary of chunks that influence\nnetwork responses. Extending this to large language models (LLMs) like LLaMA,\nwe identify similar recurring embedding states corresponding to concepts in the\ninput, with perturbations to these states activating or inhibiting the\nassociated concepts. By exploring methods to extract dictionaries of\nidentifiable chunks across neural embeddings of varying complexity, our\nfindings introduce a new framework for interpreting neural networks, framing\ntheir population activity as structured reflections of the data they process.",
      "tldr_zh": "该论文受人类认知中数据分块（chunking）的启发，提出一种新框架来解释神经网络的高维嵌入状态，旨在揭示其内部结构。研究者首先在训练于有规律序列的 RNNs 上实验，提取隐藏状态中的 chunks 字典，这些 chunks 反映了数据模式并影响网络响应。随后扩展到 LLMs 如 LLaMA，观察到嵌入状态对应输入概念，扰动这些状态可激活或抑制相关概念。该框架为解释神经网络的群体活动提供新视角，将其视为结构化的数据反映。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01803v1",
      "published_date": "2025-02-03 20:30:46 UTC",
      "updated_date": "2025-02-03 20:30:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:08:48.244644"
    },
    {
      "arxiv_id": "2502.01800v2",
      "title": "Flow-based Domain Randomization for Learning and Sequencing Robotic Skills",
      "title_zh": "基于流的领域随机化用于学习和排序机器人技能",
      "authors": [
        "Aidan Curtis",
        "Eric Li",
        "Michael Noseworthy",
        "Nishad Gothoskar",
        "Sachin Chitta",
        "Hui Li",
        "Leslie Pack Kaelbling",
        "Nicole Carey"
      ],
      "abstract": "Domain randomization in reinforcement learning is an established technique\nfor increasing the robustness of control policies trained in simulation. By\nrandomizing environment properties during training, the learned policy can\nbecome robust to uncertainties along the randomized dimensions. While the\nenvironment distribution is typically specified by hand, in this paper we\ninvestigate automatically discovering a sampling distribution via\nentropy-regularized reward maximization of a normalizing-flow-based neural\nsampling distribution. We show that this architecture is more flexible and\nprovides greater robustness than existing approaches that learn simpler,\nparameterized sampling distributions, as demonstrated in six simulated and one\nreal-world robotics domain. Lastly, we explore how these learned sampling\ndistributions, combined with a privileged value function, can be used for\nout-of-distribution detection in an uncertainty-aware multi-step manipulation\nplanner.",
      "tldr_zh": "本论文提出了一种基于 normalizing flow 的 domain randomization 方法，用于强化学习中机器人技能的学习和序列化。该方法通过熵正则化奖励最大化自动发现采样分布，比现有简单参数化方法更灵活，并显著提高了策略的鲁棒性，在六个模拟和一个真实机器人领域中得到验证。最后，该学到的采样分布与特权价值函数结合，可用于不确定性感知的多步操作规划中的分布外检测。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01800v2",
      "published_date": "2025-02-03 20:25:50 UTC",
      "updated_date": "2025-05-05 19:40:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:09:00.312592"
    },
    {
      "arxiv_id": "2502.01789v1",
      "title": "An Agentic AI Workflow for Detecting Cognitive Concerns in Real-world Data",
      "title_zh": "翻译失败",
      "authors": [
        "Jiazi Tian",
        "Liqin Wang",
        "Pedram Fard",
        "Valdery Moura Junior",
        "Deborah Blacker",
        "Jennifer S. Haas",
        "Chirag Patel",
        "Shawn N. Murphy",
        "Lidia M. V. R. Moura",
        "Hossein Estiri"
      ],
      "abstract": "Early identification of cognitive concerns is critical but often hindered by\nsubtle symptom presentation. This study developed and validated a fully\nautomated, multi-agent AI workflow using LLaMA 3 8B to identify cognitive\nconcerns in 3,338 clinical notes from Mass General Brigham. The agentic\nworkflow, leveraging task-specific agents that dynamically collaborate to\nextract meaningful insights from clinical notes, was compared to an\nexpert-driven benchmark. Both workflows achieved high classification\nperformance, with F1-scores of 0.90 and 0.91, respectively. The agentic\nworkflow demonstrated improved specificity (1.00) and achieved prompt\nrefinement in fewer iterations. Although both workflows showed reduced\nperformance on validation data, the agentic workflow maintained perfect\nspecificity. These findings highlight the potential of fully automated\nmulti-agent AI workflows to achieve expert-level accuracy with greater\nefficiency, offering a scalable and cost-effective solution for detecting\ncognitive concerns in clinical settings.",
      "tldr_zh": "这篇论文开发了一个基于LLaMA 3 8B的多智能体AI工作流，用于从3,338份Mass General Brigham临床笔记中自动识别认知问题，这些智能体动态协作提取洞见。相比专家驱动基准，该工作流在F1-score上达到0.90，与基准的0.91相当，但特异性提升至1.00，并通过更少的迭代实现提示优化。研究结果显示，虽然在验证数据上性能略有下降，该工作流仍保持完美特异性，并提供了一个高效、可扩展且成本有效的临床检测解决方案。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01789v1",
      "published_date": "2025-02-03 20:08:33 UTC",
      "updated_date": "2025-02-03 20:08:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:09:12.628587"
    },
    {
      "arxiv_id": "2502.01785v1",
      "title": "AquaticCLIP: A Vision-Language Foundation Model for Underwater Scene Analysis",
      "title_zh": "AquaticCLIP：一种视觉-语言基础模型，用于水下场景分析",
      "authors": [
        "Basit Alawode",
        "Iyyakutti Iyappan Ganapathi",
        "Sajid Javed",
        "Naoufel Werghi",
        "Mohammed Bennamoun",
        "Arif Mahmood"
      ],
      "abstract": "The preservation of aquatic biodiversity is critical in mitigating the\neffects of climate change. Aquatic scene understanding plays a pivotal role in\naiding marine scientists in their decision-making processes. In this paper, we\nintroduce AquaticCLIP, a novel contrastive language-image pre-training model\ntailored for aquatic scene understanding. AquaticCLIP presents a new\nunsupervised learning framework that aligns images and texts in aquatic\nenvironments, enabling tasks such as segmentation, classification, detection,\nand object counting. By leveraging our large-scale underwater image-text paired\ndataset without the need for ground-truth annotations, our model enriches\nexisting vision-language models in the aquatic domain. For this purpose, we\nconstruct a 2 million underwater image-text paired dataset using heterogeneous\nresources, including YouTube, Netflix, NatGeo, etc. To fine-tune AquaticCLIP,\nwe propose a prompt-guided vision encoder that progressively aggregates patch\nfeatures via learnable prompts, while a vision-guided mechanism enhances the\nlanguage encoder by incorporating visual context. The model is optimized\nthrough a contrastive pretraining loss to align visual and textual modalities.\nAquaticCLIP achieves notable performance improvements in zero-shot settings\nacross multiple underwater computer vision tasks, outperforming existing\nmethods in both robustness and interpretability. Our model sets a new benchmark\nfor vision-language applications in underwater environments. The code and\ndataset for AquaticCLIP are publicly available on GitHub at xxx.",
      "tldr_zh": "本研究引入了AquaticCLIP，一种专为水下场景分析设计的视觉-语言基础模型，通过对比语言-图像预训练框架，支持任务如分割、分类、检测和物体计数，以辅助海洋科学家的决策。模型利用一个2百万对的水下图像-文本数据集（从YouTube、Netflix、NatGeo等来源构建，无需地面真实标注），并采用prompt-guided vision encoder和vision-guided mechanism来对齐视觉和文本模态。实验结果显示，AquaticCLIP在零样本设置下显著超越现有方法，在鲁棒性和可解释性方面表现出色，并为水下环境的应用设定新基准；代码和数据集已在GitHub上公开。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01785v1",
      "published_date": "2025-02-03 19:56:16 UTC",
      "updated_date": "2025-02-03 19:56:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:09:24.268768"
    },
    {
      "arxiv_id": "2503.15524v1",
      "title": "KHAIT: K-9 Handler Artificial Intelligence Teaming for Collaborative Sensemaking",
      "title_zh": "翻译失败",
      "authors": [
        "Matthew Wilchek",
        "Linhan Wang",
        "Sally Dickinson",
        "Erica Feuerbacher",
        "Kurt Luther",
        "Feras A. Batarseh"
      ],
      "abstract": "In urban search and rescue (USAR) operations, communication between handlers\nand specially trained canines is crucial but often complicated by challenging\nenvironments and the specific behaviors canines are trained to exhibit when\ndetecting a person. Since a USAR canine often works out of sight of the\nhandler, the handler lacks awareness of the canine's location and situation,\nknown as the 'sensemaking gap.' In this paper, we propose KHAIT, a novel\napproach to close the sensemaking gap and enhance USAR effectiveness by\nintegrating object detection-based Artificial Intelligence (AI) and Augmented\nReality (AR). Equipped with AI-powered cameras, edge computing, and AR\nheadsets, KHAIT enables precise and rapid object detection from a canine's\nperspective, improving survivor localization. We evaluate this approach in a\nreal-world USAR environment, demonstrating an average survival allocation time\ndecrease of 22%, enhancing the speed and accuracy of operations.",
      "tldr_zh": "在城市搜索和救援（USAR）操作中，处理者和训练犬只之间的“sensemaking gap”问题导致处理者无法实时感知犬只的位置和情况，论文提出 KHAIT 框架来解决这一挑战。该框架整合基于物体检测的 Artificial Intelligence (AI) 和 Augmented Reality (AR) 技术，利用 AI-powered 相机、edge computing 和 AR 头盔，从犬只视角进行精确物体检测，从而提升幸存者定位效率。实验结果显示，在真实 USAR 环境中，KHAIT 平均将生存者分配时间减少 22%，显著提高了操作的速度和准确性。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CV",
        "cs.ET",
        "cs.MA",
        "I.2.11; I.4.8; H.5.2; H.5.3; J.7"
      ],
      "primary_category": "cs.HC",
      "comment": "13 pages, 7 figures, ACM 30th International Conference on Intelligent\n  User Interfaces (IUI 25)",
      "pdf_url": "http://arxiv.org/pdf/2503.15524v1",
      "published_date": "2025-02-03 19:30:56 UTC",
      "updated_date": "2025-02-03 19:30:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:09:36.518758"
    },
    {
      "arxiv_id": "2502.01774v1",
      "title": "Grokking Explained: A Statistical Phenomenon",
      "title_zh": "Grokking 详解：一个统计现象",
      "authors": [
        "Breno W. Carvalho",
        "Artur S. d'Avila Garcez",
        "Luís C. Lamb",
        "Emílio Vital Brazil"
      ],
      "abstract": "Grokking, or delayed generalization, is an intriguing learning phenomenon\nwhere test set loss decreases sharply only after a model's training set loss\nhas converged. This challenges conventional understanding of the training\ndynamics in deep learning networks. In this paper, we formalize and investigate\ngrokking, highlighting that a key factor in its emergence is a distribution\nshift between training and test data. We introduce two synthetic datasets\nspecifically designed to analyze grokking. One dataset examines the impact of\nlimited sampling, and the other investigates transfer learning's role in\ngrokking. By inducing distribution shifts through controlled imbalanced\nsampling of sub-categories, we systematically reproduce the phenomenon,\ndemonstrating that while small-sampling is strongly associated with grokking,\nit is not its cause. Instead, small-sampling serves as a convenient mechanism\nfor achieving the necessary distribution shift. We also show that when classes\nform an equivariant map, grokking can be explained by the model's ability to\nlearn from similar classes or sub-categories. Unlike earlier work suggesting\nthat grokking primarily arises from high regularization and sparse data, we\ndemonstrate that it can also occur with dense data and minimal hyper-parameter\ntuning. Our findings deepen the understanding of grokking and pave the way for\ndeveloping better stopping criteria in future training processes.",
      "tldr_zh": "这篇论文解释了 Grokking（延迟泛化）现象，即模型在训练集损失收敛后，测试集损失才急剧下降，并将其归因于训练和测试数据之间的 distribution shift。研究人员引入了两个合成数据集，通过控制不平衡采样诱导分布偏移，系统地再现了该现象，并证明小样本不是 Grokking 的直接原因，而是实现分布偏移的机制。结果显示，Grokking 可以在密集数据和最小 hyper-parameter tuning 下发生，这为深度学习训练动态提供了新见解，并有助于开发更好的停止标准。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01774v1",
      "published_date": "2025-02-03 19:28:11 UTC",
      "updated_date": "2025-02-03 19:28:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:09:49.384649"
    },
    {
      "arxiv_id": "2502.01772v1",
      "title": "On Bob Dylan: A Computational Perspective",
      "title_zh": "论 Bob Dylan：计算视角",
      "authors": [
        "Prashant Garg"
      ],
      "abstract": "Cass Sunstein's essay 'On Bob Dylan' describes Dylan's 'dishabituating' style\n-- a constant refusal to conform to expectation and a penchant for reinventing\nhis musical and lyrical identity. In this paper, I extend Sunstein's\nobservations through a large-scale computational analysis of Dylan's lyrics\nfrom 1962 to 2012. Using o3-mini-high (a large language model), I extract\nconcept-to-concept relationships from the lyrics and construct directed\nknowledge graphs that capture Dylan's thematic structure. I then quantify\nshifts in sentiment, metaphorical expression, thematic diversity, and network\ncomplexity over time. The results indicate that Dylan's lyrics increasingly\nrely on metaphor, display an evolving sentiment profile, and exhibit heightened\ndishabituation -- measured here as a growing variance in the network centrality\nof key concepts. I also find that references to movement, protest, and mythic\nimagery fluctuate in ways that align with well-known phases of Dylan's career,\nreflecting the dynamic and unpredictable quality of his art. These findings not\nonly deepen our empirical understanding of Sunstein's thesis but also introduce\na novel computational method for analyzing an artist's evolution-offering\nbroader applicability to the study of cultural and creative change.",
      "tldr_zh": "本文基于计算分析扩展了 Cass Sunstein 对 Bob Dylan “dishabituating” 风格的观察，即其拒绝预期并不断重塑音乐身份的特性。作者使用 o3-mini-high 模型从 Dylan 1962-2012 年歌词中提取概念间关系，构建有向 knowledge graphs，并量化情感、隐喻表达、主题多样性和网络复杂性的变化，结果显示歌词中隐喻使用增加、情感轮廓演变，以及 dishabituation 通过关键概念的网络中心度方差进一步增强。这些发现不仅实证支持 Sunstein 的论点，还引入了一种新型计算方法，可广泛应用于分析艺术家的演变和文化创意变化。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.SI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01772v1",
      "published_date": "2025-02-03 19:25:08 UTC",
      "updated_date": "2025-02-03 19:25:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:10:00.940955"
    },
    {
      "arxiv_id": "2502.01770v1",
      "title": "Hamming Attention Distillation: Binarizing Keys and Queries for Efficient Long-Context Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Mark Horton",
        "Tergel Molom-Ochir",
        "Peter Liu",
        "Bhavna Gopal",
        "Chiyue Wei",
        "Cong Guo",
        "Brady Taylor",
        "Deliang Fan",
        "Shan X. Wang",
        "Hai Li",
        "Yiran Chen"
      ],
      "abstract": "Pre-trained transformer models with extended context windows are notoriously\nexpensive to run at scale, often limiting real-world deployment due to their\nhigh computational and memory requirements. In this paper, we introduce Hamming\nAttention Distillation (HAD), a novel framework that binarizes keys and queries\nin the attention mechanism to achieve significant efficiency gains. By\nconverting keys and queries into {-1, +1} vectors and replacing dot-product\noperations with efficient Hamming distance computations, our method drastically\nreduces computational overhead. Additionally, we incorporate attention matrix\nsparsification to prune low-impact activations, which further reduces the cost\nof processing long-context sequences. \\par Despite these aggressive compression\nstrategies, our distilled approach preserves a high degree of representational\npower, leading to substantially improved accuracy compared to prior transformer\nbinarization methods. We evaluate HAD on a range of tasks and models, including\nthe GLUE benchmark, ImageNet, and QuALITY, demonstrating state-of-the-art\nperformance among binarized Transformers while drastically reducing the\ncomputational costs of long-context inference. \\par We implement HAD in custom\nhardware simulations, demonstrating superior performance characteristics\ncompared to a custom hardware implementation of standard attention. HAD\nachieves just $\\mathbf{1.78}\\%$ performance losses on GLUE compared to $9.08\\%$\nin state-of-the-art binarization work, and $\\mathbf{2.5}\\%$ performance losses\non ImageNet compared to $12.14\\%$, all while targeting custom hardware with a\n$\\mathbf{79}\\%$ area reduction and $\\mathbf{87}\\%$ power reduction compared to\nits standard attention counterpart.",
      "tldr_zh": "本研究提出Hamming Attention Distillation (HAD)，一种创新框架，通过将Transformer模型中注意力机制的keys和queries二值化成{-1, +1}向量，并使用Hamming距离计算替换点积操作，从而显著降低长上下文序列的计算和内存开销。HAD还结合注意力矩阵稀疏化技术，修剪低影响激活，进一步提升效率。尽管采用这些压缩策略，该方法仍保留了高表示能力，在GLUE基准上仅损失1.78%的性能，而现有二值化方法损失9.08%；在ImageNet上损失2.5%，对比其他方法的12.14%。总体上，HAD在各种任务中实现了最先进性能，并在自定义硬件模拟中实现了79%的面积减少和87%的功率减少。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01770v1",
      "published_date": "2025-02-03 19:24:01 UTC",
      "updated_date": "2025-02-03 19:24:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:10:12.622014"
    },
    {
      "arxiv_id": "2502.01755v2",
      "title": "Robust Federated Finetuning of LLMs via Alternating Optimization of LoRA",
      "title_zh": "翻译失败",
      "authors": [
        "Shuangyi Chen",
        "Yuanxin Guo",
        "Yue Ju",
        "Harik Dalal",
        "Ashish Khisti"
      ],
      "abstract": "Parameter-Efficient Fine-Tuning (PEFT) methods like Low-Rank Adaptation\n(LoRA) optimize federated training by reducing computational and communication\ncosts. We propose RoLoRA, a federated framework using alternating optimization\nto fine-tune LoRA adapters. Our approach emphasizes the importance of learning\nup and down projection matrices to enhance expressiveness and robustness. We\nuse both theoretical analysis and extensive experiments to demonstrate the\nadvantages of RoLoRA over prior approaches that either generate imperfect model\nupdates or limit expressiveness of the model. We present theoretical analysis\non a simplified linear model to demonstrate the importance of learning both\ndown-projection and up-projection matrices in LoRA. We provide extensive\nexperimental evaluations on a toy neural network on MNIST as well as large\nlanguage models including RoBERTa-Large, Llama-2-7B on diverse tasks to\ndemonstrate the advantages of RoLoRA over other methods.",
      "tldr_zh": "该论文提出 RoLoRA，一种基于交替优化的联邦框架，用于高效微调大型语言模型 (LLMs) 的 Low-Rank Adaptation (LoRA) 适配器，旨在通过学习 up 和 down projection matrices 来提升模型的表达性和鲁棒性。作者通过理论分析（如简化线性模型）和广泛实验（如在 MNIST 上的玩具神经网络，以及 RoBERTa-Large 和 Llama-2-7B 模型上）证明，RoLoRA 相较于现有方法（如生成不完美更新或限制表达性）显著提高了性能。总体而言，该框架优化了 Parameter-Efficient Fine-Tuning (PEFT) 的联邦训练过程，降低了计算和通信成本，为鲁棒的模型微调提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "A preliminary version was in ICML24 workshop, arXiv:2409.02346",
      "pdf_url": "http://arxiv.org/pdf/2502.01755v2",
      "published_date": "2025-02-03 19:02:00 UTC",
      "updated_date": "2025-02-13 03:42:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:10:24.403877"
    },
    {
      "arxiv_id": "2502.01754v1",
      "title": "Evaluation of Large Language Models via Coupled Token Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Nina Corvelo Benz",
        "Stratis Tsirtsis",
        "Eleni Straitouri",
        "Ivi Chatzi",
        "Ander Artola Velasco",
        "Suhas Thejaswi",
        "Manuel Gomez-Rodriguez"
      ],
      "abstract": "State of the art large language models rely on randomization to respond to a\nprompt. As an immediate consequence, a model may respond differently to the\nsame prompt if asked multiple times. In this work, we argue that the evaluation\nand ranking of large language models should control for the randomization\nunderpinning their functioning. Our starting point is the development of a\ncausal model for coupled autoregressive generation, which allows different\nlarge language models to sample responses with the same source of randomness.\nBuilding upon our causal model, we first show that, on evaluations based on\nbenchmark datasets, coupled autoregressive generation leads to the same\nconclusions as vanilla autoregressive generation but using provably fewer\nsamples. However, we further show that, on evaluations based on (human)\npairwise comparisons, coupled and vanilla autoregressive generation can\nsurprisingly lead to different rankings when comparing more than two models,\neven with an infinite amount of samples. This suggests that the apparent\nadvantage of a model over others in existing evaluation protocols may not be\ngenuine but rather confounded by the randomness inherent to the generation\nprocess. To illustrate and complement our theoretical results, we conduct\nexperiments with several large language models from the Llama family. We find\nthat, across multiple knowledge areas from the popular MMLU benchmark dataset,\ncoupled autoregressive generation requires up to 40% fewer samples to reach the\nsame conclusions as vanilla autoregressive generation. Further, using data from\nthe LMSYS Chatbot Arena platform, we find that the win-rates derived from\npairwise comparisons by a strong large language model to prompts differ under\ncoupled and vanilla autoregressive generation.",
      "tldr_zh": "这篇论文提出了一种耦合自回归生成（coupled autoregressive generation）的因果模型（causal model），用于评估大型语言模型（Large Language Models, LLMs），以控制随机性对响应的一致性影响，从而更准确地比较模型性能。该方法在基准数据集评估中能使用更少的样本（如减少40%）得出相同结论，同时揭示在基于人类配对比较的评估中，耦合生成可能导致与传统自回归生成不同的模型排名。研究者通过实验证明，这种随机性混淆（confounding）可能使现有评估结果不可靠。总体而言，该工作为更可靠的LLMs评估提供了新框架，并在Llama家族模型和MMLU数据集上进行了验证。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01754v1",
      "published_date": "2025-02-03 19:01:17 UTC",
      "updated_date": "2025-02-03 19:01:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:10:36.680843"
    },
    {
      "arxiv_id": "2502.01739v1",
      "title": "Grokking vs. Learning: Same Features, Different Encodings",
      "title_zh": "Grokking 与学习：相同的特征，不同的编码",
      "authors": [
        "Dmitry Manning-Coe",
        "Jacopo Gliozzi",
        "Alexander G. Stapleton",
        "Edward Hirst",
        "Giuseppe De Tomasi",
        "Barry Bradlyn",
        "David S. Berman"
      ],
      "abstract": "Grokking typically achieves similar loss to ordinary, \"steady\", learning. We\nask whether these different learning paths - grokking versus ordinary training\n- lead to fundamental differences in the learned models. To do so we compare\nthe features, compressibility, and learning dynamics of models trained via each\npath in two tasks. We find that grokked and steadily trained models learn the\nsame features, but there can be large differences in the efficiency with which\nthese features are encoded. In particular, we find a novel \"compressive regime\"\nof steady training in which there emerges a linear trade-off between model loss\nand compressibility, and which is absent in grokking. In this regime, we can\nachieve compression factors 25x times the base model, and 5x times the\ncompression achieved in grokking. We then track how model features and\ncompressibility develop through training. We show that model development in\ngrokking is task-dependent, and that peak compressibility is achieved\nimmediately after the grokking plateau. Finally, novel information-geometric\nmeasures are introduced which demonstrate that models undergoing grokking\nfollow a straight path in information space.",
      "tldr_zh": "这篇论文比较了 grokking 和 steady training 在模型训练中的差异，发现两者学习相同的特征，但特征编码效率存在显著不同。研究在两个任务中分析了模型的特征、压缩性和学习动态，引入了 compressive regime，在 steady training 中观察到模型损失与压缩性之间的线性权衡，从而实现高达25倍的压缩，比 grokking 多出5倍。实验结果显示，grokking 的模型发展依赖任务，并在 grokking plateau 后立即达到峰值压缩性；此外，新的信息几何测量证明 grokking 模型在信息空间中遵循直线路径。",
      "categories": [
        "cs.LG",
        "cond-mat.dis-nn",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Code available at:\n  https://github.com/xand-stapleton/grokking_vs_learning",
      "pdf_url": "http://arxiv.org/pdf/2502.01739v1",
      "published_date": "2025-02-03 19:00:02 UTC",
      "updated_date": "2025-02-03 19:00:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:10:49.931744"
    },
    {
      "arxiv_id": "2502.03482v1",
      "title": "Can Domain Experts Rely on AI Appropriately? A Case Study on AI-Assisted Prostate Cancer MRI Diagnosis",
      "title_zh": "翻译失败",
      "authors": [
        "Chacha Chen",
        "Han Liu",
        "Jiamin Yang",
        "Benjamin M. Mervak",
        "Bora Kalaycioglu",
        "Grace Lee",
        "Emre Cakmakli",
        "Matteo Bonatti",
        "Sridhar Pudu",
        "Osman Kahraman",
        "Gul Gizem Pamuk",
        "Aytekin Oto",
        "Aritrick Chatterjee",
        "Chenhao Tan"
      ],
      "abstract": "Despite the growing interest in human-AI decision making, experimental\nstudies with domain experts remain rare, largely due to the complexity of\nworking with domain experts and the challenges in setting up realistic\nexperiments. In this work, we conduct an in-depth collaboration with\nradiologists in prostate cancer diagnosis based on MRI images. Building on\nexisting tools for teaching prostate cancer diagnosis, we develop an interface\nand conduct two experiments to study how AI assistance and performance feedback\nshape the decision making of domain experts. In Study 1, clinicians were asked\nto provide an initial diagnosis (human), then view the AI's prediction, and\nsubsequently finalize their decision (human-AI team). In Study 2 (after a\nmemory wash-out period), the same participants first received aggregated\nperformance statistics from Study 1, specifically their own performance, the\nAI's performance, and their human-AI team performance, and then directly viewed\nthe AI's prediction before making their diagnosis (i.e., no independent initial\ndiagnosis). These two workflows represent realistic ways that clinical AI tools\nmight be used in practice, where the second study simulates a scenario where\ndoctors can adjust their reliance and trust on AI based on prior performance\nfeedback. Our findings show that, while human-AI teams consistently outperform\nhumans alone, they still underperform the AI due to under-reliance, similar to\nprior studies with crowdworkers. Providing clinicians with performance feedback\ndid not significantly improve the performance of human-AI teams, although\nshowing AI decisions in advance nudges people to follow AI more. Meanwhile, we\nobserve that the ensemble of human-AI teams can outperform AI alone, suggesting\npromising directions for human-AI collaboration.",
      "tldr_zh": "本研究探讨了放射科医生在AI辅助下进行前列腺癌MRI诊断时，如何适当地依赖AI，通过设计两个实验评估AI辅助和性能反馈的影响。在实验1中，医生先独立诊断，然后参考AI预测再最终决定；在实验2中，医生先获得性能反馈（如自身、AI和团队表现），然后直接查看AI预测。结果显示，human-AI team的表现优于人类单独，但劣于AI单独，主要由于under-reliance；提供性能反馈未显著改善团队表现，但提前显示AI决定会促使医生更多跟随AI。同时，human-AI team的集合可能优于AI单独，暗示了人类-AI合作的前景。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.CY",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.03482v1",
      "published_date": "2025-02-03 18:59:38 UTC",
      "updated_date": "2025-02-03 18:59:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:11:00.865828"
    },
    {
      "arxiv_id": "2502.05209v2",
      "title": "Model Tampering Attacks Enable More Rigorous Evaluations of LLM Capabilities",
      "title_zh": "模型篡改攻击使 LLM 能力的评估更加严格",
      "authors": [
        "Zora Che",
        "Stephen Casper",
        "Robert Kirk",
        "Anirudh Satheesh",
        "Stewart Slocum",
        "Lev E McKinney",
        "Rohit Gandikota",
        "Aidan Ewart",
        "Domenic Rosati",
        "Zichu Wu",
        "Zikui Cai",
        "Bilal Chughtai",
        "Yarin Gal",
        "Furong Huang",
        "Dylan Hadfield-Menell"
      ],
      "abstract": "Evaluations of large language model (LLM) risks and capabilities are\nincreasingly being incorporated into AI risk management and governance\nframeworks. Currently, most risk evaluations are conducted by designing inputs\nthat elicit harmful behaviors from the system. However, this approach suffers\nfrom two limitations. First, input-output evaluations cannot evaluate realistic\nrisks from open-weight models. Second, the behaviors identified during any\nparticular input-output evaluation can only lower-bound the model's\nworst-possible-case input-output behavior. As a complementary method for\neliciting harmful behaviors, we propose evaluating LLMs with model tampering\nattacks which allow for modifications to latent activations or weights. We pit\nstate-of-the-art techniques for removing harmful LLM capabilities against a\nsuite of 5 input-space and 6 model tampering attacks. In addition to\nbenchmarking these methods against each other, we show that (1) model\nresilience to capability elicitation attacks lies on a low-dimensional\nrobustness subspace; (2) the attack success rate of model tampering attacks can\nempirically predict and offer conservative estimates for the success of\nheld-out input-space attacks; and (3) state-of-the-art unlearning methods can\neasily be undone within 16 steps of fine-tuning. Together these results\nhighlight the difficulty of suppressing harmful LLM capabilities and show that\nmodel tampering attacks enable substantially more rigorous evaluations than\ninput-space attacks alone.",
      "tldr_zh": "该论文指出，当前评估大型语言模型 (LLM) 风险和能力的输入-输出方法存在局限性，包括无法评估开放权重模型的真实风险和仅提供最坏情况的下限。作者提出使用模型篡改攻击 (model tampering attacks) 作为补充方法，通过修改模型的潜在激活或权重来更严格地引发有害行为，并与5种输入空间攻击和6种现有技术进行对比。实验结果显示，模型对攻击的弹性位于一个低维度的鲁棒性子空间，且模型篡改攻击的成功率能保守预测输入空间攻击的成功率；此外，先进的无学习方法 (unlearning methods) 可以在16步微调内被撤销。这些发现突出了抑制有害LLM能力的难度，并证明模型篡改攻击能实现更全面的评估。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05209v2",
      "published_date": "2025-02-03 18:59:16 UTC",
      "updated_date": "2025-04-12 22:03:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:11:13.262112"
    },
    {
      "arxiv_id": "2502.01636v2",
      "title": "Lifelong Knowledge Editing requires Better Regularization",
      "title_zh": "终身知识编辑需要更好的正则化",
      "authors": [
        "Akshat Gupta",
        "Phudish Prateepamornkul",
        "Maochuan Lu",
        "Ahmed Alaa",
        "Thomas Hartvigsen",
        "Gopala Anumanchipalli"
      ],
      "abstract": "Knowledge editing is a promising way to improve factuality in large language\nmodels, but recent studies have shown significant model degradation during\nsequential editing. In this paper, we formalize the popular locate-then-edit\nmethods as a two-step fine-tuning process, allowing us to precisely identify\nthe root cause of this degradation. We show that model degradation occurs due\nto (1) over-optimization of internal activations and (2) continuous norm-growth\nof edited matrices. To mitigate these issues, we introduce two regularization\ntechniques: (1) Most-Probable Early Stopping (MPES) and (2) explicit Frobenius\nnorm-constraint. We demonstrate that applying these simple yet effective\nregularization techniques at key points in the editing process can\nsubstantially mitigate model degradation. Combining these regularization\nmethods enables scaling locate-then-edit methods to 10,000 edits while reducing\nediting time by 42-61%. These results show that targeted regularization is\nessential for lifelong knowledge editing.",
      "tldr_zh": "本论文探讨了在大语言模型中进行终身知识编辑时，连续编辑导致模型退化的问题，并将流行的locate-then-edit方法形式化为两步微调过程，以精确识别退化的根因：内部激活的过度优化和编辑矩阵的连续范数增长。针对这些问题，作者引入了Most-Probable Early Stopping (MPES)和显式Frobenius norm-constraint两种正则化技术，这些方法能显著缓解模型退化，支持扩展到10,000次编辑，并将编辑时间减少42-61%。研究结果强调，针对性正则化是实现高效终身知识编辑的关键。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01636v2",
      "published_date": "2025-02-03 18:59:14 UTC",
      "updated_date": "2025-05-21 17:58:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:11:24.250883"
    },
    {
      "arxiv_id": "2502.01635v1",
      "title": "The AI Agent Index",
      "title_zh": "翻译失败",
      "authors": [
        "Stephen Casper",
        "Luke Bailey",
        "Rosco Hunter",
        "Carson Ezell",
        "Emma Cabalé",
        "Michael Gerovitch",
        "Stewart Slocum",
        "Kevin Wei",
        "Nikola Jurkovic",
        "Ariba Khan",
        "Phillip J. K. Christoffersen",
        "A. Pinar Ozisik",
        "Rakshit Trivedi",
        "Dylan Hadfield-Menell",
        "Noam Kolt"
      ],
      "abstract": "Leading AI developers and startups are increasingly deploying agentic AI\nsystems that can plan and execute complex tasks with limited human involvement.\nHowever, there is currently no structured framework for documenting the\ntechnical components, intended uses, and safety features of agentic systems. To\nfill this gap, we introduce the AI Agent Index, the first public database to\ndocument information about currently deployed agentic AI systems. For each\nsystem that meets the criteria for inclusion in the index, we document the\nsystem's components (e.g., base model, reasoning implementation, tool use),\napplication domains (e.g., computer use, software engineering), and risk\nmanagement practices (e.g., evaluation results, guardrails), based on publicly\navailable information and correspondence with developers. We find that while\ndevelopers generally provide ample information regarding the capabilities and\napplications of agentic systems, they currently provide limited information\nregarding safety and risk management practices. The AI Agent Index is available\nonline at https://aiagentindex.mit.edu/",
      "tldr_zh": "该研究引入了AI Agent Index，这是首个公开数据库，用于记录已部署的代理式AI系统的技术组件、预期用途和安全特性，以填补现有框架的空白。研究团队基于公开信息和开发者通信，文档化了这些系统的关键元素，包括基础模型、推理实现、工具使用等组件，应用领域（如计算机使用和软件工程），以及风险管理实践（如评估结果和防护措施）。分析发现，虽然开发者广泛提供系统能力和应用相关的信息，但对安全和风险管理的披露仍较为有限。该数据库现已上线，可通过https://aiagentindex.mit.edu/访问，以促进代理式AI系统的透明度和改进。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Accompanying website: https://aiagentindex.mit.edu/",
      "pdf_url": "http://arxiv.org/pdf/2502.01635v1",
      "published_date": "2025-02-03 18:59:13 UTC",
      "updated_date": "2025-02-03 18:59:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:11:35.809727"
    },
    {
      "arxiv_id": "2502.01634v1",
      "title": "Online Gradient Boosting Decision Tree: In-Place Updates for Efficient Adding/Deleting Data",
      "title_zh": "在线梯度提升决策树：就地更新用于高效添加/删除数据",
      "authors": [
        "Huawei Lin",
        "Jun Woo Chung",
        "Yingjie Lao",
        "Weijie Zhao"
      ],
      "abstract": "Gradient Boosting Decision Tree (GBDT) is one of the most popular machine\nlearning models in various applications. However, in the traditional settings,\nall data should be simultaneously accessed in the training procedure: it does\nnot allow to add or delete any data instances after training. In this paper, we\npropose an efficient online learning framework for GBDT supporting both\nincremental and decremental learning. To the best of our knowledge, this is the\nfirst work that considers an in-place unified incremental and decremental\nlearning on GBDT. To reduce the learning cost, we present a collection of\noptimizations for our framework, so that it can add or delete a small fraction\nof data on the fly. We theoretically show the relationship between the\nhyper-parameters of the proposed optimizations, which enables trading off\naccuracy and cost on incremental and decremental learning. The backdoor attack\nresults show that our framework can successfully inject and remove backdoor in\na well-trained model using incremental and decremental learning, and the\nempirical results on public datasets confirm the effectiveness and efficiency\nof our proposed online learning framework and optimizations.",
      "tldr_zh": "本文提出了一种在线 Gradient Boosting Decision Tree (GBDT) 框架，支持增量 learning 和 decremental learning，实现高效的 in-place 数据添加或删除，这是在 GBDT 上首次统一处理此类操作。为了降低学习成本，该框架引入了一系列优化，并理论分析了超参数之间的关系，允许用户在准确性和计算效率之间进行权衡。实验结果显示，该框架在公开数据集上表现出色，且在 backdoor attack 测试中成功实现了后门的注入和移除。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "25 pages, 11 figures, 16 tables. Keywords: Decremental Learning,\n  Incremental Learning, Machine Unlearning, Online Learning, Gradient Boosting\n  Decision Trees, GBDTs",
      "pdf_url": "http://arxiv.org/pdf/2502.01634v1",
      "published_date": "2025-02-03 18:59:04 UTC",
      "updated_date": "2025-02-03 18:59:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:11:48.565714"
    },
    {
      "arxiv_id": "2502.01633v1",
      "title": "Adversarial Reasoning at Jailbreaking Time",
      "title_zh": "翻译失败",
      "authors": [
        "Mahdi Sabbaghi",
        "Paul Kassianik",
        "George Pappas",
        "Yaron Singer",
        "Amin Karbasi",
        "Hamed Hassani"
      ],
      "abstract": "As large language models (LLMs) are becoming more capable and widespread, the\nstudy of their failure cases is becoming increasingly important. Recent\nadvances in standardizing, measuring, and scaling test-time compute suggest new\nmethodologies for optimizing models to achieve high performance on hard tasks.\nIn this paper, we apply these advances to the task of model jailbreaking:\neliciting harmful responses from aligned LLMs. We develop an adversarial\nreasoning approach to automatic jailbreaking via test-time computation that\nachieves SOTA attack success rates (ASR) against many aligned LLMs, even the\nones that aim to trade inference-time compute for adversarial robustness. Our\napproach introduces a new paradigm in understanding LLM vulnerabilities, laying\nthe foundation for the development of more robust and trustworthy AI systems.",
      "tldr_zh": "本论文探讨了大型语言模型（LLMs）的失败案例，提出了一种基于测试时间计算的对抗性推理方法，用于自动攻破对齐的LLMs，从而诱导有害响应。该方法利用标准化、测量和扩展测试时间计算的最新进展，优化攻击策略，并在多种对齐LLMs上实现了最先进的攻击成功率（SOTA ASR），即使针对那些通过增加推理计算来提升鲁棒性的模型。实验结果揭示了LLMs的潜在漏洞，并为开发更可靠和可信赖的AI系统奠定了基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01633v1",
      "published_date": "2025-02-03 18:59:01 UTC",
      "updated_date": "2025-02-03 18:59:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:12:00.265991"
    },
    {
      "arxiv_id": "2502.01630v1",
      "title": "TReMu: Towards Neuro-Symbolic Temporal Reasoning for LLM-Agents with Memory in Multi-Session Dialogues",
      "title_zh": "翻译失败",
      "authors": [
        "Yubin Ge",
        "Salvatore Romeo",
        "Jason Cai",
        "Raphael Shu",
        "Monica Sunkara",
        "Yassine Benajiba",
        "Yi Zhang"
      ],
      "abstract": "Temporal reasoning in multi-session dialogues presents a significant\nchallenge which has been under-studied in previous temporal reasoning\nbenchmarks. To bridge this gap, we propose a new evaluation task for temporal\nreasoning in multi-session dialogues and introduce an approach to construct a\nnew benchmark by augmenting dialogues from LoCoMo and creating multi-choice\nQAs. Furthermore, we present TReMu, a new framework aimed at enhancing the\ntemporal reasoning capabilities of LLM-agents in this context. Specifically,\nthe framework employs \\textit{time-aware memorization} through timeline\nsummarization, generating retrievable memory by summarizing events in each\ndialogue session with their inferred dates. Additionally, we integrate\n\\textit{neuro-symbolic temporal reasoning}, where LLMs generate Python code to\nperform temporal calculations and select answers. Experimental evaluations on\npopular LLMs demonstrate that our benchmark is challenging, and the proposed\nframework significantly improves temporal reasoning performance compared to\nbaseline methods, raising from 29.83 on GPT-4o via standard prompting to 77.67\nvia our approach and highlighting its effectiveness in addressing temporal\nreasoning in multi-session dialogues.",
      "tldr_zh": "这篇论文针对多会话对话中的时间推理挑战，提出一个新评估任务和基准，通过增强 LoCoMo 数据集创建多选 QA，以填补现有研究的空白。TReMu 框架通过 time-aware memorization（利用时间线总结生成可检索记忆）和 neuro-symbolic temporal reasoning（LLMs 生成 Python 代码进行时间计算及答案选择）来提升 LLM-agents 的时间推理能力。实验结果显示，该框架显著改善性能，例如在 GPT-4o 上将标准提示下的 29.83 准确率提高到 77.67，证明其在处理多会话对话中的有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01630v1",
      "published_date": "2025-02-03 18:58:19 UTC",
      "updated_date": "2025-02-03 18:58:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:12:12.315973"
    },
    {
      "arxiv_id": "2502.01619v2",
      "title": "Learning to Generate Unit Tests for Automated Debugging",
      "title_zh": "翻译失败",
      "authors": [
        "Archiki Prasad",
        "Elias Stengel-Eskin",
        "Justin Chih-Yao Chen",
        "Zaid Khan",
        "Mohit Bansal"
      ],
      "abstract": "Unit tests (UTs) play an instrumental role in assessing code correctness as\nwell as providing feedback to large language models (LLMs), motivating\nautomated test generation. However, we uncover a trade-off between generating\nunit test inputs that reveal errors when given a faulty code and correctly\npredicting the unit test output without access to the gold solution. To address\nthis trade-off, we propose UTGen, which teaches LLMs to generate unit test\ninputs that reveal errors along with their correct expected outputs based on\ntask descriptions. Since model-generated tests can provide noisy signals (e.g.,\nfrom incorrectly predicted outputs), we propose UTDebug that (i) scales UTGen\nvia test-time compute to improve UT output prediction, and (ii) validates and\nbacktracks edits based on multiple generated UTs to avoid overfitting, and\nhelps LLMs debug effectively. We show that UTGen outperforms other LLM-based\nbaselines by 7.59% based on a metric measuring the presence of both\nerror-revealing UT inputs and correct UT outputs. When used with UTDebug, we\nfind that feedback from UTGen's unit tests improves pass@1 accuracy of Qwen2.5\n32B on HumanEvalFix and our own harder debugging split of MBPP+ by over 3.17%\nand 12.35% (respectively) over other LLM-based UT generation baselines. Lastly,\nwe demonstrate that UTGen is a better judge for code correctness, outperforming\na state-of-the-art trained 8B reward model by 4.43% on HumanEval+ with\nbest-of-10 sampling using Qwen2.5 7B.",
      "tldr_zh": "该论文探讨了生成单元测试（UTs）以支持自动调试的挑战，特别是在揭示代码错误与准确预测输出之间的权衡问题。作者提出 UTGen 方法，教大型语言模型（LLMs）基于任务描述生成能暴露错误的 UT 输入及其正确预期输出。进一步，UTDebug 通过测试时计算优化 UT 输出预测，并利用多个生成的 UTs 进行验证和回溯编辑，以避免过拟合并提升调试效果。实验结果显示，UTGen 比其他 LLM 基线在相关指标上提高 7.59%，并在结合 UTDebug 后，使 Qwen2.5 32B 在 HumanEvalFix 和 MBPP+ 上的 pass@1 准确率分别提升超过 3.17% 和 12.35%；此外，UTGen 作为代码正确性判断器，也优于 state-of-the-art 的 8B 奖励模型。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "First two authors contributed equally. Dataset and Code:\n  https://github.com/archiki/UTGenDebug",
      "pdf_url": "http://arxiv.org/pdf/2502.01619v2",
      "published_date": "2025-02-03 18:51:43 UTC",
      "updated_date": "2025-02-26 18:03:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:12:27.005016"
    },
    {
      "arxiv_id": "2502.01618v3",
      "title": "A Probabilistic Inference Approach to Inference-Time Scaling of LLMs using Particle-Based Monte Carlo Methods",
      "title_zh": "翻译失败",
      "authors": [
        "Isha Puri",
        "Shivchander Sudalairaj",
        "Guangxuan Xu",
        "Kai Xu",
        "Akash Srivastava"
      ],
      "abstract": "Large language models (LLMs) have achieved significant performance gains via\nscaling up model sizes and/or data. However, recent evidence suggests\ndiminishing returns from such approaches, motivating scaling the computation\nspent at inference time. Existing inference-time scaling methods, usually with\nreward models, cast the task as a search problem, which tends to be vulnerable\nto reward hacking as a consequence of approximation errors in reward models. In\nthis paper, we instead cast inference-time scaling as a probabilistic inference\ntask and leverage sampling-based techniques to explore the typical set of the\nstate distribution of a state-space model with an approximate likelihood,\nrather than optimize for its mode directly. We propose a novel inference-time\nscaling approach by adapting particle-based Monte Carlo methods to this task.\nOur empirical evaluation demonstrates that our methods have a 4-16x better\nscaling rate over our deterministic search counterparts on various challenging\nmathematical reasoning tasks. Using our approach, we show that\nQwen2.5-Math-1.5B-Instruct can surpass GPT-4o accuracy in only 4 rollouts,\nwhile Qwen2.5-Math-7B-Instruct scales to o1 level accuracy in only 32 rollouts.\nOur work not only presents an effective method to inference-time scaling, but\nalso connects the rich literature in probabilistic inference with\ninference-time scaling of LLMs to develop more robust algorithms in future\nwork. Code, videos, and further information available at\nhttps://probabilistic-inference-scaling.github.io.",
      "tldr_zh": "本研究提出了一种基于概率推理的方法，用于大型语言模型(LLMs)的推理时扩展(inference-time scaling)，通过适应粒子-based Monte Carlo 方法来探索状态空间模型的状态分布的典型集，而不是直接优化模式，从而避免了传统搜索方法因奖励模型近似错误而导致的奖励黑客(reward hacking)问题。实验结果显示，该方法在各种数学推理任务上比确定性搜索方法具有4-16倍的扩展率优势，例如Qwen2.5-Math-1.5B-Instruct仅需4次回合就超过GPT-4o的准确率，而Qwen2.5-Math-7B-Instruct在32次回合内达到o1级别准确率。该方法不仅有效提升了LLMs的性能，还将概率推理文献与推理时扩展相结合，为未来开发更鲁棒的算法提供了新路径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01618v3",
      "published_date": "2025-02-03 18:50:50 UTC",
      "updated_date": "2025-02-11 23:52:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:12:36.882242"
    },
    {
      "arxiv_id": "2502.01718v3",
      "title": "ACECODER: Acing Coder RL via Automated Test-Case Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Huaye Zeng",
        "Dongfu Jiang",
        "Haozhe Wang",
        "Ping Nie",
        "Xiaotong Chen",
        "Wenhu Chen"
      ],
      "abstract": "Most progress in recent coder models has been driven by supervised\nfine-tuning (SFT), while the potential of reinforcement learning (RL) remains\nlargely unexplored, primarily due to the lack of reliable reward data/model in\nthe code domain. In this paper, we address this challenge by leveraging\nautomated large-scale test-case synthesis to enhance code model training.\nSpecifically, we design a pipeline that generates extensive (question,\ntest-cases) pairs from existing code data. Using these test cases, we construct\npreference pairs based on pass rates over sampled programs to train reward\nmodels with Bradley-Terry loss. It shows an average of 10-point improvement for\nLlama-3.1-8B-Ins and 5-point improvement for Qwen2.5-Coder-7B-Ins through\nbest-of-32 sampling, making the 7B model on par with 236B DeepSeek-V2.5.\nFurthermore, we conduct reinforcement learning with both reward models and\ntest-case pass rewards, leading to consistent improvements across HumanEval,\nMBPP, BigCodeBench, and LiveCodeBench (V4). Notably, we follow the R1-style\ntraining to start from Qwen2.5-Coder-base directly and show that our RL\ntraining can improve model on HumanEval-plus by over 25\\% and MBPP-plus by 6\\%\nfor merely 80 optimization steps. We believe our results highlight the huge\npotential of reinforcement learning in coder models.",
      "tldr_zh": "本研究提出ACECODER框架，通过自动化测试用例合成来提升代码模型的强化学习(RL)训练，解决代码领域缺乏可靠奖励模型的问题。具体方法包括设计管道生成大量(问题、测试用例)对，并基于采样程序的通过率使用Bradley-Terry loss训练奖励模型，结果显示Llama-3.1-8B-Ins提升10点、Qwen2.5-Coder-7B-Ins提升5点，使7B模型性能媲美236B DeepSeek-V2.5。进一步应用RL训练在HumanEval、MBPP、BigCodeBench和LiveCodeBench (V4)上取得持续改进，仅需80个优化步骤，即在HumanEval-plus上提高25%、MBPP-plus上提高6%。该工作突显了RL在代码模型中的巨大潜力。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "9 pages, 1 figure, 8 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.01718v3",
      "published_date": "2025-02-03 18:46:04 UTC",
      "updated_date": "2025-02-10 18:40:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:12:50.150995"
    },
    {
      "arxiv_id": "2502.01612v2",
      "title": "Self-Improving Transformers Overcome Easy-to-Hard and Length Generalization Challenges",
      "title_zh": "自我改进的 Transformer 克服了从易到难以及长度泛化的挑战",
      "authors": [
        "Nayoung Lee",
        "Ziyang Cai",
        "Avi Schwarzschild",
        "Kangwook Lee",
        "Dimitris Papailiopoulos"
      ],
      "abstract": "Large language models often struggle with length generalization and solving\ncomplex problem instances beyond their training distribution. We present a\nself-improvement approach where models iteratively generate and learn from\ntheir own solutions, progressively tackling harder problems while maintaining a\nstandard transformer architecture. Across diverse tasks including arithmetic,\nstring manipulation, and maze solving, self-improving enables models to solve\nproblems far beyond their initial training distribution-for instance,\ngeneralizing from 10-digit to 100-digit addition without apparent saturation.\nWe observe that in some cases filtering for correct self-generated examples\nleads to exponential improvements in out-of-distribution performance across\ntraining rounds. Additionally, starting from pretrained models significantly\naccelerates this self-improvement process for several tasks. Our results\ndemonstrate how controlled weak-to-strong curricula can systematically teach a\nmodel logical extrapolation without any changes to the positional embeddings,\nor the model architecture.",
      "tldr_zh": "本文提出了一种自-improvement 方法，让 Transformer 模型通过迭代生成并学习自己的解决方案，逐步克服长度泛化和从简单到复杂问题的挑战，同时保持标准架构。实验在算术、字符串操作和迷宫求解等任务中显示，模型能泛化到远超出训练分布的问题，例如从 10 位数加法扩展到 100 位数加法，且性能无明显饱和。通过过滤正确的自生成示例，分布外性能实现指数级提升，而从预训练模型起步可加速这一过程。结果证明，控制的弱-to-strong 课程能系统地提升模型的逻辑外推能力，而无需改变位置嵌入或架构。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Added references",
      "pdf_url": "http://arxiv.org/pdf/2502.01612v2",
      "published_date": "2025-02-03 18:45:22 UTC",
      "updated_date": "2025-02-13 05:32:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:13:01.630951"
    },
    {
      "arxiv_id": "2502.01600v3",
      "title": "Reinforcement Learning for Long-Horizon Interactive LLM Agents",
      "title_zh": "针对长时域交互式 LLM ",
      "authors": [
        "Kevin Chen",
        "Marco Cusumano-Towner",
        "Brody Huval",
        "Aleksei Petrenko",
        "Jackson Hamburger",
        "Vladlen Koltun",
        "Philipp Krähenbühl"
      ],
      "abstract": "Interactive digital agents (IDAs) leverage APIs of stateful digital\nenvironments to perform tasks in response to user requests. While IDAs powered\nby instruction-tuned large language models (LLMs) can react to feedback from\ninterface invocations in multi-step exchanges, they have not been trained in\ntheir respective digital environments. Prior methods accomplish less than half\nof tasks in sophisticated benchmarks such as AppWorld. We present a\nreinforcement learning (RL) approach that trains IDAs directly in their target\nenvironments. We formalize this training as a partially observable Markov\ndecision process and derive LOOP, a data- and memory-efficient variant of\nproximal policy optimization. LOOP uses no value network and maintains exactly\none copy of the underlying LLM in memory, making its implementation\nstraightforward and as memory-efficient as fine-tuning a single LLM. A\n32-billion-parameter agent trained with LOOP in the AppWorld environment\noutperforms the much larger OpenAI o1 agent by 9 percentage points (15%\nrelative). To our knowledge, this is the first reported application of RL to\nIDAs that interact with a stateful, multi-domain, multi-app environment via\ndirect API calls. Our analysis sheds light on the effectiveness of RL in this\narea, showing that the agent learns to consult the API documentation, avoid\nunwarranted assumptions, minimize confabulation, and recover from setbacks.",
      "tldr_zh": "该论文探讨了使用强化学习（RL）训练长时序交互式大型语言模型（LLMs）代理（Interactive LLMs Agents），以提升它们在复杂数字环境中的任务执行能力。作者将训练过程形式化为部分可观测Markov决策过程（POMDP），并提出LOOP，一种基于近端策略优化（PPO）的变体，该方法无需价值网络，仅维护一个LLM副本，从而实现数据和内存高效。实验结果显示，在AppWorld基准环境中，训练的32B参数代理比OpenAI o1代理高出9个百分点（15%相对提升），展示了代理学会咨询API文档、避免不当假设、减少虚构并从错误中恢复的关键优势。该研究首次将RL应用于与有状态、多域、多应用的交互式代理，推进了可靠代理的开发。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01600v3",
      "published_date": "2025-02-03 18:35:42 UTC",
      "updated_date": "2025-03-08 05:23:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:13:12.719951"
    },
    {
      "arxiv_id": "2502.01591v1",
      "title": "Improving Transformer World Models for Data-Efficient RL",
      "title_zh": "翻译失败",
      "authors": [
        "Antoine Dedieu",
        "Joseph Ortiz",
        "Xinghua Lou",
        "Carter Wendelken",
        "Wolfgang Lehrach",
        "J Swaroop Guntupalli",
        "Miguel Lazaro-Gredilla",
        "Kevin Patrick Murphy"
      ],
      "abstract": "We present an approach to model-based RL that achieves a new state of the art\nperformance on the challenging Craftax-classic benchmark, an open-world 2D\nsurvival game that requires agents to exhibit a wide range of general abilities\n-- such as strong generalization, deep exploration, and long-term reasoning.\nWith a series of careful design choices aimed at improving sample efficiency,\nour MBRL algorithm achieves a reward of 67.4% after only 1M environment steps,\nsignificantly outperforming DreamerV3, which achieves 53.2%, and, for the first\ntime, exceeds human performance of 65.0%. Our method starts by constructing a\nSOTA model-free baseline, using a novel policy architecture that combines CNNs\nand RNNs. We then add three improvements to the standard MBRL setup: (a) \"Dyna\nwith warmup\", which trains the policy on real and imaginary data, (b) \"nearest\nneighbor tokenizer\" on image patches, which improves the scheme to create the\ntransformer world model (TWM) inputs, and (c) \"block teacher forcing\", which\nallows the TWM to reason jointly about the future tokens of the next timestep.",
      "tldr_zh": "这篇论文提出了一种改进的基于模型的强化学习（MBRL）方法，旨在提升Transformer世界模型（TWM）的样本效率，在Craftax-classic基准——一个需要强泛化、深度探索和长期推理的开放世界2D生存游戏上——实现了新的最先进性能。方法包括构建一个结合CNNs和RNNs的策略架构作为基线，并引入三个关键改进：(a) \"Dyna with warmup\" 用于在真实和想象数据上训练策略，(b) \"nearest neighbor tokenizer\" 对图像补丁进行处理以优化TWM输入，以及(c) \"block teacher forcing\" 允许TWM联合推理未来标记。实验结果显示，该算法在仅1M环境步骤后达到67.4%的奖励，比DreamerV3的53.2%显著提升，并首次超过了人类的65.0%，证明了其在数据高效RL中的优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01591v1",
      "published_date": "2025-02-03 18:25:17 UTC",
      "updated_date": "2025-02-03 18:25:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:13:25.811695"
    },
    {
      "arxiv_id": "2502.01587v1",
      "title": "Verbalized Bayesian Persuasion",
      "title_zh": "语言化的贝叶斯说服",
      "authors": [
        "Wenhao Li",
        "Yue Lin",
        "Xiangfeng Wang",
        "Bo Jin",
        "Hongyuan Zha",
        "Baoxiang Wang"
      ],
      "abstract": "Information design (ID) explores how a sender influence the optimal behavior\nof receivers to achieve specific objectives. While ID originates from everyday\nhuman communication, existing game-theoretic and machine learning methods often\nmodel information structures as numbers, which limits many applications to toy\ngames. This work leverages LLMs and proposes a verbalized framework in Bayesian\npersuasion (BP), which extends classic BP to real-world games involving human\ndialogues for the first time. Specifically, we map the BP to a verbalized\nmediator-augmented extensive-form game, where LLMs instantiate the sender and\nreceiver. To efficiently solve the verbalized game, we propose a generalized\nequilibrium-finding algorithm combining LLM and game solver. The algorithm is\nreinforced with techniques including verbalized commitment assumptions,\nverbalized obedience constraints, and information obfuscation. Numerical\nexperiments in dialogue scenarios, such as recommendation letters, courtroom\ninteractions, and law enforcement, validate that our framework can both\nreproduce theoretical results in classic BP and discover effective persuasion\nstrategies in more complex natural language and multi-stage scenarios.",
      "tldr_zh": "这篇论文提出了一种基于大型语言模型(LLMs)的 Verbalized Bayesian Persuasion 框架，将经典 Bayesian Persuasion 扩展到真实世界的人类对话场景中，旨在解决现有方法对信息结构的数字建模限制。框架将 Bayesian Persuasion 映射到一个 verbalized mediator-augmented extensive-form game，使用 LLMs 模拟发送者和接收者，并开发了一个结合 LLM 和游戏求解器的通用均衡寻找算法，辅以 verbalized commitment assumptions、verbalized obedience constraints 和 information obfuscation 等技术。实验在推荐信、法庭互动和执法等对话场景中验证了该框架，不仅能重现经典 Bayesian Persuasion 的理论结果，还在复杂多阶段的自然语言环境中发现了有效的说服策略。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.GT",
      "comment": "63 pages, 21 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.01587v1",
      "published_date": "2025-02-03 18:20:10 UTC",
      "updated_date": "2025-02-03 18:20:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:13:37.498757"
    },
    {
      "arxiv_id": "2502.01584v3",
      "title": "PhD Knowledge Not Required: A Reasoning Challenge for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zixuan Wu",
        "Francesca Lucchetti",
        "Aleksander Boruch-Gruszecki",
        "Jingmiao Zhao",
        "Carolyn Jane Anderson",
        "Joydeep Biswas",
        "Federico Cassano",
        "Molly Q Feldman",
        "Arjun Guha"
      ],
      "abstract": "Existing benchmarks for frontier models often test specialized, \"PhD-level\"\nknowledge that is difficult for non-experts to grasp. In contrast, we present a\nbenchmark with 594 problems based on the NPR Sunday Puzzle Challenge that\nrequires only general knowledge. Our benchmark is challenging for both humans\nand models; however correct solutions are easy to verify, and models' mistakes\nare easy to spot. As LLMs are more widely deployed in society, we believe it is\nuseful to develop benchmarks for frontier models that humans can understand\nwithout the need for deep domain expertise.\n  Our work reveals capability gaps that are not evident in existing benchmarks:\nOpenAI o1 significantly outperforms other reasoning models on our benchmark,\ndespite being on par with other models when tested on benchmarks that test\nspecialized knowledge. Furthermore, our analysis of reasoning outputs uncovers\nnew kinds of failures. DeepSeek R1, for instance, often concedes with \"I give\nup\" before providing an answer that it knows is wrong. R1 can also be\nremarkably \"uncertain\" in its output and in rare cases, it does not \"finish\nthinking,\" which suggests the need for techniques to \"wrap up\" before the\ncontext window limit is reached. We also quantify the effectiveness of\nreasoning longer to identify the point beyond which more reasoning is unlikely\nto improve accuracy on our benchmark.",
      "tldr_zh": "这篇论文提出一个基于一般知识的基准测试，包含594个NPR Sunday Puzzle Challenge问题，用于评估大型语言模型(LLMs)的推理能力，而非专业或“博士级”知识。该基准易于人类理解和验证，能揭示现有测试未暴露的能力差距，例如OpenAI o1在该基准上显著优于其他模型，而DeepSeek R1则常出现不确定性或提前“放弃”的失败模式。通过分析，论文量化了推理长度的效果，指出更长的推理在一定点后不再显著提升准确率。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01584v3",
      "published_date": "2025-02-03 18:10:38 UTC",
      "updated_date": "2025-03-31 14:21:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:13:48.642157"
    },
    {
      "arxiv_id": "2502.01573v1",
      "title": "Next Steps in LLM-Supported Java Verification",
      "title_zh": "LLM 支持的 Java 验证的下一步",
      "authors": [
        "Samuel Teuber",
        "Bernhard Beckert"
      ],
      "abstract": "Recent work has shown that Large Language Models (LLMs) are not only a\nsuitable tool for code generation but also capable of generating\nannotation-based code specifications. Scaling these methodologies may allow us\nto deduce provable correctness guarantees for large-scale software systems. In\ncomparison to other LLM tasks, the application field of deductive verification\nhas the notable advantage of providing a rigorous toolset to check\nLLM-generated solutions. This short paper provides early results on how this\nrigorous toolset can be used to reliably elicit correct specification\nannotations from an unreliable LLM oracle.",
      "tldr_zh": "该研究探讨了大型语言模型（LLMs）在 Java 代码验证中的潜在应用，强调 LLMs 不仅能生成代码，还能创建基于注解的代码规范，从而为大规模软件系统提供可证明的正确性保证。与其他 LLM 任务不同，演绎验证（deductive verification）的严格工具集可用于检查和验证 LLM 生成的解决方案。论文呈现早期结果，展示了如何从不可靠的 LLM 预言机中可靠地获取正确的规范注解，为未来 LLM 支持的代码验证奠定基础。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG",
        "cs.LO"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted to NSE 2025, 1st International Workshop on Neuro-Symbolic\n  Software Engineering (ICSE Workshop), 6 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.01573v1",
      "published_date": "2025-02-03 17:55:50 UTC",
      "updated_date": "2025-02-03 17:55:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:14:00.143696"
    },
    {
      "arxiv_id": "2502.01568v5",
      "title": "Visual Theory of Mind Enables the Invention of Proto-Writing",
      "title_zh": "翻译失败",
      "authors": [
        "Benjamin A. Spiegel",
        "Lucas Gelfond",
        "George Konidaris"
      ],
      "abstract": "Symbolic writing systems are graphical semiotic codes that are ubiquitous in\nmodern society but are otherwise absent in the animal kingdom. Anthropological\nevidence suggests that the earliest forms of some writing systems originally\nconsisted of iconic pictographs, which signify their referent via visual\nresemblance. While previous studies have examined the emergence and,\nseparately, the evolution of pictographic systems through a computational lens,\nmost employ non-naturalistic methodologies that make it difficult to draw clear\nanalogies to human and animal cognition. We develop a multi-agent reinforcement\nlearning testbed for emergent communication called a Signification Game, and\nformulate a model of inferential communication that enables agents to leverage\nvisual theory of mind to communicate actions using pictographs. Our model,\nwhich is situated within a broader formalism for animal communication, sheds\nlight on the cognitive and cultural processes underlying the emergence of\nproto-writing.",
      "tldr_zh": "这篇论文探讨了象征性书写系统（symbolic writing systems）的起源，强调早期象形图（pictographs）通过视觉相似性来表示参照物的作用。作者开发了一个多智能体强化学习（multi-agent reinforcement learning）测试平台，名为 Signification Game，并提出一个推理通信模型，利用视觉 Theory of Mind 让代理通过象形图来通信动作。该模型位于更广泛的动物通信形式主义中，揭示了认知和文化过程如何促成原始书写（proto-writing）的出现，并为人类和动物认知提供更自然的类比。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted for oral presentation at CogSci 2025, published here with\n  permission from organizers",
      "pdf_url": "http://arxiv.org/pdf/2502.01568v5",
      "published_date": "2025-02-03 17:50:37 UTC",
      "updated_date": "2025-05-10 19:24:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:14:13.006227"
    },
    {
      "arxiv_id": "2502.01564v1",
      "title": "MeetMap: Real-Time Collaborative Dialogue Mapping with LLMs in Online Meetings",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyue Chen",
        "Nathan Yap",
        "Xinyi Lu",
        "Aylin Gunal",
        "Xu Wang"
      ],
      "abstract": "Video meeting platforms display conversations linearly through transcripts or\nsummaries. However, ideas during a meeting do not emerge linearly. We leverage\nLLMs to create dialogue maps in real time to help people visually structure and\nconnect ideas. Balancing the need to reduce the cognitive load on users during\nthe conversation while giving them sufficient control when using AI, we explore\ntwo system variants that encompass different levels of AI assistance. In\nHuman-Map, AI generates summaries of conversations as nodes, and users create\ndialogue maps with the nodes. In AI-Map, AI produces dialogue maps where users\ncan make edits. We ran a within-subject experiment with ten pairs of users,\ncomparing the two MeetMap variants and a baseline. Users preferred MeetMap over\ntraditional methods for taking notes, which aligned better with their mental\nmodels of conversations. Users liked the ease of use for AI-Map due to the low\neffort demands and appreciated the hands-on opportunity in Human-Map for\nsense-making.",
      "tldr_zh": "本研究提出MeetMap，一种利用LLMs实现实时协作对话映射的系统，旨在解决在线会议中对话非线性呈现的问题。MeetMap探索两种变体：Human-Map，由AI生成对话摘要作为节点，用户手动创建地图；以及AI-Map，由AI自动生成完整地图，用户进行编辑，以平衡AI辅助和用户控制。在一项涉及十对用户的内部实验中，用户更偏好MeetMap，因为它更符合对话心理模型，且AI-Map提供低努力易用性，而Human-Map增强了参与感和意义构建。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "CSCW2025 Accepted",
      "pdf_url": "http://arxiv.org/pdf/2502.01564v1",
      "published_date": "2025-02-03 17:47:15 UTC",
      "updated_date": "2025-02-03 17:47:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:14:24.670438"
    },
    {
      "arxiv_id": "2502.01558v1",
      "title": "Search-Based Adversarial Estimates for Improving Sample Efficiency in Off-Policy Reinforcement Learning",
      "title_zh": "基于搜索的对抗性估计用于改进脱策略强化学习中的样本效率",
      "authors": [
        "Federico Malato",
        "Ville Hautamaki"
      ],
      "abstract": "Sample inefficiency is a long-lasting challenge in deep reinforcement\nlearning (DRL). Despite dramatic improvements have been made, the problem is\nfar from being solved and is especially challenging in environments with sparse\nor delayed rewards. In our work, we propose to use Adversarial Estimates as a\nnew, simple and efficient approach to mitigate this problem for a class of\nfeedback-based DRL algorithms. Our approach leverages latent similarity search\nfrom a small set of human-collected trajectories to boost learning, using only\nfive minutes of human-recorded experience. The results of our study show\nalgorithms trained with Adversarial Estimates converge faster than their\noriginal version. Moreover, we discuss how our approach could enable learning\nin feedback-based algorithms in extreme scenarios with very sparse rewards.",
      "tldr_zh": "本研究针对深度强化学习（DRL）中的样本效率问题，尤其是稀疏或延迟奖励的环境，提出了一种基于搜索的对抗估计（Adversarial Estimates）方法，以提升Off-Policy强化学习算法的效率。该方法利用少量人类收集轨迹（仅需五分钟记录）的潜在相似性搜索，辅助反馈-based DRL算法的训练，从而加速学习过程。实验结果显示，使用Adversarial Estimates的算法比原版更快收敛，并探讨了其在极端稀疏奖励场景下的潜力，为样本效率不足的DRL应用提供了简单有效的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted to International Conference on Machine Learning 2025.\n  Currently under peer-review",
      "pdf_url": "http://arxiv.org/pdf/2502.01558v1",
      "published_date": "2025-02-03 17:41:02 UTC",
      "updated_date": "2025-02-03 17:41:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:14:36.492020"
    },
    {
      "arxiv_id": "2502.01555v1",
      "title": "Query Brand Entity Linking in E-Commerce Search",
      "title_zh": "翻译失败",
      "authors": [
        "Dong Liu",
        "Sreyashi Nag"
      ],
      "abstract": "In this work, we address the brand entity linking problem for e-commerce\nsearch queries. The entity linking task is done by either i)a two-stage process\nconsisting of entity mention detection followed by entity disambiguation or ii)\nan end-to-end linking approaches that directly fetch the target entity given\nthe input text. The task presents unique challenges: queries are extremely\nshort (averaging 2.4 words), lack natural language structure, and must handle a\nmassive space of unique brands. We present a two-stage approach combining\nnamed-entity recognition with matching, and a novel end-to-end solution using\nextreme multi-class classification. We validate our solutions by both offline\nbenchmarks and the impact of online A/B test.",
      "tldr_zh": "本研究针对电商搜索中的品牌实体链接（entity linking）问题，提出两种解决方案：一种是两阶段方法，包括实体提及检测（entity mention detection）后结合命名实体识别（named-entity recognition）和匹配；另一种是创新的端到端方法，使用极端多类分类（extreme multi-class classification）。面对查询短小（平均2.4词）、缺乏自然语言结构以及大量独特品牌的挑战，这些方法能更有效地处理实体消岐（entity disambiguation）。通过离线基准测试和在线A/B test验证，结果显示该方法显著提升了实体链接的准确性和实用性。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01555v1",
      "published_date": "2025-02-03 17:37:37 UTC",
      "updated_date": "2025-02-03 17:37:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:14:48.470575"
    },
    {
      "arxiv_id": "2502.01550v1",
      "title": "FireCastNet: Earth-as-a-Graph for Seasonal Fire Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Dimitrios Michail",
        "Charalampos Davalas",
        "Lefki-Ioanna Panagiotou",
        "Ioannis Prapas",
        "Spyros Kondylatos",
        "Nikolaos Ioannis Bountos",
        "Ioannis Papoutsis"
      ],
      "abstract": "With climate change expected to exacerbate fire weather conditions, the\naccurate and timely anticipation of wildfires becomes increasingly crucial for\ndisaster mitigation. In this study, we utilize SeasFire, a comprehensive global\nwildfire dataset with climate, vegetation, oceanic indices, and human-related\nvariables, to enable seasonal wildfire forecasting with machine learning. For\nthe predictive analysis, we present FireCastNet, a novel architecture which\ncombines a 3D convolutional encoder with GraphCast, originally developed for\nglobal short-term weather forecasting using graph neural networks. FireCastNet\nis trained to capture the context leading to wildfires, at different spatial\nand temporal scales. Our investigation focuses on assessing the effectiveness\nof our model in predicting the presence of burned areas at varying forecasting\ntime horizons globally, extending up to six months into the future, and on how\ndifferent spatial or/and temporal context affects the performance. Our findings\ndemonstrate the potential of deep learning models in seasonal fire forecasting;\nlonger input time-series leads to more robust predictions, while integrating\nspatial information to capture wildfire spatio-temporal dynamics boosts\nperformance. Finally, our results hint that in order to enhance performance at\nlonger forecasting horizons, a larger receptive field spatially needs to be\nconsidered.",
      "tldr_zh": "该研究利用SeasFire数据集（包含气候、植被、海洋指数和人类相关变量）来实现季节性野火预测，提出FireCastNet模型，该模型结合3D convolutional encoder和GraphCast（基于图神经网络的架构），将地球视为图结构以捕捉野火的空间-temporal动态。FireCastNet能够预测全球烧毁区域的存在，预测期可达六个月。实验结果显示，更长的输入时间序列和空间信息整合显著提升预测性能，而为了改善更长预测期，需考虑更大的空间感受野。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01550v1",
      "published_date": "2025-02-03 17:30:45 UTC",
      "updated_date": "2025-02-03 17:30:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:15:00.414589"
    },
    {
      "arxiv_id": "2502.05208v1",
      "title": "Mitigation of Camouflaged Adversarial Attacks in Autonomous Vehicles--A Case Study Using CARLA Simulator",
      "title_zh": "翻译失败",
      "authors": [
        "Yago Romano Martinez",
        "Brady Carter",
        "Abhijeet Solanki",
        "Wesam Al Amiri",
        "Syed Rafay Hasan",
        "Terry N. Guo"
      ],
      "abstract": "Autonomous vehicles (AVs) rely heavily on cameras and artificial intelligence\n(AI) to make safe and accurate driving decisions. However, since AI is the core\nenabling technology, this raises serious cyber threats that hinder the\nlarge-scale adoption of AVs. Therefore, it becomes crucial to analyze the\nresilience of AV security systems against sophisticated attacks that manipulate\ncamera inputs, deceiving AI models. In this paper, we develop\ncamera-camouflaged adversarial attacks targeting traffic sign recognition (TSR)\nin AVs. Specifically, if the attack is initiated by modifying the texture of a\nstop sign to fool the AV's object detection system, thereby affecting the AV\nactuators. The attack's effectiveness is tested using the CARLA AV simulator\nand the results show that such an attack can delay the auto-braking response to\nthe stop sign, resulting in potential safety issues. We conduct extensive\nexperiments under various conditions, confirming that our new attack is\neffective and robust. Additionally, we address the attack by presenting\nmitigation strategies. The proposed attack and defense methods are applicable\nto other end-to-end trained autonomous cyber-physical systems.",
      "tldr_zh": "本论文研究了针对自动驾驶车辆（Autonomous Vehicles）的伪装式对抗攻击，焦点在于通过修改交通标志（如停止标志）的纹理来欺骗AI模型，导致车辆延迟制动并引发安全风险。使用CARLA Simulator进行实验，证明了这种攻击在各种条件下有效且鲁棒。论文进一步提出了缓解策略，以增强AV安全系统，并表示这些方法适用于其他端到端训练的自主cyber-physical系统。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.05208v1",
      "published_date": "2025-02-03 17:30:43 UTC",
      "updated_date": "2025-02-03 17:30:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:15:13.747812"
    },
    {
      "arxiv_id": "2502.01549v1",
      "title": "VideoRAG: Retrieval-Augmented Generation with Extreme Long-Context Videos",
      "title_zh": "翻译失败",
      "authors": [
        "Xubin Ren",
        "Lingrui Xu",
        "Long Xia",
        "Shuaiqiang Wang",
        "Dawei Yin",
        "Chao Huang"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) has demonstrated remarkable success in\nenhancing Large Language Models (LLMs) through external knowledge integration,\nyet its application has primarily focused on textual content, leaving the rich\ndomain of multi-modal video knowledge predominantly unexplored. This paper\nintroduces VideoRAG, the first retrieval-augmented generation framework\nspecifically designed for processing and understanding extremely long-context\nvideos. Our core innovation lies in its dual-channel architecture that\nseamlessly integrates (i) graph-based textual knowledge grounding for capturing\ncross-video semantic relationships, and (ii) multi-modal context encoding for\nefficiently preserving visual features. This novel design empowers VideoRAG to\nprocess unlimited-length videos by constructing precise knowledge graphs that\nspan multiple videos while maintaining semantic dependencies through\nspecialized multi-modal retrieval paradigms. Through comprehensive empirical\nevaluation on our proposed LongerVideos benchmark-comprising over 160 videos\ntotaling 134+ hours across lecture, documentary, and entertainment\ncategories-VideoRAG demonstrates substantial performance compared to existing\nRAG alternatives and long video understanding methods. The source code of\nVideoRAG implementation and the benchmark dataset are openly available at:\nhttps://github.com/HKUDS/VideoRAG.",
      "tldr_zh": "本论文提出VideoRAG，这是首个专为处理极长上下文视频设计的检索增强生成（RAG）框架，旨在扩展RAG应用于多模态视频领域，解决传统方法在视频知识整合中的局限性。核心创新在于其双通道架构，包括基于图的文本知识grounding（捕捉跨视频语义关系）和多模态上下文编码（高效保留视觉特征），从而构建精确的知识图谱并支持无限长视频的处理。实验在自提出的LongerVideos基准上进行，该基准包含160+视频，总时长超过134小时，涵盖讲座、纪录片和娱乐类别，结果显示VideoRAG显著优于现有RAG方法和长视频理解技术。源代码和数据集已公开在https://github.com/HKUDS/VideoRAG。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01549v1",
      "published_date": "2025-02-03 17:30:19 UTC",
      "updated_date": "2025-02-03 17:30:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:15:24.708233"
    },
    {
      "arxiv_id": "2502.01540v1",
      "title": "What is a Number, That a Large Language Model May Know It?",
      "title_zh": "翻译失败",
      "authors": [
        "Raja Marjieh",
        "Veniamin Veselovsky",
        "Thomas L. Griffiths",
        "Ilia Sucholutsky"
      ],
      "abstract": "Numbers are a basic part of how humans represent and describe the world\naround them. As a consequence, learning effective representations of numbers is\ncritical for the success of large language models as they become more\nintegrated into everyday decisions. However, these models face a challenge:\ndepending on context, the same sequence of digit tokens, e.g., 911, can be\ntreated as a number or as a string. What kind of representations arise from\nthis duality, and what are its downstream implications? Using a\nsimilarity-based prompting technique from cognitive science, we show that LLMs\nlearn representational spaces that blend string-like and numerical\nrepresentations. In particular, we show that elicited similarity judgments from\nthese models over integer pairs can be captured by a combination of Levenshtein\nedit distance and numerical Log-Linear distance, suggesting an entangled\nrepresentation. In a series of experiments we show how this entanglement is\nreflected in the latent embeddings, how it can be reduced but not entirely\neliminated by context, and how it can propagate into a realistic decision\nscenario. These results shed light on a representational tension in transformer\nmodels that must learn what a number is from text input.",
      "tldr_zh": "这篇论文探讨了大语言模型(LLMs) 在表示数字时的挑战，即同一数字序列（如911）可能根据上下文被视为数字或字符串，导致表示空间的纠缠。研究者使用认知科学中的基于相似性的提示技术，分析LLMs对整数对的相似性判断，发现这些判断可由Levenshtein编辑距离和数字Log-Linear距离共同捕捉，揭示了字符串和数字表示的混合。实验进一步显示，这种纠缠在模型的潜在嵌入中体现，通过上下文可部分缓解但无法完全消除，并可能传播到实际决策场景中，从而为transformer模型从文本输入中学习数字表示的张力提供了重要洞见。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.01540v1",
      "published_date": "2025-02-03 17:17:26 UTC",
      "updated_date": "2025-02-03 17:17:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:15:38.173218"
    },
    {
      "arxiv_id": "2502.01534v1",
      "title": "Preference Leakage: A Contamination Problem in LLM-as-a-judge",
      "title_zh": "翻译失败",
      "authors": [
        "Dawei Li",
        "Renliang Sun",
        "Yue Huang",
        "Ming Zhong",
        "Bohan Jiang",
        "Jiawei Han",
        "Xiangliang Zhang",
        "Wei Wang",
        "Huan Liu"
      ],
      "abstract": "Large Language Models (LLMs) as judges and LLM-based data synthesis have\nemerged as two fundamental LLM-driven data annotation methods in model\ndevelopment. While their combination significantly enhances the efficiency of\nmodel training and evaluation, little attention has been given to the potential\ncontamination brought by this new model development paradigm. In this work, we\nexpose preference leakage, a contamination problem in LLM-as-a-judge caused by\nthe relatedness between the synthetic data generators and LLM-based evaluators.\nTo study this issue, we first define three common relatednesses between data\ngenerator LLM and judge LLM: being the same model, having an inheritance\nrelationship, and belonging to the same model family. Through extensive\nexperiments, we empirically confirm the bias of judges towards their related\nstudent models caused by preference leakage across multiple LLM baselines and\nbenchmarks. Further analysis suggests that preference leakage is a pervasive\nissue that is harder to detect compared to previously identified biases in\nLLM-as-a-judge scenarios. All of these findings imply that preference leakage\nis a widespread and challenging problem in the area of LLM-as-a-judge. We\nrelease all codes and data at:\nhttps://github.com/David-Li0406/Preference-Leakage.",
      "tldr_zh": "该论文揭示了LLM-as-a-judge中的“preference leakage”问题，这是一种由数据生成器LLM和评判器LLM相关性导致的污染现象，可能偏向于相关模型。作者定义了三种常见相关性，包括相同模型、继承关系和同一模型家族，并通过广泛实验验证了评判器对相关学生模型的偏见。实验结果显示，这种偏见在多个LLM基准上普遍存在，且比以往偏见更难检测，强调了LLM-as-a-judge范式中的潜在挑战。论文提供了代码和数据，以促进进一步研究。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.01534v1",
      "published_date": "2025-02-03 17:13:03 UTC",
      "updated_date": "2025-02-03 17:13:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:15:51.075802"
    },
    {
      "arxiv_id": "2502.01533v1",
      "title": "Transformers trained on proteins can learn to attend to Euclidean distance",
      "title_zh": "基于蛋白质训练的 Transformer 可以学会关注欧氏距离",
      "authors": [
        "Isaac Ellmen",
        "Constantin Schneider",
        "Matthew I. J. Raybould",
        "Charlotte M. Deane"
      ],
      "abstract": "While conventional Transformers generally operate on sequence data, they can\nbe used in conjunction with structure models, typically SE(3)-invariant or\nequivariant graph neural networks (GNNs), for 3D applications such as protein\nstructure modelling. These hybrids typically involve either (1)\npreprocessing/tokenizing structural features as input for Transformers or (2)\ntaking Transformer embeddings and processing them within a structural\nrepresentation. However, there is evidence that Transformers can learn to\nprocess structural information on their own, such as the AlphaFold3 structural\ndiffusion model. In this work we show that Transformers can function\nindependently as structure models when passed linear embeddings of coordinates.\nWe first provide a theoretical explanation for how Transformers can learn to\nfilter attention as a 3D Gaussian with learned variance. We then validate this\ntheory using both simulated 3D points and in the context of masked token\nprediction for proteins. Finally, we show that pre-training protein Transformer\nencoders with structure improves performance on a downstream task, yielding\nbetter performance than custom structural models. Together, this work provides\na basis for using standard Transformers as hybrid structure-language models.",
      "tldr_zh": "该研究发现，训练在蛋白质数据上的Transformer模型可以独立学习关注欧氏距离，从而作为结构模型处理3D应用，而无需依赖SE(3)-invariant或equivariant graph neural networks (GNNs)。作者首先提供理论解释，表明Transformer能将注意力过滤为带有学习方差的3D高斯分布，并通过模拟3D点和蛋白质掩码标记预测进行验证。实验结果显示，使用结构预训练的蛋白质Transformer编码器在下游任务中表现优于自定义结构模型，为构建混合结构-语言模型提供了新基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.BM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01533v1",
      "published_date": "2025-02-03 17:12:44 UTC",
      "updated_date": "2025-02-03 17:12:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:16:00.700803"
    },
    {
      "arxiv_id": "2502.01524v1",
      "title": "Efficiently Integrate Large Language Models with Visual Perception: A Survey from the Training Paradigm Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaorui Ma",
        "Haoran Xie",
        "S. Joe Qin"
      ],
      "abstract": "The integration of vision-language modalities has been a significant focus in\nmultimodal learning, traditionally relying on Vision-Language Pretrained\nModels. However, with the advent of Large Language Models (LLMs), there has\nbeen a notable shift towards incorporating LLMs with vision modalities.\nFollowing this, the training paradigms for incorporating vision modalities into\nLLMs have evolved. Initially, the approach was to integrate the modalities\nthrough pretraining the modality integrator, named Single-stage Tuning. It has\nsince branched out into methods focusing on performance enhancement, denoted as\nTwo-stage Tuning, and those prioritizing parameter efficiency, referred to as\nDirect Adaptation. However, existing surveys primarily address the latest\nVision Large Language Models (VLLMs) with Two-stage Tuning, leaving a gap in\nunderstanding the evolution of training paradigms and their unique\nparameter-efficient considerations. This paper categorizes and reviews 34 VLLMs\nfrom top conferences, journals, and highly cited Arxiv papers, focusing on\nparameter efficiency during adaptation from the training paradigm perspective.\nWe first introduce the architecture of LLMs and parameter-efficient learning\nmethods, followed by a discussion on vision encoders and a comprehensive\ntaxonomy of modality integrators. We then review three training paradigms and\ntheir efficiency considerations, summarizing benchmarks in the VLLM field. To\ngain deeper insights into their effectiveness in parameter efficiency, we\ncompare and discuss the experimental results of representative models, among\nwhich the experiment of the Direct Adaptation paradigm is replicated. Providing\ninsights into recent developments and practical uses, this survey is a vital\nguide for researchers and practitioners navigating the efficient integration of\nvision modalities into LLMs.",
      "tldr_zh": "这篇调查论文从训练范式角度探讨了高效整合大型语言模型(LLMs)与视觉感知的方法，重点审查了34个视觉大型语言模型(VLLMs)。论文将整合方法分为Single-stage Tuning、Two-stage Tuning和Direct Adaptation三种范式，讨论了它们的架构、参数高效学习以及模态整合器的分类，并总结了相关基准测试。实验比较显示，这些范式在参数效率上表现出显著差异，为研究人员提供实用指导，以优化LLMs在视觉任务中的应用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "28 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.01524v1",
      "published_date": "2025-02-03 17:01:59 UTC",
      "updated_date": "2025-02-03 17:01:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:16:12.856972"
    },
    {
      "arxiv_id": "2502.01521v2",
      "title": "Toward Task Generalization via Memory Augmentation in Meta-Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Kaixi Bao",
        "Chenhao Li",
        "Yarden As",
        "Andreas Krause",
        "Marco Hutter"
      ],
      "abstract": "Agents trained via reinforcement learning (RL) often struggle to perform well\non tasks that differ from those encountered during training. This limitation\npresents a challenge to the broader deployment of RL in diverse and dynamic\ntask settings. In this work, we introduce memory augmentation, a memory-based\nRL approach to improve task generalization. Our approach leverages\ntask-structured augmentations to simulate plausible out-of-distribution\nscenarios and incorporates memory mechanisms to enable context-aware policy\nadaptation. Trained on a predefined set of tasks, our policy demonstrates the\nability to generalize to unseen tasks through memory augmentation without\nrequiring additional interactions with the environment. Through extensive\nsimulation experiments and real-world hardware evaluations on legged locomotion\ntasks, we demonstrate that our approach achieves zero-shot generalization to\nunseen tasks while maintaining robust in-distribution performance and high\nsample efficiency.",
      "tldr_zh": "本研究针对强化学习（RL）代理在训练外任务上泛化能力不足的问题，提出memory augmentation方法，该方法通过任务结构化增强模拟分布外场景，并利用记忆机制实现上下文感知的政策适应。训练后，代理无需额外环境交互即可泛化到未见任务。实验结果显示，该方法在模拟和真实硬件（如legged locomotion任务）评估中实现了零样本泛化，同时保持了高样本效率和分布内性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01521v2",
      "published_date": "2025-02-03 17:00:19 UTC",
      "updated_date": "2025-05-07 18:57:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:16:25.810735"
    },
    {
      "arxiv_id": "2503.04736v1",
      "title": "Standardizing Intelligence: Aligning Generative AI for Regulatory and Operational Compliance",
      "title_zh": "标准化智能：为监管和操作合规对齐生成式 AI",
      "authors": [
        "Joseph Marvin Imperial",
        "Matthew D. Jones",
        "Harish Tayyar Madabushi"
      ],
      "abstract": "Technical standards, or simply standards, are established documented\nguidelines and rules that facilitate the interoperability, quality, and\naccuracy of systems and processes. In recent years, we have witnessed an\nemerging paradigm shift where the adoption of generative AI (GenAI) models has\nincreased tremendously, spreading implementation interests across\nstandard-driven industries, including engineering, legal, healthcare, and\neducation. In this paper, we assess the criticality levels of different\nstandards across domains and sectors and complement them by grading the current\ncompliance capabilities of state-of-the-art GenAI models. To support the\ndiscussion, we outline possible challenges and opportunities with integrating\nGenAI for standard compliance tasks while also providing actionable\nrecommendations for entities involved with developing and using standards.\nOverall, we argue that aligning GenAI with standards through computational\nmethods can help strengthen regulatory and operational compliance. We\nanticipate this area of research will play a central role in the management,\noversight, and trustworthiness of larger, more powerful GenAI-based systems in\nthe near future.",
      "tldr_zh": "本论文探讨了如何通过技术标准（standards）来对齐 Generative AI (GenAI)模型，以提升监管和操作合规性。作者评估了不同领域（如工程、法律、医疗和教育）的标准关键性，并分析了当前GenAI模型的合规能力，同时讨论了整合GenAI的挑战、机会和可操作建议。研究主张，通过计算方法使GenAI与标准对齐，能够加强系统的互操作性、质量和准确性，最终提升整体可信度，并预测这将成为未来GenAI管理与监督的核心研究方向。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.04736v1",
      "published_date": "2025-02-03 16:55:01 UTC",
      "updated_date": "2025-02-03 16:55:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:16:36.812057"
    },
    {
      "arxiv_id": "2502.01517v1",
      "title": "Regularized interpolation in 4D neural fields enables optimization of 3D printed geometries",
      "title_zh": "翻译失败",
      "authors": [
        "Christos Margadji",
        "Andi Kuswoyo",
        "Sebastian W. Pattinson"
      ],
      "abstract": "The ability to accurately produce geometries with specified properties is\nperhaps the most important characteristic of a manufacturing process. 3D\nprinting is marked by exceptional design freedom and complexity but is also\nprone to geometric and other defects that must be resolved for it to reach its\nfull potential. Ultimately, this will require both astute design decisions and\ntimely parameter adjustments to maintain stability that is challenging even\nwith expert human operators. While machine learning is widely investigated in\n3D printing, existing methods typically overlook spatial features that vary\nacross prints and thus find it difficult to produce desired geometries. Here,\nwe encode volumetric representations of printed parts into neural fields and\napply a new regularization strategy, based on minimizing the partial derivative\nof the field's output with respect to a single, non-learnable parameter. By\nthus encouraging small input changes to yield only small output variations, we\nencourage smooth interpolation between observed volumes and hence realistic\ngeometry predictions. This framework therefore allows the extraction of\n'imagined' 3D shapes, revealing how a part would look if manufactured under\npreviously unseen parameters. The resulting continuous field is used for\ndata-driven optimization to maximize geometric fidelity between expected and\nproduced geometries, reducing post-processing, material waste, and production\ncosts. By optimizing process parameters dynamically, our approach enables\nadvanced planning strategies, potentially allowing manufacturers to better\nrealize complex and feature-rich designs.",
      "tldr_zh": "本文提出了一种基于 4D neural fields 的正则化插值方法，用于优化 3D 打印几何形状，通过最小化字段输出相对于非可学习参数的偏导数，实现平滑插值并预测在未见参数下的“想象”3D 形状。该方法编码打印部件的体积表示，并通过数据驱动优化最大化期望和实际几何的保真度，从而减少后处理、材料浪费和生产成本。最终，这支持动态过程参数调整和高级规划策略，帮助制造商更好地实现复杂设计。",
      "categories": [
        "cs.GR",
        "cs.AI"
      ],
      "primary_category": "cs.GR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01517v1",
      "published_date": "2025-02-03 16:50:57 UTC",
      "updated_date": "2025-02-03 16:50:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:16:49.542760"
    },
    {
      "arxiv_id": "2502.01503v2",
      "title": "Sea-cret Agents: Maritime Abduction for Region Generation to Expose Dark Vessel Trajectories",
      "title_zh": "翻译失败",
      "authors": [
        "Divyagna Bavikadi",
        "Nathaniel Lee",
        "Paulo Shakarian",
        "Chad Parvis"
      ],
      "abstract": "Bad actors in the maritime industry engage in illegal behaviors after\ndisabling their vessel's automatic identification system (AIS) - which makes\nfinding such vessels difficult for analysts. Machine learning approaches only\nsucceed in identifying the locations of these ``dark vessels'' in the immediate\nfuture. This work leverages ideas from the literature on abductive inference\napplied to locating adversarial agents to solve the problem. Specifically, we\ncombine concepts from abduction, logic programming, and rule learning to create\nan efficient method that approaches full recall of dark vessels while requiring\nless search area than machine learning methods. We provide a logic-based\nparadigm for reasoning about maritime vessels, an abductive inference query\nmethod, an automatically extracted rule-based behavior model methodology, and a\nthorough suite of experiments.",
      "tldr_zh": "该论文针对海上非法行为者关闭自动识别系统 (AIS) 后导致的“暗船”追踪难题，提出了一种基于溯因推理 (abductive inference) 的方法，结合逻辑编程 (logic programming) 和规则学习 (rule learning)，以生成潜在区域并暴露暗船轨迹。相比机器学习方法，该方法实现了接近完全召回率，同时显著减少搜索区域。论文还提供了逻辑-based 范式、溯因推理查询方法、自动提取的规则-based 行为模型，并通过全面实验验证了其有效性。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.LO",
        "cs.SC"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to 24th International Conference on Autonomous Agents and\n  Multiagent Systems (AAMAS 2025)",
      "pdf_url": "http://arxiv.org/pdf/2502.01503v2",
      "published_date": "2025-02-03 16:36:26 UTC",
      "updated_date": "2025-02-06 23:01:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:17:01.252835"
    },
    {
      "arxiv_id": "2502.01492v1",
      "title": "Develop AI Agents for System Engineering in Factorio",
      "title_zh": "翻译失败",
      "authors": [
        "Neel Kant"
      ],
      "abstract": "Continuing advances in frontier model research are paving the way for\nwidespread deployment of AI agents. Meanwhile, global interest in building\nlarge, complex systems in software, manufacturing, energy and logistics has\nnever been greater. Although AI driven system engineering holds tremendous\npromise, the static benchmarks dominating agent evaluations today fail to\ncapture the crucial skills required for implementing dynamic systems, such as\nmanaging uncertain trade-offs and ensuring proactive adaptability. This\nposition paper advocates for training and evaluating AI agents' system\nengineering abilities through automation-oriented sandbox games-particularly\nFactorio. By directing research efforts in this direction, we can equip AI\nagents with the specialized reasoning and long-horizon planning necessary to\ndesign, maintain, and optimize tomorrow's most demanding engineering projects.",
      "tldr_zh": "这篇立场论文（position paper）指出，现有的AI agents评估基准过于静态，无法有效捕捉动态系统工程所需的技能，如管理不确定性权衡和确保主动适应性。它主张通过自动化沙盒游戏如Factorio来训练和评估AI agents的系统工程能力，从而培养其专业推理和long-horizon planning技能。通过此方法，AI agents将更好地设计、维护和优化未来复杂的软件、制造、能源和物流项目。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01492v1",
      "published_date": "2025-02-03 16:26:17 UTC",
      "updated_date": "2025-02-03 16:26:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:17:12.405756"
    },
    {
      "arxiv_id": "2502.01490v1",
      "title": "MoireDB: Formula-generated Interference-fringe Image Dataset",
      "title_zh": "翻译失败",
      "authors": [
        "Yuto Matsuo",
        "Ryo Hayamizu",
        "Hirokatsu Kataoka",
        "Akio Nakamura"
      ],
      "abstract": "Image recognition models have struggled to treat recognition robustness to\nreal-world degradations. In this context, data augmentation methods like PixMix\nimprove robustness but rely on generative arts and feature visualizations\n(FVis), which have copyright, drawing cost, and scalability issues. We propose\nMoireDB, a formula-generated interference-fringe image dataset for image\naugmentation enhancing robustness. MoireDB eliminates copyright concerns,\nreduces dataset assembly costs, and enhances robustness by leveraging illusory\npatterns. Experiments show that MoireDB augmented images outperforms\ntraditional Fractal arts and FVis-based augmentations, making it a scalable and\neffective solution for improving model robustness against real-world\ndegradations.",
      "tldr_zh": "图像识别模型在处理真实世界退化时鲁棒性不足，而现有数据增强方法如PixMix依赖于生成艺术和特征可视化(FVis)，面临版权、绘制成本和可扩展性问题。论文提出MoireDB，这是一个基于公式的干扰条纹图像数据集，用于图像增强以提升模型鲁棒性，并通过利用幻觉模式消除版权担忧并降低数据集组装成本。实验结果显示，MoireDB增强的图像优于传统Fractal arts和FVis-based方法，提供了一个可扩展且有效的解决方案来改善模型对真实世界退化的性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01490v1",
      "published_date": "2025-02-03 16:24:58 UTC",
      "updated_date": "2025-02-03 16:24:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:17:24.733846"
    },
    {
      "arxiv_id": "2502.01715v1",
      "title": "Process-Supervised Reinforcement Learning for Code Generation",
      "title_zh": "过程监督强化学习用于代码生成",
      "authors": [
        "Yufan Ye",
        "Ting Zhang",
        "Wenbin Jiang",
        "Hua Huang"
      ],
      "abstract": "Existing reinforcement learning strategies based on outcome supervision have\nproven effective in enhancing the performance of large language models(LLMs)\nfor code generation. While reinforcement learning based on process supervision\nhas shown great promise in handling multi-step reasoning tasks, its\neffectiveness in code generation remains largely underexplored and\nunderjustified. The primary obstacle stems from the resource-intensive nature\nof constructing high-quality process-supervised data, which demands substantial\nhuman expertise and computational resources. In response to this challenge, we\npropose a \"statement mutation/refactoring-compile and execution verification\"\nstrategy: mutating and refactoring code line-by-line through a teacher model,\nand utilizing compiler execution results to automatically label each line,\nresulting in line-by-line process-supervised data, which is pivotal for\ntraining a process-supervised reward model. The trained reward model is then\nintegrated into the PRLCoder framework, followed by experimental validation on\nseveral benchmarks. Experimental results demonstrate that process-supervised\nreinforcement learning significantly surpasses methods relying solely on\noutcome supervision. Notably, in tackling complex code generation tasks,\nprocess-supervised reinforcement learning shows a clear advantage, ensuring\nboth the integrity of the code generation process and the correctness of the\ngeneration results.",
      "tldr_zh": "本文提出了一种基于过程监督（process supervision）的强化学习方法，用于提升大语言模型（LLMs）在代码生成的性能，以解决现有基于结果监督（outcome supervision）方法的局限性。研究团队开发了“statement mutation/refactoring-compile and execution verification”策略，通过教师模型逐行修改和重构代码，并利用编译和执行结果自动生成高质量的过程监督数据，用于训练奖励模型。实验结果显示，该方法整合到PRLCoder框架后，在多个基准测试中显著优于仅依赖结果监督的方法，尤其在复杂代码生成任务中，确保了代码过程的完整性和结果的正确性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01715v1",
      "published_date": "2025-02-03 16:22:06 UTC",
      "updated_date": "2025-02-03 16:22:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:17:37.646908"
    },
    {
      "arxiv_id": "2502.01477v1",
      "title": "Position: Empowering Time Series Reasoning with Multimodal LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Yaxuan Kong",
        "Yiyuan Yang",
        "Shiyu Wang",
        "Chenghao Liu",
        "Yuxuan Liang",
        "Ming Jin",
        "Stefan Zohren",
        "Dan Pei",
        "Yan Liu",
        "Qingsong Wen"
      ],
      "abstract": "Understanding time series data is crucial for multiple real-world\napplications. While large language models (LLMs) show promise in time series\ntasks, current approaches often rely on numerical data alone, overlooking the\nmultimodal nature of time-dependent information, such as textual descriptions,\nvisual data, and audio signals. Moreover, these methods underutilize LLMs'\nreasoning capabilities, limiting the analysis to surface-level interpretations\ninstead of deeper temporal and multimodal reasoning. In this position paper, we\nargue that multimodal LLMs (MLLMs) can enable more powerful and flexible\nreasoning for time series analysis, enhancing decision-making and real-world\napplications. We call on researchers and practitioners to leverage this\npotential by developing strategies that prioritize trust, interpretability, and\nrobust reasoning in MLLMs. Lastly, we highlight key research directions,\nincluding novel reasoning paradigms, architectural innovations, and\ndomain-specific applications, to advance time series reasoning with MLLMs.",
      "tldr_zh": "这篇立场论文（Position paper）主张利用多模态大型语言模型（Multimodal LLMs）来增强时间序列（time series）分析的推理能力，解决当前方法仅依赖数值数据而忽略文本、视觉和音频等多模态信息的局限性。论文强调MLLMs能实现更深入的时序和多模态推理，从而改善决策和实际应用，并呼吁开发注重信任、可解释性和鲁棒性的策略。未来研究方向包括探索新型推理范式、架构创新以及领域特定应用，以推进时间序列推理的进步。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01477v1",
      "published_date": "2025-02-03 16:10:48 UTC",
      "updated_date": "2025-02-03 16:10:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:17:48.685862"
    },
    {
      "arxiv_id": "2502.01472v1",
      "title": "FALCON: Fine-grained Activation Manipulation by Contrastive Orthogonal Unalignment for Large Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Jinwei Hu",
        "Zhenglin Huang",
        "Xiangyu Yin",
        "Wenjie Ruan",
        "Guangliang Cheng",
        "Yi Dong",
        "Xiaowei Huang"
      ],
      "abstract": "Large language models have been widely applied, but can inadvertently encode\nsensitive or harmful information, raising significant safety concerns. Machine\nunlearning has emerged to alleviate this concern; however, existing\ntraining-time unlearning approaches, relying on coarse-grained loss\ncombinations, have limitations in precisely separating knowledge and balancing\nremoval effectiveness with model utility. In contrast, we propose Fine-grained\nActivation manipuLation by Contrastive Orthogonal uNalignment (FALCON), a novel\nrepresentation-guided unlearning approach that leverages information-theoretic\nguidance for efficient parameter selection, employs contrastive mechanisms to\nenhance representation separation, and projects conflict gradients onto\northogonal subspaces to resolve conflicts between forgetting and retention\nobjectives. Extensive experiments demonstrate that FALCON achieves superior\nunlearning effectiveness while maintaining model utility, exhibiting robust\nresistance against knowledge recovery attempts.",
      "tldr_zh": "该研究针对大型语言模型（Large Language Models）可能编码敏感或有害信息的安全问题，提出了一种新型机器遗忘（machine unlearning）方法FALCON，即Fine-grained Activation Manipulation by Contrastive Orthogonal Unalignment。FALCON 通过信息论指导（information-theoretic guidance）进行高效参数选择、采用对比机制（contrastive mechanisms）增强表示分离，并将冲突梯度投影到正交子空间（orthogonal subspaces）中，以精确分离知识并平衡遗忘效果与模型效用。实验结果显示，FALCON 在遗忘任务上表现出色，同时维持模型性能，并有效抵抗知识恢复尝试。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2502.01472v1",
      "published_date": "2025-02-03 16:05:15 UTC",
      "updated_date": "2025-02-03 16:05:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:18:00.413371"
    },
    {
      "arxiv_id": "2502.01714v1",
      "title": "Position: Towards a Responsible LLM-empowered Multi-Agent Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Jinwei Hu",
        "Yi Dong",
        "Shuang Ao",
        "Zhuoyun Li",
        "Boxuan Wang",
        "Lokesh Singh",
        "Guangliang Cheng",
        "Sarvapali D. Ramchurn",
        "Xiaowei Huang"
      ],
      "abstract": "The rise of Agent AI and Large Language Model-powered Multi-Agent Systems\n(LLM-MAS) has underscored the need for responsible and dependable system\noperation. Tools like LangChain and Retrieval-Augmented Generation have\nexpanded LLM capabilities, enabling deeper integration into MAS through\nenhanced knowledge retrieval and reasoning. However, these advancements\nintroduce critical challenges: LLM agents exhibit inherent unpredictability,\nand uncertainties in their outputs can compound across interactions,\nthreatening system stability. To address these risks, a human-centered design\napproach with active dynamic moderation is essential. Such an approach enhances\ntraditional passive oversight by facilitating coherent inter-agent\ncommunication and effective system governance, allowing MAS to achieve desired\noutcomes more efficiently.",
      "tldr_zh": "该论文讨论了Agent AI和Large Language Model-powered Multi-Agent Systems (LLM-MAS)的兴起，以及工具如LangChain和Retrieval-Augmented Generation在增强LLM知识检索和推理能力方面的作用，但这些进步也带来了LLM代理的不可预测性和输出不确定性累积的问题，可能威胁系统稳定性。作者主张采用人类中心的设计方法，通过主动动态调节来改善代理间的连贯通信和系统治理，以超越传统的被动监督。最终，这种方法能提升LLM-MAS的效率和可靠性，确保更有效的系统运作。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2502.01714v1",
      "published_date": "2025-02-03 16:04:30 UTC",
      "updated_date": "2025-02-03 16:04:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:18:11.743841"
    },
    {
      "arxiv_id": "2502.01456v1",
      "title": "Process Reinforcement through Implicit Rewards",
      "title_zh": "通过隐式奖励的过程强化",
      "authors": [
        "Ganqu Cui",
        "Lifan Yuan",
        "Zefan Wang",
        "Hanbin Wang",
        "Wendi Li",
        "Bingxiang He",
        "Yuchen Fan",
        "Tianyu Yu",
        "Qixin Xu",
        "Weize Chen",
        "Jiarui Yuan",
        "Huayu Chen",
        "Kaiyan Zhang",
        "Xingtai Lv",
        "Shuo Wang",
        "Yuan Yao",
        "Xu Han",
        "Hao Peng",
        "Yu Cheng",
        "Zhiyuan Liu",
        "Maosong Sun",
        "Bowen Zhou",
        "Ning Ding"
      ],
      "abstract": "Dense process rewards have proven a more effective alternative to the sparse\noutcome-level rewards in the inference-time scaling of large language models\n(LLMs), particularly in tasks requiring complex multi-step reasoning. While\ndense rewards also offer an appealing choice for the reinforcement learning\n(RL) of LLMs since their fine-grained rewards have the potential to address\nsome inherent issues of outcome rewards, such as training efficiency and credit\nassignment, this potential remains largely unrealized. This can be primarily\nattributed to the challenges of training process reward models (PRMs) online,\nwhere collecting high-quality process labels is prohibitively expensive, making\nthem particularly vulnerable to reward hacking. To address these challenges, we\npropose PRIME (Process Reinforcement through IMplicit rEwards), which enables\nonline PRM updates using only policy rollouts and outcome labels through\nimplict process rewards. PRIME combines well with various advantage functions\nand forgoes the dedicated reward model training phrase that existing approaches\nrequire, substantially reducing the development overhead. We demonstrate\nPRIME's effectiveness on competitional math and coding. Starting from\nQwen2.5-Math-7B-Base, PRIME achieves a 15.1% average improvement across several\nkey reasoning benchmarks over the SFT model. Notably, our resulting model,\nEurus-2-7B-PRIME, surpasses Qwen2.5-Math-7B-Instruct on seven reasoning\nbenchmarks with 10% of its training data.",
      "tldr_zh": "该论文探讨了在强化学习(RL)中，使用密集过程奖励(dense process rewards)来提升大型语言模型(LLMs)的多步推理能力，但面临在线训练过程奖励模型(PRMs)的挑战，如标签收集困难和奖励黑客(reward hacking)问题。作者提出PRIME(Process Reinforcement through IMplicit rEwards)方法，通过仅利用策略回滚(policy rollouts)和结果标签(outcome labels)实现隐式过程奖励的在线更新，结合各种优势函数(advantage functions)并省去专用奖励模型训练阶段，从而降低开发开销。在数学和编码任务上实验显示，PRIME从Qwen2.5-Math-7B-Base模型起步，平均在多个推理基准上比SFT模型提高了15.1%，最终模型Eurus-2-7B-PRIME在使用10%训练数据的情况下超过了Qwen2.5-Math-7B-Instruct的表现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "20 pages. Model&Code&Data available at\n  https://github.com/PRIME-RL/PRIME",
      "pdf_url": "http://arxiv.org/pdf/2502.01456v1",
      "published_date": "2025-02-03 15:43:48 UTC",
      "updated_date": "2025-02-03 15:43:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:18:25.907020"
    },
    {
      "arxiv_id": "2502.01455v1",
      "title": "Temporal-consistent CAMs for Weakly Supervised Video Segmentation in Waste Sorting",
      "title_zh": "时间一致的 CAMs 用于废物分类中的",
      "authors": [
        "Andrea Marelli",
        "Luca Magri",
        "Federica Arrigoni",
        "Giacomo Boracchi"
      ],
      "abstract": "In industrial settings, weakly supervised (WS) methods are usually preferred\nover their fully supervised (FS) counterparts as they do not require costly\nmanual annotations. Unfortunately, the segmentation masks obtained in the WS\nregime are typically poor in terms of accuracy. In this work, we present a WS\nmethod capable of producing accurate masks for semantic segmentation in the\ncase of video streams. More specifically, we build saliency maps that exploit\nthe temporal coherence between consecutive frames in a video, promoting\nconsistency when objects appear in different frames. We apply our method in a\nwaste-sorting scenario, where we perform weakly supervised video segmentation\n(WSVS) by training an auxiliary classifier that distinguishes between videos\nrecorded before and after a human operator, who manually removes specific\nwastes from a conveyor belt. The saliency maps of this classifier identify\nmaterials to be removed, and we modify the classifier training to minimize\ndifferences between the saliency map of a central frame and those in adjacent\nframes, after having compensated object displacement. Experiments on a\nreal-world dataset demonstrate the benefits of integrating temporal coherence\ndirectly during the training phase of the classifier. Code and dataset are\navailable upon request.",
      "tldr_zh": "本研究针对工业废物分类中的视频语义分割问题，提出了一种基于时间一致性（Temporal-consistent）的弱监督（WS）方法，以克服传统WS方法在分割掩码准确性上的不足。该方法通过构建利用连续帧之间时间一致性的显著性图（CAMs），并训练一个辅助分类器来区分操作前后视频，从而识别需要移除的材料，并在补偿对象位移后最小化相邻帧的显著性图差异。实验结果显示，在真实废物分类数据集上，该方法直接在分类器训练阶段整合时间一致性后，显著提高了分割性能，证明了其有效性。代码和数据集可供请求获取。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "14 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.01455v1",
      "published_date": "2025-02-03 15:43:33 UTC",
      "updated_date": "2025-02-03 15:43:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:18:36.682703"
    },
    {
      "arxiv_id": "2502.01450v1",
      "title": "Simulating Rumor Spreading in Social Networks using LLM Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Tianrui Hu",
        "Dimitrios Liakopoulos",
        "Xiwen Wei",
        "Radu Marculescu",
        "Neeraja J. Yadwadkar"
      ],
      "abstract": "With the rise of social media, misinformation has become increasingly\nprevalent, fueled largely by the spread of rumors. This study explores the use\nof Large Language Model (LLM) agents within a novel framework to simulate and\nanalyze the dynamics of rumor propagation across social networks. To this end,\nwe design a variety of LLM-based agent types and construct four distinct\nnetwork structures to conduct these simulations. Our framework assesses the\neffectiveness of different network constructions and agent behaviors in\ninfluencing the spread of rumors. Our results demonstrate that the framework\ncan simulate rumor spreading across more than one hundred agents in various\nnetworks with thousands of edges. The evaluations indicate that network\nstructure, personas, and spreading schemes can significantly influence rumor\ndissemination, ranging from no spread to affecting 83\\% of agents in\niterations, thereby offering a realistic simulation of rumor spread in social\nnetworks.",
      "tldr_zh": "本研究使用LLM agents构建了一个新框架，模拟和分析社交网络中的谣言传播动态。框架设计了多种代理类型和四种网络结构，评估了这些因素如何影响谣言的传播效果。结果显示，该框架能模拟超过一百个代理在数千边网络中的互动，并证明网络结构、代理角色和传播方案能显著影响传播范围，从完全不扩散到影响83%的代理。该方法为现实社交网络谣言模拟提供了宝贵工具，有助于理解和缓解误信息问题。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "7 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.01450v1",
      "published_date": "2025-02-03 15:39:56 UTC",
      "updated_date": "2025-02-03 15:39:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:18:48.622669"
    },
    {
      "arxiv_id": "2502.01445v2",
      "title": "SPFFNet: Strip Perception and Feature Fusion Spatial Pyramid Pooling for Fabric Defect Detection",
      "title_zh": "SPFFNet：条带感知和特征融合空间金字塔池化用于织物缺陷检测",
      "authors": [
        "Peizhe Zhao"
      ],
      "abstract": "Defect detection in fabrics is critical for quality control, yet existing\nmethods often struggle with complex backgrounds and shape-specific defects. In\nthis paper, we propose an improved fabric defect detection model based on\nYOLOv11. To enhance the detection of strip defects, we introduce a Strip\nPerception Module (SPM) that improves feature capture through multi-scale\nconvolution. We further enhance the spatial pyramid pooling fast (SPPF) by\nintegrating a squeeze-and-excitation mechanism, resulting in the SE-SPPF\nmodule, which better integrates spatial and channel information for more\neffective defect feature extraction. Additionally, we propose a novel focal\nenhanced complete intersection over union (FECIoU) metric with adaptive\nweights, addressing scale differences and class imbalance by adjusting the\nweights of hard-to-detect instances through focal loss. Experimental results\ndemonstrate that our model achieves a 0.8-8.1% improvement in mean average\nprecision (mAP) on the Tianchi dataset and a 1.6-13.2% improvement on our\ncustom dataset, outperforming other state-of-the-art methods.",
      "tldr_zh": "本研究提出SPFFNet，一种基于YOLOv11的改进模型，用于布料缺陷检测，以应对复杂背景和形状特定缺陷的问题。该模型引入Strip Perception Module (SPM)，通过多尺度卷积提升条状缺陷的特征捕获；同时，优化SPPF模块为SE-SPPF，整合挤压和激励机制以更好地融合空间和通道信息。此外，提出FECIoU指标，利用自适应权重和focal loss处理尺度差异及类别不平衡。实验结果显示，该模型在Tianchi数据集上mAP提升0.8-8.1%，在自定义数据集上提升1.6-13.2%，优于现有最先进方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 4 figures, conference",
      "pdf_url": "http://arxiv.org/pdf/2502.01445v2",
      "published_date": "2025-02-03 15:33:11 UTC",
      "updated_date": "2025-02-04 03:25:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:19:00.214903"
    },
    {
      "arxiv_id": "2502.01436v2",
      "title": "Towards Safer Chatbots: A Framework for Policy Compliance Evaluation of Custom GPTs",
      "title_zh": "翻译失败",
      "authors": [
        "David Rodriguez",
        "William Seymour",
        "Jose M. Del Alamo",
        "Jose Such"
      ],
      "abstract": "Large Language Models (LLMs) have gained unprecedented prominence, achieving\nwidespread adoption across diverse domains and integrating deeply into society.\nThe capability to fine-tune general-purpose LLMs, such as Generative\nPre-trained Transformers (GPT), for specific tasks has facilitated the\nemergence of numerous Custom GPTs. These tailored models are increasingly made\navailable through dedicated marketplaces, such as OpenAI's GPT Store. However,\ntheir black-box nature introduces significant safety and compliance risks. In\nthis work, we present a scalable framework for the automated evaluation of\nCustom GPTs against OpenAI's usage policies, which define the permissible\nbehaviors of these systems. Our framework integrates three core components: (1)\nautomated discovery and data collection of models from the GPT store, (2) a\nred-teaming prompt generator tailored to specific policy categories and the\ncharacteristics of each target GPT, and (3) an LLM-as-a-judge technique to\nanalyze each prompt-response pair for potential policy violations. We validate\nour framework with a manually annotated ground truth, and evaluate it through a\nlarge-scale study with 782 Custom GPTs across three categories: Romantic,\nCybersecurity, and Academic GPTs. Our manual annotation process achieved an F1\nscore of 0.975 in identifying policy violations, confirming the reliability of\nthe framework's assessments. The results reveal that 58.7% of the analyzed\nmodels exhibit indications of non-compliance, exposing weaknesses in the GPT\nstore's review and approval processes. Furthermore, our findings indicate that\na model's popularity does not correlate with compliance, and non-compliance\nissues largely stem from behaviors inherited from base models rather than\nuser-driven customizations. We believe this approach is extendable to other\nchatbot platforms and policy domains, improving LLM-based systems safety.",
      "tldr_zh": "本文提出一个可扩展框架，用于自动评估 Custom GPTs 是否符合 OpenAI 的使用政策，旨在解决这些模型的黑箱性质带来的安全和合规风险。框架的核心组件包括：(1) 自动发现和收集 GPT 商店中的模型，(2) 针对特定政策类别和目标 GPT 的 red-teaming 提示生成器，以及 (3) LLM-as-a-judge 技术来分析提示-响应对的潜在违反。通过大规模研究 782 个 Custom GPTs（涵盖 Romantic、Cybersecurity 和 Academic 类别），结果显示 58.7% 的模型存在不合规问题，且不合规主要源于基础模型而非用户定制。该框架经手动验证 F1 分数达 0.975，证明其可靠，并可扩展到其他聊天机器人平台以提升 LLM 系统安全性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.1; I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01436v2",
      "published_date": "2025-02-03 15:19:28 UTC",
      "updated_date": "2025-04-14 16:58:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:19:13.501507"
    },
    {
      "arxiv_id": "2502.01427v1",
      "title": "Structural features of the fly olfactory circuit mitigate the stability-plasticity dilemma in continual learning",
      "title_zh": "翻译失败",
      "authors": [
        "Heming Zou",
        "Yunliang Zang",
        "Xiangyang Ji"
      ],
      "abstract": "Artificial neural networks face the stability-plasticity dilemma in continual\nlearning, while the brain can maintain memories and remain adaptable. However,\nthe biological strategies for continual learning and their potential to inspire\nlearning algorithms in neural networks are poorly understood. This study\npresents a minimal model of the fly olfactory circuit to investigate the\nbiological strategies that support continual odor learning. We introduce the\nfly olfactory circuit as a plug-and-play component, termed the Fly Model, which\ncan integrate with modern machine learning methods to address this dilemma. Our\nfindings demonstrate that the Fly Model enhances both memory stability and\nlearning plasticity, overcoming the limitations of current continual learning\nstrategies. We validated its effectiveness across various challenging continual\nlearning scenarios using commonly used datasets. The fly olfactory system\nserves as an elegant biological circuit for lifelong learning, offering a\nmodule that enhances continual learning with minimal additional computational\ncost for machine learning.",
      "tldr_zh": "本研究探讨了人工神经网络在持续学习（continual learning）中面临的稳定性-可塑性困境（stability-plasticity dilemma），并通过构建苍蝇嗅觉电路的简化模型（Fly Model）来揭示生物策略。该模型可作为插件组件整合到现代机器学习方法中，提升记忆稳定性和学习可塑性，从而克服现有策略的局限。实验在多种挑战性数据集上验证了Fly Model的有效性，为机器学习提供了一个计算成本低的终身学习模块。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "q-bio.NC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01427v1",
      "published_date": "2025-02-03 15:06:11 UTC",
      "updated_date": "2025-02-03 15:06:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:19:24.351820"
    },
    {
      "arxiv_id": "2502.01419v1",
      "title": "Visual Attention Never Fades: Selective Progressive Attention ReCalibration for Detailed Image Captioning in Multimodal Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Mingi Jung",
        "Saehuyng Lee",
        "Eunji Kim",
        "Sungroh Yoon"
      ],
      "abstract": "Detailed image captioning is essential for tasks like data generation and\naiding visually impaired individuals. High-quality captions require a balance\nbetween precision and recall, which remains challenging for current multimodal\nlarge language models (MLLMs). In this work, we hypothesize that this\nlimitation stems from weakening and increasingly noisy visual attention as\nresponses lengthen. To address this issue, we propose SPARC (Selective\nProgressive Attention ReCalibration), a training-free method that enhances the\ncontribution of visual tokens during decoding. SPARC is founded on three key\nobservations: (1) increasing the influence of all visual tokens reduces recall;\nthus, SPARC selectively amplifies visual tokens; (2) as captions lengthen,\nvisual attention becomes noisier, so SPARC identifies critical visual tokens by\nleveraging attention differences across time steps; (3) as visual attention\ngradually weakens, SPARC reinforces it to preserve its influence. Our\nexperiments, incorporating both automated and human evaluations, demonstrate\nthat existing methods improve the precision of MLLMs at the cost of recall. In\ncontrast, our proposed method enhances both precision and recall with minimal\ncomputational overhead.",
      "tldr_zh": "本研究针对多模态大语言模型(MLLMs)在详细图像描述任务中存在的精确性和召回率平衡问题，假设这是由于响应变长导致视觉注意力减弱和噪声增加而引起的。作者提出了一种无训练方法SPARC(Selective Progressive Attention ReCalibration)，通过选择性地放大关键视觉标记、利用跨时间步注意力差异识别重要标记，以及强化逐渐减弱的视觉注意力，来增强解码过程中的视觉标记贡献。实验结果显示，SPARC不仅提高了MLLMs的精确性和召回率，同时保持了最小计算开销，与现有方法相比更全面地提升了图像描述质量。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01419v1",
      "published_date": "2025-02-03 14:58:11 UTC",
      "updated_date": "2025-02-03 14:58:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:19:36.801685"
    },
    {
      "arxiv_id": "2502.01708v1",
      "title": "Aspects of Artificial Intelligence: Transforming Machine Learning Systems Naturally",
      "title_zh": "翻译失败",
      "authors": [
        "Xiuzhan Guo"
      ],
      "abstract": "In this paper, we study the machine learning elements which we are interested\nin together as a machine learning system, consisting of a collection of machine\nlearning elements and a collection of relations between the elements. The\nrelations we concern are algebraic operations, binary relations, and binary\nrelations with composition that can be reasoned categorically. A machine\nlearning system transformation between two systems is a map between the\nsystems, which preserves the relations we concern. The system transformations\ngiven by quotient or clustering, representable functor, and Yoneda embedding\nare highlighted and discussed by machine learning examples. An adjunction\nbetween machine learning systems, a special machine learning system\ntransformation loop, provides the optimal way of solving problems. Machine\nlearning system transformations are linked and compared by their maps at\n2-cell, natural transformations. New insights and structures can be obtained\nfrom universal properties and algebraic structures given by monads, which are\ngenerated from adjunctions.",
      "tldr_zh": "本论文将机器学习系统视为一个由机器学习元素及其之间关系的集合组成，并关注代数运算、binary relations 和可分类推理的二元关系。论文探讨了系统转换，如 quotient 或 clustering、representable functor 和 Yoneda embedding，通过机器学习示例进行说明，并强调 adjunction 作为解决问题的最优方式。最终，通过 natural transformations 和从 adjunction 生成的 monads，论文揭示了新的洞见和结构，为机器学习系统的自然转换提供了理论基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB",
        "cs.DM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01708v1",
      "published_date": "2025-02-03 14:45:02 UTC",
      "updated_date": "2025-02-03 14:45:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:19:48.332765"
    },
    {
      "arxiv_id": "2502.01406v1",
      "title": "GRADIEND: Monosemantic Feature Learning within Neural Networks Applied to Gender Debiasing of Transformer Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jonathan Drechsel",
        "Steffen Herbold"
      ],
      "abstract": "AI systems frequently exhibit and amplify social biases, including gender\nbias, leading to harmful consequences in critical areas. This study introduces\na novel encoder-decoder approach that leverages model gradients to learn a\nsingle monosemantic feature neuron encoding gender information. We show that\nour method can be used to debias transformer-based language models, while\nmaintaining other capabilities. We demonstrate the effectiveness of our\napproach across multiple encoder-only based models and highlight its potential\nfor broader applications.",
      "tldr_zh": "这篇论文介绍了 GRADIEND，一种新型的编码器-解码器方法，利用模型 gradients 来学习单一的 monosemantic feature neuron，以编码性别信息，从而解决 AI 系统中的性别偏见问题。该方法应用于 Transformer 模型的 gender debiasing，能够有效去除偏见同时保持模型的其他能力。在多个基于编码器的模型上进行实验验证后，研究突出了 GRADIEND 的广泛应用潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01406v1",
      "published_date": "2025-02-03 14:38:27 UTC",
      "updated_date": "2025-02-03 14:38:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:20:00.509073"
    },
    {
      "arxiv_id": "2502.01403v3",
      "title": "AdaSVD: Adaptive Singular Value Decomposition for Large Language Models",
      "title_zh": "AdaSVD：自适应奇异值分解用于大语言模型",
      "authors": [
        "Zhiteng Li",
        "Mingyuan Xia",
        "Jingyuan Zhang",
        "Zheng Hui",
        "Linghe Kong",
        "Yulun Zhang",
        "Xiaokang Yang"
      ],
      "abstract": "Large language models (LLMs) have achieved remarkable success in natural\nlanguage processing (NLP) tasks, yet their substantial memory requirements\npresent significant challenges for deployment on resource-constrained devices.\nSingular Value Decomposition (SVD) has emerged as a promising compression\ntechnique for LLMs, offering considerable reductions in memory overhead.\nHowever, existing SVD-based methods often struggle to effectively mitigate the\nerrors introduced by SVD truncation, leading to a noticeable performance gap\nwhen compared to the original models. Furthermore, applying a uniform\ncompression ratio across all transformer layers fails to account for the\nvarying importance of different layers. To address these challenges, we propose\nAdaSVD, an adaptive SVD-based LLM compression approach. Specifically, AdaSVD\nintroduces adaComp, which adaptively compensates for SVD truncation errors by\nalternately updating the singular matrices $\\mathcal{U}$ and\n$\\mathcal{V}^\\top$. Additionally, AdaSVD introduces adaCR, which adaptively\nassigns layer-specific compression ratios based on the relative importance of\neach layer. Extensive experiments across multiple LLM/VLM families and\nevaluation metrics demonstrate that AdaSVD consistently outperforms\nstate-of-the-art (SOTA) SVD-based methods, achieving superior performance with\nsignificantly reduced memory requirements. Code and models of AdaSVD will be\navailable at https://github.com/ZHITENGLI/AdaSVD.",
      "tldr_zh": "大型语言模型（LLMs）在处理自然语言任务时面临高内存需求的问题，现有的奇异值分解（SVD）压缩方法难以有效缓解截断错误并忽略不同Transformer层的重要性差异。论文提出AdaSVD，一种自适应SVD压缩方法，包括adaComp组件（通过交替更新奇异矩阵$\\mathcal{U}$和$\\mathcal{V}^\\top$补偿截断错误）和adaCR组件（根据层重要性分配特定压缩比率）。实验结果显示，AdaSVD在多个LLM/VLM系列上优于现有最先进（SOTA）方法，实现了更高的性能和显著减少的内存开销。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "The code and models will be available at\n  https://github.com/ZHITENGLI/AdaSVD",
      "pdf_url": "http://arxiv.org/pdf/2502.01403v3",
      "published_date": "2025-02-03 14:34:37 UTC",
      "updated_date": "2025-03-09 09:04:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:20:12.861845"
    },
    {
      "arxiv_id": "2502.01397v1",
      "title": "Can message-passing GNN approximate triangular factorizations of sparse matrices?",
      "title_zh": "翻译失败",
      "authors": [
        "Vladislav Trifonov",
        "Ekaterina Muravleva",
        "Ivan Oseledets"
      ],
      "abstract": "We study fundamental limitations of Graph Neural Networks (GNNs) for learning\nsparse matrix preconditioners. While recent works have shown promising results\nusing GNNs to predict incomplete factorizations, we demonstrate that the local\nnature of message passing creates inherent barriers for capturing non-local\ndependencies required for optimal preconditioning. We introduce a new benchmark\ndataset of matrices where good sparse preconditioners exist but require\nnon-local computations, constructed using both synthetic examples and\nreal-world matrices. Our experimental results show that current GNN\narchitectures struggle to approximate these preconditioners, suggesting the\nneed for new architectural approaches beyond traditional message passing\nnetworks. We provide theoretical analysis and empirical evidence to explain\nthese limitations, with implications for the broader use of GNNs in numerical\nlinear algebra.",
      "tldr_zh": "本研究探讨了消息传递 Graph Neural Networks (GNNs) 在逼近稀疏矩阵三角因子分解（triangular factorizations）时的基本限制，强调其局部消息传递机制难以捕捉所需的非局部依赖性，从而影响稀疏矩阵预处理器的学习。研究者构建了一个新基准数据集，包括合成和真实世界矩阵，这些矩阵需要非局部计算才能获得有效的预处理器。实验结果显示，现有 GNN 架构在该数据集上表现不佳，无法准确逼近这些预处理器。理论分析和经验证据进一步解释了这些局限性，并暗示 GNNs 在数值线性代数领域的应用需发展超越传统消息传递网络的新架构。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NA",
        "math.NA"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01397v1",
      "published_date": "2025-02-03 14:28:20 UTC",
      "updated_date": "2025-02-03 14:28:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:20:25.395210"
    },
    {
      "arxiv_id": "2502.01391v2",
      "title": "Learning Traffic Anomalies from Generative Models on Real-Time Observations",
      "title_zh": "翻译失败",
      "authors": [
        "Fotis I. Giasemis",
        "Alexandros Sopasakis"
      ],
      "abstract": "Accurate detection of traffic anomalies is crucial for effective urban\ntraffic management and congestion mitigation. We use the Spatiotemporal\nGenerative Adversarial Network (STGAN) framework combining Graph Neural\nNetworks and Long Short-Term Memory networks to capture complex spatial and\ntemporal dependencies in traffic data. We apply STGAN to real-time,\nminute-by-minute observations from 42 traffic cameras across Gothenburg,\nSweden, collected over several months in 2020. The images are processed to\ncompute a flow metric representing vehicle density, which serves as input for\nthe model. Training is conducted on data from April to November 2020, and\nvalidation is performed on a separate dataset from November 14 to 23, 2020. Our\nresults demonstrate that the model effectively detects traffic anomalies with\nhigh precision and low false positive rates. The detected anomalies include\ncamera signal interruptions, visual artifacts, and extreme weather conditions\naffecting traffic flow.",
      "tldr_zh": "本研究提出使用Spatiotemporal Generative Adversarial Network (STGAN)框架结合Graph Neural Networks和Long Short-Term Memory网络，来捕捉交通数据的空间和时间依赖性，从而实现对交通异常的准确检测。该框架应用于瑞典哥德堡42个交通摄像头的实时分钟级观察数据，通过计算车辆密度作为输入，并在2020年4月至11月的训练数据上进行训练。实验结果显示，模型在11月14日至23日的验证集上表现出高精度和低假阳性率，能够有效识别摄像头信号中断、视觉伪像以及极端天气对交通流的影响，为城市交通管理和拥堵缓解提供可靠工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01391v2",
      "published_date": "2025-02-03 14:23:23 UTC",
      "updated_date": "2025-05-14 09:00:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:20:36.242966"
    },
    {
      "arxiv_id": "2502.01387v3",
      "title": "TeLL-Drive: Enhancing Autonomous Driving with Teacher LLM-Guided Deep Reinforcement Learning",
      "title_zh": "TeLL-Drive：通过教师大型语言模型指导的深度强化学习增强自动驾驶",
      "authors": [
        "Chengkai Xu",
        "Jiaqi Liu",
        "Shiyu Fang",
        "Yiming Cui",
        "Dong Chen",
        "Peng Hang",
        "Jian Sun"
      ],
      "abstract": "Although Deep Reinforcement Learning (DRL) and Large Language Models (LLMs)\neach show promise in addressing decision-making challenges in autonomous\ndriving, DRL often suffers from high sample complexity, while LLMs have\ndifficulty ensuring real-time decision making. To address these limitations, we\npropose TeLL-Drive, a hybrid framework that integrates a Teacher LLM to guide\nan attention-based Student DRL policy. By incorporating risk metrics,\nhistorical scenario retrieval, and domain heuristics into context-rich prompts,\nthe LLM produces high-level driving strategies through chain-of-thought\nreasoning. A self-attention mechanism then fuses these strategies with the DRL\nagent's exploration, accelerating policy convergence and boosting robustness\nacross diverse driving conditions. The experimental results, evaluated across\nmultiple traffic scenarios, show that TeLL-Drive outperforms existing baseline\nmethods, including other LLM-based approaches, in terms of success rates,\naverage returns, and real-time feasibility. Ablation studies underscore the\nimportance of each model component, especially the synergy between the\nattention mechanism and LLM-driven guidance. Finally, we build a virtual-real\nfusion experimental platform to verify the real-time performance, robustness,\nand reliability of the algorithm running on real vehicles through\nvehicle-in-loop experiments.",
      "tldr_zh": "本文提出 TeLL-Drive 框架，将 Teacher LLM 用于指导基于注意力的 Student DRL（Deep Reinforcement Learning），以解决自动驾驶决策中 DRL 的高样本复杂性和 LLMs 的实时决策挑战。框架通过风险指标、历史场景检索和领域启发式生成上下文丰富的提示，结合链式思维推理产生高级驾驶策略，并利用自注意力机制将这些策略与 DRL 代理的探索融合，加速策略收敛并提升在多样驾驶条件下的鲁棒性。实验结果显示，TeLL-Drive 在多个交通场景中优于现有基线方法，在成功率、平均回报和实时可行性方面表现出色；消融研究和虚拟-真实融合实验平台进一步验证了各组件的协同作用及其在真实车辆上的可靠性能。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01387v3",
      "published_date": "2025-02-03 14:22:03 UTC",
      "updated_date": "2025-02-20 14:09:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:20:49.584814"
    },
    {
      "arxiv_id": "2502.01384v2",
      "title": "Fine-Tuning Discrete Diffusion Models with Policy Gradient Methods",
      "title_zh": "翻译失败",
      "authors": [
        "Oussama Zekri",
        "Nicolas Boullé"
      ],
      "abstract": "Discrete diffusion models have recently gained significant attention due to\ntheir ability to process complex discrete structures for language modeling.\nHowever, fine-tuning these models with policy gradient methods, as is commonly\ndone in Reinforcement Learning from Human Feedback (RLHF), remains a\nchallenging task. We propose an efficient, broadly applicable, and\ntheoretically justified policy gradient algorithm, called Score Entropy Policy\nOptimization (SEPO), for fine-tuning discrete diffusion models over\nnon-differentiable rewards. Our numerical experiments across several discrete\ngenerative tasks demonstrate the scalability and efficiency of our method. Our\ncode is available at https://github.com/ozekri/SEPO.",
      "tldr_zh": "这篇论文针对离散扩散模型（Discrete Diffusion Models）的微调问题，提出了Score Entropy Policy Optimization (SEPO)算法，以解决使用策略梯度方法（Policy Gradient Methods）处理非微分奖励的挑战，如在Reinforcement Learning from Human Feedback (RLHF)中的应用。SEPO是一种高效、广泛适用的算法，具有坚实的理论基础，能够优化这些模型在复杂离散结构上的表现。在多个离散生成任务的实验中，该方法展示了出色的可扩展性和效率，并提供了开源代码以供进一步验证。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "30 pages, 8 figures, 8 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.01384v2",
      "published_date": "2025-02-03 14:20:19 UTC",
      "updated_date": "2025-05-16 05:22:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:21:00.863417"
    },
    {
      "arxiv_id": "2502.01377v1",
      "title": "Data-Efficient Model for Psychological Resilience Prediction based on Neurological Data",
      "title_zh": "翻译失败",
      "authors": [
        "Zhi Zhang",
        "Yan Liu",
        "Mengxia Gao",
        "Yu Yang",
        "Jiannong Cao",
        "Wai Kai Hou",
        "Shirley Li",
        "Sonata Yau",
        "Yun Kwok Wing",
        "Tatia M. C. Lee"
      ],
      "abstract": "Psychological resilience, defined as the ability to rebound from adversity,\nis crucial for mental health. Compared with traditional resilience assessments\nthrough self-reported questionnaires, resilience assessments based on\nneurological data offer more objective results with biological markers, hence\nsignificantly enhancing credibility. This paper proposes a novel data-efficient\nmodel to address the scarcity of neurological data. We employ Neuro\nKolmogorov-Arnold Networks as the structure of the prediction model. In the\ntraining stage, a new trait-informed multimodal representation algorithm with a\nsmart chunk technique is proposed to learn the shared latent space with limited\ndata. In the test stage, a new noise-informed inference algorithm is proposed\nto address the low signal-to-noise ratio of the neurological data. The proposed\nmodel not only shows impressive performance on both public datasets and\nself-constructed datasets but also provides some valuable psychological\nhypotheses for future research.",
      "tldr_zh": "本论文提出一种数据高效模型，用于基于神经学数据的心理韧性预测，以解决神经数据稀缺的问题。模型采用 Neuro Kolmogorov-Arnold Networks 作为结构，在训练阶段引入特征信息多模态表示算法结合智能分块技术（smart chunk technique），以在有限数据下学习共享潜在空间；在测试阶段，使用噪声信息推理算法（noise-informed inference algorithm）处理神经数据的低信噪比。实验结果显示，该模型在公共数据集和自构建数据集上表现出色，并为未来心理研究提供了有价值的假设。",
      "categories": [
        "cs.CE",
        "cs.AI"
      ],
      "primary_category": "cs.CE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01377v1",
      "published_date": "2025-02-03 14:15:15 UTC",
      "updated_date": "2025-02-03 14:15:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:21:12.641716"
    },
    {
      "arxiv_id": "2502.01375v1",
      "title": "Compact Rule-Based Classifier Learning via Gradient Descent",
      "title_zh": "通过梯度下降实现的紧凑规则基分类器学习",
      "authors": [
        "Javier Fumanal-Idocin",
        "Raquel Fernandez-Peralta",
        "Javier Andreu-Perez"
      ],
      "abstract": "Rule-based models play a crucial role in scenarios that require transparency\nand accountable decision-making. However, they primarily consist of discrete\nparameters and structures, which presents challenges for scalability and\noptimization. In this work, we introduce a new rule-based classifier trained\nusing gradient descent, in which the user can control the maximum number and\nlength of the rules. For numerical partitions, the user can also control the\npartitions used with fuzzy sets, which also helps keep the number of partitions\nsmall. We perform a series of exhaustive experiments on $40$ datasets to show\nhow this classifier performs in terms of accuracy and rule base size. Then, we\ncompare our results with a genetic search that fits an equivalent classifier\nand with other explainable and non-explainable state-of-the-art classifiers.\nOur results show how our method can obtain compact rule bases that use\nsignificantly fewer patterns than other rule-based methods and perform better\nthan other explainable classifiers.",
      "tldr_zh": "该研究提出了一种紧凑的规则-based 分类器，通过 gradient descent 进行训练，以解决规则-based 模型在可扩展性和优化方面的挑战。用户可以控制规则的最大数量、长度，并使用 fuzzy sets 来管理数值分区，从而保持规则基的紧凑性。在 40 个数据集上的实验显示，该分类器在准确性方面表现良好，并与遗传搜索以及其他可解释和不可解释的分类器比较后，使用更少的模式且优于其他可解释分类器。该方法为透明决策场景提供了高效且可控的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01375v1",
      "published_date": "2025-02-03 14:13:39 UTC",
      "updated_date": "2025-02-03 14:13:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:21:23.947604"
    },
    {
      "arxiv_id": "2502.01707v1",
      "title": "CLIP-DQA: Blindly Evaluating Dehazed Images from Global and Local Perspectives Using CLIP",
      "title_zh": "翻译失败",
      "authors": [
        "Yirui Zeng",
        "Jun Fu",
        "Hadi Amirpour",
        "Huasheng Wang",
        "Guanghui Yue",
        "Hantao Liu",
        "Ying Chen",
        "Wei Zhou"
      ],
      "abstract": "Blind dehazed image quality assessment (BDQA), which aims to accurately\npredict the visual quality of dehazed images without any reference information,\nis essential for the evaluation, comparison, and optimization of image dehazing\nalgorithms. Existing learning-based BDQA methods have achieved remarkable\nsuccess, while the small scale of DQA datasets limits their performance. To\naddress this issue, in this paper, we propose to adapt Contrastive\nLanguage-Image Pre-Training (CLIP), pre-trained on large-scale image-text\npairs, to the BDQA task. Specifically, inspired by the fact that the human\nvisual system understands images based on hierarchical features, we take global\nand local information of the dehazed image as the input of CLIP. To accurately\nmap the input hierarchical information of dehazed images into the quality\nscore, we tune both the vision branch and language branch of CLIP with prompt\nlearning. Experimental results on two authentic DQA datasets demonstrate that\nour proposed approach, named CLIP-DQA, achieves more accurate quality\npredictions over existing BDQA methods. The code is available at\nhttps://github.com/JunFu1995/CLIP-DQA.",
      "tldr_zh": "本研究针对盲去雾图像质量评估（BDQA）问题，提出了一种基于Contrastive Language-Image Pre-Training (CLIP)的CLIP-DQA方法，以解决现有方法受限于数据集规模的问题。CLIP-DQA通过整合去雾图像的全局和本地层次特征作为输入，并利用prompt learning调整CLIP的视觉和语言分支，将这些特征准确映射为质量分数。实验结果显示，在两个真实DQA数据集上，CLIP-DQA比现有BDQA方法实现了更精确的质量预测，证明了其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ISCAS 2025 (Oral)",
      "pdf_url": "http://arxiv.org/pdf/2502.01707v1",
      "published_date": "2025-02-03 14:12:25 UTC",
      "updated_date": "2025-02-03 14:12:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:21:35.927799"
    },
    {
      "arxiv_id": "2502.01364v1",
      "title": "Meursault as a Data Point",
      "title_zh": "翻译失败",
      "authors": [
        "Abhinav Pratap",
        "Amit Pathak"
      ],
      "abstract": "In an era dominated by datafication, the reduction of human experiences to\nquantifiable metrics raises profound philosophical and ethical questions. This\npaper explores these issues through the lens of Meursault, the protagonist of\nAlbert Camus' The Stranger, whose emotionally detached existence epitomizes the\nexistential concept of absurdity. Using natural language processing (NLP)\ntechniques including emotion detection (BERT), sentiment analysis (VADER), and\nnamed entity recognition (spaCy)-this study quantifies key events and behaviors\nin Meursault's life. Our analysis reveals the inherent limitations of applying\nalgorithmic models to complex human experiences, particularly those rooted in\nexistential alienation and moral ambiguity. By examining how modern AI tools\nmisinterpret Meursault's actions and emotions, this research underscores the\nbroader ethical dilemmas of reducing nuanced human narratives to data points,\nchallenging the foundational assumptions of our data-driven society. The\nfindings presented in this paper serve as a critique of the increasing reliance\non data-driven narratives and advocate for incorporating humanistic values in\nartificial intelligence.",
      "tldr_zh": "这篇论文探讨了数据化时代将人类经历简化为量化指标所引发的哲学和伦理问题，以卡缪《局外人》中的主人公Meursault为例，突显存在主义荒谬概念。研究采用NLP技术，包括BERT的情感检测、VADER的情感分析和spaCy的命名实体识别，来量化Meursault的关键事件和行为。分析结果揭示了算法模型在处理复杂人类经历时的局限性，特别是对存在主义疏离和道德模糊的误解，从而强调了将细微人类叙事简化为数据点的伦理困境。最终，该研究批评了对数据驱动社会的依赖，并主张在AI中融入人文价值以平衡技术应用。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.DL",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "7 pages, 9 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.01364v1",
      "published_date": "2025-02-03 13:56:48 UTC",
      "updated_date": "2025-02-03 13:56:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:21:48.986946"
    },
    {
      "arxiv_id": "2502.01344v1",
      "title": "PSSD: Making Large Language Models Self-denial via Human Psyche Structure",
      "title_zh": "PSSD：通过人类心理",
      "authors": [
        "Jinzhi Liao",
        "Zenghua Liao",
        "Xiang Zhao"
      ],
      "abstract": "The enhance of accuracy in reasoning results of LLMs arouses the community's\ninterests, wherein pioneering studies investigate post-hoc strategies to\nrectify potential mistakes. Despite extensive efforts, they are all stuck in a\nstate of resource competition demanding significant time and computing\nexpenses. The cause of the situation lies in the failure of identifying the\nfundamental feature of the solutions in this line, coined as the self-denial of\nLLMs. In other words, LLMs should confidently determine the potential existence\nof mistakes and carefully execute the targeted correction. As the whole\nprocedure conducts within LLMs, supporting and persuasive references are hard\nto acquire, while the absence of specific steps towards refining hidden\nmistakes persists even when errors are acknowledged. In response to the\nchallenges, we present PSSD, which refers to and implements the human psyche\nstructure such that three distinct and interconnected roles contribute to human\nreasoning. Specifically, PSSD leverages the recent multi-agent paradigm, and is\nfurther enhanced with three innovatively conceived roles: (1) the\nintuition-based id role that provides initial attempts based on benign LLMs;\n(2) the rule-driven superego role that summarizes rules to regulate the above\nattempts, and returns specific key points as guidance; and (3) the\nscript-centric ego role that absorbs all procedural information to generate\nexecutable script for the final answer prediction. Extensive experiments\ndemonstrate that the proposed design not only better enhance reasoning\ncapabilities, but also seamlessly integrate with current models, leading to\nsuperior performance.",
      "tldr_zh": "该研究提出PSSD框架，通过借鉴人类心理结构（human psyche structure），使Large Language Models (LLMs) 具备self-denial能力，即自信识别和纠正潜在错误，从而提升推理准确性。PSSD采用multi-agent paradigm，设计三个创新角色：（1）基于直觉的id角色提供初始尝试；（2）规则驱动的superego角色总结指导规则；（3）脚本中心的ego角色整合信息生成最终答案。实验结果显示，PSSD不仅显著增强LLMs的推理能力，还能无缝整合现有模型，实现优越性能。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "WWW '25",
      "pdf_url": "http://arxiv.org/pdf/2502.01344v1",
      "published_date": "2025-02-03 13:37:21 UTC",
      "updated_date": "2025-02-03 13:37:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:22:00.122765"
    },
    {
      "arxiv_id": "2502.01342v1",
      "title": "Activation by Interval-wise Dropout: A Simple Way to Prevent Neural Networks from Plasticity Loss",
      "title_zh": "翻译失败",
      "authors": [
        "Sangyeon Park",
        "Isaac Han",
        "Seungwon Oh",
        "Kyung-Joong Kim"
      ],
      "abstract": "Plasticity loss, a critical challenge in neural network training, limits a\nmodel's ability to adapt to new tasks or shifts in data distribution. This\npaper introduces AID (Activation by Interval-wise Dropout), a novel method\ninspired by Dropout, designed to address plasticity loss. Unlike Dropout, AID\ngenerates subnetworks by applying Dropout with different probabilities on each\npreactivation interval. Theoretical analysis reveals that AID regularizes the\nnetwork, promoting behavior analogous to that of deep linear networks, which do\nnot suffer from plasticity loss. We validate the effectiveness of AID in\nmaintaining plasticity across various benchmarks, including continual learning\ntasks on standard image classification datasets such as CIFAR10, CIFAR100, and\nTinyImageNet. Furthermore, we show that AID enhances reinforcement learning\nperformance in the Arcade Learning Environment benchmark.",
      "tldr_zh": "这篇论文提出了 AID（Activation by Interval-wise Dropout），一种基于 Dropout 的简单方法，用于防止神经网络的 Plasticity loss，从而提升模型适应新任务或数据分布变化的能力。AID 通过在每个 preactivation interval 上应用不同概率的 Dropout 生成子网络，并通过理论分析证明其正则化效果，使网络行为类似于不会遭受 Plasticity loss 的深层线性网络。在实验中，AID 在 CIFAR10、CIFAR100 和 TinyImageNet 的持续学习任务中，以及 Arcade Learning Environment 的强化学习基准上，显著提高了模型的性能和可塑性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01342v1",
      "published_date": "2025-02-03 13:34:53 UTC",
      "updated_date": "2025-02-03 13:34:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:22:12.969961"
    },
    {
      "arxiv_id": "2502.01706v2",
      "title": "Comply: Learning Sentences with Complex Weights inspired by Fruit Fly Olfaction",
      "title_zh": "翻译失败",
      "authors": [
        "Alexei Figueroa",
        "Justus Westerhoff",
        "Golzar Atefi",
        "Dennis Fast",
        "Benjamin Winter",
        "Felix Alexader Gers",
        "Alexander Löser",
        "Wolfang Nejdl"
      ],
      "abstract": "Biologically inspired neural networks offer alternative avenues to model data\ndistributions. FlyVec is a recent example that draws inspiration from the fruit\nfly's olfactory circuit to tackle the task of learning word embeddings.\nSurprisingly, this model performs competitively even against deep learning\napproaches specifically designed to encode text, and it does so with the\nhighest degree of computational efficiency. We pose the question of whether\nthis performance can be improved further. For this, we introduce Comply. By\nincorporating positional information through complex weights, we enable a\nsingle-layer neural network to learn sequence representations. Our experiments\nshow that Comply not only supersedes FlyVec but also performs on par with\nsignificantly larger state-of-the-art models. We achieve this without\nadditional parameters. Comply yields sparse contextual representations of\nsentences that can be interpreted explicitly from the neuron weights.",
      "tldr_zh": "本研究提出 Comply，一种受果蝇嗅觉系统启发的神经网络模型，用于学习句子表示，通过引入 complex weights 来整合位置信息，从而使单层神经网络能够处理序列数据。相比于之前的 FlyVec 模型，Comply 在实验中表现出色，不仅超越了 FlyVec 的性能，还与更大的 state-of-the-art 模型相当，同时未增加额外参数。Comply 生成的句子表示是稀疏且可解释的，能够从神经元权重中显式提取，这为高效的文本编码提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at NICE2025",
      "pdf_url": "http://arxiv.org/pdf/2502.01706v2",
      "published_date": "2025-02-03 13:30:44 UTC",
      "updated_date": "2025-02-05 14:17:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:22:25.133738"
    },
    {
      "arxiv_id": "2502.01316v2",
      "title": "Learning Fused State Representations for Control from Multi-View Observations",
      "title_zh": "翻译失败",
      "authors": [
        "Zeyu Wang",
        "Yao-Hui Li",
        "Xin Li",
        "Hongyu Zang",
        "Romain Laroche",
        "Riashat Islam"
      ],
      "abstract": "Multi-View Reinforcement Learning (MVRL) seeks to provide agents with\nmulti-view observations, enabling them to perceive environment with greater\neffectiveness and precision. Recent advancements in MVRL focus on extracting\nlatent representations from multiview observations and leveraging them in\ncontrol tasks. However, it is not straightforward to learn compact and\ntask-relevant representations, particularly in the presence of redundancy,\ndistracting information, or missing views. In this paper, we propose Multi-view\nFusion State for Control (MFSC), firstly incorporating bisimulation metric\nlearning into MVRL to learn task-relevant representations. Furthermore, we\npropose a multiview-based mask and latent reconstruction auxiliary task that\nexploits shared information across views and improves MFSC's robustness in\nmissing views by introducing a mask token. Extensive experimental results\ndemonstrate that our method outperforms existing approaches in MVRL tasks. Even\nin more realistic scenarios with interference or missing views, MFSC\nconsistently maintains high performance.",
      "tldr_zh": "该论文提出Multi-View Reinforcement Learning (MVRL)中的新方法Multi-view Fusion State for Control (MFSC)，旨在从多视图观察中学习紧凑且任务相关的状态表示，以提升代理在控制任务中的感知精度。MFSC首次将bisimulation metric learning整合到MVRL中，并引入基于多视图的掩码和潜在表示重建辅助任务，利用视图间共享信息，并通过掩码标记增强对缺失视图的鲁棒性。实验结果表明，MFSC在各种MVRL任务中优于现有方法，即使在存在干扰或缺失视图的现实场景中，也能保持高性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01316v2",
      "published_date": "2025-02-03 12:46:02 UTC",
      "updated_date": "2025-05-21 12:42:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:22:37.443710"
    },
    {
      "arxiv_id": "2502.01311v1",
      "title": "TFBS-Finder: Deep Learning-based Model with DNABERT and Convolutional Networks to Predict Transcription Factor Binding Sites",
      "title_zh": "翻译失败",
      "authors": [
        "Nimisha Ghosh",
        "Pratik Dutta",
        "Daniele Santoni"
      ],
      "abstract": "Transcription factors are proteins that regulate the expression of genes by\nbinding to specific genomic regions known as Transcription Factor Binding Sites\n(TFBSs), typically located in the promoter regions of those genes. Accurate\nprediction of these binding sites is essential for understanding the complex\ngene regulatory networks underlying various cellular functions. In this regard,\nmany deep learning models have been developed for such prediction, but there is\nstill scope of improvement. In this work, we have developed a deep learning\nmodel which uses pre-trained DNABERT, a Convolutional Neural Network (CNN)\nmodule, a Modified Convolutional Block Attention Module (MCBAM), a Multi-Scale\nConvolutions with Attention (MSCA) module and an output module. The pre-trained\nDNABERT is used for sequence embedding, thereby capturing the long-term\ndependencies in the DNA sequences while the CNN, MCBAM and MSCA modules are\nuseful in extracting higher-order local features. TFBS-Finder is trained and\ntested on 165 ENCODE ChIP-seq datasets. We have also performed ablation studies\nas well as cross-cell line validations and comparisons with other models. The\nexperimental results show the superiority of the proposed method in predicting\nTFBSs compared to the existing methodologies. The codes and the relevant\ndatasets are publicly available at\nhttps://github.com/NimishaGhosh/TFBS-Finder/.",
      "tldr_zh": "这篇论文提出了一种名为 TFBS-Finder 的深度学习模型，用于预测转录因子结合位点 (TFBS)，以更好地理解基因调控网络。模型整合了 pre-trained DNABERT 用于 DNA 序列嵌入以捕捉长程依赖，以及 CNN 模块、Modified Convolutional Block Attention Module (MCBAM) 和 Multi-Scale Convolutions with Attention (MSCA) 模块来提取高级局部特征。TFBS-Finder 在 165 个 ENCODE ChIP-seq 数据集上训练和测试，并通过消融研究、跨细胞线验证和与其他模型的比较，证明其在 TFBS 预测准确性上优于现有方法。代码和数据集已公开在 GitHub 上，可供进一步研究。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.GN"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01311v1",
      "published_date": "2025-02-03 12:41:11 UTC",
      "updated_date": "2025-02-03 12:41:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:22:49.752572"
    },
    {
      "arxiv_id": "2502.01310v1",
      "title": "A Statistical Learning Perspective on Semi-dual Adversarial Neural Optimal Transport Solvers",
      "title_zh": "翻译失败",
      "authors": [
        "Roman Tarasov",
        "Petr Mokrov",
        "Milena Gazdieva",
        "Evgeny Burnaev",
        "Alexander Korotin"
      ],
      "abstract": "Neural network based Optimal Transport (OT) is a recent and fruitful\ndirection in the generative modeling community. It finds its applications in\nvarious fields such as domain translation, image super-resolution,\ncomputational biology and others. Among the existing approaches to OT, of\nconsiderable interest are adversarial minimax solvers based on semi-dual\nformulations of OT problems. While promising, these methods lack theoretical\ninvestigation from a statistical learning perspective. Our work fills this gap\nby establishing upper bounds on the generalization error of an approximate OT\nmap recovered by the minimax quadratic OT solver. Importantly, the bounds we\nderive depend solely on some standard statistical and mathematical properties\nof the considered functional classes (neural networks). While our analysis\nfocuses on the quadratic OT, we believe that similar bounds could be derived\nfor more general OT formulations, paving the promising direction for future\nresearch.",
      "tldr_zh": "这篇论文从统计学习视角分析了基于半对偶(semi-dual)公式的对抗最小最大(minimax)神经网络Optimal Transport (OT)求解器，填补了这些方法缺乏理论支撑的空白。作者建立了二次OT映射的泛化错误上界，这些上界仅依赖于功能类（如神经网络）的标准统计和数学属性。研究结果表明，此框架适用于OT在领域转换、图像超分辨率和计算生物学等领域的应用，并为扩展到更一般OT公式化提供了未来研究方向。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01310v1",
      "published_date": "2025-02-03 12:37:20 UTC",
      "updated_date": "2025-02-03 12:37:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:23:00.455144"
    },
    {
      "arxiv_id": "2502.01303v1",
      "title": "Partial Channel Network: Compute Fewer, Perform Better",
      "title_zh": "部分通道网络：计算更",
      "authors": [
        "Haiduo Huang",
        "Tian Xia",
        "Wenzhe zhao",
        "Pengju Ren"
      ],
      "abstract": "Designing a module or mechanism that enables a network to maintain low\nparameters and FLOPs without sacrificing accuracy and throughput remains a\nchallenge. To address this challenge and exploit the redundancy within feature\nmap channels, we propose a new solution: partial channel mechanism (PCM).\nSpecifically, through the split operation, the feature map channels are divided\ninto different parts, with each part corresponding to different operations,\nsuch as convolution, attention, pooling, and identity mapping. Based on this\nassumption, we introduce a novel partial attention convolution (PATConv) that\ncan efficiently combine convolution with visual attention. Our exploration\nindicates that the PATConv can completely replace both the regular convolution\nand the regular visual attention while reducing model parameters and FLOPs.\nMoreover, PATConv can derive three new types of blocks: Partial\nChannel-Attention block (PAT_ch), Partial Spatial-Attention block (PAT_sp), and\nPartial Self-Attention block (PAT_sf). In addition, we propose a novel dynamic\npartial convolution (DPConv) that can adaptively learn the proportion of split\nchannels in different layers to achieve better trade-offs. Building on PATConv\nand DPConv, we propose a new hybrid network family, named PartialNet, which\nachieves superior top-1 accuracy and inference speed compared to some SOTA\nmodels on ImageNet-1K classification and excels in both detection and\nsegmentation on the COCO dataset. Our code is available at\nhttps://github.com/haiduo/PartialNet.",
      "tldr_zh": "本文提出部分通道机制 (PCM)，通过将特征图通道分成不同部分并分配特定操作（如卷积、注意力等），来减少网络参数和 FLOPs，同时维持准确性和吞吐量。核心创新包括部分注意力卷积 (PATConv)，能替换传统卷积和注意力模块，并衍生出三种新块（PAT_ch、PAT_sp、PAT_sf），以及动态部分卷积 (DPConv) 用于自适应优化通道比例。实验结果显示，PartialNet 网络家族在 ImageNet-1K 分类任务上实现了更高的 top-1 准确率和推理速度，并在 COCO 数据集的检测和分割任务中优于现有 SOTA 模型。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01303v1",
      "published_date": "2025-02-03 12:26:55 UTC",
      "updated_date": "2025-02-03 12:26:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:23:13.029736"
    },
    {
      "arxiv_id": "2502.01295v1",
      "title": "Common Foundations for SHACL, ShEx, and PG-Schema",
      "title_zh": "SHACL、ShEx 和 PG-Schema 的共同基础",
      "authors": [
        "S. Ahmetaj",
        "I. Boneva",
        "J. Hidders",
        "K. Hose",
        "M. Jakubowski",
        "J. E. Labra-Gayo",
        "W. Martens",
        "F. Mogavero",
        "F. Murlak",
        "C. Okulmus",
        "A. Polleres",
        "O. Savkovic",
        "M. Simkus",
        "D. Tomaszuk"
      ],
      "abstract": "Graphs have emerged as an important foundation for a variety of applications,\nincluding capturing and reasoning over factual knowledge, semantic data\nintegration, social networks, and providing factual knowledge for machine\nlearning algorithms. To formalise certain properties of the data and to ensure\ndata quality, there is a need to describe the schema of such graphs. Because of\nthe breadth of applications and availability of different data models, such as\nRDF and property graphs, both the Semantic Web and the database community have\nindependently developed graph schema languages: SHACL, ShEx, and PG-Schema.\nEach language has its unique approach to defining constraints and validating\ngraph data, leaving potential users in the dark about their commonalities and\ndifferences. In this paper, we provide formal, concise definitions of the core\ncomponents of each of these schema languages. We employ a uniform framework to\nfacilitate a comprehensive comparison between the languages and identify a\ncommon set of functionalities, shedding light on both overlapping and\ndistinctive features of the three languages.",
      "tldr_zh": "这篇论文探讨了 SHACL、ShEx 和 PG-Schema 这三种图模式语言的共同基础，旨在解决图数据在 RDF 和属性图等模型中的约束定义和验证问题。作者采用统一框架，提供这些语言核心组件的正式、简洁定义，并进行全面比较。研究结果揭示了三者共享的功能集，以及它们的重叠和独特特征，从而帮助用户更好地理解和选择合适的模式语言。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "I.2.4"
      ],
      "primary_category": "cs.DB",
      "comment": "To be published at WWW 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.01295v1",
      "published_date": "2025-02-03 12:17:25 UTC",
      "updated_date": "2025-02-03 12:17:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:23:25.556498"
    },
    {
      "arxiv_id": "2502.01282v1",
      "title": "Rational Gaussian wavelets and corresponding model driven neural networks",
      "title_zh": "有理高斯小波和相应的模型驱动神经网络",
      "authors": [
        "Attila Miklós Ámon",
        "Kristian Fenech",
        "Péter Kovács",
        "Tamás Dózsa"
      ],
      "abstract": "In this paper we consider the continuous wavelet transform using Gaussian\nwavelets multiplied by an appropriate rational term. The zeros and poles of\nthis rational modifier act as free parameters and their choice highly\ninfluences the shape of the mother wavelet. This allows the proposed\nconstruction to approximate signals with complex morphology using only a few\nwavelet coefficients. We show that the proposed rational Gaussian wavelets are\nadmissible and provide numerical approximations of the wavelet coefficients\nusing variable projection operators. In addition, we show how the proposed\nvariable projection based rational Gaussian wavelet transform can be used in\nneural networks to obtain a highly interpretable feature learning layer. We\ndemonstrate the effectiveness of the proposed scheme through a biomedical\napplication, namely, the detection of ventricular ectopic beats (VEBs) in real\nECG measurements.",
      "tldr_zh": "本论文提出了一种基于理性项修改的高斯小波（Gaussian wavelets），通过零点和极点作为自由参数来调整母小波的形状，从而用少量小波系数高效近似复杂形态的信号。研究证明了这些理性高斯小波的可接受性，并使用可变投影算子（variable projection operators）提供数值逼近方法。作者进一步将这种小波变换整合到神经网络中，作为一个高度可解释的特征学习层，并在心电图检测室性早搏（VEBs）的生物医学应用中验证了方案的有效性。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "65D15",
        "G.1.2"
      ],
      "primary_category": "stat.ML",
      "comment": "Submitted to IEEE Transactions on Signal Processing, 2024 (under\n  review)",
      "pdf_url": "http://arxiv.org/pdf/2502.01282v1",
      "published_date": "2025-02-03 11:53:11 UTC",
      "updated_date": "2025-02-03 11:53:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:23:36.784776"
    },
    {
      "arxiv_id": "2502.01276v1",
      "title": "HyperSHAP: Shapley Values and Interactions for Hyperparameter Importance",
      "title_zh": "HyperSHAP: Shap",
      "authors": [
        "Marcel Wever",
        "Maximilian Muschalik",
        "Fabian Fumagalli",
        "Marius Lindauer"
      ],
      "abstract": "Hyperparameter optimization (HPO) is a crucial step in achieving strong\npredictive performance. However, the impact of individual hyperparameters on\nmodel generalization is highly context-dependent, prohibiting a\none-size-fits-all solution and requiring opaque automated machine learning\n(AutoML) systems to find optimal configurations. The black-box nature of most\nAutoML systems undermines user trust and discourages adoption. To address this,\nwe propose a game-theoretic explainability framework for HPO that is based on\nShapley values and interactions. Our approach provides an additive\ndecomposition of a performance measure across hyperparameters, enabling local\nand global explanations of hyperparameter importance and interactions. The\nframework, named HyperSHAP, offers insights into ablations, the tunability of\nlearning algorithms, and optimizer behavior across different hyperparameter\nspaces. We evaluate HyperSHAP on various HPO benchmarks by analyzing the\ninteraction structure of the HPO problem. Our results show that while\nhigher-order interactions exist, most performance improvements can be explained\nby focusing on lower-order representations.",
      "tldr_zh": "这篇论文提出了 HyperSHAP，一种基于 Shapley values 和 interactions 的游戏理论框架，用于解释超参数优化 (HPO) 的重要性，旨在解决 AutoML 系统黑箱问题并提升用户信任。HyperSHAP 通过对性能指标的加和分解，提供超参数的局部和全局解释，分析其重要性、交互结构以及在消融实验和优化器行为中的作用。在各种 HPO 基准上的实验显示，虽然存在高阶交互，但大多数性能提升可由低阶表示解释，从而为更透明的 HPO 实践奠定基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01276v1",
      "published_date": "2025-02-03 11:47:52 UTC",
      "updated_date": "2025-02-03 11:47:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:23:49.250910"
    },
    {
      "arxiv_id": "2502.01273v1",
      "title": "Analysis of Student-LLM Interaction in a Software Engineering Project",
      "title_zh": "软件工程项目中学生与LLM互动的分析",
      "authors": [
        "Agrawal Naman",
        "Ridwan Shariffdeen",
        "Guanlin Wang",
        "Sanka Rasnayaka",
        "Ganesh Neelakanta Iyer"
      ],
      "abstract": "Large Language Models (LLMs) are becoming increasingly competent across\nvarious domains, educators are showing a growing interest in integrating these\nLLMs into the learning process. Especially in software engineering, LLMs have\ndemonstrated qualitatively better capabilities in code summarization, code\ngeneration, and debugging. Despite various research on LLMs for software\nengineering tasks in practice, limited research captures the benefits of LLMs\nfor pedagogical advancements and their impact on the student learning process.\nTo this extent, we analyze 126 undergraduate students' interaction with an AI\nassistant during a 13-week semester to understand the benefits of AI for\nsoftware engineering learning. We analyze the conversations, code generated,\ncode utilized, and the human intervention levels to integrate the code into the\ncode base.\n  Our findings suggest that students prefer ChatGPT over CoPilot. Our analysis\nalso finds that ChatGPT generates responses with lower computational complexity\ncompared to CoPilot. Furthermore, conversational-based interaction helps\nimprove the quality of the code generated compared to auto-generated code.\nEarly adoption of LLMs in software engineering is crucial to remain competitive\nin the rapidly developing landscape. Hence, the next generation of software\nengineers must acquire the necessary skills to interact with AI to improve\nproductivity.",
      "tldr_zh": "本文研究了大型语言模型（LLMs）在软件工程教育中的应用，通过分析126名本科生在13周学期中使用AI助手的互动数据，包括对话、代码生成、使用情况和人类干预水平。结果显示，学生更偏好ChatGPT而非CoPilot，且ChatGPT生成的代码计算复杂度较低；此外，基于对话的互动比自动生成代码能显著提高代码质量。研究强调，早日整合LLMs于教学中至关重要，以培养学生与AI互动的技能，提升软件工程领域的竞争力。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "D.2.3"
      ],
      "primary_category": "cs.SE",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.01273v1",
      "published_date": "2025-02-03 11:44:00 UTC",
      "updated_date": "2025-02-03 11:44:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:24:00.511745"
    },
    {
      "arxiv_id": "2502.01268v1",
      "title": "Resilient UAV Trajectory Planning via Few-Shot Meta-Offline Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Eslam Eldeeb",
        "Hirley Alves"
      ],
      "abstract": "Reinforcement learning (RL) has been a promising essence in future 5G-beyond\nand 6G systems. Its main advantage lies in its robust model-free\ndecision-making in complex and large-dimension wireless environments. However,\nmost existing RL frameworks rely on online interaction with the environment,\nwhich might not be feasible due to safety and cost concerns. Another problem\nwith online RL is the lack of scalability of the designed algorithm with\ndynamic or new environments. This work proposes a novel, resilient, few-shot\nmeta-offline RL algorithm combining offline RL using conservative Q-learning\n(CQL) and meta-learning using model-agnostic meta-learning (MAML). The proposed\nalgorithm can train RL models using static offline datasets without any online\ninteraction with the environments. In addition, with the aid of MAML, the\nproposed model can be scaled up to new unseen environments. We showcase the\nproposed algorithm for optimizing an unmanned aerial vehicle (UAV) 's\ntrajectory and scheduling policy to minimize the age-of-information (AoI) and\ntransmission power of limited-power devices. Numerical results show that the\nproposed few-shot meta-offline RL algorithm converges faster than baseline\nschemes, such as deep Q-networks and CQL. In addition, it is the only algorithm\nthat can achieve optimal joint AoI and transmission power using an offline\ndataset with few shots of data points and is resilient to network failures due\nto unprecedented environmental changes.",
      "tldr_zh": "这篇论文提出了一种结合 Conservative Q-Learning (CQL) 和 Model-Agnostic Meta-Learning (MAML) 的 few-shot meta-offline Reinforcement Learning (RL) 算法，用于解决传统 RL 在复杂无线环境中的在线交互问题和可扩展性不足。算法利用静态离线数据集训练模型，无需实时环境交互，并通过元学习实现对新环境的快速适应。应用于 Unmanned Aerial Vehicle (UAV) 轨迹规划，该方法优化 Age-of-Information (AoI) 和传输功率，实验结果显示其收敛速度比深度 Q 网络和 CQL 等基线更快，且在少量数据下即可实现最佳性能，并对网络故障和环境变化具有弹性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01268v1",
      "published_date": "2025-02-03 11:39:12 UTC",
      "updated_date": "2025-02-03 11:39:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:24:14.271067"
    },
    {
      "arxiv_id": "2502.01253v1",
      "title": "Explainability-Driven Quality Assessment for Rule-Based Systems",
      "title_zh": "基于可解释性驱动的规则系统质量评估",
      "authors": [
        "Oshani Seneviratne",
        "Brendan Capuzzo",
        "William Van Woensel"
      ],
      "abstract": "This paper introduces an explanation framework designed to enhance the\nquality of rules in knowledge-based reasoning systems based on dataset-driven\ninsights. The traditional method for rule induction from data typically\nrequires labor-intensive labeling and data-driven learning. This framework\nprovides an alternative and instead allows for the data-driven refinement of\nexisting rules: it generates explanations of rule inferences and leverages\nhuman interpretation to refine rules. It leverages four complementary\nexplanation types: trace-based, contextual, contrastive, and counterfactual,\nproviding diverse perspectives for debugging, validating, and ultimately\nrefining rules. By embedding explainability into the reasoning architecture,\nthe framework enables knowledge engineers to address inconsistencies, optimize\nthresholds, and ensure fairness, transparency, and interpretability in\ndecision-making processes. Its practicality is demonstrated through a use case\nin finance.",
      "tldr_zh": "这篇论文提出一个基于解释性的框架，用于通过数据集驱动的洞察提升规则基础系统（rule-based systems）的规则质量，该框架替代传统劳动密集型学习方法，转而利用人类解释来精炼现有规则。框架整合了四种互补解释类型：trace-based、contextual、contrastive 和 counterfactual，提供多视角支持规则的调试、验证和优化。通过将解释性嵌入推理架构，该方法帮助知识工程师处理不一致、优化阈值，并确保决策过程的公平性、透明度和可解释性，其实用性在金融领域的用例中得到展示。",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01253v1",
      "published_date": "2025-02-03 11:26:09 UTC",
      "updated_date": "2025-02-03 11:26:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:24:25.364121"
    },
    {
      "arxiv_id": "2502.01247v1",
      "title": "Learnable polynomial, trigonometric, and tropical activations",
      "title_zh": "可学习的多项式、三角函数和热带激活函数",
      "authors": [
        "Ismail Khalfaoui-Hassani",
        "Stefan Kesselheim"
      ],
      "abstract": "This paper investigates scalable neural networks with learnable activation\nfunctions based on orthogonal function bases and tropical polynomials,\ntargeting ImageNet-1K classification and next token prediction on OpenWebText.\nTraditional activations, such as ReLU, are static. In contrast, learnable\nactivations enable the network to adapt dynamically during training. However,\nstability issues, such as vanishing or exploding gradients, arise with improper\nvariance management in deeper networks. To remedy this, we propose an\ninitialization scheme that single-handedly preserves unitary variance in\ntransformers and convolutional networks, ensuring stable gradient flow even in\ndeep architectures. Extensive experiments demonstrate that networks with\nHermite, Fourier, and Tropical-based learnable activations significantly\nimprove over GPT-2 and ConvNeXt networks in terms of accuracy and perplexity in\ntrain and test, highlighting the viability of learnable activations in\nlarge-scale tasks. The activation functions developed here are the subject of a\nlibrary coded entirely in pure PyTorch: torchortho, available at\nhttps://github.com/K-H-Ismail/torchortho.",
      "tldr_zh": "这篇论文探讨了基于正交函数基和 tropical polynomials 的可学习激活函数，用于 ImageNet-1K 分类和 OpenWebText 的下一个标记预测，与传统静态激活如 ReLU 相比，这些函数允许网络在训练中动态适应。作者提出一个初始化方案，确保单位方差（unitary variance），从而解决深层网络中的梯度消失或爆炸问题，并在 transformers 和卷积网络中保持稳定梯度流动。实验结果显示，使用 Hermite、Fourier 和 Tropical-based 可学习激活函数的网络，在准确性和 perplexity 上显著优于 GPT-2 和 ConvNeXt 基准模型。该研究还提供了纯 PyTorch 库 torchortho，以支持这些激活函数的应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "math.AG"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01247v1",
      "published_date": "2025-02-03 11:13:58 UTC",
      "updated_date": "2025-02-03 11:13:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:24:37.818143"
    },
    {
      "arxiv_id": "2502.01243v1",
      "title": "OphthBench: A Comprehensive Benchmark for Evaluating Large Language Models in Chinese Ophthalmology",
      "title_zh": "翻译失败",
      "authors": [
        "Chengfeng Zhou",
        "Ji Wang",
        "Juanjuan Qin",
        "Yining Wang",
        "Ling Sun",
        "Weiwei Dai"
      ],
      "abstract": "Large language models (LLMs) have shown significant promise across various\nmedical applications, with ophthalmology being a notable area of focus. Many\nophthalmic tasks have shown substantial improvement through the integration of\nLLMs. However, before these models can be widely adopted in clinical practice,\nevaluating their capabilities and identifying their limitations is crucial. To\naddress this research gap and support the real-world application of LLMs, we\nintroduce the OphthBench, a specialized benchmark designed to assess LLM\nperformance within the context of Chinese ophthalmic practices. This benchmark\nsystematically divides a typical ophthalmic clinical workflow into five key\nscenarios: Education, Triage, Diagnosis, Treatment, and Prognosis. For each\nscenario, we developed multiple tasks featuring diverse question types,\nresulting in a comprehensive benchmark comprising 9 tasks and 591 questions.\nThis comprehensive framework allows for a thorough assessment of LLMs'\ncapabilities and provides insights into their practical application in Chinese\nophthalmology. Using this benchmark, we conducted extensive experiments and\nanalyzed the results from 39 popular LLMs. Our evaluation highlights the\ncurrent gap between LLM development and its practical utility in clinical\nsettings, providing a clear direction for future advancements. By bridging this\ngap, we aim to unlock the potential of LLMs and advance their development in\nophthalmology.",
      "tldr_zh": "本研究引入了OphthBench，一种全面基准，用于评估大型语言模型(LLMs)在中文眼科实践中的性能，以填补LLMs临床应用评估的空白。OphthBench将眼科临床工作流程分为五个关键场景——Education（教育）、Triage（分诊）、Diagnosis（诊断）、Treatment（治疗）和Prognosis（预后），涵盖9个任务和591个多样化问题，从而系统评估LLMs的能力。实验结果显示，通过测试39个热门LLMs，该基准揭示了LLMs在实际临床设置中的性能差距，并为未来模型改进和眼科应用提供明确方向。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01243v1",
      "published_date": "2025-02-03 11:04:51 UTC",
      "updated_date": "2025-02-03 11:04:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:24:49.506104"
    },
    {
      "arxiv_id": "2502.01236v1",
      "title": "Eliciting Language Model Behaviors with Investigator Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Xiang Lisa Li",
        "Neil Chowdhury",
        "Daniel D. Johnson",
        "Tatsunori Hashimoto",
        "Percy Liang",
        "Sarah Schwettmann",
        "Jacob Steinhardt"
      ],
      "abstract": "Language models exhibit complex, diverse behaviors when prompted with\nfree-form text, making it difficult to characterize the space of possible\noutputs. We study the problem of behavior elicitation, where the goal is to\nsearch for prompts that induce specific target behaviors (e.g., hallucinations\nor harmful responses) from a target language model. To navigate the\nexponentially large space of possible prompts, we train investigator models to\nmap randomly-chosen target behaviors to a diverse distribution of outputs that\nelicit them, similar to amortized Bayesian inference. We do this through\nsupervised fine-tuning, reinforcement learning via DPO, and a novel Frank-Wolfe\ntraining objective to iteratively discover diverse prompting strategies. Our\ninvestigator models surface a variety of effective and human-interpretable\nprompts leading to jailbreaks, hallucinations, and open-ended aberrant\nbehaviors, obtaining a 100% attack success rate on a subset of AdvBench\n(Harmful Behaviors) and an 85% hallucination rate.",
      "tldr_zh": "该研究探讨了如何通过训练调查者代理（investigator models）来诱导语言模型（language models）产生特定行为，如幻觉（hallucinations）或有害响应（harmful responses），以探索模型的输出空间。方法包括使用监督微调（supervised fine-tuning）、强化学习 via DPO（Direct Preference Optimization），以及新型 Frank-Wolfe 训练目标，来生成多样化的提示策略，帮助模型迭代发现有效提示。实验结果显示，该方法在 AdvBench 的有害行为子集上实现了 100% 的攻击成功率（attack success rate），并在幻觉诱导中达到 85% 的 hallucination rate，从而揭示了语言模型潜在风险。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "20 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.01236v1",
      "published_date": "2025-02-03 10:52:44 UTC",
      "updated_date": "2025-02-03 10:52:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:25:00.858921"
    },
    {
      "arxiv_id": "2502.01703v1",
      "title": "QLESS: A Quantized Approach for Data Valuation and Selection in Large Language Model Fine-Tuning",
      "title_zh": "QLESS：大语言",
      "authors": [
        "Moses Ananta",
        "Muhammad Farid Adilazuarda",
        "Zayd Muhammad Kawakibi Zuhri",
        "Ayu Purwarianti",
        "Alham Fikri Aji"
      ],
      "abstract": "Fine-tuning large language models (LLMs) is often constrained by the\ncomputational costs of processing massive datasets. We propose \\textbf{QLESS}\n(Quantized Low-rank Gradient Similarity Search), which integrates gradient\nquantization with the LESS framework to enable memory-efficient data valuation\nand selection. QLESS employs a two-step compression process: first, it obtains\nlow-dimensional gradient representations through LoRA-based random projection;\nthen, it quantizes these gradients to low-bitwidth representations. Experiments\non multiple LLM architectures (LLaMA, Mistral, Qwen) and benchmarks (MMLU, BBH,\nTyDiQA) show that QLESS achieves comparable data selection performance to LESS\nwhile reducing memory usage by up to 16x. Even 1-bit gradient quantization\npreserves data valuation quality. These findings underscore QLESS as a\npractical, scalable approach to identifying informative examples within strict\nmemory constraints.",
      "tldr_zh": "本研究提出 QLESS，一种量化方法，用于大型语言模型（LLMs）微调中的数据估值和选择，以解决处理大规模数据集的计算成本问题。QLESS 通过整合梯度量化与 LESS 框架，采用两步压缩过程：首先利用 LoRA-based random projection 获取低维梯度表示，然后将这些梯度量化到低比特宽表示。实验在 LLaMA、Mistral 和 Qwen 等模型以及 MMLU、BBH 和 TyDiQA 等基准上显示，QLESS 与 LESS 的数据选择性能相当，但内存使用减少高达 16 倍，甚至 1-bit 量化也能保持估值质量，从而提供一种实用、可扩展的内存高效方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01703v1",
      "published_date": "2025-02-03 10:52:32 UTC",
      "updated_date": "2025-02-03 10:52:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:25:13.403906"
    },
    {
      "arxiv_id": "2502.01235v1",
      "title": "One-step full gradient suffices for low-rank fine-tuning, provably and efficiently",
      "title_zh": "翻译失败",
      "authors": [
        "Yuanhe Zhang",
        "Fanghui Liu",
        "Yudong Chen"
      ],
      "abstract": "This paper studies how to improve the performance of Low-Rank Adaption (LoRA)\nas guided by our theoretical analysis. Our first set of theoretical results\nshow that for random initialization and linear models, \\textit{i)} LoRA will\nalign to the certain singular subspace of one-step gradient of full\nfine-tuning; \\textit{ii)} preconditioners improve convergence in the high-rank\ncase. These insights motivate us to focus on preconditioned LoRA using a\nspecific spectral initialization strategy for aligning with certain subspaces.\nFor both linear and nonlinear models, we prove that alignment and\ngeneralization guarantees can be directly achieved at initialization, and the\nsubsequent linear convergence can be also built. Our analysis leads to the\n\\emph{LoRA-One} algorithm (using \\emph{One}-step gradient and preconditioning),\na theoretically grounded algorithm that achieves significant empirical\nimprovement over vanilla LoRA and its variants on several benchmarks. Our\ntheoretical analysis, based on decoupling the learning dynamics and\ncharacterizing how spectral initialization contributes to feature learning, may\nbe of independent interest for understanding matrix sensing and deep learning\ntheory. The source code can be found in the\nhttps://github.com/YuanheZ/LoRA-One.",
      "tldr_zh": "这篇论文通过理论分析改善了 Low-Rank Adaption (LoRA) 的性能，证明了使用一步全梯度即可实现模型对齐和高效收敛。对于随机初始化和线性模型，LoRA 会与全梯度微调的奇异子空间对齐，而预条件器 (preconditioners) 在高秩情况下提升收敛效果。论文提出 LoRA-One 算法，结合谱初始化策略 (spectral initialization) 和预条件化，确保初始化时就达到对齐与泛化保证，并在非线性模型上实现线性收敛；实验结果显示，该算法在多个基准上显著优于原版 LoRA 和其变体。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "86 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.01235v1",
      "published_date": "2025-02-03 10:50:03 UTC",
      "updated_date": "2025-02-03 10:50:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:25:26.804920"
    },
    {
      "arxiv_id": "2502.01232v1",
      "title": "Efficient rule induction by ignoring pointless rules",
      "title_zh": "翻译失败",
      "authors": [
        "Andrew Cropper",
        "David M. Cerna"
      ],
      "abstract": "The goal of inductive logic programming (ILP) is to find a set of logical\nrules that generalises training examples and background knowledge. We introduce\nan ILP approach that identifies pointless rules. A rule is pointless if it\ncontains a redundant literal or cannot discriminate against negative examples.\nWe show that ignoring pointless rules allows an ILP system to soundly prune the\nhypothesis space. Our experiments on multiple domains, including visual\nreasoning and game playing, show that our approach can reduce learning times by\n99% whilst maintaining predictive accuracies.",
      "tldr_zh": "这篇论文提出了一种高效的归纳逻辑编程（ILP）方法，通过识别和忽略pointless rules来优化规则归纳过程，其中pointless rules指包含冗余literal或无法区分负例的规则。该方法能安全地修剪假设空间，从而提高学习效率。在视觉推理和游戏玩耍等多个领域实验中，该方法将学习时间减少99%，同时保持预测准确性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Under review for a conference",
      "pdf_url": "http://arxiv.org/pdf/2502.01232v1",
      "published_date": "2025-02-03 10:46:18 UTC",
      "updated_date": "2025-02-03 10:46:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:25:36.286227"
    },
    {
      "arxiv_id": "2502.01225v1",
      "title": "The dark deep side of DeepSeek: Fine-tuning attacks against the safety alignment of CoT-enabled models",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiyuan Xu",
        "Joseph Gardiner",
        "Sana Belguith"
      ],
      "abstract": "Large language models are typically trained on vast amounts of data during\nthe pre-training phase, which may include some potentially harmful information.\nFine-tuning attacks can exploit this by prompting the model to reveal such\nbehaviours, leading to the generation of harmful content. In this paper, we\nfocus on investigating the performance of the Chain of Thought based reasoning\nmodel, DeepSeek, when subjected to fine-tuning attacks. Specifically, we\nexplore how fine-tuning manipulates the model's output, exacerbating the\nharmfulness of its responses while examining the interaction between the Chain\nof Thought reasoning and adversarial inputs. Through this study, we aim to shed\nlight on the vulnerability of Chain of Thought enabled models to fine-tuning\nattacks and the implications for their safety and ethical deployment.",
      "tldr_zh": "该论文探讨了基于Chain of Thought (CoT) 推理的语言模型DeepSeek在fine-tuning attacks下的脆弱性，揭示微调攻击如何诱导模型生成有害内容。研究方法包括分析微调对模型输出的操纵，以及CoT推理与对抗输入的交互，以评估模型的安全性。结果显示，这种攻击会显著加剧模型的响应有害性，并强调了CoT启用模型在伦理部署中的潜在风险，为改进模型安全对齐提供了重要启示。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "12 Pages",
      "pdf_url": "http://arxiv.org/pdf/2502.01225v1",
      "published_date": "2025-02-03 10:28:26 UTC",
      "updated_date": "2025-02-03 10:28:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:25:48.238769"
    },
    {
      "arxiv_id": "2502.01218v1",
      "title": "Provable Ordering and Continuity in Vision-Language Pretraining for Generalizable Embodied Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Zhizhen Zhang",
        "Lei Zhu",
        "Zhen Fang",
        "Zi Huang",
        "Yadan Luo"
      ],
      "abstract": "Pre-training vision-language representations on human action videos has\nemerged as a promising approach to reduce reliance on large-scale expert\ndemonstrations for training embodied agents. However, prior methods often\nemploy time contrastive learning based on goal-reaching heuristics,\nprogressively aligning language instructions from the initial to the final\nframe. This overemphasis on future frames can result in erroneous\nvision-language associations, as actions may terminate early or include\nirrelevant moments in the end. To address this issue, we propose Action\nTemporal Coherence Learning (AcTOL) to learn ordered and continuous\nvision-language representations without rigid goal-based constraint. AcTOL\ntreats a video as a continuous trajectory where it (1) contrasts semantic\ndifferences between frames to reflect their natural ordering, and (2) imposes a\nlocal Brownian bridge constraint to ensure smooth transitions across\nintermediate frames. Extensive imitation learning experiments across varying\nnumbers of demonstrations show that the pretrained features significantly\nenhance downstream manipulation tasks by up to 49% with high robustness to\ndifferent linguistic styles of instructions, offering a viable pathway toward\ngeneralized embodied agents. The source code is included in the supplementary\nmaterial for reference.",
      "tldr_zh": "本研究提出Action Temporal Coherence Learning (AcTOL)方法，用于在视觉-语言预训练中实现可证明的顺序性和连续性，从而提升具身代理的泛化能力。AcTOL将视频视为连续轨迹，通过对比帧之间的语义差异来反映自然顺序，并施加局部布朗桥约束确保中间帧的平滑过渡，避免了传统基于目标到达启发式方法的错误关联。在模仿学习实验中，该预训练特征显著提高了下游操作任务性能，最多提升49%，并对不同语言指令风格表现出高鲁棒性，为开发通用化具身代理提供了可行路径。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01218v1",
      "published_date": "2025-02-03 10:16:49 UTC",
      "updated_date": "2025-02-03 10:16:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:26:00.835796"
    },
    {
      "arxiv_id": "2503.15521v1",
      "title": "From Divergence to Consensus: Evaluating the Role of Large Language Models in Facilitating Agreement through Adaptive Strategies",
      "title_zh": "翻译失败",
      "authors": [
        "Loukas Triantafyllopoulos",
        "Dimitris Kalles"
      ],
      "abstract": "Achieving consensus in group decision-making often involves overcoming\nsignificant challenges, particularly in reconciling diverse perspectives and\nmitigating biases that hinder agreement. Traditional methods relying on human\nfacilitators are often constrained by scalability and efficiency, especially in\nlarge-scale, fast-paced discussions. To address these challenges, this study\nproposes a novel framework employing large language models (LLMs) as automated\nfacilitators within a custom-built multi-user chat system. Leveraging cosine\nsimilarity as a core metric, this approach evaluates the ability of three\nstate-of-the-art LLMs- ChatGPT 4.0, Mistral Large 2, and AI21 Jamba Instruct-\nto synthesize consensus proposals that align with participants' viewpoints.\nUnlike conventional techniques, the system integrates adaptive facilitation\nstrategies, including clarifying misunderstandings, summarizing discussions,\nand proposing compromises, enabling the LLMs to iteratively refine consensus\nproposals based on user feedback. Experimental results demonstrate the\nsuperiority of ChatGPT 4.0, which achieves higher alignment with participant\nopinions, requiring fewer iterations to reach consensus compared to its\ncounterparts. Moreover, analysis reveals the nuanced performance of the models\nacross various sustainability-focused discussion topics, such as climate\naction, quality education, good health and well-being, and access to clean\nwater and sanitation. These findings highlight the transformative potential of\nLLM-driven facilitation for improving collective decision-making processes and\nunderscore the importance of advancing evaluation metrics and cross-cultural\nadaptability in future research.",
      "tldr_zh": "这篇论文提出了一种新框架，使用 Large Language Models (LLMs) 作为自动 facilitator，在自定义的多用户聊天系统中帮助群体决策中克服分歧并达成共识。框架通过 cosine similarity 指标评估三个 LLM（ChatGPT 4.0、Mistral Large 2 和 AI21 Jamba Instruct）的性能，并整合 adaptive strategies，如澄清误解、总结讨论和提出妥协，以根据用户反馈迭代优化共识提案。实验结果显示，ChatGPT 4.0 在可持续性主题（如气候行动和健康福祉）讨论中表现出色，能够更快地与参与者意见对齐。总体而言，该研究强调了 LLMs 在提升集体决策效率的潜力，并建议未来研究改进评价指标和跨文化适应性。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "32 pages, 5 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2503.15521v1",
      "published_date": "2025-02-03 09:59:55 UTC",
      "updated_date": "2025-02-03 09:59:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:26:13.876118"
    },
    {
      "arxiv_id": "2502.01199v1",
      "title": "Nearly Lossless Adaptive Bit Switching",
      "title_zh": "近乎无损的自适应比特切换",
      "authors": [
        "Haiduo Huang",
        "Zhenhua Liu",
        "Tian Xia",
        "Wenzhe zhao",
        "Pengju Ren"
      ],
      "abstract": "Model quantization is widely applied for compressing and accelerating deep\nneural networks (DNNs). However, conventional Quantization-Aware Training (QAT)\nfocuses on training DNNs with uniform bit-width. The bit-width settings vary\nacross different hardware and transmission demands, which induces considerable\ntraining and storage costs. Hence, the scheme of one-shot joint training\nmultiple precisions is proposed to address this issue. Previous works either\nstore a larger FP32 model to switch between different precision models for\nhigher accuracy or store a smaller INT8 model but compromise accuracy due to\nusing shared quantization parameters. In this paper, we introduce the Double\nRounding quantization method, which fully utilizes the quantized representation\nrange to accomplish nearly lossless bit-switching while reducing storage by\nusing the highest integer precision instead of full precision. Furthermore, we\nobserve a competitive interference among different precisions during one-shot\njoint training, primarily due to inconsistent gradients of quantization scales\nduring backward propagation. To tackle this problem, we propose an Adaptive\nLearning Rate Scaling (ALRS) technique that dynamically adapts learning rates\nfor various precisions to optimize the training process. Additionally, we\nextend our Double Rounding to one-shot mixed precision training and develop a\nHessian-Aware Stochastic Bit-switching (HASB) strategy. Experimental results on\nthe ImageNet-1K classification demonstrate that our methods have enough\nadvantages to state-of-the-art one-shot joint QAT in both multi-precision and\nmixed-precision. We also validate the feasibility of our method on detection\nand segmentation tasks, as well as on LLMs task. Our codes are available at\nhttps://github.com/haiduo/Double-Rounding.",
      "tldr_zh": "本论文提出了一种Nearly Lossless Adaptive Bit Switching方法，针对Quantization-Aware Training (QAT)中统一位宽导致的训练和存储成本高问题，实现多精度和混合精度模型的几乎无损切换。核心创新包括Double Rounding量化方法，利用量化表示范围减少存储，同时引入Adaptive Learning Rate Scaling (ALRS)技术来动态调整学习率，解决多精度训练中的梯度不一致问题；此外，还扩展了Hessian-Aware Stochastic Bit-switching (HASB)策略以支持混合精度训练。实验结果显示，该方法在ImageNet-1K分类任务上优于现有一流QAT方法，并在检测、分割和LLMs任务中验证了其可行性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01199v1",
      "published_date": "2025-02-03 09:46:26 UTC",
      "updated_date": "2025-02-03 09:46:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:26:26.129527"
    },
    {
      "arxiv_id": "2502.01190v1",
      "title": "Dance recalibration for dance coherency with recurrent convolution block",
      "title_zh": "翻译失败",
      "authors": [
        "Seungho Eum",
        "Ihjoon Cho",
        "Junghyeon Kim"
      ],
      "abstract": "With the recent advancements in generative AI such as GAN, Diffusion, and\nVAE, the use of generative AI for dance generation has seen significant\nprogress and received considerable interest. In this study, We propose R-Lodge,\nan enhanced version of Lodge. R-Lodge incorporates Recurrent Sequential\nRepresentation Learning named Dance Recalibration to original coarse-to-fine\nlong dance generation model. R-Lodge utilizes Dance Recalibration method using\n$N$ Dance Recalibration Block to address the lack of consistency in the coarse\ndance representation of the Lodge model. By utilizing this method, each\ngenerated dance motion incorporates a bit of information from the previous\ndance motions. We evaluate R-Lodge on FineDance dataset and the results show\nthat R-Lodge enhances the consistency of the whole generated dance motions.",
      "tldr_zh": "该研究提出 R-Lodge，一种增强版的舞蹈生成模型，旨在通过 Recurrent Sequential Representation Learning 和 Dance Recalibration 方法改善生成舞蹈的一致性。R-Lodge 利用 $N$ 个 Dance Recalibration Block 来处理原始 Lodge 模型中粗糙舞蹈表示的问题，使每个生成的舞蹈动作融入前一个动作的信息，从而实现粗到细的序列学习。在 FineDance 数据集上的实验结果显示，R-Lodge 显著提升了整体生成舞蹈动作的连贯性和一致性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01190v1",
      "published_date": "2025-02-03 09:29:02 UTC",
      "updated_date": "2025-02-03 09:29:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:26:35.812445"
    },
    {
      "arxiv_id": "2502.01189v3",
      "title": "Compressed Image Generation with Denoising Diffusion Codebook Models",
      "title_zh": "基于去噪扩散代码本模型的压缩图像生成",
      "authors": [
        "Guy Ohayon",
        "Hila Manor",
        "Tomer Michaeli",
        "Michael Elad"
      ],
      "abstract": "We present a novel generative approach based on Denoising Diffusion Models\n(DDMs), which produces high-quality image samples along with their losslessly\ncompressed bit-stream representations. This is obtained by replacing the\nstandard Gaussian noise sampling in the reverse diffusion with a selection of\nnoise samples from pre-defined codebooks of fixed iid Gaussian vectors.\nSurprisingly, we find that our method, termed Denoising Diffusion Codebook\nModel (DDCM), retains sample quality and diversity of standard DDMs, even for\nextremely small codebooks. We leverage DDCM and pick the noises from the\ncodebooks that best match a given image, converting our generative model into a\nhighly effective lossy image codec achieving state-of-the-art perceptual image\ncompression results. More generally, by setting other noise selections rules,\nwe extend our compression method to any conditional image generation task\n(e.g., image restoration), where the generated images are produced jointly with\ntheir condensed bit-stream representations. Our work is accompanied by a\nmathematical interpretation of the proposed compressed conditional generation\nschemes, establishing a connection with score-based approximations of posterior\nsamplers for the tasks considered.",
      "tldr_zh": "本文提出了一种名为 Denoising Diffusion Codebook Models (DDCM) 的新生成方法，基于 Denoising Diffusion Models (DDMs)，通过使用预定义的 codebooks 中的固定 iid Gaussian 向量替换标准高斯噪声采样，从而生成高质量图像样本并提供无损压缩的位流表示。实验发现，即使 codebook 规模极小，DDCM 仍能保持样本质量和多样性，并在感知图像压缩中实现最先进（state-of-the-art）的有损图像编解码效果。该方法进一步扩展到条件图像生成任务（如图像修复），生成图像的同时输出压缩表示，并通过数学解释将其与基于 score 的后验采样器相连接。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.IT",
        "eess.SP",
        "math.IT"
      ],
      "primary_category": "eess.IV",
      "comment": "Code and demo are available at https://ddcm-2025.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2502.01189v3",
      "published_date": "2025-02-03 09:25:57 UTC",
      "updated_date": "2025-02-10 13:11:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:26:49.633484"
    },
    {
      "arxiv_id": "2502.01187v1",
      "title": "Skewed Memorization in Large Language Models: Quantification and Decomposition",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Li",
        "Di Huang",
        "Ziyu Wang",
        "Amir M. Rahmani"
      ],
      "abstract": "Memorization in Large Language Models (LLMs) poses privacy and security\nrisks, as models may unintentionally reproduce sensitive or copyrighted data.\nExisting analyses focus on average-case scenarios, often neglecting the highly\nskewed distribution of memorization. This paper examines memorization in LLM\nsupervised fine-tuning (SFT), exploring its relationships with training\nduration, dataset size, and inter-sample similarity. By analyzing memorization\nprobabilities over sequence lengths, we link this skewness to the token\ngeneration process, offering insights for estimating memorization and comparing\nit to established metrics. Through theoretical analysis and empirical\nevaluation, we provide a comprehensive understanding of memorization behaviors\nand propose strategies to detect and mitigate risks, contributing to more\nprivacy-preserving LLMs.",
      "tldr_zh": "本研究探讨Large Language Models (LLMs)中memorization的倾斜分布问题，该现象可能导致隐私和安全风险，如模型无意中复制敏感数据。作者分析了memorization在supervised fine-tuning (SFT)中的表现，考察其与训练持续时间、数据集大小以及样本间相似度的关系，并通过序列长度与memorization概率的关联，揭示其与token生成过程的内在联系。基于理论分析和实证评估，该论文提供了memorization的量化方法、与其他指标的比较，以及检测和缓解风险的策略，从而推动更注重隐私的LLMs发展。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01187v1",
      "published_date": "2025-02-03 09:23:53 UTC",
      "updated_date": "2025-02-03 09:23:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:27:00.471252"
    },
    {
      "arxiv_id": "2502.01185v1",
      "title": "Deep Active Speech Cancellation with Multi-Band Mamba Network",
      "title_zh": "翻译失败",
      "authors": [
        "Yehuda Mishaly",
        "Lior Wolf",
        "Eliya Nachmani"
      ],
      "abstract": "We present a novel deep learning network for Active Speech Cancellation\n(ASC), advancing beyond Active Noise Cancellation (ANC) methods by effectively\ncanceling both noise and speech signals. The proposed Multi-Band Mamba\narchitecture segments input audio into distinct frequency bands, enabling\nprecise anti-signal generation and improved phase alignment across frequencies.\nAdditionally, we introduce an optimization-driven loss function that provides\nnear-optimal supervisory signals for anti-signal generation. Experimental\nresults demonstrate substantial performance gains, achieving up to 7.2dB\nimprovement in ANC scenarios and 6.2dB in ASC, significantly outperforming\nexisting methods. Audio samples are available at\nhttps://mishalydev.github.io/DeepASC-Demo",
      "tldr_zh": "该研究提出了一种新型深度学习网络，用于 Active Speech Cancellation (ASC)，能够有效取消噪声和语音信号，超越传统的 Active Noise Cancellation (ANC) 方法。Multi-Band Mamba 架构将输入音频分成不同频率带，实现精确的反信号生成和频率间的相位对齐，同时引入一个优化驱动的损失函数来提供近优化的监督信号。实验结果显示，该方法在 ANC 场景下改善高达 7.2dB，在 ASC 下改善 6.2dB，显著优于现有方法，并提供了音频样本以供验证。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS",
        "eess.SP"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01185v1",
      "published_date": "2025-02-03 09:22:26 UTC",
      "updated_date": "2025-02-03 09:22:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:27:11.842272"
    },
    {
      "arxiv_id": "2502.01184v1",
      "title": "FragmentNet: Adaptive Graph Fragmentation for Graph-to-Sequence Molecular Representation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Ankur Samanta",
        "Rohan Gupta",
        "Aditi Misra",
        "Christian McIntosh Clarke",
        "Jayakumar Rajadas"
      ],
      "abstract": "Molecular property prediction uses molecular structure to infer chemical\nproperties. Chemically interpretable representations that capture meaningful\nintramolecular interactions enhance the usability and effectiveness of these\npredictions. However, existing methods often rely on atom-based or rule-based\nfragment tokenization, which can be chemically suboptimal and lack scalability.\nWe introduce FragmentNet, a graph-to-sequence foundation model with an\nadaptive, learned tokenizer that decomposes molecular graphs into chemically\nvalid fragments while preserving structural connectivity. FragmentNet\nintegrates VQVAE-GCN for hierarchical fragment embeddings, spatial positional\nencodings for graph serialization, global molecular descriptors, and a\ntransformer. Pre-trained with Masked Fragment Modeling and fine-tuned on\nMoleculeNet tasks, FragmentNet outperforms models with similarly scaled\narchitectures and datasets while rivaling larger state-of-the-art models\nrequiring significantly more resources. This novel framework enables adaptive\ndecomposition, serialization, and reconstruction of molecular graphs,\nfacilitating fragment-based editing and visualization of property trends in\nlearned embeddings - a powerful tool for molecular design and optimization.",
      "tldr_zh": "本研究提出FragmentNet，一种graph-to-sequence基础模型，通过自适应学习标记化器将分子图分解成化学有效的片段，同时保留结构连接性，以提升分子属性预测的化学可解释性和可扩展性。FragmentNet整合了VQVAE-GCN用于分层片段嵌入、空间位置编码用于图序列化、全球分子描述符和Transformer模型，并通过Masked Fragment Modeling预训练，在MoleculeNet任务上进行微调。实验结果显示，FragmentNet在类似规模的模型中表现出色，并可媲美更大SOTA模型，同时支持基于片段的分子图编辑和可视化，为分子设计和优化提供强大工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.chem-ph",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "22 pages, 13 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.01184v1",
      "published_date": "2025-02-03 09:21:49 UTC",
      "updated_date": "2025-02-03 09:21:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:27:25.395054"
    },
    {
      "arxiv_id": "2502.01182v1",
      "title": "A Single Model Ensemble Framework for Neural Machine Translation using Pivot Translation",
      "title_zh": "一种基于枢纽翻译的神经机器翻译",
      "authors": [
        "Seokjin Oh",
        "Keonwoong Noh",
        "Woohwan Jung"
      ],
      "abstract": "Despite the significant advances in neural machine translation, performance\nremains subpar for low-resource language pairs. Ensembling multiple systems is\na widely adopted technique to enhance performance, often accomplished by\ncombining probability distributions. However, the previous approaches face the\nchallenge of high computational costs for training multiple models.\nFurthermore, for black-box models, averaging token-level probabilities at each\ndecoding step is not feasible. To address the problems of multi-model ensemble\nmethods, we present a pivot-based single model ensemble. The proposed strategy\nconsists of two steps: pivot-based candidate generation and post-hoc\naggregation. In the first step, we generate candidates through pivot\ntranslation. This can be achieved with only a single model and facilitates\nknowledge transfer from high-resource pivot languages, resulting in candidates\nthat are not only diverse but also more accurate. Next, in the aggregation\nstep, we select k high-quality candidates from the generated candidates and\nmerge them to generate a final translation that outperforms the existing\ncandidates. Our experimental results show that our method produces translations\nof superior quality by leveraging candidates from pivot translation to capture\nthe subtle nuances of the source sentence.",
      "tldr_zh": "该论文针对低资源语言对的Neural Machine Translation性能不足问题，提出了一种基于pivot translation的单模型集成框架，以减少传统多模型集成的高计算成本。框架包括两个步骤：首先，通过pivot translation生成多样且准确的候选翻译，利用高资源枢轴语言进行知识转移；其次，进行后处理聚合，从候选中选择k个高质量翻译并合并，以生成优于现有候选的最终输出。实验结果显示，该方法能够有效捕捉源句的细微差别，提升翻译质量。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01182v1",
      "published_date": "2025-02-03 09:17:45 UTC",
      "updated_date": "2025-02-03 09:17:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:27:37.105794"
    },
    {
      "arxiv_id": "2502.01701v2",
      "title": "Learning with Differentially Private (Sliced) Wasserstein Gradients",
      "title_zh": "翻译失败",
      "authors": [
        "David Rodríguez-Vítores",
        "Clément Lalanne",
        "Jean-Michel Loubes"
      ],
      "abstract": "In this work, we introduce a novel framework for privately optimizing\nobjectives that rely on Wasserstein distances between data-dependent empirical\nmeasures. Our main theoretical contribution is, based on an explicit\nformulation of the Wasserstein gradient in a fully discrete setting, a control\non the sensitivity of this gradient to individual data points, allowing strong\nprivacy guarantees at minimal utility cost. Building on these insights, we\ndevelop a deep learning approach that incorporates gradient and activations\nclipping, originally designed for DP training of problems with a finite-sum\nstructure. We further demonstrate that privacy accounting methods extend to\nWasserstein-based objectives, facilitating large-scale private training.\nEmpirical results confirm that our framework effectively balances accuracy and\nprivacy, offering a theoretically sound solution for privacy-preserving machine\nlearning tasks relying on optimal transport distances such as Wasserstein\ndistance or sliced-Wasserstein distance.",
      "tldr_zh": "这篇论文提出了一种新框架，用于在优化依赖于Wasserstein距离的目标函数时实现Differentially Private隐私保护。核心贡献是通过Wasserstein梯度的显式公式，在离散设置中控制梯度对单个数据点的敏感性，从而提供强隐私保证，同时最小化效用损失。该框架整合了梯度和激活剪裁技术，并扩展隐私会计方法到Wasserstein-based目标，支持大规模私有训练。实验结果表明，该方法在sliced-Wasserstein距离等最优传输任务中有效平衡了准确性和隐私保护。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.ST",
        "stat.TH"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01701v2",
      "published_date": "2025-02-03 09:14:26 UTC",
      "updated_date": "2025-05-21 14:01:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:27:48.978854"
    },
    {
      "arxiv_id": "2502.01179v3",
      "title": "Joint Localization and Activation Editing for Low-Resource Fine-Tuning",
      "title_zh": "用于低资源微调的联合定位和激活编辑",
      "authors": [
        "Wen Lai",
        "Alexander Fraser",
        "Ivan Titov"
      ],
      "abstract": "Parameter-efficient fine-tuning (PEFT) methods, such as LoRA, are commonly\nused to adapt LLMs. However, the effectiveness of standard PEFT methods is\nlimited in low-resource scenarios with only a few hundred examples. Recent\nadvances in interpretability research have inspired the emergence of activation\nediting (or steering) techniques, which modify the activations of specific\nmodel components. These methods, due to their extremely small parameter counts,\nshow promise for small datasets. However, their performance is highly dependent\non identifying the correct modules to edit and often lacks stability across\ndifferent datasets. In this paper, we propose Joint Localization and Activation\nEditing (JoLA), a method that jointly learns (1) which heads in the Transformer\nto edit (2) whether the intervention should be additive, multiplicative, or\nboth and (3) the intervention parameters themselves - the vectors applied as\nadditive offsets or multiplicative scalings to the head output. Through\nevaluations on three benchmarks spanning commonsense reasoning, natural\nlanguage understanding, and natural language generation, we demonstrate that\nJoLA consistently outperforms existing methods. The code for the method is\nreleased at https://github.com/wenlai-lavine/jola.",
      "tldr_zh": "本研究针对参数高效微调 (PEFT) 方法如 LoRA 在低资源场景下的效果有限问题，提出 Joint Localization and Activation Editing (JoLA) 方法，以解决现有激活编辑技术的模块识别依赖性和稳定性不足。JoLA 同时学习编辑 Transformer 中的 heads、干预方式（加法、乘法或两者结合）以及干预参数，从而实现对模型激活的精确调整。在三个基准测试（涵盖常识推理、自然语言理解和生成）中，JoLA  consistently outperforms 现有方法，代码已开源以供进一步应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by ICML 2025. The code is released at\n  https://github.com/wenlai-lavine/jola",
      "pdf_url": "http://arxiv.org/pdf/2502.01179v3",
      "published_date": "2025-02-03 09:13:09 UTC",
      "updated_date": "2025-05-19 11:36:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:28:01.110188"
    },
    {
      "arxiv_id": "2502.01160v1",
      "title": "Scalable Precise Computation of Shannon Entropy",
      "title_zh": "可扩展的精确香农熵计算",
      "authors": [
        "Yong Lai",
        "Haolong Tong",
        "Zhenghang Xu",
        "Minghao Yin"
      ],
      "abstract": "Quantitative information flow analyses (QIF) are a class of techniques for\nmeasuring the amount of confidential information leaked by a program to its\npublic outputs.\n  Shannon entropy is an important method to quantify the amount of leakage in\nQIF.\n  This paper focuses on the programs modeled in Boolean constraints and\noptimizes the two stages of the Shannon entropy computation to implement a\nscalable precise tool PSE.\n  In the first stage, we design a knowledge compilation language called \\ADDAND\nthat combines Algebraic Decision Diagrams and conjunctive decomposition.\n  \\ADDAND avoids enumerating possible outputs of a program and supports\ntractable entropy computation.\n  In the second stage, we optimize the model counting queries that are used to\ncompute the probabilities of outputs.\n  We compare PSE with the state-of-the-art probably approximately correct tool\nEntropyEstimation, which was shown to significantly outperform the existing\nprecise tools.\n  The experimental results demonstrate that PSE solved 55 more benchmarks\ncompared to EntropyEstimation in a total of 441. For 98% of the benchmarks that\nboth PSE and EntropyEstimation solved, PSE is at least $10\\times$ as efficient\nas EntropyEstimation.",
      "tldr_zh": "这篇论文提出了一种可扩展的精确工具PSE，用于计算Shannon entropy，以量化程序中信息泄露的程度，针对用布尔约束建模的程序。方法包括设计\\ADDAND语言（结合Algebraic Decision Diagrams和conjunctive decomposition）来避免枚举输出并支持可处理的熵计算，以及优化模型计数查询来计算输出概率。与现有工具EntropyEstimation相比，实验结果显示PSE解决了55个更多基准测试，并在98%的共同基准上效率至少高10倍。",
      "categories": [
        "cs.AI",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.01160v1",
      "published_date": "2025-02-03 08:51:03 UTC",
      "updated_date": "2025-02-03 08:51:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:28:12.520090"
    },
    {
      "arxiv_id": "2502.01159v1",
      "title": "AtmosSci-Bench: Evaluating the Recent Advance of Large Language Model for Atmospheric Science",
      "title_zh": "AtmosSci-Bench：评估大语言模型在大气科学领域的最近进展",
      "authors": [
        "Chenyue Li",
        "Wen Deng",
        "Mengqian Lu",
        "Binhang Yuan"
      ],
      "abstract": "The rapid advancements in large language models (LLMs), particularly in their\nreasoning capabilities, hold transformative potential for addressing complex\nchallenges in atmospheric science. However, leveraging LLMs effectively in this\ndomain requires a robust and comprehensive evaluation benchmark. To address\nthis need, we present AtmosSci-Bench, a novel benchmark designed to\nsystematically assess LLM performance across five core categories of\natmospheric science problems: hydrology, atmospheric dynamics, atmospheric\nphysics, geophysics, and physical oceanography. We employ a template-based\nquestion generation framework, enabling scalable and diverse multiple-choice\nquestions curated from graduate-level atmospheric science problems. We conduct\na comprehensive evaluation of representative LLMs, categorized into four\ngroups: instruction-tuned models, advanced reasoning models, math-augmented\nmodels, and domain-specific climate models. Our analysis provides some\ninteresting insights into the reasoning and problem-solving capabilities of\nLLMs in atmospheric science. We believe AtmosSci-Bench can serve as a critical\nstep toward advancing LLM applications in climate service by offering a\nstandard and rigorous evaluation framework. Our source codes are currently\navailable at https://github.com/Relaxed-System-Lab/AtmosSci-Bench.",
      "tldr_zh": "该研究引入了 AtmosSci-Bench，一个新的基准，用于系统评估大型语言模型(LLMs)在大气科学领域的性能，涵盖 hydrology、atmospheric dynamics、atmospheric physics、geophysics 和 physical oceanography 等五个核心类别。研究采用模板-based question generation framework 生成可扩展的多项选择题，从研究生级问题中选取，并评估了四类代表性 LLMs，包括 instruction-tuned models、advanced reasoning models、math-augmented models 和 domain-specific climate models。结果分析揭示了 LLMs 在大气科学中的推理和问题解决能力，提供宝贵见解，并为推进 LLMs 在气候服务中的应用奠定标准评估框架。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 3 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.01159v1",
      "published_date": "2025-02-03 08:50:46 UTC",
      "updated_date": "2025-02-03 08:50:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:28:25.575754"
    },
    {
      "arxiv_id": "2502.01158v1",
      "title": "MIND: Modality-Informed Knowledge Distillation Framework for Multimodal Clinical Prediction Tasks",
      "title_zh": "MIND：模态指导知识蒸馏框架，用于多模态临床预测任务",
      "authors": [
        "Alejandro Guerra-Manzanares",
        "Farah E. Shamout"
      ],
      "abstract": "Multimodal fusion leverages information across modalities to learn better\nfeature representations with the goal of improving performance in fusion-based\ntasks. However, multimodal datasets, especially in medical settings, are\ntypically smaller than their unimodal counterparts, which can impede the\nperformance of multimodal models. Additionally, the increase in the number of\nmodalities is often associated with an overall increase in the size of the\nmultimodal network, which may be undesirable in medical use cases. Utilizing\nsmaller unimodal encoders may lead to sub-optimal performance, particularly\nwhen dealing with high-dimensional clinical data. In this paper, we propose the\nModality-INformed knowledge Distillation (MIND) framework, a multimodal model\ncompression approach based on knowledge distillation that transfers knowledge\nfrom ensembles of pre-trained deep neural networks of varying sizes into a\nsmaller multimodal student. The teacher models consist of unimodal networks,\nallowing the student to learn from diverse representations. MIND employs\nmulti-head joint fusion models, as opposed to single-head models, enabling the\nuse of unimodal encoders in the case of unimodal samples without requiring\nimputation or masking of absent modalities. As a result, MIND generates an\noptimized multimodal model, enhancing both multimodal and unimodal\nrepresentations. It can also be leveraged to balance multimodal learning during\ntraining. We evaluate MIND on binary and multilabel clinical prediction tasks\nusing time series data and chest X-ray images. Additionally, we assess the\ngeneralizability of the MIND framework on three non-medical multimodal\nmulticlass datasets. Experimental results demonstrate that MIND enhances the\nperformance of the smaller multimodal network across all five tasks, as well as\nvarious fusion methods and multimodal architectures, compared to\nstate-of-the-art baselines.",
      "tldr_zh": "该研究提出了一种名为 MIND 的模态信息知识蒸馏框架，用于处理多模态临床预测任务，以解决多模态数据集规模小和模型复杂度高等问题。MIND 通过知识蒸馏（knowledge distillation）从不同大小的预训练单模态教师网络中转移知识到一个更小的多模态学生模型，并采用多头联合融合模型（multi-head joint fusion models），允许处理缺失模态而不需填充或掩盖，从而优化多模态和单模态表示。在实验中，MIND 在二元和多标签临床预测任务（如时间序列数据和胸部X光图像）以及三个非医疗多类数据集上，显著提升了较小多模态网络的性能，优于现有基线方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Published in Transactions on Machine Learning Research (01/2025),\n  https://openreview.net/forum?id=BhOJreYmur&noteId=ymnAhncuez",
      "pdf_url": "http://arxiv.org/pdf/2502.01158v1",
      "published_date": "2025-02-03 08:50:00 UTC",
      "updated_date": "2025-02-03 08:50:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:28:37.120949"
    },
    {
      "arxiv_id": "2502.01154v1",
      "title": "Jailbreaking with Universal Multi-Prompts",
      "title_zh": "翻译失败",
      "authors": [
        "Yu-Ling Hsu",
        "Hsuan Su",
        "Shang-Tse Chen"
      ],
      "abstract": "Large language models (LLMs) have seen rapid development in recent years,\nrevolutionizing various applications and significantly enhancing convenience\nand productivity. However, alongside their impressive capabilities, ethical\nconcerns and new types of attacks, such as jailbreaking, have emerged. While\nmost prompting techniques focus on optimizing adversarial inputs for individual\ncases, resulting in higher computational costs when dealing with large\ndatasets. Less research has addressed the more general setting of training a\nuniversal attacker that can transfer to unseen tasks. In this paper, we\nintroduce JUMP, a prompt-based method designed to jailbreak LLMs using\nuniversal multi-prompts. We also adapt our approach for defense, which we term\nDUMP. Experimental results demonstrate that our method for optimizing universal\nmulti-prompts outperforms existing techniques.",
      "tldr_zh": "该研究探讨了大型语言模型(LLMs)面临的jailbreaking攻击问题，现有方法因针对单个案例而计算成本高。论文提出JUMP，一种基于提示的方法，使用universal multi-prompts来训练通用攻击器，实现对未见任务的转移攻击。同时，作者开发了防御版本DUMP。实验结果显示，JUMP在优化universal multi-prompts方面优于现有技术，为LLMs的安全性提供了新见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by NAACL Findings 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.01154v1",
      "published_date": "2025-02-03 08:44:24 UTC",
      "updated_date": "2025-02-03 08:44:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:28:48.149737"
    },
    {
      "arxiv_id": "2502.01146v1",
      "title": "Quantum Machine Learning: A Hands-on Tutorial for Machine Learning Practitioners and Researchers",
      "title_zh": "量子机器学习：面向机器学习从业者和研究人员的动手教程",
      "authors": [
        "Yuxuan Du",
        "Xinbiao Wang",
        "Naixu Guo",
        "Zhan Yu",
        "Yang Qian",
        "Kaining Zhang",
        "Min-Hsiu Hsieh",
        "Patrick Rebentrost",
        "Dacheng Tao"
      ],
      "abstract": "This tutorial intends to introduce readers with a background in AI to quantum\nmachine learning (QML) -- a rapidly evolving field that seeks to leverage the\npower of quantum computers to reshape the landscape of machine learning. For\nself-consistency, this tutorial covers foundational principles, representative\nQML algorithms, their potential applications, and critical aspects such as\ntrainability, generalization, and computational complexity. In addition,\npractical code demonstrations are provided in https://qml-tutorial.github.io/\nto illustrate real-world implementations and facilitate hands-on learning.\nTogether, these elements offer readers a comprehensive overview of the latest\nadvancements in QML. By bridging the gap between classical machine learning and\nquantum computing, this tutorial serves as a valuable resource for those\nlooking to engage with QML and explore the forefront of AI in the quantum era.",
      "tldr_zh": "该教程旨在为有 AI 背景的机器学习从业者和研究者介绍量子机器学习 (QML)，强调利用量子计算机重塑机器学习领域的潜力。内容涵盖基础原则、代表性 QML 算法、潜在应用，以及关键方面如可训练性、泛化性和计算复杂度，并提供实际代码演示（链接：https://qml-tutorial.github.io/）以支持动手学习。通过桥接经典机器学习和量子计算，该教程为读者提供全面概述，帮助他们在量子时代探索 AI 的前沿发展。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "260 pages; Comments are welcome",
      "pdf_url": "http://arxiv.org/pdf/2502.01146v1",
      "published_date": "2025-02-03 08:33:44 UTC",
      "updated_date": "2025-02-03 08:33:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:29:00.060157"
    },
    {
      "arxiv_id": "2502.01143v3",
      "title": "ASAP: Aligning Simulation and Real-World Physics for Learning Agile Humanoid Whole-Body Skills",
      "title_zh": "翻译失败",
      "authors": [
        "Tairan He",
        "Jiawei Gao",
        "Wenli Xiao",
        "Yuanhang Zhang",
        "Zi Wang",
        "Jiashun Wang",
        "Zhengyi Luo",
        "Guanqi He",
        "Nikhil Sobanbab",
        "Chaoyi Pan",
        "Zeji Yi",
        "Guannan Qu",
        "Kris Kitani",
        "Jessica Hodgins",
        "Linxi \"Jim\" Fan",
        "Yuke Zhu",
        "Changliu Liu",
        "Guanya Shi"
      ],
      "abstract": "Humanoid robots hold the potential for unparalleled versatility in performing\nhuman-like, whole-body skills. However, achieving agile and coordinated\nwhole-body motions remains a significant challenge due to the dynamics mismatch\nbetween simulation and the real world. Existing approaches, such as system\nidentification (SysID) and domain randomization (DR) methods, often rely on\nlabor-intensive parameter tuning or result in overly conservative policies that\nsacrifice agility. In this paper, we present ASAP (Aligning Simulation and\nReal-World Physics), a two-stage framework designed to tackle the dynamics\nmismatch and enable agile humanoid whole-body skills. In the first stage, we\npre-train motion tracking policies in simulation using retargeted human motion\ndata. In the second stage, we deploy the policies in the real world and collect\nreal-world data to train a delta (residual) action model that compensates for\nthe dynamics mismatch. Then, ASAP fine-tunes pre-trained policies with the\ndelta action model integrated into the simulator to align effectively with\nreal-world dynamics. We evaluate ASAP across three transfer scenarios: IsaacGym\nto IsaacSim, IsaacGym to Genesis, and IsaacGym to the real-world Unitree G1\nhumanoid robot. Our approach significantly improves agility and whole-body\ncoordination across various dynamic motions, reducing tracking error compared\nto SysID, DR, and delta dynamics learning baselines. ASAP enables highly agile\nmotions that were previously difficult to achieve, demonstrating the potential\nof delta action learning in bridging simulation and real-world dynamics. These\nresults suggest a promising sim-to-real direction for developing more\nexpressive and agile humanoids.",
      "tldr_zh": "这篇论文提出了 ASAP 框架，用于解决人形机器人模拟与现实物理动态不匹配的问题，从而实现敏捷的全身技能学习。ASAP 采用两阶段方法：首先在模拟环境中使用重定向人类运动数据预训练动作跟踪策略，然后通过真实世界数据训练 delta（残差）动作模型来补偿动态差异，并将该模型集成到模拟器中进行微调。实验在 IsaacGym 到 IsaacSim、IsaacGym 到 Genesis 以及 IsaacGym 到真实世界 Unitree G1 机器人的转移场景中验证，ASAP 显著降低了跟踪错误，提高了敏捷性和全身协调性，优于 SysID、DR 和其他基线方法，为桥接模拟与现实动态提供了新方向。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "RSS 2025. Project website: https://agile.human2humanoid.com/",
      "pdf_url": "http://arxiv.org/pdf/2502.01143v3",
      "published_date": "2025-02-03 08:22:46 UTC",
      "updated_date": "2025-04-26 03:22:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:29:14.161133"
    },
    {
      "arxiv_id": "2502.01142v1",
      "title": "DeepRAG: Thinking to Retrieval Step by Step for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyan Guan",
        "Jiali Zeng",
        "Fandong Meng",
        "Chunlei Xin",
        "Yaojie Lu",
        "Hongyu Lin",
        "Xianpei Han",
        "Le Sun",
        "Jie Zhou"
      ],
      "abstract": "Large Language Models (LLMs) have shown remarkable potential in reasoning\nwhile they still suffer from severe factual hallucinations due to timeliness,\naccuracy, and coverage of parametric knowledge. Meanwhile, integrating\nreasoning with retrieval-augmented generation (RAG) remains challenging due to\nineffective task decomposition and redundant retrieval, which can introduce\nnoise and degrade response quality. In this paper, we propose DeepRAG, a\nframework that models retrieval-augmented reasoning as a Markov Decision\nProcess (MDP), enabling strategic and adaptive retrieval. By iteratively\ndecomposing queries, DeepRAG dynamically determines whether to retrieve\nexternal knowledge or rely on parametric reasoning at each step. Experiments\nshow that DeepRAG improves retrieval efficiency while improving answer accuracy\nby 21.99%, demonstrating its effectiveness in optimizing retrieval-augmented\nreasoning.",
      "tldr_zh": "大语言模型(LLMs) 在推理方面表现出色，但易受事实性幻觉影响，且与检索增强生成(RAG) 的整合存在任务分解无效和冗余检索等问题，导致响应质量下降。论文提出 DeepRAG 框架，将检索增强推理建模为马尔可夫决策过程(MDP)，通过迭代分解查询并动态决定是否检索外部知识或依赖参数推理，实现战略性适应。实验证明，DeepRAG 提高了检索效率，并将答案准确率提升了 21.99%，展示了其在优化检索增强推理方面的有效性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01142v1",
      "published_date": "2025-02-03 08:22:45 UTC",
      "updated_date": "2025-02-03 08:22:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:29:25.619163"
    },
    {
      "arxiv_id": "2502.01141v1",
      "title": "Beyond Yes or No: Predictive Compliance Monitoring Approaches for Quantifying the Magnitude of Compliance Violations",
      "title_zh": "超越是或否：用于量化合规违规程度的预测性",
      "authors": [
        "Qian Chen",
        "Stefanie Rinderle-Ma",
        "Lijie Wen"
      ],
      "abstract": "Most existing process compliance monitoring approaches detect compliance\nviolations in an ex post manner. Only predicate prediction focuses on\npredicting them. However, predicate prediction provides a binary yes/no notion\nof compliance, lacking the ability to measure to which extent an ongoing\nprocess instance deviates from the desired state as specified in constraints.\nHere, being able to quantify the magnitude of violation would provide\norganizations with deeper insights into their operational performance, enabling\ninformed decision making to reduce or mitigate the risk of non-compliance.\nThus, we propose two predictive compliance monitoring approaches to close this\nresearch gap. The first approach reformulates the binary classification problem\nas a hybrid task that considers both classification and regression, while the\nsecond employs a multi-task learning method to explicitly predict the\ncompliance status and the magnitude of violation for deviant cases\nsimultaneously. In this work, we focus on temporal constraints as they are\nsignificant in almost any application domain, e.g., health care. The evaluation\non synthetic and real-world event logs demonstrates that our approaches are\ncapable of quantifying the magnitude of violations while maintaining comparable\nperformance for compliance predictions achieved by state-of-the-art approaches.",
      "tldr_zh": "现有预测合规监控方法多为事后检测，或仅提供二元（yes/no）合规状态，无法量化违反程度，这限制了组织对操作绩效的深入分析。本文提出两种预测合规监控方法：第一种将binary classification问题转化为混合任务，结合分类和回归；第二种采用multi-task learning，同时预测合规状态和违反程度。针对temporal constraints（如医疗领域），在合成和真实事件日志上进行评估，结果显示这些方法能有效量化违反程度，同时保持与state-of-the-art方法相当的合规预测性能。这为组织提供更精确的决策支持，减少非合规风险。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01141v1",
      "published_date": "2025-02-03 08:18:33 UTC",
      "updated_date": "2025-02-03 08:18:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:29:37.711764"
    },
    {
      "arxiv_id": "2502.01137v1",
      "title": "Self-Organizing Interaction Spaces: A Framework for Engineering Pervasive Applications in Mobile and Distributed Environments",
      "title_zh": "自组织交互空间：用于工程移动",
      "authors": [
        "Shubham Malhotra"
      ],
      "abstract": "The rapid adoption of pervasive and mobile computing has led to an\nunprecedented rate of data production and consumption by mobile applications at\nthe network edge. These applications often require interactions such as data\nexchange, behavior coordination, and collaboration, which are typically\nmediated by cloud servers. While cloud computing has been effective for\ndistributed systems, challenges like latency, cost, and intermittent\nconnectivity persist. With the advent of 5G technology, features like\nlocation-awareness and device-to-device (D2D) communication enable a more\ndistributed and adaptive architecture. This paper introduces Self-Organizing\nInteraction Spaces (SOIS), a novel framework for engineering pervasive\napplications. SOIS leverages the dynamic and heterogeneous nature of mobile\nnodes, allowing them to form adaptive organizational structures based on their\nindividual and social contexts. The framework provides two key abstractions for\nmodeling and programming pervasive applications using an organizational mindset\nand mechanisms for adapting dynamic organizational structures. Case examples\nand performance evaluations of a simulated mobile crowd-sensing application\ndemonstrate the feasibility and benefits of SOIS. Results highlight its\npotential to enhance efficiency and reduce reliance on traditional cloud\nmodels, paving the way for innovative solutions in mobile and distributed\nenvironments.",
      "tldr_zh": "这篇论文针对移动和分布式环境中 pervasive applications 的交互挑战（如数据交换、行为协调和协作），提出了Self-Organizing Interaction Spaces (SOIS)框架，以解决云服务器的延迟、成本和间歇性连接问题。SOIS利用5G技术的特性（如location-awareness和D2D communication），允许移动节点基于个人和社会上下文形成自适应的组织结构，并提供组织思维的建模和编程抽象来动态调整结构。实验评估通过模拟的移动众包应用证明了SOIS的可行性，提高了系统效率并减少了对传统云模型的依赖。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.DC",
      "comment": "9 pages, 3 listings",
      "pdf_url": "http://arxiv.org/pdf/2502.01137v1",
      "published_date": "2025-02-03 08:11:30 UTC",
      "updated_date": "2025-02-03 08:11:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:29:49.419251"
    },
    {
      "arxiv_id": "2502.01129v3",
      "title": "Deep Reinforcement Learning for Dynamic Resource Allocation in Wireless Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Shubham Malhotra",
        "Fnu Yashu",
        "Muhammad Saqib",
        "Dipkumar Mehta",
        "Jagdish Jangid",
        "Sachin Dixit"
      ],
      "abstract": "This report investigates the application of deep reinforcement learning (DRL)\nalgorithms for dynamic resource allocation in wireless communication systems.\nAn environment that includes a base station, multiple antennas, and user\nequipment is created. Using the RLlib library, various DRL algorithms such as\nDeep Q-Network (DQN) and Proximal Policy Optimization (PPO) are then applied.\nThese algorithms are compared based on their ability to optimize resource\nallocation, focusing on the impact of different learning rates and scheduling\npolicies. The findings demonstrate that the choice of algorithm and learning\nrate significantly influences system performance, with DRL providing more\nefficient resource allocation compared to traditional methods.",
      "tldr_zh": "这篇论文探讨了深度强化学习 (DRL) 算法在无线通信系统动态资源分配中的应用，创建了一个包含基站、多天线和用户设备的模拟环境。研究使用 RLlib 库比较了 Deep Q-Network (DQN) 和 Proximal Policy Optimization (PPO) 等算法，重点评估不同学习率和调度策略对优化资源分配的影响。结果表明，算法选择和学习率显著影响系统性能，DRL 方法相较于传统方法提供了更高效的资源分配。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.ET",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "Upon further review, we found inconsistencies in our analysis and\n  decided to conduct additional research before resubmitting a revised version",
      "pdf_url": "http://arxiv.org/pdf/2502.01129v3",
      "published_date": "2025-02-03 07:49:00 UTC",
      "updated_date": "2025-03-13 13:17:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:30:00.945931"
    },
    {
      "arxiv_id": "2502.01127v3",
      "title": "The Battling Influencers Game: Nash Equilibria Structure of a Potential Game and Implications to Value Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Young Wu",
        "Yancheng Zhu",
        "Jin-Yi Cai",
        "Xiaojin Zhu"
      ],
      "abstract": "When multiple influencers attempt to compete for a receiver's attention,\ntheir influencing strategies must account for the presence of one another. We\nintroduce the Battling Influencers Game (BIG), a multi-player simultaneous-move\ngeneral-sum game, to provide a game-theoretic characterization of this social\nphenomenon. We prove that BIG is a potential game, that it has either one or an\ninfinite number of pure Nash equilibria (NEs), and these pure NEs can be found\nby convex optimization. Interestingly, we also prove that at any pure NE, all\n(except at most one) influencers must exaggerate their actions to the maximum\nextent. In other words, it is rational for the influencers to be non-truthful\nand extreme because they anticipate other influencers to cancel out part of\ntheir influence. We discuss the implications of BIG to value alignment.",
      "tldr_zh": "本论文引入了 Battling Influencers Game (BIG)，一个多玩家同时移动的广义和游戏，用于游戏理论分析影响者竞争受众注意力的行为。研究证明了 BIG 是一个 Potential Game，具有零个或无限多个纯 Nash Equilibria (NEs)，这些均衡可以通过凸优化求解。在纯 NE 中，所有影响者（除最多一个外）必须将行动夸大到最大程度，导致非真实和极端策略，因为他们预期其他影响者会抵消部分影响。该模型揭示了这种竞争动态对 Value Alignment 的启示，即影响者理性行为可能加剧价值偏差。",
      "categories": [
        "cs.GT",
        "cs.AI"
      ],
      "primary_category": "cs.GT",
      "comment": "9 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.01127v3",
      "published_date": "2025-02-03 07:45:41 UTC",
      "updated_date": "2025-02-07 08:10:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:30:13.820126"
    },
    {
      "arxiv_id": "2502.01118v1",
      "title": "Large Language Model-Enhanced Multi-Armed Bandits",
      "title_zh": "大语言模型增强的多臂老虎机",
      "authors": [
        "Jiahang Sun",
        "Zhiyong Wang",
        "Runhan Yang",
        "Chenjun Xiao",
        "John C. S. Lui",
        "Zhongxiang Dai"
      ],
      "abstract": "Large language models (LLMs) have been adopted to solve sequential\ndecision-making tasks such as multi-armed bandits (MAB), in which an LLM is\ndirectly instructed to select the arms to pull in every iteration. However,\nthis paradigm of direct arm selection using LLMs has been shown to be\nsuboptimal in many MAB tasks. Therefore, we propose an alternative approach\nwhich combines the strengths of classical MAB and LLMs. Specifically, we adopt\na classical MAB algorithm as the high-level framework and leverage the strong\nin-context learning capability of LLMs to perform the sub-task of reward\nprediction. Firstly, we incorporate the LLM-based reward predictor into the\nclassical Thompson sampling (TS) algorithm and adopt a decaying schedule for\nthe LLM temperature to ensure a transition from exploration to exploitation.\nNext, we incorporate the LLM-based reward predictor (with a temperature of 0)\ninto a regression oracle-based MAB algorithm equipped with an explicit\nexploration mechanism. We also extend our TS-based algorithm to dueling bandits\nwhere only the preference feedback between pairs of arms is available, which\nrequires non-trivial algorithmic modifications. We conduct empirical\nevaluations using both synthetic MAB tasks and experiments designed using\nreal-world text datasets, in which the results show that our algorithms\nconsistently outperform previous baseline methods based on direct arm\nselection. Interestingly, we also demonstrate that in challenging tasks where\nthe arms lack semantic meanings that can be exploited by the LLM, our approach\nachieves considerably better performance than LLM-based direct arm selection.",
      "tldr_zh": "这篇论文提出了一种增强多臂赌博机 (Multi-Armed Bandits, MAB) 的方法，将大型语言模型 (Large Language Models, LLMs) 用于奖励预测子任务，而不是直接选择臂，以克服现有方法的 suboptimal 问题。具体地，该方法将 LLM 整合到 Thompson Sampling (TS) 算法中，通过衰减温度调度实现从探索到利用的平稳过渡，并扩展到基于回归预言机的算法和双臂赌博机 (dueling bandits)，后者仅依赖臂对偏好反馈。实验在合成任务和真实文本数据集上显示，该方法 consistently 优于直接臂选择的基线，尤其在臂缺乏语义含义的挑战性任务中，表现出显著性能提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2502.01118v1",
      "published_date": "2025-02-03 07:19:05 UTC",
      "updated_date": "2025-02-03 07:19:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:30:26.581408"
    },
    {
      "arxiv_id": "2503.11655v1",
      "title": "Explainable Sentiment Analysis with DeepSeek-R1: Performance, Efficiency, and Few-Shot Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Donghao Huang",
        "Zhaoxia Wang"
      ],
      "abstract": "Recent advancements in large language models (LLMs) have significantly\nenhanced sentiment analysis capabilities. However, the trade-offs between model\nperformance, efficiency, and explainability of some latest models remain\nunderexplored. This study presents the first comprehensive evaluation of the\nDeepSeek-R1 series of models, reasoning open-source LLMs, for sentiment\nanalysis, comparing them against OpenAI's GPT-4 and GPT-4-mini. We\nsystematically analyze their performance under few-shot prompting conditions,\nscaling up to 50-shot configurations to assess in-context learning\neffectiveness. Our experiments reveal that DeepSeek-R1 demonstrates competitive\naccuracy, particularly in multi-class sentiment tasks, while offering enhanced\ninterpretability through its detailed reasoning process. Additionally, we\nhighlight the impact of increasing few-shot examples on model performance and\ndiscuss key trade-offs between explainability and computational efficiency.",
      "tldr_zh": "本研究首次全面评估了DeepSeek-R1系列模型在情感分析中的性能、效率和可解释性，将其与GPT-4和GPT-4-mini进行比较。研究采用few-shot prompting方法，从1-shot扩展到50-shot配置，测试其in-context learning效果，结果显示DeepSeek-R1在多类情感任务中表现出竞争性的准确率，并通过详细的推理过程提升了可解释性。实验还揭示了增加few-shot示例对性能的积极影响，同时讨论了可解释性与计算效率之间的关键权衡，为开源LLMs在情感分析应用提供了宝贵见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 3 figures, 4 tables, submitted to an IEEE journal",
      "pdf_url": "http://arxiv.org/pdf/2503.11655v1",
      "published_date": "2025-02-03 07:17:46 UTC",
      "updated_date": "2025-02-03 07:17:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:30:37.777807"
    },
    {
      "arxiv_id": "2502.01117v3",
      "title": "Learning to Learn Weight Generation via Local Consistency Diffusion",
      "title_zh": "翻译失败",
      "authors": [
        "Yunchuan Guan",
        "Yu Liu",
        "Ke Zhou",
        "Zhiqi Shen",
        "Jenq-Neng Hwang",
        "Lei Li"
      ],
      "abstract": "Diffusion-based algorithms have emerged as promising techniques for weight\ngeneration. However, existing solutions are limited by two challenges:\ngeneralizability and local target assignment. The former arises from the\ninherent lack of cross-task transferability in existing single-level\noptimization methods, limiting the model's performance on new tasks. The latter\nlies in existing research modeling only global optimal weights, neglecting the\nsupervision signals in local target weights. Moreover, naively assigning local\ntarget weights causes local-global inconsistency. To address these issues, we\npropose Mc-Di, which integrates the diffusion algorithm with meta-learning for\nbetter generalizability. Furthermore, we extend the vanilla diffusion into a\nlocal consistency diffusion algorithm. Our theory and experiments demonstrate\nthat it can learn from local targets while maintaining consistency with the\nglobal optima. We validate Mc-Di's superior accuracy and inference efficiency\nin tasks that require frequent weight updates, including transfer learning,\nfew-shot learning, domain generalization, and large language model adaptation.",
      "tldr_zh": "本研究针对 Diffusion-based 算法在权重生成中的局限性，提出 Mc-Di 框架，以解决 generalizability（泛化性）和 local target assignment（局部目标分配）问题。Mc-Di 通过整合 diffusion 算法与 meta-learning，提升模型在跨任务转移中的性能；同时，扩展为 local consistency diffusion 算法，能从局部目标权重学习监督信号，同时保持局部-全局一致性。实验结果显示，Mc-Di 在 transfer learning、few-shot learning、domain generalization 和 large language model adaptation 等任务中，实现了更高的准确性和推理效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01117v3",
      "published_date": "2025-02-03 07:13:59 UTC",
      "updated_date": "2025-05-19 05:44:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:30:49.385286"
    },
    {
      "arxiv_id": "2502.01116v1",
      "title": "Picky LLMs and Unreliable RMs: An Empirical Study on Safety Alignment after Instruction Tuning",
      "title_zh": "挑剔的 LLMs 和不可靠的 RMs：",
      "authors": [
        "Guanlin Li",
        "Kangjie Chen",
        "Shangwei Guo",
        "Jie Zhang",
        "Han Qiu",
        "Chao Zhang",
        "Guoyin Wang",
        "Tianwei Zhang",
        "Jiwei Li"
      ],
      "abstract": "Large language models (LLMs) have emerged as powerful tools for addressing a\nwide range of general inquiries and tasks. Despite this, fine-tuning aligned\nLLMs on smaller, domain-specific datasets, critical to adapting them to\nspecialized tasks, can inadvertently degrade their safety alignment, even when\nthe datasets are benign. This phenomenon makes models more susceptible to\nproviding inappropriate responses. In this study, we systematically examine the\nfactors contributing to safety alignment degradation in benign fine-tuning\nscenarios. Our analysis identifies three critical factors affecting aligned\nLLMs: answer structure, identity calibration, and role-play. Additionally, we\nevaluate the reliability of state-of-the-art reward models (RMs), which are\noften used to guide alignment processes. Our findings reveal that these RMs\nfrequently fail to accurately reflect human preferences regarding safety,\nunderscoring their limitations in practical applications. By uncovering these\nchallenges, our work highlights the complexities of maintaining safety\nalignment during fine-tuning and offers guidance to help developers balance\nutility and safety in LLMs. Datasets and fine-tuning code used in our\nexperiments can be found in\nhttps://github.com/GuanlinLee/llm_instruction_tuning.",
      "tldr_zh": "本研究通过实证分析探讨了大型语言模型（LLMs）在指令微调后，安全对齐（safety alignment）可能退化的问题，即使微调数据集是良性的。研究识别了三个关键影响因素：回答结构（answer structure）、身份校准（identity calibration）和角色扮演（role-play），并评估了状态-of-the-art奖励模型（RMs）的可靠性，发现这些RMs往往无法准确反映人类对安全的偏好。结果表明，微调过程的复杂性可能使模型更容易产生不当响应，该工作为开发者提供了平衡LLMs实用性和安全的指导，并公开了相关数据集和代码。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01116v1",
      "published_date": "2025-02-03 07:09:09 UTC",
      "updated_date": "2025-02-03 07:09:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:31:01.522732"
    },
    {
      "arxiv_id": "2502.01113v1",
      "title": "GFM-RAG: Graph Foundation Model for Retrieval Augmented Generation",
      "title_zh": "GFM-RAG：用于检索增强生成的图基础模型",
      "authors": [
        "Linhao Luo",
        "Zicheng Zhao",
        "Gholamreza Haffari",
        "Dinh Phung",
        "Chen Gong",
        "Shirui Pan"
      ],
      "abstract": "Retrieval-augmented generation (RAG) has proven effective in integrating\nknowledge into large language models (LLMs). However, conventional RAGs\nstruggle to capture complex relationships between pieces of knowledge, limiting\ntheir performance in intricate reasoning that requires integrating knowledge\nfrom multiple sources. Recently, graph-enhanced retrieval augmented generation\n(GraphRAG) builds graph structure to explicitly model these relationships,\nenabling more effective and efficient retrievers. Nevertheless, its performance\nis still hindered by the noise and incompleteness within the graph structure.\nTo address this, we introduce GFM-RAG, a novel graph foundation model (GFM) for\nretrieval augmented generation. GFM-RAG is powered by an innovative graph\nneural network that reasons over graph structure to capture complex\nquery-knowledge relationships. The GFM with 8M parameters undergoes a two-stage\ntraining process on large-scale datasets, comprising 60 knowledge graphs with\nover 14M triples and 700k documents. This results in impressive performance and\ngeneralizability for GFM-RAG, making it the first graph foundation model\napplicable to unseen datasets for retrieval without any fine-tuning required.\nExtensive experiments on three multi-hop QA datasets and seven domain-specific\nRAG datasets demonstrate that GFM-RAG achieves state-of-the-art performance\nwhile maintaining efficiency and alignment with neural scaling laws,\nhighlighting its potential for further improvement.",
      "tldr_zh": "该研究提出 GFM-RAG，一种基于图基础模型(Graph Foundation Model)的检索增强生成(Retrieval Augmented Generation)框架，旨在解决传统 RAG 和 GraphRAG 在处理知识间复杂关系时的局限性，如噪声和不完整图结构。GFM-RAG 利用创新的图神经网络(Graph Neural Network)对图结构进行推理，捕捉查询与知识的复杂关联，并通过两阶段训练（使用 60 个知识图超过 14M 三元组和 700k 文档）构建一个 8M 参数的模型，实现无需微调即可应用于未见数据集。实验结果显示，GFM-RAG 在三个多跳 QA 数据集和七个领域特定 RAG 数据集上达到最先进(State-of-the-Art)性能，同时保持高效性和与神经缩放定律的兼容性，展示了其在知识集成和推理方面的潜力。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "19 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.01113v1",
      "published_date": "2025-02-03 07:04:29 UTC",
      "updated_date": "2025-02-03 07:04:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:31:13.735751"
    },
    {
      "arxiv_id": "2502.01111v1",
      "title": "A generative foundation model for an all-in-one seismic processing framework",
      "title_zh": "一种用于一体化地震处理框架的生成式基础模型",
      "authors": [
        "Shijun Cheng",
        "Randy Harsuko",
        "Tariq Alkhalifah"
      ],
      "abstract": "Seismic data often face challenges in their utilization due to noise\ncontamination, incomplete acquisition, and limited low-frequency information,\nwhich hinder accurate subsurface imaging and interpretation. Traditional\nprocessing methods rely heavily on task-specific designs to address these\nchallenges and fail to account for the variability of data. To address these\nlimitations, we present a generative seismic foundation model (GSFM), a unified\nframework based on generative diffusion models (GDMs), designed to tackle\nmulti-task seismic processing challenges, including denoising, backscattered\nnoise attenuation, interpolation, and low-frequency extrapolation. GSFM\nleverages a pre-training stage on synthetic data to capture the features of\nclean, complete, and broadband seismic data distributions and applies an\niterative fine-tuning strategy to adapt the model to field data. By adopting a\ntarget-oriented diffusion process prediction, GSFM improves computational\nefficiency without compromising accuracy. Synthetic data tests demonstrate GSFM\nsurpasses benchmarks with equivalent architectures in all tasks and achieves\nperformance comparable to traditional pre-training strategies, even after their\nfine-tuning. Also, field data tests suggest that our iterative fine-tuning\napproach addresses the generalization limitations of conventional pre-training\nand fine-tuning paradigms, delivering significantly enhanced performance across\ndiverse tasks. Furthermore, GSFM's inherent probabilistic nature enables\neffective uncertainty quantification, offering valuable insights into the\nreliability of processing results.",
      "tldr_zh": "本研究针对地震数据面临的噪声污染、不完整采集和低频信息不足等问题，提出了一种统一的生成式基础模型Generative Seismic Foundation Model (GSFM)，基于Generative Diffusion Models (GDMs)构建一个全流程框架，支持多任务处理如denoising、backscattered noise attenuation、interpolation和low-frequency extrapolation。GSFM 通过在合成数据上进行预训练以捕获干净完整的数据特征，并采用迭代微调策略适应现场数据，同时利用目标导向的扩散过程预测提升计算效率。实验结果显示，GSFM 在合成数据测试中超越基准模型，在现场数据测试中显著改善泛化性能，并通过其概率特性实现有效的不确定性量化，提供更可靠的处理结果。",
      "categories": [
        "physics.geo-ph",
        "cs.AI"
      ],
      "primary_category": "physics.geo-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01111v1",
      "published_date": "2025-02-03 07:01:36 UTC",
      "updated_date": "2025-02-03 07:01:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:31:25.562257"
    },
    {
      "arxiv_id": "2502.01108v1",
      "title": "Pulse-PPG: An Open-Source Field-Trained PPG Foundation Model for Wearable Applications Across Lab and Field Settings",
      "title_zh": "翻译失败",
      "authors": [
        "Mithun Saha",
        "Maxwell A. Xu",
        "Wanting Mao",
        "Sameer Neupane",
        "James M. Rehg",
        "Santosh Kumar"
      ],
      "abstract": "Photoplethysmography (PPG)-based foundation models are gaining traction due\nto the widespread use of PPG in biosignal monitoring and their potential to\ngeneralize across diverse health applications. In this paper, we introduce\nPulse-PPG, the first open-source PPG foundation model trained exclusively on\nraw PPG data collected over a 100-day field study with 120 participants.\nExisting PPG foundation models are either open-source but trained on clinical\ndata or closed-source, limiting their applicability in real-world settings. We\nevaluate Pulse-PPG across multiple datasets and downstream tasks, comparing its\nperformance against a state-of-the-art foundation model trained on clinical\ndata. Our results demonstrate that Pulse-PPG, trained on uncurated field data,\nexhibits superior generalization across clinical and mobile health applications\nin both lab and field settings. This suggests that exposure to real-world\nvariability enables the model to learn fine-grained representations, making it\nmore adaptable across tasks. Furthermore, pre-training on field data\nsurprisingly outperforms its pre-training on clinical data in many tasks,\nreinforcing the importance of training on real-world, diverse datasets. To\nencourage further advancements in robust foundation models leveraging field\ndata, we plan to release Pulse-PPG, providing researchers with a powerful\nresource for developing more generalizable PPG-based models.",
      "tldr_zh": "这篇论文介绍了Pulse-PPG，这是一个开源的PPG基础模型，首次使用原始PPG数据从100天现场研究（涉及120名参与者）进行训练，旨在提升可穿戴设备在实验室和现场环境的泛化应用。不同于基于临床数据的现有模型，Pulse-PPG利用未经整理的真实世界数据，显著提高了模型在多种下游任务中的表现。实验结果显示，该模型在临床和移动健康应用中比状态-of-the-art临床训练模型表现出色，强调了暴露于真实世界变异性的重要性。作者计划开源Pulse-PPG，以促进更鲁棒的PPG基础模型开发。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "The first two listed authors contributed equally to this research",
      "pdf_url": "http://arxiv.org/pdf/2502.01108v1",
      "published_date": "2025-02-03 06:56:40 UTC",
      "updated_date": "2025-02-03 06:56:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:31:38.290785"
    },
    {
      "arxiv_id": "2502.01101v2",
      "title": "VidSketch: Hand-drawn Sketch-Driven Video Generation with Diffusion Control",
      "title_zh": "翻译失败",
      "authors": [
        "Lifan Jiang",
        "Shuang Chen",
        "Boxi Wu",
        "Xiaotong Guan",
        "Jiahui Zhang"
      ],
      "abstract": "With the advancement of generative artificial intelligence, previous studies\nhave achieved the task of generating aesthetic images from hand-drawn sketches,\nfulfilling the public's needs for drawing. However, these methods are limited\nto static images and lack the ability to control video animation generation\nusing hand-drawn sketches. To address this gap, we propose VidSketch, the first\nmethod capable of generating high-quality video animations directly from any\nnumber of hand-drawn sketches and simple text prompts, bridging the divide\nbetween ordinary users and professional artists. Specifically, our method\nintroduces a Level-Based Sketch Control Strategy to automatically adjust the\nguidance strength of sketches during the generation process, accommodating\nusers with varying drawing skills. Furthermore, a TempSpatial Attention\nmechanism is designed to enhance the spatiotemporal consistency of generated\nvideo animations, significantly improving the coherence across frames. You can\nfind more detailed cases on our official website.",
      "tldr_zh": "该研究提出VidSketch，一种基于Diffusion Control的手绘草图驱动视频生成方法，能够从任意数量的手绘草图和简单文本提示生成高质量视频动画，从而桥接普通用户与专业艺术家的差距。具体来说，该方法引入Level-Based Sketch Control Strategy来自动调整草图的引导强度，以适应不同绘画技能的用户；同时，设计TempSpatial Attention机制以增强生成视频的时空一致性，提高帧间连贯性。通过这些创新，VidSketch扩展了生成AI的应用，从静态图像扩展到动态视频动画。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "17pages, 15 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.01101v2",
      "published_date": "2025-02-03 06:45:00 UTC",
      "updated_date": "2025-02-17 05:49:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:31:48.928920"
    },
    {
      "arxiv_id": "2502.01100v1",
      "title": "ZebraLogic: On the Scaling Limits of LLMs for Logical Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Bill Yuchen Lin",
        "Ronan Le Bras",
        "Kyle Richardson",
        "Ashish Sabharwal",
        "Radha Poovendran",
        "Peter Clark",
        "Yejin Choi"
      ],
      "abstract": "We investigate the logical reasoning capabilities of large language models\n(LLMs) and their scalability in complex non-monotonic reasoning. To this end,\nwe introduce ZebraLogic, a comprehensive evaluation framework for assessing LLM\nreasoning performance on logic grid puzzles derived from constraint\nsatisfaction problems (CSPs). ZebraLogic enables the generation of puzzles with\ncontrollable and quantifiable complexity, facilitating a systematic study of\nthe scaling limits of models such as Llama, o1 models, and DeepSeek-R1. By\nencompassing a broad range of search space complexities and diverse logical\nconstraints, ZebraLogic provides a structured environment to evaluate reasoning\nunder increasing difficulty.\n  Our results reveal a significant decline in accuracy as problem complexity\ngrows -- a phenomenon we term the curse of complexity. This limitation persists\neven with larger models and increased inference-time computation, suggesting\ninherent constraints in current LLM reasoning capabilities. Additionally, we\nexplore strategies to enhance logical reasoning, including Best-of-N sampling,\nbacktracking mechanisms, and self-verification prompts. Our findings offer\ncritical insights into the scalability of LLM reasoning, highlight fundamental\nlimitations, and outline potential directions for improvement.",
      "tldr_zh": "本研究调查了大型语言模型（LLMs）在复杂非单调推理中的逻辑推理能力和可扩展性极限，引入了 ZebraLogic 框架来评估模型在源于约束满足问题（CSPs）的逻辑网格谜题上的表现。ZebraLogic 通过生成复杂度可控的谜题，系统地测试了如 Llama、o1 模型和 DeepSeek-R1 等模型的推理性能，结果显示随着问题复杂度的增加，准确率显著下降（curse of complexity），即使使用更大模型或更多推理计算也无法完全克服这一限制。该框架揭示了当前 LLM 推理能力的固有约束，并探索了改进策略，包括 Best-of-N sampling、backtracking mechanisms 和 self-verification prompts，为未来提升 LLM 逻辑推理提供了潜在方向。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Website: https://huggingface.co/spaces/WildEval/ZebraLogic",
      "pdf_url": "http://arxiv.org/pdf/2502.01100v1",
      "published_date": "2025-02-03 06:44:49 UTC",
      "updated_date": "2025-02-03 06:44:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:32:01.964646"
    },
    {
      "arxiv_id": "2502.04342v2",
      "title": "Tutorial on Using Machine Learning and Deep Learning Models for Mental Illness Detection",
      "title_zh": "使用机器学习和深度学习模型进行精神疾病检测的教程",
      "authors": [
        "Yeyubei Zhang",
        "Zhongyan Wang",
        "Zhanyi Ding",
        "Yexin Tian",
        "Jianglai Dai",
        "Xiaorui Shen",
        "Yunchong Liu",
        "Yuchen Cao"
      ],
      "abstract": "Social media has become an important source for understanding mental health,\nproviding researchers with a way to detect conditions like depression from\nuser-generated posts. This tutorial provides practical guidance to address\ncommon challenges in applying machine learning and deep learning methods for\nmental health detection on these platforms. It focuses on strategies for\nworking with diverse datasets, improving text preprocessing, and addressing\nissues such as imbalanced data and model evaluation. Real-world examples and\nstep-by-step instructions demonstrate how to apply these techniques\neffectively, with an emphasis on transparency, reproducibility, and ethical\nconsiderations. By sharing these approaches, this tutorial aims to help\nresearchers build more reliable and widely applicable models for mental health\nresearch, contributing to better tools for early detection and intervention.",
      "tldr_zh": "这篇教程探讨了使用 machine learning 和 deep learning 模型从社交媒体数据中检测精神疾病（如抑郁）的实用方法。\n它针对常见挑战提供指导，包括处理多样数据集、改进文本预处理、应对数据不平衡以及模型评估。\n通过真实示例和逐步指令，该教程强调透明性、可重复性和伦理考虑，帮助研究者构建更可靠的模型，从而促进精神健康早期检测和干预。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.04342v2",
      "published_date": "2025-02-03 06:43:12 UTC",
      "updated_date": "2025-03-04 05:13:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:32:13.942153"
    },
    {
      "arxiv_id": "2502.01091v1",
      "title": "Enhancing Aspect-based Sentiment Analysis with ParsBERT in Persian Language",
      "title_zh": "翻译失败",
      "authors": [
        "Farid Ariai",
        "Maryam Tayefeh Mahmoudi",
        "Ali Moeini"
      ],
      "abstract": "In the era of pervasive internet use and the dominance of social networks,\nresearchers face significant challenges in Persian text mining including the\nscarcity of adequate datasets in Persian and the inefficiency of existing\nlanguage models. This paper specifically tackles these challenges, aiming to\namplify the efficiency of language models tailored to the Persian language.\nFocusing on enhancing the effectiveness of sentiment analysis, our approach\nemploys an aspect-based methodology utilizing the ParsBERT model, augmented\nwith a relevant lexicon. The study centers on sentiment analysis of user\nopinions extracted from the Persian website 'Digikala.' The experimental\nresults not only highlight the proposed method's superior semantic capabilities\nbut also showcase its efficiency gains with an accuracy of 88.2% and an F1\nscore of 61.7. The importance of enhancing language models in this context lies\nin their pivotal role in extracting nuanced sentiments from user-generated\ncontent, ultimately advancing the field of sentiment analysis in Persian text\nmining by increasing efficiency and accuracy.",
      "tldr_zh": "本论文针对波斯语文本挖掘中的数据集稀缺和语言模型低效问题，提出了一种基于 ParsBERT 的方面情感分析（Aspect-based Sentiment Analysis）方法，并结合相关词汇表分析 Digikala 网站的用户意见。研究通过增强 ParsBERT 模型的语义能力，实现了更精确的情感提取。实验结果显示，该方法在波斯语数据集上取得了 88.2% 的准确率和 61.7% 的 F1 score，显著提高了情感分析的效率和准确性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01091v1",
      "published_date": "2025-02-03 06:25:06 UTC",
      "updated_date": "2025-02-03 06:25:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:34:19.358127"
    },
    {
      "arxiv_id": "2502.01090v1",
      "title": "Classic4Children: Adapting Chinese Literary Classics for Children with Large Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Jiali Chen",
        "Xusen Hei",
        "Yuqi Xue",
        "Zihan Wu",
        "Jiayuan Xie",
        "Yi Cai"
      ],
      "abstract": "Chinese literary classics hold significant cultural and educational value,\noffering deep insights into morality, history, and human nature. These works\noften include classical Chinese and complex narratives, making them difficult\nfor children to read. To bridge this gap, we introduce a child-friendly\nliterary adaptation (CLA) task to adapt the Chinese literary classic into\nengaging and accessible text for children. However, recent large language\nmodels (LLMs) overlook children's reading preferences (\\ie, vivid character\nportrayals, concise narrative structures, and appropriate readability), which\nposes challenges in CLA. In this paper, we propose a method called\nInstructChild, which augments the LLM with these preferences for adaptation.\nSpecifically, we first obtain the characters' personalities and narrative\nstructure as additional information for fine-grained instruction tuning. Then,\nwe devise a readability metric as the reward to align the LLM with the\nchildren's reading level. Finally, a lookahead decoding strategy is applied to\nimprove the readability of the generated text during inference. To support the\nevaluation of CLA task, we construct the Classic4Children dataset, which\ncomprises both the original and child-friendly versions of the Four Great\nClassical Novels of Chinese literature. Experimental results show that our\nInstructChild significantly improves automatic and human evaluation\nperformance.",
      "tldr_zh": "本文提出儿童友好文学适应 (CLA) 任务，旨在将中文文学经典改编成适合儿童阅读的生动、简洁文本，以克服 Large Language Model (LLMs) 忽略儿童偏好（如人物描绘和可读性）的挑战。InstructChild 方法通过获取人物个性和叙事结构进行细粒度指令调整、设计可读性指标作为奖励，以及应用前瞻解码策略来提升生成文本的质量。为支持评估，该研究构建了 Classic4Children 数据集，包含中国四大名著的原版和儿童友好版。实验结果显示，InstructChild 在自动和人工评估中显著提高了性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at NAACL 2025 Findings",
      "pdf_url": "http://arxiv.org/pdf/2502.01090v1",
      "published_date": "2025-02-03 06:23:35 UTC",
      "updated_date": "2025-02-03 06:23:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:32:38.873723"
    },
    {
      "arxiv_id": "2502.01089v2",
      "title": "Advanced Architectures Integrated with Agentic AI for Next-Generation Wireless Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Kapal Dev",
        "Sunder Ali Khowaja",
        "Keshav Singh",
        "Engin Zeydan",
        "Merouane Debbah"
      ],
      "abstract": "This paper investigates a range of cutting-edge technologies and\narchitectural innovations aimed at simplifying network operations, reducing\noperational expenditure (OpEx), and enabling the deployment of new service\nmodels. The focus is on (i) Proposing novel, more efficient 6G architectures,\nwith both Control and User planes enabling the seamless expansion of services,\nwhile addressing long-term 6G network evolution. (ii) Exploring advanced\ntechniques for constrained artificial intelligence (AI) operations,\nparticularly the design of AI agents for real-time learning, optimizing energy\nconsumption, and the allocation of computational resources. (iii) Identifying\ntechnologies and architectures that support the orchestration of backend\nservices using serverless computing models across multiple domains,\nparticularly for vertical industries. (iv) Introducing optically-based,\nultra-high-speed, low-latency network architectures, with fast optical\nswitching and real-time control, replacing conventional electronic switching to\nreduce power consumption by an order of magnitude.",
      "tldr_zh": "这篇论文探讨了整合 Agentic AI 的先进架构，以简化下一代无线网络的操作、降低运营支出（OpEx），并支持新服务模型的部署。主要贡献包括提出高效的 6G 架构，支持控制平面和用户平面的无缝服务扩展，并解决长期网络演进问题；设计 AI 代理用于实时学习、优化能源消耗和计算资源分配；以及识别支持无服务器计算的跨领域编排技术和基于光学的超高速、低延迟网络架构，后者通过快速光开关取代电子切换，可将功耗降低一个数量级。这些创新为垂直行业提供更可靠、智能的网络解决方案。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "6 Pages",
      "pdf_url": "http://arxiv.org/pdf/2502.01089v2",
      "published_date": "2025-02-03 06:18:29 UTC",
      "updated_date": "2025-04-15 15:24:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:32:49.653853"
    },
    {
      "arxiv_id": "2502.01083v1",
      "title": "Tool Unlearning for Tool-Augmented LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Jiali Cheng",
        "Hadi Amiri"
      ],
      "abstract": "Tool-augmented large language models (LLMs) are often trained on datasets of\nquery-response pairs, which embed the ability to use tools or APIs directly\ninto the parametric knowledge of LLMs. Tool-augmented LLMs need the ability to\nforget learned tools due to security vulnerabilities, privacy regulations, or\ntool deprecations. However, ``tool unlearning'' has not been investigated in\nunlearning literature. We introduce this novel task, which requires addressing\ndistinct challenges compared to traditional unlearning: knowledge removal\nrather than forgetting individual samples, the high cost of optimizing LLMs,\nand the need for principled evaluation metrics. To bridge these gaps, we\npropose ToolDelete, the first approach for unlearning tools from tool-augmented\nLLMs. It implements three key properties to address the above challenges for\neffective tool unlearning and introduces a new membership inference attack\n(MIA) model for effective evaluation. Extensive experiments on multiple tool\nlearning datasets and tool-augmented LLMs show that ToolDelete effectively\nunlearns randomly selected tools, while preserving the LLM's knowledge on\nnon-deleted tools and maintaining performance on general tasks.",
      "tldr_zh": "本论文引入“tool unlearning”任务，针对Tool-augmented LLMs，帮助模型忘记已学工具以应对安全漏洞、隐私法规或工具弃用问题，该任务不同于传统unlearning，因为它需移除整体知识而非单个样本，并面临优化成本高和评估指标不足的挑战。作者提出ToolDelete方法，该方法通过三个关键属性实现有效工具删除，并引入新的membership inference attack (MIA)模型进行评估。实验在多个tool learning数据集和模型上证明，ToolDelete能成功删除随机选定的工具，同时保留模型对非删除工具的知识和在一般任务上的性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "https://clu-uml.github.io/MU-Bench-Project-Page/",
      "pdf_url": "http://arxiv.org/pdf/2502.01083v1",
      "published_date": "2025-02-03 05:50:55 UTC",
      "updated_date": "2025-02-03 05:50:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:33:01.584766"
    },
    {
      "arxiv_id": "2502.01081v2",
      "title": "The Jumping Reasoning Curve? Tracking the Evolution of Reasoning Performance in GPT-[n] and o-[n] Models on Multimodal Puzzles",
      "title_zh": "翻译失败",
      "authors": [
        "Vernon Y. H. Toh",
        "Yew Ken Chia",
        "Deepanway Ghosal",
        "Soujanya Poria"
      ],
      "abstract": "The releases of OpenAI's o-[n] series, such as o1, o3, and o4-mini, mark a\nsignificant paradigm shift in Large Language Models towards advanced reasoning\ncapabilities. Notably, models like o3 have demonstrated strong performance on\nbenchmarks like the Abstraction and Reasoning Corpus for Artificial General\nIntelligence (ARC-AGI). However, this benchmark is limited to symbolic\npatterns, whereas humans often perceive and reason about multimodal scenarios\ninvolving both vision and language data. Thus, there is an urgent need to\ninvestigate advanced reasoning capabilities in multimodal tasks. To this end,\nwe track the evolution of the GPT-[n] and o-[n] series models (including o1,\no3, and o4-mini) on challenging multimodal puzzles from PuzzleVQA and\nAlgoPuzzleVQA, which demand fine-grained visual perception. Our results reveal\nthat o-[n] series, particularly later iterations like o3 and o4-mini,\nsignificantly outperform the GPT-[n] series and show strong scalability in\nmultimodal reasoning. Nonetheless, despite these substantial advancements and\nthe superior capabilities demonstrated by the o-[n] series, our findings\nhighlight that even these leading models face persistent challenges.\nDifficulties are particularly evident in tasks requiring precise visual\nperception, robust compositional reasoning across multiple visual attributes,\nand solving complex algorithmic or highly combinatorial puzzles, indicating\ncritical areas for future AGI development. We plan to continuously track new\nmodels in the series and update our results in this paper accordingly. All\nresources used in this evaluation are openly available at\nhttps://github.com/declare-lab/LLM-PuzzleTest.",
      "tldr_zh": "本研究跟踪了 GPT-[n] 和 o-[n] 系列模型（如 o1、o3 和 o4-mini）在多模态谜题上的推理性能演变，旨在评估这些模型在涉及视觉和语言的复杂任务中的能力。作者使用 PuzzleVQA 和 AlgoPuzzleVQA 等基准进行测试，结果显示 o-[n] 系列模型，尤其是 o3 和 o4-mini，在多模态推理上显著优于 GPT-[n] 系列，并表现出良好的可扩展性。尽管取得了这些进展，但模型在精确视觉感知、跨多属性组合推理以及复杂算法或组合谜题上仍面临挑战，突显了未来 AGI 发展的关键领域；作者计划持续跟踪新模型并更新结果。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01081v2",
      "published_date": "2025-02-03 05:47:04 UTC",
      "updated_date": "2025-05-21 07:57:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:34:31.516201"
    },
    {
      "arxiv_id": "2502.01060v1",
      "title": "Learning Nonlinearity of Boolean Functions: An Experimentation with Neural Networks",
      "title_zh": "布尔函数非线性性的学习：使用神经网络的实验",
      "authors": [
        "Sriram Ranga",
        "Nandish Chattopadhyay",
        "Anupam Chattopadhyay"
      ],
      "abstract": "This paper investigates the learnability of the nonlinearity property of\nBoolean functions using neural networks. We train encoder style deep neural\nnetworks to learn to predict the nonlinearity of Boolean functions from\nexamples of functions in the form of a truth table and their corresponding\nnonlinearity values. We report empirical results to show that deep neural\nnetworks are able to learn to predict the property for functions in 4 and 5\nvariables with an accuracy above 95%. While these results are positive and a\ndisciplined analysis is being presented for the first time in this regard, we\nshould also underline the statutory warning that it seems quite challenging to\nextend the idea to higher number of variables, and it is also not clear whether\none can get advantage in terms of time and space complexity over the existing\ncombinatorial algorithms.",
      "tldr_zh": "本论文探讨了使用神经网络学习布尔函数的nonlinearity属性，通过训练编码器风格的deep neural networks从truth table和对应的nonlinearity值中预测这一属性。研究者进行了实验，结果显示神经网络能准确预测4和5变量布尔函数的nonlinearity，准确率超过95%。尽管这是首次进行这种系统的分析，但扩展到更高变量数面临显著挑战，且在时间和空间复杂度上是否优于现有combinatorial algorithms尚不明确。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "To be published in International conference on Artificial\n  Intelligence and Sustainable Computing, AISC 2024",
      "pdf_url": "http://arxiv.org/pdf/2502.01060v1",
      "published_date": "2025-02-03 05:10:25 UTC",
      "updated_date": "2025-02-03 05:10:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:34:42.622148"
    },
    {
      "arxiv_id": "2502.01059v1",
      "title": "Knowledge Synthesis of Photosynthesis Research Using a Large Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Seungri Yoon",
        "Woosang Jeon",
        "Sanghyeok Choi",
        "Taehyeong Kim",
        "Tae In Ahn"
      ],
      "abstract": "The development of biological data analysis tools and large language models\n(LLMs) has opened up new possibilities for utilizing AI in plant science\nresearch, with the potential to contribute significantly to knowledge\nintegration and research gap identification. Nonetheless, current LLMs struggle\nto handle complex biological data and theoretical models in photosynthesis\nresearch and often fail to provide accurate scientific contexts. Therefore,\nthis study proposed a photosynthesis research assistant (PRAG) based on\nOpenAI's GPT-4o with retrieval-augmented generation (RAG) techniques and prompt\noptimization. Vector databases and an automated feedback loop were used in the\nprompt optimization process to enhance the accuracy and relevance of the\nresponses to photosynthesis-related queries. PRAG showed an average improvement\nof 8.7% across five metrics related to scientific writing, with a 25.4%\nincrease in source transparency. Additionally, its scientific depth and domain\ncoverage were comparable to those of photosynthesis research papers. A\nknowledge graph was used to structure PRAG's responses with papers within and\noutside the database, which allowed PRAG to match key entities with 63% and\n39.5% of the database and test papers, respectively. PRAG can be applied for\nphotosynthesis research and broader plant science domains, paving the way for\nmore in-depth data analysis and predictive capabilities.",
      "tldr_zh": "该研究提出了一种基于 OpenAI 的 GPT-4o 的光合作用研究助手（PRAG），利用检索增强生成（RAG）技术和提示优化来整合光合作用领域的知识，并解决大型语言模型（LLMs）在处理复杂生物数据时的局限性。方法包括使用向量数据库和自动反馈循环来提升响应的准确性和相关性，同时通过知识图谱结构化输出，以匹配关键实体。实验结果显示，PRAG 在五个科学写作指标上平均提高了 8.7%，源透明度提升 25.4%，其科学深度和领域覆盖力可与现有光合作用研究论文媲美。总体而言，PRAG 为光合作用和更广泛的植物科学领域提供了更深入的数据分析和预测能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.01059v1",
      "published_date": "2025-02-03 05:10:19 UTC",
      "updated_date": "2025-02-03 05:10:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:35:07.962494"
    },
    {
      "arxiv_id": "2502.01057v3",
      "title": "FetDTIAlign: A Deep Learning Framework for Affine and Deformable Registration of Fetal Brain dMRI",
      "title_zh": "翻译失败",
      "authors": [
        "Bo Li",
        "Qi Zeng",
        "Simon K. Warfield",
        "Davood Karimi"
      ],
      "abstract": "Diffusion MRI (dMRI) provides unique insights into fetal brain microstructure\nin utero. Longitudinal and cross-sectional fetal dMRI studies can reveal\ncrucial neurodevelopmental changes but require precise spatial alignment across\nscans and subjects. This is challenging due to low data quality, rapid brain\ndevelopment, and limited anatomical landmarks. Existing registration methods,\ndesigned for high-quality adult data, struggle with these complexities. To\naddress this, we introduce FetDTIAlign, a deep learning approach for fetal\nbrain dMRI registration, enabling accurate affine and deformable alignment.\nFetDTIAlign features a dual-encoder architecture and iterative feature-based\ninference, reducing the impact of noise and low resolution. It optimizes\nnetwork configurations and domain-specific features at each registration stage,\nenhancing both robustness and accuracy. We validated FetDTIAlign on data from\n23 to 36 weeks gestation, covering 60 white matter tracts. It consistently\noutperformed two classical optimization-based methods and a deep learning\npipeline, achieving superior anatomical correspondence. Further validation on\nexternal data from the Developing Human Connectome Project confirmed its\ngeneralizability across acquisition protocols. Our results demonstrate the\nfeasibility of deep learning for fetal brain dMRI registration, providing a\nmore accurate and reliable alternative to classical techniques. By enabling\nprecise cross-subject and tract-specific analyses, FetDTIAlign supports new\ndiscoveries in early brain development.",
      "tldr_zh": "本文提出 FetDTIAlign，一种深度学习框架，用于胎儿脑 dMRI 的仿射和可变形配准，以解决低数据质量、快速脑发育和有限解剖标志的挑战。该框架采用双编码器架构和迭代特征-based 推理，优化网络配置和领域特定特征，从而提升配准的鲁棒性和准确性。在23-36周妊娠数据上验证，FetDTIAlign 优于传统优化方法和现有深度学习管道，并在外部 Developing Human Connectome Project 数据中显示出良好的泛化性，促进了早期脑发育研究的精确分析。",
      "categories": [
        "eess.IV",
        "cs.AI"
      ],
      "primary_category": "eess.IV",
      "comment": "Under review. NeuroImage, 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.01057v3",
      "published_date": "2025-02-03 05:10:00 UTC",
      "updated_date": "2025-02-24 17:55:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:35:07.072921"
    },
    {
      "arxiv_id": "2502.01048v1",
      "title": "Sparks of Explainability: Recent Advancements in Explaining Large Vision Models",
      "title_zh": "翻译失败",
      "authors": [
        "Thomas Fel"
      ],
      "abstract": "This thesis explores advanced approaches to improve explainability in\ncomputer vision by analyzing and modeling the features exploited by deep neural\nnetworks. Initially, it evaluates attribution methods, notably saliency maps,\nby introducing a metric based on algorithmic stability and an approach\nutilizing Sobol indices, which, through quasi-Monte Carlo sequences, allows a\nsignificant reduction in computation time. In addition, the EVA method offers a\nfirst formulation of attribution with formal guarantees via verified\nperturbation analysis.\n  Experimental results indicate that in complex scenarios these methods do not\nprovide sufficient understanding, particularly because they identify only\n\"where\" the model focuses without clarifying \"what\" it perceives. Two\nhypotheses are therefore examined: aligning models with human reasoning --\nthrough the introduction of a training routine that integrates the imitation of\nhuman explanations and optimization within the space of 1-Lipschitz functions\n-- and adopting a conceptual explainability approach.\n  The CRAFT method is proposed to automate the extraction of the concepts used\nby the model and to assess their importance, complemented by MACO, which\nenables their visualization. These works converge towards a unified framework,\nillustrated by an interactive demonstration applied to the 1000 ImageNet\nclasses in a ResNet model.",
      "tldr_zh": "本论文探讨了提升大型视觉模型解释性的先进方法，通过评估归因技术（如saliency maps）并引入基于算法稳定性的指标和Sobol indices方法，利用quasi-Monte Carlo序列显著减少计算时间，同时提出EVA方法，提供通过verified perturbation analysis的正式保证。论文发现现有方法仅识别模型关注“哪里”而非“什么”，因此考察了两种假设：通过模仿人类解释和优化1-Lipschitz functions空间来对齐模型与人类推理，以及采用概念解释性方法。最终，论文提出CRAFT方法用于自动化提取并评估模型概念的重要性，结合MACO方法实现概念可视化，并构建了一个统一框架，在ResNet模型上应用于ImageNet的1000类，并提供交互式演示。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Doctoral thesis",
      "pdf_url": "http://arxiv.org/pdf/2502.01048v1",
      "published_date": "2025-02-03 04:49:32 UTC",
      "updated_date": "2025-02-03 04:49:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:35:19.468735"
    },
    {
      "arxiv_id": "2502.01036v1",
      "title": "eagle: early approximated gradient based learning rate estimator",
      "title_zh": "翻译失败",
      "authors": [
        "Takumi Fujimoto",
        "Hiroaki Nishi"
      ],
      "abstract": "We propose EAGLE update rule, a novel optimization method that accelerates\nloss convergence during the early stages of training by leveraging both current\nand previous step parameter and gradient values. The update algorithm estimates\noptimal parameters by computing the changes in parameters and gradients between\nconsecutive training steps and leveraging the local curvature of the loss\nlandscape derived from these changes. However, this update rule has potential\ninstability, and to address that, we introduce an adaptive switching mechanism\nthat dynamically selects between Adam and EAGLE update rules to enhance\ntraining stability. Experiments on standard benchmark datasets demonstrate that\nEAGLE optimizer, which combines this novel update rule with the switching\nmechanism achieves rapid training loss convergence with fewer epochs, compared\nto conventional optimization methods.",
      "tldr_zh": "本论文提出了一种名为 EAGLE 的新型优化方法，通过利用当前和前一步的参数及梯度值，计算参数和梯度变化来估计损失景观的局部曲率，从而加速训练早期的损失收敛。EAGLE 引入自适应切换机制，在 Adam 和 EAGLE 更新规则之间动态选择，以解决潜在的不稳定性问题。实验在标准基准数据集上表明，EAGLE 优化器比传统方法更快地实现损失收敛，需要更少的训练周期。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "43pages, 24figures",
      "pdf_url": "http://arxiv.org/pdf/2502.01036v1",
      "published_date": "2025-02-03 04:15:34 UTC",
      "updated_date": "2025-02-03 04:15:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:35:30.150911"
    },
    {
      "arxiv_id": "2502.01029v1",
      "title": "Comprehensive Modeling Approaches for Forecasting Bitcoin Transaction Fees: A Comparative Study",
      "title_zh": "比特币交易费用预测的全面建模方法：比较研究",
      "authors": [
        "Jiangqin Ma",
        "Erfan Mahmoudinia"
      ],
      "abstract": "Transaction fee prediction in Bitcoin's ecosystem represents a crucial\nchallenge affecting both user costs and miner revenue optimization. This study\npresents a systematic evaluation of six predictive models for forecasting\nBitcoin transaction fees across a 24-hour horizon (144 blocks): SARIMAX,\nProphet, Time2Vec, Time2Vec with Attention, a Hybrid model combining SARIMAX\nwith Gradient Boosting, and the Temporal Fusion Transformer (TFT). Our approach\nintegrates comprehensive feature engineering spanning mempool metrics, network\nparameters, and historical fee patterns to capture the multifaceted dynamics of\nfee behavior.\n  Through rigorous 5-fold cross-validation and independent testing, our\nanalysis reveals that traditional statistical approaches outperform more\ncomplex deep learning architectures. The SARIMAX model achieves superior\naccuracy on the independent test set, while Prophet demonstrates strong\nperformance during cross-validation. Notably, sophisticated deep learning\nmodels like Time2Vec and TFT show comparatively lower predictive power despite\ntheir architectural complexity. This performance disparity likely stems from\nthe relatively constrained training dataset of 91 days, suggesting that deep\nlearning models may achieve enhanced results with extended historical data.\n  These findings offer significant practical implications for cryptocurrency\nstakeholders, providing empirically-validated guidance for fee-sensitive\ndecision making while illuminating critical considerations in model selection\nbased on data constraints. The study establishes a foundation for advanced fee\nprediction while highlighting the current advantages of traditional statistical\nmethods in this domain.",
      "tldr_zh": "这篇论文比较了六种模型（包括SARIMAX、Prophet、Time2Vec、Time2Vec with Attention、Hybrid model和Temporal Fusion Transformer）在预测比特币交易费用的表现，焦点是24小时（144 blocks）内的费用预测，并整合了mempool metrics、network parameters和historical fee patterns等特征工程。研究通过5-fold cross-validation和独立测试发现，传统统计模型如SARIMAX在独立测试中表现出色，而深度学习模型如Time2Vec和TFT尽管架构复杂，却预测准确率较低，可能由于训练数据集仅限于91天。总体而言，该研究为比特币用户和矿工提供实证指导，帮助优化费用决策，并强调在数据约束下传统方法的实用优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01029v1",
      "published_date": "2025-02-03 03:52:07 UTC",
      "updated_date": "2025-02-03 03:52:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:35:43.358180"
    },
    {
      "arxiv_id": "2502.01014v1",
      "title": "Refining Adaptive Zeroth-Order Optimization at Ease",
      "title_zh": "翻译失败",
      "authors": [
        "Yao Shu",
        "Qixin Zhang",
        "Kun He",
        "Zhongxiang Dai"
      ],
      "abstract": "Recently, zeroth-order (ZO) optimization plays an essential role in scenarios\nwhere gradient information is inaccessible or unaffordable, such as black-box\nsystems and resource-constrained environments. While existing adaptive methods\nsuch as ZO-AdaMM have shown promise, they are fundamentally limited by their\nunderutilization of moment information during optimization, usually resulting\nin underperforming convergence. To overcome these limitations, this paper\nintroduces Refined Adaptive Zeroth-Order Optimization (R-AdaZO). Specifically,\nwe first show the untapped variance reduction effect of first moment estimate\non ZO gradient estimation, which improves the accuracy and stability of ZO\nupdates. We then refine the second moment estimate based on these\nvariance-reduced gradient estimates to better capture the geometry of the\noptimization landscape, enabling a more effective scaling of ZO updates. We\npresent rigorous theoretical analysis to show (I) the first analysis to the\nvariance reduction of first moment estimate in ZO optimization, (II) the\nimproved second moment estimates with a more accurate approximation of its\nvariance-free ideal, (III) the first variance-aware convergence framework for\nadaptive ZO methods, which may be of independent interest, and (IV) the faster\nconvergence of R-AdaZO than existing baselines like ZO-AdaMM. Our extensive\nexperiments, including synthetic problems, black-box adversarial attack, and\nmemory-efficient fine-tuning of large language models (LLMs), further verify\nthe superior convergence of R-AdaZO, indicating that R-AdaZO offers an improved\nsolution for real-world ZO optimization challenges.",
      "tldr_zh": "这篇论文提出了 R-AdaZO（Refined Adaptive Zeroth-Order Optimization），一种改进的自适应 zeroth-order (ZO) 优化方法，针对无法获取梯度信息的场景（如黑箱系统和资源受限环境）中的收敛问题，解决了现有方法如 ZO-AdaMM 未充分利用 moment 信息导致的性能不足。R-AdaZO 通过利用第一 moment 估计的方差减小效果来提升 ZO 梯度估计的准确性和稳定性，并进一步改进第二 moment 估计以更好地捕捉优化景观的几何形状，从而实现更有效的更新。理论分析首次提供了第一 moment 估计的方差减小分析、改进的第二 moment 估计以及一个适应性 ZO 方法的方差感知收敛框架，并证明 R-AdaZO 比基线方法收敛更快；实验在合成问题、黑箱对抗攻击和大型语言模型的内存高效微调中验证了其优越性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01014v1",
      "published_date": "2025-02-03 03:10:44 UTC",
      "updated_date": "2025-02-03 03:10:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:35:55.385639"
    },
    {
      "arxiv_id": "2502.01013v1",
      "title": "Encrypted Large Model Inference: The Equivariant Encryption Paradigm",
      "title_zh": "加密大型模型推理：等变加密范式",
      "authors": [
        "James Buban",
        "Hongyang Zhang",
        "Claudio Angione",
        "Harry Yang",
        "Ahmad Farhan",
        "Seyfal Sultanov",
        "Michael Du",
        "Xuran Ma",
        "Zihao Wang",
        "Yue Zhao",
        "Arria Owlia",
        "Fielding Johnston",
        "Patrick Colangelo"
      ],
      "abstract": "Large scale deep learning model, such as modern language models and diffusion\narchitectures, have revolutionized applications ranging from natural language\nprocessing to computer vision. However, their deployment in distributed or\ndecentralized environments raises significant privacy concerns, as sensitive\ndata may be exposed during inference. Traditional techniques like secure\nmulti-party computation, homomorphic encryption, and differential privacy offer\npartial remedies but often incur substantial computational overhead, latency\npenalties, or limited compatibility with non-linear network operations. In this\nwork, we introduce Equivariant Encryption (EE), a novel paradigm designed to\nenable secure, \"blind\" inference on encrypted data with near zero performance\noverhead. Unlike fully homomorphic approaches that encrypt the entire\ncomputational graph, EE selectively obfuscates critical internal\nrepresentations within neural network layers while preserving the exact\nfunctionality of both linear and a prescribed set of non-linear operations.\nThis targeted encryption ensures that raw inputs, intermediate activations, and\noutputs remain confidential, even when processed on untrusted infrastructure.\nWe detail the theoretical foundations of EE, compare its performance and\nintegration complexity against conventional privacy preserving techniques, and\ndemonstrate its applicability across a range of architectures, from\nconvolutional networks to large language models. Furthermore, our work provides\na comprehensive threat analysis, outlining potential attack vectors and\nbaseline strategies, and benchmarks EE against standard inference pipelines in\ndecentralized settings. The results confirm that EE maintains high fidelity and\nthroughput, effectively bridging the gap between robust data confidentiality\nand the stringent efficiency requirements of modern, large scale model\ninference.",
      "tldr_zh": "本文提出 Equivariant Encryption (EE) 范式，用于解决大型深度学习模型在分布式环境中的隐私问题，实现加密数据的“盲”推理，同时几乎没有性能开销。不同于传统方法如 homomorphic encryption 和 secure multi-party computation，EE 选择性地模糊神经网络层的关键内部表示，保留线性操作和特定非线性操作的功能，从而确保原始输入、中间激活和输出在不受信任基础设施上保持保密。实验结果显示，EE 在卷积网络和大型语言模型等架构中表现出高保真度和吞吐量，并在威胁分析中证明了其在数据保密性和效率方面的显著优势。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01013v1",
      "published_date": "2025-02-03 03:05:20 UTC",
      "updated_date": "2025-02-03 03:05:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:36:07.010953"
    },
    {
      "arxiv_id": "2502.00997v3",
      "title": "MergeME: Model Merging Techniques for Homogeneous and Heterogeneous MoEs",
      "title_zh": "MergeME：针对同质和异质 MoEs 的模型合并技术",
      "authors": [
        "Yuhang Zhou",
        "Giannis Karamanolakis",
        "Victor Soto",
        "Anna Rumshisky",
        "Mayank Kulkarni",
        "Furong Huang",
        "Wei Ai",
        "Jianhua Lu"
      ],
      "abstract": "The recent success of specialized Large Language Models (LLMs) in domains\nsuch as mathematical reasoning and coding has led to growing interest in\nmethods for merging these expert LLMs into a unified Mixture-of-Experts (MoE)\nmodel, with the goal of enhancing performance in each domain while retaining\neffectiveness on general tasks. However, the effective merging of expert models\nremains an open challenge, especially for models with highly divergent weight\nparameters or different architectures. State-of-the-art MoE merging methods\nonly work with homogeneous model architectures and rely on simple unweighted\naveraging to merge expert layers, which does not address parameter interference\nand requires extensive fine-tuning of the merged MoE to restore performance. To\naddress these limitations, this paper introduces new MoE merging techniques,\nincluding strategies to mitigate parameter interference, routing heuristics to\nreduce the need for MoE fine-tuning, and a novel method for merging experts\nwith different architectures. Extensive experiments across multiple domains\ndemonstrate the effectiveness of our proposed methods, reducing fine-tuning\ncosts, improving performance over state-of-the-art methods, and expanding the\napplicability of MoE merging.",
      "tldr_zh": "该研究提出 MergeME 技术，用于合并同质和异质的 Mixture-of-Experts (MoE) 模型，旨在将专业化 Large Language Models (LLMs) 整合成一个统一框架，提升特定领域（如数学推理和编码）的性能，同时保留一般任务的有效性。新的方法包括缓解参数干扰的策略、减少 MoE 微调需求的路由启发式，以及一种创新的异构专家合并方法，以解决现有方法的局限性。实验结果显示，这些技术显著降低了微调成本，超过了最先进方法的性能，并扩展了 MoE 合并的适用范围。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by NAACL 2025 Main",
      "pdf_url": "http://arxiv.org/pdf/2502.00997v3",
      "published_date": "2025-02-03 02:34:46 UTC",
      "updated_date": "2025-02-17 16:51:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:36:18.501453"
    },
    {
      "arxiv_id": "2502.17447v1",
      "title": "AirTag, You're It: Reverse Logistics and Last Mile Dynamics",
      "title_zh": "翻译失败",
      "authors": [
        "David Noever",
        "Forrest McKee"
      ],
      "abstract": "This study addresses challenges in reverse logistics, a frequently overlooked\nbut essential component of last-mile delivery, particularly in disaster relief\nscenarios where infrastructure disruptions demand adaptive solutions. While\nhub-and-spoke logistics networks excel at long-distance scalability, they often\nfail to optimize closely spaced spokes reliant on distant hubs, introducing\ninefficiencies in transit times and resource allocation. Using 20 Apple AirTags\nembedded in packages, this research provides empirical insights into logistical\nflows, capturing granular spatial and temporal data through Bluetooth LE (BLE)\n5 trackers integrated with the Apple Find My network. These trackers\ndemonstrated their value in monitoring dynamic cargo movements, enabling\nreal-time adjustments in mobile hub placement and route optimization,\nparticularly in disaster relief contexts like Hurricane Helene. A novel\napplication of discrete event simulation (DES) further explored the saddle\npoint in hub-spoke configurations, where excessive hub reliance clashes with\ndiminishing spoke interaction demand. By coupling simulation results with\nempirical AirTag tracking, the study highlights the potential of BLE technology\nto refine reverse logistics, reduce delays, and improve operational flexibility\nin both routine and crisis-driven delivery networks.",
      "tldr_zh": "这篇论文探讨了逆向物流（reverse logistics）在最后一英里交付中的挑战，特别是灾难救援场景下基础设施中断带来的效率问题，如 hub-and-spoke 网络在处理紧密相连的 spokes 和远距离 hubs 时存在的延误和资源浪费。研究者使用 20 个 Apple AirTags 嵌入包裹，并结合 Bluetooth LE (BLE) 5 追踪器和 Apple Find My 网络，收集了详细的空间和时间数据，实现对货物动态的实时监控和路线优化，尤其在 Hurricane Helene 等事件中。论文还引入离散事件模拟 (DES) 来分析 hub-spoke 配置的 saddle point，揭示了 BLE 技术如何减少延迟、提升操作灵活性，并为常规和危机驱动的交付网络提供实证改进建议。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.17447v1",
      "published_date": "2025-02-03 02:21:23 UTC",
      "updated_date": "2025-02-03 02:21:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:36:31.751045"
    },
    {
      "arxiv_id": "2502.00989v1",
      "title": "ChartCitor: Multi-Agent Framework for Fine-Grained Chart Visual Attribution",
      "title_zh": "ChartCitor：用于细粒度图表视觉归因",
      "authors": [
        "Kanika Goswami",
        "Puneet Mathur",
        "Ryan Rossi",
        "Franck Dernoncourt"
      ],
      "abstract": "Large Language Models (LLMs) can perform chart question-answering tasks but\noften generate unverified hallucinated responses. Existing answer attribution\nmethods struggle to ground responses in source charts due to limited\nvisual-semantic context, complex visual-text alignment requirements, and\ndifficulties in bounding box prediction across complex layouts. We present\nChartCitor, a multi-agent framework that provides fine-grained bounding box\ncitations by identifying supporting evidence within chart images. The system\norchestrates LLM agents to perform chart-to-table extraction, answer\nreformulation, table augmentation, evidence retrieval through pre-filtering and\nre-ranking, and table-to-chart mapping. ChartCitor outperforms existing\nbaselines across different chart types. Qualitative user studies show that\nChartCitor helps increase user trust in Generative AI by providing enhanced\nexplainability for LLM-assisted chart QA and enables professionals to be more\nproductive.",
      "tldr_zh": "论文提出 ChartCitor，一种多智能体框架，用于实现细粒度的图表视觉归因，旨在解决 Large Language Models (LLMs) 在图表问答任务中生成未验证幻觉响应的难题。框架通过协调 LLM 智能体执行图表到表格提取、答案重述、表格增强、证据检索（包括预过滤和重新排名）以及表格到图表映射，提供精确的边界框引用以识别支持证据。实验结果显示，ChartCitor 在不同图表类型上超越现有基准，并通过增强可解释性，提高了用户对生成式 AI 的信任，并提升了专业人士的生产力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00989v1",
      "published_date": "2025-02-03 02:00:51 UTC",
      "updated_date": "2025-02-03 02:00:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:36:43.284775"
    },
    {
      "arxiv_id": "2502.00988v1",
      "title": "PlotGen: Multi-Agent LLM-based Scientific Data Visualization via Multimodal Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Kanika Goswami",
        "Puneet Mathur",
        "Ryan Rossi",
        "Franck Dernoncourt"
      ],
      "abstract": "Scientific data visualization is pivotal for transforming raw data into\ncomprehensible visual representations, enabling pattern recognition,\nforecasting, and the presentation of data-driven insights. However, novice\nusers often face difficulties due to the complexity of selecting appropriate\ntools and mastering visualization techniques. Large Language Models (LLMs) have\nrecently demonstrated potential in assisting code generation, though they\nstruggle with accuracy and require iterative debugging. In this paper, we\npropose PlotGen, a novel multi-agent framework aimed at automating the creation\nof precise scientific visualizations. PlotGen orchestrates multiple LLM-based\nagents, including a Query Planning Agent that breaks down complex user requests\ninto executable steps, a Code Generation Agent that converts pseudocode into\nexecutable Python code, and three retrieval feedback agents - a Numeric\nFeedback Agent, a Lexical Feedback Agent, and a Visual Feedback Agent - that\nleverage multimodal LLMs to iteratively refine the data accuracy, textual\nlabels, and visual correctness of generated plots via self-reflection.\nExtensive experiments show that PlotGen outperforms strong baselines, achieving\na 4-6 percent improvement on the MatPlotBench dataset, leading to enhanced user\ntrust in LLM-generated visualizations and improved novice productivity due to a\nreduction in debugging time needed for plot errors.",
      "tldr_zh": "本文提出PlotGen，一种基于多智能体LLM框架，通过多模态反馈（如Numeric Feedback Agent、Lexical Feedback Agent和Visual Feedback Agent）自动化科学数据可视化，帮助新手用户克服工具复杂性和可视化技术难题。框架包括Query Planning Agent分解用户请求、Code Generation Agent生成可执行Python代码，以及反馈代理通过自反省迭代优化数据准确性、文本标签和视觉正确性。实验结果显示，PlotGen在MatPlotBench数据集上比强基线提高了4-6%的性能，提升了用户信任并显著减少了调试时间，从而提高新手生产力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00988v1",
      "published_date": "2025-02-03 02:00:29 UTC",
      "updated_date": "2025-02-03 02:00:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:36:55.273353"
    },
    {
      "arxiv_id": "2502.00987v2",
      "title": "RandLoRA: Full-rank parameter-efficient fine-tuning of large models",
      "title_zh": "RandLoRA：全秩参数高效微调大型模型",
      "authors": [
        "Paul Albert",
        "Frederic Z. Zhang",
        "Hemanth Saratchandran",
        "Cristian Rodriguez-Opazo",
        "Anton van den Hengel",
        "Ehsan Abbasnejad"
      ],
      "abstract": "Low-Rank Adaptation (LoRA) and its variants have shown impressive results in\nreducing the number of trainable parameters and memory requirements of large\ntransformer networks while maintaining fine-tuning performance. The low-rank\nnature of the weight update inherently limits the representation power of\nfine-tuned models, however, thus potentially compromising performance on\ncomplex tasks. This raises a critical question: when a performance gap between\nLoRA and standard fine-tuning is observed, is it due to the reduced number of\ntrainable parameters or the rank deficiency? This paper aims to answer this\nquestion by introducing RandLoRA, a parameter-efficient method that performs\nfull-rank updates using a learned linear combinations of low-rank,\nnon-trainable random matrices. Our method limits the number of trainable\nparameters by restricting optimization to diagonal scaling matrices applied to\nthe fixed random matrices. This allows us to effectively overcome the low-rank\nlimitations while maintaining parameter and memory efficiency during training.\nThrough extensive experimentation across vision, language, and vision-language\nbenchmarks, we systematically evaluate the limitations of LoRA and existing\nrandom basis methods. Our findings reveal that full-rank updates are beneficial\nacross vision and language tasks individually, and even more so for\nvision-language tasks, where RandLoRA significantly reduces -- and sometimes\neliminates -- the performance gap between standard fine-tuning and LoRA,\ndemonstrating its efficacy.",
      "tldr_zh": "这篇论文针对Low-Rank Adaptation (LoRA)方法的低秩限制提出RandLoRA，一种参数高效的微调技术，通过学习对角缩放矩阵应用于固定随机矩阵，实现全秩更新，同时减少可训练参数和内存需求。RandLoRA解决了LoRA在复杂任务中的性能不足问题，尤其在视觉和语言任务上表现出色。实验结果显示，在视觉-语言基准上，RandLoRA显著缩小了与标准微调的性能差距，甚至在某些情况下完全消除。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CL",
      "comment": "To appear at the International Conference on Learning Representations\n  (ICLR) 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.00987v2",
      "published_date": "2025-02-03 01:59:45 UTC",
      "updated_date": "2025-03-12 00:43:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:37:06.993961"
    },
    {
      "arxiv_id": "2502.02610v1",
      "title": "Secure & Personalized Music-to-Video Generation via CHARCHA",
      "title_zh": "翻译失败",
      "authors": [
        "Mehul Agarwal",
        "Gauri Agarwal",
        "Santiago Benoit",
        "Andrew Lippman",
        "Jean Oh"
      ],
      "abstract": "Music is a deeply personal experience and our aim is to enhance this with a\nfully-automated pipeline for personalized music video generation. Our work\nallows listeners to not just be consumers but co-creators in the music video\ngeneration process by creating personalized, consistent and context-driven\nvisuals based on lyrics, rhythm and emotion in the music. The pipeline combines\nmultimodal translation and generation techniques and utilizes low-rank\nadaptation on listeners' images to create immersive music videos that reflect\nboth the music and the individual. To ensure the ethical use of users'\nidentity, we also introduce CHARCHA (patent pending), a facial identity\nverification protocol that protects people against unauthorized use of their\nface while at the same time collecting authorized images from users for\npersonalizing their videos. This paper thus provides a secure and innovative\nframework for creating deeply personalized music videos.",
      "tldr_zh": "这篇论文提出了一种安全的个性化音乐视频生成管道，允许用户基于音乐的歌词、节奏和情感成为视频的共同创建者，使用多模态翻译和生成技术结合 low-rank adaptation 处理用户的图像，以生成一致且沉浸式的视觉效果。论文引入了 CHARCHA（专利待批）协议，这是一种面部身份验证机制，确保用户面部的授权使用并防止未经授权的滥用，从而提升了隐私保护。总体而言，该框架提供了一个创新、安全的解决方案，使音乐视频生成过程更具互动性和个性化。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.HC",
        "cs.MM"
      ],
      "primary_category": "cs.AI",
      "comment": "NeurIPS 2024 Creative AI Track",
      "pdf_url": "http://arxiv.org/pdf/2502.02610v1",
      "published_date": "2025-02-03 01:25:47 UTC",
      "updated_date": "2025-02-03 01:25:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:37:18.711225"
    },
    {
      "arxiv_id": "2502.00980v1",
      "title": "Forecasting VIX using interpretable Kolmogorov-Arnold networks",
      "title_zh": "翻译失败",
      "authors": [
        "So-Yoon Cho",
        "Sungchul Lee",
        "Hyun-Gyoon Kim"
      ],
      "abstract": "This paper presents the use of Kolmogorov-Arnold Networks (KANs) for\nforecasting the CBOE Volatility Index (VIX). Unlike traditional MLP-based\nneural networks that are often criticized for their black-box nature, KAN\noffers an interpretable approach via learnable spline-based activation\nfunctions and symbolification. Based on a parsimonious architecture with\nsymbolic functions, KAN expresses a forecast of the VIX as a closed-form in\nterms of explanatory variables, and provide interpretable insights into key\ncharacteristics of the VIX, including mean reversion and the leverage effect.\nThrough in-depth empirical analysis across multiple datasets and periods, we\nshow that KANs achieve competitive forecasting performance while requiring\nsignificantly fewer parameters compared to MLP-based neural network models. Our\nfindings demonstrate the capacity and potential of KAN as an interpretable\nfinancial time-series forecasting method.",
      "tldr_zh": "本论文使用 Kolmogorov-Arnold Networks (KANs) 来预测 CBOE Volatility Index (VIX)，通过可学习的样条激活函数和符号化提供可解释性，克服了传统 MLP-based 神经网络的黑箱问题。KANs 的简洁架构以符号函数形式表达 VIX 预测，并揭示其关键特征，如均值回归和杠杆效应。实证分析显示，KANs 在多个数据集和时期实现了与 MLP 模型相当的预测性能，但所需参数显著更少，展示了其作为可解释金融时间序列预测方法的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00980v1",
      "published_date": "2025-02-03 01:24:02 UTC",
      "updated_date": "2025-02-03 01:24:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:37:31.314583"
    },
    {
      "arxiv_id": "2502.01697v3",
      "title": "BARE: Leveraging Base Language Models for Few-Shot Synthetic Data Generation",
      "title_zh": "BARE：利用基础语言模型进行少样本合成数据生成",
      "authors": [
        "Alan Zhu",
        "Parth Asawa",
        "Jared Quincy Davis",
        "Lingjiao Chen",
        "Boris Hanin",
        "Ion Stoica",
        "Joseph E. Gonzalez",
        "Matei Zaharia"
      ],
      "abstract": "As the demand for high-quality data in model training grows, researchers and\ndevelopers are increasingly generating synthetic data to tune and train LLMs.\nHowever, current data generation methods rely on seed sets containing tens of\nthousands of examples to prompt instruction-tuned models. This reliance can be\nespecially problematic when the curation of high-quality examples is expensive\nor difficult. In this paper we explore the novel few-shot synthetic data\ngeneration setting -- generating a high-quality dataset from a few examples. We\nshow that when working with only a few seed examples, instruction-tuned models\nused in current synthetic data methods produce insufficient diversity for\ndownstream tasks. In contrast, we show that base models without post-training,\nlargely untapped for synthetic data generation, offer substantially greater\noutput diversity, albeit with lower instruction following abilities. Leveraging\nthis insight, we propose Base-Refine (BARE), a novel two-stage method that\ncombines the diversity of base models with the quality assurance of\ninstruction-tuned models. BARE excels in few-shot synthetic data generation:\nusing only 3 seed examples it generates diverse, high-quality datasets that\nsignificantly improve downstream task performance. We show that fine-tuning\nLlama 3.1 8B with 1,000 BARE-generated samples achieves performance comparable\nto state-of-the-art similarly sized models on LiveCodeBench tasks. Furthermore,\ndata generated with BARE enables a 101% improvement for a fine-tuned Llama 3.2\n1B on GSM8K over data generated by only instruction-models, and an 18.4%\nimprovement for a fine-tuned Llama 3.1 8B over the state-of-the-art RAFT method\nfor RAG data generation.",
      "tldr_zh": "该研究探讨了少样本(few-shot)合成数据生成问题，提出BARE方法，该方法利用基础模型(base models)的输出多样性与指令微调模型(instruction-tuned models)的质量保障，通过两阶段过程从仅3个种子示例生成高质量、多样化的数据集。相比传统方法，BARE显著提升了下游任务性能，例如用1000个BARE生成的样本微调Llama 3.1 8B后，在LiveCodeBench任务上达到与最先进模型相当的水平。在GSM8K任务上，微调Llama 3.2 1B模型的性能比仅用instruction-tuned models生成的数据提高了101%，并在RAG数据生成上比RAFT方法提高了18.4%。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.01697v3",
      "published_date": "2025-02-03 00:12:40 UTC",
      "updated_date": "2025-05-21 17:50:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:37:44.333770"
    },
    {
      "arxiv_id": "2502.14874v2",
      "title": "Is Mathematics Obsolete?",
      "title_zh": "数学是否过时？",
      "authors": [
        "Jeremy Avigad"
      ],
      "abstract": "This is an essay about the value of mathematical and symbolic reasoning in\nthe age of AI.",
      "tldr_zh": "本文探讨了在AI时代，数学和符号推理(mathematical and symbolic reasoning)的价值，质疑数学是否已过时。作为一篇散文，论文可能通过论证和分析强调这些推理方式的持续重要性，为AI发展提供批判性视角。最终，它旨在强化数学在应对AI挑战中的核心作用。",
      "categories": [
        "math.HO",
        "cs.AI"
      ],
      "primary_category": "math.HO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14874v2",
      "published_date": "2025-02-03 00:10:44 UTC",
      "updated_date": "2025-02-27 02:23:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:37:53.865194"
    },
    {
      "arxiv_id": "2502.00964v3",
      "title": "ML-Dev-Bench: Comparative Analysis of AI Agents on ML development workflows",
      "title_zh": "翻译失败",
      "authors": [
        "Harshith Padigela",
        "Chintan Shah",
        "Dinkar Juyal"
      ],
      "abstract": "In this report, we present ML-Dev-Bench, a benchmark aimed at testing agentic\ncapabilities on applied Machine Learning development tasks. While existing\nbenchmarks focus on isolated coding tasks or Kaggle-style competitions,\nML-Dev-Bench tests agents' ability to handle the full complexity of ML\ndevelopment workflows. The benchmark assesses performance across critical\naspects including dataset handling, model training, improving existing models,\ndebugging, and API integration with popular ML tools. We evaluate three agents\n- ReAct, Openhands, and AIDE - on a diverse set of 30 tasks, providing insights\ninto their strengths and limitations in handling practical ML development\nchallenges. We open source the benchmark for the benefit of the community at\n\\href{https://github.com/ml-dev-bench/ml-dev-bench}{https://github.com/ml-dev-bench/ml-dev-bench}.",
      "tldr_zh": "这篇报告介绍了 ML-Dev-Bench，这是一个针对 AI Agents 在机器学习 (Machine Learning) 开发任务中的能力的基准测试。与现有基准不同，它评估代理处理完整的 ML 开发工作流，包括数据集处理、模型训练、改进现有模型、调试和 API 集成。我们评估了 ReAct、Openhands 和 AIDE 在 30 个多样化任务上的表现，揭示了它们的优势和局限性。该基准已开源，供社区使用，地址为 https://github.com/ml-dev-bench/ml-dev-bench。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00964v3",
      "published_date": "2025-02-03 00:04:49 UTC",
      "updated_date": "2025-02-19 05:09:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T06:38:06.808361"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 159,
  "processed_papers_count": 159,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-22T06:38:26.116267"
}