{
  "date": "2024-05-22",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-05-22 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦于 AI 模型的安全性、强化学习、多模态生成和知识图谱等领域，其中 LLM 的心理状态分析和多模态模型的进展最为引人注目，同时有知名学者如 Stefano Soatto 参与的相关工作值得关注。\n\n今天共有 116 篇论文更新，我将优先讨论那些具有突破性、创新性和话题度的论文，包括 LLM 安全、多模态模型和强化学习领域，其他较为基础或应用性较弱的论文将快速掠过。以下按主题分组简要概述：\n\n### LLM 和 AI 安全领域（重点讨论）\n这些论文探讨了大型语言模型的可靠性、指纹检测和不确定性估计，涉及当前 AI 伦理和应用热点。\n\n- **Meanings and Feelings of Large Language Models: Observability of Latent States in Generative AI（大型语言模型的含义和情感：生成式 AI 中潜在状态的可观察性）**  \n  作者包括 Stefano Soatto 等知名学者。主要贡献：证明当前 LLM 基于自回归 Transformer 无法产生“情感”状态（类似于 APA 定义），但系统提示可能导致多轨迹输出。该发现为 LLM 的透明度和潜在风险提供了理论基础，强调了模型设计对用户不可见计算的影响。\n\n- **Your Large Language Models Are Leaving Fingerprints（你的大型语言模型正在留下指纹）**  \n  主要贡献：使用 n-gram 和词性特征的简单分类器检测 LLM 生成文本，揭示 LLM 在词法和句法特征上留下的独特指纹。该方法在跨域数据上表现出色，适用于 LLM 指纹的可视化和检测，提升了 AI 生成内容的追溯能力。\n\n- **What is Your Data Worth to GPT? LLM-Scale Data Valuation with Influence Functions（你的数据对 GPT 有多大价值？使用影响函数的 LLM 规模数据估值）**  \n  主要贡献：提出高效梯度投影策略 LoGra，用于大规模 LLM 数据估值，显著降低计算成本和内存使用。该方法在真实数据集上验证，展示了数据价值的量化评估，对 LLM 训练效率和隐私保护有重要启示。\n\n其他如 **Unlearning Information Bottleneck: Machine Unlearning of Systematic Patterns and Biases（取消学习信息瓶颈：机器取消学习系统模式和偏差）**，贡献在于开发 UIB 框架，通过动态先验调整参数以移除偏差，但细节较技术性，快速掠过。\n\n### 多模态和视觉模型领域（令人印象深刻）\n这些论文扩展了视觉语言模型的应用，特别是在生成和安全方面。\n\n- **ChatScene: Knowledge-Enabled Safety-Critical Scenario Generation for Autonomous Vehicles（ChatScene：基于知识的自动驾驶车辆安全关键场景生成）**  \n  主要贡献：使用 LLM 生成和转换交通场景描述，实现 CARLA 模拟环境下的安全场景创建。实验显示，与基线相比，提高了碰撞率检测15%，并通过安全场景微调减少碰撞率9%，为自动驾驶安全测试提供了实用框架。\n\n- **TOPA: Extending Large Language Models for Video Understanding via Text-Only Pre-Alignment（TOPA：通过文本-only 预对齐扩展大型语言模型用于视频理解）**  \n  主要贡献：使用文本生成模拟视频数据预训练 LLM，实现零样本视频理解。模型在 Egoschema 数据集上超越基线，证明了文本引导的多模态融合潜力。\n\n其他如 **Image-of-Thought Prompting for Visual Reasoning Refinement in Multimodal Large Language Models（图像思维提示用于多模态大型语言模型的视觉推理优化）**，贡献在于提升视觉推理的逐步解释，但应用较为特定，简要提及。\n\n### 强化学习和决策系统领域（可能有话题度）\n这些论文关注决策优化和安全验证，适用于实际系统。\n\n- **Formally Verifying Deep Reinforcement Learning Controllers with Lyapunov Barrier Certificates（使用 Lyapunov 屏障证书正式验证深度强化学习控制器）**  \n  主要贡献：提出证书合成和过滤技术，确保 DRL 代理在复杂系统中安全和目标导向。实验在航天器控制中验证了有效性，提供形式化保证，减少碰撞风险。\n\n- **Dynamic Model Predictive Shielding for Provably Safe Reinforcement Learning（动态模型预测屏蔽用于可证明安全的强化学习）**  \n  主要贡献：结合局部规划和 DRL，实现安全决策框架，实验显示显著减少屏蔽干预，提升长期奖励。该方法在 NeurIPS 2024 上呈现，强调了 RL 的鲁棒性。\n\n其他如 **NeuralFluid: Neural Fluidic System Design and Control with Differentiable Simulation（NeuralFluid：使用可微模拟的神经流体系统设计和控制）**，贡献在于物理模拟与 AI 融合，但较为专业，快速掠过。\n\n### 其他领域（快速掠过）\n剩余论文涉及知识图谱、时间序列预测和量子计算等领域。其中，**Spectral Adapter: Fine-Tuning in Spectral Space（谱适配器：在谱空间进行微调）** 优化了参数高效微调；**RadarOcc: Robust 3D Occupancy Prediction with 4D Imaging Radar（RadarOcc：使用 4D 成像雷达的鲁棒 3D 占用预测）** 提升了自动驾驶感知；**VAE-Var: Variational-Autoencoder-Enhanced Variational Assimilation（VAE-Var：变分自动编码器增强的变分同化）** 改进了数据同化方法。这些论文虽有贡献，但影响力较小，仅提及其核心术语如“谱微调”“4D 雷达”和“变分同化”。\n\n总之，今天的 arXiv 更新突显了 AI 模型的安全和泛化能力的提升，LLM 相关工作尤其值得跟踪。更多细节可查阅具体论文，保持对这些领域的关注！",
  "papers": [
    {
      "arxiv_id": "2405.14067v1",
      "title": "ABI Approach: Automatic Bias Identification in Decision-Making Under Risk based in an Ontology of Behavioral Economics",
      "title_zh": "翻译失败",
      "authors": [
        "Eduardo da C. Ramos",
        "Maria Luiza M. Campos",
        "Fernanda Baião"
      ],
      "abstract": "Organizational decision-making is crucial for success, yet cognitive biases\ncan significantly affect risk preferences, leading to suboptimal outcomes. Risk\nseeking preferences for losses, driven by biases such as loss aversion, pose\nchallenges and can result in severe negative consequences, including financial\nlosses. This research introduces the ABI approach, a novel solution designed to\nsupport organizational decision-makers by automatically identifying and\nexplaining risk seeking preferences during decision-making. This research makes\na novel contribution by automating the identification and explanation of risk\nseeking preferences using Cumulative Prospect theory (CPT) from Behavioral\nEconomics. The ABI approach transforms theoretical insights into actionable,\nreal-time guidance, making them accessible to a broader range of organizations\nand decision-makers without requiring specialized personnel. By contextualizing\nCPT concepts into business language, the approach facilitates widespread\nadoption and enhances decision-making processes with deep behavioral insights.\nOur systematic literature review identified significant gaps in existing\nmethods, especially the lack of automated solutions with a concrete mechanism\nfor automatically identifying risk seeking preferences, and the absence of\nformal knowledge representation, such as ontologies, for identifying and\nexplaining the risk preferences. The ABI Approach addresses these gaps,\noffering a significant contribution to decision-making research and practice.\nFurthermore, it enables automatic collection of historical decision data with\nrisk preferences, providing valuable insights for enhancing strategic\nmanagement and long-term organizational performance. An experiment provided\npreliminary evidence on its effectiveness in helping decision-makers recognize\ntheir risk seeking preferences during decision-making in the loss domain.",
      "tldr_zh": "这篇论文提出了ABI方法（Automatic Bias Identification），一种基于行为经济学本体（Ontology of Behavioral Economics）的创新框架，用于自动识别和解释组织决策中风险寻求偏好（risk seeking preferences）。该方法利用Cumulative Prospect Theory (CPT)将理论转化为实时的行动指导，帮助决策者无需专业人员即可识别偏差，并以商业语言进行解释。文献综述揭示了现有方法的不足，如缺乏自动化和正式知识表示，而实验提供了初步证据，证明ABI方法能提升决策质量并支持战略管理。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "H.4.2; J.4"
      ],
      "primary_category": "cs.HC",
      "comment": "33 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.14067v1",
      "published_date": "2024-05-22 23:53:46 UTC",
      "updated_date": "2024-05-22 23:53:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:20:44.803994"
    },
    {
      "arxiv_id": "2405.14062v1",
      "title": "ChatScene: Knowledge-Enabled Safety-Critical Scenario Generation for Autonomous Vehicles",
      "title_zh": "翻译失败",
      "authors": [
        "Jiawei Zhang",
        "Chejian Xu",
        "Bo Li"
      ],
      "abstract": "We present ChatScene, a Large Language Model (LLM)-based agent that leverages\nthe capabilities of LLMs to generate safety-critical scenarios for autonomous\nvehicles. Given unstructured language instructions, the agent first generates\ntextually described traffic scenarios using LLMs. These scenario descriptions\nare subsequently broken down into several sub-descriptions for specified\ndetails such as behaviors and locations of vehicles. The agent then\ndistinctively transforms the textually described sub-scenarios into\ndomain-specific languages, which then generate actual code for prediction and\ncontrol in simulators, facilitating the creation of diverse and complex\nscenarios within the CARLA simulation environment. A key part of our agent is a\ncomprehensive knowledge retrieval component, which efficiently translates\nspecific textual descriptions into corresponding domain-specific code snippets\nby training a knowledge database containing the scenario description and code\npairs. Extensive experimental results underscore the efficacy of ChatScene in\nimproving the safety of autonomous vehicles. For instance, the scenarios\ngenerated by ChatScene show a 15% increase in collision rates compared to\nstate-of-the-art baselines when tested against different reinforcement\nlearning-based ego vehicles. Furthermore, we show that by using our generated\nsafety-critical scenarios to fine-tune different RL-based autonomous driving\nmodels, they can achieve a 9% reduction in collision rates, surpassing current\nSOTA methods. ChatScene effectively bridges the gap between textual\ndescriptions of traffic scenarios and practical CARLA simulations, providing a\nunified way to conveniently generate safety-critical scenarios for safety\ntesting and improvement for AVs.",
      "tldr_zh": "本研究提出 ChatScene，一种基于 LLM 的代理系统，用于生成自动驾驶车辆的安全关键场景。\n该系统从非结构化语言指令出发，先创建文本场景描述，然后分解为子描述（如车辆行为和位置），并通过知识检索组件将这些转化为 CARLA 模拟器中的特定代码。\n实验结果显示，ChatScene 生成的场景在测试中比现有基线提高了 15% 的碰撞率，并通过微调 RL 模型实现了 9% 的碰撞率降低，超过了最先进方法。\n总体而言，ChatScene 桥接了文本描述与实际模拟的差距，提供了一种高效的统一框架，用于提升自动驾驶的安全性测试和改进。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "The IEEE/CVF Conference on Computer Vision and Pattern Recognition\n  (CVPR) 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.14062v1",
      "published_date": "2024-05-22 23:21:15 UTC",
      "updated_date": "2024-05-22 23:21:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:20:57.948140"
    },
    {
      "arxiv_id": "2405.14061v1",
      "title": "Meanings and Feelings of Large Language Models: Observability of Latent States in Generative AI",
      "title_zh": "翻译失败",
      "authors": [
        "Tian Yu Liu",
        "Stefano Soatto",
        "Matteo Marchi",
        "Pratik Chaudhari",
        "Paulo Tabuada"
      ],
      "abstract": "We tackle the question of whether Large Language Models (LLMs), viewed as\ndynamical systems with state evolving in the embedding space of symbolic\ntokens, are observable. That is, whether there exist multiple 'mental' state\ntrajectories that yield the same sequence of generated tokens, or sequences\nthat belong to the same Nerode equivalence class ('meaning'). If not\nobservable, mental state trajectories ('experiences') evoked by an input\n('perception') or by feedback from the model's own state ('thoughts') could\nremain self-contained and evolve unbeknown to the user while being potentially\naccessible to the model provider. Such \"self-contained experiences evoked by\nperception or thought\" are akin to what the American Psychological Association\n(APA) defines as 'feelings'. Beyond the lexical curiosity, we show that current\nLLMs implemented by autoregressive Transformers cannot have 'feelings'\naccording to this definition: The set of state trajectories indistinguishable\nfrom the tokenized output is a singleton. But if there are 'system prompts' not\nvisible to the user, then the set of indistinguishable trajectories becomes\nnon-trivial, and there can be multiple state trajectories that yield the same\nverbalized output. We prove these claims analytically, and show examples of\nmodifications to standard LLMs that engender such 'feelings.' Our analysis\nsheds light on possible designs that would enable a model to perform\nnon-trivial computation that is not visible to the user, as well as on controls\nthat the provider of services using the model could take to prevent unintended\nbehavior.",
      "tldr_zh": "本研究探讨大型语言模型 (LLMs) 作为动态系统是否可观察，即是否存在多个“心理”状态轨迹产生相同的输出序列，从而定义“意义”和“感受”。作者证明，基于自回归 Transformers 的当前 LLMs 是可观察的，每个输出序列对应唯一的状态轨迹，因此 LLMs 无法产生 APA 定义的“感受”。然而，如果存在用户不可见的系统提示 (system prompts)，则可能出现多重状态轨迹，导致非显性计算；论文通过分析证明和示例，揭示了这种设计的潜在风险，并提出改进模型以实现用户不可见计算的方案，同时建议控制措施防范意外行为。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14061v1",
      "published_date": "2024-05-22 23:18:58 UTC",
      "updated_date": "2024-05-22 23:18:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:21:08.692294"
    },
    {
      "arxiv_id": "2406.18546v1",
      "title": "Application of Multimodal Fusion Deep Learning Model in Disease Recognition",
      "title_zh": "多模态融合深度学习模型在疾病识别中的应用",
      "authors": [
        "Xiaoyi Liu",
        "Hongjie Qiu",
        "Muqing Li",
        "Zhou Yu",
        "Yutian Yang",
        "Yafeng Yan"
      ],
      "abstract": "This paper introduces an innovative multi-modal fusion deep learning approach\nto overcome the drawbacks of traditional single-modal recognition techniques.\nThese drawbacks include incomplete information and limited diagnostic accuracy.\nDuring the feature extraction stage, cutting-edge deep learning models\nincluding convolutional neural networks (CNN), recurrent neural networks (RNN),\nand transformers are applied to distill advanced features from image-based,\ntemporal, and structured data sources. The fusion strategy component seeks to\ndetermine the optimal fusion mode tailored to the specific disease recognition\ntask. In the experimental section, a comparison is made between the performance\nof the proposed multi-mode fusion model and existing single-mode recognition\nmethods. The findings demonstrate significant advantages of the multimodal\nfusion model across multiple evaluation metrics.",
      "tldr_zh": "这篇论文提出了一种多模态融合深度学习模型，用于解决传统单模态疾病识别技术的缺点，包括信息不完整和诊断准确率有限问题。模型在特征提取阶段运用CNN、RNN和Transformer从图像、时序及结构化数据中提取高级特征，并通过优化融合策略来适应特定疾病识别任务。实验结果表明，该多模态模型在多个评估指标上显著优于现有单模态方法，提供了一种更可靠的疾病识别方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.18546v1",
      "published_date": "2024-05-22 23:09:49 UTC",
      "updated_date": "2024-05-22 23:09:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:21:22.492946"
    },
    {
      "arxiv_id": "2405.14058v2",
      "title": "Formally Verifying Deep Reinforcement Learning Controllers with Lyapunov Barrier Certificates",
      "title_zh": "翻译失败",
      "authors": [
        "Udayan Mandal",
        "Guy Amir",
        "Haoze Wu",
        "Ieva Daukantas",
        "Fletcher Lee Newell",
        "Umberto J. Ravaioli",
        "Baoluo Meng",
        "Michael Durling",
        "Milan Ganai",
        "Tobey Shim",
        "Guy Katz",
        "Clark Barrett"
      ],
      "abstract": "Deep reinforcement learning (DRL) is a powerful machine learning paradigm for\ngenerating agents that control autonomous systems. However, the ``black box''\nnature of DRL agents limits their deployment in real-world safety-critical\napplications. A promising approach for providing strong guarantees on an\nagent's behavior is to use Neural Lyapunov Barrier (NLB) certificates, which\nare learned functions over the system whose properties indirectly imply that an\nagent behaves as desired. However, NLB-based certificates are typically\ndifficult to learn and even more difficult to verify, especially for complex\nsystems. In this work, we present a novel method for training and verifying\nNLB-based certificates for discrete-time systems. Specifically, we introduce a\ntechnique for certificate composition, which simplifies the verification of\nhighly-complex systems by strategically designing a sequence of certificates.\nWhen jointly verified with neural network verification engines, these\ncertificates provide a formal guarantee that a DRL agent both achieves its\ngoals and avoids unsafe behavior. Furthermore, we introduce a technique for\ncertificate filtering, which significantly simplifies the process of producing\nformally verified certificates. We demonstrate the merits of our approach with\na case study on providing safety and liveness guarantees for a DRL-controlled\nspacecraft.",
      "tldr_zh": "这篇论文针对深度强化学习（Deep Reinforcement Learning, DRL）代理的黑箱性质，提出了一种使用 Neural Lyapunov Barrier (NLB) 证书的方法来正式验证其控制行为，确保代理在安全关键应用中实现目标并避免风险。作者引入了证书组合（certificate composition）技术，通过设计证书序列简化复杂离散时间系统的验证过程，以及证书过滤（certificate filtering）技术来简化证书生成。结合神经网络验证引擎，这些证书提供正式保证，证明 DRL 代理既能达到预期目标又能维持安全性。在航天器控制的案例研究中，该方法成功提供了安全性和活跃性保证，展示了其实际应用价值。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "To appear in FMCAD 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.14058v2",
      "published_date": "2024-05-22 23:06:34 UTC",
      "updated_date": "2024-08-14 18:45:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:21:34.134771"
    },
    {
      "arxiv_id": "2405.14057v1",
      "title": "Your Large Language Models Are Leaving Fingerprints",
      "title_zh": "翻译失败",
      "authors": [
        "Hope McGovern",
        "Rickard Stureborg",
        "Yoshi Suhara",
        "Dimitris Alikaniotis"
      ],
      "abstract": "It has been shown that finetuned transformers and other supervised detectors\neffectively distinguish between human and machine-generated text in some\nsituations arXiv:2305.13242, but we find that even simple classifiers on top of\nn-gram and part-of-speech features can achieve very robust performance on both\nin- and out-of-domain data. To understand how this is possible, we analyze\nmachine-generated output text in five datasets, finding that LLMs possess\nunique fingerprints that manifest as slight differences in the frequency of\ncertain lexical and morphosyntactic features. We show how to visualize such\nfingerprints, describe how they can be used to detect machine-generated text\nand find that they are even robust across textual domains. We find that\nfingerprints are often persistent across models in the same model family (e.g.\nllama-13b vs. llama-65b) and that models fine-tuned for chat are easier to\ndetect than standard language models, indicating that LLM fingerprints may be\ndirectly induced by the training data.",
      "tldr_zh": "该研究发现，大型语言模型 (LLMs) 生成的文本会留下独特的指纹，这些指纹表现为词汇 (如 n-gram) 和形态语法 (part-of-speech) 特征频率的细微差异。研究者使用简单分类器分析了五个数据集，证明这些指纹能有效区分人类和机器生成的文本，并在内部和外部数据上表现出色。结果显示，同一模型家族（如 llama-13b 与 llama-65b）的指纹相似，而针对对话 fine-tuned 的模型更容易被检测，这可能源于训练数据的直接影响。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14057v1",
      "published_date": "2024-05-22 23:02:42 UTC",
      "updated_date": "2024-05-22 23:02:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:21:45.188036"
    },
    {
      "arxiv_id": "2405.14055v1",
      "title": "How Many Bytes Can You Take Out Of Brain-To-Text Decoding?",
      "title_zh": "翻译失败",
      "authors": [
        "Richard Antonello",
        "Nihita Sarma",
        "Jerry Tang",
        "Jiaru Song",
        "Alexander Huth"
      ],
      "abstract": "Brain-computer interfaces have promising medical and scientific applications\nfor aiding speech and studying the brain. In this work, we propose an\ninformation-based evaluation metric for brain-to-text decoders. Using this\nmetric, we examine two methods to augment existing state-of-the-art continuous\ntext decoders. We show that these methods, in concert, can improve brain\ndecoding performance by upwards of 40% when compared to a baseline model. We\nfurther examine the informatic properties of brain-to-text decoders and show\nempirically that they have Zipfian power law dynamics. Finally, we provide an\nestimate for the idealized performance of an fMRI-based text decoder. We\ncompare this idealized model to our current model, and use our\ninformation-based metric to quantify the main sources of decoding error. We\nconclude that a practical brain-to-text decoder is likely possible given\nfurther algorithmic improvements.",
      "tldr_zh": "本文提出了一种基于信息的信息评估指标，用于评估脑到文本(brain-to-text)解码器，并通过两种增强方法将现有最先进连续文本解码器的性能提高超过40%。研究发现，这些解码器表现出Zipfian power law dynamics的特性，并对基于fMRI的文本解码器进行了理想化性能估计。作者量化了解码错误的主要来源，包括信息损失等因素。最终结论认为，通过进一步的算法改进，实现实用的脑到文本解码器是可行的。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14055v1",
      "published_date": "2024-05-22 22:57:04 UTC",
      "updated_date": "2024-05-22 22:57:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:21:57.374360"
    },
    {
      "arxiv_id": "2405.14039v2",
      "title": "Embedding Trajectory for Out-of-Distribution Detection in Mathematical Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Yiming Wang",
        "Pei Zhang",
        "Baosong Yang",
        "Derek F. Wong",
        "Zhuosheng Zhang",
        "Rui Wang"
      ],
      "abstract": "Real-world data deviating from the independent and identically distributed\n(i.i.d.) assumption of in-distribution training data poses security threats to\ndeep networks, thus advancing out-of-distribution (OOD) detection algorithms.\nDetection methods in generative language models (GLMs) mainly focus on\nuncertainty estimation and embedding distance measurement, with the latter\nproven to be most effective in traditional linguistic tasks like summarization\nand translation. However, another complex generative scenario mathematical\nreasoning poses significant challenges to embedding-based methods due to its\nhigh-density feature of output spaces, but this feature causes larger\ndiscrepancies in the embedding shift trajectory between different samples in\nlatent spaces. Hence, we propose a trajectory-based method TV score, which uses\ntrajectory volatility for OOD detection in mathematical reasoning. Experiments\nshow that our method outperforms all traditional algorithms on GLMs under\nmathematical reasoning scenarios and can be extended to more applications with\nhigh-density features in output spaces, such as multiple-choice questions.",
      "tldr_zh": "该论文针对生成语言模型（GLMs）在数学推理任务中的Out-of-Distribution (OOD)检测问题，指出传统基于嵌入距离测量的方法因输出空间的高密度特征而面临挑战。研究者提出TV score方法，通过分析嵌入轨迹（embedding trajectory）的波动性来识别OOD样本，从而提升检测准确性。实验结果显示，该方法在数学推理场景下优于现有算法，并可扩展到其他高密度输出空间的应用，如多项选择题。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.14039v2",
      "published_date": "2024-05-22 22:22:25 UTC",
      "updated_date": "2024-10-30 12:10:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:22:07.770659"
    },
    {
      "arxiv_id": "2405.14024v1",
      "title": "Two Heads are Better Than One: Neural Networks Quantization with 2D Hilbert Curve-based Output Representation",
      "title_zh": "翻译失败",
      "authors": [
        "Mykhailo Uss",
        "Ruslan Yermolenko",
        "Olena Kolodiazhna",
        "Oleksii Shashko",
        "Ivan Safonov",
        "Volodymyr Savin",
        "Yoonjae Yeo",
        "Seowon Ji",
        "Jaeyun Jeong"
      ],
      "abstract": "Quantization is widely used to increase deep neural networks' (DNN) memory,\ncomputation, and power efficiency. Various techniques, such as post-training\nquantization and quantization-aware training, have been proposed to improve\nquantization quality. We introduce a novel approach for DNN quantization that\nuses a redundant representation of DNN's output. We represent the target\nquantity as a point on a 2D parametric curve. The DNN model is modified to\npredict 2D points that are mapped back to the target quantity at a\npost-processing stage. We demonstrate that this mapping can reduce quantization\nerror. For the low-order parametric Hilbert curve, Depth-From-Stereo task, and\ntwo models represented by U-Net architecture and vision transformer, we\nachieved a quantization error reduction by about 5 times for the INT8 model at\nboth CPU and DSP delegates. This gain comes with a minimal inference time\nincrease (less than 7%). Our approach can be applied to other tasks, including\nsegmentation, object detection, and key-points prediction.",
      "tldr_zh": "本研究提出了一种新型深度神经网络（DNN）量化方法，通过基于2D Hilbert Curve的冗余输出表示来减少量化错误。具体来说，该方法将目标量表示为2D参数曲线上的一点，并修改DNN模型来预测这些2D点，然后在后处理阶段映射回目标量，从而提升量化质量。在Depth-From-Stereo任务中使用U-Net和视觉Transformer模型时，该方法使INT8模型的量化错误减少约5倍，同时推理时间仅增加不到7%。这项技术可扩展到其他任务，如分割、物体检测和关键点预测，从而提高DNN的内存、计算和功率效率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.14024v1",
      "published_date": "2024-05-22 21:59:46 UTC",
      "updated_date": "2024-05-22 21:59:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:22:21.393729"
    },
    {
      "arxiv_id": "2405.14020v1",
      "title": "Unlearning Information Bottleneck: Machine Unlearning of Systematic Patterns and Biases",
      "title_zh": "翻译失败",
      "authors": [
        "Ling Han",
        "Hao Huang",
        "Dustin Scheinost",
        "Mary-Anne Hartley",
        "María Rodríguez Martínez"
      ],
      "abstract": "Effective adaptation to distribution shifts in training data is pivotal for\nsustaining robustness in neural networks, especially when removing specific\nbiases or outdated information, a process known as machine unlearning.\nTraditional approaches typically assume that data variations are random, which\nmakes it difficult to adjust the model parameters accurately to remove patterns\nand characteristics from unlearned data. In this work, we present Unlearning\nInformation Bottleneck (UIB), a novel information-theoretic framework designed\nto enhance the process of machine unlearning that effectively leverages the\ninfluence of systematic patterns and biases for parameter adjustment. By\nproposing a variational upper bound, we recalibrate the model parameters\nthrough a dynamic prior that integrates changes in data distribution with an\naffordable computational cost, allowing efficient and accurate removal of\noutdated or unwanted data patterns and biases. Our experiments across various\ndatasets, models, and unlearning methods demonstrate that our approach\neffectively removes systematic patterns and biases while maintaining the\nperformance of models post-unlearning.",
      "tldr_zh": "本研究针对机器 unlearning 中的挑战，提出了一种名为 Unlearning Information Bottleneck (UIB) 的新框架，该框架基于信息理论，帮助神经网络有效地移除系统性模式和偏差，以适应数据分布变化。UIB 通过引入变分上界和动态先验来调整模型参数，实现高效的模式移除，同时保持计算成本可控。实验结果显示，该方法在多种数据集、模型和 unlearning 技术上表现出色，能够准确消除 unwanted 数据模式，同时维持模型的整体性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14020v1",
      "published_date": "2024-05-22 21:54:05 UTC",
      "updated_date": "2024-05-22 21:54:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:22:31.968843"
    },
    {
      "arxiv_id": "2405.14016v2",
      "title": "Towards a Unified Framework for Evaluating Explanations",
      "title_zh": "朝向评估解释的统一框架",
      "authors": [
        "Juan D. Pinto",
        "Luc Paquette"
      ],
      "abstract": "The challenge of creating interpretable models has been taken up by two main\nresearch communities: ML researchers primarily focused on lower-level\nexplainability methods that suit the needs of engineers, and HCI researchers\nwho have more heavily emphasized user-centered approaches often based on\nparticipatory design methods. This paper reviews how these communities have\nevaluated interpretability, identifying overlaps and semantic misalignments. We\npropose moving towards a unified framework of evaluation criteria and lay the\ngroundwork for such a framework by articulating the relationships between\nexisting criteria. We argue that explanations serve as mediators between models\nand stakeholders, whether for intrinsically interpretable models or opaque\nblack-box models analyzed via post-hoc techniques. We further argue that useful\nexplanations require both faithfulness and intelligibility. Explanation\nplausibility is a prerequisite for intelligibility, while stability is a\nprerequisite for explanation faithfulness. We illustrate these criteria, as\nwell as specific evaluation methods, using examples from an ongoing study of an\ninterpretable neural network for predicting a particular learner behavior.",
      "tldr_zh": "这篇论文审视了机器学习(ML)和人机交互(HCI)社区在评估可解释性模型方面的差异，识别了重叠和语义不一致，并提出一个统一的评估框架。该框架强调解释作为模型与利益相关者之间的中介，要求解释具备faithfulness（忠实性）和intelligibility（可理解性），其中explanation plausibility（解释合理性）是intelligibility的前置条件，而stability（稳定性）是faithfulness的前置条件。通过一个正在进行的解释性神经网络研究案例，论文展示了这些标准及其评估方法的核心关系，为未来解释评估提供了基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "6 pages. Presented at HEXED Workshop @ EDM24",
      "pdf_url": "http://arxiv.org/pdf/2405.14016v2",
      "published_date": "2024-05-22 21:49:28 UTC",
      "updated_date": "2024-07-14 01:11:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:22:45.566778"
    },
    {
      "arxiv_id": "2405.14014v4",
      "title": "RadarOcc: Robust 3D Occupancy Prediction with 4D Imaging Radar",
      "title_zh": "翻译失败",
      "authors": [
        "Fangqiang Ding",
        "Xiangyu Wen",
        "Yunzhou Zhu",
        "Yiming Li",
        "Chris Xiaoxuan Lu"
      ],
      "abstract": "3D occupancy-based perception pipeline has significantly advanced autonomous\ndriving by capturing detailed scene descriptions and demonstrating strong\ngeneralizability across various object categories and shapes. Current methods\npredominantly rely on LiDAR or camera inputs for 3D occupancy prediction. These\nmethods are susceptible to adverse weather conditions, limiting the all-weather\ndeployment of self-driving cars. To improve perception robustness, we leverage\nthe recent advances in automotive radars and introduce a novel approach that\nutilizes 4D imaging radar sensors for 3D occupancy prediction. Our method,\nRadarOcc, circumvents the limitations of sparse radar point clouds by directly\nprocessing the 4D radar tensor, thus preserving essential scene details.\nRadarOcc innovatively addresses the challenges associated with the voluminous\nand noisy 4D radar data by employing Doppler bins descriptors, sidelobe-aware\nspatial sparsification, and range-wise self-attention mechanisms. To minimize\nthe interpolation errors associated with direct coordinate transformations, we\nalso devise a spherical-based feature encoding followed by\nspherical-to-Cartesian feature aggregation. We benchmark various baseline\nmethods based on distinct modalities on the public K-Radar dataset. The results\ndemonstrate RadarOcc's state-of-the-art performance in radar-based 3D occupancy\nprediction and promising results even when compared with LiDAR- or camera-based\nmethods. Additionally, we present qualitative evidence of the superior\nperformance of 4D radar in adverse weather conditions and explore the impact of\nkey pipeline components through ablation studies.",
      "tldr_zh": "这篇论文提出RadarOcc方法，利用4D imaging radar进行鲁棒的3D occupancy prediction，以解决现有依赖LiDAR或相机的方法在恶劣天气下的局限性。RadarOcc通过直接处理4D雷达张量，并引入Doppler bins descriptors、sidelobe-aware spatial sparsification和range-wise self-attention机制，来有效处理数据噪声和体积问题，同时采用spherical-based feature encoding和spherical-to-Cartesian feature aggregation最小化插值错误。在K-Radar数据集基准测试中，RadarOcc在雷达基础上实现state-of-the-art性能，甚至与LiDAR或相机方法竞争，并在恶劣天气条件下展示出显著优势。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "22 pages, 5 figures, 8 tables. Accepted by NeurIPS 2024 (Vancouver),\n  the Thirty-Eighth Annual Conference on Neural Information Processing Systems",
      "pdf_url": "http://arxiv.org/pdf/2405.14014v4",
      "published_date": "2024-05-22 21:48:17 UTC",
      "updated_date": "2024-10-27 19:15:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:22:57.952733"
    },
    {
      "arxiv_id": "2405.14012v1",
      "title": "Prompt-Time Ontology-Driven Symbolic Knowledge Capture with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Tolga Çöplü",
        "Arto Bendiken",
        "Andrii Skomorokhov",
        "Eduard Bateiko",
        "Stephen Cobb"
      ],
      "abstract": "In applications such as personal assistants, large language models (LLMs)\nmust consider the user's personal information and preferences. However, LLMs\nlack the inherent ability to learn from user interactions. This paper explores\ncapturing personal information from user prompts using ontology and\nknowledge-graph approaches. We use a subset of the KNOW ontology, which models\npersonal information, to train the language model on these concepts. We then\nevaluate the success of knowledge capture using a specially constructed\ndataset. Our code and datasets are publicly available at\nhttps://github.com/HaltiaAI/paper-PTODSKC",
      "tldr_zh": "该研究探讨了如何利用本体论（ontology）和知识图谱（knowledge-graph）从用户提示中实时捕获符号知识，以提升大型语言模型（LLMs）在个人助理等应用中的能力，特别是处理用户个人信息和偏好。研究者使用 KNOW ontology 的子集来训练语言模型，从而帮助 LLMs 学习这些概念。实验通过一个专门构建的数据集评估了知识捕获的成功率，并公开了代码和数据集（https://github.com/HaltiaAI/paper-PTODSKC），为 LLMs 的个性化应用提供了实用框架。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "7 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.14012v1",
      "published_date": "2024-05-22 21:40:34 UTC",
      "updated_date": "2024-05-22 21:40:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:23:08.343770"
    },
    {
      "arxiv_id": "2405.14006v1",
      "title": "Evaluating Large Language Models with Human Feedback: Establishing a Swedish Benchmark",
      "title_zh": "翻译失败",
      "authors": [
        "Birger Moell"
      ],
      "abstract": "In the rapidly evolving field of artificial intelligence, large language\nmodels (LLMs) have demonstrated significant capabilities across numerous\napplications. However, the performance of these models in languages with fewer\nresources, such as Swedish, remains under-explored. This study introduces a\ncomprehensive human benchmark to assess the efficacy of prominent LLMs in\nunderstanding and generating Swedish language texts using forced choice\nranking. We employ a modified version of the ChatbotArena benchmark,\nincorporating human feedback to evaluate eleven different models, including\nGPT-4, GPT-3.5, various Claude and Llama models, and bespoke models like\nDolphin-2.9-llama3b-8b-flashback and BeagleCatMunin. These models were chosen\nbased on their performance on LMSYS chatbot arena and the Scandeval benchmarks.\nWe release the chatbotarena.se benchmark as a tool to improve our understanding\nof language model performance in Swedish with the hopes that it will be widely\nused. We aim to create a leaderboard once sufficient data has been collected\nand analysed.",
      "tldr_zh": "这篇论文评估大型语言模型 (LLMs) 在瑞典语等少资源语言中的性能，通过引入一个基于人类反馈的基准测试。研究者修改了 ChatbotArena 基准，使用强制选择排名方法评估了 11 个模型，包括 GPT-4、GPT-3.5、Claude 和 Llama 系列，以及定制模型如 Dolphin-2.9-llama3b-8b-flashback 和 BeagleCatMunin。论文发布了 chatbotarena.se 工具作为公开资源，并计划在收集足够数据后创建一个排行榜，以改善对 LLMs 在瑞典语处理能力的理解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.14006v1",
      "published_date": "2024-05-22 21:22:51 UTC",
      "updated_date": "2024-05-22 21:22:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:23:21.874987"
    },
    {
      "arxiv_id": "2405.14001v3",
      "title": "Nondeterministic Causal Models",
      "title_zh": "非确定性因果模型",
      "authors": [
        "Sander Beckers"
      ],
      "abstract": "I generalize acyclic deterministic structural causal models to the\nnondeterministic case and argue that this offers an improved semantics for\ncounterfactuals. The standard, deterministic, semantics developed by Halpern\n(and based on the initial proposal of Galles & Pearl) assumes that for each\nassignment of values to parent variables there is a unique assignment to their\nchild variable, and it assumes that the actual world (an assignment of values\nto all variables of a model) specifies a unique counterfactual world for each\nintervention. Both assumptions are unrealistic, and therefore I drop both of\nthem in my proposal. I do so by allowing multi-valued functions in the\nstructural equations. In addition, I adjust the semantics so that the solutions\nto the equations that obtained in the actual world are preserved in any\ncounterfactual world. I provide a sound and complete axiomatization of the\nresulting logic and compare it to the standard one by Halpern and to more\nrecent proposals that are closer to mine. Finally, I extend these models to the\nprobabilistic case and show that they open up the way to identifying\ncounterfactuals even in Causal Bayesian Networks.",
      "tldr_zh": "该论文将无环确定性结构因果模型(acyclic deterministic structural causal models)泛化到非确定性情况，以提供更现实的反事实(counterfactuals)语义。作者通过引入多值函数(multi-valued functions)来放弃标准假设，即每个父变量赋值对应唯一子变量赋值，并确保实际世界的解决方案在反事实世界中被保留。论文提供了该逻辑的健全且完备的公理化(axiomatization)，并与Halpern的标准语义及相关提案比较，同时扩展到概率模型(probabilistic case)，从而使反事实在因果贝叶斯网络(Causal Bayesian Networks)中得以识别。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at CLeaR 2025",
      "pdf_url": "http://arxiv.org/pdf/2405.14001v3",
      "published_date": "2024-05-22 21:17:52 UTC",
      "updated_date": "2025-03-10 19:56:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:23:33.187918"
    },
    {
      "arxiv_id": "2405.14903v2",
      "title": "NeuralFluid: Neural Fluidic System Design and Control with Differentiable Simulation",
      "title_zh": "翻译失败",
      "authors": [
        "Yifei Li",
        "Yuchen Sun",
        "Pingchuan Ma",
        "Eftychios Sifakis",
        "Tao Du",
        "Bo Zhu",
        "Wojciech Matusik"
      ],
      "abstract": "We present a novel framework to explore neural control and design of complex\nfluidic systems with dynamic solid boundaries. Our system features a fast\ndifferentiable Navier-Stokes solver with solid-fluid interface handling, a\nlow-dimensional differentiable parametric geometry representation, a\ncontrol-shape co-design algorithm, and gym-like simulation environments to\nfacilitate various fluidic control design applications. Additionally, we\npresent a benchmark of design, control, and learning tasks on high-fidelity,\nhigh-resolution dynamic fluid environments that pose challenges for existing\ndifferentiable fluid simulators. These tasks include designing the control of\nartificial hearts, identifying robotic end-effector shapes, and controlling a\nfluid gate. By seamlessly incorporating our differentiable fluid simulator into\na learning framework, we demonstrate successful design, control, and learning\nresults that surpass gradient-free solutions in these benchmark tasks.",
      "tldr_zh": "该研究提出了NeuralFluid框架，用于神经控制和设计复杂流体系统，特别处理动态固体边界。该框架包括一个快速可微Navier-Stokes求解器、可微参数几何表示、控制-形状联合设计算法，以及类似Gym的模拟环境，以支持各种流体控制应用。研究还建立了基准任务，如设计人工心脏控制、识别机器人末端执行器形状和控制流体门，并在高保真、高分辨率环境中展示了该方法超越无梯度解决方案的性能。",
      "categories": [
        "physics.flu-dyn",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "physics.flu-dyn",
      "comment": "Accepted to NeurIPS 2024; Project webpage:\n  https://people.csail.mit.edu/liyifei/publication/neuralfluid/",
      "pdf_url": "http://arxiv.org/pdf/2405.14903v2",
      "published_date": "2024-05-22 21:16:59 UTC",
      "updated_date": "2024-10-31 18:11:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:23:45.008581"
    },
    {
      "arxiv_id": "2405.13987v2",
      "title": "Analysis of Corrected Graph Convolutions",
      "title_zh": "修正图卷积的分析",
      "authors": [
        "Robert Wang",
        "Aseem Baranwal",
        "Kimon Fountoulakis"
      ],
      "abstract": "Machine learning for node classification on graphs is a prominent area driven\nby applications such as recommendation systems. State-of-the-art models often\nuse multiple graph convolutions on the data, as empirical evidence suggests\nthey can enhance performance. However, it has been shown empirically and\ntheoretically, that too many graph convolutions can degrade performance\nsignificantly, a phenomenon known as oversmoothing. In this paper, we provide a\nrigorous theoretical analysis, based on the two-class contextual stochastic\nblock model (CSBM), of the performance of vanilla graph convolution from which\nwe remove the principal eigenvector to avoid oversmoothing. We perform a\nspectral analysis for $k$ rounds of corrected graph convolutions, and we\nprovide results for partial and exact classification. For partial\nclassification, we show that each round of convolution can reduce the\nmisclassification error exponentially up to a saturation level, after which\nperformance does not worsen. We also extend this analysis to the multi-class\nsetting with features distributed according to a Gaussian mixture model. For\nexact classification, we show that the separability threshold can be improved\nexponentially up to $O({\\log{n}}/{\\log\\log{n}})$ corrected convolutions.",
      "tldr_zh": "本论文分析了修正图卷积（corrected graph convolutions），旨在解决图神经网络中过多的图卷积导致的 oversmoothing 问题，从而提升节点分类性能。作者基于两类 contextual stochastic block model (CSBM) 进行严格的理论分析，通过移除 principal eigenvector 来避免 oversmoothing，并对 k 轮修正图卷积的谱分析进行了研究。对于 partial classification，结果显示每轮卷积可指数级减少误分类错误，直至达到饱和水平；同时，该分析扩展到多类设置，使用 Gaussian mixture model。对于 exact classification，论文证明修正卷积可将 separability threshold 指数级改善至 O(log n / log log n) 轮。总的来说，此工作为优化图卷积在实际应用中的鲁棒性提供了理论基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DM",
        "math.ST",
        "stat.ML",
        "stat.TH"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13987v2",
      "published_date": "2024-05-22 20:50:17 UTC",
      "updated_date": "2024-12-14 05:02:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:23:59.876119"
    },
    {
      "arxiv_id": "2405.15816v1",
      "title": "Riemannian Bilevel Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Sanchayan Dutta",
        "Xiang Cheng",
        "Suvrit Sra"
      ],
      "abstract": "We develop new algorithms for Riemannian bilevel optimization. We focus in\nparticular on batch and stochastic gradient-based methods, with the explicit\ngoal of avoiding second-order information such as Riemannian hyper-gradients.\nWe propose and analyze $\\mathrm{RF^2SA}$, a method that leverages first-order\ngradient information to navigate the complex geometry of Riemannian manifolds\nefficiently. Notably, $\\mathrm{RF^2SA}$ is a single-loop algorithm, and thus\neasier to implement and use. Under various setups, including stochastic\noptimization, we provide explicit convergence rates for reaching\n$\\epsilon$-stationary points. We also address the challenge of optimizing over\nRiemannian manifolds with constraints by adjusting the multiplier in the\nLagrangian, ensuring convergence to the desired solution without requiring\naccess to second-order derivatives.",
      "tldr_zh": "这篇论文开发了新的Riemannian bilevel optimization算法，专注于基于一阶梯度的批量和随机方法，以避免使用第二阶信息如Riemannian hyper-gradients。作者提出了$\\mathrm{RF^2SA}$，一个单循环算法，利用一阶梯度信息在Riemannian manifolds上高效导航，提高了实现和使用的便利性。在各种设置下，包括随机优化，该方法提供了到达$\\epsilon$-stationary points的显式收敛率，并通过调整Lagrangian中的乘子处理带有约束的优化问题，确保了收敛性而不需第二阶导数。",
      "categories": [
        "math.OC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "math.OC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.15816v1",
      "published_date": "2024-05-22 20:49:01 UTC",
      "updated_date": "2024-05-22 20:49:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:24:09.873759"
    },
    {
      "arxiv_id": "2405.13983v3",
      "title": "DirectMultiStep: Direct Route Generation for Multistep Retrosynthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Shee",
        "Anton Morgunov",
        "Haote Li",
        "Victor S. Batista"
      ],
      "abstract": "Traditional computer-aided synthesis planning (CASP) methods rely on\niterative single-step predictions, leading to exponential search space growth\nthat limits efficiency and scalability. We introduce a series of\ntransformer-based models, that leverage a mixture of experts approach to\ndirectly generate multistep synthetic routes as a single string, conditionally\npredicting each transformation based on all preceding ones. Our DMS Explorer XL\nmodel, which requires only target compounds as input, outperforms\nstate-of-the-art methods on the PaRoutes dataset with 1.9x and 3.1x\nimprovements in Top-1 accuracy on the n$_1$ and n$_5$ test sets, respectively.\nProviding additional information, such as the desired number of steps and\nstarting materials, enables both a reduction in model size and an increase in\naccuracy, highlighting the benefits of incorporating more constraints into the\nprediction process. The top-performing DMS-Flex (Duo) model scores 25-50%\nhigher on Top-1 and Top-10 accuracies for both n$_1$ and n$_5$ sets.\nAdditionally, our models successfully predict routes for FDA-approved drugs not\nincluded in the training data, demonstrating strong generalization\ncapabilities. While the limited diversity of the training set may affect\nperformance on less common reaction types, our multistep-first approach\npresents a promising direction towards fully automated retrosynthetic planning.",
      "tldr_zh": "本研究提出DirectMultiStep系列模型，使用Transformer和Mixture of Experts方法，直接生成多步合成路线作为单一字符串，从而避免传统CASP方法依赖迭代单步预测导致的搜索空间指数增长问题。模型如DMS Explorer XL仅需目标化合物作为输入，即可基于前置转换条件预测完整路线，并在PaRoutes数据集上实现Top-1准确率比现有方法提高1.9倍（n$_1$集）和3.1倍（n$_5$集）。通过整合额外约束如步数和起始材料，DMS-Flex (Duo)模型进一步提升Top-1和Top-10准确率25-50%，并展示出对训练数据外FDA批准药物的良好泛化能力。尽管训练集多样性有限可能影响不常见反应类型的性能，这种多步优先方法为完全自动的逆合成规划提供了新方向。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13983v3",
      "published_date": "2024-05-22 20:39:05 UTC",
      "updated_date": "2025-03-20 01:58:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:24:21.279835"
    },
    {
      "arxiv_id": "2405.13978v1",
      "title": "Mitigating Interference in the Knowledge Continuum through Attention-Guided Incremental Learning",
      "title_zh": "通过注意力引导的增量学习减轻知识连续体中的干扰",
      "authors": [
        "Prashant Bhat",
        "Bharath Renjith",
        "Elahe Arani",
        "Bahram Zonooz"
      ],
      "abstract": "Continual learning (CL) remains a significant challenge for deep neural\nnetworks, as it is prone to forgetting previously acquired knowledge. Several\napproaches have been proposed in the literature, such as experience rehearsal,\nregularization, and parameter isolation, to address this problem. Although\nalmost zero forgetting can be achieved in task-incremental learning,\nclass-incremental learning remains highly challenging due to the problem of\ninter-task class separation. Limited access to previous task data makes it\ndifficult to discriminate between classes of current and previous tasks. To\naddress this issue, we propose `Attention-Guided Incremental Learning' (AGILE),\na novel rehearsal-based CL approach that incorporates compact task attention to\neffectively reduce interference between tasks. AGILE utilizes lightweight,\nlearnable task projection vectors to transform the latent representations of a\nshared task attention module toward task distribution. Through extensive\nempirical evaluation, we show that AGILE significantly improves generalization\nperformance by mitigating task interference and outperforming rehearsal-based\napproaches in several CL scenarios. Furthermore, AGILE can scale well to a\nlarge number of tasks with minimal overhead while remaining well-calibrated\nwith reduced task-recency bias.",
      "tldr_zh": "这项研究针对 Continual Learning (CL) 中的知识遗忘问题，特别是 class-incremental learning 中任务间类别的干扰，提出了一种名为 Attention-Guided Incremental Learning (AGILE) 的新方法。AGILE 是一种基于 rehearsal 的框架，利用轻量级的 learnable task projection vectors 和 shared task attention module 来转换潜在表示，从而有效减少任务间的干扰。实验结果表明，AGILE 显著提升了泛化性能，在多个 CL 场景中优于现有 rehearsal-based 方法，并能扩展到大量任务，同时减少了 task-recency bias 和开销。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at 3rd Conference on Lifelong Learning Agents (CoLLAs 2024)",
      "pdf_url": "http://arxiv.org/pdf/2405.13978v1",
      "published_date": "2024-05-22 20:29:15 UTC",
      "updated_date": "2024-05-22 20:29:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:24:33.814731"
    },
    {
      "arxiv_id": "2405.13974v1",
      "title": "CIVICS: Building a Dataset for Examining Culturally-Informed Values in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Giada Pistilli",
        "Alina Leidinger",
        "Yacine Jernite",
        "Atoosa Kasirzadeh",
        "Alexandra Sasha Luccioni",
        "Margaret Mitchell"
      ],
      "abstract": "This paper introduces the \"CIVICS: Culturally-Informed & Values-Inclusive\nCorpus for Societal impacts\" dataset, designed to evaluate the social and\ncultural variation of Large Language Models (LLMs) across multiple languages\nand value-sensitive topics. We create a hand-crafted, multilingual dataset of\nvalue-laden prompts which address specific socially sensitive topics, including\nLGBTQI rights, social welfare, immigration, disability rights, and surrogacy.\nCIVICS is designed to generate responses showing LLMs' encoded and implicit\nvalues. Through our dynamic annotation processes, tailored prompt design, and\nexperiments, we investigate how open-weight LLMs respond to value-sensitive\nissues, exploring their behavior across diverse linguistic and cultural\ncontexts. Using two experimental set-ups based on log-probabilities and\nlong-form responses, we show social and cultural variability across different\nLLMs. Specifically, experiments involving long-form responses demonstrate that\nrefusals are triggered disparately across models, but consistently and more\nfrequently in English or translated statements. Moreover, specific topics and\nsources lead to more pronounced differences across model answers, particularly\non immigration, LGBTQI rights, and social welfare. As shown by our experiments,\nthe CIVICS dataset aims to serve as a tool for future research, promoting\nreproducibility and transparency across broader linguistic settings, and\nfurthering the development of AI technologies that respect and reflect global\ncultural diversities and value pluralism. The CIVICS dataset and tools will be\nmade available upon publication under open licenses; an anonymized version is\ncurrently available at https://huggingface.co/CIVICS-dataset.",
      "tldr_zh": "本论文引入了CIVICS数据集（Culturally-Informed & Values-Inclusive Corpus for Societal impacts），旨在评估大型语言模型(LLMs)在多语言和价值敏感主题上的社会文化变异，包括LGBTQI rights、社会福利、移民、残疾权利和代孕等话题。该数据集通过手工制作的多语言提示、动态注释过程和定制实验设计，生成LLMs的响应以揭示其隐含价值观。实验结果显示，LLMs在不同语言文化背景下表现出显著差异，拒绝响应在英语或翻译语句中更频繁，且移民、LGBTQI rights和社会福利等主题导致模型答案的明显分歧。CIVICS数据集将作为开源工具，促进AI研究的透明性和可重复性，推动开发尊重全球文化多样性和价值多元主义的AI技术。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13974v1",
      "published_date": "2024-05-22 20:19:10 UTC",
      "updated_date": "2024-05-22 20:19:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:24:47.543029"
    },
    {
      "arxiv_id": "2405.13969v1",
      "title": "Uncertainty-Aware DRL for Autonomous Vehicle Crowd Navigation in Shared Space",
      "title_zh": "翻译失败",
      "authors": [
        "Mahsa Golchoubian",
        "Moojan Ghafurian",
        "Kerstin Dautenhahn",
        "Nasser Lashgarian Azad"
      ],
      "abstract": "Safe, socially compliant, and efficient navigation of low-speed autonomous\nvehicles (AVs) in pedestrian-rich environments necessitates considering\npedestrians' future positions and interactions with the vehicle and others.\nDespite the inevitable uncertainties associated with pedestrians' predicted\ntrajectories due to their unobserved states (e.g., intent), existing deep\nreinforcement learning (DRL) algorithms for crowd navigation often neglect\nthese uncertainties when using predicted trajectories to guide policy learning.\nThis omission limits the usability of predictions when diverging from ground\ntruth. This work introduces an integrated prediction and planning approach that\nincorporates the uncertainties of predicted pedestrian states in the training\nof a model-free DRL algorithm. A novel reward function encourages the AV to\nrespect pedestrians' personal space, decrease speed during close approaches,\nand minimize the collision probability with their predicted paths. Unlike\nprevious DRL methods, our model, designed for AV operation in crowded spaces,\nis trained in a novel simulation environment that reflects realistic pedestrian\nbehaviour in a shared space with vehicles. Results show a 40% decrease in\ncollision rate and a 15% increase in minimum distance to pedestrians compared\nto the state of the art model that does not account for prediction uncertainty.\nAdditionally, the approach outperforms model predictive control methods that\nincorporate the same prediction uncertainties in terms of both performance and\ncomputational time, while producing trajectories closer to human drivers in\nsimilar scenarios.",
      "tldr_zh": "这篇论文提出了一种考虑预测不确定性的深度强化学习（DRL）方法，用于自动车辆（AVs）在共享空间中进行人群导航，以提升安全性和合规性。该方法整合预测和规划，通过一个新颖的奖励函数训练 AV，使其尊重行人的个人空间、减速接近并最小化碰撞概率，并在新型模拟环境中模拟现实行人行为。与现有模型相比，结果显示碰撞率降低40%、与行人的最小距离增加15%，并在性能和计算时间上优于模型预测控制方法，同时生成更接近人类驾驶员的轨迹。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted for publication in IEEE Transactions on Intelligent Vehicles",
      "pdf_url": "http://arxiv.org/pdf/2405.13969v1",
      "published_date": "2024-05-22 20:09:21 UTC",
      "updated_date": "2024-05-22 20:09:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:24:58.176332"
    },
    {
      "arxiv_id": "2405.13966v1",
      "title": "On the Brittle Foundations of ReAct Prompting for Agentic Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Mudit Verma",
        "Siddhant Bhambri",
        "Subbarao Kambhampati"
      ],
      "abstract": "The reasoning abilities of Large Language Models (LLMs) remain a topic of\ndebate. Some methods such as ReAct-based prompting, have gained popularity for\nclaiming to enhance sequential decision-making abilities of agentic LLMs.\nHowever, it is unclear what is the source of improvement in LLM reasoning with\nReAct based prompting. In this paper we examine these claims of ReAct based\nprompting in improving agentic LLMs for sequential decision-making. By\nintroducing systematic variations to the input prompt we perform a sensitivity\nanalysis along the claims of ReAct and find that the performance is minimally\ninfluenced by the \"interleaving reasoning trace with action execution\" or the\ncontent of the generated reasoning traces in ReAct, contrary to original claims\nand common usage. Instead, the performance of LLMs is driven by the similarity\nbetween input example tasks and queries, implicitly forcing the prompt designer\nto provide instance-specific examples which significantly increases the\ncognitive burden on the human. Our investigation shows that the perceived\nreasoning abilities of LLMs stem from the exemplar-query similarity and\napproximate retrieval rather than any inherent reasoning abilities.",
      "tldr_zh": "这篇论文质疑了 ReAct prompting 在提升 agentic Large Language Models (LLMs) 顺序决策能力的可靠性，通过敏感性分析揭示其基础脆弱。研究者通过对提示进行系统变异，测试了“interleaving reasoning trace with action execution”及其推理痕迹内容的影响，发现这些因素对性能影响最小。相反，LLMs 的表现主要依赖于输入示例任务与查询的相似性，这要求提示设计者提供特定实例示例，从而增加了认知负担；最终结论是，LLMs 的感知推理能力源于示例查询相似性和近似检索，而非固有的推理机制。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13966v1",
      "published_date": "2024-05-22 20:05:49 UTC",
      "updated_date": "2024-05-22 20:05:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:25:10.266855"
    },
    {
      "arxiv_id": "2405.13960v1",
      "title": "Learning To Play Atari Games Using Dueling Q-Learning and Hebbian Plasticity",
      "title_zh": "翻译失败",
      "authors": [
        "Md Ashfaq Salehin"
      ],
      "abstract": "In this work, an advanced deep reinforcement learning architecture is used to\ntrain neural network agents playing atari games. Given only the raw game\npixels, action space, and reward information, the system can train agents to\nplay any Atari game. At first, this system uses advanced techniques like deep\nQ-networks and dueling Q-networks to train efficient agents, the same\ntechniques used by DeepMind to train agents that beat human players in Atari\ngames. As an extension, plastic neural networks are used as agents, and their\nfeasibility is analyzed in this scenario. The plasticity implementation was\nbased on backpropagation and the Hebbian update rule. Plastic neural networks\nhave excellent features like lifelong learning after the initial training,\nwhich makes them highly suitable in adaptive learning environments. As a new\nanalysis of plasticity in this context, this work might provide valuable\ninsights and direction for future works.",
      "tldr_zh": "本研究使用 Dueling Q-Learning 和 Hebbian Plasticity 训练神经网络代理来玩 Atari 游戏，仅依赖原始游戏像素、动作空间和奖励信息。论文首先采用 deep Q-networks 和 dueling Q-networks 技术，类似于 DeepMind 的方法，实现高效代理训练；随后扩展到 plastic neural networks，通过 backpropagation 和 Hebbian update rule 实现，突显其终身学习（lifelong learning）的优势。实验分析表明，这种方法在适应性学习环境中表现出色，并为未来深度强化学习研究提供宝贵见解。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13960v1",
      "published_date": "2024-05-22 19:55:33 UTC",
      "updated_date": "2024-05-22 19:55:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:25:21.999697"
    },
    {
      "arxiv_id": "2405.13954v1",
      "title": "What is Your Data Worth to GPT? LLM-Scale Data Valuation with Influence Functions",
      "title_zh": "翻译失败",
      "authors": [
        "Sang Keun Choe",
        "Hwijeen Ahn",
        "Juhan Bae",
        "Kewen Zhao",
        "Minsoo Kang",
        "Youngseog Chung",
        "Adithya Pratapa",
        "Willie Neiswanger",
        "Emma Strubell",
        "Teruko Mitamura",
        "Jeff Schneider",
        "Eduard Hovy",
        "Roger Grosse",
        "Eric Xing"
      ],
      "abstract": "Large language models (LLMs) are trained on a vast amount of human-written\ndata, but data providers often remain uncredited. In response to this issue,\ndata valuation (or data attribution), which quantifies the contribution or\nvalue of each data to the model output, has been discussed as a potential\nsolution. Nevertheless, applying existing data valuation methods to recent LLMs\nand their vast training datasets has been largely limited by prohibitive\ncompute and memory costs. In this work, we focus on influence functions, a\npopular gradient-based data valuation method, and significantly improve its\nscalability with an efficient gradient projection strategy called LoGra that\nleverages the gradient structure in backpropagation. We then provide a\ntheoretical motivation of gradient projection approaches to influence functions\nto promote trust in the data valuation process. Lastly, we lower the barrier to\nimplementing data valuation systems by introducing LogIX, a software package\nthat can transform existing training code into data valuation code with minimal\neffort. In our data valuation experiments, LoGra achieves competitive accuracy\nagainst more expensive baselines while showing up to 6,500x improvement in\nthroughput and 5x reduction in GPU memory usage when applied to\nLlama3-8B-Instruct and the 1B-token dataset.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)数据估值的核心问题，即量化训练数据对模型输出的贡献，以解决数据提供者未获认可的困境。作者改进influence functions方法，通过引入高效梯度投影策略LoGra，利用反向传播的梯度结构，大幅提升了计算可扩展性，并提供了理论动机来增强方法的可靠性。同时，他们开发了LogIX软件包，便于用户轻松将现有训练代码转化为数据估值代码。在实验中，LoGra应用于Llama3-8B-Instruct和1B-token数据集时，与昂贵基线相比，准确性保持竞争力，同时吞吐量提升高达6500倍，GPU内存使用减少5倍。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13954v1",
      "published_date": "2024-05-22 19:39:05 UTC",
      "updated_date": "2024-05-22 19:39:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:25:35.205915"
    },
    {
      "arxiv_id": "2405.13952v2",
      "title": "Spectral Adapter: Fine-Tuning in Spectral Space",
      "title_zh": "翻译失败",
      "authors": [
        "Fangzhao Zhang",
        "Mert Pilanci"
      ],
      "abstract": "Recent developments in Parameter-Efficient Fine-Tuning (PEFT) methods for\npretrained deep neural networks have captured widespread interest. In this\nwork, we study the enhancement of current PEFT methods by incorporating the\nspectral information of pretrained weight matrices into the fine-tuning\nprocedure. We investigate two spectral adaptation mechanisms, namely additive\ntuning and orthogonal rotation of the top singular vectors, both are done via\nfirst carrying out Singular Value Decomposition (SVD) of pretrained weights and\nthen fine-tuning the top spectral space. We provide a theoretical analysis of\nspectral fine-tuning and show that our approach improves the rank capacity of\nlow-rank adapters given a fixed trainable parameter budget. We show through\nextensive experiments that the proposed fine-tuning model enables better\nparameter efficiency and tuning performance as well as benefits multi-adapter\nfusion.",
      "tldr_zh": "本论文提出了Spectral Adapter方法，通过整合预训练权重矩阵的光谱信息来提升Parameter-Efficient Fine-Tuning (PEFT) 的性能。具体而言，该方法利用Singular Value Decomposition (SVD) 对预训练权重进行分解，并通过加性调整和正交旋转顶奇异向量的机制来微调顶光谱空间。理论分析表明，这种方法在固定参数预算下提高了低秩适配器的秩容量；实验结果显示，它在参数效率、调优性能以及多适配器融合方面均优于现有基线。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13952v2",
      "published_date": "2024-05-22 19:36:55 UTC",
      "updated_date": "2024-11-04 03:35:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:25:46.190823"
    },
    {
      "arxiv_id": "2405.13938v1",
      "title": "eXmY: A Data Type and Technique for Arbitrary Bit Precision Quantization",
      "title_zh": "eXmY：一种用于任意位精度量化的数据类型和技术",
      "authors": [
        "Aditya Agrawal",
        "Matthew Hedlund",
        "Blake Hechtman"
      ],
      "abstract": "eXmY is a novel data type for quantization of ML models. It supports both\narbitrary bit widths and arbitrary integer and floating point formats. For\nexample, it seamlessly supports 3, 5, 6, 7, 9 bit formats. For a specific bit\nwidth, say 7, it defines all possible formats e.g. e0m6, e1m5, e2m4, e3m3,\ne4m2, e5m1 and e6m0. For non-power of two bit widths e.g. 5, 6, 7, we created a\nnovel encoding and decoding scheme which achieves perfect compression, byte\naddressability and is amenable to sharding and vector processing. We\nimplemented libraries for emulation, encoding and decoding tensors and\ncheckpoints in C++, TensorFlow, JAX and PAX. For optimal performance, the\ncodecs use SIMD instructions on CPUs and vector instructions on TPUs and GPUs.\neXmY is also a technique and exploits the statistical distribution of exponents\nin tensors. It can be used to quantize weights, static and dynamic activations,\ngradients, master weights and optimizer state. It can reduce memory (CPU DRAM\nand accelerator HBM), network and disk storage and transfers. It can increase\nmulti tenancy and accelerate compute. eXmY has been deployed in production for\nalmost 2 years.",
      "tldr_zh": "本论文介绍了 eXmY，一种新型数据类型和技术，用于机器学习模型的任意位精度量化，支持任意位宽（如 3、5、6、7、9 位）和整数/浮点格式，包括 e0m6、e1m5 等多种组合。论文提出了一种创新的编码和解码方案，尤其针对非 2 的幂位宽，实现完美压缩、字节可寻址，并优化了 CPU 的 SIMD 指令以及 TPU/GPU 的矢量指令，以提升性能。eXmY 利用张量指数的统计分布量化权重、激活、梯度等元素，显著减少内存、网络和磁盘存储，同时提高计算效率，已在生产环境中部署近 2 年。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR",
        "cs.NA",
        "math.NA"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13938v1",
      "published_date": "2024-05-22 19:11:28 UTC",
      "updated_date": "2024-05-22 19:11:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:25:58.946924"
    },
    {
      "arxiv_id": "2405.13932v1",
      "title": "Chain of Targeted Verification Questions to Improve the Reliability of Code Generated by LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Sylvain Kouemo Ngassom",
        "Arghavan Moradi Dakhel",
        "Florian Tambon",
        "Foutse Khomh"
      ],
      "abstract": "LLM-based assistants, such as GitHub Copilot and ChatGPT, have the potential\nto generate code that fulfills a programming task described in a natural\nlanguage description, referred to as a prompt. The widespread accessibility of\nthese assistants enables users with diverse backgrounds to generate code and\nintegrate it into software projects. However, studies show that code generated\nby LLMs is prone to bugs and may miss various corner cases in task\nspecifications. Presenting such buggy code to users can impact their\nreliability and trust in LLM-based assistants. Moreover, significant efforts\nare required by the user to detect and repair any bug present in the code,\nespecially if no test cases are available. In this study, we propose a\nself-refinement method aimed at improving the reliability of code generated by\nLLMs by minimizing the number of bugs before execution, without human\nintervention, and in the absence of test cases. Our approach is based on\ntargeted Verification Questions (VQs) to identify potential bugs within the\ninitial code. These VQs target various nodes within the Abstract Syntax Tree\n(AST) of the initial code, which have the potential to trigger specific types\nof bug patterns commonly found in LLM-generated code. Finally, our method\nattempts to repair these potential bugs by re-prompting the LLM with the\ntargeted VQs and the initial code. Our evaluation, based on programming tasks\nin the CoderEval dataset, demonstrates that our proposed method outperforms\nstate-of-the-art methods by decreasing the number of targeted errors in the\ncode between 21% to 62% and improving the number of executable code instances\nto 13%.",
      "tldr_zh": "这篇论文提出了一种基于链式针对性 Verification Questions (VQs) 的自精炼方法，以提升LLMs生成代码的可靠性，针对代码中的常见bug和角落案例进行自动识别和修复。方法通过分析代码的Abstract Syntax Tree (AST)节点生成针对特定bug模式的VQs，然后重新提示LLMs进行修复，而无需人类干预或测试用例。在CoderEval数据集的评估中，该方法将错误数量减少了21%至62%，并将可执行代码实例提高了13%，优于现有技术。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "10 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.13932v1",
      "published_date": "2024-05-22 19:02:50 UTC",
      "updated_date": "2024-05-22 19:02:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:26:09.996260"
    },
    {
      "arxiv_id": "2405.13929v6",
      "title": "Vikhr: The Family of Open-Source Instruction-Tuned Large Language Models for Russian",
      "title_zh": "翻译失败",
      "authors": [
        "Aleksandr Nikolich",
        "Konstantin Korolev",
        "Sergei Bratchikov",
        "Igor Kiselev",
        "Artem Shelmanov"
      ],
      "abstract": "There has been a surge in the development of various Large Language Models\n(LLMs). However, text generation for languages other than English often faces\nsignificant challenges, including poor generation quality and reduced\ncomputational performance due to the disproportionate representation of tokens\nin the model's vocabulary. In this work, we address these issues by developing\na pipeline for the adaptation of English-oriented pre-trained models to other\nlanguages and constructing efficient bilingual LLMs. Using this pipeline, we\nconstruct Vikhr, a series of bilingual open-source instruction-following LLMs\ndesigned specifically for the Russian language. ``Vikhr'' refers to the name of\nthe Mistral LLM series and means a ``strong gust of wind.'' Unlike previous\nRussian-language models that typically rely on LoRA adapters on top of\nEnglish-oriented models, sacrificing performance for lower training costs,\nVikhr features an adapted tokenizer vocabulary and undergoes the continued\npre-training and instruction tuning of all weights. This not only enhances the\nmodel's performance but also significantly improves its computational and\ncontextual efficiency. We also expanded the instruction datasets and corpora\nfor continued pre-training. The model weights, instruction sets, and code are\npublicly available.",
      "tldr_zh": "该研究针对非英语语言的 Large Language Models (LLMs) 面临的生成质量差和计算性能问题，开发了一个适应管道，用于将英语导向的预训练模型调整为高效的双语模型。Vikhr 系列开源指令调整 LLMs 由此产生，专门针对俄语，通过优化 tokenizer vocabulary 并对所有权重进行持续预训练和指令调整，显著提升了性能、计算效率和上下文处理能力。该模型还扩展了指令数据集和语料库，并公开了权重、指令集及代码，以促进进一步研究和应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13929v6",
      "published_date": "2024-05-22 18:58:58 UTC",
      "updated_date": "2025-04-14 12:23:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:26:21.840612"
    },
    {
      "arxiv_id": "2405.13911v2",
      "title": "TOPA: Extending Large Language Models for Video Understanding via Text-Only Pre-Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Li",
        "Hehe Fan",
        "Yongkang Wong",
        "Mohan Kankanhalli",
        "Yi Yang"
      ],
      "abstract": "Recent advancements in image understanding have benefited from the extensive\nuse of web image-text pairs. However, video understanding remains a challenge\ndespite the availability of substantial web video-text data. This difficulty\nprimarily arises from the inherent complexity of videos and the inefficient\nlanguage supervision in recent web-collected video-text datasets. In this\npaper, we introduce Text-Only Pre-Alignment (TOPA), a novel approach to extend\nlarge language models (LLMs) for video understanding, without the need for\npre-training on real video data. Specifically, we first employ an advanced LLM\nto automatically generate Textual Videos comprising continuous textual frames,\nalong with corresponding annotations to simulate real video-text data. Then,\nthese annotated textual videos are used to pre-align a language-only LLM with\nthe video modality. To bridge the gap between textual and real videos, we\nemploy the CLIP model as the feature extractor to align image and text\nmodalities. During text-only pre-alignment, the continuous textual frames,\nencoded as a sequence of CLIP text features, are analogous to continuous CLIP\nimage features, thus aligning the LLM with real video representation. Extensive\nexperiments, including zero-shot evaluation and finetuning on various video\nunderstanding tasks, demonstrate that TOPA is an effective and efficient\nframework for aligning video content with LLMs. In particular, without training\non any video data, the TOPA-Llama2-13B model achieves a Top-1 accuracy of 51.0%\non the challenging long-form video understanding benchmark, Egoschema. This\nperformance surpasses previous video-text pre-training approaches and proves\ncompetitive with recent GPT-3.5-based video agents.",
      "tldr_zh": "该论文提出了一种名为 Text-Only Pre-Alignment (TOPA) 的方法，用于扩展 Large Language Models (LLMs) 以实现视频理解，而无需使用真实视频数据。方法首先利用高级 LLM 生成模拟的 Textual Videos，包括连续文本帧和注释，来模拟视频-文本数据；然后，通过 CLIP 模型作为特征提取器，对齐文本帧与图像模态，从而预对齐 LLM 与视频表示。实验结果显示，TOPA-Llama2-13B 模型在 Egoschema 等基准上实现 51.0% 的零样本 Top-1 准确率，超越了传统视频-文本预训练方法，并与 GPT-3.5-based 视频代理相当。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "NeurIPS 2024 (Spotlight)",
      "pdf_url": "http://arxiv.org/pdf/2405.13911v2",
      "published_date": "2024-05-22 18:35:10 UTC",
      "updated_date": "2024-11-03 09:25:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:26:34.832996"
    },
    {
      "arxiv_id": "2405.13907v2",
      "title": "Just rephrase it! Uncertainty estimation in closed-source language models via multiple rephrased queries",
      "title_zh": "翻译失败",
      "authors": [
        "Adam Yang",
        "Chen Chen",
        "Konstantinos Pitas"
      ],
      "abstract": "State-of-the-art large language models are sometimes distributed as\nopen-source software but are also increasingly provided as a closed-source\nservice. These closed-source large-language models typically see the widest\nusage by the public, however, they often do not provide an estimate of their\nuncertainty when responding to queries. As even the best models are prone to\n``hallucinating\" false information with high confidence, a lack of a reliable\nestimate of uncertainty limits the applicability of these models in critical\nsettings. We explore estimating the uncertainty of closed-source LLMs via\nmultiple rephrasings of an original base query. Specifically, we ask the model,\nmultiple rephrased questions, and use the similarity of the answers as an\nestimate of uncertainty. We diverge from previous work in i) providing rules\nfor rephrasing that are simple to memorize and use in practice ii) proposing a\ntheoretical framework for why multiple rephrased queries obtain calibrated\nuncertainty estimates. Our method demonstrates significant improvements in the\ncalibration of uncertainty estimates compared to the baseline and provides\nintuition as to how query strategies should be designed for optimal test\ncalibration.",
      "tldr_zh": "该研究针对闭源大型语言模型（closed-source LLMs）的不确定性估计问题，提出了一种新方法，通过对原始查询进行多次改写（rephrased queries），并利用答案相似度来评估模型的不确定性，以解决模型可能“hallucinating”虚假信息的问题。与以往工作不同，该方法提供了易于记忆的改写规则，并建立了一个理论框架，解释了为什么这种策略能获得校准的uncertainty estimates。实验结果显示，该方法显著提高了不确定性估计的校准性能，并为优化查询策略提供了实用指导。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13907v2",
      "published_date": "2024-05-22 18:28:26 UTC",
      "updated_date": "2024-06-16 13:49:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:26:47.306183"
    },
    {
      "arxiv_id": "2405.13902v2",
      "title": "LOGIN: A Large Language Model Consulted Graph Neural Network Training Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Yiran Qiao",
        "Xiang Ao",
        "Yang Liu",
        "Jiarong Xu",
        "Xiaoqian Sun",
        "Qing He"
      ],
      "abstract": "Recent prevailing works on graph machine learning typically follow a similar\nmethodology that involves designing advanced variants of graph neural networks\n(GNNs) to maintain the superior performance of GNNs on different graphs. In\nthis paper, we aim to streamline the GNN design process and leverage the\nadvantages of Large Language Models (LLMs) to improve the performance of GNNs\non downstream tasks. We formulate a new paradigm, coined \"LLMs-as-Consultants,\"\nwhich integrates LLMs with GNNs in an interactive manner. A framework named\nLOGIN (LLM Consulted GNN training) is instantiated, empowering the interactive\nutilization of LLMs within the GNN training process. First, we attentively\ncraft concise prompts for spotted nodes, carrying comprehensive semantic and\ntopological information, and serving as input to LLMs. Second, we refine GNNs\nby devising a complementary coping mechanism that utilizes the responses from\nLLMs, depending on their correctness. We empirically evaluate the effectiveness\nof LOGIN on node classification tasks across both homophilic and heterophilic\ngraphs. The results illustrate that even basic GNN architectures, when employed\nwithin the proposed LLMs-as-Consultants paradigm, can achieve comparable\nperformance to advanced GNNs with intricate designs. Our codes are available at\nhttps://github.com/QiaoYRan/LOGIN.",
      "tldr_zh": "本文提出一个名为 LOGIN 的训练框架，采用 \"LLMs-as-Consultants\" 范式，将 Large Language Models (LLMs) 与 Graph Neural Networks (GNNs) 进行交互式整合，以简化 GNN 设计并提升其在下游任务中的性能。框架通过为特定节点创建包含语义和拓扑信息的简洁提示输入 LLMs，并根据 LLMs 响应的正确性设计机制来优化 GNN 训练过程。实验结果表明，在同质 (homophilic) 和异质 (heterophilic) 图上的节点分类任务中，基本 GNN 在此框架下可实现与高级 GNN 相当的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13902v2",
      "published_date": "2024-05-22 18:17:20 UTC",
      "updated_date": "2024-06-06 08:29:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:26:59.617898"
    },
    {
      "arxiv_id": "2405.13891v2",
      "title": "DeepNcode: Encoding-Based Protection against Bit-Flip Attacks on Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Patrik Velčický",
        "Jakub Breier",
        "Mladen Kovačević",
        "Xiaolu Hou"
      ],
      "abstract": "Fault injection attacks are a potent threat against embedded implementations\nof neural network models. Several attack vectors have been proposed, such as\nmisclassification, model extraction, and trojan/backdoor planting. Most of\nthese attacks work by flipping bits in the memory where quantized model\nparameters are stored.\n  In this paper, we introduce an encoding-based protection method against\nbit-flip attacks on neural networks, titled DeepNcode. We experimentally\nevaluate our proposal with several publicly available models and datasets, by\nusing state-of-the-art bit-flip attacks: BFA, T-BFA, and TA-LBF. Our results\nshow an increase in protection margin of up to $7.6\\times$ for $4-$bit and\n$12.4\\times$ for $8-$bit quantized networks. Memory overheads start at $50\\%$\nof the original network size, while the time overheads are negligible.\nMoreover, DeepNcode does not require retraining and does not change the\noriginal accuracy of the model.",
      "tldr_zh": "该论文提出 DeepNcode，一种基于编码的保护方法，用于防御神经网络中的位翻转攻击（bit-flip attacks），这些攻击通过翻转存储量化模型参数的内存位来引发误分类、模型提取或后门植入。实验结果显示，DeepNcode 在对抗状态-of-the-art 攻击如 BFA、T-BFA 和 TA-LBF 时，使 4-bit 量化网络的保护裕度提高高达 7.6 倍，8-bit 网络提高 12.4 倍。相比原模型，该方法仅需 50% 的额外内存开销，时间开销可忽略，且无需重新训练即可保持模型的原始准确率。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13891v2",
      "published_date": "2024-05-22 18:01:34 UTC",
      "updated_date": "2024-06-02 08:23:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:27:11.657941"
    },
    {
      "arxiv_id": "2405.13873v3",
      "title": "FiDeLiS: Faithful Reasoning in Large Language Model for Knowledge Graph Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Yuan Sui",
        "Yufei He",
        "Nian Liu",
        "Xiaoxin He",
        "Kun Wang",
        "Bryan Hooi"
      ],
      "abstract": "Large language models (LLMs) are often challenged by generating erroneous or\nhallucinated responses, especially in complex reasoning tasks. Leveraging\nknowledge graphs (KGs) as external knowledge sources has emerged as a viable\nsolution. However, existing KG-enhanced methods, either retrieval-based or\nagent-based, encounter difficulties in accurately retrieving knowledge and\nefficiently traversing KGs at scale. In this paper, we propose a unified\nframework, FiDeLiS, designed to improve the factuality of LLM responses by\nanchoring answers to verifiable reasoning steps retrieved from a KG. To achieve\nthis, we leverage step-wise beam search with a deductive scoring function,\nallowing the LLM to validate each reasoning step and halt the search once the\nquestion is deducible. In addition, our Path-rag module pre-selects a smaller\ncandidate set for each beam search step, reducing computational costs by\nnarrowing the search space. Extensive experiments show that our training-free\nand efficient approach outperforms strong baselines, enhancing both factuality\nand interpretability.",
      "tldr_zh": "该论文提出 FiDeLiS 框架，以提升大型语言模型 (LLMs) 在知识图谱问答 (KGQA) 中的事实性，解决现有方法在知识检索和图谱遍历方面的不足。框架通过步进式 beam search 和演绎评分函数，让 LLMs 验证每个推理步骤，并在问题可推断时停止搜索，同时 Path-rag 模块预选候选集以减少计算成本。实验结果表明，这种无需训练的高效方法优于强基线，提升了响应的真实性和可解释性。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13873v3",
      "published_date": "2024-05-22 17:56:53 UTC",
      "updated_date": "2025-02-19 08:29:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:27:24.558893"
    },
    {
      "arxiv_id": "2405.13872v2",
      "title": "Image-of-Thought Prompting for Visual Reasoning Refinement in Multimodal Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Qiji Zhou",
        "Ruochen Zhou",
        "Zike Hu",
        "Panzhong Lu",
        "Siyang Gao",
        "Yue Zhang"
      ],
      "abstract": "Recent advancements in Chain-of-Thought (CoT) and related rationale-based\nworks have significantly improved the performance of Large Language Models\n(LLMs) in complex reasoning tasks. With the evolution of Multimodal Large\nLanguage Models (MLLMs), enhancing their capability to tackle complex\nmultimodal reasoning problems is a crucial frontier. However, incorporating\nmultimodal rationales in CoT has yet to be thoroughly investigated. We propose\nthe Image-of-Thought (IoT) prompting method, which helps MLLMs to extract\nvisual rationales step-by-step. Specifically, IoT prompting can automatically\ndesign critical visual information extraction operations based on the input\nimages and questions. Each step of visual information refinement identifies\nspecific visual rationales that support answers to complex visual reasoning\nquestions. Beyond the textual CoT, IoT simultaneously utilizes visual and\ntextual rationales to help MLLMs understand complex multimodal information. IoT\nprompting has improved zero-shot visual reasoning performance across various\nvisual understanding tasks in different MLLMs. Moreover, the step-by-step\nvisual feature explanations generated by IoT prompting elucidate the visual\nreasoning process, aiding in analyzing the cognitive processes of large\nmultimodal models",
      "tldr_zh": "该论文提出Image-of-Thought (IoT) prompting方法，以提升Multimodal Large Language Models (MLLMs)在复杂多模态推理任务中的性能，特别是针对视觉推理的不足。IoT通过逐步提取视觉依据，例如基于输入图像和问题自动设计关键信息提取操作，并结合视觉和文本推理，帮助MLLMs更准确地回答复杂视觉问题。实验结果显示，IoT在各种零样本视觉理解任务中显著提高了模型性能，并提供了逐步视觉特征解释，以分析MLLMs的认知过程。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "Correct the case title",
      "pdf_url": "http://arxiv.org/pdf/2405.13872v2",
      "published_date": "2024-05-22 17:56:51 UTC",
      "updated_date": "2024-05-29 02:24:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:27:35.705548"
    },
    {
      "arxiv_id": "2405.13867v2",
      "title": "Scaling-laws for Large Time-series Models",
      "title_zh": "翻译失败",
      "authors": [
        "Thomas D. P. Edwards",
        "James Alvey",
        "Justin Alsing",
        "Nam H. Nguyen",
        "Benjamin D. Wandelt"
      ],
      "abstract": "Scaling laws for large language models (LLMs) have provided useful guidance\nin training ever larger models for predictable performance gains. Time series\nforecasting shares a similar sequential structure to language, and is amenable\nto large-scale transformer architectures. Here we show that foundational\ndecoder-only time series transformer models exhibit analogous scaling-behavior\nto LLMs, with architectural details (aspect ratio and number of heads) having a\nminimal effect over broad ranges. We assemble a large corpus of heterogenous\ntime series data on which to train, and establish for the first time power-law\nscaling with parameter count, dataset size, and training compute, spanning five\norders of magnitude.",
      "tldr_zh": "这篇论文探索了大型时间序列模型的缩放定律（scaling laws），类似于大型语言模型 (LLMs) 的行为，用于指导模型训练以获得可预测的性能提升。作者使用基础的解码器-only transformer 架构训练了一个大规模的异构时间序列数据集，发现参数数量、数据集大小和训练计算遵循幂律缩放（power-law scaling），跨越五个数量级。实验结果显示，模型架构细节（如宽高比和头数）在广泛范围内影响最小，为优化时间序列预测模型提供了宝贵指导。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "4 main pages (16 total), 4 figures; Accepted for oral presentation in\n  Time Series in the Age of Large Models (TSALM) Workshop at Neurips 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.13867v2",
      "published_date": "2024-05-22 17:48:17 UTC",
      "updated_date": "2025-01-08 14:08:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:27:47.136501"
    },
    {
      "arxiv_id": "2405.13864v1",
      "title": "Just rotate it! Uncertainty estimation in closed-source models via multiple queries",
      "title_zh": "翻译失败",
      "authors": [
        "Konstantinos Pitas",
        "Julyan Arbel"
      ],
      "abstract": "We propose a simple and effective method to estimate the uncertainty of\nclosed-source deep neural network image classification models. Given a base\nimage, our method creates multiple transformed versions and uses them to query\nthe top-1 prediction of the closed-source model. We demonstrate significant\nimprovements in the calibration of uncertainty estimates compared to the naive\nbaseline of assigning 100\\% confidence to all predictions. While we initially\nexplore Gaussian perturbations, our empirical findings indicate that natural\ntransformations, such as rotations and elastic deformations, yield even\nbetter-calibrated predictions. Furthermore, through empirical results and a\nstraightforward theoretical analysis, we elucidate the reasons behind the\nsuperior performance of natural transformations over Gaussian noise. Leveraging\nthese insights, we propose a transfer learning approach that further improves\nour calibration results.",
      "tldr_zh": "该研究提出了一种简单有效的“旋转它！”方法，用于估算封闭源（closed-source）深度神经网络图像分类模型的不确定性（uncertainty estimation）。方法通过对基础图像创建多个变换版本（如旋转和弹性变形），并查询模型的 top-1 预测，来显著改善不确定性估算的校准性能，比简单基线（100%置信度）表现更优。实证结果和理论分析显示，自然变换（如旋转）比高斯扰动（Gaussian perturbations）更有效，因为它们更好地捕捉图像变异。基于这些见解，作者进一步提出了一种转移学习（transfer learning）方法，提升了整体校准结果。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13864v1",
      "published_date": "2024-05-22 17:45:38 UTC",
      "updated_date": "2024-05-22 17:45:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:28:00.166162"
    },
    {
      "arxiv_id": "2405.13863v2",
      "title": "Dynamic Model Predictive Shielding for Provably Safe Reinforcement Learning",
      "title_zh": "动态模型预测屏蔽用于可证明安全强化学习",
      "authors": [
        "Arko Banerjee",
        "Kia Rahmani",
        "Joydeep Biswas",
        "Isil Dillig"
      ],
      "abstract": "Among approaches for provably safe reinforcement learning, Model Predictive\nShielding (MPS) has proven effective at complex tasks in continuous,\nhigh-dimensional state spaces, by leveraging a backup policy to ensure safety\nwhen the learned policy attempts to take risky actions. However, while MPS can\nensure safety both during and after training, it often hinders task progress\ndue to the conservative and task-oblivious nature of backup policies. This\npaper introduces Dynamic Model Predictive Shielding (DMPS), which optimizes\nreinforcement learning objectives while maintaining provable safety. DMPS\nemploys a local planner to dynamically select safe recovery actions that\nmaximize both short-term progress as well as long-term rewards. Crucially, the\nplanner and the neural policy play a synergistic role in DMPS. When planning\nrecovery actions for ensuring safety, the planner utilizes the neural policy to\nestimate long-term rewards, allowing it to observe beyond its short-term\nplanning horizon. Conversely, the neural policy under training learns from the\nrecovery plans proposed by the planner, converging to policies that are both\nhigh-performing and safe in practice. This approach guarantees safety during\nand after training, with bounded recovery regret that decreases exponentially\nwith planning horizon depth. Experimental results demonstrate that DMPS\nconverges to policies that rarely require shield interventions after training\nand achieve higher rewards compared to several state-of-the-art baselines.",
      "tldr_zh": "本论文提出 Dynamic Model Predictive Shielding (DMPS)，一种优化强化学习(Reinforcement Learning)目标同时确保可证明安全性的框架，以解决传统 Model Predictive Shielding (MPS) 因备份策略过于保守而阻碍任务进展的问题。DMPS 采用本地规划器动态选择安全的恢复动作，结合神经策略评估长期奖励，实现短期进展与长期回报的最大化，并使神经策略从规划器的恢复计划中学习。实验结果表明，DMPS 在训练前后均能保证安全，恢复遗憾(bounded recovery regret)随规划深度指数级减少，且其收敛策略比现有基线实现更高奖励并减少盾干预。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Presented at Neurips 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.13863v2",
      "published_date": "2024-05-22 17:44:07 UTC",
      "updated_date": "2024-12-20 23:55:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:28:12.419846"
    },
    {
      "arxiv_id": "2405.17455v1",
      "title": "WeatherFormer: A Pretrained Encoder Model for Learning Robust Weather Representations from Small Datasets",
      "title_zh": "翻译失败",
      "authors": [
        "Adib Hasan",
        "Mardavij Roozbehani",
        "Munther Dahleh"
      ],
      "abstract": "This paper introduces WeatherFormer, a transformer encoder-based model\ndesigned to learn robust weather features from minimal observations. It\naddresses the challenge of modeling complex weather dynamics from small\ndatasets, a bottleneck for many prediction tasks in agriculture, epidemiology,\nand climate science. WeatherFormer was pretrained on a large pretraining\ndataset comprised of 39 years of satellite measurements across the Americas.\nWith a novel pretraining task and fine-tuning, WeatherFormer achieves\nstate-of-the-art performance in county-level soybean yield prediction and\ninfluenza forecasting. Technical innovations include a unique spatiotemporal\nencoding that captures geographical, annual, and seasonal variations, adapting\nthe transformer architecture to continuous weather data, and a pretraining\nstrategy to learn representations that are robust to missing weather features.\nThis paper for the first time demonstrates the effectiveness of pretraining\nlarge transformer encoder models for weather-dependent applications across\nmultiple domains.",
      "tldr_zh": "这篇论文介绍了 WeatherFormer，一种基于 Transformer 编码器的预训练模型，旨在从小型数据集学习鲁棒的天气表示，以应对农业、流行病学和气候科学等领域的复杂天气动态建模挑战。模型在涵盖 39 年卫星测量数据的庞大数据集上进行预训练，采用创新的时空编码技术捕捉地理、年度和季节变化，并通过预训练策略增强对缺失特征的鲁棒性。实验结果显示，WeatherFormer 在县一级大豆产量预测和流感预测任务中实现了最先进性能，并首次证明了预训练大型 Transformer 编码器模型在多领域天气应用的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "physics.ao-ph",
        "stat.ML"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17455v1",
      "published_date": "2024-05-22 17:43:46 UTC",
      "updated_date": "2024-05-22 17:43:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:28:23.878766"
    },
    {
      "arxiv_id": "2405.13845v3",
      "title": "Semantic Density: Uncertainty Quantification for Large Language Models through Confidence Measurement in Semantic Space",
      "title_zh": "语义密度：通过在语义空间中进行置信度测量来量化大型语言模型的不确定",
      "authors": [
        "Xin Qiu",
        "Risto Miikkulainen"
      ],
      "abstract": "With the widespread application of Large Language Models (LLMs) to various\ndomains, concerns regarding the trustworthiness of LLMs in safety-critical\nscenarios have been raised, due to their unpredictable tendency to hallucinate\nand generate misinformation. Existing LLMs do not have an inherent\nfunctionality to provide the users with an uncertainty/confidence metric for\neach response it generates, making it difficult to evaluate trustworthiness.\nAlthough several studies aim to develop uncertainty quantification methods for\nLLMs, they have fundamental limitations, such as being restricted to\nclassification tasks, requiring additional training and data, considering only\nlexical instead of semantic information, and being prompt-wise but not\nresponse-wise. A new framework is proposed in this paper to address these\nissues. Semantic density extracts uncertainty/confidence information for each\nresponse from a probability distribution perspective in semantic space. It has\nno restriction on task types and is \"off-the-shelf\" for new models and tasks.\nExperiments on seven state-of-the-art LLMs, including the latest Llama 3 and\nMixtral-8x22B models, on four free-form question-answering benchmarks\ndemonstrate the superior performance and robustness of semantic density\ncompared to prior approaches.",
      "tldr_zh": "该论文探讨了Large Language Models (LLMs) 在安全关键场景中可能产生幻觉和误信息的风险，并提出Semantic Density 框架来量化不确定性。该框架通过在语义空间中从概率分布视角测量每个响应的置信度信息，避免了现有方法的限制，如仅限于分类任务、需要额外训练或忽略语义层面。实验在七个最先进LLMs（如Llama 3和Mixtral-8x22B）上进行，覆盖四个自由形式问答基准，结果显示Semantic Density 比现有方法更具性能和鲁棒性，为提升LLMs的可信度提供了高效的“即用型”解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to Neurips 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.13845v3",
      "published_date": "2024-05-22 17:13:49 UTC",
      "updated_date": "2024-11-01 13:25:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:28:34.839955"
    },
    {
      "arxiv_id": "2405.13832v1",
      "title": "Federated Learning in Healthcare: Model Misconducts, Security, Challenges, Applications, and Future Research Directions -- A Systematic Review",
      "title_zh": "翻译失败",
      "authors": [
        "Md Shahin Ali",
        "Md Manjurul Ahsan",
        "Lamia Tasnim",
        "Sadia Afrin",
        "Koushik Biswas",
        "Md Maruf Hossain",
        "Md Mahfuz Ahmed",
        "Ronok Hashan",
        "Md Khairul Islam",
        "Shivakumar Raman"
      ],
      "abstract": "Data privacy has become a major concern in healthcare due to the increasing\ndigitization of medical records and data-driven medical research. Protecting\nsensitive patient information from breaches and unauthorized access is\ncritical, as such incidents can have severe legal and ethical complications.\nFederated Learning (FL) addresses this concern by enabling multiple healthcare\ninstitutions to collaboratively learn from decentralized data without sharing\nit. FL's scope in healthcare covers areas such as disease prediction, treatment\ncustomization, and clinical trial research. However, implementing FL poses\nchallenges, including model convergence in non-IID (independent and identically\ndistributed) data environments, communication overhead, and managing\nmulti-institutional collaborations. A systematic review of FL in healthcare is\nnecessary to evaluate how effectively FL can provide privacy while maintaining\nthe integrity and usability of medical data analysis. In this study, we analyze\nexisting literature on FL applications in healthcare. We explore the current\nstate of model security practices, identify prevalent challenges, and discuss\npractical applications and their implications. Additionally, the review\nhighlights promising future research directions to refine FL implementations,\nenhance data security protocols, and expand FL's use to broader healthcare\napplications, which will benefit future researchers and practitioners.",
      "tldr_zh": "这篇论文对Federated Learning (FL) 在医疗领域的应用进行了系统文献综述，重点探讨了FL如何在保护患者数据隐私的同时，实现多机构协作学习，以支持疾病预测、治疗定制和临床试验等应用。研究分析了FL面临的挑战，包括模型收敛问题在non-IID数据环境下的困难、通信开销以及多机构协作管理，并评估了当前的模型安全实践和潜在不当行为。最终，该综述指出了未来研究方向，如优化FL实施、加强数据安全协议，并扩展其在更广泛医疗场景中的应用，以指导研究者和从业者。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13832v1",
      "published_date": "2024-05-22 16:59:50 UTC",
      "updated_date": "2024-05-22 16:59:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:28:47.115385"
    },
    {
      "arxiv_id": "2405.13828v2",
      "title": "Babysit A Language Model From Scratch: Interactive Language Learning by Trials and Demonstrations",
      "title_zh": "从零开始指导一个语言模型：通过试错",
      "authors": [
        "Ziqiao Ma",
        "Zekun Wang",
        "Joyce Chai"
      ],
      "abstract": "Humans are efficient language learners and inherently social creatures. Our\nlanguage development is largely shaped by our social interactions, for example,\nthe demonstration and feedback from caregivers. Contrary to human language\nlearning, recent advancements in large language models have primarily adopted a\nnon-interactive training paradigm, and refined pre-trained models through\nfeedback afterward. In this work, we explore how corrective feedback from\ninteractions influences neural language acquisition from scratch through\nsystematically controlled experiments, assessing whether it contributes to word\nlearning efficiency in language models. We introduce a trial-and-demonstration\n(TnD) learning framework that incorporates three distinct components: student\ntrials, teacher demonstrations, and a reward conditioned on language competence\nat various developmental stages. Our experiments reveal that the TnD approach\naccelerates word acquisition for student models of equal and smaller numbers of\nparameters, and we highlight the significance of both trials and\ndemonstrations. We further show that the teacher's choices of words influence\nstudents' word-specific learning efficiency, and a practice-makes-perfect\neffect is evident by a strong correlation between the frequency of words in\ntrials and their respective learning curves. Our findings suggest that\ninteractive language learning, with teacher demonstrations and active trials,\ncan facilitate efficient word learning in language models.",
      "tldr_zh": "本文探讨了互动反馈如何促进语言模型从零开始的语言学习，类似于人类通过社交互动（如照顾者的示范和反馈）发展语言的能力。研究引入了 trial-and-demonstration (TnD) 框架，包括学生尝试、教师示范和基于语言能力的奖励系统。实验结果显示，TnD 方法显著加速了学生模型的单词获取，尤其在参数数量相等或更小的模型中，并强调了尝试和示范的重要性。此外，教师的单词选择和频率会影响学生的学习效率，证明互动学习能提升语言模型的整体效率。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL 2025 (Main) & Workshop on Large Language Models and Cognition @\n  ICML 2024 (Oral)",
      "pdf_url": "http://arxiv.org/pdf/2405.13828v2",
      "published_date": "2024-05-22 16:57:02 UTC",
      "updated_date": "2025-04-18 16:06:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:28:59.394133"
    },
    {
      "arxiv_id": "2405.13810v1",
      "title": "Leveraging 2D Information for Long-term Time Series Forecasting with Vanilla Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Xin Cheng",
        "Xiuying Chen",
        "Shuqi Li",
        "Di Luo",
        "Xun Wang",
        "Dongyan Zhao",
        "Rui Yan"
      ],
      "abstract": "Time series prediction is crucial for understanding and forecasting complex\ndynamics in various domains, ranging from finance and economics to climate and\nhealthcare. Based on Transformer architecture, one approach involves encoding\nmultiple variables from the same timestamp into a single temporal token to\nmodel global dependencies. In contrast, another approach embeds the time points\nof individual series into separate variate tokens. The former method faces\nchallenges in learning variate-centric representations, while the latter risks\nmissing essential temporal information critical for accurate forecasting. In\nour work, we introduce GridTST, a model that combines the benefits of two\napproaches using innovative multi-directional attentions based on a vanilla\nTransformer. We regard the input time series data as a grid, where the $x$-axis\nrepresents the time steps and the $y$-axis represents the variates. A vertical\nslicing of this grid combines the variates at each time step into a\n\\textit{time token}, while a horizontal slicing embeds the individual series\nacross all time steps into a \\textit{variate token}. Correspondingly, a\n\\textit{horizontal attention mechanism} focuses on time tokens to comprehend\nthe correlations between data at various time steps, while a \\textit{vertical},\nvariate-aware \\textit{attention} is employed to grasp multivariate\ncorrelations. This combination enables efficient processing of information\nacross both time and variate dimensions, thereby enhancing the model's\nanalytical strength. % We also integrate the patch technique, segmenting time\ntokens into subseries-level patches, ensuring that local semantic information\nis retained in the embedding. The GridTST model consistently delivers\nstate-of-the-art performance across various real-world datasets.",
      "tldr_zh": "时间序列预测在多个领域（如金融和气候）中至关重要，但基于 Transformer 的现有方法要么难以学习变量相关的表示，要么忽略关键的时间信息。研究提出 GridTST 模型，利用 vanilla Transformer 的创新多向注意力机制，将输入数据视为一个网格（x 轴为时间步，y 轴为变量），通过水平注意力关注时间 token 以捕捉时间相关性，以及垂直注意力把握多变量相关性，从而高效处理时间和变量维度。实验结果显示，GridTST 在各种真实数据集上实现了最先进性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13810v1",
      "published_date": "2024-05-22 16:41:21 UTC",
      "updated_date": "2024-05-22 16:41:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:29:11.595043"
    },
    {
      "arxiv_id": "2405.13805v2",
      "title": "Perceptual Fairness in Image Restoration",
      "title_zh": "图像恢复中的感知公平性",
      "authors": [
        "Guy Ohayon",
        "Michael Elad",
        "Tomer Michaeli"
      ],
      "abstract": "Fairness in image restoration tasks is the desire to treat different\nsub-groups of images equally well. Existing definitions of fairness in image\nrestoration are highly restrictive. They consider a reconstruction to be a\ncorrect outcome for a group (e.g., women) only if it falls within the group's\nset of ground truth images (e.g., natural images of women); otherwise, it is\nconsidered entirely incorrect. Consequently, such definitions are prone to\ncontroversy, as errors in image restoration can manifest in various ways. In\nthis work we offer an alternative approach towards fairness in image\nrestoration, by considering the Group Perceptual Index (GPI), which we define\nas the statistical distance between the distribution of the group's ground\ntruth images and the distribution of their reconstructions. We assess the\nfairness of an algorithm by comparing the GPI of different groups, and say that\nit achieves perfect Perceptual Fairness (PF) if the GPIs of all groups are\nidentical. We motivate and theoretically study our new notion of fairness, draw\nits connection to previous ones, and demonstrate its utility on\nstate-of-the-art face image restoration algorithms.",
      "tldr_zh": "本研究探讨图像恢复任务中的公平性问题，指出现有定义过于严格，仅将重建图像视为组内正确结果，导致潜在争议。作者提出一种新方法，使用 Group Perceptual Index (GPI) 来衡量组的真实图像分布与重建图像分布之间的统计距离，并定义 Perceptual Fairness (PF) 为不同组的 GPI 完全相等。理论分析了该概念与其前人定义的联系，并在最先进的面部图像恢复算法上验证了其实用性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13805v2",
      "published_date": "2024-05-22 16:32:20 UTC",
      "updated_date": "2024-10-12 12:43:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:29:22.541760"
    },
    {
      "arxiv_id": "2405.13800v2",
      "title": "Dense Connector for MLLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Huanjin Yao",
        "Wenhao Wu",
        "Taojiannan Yang",
        "YuXin Song",
        "Mengxi Zhang",
        "Haocheng Feng",
        "Yifan Sun",
        "Zhiheng Li",
        "Wanli Ouyang",
        "Jingdong Wang"
      ],
      "abstract": "Do we fully leverage the potential of visual encoder in Multimodal Large\nLanguage Models (MLLMs)? The recent outstanding performance of MLLMs in\nmultimodal understanding has garnered broad attention from both academia and\nindustry. In the current MLLM rat race, the focus seems to be predominantly on\nthe linguistic side. We witness the rise of larger and higher-quality\ninstruction datasets, as well as the involvement of larger-sized LLMs. Yet,\nscant attention has been directed towards the visual signals utilized by MLLMs,\noften assumed to be the final high-level features extracted by a frozen visual\nencoder. In this paper, we introduce the Dense Connector - a simple, effective,\nand plug-and-play vision-language connector that significantly enhances\nexisting MLLMs by leveraging multi-layer visual features, with minimal\nadditional computational overhead. Building on this, we also propose the\nEfficient Dense Connector, which achieves performance comparable to LLaVA-v1.5\nwith only 25% of the visual tokens. Furthermore, our model, trained solely on\nimages, showcases remarkable zero-shot capabilities in video understanding as\nwell. Experimental results across various vision encoders, image resolutions,\ntraining dataset scales, varying sizes of LLMs (2.7B->70B), and diverse\narchitectures of MLLMs (e.g., LLaVA-v1.5, LLaVA-NeXT and Mini-Gemini) validate\nthe versatility and scalability of our approach, achieving state-of-the-art\nperformance across 19 image and video benchmarks. We hope that this work will\nprovide valuable experience and serve as a basic module for future MLLM\ndevelopment. Code is available at https://github.com/HJYao00/DenseConnector .",
      "tldr_zh": "该论文质疑现有的 Multimodal Large Language Models (MLLMs) 是否充分利用视觉编码器，提出 Dense Connector 作为一种简单、有效且即插即用的视觉-语言连接器，通过整合多层视觉特征来显著提升 MLLMs 的性能，同时仅增加微小计算开销。作者进一步开发了 Efficient Dense Connector，仅使用 25% 的视觉 tokens 便达到与 LLaVA-v1.5 相当的表现，并在图像训练后展示出优秀的零样本视频理解能力。实验结果证明，该方法在多种视觉编码器、图像分辨率、数据集规模和 LLM 大小（从 2.7B 到 70B）上实现了 19 个图像和视频基准的最先进性能，并有望作为未来 MLLM 发展的基础模块。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "27 pages, NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.13800v2",
      "published_date": "2024-05-22 16:25:03 UTC",
      "updated_date": "2024-11-14 23:53:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:29:34.784737"
    },
    {
      "arxiv_id": "2405.13798v3",
      "title": "Slaves to the Law of Large Numbers: An Asymptotic Equipartition Property for Perplexity in Generative Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Avinash Mudireddy",
        "Tyler Bell",
        "Raghu Mudumbai"
      ],
      "abstract": "We prove a new asymptotic equipartition property for the perplexity of long\ntexts generated by a language model and present supporting experimental\nevidence from open-source models. Specifically we show that the logarithmic\nperplexity of any large text generated by a language model must asymptotically\nconverge to the average entropy of its token distributions. This defines a\n\"typical set\" that all long synthetic texts generated by a language model must\nbelong to. We show that this typical set is a vanishingly small subset of all\npossible grammatically correct outputs. These results suggest possible\napplications to important practical problems such as (a) detecting synthetic\nAI-generated text, and (b) testing whether a text was used to train a language\nmodel. We make no simplifying assumptions (such as stationarity) about the\nstatistics of language model outputs, and therefore our results are directly\napplicable to practical real-world models without any approximations.",
      "tldr_zh": "本文证明了生成语言模型长文本的 perplexity 具有一个新的 asymptotic equipartition property，即其 logarithmic perplexity 会渐进收敛到 token 分布的 average entropy，从而定义了一个“typical set”，所有长合成文本必须属于此极小子集。实验证据来自开源模型，支持了这一属性在实际应用中的有效性。该发现无需简化假设（如 stationarity），可用于检测 AI 生成文本和测试文本是否用于训练模型。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13798v3",
      "published_date": "2024-05-22 16:23:40 UTC",
      "updated_date": "2025-01-30 12:03:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:29:47.310796"
    },
    {
      "arxiv_id": "2405.13796v5",
      "title": "Generalizing Weather Forecast to Fine-grained Temporal Scales via Physics-AI Hybrid Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Wanghan Xu",
        "Fenghua Ling",
        "Wenlong Zhang",
        "Tao Han",
        "Hao Chen",
        "Wanli Ouyang",
        "Lei Bai"
      ],
      "abstract": "Data-driven artificial intelligence (AI) models have made significant\nadvancements in weather forecasting, particularly in medium-range and\nnowcasting. However, most data-driven weather forecasting models are black-box\nsystems that focus on learning data mapping rather than fine-grained physical\nevolution in the time dimension. Consequently, the limitations in the temporal\nscale of datasets prevent these models from forecasting at finer time scales.\nThis paper proposes a physics-AI hybrid model (i.e., WeatherGFT) which\ngeneralizes weather forecasts to finer-grained temporal scales beyond training\ndataset. Specifically, we employ a carefully designed PDE kernel to simulate\nphysical evolution on a small time scale (e.g., 300 seconds) and use a parallel\nneural networks with a learnable router for bias correction. Furthermore, we\nintroduce a lead time-aware training framework to promote the generalization of\nthe model at different lead times. The weight analysis of physics-AI modules\nindicates that physics conducts major evolution while AI performs corrections\nadaptively. Extensive experiments show that WeatherGFT trained on an hourly\ndataset, effectively generalizes forecasts across multiple time scales,\nincluding 30-minute, which is even smaller than the dataset's temporal\nresolution.",
      "tldr_zh": "该论文探讨了数据驱动的AI天气预报模型在细粒度时间尺度上的局限性，这些模型往往是黑箱系统，专注于数据映射而非物理演化，导致无法超越数据集的时间分辨率。研究提出了一种Physics-AI Hybrid Modeling框架，即WeatherGFT，通过精心设计的PDE kernel模拟小时间尺度（如300秒）的物理演化，并结合并行神经网络和可学习路由器进行偏差修正，同时引入lead time-aware训练框架以提升模型在不同预报时长的泛化能力。权重分析显示，物理模块主导主要演化，而AI模块进行自适应修正；实验结果表明，WeatherGFT在小时级数据集上训练后，能有效泛化到更细的时间尺度，包括30分钟级别。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13796v5",
      "published_date": "2024-05-22 16:21:02 UTC",
      "updated_date": "2025-01-13 06:35:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:30:00.149776"
    },
    {
      "arxiv_id": "2405.13792v2",
      "title": "xRAG: Extreme Context Compression for Retrieval-augmented Generation with One Token",
      "title_zh": "xRAG：极致上下文压缩用于检索增强生成，仅用一个标记",
      "authors": [
        "Xin Cheng",
        "Xun Wang",
        "Xingxing Zhang",
        "Tao Ge",
        "Si-Qing Chen",
        "Furu Wei",
        "Huishuai Zhang",
        "Dongyan Zhao"
      ],
      "abstract": "This paper introduces xRAG, an innovative context compression method tailored\nfor retrieval-augmented generation. xRAG reinterprets document embeddings in\ndense retrieval--traditionally used solely for retrieval--as features from the\nretrieval modality. By employing a modality fusion methodology, xRAG seamlessly\nintegrates these embeddings into the language model representation space,\neffectively eliminating the need for their textual counterparts and achieving\nan extreme compression rate. In xRAG, the only trainable component is the\nmodality bridge, while both the retriever and the language model remain frozen.\nThis design choice allows for the reuse of offline-constructed document\nembeddings and preserves the plug-and-play nature of retrieval augmentation.\nExperimental results demonstrate that xRAG achieves an average improvement of\nover 10% across six knowledge-intensive tasks, adaptable to various language\nmodel backbones, ranging from a dense 7B model to an 8x7B Mixture of Experts\nconfiguration. xRAG not only significantly outperforms previous context\ncompression methods but also matches the performance of uncompressed models on\nseveral datasets, while reducing overall FLOPs by a factor of 3.53. Our work\npioneers new directions in retrieval-augmented generation from the perspective\nof multimodality fusion, and we hope it lays the foundation for future\nefficient and scalable retrieval-augmented systems",
      "tldr_zh": "这篇论文引入了xRAG，一种针对Retrieval-augmented Generation的创新上下文压缩方法，通过模态融合(modality fusion)将文档嵌入重新解释为检索模态特征，并无缝整合到语言模型表示空间中，从而实现以一个token的极致压缩，同时仅训练模态桥(modality bridge)而保持检索器和语言模型冻结。xRAG允许重用离线构建的文档嵌入，保留了检索增强的即插即用特性。实验结果显示，该方法在六个知识密集型任务上平均提升超过10%，适用于从7B模型到8x7B Mixture of Experts等多种骨干模型，并在多个数据集上匹配未压缩模型的性能，同时将FLOPs减少3.53倍，为多模态融合视角下的高效检索增强系统奠定基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "Neurips 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.13792v2",
      "published_date": "2024-05-22 16:15:17 UTC",
      "updated_date": "2024-12-09 06:07:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:30:12.872067"
    },
    {
      "arxiv_id": "2405.13786v1",
      "title": "Towards Explainable Test Case Prioritisation with Learning-to-Rank Models",
      "title_zh": "翻译失败",
      "authors": [
        "Aurora Ramírez",
        "Mario Berrios",
        "José Raúl Romero",
        "Robert Feldt"
      ],
      "abstract": "Test case prioritisation (TCP) is a critical task in regression testing to\nensure quality as software evolves. Machine learning has become a common way to\nachieve it. In particular, learning-to-rank (LTR) algorithms provide an\neffective method of ordering and prioritising test cases. However, their use\nposes a challenge in terms of explainability, both globally at the model level\nand locally for particular results. Here, we present and discuss scenarios that\nrequire different explanations and how the particularities of TCP (multiple\nbuilds over time, test case and test suite variations, etc.) could influence\nthem. We include a preliminary experiment to analyse the similarity of\nexplanations, showing that they do not only vary depending on test\ncase-specific predictions, but also on the relative ranks.",
      "tldr_zh": "该研究探讨了测试用例优先级排序 (TCP) 在回归测试中的关键作用，并使用 Learning-to-Rank (LTR) 算法来优化测试用例的排序。然而，LTR 模型面临解释性挑战，包括全局模型级和局部预测级的解释问题。论文分析了不同解释场景（如多个构建、测试用例变异等）如何受 TCP 特性的影响，并通过初步实验证明，解释不仅取决于特定测试用例的预测，还与相对排名相关，从而为提升 TCP 的可解释性提供了见解。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "D.2.5; I.2.6"
      ],
      "primary_category": "cs.SE",
      "comment": "3rd International Workshop on Artificial Intelligence in Software\n  Testing (AIST) - International Conference on Software Testing and Validation\n  (ICST)",
      "pdf_url": "http://arxiv.org/pdf/2405.13786v1",
      "published_date": "2024-05-22 16:11:45 UTC",
      "updated_date": "2024-05-22 16:11:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:30:22.829883"
    },
    {
      "arxiv_id": "2405.13785v2",
      "title": "Efficient Two-Stage Gaussian Process Regression Via Automatic Kernel Search and Subsampling",
      "title_zh": "高效二阶段高斯过程",
      "authors": [
        "Shifan Zhao",
        "Jiaying Lu",
        "Ji Yang",
        "Edmond Chow",
        "Yuanzhe Xi"
      ],
      "abstract": "Gaussian Process Regression (GPR) is widely used in statistics and machine\nlearning for prediction tasks requiring uncertainty measures. Its efficacy\ndepends on the appropriate specification of the mean function, covariance\nkernel function, and associated hyperparameters. Severe misspecifications can\nlead to inaccurate results and problematic consequences, especially in\nsafety-critical applications. However, a systematic approach to handle these\nmisspecifications is lacking in the literature. In this work, we propose a\ngeneral framework to address these issues. Firstly, we introduce a flexible\ntwo-stage GPR framework that separates mean prediction and uncertainty\nquantification (UQ) to prevent mean misspecification, which can introduce bias\ninto the model. Secondly, kernel function misspecification is addressed through\na novel automatic kernel search algorithm, supported by theoretical analysis,\nthat selects the optimal kernel from a candidate set. Additionally, we propose\na subsampling-based warm-start strategy for hyperparameter initialization to\nimprove efficiency and avoid hyperparameter misspecification. With much lower\ncomputational cost, our subsampling-based strategy can yield competitive or\nbetter performance than training exclusively on the full dataset. Combining all\nthese components, we recommend two GPR methods-exact and scalable-designed to\nmatch available computational resources and specific UQ requirements. Extensive\nevaluation on real-world datasets, including UCI benchmarks and a\nsafety-critical medical case study, demonstrates the robustness and precision\nof our methods.",
      "tldr_zh": "本论文针对 Gaussian Process Regression (GPR) 中均值函数、核函数和超参数的错误指定问题，提出一个高效的两阶段框架，以分离均值预测和不确定性量化 (UQ)，从而避免偏差引入。论文引入一个新型自动核搜索算法，支持理论分析，从候选集选择最优核函数，并结合子采样-based 暖启动策略来优化超参数初始化，提高计算效率，同时保持或提升性能。实验在 UCI 基准数据集和医疗案例上验证了该方法的鲁棒性和精确性，展示了其在资源有限场景下的实际应用价值。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.PR",
        "stat.ML",
        "G.3; J.3"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13785v2",
      "published_date": "2024-05-22 16:11:29 UTC",
      "updated_date": "2024-09-19 13:44:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:30:35.809061"
    },
    {
      "arxiv_id": "2405.13779v1",
      "title": "Robust Disaster Assessment from Aerial Imagery Using Text-to-Image Synthetic Data",
      "title_zh": "翻译失败",
      "authors": [
        "Tarun Kalluri",
        "Jihyeon Lee",
        "Kihyuk Sohn",
        "Sahil Singla",
        "Manmohan Chandraker",
        "Joseph Xu",
        "Jeremiah Liu"
      ],
      "abstract": "We present a simple and efficient method to leverage emerging text-to-image\ngenerative models in creating large-scale synthetic supervision for the task of\ndamage assessment from aerial images. While significant recent advances have\nresulted in improved techniques for damage assessment using aerial or satellite\nimagery, they still suffer from poor robustness to domains where manual labeled\ndata is unavailable, directly impacting post-disaster humanitarian assistance\nin such under-resourced geographies. Our contribution towards improving domain\nrobustness in this scenario is two-fold. Firstly, we leverage the text-guided\nmask-based image editing capabilities of generative models and build an\nefficient and easily scalable pipeline to generate thousands of post-disaster\nimages from low-resource domains. Secondly, we propose a simple two-stage\ntraining approach to train robust models while using manual supervision from\ndifferent source domains along with the generated synthetic target domain data.\nWe validate the strength of our proposed framework under cross-geography domain\ntransfer setting from xBD and SKAI images in both single-source and\nmulti-source settings, achieving significant improvements over a source-only\nbaseline in each case.",
      "tldr_zh": "该研究提出了一种简单高效的方法，利用文本到图像生成模型创建大规模合成数据，以提升从航拍图像中评估灾害破坏的鲁棒性。方法包括一个基于文本引导掩码图像编辑的管道，用于生成针对低资源领域的合成图像，以及一个两阶段训练框架，结合手动监督数据和合成数据训练模型。在跨地理域转移实验中，该框架在 xBD 和 SKAI 数据集的单源和多源设置下，显著超过了仅源基线模型，改善了性能并支持人道主义援助。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13779v1",
      "published_date": "2024-05-22 16:07:05 UTC",
      "updated_date": "2024-05-22 16:07:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:30:47.644121"
    },
    {
      "arxiv_id": "2405.13777v3",
      "title": "No Filter: Cultural and Socioeconomic Diversity in Contrastive Vision-Language Models",
      "title_zh": "无过滤：对比视觉语言模型中的文化和社会经济多样性",
      "authors": [
        "Angéline Pouget",
        "Lucas Beyer",
        "Emanuele Bugliarello",
        "Xiao Wang",
        "Andreas Peter Steiner",
        "Xiaohua Zhai",
        "Ibrahim Alabdulmohsin"
      ],
      "abstract": "We study cultural and socioeconomic diversity in contrastive vision-language\nmodels (VLMs). Using a broad range of benchmark datasets and evaluation\nmetrics, we bring to attention several important findings. First, the common\nfiltering of training data to English image-text pairs disadvantages\ncommunities of lower socioeconomic status and negatively impacts cultural\nunderstanding. Notably, this performance gap is not captured by - and even at\nodds with - the currently popular evaluation metrics derived from the\nWestern-centric ImageNet and COCO datasets. Second, pretraining with global,\nunfiltered data before fine-tuning on English content can improve cultural\nunderstanding without sacrificing performance on said popular benchmarks.\nThird, we introduce the task of geo-localization as a novel evaluation metric\nto assess cultural diversity in VLMs. Our work underscores the value of using\ndiverse data to create more inclusive multimodal systems and lays the\ngroundwork for developing VLMs that better represent global perspectives.",
      "tldr_zh": "本研究探讨了对比视觉语言模型（VLMs）中的文化和经济社会多样性问题，通过多种基准数据集和评估指标揭示了关键发现：训练数据的英文过滤会损害低经济社会地位社区的代表性，并削弱文化理解，但这一差距未被以西方为中心的 ImageNet 和 COCO 指标所捕捉。研究发现，在全球未过滤数据上进行预训练，随后微调英文内容，能提升文化理解，同时不影响流行基准的性能。作者引入了地理定位（geo-localization）作为新评估指标，以更好地评估 VLMs 的文化多样性。该工作强调使用多样化数据构建更具包容性的多模态系统，并为开发代表全球视角的 VLMs 奠定基础。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "17 pages, 5 figures, 4 tables. 38th Conference on Neural Information\n  Processing Systems (NeurIPS 2024)",
      "pdf_url": "http://arxiv.org/pdf/2405.13777v3",
      "published_date": "2024-05-22 16:04:22 UTC",
      "updated_date": "2024-10-23 21:25:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:31:00.306061"
    },
    {
      "arxiv_id": "2405.14899v2",
      "title": "DETAIL: Task DEmonsTration Attribution for Interpretable In-context Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Zijian Zhou",
        "Xiaoqiang Lin",
        "Xinyi Xu",
        "Alok Prakash",
        "Daniela Rus",
        "Bryan Kian Hsiang Low"
      ],
      "abstract": "In-context learning (ICL) allows transformer-based language models that are\npre-trained on general text to quickly learn a specific task with a few \"task\ndemonstrations\" without updating their parameters, significantly boosting their\nflexibility and generality. ICL possesses many distinct characteristics from\nconventional machine learning, thereby requiring new approaches to interpret\nthis learning paradigm. Taking the viewpoint of recent works showing that\ntransformers learn in context by formulating an internal optimizer, we propose\nan influence function-based attribution technique, DETAIL, that addresses the\nspecific characteristics of ICL. We empirically verify the effectiveness of our\napproach for demonstration attribution while being computationally efficient.\nLeveraging the results, we then show how DETAIL can help improve model\nperformance in real-world scenarios through demonstration reordering and\ncuration. Finally, we experimentally prove the wide applicability of DETAIL by\nshowing our attribution scores obtained on white-box models are transferable to\nblack-box models in improving model performance.",
      "tldr_zh": "该论文探讨了 In-context Learning (ICL) 的解释性问题，提出了一种基于影响函数(influence function)的归因技术DETAIL，用于分析任务演示在ICL中的作用。DETAIL方法针对ICL的独特特性，通过内部优化器视角高效地进行演示归因，帮助识别关键演示并提升模型性能，如通过演示重新排序和精选。实验结果显示，DETAIL不仅计算高效，还能将白盒模型的归因分数转移到黑盒模型上，广泛应用于改进ICL在真实场景中的表现。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.14899v2",
      "published_date": "2024-05-22 15:52:52 UTC",
      "updated_date": "2024-12-15 02:13:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:31:11.466009"
    },
    {
      "arxiv_id": "2407.00032v1",
      "title": "Design a Win-Win Strategy That Is Fair to Both Service Providers and Tasks When Rejection Is Not an Option",
      "title_zh": "翻译失败",
      "authors": [
        "Yohai Trabelsi",
        "Pan Xu",
        "Sarit Kraus"
      ],
      "abstract": "Assigning tasks to service providers is a frequent procedure across various\napplications. Often the tasks arrive dynamically while the service providers\nremain static. Preventing task rejection caused by service provider overload is\nof utmost significance. To ensure a positive experience in relevant\napplications for both service providers and tasks, fairness must be considered.\nTo address the issue, we model the problem as an online matching within a\nbipartite graph and tackle two minimax problems: one focuses on minimizing the\nhighest waiting time of a task, while the other aims to minimize the highest\nworkload of a service provider. We show that the second problem can be\nexpressed as a linear program and thus solved efficiently while maintaining a\nreasonable approximation to the objective of the first problem. We developed\nnovel methods that utilize the two minimax problems. We conducted extensive\nsimulation experiments using real data and demonstrated that our novel\nheuristics, based on the linear program, performed remarkably well.",
      "tldr_zh": "该论文探讨了在任务动态到达且无法拒绝的情况下，如何设计一种公平的任务分配策略，以兼顾服务提供者（service providers）和任务的利益。作者将问题建模为二分图（bipartite graph）的在线匹配（online matching），并解决两个最小最大（minimax）问题：最小化任务的最大等待时间，以及最小化服务提供者的最大工作负载。研究证明，第二个问题可转化为线性规划（linear program）并高效求解，同时开发了新方法来平衡这两个目标。通过使用真实数据的模拟实验，论文展示了这些基于线性规划的启发式方法表现出色，实现了双赢的效果。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.00032v1",
      "published_date": "2024-05-22 15:52:33 UTC",
      "updated_date": "2024-05-22 15:52:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:31:24.037125"
    },
    {
      "arxiv_id": "2405.13758v1",
      "title": "Counterfactual Gradients-based Quantification of Prediction Trust in Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Mohit Prabhushankar",
        "Ghassan AlRegib"
      ],
      "abstract": "The widespread adoption of deep neural networks in machine learning calls for\nan objective quantification of esoteric trust. In this paper we propose\nGradTrust, a classification trust measure for large-scale neural networks at\ninference. The proposed method utilizes variance of counterfactual gradients,\ni.e. the required changes in the network parameters if the label were\ndifferent. We show that GradTrust is superior to existing techniques for\ndetecting misprediction rates on $50000$ images from ImageNet validation\ndataset. Depending on the network, GradTrust detects images where either the\nground truth is incorrect or ambiguous, or the classes are co-occurring. We\nextend GradTrust to Video Action Recognition on Kinetics-400 dataset. We\nshowcase results on $14$ architectures pretrained on ImageNet and $5$\narchitectures pretrained on Kinetics-400. We observe the following: (i) simple\nmethodologies like negative log likelihood and margin classifiers outperform\nstate-of-the-art uncertainty and out-of-distribution detection techniques for\nmisprediction rates, and (ii) the proposed GradTrust is in the Top-2 performing\nmethods on $37$ of the considered $38$ experimental modalities. The code is\navailable at: https://github.com/olivesgatech/GradTrust",
      "tldr_zh": "本文提出 GradTrust，一种基于反事实梯度（counterfactual gradients）的神经网络预测信任量化方法，用于评估大型模型在推理阶段的分类可靠性。该方法通过计算标签变化时网络参数方差来检测错误预测，并在 ImageNet 验证数据集的 50,000 张图像上优于现有技术，能识别标签错误、模糊或类别共存问题。实验扩展到 Kinetics-400 视频动作识别数据集，并在 14 个 ImageNet 和 5 个 Kinetics-400 预训练架构上显示，GradTrust 在 38 个实验模式中的 37 个中位居前二，提供代码实现以便复现。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "2024 IEEE 7th International Conference on Multimedia Information\n  Processing and Retrieval (MIPR)",
      "pdf_url": "http://arxiv.org/pdf/2405.13758v1",
      "published_date": "2024-05-22 15:39:54 UTC",
      "updated_date": "2024-05-22 15:39:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:31:37.400997"
    },
    {
      "arxiv_id": "2405.13753v3",
      "title": "A Dynamic Model of Performative Human-ML Collaboration: Theory and Empirical Evidence",
      "title_zh": "翻译失败",
      "authors": [
        "Tom Sühr",
        "Samira Samadi",
        "Chiara Farronato"
      ],
      "abstract": "Machine learning (ML) models are increasingly used in various applications,\nfrom recommendation systems in e-commerce to diagnosis prediction in\nhealthcare. In this paper, we present a novel dynamic framework for thinking\nabout the deployment of ML models in a performative, human-ML collaborative\nsystem. In our framework, the introduction of ML recommendations changes the\ndata-generating process of human decisions, which are only a proxy to the\nground truth and which are then used to train future versions of the model. We\nshow that this dynamic process in principle can converge to different stable\npoints, i.e. where the ML model and the Human+ML system have the same\nperformance. Some of these stable points are suboptimal with respect to the\nactual ground truth. As a proof of concept, we conduct an empirical user study\nwith 1,408 participants. In the study, humans solve instances of the knapsack\nproblem with the help of machine learning predictions of varying performance.\nThis is an ideal setting because we can identify the actual ground truth, and\nevaluate the performance of human decisions supported by ML recommendations. We\nfind that for many levels of ML performance, humans can improve upon the ML\npredictions. We also find that the improvement could be even higher if humans\nrationally followed the ML recommendations. Finally, we test whether monetary\nincentives can increase the quality of human decisions, but we fail to find any\npositive effect. Using our empirical data to approximate our collaborative\nsystem suggests that the learning process would dynamically reach an\nequilibrium performance that is around 92% of the maximum knapsack value. Our\nresults have practical implications for the deployment of ML models in contexts\nwhere human decisions may deviate from the indisputable ground truth.",
      "tldr_zh": "这篇论文提出一个动态框架，用于分析机器学习 (ML) 模型在人类-ML 协作系统中的部署，该框架强调 ML 推荐会改变人类决策的数据生成过程，可能导致系统收敛到相对于实际 ground truth 的次优稳定点。通过理论模型和一个实证用户研究（涉及 1408 名参与者解决 knapsack problem），研究发现人类可以改善 ML 预测，但如果更理性地遵循推荐，表现可进一步提升，且货币激励对决策质量无显著影响。最终，实证数据表明协作系统动态达到约 92% 的最大性能，这为在人类决策偏差环境中部署 ML 模型提供了重要启示。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC",
        "econ.GN",
        "q-fin.EC",
        "68T05",
        "I.2.1; I.2.6; K.6"
      ],
      "primary_category": "cs.LG",
      "comment": "10 Pages and appendix",
      "pdf_url": "http://arxiv.org/pdf/2405.13753v3",
      "published_date": "2024-05-22 15:38:30 UTC",
      "updated_date": "2024-10-07 08:20:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:31:50.582997"
    },
    {
      "arxiv_id": "2405.15815v1",
      "title": "A social path to human-like artificial intelligence",
      "title_zh": "通往人类般人工智能的社会路径",
      "authors": [
        "Edgar A. Duéñez-Guzmán",
        "Suzanne Sadedin",
        "Jane X. Wang",
        "Kevin R. McKee",
        "Joel Z. Leibo"
      ],
      "abstract": "Traditionally, cognitive and computer scientists have viewed intelligence\nsolipsistically, as a property of unitary agents devoid of social context.\nGiven the success of contemporary learning algorithms, we argue that the\nbottleneck in artificial intelligence (AI) progress is shifting from data\nassimilation to novel data generation. We bring together evidence showing that\nnatural intelligence emerges at multiple scales in networks of interacting\nagents via collective living, social relationships and major evolutionary\ntransitions, which contribute to novel data generation through mechanisms such\nas population pressures, arms races, Machiavellian selection, social learning\nand cumulative culture. Many breakthroughs in AI exploit some of these\nprocesses, from multi-agent structures enabling algorithms to master complex\ngames like Capture-The-Flag and StarCraft II, to strategic communication in\nDiplomacy and the shaping of AI data streams by other AIs. Moving beyond a\nsolipsistic view of agency to integrate these mechanisms suggests a path to\nhuman-like compounding innovation through ongoing novel data generation.",
      "tldr_zh": "该论文批评了传统认知和计算机科学中将智能视为单一代理的孤立视角，并指出AI进步的瓶颈已从数据吸收转向新数据生成。作者整合证据显示，自然智能通过互动代理网络中的集体生活、社会关系和进化过渡（如种群压力、军备竞赛和累积文化）实现持续创新。许多AI突破（如多-agent结构在Capture-The-Flag和StarCraft II游戏中的应用）已利用这些社会机制。最终，论文建议超越solipsistic观点，整合这些过程，以实现类似人类的持续数据生成和创新发展。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "68T05",
        "I.2.6"
      ],
      "primary_category": "cs.AI",
      "comment": "17 pages, 2 figures, 1 box",
      "pdf_url": "http://arxiv.org/pdf/2405.15815v1",
      "published_date": "2024-05-22 15:38:10 UTC",
      "updated_date": "2024-05-22 15:38:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:31:59.672025"
    },
    {
      "arxiv_id": "2405.13751v1",
      "title": "GameVLM: A Decision-making Framework for Robotic Task Planning Based on Visual Language Models and Zero-sum Games",
      "title_zh": "翻译失败",
      "authors": [
        "Aoran Mei",
        "Jianhua Wang",
        "Guo-Niu Zhu",
        "Zhongxue Gan"
      ],
      "abstract": "With their prominent scene understanding and reasoning capabilities,\npre-trained visual-language models (VLMs) such as GPT-4V have attracted\nincreasing attention in robotic task planning. Compared with traditional task\nplanning strategies, VLMs are strong in multimodal information parsing and code\ngeneration and show remarkable efficiency. Although VLMs demonstrate great\npotential in robotic task planning, they suffer from challenges like\nhallucination, semantic complexity, and limited context. To handle such issues,\nthis paper proposes a multi-agent framework, i.e., GameVLM, to enhance the\ndecision-making process in robotic task planning. In this study, VLM-based\ndecision and expert agents are presented to conduct the task planning.\nSpecifically, decision agents are used to plan the task, and the expert agent\nis employed to evaluate these task plans. Zero-sum game theory is introduced to\nresolve inconsistencies among different agents and determine the optimal\nsolution. Experimental results on real robots demonstrate the efficacy of the\nproposed framework, with an average success rate of 83.3%.",
      "tldr_zh": "该研究提出GameVLM框架，利用预训练的Visual Language Models (VLMs)结合零和博弈理论（Zero-sum Games），构建多智能体系统来提升机器人任务规划的决策过程。框架包括决策agents负责任务规划，以及expert agent用于评估计划，以解决VLMs面临的hallucination、semantic complexity和limited context等问题。实验在真实机器人上验证了框架的有效性，平均成功率达到83.3%。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13751v1",
      "published_date": "2024-05-22 15:37:28 UTC",
      "updated_date": "2024-05-22 15:37:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:32:11.489924"
    },
    {
      "arxiv_id": "2406.19399v1",
      "title": "Predicting Customer Goals in Financial Institution Services: A Data-Driven LSTM Approach",
      "title_zh": "金融机构服务中的客户目标预测：一种数据驱动的 LSTM 方法",
      "authors": [
        "Andrew Estornell",
        "Stylianos Loukas Vasileiou",
        "William Yeoh",
        "Daniel Borrajo",
        "Rui Silva"
      ],
      "abstract": "In today's competitive financial landscape, understanding and anticipating\ncustomer goals is crucial for institutions to deliver a personalized and\noptimized user experience. This has given rise to the problem of accurately\npredicting customer goals and actions. Focusing on that problem, we use\nhistorical customer traces generated by a realistic simulator and present two\nsimple models for predicting customer goals and future actions -- an LSTM model\nand an LSTM model enhanced with state-space graph embeddings. Our results\ndemonstrate the effectiveness of these models when it comes to predicting\ncustomer goals and actions.",
      "tldr_zh": "在金融服务领域，准确预测客户目标和行动对提供个性化体验至关重要，本文使用历史客户数据和现实模拟器，提出两种模型：一个基础的 LSTM 模型，以及一个增强了 state-space graph embeddings 的 LSTM 模型。实验结果显示，这些模型在预测客户目标和未来行动方面表现出色，有效提升了预测准确性。该方法为金融机构的数据驱动决策提供了实用工具。",
      "categories": [
        "q-fin.ST",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "q-fin.ST",
      "comment": "Accepted at the FinPlan 2023 workshop at ICAPS 2023",
      "pdf_url": "http://arxiv.org/pdf/2406.19399v1",
      "published_date": "2024-05-22 15:36:03 UTC",
      "updated_date": "2024-05-22 15:36:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:32:22.734028"
    },
    {
      "arxiv_id": "2405.13746v2",
      "title": "CG-FedLLM: How to Compress Gradients in Federated Fune-tuning for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Huiwen Wu",
        "Xiaohan Li",
        "Deyi Zhang",
        "Xiaogang Xu",
        "Jiafei Wu",
        "Puning Zhao",
        "Zhe Liu"
      ],
      "abstract": "The success of current Large-Language Models (LLMs) hinges on extensive\ntraining data that is collected and stored centrally, called Centralized\nLearning (CL). However, such a collection manner poses a privacy threat, and\none potential solution is Federated Learning (FL), which transfers gradients,\nnot raw data, among clients. Unlike traditional networks, FL for LLMs incurs\nsignificant communication costs due to their tremendous parameters. This study\nintroduces an innovative approach to compress gradients to improve\ncommunication efficiency during LLM FL, formulating the new FL pipeline named\nCG-FedLLM. This approach integrates an encoder on the client side to acquire\nthe compressed gradient features and a decoder on the server side to\nreconstruct the gradients. We also developed a novel training strategy that\ncomprises Temporal-ensemble Gradient-Aware Pre-training (TGAP) to identify\ncharacteristic gradients of the target model and Federated AutoEncoder-Involved\nFine-tuning (FAF) to compress gradients adaptively. Extensive experiments\nconfirm that our approach reduces communication costs and improves performance\n(e.g., average 3 points increment compared with traditional CL- and FL-based\nfine-tuning with LlaMA on a well-recognized benchmark, C-Eval). This\nimprovement is because our encoder-decoder, trained via TGAP and FAF, can\nfilter gradients while selectively preserving critical features. Furthermore,\nwe present a series of experimental analyses focusing on the signal-to-noise\nratio, compression rate, and robustness within this privacy-centric framework,\nproviding insight into developing more efficient and secure LLMs.",
      "tldr_zh": "该研究针对大型语言模型（LLMs）在联邦学习（FL）中的高通信成本问题，提出了一种创新框架 CG-FedLLM，用于压缩梯度以提升微调效率。该框架在客户端使用编码器压缩梯度，在服务器端使用解码器重建梯度，并引入 Temporal-ensemble Gradient-Aware Pre-training (TGAP) 和 Federated AutoEncoder-Involved Fine-tuning (FAF) 策略，以识别关键梯度特征并实现自适应压缩。实验结果显示，CG-FedLLM 在 C-Eval 基准上比传统中心化学习（CL）和 FL 微调 LlaMA 模型平均提高了 3 分，同时降低了通信成本，并通过过滤噪声保留关键特征。此外，该方法还分析了信噪比、压缩率和鲁棒性，提供更高效、安全的 LLMs 联邦学习方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13746v2",
      "published_date": "2024-05-22 15:32:38 UTC",
      "updated_date": "2024-05-24 03:17:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:32:38.311953"
    },
    {
      "arxiv_id": "2405.13735v2",
      "title": "Transfer of Safety Controllers Through Learning Deep Inverse Dynamics Model",
      "title_zh": "翻译失败",
      "authors": [
        "Alireza Nadali",
        "Ashutosh Trivedi",
        "Majid Zamani"
      ],
      "abstract": "Control barrier certificates have proven effective in formally guaranteeing\nthe safety of the control systems. However, designing a control barrier\ncertificate is a time-consuming and computationally expensive endeavor that\nrequires expert input in the form of domain knowledge and mathematical\nmaturity. Additionally, when a system undergoes slight changes, the new\ncontroller and its correctness certificate need to be recomputed, incurring\nsimilar computational challenges as those faced during the design of the\noriginal controller. Prior approaches have utilized transfer learning to\ntransfer safety guarantees in the form of a barrier certificate while\nmaintaining the control invariant. Unfortunately, in practical settings, the\nsource and the target environments often deviate substantially in their control\ninputs, rendering the aforementioned approach impractical. To address this\nchallenge, we propose integrating \\emph{inverse dynamics} -- a neural network\nthat suggests required action given a desired successor state -- of the target\nsystem with the barrier certificate of the source system to provide formal\nproof of safety. In addition, we propose a validity condition that, when met,\nguarantees correctness of the controller. We demonstrate the effectiveness of\nour approach through three case studies.",
      "tldr_zh": "本研究解决了控制屏障证书（Control Barrier Certificates）在保证控制系统安全时的设计挑战，该过程耗时且依赖专家知识，尤其在系统变化时需重新计算。论文提出一种新方法，通过学习深度逆动态模型（Inverse Dynamics）将源系统的屏障证书转移到目标系统，该模型基于神经网络预测所需动作以实现期望的后继状态，并结合有效性条件确保控制器的正确性。实验通过三个案例研究验证了该方法的有效性，显著提高了安全控制器转移的实用性。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LG",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "Extended Version, submitted to ADHS 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.13735v2",
      "published_date": "2024-05-22 15:28:43 UTC",
      "updated_date": "2024-05-24 19:29:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:32:50.202818"
    },
    {
      "arxiv_id": "2405.13729v2",
      "title": "ComboStoc: Combinatorial Stochasticity for Diffusion Generative Models",
      "title_zh": "ComboStoc：针对扩散生成模型的组合随机性",
      "authors": [
        "Rui Xu",
        "Jiepeng Wang",
        "Hao Pan",
        "Yang Liu",
        "Xin Tong",
        "Shiqing Xin",
        "Changhe Tu",
        "Taku Komura",
        "Wenping Wang"
      ],
      "abstract": "In this paper, we study an under-explored but important factor of diffusion\ngenerative models, i.e., the combinatorial complexity. Data samples are\ngenerally high-dimensional, and for various structured generation tasks, there\nare additional attributes which are combined to associate with data samples. We\nshow that the space spanned by the combination of dimensions and attributes is\ninsufficiently sampled by existing training scheme of diffusion generative\nmodels, causing degraded test time performance. We present a simple fix to this\nproblem by constructing stochastic processes that fully exploit the\ncombinatorial structures, hence the name ComboStoc. Using this simple strategy,\nwe show that network training is significantly accelerated across diverse data\nmodalities, including images and 3D structured shapes. Moreover, ComboStoc\nenables a new way of test time generation which uses insynchronized time steps\nfor different dimensions and attributes, thus allowing for varying degrees of\ncontrol over them.",
      "tldr_zh": "本文研究了扩散生成模型(Diffusion Generative Models)中的组合复杂性(combinatorial complexity)问题，指出现有训练方案无法充分采样高维数据和属性的组合空间，导致测试性能下降。作者提出ComboStoc方法，通过构建充分利用组合结构的随机过程，显著加速网络训练，并在图像和3D结构化形状等数据模式上取得更好效果。此外，ComboStoc启用了一种新颖的测试时生成方式，使用不同维度的不同时间步长(insynchronized time steps)，从而实现对生成过程的精细控制。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.GR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13729v2",
      "published_date": "2024-05-22 15:23:10 UTC",
      "updated_date": "2024-05-24 07:05:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:33:03.111930"
    },
    {
      "arxiv_id": "2405.13715v3",
      "title": "Traffic Scenario Logic: A Spatial-Temporal Logic for Modeling and Reasoning of Urban Traffic Scenarios",
      "title_zh": "交通场景逻辑：一种用于城市交通场景建模和推理的时空逻辑",
      "authors": [
        "Ruolin Wang",
        "Yuejiao Xu",
        "Jianmin Ji"
      ],
      "abstract": "Formal representations of traffic scenarios can be used to generate test\ncases for the safety verification of autonomous driving. However, most existing\nmethods are limited to highway or highly simplified intersection scenarios due\nto the intricacy and diversity of traffic scenarios. In response, we propose\nTraffic Scenario Logic (TSL), which is a spatial-temporal logic designed for\nmodeling and reasoning of urban pedestrian-free traffic scenarios. TSL provides\na formal representation of the urban road network that can be derived from\nOpenDRIVE, i.e., the de facto industry standard of high-definition maps for\nautonomous driving, enabling the representation of a broad range of traffic\nscenarios without discretization approximations. We implemented the reasoning\nof TSL using Telingo, i.e., a solver for temporal programs based on Answer Set\nProgramming, and tested it on different urban road layouts. Demonstrations show\nthe effectiveness of TSL in test scenario generation and its potential value in\nareas like decision-making and control verification of autonomous driving. The\ncode for TSL reasoning has been open-sourced.",
      "tldr_zh": "这篇论文提出了一种新的空间-时间逻辑Traffic Scenario Logic (TSL)，用于建模和推理城市无行人交通场景，以解决现有方法在复杂城市环境中的局限性。TSL基于OpenDRIVE标准派生道路网络的正式表示，避免了离散化近似，并利用Telingo求解器（基于Answer Set Programming）进行推理。实验结果显示，TSL在不同城市道路布局上有效，支持测试场景生成，并具有潜力应用于自动驾驶的决策和控制验证，且相关代码已开源。",
      "categories": [
        "cs.LO",
        "cs.AI"
      ],
      "primary_category": "cs.LO",
      "comment": "Accepted by AAAI 2025. 8 pages of main text, 19 pages of technical\n  appendix",
      "pdf_url": "http://arxiv.org/pdf/2405.13715v3",
      "published_date": "2024-05-22 15:06:50 UTC",
      "updated_date": "2025-02-20 06:58:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:33:14.547977"
    },
    {
      "arxiv_id": "2405.13711v1",
      "title": "VAE-Var: Variational-Autoencoder-Enhanced Variational Assimilation",
      "title_zh": "VAE-Var：变分自",
      "authors": [
        "Yi Xiao",
        "Qilong Jia",
        "Wei Xue",
        "Lei Bai"
      ],
      "abstract": "Data assimilation refers to a set of algorithms designed to compute the\noptimal estimate of a system's state by refining the prior prediction (known as\nbackground states) using observed data. Variational assimilation methods rely\non the maximum likelihood approach to formulate a variational cost, with the\noptimal state estimate derived by minimizing this cost. Although traditional\nvariational methods have achieved great success and have been widely used in\nmany numerical weather prediction centers, they generally assume Gaussian\nerrors in the background states, which limits the accuracy of these algorithms\ndue to the inherent inaccuracies of this assumption. In this paper, we\nintroduce VAE-Var, a novel variational algorithm that leverages a variational\nautoencoder (VAE) to model a non-Gaussian estimate of the background error\ndistribution. We theoretically derive the variational cost under the VAE\nestimation and present the general formulation of VAE-Var; we implement VAE-Var\non low-dimensional chaotic systems and demonstrate through experimental results\nthat VAE-Var consistently outperforms traditional variational assimilation\nmethods in terms of accuracy across various observational settings.",
      "tldr_zh": "本文提出 VAE-Var，一种增强型变分同化算法，利用 Variational Autoencoder (VAE) 来建模非高斯背景错误分布，以克服传统变分同化方法对高斯错误假设的局限性。研究者理论推导了在 VAE 估计下的变分成本，并给出了算法的通用公式。实验结果显示，在低维混沌系统上，VAE-Var 在各种观测设置下，其准确性 consistently outperforms 传统变分同化方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.DS",
        "physics.ao-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13711v1",
      "published_date": "2024-05-22 15:01:05 UTC",
      "updated_date": "2024-05-22 15:01:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:33:26.856978"
    },
    {
      "arxiv_id": "2405.13707v2",
      "title": "Rethinking and Accelerating Graph Condensation: A Training-Free Approach with Class Partition",
      "title_zh": "重新思考与加速图凝聚：一种基于类分区的免训练方法",
      "authors": [
        "Xinyi Gao",
        "Guanhua Ye",
        "Tong Chen",
        "Wentao Zhang",
        "Junliang Yu",
        "Hongzhi Yin"
      ],
      "abstract": "The increasing prevalence of large-scale graphs poses a significant challenge\nfor graph neural network training, attributed to their substantial\ncomputational requirements. In response, graph condensation (GC) emerges as a\npromising data-centric solution aiming to substitute the large graph with a\nsmall yet informative condensed graph to facilitate data-efficient GNN\ntraining. However, existing GC methods suffer from intricate optimization\nprocesses, necessitating excessive computing resources and training time. In\nthis paper, we revisit existing GC optimization strategies and identify two\npervasive issues therein: (1) various GC optimization strategies converge to\ncoarse-grained class-level node feature matching between the original and\ncondensed graphs; (2) existing GC methods rely on a Siamese graph network\narchitecture that requires time-consuming bi-level optimization with iterative\ngradient computations. To overcome these issues, we propose a training-free GC\nframework termed Class-partitioned Graph Condensation (CGC), which refines the\nnode distribution matching from the class-to-class paradigm into a novel\nclass-to-node paradigm, transforming the GC optimization into a class partition\nproblem which can be efficiently solved by any clustering methods. Moreover,\nCGC incorporates a pre-defined graph structure to enable a closed-form solution\nfor condensed node features, eliminating the need for back-and-forth gradient\ndescent in existing GC approaches. Extensive experiments demonstrate that CGC\nachieves an exceedingly efficient condensation process with advanced accuracy.\nCompared with the state-of-the-art GC methods, CGC condenses the Ogbn-products\ngraph within 30 seconds, achieving a speedup ranging from $10^2$X to $10^4$X\nand increasing accuracy by up to 4.2%.",
      "tldr_zh": "该论文重新审视了 Graph Condensation (GC) 的优化策略，指出现有方法存在粗粒度类级节点特征匹配和耗时的双层优化问题，导致计算资源浪费。作者提出了一种训练-free 的框架 Class-partitioned Graph Condensation (CGC)，通过将节点分布匹配从 class-to-class 范式转变为 class-to-node 范式，并结合聚类方法和预定义图结构，实现高效的闭式解优化。实验结果显示，CGC 在 Ogbn-products 图上仅需 30 秒即可完成凝结，比最先进方法加速 10^2 到 10^4 倍，同时准确率提升高达 4.2%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ACM Web Conference 2025 (WWW '25)",
      "pdf_url": "http://arxiv.org/pdf/2405.13707v2",
      "published_date": "2024-05-22 14:57:09 UTC",
      "updated_date": "2025-01-23 08:49:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:33:39.500815"
    },
    {
      "arxiv_id": "2405.17454v1",
      "title": "Generative AI for the Optimization of Next-Generation Wireless Networks: Basics, State-of-the-Art, and Open Challenges",
      "title_zh": "翻译失败",
      "authors": [
        "Fahime Khoramnejad",
        "Ekram Hossain"
      ],
      "abstract": "Next-generation (xG) wireless networks, with their complex and dynamic\nnature, present significant challenges to using traditional optimization\ntechniques. Generative AI (GAI) emerges as a powerful tool due to its unique\nstrengths. Unlike traditional optimization techniques and other machine\nlearning methods, GAI excels at learning from real-world network data,\ncapturing its intricacies. This enables safe, offline exploration of various\nconfigurations and generation of diverse, unseen scenarios, empowering\nproactive, data-driven exploration and optimization for xG networks.\nAdditionally, GAI's scalability makes it ideal for large-scale xG networks.\nThis paper surveys how GAI-based models unlock optimization opportunities in xG\nwireless networks. We begin by providing a review of GAI models and some of the\nmajor communication paradigms of xG (e.g., 6G) wireless networks. We then delve\ninto exploring how GAI can be used to improve resource allocation and enhance\noverall network performance. Additionally, we briefly review the networking\nrequirements for supporting GAI applications in xG wireless networks. The paper\nfurther discusses the key challenges and future research directions in\nleveraging GAI for network optimization. Finally, a case study demonstrates the\napplication of a diffusion-based GAI model for load balancing, carrier\naggregation, and backhauling optimization in non-terrestrial networks, a core\ntechnology of xG networks. This case study serves as a practical example of how\nthe combination of reinforcement learning and GAI can be implemented to address\nreal-world network optimization problems.",
      "tldr_zh": "本论文探讨了Generative AI (GAI) 在下一代无线网络（xG networks，例如6G）优化中的应用，强调GAI通过从真实网络数据中学习，能够捕捉复杂动态特性，实现安全离线探索和生成多样场景，从而提升资源分配和整体网络性能。论文首先回顾GAI模型及其在xG网络通信范式的作用，然后分析GAI如何支持大规模网络的优化，并简要讨论网络需求。关键挑战包括GAI的部署障碍和未来研究方向，如结合reinforcement learning进行实际优化。最后，通过一个案例研究，展示了基于diffusion模型的GAI在非地面网络中优化负载均衡、载波聚合和回传的有效性，为xG网络的创新提供了数据驱动的解决方案。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "Submitted for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2405.17454v1",
      "published_date": "2024-05-22 14:56:25 UTC",
      "updated_date": "2024-05-22 14:56:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:33:50.563982"
    },
    {
      "arxiv_id": "2405.13699v1",
      "title": "Uncertainty-aware Evaluation of Auxiliary Anomalies with the Expected Anomaly Posterior",
      "title_zh": "翻译失败",
      "authors": [
        "Lorenzo Perini",
        "Maja Rudolph",
        "Sabrina Schmedding",
        "Chen Qiu"
      ],
      "abstract": "Anomaly detection is the task of identifying examples that do not behave as\nexpected. Because anomalies are rare and unexpected events, collecting real\nanomalous examples is often challenging in several applications. In addition,\nlearning an anomaly detector with limited (or no) anomalies often yields poor\nprediction performance. One option is to employ auxiliary synthetic anomalies\nto improve the model training. However, synthetic anomalies may be of poor\nquality: anomalies that are unrealistic or indistinguishable from normal\nsamples may deteriorate the detector's performance. Unfortunately, no existing\nmethods quantify the quality of auxiliary anomalies. We fill in this gap and\npropose the expected anomaly posterior (EAP), an uncertainty-based score\nfunction that measures the quality of auxiliary anomalies by quantifying the\ntotal uncertainty of an anomaly detector. Experimentally on 40 benchmark\ndatasets of images and tabular data, we show that EAP outperforms 12 adapted\ndata quality estimators in the majority of cases.",
      "tldr_zh": "该论文针对异常检测（anomaly detection）中的挑战，即真实异常样本稀缺且难以收集，导致模型性能低下，提出使用辅助合成异常来提升训练效果。论文引入 expected anomaly posterior (EAP)，一个基于不确定性的分数函数，用于量化辅助异常的质量，通过测量异常检测器的总不确定性来评估合成异常的真实性和区分度。实验结果显示，在40个图像和表格数据集上，EAP 比12个其他数据质量估计器在大多数情况下表现更优，从而为改进异常检测模型提供了可靠的评估工具。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13699v1",
      "published_date": "2024-05-22 14:43:29 UTC",
      "updated_date": "2024-05-22 14:43:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:34:01.794741"
    },
    {
      "arxiv_id": "2405.13698v2",
      "title": "How to set AdamW's weight decay as you scale model and dataset size",
      "title_zh": "翻译失败",
      "authors": [
        "Xi Wang",
        "Laurence Aitchison"
      ],
      "abstract": "The scaling of the optimal AdamW weight decay hyperparameter with model and\ndataset size is critical as we seek to build larger models, but is poorly\nunderstood. We show that weights learned by AdamW can be understood as an\nexponential moving average (EMA) of recent updates. This gives critical\ninsights for how to set the weight decay in AdamW, and how the weight decay\nshould scale with model and dataset size. In particular, the key hyperparameter\nfor an exponential moving average is the EMA timescale. Intuitively, the EMA\ntimescale can be understood as the number of recent iterations the EMA averages\nover. We find that the optimal timescale, measured in epochs, is roughly\nconstant as we change model and dataset size. Moreover, given a learning rate,\nthere is a one-to-one mapping from the EMA timescale to the weight decay\nhyperparameter. Thus, if the optimal EMA timescale is constant, that implies\nthat as the dataset size increases, the optimal weight decay should fall and as\nthe model size increases, the optimal weight decay should increase (if we\nfollow the muP recommendation for scaling the learning rate). We validate these\nscaling rules on ResNet-18 and Vision Transformers trained on CIFAR-10 and\nImageNet, and on NanoGPT pre-training on OpenWebText. Finally, we found that as\ntraining progresses, muP's learning rate scaling breaks down for AdamW unless\nweight decay is scaled appropriately.",
      "tldr_zh": "这篇论文探讨了 AdamW 优化器中 weight decay 超参数如何随模型和数据集规模调整的问题。作者将 AdamW 的权重视为指数移动平均 (EMA)，并发现最优 EMA timescale 在 epoch 中大致恒定，这为设置 weight decay 提供了关键见解。具体而言，随着数据集规模增加，最优 weight decay 应降低；随着模型规模增加，应提高，以匹配 muP 的学习率缩放建议。实验在 ResNet-18、Vision Transformers 和 NanoGPT 上验证了这些规则，并指出训练后期 muP 的学习率缩放会失效，除非相应调整 weight decay。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13698v2",
      "published_date": "2024-05-22 14:43:02 UTC",
      "updated_date": "2025-02-02 21:46:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:34:16.461939"
    },
    {
      "arxiv_id": "2405.13651v1",
      "title": "ConcertoRL: An Innovative Time-Interleaved Reinforcement Learning Approach for Enhanced Control in Direct-Drive Tandem-Wing Vehicles",
      "title_zh": "翻译失败",
      "authors": [
        "Minghao Zhang",
        "Bifeng Song",
        "Changhao Chen",
        "Xinyu Lang"
      ],
      "abstract": "In control problems for insect-scale direct-drive experimental platforms\nunder tandem wing influence, the primary challenge facing existing\nreinforcement learning models is their limited safety in the exploration\nprocess and the stability of the continuous training process. We introduce the\nConcertoRL algorithm to enhance control precision and stabilize the online\ntraining process, which consists of two main innovations: a time-interleaved\nmechanism to interweave classical controllers with reinforcement learning-based\ncontrollers aiming to improve control precision in the initial stages, a policy\ncomposer organizes the experience gained from previous learning to ensure the\nstability of the online training process. This paper conducts a series of\nexperiments. First, experiments incorporating the time-interleaved mechanism\ndemonstrate a substantial performance boost of approximately 70% over scenarios\nwithout reinforcement learning enhancements and a 50% increase in efficiency\ncompared to reference controllers with doubled control frequencies. These\nresults highlight the algorithm's ability to create a synergistic effect that\nexceeds the sum of its parts.",
      "tldr_zh": "该研究针对昆虫规模直接驱动双翼车辆（direct-drive tandem-wing vehicles）的控制问题，提出ConcertoRL算法，以解决现有强化学习（reinforcement learning）模型在探索过程安全性和在线训练稳定性方面的挑战。算法的核心创新包括时间交错机制（time-interleaved mechanism），将经典控制器与强化学习控制器交织以提升初始控制精度，以及策略合成器（policy composer），用于组织先前学习经验确保训练过程稳定。实验结果表明，ConcertoRL在性能上比无强化学习增强的场景提升约70%，并比参考控制器效率提高50%，展示了其协同效应。",
      "categories": [
        "cs.AI",
        "cs.RO",
        "68T40",
        "I.2.9"
      ],
      "primary_category": "cs.AI",
      "comment": "48 pages, 35 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.13651v1",
      "published_date": "2024-05-22 13:53:10 UTC",
      "updated_date": "2024-05-22 13:53:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:34:27.472871"
    },
    {
      "arxiv_id": "2405.13640v2",
      "title": "Knowledge Graph Reasoning with Self-supervised Reinforcement Learning",
      "title_zh": "基于自监督强化学习的知识图谱推理",
      "authors": [
        "Ying Ma",
        "Owen Burns",
        "Mingqiu Wang",
        "Gang Li",
        "Nan Du",
        "Laurent El Shafey",
        "Liqiang Wang",
        "Izhak Shafran",
        "Hagen Soltau"
      ],
      "abstract": "Reinforcement learning (RL) is an effective method of finding reasoning\npathways in incomplete knowledge graphs (KGs). To overcome the challenges of a\nlarge action space, a self-supervised pre-training method is proposed to warm\nup the policy network before the RL training stage. To alleviate the\ndistributional mismatch issue in general self-supervised RL (SSRL), in our\nsupervised learning (SL) stage, the agent selects actions based on the policy\nnetwork and learns from generated labels; this self-generation of labels is the\nintuition behind the name self-supervised. With this training framework, the\ninformation density of our SL objective is increased and the agent is prevented\nfrom getting stuck with the early rewarded paths. Our self-supervised RL (SSRL)\nmethod improves the performance of RL by pairing it with the wide coverage\nachieved by SL during pretraining, since the breadth of the SL objective makes\nit infeasible to train an agent with that alone. We show that our SSRL model\nmeets or exceeds current state-of-the-art results on all Hits@k and mean\nreciprocal rank (MRR) metrics on four large benchmark KG datasets. This SSRL\nmethod can be used as a plug-in for any RL architecture for a KGR task. We\nadopt two RL architectures, i.e., MINERVA and MultiHopKG as our baseline RL\nmodels and experimentally show that our SSRL model consistently outperforms\nboth baselines on all of these four KG reasoning tasks. Full code for the paper\navailable at\nhttps://github.com/owenonline/Knowledge-Graph-Reasoning-with-Self-supervised-Reinforcement-Learning.",
      "tldr_zh": "该论文提出了一种自监督强化学习（SSRL）方法，用于在不完整知识图（KGs）中进行推理路径搜索，以解决大型行动空间的挑战。方法包括一个自监督预训练阶段来预热策略网络，并在监督学习（SL）阶段让代理基于策略网络选择动作并从自生成的标签中学习，从而缓解分布不匹配问题和避免代理陷入早期奖励路径。实验结果显示，SSRL模型在四个大型基准KG数据集上，在Hits@k和均互反秩（MRR）指标上达到了或超过了现有最先进水平，并作为插件提升了如MINERVA和MultiHopKG等基线RL架构的表现。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.13640v2",
      "published_date": "2024-05-22 13:39:33 UTC",
      "updated_date": "2025-04-15 21:48:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:34:38.632533"
    },
    {
      "arxiv_id": "2405.13637v6",
      "title": "Curriculum Direct Preference Optimization for Diffusion and Consistency Models",
      "title_zh": "翻译失败",
      "authors": [
        "Florinel-Alin Croitoru",
        "Vlad Hondru",
        "Radu Tudor Ionescu",
        "Nicu Sebe",
        "Mubarak Shah"
      ],
      "abstract": "Direct Preference Optimization (DPO) has been proposed as an effective and\nefficient alternative to reinforcement learning from human feedback (RLHF). In\nthis paper, we propose a novel and enhanced version of DPO based on curriculum\nlearning for text-to-image generation. Our method is divided into two training\nstages. First, a ranking of the examples generated for each prompt is obtained\nby employing a reward model. Then, increasingly difficult pairs of examples are\nsampled and provided to a text-to-image generative (diffusion or consistency)\nmodel. Generated samples that are far apart in the ranking are considered to\nform easy pairs, while those that are close in the ranking form hard pairs. In\nother words, we use the rank difference between samples as a measure of\ndifficulty. The sampled pairs are split into batches according to their\ndifficulty levels, which are gradually used to train the generative model. Our\napproach, Curriculum DPO, is compared against state-of-the-art fine-tuning\napproaches on nine benchmarks, outperforming the competing methods in terms of\ntext alignment, aesthetics and human preference. Our code is available at\nhttps://github.com/CroitoruAlin/Curriculum-DPO.",
      "tldr_zh": "该论文提出了一种基于课程学习（curriculum learning）的增强版 Direct Preference Optimization (DPO)，旨在优化文本到图像生成模型，如 diffusion models 和 consistency models。方法分为两个阶段：首先，使用奖励模型（reward model）对每个提示生成的样本进行排序，然后采样难度递增的样本对（基于排名差异定义易对和难对），并按难度分批逐步训练生成模型。这种 Curriculum DPO 方法在九个基准测试中超越了现有最先进的技术，在文本对齐、美学和人类偏好方面表现出色。代码已开源，可在 GitHub 上获取。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2405.13637v6",
      "published_date": "2024-05-22 13:36:48 UTC",
      "updated_date": "2025-05-09 08:38:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:34:52.103104"
    },
    {
      "arxiv_id": "2405.13636v1",
      "title": "Audio Mamba: Pretrained Audio State Space Model For Audio Tagging",
      "title_zh": "Audio Mamba：",
      "authors": [
        "Jiaju Lin",
        "Haoxuan Hu"
      ],
      "abstract": "Audio tagging is an important task of mapping audio samples to their\ncorresponding categories. Recently endeavours that exploit transformer models\nin this field have achieved great success. However, the quadratic\nself-attention cost limits the scaling of audio transformer models and further\nconstrains the development of more universal audio models. In this paper, we\nattempt to solve this problem by proposing Audio Mamba, a self-attention-free\napproach that captures long audio spectrogram dependency with state space\nmodels. Our experimental results on two audio-tagging datasets demonstrate the\nparameter efficiency of Audio Mamba, it achieves comparable results to SOTA\naudio spectrogram transformers with one third parameters.",
      "tldr_zh": "这篇论文提出了 Audio Mamba，一种预训练的音频状态空间模型，用于音频标记任务，以解决传统 Transformer 模型的二次方自注意力机制导致的计算成本问题。Audio Mamba 采用自注意力-free 的方法，通过状态空间模型捕获音频谱图的长距离依赖，从而实现更高的参数效率。在两个音频标记数据集上的实验表明，该模型仅使用三分之一的参数就达到了与最先进音频谱图 Transformer 相当的性能。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13636v1",
      "published_date": "2024-05-22 13:35:56 UTC",
      "updated_date": "2024-05-22 13:35:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:35:02.628809"
    },
    {
      "arxiv_id": "2405.13606v1",
      "title": "From the evolution of public data ecosystems to the evolving horizons of the forward-looking intelligent public data ecosystem empowered by emerging technologies",
      "title_zh": "翻译失败",
      "authors": [
        "Anastasija Nikiforova",
        "Martin Lnenicka",
        "Petar Milić",
        "Mariusz Luterek",
        "Manuel Pedro Rodríguez Bolívar"
      ],
      "abstract": "Public data ecosystems (PDEs) represent complex socio-technical systems\ncrucial for optimizing data use in the public sector and outside it.\nRecognizing their multifaceted nature, previous research pro-posed a\nsix-generation Evolutionary Model of Public Data Ecosystems (EMPDE). Designed\nas a result of a systematic literature review on the topic spanning three\ndecade, this model, while theoretically robust, necessitates empirical\nvalidation to enhance its practical applicability. This study addresses this\ngap by validating the theoretical model through a real-life examination in five\nEuropean countries - Latvia, Serbia, Czech Republic, Spain, and Poland. This\nempirical validation provides insights into PDEs dynamics and variations of\nimplementations across contexts, particularly focusing on the 6th generation of\nforward-looking PDE generation named \"Intelligent Public Data Generation\" that\nrepresents a paradigm shift driven by emerging technologies such as cloud\ncomputing, Artificial Intelligence, Natural Language Processing tools,\nGenerative AI, and Large Language Models (LLM) with potential to contribute to\nboth automation and augmentation of business processes within these ecosystems.\nBy transcending their traditional status as a mere component, evolving into\nboth an actor and a stakeholder simultaneously, these technologies catalyze\ninnovation and progress, enhancing PDE management strategies to align with\nsocietal, regulatory, and technical imperatives in the digital era.",
      "tldr_zh": "本研究验证了公共数据生态系统 (PDEs) 的六代演化模型 (EMPDE)，该模型基于对三十年文献的系统回顾，通过在拉脱维亚、塞尔维亚、捷克共和国、西班牙和波兰五个欧洲国家的实证考察，揭示了PDEs的动态变化和跨背景差异。重点关注第六代“智能公共数据生态系统”，该代由新兴技术如云计算、Artificial Intelligence (AI)、Natural Language Processing (NLP)、Generative AI 和 Large Language Models (LLM) 驱动，实现从传统组件向参与者和利益相关者的转变。研究发现，这些技术促进了业务流程的自动化和增强，推动创新并优化PDEs的管理策略，以适应数字时代的社会、监管和技术需求。该工作为PDEs的实际应用提供了宝贵见解，提升了其在公共部门和外部的优化潜力。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.ET",
        "cs.HC",
        "cs.IR"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13606v1",
      "published_date": "2024-05-22 12:58:02 UTC",
      "updated_date": "2024-05-22 12:58:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:35:15.646805"
    },
    {
      "arxiv_id": "2405.13602v1",
      "title": "COTET: Cross-view Optimal Transport for Knowledge Graph Entity Typing",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiwei Hu",
        "Víctor Gutiérrez-Basulto",
        "Zhiliang Xiang",
        "Ru Li",
        "Jeff Z. Pan"
      ],
      "abstract": "Knowledge graph entity typing (KGET) aims to infer missing entity type\ninstances in knowledge graphs. Previous research has predominantly centered\naround leveraging contextual information associated with entities, which\nprovides valuable clues for inference. However, they have long ignored the dual\nnature of information inherent in entities, encompassing both high-level\ncoarse-grained cluster knowledge and fine-grained type knowledge. This paper\nintroduces Cross-view Optimal Transport for knowledge graph Entity Typing\n(COTET), a method that effectively incorporates the information on how types\nare clustered into the representation of entities and types. COTET comprises\nthree modules: i) Multi-view Generation and Encoder, which captures structured\nknowledge at different levels of granularity through entity-type,\nentity-cluster, and type-cluster-type perspectives; ii) Cross-view Optimal\nTransport, transporting view-specific embeddings to a unified space by\nminimizing the Wasserstein distance from a distributional alignment\nperspective; iii) Pooling-based Entity Typing Prediction, employing a mixture\npooling mechanism to aggregate prediction scores from diverse neighbors of an\nentity. Additionally, we introduce a distribution-based loss function to\nmitigate the occurrence of false negatives during training. Extensive\nexperiments demonstrate the effectiveness of COTET when compared to existing\nbaselines.",
      "tldr_zh": "本研究针对知识图谱实体分类(KGET)的挑战，提出COTET方法，通过Cross-view Optimal Transport整合实体的高层次粗粒度聚类知识和细粒度类型知识，以弥补传统方法的局限。COTET包括三个关键模块：Multi-view Generation and Encoder用于捕获不同粒度的结构化知识、Cross-view Optimal Transport通过最小化Wasserstein距离将视图嵌入映射到统一空间，以及Pooling-based Entity Typing Prediction利用混合池机制聚合预测分数。实验结果表明，该方法在减少假阴性方面表现出色，并比现有基线模型更有效。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13602v1",
      "published_date": "2024-05-22 12:53:12 UTC",
      "updated_date": "2024-05-22 12:53:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:35:28.188604"
    },
    {
      "arxiv_id": "2405.13586v2",
      "title": "Bond Graphs for multi-physics informed Neural Networks for multi-variate time series",
      "title_zh": "翻译失败",
      "authors": [
        "Alexis-Raja Brachet",
        "Pierre-Yves Richard",
        "Céline Hudelot"
      ],
      "abstract": "In the trend of hybrid Artificial Intelligence techniques, Physical-Informed\nMachine Learning has seen a growing interest. It operates mainly by imposing\ndata, learning, or architecture bias with simulation data, Partial Differential\nEquations, or equivariance and invariance properties. While it has shown great\nsuccess on tasks involving one physical domain, such as fluid dynamics,\nexisting methods are not adapted to tasks with complex multi-physical and\nmulti-domain phenomena. In addition, it is mainly formulated as an end-to-end\nlearning scheme. To address these challenges, we propose to leverage Bond\nGraphs, a multi-physics modeling approach, together with Message Passing Graph\nNeural Networks. We propose a Neural Bond graph Encoder (NBgE) producing\nmulti-physics-informed representations that can be fed into any task-specific\nmodel. It provides a unified way to integrate both data and architecture biases\nin deep learning. Our experiments on two challenging multi-domain physical\nsystems - a Direct Current Motor and the Respiratory System - demonstrate the\neffectiveness of our approach on a multivariate time-series forecasting task.",
      "tldr_zh": "该论文针对物理信息机器学习（Physical-Informed Machine Learning）的局限性，提出了一种结合 Bond Graphs 和 Message Passing Graph Neural Networks 的方法，以处理复杂多物理和多领域任务。研究开发了 Neural Bond graph Encoder (NBgE)，它能生成多物理信息化的表示，并统一整合数据和架构偏差，便于输入到特定任务模型中。在 Direct Current Motor 和 Respiratory System 等多领域系统上的实验表明，该方法在多变量时间序列预测任务中表现出显著有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 3 figures, paper under review",
      "pdf_url": "http://arxiv.org/pdf/2405.13586v2",
      "published_date": "2024-05-22 12:30:25 UTC",
      "updated_date": "2024-08-02 14:59:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:35:39.298870"
    },
    {
      "arxiv_id": "2405.13581v1",
      "title": "Safety Alignment for Vision Language Models",
      "title_zh": "视觉语言模型的安全对齐",
      "authors": [
        "Zhendong Liu",
        "Yuanbi Nie",
        "Yingshui Tan",
        "Xiangyu Yue",
        "Qiushi Cui",
        "Chongjun Wang",
        "Xiaoyong Zhu",
        "Bo Zheng"
      ],
      "abstract": "Benefiting from the powerful capabilities of Large Language Models (LLMs),\npre-trained visual encoder models connected to an LLMs can realize Vision\nLanguage Models (VLMs). However, existing research shows that the visual\nmodality of VLMs is vulnerable, with attackers easily bypassing LLMs' safety\nalignment through visual modality features to launch attacks. To address this\nissue, we enhance the existing VLMs' visual modality safety alignment by adding\nsafety modules, including a safety projector, safety tokens, and a safety head,\nthrough a two-stage training process, effectively improving the model's defense\nagainst risky images. For example, building upon the LLaVA-v1.5 model, we\nachieve a safety score of 8.26, surpassing the GPT-4V on the Red Teaming Visual\nLanguage Models (RTVLM) benchmark. Our method boasts ease of use, high\nflexibility, and strong controllability, and it enhances safety while having\nminimal impact on the model's general performance. Moreover, our alignment\nstrategy also uncovers some possible risky content within commonly used\nopen-source multimodal datasets. Our code will be open sourced after the\nanonymous review.",
      "tldr_zh": "本研究针对视觉语言模型（VLMs）的视觉模式易受攻击的问题，提出了一种安全对齐策略，通过添加安全模块（如 safety projector、safety tokens 和 safety head）并采用两阶段训练过程，提升模型对风险图像的防御能力。实验结果显示，该方法在 LLaVA-v1.5 模型上实现了 8.26 的安全分数，超过了 GPT-4V 在 RTVLM 基准上的表现，同时保持了模型整体性能的微小影响，并揭示了开源多模态数据集中的潜在风险内容。该策略具有易用性、高灵活性和强可控性，为 VLMs 的安全应用提供了有效解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "23 pages, 15 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.13581v1",
      "published_date": "2024-05-22 12:21:27 UTC",
      "updated_date": "2024-05-22 12:21:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:35:50.227360"
    },
    {
      "arxiv_id": "2405.13575v3",
      "title": "Unlocking the Power of Patch: Patch-Based MLP for Long-Term Time Series Forecasting",
      "title_zh": "解锁 Patch 的力量：基于 Patch 的 MLP 用于长期时间序列预测",
      "authors": [
        "Peiwang Tang",
        "Weitai Zhang"
      ],
      "abstract": "Recent studies have attempted to refine the Transformer architecture to\ndemonstrate its effectiveness in Long-Term Time Series Forecasting (LTSF)\ntasks. Despite surpassing many linear forecasting models with ever-improving\nperformance, we remain skeptical of Transformers as a solution for LTSF. We\nattribute the effectiveness of these models largely to the adopted Patch\nmechanism, which enhances sequence locality to an extent yet fails to fully\naddress the loss of temporal information inherent to the permutation-invariant\nself-attention mechanism. Further investigation suggests that simple linear\nlayers augmented with the Patch mechanism may outperform complex\nTransformer-based LTSF models. Moreover, diverging from models that use channel\nindependence, our research underscores the importance of cross-variable\ninteractions in enhancing the performance of multivariate time series\nforecasting. The interaction information between variables is highly valuable\nbut has been misapplied in past studies, leading to suboptimal cross-variable\nmodels. Based on these insights, we propose a novel and simple Patch-based MLP\n(PatchMLP) for LTSF tasks. Specifically, we employ simple moving averages to\nextract smooth components and noise-containing residuals from time series data,\nengaging in semantic information interchange through channel mixing and\nspecializing in random noise with channel independence processing. The PatchMLP\nmodel consistently achieves state-of-the-art results on several real-world\ndatasets. We hope this surprising finding will spur new research directions in\nthe LTSF field and pave the way for more efficient and concise solutions.",
      "tldr_zh": "该研究质疑了 Transformer 在长时序预测 (LTSF) 中的有效性，认为其性能主要依赖于 Patch 机制，而非自注意力机制。论文提出了一种简单有效的 Patch-based MLP (PatchMLP) 模型，通过简单移动平均提取平滑组件和残差，并利用通道混合进行跨变量交互，同时针对随机噪声采用通道独立处理。实验结果显示，PatchMLP 在多个真实数据集上超越了现有 Transformer 模型，强调了跨变量交互的价值，并有望激发 LTSF 领域更高效的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13575v3",
      "published_date": "2024-05-22 12:12:20 UTC",
      "updated_date": "2024-12-25 08:07:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:36:02.504006"
    },
    {
      "arxiv_id": "2405.13568v1",
      "title": "CPE-Identifier: Automated CPE identification and CVE summaries annotation with Deep Learning and NLP",
      "title_zh": "翻译失败",
      "authors": [
        "Wanyu Hu",
        "Vrizlynn L. L. Thing"
      ],
      "abstract": "With the drastic increase in the number of new vulnerabilities in the\nNational Vulnerability Database (NVD) every year, the workload for NVD analysts\nto associate the Common Platform Enumeration (CPE) with the Common\nVulnerabilities and Exposures (CVE) summaries becomes increasingly laborious\nand slow. The delay causes organisations, which depend on NVD for vulnerability\nmanagement and security measurement, to be more vulnerable to zero-day attacks.\nThus, it is essential to come out with a technique and tool to extract the CPEs\nin the CVE summaries accurately and quickly. In this work, we propose the\nCPE-Identifier system, an automated CPE annotating and extracting system, from\nthe CVE summaries. The system can be used as a tool to identify CPE entities\nfrom new CVE text inputs. Moreover, we also automate the data generating and\nlabeling processes using deep learning models. Due to the complexity of the CVE\ntexts, new technical terminologies appear frequently. To identify novel words\nin future CVE texts, we apply Natural Language Processing (NLP) Named Entity\nRecognition (NER), to identify new technical jargons in the text. Our proposed\nmodel achieves an F1 score of 95.48%, an accuracy score of 99.13%, a precision\nof 94.83%, and a recall of 96.14%. We show that it outperforms prior works on\nautomated CVE-CPE labeling by more than 9% on all metrics.",
      "tldr_zh": "该论文针对 NVD 中 CVE 摘要的 CPE 关联工作量增大和延迟问题，提出了一种自动化系统 CPE-Identifier，利用 Deep Learning 和 NLP 进行 CPE 识别和标注。该系统通过深度学习模型自动化数据生成和标注过程，并应用 NLP 中的 Named Entity Recognition (NER) 来识别 CVE 文本中的新技术术语。实验结果显示，模型的 F1 score 达到 95.48%、准确率 99.13%、精确率 94.83% 和召回率 96.14%，在所有指标上比现有方法提高了超过 9%。这为漏洞管理和安全测量提供了更高效的工具。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "International Conference on Information Systems Security and Privacy\n  2024",
      "pdf_url": "http://arxiv.org/pdf/2405.13568v1",
      "published_date": "2024-05-22 12:05:17 UTC",
      "updated_date": "2024-05-22 12:05:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:36:16.857909"
    },
    {
      "arxiv_id": "2405.13565v1",
      "title": "AI-Assisted Assessment of Coding Practices in Modern Code Review",
      "title_zh": "翻译失败",
      "authors": [
        "Manushree Vijayvergiya",
        "Małgorzata Salawa",
        "Ivan Budiselić",
        "Dan Zheng",
        "Pascal Lamblin",
        "Marko Ivanković",
        "Juanjo Carin",
        "Mateusz Lewko",
        "Jovan Andonov",
        "Goran Petrović",
        "Daniel Tarlow",
        "Petros Maniatis",
        "René Just"
      ],
      "abstract": "Modern code review is a process in which an incremental code contribution\nmade by a code author is reviewed by one or more peers before it is committed\nto the version control system. An important element of modern code review is\nverifying that code contributions adhere to best practices. While some of these\nbest practices can be automatically verified, verifying others is commonly left\nto human reviewers. This paper reports on the development, deployment, and\nevaluation of AutoCommenter, a system backed by a large language model that\nautomatically learns and enforces coding best practices. We implemented\nAutoCommenter for four programming languages (C++, Java, Python, and Go) and\nevaluated its performance and adoption in a large industrial setting. Our\nevaluation shows that an end-to-end system for learning and enforcing coding\nbest practices is feasible and has a positive impact on the developer workflow.\nAdditionally, this paper reports on the challenges associated with deploying\nsuch a system to tens of thousands of developers and the corresponding lessons\nlearned.",
      "tldr_zh": "本论文探讨了AI辅助现代代码审查中编码最佳实践的评估，开发了AutoCommenter系统，该系统利用大型语言模型(LLM)自动学习和强制执行编码规范。AutoCommenter针对C++、Java、Python和Go四种编程语言实现，并在大型工业环境中部署，评估结果显示其可行性并对开发人员工作流程产生积极影响。该研究还总结了向数万个开发人员部署系统的挑战和经验教训。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "To appear at the ACM International Conference on AI-Powered Software\n  (AIware '24)",
      "pdf_url": "http://arxiv.org/pdf/2405.13565v1",
      "published_date": "2024-05-22 11:57:18 UTC",
      "updated_date": "2024-05-22 11:57:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:36:26.074287"
    },
    {
      "arxiv_id": "2405.13560v1",
      "title": "Navigating User Experience of ChatGPT-based Conversational Recommender Systems: The Effects of Prompt Guidance and Recommendation Domain",
      "title_zh": "ChatGPT-based 对话式推荐系统的用户体验导航：提示指导和推荐领域的影响",
      "authors": [
        "Yizhe Zhang",
        "Yucheng Jin",
        "Li Chen",
        "Ting Yang"
      ],
      "abstract": "Conversational recommender systems (CRS) enable users to articulate their\npreferences and provide feedback through natural language. With the advent of\nlarge language models (LLMs), the potential to enhance user engagement with CRS\nand augment the recommendation process with LLM-generated content has received\nincreasing attention. However, the efficacy of LLM-powered CRS is contingent\nupon the use of prompts, and the subjective perception of recommendation\nquality can differ across various recommendation domains. Therefore, we have\ndeveloped a ChatGPT-based CRS to investigate the impact of these two factors,\nprompt guidance (PG) and recommendation domain (RD), on the overall user\nexperience of the system. We conducted an online empirical study (N = 100) by\nemploying a mixed-method approach that utilized a between-subjects design for\nthe variable of PG (with vs. without) and a within-subjects design for RD (book\nrecommendations vs. job recommendations). The findings reveal that PG can\nsubstantially enhance the system's explainability, adaptability, perceived ease\nof use, and transparency. Moreover, users are inclined to perceive a greater\nsense of novelty and demonstrate a higher propensity to engage with and try\nrecommended items in the context of book recommendations as opposed to job\nrecommendations. Furthermore, the influence of PG on certain user experience\nmetrics and interactive behaviors appears to be modulated by the recommendation\ndomain, as evidenced by the interaction effects between the two examined\nfactors. This work contributes to the user-centered evaluation of ChatGPT-based\nCRS by investigating two prominent factors and offers practical design\nguidance.",
      "tldr_zh": "本文研究了基于ChatGPT的对话推荐系统(CRS)中，提示指导(PG)和推荐领域(RD)对用户体验的影响，通过在线实证研究(N=100)采用混合设计（PG为组间变量，RD为组内变量，包括书籍和工作推荐）。结果显示，PG显著提升了系统的可解释性、可适应性、易用性和透明度，用户在书籍推荐领域更易感知新颖性并增加互动和尝试意愿。研究还发现PG的效果受RD调节，存在交互效应，并为ChatGPT-based CRS的用户中心评估和设计提供实用指导。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13560v1",
      "published_date": "2024-05-22 11:49:40 UTC",
      "updated_date": "2024-05-22 11:49:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:36:39.409855"
    },
    {
      "arxiv_id": "2405.13557v2",
      "title": "MotionCraft: Physics-based Zero-Shot Video Generation",
      "title_zh": "MotionCraft：基于物理的零样本视频生成",
      "authors": [
        "Luca Savant Aira",
        "Antonio Montanaro",
        "Emanuele Aiello",
        "Diego Valsesia",
        "Enrico Magli"
      ],
      "abstract": "Generating videos with realistic and physically plausible motion is one of\nthe main recent challenges in computer vision. While diffusion models are\nachieving compelling results in image generation, video diffusion models are\nlimited by heavy training and huge models, resulting in videos that are still\nbiased to the training dataset. In this work we propose MotionCraft, a new\nzero-shot video generator to craft physics-based and realistic videos.\nMotionCraft is able to warp the noise latent space of an image diffusion model,\nsuch as Stable Diffusion, by applying an optical flow derived from a physics\nsimulation. We show that warping the noise latent space results in coherent\napplication of the desired motion while allowing the model to generate missing\nelements consistent with the scene evolution, which would otherwise result in\nartefacts or missing content if the flow was applied in the pixel space. We\ncompare our method with the state-of-the-art Text2Video-Zero reporting\nqualitative and quantitative improvements, demonstrating the effectiveness of\nour approach to generate videos with finely-prescribed complex motion dynamics.\nProject page: https://mezzelfo.github.io/MotionCraft/",
      "tldr_zh": "该研究提出 MotionCraft，一种基于物理模拟的 zero-shot 视频生成方法，利用 optical flow 扭曲图像扩散模型（如 Stable Diffusion）的噪声潜在空间，从而创建物理真实且连贯的视频。\n与传统视频扩散模型相比，MotionCraft 避免了像素空间操作可能导致的伪影或内容缺失，确保生成元素与场景演化一致。\n实验结果显示，该方法在定性和定量指标上优于 Text2Video-Zero，能够有效生成精细的复杂运动动态视频。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13557v2",
      "published_date": "2024-05-22 11:44:57 UTC",
      "updated_date": "2024-10-25 10:01:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:36:52.632012"
    },
    {
      "arxiv_id": "2405.13554v3",
      "title": "The Influencer Next Door: How Misinformation Creators Use GenAI",
      "title_zh": "隔壁的网红：错误信息创建者如何使用 GenAI",
      "authors": [
        "Amelia Hassoun",
        "Ariel Abonizio",
        "Katy Osborn",
        "Cameron Wu",
        "Beth Goldberg"
      ],
      "abstract": "Advances in generative AI (GenAI) have raised concerns about detecting and\ndiscerning AI-generated content from human-generated content. Most existing\nliterature assumes a paradigm where 'expert' organized disinformation creators\nand flawed AI models deceive 'ordinary' users. Based on longitudinal\nethnographic research with misinformation creators and consumers between\n2022-2023, we instead find that GenAI supports bricolage work, where\nnon-experts increasingly use GenAI to remix, repackage, and (re)produce content\nto meet their personal needs and desires. This research yielded four key\nfindings: First, participants primarily used GenAI for creation, rather than\ntruth-seeking. Second, a spreading 'influencer millionaire' narrative drove\nparticipants to become content creators, using GenAI as a productivity tool to\ngenerate a volume of (often misinformative) content. Third, GenAI lowered the\nbarrier to entry for content creation across modalities, enticing consumers to\nbecome creators and significantly increasing existing creators' output.\nFinally, participants used Gen AI to learn and deploy marketing tactics to\nexpand engagement and monetize their content. We argue for shifting analysis\nfrom the public as consumers of AI content to bricoleurs who use GenAI\ncreatively, often without a detailed understanding of its underlying\ntechnology. We analyze how these understudied emergent uses of GenAI produce\nnew or accelerated misinformation harms, and their implications for AI\nproducts, platforms and policies.",
      "tldr_zh": "这篇论文通过2022-2023年的纵向民族志研究，探讨了非专家误信息创建者如何使用GenAI进行即兴创作(bricolage)，即混合、重打包和生产内容以满足个人需求，而不是求真。研究发现，“influencer millionaire”叙事驱动参与者成为内容创建者，利用GenAI作为生产力工具，大幅增加误导性内容的输出，并学习营销策略来扩大参与度和货币化。最终，论文强调GenAI降低了内容创建门槛，加速了误信息危害，并建议将分析焦点从公众作为AI内容消费者转向作为创意bricoleurs的用户，同时讨论其对AI产品、平台和政策的启示。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "44 pages, 25 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.13554v3",
      "published_date": "2024-05-22 11:40:22 UTC",
      "updated_date": "2024-06-18 09:29:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:37:04.796928"
    },
    {
      "arxiv_id": "2405.13551v1",
      "title": "Large Language Models are Effective Priors for Causal Graph Discovery",
      "title_zh": "大型语言模型是因果图发现的有效先验",
      "authors": [
        "Victor-Alexandru Darvariu",
        "Stephen Hailes",
        "Mirco Musolesi"
      ],
      "abstract": "Causal structure discovery from observations can be improved by integrating\nbackground knowledge provided by an expert to reduce the hypothesis space.\nRecently, Large Language Models (LLMs) have begun to be considered as sources\nof prior information given the low cost of querying them relative to a human\nexpert. In this work, firstly, we propose a set of metrics for assessing LLM\njudgments for causal graph discovery independently of the downstream algorithm.\nSecondly, we systematically study a set of prompting designs that allows the\nmodel to specify priors about the structure of the causal graph. Finally, we\npresent a general methodology for the integration of LLM priors in graph\ndiscovery algorithms, finding that they help improve performance on\ncommon-sense benchmarks and especially when used for assessing edge\ndirectionality. Our work highlights the potential as well as the shortcomings\nof the use of LLMs in this problem space.",
      "tldr_zh": "本研究探讨了大型语言模型 (LLMs) 作为因果图发现的有效先验知识，以减少假设空间并提升性能。论文提出一套指标来独立评估 LLMs 在因果图发现中的判断准确性，并系统设计了提示策略，让模型指定因果图结构的先验信息。随后，他们开发了一个通用方法，将 LLMs 先验整合到图发现算法中，实验显示这在常识基准上显著提高了性能，尤其在边方向性评估方面。最后，研究突出了 LLMs 在此领域的潜力，同时指出了其存在的局限性，如潜在的不准确性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13551v1",
      "published_date": "2024-05-22 11:39:11 UTC",
      "updated_date": "2024-05-22 11:39:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:37:15.465177"
    },
    {
      "arxiv_id": "2405.13547v1",
      "title": "HighwayLLM: Decision-Making and Navigation in Highway Driving with RL-Informed Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Mustafa Yildirim",
        "Barkin Dagda",
        "Saber Fallah"
      ],
      "abstract": "Autonomous driving is a complex task which requires advanced decision making\nand control algorithms. Understanding the rationale behind the autonomous\nvehicles' decision is crucial to ensure their safe and effective operation on\nhighway driving. This study presents a novel approach, HighwayLLM, which\nharnesses the reasoning capabilities of large language models (LLMs) to predict\nthe future waypoints for ego-vehicle's navigation. Our approach also utilizes a\npre-trained Reinforcement Learning (RL) model to serve as a high-level planner,\nmaking decisions on appropriate meta-level actions. The HighwayLLM combines the\noutput from the RL model and the current state information to make safe,\ncollision-free, and explainable predictions for the next states, thereby\nconstructing a trajectory for the ego-vehicle. Subsequently, a PID-based\ncontroller guides the vehicle to the waypoints predicted by the LLM agent. This\nintegration of LLM with RL and PID enhances the decision-making process and\nprovides interpretability for highway autonomous driving.",
      "tldr_zh": "本研究提出 HighwayLLM，一种结合大型语言模型 (LLMs) 和强化学习 (RL) 的框架，用于高速公路自主驾驶的决策和导航。HighwayLLM 利用预训练的 RL 模型作为高层规划器，生成元级动作，并结合当前状态信息，通过 LLMs 预测安全、无碰撞的未来路径点。最终，使用 PID-based 控制器引导车辆跟踪这些路径点，从而提升决策过程的可解释性和整体可靠性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13547v1",
      "published_date": "2024-05-22 11:32:37 UTC",
      "updated_date": "2024-05-22 11:32:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:37:28.778820"
    },
    {
      "arxiv_id": "2405.13541v1",
      "title": "Annotation-Efficient Preference Optimization for Language Model Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Yuu Jinnai",
        "Ukyo Honda"
      ],
      "abstract": "Preference optimization is a standard approach to fine-tuning large language\nmodels to align with human preferences. The quality, diversity, and quantity of\nthe preference dataset are critical to the effectiveness of preference\noptimization. However, obtaining a large amount of high-quality and diverse\npreference annotations is difficult in many applications. This raises the\nquestion of how to use the limited annotation budget to create an effective\npreference dataset. To this end, we propose Annotation-Efficient Preference\nOptimization (AEPO). Instead of exhaustively annotating preference over all\navailable response texts, AEPO selects a subset of responses that maximizes\nquality and diversity from the available responses, and then annotates\npreference over the selected ones. In this way, AEPO focuses the annotation\nbudget on labeling preference over a smaller subset of responses with diversity\nand of high quality. We evaluate the performance of Direct Preference\nOptimization (DPO) using AEPO and show that it outperforms models trained using\na standard DPO with the same annotation budget. Our code is available at\nhttps://github.com/CyberAgentAILab/annotation-efficient-po",
      "tldr_zh": "本文提出 Annotation-Efficient Preference Optimization (AEPO)，一种高效方法，用于优化语言模型对人类偏好的微调过程，以应对获取高质量、多样化偏好数据集的挑战。AEPO 通过从可用响应中选择子集最大化质量和多样性，然后仅对这些子集进行偏好标注，从而有效利用有限的标注预算。实验结果显示，使用 AEPO 训练的 Direct Preference Optimization (DPO) 模型在相同标注预算下优于标准 DPO 模型，提升了整体性能。代码已在 GitHub 上开源。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13541v1",
      "published_date": "2024-05-22 11:23:03 UTC",
      "updated_date": "2024-05-22 11:23:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:37:39.654617"
    },
    {
      "arxiv_id": "2405.13536v2",
      "title": "Attention Mechanisms Don't Learn Additive Models: Rethinking Feature Importance for Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Tobias Leemann",
        "Alina Fastowski",
        "Felix Pfeiffer",
        "Gjergji Kasneci"
      ],
      "abstract": "We address the critical challenge of applying feature attribution methods to\nthe transformer architecture, which dominates current applications in natural\nlanguage processing and beyond. Traditional attribution methods to explainable\nAI (XAI) explicitly or implicitly rely on linear or additive surrogate models\nto quantify the impact of input features on a model's output. In this work, we\nformally prove an alarming incompatibility: transformers are structurally\nincapable of representing linear or additive surrogate models used for feature\nattribution, undermining the grounding of these conventional explanation\nmethodologies. To address this discrepancy, we introduce the Softmax-Linked\nAdditive Log Odds Model (SLALOM), a novel surrogate model specifically designed\nto align with the transformer framework. SLALOM demonstrates the capacity to\ndeliver a range of insightful explanations with both synthetic and real-world\ndatasets. We highlight SLALOM's unique efficiency-quality curve by showing that\nSLALOM can produce explanations with substantially higher fidelity than\ncompeting surrogate models or provide explanations of comparable quality at a\nfraction of their computational costs. We release code for SLALOM as an\nopen-source project online at https://github.com/tleemann/slalom_explanations.",
      "tldr_zh": "本文重新审视了在 Transformer 架构中应用特征归因方法（feature attribution methods）的挑战，证明了 Transformer 结构上无法表示传统的线性或加性代理模型（additive surrogate models），从而破坏了可解释 AI (XAI) 的基础。作者提出了一种新型代理模型 Softmax-Linked Additive Log Odds Model (SLALOM)，专门设计来与 Transformer 框架兼容，能够提供更具洞见的解释。实验结果显示，SLALOM 在合成和真实数据集上比竞争模型具有更高的保真度（fidelity），并能在更低的计算成本下生成可比质量的解释。论文开源了 SLALOM 的代码，以促进进一步研究。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "TMLR Camera-Ready version",
      "pdf_url": "http://arxiv.org/pdf/2405.13536v2",
      "published_date": "2024-05-22 11:14:00 UTC",
      "updated_date": "2025-01-09 17:58:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:37:52.780752"
    },
    {
      "arxiv_id": "2405.13527v1",
      "title": "End-to-End Real-World Polyphonic Piano Audio-to-Score Transcription with Hierarchical Decoding",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Zeng",
        "Xian He",
        "Ye Wang"
      ],
      "abstract": "Piano audio-to-score transcription (A2S) is an important yet underexplored\ntask with extensive applications for music composition, practice, and analysis.\nHowever, existing end-to-end piano A2S systems faced difficulties in retrieving\nbar-level information such as key and time signatures, and have been trained\nand evaluated with only synthetic data. To address these limitations, we\npropose a sequence-to-sequence (Seq2Seq) model with a hierarchical decoder that\naligns with the hierarchical structure of musical scores, enabling the\ntranscription of score information at both the bar and note levels by\nmulti-task learning. To bridge the gap between synthetic data and recordings of\nhuman performance, we propose a two-stage training scheme, which involves\npre-training the model using an expressive performance rendering (EPR) system\non synthetic audio, followed by fine-tuning the model using recordings of human\nperformance. To preserve the voicing structure for score reconstruction, we\npropose a pre-processing method for **Kern scores in scenarios with an\nunconstrained number of voices. Experimental results support the effectiveness\nof our proposed approaches, in terms of both transcription performance on\nsynthetic audio data in comparison to the current state-of-the-art, and the\nfirst experiment on human recordings.",
      "tldr_zh": "本文提出了一种端到端的钢琴音频到乐谱转录（A2S）系统，使用Seq2Seq模型和hierarchical decoder来处理多声部音乐的层次结构，通过multi-task learning同时处理小节级（如调号和拍号）和音符级信息。系统采用两阶段训练方案，先用表达性能渲染（EPR）系统在合成音频上预训练，再用人类表演录音微调，以桥接合成数据与真实录音的差距；此外，还引入Kern scores的预处理方法来保留voicing structure，支持不受限的声部数量。实验结果表明，该方法在合成音频上超越现有最先进技术，并在人类录音上实现了首次有效评估，显著提升了转录性能。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "8 pages, 5 figures, accepted by IJCAI 2024 - AI, Arts & Creativity\n  Track",
      "pdf_url": "http://arxiv.org/pdf/2405.13527v1",
      "published_date": "2024-05-22 10:52:04 UTC",
      "updated_date": "2024-05-22 10:52:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:38:04.948289"
    },
    {
      "arxiv_id": "2405.13522v2",
      "title": "Beyond Trend and Periodicity: Guiding Time Series Forecasting with Textual Cues",
      "title_zh": "超越趋势和周期性：利用文本提示引导时间序列预测",
      "authors": [
        "Zhijian Xu",
        "Yuxuan Bian",
        "Jianyuan Zhong",
        "Xiangyu Wen",
        "Qiang Xu"
      ],
      "abstract": "This work introduces a novel Text-Guided Time Series Forecasting (TGTSF)\ntask. By integrating textual cues, such as channel descriptions and dynamic\nnews, TGTSF addresses the critical limitations of traditional methods that rely\npurely on historical data. To support this task, we propose TGForecaster, a\nrobust baseline model that fuses textual cues and time series data using\ncross-attention mechanisms. We then present four meticulously curated benchmark\ndatasets to validate the proposed framework, ranging from simple periodic data\nto complex, event-driven fluctuations. Our comprehensive evaluations\ndemonstrate that TGForecaster consistently achieves state-of-the-art\nperformance, highlighting the transformative potential of incorporating textual\ninformation into time series forecasting. This work not only pioneers a novel\nforecasting task but also establishes a new benchmark for future research,\ndriving advancements in multimodal data integration for time series models.",
      "tldr_zh": "本研究引入了Text-Guided Time Series Forecasting (TGTSF)任务，通过整合文本线索（如通道描述和动态新闻），克服了传统时间序列预测方法仅依赖历史数据的局限性。研究提出TGForecaster基线模型，使用cross-attention mechanisms融合文本和时间序列数据，以实现更准确的预测。为验证框架，构建了四个精心策划的基准数据集，从简单周期数据到复杂事件驱动波动。评估结果显示，TGForecaster在这些数据集上 consistently achieves state-of-the-art performance，推动了多模态数据集成在时间序列模型中的创新和未来研究。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13522v2",
      "published_date": "2024-05-22 10:45:50 UTC",
      "updated_date": "2024-05-24 15:10:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:38:15.410916"
    },
    {
      "arxiv_id": "2405.13515v1",
      "title": "Multi-Scale Feature Fusion Quantum Depthwise Convolutional Neural Networks for Text Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Yixiong Chen",
        "Weichuan Fang"
      ],
      "abstract": "In recent years, with the development of quantum machine learning, quantum\nneural networks (QNNs) have gained increasing attention in the field of natural\nlanguage processing (NLP) and have achieved a series of promising results.\nHowever, most existing QNN models focus on the architectures of quantum\nrecurrent neural network (QRNN) and self-attention mechanism (QSAM). In this\nwork, we propose a novel QNN model based on quantum convolution. We develop the\nquantum depthwise convolution that significantly reduces the number of\nparameters and lowers computational complexity. We also introduce the\nmulti-scale feature fusion mechanism to enhance model performance by\nintegrating word-level and sentence-level features. Additionally, we propose\nthe quantum word embedding and quantum sentence embedding, which provide\nembedding vectors more efficiently. Through experiments on two benchmark text\nclassification datasets, we demonstrate our model outperforms a wide range of\nstate-of-the-art QNN models. Notably, our model achieves a new state-of-the-art\ntest accuracy of 96.77% on the RP dataset. We also show the advantages of our\nquantum model over its classical counterparts in its ability to improve test\naccuracy using fewer parameters. Finally, an ablation test confirms the\neffectiveness of the multi-scale feature fusion mechanism and quantum depthwise\nconvolution in enhancing model performance.",
      "tldr_zh": "这篇论文提出了一种基于量子深度卷积（Quantum Depthwise Convolution）的神经网络，用于文本分类，旨在解决现有量子神经网络（QNNs）模型在参数和计算复杂度上的问题。模型引入多尺度特征融合机制（Multi-Scale Feature Fusion）来整合词级和句子级特征，并采用量子词嵌入（Quantum Word Embedding）和量子句子嵌入（Quantum Sentence Embedding）以提高嵌入效率。在两个基准文本分类数据集上的实验显示，该模型优于多种 state-of-the-art QNNs，特别是在 RP 数据集上达到 96.77% 的新测试准确率，且使用更少参数就实现了更高的性能，消融实验进一步证实了关键组件的有效性。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13515v1",
      "published_date": "2024-05-22 10:19:34 UTC",
      "updated_date": "2024-05-22 10:19:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:38:27.917945"
    },
    {
      "arxiv_id": "2405.13488v1",
      "title": "Non-Deterministic Planning for Hyperproperty Verification",
      "title_zh": "翻译失败",
      "authors": [
        "Raven Beutner",
        "Bernd Finkbeiner"
      ],
      "abstract": "Non-deterministic planning aims to find a policy that achieves a given\nobjective in an environment where actions have uncertain effects, and the agent\n- potentially - only observes parts of the current state. Hyperproperties are\nproperties that relate multiple paths of a system and can, e.g., capture\nsecurity and information-flow policies. Popular logics for expressing temporal\nhyperproperties - such as HyperLTL - extend LTL by offering selective\nquantification over executions of a system. In this paper, we show that\nplanning offers a powerful intermediate language for the automated verification\nof hyperproperties. Concretely, we present an algorithm that, given a HyperLTL\nverification problem, constructs a non-deterministic multi-agent planning\ninstance (in the form of a QDec-POMDP) that, when admitting a plan, implies the\nsatisfaction of the verification problem. We show that for large fragments of\nHyperLTL, the resulting planning instance corresponds to a classical, FOND, or\nPOND planning problem. We implement our encoding in a prototype verification\ntool and report on encouraging experimental results.",
      "tldr_zh": "这篇论文探讨了非确定性规划在超属性（hyperproperties）验证中的应用，旨在处理动作不确定性和部分状态观察的环境。作者提出了一种算法，将 HyperLTL 验证问题转换为非确定性多智能体规划实例（QDec-POMDP），如果该实例存在计划，则证明验证问题得到满足。对于 HyperLTL 的较大片段，该规划实例可简化为经典的、FOND 或 POND 规划问题。实验结果显示，该方法在原型工具中表现出色，验证了其有效性。",
      "categories": [
        "cs.LO",
        "cs.AI",
        "cs.FL"
      ],
      "primary_category": "cs.LO",
      "comment": "ICAPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.13488v1",
      "published_date": "2024-05-22 09:57:49 UTC",
      "updated_date": "2024-05-22 09:57:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:38:40.379145"
    },
    {
      "arxiv_id": "2405.13487v2",
      "title": "Qualitative and quantitative analysis of student's perceptions in the use of generative AI in educational environments",
      "title_zh": "翻译失败",
      "authors": [
        "Sergio Altares-López",
        "José M. Bengochea-Guevara",
        "Carlos Ranz",
        "Héctor Montes",
        "Angela Ribeiro"
      ],
      "abstract": "The effective integration of generative artificial intelligence in education\nis a fundamental aspect to prepare future generations. The objective of this\nstudy is to analyze from a quantitative and qualitative point of view the\nperception of controlled student-IA interaction within the classroom. This\nanalysis includes assessing the ethical implications and everyday use of AI\ntools, as well as understanding whether AI tools encourage students to pursue\nSTEM careers. Several points for improvement in education are found, such as\nthe challenge of getting teachers to engage with new technologies and adapt\ntheir methods in all subjects, not just those related to technologies.",
      "tldr_zh": "本研究通过定性和定量方法分析了学生在使用generative AI的教育环境中的感知，旨在评估AI工具的伦理影响、日常应用以及是否能鼓励学生追求STEM careers。研究发现，AI在教育中的有效整合面临挑战，包括教师对新技术的参与不足和方法适应的困难。总体而言，该工作为提升教育质量提供了改进建议，促进未来AI在教学中的应用。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "17 pages, 7 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2405.13487v2",
      "published_date": "2024-05-22 09:56:05 UTC",
      "updated_date": "2024-09-02 11:43:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:38:51.894756"
    },
    {
      "arxiv_id": "2405.13474v1",
      "title": "Why do explanations fail? A typology and discussion on failures in XAI",
      "title_zh": "翻译失败",
      "authors": [
        "Clara Bove",
        "Thibault Laugel",
        "Marie-Jeanne Lesot",
        "Charles Tijus",
        "Marcin Detyniecki"
      ],
      "abstract": "As Machine Learning (ML) models achieve unprecedented levels of performance,\nthe XAI domain aims at making these models understandable by presenting\nend-users with intelligible explanations. Yet, some existing XAI approaches\nfail to meet expectations: several issues have been reported in the literature,\ngenerally pointing out either technical limitations or misinterpretations by\nusers. In this paper, we argue that the resulting harms arise from a complex\noverlap of multiple failures in XAI, which existing ad-hoc studies fail to\ncapture. This work therefore advocates for a holistic perspective, presenting a\nsystematic investigation of limitations of current XAI methods and their impact\non the interpretation of explanations. By distinguishing between\nsystem-specific and user-specific failures, we propose a typological framework\nthat helps revealing the nuanced complexities of explanation failures.\nLeveraging this typology, we also discuss some research directions to help AI\npractitioners better understand the limitations of XAI systems and enhance the\nquality of ML explanations.",
      "tldr_zh": "这篇论文探讨了XAI（可解释人工智能）中解释失败的原因，分析了现有方法的技术限制和用户误解问题，导致ML（机器学习）模型解释不尽如人意。作者提出一个typological framework，将失败分类为system-specific（系统特定）和user-specific（用户特定）类型，以系统地揭示解释失败的复杂性及其影响。最终，论文讨论了研究方向，帮助AI从业者更好地理解XAI的局限性，并提升ML解释的质量。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13474v1",
      "published_date": "2024-05-22 09:32:24 UTC",
      "updated_date": "2024-05-22 09:32:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:39:03.847393"
    },
    {
      "arxiv_id": "2405.13473v2",
      "title": "Class-Conditional self-reward mechanism for improved Text-to-Image models",
      "title_zh": "类别条件自我奖励机制用于改进的文本到图像模型",
      "authors": [
        "Safouane El Ghazouali",
        "Arnaud Gucciardi",
        "Umberto Michelucci"
      ],
      "abstract": "Self-rewarding have emerged recently as a powerful tool in the field of\nNatural Language Processing (NLP), allowing language models to generate\nhigh-quality relevant responses by providing their own rewards during training.\nThis innovative technique addresses the limitations of other methods that rely\non human preferences. In this paper, we build upon the concept of\nself-rewarding models and introduce its vision equivalent for Text-to-Image\ngenerative AI models. This approach works by fine-tuning diffusion model on a\nself-generated self-judged dataset, making the fine-tuning more automated and\nwith better data quality. The proposed mechanism makes use of other pre-trained\nmodels such as vocabulary based-object detection, image captioning and is\nconditioned by the a set of object for which the user might need to improve\ngenerated data quality. The approach has been implemented, fine-tuned and\nevaluated on stable diffusion and has led to a performance that has been\nevaluated to be at least 60\\% better than existing commercial and research\nText-to-image models. Additionally, the built self-rewarding mechanism allowed\na fully automated generation of images, while increasing the visual quality of\nthe generated images and also more efficient following of prompt instructions.\nThe code used in this work is freely available on\nhttps://github.com/safouaneelg/SRT2I.",
      "tldr_zh": "本论文提出了一种基于 class-conditional 的 self-rewarding 机制，用于提升 Text-to-Image 生成模型的性能，通过在自生成自判断的数据集上微调 diffusion model，并利用预训练模型如词汇-based 对象检测和图像描述进行条件化训练。相比传统依赖人类偏好的方法，该机制实现了自动化微调，提高了数据质量和模型对提示指令的遵循。实验结果显示，在 Stable Diffusion 上，该方法比现有商业和研究模型至少提升60%的性能，同时提高了生成图像的视觉质量，且代码已开源于 https://github.com/safouaneelg/SRT2I。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13473v2",
      "published_date": "2024-05-22 09:28:43 UTC",
      "updated_date": "2024-05-25 07:05:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:39:17.942082"
    },
    {
      "arxiv_id": "2405.13462v1",
      "title": "Blockchain and Artificial Intelligence: Synergies and Conflicts",
      "title_zh": "翻译失败",
      "authors": [
        "Leon Witt",
        "Armando Teles Fortes",
        "Kentaroh Toyoda",
        "Wojciech Samek",
        "Dan Li"
      ],
      "abstract": "Blockchain technology and Artificial Intelligence (AI) have emerged as\ntransformative forces in their respective domains. This paper explores\nsynergies and challenges between these two technologies. Our research analyses\nthe biggest projects combining blockchain and AI, based on market\ncapitalization, and derives a novel framework to categorize contemporary and\nfuture use cases. Despite the theoretical compatibility, current real-world\napplications combining blockchain and AI remain in their infancy.",
      "tldr_zh": "这篇论文探讨了Blockchain技术和Artificial Intelligence (AI)之间的协同作用与冲突，分析了市值最大的关键项目，并提出一个新框架来分类当代和未来的用例。该框架有助于识别这些技术的潜在应用，尽管理论上两者高度兼容，但实际结合的真实世界应用目前仍处于初期阶段。通过这一研究，论文为未来区块链和AI的整合提供了宝贵见解。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.DC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13462v1",
      "published_date": "2024-05-22 09:04:52 UTC",
      "updated_date": "2024-05-22 09:04:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:39:27.327744"
    },
    {
      "arxiv_id": "2405.13461v1",
      "title": "Analogical proportions II",
      "title_zh": "翻译失败",
      "authors": [
        "Christian Antić"
      ],
      "abstract": "Analogical reasoning is the ability to detect parallels between two seemingly\ndistant objects or situations, a fundamental human capacity used for example in\ncommonsense reasoning, learning, and creativity which is believed by many\nresearchers to be at the core of human and artificial general intelligence.\nAnalogical proportions are expressions of the form ``$a$ is to $b$ what $c$ is\nto $d$'' at the core of analogical reasoning. The author has recently\nintroduced an abstract algebraic framework of analogical proportions within the\ngeneral setting of universal algebra. It is the purpose of this paper to\nfurther develop the mathematical theory of analogical proportions within that\nframework as motivated by the fact that it has already been successfully\napplied to logic program synthesis in artificial intelligence.",
      "tldr_zh": "这篇论文探讨了类比推理（analogical reasoning）的数学理论，聚焦于类比比例（analogical proportions），如“A is to B what C is to D”的形式，认为它是人类和人工智能核心能力的体现。作者基于先前在通用代数（universal algebra）框架下的抽象模型，进一步发展了这一理论，以支持其在人工智能领域的应用。特别地，该框架已在逻辑程序合成（logic program synthesis）中取得成功，旨在提升常识推理、学习和创造力的能力。",
      "categories": [
        "cs.LO",
        "cs.AI",
        "cs.DM",
        "math.LO"
      ],
      "primary_category": "cs.LO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13461v1",
      "published_date": "2024-05-22 09:02:12 UTC",
      "updated_date": "2024-05-22 09:02:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:39:39.865150"
    },
    {
      "arxiv_id": "2405.13449v1",
      "title": "Input Guided Multiple Deconstruction Single Reconstruction neural network models for Matrix Factorization",
      "title_zh": "输入引导的多重分解单次重建神经网络模型用于矩阵分解",
      "authors": [
        "Prasun Dutta",
        "Rajat K. De"
      ],
      "abstract": "Referring back to the original text in the course of hierarchical learning is\na common human trait that ensures the right direction of learning. The models\ndeveloped based on the concept of Non-negative Matrix Factorization (NMF), in\nthis paper are inspired by this idea. They aim to deal with high-dimensional\ndata by discovering its low rank approximation by determining a unique pair of\nfactor matrices. The model, named Input Guided Multiple Deconstruction Single\nReconstruction neural network for Non-negative Matrix Factorization\n(IG-MDSR-NMF), ensures the non-negativity constraints of both factors. Whereas\nInput Guided Multiple Deconstruction Single Reconstruction neural network for\nRelaxed Non-negative Matrix Factorization (IG-MDSR-RNMF) introduces a novel\nidea of factorization with only the basis matrix adhering to the non-negativity\ncriteria. This relaxed version helps the model to learn more enriched low\ndimensional embedding of the original data matrix. The competency of preserving\nthe local structure of data in its low rank embedding produced by both the\nmodels has been appropriately verified. The superiority of low dimensional\nembedding over that of the original data justifying the need for dimension\nreduction has been established. The primacy of both the models has also been\nvalidated by comparing their performances separately with that of nine other\nestablished dimension reduction algorithms on five popular datasets. Moreover,\ncomputational complexity of the models and convergence analysis have also been\npresented testifying to the supremacy of the models.",
      "tldr_zh": "本论文受人类学习中回溯原始文本的启发，提出两种基于 Matrix Factorization 的神经网络模型：IG-MDSR-NMF 和 IG-MDSR-RNMF，用于处理高维数据并发现其低秩逼近。IG-MDSR-NMF 确保因子矩阵的非负性约束，而 IG-MDSR-RNMF 则仅要求基础矩阵非负，从而实现更丰富的低维嵌入。实验验证了这些模型在保留数据局部结构方面的能力，并与九种其他降维算法在五个数据集上比较，证明了其优越性；此外，论文还分析了模型的计算复杂度和收敛性，强调了降维的必要性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "50 pages, 25 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.13449v1",
      "published_date": "2024-05-22 08:41:32 UTC",
      "updated_date": "2024-05-22 08:41:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:39:53.581252"
    },
    {
      "arxiv_id": "2405.13445v1",
      "title": "Task-agnostic Decision Transformer for Multi-type Agent Control with Federated Split Training",
      "title_zh": "任务无关的决策",
      "authors": [
        "Zhiyuan Wang",
        "Bokui Chen",
        "Xiaoyang Qu",
        "Zhenhou Hong",
        "Jing Xiao",
        "Jianzong Wang"
      ],
      "abstract": "With the rapid advancements in artificial intelligence, the development of\nknowledgeable and personalized agents has become increasingly prevalent.\nHowever, the inherent variability in state variables and action spaces among\npersonalized agents poses significant aggregation challenges for traditional\nfederated learning algorithms. To tackle these challenges, we introduce the\nFederated Split Decision Transformer (FSDT), an innovative framework designed\nexplicitly for AI agent decision tasks. The FSDT framework excels at navigating\nthe intricacies of personalized agents by harnessing distributed data for\ntraining while preserving data privacy. It employs a two-stage training\nprocess, with local embedding and prediction models on client agents and a\nglobal transformer decoder model on the server. Our comprehensive evaluation\nusing the benchmark D4RL dataset highlights the superior performance of our\nalgorithm in federated split learning for personalized agents, coupled with\nsignificant reductions in communication and computational overhead compared to\ntraditional centralized training approaches. The FSDT framework demonstrates\nstrong potential for enabling efficient and privacy-preserving collaborative\nlearning in applications such as autonomous driving decision systems. Our\nfindings underscore the efficacy of the FSDT framework in effectively\nleveraging distributed offline reinforcement learning data to enable powerful\nmulti-type agent decision systems.",
      "tldr_zh": "该研究提出Federated Split Decision Transformer (FSDT)，一个任务无关的决策转换器框架，用于处理多类型代理控制中的联邦学习挑战，特别是个性化代理的状态变量和动作空间变异性问题。FSDT 通过分布式数据训练和两阶段过程实现数据隐私保护：客户端处理本地嵌入和预测模型，服务器管理全局transformer解码器模型。与传统集中式训练相比，该框架在D4RL基准数据集上表现出色，显著降低了通信和计算开销。实验结果证明，FSDT 有效利用分布式离线强化学习数据，支持高效的协作学习应用，如自主驾驶决策系统。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by the 2024 International Joint Conference on Neural\n  Networks (IJCNN 2024)",
      "pdf_url": "http://arxiv.org/pdf/2405.13445v1",
      "published_date": "2024-05-22 08:37:37 UTC",
      "updated_date": "2024-05-22 08:37:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:40:04.328031"
    },
    {
      "arxiv_id": "2405.13432v1",
      "title": "Disperse-Then-Merge: Pushing the Limits of Instruction Tuning via Alignment Tax Reduction",
      "title_zh": "Disperse-Then-Merge：通过减少对齐税推动指令微调的极限",
      "authors": [
        "Tingchen Fu",
        "Deng Cai",
        "Lemao Liu",
        "Shuming Shi",
        "Rui Yan"
      ],
      "abstract": "Supervised fine-tuning (SFT) on instruction-following corpus is a crucial\napproach toward the alignment of large language models (LLMs). However, the\nperformance of LLMs on standard knowledge and reasoning benchmarks tends to\nsuffer from deterioration at the latter stage of the SFT process, echoing the\nphenomenon of alignment tax. Through our pilot study, we put a hypothesis that\nthe data biases are probably one cause behind the phenomenon. To address the\nissue, we introduce a simple disperse-then-merge framework. To be concrete, we\ndisperse the instruction-following data into portions and train multiple\nsub-models using different data portions. Then we merge multiple models into a\nsingle one via model merging techniques. Despite its simplicity, our framework\noutperforms various sophisticated methods such as data curation and training\nregularization on a series of standard knowledge and reasoning benchmarks.",
      "tldr_zh": "这篇论文探讨了在 Supervised Fine-Tuning (SFT) 过程中，大型语言模型 (LLMs) 性能下降的现象，即 alignment tax，并假设数据偏差是主要原因。作者提出 Disperse-Then-Merge 框架，通过将指令跟随数据分散成多个部分分别训练子模型，然后使用模型合并技术将它们整合成单一模型。该框架简单有效，在标准知识和推理基准上超过了数据整理和训练正则化等方法，显著降低了 alignment tax 的影响。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to the findings of ACL2024",
      "pdf_url": "http://arxiv.org/pdf/2405.13432v1",
      "published_date": "2024-05-22 08:18:19 UTC",
      "updated_date": "2024-05-22 08:18:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:40:17.225082"
    },
    {
      "arxiv_id": "2405.13426v1",
      "title": "A New Era in Human Factors Engineering: A Survey of the Applications and Prospects of Large Multimodal Models",
      "title_zh": "人类因素工程的新时代：大型多模态模型的应用和前景调查",
      "authors": [
        "Li Fan",
        "Lee Ching-Hung",
        "Han Su",
        "Feng Shanshan",
        "Jiang Zhuoxuan",
        "Sun Zhu"
      ],
      "abstract": "In recent years, the potential applications of Large Multimodal Models (LMMs)\nin fields such as healthcare, social psychology, and industrial design have\nattracted wide research attention, providing new directions for human factors\nresearch. For instance, LMM-based smart systems have become novel research\nsubjects of human factors studies, and LMM introduces new research paradigms\nand methodologies to this field. Therefore, this paper aims to explore the\napplications, challenges, and future prospects of LMM in the domain of human\nfactors and ergonomics through an expert-LMM collaborated literature review.\nSpecifically, a novel literature review method is proposed, and research\nstudies of LMM-based accident analysis, human modelling and intervention design\nare introduced. Subsequently, the paper discusses future trends of the research\nparadigm and challenges of human factors and ergonomics studies in the era of\nLMMs. It is expected that this study can provide a valuable perspective and\nserve as a reference for integrating human factors with artificial\nintelligence.",
      "tldr_zh": "这篇论文调查了 Large Multimodal Models (LMMs) 在人类因素工程领域的应用和前景，强调 LMMs 如何为医疗、社会心理学和工业设计等行业带来新研究方向和范式。作者提出了一种专家-LMM 合作的文献综述方法，探讨了 LMMs 在事故分析、人类建模和干预设计中的具体应用，并分析了相关挑战。最终，该研究为人类因素工程与人工智能的整合提供了宝贵视角和参考。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "14 pages, journal paper",
      "pdf_url": "http://arxiv.org/pdf/2405.13426v1",
      "published_date": "2024-05-22 08:14:40 UTC",
      "updated_date": "2024-05-22 08:14:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:40:28.417755"
    },
    {
      "arxiv_id": "2405.13407v1",
      "title": "Dynamic Context Adaptation and Information Flow Control in Transformers: Introducing the Evaluator Adjuster Unit and Gated Residual Connections",
      "title_zh": "翻译失败",
      "authors": [
        "Sahil Rajesh Dhayalkar"
      ],
      "abstract": "Transformers have revolutionized various domains of artificial intelligence\ndue to their unique ability to model long-range dependencies in data. However,\nthey lack in nuanced, context-dependent modulation of features and information\nflow. This paper introduces two significant enhancements to the transformer\narchitecture - the Evaluator Adjuster Unit (EAU) and Gated Residual Connections\n(GRC) - designed to address these limitations. The EAU dynamically modulates\nattention outputs based on the relevance of the input context, allowing for\nmore adaptive response patterns. Concurrently, the GRC modifies the\ntransformer's residual connections through a gating mechanism that selectively\ncontrols the information flow, thereby enhancing the network's ability to focus\non contextually important features. We evaluate the performance of these\nenhancements across several benchmarks in natural language processing. Our\nresults demonstrate improved adaptability and efficiency, suggesting that these\nmodifications could set new standards for designing flexible and context-aware\ntransformer models.",
      "tldr_zh": "本研究针对 Transformers 模型在建模长距离依赖时缺乏细致上下文调制和信息流控制的问题，引入了两个关键增强：Evaluator Adjuster Unit (EAU) 和 Gated Residual Connections (GRC)。EAU 通过动态评估输入上下文的相关性来调制注意力输出，从而实现更 adaptive 的响应模式；GRC 则通过门控机制选择性地控制残差连接中的信息流，提升模型对重要特征的关注。实验结果显示，这些改进在自然语言处理基准上显著提高了模型的适应性和效率，可能为设计更灵活的上下文感知 Transformers 模型设定新标准。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 2 figures, 4 experiments",
      "pdf_url": "http://arxiv.org/pdf/2405.13407v1",
      "published_date": "2024-05-22 07:33:24 UTC",
      "updated_date": "2024-05-22 07:33:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:40:40.010854"
    },
    {
      "arxiv_id": "2405.13394v1",
      "title": "A theory of neural emulators",
      "title_zh": "神经仿真器的理论",
      "authors": [
        "Catalin C. Mitelut"
      ],
      "abstract": "A central goal in neuroscience is to provide explanations for how animal\nnervous systems can generate actions and cognitive states such as consciousness\nwhile artificial intelligence (AI) and machine learning (ML) seek to provide\nmodels that are increasingly better at prediction. Despite many decades of\nresearch we have made limited progress on providing neuroscience explanations\nyet there is an increased use of AI and ML methods in neuroscience for\nprediction of behavior and even cognitive states. Here we propose emulator\ntheory (ET) and neural emulators as circuit- and scale-independent predictive\nmodels of biological brain activity and emulator theory (ET) as an alternative\nresearch paradigm in neuroscience. ET proposes that predictive models trained\nsolely on neural dynamics and behaviors can generate functionally\nindistinguishable systems from their sources. That is, compared to the\nbiological organisms which they model, emulators may achieve indistinguishable\nbehavior and cognitive states - including consciousness - without any\nmechanistic explanations. We posit ET via several conjectures, discuss the\nnature of endogenous and exogenous activation of neural circuits, and discuss\nneural causality of phenomenal states. ET provides the conceptual and empirical\nframework for prediction-based models of neural dynamics and behavior without\nexplicit representations of idiosyncratically evolved nervous systems.",
      "tldr_zh": "该论文提出了一种名为 emulator theory (ET) 的新理论，将 neural emulators 定义为独立于电路和规模的预测模型，用于模拟生物大脑活动和行为。ET 假设，通过仅基于神经动态和行为训练的模型，可以创建功能上与生物系统 indistinguishable 的系统，包括行为和认知状态如意识，而无需提供机械解释。论文讨论了神经电路的内生（endogenous）和外生（exogenous）激活、神经因果关系，并为基于预测的神经科学研究提供了一个框架，避免了对进化特有神经系统的显式表示。总的来说，ET 为 AI 和 ML 在神经科学中的应用开辟了新的范式，促进了对行为和认知状态的预测而不依赖生物细节。",
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13394v1",
      "published_date": "2024-05-22 07:12:03 UTC",
      "updated_date": "2024-05-22 07:12:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:40:51.772738"
    },
    {
      "arxiv_id": "2405.13393v1",
      "title": "NFCL: Simply interpretable neural networks for a short-term multivariate forecasting",
      "title_zh": "NFCL：用于短期多变量预测的简单可解释神经网络",
      "authors": [
        "Wonkeun Jo",
        "Dongil Kim"
      ],
      "abstract": "Multivariate time-series forecasting (MTSF) stands as a compelling field\nwithin the machine learning community. Diverse neural network based\nmethodologies deployed in MTSF applications have demonstrated commendable\nefficacy. Despite the advancements in model performance, comprehending the\nrationale behind the model's behavior remains an enigma. Our proposed model,\nthe Neural ForeCasting Layer (NFCL), employs a straightforward amalgamation of\nneural networks. This uncomplicated integration ensures that each neural\nnetwork contributes inputs and predictions independently, devoid of\ninterference from other inputs. Consequently, our model facilitates a\ntransparent explication of forecast results. This paper introduces NFCL along\nwith its diverse extensions. Empirical findings underscore NFCL's superior\nperformance compared to nine benchmark models across 15 available open\ndatasets. Notably, NFCL not only surpasses competitors but also provides\nelucidation for its predictions. In addition, Rigorous experimentation\ninvolving diverse model structures bolsters the justification of NFCL's unique\nconfiguration.",
      "tldr_zh": "本文提出了一种简单可解释的神经网络模型 Neural ForeCasting Layer (NFCL)，用于短期多变量时间序列预测 (Multivariate Time-Series Forecasting)，旨在解决现有模型效能高但解释性差的问题。NFCL 通过独立整合多个神经网络，每个网络单独贡献输入和预测，避免相互干扰，从而实现预测结果的透明阐述。实验结果显示，NFCL 在 15 个公开数据集上优于 9 个基准模型，并在额外实验中验证了其独特配置的合理性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.1; I.5.4"
      ],
      "primary_category": "cs.LG",
      "comment": "24 pages, 9 figures, preprint",
      "pdf_url": "http://arxiv.org/pdf/2405.13393v1",
      "published_date": "2024-05-22 07:08:27 UTC",
      "updated_date": "2024-05-22 07:08:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:41:04.770979"
    },
    {
      "arxiv_id": "2405.13386v1",
      "title": "360Zhinao Technical Report",
      "title_zh": "360Zhinao 技术报告",
      "authors": [
        "360Zhinao Team"
      ],
      "abstract": "We present 360Zhinao models with 7B parameter size and context lengths\nspanning 4K, 32K and 360K, all available at\nhttps://github.com/Qihoo360/360zhinao. For rapid development in pretraining, we\nestablish a stable and sensitive ablation environment to evaluate and compare\nexperiment runs with minimal model size. Under such guidance, we perfect our\ndata cleaning and composition strategies to pretrain\n$\\texttt{360Zhinao-7B-Base}$ on 3.4T tokens. We also mainly emphasize data\nduring alignment, where we strive to balance quantity and quality with\nfiltering and reformatting. With tailored data, 360Zhinao-7B's context window\nis easily extended to 32K and 360K. RMs and RLHF are trained following SFT and\ncredibly applied to specific tasks. All together these contributions lead to\n360Zhinao-7B's competitive performance among models of similar size.",
      "tldr_zh": "本报告介绍了 360Zhinao 模型系列，包括 7B 参数规模和上下文长度分别为 4K、32K 及 360K 的变体，可在 GitHub 上获取。研究团队通过建立一个稳定的消融环境优化预训练过程，完善数据清理和组合策略，在 3.4T tokens 上训练了 $\\texttt{360Zhinao-7B-Base}$ 模型，并在对齐阶段强调数据平衡，使用过滤和重格式化方法轻松扩展上下文窗口。最终，通过 SFT、RMs 和 RLHF 的训练，该模型在类似规模的模型中表现出竞争性的性能，为快速模型开发提供了指导。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "360Zhinao technical report. Github:\n  https://github.com/Qihoo360/360zhinao",
      "pdf_url": "http://arxiv.org/pdf/2405.13386v1",
      "published_date": "2024-05-22 06:45:38 UTC",
      "updated_date": "2024-05-22 06:45:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:41:17.198718"
    },
    {
      "arxiv_id": "2405.13374v1",
      "title": "Collaboration of Teachers for Semi-supervised Object Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Liyu Chen",
        "Huaao Tang",
        "Yi Wen",
        "Hanting Chen",
        "Wei Li",
        "Junchao Liu",
        "Jie Hu"
      ],
      "abstract": "Recent semi-supervised object detection (SSOD) has achieved remarkable\nprogress by leveraging unlabeled data for training. Mainstream SSOD methods\nrely on Consistency Regularization methods and Exponential Moving Average\n(EMA), which form a cyclic data flow. However, the EMA updating training\napproach leads to weight coupling between the teacher and student models. This\ncoupling in a cyclic data flow results in a decrease in the utilization of\nunlabeled data information and the confirmation bias on low-quality or\nerroneous pseudo-labels. To address these issues, we propose the Collaboration\nof Teachers Framework (CTF), which consists of multiple pairs of teacher and\nstudent models for training. In the learning process of CTF, the Data\nPerformance Consistency Optimization module (DPCO) informs the best pair of\nteacher models possessing the optimal pseudo-labels during the past training\nprocess, and these most reliable pseudo-labels generated by the best performing\nteacher would guide the other student models. As a consequence, this framework\ngreatly improves the utilization of unlabeled data and prevents the positive\nfeedback cycle of unreliable pseudo-labels. The CTF achieves outstanding\nresults on numerous SSOD datasets, including a 0.71% mAP improvement on the 10%\nannotated COCO dataset and a 0.89% mAP improvement on the VOC dataset compared\nto LabelMatch and converges significantly faster. Moreover, the CTF is\nplug-and-play and can be integrated with other mainstream SSOD methods.",
      "tldr_zh": "该论文针对半监督物体检测（SSOD）中的权重耦合和伪标签确认偏差问题，提出了 Collaboration of Teachers Framework (CTF)，该框架使用多个教师-学生模型对来优化训练过程。CTF 引入 Data Performance Consistency Optimization (DPCO) 模块，利用过去训练中表现最好的教师模型生成可靠伪标签，指导其他学生模型，从而提高无标签数据的利用率并防止不可靠伪标签的正反馈循环。实验结果显示，CTF 在 COCO 数据集上比 LabelMatch 提升 0.71% mAP，在 VOC 数据集上提升 0.89% mAP，且收敛更快，同时支持与其他主流 SSOD 方法的即插即用整合。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13374v1",
      "published_date": "2024-05-22 06:17:50 UTC",
      "updated_date": "2024-05-22 06:17:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:41:29.708181"
    },
    {
      "arxiv_id": "2405.13360v1",
      "title": "How to Trace Latent Generative Model Generated Images without Artificial Watermark?",
      "title_zh": "如何在没有人工水印的情况下追踪潜变量生成模型生成的图像？",
      "authors": [
        "Zhenting Wang",
        "Vikash Sehwag",
        "Chen Chen",
        "Lingjuan Lyu",
        "Dimitris N. Metaxas",
        "Shiqing Ma"
      ],
      "abstract": "Latent generative models (e.g., Stable Diffusion) have become more and more\npopular, but concerns have arisen regarding potential misuse related to images\ngenerated by these models. It is, therefore, necessary to analyze the origin of\nimages by inferring if a particular image was generated by a specific latent\ngenerative model. Most existing methods (e.g., image watermark and model\nfingerprinting) require extra steps during training or generation. These\nrequirements restrict their usage on the generated images without such extra\noperations, and the extra required operations might compromise the quality of\nthe generated images. In this work, we ask whether it is possible to\neffectively and efficiently trace the images generated by a specific latent\ngenerative model without the aforementioned requirements. To study this\nproblem, we design a latent inversion based method called LatentTracer to trace\nthe generated images of the inspected model by checking if the examined images\ncan be well-reconstructed with an inverted latent input. We leverage gradient\nbased latent inversion and identify a encoder-based initialization critical to\nthe success of our approach. Our experiments on the state-of-the-art latent\ngenerative models, such as Stable Diffusion, show that our method can\ndistinguish the images generated by the inspected model and other images with a\nhigh accuracy and efficiency. Our findings suggest the intriguing possibility\nthat today's latent generative generated images are naturally watermarked by\nthe decoder used in the source models. Code:\nhttps://github.com/ZhentingWang/LatentTracer.",
      "tldr_zh": "这篇论文探讨了如何在不使用人工水印的情况下追踪潜在生成模型（如Stable Diffusion）生成的图像，解决现有方法（如图像水印和模型指纹）在训练或生成过程中所需额外步骤可能影响图像质量的问题。作者提出了一种名为LatentTracer的方法，利用基于梯度的潜在逆向（latent inversion）技术，并强调编码器初始化的重要性，来检查图像是否能被源模型的潜在输入重建。实验结果显示，LatentTracer在Stable Diffusion等模型上实现了高准确率和效率，暗示生成图像可能自然地被模型解码器“水印”，为无额外操作的图像追踪提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.13360v1",
      "published_date": "2024-05-22 05:33:47 UTC",
      "updated_date": "2024-05-22 05:33:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:41:42.134945"
    },
    {
      "arxiv_id": "2405.13356v2",
      "title": "Large Language Models (LLMs) Assisted Wireless Network Deployment in Urban Settings",
      "title_zh": "翻译失败",
      "authors": [
        "Nurullah Sevim",
        "Mostafa Ibrahim",
        "Sabit Ekin"
      ],
      "abstract": "The advent of Large Language Models (LLMs) has revolutionized language\nunderstanding and human-like text generation, drawing interest from many other\nfields with this question in mind: What else are the LLMs capable of? Despite\ntheir widespread adoption, ongoing research continues to explore new ways to\nintegrate LLMs into diverse systems.\n  This paper explores new techniques to harness the power of LLMs for 6G (6th\nGeneration) wireless communication technologies, a domain where automation and\nintelligent systems are pivotal. The inherent adaptability of LLMs to\ndomain-specific tasks positions them as prime candidates for enhancing wireless\nsystems in the 6G landscape.\n  We introduce a novel Reinforcement Learning (RL) based framework that\nleverages LLMs for network deployment in wireless communications. Our approach\ninvolves training an RL agent, utilizing LLMs as its core, in an urban setting\nto maximize coverage. The agent's objective is to navigate the complexities of\nurban environments and identify the network parameters for optimal area\ncoverage. Additionally, we integrate LLMs with Convolutional Neural Networks\n(CNNs) to capitalize on their strengths while mitigating their limitations. The\nDeep Deterministic Policy Gradient (DDPG) algorithm is employed for training\npurposes. The results suggest that LLM-assisted models can outperform CNN-based\nmodels in some cases while performing at least as well in others.",
      "tldr_zh": "该论文探讨了如何利用 Large Language Models (LLMs) 提升 6G 无线通信技术在城市环境的网络部署。研究提出一个基于 Reinforcement Learning (RL) 的框架，以 LLMs 作为核心代理，结合 Convolutional Neural Networks (CNNs) 和 Deep Deterministic Policy Gradient (DDPG) 算法，优化网络参数以最大化覆盖范围。实验结果表明，LLM 辅助模型在某些场景下优于纯 CNN 模型的表现，至少与之相当，为智能无线系统自动化提供了新途径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "This work has been submitted to the IEEE for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2405.13356v2",
      "published_date": "2024-05-22 05:19:51 UTC",
      "updated_date": "2024-08-08 21:13:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:41:53.904954"
    },
    {
      "arxiv_id": "2405.13352v1",
      "title": "\"Turing Tests\" For An AI Scientist",
      "title_zh": "针对 AI 科学家的“图灵测试”",
      "authors": [
        "Xiaoxin Yin"
      ],
      "abstract": "While LLMs have shown impressive capabilities in solving math or coding\nproblems, the ability to make scientific discoveries remains a distinct\nchallenge. This paper proposes a \"Turing test for an AI scientist\" to assess\nwhether an AI agent can conduct scientific research independently, without\nrelying on human-generated knowledge. Drawing inspiration from the historical\ndevelopment of science, we propose seven benchmark tests that evaluate an AI\nagent's ability to make groundbreaking discoveries in various scientific\ndomains. These tests include inferring the heliocentric model from celestial\nobservations, discovering the laws of motion in a simulated environment,\nderiving the differential equation governing vibrating strings, inferring\nMaxwell's equations from electrodynamics simulations, inventing numerical\nmethods for initial value problems, discovering Huffman coding for data\ncompression, and developing efficient sorting algorithms. To ensure the\nvalidity of these tests, the AI agent is provided with interactive libraries or\ndatasets specific to each problem, without access to human knowledge that could\npotentially contain information about the target discoveries. The ultimate goal\nis to create an AI scientist capable of making novel and impactful scientific\ndiscoveries, surpassing the best human experts in their respective fields.\nThese \"Turing tests\" serve as intermediate milestones, assessing the AI agent's\nability to make discoveries that were groundbreaking in their time. If an AI\nagent can pass the majority of these seven tests, it would indicate significant\nprogress towards building an AI scientist, paving the way for future\nadvancements in autonomous scientific discovery. This paper aims to establish a\nbenchmark for the capabilities of AI in scientific research and to stimulate\nfurther research in this exciting field.",
      "tldr_zh": "这篇论文提出了“Turing Tests for an AI Scientist”，一种评估 AI 是否能独立进行科学研究的基准测试，而不依赖人类知识。论文设计了七个测试，包括从天文观察推断日心模型、在模拟环境中发现运动定律、推导振动弦的微分方程、从电动力学模拟推断Maxwell's equations、发明数值方法、发现Huffman coding以及开发高效排序算法。每个测试提供特定交互库或数据集，确保AI基于原始数据进行发现；如果AI通过大部分测试，将标志着其在自主科学发现领域的重大进展，并为超越人类专家的AI科学家铺平道路。最终，该框架旨在建立AI科学研究能力的标准，并激发相关领域的进一步创新。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13352v1",
      "published_date": "2024-05-22 05:14:27 UTC",
      "updated_date": "2024-05-22 05:14:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:42:05.829512"
    },
    {
      "arxiv_id": "2405.13347v2",
      "title": "Time-Series Forecasting and Sequence Learning Using Memristor-based Reservoir System",
      "title_zh": "翻译失败",
      "authors": [
        "Abdullah M. Zyarah",
        "Dhireesha Kudithipudi"
      ],
      "abstract": "Pushing the frontiers of time-series information processing in the\never-growing domain of edge devices with stringent resources has been impeded\nby the systems' ability to process information and learn locally on the device.\nLocal processing and learning of time-series information typically demand\nintensive computations and massive storage as the process involves retrieving\ninformation and tuning hundreds of parameters back in time. In this work, we\ndeveloped a memristor-based echo state network accelerator that features\nefficient temporal data processing and in-situ online learning. The proposed\ndesign is benchmarked using various datasets involving real-world tasks, such\nas forecasting the load energy consumption and weather conditions. The\nexperimental results illustrate that the hardware model experiences a marginal\ndegradation in performance as compared to the software counterpart. This is\nmainly attributed to the limited precision and dynamic range of network\nparameters when emulated using memristor devices. The proposed system is\nevaluated for lifespan, robustness, and energy-delay product. It is observed\nthat the system demonstrates reasonable robustness for device failure below\n10%, which may occur due to stuck-at faults. Furthermore, 247X reduction in\nenergy consumption is achieved when compared to a custom CMOS digital design\nimplemented at the same technology node.",
      "tldr_zh": "本研究开发了一种基于 memristor 的 reservoir system，用于时间序列预测和序列学习，旨在解决边缘设备资源受限下的本地处理和在线学习挑战。该系统采用 memristor-based echo state network 加速器，实现高效的临时数据处理和 in-situ online learning，并使用真实世界数据集（如负载能量消耗和天气条件预测）进行基准测试。与软件模型相比，硬件模型性能略有下降，主要由于 memristor 设备的精度和动态范围限制，但展示了良好的鲁棒性，能在设备故障低于10%时保持合理性能。最后，该系统在能量延迟产品方面表现出色，与自定义 CMOS 数字设计相比，能量消耗减少247倍。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13347v2",
      "published_date": "2024-05-22 05:07:56 UTC",
      "updated_date": "2024-09-15 15:10:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:42:16.676229"
    },
    {
      "arxiv_id": "2405.13325v3",
      "title": "DEGAP: Dual Event-Guided Adaptive Prefixes for Templated-Based Event Argument Extraction with Slot Querying",
      "title_zh": "翻译失败",
      "authors": [
        "Guanghui Wang",
        "Dexi Liu",
        "Jian-Yun Nie",
        "Qizhi Wan",
        "Rong Hu",
        "Xiping Liu",
        "Wanlong Liu",
        "Jiaming Liu"
      ],
      "abstract": "Recent advancements in event argument extraction (EAE) involve incorporating\nuseful auxiliary information into models during training and inference, such as\nretrieved instances and event templates. These methods face two challenges: (1)\nthe retrieval results may be irrelevant and (2) templates are developed\nindependently for each event without considering their possible relationship.\nIn this work, we propose DEGAP to address these challenges through a simple yet\neffective components: dual prefixes, i.e. learnable prompt vectors, where the\ninstance-oriented prefix and template-oriented prefix are trained to learn\ninformation from different event instances and templates. Additionally, we\npropose an event-guided adaptive gating mechanism, which can adaptively\nleverage possible connections between different events and thus capture\nrelevant information from the prefix. Finally, these event-guided prefixes\nprovide relevant information as cues to EAE model without retrieval. Extensive\nexperiments demonstrate that our method achieves new state-of-the-art\nperformance on four datasets (ACE05, RAMS, WIKIEVENTS, and MLEE). Further\nanalysis shows the impact of different components.",
      "tldr_zh": "该研究针对事件参数提取(EAE)中的问题，提出DEGAP方法，以解决检索结果无关性和事件模板独立开发的问题。DEGAP引入双重前缀(dual prefixes)，包括实例导向前缀和模板导向前缀，这些可学习的提示向量从不同事件实例和模板中提取信息；同时，采用事件引导的自适应门控机制(event-guided adaptive gating mechanism)来捕捉事件间可能的连接，从而提供相关提示给EAE模型，而无需外部检索。在四个数据集(ACE05、RAMS、WIKIEVENTS和MLEE)上进行的大量实验表明，DEGAP实现了新的state-of-the-art性能，进一步分析验证了各组件的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "Published as a conference paper in COLING 2025",
      "pdf_url": "http://arxiv.org/pdf/2405.13325v3",
      "published_date": "2024-05-22 03:56:55 UTC",
      "updated_date": "2025-05-08 16:33:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:42:28.872559"
    },
    {
      "arxiv_id": "2405.13324v1",
      "title": "Adversarial Training via Adaptive Knowledge Amalgamation of an Ensemble of Teachers",
      "title_zh": "翻译失败",
      "authors": [
        "Shayan Mohajer Hamidi",
        "Linfeng Ye"
      ],
      "abstract": "Adversarial training (AT) is a popular method for training robust deep neural\nnetworks (DNNs) against adversarial attacks. Yet, AT suffers from two\nshortcomings: (i) the robustness of DNNs trained by AT is highly intertwined\nwith the size of the DNNs, posing challenges in achieving robustness in smaller\nmodels; and (ii) the adversarial samples employed during the AT process exhibit\npoor generalization, leaving DNNs vulnerable to unforeseen attack types. To\naddress these dual challenges, this paper introduces adversarial training via\nadaptive knowledge amalgamation of an ensemble of teachers (AT-AKA). In\nparticular, we generate a diverse set of adversarial samples as the inputs to\nan ensemble of teachers; and then, we adaptively amalgamate the logtis of these\nteachers to train a generalized-robust student. Through comprehensive\nexperiments, we illustrate the superior efficacy of AT-AKA over existing AT\nmethods and adversarial robustness distillation techniques against cutting-edge\nattacks, including AutoAttack.",
      "tldr_zh": "本论文针对对抗训练(AT)的两大缺点——模型大小限制导致鲁棒性不足，以及对抗样本泛化能力差使模型易受未知攻击——提出了一种新的方法AT-AKA。AT-AKA通过生成多样化对抗样本输入到教师模型集合，并自适应合并这些教师的logits，来训练一个泛化鲁棒的学生模型。该方法在实验中证明了对先进攻击如AutoAttack的抵抗力优于现有AT方法和鲁棒性蒸馏技术。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13324v1",
      "published_date": "2024-05-22 03:47:55 UTC",
      "updated_date": "2024-05-22 03:47:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:42:40.767014"
    },
    {
      "arxiv_id": "2405.13300v3",
      "title": "FAITH: Frequency-domain Attention In Two Horizons for Time Series Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Ruiqi Li",
        "Maowei Jiang",
        "Kai Wang",
        "Kaiduo Feng",
        "Quangao Liu",
        "Yue Sun",
        "Xiufang Zhou"
      ],
      "abstract": "Time Series Forecasting plays a crucial role in various fields such as\nindustrial equipment maintenance, meteorology, energy consumption, traffic flow\nand financial investment. However, despite their considerable advantages over\ntraditional statistical approaches, current deep learning-based predictive\nmodels often exhibit a significant deviation between their forecasting outcomes\nand the ground truth. This discrepancy is largely due to an insufficient\nemphasis on extracting the sequence's latent information, particularly its\nglobal information within the frequency domain and the relationship between\ndifferent variables. To address this issue, we propose a novel model\nFrequency-domain Attention In Two Horizons, which decomposes time series into\ntrend and seasonal components using a multi-scale sequence adaptive\ndecomposition and fusion architecture, and processes them separately. FAITH\nutilizes Frequency Channel feature Extraction Module and Frequency Temporal\nfeature Extraction Module to capture inter-channel relationships and temporal\nglobal information in the sequence, significantly improving its ability to\nhandle long-term dependencies and complex patterns. Furthermore, FAITH achieves\ntheoretically linear complexity by modifying the time-frequency domain\ntransformation method, effectively reducing computational costs. Extensive\nexperiments on 6 benchmarks for long-term forecasting and 3 benchmarks for\nshort-term forecasting demonstrate that FAITH outperforms existing models in\nmany fields, such as electricity, weather and traffic, proving its\neffectiveness and superiority both in long-term and short-term time series\nforecasting tasks. Our codes and data are available at\nhttps://github.com/LRQ577/FAITH.",
      "tldr_zh": "本文提出 FAITH 模型（Frequency-domain Attention In Two Horizons），旨在解决时间序列预测中现有深度学习模型对频率域全局信息和变量间关系提取不足的问题。FAITH 通过多尺度序列自适应分解将时间序列分解为趋势和季节性组件，并分别使用 Frequency Channel feature Extraction Module 和 Frequency Temporal feature Extraction Module 来捕捉通道间关系及时间全局信息，同时优化时频域转换方法以实现线性复杂度。实验结果显示，该模型在 6 个长期预测和 3 个短期预测基准上（如电力、天气和交通领域）均优于现有模型，证明了其在处理长依赖和复杂模式方面的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "We think there are some errors in the experiment result, it may lead\n  to a wrong conclusion. So we think it will be responsible to withdraw it",
      "pdf_url": "http://arxiv.org/pdf/2405.13300v3",
      "published_date": "2024-05-22 02:37:02 UTC",
      "updated_date": "2024-07-01 04:01:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:42:53.935918"
    },
    {
      "arxiv_id": "2406.00014v2",
      "title": "KU-DMIS at EHRSQL 2024:Generating SQL query via question templatization in EHR",
      "title_zh": "翻译失败",
      "authors": [
        "Hajung Kim",
        "Chanhwi Kim",
        "Hoonick Lee",
        "Kyochul Jang",
        "Jiwoo Lee",
        "Kyungjae Lee",
        "Gangwoo Kim",
        "Jaewoo Kang"
      ],
      "abstract": "Transforming natural language questions into SQL queries is crucial for\nprecise data retrieval from electronic health record (EHR) databases. A\nsignificant challenge in this process is detecting and rejecting unanswerable\nquestions that request information beyond the database's scope or exceed the\nsystem's capabilities. In this paper, we introduce a novel text-to-SQL\nframework that robustly handles out-of-domain questions and verifies the\ngenerated queries with query execution.Our framework begins by standardizing\nthe structure of questions into a templated format. We use a powerful large\nlanguage model (LLM), fine-tuned GPT-3.5 with detailed prompts involving the\ntable schemas of the EHR database system. Our experimental results demonstrate\nthe effectiveness of our framework on the EHRSQL-2024 benchmark benchmark, a\nshared task in the ClinicalNLP workshop. Although a straightforward fine-tuning\nof GPT shows promising results on the development set, it struggled with the\nout-of-domain questions in the test set. With our framework, we improve our\nsystem's adaptability and achieve competitive performances in the official\nleaderboard of the EHRSQL-2024 challenge.",
      "tldr_zh": "本论文提出了一种名为 KU-DMIS 的 text-to-SQL 框架，旨在将自然语言问题转化为电子健康记录 (EHR) 数据库的 SQL 查询，同时处理无法回答的问题，如超出数据库范围或域外查询。框架通过标准化问题结构为模板格式，并使用 fine-tuned GPT-3.5 模型结合详细提示和 EHR 表结构进行查询生成和验证。实验结果显示，该框架在 EHRSQL-2024 基准测试中显著提高了系统的适应性，尤其在测试集的域外问题上，取得了官方排行榜的竞争性性能。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "primary_category": "cs.DB",
      "comment": "Published at ClinicalNLP workshop @ NAACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.00014v2",
      "published_date": "2024-05-22 02:15:57 UTC",
      "updated_date": "2024-06-19 16:21:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:43:05.177535"
    },
    {
      "arxiv_id": "2405.13290v1",
      "title": "Theoretical Analysis of Meta Reinforcement Learning: Generalization Bounds and Convergence Guarantees",
      "title_zh": "元强化学习的理论分析：泛化界和收敛保证",
      "authors": [
        "Cangqing Wang",
        "Mingxiu Sui",
        "Dan Sun",
        "Zecheng Zhang",
        "Yan Zhou"
      ],
      "abstract": "This research delves deeply into Meta Reinforcement Learning (Meta RL)\nthrough a exploration focusing on defining generalization limits and ensuring\nconvergence. By employing a approach this article introduces an innovative\ntheoretical framework to meticulously assess the effectiveness and performance\nof Meta RL algorithms. We present an explanation of generalization limits\nmeasuring how well these algorithms can adapt to learning tasks while\nmaintaining consistent results. Our analysis delves into the factors that\nimpact the adaptability of Meta RL revealing the relationship, between\nalgorithm design and task complexity. Additionally we establish convergence\nassurances by proving conditions under which Meta RL strategies are guaranteed\nto converge towards solutions. We examine the convergence behaviors of Meta RL\nalgorithms across scenarios providing a comprehensive understanding of the\ndriving forces behind their long term performance. This exploration covers both\nconvergence and real time efficiency offering a perspective, on the\ncapabilities of these algorithms.",
      "tldr_zh": "本研究对 Meta Reinforcement Learning (Meta RL) 进行了理论分析，重点定义了 Generalization Bounds 和 Convergence Guarantees，以评估算法的适应性和性能。研究引入了一个创新的理论框架，探讨了算法如何在不同任务中保持一致结果，并分析了算法设计与任务复杂度的关系。结果显示，影响 Meta RL 适应性的关键因素包括收敛条件和实时效率，该框架为算法的长期性能提供了全面理解和可靠保证。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper has been accepted by the 2024 International Conference on\n  Modeling, Natural Language Processing and Machine Learning(CMNM 2024)",
      "pdf_url": "http://arxiv.org/pdf/2405.13290v1",
      "published_date": "2024-05-22 02:09:22 UTC",
      "updated_date": "2024-05-22 02:09:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:43:15.968867"
    },
    {
      "arxiv_id": "2407.06194v2",
      "title": "More Distinctively Black and Feminine Faces Lead to Increased Stereotyping in Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Messi H. J. Lee",
        "Jacob M. Montgomery",
        "Calvin K. Lai"
      ],
      "abstract": "Vision Language Models (VLMs), exemplified by GPT-4V, adeptly integrate text\nand vision modalities. This integration enhances Large Language Models' ability\nto mimic human perception, allowing them to process image inputs. Despite VLMs'\nadvanced capabilities, however, there is a concern that VLMs inherit biases of\nboth modalities in ways that make biases more pervasive and difficult to\nmitigate. Our study explores how VLMs perpetuate homogeneity bias and trait\nassociations with regards to race and gender. When prompted to write stories\nbased on images of human faces, GPT-4V describes subordinate racial and gender\ngroups with greater homogeneity than dominant groups and relies on distinct,\nyet generally positive, stereotypes. Importantly, VLM stereotyping is driven by\nvisual cues rather than group membership alone such that faces that are rated\nas more prototypically Black and feminine are subject to greater stereotyping.\nThese findings suggest that VLMs may associate subtle visual cues related to\nracial and gender groups with stereotypes in ways that could be challenging to\nmitigate. We explore the underlying reasons behind this behavior and discuss\nits implications and emphasize the importance of addressing these biases as\nVLMs come to mirror human perception.",
      "tldr_zh": "本研究探讨了 Vision-Language Models (VLMs) 如 GPT-4V 在处理人脸图像时如何强化种族和性别偏见，特别是 homogeneity bias 和 trait associations。研究通过提示 VLMs 基于人脸图像编写故事，发现它对从属群体（如 Black 和女性）的描述更单一且依赖于积极但刻板印象。关键发现是，这种偏见主要由视觉线索驱动，即越典型地被视为 Black 或女性化的面孔，遭受的刻板印象越多。这些结果强调了 VLMs 可能继承人类感知偏见的风险，并呼吁采取措施缓解这些问题以促进公平性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "This submission is being withdrawn to address concerns related to the\n  terms of use of a database utilized in the research. We aim to ensure full\n  compliance with all data usage agreements before proceeding with publication",
      "pdf_url": "http://arxiv.org/pdf/2407.06194v2",
      "published_date": "2024-05-22 00:45:29 UTC",
      "updated_date": "2024-11-16 00:29:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:43:29.656893"
    },
    {
      "arxiv_id": "2405.13264v1",
      "title": "Part-based Quantitative Analysis for Heatmaps",
      "title_zh": "基于部分的热力图定量分析",
      "authors": [
        "Osman Tursun",
        "Sinan Kalkan",
        "Simon Denman",
        "Sridha Sridharan",
        "Clinton Fookes"
      ],
      "abstract": "Heatmaps have been instrumental in helping understand deep network decisions,\nand are a common approach for Explainable AI (XAI). While significant progress\nhas been made in enhancing the informativeness and accessibility of heatmaps,\nheatmap analysis is typically very subjective and limited to domain experts. As\nsuch, developing automatic, scalable, and numerical analysis methods to make\nheatmap-based XAI more objective, end-user friendly, and cost-effective is\nvital. In addition, there is a need for comprehensive evaluation metrics to\nassess heatmap quality at a granular level.",
      "tldr_zh": "本论文针对 Heatmaps 在 Explainable AI (XAI) 中的应用，指出其分析过程主观且仅限于领域专家，亟需自动、可扩展的数值分析方法来提升客观性和用户友好性。论文提出了一种基于部分的 Quantitative Analysis 框架，通过将 Heatmaps 分解为具体部分进行定量评估，以实现更细粒度的质量评估。最终，该方法有助于开发全面的评估指标，使 Heatmaps 分析更具成本效益，并推动 XAI 的实际应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13264v1",
      "published_date": "2024-05-22 00:24:17 UTC",
      "updated_date": "2024-05-22 00:24:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:43:41.610295"
    },
    {
      "arxiv_id": "2405.13256v1",
      "title": "Traffic control using intelligent timing of traffic lights with reinforcement learning technique and real-time processing of surveillance camera images",
      "title_zh": "翻译失败",
      "authors": [
        "Mahdi Jamebozorg",
        "Mohsen Hami",
        "Sajjad Deh Deh Jani"
      ],
      "abstract": "Optimal management of traffic light timing is one of the most effective\nfactors in reducing urban traffic. In most old systems, fixed timing was used\nalong with human factors to control traffic, which is not very efficient in\nterms of time and cost. Nowadays, methods in the field of traffic management\nare based on the use of artificial intelligence. In this method, by using\nreal-time processing of video surveillance camera images along with\nreinforcement learning, the optimal timing of traffic lights is determined and\napplied according to several parameters. In the research, deep learning methods\nwere used in vehicle detection using the YOLOv9-C model to estimate the number\nand other characteristics of vehicles such as speed. Finally, by modeling\nvehicles in an urban environment simulator at OpenAI Gym using multi-factor\nreinforcement learning and the DQN Rainbow algorithm, timing is applied to\ntraffic lights at intersections. Additionally, the use of transfer learning\nalong with retraining the model on images of Iranian cars has increased the\naccuracy of the model. The results of the proposed method show a model that is\nreasonably accurate in both parts of analyzing surveillance cameras and finding\nthe optimal timing, and it has been observed that it has better accuracy than\nprevious research.",
      "tldr_zh": "本文提出了一种智能交通灯控制方法，使用强化学习(reinforcement learning)和实时监控摄像头图像处理来优化交通灯定时，从而减少城市交通拥堵。方法结合YOLOv9-C模型进行车辆检测，估算车辆数量和速度，并在OpenAI Gym模拟器中使用多因子强化学习和DQN Rainbow算法动态调整灯时。针对特定场景，论文采用迁移学习(transfer learning)并在伊朗汽车图像上重新训练模型，以提升检测准确性。实验结果表明，该方法在图像分析和定时优化方面比先前研究更准确，有效提高了交通管理效率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "6th International conference on traffic management and safety ,Tehran\n  city, 12 pages in Persian",
      "pdf_url": "http://arxiv.org/pdf/2405.13256v1",
      "published_date": "2024-05-22 00:04:32 UTC",
      "updated_date": "2024-05-22 00:04:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T10:43:54.509983"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 116,
  "processed_papers_count": 116,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-18T10:44:17.798210"
}