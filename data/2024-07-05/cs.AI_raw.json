[
  {
    "arxiv_id": "2407.04885v1",
    "title": "Automating Venture Capital: Founder assessment using LLM-powered segmentation, feature engineering and automated labeling techniques",
    "authors": [
      "Ekin Ozince",
      "Yiğit Ihlamur"
    ],
    "abstract": "This study explores the application of large language models (LLMs) in\nventure capital (VC) decision-making, focusing on predicting startup success\nbased on founder characteristics. We utilize LLM prompting techniques, like\nchain-of-thought, to generate features from limited data, then extract insights\nthrough statistics and machine learning. Our results reveal potential\nrelationships between certain founder characteristics and success, as well as\ndemonstrate the effectiveness of these characteristics in prediction. This\nframework for integrating ML techniques and LLMs has vast potential for\nimproving startup success prediction, with important implications for VC firms\nseeking to optimize their investment strategies.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "For the relevant code, see\n  https://github.com/velapartners/moneyball-LLM-based-founder-features.git",
    "pdf_url": "http://arxiv.org/pdf/2407.04885v1",
    "published_date": "2024-07-05 22:54:13 UTC",
    "updated_date": "2024-07-05 22:54:13 UTC"
  },
  {
    "arxiv_id": "2407.04882v1",
    "title": "Improving ensemble extreme precipitation forecasts using generative artificial intelligence",
    "authors": [
      "Yingkai Sha",
      "Ryan A. Sobash",
      "David John Gagne II"
    ],
    "abstract": "An ensemble post-processing method is developed to improve the probabilistic\nforecasts of extreme precipitation events across the conterminous United States\n(CONUS). The method combines a 3-D Vision Transformer (ViT) for bias correction\nwith a Latent Diffusion Model (LDM), a generative Artificial Intelligence (AI)\nmethod, to post-process 6-hourly precipitation ensemble forecasts and produce\nan enlarged generative ensemble that contains spatiotemporally consistent\nprecipitation trajectories. These trajectories are expected to improve the\ncharacterization of extreme precipitation events and offer skillful multi-day\naccumulated and 6-hourly precipitation guidance. The method is tested using the\nGlobal Ensemble Forecast System (GEFS) precipitation forecasts out to day 6 and\nis verified against the Climate-Calibrated Precipitation Analysis (CCPA) data.\nVerification results indicate that the method generated skillful ensemble\nmembers with improved Continuous Ranked Probabilistic Skill Scores (CRPSSs) and\nBrier Skill Scores (BSSs) over the raw operational GEFS and a multivariate\nstatistical post-processing baseline. It showed skillful and reliable\nprobabilities for events at extreme precipitation thresholds. Explainability\nstudies were further conducted, which revealed the decision-making process of\nthe method and confirmed its effectiveness on ensemble member generation. This\nwork introduces a novel, generative-AI-based approach to address the limitation\nof small numerical ensembles and the need for larger ensembles to identify\nextreme precipitation events.",
    "categories": [
      "physics.ao-ph",
      "cs.AI"
    ],
    "primary_category": "physics.ao-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.04882v1",
    "published_date": "2024-07-05 22:30:33 UTC",
    "updated_date": "2024-07-05 22:30:33 UTC"
  },
  {
    "arxiv_id": "2407.07917v1",
    "title": "Non-Cooperative Backdoor Attacks in Federated Learning: A New Threat Landscape",
    "authors": [
      "Tuan Nguyen",
      "Dung Thuy Nguyen",
      "Khoa D Doan",
      "Kok-Seng Wong"
    ],
    "abstract": "Despite the promise of Federated Learning (FL) for privacy-preserving model\ntraining on distributed data, it remains susceptible to backdoor attacks. These\nattacks manipulate models by embedding triggers (specific input patterns) in\nthe training data, forcing misclassification as predefined classes during\ndeployment. Traditional single-trigger attacks and recent work on cooperative\nmultiple-trigger attacks, where clients collaborate, highlight limitations in\nattack realism due to coordination requirements. We investigate a more alarming\nscenario: non-cooperative multiple-trigger attacks. Here, independent\nadversaries introduce distinct triggers targeting unique classes. These\nparallel attacks exploit FL's decentralized nature, making detection difficult.\nOur experiments demonstrate the alarming vulnerability of FL to such attacks,\nwhere individual backdoors can be successfully learned without impacting the\nmain task. This research emphasizes the critical need for robust defenses\nagainst diverse backdoor attacks in the evolving FL landscape. While our focus\nis on empirical analysis, we believe it can guide backdoor research toward more\nrealistic settings, highlighting the crucial role of FL in building robust\ndefenses against diverse backdoor threats. The code is available at\n\\url{https://anonymous.4open.science/r/nba-980F/}.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.07917v1",
    "published_date": "2024-07-05 22:03:13 UTC",
    "updated_date": "2024-07-05 22:03:13 UTC"
  },
  {
    "arxiv_id": "2407.04873v2",
    "title": "Evaluating Language Models for Generating and Judging Programming Feedback",
    "authors": [
      "Charles Koutcheme",
      "Nicola Dainese",
      "Arto Hellas",
      "Sami Sarsa",
      "Juho Leinonen",
      "Syed Ashraf",
      "Paul Denny"
    ],
    "abstract": "The emergence of large language models (LLMs) has transformed research and\npractice across a wide range of domains. Within the computing education\nresearch (CER) domain, LLMs have garnered significant attention, particularly\nin the context of learning programming. Much of the work on LLMs in CER,\nhowever, has focused on applying and evaluating proprietary models. In this\narticle, we evaluate the efficiency of open-source LLMs in generating\nhigh-quality feedback for programming assignments and judging the quality of\nprogramming feedback, contrasting the results with proprietary models. Our\nevaluations on a dataset of students' submissions to introductory Python\nprogramming exercises suggest that state-of-the-art open-source LLMs are nearly\non par with proprietary models in both generating and assessing programming\nfeedback. Additionally, we demonstrate the efficiency of smaller LLMs in these\ntasks and highlight the wide range of LLMs accessible, even for free, to\neducators and practitioners.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "2 tables. Accepted for SIGCSE TS 2025",
    "pdf_url": "http://arxiv.org/pdf/2407.04873v2",
    "published_date": "2024-07-05 21:44:11 UTC",
    "updated_date": "2024-11-22 01:13:13 UTC"
  },
  {
    "arxiv_id": "2407.04869v1",
    "title": "A Defeasible Deontic Calculus for Resolving Norm Conflicts",
    "authors": [
      "Taylor Olson",
      "Roberto Salas-Damian",
      "Kenneth D. Forbus"
    ],
    "abstract": "When deciding how to act, we must consider other agents' norms and values.\nHowever, our norms are ever-evolving. We often add exceptions or change our\nminds, and thus norms can conflict over time. Therefore, to maintain an\naccurate mental model of other's norms, and thus to avoid social friction, such\nconflicts must be detected and resolved quickly. Formalizing this process has\nbeen the focus of various deontic logics and normative multi-agent systems. We\naim to bridge the gap between these two fields here. We contribute a defeasible\ndeontic calculus with inheritance and prove that it resolves norm conflicts.\nThrough this analysis, we also reveal a common resolution strategy as a red\nherring. This paper thus contributes a theoretically justified axiomatization\nof norm conflict detection and resolution.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "16 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.04869v1",
    "published_date": "2024-07-05 21:16:16 UTC",
    "updated_date": "2024-07-05 21:16:16 UTC"
  },
  {
    "arxiv_id": "2407.04868v1",
    "title": "Looking into Black Box Code Language Models",
    "authors": [
      "Muhammad Umair Haider",
      "Umar Farooq",
      "A. B. Siddique",
      "Mark Marron"
    ],
    "abstract": "Language Models (LMs) have shown their application for tasks pertinent to\ncode and several code~LMs have been proposed recently. The majority of the\nstudies in this direction only focus on the improvements in performance of the\nLMs on different benchmarks, whereas LMs are considered black boxes. Besides\nthis, a handful of works attempt to understand the role of attention layers in\nthe code~LMs. Nonetheless, feed-forward layers remain under-explored which\nconsist of two-thirds of a typical transformer model's parameters.\n  In this work, we attempt to gain insights into the inner workings of code\nlanguage models by examining the feed-forward layers. To conduct our\ninvestigations, we use two state-of-the-art code~LMs, Codegen-Mono and\nPloycoder, and three widely used programming languages, Java, Go, and Python.\nWe focus on examining the organization of stored concepts, the editability of\nthese concepts, and the roles of different layers and input context size\nvariations for output generation. Our empirical findings demonstrate that lower\nlayers capture syntactic patterns while higher layers encode abstract concepts\nand semantics. We show concepts of interest can be edited within feed-forward\nlayers without compromising code~LM performance. Additionally, we observe\ninitial layers serve as ``thinking'' layers, while later layers are crucial for\npredicting subsequent code tokens. Furthermore, we discover earlier layers can\naccurately predict smaller contexts, but larger contexts need critical later\nlayers' contributions. We anticipate these findings will facilitate better\nunderstanding, debugging, and testing of code~LMs.",
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.04868v1",
    "published_date": "2024-07-05 21:13:41 UTC",
    "updated_date": "2024-07-05 21:13:41 UTC"
  },
  {
    "arxiv_id": "2407.04859v1",
    "title": "Hybrid Primal Sketch: Combining Analogy, Qualitative Representations, and Computer Vision for Scene Understanding",
    "authors": [
      "Kenneth D. Forbus",
      "Kezhen Chen",
      "Wangcheng Xu",
      "Madeline Usher"
    ],
    "abstract": "One of the purposes of perception is to bridge between sensors and conceptual\nunderstanding. Marr's Primal Sketch combined initial edge-finding with multiple\ndownstream processes to capture aspects of visual perception such as grouping\nand stereopsis. Given the progress made in multiple areas of AI since then, we\nhave developed a new framework inspired by Marr's work, the Hybrid Primal\nSketch, which combines computer vision components into an ensemble to produce\nsketch-like entities which are then further processed by CogSketch, our model\nof high-level human vision, to produce both more detailed shape representations\nand scene representations which can be used for data-efficient learning via\nanalogical generalization. This paper describes our theoretical framework,\nsummarizes several previous experiments, and outlines a new experiment in\nprogress on diagram understanding.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "16 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.04859v1",
    "published_date": "2024-07-05 20:44:35 UTC",
    "updated_date": "2024-07-05 20:44:35 UTC"
  },
  {
    "arxiv_id": "2407.04856v2",
    "title": "Explorative Imitation Learning: A Path Signature Approach for Continuous Environments",
    "authors": [
      "Nathan Gavenski",
      "Juarez Monteiro",
      "Felipe Meneguzzi",
      "Michael Luck",
      "Odinaldo Rodrigues"
    ],
    "abstract": "Some imitation learning methods combine behavioural cloning with\nself-supervision to infer actions from state pairs. However, most rely on a\nlarge number of expert trajectories to increase generalisation and human\nintervention to capture key aspects of the problem, such as domain constraints.\nIn this paper, we propose Continuous Imitation Learning from Observation\n(CILO), a new method augmenting imitation learning with two important features:\n(i) exploration, allowing for more diverse state transitions, requiring less\nexpert trajectories and resulting in fewer training iterations; and (ii) path\nsignatures, allowing for automatic encoding of constraints, through the\ncreation of non-parametric representations of agents and expert trajectories.\nWe compared CILO with a baseline and two leading imitation learning methods in\nfive environments. It had the best overall performance of all methods in all\nenvironments, outperforming the expert in two of them.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "This paper has been accepted in the 27th European Conference on\n  Artificial Intelligence (ECAI) 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.04856v2",
    "published_date": "2024-07-05 20:25:39 UTC",
    "updated_date": "2024-07-22 15:32:50 UTC"
  },
  {
    "arxiv_id": "2407.04855v1",
    "title": "Towards Enhancing Coherence in Extractive Summarization: Dataset and Experiments with LLMs",
    "authors": [
      "Mihir Parmar",
      "Hanieh Deilamsalehy",
      "Franck Dernoncourt",
      "Seunghyun Yoon",
      "Ryan A. Rossi",
      "Trung Bui"
    ],
    "abstract": "Extractive summarization plays a pivotal role in natural language processing\ndue to its wide-range applications in summarizing diverse content efficiently,\nwhile also being faithful to the original content. Despite significant\nadvancement achieved in extractive summarization by Large Language Models\n(LLMs), these summaries frequently exhibit incoherence. An important aspect of\nthe coherent summary is its readability for intended users. Although there have\nbeen many datasets and benchmarks proposed for creating coherent extractive\nsummaries, none of them currently incorporate user intent to improve coherence\nin extractive summarization. Motivated by this, we propose a systematically\ncreated human-annotated dataset consisting of coherent summaries for five\npublicly available datasets and natural language user feedback, offering\nvaluable insights into how to improve coherence in extractive summaries. We\nutilize this dataset for aligning LLMs through supervised fine-tuning with\nnatural language human feedback to enhance the coherence of their generated\nsummaries. Preliminary experiments with Falcon-40B and Llama-2-13B show\nsignificant performance improvements (~10% Rouge-L) in terms of producing\ncoherent summaries. We further utilize human feedback to benchmark results over\ninstruction-tuned models such as FLAN-T5 which resulted in several interesting\nfindings. Data and source code are available at\nhttps://github.com/Mihir3009/Extract-AI.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2407.04855v1",
    "published_date": "2024-07-05 20:25:04 UTC",
    "updated_date": "2024-07-05 20:25:04 UTC"
  },
  {
    "arxiv_id": "2407.04846v2",
    "title": "Amazing Things Come From Having Many Good Models",
    "authors": [
      "Cynthia Rudin",
      "Chudi Zhong",
      "Lesia Semenova",
      "Margo Seltzer",
      "Ronald Parr",
      "Jiachang Liu",
      "Srikar Katta",
      "Jon Donnelly",
      "Harry Chen",
      "Zachery Boner"
    ],
    "abstract": "The Rashomon Effect, coined by Leo Breiman, describes the phenomenon that\nthere exist many equally good predictive models for the same dataset. This\nphenomenon happens for many real datasets and when it does, it sparks both\nmagic and consternation, but mostly magic. In light of the Rashomon Effect,\nthis perspective piece proposes reshaping the way we think about machine\nlearning, particularly for tabular data problems in the nondeterministic\n(noisy) setting. We address how the Rashomon Effect impacts (1) the existence\nof simple-yet-accurate models, (2) flexibility to address user preferences,\nsuch as fairness and monotonicity, without losing performance, (3) uncertainty\nin predictions, fairness, and explanations, (4) reliable variable importance,\n(5) algorithm choice, specifically, providing advanced knowledge of which\nalgorithms might be suitable for a given problem, and (6) public policy. We\nalso discuss a theory of when the Rashomon Effect occurs and why. Our goal is\nto illustrate how the Rashomon Effect can have a massive impact on the use of\nmachine learning for complex problems in society.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.04846v2",
    "published_date": "2024-07-05 20:14:36 UTC",
    "updated_date": "2024-07-10 02:39:01 UTC"
  },
  {
    "arxiv_id": "2407.04844v1",
    "title": "Neural varifolds: an aggregate representation for quantifying the geometry of point clouds",
    "authors": [
      "Juheon Lee",
      "Xiaohao Cai",
      "Carola-Bibian Schönlieb",
      "Simon Masnou"
    ],
    "abstract": "Point clouds are popular 3D representations for real-life objects (such as in\nLiDAR and Kinect) due to their detailed and compact representation of\nsurface-based geometry. Recent approaches characterise the geometry of point\nclouds by bringing deep learning based techniques together with geometric\nfidelity metrics such as optimal transportation costs (e.g., Chamfer and\nWasserstein metrics). In this paper, we propose a new surface geometry\ncharacterisation within this realm, namely a neural varifold representation of\npoint clouds. Here the surface is represented as a measure/distribution over\nboth point positions and tangent spaces of point clouds. The varifold\nrepresentation quantifies not only the surface geometry of point clouds through\nthe manifold-based discrimination, but also subtle geometric consistencies on\nthe surface due to the combined product space. This study proposes neural\nvarifold algorithms to compute the varifold norm between two point clouds using\nneural networks on point clouds and their neural tangent kernel\nrepresentations. The proposed neural varifold is evaluated on three different\nsought-after tasks -- shape matching, few-shot shape classification and shape\nreconstruction. Detailed evaluation and comparison to the state-of-the-art\nmethods demonstrate that the proposed versatile neural varifold is superior in\nshape matching and few-shot shape classification, and is competitive for shape\nreconstruction.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "The first author, Juheon Lee, is an unaffiliated, independent\n  researcher. This work is a personal endeavor, unrelated to his current job",
    "pdf_url": "http://arxiv.org/pdf/2407.04844v1",
    "published_date": "2024-07-05 20:08:16 UTC",
    "updated_date": "2024-07-05 20:08:16 UTC"
  },
  {
    "arxiv_id": "2407.04841v2",
    "title": "Associative Recurrent Memory Transformer",
    "authors": [
      "Ivan Rodkin",
      "Yuri Kuratov",
      "Aydar Bulatov",
      "Mikhail Burtsev"
    ],
    "abstract": "This paper addresses the challenge of creating a neural architecture for very\nlong sequences that requires constant time for processing new information at\neach time step. Our approach, Associative Recurrent Memory Transformer (ARMT),\nis based on transformer self-attention for local context and segment-level\nrecurrence for storage of task specific information distributed over a long\ncontext. We demonstrate that ARMT outperfors existing alternatives in\nassociative retrieval tasks and sets a new performance record in the recent\nBABILong multi-task long-context benchmark by answering single-fact questions\nover 50 million tokens with an accuracy of 79.9%. The source code for training\nand evaluation is available on github.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "ICML 2024 Next Generation of Sequence Modeling Architectures Workshop",
    "pdf_url": "http://arxiv.org/pdf/2407.04841v2",
    "published_date": "2024-07-05 19:57:49 UTC",
    "updated_date": "2025-02-13 20:10:59 UTC"
  },
  {
    "arxiv_id": "2407.04833v4",
    "title": "3D Adaptive Structural Convolution Network for Domain-Invariant Point Cloud Recognition",
    "authors": [
      "Younggun Kim",
      "Beomsik Cho",
      "Seonghoon Ryoo",
      "Soomok Lee"
    ],
    "abstract": "Adapting deep learning networks for point cloud data recognition in\nself-driving vehicles faces challenges due to the variability in datasets and\nsensor technologies, emphasizing the need for adaptive techniques to maintain\naccuracy across different conditions. In this paper, we introduce the 3D\nAdaptive Structural Convolution Network (3D-ASCN), a cutting-edge framework for\n3D point cloud recognition. It combines 3D convolution kernels, a structural\ntree structure, and adaptive neighborhood sampling for effective geometric\nfeature extraction. This method obtains domain-invariant features and\ndemonstrates robust, adaptable performance on a variety of point cloud\ndatasets, ensuring compatibility across diverse sensor configurations without\nthe need for parameter adjustments. This highlights its potential to\nsignificantly enhance the reliability and efficiency of self-driving vehicle\ntechnology.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "I.2.10; I.5.1"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.04833v4",
    "published_date": "2024-07-05 19:38:10 UTC",
    "updated_date": "2024-10-22 03:41:08 UTC"
  },
  {
    "arxiv_id": "2407.04831v2",
    "title": "Code Hallucination",
    "authors": [
      "Mirza Masfiqur Rahman",
      "Ashish Kundu"
    ],
    "abstract": "Generative models such as large language models are extensively used as code\ncopilots and for whole program generation. However, the programs they generate\noften have questionable correctness, authenticity and reliability in terms of\nintegration as they might not follow the user requirements, provide incorrect\nand/or nonsensical outputs, or even contain semantic/syntactic errors - overall\nknown as LLM hallucination. In this work, we present several types of code\nhallucination. We have generated such hallucinated code manually using large\nlanguage models. We also present a technique - HallTrigger, in order to\ndemonstrate efficient ways of generating arbitrary code hallucination. Our\nmethod leverages 3 different dynamic attributes of LLMs to craft prompts that\ncan successfully trigger hallucinations from models without the need to access\nmodel architecture or parameters. Results from popular blackbox models suggest\nthat HallTrigger is indeed effective and the pervasive LLM hallucination have\nsheer impact on software development.",
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.04831v2",
    "published_date": "2024-07-05 19:37:37 UTC",
    "updated_date": "2024-08-08 01:01:47 UTC"
  },
  {
    "arxiv_id": "2407.04819v1",
    "title": "RPN: Reconciled Polynomial Network Towards Unifying PGMs, Kernel SVMs, MLP and KAN",
    "authors": [
      "Jiawei Zhang"
    ],
    "abstract": "In this paper, we will introduce a novel deep model named Reconciled\nPolynomial Network (RPN) for deep function learning. RPN has a very general\narchitecture and can be used to build models with various complexities,\ncapacities, and levels of completeness, which all contribute to the correctness\nof these models. As indicated in the subtitle, RPN can also serve as the\nbackbone to unify different base models into one canonical representation. This\nincludes non-deep models, like probabilistic graphical models (PGMs) - such as\nBayesian network and Markov network - and kernel support vector machines\n(kernel SVMs), as well as deep models like the classic multi-layer perceptron\n(MLP) and the recent Kolmogorov-Arnold network (KAN).\n  Technically, RPN proposes to disentangle the underlying function to be\ninferred into the inner product of a data expansion function and a parameter\nreconciliation function. Together with the remainder function, RPN accurately\napproximates the underlying functions that governs data distributions. The data\nexpansion functions in RPN project data vectors from the input space to a\nhigh-dimensional intermediate space, specified by the expansion functions in\ndefinition. Meanwhile, RPN also introduces the parameter reconciliation\nfunctions to fabricate a small number of parameters into a higher-order\nparameter matrix to address the ``curse of dimensionality'' problem caused by\nthe data expansions. Moreover, the remainder functions provide RPN with\nadditional complementary information to reduce potential approximation errors.\nWe conducted extensive empirical experiments on numerous benchmark datasets\nacross multiple modalities, including continuous function datasets, discrete\nvision and language datasets, and classic tabular datasets, to investigate the\neffectiveness of RPN.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.IT",
      "math.IT",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "110 pages, 31 figures, 33 tables",
    "pdf_url": "http://arxiv.org/pdf/2407.04819v1",
    "published_date": "2024-07-05 19:00:18 UTC",
    "updated_date": "2024-07-05 19:00:18 UTC"
  },
  {
    "arxiv_id": "2407.04808v1",
    "title": "Brain Age Estimation with a Greedy Dual-Stream Model for Limited Datasets",
    "authors": [
      "Iman Kianian",
      "Hedieh Sajedi"
    ],
    "abstract": "Brain age estimation involves predicting the biological age of individuals\nfrom their brain images, which offers valuable insights into the aging process\nand the progression of neurodegenerative diseases. Conducting large-scale\ndatasets for medical image analysis is a challenging and time-consuming task.\nExisting approaches mostly depend on large datasets, which are hard to come by\nand expensive. These approaches also require sophisticated, resource-intensive\nmodels with a large number of parameters, necessitating a considerable amount\nof processing power. As a result, there is a vital need to develop innovative\nmethods that can achieve robust performance with limited datasets and efficient\nuse of computational resources. This paper proposes a novel slice-based\ndual-stream method called GDSM (Greedy Dual-Stream Model) for brain age\nestimation. This method addresses the limitations of large dataset requirements\nand computational resource intensiveness. The proposed method incorporates\nlocal and global aspects of the brain, thereby refining the focus on specific\ntarget regions. The approach employs four backbones to predict ages based on\nlocal and global features, complemented by a final model for age correction.\nOur method demonstrates a Mean Absolute Error (MAE) of 3.25 years on the test\nset of IBID, which only contains 289 subjects. To demonstrate the robustness of\nour approach for any small dataset, we analyzed the proposed method with the\nIXI dataset and achieved an MAE of 4.18 years on the test set of IXI. By\nleveraging dual-stream and greedy strategies, this approach achieves efficiency\nand robust performance, making it comparable with other state-of-the-art\nmethods. The code for the GDSM model is available at\nhttps://github.com/iman2693/GDSM.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.04808v1",
    "published_date": "2024-07-05 18:44:57 UTC",
    "updated_date": "2024-07-05 18:44:57 UTC"
  },
  {
    "arxiv_id": "2407.04803v1",
    "title": "The Impact of Quantization and Pruning on Deep Reinforcement Learning Models",
    "authors": [
      "Heng Lu",
      "Mehdi Alemi",
      "Reza Rawassizadeh"
    ],
    "abstract": "Deep reinforcement learning (DRL) has achieved remarkable success across\nvarious domains, such as video games, robotics, and, recently, large language\nmodels. However, the computational costs and memory requirements of DRL models\noften limit their deployment in resource-constrained environments. The\nchallenge underscores the urgent need to explore neural network compression\nmethods to make RDL models more practical and broadly applicable. Our study\ninvestigates the impact of two prominent compression methods, quantization and\npruning on DRL models. We examine how these techniques influence four\nperformance factors: average return, memory, inference time, and battery\nutilization across various DRL algorithms and environments. Despite the\ndecrease in model size, we identify that these compression techniques generally\ndo not improve the energy efficiency of DRL models, but the model size\ndecreases. We provide insights into the trade-offs between model compression\nand DRL performance, offering guidelines for deploying efficient DRL models in\nresource-constrained settings.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.04803v1",
    "published_date": "2024-07-05 18:21:17 UTC",
    "updated_date": "2024-07-05 18:21:17 UTC"
  },
  {
    "arxiv_id": "2407.04801v1",
    "title": "Revisiting Structured Sentiment Analysis as Latent Dependency Graph Parsing",
    "authors": [
      "Chengjie Zhou",
      "Bobo Li",
      "Hao Fei",
      "Fei Li",
      "Chong Teng",
      "Donghong Ji"
    ],
    "abstract": "Structured Sentiment Analysis (SSA) was cast as a problem of bi-lexical\ndependency graph parsing by prior studies. Multiple formulations have been\nproposed to construct the graph, which share several intrinsic drawbacks: (1)\nThe internal structures of spans are neglected, thus only the boundary tokens\nof spans are used for relation prediction and span recognition, thus hindering\nthe model's expressiveness; (2) Long spans occupy a significant proportion in\nthe SSA datasets, which further exacerbates the problem of internal structure\nneglect. In this paper, we treat the SSA task as a dependency parsing task on\npartially-observed dependency trees, regarding flat spans without determined\ntree annotations as latent subtrees to consider internal structures of spans.\nWe propose a two-stage parsing method and leverage TreeCRFs with a novel\nconstrained inside algorithm to model latent structures explicitly, which also\ntakes advantages of joint scoring graph arcs and headed spans for global\noptimization and inference. Results of extensive experiments on five benchmark\ndatasets reveal that our method performs significantly better than all previous\nbi-lexical methods, achieving new state-of-the-art.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.04801v1",
    "published_date": "2024-07-05 18:18:50 UTC",
    "updated_date": "2024-07-05 18:18:50 UTC"
  },
  {
    "arxiv_id": "2407.04794v2",
    "title": "On Evaluating The Performance of Watermarked Machine-Generated Texts Under Adversarial Attacks",
    "authors": [
      "Zesen Liu",
      "Tianshuo Cong",
      "Xinlei He",
      "Qi Li"
    ],
    "abstract": "Large Language Models (LLMs) excel in various applications, including text\ngeneration and complex tasks. However, the misuse of LLMs raises concerns about\nthe authenticity and ethical implications of the content they produce, such as\ndeepfake news, academic fraud, and copyright infringement. Watermarking\ntechniques, which embed identifiable markers in machine-generated text, offer a\npromising solution to these issues by allowing for content verification and\norigin tracing. Unfortunately, the robustness of current LLM watermarking\nschemes under potential watermark removal attacks has not been comprehensively\nexplored.\n  In this paper, to fill this gap, we first systematically comb the mainstream\nwatermarking schemes and removal attacks on machine-generated texts, and then\nwe categorize them into pre-text (before text generation) and post-text (after\ntext generation) classes so that we can conduct diversified analyses. In our\nexperiments, we evaluate eight watermarks (five pre-text, three post-text) and\ntwelve attacks (two pre-text, ten post-text) across 87 scenarios. Evaluation\nresults indicate that (1) KGW and Exponential watermarks offer high text\nquality and watermark retention but remain vulnerable to most attacks; (2)\nPost-text attacks are found to be more efficient and practical than pre-text\nattacks; (3) Pre-text watermarks are generally more imperceptible, as they do\nnot alter text fluency, unlike post-text watermarks; (4) Additionally, combined\nattack methods can significantly increase effectiveness, highlighting the need\nfor more robust watermarking solutions. Our study underscores the\nvulnerabilities of current techniques and the necessity for developing more\nresilient schemes.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.04794v2",
    "published_date": "2024-07-05 18:09:06 UTC",
    "updated_date": "2024-11-28 11:28:39 UTC"
  },
  {
    "arxiv_id": "2407.04787v1",
    "title": "Re-Tuning: Overcoming the Compositionality Limits of Large Language Models with Recursive Tuning",
    "authors": [
      "Eric Pasewark",
      "Kyle Montgomery",
      "Kefei Duan",
      "Dawn Song",
      "Chenguang Wang"
    ],
    "abstract": "We present a new method for large language models to solve compositional\ntasks. Although they have shown strong performance on traditional language\nunderstanding tasks, large language models struggle to solve compositional\ntasks, where the solution depends on solving smaller instances of the same\nproblem. We propose a natural approach to solve compositional tasks\nrecursively. Our method, Re-Tuning, tunes models to break down a problem into\nsubproblems, solve those subproblems, and combine the results. We show that our\nmethod significantly improves model performance on three representative\ncompositional tasks: integer addition, dynamic programming, and parity.\nCompared to state-of-the-art methods that keep intermediate steps towards\nsolving the problems, Re-Tuning achieves significantly higher accuracy and is\nmore GPU memory efficient.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.04787v1",
    "published_date": "2024-07-05 18:02:28 UTC",
    "updated_date": "2024-07-05 18:02:28 UTC"
  },
  {
    "arxiv_id": "2407.04699v2",
    "title": "LaRa: Efficient Large-Baseline Radiance Fields",
    "authors": [
      "Anpei Chen",
      "Haofei Xu",
      "Stefano Esposito",
      "Siyu Tang",
      "Andreas Geiger"
    ],
    "abstract": "Radiance field methods have achieved photorealistic novel view synthesis and\ngeometry reconstruction. But they are mostly applied in per-scene optimization\nor small-baseline settings. While several recent works investigate feed-forward\nreconstruction with large baselines by utilizing transformers, they all operate\nwith a standard global attention mechanism and hence ignore the local nature of\n3D reconstruction. We propose a method that unifies local and global reasoning\nin transformer layers, resulting in improved quality and faster convergence.\nOur model represents scenes as Gaussian Volumes and combines this with an image\nencoder and Group Attention Layers for efficient feed-forward reconstruction.\nExperimental results demonstrate that our model, trained for two days on four\nGPUs, demonstrates high fidelity in reconstructing 360 deg radiance fields, and\nrobustness to zero-shot and out-of-domain testing. Our project Page:\nhttps://apchenstu.github.io/LaRa/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Project Page: https://apchenstu.github.io/LaRa/",
    "pdf_url": "http://arxiv.org/pdf/2407.04699v2",
    "published_date": "2024-07-05 17:59:58 UTC",
    "updated_date": "2024-07-15 20:18:09 UTC"
  },
  {
    "arxiv_id": "2407.04694v1",
    "title": "Me, Myself, and AI: The Situational Awareness Dataset (SAD) for LLMs",
    "authors": [
      "Rudolf Laine",
      "Bilal Chughtai",
      "Jan Betley",
      "Kaivalya Hariharan",
      "Jeremy Scheurer",
      "Mikita Balesni",
      "Marius Hobbhahn",
      "Alexander Meinke",
      "Owain Evans"
    ],
    "abstract": "AI assistants such as ChatGPT are trained to respond to users by saying, \"I\nam a large language model\". This raises questions. Do such models know that\nthey are LLMs and reliably act on this knowledge? Are they aware of their\ncurrent circumstances, such as being deployed to the public? We refer to a\nmodel's knowledge of itself and its circumstances as situational awareness. To\nquantify situational awareness in LLMs, we introduce a range of behavioral\ntests, based on question answering and instruction following. These tests form\nthe $\\textbf{Situational Awareness Dataset (SAD)}$, a benchmark comprising 7\ntask categories and over 13,000 questions. The benchmark tests numerous\nabilities, including the capacity of LLMs to (i) recognize their own generated\ntext, (ii) predict their own behavior, (iii) determine whether a prompt is from\ninternal evaluation or real-world deployment, and (iv) follow instructions that\ndepend on self-knowledge.\n  We evaluate 16 LLMs on SAD, including both base (pretrained) and chat models.\nWhile all models perform better than chance, even the highest-scoring model\n(Claude 3 Opus) is far from a human baseline on certain tasks. We also observe\nthat performance on SAD is only partially predicted by metrics of general\nknowledge (e.g. MMLU). Chat models, which are finetuned to serve as AI\nassistants, outperform their corresponding base models on SAD but not on\ngeneral knowledge tasks. The purpose of SAD is to facilitate scientific\nunderstanding of situational awareness in LLMs by breaking it down into\nquantitative abilities. Situational awareness is important because it enhances\na model's capacity for autonomous planning and action. While this has potential\nbenefits for automation, it also introduces novel risks related to AI safety\nand control. Code and latest results available at\nhttps://situational-awareness-dataset.org .",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "11 page main body, 98 page appendix, 58 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.04694v1",
    "published_date": "2024-07-05 17:57:02 UTC",
    "updated_date": "2024-07-05 17:57:02 UTC"
  },
  {
    "arxiv_id": "2407.04693v2",
    "title": "ANAH-v2: Scaling Analytical Hallucination Annotation of Large Language Models",
    "authors": [
      "Yuzhe Gu",
      "Ziwei Ji",
      "Wenwei Zhang",
      "Chengqi Lyu",
      "Dahua Lin",
      "Kai Chen"
    ],
    "abstract": "Large language models (LLMs) exhibit hallucinations in long-form\nquestion-answering tasks across various domains and wide applications. Current\nhallucination detection and mitigation datasets are limited in domains and\nsizes, which struggle to scale due to prohibitive labor costs and insufficient\nreliability of existing hallucination annotators. To facilitate the scalable\noversight of LLM hallucinations, this paper introduces an iterative\nself-training framework that simultaneously and progressively scales up the\nhallucination annotation dataset and improves the accuracy of the hallucination\nannotator. Based on the Expectation Maximization (EM) algorithm, in each\niteration, the framework first applies a hallucination annotation pipeline to\nannotate a scaled dataset and then trains a more accurate hallucination\nannotator on the dataset. This new hallucination annotator is adopted in the\nhallucination annotation pipeline used for the next iteration. Extensive\nexperimental results demonstrate that the finally obtained hallucination\nannotator with only 7B parameters surpasses the performance of GPT-4 and\nobtains new state-of-the-art hallucination detection results on HaluEval and\nHalluQA by zero-shot inference. Such an annotator can not only evaluate the\nhallucination levels of various LLMs on the large-scale dataset but also help\nto mitigate the hallucination of LLMs generations, with the Natural Language\nInference (NLI) metric increasing from 25% to 37% on HaluEval.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by NeurIPS 2024. Dataset, code, and model are released at\n  https://github.com/open-compass/ANAH",
    "pdf_url": "http://arxiv.org/pdf/2407.04693v2",
    "published_date": "2024-07-05 17:56:38 UTC",
    "updated_date": "2024-12-19 15:11:47 UTC"
  },
  {
    "arxiv_id": "2407.04681v1",
    "title": "Rethinking Visual Prompting for Multimodal Large Language Models with External Knowledge",
    "authors": [
      "Yuanze Lin",
      "Yunsheng Li",
      "Dongdong Chen",
      "Weijian Xu",
      "Ronald Clark",
      "Philip Torr",
      "Lu Yuan"
    ],
    "abstract": "In recent years, multimodal large language models (MLLMs) have made\nsignificant strides by training on vast high-quality image-text datasets,\nenabling them to generally understand images well. However, the inherent\ndifficulty in explicitly conveying fine-grained or spatially dense information\nin text, such as masks, poses a challenge for MLLMs, limiting their ability to\nanswer questions requiring an understanding of detailed or localized visual\nelements. Drawing inspiration from the Retrieval-Augmented Generation (RAG)\nconcept, this paper proposes a new visual prompt approach to integrate\nfine-grained external knowledge, gleaned from specialized vision models (e.g.,\ninstance segmentation/OCR models), into MLLMs. This is a promising yet\nunderexplored direction for enhancing MLLMs' performance. Our approach diverges\nfrom concurrent works, which transform external knowledge into additional text\nprompts, necessitating the model to indirectly learn the correspondence between\nvisual content and text coordinates. Instead, we propose embedding fine-grained\nknowledge information directly into a spatial embedding map as a visual prompt.\nThis design can be effortlessly incorporated into various MLLMs, such as LLaVA\nand Mipha, considerably improving their visual understanding performance.\nThrough rigorous experiments, we demonstrate that our method can enhance MLLM\nperformance across nine benchmarks, amplifying their fine-grained context-aware\ncapabilities.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.04681v1",
    "published_date": "2024-07-05 17:43:30 UTC",
    "updated_date": "2024-07-05 17:43:30 UTC"
  },
  {
    "arxiv_id": "2407.04680v1",
    "title": "Lost in Translation: The Algorithmic Gap Between LMs and the Brain",
    "authors": [
      "Tommaso Tosato",
      "Pascal Jr Tikeng Notsawo",
      "Saskia Helbling",
      "Irina Rish",
      "Guillaume Dumas"
    ],
    "abstract": "Language Models (LMs) have achieved impressive performance on various\nlinguistic tasks, but their relationship to human language processing in the\nbrain remains unclear. This paper examines the gaps and overlaps between LMs\nand the brain at different levels of analysis, emphasizing the importance of\nlooking beyond input-output behavior to examine and compare the internal\nprocesses of these systems. We discuss how insights from neuroscience, such as\nsparsity, modularity, internal states, and interactive learning, can inform the\ndevelopment of more biologically plausible language models. Furthermore, we\nexplore the role of scaling laws in bridging the gap between LMs and human\ncognition, highlighting the need for efficiency constraints analogous to those\nin biological systems. By developing LMs that more closely mimic brain\nfunction, we aim to advance both artificial intelligence and our understanding\nof human cognition.",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "q-bio.NC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.04680v1",
    "published_date": "2024-07-05 17:43:16 UTC",
    "updated_date": "2024-07-05 17:43:16 UTC"
  },
  {
    "arxiv_id": "2407.04678v1",
    "title": "XQSV: A Structurally Variable Network to Imitate Human Play in Xiangqi",
    "authors": [
      "Chenliang Zhou"
    ],
    "abstract": "In this paper, we introduce an innovative deep learning architecture, termed\nXiangqi Structurally Variable (XQSV), designed to emulate the behavioral\npatterns of human players in Xiangqi, or Chinese Chess. The unique attribute of\nXQSV is its capacity to alter its structural configuration dynamically,\noptimizing performance for the task based on the particular subset of data on\nwhich it is trained. We have incorporated several design improvements to\nsignificantly enhance the network's predictive accuracy, including a local\nillegal move filter, an Elo range partitioning, a sequential one-dimensional\ninput, and a simulation of imperfect memory capacity. Empirical evaluations\nreveal that XQSV attains a predictive accuracy of approximately 40%, with its\nperformance peaking within the trained Elo range. This indicates the model's\nsuccess in mimicking the play behavior of individuals within that specific\nrange. A three-terminal Turing Test was employed to demonstrate that the XQSV\nmodel imitates human behavior more accurately than conventional Xiangqi\nengines, rendering it indistinguishable from actual human opponents. Given the\ninherent nondeterminism in human gameplay, we propose two supplementary relaxed\nevaluation metrics. To our knowledge, XQSV represents the first model to mimic\nXiangqi players.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.04678v1",
    "published_date": "2024-07-05 17:43:05 UTC",
    "updated_date": "2024-07-05 17:43:05 UTC"
  },
  {
    "arxiv_id": "2407.04676v1",
    "title": "Is plantar thermography a valid digital biomarker for characterising diabetic foot ulceration risk?",
    "authors": [
      "Akshay Jagadeesh",
      "Chanchanok Aramrat",
      "Aqsha Nur",
      "Poppy Mallinson",
      "Sanjay Kinra"
    ],
    "abstract": "Background: In the absence of prospective data on diabetic foot ulcers (DFU),\ncross-sectional associations with causal risk factors (peripheral neuropathy,\nand peripheral arterial disease (PAD)) could be used to establish the validity\nof plantar thermography for DFU risk stratification.\n  Methods: First, we investigated the associations between the intrinsic\nclusters of plantar thermographic images with several DFU risk factors using an\nunsupervised deep-learning framework. We then studied associations between\nobtained thermography clusters and DFU risk factors. Second, to identify those\nassociations with predictive power, we used supervised learning to train\nConvolutional Neural Network (CNN) regression/classification models that\npredicted the risk factor based on the thermograph (and visual) input.\n  Findings: Our dataset comprised 282 thermographs from type 2 diabetes\nmellitus patients (aged 56.31 +- 9.18 years, 51.42 % males). On clustering, we\nfound two overlapping clusters (silhouette score = 0.10, indicating weak\nseparation). There was strong evidence for associations between assigned\nclusters and several factors related to diabetic foot ulceration such as\nperipheral neuropathy, PAD, number of diabetes complications, and composite DFU\nrisk prediction scores such as Martins-Mendes, PODUS-2020, and SIGN. However,\nmodels predicting said risk factors had poor performances.\n  Interpretation: The strong associations between intrinsic thermography\nclusters and several DFU risk factors support the validity of using\nthermography for characterising DFU risk. However, obtained associations did\nnot prove to be predictive, likely due to, spectrum bias, or because\nthermography and classical risk factors characterise incompletely overlapping\nportions of the DFU risk construct. Our findings highlight the challenges in\nstandardising ground truths when defining novel digital biomarkers.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "I.2; I.5"
    ],
    "primary_category": "cs.CV",
    "comment": "13 pages, 2 Figures, 1 Table. Supplementary files and link to code to\n  be uploaded",
    "pdf_url": "http://arxiv.org/pdf/2407.04676v1",
    "published_date": "2024-07-05 17:39:03 UTC",
    "updated_date": "2024-07-05 17:39:03 UTC"
  },
  {
    "arxiv_id": "2407.04648v1",
    "title": "Efficient Materials Informatics between Rockets and Electrons",
    "authors": [
      "Adam M. Krajewski"
    ],
    "abstract": "The true power of computational research typically can lay in either what it\naccomplishes or what it enables others to accomplish. In this work, both\navenues are simultaneously embraced across several distinct efforts existing at\nthree general scales of abstractions of what a material is - atomistic,\nphysical, and design. At each, an efficient materials informatics\ninfrastructure is being built from the ground up based on (1) the fundamental\nunderstanding of the underlying prior knowledge, including the data, (2)\ndeployment routes that take advantage of it, and (3) pathways to extend it in\nan autonomous or semi-autonomous fashion, while heavily relying on artificial\nintelligence (AI) to guide well-established DFT-based ab initio and\nCALPHAD-based thermodynamic methods.\n  The resulting multi-level discovery infrastructure is highly generalizable as\nit focuses on encoding problems to solve them easily rather than looking for an\nexisting solution. To showcase it, this dissertation discusses the design of\nmulti-alloy functionally graded materials (FGMs) incorporating ultra-high\ntemperature refractory high entropy alloys (RHEAs) towards gas turbine and jet\nengine efficiency increase reducing CO2 emissions, as well as hypersonic\nvehicles. It leverages a new graph representation of underlying mathematical\nspace using a newly developed algorithm based on combinatorics, not subject to\nmany problems troubling the community. Underneath, property models and phase\nrelations are learned from optimized samplings of the largest and highest\nquality dataset of HEA in the world, called ULTERA. At the atomistic level, a\ndata ecosystem optimized for machine learning (ML) from over 4.5 million\nrelaxed structures, called MPDD, is used to inform experimental observations\nand improve thermodynamic models by providing stability data enabled by a new\nefficient featurization framework.",
    "categories": [
      "cond-mat.mtrl-sci",
      "cs.AI",
      "cs.DB",
      "physics.data-an",
      "G.4; E.1; I.2.4; I.2.6; I.2.8; I.5.3; I.6.5; J.2; J.7"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "comment": "PhD Dissertation in Materials Science and Engineering defended on May\n  20th 2024, 319 body pages, 109 figures, combined-bibliography version, source\n  repository at https://github.com/amkrajewski/PhD-Dissertation",
    "pdf_url": "http://arxiv.org/pdf/2407.04648v1",
    "published_date": "2024-07-05 17:03:26 UTC",
    "updated_date": "2024-07-05 17:03:26 UTC"
  },
  {
    "arxiv_id": "2407.04629v2",
    "title": "Entity Decomposition with Filtering: A Zero-Shot Clinical Named Entity Recognition Framework",
    "authors": [
      "Reza Averly",
      "Xia Ning"
    ],
    "abstract": "Clinical named entity recognition (NER) aims to retrieve important entities\nwithin clinical narratives. Recent works have demonstrated that large language\nmodels (LLMs) can achieve strong performance in this task. While previous works\nfocus on proprietary LLMs, we investigate how open NER LLMs, trained\nspecifically for entity recognition, perform in clinical NER. Our initial\nexperiment reveals significant contrast in performance for some clinical\nentities and how a simple exploitment on entity types can alleviate this issue.\nIn this paper, we introduce a novel framework, entity decomposition with\nfiltering, or EDF. Our key idea is to decompose the entity recognition task\ninto several retrievals of entity sub-types and then filter them. Our\nexperimental results demonstrate the efficacies of our framework and the\nimprovements across all metrics, models, datasets, and entity types. Our\nanalysis also reveals substantial improvement in recognizing previously missed\nentities using entity decomposition. We further provide a comprehensive\nevaluation of our framework and an in-depth error analysis to pave future\nworks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to NAACL 2025 Main Conference",
    "pdf_url": "http://arxiv.org/pdf/2407.04629v2",
    "published_date": "2024-07-05 16:38:23 UTC",
    "updated_date": "2025-02-19 20:51:20 UTC"
  },
  {
    "arxiv_id": "2407.04620v3",
    "title": "Learning to (Learn at Test Time): RNNs with Expressive Hidden States",
    "authors": [
      "Yu Sun",
      "Xinhao Li",
      "Karan Dalal",
      "Jiarui Xu",
      "Arjun Vikram",
      "Genghan Zhang",
      "Yann Dubois",
      "Xinlei Chen",
      "Xiaolong Wang",
      "Sanmi Koyejo",
      "Tatsunori Hashimoto",
      "Carlos Guestrin"
    ],
    "abstract": "Self-attention performs well in long context but has quadratic complexity.\nExisting RNN layers have linear complexity, but their performance in long\ncontext is limited by the expressive power of their hidden states. We present a\npractical framework for instantiating sequence modeling layers with linear\ncomplexity and expressive hidden states. The key idea is to make the hidden\nstate a machine learning model itself, and the update rule a step of\nself-supervised learning. Since the hidden state is updated by training even on\ntest sequences, our layers are called Test-Time Training (TTT) layers. We\nconsider two instantiations: TTT-Linear and TTT-MLP, whose hidden state is a\nlinear model and a two-layer MLP respectively. We evaluate our instantiations\nat the scale of 125M to 1.3B parameters, comparing with a strong Transformer\nand Mamba, a modern RNN. Similar to Transformer, TTT-Linear and TTT-MLP can\nkeep reducing perplexity by conditioning on more tokens, while Mamba cannot\nafter 16k context. TTT-MLP still faces challenges in memory I/O, but shows\nlarger potential in long context, pointing to a promising direction for future\nresearch.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "The current version contains updates on related work and limitations.\n  All experiments were completed in the first version",
    "pdf_url": "http://arxiv.org/pdf/2407.04620v3",
    "published_date": "2024-07-05 16:23:20 UTC",
    "updated_date": "2025-04-03 18:30:11 UTC"
  },
  {
    "arxiv_id": "2407.04616v1",
    "title": "Isomorphic Pruning for Vision Models",
    "authors": [
      "Gongfan Fang",
      "Xinyin Ma",
      "Michael Bi Mi",
      "Xinchao Wang"
    ],
    "abstract": "Structured pruning reduces the computational overhead of deep neural networks\nby removing redundant sub-structures. However, assessing the relative\nimportance of different sub-structures remains a significant challenge,\nparticularly in advanced vision models featuring novel mechanisms and\narchitectures like self-attention, depth-wise convolutions, or residual\nconnections. These heterogeneous substructures usually exhibit diverged\nparameter scales, weight distributions, and computational topology, introducing\nconsiderable difficulty to importance comparison. To overcome this, we present\nIsomorphic Pruning, a simple approach that demonstrates effectiveness across a\nrange of network architectures such as Vision Transformers and CNNs, and\ndelivers competitive performance across different model sizes. Isomorphic\nPruning originates from an observation that, when evaluated under a pre-defined\nimportance criterion, heterogeneous sub-structures demonstrate significant\ndivergence in their importance distribution, as opposed to isomorphic\nstructures that present similar importance patterns. This inspires us to\nperform isolated ranking and comparison on different types of sub-structures\nfor more reliable pruning. Our empirical results on ImageNet-1K demonstrate\nthat Isomorphic Pruning surpasses several pruning baselines dedicatedly\ndesigned for Transformers or CNNs. For instance, we improve the accuracy of\nDeiT-Tiny from 74.52% to 77.50% by pruning an off-the-shelf DeiT-Base model.\nAnd for ConvNext-Tiny, we enhanced performance from 82.06% to 82.18%, while\nreducing the number of parameters and memory usage. Code is available at\n\\url{https://github.com/VainF/Isomorphic-Pruning}.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.04616v1",
    "published_date": "2024-07-05 16:14:53 UTC",
    "updated_date": "2024-07-05 16:14:53 UTC"
  },
  {
    "arxiv_id": "2407.14521v1",
    "title": "Towards Automated Functional Equation Proving: A Benchmark Dataset and A Domain-Specific In-Context Agent",
    "authors": [
      "Mahdi Buali",
      "Robert Hoehndorf"
    ],
    "abstract": "Automated Theorem Proving (ATP) faces challenges due to its complexity and\ncomputational demands. Recent work has explored using Large Language Models\n(LLMs) for ATP action selection, but these methods can be resource-intensive.\nThis study introduces FEAS, an agent that enhances the COPRA in-context\nlearning framework within Lean. FEAS refines prompt generation, response\nparsing, and incorporates domain-specific heuristics for functional equations.\nIt introduces FunEq, a curated dataset of functional equation problems with\nvarying difficulty. FEAS outperforms baselines on FunEq, particularly with the\nintegration of domain-specific heuristics. The results demonstrate FEAS's\neffectiveness in generating and formalizing high-level proof strategies into\nLean proofs, showcasing the potential of tailored approaches for specific ATP\nchallenges.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.SC"
    ],
    "primary_category": "cs.AI",
    "comment": "11 pages",
    "pdf_url": "http://arxiv.org/pdf/2407.14521v1",
    "published_date": "2024-07-05 15:59:16 UTC",
    "updated_date": "2024-07-05 15:59:16 UTC"
  },
  {
    "arxiv_id": "2407.04597v1",
    "title": "Feature Attenuation of Defective Representation Can Resolve Incomplete Masking on Anomaly Detection",
    "authors": [
      "YeongHyeon Park",
      "Sungho Kang",
      "Myung Jin Kim",
      "Hyeong Seok Kim",
      "Juneho Yi"
    ],
    "abstract": "In unsupervised anomaly detection (UAD) research, while state-of-the-art\nmodels have reached a saturation point with extensive studies on public\nbenchmark datasets, they adopt large-scale tailor-made neural networks (NN) for\ndetection performance or pursued unified models for various tasks. Towards edge\ncomputing, it is necessary to develop a computationally efficient and scalable\nsolution that avoids large-scale complex NNs. Motivated by this, we aim to\noptimize the UAD performance with minimal changes to NN settings. Thus, we\nrevisit the reconstruction-by-inpainting approach and rethink to improve it by\nanalyzing strengths and weaknesses. The strength of the SOTA methods is a\nsingle deterministic masking approach that addresses the challenges of random\nmultiple masking that is inference latency and output inconsistency.\nNevertheless, the issue of failure to provide a mask to completely cover\nanomalous regions is a remaining weakness. To mitigate this issue, we propose\nFeature Attenuation of Defective Representation (FADeR) that only employs two\nMLP layers which attenuates feature information of anomaly reconstruction\nduring decoding. By leveraging FADeR, features of unseen anomaly patterns are\nreconstructed into seen normal patterns, reducing false alarms. Experimental\nresults demonstrate that FADeR achieves enhanced performance compared to\nsimilar-scale NNs. Furthermore, our approach exhibits scalability in\nperformance enhancement when integrated with other single deterministic masking\nmethods in a plug-and-play manner.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages, 6 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2407.04597v1",
    "published_date": "2024-07-05 15:44:53 UTC",
    "updated_date": "2024-07-05 15:44:53 UTC"
  },
  {
    "arxiv_id": "2407.04559v4",
    "title": "Not (yet) the whole story: Evaluating Visual Storytelling Requires More than Measuring Coherence, Grounding, and Repetition",
    "authors": [
      "Aditya K Surikuchi",
      "Raquel Fernández",
      "Sandro Pezzelle"
    ],
    "abstract": "Visual storytelling consists in generating a natural language story given a\ntemporally ordered sequence of images. This task is not only challenging for\nmodels, but also very difficult to evaluate with automatic metrics since there\nis no consensus about what makes a story 'good'. In this paper, we introduce a\nnovel method that measures story quality in terms of human likeness regarding\nthree key aspects highlighted in previous work: visual grounding, coherence,\nand repetitiveness. We then use this method to evaluate the stories generated\nby several models, showing that the foundation model LLaVA obtains the best\nresult, but only slightly so compared to TAPM, a 50-times smaller visual\nstorytelling model. Upgrading the visual and language components of TAPM\nresults in a model that yields competitive performance with a relatively low\nnumber of parameters. Finally, we carry out a human evaluation study, whose\nresults suggest that a 'good' story may require more than a human-like level of\nvisual grounding, coherence, and repetition.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "In proceedings of EMNLP 2024 (Findings)",
    "pdf_url": "http://arxiv.org/pdf/2407.04559v4",
    "published_date": "2024-07-05 14:48:15 UTC",
    "updated_date": "2024-10-25 13:47:11 UTC"
  },
  {
    "arxiv_id": "2407.04551v1",
    "title": "An AI Architecture with the Capability to Classify and Explain Hardware Trojans",
    "authors": [
      "Paul Whitten",
      "Francis Wolff",
      "Chris Papachristou"
    ],
    "abstract": "Hardware trojan detection methods, based on machine learning (ML) techniques,\nmainly identify suspected circuits but lack the ability to explain how the\ndecision was arrived at. An explainable methodology and architecture is\nintroduced based on the existing hardware trojan detection features. Results\nare provided for explaining digital hardware trojans within a netlist using\ntrust-hub trojan benchmarks.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.04551v1",
    "published_date": "2024-07-05 14:36:19 UTC",
    "updated_date": "2024-07-05 14:36:19 UTC"
  },
  {
    "arxiv_id": "2407.04549v1",
    "title": "Spontaneous Reward Hacking in Iterative Self-Refinement",
    "authors": [
      "Jane Pan",
      "He He",
      "Samuel R. Bowman",
      "Shi Feng"
    ],
    "abstract": "Language models are capable of iteratively improving their outputs based on\nnatural language feedback, thus enabling in-context optimization of user\npreference. In place of human users, a second language model can be used as an\nevaluator, providing feedback along with numerical ratings which the generator\nattempts to optimize. However, because the evaluator is an imperfect proxy of\nuser preference, this optimization can lead to reward hacking, where the\nevaluator's ratings improve while the generation quality remains stagnant or\neven decreases as judged by actual user preference. The concern of reward\nhacking is heightened in iterative self-refinement where the generator and the\nevaluator use the same underlying language model, in which case the\noptimization pressure can drive them to exploit shared vulnerabilities. Using\nan essay editing task, we show that iterative self-refinement leads to\ndeviation between the language model evaluator and human judgment,\ndemonstrating that reward hacking can occur spontaneously in-context with the\nuse of iterative self-refinement. In addition, we study conditions under which\nreward hacking occurs and observe two factors that affect reward hacking\nseverity: model size and context sharing between the generator and the\nevaluator.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.04549v1",
    "published_date": "2024-07-05 14:34:50 UTC",
    "updated_date": "2024-07-05 14:34:50 UTC"
  },
  {
    "arxiv_id": "2407.04547v1",
    "title": "Real-time Timbre Remapping with Differentiable DSP",
    "authors": [
      "Jordie Shier",
      "Charalampos Saitis",
      "Andrew Robertson",
      "Andrew McPherson"
    ],
    "abstract": "Timbre is a primary mode of expression in diverse musical contexts. However,\nprevalent audio-driven synthesis methods predominantly rely on pitch and\nloudness envelopes, effectively flattening timbral expression from the input.\nOur approach draws on the concept of timbre analogies and investigates how\ntimbral expression from an input signal can be mapped onto controls for a\nsynthesizer. Leveraging differentiable digital signal processing, our method\nfacilitates direct optimization of synthesizer parameters through a novel\nfeature difference loss. This loss function, designed to learn relative timbral\ndifferences between musical events, prioritizes the subtleties of graded timbre\nmodulations within phrases, allowing for meaningful translations in a timbre\nspace. Using snare drum performances as a case study, where timbral expression\nis central, we demonstrate real-time timbre remapping from acoustic snare drums\nto a differentiable synthesizer modeled after the Roland TR-808.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS",
      "eess.SP"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted for publication at the 24th International Conference on New\n  Interfaces for Musical Expression in Utrecht, Netherlands",
    "pdf_url": "http://arxiv.org/pdf/2407.04547v1",
    "published_date": "2024-07-05 14:32:52 UTC",
    "updated_date": "2024-07-05 14:32:52 UTC"
  },
  {
    "arxiv_id": "2407.04541v2",
    "title": "PoPreRo: A New Dataset for Popularity Prediction of Romanian Reddit Posts",
    "authors": [
      "Ana-Cristina Rogoz",
      "Maria Ilinca Nechita",
      "Radu Tudor Ionescu"
    ],
    "abstract": "We introduce PoPreRo, the first dataset for Popularity Prediction of Romanian\nposts collected from Reddit. The PoPreRo dataset includes a varied compilation\nof post samples from five distinct subreddits of Romania, totaling 28,107 data\nsamples. Along with our novel dataset, we introduce a set of competitive models\nto be used as baselines for future research. Interestingly, the top-scoring\nmodel achieves an accuracy of 61.35% and a macro F1 score of 60.60% on the test\nset, indicating that the popularity prediction task on PoPreRo is very\nchallenging. Further investigations based on few-shot prompting the Falcon-7B\nLarge Language Model also point in the same direction. We thus believe that\nPoPreRo is a valuable resource that can be used to evaluate models on\npredicting the popularity of social media posts in Romanian. We release our\ndataset at https://github.com/ana-rogoz/PoPreRo.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at ICPR 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.04541v2",
    "published_date": "2024-07-05 14:28:12 UTC",
    "updated_date": "2024-11-24 09:40:34 UTC"
  },
  {
    "arxiv_id": "2407.04538v3",
    "title": "PDiscoFormer: Relaxing Part Discovery Constraints with Vision Transformers",
    "authors": [
      "Ananthu Aniraj",
      "Cassio F. Dantas",
      "Dino Ienco",
      "Diego Marcos"
    ],
    "abstract": "Computer vision methods that explicitly detect object parts and reason on\nthem are a step towards inherently interpretable models. Existing approaches\nthat perform part discovery driven by a fine-grained classification task make\nvery restrictive assumptions on the geometric properties of the discovered\nparts; they should be small and compact. Although this prior is useful in some\ncases, in this paper we show that pre-trained transformer-based vision models,\nsuch as self-supervised DINOv2 ViT, enable the relaxation of these constraints.\nIn particular, we find that a total variation (TV) prior, which allows for\nmultiple connected components of any size, substantially outperforms previous\nwork. We test our approach on three fine-grained classification benchmarks:\nCUB, PartImageNet and Oxford Flowers, and compare our results to previously\npublished methods as well as a re-implementation of the state-of-the-art method\nPDiscoNet with a transformer-based backbone. We consistently obtain substantial\nimprovements across the board, both on part discovery metrics and the\ndownstream classification task, showing that the strong inductive biases in\nself-supervised ViT models require to rethink the geometric priors that can be\nused for unsupervised part discovery.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted as a main conference paper at the European Conference of\n  Computer Vision (ECCV) 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.04538v3",
    "published_date": "2024-07-05 14:24:37 UTC",
    "updated_date": "2024-07-22 09:41:39 UTC"
  },
  {
    "arxiv_id": "2407.04528v4",
    "title": "GPT vs RETRO: Exploring the Intersection of Retrieval and Parameter-Efficient Fine-Tuning",
    "authors": [
      "Aleksander Ficek",
      "Jiaqi Zeng",
      "Oleksii Kuchaiev"
    ],
    "abstract": "Parameter-Efficient Fine-Tuning (PEFT) and Retrieval-Augmented Generation\n(RAG) have become popular methods for adapting large language models while\nminimizing compute requirements. In this paper, we apply PEFT methods\n(P-tuning, Adapters, and LoRA) to a modified Retrieval-Enhanced Transformer\n(RETRO) and a baseline GPT model across several sizes, ranging from 823 million\nto 48 billion parameters. We show that RETRO models outperform GPT models in\nzero-shot settings due to their unique pre-training process but GPT models have\nhigher performance potential with PEFT. Additionally, our study indicates that\n8B parameter models strike an optimal balance between cost and performance and\nP-tuning lags behind other PEFT techniques. We further provide a comparative\nanalysis between applying PEFT to an Instruction-tuned RETRO model and base\nRETRO model. This work presents the first comprehensive comparison of various\nPEFT methods integrated with RAG, applied to both GPT and RETRO models,\nhighlighting their relative performance.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.04528v4",
    "published_date": "2024-07-05 14:16:47 UTC",
    "updated_date": "2024-10-25 14:33:23 UTC"
  },
  {
    "arxiv_id": "2407.04525v4",
    "title": "Enhancing learning in spiking neural networks through neuronal heterogeneity and neuromodulatory signaling",
    "authors": [
      "Alejandro Rodriguez-Garcia",
      "Jie Mei",
      "Srikanth Ramaswamy"
    ],
    "abstract": "Recent progress in artificial intelligence (AI) has been driven by insights\nfrom neuroscience, particularly with the development of artificial neural\nnetworks (ANNs). This has significantly enhanced the replication of complex\ncognitive tasks such as vision and natural language processing. Despite these\nadvances, ANNs struggle with continual learning, adaptable knowledge transfer,\nrobustness, and resource efficiency - capabilities that biological systems\nhandle seamlessly. Specifically, ANNs often overlook the functional and\nmorphological diversity of the brain, hindering their computational\ncapabilities. Furthermore, incorporating cell-type specific neuromodulatory\neffects into ANNs with neuronal heterogeneity could enable learning at two\nspatial scales: spiking behavior at the neuronal level, and synaptic plasticity\nat the circuit level, thereby potentially enhancing their learning abilities.\nIn this article, we summarize recent bio-inspired models, learning rules and\narchitectures and propose a biologically-informed framework for enhancing ANNs.\nOur proposed dual-framework approach highlights the potential of spiking neural\nnetworks (SNNs) for emulating diverse spiking behaviors and dendritic\ncompartments to simulate morphological and functional diversity of neuronal\ncomputations. Finally, we outline how the proposed approach integrates\nbrain-inspired compartmental models and task-driven SNNs, balances\nbioinspiration and complexity, and provides scalable solutions for pressing AI\nchallenges, such as continual learning, adaptability, robustness, and\nresource-efficiency.",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.LG",
      "92B20"
    ],
    "primary_category": "q-bio.NC",
    "comment": "30 pages, 4 figures, 3 boxes",
    "pdf_url": "http://arxiv.org/pdf/2407.04525v4",
    "published_date": "2024-07-05 14:11:28 UTC",
    "updated_date": "2024-11-11 16:58:38 UTC"
  },
  {
    "arxiv_id": "2407.04513v2",
    "title": "LayerShuffle: Enhancing Robustness in Vision Transformers by Randomizing Layer Execution Order",
    "authors": [
      "Matthias Freiberger",
      "Peter Kun",
      "Anders Sundnes Løvlie",
      "Sebastian Risi"
    ],
    "abstract": "Due to their architecture and how they are trained, artificial neural\nnetworks are typically not robust toward pruning or shuffling layers at test\ntime. However, such properties would be desirable for different applications,\nsuch as distributed neural network architectures where the order of execution\ncannot be guaranteed or parts of the network can fail during inference. In this\nwork, we address these issues through a number of training approaches for\nvision transformers whose most important component is randomizing the execution\norder of attention modules at training time. With our proposed approaches,\nvision transformers are capable to adapt to arbitrary layer execution orders at\ntest time assuming one tolerates a reduction (about 20\\%) in accuracy at the\nsame model size. We analyse the feature representations of our trained models\nas well as how each layer contributes to the models prediction based on its\nposition during inference. Our analysis shows that layers learn to contribute\ndifferently based on their position in the network. Finally, we layer-prune our\nmodels at test time and find that their performance declines gracefully. Code\navailable at https://github.com/matfrei/layershuffle.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.04513v2",
    "published_date": "2024-07-05 13:54:15 UTC",
    "updated_date": "2024-12-06 14:20:26 UTC"
  },
  {
    "arxiv_id": "2407.04503v2",
    "title": "When LLMs Play the Telephone Game: Cumulative Changes and Attractors in Iterated Cultural Transmissions",
    "authors": [
      "Jérémy Perez",
      "Grgur Kovač",
      "Corentin Léger",
      "Cédric Colas",
      "Gaia Molinaro",
      "Maxime Derex",
      "Pierre-Yves Oudeyer",
      "Clément Moulin-Frier"
    ],
    "abstract": "As large language models (LLMs) start interacting with each other and\ngenerating an increasing amount of text online, it becomes crucial to better\nunderstand how information is transformed as it passes from one LLM to the\nnext. While significant research has examined individual LLM behaviors,\nexisting studies have largely overlooked the collective behaviors and\ninformation distortions arising from iterated LLM interactions. Small biases,\nnegligible at the single output level, risk being amplified in iterated\ninteractions, potentially leading the content to evolve towards attractor\nstates. In a series of telephone game experiments, we apply a transmission\nchain design borrowed from the human cultural evolution literature: LLM agents\niteratively receive, produce, and transmit texts from the previous to the next\nagent in the chain. By tracking the evolution of text toxicity, positivity,\ndifficulty, and length across transmission chains, we uncover the existence of\nbiases and attractors, and study their dependence on the initial text, the\ninstructions, language model, and model size. For instance, we find that more\nopen-ended instructions lead to stronger attraction effects compared to more\nconstrained tasks. We also find that different text properties display\ndifferent sensitivity to attraction effects, with toxicity leading to stronger\nattractors than length. These findings highlight the importance of accounting\nfor multi-step transmission dynamics and represent a first step towards a more\ncomprehensive understanding of LLM cultural dynamics.",
    "categories": [
      "physics.soc-ph",
      "cs.AI",
      "cs.MA",
      "68T50",
      "I.2.7"
    ],
    "primary_category": "physics.soc-ph",
    "comment": "Code available at https://github.com/jeremyperez2/TelephoneGameLLM.\n  Companion website with a Data Explorer tool at\n  https://sites.google.com/view/telephone-game-llm",
    "pdf_url": "http://arxiv.org/pdf/2407.04503v2",
    "published_date": "2024-07-05 13:44:09 UTC",
    "updated_date": "2024-12-18 11:02:14 UTC"
  },
  {
    "arxiv_id": "2407.04486v1",
    "title": "Variational and Explanatory Neural Networks for Encoding Cancer Profiles and Predicting Drug Responses",
    "authors": [
      "Tianshu Feng",
      "Rohan Gnanaolivu",
      "Abolfazl Safikhani",
      "Yuanhang Liu",
      "Jun Jiang",
      "Nicholas Chia",
      "Alexander Partin",
      "Priyanka Vasanthakumari",
      "Yitan Zhu",
      "Chen Wang"
    ],
    "abstract": "Human cancers present a significant public health challenge and require the\ndiscovery of novel drugs through translational research. Transcriptomics\nprofiling data that describes molecular activities in tumors and cancer cell\nlines are widely utilized for predicting anti-cancer drug responses. However,\nexisting AI models face challenges due to noise in transcriptomics data and\nlack of biological interpretability. To overcome these limitations, we\nintroduce VETE (Variational and Explanatory Transcriptomics Encoder), a novel\nneural network framework that incorporates a variational component to mitigate\nnoise effects and integrates traceable gene ontology into the neural network\narchitecture for encoding cancer transcriptomics data. Key innovations include\na local interpretability-guided method for identifying ontology paths, a\nvisualization tool to elucidate biological mechanisms of drug responses, and\nthe application of centralized large scale hyperparameter optimization. VETE\ndemonstrated robust accuracy in cancer cell line classification and drug\nresponse prediction. Additionally, it provided traceable biological\nexplanations for both tasks and offers insights into the mechanisms underlying\nits predictions. VETE bridges the gap between AI-driven predictions and\nbiologically meaningful insights in cancer research, which represents a\npromising advancement in the field.",
    "categories": [
      "q-bio.QM",
      "cs.AI"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.04486v1",
    "published_date": "2024-07-05 13:13:02 UTC",
    "updated_date": "2024-07-05 13:13:02 UTC"
  },
  {
    "arxiv_id": "2407.04472v3",
    "title": "EventChat: Implementation and user-centric evaluation of a large language model-driven conversational recommender system for exploring leisure events in an SME context",
    "authors": [
      "Hannes Kunstmann",
      "Joseph Ollier",
      "Joel Persson",
      "Florian von Wangenheim"
    ],
    "abstract": "Large language models (LLMs) present an enormous evolution in the strategic\npotential of conversational recommender systems (CRS). Yet to date, research\nhas predominantly focused upon technical frameworks to implement LLM-driven\nCRS, rather than end-user evaluations or strategic implications for firms,\nparticularly from the perspective of a small to medium enterprises (SME) that\nmakeup the bedrock of the global economy. In the current paper, we detail the\ndesign of an LLM-driven CRS in an SME setting, and its subsequent performance\nin the field using both objective system metrics and subjective user\nevaluations. While doing so, we additionally outline a short-form revised\nResQue model for evaluating LLM-driven CRS, enabling replicability in a rapidly\nevolving field. Our results reveal good system performance from a user\nexperience perspective (85.5% recommendation accuracy) but underscore latency,\ncost, and quality issues challenging business viability. Notably, with a median\ncost of $0.04 per interaction and a latency of 5.7s, cost-effectiveness and\nresponse time emerge as crucial areas for achieving a more user-friendly and\neconomically viable LLM-driven CRS for SME settings. One major driver of these\ncosts is the use of an advanced LLM as a ranker within the retrieval-augmented\ngeneration (RAG) technique. Our results additionally indicate that relying\nsolely on approaches such as Prompt-based learning with ChatGPT as the\nunderlying LLM makes it challenging to achieve satisfying quality in a\nproduction environment. Strategic considerations for SMEs deploying an\nLLM-driven CRS are outlined, particularly considering trade-offs in the current\ntechnical landscape.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "68T50",
      "I.2.7; H.5.2"
    ],
    "primary_category": "cs.IR",
    "comment": "27 pages, 3 tables, 5 figures, pre-print manuscript, updated version\n  of manuscript due to typo (previous version, Figure 5 was incorrectly named\n  Figure 6)",
    "pdf_url": "http://arxiv.org/pdf/2407.04472v3",
    "published_date": "2024-07-05 12:42:31 UTC",
    "updated_date": "2024-07-09 13:31:00 UTC"
  },
  {
    "arxiv_id": "2407.04467v3",
    "title": "Are Large Language Models Strategic Decision Makers? A Study of Performance and Bias in Two-Player Non-Zero-Sum Games",
    "authors": [
      "Nathan Herr",
      "Fernando Acero",
      "Roberta Raileanu",
      "María Pérez-Ortiz",
      "Zhibin Li"
    ],
    "abstract": "Large Language Models (LLMs) have been increasingly used in real-world\nsettings, yet their strategic decision-making abilities remain largely\nunexplored. To fully benefit from the potential of LLMs, it's essential to\nunderstand their ability to function in complex social scenarios. Game theory,\nwhich is already used to understand real-world interactions, provides a good\nframework for assessing these abilities. This work investigates the performance\nand merits of LLMs in canonical game-theoretic two-player non-zero-sum games,\nStag Hunt and Prisoner Dilemma. Our structured evaluation of GPT-3.5,\nGPT-4-Turbo, GPT-4o, and Llama-3-8B shows that these models, when making\ndecisions in these games, are affected by at least one of the following\nsystematic biases: positional bias, payoff bias, or behavioural bias. This\nindicates that LLMs do not fully rely on logical reasoning when making these\nstrategic decisions. As a result, it was found that the LLMs' performance drops\nwhen the game configuration is misaligned with the affecting biases. When\nmisaligned, GPT-3.5, GPT-4-Turbo, GPT-4o, and Llama-3-8B show an average\nperformance drop of 32\\%, 25\\%, 34\\%, and 29\\% respectively in Stag Hunt, and\n28\\%, 16\\%, 34\\%, and 24\\% respectively in Prisoner's Dilemma. Surprisingly,\nGPT-4o (a top-performing LLM across standard benchmarks) suffers the most\nsubstantial performance drop, suggesting that newer models are not addressing\nthese issues. Interestingly, we found that a commonly used method of improving\nthe reasoning capabilities of LLMs, chain-of-thought (CoT) prompting, reduces\nthe biases in GPT-3.5, GPT-4o, and Llama-3-8B but increases the effect of the\nbias in GPT-4-Turbo, indicating that CoT alone cannot fully serve as a robust\nsolution to this problem. We perform several additional experiments, which\nprovide further insight into these observed behaviours.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.GT"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.04467v3",
    "published_date": "2024-07-05 12:30:02 UTC",
    "updated_date": "2024-10-15 11:29:10 UTC"
  },
  {
    "arxiv_id": "2407.04458v1",
    "title": "Robust Multimodal Learning via Representation Decoupling",
    "authors": [
      "Shicai Wei",
      "Yang Luo",
      "Yuji Wang",
      "Chunbo Luo"
    ],
    "abstract": "Multimodal learning robust to missing modality has attracted increasing\nattention due to its practicality. Existing methods tend to address it by\nlearning a common subspace representation for different modality combinations.\nHowever, we reveal that they are sub-optimal due to their implicit constraint\non intra-class representation. Specifically, the sample with different\nmodalities within the same class will be forced to learn representations in the\nsame direction. This hinders the model from capturing modality-specific\ninformation, resulting in insufficient learning. To this end, we propose a\nnovel Decoupled Multimodal Representation Network (DMRNet) to assist robust\nmultimodal learning. Specifically, DMRNet models the input from different\nmodality combinations as a probabilistic distribution instead of a fixed point\nin the latent space, and samples embeddings from the distribution for the\nprediction module to calculate the task loss. As a result, the direction\nconstraint from the loss minimization is blocked by the sampled representation.\nThis relaxes the constraint on the inference representation and enables the\nmodel to capture the specific information for different modality combinations.\nFurthermore, we introduce a hard combination regularizer to prevent DMRNet from\nunbalanced training by guiding it to pay more attention to hard modality\ncombinations. Finally, extensive experiments on multimodal classification and\nsegmentation tasks demonstrate that the proposed DMRNet outperforms the\nstate-of-the-art significantly.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "ECCV2024 17 pages",
    "pdf_url": "http://arxiv.org/pdf/2407.04458v1",
    "published_date": "2024-07-05 12:09:33 UTC",
    "updated_date": "2024-07-05 12:09:33 UTC"
  },
  {
    "arxiv_id": "2407.04451v1",
    "title": "Hindsight Preference Learning for Offline Preference-based Reinforcement Learning",
    "authors": [
      "Chen-Xiao Gao",
      "Shengjun Fang",
      "Chenjun Xiao",
      "Yang Yu",
      "Zongzhang Zhang"
    ],
    "abstract": "Offline preference-based reinforcement learning (RL), which focuses on\noptimizing policies using human preferences between pairs of trajectory\nsegments selected from an offline dataset, has emerged as a practical avenue\nfor RL applications. Existing works rely on extracting step-wise reward signals\nfrom trajectory-wise preference annotations, assuming that preferences\ncorrelate with the cumulative Markovian rewards. However, such methods fail to\ncapture the holistic perspective of data annotation: Humans often assess the\ndesirability of a sequence of actions by considering the overall outcome rather\nthan the immediate rewards. To address this challenge, we propose to model\nhuman preferences using rewards conditioned on future outcomes of the\ntrajectory segments, i.e. the hindsight information. For downstream RL\noptimization, the reward of each step is calculated by marginalizing over\npossible future outcomes, the distribution of which is approximated by a\nvariational auto-encoder trained using the offline dataset. Our proposed\nmethod, Hindsight Preference Learning (HPL), can facilitate credit assignment\nby taking full advantage of vast trajectory data available in massive unlabeled\ndatasets. Comprehensive empirical studies demonstrate the benefits of HPL in\ndelivering robust and advantageous rewards across various domains. Our code is\npublicly released at https://github.com/typoverflow/WiseRL.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.04451v1",
    "published_date": "2024-07-05 12:05:37 UTC",
    "updated_date": "2024-07-05 12:05:37 UTC"
  },
  {
    "arxiv_id": "2407.04449v1",
    "title": "Multi-modal Masked Siamese Network Improves Chest X-Ray Representation Learning",
    "authors": [
      "Saeed Shurrab",
      "Alejandro Guerra-Manzanares",
      "Farah E. Shamout"
    ],
    "abstract": "Self-supervised learning methods for medical images primarily rely on the\nimaging modality during pretraining. While such approaches deliver promising\nresults, they do not leverage associated patient or scan information collected\nwithin Electronic Health Records (EHR). Here, we propose to incorporate EHR\ndata during self-supervised pretraining with a Masked Siamese Network (MSN) to\nenhance the quality of chest X-ray representations. We investigate three types\nof EHR data, including demographic, scan metadata, and inpatient stay\ninformation. We evaluate our approach on three publicly available chest X-ray\ndatasets, MIMIC-CXR, CheXpert, and NIH-14, using two vision transformer (ViT)\nbackbones, specifically ViT-Tiny and ViT-Small. In assessing the quality of the\nrepresentations via linear evaluation, our proposed method demonstrates\nsignificant improvement compared to vanilla MSN and state-of-the-art\nself-supervised learning baselines. Our work highlights the potential of\nEHR-enhanced self-supervised pre-training for medical imaging. The code is\npublicly available at: https://github.com/nyuad-cai/CXR-EHR-MSN",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Under review",
    "pdf_url": "http://arxiv.org/pdf/2407.04449v1",
    "published_date": "2024-07-05 12:04:12 UTC",
    "updated_date": "2024-07-05 12:04:12 UTC"
  },
  {
    "arxiv_id": "2407.11036v1",
    "title": "Hybrid-Generative Diffusion Models for Attack-Oriented Twin Migration in Vehicular Metaverses",
    "authors": [
      "Yingkai Kang",
      "Jinbo Wen",
      "Jiawen Kang",
      "Tao Zhang",
      "Hongyang Du",
      "Dusit Niyato",
      "Rong Yu",
      "Shengli Xie"
    ],
    "abstract": "The vehicular metaverse is envisioned as a blended immersive domain that\npromises to bring revolutionary changes to the automotive industry. As a core\ncomponent of vehicular metaverses, Vehicle Twins (VTs) are digital twins that\ncover the entire life cycle of vehicles, providing immersive virtual services\nfor Vehicular Metaverse Users (VMUs). Vehicles with limited resources offload\nthe computationally intensive tasks of constructing and updating VTs to edge\nservers and migrate VTs between these servers, ensuring seamless and immersive\nexperiences for VMUs. However, the high mobility of vehicles, uneven deployment\nof edge servers, and potential security threats pose challenges to achieving\nefficient and reliable VT migrations. To address these issues, we propose a\nsecure and reliable VT migration framework in vehicular metaverses.\nSpecifically, we design a two-layer trust evaluation model to comprehensively\nevaluate the reputation value of edge servers in the network communication and\ninteraction layers. Then, we model the VT migration problem as a partially\nobservable Markov decision process and design a hybrid-Generative Diffusion\nModel (GDM) algorithm based on deep reinforcement learning to generate optimal\nmigration decisions by taking hybrid actions (i.e., continuous actions and\ndiscrete actions). Numerical results demonstrate that the hybrid-GDM algorithm\noutperforms the baseline algorithms, showing strong adaptability in various\nsettings and highlighting the potential of the hybrid-GDM algorithm for\naddressing various optimization issues in vehicular metaverses.",
    "categories": [
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.11036v1",
    "published_date": "2024-07-05 11:11:33 UTC",
    "updated_date": "2024-07-05 11:11:33 UTC"
  },
  {
    "arxiv_id": "2407.04419v1",
    "title": "The Complexity of Symmetry Breaking Beyond Lex-Leader",
    "authors": [
      "Markus Anders",
      "Sofia Brenner",
      "Gaurav Rattan"
    ],
    "abstract": "Symmetry breaking is a widely popular approach to enhance solvers in\nconstraint programming, such as those for SAT or MIP. Symmetry breaking\npredicates (SBPs) typically impose an order on variables and single out the\nlexicographic leader (lex-leader) in each orbit of assignments. Although it is\nNP-hard to find complete lex-leader SBPs, incomplete lex-leader SBPs are widely\nused in practice.\n  In this paper, we investigate the complexity of computing complete SBPs,\nlex-leader or otherwise, for SAT. Our main result proves a natural barrier for\nefficiently computing SBPs: efficient certification of graph non-isomorphism.\nOur results explain the difficulty of obtaining short SBPs for important CP\nproblems, such as matrix-models with row-column symmetries and graph generation\nproblems. Our results hold even when SBPs are allowed to introduce additional\nvariables. We show polynomial upper bounds for breaking certain symmetry\ngroups, namely automorphism groups of trees and wreath products of groups with\nefficient SBPs.",
    "categories": [
      "cs.AI",
      "cs.CC"
    ],
    "primary_category": "cs.AI",
    "comment": "accepted to CP 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.04419v1",
    "published_date": "2024-07-05 11:09:55 UTC",
    "updated_date": "2024-07-05 11:09:55 UTC"
  },
  {
    "arxiv_id": "2407.04418v2",
    "title": "Enabling On-Device LLMs Personalization with Smartphone Sensing",
    "authors": [
      "Shiquan Zhang",
      "Ying Ma",
      "Le Fang",
      "Hong Jia",
      "Simon D'Alfonso",
      "Vassilis Kostakos"
    ],
    "abstract": "This demo presents a novel end-to-end framework that combines on-device large\nlanguage models (LLMs) with smartphone sensing technologies to achieve\ncontext-aware and personalized services. The framework addresses critical\nlimitations of current personalization solutions via cloud LLMs, such as\nprivacy concerns, latency and cost, and limited personal information. To\nachieve this, we innovatively proposed deploying LLMs on smartphones with\nmultimodal sensor data through context-aware sensing and customized prompt\nengineering, ensuring privacy and enhancing personalization performance. A case\nstudy involving a university student demonstrated the capability of the\nframework to provide tailored recommendations. In addition, we show that the\nframework achieves the best trade-off in privacy, performance, latency, cost,\nbattery and energy consumption between on-device and cloud LLMs. To the best of\nour knowledge, this is the first framework to provide on-device LLMs\npersonalization with smartphone sensing. Future work will incorporate more\ndiverse sensor data and involve extensive user studies to enhance\npersonalization. Our proposed framework has the potential to substantially\nimprove user experiences across domains including healthcare, productivity, and\nentertainment.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "5 pages, 3 figures, conference demo paper",
    "pdf_url": "http://arxiv.org/pdf/2407.04418v2",
    "published_date": "2024-07-05 11:09:05 UTC",
    "updated_date": "2024-07-24 01:32:05 UTC"
  },
  {
    "arxiv_id": "2407.04411v2",
    "title": "Waterfall: Framework for Robust and Scalable Text Watermarking and Provenance for LLMs",
    "authors": [
      "Gregory Kang Ruey Lau",
      "Xinyuan Niu",
      "Hieu Dao",
      "Jiangwei Chen",
      "Chuan-Sheng Foo",
      "Bryan Kian Hsiang Low"
    ],
    "abstract": "Protecting intellectual property (IP) of text such as articles and code is\nincreasingly important, especially as sophisticated attacks become possible,\nsuch as paraphrasing by large language models (LLMs) or even unauthorized\ntraining of LLMs on copyrighted text to infringe such IP. However, existing\ntext watermarking methods are not robust enough against such attacks nor\nscalable to millions of users for practical implementation. In this paper, we\npropose Waterfall, the first training-free framework for robust and scalable\ntext watermarking applicable across multiple text types (e.g., articles, code)\nand languages supportable by LLMs, for general text and LLM data provenance.\nWaterfall comprises several key innovations, such as being the first to use LLM\nas paraphrasers for watermarking along with a novel combination of techniques\nthat are surprisingly effective in achieving robust verifiability and\nscalability. We empirically demonstrate that Waterfall achieves significantly\nbetter scalability, robust verifiability, and computational efficiency compared\nto SOTA article-text watermarking methods, and showed how it could be directly\napplied to the watermarking of code. We also demonstrated that Waterfall can be\nused for LLM data provenance, where the watermarks of LLM training data can be\ndetected in LLM output, allowing for detection of unauthorized use of data for\nLLM training and potentially enabling model-centric watermarking of\nopen-sourced LLMs which has been a limitation of existing LLM watermarking\nworks. Our code is available at https://github.com/aoi3142/Waterfall.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted to EMNLP 2024 Main Conference",
    "pdf_url": "http://arxiv.org/pdf/2407.04411v2",
    "published_date": "2024-07-05 10:51:33 UTC",
    "updated_date": "2024-10-29 07:02:51 UTC"
  },
  {
    "arxiv_id": "2407.04405v3",
    "title": "Discovering physical laws with parallel combinatorial tree search",
    "authors": [
      "Kai Ruan",
      "Yilong Xu",
      "Ze-Feng Gao",
      "Yike Guo",
      "Hao Sun",
      "Ji-Rong Wen",
      "Yang Liu"
    ],
    "abstract": "Symbolic regression plays a crucial role in modern scientific research thanks\nto its capability of discovering concise and interpretable mathematical\nexpressions from data. A grand challenge lies in the arduous search for\nparsimonious and generalizable mathematical formulas, in an infinite search\nspace, while intending to fit the training data. Existing algorithms have faced\na critical bottleneck of accuracy and efficiency over a decade when handling\nproblems of complexity, which essentially hinders the pace of applying symbolic\nregression for scientific exploration across interdisciplinary domains. To this\nend, we introduce a parallel combinatorial tree search (PCTS) model to\nefficiently distill generic mathematical expressions from limited data. Through\na series of extensive experiments, we demonstrate the superior accuracy and\nefficiency of PCTS for equation discovery, which greatly outperforms the\nstate-of-the-art baseline models on over 200 synthetic and experimental\ndatasets (e.g., lifting its performance by up to 99% accuracy improvement and\none-order of magnitude speed up). PCTS represents a key advance in accurate and\nefficient data-driven discovery of symbolic, interpretable models (e.g.,\nunderlying physical laws) and marks a pivotal transition towards scalable\nsymbolic learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.04405v3",
    "published_date": "2024-07-05 10:41:15 UTC",
    "updated_date": "2025-03-03 03:39:50 UTC"
  },
  {
    "arxiv_id": "2407.04396v2",
    "title": "Graph-Guided Test-Time Adaptation for Glaucoma Diagnosis using Fundus Photography",
    "authors": [
      "Qian Zeng",
      "Le Zhang",
      "Yipeng Liu",
      "Ce Zhu",
      "Fan Zhang"
    ],
    "abstract": "Glaucoma is a leading cause of irreversible blindness worldwide. While deep\nlearning approaches using fundus images have largely improved early diagnosis\nof glaucoma, variations in images from different devices and locations (known\nas domain shifts) challenge the use of pre-trained models in real-world\nsettings. To address this, we propose a novel Graph-guided Test-Time Adaptation\n(GTTA) framework to generalize glaucoma diagnosis models to unseen test\nenvironments. GTTA integrates the topological information of fundus images into\nthe model training, enhancing the model's transferability and reducing the risk\nof learning spurious correlation. During inference, GTTA introduces a novel\ntest-time training objective to make the source-trained classifier\nprogressively adapt to target patterns with reliable class conditional\nestimation and consistency regularization. Experiments on cross-domain glaucoma\ndiagnosis benchmarks demonstrate the superiority of the overall framework and\nindividual components under different backbone networks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages, 3 figures, 3 tables, submitted to MICCAI",
    "pdf_url": "http://arxiv.org/pdf/2407.04396v2",
    "published_date": "2024-07-05 10:06:55 UTC",
    "updated_date": "2024-07-10 03:54:23 UTC"
  },
  {
    "arxiv_id": "2407.04381v1",
    "title": "Multi-Branch Auxiliary Fusion YOLO with Re-parameterization Heterogeneous Convolutional for accurate object detection",
    "authors": [
      "Zhiqiang Yang",
      "Qiu Guan",
      "Keer Zhao",
      "Jianmin Yang",
      "Xinli Xu",
      "Haixia Long",
      "Ying Tang"
    ],
    "abstract": "Due to the effective performance of multi-scale feature fusion, Path\nAggregation FPN (PAFPN) is widely employed in YOLO detectors. However, it\ncannot efficiently and adaptively integrate high-level semantic information\nwith low-level spatial information simultaneously. We propose a new model named\nMAF-YOLO in this paper, which is a novel object detection framework with a\nversatile neck named Multi-Branch Auxiliary FPN (MAFPN). Within MAFPN, the\nSuperficial Assisted Fusion (SAF) module is designed to combine the output of\nthe backbone with the neck, preserving an optimal level of shallow information\nto facilitate subsequent learning. Meanwhile, the Advanced Assisted Fusion\n(AAF) module deeply embedded within the neck conveys a more diverse range of\ngradient information to the output layer.\n  Furthermore, our proposed Re-parameterized Heterogeneous Efficient Layer\nAggregation Network (RepHELAN) module ensures that both the overall model\narchitecture and convolutional design embrace the utilization of heterogeneous\nlarge convolution kernels. Therefore, this guarantees the preservation of\ninformation related to small targets while simultaneously achieving the\nmulti-scale receptive field. Finally, taking the nano version of MAF-YOLO for\nexample, it can achieve 42.4% AP on COCO with only 3.76M learnable parameters\nand 10.51G FLOPs, and approximately outperforms YOLOv8n by about 5.1%. The\nsource code of this work is available at:\nhttps://github.com/yang-0201/MAF-YOLO.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.04381v1",
    "published_date": "2024-07-05 09:35:30 UTC",
    "updated_date": "2024-07-05 09:35:30 UTC"
  },
  {
    "arxiv_id": "2407.04377v1",
    "title": "A systematic review on expert systems for improving energy efficiency in the manufacturing industry",
    "authors": [
      "Borys Ioshchikhes",
      "Michael Frank",
      "Matthias Weigold"
    ],
    "abstract": "Against the backdrop of the European Union's commitment to achieve climate\nneutrality by 2050, efforts to improve energy efficiency are being intensified.\nThe manufacturing industry is a key focal point of these endeavors due to its\nhigh final electrical energy demand, while simultaneously facing a growing\nshortage of skilled workers crucial for meeting established goals. Expert\nsystems (ESs) offer the chance to overcome this challenge by automatically\nidentifying potential energy efficiency improvements and thereby playing a\nsignificant role in reducing electricity consumption. This paper systematically\nreviews state-of-the-art approaches of ESs aimed at improving energy efficiency\nin industry, with a focus on manufacturing. The literature search yields 1692\nresults, of which 54 articles published between 1987 and 2023 are analyzed in\ndepth. These publications are classified according to the system boundary,\nmanufacturing type, application perspective, application purpose, ES type, and\nindustry. Furthermore, we examine the structure, implementation, utilization,\nand development of ESs in this context. Through this analysis, the review\nreveals research gaps, pointing toward promising topics for future research.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "23 pages, 7 figures, journal",
    "pdf_url": "http://arxiv.org/pdf/2407.04377v1",
    "published_date": "2024-07-05 09:28:31 UTC",
    "updated_date": "2024-07-05 09:28:31 UTC"
  },
  {
    "arxiv_id": "2407.12847v1",
    "title": "Aligning Model Evaluations with Human Preferences: Mitigating Token Count Bias in Language Model Assessments",
    "authors": [
      "Roland Daynauth",
      "Jason Mars"
    ],
    "abstract": "The SLAM paper demonstrated that on-device Small Language Models (SLMs) are a\nviable and cost-effective alternative to API-based Large Language Models\n(LLMs), such as OpenAI's GPT-4, offering comparable performance and stability.\nHowever, SLAM also identified discrepancies between human preferences and\ntraditional auto-evaluators. This follow-up paper explores methods to align LLM\nevaluator preferences with human evaluations by addressing biases, particularly\ntoward higher token counts. We employed Bayesian statistics and a t-test to\nquantify this bias and developed a recalibration procedure to adjust the\nGPTScorer. Our findings significantly improve aligning the recalibrated LLM\nevaluator with human evaluations across multiple use cases. For instance,\nspearman's ranking correlation score in the Recommendation use case improved\nfrom -27.27 to 44.55. These results highlight the importance of accounting for\nbiases in automated evaluations to ensure fair and accurate model assessments.\nThe recalibration process enhances the reliability of automated evaluators,\nleading to better AI models that align with human values and expectations. This\nstudy provides a robust methodology for future research into bias correction\nand emphasizes the feasibility and benefits of developing human-aligned AI\nevaluation systems.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.12847v1",
    "published_date": "2024-07-05 09:26:40 UTC",
    "updated_date": "2024-07-05 09:26:40 UTC"
  },
  {
    "arxiv_id": "2407.04371v1",
    "title": "Exploiting the equivalence between quantum neural networks and perceptrons",
    "authors": [
      "Chris Mingard",
      "Jessica Pointing",
      "Charles London",
      "Yoonsoo Nam",
      "Ard A. Louis"
    ],
    "abstract": "Quantum machine learning models based on parametrized quantum circuits, also\ncalled quantum neural networks (QNNs), are considered to be among the most\npromising candidates for applications on near-term quantum devices. Here we\nexplore the expressivity and inductive bias of QNNs by exploiting an exact\nmapping from QNNs with inputs $x$ to classical perceptrons acting on $x \\otimes\nx$ (generalised to complex inputs). The simplicity of the perceptron\narchitecture allows us to provide clear examples of the shortcomings of current\nQNN models, and the many barriers they face to becoming useful general-purpose\nlearning algorithms. For example, a QNN with amplitude encoding cannot express\nthe Boolean parity function for $n\\geq 3$, which is but one of an exponential\nnumber of data structures that such a QNN is unable to express. Mapping a QNN\nto a classical perceptron simplifies training, allowing us to systematically\nstudy the inductive biases of other, more expressive embeddings on Boolean\ndata. Several popular embeddings primarily produce an inductive bias towards\nfunctions with low class balance, reducing their generalisation performance\ncompared to deep neural network architectures which exhibit much richer\ninductive biases. We explore two alternate strategies that move beyond standard\nQNNs. In the first, we use a QNN to help generate a classical DNN-inspired\nkernel. In the second we draw an analogy to the hierarchical structure of deep\nneural networks and construct a layered non-linear QNN that is provably fully\nexpressive on Boolean data, while also exhibiting a richer inductive bias than\nsimple QNNs. Finally, we discuss characteristics of the QNN literature that may\nobscure how hard it is to achieve quantum advantage over deep learning\nalgorithms on classical data.",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "primary_category": "quant-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.04371v1",
    "published_date": "2024-07-05 09:19:58 UTC",
    "updated_date": "2024-07-05 09:19:58 UTC"
  },
  {
    "arxiv_id": "2407.04370v2",
    "title": "Regulating Model Reliance on Non-Robust Features by Smoothing Input Marginal Density",
    "authors": [
      "Peiyu Yang",
      "Naveed Akhtar",
      "Mubarak Shah",
      "Ajmal Mian"
    ],
    "abstract": "Trustworthy machine learning necessitates meticulous regulation of model\nreliance on non-robust features. We propose a framework to delineate and\nregulate such features by attributing model predictions to the input. Within\nour approach, robust feature attributions exhibit a certain consistency, while\nnon-robust feature attributions are susceptible to fluctuations. This behavior\nallows identification of correlation between model reliance on non-robust\nfeatures and smoothness of marginal density of the input samples. Hence, we\nuniquely regularize the gradients of the marginal density w.r.t. the input\nfeatures for robustness. We also devise an efficient implementation of our\nregularization to address the potential numerical instability of the underlying\noptimization process. Moreover, we analytically reveal that, as opposed to our\nmarginal density smoothing, the prevalent input gradient regularization\nsmoothens conditional or joint density of the input, which can cause limited\nrobustness. Our experiments validate the effectiveness of the proposed method,\nproviding clear evidence of its capability to address the feature leakage\nproblem and mitigate spurious correlations. Extensive results further establish\nthat our technique enables the model to exhibit robustness against\nperturbations in pixel values, input gradients, and density.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.04370v2",
    "published_date": "2024-07-05 09:16:56 UTC",
    "updated_date": "2024-07-09 03:09:41 UTC"
  },
  {
    "arxiv_id": "2407.04363v3",
    "title": "AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents",
    "authors": [
      "Petr Anokhin",
      "Nikita Semenov",
      "Artyom Sorokin",
      "Dmitry Evseev",
      "Andrey Kravchenko",
      "Mikhail Burtsev",
      "Evgeny Burnaev"
    ],
    "abstract": "Advancements in the capabilities of Large Language Models (LLMs) have created\na promising foundation for developing autonomous agents. With the right tools,\nthese agents could learn to solve tasks in new environments by accumulating and\nupdating their knowledge. Current LLM-based agents process past experiences\nusing a full history of observations, summarization, retrieval augmentation.\nHowever, these unstructured memory representations do not facilitate the\nreasoning and planning essential for complex decision-making. In our study, we\nintroduce AriGraph, a novel method wherein the agent constructs and updates a\nmemory graph that integrates semantic and episodic memories while exploring the\nenvironment. We demonstrate that our Ariadne LLM agent, consisting of the\nproposed memory architecture augmented with planning and decision-making,\neffectively handles complex tasks within interactive text game environments\ndifficult even for human players. Results show that our approach markedly\noutperforms other established memory methods and strong RL baselines in a range\nof problems of varying complexity. Additionally, AriGraph demonstrates\ncompetitive performance compared to dedicated knowledge graph-based methods in\nstatic multi-hop question-answering.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Code for this work is avaliable at\n  https://github.com/AIRI-Institute/AriGraph",
    "pdf_url": "http://arxiv.org/pdf/2407.04363v3",
    "published_date": "2024-07-05 09:06:47 UTC",
    "updated_date": "2025-05-15 10:57:51 UTC"
  },
  {
    "arxiv_id": "2407.04359v1",
    "title": "Dance of the ADS: Orchestrating Failures through Historically-Informed Scenario Fuzzing",
    "authors": [
      "Tong Wang",
      "Taotao Gu",
      "Huan Deng",
      "Hu Li",
      "Xiaohui Kuang",
      "Gang Zhao"
    ],
    "abstract": "As autonomous driving systems (ADS) advance towards higher levels of\nautonomy, orchestrating their safety verification becomes increasingly\nintricate. This paper unveils ScenarioFuzz, a pioneering scenario-based fuzz\ntesting methodology. Designed like a choreographer who understands the past\nperformances, it uncovers vulnerabilities in ADS without the crutch of\npredefined scenarios. Leveraging map road networks, such as OPENDRIVE, we\nextract essential data to form a foundational scenario seed corpus. This\ncorpus, enriched with pertinent information, provides the necessary boundaries\nfor fuzz testing in the absence of starting scenarios. Our approach integrates\nspecialized mutators and mutation techniques, combined with a graph neural\nnetwork model, to predict and filter out high-risk scenario seeds, optimizing\nthe fuzzing process using historical test data. Compared to other methods, our\napproach reduces the time cost by an average of 60.3%, while the number of\nerror scenarios discovered per unit of time increases by 103%. Furthermore, we\npropose a self-supervised collision trajectory clustering method, which aids in\nidentifying and summarizing 54 high-risk scenario categories prone to inducing\nADS faults. Our experiments have successfully uncovered 58 bugs across six\ntested systems, emphasizing the critical safety concerns of ADS.",
    "categories": [
      "cs.AI",
      "cs.NE",
      "cs.SE",
      "68Txx (Primary)",
      "D.2.4; I.2.9; I.6.7"
    ],
    "primary_category": "cs.AI",
    "comment": "This paper was accepted by 33rd ACM SIGSOFT International Symposium\n  on Software Testing and Analysis (ISSTA 2024)",
    "pdf_url": "http://arxiv.org/pdf/2407.04359v1",
    "published_date": "2024-07-05 08:58:09 UTC",
    "updated_date": "2024-07-05 08:58:09 UTC"
  },
  {
    "arxiv_id": "2407.04336v2",
    "title": "AI-Driven Mobility Management for High-Speed Railway Communications: Compressed Measurements and Proactive Handover",
    "authors": [
      "Wen Li",
      "Wei Chen",
      "Shiyue Wang",
      "Yuanyuan Zhang",
      "Michail Matthaiou",
      "Bo Ai"
    ],
    "abstract": "High-speed railway (HSR) communications are pivotal for ensuring rail safety,\noperations, maintenance, and delivering passenger information services. The\nhigh speed of trains creates rapidly time-varying wireless channels, increases\nthe signaling overhead, and reduces the system throughput, making it difficult\nto meet the growing and stringent needs of HSR applications. In this article,\nwe explore artificial intelligence (AI)-based beam-level and cell-level\nmobility management suitable for HSR communications. Particularly, we propose a\ncompressed spatial multi-beam measurements scheme via compressive sensing for\nbeam-level mobility management in HSR communications. In comparison to\ntraditional down-sampling spatial beam measurements, this method leads to\nimproved spatial-temporal beam prediction accuracy with the same measurement\noverhead. Moreover, we propose a novel AI-based proactive handover scheme to\npredict handover events and reduce radio link failure (RLF) rates in HSR\ncommunications. Compared with the traditional event A3-based handover\nmechanism, the proposed approach significantly reduces the RLF rates which\nsaves 50% beam measurement overhead.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.04336v2",
    "published_date": "2024-07-05 08:23:13 UTC",
    "updated_date": "2024-12-19 05:40:36 UTC"
  },
  {
    "arxiv_id": "2407.04335v1",
    "title": "Geometrically Inspired Kernel Machines for Collaborative Learning Beyond Gradient Descent",
    "authors": [
      "Mohit Kumar",
      "Alexander Valentinitsch",
      "Magdalena Fuchs",
      "Mathias Brucker",
      "Juliana Bowles",
      "Adnan Husakovic",
      "Ali Abbas",
      "Bernhard A. Moser"
    ],
    "abstract": "This paper develops a novel mathematical framework for collaborative learning\nby means of geometrically inspired kernel machines which includes statements on\nthe bounds of generalisation and approximation errors, and sample complexity.\nFor classification problems, this approach allows us to learn bounded geometric\nstructures around given data points and hence solve the global model learning\nproblem in an efficient way by exploiting convexity properties of the related\noptimisation problem in a Reproducing Kernel Hilbert Space (RKHS). In this way,\nwe can reduce classification problems to determining the closest bounded\ngeometric structure from a given data point. Further advantages that come with\nour solution is that our approach does not require clients to perform multiple\nepochs of local optimisation using stochastic gradient descent, nor require\nrounds of communication between client/server for optimising the global model.\nWe highlight that numerous experiments have shown that the proposed method is a\ncompetitive alternative to the state-of-the-art.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.04335v1",
    "published_date": "2024-07-05 08:20:27 UTC",
    "updated_date": "2024-07-05 08:20:27 UTC"
  },
  {
    "arxiv_id": "2407.04751v2",
    "title": "A Unified Learn-to-Distort-Data Framework for Privacy-Utility Trade-off in Trustworthy Federated Learning",
    "authors": [
      "Xiaojin Zhang",
      "Mingcong Xu",
      "Wei Chen"
    ],
    "abstract": "In this paper, we first give an introduction to the theoretical basis of the\nprivacy-utility equilibrium in federated learning based on Bayesian privacy\ndefinitions and total variation distance privacy definitions. We then present\nthe \\textit{Learn-to-Distort-Data} framework, which provides a principled\napproach to navigate the privacy-utility equilibrium by explicitly modeling the\ndistortion introduced by the privacy-preserving mechanism as a learnable\nvariable and optimizing it jointly with the model parameters. We demonstrate\nthe applicability of our framework to a variety of privacy-preserving\nmechanisms on the basis of data distortion and highlight its connections to\nrelated areas such as adversarial training, input robustness, and unlearnable\nexamples. These connections enable leveraging techniques from these areas to\ndesign effective algorithms for privacy-utility equilibrium in federated\nlearning under the \\textit{Learn-to-Distort-Data} framework.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.04751v2",
    "published_date": "2024-07-05 08:15:09 UTC",
    "updated_date": "2024-07-09 16:11:04 UTC"
  },
  {
    "arxiv_id": "2407.04331v1",
    "title": "MuseBarControl: Enhancing Fine-Grained Control in Symbolic Music Generation through Pre-Training and Counterfactual Loss",
    "authors": [
      "Yangyang Shu",
      "Haiming Xu",
      "Ziqin Zhou",
      "Anton van den Hengel",
      "Lingqiao Liu"
    ],
    "abstract": "Automatically generating symbolic music-music scores tailored to specific\nhuman needs-can be highly beneficial for musicians and enthusiasts. Recent\nstudies have shown promising results using extensive datasets and advanced\ntransformer architectures. However, these state-of-the-art models generally\noffer only basic control over aspects like tempo and style for the entire\ncomposition, lacking the ability to manage finer details, such as control at\nthe level of individual bars. While fine-tuning a pre-trained symbolic music\ngeneration model might seem like a straightforward method for achieving this\nfiner control, our research indicates challenges in this approach. The model\noften fails to respond adequately to new, fine-grained bar-level control\nsignals. To address this, we propose two innovative solutions. First, we\nintroduce a pre-training task designed to link control signals directly with\ncorresponding musical tokens, which helps in achieving a more effective\ninitialization for subsequent fine-tuning. Second, we implement a novel\ncounterfactual loss that promotes better alignment between the generated music\nand the control prompts. Together, these techniques significantly enhance our\nability to control music generation at the bar level, showing a 13.06\\%\nimprovement over conventional methods. Our subjective evaluations also confirm\nthat this enhanced control does not compromise the musical quality of the\noriginal pre-trained generative model.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Demo is available at:\n  https://ganperf.github.io/musebarcontrol.github.io/musebarcontrol/",
    "pdf_url": "http://arxiv.org/pdf/2407.04331v1",
    "published_date": "2024-07-05 08:08:22 UTC",
    "updated_date": "2024-07-05 08:08:22 UTC"
  },
  {
    "arxiv_id": "2407.04317v2",
    "title": "Knowledge-based Drug Samples' Comparison",
    "authors": [
      "Sébastien Guillemin",
      "Ana Roxin",
      "Laurence Dujourdy",
      "Ludovic Journaux"
    ],
    "abstract": "Drug sample comparison is a process used by the French National police to\nidentify drug distribution networks. The current approach is based on manual\ncomparison done by forensic experts. In this article, we present our approach\nto acquire, formalise, and specify expert knowledge to improve the current\nprocess. For modelling the underlying knowledge we use an ontology coupled with\nlogical rules. The different steps of our approach are designed to be reused in\nother application domains. The results obtained are explainable making them\nusable by experts in different fields.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "17th International Conference on Signal Image Technology & Internet\n  based Systems (SITIS), Nov 2023, Bangkok, Thailand",
    "pdf_url": "http://arxiv.org/pdf/2407.04317v2",
    "published_date": "2024-07-05 07:40:25 UTC",
    "updated_date": "2024-07-16 07:16:17 UTC"
  },
  {
    "arxiv_id": "2407.04295v2",
    "title": "Jailbreak Attacks and Defenses Against Large Language Models: A Survey",
    "authors": [
      "Sibo Yi",
      "Yule Liu",
      "Zhen Sun",
      "Tianshuo Cong",
      "Xinlei He",
      "Jiaxing Song",
      "Ke Xu",
      "Qi Li"
    ],
    "abstract": "Large Language Models (LLMs) have performed exceptionally in various\ntext-generative tasks, including question answering, translation, code\ncompletion, etc. However, the over-assistance of LLMs has raised the challenge\nof \"jailbreaking\", which induces the model to generate malicious responses\nagainst the usage policy and society by designing adversarial prompts. With the\nemergence of jailbreak attack methods exploiting different vulnerabilities in\nLLMs, the corresponding safety alignment measures are also evolving. In this\npaper, we propose a comprehensive and detailed taxonomy of jailbreak attack and\ndefense methods. For instance, the attack methods are divided into black-box\nand white-box attacks based on the transparency of the target model. Meanwhile,\nwe classify defense methods into prompt-level and model-level defenses.\nAdditionally, we further subdivide these attack and defense methods into\ndistinct sub-classes and present a coherent diagram illustrating their\nrelationships. We also conduct an investigation into the current evaluation\nmethods and compare them from different perspectives. Our findings aim to\ninspire future research and practical implementations in safeguarding LLMs\nagainst adversarial attacks. Above all, although jailbreak remains a\nsignificant concern within the community, we believe that our work enhances the\nunderstanding of this domain and provides a foundation for developing more\nsecure LLMs.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.04295v2",
    "published_date": "2024-07-05 06:57:30 UTC",
    "updated_date": "2024-08-30 11:57:47 UTC"
  },
  {
    "arxiv_id": "2407.04287v1",
    "title": "MARS: Paying more attention to visual attributes for text-based person search",
    "authors": [
      "Alex Ergasti",
      "Tomaso Fontanini",
      "Claudio Ferrari",
      "Massimo Bertozzi",
      "Andrea Prati"
    ],
    "abstract": "Text-based person search (TBPS) is a problem that gained significant interest\nwithin the research community. The task is that of retrieving one or more\nimages of a specific individual based on a textual description. The multi-modal\nnature of the task requires learning representations that bridge text and image\ndata within a shared latent space. Existing TBPS systems face two major\nchallenges. One is defined as inter-identity noise that is due to the inherent\nvagueness and imprecision of text descriptions and it indicates how\ndescriptions of visual attributes can be generally associated to different\npeople; the other is the intra-identity variations, which are all those\nnuisances e.g. pose, illumination, that can alter the visual appearance of the\nsame textual attributes for a given subject. To address these issues, this\npaper presents a novel TBPS architecture named MARS\n(Mae-Attribute-Relation-Sensitive), which enhances current state-of-the-art\nmodels by introducing two key components: a Visual Reconstruction Loss and an\nAttribute Loss. The former employs a Masked AutoEncoder trained to reconstruct\nrandomly masked image patches with the aid of the textual description. In doing\nso the model is encouraged to learn more expressive representations and\ntextual-visual relations in the latent space. The Attribute Loss, instead,\nbalances the contribution of different types of attributes, defined as\nadjective-noun chunks of text. This loss ensures that every attribute is taken\ninto consideration in the person retrieval process. Extensive experiments on\nthree commonly used datasets, namely CUHK-PEDES, ICFG-PEDES, and RSTPReid,\nreport performance improvements, with significant gains in the mean Average\nPrecision (mAP) metric w.r.t. the current state of the art.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.04287v1",
    "published_date": "2024-07-05 06:44:43 UTC",
    "updated_date": "2024-07-05 06:44:43 UTC"
  },
  {
    "arxiv_id": "2407.04285v4",
    "title": "Tackling Data Corruption in Offline Reinforcement Learning via Sequence Modeling",
    "authors": [
      "Jiawei Xu",
      "Rui Yang",
      "Shuang Qiu",
      "Feng Luo",
      "Meng Fang",
      "Baoxiang Wang",
      "Lei Han"
    ],
    "abstract": "Learning policy from offline datasets through offline reinforcement learning\n(RL) holds promise for scaling data-driven decision-making while avoiding\nunsafe and costly online interactions. However, real-world data collected from\nsensors or humans often contains noise and errors, posing a significant\nchallenge for existing offline RL methods, particularly when the real-world\ndata is limited. Our study reveals that prior research focusing on adapting\npredominant offline RL methods based on temporal difference learning still\nfalls short under data corruption when the dataset is limited. In contrast, we\ndiscover that vanilla sequence modeling methods, such as Decision Transformer,\nexhibit robustness against data corruption, even without specialized\nmodifications. To unlock the full potential of sequence modeling, we propose\nRobust Decision Rransformer (RDT) by incorporating three simple yet effective\nrobust techniques: embedding dropout to improve the model's robustness against\nerroneous inputs, Gaussian weighted learning to mitigate the effects of\ncorrupted labels, and iterative data correction to eliminate corrupted data\nfrom the source. Extensive experiments on MuJoCo, Kitchen, and Adroit tasks\ndemonstrate RDT's superior performance under various data corruption scenarios\ncompared to prior methods. Furthermore, RDT exhibits remarkable robustness in a\nmore challenging setting that combines training-time data corruption with\ntest-time observation perturbations. These results highlight the potential of\nsequence modeling for learning from noisy or corrupted offline datasets,\nthereby promoting the reliable application of offline RL in real-world\nscenarios. Our code is available at\nhttps://github.com/jiawei415/RobustDecisionTransformer.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by ICLR2025",
    "pdf_url": "http://arxiv.org/pdf/2407.04285v4",
    "published_date": "2024-07-05 06:34:32 UTC",
    "updated_date": "2025-03-02 08:28:00 UTC"
  },
  {
    "arxiv_id": "2407.04271v1",
    "title": "Variational Partial Group Convolutions for Input-Aware Partial Equivariance of Rotations and Color-Shifts",
    "authors": [
      "Hyunsu Kim",
      "Yegon Kim",
      "Hongseok Yang",
      "Juho Lee"
    ],
    "abstract": "Group Equivariant CNNs (G-CNNs) have shown promising efficacy in various\ntasks, owing to their ability to capture hierarchical features in an\nequivariant manner. However, their equivariance is fixed to the symmetry of the\nwhole group, limiting adaptability to diverse partial symmetries in real-world\ndatasets, such as limited rotation symmetry of handwritten digit images and\nlimited color-shift symmetry of flower images. Recent efforts address this\nlimitation, one example being Partial G-CNN which restricts the output group\nspace of convolution layers to break full equivariance. However, such an\napproach still fails to adjust equivariance levels across data. In this paper,\nwe propose a novel approach, Variational Partial G-CNN (VP G-CNN), to capture\nvarying levels of partial equivariance specific to each data instance. VP G-CNN\nredesigns the distribution of the output group elements to be conditioned on\ninput data, leveraging variational inference to avoid overfitting. This enables\nthe model to adjust its equivariance levels according to the needs of\nindividual data points. Additionally, we address training instability inherent\nin discrete group equivariance models by redesigning the reparametrizable\ndistribution. We demonstrate the effectiveness of VP G-CNN on both toy and\nreal-world datasets, including MNIST67-180, CIFAR10, ColorMNIST, and\nFlowers102. Our results show robust performance, even in uncertainty metrics.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "ICML2024",
    "pdf_url": "http://arxiv.org/pdf/2407.04271v1",
    "published_date": "2024-07-05 05:52:51 UTC",
    "updated_date": "2024-07-05 05:52:51 UTC"
  },
  {
    "arxiv_id": "2407.04268v3",
    "title": "NeuFair: Neural Network Fairness Repair with Dropout",
    "authors": [
      "Vishnu Asutosh Dasu",
      "Ashish Kumar",
      "Saeid Tizpaz-Niari",
      "Gang Tan"
    ],
    "abstract": "This paper investigates neuron dropout as a post-processing bias mitigation\nfor deep neural networks (DNNs). Neural-driven software solutions are\nincreasingly applied in socially critical domains with significant fairness\nimplications. While neural networks are exceptionally good at finding\nstatistical patterns from data, they may encode and amplify existing biases\nfrom the historical data. Existing bias mitigation algorithms often require\nmodifying the input dataset or the learning algorithms. We posit that the\nprevalent dropout methods that prevent over-fitting during training by randomly\ndropping neurons may be an effective and less intrusive approach to improve the\nfairness of pre-trained DNNs. However, finding the ideal set of neurons to drop\nis a combinatorial problem. We propose NeuFair, a family of post-processing\nrandomized algorithms that mitigate unfairness in pre-trained DNNs via dropouts\nduring inference after training. Our randomized search is guided by an\nobjective to minimize discrimination while maintaining the model's utility. We\nshow that our design of randomized algorithms is effective and efficient in\nimproving fairness (up to 69%) with minimal or no model performance\ndegradation. We provide intuitive explanations of these phenomena and carefully\nexamine the influence of various hyperparameters of search algorithms on the\nresults. Finally, we empirically and conceptually compare NeuFair to different\nstate-of-the-art bias mitigators.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.LG",
    "comment": "Paper accepted at ACM ISSTA 2024",
    "pdf_url": "http://arxiv.org/pdf/2407.04268v3",
    "published_date": "2024-07-05 05:45:34 UTC",
    "updated_date": "2024-09-02 17:13:22 UTC"
  },
  {
    "arxiv_id": "2407.04259v2",
    "title": "Robust Q-Learning for finite ambiguity sets",
    "authors": [
      "Cécile Decker",
      "Julian Sester"
    ],
    "abstract": "In this paper we propose a novel $Q$-learning algorithm allowing to solve\ndistributionally robust Markov decision problems for which the ambiguity set of\nprobability measures can be chosen arbitrarily as long as it comprises only a\nfinite amount of measures. Therefore, our approach goes beyond the well-studied\ncases involving ambiguity sets of balls around some reference measure with the\ndistance to reference measure being measured with respect to the Wasserstein\ndistance or the Kullback--Leibler divergence. Hence, our approach allows the\napplicant to create ambiguity sets better tailored to her needs and to solve\nthe associated robust Markov decision problem via a $Q$-learning algorithm\nwhose convergence is guaranteed by our main result. Moreover, we showcase in\nseveral numerical experiments the tractability of our approach.",
    "categories": [
      "math.OC",
      "cs.AI",
      "cs.LG",
      "math.PR"
    ],
    "primary_category": "math.OC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.04259v2",
    "published_date": "2024-07-05 05:19:36 UTC",
    "updated_date": "2025-02-16 03:16:16 UTC"
  },
  {
    "arxiv_id": "2407.04258v1",
    "title": "Unsupervised Video Summarization via Reinforcement Learning and a Trained Evaluator",
    "authors": [
      "Mehryar Abbasi",
      "Hadi Hadizadeh",
      "Parvaneh Saeedi"
    ],
    "abstract": "This paper presents a novel approach for unsupervised video summarization\nusing reinforcement learning. It aims to address the existing limitations of\ncurrent unsupervised methods, including unstable training of adversarial\ngenerator-discriminator architectures and reliance on hand-crafted reward\nfunctions for quality evaluation. The proposed method is based on the concept\nthat a concise and informative summary should result in a reconstructed video\nthat closely resembles the original. The summarizer model assigns an importance\nscore to each frame and generates a video summary. In the proposed scheme,\nreinforcement learning, coupled with a unique reward generation pipeline, is\nemployed to train the summarizer model. The reward generation pipeline trains\nthe summarizer to create summaries that lead to improved reconstructions. It\ncomprises a generator model capable of reconstructing masked frames from a\npartially masked video, along with a reward mechanism that compares the\nreconstructed video from the summary against the original. The video generator\nis trained in a self-supervised manner to reconstruct randomly masked frames,\nenhancing its ability to generate accurate summaries. This training pipeline\nresults in a summarizer model that better mimics human-generated video\nsummaries compared to methods relying on hand-crafted rewards. The training\nprocess consists of two stable and isolated training steps, unlike adversarial\narchitectures. Experimental results demonstrate promising performance, with\nF-scores of 62.3 and 54.5 on TVSum and SumMe datasets, respectively.\nAdditionally, the inference stage is 300 times faster than our previously\nreported state-of-the-art method.",
    "categories": [
      "cs.MM",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.MM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.04258v1",
    "published_date": "2024-07-05 05:08:06 UTC",
    "updated_date": "2024-07-05 05:08:06 UTC"
  },
  {
    "arxiv_id": "2407.04247v1",
    "title": "ArAIEval Shared Task: Propagandistic Techniques Detection in Unimodal and Multimodal Arabic Content",
    "authors": [
      "Maram Hasanain",
      "Md. Arid Hasan",
      "Fatema Ahmed",
      "Reem Suwaileh",
      "Md. Rafiul Biswas",
      "Wajdi Zaghouani",
      "Firoj Alam"
    ],
    "abstract": "We present an overview of the second edition of the ArAIEval shared task,\norganized as part of the ArabicNLP 2024 conference co-located with ACL 2024. In\nthis edition, ArAIEval offers two tasks: (i) detection of propagandistic\ntextual spans with persuasion techniques identification in tweets and news\narticles, and (ii) distinguishing between propagandistic and non-propagandistic\nmemes. A total of 14 teams participated in the final evaluation phase, with 6\nand 9 teams participating in Tasks 1 and 2, respectively. Finally, 11 teams\nsubmitted system description papers. Across both tasks, we observed that\nfine-tuning transformer models such as AraBERT was at the core of the majority\nof the participating systems. We provide a description of the task setup,\nincluding a description of the dataset construction and the evaluation setup.\nWe further provide a brief overview of the participating systems. All datasets\nand evaluation scripts are released to the research community\n(https://araieval.gitlab.io/). We hope this will enable further research on\nthese important tasks in Arabic.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "68T50",
      "F.2.2; I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "propaganda, span detection, disinformation, misinformation, fake\n  news, LLMs, GPT-4, multimodality, multimodal LLMs",
    "pdf_url": "http://arxiv.org/pdf/2407.04247v1",
    "published_date": "2024-07-05 04:28:46 UTC",
    "updated_date": "2024-07-05 04:28:46 UTC"
  },
  {
    "arxiv_id": "2407.04241v2",
    "title": "AnySR: Realizing Image Super-Resolution as Any-Scale, Any-Resource",
    "authors": [
      "Wengyi Zhan",
      "Mingbao Lin",
      "Chia-Wen Lin",
      "Rongrong Ji"
    ],
    "abstract": "In an effort to improve the efficiency and scalability of single-image\nsuper-resolution (SISR) applications, we introduce AnySR, to rebuild existing\narbitrary-scale SR methods into any-scale, any-resource implementation. As a\ncontrast to off-the-shelf methods that solve SR tasks across various scales\nwith the same computing costs, our AnySR innovates in: 1) building\narbitrary-scale tasks as any-resource implementation, reducing resource\nrequirements for smaller scales without additional parameters; 2) enhancing\nany-scale performance in a feature-interweaving fashion, inserting scale pairs\ninto features at regular intervals and ensuring correct feature/scale\nprocessing. The efficacy of our AnySR is fully demonstrated by rebuilding most\nexisting arbitrary-scale SISR methods and validating on five popular SISR test\ndatasets. The results show that our AnySR implements SISR tasks in a\ncomputing-more-efficient fashion, and performs on par with existing\narbitrary-scale SISR methods. For the first time, we realize SISR tasks as not\nonly any-scale in literature, but also as any-resource. Code is available at\nhttps://github.com/CrispyFeSo4/AnySR.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.04241v2",
    "published_date": "2024-07-05 04:00:14 UTC",
    "updated_date": "2024-10-10 14:10:22 UTC"
  },
  {
    "arxiv_id": "2407.04221v2",
    "title": "Autoverse: An Evolvable Game Language for Learning Robust Embodied Agents",
    "authors": [
      "Sam Earle",
      "Julian Togelius"
    ],
    "abstract": "We introduce Autoverse, an evolvable, domain-specific language for\nsingle-player 2D grid-based games, and demonstrate its use as a scalable\ntraining ground for Open-Ended Learning (OEL) algorithms. Autoverse uses\ncellular-automaton-like rewrite rules to describe game mechanics, allowing it\nto express various game environments (e.g. mazes, dungeons, sokoban puzzles)\nthat are popular testbeds for Reinforcement Learning (RL) agents. Each rewrite\nrule can be expressed as a series of simple convolutions, allowing for\nenvironments to be parallelized on the GPU, thereby drastically accelerating RL\ntraining. Using Autoverse, we propose jump-starting open-ended learning by\nimitation learning from search. In such an approach, we first evolve Autoverse\nenvironments (their rules and initial map topology) to maximize the number of\niterations required by greedy tree search to discover a new best solution,\nproducing a curriculum of increasingly complex environments and playtraces. We\nthen distill these expert playtraces into a neural-network-based policy using\nimitation learning. Finally, we use the learned policy as a starting point for\nopen-ended RL, where new training environments are continually evolved to\nmaximize the RL player agent's value function error (a proxy for its regret, or\nthe learnability of generated environments), finding that this approach\nimproves the performance and generality of resultant player agents.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2407.04221v2",
    "published_date": "2024-07-05 02:18:02 UTC",
    "updated_date": "2024-08-06 09:39:14 UTC"
  },
  {
    "arxiv_id": "2407.04218v1",
    "title": "Batch Transformer: Look for Attention in Batch",
    "authors": [
      "Myung Beom Her",
      "Jisu Jeong",
      "Hojoon Song",
      "Ji-Hyeong Han"
    ],
    "abstract": "Facial expression recognition (FER) has received considerable attention in\ncomputer vision, with \"in-the-wild\" environments such as human-computer\ninteraction. However, FER images contain uncertainties such as occlusion, low\nresolution, pose variation, illumination variation, and subjectivity, which\nincludes some expressions that do not match the target label. Consequently,\nlittle information is obtained from a noisy single image and it is not trusted.\nThis could significantly degrade the performance of the FER task. To address\nthis issue, we propose a batch transformer (BT), which consists of the proposed\nclass batch attention (CBA) module, to prevent overfitting in noisy data and\nextract trustworthy information by training on features reflected from several\nimages in a batch, rather than information from a single image. We also propose\nmulti-level attention (MLA) to prevent overfitting the specific features by\ncapturing correlations between each level. In this paper, we present a batch\ntransformer network (BTN) that combines the above proposals. Experimental\nresults on various FER benchmark datasets show that the proposed BTN\nconsistently outperforms the state-ofthe-art in FER datasets. Representative\nresults demonstrate the promise of the proposed BTN for FER.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2407.04218v1",
    "published_date": "2024-07-05 02:13:47 UTC",
    "updated_date": "2024-07-05 02:13:47 UTC"
  },
  {
    "arxiv_id": "2407.04212v1",
    "title": "Smart Vision-Language Reasoners",
    "authors": [
      "Denisa Roberts",
      "Lucas Roberts"
    ],
    "abstract": "In this article, we investigate vision-language models (VLM) as reasoners.\nThe ability to form abstractions underlies mathematical reasoning,\nproblem-solving, and other Math AI tasks. Several formalisms have been given to\nthese underlying abstractions and skills utilized by humans and intelligent\nsystems for reasoning. Furthermore, human reasoning is inherently multimodal,\nand as such, we focus our investigations on multimodal AI. In this article, we\nemploy the abstractions given in the SMART task (Simple Multimodal Algorithmic\nReasoning Task) introduced in \\cite{cherian2022deep} as meta-reasoning and\nproblem-solving skills along eight axes: math, counting, path, measure, logic,\nspatial, and pattern. We investigate the ability of vision-language models to\nreason along these axes and seek avenues of improvement. Including composite\nrepresentations with vision-language cross-attention enabled learning\nmultimodal representations adaptively from fused frozen pretrained backbones\nfor better visual grounding. Furthermore, proper hyperparameter and other\ntraining choices led to strong improvements (up to $48\\%$ gain in accuracy) on\nthe SMART task, further underscoring the power of deep multimodal learning. The\nsmartest VLM, which includes a novel QF multimodal layer, improves upon the\nbest previous baselines in every one of the eight fundamental reasoning skills.\nEnd-to-end code is available at https://github.com/smarter-vlm/smarter.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted in ICML 2024 MATH AI Workshop",
    "pdf_url": "http://arxiv.org/pdf/2407.04212v1",
    "published_date": "2024-07-05 01:47:21 UTC",
    "updated_date": "2024-07-05 01:47:21 UTC"
  }
]