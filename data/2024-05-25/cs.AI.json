{
  "date": "2024-05-25",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-05-25 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 62 篇论文，主要聚焦 AI 模型的安全性、生成式 AI 应用（如 LLM 和扩散模型）、强化学习优化，以及量子计算和生物领域的创新。其中，令人印象深刻的包括 ICLR 2025 和 NeurIPS 2024 接受的论文，如扩散模型在 Lie 群上的应用，以及 LLM 在用户兴趣探索和生物知识发现中的实证研究；知名学者如 Ashok K. Goel 的 AI 信任分析也值得关注。\n\n下面，我将挑选并简要讨论重点论文，先从高影响力主题入手（如 AI 安全、LLM 应用和量子计算），再快速掠过其他次要内容。每个条目列出论文标题（中文 + 英文），并突出核心贡献和发现。\n\n### 重点论文讨论\n\n**AI 安全与信任（高话题度主题）**  \n- **Visual-RolePlay: Universal Jailbreak Attack on MultiModal Large Language Models via Role-playing Image Character**（中文：视觉角色扮演：通过角色扮演图像人物的多模态大型语言模型通用越狱攻击）  \n  这篇论文提出了一种新颖的越狱攻击方法，使用角色扮演图像来误导 MLLM 生成恶意响应。核心贡献是利用 LLM 生成高风险角色描述，并通过实验证明其在多模型上的攻击成功率（ASR）比现有方法高 14.3%，揭示了多模态模型的安全漏洞，对 AI 伦理和防护有重要启示。  \n- **Navigating AI Fallibility: Examining People's Reactions and Perceptions of AI after Encountering Personality Misrepresentations**（中文：应对 AI 易错性：探索人们在遇到人格误表征后对 AI 的反应和认知）  \n  作者 Ashok K. Goel 等研究了 AI 在人格推断中的错误如何影响用户信任。关键发现是通过访谈和实验，识别了用户对 AI 的三种认知模式（机器、人或魔术），并证明 AI 素养能缓解信任下降。该工作为设计负责任的 AI 系统提供洞见，具有实际应用价值。\n\n**LLM 和生成模型应用（核心 AI 创新）**  \n- **Trivialized Momentum Facilitates Diffusion Generative Modeling on Lie Groups**（中文：简化动量促进 Lie 群上的扩散生成模型）  \n  这篇 ICLR 2025 接受论文引入了“trivialization”技术，将扩散模型从欧式空间扩展到 Lie 群。核心贡献是设计新动量变量和流形保留积分器，提高了生成效率和保真度（如蛋白质和 RNA 生成），并首次处理高维 Special Orthogonal 和 Unitary 群，代码开源。  \n- **LLMs for User Interest Exploration in Large-scale Recommendation Systems**（中文：大型语言模型用于大规模推荐系统的用户兴趣探索）  \n  作者团队包括 Ed Chi 和 Minmin Chen，提出混合框架结合 LLM 和经典推荐模型。关键发现是通过“兴趣集群”控制探索，用户在亿级平台上兴趣多样性增加 3.5%，显著提升推荐效果，展示了 LLM 在工业应用的潜力。  \n- **Devil's Advocate: Anticipatory Reflection for LLM Agents**（中文：魔鬼代言人：LLM 代理的预见性反思）  \n  该论文设计了 LLM 代理的自省机制，包括预见失败和后置校准。核心贡献是零-shot 方法在 WebArena 任务中成功率达 23.5%，比现有方法高 3.5%，并减少试验次数 45%，为 LLM 代理的鲁棒性提供新路径。  \n- **Learning to Reason via Program Generation, Emulation, and Search**（中文：通过程序生成、仿真和搜索实现推理学习）  \n  NeurIPS 2024 论文提出 CoGEX 框架，使用 LLM 生成伪程序并仿真执行。关键发现是显著改善算法和软推理任务的性能，扩展了代码合成在非算法领域的应用，代码已发布。\n\n**量子计算与异常检测（前沿技术）**  \n- **Qsco: A Quantum Scoring Module for Open-set Supervised Anomaly Detection**（中文：Qsco：用于开集监督异常检测的量子评分模块）  \n  AAAI-25 接受的论文将量子变分电路集成到神经网络中。核心贡献是通过实验证明在八个真实数据集上检测性能优于传统方法，且时间复杂度可控，验证了量子增强异常检测的实用性。\n\n**其他亮点（快速总结）**  \n- **SLoPe: Double-Pruned Sparse Plus Lazy Low-Rank Adapter Pretraining of LLMs**（中文：SLoPe：LLM 的双剪枝稀疏加惰性低秩适配器预训练）  \n  ICLR 2025 论文优化 LLM 预训练，通过双剪枝和低秩适配器加速训练和推理，减少内存使用率达 63%，在 OPT-33B 和 OPT-66B 上性能提升 1.25 倍。  \n- **Time-SSM: Simplifying and Unifying State Space Models for Time Series Forecasting**（中文：Time-SSM：简化并统一状态空间模型用于时间序列预测）  \n  提出动态谱算子框架，构建高效 SSM 模型。核心发现是参数减少 85%，在时间序列预测上超越 Mamba，验证了其泛化能力。\n\n### 次要论文掠过\n其余论文如强化学习优化（e.g., Adaptive $Q$-Network）、图像生成（e.g., N-BVH）、生物应用（e.g., GeneAgent）等虽有贡献，但主题较小众或重复，我仅快速提及：这些工作在各自领域（如故障检测、轨迹优化）提供了新方法，但影响力有限。例如，GeneAgent 使用 LLM 代理提升基因知识发现，但实验结果虽好，实际应用需进一步验证。总计 62 篇中，我优先聚焦以上 8-10 篇核心内容，以控制篇幅。\n\n今天的 arXiv 更新强调 AI 的可靠性和创新应用，建议读者关注 LLM 和量子领域的论文，以捕捉前沿趋势。明日见！",
  "papers": [
    {
      "arxiv_id": "2405.16381v2",
      "title": "Trivialized Momentum Facilitates Diffusion Generative Modeling on Lie Groups",
      "title_zh": "平凡化动量促进李",
      "authors": [
        "Yuchen Zhu",
        "Tianrong Chen",
        "Lingkai Kong",
        "Evangelos A. Theodorou",
        "Molei Tao"
      ],
      "abstract": "The generative modeling of data on manifolds is an important task, for which\ndiffusion models in flat spaces typically need nontrivial adaptations. This\narticle demonstrates how a technique called `trivialization' can transfer the\neffectiveness of diffusion models in Euclidean spaces to Lie groups. In\nparticular, an auxiliary momentum variable was algorithmically introduced to\nhelp transport the position variable between data distribution and a fixed,\neasy-to-sample distribution. Normally, this would incur further difficulty for\nmanifold data because momentum lives in a space that changes with the position.\nHowever, our trivialization technique creates a new momentum variable that\nstays in a simple fixed vector space. This design, together with a manifold\npreserving integrator, simplifies implementation and avoids inaccuracies\ncreated by approximations such as projections to tangent space and manifold,\nwhich were typically used in prior work, hence facilitating generation with\nhigh-fidelity and efficiency. The resulting method achieves state-of-the-art\nperformance on protein and RNA torsion angle generation and sophisticated torus\ndatasets. We also, arguably for the first time, tackle the generation of data\non high-dimensional Special Orthogonal and Unitary groups, the latter essential\nfor quantum problems. Code is available at\nhttps://github.com/yuchen-zhu-zyc/TDM.",
      "tldr_zh": "这篇论文提出了一种名为“trivialization”的技术，将diffusion models从欧式空间扩展到Lie groups上，以简化生成流形数据的建模过程。该方法通过引入一个固定向量空间的辅助动量变量和manifold preserving integrator，避免了传统方法中如投影到切空间的近似误差，从而提升了生成的高保真度和效率。实验结果显示，该方法在蛋白质、RNA扭转角度以及复杂环面数据集上达到了最先进性能，并首次实现了高维Special Orthogonal和Unitary groups的数据生成，这对量子问题等应用具有重要意义。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2405.16381v2",
      "published_date": "2024-05-25 23:53:07 UTC",
      "updated_date": "2025-02-12 00:48:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:51:58.898096"
    },
    {
      "arxiv_id": "2405.16368v2",
      "title": "Qsco: A Quantum Scoring Module for Open-set Supervised Anomaly Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Yifeng Peng",
        "Xinyi Li",
        "Zhiding Liang",
        "Ying Wang"
      ],
      "abstract": "Open set anomaly detection (OSAD) is a crucial task that aims to identify\nabnormal patterns or behaviors in data sets, especially when the anomalies\nobserved during training do not represent all possible classes of anomalies.\nThe recent advances in quantum computing in handling complex data structures\nand improving machine learning models herald a paradigm shift in anomaly\ndetection methodologies. This study proposes a Quantum Scoring Module (Qsco),\nembedding quantum variational circuits into neural networks to enhance the\nmodel's processing capabilities in handling uncertainty and unlabeled data.\nExtensive experiments conducted across eight real-world anomaly detection\ndatasets demonstrate our model's superior performance in detecting anomalies\nacross varied settings and reveal that integrating quantum simulators does not\nresult in prohibitive time complexities. Our study validates the feasibility of\nquantum-enhanced anomaly detection methods in practical applications.",
      "tldr_zh": "这篇论文提出了一种量子评分模块(Qsco)，用于开放集监督异常检测(OSAD)，旨在识别训练数据中未覆盖的异常模式。Qsco通过将量子变分电路嵌入神经网络，提升了模型处理不确定性和未标记数据的能力。实验在八个真实世界数据集上进行，结果显示该模块在各种设置下检测异常的性能优于传统方法，且整合量子模拟器不会导致不可接受的时间复杂度。该研究验证了量子增强异常检测方法在实际应用中的可行性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "The Thirty-Ninth AAAI Conference on Artificial Intelligence (AAAI-25)",
      "pdf_url": "http://arxiv.org/pdf/2405.16368v2",
      "published_date": "2024-05-25 22:37:43 UTC",
      "updated_date": "2024-12-16 18:11:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:52:09.701863"
    },
    {
      "arxiv_id": "2405.16363v2",
      "title": "LLMs for User Interest Exploration in Large-scale Recommendation Systems",
      "title_zh": "LLMs 用于大规模推荐系统中的用户兴趣探索",
      "authors": [
        "Jianling Wang",
        "Haokai Lu",
        "Yifan Liu",
        "He Ma",
        "Yueqi Wang",
        "Yang Gu",
        "Shuzhou Zhang",
        "Ningren Han",
        "Shuchao Bi",
        "Lexi Baugher",
        "Ed Chi",
        "Minmin Chen"
      ],
      "abstract": "Traditional recommendation systems are subject to a strong feedback loop by\nlearning from and reinforcing past user-item interactions, which in turn limits\nthe discovery of novel user interests. To address this, we introduce a hybrid\nhierarchical framework combining Large Language Models (LLMs) and classic\nrecommendation models for user interest exploration. The framework controls the\ninterfacing between the LLMs and the classic recommendation models through\n\"interest clusters\", the granularity of which can be explicitly determined by\nalgorithm designers. It recommends the next novel interests by first\nrepresenting \"interest clusters\" using language, and employs a fine-tuned LLM\nto generate novel interest descriptions that are strictly within these\npredefined clusters. At the low level, it grounds these generated interests to\nan item-level policy by restricting classic recommendation models, in this case\na transformer-based sequence recommender to return items that fall within the\nnovel clusters generated at the high level. We showcase the efficacy of this\napproach on an industrial-scale commercial platform serving billions of users.\nLive experiments show a significant increase in both exploration of novel\ninterests and overall user enjoyment of the platform.",
      "tldr_zh": "本研究针对传统推荐系统的反馈循环问题，该问题导致用户新兴趣难以发现，提出了一种结合Large Language Models (LLMs) 和经典推荐模型的混合层次框架。通过“interest clusters”控制接口，框架先利用LLMs生成严格限定在预定义集群内的novel interest descriptions，然后在低层使用transformer-based sequence recommender将这些兴趣映射到具体物品推荐。实验在工业规模商业平台上验证，结果显示该方法显著提升了新兴趣探索和用户整体满意度。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16363v2",
      "published_date": "2024-05-25 21:57:36 UTC",
      "updated_date": "2024-06-07 18:06:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:52:21.627627"
    },
    {
      "arxiv_id": "2405.16355v1",
      "title": "Navigating AI Fallibility: Examining People's Reactions and Perceptions of AI after Encountering Personality Misrepresentations",
      "title_zh": "翻译失败",
      "authors": [
        "Qiaosi Wang",
        "Chidimma L. Anyi",
        "Vedant Das Swain",
        "Ashok K. Goel"
      ],
      "abstract": "Many hyper-personalized AI systems profile people's characteristics (e.g.,\npersonality traits) to provide personalized recommendations. These systems are\nincreasingly used to facilitate interactions among people, such as providing\nteammate recommendations. Despite improved accuracy, such systems are not\nimmune to errors when making inferences about people's most personal traits.\nThese errors manifested as AI misrepresentations. However, the repercussions of\nsuch AI misrepresentations are unclear, especially on people's reactions and\nperceptions of the AI. We present two studies to examine how people react and\nperceive the AI after encountering personality misrepresentations in\nAI-facilitated team matching in a higher education context. Through\nsemi-structured interviews (n=20) and a survey experiment (n=198), we pinpoint\nhow people's existing and newly acquired AI knowledge could shape their\nperceptions and reactions of the AI after encountering AI misrepresentations.\nSpecifically, we identified three rationales that people adopted through\nknowledge acquired from AI (mis)representations: AI works like a machine,\nhuman, and/or magic. These rationales are highly connected to people's\nreactions of over-trusting, rationalizing, and forgiving of AI\nmisrepresentations. Finally, we found that people's existing AI knowledge,\ni.e., AI literacy, could moderate people's changes in their trust in AI after\nencountering AI misrepresentations, but not changes in people's social\nperceptions of AI. We discuss the role of people's AI knowledge when facing AI\nfallibility and implications for designing responsible mitigation and repair\nstrategies.",
      "tldr_zh": "本研究探讨了当AI系统在个性特征推断中出现错误（AI misrepresentations）时，人们对AI的反应和感知问题，特别是AI辅助团队匹配场景。研究通过半结构化访谈（n=20）和调查实验（n=198）发现，人们基于从AI错误中获得的知识，形成三种理性视角：将AI视为机器、人类或魔法，这些视角导致人们对AI错误的过度信任、合理化和原谅。结果显示，人们的现有AI知识（AI literacy）会调节AI错误后对AI信任的变化，但不影响对AI社会感知的改变。该研究为设计负责任的AI错误缓解和修复策略提供了重要启示。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "I.2.0"
      ],
      "primary_category": "cs.HC",
      "comment": "37 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.16355v1",
      "published_date": "2024-05-25 21:27:15 UTC",
      "updated_date": "2024-05-25 21:27:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:52:34.108736"
    },
    {
      "arxiv_id": "2405.16350v3",
      "title": "A Second-Order Perspective on Model Compositionality and Incremental Learning",
      "title_zh": "模型组合性和增量学习的二阶视角",
      "authors": [
        "Angelo Porrello",
        "Lorenzo Bonicelli",
        "Pietro Buzzega",
        "Monica Millunzi",
        "Simone Calderara",
        "Rita Cucchiara"
      ],
      "abstract": "The fine-tuning of deep pre-trained models has revealed compositional\nproperties, with multiple specialized modules that can be arbitrarily composed\ninto a single, multi-task model. However, identifying the conditions that\npromote compositionality remains an open issue, with recent efforts\nconcentrating mainly on linearized networks. We conduct a theoretical study\nthat attempts to demystify compositionality in standard non-linear networks\nthrough the second-order Taylor approximation of the loss function. The\nproposed formulation highlights the importance of staying within the\npre-training basin to achieve composable modules. Moreover, it provides the\nbasis for two dual incremental training algorithms: the one from the\nperspective of multiple models trained individually, while the other aims to\noptimize the composed model as a whole. We probe their application in\nincremental classification tasks and highlight some valuable skills. In fact,\nthe pool of incrementally learned modules not only supports the creation of an\neffective multi-task model but also enables unlearning and specialization in\ncertain tasks. Code available at https://github.com/aimagelab/mammoth.",
      "tldr_zh": "这篇论文从second-order视角探讨了深度预训练模型的组合性(compositionality)和增量学习(incremental learning)。作者通过second-order Taylor approximation对损失函数进行理论分析，揭示了在非线性网络中保持预训练盆地(pre-training basin)的重要性，以实现可组合模块。论文提出两个双重增量训练算法：一个针对独立训练的多个模型，另一个优化整体组合模型，并在增量分类任务中验证其效果，支持创建高效多任务模型、任务unlearning和specialization。总体而言，该工作为理解和应用模型组合性提供了新见解，并提供了开源代码。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to ICLR 2025 (Spotlight)",
      "pdf_url": "http://arxiv.org/pdf/2405.16350v3",
      "published_date": "2024-05-25 20:56:54 UTC",
      "updated_date": "2025-02-28 19:08:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:52:46.696871"
    },
    {
      "arxiv_id": "2405.16337v3",
      "title": "Learning to Reason via Program Generation, Emulation, and Search",
      "title_zh": "通过程序生成、仿真和搜索学习推理",
      "authors": [
        "Nathaniel Weir",
        "Muhammad Khalifa",
        "Linlu Qiu",
        "Orion Weller",
        "Peter Clark"
      ],
      "abstract": "Program synthesis with language models (LMs) has unlocked a large set of\nreasoning abilities; code-tuned LMs have proven adept at generating programs\nthat solve a wide variety of algorithmic symbolic manipulation tasks (e.g. word\nconcatenation). However, not all reasoning tasks are easily expressible as\ncode, e.g. tasks involving commonsense reasoning, moral decision-making, and\nsarcasm understanding. Our goal is to extend an LM's program synthesis skills\nto such tasks and evaluate the results via pseudo-programs, namely Python\nprograms where some leaf function calls are left undefined. To that end, we\npropose, Code Generation and Emulated EXecution (CoGEX). CoGEX works by (1)\ntraining LMs to generate pseudo-programs, (2) teaching them to emulate their\ngenerated program's execution, including those leaf functions, allowing the\nLM's knowledge to fill in the execution gaps; and (3) using them to search over\nmany programs to find an optimal one. To adapt the CoGEX model to a new task,\nwe introduce a method for performing program search to find a single program\nwhose pseudo-execution yields optimal performance when applied to all the\ninstances of a given dataset. We show that our approach yields large\nimprovements compared to standard in-context learning approaches on a battery\nof tasks, both algorithmic and soft reasoning. This result thus demonstrates\nthat code synthesis can be applied to a much broader class of problems than\npreviously considered. Our released dataset, fine-tuned models, and\nimplementation can be found at \\url{https://github.com/nweir127/CoGEX}.",
      "tldr_zh": "本研究提出了一种名为 CoGEX 的方法，用于扩展语言模型 (LMs) 的程序合成能力，以处理不易用代码表达的推理任务，如常识推理和道德决策。CoGEX 通过训练 LMs 生成 pseudo-programs（部分函数未定义的 Python 程序）、模拟其执行（利用 LMs 知识填充缺失部分），并在多个程序中进行搜索，找到最优解决方案。针对新任务，该方法引入程序搜索技术，以确保一个伪程序在整个数据集上实现最佳性能。实验结果显示，CoGEX 在算法和软推理任务上比标准 in-context learning 方法有显著改进，证明程序合成可应用于更广泛的问题类别。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NeurIPS 2024 camera ready",
      "pdf_url": "http://arxiv.org/pdf/2405.16337v3",
      "published_date": "2024-05-25 19:40:50 UTC",
      "updated_date": "2024-11-03 22:44:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:52:58.424125"
    },
    {
      "arxiv_id": "2405.16334v4",
      "title": "Devil's Advocate: Anticipatory Reflection for LLM Agents",
      "title_zh": "Devil's Advocate：针对 LLM 代理的预期性反思",
      "authors": [
        "Haoyu Wang",
        "Tao Li",
        "Zhiwei Deng",
        "Dan Roth",
        "Yang Li"
      ],
      "abstract": "In this work, we introduce a novel approach that equips LLM agents with\nintrospection, enhancing consistency and adaptability in solving complex tasks.\nOur approach prompts LLM agents to decompose a given task into manageable\nsubtasks (i.e., to make a plan), and to continuously introspect upon the\nsuitability and results of their actions. %; and when necessary, to explore\n``the road not taken.'' We implement a three-fold introspective intervention:\n1) anticipatory reflection on potential failures and alternative remedy before\naction execution, 2) post-action alignment with subtask objectives and\nbacktracking with remedy to ensure utmost effort in plan execution, and 3)\ncomprehensive review upon plan completion for future strategy refinement. By\ndeploying and experimenting with this methodology -- a zero-shot approach --\nwithin WebArena for practical tasks in web environments, our agent demonstrates\nsuperior performance with a success rate of 23.5% over existing zero-shot\nmethods by 3.5%. The experimental results suggest that our introspection-driven\napproach not only enhances the agent's ability to navigate unanticipated\nchallenges through a robust mechanism of plan execution, but also improves\nefficiency by reducing the number of trials and plan revisions by 45% needed to\nachieve a task.",
      "tldr_zh": "本研究提出“Devil's Advocate”方法，为LLM代理添加内省机制，以提升任务解决的一致性和适应性。该方法通过分解任务为子任务，并实施三折内省干预：包括行动前预先反思潜在失败和备选方案、行动后与子任务目标对齐并回溯修正，以及计划完成后的全面回顾以优化未来策略。作为一种zero-shot方法，该方法在WebArena上的实验中实现了23.5%的成功率，比现有zero-shot方法高出3.5%，并减少了45%的尝试和计划修订，从而提高了任务执行效率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.16334v4",
      "published_date": "2024-05-25 19:20:15 UTC",
      "updated_date": "2024-06-20 19:41:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:53:11.717154"
    },
    {
      "arxiv_id": "2405.16325v3",
      "title": "SLoPe: Double-Pruned Sparse Plus Lazy Low-Rank Adapter Pretraining of LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammad Mozaffari",
        "Amir Yazdanbakhsh",
        "Zhao Zhang",
        "Maryam Mehri Dehnavi"
      ],
      "abstract": "We propose SLoPe, a Double-Pruned Sparse Plus Lazy Low-rank Adapter\nPretraining method for LLMs that improves the accuracy of sparse LLMs while\naccelerating their pretraining and inference and reducing their memory\nfootprint. Sparse pretraining of LLMs reduces the accuracy of the model, to\novercome this, prior work uses dense models during fine-tuning. SLoPe improves\nthe accuracy of sparsely pretrained models by adding low-rank adapters in the\nfinal 1% iterations of pretraining without adding significant overheads to the\nmodel pretraining and inference. In addition, SLoPe uses a double-pruned\nbackward pass formulation that prunes the transposed weight matrix using N:M\nsparsity structures to enable an accelerated sparse backward pass. SLoPe\naccelerates the training and inference of models with billions of parameters up\nto $1.25\\times$ and $1.54\\times$ respectively (OPT-33B and OPT-66B) while\nreducing their memory usage by up to $0.63\\times$ and $0.61\\times$ for training\nand inference respectively.",
      "tldr_zh": "我们提出 SLoPe，一种 Double-Pruned Sparse Plus Lazy Low-Rank Adapter Pretraining 方法，用于提升大型语言模型 (LLMs) 的准确性，同时加速预训练和推理过程，并显著减少内存占用。\nSLoPe 通过在预训练最后 1% 迭代中添加 low-rank adapters 来改善稀疏模型的性能，并采用 double-pruned 后向传播公式，利用 N:M sparsity 结构修剪转置权重矩阵，以加速稀疏计算。\n实验结果显示，对于 OPT-33B 和 OPT-66B 模型，SLoPe 可将训练速度提高 1.25 倍、推理速度提高 1.54 倍，同时将训练和推理内存使用分别降低至 0.63 倍和 0.61 倍。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at ICLR2025",
      "pdf_url": "http://arxiv.org/pdf/2405.16325v3",
      "published_date": "2024-05-25 18:43:05 UTC",
      "updated_date": "2025-01-25 22:24:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:53:24.218255"
    },
    {
      "arxiv_id": "2405.17497v1",
      "title": "Secure Hierarchical Federated Learning in Vehicular Networks Using Dynamic Client Selection and Anomaly Detection",
      "title_zh": "使用动态客户端选择和异常检测的安全分层联邦学习在车辆网络中",
      "authors": [
        "M. Saeid HaghighiFard",
        "Sinem Coleri"
      ],
      "abstract": "Hierarchical Federated Learning (HFL) faces the significant challenge of\nadversarial or unreliable vehicles in vehicular networks, which can compromise\nthe model's integrity through misleading updates. Addressing this, our study\nintroduces a novel framework that integrates dynamic vehicle selection and\nrobust anomaly detection mechanisms, aiming to optimize participant selection\nand mitigate risks associated with malicious contributions. Our approach\ninvolves a comprehensive vehicle reliability assessment, considering historical\naccuracy, contribution frequency, and anomaly records. An anomaly detection\nalgorithm is utilized to identify anomalous behavior by analyzing the cosine\nsimilarity of local or model parameters during the federated learning (FL)\nprocess. These anomaly records are then registered and combined with past\nperformance for accuracy and contribution frequency to identify the most\nsuitable vehicles for each learning round. Dynamic client selection and anomaly\ndetection algorithms are deployed at different levels, including cluster heads\n(CHs), cluster members (CMs), and the Evolving Packet Core (EPC), to detect and\nfilter out spurious updates. Through simulation-based performance evaluation,\nour proposed algorithm demonstrates remarkable resilience even under intense\nattack conditions. Even in the worst-case scenarios, it achieves convergence\ntimes at $63$\\% as effective as those in scenarios without any attacks.\nConversely, in scenarios without utilizing our proposed algorithm, there is a\nhigh likelihood of non-convergence in the FL process.",
      "tldr_zh": "本研究针对车联网中 Hierarchical Federated Learning (HFL) 面临的敌对或不可靠车辆问题，提出一个新框架，整合动态车辆选择和异常检测机制，以优化参与者选择并降低恶意贡献的风险。框架通过评估车辆的历史准确性、贡献频率和异常记录，并利用余弦相似性分析本地或模型参数来识别异常行为，在 Cluster Heads (CHs)、Cluster Members (CMs) 和 Evolving Packet Core (EPC) 等级别部署算法以过滤虚假更新。模拟实验结果表明，该算法在激烈攻击条件下显示出显著弹性，即使在最坏情况下，收敛时间可达无攻击场景的 63%，而未使用该算法时 Federated Learning (FL) 过程可能无法收敛。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17497v1",
      "published_date": "2024-05-25 18:31:20 UTC",
      "updated_date": "2024-05-25 18:31:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:53:35.663040"
    },
    {
      "arxiv_id": "2405.16312v2",
      "title": "Time-SSM: Simplifying and Unifying State Space Models for Time Series Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaxi Hu",
        "Disen Lan",
        "Ziyu Zhou",
        "Qingsong Wen",
        "Yuxuan Liang"
      ],
      "abstract": "State Space Models (SSMs) have emerged as a potent tool in sequence modeling\ntasks in recent years. These models approximate continuous systems using a set\nof basis functions and discretize them to handle input data, making them\nwell-suited for modeling time series data collected at specific frequencies\nfrom continuous systems. Despite its potential, the application of SSMs in time\nseries forecasting remains underexplored, with most existing models treating\nSSMs as a black box for capturing temporal or channel dependencies. To address\nthis gap, this paper proposes a novel theoretical framework termed Dynamic\nSpectral Operator, offering more intuitive and general guidance on applying\nSSMs to time series data. Building upon our theory, we introduce Time-SSM, a\nnovel SSM-based foundation model with only one-seventh of the parameters\ncompared to Mamba. Various experiments validate both our theoretical framework\nand the superior performance of Time-SSM.",
      "tldr_zh": "State Space Models (SSMs) 在时间序列预测中尚未充分应用，本文提出 Dynamic Spectral Operator 理论框架，提供更直观和通用的指导，以更好地捕捉时间或通道依赖。基于此框架，作者引入 Time-SSM，这是一个参数仅为 Mamba 七分之一的简化统一 SSM 基础模型。实验结果验证了该理论框架的有效性，并展示了 Time-SSM 在各种时间序列预测任务中的优越性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "arXiv admin note: text overlap with arXiv:2402.11463",
      "pdf_url": "http://arxiv.org/pdf/2405.16312v2",
      "published_date": "2024-05-25 17:42:40 UTC",
      "updated_date": "2024-07-14 14:40:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:53:46.441744"
    },
    {
      "arxiv_id": "2405.16310v1",
      "title": "An Empirical Exploration of Trust Dynamics in LLM Supply Chains",
      "title_zh": "LLM 供应链中信任动态的实证探索",
      "authors": [
        "Agathe Balayn",
        "Mireia Yurrita",
        "Fanny Rancourt",
        "Fabio Casati",
        "Ujwal Gadiraju"
      ],
      "abstract": "With the widespread proliferation of AI systems, trust in AI is an important\nand timely topic to navigate. Researchers so far have largely employed a myopic\nview of this relationship. In particular, a limited number of relevant trustors\n(e.g., end-users) and trustees (i.e., AI systems) have been considered, and\nempirical explorations have remained in laboratory settings, potentially\noverlooking factors that impact human-AI relationships in the real world. In\nthis paper, we argue for broadening the scope of studies addressing `trust in\nAI' by accounting for the complex and dynamic supply chains that AI systems\nresult from. AI supply chains entail various technical artifacts that diverse\nindividuals, organizations, and stakeholders interact with, in a variety of\nways. We present insights from an in-situ, empirical study of LLM supply\nchains. Our work reveals additional types of trustors and trustees and new\nfactors impacting their trust relationships. These relationships were found to\nbe central to the development and adoption of LLMs, but they can also be the\nterrain for uncalibrated trust and reliance on untrustworthy LLMs. Based on\nthese findings, we discuss the implications for research on `trust in AI'. We\nhighlight new research opportunities and challenges concerning the appropriate\nstudy of inter-actor relationships across the supply chain and the development\nof calibrated trust and meaningful reliance behaviors. We also question the\nmeaning of building trust in the LLM supply chain.",
      "tldr_zh": "本研究通过实地实证研究（empirical study）探索了大型语言模型（LLMs）供应链中的信任动态（trust dynamics），强调了现有研究视角的局限性，如仅关注最终用户和实验室环境。作者主张扩展研究范围，考虑AI供应链中各种技术制品和利益相关者的复杂互动。研究发现，供应链引入了新的信任者（trustors）和被信任者（trustees），以及影响信任关系的新因素，这些关系促进了LLMs的开发和采用，但也可能导致不当信任和依赖不可靠的模型。最终，论文讨论了这些发现对“信任在AI”研究的启示，包括新的研究机会和挑战，并质疑在LLMs供应链中构建信任的实际意义。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Paper accepted at the TREW workshop co-located with CHI'24",
      "pdf_url": "http://arxiv.org/pdf/2405.16310v1",
      "published_date": "2024-05-25 17:37:56 UTC",
      "updated_date": "2024-05-25 17:37:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:53:58.657393"
    },
    {
      "arxiv_id": "2405.20773v2",
      "title": "Visual-RolePlay: Universal Jailbreak Attack on MultiModal Large Language Models via Role-playing Image Character",
      "title_zh": "Visual-RolePlay",
      "authors": [
        "Siyuan Ma",
        "Weidi Luo",
        "Yu Wang",
        "Xiaogeng Liu"
      ],
      "abstract": "With the advent and widespread deployment of Multimodal Large Language Models\n(MLLMs), ensuring their safety has become increasingly critical. To achieve\nthis objective, it requires us to proactively discover the vulnerability of\nMLLMs by exploring the attack methods. Thus, structure-based jailbreak attacks,\nwhere harmful semantic content is embedded within images, have been proposed to\nmislead the models. However, previous structure-based jailbreak methods mainly\nfocus on transforming the format of malicious queries, such as converting\nharmful content into images through typography, which lacks sufficient\njailbreak effectiveness and generalizability. To address these limitations, we\nfirst introduce the concept of \"Role-play\" into MLLM jailbreak attacks and\npropose a novel and effective method called Visual Role-play (VRP).\nSpecifically, VRP leverages Large Language Models to generate detailed\ndescriptions of high-risk characters and create corresponding images based on\nthe descriptions. When paired with benign role-play instruction texts, these\nhigh-risk character images effectively mislead MLLMs into generating malicious\nresponses by enacting characters with negative attributes. We further extend\nour VRP method into a universal setup to demonstrate its generalizability.\nExtensive experiments on popular benchmarks show that VRP outperforms the\nstrongest baseline, Query relevant and FigStep, by an average Attack Success\nRate (ASR) margin of 14.3% across all models.",
      "tldr_zh": "这篇论文提出了 Visual Role-play (VRP)，一种针对 Multimodal Large Language Models (MLLMs) 的通用越狱攻击方法，通过生成高风险角色图像和描述来嵌入恶意内容。VRP 利用 Large Language Models (LLMs) 创建详细的角色描述，并结合良性指令误导 MLLMs 产生有害响应，从而克服了传统结构化攻击的局限性。实验结果显示，VRP 在多个基准上比最强基线（如 Query relevant 和 FigStep）平均提高了 14.3% 的 Attack Success Rate (ASR)，证明了其有效性和泛化性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.20773v2",
      "published_date": "2024-05-25 17:17:18 UTC",
      "updated_date": "2024-06-12 07:13:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:54:12.608656"
    },
    {
      "arxiv_id": "2405.16304v2",
      "title": "Federated Unsupervised Domain Generalization using Global and Local Alignment of Gradients",
      "title_zh": "翻译失败",
      "authors": [
        "Farhad Pourpanah",
        "Mahdiyar Molahasani",
        "Milad Soltany",
        "Michael Greenspan",
        "Ali Etemad"
      ],
      "abstract": "We address the problem of federated domain generalization in an unsupervised\nsetting for the first time. We first theoretically establish a connection\nbetween domain shift and alignment of gradients in unsupervised federated\nlearning and show that aligning the gradients at both client and server levels\ncan facilitate the generalization of the model to new (target) domains.\nBuilding on this insight, we propose a novel method named FedGaLA, which\nperforms gradient alignment at the client level to encourage clients to learn\ndomain-invariant features, as well as global gradient alignment at the server\nto obtain a more generalized aggregated model. To empirically evaluate our\nmethod, we perform various experiments on four commonly used multi-domain\ndatasets, PACS, OfficeHome, DomainNet, and TerraInc. The results demonstrate\nthe effectiveness of our method which outperforms comparable baselines.\nAblation and sensitivity studies demonstrate the impact of different components\nand parameters in our approach. The source code is available at:\nhttps://github.com/MahdiyarMM/FedGaLA.",
      "tldr_zh": "本研究首次探讨了Federated Unsupervised Domain Generalization问题，通过理论分析建立了域移位与梯度对齐在无监督联邦学习中的联系，证明了在客户端和服务器级别对齐gradients有助于模型泛化到新域。提出了一种新方法FedGaLA，在客户端级别进行local alignment以学习域不变特征，并在服务器级别进行global alignment以获得更泛化的聚合模型。在PACS、OfficeHome、DomainNet和TerraInc等四个多域数据集上的实验显示，FedGaLA优于基线方法，消融和敏感性研究进一步验证了其组件和参数的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to AAAI 2025, 16 pages, 3 figure",
      "pdf_url": "http://arxiv.org/pdf/2405.16304v2",
      "published_date": "2024-05-25 17:12:54 UTC",
      "updated_date": "2025-01-02 23:28:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:54:23.734746"
    },
    {
      "arxiv_id": "2407.13059v2",
      "title": "Prioritizing High-Consequence Biological Capabilities in Evaluations of Artificial Intelligence Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jaspreet Pannu",
        "Doni Bloomfield",
        "Alex Zhu",
        "Robert MacKnight",
        "Gabe Gomes",
        "Anita Cicero",
        "Thomas V. Inglesby"
      ],
      "abstract": "As a result of rapidly accelerating AI capabilities, over the past year,\nnational governments and multinational bodies have announced efforts to address\nsafety, security and ethics issues related to AI models. One high priority\namong these efforts is the mitigation of misuse of AI models. Many biologists\nhave for decades sought to reduce the risks of scientific research that could\nlead, through accident or misuse, to high-consequence disease outbreaks.\nScientists have carefully considered what types of life sciences research have\nthe potential for both benefit and risk (dual-use), especially as scientific\nadvances have accelerated our ability to engineer organisms and create novel\nvariants of pathogens. Here we describe how previous experience and study by\nscientists and policy professionals of dual-use capabilities in the life\nsciences can inform risk evaluations of AI models with biological capabilities.\nWe argue that AI model evaluations should prioritize addressing\nhigh-consequence risks (those that could cause large-scale harm to the public,\nsuch as pandemics), and that these risks should be evaluated prior to model\ndeployment so as to allow potential biosafety and/or biosecurity measures.\nScientists' experience with identifying and mitigating dual-use biological\nrisks can help inform new approaches to evaluating biological AI models.\nIdentifying which AI capabilities post the greatest biosecurity and biosafety\nconcerns is necessary in order to establish targeted AI safety evaluation\nmethods, secure these tools against accident and misuse, and avoid impeding\nimmense potential benefits.",
      "tldr_zh": "该论文强调，在评估人工智能（AI）模型时，应优先关注高后果生物能力风险，例如可能引发大流行等大规模危害。作者借鉴生命科学领域对双重用途（dual-use）研究的经验，建议在AI模型部署前评估这些风险，并实施生物安全（biosafety）和生物安全（biosecurity）措施，以防范事故或滥用。最终，该方法旨在建立针对性的AI安全评估框架，既缓解潜在威胁，又避免阻碍AI的巨大潜在益处。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.CY",
      "comment": "9 pages, 1 figure, 3 tables, 1 box",
      "pdf_url": "http://arxiv.org/pdf/2407.13059v2",
      "published_date": "2024-05-25 16:29:17 UTC",
      "updated_date": "2024-07-23 01:08:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:54:35.670916"
    },
    {
      "arxiv_id": "2405.16282v5",
      "title": "Confidence Under the Hood: An Investigation into the Confidence-Probability Alignment in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Abhishek Kumar",
        "Robert Morabito",
        "Sanzhar Umbet",
        "Jad Kabbara",
        "Ali Emami"
      ],
      "abstract": "As the use of Large Language Models (LLMs) becomes more widespread,\nunderstanding their self-evaluation of confidence in generated responses\nbecomes increasingly important as it is integral to the reliability of the\noutput of these models. We introduce the concept of Confidence-Probability\nAlignment, that connects an LLM's internal confidence, quantified by token\nprobabilities, to the confidence conveyed in the model's response when\nexplicitly asked about its certainty. Using various datasets and prompting\ntechniques that encourage model introspection, we probe the alignment between\nmodels' internal and expressed confidence. These techniques encompass using\nstructured evaluation scales to rate confidence, including answer options when\nprompting, and eliciting the model's confidence level for outputs it does not\nrecognize as its own. Notably, among the models analyzed, OpenAI's GPT-4 showed\nthe strongest confidence-probability alignment, with an average Spearman's\n$\\hat{\\rho}$ of 0.42, across a wide range of tasks. Our work contributes to the\nongoing efforts to facilitate risk assessment in the application of LLMs and to\nfurther our understanding of model trustworthiness.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)中信心-概率对齐(Confidence-Probability Alignment)的概念，即模型内部信心（通过 token probabilities 量化）与模型在被询问时表达信心的对齐度。研究者使用多种数据集和提示技术，包括结构化评估规模、在提示中加入答案选项，以及针对模型不认出的输出来eliciting信心水平，来评估这种对齐度。结果显示，OpenAI 的 GPT-4 在各种任务中表现出最强的对齐度，平均 Spearman's ρ 为 0.42。该工作有助于改进 LLM 的风险评估，并提升模型的可信度和可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages (excluding references), accepted to ACL 2024 Main Conference",
      "pdf_url": "http://arxiv.org/pdf/2405.16282v5",
      "published_date": "2024-05-25 15:42:04 UTC",
      "updated_date": "2024-06-15 22:18:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:54:47.327876"
    },
    {
      "arxiv_id": "2406.00033v1",
      "title": "Retrieval-Augmented Conversational Recommendation with Prompt-based Semi-Structured Natural Language State Tracking",
      "title_zh": "翻译失败",
      "authors": [
        "Sara Kemper",
        "Justin Cui",
        "Kai Dicarlantonio",
        "Kathy Lin",
        "Danjie Tang",
        "Anton Korikov",
        "Scott Sanner"
      ],
      "abstract": "Conversational recommendation (ConvRec) systems must understand rich and\ndiverse natural language (NL) expressions of user preferences and intents,\noften communicated in an indirect manner (e.g., \"I'm watching my weight\"). Such\ncomplex utterances make retrieving relevant items challenging, especially if\nonly using often incomplete or out-of-date metadata. Fortunately, many domains\nfeature rich item reviews that cover standard metadata categories and offer\ncomplex opinions that might match a user's interests (e.g., \"classy joint for a\ndate\"). However, only recently have large language models (LLMs) let us unlock\nthe commonsense connections between user preference utterances and complex\nlanguage in user-generated reviews. Further, LLMs enable novel paradigms for\nsemi-structured dialogue state tracking, complex intent and preference\nunderstanding, and generating recommendations, explanations, and question\nanswers. We thus introduce a novel technology RA-Rec, a Retrieval-Augmented,\nLLM-driven dialogue state tracking system for ConvRec, showcased with a video,\nopen source GitHub repository, and interactive Google Colab notebook.",
      "tldr_zh": "该论文提出了一种Retrieval-Augmented Conversational Recommendation (RA-Rec)系统，旨在解决对话推荐(ConvRec)中用户复杂偏好表达的挑战，例如间接语言理解和元数据不足的问题。该系统利用LLMs结合检索增强技术，从用户生成评论中提取相关信息，实现基于提示的半结构化自然语言状态跟踪，从而提升意图理解、推荐生成和解释能力。RA-Rec展示了在对话推荐领域的显著改进，并提供了开源GitHub仓库、视频和交互式Google Colab笔记本以便于应用和验证。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.00033v1",
      "published_date": "2024-05-25 15:41:26 UTC",
      "updated_date": "2024-05-25 15:41:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:55:00.045947"
    },
    {
      "arxiv_id": "2405.16279v2",
      "title": "AI-Assisted Detector Design for the EIC (AID(2)E)",
      "title_zh": "翻译失败",
      "authors": [
        "M. Diefenthaler",
        "C. Fanelli",
        "L. O. Gerlach",
        "W. Guan",
        "T. Horn",
        "A. Jentsch",
        "M. Lin",
        "K. Nagai",
        "H. Nayak",
        "C. Pecar",
        "K. Suresh",
        "A. Vossen",
        "T. Wang",
        "T. Wenaus"
      ],
      "abstract": "Artificial Intelligence is poised to transform the design of complex,\nlarge-scale detectors like the ePIC at the future Electron Ion Collider.\nFeaturing a central detector with additional detecting systems in the far\nforward and far backward regions, the ePIC experiment incorporates numerous\ndesign parameters and objectives, including performance, physics reach, and\ncost, constrained by mechanical and geometric limits. This project aims to\ndevelop a scalable, distributed AI-assisted detector design for the EIC\n(AID(2)E), employing state-of-the-art multiobjective optimization to tackle\ncomplex designs. Supported by the ePIC software stack and using Geant4\nsimulations, our approach benefits from transparent parameterization and\nadvanced AI features. The workflow leverages the PanDA and iDDS systems, used\nin major experiments such as ATLAS at CERN LHC, the Rubin Observatory, and\nsPHENIX at RHIC, to manage the compute intensive demands of ePIC detector\nsimulations. Tailored enhancements to the PanDA system focus on usability,\nscalability, automation, and monitoring. Ultimately, this project aims to\nestablish a robust design capability, apply a distributed AI-assisted workflow\nto the ePIC detector, and extend its applications to the design of the second\ndetector (Detector-2) in the EIC, as well as to calibration and alignment\ntasks. Additionally, we are developing advanced data science tools to\nefficiently navigate the complex, multidimensional trade-offs identified\nthrough this optimization process.",
      "tldr_zh": "这篇论文介绍了 AID(2)E 项目，利用人工智能(AI)辅助多目标优化(multiobjective optimization)来设计未来电子离子对撞机(EIC)的复杂探测器，如 ePIC 实验。方法结合 Geant4 模拟、ePIC 软件栈以及分布式系统 PanDA 和 iDDS 来处理性能、物理范围和成本等参数的权衡，确保设计过程的扩展性和自动化。最终，该框架显著提升了探测器设计效率，在 ePIC 和 Detector-2 的开发中应用，并扩展到校准和对齐任务，同时开发高级数据科学工具来导航多维优化权衡。",
      "categories": [
        "physics.ins-det",
        "cs.AI"
      ],
      "primary_category": "physics.ins-det",
      "comment": "11 pages, 4 figures, AI4EIC 2023 proceeding",
      "pdf_url": "http://arxiv.org/pdf/2405.16279v2",
      "published_date": "2024-05-25 15:33:44 UTC",
      "updated_date": "2024-05-28 16:31:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:55:12.208809"
    },
    {
      "arxiv_id": "2405.16277v3",
      "title": "Picturing Ambiguity: A Visual Twist on the Winograd Schema Challenge",
      "title_zh": "描绘歧义：Winograd Schema Challenge 的视觉变体",
      "authors": [
        "Brendan Park",
        "Madeline Janecek",
        "Naser Ezzati-Jivan",
        "Yifeng Li",
        "Ali Emami"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable success in tasks\nlike the Winograd Schema Challenge (WSC), showcasing advanced textual\ncommon-sense reasoning. However, applying this reasoning to multimodal domains,\nwhere understanding text and images together is essential, remains a\nsubstantial challenge. To address this, we introduce WinoVis, a novel dataset\nspecifically designed to probe text-to-image models on pronoun disambiguation\nwithin multimodal contexts. Utilizing GPT-4 for prompt generation and Diffusion\nAttentive Attribution Maps (DAAM) for heatmap analysis, we propose a novel\nevaluation framework that isolates the models' ability in pronoun\ndisambiguation from other visual processing challenges. Evaluation of\nsuccessive model versions reveals that, despite incremental advancements,\nStable Diffusion 2.0 achieves a precision of 56.7% on WinoVis, only marginally\nsurpassing random guessing. Further error analysis identifies important areas\nfor future research aimed at advancing text-to-image models in their ability to\ninterpret and interact with the complex visual world.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）在Winograd Schema Challenge (WSC)上的成功，但强调其在多模态环境（结合文本和图像）中的代词消歧挑战。为此，引入了WinoVis数据集，用于评估文本到图像模型的代词消歧能力，并提出了一种新评估框架，利用GPT-4生成提示和Diffusion Attentive Attribution Maps (DAAM)进行热图分析。实验结果显示，Stable Diffusion 2.0在WinoVis上的精度仅为56.7%，略高于随机猜测，这突显了模型在处理复杂视觉交互方面的不足。未来研究应聚焦于提升文本到图像模型的解释力和性能，以更好地理解多模态上下文。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages (excluding references), accepted to ACL 2024 Main Conference",
      "pdf_url": "http://arxiv.org/pdf/2405.16277v3",
      "published_date": "2024-05-25 15:28:22 UTC",
      "updated_date": "2024-06-03 16:42:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:55:22.399799"
    },
    {
      "arxiv_id": "2405.16263v1",
      "title": "Assessing Image Inpainting via Re-Inpainting Self-Consistency Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Tianyi Chen",
        "Jianfu Zhang",
        "Yan Hong",
        "Yiyi Zhang",
        "Liqing Zhang"
      ],
      "abstract": "Image inpainting, the task of reconstructing missing segments in corrupted\nimages using available data, faces challenges in ensuring consistency and\nfidelity, especially under information-scarce conditions. Traditional\nevaluation methods, heavily dependent on the existence of unmasked reference\nimages, inherently favor certain inpainting outcomes, introducing biases.\nAddressing this issue, we introduce an innovative evaluation paradigm that\nutilizes a self-supervised metric based on multiple re-inpainting passes. This\napproach, diverging from conventional reliance on direct comparisons in pixel\nor feature space with original images, emphasizes the principle of\nself-consistency to enable the exploration of various viable inpainting\nsolutions, effectively reducing biases. Our extensive experiments across\nnumerous benchmarks validate the alignment of our evaluation method with human\njudgment.",
      "tldr_zh": "本文提出了一种创新的评估方法，用于评估Image Inpainting（图像修复）任务，该方法通过多次Re-Inpainting过程实现自监督的Self-Consistency指标，旨在减少传统依赖参考图像的偏见问题。不同于直接比较像素或特征空间，该方法强调探索多种可行修复方案，确保评估结果更客观和多样化。主要实验结果显示，该评估范式在多个基准上与人类判断高度一致，为更可靠的图像修复评估提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16263v1",
      "published_date": "2024-05-25 15:05:08 UTC",
      "updated_date": "2024-05-25 15:05:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:55:34.424020"
    },
    {
      "arxiv_id": "2405.16259v1",
      "title": "Front-propagation Algorithm: Explainable AI Technique for Extracting Linear Function Approximations from Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Javier Viaña"
      ],
      "abstract": "This paper introduces the front-propagation algorithm, a novel eXplainable AI\n(XAI) technique designed to elucidate the decision-making logic of deep neural\nnetworks. Unlike other popular explainability algorithms such as Integrated\nGradients or Shapley Values, the proposed algorithm is able to extract an\naccurate and consistent linear function explanation of the network in a single\nforward pass of the trained model. This nuance sets apart the time complexity\nof the front-propagation as it could be running real-time and in parallel with\ndeployed models. We packaged this algorithm in a software called\n$\\texttt{front-prop}$ and we demonstrate its efficacy in providing accurate\nlinear functions with three different neural network architectures trained on\npublicly available benchmark datasets.",
      "tldr_zh": "本论文引入了 front-propagation algorithm，一种新型 eXplainable AI (XAI) 技术，用于揭示深度神经网络的决策逻辑。该算法能够在单次前向传播中提取准确且一致的线性函数解释，与 Integrated Gradients 或 Shapley Values 等方法不同，其时间复杂度更低，支持实时运行和与部署模型并行。作者开发了 $\\texttt{front-prop}$ 软件，并在三个不同神经网络架构上使用公开基准数据集进行了验证，证明了其有效性。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "68T07"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 6 figures. Accepted for publication in: Barnabas Bede,\n  Kelly Cohen, and Vladik Kreinovich (eds.), Proceedings of the NAFIPS\n  International Conference on Fuzzy Systems, Soft Computing, and Explainable\n  AI. NAFIPS'2024, South Padre Island, Texas, May 27-29, 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.16259v1",
      "published_date": "2024-05-25 14:50:23 UTC",
      "updated_date": "2024-05-25 14:50:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:55:46.000770"
    },
    {
      "arxiv_id": "2405.16258v1",
      "title": "USD: Unsupervised Soft Contrastive Learning for Fault Detection in Multivariate Time Series",
      "title_zh": "USD：用于多变量时间序列故障检测的无监督软对比学习",
      "authors": [
        "Hong Liu",
        "Xiuxiu Qiu",
        "Yiming Shi",
        "Zelin Zang"
      ],
      "abstract": "Unsupervised fault detection in multivariate time series is critical for\nmaintaining the integrity and efficiency of complex systems, with current\nmethodologies largely focusing on statistical and machine learning techniques.\nHowever, these approaches often rest on the assumption that data distributions\nconform to Gaussian models, overlooking the diversity of patterns that can\nmanifest in both normal and abnormal states, thereby diminishing discriminative\nperformance. Our innovation addresses this limitation by introducing a\ncombination of data augmentation and soft contrastive learning, specifically\ndesigned to capture the multifaceted nature of state behaviors more accurately.\nThe data augmentation process enriches the dataset with varied representations\nof normal states, while soft contrastive learning fine-tunes the model's\nsensitivity to the subtle differences between normal and abnormal patterns,\nenabling it to recognize a broader spectrum of anomalies. This dual strategy\nsignificantly boosts the model's ability to distinguish between normal and\nabnormal states, leading to a marked improvement in fault detection performance\nacross multiple datasets and settings, thereby setting a new benchmark for\nunsupervised fault detection in complex systems. The code of our method is\navailable at \\url{https://github.com/zangzelin/code_USD.git}.",
      "tldr_zh": "这篇论文提出了一种名为USD的无监督软对比学习(Unsupervised Soft Contrastive Learning)方法，用于多变量时间序列(Multivariate Time Series)的故障检测，以解决现有方法依赖高斯分布假设而忽略数据多样性的问题。方法结合数据增强技术来丰富正常状态的表示，并通过软对比学习微调模型，使其更敏感于正常和异常模式之间的细微差异，从而提升故障检测的准确性。实验结果显示，USD在多个数据集上显著提高了性能，设置了新的无监督故障检测基准，并提供了开源代码（https://github.com/zangzelin/code_USD.git）。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "19 pages, 7 figures, under review",
      "pdf_url": "http://arxiv.org/pdf/2405.16258v1",
      "published_date": "2024-05-25 14:48:04 UTC",
      "updated_date": "2024-05-25 14:48:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:55:59.759263"
    },
    {
      "arxiv_id": "2405.16256v2",
      "title": "HETHUB: A Distributed Training System with Heterogeneous Cluster for Large-Scale Models",
      "title_zh": "HETHUB：一种用于大规模模型的异构集群分布式训练系统",
      "authors": [
        "Si Xu",
        "Zixiao Huang",
        "Yan Zeng",
        "Shengen Yan",
        "Xuefei Ning",
        "Quanlu Zhang",
        "Haolin Ye",
        "Sipei Gu",
        "Chunsheng Shui",
        "Zhezheng Lin",
        "Hao Zhang",
        "Sheng Wang",
        "Guohao Dai",
        "Yu Wang"
      ],
      "abstract": "Training large-scale models relies on a vast number of computing resources.\nFor example, training the GPT-4 model (1.8 trillion parameters) requires 25000\nA100 GPUs . It is a challenge to build a large-scale cluster with one type of\nGPU-accelerator. Using multiple types of GPU-accelerators to construct a\nlarge-scale cluster is an effective way to solve the problem of insufficient\nhomogeneous GPU-accelerators. However, the existing distributed training\nsystems for large-scale models only support homogeneous GPU-accelerators, not\nsupport heterogeneous GPU-accelerators. To address the problem, this paper\nproposes a distributed training system with hybrid parallelism, HETHUB, for\nlarge-scale models, which supports heterogeneous cluster, including AMD, Nvidia\nGPU and other types of GPU-accelerators . It introduces a distributed unified\ncommunicator to realize the communication between heterogeneous\nGPU-accelerators, a distributed performance predictor, and an automatic\nparallel planner to develop and train models efficiently with heterogeneous\nGPU-accelerators. Compared to the distributed training system with homogeneous\nGPU-accelerators, our system can support six combinations of heterogeneous\nGPU-accelerators. We train the Llama-140B model on a heterogeneous cluster with\n768 GPU-accelerators(128 AMD and 640 GPU-accelerator A). The experiment results\nshow that the optimal performance of our system in the heterogeneous cluster\nhas achieved up to 97.49% of the theoretical upper bound performance.",
      "tldr_zh": "该论文提出 HETHUB，一种支持异质 GPU 集群的分布式训练系统，用于高效训练大型模型，如 GPT-4 和 Llama-140B，以解决同质 GPU-accelerators 资源不足的问题。HETHUB 引入分布式统一通信器、分布式性能预测器和自动并行规划器，实现异质 GPU（如 AMD 和 Nvidia）间的通信优化和自动训练规划。实验结果显示，在一个包含 768 个 GPU-accelerators（128 AMD 和 640 Nvidia）的异质集群上，HETHUB 的性能达到理论上限的 97.49%，并支持六种异质组合配置。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16256v2",
      "published_date": "2024-05-25 14:36:35 UTC",
      "updated_date": "2024-08-09 02:38:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:56:10.719656"
    },
    {
      "arxiv_id": "2405.16247v4",
      "title": "AutoManual: Constructing Instruction Manuals by LLM Agents via Interactive Environmental Learning",
      "title_zh": "AutoManual：LLM 代理通过交互式环境学习构建指令手册",
      "authors": [
        "Minghao Chen",
        "Yihang Li",
        "Yanting Yang",
        "Shiyu Yu",
        "Binbin Lin",
        "Xiaofei He"
      ],
      "abstract": "Large Language Models (LLM) based agents have shown promise in autonomously\ncompleting tasks across various domains, e.g., robotics, games, and web\nnavigation. However, these agents typically require elaborate design and expert\nprompts to solve tasks in specific domains, which limits their adaptability. We\nintroduce AutoManual, a framework enabling LLM agents to autonomously build\ntheir understanding through interaction and adapt to new environments.\nAutoManual categorizes environmental knowledge into diverse rules and optimizes\nthem in an online fashion by two agents: 1) The Planner codes actionable plans\nbased on current rules for interacting with the environment. 2) The Builder\nupdates the rules through a well-structured rule system that facilitates online\nrule management and essential detail retention. To mitigate hallucinations in\nmanaging rules, we introduce a *case-conditioned prompting* strategy for the\nBuilder. Finally, the Formulator agent compiles these rules into a\ncomprehensive manual. The self-generated manual can not only improve the\nadaptability but also guide the planning of smaller LLMs while being\nhuman-readable. Given only one simple demonstration, AutoManual significantly\nimproves task success rates, achieving 97.4\\% with GPT-4-turbo and 86.2\\% with\nGPT-3.5-turbo on ALFWorld benchmark tasks. The code is available at\nhttps://github.com/minghchen/automanual.",
      "tldr_zh": "该研究提出AutoManual框架，让LLM（Large Language Models）代理通过交互式环境学习自主构建指令手册，从而提升其适应性。框架包括Planner代理基于当前规则制定行动计划、Builder代理使用case-conditioned prompting策略在线优化规则以减少幻觉，以及Formulator代理编译规则成可读手册。实验结果显示，仅需一个简单演示，AutoManual在ALFWorld基准任务上实现了97.4%的成功率（使用GPT-4-turbo）和86.2%（使用GPT-3.5-turbo），显著改善了LLM代理的性能和通用性。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.16247v4",
      "published_date": "2024-05-25 14:11:44 UTC",
      "updated_date": "2024-11-10 12:54:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:56:23.300187"
    },
    {
      "arxiv_id": "2405.16241v1",
      "title": "FastQuery: Communication-efficient Embedding Table Query for Private LLM Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Chenqi Lin",
        "Tianshi Xu",
        "Zebin Yang",
        "Runsheng Wang",
        "Ru Huang",
        "Meng Li"
      ],
      "abstract": "With the fast evolution of large language models (LLMs), privacy concerns\nwith user queries arise as they may contain sensitive information. Private\ninference based on homomorphic encryption (HE) has been proposed to protect\nuser query privacy. However, a private embedding table query has to be\nformulated as a HE-based matrix-vector multiplication problem and suffers from\nenormous computation and communication overhead. We observe the overhead mainly\ncomes from the neglect of 1) the one-hot nature of user queries and 2) the\nrobustness of the embedding table to low bit-width quantization noise. Hence,\nin this paper, we propose a private embedding table query optimization\nframework, dubbed FastQuery. FastQuery features a communication-aware embedding\ntable quantization algorithm and a one-hot-aware dense packing algorithm to\nsimultaneously reduce both the computation and communication costs. Compared to\nprior-art HE-based frameworks, e.g., Cheetah, Iron, and Bumblebee, FastQuery\nachieves more than $4.3\\times$, $2.7\\times$, $1.3\\times$ latency reduction,\nrespectively and more than $75.7\\times$, $60.2\\times$, $20.2\\times$\ncommunication reduction, respectively, on both LLAMA-7B and LLAMA-30B.",
      "tldr_zh": "该论文针对大型语言模型(LLMs)中用户查询的隐私问题，提出FastQuery框架，以优化基于同态加密(HE)的嵌入表查询。FastQuery通过通信-aware embedding table quantization算法和one-hot-aware dense packing算法，同时减少计算和通信开销，充分利用用户查询的one-hot性质和嵌入表的量化鲁棒性。实验结果显示，与Cheetah、Iron和Bumblebee等现有框架相比，FastQuery在LLAMA-7B和LLAMA-30B上实现了超过4.3倍的延迟减少和75.7倍的通信减少。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "6 pages, DAC2024",
      "pdf_url": "http://arxiv.org/pdf/2405.16241v1",
      "published_date": "2024-05-25 13:58:45 UTC",
      "updated_date": "2024-05-25 13:58:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:56:36.440714"
    },
    {
      "arxiv_id": "2405.16237v1",
      "title": "N-BVH: Neural ray queries with bounding volume hierarchies",
      "title_zh": "翻译失败",
      "authors": [
        "Philippe Weier",
        "Alexander Rath",
        "Élie Michel",
        "Iliyan Georgiev",
        "Philipp Slusallek",
        "Tamy Boubekeur"
      ],
      "abstract": "Neural representations have shown spectacular ability to compress complex\nsignals in a fraction of the raw data size. In 3D computer graphics, the bulk\nof a scene's memory usage is due to polygons and textures, making them ideal\ncandidates for neural compression. Here, the main challenge lies in finding\ngood trade-offs between efficient compression and cheap inference while\nminimizing training time. In the context of rendering, we adopt a ray-centric\napproach to this problem and devise N-BVH, a neural compression architecture\ndesigned to answer arbitrary ray queries in 3D. Our compact model is learned\nfrom the input geometry and substituted for it whenever a ray intersection is\nqueried by a path-tracing engine. While prior neural compression methods have\nfocused on point queries, ours proposes neural ray queries that integrate\nseamlessly into standard ray-tracing pipelines. At the core of our method, we\nemploy an adaptive BVH-driven probing scheme to optimize the parameters of a\nmulti-resolution hash grid, focusing its neural capacity on the sparse 3D\noccupancy swept by the original surfaces. As a result, our N-BVH can serve\naccurate ray queries from a representation that is more than an order of\nmagnitude more compact, providing faithful approximations of visibility, depth,\nand appearance attributes. The flexibility of our method allows us to combine\nand overlap neural and non-neural entities within the same 3D scene and extends\nto appearance level of detail.",
      "tldr_zh": "该论文提出N-BVH，一种神经压缩架构，旨在通过神经表示高效压缩3D计算机图形学中的多边形和纹理，同时优化压缩效率、推理成本和训练时间。核心方法采用射线中心(ray-centric)方法，使用自适应BVH（Bounding Volume Hierarchies）驱动的探测方案来优化多分辨率哈希网格的参数，聚焦于原始表面的稀疏3D占用。结果显示，N-BVH能从一个数量级更紧凑的表示中提供准确的神经射线查询，逼真逼近可见性、深度和外观属性，并支持在同一3D场景中混合神经和非神经实体。",
      "categories": [
        "cs.GR",
        "cs.AI"
      ],
      "primary_category": "cs.GR",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2405.16237v1",
      "published_date": "2024-05-25 13:54:34 UTC",
      "updated_date": "2024-05-25 13:54:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:56:47.359099"
    },
    {
      "arxiv_id": "2405.16225v2",
      "title": "Local Causal Structure Learning in the Presence of Latent Variables",
      "title_zh": "在潜在变量存在情况下的局部因果结构学习",
      "authors": [
        "Feng Xie",
        "Zheng Li",
        "Peng Wu",
        "Yan Zeng",
        "Chunchen Liu",
        "Zhi Geng"
      ],
      "abstract": "Discovering causal relationships from observational data, particularly in the\npresence of latent variables, poses a challenging problem. While current local\nstructure learning methods have proven effective and efficient when the focus\nlies solely on the local relationships of a target variable, they operate under\nthe assumption of causal sufficiency. This assumption implies that all the\ncommon causes of the measured variables are observed, leaving no room for\nlatent variables. Such a premise can be easily violated in various real-world\napplications, resulting in inaccurate structures that may adversely impact\ndownstream tasks. In light of this, our paper delves into the primary\ninvestigation of locally identifying potential parents and children of a target\nfrom observational data that may include latent variables. Specifically, we\nharness the causal information from m-separation and V-structures to derive\ntheoretical consistency results, effectively bridging the gap between global\nand local structure learning. Together with the newly developed stop rules, we\npresent a principled method for determining whether a variable is a direct\ncause or effect of a target. Further, we theoretically demonstrate the\ncorrectness of our approach under the standard causal Markov and faithfulness\nconditions, with infinite samples. Experimental results on both synthetic and\nreal-world data validate the effectiveness and efficiency of our approach.",
      "tldr_zh": "该论文探讨了在存在潜在变量（latent variables）的情况下，从观测数据中学习本地因果结构的问题，指出现有方法依赖于因果充分性（causal sufficiency）假设，这在实际应用中易被违反导致结构不准确。作者提出了一种新方法，利用 m-separation 和 V-structures 的因果信息，结合新开发的停止规则，来识别目标变量的潜在父母和孩子变量，并证明了该方法在标准因果 Markov 和 faithfulness 条件下的一致性。实验结果显示，该方法在合成和真实数据上表现出色，提高了有效性和效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16225v2",
      "published_date": "2024-05-25 13:31:05 UTC",
      "updated_date": "2024-06-06 07:44:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:56:59.021523"
    },
    {
      "arxiv_id": "2405.16224v1",
      "title": "Negative as Positive: Enhancing Out-of-distribution Generalization for Graph Contrastive Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Zixu Wang",
        "Bingbing Xu",
        "Yige Yuan",
        "Huawei Shen",
        "Xueqi Cheng"
      ],
      "abstract": "Graph contrastive learning (GCL), standing as the dominant paradigm in the\nrealm of graph pre-training, has yielded considerable progress. Nonetheless,\nits capacity for out-of-distribution (OOD) generalization has been relatively\nunderexplored. In this work, we point out that the traditional optimization of\nInfoNCE in GCL restricts the cross-domain pairs only to be negative samples,\nwhich inevitably enlarges the distribution gap between different domains. This\nviolates the requirement of domain invariance under OOD scenario and\nconsequently impairs the model's OOD generalization performance. To address\nthis issue, we propose a novel strategy \"Negative as Positive\", where the most\nsemantically similar cross-domain negative pairs are treated as positive during\nGCL. Our experimental results, spanning a wide array of datasets, confirm that\nthis method substantially improves the OOD generalization performance of GCL.",
      "tldr_zh": "该研究发现，传统图对比学习（GCL）中InfoNCE的优化方式仅将跨域对视为负样本，这会扩大不同域间的分布差距，从而损害模型的分布外（OOD）泛化性能。针对这一问题，论文提出“Negative as Positive”策略，将语义上最相似的跨域负样本对视为正样本，以增强域不变性。实验结果在多种数据集上证明，该方法显著提高了GCL的OOD泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2"
      ],
      "primary_category": "cs.LG",
      "comment": "5 pages, 5 figures, In Proceedings of the 47th International ACM\n  SIGIR Conference on Research and Development in Information Retrieval (SIGIR\n  '24), July 14-18, 2024, Washington, DC, USA",
      "pdf_url": "http://arxiv.org/pdf/2405.16224v1",
      "published_date": "2024-05-25 13:29:31 UTC",
      "updated_date": "2024-05-25 13:29:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:57:10.355561"
    },
    {
      "arxiv_id": "2405.20771v3",
      "title": "Towards Black-Box Membership Inference Attack for Diffusion Models",
      "title_zh": "针对扩散模型的黑盒成员推理攻击",
      "authors": [
        "Jingwei Li",
        "Jing Dong",
        "Tianxing He",
        "Jingzhao Zhang"
      ],
      "abstract": "Given the rising popularity of AI-generated art and the associated copyright\nconcerns, identifying whether an artwork was used to train a diffusion model is\nan important research topic. The work approaches this problem from the\nmembership inference attack (MIA) perspective. We first identify the limitation\nof applying existing MIA methods for proprietary diffusion models: the required\naccess of internal U-nets. To address the above problem, we introduce a novel\nmembership inference attack method that uses only the image-to-image variation\nAPI and operates without access to the model's internal U-net. Our method is\nbased on the intuition that the model can more easily obtain an unbiased noise\nprediction estimate for images from the training set. By applying the API\nmultiple times to the target image, averaging the outputs, and comparing the\nresult to the original image, our approach can classify whether a sample was\npart of the training set. We validate our method using DDIM and Stable\nDiffusion setups and further extend both our approach and existing algorithms\nto the Diffusion Transformer architecture. Our experimental results\nconsistently outperform previous methods.",
      "tldr_zh": "该研究针对扩散模型（diffusion models）的版权问题，提出了一种黑-box Membership Inference Attack (MIA) 方法，用于判断图像是否用于模型训练，而无需访问内部 U-net。方法基于模型对训练集图像更容易获得无偏噪声预测的原理，通过多次应用 image-to-image variation API、平均输出并与原图像比较，来分类样本是否属于训练集。实验在 DDIM 和 Stable Diffusion 模型上验证，并扩展到 Diffusion Transformer 架构，结果显示该方法 consistently outperform 现有算法。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.20771v3",
      "published_date": "2024-05-25 12:47:58 UTC",
      "updated_date": "2024-11-27 03:48:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:57:22.558752"
    },
    {
      "arxiv_id": "2405.16205v1",
      "title": "GeneAgent: Self-verification Language Agent for Gene Set Knowledge Discovery using Domain Databases",
      "title_zh": "翻译失败",
      "authors": [
        "Zhizheng Wang",
        "Qiao Jin",
        "Chih-Hsuan Wei",
        "Shubo Tian",
        "Po-Ting Lai",
        "Qingqing Zhu",
        "Chi-Ping Day",
        "Christina Ross",
        "Zhiyong Lu"
      ],
      "abstract": "Gene set knowledge discovery is essential for advancing human functional\ngenomics. Recent studies have shown promising performance by harnessing the\npower of Large Language Models (LLMs) on this task. Nonetheless, their results\nare subject to several limitations common in LLMs such as hallucinations. In\nresponse, we present GeneAgent, a first-of-its-kind language agent featuring\nself-verification capability. It autonomously interacts with various biological\ndatabases and leverages relevant domain knowledge to improve accuracy and\nreduce hallucination occurrences. Benchmarking on 1,106 gene sets from\ndifferent sources, GeneAgent consistently outperforms standard GPT-4 by a\nsignificant margin. Moreover, a detailed manual review confirms the\neffectiveness of the self-verification module in minimizing hallucinations and\ngenerating more reliable analytical narratives. To demonstrate its practical\nutility, we apply GeneAgent to seven novel gene sets derived from mouse B2905\nmelanoma cell lines, with expert evaluations showing that GeneAgent offers\nnovel insights into gene functions and subsequently expedites knowledge\ndiscovery.",
      "tldr_zh": "该研究提出 GeneAgent，一种具备 self-verification 能力的语言代理，用于基因组知识发现，通过自主与生物数据库互动并利用领域知识来提高准确性和减少 Large Language Models (LLMs) 的 hallucinations 问题。在 1,106 个基因组基准测试中，GeneAgent 显著优于标准 GPT-4，并在手动审查中证明其 self-verification 模块能生成更可靠的分析叙述。最后，通过应用于七个从老鼠 B2905 黑色素瘤细胞系衍生的基因组，GeneAgent 提供了新颖见解，加速了知识发现过程。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "30 pages with 10 figures and/or tables",
      "pdf_url": "http://arxiv.org/pdf/2405.16205v1",
      "published_date": "2024-05-25 12:35:15 UTC",
      "updated_date": "2024-05-25 12:35:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:57:35.228888"
    },
    {
      "arxiv_id": "2405.16204v2",
      "title": "VOODOO XP: Expressive One-Shot Head Reenactment for VR Telepresence",
      "title_zh": "翻译失败",
      "authors": [
        "Phong Tran",
        "Egor Zakharov",
        "Long-Nhat Ho",
        "Liwen Hu",
        "Adilbek Karmanov",
        "Aviral Agarwal",
        "McLean Goldwhite",
        "Ariana Bermudez Venegas",
        "Anh Tuan Tran",
        "Hao Li"
      ],
      "abstract": "We introduce VOODOO XP: a 3D-aware one-shot head reenactment method that can\ngenerate highly expressive facial expressions from any input driver video and a\nsingle 2D portrait. Our solution is real-time, view-consistent, and can be\ninstantly used without calibration or fine-tuning. We demonstrate our solution\non a monocular video setting and an end-to-end VR telepresence system for\ntwo-way communication. Compared to 2D head reenactment methods, 3D-aware\napproaches aim to preserve the identity of the subject and ensure\nview-consistent facial geometry for novel camera poses, which makes them\nsuitable for immersive applications. While various facial disentanglement\ntechniques have been introduced, cutting-edge 3D-aware neural reenactment\ntechniques still lack expressiveness and fail to reproduce complex and\nfine-scale facial expressions. We present a novel cross-reenactment\narchitecture that directly transfers the driver's facial expressions to\ntransformer blocks of the input source's 3D lifting module. We show that highly\neffective disentanglement is possible using an innovative multi-stage\nself-supervision approach, which is based on a coarse-to-fine strategy,\ncombined with an explicit face neutralization and 3D lifted frontalization\nduring its initial training stage. We further integrate our novel head\nreenactment solution into an accessible high-fidelity VR telepresence system,\nwhere any person can instantly build a personalized neural head avatar from any\nphoto and bring it to life using the headset. We demonstrate state-of-the-art\nperformance in terms of expressiveness and likeness preservation on a large set\nof diverse subjects and capture conditions.",
      "tldr_zh": "该研究引入了 VOODOO XP，一种 3D-aware 的单次（one-shot）头部重演方法，能够从任意输入驱动视频和一个 2D 肖像生成高度表达性的面部表情，并实现实时、视角一致的输出，无需校准或微调。核心创新在于一种新型跨重演架构，直接将驱动者的面部表情转移到输入源的 transformer blocks 中，并采用多阶段自监督策略，包括粗到细训练、显式面部中和化和 3D 提升正面化，以实现有效的面部解耦。实验结果显示，该方法在各种主题和捕获条件下表现出 state-of-the-art 的表现，尤其在表达性和主体相似性保留方面，适用于单目视频和端到端的 VR telepresence 系统。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16204v2",
      "published_date": "2024-05-25 12:33:40 UTC",
      "updated_date": "2024-05-28 09:22:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:57:47.475872"
    },
    {
      "arxiv_id": "2405.16195v3",
      "title": "Adaptive $Q$-Network: On-the-fly Target Selection for Deep Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Théo Vincent",
        "Fabian Wahren",
        "Jan Peters",
        "Boris Belousov",
        "Carlo D'Eramo"
      ],
      "abstract": "Deep Reinforcement Learning (RL) is well known for being highly sensitive to\nhyperparameters, requiring practitioners substantial efforts to optimize them\nfor the problem at hand. This also limits the applicability of RL in real-world\nscenarios. In recent years, the field of automated Reinforcement Learning\n(AutoRL) has grown in popularity by trying to address this issue. However,\nthese approaches typically hinge on additional samples to select\nwell-performing hyperparameters, hindering sample-efficiency and practicality.\nFurthermore, most AutoRL methods are heavily based on already existing AutoML\nmethods, which were originally developed neglecting the additional challenges\ninherent to RL due to its non-stationarities. In this work, we propose a new\napproach for AutoRL, called Adaptive $Q$-Network (AdaQN), that is tailored to\nRL to take into account the non-stationarity of the optimization procedure\nwithout requiring additional samples. AdaQN learns several $Q$-functions, each\none trained with different hyperparameters, which are updated online using the\n$Q$-function with the smallest approximation error as a shared target. Our\nselection scheme simultaneously handles different hyperparameters while coping\nwith the non-stationarity induced by the RL optimization procedure and being\northogonal to any critic-based RL algorithm. We demonstrate that AdaQN is\ntheoretically sound and empirically validate it in MuJoCo control problems and\nAtari $2600$ games, showing benefits in sample-efficiency, overall performance,\nrobustness to stochasticity and training stability.",
      "tldr_zh": "本研究针对深度强化学习（Deep Reinforcement Learning）对超参数高度敏感的问题，提出了一种新型自动化强化学习（AutoRL）方法：Adaptive $Q$-Network (AdaQN)。AdaQN 通过学习多个 $Q$-functions，每个使用不同的超参数，并在在线过程中以最小近似误差的 $Q$-function 作为共享目标，实现对非平稳性（non-stationarities）的动态处理，而无需额外样本。实验结果显示，该方法在 MuJoCo 控制任务和 Atari 2600 游戏中显著提升了样本效率、整体性能、鲁棒性和训练稳定性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ICLR https://iclr.cc/virtual/2025/poster/28508",
      "pdf_url": "http://arxiv.org/pdf/2405.16195v3",
      "published_date": "2024-05-25 11:57:43 UTC",
      "updated_date": "2025-03-03 11:39:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:58:00.753569"
    },
    {
      "arxiv_id": "2405.16194v4",
      "title": "Diffusion-Reward Adversarial Imitation Learning",
      "title_zh": "扩散奖励对抗性模仿学习",
      "authors": [
        "Chun-Mao Lai",
        "Hsiang-Chun Wang",
        "Ping-Chun Hsieh",
        "Yu-Chiang Frank Wang",
        "Min-Hung Chen",
        "Shao-Hua Sun"
      ],
      "abstract": "Imitation learning aims to learn a policy from observing expert\ndemonstrations without access to reward signals from environments. Generative\nadversarial imitation learning (GAIL) formulates imitation learning as\nadversarial learning, employing a generator policy learning to imitate expert\nbehaviors and discriminator learning to distinguish the expert demonstrations\nfrom agent trajectories. Despite its encouraging results, GAIL training is\noften brittle and unstable. Inspired by the recent dominance of diffusion\nmodels in generative modeling, we propose Diffusion-Reward Adversarial\nImitation Learning (DRAIL), which integrates a diffusion model into GAIL,\naiming to yield more robust and smoother rewards for policy learning.\nSpecifically, we propose a diffusion discriminative classifier to construct an\nenhanced discriminator, and design diffusion rewards based on the classifier's\noutput for policy learning. Extensive experiments are conducted in navigation,\nmanipulation, and locomotion, verifying DRAIL's effectiveness compared to prior\nimitation learning methods. Moreover, additional experimental results\ndemonstrate the generalizability and data efficiency of DRAIL. Visualized\nlearned reward functions of GAIL and DRAIL suggest that DRAIL can produce more\nrobust and smoother rewards. Project page:\nhttps://nturobotlearninglab.github.io/DRAIL/",
      "tldr_zh": "该研究提出了一种Diffusion-Reward Adversarial Imitation Learning (DRAIL)方法，旨在解决传统Generative Adversarial Imitation Learning (GAIL)训练不稳定的问题，通过整合diffusion model来生成更稳健和平滑的奖励信号。DRAIL使用diffusion discriminative classifier构建增强的discriminator，并基于其输出设计diffusion rewards，以优化policy learning的过程。在导航、manipulation和locomotion任务的实验中，DRAIL比现有imitation learning方法表现出色，展示了更好的泛化性、数据效率和奖励函数稳定性。总的来说，该框架为imitation learning提供了更可靠的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024. Project page:\n  https://nturobotlearninglab.github.io/DRAIL/",
      "pdf_url": "http://arxiv.org/pdf/2405.16194v4",
      "published_date": "2024-05-25 11:53:23 UTC",
      "updated_date": "2024-11-26 02:47:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:58:11.906921"
    },
    {
      "arxiv_id": "2405.16191v1",
      "title": "Rocket Landing Control with Grid Fins and Path-following using MPC",
      "title_zh": "翻译失败",
      "authors": [
        "Junhao Yu",
        "Jiarun Wei"
      ],
      "abstract": "In this project, we attempt to optimize a landing trajectory of a rocket. The\ngoal is to minimize the total fuel consumption during the landing process using\ndifferent techniques. Once the optimal and feasible trajectory is generated\nusing batch approach, we attempt to follow the path using a Model Predictive\nControl (MPC) based algorithm, called Trajectory Optimizing Path following\nEstimation from Demonstration (TOPED), in order to generalize to similar\ninitial states and models, where we introduce a novel cost function for the MPC\nto solve. We further show that TOPED can follow a demonstration trajectory well\nin practice under model mismatch and different initial states.",
      "tldr_zh": "这篇论文研究了使用 Grid Fins 的火箭着陆控制，目标是通过优化轨迹来最小化燃料消耗。作者首先采用批处理方法生成最优可行轨迹，然后利用基于 Model Predictive Control (MPC) 的 Trajectory Optimizing Path following Estimation from Demonstration (TOPED) 算法进行路径跟随，该算法引入了一个新颖的成本函数以适应类似初始状态和模型。实验结果显示，TOPED 能够在模型不匹配和不同初始状态下有效跟踪演示轨迹，从而提升了火箭着陆的鲁棒性和效率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16191v1",
      "published_date": "2024-05-25 11:42:29 UTC",
      "updated_date": "2024-05-25 11:42:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:58:23.136661"
    },
    {
      "arxiv_id": "2405.16185v1",
      "title": "Differentiable Cluster Graph Neural Network",
      "title_zh": "可微聚类图神经网络",
      "authors": [
        "Yanfei Dong",
        "Mohammed Haroon Dupty",
        "Lambert Deng",
        "Zhuanghua Liu",
        "Yong Liang Goh",
        "Wee Sun Lee"
      ],
      "abstract": "Graph Neural Networks often struggle with long-range information propagation\nand in the presence of heterophilous neighborhoods. We address both challenges\nwith a unified framework that incorporates a clustering inductive bias into the\nmessage passing mechanism, using additional cluster-nodes. Central to our\napproach is the formulation of an optimal transport based implicit clustering\nobjective function. However, the algorithm for solving the implicit objective\nfunction needs to be differentiable to enable end-to-end learning of the GNN.\nTo facilitate this, we adopt an entropy regularized objective function and\npropose an iterative optimization process, alternating between solving for the\ncluster assignments and updating the node/cluster-node embeddings. Notably, our\nderived closed-form optimization steps are themselves simple yet elegant\nmessage passing steps operating seamlessly on a bipartite graph of nodes and\ncluster-nodes. Our clustering-based approach can effectively capture both local\nand global information, demonstrated by extensive experiments on both\nheterophilous and homophilous datasets.",
      "tldr_zh": "本研究提出了一种可微聚类图神经网络（Differentiable Cluster Graph Neural Network），旨在解决Graph Neural Networks在长距离信息传播和异质邻居（heterophilous neighborhoods）问题上的挑战。该框架通过引入聚类诱导偏差（clustering inductive bias）和额外cluster-nodes，将最优传输（optimal transport）为基础的隐式聚类目标函数整合到消息传递机制中，并采用熵正则化（entropy regularized）目标函数进行迭代优化，实现端到端学习。实验结果显示，该方法在异质（heterophilous）和同质（homophilous）数据集上有效捕获局部和全局信息，显著提升了性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16185v1",
      "published_date": "2024-05-25 11:23:39 UTC",
      "updated_date": "2024-05-25 11:23:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:58:35.736644"
    },
    {
      "arxiv_id": "2405.16184v1",
      "title": "Safe Deep Model-Based Reinforcement Learning with Lyapunov Functions",
      "title_zh": "翻译失败",
      "authors": [
        "Harry Zhang"
      ],
      "abstract": "Model-based Reinforcement Learning (MBRL) has shown many desirable properties\nfor intelligent control tasks. However, satisfying safety and stability\nconstraints during training and rollout remains an open question. We propose a\nnew Model-based RL framework to enable efficient policy learning with unknown\ndynamics based on learning model predictive control (LMPC) framework with\nmathematically provable guarantees of stability. We introduce and explore a\nnovel method for adding safety constraints for model-based RL during training\nand policy learning. The new stability-augmented framework consists of a\nneural-network-based learner that learns to construct a Lyapunov function, and\na model-based RL agent to consistently complete the tasks while satisfying\nuser-specified constraints given only sub-optimal demonstrations and\nsparse-cost feedback. We demonstrate the capability of the proposed framework\nthrough simulated experiments.",
      "tldr_zh": "该研究提出了一种安全的深度模型-based Reinforcement Learning (MBRL) 框架，利用 Lyapunov Functions 确保训练和执行过程中的稳定性和安全性。该框架基于 Learning Model Predictive Control (LMPC)，通过神经网络学习器构建 Lyapunov 函数，并结合 MBRL 代理，在仅提供次优演示和稀疏成本反馈的情况下，实现任务完成的同时满足用户指定的约束。实验结果显示，该框架在模拟环境中有效提升了策略学习的效率和可靠性。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LG",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16184v1",
      "published_date": "2024-05-25 11:21:12 UTC",
      "updated_date": "2024-05-25 11:21:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:58:46.891867"
    },
    {
      "arxiv_id": "2405.16183v1",
      "title": "Graph Neural PDE Solvers with Conservation and Similarity-Equivariance",
      "title_zh": "翻译失败",
      "authors": [
        "Masanobu Horie",
        "Naoto Mitsume"
      ],
      "abstract": "Utilizing machine learning to address partial differential equations (PDEs)\npresents significant challenges due to the diversity of spatial domains and\ntheir corresponding state configurations, which complicates the task of\nencompassing all potential scenarios through data-driven methodologies alone.\nMoreover, there are legitimate concerns regarding the generalization and\nreliability of such approaches, as they often overlook inherent physical\nconstraints. In response to these challenges, this study introduces a novel\nmachine-learning architecture that is highly generalizable and adheres to\nconservation laws and physical symmetries, thereby ensuring greater\nreliability. The foundation of this architecture is graph neural networks\n(GNNs), which are adept at accommodating a variety of shapes and forms.\nAdditionally, we explore the parallels between GNNs and traditional numerical\nsolvers, facilitating a seamless integration of conservative principles and\nsymmetries into machine learning models. Our findings from experiments\ndemonstrate that the model's inclusion of physical laws significantly enhances\nits generalizability, i.e., no significant accuracy degradation for unseen\nspatial domains while other models degrade. The code is available at\nhttps://github.com/yellowshippo/fluxgnn-icml2024.",
      "tldr_zh": "该论文探讨了使用机器学习解决偏微分方程 (PDEs) 的挑战，包括空间领域的多样性和对物理约束的忽略，导致模型泛化性和可靠性不足。为此，研究提出了一种基于 Graph Neural Networks (GNNs) 的新型架构，该架构融入守恒定律 (Conservation) 和相似性等变性 (Similarity-Equivariance)，以提升模型的可靠性并适应各种形状。实验结果表明，该模型在未见空间领域上保持了高准确性，而其他模型则显著下降，提供了一个更具泛化性的 PDE 求解框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE",
        "physics.comp-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML2024",
      "pdf_url": "http://arxiv.org/pdf/2405.16183v1",
      "published_date": "2024-05-25 11:18:27 UTC",
      "updated_date": "2024-05-25 11:18:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:58:59.816256"
    },
    {
      "arxiv_id": "2405.16164v3",
      "title": "Acquiring Better Load Estimates by Combining Anomaly and Change Point Detection in Power Grid Time-series Measurements",
      "title_zh": "通过结合异常检测和变化点检测在电力网格时间序列测量中获取更好的负载估计",
      "authors": [
        "Roel Bouman",
        "Linda Schmeitz",
        "Luco Buise",
        "Jacco Heres",
        "Yuliya Shapovalova",
        "Tom Heskes"
      ],
      "abstract": "In this paper we present novel methodology for automatic anomaly and switch\nevent filtering to improve load estimation in power grid systems. By leveraging\nunsupervised methods with supervised optimization, our approach prioritizes\ninterpretability while ensuring robust and generalizable performance on unseen\ndata. Through experimentation, a combination of binary segmentation for change\npoint detection and statistical process control for anomaly detection emerges\nas the most effective strategy, specifically when ensembled in a novel\nsequential manner. Results indicate the clear wasted potential when filtering\nis not applied. The automatic load estimation is also fairly accurate, with\napproximately 90% of estimates falling within a 10% error margin, with only a\nsingle significant failure in both the minimum and maximum load estimates\nacross 60 measurements in the test set. Our methodology's interpretability\nmakes it particularly suitable for critical infrastructure planning, thereby\nenhancing decision-making processes.",
      "tldr_zh": "本研究提出了一种新方法，通过结合异常检测和变化点检测（change point detection），来自动过滤电力网格时序测量中的异常和开关事件，从而提升负载估计的准确性。该方法整合无监督方法与监督优化，强调可解释性，并通过实验证明，将二元分割（binary segmentation）用于变化点检测和统计过程控制（statistical process control）用于异常检测的顺序集成方式最为有效。结果显示，应用此过滤后，约90%的负载估计误差在10%以内，仅在测试集的60个测量中出现单一重大失败于最小和最大负载估计，且未应用过滤会显著浪费潜力。该方法的可解释性使其特别适用于关键基础设施规划，提升决策过程。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.AP",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "All code can be found at: https://github.com/RoelBouman/StormPhase2",
      "pdf_url": "http://arxiv.org/pdf/2405.16164v3",
      "published_date": "2024-05-25 10:15:51 UTC",
      "updated_date": "2024-10-23 14:24:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:59:12.410796"
    },
    {
      "arxiv_id": "2405.16153v4",
      "title": "DefSent+: Improving sentence embeddings of language models by projecting definition sentences into a quasi-isotropic or isotropic vector space of unlimited dictionary entries",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaodong Liu"
      ],
      "abstract": "This paper presents a significant improvement on the previous conference\npaper known as DefSent. The prior study seeks to improve sentence embeddings of\nlanguage models by projecting definition sentences into the vector space of\ndictionary entries. We discover that this approach is not fully explored due to\nthe methodological limitation of using word embeddings of language models to\nrepresent dictionary entries. This leads to two hindrances. First, dictionary\nentries are constrained by the single-word vocabulary, and thus cannot be fully\nexploited. Second, semantic representations of language models are known to be\nanisotropic, but pre-processing word embeddings for DefSent is not allowed\nbecause its weight is frozen during training and tied to the prediction layer.\nIn this paper, we propose a novel method to progressively build entry\nembeddings not subject to the limitations. As a result, definition sentences\ncan be projected into a quasi-isotropic or isotropic vector space of unlimited\ndictionary entries, so that sentence embeddings of noticeably better quality\nare attainable. We abbreviate our approach as DefSent+ (a plus version of\nDefSent), involving the following strengths: 1) the task performance on\nmeasuring sentence similarities is significantly improved compared to DefSent;\n2) when DefSent+ is used to further train data-augmented models like SIMCSE,\nSNCSE, and SynCSE, state-of-the-art performance on measuring sentence\nsimilarities can be achieved among the approaches without using manually\nlabeled datasets; 3) DefSent+ is also competitive in feature-based transfer for\nNLP downstream tasks.",
      "tldr_zh": "这篇论文提出了 DefSent+，一种改进版本的先前方法 DefSent，用于提升语言模型的句子嵌入(sentence embeddings)。DefSent+ 通过逐步构建不受词汇限制的条目嵌入，将定义句子投射到一个准各向同性(quasi-isotropic)或各向同性(isotropic)向量空间中，从而克服了原有方法的局限，如字典条目受限于单字词汇和语义表示的各向异性(anisotropic)。实验结果显示，DefSent+ 在句子相似性测量任务上显著优于 DefSent，并在进一步训练数据增强模型如 SIMCSE、SNCSE 和 SynCSE 时，实现了不依赖手动标记数据集的 state-of-the-art 性能；此外，它在 NLP 下游任务的特征转移(feature-based transfer)中也表现出竞争力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16153v4",
      "published_date": "2024-05-25 09:43:38 UTC",
      "updated_date": "2024-09-29 05:38:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:59:24.376775"
    },
    {
      "arxiv_id": "2405.16144v1",
      "title": "GreenCOD: A Green Camouflaged Object Detection Method",
      "title_zh": "GreenCOD：一种绿色伪装物体检测方法",
      "authors": [
        "Hong-Shuo Chen",
        "Yao Zhu",
        "Suya You",
        "Azad M. Madni",
        "C. -C. Jay Kuo"
      ],
      "abstract": "We introduce GreenCOD, a green method for detecting camouflaged objects,\ndistinct in its avoidance of backpropagation techniques. GreenCOD leverages\ngradient boosting and deep features extracted from pre-trained Deep Neural\nNetworks (DNNs). Traditional camouflaged object detection (COD) approaches\noften rely on complex deep neural network architectures, seeking performance\nimprovements through backpropagation-based fine-tuning. However, such methods\nare typically computationally demanding and exhibit only marginal performance\nvariations across different models. This raises the question of whether\neffective training can be achieved without backpropagation. Addressing this,\nour work proposes a new paradigm that utilizes gradient boosting for COD. This\napproach significantly simplifies the model design, resulting in a system that\nrequires fewer parameters and operations and maintains high performance\ncompared to state-of-the-art deep learning models. Remarkably, our models are\ntrained without backpropagation and achieve the best performance with fewer\nthan 20G Multiply-Accumulate Operations (MACs). This new, more efficient\nparadigm opens avenues for further exploration in green, backpropagation-free\nmodel training.",
      "tldr_zh": "本文提出 GreenCOD，一种绿色 Camouflaged Object Detection (COD) 方法，该方法避免使用 backpropagation 技术，而是利用 gradient boosting 和从预训练 Deep Neural Networks (DNNs) 中提取的深度特征，简化模型设计并减少参数和操作。相比传统 COD 模型，GreenCOD 在保持高性能的同时，仅需少于 20G Multiply-Accumulate Operations (MACs) 即可实现最佳检测效果。這種新范式為高效、環保的無 backpropagation 訓練開辟了新途徑。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16144v1",
      "published_date": "2024-05-25 09:25:27 UTC",
      "updated_date": "2024-05-25 09:25:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:59:36.122057"
    },
    {
      "arxiv_id": "2405.16141v4",
      "title": "AIGB: Generative Auto-bidding via Conditional Diffusion Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Jiayan Guo",
        "Yusen Huo",
        "Zhilin Zhang",
        "Tianyu Wang",
        "Chuan Yu",
        "Jian Xu",
        "Yan Zhang",
        "Bo Zheng"
      ],
      "abstract": "Auto-bidding plays a crucial role in facilitating online advertising by\nautomatically providing bids for advertisers. Reinforcement learning (RL) has\ngained popularity for auto-bidding. However, most current RL auto-bidding\nmethods are modeled through the Markovian Decision Process (MDP), which assumes\nthe Markovian state transition. This assumption restricts the ability to\nperform in long horizon scenarios and makes the model unstable when dealing\nwith highly random online advertising environments. To tackle this issue, this\npaper introduces AI-Generated Bidding (AIGB), a novel paradigm for auto-bidding\nthrough generative modeling. In this paradigm, we propose DiffBid, a\nconditional diffusion modeling approach for bid generation. DiffBid directly\nmodels the correlation between the return and the entire trajectory,\neffectively avoiding error propagation across time steps in long horizons.\nAdditionally, DiffBid offers a versatile approach for generating trajectories\nthat maximize given targets while adhering to specific constraints. Extensive\nexperiments conducted on the real-world dataset and online A/B test on Alibaba\nadvertising platform demonstrate the effectiveness of DiffBid, achieving 2.81%\nincrease in GMV and 3.36% increase in ROI.",
      "tldr_zh": "本论文针对在线广告中的 auto-bidding 问题，指出传统基于 Reinforcement Learning (RL) 和 Markovian Decision Process (MDP) 的方法在长周期场景下易受随机环境影响而不稳定，并引入 AIGB 范式，通过生成建模来优化出价策略。作者提出 DiffBid，一种基于 conditional diffusion modeling 的方法，直接建模回报与整个轨迹的相关性，避免了跨时间步的错误传播，并支持生成满足特定约束的最大化目标。实验结果显示，在真实数据集和 Alibaba 平台的在线 A/B 测试中，DiffBid 实现了 GMV 增加 2.81% 和 ROI 增加 3.36%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by KDD 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.16141v4",
      "published_date": "2024-05-25 09:21:43 UTC",
      "updated_date": "2024-10-08 07:02:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T11:59:48.542627"
    },
    {
      "arxiv_id": "2405.16136v1",
      "title": "C3LLM: Conditional Multimodal Content Generation Using Large Language Models",
      "title_zh": "C3LLM：使用大语言模型的条件多模态内容生成",
      "authors": [
        "Zixuan Wang",
        "Qinkai Duan",
        "Yu-Wing Tai",
        "Chi-Keung Tang"
      ],
      "abstract": "We introduce C3LLM (Conditioned-on-Three-Modalities Large Language Models), a\nnovel framework combining three tasks of video-to-audio, audio-to-text, and\ntext-to-audio together. C3LLM adapts the Large Language Model (LLM) structure\nas a bridge for aligning different modalities, synthesizing the given\nconditional information, and making multimodal generation in a discrete manner.\nOur contributions are as follows. First, we adapt a hierarchical structure for\naudio generation tasks with pre-trained audio codebooks. Specifically, we train\nthe LLM to generate audio semantic tokens from the given conditions, and\nfurther use a non-autoregressive transformer to generate different levels of\nacoustic tokens in layers to better enhance the fidelity of the generated\naudio. Second, based on the intuition that LLMs were originally designed for\ndiscrete tasks with the next-word prediction method, we use the discrete\nrepresentation for audio generation and compress their semantic meanings into\nacoustic tokens, similar to adding \"acoustic vocabulary\" to LLM. Third, our\nmethod combines the previous tasks of audio understanding, video-to-audio\ngeneration, and text-to-audio generation together into one unified model,\nproviding more versatility in an end-to-end fashion. Our C3LLM achieves\nimproved results through various automated evaluation metrics, providing better\nsemantic alignment compared to previous methods.",
      "tldr_zh": "我们引入了 C3LLM 框架，它将视频-to-audio、audio-to-text 和 text-to-audio 三个任务整合在一起，使用 Large Language Models (LLM) 作为不同模态对齐的桥梁，实现条件多模态内容生成。框架采用分层结构训练 LLM 生成音频语义 tokens，然后通过非自回归 transformer 生成多层声学 tokens，以提高音频生成的保真度和语义压缩效果。C3LLM 将音频理解、视频-to-audio 和 text-to-audio 任务统一到一个端到端模型中，提供更通用的离散表示生成方式。实验结果显示，该框架在各种自动评估指标上实现了更好的语义对齐性能，超越了现有方法。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16136v1",
      "published_date": "2024-05-25 09:10:12 UTC",
      "updated_date": "2024-05-25 09:10:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:00:03.097588"
    },
    {
      "arxiv_id": "2405.16133v3",
      "title": "Uncovering LLM-Generated Code: A Zero-Shot Synthetic Code Detector via Code Rewriting",
      "title_zh": "翻译失败",
      "authors": [
        "Tong Ye",
        "Yangkai Du",
        "Tengfei Ma",
        "Lingfei Wu",
        "Xuhong Zhang",
        "Shouling Ji",
        "Wenhai Wang"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable proficiency in\ngenerating code. However, the misuse of LLM-generated (synthetic) code has\nraised concerns in both educational and industrial contexts, underscoring the\nurgent need for synthetic code detectors. Existing methods for detecting\nsynthetic content are primarily designed for general text and struggle with\ncode due to the unique grammatical structure of programming languages and the\npresence of numerous ''low-entropy'' tokens. Building on this, our work\nproposes a novel zero-shot synthetic code detector based on the similarity\nbetween the original code and its LLM-rewritten variants. Our method is based\non the observation that differences between LLM-rewritten and original code\ntend to be smaller when the original code is synthetic. We utilize\nself-supervised contrastive learning to train a code similarity model and\nevaluate our approach on two synthetic code detection benchmarks. Our results\ndemonstrate a significant improvement over existing SOTA synthetic content\ndetectors, with AUROC scores increasing by 20.5% on the APPS benchmark and\n29.1% on the MBPP benchmark.",
      "tldr_zh": "本文研究了大型语言模型(LLMs)生成的合成代码在教育和工业领域的滥用问题，并提出了一种零-shot合成代码检测器，通过比较原始代码与其LLM重写版本的相似度来实现检测。该方法基于观察，即合成代码的重写差异通常较小，并利用自监督对比学习(self-supervised contrastive learning)训练代码相似性模型。在APPS和MBPP基准测试中，该检测器将AUROC分数分别提高了20.5%和29.1%，显著超越现有最先进方法。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted by AAAI 2025; previously submitted to EMNLP 2023",
      "pdf_url": "http://arxiv.org/pdf/2405.16133v3",
      "published_date": "2024-05-25 08:57:28 UTC",
      "updated_date": "2024-12-16 15:42:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:00:12.683084"
    },
    {
      "arxiv_id": "2405.16128v1",
      "title": "How Well Do Deep Learning Models Capture Human Concepts? The Case of the Typicality Effect",
      "title_zh": "深度学习模型捕捉人类概念的效果如何？：典型性效应的案例",
      "authors": [
        "Siddhartha K. Vemuri",
        "Raj Sanjay Shah",
        "Sashank Varma"
      ],
      "abstract": "How well do representations learned by ML models align with those of humans?\nHere, we consider concept representations learned by deep learning models and\nevaluate whether they show a fundamental behavioral signature of human\nconcepts, the typicality effect. This is the finding that people judge some\ninstances (e.g., robin) of a category (e.g., Bird) to be more typical than\nothers (e.g., penguin). Recent research looking for human-like typicality\neffects in language and vision models has focused on models of a single\nmodality, tested only a small number of concepts, and found only modest\ncorrelations with human typicality ratings. The current study expands this\nbehavioral evaluation of models by considering a broader range of language (N =\n8) and vision (N = 10) model architectures. It also evaluates whether the\ncombined typicality predictions of vision + language model pairs, as well as a\nmultimodal CLIP-based model, are better aligned with human typicality judgments\nthan those of models of either modality alone. Finally, it evaluates the models\nacross a broader range of concepts (N = 27) than prior studies. There were\nthree important findings. First, language models better align with human\ntypicality judgments than vision models. Second, combined language and vision\nmodels (e.g., AlexNet + MiniLM) better predict the human typicality data than\nthe best-performing language model (i.e., MiniLM) or vision model (i.e.,\nViT-Huge) alone. Third, multimodal models (i.e., CLIP ViT) show promise for\nexplaining human typicality judgments. These results advance the\nstate-of-the-art in aligning the conceptual representations of ML models and\nhumans. A methodological contribution is the creation of a new image set for\ntesting the conceptual alignment of vision models.",
      "tldr_zh": "本文研究评估了深度学习模型的概念表示是否与人类概念一致，焦点是典型的典型性效应（typicality effect），即人们对某些类别实例（如 robin 相对于 penguin）的典型性判断。研究扩展了先前工作，通过测试8种语言模型（N=8）和10种视觉模型（N=10），并考察语言+视觉模型组合（如 AlexNet + MiniLM）以及多模态模型（如 CLIP ViT）在27个概念上的预测表现。结果显示，语言模型比视觉模型更符合人类典型性判断，而组合模型的预测准确性优于单一模态模型，多模态模型（如 CLIP ViT）展现出更高的潜力。该研究推进了机器学习模型与人类概念表示的 alignment，并贡献了一个新的图像集用于视觉模型评估。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "To appear at CogSci 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.16128v1",
      "published_date": "2024-05-25 08:38:30 UTC",
      "updated_date": "2024-05-25 08:38:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:00:27.090737"
    },
    {
      "arxiv_id": "2405.16123v1",
      "title": "Retro-prob: Retrosynthetic Planning Based on a Probabilistic Model",
      "title_zh": "翻译失败",
      "authors": [
        "Chengyang Tian",
        "Yangpeng Zhang",
        "Yang Liu"
      ],
      "abstract": "Retrosynthesis is a fundamental but challenging task in organic chemistry,\nwith broad applications in fields such as drug design and synthesis. Given a\ntarget molecule, the goal of retrosynthesis is to find out a series of\nreactions which could be assembled into a synthetic route which starts from\npurchasable molecules and ends at the target molecule. The uncertainty of\nreactions used in retrosynthetic planning, which is caused by hallucinations of\nbackward models, has recently been noticed. In this paper we propose a succinct\nprobabilistic model to describe such uncertainty. Based on the model, we\npropose a new retrosynthesis planning algorithm called retro-prob to maximize\nthe successful synthesis probability of target molecules, which acquires high\nefficiency by utilizing the chain rule of derivatives. Experiments on the\nParoutes benchmark show that retro-prob outperforms previous algorithms, retro*\nand retro-fallback, both in speed and in the quality of synthesis plans.",
      "tldr_zh": "本研究针对有机化学中的逆合成（Retrosynthesis）任务提出了一种基于概率模型的规划方法，以解决反应不确定性（如 backward models 的 hallucination）问题。研究者开发了 retro-prob 算法，该算法利用概率模型和链式导数规则（chain rule of derivatives）来最大化目标分子的成功合成概率，同时提升计算效率。在 Paroutes benchmark 测试中，retro-prob 比现有算法 retro* 和 retro-fallback 在速度和合成计划质量上表现出色，证明了其在药物设计等领域的潜在应用。",
      "categories": [
        "cs.AI",
        "q-bio.BM"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16123v1",
      "published_date": "2024-05-25 08:23:40 UTC",
      "updated_date": "2024-05-25 08:23:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:00:36.769724"
    },
    {
      "arxiv_id": "2405.16122v2",
      "title": "Prompt Optimization with EASE? Efficient Ordering-aware Automated Selection of Exemplars",
      "title_zh": "翻译失败",
      "authors": [
        "Zhaoxuan Wu",
        "Xiaoqiang Lin",
        "Zhongxiang Dai",
        "Wenyang Hu",
        "Yao Shu",
        "See-Kiong Ng",
        "Patrick Jaillet",
        "Bryan Kian Hsiang Low"
      ],
      "abstract": "Large language models (LLMs) have shown impressive capabilities in real-world\napplications. The capability of in-context learning (ICL) allows us to adapt an\nLLM to downstream tasks by including input-label exemplars in the prompt\nwithout model fine-tuning. However, the quality of these exemplars in the\nprompt greatly impacts performance, highlighting the need for an effective\nautomated exemplar selection method. Recent studies have explored\nretrieval-based approaches to select exemplars tailored to individual test\nqueries, which can be undesirable due to extra test-time computation and an\nincreased risk of data exposure. Moreover, existing methods fail to adequately\naccount for the impact of exemplar ordering on the performance. On the other\nhand, the impact of the instruction, another essential component in the prompt\ngiven to the LLM, is often overlooked in existing exemplar selection methods.\nTo address these challenges, we propose a novel method named EASE, which\nleverages the hidden embedding from a pre-trained language model to represent\nordered sets of exemplars and uses a neural bandit algorithm to optimize the\nsets of exemplars while accounting for exemplar ordering. Our EASE can\nefficiently find an ordered set of exemplars that performs well for all test\nqueries from a given task, thereby eliminating test-time computation.\nImportantly, EASE can be readily extended to jointly optimize both the\nexemplars and the instruction. Through extensive empirical evaluations\n(including novel tasks), we demonstrate the superiority of EASE over existing\nmethods, and reveal practical insights about the impact of exemplar selection\non ICL, which may be of independent interest. Our code is available at\nhttps://github.com/ZhaoxuanWu/EASE-Prompt-Optimization.",
      "tldr_zh": "本文提出 EASE 方法，用于优化大型语言模型 (LLMs) 的 in-context learning (ICL) 提示，通过自动选择有序示例集来提升性能。EASE 利用预训练语言模型的隐藏嵌入表示示例顺序，并采用神经 bandit 算法高效优化示例集，从而避免测试时额外计算，并可扩展到联合优化示例和指令。实验结果显示，EASE 在各种任务上优于现有方法，并揭示了示例选择对 ICL 的关键影响，提供实用见解。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.AI",
      "comment": "28 pages, 1 figure, 35 tables",
      "pdf_url": "http://arxiv.org/pdf/2405.16122v2",
      "published_date": "2024-05-25 08:23:05 UTC",
      "updated_date": "2024-10-29 11:17:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:00:49.388661"
    },
    {
      "arxiv_id": "2405.16114v1",
      "title": "Multi-scale Quaternion CNN and BiGRU with Cross Self-attention Feature Fusion for Fault Diagnosis of Bearing",
      "title_zh": "多尺度四元数 CNN 和 BiGRU 结合交叉自注意力特征融合用于轴承故障诊断",
      "authors": [
        "Huanbai Liu",
        "Fanlong Zhang",
        "Yin Tan",
        "Lian Huang",
        "Yan Li",
        "Guoheng Huang",
        "Shenghong Luo",
        "An Zeng"
      ],
      "abstract": "In recent years, deep learning has led to significant advances in bearing\nfault diagnosis (FD). Most techniques aim to achieve greater accuracy. However,\nthey are sensitive to noise and lack robustness, resulting in insufficient\ndomain adaptation and anti-noise ability. The comparison of studies reveals\nthat giving equal attention to all features does not differentiate their\nsignificance. In this work, we propose a novel FD model by integrating\nmulti-scale quaternion convolutional neural network (MQCNN), bidirectional\ngated recurrent unit (BiGRU), and cross self-attention feature fusion (CSAFF).\nWe have developed innovative designs in two modules, namely MQCNN and CSAFF.\nFirstly, MQCNN applies quaternion convolution to multi-scale architecture for\nthe first time, aiming to extract the rich hidden features of the original\nsignal from multiple scales. Then, the extracted multi-scale information is\ninput into CSAFF for feature fusion, where CSAFF innovatively incorporates\ncross self-attention mechanism to enhance discriminative interaction\nrepresentation within features. Finally, BiGRU captures temporal dependencies\nwhile a softmax layer is employed for fault classification, achieving accurate\nFD. To assess the efficacy of our approach, we experiment on three public\ndatasets (CWRU, MFPT, and Ottawa) and compare it with other excellent methods.\nThe results confirm its state-of-the-art, which the average accuracies can\nachieve up to 99.99%, 100%, and 99.21% on CWRU, MFPT, and Ottawa datasets.\nMoreover, we perform practical tests and ablation experiments to validate the\nefficacy and robustness of the proposed approach. Code is available at\nhttps://github.com/mubai011/MQCCAF.",
      "tldr_zh": "本研究提出了一种新型轴承故障诊断模型，结合 Multi-scale Quaternion CNN (MQCNN)、BiGRU 和 Cross Self-attention Feature Fusion (CSAFF)，以解决现有方法的噪声敏感性和特征重要性差异问题。MQCNN 首次将四元数卷积应用于多尺度架构，提取原始信号的丰富隐藏特征，而 CSAFF 通过交叉自注意力机制增强特征间的交互表示，随后 BiGRU 捕获时间依赖性，并使用 softmax 层进行分类。在 CWRU、MFPT 和 Ottawa 数据集上，该模型平均准确率分别达到 99.99%、100% 和 99.21%，展现出最先进性能，并通过实际测试和消融实验验证了其鲁棒性和有效性。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16114v1",
      "published_date": "2024-05-25 07:55:02 UTC",
      "updated_date": "2024-05-25 07:55:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:01:02.777954"
    },
    {
      "arxiv_id": "2406.01604v2",
      "title": "An Empirical Study of Excitation and Aggregation Design Adaptions in CLIP4Clip for Video-Text Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaolun Jing",
        "Genke Yang",
        "Jian Chu"
      ],
      "abstract": "CLIP4Clip model transferred from the CLIP has been the de-factor standard to\nsolve the video clip retrieval task from frame-level input, triggering the\nsurge of CLIP4Clip-based models in the video-text retrieval domain. In this\nwork, we rethink the inherent limitation of widely-used mean pooling operation\nin the frame features aggregation and investigate the adaptions of excitation\nand aggregation design for discriminative video representation generation. We\npresent a novel excitationand-aggregation design, including (1) The excitation\nmodule is available for capturing non-mutuallyexclusive relationships among\nframe features and achieving frame-wise features recalibration, and (2) The\naggregation module is applied to learn exclusiveness used for frame\nrepresentations aggregation. Similarly, we employ the cascade of sequential\nmodule and aggregation design to generate discriminative video representation\nin the sequential type. Besides, we adopt the excitation design in the tight\ntype to obtain representative frame features for multi-modal interaction. The\nproposed modules are evaluated on three benchmark datasets of MSR-VTT,\nActivityNet and DiDeMo, achieving MSR-VTT (43.9 R@1), ActivityNet (44.1 R@1)\nand DiDeMo (31.0 R@1). They outperform the CLIP4Clip results by +1.2% (+0.5%),\n+4.5% (+1.9%) and +9.5% (+2.7%) relative (absolute) improvements, demonstrating\nthe superiority of our proposed excitation and aggregation designs. We hope our\nwork will serve as an alternative for frame representations aggregation and\nfacilitate future research.",
      "tldr_zh": "本文通过实证研究，探讨了 CLIP4Clip 模型中 excitation 和 aggregation 设计的适应，以改进视频-文本检索任务中的帧特征聚合。作者提出了一种新颖的 excitation 模块，用于捕捉帧特征间的非互斥关系并实现特征重新校准，以及 aggregation 模块，用于学习排他性聚合帧表示，并在顺序和紧凑类型中应用这些设计。实验在 MSR-VTT、ActivityNet 和 DiDeMo 数据集上显示，该方法分别将 R@1 指标提升至 43.9%、44.1% 和 31.0%，较 CLIP4Clip 实现了 1.2%、4.5% 和 9.5% 的绝对改进，从而为生成更具区分性的视频表示提供了有效替代方案。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CV",
        "cs.MM"
      ],
      "primary_category": "cs.IR",
      "comment": "20 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.01604v2",
      "published_date": "2024-05-25 07:45:10 UTC",
      "updated_date": "2024-06-08 05:49:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:01:15.186913"
    },
    {
      "arxiv_id": "2405.16105v1",
      "title": "MambaLLIE: Implicit Retinex-Aware Low Light Enhancement with Global-then-Local State Space",
      "title_zh": "翻译失败",
      "authors": [
        "Jiangwei Weng",
        "Zhiqiang Yan",
        "Ying Tai",
        "Jianjun Qian",
        "Jian Yang",
        "Jun Li"
      ],
      "abstract": "Recent advances in low light image enhancement have been dominated by\nRetinex-based learning framework, leveraging convolutional neural networks\n(CNNs) and Transformers. However, the vanilla Retinex theory primarily\naddresses global illumination degradation and neglects local issues such as\nnoise and blur in dark conditions. Moreover, CNNs and Transformers struggle to\ncapture global degradation due to their limited receptive fields. While state\nspace models (SSMs) have shown promise in the long-sequence modeling, they face\nchallenges in combining local invariants and global context in visual data. In\nthis paper, we introduce MambaLLIE, an implicit Retinex-aware low light\nenhancer featuring a global-then-local state space design. We first propose a\nLocal-Enhanced State Space Module (LESSM) that incorporates an augmented local\nbias within a 2D selective scan mechanism, enhancing the original SSMs by\npreserving local 2D dependency. Additionally, an Implicit Retinex-aware\nSelective Kernel module (IRSK) dynamically selects features using\nspatially-varying operations, adapting to varying inputs through an adaptive\nkernel selection process. Our Global-then-Local State Space Block (GLSSB)\nintegrates LESSM and IRSK with LayerNorm as its core. This design enables\nMambaLLIE to achieve comprehensive global long-range modeling and flexible\nlocal feature aggregation. Extensive experiments demonstrate that MambaLLIE\nsignificantly outperforms state-of-the-art CNN and Transformer-based methods.\nProject Page: https://mamballie.github.io/anon/",
      "tldr_zh": "该研究针对低光图像增强中的 Retinex 理论局限性，提出 MambaLLIE 框架，以全局-然后-局部状态空间设计解决 CNNs 和 Transformers 在捕捉全局退化及局部问题（如噪声和模糊）方面的不足。MambaLLIE 引入 Local-Enhanced State Space Module (LESSM) 和 Implicit Retinex-aware Selective Kernel module (IRSK)，其中 LESSM 通过增强局部偏差在 2D 选择性扫描机制中保留局部依赖，IRSK 则通过自适应内核选择动态处理空间变化特征；二者整合于 Global-then-Local State Space Block (GLSSB)，实现高效的全局长程建模和局部特征聚合。实验结果显示，MambaLLIE 显著优于现有 CNN 和 Transformer 方法，在低光增强任务中表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16105v1",
      "published_date": "2024-05-25 07:31:49 UTC",
      "updated_date": "2024-05-25 07:31:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:01:27.542784"
    },
    {
      "arxiv_id": "2406.00032v2",
      "title": "Paths of A Million People: Extracting Life Trajectories from Wikipedia",
      "title_zh": "翻译失败",
      "authors": [
        "Ying Zhang",
        "Xiaofeng Li",
        "Zhaoyang Liu",
        "Haipeng Zhang"
      ],
      "abstract": "The life trajectories of notable people have been studied to pinpoint the\ntimes and places of significant events such as birth, death, education,\nmarriage, competition, work, speeches, scientific discoveries, artistic\nachievements, and battles. Understanding how these individuals interact with\nothers provides valuable insights for broader research into human dynamics.\nHowever, the scarcity of trajectory data in terms of volume, density, and\ninter-person interactions, limits relevant studies from being comprehensive and\ninteractive. We mine millions of biography pages from Wikipedia and tackle the\ngeneralization problem stemming from the variety and heterogeneity of the\ntrajectory descriptions. Our ensemble model COSMOS, which combines the idea of\nsemi-supervised learning and contrastive learning, achieves an F1 score of\n85.95%. For this task, we also create a hand-curated dataset,\nWikiLifeTrajectory, consisting of 8,852 (person, time, location) triplets as\nground truth. Besides, we perform an empirical analysis on the trajectories of\n8,272 historians to demonstrate the validity of the extracted results. To\nfacilitate the research on trajectory extractions and help the analytical\nstudies to construct grand narratives, we make our code, the million-level\nextracted trajectories, and the WikiLifeTrajectory dataset publicly available.",
      "tldr_zh": "本研究从 Wikipedia 挖掘数百万传记页面，提取著名人物的生活轨迹，包括出生、死亡、教育和工作等关键事件，以解决现有数据在体积、密度和人际互动方面的稀缺问题。研究提出 ensemble 模型 COSMOS，结合 semi-supervised learning 和 contrastive learning，实现了 85.95% 的 F1 score，并创建了手 curation 的 WikiLifeTrajectory 数据集，包含 8,852 个 (person, time, location) 三元组作为 ground truth。对 8,272 名历史学家的轨迹进行实证分析，验证了提取结果的有效性。该研究公开代码、百万级轨迹数据和数据集，促进了轨迹提取和人类动态研究的深入发展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ICWSM 2025. 15 pages",
      "pdf_url": "http://arxiv.org/pdf/2406.00032v2",
      "published_date": "2024-05-25 06:57:33 UTC",
      "updated_date": "2024-07-21 06:52:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:01:37.299762"
    },
    {
      "arxiv_id": "2405.16082v1",
      "title": "Uncertainty Measurement of Deep Learning System based on the Convex Hull of Training Sets",
      "title_zh": "基于训练集凸包的深度学习系统不确定性测量",
      "authors": [
        "Hyekyoung Hwang",
        "Jitae Shin"
      ],
      "abstract": "Deep Learning (DL) has made remarkable achievements in computer vision and\nadopted in safety critical domains such as medical imaging or autonomous drive.\nThus, it is necessary to understand the uncertainty of the model to effectively\nreduce accidents and losses due to misjudgment of the Deep Neural Networks\n(DNN). This can start by efficiently selecting data that could potentially\nmalfunction to the model. Traditionally, data collection and labeling have been\ndone manually, but recently test data selection methods have emerged that focus\non capturing samples that are not relevant to what the model had been learned.\nThey're selected based on the activation pattern of neurons in DNN, entropy\nminimization based on softmax output of the DL. However, these methods cannot\nquantitatively analyze the extent to which unseen samples are extrapolated from\nthe training data. Therefore, we propose To-hull Uncertainty and Closure Ratio,\nwhich measures an uncertainty of trained model based on the convex hull of\ntraining data. It can observe the positional relation between the convex hull\nof the learned data and an unseen sample and infer how extrapolate the sample\nis from the convex hull. To evaluate the proposed method, we conduct empirical\nstudies on popular datasets and DNN models, compared to state-of-the art test\nselection metrics. As a result of the experiment, the proposed To-hull\nUncertainty is effective in finding samples with unusual patterns (e.g.\nadversarial attack) compared to the existing test selection metric.",
      "tldr_zh": "该论文针对深度学习（Deep Learning）系统的不确定性测量问题，提出了一种基于训练集凸包（Convex Hull）的新方法，包括To-hull Uncertainty和Closure Ratio指标。这些指标通过分析训练数据凸包与未见样本的位置关系，量化样本相对于训练数据的外部程度，从而更有效地识别潜在错误或异常模式。与传统方法（如基于神经元激活或熵最小化）相比，实验结果显示，该方法在流行数据集和DNN模型上表现更优，尤其在检测对抗攻击等异常样本时提升了准确性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages",
      "pdf_url": "http://arxiv.org/pdf/2405.16082v1",
      "published_date": "2024-05-25 06:25:24 UTC",
      "updated_date": "2024-05-25 06:25:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:01:49.324238"
    },
    {
      "arxiv_id": "2405.16075v2",
      "title": "Continuous Temporal Domain Generalization",
      "title_zh": "连续时间域泛化",
      "authors": [
        "Zekun Cai",
        "Guangji Bai",
        "Renhe Jiang",
        "Xuan Song",
        "Liang Zhao"
      ],
      "abstract": "Temporal Domain Generalization (TDG) addresses the challenge of training\npredictive models under temporally varying data distributions. Traditional TDG\napproaches typically focus on domain data collected at fixed, discrete time\nintervals, which limits their capability to capture the inherent dynamics\nwithin continuous-evolving and irregularly-observed temporal domains. To\novercome this, this work formalizes the concept of Continuous Temporal Domain\nGeneralization (CTDG), where domain data are derived from continuous times and\nare collected at arbitrary times. CTDG tackles critical challenges including:\n1) Characterizing the continuous dynamics of both data and models, 2) Learning\ncomplex high-dimensional nonlinear dynamics, and 3) Optimizing and controlling\nthe generalization across continuous temporal domains. To address them, we\npropose a Koopman operator-driven continuous temporal domain generalization\n(Koodos) framework. We formulate the problem within a continuous dynamic system\nand leverage the Koopman theory to learn the underlying dynamics; the framework\nis further enhanced with a comprehensive optimization strategy equipped with\nanalysis and control driven by prior knowledge of the dynamics patterns.\nExtensive experiments demonstrate the effectiveness and efficiency of our\napproach. The code can be found at: https://github.com/Zekun-Cai/Koodos.",
      "tldr_zh": "这篇论文引入了 Continuous Temporal Domain Generalization (CTDG)，旨在解决传统 Temporal Domain Generalization (TDG) 在处理连续演化和不规则时间数据分布时的局限性。CTDG 面临的挑战包括表征数据和模型的连续动态、学习复杂高维非线性动态，以及优化跨连续时间域的泛化。为此，作者提出了一种基于 Koopman operator 的 Koodos 框架，利用 Koopman 理论学习底层动态，并通过优化策略增强泛化性能。实验结果显示，该方法在效率和效果上均优于基线，并提供了开源代码（https://github.com/Zekun-Cai/Koodos）。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.16075v2",
      "published_date": "2024-05-25 05:52:04 UTC",
      "updated_date": "2024-10-29 09:32:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:02:02.046338"
    },
    {
      "arxiv_id": "2405.16072v4",
      "title": "SynthAI: A Multi Agent Generative AI Framework for Automated Modular HLS Design Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Seyed Arash Sheikholeslam",
        "Andre Ivanov"
      ],
      "abstract": "In this paper, we introduce SynthAI, a new method for the automated creation\nof High-Level Synthesis (HLS) designs. SynthAI integrates ReAct agents,\nChain-of-Thought (CoT) prompting, web search technologies, and the\nRetrieval-Augmented Generation (RAG) framework within a structured decision\ngraph. This innovative approach enables the systematic decomposition of complex\nhardware design tasks into multiple stages and smaller, manageable modules. As\na result, SynthAI produces synthesizable designs that closely adhere to\nuser-specified design objectives and functional requirements. We further\nvalidate the capabilities of SynthAI through several case studies, highlighting\nits proficiency in generating complex, multi-module logic designs from a single\ninitial prompt. The SynthAI code is provided via the following repo:\n\\url{https://github.com/sarashs/FPGA_AGI}",
      "tldr_zh": "本文介绍了 SynthAI，一种多智能体生成 AI 框架，用于自动化模块化 High-Level Synthesis (HLS) 设计生成。SynthAI 通过整合 ReAct agents、Chain-of-Thought (CoT) prompting、web search 技术和 Retrieval-Augmented Generation (RAG) 框架，以及结构化决策图，将复杂硬件设计任务分解成多个阶段和可管理模块，从而生成符合用户指定目标和功能要求的合成设计。通过几个案例研究，验证了 SynthAI 的效能，能够从单一初始提示高效创建复杂多模块逻辑设计，并提供了开源代码仓库。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "This work is in progress and we will be updating it",
      "pdf_url": "http://arxiv.org/pdf/2405.16072v4",
      "published_date": "2024-05-25 05:45:55 UTC",
      "updated_date": "2024-09-23 14:38:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:02:14.718089"
    },
    {
      "arxiv_id": "2405.17492v2",
      "title": "StatWhy: Formal Verification Tool for Statistical Hypothesis Testing Programs",
      "title_zh": "StatWhy：用于统计假设检验程序的形式验证工具",
      "authors": [
        "Yusuke Kawamoto",
        "Kentaro Kobayashi",
        "Kohei Suenaga"
      ],
      "abstract": "Statistical methods have been widely misused and misinterpreted in various\nscientific fields, raising significant concerns about the integrity of\nscientific research. To mitigate this problem, we propose a new method for\nformally specifying and automatically verifying the correctness of statistical\nprograms. In this method, programmers are required to annotate the source code\nof the statistical programs with the requirements for these methods. Through\nthis annotation, they are reminded to check the requirements for statistical\nmethods, including those that cannot be formally verified, such as the\ndistribution of the unknown true population. Our software tool StatWhy\nautomatically checks whether programmers have properly specified the\nrequirements for the statistical methods, thereby identifying any missing\nrequirements that need to be addressed. This tool is implemented using the Why3\nplatform to verify the correctness of OCaml programs that conduct statistical\nhypothesis testing. We demonstrate how StatWhy can be used to avoid common\nerrors in various popular statistical hypothesis testing programs.",
      "tldr_zh": "这篇论文提出了 StatWhy，一种用于统计假设测试程序的正式验证工具，旨在解决统计方法在科学领域的误用和误解问题。程序员需在源代码中注解统计方法的各项要求，包括无法正式验证的部分（如未知真实总体分布），以提醒检查完整性；StatWhy 自动检查这些注解，识别任何缺失要求。该工具基于 Why3 平台，针对 OCaml 程序进行验证，并通过示例展示了如何避免常见统计假设测试错误，从而提升研究完整性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17492v2",
      "published_date": "2024-05-25 05:07:33 UTC",
      "updated_date": "2024-11-01 16:16:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:02:25.085980"
    },
    {
      "arxiv_id": "2405.16051v1",
      "title": "A Bi-Objective Approach to Last-Mile Delivery Routing Considering Driver Preferences",
      "title_zh": "翻译失败",
      "authors": [
        "Juan Pablo Mesa",
        "Alejandro Montoya",
        "Raul Ramos-Pollán",
        "Mauricio Toro"
      ],
      "abstract": "The Multi-Objective Vehicle Routing Problem (MOVRP) is a complex optimization\nproblem in the transportation and logistics industry. This paper proposes a\nnovel approach to the MOVRP that aims to create routes that consider drivers'\nand operators' decisions and preferences. We evaluate two approaches to address\nthis objective: visually attractive route planning and data mining of\nhistorical driver behavior to plan similar routes. Using a real-world dataset\nprovided by Amazon, we demonstrate that data mining of historical patterns is\nmore effective than visual attractiveness metrics found in the literature.\nFurthermore, we propose a bi-objective problem to balance the similarity of\nroutes to historical routes and minimize routing costs. We propose a two-stage\nGRASP algorithm with heuristic box splitting to solve this problem. The\nproposed algorithm aims to approximate the Pareto front and to present routes\nthat cover a wide range of the objective function space. The results\ndemonstrate that our approach can generate a small number of non-dominated\nsolutions per instance, which can help decision-makers to identify trade-offs\nbetween routing costs and drivers' preferences. Our approach has the potential\nto enhance the last-mile delivery operations of logistics companies by\nbalancing these conflicting objectives.",
      "tldr_zh": "这篇论文针对多目标车辆路径问题(MOVRP)提出了一种新方法，旨在优化最后一英里配送路由，同时考虑驾驶员偏好。作者比较了视觉吸引度路线规划和基于历史驾驶员行为的数据挖掘两种方式，发现数据挖掘更有效，并定义了一个双目标优化问题，以平衡路线与历史路线的相似性及最小化路由成本。论文开发了一个两阶段 GRASP 算法，结合启发式箱分割来逼近 Pareto 前沿，结果显示该方法能生成少量非占优解，帮助决策者权衡成本与偏好，从而提升物流公司的配送操作效率。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16051v1",
      "published_date": "2024-05-25 04:25:00 UTC",
      "updated_date": "2024-05-25 04:25:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:02:38.516026"
    },
    {
      "arxiv_id": "2405.16041v3",
      "title": "Explainable Molecular Property Prediction: Aligning Chemical Concepts with Predictions via Language Models",
      "title_zh": "可解释分子属性预测：通过语言模型将化学概念与预测对齐",
      "authors": [
        "Zhenzhong Wang",
        "Zehui Lin",
        "Wanyu Lin",
        "Ming Yang",
        "Minggang Zeng",
        "Kay Chen Tan"
      ],
      "abstract": "Providing explainable molecular property predictions is critical for many\nscientific domains, such as drug discovery and material science. Though\ntransformer-based language models have shown great potential in accurate\nmolecular property prediction, they neither provide chemically meaningful\nexplanations nor faithfully reveal the molecular structure-property\nrelationships. In this work, we develop a framework for explainable molecular\nproperty prediction based on language models, dubbed as Lamole, which can\nprovide chemical concepts-aligned explanations. We take a string-based\nmolecular representation -- Group SELFIES -- as input tokens to pretrain and\nfine-tune our Lamole, as it provides chemically meaningful semantics. By\ndisentangling the information flows of Lamole, we propose combining\nself-attention weights and gradients for better quantification of each\nchemically meaningful substructure's impact on the model's output. To make the\nexplanations more faithfully respect the structure-property relationship, we\nthen carefully craft a marginal loss to explicitly optimize the explanations to\nbe able to align with the chemists' annotations. We bridge the manifold\nhypothesis with the elaborated marginal loss to prove that the loss can align\nthe explanations with the tangent space of the data manifold, leading to\nconcept-aligned explanations. Experimental results over six mutagenicity\ndatasets and one hepatotoxicity dataset demonstrate Lamole can achieve\ncomparable classification accuracy and boost the explanation accuracy by up to\n14.3%, being the state-of-the-art in explainable molecular property prediction.",
      "tldr_zh": "本研究提出了一种基于语言模型的框架Lamole，用于可解释的分子属性预测，旨在解决现有模型在化学概念解释和结构-属性关系揭示方面的不足。Lamole使用Group SELFIES作为输入表示，以提供化学意义语义，并通过结合self-attention weights和gradients来量化每个化学子结构的输出影响。为提升解释的准确性，该框架引入marginal loss优化解释，使其与化学家注释对齐，并通过manifold hypothesis证明loss能使解释与数据流形的切空间对齐。实验在六个致突变性数据集和一个肝毒性数据集上显示，Lamole实现了与现有方法相当的分类准确率，并将解释准确率最高提升14.3%，成为最先进的解释性分子属性预测方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16041v3",
      "published_date": "2024-05-25 03:27:04 UTC",
      "updated_date": "2024-10-02 03:52:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:02:49.865593"
    },
    {
      "arxiv_id": "2405.17489v1",
      "title": "On the Inflation of KNN-Shapley Value",
      "title_zh": "翻译失败",
      "authors": [
        "Ziao Yang",
        "Han Yue",
        "Jian Chen",
        "Hongfu Liu"
      ],
      "abstract": "Shapley value-based data valuation methods, originating from cooperative game\ntheory, quantify the usefulness of each individual sample by considering its\ncontribution to all possible training subsets. Despite their extensive\napplications, these methods encounter the challenge of value inflation - while\nsamples with negative Shapley values are detrimental, some with positive values\ncan also be harmful. This challenge prompts two fundamental questions: the\nsuitability of zero as a threshold for distinguishing detrimental from\nbeneficial samples and the determination of an appropriate threshold. To\naddress these questions, we focus on KNN-Shapley and propose Calibrated\nKNN-Shapley (CKNN-Shapley), which calibrates zero as the threshold to\ndistinguish detrimental samples from beneficial ones by mitigating the negative\neffects of small-sized training subsets. Through extensive experiments, we\ndemonstrate the effectiveness of CKNN-Shapley in alleviating data valuation\ninflation, detecting detrimental samples, and assessing data quality. We also\nextend our approach beyond conventional classification settings, applying it to\ndiverse and practical scenarios such as learning with mislabeled data, online\nlearning with stream data, and active learning for label annotation.",
      "tldr_zh": "本文研究了基于 Shapley value 的数据估值方法在处理价值膨胀问题时面临的挑战，特别是 KNN-Shapley 中正值样本可能有害的问题，并质疑零作为区分有害和有益样本阈值的适宜性。为此，作者提出 Calibrated KNN-Shapley (CKNN-Shapley) 方法，通过缓解小训练子集的负面影响来校准阈值。实验结果显示，该方法显著降低了价值膨胀，提升了有害样本检测和数据质量评估的准确性，并扩展应用到错误标记数据、在线学习和主动学习等实际场景中。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17489v1",
      "published_date": "2024-05-25 03:26:33 UTC",
      "updated_date": "2024-05-25 03:26:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:03:02.343298"
    },
    {
      "arxiv_id": "2405.16039v2",
      "title": "MoEUT: Mixture-of-Experts Universal Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Róbert Csordás",
        "Kazuki Irie",
        "Jürgen Schmidhuber",
        "Christopher Potts",
        "Christopher D. Manning"
      ],
      "abstract": "Previous work on Universal Transformers (UTs) has demonstrated the importance\nof parameter sharing across layers. By allowing recurrence in depth, UTs have\nadvantages over standard Transformers in learning compositional\ngeneralizations, but layer-sharing comes with a practical limitation of\nparameter-compute ratio: it drastically reduces the parameter count compared to\nthe non-shared model with the same dimensionality. Naively scaling up the layer\nsize to compensate for the loss of parameters makes its computational resource\nrequirements prohibitive. In practice, no previous work has succeeded in\nproposing a shared-layer Transformer design that is competitive in parameter\ncount-dominated tasks such as language modeling. Here we propose MoEUT\n(pronounced \"moot\"), an effective mixture-of-experts (MoE)-based shared-layer\nTransformer architecture, which combines several recent advances in MoEs for\nboth feedforward and attention layers of standard Transformers together with\nnovel layer-normalization and grouping schemes that are specific and crucial to\nUTs. The resulting UT model, for the first time, slightly outperforms standard\nTransformers on language modeling tasks such as BLiMP and PIQA, while using\nsignificantly less compute and memory.",
      "tldr_zh": "该研究提出 MoEUT，一种基于 Mixture-of-Experts (MoE) 的共享层 Universal Transformers (UTs) 架构，以解决 UTs 参数共享导致的参数减少问题，同时保持计算效率。MoEUT 整合了 MoE 技术应用于标准 Transformers 的前馈和注意力层，并引入了特定于 UTs 的新型层归一化和分组方案。实验结果显示，MoEUT 在语言建模任务如 BLiMP 和 PIQA 上首次略微优于标准 Transformers，同时显著减少了计算和内存资源需求。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.16039v2",
      "published_date": "2024-05-25 03:24:32 UTC",
      "updated_date": "2024-10-13 04:46:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:03:17.033668"
    },
    {
      "arxiv_id": "2405.16003v2",
      "title": "Disentangling Heterogeneous Knowledge Concept Embedding for Cognitive Diagnosis on Untested Knowledge",
      "title_zh": "翻译失败",
      "authors": [
        "Miao Zhang",
        "Ziming Wang",
        "Runtian Xing",
        "Kui Xiao",
        "Zhifei Li",
        "Yan Zhang",
        "Chang Tang"
      ],
      "abstract": "Cognitive diagnosis is a fundamental and critical task in learning\nassessment, which aims to infer students' proficiency on knowledge concepts\nfrom their response logs. Current works assume each knowledge concept will\ncertainly be tested and covered by multiple exercises. However, whether online\nor offline courses, it's hardly feasible to completely cover all knowledge\nconcepts in several exercises. Restricted tests lead to undiscovered knowledge\ndeficits, especially untested knowledge concepts(UKCs). In this paper, we\npropose a novel framework for Cognitive Diagnosis called Disentangling\nHeterogeneous Knowledge Cognitive Diagnosis(DisKCD) on untested knowledge.\nSpecifically, we leverage course grades, exercise questions, and learning\nresources to learn the potential representations of students, exercises, and\nknowledge concepts. In particular, knowledge concepts are disentangled into\ntested and untested based on the limiting actual exercises. We construct a\nheterogeneous relation graph network via students, exercises, tested knowledge\nconcepts(TKCs), and UKCs. Then, through a hierarchical heterogeneous\nmessage-passing mechanism, the fine-grained relations are incorporated into the\nembeddings of the entities. Finally, the embeddings will be applied to multiple\nexisting cognitive diagnosis models to infer students' proficiency on UKCs.\nExperimental results on real-world datasets show that the proposed model can\neffectively improve the performance of the task of diagnosing students'\nproficiency on UKCs. Our code is available at\nhttps://github.com/Hubuers/DisKCD.",
      "tldr_zh": "本论文针对认知诊断（Cognitive Diagnosis）中的未测试知识概念（UKCs）问题，提出了一种新型框架DisKCD，通过分离异构知识概念嵌入来推断学生在UKCs上的熟练度。框架利用课程成绩、练习题和学习资源构建异构关系图网络，包括学生、练习、已测试知识概念（TKCs）和UKCs，并通过分层异构消息传递机制整合细粒度关系以优化实体嵌入。实验结果显示，DisKCD显著提升了在真实数据集上诊断UKCs性能的表现，证明了其有效性。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16003v2",
      "published_date": "2024-05-25 01:49:54 UTC",
      "updated_date": "2024-10-18 02:57:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:03:27.041000"
    },
    {
      "arxiv_id": "2405.16000v1",
      "title": "Carnatic Raga Identification System using Rigorous Time-Delay Neural Network",
      "title_zh": "基于严谨时延",
      "authors": [
        "Sanjay Natesan",
        "Homayoon Beigi"
      ],
      "abstract": "Large scale machine learning-based Raga identification continues to be a\nnontrivial issue in the computational aspects behind Carnatic music. Each raga\nconsists of many unique and intrinsic melodic patterns that can be used to\neasily identify them from others. These ragas can also then be used to cluster\nsongs within the same raga, as well as identify songs in other closely related\nragas. In this case, the input sound is analyzed using a combination of steps\nincluding using a Discrete Fourier transformation and using Triangular\nFiltering to create custom bins of possible notes, extracting features from the\npresence of particular notes or lack thereof. Using a combination of Neural\nNetworks including 1D Convolutional Neural Networks conventionally known as\nTime-Delay Neural Networks) and Long Short-Term Memory (LSTM), which are a form\nof Recurrent Neural Networks, the backbone of the classification strategy to\nbuild the model can be created. In addition, to help with variations in shruti,\na long-time attention-based mechanism will be implemented to determine the\nrelative changes in frequency rather than the absolute differences. This will\nprovide a much more meaningful data point when training audio clips in\ndifferent shrutis. To evaluate the accuracy of the classifier, a dataset of 676\nrecordings is used. The songs are distributed across the list of ragas. The\ngoal of this program is to be able to effectively and efficiently label a much\nwider range of audio clips in more shrutis, ragas, and with more background\nnoise.",
      "tldr_zh": "这篇论文提出了一种基于 Time-Delay Neural Networks 的 Carnatic Raga 识别系统，用于解决 Carnatic 音乐中大规模机器学习识别的难题，通过分析独特旋律模式来区分不同 Raga。系统采用 Discrete Fourier Transformation 和 Triangular Filtering 来创建自定义音符 bins，并提取音符存在或缺失的特征，然后结合 1D Convolutional Neural Networks 和 Long Short-Term Memory (LSTM) 模型构建分类 backbone，同时引入基于注意力的机制处理 shruti 变化，关注频率的相对差异。实验在 676 个录音数据集上进行评估，目标是高效识别更多 ragas、shrutis 和背景噪声下的音频。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "cs.MM",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "7 pages, 2 tables, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.16000v1",
      "published_date": "2024-05-25 01:31:58 UTC",
      "updated_date": "2024-05-25 01:31:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:03:39.663942"
    },
    {
      "arxiv_id": "2405.15994v2",
      "title": "Verified Safe Reinforcement Learning for Neural Network Dynamic Models",
      "title_zh": "针对神经网络动态模型的验证安全强化学习",
      "authors": [
        "Junlin Wu",
        "Huan Zhang",
        "Yevgeniy Vorobeychik"
      ],
      "abstract": "Learning reliably safe autonomous control is one of the core problems in\ntrustworthy autonomy. However, training a controller that can be formally\nverified to be safe remains a major challenge. We introduce a novel approach\nfor learning verified safe control policies in nonlinear neural dynamical\nsystems while maximizing overall performance. Our approach aims to achieve\nsafety in the sense of finite-horizon reachability proofs, and is comprised of\nthree key parts. The first is a novel curriculum learning scheme that\niteratively increases the verified safe horizon. The second leverages the\niterative nature of gradient-based learning to leverage incremental\nverification, reusing information from prior verification runs. Finally, we\nlearn multiple verified initial-state-dependent controllers, an idea that is\nespecially valuable for more complex domains where learning a single universal\nverified safe controller is extremely challenging. Our experiments on five safe\ncontrol problems demonstrate that our trained controllers can achieve verified\nsafety over horizons that are as much as an order of magnitude longer than\nstate-of-the-art baselines, while maintaining high reward, as well as a perfect\nsafety record over entire episodes. Our code is available at\nhttps://github.com/jlwu002/VSRL.",
      "tldr_zh": "本研究提出了一种新方法，用于在神经网络动态系统中学习验证安全的强化学习(Reinforcement Learning)控制器，同时最大化整体性能，以实现有限时限的可达性证明(Safe in the sense of finite-horizon reachability proofs)。该方法包括三个关键部分：一个迭代式课程学习方案逐步增加验证安全时限、利用梯度-based 学习的增量验证重用先前信息，以及学习多个依赖初始状态的控制器，以应对复杂领域挑战。实验结果显示，在五个安全控制问题上，该方法训练的控制器实现了比现有基线高出一个数量级的验证安全时限，同时保持高奖励和全程完美安全记录。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.15994v2",
      "published_date": "2024-05-25 00:35:39 UTC",
      "updated_date": "2024-11-16 04:21:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:03:50.238292"
    },
    {
      "arxiv_id": "2405.15991v2",
      "title": "Rényi Neural Processes",
      "title_zh": "翻译失败",
      "authors": [
        "Xuesong Wang",
        "He Zhao",
        "Edwin V. Bonilla"
      ],
      "abstract": "Neural Processes (NPs) are deep probabilistic models that represent\nstochastic processes by conditioning their prior distributions on a set of\ncontext points. Despite their obvious advantages in uncertainty estimation for\ncomplex distributions, NPs enforce parameterization coupling between the\nconditional prior model and the posterior model, thereby risking introducing a\nmisspecified prior distribution. We hereby revisit the NP objectives and\npropose R\\'enyi Neural Processes (RNP) to ameliorate the impacts of prior\nmisspecification by optimizing an alternative posterior that achieves better\nmarginal likelihood. More specifically, by replacing the standard KL divergence\nwith the R\\'enyi divergence between the model posterior and the true posterior,\nwe scale the density ratio $\\frac{p}{q}$ by the power of (1-$\\alpha$) in the\ndivergence gradients with respect to the posterior. This hyper parameter\n$\\alpha$ allows us to dampen the effects of the misspecified prior for the\nposterior update, which has been shown to effectively avoid oversmoothed\npredictions and improve the expressiveness of the posterior model. Our\nextensive experiments show consistent log-likelihood improvements over\nstate-of-the-art NP family models which adopt both the variational inference or\nmaximum likelihood estimation objectives. We validate the effectiveness of our\napproach across multiple benchmarks including regression and image inpainting\ntasks, and show significant performance improvements of RNPs in real-world\nregression problems where the underlying prior model is misspecifed.",
      "tldr_zh": "本论文提出 Rényi Neural Processes (RNP)，一种改进 Neural Processes (NPs) 的深度概率模型，通过优化后验分布来缓解先验分布错误指定的问题。RNP 方法将标准 KL divergence 替换为 Rényi divergence，利用超参数 α 缩放密度比（$\\frac{p}{q}$ 的 $(1-\\alpha)$ 次幂），从而减弱错误先验对后验更新的影响，提高后验模型的表达性和避免预测过度平滑。实验结果显示，RNP 在回归和图像修复任务的多个基准上，比现有 NPs 模型（如基于变分推理或最大似然估计的版本）显著提升对数似然，尤其在先验错误指定的真实回归问题中表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.15991v2",
      "published_date": "2024-05-25 00:14:55 UTC",
      "updated_date": "2024-10-03 09:33:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:04:02.663879"
    },
    {
      "arxiv_id": "2405.15988v1",
      "title": "Transductive Confidence Machine and its application to Medical Data Sets",
      "title_zh": "翻译失败",
      "authors": [
        "David Lindsay"
      ],
      "abstract": "The Transductive Confidence Machine Nearest Neighbours (TCMNN) algorithm and\na supporting, simple user interface was developed. Different settings of the\nTCMNN algorithms' parameters were tested on medical data sets, in addition to\nthe use of different Minkowski metrics and polynomial kernels. The effect of\nincreasing the number of nearest neighbours and marking results with\nsignificance was also investigated. SVM implementation of the Transductive\nConfidence Machine was compared with Nearest Neighbours implementation. The\napplication of neural networks was investigated as a useful comparison to the\ntransductive algorithms.",
      "tldr_zh": "该论文介绍了 Transductive Confidence Machine Nearest Neighbours (TCMNN) 算法及其简单用户界面，旨在应用于医疗数据集。研究者测试了 TCMNN 的不同参数设置，包括 Minkowski metrics 和 polynomial kernels，并探讨了增加最近邻居数量以及结果显著性标记的影响。与 SVM 实现的 Transductive Confidence Machine 进行了比较，并使用神经网络作为基准，以评估算法性能。总体而言，此工作展示了 TCMNN 在医疗数据处理中的潜力，提供了一个可靠的置信度评估框架。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "160 pages",
      "pdf_url": "http://arxiv.org/pdf/2405.15988v1",
      "published_date": "2024-05-25 00:02:15 UTC",
      "updated_date": "2024-05-25 00:02:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:04:14.487112"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 62,
  "processed_papers_count": 62,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-18T12:04:35.886472"
}