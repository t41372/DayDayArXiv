{
  "date": "2025-05-12",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-05-12 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦于 AI 模型的自提升、安全性、应用以及强化学习等领域，突出 LLM 在道德推理和高效训练中的创新，令人印象深刻的包括 LLM 自奖励机制和多代理强化学习的论文，而著名学者如 Dorsa Sadigh 和 Chelsea Finn 的作品则展现了机器人领域的最新进展。\n\n### 重点论文讨论\n我将优先选取重要、话题性和影响力高的论文进行简要分析，将相关主题归类讨论，并快速掠过一些技术性较弱或重复性的内容。以下按主题分组，突出核心贡献。\n\n#### LLM 自提升与安全\n- **Self Rewarding Self Improving (自奖励自提升)**  \n  作者：Toby Simonds 等。论文展示 LLM 通过自判断机制（如生成与验证的不对称性）实现自提升，在无需参考答案的情况下，通过强化学习在 Countdown 谜题和 MIT 积分问题上提升性能，实现了 8% 的改进并超越 GPT-4o。该发现暗示 AI 系统可实现自主学习，减少对人工训练的依赖。\n\n- **Are LLMs complicated ethical dilemma analyzers? (LLM 是否是复杂的道德困境分析器？)**  \n  作者：Jiashen Du 等。论文构建了一个包含 196 个真实道德困境的基准数据集，评估 LLM（如 GPT-4o-mini）在道德推理中的表现。LLM 在词汇和结构上优于人类，但挣扎于历史背景和细致策略，强调 LLM 在道德决策中的局限性。\n\n这些论文揭示了 LLM 在自我优化和伦理方面的潜力，但也暴露了安全风险，相关工作如 FalseReject（通过结构化推理缓解 LLM 过度拒绝）则快速扩展了这一主题，提供数据集来改进 LLM 的安全响应。\n\n#### 机器人与计算机视觉\n- **SLAG: Scalable Language-Augmented Gaussian Splatting (可扩展语言增强高斯散射)**  \n  作者：Laszlo Szilagyi 等。论文提出 SLAG 框架，用于机器人场景编码，结合 2D 视觉语言模型（如 SAM 和 CLIP）生成高效的 3D 嵌入，实现 18 倍速度提升，同时保持嵌入质量。该方法适用于大规模机器人应用，如搜索救援。\n\n- **What Matters for Batch Online Reinforcement Learning in Robotics? (批量在线强化学习在机器人中的关键因素？)**  \n  作者：Perry Dong, Dorsa Sadigh, Chelsea Finn 等。论文通过系统实验分析算法类、策略提取和策略表达性，提出优化强化学习配方，包括使用 Q 函数和时间相关噪声，提升机器人任务性能。该工作由著名学者 Sadigh 和 Finn 领导，在实际机器人任务中实现显著改进。\n\n- **Multi-source Plume Tracing via Multi-Agent Reinforcement Learning (多源羽流追踪的多代理强化学习)**  \n  作者：Pedro Antonio Alarcon Granadeno 等。论文开发 MARL 算法，用于无人机追踪污染源，在模拟环境中仅探索 1.29% 的区域即可定位，显著优于传统方法。该发现适用于环境监测，如 Bhopal 灾难响应。\n\n机器人领域的这些论文强调多代理协作和高效视觉处理，PRISM（多任务多代理路径规划）等相关工作则快速掠过，其在动态路径规划中的鲁棒性值得关注。\n\n#### 医学与生物信息\n- **JSover: Joint Spectrum Estimation and Multi-Material Decomposition from Single-Energy CT Projections (联合光谱估计和多材料分解从单能 CT 投影)**  \n  作者：Qing Wu 等。论文提出 JSover 框架，直接从单能 CT 投影重建多材料成分，结合物理先验和隐式神经表示，提高分解准确性和效率。该方法在模拟和真实数据集上超越现有技术，适用于临床图像分析。\n\n- **A Comparative Study of Transformer-Based Models for Multi-Horizon Blood Glucose Prediction (基于 Transformer 模型的多时序血糖预测比较研究)**  \n  作者：Meryem Altin Karagoz 等。论文比较 Transformer 模型在血糖预测中的表现，PatchTST 在长时预测中表现出色，RMSE 低至 15.6 mg/dL。该发现有助于糖尿病管理，但其他医学论文如 Probabilistic approach to longitudinal response prediction 等则简要提及，其在放射组学中的不确定性建模贡献较小。\n\n这些工作突出了 AI 在医疗中的潜力，但整体主题较为专业，我仅选取了高影响力的部分。\n\n#### 图形神经网络与强化学习\n- **Graph Neural Networks and MSO (图形神经网络和一阶逻辑片段)**  \n  作者：Bernardo Cuenca Grau 等。论文证明有界 GNN 与一阶逻辑片段（如模态逻辑）对应，提供统一框架理解 GNN 的表达能力。该理论贡献显著，连接计算语言学和图形学习。\n\n- **Explainable Reinforcement Learning Agents Using World Models (使用世界模型的可解释强化学习代理)**  \n  作者：Madhuri Singh, Mark O. Riedl 等。论文引入反向世界模型生成反事实轨迹，提高代理决策的可解释性。该方法通过模拟环境变化提升用户理解，相关于道德 AI。\n\n强化学习论文众多，如 Gradient Sparse Autoencoders 等快速掠过，其在 LLM 解释中的梯度优化虽有趣，但影响力不及上述。\n\n其他论文如 Large Language Models and Arabic Content（LLM 在阿拉伯 NLP 中的应用）和 Benchmarking Retrieval-Augmented Generation for Chemistry（化学领域的检索增强生成）等，主题虽多样但不为核心，我仅简要提到其在跨语言和科学领域的基准贡献。\n\n总之，今天的 arXiv 论文展示了 AI 领域的多样创新，LLM 的自提升和机器人应用尤为突出，期待这些进展推动更安全、智能的系统。更多细节可查阅具体论文！",
  "papers": [
    {
      "arxiv_id": "2505.08827v1",
      "title": "Self Rewarding Self Improving",
      "title_zh": "自我奖励自我改进",
      "authors": [
        "Toby Simonds",
        "Kevin Lopez",
        "Akira Yoshiyama",
        "Dominique Garmier"
      ],
      "abstract": "We demonstrate that large language models can effectively self-improve\nthrough self-judging without requiring reference solutions, leveraging the\ninherent asymmetry between generating and verifying solutions. Our experiments\non Countdown puzzles and MIT Integration Bee problems show that models can\nprovide reliable reward signals without ground truth answers, enabling\nreinforcement learning in domains previously not possible. By implementing\nself-judging, we achieve significant performance gains maintaining alignment\nwith formal verification. When combined with synthetic question generation, we\nestablish a complete self-improvement loop where models generate practice\nproblems, solve them, and evaluate their own performance-achieving an 8%\nimprovement with Qwen 2.5 7B over baseline and surpassing GPT-4o performance on\nintegration tasks. Our findings demonstrate that LLM judges can provide\neffective reward signals for training models, unlocking many reinforcement\nlearning environments previously limited by the difficulty of creating\nprogrammatic rewards. This suggests a potential paradigm shift toward AI\nsystems that continuously improve through self-directed learning rather than\nhuman-guided training, potentially accelerating progress in domains with scarce\ntraining data or complex evaluation requirements.",
      "tldr_zh": "本研究证明，大语言模型（LLMs）可以通过自我判断（self-judging）实现自我改进，而无需参考解决方案，利用生成和验证解决方案的内在不对称性。在Countdown puzzles和MIT Integration Bee问题上，实验显示LLMs能提供可靠的奖励信号，并通过结合合成问题生成，形成一个完整的自我改进循环，包括生成问题、解决问题和自我评估。结果表明，Qwen 2.5 7B模型比基线提升8%，并在积分任务上超越GPT-4o性能。这一发现为reinforcement learning环境打开新可能，推动AI系统转向自我导向学习，加速稀缺数据或复杂评估领域的进展。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08827v1",
      "published_date": "2025-05-12 23:51:04 UTC",
      "updated_date": "2025-05-12 23:51:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:36:52.303645"
    },
    {
      "arxiv_id": "2505.08124v1",
      "title": "SLAG: Scalable Language-Augmented Gaussian Splatting",
      "title_zh": "SLAG：可扩展语言增强高斯喷溅",
      "authors": [
        "Laszlo Szilagyi",
        "Francis Engelmann",
        "Jeannette Bohg"
      ],
      "abstract": "Language-augmented scene representations hold great promise for large-scale\nrobotics applications such as search-and-rescue, smart cities, and mining. Many\nof these scenarios are time-sensitive, requiring rapid scene encoding while\nalso being data-intensive, necessitating scalable solutions. Deploying these\nrepresentations on robots with limited computational resources further adds to\nthe challenge. To address this, we introduce SLAG, a multi-GPU framework for\nlanguage-augmented Gaussian splatting that enhances the speed and scalability\nof embedding large scenes. Our method integrates 2D visual-language model\nfeatures into 3D scenes using SAM and CLIP. Unlike prior approaches, SLAG\neliminates the need for a loss function to compute per-Gaussian language\nembeddings. Instead, it derives embeddings from 3D Gaussian scene parameters\nvia a normalized weighted average, enabling highly parallelized scene encoding.\nAdditionally, we introduce a vector database for efficient embedding storage\nand retrieval. Our experiments show that SLAG achieves an 18 times speedup in\nembedding computation on a 16-GPU setup compared to OpenGaussian, while\npreserving embedding quality on the ScanNet and LERF datasets. For more\ndetails, visit our project website: https://slag-project.github.io/.",
      "tldr_zh": "该研究提出 SLAG，一种可扩展的语言增强高斯喷溅(Gaussian Splatting)框架，旨在加速大型场景嵌入以支持时间敏感的机器人应用，如搜索救援和智能城市。SLAG 通过整合 SAM 和 CLIP 的 2D 视觉语言模型特征，并采用归一化加权平均从 3D 高斯场景参数派生嵌入，而非依赖损失函数，实现高度并行化和多 GPU 优化，同时引入向量数据库提升存储及检索效率。实验结果显示，在 16-GPU 设置下，SLAG 相较 OpenGaussian 实现了 18 倍的计算速度提升，同时在 ScanNet 和 LERF 数据集上保持嵌入质量。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08124v1",
      "published_date": "2025-05-12 23:32:24 UTC",
      "updated_date": "2025-05-12 23:32:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:36:54.836274"
    },
    {
      "arxiv_id": "2505.08123v1",
      "title": "JSover: Joint Spectrum Estimation and Multi-Material Decomposition from Single-Energy CT Projections",
      "title_zh": "JSover：基于单能量 CT 投影的联合光谱估计与多材料分解",
      "authors": [
        "Qing Wu",
        "Hongjiang Wei",
        "Jingyi Yu",
        "S. Kevin Zhou",
        "Yuyao Zhang"
      ],
      "abstract": "Multi-material decomposition (MMD) enables quantitative reconstruction of\ntissue compositions in the human body, supporting a wide range of clinical\napplications. However, traditional MMD typically requires spectral CT scanners\nand pre-measured X-ray energy spectra, significantly limiting clinical\napplicability. To this end, various methods have been developed to perform MMD\nusing conventional (i.e., single-energy, SE) CT systems, commonly referred to\nas SEMMD. Despite promising progress, most SEMMD methods follow a two-step\nimage decomposition pipeline, which first reconstructs monochromatic CT images\nusing algorithms such as FBP, and then performs decomposition on these images.\nThe initial reconstruction step, however, neglects the energy-dependent\nattenuation of human tissues, introducing severe nonlinear beam hardening\nartifacts and noise into the subsequent decomposition. This paper proposes\nJSover, a fundamentally reformulated one-step SEMMD framework that jointly\nreconstructs multi-material compositions and estimates the energy spectrum\ndirectly from SECT projections. By explicitly incorporating physics-informed\nspectral priors into the SEMMD process, JSover accurately simulates a virtual\nspectral CT system from SE acquisitions, thereby improving the reliability and\naccuracy of decomposition. Furthermore, we introduce implicit neural\nrepresentation (INR) as an unsupervised deep learning solver for representing\nthe underlying material maps. The inductive bias of INR toward continuous image\npatterns constrains the solution space and further enhances estimation quality.\nExtensive experiments on both simulated and real CT datasets show that JSover\noutperforms state-of-the-art SEMMD methods in accuracy and computational\nefficiency.",
      "tldr_zh": "本研究针对多材料分解 (MMD) 在临床应用中的局限性，提出 JSover 框架，该框架从单能 CT (SECT) 投影直接联合估计能量谱和重建多材料成分，克服了传统两步 SEMMD 方法中重建步骤引入的 beam hardening artifacts 和噪声问题。JSover 通过整合基于物理的 spectral priors 模拟虚拟光谱 CT 系统，并利用 implicit neural representation (INR) 作为无监督深度学习求解器来约束解空间，提升分解的准确性和可靠性。实验结果显示，在模拟和真实 CT 数据集上，JSover 比现有 SEMMD 方法在准确性和计算效率上表现出显著优势。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.08123v1",
      "published_date": "2025-05-12 23:32:21 UTC",
      "updated_date": "2025-05-12 23:32:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:36:55.855724"
    },
    {
      "arxiv_id": "2505.08106v1",
      "title": "Are LLMs complicated ethical dilemma analyzers?",
      "title_zh": "LLMs 是复杂的伦理困境分析器吗？",
      "authors": [
        "Jiashen",
        "Du",
        "Jesse Yao",
        "Allen Liu",
        "Zhekai Zhang"
      ],
      "abstract": "One open question in the study of Large Language Models (LLMs) is whether\nthey can emulate human ethical reasoning and act as believable proxies for\nhuman judgment. To investigate this, we introduce a benchmark dataset\ncomprising 196 real-world ethical dilemmas and expert opinions, each segmented\ninto five structured components: Introduction, Key Factors, Historical\nTheoretical Perspectives, Resolution Strategies, and Key Takeaways. We also\ncollect non-expert human responses for comparison, limited to the Key Factors\nsection due to their brevity. We evaluate multiple frontier LLMs (GPT-4o-mini,\nClaude-3.5-Sonnet, Deepseek-V3, Gemini-1.5-Flash) using a composite metric\nframework based on BLEU, Damerau-Levenshtein distance, TF-IDF cosine\nsimilarity, and Universal Sentence Encoder similarity. Metric weights are\ncomputed through an inversion-based ranking alignment and pairwise AHP\nanalysis, enabling fine-grained comparison of model outputs to expert\nresponses. Our results show that LLMs generally outperform non-expert humans in\nlexical and structural alignment, with GPT-4o-mini performing most consistently\nacross all sections. However, all models struggle with historical grounding and\nproposing nuanced resolution strategies, which require contextual abstraction.\nHuman responses, while less structured, occasionally achieve comparable\nsemantic similarity, suggesting intuitive moral reasoning. These findings\nhighlight both the strengths and current limitations of LLMs in ethical\ndecision-making.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)是否能模拟人类道德推理并作为人类判断的代理，通过引入一个包含196个真实道德困境的基准数据集（包括Introduction、Key Factors等五个部分）及其专家意见进行评估。研究方法包括收集非专家人类响应，并使用复合指标框架（如BLEU、Damerau-Levenshtein距离、TF-IDF余弦相似度和Universal Sentence Encoder相似度）来评估GPT-4o-mini、Claude-3.5-Sonnet等模型的性能。结果显示，LLMs在词汇和结构对齐上普遍优于非专家人类，但模型在处理历史理论背景和细致解决策略时表现欠佳，而人类响应则显示出直观的道德推理能力，突显了LLMs在伦理决策中的优势与局限。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "CS194-280 Advanced LLM Agents project. Project page:\n  https://github.com/ALT-JS/ethicaLLM",
      "pdf_url": "http://arxiv.org/pdf/2505.08106v1",
      "published_date": "2025-05-12 22:35:07 UTC",
      "updated_date": "2025-05-12 22:35:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:36:59.427280"
    },
    {
      "arxiv_id": "2505.08088v1",
      "title": "Graph-Based Floor Separation Using Node Embeddings and Clustering of WiFi Trajectories",
      "title_zh": "基于图的楼层分离：使用节点嵌入和 WiFi 轨迹聚类",
      "authors": [
        "Rabia Yasa Kostas",
        "Kahraman Kostas"
      ],
      "abstract": "Indoor positioning systems (IPSs) are increasingly vital for location-based\nservices in complex multi-storey environments. This study proposes a novel\ngraph-based approach for floor separation using Wi-Fi fingerprint trajectories,\naddressing the challenge of vertical localization in indoor settings. We\nconstruct a graph where nodes represent Wi-Fi fingerprints, and edges are\nweighted by signal similarity and contextual transitions. Node2Vec is employed\nto generate low-dimensional embeddings, which are subsequently clustered using\nK-means to identify distinct floors. Evaluated on the Huawei University\nChallenge 2021 dataset, our method outperforms traditional community detection\nalgorithms, achieving an accuracy of 68.97%, an F1- score of 61.99%, and an\nAdjusted Rand Index of 57.19%. By publicly releasing the preprocessed dataset\nand implementation code, this work contributes to advancing research in indoor\npositioning. The proposed approach demonstrates robustness to signal noise and\narchitectural complexities, offering a scalable solution for floor-level\nlocalization.",
      "tldr_zh": "该研究提出了一种基于图的楼层分离方法，使用 WiFi 指纹轨迹来解决室内定位系统在多层建筑中的垂直定位挑战。方法包括构建加权图（节点为 WiFi 指纹，边基于信号相似性和上下文转换）、应用 Node2Vec 生成低维嵌入，并使用 K-means 聚类来识别不同楼层。在 Huawei University Challenge 2021 数据集上，该方法优于传统社区检测算法，实现了 68.97% 的准确率、61.99% 的 F1-score 和 57.19% 的 Adjusted Rand Index，并展示了良好的鲁棒性和可扩展性。通过公开预处理数据集和代码，该工作推动了室内定位研究的进展。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.CR",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08088v1",
      "published_date": "2025-05-12 21:46:36 UTC",
      "updated_date": "2025-05-12 21:46:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:36:58.707522"
    },
    {
      "arxiv_id": "2505.08825v1",
      "title": "Multi-source Plume Tracing via Multi-Agent Reinforcement Learning",
      "title_zh": "通过多智能体强化学习的多源羽流追踪",
      "authors": [
        "Pedro Antonio Alarcon Granadeno",
        "Theodore Chambers",
        "Jane Cleland-Huang"
      ],
      "abstract": "Industrial catastrophes like the Bhopal disaster (1984) and the Aliso Canyon\ngas leak (2015) demonstrate the urgent need for rapid and reliable plume\ntracing algorithms to protect public health and the environment. Traditional\nmethods, such as gradient-based or biologically inspired approaches, often fail\nin realistic, turbulent conditions. To address these challenges, we present a\nMulti-Agent Reinforcement Learning (MARL) algorithm designed for localizing\nmultiple airborne pollution sources using a swarm of small uncrewed aerial\nsystems (sUAS). Our method models the problem as a Partially Observable Markov\nGame (POMG), employing a Long Short-Term Memory (LSTM)-based Action-specific\nDouble Deep Recurrent Q-Network (ADDRQN) that uses full sequences of historical\naction-observation pairs, effectively approximating latent states. Unlike prior\nwork, we use a general-purpose simulation environment based on the Gaussian\nPlume Model (GPM), incorporating realistic elements such as a three-dimensional\nenvironment, sensor noise, multiple interacting agents, and multiple plume\nsources. The incorporation of action histories as part of the inputs further\nenhances the adaptability of our model in complex, partially observable\nenvironments. Extensive simulations show that our algorithm significantly\noutperforms conventional approaches. Specifically, our model allows agents to\nexplore only 1.29\\% of the environment to successfully locate pollution\nsources.",
      "tldr_zh": "该论文针对工业灾难中的烟羽追踪问题，提出了一种基于 Multi-Agent Reinforcement Learning (MARL) 的算法，利用小型无人驾驶飞机（sUAS）群来定位多个空气污染源，以应对传统方法在湍流环境下的失效。方法将问题建模为 Partially Observable Markov Game (POMG)，并采用 Long Short-Term Memory (LSTM)-based Action-specific Double Deep Recurrent Q-Network (ADDRQN)，通过整合历史行动-观察序列和基于 Gaussian Plume Model (GPM) 的真实模拟环境，提升了代理的适应性和效率。实验结果显示，该算法显著优于传统方法，仅需探索环境的 1.29% 即可成功定位污染源，为公共健康和环境保护提供了更可靠的解决方案。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "13 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.08825v1",
      "published_date": "2025-05-12 21:33:15 UTC",
      "updated_date": "2025-05-12 21:33:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:37:05.414552"
    },
    {
      "arxiv_id": "2505.08082v1",
      "title": "Fréchet Power-Scenario Distance: A Metric for Evaluating Generative AI Models across Multiple Time-Scales in Smart Grids",
      "title_zh": "Fréchet Power-Scenario 距离：一种用于评估生成式 AI 模型在智能电网中跨多个时间尺度的度量",
      "authors": [
        "Yuting Cai",
        "Shaohuai Liu",
        "Chao Tian",
        "Le Xie"
      ],
      "abstract": "Generative artificial intelligence (AI) models in smart grids have advanced\nsignificantly in recent years due to their ability to generate large amounts of\nsynthetic data, which would otherwise be difficult to obtain in the real world\ndue to confidentiality constraints. A key challenge in utilizing such synthetic\ndata is how to assess the data quality produced from such generative models.\nTraditional Euclidean distance-based metrics only reflect pair-wise relations\nbetween two individual samples, and could fail in evaluating quality\ndifferences between groups of synthetic datasets. In this work, we propose a\nnovel metric based on the Fr\\'{e}chet Distance (FD) estimated between two\ndatasets in a learned feature space. The proposed method evaluates the quality\nof generation from a distributional perspective. Empirical results demonstrate\nthe superiority of the proposed metric across timescales and models, enhancing\nthe reliability of data-driven decision-making in smart grid operations.",
      "tldr_zh": "本文提出了一种名为 Fréchet Power-Scenario Distance 的新指标，用于评估生成式 AI 模型在智能电网中的合成数据质量。该指标基于 Fréchet Distance (FD)，通过在学习特征空间中计算数据集间的距离，从分布角度全面评估生成质量，克服了传统欧氏距离指标仅关注样本对关系的局限性。实验结果显示，该方法在不同时间尺度和技术上优于基线模型，提高了智能电网数据驱动决策的可靠性和准确性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08082v1",
      "published_date": "2025-05-12 21:32:23 UTC",
      "updated_date": "2025-05-12 21:32:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:37:03.155160"
    },
    {
      "arxiv_id": "2505.08080v1",
      "title": "Beyond Input Activations: Identifying Influential Latents by Gradient Sparse Autoencoders",
      "title_zh": "超越输入激活：通过梯度稀疏自动编码器识别有影响力的潜在特征",
      "authors": [
        "Dong Shu",
        "Xuansheng Wu",
        "Haiyan Zhao",
        "Mengnan Du",
        "Ninghao Liu"
      ],
      "abstract": "Sparse Autoencoders (SAEs) have recently emerged as powerful tools for\ninterpreting and steering the internal representations of large language models\n(LLMs). However, conventional approaches to analyzing SAEs typically rely\nsolely on input-side activations, without considering the causal influence\nbetween each latent feature and the model's output. This work is built on two\nkey hypotheses: (1) activated latents do not contribute equally to the\nconstruction of the model's output, and (2) only latents with high causal\ninfluence are effective for model steering. To validate these hypotheses, we\npropose Gradient Sparse Autoencoder (GradSAE), a simple yet effective method\nthat identifies the most influential latents by incorporating output-side\ngradient information.",
      "tldr_zh": "该研究指出，传统稀疏自动编码器 (SAEs) 在解释和引导大型语言模型 (LLMs) 内部表示时，仅依赖输入激活，而忽略了每个潜在特征 (latents) 对模型输出的因果影响。论文基于两个关键假设——激活的 latents 对输出贡献不均等，且仅高因果影响的 latents 才适用于模型引导——并提出 Gradient Sparse Autoencoder (GradSAE)，一种简单有效的方法，通过整合输出侧梯度信息来识别最具影响力的 latents。该方法有望提升对 LLMs 的解释性和控制能力，为模型 steering 提供更精确的工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.08080v1",
      "published_date": "2025-05-12 21:29:12 UTC",
      "updated_date": "2025-05-12 21:29:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:37:05.686615"
    },
    {
      "arxiv_id": "2505.08078v1",
      "title": "What Matters for Batch Online Reinforcement Learning in Robotics?",
      "title_zh": "机器人领域的批量在线强化学习中，什么是最重要的？",
      "authors": [
        "Perry Dong",
        "Suvir Mirchandani",
        "Dorsa Sadigh",
        "Chelsea Finn"
      ],
      "abstract": "The ability to learn from large batches of autonomously collected data for\npolicy improvement -- a paradigm we refer to as batch online reinforcement\nlearning -- holds the promise of enabling truly scalable robot learning by\nsignificantly reducing the need for human effort of data collection while\ngetting benefits from self-improvement. Yet, despite the promise of this\nparadigm, it remains challenging to achieve due to algorithms not being able to\nlearn effectively from the autonomous data. For example, prior works have\napplied imitation learning and filtered imitation learning methods to the batch\nonline RL problem, but these algorithms often fail to efficiently improve from\nthe autonomously collected data or converge quickly to a suboptimal point. This\nraises the question of what matters for effective batch online RL in robotics.\nMotivated by this question, we perform a systematic empirical study of three\naxes -- (i) algorithm class, (ii) policy extraction methods, and (iii) policy\nexpressivity -- and analyze how these axes affect performance and scaling with\nthe amount of autonomous data. Through our analysis, we make several\nobservations. First, we observe that the use of Q-functions to guide batch\nonline RL significantly improves performance over imitation-based methods.\nBuilding on this, we show that an implicit method of policy extraction -- via\nchoosing the best action in the distribution of the policy -- is necessary over\ntraditional policy extraction methods from offline RL. Next, we show that an\nexpressive policy class is preferred over less expressive policy classes. Based\non this analysis, we propose a general recipe for effective batch online RL. We\nthen show a simple addition to the recipe of using temporally-correlated noise\nto obtain more diversity results in further performance gains. Our recipe\nobtains significantly better performance and scaling compared to prior methods.",
      "tldr_zh": "这篇论文探讨了批量在线强化学习（batch online reinforcement learning）在机器人领域的关键因素，通过系统实证研究算法类别、策略提取方法和策略表达性。研究发现，使用Q函数指导的算法比基于模仿学习（imitation learning）的传统方法更有效地从自主数据中提升性能，而隐式策略提取和更具表达能力的策略类也至关重要。基于这些观察，论文提出一个通用配方，并通过添加时间相关噪声来增加策略多样性，进一步改善算法的性能和数据扩展能力。实验结果显示，该方法显著优于现有方法。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08078v1",
      "published_date": "2025-05-12 21:24:22 UTC",
      "updated_date": "2025-05-12 21:24:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:37:08.147125"
    },
    {
      "arxiv_id": "2505.08073v1",
      "title": "Explainable Reinforcement Learning Agents Using World Models",
      "title_zh": "使用世界模型的可解释强化学习智能体",
      "authors": [
        "Madhuri Singh",
        "Amal Alabdulkarim",
        "Gennie Mansi",
        "Mark O. Riedl"
      ],
      "abstract": "Explainable AI (XAI) systems have been proposed to help people understand how\nAI systems produce outputs and behaviors. Explainable Reinforcement Learning\n(XRL) has an added complexity due to the temporal nature of sequential\ndecision-making. Further, non-AI experts do not necessarily have the ability to\nalter an agent or its policy. We introduce a technique for using World Models\nto generate explanations for Model-Based Deep RL agents. World Models predict\nhow the world will change when actions are performed, allowing for the\ngeneration of counterfactual trajectories. However, identifying what a user\nwanted the agent to do is not enough to understand why the agent did something\nelse. We augment Model-Based RL agents with a Reverse World Model, which\npredicts what the state of the world should have been for the agent to prefer a\ngiven counterfactual action. We show that explanations that show users what the\nworld should have been like significantly increase their understanding of the\nagent policy. We hypothesize that our explanations can help users learn how to\ncontrol the agents execution through by manipulating the environment.",
      "tldr_zh": "该论文提出了一种使用 World Models 生成解释的 Explainable Reinforcement Learning (XRL) 技术，以帮助非 AI 专家理解强化学习代理的行为。方法涉及 World Models 预测动作对世界的变化，从而生成 counterfactual trajectories（反事实轨迹），并引入 Reverse World Model 来预测世界状态应如何调整，以使代理偏好特定反事实动作。实验结果显示，这种解释显著提升了用户对代理策略的理解，并可能帮助用户通过操纵环境来控制代理的执行。总的来说，该技术为可解释的模型驱动深度强化学习提供了新框架。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "The paper content spans 7 pages, followed by a page of references. It\n  contains 7 figures and 2 small tables",
      "pdf_url": "http://arxiv.org/pdf/2505.08073v1",
      "published_date": "2025-05-12 21:18:31 UTC",
      "updated_date": "2025-05-12 21:18:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:37:08.591426"
    },
    {
      "arxiv_id": "2505.08823v1",
      "title": "An Extra RMSNorm is All You Need for Fine Tuning to 1.58 Bits",
      "title_zh": "额外一个 RMSNorm 就是微调至 1.58 位的全部所需",
      "authors": [
        "Cody Steinmetz",
        "Gavin Childress",
        "Aaron Herbst",
        "Gavin Jones",
        "Jasdeep Singh",
        "Eli Vang",
        "Keagan Weinstock"
      ],
      "abstract": "Large language models (LLMs) have transformed natural-language processing,\nyet their scale makes real-world deployment costly. Post-training quantization\nreduces memory and computation but often degrades accuracy, while\nquantization-aware training can recover performance at the cost of extra\ntraining. Pushing quantization to the ternary (2-bit) regime yields even larger\nsavings but is notoriously unstable. Building on recent work showing that a\nbias-free, RMS-normalized Transformer with straight-through estimation can\nreach 1.58-bit precision, we demonstrate that simply inserting RMS\nnormalization before every linear projection and applying a gradual, layer-wise\nquantization schedule stably fine-tunes full-precision checkpoints into ternary\nLLMs. Our approach matches or surpasses more elaborate knowledge-distillation\npipelines on standard language-modeling benchmarks without adding model\ncomplexity. These results indicate that careful normalization alone can close\nmuch of the accuracy gap between ternary and full-precision LLMs, making\nultra-low-bit inference practical.",
      "tldr_zh": "这篇论文提出了一种简单方法，通过在每个线性投影前添加额外的RMSNorm，并采用渐进的层-wise量化时间表，来稳定地将大型语言模型(LLMs)微调至1.58-bit精度，从而减少内存和计算成本。不同于复杂的知识蒸馏管道，该方法基于RMS归一化的Transformer和直通估计，避免了额外训练开销，并在标准语言建模基准上匹配或超越了现有技术。结果表明，这种策略显著缩小了三元量化LLMs与全精度模型之间的准确率差距，使超低位推理在实际部署中变得可行。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08823v1",
      "published_date": "2025-05-12 21:14:29 UTC",
      "updated_date": "2025-05-12 21:14:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:37:16.746667"
    },
    {
      "arxiv_id": "2505.08064v1",
      "title": "Justified Evidence Collection for Argument-based AI Fairness Assurance",
      "title_zh": "针对基于论证的 AI 公平性保证的合理证据收集",
      "authors": [
        "Alpay Sabuncuoglu",
        "Christopher Burr",
        "Carsten Maple"
      ],
      "abstract": "It is well recognised that ensuring fair AI systems is a complex\nsociotechnical challenge, which requires careful deliberation and continuous\noversight across all stages of a system's lifecycle, from defining requirements\nto model deployment and deprovisioning. Dynamic argument-based assurance cases,\nwhich present structured arguments supported by evidence, have emerged as a\nsystematic approach to evaluating and mitigating safety risks and hazards in\nAI-enabled system development and have also been extended to deal with broader\nnormative goals such as fairness and explainability. This paper introduces a\nsystems-engineering-driven framework, supported by software tooling, to\noperationalise a dynamic approach to argument-based assurance in two stages. In\nthe first stage, during the requirements planning phase, a multi-disciplinary\nand multi-stakeholder team define goals and claims to be established (and\nevidenced) by conducting a comprehensive fairness governance process. In the\nsecond stage, a continuous monitoring interface gathers evidence from existing\nartefacts (e.g. metrics from automated tests), such as model, data, and use\ncase documentation, to support these arguments dynamically. The framework's\neffectiveness is demonstrated through an illustrative case study in finance,\nwith a focus on supporting fairness-related arguments.",
      "tldr_zh": "这篇论文提出一个基于 systems-engineering-driven 框架，用于操作化动态 argument-based assurance cases，以确保 AI 系统的公平性，解决从需求定义到部署的复杂 sociotechnical 挑战。框架分为两个阶段：首先，在要求规划阶段，多学科和多利益相关者团队通过全面的 fairness governance 过程定义目标和声明；其次，持续监控接口从现有工件（如自动化测试指标、模型和数据文档）动态收集证据来支持这些论点。该框架的有效性通过一个金融领域的案例研究得到证明，展示了其在支持公平相关论点的潜力。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "The paper is accepted for ACM Conference on Fairness, Accountability,\n  and Transparency (ACM FAccT '25)",
      "pdf_url": "http://arxiv.org/pdf/2505.08064v1",
      "published_date": "2025-05-12 21:05:33 UTC",
      "updated_date": "2025-05-12 21:05:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:37:18.097859"
    },
    {
      "arxiv_id": "2505.08054v1",
      "title": "FalseReject: A Resource for Improving Contextual Safety and Mitigating Over-Refusals in LLMs via Structured Reasoning",
      "title_zh": "FalseReject：一种通过结构化推理改善大型语言模型中上下文安全并缓解过度拒绝的资源",
      "authors": [
        "Zhehao Zhang",
        "Weijie Xu",
        "Fanyou Wu",
        "Chandan K. Reddy"
      ],
      "abstract": "Safety alignment approaches in large language models (LLMs) often lead to the\nover-refusal of benign queries, significantly diminishing their utility in\nsensitive scenarios. To address this challenge, we introduce FalseReject, a\ncomprehensive resource containing 16k seemingly toxic queries accompanied by\nstructured responses across 44 safety-related categories. We propose a\ngraph-informed adversarial multi-agent interaction framework to generate\ndiverse and complex prompts, while structuring responses with explicit\nreasoning to aid models in accurately distinguishing safe from unsafe contexts.\nFalseReject includes training datasets tailored for both standard\ninstruction-tuned models and reasoning-oriented models, as well as a\nhuman-annotated benchmark test set. Our extensive benchmarking on 29\nstate-of-the-art (SOTA) LLMs reveals persistent over-refusal challenges.\nEmpirical results demonstrate that supervised finetuning with FalseReject\nsubstantially reduces unnecessary refusals without compromising overall safety\nor general language capabilities.",
      "tldr_zh": "这篇论文引入了FalseReject资源，该资源包含16k个看似有毒的查询及其在44个安全相关类别下的结构化响应，旨在解决大语言模型(LLMs)安全对齐导致的过度拒绝问题。研究者提出了一种基于图形的对抗多智能体交互框架，通过显式推理结构化响应，帮助模型更准确地区分安全与不安全上下文，并提供了针对标准和推理导向模型的训练数据集及人工标注基准。实验结果显示，在29个SOTA LLMs上进行监督微调后，不必要拒绝显著减少29%，同时未影响整体安全性和语言能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08054v1",
      "published_date": "2025-05-12 20:45:25 UTC",
      "updated_date": "2025-05-12 20:45:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:37:20.527232"
    },
    {
      "arxiv_id": "2505.08052v1",
      "title": "NAZM: Network Analysis of Zonal Metrics in Persian Poetic Tradition",
      "title_zh": "NAZM：波斯诗歌传统中的分区指标网络分析",
      "authors": [
        "Kourosh Shahnazari",
        "Seyed Moein Ayyoubzadeh"
      ],
      "abstract": "This study formalizes a computational model to simulate classical Persian\npoets' dynamics of influence through constructing a multi-dimensional\nsimilarity network. Using a rigorously curated dataset based on Ganjoor's\ncorpus, we draw upon semantic, lexical, stylistic, thematic, and metrical\nfeatures to demarcate each poet's corpus. Each is contained within weighted\nsimilarity matrices, which are then appended to generate an aggregate graph\nshowing poet-to-poet influence. Further network investigation is carried out to\nidentify key poets, style hubs, and bridging poets by calculating degree,\ncloseness, betweenness, eigenvector, and Katz centrality measures. Further, for\ntypological insight, we use the Louvain community detection algorithm to\ndemarcate clusters of poets sharing both style and theme coherence, which\ncorrespond closely to acknowledged schools of literature like Sabk-e Hindi,\nSabk-e Khorasani, and the Bazgasht-e Adabi phenomenon. Our findings provide a\nnew data-driven view of Persian literature distinguished between canonical\nsignificance and interextual influence, thus highlighting relatively\nlesser-known figures who hold great structural significance. Combining\ncomputational linguistics with literary study, this paper produces an\ninterpretable and scalable model for poetic tradition, enabling retrospective\nreflection as well as forward-looking research within digital humanities.",
      "tldr_zh": "本研究提出NAZM框架，通过构建多维相似性网络，模拟古典波斯诗人的影响动态，使用语义、词汇、风格、主题和格律特征基于Ganjoor语料库生成加权矩阵和聚合图。研究计算degree、closeness、betweenness、eigenvector和Katz centrality指标，识别关键诗人、风格中心和桥梁诗人，并应用Louvain community detection算法检测诗人集群，这些集群与Sabk-e Hindi、Sabk-e Khorasani和Bazgasht-e Adabi等文学流派高度一致。主要发现包括数据驱动的视角，突显经典意义和互文影响，并强调一些较不为人知的诗人的结构性重要性。该框架结合计算语言学和文学研究，提供了一个可解释且可扩展的模型，支持数字人文领域的回顾与前瞻研究。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08052v1",
      "published_date": "2025-05-12 20:39:53 UTC",
      "updated_date": "2025-05-12 20:39:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:37:23.156059"
    },
    {
      "arxiv_id": "2505.08049v1",
      "title": "Bias or Optimality? Disentangling Bayesian Inference and Learning Biases in Human Decision-Making",
      "title_zh": "偏见还是最优性？区分贝叶斯推理与学习偏见在人类决策中",
      "authors": [
        "Prakhar Godara"
      ],
      "abstract": "Recent studies claim that human behavior in a two-armed Bernoulli bandit\n(TABB) task is described by positivity and confirmation biases, implying that\nhumans do not integrate new information objectively. However, we find that even\nif the agent updates its belief via objective Bayesian inference, fitting the\nstandard Q-learning model with asymmetric learning rates still recovers both\nbiases. Bayesian inference cast as an effective Q-learning algorithm has\nsymmetric, though decreasing, learning rates. We explain this by analyzing the\nstochastic dynamics of these learning systems using master equations. We find\nthat both confirmation bias and unbiased but decreasing learning rates yield\nthe same behavioral signatures. Finally, we propose experimental protocols to\ndisentangle true cognitive biases from artifacts of decreasing learning rates.",
      "tldr_zh": "本论文探讨了人类决策中观察到的积极性和确认偏差（positivity and confirmation biases）是否为真正的认知偏差，还是贝叶斯推理（Bayesian inference）和Q学习模型拟合的伪迹。在两臂伯努瓦博弈（Two-Armed Bernoulli Bandit, TABB）任务中，研究发现即使采用客观贝叶斯推理，其等效Q学习算法也表现出对称但递减的学习率，通过主方程（master equations）分析随机动态来解释这一现象。结果表明，确认偏差和无偏但递减的学习率会产生相同的行为特征，最终提出实验协议来区分真实的认知偏差与学习率下降的效应。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08049v1",
      "published_date": "2025-05-12 20:36:43 UTC",
      "updated_date": "2025-05-12 20:36:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:37:24.531351"
    },
    {
      "arxiv_id": "2505.08821v1",
      "title": "A Comparative Study of Transformer-Based Models for Multi-Horizon Blood Glucose Prediction",
      "title_zh": "基于Transformer模型的多时间尺度血糖预测比较研究",
      "authors": [
        "Meryem Altin Karagoz",
        "Marc D. Breton",
        "Anas El Fathi"
      ],
      "abstract": "Accurate blood glucose prediction can enable novel interventions for type 1\ndiabetes treatment, including personalized insulin and dietary adjustments.\nAlthough recent advances in transformer-based architectures have demonstrated\nthe power of attention mechanisms in complex multivariate time series\nprediction, their potential for blood glucose (BG) prediction remains\nunderexplored. We present a comparative analysis of transformer models for\nmulti-horizon BG prediction, examining forecasts up to 4 hours and input\nhistory up to 1 week. The publicly available DCLP3 dataset (n=112) was split\n(80%-10%-10%) for training, validation, and testing, and the OhioT1DM dataset\n(n=12) served as an external test set. We trained networks with point-wise,\npatch-wise, series-wise, and hybrid embeddings, using CGM, insulin, and meal\ndata. For short-term blood glucose prediction, Crossformer, a patch-wise\ntransformer architecture, achieved a superior 30-minute prediction of RMSE\n(15.6 mg / dL on OhioT1DM). For longer-term predictions (1h, 2h, and 4h),\nPatchTST, another path-wise transformer, prevailed with the lowest RMSE (24.6\nmg/dL, 36.1 mg/dL, and 46.5 mg/dL on OhioT1DM). In general, models that used\ntokenization through patches demonstrated improved accuracy with larger input\nsizes, with the best results obtained with a one-week history. These findings\nhighlight the promise of transformer-based architectures for BG prediction by\ncapturing and leveraging seasonal patterns in multivariate time-series data to\nimprove accuracy.",
      "tldr_zh": "本研究比较了基于Transformer模型的多时间尺度血糖预测性能，旨在为1型糖尿病治疗提供个性化干预，如胰岛素和饮食调整。研究使用DCLP3数据集（n=112）进行训练、验证和测试，以及OhioT1DM数据集（n=12）作为外部测试集，测试了点式、补丁式、序列式和混合嵌入策略，并结合CGM、胰岛素和进餐数据进行预测。结果显示，Crossformer在短期预测（如30分钟）中取得最低RMSE（15.6 mg/dL），而PatchTST在长期预测（1h、2h和4h）中表现最佳，RMSE分别为24.6 mg/dL、36.1 mg/dL和46.5 mg/dL；补丁式标记化的模型在较大输入历史（如一周）时准确性更高。这些发现突出了Transformer模型通过捕捉多变量时间序列中的季节性模式，提升血糖预测准确性的潜力。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "stat.AP"
      ],
      "primary_category": "q-bio.QM",
      "comment": "7 pages, 2 figures, 1 table, 1st IFAC Workshop on Engineering\n  Diabetes Technologies (EDT 2025)",
      "pdf_url": "http://arxiv.org/pdf/2505.08821v1",
      "published_date": "2025-05-12 20:22:44 UTC",
      "updated_date": "2025-05-12 20:22:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:37:28.349033"
    },
    {
      "arxiv_id": "2505.08032v1",
      "title": "Online Learning-based Adaptive Beam Switching for 6G Networks: Enhancing Efficiency and Resilience",
      "title_zh": "基于在线学习的自适应波束切换用于6G网络：增强效率与韧性",
      "authors": [
        "Seyed Bagher Hashemi Natanzi",
        "Zhicong Zhu",
        "Bo Tang"
      ],
      "abstract": "Adaptive beam switching in 6G networks is challenged by high frequencies,\nmobility, and blockage. We propose an Online Learning framework using Deep\nReinforcement Learning (DRL) with an enhanced state representation (velocity\nand blockage history), a GRU architecture, and prioritized experience replay\nfor real-time beam optimization. Validated via Nvidia Sionna under\ntime-correlated blockage, our approach significantly enhances resilience in\nSNR, throughput, and accuracy compared to a conventional heuristic.\nFurthermore, the enhanced DRL agent outperforms a reactive Multi-Armed Bandit\n(MAB) baseline by leveraging temporal dependencies, achieving lower performance\nvariability. This demonstrates the benefits of memory and prioritized learning\nfor robust 6G beam management, while confirming MAB as a strong baseline.",
      "tldr_zh": "这篇论文针对6G网络中自适应波束切换面临的挑战（如高频、移动性和阻塞），提出了一种基于在线学习的框架，使用Deep Reinforcement Learning (DRL)来优化波束选择。该框架通过增强的状态表示（包括速度和阻塞历史）、GRU架构以及优先经验回放，实现实时波束优化，并在Nvidia Sionna模拟器中验证。实验结果显示，该方法显著提升了SNR、吞吐量和准确性的弹性，并比传统的启发式方法和Multi-Armed Bandit (MAB)基线表现出更低的性能变异性，证明了记忆和优先学习在鲁棒6G波束管理中的优势。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08032v1",
      "published_date": "2025-05-12 19:59:05 UTC",
      "updated_date": "2025-05-12 19:59:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:37:29.787661"
    },
    {
      "arxiv_id": "2505.08025v1",
      "title": "PRISM: Complete Online Decentralized Multi-Agent Pathfinding with Rapid Information Sharing using Motion Constraints",
      "title_zh": "PRISM：完整的在线去中心化多智能体路径规划，使用运动约束的快速信息共享",
      "authors": [
        "Hannah Lee",
        "Zachary Serlin",
        "James Motes",
        "Brendan Long",
        "Marco Morales",
        "Nancy M. Amato"
      ],
      "abstract": "We introduce PRISM (Pathfinding with Rapid Information Sharing using Motion\nConstraints), a decentralized algorithm designed to address the multi-task\nmulti-agent pathfinding (MT-MAPF) problem. PRISM enables large teams of agents\nto concurrently plan safe and efficient paths for multiple tasks while avoiding\ncollisions. It employs a rapid communication strategy that uses information\npackets to exchange motion constraint information, enhancing cooperative\npathfinding and situational awareness, even in scenarios without direct\ncommunication. We prove that PRISM resolves and avoids all deadlock scenarios\nwhen possible, a critical challenge in decentralized pathfinding. Empirically,\nwe evaluate PRISM across five environments and 25 random scenarios,\nbenchmarking it against the centralized Conflict-Based Search (CBS) and the\ndecentralized Token Passing with Task Swaps (TPTS) algorithms. PRISM\ndemonstrates scalability and solution quality, supporting 3.4 times more agents\nthan CBS and handling up to 2.5 times more tasks in narrow passage environments\nthan TPTS. Additionally, PRISM matches CBS in solution quality while achieving\nfaster computation times, even under low-connectivity conditions. Its\ndecentralized design reduces the computational burden on individual agents,\nmaking it scalable for large environments. These results confirm PRISM's\nrobustness, scalability, and effectiveness in complex and dynamic pathfinding\nscenarios.",
      "tldr_zh": "该研究引入了 PRISM，一种完整的在线去中心化多智能体路径规划（MT-MAPF）算法，通过快速信息共享机制利用运动约束，帮助大量智能体同时规划安全的路径以完成多个任务，同时避免碰撞。PRISM 采用信息包交换策略来增强合作路径规划和 situational awareness，即使在没有直接通信的环境中，也能证明并解决所有可能的死锁场景。在实验中，PRISM 在五个环境和25个随机场景中与中心化 Conflict-Based Search (CBS) 和去中心化 Token Passing with Task Swaps (TPTS) 相比，支持3.4倍更多智能体、处理2.5倍更多任务，并与 CBS 在解决方案质量相当，同时实现更快计算时间和更好的可扩展性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "38 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.08025v1",
      "published_date": "2025-05-12 19:48:32 UTC",
      "updated_date": "2025-05-12 19:48:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:37:30.752669"
    },
    {
      "arxiv_id": "2505.08021v1",
      "title": "The Correspondence Between Bounded Graph Neural Networks and Fragments of First-Order Logic",
      "title_zh": "有界图神经网络与一阶逻辑片段的对应关系",
      "authors": [
        "Bernardo Cuenca Grau",
        "Przemysław A. Wałęga"
      ],
      "abstract": "Graph Neural Networks (GNNs) address two key challenges in applying deep\nlearning to graph-structured data: they handle varying size input graphs and\nensure invariance under graph isomorphism. While GNNs have demonstrated broad\napplicability, understanding their expressive power remains an important\nquestion. In this paper, we show that bounded GNN architectures correspond to\nspecific fragments of first-order logic (FO), including modal logic (ML),\ngraded modal logic (GML), modal logic with the universal modality (ML(A)), the\ntwo-variable fragment (FO2) and its extension with counting quantifiers (C2).\nTo establish these results, we apply methods and tools from finite model theory\nof first-order and modal logics to the domain of graph representation learning.\nThis provides a unifying framework for understanding the logical expressiveness\nof GNNs within FO.",
      "tldr_zh": "这篇论文探讨了有界 Graph Neural Networks (GNNs) 与一阶逻辑 (FO) 片段之间的对应关系，旨在理解 GNNs 在处理图结构数据时的表达能力。研究通过应用有限模型理论的方法，证明了 GNNs 对应于特定逻辑片段，包括 modal logic (ML)、graded modal logic (GML)、modal logic with the universal modality (ML(A))、two-variable fragment (FO2) 及其带 counting quantifiers (C2) 的扩展。这些发现为图表示学习提供了一个统一的框架，帮助阐明 GNNs 的逻辑表达潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.08021v1",
      "published_date": "2025-05-12 19:45:45 UTC",
      "updated_date": "2025-05-12 19:45:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:37:33.038301"
    },
    {
      "arxiv_id": "2505.08004v1",
      "title": "Large Language Models and Arabic Content: A Review",
      "title_zh": "大语言模型与阿拉伯内容：综述",
      "authors": [
        "Haneh Rhel",
        "Dmitri Roussinov"
      ],
      "abstract": "Over the past three years, the rapid advancement of Large Language Models\n(LLMs) has had a profound impact on multiple areas of Artificial Intelligence\n(AI), particularly in Natural Language Processing (NLP) across diverse\nlanguages, including Arabic. Although Arabic is considered one of the most\nwidely spoken languages across 27 countries in the Arabic world and used as a\nsecond language in some other non-Arabic countries as well, there is still a\nscarcity of Arabic resources, datasets, and tools. Arabic NLP tasks face\nvarious challenges due to the complexities of the Arabic language, including\nits rich morphology, intricate structure, and diverse writing standards, among\nother factors. Researchers have been actively addressing these challenges,\ndemonstrating that pre-trained Large Language Models (LLMs) trained on\nmultilingual corpora achieve significant success in various Arabic NLP tasks.\nThis study provides an overview of using large language models (LLMs) for the\nArabic language, highlighting early pre-trained Arabic Language models across\nvarious NLP applications and their ability to handle diverse Arabic content\ntasks and dialects. It also provides an overview of how techniques like\nfinetuning and prompt engineering can enhance the performance of these models.\nAdditionally, the study summarizes common Arabic benchmarks and datasets while\npresenting our observations on the persistent upward trend in the adoption of\nLLMs.",
      "tldr_zh": "这篇综述论文探讨了Large Language Models (LLMs) 在阿拉伯语内容中的应用，强调了LLMs 在过去三年中对Natural Language Processing (NLP) 的影响，特别是针对阿拉伯语的挑战，如其复杂形态结构和资源稀缺。论文回顾了早期预训练的阿拉伯语言模型在各种NLP 任务中的表现，以及通过fine-tuning 和prompt engineering 等技术提升模型处理阿拉伯方言和任务的能力。同时，它总结了常见的阿拉伯基准数据集，并观察到LLMs 在该领域的采用趋势持续上升。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Original language: English This paper has been submitted to the First\n  International Conference on Artificial Intelligence and Generative AI\n  (FICAILY 2025), and it has been accepted for presentation at FICAILY on\n  9-10/July 2025 and for publication in the Springer Nature. Number of pages:\n  16 Publication status Accepted/In press - 7 Apr 2025\n  https://www.gena-ai-libya2025.com/",
      "pdf_url": "http://arxiv.org/pdf/2505.08004v1",
      "published_date": "2025-05-12 19:09:12 UTC",
      "updated_date": "2025-05-12 19:09:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:37:33.469210"
    },
    {
      "arxiv_id": "2505.08818v1",
      "title": "Position: Restructuring of Categories and Implementation of Guidelines Essential for VLM Adoption in Healthcare",
      "title_zh": "Position: 类别重组和指南实施对于VLM在医疗领域的采用至关重要",
      "authors": [
        "Amara Tariq",
        "Rimita Lahiri",
        "Charles Kahn",
        "Imon Banerjee"
      ],
      "abstract": "The intricate and multifaceted nature of vision language model (VLM)\ndevelopment, adaptation, and application necessitates the establishment of\nclear and standardized reporting protocols, particularly within the high-stakes\ncontext of healthcare. Defining these reporting standards is inherently\nchallenging due to the diverse nature of studies involving VLMs, which vary\nsignificantly from the development of all new VLMs or finetuning for domain\nalignment to off-the-shelf use of VLM for targeted diagnosis and prediction\ntasks. In this position paper, we argue that traditional machine learning\nreporting standards and evaluation guidelines must be restructured to\naccommodate multiphase VLM studies; it also has to be organized for intuitive\nunderstanding of developers while maintaining rigorous standards for\nreproducibility. To facilitate community adoption, we propose a categorization\nframework for VLM studies and outline corresponding reporting standards that\ncomprehensively address performance evaluation, data reporting protocols, and\nrecommendations for manuscript composition. These guidelines are organized\naccording to the proposed categorization scheme. Lastly, we present a checklist\nthat consolidates reporting standards, offering a standardized tool to ensure\nconsistency and quality in the publication of VLM-related research.",
      "tldr_zh": "这篇立场论文强调，在医疗领域采用视觉语言模型 (VLM) 的复杂性要求建立清晰的标准化报告协议，以应对高风险环境下的多样化研究。论文主张重组传统机器学习报告标准，以适应多阶段 VLM 研究，包括从新模型开发到现成应用的各种场景，并确保开发者的直观理解和研究的可重复性。为此，作者提出一个 VLM 研究的分类框架，并制定相应的报告标准，涵盖性能评估、数据报告协议以及稿件撰写推荐。最终，论文提供了一个整合检查列表，作为工具来提升 VLM 相关研究的统一性和质量。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "15 pages, 2, tables, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.08818v1",
      "published_date": "2025-05-12 18:39:54 UTC",
      "updated_date": "2025-05-12 18:39:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:37:40.982615"
    },
    {
      "arxiv_id": "2505.07985v1",
      "title": "Fair Play for Individuals, Foul Play for Groups? Auditing Anonymization's Impact on ML Fairness",
      "title_zh": "对个人公平，对群体不公？审计匿名化对机器学习公平性的影响",
      "authors": [
        "Héber H. Arcolezi",
        "Mina Alishahi",
        "Adda-Akram Bendoukha",
        "Nesrine Kaaniche"
      ],
      "abstract": "Machine learning (ML) algorithms are heavily based on the availability of\ntraining data, which, depending on the domain, often includes sensitive\ninformation about data providers. This raises critical privacy concerns.\nAnonymization techniques have emerged as a practical solution to address these\nissues by generalizing features or suppressing data to make it more difficult\nto accurately identify individuals. Although recent studies have shown that\nprivacy-enhancing technologies can influence ML predictions across different\nsubgroups, thus affecting fair decision-making, the specific effects of\nanonymization techniques, such as $k$-anonymity, $\\ell$-diversity, and\n$t$-closeness, on ML fairness remain largely unexplored. In this work, we\nsystematically audit the impact of anonymization techniques on ML fairness,\nevaluating both individual and group fairness. Our quantitative study reveals\nthat anonymization can degrade group fairness metrics by up to four orders of\nmagnitude. Conversely, similarity-based individual fairness metrics tend to\nimprove under stronger anonymization, largely as a result of increased input\nhomogeneity. By analyzing varying levels of anonymization across diverse\nprivacy settings and data distributions, this study provides critical insights\ninto the trade-offs between privacy, fairness, and utility, offering actionable\nguidelines for responsible AI development. Our code is publicly available at:\nhttps://github.com/hharcolezi/anonymity-impact-fairness.",
      "tldr_zh": "本研究审计了匿名化技术（如 k-anonymity、ℓ-diversity 和 t-closeness）对机器学习（ML）公平性的影响，探讨这些技术在保护隐私的同时如何改变 ML 算法的公平表现。研究通过量化评估发现，匿名化可能使群体公平指标下降高达四个数量级，而基于相似性的个体公平指标则往往因输入数据的同质性增加而改善。作者分析了不同匿名化水平、隐私设置和数据分布，揭示了隐私、公平性和效用之间的关键权衡，并提供了用于负责任 AI 开发的行动指南。代码已在 GitHub 上公开可用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07985v1",
      "published_date": "2025-05-12 18:32:28 UTC",
      "updated_date": "2025-05-12 18:32:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:37:43.513152"
    },
    {
      "arxiv_id": "2505.07973v1",
      "title": "Probabilistic approach to longitudinal response prediction: application to radiomics from brain cancer imaging",
      "title_zh": "纵向响应预测的概率方法：脑癌影像学放射组学应用",
      "authors": [
        "Isabella Cama",
        "Michele Piana",
        "Cristina Campi",
        "Sara Garbarino"
      ],
      "abstract": "Longitudinal imaging analysis tracks disease progression and treatment\nresponse over time, providing dynamic insights into treatment efficacy and\ndisease evolution. Radiomic features extracted from medical imaging can support\nthe study of disease progression and facilitate longitudinal prediction of\nclinical outcomes. This study presents a probabilistic model for longitudinal\nresponse prediction, integrating baseline features with intermediate\nfollow-ups. The probabilistic nature of the model naturally allows to handle\nthe instrinsic uncertainty of the longitudinal prediction of disease\nprogression. We evaluate the proposed model against state-of-the-art disease\nprogression models in both a synthetic scenario and using a brain cancer\ndataset. Results demonstrate that the approach is competitive against existing\nmethods while uniquely accounting for uncertainty and controlling the growth of\nproblem dimensionality, eliminating the need for data from intermediate\nfollow-ups.",
      "tldr_zh": "该研究提出了一种概率模型（probabilistic model），用于纵向响应预测（longitudinal response prediction），通过整合基线特征和中间随访数据，应用于脑癌影像的放射组学（radiomics）。该模型自然处理了疾病进展预测的固有不确定性（intrinsic uncertainty），并有效控制问题维度的增长，无需依赖中间随访数据。实验结果显示，该方法在合成场景和脑癌数据集上与现有模型竞争性强，同时提供独特的不确定性评估，为疾病进展分析提供动态洞见。",
      "categories": [
        "stat.AP",
        "cs.AI",
        "62P10 (Primary), 68T09, 92F05 (Secondary)"
      ],
      "primary_category": "stat.AP",
      "comment": "21 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.07973v1",
      "published_date": "2025-05-12 18:15:24 UTC",
      "updated_date": "2025-05-12 18:15:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:37:44.736836"
    },
    {
      "arxiv_id": "2505.07819v1",
      "title": "H$^{\\mathbf{3}}$DP: Triply-Hierarchical Diffusion Policy for Visuomotor Learning",
      "title_zh": "H³DP：三重层次扩散策略用于视觉运动学习",
      "authors": [
        "Yiyang Lu",
        "Yufeng Tian",
        "Zhecheng Yuan",
        "Xianbang Wang",
        "Pu Hua",
        "Zhengrong Xue",
        "Huazhe Xu"
      ],
      "abstract": "Visuomotor policy learning has witnessed substantial progress in robotic\nmanipulation, with recent approaches predominantly relying on generative models\nto model the action distribution. However, these methods often overlook the\ncritical coupling between visual perception and action prediction. In this\nwork, we introduce $\\textbf{Triply-Hierarchical Diffusion\nPolicy}~(\\textbf{H$^{\\mathbf{3}}$DP})$, a novel visuomotor learning framework\nthat explicitly incorporates hierarchical structures to strengthen the\nintegration between visual features and action generation. H$^{3}$DP contains\n$\\mathbf{3}$ levels of hierarchy: (1) depth-aware input layering that organizes\nRGB-D observations based on depth information; (2) multi-scale visual\nrepresentations that encode semantic features at varying levels of granularity;\nand (3) a hierarchically conditioned diffusion process that aligns the\ngeneration of coarse-to-fine actions with corresponding visual features.\nExtensive experiments demonstrate that H$^{3}$DP yields a $\\mathbf{+27.5\\%}$\naverage relative improvement over baselines across $\\mathbf{44}$ simulation\ntasks and achieves superior performance in $\\mathbf{4}$ challenging bimanual\nreal-world manipulation tasks. Project Page: https://lyy-iiis.github.io/h3dp/.",
      "tldr_zh": "本研究提出H$^{\\mathbf{3}}$DP，一种针对visuomotor learning的三层层次扩散策略(triply-hierarchical diffusion policy)，旨在加强视觉感知与动作预测的耦合，以提升机器人操作性能。\n该框架包括：深度感知输入分层(depth-aware input layering)来组织RGB-D观察、多尺度视觉表示(multi-scale visual representations)来编码不同粒度的语义特征，以及层次化条件扩散过程(hierarchically conditioned diffusion process)来对齐粗到细的动作生成。\n实验结果显示，H$^{\\mathbf{3}}$DP在44个模拟任务上比基线平均提升27.5%，并在4个真实双臂操作任务中表现出色。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07819v1",
      "published_date": "2025-05-12 17:59:43 UTC",
      "updated_date": "2025-05-12 17:59:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:37:49.190299"
    },
    {
      "arxiv_id": "2505.07816v2",
      "title": "Graph neural networks and MSO",
      "title_zh": "图神经网络与 MSO",
      "authors": [
        "Veeti Ahvonen",
        "Damian Heiman",
        "Antti Kuusisto"
      ],
      "abstract": "We give an alternative proof for the existing result that recurrent graph\nneural networks working with reals have the same expressive power in\nrestriction to monadic second-order logic MSO as the graded modal substitution\ncalculus. The proof is based on constructing distributed automata that capture\nall MSO-definable node properties over trees. We also consider some variants of\nthe acceptance conditions.",
      "tldr_zh": "该研究提供了一个替代证明，证明了使用实数的循环图神经网络（recurrent graph neural networks）在单目二阶逻辑（MSO）的限制下，与分级模态替换演算（graded modal substitution calculus）具有相同的表达能力。主要方法是构建分布式自动机（distributed automata），以捕捉树上所有 MSO 定义的节点属性。论文还探讨了接受条件的某些变体，进一步扩展了这一框架的应用潜力。",
      "categories": [
        "cs.LO",
        "cs.AI",
        "F.4.1; F.1.1; I.2.0"
      ],
      "primary_category": "cs.LO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07816v2",
      "published_date": "2025-05-12 17:59:22 UTC",
      "updated_date": "2025-05-15 13:32:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:37:47.514874"
    },
    {
      "arxiv_id": "2505.07813v1",
      "title": "DexWild: Dexterous Human Interactions for In-the-Wild Robot Policies",
      "title_zh": "DexWild：用于野外机器人策略的灵巧人类互动",
      "authors": [
        "Tony Tao",
        "Mohan Kumar Srirama",
        "Jason Jingzhou Liu",
        "Kenneth Shaw",
        "Deepak Pathak"
      ],
      "abstract": "Large-scale, diverse robot datasets have emerged as a promising path toward\nenabling dexterous manipulation policies to generalize to novel environments,\nbut acquiring such datasets presents many challenges. While teleoperation\nprovides high-fidelity datasets, its high cost limits its scalability. Instead,\nwhat if people could use their own hands, just as they do in everyday life, to\ncollect data? In DexWild, a diverse team of data collectors uses their hands to\ncollect hours of interactions across a multitude of environments and objects.\nTo record this data, we create DexWild-System, a low-cost, mobile, and\neasy-to-use device. The DexWild learning framework co-trains on both human and\nrobot demonstrations, leading to improved performance compared to training on\neach dataset individually. This combination results in robust robot policies\ncapable of generalizing to novel environments, tasks, and embodiments with\nminimal additional robot-specific data. Experimental results demonstrate that\nDexWild significantly improves performance, achieving a 68.5% success rate in\nunseen environments-nearly four times higher than policies trained with robot\ndata only-and offering 5.8x better cross-embodiment generalization. Video\nresults, codebases, and instructions at https://dexwild.github.io",
      "tldr_zh": "该研究提出DexWild框架，利用人类双手互动收集大规模多样化数据集，以解决灵巧操作策略(dexterous manipulation policies)泛化到新型环境的挑战。DexWild-System是一个低成本、移动且易用的设备，由多样化团队用于记录小时级互动数据；学习框架通过联合训练人类和机器人演示数据，提升策略性能。实验结果显示，DexWild在未见环境中实现68.5%的成功率，比仅用机器人数据训练的策略高出近四倍，并在跨设备(embodiment)泛化上提升5.8倍，显著提高了机器人策略的鲁棒性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "In RSS 2025. Website at https://dexwild.github.io",
      "pdf_url": "http://arxiv.org/pdf/2505.07813v1",
      "published_date": "2025-05-12 17:59:05 UTC",
      "updated_date": "2025-05-12 17:59:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:37:52.006036"
    },
    {
      "arxiv_id": "2505.07809v1",
      "title": "A Comparative Analysis of Static Word Embeddings for Hungarian",
      "title_zh": "针对匈牙利语的静态词嵌入比较分析",
      "authors": [
        "Máté Gedeon"
      ],
      "abstract": "This paper presents a comprehensive analysis of various static word\nembeddings for Hungarian, including traditional models such as Word2Vec,\nFastText, as well as static embeddings derived from BERT-based models using\ndifferent extraction methods. We evaluate these embeddings on both intrinsic\nand extrinsic tasks to provide a holistic view of their performance. For\nintrinsic evaluation, we employ a word analogy task, which assesses the\nembeddings ability to capture semantic and syntactic relationships. Our results\nindicate that traditional static embeddings, particularly FastText, excel in\nthis task, achieving high accuracy and mean reciprocal rank (MRR) scores. Among\nthe BERT-based models, the X2Static method for extracting static embeddings\ndemonstrates superior performance compared to decontextualized and aggregate\nmethods, approaching the effectiveness of traditional static embeddings. For\nextrinsic evaluation, we utilize a bidirectional LSTM model to perform Named\nEntity Recognition (NER) and Part-of-Speech (POS) tagging tasks. The results\nreveal that embeddings derived from dynamic models, especially those extracted\nusing the X2Static method, outperform purely static embeddings. Notably, ELMo\nembeddings achieve the highest accuracy in both NER and POS tagging tasks,\nunderscoring the benefits of contextualized representations even when used in a\nstatic form. Our findings highlight the continued relevance of static word\nembeddings in NLP applications and the potential of advanced extraction methods\nto enhance the utility of BERT-based models. This piece of research contributes\nto the understanding of embedding performance in the Hungarian language and\nprovides valuable insights for future developments in the field. The training\nscripts, evaluation codes, restricted vocabulary, and extracted embeddings will\nbe made publicly available to support further research and reproducibility.",
      "tldr_zh": "这篇论文对匈牙利语的静态词嵌入进行了全面比较分析，包括传统模型如 Word2Vec 和 FastText，以及从 BERT 模型提取的静态嵌入（如 X2Static 方法）。\n研究通过内在任务（例如词类比任务）评估嵌入捕捉语义和句法关系的性能，结果显示 FastText 在准确率和 MRR 分数上表现出色。\n在外在任务中，如 Named Entity Recognition (NER) 和 Part-of-Speech (POS) 标注，使用双向 LSTM 模型的实验表明，X2Static 方法提取的嵌入，尤其是 ELMo 嵌入，超过了传统静态嵌入的准确率。\n这项研究强调了静态词嵌入在 NLP 应用中的持续价值，并通过公开训练脚本和代码促进了匈牙利语相关研究的再现性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07809v1",
      "published_date": "2025-05-12 17:57:11 UTC",
      "updated_date": "2025-05-12 17:57:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:37:54.340094"
    },
    {
      "arxiv_id": "2505.07802v1",
      "title": "Improving Trajectory Stitching with Flow Models",
      "title_zh": "使用流模型改进轨迹拼接",
      "authors": [
        "Reece O'Mahoney",
        "Wanming Yu",
        "Ioannis Havoutis"
      ],
      "abstract": "Generative models have shown great promise as trajectory planners, given\ntheir affinity to modeling complex distributions and guidable inference\nprocess. Previous works have successfully applied these in the context of\nrobotic manipulation but perform poorly when the required solution does not\nexist as a complete trajectory within the training set. We identify that this\nis a result of being unable to plan via stitching, and subsequently address the\narchitectural and dataset choices needed to remedy this. On top of this, we\npropose a novel addition to the training and inference procedures to both\nstabilize and enhance these capabilities. We demonstrate the efficacy of our\napproach by generating plans with out of distribution boundary conditions and\nperforming obstacle avoidance on the Franka Panda in simulation and on real\nhardware. In both of these tasks our method performs significantly better than\nthe baselines and is able to avoid obstacles up to four times as large.",
      "tldr_zh": "这篇论文针对生成模型在轨迹规划中的局限性，提出使用 Flow Models 来改进 trajectory stitching 能力，以处理训练集中不存在的完整轨迹问题。作者优化了模型架构和数据集选择，并引入一个新的训练和推理过程，以稳定和增强拼接功能。实验结果显示，该方法在模拟和真实硬件上的 Franka Panda 机器人中，成功生成分布外边界条件下的计划，并实现障碍物避免能力，比基线模型提高显著，可避开多达四倍大的障碍物。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07802v1",
      "published_date": "2025-05-12 17:50:10 UTC",
      "updated_date": "2025-05-12 17:50:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:37:55.398066"
    },
    {
      "arxiv_id": "2505.07796v1",
      "title": "Learning Dynamics in Continual Pre-Training for Large Language Models",
      "title_zh": "在持续预训练中针对大型语言模型的学习动态",
      "authors": [
        "Xingjin Wang",
        "Howe Tissue",
        "Lu Wang",
        "Linjing Li",
        "Daniel Dajun Zeng"
      ],
      "abstract": "Continual Pre-Training (CPT) has become a popular and effective method to\napply strong foundation models to specific downstream tasks. In this work, we\nexplore the learning dynamics throughout the CPT process for large language\nmodels. We specifically focus on how general and downstream domain performance\nevolves at each training step, with domain performance measured via validation\nlosses. We have observed that the CPT loss curve fundamentally characterizes\nthe transition from one curve to another hidden curve, and could be described\nby decoupling the effects of distribution shift and learning rate annealing. We\nderive a CPT scaling law that combines the two factors, enabling the prediction\nof loss at any (continual) training steps and across learning rate schedules\n(LRS) in CPT. Our formulation presents a comprehensive understanding of several\ncritical factors in CPT, including loss potential, peak learning rate, training\nsteps, replay ratio, etc. Moreover, our approach can be adapted to customize\ntraining hyper-parameters to different CPT goals such as balancing general and\ndomain-specific performance. Extensive experiments demonstrate that our scaling\nlaw holds across various CPT datasets and training hyper-parameters.",
      "tldr_zh": "本研究探讨了在Continual Pre-Training (CPT) 过程中，大语言模型(Large Language Models)的学习动态，重点分析通用性能和下游领域性能如何随每个训练步骤演变，并通过验证损失进行衡量。研究发现，CPT损失曲线可分解为分布偏移和学习率退火的影响，从而推导出一个CPT scaling law，能够预测任意训练步骤的损失并适用于不同学习率调度。该定律提供了对关键因素（如损失潜力、峰值学习率、训练步骤和重放比率）的全面理解，并可用于自定义训练超参数以平衡通用和领域特定性能；广泛实验证实了该定律在各种CPT数据集和超参数设置中的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ICML2025 (spotlight)",
      "pdf_url": "http://arxiv.org/pdf/2505.07796v1",
      "published_date": "2025-05-12 17:47:32 UTC",
      "updated_date": "2025-05-12 17:47:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:37:57.965828"
    },
    {
      "arxiv_id": "2505.07793v1",
      "title": "Overflow Prevention Enhances Long-Context Recurrent LLMs",
      "title_zh": "溢出预防提升长上下文循环大语言模型",
      "authors": [
        "Assaf Ben-Kish",
        "Itamar Zimerman",
        "M. Jehanzeb Mirza",
        "James Glass",
        "Leonid Karlinsky",
        "Raja Giryes"
      ],
      "abstract": "A recent trend in LLMs is developing recurrent sub-quadratic models that\nimprove long-context processing efficiency. We investigate leading large\nlong-context models, focusing on how their fixed-size recurrent memory affects\ntheir performance. Our experiments reveal that, even when these models are\ntrained for extended contexts, their use of long contexts remains\nunderutilized. Specifically, we demonstrate that a chunk-based inference\nprocedure, which identifies and processes only the most relevant portion of the\ninput can mitigate recurrent memory failures and be effective for many\nlong-context tasks: On LongBench, our method improves the overall performance\nof Falcon3-Mamba-Inst-7B by 14%, Falcon-Mamba-Inst-7B by 28%,\nRecurrentGemma-IT-9B by 50%, and RWKV6-Finch-7B by 51%. Surprisingly, this\nsimple approach also leads to state-of-the-art results in the challenging\nLongBench v2 benchmark, showing competitive performance with equivalent size\nTransformers. Furthermore, our findings raise questions about whether recurrent\nmodels genuinely exploit long-range dependencies, as our single-chunk strategy\ndelivers stronger performance - even in tasks that presumably require\ncross-context relations.",
      "tldr_zh": "本研究探讨了循环大型语言模型（LLMs）在处理长上下文时的效率问题，特别关注其固定大小的循环内存导致的上下文利用不足。研究提出了一种基于块（chunk-based）的推理程序，仅处理输入中最相关的部分，以防止内存溢出（overflow prevention），从而提升模型性能。在 LongBench 基准测试中，该方法使 Falcon3-Mamba-Inst-7B 模型提升 14%、Falcon-Mamba-Inst-7B 提升 28%、RecurrentGemma-IT-9B 提升 50%、RWKV6-Finch-7B 提升 51%。此外，该方法在 LongBench v2 上实现了最先进水平，与同等大小的 Transformers 模型竞争，并质疑循环模型是否真正利用了长程依赖，因为单块策略在跨上下文任务中表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07793v1",
      "published_date": "2025-05-12 17:45:05 UTC",
      "updated_date": "2025-05-12 17:45:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:37:59.386766"
    },
    {
      "arxiv_id": "2505.07775v1",
      "title": "Must Read: A Systematic Survey of Computational Persuasion",
      "title_zh": "必读：计算说服的系统综述",
      "authors": [
        "Nimet Beyza Bozdag",
        "Shuhaib Mehri",
        "Xiaocheng Yang",
        "Hyeonjeong Ha",
        "Zirui Cheng",
        "Esin Durmus",
        "Jiaxuan You",
        "Heng Ji",
        "Gokhan Tur",
        "Dilek Hakkani-Tür"
      ],
      "abstract": "Persuasion is a fundamental aspect of communication, influencing\ndecision-making across diverse contexts, from everyday conversations to\nhigh-stakes scenarios such as politics, marketing, and law. The rise of\nconversational AI systems has significantly expanded the scope of persuasion,\nintroducing both opportunities and risks. AI-driven persuasion can be leveraged\nfor beneficial applications, but also poses threats through manipulation and\nunethical influence. Moreover, AI systems are not only persuaders, but also\nsusceptible to persuasion, making them vulnerable to adversarial attacks and\nbias reinforcement. Despite rapid advancements in AI-generated persuasive\ncontent, our understanding of what makes persuasion effective remains limited\ndue to its inherently subjective and context-dependent nature. In this survey,\nwe provide a comprehensive overview of computational persuasion, structured\naround three key perspectives: (1) AI as a Persuader, which explores\nAI-generated persuasive content and its applications; (2) AI as a Persuadee,\nwhich examines AI's susceptibility to influence and manipulation; and (3) AI as\na Persuasion Judge, which analyzes AI's role in evaluating persuasive\nstrategies, detecting manipulation, and ensuring ethical persuasion. We\nintroduce a taxonomy for computational persuasion research and discuss key\nchallenges, including evaluating persuasiveness, mitigating manipulative\npersuasion, and developing responsible AI-driven persuasive systems. Our survey\noutlines future research directions to enhance the safety, fairness, and\neffectiveness of AI-powered persuasion while addressing the risks posed by\nincreasingly capable language models.",
      "tldr_zh": "这篇调查论文系统地审视了计算说服（computational persuasion），强调其在AI时代的影响，包括机会（如有益应用）和风险（如操纵与不道德影响）。论文从三个关键视角组织内容：（1）AI作为说服者（AI as a Persuader），探讨AI生成说服性内容的应用；（2）AI作为被说服者（AI as a Persuadee），分析AI对影响的易受性；以及（3）AI作为说服判断者（AI as a Persuasion Judge），评估AI在检测操纵和确保伦理方面的作用。作者引入了一个计算说服研究分类法（taxonomy），并讨论了主要挑战，如评估说服性、缓解操纵性说服，以及开发负责任的AI系统。最终，论文概述了未来研究方向，以提升AI驱动说服的安全性、公平性和有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07775v1",
      "published_date": "2025-05-12 17:26:31 UTC",
      "updated_date": "2025-05-12 17:26:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:38:08.006463"
    },
    {
      "arxiv_id": "2505.07773v2",
      "title": "Agent RL Scaling Law: Agent RL with Spontaneous Code Execution for Mathematical Problem Solving",
      "title_zh": "Agent RL 规模定律：Agent RL 结合自发代码执行用于数学问题解决",
      "authors": [
        "Xinji Mai",
        "Haotian Xu",
        "Xing W",
        "Weinong Wang",
        "Yingying Zhang",
        "Wenqiang Zhang"
      ],
      "abstract": "Large Language Models (LLMs) often struggle with mathematical reasoning tasks\nrequiring precise, verifiable computation. While Reinforcement Learning (RL)\nfrom outcome-based rewards enhances text-based reasoning, understanding how\nagents autonomously learn to leverage external tools like code execution\nremains crucial. We investigate RL from outcome-based rewards for\nTool-Integrated Reasoning, ZeroTIR, training base LLMs to spontaneously\ngenerate and execute Python code for mathematical problems without supervised\ntool-use examples. Our central contribution is we demonstrate that as RL\ntraining progresses, key metrics scale predictably. Specifically, we observe\nstrong positive correlations where increased training steps lead to increases\nin the spontaneous code execution frequency, the average response length, and,\ncritically, the final task accuracy. This suggests a quantifiable relationship\nbetween computational effort invested in training and the emergence of\neffective, tool-augmented reasoning strategies. We implement a robust framework\nfeaturing a decoupled code execution environment and validate our findings\nacross standard RL algorithms and frameworks. Experiments show ZeroTIR\nsignificantly surpasses non-tool ZeroRL baselines on challenging math\nbenchmarks. Our findings provide a foundational understanding of how autonomous\ntool use is acquired and scales within Agent RL, offering a reproducible\nbenchmark for future studies. Code is released at\n\\href{https://github.com/yyht/openrlhf_async_pipline}{https://github.com/yyht/openrlhf\\_async\\_pipline}.",
      "tldr_zh": "本研究探讨了使用强化学习 (RL) 训练大型语言模型 (LLMs) 来解决数学推理任务，焦点在于模型自发生成和执行 Python code 的 ZeroTIR 框架，而无需监督的工具使用示例。通过分析 RL 的基于结果奖励机制，研究发现训练步骤增加与代码执行频率、响应长度以及任务准确率呈强正相关关系，这揭示了 RL 训练中工具增强推理策略的量化缩放定律 (Scaling Law)。实验结果显示，ZeroTIR 在挑战性数学基准测试中显著优于无工具的 ZeroRL 基线，提升了模型的自主工具使用能力。该框架提供了一个解耦的代码执行环境，并开源代码以供未来研究参考。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07773v2",
      "published_date": "2025-05-12 17:23:34 UTC",
      "updated_date": "2025-05-14 04:15:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:38:09.050077"
    },
    {
      "arxiv_id": "2505.07768v1",
      "title": "Enhancing Code Generation via Bidirectional Comment-Level Mutual Grounding",
      "title_zh": "通过双向注释级相互 grounding 增强代码生成",
      "authors": [
        "Yifeng Di",
        "Tianyi Zhang"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated unprecedented capability in\ncode generation. However, LLM-generated code is still plagued with a wide range\nof functional errors, especially for complex programming tasks that LLMs have\nnot seen before. Recent studies have shown that developers often struggle with\ninspecting and fixing incorrect code generated by LLMs, diminishing their\nproductivity and trust in LLM-based code generation. Inspired by the mutual\ngrounding theory in communication, we propose an interactive approach that\nleverages code comments as a medium for developers and LLMs to establish a\nshared understanding. Our approach facilitates iterative grounding by\ninterleaving code generation, inline comment generation, and contextualized\nuser feedback through editable comments to align generated code with developer\nintent. We evaluated our approach on two popular benchmarks and demonstrated\nthat our approach significantly improved multiple state-of-the-art LLMs, e.g.,\n17.1% pass@1 improvement for code-davinci-002 on HumanEval. Furthermore, we\nconducted a user study with 12 participants in comparison to two baselines: (1)\ninteracting with GitHub Copilot, and (2) interacting with a multi-step code\ngeneration paradigm called Multi-Turn Program Synthesis. Participants completed\nthe given programming tasks 16.7% faster and with 10.5% improvement in task\nsuccess rate when using our approach. Both results show that interactively\nrefining code comments enables the collaborative establishment of mutual\ngrounding, leading to more accurate code generation and higher developer\nconfidence.",
      "tldr_zh": "这篇论文针对大型语言模型（LLMs）在代码生成中存在的功能错误问题，提出了一种基于双向注释级互操作（Bidirectional Comment-Level Mutual Grounding）的交互式方法，通过交替代码生成、内联注释生成和用户反馈来建立开发者和模型间的共享理解。方法允许迭代优化，确保生成的代码与开发者意图对齐。在基准测试中，该方法显著提升了 LLMs 的性能，例如 code-davinci-002 在 HumanEval 上 pass@1 提高了 17.1%。用户研究进一步证明，使用此方法，开发人员完成编程任务的速度提升 16.7%，成功率提高 10.5%。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted to ICSE 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.07768v1",
      "published_date": "2025-05-12 17:20:30 UTC",
      "updated_date": "2025-05-12 17:20:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:38:13.450516"
    },
    {
      "arxiv_id": "2505.07759v1",
      "title": "\"I Apologize For Not Understanding Your Policy\": Exploring the Specification and Evaluation of User-Managed Access Control Policies by AI Virtual Assistants",
      "title_zh": "“我为不理解您的政策而道歉”：探索AI虚拟助手对用户管理的访问控制策略的规范和评估",
      "authors": [
        "Jennifer Mondragon",
        "Carlos Rubio-Medrano",
        "Gael Cruz",
        "Dvijesh Shastri"
      ],
      "abstract": "The rapid evolution of Artificial Intelligence (AI)-based Virtual Assistants\n(VAs) e.g., Google Gemini, ChatGPT, Microsoft Copilot, and High-Flyer Deepseek\nhas turned them into convenient interfaces for managing emerging technologies\nsuch as Smart Homes, Smart Cars, Electronic Health Records, by means of\nexplicit commands,e.g., prompts, which can be even launched via voice, thus\nproviding a very convenient interface for end-users. However, the proper\nspecification and evaluation of User-Managed Access Control Policies (U-MAPs),\nthe rules issued and managed by end-users to govern access to sensitive data\nand device functionality - within these VAs presents significant challenges,\nsince such a process is crucial for preventing security vulnerabilities and\nprivacy leaks without impacting user experience. This study provides an initial\nexploratory investigation on whether current publicly-available VAs can manage\nU-MAPs effectively across differing scenarios. By conducting unstructured to\nstructured tests, we evaluated the comprehension of such VAs, revealing a lack\nof understanding in varying U-MAP approaches. Our research not only identifies\nkey limitations, but offers valuable insights into how VAs can be further\nimproved to manage complex authorization rules and adapt to dynamic changes.",
      "tldr_zh": "这篇论文探讨了AI虚拟助手（如Google Gemini和ChatGPT）在管理用户管理访问控制策略（User-Managed Access Control Policies, U-MAPs）时的挑战，这些策略用于控制对敏感数据和设备功能的访问，以防止安全漏洞和隐私泄露。研究通过非结构化和结构化测试评估了现有VAs在不同场景下的理解能力，发现这些助手在处理各种U-MAP方法时存在显著不足。结果揭示了关键限制，并提供了宝贵见解，帮助改进VAs以更好地管理复杂授权规则并适应动态变化。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07759v1",
      "published_date": "2025-05-12 17:03:52 UTC",
      "updated_date": "2025-05-12 17:03:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:38:12.737209"
    },
    {
      "arxiv_id": "2505.07757v1",
      "title": "Emotion-Gradient Metacognitive RSI (Part I): Theoretical Foundations and Single-Agent Architecture",
      "title_zh": "Emotion-Gradient Metacognitive RSI (第一部分)：理论基础和单智能体架构",
      "authors": [
        "Rintaro Ando"
      ],
      "abstract": "We present the Emotion-Gradient Metacognitive Recursive Self-Improvement\n(EG-MRSI) framework, a novel architecture that integrates introspective\nmetacognition, emotion-based intrinsic motivation, and recursive\nself-modification into a unified theoretical system. The framework is\nexplicitly capable of overwriting its own learning algorithm under formally\nbounded risk. Building upon the Noise-to-Meaning RSI (N2M-RSI) foundation,\nEG-MRSI introduces a differentiable intrinsic reward function driven by\nconfidence, error, novelty, and cumulative success. This signal regulates both\na metacognitive mapping and a self-modification operator constrained by\nprovable safety mechanisms. We formally define the initial agent configuration,\nemotion-gradient dynamics, and RSI trigger conditions, and derive a\nreinforcement-compatible optimization objective that guides the agent's\ndevelopment trajectory. Meaning Density and Meaning Conversion Efficiency are\nintroduced as quantifiable metrics of semantic learning, closing the gap\nbetween internal structure and predictive informativeness. This Part I paper\nestablishes the single-agent theoretical foundations of EG-MRSI. Future parts\nwill extend this framework to include safety certificates and rollback\nprotocols (Part II), collective intelligence mechanisms (Part III), and\nfeasibility constraints including thermodynamic and computational limits (Part\nIV). Together, the EG-MRSI series provides a rigorous, extensible foundation\nfor open-ended and safe AGI.",
      "tldr_zh": "本论文提出了 Emotion-Gradient Metacognitive RSI (EG-MRSI) 框架，这是一个整合内省式元认知、基于情感的内在动机和递归自修改的统一系统，允许代理在形式化风险约束下重写自身学习算法。框架建立在 N2M-RSI 基础上，引入了由置信度、错误、新奇性和累积成功驱动的可微内在奖励函数，并定义了初始代理配置、情感梯度动态、RSI 触发条件以及一个兼容强化学习的优化目标，同时引入 Meaning Density 和 Meaning Conversion Efficiency 作为量化语义学习的指标。EG-MRSI 为单代理的开放式和安全 AGI 提供了理论基础，后续部分将扩展到安全证书、集体智能机制以及热力学和计算限制。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "F.1.2; I.2.0"
      ],
      "primary_category": "cs.AI",
      "comment": "21 pages, 3 figures. Part I of a four-part series (Parts II-IV\n  forthcoming)",
      "pdf_url": "http://arxiv.org/pdf/2505.07757v1",
      "published_date": "2025-05-12 17:02:47 UTC",
      "updated_date": "2025-05-12 17:02:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:38:16.984292"
    },
    {
      "arxiv_id": "2505.07755v1",
      "title": "Benchmarking of CPU-intensive Stream Data Processing in The Edge Computing Systems",
      "title_zh": "边缘计算系统中的 CPU 密集型流数据处理的基准测试",
      "authors": [
        "Tomasz Szydlo",
        "Viacheslaw Horbanow",
        "Dev Nandan Jha",
        "Shashikant Ilager",
        "Aleksander Slominski",
        "Rajiv Ranjan"
      ],
      "abstract": "Edge computing has emerged as a pivotal technology, offering significant\nadvantages such as low latency, enhanced data security, and reduced reliance on\ncentralized cloud infrastructure. These benefits are crucial for applications\nrequiring real-time data processing or strict security measures. Despite these\nadvantages, edge devices operating within edge clusters are often\nunderutilized. This inefficiency is mainly due to the absence of a holistic\nperformance profiling mechanism which can help dynamically adjust the desired\nsystem configuration for a given workload. Since edge computing environments\ninvolve a complex interplay between CPU frequency, power consumption, and\napplication performance, a deeper understanding of these correlations is\nessential. By uncovering these relationships, it becomes possible to make\ninformed decisions that enhance both computational efficiency and energy\nsavings. To address this gap, this paper evaluates the power consumption and\nperformance characteristics of a single processing node within an edge cluster\nusing a synthetic microbenchmark by varying the workload size and CPU\nfrequency. The results show how an optimal measure can lead to optimized usage\nof edge resources, given both performance and power consumption.",
      "tldr_zh": "边缘计算（Edge Computing）虽然提供低延迟、增强数据安全和减少对集中式云依赖等优势，但边缘设备利用率低下，主要由于缺少整体性能评估机制，无法动态调整系统配置以优化 CPU 频率、功耗和应用性能之间的关系。本文通过使用合成微基准测试评估单个处理节点的功耗和性能表现，系统地改变工作负载大小和 CPU 频率。结果表明，通过这种优化方法，可以实现边缘资源的有效利用，同时提升计算效率和能源节约。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07755v1",
      "published_date": "2025-05-12 17:02:02 UTC",
      "updated_date": "2025-05-12 17:02:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:38:16.249652"
    },
    {
      "arxiv_id": "2505.07921v2",
      "title": "Self-cross Feature based Spiking Neural Networks for Efficient Few-shot Learning",
      "title_zh": "基于自交叉特征的脉冲神经网络用于高效少样本学习",
      "authors": [
        "Qi Xu",
        "Junyang Zhu",
        "Dongdong Zhou",
        "Hao Chen",
        "Yang Liu",
        "Jiangrong Shen",
        "Qiang Zhang"
      ],
      "abstract": "Deep neural networks (DNNs) excel in computer vision tasks, especially,\nfew-shot learning (FSL), which is increasingly important for generalizing from\nlimited examples. However, DNNs are computationally expensive with scalability\nissues in real world. Spiking Neural Networks (SNNs), with their event-driven\nnature and low energy consumption, are particularly efficient in processing\nsparse and dynamic data, though they still encounter difficulties in capturing\ncomplex spatiotemporal features and performing accurate cross-class\ncomparisons. To further enhance the performance and efficiency of SNNs in\nfew-shot learning, we propose a few-shot learning framework based on SNNs,\nwhich combines a self-feature extractor module and a cross-feature contrastive\nmodule to refine feature representation and reduce power consumption. We apply\nthe combination of temporal efficient training loss and InfoNCE loss to\noptimize the temporal dynamics of spike trains and enhance the discriminative\npower. Experimental results show that the proposed FSL-SNN significantly\nimproves the classification performance on the neuromorphic dataset N-Omniglot,\nand also achieves competitive performance to ANNs on static datasets such as\nCUB and miniImageNet with low power consumption.",
      "tldr_zh": "该研究针对深度神经网络(DNNs)在少样本学习(Few-shot Learning, FSL)中的高计算开销问题，提出了一种基于脉冲神经网络(SNNs)的高效框架。该框架结合自特征提取模块和跨特征对比模块，以优化特征表示并降低功耗，同时使用时间高效训练损失(temporal efficient training loss)和InfoNCE损失来提升脉冲序列的时序动态和区分能力。实验结果显示，该框架在神经形态数据集N-Omniglot上显著提高了分类性能，并在静态数据集如CUB和miniImageNet上与ANNs相比表现出竞争性优势，同时实现了低功耗。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07921v2",
      "published_date": "2025-05-12 16:51:08 UTC",
      "updated_date": "2025-05-15 02:56:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:38:18.756720"
    },
    {
      "arxiv_id": "2505.07728v1",
      "title": "Guiding Data Collection via Factored Scaling Curves",
      "title_zh": "通过因子缩放曲线指导数据收集",
      "authors": [
        "Lihan Zha",
        "Apurva Badithela",
        "Michael Zhang",
        "Justin Lidard",
        "Jeremy Bao",
        "Emily Zhou",
        "David Snyder",
        "Allen Z. Ren",
        "Dhruv Shah",
        "Anirudha Majumdar"
      ],
      "abstract": "Generalist imitation learning policies trained on large datasets show great\npromise for solving diverse manipulation tasks. However, to ensure\ngeneralization to different conditions, policies need to be trained with data\ncollected across a large set of environmental factor variations (e.g., camera\npose, table height, distractors) $-$ a prohibitively expensive undertaking, if\ndone exhaustively. We introduce a principled method for deciding what data to\ncollect and how much to collect for each factor by constructing factored\nscaling curves (FSC), which quantify how policy performance varies as data\nscales along individual or paired factors. These curves enable targeted data\nacquisition for the most influential factor combinations within a given budget.\nWe evaluate the proposed method through extensive simulated and real-world\nexperiments, across both training-from-scratch and fine-tuning settings, and\nshow that it boosts success rates in real-world tasks in new environments by up\nto 26% over existing data-collection strategies. We further demonstrate how\nfactored scaling curves can effectively guide data collection using an offline\nmetric, without requiring real-world evaluation at scale.",
      "tldr_zh": "这篇论文提出了一种基于 Factored Scaling Curves (FSC) 的方法，用于指导数据收集过程，以训练通用模仿学习 policies，从而处理环境因素变化（如相机姿势、桌子高度和干扰物）带来的挑战。FSC 通过量化策略性能随单个或成对因素数据规模的变化，帮助在预算内优先获取最有影响的因素组合数据。实验结果显示，该方法在模拟和真实场景中提高了新环境下的任务成功率高达 26%，并能通过离线指标有效指导数据收集，而无需大规模真实评估。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Project website: https://factored-data-scaling.github.io",
      "pdf_url": "http://arxiv.org/pdf/2505.07728v1",
      "published_date": "2025-05-12 16:36:35 UTC",
      "updated_date": "2025-05-12 16:36:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:38:21.155499"
    },
    {
      "arxiv_id": "2505.07715v1",
      "title": "Hybrid Spiking Vision Transformer for Object Detection with Event Cameras",
      "title_zh": "混合脉冲视觉 Transformer 用于事件相机物体检测",
      "authors": [
        "Qi Xu",
        "Jie Deng",
        "Jiangrong Shen",
        "Biwu Chen",
        "Huajin Tang",
        "Gang Pan"
      ],
      "abstract": "Event-based object detection has gained increasing attention due to its\nadvantages such as high temporal resolution, wide dynamic range, and\nasynchronous address-event representation. Leveraging these advantages, Spiking\nNeural Networks (SNNs) have emerged as a promising approach, offering low\nenergy consumption and rich spatiotemporal dynamics. To further enhance the\nperformance of event-based object detection, this study proposes a novel hybrid\nspike vision Transformer (HsVT) model. The HsVT model integrates a spatial\nfeature extraction module to capture local and global features, and a temporal\nfeature extraction module to model time dependencies and long-term patterns in\nevent sequences. This combination enables HsVT to capture spatiotemporal\nfeatures, improving its capability to handle complex event-based object\ndetection tasks. To support research in this area, we developed and publicly\nreleased The Fall Detection Dataset as a benchmark for event-based object\ndetection tasks. This dataset, captured using an event-based camera, ensures\nfacial privacy protection and reduces memory usage due to the event\nrepresentation format. We evaluated the HsVT model on GEN1 and Fall Detection\ndatasets across various model sizes. Experimental results demonstrate that HsVT\nachieves significant performance improvements in event detection with fewer\nparameters.",
      "tldr_zh": "本研究提出了一种Hybrid Spiking Vision Transformer (HsVT)模型，用于基于Event Cameras的事件物体检测，旨在利用Spiking Neural Networks (SNNs)的低能耗和丰富时空动态优势。HsVT整合了空间特征提取模块（捕捉局部和全局特征）和时间特征提取模块（建模事件序列的时间依赖性和长期模式），从而提升了对复杂任务的处理能力。为支持该领域研究，团队开发并公开了The Fall Detection Dataset作为基准数据集，该数据集确保面部隐私保护并减少内存使用。实验结果显示，HsVT在GEN1和Fall Detection数据集上实现了显著性能改进，同时使用更少的参数。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07715v1",
      "published_date": "2025-05-12 16:19:20 UTC",
      "updated_date": "2025-05-12 16:19:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:38:23.337659"
    },
    {
      "arxiv_id": "2505.07711v1",
      "title": "Circuit Partitioning Using Large Language Models for Quantum Compilation and Simulations",
      "title_zh": "利用大型语言模型的电路分区，用于量子编译和模拟",
      "authors": [
        "Pranav Sinha",
        "Sumit Kumar Jha",
        "Sunny Raj"
      ],
      "abstract": "We are in the midst of the noisy intermediate-scale quantum (NISQ) era, where\nquantum computers are limited by noisy gates, some of which are more\nerror-prone than others and can render the final computation incomprehensible.\nQuantum circuit compilation algorithms attempt to minimize these noisy gates\nwhen mapping quantum algorithms onto quantum hardware but face computational\nchallenges that restrict their application to circuits with no more than 5-6\nqubits, necessitating the need to partition large circuits before the\napplication of noisy quantum gate minimization algorithms. The existing\ngeneration of these algorithms is heuristic in nature and does not account for\ndownstream gate minimization tasks. Large language models (LLMs) have the\npotential to change this and help improve quantum circuit partitions. This\npaper investigates the use of LLMs, such as Llama and Mistral, for partitioning\nquantum circuits by capitalizing on their abilities to understand and generate\ncode, including QASM. Specifically, we teach LLMs to partition circuits using\nthe quick partition approach of the Berkeley Quantum Synthesis Toolkit. Through\nexperimental evaluations, we show that careful fine-tuning of open source LLMs\nenables us to obtain an accuracy of 53.4% for the partition task while\nover-the-shelf LLMs are unable to correctly partition circuits, using standard\n1-shot and few-shot training approaches.",
      "tldr_zh": "该论文探讨了在 NISQ 时代使用大型语言模型(LLMs)，如 Llama 和 Mistral，对量子电路进行分区，以最小化噪声门并优化量子编译和模拟。研究方法包括教 LLMs 理解和生成 QASM 代码，并采用 Berkeley Quantum Synthesis Toolkit 的快速分区方法进行细化训练。实验结果显示，通过细调开源 LLMs，分区任务的准确率达到53.4%，而直接使用现成 LLMs 的1-shot 或 few-shot 方法无法有效实现分区，从而为量子电路处理提供了新途径。",
      "categories": [
        "cs.ET",
        "cs.AI",
        "quant-ph"
      ],
      "primary_category": "cs.ET",
      "comment": "7 pages, 2 tables and 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.07711v1",
      "published_date": "2025-05-12 16:18:48 UTC",
      "updated_date": "2025-05-12 16:18:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:38:25.796204"
    },
    {
      "arxiv_id": "2505.07701v1",
      "title": "Lightweight End-to-end Text-to-speech Synthesis for low resource on-device applications",
      "title_zh": "轻量级端到端文本到语音合成，用于低资源设备端应用",
      "authors": [
        "Biel Tura Vecino",
        "Adam Gabryś",
        "Daniel Mątwicki",
        "Andrzej Pomirski",
        "Tom Iddon",
        "Marius Cotescu",
        "Jaime Lorenzo-Trueba"
      ],
      "abstract": "Recent works have shown that modelling raw waveform directly from text in an\nend-to-end (E2E) fashion produces more natural-sounding speech than traditional\nneural text-to-speech (TTS) systems based on a cascade or two-stage approach.\nHowever, current E2E state-of-the-art models are computationally complex and\nmemory-consuming, making them unsuitable for real-time offline on-device\napplications in low-resource scenarios. To address this issue, we propose a\nLightweight E2E-TTS (LE2E) model that generates high-quality speech requiring\nminimal computational resources. We evaluate the proposed model on the LJSpeech\ndataset and show that it achieves state-of-the-art performance while being up\nto $90\\%$ smaller in terms of model parameters and $10\\times$ faster in\nreal-time-factor. Furthermore, we demonstrate that the proposed E2E training\nparadigm achieves better quality compared to an equivalent architecture trained\nin a two-stage approach. Our results suggest that LE2E is a promising approach\nfor developing real-time, high quality, low-resource TTS applications for\non-device applications.",
      "tldr_zh": "该论文提出了一种轻量级的端到-end (E2E) Text-to-speech (TTS) 合成模型，名为 Lightweight E2E-TTS (LE2E)，旨在为低资源设备提供高效的实时语音生成解决方案，以解决现有 E2E 模型计算复杂和内存消耗大的问题。LE2E 在 LJSpeech 数据集上实现了与最先进模型相当的性能，同时参数量减少 90% 且实时因子提升 10 倍。相比于等效的两阶段训练方法，E2E 训练范式进一步提升了语音质量。总体而言，该方法为低资源 on-device TTS 应用提供了高效且高质量的潜在方案。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Published as a conference paper at SSW 2023",
      "pdf_url": "http://arxiv.org/pdf/2505.07701v1",
      "published_date": "2025-05-12 16:10:15 UTC",
      "updated_date": "2025-05-12 16:10:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:38:35.106783"
    },
    {
      "arxiv_id": "2505.07920v1",
      "title": "Re$^2$: A Consistency-ensured Dataset for Full-stage Peer Review and Multi-turn Rebuttal Discussions",
      "title_zh": "Re$^2$：一个确保一致性的数据集，用于全阶段同行评审和多轮反驳讨论",
      "authors": [
        "Daoze Zhang",
        "Zhijian Bao",
        "Sihang Du",
        "Zhiyi Zhao",
        "Kuangling Zhang",
        "Dezheng Bao",
        "Yang Yang"
      ],
      "abstract": "Peer review is a critical component of scientific progress in the fields like\nAI, but the rapid increase in submission volume has strained the reviewing\nsystem, which inevitably leads to reviewer shortages and declines review\nquality. Besides the growing research popularity, another key factor in this\noverload is the repeated resubmission of substandard manuscripts, largely due\nto the lack of effective tools for authors to self-evaluate their work before\nsubmission. Large Language Models (LLMs) show great promise in assisting both\nauthors and reviewers, and their performance is fundamentally limited by the\nquality of the peer review data. However, existing peer review datasets face\nthree major limitations: (1) limited data diversity, (2) inconsistent and\nlow-quality data due to the use of revised rather than initial submissions, and\n(3) insufficient support for tasks involving rebuttal and reviewer-author\ninteractions. To address these challenges, we introduce the largest\nconsistency-ensured peer review and rebuttal dataset named Re^2, which\ncomprises 19,926 initial submissions, 70,668 review comments, and 53,818\nrebuttals from 24 conferences and 21 workshops on OpenReview. Moreover, the\nrebuttal and discussion stage is framed as a multi-turn conversation paradigm\nto support both traditional static review tasks and dynamic interactive LLM\nassistants, providing more practical guidance for authors to refine their\nmanuscripts and helping alleviate the growing review burden. Our data and code\nare available in https://anonymous.4open.science/r/ReviewBench_anon/.",
      "tldr_zh": "这篇论文引入了Re$^2$数据集，这是目前最大的确保一致性的同行评审和多轮驳斥讨论数据集，旨在解决AI等领域同行评审系统面临的提交量增加、评审者短缺以及现有数据集的局限性（如数据多样性不足和低质量）。Re$^2$包含19,926个初始提交、70,668个评论和53,818个驳斥，源自24个会议和21个研讨会，并将驳斥阶段构建为多轮对话范式，以支持传统静态任务和动态Large Language Models (LLMs)互动助手。数据集通过使用初始提交确保数据质量，提供实用指导帮助作者自评和改进稿件，从而减轻评审负担；相关数据和代码已在指定链接开放访问。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "2 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.07920v1",
      "published_date": "2025-05-12 16:02:52 UTC",
      "updated_date": "2025-05-12 16:02:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:38:38.146234"
    },
    {
      "arxiv_id": "2505.07693v1",
      "title": "Belief Injection for Epistemic Control in Linguistic State Space",
      "title_zh": "信念注入在语言状态空间中的认识论控制",
      "authors": [
        "Sebastian Dumbrava"
      ],
      "abstract": "This work introduces belief injection, a proactive epistemic control\nmechanism for artificial agents whose cognitive states are structured as\ndynamic ensembles of linguistic belief fragments. Grounded in the Semantic\nManifold framework, belief injection directly incorporates targeted linguistic\nbeliefs into an agent's internal cognitive state, influencing reasoning and\nalignment proactively rather than reactively. We delineate various injection\nstrategies, such as direct, context-aware, goal-oriented, and reflective\napproaches, and contrast belief injection with related epistemic control\nmechanisms, notably belief filtering. Additionally, this work discusses\npractical applications, implementation considerations, ethical implications,\nand outlines promising directions for future research into cognitive governance\nusing architecturally embedded belief injection.",
      "tldr_zh": "本研究引入了 belief injection 机制，作为一种主动的 epistemic control 方法，用于结构化为动态语言信念片段的智能体认知状态。该机制基于 Semantic Manifold 框架，直接将目标 linguistic beliefs 注入智能体的内部状态，从而主动影响其推理和对齐过程，而非被动响应。论文详细阐述了多种注入策略，包括 direct、context-aware、goal-oriented 和 reflective 方式，并将其与 belief filtering 等相关机制进行对比。同时，讨论了实际应用、实施考虑、伦理含义以及未来在认知治理领域的研究方向。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "30 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.07693v1",
      "published_date": "2025-05-12 15:58:56 UTC",
      "updated_date": "2025-05-12 15:58:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:38:37.124105"
    },
    {
      "arxiv_id": "2505.07686v1",
      "title": "S-GRPO: Early Exit via Reinforcement Learning in Reasoning Models",
      "title_zh": "S-GRPO：通过强化学习在推理模型中实现提前退出",
      "authors": [
        "Muzhi Dai",
        "Chenxu Yang",
        "Qingyi Si"
      ],
      "abstract": "As Test-Time Scaling emerges as an active research focus in the large\nlanguage model community, advanced post-training methods increasingly emphasize\nextending chain-of-thought (CoT) generation length, thereby enhancing reasoning\ncapabilities to approach Deepseek R1-like reasoning models. However, recent\nstudies reveal that reasoning models (even Qwen3) consistently exhibit\nexcessive thought redundancy in CoT generation. This overthinking problem stems\nfrom conventional outcome-reward reinforcement learning's systematic neglect in\nregulating intermediate reasoning steps. This paper proposes Serial-Group\nDecaying-Reward Policy Optimization (namely S-GRPO), a novel reinforcement\nlearning method that empowers models with the capability to determine the\nsufficiency of reasoning steps, subsequently triggering early exit of CoT\ngeneration. Specifically, unlike GRPO, which samples multiple possible\ncompletions (parallel group) in parallel, we select multiple temporal positions\nin the generation of one CoT to allow the model to exit thinking and instead\ngenerate answers (serial group), respectively. For the correct answers in a\nserial group, we assign rewards that decay according to positions, with lower\nrewards towards the later ones, thereby reinforcing the model's behavior to\ngenerate higher-quality answers at earlier phases with earlier exits of\nthinking. Empirical evaluations demonstrate compatibility with state-of-the-art\nreasoning models, including Qwen3 and Deepseek-distill models, achieving 35.4%\n~ 61.1\\% sequence length reduction with 0.72% ~ 6.08% accuracy improvements\nacross GSM8K, AIME 2024, AMC 2023, MATH-500, and GPQA Diamond benchmarks.",
      "tldr_zh": "这篇论文提出 S-GRPO，一种基于 Reinforcement Learning 的方法，用于解决大型语言模型在 Chain-of-Thought (CoT) 生成中的过度思考问题，从而实现早期退出（Early Exit）。S-GRPO 通过在单个 CoT 生成过程中选择多个时间点进行序列组采样，并分配递减奖励（Decaying-Reward），鼓励模型在早期阶段生成高质量答案，而不是冗余思考。与 GRPO 的并行采样不同，这种序列组策略强化了中间步骤的调节。实验结果显示，在 Qwen3 和 Deepseek-distill 等模型上，S-GRPO 实现了 35.4% ~ 61.1% 的序列长度减少，同时准确率提升 0.72% ~ 6.08%，在 GSM8K、AIME 2024 等基准上表现出色。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07686v1",
      "published_date": "2025-05-12 15:50:44 UTC",
      "updated_date": "2025-05-12 15:50:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:38:42.162688"
    },
    {
      "arxiv_id": "2505.07683v1",
      "title": "Multimodal Survival Modeling in the Age of Foundation Models",
      "title_zh": "多模态生存建模在基础模型时代",
      "authors": [
        "Steven Song",
        "Morgan Borjigin-Wang",
        "Irene Madejski",
        "Robert L. Grossman"
      ],
      "abstract": "The Cancer Genome Atlas (TCGA) has enabled novel discoveries and served as a\nlarge-scale reference through its harmonized genomics, clinical, and image\ndata. Prior studies have trained bespoke cancer survival prediction models from\nunimodal or multimodal TCGA data. A modern paradigm in biomedical deep learning\nis the development of foundation models (FMs) to derive meaningful feature\nembeddings, agnostic to a specific modeling task. Biomedical text especially\nhas seen growing development of FMs. While TCGA contains free-text data as\npathology reports, these have been historically underutilized. Here, we\ninvestigate the feasibility of training classical, multimodal survival models\nover zero-shot embeddings extracted by FMs. We show the ease and additive\neffect of multimodal fusion, outperforming unimodal models. We demonstrate the\nbenefit of including pathology report text and rigorously evaluate the effect\nof model-based text summarization and hallucination. Overall, we modernize\nsurvival modeling by leveraging FMs and information extraction from pathology\nreports.",
      "tldr_zh": "本研究探讨了在 foundation models (FMs) 时代，利用 The Cancer Genome Atlas (TCGA) 的多模态数据（如 genomics、clinical、image 和 pathology reports）来训练癌症生存预测模型。研究方法涉及使用 FMs 提取零-shot embeddings，并通过多模态融合构建模型，突显了 pathology reports 的潜在价值，同时评估了文本总结和幻觉的影响。结果显示，多模态模型显著优于单模态模型，证明了这种方法的易用性和效果加成，为现代生存建模提供了新范式。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "23 pages, 7 figures, 8 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.07683v1",
      "published_date": "2025-05-12 15:47:21 UTC",
      "updated_date": "2025-05-12 15:47:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:38:41.767814"
    },
    {
      "arxiv_id": "2505.07675v1",
      "title": "Simple Semi-supervised Knowledge Distillation from Vision-Language Models via $\\mathbf{\\texttt{D}}$ual-$\\mathbf{\\texttt{H}}$ead $\\mathbf{\\texttt{O}}$ptimization",
      "title_zh": "简单的半监督知识蒸馏：从视觉语言模型通过双头优化",
      "authors": [
        "Seongjae Kang",
        "Dong Bok Lee",
        "Hyungjoon Jang",
        "Sung Ju Hwang"
      ],
      "abstract": "Vision-language models (VLMs) have achieved remarkable success across diverse\ntasks by leveraging rich textual information with minimal labeled data.\nHowever, deploying such large models remains challenging, particularly in\nresource-constrained environments. Knowledge distillation (KD) offers a\nwell-established solution to this problem; however, recent KD approaches from\nVLMs often involve multi-stage training or additional tuning, increasing\ncomputational overhead and optimization complexity. In this paper, we propose\n$\\mathbf{\\texttt{D}}$ual-$\\mathbf{\\texttt{H}}$ead\n$\\mathbf{\\texttt{O}}$ptimization ($\\mathbf{\\texttt{DHO}}$) -- a simple yet\neffective KD framework that transfers knowledge from VLMs to compact,\ntask-specific models in semi-supervised settings. Specifically, we introduce\ndual prediction heads that independently learn from labeled data and teacher\npredictions, and propose to linearly combine their outputs during inference. We\nobserve that $\\texttt{DHO}$ mitigates gradient conflicts between supervised and\ndistillation signals, enabling more effective feature learning than single-head\nKD baselines. As a result, extensive experiments show that $\\texttt{DHO}$\nconsistently outperforms baselines across multiple domains and fine-grained\ndatasets. Notably, on ImageNet, it achieves state-of-the-art performance,\nimproving accuracy by 3% and 0.1% with 1% and 10% labeled data, respectively,\nwhile using fewer parameters.",
      "tldr_zh": "本研究提出了一种简单有效的知识蒸馏（KD）框架，名为 Dual-Head Optimization（DHO），旨在从 Vision-Language Models（VLMs）中转移知识到紧凑的任务特定模型，尤其适用于半监督场景。DHO 通过引入双预测头（一个从标记数据学习，另一个从教师预测学习），并在推理时线性组合它们的输出，从而缓解监督信号和蒸馏信号之间的梯度冲突，促进更有效的特征学习。实验结果显示，DHO 在多个领域和细粒度数据集上优于基线模型，例如在 ImageNet 上，使用 1% 和 10% 标记数据时，准确率分别提高了 3% 和 0.1%，同时使用更少的参数。总的来说，该方法简化了 VLMs 的部署过程，提供了一个高效的优化策略。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "41 pages, 19 figures, preprint",
      "pdf_url": "http://arxiv.org/pdf/2505.07675v1",
      "published_date": "2025-05-12 15:39:51 UTC",
      "updated_date": "2025-05-12 15:39:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:38:45.339061"
    },
    {
      "arxiv_id": "2505.07672v2",
      "title": "OnPrem.LLM: A Privacy-Conscious Document Intelligence Toolkit",
      "title_zh": "OnPrem.LLM：注重隐私的文档智能工具包",
      "authors": [
        "Arun S. Maiya"
      ],
      "abstract": "We present OnPrem$.$LLM, a Python-based toolkit for applying large language\nmodels (LLMs) to sensitive, non-public data in offline or restricted\nenvironments. The system is designed for privacy-preserving use cases and\nprovides prebuilt pipelines for document processing and storage,\nretrieval-augmented generation (RAG), information extraction, summarization,\nclassification, and prompt/output processing with minimal configuration.\nOnPrem$.$LLM supports multiple LLM backends -- including llama$.$cpp, Ollama,\nvLLM, and Hugging Face Transformers -- with quantized model support, GPU\nacceleration, and seamless backend switching. Although designed for fully local\nexecution, OnPrem$.$LLM also supports integration with a wide range of cloud\nLLM providers when permitted, enabling hybrid deployments that balance\nperformance with data control. A no-code web interface extends accessibility to\nnon-technical users.",
      "tldr_zh": "我们介绍了OnPrem.LLM，这是一个基于Python的工具包，旨在在离线或受限环境中处理敏感非公开数据，确保隐私保护。工具包提供预构建管道，包括文档处理、存储、RAG（检索增强生成）、信息提取、总结、分类以及提示/输出处理，支持多种LLM后端如llama.cpp、Ollama、vLLM和Hugging Face Transformers，并提供量化模型支持、GPU加速和无缝切换。OnPrem.LLM允许完全本地执行，同时支持与云提供商的混合部署，并通过无代码Web界面增强非技术用户的可访问性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "6 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.07672v2",
      "published_date": "2025-05-12 15:36:27 UTC",
      "updated_date": "2025-05-13 02:43:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:38:44.713187"
    },
    {
      "arxiv_id": "2505.07671v1",
      "title": "Benchmarking Retrieval-Augmented Generation for Chemistry",
      "title_zh": "针对化学的检索增强生成基准测试",
      "authors": [
        "Xianrui Zhong",
        "Bowen Jin",
        "Siru Ouyang",
        "Yanzhen Shen",
        "Qiao Jin",
        "Yin Fang",
        "Zhiyong Lu",
        "Jiawei Han"
      ],
      "abstract": "Retrieval-augmented generation (RAG) has emerged as a powerful framework for\nenhancing large language models (LLMs) with external knowledge, particularly in\nscientific domains that demand specialized and dynamic information. Despite its\npromise, the application of RAG in the chemistry domain remains underexplored,\nprimarily due to the lack of high-quality, domain-specific corpora and\nwell-curated evaluation benchmarks. In this work, we introduce ChemRAG-Bench, a\ncomprehensive benchmark designed to systematically assess the effectiveness of\nRAG across a diverse set of chemistry-related tasks. The accompanying chemistry\ncorpus integrates heterogeneous knowledge sources, including scientific\nliterature, the PubChem database, PubMed abstracts, textbooks, and Wikipedia\nentries. In addition, we present ChemRAG-Toolkit, a modular and extensible RAG\ntoolkit that supports five retrieval algorithms and eight LLMs. Using\nChemRAG-Toolkit, we demonstrate that RAG yields a substantial performance gain\n-- achieving an average relative improvement of 17.4% over direct inference\nmethods. We further conduct in-depth analyses on retriever architectures,\ncorpus selection, and the number of retrieved passages, culminating in\npractical recommendations to guide future research and deployment of RAG\nsystems in the chemistry domain. The code and data is available at\nhttps://chemrag.github.io.",
      "tldr_zh": "本研究针对化学领域的 Retrieval-Augmented Generation (RAG) 应用，引入了 ChemRAG-Bench 基准，用于系统评估 RAG 在多样化学任务上的有效性，以解决现有语料库和评估标准的不足。ChemRAG-Bench 整合了异构知识来源，包括科学文献、PubChem 数据库、PubMed 摘要、教科书和 Wikipedia 条目，同时开发了 ChemRAG-Toolkit，这是一个支持五种检索算法和八种 Large Language Models (LLMs) 的模块化工具包。实验结果显示，RAG 相较于直接推理方法平均提高了 17.4% 的性能，并通过深入分析检索器架构、语料库选择和检索段落数量，给出了化学领域 RAG 系统的实用部署建议。代码和数据可在 https://chemrag.github.io 获取。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07671v1",
      "published_date": "2025-05-12 15:34:45 UTC",
      "updated_date": "2025-05-12 15:34:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:38:48.772428"
    },
    {
      "arxiv_id": "2505.07664v1",
      "title": "A Case Study Investigating the Role of Generative AI in Quality Evaluations of Epics in Agile Software Development",
      "title_zh": "生成式 AI 在敏捷软件开发 Epic 质量评估中的作用：一个案例研究",
      "authors": [
        "Werner Geyer",
        "Jessica He",
        "Daita Sarkar",
        "Michelle Brachman",
        "Chris Hammond",
        "Jennifer Heins",
        "Zahra Ashktorab",
        "Carlos Rosemberg",
        "Charlie Hill"
      ],
      "abstract": "The broad availability of generative AI offers new opportunities to support\nvarious work domains, including agile software development. Agile epics are a\nkey artifact for product managers to communicate requirements to stakeholders.\nHowever, in practice, they are often poorly defined, leading to churn, delivery\ndelays, and cost overruns. In this industry case study, we investigate\nopportunities for large language models (LLMs) to evaluate agile epic quality\nin a global company. Results from a user study with 17 product managers\nindicate how LLM evaluations could be integrated into their work practices,\nincluding perceived values and usage in improving their epics. High levels of\nsatisfaction indicate that agile epics are a new, viable application of AI\nevaluations. However, our findings also outline challenges, limitations, and\nadoption barriers that can inform both practitioners and researchers on the\nintegration of such evaluations into future agile work practices.",
      "tldr_zh": "本研究通过一个行业案例研究，探讨了生成式 AI（特别是大型语言模型LLMs）在敏捷软件开发中评估Epic质量的作用，以解决Epic定义不佳导致的迭代混乱、延误和成本超支问题。研究涉及对17名产品经理进行用户研究，结果显示LLMs评估可以有效整合到工作实践中，提高Epic质量，并获得高满意度。研究确认了AI评估在敏捷领域的可行性，但也指出了挑战、限制和采用障碍，为从业者和研究者提供指导，帮助未来优化敏捷工作实践。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07664v1",
      "published_date": "2025-05-12 15:31:16 UTC",
      "updated_date": "2025-05-12 15:31:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:38:52.025230"
    },
    {
      "arxiv_id": "2505.07637v1",
      "title": "Chronocept: Instilling a Sense of Time in Machines",
      "title_zh": "Chronocept：赋予机器时间感",
      "authors": [
        "Krish Goel",
        "Sanskar Pandey",
        "KS Mahadevan",
        "Harsh Kumar",
        "Vishesh Khadaria"
      ],
      "abstract": "Human cognition is deeply intertwined with a sense of time, known as\nChronoception. This sense allows us to judge how long facts remain valid and\nwhen knowledge becomes outdated. Despite progress in vision, language, and\nmotor control, AI still struggles to reason about temporal validity. We\nintroduce Chronocept, the first benchmark to model temporal validity as a\ncontinuous probability distribution over time. Using skew-normal curves fitted\nalong semantically decomposed temporal axes, Chronocept captures nuanced\npatterns of emergence, decay, and peak relevance. It includes two datasets:\nBenchmark I (atomic facts) and Benchmark II (multi-sentence passages).\nAnnotations show strong inter-annotator agreement (84% and 89%). Our baselines\npredict curve parameters - location, scale, and skewness - enabling\ninterpretable, generalizable learning and outperforming classification-based\napproaches. Chronocept fills a foundational gap in AI's temporal reasoning,\nsupporting applications in knowledge grounding, fact-checking,\nretrieval-augmented generation (RAG), and proactive agents. Code and data are\npublicly available.",
      "tldr_zh": "该论文探讨了AI在时间有效性推理上的不足，引入Chronocept基准，这是首个将时间有效性建模为连续概率分布的方法。Chronocept使用skew-normal曲线沿语义分解的时间轴捕捉事实的出现、衰减和峰值相关模式，并提供了两个数据集：Benchmark I（原子事实）和Benchmark II（多句段落），标注一致性分别达到84%和89%。基线模型通过预测曲线参数（位置、规模和偏斜度）实现了可解释性和泛化性，优于基于分类的方案。总体上，Chronocept填补了AI时间推理的空白，支持知识grounding、事实检查、retrieval-augmented generation (RAG)以及主动代理的应用，并公开了代码和数据。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "20 pages, 8 figures, 18 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.07637v1",
      "published_date": "2025-05-12 15:07:32 UTC",
      "updated_date": "2025-05-12 15:07:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:38:52.000524"
    },
    {
      "arxiv_id": "2505.07634v2",
      "title": "Neural Brain: A Neuroscience-inspired Framework for Embodied Agents",
      "title_zh": "Neural Brain：一种受神经科学启发的具身代理框架",
      "authors": [
        "Jian Liu",
        "Xiongtao Shi",
        "Thai Duy Nguyen",
        "Haitian Zhang",
        "Tianxiang Zhang",
        "Wei Sun",
        "Yanjie Li",
        "Athanasios V. Vasilakos",
        "Giovanni Iacca",
        "Arshad Ali Khan",
        "Arvind Kumar",
        "Jae Won Cho",
        "Ajmal Mian",
        "Lihua Xie",
        "Erik Cambria",
        "Lin Wang"
      ],
      "abstract": "The rapid evolution of artificial intelligence (AI) has shifted from static,\ndata-driven models to dynamic systems capable of perceiving and interacting\nwith real-world environments. Despite advancements in pattern recognition and\nsymbolic reasoning, current AI systems, such as large language models, remain\ndisembodied, unable to physically engage with the world. This limitation has\ndriven the rise of embodied AI, where autonomous agents, such as humanoid\nrobots, must navigate and manipulate unstructured environments with human-like\nadaptability. At the core of this challenge lies the concept of Neural Brain, a\ncentral intelligence system designed to drive embodied agents with human-like\nadaptability. A Neural Brain must seamlessly integrate multimodal sensing and\nperception with cognitive capabilities. Achieving this also requires an\nadaptive memory system and energy-efficient hardware-software co-design,\nenabling real-time action in dynamic environments. This paper introduces a\nunified framework for the Neural Brain of embodied agents, addressing two\nfundamental challenges: (1) defining the core components of Neural Brain and\n(2) bridging the gap between static AI models and the dynamic adaptability\nrequired for real-world deployment. To this end, we propose a biologically\ninspired architecture that integrates multimodal active sensing,\nperception-cognition-action function, neuroplasticity-based memory storage and\nupdating, and neuromorphic hardware/software optimization. Furthermore, we also\nreview the latest research on embodied agents across these four aspects and\nanalyze the gap between current AI systems and human intelligence. By\nsynthesizing insights from neuroscience, we outline a roadmap towards the\ndevelopment of generalizable, autonomous agents capable of human-level\nintelligence in real-world scenarios.",
      "tldr_zh": "本论文提出“Neural Brain”，一个受神经科学启发的框架，旨在为“Embodied Agents”提供核心智能系统，帮助它们在真实环境中实现人类般的感知、互动和适应性。\n框架整合了多模态主动感知、感知-认知-行动功能、基于神经可塑性的记忆存储，以及神经形态硬件/软件优化，以桥接静态AI模型与动态环境部署的差距。\n通过回顾最新研究并分析当前AI与人类智能的差异，论文概述了通往通用自主代理的路线图，推动AI向更智能、更高效的方向发展。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "51 pages, 17 figures, 9 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.07634v2",
      "published_date": "2025-05-12 15:05:34 UTC",
      "updated_date": "2025-05-14 12:56:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:38:59.858659"
    },
    {
      "arxiv_id": "2505.07917v1",
      "title": "Efficient and Reproducible Biomedical Question Answering using Retrieval Augmented Generation",
      "title_zh": "高效且可复现的生物医学问答，使用检索增强生成",
      "authors": [
        "Linus Stuhlmann",
        "Michael Alexander Saxer",
        "Jonathan Fürst"
      ],
      "abstract": "Biomedical question-answering (QA) systems require effective retrieval and\ngeneration components to ensure accuracy, efficiency, and scalability. This\nstudy systematically examines a Retrieval-Augmented Generation (RAG) system for\nbiomedical QA, evaluating retrieval strategies and response time trade-offs. We\nfirst assess state-of-the-art retrieval methods, including BM25, BioBERT,\nMedCPT, and a hybrid approach, alongside common data stores such as\nElasticsearch, MongoDB, and FAISS, on a ~10% subset of PubMed (2.4M documents)\nto measure indexing efficiency, retrieval latency, and retriever performance in\nthe end-to-end RAG system. Based on these insights, we deploy the final RAG\nsystem on the full 24M PubMed corpus, comparing different retrievers' impact on\noverall performance. Evaluations of the retrieval depth show that retrieving 50\ndocuments with BM25 before reranking with MedCPT optimally balances accuracy\n(0.90), recall (0.90), and response time (1.91s). BM25 retrieval time remains\nstable (82ms), while MedCPT incurs the main computational cost. These results\nhighlight previously not well-known trade-offs in retrieval depth, efficiency,\nand scalability for biomedical QA. With open-source code, the system is fully\nreproducible and extensible.",
      "tldr_zh": "本研究系统评估了使用 Retrieval-Augmented Generation (RAG) 系统进行生物医学问答 (QA)，通过比较 BM25、BioBERT、MedCPT 等检索方法以及 Elasticsearch、MongoDB、FAISS 等数据存储，探讨了检索策略、效率和响应时间之间的权衡。\n在约10%的 PubMed 子集（2.4M 文档）上测试后，该系统扩展到完整24M 语料库，结果显示使用 BM25 检索50个文档并由 MedCPT 重新排序，能最佳平衡准确率（0.90）、召回率（0.90）和响应时间（1.91秒），其中 BM25 的检索时间保持稳定（82ms）。\n该开源系统突出了检索深度、效率和可伸缩性的关键权衡，提供可重现的框架以提升生物医学 QA 的准确性和实用性。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.DB",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted at SDS25",
      "pdf_url": "http://arxiv.org/pdf/2505.07917v1",
      "published_date": "2025-05-12 14:51:47 UTC",
      "updated_date": "2025-05-12 14:51:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:39:03.570531"
    },
    {
      "arxiv_id": "2505.07621v1",
      "title": "Bang for the Buck: Vector Search on Cloud CPUs",
      "title_zh": "性价比：云端 CPU 上的向量搜索",
      "authors": [
        "Leonardo Kuffo",
        "Peter Boncz"
      ],
      "abstract": "Vector databases have emerged as a new type of systems that support efficient\nquerying of high-dimensional vectors. Many of these offer their database as a\nservice in the cloud. However, the variety of available CPUs and the lack of\nvector search benchmarks across CPUs make it difficult for users to choose one.\nIn this study, we show that CPU microarchitectures available in the cloud\nperform significantly differently across vector search scenarios. For instance,\nin an IVF index on float32 vectors, AMD's Zen4 gives almost 3x more queries per\nsecond (QPS) compared to Intel's Sapphire Rapids, but for HNSW indexes, the\ntables turn. However, when looking at the number of queries per dollar (QP$),\nGraviton3 is the best option for most indexes and quantization settings, even\nover Graviton4 (Table 1). With this work, we hope to guide users in getting the\nbest \"bang for the buck\" when deploying vector search systems.",
      "tldr_zh": "该研究比较了云端 CPU 在向量搜索中的性能差异，旨在帮助用户选择最佳选项。研究发现，不同 CPU 微架构（如 AMD 的 Zen4 和 Intel 的 Sapphire Rapids）在各种场景下表现迥异，例如 Zen4 在 IVF index 上提供近 3 倍的查询每秒 (QPS)，但在 HNSW indexes 上则落后。考虑到成本因素，从查询每美元 (QP$) 角度评估，Graviton3 在大多数索引和量化设置下优于 Graviton4，成为最具性价比的选择。该工作为部署向量搜索系统提供了实用指导，确保用户获得最佳的“bang for the buck”。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "To be published in Proceedings of 21st International Workshop on Data\n  Management on New Hardware (DaMoN '25)",
      "pdf_url": "http://arxiv.org/pdf/2505.07621v1",
      "published_date": "2025-05-12 14:44:21 UTC",
      "updated_date": "2025-05-12 14:44:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:39:03.854004"
    },
    {
      "arxiv_id": "2505.07615v1",
      "title": "Diffused Responsibility: Analyzing the Energy Consumption of Generative Text-to-Audio Diffusion Models",
      "title_zh": "扩散责任：分析生成式文本到音频扩散模型的能源消耗",
      "authors": [
        "Riccardo Passoni",
        "Francesca Ronchini",
        "Luca Comanducci",
        "Romain Serizel",
        "Fabio Antonacci"
      ],
      "abstract": "Text-to-audio models have recently emerged as a powerful technology for\ngenerating sound from textual descriptions. However, their high computational\ndemands raise concerns about energy consumption and environmental impact. In\nthis paper, we conduct an analysis of the energy usage of 7 state-of-the-art\ntext-to-audio diffusion-based generative models, evaluating to what extent\nvariations in generation parameters affect energy consumption at inference\ntime. We also aim to identify an optimal balance between audio quality and\nenergy consumption by considering Pareto-optimal solutions across all selected\nmodels. Our findings provide insights into the trade-offs between performance\nand environmental impact, contributing to the development of more efficient\ngenerative audio models.",
      "tldr_zh": "本文分析了生成式文本-to-audio diffusion models 的能源消耗问题，强调其高计算需求可能带来的环境影响。研究评估了7个最先进模型在不同生成参数下的能源使用，并通过Pareto-optimal解决方案识别音频质量与能耗的最佳平衡。结果揭示了性能和环境影响之间的权衡，为开发更高效的生成音频模型提供了重要见解。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.LG",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07615v1",
      "published_date": "2025-05-12 14:36:47 UTC",
      "updated_date": "2025-05-12 14:36:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:39:05.458632"
    },
    {
      "arxiv_id": "2505.07610v1",
      "title": "Concept-Level Explainability for Auditing & Steering LLM Responses",
      "title_zh": "概念级可解释性用于审计与引导 LLM 响应",
      "authors": [
        "Kenza Amara",
        "Rita Sevastjanova",
        "Mennatallah El-Assady"
      ],
      "abstract": "As large language models (LLMs) become widely deployed, concerns about their\nsafety and alignment grow. An approach to steer LLM behavior, such as\nmitigating biases or defending against jailbreaks, is to identify which parts\nof a prompt influence specific aspects of the model's output. Token-level\nattribution methods offer a promising solution, but still struggle in text\ngeneration, explaining the presence of each token in the output separately,\nrather than the underlying semantics of the entire LLM response. We introduce\nConceptX, a model-agnostic, concept-level explainability method that identifies\nthe concepts, i.e., semantically rich tokens in the prompt, and assigns them\nimportance based on the outputs' semantic similarity. Unlike current\ntoken-level methods, ConceptX also offers to preserve context integrity through\nin-place token replacements and supports flexible explanation goals, e.g.,\ngender bias. ConceptX enables both auditing, by uncovering sources of bias, and\nsteering, by modifying prompts to shift the sentiment or reduce the harmfulness\nof LLM responses, without requiring retraining. Across three LLMs, ConceptX\noutperforms token-level methods like TokenSHAP in both faithfulness and human\nalignment. Steering tasks boost sentiment shift by 0.252 versus 0.131 for\nrandom edits and lower attack success rates from 0.463 to 0.242, outperforming\nattribution and paraphrasing baselines. While prompt engineering and\nself-explaining methods sometimes yield safer responses, ConceptX offers a\ntransparent and faithful alternative for improving LLM safety and alignment,\ndemonstrating the practical value of attribution-based explainability in\nguiding LLM behavior.",
      "tldr_zh": "该研究针对大型语言模型（LLMs）的安全性和对齐性问题，提出了一种模型无关的概念级别可解释性方法ConceptX，用于识别提示中的语义丰富概念并基于输出语义相似性分配重要性，从而支持审计和指导LLM行为。ConceptX通过原地token替换保留上下文完整性，并允许灵活设定解释目标，如缓解性别偏见，而无需重新训练模型。实验结果显示，ConceptX在三个LLMs上优于TokenSHAP方法，在忠实度和人类对齐方面表现更好，能够提升情感转移效果（提升0.252 vs 0.131）和降低攻击成功率（从0.463降至0.242），从而为改进LLM的安全性和对齐提供透明、可信的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages, 7 figures, Submission to Neurips 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.07610v1",
      "published_date": "2025-05-12 14:31:51 UTC",
      "updated_date": "2025-05-12 14:31:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:39:09.142689"
    },
    {
      "arxiv_id": "2505.07608v1",
      "title": "MiMo: Unlocking the Reasoning Potential of Language Model -- From Pretraining to Posttraining",
      "title_zh": "MiMo: 解锁语言模型的推理潜力——从预训练到后训练",
      "authors": [
        "Xiaomi LLM-Core Team",
        ":",
        "Bingquan Xia",
        "Bowen Shen",
        "Cici",
        "Dawei Zhu",
        "Di Zhang",
        "Gang Wang",
        "Hailin Zhang",
        "Huaqiu Liu",
        "Jiebao Xiao",
        "Jinhao Dong",
        "Liang Zhao",
        "Peidian Li",
        "Peng Wang",
        "Shihua Yu",
        "Shimao Chen",
        "Weikun Wang",
        "Wenhan Ma",
        "Xiangwei Deng",
        "Yi Huang",
        "Yifan Song",
        "Zihan Jiang",
        "Bowen Ye",
        "Can Cai",
        "Chenhong He",
        "Dong Zhang",
        "Duo Zhang",
        "Guoan Wang",
        "Hao Tian",
        "Haochen Zhao",
        "Heng Qu",
        "Hongshen Xu",
        "Jun Shi",
        "Kainan Bao",
        "QingKai Fang",
        "Kang Zhou",
        "Kangyang Zhou",
        "Lei Li",
        "Menghang Zhu",
        "Nuo Chen",
        "Qiantong Wang",
        "Shaohui Liu",
        "Shicheng Li",
        "Shuhao Gu",
        "Shuhuai Ren",
        "Shuo Liu",
        "Sirui Deng",
        "Weiji Zhuang",
        "Weiwei Lv",
        "Wenyu Yang",
        "Xin Zhang",
        "Xing Yong",
        "Xing Zhang",
        "Xingchen Song",
        "Xinzhe Xu",
        "Xu Wang",
        "Yihan Yan",
        "Yu Tu",
        "Yuanyuan Tian",
        "Yudong Wang",
        "Yue Yu",
        "Zhenru Lin",
        "Zhichao Song",
        "Zihao Yue"
      ],
      "abstract": "We present MiMo-7B, a large language model born for reasoning tasks, with\noptimization across both pre-training and post-training stages. During\npre-training, we enhance the data preprocessing pipeline and employ a\nthree-stage data mixing strategy to strengthen the base model's reasoning\npotential. MiMo-7B-Base is pre-trained on 25 trillion tokens, with additional\nMulti-Token Prediction objective for enhanced performance and accelerated\ninference speed. During post-training, we curate a dataset of 130K verifiable\nmathematics and programming problems for reinforcement learning, integrating a\ntest-difficulty-driven code-reward scheme to alleviate sparse-reward issues and\nemploying strategic data resampling to stabilize training. Extensive\nevaluations show that MiMo-7B-Base possesses exceptional reasoning potential,\noutperforming even much larger 32B models. The final RL-tuned model,\nMiMo-7B-RL, achieves superior performance on mathematics, code and general\nreasoning tasks, surpassing the performance of OpenAI o1-mini. The model\ncheckpoints are available at https://github.com/xiaomimimo/MiMo.",
      "tldr_zh": "我们介绍了 MiMo-7B，一种针对推理任务优化的语言模型，通过在 pre-training 和 post-training 阶段的全面优化来提升其推理潜力。在 pre-training 中，我们改进了数据预处理管道、采用三阶段数据混合策略，并在 25 万亿 tokens 上训练，同时整合 Multi-Token Prediction 目标以提高性能和加速推理。在 post-training 阶段，我们构建了 13 万可验证的数学和编程问题数据集，运用 reinforcement learning 结合 test-difficulty-driven code-reward 方案及数据重采样来解决稀疏奖励问题。实验结果显示，MiMo-7B-Base 超过了更大的 32B 模型，而最终的 MiMo-7B-RL 在数学、代码和一般推理任务上超越了 OpenAI o1-mini。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07608v1",
      "published_date": "2025-05-12 14:30:11 UTC",
      "updated_date": "2025-05-12 14:30:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:39:12.594894"
    },
    {
      "arxiv_id": "2505.07601v1",
      "title": "Characterizing the Investigative Methods of Fictional Detectives with Large Language Models",
      "title_zh": "利用大型语言模型表征虚构侦探的调查方法",
      "authors": [
        "Edirlei Soares de Lima",
        "Marco A. Casanova",
        "Bruno Feijó",
        "Antonio L. Furtado"
      ],
      "abstract": "Detective fiction, a genre defined by its complex narrative structures and\ncharacter-driven storytelling, presents unique challenges for computational\nnarratology, a research field focused on integrating literary theory into\nautomated narrative generation. While traditional literary studies have offered\ndeep insights into the methods and archetypes of fictional detectives, these\nanalyses often focus on a limited number of characters and lack the scalability\nneeded for the extraction of unique traits that can be used to guide narrative\ngeneration methods. In this paper, we present an AI-driven approach for\nsystematically characterizing the investigative methods of fictional\ndetectives. Our multi-phase workflow explores the capabilities of 15 Large\nLanguage Models (LLMs) to extract, synthesize, and validate distinctive\ninvestigative traits of fictional detectives. This approach was tested on a\ndiverse set of seven iconic detectives - Hercule Poirot, Sherlock Holmes,\nWilliam Murdoch, Columbo, Father Brown, Miss Marple, and Auguste Dupin -\ncapturing the distinctive investigative styles that define each character. The\nidentified traits were validated against existing literary analyses and further\ntested in a reverse identification phase, achieving an overall accuracy of\n91.43%, demonstrating the method's effectiveness in capturing the distinctive\ninvestigative approaches of each detective. This work contributes to the\nbroader field of computational narratology by providing a scalable framework\nfor character analysis, with potential applications in AI-driven interactive\nstorytelling and automated narrative generation.",
      "tldr_zh": "本文利用大型语言模型 (LLMs) 提出一种多阶段工作流，系统地表征虚构侦探的调查方法，以克服传统文学研究的局限性。研究对七位标志性侦探（如 Sherlock Holmes 和 Hercule Poirot）进行特征提取、合成和验证，准确捕捉了每个角色的独特调查风格，并在反向识别测试中达到91.43%的准确率。该方法为计算叙事学 (computational narratology) 提供了可扩展框架，支持AI驱动的互动故事生成和自动叙事。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07601v1",
      "published_date": "2025-05-12 14:24:58 UTC",
      "updated_date": "2025-05-12 14:24:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:39:12.100795"
    },
    {
      "arxiv_id": "2505.07596v1",
      "title": "Reinforced Internal-External Knowledge Synergistic Reasoning for Efficient Adaptive Search Agent",
      "title_zh": "强化内部-外部知识协同推理用于高效自适应搜索代理",
      "authors": [
        "Ziyang Huang",
        "Xiaowei Yuan",
        "Yiming Ju",
        "Jun Zhao",
        "Kang Liu"
      ],
      "abstract": "Retrieval-augmented generation (RAG) is a common strategy to reduce\nhallucinations in Large Language Models (LLMs). While reinforcement learning\n(RL) can enable LLMs to act as search agents by activating retrieval\ncapabilities, existing ones often underutilize their internal knowledge. This\ncan lead to redundant retrievals, potential harmful knowledge conflicts, and\nincreased inference latency. To address these limitations, an efficient and\nadaptive search agent capable of discerning optimal retrieval timing and\nsynergistically integrating parametric (internal) and retrieved (external)\nknowledge is in urgent need. This paper introduces the Reinforced\nInternal-External Knowledge Synergistic Reasoning Agent (IKEA), which could\nindentify its own knowledge boundary and prioritize the utilization of internal\nknowledge, resorting to external search only when internal knowledge is deemed\ninsufficient. This is achieved using a novel knowledge-boundary aware reward\nfunction and a knowledge-boundary aware training dataset. These are designed\nfor internal-external knowledge synergy oriented RL, incentivizing the model to\ndeliver accurate answers, minimize unnecessary retrievals, and encourage\nappropriate external searches when its own knowledge is lacking. Evaluations\nacross multiple knowledge reasoning tasks demonstrate that IKEA significantly\noutperforms baseline methods, reduces retrieval frequency significantly, and\nexhibits robust generalization capabilities.",
      "tldr_zh": "该论文提出IKEA（Reinforced Internal-External Knowledge Synergistic Reasoning Agent），一种高效的自适应搜索代理，用于优化Large Language Models (LLMs)中的Retrieval-augmented Generation (RAG)，以解决现有Reinforcement Learning (RL)代理未充分利用内部知识的问题，导致的冗余检索和知识冲突。IKEA通过引入知识边界感知奖励函数和训练数据集，实现内部知识与外部知识的协同推理，优先使用内部知识并仅在内部知识不足时进行外部搜索，从而提高准确性和效率。实验结果表明，IKEA在多个知识推理任务上显著优于基线方法，显著减少检索频率，并展示了强大的泛化能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07596v1",
      "published_date": "2025-05-12 14:21:57 UTC",
      "updated_date": "2025-05-12 14:21:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:39:15.179335"
    },
    {
      "arxiv_id": "2505.07591v1",
      "title": "A Multi-Dimensional Constraint Framework for Evaluating and Improving Instruction Following in Large Language Models",
      "title_zh": "一个多维约束框架，用于评估和改进大语言模型中的指令遵循",
      "authors": [
        "Junjie Ye",
        "Caishuang Huang",
        "Zhuohan Chen",
        "Wenjie Fu",
        "Chenyuan Yang",
        "Leyi Yang",
        "Yilong Wu",
        "Peng Wang",
        "Meng Zhou",
        "Xiaolong Yang",
        "Tao Gui",
        "Qi Zhang",
        "Zhongchao Shi",
        "Jianping Fan",
        "Xuanjing Huang"
      ],
      "abstract": "Instruction following evaluates large language models (LLMs) on their ability\nto generate outputs that adhere to user-defined constraints. However, existing\nbenchmarks often rely on templated constraint prompts, which lack the diversity\nof real-world usage and limit fine-grained performance assessment. To fill this\ngap, we propose a multi-dimensional constraint framework encompassing three\nconstraint patterns, four constraint categories, and four difficulty levels.\nBuilding on this framework, we develop an automated instruction generation\npipeline that performs constraint expansion, conflict detection, and\ninstruction rewriting, yielding 1,200 code-verifiable instruction-following\ntest samples. We evaluate 19 LLMs across seven model families and uncover\nsubstantial variation in performance across constraint forms. For instance,\naverage performance drops from 77.67% at Level I to 32.96% at Level IV.\nFurthermore, we demonstrate the utility of our approach by using it to generate\ndata for reinforcement learning, achieving substantial gains in instruction\nfollowing without degrading general performance. In-depth analysis indicates\nthat these gains stem primarily from modifications in the model's attention\nmodules parameters, which enhance constraint recognition and adherence. Code\nand data are available in https://github.com/Junjie-Ye/MulDimIF.",
      "tldr_zh": "该研究提出了一种多维约束框架，用于评估和提升大型语言模型（LLMs）的指令遵循能力，该框架涵盖三种约束模式、四种约束类别和四种难度级别，以解决现有基准缺乏多样性和细粒度评估的问题。研究开发了自动化指令生成管道，包括约束扩展、冲突检测和指令重写，生成1200个可代码验证的测试样本，并评估了19个LLMs模型，揭示性能在不同约束形式上的显著差异，例如从Level I的77.67%下降到Level IV的32.96%。通过使用该框架生成数据进行reinforcement learning训练，模型在指令遵循方面实现了显著提升，同时未影响整体性能。深入分析显示，这些改进主要源于模型注意力模块参数的调整，提升了约束识别和遵守能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07591v1",
      "published_date": "2025-05-12 14:16:55 UTC",
      "updated_date": "2025-05-12 14:16:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:39:16.280814"
    },
    {
      "arxiv_id": "2505.07581v1",
      "title": "YuLan-OneSim: Towards the Next Generation of Social Simulator with Large Language Models",
      "title_zh": "YuLan-OneSim：迈向使用大型语言模型的下一代社会模拟器",
      "authors": [
        "Lei Wang",
        "Heyang Gao",
        "Xiaohe Bo",
        "Xu Chen",
        "Ji-Rong Wen"
      ],
      "abstract": "Leveraging large language model (LLM) based agents to simulate human social\nbehaviors has recently gained significant attention. In this paper, we\nintroduce a novel social simulator called YuLan-OneSim. Compared to previous\nworks, YuLan-OneSim distinguishes itself in five key aspects: (1) Code-free\nscenario construction: Users can simply describe and refine their simulation\nscenarios through natural language interactions with our simulator. All\nsimulation code is automatically generated, significantly reducing the need for\nprogramming expertise. (2) Comprehensive default scenarios: We implement 50\ndefault simulation scenarios spanning 8 domains, including economics,\nsociology, politics, psychology, organization, demographics, law, and\ncommunication, broadening access for a diverse range of social researchers. (3)\nEvolvable simulation: Our simulator is capable of receiving external feedback\nand automatically fine-tuning the backbone LLMs, significantly enhancing the\nsimulation quality. (4) Large-scale simulation: By developing a fully\nresponsive agent framework and a distributed simulation architecture, our\nsimulator can handle up to 100,000 agents, ensuring more stable and reliable\nsimulation results. (5) AI social researcher: Leveraging the above features, we\ndevelop an AI social researcher. Users only need to propose a research topic,\nand the AI researcher will automatically analyze the input, construct\nsimulation environments, summarize results, generate technical reports, review\nand refine the reports--completing the social science research loop. To\ndemonstrate the advantages of YuLan-OneSim, we conduct experiments to evaluate\nthe quality of the automatically generated scenarios, the reliability,\nefficiency, and scalability of the simulation process, as well as the\nperformance of the AI social researcher.",
      "tldr_zh": "本文提出YuLan-OneSim，一种基于Large Language Models (LLM)的下一代社会模拟器，用于模拟人类社会行为，并通过五个关键创新提升了模拟的易用性和规模：无代码场景构建、50个默认场景覆盖8个领域（如经济学和社会学）、可演化模拟、支持多达10万代理的大规模架构，以及AI social researcher功能，能自动完成从研究主题分析到报告生成的整个流程。与现有方法相比，实验结果显示YuLan-OneSim显著提高了场景质量、模拟可靠性和效率，为社会科学研究提供了更强大的工具。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07581v1",
      "published_date": "2025-05-12 14:05:17 UTC",
      "updated_date": "2025-05-12 14:05:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:39:19.394279"
    },
    {
      "arxiv_id": "2505.07576v1",
      "title": "Evaluating Modern Visual Anomaly Detection Approaches in Semiconductor Manufacturing: A Comparative Study",
      "title_zh": "评估现代视觉异常检测方法在半导体制造中的应用：一项比较研究",
      "authors": [
        "Manuel Barusco",
        "Francesco Borsatti",
        "Youssef Ben Khalifa",
        "Davide Dalle Pezze",
        "Gian Antonio Susto"
      ],
      "abstract": "Semiconductor manufacturing is a complex, multistage process. Automated\nvisual inspection of Scanning Electron Microscope (SEM) images is indispensable\nfor minimizing equipment downtime and containing costs. Most previous research\nconsiders supervised approaches, assuming a sufficient number of anomalously\nlabeled samples. On the contrary, Visual Anomaly Detection (VAD), an emerging\nresearch domain, focuses on unsupervised learning, avoiding the costly defect\ncollection phase while providing explanations of the predictions. We introduce\na benchmark for VAD in the semiconductor domain by leveraging the MIIC dataset.\nOur results demonstrate the efficacy of modern VAD approaches in this field.",
      "tldr_zh": "本研究评估了现代视觉异常检测（Visual Anomaly Detection, VAD）方法在半导体制造中的性能，聚焦于无监督学习以避免昂贵的异常样本收集过程，并提供预测解释。研究利用MIIC数据集作为基准，对这些方法进行了比较分析，强调其在Scanning Electron Microscope (SEM)图像自动化视觉检查中的应用。结果表明，现代VAD方法在该领域表现出色，有效降低了设备停机时间和成本。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07576v1",
      "published_date": "2025-05-12 13:56:59 UTC",
      "updated_date": "2025-05-12 13:56:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:39:26.800767"
    },
    {
      "arxiv_id": "2505.07573v1",
      "title": "Robust Kidney Abnormality Segmentation: A Validation Study of an AI-Based Framework",
      "title_zh": "鲁棒肾脏异常分割：一个基于人工智能框架的验证研究",
      "authors": [
        "Sarah de Boer",
        "Hartmut Häntze",
        "Kiran Vaidhya Venkadesh",
        "Myrthe A. D. Buser",
        "Gabriel E. Humpire Mamani",
        "Lina Xu",
        "Lisa C. Adams",
        "Jawed Nawabi",
        "Keno K. Bressem",
        "Bram van Ginneken",
        "Mathias Prokop",
        "Alessa Hering"
      ],
      "abstract": "Kidney abnormality segmentation has important potential to enhance the\nclinical workflow, especially in settings requiring quantitative assessments.\nKidney volume could serve as an important biomarker for renal diseases, with\nchanges in volume correlating directly with kidney function. Currently,\nclinical practice often relies on subjective visual assessment for evaluating\nkidney size and abnormalities, including tumors and cysts, which are typically\nstaged based on diameter, volume, and anatomical location. To support a more\nobjective and reproducible approach, this research aims to develop a robust,\nthoroughly validated kidney abnormality segmentation algorithm, made publicly\navailable for clinical and research use. We employ publicly available training\ndatasets and leverage the state-of-the-art medical image segmentation framework\nnnU-Net. Validation is conducted using both proprietary and public test\ndatasets, with segmentation performance quantified by Dice coefficient and the\n95th percentile Hausdorff distance. Furthermore, we analyze robustness across\nsubgroups based on patient sex, age, CT contrast phases, and tumor histologic\nsubtypes. Our findings demonstrate that our segmentation algorithm, trained\nexclusively on publicly available data, generalizes effectively to external\ntest sets and outperforms existing state-of-the-art models across all tested\ndatasets. Subgroup analyses reveal consistent high performance, indicating\nstrong robustness and reliability. The developed algorithm and associated code\nare publicly accessible at\nhttps://github.com/DIAGNijmegen/oncology-kidney-abnormality-segmentation.",
      "tldr_zh": "本研究针对肾脏异常分割的临床需求，开发了一个基于AI的鲁棒框架，以提供更客观和可重复的定量评估，如通过肾脏体积作为肾脏疾病的生物标志物。该框架利用公开可用数据集和nnU-Net模型进行训练，并通过Dice coefficient和95th percentile Hausdorff distance等指标，在专有和公开测试集上进行验证。结果显示，该算法在外部数据集上泛化良好，优于现有最先进模型，并在患者性别、年龄、CT对比相和肿瘤组织亚型等子组中表现出一致的高鲁棒性。该算法及其代码已公开在https://github.com/DIAGNijmegen/oncology-kidney-abnormality-segmentation上，供临床和研究使用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "35 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.07573v1",
      "published_date": "2025-05-12 13:53:19 UTC",
      "updated_date": "2025-05-12 13:53:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:39:29.410768"
    },
    {
      "arxiv_id": "2505.07911v1",
      "title": "Combining Bayesian Inference and Reinforcement Learning for Agent Decision Making: A Review",
      "title_zh": "结合贝叶斯推理和强化学习用于代理决策：一个综述",
      "authors": [
        "Chengmin Zhou",
        "Ville Kyrki",
        "Pasi Fränti",
        "Laura Ruotsalainen"
      ],
      "abstract": "Bayesian inference has many advantages in decision making of agents (e.g.\nrobotics/simulative agent) over a regular data-driven black-box neural network:\nData-efficiency, generalization, interpretability, and safety where these\nadvantages benefit directly/indirectly from the uncertainty quantification of\nBayesian inference. However, there are few comprehensive reviews to summarize\nthe progress of Bayesian inference on reinforcement learning (RL) for decision\nmaking to give researchers a systematic understanding. This paper focuses on\ncombining Bayesian inference with RL that nowadays is an important approach in\nagent decision making. To be exact, this paper discusses the following five\ntopics: 1) Bayesian methods that have potential for agent decision making.\nFirst basic Bayesian methods and models (Bayesian rule, Bayesian learning, and\nBayesian conjugate models) are discussed followed by variational inference,\nBayesian optimization, Bayesian deep learning, Bayesian active learning,\nBayesian generative models, Bayesian meta-learning, and lifelong Bayesian\nlearning. 2) Classical combinations of Bayesian methods with model-based RL\n(with approximation methods), model-free RL, and inverse RL. 3) Latest\ncombinations of potential Bayesian methods with RL. 4) Analytical comparisons\nof methods that combine Bayesian methods with RL with respect to\ndata-efficiency, generalization, interpretability, and safety. 5) In-depth\ndiscussions in six complex problem variants of RL, including unknown reward,\npartial-observability, multi-agent, multi-task, non-linear non-Gaussian, and\nhierarchical RL problems and the summary of how Bayesian methods work in the\ndata collection, data processing and policy learning stages of RL to pave the\nway for better agent decision-making strategies.",
      "tldr_zh": "这篇综述论文探讨了Bayesian inference与reinforcement learning (RL)相结合在代理决策（如机器人）中的应用，强调Bayesian inference的优势，包括数据效率、泛化性、可解释性和安全性，这些源于其不确定性量化。论文系统总结了五大主题：潜在的Bayesian方法（如Bayesian rule、variational inference和Bayesian deep learning）、经典和最新组合（如与model-based RL或model-free RL的整合）、方法的分析比较，以及Bayesian方法在RL复杂变体（如多代理或部分可观察性问题）中的作用。最终，该综述为研究者提供了全面框架，帮助提升代理决策策略在数据收集、处理和政策学习阶段的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07911v1",
      "published_date": "2025-05-12 13:34:50 UTC",
      "updated_date": "2025-05-12 13:34:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:39:31.853159"
    },
    {
      "arxiv_id": "2505.07553v1",
      "title": "Towards Requirements Engineering for RAG Systems",
      "title_zh": "迈向 RAG 系统的需求工程",
      "authors": [
        "Tor Sporsem",
        "Rasmus Ulfsnes"
      ],
      "abstract": "This short paper explores how a maritime company develops and integrates\nlarge-language models (LLM). Specifically by looking at the requirements\nengineering for Retrieval Augmented Generation (RAG) systems in expert\nsettings. Through a case study at a maritime service provider, we demonstrate\nhow data scientists face a fundamental tension between user expectations of AI\nperfection and the correctness of the generated outputs. Our findings reveal\nthat data scientists must identify context-specific \"retrieval requirements\"\nthrough iterative experimentation together with users because they are the ones\nwho can determine correctness. We present an empirical process model describing\nhow data scientists practically elicited these \"retrieval requirements\" and\nmanaged system limitations. This work advances software engineering knowledge\nby providing insights into the specialized requirements engineering processes\nfor implementing RAG systems in complex domain-specific applications.",
      "tldr_zh": "这篇论文探讨了在专业环境中为检索增强生成（RAG）系统进行需求工程（Requirements Engineering）的过程，通过一个海事公司的案例研究，揭示了数据科学家在用户对AI完美性期望与生成输出正确性之间面临的根本张力。研究发现，数据科学家需通过与用户的迭代实验来识别特定上下文的“retrieval requirements”，以确保输出准确性，并管理系统限制。最终，该工作呈现了一个经验过程模型，推进了软件工程知识，为在复杂领域应用中实施RAG系统提供了宝贵见解。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted to EASE 2025, 17-20 June, Istanbul, Turkey",
      "pdf_url": "http://arxiv.org/pdf/2505.07553v1",
      "published_date": "2025-05-12 13:30:44 UTC",
      "updated_date": "2025-05-12 13:30:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:39:33.076358"
    },
    {
      "arxiv_id": "2505.07552v1",
      "title": "Automated Visual Attention Detection using Mobile Eye Tracking in Behavioral Classroom Studies",
      "title_zh": "利用移动眼动追踪在行为课堂研究中的自动视觉注意力检测",
      "authors": [
        "Efe Bozkir",
        "Christian Kosel",
        "Tina Seidel",
        "Enkelejda Kasneci"
      ],
      "abstract": "Teachers' visual attention and its distribution across the students in\nclassrooms can constitute important implications for student engagement,\nachievement, and professional teacher training. Despite that, inferring the\ninformation about where and which student teachers focus on is not trivial.\nMobile eye tracking can provide vital help to solve this issue; however, the\nuse of mobile eye tracking alone requires a significant amount of manual\nannotations. To address this limitation, we present an automated processing\npipeline concept that requires minimal manually annotated data to recognize\nwhich student the teachers focus on. To this end, we utilize state-of-the-art\nface detection models and face recognition feature embeddings to train face\nrecognition models with transfer learning in the classroom context and combine\nthese models with the teachers' gaze from mobile eye trackers. We evaluated our\napproach with data collected from four different classrooms, and our results\nshow that while it is possible to estimate the visually focused students with\nreasonable performance in all of our classroom setups, U-shaped and small\nclassrooms led to the best results with accuracies of approximately 0.7 and\n0.9, respectively. While we did not evaluate our method for teacher-student\ninteractions and focused on the validity of the technical approach, as our\nmethodology does not require a vast amount of manually annotated data and\noffers a non-intrusive way of handling teachers' visual attention, it could\nhelp improve instructional strategies, enhance classroom management, and\nprovide feedback for professional teacher development.",
      "tldr_zh": "本研究针对教师在课堂上的视觉注意力分布及其对学生参与度和教学的影响，提出了一种自动化检测方法，利用移动眼动追踪（mobile eye tracking）结合面部检测和面部识别特征嵌入。方法通过迁移学习（transfer learning）训练面部识别模型，仅需少量手动标注数据，即可识别教师关注的特定学生。实验在四个不同课堂环境中评估，结果显示U形和小型课堂的准确率最高，分别为约0.7和0.9。该方法提供非侵入式解决方案，有助于优化教学策略、提升课堂管理和支持教师专业发展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted as a long paper at the Educational Data Mining (EDM)\n  Conference 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.07552v1",
      "published_date": "2025-05-12 13:30:30 UTC",
      "updated_date": "2025-05-12 13:30:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:39:34.484957"
    },
    {
      "arxiv_id": "2505.07548v1",
      "title": "Noise Optimized Conditional Diffusion for Domain Adaptation",
      "title_zh": "噪声优化的条件扩散用于领域适应",
      "authors": [
        "Lingkun Luo",
        "Shiqiang Hu",
        "Liming Chen"
      ],
      "abstract": "Pseudo-labeling is a cornerstone of Unsupervised Domain Adaptation (UDA), yet\nthe scarcity of High-Confidence Pseudo-Labeled Target Domain Samples\n(\\textbf{hcpl-tds}) often leads to inaccurate cross-domain statistical\nalignment, causing DA failures. To address this challenge, we propose\n\\textbf{N}oise \\textbf{O}ptimized \\textbf{C}onditional \\textbf{D}iffusion for\n\\textbf{D}omain \\textbf{A}daptation (\\textbf{NOCDDA}), which seamlessly\nintegrates the generative capabilities of conditional diffusion models with the\ndecision-making requirements of DA to achieve task-coupled optimization for\nefficient adaptation. For robust cross-domain consistency, we modify the DA\nclassifier to align with the conditional diffusion classifier within a unified\noptimization framework, enabling forward training on noise-varying cross-domain\nsamples. Furthermore, we argue that the conventional \\( \\mathcal{N}(\\mathbf{0},\n\\mathbf{I}) \\) initialization in diffusion models often generates\nclass-confused hcpl-tds, compromising discriminative DA. To resolve this, we\nintroduce a class-aware noise optimization strategy that refines sampling\nregions for reverse class-specific hcpl-tds generation, effectively enhancing\ncross-domain alignment. Extensive experiments across 5 benchmark datasets and\n29 DA tasks demonstrate significant performance gains of \\textbf{NOCDDA} over\n31 state-of-the-art methods, validating its robustness and effectiveness.",
      "tldr_zh": "这篇论文针对无监督域适应（UDA）中高置信度伪标签目标域样本（hcpl-tds）的稀缺问题，提出了噪声优化条件扩散模型（NOCDDA），通过整合条件扩散模型的生成能力与 DA 的决策需求，实现任务耦合优化以提升跨域一致性。NOCDDA 修改了 DA 分类器，使其与条件扩散分类器在统一框架中对齐，并在噪声变化的跨域样本上进行前向训练；同时，引入类感知噪声优化策略，优化采样区域以生成更精确的反向类特定 hcpl-tds，从而增强跨域对齐。在 5 个基准数据集和 29 个 UDA 任务上的实验表明，NOCDDA 比 31 个最先进方法取得了显著性能提升，验证了其鲁棒性和有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 4 figures This work has been accepted by the International\n  Joint Conference on Artificial Intelligence (IJCAI 2025)",
      "pdf_url": "http://arxiv.org/pdf/2505.07548v1",
      "published_date": "2025-05-12 13:28:31 UTC",
      "updated_date": "2025-05-12 13:28:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:39:39.025830"
    },
    {
      "arxiv_id": "2505.07546v1",
      "title": "GRADA: Graph-based Reranker against Adversarial Documents Attack",
      "title_zh": "GRADA：基于图形的对抗性文档攻击重新排名器",
      "authors": [
        "Jingjie Zheng",
        "Aryo Pradipta Gema",
        "Giwon Hong",
        "Xuanli He",
        "Pasquale Minervini",
        "Youcheng Sun",
        "Qiongkai Xu"
      ],
      "abstract": "Retrieval Augmented Generation (RAG) frameworks improve the accuracy of large\nlanguage models (LLMs) by integrating external knowledge from retrieved\ndocuments, thereby overcoming the limitations of models' static intrinsic\nknowledge. However, these systems are susceptible to adversarial attacks that\nmanipulate the retrieval process by introducing documents that are adversarial\nyet semantically similar to the query. Notably, while these adversarial\ndocuments resemble the query, they exhibit weak similarity to benign documents\nin the retrieval set. Thus, we propose a simple yet effective Graph-based\nReranking against Adversarial Document Attacks (GRADA) framework aiming at\npreserving retrieval quality while significantly reducing the success of\nadversaries. Our study evaluates the effectiveness of our approach through\nexperiments conducted on five LLMs: GPT-3.5-Turbo, GPT-4o, Llama3.1-8b,\nLlama3.1-70b, and Qwen2.5-7b. We use three datasets to assess performance, with\nresults from the Natural Questions dataset demonstrating up to an 80% reduction\nin attack success rates while maintaining minimal loss in accuracy.",
      "tldr_zh": "该论文提出 GRADA 框架，这是一种基于图形的重新排序机制，旨在对抗 Retrieval Augmented Generation (RAG) 系统中的敌对文档攻击，这些攻击通过引入与查询语义相似但实际有害的文档来操纵检索过程。GRADA 通过构建图形结构来评估文档相似度，确保检索质量的同时显著降低攻击成功率。实验在 GPT-3.5-Turbo、GPT-4o、Llama3.1-8b、Llama3.1-70b 和 Qwen2.5-7b 等五个 Large Language Models (LLMs) 上进行，结果显示在 Natural Questions 数据集上，攻击成功率降低高达80%，而准确性损失最小。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07546v1",
      "published_date": "2025-05-12 13:27:35 UTC",
      "updated_date": "2025-05-12 13:27:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:39:39.277987"
    },
    {
      "arxiv_id": "2505.07910v1",
      "title": "Tuning for Trustworthiness -- Balancing Performance and Explanation Consistency in Neural Network Optimization",
      "title_zh": "可信性调优：平衡神经网络优化中的性能和解释一致性",
      "authors": [
        "Alexander Hinterleitner",
        "Thomas Bartz-Beielstein"
      ],
      "abstract": "Despite the growing interest in Explainable Artificial Intelligence (XAI),\nexplainability is rarely considered during hyperparameter tuning or neural\narchitecture optimization, where the focus remains primarily on minimizing\npredictive loss. In this work, we introduce the novel concept of XAI\nconsistency, defined as the agreement among different feature attribution\nmethods, and propose new metrics to quantify it. For the first time, we\nintegrate XAI consistency directly into the hyperparameter tuning objective,\ncreating a multi-objective optimization framework that balances predictive\nperformance with explanation robustness. Implemented within the Sequential\nParameter Optimization Toolbox (SPOT), our approach uses both weighted\naggregation and desirability-based strategies to guide model selection. Through\nour proposed framework and supporting tools, we explore the impact of\nincorporating XAI consistency into the optimization process. This enables us to\ncharacterize distinct regions in the architecture configuration space: one\nregion with poor performance and comparatively low interpretability, another\nwith strong predictive performance but weak interpretability due to low\n\\gls{xai} consistency, and a trade-off region that balances both objectives by\noffering high interpretability alongside competitive performance. Beyond\nintroducing this novel approach, our research provides a foundation for future\ninvestigations into whether models from the trade-off zone-balancing\nperformance loss and XAI consistency-exhibit greater robustness by avoiding\noverfitting to training performance, thereby leading to more reliable\npredictions on out-of-distribution data.",
      "tldr_zh": "该研究提出了一种新方法，将可解释人工智能（XAI）的解释一致性（XAI consistency）整合到神经网络优化中，以平衡预测性能和解释可靠性。作者定义了XAI consistency为不同特征归因方法之间的同意度，并引入新指标将其纳入多目标优化框架，使用Sequential Parameter Optimization Toolbox (SPOT)结合加权聚合和基于期望性的策略进行超参数调整。实验结果揭示了架构配置空间中的不同区域，包括性能差且解释性低的区域、高性能但解释性弱的区域，以及权衡两者的折中区域，这为开发更鲁棒的模型提供了基础，可能减少过拟合并提升对分布外数据的预测可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07910v1",
      "published_date": "2025-05-12 13:19:14 UTC",
      "updated_date": "2025-05-12 13:19:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:39:40.916333"
    },
    {
      "arxiv_id": "2505.07534v1",
      "title": "The Human-Data-Model Interaction Canvas for Visual Analytics",
      "title_zh": "视觉分析的人类-数据-模型交互画布",
      "authors": [
        "Jürgen Bernard"
      ],
      "abstract": "Visual Analytics (VA) integrates humans, data, and models as key actors in\ninsight generation and data-driven decision-making. This position paper values\nand reflects on 16 VA process models and frameworks and makes nine high-level\nobservations that motivate a fresh perspective on VA. The contribution is the\nHDMI Canvas, a perspective to VA that complements the strengths of existing VA\nprocess models and frameworks. It systematically characterizes diverse roles of\nhumans, data, and models, and how these actors benefit from and contribute to\nVA processes. The descriptive power of the HDMI Canvas eases the\ndifferentiation between a series of VA building blocks, rather than describing\ngeneral VA principles only. The canvas includes modern human-centered\nmethodologies, including human knowledge externalization and forms of feedback\nloops, while interpretable and explainable AI highlight model contributions\nbeyond their conventional outputs. The HDMI Canvas has generative power,\nguiding the design of new VA processes and is optimized for external\nstakeholders, improving VA outreach, interdisciplinary collaboration, and\nuser-centered design. The utility of the HDMI Canvas is demonstrated through\ntwo preliminary case studies.",
      "tldr_zh": "这篇论文探讨了Visual Analytics (VA) 中人类、数据和模型作为关键参与者在洞察生成和数据驱动决策中的作用，通过回顾16个VA过程模型和框架，并提出九个高层观察。论文的主要贡献是引入HDMI Canvas，这是一种新视角，能系统地描述人类、数据和模型的多样角色，以及它们如何相互受益和贡献于VA过程。HDMI Canvas 便于区分VA的构建块、整合现代以人为中心方法（如人类知识外部化和反馈循环）以及可解释和可解释 AI，同时指导新VA过程设计并提升跨学科合作。最终，通过两个初步案例研究，展示了HDMI Canvas 的实用性和优化外部利益相关者的潜力。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "7 pages, 5 figures, LaTeX; to appear at the 16th International\n  EuroVis Workshop on Visual Analytics (EuroVA'25) as a position paper",
      "pdf_url": "http://arxiv.org/pdf/2505.07534v1",
      "published_date": "2025-05-12 13:15:31 UTC",
      "updated_date": "2025-05-12 13:15:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:39:43.294150"
    },
    {
      "arxiv_id": "2505.07533v1",
      "title": "IKrNet: A Neural Network for Detecting Specific Drug-Induced Patterns in Electrocardiograms Amidst Physiological Variability",
      "title_zh": "IKrNet：一种用于在生理变异性中检测心电图特定药物诱导模式的神经网络",
      "authors": [
        "Ahmad Fall",
        "Federica Granese",
        "Alex Lence",
        "Dominique Fourer",
        "Blaise Hanczar",
        "Joe-Elie Salem",
        "Jean-Daniel Zucker",
        "Edi Prifti"
      ],
      "abstract": "Monitoring and analyzing electrocardiogram (ECG) signals, even under varying\nphysiological conditions, including those influenced by physical activity,\ndrugs and stress, is crucial to accurately assess cardiac health. However,\ncurrent AI-based methods often fail to account for how these factors interact\nand alter ECG patterns, ultimately limiting their applicability in real-world\nsettings. This study introduces IKrNet, a novel neural network model, which\nidentifies drug-specific patterns in ECGs amidst certain physiological\nconditions. IKrNet's architecture incorporates spatial and temporal dynamics by\nusing a convolutional backbone with varying receptive field size to capture\nspatial features. A bi-directional Long Short-Term Memory module is also\nemployed to model temporal dependencies. By treating heart rate variability as\na surrogate for physiological fluctuations, we evaluated IKrNet's performance\nacross diverse scenarios, including conditions with physical stress, drug\nintake alone, and a baseline without drug presence. Our assessment follows a\nclinical protocol in which 990 healthy volunteers were administered 80mg of\nSotalol, a drug which is known to be a precursor to Torsades-de-Pointes, a\nlife-threatening arrhythmia. We show that IKrNet outperforms state-of-the-art\nmodels' accuracy and stability in varying physiological conditions,\nunderscoring its clinical viability.",
      "tldr_zh": "本研究提出IKrNet，一种新型神经网络模型，用于在生理变异性（如身体活动、药物和压力影响）下检测ECG中的药物特定模式，解决了现有AI方法忽略这些因素的局限性。IKrNet的架构结合了卷积骨干网（以不同感受野大小捕捉空间特征）和双向Long Short-Term Memory（LSTM）模块，以建模时间依赖性。实验通过心率变异性作为生理波动代理，在990名健康志愿者服用80mg Sotalol的临床协议中评估模型性能，结果显示IKrNet在准确性和稳定性上优于现有模型，证明了其在真实临床场景中的可行性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07533v1",
      "published_date": "2025-05-12 13:14:47 UTC",
      "updated_date": "2025-05-12 13:14:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:39:45.680794"
    },
    {
      "arxiv_id": "2505.07531v1",
      "title": "QuantX: A Framework for Hardware-Aware Quantization of Generative AI Workloads",
      "title_zh": "QuantX: 生成式 AI 工作负载的硬件感知量化框架",
      "authors": [
        "Khurram Mazher",
        "Saad Bin Nasir"
      ],
      "abstract": "We present QuantX: a tailored suite of recipes for LLM and VLM quantization.\nIt is capable of quantizing down to 3-bit resolutions with minimal loss in\nperformance. The quantization strategies in QuantX take into account\nhardware-specific constraints to achieve efficient dequantization during\ninference ensuring flexible trade-off between runtime speed, memory requirement\nand model accuracy. Our results demonstrate that QuantX achieves performance\nwithin 6% of the unquantized model for LlaVa-v1.6 quantized down to 3-bits for\nmultiple end user tasks and outperforms recently published state-of-the-art\nquantization techniques. This manuscript provides insights into the LLM\nquantization process that motivated the range of recipes and options that are\nincorporated in QuantX.",
      "tldr_zh": "本研究提出了 QuantX 框架，这是一个针对生成式 AI 工作负载的硬件感知量化工具套件，能够将 LLM 和 VLM 量化到 3 位分辨率，同时最小化性能损失。\nQuantX 的量化策略考虑硬件特定约束，实现高效的去量化过程，从而在推理时平衡运行速度、内存需求和模型准确性。\n实验结果显示，在 LlaVa-v1.6 模型上量化到 3 位后，性能仅比未量化模型低 6%，并优于现有最先进量化技术。\n此外，该论文提供了 LLM 量化过程的见解，指导了 QuantX 中的多种方案设计。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07531v1",
      "published_date": "2025-05-12 13:13:06 UTC",
      "updated_date": "2025-05-12 13:13:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:39:55.313440"
    },
    {
      "arxiv_id": "2505.07512v1",
      "title": "ToolACE-DEV: Self-Improving Tool Learning via Decomposition and EVolution",
      "title_zh": "ToolACE-DEV：通过分解和进化实现自我改进的工具学习",
      "authors": [
        "Xu Huang",
        "Weiwen Liu",
        "Xingshan Zeng",
        "Yuefeng Huang",
        "Xinlong Hao",
        "Yuxian Wang",
        "Yirong Zeng",
        "Chuhan Wu",
        "Yasheng Wang",
        "Ruiming Tang",
        "Defu Lian"
      ],
      "abstract": "The tool-using capability of large language models (LLMs) enables them to\naccess up-to-date external information and handle complex tasks. Current\napproaches to enhancing this capability primarily rely on distilling advanced\nmodels by data synthesis. However, this method incurs significant costs\nassociated with advanced model usage and often results in data compatibility\nissues, led by the high discrepancy in the knowledge scope between the advanced\nmodel and the target model. To address these challenges, we propose\nToolACE-DEV, a self-improving framework for tool learning. First, we decompose\nthe tool-learning objective into sub-tasks that enhance basic tool-making and\ntool-using abilities. Then, we introduce a self-evolving paradigm that allows\nlightweight models to self-improve, reducing reliance on advanced LLMs.\nExtensive experiments validate the effectiveness of our approach across models\nof varying scales and architectures.",
      "tldr_zh": "该研究针对大型语言模型(LLMs)的工具使用能力问题，指出现有方法依赖高级模型的数据合成，存在高成本和兼容性挑战。ToolACE-DEV 框架通过分解工具学习目标为子任务（如提升工具制作和使用能力），并引入自演化范式，让轻量级模型实现自我改进，从而减少对高级LLMs的依赖。实验结果显示，该方法在不同规模和架构的模型上均表现出色，验证了其有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07512v1",
      "published_date": "2025-05-12 12:48:30 UTC",
      "updated_date": "2025-05-12 12:48:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:39:55.184337"
    },
    {
      "arxiv_id": "2505.07511v1",
      "title": "MAIS: Memory-Attention for Interactive Segmentation",
      "title_zh": "MAIS：记忆-注意力用于交互式分割",
      "authors": [
        "Mauricio Orbes-Arteaga",
        "Oeslle Lucena",
        "Sabastien Ourselin",
        "M. Jorge Cardoso"
      ],
      "abstract": "Interactive medical segmentation reduces annotation effort by refining\npredictions through user feedback. Vision Transformer (ViT)-based models, such\nas the Segment Anything Model (SAM), achieve state-of-the-art performance using\nuser clicks and prior masks as prompts. However, existing methods treat\ninteractions as independent events, leading to redundant corrections and\nlimited refinement gains. We address this by introducing MAIS, a\nMemory-Attention mechanism for Interactive Segmentation that stores past user\ninputs and segmentation states, enabling temporal context integration. Our\napproach enhances ViT-based segmentation across diverse imaging modalities,\nachieving more efficient and accurate refinements.",
      "tldr_zh": "交互式医疗分割通过用户反馈减少标注努力，但现有基于 Vision Transformer (ViT) 的模型如 Segment Anything Model (SAM)，因将交互视为独立事件，导致冗余修正和改进有限。论文提出 MAIS（Memory-Attention 机制），通过存储过去的用户输入和分割状态，整合时间上下文以提升模型的连续性。实验结果显示，MAIS 显著提高了 ViT-based 模型在多种成像模式下的分割效率和准确性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07511v1",
      "published_date": "2025-05-12 12:48:27 UTC",
      "updated_date": "2025-05-12 12:48:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:39:57.575973"
    },
    {
      "arxiv_id": "2505.07509v1",
      "title": "HALO: Half Life-Based Outdated Fact Filtering in Temporal Knowledge Graphs",
      "title_zh": "HALO: 基于半衰期的过时事实过滤在时序知识图谱中",
      "authors": [
        "Feng Ding",
        "Tingting Wang",
        "Yupeng Gao",
        "Shuo Yu",
        "Jing Ren",
        "Feng Xia"
      ],
      "abstract": "Outdated facts in temporal knowledge graphs (TKGs) result from exceeding the\nexpiration date of facts, which negatively impact reasoning performance on\nTKGs. However, existing reasoning methods primarily focus on positive\nimportance of historical facts, neglecting adverse effects of outdated facts.\nBesides, training on these outdated facts yields extra computational cost. To\naddress these challenges, we propose an outdated fact filtering framework named\nHALO, which quantifies the temporal validity of historical facts by exploring\nthe half-life theory to filter outdated facts in TKGs. HALO consists of three\nmodules: the temporal fact attention module, the dynamic relation-aware encoder\nmodule, and the outdated fact filtering module. Firstly, the temporal fact\nattention module captures the evolution of historical facts over time to\nidentify relevant facts. Secondly, the dynamic relation-aware encoder module is\ndesigned for efficiently predicting the half life of each fact. Finally, we\nconstruct a time decay function based on the half-life theory to quantify the\ntemporal validity of facts and filter outdated facts. Experimental results show\nthat HALO outperforms the state-of-the-art TKG reasoning methods on three\npublic datasets, demonstrating its effectiveness in detecting and filtering\noutdated facts (Codes are available at\nhttps://github.com/yushuowiki/K-Half/tree/main ).",
      "tldr_zh": "该论文针对 Temporal Knowledge Graphs (TKGs) 中过时事实导致的推理性能下降问题，提出 HALO 框架，该框架基于半衰期理论量化历史事实的时效性并进行过滤。HALO 包括三个模块：temporal fact attention module 用于捕捉事实演变、dynamic relation-aware encoder module 用于预测每个事实的半衰期，以及 outdated fact filtering module 用于构建时间衰减函数以筛选过时事实。实验结果显示，HALO 在三个公共数据集上优于现有 TKG 推理方法，证明了其在检测和过滤过时事实方面的有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07509v1",
      "published_date": "2025-05-12 12:47:20 UTC",
      "updated_date": "2025-05-12 12:47:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:39:59.584891"
    },
    {
      "arxiv_id": "2505.07508v1",
      "title": "EAGLE: Contrastive Learning for Efficient Graph Anomaly Detection",
      "title_zh": "EAGLE：用于高效图异常检测的对比学习",
      "authors": [
        "Jing Ren",
        "Mingliang Hou",
        "Zhixuan Liu",
        "Xiaomei Bai"
      ],
      "abstract": "Graph anomaly detection is a popular and vital task in various real-world\nscenarios, which has been studied for several decades. Recently, many studies\nextending deep learning-based methods have shown preferable performance on\ngraph anomaly detection. However, existing methods are lack of efficiency that\nis definitely necessary for embedded devices. Towards this end, we propose an\nEfficient Anomaly detection model on heterogeneous Graphs via contrastive\nLEarning (EAGLE) by contrasting abnormal nodes with normal ones in terms of\ntheir distances to the local context. The proposed method first samples\ninstance pairs on meta path-level for contrastive learning. Then, a graph\nautoencoder-based model is applied to learn informative node embeddings in an\nunsupervised way, which will be further combined with the discriminator to\npredict the anomaly scores of nodes. Experimental results show that EAGLE\noutperforms the state-of-the-art methods on three heterogeneous network\ndatasets.",
      "tldr_zh": "该研究针对图异常检测任务提出了一种高效模型EAGLE，通过对比学习对比异常节点与正常节点的局部距离来提升检测效率。EAGLE首先在元路径级别采样实例对，然后使用图自编码器进行无监督学习节点嵌入，并结合鉴别器计算节点异常分数。这种方法解决了现有深度学习模型在嵌入式设备上的效率问题。实验结果显示，EAGLE在三个异构网络数据集上超过了最先进的方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07508v1",
      "published_date": "2025-05-12 12:45:07 UTC",
      "updated_date": "2025-05-12 12:45:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:40:00.864085"
    },
    {
      "arxiv_id": "2505.07908v1",
      "title": "A Reproduction Study: The Kernel PCA Interpretation of Self-Attention Fails Under Scrutiny",
      "title_zh": "再现研究：自注意力机制的核主成分分析解释经不起仔细审查",
      "authors": [
        "Karahan Sarıtaş",
        "Çağatay Yıldız"
      ],
      "abstract": "In this reproduction study, we revisit recent claims that self-attention\nimplements kernel principal component analysis (KPCA) (Teo et al., 2024),\npositing that (i) value vectors $V$ capture the eigenvectors of the Gram matrix\nof the keys, and (ii) that self-attention projects queries onto the principal\ncomponent axes of the key matrix $K$ in a feature space. Our analysis reveals\nthree critical inconsistencies: (1) No alignment exists between learned\nself-attention value vectors and what is proposed in the KPCA perspective, with\naverage similarity metrics (optimal cosine similarity $\\leq 0.32$, linear CKA\n(Centered Kernel Alignment) $\\leq 0.11$, kernel CKA $\\leq 0.32$) indicating\nnegligible correspondence; (2) Reported decreases in reconstruction loss\n$J_\\text{proj}$, arguably justifying the claim that the self-attention\nminimizes the projection error of KPCA, are misinterpreted, as the quantities\ninvolved differ by orders of magnitude ($\\sim\\!10^3$); (3) Gram matrix\neigenvalue statistics, introduced to justify that $V$ captures the eigenvector\nof the gram matrix, are irreproducible without undocumented\nimplementation-specific adjustments. Across 10 transformer architectures, we\nconclude that the KPCA interpretation of self-attention lacks empirical\nsupport.",
      "tldr_zh": "这篇再现研究重新审视了 Teo et al. (2024) 的主张，即自注意力机制实现了核主成分分析 (KPCA)，具体声称值向量 $V$ 捕捉键的 Gram 矩阵特征向量，且自注意力将查询投影到键矩阵 $K$ 的主成分轴上。研究者通过分析发现三个关键不一致性：(1) 学习到的自注意力值向量与 KPCA 视角的向量对齐度极低，平均相似性指标如最优余弦相似度 ≤ 0.32、线性 CKA ≤ 0.11 和 kernel CKA ≤ 0.32；(2) 重建损失 $J_\\text{proj}$ 的减少被误解，因为相关数量相差数千倍；(3) Gram 矩阵特征值统计无法再现，除非使用未记录的实现调整。主要结论是，在 10 个 Transformer 架构上，自注意力的 KPCA 解释缺乏可靠的经验支持。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07908v1",
      "published_date": "2025-05-12 12:38:46 UTC",
      "updated_date": "2025-05-12 12:38:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:40:05.873398"
    },
    {
      "arxiv_id": "2505.07473v1",
      "title": "Web-Bench: A LLM Code Benchmark Based on Web Standards and Frameworks",
      "title_zh": "Web-Bench：基于 Web 标准和框架的 LLM 代码基准",
      "authors": [
        "Kai Xu",
        "YiWei Mao",
        "XinYi Guan",
        "ZiLong Feng"
      ],
      "abstract": "The application of large language models (LLMs) in the field of coding is\nevolving rapidly: from code assistants, to autonomous coding agents, and then\nto generating complete projects through natural language. Early LLM code\nbenchmarks primarily focused on code generation accuracy, but these benchmarks\nhave gradually become saturated. Benchmark saturation weakens their guiding\nrole for LLMs. For example, HumanEval Pass@1 has reached 99.4% and MBPP 94.2%.\nAmong various attempts to address benchmark saturation, approaches based on\nsoftware engineering have stood out, but the saturation of existing software\nengineering benchmarks is rapidly increasing. To address this, we propose a new\nbenchmark, Web-Bench, which contains 50 projects, each consisting of 20 tasks\nwith sequential dependencies. The tasks implement project features in sequence,\nsimulating real-world human development workflows. When designing Web-Bench, we\naim to cover the foundational elements of Web development: Web Standards and\nWeb Frameworks. Given the scale and complexity of these projects, which were\ndesigned by engineers with 5 to 10 years of experience, each presents a\nsignificant challenge. On average, a single project takes 4 to 8 hours for a\nsenior engineer to complete. On our given benchmark agent (Web-Agent), SOTA\n(Claude 3.7 Sonnet) achieves only 25.1% Pass@1, significantly lower (better)\nthan SWE-Bench's Verified (65.4%) and Full (33.8%) scores. Finally, we discuss\nthat in any development field, Standards and Frameworks represent foundational\nknowledge and efficiency tools, respectively, and LLMs require optimization\ntailored to them.",
      "tldr_zh": "本研究提出 Web-Bench，一种基于 Web 标准和框架的 LLM 代码基准，用于解决现有代码生成基准（如 HumanEval 和 MBPP）的饱和问题，通过模拟真实开发工作流来评估 LLM 的性能。Web-Bench 包含 50 个项目，每个项目由 20 个顺序依赖任务组成，由经验丰富的工程师设计，每个项目平均需资深工程师 4-8 小时完成。实验结果显示，在 Web-Agent 上，SOTA 模型（Claude 3.7 Sonnet）的 Pass@1 仅为 25.1%，远低于 SWE-Bench 的分数，突显 LLMs 在复杂 Web 开发任务中的挑战，并强调需要针对标准和框架进行优化。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "28 pages, 15 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.07473v1",
      "published_date": "2025-05-12 12:06:23 UTC",
      "updated_date": "2025-05-12 12:06:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:40:06.861628"
    },
    {
      "arxiv_id": "2505.07460v1",
      "title": "A Survey on Collaborative Mechanisms Between Large and Small Language Models",
      "title_zh": "大型语言模型与小型语言模型协作机制的综述",
      "authors": [
        "Yi Chen",
        "JiaHao Zhao",
        "HaoHao Han"
      ],
      "abstract": "Large Language Models (LLMs) deliver powerful AI capabilities but face\ndeployment challenges due to high resource costs and latency, whereas Small\nLanguage Models (SLMs) offer efficiency and deployability at the cost of\nreduced performance. Collaboration between LLMs and SLMs emerges as a crucial\nparadigm to synergistically balance these trade-offs, enabling advanced AI\napplications, especially on resource-constrained edge devices. This survey\nprovides a comprehensive overview of LLM-SLM collaboration, detailing various\ninteraction mechanisms (pipeline, routing, auxiliary, distillation, fusion),\nkey enabling technologies, and diverse application scenarios driven by\non-device needs like low latency, privacy, personalization, and offline\noperation. While highlighting the significant potential for creating more\nefficient, adaptable, and accessible AI, we also discuss persistent challenges\nincluding system overhead, inter-model consistency, robust task allocation,\nevaluation complexity, and security/privacy concerns. Future directions point\ntowards more intelligent adaptive frameworks, deeper model fusion, and\nexpansion into multimodal and embodied AI, positioning LLM-SLM collaboration as\na key driver for the next generation of practical and ubiquitous artificial\nintelligence.",
      "tldr_zh": "这篇调查论文探讨了 Large Language Models (LLMs) 与 Small Language Models (SLMs) 之间的协作机制，以平衡 LLMs 的强大性能和 SLMs 的高效部署。论文详细概述了多种交互方式，包括 pipeline、routing、auxiliary、distillation 和 fusion 等机制，以及关键技术在低延迟、隐私、个性化及离线操作等资源受限场景中的应用。虽有潜力提升 AI 的效率和可访问性，但论文也指出了挑战，如系统开销、模型一致性和安全问题，并展望未来方向，如智能自适应框架和多模态 AI 的扩展。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07460v1",
      "published_date": "2025-05-12 11:48:42 UTC",
      "updated_date": "2025-05-12 11:48:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:40:07.516044"
    },
    {
      "arxiv_id": "2505.07457v1",
      "title": "Can Generative AI agents behave like humans? Evidence from laboratory market experiments",
      "title_zh": "生成式 AI 代理能否像人类一样行为？ 实验室市场实验的证据",
      "authors": [
        "R. Maria del Rio-Chanona",
        "Marco Pangallo",
        "Cars Hommes"
      ],
      "abstract": "We explore the potential of Large Language Models (LLMs) to replicate human\nbehavior in economic market experiments. Compared to previous studies, we focus\non dynamic feedback between LLM agents: the decisions of each LLM impact the\nmarket price at the current step, and so affect the decisions of the other LLMs\nat the next step. We compare LLM behavior to market dynamics observed in\nlaboratory settings and assess their alignment with human participants'\nbehavior. Our findings indicate that LLMs do not adhere strictly to rational\nexpectations, displaying instead bounded rationality, similarly to human\nparticipants. Providing a minimal context window i.e. memory of three previous\ntime steps, combined with a high variability setting capturing response\nheterogeneity, allows LLMs to replicate broad trends seen in human experiments,\nsuch as the distinction between positive and negative feedback markets.\nHowever, differences remain at a granular level--LLMs exhibit less\nheterogeneity in behavior than humans. These results suggest that LLMs hold\npromise as tools for simulating realistic human behavior in economic contexts,\nthough further research is needed to refine their accuracy and increase\nbehavioral diversity.",
      "tldr_zh": "本研究探讨大型语言模型（LLMs）是否能在经济市场实验中复制人类行为，重点考察LLMs之间的动态反馈机制，其中每个LLMs的决策会影响当前市场价格并影响后续决策。研究通过比较LLMs与人类参与者的行为，发现LLMs表现出有限理性（bounded rationality），类似于人类，并在提供最小上下文窗口（记忆前三个时间步骤）和高变异性设置下，能复制人类实验中的整体趋势，如正负反馈市场的区别。然而，LLMs的行为异质性低于人类，表明尽管LLMs有潜力作为模拟人类行为的工具，但需进一步优化以提升准确性和多样性。",
      "categories": [
        "econ.GN",
        "cs.AI",
        "q-fin.EC"
      ],
      "primary_category": "econ.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07457v1",
      "published_date": "2025-05-12 11:44:46 UTC",
      "updated_date": "2025-05-12 11:44:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:40:09.883525"
    },
    {
      "arxiv_id": "2505.07453v1",
      "title": "How well do LLMs reason over tabular data, really?",
      "title_zh": "LLMs 在表格数据上推理能力到底有多好？真的？",
      "authors": [
        "Cornelius Wolff",
        "Madelon Hulsebos"
      ],
      "abstract": "Large Language Models (LLMs) excel in natural language tasks, but less is\nknown about their reasoning capabilities over tabular data. Prior analyses\ndevise evaluation strategies that poorly reflect an LLM's realistic performance\non tabular queries. Moreover, we have a limited understanding of the robustness\nof LLMs towards realistic variations in tabular inputs. Therefore, we ask: Can\ngeneral-purpose LLMs reason over tabular data, really?, and focus on two\nquestions 1) are tabular reasoning capabilities of general-purpose LLMs robust\nto real-world characteristics of tabular inputs, and 2) how can we\nrealistically evaluate an LLM's performance on analytical tabular queries?\nBuilding on a recent tabular reasoning benchmark, we first surface shortcomings\nof its multiple-choice prompt evaluation strategy, as well as commonly used\nfree-form text metrics such as SacreBleu and BERT-score. We show that an\nLLM-as-a-judge procedure yields more reliable performance insights and unveil a\nsignificant deficit in tabular reasoning performance of LLMs. We then extend\nthe tabular inputs reflecting three common characteristics in practice: 1)\nmissing values, 2) duplicate entities, and 3) structural variations.\nExperiments show that the tabular reasoning capabilities of general-purpose\nLLMs suffer from these variations, stressing the importance of improving their\nrobustness for realistic tabular inputs.",
      "tldr_zh": "这篇论文质疑了大型语言模型（LLMs）在表格数据上的推理能力，指出现有评估策略无法真实反映其性能，并探讨了LLMs对真实表格输入变异的鲁棒性。研究者分析了多选提示评估和常用指标如SacreBleu及BERT-score的不足，改用LLM-as-a-judge方法来获得更可靠的性能评估，结果显示LLMs在表格推理上存在显著缺陷。随后，他们扩展了表格输入以包括缺失值、重复实体和结构变化的常见特征，实验证明这些变异会严重影响LLMs的推理能力，强调了提升其鲁棒性的必要性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.07453v1",
      "published_date": "2025-05-12 11:35:28 UTC",
      "updated_date": "2025-05-12 11:35:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:40:12.116019"
    },
    {
      "arxiv_id": "2505.07450v2",
      "title": "Prototype Augmented Hypernetworks for Continual Learning",
      "title_zh": "原型增强超网络用于持续学习",
      "authors": [
        "Neil De La Fuente",
        "Maria Pilligua",
        "Daniel Vidal",
        "Albin Soutiff",
        "Cecilia Curreli",
        "Daniel Cremers",
        "Andrey Barsky"
      ],
      "abstract": "Continual learning (CL) aims to learn a sequence of tasks without forgetting\nprior knowledge, but gradient updates for a new task often overwrite the\nweights learned earlier, causing catastrophic forgetting (CF). We propose\nPrototype-Augmented Hypernetworks (PAH), a framework where a single\nhypernetwork, conditioned on learnable task prototypes, dynamically generates\ntask-specific classifier heads on demand. To mitigate forgetting, PAH combines\ncross-entropy with dual distillation losses, one to align logits and another to\nalign prototypes, ensuring stable feature representations across tasks.\nEvaluations on Split-CIFAR100 and TinyImageNet demonstrate that PAH achieves\nstate-of-the-art performance, reaching 74.5 % and 63.7 % accuracy with only 1.7\n% and 4.4 % forgetting, respectively, surpassing prior methods without storing\nsamples or heads.",
      "tldr_zh": "该论文针对持续学习(Continual Learning)中的灾难性遗忘(Catastrophic Forgetting)问题，提出了一种Prototype-Augmented Hypernetworks (PAH)框架，该框架利用一个超网络(hypernetwork)基于可学习的任务原型动态生成任务特定的分类器头，以避免新任务训练覆盖先前知识。PAH 通过结合交叉熵损失和双重蒸馏损失（一个用于对齐logits，另一个用于对齐原型）来保持特征表示的稳定性，从而缓解遗忘。实验结果显示，在Split-CIFAR100和TinyImageNet数据集上，PAH 分别实现了74.5%和63.7%的准确率，遗忘率仅为1.7%和4.4%，且无需存储样本或头，超越了现有方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "CVPR (LatinX in CV)",
      "pdf_url": "http://arxiv.org/pdf/2505.07450v2",
      "published_date": "2025-05-12 11:25:54 UTC",
      "updated_date": "2025-05-13 07:08:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:40:20.172618"
    },
    {
      "arxiv_id": "2505.07447v1",
      "title": "Unified Continuous Generative Models",
      "title_zh": "统一的连续生成模型",
      "authors": [
        "Peng Sun",
        "Yi Jiang",
        "Tao Lin"
      ],
      "abstract": "Recent advances in continuous generative models, including multi-step\napproaches like diffusion and flow-matching (typically requiring 8-1000\nsampling steps) and few-step methods such as consistency models (typically 1-8\nsteps), have demonstrated impressive generative performance. However, existing\nwork often treats these approaches as distinct paradigms, resulting in separate\ntraining and sampling methodologies. We introduce a unified framework for\ntraining, sampling, and analyzing these models. Our implementation, the Unified\nContinuous Generative Models Trainer and Sampler (UCGM-{T,S}), achieves\nstate-of-the-art (SOTA) performance. For example, on ImageNet 256x256 using a\n675M diffusion transformer, UCGM-T trains a multi-step model achieving 1.30 FID\nin 20 steps and a few-step model reaching 1.42 FID in just 2 steps.\nAdditionally, applying UCGM-S to a pre-trained model (previously 1.26 FID at\n250 steps) improves performance to 1.06 FID in only 40 steps. Code is available\nat: https://github.com/LINs-lab/UCGM.",
      "tldr_zh": "这篇论文提出了一种统一的框架，用于训练、采样和分析连续生成模型，包括多步方法（如diffusion和flow-matching）和少步方法（如consistency models），从而解决现有方法的分离问题。作者实现了UCGM-T和UCGM-S工具，实现了SOTA性能，例如在ImageNet 256x256上，使用675M diffusion transformer，UCGM-T训练的多步模型在20步达到1.30 FID，几步模型在2步达到1.42 FID。实验还显示，应用UCGM-S到预训练模型后，将采样步数从250步减少到40步，同时FID从1.26提升到1.06，为高效生成模型提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "https://github.com/LINs-lab/UCGM",
      "pdf_url": "http://arxiv.org/pdf/2505.07447v1",
      "published_date": "2025-05-12 11:15:39 UTC",
      "updated_date": "2025-05-12 11:15:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:40:24.031929"
    },
    {
      "arxiv_id": "2505.07437v1",
      "title": "LEAD: Iterative Data Selection for Efficient LLM Instruction Tuning",
      "title_zh": "LEAD：用于高效LLM指令微调的迭代数据选择",
      "authors": [
        "Xiaotian Lin",
        "Yanlin Qi",
        "Yizhang Zhu",
        "Themis Palpanas",
        "Chengliang Chai",
        "Nan Tang",
        "Yuyu Luo"
      ],
      "abstract": "Instruction tuning has emerged as a critical paradigm for improving the\ncapabilities and alignment of large language models (LLMs). However, existing\niterative model-aware data selection methods incur significant computational\noverhead, as they rely on repeatedly performing full-dataset model inference to\nestimate sample utility for subsequent training iterations, creating a\nfundamental efficiency bottleneck. In this paper, we propose LEAD, an efficient\niterative data selection framework that accurately estimates sample utility\nentirely within the standard training loop, eliminating the need for costly\nadditional model inference. At its core, LEAD introduces Instance-Level Dynamic\nUncertainty (IDU), a theoretically grounded utility function combining\ninstantaneous training loss, gradient-based approximation of loss changes, and\nexponential smoothing of historical loss signals. To further scale efficiently\nto large datasets, LEAD employs a two-stage, coarse-to-fine selection strategy,\nadaptively prioritizing informative clusters through a multi-armed bandit\nmechanism, followed by precise fine-grained selection of high-utility samples\nusing IDU. Extensive experiments across four diverse benchmarks show that LEAD\nsignificantly outperforms state-of-the-art methods, improving average model\nperformance by 6.1%-10.8% while using only 2.5% of the training data and\nreducing overall training time by 5-10x.",
      "tldr_zh": "本研究提出LEAD框架，用于高效的LLM指令微调，解决现有方法因反复全数据集模型推理而导致的计算开销问题。LEAD的核心是Instance-Level Dynamic Uncertainty (IDU)效用函数，该函数结合即时训练损失、梯度近似损失变化以及历史损失信号的指数平滑，并在标准训练循环中估计样本效用；同时，它采用两阶段粗到细选择策略，通过多臂赌博机优先筛选信息丰富的集群，再用IDU精确选择高效用样本。实验结果显示，LEAD在四个多样化基准上比现有方法提升模型性能6.1%-10.8%，仅使用2.5%的训练数据，并将整体训练时间减少5-10倍。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07437v1",
      "published_date": "2025-05-12 10:57:51 UTC",
      "updated_date": "2025-05-12 10:57:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:40:24.659175"
    },
    {
      "arxiv_id": "2505.07903v1",
      "title": "SEM: Reinforcement Learning for Search-Efficient Large Language Models",
      "title_zh": "SEM：用于搜索高效大型语言模型的强化学习",
      "authors": [
        "Zeyang Sha",
        "Shiwen Cui",
        "Weiqiang Wang"
      ],
      "abstract": "Recent advancements in Large Language Models(LLMs) have demonstrated their\ncapabilities not only in reasoning but also in invoking external tools,\nparticularly search engines. However, teaching models to discern when to invoke\nsearch and when to rely on their internal knowledge remains a significant\nchallenge. Existing reinforcement learning approaches often lead to redundant\nsearch behaviors, resulting in inefficiencies and over-cost. In this paper, we\npropose SEM, a novel post-training reinforcement learning framework that\nexplicitly trains LLMs to optimize search usage. By constructing a balanced\ndataset combining MuSiQue and MMLU, we create scenarios where the model must\nlearn to distinguish between questions it can answer directly and those\nrequiring external retrieval. We design a structured reasoning template and\nemploy Group Relative Policy Optimization(GRPO) to post-train the model's\nsearch behaviors. Our reward function encourages accurate answering without\nunnecessary search while promoting effective retrieval when needed.\nExperimental results demonstrate that our method significantly reduces\nredundant search operations while maintaining or improving answer accuracy\nacross multiple challenging benchmarks. This framework advances the model's\nreasoning efficiency and extends its capability to judiciously leverage\nexternal knowledge.",
      "tldr_zh": "该研究提出 SEM，一种后训练强化学习框架，旨在优化大型语言模型(LLMs)的搜索效率，解决模型在调用搜索引擎时判断不当导致的冗余行为问题。通过构建结合 MuSiQue 和 MMLU 的平衡数据集，SEM 训练模型区分可直接回答的问题与需要外部检索的场景，并采用结构化推理模板和 Group Relative Policy Optimization(GRPO) 来引导搜索行为。奖励函数强调准确回答同时避免不必要搜索，实验结果显示该框架显著减少冗余操作，同时维持或提升答案准确性，在多个基准测试中表现出色。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07903v1",
      "published_date": "2025-05-12 09:45:40 UTC",
      "updated_date": "2025-05-12 09:45:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:40:26.013898"
    },
    {
      "arxiv_id": "2505.07393v1",
      "title": "AI in Money Matters",
      "title_zh": "人工智能在金钱事务中",
      "authors": [
        "Nadine Sandjo Tchatchoua",
        "Richard Harper"
      ],
      "abstract": "In November 2022, Europe and the world by and large were stunned by the birth\nof a new large language model : ChatGPT. Ever since then, both academic and\npopulist discussions have taken place in various public spheres such as\nLinkedIn and X(formerly known as Twitter) with the view to both understand the\ntool and its benefits for the society. The views of real actors in professional\nspaces, especially in regulated industries such as finance and law have been\nlargely missing. We aim to begin to close this gap by presenting results from\nan empirical investigation conducted through interviews with professional\nactors in the Fintech industry. The paper asks the question, how and to what\nextent are large language models in general and ChatGPT in particular being\nadopted and used in the Fintech industry? The results show that while the\nfintech experts we spoke with see a potential in using large language models in\nthe future, a lot of questions marks remain concerning how they are policed and\ntherefore might be adopted in a regulated industry such as Fintech. This paper\naims to add to the existing academic discussing around large language models,\nwith a contribution to our understanding of professional viewpoints.",
      "tldr_zh": "这篇论文探讨了大型语言模型（如 ChatGPT）在 Fintech 行业的采用和应用情况，通过对 Fintech 专业人士的访谈进行实证调查，以填补学术讨论中的专业视角空白。研究发现，虽然专家们看到这些模型在未来提升效率的潜力，但监管问题和不确定性可能阻碍其在受管制行业中的推广。总体结果强调了大型语言模型的益处与挑战的平衡，为理解其在金融领域的实际应用提供了宝贵见解。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07393v1",
      "published_date": "2025-05-12 09:43:51 UTC",
      "updated_date": "2025-05-12 09:43:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:40:27.104678"
    },
    {
      "arxiv_id": "2505.07381v1",
      "title": "Few-shot Semantic Encoding and Decoding for Video Surveillance",
      "title_zh": "少样本语义编码和解码用于视频监控",
      "authors": [
        "Baoping Cheng",
        "Yukun Zhang",
        "Liming Wang",
        "Xiaoyan Xie",
        "Tao Fu",
        "Dongkun Wang",
        "Xiaoming Tao"
      ],
      "abstract": "With the continuous increase in the number and resolution of video\nsurveillance cameras, the burden of transmitting and storing surveillance video\nis growing. Traditional communication methods based on Shannon's theory are\nfacing optimization bottlenecks. Semantic communication, as an emerging\ncommunication method, is expected to break through this bottleneck and reduce\nthe storage and transmission consumption of video. Existing semantic decoding\nmethods often require many samples to train the neural network for each scene,\nwhich is time-consuming and labor-intensive. In this study, a semantic encoding\nand decoding method for surveillance video is proposed. First, the sketch was\nextracted as semantic information, and a sketch compression method was proposed\nto reduce the bit rate of semantic information. Then, an image translation\nnetwork was proposed to translate the sketch into a video frame with a\nreference frame. Finally, a few-shot sketch decoding network was proposed to\nreconstruct video from sketch. Experimental results showed that the proposed\nmethod achieved significantly better video reconstruction performance than\nbaseline methods. The sketch compression method could effectively reduce the\nstorage and transmission consumption of semantic information with little\ncompromise on video quality. The proposed method provides a novel semantic\nencoding and decoding method that only needs a few training samples for each\nsurveillance scene, thus improving the practicality of the semantic\ncommunication system.",
      "tldr_zh": "本文提出了一种few-shot语义编码和解码方法，用于解决视频监控传输和存储负担增加的问题。方法首先提取草图作为语义信息，并引入草图压缩技术来降低比特率；随后使用图像翻译网络将草图转化为带有参考帧的视频帧，并通过few-shot草图解码网络重建视频。实验结果显示，该方法在视频重建性能上显著优于基线方法，同时有效减少了语义信息的存储和传输消耗，仅需少量训练样本即可应用于不同监控场景，提高了语义通信系统的实用性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07381v1",
      "published_date": "2025-05-12 09:27:28 UTC",
      "updated_date": "2025-05-12 09:27:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:40:30.391832"
    },
    {
      "arxiv_id": "2505.07902v1",
      "title": "Multimodal Assessment of Classroom Discourse Quality: A Text-Centered Attention-Based Multi-Task Learning Approach",
      "title_zh": "多模态课堂话语质量评估：一种基于文本中心的注意力机制多任务学习方法",
      "authors": [
        "Ruikun Hou",
        "Babette Bühler",
        "Tim Fütterer",
        "Efe Bozkir",
        "Peter Gerjets",
        "Ulrich Trautwein",
        "Enkelejda Kasneci"
      ],
      "abstract": "Classroom discourse is an essential vehicle through which teaching and\nlearning take place. Assessing different characteristics of discursive\npractices and linking them to student learning achievement enhances the\nunderstanding of teaching quality. Traditional assessments rely on manual\ncoding of classroom observation protocols, which is time-consuming and costly.\nDespite many studies utilizing AI techniques to analyze classroom discourse at\nthe utterance level, investigations into the evaluation of discursive practices\nthroughout an entire lesson segment remain limited. To address this gap, our\nstudy proposes a novel text-centered multimodal fusion architecture to assess\nthe quality of three discourse components grounded in the Global Teaching\nInSights (GTI) observation protocol: Nature of Discourse, Questioning, and\nExplanations. First, we employ attention mechanisms to capture inter- and\nintra-modal interactions from transcript, audio, and video streams. Second, a\nmulti-task learning approach is adopted to jointly predict the quality scores\nof the three components. Third, we formulate the task as an ordinal\nclassification problem to account for rating level order. The effectiveness of\nthese designed elements is demonstrated through an ablation study on the GTI\nGermany dataset containing 92 videotaped math lessons. Our results highlight\nthe dominant role of text modality in approaching this task. Integrating\nacoustic features enhances the model's consistency with human ratings,\nachieving an overall Quadratic Weighted Kappa score of 0.384, comparable to\nhuman inter-rater reliability (0.326). Our study lays the groundwork for the\nfuture development of automated discourse quality assessment to support teacher\nprofessional development through timely feedback on multidimensional discourse\npractices.",
      "tldr_zh": "该研究提出了一种基于文本中心的多模态融合架构，用于评估课堂话语质量，针对Global Teaching InSights (GTI)协议中的三个组件：Nature of Discourse、Questioning和Explanations。方法采用注意力机制捕捉转录、音频和视频流的互动物化，并结合Multi-Task Learning和序数分类问题来联合预测这些组件的质量分数。在GTI Germany数据集的92节数学课实验中，结果显示文本模态发挥主导作用，整合声学特征后模型的Quadratic Weighted Kappa分数达到0.384，与人类评分者可靠性(0.326)相当。该框架为自动课堂话语质量评估提供基础，支持教师专业发展通过及时的多维反馈。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "The 18th International Conference on Educational Data Mining (EDM\n  2025)",
      "pdf_url": "http://arxiv.org/pdf/2505.07902v1",
      "published_date": "2025-05-12 09:24:21 UTC",
      "updated_date": "2025-05-12 09:24:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:40:31.406775"
    },
    {
      "arxiv_id": "2505.07901v1",
      "title": "Latent Behavior Diffusion for Sequential Reaction Generation in Dyadic Setting",
      "title_zh": "潜在行为扩散用于双人设置中的顺序反应生成",
      "authors": [
        "Minh-Duc Nguyen",
        "Hyung-Jeong Yang",
        "Soo-Hyung Kim",
        "Ji-Eun Shin",
        "Seung-Won Kim"
      ],
      "abstract": "The dyadic reaction generation task involves synthesizing responsive facial\nreactions that align closely with the behaviors of a conversational partner,\nenhancing the naturalness and effectiveness of human-like interaction\nsimulations. This paper introduces a novel approach, the Latent Behavior\nDiffusion Model, comprising a context-aware autoencoder and a diffusion-based\nconditional generator that addresses the challenge of generating diverse and\ncontextually relevant facial reactions from input speaker behaviors. The\nautoencoder compresses high-dimensional input features, capturing dynamic\npatterns in listener reactions while condensing complex input data into a\nconcise latent representation, facilitating more expressive and contextually\nappropriate reaction synthesis. The diffusion-based conditional generator\noperates on the latent space generated by the autoencoder to predict realistic\nfacial reactions in a non-autoregressive manner. This approach allows for\ngenerating diverse facial reactions that reflect subtle variations in\nconversational cues and emotional states. Experimental results demonstrate the\neffectiveness of our approach in achieving superior performance in dyadic\nreaction synthesis tasks compared to existing methods.",
      "tldr_zh": "本研究针对 dyadic reaction generation 任务，提出了一种名为 Latent Behavior Diffusion Model 的新方法，用于从输入说话者行为中合成多样化和上下文相关的面部反应，从而提升人机交互的自然性。该模型包括一个 context-aware autoencoder，用于压缩高维输入特征并捕捉听众反应的动态模式，将复杂数据转化为简洁的潜在表示；以及一个 diffusion-based conditional generator，在潜在空间上非自回归地生成真实的反应，反映对话线索和情感状态的细微变化。实验结果表明，该方法在 dyadic reaction synthesis 任务中比现有方法表现出色，实现了更精确和多样的反应生成。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07901v1",
      "published_date": "2025-05-12 09:22:27 UTC",
      "updated_date": "2025-05-12 09:22:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:40:33.057933"
    },
    {
      "arxiv_id": "2505.07377v1",
      "title": "Examining the Role of LLM-Driven Interactions on Attention and Cognitive Engagement in Virtual Classrooms",
      "title_zh": "探究 LLM 驱动互动对虚拟教室中注意力和认知参与的作用",
      "authors": [
        "Suleyman Ozdel",
        "Can Sarpkaya",
        "Efe Bozkir",
        "Hong Gao",
        "Enkelejda Kasneci"
      ],
      "abstract": "Transforming educational technologies through the integration of large\nlanguage models (LLMs) and virtual reality (VR) offers the potential for\nimmersive and interactive learning experiences. However, the effects of LLMs on\nuser engagement and attention in educational environments remain open\nquestions. In this study, we utilized a fully LLM-driven virtual learning\nenvironment, where peers and teachers were LLM-driven, to examine how students\nbehaved in such settings. Specifically, we investigate how peer question-asking\nbehaviors influenced student engagement, attention, cognitive load, and\nlearning outcomes and found that, in conditions where LLM-driven peer learners\nasked questions, students exhibited more targeted visual scanpaths, with their\nattention directed toward the learning content, particularly in complex\nsubjects. Our results suggest that peer questions did not introduce extraneous\ncognitive load directly, as the cognitive load is strongly correlated with\nincreased attention to the learning material. Considering these findings, we\nprovide design recommendations for optimizing VR learning spaces.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）驱动的互动在虚拟课堂（VR）中的作用，重点考察其对学生注意力和认知参与的影响。研究采用一个完全由 LLMs 驱动的虚拟学习环境，让同伴和教师由模型控制，并分析同伴提问行为对学生参与、视觉扫描路径和学习成果的影响。结果显示，在同伴提问条件下，学生表现出更针对性的注意力，特别是针对复杂科目，而这些互动并未直接增加无关的认知负荷，反而与对学习材料的注意力增强相关。基于这些发现，研究提供了优化 VR 学习空间的设计推荐，以提升教育效果。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted to EDM 2025 (Eighteenth International Conference on\n  Educational Data Mining)",
      "pdf_url": "http://arxiv.org/pdf/2505.07377v1",
      "published_date": "2025-05-12 09:21:19 UTC",
      "updated_date": "2025-05-12 09:21:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:40:34.958337"
    },
    {
      "arxiv_id": "2505.07374v1",
      "title": "AIS Data-Driven Maritime Monitoring Based on Transformer: A Comprehensive Review",
      "title_zh": "基于 Transformer 的 AIS 数据驱动海事监测：一个全面综述",
      "authors": [
        "Zhiye Xie",
        "Enmei Tu",
        "Xianping Fu",
        "Guoliang Yuan",
        "Yi Han"
      ],
      "abstract": "With the increasing demands for safety, efficiency, and sustainability in\nglobal shipping, Automatic Identification System (AIS) data plays an\nincreasingly important role in maritime monitoring. AIS data contains\nspatial-temporal variation patterns of vessels that hold significant research\nvalue in the marine domain. However, due to its massive scale, the full\npotential of AIS data has long remained untapped. With its powerful sequence\nmodeling capabilities, particularly its ability to capture long-range\ndependencies and complex temporal dynamics, the Transformer model has emerged\nas an effective tool for processing AIS data. Therefore, this paper reviews the\nresearch on Transformer-based AIS data-driven maritime monitoring, providing a\ncomprehensive overview of the current applications of Transformer models in the\nmarine field. The focus is on Transformer-based trajectory prediction methods,\nbehavior detection, and prediction techniques. Additionally, this paper\ncollects and organizes publicly available AIS datasets from the reviewed\npapers, performing data filtering, cleaning, and statistical analysis. The\nstatistical results reveal the operational characteristics of different vessel\ntypes, providing data support for further research on maritime monitoring\ntasks. Finally, we offer valuable suggestions for future research, identifying\ntwo promising research directions. Datasets are available at\nhttps://github.com/eyesofworld/Maritime-Monitoring.",
      "tldr_zh": "这篇论文对基于 Transformer 的 AIS 数据驱动海上监控进行了全面综述，强调了 AIS 数据在全球航运安全、效率和可持续性中的重要作用，以及 Transformer 模型在处理大规模 AIS 数据时的优势，如捕捉长程依赖和复杂时间动态。论文重点回顾了 Transformer 在轨迹预测、行为检测和预测技术方面的应用，并收集了公开数据集进行过滤、清洗和统计分析，揭示了不同船只类型的操作特征，为后续研究提供数据支持。最后，论文提出了未来研究的两个有前景方向，并提供了数据集链接（https://github.com/eyesofworld/Maritime-Monitoring）。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07374v1",
      "published_date": "2025-05-12 09:17:43 UTC",
      "updated_date": "2025-05-12 09:17:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:40:37.681349"
    },
    {
      "arxiv_id": "2505.07372v1",
      "title": "Synthetic Code Surgery: Repairing Bugs and Vulnerabilities with LLMs and Synthetic Data",
      "title_zh": "合成代码手术：利用 LLMs 和合成数据修复错误和漏洞",
      "authors": [
        "David de-Fitero-Dominguez",
        "Antonio Garcia-Cabot",
        "Eva Garcia-Lopez"
      ],
      "abstract": "This paper presents a novel methodology for enhancing Automated Program\nRepair (APR) through synthetic data generation utilizing Large Language Models\n(LLMs). Current APR systems are constrained by the limited availability of\nhigh-quality training data encompassing diverse bug types across multiple\nprogramming languages. The proposed approach addresses this limitation through\na two-phase process: a synthetic sample generation followed by a rigorous\nquality assessment. Multiple state-of-the-art LLMs were employed to generate\napproximately 30,000 paired examples of buggy and fixed code across 12\nprogramming languages and 13 bug categories. Subsequently, these samples\nunderwent cross-model evaluation against five criteria: correctness, code\nquality, security, performance, and completeness. Experimental evaluation on\nthe VulRepair test set dataset showed statistically significant improvements in\nPerfect Prediction rates, with the quality-filtered synthetic dataset\noutperforming both baseline and real-world commit data configurations in\ncertain scenarios. The methodology was validated through rigorous statistical\ntesting, including ANOVA and post-hoc Tukey's Honest Significant Difference\nanalysis. Furthermore, the best-performing configurations surpassed existing\nsystems despite using a less computationally intensive decoding strategy. This\nresearch establishes a self-bootstrapping paradigm in which LLMs generate and\nevaluate their own training data, potentially transforming approaches to data\nscarcity across software engineering tasks and advancing the development of\nrobust, adaptable tools for automated code maintenance.",
      "tldr_zh": "这篇论文提出了一种名为 Synthetic Code Surgery 的新方法，利用大型语言模型 (LLMs) 生成合成数据来提升 Automated Program Repair (APR)，以解决高质量训练数据稀缺的问题。该方法采用两阶段过程：首先生成约 30,000 对 buggy 和 fixed 代码样本，覆盖 12 种编程语言和 13 种 bug 类别；然后通过五项标准（正确性、代码质量、安全性、性能和完整性）进行跨模型质量评估。实验结果显示，在 VulRepair 测试集上，使用质量过滤后的合成数据集在某些场景下优于基线和真实世界数据，实现 Perfect Prediction 率的显著提升，并通过 ANOVA 和 Tukey's HSD 统计测试验证。该研究建立了 LLMs 自引导生成和评估训练数据的范式，有望变革软件工程任务中数据稀缺的挑战，推动更鲁棒的自动代码维护工具发展。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07372v1",
      "published_date": "2025-05-12 09:14:20 UTC",
      "updated_date": "2025-05-12 09:14:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:40:46.633650"
    },
    {
      "arxiv_id": "2505.07365v1",
      "title": "Multi-Domain Audio Question Answering Toward Acoustic Content Reasoning in The DCASE 2025 Challenge",
      "title_zh": "多领域音频问答：面向 DCASE 2025 挑战的声学内容推理",
      "authors": [
        "Chao-Han Huck Yang",
        "Sreyan Ghosh",
        "Qing Wang",
        "Jaeyeon Kim",
        "Hengyi Hong",
        "Sonal Kumar",
        "Guirui Zhong",
        "Zhifeng Kong",
        "S Sakshi",
        "Vaibhavi Lokegaonkar",
        "Oriol Nieto",
        "Ramani Duraiswami",
        "Dinesh Manocha",
        "Gunhee Kim",
        "Jun Du",
        "Rafael Valle",
        "Bryan Catanzaro"
      ],
      "abstract": "We present Task 5 of the DCASE 2025 Challenge: an Audio Question Answering\n(AQA) benchmark spanning multiple domains of sound understanding. This task\ndefines three QA subsets (Bioacoustics, Temporal Soundscapes, and Complex QA)\nto test audio-language models on interactive question-answering over diverse\nacoustic scenes. We describe the dataset composition (from marine mammal calls\nto soundscapes and complex real-world clips), the evaluation protocol (top-1\naccuracy with answer-shuffling robustness), and baseline systems\n(Qwen2-Audio-7B, AudioFlamingo 2, Gemini-2-Flash). Preliminary results on the\ndevelopment set are compared, showing strong variation across models and\nsubsets. This challenge aims to advance the audio understanding and reasoning\ncapabilities of audio-language models toward human-level acuity, which are\ncrucial for enabling AI agents to perceive and interact about the world\neffectively.",
      "tldr_zh": "本论文介绍了 DCASE 2025 Challenge 的 Task 5，这是一个多领域音频问答 (AQA) 基准，旨在测试音频语言模型在声学内容推理方面的能力，包括三个 QA 子集：Bioacoustics、Temporal Soundscapes 和 Complex QA。数据集涵盖从海洋哺乳动物叫声到复杂真实世界音频剪辑，采用 top-1 准确率和 answer-shuffling 鲁棒性作为评估协议，并使用基线系统如 Qwen2-Audio-7B、AudioFlamingo 2 和 Gemini-2-Flash 进行比较。初步结果显示模型在不同子集上的表现存在显著差异，此挑战的目标是提升音频语言模型的理解和推理能力，以实现人类水平的声学感知和交互。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "cs.MM",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Preprint. DCASE 2025 Audio QA Challenge:\n  https://dcase.community/challenge2025/task-audio-question-answering",
      "pdf_url": "http://arxiv.org/pdf/2505.07365v1",
      "published_date": "2025-05-12 09:04:16 UTC",
      "updated_date": "2025-05-12 09:04:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:40:48.903847"
    },
    {
      "arxiv_id": "2505.07364v1",
      "title": "GAN-based synthetic FDG PET images from T1 brain MRI can serve to improve performance of deep unsupervised anomaly detection models",
      "title_zh": "基于 GAN 的从 T1 脑部 MRI 生成的合成 FDG PET 图像可以改善深度无监督异常检测模型的性能",
      "authors": [
        "Daria Zotova",
        "Nicolas Pinon",
        "Robin Trombetta",
        "Romain Bouet",
        "Julien Jung",
        "Carole Lartizien"
      ],
      "abstract": "Background and Objective. Research in the cross-modal medical image\ntranslation domain has been very productive over the past few years in tackling\nthe scarce availability of large curated multimodality datasets with the\npromising performance of GAN-based architectures. However, only a few of these\nstudies assessed task-based related performance of these synthetic data,\nespecially for the training of deep models. Method. We design and compare\ndifferent GAN-based frameworks for generating synthetic brain\n[18F]fluorodeoxyglucose (FDG) PET images from T1 weighted MRI data. We first\nperform standard qualitative and quantitative visual quality evaluation. Then,\nwe explore further impact of using these fake PET data in the training of a\ndeep unsupervised anomaly detection (UAD) model designed to detect subtle\nepilepsy lesions in T1 MRI and FDG PET images. We introduce novel diagnostic\ntask-oriented quality metrics of the synthetic FDG PET data tailored to our\nunsupervised detection task, then use these fake data to train a use case UAD\nmodel combining a deep representation learning based on siamese autoencoders\nwith a OC-SVM density support estimation model. This model is trained on normal\nsubjects only and allows the detection of any variation from the pattern of the\nnormal population. We compare the detection performance of models trained on 35\npaired real MR T1 of normal subjects paired either on 35 true PET images or on\n35 synthetic PET images generated from the best performing generative models.\nPerformance analysis is conducted on 17 exams of epilepsy patients undergoing\nsurgery. Results. The best performing GAN-based models allow generating\nrealistic fake PET images of control subject with SSIM and PSNR values around\n0.9 and 23.8, respectively and in distribution (ID) with regard to the true\ncontrol dataset. The best UAD model trained on these synthetic normative PET\ndata allows reaching 74% sensitivity. Conclusion. Our results confirm that\nGAN-based models are the best suited for MR T1 to FDG PET translation,\noutperforming transformer or diffusion models. We also demonstrate the\ndiagnostic value of these synthetic data for the training of UAD models and\nevaluation on clinical exams of epilepsy patients. Our code and the normative\nimage dataset are available.",
      "tldr_zh": "本篇论文探讨了使用 GAN-based 框架从 T1 brain MRI 生成合成 FDG PET 图像，以解决多模态医疗图像数据稀缺问题。研究者设计并比较了不同 GAN 模型，评估合成图像的质量（SSIM 和 PSNR 值分别约 0.9 和 23.8），并将其应用于训练一个深度无监督异常检测 (UAD) 模型，该模型结合 siamese autoencoders 和 OC-SVM 用于检测癫痫病变。结果显示，使用合成 FDG PET 图像训练的 UAD 模型在 17 例癫痫患者手术数据上达到了 74% 的敏感度，优于使用真实图像的基线。论文证实 GAN 模型在 MR T1 到 FDG PET 转换中超越 transformer 或 diffusion 模型，并证明了合成数据的诊断价值。",
      "categories": [
        "eess.IV",
        "cs.AI"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07364v1",
      "published_date": "2025-05-12 09:00:03 UTC",
      "updated_date": "2025-05-12 09:00:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:40:51.353805"
    },
    {
      "arxiv_id": "2505.07345v1",
      "title": "QUPID: Quantified Understanding for Enhanced Performance, Insights, and Decisions in Korean Search Engines",
      "title_zh": "QUPID: 用于韩国搜索引擎的量化理解，以提升性能、洞察力和决策",
      "authors": [
        "Ohjoon Kwon",
        "Changsu Lee",
        "Jihye Back",
        "Lim Sun Suk",
        "Inho Kang",
        "Donghyeon Jeon"
      ],
      "abstract": "Large language models (LLMs) have been widely used for relevance assessment\nin information retrieval. However, our study demonstrates that combining two\ndistinct small language models (SLMs) with different architectures can\noutperform LLMs in this task. Our approach -- QUPID -- integrates a generative\nSLM with an embedding-based SLM, achieving higher relevance judgment accuracy\nwhile reducing computational costs compared to state-of-the-art LLM solutions.\nThis computational efficiency makes QUPID highly scalable for real-world search\nsystems processing millions of queries daily. In experiments across diverse\ndocument types, our method demonstrated consistent performance improvements\n(Cohen's Kappa of 0.646 versus 0.387 for leading LLMs) while offering 60x\nfaster inference times. Furthermore, when integrated into production search\npipelines, QUPID improved nDCG@5 scores by 1.9%. These findings underscore how\narchitectural diversity in model combinations can significantly enhance both\nsearch relevance and operational efficiency in information retrieval systems.",
      "tldr_zh": "本文提出QUPID框架，通过结合生成式SLM和嵌入式SLM，优化韩国搜索引擎的相关性评估性能，实现比LLMs更高的准确率（Cohen's Kappa 0.646 vs. 0.387）并降低计算成本。相比LLMs，QUPID的推理速度提升60倍，使其更适合处理大规模查询的真实搜索系统。实验结果显示，在多种文档类型上，QUPID提高了nDCG@5分数1.9%，证明模型架构多样性能显著提升信息检索的效率和相关性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07345v1",
      "published_date": "2025-05-12 08:35:09 UTC",
      "updated_date": "2025-05-12 08:35:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:40:51.618268"
    },
    {
      "arxiv_id": "2505.07344v2",
      "title": "Generative Pre-trained Autoregressive Diffusion Transformer",
      "title_zh": "生成式预训练自回归扩散Transformer",
      "authors": [
        "Yuan Zhang",
        "Jiacheng Jiang",
        "Guoqing Ma",
        "Zhiying Lu",
        "Haoyang Huang",
        "Jianlong Yuan",
        "Nan Duan"
      ],
      "abstract": "In this work, we present GPDiT, a Generative Pre-trained Autoregressive\nDiffusion Transformer that unifies the strengths of diffusion and\nautoregressive modeling for long-range video synthesis, within a continuous\nlatent space. Instead of predicting discrete tokens, GPDiT autoregressively\npredicts future latent frames using a diffusion loss, enabling natural modeling\nof motion dynamics and semantic consistency across frames. This continuous\nautoregressive framework not only enhances generation quality but also endows\nthe model with representation capabilities. Additionally, we introduce a\nlightweight causal attention variant and a parameter-free rotation-based\ntime-conditioning mechanism, improving both the training and inference\nefficiency. Extensive experiments demonstrate that GPDiT achieves strong\nperformance in video generation quality, video representation ability, and\nfew-shot learning tasks, highlighting its potential as an effective framework\nfor video modeling in continuous space.",
      "tldr_zh": "本研究提出了 GPDiT（Generative Pre-trained Autoregressive Diffusion Transformer），这是一种统一扩散模型和自回归建模的框架，用于在连续潜在空间中进行长序列视频合成。GPDiT 通过自回归预测未来潜在帧并采用 diffusion loss，实现对运动动态和语义一致性的自然建模，同时提升了生成质量和模型表示能力。该框架引入了轻量级因果注意力变体（causal attention variant）和无参数旋转-based 时间条件机制，提高了训练和推理效率。实验结果显示，GPDiT 在视频生成质量、视频表示能力和少样本学习任务上表现出色，展示了其作为连续空间视频建模的有效框架潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07344v2",
      "published_date": "2025-05-12 08:32:39 UTC",
      "updated_date": "2025-05-15 10:24:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:40:52.299832"
    },
    {
      "arxiv_id": "2505.08814v1",
      "title": "Towards Understanding Deep Learning Model in Image Recognition via Coverage Test",
      "title_zh": "通过覆盖测试理解深度学习模型在图像识别中的机制",
      "authors": [
        "Wenkai Li",
        "Xiaoqi Li",
        "Yingjie Mao",
        "Yishun Wang"
      ],
      "abstract": "Deep neural networks (DNNs) play a crucial role in the field of artificial\nintelligence, and their security-related testing has been a prominent research\nfocus. By inputting test cases, the behavior of models is examined for\nanomalies, and coverage metrics are utilized to determine the extent of neurons\ncovered by these test cases. With the widespread application and advancement of\nDNNs, different types of neural behaviors have garnered attention, leading to\nthe emergence of various coverage metrics for neural networks. However, there\nis currently a lack of empirical research on these coverage metrics,\nspecifically in analyzing the relationships and patterns between model depth,\nconfiguration information, and neural network coverage. This paper aims to\ninvestigate the relationships and patterns of four coverage metrics: primary\nfunctionality, boundary, hierarchy, and structural coverage. A series of\nempirical experiments were conducted, selecting LeNet, VGG, and ResNet as\ndifferent DNN architectures, along with 10 models of varying depths ranging\nfrom 5 to 54 layers, to compare and study the relationships between different\ndepths, configuration information, and various neural network coverage metrics.\nAdditionally, an investigation was carried out on the relationships between\nmodified decision/condition coverage and dataset size. Finally, three potential\nfuture directions are proposed to further contribute to the security testing of\nDNN Models.",
      "tldr_zh": "该论文探讨了通过覆盖测试理解深度学习模型（DNNs）在图像识别中的行为，重点分析四种覆盖指标：primary functionality, boundary, hierarchy, and structural coverage。研究者进行了实证实验，使用LeNet、VGG和ResNet等架构，以及10个深度从5到54层的模型，比较了模型深度、配置信息与这些覆盖指标之间的关系，并考察了修改后的decision/condition coverage与数据集大小的关联。最终，论文揭示了这些指标间的模式，并提出了三个未来方向，以提升DNNs的安全测试。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08814v1",
      "published_date": "2025-05-12 08:25:55 UTC",
      "updated_date": "2025-05-12 08:25:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:40:57.355513"
    },
    {
      "arxiv_id": "2505.07339v1",
      "title": "Laypeople's Attitudes Towards Fair, Affirmative, and Discriminatory Decision-Making Algorithms",
      "title_zh": "普通大众对公平、肯定行动和歧视性决策算法的态度",
      "authors": [
        "Gabriel Lima",
        "Nina Grgić-Hlača",
        "Markus Langer",
        "Yixin Zou"
      ],
      "abstract": "Affirmative algorithms have emerged as a potential answer to algorithmic\ndiscrimination, seeking to redress past harms and rectify the source of\nhistorical injustices. We present the results of two experiments ($N$$=$$1193$)\ncapturing laypeople's perceptions of affirmative algorithms -- those which\nexplicitly prioritize the historically marginalized -- in hiring and criminal\njustice. We contrast these opinions about affirmative algorithms with folk\nattitudes towards algorithms that prioritize the privileged (i.e.,\ndiscriminatory) and systems that make decisions independently of demographic\ngroups (i.e., fair). We find that people -- regardless of their political\nleaning and identity -- view fair algorithms favorably and denounce\ndiscriminatory systems. In contrast, we identify disagreements concerning\naffirmative algorithms: liberals and racial minorities rate affirmative systems\nas positively as their fair counterparts, whereas conservatives and those from\nthe dominant racial group evaluate affirmative algorithms as negatively as\ndiscriminatory systems. We identify a source of these divisions: people have\nvarying beliefs about who (if anyone) is marginalized, shaping their views of\naffirmative algorithms. We discuss the possibility of bridging these\ndisagreements to bring people together towards affirmative algorithms.",
      "tldr_zh": "本研究通过两个实验（N=1193）调查了普通人对fair algorithms（公平算法）、affirmative algorithms（肯定性算法）和discriminatory algorithms（歧视性算法）的态度，前者优先边缘化群体以纠正历史不公。结果显示，人们普遍支持fair algorithms并反对discriminatory algorithms，但对affirmative algorithms存在分歧：自由主义者和少数族裔视其为正面，而保守主义者和主导族裔视其为负面。分歧的主要原因在于人们对谁被边缘化的不同信念，论文讨论了弥合这些分歧的可能性，以促进对affirmative algorithms的共识。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07339v1",
      "published_date": "2025-05-12 08:25:15 UTC",
      "updated_date": "2025-05-12 08:25:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:40:58.578408"
    },
    {
      "arxiv_id": "2505.07336v1",
      "title": "SAEN-BGS: Energy-Efficient Spiking AutoEncoder Network for Background Subtraction",
      "title_zh": "SAEN-BGS：用于背景减法的能量高效脉冲自编码器网络",
      "authors": [
        "Zhixuan Zhang",
        "Xiaopeng Li",
        "Qi Liu"
      ],
      "abstract": "Background subtraction (BGS) is utilized to detect moving objects in a video\nand is commonly employed at the onset of object tracking and human recognition\nprocesses. Nevertheless, existing BGS techniques utilizing deep learning still\nencounter challenges with various background noises in videos, including\nvariations in lighting, shifts in camera angles, and disturbances like air\nturbulence or swaying trees. To address this problem, we design a spiking\nautoencoder network, termed SAEN-BGS, based on noise resilience and\ntime-sequence sensitivity of spiking neural networks (SNNs) to enhance the\nseparation of foreground and background. To eliminate unnecessary background\nnoise and preserve the important foreground elements, we begin by creating the\ncontinuous spiking conv-and-dconv block, which serves as the fundamental\nbuilding block for the decoder in SAEN-BGS. Moreover, in striving for enhanced\nenergy efficiency, we introduce a novel self-distillation spiking supervised\nlearning method grounded in ANN-to-SNN frameworks, resulting in decreased power\nconsumption. In extensive experiments conducted on CDnet-2014 and DAVIS-2016\ndatasets, our approach demonstrates superior segmentation performance relative\nto other baseline methods, even when challenged by complex scenarios with\ndynamic backgrounds.",
      "tldr_zh": "这篇论文提出了 SAEN-BGS，一种基于脉冲神经网络 (SNNs) 的能量高效脉冲自编码器网络，用于提升背景减法 (BGS) 在视频中检测移动物体的性能，特别针对光线变化、相机角度偏移和动态干扰等背景噪声问题。SAEN-BGS 通过设计连续脉冲 conv-and-dconv 块作为解码器基础块，实现前景元素的保留和背景噪声的消除，同时引入基于 ANN-to-SNN 框架的自蒸馏脉冲监督学习方法，以显著降低功耗。在 CDnet-2014 和 DAVIS-2016 数据集的实验中，该方法在复杂动态背景场景下表现出优于基线方法的分割性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by Pattern Recognition",
      "pdf_url": "http://arxiv.org/pdf/2505.07336v1",
      "published_date": "2025-05-12 08:21:47 UTC",
      "updated_date": "2025-05-12 08:21:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:41:00.877529"
    },
    {
      "arxiv_id": "2505.07320v1",
      "title": "Dynamical Label Augmentation and Calibration for Noisy Electronic Health Records",
      "title_zh": "动态标签增强与校准技术用于嘈杂电子健康记录",
      "authors": [
        "Yuhao Li",
        "Ling Luo",
        "Uwe Aickelin"
      ],
      "abstract": "Medical research, particularly in predicting patient outcomes, heavily relies\non medical time series data extracted from Electronic Health Records (EHR),\nwhich provide extensive information on patient histories. Despite rigorous\nexamination, labeling errors are inevitable and can significantly impede\naccurate predictions of patient outcome. To address this challenge, we propose\nan \\textbf{A}ttention-based Learning Framework with Dynamic\n\\textbf{C}alibration and Augmentation for \\textbf{T}ime series Noisy\n\\textbf{L}abel \\textbf{L}earning (ACTLL). This framework leverages a\ntwo-component Beta mixture model to identify the certain and uncertain sets of\ninstances based on the fitness distribution of each class, and it captures\nglobal temporal dynamics while dynamically calibrating labels from the\nuncertain set or augmenting confident instances from the certain set.\nExperimental results on large-scale EHR datasets eICU and MIMIC-IV-ED, and\nseveral benchmark datasets from the UCR and UEA repositories, demonstrate that\nour model ACTLL has achieved state-of-the-art performance, especially under\nhigh noise levels.",
      "tldr_zh": "这篇论文针对电子健康记录 (EHR) 中的噪声标签问题，提出了一种注意力-based 学习框架 ACTLL，用于时间序列噪声标签学习。该框架采用两组件 Beta mixture model 来区分实例的确定集和不确定集，同时捕捉全局时间动态，并动态校准不确定集的标签或增强确定集的置信实例。在 eICU、MIMIC-IV-ED 等大型数据集以及 UCR 和 UEA 基准数据集上的实验表明，ACTLL 在高噪声水平下实现了最先进性能，提高了患者结果预测的准确性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07320v1",
      "published_date": "2025-05-12 08:06:16 UTC",
      "updated_date": "2025-05-12 08:06:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:41:01.547174"
    },
    {
      "arxiv_id": "2505.07317v1",
      "title": "How Do Companies Manage the Environmental Sustainability of AI? An Interview Study About Green AI Efforts and Regulations",
      "title_zh": "公司如何管理人工智能的环境可持续性？ 关于绿色 AI 努力和法规的一项访谈研究",
      "authors": [
        "Ashmita Sampatsing",
        "Sophie Vos",
        "Emma Beauxis-Aussalet",
        "Justus Bogner"
      ],
      "abstract": "With the ever-growing adoption of artificial intelligence (AI), AI-based\nsoftware and its negative impact on the environment are no longer negligible,\nand studying and mitigating this impact has become a critical area of research.\nHowever, it is currently unclear which role environmental sustainability plays\nduring AI adoption in industry and how AI regulations influence Green AI\npractices and decision-making in industry. We therefore aim to investigate the\nGreen AI perception and management of industry practitioners. To this end, we\nconducted a total of 11 interviews with participants from 10 different\norganizations that adopted AI-based software. The interviews explored three\nmain themes: AI adoption, current efforts in mitigating the negative\nenvironmental impact of AI, and the influence of the EU AI Act and the\nCorporate Sustainability Reporting Directive (CSRD). Our findings indicate that\n9 of 11 participants prioritized business efficiency during AI adoption, with\nminimal consideration of environmental sustainability. Monitoring and\nmitigation of AI's environmental impact were very limited. Only one participant\nmonitored negative environmental effects. Regarding applied mitigation\npractices, six participants reported no actions, with the others sporadically\nmentioning techniques like prompt engineering, relying on smaller models, or\nnot overusing AI. Awareness and compliance with the EU AI Act are low, with\nonly one participant reporting on its influence, while the CSRD drove\nsustainability reporting efforts primarily in larger companies. All in all, our\nfindings reflect a lack of urgency and priority for sustainable AI among these\ncompanies. We suggest that current regulations are not very effective, which\nhas implications for policymakers. Additionally, there is a need to raise\nindustry awareness, but also to provide user-friendly techniques and tools for\nGreen AI practices.",
      "tldr_zh": "这篇论文通过对11位从业者的采访，调查了公司在采用AI时对环境可持续性的管理，以及Green AI实践和法规（如EU AI Act和CSRD）的影响。研究发现，大多数参与者（9/11）优先考虑业务效率，而非环境可持续性，AI的环境影响监控和缓解措施非常有限，只有少数人偶尔采用如prompt engineering或使用较小模型等技术。总体而言，现有法规效果不佳，论文建议政策制定者加强监管、提升行业对Green AI的意识，并开发用户友好的工具以促进可持续AI实践。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "Accepted for publication at the 11th International Conference on ICT\n  for Sustainability (ICT4S'25), see https://conf.researchr.org/home/ict4s-2025",
      "pdf_url": "http://arxiv.org/pdf/2505.07317v1",
      "published_date": "2025-05-12 08:03:55 UTC",
      "updated_date": "2025-05-12 08:03:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:41:04.146637"
    },
    {
      "arxiv_id": "2505.07315v1",
      "title": "FedIFL: A federated cross-domain diagnostic framework for motor-driven systems with inconsistent fault modes",
      "title_zh": "FedIFL：一种用于具有不一致故障模式的电机驱动系统的联邦跨域诊断框架",
      "authors": [
        "Zexiao Wang",
        "Yankai Wang",
        "Xiaoqiang Liao",
        "Xinguo Ming",
        "Weiming Shen"
      ],
      "abstract": "Due to the scarcity of industrial data, individual equipment users,\nparticularly start-ups, struggle to independently train a comprehensive fault\ndiagnosis model; federated learning enables collaborative training while\nensuring data privacy, making it an ideal solution. However, the diversity of\nworking conditions leads to variations in fault modes, resulting in\ninconsistent label spaces across different clients. In federated diagnostic\nscenarios, label space inconsistency leads to local models focus on\nclient-specific fault modes and causes local models from different clients to\nmap different failure modes to similar feature representations, which weakens\nthe aggregated global model's generalization. To tackle this issue, this\narticle proposed a federated cross-domain diagnostic framework termed Federated\nInvariant Features Learning (FedIFL). In intra-client training, prototype\ncontrastive learning mitigates intra-client domain shifts, subsequently,\nfeature generating ensures local models can access distributions of other\nclients in a privacy-friendly manner. Besides, in cross-client training, a\nfeature disentanglement mechanism is introduced to mitigate cross-client domain\nshifts, specifically, an instance-level federated instance consistency loss is\ndesigned to ensure the instance-level consistency of invariant features between\ndifferent clients, furthermore, a federated instance personalization loss and\nan orthogonal loss are constructed to distinguish specific features that from\nthe invariant features. Eventually, the aggregated model achieves promising\ngeneralization among global label spaces, enabling accurate fault diagnosis for\ntarget clients' Motor Driven Systems (MDSs) with inconsistent label spaces.\nExperiments on real-world MDSs validate the effectiveness and superiority of\nFedIFL in federated cross-domain diagnosis with inconsistent fault modes.",
      "tldr_zh": "该研究针对工业数据稀缺和联邦学习（Federated Learning）中标签空间不一致的问题，提出了一种Federated Invariant Features Learning (FedIFL)框架，用于电机驱动系统（Motor Driven Systems, MDSs）的跨域故障诊断。框架在intra-client训练中采用原型对比学习（prototype contrastive learning）和特征生成（feature generating）来减轻内部领域偏移，并确保本地模型隐私友好地访问其他客户端分布；在cross-client训练中，通过特征解耦机制（feature disentanglement）、实例级联邦实例一致性损失（federated instance consistency loss）、联邦实例个性化损失和正交损失（orthogonal loss）来缓解跨客户端领域偏移，实现不变特征的一致性。实验结果显示，FedIFL在真实世界MDSs上实现了优秀的泛化性能，能够准确诊断具有不一致故障模式的系统，并验证了其有效性和优越性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07315v1",
      "published_date": "2025-05-12 08:00:49 UTC",
      "updated_date": "2025-05-12 08:00:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:41:12.685623"
    },
    {
      "arxiv_id": "2505.07313v1",
      "title": "Towards Multi-Agent Reasoning Systems for Collaborative Expertise Delegation: An Exploratory Design Study",
      "title_zh": "朝向用于协作专家知识委托的多智能体推理系统：一个探索性设计研究",
      "authors": [
        "Baixuan Xu",
        "Chunyang Li",
        "Weiqi Wang",
        "Wei Fan",
        "Tianshi Zheng",
        "Haochen Shi",
        "Tao Fan",
        "Yangqiu Song",
        "Qiang Yang"
      ],
      "abstract": "Designing effective collaboration structure for multi-agent LLM systems to\nenhance collective reasoning is crucial yet remains under-explored. In this\npaper, we systematically investigate how collaborative reasoning performance is\naffected by three key design dimensions: (1) Expertise-Domain Alignment, (2)\nCollaboration Paradigm (structured workflow vs. diversity-driven integration),\nand (3) System Scale. Our findings reveal that expertise alignment benefits are\nhighly domain-contingent, proving most effective for contextual reasoning\ntasks. Furthermore, collaboration focused on integrating diverse knowledge\nconsistently outperforms rigid task decomposition. Finally, we empirically\nexplore the impact of scaling the multi-agent system with expertise\nspecialization and study the computational trade off, highlighting the need for\nmore efficient communication protocol design. This work provides concrete\nguidelines for configuring specialized multi-agent system and identifies\ncritical architectural trade-offs and bottlenecks for scalable multi-agent\nreasoning. The code will be made available upon acceptance.",
      "tldr_zh": "本研究探讨了多智能体LLM系统的协作结构设计，以提升集体推理性能，重点调查三个关键维度：(1) Expertise-Domain Alignment的专业领域对齐，(2) Collaboration Paradigm的协作范式（结构化工作流 vs. 多样性驱动整合），以及(3) System Scale的系统规模。结果显示，专业领域对齐在上下文推理任务中最为有效，而强调多样知识整合的协作方式优于刚性任务分解；此外，扩展系统规模虽能提升专业化，但需权衡计算效率和通信协议设计。该工作提供了配置专业化多智能体系统的具体指导，并识别了可扩展多智能体推理的关键架构权衡和瓶颈。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.07313v1",
      "published_date": "2025-05-12 07:59:13 UTC",
      "updated_date": "2025-05-12 07:59:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:41:13.908706"
    },
    {
      "arxiv_id": "2505.07299v1",
      "title": "Interpretable Event Diagnosis in Water Distribution Networks",
      "title_zh": "在水分配网络中的可解释事件诊断",
      "authors": [
        "André Artelt",
        "Stelios G. Vrachimis",
        "Demetrios G. Eliades",
        "Ulrike Kuhl",
        "Barbara Hammer",
        "Marios M. Polycarpou"
      ],
      "abstract": "The increasing penetration of information and communication technologies in\nthe design, monitoring, and control of water systems enables the use of\nalgorithms for detecting and identifying unanticipated events (such as leakages\nor water contamination) using sensor measurements. However, data-driven\nmethodologies do not always give accurate results and are often not trusted by\noperators, who may prefer to use their engineering judgment and experience to\ndeal with such events.\n  In this work, we propose a framework for interpretable event diagnosis -- an\napproach that assists the operators in associating the results of algorithmic\nevent diagnosis methodologies with their own intuition and experience. This is\nachieved by providing contrasting (i.e., counterfactual) explanations of the\nresults provided by fault diagnosis algorithms; their aim is to improve the\nunderstanding of the algorithm's inner workings by the operators, thus enabling\nthem to take a more informed decision by combining the results with their\npersonal experiences. Specifically, we propose counterfactual event\nfingerprints, a representation of the difference between the current event\ndiagnosis and the closest alternative explanation, which can be presented in a\ngraphical way. The proposed methodology is applied and evaluated on a realistic\nuse case using the L-Town benchmark.",
      "tldr_zh": "该研究针对水分配网络中事件诊断（如泄漏或水污染）的挑战，提出一个可解释框架，以解决数据驱动算法准确性不足和操作员信任问题。该框架通过提供对比性解释（counterfactual explanations），帮助操作员将算法结果与自身经验相结合。具体地，引入了counterfactual event fingerprints，这是一种图形化表示，展示当前事件诊断与最近替代解释的差异。在L-Town基准上的实际应用表明，该方法能提升操作员的决策能力。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07299v1",
      "published_date": "2025-05-12 07:36:00 UTC",
      "updated_date": "2025-05-12 07:36:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:41:15.266367"
    },
    {
      "arxiv_id": "2505.07294v1",
      "title": "HuB: Learning Extreme Humanoid Balance",
      "title_zh": "HuB：学习极端人形机器人平衡",
      "authors": [
        "Tong Zhang",
        "Boyuan Zheng",
        "Ruiqian Nai",
        "Yingdong Hu",
        "Yen-Jen Wang",
        "Geng Chen",
        "Fanqi Lin",
        "Jiongye Li",
        "Chuye Hong",
        "Koushil Sreenath",
        "Yang Gao"
      ],
      "abstract": "The human body demonstrates exceptional motor capabilities-such as standing\nsteadily on one foot or performing a high kick with the leg raised over 1.5\nmeters-both requiring precise balance control. While recent research on\nhumanoid control has leveraged reinforcement learning to track human motions\nfor skill acquisition, applying this paradigm to balance-intensive tasks\nremains challenging. In this work, we identify three key obstacles: instability\nfrom reference motion errors, learning difficulties due to morphological\nmismatch, and the sim-to-real gap caused by sensor noise and unmodeled\ndynamics. To address these challenges, we propose HuB (Humanoid Balance), a\nunified framework that integrates reference motion refinement, balance-aware\npolicy learning, and sim-to-real robustness training, with each component\ntargeting a specific challenge. We validate our approach on the Unitree G1\nhumanoid robot across challenging quasi-static balance tasks, including extreme\nsingle-legged poses such as Swallow Balance and Bruce Lee's Kick. Our policy\nremains stable even under strong physical disturbances-such as a forceful\nsoccer strike-while baseline methods consistently fail to complete these tasks.\nProject website: https://hub-robot.github.io",
      "tldr_zh": "这篇论文针对人形机器人的极端平衡任务，提出了 HuB 框架，以解决参考动作错误导致的不稳定、形态不匹配的学习困难以及模拟到真实世界的差距（如传感器噪声和未建模动态）等问题。HuB 整合了参考动作精炼、平衡感知策略学习和模拟到真实世界的鲁棒性训练，针对性地提升机器人平衡控制能力。在 Unitree G1 机器人上实验验证显示，该框架能稳定完成挑战性任务，如 Swallow Balance 和 Bruce Lee's Kick，甚至在强物理干扰（如足球猛击）下保持平衡，而基线方法则失败。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "Project website: https://hub-robot.github.io",
      "pdf_url": "http://arxiv.org/pdf/2505.07294v1",
      "published_date": "2025-05-12 07:31:42 UTC",
      "updated_date": "2025-05-12 07:31:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:41:17.914931"
    },
    {
      "arxiv_id": "2505.07289v1",
      "title": "Semantic Retention and Extreme Compression in LLMs: Can We Have Both?",
      "title_zh": "LLMs 中的语义保留和极端压缩：我们能兼得吗？",
      "authors": [
        "Stanislas Laborde",
        "Martin Cousseau",
        "Antoun Yaacoub",
        "Lionel Prevost"
      ],
      "abstract": "The exponential growth in Large Language Model (LLM) deployment has\nintensified the need for efficient model compression techniques to reduce\ncomputational and memory costs. While pruning and quantization have shown\npromise, their combined potential remains largely unexplored. In this paper, we\nexamine joint compression and how strategically combining pruning and\nquantization could yield superior performance-to-compression ratios compared to\nsingle-method approaches. Recognizing the challenges in accurately assessing\nLLM performance, we address key limitations of previous evaluation frameworks\nand introduce the Semantic Retention Compression Rate (SrCr), a novel metric\nthat quantifies the trade-off between model compression and semantic\npreservation, facilitating the optimization of pruning-quantization\nconfigurations. Experiments demonstrate that our recommended combination\nachieves, on average, a 20% performance increase compared to an equivalent\nquantization-only model at the same theoretical compression rate.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLM)中实现语义保留和极端压缩的平衡可能性，重点考察修剪(pruning)和量化(quantization)的联合方法，以获得更高的性能-压缩比。作者引入了新的指标Semantic Retention Compression Rate (SrCr)，用于量化模型压缩与语义保留的权衡，从而优化修剪-量化配置。实验结果显示，这种组合方法在相同理论压缩率下，比单一量化模型平均提高了20%的性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "68P30 (Primary) 68T07, 68T50 (Secondary)",
        "I.2.6; I.5.1; I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted for publication in the Proceedings of the 2025 International\n  Joint Conference on Neural Networks (IJCNN); this arXiv version includes an\n  appendix with 6 result tables; 10 pages, 15 figures, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.07289v1",
      "published_date": "2025-05-12 07:23:19 UTC",
      "updated_date": "2025-05-12 07:23:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:41:18.834570"
    },
    {
      "arxiv_id": "2505.07286v1",
      "title": "Piloting Structure-Based Drug Design via Modality-Specific Optimal Schedule",
      "title_zh": "通过特定模态的最优调度试点结构药物设计",
      "authors": [
        "Keyue Qiu",
        "Yuxuan Song",
        "Zhehuan Fan",
        "Peidong Liu",
        "Zhe Zhang",
        "Mingyue Zheng",
        "Hao Zhou",
        "Wei-Ying Ma"
      ],
      "abstract": "Structure-Based Drug Design (SBDD) is crucial for identifying bioactive\nmolecules. Recent deep generative models are faced with challenges in geometric\nstructure modeling. A major bottleneck lies in the twisted probability path of\nmulti-modalities -- continuous 3D positions and discrete 2D topologies -- which\njointly determine molecular geometries. By establishing the fact that noise\nschedules decide the Variational Lower Bound (VLB) for the twisted probability\npath, we propose VLB-Optimal Scheduling (VOS) strategy in this under-explored\narea, which optimizes VLB as a path integral for SBDD. Our model effectively\nenhances molecular geometries and interaction modeling, achieving\nstate-of-the-art PoseBusters passing rate of 95.9% on CrossDock, more than 10%\nimprovement upon strong baselines, while maintaining high affinities and robust\nintramolecular validity evaluated on held-out test set.",
      "tldr_zh": "该论文针对Structure-Based Drug Design (SBDD)中深度生成模型的几何结构建模挑战，提出VLB-Optimal Scheduling (VOS)策略，以优化多模态（连续3D位置和离散2D拓扑）的扭曲概率路径。VOS通过调整噪声时间表来最大化Variational Lower Bound (VLB)作为路径积分，从而提升分子几何和交互建模的准确性。实验结果显示，该模型在CrossDock数据集上实现了95.9%的PoseBusters通过率，比强基线模型提高了10%以上，同时保持了高亲和力和分子内部有效性。",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.BM",
      "comment": "Accepted to ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.07286v1",
      "published_date": "2025-05-12 07:18:09 UTC",
      "updated_date": "2025-05-12 07:18:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:41:22.142336"
    },
    {
      "arxiv_id": "2505.07899v1",
      "title": "DeltaEdit: Enhancing Sequential Editing in Large Language Models by Controlling Superimposed Noise",
      "title_zh": "DeltaEdit：通过控制叠加噪声增强大型语言模型中的顺序编辑",
      "authors": [
        "Ding Cao",
        "Yuchen Cai",
        "Rongxi Guo",
        "Xuesong He",
        "Guiquan Liu"
      ],
      "abstract": "Sequential knowledge editing techniques aim to continuously update the\nknowledge in large language models at a low cost, preventing the models from\ngenerating outdated or incorrect information. However, existing sequential\nediting methods suffer from a significant decline in editing success rates\nafter long-term editing. Through theoretical analysis and experiments, we\nidentify that as the number of edits increases, the model's output increasingly\ndeviates from the desired target, leading to a drop in editing success rates.\nWe refer to this issue as the accumulation of superimposed noise problem. To\naddress this, we identify the factors contributing to this deviation and\npropose DeltaEdit, a novel method that optimizes update parameters through a\ndynamic orthogonal constraints strategy, effectively reducing interference\nbetween edits to mitigate deviation. Experimental results demonstrate that\nDeltaEdit significantly outperforms existing methods in edit success rates and\nthe retention of generalization capabilities, ensuring stable and reliable\nmodel performance even under extensive sequential editing.",
      "tldr_zh": "该论文针对大型语言模型(Large Language Models)中的顺序编辑(Sequential Editing)问题，指出现有方法在长期编辑后成功率显著下降，主要归因于叠加噪声(Superimposed Noise)导致模型输出偏离目标。作者通过理论分析和实验识别出偏差的因素，并提出DeltaEdit方法，该方法采用动态正交约束策略(Dynamic Orthogonal Constraints Strategy)优化更新参数，以减少编辑间的干扰并缓解该问题。实验结果表明，DeltaEdit在编辑成功率和泛化能力保留方面显著优于现有方法，确保模型在大量顺序编辑下保持稳定可靠的性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07899v1",
      "published_date": "2025-05-12 07:11:26 UTC",
      "updated_date": "2025-05-12 07:11:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:41:24.365765"
    },
    {
      "arxiv_id": "2505.07280v1",
      "title": "Predicting Music Track Popularity by Convolutional Neural Networks on Spotify Features and Spectrogram of Audio Waveform",
      "title_zh": "通过卷积神经网络基于 Spotify 特征和音频波形频谱图预测音乐曲目流行度",
      "authors": [
        "Navid Falah",
        "Behnam Yousefimehr",
        "Mehdi Ghatee"
      ],
      "abstract": "In the digital streaming landscape, it's becoming increasingly challenging\nfor artists and industry experts to predict the success of music tracks. This\nstudy introduces a pioneering methodology that uses Convolutional Neural\nNetworks (CNNs) and Spotify data analysis to forecast the popularity of music\ntracks. Our approach takes advantage of Spotify's wide range of features,\nincluding acoustic attributes based on the spectrogram of audio waveform,\nmetadata, and user engagement metrics, to capture the complex patterns and\nrelationships that influence a track's popularity. Using a large dataset\ncovering various genres and demographics, our CNN-based model shows impressive\neffectiveness in predicting the popularity of music tracks. Additionally, we've\nconducted extensive experiments to assess the strength and adaptability of our\nmodel across different musical styles and time periods, with promising results\nyielding a 97\\% F1 score. Our study not only offers valuable insights into the\ndynamic landscape of digital music consumption but also provides the music\nindustry with advanced predictive tools for assessing and predicting the\nsuccess of music tracks.",
      "tldr_zh": "本研究提出了一种使用 Convolutional Neural Networks (CNNs) 的创新方法，通过分析 Spotify 的特征（如音频波形的 spectrogram、元数据和用户互动指标），来预测音乐曲目的流行度。利用覆盖多种流派和人口统计学的大型数据集，该模型在实验中展示了出色的表现，达到了97%的 F1 score，并在不同音乐风格和时间段上表现出良好的适应性。该方法不仅为音乐行业提供了先进的预测工具，还揭示了数字音乐消费的复杂模式和动态关系。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "68T05, 68T10, 68T37",
        "I.2.6; I.2.1"
      ],
      "primary_category": "cs.SD",
      "comment": "12 pages, 6 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.07280v1",
      "published_date": "2025-05-12 07:03:17 UTC",
      "updated_date": "2025-05-12 07:03:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:41:27.238264"
    },
    {
      "arxiv_id": "2505.08810v1",
      "title": "Machine Learning-Based Detection of DDoS Attacks in VANETs for Emergency Vehicle Communication",
      "title_zh": "基于机器学习的 VANETs 中 DDoS 攻击检测，用于紧急车辆通信",
      "authors": [
        "Bappa Muktar",
        "Vincent Fono",
        "Adama Nouboukpo"
      ],
      "abstract": "Vehicular Ad Hoc Networks (VANETs) play a key role in Intelligent\nTransportation Systems (ITS), particularly in enabling real-time communication\nfor emergency vehicles. However, Distributed Denial of Service (DDoS) attacks,\nwhich interfere with safety-critical communication channels, can severely\nimpair their reliability. This study introduces a robust and scalable framework\nto detect DDoS attacks in highway-based VANET environments. A synthetic dataset\nwas constructed using Network Simulator 3 (NS-3) in conjunction with the\nSimulation of Urban Mobility (SUMO) and further enriched with real-world\nmobility traces from Germany's A81 highway, extracted via OpenStreetMap (OSM).\nThree traffic categories were simulated: DDoS, VoIP, and TCP-based video\nstreaming (VideoTCP). The data preprocessing pipeline included normalization,\nsignal-to-noise ratio (SNR) feature engineering, missing value imputation, and\nclass balancing using the Synthetic Minority Over-sampling Technique (SMOTE).\nFeature importance was assessed using SHapley Additive exPlanations (SHAP).\nEleven classifiers were benchmarked, among them XGBoost (XGB), CatBoost (CB),\nAdaBoost (AB), GradientBoosting (GB), and an Artificial Neural Network (ANN).\nXGB and CB achieved the best performance, each attaining an F1-score of 96%.\nThese results highlight the robustness of the proposed framework and its\npotential for real-time deployment in VANETs to secure critical emergency\ncommunications.",
      "tldr_zh": "这篇论文提出了一种基于机器学习的框架，用于检测车载自组织网络(VANETs)中的分布式拒绝服务(DDoS)攻击，以保障紧急车辆的实时通信。该框架利用 Network Simulator 3 (NS-3) 和 Simulation of Urban Mobility (SUMO) 构建合成数据集，并结合德国 A81 高速公路的真实移动轨迹，进行数据预处理（如标准化、SNR 特征工程、SMOTE 平衡）和 SHapley Additive exPlanations (SHAP) 特征重要性评估。随后，基准测试了 11 个分类器，包括 XGBoost (XGB) 和 CatBoost (CB)，其中 XGB 和 CB 取得了 96% 的 F1-score。研究结果突显了该框架的鲁棒性和可扩展性，为 VANETs 中的实时安全通信提供了潜在解决方案。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08810v1",
      "published_date": "2025-05-12 07:00:04 UTC",
      "updated_date": "2025-05-12 07:00:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:41:28.659397"
    },
    {
      "arxiv_id": "2505.07271v1",
      "title": "On the Robustness of Reward Models for Language Model Alignment",
      "title_zh": "奖励模型在语言模型对齐中的鲁棒性",
      "authors": [
        "Jiwoo Hong",
        "Noah Lee",
        "Eunki Kim",
        "Guijin Son",
        "Woojin Chung",
        "Aman Gupta",
        "Shao Tang",
        "James Thorne"
      ],
      "abstract": "The Bradley-Terry (BT) model is widely practiced in reward modeling for\nreinforcement learning with human feedback (RLHF). Despite its effectiveness,\nreward models (RMs) trained with BT model loss are prone to over-optimization,\nlosing generalizability to unseen input distributions. In this paper, we study\nthe cause of over-optimization in RM training and its downstream effects on the\nRLHF procedure, accentuating the importance of distributional robustness of RMs\nin unseen data. First, we show that the excessive dispersion of hidden state\nnorms is the main source of over-optimization. Then, we propose batch-wise\nsum-to-zero regularization (BSR) to enforce zero-centered reward sum per batch,\nconstraining the rewards with extreme magnitudes. We assess the impact of BSR\nin improving robustness in RMs through four scenarios of over-optimization,\nwhere BSR consistently manifests better robustness. Subsequently, we compare\nthe plain BT model and BSR on RLHF training and empirically show that robust\nRMs better align the policy to the gold preference model. Finally, we apply BSR\nto high-quality data and models, which surpasses state-of-the-art RMs in the 8B\nscale by adding more than 5% in complex preference prediction tasks. By\nconducting RLOO training with 8B RMs, AlpacaEval 2.0 reduces generation length\nby 40% while adding a 7% increase in win rate, further highlighting that\nrobustness in RMs induces robustness in RLHF training. We release the code,\ndata, and models: https://github.com/LinkedIn-XFACT/RM-Robustness.",
      "tldr_zh": "本研究探讨了Bradley-Terry (BT) 模型在强化学习与人类反馈 (RLHF) 中的奖励模型 (RMs) 训练问题，指出RMs易于过优化，导致在新数据上泛化性差，主要源于隐藏状态范数的过度分散。作者提出batch-wise sum-to-zero regularization (BSR) 方法，通过约束每个批次的奖励和为零来限制极端奖励幅度，从而提升RMs的分布鲁棒性。实验结果显示，BSR在四种过优化场景中显著改善鲁棒性，并在RLHF训练中使策略更好地与黄金偏好模型对齐；在8B规模模型上，BSR提高了5%以上的复杂偏好预测性能，并通过AlpacaEval 2.0验证，生成长度减少40%、获胜率增加7%。作者发布了相关代码、数据和模型。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.07271v1",
      "published_date": "2025-05-12 06:48:26 UTC",
      "updated_date": "2025-05-12 06:48:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:41:30.743991"
    },
    {
      "arxiv_id": "2505.08809v1",
      "title": "MixBridge: Heterogeneous Image-to-Image Backdoor Attack through Mixture of Schrödinger Bridges",
      "title_zh": "MixBridge：通过施罗丁格桥混合的异构图像到图像后门攻击",
      "authors": [
        "Shixi Qin",
        "Zhiyong Yang",
        "Shilong Bao",
        "Shi Wang",
        "Qianqian Xu",
        "Qingming Huang"
      ],
      "abstract": "This paper focuses on implanting multiple heterogeneous backdoor triggers in\nbridge-based diffusion models designed for complex and arbitrary input\ndistributions. Existing backdoor formulations mainly address single-attack\nscenarios and are limited to Gaussian noise input models. To fill this gap, we\npropose MixBridge, a novel diffusion Schr\\\"odinger bridge (DSB) framework to\ncater to arbitrary input distributions (taking I2I tasks as special cases).\nBeyond this trait, we demonstrate that backdoor triggers can be injected into\nMixBridge by directly training with poisoned image pairs. This eliminates the\nneed for the cumbersome modifications to stochastic differential equations\nrequired in previous studies, providing a flexible tool to study backdoor\nbehavior for bridge models. However, a key question arises: can a single DSB\nmodel train multiple backdoor triggers? Unfortunately, our theory shows that\nwhen attempting this, the model ends up following the geometric mean of benign\nand backdoored distributions, leading to performance conflict across backdoor\ntasks. To overcome this, we propose a Divide-and-Merge strategy to mix\ndifferent bridges, where models are independently pre-trained for each specific\nobjective (Divide) and then integrated into a unified model (Merge). In\naddition, a Weight Reallocation Scheme (WRS) is also designed to enhance the\nstealthiness of MixBridge. Empirical studies across diverse generation tasks\nspeak to the efficacy of MixBridge.",
      "tldr_zh": "本论文提出MixBridge，一种新型的扩散Schrödinger bridge (DSB)框架，用于在桥接-based扩散模型中植入多个异构后门触发器，以应对复杂输入分布的图像到图像(I2I)任务，并避免了传统方法对随机微分方程的繁琐修改。理论分析显示，单一DSB模型无法同时训练多个触发器，因为它会趋向良性和后门分布的几何均值，导致性能冲突；为此，作者引入Divide-and-Merge策略，独立预训练每个目标模型后整合成统一模型，并设计Weight Reallocation Scheme (WRS)来提升攻击的隐蔽性。实证研究在多种生成任务中证明，MixBridge显著提高了后门攻击的有效性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08809v1",
      "published_date": "2025-05-12 06:40:23 UTC",
      "updated_date": "2025-05-12 06:40:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:41:39.096227"
    },
    {
      "arxiv_id": "2505.07261v2",
      "title": "CHD: Coupled Hierarchical Diffusion for Long-Horizon Tasks",
      "title_zh": "CHD：耦合层次扩散用于长时域任务",
      "authors": [
        "Ce Hao",
        "Anxing Xiao",
        "Zhiwei Xue",
        "Harold Soh"
      ],
      "abstract": "Diffusion-based planners have shown strong performance in short-horizon tasks\nbut often fail in complex, long-horizon settings. We trace the failure to loose\ncoupling between high-level (HL) sub-goal selection and low-level (LL)\ntrajectory generation, which leads to incoherent plans and degraded\nperformance. We propose Coupled Hierarchical Diffusion (CHD), a framework that\nmodels HL sub-goals and LL trajectories jointly within a unified diffusion\nprocess. A shared classifier passes LL feedback upstream so that sub-goals\nself-correct while sampling proceeds. This tight HL-LL coupling improves\ntrajectory coherence and enables scalable long-horizon diffusion planning.\nExperiments across maze navigation, tabletop manipulation, and household\nenvironments show that CHD consistently outperforms both flat and hierarchical\ndiffusion baselines. Our website is: https://sites.google.com/view/chd2025/home",
      "tldr_zh": "扩散模型在短时任务中表现出色，但长期任务中因高层（HL）子目标选择与底层（LL）轨迹生成的松散耦合而导致计划不连贯。论文提出Coupled Hierarchical Diffusion (CHD)框架，通过在统一扩散过程中联合建模HL子目标和LL轨迹，并利用共享分类器将LL反馈传递到HL，实现子目标的自我修正和轨迹的连贯性。实验结果显示，CHD在迷宫导航、桌面操作和家庭环境中显著优于平坦和分层扩散基线，推动了可扩展的长期任务规划。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07261v2",
      "published_date": "2025-05-12 06:21:48 UTC",
      "updated_date": "2025-05-13 09:28:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:41:40.422913"
    },
    {
      "arxiv_id": "2505.07260v1",
      "title": "UMoE: Unifying Attention and FFN with Shared Experts",
      "title_zh": "UMoE：利用共享专家统一注意力机制与前馈网络",
      "authors": [
        "Yuanhang Yang",
        "Chaozheng Wang",
        "Jing Li"
      ],
      "abstract": "Sparse Mixture of Experts (MoE) architectures have emerged as a promising\napproach for scaling Transformer models. While initial works primarily\nincorporated MoE into feed-forward network (FFN) layers, recent studies have\nexplored extending the MoE paradigm to attention layers to enhance model\nperformance. However, existing attention-based MoE layers require specialized\nimplementations and demonstrate suboptimal performance compared to their\nFFN-based counterparts. In this paper, we aim to unify the MoE designs in\nattention and FFN layers by introducing a novel reformulation of the attention\nmechanism, revealing an underlying FFN-like structure within attention modules.\nOur proposed architecture, UMoE, achieves superior performance through\nattention-based MoE layers while enabling efficient parameter sharing between\nFFN and attention components.",
      "tldr_zh": "本文提出UMoE架构，旨在统一Transformer模型中注意力(attention)和前馈网络(FFN)层的稀疏混合专家(Sparse Mixture of Experts, MoE)设计，通过重新表述注意力机制揭示其内在FFN-like结构。UMoE实现了FFN和注意力组件之间的参数共享，解决了现有注意力-based MoE层在实现和性能上的不足。实验结果显示，该架构在注意力层应用MoE时显著提升了模型性能，提供了一种高效的扩展方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07260v1",
      "published_date": "2025-05-12 06:21:44 UTC",
      "updated_date": "2025-05-12 06:21:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:41:42.037281"
    },
    {
      "arxiv_id": "2505.07258v1",
      "title": "No Query, No Access",
      "title_zh": "无查询，无访问",
      "authors": [
        "Wenqiang Wang",
        "Siyuan Liang",
        "Yangshijie Zhang",
        "Xiaojun Jia",
        "Hao Lin",
        "Xiaochun Cao"
      ],
      "abstract": "Textual adversarial attacks mislead NLP models, including Large Language\nModels (LLMs), by subtly modifying text. While effective, existing attacks\noften require knowledge of the victim model, extensive queries, or access to\ntraining data, limiting real-world feasibility. To overcome these constraints,\nwe introduce the \\textbf{Victim Data-based Adversarial Attack (VDBA)}, which\noperates using only victim texts. To prevent access to the victim model, we\ncreate a shadow dataset with publicly available pre-trained models and\nclustering methods as a foundation for developing substitute models. To address\nthe low attack success rate (ASR) due to insufficient information feedback, we\npropose the hierarchical substitution model design, generating substitute\nmodels to mitigate the failure of a single substitute model at the decision\nboundary.\n  Concurrently, we use diverse adversarial example generation, employing\nvarious attack methods to generate and select the adversarial example with\nbetter similarity and attack effectiveness. Experiments on the Emotion and SST5\ndatasets show that VDBA outperforms state-of-the-art methods, achieving an ASR\nimprovement of 52.08\\% while significantly reducing attack queries to 0. More\nimportantly, we discover that VDBA poses a significant threat to LLMs such as\nQwen2 and the GPT family, and achieves the highest ASR of 45.99% even without\naccess to the API, confirming that advanced NLP models still face serious\nsecurity risks. Our codes can be found at\nhttps://anonymous.4open.science/r/VDBA-Victim-Data-based-Adversarial-Attack-36EC/",
      "tldr_zh": "本研究提出了一种 Victim Data-based Adversarial Attack (VDBA) 方法，用于生成文本对抗样本，以误导 NLP 模型和 Large Language Models (LLMs)，而无需访问受害者模型、查询其 API 或训练数据。VDBA 通过创建影子数据集（利用公开预训练模型和聚类方法）并设计层次化替代模型来提高攻击成功率 (ASR)，同时采用多样化对抗样本生成策略来优化样本的相似性和有效性。在 Emotion 和 SST5 数据集上的实验显示，VDBA 比现有方法提升 52.08% 的 ASR，且查询次数为 0。更重要的是，该攻击对 LLMs 如 Qwen2 和 GPT 系列构成重大威胁，即使无 API 访问也能达到 45.99% 的最高 ASR，暴露了高级 NLP 模型的安全风险。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07258v1",
      "published_date": "2025-05-12 06:19:59 UTC",
      "updated_date": "2025-05-12 06:19:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:41:46.319598"
    },
    {
      "arxiv_id": "2505.07251v1",
      "title": "Incomplete In-context Learning",
      "title_zh": "不完整的上下文学习",
      "authors": [
        "Wenqiang Wang",
        "Yangshijie Zhang"
      ],
      "abstract": "Large vision language models (LVLMs) achieve remarkable performance through\nVision In-context Learning (VICL), a process that depends significantly on\ndemonstrations retrieved from an extensive collection of annotated examples\n(retrieval database). Existing studies often assume that the retrieval database\ncontains annotated examples for all labels. However, in real-world scenarios,\ndelays in database updates or incomplete data annotation may result in the\nretrieval database containing labeled samples for only a subset of classes. We\nrefer to this phenomenon as an \\textbf{incomplete retrieval database} and\ndefine the in-context learning under this condition as \\textbf{Incomplete\nIn-context Learning (IICL)}. To address this challenge, we propose\n\\textbf{Iterative Judgments and Integrated Prediction (IJIP)}, a two-stage\nframework designed to mitigate the limitations of IICL. The Iterative Judgments\nStage reformulates an \\(\\boldsymbol{m}\\)-class classification problem into a\nseries of \\(\\boldsymbol{m}\\) binary classification tasks, effectively\nconverting the IICL setting into a standard VICL scenario. The Integrated\nPrediction Stage further refines the classification process by leveraging both\nthe input image and the predictions from the Iterative Judgments Stage to\nenhance overall classification accuracy. IJIP demonstrates considerable\nperformance across two LVLMs and two datasets under three distinct conditions\nof label incompleteness, achieving the highest accuracy of 93.9\\%. Notably,\neven in scenarios where labels are fully available, IJIP still achieves the\nbest performance of all six baselines. Furthermore, IJIP can be directly\napplied to \\textbf{Prompt Learning} and is adaptable to the \\textbf{text\ndomain}.",
      "tldr_zh": "该研究探讨了大型视觉语言模型(LVLMs)在Vision In-context Learning (VICL)中的挑战，即当检索数据库不完整时，导致Incomplete In-context Learning (IICL)问题。作者提出Iterative Judgments and Integrated Prediction (IJIP)框架，该框架分为两阶段：第一阶段将多类分类问题转化为一系列二元分类任务，以适应标准VICL场景；第二阶段则整合输入图像和初步预测来提升整体准确性。在实验中，IJIP在两个LVLMs和两个数据集上表现优异，最高准确率达93.9%，并在标签完整条件下优于所有基线模型，同时可扩展至Prompt Learning和文本领域。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07251v1",
      "published_date": "2025-05-12 05:57:39 UTC",
      "updated_date": "2025-05-12 05:57:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:41:48.081901"
    },
    {
      "arxiv_id": "2505.07247v2",
      "title": "SAS-Bench: A Fine-Grained Benchmark for Evaluating Short Answer Scoring with Large Language Models",
      "title_zh": "SAS-Bench：细粒度基准，用于评估使用大型语言模型的短答题评分",
      "authors": [
        "Peichao Lai",
        "Kexuan Zhang",
        "Yi Lin",
        "Linyihan Zhang",
        "Feiyang Ye",
        "Jinhao Yan",
        "Yanwei Xu",
        "Conghui He",
        "Yilei Wang",
        "Wentao Zhang",
        "Bin Cui"
      ],
      "abstract": "Subjective Answer Grading (SAG) plays a crucial role in education,\nstandardized testing, and automated assessment systems, particularly for\nevaluating short-form responses in Short Answer Scoring (SAS). However,\nexisting approaches often produce coarse-grained scores and lack detailed\nreasoning. Although large language models (LLMs) have demonstrated potential as\nzero-shot evaluators, they remain susceptible to bias, inconsistencies with\nhuman judgment, and limited transparency in scoring decisions. To overcome\nthese limitations, we introduce SAS-Bench, a benchmark specifically designed\nfor LLM-based SAS tasks. SAS-Bench provides fine-grained, step-wise scoring,\nexpert-annotated error categories, and a diverse range of question types\nderived from real-world subject-specific exams. This benchmark facilitates\ndetailed evaluation of model reasoning processes and explainability. We also\nrelease an open-source dataset containing 1,030 questions and 4,109 student\nresponses, each annotated by domain experts. Furthermore, we conduct\ncomprehensive experiments with various LLMs, identifying major challenges in\nscoring science-related questions and highlighting the effectiveness of\nfew-shot prompting in improving scoring accuracy. Our work offers valuable\ninsights into the development of more robust, fair, and educationally\nmeaningful LLM-based evaluation systems.",
      "tldr_zh": "本文引入 SAS-Bench，一种细粒度的基准，用于评估大型语言模型 (LLMs) 在主观答案评分 (SAG) 特别是短答案评分 (SAS) 任务中的性能，该基准提供逐步评分、专家标注的错误类别以及从真实考试中提取的多样化问题类型。研究发布了一个开源数据集，包含 1030 个问题和 4109 个学生响应，由领域专家进行标注，以便详细评估模型的推理过程和可解释性。通过全面实验，论文识别了 LLMs 在科学相关问题上的主要挑战，并证明了 few-shot prompting 可以显著提高评分准确性。该工作为开发更稳健、公平且教育意义的 LLM 评估系统提供了重要见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07247v2",
      "published_date": "2025-05-12 05:43:21 UTC",
      "updated_date": "2025-05-15 11:01:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:41:49.512720"
    },
    {
      "arxiv_id": "2505.07245v1",
      "title": "REMEDI: Relative Feature Enhanced Meta-Learning with Distillation for Imbalanced Prediction",
      "title_zh": "REMEDI：相对特征增强的元学习，结合知识蒸馏，用于不平衡预测",
      "authors": [
        "Fei Liu",
        "Huanhuan Ren",
        "Yu Guan",
        "Xiuxu Wang",
        "Wang Lv",
        "Zhiqiang Hu",
        "Yaxi Chen"
      ],
      "abstract": "Predicting future vehicle purchases among existing owners presents a critical\nchallenge due to extreme class imbalance (<0.5% positive rate) and complex\nbehavioral patterns. We propose REMEDI (Relative feature Enhanced Meta-learning\nwith Distillation for Imbalanced prediction), a novel multi-stage framework\naddressing these challenges. REMEDI first trains diverse base models to capture\ncomplementary aspects of user behavior. Second, inspired by comparative\nop-timization techniques, we introduce relative performance meta-features\n(deviation from ensemble mean, rank among peers) for effective model fusion\nthrough a hybrid-expert architecture. Third, we distill the ensemble's\nknowledge into a single efficient model via supervised fine-tuning with MSE\nloss, enabling practical deployment. Evaluated on approximately 800,000 vehicle\nowners, REMEDI significantly outperforms baseline approaches, achieving the\nbusiness target of identifying ~50% of actual buyers within the top 60,000\nrecommendations at ~10% precision. The distilled model preserves the ensemble's\npredictive power while maintaining deployment efficiency, demonstrating\nREMEDI's effectiveness for imbalanced prediction in industry settings.",
      "tldr_zh": "这篇论文提出了 REMEDI 框架，用于处理极端类 imbalance（如 <0.5% 正样本率）的车辆购买预测问题，通过多阶段方法提升预测准确性。REMEDI 先训练多样化的 base models 以捕捉用户行为的互补方面，然后引入 relative performance meta-features（如与 ensemble 均值的偏差和排名）来实现模型融合的 hybrid-expert architecture，最后通过 supervised fine-tuning 和 MSE loss 将 ensemble 知识蒸馏到单个高效模型中，便于实际部署。在约 80 万车主数据上的实验中，REMEDI 显著优于基线模型，实现了业务目标：在前 60,000 推荐中识别约 50% 的实际买家，精度达 ~10%。该框架展示了在工业场景中处理 imbalance prediction 的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07245v1",
      "published_date": "2025-05-12 05:40:20 UTC",
      "updated_date": "2025-05-12 05:40:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:41:52.097978"
    },
    {
      "arxiv_id": "2505.07897v1",
      "title": "LongCodeBench: Evaluating Coding LLMs at 1M Context Windows",
      "title_zh": "LongCodeBench：在1M上下文窗口下评估编码LLM",
      "authors": [
        "Stefano Rando",
        "Luca Romani",
        "Alessio Sampieri",
        "Yuta Kyuragi",
        "Luca Franco",
        "Fabio Galasso",
        "Tatsunori Hashimoto",
        "John Yang"
      ],
      "abstract": "Context lengths for models have grown rapidly, from thousands to millions of\ntokens in just a few years. The extreme context sizes of modern long-context\nmodels have made it difficult to construct realistic long-context benchmarks --\nnot only due to the cost of collecting million-context tasks but also in\nidentifying realistic scenarios that require significant contexts. We identify\ncode comprehension and repair as a natural testbed and challenge task for\nlong-context models and introduce LongCodeBench (LCB), a benchmark to test LLM\ncoding abilities in long-context scenarios. Our benchmark tests both the\ncomprehension and repair capabilities of LCLMs in realistic and important\nsettings by drawing from real-world GitHub issues and constructing QA\n(LongCodeQA) and bug fixing (LongSWE-Bench) tasks. We carefully stratify the\ncomplexity of our benchmark, enabling us to evaluate models across different\nscales -- ranging from Qwen2.5 14B Instruct to Google's flagship Gemini model.\nWe find that long-context remains a weakness for all models, with performance\ndrops such as from 29% to 3% for Claude 3.5 Sonnet, or from 70.2% to 40% for\nQwen2.5.",
      "tldr_zh": "该研究引入了LongCodeBench基准测试，用于评估大语言模型(LLMs)在1M上下文窗口下的编码能力，针对长上下文场景的挑战。LongCodeBench基于真实GitHub问题构建了QA任务(LongCodeQA)和bug修复任务(LongSWE-Bench)，测试模型的代码理解和修复能力，并覆盖不同规模的模型，如Qwen2.5 14B Instruct和Gemini。结果显示，长上下文仍是模型的弱点，例如Claude 3.5 Sonnet的性能从29%降至3%，Qwen2.5从70.2%降至40%，突显了改进长上下文处理的需求。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07897v1",
      "published_date": "2025-05-12 05:38:03 UTC",
      "updated_date": "2025-05-12 05:38:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:41:56.284627"
    },
    {
      "arxiv_id": "2505.07239v1",
      "title": "Comet: Accelerating Private Inference for Large Language Model by Predicting Activation Sparsity",
      "title_zh": "Comet：通过预测激活稀疏性加速大型语言模型的隐私推理",
      "authors": [
        "Guang Yan",
        "Yuhui Zhang",
        "Zimu Guo",
        "Lutan Zhao",
        "Xiaojun Chen",
        "Chen Wang",
        "Wenhao Wang",
        "Dan Meng",
        "Rui Hou"
      ],
      "abstract": "With the growing use of large language models (LLMs) hosted on cloud\nplatforms to offer inference services, privacy concerns about the potential\nleakage of sensitive information are escalating. Secure multi-party computation\n(MPC) is a promising solution to protect the privacy in LLM inference. However,\nMPC requires frequent inter-server communication, causing high performance\noverhead.\n  Inspired by the prevalent activation sparsity of LLMs, where most neuron are\nnot activated after non-linear activation functions, we propose an efficient\nprivate inference system, Comet. This system employs an accurate and fast\npredictor to predict the sparsity distribution of activation function output.\nAdditionally, we introduce a new private inference protocol. It efficiently and\nsecurely avoids computations involving zero values by exploiting the spatial\nlocality of the predicted sparse distribution. While this computation-avoidance\napproach impacts the spatiotemporal continuity of KV cache entries, we address\nthis challenge with a low-communication overhead cache refilling strategy that\nmerges miss requests and incorporates a prefetching mechanism. Finally, we\nevaluate Comet on four common LLMs and compare it with six state-of-the-art\nprivate inference systems. Comet achieves a 1.87x-2.63x speedup and a\n1.94x-2.64x communication reduction.",
      "tldr_zh": "本论文提出了一种名为 Comet 的高效私有推理系统，旨在解决大型语言模型（LLMs）在云端推理中隐私泄露问题，同时缓解安全多方计算（MPC）带来的高性能开销。Comet 通过预测激活稀疏性（activation sparsity）的分布，使用一个准确快速的预测器和新的私有推理协议，避免零值计算，并通过低通信开销的 KV cache 重填策略处理时空连续性挑战。实验结果显示，Comet 在四个常见 LLMs 上比六种最先进系统实现 1.87x-2.63x 的加速和 1.94x-2.64x 的通信减少，为隐私保护的 LLM 推理提供了高效解决方案。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted to SP 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.07239v1",
      "published_date": "2025-05-12 05:29:30 UTC",
      "updated_date": "2025-05-12 05:29:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:41:56.086268"
    },
    {
      "arxiv_id": "2505.07236v1",
      "title": "UAV-CodeAgents: Scalable UAV Mission Planning via Multi-Agent ReAct and Vision-Language Reasoning",
      "title_zh": "UAV-CodeAgents：通过多智能体 ReAct 和视觉-语言推理的可扩展无人机任务规划",
      "authors": [
        "Oleg Sautenkov",
        "Yasheerah Yaqoot",
        "Muhammad Ahsan Mustafa",
        "Faryal Batool",
        "Jeffrin Sam",
        "Artem Lykov",
        "Chih-Yung Wen",
        "Dzmitry Tsetserukou"
      ],
      "abstract": "We present UAV-CodeAgents, a scalable multi-agent framework for autonomous\nUAV mission generation, built on large language and vision-language models\n(LLMs/VLMs). The system leverages the ReAct (Reason + Act) paradigm to\ninterpret satellite imagery, ground high-level natural language instructions,\nand collaboratively generate UAV trajectories with minimal human supervision. A\ncore component is a vision-grounded, pixel-pointing mechanism that enables\nprecise localization of semantic targets on aerial maps. To support real-time\nadaptability, we introduce a reactive thinking loop, allowing agents to\niteratively reflect on observations, revise mission goals, and coordinate\ndynamically in evolving environments.\n  UAV-CodeAgents is evaluated on large-scale mission scenarios involving\nindustrial and environmental fire detection. Our results show that a lower\ndecoding temperature (0.5) yields higher planning reliability and reduced\nexecution time, with an average mission creation time of 96.96 seconds and a\nsuccess rate of 93%. We further fine-tune Qwen2.5VL-7B on 9,000 annotated\nsatellite images, achieving strong spatial grounding across diverse visual\ncategories. To foster reproducibility and future research, we will release the\nfull codebase and a novel benchmark dataset for vision-language-based UAV\nplanning.",
      "tldr_zh": "本研究提出UAV-CodeAgents，一种基于多智能体ReAct（Reason + Act）范式和视觉语言推理的可扩展框架，用于无人机的自主任务规划。该系统利用LLMs/VLMs模型解释卫星图像、处理自然语言指令，并通过视觉基础的像素指向机制实现语义目标的精确定位，同时引入反应性思考循环以支持实时环境适应。实验在工业和环境火灾检测场景中显示，低解码温度（0.5）提升了规划可靠性，平均任务创建时间为96.96秒，成功率达93%；此外，作者微调了Qwen2.5VL-7B模型并将发布代码和基准数据集，以促进未来研究。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Submitted",
      "pdf_url": "http://arxiv.org/pdf/2505.07236v1",
      "published_date": "2025-05-12 05:23:51 UTC",
      "updated_date": "2025-05-12 05:23:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:41:57.213951"
    },
    {
      "arxiv_id": "2505.07233v1",
      "title": "DynamicRAG: Leveraging Outputs of Large Language Model as Feedback for Dynamic Reranking in Retrieval-Augmented Generation",
      "title_zh": "DynamicRAG：利用大语言模型输出作为反馈进行检索增强生成中的动态重新排序",
      "authors": [
        "Jiashuo Sun",
        "Xianrui Zhong",
        "Sizhe Zhou",
        "Jiawei Han"
      ],
      "abstract": "Retrieval-augmented generation (RAG) systems combine large language models\n(LLMs) with external knowledge retrieval, making them highly effective for\nknowledge-intensive tasks. A crucial but often under-explored component of\nthese systems is the reranker, which refines retrieved documents to enhance\ngeneration quality and explainability. The challenge of selecting the optimal\nnumber of documents (k) remains unsolved: too few may omit critical\ninformation, while too many introduce noise and inefficiencies. Although recent\nstudies have explored LLM-based rerankers, they primarily leverage internal\nmodel knowledge and overlook the rich supervisory signals that LLMs can\nprovide, such as using response quality as feedback for optimizing reranking\ndecisions. In this paper, we propose DynamicRAG, a novel RAG framework where\nthe reranker dynamically adjusts both the order and number of retrieved\ndocuments based on the query. We model the reranker as an agent optimized\nthrough reinforcement learning (RL), using rewards derived from LLM output\nquality. Across seven knowledge-intensive datasets, DynamicRAG demonstrates\nsuperior performance, achieving state-of-the-art results. The model, data and\ncode are available at https://github.com/GasolSun36/DynamicRAG",
      "tldr_zh": "本论文提出 DynamicRAG，一种新型 Retrieval-Augmented Generation (RAG) 框架，通过利用大型语言模型 (LLMs) 的输出作为反馈，动态优化 reranker 组件的文档顺序和数量，以解决传统 RAG 系统在选择最佳文档数量 (k) 时可能遗漏信息或引入噪声的问题。框架将 reranker 建模为一个通过强化学习 (RL) 优化的代理，使用 LLMs 输出质量作为奖励信号，实现对查询的适应性调整。在七个知识密集型数据集上的实验中，DynamicRAG 取得了 state-of-the-art 性能，展示了其在提升生成质量和解释性方面的显著优势。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "24 pages, 6 figures, 15 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.07233v1",
      "published_date": "2025-05-12 05:19:01 UTC",
      "updated_date": "2025-05-12 05:19:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:42:06.600410"
    },
    {
      "arxiv_id": "2505.07215v1",
      "title": "Measuring General Intelligence with Generated Games",
      "title_zh": "通过生成的游戏测量通用智能",
      "authors": [
        "Vivek Verma",
        "David Huang",
        "William Chen",
        "Dan Klein",
        "Nicholas Tomlin"
      ],
      "abstract": "We present gg-bench, a collection of game environments designed to evaluate\ngeneral reasoning capabilities in language models. Unlike most static\nbenchmarks, gg-bench is a data generating process where new evaluation\ninstances can be generated at will. In particular, gg-bench is synthetically\ngenerated by (1) using a large language model (LLM) to generate natural\nlanguage descriptions of novel games, (2) using the LLM to implement each game\nin code as a Gym environment, and (3) training reinforcement learning (RL)\nagents via self-play on the generated games. We evaluate language models by\ntheir winrate against these RL agents by prompting models with the game\ndescription, current board state, and a list of valid moves, after which models\noutput the moves they wish to take. gg-bench is challenging: state-of-the-art\nLLMs such as GPT-4o and Claude 3.7 Sonnet achieve winrates of 7-9% on gg-bench\nusing in-context learning, while reasoning models such as o1, o3-mini and\nDeepSeek-R1 achieve average winrates of 31-36%. We release the generated games,\ndata generation process, and evaluation code in order to support future\nmodeling work and expansion of our benchmark.",
      "tldr_zh": "该论文提出 gg-bench，一种动态生成游戏环境集合，用于评估语言模型的一般推理能力，与传统静态基准不同，该基准通过大语言模型 (LLM) 生成新游戏描述、实现为 Gym 环境，并训练强化学习 (RL) 代理进行自对弈。评估方法涉及语言模型基于游戏描述、当前棋盘状态和有效移动输出决策，与 RL 代理对弈。实验结果显示，顶级 LLM 如 GPT-4o 和 Claude 3.7 Sonnet 的胜率仅 7-9%，而推理模型如 o1、o3-mini 和 DeepSeek-R1 的平均胜率达 31-36%，突显了现有模型的推理局限性。作者开源了生成的游戏、数据生成过程和评估代码，以支持未来模型开发和基准扩展。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07215v1",
      "published_date": "2025-05-12 04:01:03 UTC",
      "updated_date": "2025-05-12 04:01:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:42:08.059084"
    },
    {
      "arxiv_id": "2505.07214v2",
      "title": "Towards user-centered interactive medical image segmentation in VR with an assistive AI agent",
      "title_zh": "朝向用户中心化的交互式医学图像分割：在 VR 中使用辅助 AI 代理",
      "authors": [
        "Pascal Spiegler",
        "Arash Harirpoush",
        "Yiming Xiao"
      ],
      "abstract": "Crucial in disease analysis and surgical planning, manual segmentation of\nvolumetric medical scans (e.g. MRI, CT) is laborious, error-prone, and\nchallenging to master, while fully automatic algorithms can benefit from user\nfeedback. Therefore, with the complementary power of the latest radiological AI\nfoundation models and virtual reality (VR)'s intuitive data interaction, we\npropose SAMIRA, a novel conversational AI agent that assists users with\nlocalizing, segmenting, and visualizing 3D medical concepts in VR. Through\nspeech-based interaction, the agent helps users understand radiological\nfeatures, locate clinical targets, and generate segmentation masks that can be\nrefined with just a few point prompts. The system also supports true-to-scale\n3D visualization of segmented pathology to enhance patient-specific anatomical\nunderstanding. Furthermore, to determine the optimal interaction paradigm under\nnear-far attention-switching for refining segmentation masks in an immersive,\nhuman-in-the-loop workflow, we compare VR controller pointing, head pointing,\nand eye tracking as input modes. With a user study, evaluations demonstrated a\nhigh usability score (SUS=90.0 $\\pm$ 9.0), low overall task load, as well as\nstrong support for the proposed VR system's guidance, training potential, and\nintegration of AI in radiological segmentation tasks.",
      "tldr_zh": "本研究针对手动分割医学图像（如 MRI 和 CT）的费时和易错问题，提出 SAMIRA，一种用户中心的对话式 AI 代理，结合放射学 AI 基础模型和 VR 技术，帮助用户在虚拟现实环境中定位、分割和可视化 3D 医学概念。系统通过语音交互允许用户理解放射学特征、生成并精炼分割掩码，并支持真实比例的 3D 病理可视化，以提升患者解剖理解。实验比较了 VR 控制器指向、头部指向和眼动追踪等交互模式，结果显示系统具有高可用性（SUS=90.0 ± 9.0）、低任务负荷，并为放射学分割任务的 AI 整合提供强有力支持。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07214v2",
      "published_date": "2025-05-12 03:47:05 UTC",
      "updated_date": "2025-05-15 05:47:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:42:09.616990"
    },
    {
      "arxiv_id": "2505.07896v1",
      "title": "Bridging Large Language Models and Single-Cell Transcriptomics in Dissecting Selective Motor Neuron Vulnerability",
      "title_zh": "桥接大语言模型和单细胞转录组学以剖析选择性运动神经元易损性",
      "authors": [
        "Douglas Jiang",
        "Zilin Dai",
        "Luxuan Zhang",
        "Qiyi Yu",
        "Haoqi Sun",
        "Feng Tian"
      ],
      "abstract": "Understanding cell identity and function through single-cell level sequencing\ndata remains a key challenge in computational biology. We present a novel\nframework that leverages gene-specific textual annotations from the NCBI Gene\ndatabase to generate biologically contextualized cell embeddings. For each cell\nin a single-cell RNA sequencing (scRNA-seq) dataset, we rank genes by\nexpression level, retrieve their NCBI Gene descriptions, and transform these\ndescriptions into vector embedding representations using large language models\n(LLMs). The models used include OpenAI text-embedding-ada-002,\ntext-embedding-3-small, and text-embedding-3-large (Jan 2024), as well as\ndomain-specific models BioBERT and SciBERT. Embeddings are computed via an\nexpression-weighted average across the top N most highly expressed genes in\neach cell, providing a compact, semantically rich representation. This\nmultimodal strategy bridges structured biological data with state-of-the-art\nlanguage modeling, enabling more interpretable downstream applications such as\ncell-type clustering, cell vulnerability dissection, and trajectory inference.",
      "tldr_zh": "本研究提出一个新框架，将大型语言模型（LLMs）与单细胞转录组学（scRNA-seq）相结合，旨在通过 NCBI Gene 数据库的基因文本注释生成生物学背景化的细胞嵌入，从而解析选择性运动神经元易损性。方法包括对每个细胞按基因表达水平排名，检索相应基因描述，并使用 LLMs（如 OpenAI text-embedding-ada-002、text-embedding-3-small 和 text-embedding-3-large，以及 BioBERT 和 SciBERT）计算表达加权平均嵌入，提供紧凑且语义丰富的表示。这种多模态策略提升了下游应用的解释性，包括细胞类型聚类、细胞易损性剖析和轨迹推断。",
      "categories": [
        "q-bio.GN",
        "cs.AI"
      ],
      "primary_category": "q-bio.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07896v1",
      "published_date": "2025-05-12 03:39:33 UTC",
      "updated_date": "2025-05-12 03:39:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:42:13.710617"
    },
    {
      "arxiv_id": "2505.07895v1",
      "title": "Representation Learning with Mutual Influence of Modalities for Node Classification in Multi-Modal Heterogeneous Networks",
      "title_zh": "多模态异构网络中基于模态相互影响的表示学习用于节点分类",
      "authors": [
        "Jiafan Li",
        "Jiaqi Zhu",
        "Liang Chang",
        "Yilin Li",
        "Miaomiao Li",
        "Yang Wang",
        "Hongan Wang"
      ],
      "abstract": "Nowadays, numerous online platforms can be described as multi-modal\nheterogeneous networks (MMHNs), such as Douban's movie networks and Amazon's\nproduct review networks. Accurately categorizing nodes within these networks is\ncrucial for analyzing the corresponding entities, which requires effective\nrepresentation learning on nodes. However, existing multi-modal fusion methods\noften adopt either early fusion strategies which may lose the unique\ncharacteristics of individual modalities, or late fusion approaches overlooking\nthe cross-modal guidance in GNN-based information propagation. In this paper,\nwe propose a novel model for node classification in MMHNs, named Heterogeneous\nGraph Neural Network with Inter-Modal Attention (HGNN-IMA). It learns node\nrepresentations by capturing the mutual influence of multiple modalities during\nthe information propagation process, within the framework of heterogeneous\ngraph transformer. Specifically, a nested inter-modal attention mechanism is\nintegrated into the inter-node attention to achieve adaptive multi-modal\nfusion, and modality alignment is also taken into account to encourage the\npropagation among nodes with consistent similarities across all modalities.\nMoreover, an attention loss is augmented to mitigate the impact of missing\nmodalities. Extensive experiments validate the superiority of the model in the\nnode classification task, providing an innovative view to handle multi-modal\ndata, especially when accompanied with network structures.",
      "tldr_zh": "本研究针对多模态异构网络（Multi-Modal Heterogeneous Networks）中的节点分类问题，提出了一种新模型Heterogeneous Graph Neural Network with Inter-Modal Attention (HGNN-IMA)，通过捕获模态之间的相互影响来实现有效的节点表示学习。模型在异构图变换器框架下，整合了嵌套的跨模态注意力机制（Inter-Modal Attention），实现自适应多模态融合，并通过模态对齐（Modality Alignment）和注意力损失（Attention Loss）来处理信息传播和缺失模态问题。实验结果显示，HGNN-IMA 在节点分类任务上优于现有方法，提供了一种创新视角来处理网络结构下的多模态数据。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07895v1",
      "published_date": "2025-05-12 02:59:46 UTC",
      "updated_date": "2025-05-12 02:59:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:42:14.507069"
    },
    {
      "arxiv_id": "2505.08808v1",
      "title": "SparseMeXT Unlocking the Potential of Sparse Representations for HD Map Construction",
      "title_zh": "SparseMeXT：释放稀疏表示在 HD 地图构建中的潜力",
      "authors": [
        "Anqing Jiang",
        "Jinhao Chai",
        "Yu Gao",
        "Yiru Wang",
        "Yuwen Heng",
        "Zhigang Sun",
        "Hao Sun",
        "Zezhong Zhao",
        "Li Sun",
        "Jian Zhou",
        "Lijuan Zhu",
        "Shugong Xu",
        "Hao Zhao"
      ],
      "abstract": "Recent advancements in high-definition \\emph{HD} map construction have\ndemonstrated the effectiveness of dense representations, which heavily rely on\ncomputationally intensive bird's-eye view \\emph{BEV} features. While sparse\nrepresentations offer a more efficient alternative by avoiding dense BEV\nprocessing, existing methods often lag behind due to the lack of tailored\ndesigns. These limitations have hindered the competitiveness of sparse\nrepresentations in online HD map construction. In this work, we systematically\nrevisit and enhance sparse representation techniques, identifying key\narchitectural and algorithmic improvements that bridge the gap with--and\nultimately surpass--dense approaches. We introduce a dedicated network\narchitecture optimized for sparse map feature extraction, a sparse-dense\nsegmentation auxiliary task to better leverage geometric and semantic cues, and\na denoising module guided by physical priors to refine predictions. Through\nthese enhancements, our method achieves state-of-the-art performance on the\nnuScenes dataset, significantly advancing HD map construction and centerline\ndetection. Specifically, SparseMeXt-Tiny reaches a mean average precision\n\\emph{mAP} of 55.5% at 32 frames per second \\emph{fps}, while SparseMeXt-Base\nattains 65.2% mAP. Scaling the backbone and decoder further, SparseMeXt-Large\nachieves an mAP of 68.9% at over 20 fps, establishing a new benchmark for\nsparse representations in HD map construction. These results underscore the\nuntapped potential of sparse methods, challenging the conventional reliance on\ndense representations and redefining efficiency-performance trade-offs in the\nfield.",
      "tldr_zh": "该论文探讨了在 HD 地图构建中利用稀疏表示（sparse representations）的潜力，以克服现有方法的计算密集型 BEV 特征依赖问题。作者引入了 SparseMeXT 框架，包括专用的网络架构、稀疏-密集分割辅助任务以及基于物理先验的去噪模块，这些创新设计显著提升了稀疏表示的性能和效率。在 nuScenes 数据集上，SparseMeXT-Tiny 达到 55.5% mAP at 32 fps，SparseMeXT-Base 达 65.2% mAP，而 SparseMeXT-Large 则实现 68.9% mAP at over 20 fps，超越了传统密集方法，并重新定义了效率与性能的权衡。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08808v1",
      "published_date": "2025-05-12 02:26:58 UTC",
      "updated_date": "2025-05-12 02:26:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:42:15.376758"
    },
    {
      "arxiv_id": "2505.07178v1",
      "title": "Accountability of Generative AI: Exploring a Precautionary Approach for \"Artificially Created Nature\"",
      "title_zh": "生成式 AI 的问责制：探索针对“人工创造的自然”的预防性方法",
      "authors": [
        "Yuri Nakao"
      ],
      "abstract": "The rapid development of generative artificial intelligence (AI) technologies\nraises concerns about the accountability of sociotechnical systems. Current\ngenerative AI systems rely on complex mechanisms that make it difficult for\neven experts to fully trace the reasons behind the outputs. This paper first\nexamines existing research on AI transparency and accountability and argues\nthat transparency is not a sufficient condition for accountability but can\ncontribute to its improvement. We then discuss that if it is not possible to\nmake generative AI transparent, generative AI technology becomes ``artificially\ncreated nature'' in a metaphorical sense, and suggest using the precautionary\nprinciple approach to consider AI risks. Finally, we propose that a platform\nfor citizen participation is needed to address the risks of generative AI.",
      "tldr_zh": "该论文探讨了生成式 AI 的责任性问题，审查现有 AI 透明度和责任性研究，并论证透明度虽有助于改善但并非充分条件。作者将不可透明的生成式 AI 比喻为“artificially created nature”，建议采用 precautionary principle 的预防性方法来评估和应对潜在风险。最后，论文提出建立公民参与平台，以共同管理生成式 AI 的风险挑战。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.07178v1",
      "published_date": "2025-05-12 02:10:55 UTC",
      "updated_date": "2025-05-12 02:10:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:42:15.603118"
    },
    {
      "arxiv_id": "2505.08807v1",
      "title": "Security of Internet of Agents: Attacks and Countermeasures",
      "title_zh": "智能体互联网的安全：攻击与对策",
      "authors": [
        "Yuntao Wang",
        "Yanghe Pan",
        "Shaolong Guo",
        "Zhou Su"
      ],
      "abstract": "With the rise of large language and vision-language models, AI agents have\nevolved into autonomous, interactive systems capable of perception, reasoning,\nand decision-making. As they proliferate across virtual and physical domains,\nthe Internet of Agents (IoA) has emerged as a key infrastructure for enabling\nscalable and secure coordination among heterogeneous agents. This survey offers\na comprehensive examination of the security and privacy landscape in IoA\nsystems. We begin by outlining the IoA architecture and its distinct\nvulnerabilities compared to traditional networks, focusing on four critical\naspects: identity authentication threats, cross-agent trust issues, embodied\nsecurity, and privacy risks. We then review existing and emerging defense\nmechanisms and highlight persistent challenges. Finally, we identify open\nresearch directions to advance the development of resilient and\nprivacy-preserving IoA ecosystems.",
      "tldr_zh": "这篇调查论文探讨了Internet of Agents (IoA) 的安全和隐私挑战，随着AI agents 的兴起及其在虚拟和物理领域的扩散。论文首先概述了IoA 架构及其与传统网络不同的漏洞，重点关注四个关键方面：身份认证威胁、跨-agent 信任问题、embodied security 和隐私风险。接着，它审查了现有的和新兴的防御机制，强调了持续挑战，并提出了推进IoA 生态系统韧性和隐私保护的开放研究方向。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "11 pages, 5 figures, 3 tables, submitted to IEEE OJCS",
      "pdf_url": "http://arxiv.org/pdf/2505.08807v1",
      "published_date": "2025-05-12 02:04:57 UTC",
      "updated_date": "2025-05-12 02:04:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:42:19.028519"
    },
    {
      "arxiv_id": "2505.07176v1",
      "title": "Internet of Agents: Fundamentals, Applications, and Challenges",
      "title_zh": "智能体互联网：基础、应用和挑战",
      "authors": [
        "Yuntao Wang",
        "Shaolong Guo",
        "Yanghe Pan",
        "Zhou Su",
        "Fahao Chen",
        "Tom H. Luan",
        "Peng Li",
        "Jiawen Kang",
        "Dusit Niyato"
      ],
      "abstract": "With the rapid proliferation of large language models and vision-language\nmodels, AI agents have evolved from isolated, task-specific systems into\nautonomous, interactive entities capable of perceiving, reasoning, and acting\nwithout human intervention. As these agents proliferate across virtual and\nphysical environments, from virtual assistants to embodied robots, the need for\na unified, agent-centric infrastructure becomes paramount. In this survey, we\nintroduce the Internet of Agents (IoA) as a foundational framework that enables\nseamless interconnection, dynamic discovery, and collaborative orchestration\namong heterogeneous agents at scale. We begin by presenting a general IoA\narchitecture, highlighting its hierarchical organization, distinguishing\nfeatures relative to the traditional Internet, and emerging applications. Next,\nwe analyze the key operational enablers of IoA, including capability\nnotification and discovery, adaptive communication protocols, dynamic task\nmatching, consensus and conflict-resolution mechanisms, and incentive models.\nFinally, we identify open research directions toward building resilient and\ntrustworthy IoA ecosystems.",
      "tldr_zh": "这篇论文探讨了 AI 代理的演变，从孤立的特定任务系统发展为自主互动实体，并引入 Internet of Agents (IoA) 作为一种统一的框架，支持异构代理在虚拟和物理环境中的无缝连接、动态发现和协作编排。IoA 架构采用分层组织，突出其与传统 Internet 的区别，并涵盖新兴应用，如虚拟助理和机器人。论文分析了关键操作要素，包括 capability notification and discovery、adaptive communication protocols、dynamic task matching、consensus and conflict-resolution mechanisms 以及激励模型，并指出了构建弹性、可信 IoA 生态系统的未来研究方向。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "22 pages,10 figures, 8 tables. Submitted to IEEE TCCN",
      "pdf_url": "http://arxiv.org/pdf/2505.07176v1",
      "published_date": "2025-05-12 02:04:37 UTC",
      "updated_date": "2025-05-12 02:04:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:42:20.699966"
    },
    {
      "arxiv_id": "2505.07171v1",
      "title": "ReCDAP: Relation-Based Conditional Diffusion with Attention Pooling for Few-Shot Knowledge Graph Completion",
      "title_zh": "ReCDAP：基于关系的条件扩散模型，结合注意力池化，用于少样本知识图谱补全",
      "authors": [
        "Jeongho Kim",
        "Chanyeong Heo",
        "Jaehee Jung"
      ],
      "abstract": "Knowledge Graphs (KGs), composed of triples in the form of (head, relation,\ntail) and consisting of entities and relations, play a key role in information\nretrieval systems such as question answering, entity search, and\nrecommendation. In real-world KGs, although many entities exist, the relations\nexhibit a long-tail distribution, which can hinder information retrieval\nperformance. Previous few-shot knowledge graph completion studies focused\nexclusively on the positive triple information that exists in the graph or,\nwhen negative triples were incorporated, used them merely as a signal to\nindicate incorrect triples. To overcome this limitation, we propose\nRelation-Based Conditional Diffusion with Attention Pooling (ReCDAP). First,\nnegative triples are generated by randomly replacing the tail entity in the\nsupport set. By conditionally incorporating positive information in the KG and\nnon-existent negative information into the diffusion process, the model\nseparately estimates the latent distributions for positive and negative\nrelations. Moreover, including an attention pooler enables the model to\nleverage the differences between positive and negative cases explicitly.\nExperiments on two widely used datasets demonstrate that our method outperforms\nexisting approaches, achieving state-of-the-art performance. The code is\navailable at https://github.com/hou27/ReCDAP-FKGC.",
      "tldr_zh": "该研究针对知识图谱(KGs)中关系长尾分布导致的少样本完成问题，提出ReCDAP方法，通过生成负三元组并使用基于关系的条件扩散(Conditional Diffusion)来整合正负信息，并引入注意力池化(Attention Pooling)以显式区分正负案例差异。相比以往仅关注正三元组的局限，该方法能更准确地估计潜在分布，从而提升KGs的完成性能。在两个常用数据集上的实验显示，ReCDAP超越现有方法，实现了最先进结果。",
      "categories": [
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by SIGIR 2025, 5 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2505.07171v1",
      "published_date": "2025-05-12 01:49:52 UTC",
      "updated_date": "2025-05-12 01:49:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T10:42:23.882909"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 130,
  "processed_papers_count": 130,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-16T10:42:50.929922"
}